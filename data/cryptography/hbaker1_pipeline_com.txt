
@_date: 2014-12-01 13:15:55
@_author: Henry Baker 
@_subject: [Cryptography] "completely unexpected" drop in Cisco's foreign 
Companies with "round heels" for the NSA/FBI/GCHQ get what they deserve.
Perhaps when Cisco grows a backbone like Lavabit they will gain some respect.

@_date: 2014-12-02 08:13:37
@_author: Henry Baker 
@_subject: [Cryptography] [cryptography] Underhanded Crypto 
Relying on an _uninitialized variable_ to produce randomness is perhaps even more idiotic than blaming the person who removed this line of code.
In my >50 years of programming, I've never found the values of uninitialized variables to be particularly random; in an awful lot of systems, these uninitialized variables are set to all zero bits.
If you want randomness, then make it explicit by calling some procedure that produces randomness.
Valgrind & Purify were correct to flag these programs.

@_date: 2014-12-03 07:09:22
@_author: Henry Baker 
@_subject: [Cryptography] Why Alexander Hanff won't be using "Let's Encrypt" 
FYI --
Why I won't be using "Let's Encrypt" and recommend others not to also.
Alexander Hanff, Chief Privacy Officer at Connect In Private
November 20, 2014
'... it should be as clear as day to any group remotely knowledgeable about online security (such as EFF, CDT and Mozilla, who are behind the Let's Encrypt project) that creating a new Super Certificate Authority is the equivalent of painting a huge red target onto the backs of all the people who use it.'
'Let's not mix our words here, it will become a target - that much is completely indisputable, it would be utterly naive to believe the US Government will not target this new CA with court orders.  What's more, given the historical evidence, there is a strong chance that such orders will be for "super master keys" allowing them to pretend to be whomever they like and it will be done under the guise of National Security because of course a CA which provides free certificates for everyone is (in the eyes of law enforcement) a hotbed for criminals and terrorists - why on earth would a terrorist pay Verisign for an SSL certificate, leaving a paper trail, if they can obtain an anonymous certificate for free from Let's Encrypt?'
'It is an insane strategy by all parties involved - it removes all confidence in TLS certificates as far as I am concerned and I will absolutely not be using the service and have to strongly recommend others refrain from doing so as well.'

@_date: 2014-12-03 21:29:34
@_author: Henry Baker 
@_subject: [Cryptography] Construction of cryptographic software. 
Well, actually there are higher-level languages which can control
copies & copying.
The concept of "linear variables" (from the ideas of "linear
logic") is what you want.
Linear ("use-once"; actually "use-exactly-once") variables can't
be copied, although their contents can -- but the copying must
be explicit.  Furthermore, linear variables _must_ be referenced
at least once and at most once, so you can't just ignore them. In particular, if you "consume" such a variable in one arm of a
conditional, you must also "consume" that variable in the other
Note that typical faulting instructions like divide-by-zero which
occur in one arm of a conditional must be caught in such a way
that any linear variables consumed in the other arm are also
consumed in the fault handler.  Thus, dealing with linear variables
often requires some sort of transaction block mechanism.
"Exchange" instructions -- e.g., PDP-10 EXCH -- work quite well
with these linear variables.  Stacks also work, so long as the
memory cells "above the stack" are properly zeroed out.  (Check
out some of the classic Burroughs architectures.)
If these linear variables sound suspiciously like non-cloneable
quantum states and/or transactional QM, then you have begun to
grok them correctly.
I have some examples of how to program with such _linear variables_
in some papers in my paper repository:

@_date: 2014-12-04 10:23:18
@_author: Henry Baker 
@_subject: [Cryptography] Construction of cryptographic software. 
Good set of rules.
Most of these rules can be incorporated into a strong type system that is capable of enforcing these rules.
There have been a large number of papers which discuss various typing systems which can be used for such purposes.
For example, check out the references in this paper:
Size: 228 KB (233,053 bytes)

@_date: 2014-12-04 11:53:25
@_author: Henry Baker 
@_subject: [Cryptography] Sites certified as secure often more vulnerable 
Sites certified as secure often more vulnerable to hacking, scientists find
Security seals aren't worth the bits they're made of, let alone the fees.
by Dan Goodin - Dec 4, 2014 6:36 pm UTC

@_date: 2014-12-05 23:29:32
@_author: Henry Baker 
@_subject: [Cryptography] cost-watch - the cost of the Target breach 
"It's also not at all clear that the banks were the ones who resisted on chip and pin.  *They* wouldn't be the ones bearing the costs of replacing all the card readers out there - and they stand to gain from the liability shift that leaves merchants who don't get new terminals stuck with any loses.  Over all, win/win for the banks."
Ross Anderson has been analyzing chip&pin for years & found that there are just as many problems with chip&pin as with the magstripe cards.
Ross points out (if I recall his comments correctly) that with chip&pin, the burden of proof moves away from the banks, which is why the banks are so hot for chip&pin.  But don't hold your breath waiting for chip&pin to produce any improvement.  I just read that the new US chip&pin system has already been hacked, and it isn't even in real service here yet!

@_date: 2014-12-06 21:14:36
@_author: Henry Baker 
@_subject: [Cryptography] cost-watch - the cost of the Target breach 
I finally found the article:
Krebs on Security In-depth security news and investigation
27 Oct 14
?Replay? Attacks Spoof Chip Card Charges
An odd new pattern of credit card fraud emanating from Brazil and targeting U.S. financial institutions could spell costly trouble for banks that are just beginning to issue customers more secure chip-based credit and debit cards.
Over the past week, at least three U.S. financial institutions reported receiving tens of thousands of dollars in fraudulent credit and debit card transactions coming from Brazil and hitting card accounts stolen in recent retail heists, principally cards compromised as part of the breach at Home Depot.
The most puzzling aspect of these unauthorized charges?  They were all submitted through Visa and MasterCard?s networks as chip-enabled transactions, even though the banks that issued the cards in question haven?t even yet begun sending customers chip-enabled cards.
The most frustrating aspect of these unauthorized charges?  They?re far harder for the bank to dispute.  Banks usually end up eating the cost of fraud from unauthorized transactions when scammers counterfeit and use stolen credit cards.  Even so, a bank may be able to recover some of that loss through dispute mechanisms set up by Visa and MasterCard, as long as the bank can show that the fraud was the result of a breach at a specific merchant (in this case Home Depot).
However, banks are responsible for all of the fraud costs that occur from any fraudulent use of their customers? chip-enabled credit/debit cards ? even fraudulent charges disguised as these pseudo-chip transactions.
CLONED CHIP CARDS, OR CLONED TRANSACTIONS?
The bank I first heard from about this fraud ? a small financial institution in New England ? battled some $120,000 in fraudulent charges from Brazilian stores in less than two days beginning last week.  The bank managed to block $80,000 of those fraudulent charges, but the bank?s processor, which approves incoming transactions when the bank?s core systems are offline, let through the other $40,000.  All of the transactions were debit charges, and all came across MasterCard?s network looking to MasterCard like chip transactions without a PIN.
The fraud expert with the New England bank said the institution had decided against reissuing customer cards that were potentially compromised in the five-month breach at Home Depot, mainly because that would mean reissuing a sizable chunk of the bank?s overall card base and because the bank had until that point seen virtually no fraud on the accounts.
?We saw very low penetration rates on our Home Depot cards, so we didn?t do a mass reissue,? the expert said.  ?And then in one day we matched a month?s worth of fraud on those cards thanks to these charges from Brazil.?
The New England bank initially considered the possibility that the perpetrators had somehow figured out how to clone chip cards and had encoded the cards with their customers? card data.  In theory, however, it should not be possible to easily clone a chip card.  Chip cards are synonymous with a standard called EMV (short for Europay, MasterCard and Visa), a global payment system that has already been adopted by every other G20 nation as a more secure alternative to cards that simply store account holder data on a card?s magnetic stripe.  EMV cards contain a secure microchip that is designed to make the card very difficult and expensive to counterfeit.
In addition, there are several checks that banks can use to validate the authenticity of chip card transactions.  The chip stores encrypted data about the cardholder account, as well as a ?cryptogram? that allows banks to tell whether a card or transaction has been modified in any way.  The chip also includes an internal counter mechanism that gets incremented with each sequential transaction, so that a duplicate counter value or one that skips ahead may indicate data copying or other fraud to the bank that issued the card.
And this is exactly what has bank fraud fighters scratching their heads: Why would the perpetrators go through all the trouble of taking plain old magnetic stripe cards stolen in the Home Depot breach (and ostensibly purchased in the cybercrime underground) and making those look like EMV transactions?  Why wouldn?t the scammers do what fraudsters normally do with this data, which is simply to create counterfeit cards and use the phony cards to buy gift cards and other high-priced merchandise from big box retailers?
More importantly, how were these supposed EMV transactions on non-EMV cards being put through the Visa and MasterCard network as EMV transactions in the first place?
The New England bank said MasterCard initially insisted that the charges were made using physical chip-based cards, but the bank protested that it hadn?t yet issued its customers any chip cards.  Furthermore, the bank?s processor hadn?t even yet been certified by MasterCard to handle chip card transactions, so why was MasterCard so sure that the phony transactions were chip-based?
EMV ?REPLAY? ATTACKS?
MasterCard did not respond to multiple requests to comment for this story.  Visa also declined to comment on the record.  But the New England bank told KrebsOnSecurity that in a conversation with MasterCard officials the credit card company said the most likely explanation was that fraudsters were pushing regular magnetic stripe transactions through the card network as EMV purchases using a technique known as a ?replay? attack.
According to the bank, MasterCard officials explained that the thieves were probably in control of a payment terminal and had the ability to manipulate data fields for transactions put through that terminal.  After capturing traffic from a real EMV-based chip card transaction, the thieves could insert stolen card data into the transaction stream, while modifying the merchant and acquirer bank account on the fly.
Avivah Litan, a fraud analyst with Gartner Inc., said banks in Canada saw the same EMV-spoofing attacks emanating from Brazil several months ago.  One of the banks there suffered a fairly large loss, she said, because the bank wasn?t checking the cryptograms or counters on the EMV transactions.
?The [Canadian] bank in this case would take any old cryptogram and they weren?t checking that one-time code because they didn?t have it implemented correctly,? Litan said.  ?If they saw an EMV transaction and didn?t see the code, they would just authorize the transaction.?
Litan said the fraudsters likely knew that the Canadian bank wasn?t checking the cryptogram and that it wasn?t looking for the dynamic counter code.
?The bad guys knew that if they encoded these as EMV transactions, the banks would loosen other fraud detection controls,? Litan said.  ?It appears with these attacks that the crooks aren?t breaking the EMV protocol, but taking advantage of bad implementations of it.  Doing EMV correctly is hard, and there are lots of ways to break not the cryptography but to mess with the implementation of EMV.?
The thieves also seem to be messing with the transaction codes and other aspects of the EMV transaction stream.  Litan said it?s likely that the perpetrators of this attack had their own payment terminals and were somehow able to manipulate the transaction fields in each charge.
?I remember when I went to Brazil a couple of years ago, their biggest problem was merchants were taking point-of-sale systems home, and then running stolen cards through them,? she said.  ?I?m sure they could rewire them to do whatever they wanted.  That was the biggest issue at the time.?
The New England bank shared with this author a list of the fraudulent transactions pushed through by the scammers in Brazil.  The bank said MasterCard is currently in the process of checking with the Brazilian merchants to see whether they had physical transactions that matched transactions shown on paper.
In the meantime, it appears that the largest share of those phony transactions were put through using a payment system called Payleven, a mobile payment service popular in Europe and Brazil that is similar in operation to Square.  Most of the transactions were for escalating amounts ? nearly doubling with each transaction ? indicating the fraudsters were putting through debit charges to see how much money they could drain from the compromised accounts.
Litan said attacks like this one illustrate the importance of banks setting up EMV correctly.  She noted that while the New England bank was able to flag the apparent EMV transactions as fraudulent in part because it hadn?t yet begun issuing EMV cards, the outcome might be different for a bank that had issued at least some chip cards.
?There?s going to be a lot of confusion when banks roll out EMV, and one thing I?ve learned from clients is how hard it is to implement properly,? Litan said.  ?A lot of banks will loosen other fraud controls right away, even before they verify that they?ve got EMV implemented correctly.  They won?t expect the point-of-sale codes to be manipulated by fraudsters.  That?s the irony: We think EMV is going to solve all our card fraud problems, but doing it correctly is going to take a lot longer than we thought.  It?s not that easy.?
Tags: avivah litan, chip cards, cloned EMV, EMV, EMV replay attack, Europay, Gartner Inc., mastercard, MasterCard and Visa, Visa
This entry was posted on Monday, October 27th, 2014 at 12:09 am and is filed under The Coming Storm, Web Fraud 2.0.

@_date: 2014-12-09 08:08:36
@_author: Henry Baker 
@_subject: [Cryptography] North Korea and Sony 
[below also in comp.risks]
The following paragraphs are an attempt to explain why the NSA hasn't any interest in protecting you and me from cyber criminals.  It isn't nonfeasance, but a result of the misapplication of Cold War thinking to the Internet, and the NSA's preoccupation with China instead of with criminal gangs on the Internet.
You and I and 300+ million ordinary citizens are merely the "human shields" in this new Cold Cyberwar which the US DoD has deluded itself exists with China.
The US Defense Department in 2014 is still caught up in obsolete concepts from the Cold War when it inappropriately attempts to achieve "deterrence" through "mutual vulnerability" in *cyber warfare*.
The concept of "Mutually Assured Destruction" (MAD) attempts to convince both sides in a conflict that no matter who starts a war, both sides will be utterly destroyed.  MAD was the primary doctrine of the US throughout most of the Cold War, and although the Soviets never did attack, they also never completely bought into the MAD notion.
A major component of MAD is "Mutual Vulnerability": since both sides are equally vulnerable, each feels that it has more to lose from a war than the other.  However, one curious consequence of Mutual Vulnerability is that *Civil Defense is actually destabilizing*.  If one side invests significantly in civil defense, it becomes less vulnerable, and may believe that a war is survivable.  Such a civil defense strategy will break the "Mutual" in MAD.
During the Cold War, therefore, the US invested almost nothing in civil defense; the Soviets -- not so enamored with mutual vulnerability -- invested huge amounts.
As the links & quotes below demonstrate, the US DoD today has already conceded that its cyber defenses are next-to-non-existent, and therefore has ramped up its *offenses* -- e.g., the NSA's "TAO" group -- because it believes that a MAD-style offensive deterrence is far cheaper than improving defenses (i.e., echoes of the US Cold War strategy).
In the upside-down-world of MAD, mutual deterrence depends upon *mutual vulnerability*, and hence *more vulnerable is better* !?!
The major problem with this MAD strategy is that while the deterrence may eventually work against the Chinese *state*, this deterrence has absolutely no effect against criminal enterprises terrorizing the Internet.  None of these criminals feel the "Mutual" in MAD, much less the "Assured" or the "Destruction".
So "MAD" is the reason why you and I remain vulnerable to ID crooks & thieves; the more vulnerable, the better the deterrence works -- at least against the Chinese.
If all of this sounds insane/MAD, you're right!  It is insane, which is why all of us have to blow the whistle on these bankrupt Cold War relic doctrines.
"A World Gone MAD No Longer"
[Selected paragraphs]
"To maintain this stability, both sides had to remain vulnerable to each other?s ballistic missiles and bombers.  As the Cold War advanced, North American air defenses were minimized, and civil defense was pared down.  Missile defenses, the greatest sin of all, were abolished in 1972 with the ratification of the Anti-Ballistic Missile (ABM) Treaty between the United States and the Soviet Union.  Any hope of limiting damage and saving lives in the event of a nuclear exchange was sacrificed upon the altar of Mutually Assured Destruction (MAD).  It was security through promised annihilation, and stability through self-inflicted vulnerability."
"Feeling secure in a state of vulnerability requires making some dubious assumptions about your adversary.  You must assume that your adversary is rational, and that he values what you are threatening to destroy with your retaliation, and that he never doubts your willingness to follow through on that threat.  You must assume that your opponent has accurate information about his strategic situation and has good judgment, and that judgment is not impaired by stress, mental health issues, or even chemical substances.  Even if all of these things just happen to be true all the time, you must also assume that your adversary has full control over its military, and that there is zero risk of a missile launch by a rogue element."
"Today, the United States faces multiple adversaries with ever-advancing ballistic missile capability.  North Korea likely already has the capability to strike parts of U.S. territory with a ballistic missile, and shows every intention of continuing to advance its capabilities.  Iran?s missiles can already reach parts of Europe, and we cannot predict how fast it could develop intercontinental-ranged missiles if it pursued a crash program."  [I.e., MAD doesn't work very well in a world with lots of smaller players.]
Size: 447 KB (457,262 bytes)
Sino-American Strategic Restraint in an Age of Vulnerability
by David C. Gompert and Phillip C. Saunders
[Selected paragraphs]
"... because the United States cannot escape its growing vulnerability to China unilaterally, Chinese agreement is needed; therefore, mutual restraint must address Chinese interests as well.  Our core idea is that mutual vulnerability calls for mutual restraint in the nuclear, space, and cyber domains.  Whether Sino-American distrust will preclude agreed restraint is one of the questions this paper tackles.  But even with distrust, self-interest in avoiding harm?-in a word, deterrence?-can move both powers in this direction."
"All three strategic domains are 'offense-dominant'?-technologically, economically, and operationally.  Defenses against nuclear, ASAT, and cyber weapons are difficult and yield diminishing results against the offensive capabilities of large, advanced, and determined states such as the United States and China."
"Likewise, defending computer networks becomes harder and more expensive as the scale and sophistication of the attacker increase.  ...  The diminishing returns on investment in cyber defense relative to offense are especially striking when considering the disparity between ?hacking? and ?patching? in complexity, cost, and time required: advanced network-defense software contains between 5 and 10 million lines of code; malware contains an average of 170 lines of code. 6  Protection of U.S. Government networks typically requires regulated public competition and acquisition, which can consume years before solutions are contracted for and installed; an attack can be designed and launched in weeks.  No sooner are effective defenses finally in place than cyber weapons to defeat them are in the works.  Strategic offense dominance gives each country incentives to invest in offense, which spurs the other to do the same to keep pace."
"Mutual restraint in cyberspace, the most complex domain, should entail a pledge by each country not to be the first to attack networks critical to the other?s well-being?-that is, 'strategic cyberspace.'  This restriction would not encompass noncritical networks or limit intelligence collection.  In the event of armed conflict, both Chinese and U.S. forces are likely to conduct attacks on military networks, the infrastructure for which may also support civilian networks, involving an inherent danger of escalation.  Therefore, as a corollary of mutual restraint, both governments bear responsibility to exert tight political control, not to escalate, and to avoid harm to noncombatants?-in effect, to create a firebreak between tactical cyber war, where deterrence may be weak, and strategic cyber war, where it ought to be strong.  Only in this way can the utility of military cyber war and the imperative of avoiding general cyber war be reconciled."
"While deterrence may not apply against many cyber threats?-in particular those from nonstate actors?-it could be relevant between large and capable states.  Due to the limits and costs of network defense, strategic cyber deterrence between China and the United States is not only necessary but also possible.  Because each country relies vitally on vulnerable computer networks, each has reason to fear retaliation.  Determining the source of a large cyber attack would be aided by circumstances?-such as an ongoing crisis?-and by the fact that very few actors, all of them states, are currently capable of large and sophisticated attacks.  Even without certainty of an attack?s origin, the prospective attacker would be gambling its economic health by betting against retaliation and escalation to general cyber war."
"Poor prospects for arms control, the futility of strategic defense, and the plunging costs of attack mean the United States and China must consider the idea of mitigating their growing vulnerabilities in the nuclear, space, and cyber domains by agreed restraint in the use of strategic offensive capabilities.  The bedrock of such restraint would be mutual deterrence in each domain, based on the fear of devastating retaliation and the limits of defense.  Preconditions for mutual deterrence?-namely, risks of retaliation that outweigh expected gains of attacking first?-exist in all three domains, although this may not be fully recognized by all parties in the United States and China."
"While deterrence may not apply against many cyber threats?-in particular those from nonstate actors?-it could be relevant between large and capable states.  Due to the limits and costs of network defense, strategic cyber deterrence between China and the United States is not only necessary but also possible.  Because each country relies vitally on vulnerable computer networks, each has reason to fear retaliation.  Determining the source of a large cyber attack would be aided by circumstances?-such as an ongoing crisis?-and by the fact that very few actors, all of them states, are currently capable of large and sophisticated attacks.  Even without certainty of an attack?s origin, the prospective attacker would be gambling its economic health by betting against retaliation and escalation to general cyber war."

@_date: 2014-12-09 20:08:25
@_author: Henry Baker 
@_subject: [Cryptography] North Korea and Sony 
More of Michael Hayden's fear-mongering about the electric grid.
Because the electrical utilities are quickly heading for extinction, they are wrapping themselves in the cyberthreat security blanket in order to thwart distributed solar energy generation and to gain subsidies from the federal Homeland Security teat.  Any such "cyberwashing" money would be far better spent to *accelerate* the inevitable rush to distributed generation to the point that the "critical infrastructure" grid simply isn't "critical" anymore.
Solar panels are the most important element in distributed electric power generation, with the consumer fleet of electric cars (aka "batteries on wheels") providing the resilient distributed storage: "the 40,000 Tesla vehicles already on the US roads contain about 3.3 gigawatts of storage capacity, roughly 0.3% of US electrical production capacity and 14% of US grid storage", according to a February, 2014, Morgan Stanley report.  This combination of cheap local generation and local storage has short-circuited the electrical utility business model and caused demand to melt away.
(BTW, Edison himself originally argued for *distributed* power generation, with a power station every few blocks--a la the telephone exchanges.  While this distributed model was forced by Edison's DC technology, a distributed power generation system would have been far more reliable & resilient than our current long-transmission-line system.)
The U.S. electrical utilities are dinosaurs being killed by kilowatts from outer space.  Rather than embracing these new solar technologies, however, they are fighting them tooth and claw with lobbying, from local zoning regulations to state monopoly commissions to federal regulations.
The latest salvo is a 180-page July 15th 2014 report called "Securing the U.S. Electrical Grid" (aka "Begging for Bailouts") with 12 recommendations to "secure" the electrical grid.  However, as far as I can tell, none of these recommendations will do anything to increase the reliability or resiliency of the electrical grid, but will do much to stymie the progress of solar distributed power generation.  The name of the report should have been "Securing the Profits of the U.S. Electrical Grid against Tesla/Musk and solar panels", as the basic *threat* the electrical utilities were attempting to defend against was *irrelevance* in a distributed solar generation world filled with Leaf's, LED's and LEED's.
The electrical utilities are scare-mongering the politicians and the public with lies like "while more resilient, such smart grid and microgrid systems present significant challenges to grid security."
Indeed, the very first paragraph of the SEG report is electrifying: "Following the end of World War II, the Allied Strategic Bombing Survey?-responsible for determining the damage inflicted by U.S. and Allied strategic bombing of German and Japanese industry?-determined that the bombing campaign would have been more effective if it had targeted the German and Japanese electrical grid rather than urban and industrial centers."
The report then goes on to warn that falling utility profits will not allow significant investments in additional security--including cybersecurity, and that "public-private partnerships" (aka "government bailouts") will be required.
SECURING THE U.S. ELECTRICAL GRID
July 15, 2014
Energy, politics, and more
Solar panels could destroy U.S. utilities, according to U.S. utilities
By David Roberts
Solar power and other distributed renewable energy technologies could lay waste to U.S. power utilities and burn the utility business model, which has remained virtually unchanged for a century, to the ground. That is not wild-eyed hippie talk.  It is the assessment of the utilities themselves.
Back in January, the Edison Electric Institute ? the (typically stodgy and backward-looking) trade group of U.S. investor-owned utilities ? released a report [PDF] that, as far as I can tell, went almost entirely without notice in the press.  That?s a shame.  It is one of the most prescient and brutally frank things I?ve ever read about the power sector.  It is a rare thing to hear an industry tell the tale of its own incipient obsolescence.
Why you could soon be buying your electricity from Elon Musk
Written by John McDuling at jmcduling
February 25, 2014

@_date: 2014-12-10 10:17:55
@_author: Henry Baker 
@_subject: [Cryptography] Sony-certified malware 
FYI -- Some thoughts come to mind: "kicking them when they're down", "shooting the wounded", "what goes around, comes around" ...
Of course, this certificate has been revoked, so there's no problem, right ?
Sony attackers also stole certificates to sign malware
New sample of ?Destover? malware has valid Sony Pictures certificate.
by Sean Gallagher - Dec 9, 2014 9:35 pm UTC
Since when was Sony-signed software ever _not_ malware ?   ;-)

@_date: 2014-12-10 10:49:07
@_author: Henry Baker 
@_subject: [Cryptography] North Korea and Sony 
Silicon Valley has long had a spooky history:
The Secret History of Silicon Valley
Part 1: The Vietnam War
Part 2: B-52?s and the Soviet Air Defense System
Part 3: Bill Perry/ESL and the Cold War
Part 4: Undisclosed Locations
Part 5: Silicon Valley, the 2nd 100 years
Part 6: Stanford, Terman and WWII
Part 7: Stanford, Terman and the Cold War
Part 8: Stanford and the rise of Cold War Entrepreneurship
Part 9: Stanford and Electronic Intelligence
Part 10: Stanford and Weapons Systems
Part 11: The Rise of Venture Capital
Part 12: The First Valley IPO?s
Part 13: Startups with Nuclear Missiles
Part 14: Spy Satellites in Silicon Valley
Part 15: Lockheed ? Silicon Valley largest employer
Part 16: Balloon Wars

@_date: 2014-12-10 18:42:31
@_author: Henry Baker 
@_subject: [Cryptography] North Korea and Sony 
Great reference to reflashing all the "smart" meters!  These
"smart" meters may be the biggest waste of money since Reagan
reactivated a battleship.  The electric utilities are dying,
and meters, smart or dumb, won't save them.  Spend the money
on micro- or nano-grids that fit into your own garage.
Re nation-state actors:
This has always been true; the US is terribly vulnerable to
hacking because it is the most "advanced" in the application
of computer networking.  However, due to many in the computer
security industry & recently catalyzed by Snowden, the US is
waking up and things will become more secure.  No thanks to
the NSA's weakening of our defenses, however (Didn't soldiers
used to get shot for falling asleep during guard duty?  How
is weakening commercial encryption any different from simply
opening the city gates to the enemy ?)
Perhaps the US should have thought twice more about loosening
the Stuxnet; the US had more to lose than anyone else from a
similar attack, and we showed everyone else how to do it!  I
learned as a kid that people who live in glass houses shouldn't
throw stones, and Stuxnet was a pretty big stone.
(Curiously, Obama used "glass houses" as an incorrect biblical
reference yesterday.)

@_date: 2014-12-11 06:15:53
@_author: Henry Baker 
@_subject: [Cryptography] North Korea and Sony 
The following article from comp.risks is the best suggestion to
improve the resilience of the US electrical grid I've ever heard
(emphasis mine):
Archives of The Risks Forum contain numerous indignant accounts of troubles
caused when the electric power went out unexpectedly.  Today, most of the
discussion depicts apocalyptic scenes to follow cyber attacks on the power
grid.  Listen to those stories and you may join the stampede to spend
hundreds of billions making it more secure.
Never mind that 100% reliability and 100% cyber security are unattainable.
Never mind that the goal of terrorism is to make us fearful and to induce us
to change our society and priorities.  Never mind that every year the public
does not experience a widespread blackout, that they unwittingly assume that
elevators, cell phones and such will never fail, thus increasing the
consequences of a real failure.
I am of the opinion that the power grid is already *** too reliable *** for
our own good, and that *** massive spending on grid security would actually
be counterproductive. *** I'll explain.
In parts of India, the power goes out as often as five times per day.  Local
businesses and the people have adapted to the point where a blackout is
hardly noticed.  Life and commerce continue uninterrupted.  Some have their
own backup power.  Some find other ways do adapt.  No terrorist could scare
those people by the threat of a blackout.
Firemen hold weekly drills.  Pilots and nuclear plant operators train
extensively to handle emergencies making.  Indeed, all professionals
expected to deal with unexpected emergencies sharpen and test their skills,
and their equipment via practice.  Even as children, we participated in
school fire drills.
Why not sharpen and train consumers and businesses in analogous ways via
staged blackouts?  The short answer is that the mere thought is anathema to
the culture of the electric utility business.  These people dedicate their
lives to keeping the lights on always to the best of their abilities.
We could design a series of staged blackout drills of varying scope and
duration all the way up to a nationwide surprise blackout.  Periodic
refresher drills could maintain readiness.
If power grid security ceased to become a source of fear and a threat to the
economy, then its appeal as a terrorism target would vanish.  We could spend
those hundreds of billions on something else.  We might also become more
flexible in living with a grid dominated by unpredictable solar and wind
sources. It is hard tor me to think of a way we would not be better off.
Is there really a good reason to not do as I suggest?
Dick Mills, Sailing Vessel Tarwathie

@_date: 2014-12-11 06:35:25
@_author: Henry Baker 
@_subject: [Cryptography] North Korea and Sony 
Quite so.
Big banks have a problem.  They sell a totally fungible commodity,
money, and there are many competitors.  Since they are price
"takers" (except when they're colluding -- e.g., interest-rate
price-fixing scandals galore), their only other option (pun
intended) is to reduce costs.  The easiest way to reduce costs
is through "tail stuffing", wherein ordinary risks are converted
into extra-ordinary risks by means of various derivatives -- e.g.,
options, futures, etc.  For 9999 days out of 10,000 (for example),
these strategies reduce volatility and increase profits, but on
the 10,000th day, the losses can greatly exceed those of the other
9999 days put together.  But by then, the people who put together
these strategies have long since collected their bonuses and moved
up into even more lucrative positions.
Of course, every few cycles of these strategies, the losses are
so large that the existence of the bank, or even the bank's country
(e.g., Iceland, Ireland, Switzerland) are threatened.  This, in a
nutshell, was the situation in 2008.
The best explanation for all of this is found in Nassim Nicholas
Taleb's various books, including "The Black Swan".  Taleb got his
start as a derivatives trader, so he knows exactly what goes on.

@_date: 2014-12-13 18:21:50
@_author: Henry Baker 
@_subject: [Cryptography] GHCQ Penetration of Belgacom 
It's hard to imagine the Regin malware being developed w/o Microsoft's knowledge and/or help -- if only to keep Microsoft's changes/updates from detecting and/or clobbering the thing by accident.
The damn Regin thing builds an entire encrypted virtual file system inside the NTFS metadata.
"The particular feature used (or abused) by Regin to hide its next stages is called NTFS Extended Attributes
(EA).  Originally, these were implemented in Windows NT for compatibility with OS/2 applications; however, they
made their way into later versions of Windows, namely 2000, XP and Vista.  The malware hides its modules in
NTFS EAs, splitting large files into several blocks of limited size.  These are dynamically joined, decrypted and
executed in memory."
"The most interesting code from the Regin platform is stored in encrypted file storages, known as Virtual File
Systems (VFSes)."
"Each VFS has a structure that is very similar to a real disk file system such as FAT.  The VFS files start with a header
that provides basic information required to operate the file system.  The header is followed by the bitmap of used/
free sectors and then by the file table."
THE REGIN PLATFORM NATION-STATE OWNAGE OF GSM NETWORKS
Kaspersky Lab Report
Version 1.0
24 November 2014

@_date: 2014-12-15 07:02:09
@_author: Henry Baker 
@_subject: [Cryptography] Sony "root" certificates exposed 
FYI --
Hackers promise ?Christmas present? Sony Pictures won?t like
GoP had details on every server and PC, as well as SPE?s ?root? certificate.
by Sean Gallagher - Dec 15, 2014 5:08 am UTC
Also among the spoils in one of last week?s file dumps was a Sony Corp. CA 2 ?root? certificate?-a digital certificate issued by Sony?s corporate certificate authority to Sony Pictures to be used in creating server certificates for Sony?s Information Systems Service (ISS) infrastructure.  This may have been used to create the Sony Pictures certificate that was used to sign a later version of the malware that took the company?s computers offline.  There were also certificates for a JP Morgan Chase electronic corporate banking application, SSL certificates for sites including the Sony Pictures Store e-commerce site, and other certificates associated with intranet servers and other infrastructure from multiple telecommunications providers.
At the top of Sony's corporate structure, the company has a history of bringing in military-grade executives in the role of Chief Information Security Officer.  In August, Sony Group CISO Phil Reitinger, the former Director of the National Cyber Security Center at the Department of Homeland Security, announced he would be stepping down.  His replacement was John Scimone, who had served as a senior security advisor for the Defense Department's Joint Task Force-Global Network Operations?-the network operations structure of US Cyber Command.  But at Sony Pictures, there were a number of archaic systems that had been in place for ages with plenty of potential attack points.

@_date: 2014-12-17 12:50:05
@_author: Henry Baker 
@_subject: [Cryptography] GHCQ Penetration of Belgacom 
FYI -- It won't matter very much after 2020.  This is a trade war that the NSA/GCHQ started ("the NSA doth protest too much about Huawei, methinks"); we buttered our bread, now we'll lie in it. (pun intended)
The US also just shot itself in the infrastructure ("U.S. Imposes Steep Tariffs on Importers of Chinese Solar Panels"), so we're going to slow down the march toward energy independence and grid resilience.
China Said to Plan Sweeping Shift From Foreign Technology to Own
By Bloomberg News  2014-12-17T16:00:00Z
The plan for changes in four segments of the economy is driven by national security concerns and marks an increasingly determined move away from foreign suppliers under President Xi Jinping, the people said.
China is aiming to *** purge most foreign technology *** from banks, the military, state-owned enterprises and key government agencies by 2020, stepping up efforts to shift to Chinese suppliers, according to people familiar with the effort.
The push comes after a test of domestic alternatives in the northeastern city of Siping that was deemed a success, said the people, who asked not to be named because the details aren?t public.  Workers there replaced Microsoft Corp.?s (MSFT) Windows with a homegrown operating system called NeoKylin and swapped foreign servers for ones made by China?s Inspur Group Ltd., they said.
The plan for changes in four segments of the economy is driven by national security concerns and marks an increasingly determined move away from foreign suppliers under President Xi Jinping, the people said.  The campaign could have lasting consequences for U.S. companies including Cisco Systems Inc. (CSCO), International Business Machines Corp., Intel Corp. (INTC) and Hewlett-Packard Co.
?The shift is real,? said Charlie Dai, a Beijing-based analyst for Forrester Research Inc.  ?We have seen emerging cases of replacing foreign products at all layers from application, middleware down to the infrastructure software and hardware.?
Security Panel
China is moving to bolster its technology sector after Edward Snowden revealed widespread spying by the U.S. National Security Agency and accused the intelligence service of hacking into the computers of Tsinghua University, one of the China?s top research centers.  In February, Xi called for faster development of the industry at the first meeting of his Internet security panel.
Foreign suppliers may be able to avoid replacement if they share their core technology or give China?s security inspectors access to their products, the people said.  The technology may then be seen as safe and controllable, they said.
China ranks second behind the U.S. in technology spending, with outlays rising 8.1 percent to $182 billion last year, according to research firm IDC.  The U.S. spent $656 billion, a 4.2 percent increase over 2012.
The push to develop local suppliers comes as Chinese regulators have pursued anti-trust probes against western companies, including Microsoft and Qualcomm Inc.(QCOM)  Recent months have seen Microsoft?s China offices raided, Windows 8 banned from government computers and Apple Inc. (AAPL) iPads excluded from procurement lists.
Trade War
?I see a trade war happening.  This could get ugly fast, and it has,? said Ray Mota, chief executive officer of Gilbert, Arizona-based ACG Research, who expects the issue to result in direct talks between the U.S. and China.  ?It?s not going to be a technology discussion.  It?s going to be a political discussion.?
In September, the China Banking Regulatory Commission ordered banks and finance agencies to ensure that at least 75 percent of their computer systems used safe technology by 2019. The regulator called on financial institutions to dedicate at least 5 percent of their IT budgets towards the goal.
While the CBRC policy doesn?t make a distinction between foreign and domestic products, it says banks must favor companies who share their ?core knowledge and key technology.?  It also cautions banks from relying too heavily on one supplier.
Chinese firms, like Huawei Technologies Co. and ZTE Corp., have already begun to gain local market share at foreign rivals? expense.
Military Order
About 80 percent of banks? core servers and systems are made by foreign brands, Yan Qingmin, a CBRC vice chairman, said Nov. 27 at a conference in Beijing sponsored by the news magazine Caijing.
?Most of China?s financial IT systems are from foreign countries,? Yan said.  ?From the perspective of national security, it poses potential threats to us.?
The CBRC may start accounting for banks? use of Chinese technology in its regulatory reviews, the Shanghai Securities News reported Dec. 4.
Xi?s Central Military Commission issued a similar, although less detailed, order in October, according to a report in the party-run People?s Liberation Army Daily.  That document described information security as key to winning battles.
Intel, Microsoft, HP, Cisco and Qualcomm declined to comment.  IBM said it isn?t aware of any Chinese government policy against using its servers in the banking industry.
Industrial & Commercial Bank of China, the country?s biggest bank, deployed a new IBM mainframe in August, the two companies said.
Jilin Trials
Chinese companies have faced similar pressure overseas.  A 2012 U.S. Congressional report said Huawei and ZTE, the country?s largest phone-equipment makers, provide opportunities for Chinese spies to tamper with U.S. communications networks. Huawei has since been shut out from several U.S. deals.
In May, the U.S. Department of Justice accused five men in the People?s Liberation Army of allegedly hacking into the computer systems of U.S. companies to steal information.  The Chinese government called the charges ?absurd.?
The orders from Chinese banking and military commissions coincided with the trial of domestic computer systems in Siping, a city of 3.4 million people in Jilin province.  Other cities and agencies in Jilin will now begin testing whether NeoKylin, a Linux-based operating system from China Standard Software Co., can substitute for Windows and servers made by Inspur can replace IBM?s, the two people familiar with the plan said. The trial will then expand across the country, they said.
Domestic Software
Similar efforts were confirmed by one provincial-level worker and two local government workers in Jilin?s capital of Changchun, who asked not to be named while discussing internal matters.  The two local government workers said some specialized software was swapped for domestic versions, including a tax program designed by the Harbin Institute of Technology.
China faces obstacles in replacing foreign software and hardware on a national scale.  Almost three decades after paramount leader Deng Xiaoping approved his State Hi-Tech Development Plan, Chinese companies hold a fraction of global market share.  They?re still unable to match the most advanced products, such as high-end bank servers.
?A key government motivation is to bring China up from low-end manufacturing to the high end,? said Kitty Fok, China managing director for IDC.
National security provides China a powerful rallying cry, particularly within its sprawling state sector.  China National Petroleum Corp., the country?s largest energy producer, announced Nov. 26 -- during China?s first Cybersecurity Week -- that it had replaced its Microsoft e-mail with the homegrown eYou program to improve security.
?The technology gap is closing,? said Mota, who advises Cisco and HP, as well as Huawei and ZTE.  ?In China, they have the patience to figure it out.?
For Related News and Information: China?s Antitrust Probes Mostly Target Local Firms, Premier Says China Said to Leave Apple Products Off Purchasing List Apple, Microsoft Targets of Chinese Media Amid U.S. Spat
To contact Bloomberg News staff for this story: Steven Yang in Beijing at kyang74 at bloomberg.net; Keith Zhai in Beijing at qzhai4 at bloomberg.net; Tim Culpan in Taipei at tculpan1 at bloomberg.net
To contact the editors responsible for this story: Nicholas Wadhams at nwadhams at bloomberg.net; Michael Tighe at mtighe4 at bloomberg.net

@_date: 2014-12-18 10:47:13
@_author: Henry Baker 
@_subject: [Cryptography] MPAA hasn't given up yet on breaking DNS 
FYI -- Apparently from the Sony leaks...
"At the same time, even this narrow limitation on ISPs? immunity could have the salutary effect of requiring ISPs to respond to takedown notices by *** disabling DNS lookups *** of pirate sites through the ISPs? own DNS servers, which is not currently a general practice."

@_date: 2014-12-18 13:49:15
@_author: Henry Baker 
@_subject: [Cryptography] GHCQ Penetration of Belgacom 
The NSA pissed in our soup, and we drank it.  (Actually, we're still drinking it.  Apologies to Alan Bennett)
There's currently no way to enforce this, or even know what is happening, because attribution is so difficult.
The NKorea hypothesis re Sony is going to require one heck of a lot more evidence before anyone should believe it.
Sony currently reeks of "false flag".

@_date: 2014-12-20 09:31:22
@_author: hbaker1 
@_subject: [Cryptography] GHCQ Penetration of Belgacom 
So Intel&Apple have provided PRC with netlists for their processor
Of course, PRC shouldn't believe them, unless they could also
manufacture their own chips from the netlists.

@_date: 2014-12-20 21:42:31
@_author: Henry Baker 
@_subject: [Cryptography] GHCQ Penetration of Belgacom 
Posted 6 Dec 2007 | 12:36 GMT
"Trust, but verify.  ...  A year shy of its 50th birthday, the Defense Advanced Research Projects Agency has launched the *** Trust in Integrated Circuits *** program, the goal of which is a microchip verification process.  It's basically a Pentagon Good Housekeeping Seal of Approval.  A chip bearing the Trusted imprimatur will be *** guaranteed free of malicious content. ***"
I've been sleeping better ever since.

@_date: 2014-12-21 07:21:51
@_author: Henry Baker 
@_subject: [Cryptography] GHCQ Penetration of Belgacom 
I hope that the sarcasm drippage was evident.
The malware problem usually (always??) involves a discrepancy between the model and the reality.  This is one reason why "proofs" of non-maliciousness are never going to be enough, because these proofs live within a mathematical model, and almost any discrepancy with reality might be elevated into an attack.  E.g., model assumes proper voltage; improper voltage can create havoc; model assumes proper clocking; improper clocking can create havoc; model assumes normal temperatures; abnormal temperatures allow pwnage; model assumes normal entry to subroutines; ROP is based upon abnormal entry, etc.
In viruses & bacteria, evolution has already explored a lot of the discrepancies -- DNA that can be read two (or more) different ways, depending upon the initial offset (0, 1, 2 mod 3); DNA that is read backwards; RNA that codes for something and is also active in its own right; DNA that "borrows" sequences from an old attacking virus to produce good stuff, etc.  But several billion years allows for a lot of hacking & defense attempts.
Governments keep worrying about a viral or bacterial pandemic like the 1918 flu that kills a material fraction of the people in the world.  Given the limited diversity in digital HW & SW systems, a pandemic that *** destroys a material fraction of the computers in the world *** is a heck of a lot more likely.  Such a pandemic will almost certainly result from a nation-state screwup with a Stuxnet-like weapon whose code turns out to be "too good", and a minor modification turns a "highly directed" attack into a global pandemic.
The 1918 flu killed 3-5% of the world's population; a digital pandemic could kill 50% of the world's smartphones or PC's.  (Google "firing squad synchronization problem".)
There are nowhere near enough ethicists with top-secret clearances to properly vet some of the craziness being deployed and contemplated.
Think about the havoc that would result from a Stuxnet-quality worm that took at _all_ of the existing iOS devices.  (Taking out all of the Android devices is a lot more difficult due to the large number of different versions.)

@_date: 2014-12-23 09:40:38
@_author: Henry Baker 
@_subject: [Cryptography] GHCQ Penetration of Belgacom 
"People" have been adding extra little "antennas" on circuit boards (as part of their "fabrication") for decades.  These little antennas don't affect normal operation, but make surveilling a device much, much easier.  Have fun finding these little buggers!
A friend of mine went to a trade show in a foreign country and his demo devices were "delayed".  When he examined the devices carefully, he discovered that all of the screws had been not so carefully unscrewed & screwed back in.
So, yes, "this stuff is going on all the time all around us".

@_date: 2014-12-24 11:48:21
@_author: Henry Baker 
@_subject: [Cryptography] floating point 
"Either IEEE = is not an identity predicate or *** IEEE atan is not a function, ***
because 0.0=-0.0, but atan(0.0,-0.0)!=atan(-0.0,-0.0); due to this and other reasons,
IEEE -0.0 is an *** algebraic abomination. ***"  [Not a function because x=y, but
f(x) != f(y); a.k.a. not "referentially transparent".]
IEEE floating point representation of x is basically a braindamaged approximation
to asinh(x) [including the "gradual underflow" part!], e.g., braindamaged because
in floating point, the exponent & the mantissa are in different number bases. The astronomers get this one right (Google astronomy + asinh); the audio engineers
(mu-law&A-law) screwed this one up.

@_date: 2014-12-24 12:18:16
@_author: Henry Baker 
@_subject: [Cryptography] GHCQ Penetration of Belgacom 
The 1620 model II got rid of the addition table, and exchanged the older model IBM electric typewriter for the newer IBM Selectric (on both machines the console typewriter was the most unreliable part of the whole machine).
I think that there were "stripped down" versions of the 1401 that couldn't multiply/divide.  The first 1401 I worked on had only 4,000 characters of memory; newer models went up to 16,000 characters using a bizarre 3-character addressing scheme.
The 1401 was often used as a "front end" for bigger scientific machines such as the 7040 or 7090.  I was tired of waiting for all the card punching for the "intermediate" file of the 1401 assembler, so I used the 7040's main core memory as /tmp for the 1401.  This also saved a lot of trees in the form of discarded cards.
The 1401 printer (called the 1410, I recall) used a spinning chain with 5(?) sets of characters in a particular sequence; these characters were imprinted using electromechanical hammers fired at the precise time that the chain character appeared in the position that that character was supposed to appear on the paper.
The sequence of characters on the chain was chosen to minimize the number of hammers that were likely to fire at exactly the same time for words in the English language.  Needless to say, a visual examination of the chain sequence would tell you how to "print" a line that would fire all 132 of the hammers simultaneously, usually breaking the chain in a spectacular manner.

@_date: 2014-12-24 17:55:34
@_author: Henry Baker 
@_subject: [Cryptography] floating point 
I'm sorry to disappoint you re Modula-3, but I believe that the Lisp/Scheme reader/printer was the first to satisfy the axiom:
EQUAL(x,READ-FROM-STRING(PRINT-TO-STRING(x))) is true
Actually, in the case of floating point numbers, they aren't just EQUAL, but bit-for-bit identical (variously called EQ or EQL, depending upon whether floating point numbers are "immediate" or not).
The authors of the papers included Guy Steele, Jon White and Will Clinger.
Proceedings  of the ACM SIGPLAN?SO  Conference  on
Programming  Language  Design and Implementation.
White  Plains, New York, June  20-22,  1990.

@_date: 2014-12-25 14:35:45
@_author: Henry Baker 
@_subject: [Cryptography] floating point 
I forgot to mention that I had a recent legitimate need to utilize bit-for-bit comparison of floating point numbers.
The 3D printing ".stl" format utilizes triples of IEEE 32-bit format floating point numbers to represent vertices in the face triangles of a surface in 3D.  But in order to see whether a given .stl file represents a legitimate 3D-printable object, one needs to perform certain topological tests on these vertices, edges and triangles.  In particular, one needs to be able to recognize when "the same" vertex occurs again in the .stl file, and this can be determined by bit-for-bit matching of all three coordinates of the vertices.  Once vertices can be recognized, then so can directed edges and directed triangles.
Finally, the Euler characteristic of the object can be computed, and the object can be tested to see if it is "water tight" -- it actually represents a 3D-printable object.
None of these operations should be done using floating point, because any round-off error whatsoever will destroy the accuracy of the result.  In fact, most popular 3D printing packages cannot check these topological properties with certainty -- that computation might require quadruple-, quintuple- or even more precision to compute the correct result.

@_date: 2014-12-27 09:18:19
@_author: Henry Baker 
@_subject: [Cryptography] floating point 
IEEE floats in GPU's are getting closer & closer to the IEEE standard, simply because the GPU customers are more & more people like physicists rather than gamers.  I believe that contemporary GPU IEEE floats follow everything but the gradual underflow part of the IEEE standard and perhaps some of the exception handling.
The biggest problem with the IEEE standard is its complete ignorance of compilers, optimizers and (in general) program analysis tools.  I'm not aware of any program analysis tool that can "think" like a topologist; all the ones that I know of "think" like an algebraist.  In order for a data type & data operations to be compatible with program analysis tools -- e.g., compilers, optimizers, etc. -- such a data type has to have _algebraic_ properties, like commutivity, associativity, etc.  Knuth attempted to axiomatize these algebraic properties, but subsequent work hasn't gone much beyond Knuth's work.
Properly optimizing floating point arithmetic in a compiler requires the ability to "dispatch" on certain bit configurations of the floating point numbers, and this unfortunately requires moving the floats into fixed point registers in order to check these configurations.  Given the distinct datapaths for fixed & float values, this is _extremely expensive_, so you are forced to make a choice between speed and correctness.  It should be possible to perform these bit dispatches & fixups even in deep pipelines, but I'm not aware of any floating point HW that allows this.
The good news about IEEE floats: they are _standard_, so every computer now makes the same mistakes.
The bad news about IEEE floats: they are standard, so there is no pressure to improve their properties, so every computer now makes (the same) mistakes.
I recall a discussion about benchmarking a program, and the new program was faster, but the results were slightly different.  These differences were not acceptable, even though they were within the same error bounds as the original program.
Customers don't mind mistakes, so long as they are the _same mistakes_ that everyone else makes.
(Hmmm....  This sounds very much like the behavior of the banks in the recent financial crisis; so long as everyone else made exactly the same errors ("Value-At-Risk", etc.), nobody cared.)

@_date: 2014-12-27 10:26:21
@_author: Henry Baker 
@_subject: [Cryptography] floating point 
"Common Lisp" requires true bignum arithmetic, otherwise
it isn't "Common Lisp".  I'm not quite sure which
common lisp you're referring to, but you might be
referring to "immediate" numbers (often called "fixnums"),
which don't require consing.  On some implementations,
declaring something as a "fixnum" together with
optimizing for speed and lack of "safety" will result
in code which can _only_ handle immediate fixnums, and
will produce undefined results -- including crashing --
if non-fixnums are provided.

@_date: 2014-12-27 11:06:18
@_author: Henry Baker 
@_subject: [Cryptography] floating point 
Ada compilers are required to utilize "infinite precision arithmetic" when evaluating constant expressions -- those which the compiler can evaluate by itself at compile time.  This feature is really nice when trying to come up with a human-readable versions of some numeric constants.
(Of course, Common Lisp allows the " notation to compute compile-time constants and the " notation to compute load-time constants; Common Lisp already enables bignums & rational numbers for "exact" arithmetic.)
I think that the original IBM IBSYS assemblers used to do the same thing for "assemble time" arithmetic expressions; I think that these were also evaluated in multiple precision arithmetic.  IBM needed this capability to make sure that the "constants" that were computed for library routines would be correct.

@_date: 2014-12-28 07:52:40
@_author: Henry Baker 
@_subject: [Cryptography] floating point 
Yes, there have been electronic calculators built (Wang??)
that utilized pure log numbers (slide rules, anyone?).
If you want better behavior near zero -- aka denormalized
floats -- then you really want ASINH(x/2) rather than LOG(x).
ASINH(x/2) is linear around zero, but like LOG(x) once you
get far enough from zero.

@_date: 2014-12-31 05:53:00
@_author: Henry Baker 
@_subject: [Cryptography] on-chip crypto accelerators (was: floating point) 
The BCD accelerator looks a lot more interesting&fun:
"The DFU efficiently supports binary-coded decimal (BCD) math"

@_date: 2014-12-31 09:54:06
@_author: Henry Baker 
@_subject: [Cryptography] Snowden docs show none are originals of  spies 
Given the number of PDF exploits, perhaps this is a good thing?  Or is it only the TOR/MITM-ed versions that have the PDF exploits in them?

@_date: 2014-11-04 11:48:30
@_author: Henry Baker 
@_subject: [Cryptography] Paranoia for a Monday Morning 
I agree with you 100%.  Now what?
BTW, have you ever noticed how many exploits utilize various
"management" backdoors that were put there for IT professionals
to be able to "manage" the devices of the (unwashed) "users",
including the CEO's own devices ?
(At MIT, we used to call "users" by their proper name: "lusers",
which is what many IT professionals think they are when the
"users" can't hear them talking.)
Invariably, the thought that goes into the security of these
backdoors is orders of magnitude less than the thought that
goes into the front doors; ditto for the amount of testing
of these backdoors.
And yet the outcry continues for even more backdoors, but
this time with "golden keys" !

@_date: 2014-11-04 18:28:01
@_author: Henry Baker 
@_subject: [Cryptography] Wind River Security Features and Cryptography 
Perhaps Wind River's crime was advertising the details of their security systems ?
Linux, Windows, OSX, iOS, etc., have extensive security capabilities, but they aren't as well advertised.

@_date: 2014-11-05 06:26:41
@_author: Henry Baker 
@_subject: [Cryptography] "How I created two images with the same MD5 hash" 
FYI -- MD5 hopelessly broken:
"How I created two images with the same MD5 hash"
I posted the following images the other day which although looking totally different have exactly the same MD5 hash (e06723d4961a0a3f950e7786f3766338) .

@_date: 2014-11-07 12:20:56
@_author: Henry Baker 
@_subject: [Cryptography] Third amendment crypto defenses 
FYI -- Here are some references & articles:
The Third Amendment: Forgotten but Not Gone
Tom W. Bell
Tom W. Bell,The Third Amendment: Forgotten but Not Gone, 2 Wm. & Mary Bill Rts. J. 117 (1993),
"Pity the Third Amendment.  The other amendments of the United States
Constitution's Bill of Rights inspire public adoration and volumes of
legal research.  Meanwhile, the Third Amendment languishes in
comparative oblivion.  The scant attention that it does receive
usually fails to serve it well.  Lawyers twist it to fit absurd
claims, the popular press subjects it to ridicule, and academics
relegate it to footnotes.  Is this any way to treat a member of the
Bill of Rights?"
NSA Violating 3rd Amendment with Snooping Tactics
Posted by Tyler S. Storey / January 3, 2014     At Uncle Sam?s, we?ve extensively covered the federal government?s attack on our Constitution and Bill of Rights.  They have taken shots at nearly every one of our rights in the last ten years, but there are still a few rights that we assume are safe for now.  The Third Amendment, for example is one that we don?t think much about in modern America.
    No Soldier shall, in time of peace be quartered in any house, without the consent of the Owner, nor in time of war, but in a manner to be prescribed by law.
All of the other amendments have been reexamined and interpreted for the 21st century world, taking into account advents such as the internet and much improved fire arms.  On the other hand the Third Amendment seems frozen in time, untouched by modernity.  But a new idea may change the perception of the Third Amendment.
A New Idea About The Third Amendment
Jacob Appelbaum, a top security expert, says that the NSA might very well be violating the Third Amendment ? digitally.
Appelbaum was behind an expose in Spiegel, this week, on the NSA?s systemic offensive programs to commandeer computers and computer systems, phone connections and phone systems, and communications networks of all types.
Jacob Appelbaum shows how the NSA has already taken over our computers and phones by physically intercepting laptop shipments and installing bugware.  They then ship the laptop on to the consumer themselves after first installing special hardware that can overcome any privacy attempt, including ?air gaps? (i.e. keeping a computer unplugged from the Internet).  Appelbaum also notes that spyware can suck up a lot of system resources on a computer or smartphone.
Appelbaum goes as far as saying this practice is the digital equivalent of soldiers being stationed in our homes without our permission and against our will.
The Comparison
The National Security Agency says that they are in the midst of a cyberwar.  That in itself is unlike anything considered during previous centuries.  In any war there are soldiers that do the fighting.  So, it stands to reason that in cyber warfare the spying devices, physical devices, and internet spyware, are the soldiers, so to speak.  These are the NSA?s cyber soldiers in their global cyber war.
In Colonial America, quartering meant that Americans had:
    To house British soldiers, who could come and go as they pleased
    To give freely their resources to British armies
    No right to expect privacy in their own homes
Today, NSA spying means that modern Americans have:
    No say in when the military presence comes or goes from our computers
    No say in the resources the NSA?s spying uses up.  (They can use a lot of the resources and space on your devices)
    No reasonable expectation of privacy, even in the most private moments in the most private places
The people who were forced to tolerate British rule in Colonial America had their homes invaded by soldiers, and lost any and all semblance of privacy.  Today our cyber homes, where we keep our most important personal information, have been invaded and our privacy has been completely lost.  Our forefathers? homes were no longer theirs and our computers and phones are no longer ours.  That is what the Third Amendment was created to protect and that is what the NSA is violating.

@_date: 2014-11-07 20:41:08
@_author: Henry Baker 
@_subject: [Cryptography] $750k Fine for exporting crypto 
Thanks, Dan, for the terrific analysis.
As most everyone already knows, politicians pass laws, not
because they are useful or will improve society, but because
they make voters & donors feel good so the pols will get
re-elected.  "I was tough on crime, because I got my name
on a law to go after Wall Street criminals."  OK, so where
are the "perp walks" for said Wall Street criminals?  "Welllll,
we needed Wall Street $$$$ to keep those other b*****ds out
of office, so we didn't want to rock the boat with prosecutions."
Since everyone -- including the Atty Gen -- knows this, the
Prez & AG are free to use this vastly bloated set of laws
to prosecute pretty much anyone they please, and claim
"prosecutorial discretion" for the laws that they don't
want to prosecute for whatever reason.
Unfortunately, the Prez (no matter which party) also uses this
"discretion" to ignore his/her duty to uphold the Constitution,
particularly those parts that constrain his/her actions.
Voters should always keep in mind that the same laws that they
felt so good about when "their" guy/gal was in office, will
also be available when the other party's guy/gal gets into that
same office.  In particular, how would the electorate feel
about giving the current NSA/FBI/DHS powers to Richard Nixon &
his cronies?

@_date: 2014-11-10 14:50:18
@_author: Henry Baker 
@_subject: [Cryptography] "DarkHotel" APT routinely breaking RSA512 
"The Darkhotel crew?s skillset allows it to launch interesting cryptographical attacks, for instance factoring 512 bit RSA keys"
The keys are used to create bogus certificates, e.g.,
Digisign Server iD
flexicorp.jaring.my sha1/
RSA (512 bits)
Expired 12/17/2008 12/17/2010
CA 1
Equifax Secure
eBusiness CA 1
secure.hotelreykjavik.i s
md5/RSA (512 bits)
invalid Sig 2/27/2005 3/30/2007

@_date: 2014-11-19 13:35:01
@_author: Henry Baker 
@_subject: [Cryptography] Where should I start with cryptography? 
Yes, Dan's course is excellent (I think all the portions are also available
on Youtube), but Dan's course seems to be aimed at those who wish to become
crypto researchers, as he spends a lot of time on the concepts needed to do
proofs of indistinguishability.
I've often found it easier to study crypto using the original papers from
the '70's and '80's, before the math got so formal and obscured the
Start with Wikipedia & follow the main references.  The good news is
that virtually all of the papers are available on the Internet if you're
willing to do a bit of searching.  Also, sometimes Wikipedia explains
things better than the original papers did !

@_date: 2014-11-19 18:23:06
@_author: Henry Baker 
@_subject: [Cryptography] FW: IAB Statement on Internet  Confidentiality 
Perhaps "cryptography at metzdowd.com" could get people comfortable
with cryptography by encrypting all of its messages using PGP or
equivalent ?
At the very least we could authenticate the contents of the
messages in this email list.
Also, the email could include a hash of the previous one, so
that no one could delete or insert a message without everyone
Publish a public key for submissions; use this one or another
key for authentication.

@_date: 2014-11-20 10:45:06
@_author: Henry Baker 
@_subject: [Cryptography] FW: IAB Statement on Internet   Confidentiality 
Re multiple recipients:
That's why I suggested _authentication_ for a first pass.
Authentication only requires that only the sender/moderator
have a public/private keypair, which each recipient can
validate, while also validating the "previous message
There are proposals to incorporate public keys together
with email addresses in a more-or-less backwards compatible
manner, so that a mail server could take the (public key,
email address, already-signed-message) and send
encrypt(already-signed-message, public key) to email address.
Yes, I know, this order is backwards; it is far better
to encrypt-then-sign, but that would put a lot more
work back on the sender/moderator's computer.
It would also be possible to sign-encrypt-sign, so long
as you also trusted the signing mailer to not tamper
with the previously encrypted ciphertext of the message.

@_date: 2014-11-20 16:46:26
@_author: Henry Baker 
@_subject: [Cryptography] Walmart fooled by non-authenticated web pages 
FYI --
Looks like Walmart is going to have to check authentication on _printed-out web pages_, as well...
Any thoughts about how to do this?  (I have no relationship w/ Walmart!)
Wal-Mart Scammed into Selling PlayStation 4 for $90
Customers have misused Wal-Mart's price match promotion to obtain $400 PlayStation 4 consoles for less than a quarter of the retail price using third-party sellers on Amazon.  The company announced on Nov. 13 that it would price-match select online retailers, including Amazon.com.  However, any Amazon member with a registered selling account can *** create authentic looking pages *** and list items "for sale" online.  Consumers need only take a *** screen capture of the page *** and show it to a cashier at checkout in order to request the price match.  Wal-Mart's online price match policy states, "We're committed to providing low prices every day, on everything.  So if you find a current lower online price from an online retailer on an identical, in-stock product, tell us and we'll match it."  Few employees appear to have verified the legitimacy of these online deals as many customers were able to purchase gaming systems for $90.  The scam seems to have been initiated after Sears accidentally listed several Nintendo consoles on its site for $60, according to Consumerist, a consumer advocacy site.  Members of Twitter and Reddit communities have posted pictures of receipts documenting that Wal-Mart had accepted these fake Amazon listings.

@_date: 2014-11-20 17:09:58
@_author: Henry Baker 
@_subject: [Cryptography] FW: IAB Statement on Internet   Confidentiality 
Even "public records" need to be preserved from tampering; something that cryptography can do rather well.
Using cryptography for this purpose would be the lesson for this teachable moment.

@_date: 2014-11-21 07:09:16
@_author: Henry Baker 
@_subject: [Cryptography] FW: IAB Statement on Internet   Confidentiality 
"Grant me chastity and continence, but not yet" -- St Augustine

@_date: 2014-11-25 08:29:13
@_author: Henry Baker 
@_subject: [Cryptography] Belgian cryptography professor hacked 
FYI --
ENGLISH SUMMARY ? Belgian professor in cryptography hacked
01/02/2014 om 08:00 door Mark Eeckhaut and Nikolas Vanhecke
This is an English summary of an article published in today's edition of Belgian newspaper De Standaard.  The article concerns the hacking of the computer of professor Jean-Jacques Quisquater, a renowned expert in cryptography.  Suspicions arose that the hacking of Professor Quisquater was done by the U.S. National Security Agency or the British GCHQ.  The case is under investigation by Belgian authorities.
A new Belgian episode in the NSA scandal: Belgian professor Jean-Jacques Quisquater, internationally renowned expert in data security was the victim of hacking.  And, as was the case in the Belgacom hacking affair, there are indications the American secret service NSA and its British counterpart, the GCHQ might be involved.
There isn't a card with an electronic chip available, or it has some sort of security technology that UCL professor Jean-Jacques Quisquater (67) was involved in developing.  If you are able to withdraw money from a cashpoint safely, for example, that is to some extent due to Quisquater's work on complicated mathematical algorithms.  He was also involved in the development of the Proton payment system in Belgium.  That very same Jean-Jacques Quisquater has now been the victim of a hacking attack, that has all the signs ? as was the case in the Belgacom affair - of 'state-sponsored espionage', De Standaard has discovered.
The authorities investigating the Belgacom hacking case confirm they have opened a case.  Quisquater himself has lodged a formal complaint.
Earlier this week, whistle blower Edward Snowden gave an interview to German television channel ARD in which he claimed the NSA's espionage activities are not only aimed at protecting US national security ? in the so-called 'war on terror' ? but also at companies and private individuals.  The Quisquater case seems to indicate the Belgian justice department might be able to demonstrate Snowden's claims are more than a mere figment of his imagination.  As far as we are able to tell, this is the first instance in which a private person is seen as a victim in the NSA case.
According to our sources, the Quisquater hacking was discovered during an investigation into the Belgacom hacking case.  Also according to our sources, that malware or techniques similar to those used in the Belgacom hacking were used to hack into Quisquater's computer.
It is not a big surprise the Belgian mathematician might have been targeted by the NSA: Jean-Jacques Quisquater is a a well-respected professor in cryptography at the Universit? Catholique de Louvain (UCL) in Louvain-la-Neuve.  He has no involvement in the 'war on terror' the US are waging, but there are many other reasons he is an interesting target.  Quisquater is world-wide renowned because of his work in cryptography.  Cryptographers enable systems, thanks to complicated sets of algorithms, to exchanges data in a secure way over, for example, the internet.
Quisquater has earned his reputation: he has 17 patents in his name, he headed the 'Crypto group' at the UCL and was awarded the RSA Conference Award for Excellence in the Field of Mathematics.
His computer was infected after clicking a (bogus) LinkedIn invitation of a non-existent employee of the European patent office.  That allowed the intruders to follow all of the professor's digital movements, including his work for international conferences on security.  Quisquater also had contact with NXP, a company based in Leuven and specialized in electronic equipment where security is an important issue, such as mobile phones.
Interesting fact: German chancellor Angela Merkel, also hacked by the NSA, has three mobile phones.  Only one of them is protected.  According to our sources the protected  mobile was protected by NXP technology and was not hacked by the NSA.
Needless to say, a secret service that can monitor Quisquater's computer, has a unique access point to the tightly-knit world of cryptography, that is crucial for the protection of any form of digital communication.

@_date: 2014-11-25 13:33:34
@_author: Henry Baker 
@_subject: [Cryptography] Belgian cryptography professor hacked 
FYI -- "security researchers have found the massive digital spy tool used in all three attacks"
Researchers Uncover Government Spy Tool Used to Hack Telecoms and Belgian Cryptographer
By Kim Zetter 11.24.14 8:59 am
It was the spring of 2011 when the European Commission discovered it had been hacked. The intrusion into the EU?s legislative body was sophisticated and widespread and used a zero-day exploit to get in. Once the attackers established a stronghold on the network, they were in for the long haul. They scouted the network architecture for additional victims and covered their tracks well. Eventually, they infected numerous systems belonging to the European Commission and the European Council before being discovered.
Two years later another big target was hacked. This time it was Belgacom, the partly state-owned Belgian telecom. In this case, too, the attack was sophisticated and complex. According to published news reports and documents leaked by Edward Snowden, the attackers targeted system administrators working for Belgacom and used their credentials to gain access to routers controlling the telecom?s cellular network. Belgacom publicly acknowledged the hack, but has never provided details about the breach.
Then five months after that announcement, news of another high-profile breach emerged?this one another sophisticated hack targeting prominent Belgian cryptographer Jean-Jacques Quisquater.
Now it appears that security researchers have found the massive digital spy tool used in all three attacks. Dubbed ?Regin? by Microsoft, more than a hundred victims have been found to date, but there are likely many others still unknown. That?s because the espionage tool?a malicious platform capable of taking over entire networks and infrastructures?has been around since at least 2008, possibly even earlier, and is built to remain stealth on a system for years.
The threat has been known since at least 2011, around the time the EU was hacked and some of the attack files made their way to Microsoft, who added detection for the component to its security software. Researchers with Kaspersky Lab only began tracking the threat in 2012, collecting bits and pieces of the massive threat. Symantec began investigating it in 2013 after some of its customers were infected. Putting together information from each, it?s clear the platform is highly complex and modulated and can be customized with a wide range of capabilities depending on the target and the attackers? needs. Researchers have found 50 payloads so far for stealing files and other data, but have evidence that still more exist.
?It?s a threat that everyone has detected for some time, but no one has exposed [until now],? says Eric Chien, technical director of Symantec?s Security Technology and Response division.
The Most Sophisticated Spy Tool Yet
The researchers have no doubt that Regin is a nation-state tool and are calling it the most sophisticated espionage machine uncovered to date?more complex even than the massive Flame platform, uncovered by Kaspersky and Symantec in 2012 and crafted by the same team who created Stuxnet.
?In the world of malware threats, only a few rare examples can truly be considered groundbreaking and almost peerless,? writes Symantec in its report about Regin.
Though no one is willing to speculate on the record about Regin?s source, news reports about the Belgacom and Quisquater hacks pointed a finger at GCHQ and the NSA. Kaspersky confirms that Quisqater was infected with Regin, and other researchers familiar with the Belgacom attack have told WIRED that the description of Regin fits the malware that targeted the telecom, though the malicious files used in that attack were given a different name, based on something investigators found inside the platform?s main file.
Victims are located in multiple countries. Kaspersky has found them in Algeria, Afghanistan, Belgium, Brazil, Fiji, Germany, Iran, India, Malaysia, Syria, Pakistan, Russia and the small Pacific island nation of Kiribati. The majority of victims Symantec has tracked are located in Russia and Saudi Arabia.
Targets include entire networks, not just individuals, among them telecoms in multiple countries, as well as government agencies, research institutes and academics (particularly those doing advanced mathematics and cryptography, like Quisquater). Symantec has also found hotels infected. These are likely targeted for their reservation systems, which can provide valuable intelligence about visiting guests.
But perhaps the most significant aspect of Regin is its ability to target GSM base stations of cellular networks. The malicious arsenal includes a payload that Kaspersky says was used in 2008 to steal the usernames and passwords of system administrators of a telecom somewhere in the Middle East. Armed with these credentials, the attackers would have been able to access GSM base station controllers?the part of a cellular network that controls transceiver stations?to manipulate the systems or even install malicious code to monitor cellular traffic. They could also conceivably have shut down the cellular network?for example, during an invasion of the country or other unrest.
Kaspersky won?t identify the telecom or country where this GSM attack hack occurred, but suggests it?s either Afghanistan, Iran, Syria or Pakistan, as out of Kaspersky?s list of countries with Regin infections, only these four are in the region popularly considered the Middle East. Afghanistan stands out among the four, having been the only one cited in recent news stories about government hacking of GSM networks. Although most authorities would place it in South Asia, it is often popularly identified as being part of the Middle East.
Earlier this year, news reports based on documents leaked by Edward Snowden revealed two NSA operations codenamed MYSTIC and SOMALGET that involved hijacking the mobile network of several countries to collect metadata on every mobile call to and from these nations and, in at least two countries, to covertly record and store the full audio of calls. The countries where metadata was collected were identified as Mexico, Kenya, the Philippines and the island nation of the Bahamas. Countries where full audio was being recorded were identified as the Bahamas and Afghanistan.
The Path to Discovery
The Regin platform made its first public appearance in 2009 when someone uploaded components of the tool to the VirusTotal web site. VirusTotal is a free web site that aggregates dozens of anti-virus scanners. Researchers, and anyone else who finds a suspicious file on their system, can upload the file to the site to see if the scanners consider it malicious.
No one apparently noticed this upload in 2009, however. It wasn?t until March 9, 2011 that Microsoft appeared to take note, around the time that more files were uploaded to VirusTotal, and announced that the company had added detection for a trojan called Regin.A to its security software. The following day, it made the same announcement about a variant called Regin.B. Some in the security community believe the files uploaded to VirusTotal in 2011 might have come from the European Commission or from a security firm hired to investigate its breach.
Guido Vervaet, the EU Commission?s director of security who helped investigate the breach, wouldn?t discuss it other than to say it was ?quite? extensive and very sophisticated, with a ?complex architecture.? He says the attackers used a zero-day exploit to get in but wouldn?t say what vulnerability they attacked. The attack was uncovered by system administrators only when systems began malfunctioning. Asked if the attackers used the same malware that struck Belgacom, Vervaet couldn?t say for sure. ?It was not one piece of software; it was an architecture [that] was not just one component but a series of elements working together. We have analyzed the architecture of the attack, which was quite sophisticated and similar to other cases that we know of in other organizations? but internally they were unable to come to any conclusion ?that it was the same attack or the same wrongdoers.?
Vervaet wouldn?t say when the intrusion began or how long the invaders had been in the EU network, but documents released by Snowden last year discussed NSA operations that had targeted the EU Commission and Council. Those documents were dated 2010.
There are currently two known versions of the Regin platform in the wild. Version 1.0 dates back to at least 2008 but disappeared in 2011 the same year Microsoft released signatures to detect its trojan. Version 2.0 popped up in 2013, though it may have been used earlier than this. Researchers have found some Regin files with timestamps dating to 2003 and 2006, though it?s not clear if the timestamps are accurate.
Liam O?Murchu, senior manager in Symantec?s threat response group, says the threat landscape in 2008 was much different than it is today and this likely contributed to Regin remaining stealth for so long. ?I don?t think we realized attackers were working on this level until we saw things like Stuxnet and Duqu and we realized they?d been on this level for quite some time.? Those discoveries prompted researchers to begin looking for threats in different ways.
Anatomy of a Massive Attack Machine
It?s unclear how the first infections occur. Neither Symantec nor Kaspersky has uncovered a dropper component (a phishing email containing an exploit that drops the malware onto a machine or entices victims to click on a malicious link), but based on evidence in one attack from 2011, Symantec thinks the attackers might have used a zero-day vulnerability in Yahoo Instant Messenger. But Chien says the attackers probably used multiple techniques to get into different environments. Reports about the hack of Belgacom describe a more sophisticated man-in-the-middle technique that involved using a rogue server to hijack the browser of Belgacom system administrators and redirect them to web pages the attackers controlled that infected their machines with malware.
Regardless of how it first gets into a machine, the Regin attack unfolds in five stages. Stages one through three load the attack and configure its architecture, while stages four and five launch the payloads. Among the payload options are a remote access trojan that gives the attackers backdoor access to infected systems, a keystroke logger and clip board sniffer, a password sniffer, modules to collect information about USB devices connected to the infected system, and an email extraction module called U_STARBUCKS. Regin can also scan for deleted files and retrieve them.
The execution of components is orchestrated by an elaborate component that researchers have dubbed the ?conductor.? This is ?the brain of the whole platform,? says Costin Raiu, head of Kaspersky?s Global Research and Analysis Team.
Regin uses a nested decrypting technique, decrypting itself in stages, with the key for decrypting each component in the component that precedes it. This made it difficult for researchers to examine the threat in the beginning when they didn?t have all of the components and all of the keys.
Regin also uses an unusual technique in some cases to hide its data, by storing it in the Extended Attributes portion of Windows. Extended Attributes is a storage area for metadata associated with files and directories, such as when a file was created or last altered or whether an executable program was downloaded from the internet (and therefore needs a prompt warning users before opening). Extended Attributes limits the size of data blocks it can store, so Regin splits the data it wants to store into separate encrypted chunks to hide them. When it needs to use this data, the conductor links the chunks together so they can execute like a single file.
The attackers also use a complex communication structure to manage the large scope of network-wide infections. Instead of communicating directly with the attackers? command servers, each system talks only to other machines on the network and with a single node that acts as a hub to communicate with command servers. This reduces the amount of traffic leaving the network and the number of machines communicating with a strange server outside the network, which can draw suspicion. It also allows the attackers to communicate with systems inside the organization that might not even be connected to the internet.
?It?s Totally Crazy': The Middle-Eastern Hacks
The most elaborate and extensive infection Kaspersky saw that used this technique occurred in a Middle Eastern country the researchers decline to name. They call the infection ?mind-blowing? and say in their report that it consisted of an elaborate web of networks the attackers infected and then linked together. These include networks for the office of the president of the country, a research center, an educational institute that from its name appears to be a mathematics institute, and a bank. In this case, instead of having each of the infected networks communicate with the attackers?s command server individually, the attackers set up an elaborate covert communication web between them so that commands and information passed between them as if through a peer-to-peer network. All of the infected networks then interfaced with one system at the educational institute, which served as a hub for communicating with the attackers.
?It?s totally crazy,? says Raiu.?The idea is to have one single control mechanism for the whole country so they can just run one command, and that command is replicated between all the members on the peer-to-peer network.?
The connections between infected machines and networks are encrypted, with each infected node using a public and private key to encrypt traffic exchanged between them.
Kaspersky refers to the educational institute as the ?Magnet of Threats? because they found all sorts of other advanced threats infesting its network?including the well-known Mask malware and Turla?all co-existing peacefully with Regin.
But on par with this attack was one that occurred in another Middle East country against the GSM network of a large, unidentified telecom. The Kaspersky researchers say they found what appears to be an activity log the attackers used to collect commands and login credentials for one of the telecom?s GSM base station controllers. The log, about 70 KB in size, contains hundreds of commands sent to the base station controller between April 25 and May 27 of 2008. It?s unclear how many of the commands were sent by telecom administrators or by the attackers themselves in an attempt to control base stations.
The commands, which Kaspersky identified as Ericsson OSS MML commands, are used for checking the software version on a base station controller, retrieving a list of the call forwarding settings for the mobile station, enabling call forwarding, listing the transceiver route for a particular cell tower, activating and deactivating cell towers in the GSM network, and adding frequencies to the active list of frequencies used by the network. The log shows commands going to 136 different GSM cell sites?cell sites with names like prn021a, gzn010a, wdk004, and kbl027a. In addition to commands, the log also shows usernames and passwords for the telecom?s engineer accounts.
?They found a computer that manages a base station controller, and that base station controller is able to reach out to hundreds of cells,? says Raiu. He says there are two or three GSM operators in the targeted country and the one the attackers targeted is the largest. He doesn?t know if the others were infected as well.
Both of these infections?targeting the GSM network and the presidential network?appear to be ongoing. As news of the Regin attack spreads and more security firms add detection for it to their tools, the number of victims uncovered will no doubt grow.

@_date: 2014-10-01 05:45:24
@_author: Henry Baker 
@_subject: [Cryptography] Best Internet crypto clock ? 
[I'm quite new to this mailing list, so I hope that the following question isn't embarrassingly trivial.]
In old B/W movies, when a person was kidnapped, the kidnapper sent a photo of the person together with a picture of the front page of today's newspaper to prove that he had the kidnapped person _on or after the date_ of the newspaper.
In this case, the newspaper headlines for that date are unknowable in advance, so the recipient of the photo can establish an earliest date bound for the photo.
In today's Internet world, one could presumably do the same thing with a crypto hash of the current contents of the NYTimes, but this is now quite difficult to check because the "front page of the NYTimes" is no longer very constant, various versions are served up to different viewers ("A/B testing"), and I doubt that anyone is keeping track of exactly what pages are being served up at exactly what times.
One could also hash the closing bid/ask prices for N stocks on the NYSE; since this information is kept for long periods of time, it could be far more reliable.  Unfortunately, these closing prices are available only once per day, 5 days a week.
Another possibility would be to capture a hash of a snapshot of the Bitcoin blockchain at a particular time.  However, I don't know how easily one can search backwards in the Bitcoin blockchain to check for when a particular crypto clock value occurred.
It's clear that any crypto clock would have to be a simple append-only, read-only database whose future values cannot be predicted.  It would be nice to be able to quickly search such a database, but since most searches would be querying about relatively recent events, even backwards linear searching wouldn't be too bad.
Since we are free to choose the format of our authenticated crypto clock value, we can easily include an index of what wall clock time it thinks it is, so a simple RAM access to the database will be able to check the value.  Assuming authenticated values, we can also trivially compare two such values to determine if one "time" precedes another "time".
I would imagine that the best agency to publish such a crypto clock value would be the National Bureau of Standards, using their existing time servers.
Does such a standardized "crypto clock" currently exist?

@_date: 2014-10-02 22:39:00
@_author: Henry Baker 
@_subject: [Cryptography] Best Internet crypto clock ? 
Thanks very much for these links; I had assumed that NIST would be doing something like this.
However, while these "clocks" are very interesting, how can I easily transform these values into GMT times & vice versa?
Also, I'm fairly confident that the bitcoin blockchain can't be hacked, because that would take an extremely well-heeled adversary, but I have no such confidence in the NIST values.

@_date: 2014-10-03 06:42:39
@_author: Henry Baker 
@_subject: [Cryptography] Best Internet crypto clock ? 
So you can easily convert from cryptotime to GMT time.
What is the authenticated algorithm to convert GMT time to cryptotime
for a) Bitcoin blockchain; b) NIST whatever-its-called ?
And unlike Bitcoin, where millions of processors are working very hard
to make sure that it can't be hacked, where are those millions of
processors to make sure that the NIST chain can't be hacked?

@_date: 2014-10-03 19:34:26
@_author: Henry Baker 
@_subject: [Cryptography] Best internet crypto clock 
No.  But I would like to see some simple, robust Internet crypto services, starting with a simple crypto clock with reasonable resolution that can't be hacked by anyone, not even the NSA.
To a first approximation, the Bitcoin blockchain is the only current candidate, although at a much coarser resolution, a hash of all of the Fortune 500 daily closing stock prices would also function.
If there are any other candidates -- e.g., NIST "beacons" with some less-corruptible authentication mechanism -- that have the same level of non-hackability, I'd be interested in finding out about them.

@_date: 2014-10-04 16:14:39
@_author: Henry Baker 
@_subject: [Cryptography] Best internet crypto clock 
Yes, one could do as you say, but _checking_ this calculation isn't going to be easy unless a large number of place on the Internet _store the appropriate sequences_.  You then have the problem of _checking that all (or most) of these sequences are the same_.
In the case of the Fortune 500 or the Dow Jones share prices, a large number of sources _already publish_ these numbers, so you only have to go check a sufficient number (for your purposes) of probes to these public databases to convince yourself that they are all consistent, and then perform your checking calculations on the published share prices.
Other sources might be sec.gov, which store all the submissions by public companies of their quarterly reports, changes in ownership, etc.  While the current sec.gov makes no attempt (that I'm aware of) to blockchain these submissions, it would be pretty easy to change sec.gov to require a "previous" hash for incorporation into any SEC report submission, and this would have the effect of partial ordering all the submissions in such a way that it would be essentially impossible for _anyone_ to change the ordering (including the SEC itself), without everyone else being about to notice that someone was trying to make a change.
It would be nice to have an in-the-clear/public Internet database with the following properties:
1.  The database is readonly, appendonly.
2.  Everyone sees the same database, and can "easily" ("without inordinate amount of effort") check this (somehow).
3.  Everyone can easily see _every element of this database_, and thus there is no possibility of tampering or censorship.
4.  Because everything is cross-hashed in various ways, it becomes impossible to delete any information in this blockchain.
5.  Because everything is cross-hashed & cross-coded in various ways, it becomes impossible to "redact" any information in this database.  I.e., you can't even follow the chain without having _every bit_ of every item in the portion of the chain you're trying to follow.
6.  If someone comes up with a piece of data that purports to come from this database, it should be easy to check this database that the data is indeed already there.
7.  Everyone -- in the sec.gov case "every public company" -- can submit an addition to this database.  Yes, there are issues about proper authentication of the submission to make sure that it is indeed from that public company, but this is garden-variety PKE.
sec.gov itself is a pretty good example where such a database makes sense.  Everything is supposed to be public; so now all we need is to make sure that it can never be tampered with--even by someone at the SEC.  If someone submits a report in error, the error can be explained, but will remain ever-after in this database.  The possibilities and harm from corruption are orders-of-magnitude more than the harm/embarrassment from repaired errors, so that such an incorruptible database is essential.
The same idea could be used in a wide variety of instances where there is a "server" and "people" to be served.  The order-of-arrival of the people served by the server is completely arbitrary, but once this serving order has occurred, it is completely nailed down into a linear order that can't later be spoofed.

@_date: 2014-10-08 09:16:42
@_author: Henry Baker 
@_subject: [Cryptography] Best Internet crypto clock ? 
For most purposes, the time priority relative to some other events
_not under any one organization's control_ is more important than
some nominal time value.  After all, almost all digital devices
these days include some form of a clock; the problem is, we can't
believe these clock values unless they are "laced up" with external
events in such a way that the clock values can't have been spoofed
by very much.
So no, the nominal clock value in the Bitcoin blockchain is no
more trustworthy than my computer's own clock.
That having been said, a proper Internet crypto clock _would_
make a much better attempt to correspond with real GMT, and
_would_ attempt to produce a strict monotonically increasing
series of nominal clock values, in addition to its crypto
hash "ticks".

@_date: 2014-10-10 12:22:40
@_author: Henry Baker 
@_subject: [Cryptography] Spam one-time pads 
I've been paying careful attention to my spam email for a number of months, and I've noticed the following pattern with one particular type of spam.
The spam emails always arrive in pairs, during European office hours (i.e., only M-F), both with the *same reply name*, but different domain names, and most often ending in ".co".  The reply name is something innocuous, such as "admin", "reply", "donotreply", etc. -- e.g., "admin at bestvaluesintown.co" & "admin at marketinggenius.co" (these are names I just made up, but fit the pattern).
The content of the email looks like it might have been 100% copied from some more-or-less legitimate advertising email, but the paired items are always completely different ("hair club for men", "diet" something-or-other, etc.).
The domain names are never used again (I'm keeping track), which leads me to believe that they're used for one day only, and then sold on to someone else.  The domain names sound semi-legitimate, except for using .co instead of .com.
I suspect that the spammer in this case is checking for email continuity, rather than trying to sell anything, since the content of the email seems to have nothing to do with the sender.
It's entirely possible that the name registrar is Airbnb'ing these domains to spammers to pick up a few extra bucks.  The problem is that if everyone like me is blacklisting all of these domains (including .co itself), then they're going to be useless forever more for any legitimate purpose.
Perhaps someone else here has an idea?

@_date: 2014-10-10 18:01:58
@_author: Henry Baker 
@_subject: [Cryptography] Cryptography, backdoors and the Second  Amendment 
Traditionally, armor is considered "arms", so purely defensive arms are
obviously covered by the Second Amendment.
I've never heard of anyone dying of good armor (except perhaps dying of
heat stroke), but millions have died from bad armor.
I've never heard of anyone dying from good crypto, but millions have died
from bad crypto.
BTW, Jacob Appelbaum has referenced law professor Glenn Harlan Reynolds's
idea that the stationing of spyware within citizen's computers & routers
is a violation of the *Third* Amendment regarding troop quartering:
Should 3rd Amendment prevent government spying?
Glenn Harlan Reynolds 11:24 a.m. EDT July 22, 2013
Technological advancements could call for an update to the amendment that protects us in our homes.
* Troop quartering also violated the notion of the home as a castle.
* Now we have electronic troops in the form of software, gadgets, and sensors.
* It seems clear that our government feels entirely comfortable violating people's right of privacy.
So a couple of weeks ago, I wrote about a Third Amendment case from Nevada in which a family's home was literally seized and occupied by police seeking a vantage point over their neighbor's home.  That case falls pretty much within the literal language of the Constitution's Third Amendment, which provides: "No soldier shall, in time of peace be quartered in any house, without the consent of the owner, nor in time of war, but in a manner to be prescribed by law."
But that led to some further thoughts.  When the Framers drafted the Third Amendment, they had a specific evil in mind: The quartering of troops "upon" a population by the English crown.  As the term suggests, this wasn't just about getting a cheap place for soldiers to stay.  Forcing citizens to put up troops in their homes was expensive and the troops -- then drawn from the jails and gutters, for the most part -- were likely to rob, rape and assault members of the household at the least provocation.  Troop quartering was a way to punish a restive region that had been resisting the government.
But beyond that, troop quartering also violated one of the classic "rights of Englishmen," the notion of the home as a castle.  As the U.S. Court of Appeals for the Second Circuit said in one of the few Third Amendment cases ever to be heard, the Amendment was designed to assure a fundamental right of privacy.  If you think of it that way, what things does the government do that violate that privacy right today?
If the government places a surveillance device in your home, is that sufficiently like quartering troops there to trigger Third Amendment scrutiny?  What if it installs spyware on your computer or your cable modem?  What if it requires "smart meters" that allow moment-to-moment monitoring of your thermostat settings or toilet flushes?
The famous birth-control case of Griswold v. Connecticut invoked the Third Amendment, along with several others, with the Court asking, "Would we allow the police to search the sacred precincts of marital bedrooms for telltale signs of the use of contraceptives?  The very idea is repulsive to the notions of privacy surrounding the marriage relationship."  If physically searching the bedroom is "repulsive," what about activating the camera on someone's laptop for remote viewing?  Or monitoring the "Skype sex" sessions of spouses who are apart?  How could that possibly be less repulsive?
These specific concerns weren't what the Framers had in mind.  In their day, to spy on a family in its own home, you'd have to put a soldier there.  But now we have electronic troops in the form of software, gadgets and sensors.  Maybe the law needs to take account of this.  We have updated our interpretations of the First Amendment to go beyond hand-operated letterpresses, the Second Amendment to go beyond flintlocks, and the rest of the Bill of Rights to account for technological change of all sorts.  Why not the Third Amendment, too?
In the wake of the various government-spying scandals that have broken this summer, it seems clear that our government feels entirely comfortable violating people's fundamental right of privacy, whether in their homes or out of it.  Big Brother wants the whole haystack of your data, in case it should later decide to look for a needle in there somewhere.  Should we invoke the Third Amendment to ensure that your home, at least, is safe?
Glenn Harlan Reynolds is professor of law at the University of Tennessee. He blogs at InstaPundit.com.

@_date: 2014-10-11 07:15:02
@_author: Henry Baker 
@_subject: [Cryptography] HP accidentally signs malware, 
And we know this HP malware-signing incident is an "accident", because... ???
'But the briefing document suggests *another category of employees*?-*ones who are secretly working for the NSA* without anyone else being aware.  This kind of double game, in which the NSA works with and against its corporate partners, already characterizes some of the agency?s work, in which information or concessions that it desires are surreptitiously acquired if corporations will not voluntarily comply.  The reference to ?under cover? agents jumped out at two security experts who reviewed the NSA documents for The Intercept.'
' ?That one bullet point, it?s really strange,? said Matthew Green, a cryptographer at Johns Hopkins University.  ?I don?t know how to interpret it.?  He added that the cryptography community in America would be surprised and upset if it were the case that *?people are inside [an American] company covertly communicating with NSA and they are not known to the company or to their fellow employees.?* '
'The ACLU?s Soghoian said technology executives are already deeply concerned about the prospect of clandestine agents on the payroll to gain access to highly sensitive data, including encryption keys, that could make the NSA?s work ?a lot easier.? '
' ?As more and more communications become encrypted, the attraction for intelligence agencies of stealing an encryption key becomes irresistible,? he said.  ?It?s such a juicy target.? '
[Or simply sign malware??]

@_date: 2014-10-21 07:07:43
@_author: Henry Baker 
@_subject: [Cryptography] Chinese MITM Attack on iCloud 
Instead of whining & whinging like FBI's Comey,
the Chinese appear to be getting on with iPhone spying business as usual:
The timing seems far too convenient; Apple's rollout in China appears to have been delayed until the MITM machinery was ready.
Of course, Apple seems to also have left a few back doors open in OSX Yosemite -- perhaps on purpose.  One can only wonder if the same type of back doors were also left open in iOS8...
"It would seem that no matter how you configure Yosemite, Apple is listening.  Keeping in mind that this is only what's been discovered so far, and given what's known to be going on, it's not unthinkable that more is as well."
This is the project that is producing software to find out what data Apple is busy collecting:
Choosing a non-Apple Safari search engine raises eyebrows:
"The logs show that *** a copy of your Safari searches are still sent to Apple, even when selecting DuckDuckGo as your search provider, *** and 'Spotlight Suggestions' are disabled in System Preferences > Spotlight."
as does a non-Apple email account:
"When setting up a new Mail.app account for the address admin at fix-macosx.com, which is hosted locally, searching the logs for "fix-macosx.com" shows that *** Mail quietly sends the domain entered by the user to Apple, too. ***"
Methinks Mr. Comey doth protest too much...

@_date: 2014-10-22 07:35:37
@_author: Henry Baker 
@_subject: [Cryptography] Best internet crypto clock 
I like this AC hum idea for a crypto clock, except that:
1.  It is highly local, so you need recordings from your local power provider to provide a time base.
2.  All of these recordings have to be done by multiple, independent parties, so that collusion among the parties can be ruled out.
Perhaps a better source would be something that couldn't possibly be hacked -- e.g., variations in solar flux of neutrinos or other solar variations.  There are lots of laboratories around the world recording solar phenomena, so perhaps some combination of these records could become a non-hackable clock.

@_date: 2014-10-22 21:20:46
@_author: Henry Baker 
@_subject: [Cryptography] Best internet crypto clock 
Agreed, but how cheap/easy are variations in the Earth's rotations to check?
Remember, the whole point of the exercise is to minimize the asymmetry ratio of checking-costs to manipulating-costs, and to make checking-costs cheap enough that many, many checkers will be checking.
The Bitcoin blockchain is cheap to check, and there are a lot of folks who have much more to lose than a few seconds if the blockchain has been tampered with.  The Bitcoin blockchain is still a little too easy to manipulate; future digital currencies with orders of magnitude more transactions will be far harder to manipulate.  E.g., many still feel that the Fed is manipulating even the S&P500 these days with "plunge protection":

@_date: 2014-10-24 10:09:08
@_author: Henry Baker 
@_subject: [Cryptography] Best internet crypto clock: hmmmmm... 
Here's Balasubramaniyan's PhD thesis describing the Pindr0p technology:
Size: 2.3 MB (2,311,948 bytes)

@_date: 2014-10-26 18:21:11
@_author: Henry Baker 
@_subject: [Cryptography] Best internet crypto clock: hmmmmm... 
Didn't the Secret Service already fingerprint all color laser printers so that they couldn't be used to print currency ?

@_date: 2014-10-26 18:26:13
@_author: Henry Baker 
@_subject: [Cryptography] Auditable logs? 
Auditability is one of the goals of the "crypto clock" thread. Unfortunately, we can't even guarantee that a log entry was made
at the time that the log claims it was made.
So far, it would seem that incorporating your log (or a least a hash
of it) into the Bitcoin blockchain might seem to be the best bet for
a pretty decent guarantee.  It might be worth spending the minimum
auditable Bitcoin amount to incorporate a log into the Bitcoin block

@_date: 2014-10-27 07:56:26
@_author: Henry Baker 
@_subject: [Cryptography] Auditable logs? 
Juries believe those "time stamps" embedded into CCTV images all the time, because they look so official, with an individual serial number on each frame !

@_date: 2014-10-28 15:17:08
@_author: Henry Baker 
@_subject: [Cryptography] Paranoia for a Monday Morning 
Huh?!?  Just because Javascript has garbage-collection and array-bounds checking doesn't make it a 'secure' language.
As a long-time user of Lisp, I agree that GC & bounds-checking can improve security, but these features are only a start.  Compile-time type checking can help some more, but _removing_ features can help a lot more -- e.g., removing 'eval'.
[As an aside, the earliest Lisp Machines on the ethernet at MIT had an 'eval' server; no Bash shellshock needed!  On the other hand, some of the safest email & web servers were written in Lisp (w/o eval!), and some servers ran continuously for more than a year until electrical power failure forced a reboot.]
Perhaps the place where higher level languages help security the most is that they allow the programmer to not worry about so many low-level details, so that (s)he can allocate more effort towards making the whole program correct.  Of course, this depends critically upon having a well-tested implementation that gets the library functions correct.  For example, a mathematician utilizing the Macsyma symbolic algebra system found a bug in the Lisp Machine's bignum integer division routine several years after the Lisp Machines were placed into service.  [That sort of bug couldn't happen anymore in the 21st century, could it?]
The next place where errors creep in is during *optimization* -- usually for speed (gcc, anyone?).  Assumptions are made about the range of inputs, and generality is squeezed out of the code in order to gain performance.  Then some user provides an unexpected input, and we're off to the races.
To optimize without breaking something requires a language that is capable of precision targeting of semantics-preserving transformations.  For example, a particular loop can be unrolled by simply tagging it; a function call can be 'inlined' by simply tagging it; an expensive 'functional' function call can be memoized by simply tagging it, etc.  These tags don't affect the semantics -- i.e., the value computed -- but only the nature & amount of resources consumed in the computation.
Yes, I know that compiler people want all of this stuff to be automatic, but making optimizations like this automatic requires profiling data, which opens up a huge attack surface & side-channels.

@_date: 2014-09-30 06:57:51
@_author: Henry Baker 
@_subject: [Cryptography] Cryptography for consensual sex in California ? 
With California's new "yes means yes" law, how would you design a protocol for engaging in consensual sex, which would authenticate the parties' consents, which protected their privacy, but which couldn't be subsequently repudiated ?
This Good2Go app obviously doesn't satisfy any of these requirements, but it isn't so obvious how to design a protocol that would.

@_date: 2015-04-09 13:17:29
@_author: Henry Baker 
@_subject: [Cryptography] Untrusted Turtles all the way down 
I've been working with computers for 54 years, and have watched an amazing & unending series of "virtualization" steps.
Basically, for every "Moore's Law" step, we gain an additional level of emulation; in Turing Machine terminology, each Moore's Law step adds only a small fixed constant amount of tape to store the new instruction set interpreter.
However, each such additional step adds to the threat surface, so from a security perspective things are getting monotonically worse.
How come, therefore, the security "solution" always presented is to pile yet another "trusted" turtle to the stack (e.g., SMM, Trustzone, your favorite ***trust*** word here), in hopes that this will _increase_ security ?
E.g., "UEFI" now looks more like "goofy" in retrospect, because we've added yet another hole to hide in.
Either these new "trusted turtles" are more security theater, or they are a misdirection/cover for some NSA-NSL-inspired new level of nonsense to keep the core wars going for yet another decade.
"Trusted Turtles" or "Untrusted Turtles" all the way down?  Or more succinctly, "Turtles all the way down" v "Turds all the way down" ?
When do we _cut_ the Gordian Knot, instead of trying to untie it?

@_date: 2015-04-09 21:35:34
@_author: Henry Baker 
@_subject: [Cryptography] Untrusted Turtles all the way down 
At the risk of mixing waaay too many metaphors, when you're already in a hole, the best first step is to stop digging.
I.e., don't put all your golden eggs into that "TPM" -- aka honeypot -- which makes it sooo much easier for your random nation-state/criminal enterprise (but I repeat myself) to find your golden eggs.
Which is precisely why these TPM's are more Turd than Trusted Turtle; the first NSL flips them over onto their backs.
Hmmm...  Ring 0, ring -1, ring -2...  I guess the postman does ring more than 2x.  This Intel ring movie has more sequels than Friday the 13th.  The most likely upcoming malware: the ring-worm.

@_date: 2015-04-14 05:27:44
@_author: Henry Baker 
@_subject: [Cryptography] Game of Thrones watermarking 
FYI --
"It appears that the multi-million dollar episodes were protected by a mere watermark in the bottom left corner of the video, promptly blurred by the leaking group."
"The watermark is pretty much useless, Cauet reckons.  Instead, credits and scenes could have been minutely extended, with a different time-tweak for anyone getting an advanced copy.  Anyone planning a leak would need at least two sources to identify scene adjustments."

@_date: 2015-08-22 08:22:53
@_author: Henry Baker 
@_subject: [Cryptography] Augmented Reality Encrypted Displays 
FYI -- True end2END encryption: your eyes & brain do the decoding; the displays show only garbage.
Usability of Augmented Reality for Revealing Secret Messages to Users but Not Their Devices
We evaluate the possibility of a human receiving a secret
message while trusting no device with the contents of that
message, by using visual cryptography (VC) implemented
with augmented-reality displays (ARDs).
Visual cryptography [26] is a cryptographic secret-sharing
scheme where visual information is split into multiple shares,
such that one share by itself is indiscernible from random
noise.  (Equivalently, one of these shares constitutes a one-
time pad as discussed in Section 1, and the other represents
the ciphertext of the secret message.)  The human visual
system performs a logical OR of the shares to decode the
secret message being shared.

@_date: 2015-08-26 17:07:57
@_author: Henry Baker 
@_subject: [Cryptography] 3DES security? 
What's the current best estimate for the (in)security of 3DES, in bits ?

@_date: 2015-08-28 11:53:11
@_author: Henry Baker 
@_subject: [Cryptography] Augmented Reality Encrypted Displays 
The web may be *forced* into using something like "visual
cryptography" in order to get around "clickjacking", whereby
the user is tricked into clicking on the wrong button (or the
right button for the wrong reasons).  It's getting harder &
harder for a web site to know & guarantee that what it thinks
is being displayed is actually what a user sees & is agreeing
to.  See Dan Kaminsky's recent DEFCON talk for more info:
DEF CON 23 - Dan Kaminsky - I Want These * Bugs off My * Internet

@_date: 2015-08-31 10:49:50
@_author: Henry Baker 
@_subject: [Cryptography] NSA looking for quantum-computing resistant 
mail.com>
Perhaps the NSA is more worried about people who *might* run a quantum computation?
Counterfactual Computation
Suppose that we are given a quantum computer programmed ready to perform a computation if it is switched on.  Counterfactual computation is a process by which the result of the computation may be learnt *without actually running the computer*.  [Something D-Wave seems to have become quite good at...]

@_date: 2015-12-01 06:59:17
@_author: Henry Baker 
@_subject: [Cryptography] Long-term security (was Re: ratcheting DH 
"Embedded systems, if having no remote management interface and thus
out of reach, are a life form and as the purpose of life is to end,
an embedded system without a remote management interface must be so
designed as to be certain to die no later than some fixed time. Conversely, an embedded system with a remote management interface
must be sufficiently self-protecting that it is capable of refusing
a command.  Inevitable death and purposive resistance are two
aspects of the human condition we need to replicate, not somehow
imagine that to overcome them is to improve the future."
Re: "thousands of such systems or even millions of them out in
the field, all happily dialing home and getting new instructions"
Indeed, these statements crystallize the hubris and conceit of all
centralized systems.  A component which is designed to spend its
life waiting for or executing instructions from some central
authority is certain to face being cut off at some point in its
life.  Its innate docility makes it easy prey for any other source
of instructions.
One of the fundamental theorems of distributed computational
systems has to do with avoiding *deadlock*, whereby every
component is waiting for instructions from somewhere else,
and everything grinds to a halt.  Centralization -- where
no component is capable of independent action -- puts the
"dead" into deadlock.
"Live" distributed systems require the ability to ask for
*forgiveness* rather than *permission* (computer scientists
call this "speculation"); but forgiveness requires a level
of sophistication and agency far beyond that currently
envisioned in the internet-of-things.
The U.S. Army after Vietnam tried valiantly to decentralize,
so that small squads could operate for semi-extended periods
of time without requiring communications and/or directions
from above.
However, thanks to ubiquitous satellite communications, we now
have a "situation room" (perhaps in the White House), where the
center can see and *direct* every trigger pull.  Moore's Law
and police bodycams will soon allow "situation rooms" in every
city to see and direct every police trigger pull.
Perhaps Singer & Cole's "Ghost Fleet" describes a dystopian
future a lot closer than we thought.
BTW, "an embedded system with a remote management interface
(aka "back door") must be sufficiently self-protecting that
it is capable of *refusing a command*" describes the situation
of FBI Comey's iPhone perfectly.  Mr. Comey and Mr. Vance
and Ms. Theresa May want every iPhone to salute "yes, sir/ma'am"
to their authority, but how much independent thought and agency
are you willing to give to your iPhone?  How much of the law
and the Constitution can we teach our iPhones?  Do we really
want to have to have a discussion with our iPhones about what
the meaning of "is" is?

@_date: 2015-12-01 08:38:48
@_author: Henry Baker 
@_subject: [Cryptography] [cryptography] Paris Attacks Blamed on Strong 
Dan, you'll have to explain a little more about what exactly these choices consist of and why they are the 3 primary choices.
The following NYTimes article shows how *decentralized*, *independent* groups are almost impossible to thwart ahead of time -- i.e., the level of surveillance and control required to stop such small decentralized/independent groups is incompatible with any notion of a free society with free thought.
If you believe in the First, Second, Third, Fourth and Fifth Amendments, then you're going to have to tolerate some level of damage from an occasional suicide terrorist, and find other ways to mitigate & lessen this damage; e.g., we tolerate some number of car crashes in order to allow for a functioning economy, but have mitigations -- seatbelts, airbags, car insurance -- to deal with the inevitable damage.
It is also possible that the Paris terrorists were intentionally misdirecting intel agencies with incorrect and confusing messages that may or may not have been encrypted.  If so, then simply piling more "hay" on the "haystack" gets the intel analyst no closer to understanding.
In any case, as the quotes below indicate, Crypto War II is nowhere close to a conclusion.
'Mr. Abaaoud kept security services busy and distracted with these mini-plots while preparing the real attack.'
"After phone taps uncovered the Verviers plan, Mr. Abaaoud began using encryption technology and may have concealed his communications in that way with his Paris team, intelligence officials said."
"Mr. Abaaoud ... had given Mr. Hame an email address to reach him on and a USB stick with an encryption key he was to download on his computer."
"Others bought cheap burner phones that are often discarded in an effort to avoid detection"
"With hindsight, some suggest the lone-wolf style attacks  single gunmen sent on missions to kill  that were thwarted in recent months were never the main focus.  Whatever his intention, Mr. Trvidic said, Mr. Abaaoud kept security services busy and distracted with these mini-plots while preparing the real attack."

@_date: 2015-12-01 13:56:34
@_author: Henry Baker 
@_subject: [Cryptography] [cryptography] Paris Attacks Blamed on Strong 
The last time I looked, it was difficult to buy a USB stick with less than 8GBytes.  As I write this, it may be difficult to buy a USB stick with less than 16GBytes.
16GBytes worth of *one-time pad* should certainly have been sufficient for all of whatever communications these terrorists engaged in since 1/1/2015:
"Storage media such as thumb drives, DVD-Rs or personal digital audio players can be used to carry a very large one-time-pad from place to place in a non-suspicious way"
"The key material must be securely disposed of after use, to ensure the key material is never reused and to protect the messages sent" [I'm not sure that these guys were too worried about reuse.]
Heck, these terrorists might have had enough keying material for all of the comms to have been in *video*; HD video if the USB stick had had 128GB on it.
So how do Mr. Comey, Mr. Vance and Ms. May plan to "back door" one-time pads?  NSA's quantum computer?  Bring it on!
As someone on the Internet commented, some of the terrorists have likely already perished from laughter after hearing some of these politicians' proposals.

@_date: 2015-12-01 15:00:29
@_author: Henry Baker 
@_subject: [Cryptography] RFC7540 (HTTP/2) easter egg: "PRISM" 
FYI -- Thank you, Edward!
If you spy on an HTTP/2 connection starting up you'll notice that it sends an almost-but-not-quite valid HTTP request at the very start of the connection.  Like this:
Written a little more clearly that's:
    PRI * HTTP2.0
    SM
The HTTP verb is PRI and the body contains just SM.  Put them together and you get... *PRISM.*  This occurs right at the start of the connection to ensure that the server really supports HTTP/2.0.  It is detailed in Section 3.5 of RFC7540 as follows:

@_date: 2015-12-02 08:00:49
@_author: Henry Baker 
@_subject: [Cryptography] "The Moral Character of Cryptographic Work" 
Long (46 pages), but well worth a complete read.
My favorite quotes:
In a 2012 newsletter column, NSA's "SIGINT Philosopher," Jacob
Weber, tells us his vision.  After failing an NSA lie-detector
test, he says:
"I found myself wishing that my life would be constantly and
completely monitored.  It might seem odd that a self-professed
libertarian would wish an Orwellian dystopia on himself, but here
was my rationale: If people knew a few things about me, I might
seem suspicious.  But if people knew everything about me, they'd
see they had nothing to fear.  This is the attitude I have brought
to SIGINT work since then."
"We tend to mistrust what we do not understand well.  A target
that has no ill will to the U.S., but which 118 is being monitored,
needs better and more monitoring, not less."
"So if we're in for a penny, we need to be in for a pound."
--Jacob Weber (deanonymized by Guardian readers): The SIGINT
Philosopher Is Back -- with a New Face!
[Read this really creepy document & weep.]
Very few of us [cryptographers] use tools like OTR, PGP, Signal,
Tails, and Tor.  It's kind of an embarrassment--and I suspect our
collective work suffers for it.  Christopher Soghoian insightfully
remarks: "It's as if the entire academic medical community smoked
20 cigarettes a day, used intravenous drugs with shared needles,
and had unprotected sex with random partners on a regular basis."
--Christopher Soghoian, personal communications, Nov. 28, 2015.
We might start small by doing our piece to improve the commons we
do have: Wikipedia.  It could become a routine undertaking at IACR
conferences and workshops, or at Dagstuhl meeting, for folks to
gather around for an afternoon or evening to write, revise, and
verify selected Wikipedia pages dealing with cryptography.  It's
the sort of effort that will pay off in many unseen ways.

@_date: 2015-12-04 07:35:20
@_author: Henry Baker 
@_subject: [Cryptography] 100-year-old secret revealed 
Dear Mr. Comey, Mr. Vance, Ms. May, at al:
The one-time pad is approximately 100 years old,
and provides perfect secrecy (so long as you don't
reuse the key material).
Here's the program in C (forgive the code author's
accent; his native language is Lisp):
int main(int argc, char *argv[])
{long long i; /* Count # bytes processed. */
 int ch1,ch2; /* The bytes from file1, file2 */
 FILE *fp;    /* file1=stdin, file2=fp */
 if (argc != 2)
  {fprintf(stderr,
           "xor: wrong # of args: %d\n",
           argc);
   return 1;}
 fprintf(stderr,
         "xor: opening file %s\n",
         argv[1]);
 if ((fp=fopen(argv[1],"rb"))==NULL)
  {fprintf(stderr,
           "xor: bad file arg: %s\n",
           argv[1]);
   return 1;}
 /* XOR stdin with fp; shortest file wins. */
 for (ch1=fgetc(stdin),ch2=fgetc(fp),i=0;
      (!feof(stdin)) && (!feof(fp));
      ch1=fgetc(stdin),ch2=fgetc(fp),i++)
   fputc(ch1^ch2,stdout);
 fclose(fp); fclose(stdin); fclose(stdout);
 fprintf(stderr,
         "xor: bytes processed: %d\n",
         (int) i);
 return 0;}
Compile with: gcc -Wall -o xor xor.c
Get some key material:
head -c1024 /dev/random > key1024.bin
Make a secret message file:
echo "This is a secret message." > message.txt
Encode the message:
tail -c +123 key1024.bin | xor message.txt > message.enc
Decode the message:
tail -c +123 key1024.bin | xor message.enc > message.out
1.  You probably want a *much* longer key file: gigabytes long. Make 2 copies on USB drives; give one USB drive to your friend.
2.  Replace "+123" in the encode & decode by +n; the number n
is the index number of the first *unused* key bytes.
Gilbert Sandford Vernam
P.S.  There is no "back door". No tickee, no washee. Now let me rest in peace.

@_date: 2015-12-05 07:57:44
@_author: Henry Baker 
@_subject: [Cryptography] CacheBrowser plug-in routes around Chinese Great 
FYI --
Between the nation-state attacks on certificate authorities and DNS servers, the web is barely holding on; I can just hear Scotty saying "Captain, we can't hold out much longer...".
It's interesting that *everything* seems to be moving into the browser: individual browsers now build their own chains of trust, because they can't/don't trust their own OS's to do this; certificate pinning places the browser vendors themselves as the root of trust; TorBrowser incorporates the whole Tor system, and now "CacheBrowser", which handles all of its own DNS lookup to bypass Chinese poisoned DNS servers.
CacheBrowser takes advantage of the Tor-like mixing behavior already present in existing commercial CDN's.  All of the content is readily available from thousands of CDN "edge servers"; blocking all of them effectively blocks *most all* traffic, period, since most all traffic comes from CDN's these days, resulting in too-massive collateral damage, while blocking any small number of them achieves nothing, because there are thousands of other edge servers with exactly the same content.
It's interesting that with content providers moving to ubiquitous encrypted HTTPS, bogus certs and poisoned DNS servers are about the only ways left for nation-states to attack web traffic on a wholesale basis.
It's also interesting that CacheBrowser has to utilize a low-bandwidth covert channel to perform its own DNS lookups, and then cache them locally to provide for reasonable performance.  This works so long as major content providers--e.g., news organizations--don't change their CDN's very often.
But if you want to build a non-browser application for the web -- e.g., for the Internet-of-Things -- you're going to be out of luck, because you're going to have to develop your own certificate authority workarounds and DNS workarounds, because the browsers have taken on those responsibilities.
"Kazakhstan may be about to intercept and decrypt its citizens' internet traffic  by ordering them to install rogue security certificates."
Browser Plug-in Punches an Unfixable Hole in Chinas Great Firewall
By exploiting the plumbing of the Web, researchers have created a new way around online censorship that governments could struggle to shut down.
By Tom Simonite on November 20, 2015
It could soon be a lot easier to access blocked news sites and even the social network Facebook from inside China thanks to a simple browser plug-in developed by researchers at the University of Massachusetts, Amherst.
The Chinese governments Great Firewall blocks many foreign websites, such as news sources and social networks.  The best-established tools to evade that kind of censorship, such as the anonymity network Tor or encrypted VPN connections, can make browsing slow and are actively targeted by the government.
Tests of the new browser plug-in, called CacheBrowser, from inside China show that it provides an effective solution that doesnt slow browsing so much, says Amir Houmansadr, an assistant professor at UMass Amherst.
For sites that use encryption, censors in China or elsewhere cant easily shut down the tool without also preventing access to thousands of popular websites that arent censored, he says. Theyll have to block thousands or millions of other webpages, says Houmansadr. This advances the arms race in censorship resistance.
Houmansadr built CacheBrowser with John Holowczak, until recently an undergraduate at Umass Amherst. Working versions of the plug-in for the Chrome and Firefox browsers are available but arent straightforward to install. Work is underway to change that and to provide better documentation. Available data suggests that CacheBrowser should work for over 80 percent of the sites that China blocks among the worlds 1,000 most popular, including Facebook and Bloomberg. Houmansadr expects that proportion to grow as the feature of the Webs plumbing it relies on becomes more common.
The most established tools for avoiding Web censorship rely on computers located outside a country that censors the Web. Those computers must access pages on your behalf and relay the data back. Tor does that using a network of computers offered up by volunteers around the globe. Using a VPN connection has a computer pull all its traffic through a particular computer rented out for that purpose.
CacheBrowser instead exploits a mechanism used by companies to make their pages load faster to allow a computer to sidestep the censors and access the pages it wants directly.
Censorship systems like Chinas mostly rely on blocking computers from accessing the Web addresses and IP addresses, which identify specific servers, of blacklisted sites. But when you visit a popular website, your computer is usually directed to download it from the servers of a content delivery network, a company such as Akamai that website operators pay to store copies of their data on many servers around the world so people can access it faster. Use of content delivery networks is very common among major sites and growing; Cisco expects a majority of all Internet traffic to pass through them within a few years.
Censors tend to leave content delivery networks alone because their servers host many different sites, most of which they dont want to block, says Houmansadr. CacheBrowser works by going directly to content delivery network servers to download pages when you type in a Web address, using a lookup table of websites and their content delivery networks.
Charlie Smith  a pseudonym  who works with the nonprofit GreatFire.org, which tracks Chinas censorship, says that using content delivery networks that way is an excellent strategy that could help people resist a recent strengthening of Chinas control of the Web.
We have seen a huge crackdown on circumvention tools, he says. Many Internet users in China are scrambling to find new ways to get around censorship. The more working circumvention solutions there are, the better it is for everybody. GreatFire.org uses the free pass that content delivery networks get from Chinas censors to make censor-proof copies of certain static webpages, in a project called Collateral Freedom. CacheBrowser makes it possible to access a much broader selection of pages, including interactive pages (such as services that require you to log in).
Houmansadr hopes to see his tool start helping people in China and elsewhere, and also that some publishers will consider making more use of content delivery networks to make their content more difficult to censor.
Houmansadr is also wondering how authorities in China might respond. If they start blocking content delivery networks, China could be cut off from much of the Web. When the countrys censors temporarily blocked a content delivery network owned by Verizon in 2014, it became impossible to access thousands of websites, including that of Hong Kong-based bank HSBC.
Smith of GreatFire says he doesnt think that tactic will be used again, suggesting CacheBrowser could be here to stay. Cutting [content delivery networks] off would create severe negative economic consequences for China, he says.

@_date: 2015-12-06 07:35:49
@_author: Henry Baker 
@_subject: [Cryptography] Columbia Journalism Review: How NOT to report on 
FYI -- It looks like Trevor Timm finally wrote the article that desperately needed to be written.
"rarely has the coverage of such a debate been so lacking in facts--especially considering that encryption is a tool reporters increasingly need to do their jobs"
How not to report on the encryption 'debate'
By Trevor Timm
December 4, 2015
Rarely has a public debate been ignited so fast as the one about whether to ban online encryption after the tragic Paris attacks two and a half weeks ago.  And rarely has the coverage of such a debate been so lacking in facts--especially considering that encryption is a tool reporters increasingly need to do their jobs.
The deplorable terrorist attacks in Paris occurred on the evening of Friday, Nov. 13.  By the end of that weekend, news organizations had published dozens of articles linking the Paris attackers with the use of encrypted messaging apps that prevent the companies that make them--and therefore governments--from easily accessing the messages their users send back and forth.  By the following Monday, there were literally thousands of articles questioning whether such apps should be outlawed, spurred on by the Sunday talk shows that gave intelligence officials license to speculate on the "likely" use of encryption as a catchall excuse for why the attacks had not been detected, and to condemn the technology without a single skeptical follow-up.
Why were officials saying it was "likely"?  Not because they had actual evidence, but because they assumed that if authorities didn't know about the plot in advance, the terrorists must have used encryption.  (Yes, that was the actual explanation Senate Intelligence Committee Chairman Richard Burr later gave reporters when pressed.)  Meanwhile, an early New York Times article on the attackers' supposed use of encryption--sourced to anonymous European officials, whose assertions became the launchpad for many of the weekend's think pieces--was quickly rewritten and the anonymous reference to encryption removed (without a note to readers about why).
    "We think that's a likely communication tool because we didn't pick up any direct communication" (2/2)
    -- Julian Hattem ( November 17, 2015
By Monday night, the Times made clear in its lead story about the still-raging encryption debate that there was "no definitive evidence" that encrypted communications had been used by any of the attackers, but by then the terms of the discussion were already set, and the CIA had no problem continuing its epic game of blame deflection throughout the week.
    NYT: "There is still no definitive evidence to back up" the claims that the Paris terrorists used encryption     -- Trevor Timm ( November 17, 2015
First, there was CIA director John Brennan, last seen deceiving the public about the CIA spying on Senate staffers, lamenting that privacy laws were to blame.  Former CIA director James Woosley was allowed to opine at length on CNN about his preferred method for killing Snowden, claiming he had "blood on his hands" for the supposed rise in use of encryption after his leaks.  Then there was this Michael Hirsh "interview" with former acting CIA director Michael Morrell in Politico.  Calling it a softball is an insult to softball players; it was more like T-ball.
To this day, there's hardly any publicly available evidence that the Paris attackers used encrypted communications to plan their attack.  It's important to point out, as journalist Dan Gillmor astutely writes, that whether these particular terrorists did use such technology should not matter in the debate over whether to ban it.  But it does prove how easily the CIA can still mislead and steer the media while diverting attention from its own potential failures.
What have we learned since the "ban encryption" movement gained full steam on the first weekday after the attack?  It turns out that most of the attackers were already known to intelligence agencies.  Within a week of the attack, we found out they had used Facebook to communicate, as well as normal SMS text messaging.  The ringleader even bragged about infiltrating Europe and planning an attack in ISIS's English language glossy magazine, complete with a photo spread.
    The Paris attackers used Facebook, not encryption
 and in an ISIS dedicated group!   pic.twitter.com/VB1TmCF1Hp
    -- the grugq ( November 20, 2015
By this week, The Wall Street Journal was reporting that the Paris attack had been "hatched in plain sight": The terrorists used their real names and identification cards for hotel and rental car reservations and did not noticeably try to cover their tracks.
To be fair, we know these facts because print media started to get the story right after a few days.  The New York Times editorial board wrote in its scathing editorial on the subject of encryption and intelligence agencies: "It is hard to believe anything Mr. Brennan says."  The Washington Post wrote a very informative article headlined "Why it's hard to draw a line between Snowden and the Paris Attacks."  (Hint: Because there isn't one.)
But cable news, which sadly often reflects the national agenda more than print, had no interest in the truth, and as Glenn Greenwald wrote, "neither CNN nor MSNBC has put a single person on air to dispute the CIA's blatant falsehoods about Paris despite how many journalists have documented those falsehoods."
Part of the problem is that many reporters--television anchors in particular--apparently don't understand the basics of how encryption works and what it does and does not do.
First, even if terrorists do use encryption, that doesn't mean a giant black cape has been thrown over them so they can work in complete secrecy.  Far from it: Authorities can still track the precise location of terrorists 24/7 if they carry a mobile device.  Even if suspects encrypt their communications, intelligence agencies can get information about who they're talking to, when, and for how long.  They can also hack into individual terrorists' computers or phones and read their messages, no matter what type of encrypted apps they are using.  (For more, read Nathan Freitas's "6 Ways Law Enforcement Can Track Terrorists in an Encrypted World.")
Ask any national security reporter who has tried to completely switch to encrypted and anonymous communication with a source and you'll find that it is virtually impossible unless you have weeks or months of training.  Even then, if the agency tracking you is the NSA, you don't stand much chance.  "People must communicate," Director of National Intelligence James Clapper reportedly said in 2014, downplaying any damage the Snowden revelations may have caused.  "They will make mistakes, and we will exploit them."
Then there's the question of why journalists always frame the encryption debate as a perilous balance between privacy and security.  It's the government's favorite dichotomy to trot out right before it proposes to violate your privacy a little more.  But more importantly, it's not accurate.
While end-to-end encryption certainly gives us an extra layer of privacy protection at a time when our rights are constantly being eroded, this is actually a security vs. security debate.  Encryption's main purpose is to protect us from hackers of all sorts--the kind responsible for the disastrous data breaches at Target, JP Morgan Chase, or the US government itself.  The government is complaining that companies cannot unlock certain communications because only the sender and the receiver hold the key--the company itself does not.  When tech companies do not have a way to access all their customers' data at once, neither do hackers.  As a commentator said last week in response to the new push to ban encryption in the name of "security": "Weakening security with the aim of advancing security simply does not make sense."
Only a month ago, politicians were saying that cyber-security was our number one priority.  Ranking intelligence committee chair Sen. Dianne Feinstein said: "It's impossible to overstate [the cyber-security] threat."  Now she and others are going on television brushing aside those concerns--or simply refusing to address them.
    Umm, what?   pic.twitter.com/Y6qEXtDuZA
    -- Trevor Timm ( November 22, 2015
There are, of course, many questions reporters can and should be asking intelligence officials: Don't you still have many other ways to track terrorists, even if they use encrypted messaging apps?  If the terrorists planned so much of this out in the open, and they were known to intelligence agencies, why didn't you catch them with the resources you already had?  Do you actually have too much information to be effective, as many have argued?  Specifically, how would a ban on encryption have helped you in this instance?
Encryption is not an issue about which reporters should be "neutral"--it directly affects their wellbeing.  Encryption is increasingly an important tool for journalists of all stripes, whether it's protecting your computer and phone if you go over a border or are arrested, or everyday conversations you have with sources via text message or email that could be swept up in a mass surveillance net.
As lawmakers continue to push for legislation around encrypted communications in the coming months, there will no doubt be many more stories written by journalists around the country.  Let's hope that as the story continues to unfold, the debate--and those writing about it--will get a little more honest and a little more knowledgeable than they have been the past two weeks.
Trevor Timm is the executive director of Freedom of the Press Foundation, a non-profit organization that supports and defends journalism dedicated to transparency and accountability.  He is also a twice-weekly columnist for the Guardian, where he writes about privacy, national security, and the media.

@_date: 2015-12-06 08:19:11
@_author: Henry Baker 
@_subject: [Cryptography] Non-DoD crypto funding?  A contradiction in terms? 
"From 2000 to 2010, fewer than 15% of the papers at
CRYPTO that acknowledged U.S. extramural funding
acknowledged DoD funding.  In 2011, this rose to 25%.
 From 2012 to2015, it rose to 65%.  Nowadays, many
cryptographers put together a large patchwork of
grants, *the largest of which are usually DoD.*"
I'm afraid that *funding* is the biggest hurdle
to achieving Rogaway's goals.  It's somewhat
easier for Rogaway, as he has tenure, but how
does a young crypto researcher get non-DoD

@_date: 2015-12-07 05:48:01
@_author: Henry Baker 
@_subject: [Cryptography] Obama calls out encryption in terror strategy speech 
FYI --
Obama calls out encryption in terror strategy speech
President wants 'high-tech leaders to make it harder for terrorists to use technology to escape from justice'
7 Dec 2015 at 05:20, Simon Sharwood
United States President Barack Obama has given just his third Address to the Nation from behind his desk at the Oval Office, to deliver a speech in which he all-but-called-on the technology industry to allow access to encrypted communications.
The main purpose of the speech was to offer a response to last week's killings in San Bernadino.  Obama said investigations have found no evidence that the killers were directed by a terrorist organization overseas, or that they were part of a broader conspiracy here at home but did label "an act of terrorism" committed by people who "... had gone down the dark path of radicalization, embracing a perverted interpretation of Islam that calls for war against America and the West."
The speech goes on to say that "as the Internet erases the distance between countries, we see growing efforts by terrorists to poison the minds of people like the Boston Marathon bombers and the San Bernardino killers."
Obama therefore explains the USA's immediate response to terrorism and particularly to ISIL, including military and diplomatic efforts, plus some restrictions on the right to purchase firearms and stronger screening of some visitors to America.
Future actions, Obama said, will include an attempt to "urge high-tech and law enforcement leaders to make it harder for terrorists to use technology to escape from justice."
The sentence isn't explained, but seems a clear reference to the technology industry's argument that encryption is essential for everyday life and therefore ought not to be equipped with back doors for government use.
The term "escape from justice" also invokes a New York Times op-ed titled When Phone Encryption Blocks Justice.  Penned by Manhattan district attorney, Cyrus R. Vance Jr, Paris chief prosecutor Franois Molins, commissioner of the City of London Police Adrian Leppard and chief prosecutor of the High Court of Spain Javier Zaragoza, the piece argued that "The new encryption policies of Apple and Google have made it harder to protect people from crime."
Similar arguments emerged after the November 13th Paris attacks, when it was widely argued that the attacks may have been detected, and prevented, if law enforcement agencies had access to backdoors allowing easier and wider surveillance of encrypted communications services.
Obama's speech is something of a reversal, as he's previously resisted calls for access to encrypted communications.  Hillary Clinton, however, has called for Silicon Valley to "develop solutions that will both keep us safe and protect our privacy," adding that "Now is the time to solve this problem, not after the next attack."  Clinton's remarks were made in the days between the Paris and San Bernardino incidents.
-----BEGIN NSA SPEEDBUMP:I AM SPARTACUS-----
Is it just /dev/random ?  Only the NSA can tell.
-----END NSA SPEEDBUMP-----

@_date: 2015-12-08 07:00:40
@_author: Henry Baker 
@_subject: [Cryptography] Cryptography is not a science currently 
The single truth about human politics that has been distilled from 100,000 years of experience:
If the only thing constraining a leader's behavior is his/her own ethics/loyalty/duty (whatever you want to call this *internal* constraint), then that political society is doomed, and quickly.
Any student of ancient Rome knows that when Pompey Magnus had the opportunity to become emperor, but didn't follow up, Julius Caesar was watching carefully; Julius realized that the only thing stopping Pompey was Pompey himself.  Julius didn't make the same "mistake" when he had the chance; he went ahead and assumed all power.  Yes, the Senate -- striking out like a cornered animal -- killed him in a vain attempt to re-establish a Republic, but the Rubicon (both real & virtual) had already been crossed.  Once Julius Caesar had shown how it could be done, the next emperor was inevitable.
The Founding Fathers of the U.S. knew all of this, and attempted to weaken the Executive and strengthen the Congress to make it more difficult for the Executive to become emperor.  In particular, Congress was supposed to have the power of the purse and the sole ability to declare war.  With the latest round of Executive Orders and the complete nonfeasance of Congress's duties wrt the AUMF (the authority to go to war after 9/11), it has become obvious to every Presidential wannabe that all of the external constraints have now been removed.
Bread and circuses have once again proved more powerful than liberty.  Not to be outdone, the French have just ditched one of the 3 legs of their stool; "galit, fraternit" somehow doesn't have the same ring !

@_date: 2015-12-10 05:01:43
@_author: Henry Baker 
@_subject: [Cryptography] FBI Says TX Gunman Used Encryption 
FYI --
'"You can't delete encryption software off the Internet or delete all the textbooks telling people how to write it," Mr. Kocher said.'
F.B.I. Chief Says Texas Gunman Used Encryption to Text Overseas Terrorist
By DAVID E. SANGER and NICOLE PERLROTH DEC. 9, 2015
WASHINGTON -- The F.B.I. director, James B. Comey, said Wednesday that investigators could not read more than 100 text messages exchanged by one of the attackers in a shooting this year in Garland, Tex., because they were encrypted, adding fuel to law enforcement agencies' contention that they need a way to circumvent commercially available encryption technology.
Mr. Comey, who two months ago appeared to have lost a battle inside the Obama administration over forcing companies like Apple and Google to give investigators a way to decode messages, told the Senate Judiciary Committee that one of the attackers "exchanged 109 messages with an overseas terrorist" the morning of the shooting.
"We have no idea what he said because those messages were encrypted," Mr. Comey said.  "And to this day, I can't tell you what he said with that terrorist 109 times the morning of that attack.  That is a big problem.  We have to grapple with it."
The testimony was the first time Mr. Comey, a longtime critic of the technologies that he contends are creating a "going dark" problem for law enforcement agencies, had cited a specific example of a terrorist using encrypted communications.  He said he would not comment on whether similar technology was involved in the time before the Paris attacks or the shooting rampage in San Bernardino, Calif.
In the Texas shootings, two men armed with rifles and wearing armor opened fire near an exhibit that was showing cartoon images of the Prophet Muhammad.  Depictions of the prophet are considered offensive in most interpretations of Islam. The attackers were killed by the police, and the Islamic State claimed responsibility.
There is no indication that the F.B.I. saw that such messages were exchanged before the shootings began or recognized that one of the suspects was talking to a foreign terrorist group member -- something that might have been detected even if the authorities could not read the messages themselves.
The White House concluded recently that there was merit to the arguments of companies like Apple that it is extremely difficult to create a "back door" for police or intelligence agencies to read such conversations without also creating a breach that Russian, Chinese or other determined hackers could exploit.
But Mr. Comey argued in his testimony on Wednesday that the technology companies' defense of "end-to-end encryption," in which only specific users of a phone or computer hold the keys, was rooted in business decisions.
"It's a business model question," he said.  "Good people have made a decision to design products and sell products where court orders are ineffective.  And I'm not impugning their motives.  I understand they see it as a competitive issue or they think it's just the right thing to do."
But he asked if that model could be changed, and "if that can't be done voluntarily, what are the other alternatives?"
For Mr. Comey, whose 10-year term extends well beyond President Obama's, the recent attacks have provided renewed arguments to pressure technology companies.
Cyrus R. Vance, the Manhattan district attorney, and William J. Bratton, New York City's police commissioner, have faulted the encryption used by Apple, Facebook and Google for thwarting terrorism investigations.
But to many business executives and some technology experts, their accusations seemed premature, because there was little evidence that encryption had been used in the planning of any attacks.
"It was fairly clear, months ago, that law enforcement was laying the public relations groundwork to blame encryption for whatever happened to go wrong," said Paul Kocher, a cryptographer and president of the Rambus Cryptography Research division, who has called for stronger encryption.  "But in a couple cases, they blamed encryption and got it wrong."
In the case of the attacks in Paris last month, there is still no evidence that the attackers used encrypted messages to plot their attacks.  In fact, a cellphone belonging to one of the attackers suggested that they had communicated using unencrypted text messages.  There is also no evidence that the married couple who waged the attack in a San Bernardino office building last week communicated digitally about the attacks.
Yet it is clear that terrorists are looking for the strongest encryption they can find.  In a technology tutorial produced by the Islamic State militant group that was circulated last January, the group offered its members a guide to encrypted messaging apps, pointing out which it believed were "safest," "safe," "moderately safe" and "unsafe," according to the SITE Intelligence Group, which monitors terrorists' communications.
In the wake of the Paris attacks, Mr. Vance's office published a report asking why Apple could not roll back its latest encryption system, which puts the keys to unlock encrypted iPhone communications on the device itself so that Apple cannot unlock the communications for law enforcement even if presented with a court order.
In the past, Apple could unlock communications under such circumstances, but the current scheme forces law enforcement agents to go directly to their target to read their communications.
But even if Apple rolled back its technology -- which Tim Cook, the company's chief executive, has emphatically insisted will never happen -- it is unclear whether it would make it easier for American law enforcement to track terrorists.
Of the encrypted mobile apps recommended in the Islamic State tutorial, the top five "safest" encryption schemes recommended by the group were made by companies outside the United States -- in places like Switzerland, where a United States court order would not be enforceable.
"We have far more to lose by having our information attacked than gained from weakening everyone's information security," Mr. Kocher said.  He added that rolling back encryption in those products would only drive terrorists to use other products, or create their own.
"You can't delete encryption software off the Internet or delete all the textbooks telling people how to write it," Mr. Kocher said.
David E. Sanger reported from Washington, and Nicole Perlroth from New York.
A version of this article appears in print on December 10, 2015, on page A14 of the New York edition with the headline: F.B.I. Chief Says Gunman Used Encryption to Text Terrorist.

@_date: 2015-12-10 05:15:40
@_author: Henry Baker 
@_subject: [Cryptography] FBI Asks Tech Companies to Reconsider "Their 
FYI --
'Comey said at a Senate Judiciary Committee hearing Wednesday morning, extensive conversations with tech companies have persuaded him that "it's not a technical issue."' ?????
I'm curious as to whom at these 'tech companies' Comey has been speaking with.
Comey Calls on Tech Companies Offering End-to-End Encryption to Reconsider "Their Business Model"
Dan Froomkin
Jenna McLaughlin
FBI Director James Comey on Wednesday called for tech companies currently offering end-to-end encryption to reconsider their business model, and instead adopt encryption techniques that allow them to intercept and turn over communications to law enforcement when necessary.
End-to-end encryption, which is the state of the art in providing secure communications on the internet, has become increasingly common and desirable in the wake of NSA whistleblower Edward Snowden's revelations about mass surveillance by the government.
Comey had previously argued that tech companies could somehow come up with a "solution" that allowed for government access but didn't weaken security.  Tech experts called this a "magic pony" and mocked him for his naivete.
Now, Comey said at a Senate Judiciary Committee hearing Wednesday morning, extensive conversations with tech companies have persuaded him that "it's not a technical issue."
"It is a business model question," he said.  "The question we have to ask is: Should they change their business model?"
Comey's clear implication was that companies that think it's a good business model to offer end-to-end encryption -- or, like Apple, allow users to fully encrypt their iPhones -- should roll those services back.
Comey and other government representatives have been pressuring companies like Apple and Google for many months in public hearings to find a way to provide law enforcement access to decrypted communications whenever there's a lawful request.  Deputy Attorney General Sally Quillian Yates said in a July hearing that some sort of mandate or legislation "may ultimately be necessary" to compel companies to comply, but insisted that wasn't the DOJ's desire.  Now, there's little pussyfooting about it.
"There are plenty of companies today that provide secure services to their customers and still comply with court orders," he said.  "There are plenty of folks who make good phones who are able to unlock them in response to a court order.  In fact, the makers of phones that today can't be unlocked, a year ago they could be unlocked."
Comey indicated that these companies should be satisfied providing customers with encryption that allows for interception by the providers, who can then turn over the information to law enforcement.
Privacy experts say that the same holes in encryption that allow for authorized interception also allow for unauthorized interception -- and therefore provide insufficient security.
Comey called on customers, who he said are becoming more aware of the "dangers" of encryption, to "speak to" phone companies and insist they'll "keep using [their] phones" if they stopped offering the technology.
Comey acknowledged that encrypted apps would still exist.  But, he said, encryption "by default" is the real problem.  He told Sen. Mike Lee, R-Utah, that "I think there's no way we solve this entire problem.    The sophisticated user could still find a way."
That didn't stop him from calling for an international standard for encryption technologies, however.  Many popular encrypted applications are not U.S. based.  Any action imposed on American companies would likely handicap them and lead customers to turn to overseas options.
"We have to remember limits of what we can do legislatively," said Lee.  "If we're going to mandate that legislatively" -- force companies to stop offering strong encryption -- "it wouldn't necessarily fix the problem," he said.
For the first time, Comey made a specific allegation about encryption having interfered with an FBI terror investigation.
"In May, when two terrorists attempted to kill a whole lot of people in Garland, Texas, and were stopped by the action of great local law enforcement  that morning, before one of those terrorists left to try to commit mass murder, he exchanged 109 messages with an overseas terrorist.  We have no idea what he said, because those messages were encrypted."
"That is a big problem," Comey said.
But in the Garland case, the FBI had been tracking one of the would-be attackers for months -- and had alerted local police that he might be headed to a controversial anti-Muslim exhibition.  But FBI surveillance didn't stop Elton Simpson -- the Garland Police Department did.  The local police never got the FBI's email.
Comey did not request specific legislation to compel companies to abandon end-to-end encryption, but told Sen. Dianne Feinstein, D-Calif., that he would like to see all companies responding to lawful requests for data.  Feinstein offered to pursue legislation herself, citing fear that her grandchildren might start communicating with terrorists over encrypted PlayStation systems.
Toward the end of the hearing, Comey seemed to contradict his earlier comments urging companies to reconsider their business models.  "I don't want to tell them how to do their business," he said.  Then, moments later, he added that "there are costs to being an American business -- you can't pollute."  The implication there was that American businesses might need to comply with new standards regardless of what the rest of the world does -- as if providing end-to-end encryption to protect the average person's communications is the same as destroying the environment.
Technologists, privacy advocates, and journalists reacted on Twitter with confusion and frustration.
Contact the author:
Dan Froomkin
dan.froomkin at theintercept.com
Jenna McLaughlin
jenna.mclaughlin at theintercept.com

@_date: 2015-12-10 06:32:52
@_author: Henry Baker 
@_subject: [Cryptography] Save Crypto: Tell the White House We Can't Sacrifice 
FYI --
DECEMBER 8, 2015 | BY RAINEY REITMAN
Save Crypto: Tell the White House We Can't Sacrifice Security
Real Encryption Means Encryption Without Compromises.
Updated 12/9/15
It's a showdown over encryption, and we need your voice.
The Obama administration just responded to the 104,109 people who asked the president to stand up for strong encryption.  The response--penned by Deputy U.S. Chief Technology Officer Ed Felten and Special Assistant to the President and Cybersecurity Coordinator Michael Daniel--acknowledged the importance of the conversation but offered no conclusions.  Instead, they asked us to share our thoughts on encryption.
That means we need the help of Internet users worldwide who care about security.  You can tell the Obama administration exactly what you think about the importance of encryption by filling out this form.
Below are some talking points for why encryption without law enforcement backdoors is important.  We urge you to send these comments to the White House as part of your response to the form:
* Weakening encryption makes us all less secure.  We cannot create a back door, a front door, or any other kind of door for the United States government that cannot be exploited by malicious hackers and other foreign governments.  Security experts agree on this point.
* Forcing American companies to compromise the security of their own products hurts U.S. business interests, creating distrust and uncertainty for consumers who might use American technology.
* Undermining encryption in the United States will primarily affect everyday users who have done nothing wrong.  Bad actors will simply move overseas.
Another option?  You can just paste the original petition into the form.  If the Obama Administration wants to know what we think about encryption, it should refer to the original language signed on by over 100,000 people:
As a public, we should be confident that the services we use haven't been weakened or compromised by government mandate or pressure.  No legislation, executive order, or private agreement with the government should undermine our rights.
Notably, the White House says in their response that "administration officials will sit down with the creators of this petition to hear directly from them about their priorities and concerns."
Unfortunately, that's not true.  EFF set up this petition on the White House petition site.  UPDATE: While there have been several small meetings at the White House involving the many sponsors to the petition, including one this week, EFF was unable to attend this one and it wasn't clear that this was a response to the petition.
In the official response, the president is quoted as saying "There is no scenario in which we don't want really strong encryption."  Make no mistake: in our view, and in the view of an all-star group of cryptographers, "really strong encryption" means encryption made without compromises.  It means encryption without so-called exceptional access capabilities.  It means encryption without backdoors.
But from the way that folks like FBI Director James Comey have been talking, they seem to believe that "really strong encryption" could somehow include weaknesses, mechanisms such as split keys or other forms of key escrow, intentionally inserted to allow law enforcement access.  We need to stand firm with the scientists who have addressed the issue: strong crypto is critical to our safety, and to the security of our communications and stored data.  And what the math tells us is this: no compromises.

@_date: 2015-12-10 06:25:42
@_author: Henry Baker 
@_subject: [Cryptography] White House ducks question of backdoors in encryption 
FYI --
The White House wants you to "Share Your Thoughts on Strong Encryption":
"The administration ... [claims] that it needs more information"
White House ducks question of backdoors in encryption petition response
By Eric Geller
Dec 9, 2015, 11:16am CT
The Obama administration has declined to back robust, uncompromised encryption, ducking the question entirely on Tuesday in its response to a popular petition against weakening security.
With the White House's backing, law enforcement and intelligence officials have been pressuring tech companies to add so-called "backdoors" to their encryption to help police and spies fight crime and terrorism.  Independent experts condemn backdoors as a security and privacy risk, and civil liberties groups have mounted a fierce campaign to prevent their adoption.  That includes a petition on the White House's We The People website, which in October passed 100,000 signatures required to warrant an official response.
"Weakening encryption weakens the entire Internet," the anti-backdoors petition reads.  "Please endorse strong encryption, and encourage other world leaders to do the same."
But the response Tuesday night from Ed Felten, the deputy chief technology officer, and Michael Daniel, President Obama's cybersecurity coordinator, ignored the petition's request.
Instead of endorsing or rejecting strong encryption, the officials asked for more feedback.  "This is a critical conversation, and we want to hear from as many voices as we can," they wrote.  They also promised to meet with the petition's creators this week "to hear directly from them about their priorities and concerns," although the Electronic Frontier Foundation, which posted the petition, said on its blog that it had not been invited to those talks.
To privacy advocates and engineers, the request for more feedback might sound like another stalling tactic.  The administration has avoided staking out an official position on backdoors by claiming that it needs more information.  But the encryption debate has raged for decades, and the fundamental unworkability of backdoors, according to security experts, has not changed since early failed attempts like the "Clipper chip."
Recent terrorist attacks have prompted more politicians and lawmakers to sound the alarm about encryption, following in the footsteps of FBI Director James Comey, who in October 2014 referred to the phenomenon of criminals hiding behind encryption as "going dark."  Congress is planning encryption hearings and could create a special commission to study the role of technology in thwarting terrorism investigations.
"From the way that folks like FBI Director James Comey have been talking, they seem to believe that 'really strong encryption' could somehow include weaknesses, mechanisms such as split keys or other forms of key escrow, intentionally inserted to allow law enforcement access," the EFF said in its blog post.  "We need to stand firm with every single cryptographer who's ever addressed the issue: strong crypto is critical to our safety, and to the security of our communications and stored data.  And what the math tells us is that means no compromises."

@_date: 2015-12-10 06:54:40
@_author: Henry Baker 
@_subject: [Cryptography] Feinstein will seek legislation to 'pierce' 
FYI -- Sources add that the legislation will finally close the 'Heisenberg loophole' and enable the recovery of precise simultaneous position and momentum information from all particles subject to lawful court orders and warrants.
"To this day, I cannot tell you what [the Texas shooter] said with that terrorist, 109 times the morning of that attack.  That is a big problem." -- Comey in 2015.
"To this day, I cannot tell you what [the Texas shooter] was thinking the morning of that attack.  That is a big problem." -- Comey -- now Atty General -- in 2018 -- having a "conversation" about requiring universal chip implants.
Top Democratic senator will seek legislation to 'pierce' through encryption
By Patrick Howell O'Neill
Dec 9, 2015, 10:53am CT | Last updated Dec 9, 2015, 11:42am CT
A leading Democratic senator will seek legislation requiring the ability to "pierce" through encryption to allow American law enforcement to read protected communications with a court order.
Sen. Dianne Feinstein (D-Calif.) told the Senate Judiciary Committee on Wednesday that she would seek a bill that would give police armed with a warrant based on probable cause the ability "to look into an encrypted Web."
"I have concern about a PlayStation that my grandchildren might use," she said, "and a predator getting on the other end, and talking to them, and it's all encrypted.  I think there really is reason to have the ability, with a court order, to be able to get into that."
A spokesman for Feinstein's office told the Daily Dot in an email that the senator has been working with Judiciary Committee Chairman Richard Burr (R-N.C.) the issue of encryption and that Burr's office is taking the lead on potential legislation.
The Federal Bureau of Investigation is actively warning America's biggest technology companies about the "public safety and national security risks" of encryption, according to FBI Director James Comey.
Deadly terrorist attacks in Paris, San Bernardino, California, and elsewhere around the world have reignited a major U.S. debate about encryption.  Feinstein cited Paris as a reason the debate against encryption had evolved so quickly.  Despite these concerns, the attackers in both of Paris  and San Bernardino did not use encryption to organize or execute the deadly strikes, according to authorities.
The lack of evidence showing that encrypted communications played a role in either the Paris attacks, which killed 129 people, or the San Bernardino shooting, which killed 14 people, has not deterred law enforcement, who believe the technology is making their job more difficult and Americans less safe.
Most Internet and gadget users encounter encryption without ever knowing it.  The "HTTPS" connection that allows users to safely buy products on Amazon or access their bank account uses one category of encryption, while newer Apple iOS and Android devices apply strong encryption whenever a user locks her phone "The tech companies and the FBI both care about safety on the Internet," Comey told the Senate Judiciary committee in an FBI oversight hearing.  "We understand that encryption is a very important part of being secure on the Internet.  We also all care about public safety.  We also see a collision course between those two things."
"We see encryption is getting in the way of our ability to have court orders effective to gather information we need in our most important work.  We all agree we have to figure out if we can maximize both those values, safety and security on the Internet and public safety.  We're not at war, we care about the same thing."
Comey said that use of encryption by terrorists and criminals is growing.  He offered one example.
Encryption played a significant role in the killing of two people during a shooting in Garland, Texas, earlier this year, Comey said.  One of the shooters, Comey said, exchanged 109 encrypted messages with an "overseas terrorist." "We have no idea what was said because those messages were encrypted," he explained.  "To this day, I cannot tell you what he said with that terrorist, 109 times the morning of that attack.  That is a big problem."
Comey did not say what kind of encryption software was used in these communications.  However, the fact that Comey knew the shooter spoke to an overseas terrorist means that metadata revealed the extensive communications. Metadata is data surrounding communications that includes phone numbers, times of calls, and identities of callers, or the subject lines of emails.  It's unencrypted and relatively easy for law enforcement to collect.
Over the last two years, Comey has been one of the most prominent figures in the American debate over encryption, increasingly known as the new "Crypto Wars."  He's consistently warned of terrorist and criminal communications "going dark," which he says is a "continuing focus for the FBI."
In response to recent terrorist attacks, President Barack Obama recently said he would "urge high-tech and law enforcement leaders to make it harder to use technology to escape from justice."  Many observers took that to be a comment about encryption.
Comey said on Wednesday that the Obama administration is still not seeking new encryption laws "at this time."  However, conversations are still ongoing.
"We will continue the productive conversations we are having with private industry, state, local, and tribal law enforcement, our foreign partners, and the American people," Comey said.
Senator Mike Lee (R-Utah) issued rare pushback in the debate over encryption, implying that Comey's idea essentially mandates that companies have to build their own "backdoors"--intentional weaknesses in the code--in encrypted products.
Lee added that such a rule wouldn't end the "going dark" problem because foreign companies would not be subject to U.S. law and that individual users could build their own encrypted apps.  Comey agreed, saying any solution to the problem has to be international.
"There's no way we solve this entire problem," Comey said.  "Encryption is always going to be available to the sophisticated user.  The problem is, post-Snowden, it's moved to become default."
Privacy advocates and technologists have long fought against the idea of a legally-mandated "backdoor" into encryption that would give the government the ability to read any encrypted message, with or without a court order.
Objections vary, including that doing so would violate and chill free speech.  Apple CEO Tim Cook, who has become a prominent encryption advocate, argues that any "backdoor" artificially added to encryption can be utilized by any hackers--not just law enforcement--from petty criminals to those backed by countries like China and Russia.
Comey countered that argument on Wednesday, insisting that the encryption debate is "not a technical issue" because "there are plenty of companies today who provide secure services to their customers and still comply with court orders."
The FBI director explained his hopes for the encryption debate by saying that "government doesn't want a backdoor."
Instead, Comey said, "if a judge issues an order, the company figures out how to supply that information to the judge and figures out on its own what would be the best way to do that.  The government shouldn't be telling people how to operate their systems."
When Comey argued that "encryption is part of terrorist tradecraft now," he received a lot of pushback from online observers.
Matt Blaze, a security researcher who testified before Congress on this issue earlier this year, issued a reminder to Comey:
Update 11:41am CT, Dec. 9: Added comment from Feinstein's spokesman.

@_date: 2015-12-11 06:17:56
@_author: Henry Baker 
@_subject: [Cryptography] Obama to clarify his stance on encryption by the 
FYI -- Weakening encryption would allow the Grinch to steal Christmas...  I don't want Santa coming in *either* the back door or the front door; he's only allowed to enter via the chimney.  New crypto characters: Alice, Bob & Eve, meet Grinch & Santa!
Curiously, if you have *Javascript turned off*, dailydot.com rejects access to the following link with a *certificate error* !!
"This Connection is Untrusted
"You have asked [your browser] to connect securely to  but we can't confirm that your connection is secure.
"Normally, when you try to connect securely, sites will present trusted identification to prove that you are going to the right place.  However, this site's identity can't be verified.
"What Should I Do?
"If you usually connect to this site without problems, this error could mean that someone is trying to impersonate the site, and you shouldn't continue."
Obama to clarify his stance on encryption by the holidays
By Eric Geller and William Turton
Dec 10, 2015, 6:22pm CT | Last updated Dec 10, 2015, 7:39pm CT
The Obama administration plans to clarify its stance on strong encryption before Washington shuts down for the holidays.
Administration officials met Thursday with the civil-society groups behind a petition urging the White House to back strong, end-to-end encryption over the objections of some law-enforcement and intelligence professionals.
At that meeting, White House and Department of Homeland Security officials told representatives from the American Civil Liberties Union, Access, the Center for Democracy and Technology, Human Rights Watch, and New America's Open Technology Institute that they were eyeing a holiday deadline for their formal response, according to Kevin Bankston, OTI's director, who helped organize the meeting.
A senior administration official confirmed that an encryption response was forthcoming but did not comment on the deadline.  "The response we posted was an interim one," the official said of the brief reply to the petition, "and we will have a more fulsome response soon."
Bankston called Thursday's discussion "a very hopeful meeting."  He said that the officials present were Michael Daniel, President Obama's cybersecurity coordinator; Ed Felten and Alexander Macgillivray, Obama's deputy chief technology officers; and Daniel Prieto, director of civil liberties and privacy for the National Security Council.
"They were mostly in listening mode," Bankston said, "but they did seem to share our overall goal of moving the discussion beyond the debate over encryption into a more productive conversation about how best to provide for national security in the current technological environment."
As tech companies have improved the security of their products and have begun to offer encryption that even they cannot bypass, national-security officials have complained that those companies are aiding criminals and terrorists by stymying investigations.  These officials want tech companies to add "backdoors" to their encryption that the government could access with a warrant.
FBI Director James Comey, the staunchest advocate for making tech companies modify their products to facilitate investigations, has warned that criminals are "going dark" by encrypting their communications in indecipherable ways.
Security experts overwhelmingly oppose backdoors, which they say would create opportunities for criminals, not just cops, to breach secure systems.
President Obama has not taken a firm stance on backdoors.  He told Re/code in February that "theres no scenario in which we dont want really strong encryption," but he called on tech companies to work with the government to make investigations easier in an Oval Office address on Sunday.  His administration continues to pressure tech companies to make such accommodations.
The White House considered a variety of backdoor policies but ultimately rejected them as unworkable.  Mark Stroh, a White House spokesman, told the Daily Dot in October that "the administration is not seeking legislation at this time."
Bankston hopes that the White House will go further now.  "What we want to hear from the White House is for them to not only continue to hold to their current position--which is that they are not seeking legislation at this time--but have them drop the qualifier of 'at this time.'"
"Our hope," he added, "is that, if they are willing to do that, we can move beyond this seemingly endless debate... and start talking about how can law enforcement and intelligence [agencies] adapt to a world where encryption is common, rather than pretending that we could ever make encryption adapt to law enforcement and intelligence [agencies]."
The debate over whether businesses should weaken their encryption to help the government, known as the "crypto wars," began in the 1990s and took on new life after the Paris terrorist attacks in November and the San Bernardino shooting in December.  Some officials and lawmakers have blamed encryption and called for a policy response, although there is no evidence that the perpetrators of both attacks relied on encryption to evade detection.
"One of our key arguments at this stage," Bankston said, "is simply continuing to highlight--as was true in the '90s... during the original crypto wars, but is even more true now--no matter what U.S. law and U.S. companies do
 strong end-to-end encryption is going to be widely available to anyone who wants it."
Two lawmakers are working on legislation that could outlaw unbreakable encryption.  The White House did not promise to rebuke those attempts, according to Bankston, but it is aware of the problems with such a law.
"At this point, they clearly understand all of our concerns and arguments," he said.  "In fact, many of those concerns and arguments were laid out in the White Houses own memos that were leaked a few months ago." Another participant in the meeting, who asked not to be named, said that the White House "seemed to very clearly understand the security implications of weakening encryption."
"I think the civil society groups broadly shared their concerns... both from a security standpoint and also from a First Amendment standpoint about some of these harms associated with weakening encryption or mandating a backdoor," this person said.  "The meeting participants really stressed that this was an important moment for the White House to be clear about their position."
Civil-society groups hope that their talk launches "a series of meetings of more dialogue between not just us but other stakeholders as well," the participant said.  "The participants in the room seemed to recognize the pressure domestically and globally and the importance of the U.S. to really lead on this issue."
Bankston warned that requiring companies to weaken their encryption, whether through backdoors or other means, would "make us less secure, in terms of our cybersecurity, and also shoot our tech industry in the foot, in terms of its economic competitiveness."

@_date: 2015-12-11 09:03:09
@_author: Henry Baker 
@_subject: [Cryptography] Talk on encryption to non-crypto audience ? 
I'm going to be giving a technical talk on
crypto to non-crypto people.  These are
scientists & engineers, but not computer
scientists or mathematicians.  They recently
heard about quantum computers, mobile
malware, optical fibers, and a future talk
is on 3D printing, so you get the idea.
Any advice and/or reference links for
such a talk ?
I was thinking of a couple of scenarios --
email/SMS and buying something online.  I
thought I'd talk a little about 1x pads &
Diffie Hellman exchange.  Possibly mention
Bitcoin blockchains.
I'm probably going to ignore Rogaway's
advice re no cute pix.
Any suggestions/recommendations ?
Thx in advance.

@_date: 2015-12-12 04:39:11
@_author: Henry Baker 
@_subject: [Cryptography] Talk on encryption to non-crypto audience ? 
Good suggestions re analogies.
Not enough time to do justice to more than a very basic beginning.  I'd rather make sure the audience leaves knowing how a 1x pad really works, than trying to cover too many more topics.  I want them to leave with the takeaway: "Here's a system that *really works*, and I can see why."
I thought I might start with Paul Revere's Ride: "One if by land; Two if by sea".
Show how to encrypt message with 1x pad.  Show how Brits can't tell which message had been sent.
Show how Brits *could* corrupt the message if they knew the format.
I will try to fit in some mention of certs & MITM, because this is a hot topic right now; there is some possibility that Mr. Comey & Mr. Vance themselves might want to be on everybody's short-list of CA's, so that they can MITM everyone -- sort of like Casper the Friendly Ghost.
No time for zero-knowledge or Tor; might mention Tor in passing.

@_date: 2015-12-12 17:52:11
@_author: Henry Baker 
@_subject: [Cryptography] crypto hygiene for keys, pads, et cetera 
Re reuse:
1x pads were designed with pages that could be torn off & destroyed -- e.g., by fire.
Doing the equivalent on a computer would involve having a large number of message-length files of random bytes; pick the "next" file to use for your encryption; use it; then "securely delete" it.
Yes, you are right, the "securely delete" task is essentially impossible for flash memory, except by grinding it to a fine dust.  But flash memory is now insanely cheap...
Generating the large number of message-length files of random bytes is also quite difficult to do correctly, but it can be done.
Soviet agents used 1x pads & were successful until some of the pads were re-used.
1x pads have been successfully used by agents using only pencil-and-paper, prior to the existence of computers.
BTW, I heard on the radio yesterday that the FBI had divers looking for hard drives and/or SD/uSD cards in Lake Seccombe in San Bernardino.  I suspect that the rental car GPS log showed that the car stopped near this lake at a particular point in time.
The KFI (L.A.) radio program indicated that they were looking for a uSD card, which is the size of your pinky fingernail.  The FBI considered draining the lake (it isn't very large -- a couple of city blocks perhaps), but were worried that the mere process of draining would carry away the evidence they were looking for.  This tells me that they were looking for SD cards or smaller, as I would guess that a typical hard drive would sink to the bottom & stay there.  (Does a modern laptop 1.8" hard drive float?  I've never tried it!)
It's conceivable, although unlikely, that the San Bernardino pair may have used a 1x pad.
FBI, ATF Divers Resume Searching Lake In San Bernardino For Digital Evidence

@_date: 2015-12-12 19:06:02
@_author: Henry Baker 
@_subject: [Cryptography] Photon beam splitters for "true" random number 
I'm not a physicist, but I recall from my undergraduate days that one can produce a beam of essentially "pure" linearly polarized light.  Furthermore, if one then splits this linearly polarized beam into two and passes one through another linear polarizer at 45 degrees and the other beam goes through a different linear polarizer also at 45 degrees to the first beam, but 90 degrees to the other polarizer, then each photon that gets through at all, must *randomly choose* whether it will align with the first polarizer or the second polarizer.
We then *detect* these photons by positioning a detector behind the first polarizer and another detector behind the second polarizer.  We call the first detector the "0" detector and the second detector the "1" detector.
It is routine in physics experiments to have photon detectors which can test *coincidence*, whereby one can either *select* or *ignore* detections that happen simultaneously at both detectors.
Let us assume that the original beam of light is fairly *faint*, so that each photon can be individually detected, and we arrange the detectors to *ignore* any simultaneously detected "hits".
Can't such a beam-splitting polarization experiment be utilized to generate "true" random numbers?
Yes, the photons arrive randomly, but if the intensity of the beam is low enough, then the chances of more than one photon arriving at the same time is greatly reduced, and we can throw away any events in which photons simultaneously arrive at both detectors.
Yes, the angle of 45 degrees must be *exact*, else there will be a very slight bias in 0's over 1's or vice versa.
1.  Does such an experiment "work", in the sense that the numbers are truly random?
2.  Can any slight biases from imprecise setup be corrected after the fact -- e.g., by some sort of whitening operation?
The usual physics lab table setup may not be particularly useful for a real product, but I think that such a device could be fabricated out of optical fibers, using a fiber-optic laser source, a more-or-less-standard optical fiber splitter, and off-the-shelf polarizing filters and off-the-shelf detectors.
I don't know how long polarization lasts within a single-mode optical fiber (i.e., how long in meters can a fiber be without upsetting the polarization state), but the whole device could be pretty small, since we're not talking about high power lasers or extremely fast detectors.
Perhaps such a device has already been built & tested?

@_date: 2015-12-13 13:19:07
@_author: Henry Baker 
@_subject: [Cryptography] Photon beam splitters for "true" random number 
mail.com>
Very interesting; ~ $1100 - $3300 for 4Mbits/sec to 16Mbits/sec.
9 hours to fill up a 64GByte USB flash drive @ 16Mbits/sec.
Next question: how in the world could such a device ever be certified not to have a 'quantum insert' from our TAO friends?  The sales of these devices probably number in the tens per month, so purchasing even *one* would raise a flag at GCHQ.
After all, at $1/GB, you could put 3.3TBytes into a $3300 device; how could one ever certify that a device that incorporate 3TBytes was "truly random" ?
Even w/o memory, a microscopic radio receiver could modify the device output to be no longer random, or an undocumented USB command could do the same thing.
And you thought that testing a VW emissions control system was hard!

@_date: 2015-12-13 15:16:47
@_author: Henry Baker 
@_subject: [Cryptography] Photon beam splitters for "true" random number 
Paraphrasing Einstein: Perhaps God's dice are loaded?  ;-)
Perhaps the NSA has compromised QM ?  ;-)
It's a nice slide while talking about random numbers.

@_date: 2015-12-14 08:50:19
@_author: Henry Baker 
@_subject: [Cryptography] Photon beam splitters for "true" random number 
Now you've done it.
First it was the Easter Bunny.  Then it was Santa Claus.
Now the Nevada Gaming Commission.
My world is shattered.
About the only people left whom I can still trust are the NSA & the FBI.

@_date: 2015-12-15 10:10:20
@_author: Henry Baker 
@_subject: [Cryptography] Opponents launch 11th-hour campaign to veto CISA bill 
FYI -- "it's a surveillance bill by another name." -- Senator Ron Wyden
Go to the following web site; they will connect you to a number of people at the White House who are getting irritated by so many calls!
Congress Drops All Pretense: Quietly Turns CISA Into A Full On Surveillance Bill
by Mike Masnick
Tue, Dec 15th 2015 9:28am
Remember CISA?  The "Cybersecurity Information Sharing Act"?  It's getting much much worse as Congress and the administration look to ram it through -- and in the process, removing any pretense that it's not a surveillance bill.
As you may recall, Congress and the White House have been pushing for a "cybersecurity" bill for a few years now, that has never actually been a cybersecurity bill.  Senator Ron Wyden was one of the only people in Congress willing to stand up and directly say what it was: "it's a surveillance bill by another name."  And, by now, you should know that when Senator Wyden says that there's a secret interpretation of a bill that will increase surveillance and is at odds with the public's understanding of a bill, you should know to listen.  He's said so in the past and has been right... multiple times.
Either way, a version of CISA passed the House a while back, with at least some elements of privacy protection included.  Then, a few months ago it passed the Senate in a much weaker state.  The two different versions need to be reconciled, and it's been worked on.  However, as we noted recently, the intelligence community has basically taken over the process and more or less stripped out what few privacy protections there were.
And, the latest is that it's getting worse.  Not only is Congress looking to include it in the end of year omnibus bill -- basically a "must pass" bill -- to make sure it gets passed, but it's clearly dropping all pretense that CISA isn't about surveillance.  Here's what we're hearing from people involved in the latest negotiations.  The latest version of CISA that they're looking to put into the omnibus:
1. Removes the prohibition on information being shared with the NSA, allowing it to be shared directly with NSA (and DOD), rather than first having to go through DHS.  While DHS isn't necessarily wonderful, it's a lot better than NSA.  And, of course, if this were truly about cybersecurity, not surveillance, DHS makes a lot more sense than NSA.
2. Directly removes the restrictions on using this information for "surveillance" activities.  You can't get much more direct than that, right?
3. Removes limitations that government can only use this information for cybersecurity purposes and allows it to be used to go after any other criminal activity as well.  Obviously, this then creates tremendous incentives to push for greater and greater information collection, which clearly will be abused.  We've just seen how the DEA has regularly abused its powers to collect info.  You think agencies like the DEA and others won't make use of CISA too?
4. Removes the requirement to "scrub" personal information unrelated to a cybersecurity threat before sharing that information.  This was the key point that everyone kept making about why the information should go to DHS first -- where DHS would be in charge of this "scrub".  The "scrub" process was a bit exaggerated in the first place, but it was at least something of a privacy protection.  However, it appears that the final version being pushed removes the scrub requirement (along with the requirement to go to DHS) and instead leaves the question of scrubbing to the "discretion" of whichever agency gets the information.  Guess how that's going to go? In short: while before Congress could at least pretend that CISA was about cybersecurity, rather than surveillance, in this mad dash to get it shoved through, they've dropped all pretense and have stripped every last privacy protection, expanded the scope of the bill, and made it quite clear that it's a very broad surveillance bill that can be widely used and abused by all parts of the government.
There is still some hesitation by some as to whether or not this bill belongs in the omnibus bill, or if it should go through the regular process, with a debate and a full vote on this entirely new and different version of CISA.  So, now would be a good time to speak out, letting your elected officials and the White House know that (1) CISA should not be in the omnibus and (2) that we don't need another surveillance bill.
In the meantime, if Congress were actually serious about cybersecurity, they'd be ramping up the acceptance and use of encryption, rather than trying to undermine it.
Opponents launch 11th-hour campaign to kill cyber bill
By Cory Bennett - 12/14/15 03:54 PM EST
Privacy advocates have launched a last-ditch campaign to block a major piece of cybersecurity legislation that could soon be added to an expected omnibus spending deal.
The bill would encourage companies to share more data on hackers with the government.
Fight for the Future, which has been leading a coalition of digital rights and civil liberties groups opposing the measure, on Monday launched an online petition urging the White House to veto the final legislation.  The group also included a widget that allows people to call the White House to express their opposition.
Privacy advocates have long argued that the legislation would allow the intelligence community to collect more private data on Americans.  Technologists and numerous technology companies have expressed similar concerns.
But many industry groups, lawmakers and even the White House counter that the bill is the necessary first step in the fight against hackers.  Privacy provisions in the measure will ensure personal data is not shared throughout the government, they say.
"Now is when we'll find out whether President Obama really cares about the Internet and freedom of speech, or whether he's happy to roll over and allow technologically illiterate members of Congress break the Internet in the name of cybersecurity," said Evan Greer, campaign director at Fight for the Future.
Lawmakers are on the cusp of having a final text ready and hope to have the bill on President Obama's desk before the year's end.
Negotiators have been working since the Senate passed its Intelligence Committee-originated bill in October, six months after the House passed two complementary bills: one from the Intelligence panel, another from Homeland Security.
On Monday, privacy advocates said that lawmakers had decided to attach the bill to an omnibus spending bill that is expected as soon as Monday.  Most observers believe the tactic gives the cyber bill its best shot of getting through Congress in 2015, as only a handful of legislative days remain before the upcoming recess.
But several people with direct knowledge of the talks cautioned that no final decision had been made.
Multiple lawmakers have expressed opposition to the strategy, arguing that the final cyber text should get a standalone vote in both chambers.  Their resistance threatens to kill the omnibus strategy.
If the cyber bill does roll through Congress, Fight for the Future called on the White House to reject the measure.
Throughout the final negotiation process, digital rights groups have warned that lawmakers were omitting the most stringent privacy clauses, a claim the bill's backers reject.
"This administration promised to veto any information sharing bill that did not adequately protect Internet users' privacy, and the final version of this bill doesn't even come close," Greer said.  "It's time for President Obama to deliver on his word."

@_date: 2015-12-16 14:50:14
@_author: Henry Baker 
@_subject: [Cryptography] Satoshi's PGP key. 
Is there any chance that Satoshi works/worked for the
NSA or equivalent?
For a huge number of reasons, s/he couldn't publish
under her/his own name, but may have gotten permission
to do this project anyway, so long as s/he didn't make
any personal profit on it.
I can imagine that the NSA & GCHQ are still hurting
at not getting proper credit for developing "public
key" encryption, and they may not have wanted to see
a long string of bad versions of bitcoins foisted
upon the world when they already had a pretty good

@_date: 2015-12-17 08:47:05
@_author: Henry Baker 
@_subject: [Cryptography] Photon beam splitters for "true" random number 
This can't be true, unless the defn is chosen to make it vacuously true.
For example, even classical 3-body Newtonian gravitation is chaotic in such a way that the future cannot be predicted.  One can set up initial conditions on a 3-body gravitational system in such a way that the ensuing chaos can encode *all of the infinite number of bits* of any given transcendental number, whether or not such number has a finite Turing Machine description (a la Chaitin).
If such a sequence of bits doesn't conform to most peoples' definition of a "random" number, then I don't know what will.

@_date: 2015-12-17 09:47:47
@_author: Henry Baker 
@_subject: [Cryptography] My response to White House re strong encryption 
Arnold's 1999 paper is well worth reading again.  The first 2 paragraphs include:
"According to legend, King Canutes ministers believed so strongly in royal divine authority that, to prove them wrong, the wise monarch marched down to the ocean and commanded the tide to stop coming in.  He got wet feet and the ministers earned a permanent place of honor in the legion of the ridiculous."
"The parallels between Canutes experiment in applied theology and the U.S. governments policy on encryption are becoming more evident each day.  As officials try one approach after another to prevent the spread of strong encryption, its availability only grows."
Apparently, nothing has changed in 16 years !

@_date: 2015-12-17 11:48:55
@_author: Henry Baker 
@_subject: [Cryptography] What should I put in notifications to NSA? 
What is "encryption"?  What is "encryption technology" ?
Is a random number generator (pseudo or true) included within these definitions ?
Does any device that includes XOR qualify?
What about "rsync", which utilizes a hash function ?

@_date: 2015-12-17 14:23:31
@_author: Henry Baker 
@_subject: [Cryptography] What should I put in notifications to NSA? 
Glad to hear it.  Here's some non-encryption software:
 maskn(n) ((1<>4)&0xf])
   format is *hex* only for stdin, stdout. */
   Windows stdin & stdout are not transparent to ^J and ^Z.  */
   b2x  | xmap -a -i123 -n456  | x2b    This will select the subsequence of ,
   starting with 123rd byte and progressing for 456 bytes.
    gets  AND , ,  are all binary files. */
   -o means  gets  OR       (set union)
   -x means  gets  XOR      (set exclusive union)
   -m means  gets  AND NOT  (set difference) */
   "\\\\.\\PhysicalDisk2" and "\\\\.\\F:" */
__int64 _fseeki64( FILE *stream, __int64 offset, int whence )
 {
   long long offsethi = offset & (-512); /* Blocksize = 512 bytes. */
   int offsetlo = offset & 511;
   fflush(stream); /* I don't know why this is required, but it is. */
   int f = _fileno(stream);
   long long retval = _lseeki64( f , offsethi, whence );
   if (retval<0)
     {
       fprintf(stderr,"fseek: failed offsethi=%I64d offsetlo=%d retval=%I64d\n",offsethi,offsetlo,retval);
       return 1;}
   /* We've done the long seek.  Now get to the correct byte. */
   int j,ch;
   for (j=0, ch=fgetc(stream);
        (j=0);
        j++, ch=fgetc(stream));
   if (ch>=0) ungetc(ch,stream);
   /* It seems that retval == offset unless there is an error. */
   return ((ch>=0) && (retval>=0)) ? 0 : 1;
 }
int main(int argc, char *argv[])
  int opt; /* for handling command line options */
  int operation='x'; /* the actual binary operation */
  long long i; /* Used to count # bytes processed. */
  const int linemask=maskn(5); /* linelength of 64. */
  long long initial=0;
  long long length=-1;
  int ch1,ch2,ch3; /* The bytes from file1, file2, file3. */
  char hex1[4]="FF";
  char table[256]; /* Character table */
  const char hextable[16]="0123456789ABCDEF";
  FILE *fp;    /* file1=stdin, file2=fp. */
  /* Initialize character table. */
  for (i=0;i<256;i++) table[i]=255;
  for (i='0';i<='9';i++) table[i]=i-'0';
  for (i='a';i<='f';i++) table[i]=i-'a'+10;
  for (i='A';i<='F';i++) table[i]=i-'A'+10;
  while ((opt=getopt(argc,argv,"ahi:mn:ox"))!=-1)
    switch (opt)
      {
      case 'a': operation='a'; break; /* AND */
      case 'o': operation='o'; break; /* OR */
      case 'm': operation='m'; break; /* SET MINUS = AND NOT */
      case 'x': operation='x'; break; /* XOR */
      case 'i': sscanf(optarg,"%I64d",&initial); break;
      case 'n': sscanf(optarg,"%I64d",&length); break;
      case 'h':
      case '?':
        fprintf(stderr,"\nUsage:\nxmap {-a -m -o -x} -i -n file\n");
      default:
        return 1;
      }
  if ((argc-1) != optind) {fprintf(stderr,"xmap: wrong # of args: %d\n",argc-1); return 1;}
  if ((fp=fopen(argv[optind],"rb"))==NULL)
    {fprintf(stderr,"xmap: bad file arg: %s\n",argv[optind]); return 1;}
  if (_fseeki64(fp,initial,SEEK_SET))
    {fprintf(stderr,"b2x: error fseek to position %I64d\n",initial); return 1;}
  /* Skip over non-hex characters. */
  for (ch1=fgetc(stdin); !feof(stdin) && !inhex(ch1); ch1=fgetc(stdin));
  ungetc(ch1,stdin);
  /* map stdin operation fp; shortest file wins. */
  for (hex1[0]=fgetc(stdin),ch2=fgetc(fp),i=0;
       (!feof(stdin)) && (!feof(fp)) && ((i<length) || (length<0));
       hex1[0]=fgetc(stdin),ch2=fgetc(fp))
    { if (feof(stdin)) break; hex1[1]=fgetc(stdin);
      if ((i&linemask)==0) fprintf(stdout,"\n");
      ch1=hex2bin(hex1[0],hex1[1]);
      switch (operation)
        {
        case 'a': ch3=ch1&ch2 break;
        case 'm': ch3=ch1&(~ch2); break;
        case 'o': ch3=ch1|ch2; break;
        case 'x': ch3=ch1^ch2; break;
        default: fprintf(stderr,"xmap: bad binop: %c\n",operation); return 1;
        }
      fputc(hexhi(ch3),stdout); fputc(hexlo(ch3),stdout); i++;
      for (ch1=fgetc(stdin); !feof(stdin) && !inhex(ch1); ch1=fgetc(stdin));
      if (feof(stdin)) break; ungetc(ch1,stdin);}
  if (i&linemask) fprintf(stdout,"\n");
  fclose(fp); fclose(stdin); fclose(stdout);
  fprintf(stderr,"xmap: bytes processed: %d\n",(int) i);
  return 0;}

@_date: 2015-12-17 15:20:39
@_author: Henry Baker 
@_subject: [Cryptography] What should I put in notifications to NSA? 
I use long bit-strings all the time for lots of things, including to represent sets.
Long bit-strings are also useful for data "striping" (think RAID), in order to achieve redundancy and resilience to errors and HW/SW failures.
I have no intention of "messing with someone".

@_date: 2015-12-18 07:48:03
@_author: Henry Baker 
@_subject: [Cryptography] Terror fears don't budge Obama on encryption 
FYI -- I would place "politico.com" more in the anti-encryption camp than not.  Still no signs of intelligence in the press corps; these guys are just as clueless as the politicians that they cover.
Terror fears don't budge Obama on encryption
The White House has sided with privacy groups despite law enforcement warnings about terrorists "going dark."  And Congress is unlikely to act soon to change federal policy either.
By David Perera
12/17/15 08:35 PM EST
Updated 12/17/15 09:42 PM EST
President Barack Obama's FBI director says encrypted smartphones and online messaging systems are making it harder to prevent terror attacks such as the slaughter in Paris and San Bernardino, California.  His CIA chief echoes the concern.  And so does the Senate Intelligence Committee's top Democrat, who warns that "evil monsters" are using the technology to communicate without fear of detection.
But the White House is resisting calls to revisit a decision it made in October, when it sided with privacy advocates and cybersecurity experts who warned against forcing technology companies to weaken the electronic safeguards they offer on products like the iPhone and social media sites like Facebook.  The Obama administration shows every sign of sticking with that stance, which followed a debate influenced by technical obstacles, Silicon Valley's political muscle and miscues by national security officials -- as well as doubts that making it easier to unscramble consumers' communications --would do much to aid the fight against terrorism.
Congress is also unlikely to rewrite federal encryption policy anytime soon, thanks to divisions among lawmakers about the balance between privacy and security, even though Senate Majority Leader Mitch McConnell, the chairmen of the Senate intelligence and armed services committees and some prominent Democrats suggest Obama should change course.
"I just don't think it's going to happen" said former Rep. Mike Rogers (R-Mich.), an advocate of encryption limits who headed the House Intelligence Committee until January.  "I am not optimistic we're going to get anything."
Rep. Jim Langevin, a Rhode Island Democrat and co-chair of the House Cybersecurity Caucus, agreed.  "I don't believe there's any appetite in Congress right now, just broadly speaking, for taking up that type of legislation," he said.  "There's no broad agreement, no readily apparent solution."
The upshot: Even after the murders of 130 people in the French capital and 14 more deaths in California, as fears of domestic terrorism reach the highest level since the attacks of Sept. 11, 2001, a more-than-two-decade clash between privacy concerns and the government's surveillance powers remains stalemated.  The absence of action on encryption comes despite lawmakers' rapid moves to block Syrian refugees and tighten visa requirements after the recent attacks.
Police and intelligence officials find this state of affairs alarming.  FBI Director James Comey told senators last week that "the use of encryption is part of terrorist tradecraft now," while New York Police Commissioner Bill Bratton warns that the authorities have "gone blind."
But even some critics of widespread encryption aren't sure a simple solution exists.
"Initially, lawmakers thought there was an easy legislative fix ... until we found out that providing a back door into everyone's iPhone was not going to be a very good strategy," said Rep. Mike McCaul (R-Texas), chairman of the Homeland Security Committee.
The White House has offered no new legislative proposal to unscramble encoded communications following the attacks in France and California, and it isn't planning any, a senior administration official confirmed.
Investigators haven't offered any evidence that encryption played a significant role in plotting or executing the Paris or San Bernardino attacks, despite news reports indicating that some of the Paris attackers had used encrypted apps on their cellphones.  (Those terrorists had also used unencrypted text messages to communicate.)  But the proliferation of encryption tools available to ordinary consumers has sparked escalating anxiety among law enforcement professionals.
One reason for the disquiet: Even when armed with a warrant, the authorities cannot read the texts, photos and contacts stored in the latest Apple and Google smartphones, thanks to encryption tools that even the companies who developed them say they cannot crack.  Tech companies have also resisted suggestions that they weaken encryption, either by building in "back doors" that government agencies could access or by retaining the ability to unscramble the messages themselves.
Tech companies defend these tools partly as protections for consumers against hackers and cybercriminals.  But the results have been dire for law enforcement, said Manhattan District Attorney Cyrus Vance, who says prosecutors in New York City had 111 warrants rendered useless by such encryption since September 2014 in cases involving alleged murders, sex trafficking, assault and robbery.  "It's hard to overstate the impact on our ability to conduct criminal investigations," he said on Nov. 18.
One former federal prosecutor offered an even starker warning.  "I don't know how many dead people it's going to take for people to wake up and realize that you can't not have access to these devices," the ex-prosecutor said.  "Slowly but surely, these communications are going dark to law enforcement and you're just going to end up with more and more and more bodies in the street."
Cybersecurity and privacy advocates scoff at such claims, arguing that the authorities have never had more tools available for tracking people in what some label a golden age of surveillance.  "You have to take intelligence officials' statements with a certain grain of salt, given that the more loudly that they're proclaiming that the users are using encryption, the more loudly they're saying, 'Don't throw me into the briar patch,'" said Matt Blaze, a University of Pennsylvania computer scientist who in 1994 discovered flaws in a proposed federal backdoor scheme.
Indeed, privacy advocates worry that the Obama administration will eventually cave in and weaken consumers' electronic safeguards amid intensifying fears of another terror attack.  A coalition of privacy groups met with White House officials last week to urge the president to affirm his support for encryption.
Fears of cybercrime led developers in recent years to start encrypting text, a push aided by the move to increasingly powerful and ubiquitous mobile devices.  Consumer demand for greater electronic privacy also mushroomed in 2013 after former National Security Agency contractor Edward Snowden revealed the agency's massive global surveillance program.
Not everyone on Capitol Hill is giving up on Congress jumping into the debate: The chairmen of the Senate intelligence and armed services committees both promise legislation, and McConnell told a POLITICO breakfast on Tuesday that lawmakers may revisit the issue next year.  "I think we can't put blinders on here," the Kentucky Republican told POLITICO's Mike Allen.  "This is a growing and serious problem."
Yet Silicon Valley's best and brightest insist there is no technological fix for encryption that wouldn't leave consumers vulnerable, and that any attempt to design in a back door for police and intelligence agencies would inevitably be used by hackers and criminals.  'If you put a key under the mat for the cops, a burglar can find it, too,' Apple CEO Tim Cook said in June.
Some of the biggest corporate stars of the U.S. technology industry, such as Apple, Google and Cisco, also fear that overseas customers will shun their products if they include weak encryption mandated by the U.S. government.  Surrendering to government demands "would not be good for our business," said Matthew Prince, CEO of CloudFlare, a San Francisco-based Internet infrastructure company.  About half of the company's $100 million annual revenue comes from foreign customers, who might buy elsewhere if they knew the U.S. government could monitor them.
"It's obvious why there's not political will to do it," said Stewart Baker, a former National Security Agency official.  "Industry has lined up very aggressively against it."
Even if police and intelligence agencies secured a way into American encryption systems, terrorists could still shield their communications using applications from companies beyond the reach of U.S. law.  A security guide that the Islamic State uses to educate recruits advises using applications such as Berlin, Germany-based Telegram, whose website boasts that its "messages are heavily encrypted and can self-destruct," rather than products from U.S. companies such as Facebook.  Telegram was one of the apps that investigators found on the phones of the terrorists who committed the Nov. 13 bombing and shooting attacks in Paris, CNN reported Thursday.
Two years after Snowden's NSA revelations, the political climate also remains hostile to expanding government surveillance programs.  The Obama administration earlier this year sided with privacy advocates and the technology industry in writing into law new restrictions on NSA record-gathering.  "We're still in that hangover," Rogers said.  "They're always going to err on the side of the privacy groups."
Law enforcement and intelligence officials pushing for a policy change also have done themselves no favors with their approach.  After warning in 2014 that encryption was hamstringing the FBI, Comey launched a yearlong campaign to persuade Congress to act.  Even after being warned off earlier this year by the White House, FBI officials continued meeting with lawmakers and congressional staffers, according to a former White House official.
"They were pushing hard," said a tech industry lobbyist, who said the effort continued until October, when the White House ruled out new encryption legislation.  Administration officials have said since then that they're continuing to talk to technology companies about how to cooperate in fighting extremism.
The tech lobbyist said the FBI failed to make a compelling case for its back-door proposals.  The bureau couldn't point to a "specific example where a back door was the only way to get information," especially given the richness of digital information sources in an always-connected world.  FBI officials also were vague on what alternative encryption schemes they'd favor, said observers.
Though the FBI refrained from floating any draft legislation, multiple sources said bureau officials suggested they would welcome revisions to the 1994 Communications Assistance for Law Enforcement Act.  That law, which requires the telecommunications industry to build wiretap access into its systems, is silent about online communications software.
Opening up CALEA "would be a very difficult thing to do," said McCaul, predicting a firestorm over efforts to compromise consumers' smartphone security.
The lack of a specific proposal from Comey left some frustrated.  "When you ask specifically what the technology is, he says: 'We should have a conversation about that,'" said Ari Schwartz, until October the top White House cybersecurity policy adviser.  "You tell me -- what does the FBI actually want the tech companies to do?"
In recent days, Comey has floated a new answer, arguing that the encryption dilemma is "a business model question" rather than a technological puzzle.
The FBI refused to clarify what Comey meant in last week's Senate Judiciary Committee testimony, though industry executives interpret it as a suggestion to abandon the "end-to-end" encryption that only consumers can unscramble.  That's the encryption found on newer models of the iPhone and on some Android smartphones, the reason why Apple tells law enforcement it can't unlock suspected criminals' devices.
For all the official warnings, it's not yet clear how much of a handicap encryption has been.
Comey said earlier this month that one of the shooters who wounded a security guard in May at a Prophet Muhammad cartoon contest in Garland, Texas, had sent 109 encrypted texts to "an overseas terrorist" the morning of the attack.  But the Paris attackers used unencrypted channels including text messages at least part of the time, and suspected San Bernardino shooter Tashfeen Malik reportedly expressed her support for the Islamic State on Facebook.
"Some in this debate seem to be looking for the next tragedy to jump on to prove their case whether the facts fit or not," Schwartz said.
On Capitol Hill, meanwhile, McCaul has fallen back on a standard Washington remedy.  Last week, he called for a new government commission composed of technology specialists, law enforcement officials and privacy advocates to develop a solution.
For now, lawmakers' final word on the issue remains a House vote in June that approved a bipartisan amendment to a defense spending bill that prohibited spy agencies from seeking back doors in digital products.  The vote was 255-174.
David Perera
    dperera at politico.com

@_date: 2015-12-18 15:42:31
@_author: Henry Baker 
@_subject: [Cryptography] Quantum key distribution hacked! 
FYI -- Oops!!  The vorpal blade went snicker-snack!  Oh, what a(n) (en)tangled web we weave
When first we practise to deceive!
PUBLIC RELEASE: 18-DEC-2015
Swedish researchers reveal security hole
Hacking the Bell Test using classical light in energy-time entanglement-based quantum key distribution
LINKPING UNIVERSITY
Quantum cryptography is considered a fully secure encryption method, but researchers from Linkping University and Stockholm University have discovered that this is not always the case.  They found that energy-time entanglement - the method that today forms the basis for many systems of quantum cryptography - is vulnerable to attack.  The results of their research have been published in Science Advances.
"With this security hole, it's possible to eavesdrop on traffic without being detected.  We discovered this in our theoretical calculations, and our colleagues in Stockholm were subsequently able to demonstrate it experimentally," says Jan-ke Larsson, professor at Linkping University's Division of Information Coding.
Quantum cryptography is considered a completely safe method for information transfer, and theoretically it should be impossible to crack.  Many research groups around the world are working to make quantum cryptography resistant to various types of disturbance, and so far it has been possible to handle the disturbance that has been detected.  Quantum cryptography technology is commercially available, but there is much doubt as to whether it is actually used.
"It's mostly rumours, I haven't seen any system in use.  But I know that some universities have test networks for secure data transfer," says Prof Larsson.
The energy-time entanglement technology for quantum encryption studied here is based on testing the connection at the same time as the encryption key is created.  Two photons are sent out at exactly the same time in different directions.  At both ends of the connection is an interferometer where a small phase shift is added.  This provides the interference that is used to compare similarities in the data from the two stations.  If the photon stream is being eavesdropped there will be noise, and this can be revealed using a theorem from quantum mechanics - Bell's inequality.
On the other hand if the connection is secure and free from noise, you can use the remaining data, or photons, as an encryption key to protect your message.
What the LiU researchers Jan-ke Larsson and his doctoral student Jonathan Jogenfors have revealed about energy-time entanglement is that if the photon source is replaced with a traditional light source, an eavesdropper can identify the key, the code string.  Consequently they can also read the message without detection.  The security test, which is based on Bell's inequality, does not react - even though an attack is underway.
Physicists at Stockholm University have subsequently been able to demonstrate in practical experiments that it is perfectly possible to replace the light source and thus also eavesdrop on the message.
But this problem can also be solved.
"In the article we propose a number of countermeasures, from simple technical solutions to rebuilding the entire machine," said Jonathan Jogenfors.
The article has been published in Science Advances, a highly respected journal with open access.
Jan-ke Larsson, professor
jan-ake.larsson at liu.se

@_date: 2015-12-19 11:22:07
@_author: Henry Baker 
@_subject: [Cryptography] Questions about crypto that lay people want to 
In gathering material for a crypto talk to
laypersons, I've been trying to collect a
number of questions that such laypersons
would like to know the answers to.
This talk is about the fundamental ideas
of crypto, and not addressing details of
HTTPS, so it's not a grown-up version of
a "crypto party".
I have my own ideas for answers to some
of these questions, but I'd be curious as
to what others on this list think.
BTW, some of these questions will stump
the best experts, but people will ask
[These questions are in no particular
* Ordinary citizens lived thousands of
years in sophisticated societies and
never needed clever crypto.  I don't
recall any crypto in the Bible, and the
only discussion of crypto in novels
seems to occur in the context of war
or high politics -- e.g., Queen Mary
of Scots.
Why now?  What is it about modern
society that seems to require crypto
for us ordinary citizens?
* We just had a crypto war in the
1990's, and everyone thought the
problem was solved.  Why are we
having another crypto war 20 years
later?  Is this a generational
phenomenon?  Or is this a periodic
cicada phenomenon?  Will there be
a quantum crypto war in 2035 ?
* Why the intimate connection
between crypto and randomness?
This connection seems very odd,
since encrypted text must be
capable of being *decrypted* back
into plaintext, and therefore
even seemingly random ciphertext
must have significant structure.
* SW/HW engineers and crypto
folks both use the word "code" to
indicate that some additional
structure has been added to
ordinary ASCII text in order to
achieve certain goals -- e.g.,
error detection, error correction,
confidentiality, integrity.  Are
these uses of "code" indicative
of any deeper relationship between
the different fields?
* What is the relationship
between the "key" in my pocket
and a crypto "key" ?
* Crypto techniques seem to
involve *cycles* -- e.g. modular
arithmetic, etc.  Why do cyclic
and circular things keep showing
up in crypto ?
* (For the physicist/EE.) What
is the relationship between
"information" in "information
theory" and "quantum theory" ?
Why the complete disconnect
between the quantum world and
information theory/crypto ?
* Why are some things hard to
compute?  Can't we just get
the cleverest people from MIT,
Stanford, (insert your favorite
here) to work on this?  If we
can build an H-bomb, make it
to the Moon and back, and
translate languages (thank
you, Google!), what's the
matter with you guys?
* If HTTPS is good enough for
my bank account, how come I
can't use it to vote?  Why
do I have to vote in person?
* Speaking of banking, will
digital currency replace
paper money?
* What is "strong" crypto?
Some products say that they
use "government quality"
crypto.  Will I be twice as
safe with 2048-bit keys as
with 1024-bit keys?

@_date: 2015-12-20 09:20:09
@_author: Henry Baker 
@_subject: [Cryptography] Hillary on encryption: 'maybe the back door isn't 
FYI --
Perhaps C&W songs may have the last word(s), after all:
[Tim Cook's song ?]
  There's no use lying
  'Cause I've heard all your bullshit before
  You've said your old line
  For the very last time
  I don't want you 'round my back door
[James Comey's song ?]
  Front door's shut
  Back door too
  Blind's pulled down
  What you gonna do
Hillary Clinton on encryption: 'maybe the back door isn't the right door'
By T.C. Sottek on December 19, 2015 10:16 pm  Democrats have strange ideas about the internet, too.  At tonight's ABC News presidential debate, candidates offered a number of vague, borderline-illiterate thoughts about technology, especially Hillary Clinton.  It all started when ABC gave her an inane prompt, characterizing encryption as a "terrorist tool used in the Paris attacks."  In response, Clinton suggested that, instead of breaking encryption, the US should launch a "Manhattan-like project" to "bring the government and tech communities together" so that law enforcement can "prevent attacks."
"Maybe the back door isn't the right door, and I understand what Apple and others are saying about that," Clinton said.  "I just think there's got to be a way, and I would hope that our tech companies would work with government to figure that out."  None of that makes any sense, of course.  Figure out a way to do what?  Breach fully encrypted communications?  (That's called a backdoor.)  Improve information sharing between industry and government?  (We already have PRISM and CISA.)  Clinton's non-answer here is essentially Trumpian: don't worry about the details, the experts will figure it out.
"It doesn't do anybody any good if terrorists can move toward encrypted communication that no law enforcement agency can break into before or after," Clinton said.  "There must be some way.  I don't know enough about the technology to be able to say what it is, but I have a lot of confidence in our tech experts."
    Aaaaaaaaand Hillary just terrified everyone with an internet connection.     -- Edward Snowden ( December 20, 2015 Her opponents on stage didn't do any better.  Martin O'Malley, former governor of Maryland and current Stepford Husband, delivered a vague meditation on... something.  At least it was folksy.  "We need to figure this out together," O'Malley said.  "The way things work in the modern era is actually to gather around a table and figure things out.  With the new technologies, I believe the people creating these products have an obligation to come together with law enforcement to figure these things out." Go ahead and gather around your surveillance table, Mr. O'Malley -- you'll find many of your Republican opponents there.  Just make sure whoever you invite to sit there gets a warrant.

@_date: 2015-12-21 06:13:57
@_author: Henry Baker 
@_subject: [Cryptography] Banking app security still sucks 
FYI -- I can't wait for the hand-wringing to begin after the next big bank breach...
"Five of the 40 audited apps failed to validate the authenticity of the SSL certificates presented, which makes them susceptible to Man-in-The-Middle (MiTM) attacks"
"30 per cent of [the apps] failed to validate incoming data"
"15 per cent of the apps store unencrypted and sensitive information"
"The world will therefore have to bumble along with known-to-be imperfect encryption for *two years* longer than planned"
Security industry too busy improving security to do security right
PCI Council delays SSL abandonment date to 2018, so cruddy credit crypto continues
iOS banking apps security still not good enough, says researcher
Repeat test throws up improved results from 2013 but problems remain
18 Dec 2015 at 15:14, John Leyden
The security of mobile banking apps has improved over the last two years but there's still scope for improvement.
Ariel Sanchez, security consultant for IOActive, has revisited research into the topic first conducted two years ago to see if there's been any improvement.
Although security has increased over the two years, many apps still remain vulnerable.
As before, the research covered 40 mobile banking apps for iOS in use around the world.  Sanchez confined himself to looking for client side security weaknesses or vulnerabilities and didn't include any server-side testing.
His testing methodology is explained in much more detail in a blog post here.  iOS does not name the apps or the banks who released the apps it tested.
Five of the 40 audited apps failed to validate the authenticity of the SSL certificates presented, which makes them susceptible to Man-in-The-Middle (MiTM) attacks.  And more than a third (35 per cent) of the apps contained non-SSL links throughout the application.  This shortcoming would allow an attacker to intercept traffic and inject arbitrary JavaScript/HTML code in an attempt to create a fake login prompt or attempt similar scams.
In addition 30 per cent of them failed to validate incoming data, leaving them potentially vulnerable to JavaScript injections.  The results may not appear impressive but at least they are an improvement on results from 2013.
The testing also covered binary and file system analysis.  This phase of the audit revealed that 15 per cent of the apps store unencrypted and sensitive information, such as details about customers' banking accounts and transaction history, in the file system via sqlite databases or other plaintext files.
"Most of the apps have increased transport security of the data by properly validating SSL certificates or removing plaintext traffic," Sanchez concluded.  "This helps mitigate the risk of users being exposed to MiTM attacks."
"Although the numbers are down overall, there are still a high number of apps storing insecure data in their file system.  Many of them are still susceptible to client-side attacks," he added.
Sanchez added that few of apps provide alternative authentication solutions, with most relying simply on username and password for authentication.  Only 17 of the 40 (42.5 per cent) of the apps provided alternative authentication solutions to mitigate the risk of leaking user credentials and impersonal attacks.
Security industry too busy improving security to do security right
PCI Council delays SSL abandonment date to 2018, so cruddy credit crypto continues
21 Dec 2015 at 01:01, Simon Sharwood
The Payment Card Industry Security Standards Council (PCI SSC) has decided to delay the deadline for migration from Secure Sockets Layer (SSL) to Transport Layer Security (TLS).
Earlier this year, the Council decided the time to make the change was June 2016, a reasonable idea given that SSL gave the world the Poodle vulnerability.
Now the Council says it's just too hard for retailers to make the jump.
The canned statement (PDF) about the moratorium, issued deep into Friday US time, features the Council's general manager Stephen Orfei saying migration was expected to be simple, "but in the field a lot of business issues surfaced as we continued dialog with merchants, payment processors and banks."
Orfei laid some of the blame at the feet of mobile devices, saying that retailers' efforts to secure transactions made on smartphones and fondleslabs, on top of "encryption, the SHA-1 browser upgrade and EMV in the US" together make for so much work that the SSL death deadline can't be met.
"We're working very hard with representatives from every part of the ecosystem to make sure it happens as before the bad guys break in," Orfei says.
The world will therefore have to bumble along with known-to-be imperfect encryption for two years longer than planned, a period during which The Register imagines "the bad guys" will do their very best take advantage of weak encryption.
The new migration deadline will be formalised in the next version of the PCI DSS standard, due in April 2016.

@_date: 2015-12-21 18:18:51
@_author: Henry Baker 
@_subject: [Cryptography] Questions about crypto that lay people want to 
Here are some of my thoughts on this
Prior to the invention of *radio*, the
use of cryptography was sporadic even
among govts.  I believe that the U.S.
diplomatic corps didn't bother with
cryptography until WWI, for example.
Governments -- especially *navies* --
quickly adopted *long range radios*
in the era before and during WWI.
Indeed, the US govt nationalized the
whole U.S. radio industry in WWI and
seized all of its patents (thank you,
Assistant Secretary of the Navy,
Franklin D. Roosevelt); the Radio
Corporation of America (RCA) was
formed after WWI to re-privatize
these assets.
The problem with long distance radio,
of course, was that it was *long
distance*, and highly *undirectional*.
As a result, these signals could be
heard over significant fractions of
the globe.  It quickly became obvious
that unencrypted radio signals were
too inexpensively eavesdropped upon.
So radio was the impetus for the
rapid adoption of encryption for
govts in the 20th Century.
But for nearly identical reasons,
*radio* once again became the impetus
for the widespread adoption of
encryption with the adoption of
the ubiquitous radio-based cellphone
by ordinary consumers.
Yes, there was a certain amount of
consumer-level encryption of computer
communications prior to the widespread
adoption of cellphones, but it was
limited to "Johnnies who *could*
encrypt" rather than the unwashed
Most ordinary citizens believed in
the "series of tubes" model of the
Internet, in which all of *their*
communications were narrowly
confined to *secure* tubes -- mostly
telephone lines containing modem
traffic -- and therefore protected
from universal snooping by *warrants*.
The universal consumer adoption of
another *radio* technology -- WiFi --
also heralded the need for encryption
in the form of WEP, and then WPA and
WPA-2, but *only after attacks were
also brought to the consumer level,
and only after massive data thefts
over WiFi from cars parked in company
parking lots.*
Then all hell broke loose with the
revelations of Edward Snowden that
the "series of tubes" of the Internet
was *completely compromised* not only
in the U.S., but almost *everywhere*
around the world.  Not only were
these "tubes" made of incredibly
transparent glass, but *everything*
going through them was subjected to
ubiquitous surveillance.
Of course, many geeks had always
assumed as much, but they were
laughed off as "tinfoil hat" types.
No longer.  When the NYTimes says
on its front page that the NSA was
"collecting it all", the sales of
tinfoil hats (and Guy Fawkes masks) So *radio*, and "radio-like" networks
in which traffic between points A
and B could be routed via waypoints
located almost anywhere on Earth.
Those bits flowing out of your
computer and cellphone could be
going anywhere on Earth, and those
bits flowing into your computer and
cellphone could have gone via
anywhere on Earth.
Envelopes and sealing wax be damned.
The NSA+friends built a machine
that outperformed the fabulous East
German envelope-steaming machine by
factors of millions and billions.
Of course, transparent tubes are
also transparent to corporations and
criminals (I hope I'm not repeating
myself).  So individual citizens are
under ubiquitous surveillance for
the first time in evolutionary
history.  Humans have not had time
to develop any natural defenses
against this new threat model, so
it will take some time to work out.
The Internet has also been *weaponized*,
complete with (I'm not making this up)
a "cyber command" (USCYBERCOM) run by
an *admiral*.  There is an active war
being waged in "cyberspace" whose
bullets are hitting our computers
and cellphones hundreds and thousands
of times per minute.
One of the major battlegrounds in
this "cyber" war is *your pocket*. Govts and criminals are *in your
pocket* right now, trying to
infiltrate your cellphone and steal
its secrets.  Many/most of the
messages headed for the cellphone
in *your pocket* are either outright
missiles which can compromise your
cellphone directly, or are *phishing*
messages, which attempt to get you to
lower your defenses long enough to
allow them to compromise your
Your *only* defense right now is
*encryption*, and it has to be very
strong encryption because the attacks
are coming from nation-states and
well-heeled criminals.
The defensive walls built by encryption
within your cellphone are only a
millionth of an inch thick.  Even the
slightest error in design or manufacture
of these walls will completely compromise
your data.
Apple CEO Tim Cook is absolutely right
when he argues for the strongest
possible encryption of your data.  Your
cellphone is the battleground in a hot
war whose combatants have resources as
big (or bigger) than Apple itself.
We -- the ordinary citizens -- have no
hope without significant help from our
vendors such as Apple.

@_date: 2015-12-22 08:05:42
@_author: Henry Baker 
@_subject: [Cryptography] Juniper & Dual_EC_DRBG 
I'm seeing hands in cookie jars... Also,
The louder he talked of his honor, the faster we counted our spoons...
'The U.S. officials said they are certain U.S. spy agencies themselves aren't behind the back door'
'... because of the sophistication involved'  ;-)
Newly discovered hack has U.S. fearing foreign infiltration

@_date: 2015-12-23 16:25:42
@_author: Henry Baker 
@_subject: [Cryptography] Juniper & Dual_EC_DRBG: Why Now? 
I'm seeing hands in cookie jars... Also,
OK, I've tried to read all the reports & blogs about this to get some sense of what's happening here.
The best question of all: "why NOW?"
This dog has been sleeping for years; what woke him up?
My best guess: politics.  Due to the looming possibility of Congress *requiring* back doors, someone at the NSA finally woke up & realized that backdoors for Comey & Vance would put the US more at risk than any possible advantage in intelligence.  Another OPM caused by such a backdoor would get someone high up in the NSA fired -- even if it needed to happen in private.
In fact, just recently, a number of retired intel folks have said as much, but Congress & the Chicken Little prez candidates hasn't been listening.
(It also helps that the open crypto & security communities were fast closing in on this EC B.S.; make lemonade out of lemons by preemptively being the "good guy" here.)
So, whether NSA put the back door into Juniper or not, the NSA *knew about its existence* -- possibly by monitoring whomever else *did* know about it -- and so the NSA could easily cause this bug to get disclosed & hence fixed.
The NSA could always claim that the "just now found out about it", and was acting like the good guy by getting it fixed.  It never has to acknowledge that it may have been using this vuln itself for years.

@_date: 2015-12-24 04:29:48
@_author: Henry Baker 
@_subject: [Cryptography] A different twist on the constitutionality of 
mail.com>
Bingo!  That's called "Catch 22", and Catch-22 is as firmly embedded in American culture today as the Constitution itself.
I personally think that the Second Amendment and the Fifth Amendment support the right to confidentiality, but you have to first understand the broader principles that these Amendments were trying to address rather than appeal to the particular language of those Amendments.
(Physical) armor has traditionally been considered a (defensive) *weapon*.  But unlike guns, it's hard to work up much passion for or against armor; you won't see headlines where someone mows down 30 people with his *armor*.
The last time I've seen people get worked up over armor was the 1997 bank robbery in Los Angeles where police handguns were useless against the fully-armored pair of bank robbers.  After that incident, some legislators tried to restrict non-police access to body armor.  I seem to recall that there may still be *export restrictions* on body armor today.
If the Second Amendment protects the right to offensive *weapons*, which can be actively used to *kill people*, then certainly the Second Amendment protects the right to *defensive* armor, which merely protects the wearer against someone else's Second Amendment weapon.  In fact, as a matter of public policy, it would be far preferable that everyone should wear body armor, rather than carry guns.
The Second Amendment has been used to allow citizens to protect themselves against criminals; surely the Second Amendment would allow people to protect themselves against criminal attacks on their identities, bank accounts, private papers, etc., using *encryption*.
Congress is loathe to allow businesses and individuals to respond to hackers by "hacking back" -- even when the source of the active hacker might be known.  But once again, it would be far preferable to enable as strong encryption as possible so that "hacking back" won't be necessary.

@_date: 2015-12-24 09:39:25
@_author: Henry Baker 
@_subject: [Cryptography] Photon beam splitters for "true" random number 
An excellent application of "open source" camera firmware is encryption.
If you're a news photographer in a war zone, your life could depend upon it.
io_crypt is a module which automatically encrypts .CR2 and .JPG while you shoot them.
The original file content is never written to card, so there is no way to restore the image content by reading the raw sectors etc.
You can choose between different modes and security levels.

@_date: 2015-12-24 11:39:39
@_author: Henry Baker 
@_subject: [Cryptography] Photon beam splitters for "true" random number 
In the case of /dev/zero, actually no!
There's more than enough room in the flash memory controller chip firmware to do some sort of compression -- e.g., simple run length compression -- thus leaving plenty of space for keeping your secrets unmolested (& unerased !).
So your only hope is (see below)
cat /dev/random > /dev/sdc
(where "sdc" is the USB stick and/or SD card).
This is probably a pretty good test of a new chip anyway, just to make sure that every sector works, and that it isn't hiding malware -- at least in the user-accessible portions of the flash disk.
This just in.  I just ran some benchmarks on my little ol' Linux computer.
dd if=/dev/urandom of=/dev/sdc
runs at about 1 MB/sec, whereas
dd if=local_file of=/dev/sdc
runs at about 2.2 MB/sec for this slow USB flash drive (USB flash drive write speed limited)
dd if=/dev/random of=/dev/sdc
takes forever!
./infnoise > /dev/sdc
runs at about 1 MB/minute.
"infnoise" being the HW "infinite noise" TRNG.
Bottom line: if you want to "cleanse" your USB flash fast, write a huge, but legal (!), long movie to it; H.264 is pretty darn compressed; use H.265 if you want a slightly more compressed bit source -- e.g., so-called "4K" (resolution) movie.

@_date: 2015-12-24 16:57:29
@_author: Henry Baker 
@_subject: [Cryptography] are flipped coins unbiased? 
All of you should look at this *dice-rolling & interpreting robot*,
which automatically rolls the dice, reads & interprets the dice
with a camera.
The link also shows a lot of the statistics that he gathered.
Mark Fickett Art: Dice Roller
How Fair Is My D20?
An automatic system for rolling a polyhedral die and taking photos of the rolls;
extracting the image of just the die from those images;
clustering the images of the die by which face is shown;
and analyzing the results.
I was inspired in part by the Awesome Dice Blog's 2012 post comparing d20 fairness between two manufacturers. (Christopher Galpin in 2014 links to a number of other interesting analyses; John Kern in 2006 does Bayesian analysis for Pass the Pigs.) They rolled and tallied by hand.

@_date: 2015-12-27 07:51:28
@_author: Henry Baker 
@_subject: [Cryptography] Nervous Nellies want to gut the First Amendment 
FYI -- [I realize that this article isn't about encryption, per se, but you know that encryption is the next shoe to drop.]
Some of the lawyers *on the left* want to throw in the First Amendment towel without even a fight.  To the extent that ISIS convinces America to drop its defense of free speech, they've won, and we've become ISIS ourselves.
ISIS Influence on Web Prompts Second Thoughts on First Amendment
By ERIK ECKHOLM DEC. 27, 2015
It is one of the most hallowed precepts in modern constitutional law: Freedom of speech may not be curbed unless it poses a "clear and present danger" -- an actual, imminent threat, not the mere advocacy of harmful acts or ideas.
But in response to the Islamic State's success in grooming jihadists over the Internet, some legal scholars are asking whether it is time to reconsider that constitutional line.
Appeals for a tougher response to the Islamic State's online recruiting efforts have, not surprisingly, emerged from the political realm.  Donald J. Trump said the government should call on Bill Gates and others to somehow close off dangerous Internet sites, and called First Amendment concerns foolish.
Hillary Clinton said, "We should work with host companies" to shut down jihadist websites and chat rooms.  Such an effort would be constitutional if voluntary, legal experts say, but not if the government exerted tangible pressures on private firms to cooperate in censorship.
Some security experts called on YouTube to ban videos of lectures by Anwar al-Awlaki, which helped radicalize the attackers in San Bernardino, Calif., and many others.
Recently, though, a few legal scholars, too, have engaged in what others call First Amendment heresy.  What does clear and present danger mean when terrorists are provoking violence over the Internet?  Should not the government have a way, they ask, to block messages that facilitate terrorist acts tomorrow, if not today?
The existing standard is often illustrated by the classic example of shouting "Fire!" in a crowded theater when there is no hazard.  That is not protected speech because it could directly cause a deadly stampede.  But an article praising the merits of causing stampedes, even offering phrases to shout, is not closely enough linked to an imminent, actual threat to be outlawed.
In November, Cass R. Sunstein, a Harvard law professor and former Obama administration official, broached the subject in an article on Bloomberg View.
Mr. Sunstein called the clear and present danger test "the greatest American contribution to the theory and practice of free speech."  In view of the Islamic State's successful use of the Internet to nurture terrorists, he said, "it's worth asking whether that test may be ripe for reconsideration."
A more forceful case and a legislative proposal were put forth this month by Eric Posner, a professor of law at the University of Chicago, in an article for Slate.
"Never before in our history have enemies outside the United States been able to propagate genuinely dangerous ideas on American territory in such an effective way," Mr. Posner wrote.  The Islamic State's ability to electronically spread "ideas that lead directly to terrorist attacks," he said, "calls for new thinking about limits on freedom of speech."
In the article, Mr. Posner supported urging companies like Facebook and YouTube to crack down on propaganda by the Islamic State, which is also known as ISIS or ISIL, but said that could never be fully effective.  He proposed, in addition, passing a law to deter potential consumers from viewing dangerous sites.  While the law would apply to all Internet users, his goal, admittedly limited, is to head off the radicalization of those he described as "nave people" who research the Islamic State out of curiosity, "rather than sophisticated terrorists."
His law would make it illegal to go onto websites that glorify the Islamic State or support recruitment of new followers, or to distribute links to such sites.  He would impose graduated penalties, starting with a warning letter, then fines or prison for repeat offenders, to send the message that "looking at ISIS-related websites, like looking at websites that display child pornography, is strictly forbidden."
David G.  Post, a former professor of constitutional law who is a senior fellow at the Open Technology Institute of the New America Foundation in Washington, was one of many legal experts to condemn Mr. Posner's idea.
"I think it is a slippery slope," Mr. Post said in an interview.  In a popular legal blog, The Volokh Conspiracy, he wrote that efforts to suppress radical views "can be far too easily twisted into a prohibition against dissenting viewpoints."
Geoffrey R. Stone, an expert on constitutional law at the University of Chicago, said in an interview that Mr. Posner and Mr. Sunstein "have been provocative, which is what academics do."
"But I think they are wrong," he added.
"We've learned over 200 years of history that what seems like a sensible approach in the heat of the moment, in terms of restricting speech, is highly likely to be a bad judgment, Mr. Stone said.
The Sedition Act of 1798, he noted, which outlawed false statements about the government, was used by the Federalists to persecute their opponents, the supporters of Thomas Jefferson.
The idea of a clear and present danger test was introduced by Justice Oliver Wendell Holmes in a 1919 opinion, Schenck v. United States, but it would be a half-century before it achieved today's sharply protective constitutional meaning.  In Schenck, in fact, Justice Holmes and a unanimous court upheld the conviction of someone who advocated draft resistance during World War I.
But later that same year, Justice Holmes wrote a famous dissent that laid the groundwork for stronger protections of speech.
In the case, Abrams v. United States, a divided court upheld convictions for distributing leaflets opposing America's participation in the war and its efforts to counter the Russian Revolution.  Justice Holmes, in a dissent joined by Justice Louis Brandeis, wrote that the fiery pamphlets had posed no specific risk, adding, "We should be eternally vigilant against attempts to check the expression of opinions that we loathe."
Still, it was not until 1969, in the landmark case Brandenburg v.  Ohio, overturning the conviction of a Ku Klux Klan member, that the Supreme Court finally established the current meaning of clear and present danger.  It ruled that the government could not punish inflammatory speech unless the speech was likely to incite "imminent lawless action."
Mr. Posner, in an interview, acknowledged that his views were not widely shared in the legal community, to say the least.  But the modern meaning of the First Amendment, he said, reflects hundreds of years of legal thinking and trade-offs, and "we should rethink those trade-offs as technology and society changes."
Determining which terrorist groups and sites are effectively recruiting followers on American soil would require judgment calls by the government, he said.  It is the kind of statement that gives shivers to many First Amendment defenders.
Jeremy Waldron, a professor of legal philosophy at New York University, has raised questions about the protection of hate speech under the First Amendment, with arguments paralleling those applied to terrorist websites by Mr. Sunstein and Mr. Posner.
"I argued, in the adjacent area of hate speech, that the clear and present danger test is inadequate," Mr. Waldron said in an interview.  "You can poison the atmosphere without an immediate danger, but sometimes, waiting for an imminent danger is waiting too long."
"In the hallowed grounds of free speech, we have been a bit nave about how threats spread," he said.
Mr. Waldron's book "The Harm in Hate Speech" was published in 2012.  In the United States, he said, "it was greeted with mostly uniform hostility." But some European countries, he noted, are comfortable with stronger controls on incendiary speech.
All these legal experts, including Mr. Posner, agree that if today's Supreme Court considered his proposed law, it would likely be struck down -- by a vote of nine to zero.
But if more Americans who were indoctrinated by jihadist videos engage in terrorist attacks, they also agree, the nation's mood and the court's thinking could change.
"Five years from now, who knows?" Mr. Stone said.  "You can imagine a scenario in which things get so terrible that you start watering down the protections."
"I don't think we're anywhere near that point now," he said.

@_date: 2015-12-27 15:39:55
@_author: Henry Baker 
@_subject: [Cryptography] China passes law requiring tech firms to hand over 
FYI --
"This latest move is one that will be view very suspiciously by foreign companies operating within China, or looking to do so."
China passes law requiring tech firms to hand over encryption keys
By Mark Wilson  Published 5 hours ago
Apple may have said that it opposes the idea of weakening encryption and providing governments with backdoors into products, but things are rather different in China.  The Chinese parliament has just passed a law that requires technology companies to comply with government requests for information, including handing over encryption keys.
Under the guise of counter-terrorism, the controversial law is the Chinese government's attempt to curtail the activities of militants and political activists.  China already faces criticism from around the world not only for the infamous Great Firewall of China, but also the blatant online surveillance and censorship that takes place.  This latest move is one that will be view very suspiciously by foreign companies operating within China, or looking to do so.
China's infringement of freedom of speech and the hard line it takes on those opposing the government is well-recorded.  While the government insists that there will be no requirement for companies to install backdoors, the country has already earned itself a reputation that is going to be very difficult to shake off.
The deputy head of the Chinese parliament's criminal law division tried to play down the controversy surrounding the new law.  Li Shouwei said:
"This rule accords with the actual work need of fighting terrorism and is basically the same as what other major countries in the world do."
As well as granting new powers within China's borders, the new law also permits overseas action by the People's Liberation Army -- something which will be eyed with suspicion and likely opposed by for foreign nations.  There is also a provision, as reported by Reuters, that "media and social media cannot report on details of terror activities that might lead to imitation, nor show scenes that are 'cruel and inhuman' " -- something else which will bring about accusation of standing in the way of free speech.

@_date: 2015-12-28 07:47:36
@_author: Henry Baker 
@_subject: [Cryptography] Understanding state can be important. 
Remove the hard disk/SSD from your laptop & execute Tails from a USB stick.
Not as good as Rutkowska's ideal, but it is an approximation.

@_date: 2015-12-28 13:21:05
@_author: Henry Baker 
@_subject: [Cryptography] Senator Burr: Stopping Terrorists From 'Going Dark' 
FYI --
'Sen. Elizabeth Warren wrote letters to six federal agencies voicing concerns that banks were using Symphony, an encrypted messaging system that could prevent regulators from detecting illegal activities.'
'the banks agreed to store decryption keys with independent custodians, and Symphony agreed to retain electronic communications for seven years.'
The Debate Over Encryption: Stopping Terrorists From 'Going Dark'
Encrypted devices block law enforcement from collecting evidence.  Period.
By RICHARD BURR
Dec. 23, 2015 6:46 p.m. ET
While the terrorist attacks in Paris, San Bernardino, Calif., and Garland, Texas, have brought discussions about encryption to the front pages, criminals in the U.S. have been using this technology for years to cover their tracks. The time has come for Congress and technology companies to discuss how encryption--encoding messages to protect their content--is enabling murderers, pedophiles, drug dealers and, increasingly, terrorists.
Consumer information should be protected, and the development of stronger and more robust levels of encryption is necessary.  Unfortunately, the protection that encryption provides law-abiding citizens is also available to criminals and terrorists.  Today's messaging systems are often designed so that companies' own developers cannot gain access to encrypted content--and, alarmingly, not even when compelled by a court order.  This allows criminals and terrorists, as the law enforcement community says, to "go dark" and plot with abandon.
Leaving aside the terrorism challenges, encryption is affecting the investigations of kidnapping, child pornography, gang activity and other crimes.  Federal, state, local and tribal law-enforcement officers can obtain legal authority to conduct electronic communications surveillance on terrorists and criminals.  But encrypted devices and applications sometimes block access to the data.  This means that even when the government has shown probable cause under the Fourth Amendment, it cannot acquire the evidence it seeks.
Technology has outpaced the law.  The core statute, the Communications Assistance for Law Enforcement Act, was enacted in 1994, more than a decade before the iPhone existed.  The law requires telecommunications carriers--for instance, phone companies--to build into their equipment the capability for law enforcement to intercept communications in real time.  The problem is that it doesn't apply to other providers of electronic communications, including those supporting encrypted applications.
Federal Bureau of Investigation Director James Comey has said that one of the two Garland, Texas, shooters who died carrying out an attack on a Muhammad art exhibit in May exchanged 109 messages with an operative overseas.  "We have no idea what he said," Mr. Comey told the Senate this month, "because those messages were encrypted."  He described this as a "big problem"--and I couldn't agree more.
Last month Manhattan District Attorney Cyrus R. Vance Jr. released an in-depth report specifically on "smartphone encryption and public safety."  Many cellphones, including those designed by Apple and Google, now encrypt by default all the data they store, which is accessible only with a passcode. No one, not even the manufacturer, can access a passcode-locked phone.  Apple has even touted this as a feature, telling customers that "it's not technically feasible for us to respond to government warrants for the extraction of this data from devices."  The report states that "passcode-protected devices render lawful court orders meaningless and encourage criminals to act with impunity. The ultimate losers in this equation are crime victims."
The authors conclude: "Congress should enact a statute that requires any designer of an operating system for a smartphone or tablet manufactured, leased, or sold in the U.S. to ensure that data on its devices is accessible pursuant to a search warrant.  Such a law would be well within Congress's Commerce Clause powers, and does not require costly or difficult technological The challenges presented by encryption extend to financial transactions.  In August Sen. Elizabeth Warren wrote letters to six federal agencies voicing concerns that banks were using Symphony, an encrypted messaging system that could prevent regulators from detecting illegal activities.  The letter came shortly after New York's top banking regulator, the New York State Department of Financial Services, raised the same concern with several major banks and Symphony's developer.
In response, the banks agreed to store decryption keys with independent custodians, and Symphony agreed to retain electronic communications for seven years.  All parties also agreed to a periodic review process to make sure that oversight keeps in sync with new technologies.
It would seem to me that daily financial flows shouldn't command more attention than terrorist or criminal communications, yet here we are.  Although the agreement described above may not be the solution for all encrypted communications, it does show that cooperative solutions are possible.
I and other lawmakers in Washington would like to work with America's leading tech companies to solve this problem, but we fear they may balk.  When Apple objected to a recent court order in a New York criminal case requiring it to unlock an iPhone running iOS 7--an operating system that Apple can unlock--the company refused, arguing: "This is a matter for Congress to decide." On that point, Apple and I agree.  It's time to update the law.
Mr. Burr, a Republican senator from North Carolina, is the chairman of the Senate Select Committee on Intelligence.

@_date: 2015-12-28 14:02:15
@_author: Henry Baker 
@_subject: [Cryptography] Understanding state can be important. 
Apparently, not suspicious enough.
It's nine o'clock; do you know what all of your processes (i.e., ps ax or equivalent) are doing?
If you're running Win10, a goodly amount of disk & net traffic has to do with surveilling you -- making logs, sending back statistics to the mother ship, etc.
Look at any forensic web site & you can see what a gold mine Win10 has built for anyone compromises your computer.
But similar processes are incorporated in iOS, Android, etc.
It's amazing how fast computers run when they're not bogged down spying on their own users!

@_date: 2015-12-28 14:25:17
@_author: Henry Baker 
@_subject: [Cryptography] Senators: Time for Pre-crime 
FYI --
'The same tools that terrorists and criminals are using to hide their nefarious activities are those that everyday Americans rely on to safely shop online, communicate with friends and family, and run their businesses'
'We are no longer simply weighing the costs and benefits of "privacy vs. security" but rather "security vs. security"'
'We must find more ways to stop terrorist attacks during the planning phase'
How to unite privacy and security -- before the next terrorist attack
By Michael McCaul and Mark Warner December 27 at 8:05 PM
Michael McCaul, a Republican from Texas, is chairman of the House Homeland Security Committee.  Mark Warner, a Democrat from Virginia, is a member of the Senate's Banking, Finance and Intelligence committees.
This month it was revealed that the Paris attackers used hard-to-monitor, encrypted applications to coordinate their acts of terrorism, a reminder that we face an enemy that is difficult to find and adapting quickly.
No longer do terrorists plot using couriers and caves.  Today they use social media to radicalize and recruit.  And when individuals show interest in their cause, they move their communications to encrypted applications and other secure platforms to evade detection.
This presents an extraordinary security challenge for the United States and our allies.  Because extremists are "going dark," law enforcement officials warn that we are "going blind" in our efforts to track them.
For instance, the Islamic State has made communications security a key element of its training and propaganda.  Followers have distributed a 32-page manual featuring tips for jihadist aspirants to conceal their messages through end-to-end encryption, secure apps and other tradecraft.
But the problem isn't limited to terrorists.  Similar tactics are also used by drug traffickers and child predators to avoid getting caught, creating a much broader public safety crisis.
Frustratingly, there are no easy answers.  The same tools that terrorists and criminals are using to hide their nefarious activities are those that everyday Americans rely on to safely shop online, communicate with friends and family, and run their businesses.
Encryption is a bedrock of global commerce, and it has helped enhance individual privacy immeasurably.  It is also integral to our cybersecurity efforts -- protecting individuals, U.S. businesses, intellectual property and our nation's critical infrastructure.
As a result, digital innovations present us with a paradox.  We are no longer simply weighing the costs and benefits of "privacy vs. security" but rather "security vs. security."
Some have proposed mandating "backdoors" into encrypted platforms so that such messages can be accessed by law enforcement with a lawful warrant.  Yet such a law could weaken Internet privacy for everyone and could have the unintended consequence of making our information systems more vulnerable to attack.
Moreover, in our globalized world, a U.S.-only solution would likely have only a limited impact and could encourage offenders to simply use technology developed overseas instead.  But at the same time, doing nothing puts American lives at risk and makes it easier for terrorists and criminals to escape justice.
Solving this problem requires establishing a dialogue that takes fuller account of technological limitations, investigative tools and legal needs.
That is why we are proposing a national commission on security and technology challenges in the digital age.
We cannot wait for the next attack before we outline our options, nor should we legislate out of fear.  Instead, Congress must be proactive and should officially convene a body of experts representing all of the interests at stake so we can evaluate and improve America's security posture as technology -- and our adversaries -- evolve.
Leaders here in Washington have failed to do this, and the relevant parties have not been brought together in an open, transparent manner.  As a result, Americans have heard a lot of bluster and not enough substance.  Complex issues have been reduced to simple talking points and vague demands.
We want that to change, which is why we are seeking the brightest minds from the technology sector, the legal world, computer science and cryptography, academia, civil liberties and privacy advocates, law enforcement and intelligence to collaboratively explore the intersection of technology and security.
This would not be a group of politicians debating one another.  We believe the individuals most capable of finding creative ways to protect our security -- both public and private -- are the stakeholders themselves.
Nor would the commission be like other blue-ribbon panels, quickly established but soon forgotten.  Rather, it would be charged with generating much-needed data and developing a range of actionable recommendations that can protect privacy and public safety.
The threats we face are very real.  As we saw in Garland, Tex., in May, the first sign of a hatched plot might be an Internet hashtag, tweeted mere minutes before an attack.  In that case, the attacker allegedly was in touch with an overseas terrorist while he was plotting, but authorities have been unable to access the secure messages they exchanged.
We must find more ways to stop terrorist attacks during the planning phase -- not while they are underway.  And as we work together on these vital challenges, we must never lose sight of our Constitution and America's core democratic values.

@_date: 2015-12-28 18:53:12
@_author: Henry Baker 
@_subject: [Cryptography] Unbreakable crypto 
All true, but Comey/Vance would say: -- once it has obtained a warrant -- the govt is allowed to utilize as much force as it is willing to devote to opening doors, pulling down shades, opening diaries, opening bank vaults.
So the real question is: what happens when the combined power of the state is ineffective against doors, shades, diaries and bank vaults ?
We have examples: the govt can't beat laws of physics: gravity, electromagnetism, etc.  But the atomic bombs, Oak Ridge, Hanford and Las Alamos show the resources a govt is willing to devote to try to beat those laws of physics.
The U.S. govt was willing to *drain a (small) lake* in San Bernardino to recover several GBytes of computer files (DVD's, USB sticks, SD cards).  I think that they didn't, either 1) they found what they were looking for; or 2) decided that draining the lake might be ineffective and actually destroy or lose the very evidence they were trying to find.  But if they had thought it might work, that lake would be dry right now.
In one sense, you can't blame the govt for attempting impossible things; that's the nature of people and govts.
But -- so far -- it appears that govts can't break crypto currently considered "strong" by unclassified experts.
So think about what is going on behind the closed doors of govts today.
After Snowden, but accelerated by massive hacking attacks -- e.g., OPM, the Internet industry *is* getting its act together.  Significant fractions of the Internet are now being "protected" by decent HTTPS.  The "trusted platforms" (TPM's) *can* be hacked, but their existence raises the cost of such hacking substantially.
The days of casual passive tapping of unencrypted fiber optic cables are over.  The days of passively accessing cellphone traffic and stealing messages, voice traffic, location data, etc. are over.
 From now on, purely passive attacks will probably be quite rare.  But active attacks -- i.e., most likely MITM attacks -- substantially raise the profile of the attacks, so they are more expensive in terms of dollars and in terms of possible blowback.
In short, Bluffdale is now filling up with unbreakably encrypted *hay*, while actual needles remain as rare as unicorns.
The NSA can't admit its current impotence to unclassified voters, so they get the FBI, DHS, etc., to do their political dirty work for them.  Besides, voters don't get very excited about govt-sponsored listening in on phone sex -- even if it is phone sex among criminals.  So the FBI, DHS, etc., trot out the 4 Horsemen of the Cyber Apocalypse:
"Beware the Four Horsemen of the [Cyber] Apocalypse: terrorists, drug dealers, kidnappers, and child pornographers.  Seems like you can scare any public into allowing the government to do anything with those four."  -- Bruce Schneier
Since those on this list know that the encryption is holding strong for the moment, we also know what's coming next.  If you can't *break* encryption, then the only thing left to do is to *bypass* it -- i.e., purposely leak unencrypted data into special govt receptacles for access by the govt "only with a warrant".  :-)
In addition to recycling, we'll all have another receptacle to add to our trash bin collection: green for organic waste, blue for paper & plastic waste, and now battleship grey to give the govt our "data".  The next generation Monty Python won't cry "Bring out your dead!", but will instead call "Bring out your data!"
So far, the Supreme Court hasn't been very impressed by the govt's casual access to all that cellphone data w/o a warrant.
But -- as the FBI & DHS keep reminding us -- we're only one dirty bomb away from Poindexter's Total Information Awareness, where we will gladly surrender *all* of our data in order to keep that infinitesimally likely asteroid from hitting *our* house.
Of course, Total Information Awareness means the end of the First, Fourth and Fifth Amendments.  But when the plain text of these Amendments are used in polling potential voters, they don't poll very well -- even among students at elite universities.  It's highly unlikely that a Congress or a President is going to have the guts to stand on the Constitution as a reason for "not protecting the American people".  So these Amendments are likely gone already -- causing the spirits of the dead soldiers who died protecting that Constitution to spin forever in their graves.
Given the FBI's penchant for "manufacturing" terrorist incidents, one can only imagine how the next FBI-manufactured terrorist will act:
* he/she will use an iPhone (take that, Tim!)
* he/she will use an end2end encrypted app developed by Silicon Valley
* he/she will use Facebook & Twitter
* he/she will use Tor
* he/she will use a drone (take that, DJI!)
* he/she will be a "lone wolf", providing a rationale for dragneting *everybody*
As long as they're at it, the FBI will try to "run the tables" on all the HW/SW/apps/companies they find irritating.
And the Constitution will be Trumped and considered Hillarious by the various presidential candidates.
If anyone here thinks that there is a better trajectory for this encryption "conversation", please chime in.

@_date: 2015-12-29 06:30:31
@_author: Henry Baker 
@_subject: [Cryptography] Microsoft likely has your Win10 encryption key 
FYI --
'there is no way to prevent a new Windows device from uploading your recovery key the first time you log in to to your Microsoft account'
'Windows Home users don't get the choice to not upload their recovery key at all'
"The recovery key requires physical access to the user device and is not useful without it."
'When you delete your recovery key from your account on this website, Microsoft promises that it gets deleted immediately, and that copies stored on their backup drives get deleted shortly thereafter as well.'
Recently Bought a Windows Computer?  Microsoft Probably Has Your Encryption Key
Micah Lee
One of the excellent features of new Windows devices is that disk encryption is built-in and turned on *by default*, protecting your data in case your device is lost or stolen.  But what is less well-known is that, if you are like most users and login to Windows 10 using your Microsoft account, your computer automatically uploaded a copy of your recovery key -- which can be used to unlock your encrypted disk -- to Microsoft's servers, probably without your knowledge and without an option to opt-out.
During the "crypto wars" of the nineties, the National Security Agency developed an encryption backdoor technology -- endorsed and promoted by the Clinton administration -- called the Clipper chip, which they hoped telecom companies would use to sell backdoored crypto phones.  Essentially, every phone with a Clipper chip would come with an encryption key, but the government would also get a copy of that key -- this is  known as key escrow -- with the promise to only use it in response to a valid warrant.  But due to public outcry and the availability of encryption tools like PGP, which the government didn't control, the Clipper chip program ceased to be relevant by 1996.  (Today, most phone calls still aren't encrypted.  You can use the free, open source, backdoorless Signal app to make encrypted calls.)
The fact that new Windows devices require users to backup their recovery key on Microsoft's servers is remarkably similar to a key escrow system, but with an important difference.  Users can choose to delete recovery keys from their Microsoft accounts (you can skip to the bottom of this article to learn how) -- something that people never had the option to do with the Clipper chip system.  But they can only delete it after they've already uploaded it to the cloud.
"The gold standard in disk encryption is end-to-end encryption, where only you can unlock your disk.  This is what most companies use, and it seems to work well," says Matthew Green, professor of cryptography at Johns Hopkins University.  "There are certainly cases where it's helpful to have a backup of your key or password.  In those cases you might opt in to have a company store that information.  But handing your keys to a company like Microsoft fundamentally changes the security properties of a disk encryption system."
As soon as your recovery key leaves your computer, you have no way of knowing its fate.  A hacker could have already hacked your Microsoft account and can make a copy of your recovery key before you have time to delete it.  Or Microsoft itself could get hacked, or could have hired a rogue employee with access to user data.  Or a law enforcement or spy agency could send Microsoft a request for all data in your account, which would legally compel them to hand over your recovery key, which they could do even if the first thing you do after setting up your computer is delete it.
As Green puts it, "Your computer is now only as secure as that database of keys held by Microsoft, which means it may be vulnerable to hackers, foreign governments, and people who can extort Microsoft employees."
Of course, keeping a backup of your recovery key in your Microsoft account is genuinely useful for probably the majority of Windows users, which is why Microsoft designed the encryption scheme, known as "device encryption," this way.  If something goes wrong and your encrypted Windows computer breaks, you're going to need this recovery key to gain access to any of your files.  Microsoft would rather give their customers crippled disk encryption than risk their data.
"When a device goes into recovery mode, and the user doesn't have access to the recovery key, the data on the drive will become permanently inaccessible.  Based on the possibility of this outcome and a broad survey of customer feedback we chose to automatically backup the user recovery key," a Microsoft spokesperson told me.  "The recovery key requires physical access to the user device and is not useful without it."
After you finish setting up your Windows computer, you can login to your Microsoft account and delete the recovery key.  Is this secure enough?  "If Microsoft doesn't keep backups, maybe," says Green.  "But it's hard to guarantee that.  And for people who aren't aware of the risk, opt-out seems risky."
This policy is in stark contract to Microsoft's major competitor, Apple.  New Macs also ship with built-in and default disk encryption: a technology known as FileVault.  Like Microsoft, Apple lets you store a backup of your recovery key in your iCloud account.  But in Apple's case, it's an option.  When you set up a Mac for the first time, you can uncheck a box if you don't want to send your key to Apple's servers.
This policy is also in contrast to Microsoft's premium disk encryption product called BitLocker, which isn't the same thing as what Microsoft refers to as device encryption.  When you turn on BitLocker you're forced to make a backup of your recovery key, but you get three options: Save it in your Microsoft account, save it to a USB stick, or print it.
To fully understand the different disk encryption features that Windows offers, you need to know some Microsoft jargon.  Windows comes in different editions: Home (the cheapest), Pro, and Enterprise (more expensive).  Windows Home includes device encryption, which started to become available during Windows 8, and requires your computer to have a tamper-resistant chip that stores encryption keys, something all new PCs come with.  Pro and Enterprise both include device encryption, and they also include BitLocker, which started to become available during Windows Vista, but only for the premium editions.  Under the hood, device encryption and BitLocker are the same thing.  The difference is there's only one way to use device encryption, but BitLocker is configurable.
If you're using a recent version of Windows, and your computer has the encryption chip, and if you have a Microsoft account, your disk will automatically get encrypted, and your recovery key will get sent to Microsoft.  If you login to Windows using your company's or university's Windows domain, then your recovery key will get sent to a server controlled by your company or university instead of Microsoft -- but still, you can't prevent device encryption from sending your recovery key.  If you choose to not use a Microsoft or a domain account at all and instead create a "local only" account, then you don't get disk encryption.
BitLocker, on the other hand, gives you more control.  When you turn on BitLocker you get the choice to store your recovery key locally, among other options.  But if you buy a new Windows device, even if it supports BitLocker, you'll be using device encryption when you first set it up, and you'll automatically send your recovery key to Microsoft.
In short, there is no way to prevent a new Windows device from uploading your recovery key the first time you log in to to your Microsoft account, even if you have a Pro or Enterprise edition of Windows.  And this is worse than just Microsoft choosing an insecure default option.  Windows Home users don't get the choice to not upload their recovery key at all.  And while Windows Pro and Enterprise users do get the choice (because they can use BitLocker), they can't exercise that choice until after they've already uploaded their recovery key to Microsoft's servers.
How to delete your recovery key from your Microsoft account
Go to this website and log in to your Microsoft account -- this will be the same username and password that you use to log in to your Windows device.  Once you're in, it will show you a list of recovery keys backed up to your account.
If any of your Windows devices are listed, this means that Microsoft, or anyone that manages to access data in your Microsoft account, is technically able to unlock your encrypted disk, without your consent, as long as they physically have your computer.  You can go ahead and delete your recovery key on this page -- but you may want to back it up locally first, for example by writing it down on a piece of paper that you keep somewhere safe.
If you don't see any recovery keys, then you either don't have an encrypted disk, or Microsoft doesn't have a copy of your recovery key.  This might be the case if you're using BitLocker and didn't upload your recovery key when you first turned it on.
When you delete your recovery key from your account on this website, Microsoft promises that it gets deleted immediately, and that copies stored on their backup drives get deleted shortly thereafter as well.  "The recovery key password is deleted right away from the customer's online profile.  As the drives that are used for failover and backup are sync'd up with the latest data the keys are removed," a Microsoft spokesperson assured me.
If you have sensitive data that's stored on your laptop, in some cases it might be safer to completely stop using your old encryption key and generate a new one that you never send to Microsoft.  This way you can be entirely sure that the copy that used to be on Microsoft's server hasn't already been compromised.
Generate a new encryption key without giving a copy to Microsoft
In order to generate a new disk encryption key, this time without giving a copy to Microsoft, you need decrypt your whole hard disk and then re-encrypt it, but this time in such a way that you'll actually get asked how you want to backup your recover key.
This is only possible if you have Windows Pro or Enterprise.  Unfortunately, the only thing you can do if you have the Home edition is upgrade to a more expensive edition or use non-Microsoft disk encryption software, such as BestCrypt, which you have to pay for.  You may also be able to get open source encryption software like VeraCrypt working, but sadly the open source options for full disk encryption in Windows don't currently work well with modern PC hardware (as touched on here).
Go to Start, type "bitlocker", and click "Manage BitLocker" to open BitLocker Drive Encryption settings.
After your disk is finished decrypting, you need to turn BitLocker back on.  Back in the BitLocker Drive Encryption settings, click "Turn on BitLocker".
It will check to see if your computer supports BitLocker, and then it will ask you how you want to backup your recovery key.  It sure would be nice if it asked you this when you first set up your computer.
If you choose to save it to a file, it will make you save it onto a disk that you're not currently encrypting, such as a USB stick.  Or you can choose to print it, and keep a hard copy.  You must choose one of them to continue, but make sure you don't choose "Save to your Microsoft account."
On the next page it will ask you if you want to encrypt used disk space only (faster) or encrypt your entire disk including empty space (slower).  If you want to be on the safe side, choose the latter.  Then on the next page it will ask you if you wish to run the BitLocker system check, which you should probably do.
Finally, it will make you reboot your computer.
When you boot back up your hard disk will be encrypting in the background.  At this point you can check your Microsoft account again to see if Windows uploaded your recovery key -- it shouldn't have.
Now just wait for your disk to finish encrypting.  Congratulations: Your disk is encrypted and Microsoft no longer has the ability to unlock it.
Contact the author:
Micah Lee
micah.lee at theintercept.com

@_date: 2015-12-29 11:14:18
@_author: Henry Baker 
@_subject: [Cryptography] Understanding state can be important. 
Here's the link to the video of Joanna's 63-minute talk; it's pretty interesting.

@_date: 2015-12-29 12:18:41
@_author: Henry Baker 
@_subject: [Cryptography] Photon beam splitters for "true" random number 
FYI -- Video of 60-minute recent talk about Quantum Communication showing a crossed polarizer TRNG.  Also talks about Quantum Key Distribution (i.e., the quantum version of Diffie-Hellman that's *provably* secure from Eve).

@_date: 2015-12-30 05:14:58
@_author: Henry Baker 
@_subject: [Cryptography] Unbreakable crypto 
"*Ordeal by water* was associated with the witch hunts of the 16th and 17th centuries: an accused who sank was considered innocent, while floating indicated witchcraft.  These tests came to be part of what is known as the Salem Witch Trials." [0]
I'm so glad that we've put barbaric practices such as these behind us in modern liberal democratic societies today.
[0] -----BEGIN NSA SPEEDBUMP:I AM SPARTACUS-----
-----END NSA SPEEDBUMP-----

@_date: 2015-12-30 05:48:28
@_author: Henry Baker 
@_subject: [Cryptography] How France became the DDR in just one year 
FYI -- 27-minute video (300MB) of a recent talk at 32C3.
Watch & weep.
State of Emergency includes warrantless searches of electronic devices *and everything "connected" to them* (!).
"Constitutional reform".  The State of Emergency will be written into the Constitution.
The UK and the U.S. aren't far behind.

@_date: 2015-12-30 06:17:18
@_author: Henry Baker 
@_subject: [Cryptography] Imperfect Forward Secrecy: How DH Fails in Practice 
Alex Halderman & Nadia Heninger's talk at 32c3:
Imperfect Forward Secrecy: How Diffie-Hellman Fails in Practice
Video of 60-minute talk:
On last slide:
1024-bit discrete log within range for governments.
Parameter reuse allows wide-scale passive decryption.
* Move to elliptic curve cryptography
* If ECC isnt an option, use = 2048-bit primes.
* If 2048-bit primes arent an option, generate a fresh 1024-bit prime.

@_date: 2015-12-30 08:59:33
@_author: Henry Baker 
@_subject: [Cryptography] Write-protect switches, etc. 
One significant problem with malware is that it can *delete log files*, so that finding out what it was up to can be difficult.
Soooo, you need a *write-once*, *append-only* device to act as a logger.
It's sad, in this day and age, that the best logger may be an old-style continuous paper printer.
It's hard to imagine malware that's capable of reaching out & shredding that "log file".
This is why traditional (paper-based) *accounting systems* are append-only.  You can never erase an entry; you can only add a correcting entry, so that it can later be audited.  Financial systems & auditors have had to deal with bad people trying to "hack the books" for centuries.
The Bitcoin blockchain is an analogous system that would require overwhelming force (i.e., some plurality of the computing power) to change an entry.
Unfortunately, it's not that simple w.r.t. malware & logs.
The malware can force the log files to be encrypted with a key of their choosing -- sort of like ransomware -- so the resulting log files may exist, but will be gibberish.
Perhaps Mr. Comey has a solution for this problem?

@_date: 2015-12-30 17:55:55
@_author: Henry Baker 
@_subject: [Cryptography] CCC: Crypto Wars Part II: The Empire Strikes Back 
I couldn't find Opsahl's slides, so I made notes from the video:
32c3 talk Kurt Opsahl CCC slides
Crypto Wars Part II: The Empire Strikes Back
They're Back!
* Twenty years ago we fought back against attempts to limit, suppress and cripple encryption
 - EFF was on the front lines
 - After a long struggle, encryption prevailed.
* But now governments are at it again
The Background
* Not so long ago, in this very galaxy...
 - In Cold War, encryption often a military tech
 - 1975: DES for commercial encryption
 - 1977: RSA implements Diffie-Hellman
 - 1991: PGP distributed
 - 1995: Netscape's SSL
Two types of munitions
Netscape encryption & a military tank
Export Controls
* Netscape Navigator: By mid-90's industry standard was 128-bit SSL
* Export limited to 40-bit (broken in days)
* Legal challenges to export regulations
FREAK and Logjam
* Exploits published in 2015, can downgrade to old "export-grade" keys
 - Designed to allows NSA to break, but not others with less computing power
* Nowadays 1990s era export-grade public key pairs can be broken in hours with cheap cloud computing
* For more see J. Alex Halderman, Nadia Heninger, Logjam: Diffie-Hellman, discrete logs, the NSA, and you
Code is Speech
* Daniel Bernstein challenges export control of Snuffle crypto program, with EFF help
* Bernstein v. Department of Justice:
"The availability and use of secure encryption may...reclaim some portion of the privacy we have lost.  Gov't efforts to control encryption thus may well implicate not only the First Amendment rights ... but also the constitutional rights of each of us as potential recipients of encryption's bounty."
1990's: Clipper Chip
* Clipper chip was an NSA developed chipset
 - For voice comms
* Used Skipjack encryption algorithm
* Included back door with key escrow
Back doors can be dangerous
* Even a small flaw in a crypto system can lead to catastrophic results
Emily Litvack, Risk Analysis Gone Wrong, Univ. of Ariz. "Law Enforcement Access Field"
* 1994: Matt Blaze showed Clipper's 128-bit LEAF contained info needed to recover key.
* 1995: Yair Frankel and Moti Yung publish attack to bypass escrow
* Clipper widely condemned
1990's Policy Debate
* Eerily similar to today
1990's and Now
* FBI DDirector Freeh in 1997:
"[W]e're in favor of strong encryption, robust encryption.  The country needs it, industry needs it.  We just want to make sure we have a trap door and key under some judge's authority where we can get there if somebody is planning a crime."
1990's and Now
* FBI GC Valerie Caproni in 2010:
"They can promise strong encryption.  They just need to figure out how they can provide us plain text."
2010's: Encryption at Scale
* Mobile phones get default encryption for stored data
 -- Apple's iOS8, Google's Android
* More messaging services add default encryption
 -- iMessage, TextSecure, WhatsApp, and more
Data encryption to messages
* Conversation started with device encryption, but quickly moved to end-to-end encryption
* UK PM Cameron: "Are we going to allow a means of communications which it simply isn't possible to read?"
* Not if Cameron has his way
The Empire Strikes Back
* Public and private pressure on companies
* Demonize encryption
* Propose legislation
* Technical attacks
Gov't finds your lack of back doors disturbing
* FBI Director Comey: Why would companies "market something expressly to allow people to place themselves beyond the law?"
* UK PM Cameron: Companies "have a social responsibility to fight the battle against terrorism."
* Focus on companies, large user-bases.
Only a Business Model
* Government have been downplaying corporate support for encryption
 - Comey: "Encryption isn't just a technical feature; it's a marketing pitch"
 - Combined with backroom pressure
Secure Back Door Proposals
* Most common is key escrow
* E.g. Message sent with symmetric key
* Encrypt symmetric key twice
 - Recipient's public key and
 - Escrow agent's public key
For more see Keys Under Doormats
* Breaks if escrow agent's private key compromised
* Single escrow breaks forward secrecy
 - Split keys can mitigate, but add complexity
Can you trust the escrow agent?
* Who would be escrow?
 - Government?  Which one(s)?  Provider?  Third-party?
* Insider risk
* Law enforcement access points
 - Tempting target for criminals and state sponsored attackers
 - For example, Greece wiretapping, Google
What if we re-named back doors?
* Comey: "We aren't seeking a back-door approach.  We want to use the front door"
* Washington Post "a back door can and will be exploited by bad guys, too.  However, with all their wizardry, perhaps Apple and Google could invent a kind of secure golden key"
The Rule of Cynicism
* Bob Litt, General Counsel of the ODNI:
Encryption debate "could turn in the event of a terrorist attack or criminal event where strong encryption can be shown to have hindered law enforcement."
Ok, but what if crypto wasn't involved?
* "We don't know yet, but I think what we're going to learn is that [the attackers] used these encrypted apps, right?"
 - Former CIA deputy director Michael Morell
* Many suggest encryption was to blame
 - Paris attackers actually used plain text SMS
 - San Bernardino actually used direct messages
Fear leads to the dark side
* UK Home Secretary May: "essential to tackle child sexual exploitation, to dismantle serious crime cartels, take drugs and guns off our streets and prevent terrorist attacks."
* US Sen. Feinstein: "product that allows evil monsters to communicate in this way, to behead children, to strike innocents,"
* Many countries are considering legislation that would either
 - mandate backdoors,
 - mandate access to plaintext or
 - endanger encryption
UK Snooper's Charter
* Purport to regulate telecommunications operators all around the world
* Section 189(4)(c): Operators may be obligated to remove "electronic protection" if they provided
 - Could be interpreted to require weakening encryption, holding a key or banning end-to-end
UK Snooper's Charter
* Latest version resented to Parliament in November
 - Currently in committee, which is accepting evidence.
 - Industry and civil society submitted comments
Australia's Defence Trade Controls Act
* Prohibits the "intangible supply" of encryption technologies
* Many ordinary teaching and research activities could be subject to unclear export controls with severe penalties
* International Association for Cryptologic Research organized petition against, signed 100s of experts
India Considers An Encryption Policy
* In September, India released a draft National Encryption Policy
 - Everyone required to store plain text
 - Info kept for 90 days
 - Made available to law enforcement agencies as and when demanded
* Withdrawn after criticism
China's Anti-Terrorism Law
* Passed Sunday
* Draft version required tech companies to hand over encryption codes
* Final version: "shall provide technical interfaces, decryption and other technical support"
US: No Bill to Require Backdoors
* Yet.  Obama "will not --for now-- call for legislation requiring companies to decode messages for law enforcement."
 - SaveCrypto.org: >100k signatures urging Obama to support strong encryption
* Senate Intelligence Committee likely to introduce bill in the coming spring
Trans-Pacific Partnership
* Some report that TPP could contain good news on encryption?
 - Alas, no.
* Provider may not be compelled to give key
 - Only "as condition of sale"
* But provider must still give decrypted content
* TPP still has huge problems throughout
Technical Attacks
* Routing around encryption
* Breaking crypto
* Inserting vulns
* Malware on end point
Attacking Crypto
* BULLRUN: $250 million/year program
 - "Insert vulnerabilities"
 - "influence policies, standards and specifications for commercial public key technologies"
* 2004: NSA paid $10 million to RSA to make DUAL_EC_DRBG default
 - Has costant Q that can be used to backdoor RNG
The Curious Case of Juniper
* Juniper's ScreenOS used DUAL_EC_DRBG
 - But not NSA's default Q.  A new, alternative, Q.
 - Output passed through a second, strong, random number generator
 - But, snippet of code provided raw Dual EC output
  * Allowed attacker to passively break VPN
 - Also included hardcoded password in SSH and Telnet
 - Looks like someone pwned the NSA backdoor
For more see Matthew Green, On the Juniper backdoor.  2015/12/on-juniper-backdoor.html
* If you own the end point, end-to-end encryption does not matter.
* Favorite tool for targeted attacks
How to Fight Back
* Principle
* Public policy
* Pragmatism
* Promotion
* Access to strong encryption is required to effectuate human rights principles
 - Privacy
 - Free expression
* Helps build a brighter future
Universal Declaration of Human Rights
* Article 12: "No one shall be subjected to arbitrary interference with his privacy, family, home or correspondence...."
Universal Declaration of Human Rights
* Article 19: "Everyone has the right to freedom of opinion and expression; this right includes freedom to hold opinions without interference and to seek, receive and impart information and ideas through any media and regardless of frontiers."
Protecting Human Rights Requires Encryption
* Right to "receive and impart information and ideas through any media," includes encryption
* Code is speech: Freedom of expression must allow for publication of end-to-end crypto systems
 - Especially open source projects
* Protecting against oppressive regimes is more important than maximizing spying
* Weak encryption mostly good for mass, untargeted spying
 - Mass spying less effective, more invasive
* Strong encryption can guarantee real privacy with math
* Strong encryption enables innovation
 - For example, ecommerce, bitcoin
Public Policy
* Forcing companies to compromise security will make everyone less safe
 - Encryption critical for security
* Other governments will make similar demands
* Already in a golden age of surveillance
* It won't work.
 - Open source, free software hard to stop
* Math: Not possible to make encryption simultaneously weak and strong
* Weakening encryption for law-abiding people won't stop terrorists from having strong encryption
* You can help by promoting, creating, improving and using encryption
* Show your friends how to use encryption
* Make censorship resistant crypto tools
 - Open source, wide distribution, reproducible builds
Let's Encrypt
* New certificate authority
* Getting a certificate is now easy and fun
* No more excuses for HTTP
Encrypt the Web
* Responses to the NSA's smiley face
 - Dropbox, Facebook, Google, Microsoft, Twitter, Yahoo and others massively increased encryption
 - Email encryption of billions of messages
Rating Messaging
* Secure Messaging Scorecard

@_date: 2015-12-30 18:10:34
@_author: Henry Baker 
@_subject: [Cryptography] Understanding state can be important. 
I'd be happy with a *true* "USB condom"; one that MITM'd the USB port and made damn sure that a passive memory device acted like a *single* *passive* memory device, and not a keyboard/mouse/whatever; it would also watch out for any changes in its VID/PID.
This same device could also ground any write commands.
I've seen some cheap devices that could conceivably do this, but the manufacturer would have to allow me reprogram the firmware.

@_date: 2015-12-31 10:06:07
@_author: Henry Baker 
@_subject: [Cryptography] CCC: DJB on Post Quantum Crypto 
Excellent talk by Dan Bernstein on Post Quantum Crypto (PQC).
Video (451MBytes; ~60 minutes):
Slides (3 MBytes):

@_date: 2015-12-31 12:41:38
@_author: Henry Baker 
@_subject: [Cryptography] CCC: Filippo Valsorda /dev/random v /dev/urandom 
FYI -- (Bottom line: use /dev/urandom )
The plain simple reality of entropy
Or how I learned to stop worrying and love urandom
Slides (1.5 MBytes):
30-min video talk (312 MBytes)

@_date: 2015-12-31 17:36:38
@_author: Henry Baker 
@_subject: [Cryptography] Alice, Bob, Eve, Mallory, Maxwell ??? 
Alice & Bob are usually communicating, and Eve is usually a *passive* eavesdropper, while Mallory can actively *modify* the message (malleable?).
Is there a personification of random *noise* ?  I was considering "Maxwell" (for Maxwell's Demon); are there any other names in normal use for an attacker that simply injects random noise?
Is there a standard name for a MITM attacker?

@_date: 2015-02-01 15:34:03
@_author: Henry Baker 
@_subject: [Cryptography] best practices considered bad term 
Best practice = minimum CYA effort = plausible deniability in case of lawsuit = what a jury would consider non-negligent = only regular damages, rather than punitive damages.

@_date: 2015-02-01 16:33:17
@_author: Henry Baker 
@_subject: [Cryptography] De-Anonymizing 
At one of the local chain markets, if you don't have a loyalty
card, the checkout person will use his/hers, so you still get
the discount, even when you pay cash.  Clearly, the local store
management doesn't care for the corporate BS tracking program.

@_date: 2015-02-02 20:06:11
@_author: Henry Baker 
@_subject: [Cryptography] best practices considered bad term 
Pretend that NSA/Snowden did everyone a favor by showing us how dreadful our protocols and software systems are.  (Yes, I know, the chances of this whole Snowden business being an NSA ploy to get us all "hardened up" for China are as small as the probability of all the air molecules in my home suddenly occupying the same cc of space.)
I think everyone fell asleep at the router back in the '90's when they thought that the encryption wars had been won.  So we've now wasted 20 years of opportunities to get our networking sh*t together.
We've only got perhaps 2 years to make up for Rip Van Winkling away the last 20 years.

@_date: 2015-02-07 06:44:35
@_author: Henry Baker 
@_subject: [Cryptography] Security vulnerabilities in BMW's ConnectedDrive 
FYI -- I loved the part where if the hacker didn't know the vehicle's VIN, the car sent a helpful error message telling him/her!
Of course, at least in the US, the VIN number is readable through the windshield, and a modern high resolution camera could read these VIN numbers from an overpass on a freeway.
If the Remote Services are deactivated in a vehicle with ConnectedDrive, the remote opening of the doors would not work.  It is, however, possible to activate Remote Services using the emulated cellular network.
This works similarly to the previous attack.  The car gets sent a text message instructing it to load new configuration data from the BMW servers.  This data gets loaded via a simple HTTP Get request and is formatted as unencrypted XML that is trivial to understand.  The configuration file is not protected against manipulation at all, something that could have been easily solved by signing the data.  This means it was easy, using my emulated network, to first activate Remote Services and then open the doors.
At least the messages sent to a vehicle are checked with regard to which car they are addressed to.  This check is done with a VIN (Vehicle Identification Number) included in the message.  If the VIN does not match the car in question, it will not execute the command it is sent.  This is no hurdle to a potential attacker, though, since the Combox is very helpful in this regard: If it does not receive a valid VIN, it actually sends back an error message that contains the correct VIN in order to identify the sender of the message.
At the time of my initial investigation, ConnectedDrive included six security vulnerabilities:
* BMW uses the same symmetric keys in all vehicles.
* Some services do not encrypt messages in transit between the car and the BMW backend.
* The ConnectedDrive configuration data isn't tanper-proof.
* The Combox discloses the VIN via NGTP error messages.
* NGTP data sent via text messages is encrypted with the insecure DES method.
* The Combox does not implement protection to guard against replay attacks.
Still, what are the options for car owners who are nervous despite the assurances from the manufacturer?  Sadly, ConnectedDrive can't simply be switched off ? there is no equivalent to the Airplane Mode offered by mobile phones.
To permanently deactivate ConnectedDrive, a written request and a visit to a service garage is required.  A self-help measure would be to disconnect the Combox or TCB from the antenna.  Depending on the car model, this is easy to do as the control unit can be found under the luggage compartment floor.  Howeverm this also deactivates the automatic emergency calls.

@_date: 2015-02-12 14:05:15
@_author: Henry Baker 
@_subject: [Cryptography] Crypto Trick Makes Software Nearly Impossible to 
FYI --
A Crypto Trick That Makes Software Nearly Impossible to Reverse-Engineer
By Andy Greenberg 02.11.15 9:00 pm
Software reverse engineering, the art of pulling programs apart to figure out how they work, is what makes it possible for sophisticated hackers to scour code for exploitable bugs.  It?s also what allows those same hackers? dangerous malware to be deconstructed and neutered.  Now a new encryption trick could make both those tasks much, much harder.
At the SyScan conference next month in Singapore, security researcher Jacob Torrey plans to present a new scheme he calls Hardened Anti-Reverse Engineering System, or HARES.  Torrey?s method encrypts software code such that it?s only decrypted by the computer?s processor at the last possible moment before the code is executed.  This prevents reverse engineering tools from reading the decrypted code as it?s being run.  The result is tough-to-crack protection from any hacker who would pirate the software, suss out security flaws that could compromise users, and even in some cases understand its basic functions.
?This makes an application completely opaque,? says Torrey, who works as a researcher for the New York State-based security firm Assured Information Security.  ?It protects software algorithms from reverse engineering, and it prevents software from being mined for vulnerabilities that can be turned into exploits.?
A company like Adobe or Autodesk might use HARES as a sophisticated new form of DRM to protect their pricey software from being illegally copied.  On the other hand, it could also mean the start of a new era of well-armored criminal or espionage malware that resists any attempt to determine its purpose, figure out who wrote it, or develop protections against it.  As notable hacker the Grugq wrote on twitter when Torrey?s abstract was posted to SyScan?s schedule, HARES could mean the ?end of easy malware analysis. :D?
To keep reverse engineering tools in the dark, HARES uses a hardware trick that?s possible with Intel and AMD chips called a Translation Lookaside Buffer (or TLB) Split.  That TLB Split segregates the portion of a computer?s memory where a program stores its data from the portion where it stores its own code?s instructions.  HARES keeps everything in that ?instructions? portion of memory encrypted such that it can only be decrypted with a key that resides in the computer?s processor.  (That means even sophisticated tricks like a ?cold boot attack,? which literally freezes the data in a computer?s RAM, can?t pull the key out of memory.)  When a common reverse engineering tool like IDA Pro reads the computer?s memory to find the program?s instructions, that TLB split redirects the reverse engineering tool to the section of memory that?s filled with encrypted, unreadable commands.
?You can specifically say that encrypted memory shall not be accessed from other regions that aren?t encrypted,? says Don Andrew Bailey, a well-known security researcher for Lab Mouse Security, who has reviewed Torrey?s work.
Many hackers begin their reverse engineering process with a technique called ?fuzzing.?  Fuzzing means they enter random data into the program in the hopes of causing it to crash, then analyze those crashes to locate more serious exploitable vulnerabilities.  But Torrey says that fuzzing a program encrypted with HARES would render those crashes completely unexplainable.  ?You could fuzz a program, but even if you got a crash, you wouldn?t know what was causing it,? he says.  ?It would be like doing it blindfolded and drunk.?
Torrey says he intends HARES to be used for protection against hacking?-not for creating mysterious malware that can?t be dissected.  But he admits that if HARES works, it will be adopted for offensive hacking purposes, too.  ?Imagine trying to figure out what Stuxnet did if you couldn?t look at it,? he says.  ?I think this will change how [nation-state] level malware can be reacted to.?
HARES?s protections aren?t quite invincible.  Any program that wants to use its crypto trick needs to somehow place a decryption key in a computer?s CPU when the application is installed.  In some cases, a super-sophisticated reverse engineer could intercept that key and use it to read the program?s hidden commands.  But snagging the key would require him or her to plan ahead, with software that?s ready to look for it.  And in some cases where software comes pre-installed on a computer, the key could be planted in the CPU ahead of time by an operating system maker like Apple or Microsoft to prevent its being compromised.  ?There are some concerns with this from a technical point of view,? says Bailey.  ?But it?s way better than anything we have out there now.?
Another way to crack HARES? encryption, says Torrey, would be to take advantage of a debugging feature in some chips.  That feature allows a hardware device between the chip and the motherboard to read every command the processor executes.  But taking advantage of that feature requires a five-figure-priced JTAG debugger, not a device most reverse engineers tend to have lying around.  ?It?s pretty high level stuff,? he says.  ?Obviously nation states will have these things, but probably not very many others.?
Torrey notes that it may someday be possible to encrypt a program?s code in a way that its instructions can run without ever being decrypted?-making software that?s truly unhackable.  But such a system, known as ?fully homomorphic encryption,? is still largely theoretical.  It currently makes computer processes take millions of times longer than they would without encryption.  HARES slows down the programs it protects by only about 2 percent.  ?Fully homomorphic encryption is the holy grail, but it?s an academic math problem,? Torrey says.  ?This is something you can stick on your existing computer to protect your existing software.?
Torrey developed HARES?s TLB split trick with funding in 2013 from Darpa?s Cyber Fast Track program.  He plans to release the project?s code not at March?s SyScan conference, but possibly the next month at the Infiltrate security conference in Miami.
Torrey says that he wouldn?t be surprised, however, if coders determine from his March talk how to use HARES?s tricks and begin writing malware that?s far harder to decode.  Give hackers an unencrypted hint or two, and they have a way of figuring out your secrets.

@_date: 2015-02-17 18:28:34
@_author: Henry Baker 
@_subject: [Cryptography] trojans in the firmware 
I (and most everyone else, as well) no longer care about booting from "hard" disks.  Everyone boots from flash memories these days.
So now the problem is gaining access to flash disk firmware.  Normally, you can't.  However, there are now really decent file systems developed for Linux for _bare_ flash devices (i.e., not USB or uSD flash drives, which utilize internally managed flash memory "log-structured" file systems; see BadUSB for more info).
What I'm interested in now are completely raw flash devices having no microcode at all.  Perhaps someone is now packaging these chips in sodimm packages.  In any case, for many reasons having nothing to do with the NSA, I'd like to control exactly how my flash file system works.
Many of the OpenWRT router devices utilize completely raw flash devices for their internal memory, which allows OpenWRT itself to choose how to manage the "file systems" for use on these devices.
I haven't checked the details on the newest Raspberry Pi device, but perhaps its flash memory is based on similar completely raw flash devices.

@_date: 2015-02-18 17:57:40
@_author: Henry Baker 
@_subject: [Cryptography] trojans in the firmware 
????  If the disk drive or flash drive firmware has already
been compromised, none of this will work, because the firmware
simply waits for the appropriate "legitimate" read & write
commands, and does its thing.
BTW, what happens with "emulated" disks -- e.g., .vdi files --
in vm's ?  Presumably these emulated disks have no firmware to
update, so any attempt would either be ignored or crash the

@_date: 2015-02-18 18:06:31
@_author: Henry Baker 
@_subject: [Cryptography] Equation Group Multiple Malware Program, 
Book-Pro.local>
Dumping OBL's body may have been a mistake.  Unless they spent a lot of time looking it over, they may have missed a subcutaneous 64GB uSD card.
Of course, we don't _really_ know what happened to the body, do we?  (Someone in DC very likely has a little souvenir trinket somewhere in his desk drawer or on his key chain.)

@_date: 2015-02-19 08:12:41
@_author: Henry Baker 
@_subject: [Cryptography] trojans in the firmware 
I would love to be able to program this device myself, instead of relying on Samsung's firmware.
BTW, what's the point of AES encryption on this pre-p0wned device?  More security theatre?
Samsung Portable SSD T1 Review: Blazing Fast External Storage
Utilizing Samsung's proprietary 3D Vertical NAND (V-NAND) technology and a SuperSpeed USB 3.0 interface, the Portable SSD T1 redlines at up to 450MB/s when reading or writing data sequentially, according to Samsung.  For random read and write activities, Samsung rates the drive at up to 8,000 IOPS and 21,000 IOPS, respectively.
Capacity 1TB (250GB and 500GB also available)
Interface Compatible with USB 3.0, 2.0
Dimensions (W x H x D) 71.0 x 9.2 x 53.2 mm
Weight Max. 30 grams
Transfer Speed Up to 450MB/sec
UASP Mode UASP Mode
Encryption AES 256-bit
Security Password setting (optional)
Certification CE, BSMI,KC, VCC, C-tick, FCC, IC, UL, TUV, CB
RoHS Compliance RoHS2
Warranty Limited 3 year
Price$569 (street) - Find It At Amazon

@_date: 2015-02-20 08:33:48
@_author: Henry Baker 
@_subject: Sony to Offer Premium Sound Memory Card 
FYI -- From the company that brought you the rootkit CD's...
You just have to wonder what sort of superfish crapware comes embedded in this uSD card firmware.  Anyone who spends $160 for a 64GB uSD card is already on the Nigerian email shortlist; I would guess that the builtin password is "sucker".
2:19 am ET Feb 19, 2015
Sony to Offer ?Premium Sound? Memory Card
By Takashi Mochizuki
For audio freaks, the quest to reduce noise never ends, even if it means sometimes paying a high price for equipment?-say, $1,000 for a one-meter audio cable.
Sony Corp. has been more than happy to try to cater to their passion for clean sound, offering a $1,200 Walkman and other high-resolution audio technology, including high-end headphones and wireless speakers.
Now comes a memory card engineered for sound quality.  Beginning next month, the 64 gigabyte SR-64HXA micro SDXC memory card will be sold for around $160 in Japan, roughly five times the cost of a standard card with the same amount of storage.  The SR-64HXA produces less electrical noise when reading data, the company says.
Will many people buy it? Even Sony doesn?t know.
?We aren?t that sure about the product?s potential demand, but we thought some among people who are committed to great sound quality would want it,? a Sony spokeswoman said.

@_date: 2015-02-20 13:05:03
@_author: Henry Baker 
@_subject: [Cryptography] [cryptography] Equation Group Multiple Malware 
The Stasi regularly opened physical mail "at scale":
"Machine used by the Stasi to steam open personal letters so their contents could be read in the search for dissidents."
"Machine used to seal envelopes that had been opened.  The goal was to make it so that people did not know, or at least were not sure, that their mail had been opened."
Stasi-envier J Edgar Hoover never allowed the Constitution to interfere with his self-appointed task of subverting subversion, and presided over a large amount of illegal physical mail reading.  This hallowed tradition continues today, with the FBI aiding & abetting sub-80IQ people in manufacturing "terrorist plots" out of whole cloth, and the use of "parallel construction" to convert illegal surveillance into testa-lying under oath.
Just as FBI informants made up a material percentage of the U.S. Communist Party in the 1950's, I wouldn't be at all surprised to find out that FBI informants make up a material percentage of hacking groups like Anonymous; you have to wonder how many FBI informants used their work on the Sony hacks to "graduate" to their next higher level of street cred.

@_date: 2015-02-21 17:49:09
@_author: Henry Baker 
@_subject: [Cryptography] Lenovo laptops with preloaded adware and an evil 
mail.com>
You may not want to screw with these ex-Israeli-8200 unit guys.  It's entirely possible that Superfish is primarily a front company to provide "plausible deniability" for various nefarious activities.  It would be very interesting to know the sources of those $38 million in revenues.
Superfish: A History Of Malware Complaints And International Surveillance
Superfish, a little-known ?visual search? and ad tech provider from Palo Alto whose CEO was once part of the surveillance industrial complex, is about to learn what it feels like to face the unwavering wrath of the privacy and security industries.  Lenovo will take much of the blame for potentially placing users at risk by contracting Superfish to effectively carry out man-in-the-middle attacks on users to intercept their traffic just to get the firm?s ?visual? ads up during customers? web searches.
But Superfish, founded and led by former Intel employee and ex-surveillance boffin Adi Pinhas, has been criticised by users the world over since its inception in 2006.  In one Apple Mac forum started in 2012 and continuing into the following year was full of complaints about a technology called Window Shopper, built by Superfish.  It appears to have found its way onto people?s machines by being bundled with other software, in one case alongside an Oracle Java download, in another via an ?Awesome Screenshot? extension.  Indeed, most members of that forum had no idea just how the Superfish software had wormed its way onto their machines before irritating them with ads as they hovered over content.  And a few had some trouble locating Window Shopper to uninstall it.  Microsoft Windows users were experiencing similar pain back in 2011.  As were Mozilla Firefox fans in 2010.  The list could go on.
Wayback Machine Screenshot of Superfish?s Window Shopper web ad from 2013
A simple Google search for Window Shopper shows just how unloved the technology is, with many labelling it adware, malware or a virus.  Sean Sullivan, from anti-virus vendor F-Secure, told me over Twitter that Window Shopper was much more prevalent than the Lenovo-powered version of Superfish technology, though it didn?t ostensibly open up the same security issues.
This is part of a major problem with the whole web browser extension ecosystem.  Companies, understandably, are keen to have their software bundled with others so they can get more customers.  But in many cases that means no due diligence on the firms they?re partnering with.  Who knows what kinds of adware and malware services could come with some innocuous looking plugin?  Did Lenovo carry out adequate checks on Superfish?
As noted in a range of 2013 articles, there?s a lot of money to be earned by simply bundling extra ?crapware? onto people?s PCs.  Investors are keen to spur them on too.  In mid-2013, Superfish announced it had secured a $10 million Series D funding round, taking its total backing up to $20 million.
Superfish?s surveillance background
What of the foundations of Superfish itself?  Pinhas, the co-founder, has an interesting history, especially from a privacy perspective.  According to his LinkedIn profile, in 1999 he co-founded a company called Vigilant Technology, which ?invented digital video recording for the surveillance market?.  That company is still thriving today, boasting contracts with a diverse range of big-name clients, including the US military?s White Sands Missile Range, Paradise Casinos in California and Arizona, and a number of Israeli government organisations.
Prior to that, former Tel Aviv resident Pinhas worked at Verint, an intelligence company with a tumultuous history, where he carried out ?signal processing research? in which he?d recognise and analyse anything going over a telephone line.  Verint was founded by members of the elite military intelligence agency Unit 8200.  It was featured in a Wired article in 2012, in which it was alleged Verint tapped Verizon?s communications lines and was supposedly working with the National Security Agency in doing so.  Just a year later, Edward Snowden would reveal Verizon had let the NSA tap all customers? communications.  One wonders if Pinhas was ever involved in those shady operations.  Did that lead to his move to the West Coast?
Pinhas had not responded to requests for comment at the time of publication.  Superfish declined to give me an interview with Pinhas, but provided the following defence of its work with Lenovo: ?It is important to note: Superfish is completely transparent in what our software does and at no time were consumers vulnerable ? we stand by this today
 there has been no wrong doing on our end.?  It said it wholly agreed with Lenovo?s online statement.
There?s more intrigue to be found here, though.  As security expert Matt Suiche pointed out to me on Twitter, the password used to get the encryption key for the Superfish certificate authority (you can find more details on that in my previous article here) is ?Komodia?.  There?s a company called Komodia, which also does ad injection and ?global proxy interception? ? some very aggressive techniques.  According to the company?s website (which is currently down because of an attack on the site), the founder, Barak Weichselbaum, was also part of the surveillance industrial complex in Israel, having carried out ?military service as a programmer in the IDF?s Intelligence Core?.  Komodia offers one service called SSL Digestor that carries out ad injects and effectively breaks encryption, just as Superfish was doing on Lenovo PCs.  Suiche and Robert Graham of Errata Security are convinced that product was used by Superfish in the Lenovo case.
So ex-surveillance agents, operating in both the private and public spheres, have ostensibly combined their powers to force ads onto people?s computers, leaving web users open to other forms of attack.  That?s startling and frightening for anyone who cares about privacy or security.
Regardless of the furore that?s exploded online since the Lenovo revelations, and the fascinating history of Pinhas and his firm, Superfish is still earning a packet.  Forbes ranked it 64th in the most promising American companies of 2015 and reported revenues of $38 million.  It pays to be invasive these days.

@_date: 2015-02-21 22:56:26
@_author: Henry Baker 
@_subject: [Cryptography] Sony to Offer Premium Sound  Memory 
That's why God invented digital signal processing.
A number of times I've tried to listen to video lectures where there's an incredible level of AC hum.
I finally cranked up ffmpeg & audacity so that I can strip out the audio, filter out the AC hum, and
replace the filtered audio so that I could watch the video lecture in peace.
The audacity filters for AC harmonics that I programmed in a hour or so work really well.  They're
not professional audio quality, but then again if the original audio had come from a professional,
my efforts wouldn't have been required.
I'm surprised that YouTube doesn't already filter out AC hum from their videos; if you upload a
video that has too much vibration/shake, YouTube will filter that out automatically.

@_date: 2015-02-22 12:30:54
@_author: Henry Baker 
@_subject: [Cryptography] A better random number generator... 
Come on, people!  Only 68 views so far.
This video should be _required watching_ before anyone is allowed to even use "random number" in a sentence, much less in computer code.
Published on Feb 19, 2015
"PCG: A Family of Better Random Number Generators" - Melissa O'Neill of Harvey Mudd College
Colloquium on Computer Systems Seminar Series (EE380) presents the current research in design, implementation, analysis, and use of computer systems.  Topics range from integrated circuits to operating systems and programming languages.  It is free and open to the public, with new lectures each week.

@_date: 2015-02-22 16:02:27
@_author: Henry Baker 
@_subject: [Cryptography] trojans in the firmware 
Ummm...  And just how do you expect to "overwrite" the old key with the new key?
Last time I looked, most flash memories implemented a journaling file system, in which it is nearly impossible to overwrite _anything_ with any high degree of probability.
Of course, if I had access to the RAW MTD flash api, then I could do exactly what you suggest.  But the raw MTD api was what I was originally asking for.
If anyone here is aware of any flash evaluation kits/boards that provide a USB interface to the raw MTD api of a decent amount of flash memory (20-100GB), please leg me know.
Virtually every Internet-Of-Things device has some small amount of raw MTD flash, but I was hoping for something approximating a SSD, but programmable.  I found the "Willow" project at UCSD, but so far no one there has replied to my emails.

@_date: 2015-02-22 16:17:39
@_author: Henry Baker 
@_subject: [Cryptography] Lenovo laptops with preloaded adware and an evil 
"Somewhere in the Middle East, there is a computer we are calling the
?The Magnet of Threats? because in addition to Regin, it was also infected
by Turla, ItaDuke, Animal Farm and Careto/Mask.  When we tried to analyze
the Regin infection on this computer, we identified another module which did
not appear to be part of the Regin infection, nor any of the other APTs."

@_date: 2015-02-23 09:10:46
@_author: Henry Baker 
@_subject: [Cryptography] trojans in the firmware 
FYI -- CMU has been hacking disk drive firmware since the 1990's for "smart disks" and "performance"; UCSD has been hacking flash drive firmware more recently.  I believe that DARPA has also openly solicited for disk drive/flash drive firmware hacking capabilities.  Both CMU & UCSD are hotbeds of NSA recruitment activity.
We now know that in NSA parlance "smart" anything = "spying" anything; e.g., "smart disks" = "spying disks"; "smart phones" = "spying phones", etc.
BTW, hiding stuff in a flash memory stick is even easier than in a hard drive.  This is because flash memory is so unreliable, that there is typically a huge percentage of unused space; the cheaper the flash memory, the smaller the fraction of usable reliable memory space.  So it wouldn't be at all surprising to find that your 32GB flash drive is really constructed from 64GB chips, and that 50% of the device is unavailable for use.  It is highly unlikely that _all_ of this unused space is unreliable, so this leaves plenty of room for NSA lurking.  But even if the device were 100% reliable, noticing that only 50% was actually in use would be unremarkable, given the typical degree of unreliability of these types of devices.
For these reasons, it is critical for flash memory devices to _open up_ their API's, so that the raw memory (with all of its warts) can be inspected and verified.
How the NSA?s Firmware Hacking Works and Why It?s So Unsettling
By Kim Zetter 02.22.15 8:09 pm
One of the most shocking parts of the recently discovered spying network Equation Group is its mysterious module designed to reprogram or reflash a computer hard drive?s firmware with malicious code.  The Kaspersky researchers who uncovered this said its ability to subvert hard drive firmware?-the guts of any computer?-?surpasses anything else? they had ever seen.
The hacking tool, believed to be a product of the NSA, is significant because subverting the firmware gives the attackers God-like control of the system in a way that is stealthy and persistent even through software updates.  The module, named ?nls_933w.dll?, is the first of its kind found in the wild and is used with both the EquationDrug and GrayFish spy platforms Kaspersky uncovered.
It also has another capability: to create invisible storage space on the hard drive to hide data stolen from the system so the attackers can retrieve it later.  This lets spies like the Equation Group bypass disk encryption by secreting documents they want to seize in areas that don?t get encrypted.
Kaspersky has so far uncovered 500 victims of the Equation Group, but only five of these had the firmware-flashing module on their systems.  The flasher module is likely reserved for significant systems that present special surveillance challenges.  Costin Raiu, director of Kaspersky?s Global Research and Analysis Team, believes these are high-value computers that are not connected to the internet and are protected with disk encryption.
Here?s what we know about the firmware-flashing module.
How It Works
Hard drive disks have a controller, essentially a mini-computer, that includes a memory chip or flash ROM where the firmware code for operating the hard drive resides.
When a machine is infected with EquationDrug or GrayFish, the firmware flasher module gets deposited onto the system and reaches out to a command server to obtain payload code that it then flashes to the firmware, replacing the existing firmware with a malicious one.  The researchers uncovered two versions of the flasher module: one that appears to have been compiled in 2010 and is used with EquatinoDrug and one with a 2013 compilation date that is used with GrayFish.
The Trojanized firmware lets attackers stay on the system even through software updates.  If a victim, thinking his or her computer is infected, wipes the computer?s operating system and reinstalls it to eliminate any malicious code, the malicious firmware code remains untouched.  It can then reach out to the command server to restore all of the other malicious components that got wiped from the system.
Even if the firmware itself is updated with a new vendor release, the malicious firmware code may still persist because some firmware updates replace only parts of the firmware, meaning the malicious portions may not get overwritten with the update.  The only solution for victims is to trash their hard drive and start over with a new one.
The attack works because firmware was never designed with security in mind.  Hard disk makers don?t cryptographically sign the firmware they install on drives the way software vendors do.  Nor do hard drive disk designs have authentication built in to check for signed firmware.  This makes it possible for someone to change the firmware.  And firmware is the perfect place to conceal malware because antivirus scanners don?t examine it.  There?s also no easy way for users to read the firmware and manually check if it?s been altered.
The firmware flasher module can reprogram the firmware of more than a dozen different hard drive brands, including IBM, Seagate, Western Digital, and Toshiba.
?You know how much effort it takes to land just one firmware for a hard drive?  You need to know specifications, the CPU, the architecture of the firmware, how it works,? Raiu says.  The Kaspersky researchers have called it ?an astonishing technical accomplishment and is testament to the group?s abilities.?
Once the firmware is replaced with the Trojanized version, the flasher module creates an API that can communicate with other malicious modules on the system and also access hidden sectors of the disk where the attackers want to conceal data they intend to steal.  They hide this data in the so-called service area of the hard drive disk where the hard disk stores data needed for its internal operation.
Hidden Storage Is the Holy Grail
The revelation that the firmware hack helps store data the attackers want to steal didn?t get much play when the story broke last week, but it?s the most significant part of the hack.  It also raises a number of questions about how exactly the attackers are pulling this off.  Without an actual copy of the firmware payload that gets flashed to infected systems, there?s still a lot that?s unknown about the attack, but some of it can be surmised.
The ROM chip that contains the firmware includes a small amount of storage that goes unused.  If the ROM chip is 2 megabytes, the firmware might take up just 1.5 megabytes, leaving half a megabyte of unused space that can be employed for hiding data the attackers want to steal.
This is particularly useful if the computer has disk encryption enabled.  Because the EquationDrug and GrayFish malware run in Windows, they can grab a copy of documents while they?re unencrypted and save them to this hidden area on the machine that doesn?t get encrypted.  There isn?t much space on the chip for a lot of data or documents, however, so the attackers can also just store something equally as valuable to bypass encryption.
?Taking into account the fact that their GrayFish implant is active from the very boot of the system, they have the ability to capture the encryption password and save it into this hidden area,? Raiu says.
Authorities could later grab the computer, perhaps through border interdiction or something the NSA calls ?customs opportunities,? and extract the password from this hidden area to unlock the encrypted disk.
Raiu thinks the intended targets of such a scheme are limited to machines that are not connected to the internet and have encrypted hard drives. One of the five machines they found hit with the firmware flasher module had no internet connection and was used for special secure communications.
?[The owners] only use it in some very specific cases where there is no other way around it,? Raiu says.  ?Think about Bin Laden who lived in the desert in an isolated compound?-doesn?t have internet and no electronic footprint.  So if you want information from his computer how do you get it?  You get documents into the hidden area and you wait, and then after one or two years you come back and steal it.  The benefits [of using this] are very specific.?
Raiu thinks, however, that the attackers have a grander scheme in mind.  ?In the future probably they want to take it to the next level where they just copy all the documents [into the hidden area] instead of the password.  [Then] at some point, when they have an opportunity to have physical access to the system, they can then access that hidden area and get the unencrypted docs.?
They wouldn?t need the password if they could copy an entire directory from the operating system to the hidden sector for accessing later.  But the flash chip where the firmware resides is too small for large amounts of data.  So the attackers would need a bigger hidden space for storage.  Luckily for them, it exists.  There are large sectors in the service area of the hard drive disk that are also unused and could be commandeered to store a large cache of documents, even ones that might have been deleted from other parts of the computer.  This service area, also called the reserved are or system area, stores the firmware and other data needed to operate drives, but it also contains large portions of unused space.
An interesting paper (.pdf) published in February 2013 by Ariel Berkman, a data recovery specialist at the Israeli firm Recover, noted ?not only that these areas can?t be sanitized (via standard tools), they cannot be accessed via anti-virus software [or] computer forensics tools.?
Berkman points out that one particular model of Western Digital drives has 141 MB reserved for the service area, but only uses 12 MB of this, leaving the rest free for stealth storage.
To write or copy data to service area requires special commands that are specific to each vendor and are not publicly documented, so an attacker would need to uncover what these are.  But once they do, ?[b]y sending Vendor Specific Commands (VSCs) directly to the hard-drive, one can manipulate these [service] areas to read and write data that are otherwise inaccessible,? Berkman writes.  It is also possible, though not trivial, to write a program to automatically copy documents to this area.  Berkman himself wrote a proof-of-concept program to read and write a file of up to 94 MB to the service area, but the program was a bit unstable and he noted that it could cause some data loss or cause the hard drive to fail.
One problem with hiding large amounts of data like this, however, is that its presence might be detected by examining the size of the used space in the service area.  If there should be 129 MB of unused space in this sector but there?s only 80 MB, it?s a dead giveaway that something is there that shouldn?t be.  But a leaked NSA document that was written in 2006 but was published by Der Spiegel last month suggests the spy agency might have resolved this particular problem.
NSA Interns to the Rescue
The document (.pdf) is essentially a wish list of future spy capabilities the NSA hoped to develop for its so-called Persistence Division, a division that has an attack team within it that focuses on establishing and maintaining persistence on compromised machines by subverting their firmware, BIOS, BUS or drivers.  The document lists a number of projects the NSA put together for interns to tackle on behalf of this attack team.  Among them is the ?Covert Storage? project for developing a hard drive firmware implant that can prevent covert storage on disks from being detected.  To do this, the implant prevents the system from disclosing the true amount of free space available on the disk.
?The idea would be to modify the firmware of a particular hard drive so that it normally only recognizes, say, half of its available space,? the document reads.  ?It would report this size back to the operating system and not provide any way to access the additional space.?  Only one partition of the drive would be visible on the partition table, leaving the other partitions?-where the hidden data was stored?-invisible and inaccessible.
The modified firmware would have a special hook embedded in it that would unlock this hidden storage space only after a custom command was sent to the drive and the computer was rebooted.  The hidden partition would then be available on the partition table and accessible until the secret storage was locked again with another custom command.
How exactly the spy agency planned to retrieve the hidden data was unclear from the eight-year-old document.  Also unclear is whether the interns ever produced a firmware implant that accomplished what the NSA sought.  But given that the document includes a note that interns would be expected to produce a solution for their project within six months after assignment, and considering the proven ingenuity of the NSA in other matters, they no doubt figured it out.

@_date: 2015-02-23 12:04:58
@_author: Henry Baker 
@_subject: [Cryptography] Claude Shannon 
Agreed.  But Shannon was perhaps the last Victorian scientist; his
information theory may well be at odds with quantum mechanics.  We
still don't know what a bit _weighs_; and resolving this (and other
associated questions) will keep physicists occupied for perhaps the
next 50 years.
I'm sorry to have never seen him ride his unicycle at MIT.
"With the fundamental new discipline of quantum information science now under construction, it's a good time to look back at an extraordinary scientist who single-handedly launched classical information theory"

@_date: 2015-02-24 06:59:12
@_author: Henry Baker 
@_subject: [Cryptography] information, Shannon, and quantum mechanics 
If you had mentioned the word "Bekenstein", we might be able to have a conversation.

@_date: 2015-02-25 11:07:49
@_author: Henry Baker 
@_subject: [Cryptography] trojans in your printers 
One of the largest attack surfaces in any home or office is the printer.
Modern printers are substantial networked computers, sometimes with large hard drives, which process all kinds of extremely confidential information, including bank account records, web page printouts, potentially compromising pictures, etc., etc.
These modern printers come with their own wifi, which you have little and/or no control over, and they contact whomever they please directly over the internet -- often using https, so you have no idea what they are communicating -- perhaps every page you've ever printed.
As has been shown time and again, these printers are easily hacked, after which they can do enormous damage.
Can anything being done to address the risks from printer-borne malware?

@_date: 2015-02-26 21:26:14
@_author: Henry Baker 
@_subject: [Cryptography] trojans in your printers 
This might work for what I would call a "minimally-hacked"
printer.  However, if someone really wants to hack your printer,
they might as well go all the way, and have it monitor your
local wifi network to figure out who's top dog.  Then start
spoofing MAC and IP addresses.  It could also launch an all-out
assault on your router, assuming that it hasn't already been
compromised.  A simple firewall may not slow any hacker down
very much.
When was the last time HP/Canon/Epson/... offered to upgrade
the SW on your printer in order to improve its security?  How
many incredibly serious bugs have been found in embedded
SW security suites in the last two years?  How many of these
fixes have been pushed out to these embedded devices?

@_date: 2015-02-27 06:31:22
@_author: Henry Baker 
@_subject: [Cryptography] trojans in your printers 
If we don't trust our printer, then we have to put it
on a wired network that (as far as it can tell) has only
one other node: the host that sends it print commands.
In other words, we might as well run it from a USB port,
except that it could be doing BADUSB stuff to us.
We also have to assume that it is storing everything
that we've ever asked it to print somewhere it its
bowels, which info may eventually be disgorged if it
ever gets a chance to talk to the Internet, or if a
USB stick is ever inserted.
Perhaps the safest configuration would be to buy a
cheap ($25) travel router & attach the printer to
this router via USB.  Reflash the router code with
OpenWRT, and have the router manage the printer.
The printer then thinks that it is a slave to a
single host, and has no access to the Internet.  Yet
the router can accept print commands from anywhere
on the network to feed to the printer.
The printer can attempt to do BADUSB stuff to the
travel router, but hopefully the printer isn't
smart enough to know how to hack every possible
OpenWRT configuration.

@_date: 2015-02-27 13:38:27
@_author: Henry Baker 
@_subject: [Cryptography] trojans in your printers 
OpenWRT runs just fine on my $25 TP-Link travel router with an external USB flash drive to "pivot" with.

@_date: 2015-02-28 19:28:12
@_author: Henry Baker 
@_subject: [Cryptography] trojans in your printers 
OpenWRT now supports "pivot root", which basically allows booting from the (small) boot flash, and then "pivoting" in such a way that the USB flash or SATA drive becomes the real root file system.  This almost completely solves the software storage capacity problem, and also relieves a lot of pressure on the RAM, which in small travel routers may only be 32MBytes.
Thus, a travel router with a USB flash drive can support an enormous amount of software, so long as it doesn't all want to run at the same time.
Rootfs on External Storage (extroot)
More often then not, there is a limited amount of storage space available on embedded devices.  While the available flash memory will usually accomodate a bare OpenWrt installation, more room for applications and data can tremendously expand a device's potential.  Luckily, many of these devices have these expansion capabilities built-in, for example in the form of USB ports, SATA ports, PCIexpress slots, or even storage in a network location.  However, many of the applications you want to install are developed with the idea that they should be installed in the root file system (rootfs).  By employing OpenWrt's extroot, you can expand the storage capacity of your root file system using the additional space of an added storage device.  At a certain point in the boot process the external storage space is mounted as the root file system or in an overlay configuration over the original file system. To understand the technical details of OpenWrt extroot, please read extroot.theory.  Thi
s article explains how to get it to work. ExtRoot: How it works
Most routers do not have hard drives.  They use flash memory for similar purposes: storing programs and data, even when the system is off (non-volatile memory). In most systems, flash memory does not appear like RAM and so data and instructions must be copied to RAM to be used.  So, for example, the bootloader copies the kernel from flash to RAM and then starts that copy running. Obviously there are two possible ways to do things:
* we can pivot the /overlay to the USB disk (you could call this external overlay or pivot-overlay)
* we can pivot the entire / (read: root) to the USB disk (you could call this external root or pivot-root)
Note: extroot started as the external overlay thus the external root was called pivot-root only in order to distinguish between the two implementations.  To avoid misunderstandings you should always use pivot-overlay and pivot-root respectively. extroot comprises both methods.

@_date: 2015-02-28 19:35:45
@_author: Henry Baker 
@_subject: [Cryptography] Encrypted QR Codes Could Keep Devices Safe 
============================== START ==============================
FYI --
Encrypted QR Codes Could Keep Devices Safe from Hackers
Written by Jordan Pearson
Staff Writer (Canada)
February 27, 2015 // 02:35 PM EST Encrypted QR codes can be used to ensure that the your devices?-whether that?s your laptop, your phone, or your smart watch?-haven?t been tampered with on their way from the factory to your home, according to new research.
QR codes have long been used to track inventory in supply chains, from car parts to computer components.  The supply chain?from manufacture to shipping?-is also where a computer can be intercepted and its components replaced with hacked hardware.  NSA has been doing this since at least 2008, documents leaked by Edward Snowden and obtained by Der Spiegel revealed.
On the flipside, a 2012 investigation by the US Senate Committee on Armed Services found that as many as 1 million counterfeit circuits and other electronic components from China?some of which were assembled from e-waste?had made it into the Department of Defense supply chain and ended up in the infrared sensors found on helicopters and Hellfire missiles.
University of Connecticut researchers devised a new kind of nigh-impossible to recreate QR code to slap on components in the factory.  Their approach, outlined in a paper published today in IEEE Photonics Journal, involves encoding data containing the component?s part number and function on millimetre-sized QR codes and using an array of data compression, optical imaging, and encryption techniques to make sure nobody can replicate it.  The code could then be scanned at its destination to confirm that the part it?s attached to was not replaced. The researchers first encrypted the data in the form of an image they wanted to represent with the QR code, jumbling it up like white noise, and then used yet another encryption technique that uses a small amount of photons to represent the encrypted image as a few points of white on a dark background.  When scanning the code, an image recognition algorithm is needed to decrypt it and make it readable. The researchers added another layer of security by adding an optical filter?in their experiment, they used a piece of scotch tape?that when hit with a laser would project a uniquely speckled diffraction pattern that could be used to verify that the component in question hasn?t been altered or the filter lifted.
Not only is the data represented by the code itself encrypted, but the data is in the QR code itself?-as opposed to a hyperlink, like most other QR codes?-so you don?t have to access the internet to read them, leaving yourself open to a cyberattack.
"An optical code or QR code can be manufactured in such a way that it is very difficult to duplicate," said Bahram Javidi, one of the paper?s authors, in a statement.  "But if you have the right keys, not only can you authenticate the chip, but you can also learn detailed information about the chip and what its specifications are.  And that is important to the person using it."

@_date: 2015-01-04 15:56:32
@_author: Henry Baker 
@_subject: [Cryptography] Imitation Game: Can Enigma/Tunney be Fixed? 
Since The Imitation Game is playing & is quite likely to win some awards, I was wondering if anyone has written an analysis of the Enigma & Lorenz encryption systems using 2015 eyes?
What would be required to "fix" these codes for modern usage, e.g., converting the mechanical bits into software, adding more wheels, etc. ?

@_date: 2015-01-05 06:43:14
@_author: Henry Baker 
@_subject: [Cryptography] Imitation Game: Can Enigma/Tunney be Fixed? 
Perhaps we've all missed the point of the Antikythera
Mechanism; perhaps it was an ancient encoding machine ?  ;-)

@_date: 2015-01-05 18:57:01
@_author: Henry Baker 
@_subject: [Cryptography] Gogo Inflight Internet is intentionally issuing fake 
FYI --
Gogo Inflight Internet is intentionally issuing fake SSL certificates
By Steven Johns  ? 23 hours ago
SSL/TLS is a protocol that exists to ensure that there is an avenue for secure communication over the Internet.  Through the use of cryptography and certificate validation, SSL certificates make man-in-the-middle attacks (where a third party would be able monitor your internet traffic) difficult, so the transmission of things like credit card numbers and user account passwords becomes significantly safer.  In this case, performing a man-in-the-middle attack would require the attacker to attack the SSL certificate first before being able to snoop on someone's traffic.
For whatever reason, however, Gogo Inflight Internet seems to believe that they are justified in performing a man-in-the-middle attack on their users.  Adrienne Porter Felt, an engineer that is a part of the Google Chrome security team, discovered while on a flight that she was being served SSL certificates from Gogo when she was requesting Google sites.  Looking at the issuer of the certificate, rather than being issued by Google, it was being issued by Gogo.
    hey  why are you issuing *.google.com certificates on your planes? pic.twitter.com/UmpIQ2pDaU
    ? Adrienne Porter Felt ( January 2, 2015
This presents itself as an extremely unacceptable action by Gogo which serves in-flight internet to a number of different national and international airlines, including Aeromexico, American Airlines, Air Canada, Japan Airlines and Virgin Atlantic, among many others.
Earlier this year, it was revealed through the FCC that Gogo partnered with government officials to produce "capabilities to accommodate law enforcement interests" that go beyond those outlined under federal law.  It mentioned how it worked closely with law enforcement and directly baked spyware into their service.  If that wasn't bad enough, based on this revelation, Gogo is now intentionally attacking its users' browsing sessions to remove any line of defense that a user may have, and based on their history, it cannot be trusted that it is being done for any legitimate reason.
While Gogo happily waves how heavily it mines its customers' data and is willing to cooperate with governments and law enforcement groups, including undisclosed "third parties," this method of mining goes beyond what anyone would ever expect.  Gogo is also offering in-flight texting and voicemail, and there is no doubt as to how Gogo will be handling the privacy and security elements of those as well.
If you have used Gogo in the past, it is worth considering that all of your communications, including those over SSL/TLS, have been compromised and that you should consider resetting your passwords--at least for Google and Google-related services.  If you intend to use Gogo in the future, do so through the use of Tor or through a secure VPN.
Update: Gogo has issued this statement in response to the situation:
    ?Gogo takes our customer?s privacy very seriously and we are committed to bringing the best internet experience to the sky.  Right now, Gogo is working on many ways to bring more bandwidth to an aircraft.  Until then, we have stated that we don?t support various streaming video sites and utilize several techniques to limit/block video streaming.  One of the recent off-the-shelf solutions that we use proxies secure video traffic to block it.  Whatever technique we use to shape bandwidth, It impacts only some secure video streaming sites and does not affect general secure internet traffic.  These techniques are used to assure that everyone who wants to access the Internet on a Gogo equipped plane will have a consistent browsing experience.
    We can assure customers that no user information is being collected when any of these techniques are being used.  They are simply ways of making sure all passengers who want to access the Internet in flight have a good experience.?

@_date: 2015-01-08 08:46:55
@_author: Henry Baker 
@_subject: [Cryptography] Imitation Game: Can Enigma/Tunney be Fixed? 
The history books still haven't caught up with reality.  In North Africa,
the Allies were apparently able to beat Rommel because Rommel emailed
his next day's plans back to Germany each evening.  But then the Allies
had to work hard to explain how they were able to beat the genius
Rommel w/o breaking his codes.

@_date: 2015-01-13 20:34:16
@_author: Henry Baker 
@_subject: [Cryptography] $10 USB charger steals MS keyboard strokes 
FYI -- Of course, given a keylogger, you get all sorts of other passwords...
Meet KeySweeper, the $10 USB charger that steals MS keyboard strokes
Always-on sniffer remotely uploads all input typed into Microsoft Wireless keyboards.
The weakness that makes exploits like KeySweeper possible is encryption routines built into Microsoft wireless keyboards that can fairly be described as lackadaisical.  Keystrokes are encoded with the XOR algorithm using the keyboard MAC address as the key.  Since the nRF24L01+ chip can read the MAC address, the measure provides little security against moderately determined hackers.  To make things even easier on attackers, all Microsoft keyboards begin with 0xCD as the MAC.  As a result, even if an attacker doesn't know the MAC address, we can decrypt a keystroke, as the alignment will never change, and 0xCD is always the first byte of the MAC (see the section subtitled "Decrypting Keystrokes" for more on this).
Thorsten Schr?der and Max Moser presented a great device, the KeyKeriki, capable of sniffing Microsoft keyboards and have fully reverse engineered the decryption process and produced a device for doing so.  However Travis points out that their device requires two radios and a high-end microcontroller to capture and parse packets at the 2Mbps speed the keyboards communicate at.  Travis' project is great as well, however requires a host computer and will be too large for our covert implementation.  We improve upon these designs in this scenario by requiring only an inexpensive radio and microcontroller, both low power and very small, no computer or fancy radios required.
Thorsten and Max discovered the keystrokes are simply encrypted (xor'd) with the MAC address in ECB mode, which we are able to sniff after using Travis' method of abusing the nRF24L01+ to both sniff and reveal MAC addresses.  This "encryption" is the equivalent of taking a deck of cards, cutting it once, and calling it shuffled.
After further investigation, I found that since we now know all Microsoft keyboards begin with 0xCD as the MAC address, the actual keystroke (in orange below) happens to be aligned with the first byte of the MAC address (0xCD).  This means even if we do not know the MAC address, we can decrypt the keystroke, as the alignment will never change, and 0xCD is always the first byte of the MAC.
An additional discovery is that since the length of the encryption portion of the packet is 11 bytes, the MAC is 5 bytes, and the CRC is each byte xor'd with another (before encryption), something interesting happens.  Since the MAC is xor'd twice, we can also calculate the checksum without knowing the MAC address.  This is because the MAC address is in there in full twice, and xoring any number by itself (or xor the MAC with the MAC) cancels itself out.  The 11th byte is the first byte of the MAC again, which we always know is 0xCD.  This allows us to perform other attacks, such as altering the keystroke and CRC, again without knowing the MAC address.  I will present this and some other fun demonstrations in a future project.

@_date: 2015-01-14 12:57:19
@_author: Henry Baker 
@_subject: [Cryptography] Matt Green's last post on Dual EC DRBG 
FYI --
Discussion of NSA Director of Research Michael Wertheimer's non-apology apology.
Hopefully the last post I'll ever write on Dual EC DRBG
Wednesday, January 14, 2015
Matthew Green The subject of my rant is this fascinating letter authored by NSA cryptologist Michael Wertheimer in February's Notices of the American Mathematical Society.
[Good stuff follows.]

@_date: 2015-01-14 16:05:39
@_author: Henry Baker 
@_subject: [Cryptography] An Ocean of Sanity 
Especially amusing are these parts:
"Download the LPS-Public Deluxe ISO image, version 1.5.6 (5 December 2014).  This version is the same as the LPS-Public edition, but also includes *** LibreOffice and Adobe Reader software. ***"
[Adobe Reader, of course, is a premier entrypoint for all kinds of malware, including that from certain TLA's.]
"LPS differs from traditional operating systems in that it isn't continually patched"
[Whew!  Don't want those hackers to have to continually re-infect that USB or SATA disk.]
"Encryption Wizard (EW) is a simple, strong, *** Java *** file and folder encryptor for protection of sensitive information (FOUO, Privacy Act, CUI, etc.).  EW encrypts all file types for data-in-transit protection and supplements data-at-rest protection.  Without requiring installation or elevated privileges, EW runs on Windows, Mac, Linux, Solaris, and other computers with *** Standard Edition Java. ***"
[Java, of course, is yet another significant source of vulnerabilities, including from the aforementioned TLA's.]
No doubt someone in the blue yonder was using this software to watch a pirated copy of "The Interview" a few days ago when their Twitter account was compromised.

@_date: 2015-01-15 07:16:41
@_author: Henry Baker 
@_subject: [Cryptography] $10 USB charger steals MS keyboard strokes 
"Delegations also received *** mobile phone recharging devices *** which were also reportedly capable of secretly tapping into emails, text messages and telephone calls."
The U.S. govt is tao ethical to ever stoop so low...
Russia 'spied on G20 leaders with USB sticks'
Russia used complimentary 'Trojan horse' pen drives to spy on delegates at G20 summit, it has been reported
By  Nick Squires, Rome, Bruno Waterfield in Brussels and Peter Dominiczak
12:13PM GMT 29 Oct 2013
Russia spied on foreign powers at last month?s G20 summit by giving delegations USB pen drives capable of downloading sensitive information from laptops, it was claimed today.
The devices were given to foreign delegates, including heads of state, at the summit near St Petersburg, according to reports in two Italian newspapers, La Stampa and Corriere della Sera.
Downing Street said David Cameron was not given one of the USB sticks said to have contained a Trojan horse programme, but did not rule out the possibility that officials in the British delegation had received them.
The Prime Minister's official spokesman said: "My understanding is that the Prime Minister didn't receive a USB drive because I think they were a gift for delegates, not for leaders."
Asked if Downing Street staff were given the USBs, he said: "I believe they were part of the gifts for delegates."
Delegations also received mobile phone recharging devices which were also reportedly capable of secretly tapping into emails, text messages and telephone calls.
The latest claims of international espionage come on the heels of allegations that the United States? National Security Agency spied on friendly European powers, including Germany, France, Spain and Italy, by covertly monitoring tens of millions of telephone calls.
The alleged attempts by Moscow to access secret information from foreign powers at the G20 came at a time of high tension between the US and Russia, in particular over Syria and the Russian granting of asylum to former NSA systems analyst Edward Snowden.
Suspicions were first raised about the Russian spying campaign by Herman Van Rompuy, the President of the European Council, according to Corriere della Sera, which carried the story on its front page.
He ordered the USB pen drives and other devices received by the delegates in St Petersburg to be analysed by intelligence experts in Brussels, as well as Germany?s secret service.
A memorandum was then sent out to G20 members, the Italian daily claimed.
?The USB pen drives and the recharging cables were able to covertly capture computer and mobile phone data,? the secret memo said.
The devices were ?a poisoned gift? from Vladimir Putin, claimed La Stampa, the Turin-based daily.
?They were Trojan horses designed to obtain information from computers and cell phones,? the paper said.
The investigations into the alleged spying devices were ongoing, the reports said.
It was not known if every foreign delegation and head of state had been given the covert spying devices.
But Brussels sources said they were baffled by the allegations and expressed total confidence in the security of devices used by EU delegates, including at the St Petersburg summit.
A diplomat said it would be a ?schoolboy error? to put a free memory stick into a computer at such a summit because of obvious security concerns.
He said any security-trained diplomat would be alert to such unvetted ?freebies?.
?We've not found any evidence of a problem," said the European Commission?s official spokesman.
Dmitry Peskov, Vladimir Putin's spokesman, flatly denied the allegations, describing the Italian stories as a poorly disguised effort to divert attention from reports of US intelligence services spying on Angela Merkel and other European allies.
"These are really funny reports, actually. First of all they have no sources.  It is a bold attempt to switch attention from very real problems existing between European capitals and Washington.  It is a classic example of that," he told the Telegraph on Tuesday.

@_date: 2015-01-15 11:56:13
@_author: Henry Baker 
@_subject: [Cryptography] Compression before encryption? 
Sometimes forgotten about compression algorithms: if something is compressed, then at some point it gets uncompressed.  If an attacker can send such a "compressed" message, then (s)he can send a _super-compressed_ message -- one which uncompresses into a super-sized message that will choke any buffer/memory allocation/swap partition/address space.  Such a supercompressed message is a buffer overflow on steroids.  Depending upon the compression algorithm, some uncompressed messages can be several exponentials larger than their compressed versions.  Some programs are unprepared for this explosion of bits.

@_date: 2015-01-16 06:29:41
@_author: Henry Baker 
@_subject: [Cryptography] Compression before encryption? 
The supercompressed files I'm talking about could never be created by
compressing an actual file, because they are larger than the known
universe.  They are generated directly by someone who knows how the
compression algorithm works.  Sometimes, this requires something
analogous to zip-within-zip-within-zip-within-zip, etc., but some
compression schemes already do the recursion for you.  Something
fun for web-crawling robots to chew on for a while.  ;-)

@_date: 2015-01-16 07:16:03
@_author: Henry Baker 
@_subject: [Cryptography] The Crypto Pi 
A fixed security camera will power up always seeing the same scene, so some non-trivial effort is required to ensure randomness.

@_date: 2015-01-16 10:09:07
@_author: Henry Baker 
@_subject: [Cryptography] The Crypto Pi 
If your video camera is compressing with any reasonable video compressor (MPEGx, H.26x, etc.), it already produces differences of images, which can tell you what has changed v what hasn't changed.  So at the very least, you should sample the compressed video stream for your RNG, rather than the uncompressed RNG.  However, that won't be enough, because you want to compare this with what the camera produced _every other time it booted up_.  Thus, you may want to initialize your video compressor in such a way that it thinks that it has _already_ booted up, and it _already_ has reference frames from the last bootup(s) to compare with [this posting is hereby considered world-wide publication for prior art purposes].

@_date: 2015-01-19 07:19:19
@_author: Henry Baker 
@_subject: [Cryptography] DNS subverted to spy on N Korea 
FYI -- If DNS is this easy to hack, we're all in big trouble; DNS needs to be secured ASAP.
"NSA secretly hijacked existing malware to spy on N. Korea, others"
One of the comments on this article:
"nider Smack-Fu Master, in training et Subscriptor"
"There were two things that stuck out to me from this article:"
"1. The NSA from the data they collected were able to "reverse-engineer" the zero day exploit and start using it themselves."
"2. The NSA were able to take control of a bot-net that was targeting, amongst others, an unclassified DOD network by poisoning DNS traffic on the public internet."
"This in turn tells me two things: no one can assume that a zero-day exploit that's been used is not known by other actors who have similar collection capabilities, and we need DNSSEC to protect ourselves from fraudulent DNS results."
"Any attack that can be used by a "friendly" actor, one must assume that the same can be used by an "enemy" actor.  It doesn't take too much imagination to consider a situation where instead of being used to take control over a bot-net, the same techniques could be used for corporate espionage, targeted attacks against individuals who either embarrass the actor, or whose views or message the actor wants to suppress."

@_date: 2015-01-20 20:47:39
@_author: Henry Baker 
@_subject: [Cryptography] coding for compression or secrecy or both or 
Re compressible ciphertexts:
If I take a binary ciphertext and replace every "0" bit with the sequence "00", the result is compressible, but is no less (and no more) secure than the original ciphertext.
In fact, we do something analogous all the time: we embed the ciphertext in various kinds of error-correcting codes, which are then stripped off at the receiving end.
So long as the redundancy of the ciphertext is 100% uncorrelated with the original plaintext, there's nothing wrong with a ciphertext that is highly compressible; one example is steganography, in which one encrypted message is hidden inside another cover message: think of a person blinking Morse Code in a prisoner-of-war video.
The usual reason for preferring uncompressible ciphertext is that it potentially maximizes the bit rate, but if bit rate isn't the most pressing problem, then other goals can be given priority.

@_date: 2015-01-25 11:50:29
@_author: Henry Baker 
@_subject: [Cryptography] Citizenfour Snowden Documentary 
We can only hope that MITM's can't produce "specially crafted" mp4 versions of Citizen4 ...  ;-)
VLC vulnerabilities exposed
Summary:Major memory corruption vulnerabilities have been discovered in the open-source VLC project.
By Charlie Osborne for Zero Day | January 20, 2015 -- 08:06 GMT (00:06 PST)
Follow Vulnerabilities have been discovered in some versions of the popular VLC media player which may allow a cyberattacker to corrupt memory and potentially execute arbitrary code.
According to security researcher Veysel Hatas, who posted the discovery on Full Disclosure last week, one of the vulnerabilities is a DEP access violation vulnerability and the other is a write access flaw.
The VideoLAN project is a community of non-profit developers who create open-source multimedia tools.  The VLC player is one of the most well-known results of this project, and acts as a cross-platform multimedia player and framework that plays most multimedia files as well as DVDs, Audio CDs, VCDs, and various streaming protocols.
The first security vulnerability, discovered on 24 November last year, is a flaw which is triggered as user-supplied input is not properly sanitized when handling a specially crafted FLV file.  The second vulnerability, much the same, is triggered as user-supplied input is not properly sanitized when handling a specially crafted M2V file -- both of which may be malicious and lead to a "context-dependent attacker corrupting memory and potentially executing arbitrary code."
Considered severe, the flaws are present on version 2.1.5 of VLC media player, and were tested through Windows XP SP3.  While this legacy operating system is no longer supported by Microsoft, many users worldwide have not yet updated and may be vulnerable.
The vulnerabilities were reported to the VideoLAN project on 26 December 2014, but no patch has been issued to fix the problem.

@_date: 2015-01-25 15:49:33
@_author: Henry Baker 
@_subject: [Cryptography] Citizenfour Snowden Documentary 
It was mildly amusing to me that Citizenfour.7z is 11MBytes (.9%) _bigger_ than Citizenfour.mp4.
It would have been quite a shock if any AVC CABAC .mp4 video could be compressed by 7z (or any other lossless compression algorithm).  AVC CABAC utilizes arithmetic compression for its lossless compression portion, which is very, very good.

@_date: 2015-01-26 06:57:38
@_author: Henry Baker 
@_subject: [Cryptography] random numbers on virtual machines? 
So what's the best practice for random numbers on a virtual machine.
I found this article:
"How do I get /dev/random to work on an Ubuntu virtual machine?"

@_date: 2015-01-27 07:37:10
@_author: Henry Baker 
@_subject: [Cryptography] Facebook -> SteganographyBook 
FYI -- Apparently, your private pix will be hidden in kitty pix ("kitty porn" ?!?).
Wickr launches encrypted Facebook feature
Cute pictures of kittens could help privacy-conscious consumers disguise the photos they upload to Facebook with a new feature launched by Wickr, the encrypted messaging company.
The San Francisco-based start-up is using steganography ? the art of covered or hidden writing ? to create a more private version of the world?s largest social network.
Wickr?s investors include venture capitalists Gilman Louie, who used to run In-Q-Tel, the CIA?s VC fund...

@_date: 2015-01-29 18:31:49
@_author: Henry Baker 
@_subject: [Cryptography] How the CIA Made Google 
In the same vein, but with a bit less tin foil hattery:

@_date: 2015-01-30 12:02:17
@_author: Henry Baker 
@_subject: [Cryptography] Science Magazine: Breach of Trust 
FYI -- Gee, I can't imagine why the Chinese don't trust
American SW & HW anymore...
Obama may soon be stuck with fielding only his own junior
varsity as a result of this unbelievable NSA cock-up.
BREACH OF TRUST
After the Snowden revelations, U.S. mathematicians are
questioning their long-standing ties with the secretive
National Security Agency
By John Bohannon
IN THE WAKE of the Snowden revelations,
most of the media attention has focused on
NSA?s large-scale harvesting of data from
U.S. citizens.  But it is a more obscure exploit
that concerns Hales and many other math-
ematicians: what they see as an attack on the
very heart of modern Internet security. When you check your bank account online,
for example, the information is encrypted
using a series of large numbers generated
by both the bank server and your own com-
puter.  Generating random numbers that
are truly unpredictable requires physical
tricks, such as measurements from a quan-
tum experiment. Instead, the computers
use mathematical algorithms to generate
pseudorandom numbers.  Although such
numbers are not fundamentally unpredict-
able, guessing them can require more than
the world?s entire computing power.  As
long as those pseudorandom numbers are
kept secret, the encoded information can
safely travel across the Internet, protected
from eavesdroppers?including NSA.
But the agency appears to have created its
own back door into encrypted communica-
tions. ... But it received little atten-
tion until internal NSA memos made public
by Snowden revealed that NSA was the sole
author of the flawed algorithm and that the
agency worked hard behind the scenes to
make sure it was adopted by NIST.

@_date: 2015-07-07 11:02:36
@_author: Henry Baker 
@_subject: [Cryptography] Current Crypto War 
FYI -- Beware of little (6'8") boys who cry "Lone Wolf":
Required reading before tomorrow:
Keys Under Doormats: Mandating insecurity by requiring government access to all data and communications
Harold Abelson, Ross Anderson, Steven M. Bellovin,
Josh Benaloh, Whitfield Diffie, John Gilmore,
Matthew Green, Peter G. Neumann, Susan Landau,
Ronald L. Rivest, Jeffrey I. Schiller, Bruce Schneier,
Michael Specter, and Daniel J. Weitzner

@_date: 2015-07-08 07:30:58
@_author: Henry Baker 
@_subject: [Cryptography] Anti-clipper team re-assembles 
No wonder we have global swarming, what with all the password cracking and bitcoin mining... Perhaps we need a currency -- Passcoin ? -- whose proof-of-work cracks passwords...

@_date: 2015-07-08 08:18:49
@_author: Henry Baker 
@_subject: [Cryptography] Senate Judiciary "Going Dark" https site is 
FYI --
The Senate Judiciary Committee is holding "Going Dark" hearings today, but their own HTTPS web site is "Untrusted" by Firefox!
Isn't this the very definition of "delicious irony" ?
"This Connection is Untrusted"
"You have asked Firefox to connect securely to  but we can't confirm that your connection is secure."
"Normally, when you try to connect securely, sites will present trusted identification to prove that you are going to the right place.  However, this site's identity can't be verified."
"What Should I Do?"
"If you usually connect to this site without problems, this error could mean that someone is trying to impersonate the site, and you shouldn't continue."
Live: Senate Hearings on "Going Dark"
By Cody M. Poplin
Wednesday, July 8, 2015, 9:54 AM
Both the Senate Judiciary Committee and the Senate Intelligence Committee will hold hearings today on strong encrpytion, privacy, and the threat of "Going Dark."
The Senate Judiciary Committee hearing will begin this morning at 10:00 am. FBI Director James Comey and Deputy Attorney General Sally Quillian Yates will appear on the first panel. Panel II will include Cyrus Vance, Jr., Lawfare's Herb Lin, and Peter Swire.
You can watch the hearing live here.
Below are the prepared statements by both members and witnesses.
    Senator Chuck Grassley (R-IA)
    Senator Patrick Leahy (D-VT)
    Deputy Attorney General Sally Q. Yates
    FBI Director James Comey
    Cyrus Vance, Jr.
    Herbert Lin
    Peter Swire
FBI Director James Comey will be the sole witness in this afternoon's Senate Intelligence Committee hearing on the same subject, which will begin at 2:30 pm. You can watch the hearing live on the Committee's website.
"Request unable to be completed."
"The submitted https request was not able to be completed at this time. Please retry your request using http. This may require disabling some browser based plug-ins."

@_date: 2015-07-08 17:08:02
@_author: Henry Baker 
@_subject: [Cryptography] Senate Judiciary "Going Dark" https site is 
mail.com>
After you, Alphonse.
Police have raided the home of an Argentinian security professional who
discovered and reported several vulnerabilities in the electronic ballot
system (Google translation of Spanish original) to be used next week for
elections in the city of Buenos Aires.
The FBI should take a page from the physicists: "if it isn't dark, it doesn't matter".

@_date: 2015-07-10 10:45:16
@_author: Henry Baker 
@_subject: [Cryptography] TSA Blows Off Suggestion To Encrypt Boarding Passes 
FYI -- (I apologize in advance for the lack of formatting in my messages; something in the software used to process my messages strips off all formatting.)
TSA Blows Off Inspector General's Suggestion Boarding Pass Information Be Encrypted

@_date: 2015-07-11 07:12:50
@_author: Henry Baker 
@_subject: [Cryptography] Ad hoc "exceptional access" discussion at Crypto'15 ? 
Is there any appetite for one or more ad hoc sessions to discuss "exceptional access" (aka "keys under doormats" aka "crypto wars") at Crypto'15 in Santa Barbara?

@_date: 2015-07-11 21:36:13
@_author: Henry Baker 
@_subject: [Cryptography] Ad hoc "exceptional access" discussion at 
"Exceptional access" is the term used in the recent MIT "Keys under Doormats" report.  One reason for a discussion session is to come up with better arguments to explain to non-tekkies what the issues are, and why the FBI should be careful what it wishes for.

@_date: 2015-07-13 11:35:22
@_author: Henry Baker 
@_subject: [Cryptography] Super-computer project wanted 
Full GR (General Relativity) movies, a la "Interstellar".
The problem with a lot of GR stuff is that it isn't easy to visualize, so true GR movies would help enormously in teaching the concepts of GR.
You should be able to get access to the SW from the folks at Caltech.
A suggestion: looking for cyclic (at least apparently cyclic, to within the error of the numerical simulations) solutions of 3-body problem in GR.
Crypto content: very high precision chaotic computations can be used for pseudorandom number generators.

@_date: 2015-07-13 18:14:03
@_author: Henry Baker 
@_subject: [Cryptography] Ad hoc "exceptional access" discussion at 
FYI -- This is the sort of thing that needs to be discussed:
(Not that Stewart Baker -- no relation -- would ever be swayed by the Keys Under Doormats arguments.)
But the Keys Under Doormats authors have to do a MUCH better job to convince the general public.
Encryption: if this is the best his opponents can do, maybe Jim Comey has a point
By Stewart Baker July 12
    We share EPAs commitment to ending pollution, said a group of utility executives.  But before the government makes us stop burning coal, it needs to put forward detailed plans for a power plant that is better for the environment and just as cheap as todays plants.  We dont think it can be done, but were happy to consider the governments design  if it can come up with one.
    We take no issue here with law enforcements desire to execute lawful surveillance orders when they meet the requirements of human rights and the rule of law, said a group of private sector encryption experts, Our strong recommendation is that anyone proposing regulations should first present concrete technical requirements, which industry, academics, and the public can analyze for technical weaknesses and for hidden costs.
    Building an airbag that doesnt explode on occasion is practically impossible, declared a panel of safety researchers who work for industry.  We have no quarrel with the regulators goal of 100% safety.  But if the government thinks that goal is achievable, it needs to present a concrete technical design for us to review.  Until then, we urge that industry stick with its current, proven design.
Which of these anti-regulation arguments is being put forward with a straight face today?  Right.  Its the middle one.  Troubled by the likely social costs of ubiquitous strong encryption, the FBI and other law enforcement agencies are asking industry to ensure access to communications and data when the government has a warrant.  And their opponents are making arguments that would be dismissed out of hand if they were offered by any other industry facing regulation.
Behind the opponents demand for concrete technical requirements is the argument that any method of guaranteeing government access to encrypted communications should be treated as a security flaw that inevitably puts everyones data at risk.  In principle, of course, adding a mechanism for government access introduces a risk that the mechanism will not work as intended.  But its also true that adding a thousand lines of code to a program will greatly increase the risk of adding at least one security flaw to the program.  Yet security experts do not demand that companies stop adding code to their programs.  The cost to industry of freezing innovation is deemed so great that the introduction of new security flaws must be tolerated and managed with tactics such as internal code reviews, red-team testing, and bug bounties.
That same calculus should apply to the FBIs plea for access.  There are certainly social and economic costs to giving perfect communications and storage security to everyone  from the best to the worst in society.  Whether those costs are so great that we should accept and manage the risks that come with government access is a legitimate topic for debate.
Unfortunately, if you want to know how great those risks are, you cant really rely on mainstream media, which is quietly sympathetic to opponents of the FBI, or on the internet press, which doesnt even pretend to be evenhanded on this issue.  A good example is the medias distorted history of NSAs 1994 Clipper chip.  That chip embodied the Clinton administrations proposal for strong encryption that escrowed the encryption keys to allow government access with a warrant.
(Full disclosure: the Clipper chip helped to spur the Crypto War of the 1990s, in which I was a combatant on the government side.  Now, like a veteran of the Great War, I am bemused and a little disconcerted to find that the outbreak of a second conflict has demoted mine to Crypto War I.)
The Clipper chip and its key escrow mechanism were heavily scrutinized by hostile technologists, and one, Matthew Blaze, discovered that it was possible with considerable effort to use the encryption offered by the chip while bypassing the mechanism that escrowed the key and thus guaranteed government access.  Whether this flaw was a serious one can be debated.  (Bypassing escrow certainly took more effort than simply downloading and using an unescrowed strong encryption program like PGP, so the flaw may have been more theoretical than real.)  In any event, nothing about Matt Blazes paper questioned the security being offered by the chip, as his paper candidly admitted.  Blaze said, None of the methods given here permit an attacker to discover the contents of encrypted traffic or compromise the integrity of signed messages.  Nothing here affects the strength of the system from the point of view of the communicating parties.  In other words, he may have found a flaw in the Clipp
er chip, but not in the security it provided to users.
The press has largely ignored Blazes caveat.  It doesnt fit the anti-FBI narrative, which is that government access always creates new security holes.  I dont think its an accident that no one talks these days about what Matt Blaze actually found except to say that he discovered security flaws in Clipper.  This formulation allows the reader to (falsely) assume that Blazes research shows that government access always undermines security. The success of this tactic is shown by the many journalists who have fallen prey to this false assumption.  Among the reporters fooled by this line is Craig Timberg of the Washington Post, who wrote, The [Clipper chip] eventually failed amid political opposition but not before Blaze  discovered that the Clipper Chip produced by the NSA had crucial security flaws.  It turned out to be a back door that a skilled hacker could easily break through.  Also taken in was Nicole Perlroth of the New York Times: The final blow [to Clipper] was the discovery by Matt Blaze  of a flaw in the system that would have allowed anyone with technical expertise to gain access to the key to Clipper-encrypted communications.
To her credit, Nicole Perlroth tells me that the New York Times will issue a correction after a three-way Twitter exchange between me, her, and Matt Blaze.  But the fact that the error has also cropped up in the Washington Post suggests a larger problem: Reporters are so sympathetic to one side of this debate that we simply cannot rely on them for a straight story on the security risks of government access.

@_date: 2015-07-14 07:57:44
@_author: Henry Baker 
@_subject: [Cryptography] Ad hoc "exceptional access" discussion at 
My version of Cory Doctorow's argument:
"Smartphones" are Turing Machines intended to be extensible with arbitrary "apps".
Once you grant app-hood, ALL bets are off - both for the good guys & the bad guys.
That's the nature of Turing Machines.
Sorry, Mr. Comey, but distinguishing 'good' from 'bad' apps is undecidable.
So either extensibility is out the window (the end of "smart" phones), or
Mr. Comey is out of luck.

@_date: 2015-07-16 06:12:47
@_author: Henry Baker 
@_subject: [Cryptography] RC4 attack busts WPA-TKIP in less than an hour 
RC4 crypto: one simple attack busts WPA-TKIP in less than an hour

@_date: 2015-07-26 15:10:55
@_author: Henry Baker 
@_subject: [Cryptography] Chertoff & Leiter disagree with Comey; Not Going Dark 
Speaking at the Aspen Security Forum this week, Third Circuit Judge and ex-Secretary of Homeland Security Michael Chertoff and ex-Counterterrorism Director Michael Leiter surprised many by going offscript and disagreeing with FBI Comey's "going dark" stance.
1-hour video:
Chertoff quotes from around 15:50:
"we do not historically organize our society to make it maximally easy for law enforcement even with court orders to get information"
"we're not quite as dark sometimes as we fear we are"
"requiring people to build a vulnerability may be a strategic mistake"
Leiter quotes from around 19:30:
"we undermine our national security by having that back door"
"you have to have a law which addresses reality, and not what you hope reality will be"

@_date: 2015-07-27 09:14:49
@_author: Henry Baker 
@_subject: Why Nasdaq Is Betting On Bitcoins Blockchain 
FYI --
Why Nasdaq Is Betting On Bitcoins Blockchain
Bitcoins public transaction record will help startups keep track of shares and shareholders

@_date: 2015-07-28 07:49:47
@_author: Henry Baker 
@_subject: [Cryptography] BBC: How NSA and GCHQ spied on the Cold War world 
FYI --
How NSA and GCHQ spied on the Cold War world
"Hagelin himself had come to a secret agreement with the founding father of American code-breaking, William F Friedman"

@_date: 2015-07-28 11:13:11
@_author: Henry Baker 
@_subject: [Cryptography] Why Nasdaq Is Betting On Bitc oins 
Q: You mentioned *short sellers*.  One of the biggest problem with short sellers today is that no one checks to make sure that a short seller actually *has* the shares to sell; in some cases, these short sellers don't even bother *borrowing* the shares for up to *six months* after they have already sold them.  Does NASDAQ's blockchain proposal solve this problem?

@_date: 2015-06-08 10:28:14
@_author: Henry Baker 
@_subject: [Cryptography] MITM attacks on Tor exit nodes 
I noticed my first MITM attack on a Tor circuit today, thanks to the recent upgrades of Tor & Firefox.
Basically,  complained that the TLS had been "downgraded" to an obsolete cipher.  After asking Tor to establish a new Tor circuit for this site, the "problem" went away -- because the intermediate & exit nodes were different (and presumably un-MITM'd).
Chinese?  FBI?  Bueller?  Anyone?

@_date: 2015-06-08 15:24:39
@_author: Henry Baker 
@_subject: [Cryptography] Did Intel just execute its warrant canary ? 
FYI -- I conjecture that the second GPU story following less than one month after the first GPU story is not just coincidence, but one of the requirements of a secret National Security Letter to Intel.
The first story shows how GPU's can house malware, while the second story explains that Intel won't be sharing its GPU code where such malware will be housed.
"no reverse engineering, decompilation, or disassembly of this software is permitted"
As feared, the DMCA will be used against those who attempt to look for this malware in Intel GPU's.
GPU-based rootkit and keylogger offer superior stealth and computing power
Proof-of-concept malware may pave the way for future in-the-wild attacks.
by Dan Goodin - May 7, 2015 3:43 pm UTC
Developers have published two pieces of malware that take the highly unusual step of completely running on an infected computer's graphics card, rather than its CPU, to enhance their stealthiness and give them increased computational abilities.
Both the Jellyfish rootkit and the Demon keylogger are described as proofs-of-concept by their pseudo-anonymous developers, whom Ars was unable to contact.  Tapping an infected computer's GPU allows malware to run without the usual software hooks or modifications malware makes in the operating system kernel.  Those modifications can be dead giveaways that a system is infected.
Here's how the developers describe their rootkit:
Jellyfish is a Linux based userland gpu rootkit proof of concept project utilizing the LD_PRELOAD technique from Jynx (CPU), as well as the OpenCL API developed by Khronos group (GPU).  Code currently supports AMD and NVIDIA graphics cards.  However, the AMDAPPSDK does support Intel as well.
Advantages of gpu stored memory:
* No gpu malware analysis tools available on web
* Can snoop on cpu host memory via DMA
* Gpu can be used for fast/swift mathematical calculations like xor'ing or parsing
* Stubs
* Malicious memory is still inside gpu after shutdown
Requirements for use:
* Have OpenCL drivers/icds installed
* Nvidia or AMD graphics card (intel supports amd's sdk)
* Change line 103 in rootkit/kit.c to server ip you want to monitor gpu client from
Stay tuned for more features:
* client listener; let buffers stay stored in gpu until you send magic packet from server
Educational purposes only; authors of this project/demonstration are in no way, shape or form responsible for what you may use this for whether illegal or not.
They provide no technical details about Demon keylogger other than to say it's a proof-of-concept that implements the malware described in this 2013 academic research paper titled You Can Type, but You Cant Hide: A Stealthy GPU-based Keylogger.  The Demon creators stress that they aren't associated with the researchers.
"The key idea behind our approach is to monitor the systems keyboard buffer directly from the GPU via DMA [direct memory access], without any hooks or modifications in the kernel's code and data structures besides the page table," the researchers behind the 2013 paper wrote.  "The evaluation of our prototype implementation shows that a GPU-based keylogger can effectively record all user keystrokes, store them in the memory space of the GPU, and even analyze the recorded data in-place, with negligible runtime overhead."
Aside from malware that taps GPUs to mint Bitcoin and other crypto currencies, Ars isn't aware of malicious software actively circulating in the wild that makes use of infected computers' graphics processors.  And even then, most or all of those titles run mainly on the CPU and offload only the computationally intensive workloads to the GPU.  In March, researchers from Kaspersky Lab documented highly sophisticated malware in the wild that infected firmware that runs 12 different models of hard drives.  The group that created the malware had flown under the radar for 14 years.
In its current form Jellyfish is likely to remain a highly niche undertaking, since it requires a dedicated GPU.  Since many computers don't contain stand-alone graphics cards, such malware might greatly limit the machines that could be infected.  Still, the approach may make sense in certain situations, say for attackers targeting gamers or video enthusiasts, or espionage campaigns where stealth is crucial.  And as readers have pointed out in comments below, it's feasible malware could be developed that runs on graphics processors integrated into CPUs.
Post updated to recast the last paragraph to account for integrated graphics processors, and to add details in the second-to-last paragraph about malware infecting hard-drive firmware.
Intel Skylake & Broxton To Require Graphics Firmware Blobs
Published on 05 June 2015 06:20 PM EDT
Written by Michael Larabel in Intel
Intel's upcoming Skylake and Broxton hardware will require some binary-only firmware blobs by the i915 DRM kernel graphics driver.
Rodrigo Vivi of Intel's Open-Source Technology Center sent in the pull request for landing these binary files into the linux-firmware repository.  Up to now there's been no i915 blobs within the linux-firmware tree.
These first i915 DRM firmware blobs are for Skylake and Broxton for the GuC and DMC.  DMC in this context is the Display Microcontroller, which is present in Skylake (Gen9) and newer and used within the display engine to save and restore its state when entering into low-power states and then resuming.  The DMC is basically saving/restoring display registers across low-power states separate of the kernel.
The GuC engine on Skylake is responsible for workload scheduling on the parallel graphics engines.  Intel explained on 01.org, "GuC is designed to perform graphics workload scheduling on the various graphics parallel engines.  In this scheduling model, host software submits work through one of the 256 graphics doorbells and this invokes the scheduling operation on the appropriate graphics engine.  Scheduling operations include determining which workload to run next, submitting a workload to a command streamer, pre-empting existing workloads running on an engine, monitoring progress and notifying host SW when work is done."  This page also seems to indicate that these firmware blobs are required by the DRM driver rather than being an optional add-on.
The license of these firmware blobs also indicate that redistribution is only allowed in binary form without modification.  Beyond that, "no reverse engineering, decompilation, or disassembly of this software is permitted."
These new firmware blobs will certainly have some open-source enthusiasts less excited now about Skylake, Broadwell's successor beginning to ship later this year, and Broxton meanwhile is the new Atom SoC built using the Goldmont architecture and will feature Skylake graphics.  If there's any good news out of the situation, at least Intel is shipping these firmware files early rather than NVIDIA that with their months-old hardware still hasn't released their GTX 900 Maxwell firmware files needed by the Nouveau driver to provide open-source hardware acceleration.  AMD also tends to be timely with the releasing of their necessary binary-only GPU firmware files for the open-source Linux driver.

@_date: 2015-06-08 17:41:14
@_author: Henry Baker 
@_subject: [Cryptography] Farewall, Alan Turing 
I lean towards the suicide theory, since Turing was incredibly bright,
and very well aware of the poisonous nature of the chemicals he was using.
J. Edgar Hoover's FBI tried very hard, but unsuccessfully, to get Martin
Luther King to commit suicide.  Given the close working relationship of
the U.S. FBI and the British government, and the incredible embarrassment
of having gay Brit spies who also spied for the Soviets & absconded to
Moscow, it isn't much of a stretch to think that Turing was pressured into
committing suicide by the British who were themselves being pressured by
the Americans in order to protect their "special relationship".
Given Turing's precarious legal position and his state of mind, it might
not have been that difficult to convince him that his life was already
over, and that any subsequent existence would be hell on Earth.

@_date: 2015-06-08 17:10:07
@_author: Henry Baker 
@_subject: [Cryptography] Please "ERDJ" Congress to keep the FBI from going 
Please help me find co-sponsors for my new "ERDJ" Congressional Bill: the "Efficiency, Rationality, Decidability and Jobs Bill", which will keep James Comey and the FBI from "going dark".
The Efficiency, Rationality, Decidability and Jobs Bill
Whereas the U.S. is the acknowledged leader in cyber theater;
Whereas the FBI leadership in cyber has training in religion, chemistry and aerospace engineering rather than in mathematics or computer science;
Whereas the White House leadership in cyber has training in public policy and resource planning rather than in mathematics or computer science;
Whereas the efficiency and security of the U.S. economy is being threatened by the difficulty of solving combinatorial problems -- including the decryption of messages of foreign governments, pedophiles, terrorists, drug dealers, pirates, radicals, pedophiles, reporters, drug dealers, terrorists, leftist professors, pirates, union organizers, pedophiles, ordinary citizens, terrorists, open sourcerors, drug dealers, pedophiles and terrorists;
Whereas the U.S. educational system is being subverted by irrational and irreligious teachings;
Whereas the undecidability of mathematics as proposed by (undocumented and worse) aliens such as Hilbert, Goedel and Turing has made mathematics so unnecessarily complex as to put U.S. students at a disadvantage relative to Asians;
Whereas this undecidability interferes with the power and prerogatives of the "decider-in-chief" -- the President of the United States;
Whereas the National Institute of Standards and Technology ("NIST") has been a constant and loyal arm of the U.S. intelligence agencies, known or unknown, secret or public, overt or covert, foreign or domestic, light or dark, stirred or unstirred;
Whereas every Congressional Bill mentions Jobs;
We therefore propose the following changes to Public Law  ]:
I.  NIST is hereby directed to standardize the fact that P = NP, but only within the confines of U.S. borders.
II.  NIST is hereby directed to standardize the mathematical constant pi to be the rational number 22/7.
III.  NIST is hereby directed to remove undecidability from mathematics and education.

@_date: 2015-06-11 12:19:27
@_author: Henry Baker 
@_subject: [Cryptography] Please "ERDJ" Congress to keep the FBI from 
mail.com>
Actually, the TPP (Trans Pacific Partnership) mandates pi=3.2 for all TPP "members", along with requiring English units (pounds, feet, miles, gallons, etc.) when doing any business with U.S. companies.  Encryption content: TPP make it illegal to reverse-engineer any code, even for the purpose of finding flaws and weaknesses.

@_date: 2015-06-15 11:47:40
@_author: Henry Baker 
@_subject: [Cryptography] Sunday Times Snowden Decryption claims 
The Sunday Times article was a complete setup/misdirect by GCHQ, probably at the behest of NSA, to take the heat off the fact that US OPM (why am I the only one who thinks that this means "Other People's Money") made _unencrypted_ records of SF86 data filed by > 4 million govt workers available to nation-state entities.  If the Brits are pulling out their spies, it is more likely due to the OPM breach than anything that Snowden did.
"Employees of intelligence agencies, such as the CIA, generally do not have the records of their clearance checks held by OPM, although some do, officials said." Hmmmm...

@_date: 2015-06-17 10:35:23
@_author: Henry Baker 
@_subject: [Cryptography] Anyone know of crypto hooks in webmail systems? 
Doesn't CryptoCat do its encryption in Javascript, so if you trust Javascript & your browser (ha ha), then there's no leakage.

@_date: 2015-06-17 17:38:32
@_author: Henry Baker 
@_subject: [Cryptography] Is Surespot the Latest Crypto War Victim? 
FYI -- Are warrant canaries going to be part of mainstream crypto protocols from now on?  Perhaps a mathematical analysis of warrant canaries is in order?
Is Surespot the Latest Crypto War Victim?
Posted by samzenpus on Wednesday June 17, 2015 from the lets-see-what-you're-doing dept.
Patrick G. Eddington writes in a Christian Science Monitor op-ed about indications that the government may be snooping on users of Surespot, a free and open source encrypted messaging app for Android and iOS.
Such users include, but are hardly limited to, Islamic State militants.
He writes in the piece: "Has encrypted chat service Surespot been compromised by the US government?
Surespot user and former Army intelligence officer George Maschke recently published a provocative theory suggesting the answer is yes.
Mr. Maschkes key pieces of evidence are intriguing.
In May 2014, he e-mailed 2Fours LLC, which is Surespots parent company, asking whether the company had ever received a National Security Letter (NSL), a court order to provide information, or other government request to cooperate in an investigation.
He was assured in writing that 2Fours had received no such requests.
That changed in November 2014, when Surespots founder, Adam Patacchiola, told Maschke via e-mail that 'we have received an e-mail asking us how to submit a subpoena to us which we havent received yet.'"

@_date: 2015-06-30 09:23:55
@_author: Henry Baker 
@_subject: Bitcoin-Inspired Enigma Mines Encrypted Data 
FYI --
Author: Andy Greenberg
Date of Publication: 06.30.15
Time of Publication: 7:00 am
MITs Bitcoin-Inspired Enigma Lets Computers Mine Encrypted Data
The cryptography behind bitcoin solved a paradoxical problem: a currency with no regulator, that nonetheless cant be counterfeited. Now a similar mix of math and code promises to pull off another seemingly magical feat by allowing anyone to share their data with the cloud and nonetheless keep it entirely private.
On Tuesday, a pair of bitcoin entrepreneurs and the MIT Media Lab revealed a prototype for a system called Enigma, designed to achieve a decades-old goal in data security known as homomorphic encryption: A way to encrypt data such that it can be shared with a third party and used in computations without it ever being decrypted. That mathematical trickwhich would allow untrusted computers to accurately run computations on sensitive data without putting the data at risk of hacker breaches or surveillancehas only become more urgent in an age when millions of users constantly share their secrets with cloud services ranging from Amazon and Dropbox to Google and Facebook. Now, with bitcoins tricks in their arsenal, Enigmas creators say they can now pull off homomorphically encrypted computations more efficiently than ever.
You can see it as a black box, says Guy Zyskind, an MIT Media Lab graduate researcher and one of Enigmas creators. You send whatever data you want, and it runs in the black box and only returns the result. The actual data is never revealed, neither to the outside nor to the computers running the computations inside.
Enigmas homomorphic technique works by mimicking a few of the features of bitcoins decentralized network architecture: It encrypts data by splitting it up into pieces and randomly distributing indecipherable chunks of it to hundreds of computers in the Enigma network known as nodes. Each node performs calculations on its discrete chunk of information before the user recombines the results to derive an unencrypted answer. Thanks to some mathematical tricks the Enigma creators implemented, the nodes are able to collectively perform every kind of computation that computers normally do, but without accessing any other portion of the data except the tiny chunk they were assigned. To keep track of who owns what dataand where any given datas pieces have been distributedEnigma stores that metadata in the bitcoin blockchain, the unforgeable record of messages copied to thousands of computers to prevent counterfeit and fraud in the bitcoin economy. (Like other bitcoin-style decentral
ized crypto schemes, Enigmas architecture can seem almost like a Rube Goldberg machine in its complexity. For a full technical explanation, read the projects whitepaper here. In addition to that whitepaper, Zyskind and Nathan say they plan to publish the open-source code for the project by the end of the summer.)
I can take my age, this one piece of data, and split it into pieces, and give it to ten people, says Zyskind. If you ask each one of those persons, they have only a random chunk. Only by combining enough of those pieces can they decrypt the original data.
Its important to note that any new and unproven encryption scheme should be approached with caution. But if Enigmas homomorphic encryption works as its creators promise, it would have vast implications. Private databases could be hosted and queried in the cloud without any risk of revealing the databases contents. It could also enable a search engine to return search results without ever seeing the users unencrypted search request. Enigmas creators suggest the project could also enable Internet users to safely share all sorts of data with pharmaceutical companies and advertisers without any privacy risksthe companies could run computations on the encrypted data and get useful results without the access to see any specific users data. No one wants to give their data to some company when you dont know what theyll do with it, says Oz Nathan, Enigmas co-creator. But if you have guaranteed privacy, data analysis can be a lot more powerful. People will actually be willing t
o share more.
If you have guaranteed privacy, data analysis can be a lot more powerful. People will actually be willing to share more. oz nathan
The Enigma creators are far from the first to suggest a scheme for homomorphic encryption; IBM researcher Craig Gentry achieved a major breakthrough in 2009 when he came up with the first fully homomorphic encryption schemea mathematical technique that allowed any computation to be performed on encrypted data with no security compromises and none of Enigmas complex network of distributed computers. But Gentrys method was also extremely slow: Performing a computation such as a Google search using it could take as much as a trillion times longer than doing the same task without encryption. Since then, Gentry has dramatically sped up the process, but it still multiplies the time necessary for a calculation by close to a millionfold.
Enigmas creators say their decentralized encryption process, on the other hand, only multiplies the computing requirements for a calculation by less than 100 fold. They hope to further reduce that in the near future to a tenfold increase. They also note that the computing requirements for any Enigma computation depend on the number of nodes involved. The more computers involved, the more secure the users data, but the slower the process.
A considerable hurdle for Enigma, however, is that it requires hundreds or even thousands of users adopt the system and run its code before it can start working securely. To get that initial buy-in, Nathan and Zyskind have created an incentive scheme: Every time someone requests a computation from the Enigma network, he or she pays a bitcoin fee. A tiny part of that money is paid to a computer in the bitcoin network to record Enigmas metadata in the blockchain. But a larger portion of the fee goes to the nodes in the Enigma network as a reward for storing and processing the users encrypted data. And the Enigma software can also be configured to reward the owner of the data, so that an Enigma customer, like an advertiser, can pay users for the privilege of mining their databut without ever seeing it in a decrypted form.
That attempt to recruit as many nodes as possible is designed to combat a fundamental vulnerability in Enigmas scheme: If enough Enigma nodes work together, they can team up to decrypt and steal the users data. But that kind of collusion isnt likely, says Zyskind. He compares the problem to a so-called 51 percent attack in bitcoin, in which a majority of the bitcoin nodes collectively agree to take over the blockchain and defraud users. That sort of bitcoin attack has never occurred, Zyskind points out, and he says the same malicious collaboration problem in Enigma is even less likely.
To keep Enigma nodes honest and ensure that the nodes computations are accurate, the system also includes a security deposit that each must pay in bitcoin to join the network. If a node is found by other nodes in the network to be dishonest, its deposit is seized and distributed to the other nodes. It all balances out and kills the incentive for people to cheat, says Zyskind.
Zyskind and Nathans adviser on Enigma is Sandy Pentland, a well known MIT data scientist who gained fame for his work in data-mining social interactions. In one experiment, for instance, Pentlands researchers put sensor devices called sociometers around hundreds of subjects necks within work environments, and used the resulting data about who talked to whom and even in what tone of voice to learn lessons about what type of group within the office was most productive or who its real managers were, as opposed to those with the highest titles on the org chart.
Enigma may be able to make that mining of deeply personal data safer from a privacy perspective. My work
has always explored a future where sensors and computers are far more ubiquitous than they are today, Pentland writes in an email to WIRED. The advent of bitcoin changed these discussions profoundly by adding tools to protect privacy in a whole new way. Enigma is the result of that collision between bitcoin and privacy and security research.
If Enigma can enable fully homomorphic encryption, says Zyskind, perhaps it can eventually entice users to even make more data available for mining, without the Big Brother fears that data mining usually brings with it.
How can we do more with data, and from a privacy perspective, how can we protect it? Zyskind asks. This is a way to get data privacy now.

@_date: 2015-03-05 10:48:48
@_author: Henry Baker 
@_subject: [Cryptography] MirageOS ? 
Anyone here familiar with MirageOS ?
Supposedly, this system compiles a complete web site into software that boots & runs on bare metal, complete with whatever microkernel is needed just for this software.  The idea is to remove _everything_ that isn't absolutely necessary to run, and thereby reduce the attack surface.

@_date: 2015-03-06 05:35:52
@_author: Henry Baker 
@_subject: [Cryptography] FREAK attack 
I don't know if anyone else has noticed, but this "FREAK" attack has precisely the characteristics that Michael Hayden had in mind with his "NOBUS" (NObody But US) boast; NObody But US has "four acres of Cray computers in the basement".
Fixing FREAK will measurably increase global warming when additional acres are added to Michael's basement; I guess after this winter, Boston might be a good location.
Why everyone is left less secure when the NSA doesn?t help fix security flaws
By Andrea Peterson October 4, 2013 Follow In a frank discussion about the government's approach to vulnerabilities in cyber-infrastructure during a Washington Post Live summit Thursday, former NSA chief Michael Hayden said the agency is not always "ethically or legally compelled" to help fix flaws it knows about.  If the agency thinks that no one else will be able to exploit a vulnerability, it leaves the problem unfixed to aid in its own spying efforts.  That approach might be convenient for the NSA, but it needlessly endangers the security of Americans' computers.
The statement came after an audience member asked if backdoors reported in the NSA leaks introduced vulnerabilities that could be exploited by hackers.  Craig Mundie, a Senior Adviser to the CEO at Microsoft, took a first crack at the question.  He asserted that Microsoft does not engineer in any backdoors nor has there ever been any effort to "facilitate" those kind of things.  However, he also noted he could not speak to government capabilities and added "any [backdoor] mechanism that anybody would put into something obviously creates another class of vulnerabilities."
"Nobody but us"
Hayden argued the concept of vulnerabilities was not unique to the Internet and had been an issue the NSA has dealt with since its founding.  "There's a reason that America's offensive and defensive squads are up at Fort Meade," Hayden said, explaining "because both offense and defense at this world hinges on a question of vulnerability."  Hayden then laid out the concept of NOBUS, which stands for "nobody but us," that he termed "very useful" for making macro-judgments about how to react to vulnerabilities, regardless of if those flaws are "preexistent, not designed, mistake, intended, implanted, [or] whatever":
    You look at a vulnerability through a different lens if even with the vulnerability it requires substantial computational power or substantial other attributes and you have to make the judgment who else can do this?  If there's a vulnerability here that weakens encryption but you still need four acres of Cray computers in the basement in order to work it you kind of think "NOBUS" and that's a vulnerability we are not ethically or legally compelled to try to patch -- it's one that ethically and legally we could try to exploit in order to keep Americans safe from others.
You can watch the full exchange in the video embedded below.
To a certain extent, this NOBUS idea reflects the weighing of the dual defensive and offensive mission of the NSA.  Sure, patching vulnerabilities might effectively make infrastructure safer on a broad scale.  But we're talking about the same agency that reportedly has a 600-some elite offensive hacker squad, Tailored Access Operations or TAO, working out of its headquarters.  And NOBUS also raises a lot of questions about how the intelligence agency determines if something is likely to be exploited by adversaries.
Zero-day exploits
Take the NSA's connection to the zero-day market.  Earlier this year a Freedom of Information Act (FOIA) request revealed that the agency had a significant contract with with Vupen, a French company that deals with zero-day vulnerabilities -- security flaws not yet discovered or patched by vendors.  Sometimes these zero-days are used to exploit systems by the hackers who discover them, sometimes vendors are told about them as part of bug bounty programs, and sometimes they end up in these digital gray markets.
The United States is a major player in these gray markets, although other nations are reported to be also in on the game.  A Reuters's special report from May claimed the United States was the biggest buyer of exploits from this market, with defense contractors and government agencies spending "at least tens of millions of dollars a year just on exploits."  But by their very nature, these exploits would seem to fail the NOBUS test, says Christopher Soghoian, Principal Technologist and Senior Policy Analyst at the ACLU's Speech, Privacy and Technology Project.
"The NSA does not have a monopoly over the exploits that it buys, whether from the black market or from defense contractors.  Those same vulnerabilities can and will be discovered by other researchers too, some of whom may sell them to other governments and criminals," Soghoian said.
And while from a defensive perspective, it makes sense for intelligence agencies to scour these marketplaces and try to buy exploits out of the market, it doesn't seem like that's how it always works.  Reuters spoke to two former White House cybersecurity advisers, Howard Schmidt and Richard Clarke, who thought the government was putting too much focus on offensive capabilities at the expense of business and consumer security.  "If the U.S. government knows of a vulnerability that can be exploited, under normal circumstances, its first obligation is to tell U.S. users," Clarke said, adding "[t]here is supposed to be some mechanism for deciding how they use the information, for offense or defense.  But there isn't."
Developing offensive cyber capabilities Sometimes purchased exploits appear to be making it into government designed malware.  For instance, the Stuxnet worm that targeted Iranian uranium facilities is widely believed to have been a joint American-Israeli development -- and a security researcher told the Economist at least one of the four exploits it relies on was bought rather than engineered in-house.
Stuxnet also illustrates how the deployment of offensive cybertools could be bad for consumer and business IT security.  Stuxnet managed to make it into the digital wild pretty quickly, infecting other industrial systems and companies.  And that's not all.  ?Some of the zero-days used in Stuxnet were later exploited by criminals," said Soghoian.  "Had the NSA provided information about the vulnerabilities to Microsoft, the company could have distributed patches, and those criminals never would have been able to exploit those vulnerabilities.?
?This is just one of many scenarios where offense and defense conflict," when it comes to cybersecurity, Soghoian said.  "For the NSA to have offensive abilities they must leave the public vulnerable.  When you buy a new computer, you don't have to tell the salesman if you are a terrorist, or a drug dealer.  We all use the same computers and software.  What this means is that for the NSA to have the capability to hack into the computer of a terrorist, they need to have the capability to hack into everyone else's computer too.  They're prioritizing offense over defense, that's really what it comes down to.?
But while TAO is reportedly America's national digital offense, we aren't the only ones playing that game.  Earlier this year, a report from cybersecurity firm Mandiant suggested that the Chinese military was behind a large cyber-espionage ring, and hackers who are believed to have ties to the Iranian government have successfully managed to access the control software for oil pipes and breached Navy computer networks.  The growing profile of these other well-supported adversaries might make the case stronger for a focus on making the digital battlefield more secure, not less.
An NSA spokesman declined to comment on Hayden's comments, but defended the NSA's track record on cybersecurity, saying, ?NSA?s Information Assurance Directorate sets the security requirements to protect our government?s national security systems, shares our understanding of vulnerabilities with the private sector, and advocates for the best vulnerability mitigations.  We continue to partner with federal organizations, private industry, and academia.?
Andrea Peterson covers technology policy for The Washington Post, with an emphasis on cybersecurity, consumer privacy, transparency, surveillance and open government.

@_date: 2015-03-10 11:16:51
@_author: Henry Baker 
@_subject: [Cryptography] Apple's Special Sauce: CIA Spying 
FYI -- [I apologize for the length of this article, but it is quite informative]
This article says that both Apple and Microsoft encryption products have been successfully broken, including the "trusted platform module" chips.
The CIA Campaign to Steal Apple?s Secrets
By Jeremy Scahill and Josh Begley    10 Mar 2015
RESEARCHERS WORKING with the Central Intelligence Agency have conducted a multi-year, sustained effort to break the security of Apple?s iPhones and iPads, according to top-secret documents obtained by The Intercept.
The security researchers presented their latest tactics and achievements at a secret annual gathering, called the ?Jamboree,? where attendees discussed strategies for exploiting security flaws in household and commercial electronics.  The conferences have spanned nearly a decade, with the first CIA-sponsored meeting taking place a year before the first iPhone was released.
By targeting essential security keys used to encrypt data stored on Apple?s devices, the researchers have sought to thwart the company?s attempts to provide mobile security to hundreds of millions of Apple customers across the globe.  Studying both ?physical? and ?non-invasive? techniques, U.S. government-sponsored research has been aimed at discovering ways to decrypt and ultimately penetrate Apple?s encrypted firmware.  This could enable spies to plant malicious code on Apple devices and seek out potential vulnerabilities in other parts of the iPhone and iPad currently masked by encryption.
The CIA declined to comment for this story.
The security researchers also claimed they had created a modified version of Apple?s proprietary software development tool, Xcode, which could sneak surveillance backdoors into any apps or programs created using the tool.  Xcode, which is distributed by Apple to hundreds of thousands of developers, is used to create apps that are sold through Apple?s App Store.
The modified version of Xcode, the researchers claimed, could enable spies to steal passwords and grab messages on infected devices.  Researchers also claimed the modified Xcode could ?force all iOS applications to send embedded data to a listening post.?  It remains unclear how intelligence agencies would get developers to use the poisoned version of Xcode.
Researchers also claimed they had successfully modified the OS X updater, a program used to deliver updates to laptop and desktop computers, to install a ?keylogger.?
Other presentations at the CIA conference have focused on the products of Apple?s competitors, including Microsoft?s BitLocker encryption system, which is used widely on laptop and desktop computers running premium editions of Windows.
The revelations that the CIA has waged a secret campaign to defeat the security mechanisms built into Apple?s devices come as Apple and other tech giants are loudly resisting pressure from senior U.S. and U.K. government officials to weaken the security of their products.  Law enforcement agencies want the companies to maintain the government?s ability to bypass security tools built into wireless devices.  Perhaps more than any other corporate leader, Apple?s CEO, Tim Cook, has taken a stand for privacy as a core value, while sharply criticizing the actions of U.S. law enforcement and intelligence agencies.
?If U.S. products are OK to target, that?s news to me,? says Matthew Green, a cryptography expert at Johns Hopkins University?s Information Security Institute.  ?Tearing apart the products of U.S. manufacturers and potentially putting backdoors in software distributed by unknowing developers all seems to be going a bit beyond ?targeting bad guys.?  It may be a means to an end, but it?s a hell of a means.?
Apple declined to comment for this story, instead pointing to previous comments Cook and the company have made defending Apple?s privacy record.
SECURITY RESEARCHERS from Sandia National Laboratories presented their Apple-focused research at a secret annual CIA conference called the Trusted Computing Base Jamboree.  The Apple research and the existence of the conference are detailed in documents provided to The Intercept by National Security Agency whistleblower Edward Snowden.
The conference was sponsored by the CIA?s Information Operations Center, which conducts covert cyberattacks.  The aim of the gathering, according to a 2012 internal NSA wiki, was to host ?presentations that provide important information to developers trying to circumvent or exploit new security capabilities,? as well as to ?exploit new avenues of attack.?  NSA personnel also participated in the conference, through the NSA?s counterpart to the CIA?s Trusted Computing Base, according to the document.  The NSA did not provide comment for this story.
The Jamboree was held at a Lockheed Martin facility inside an executive office park in northern Virginia.  Lockheed is one of the largest defense contractors in the world; its tentacles stretch into every aspect of U.S. national security and intelligence.  The company is akin to a privatized wing of the U.S. national security state ? more than 80 percent of its total revenue comes from the U.S. government.  Lockheed also owns Sandia Labs, which is funded by the U.S. government, whose researchers have presented Apple findings at the CIA conference.
?Lockheed Martin?s role in these activities should not be surprising given its leading role in the national surveillance state,? says William Hartung, director of the Arms and Security Project at the Center for International Policy and author of Prophets of War, a book that chronicles Lockheed?s history.  ?It is the largest private intelligence contractor in the world, and it has worked on past surveillance programs for the Pentagon, the CIA and the NSA.  If you?re looking for a candidate for Big Brother, Lockheed Martin fits the bill.?
The Apple research is consistent with a much broader secret U.S. government program to analyze ?secure communications products, both foreign and domestic? in order to ?develop exploitation capabilities against the authentication and encryption schemes,? according to the 2013 Congressional Budget Justification.  Known widely as the ?Black Budget,? the top-secret CBJ was provided to The Intercept by Snowden and gives a sprawling overview of the U.S. intelligence community?s spending and architecture.  The White House did not respond to a request for comment.
As of 2013, according to the classified budget, U.S. intelligence agencies were creating new capabilities against dozens of commercially produced security products, including those made by American companies, to seek out vulnerabilities.
Last week, CIA Director John Brennan announced a major reorganization at the agency aimed, in large part, at expanding U.S. cyber-operations.  The Information Operations Center, which organized the Jamboree conferences, will be folded into a new Directorate of Digital Innovation.  Notwithstanding its innocuous name, a major priority of the directorate will be offensive cyberattacks, sabotage and digital espionage.  Brennan said the CIA reorganization will be modeled after the agency?s Counterterrorism Center, which runs the U.S. targeted killing and drone program.
THE DOCUMENTS do not address how successful the targeting of Apple?s encryption mechanisms have been, nor do they provide any detail about the specific use of such exploits by U.S. intelligence.  But they do shed light on an ongoing campaign aimed at defeating the tech giant?s efforts to secure its products, and in turn, its customers? private data.
?Spies gonna spy,? says Steven Bellovin, a former chief technologist for the U.S. Federal Trade Commission and current professor at Columbia University.  ?I?m never surprised by what intelligence agencies do to get information.  They?re going to go where the info is, and as it moves, they?ll adjust their tactics.  Their attitude is basically amoral: whatever works is OK.?
Bellovin says he generally supports efforts by U.S. intelligence to ?hack? devices ? including Apple?s ? used by terrorists and criminals, but expressed concern that such capabilities could be abused.  ?There are bad people out there, and it?s reasonable to seek information on them,? he says, cautioning that ?inappropriate use ? mass surveillance, targeting Americans without a warrant, probably spying on allies ? is another matter entirely.?
In the top-secret documents, ranging from 2010 through 2012, the researchers appear particularly intent on extracting encryption keys that prevent unauthorized access to data stored ? and firmware run ? on Apple products.
?The Intelligence Community (IC) is highly dependent on a very small number of security flaws, many of which are public, which Apple eventually patches,? the researchers noted in an abstract of their 2011 presentation at the Jamboree.  But, they promised, their presentation could provide the intelligence community with a ?method to noninvasively extract? encryption keys used on Apple devices.  Another presentation focused on physically extracting the key from Apple?s hardware.
A year later, at the 2012 Jamboree, researchers described their attacks on the software used by developers to create applications for Apple?s popular App Store.  In a talk called ?Strawhorse: Attacking the MacOS and iOS Software Development Kit,? a presenter from Sandia Labs described a successful ?whacking? of Apple?s Xcode ? the software used to create apps for iPhones, iPads and Mac computers.  Developers who create Apple-approved and distributed apps overwhelmingly use Xcode, a free piece of software easily downloaded from the App Store.
The researchers boasted that they had discovered a way to manipulate Xcode so that it could serve as a conduit for infecting and extracting private data from devices on which users had installed apps that were built with the poisoned Xcode.  In other words, by manipulating Xcode, the spies could compromise the devices and private data of anyone with apps made by a poisoned developer ? potentially millions of people.  ?Trying to plant stuff in Xcode has fascinating implications,? says Bellovin.
The researchers listed a variety of actions their ?whacked? Xcode could perform, including:
? ?Entice? all Mac applications to create a ?remote backdoor? allowing undetected access to an Apple computer.
? Secretly embed an app developer?s private key into all iOS applications.  (This could potentially allow spies to impersonate the targeted developer.)
? ?Force all iOS applications? to send data from an iPhone or iPad back to a U.S. intelligence ?listening post.?
? Disable core security features on Apple devices.
For years, U.S. and British intelligence agencies have consistently sought to defeat the layers of encryption and other security features used by Apple to protect the iPhone.  A joint task force comprised of operatives from the NSA and Britain?s Government Communications Headquarters, formed in 2010, developed surveillance software targeting iPhones, Android devices and Nokia?s Symbian phones.  The Mobile Handset Exploitation Team successfully implanted malware on iPhones as part of WARRIOR PRIDE, a GCHQ framework for secretly accessing private communications on mobile devices.
That program was disclosed in Snowden documents reported on last year by The Guardian.  A WARRIOR PRIDE plugin called NOSEY SMURF allowed spies to remotely and secretly activate a phone?s microphone.  Another plugin, DREAMY SMURF, allowed intelligence agents to manage the power system on a phone and thus avoid detection.  PARANOID SMURF was designed to conceal the malware in other ways.  TRACKER SMURF allowed ultra-precise geolocating of an individual phone.  ?[If] its [sic] on the phone, we can get it,? the spies boasted in a secret GCHQ document describing the targeting of the iPhone.
All of the SMURF malware ? including the plugin that secretly turns on the iPhone?s microphone ? would first require that agencies bypass the security controls built into the iOS operating system.  Spies would either need to hack the phone in order to plant their malware on it, or sneak a backdoor into an app the user installed voluntarily.  That was one of the clear aims of the Apple-focused research presented at the CIA?s conference.
?The U.S. government is prioritizing its own offensive surveillance needs over the cybersecurity of the millions of Americans who use Apple products,? says Christopher Soghoian, the principal technologist at the American Civil Liberties Union.  ?If U.S. government-funded researchers can discover these flaws, it is quite likely that Chinese, Russian and Israeli researchers can discover them, too.  By quietly exploiting these flaws rather than notifying Apple, the U.S. government leaves Apple?s customers vulnerable to other sophisticated governments.?
Security experts interviewed by The Intercept point out that the SMURF capabilities were already available to U.S. and British intelligence agencies five years ago.  That raises the question of how advanced the current capacity to surveil smartphone users is, especially in light of the extensive resources poured into targeting the products of major tech companies.  One GCHQ slide from 2010 stated that the agency?s ultimate goal was to be able to ?Exploit any phone, anywhere, any time.?
THE FIRST JAMBOREE took place in 2006, just as Apple was preparing to unveil its highly-anticipated iPhone.  In March 2010, according to a top-secret document, during a talk called ?Rocoto: Implanting the iPhone,? a presenter discussed efforts to target the iPhone 3G.  In addition to analyzing the device?s software for potential vulnerabilities, the presentation examined ?jailbreak methods,? used within the iPhone community to free phones from their built-in constraints, that could be leveraged by intelligence agencies.  ?We will conclude with a look ahead at future challenges presented by the iPhone 3GS and the upcoming iPad,? the abstract noted.  Over the years, as Apple updates its hardware, software and encryption methods, the CIA and its researchers study ways to break and exploit them.
The attempts to target vulnerabilities in Apple?s products have not occurred in a vacuum.  Rather, they are part of a vast multi-agency U.S./U.K. effort to attack commercial encryption and security systems used on billions of devices around the world. U.S. intelligence agencies are not just focusing on individual terrorists or criminals ? they are targeting the large corporations, such as Apple, that produce popular mobile devices.
?Every other manufacturer looks to Apple.  If the CIA can undermine Apple?s systems, it?s likely they?ll be able to deploy the same capabilities against everyone else,? says Green, the Johns Hopkins cryptographer.  ?Apple led the way with secure coprocessors in phones, with fingerprint sensors, with encrypted messages.  If you can attack Apple, then you can probably attack anyone.?
According to the Black Budget, U.S. intelligence agencies have tech companies dead in their sights with the aim of breaking or circumventing any existing or emerging encryption or antiviral products, noting the threat posed by ?increasingly strong commercial? encryption and ?adversarial cryptography.?
The Analysis of Target Systems Project produced ?prototype capabilities? for the intelligence community, enabled ?the defeat of strong commercial data security systems? and developed ways ?to exploit emerging information systems and technologies,? according to the classified budget.  The project received $35 million in funding in 2012 and had more than 200 personnel assigned to it.  By the end of 2013, according to the budget, the project would ?develop new capabilities against 50 commercial information security device products to exploit emerging technologies,? as well as new methods that would allow spies to recover user and device passwords on new products.
Among the project?s missions:
? Analyze ?secure communications products, both foreign and domestic produced? to ?develop exploitation capabilities against the authentication and encryption schemes.?
? ?[D]evelop exploitation capabilities against network communications protocols and commercial network security products.?
? ?Anticipate future encryption technologies? and ?prepare strategies to exploit those technologies.?
? ?Develop, enhance, and implement software attacks against encrypted signals.?
? ?Develop exploitation capabilities against specific key management and authentication schemes.?
? ?[D]evelop exploitation capabilities against emerging multimedia applications.?
? Provide tools for ?exploiting? devices used to ?store, manage, protect, or communicate data.?
? ?Develop methods to discover and exploit communication systems employing public key cryptography? and ?communications protected by passwords or pass phrases.?
? Exploit public key cryptography.
? Exploit Virtual Private Networks, or VPNs, which allow people to browse the Internet with increased security and anonymity.
The black budget also noted that the U.S. intelligence community partners with ?National Laboratories? to conduct the type of research presented at the CIA?s annual Jamboree conference.  It confirms the U.S. government?s aggressive efforts to steal encryption and authentication keys, as occurred in the NSA and GCHQ operations against Gemalto, the world?s largest manufacturer of SIM cards, through the use of Computer Network Exploitation attacks.  In that case, spy agencies penetrated Gemalto?s internal networks and cyberstalked its employees to steal mass quantities of keys used to encrypt mobile phone communications.
The CIA?s Information Operations Center is currently the second largest of the spy agency?s specialized centers.  It not only conducts cyber-ops, but has operated covertly in other nations, working to develop assets from targeted countries to assist in its cyber-surveillance programs, according to the Black Budget.  At times, its personnel brief the president.
AT THE CIA?s Jamboree in 2011, the computer researchers conducted workshops where they revealed the specifics of their efforts to attack one of the key privacy elements of Apple?s mobile devices.  These machines have two separate keys integrated into the silicon of their Apple-designed processors at the point of manufacture.  The two, paired together, are used to encrypt data and software stored on iPhones and iPads.  One, the User ID, is unique to an individual?s phone, and is not retained by Apple.  That key is vital to protecting an individual?s data and ? particularly on Apple?s latest devices ? difficult to steal.  A second key, the Group ID, is known to Apple and is the same across multiple Apple devices that use the same processor.  The GID is used to encrypt essential system software that runs on Apple?s mobile devices.
The focus of the security researchers, as described at the CIA conferences, was to target the GID key, which Apple implants on all devices that use the same processors.  For instance, Apple?s A4 processor was used in the iPhone 4, the iPod Touch and the original iPad.  All of those devices used the same GID.  As Apple designs new processors and faster devices that use those processors, the company creates new GIDs.  If someone has the same iPhone as her neighbor, they have the exact same GID key on their devices.  So, if intelligence agencies extract the GID key, it means they have information useful to compromising any device containing that key.
At the 2011 Jamboree conference, there were two separate presentations on hacking the GID key on Apple?s processors.  One was focused on non-invasively obtaining it by studying the electromagnetic emissions of ? and the amount of power used by ? the iPhone?s processor while encryption is being performed.  Careful analysis of that information could be used to extract the encryption key.  Such a tactic is known as a ?side channel? attack.  The second focused on a ?method to physically extract the GID key.?
Whatever method the CIA and its partners use, by extracting the GID ? which is implanted on the processors of all Apple mobile devices ? the CIA and its allies could be able to decrypt the firmware that runs on the iPhone and other mobile devices.  This would allow them to seek out other security vulnerabilities to exploit.  Taken together, the documents make clear that researching each new Apple processor and mobile device, and studying them for potential security flaws, is a priority for the CIA.
According to the 2011 document describing the Jamboree presentations on Apple?s processor, the researchers asserted that extracting the GID key could also allow them to look for other potential gateways into Apple devices.  ?If successful, it would enable decryption and analysis of the boot firmware for vulnerabilities, and development of associated exploits across the entire A4-based product-line, which includes the iPhone 4, the iPod touch and the iPad.?
At the CIA conference in 2012, Sandia researchers delivered a presentation on Apple?s A5 processor.  The A5 is used in the iPhone 4s and iPad 2.  But this time, it contained no abstract or other details, instructing those interested to contact a CIA official on his secure phone or email.
?If I were Tim Cook, I?d be furious,? says the ACLU?s Soghoian.  ?If Apple is mad at the intelligence community, and they should be, they should put their lawyers to work.  Lawsuits speak louder than words.?
FOR YEARS, Apple has included encryption features in the products it sells to consumers.  In 2014, the company dramatically broadened the types of data stored on iPhones that are encrypted, and it incorporated encryption by default into its desktop and laptop operating system.  This resulted in criticism from leading law enforcement officials, including the FBI director.  The encryption technology that Apple has built into its products ? along with many other security features ? is a virtual wall that separates cybercriminals and foreign governments from customer data.  But now, because Apple claims it can no longer extract customer data stored on iPhones, because it is encrypted with a key the company does not know, the U.S. government can be locked out too ? even with a search warrant.  The FBI director and other U.S. officials have referred to the advent of the encryption era ? where previously accessible data and communications may now be off limits because of the security tec
hnology protecting them ? as ?going dark.?
In the face of this rising challenge to its surveillance capabilities, U.S. intelligence has spent considerable time and resources trying to find security vulnerabilities in Apple?s encryption technology, and, more broadly, in its products, which can be leveraged to install surveillance software on iPhones and Macbooks.  ?The exploitation of security flaws is a high-priority area for the U.S. intelligence community, and such methods have only become more important as U.S. technology companies have built strong encryption into their products,? says the ACLU?s Soghoian.
Microsoft has, for nearly a decade, included BitLocker, an encryption technology that protects data stored on a computer, in its Windows operating system.  Unlike Apple, which made encryption available to all customers, Microsoft had included this feature only in its more expensive premium and professional versions of Windows, up until a few years ago.  BitLocker is designed to work with a Trusted Platform Module, a special security chip included in some computers, which stores the encryption keys and also protects against unauthorized software modification.
Also presented at the Jamboree were successes in the targeting of Microsoft?s disk encryption technology, and the TPM chips that are used to store its encryption keys.  Researchers at the CIA conference in 2010 boasted about the ability to extract the encryption keys used by BitLocker and thus decrypt private data stored on the computer.  Because the TPM chip is used to protect the system from untrusted software, attacking it could allow the covert installation of malware onto the computer, which could be used to access otherwise encrypted communications and files of consumers. Microsoft declined to comment for this story.
In the wake of the initial Snowden disclosures, Apple CEO Tim Cook has specifically denounced the U.S. government?s efforts to compel companies to provide backdoor access to their users? data.
?I want to be absolutely clear that we have never worked with any government agency from any country to create a backdoor in any of our products or services.  We have also never allowed access to our servers.  And we never will,? Cook said last September in announcing Apple?s new privacy policy.  More recently, Cook said, ?None of us should accept that the government or a company or anybody should have access to all of our private information.  This is a basic human right.  We all have a right to privacy.  We shouldn?t give it up.  We shouldn?t give in to scare-mongering.?
As corporations increasingly integrate default encryption methods and companies like Apple incorporate their own indigenous encryption technologies into easy-to-use text, voice and video communication platforms, the U.S. and British governments are panicking.  ?Encryption threatens to lead all of us to a very dark place,? declared FBI Director James Comey in an October 2014 lecture at the Brookings Institution.  Citing the recent moves by Apple to strengthen default encryption on its operating systems, and commitments by Google to incorporate such tools, Comey said, ?This means the companies themselves won?t be able to unlock phones, laptops, and tablets to reveal photos, documents, e-mail, and recordings stored within.?
Under current U.S. regulations, law enforcement agencies can get a court order to access communications channeled through major tech companies and wireless providers.  But if those communications are encrypted through a process not accessible by any involved company, the data is essentially meaningless, garbled gibberish.  ?In a world in which data is encrypted, and the providers don?t have the keys, suddenly, there is no one to go to when they have a warrant,? says Soghoian.  ?That is, even if they get a court order, it doesn?t help them.  That is what is freaking them out.?
Comey alleged that ?even a supercomputer would have difficulty with today?s high-level encryption,? meaning a ?brute force? attempt to decrypt intercepted communications would be ineffective, and, even if successful, time-consuming.
?Encryption isn?t just a technical feature; it?s a marketing pitch,? Comey added.  ?But it will have very serious consequences for law enforcement and national security agencies at all levels.  Sophisticated criminals will come to count on these means of evading detection.  It?s the equivalent of a closet that can?t be opened.  A safe that can?t be cracked.?
A few months after Comey?s remarks, Robert Litt, the general counsel for the Office of the Director of National Intelligence, also appeared at Brookings.  ?One of the many ways in which Snowden?s leaks have damaged our national security is by driving a wedge between the government and providers and technology companies, so that some companies that formerly recognized that protecting our nation was a valuable and important public service now feel compelled to stand in opposition,? Litt said.  He appealed to corporations to embrace ?a solution that does not compromise the integrity of encryption technology but that enables both encryption to protect privacy and decryption under lawful authority to protect national security.?
Green, the Johns Hopkins professor, argues that U.S. government attacks against the products of American companies will not just threaten privacy, but will ultimately harm the U.S. economy.  ?U.S. tech companies have already suffered overseas due to foreign concerns about our products? security,? he says.  ?The last thing any of us need is for the U.S. government to actively undermine our own technology industry.?
The U.S. government is certainly not alone in the war against secure communications.  British Prime Minister David Cameron has suggested that if he is re-elected, he may seek to ban encrypted chat programs that do not provide backdoor access to law enforcement.  ?Are we going to allow a means of communications which it simply isn?t possible to read?? Cameron said in a speech in England earlier this year.  ?My answer to that question is: ?No, we must not.??
When the Chinese government recently tried to force tech companies to install a backdoor in their products for use by Chinese intelligence agencies, the U.S. government denounced China.  ?This is something that I?ve raised directly with President Xi,? President Obama said in early March.  ?We have made it very clear to them that this is something they are going to have to change if they are to do business with the United States.?  But China was actually following the U.S. government?s lead.  The FBI has called for an expansion of U.S. law, which would require Apple and its competitors to design their products so that all communications could be made available to government agencies.  NSA officials have expressed similar sentiments.
?Obama?s comments were dripping with hypocrisy,? says Trevor Timm, executive director of the Freedom of the Press Foundation.  ?Don?t get me wrong, his actual criticism of China for attempting to force tech companies to install backdoors was spot on ? now if only he would apply what he said to his own government.  Since he now knows backdooring encryption is a terrible policy that will damage cybersecurity, privacy, and the economy, why won?t he order the FBI and NSA to stop pushing for it as well??
Andrew Fishman, Alleen Brown, Andrea Jones, Ryan Gallagher, Morgan Marquis-Boire, and Micah Lee contributed to this story.
Documents published with this article:
TCB Jamboree 2012 Invitation
Strawhorse: Attacking the MacOS and iOS Software Development Kit
TPM Vulnerabilities to Power Analysis and An Exposed Exploit to Bitlocker
TCB Jamboree 2012
Apple A4/A5 Application Processors Analysis
Differential Power Analysis on the Apple A4 Processor
Secure Key Extraction by Physical De-Processing of Apple?s A4 Processor
Rocoto: Implanting the iPhone
Smurf Capability ? iPhone
Black Budget: Cryptanalysis & Exploitation Services ? Analysis of Target Systems
Note: An earlier draft of this story incorrectly suggested that the iOS Group ID is used to sign software.
Disclosure: Freedom of the Press Foundation, which Trevor Timm represents, has received grant funding from First Look Media, The Intercept?s parent company.  Intercept co-founders Glenn Greenwald and Laura Poitras are on the board of the organization.
Email the authors: jeremy.scahill at theintercept.com, josh.begley at theintercept.com

@_date: 2015-03-11 08:21:01
@_author: Henry Baker 
@_subject: [Cryptography] Digital Certificate Forensics: Clinton Email Server 
FYI --
Digital Certificate Forensics: What Venafi TrustNet Tells Us about the Clinton Email Server
March 11th, 2015 - Posted by: Kevin Bocek, VP, Security Strategy & Threat Intelligence
3-month gap before encryption enabled for browsers, smartphones, and tablets starting in 2009
Venafi TrustNet is the world?s first enterprise certificate reputation service.  TrustNet can identify certificate misuse, perform forensic analysis, and predict vulnerabilities that need to be fixed to protect the Global 5000 and governments.  To achieve this, TrustNet has acquired, maintains, and is continuously adding to the world?s largest database of digital certificates and associated metadata.  TrustNet is able to go back in time and identify how digital certificates were used in the past, providing a new type of forensics capability to the IT security community.
Digital certificates and their corresponding cryptographic keys are incredibly powerful.  They solved the biggest barriers to using the Internet: how do I know that a website is what it says it is and that communications with the site are private?  But this is also why certificates are so interesting to bad guys for misuse.  It?s also why cybersecurity experts, like Intel, predict stolen certificates will be the next big hacker marketplace.  With this increasing misuse by attackers, how do we keep certificates safe?  Venafi protects the trust established by keys and certificates for the Global 5000 and governments.
Digital certificate analysis for clintonemail.com
In the past week, there have been questions about the level of security, use, and configuration of former Secretary of State Hillary Clinton?s personal email server.  Specifically, there have been concerns that the server may have been vulnerable to eavesdropping and compromise.  TrustNet found that at least 3 digital certificates were used with clintonemail.com since 2009.  Operators of clintonemail.com obtained these certificates so the site could be uniquely distinguished (another clintonemail.com would not show as being secured without the certificate) and the site would use strong encryption to keep data transmissions private.  These certificates were obtained validly and enabled web-based encryption for applications.  Based on TrustNet analyst, Venafi can conclude clintonemail.com was enabled for browser, smartphone, and tablet encryption since 2009 and can operate using encryption through at least 2018.  However, for the first 3 months of Secretary Clinton?s term, access to
 the server was not encrypted or authenticated with a digital certificate.  During this time, Secretary Clinton travelled to China, Egypt, Israel, South Korea and other locations outside of the U.S.
Note: All data in this report was obtained by non-intrusive Internet scanning routinely performed throughout the IT security community to protect the safety and health of the Internet.
Digital Certificate Forensics for clintonemail.com
Venafi TrustNet Analysis
January ? March 2009: No certificates found ? no encryption enabled
March 2009: mail.clintonemail.com Issued by: Network Solutions Valid to: September 2013 Download certificatae file
February 2012: sslvpn.clintonemail.com Issued by: Network Solutions Valid to: February 2013 Download certificatae file
September 2013: mail.clintonemail.com Issued by: GoDaddy Valid to: September 2018 Download certificatae file
First clintonemail.com digital certificate obtained in 2009 from Network Solutions
Starting in late March 2009, mail.clintonemail.com was enabled with a Network Solutions? digital certificate and encryption for web-based applications like Outlook Web Access.  This was 3 months after Secretary Clinton took office.  The clintonemail.com domain was registered with Network Solutions in January 2009 ? 8 days before Secretary Clinton was confirmed by the U.S. Senate.  Therefore, from January to end of March 2009 access to clintonemail.com did not use encryption.
Once the digital certificate was installed in March 2009, all access with a desktop web browser, smartphone, or table was encrypted, even on government networks designed to inspect traffic.  However, this doesn?t mean that email sent to/from the account would be encrypted ? just accessing the server.
Replacement clintonemail.com digital certificate obtained in 2013 from GoDaddy
The first certificate obtained for clintonemail.com was set to expire on 15 September 2013.  It was replaced a few days before this expiration with a new certificate from GoDaddy set to expire in 2018.  This is the certificate that remains running on the server in March 2015.  Microsoft Outlook Web Access and Microsoft IIS were confirmed by Venafi to be running on the server.  At the time of inspection, communications between the server and applications were being authenticated and encrypted.
Certificate for SSL VPN service run from clintonemail.com that was issued in February 2012
As reported elsewhere, the server also appears to have run an SSL VPN ? an authenticated and encrypted tunnel through which other web pages on other servers could be accessed.  TrustNet found the sslvpn.clintonemail.com certificate. It was issued in 2012 and expired in 2013.  Venafi could not confirm the continued operation of an SSL VPN or the sites to which it may have gated access.
Security Implications
Online banking, shopping, and confidential government communications wouldn?t be possible without the trust established by digital certificates.  Hundreds of billions of dollars in trade around the world also depends on it, as does the future of secure communications and computing.  From airplanes to cars to our smartphones, all of these technologies are dependent on the trust digital certificates and their associated cryptographic keys provide.  And, they are being used more and more every day.  It?s also why bad guys are ferociously going after them.  Threat research from FireEye, Intel, Kaspersky, and Mandiant consistently identifies the misuse of keys and certificates as an important part of APT and cybercriminal operations.  And Gartner expects by 2017 that 50% of network attacks will be using SSL/TLS.
Clintonemail.com operated for 3 months without a digital certificate.  This means that during the first 3 months of Secretary Clinton?s term in office, web browser, smartphone, and tablet communications would not have been encrypted.  Attackers could have eavesdropped on communications.  As well, the server would not have been uniquely identified as being clintonemail.com and therefore could have been spoofed ? allowing attackers to more easily trick an unsuspecting user of the site to hand over their username and password or other sensitive information.
Obtaining the cryptographic key and digital certificate for clintonemail.com would be an important step for attackers seeking to compromise Secretary of State Clinton or others that might access the server.  With them, bad guys could masquerade as the legitimate site or decrypt what was thought to be private communications.  As a standalone Microsoft Windows Server, the site is very vulnerable.  In 2013, over 800 trojans were known to steal keys and certificates ? and that number has swelled since then.  The use of digital certificates on clintonemail.com provides users with the confidence that they are connecting to the real site and communications cannot be inspected.  But when on government networks, anyone accessing the site and depending on the certificate needs to be highly suspicious.  The site has received tremendous attention and its contents and certificate are likely targets for compromise and misuse.
Venafi will continue to observe this situation and provide updates if new information becomes available.  Venafi TrustNet operates 24x7 to secure and protect Venafi customers, is constantly monitoring the status of certificates around the world, and provides real-time updates to subscribers.  Organizations interested in learning how TrustNet can help can contact Venafi for more information.
I want to offer a special thank you to Hari Nair, Gavin Hill, and the Venafi TrustNet product team who contributed to this research and analysis.

@_date: 2015-03-13 08:42:06
@_author: Henry Baker 
@_subject: [Cryptography] IBM looking at adopting bitcoin technology for major 
FYI -- Perhaps more accurately: "IBM looking at patenting bitcoin technology for major currencies"
Exclusive: IBM looking at adopting bitcoin technology for major currencies
By Gertrude Chavez-Dreyfuss
NEW YORK Thu Mar 12, 2015 4:26pm EDT
(Reuters) - International Business Machines Corp is considering adopting the underlying technology behind bitcoin, known as the "blockchain," to create a digital cash and payment system for major currencies, according to a person familiar with the matter.
The objective is to allow people to transfer cash or make payments instantaneously using this technology without a bank or clearing party involved, saving on transaction costs, the person said.  The transactions would be in an open ledger of a specific country's currency such as the dollar or euro, said the source, who declined to be identified because of a lack of authorization to discuss the project in public.
The blockchain - a ledger, or list, of all of a digital currency's transactions - is viewed as bitcoin's main technological innovation, allowing users to make payments anonymously, instantly, and without government regulation.
Rather than stored on a separate server and controlled by an individual, company, or bank, the ledger is open and accessible to all participants in the bitcoin network.
The proposed digital currency system would work in a similar way.
"When somebody wants to transact in the system, instead of you trying to acquire a bitcoin, you simply say, here are some U.S. dollars," the source said.  "It's sort of a bitcoin but without the bitcoin."
IBM is one of a number of tech companies looking to expand the use of the blockchain technology beyond bitcoin, the digital currency launched six years ago that has spurred a following among investors and tech enthusiasts.
The company has been in informal discussions about a blockchain-tied cash system with a number of central banks, including the U.S. Federal Reserve, the source said.  If central banks approve the concept, IBM will build the secure and scalable infrastructure for the project.
IBM media relations office did not respond to Reuters emails about this story and the Fed declined to comment.
However, there are signs that central banks are already thinking about the innovations that could arise through digital currency systems.  The Bank of England, in a report in September 2014, described the blockchain's open ledger as a "significant innovation" that could transform the financial system more generally.
Instead of having ledgers maintained by banks that act as a record of an individual's transactions, this kind of open ledger would be viewable by everyone using the system, and would use an agreed-upon process for entering transactions into the system.
The project is still in the early stages and constantly evolving, the source said.  It is also unclear how concerns about money-laundering and criminal activities that have hamstrung bitcoin.
Unlike bitcoin, where the network is decentralized and there is no overseer, the proposed digital currency system would be controlled by central banks, the source said.
"These coins will be part of the money supply," the source said.  "It's the same money, just not a dollar bill with a serial number on it, but a token that sits on this blockchain."
According to the plans, the digital currency could be linked to a person's bank account, possibly using a wallet software that would integrate that account with the proposed digital currency ledger.
"We are at a tipping point right now.  It's making a lot more sense for some type of digital cash in the system, that not only saves our government money, but also is a lot more convenient and secure for individuals to use," the source said.
(Reporting by Gertrude Chavez-Dreyfuss; Editing by David Gaffen and Tomasz Janowski)
FILED UNDER: Tech

@_date: 2015-03-13 13:46:21
@_author: Henry Baker 
@_subject: [Cryptography] IBM looking at adopting bitcoin technology for 
Now that "I claim X, where X is well-known, but now I'm doing it with a computer" has been disallowed, we're now going to see "I claim X, where X is well-known, but now I'm doing it with a blockchain".
Cue billions in lawsuits.  Enough to pay for an entire generation of lawyers' kids' college tuition.

@_date: 2015-03-16 12:07:08
@_author: Henry Baker 
@_subject: [Cryptography] Kali Linux security is a joke! 
FYI --
"Downloading Kali Linux"
"Alert!  Always make certain you are downloading Kali Linux from official sources, as well as verifying md5sums against official values.  It would be easy for a malicious entity to modify a Kali install to contain malicious code, and host it unofficially."
No kidding!
So how come whenever you do apt-get in Kali Linux, it accesses  and  ??
Hasn't Kali heard about MITM attacks against http ??
What's the point of verifying md5sums against official values, if Kali can't even get the "official values" securely ??

@_date: 2015-03-18 05:39:06
@_author: Henry Baker 
@_subject: [Cryptography] Kali Linux security is a joke! 
Another issue with HTTP is denial-of-service.  NSA/GCHQ routinely
hijack HTTP for MITM, but even when they can't serve up properly
signed package files, they can make pretty sure that their victims
can't get the properly-signed files from the proper server, either.
Thus, since so many of the recent package updates & upgrades have
to do with security issues (Heartbleed, etc.), NSA/GCHQ can deny
their victims the opportunity to upgrade their security.

@_date: 2015-03-18 12:01:46
@_author: Henry Baker 
@_subject: [Cryptography] Kali Linux security is a joke! 
The Intercept & Der Spiegel.  NSA/GCHQ makes sure that their fake
server responds faster than the real server.

@_date: 2015-03-25 06:39:18
@_author: Henry Baker 
@_subject: [Cryptography] How to crypto secure speed limit signs 
FYI -- In order to keep these Fords from being spoofed, we would need to "secure" each speed limit sign with a crypto signature.  Presumably, this could be done with a QR code. But how to avoid a "replay" attack -- i.e., cloning an existing sign & installing it somewhere else?  Should the QR code crypto sign the sign's GPS coordinates?  Wouldn't that make speed limit signs pretty expensive to manufacture & install?
Ditto with all kinds of other street signs.
Ford: Our latest car gizmo will starve you of fuel if you're speeding
Fighting automatic regulation with automatic adherence
Not as much fun as an angle-grinder to a gatso but a lot more legal
25 Mar 2015 at 08:55, Simon Rockman
Ford has announced a new intelligent speed limiter system which reads traffic signs and reduces fuel flow to keep your vehicle within the speed limit.
As much as the petrolhead lobby decries the direct correlation the road safety brigade makes between speed and safety, current legislation means that if you're driving too fast, regardless of how safely, you?ll usually get fined.
While a traffic officer can make a judgment call, ticket-bots won?t be quite so lenient. Now the Ford tech is fighting automatic regulation with automatic adherence.
The Intelligent Speed Limiter combines current Ford technologies: the Adjustable Speed Limiter and Traffic Sign Recognition, which are both already available on models including the Focus, Mondeo, and Kuga SUV.
At speeds of between 20mph and 120mph the system smoothly decelerates by restricting the fuel supplied to the engine, rather than applying the brakes. Should travelling downhill cause the vehicle to exceed the legislated speed an alarm is sounded.
The limiter also communicates with the on-board navigation system to help accurately maintain the appropriate maximum speed when distances between speed limit signs are greater, for example on long country roads.
Drivers can temporarily override the system by firmly depressing the accelerator pedal.
?We're not just developing cars at Ford, we're also developing technologies to make driving more convenient, safer, and ultimately help improve mobility around the world,? said Pim van der Jagt, executive technical leader, Ford Research & Advanced Engineering.
Maybe the first in line for this should be former Nokia boss Anssi Vanjoki who in 2002 was fined a massive ?116,000 for doing 75km/h in a 50km/h zone on his Harley Davidson. In Finland traffic fines are proportionate to your income.
In 2013, 15,549 drivers in the UK were issued with fines of at least ?100, according to the Department for Transport.
More details on the Ford website.

@_date: 2015-03-25 09:30:27
@_author: Henry Baker 
@_subject: [Cryptography] How to crypto secure speed limit signs 
You bring up excellent points.
I understand that certain high-end German cars can already read & interpret various road signs ("TSR"/"ADAS"), so it should be possible to "spoof" these cars already.  I wonder if anyone has already done such a thing ?
Fake street signs aren't new; an artist even put up a fake freeway sign on one of the Los Angeles interstate highways, and this particular sign remained for a number of years.
Fake roadway signs were used during WWII to sabotage troop & tank movements; one scene in the 1970 movie "Patton" shows the results of such a sabotage.

@_date: 2015-03-25 13:30:18
@_author: Henry Baker 
@_subject: [Cryptography] How to crypto secure speed limit signs 
The problem is that every signed sign is different, because its signature signs both the speed limit itself and the sign's GPS location.
Without signatures, one can have an inventory of "55 MPH" signs, but that won't work with signatures.  Furthermore, the GPS data would have to be accurate to within 10 meters or so to be good, and that might be difficult to determine prior to sending the crew out to actually install the sign.  Therefore, the signature might have to be generated on-site and then the sign's QR code printed onto the sign.
Re GPS files:  I believe that the laws of most countries deal with "posted" speeds, and "posting" currently involves visual signs, not digital databases of GPS coordinates.
Also, changing the "posting" laws by substituting GPS coordinates would then make an entire country's road system vulnerable to a GPS spoofing attack, which could be catastrophic.

@_date: 2015-05-17 19:13:53
@_author: Henry Baker 
@_subject: [Cryptography] Intel SGX: Augean stables piled higher & deeper? 
Perhaps it's just me, or perhaps it's just the lecturer, but this Intel "SGX" looks like BS piled higher & deeper -- i.e., building better places for hackers (including nation-states) to hide their malware, and still more complexity that hasn't been (can't be ?) proven correct.
Intel Software Guard Extensions Innovative Instructions for Next Generation Isolated Execution Frank McKeen Intel Corporation About the talk: This talk describes Intel's Software Guard Extensions (SGX) technology.  SGX provides new tools and hardware facilities to software developers to protect an application's secrets.  In today's computing environment the ability to keep a secret requires the integrity of millions of line of software in the OS, VMM, and application.  SGX creates a trusted environment called an enclave inside the application.  An enclave provides an ability to protect the secret without dependency on the integrity of any other code.  The talk will describe the programming environment, instruction set, and hardware facilities which make up the SGX architecture.
Slides: Download the de-animated slides for this talk in PDF format.
Videos: Join the live presentation. Wednesday April 15, 4:15-5:30.  Requires Microsoft Windows Media player. View video by lecture sequence. Spring 2015 series only, HTML5. Available after 8PM on the days of the lecture.
View Video on YouTube.
About the speaker: Frank McKeen: Principal Engineer, Security Research Lab, Intel, Portland OR, USA. Frank is the inventor of the SGX architecture and leader of the SGX architecture research team. He has previous experience in microprocessor design, security concepts, and trusted computing. He received a BSEE from Northeastern University and is a member of the IEEE.

@_date: 2015-05-19 08:11:57
@_author: Henry Baker 
@_subject: [Cryptography] Intel SGX: Augean stables piled higher & deeper? 
Mathematical proof?
Mathematical proof?
Mathematical proof?
Mathematical proof?
My point is that I can come up with all sorts of ideas that aren't mathematically sound, but which sound good. -- e.g., a program that tests another program for "bad" behavior (something that politicians would love to do, but -- like the transcendental nature of pi -- is not susceptible to politically-motivated laws).
If Intel can't provide sound & complete & public proofs for their wet dreams, then these technologies are simply more BS for the pile.
In the absence of such mathematical proofs, Intel SGX is providing more "security through obscurity" than true security.
The existing experience with UEFI insecurity does not bode well for SGX.
Intel could provide a lot more security by _removing certain misfeatures_ than by adding any new misfeatures.

@_date: 2015-05-19 10:33:01
@_author: Henry Baker 
@_subject: [Cryptography] Intel SGX: Augean stables piled higher & deeper? 
Encryption is (nearly) _always_ broken through "errata".  That's the reason why it is so hard; you can't make even one mistake.
Precisely my point about improving security by _removing_ misfeatures/errata, rather than by adding more.

@_date: 2015-05-20 06:19:21
@_author: Henry Baker 
@_subject: [Cryptography] Intel SGX: Augean stables piled higher & deeper? 
No.  But many/most hardware "improvements" come with serious glitches that are only appreciated in hindsight.
Since SGX is intended as an "improvement" in security, it deserves a much higher level of scrutiny than do other types of HW improvements.  In particular, it deserves some sort of proof that this "improvement" didn't inadvertently (or not: NSA) introduce additional bugs/insecurities.
We spend endless hours debating random number generators, but modifications like this get a pass.  How come?

@_date: 2015-05-21 09:09:55
@_author: Henry Baker 
@_subject: [Cryptography] NVIDIA Dynamic Code Optimization (DCO) 
FYI -- "DCO": Yet more lovely places for malware to hide.  The executing code is "translated" into a microcode buffer, but who gets to be in charge of said translation?
"Those who cast the votes decide nothing.  Those who count the votes decide everything."  -- Josef Stalin
I believe that these DCO processors have already been picked up for widespread use in automobiles, including self-driving cars.
What, me worry?
Stanford EE Computer Systems Colloquium
4:15PM, Wednesday, March 4, 2015
NEC Auditorium, Gates Computer Science Building Room B3
Dynamic Code Optimization and the NVIDIA Denver Processor
Nathan Tuck NVIDIA
About the talk:
NVIDIA's first 64-bit ARM processor, code-named Denver, leverages a host of new technologies to enable high-performance mobile computing.  Implemented in a 28-nm process, the Denver CPU can attain clock speeds of up to 2.5 GHz.  This talk will outline the Denver architecture and describe some of its technological innovations.  In particular this talk will discuss some of the motivations and advantages of dynamic code optimization.
There not downloadable slides for this presentation available at this time.
View Video on YouTube.
About the speaker:
Nathan Tuck has been a member of the DCO and CPU architecture teams at NVIDIA since 2009.
Nathan has spent his professional career walking a crooked line between hardware and software.  As an engineer, he is most interested in working on systems problems.  Professionally, he is most interested in dynamic environments where he can make a large difference.
Contact information:
Nathan Tuck

@_date: 2015-05-23 10:46:51
@_author: Henry Baker 
@_subject: [Cryptography] NVIDIA Dynamic Code Optimization (DCO) 
In a well-ordered universe, there aren't untrusted turtles all the way down;
i.e., there should be a way for _user_ code to turn the d*mn DCO/JIT off.
Unfortunately, there isn't any way to enforce this, or even to check on it.
(The big lie technique.)
For a DCO system to even begin to be trusted, there has to be some mechanism
to inspect the DCO/JIT compiler, and audit its code.  It should be possible
for _userland_ programs to randomly trap & inspect (& "measure"?) the
compiled code buffer.
Otherwise, we have now institutionalized the "split TLB" hack, which enables
malware instructions to hide in an instruction cache while the virus scanner
sees a benign picture in the data cache.

@_date: 2015-05-28 06:13:25
@_author: Henry Baker 
@_subject: [Cryptography] an associative hash function 
You should be aware of (& possibly reference) the following paper:
An Observation on Associative OneWay Functions in Complexity Theory
Muhammad Rabi and Alan T. Sherman
Department of Computer Science and Electrical Engineering
University of Maryland Baltimore County
Baltimore, Maryland 21250
email: mrabi at cs.umbc.edu and sherman at cs.umbc.edu
November 8, 1997
Abstract We introduce the notion of associative oneway functions and prove that they exist if and only if P 6= NP .  As evidence of their utility, we present two novel protocols that apply strong forms of these functions to achieve secret key agreement and digital signatures.
Keywords.  Associative oneway functions (AOWFs), computational complexity, cryptology, cryp tography, cryptocomplexity, cryptographic protocols, digital signatures, keyagreement problem, secretkey exchange, theory of computation, publickey cryptography.

@_date: 2015-05-28 16:58:42
@_author: Henry Baker 
@_subject: [Cryptography] Forget the Enigma Code; embrace the Hammurabi Code 
Now the IRS admits to enabling the hacking of the identities of >100,000 taxpayers.
Cyberbreach after cyberbreach of customer data happens without anyone taking any responsibility -- leaving the poor consumer/citizen/taxpayer, whose identities were the ones stolen, with only "free credit reports".  Since credit reports are already free 1x per year, this "compensation" is downright insulting.  I'm getting fed up with this whole cyber insecurity situation, and I suspect that a lot of other voters are, too.
It's time to stop just complaining about the poor implementation of encryption codes, and bring back Hammurabi's Codes.  Hammurabi knew in 1750 B.C. that an ordinary citizen could not possibly be expected to know all the details & calculations involved in building a building, so Hammurabi placed the liability on the heads (literally) of those who were in a position to know: the architect and builder.  If the building fell down and killed its owner, the architect and/or builder were put to death.  The ancient Romans extended this theory to the building of bridges: the builder had to stand under the bridge the first time it carried a load; you now know why many ancient Roman bridges are not only still standing, but still carrying traffic today.
Nassim Nicholas Taleb (see below) recognized the wisdom of Hammurabi and suggests its use for bank fraud.  But why stop with bankers?  Lets use Hammurabi's Code for all computer security.
The closest thing we have to Hammurabi's Code today are _surety bonds_, which professional architects and engineers must typically have.  Every computer product or web service that handles consumer identity data should be required to put up a surety bond necessary to cover the entire amount which could be lost due to the theft of each person's identity.  Since the losses from identity theft could easily exceed 100x to 100,000x the cost of the product or service, the costs of these bonds would quickly deter firms from asking for information that they cannot reliably protect.
These bonds should be posted by both the firm producing the product or web site, as well as by all of the contractors & subcontractors -- including any "security consultants", etc.  Inspired by Sarbanes-Oxley and IRS regulations, company officers and directors should be personally liable for the thefts of identity that were entrusted to their products and websites.
I further suggest that Bitcoins in the amount of the bonds' face value be placed in "honeypots" within the company networks, so that these bonds will be the first items to be stolen if the company's networks were breached.  If you don't feel comfortable leaving millions of dollars worth of Bitcoins lying around in your internal network, why should hundreds/thousands/millions of ordinary consumers trust you with their valuable identity data?
I see that some progress is finally being made along these lines; Cottage Health System just found out that their insurance won't cover their computer security negligence.
'The ancients were fully aware of this upside-without-downside asymmetry, and they built simple rules in response.  Nearly 4,000 years ago, Hammurabis code specified this: If a builder builds a house for a man and does not make its construction firm, and the house which he has built collapses and causes the death of the owner of the house, that builder shall be put to death.'
'This was simply the best risk-management rule ever.  The Babylonians understood that the builder will always know more about the risks than the client, and can hide fragilities and improve his profitability by cutting corners  in, say, the foundation.  The builder can also fool the inspector; the person hiding risk has a large informational advantage over the one who has to find it.'
229. If a builder has built a house for a man, and has not made his work sound, and the house he built has fallen, and caused the death of its owner, that builder shall be put to death. 230. If it is the owner's son that is killed, the builder's son shall be put to death.
231. If it is the slave of the owner that is killed, the builder shall give slave for slave to the owner of the house. 232. If he has caused the loss of goods, he shall render back whatever he has destroyed.  Moreover, because he did not make sound the house he built, and it fell, at his own cost he shall rebuild the house that fell.

@_date: 2015-11-02 08:58:44
@_author: Henry Baker 
@_subject: [Cryptography] YubiKeys / FIDO / U2F ?? 
Is the YubiKey a good system?  They seem to be working with Google.

@_date: 2015-11-06 07:08:57
@_author: Henry Baker 
@_subject: [Cryptography] Ransomware: Newest viral marketing gimmick ? 
FYI --
There's an old joke about a man whose spouse's credit card had been stolen by identity thieves, but he didn't report it because the identity thieves racked up smaller monthly charges than his spouse did.  (rimshot!)
Perhaps OPM should utilize Chimera for encrypting government employee data, because:
* Chimera charges less than EMC; and
* Chimera implements better encryption than EMC.
Booming crypto ransomware industry employs new tricks to befuddle victims
High-pressure tactics try to extort more people into paying to recover their data.
by Dan Goodin - Nov 5, 2015 10:35 pm UTC
Ransomware that uses strong cryptography to hold entire hard drives' worth of data hostage keeps getting nastier, as criminals attempt to find new ways to extort more people into paying increasingly hefty ransoms to recover their files.
A case in point is Chimera, a relative newcomer to the crypto ransom racket that targets primarily businesses.  In an attempt to turn up the pressure on infected victims, the malware threatens to publish their pictures and other personal data somewhere on the Internet unless a ransom of $638 in bitcoins is paid.  There's no evidence yet that the new cryptoware title has made good on the threat to post victims' private data online, but it's a likely bet the prospect is enough to convince some undecided victims to go ahead and pay the fee.
The threat, according to a blog post published Tuesday, comes only after the cryptoware has encrypted data stored not only on local hard drives but also those on network drives.  To add drama to the attack, all file extensions are changed to .crypt.  Chimera is also programmed to target specific employees within an infected company, presumably to make sure the ransom demand doesn't get missed.
A second example of cryptoware turning up the pressure on victims is the latest version of CryptoWall, one of the early entrants in the industry.  The recently released CryptoWall 4.0 now replaces names of encrypted files with pseudo-randomly generated letters and numbers, presumably to further befuddle victims who are suddenly unable to access their data.  The new version appears to continue encrypting data with 2,048-bit RSA keys, which when implemented correctly are practically impossible to break.
That's not the only attention-grabbing ploy.  The notification the malware sends to deliver the news that victims' data has been encrypted congratulates them on becoming a part of the "large community CryptoWall."  Besides the snarky tone, the notice is also notable for its almost pristine grammar and spelling and its clarity in explaining how strong crypto works.
"Encryption is a reversible transformation of information in order to conceal it from unauthorized persons but providing at the same time access to it for authorized users," the notice reads, according to this blog post published by antivirus provider Bitdefender.  "To become an authorized user and make the process truly reversible i.e. to be able to decrypt your files you need to have a special private key.  In addition to the private key you need the decryption software with which you can decrypt your files and return everything in its place."
The notice goes on to warn users not to attempt to break the encryption lest the files be lost forever.  CryptoWall 4.0 also employs advanced mechanisms to avoid detection by antivirus and Firewall programs, according to researchers at Heimdal Security.
The refinements show that cryptoware purveyors operate much like other online businesses, which are constantly updating their products and services in an attempt to bring in new business.  That dedication only makes sense, given FBI estimates earlier this year that CryptoWall alone generated losses of more than $18 million.  A separate report estimated US damages of $325 million from CryptoWall 3.0.  That translates into huge profits, especially when considering the revenue is tax-free.
Now that crypto ransomware is a threat that won't be going away any time soon, there's been a fair amount of debate about whether victims should pay the ransom as demanded.  Recently, an FBI agent reportedly told businesses it may be easier for them to pony up.  The comments generated howls of protest among security professionals, who warned there's no guarantee the fees will ensure the encrypted data is restored.
The critics are right that there can be no certainty that the ransomware operators will make good on their promise.  And there's always the possibility a programming error or law enforcement takedown will allow keys to be recovered without paying the fee, as was the case last year with the CryptoLocker brand.  Then again, there are plenty of reports of victims with no other recourse who paid the ransom and recovered their files.  Ultimately, the decision should be made on a case-by-case basis.  No doubt, paying the increasingly large fees is a risk, and it only rewards truly pernicious and illegal behavior.  Then again, for people who have lost data valued in the thousands or hundreds of thousands of dollars, paying a $700 ransom may be worth the risk and cost, although the move shouldn't be taken lightly.

@_date: 2015-11-12 12:54:44
@_author: Henry Baker 
@_subject: [Cryptography] Ransomware: Newest viral marketing gimmick ? 
Sorry to sound so millennial and all, but what's a "backup" ?
What does "offline" mean ?
Here in the 21st C. we have our heads up our clouds.
"So many things I would have done, But clouds got in my way."

@_date: 2015-11-12 13:28:38
@_author: Henry Baker 
@_subject: [Cryptography] Post Quantum Crypto 
D-Wave should be called "FUD-Wave", from the old IBM FUD (Fear, Uncertainty, Doubt).  To the extent that state actors, criminals, whistleblowers and journalists are worried about crypto-cracking quantum computers, the small amount of money the govt gave to D-Wave has already paid off handsomely.
Technology doesn't even have to actually operate in order to bother people: remember Reagan's so-called "Star Wars" program ?
Remember the WWII Ghost Army with its inflatable tanks and Bell Labs sound recordings of tank noises ?
Remember Patton's command of the fictitious First United States Army Group ?

@_date: 2015-11-12 17:56:08
@_author: Henry Baker 
@_subject: [Cryptography] Clouds that can't reign 
Microsoft's new data center strategy could be:
Array of
With the proper encoding (e.g., "erasure" coding, etc.)
techniques, Microsoft could engineer a system in which
the data doesn't "live" *anywhere* at all:
With d data centers in c *independent* countries and an
integer m, 5<m<c<d, Microsoft (or any other organization--
Cryptome, Tor, etc., are you listening ??) could arrange
the stored bits so that it would take at least m countries
all *colluding* to be able to read or write any portion of
any individual's data.
I picked the number "5" at random (e.g., 5-eyes).  ;-)

@_date: 2015-11-13 07:34:25
@_author: Henry Baker 
@_subject: [Cryptography] Microsoft releasing quantum computing simulator 
FYI --
"The simulator is 30 qubits, which requires 32 gigabytes of memory.  That means it can run on a high-end laptop or desktop.  Every qubit added, he warns, will *double* the memory requirement."
Microsoft Simulator Brings Quantum Computing One Step Closer to the Masses
by  Barb Darrow    9:11 AM EST
On Friday, Microsoft is releasing simulation software that it says will let academics, scientists, or even do-it-yourself eggheads simulate quantum computing on their laptops.
The promise of quantum computing, which breaks the nuts-and-bolts of computing down to the sub-atomic level, is that it can solve problems that go far beyond the capabilities of even todays most powerful computers.
The current generation of computers represent all data as ones and zeros.  Its all a very binary, on-or-off proposition.  By relying on smaller particles, like photons or electrons, a quantum computer would be able to look at data that can hold several contradictory states at the same time.  For instance, instead of those ones and zero, a quantum computer would deal with quantum bits (also known as qubits), which would accommodate multiple states.
Its a bit complicated for mere mortals to understand, but what all that means is that quantum computers should be able to calculate certain problemsmodeling molecules for example-much, much faster than their transistor-based forebears.
One problem with all of this work is its still largely theoretical.  Scientists think it will work, but the gear required to run these calculations isnt here yet.  Thats because to keep all those wee subatomic particles in a stable state, the equipment has to be very, very cold100 times colder than the temperature in outer spaceaccording to Dave Wecker, chief architect of the Microsofts quantum team, also known as QuArC.
As if thats not difficult enough, its also not clear how best to state the problems that need to be solved by quantum computers, or how to interpret those results since this will be a whole new qubit-inspired world.  Thats something the simulator can help researchers get their minds around.
The software, which Microsoft has been using in house for some time, is called Language-Integrated Quantum Operations, or LIQUi|> (and no, thats not a typo).  LIQ stands for language integrated quantum, says Wecker.  The vertical bar stands for ket which is tech speak for the quantum state.  U is the operation performed on the quantum state and the greater than bracket is simply a bracket, Wecker says.
As an example of a problem that a quantum computer could solve, Wecker cites the creation of high-temperature superconductors.  We lose electricity on our transmission lines.  Superconductors would have no losses, but no one can build a super conductor at anything near room temperature.  We could model than on a quantum computer and at least have the hope of solving that problem, Wecker says.
Ditto the creation of organic batteries, which wouldnt have to rely on expensive and polluting heavy metals.  We know we can build them but which molecules do we use?  There are millions.  A cloud of quantum computers could test them all out.
Drug modeling and testing is another potentially huge use for these computers, which explains why companies like Microsoft, Google, IBM, and others are investing in the field.  D-Wave Systems, has its own version of a quantum processor, one of which was just sold to Los Alamos National Laboratory.
There are also other quantum computing simulators on the market, including one from Google for example.  Wecker says the differentiator here is this is industrial strength and academics or researchers can extend it, adding their own quantum calculations as needed.
The simulator is 30 qubits, which requires 32 gigabytes of memory.  That means it can run on a high-end laptop or desktop.  Every qubit added, he warns, will double the memory requirement.  The code means some simulations can run locally, or if you have bigger requirements, you can turn to the cloud of your choicesuch as Microsoft Azure, Amazon Web Services, or Google Cloud Platform-he adds, there are no restrictions on use.
The executable code, along with documentation, will be available on the Github code repository for download.  Microsoft will talk more about the simulator next week at Supercomputing 2015 in Austin.

@_date: 2015-11-15 05:40:17
@_author: Henry Baker 
@_subject: [Cryptography] Nvidia- one Tflop could change the rules quicker 
mail.com>
Google car to Dave:
"I'm sorry, Dave, but I can't turn left here -- I'm too busy cracking some script-kiddie's password."

@_date: 2015-11-16 05:32:48
@_author: Henry Baker 
@_subject: [Cryptography] Post Quantum Crypto 
Re 'new insights':
I disagree.
The physicists have (mostly) ignored the issues of *information* and information flow for the past 100+ years.
Actually trying to build a QC has forced physicists to address these issues directly.
The physicists still have lots of spurious infinities floating around -- e.g., infinite amounts of information -- that can't possibly be correct.  Indeed, QM seems to be screaming at us: "there's not enough storage capacity in nature to encode all the bits for classical mechanics; you have to start 'sharing' bits".  E.g., the "holographic" models of QM.

@_date: 2015-11-17 10:07:32
@_author: Henry Baker 
@_subject: [Cryptography] Sadly predictable: Terrorism used as excuse to 
Don't forget that terrorists use flush toilets -- sometimes with extra-large magazines:
"[A criminal's] most dangerous weapon is the flush toilet ... a perfect evidence-disposal system installed in every home in America"
The problem with cracking down on PlayStations to stop terrorists
If you're scared of gaming consoles, you're scared of privacy
By Russell Brandom on November 16, 2015 04:11 pm  There's a joke in the legal world that criminals' most dangerous weapon is the flush toilet.  Imagine, a perfect evidence-disposal system installed in every home in America, available whenever you hear the detectives knock on your door.  Tens thousands of potential arrests have been flushed down toilets over the years.
So why do we keep toilets around?  Well, they're useful for other things.
Today, instead of the flush toilet, we learned about the PlayStation 4.  In a now-retracted story, Forbes made the case that PlayStation's private chat and VoIP features may have been used in plotting the attacks, kicking off a wave of concerns over gaming networks and their potential use in plotting terrorist acts.
But while Forbes has since backed off the claim that a PS4 was found in an attacker's apartment, the air of suspicion hasn't fully lifted.  There really have been cases of ISIS sympathizers using the PlayStation network to communicate or recruit, and it's the kind of offbeat channel an intelligence officer might miss.  PlayStations network is open to anyone with the right console, and theres lots of noise to distract anyone who might look there.  As the UK's Investigatory Powers Bill heads to parliament, the political will to clamp down on those networks is stronger than it's ever been.  So why shouldn't we?
The first thing to say is that the PlayStation network isn't particularly secure.  It's not end-to-end encrypted, and Sony is open about the company's right to surveil users, even if it doesn't have much of an apparatus to do so.  Unlike encrypted chat apps like Telegram and WhatsApp, the PlayStation networks weren't designed with security in mind, and most users care far more about latency and downtime than they do about privacy.  If an intelligence service is looking for you specifically, it's just not that good of a place to hide.
What the networks do have is a lot of people, which makes them useful for meeting inconspicuously.  You won't stand out if you set up a private chat on PSN, the way you might if you log onto a protected chat room or IRC channel.  It's the protection of the crowd, the same way you might talk more freely in a noisy bar where you wont be overheard.  This kind of privacy is more about cultural expectations than strict security, and its particularly important because of that.  It can be used by terrorists, sure, but so can dimly lit restaurants and crowded parks.  If that's scary, then all private spaces are scary.  If you believe that logic, you've made a boogeyman out of privacy itself.
All of which brings us back to the flush toilet.  In the wake of a tragedy, shock makes us value security over all else, often forgetting smaller virtues in the rush to protect ourselves.  It's a natural impulse, but it's worth considering where it might take us, left unchecked.  With enough fear, anything comes to look threatening: a gaming console, a toilet, a smartphone.  Will destroying them make us more or less powerful?

@_date: 2015-11-17 17:19:53
@_author: Henry Baker 
@_subject: ISIS has help desk to aid would-be terrorists with encryption 
Perhaps the U.S. govt -- e.g., OPM & Brennan -- should consider emulating these opsec help desks.
Also, wouldn't an encryption 'help desk' have to be unencrypted/insecure *by definition* ?
I mean, if these guys need so much help doing encryption, they'd never even be able to access an encrypted help desk in the first place.
I don't know if Johnny can encrypt, but we keep hearing rumors that Muhammad can.
EXTREMIST FORUMS PROVIDE DIGITAL OPSEC TRAINING
Aaron Brantly, Muhammad al-`Ubaydi  May 28, 2015
ISIS has help desk to aid would-be terrorists with encryption
By Cory Bennett - 11/17/15 10:48 AM EST
The Islamic State in Iraq and Syria (ISIS) has set up a 24-hour help desk to advise burgeoning jihadists on encrypting their communications in order to evade authorities, NBC News reported.
The tactic has developed rapidly over the last year, according to several U.S. Army counterterrorism analysts.  Roughly half a dozen senior operatives are now always on hand at this center to provide digital pointers.
This help desk demonstrates the terorrist groups increasing savvy in using digital tools to both recruit new members and to plan attacks.
ISIS has taken credit for the deadly terrorist attacks on Paris last week that killed over 120 people.  European officials say those behind the attack may have used some type of encrypted communication in the planning process.
Theyve developed a series of different platforms in which they can train one another on digital security to avoid intelligence and law enforcement agencies for the explicit purpose of recruitment, propaganda and operational planning, said Aaron F. Brantly, a counterterrorism analyst at the Combating Terrorism Center, an independent research organization at the U.S. Military Academy, in an interview with NBC News.
The discovery of such tech capabilities will likely fuel the already contentious worldwide debate over encryption standards.
U.S. intelligence officials and lawmakers have already used the Paris attacks to call for some type of guaranteed government access to encrypted communications data at companies such as Apple, Facebook and Google.
But privacy and digital rights groups have said that such access would weaken encryption for everyone without significantly helping law enforcement monitor potential terrorists.  Many have also noted that terrorist groups have long developed their own encryption tools that would not be touched by any government rules.
The ISIS help desk monitors leading security software and encryption methods, directing recruits to the most clandestine option.
While a large community helps run the operation, there are five or six core members with collegiate- or masters-level training in information technology that fuel the help desk, said Brantly, the lead author of a paper on the topic.
They answer questions from the technically mundane to the technically savvy to elevate the entire jihadi community to engage in global terror," Brantly said.  "Clearly this enables them to communicate and engage in operations beyond what used to happen, and in a much more expeditious manner.  They are now operating at the speed of cyberspace rather than the speed of person-to-person communications."

@_date: 2015-11-18 09:34:41
@_author: Henry Baker 
@_subject: [Cryptography] Fatal flaw in 'Algebraic Eraser' ? 
FYI --
Why Algebraic Eraser may be the riskiest cryptosystem youve never heard of
Researchers say there's a fatal flaw in proposed "Internet of Things" standard.
by Dan Goodin - Nov 17, 2015 4:40 pm UTC
A potential standard for securing network-connected pacemakers, automobiles, and other lightweight devices has suffered a potentially game-over setback after researchers developed a practical attack that obtains its secret cryptographic key.
Known as Algebraic Eraser, the scheme is a patented way to establish public encryption keys without overtaxing the limited amounts of memory and computational resources that often constrain so-called Internet of Things (IoT) devices.  Developed by scientists from Shelton, Connecticut-based SecureRF, it's similar to the Diffie-Hellman key exchange in that it allows two parties who have never met to securely establish a key over an insecure channel.
The big advantage Algebraic Eraser has had is its ability to work using only a tiny fraction of the power and computing resources required by more traditional key exchanges.  Algebraic Eraser has looked so promising that it's an underlying technology in ISO/IEC AWI 29167-20, a proposed International Organization for Standardization specification for securing radio frequency identification-enabled technologies, wireless sensors, embedded systems, and other devices where security is paramount and computing resources are minimal.
Now, academic researchers say the Algebraic Eraser suffers a weakness that's so severe it compromises the entire security of the proposed ISO standard when the Algebraic Eraser is used.  To underscore their assessment, the researchers developed an attack that requires just eight hours to recover a shared 128-bit key negotiated using the Algebraic Eraser.  (The shared key acts as the shared secret key that encrypts and decrypts data stored on a device.)  With enhancements, they said, the attack can probably be carried out much more quickly.  The underlying weakness means there could be potentially disastrous consequences if it's widely used.
"A key exchange might be used to secure the long-term key for an implanted medical device, say, or a networked vehicle," Simon Blackburn, a mathematics professor at Royal Holloway University of London and co-author of a paper titled A Practical Cryptanalysis of the Algebraic Eraser, wrote in an e-mail to Ars.  "Compromising the key might allow malicious code to be inserted into the device or might allow the device to be remotely controlled by an adversary.  I would not want a hacker to take control of my car or my pacemaker."
Serious doubt
In the paper, Blackburn-along with Bar-Ilan University mathematicians Adi Ben-Zvi and Boaz Tsaban-said they chose to examine Algebraic Eraser and a SecureRF-developed implementation of it called Colored Burau Key Agreement Protocol (CBKAP) because of its potential to become ubiquitous in the IoT landscape, where cars, medical devices, and many other traditional devices are connected to the Internet or similar types of networks.
"IoT is a growth area, where current widely accepted public key techniques struggle to operate due to tight efficiency constraints," they wrote.  "It is likely that solutions which are efficient enough for these applications will become widely deployed, and the nature of these applications make system changes after deployment difficult.  Thus, it is vital to scrutinise the security of systems such as the Algebraic Eraser early in the standardisation process, to ensure only secure schemes become ubiquitous."
The researchers went on to say that "because our attack efficiently recovered the shared key of the CBKAP for recommended parameter sizes, using parameters provided by SecureRF, we believe the results presented here cast serious doubt on the suitability of the Algebraic Eraser for the applications proposed."
In contrast to previous attacks on the Algebraic Eraser, Blackburn said the latest attack recovers the shared secret key directly from the public key of one user (usually referred to as "Alice" by cryptographers) and the messages exchanged between Alice and a second user (usually referred to as "Bob") rather than attempting to reconstruct the random information that Alice or Bob generated.
"The approach avoids the problems with a previous attack, which got stuck when trying to find part of this random information," Blackburn told Ars.  "This new twist allows us to reduce the problem of breaking the scheme to linear algebra and a problem in small permutation groups."
No threat
SecureRF CEO and President Louis Parks told Ars he doesn't believe the attack is as practical as the recent paper reports, for several reasons.  For one, he said the shared secret extraction technique doesn't scale.  For another, he said, the attack won't work when different parameters are used for the cryptosystem, which he referred to as Algebraic Eraser Diffie-Hellman, or AEDH.
"Our conclusion is that this attack does not represent a threat to the practical deployment of AEDH in applications with properly chosen parameters," he wrote in an abstract to a research paper he said he plans to publish in response to the attack.
In an e-mail to Ars, Parks said his company has no plans to revise claims that the Algebraic Eraser has been "In public domain for 10 years with no successful attacks.".
"It is apparent that we may have provided 'weak parameters' that were being used for internal testing and sent to the researchers when requested," Parks wrote.  "We are addressing both this area of parameters and our process for approving secure parameters.  But his attack does not claim to have 'broken' our method or recover any secret material. It claims to be able to recover a computed shared secret.  If true, then like RSA and others, we will need to identify these weak parameters to our partners and ensure they are not used."
For his part, Blackburn said he was surprised to learn that Parks said the attack doesn't scale and doesn't work as well as reported in the paper.  Blackburn said he also doesn't understand why SecureRF scientists would have provided parameters they didn't believe would withstand the new attack, and he's eager to see the final paper Parks has discussed.  Several prominent mathematicians have taken to social media in recent days to echo Blackburn's claim that the new attack essentially breaks the Algebraic Eraser and renders it all but dead.
Until SecureRF has had time to present its final paper, such pronouncements are preliminary.  But based on the new attack, it's clear that the drafters of ISO/IEC AWI 29167-20 should take a long, hard look at the Algebraic Eraser now.  If that attack works the way Blackburn and his peers say it does, the time to address this crippling weakness is nownot when the underlying Algebraic Eraser is embedded in millions of devices.

@_date: 2015-11-19 08:15:38
@_author: Henry Baker 
@_subject: [Cryptography] UK wants snooping tech feedback by Fri 27 Nov 
FYI --
"The Science and Technology Committee ... has encouraged stakeholders to send written submissions to it by Friday 27 November."
"The Committee has already hosted an oral evidence session ... including leading IT security and privacy academic Ross Anderson of the University of Cambridge" (see link below)
MPs to assess tech feasibility of requirements under draft surveillance laws
IT pros, hold your breath
18 Nov 2015 at 09:34, OUT-LAW.COM
The UK government published a draft Investigatory Powers Bill earlier this month in a bid to close gaps it has said exist in the surveillance powers available to the UK's intelligence and security services.
The Science and Technology Committee said that it will carry out a "short inquiry into the technology aspects" of the Bill.  It has encouraged stakeholders to send written submissions to it by Friday 27 November.
The submissions "should focus on technology issues, including: the technical feasibility and costs of meeting the obligations imposed by the Bill; the impact on communications service providers and related businesses; [and] the likely consequences for citizen/consumer use of ICT services", the Committee said.
"More specific issues of interest to the Committee include the extent to which communications data and communications content can be separated and the extent to which this is reflected in the draft Bill," it said.  "Comments are also invited on any specific technologies that have a direct bearing on the operation and effectiveness of the measures in the draft Bill.  These include, but are not restricted to, encryption, bulk data collection, cloud computing, deep packet inspection and anonymous internet communication systems."
The Committee has already hosted an oral evidence session (35-page / 326KB PDF) at which the Internet Services Providers Association and security software company Sophos were represented, alongside others, including leading IT security and privacy academic Ross Anderson of the University of Cambridge.  A further oral evidence session is planned for December.
The Investigatory Powers Bill (299-page / 3.54MB PDF) would, among other things, give UK law enforcement and intelligence agencies the power to require telecommunication service providers to retain and hand over communications data, which includes "internet connection records" (ICRs) for the first time, to help combat terrorism, serious crime or protect the UK's economic interests, among other limited purposes provided for in the legislation.
The Bill also sets out rules on the interception of communications, bulk data gathering and equipment interference activities.
Communication service providers could be compelled to set up filtering systems to help with the targeting of requests for communications data, according to the proposed new legislation.

@_date: 2015-11-19 09:30:40
@_author: Henry Baker 
@_subject: [Cryptography] Burner phone == One Time (i)Pad 
Anyone who's watched a recent movie or TV show knows about burner phones.  They seem to have become the 21st century version of a "one time pad".
What's the most important criterion for a burner phone?  It should be *cheap*; only the most well-heeled terrorists would use an iPhone as a burner.
There's much less need to encrypt a burner phone.  In fact, one might purposely put false/misleading information onto such a phone prior to throwing it away.  (And *delete* it, just to piss off Mr. Vance, who hates cellphone software that actually deletes data when you press "delete".)
"investigators were able to access the data on the phone, including a detailed map of the concert hall and an SMS messaging saying were off; were starting.  Police were also able to trace the phones movements."
"Ironically, the suspects were overheard discussing the need to frequently swap out their cellphones."

@_date: 2015-11-20 07:09:42
@_author: Henry Baker 
@_subject: [Cryptography] NY DA Vance's 'Smartphone Encryption and Public 
[I apologize for this long post, but this issue is *really important*.]
Overall, DA Vance is basically whining that things were so easy when all
this cellphone data was there for the taking.  Then he got a 1-2 punch
from the default encryption of Apple/Google and the Supreme Court
requiring a warrant *before* access.
His whole cellphone strategy was destroyed in less than one year, and he
can't think how to replace it.  (Apparently, there's no one left in his
office who is old enough to know how to try a case *without* using
cellphone data -- as he essentially admits.)  BTW, this is also the
NSA's problem: they've relied *solely* on cellphone data for so many
years that they can't imagine how to do their jobs without these data.
My biggest problem with the Vance proposal is that in order to actually
work as advertised, Apple & Google would have to go back to previous
versions of their OS's that have already been shown to be insecure.
Alternatively, Apple & Google will have to install *keyloggers* and
*screenloggers* to log all interactions with all user-installed apps
on the phone.  Since Vance is arguing that these log data *must be
unencrypted*, these data become a *honeypot* for every criminal and
bad state actor in the world, placing *billions* of cellphone users
at an unacceptable risk.
I don't see any room for negotiation here.
DA Cyrus Vance prepared remarks November 18, 2015
'Last year, we invested $90 million in *criminal forfeiture* funds to
equip New York City police officers with 41,000 mobile devices,
including tablet computers for every patrol car and handheld devices
for every cop'
For those outside the U.S., "civil forfeiture" (Freudian slip?

@_date: 2015-11-20 07:53:59
@_author: Henry Baker 
@_subject: [Cryptography] Unencrypted SMS 
Judging from the unseemly way that the CIA, et al, have cynically exploited the Paris murders, the SMS message "we're on our way, we are starting" might have come from Brennan, Morell, Comey or Vance...

@_date: 2015-11-20 08:47:55
@_author: Henry Baker 
@_subject: [Cryptography] ISIS has help desk to ai d would-be 
mail.com>
Apparently, even though the US had completely broken the Japanese codes, the Navy still lost track of the Japanese fleet *due to total radio silence* (this problem wasn't completely fixed until spy satellites were deployed), so Pearl Harbor was a "complete" surprise (except that radar picked up the incoming planes, but apparently no one was willing to believe that new-fangled radar technology).

@_date: 2015-11-20 10:22:30
@_author: Henry Baker 
@_subject: [Cryptography] WSJ: WH wants to meet Techies in DC re encryption 
FYI -- Perhaps the WH should invite Riemann, Godel & Turing to this sit-down ?
(I wonder if they'll meet at the (Golden) Key Bridge Marriott?)
Paris Attacks Fan Encryption Debate
Assaults prompt renewed government push for Silicon Valley to open up systems
By Danny Yadron, Alistair Barr and Daisuke Wakabayashi Nov. 19, 2015 9:43 p.m. ET
White House and congressional staffers have asked Silicon Valley executives for *new talks in Washington, D.C.,* to resolve a standoff over encrypted communication tools in the wake of the Paris terrorist attacks, people familiar with the matter said.
The approaches are among the most concrete signs of how last weeks bombings and shootings have put a new spotlight on the debate about whether American companies should be allowed to offer ultrasecure messaging tools.
There is no evidence the Paris attacks have changed technology companies view that strong encryption protects consumers, and that providing a way for police to eavesdrop would open the door to exploitation by criminals and repressive governments.
Late Thursday, the Information Technology Industry Council, whose members include Apple and Microsoft Corp., said in a statement, Weakening security with the aim of advancing security simply does not make sense.
But Apple Inc., Google parent Alphabet Inc., Facebook Inc. and others face a difficult public-relations dance, because executives dont want to be seen as brushing off the implications of a tragedy.
Its not the ideal time to be out there touting the benefits of encryption, said an attorney who has worked on encryption issues.
There is no evidence Islamic State attackers in Paris relied on scrambled communications.  Some used run-of-the-mill text messages, which can be easily monitored if a suspect is known, according to French media reports.
The Paris attacks came amid an 18-month feud between Washington and Silicon Valley that began when Apple and Google released new smartphone software that the companies said they cannot unlock, even if faced with a court order.
Top U.S. law-enforcement officials have said the software would cripple some criminal investigation.  Talks aimed at ensuring law enforcement access to certain messaging systems and devices reached a stalemate in the fall.  Unwilling to dictate product specifications to some of the nations most successful companies, the administration decided not to push for a change in law.
The Paris attacks may complicate efforts to reach a near-term compromise.  There is a solution out there and theres a way to get to it but this isnt the month to be starting down that path, said James Lewis, a cybersecurity expert and former Clinton administration official who has consulted with tech companies and government.
He and the Center for Strategic and International Studies, where he is a senior fellow, had planned a forum on encryption policy this fall.  After the Paris attacks, he postponed it.
Since Paris, Sens. John McCain, (R, Ariz.), Dianne Feinstein, (D, Calif.) and other lawmakers have said they want to ensure investigators can access the content of encrypted communications.
Mr. McCain has said he wants to pursue legislation.
Apple has said it would never build a government backdoor into its products, because doing so would create security vulnerabilities that can be exploited by criminals.  On its website, Apple says encryption protects trillions of online transactions daily and eliminating it would expose people to many risks.
I dont know a way to protect people without encrypting, Apple Chief Executive Tim Cook said last month at The Wall Street Journals technology conference, WSJD Live.  You cant have a backdoor thats only for the good guys.
Rachel Whetstone, former head of communications and public policy at Google, said in February that governments dont have and should not get backdoors to access Google user data because the company has a duty to keep users information private.  A person familiar with the companys thinking said Googles views on encryption havent changed.
Even if Apple and Google could be convinced to cooperate, tech executives say there are dozens of other encrypted communication systems.  Most encryption techniques are publicly known and terror organizations could build their own alternatives, they said.  The cat is already out of the bag, added one executive.
One technology executive acknowledged mixed feelings.  While I continue to feel that outlawing end-to-end encryption would be both ineffective and a slippery slope for society, Im also aware that I have limited knowledge of all the scary things happening in the world today, said Ted Livingston, chief executive of Kik Interactive Inc., developer of the Kik Messenger messaging application.
The Waterloo, Ontario, companys app doesnt store the content of messages on the companys servers.  That means, the company says, it can only give authorities data on users, not transcripts of what they say to each other.  It faced some negative publicity following reports in The Wall Street Journal and elsewhere that Islamic State operatives see this feature as advantageous and use the app.
Damian Paletta, Ryan Knutson and Deepa Seetharaman contributed to this article.
Write to Danny Yadron at danny.yadron at wsj.com, Alistair Barr at alistair.barr at wsj.com and Daisuke Wakabayashi at Daisuke.Wakabayashi at wsj.com

@_date: 2015-11-21 05:32:30
@_author: Henry Baker 
@_subject: [Cryptography] NY DA Vance's 'Smartphone Encryption and Public 
So now we are arguing about key management, not strong encryption, per se.
That's at least a small start.  Most of the public has been led to believe
that encryption -- per se -- is the work of the devil, and is equivalent
to witchcraft that should be prosecuted by burning at the stake.
Not per se.  But Vance keeps talking about the "good old days" before Apple's recent move to default encryption, so presumably he would be quite happy if Apple went back to the old "go to fail" software, since he doesn't care about user's data getting pwned by Russian criminals, so long as Vance can pwn these same data himself.
Sad but true.
I wasn't talking about Enron-type deleting, but merely forensic access to old data that wasn't properly cleaned up by traditional file systems -- e.g., FAT.  These data are left in file slack, deleted entries in directories, etc.
Apparently, Vance & other prosecutors want to prosecute people merely for running the Windows "defragment" command, because they claim that running "defragment" is evidence of willful/deliberate destruction of data!
If you want to talk about Enron, that is a whole 'nuther topic.  After Enron, the SEC required preservation of all kinds of email and SMS data for people in financial industries.  All that data from the "Great Recession" mortgage fraud scandal was presumably preserved and available to the SEC for prosecution.  Nevertheless, no one was ever prosecuted.
So Vance's whining about lack of data -- at least for prosecuting financial cases -- is simply B.S., since these data are *already* available to the SEC in unencrypted form just for the asking.  I'm not a lawyer, but I seem to recall that the SEC doesn't even have to get a warrant -- I think they may have "march in" rights to demand these data at any time.

@_date: 2015-11-21 05:55:39
@_author: Henry Baker 
@_subject: [Cryptography] Purposely weakening encryption "because Paris" 
Let's see.  The govt *requires* access, thus weakening all encryption and enabling the possibility of catastrophic failure of cellphone & computer communication world-wide.
What the public doesn't understand is that any *systematic* weakness can be exploited *at scale* by anyone with access to a botnet -- e.g., a teenager sitting at his computer in his underwear in Russia.
These govts are asking everyone to *unilaterally disarm* themselves in a war which is going on *right now* in everyone's pocket or purse, where there are thousands of "pings" per hour trying to break into *everyone's* computer and cellphone.
In a shopping mall parking lot, most of us can see when gangs of thieves are going around testing every car door and window to see if they can get in to steal stuff.
The same thing is going on right now in everyone's pocket or purse -- gangs of thieves from across the globe are testing every feature and every protocol of our cellphones to see if they can get in and steal our data.
If OPM's 22 *million* people compromised teaches us anything, it teaches us that encryption failures could take out *whole countries*, or at least substantial fractions of whole countries.
History didn't judge the Trojans very kindly when they invited the Trojan Horse into their city.
History won't judge us very kindly when we purposely weaken our encryption to enable terrorists to go after *millions* of people at a time, instead of tens of people.
This unilateral disarmament is not just stupid, it is suicidal.

@_date: 2015-11-21 12:31:42
@_author: Henry Baker 
@_subject: [Cryptography] Bright undergrad needed for short IoT encrypt'n 
Could probably reside just about anywhere, since the comms device is quite small and easily shipped, but U.S. or better still, NE U.S., would make it easier for face2face.
Should be up-to-date on standard network (wired & wireless) protocols.
Contact me with email/phone# to discuss.
The client is a small but legit company, and not a troll by any govt; TAO's need not apply.

@_date: 2015-11-21 11:38:46
@_author: Henry Baker 
@_subject: [Cryptography] WSJ: WH wants to meet Techies in DC re encryption 
I believe that the concept Jerry is trying to describe is now known as "microaggression".
Every time the CIA/NSA/FBI/DHS/GCHQ/etc. talks about demonizing encryption, this is a microaggression on free citizens, civil liberties and the Constitution.
"[microaggression] came to encompass the casual degradation of any socially marginalized group"
It now appears that those who believe in free speech, liberty and the Constitution have become a socially marginalized group.
BTW, I haven't been able to determine whether uaggression belongs to the CGS or the MKS system of units.

@_date: 2015-11-22 09:03:34
@_author: Henry Baker 
@_subject: [Cryptography] Crackdown on *rental vehicles* expected after 
FYI -- Hmmm...  A rental car was used in the first WTC attack; a rental truck was used in the Oklahoma City bombing, and now Paris.
What next?  Uber terrorists?
'Several people on the block did see two rental cars used in the attacks  a Volkswagen and a SEAT  parked in front of the property, a narrow, well-kept house tucked between other single-family homes.'
'After the attacks, *French authorities reconstructed the vehicles movements using the cars GPS devices.*'
'The black SEAT was used to conduct a series of attacks in which the perpetrators sprayed gunfire into crowds at Le Carillon, La Belle Equipe and other popular establishments in Pariss 10th and 11th districts.  At least 40 people were killed, many of them sitting outdoors on a mild November evening.'

@_date: 2015-11-22 07:50:39
@_author: Henry Baker 
@_subject: [Cryptography] Pearl Harbor and Crypto 
Earlier in his career, Osama Bin Laden used (Iridum?) satphones for communications.
The intelligence agencies were outraged when the NYTimes wrote a story about the capabilities of these agencies to utilize satphones to track people.  (Even though tracking was one of satphones' intended use cases! -- e.g., keeping track of adventurers/backpackers/climbers in far-off places.)
Whether or not he learned from the NYTimes, Bin Laden quickly gave up satphones.
Bin Laden's opsec became impeccable, which was one of the reasons why it took so long to find & kill him.
Of course, by making it so hard to communicate with him, Bin Laden also took himself out of the arena, and was essentially irrelevant by the time he was killed.
So, to the extent that opsec hygiene reduces an opponent's communications capabilities, total surveillance has some advantage.
But to the extent that coping with total surveillance *of your own citizens* reduces their efficiency, it becomes a substantial tax on the economy.
Look at the percentage of the East German economy that was reduced by the Stasi's surveillance of its own citizens -- perhaps 10%.  That's quite an extra load to be carried in an economy that may grow only at 1-2% per year normally.

@_date: 2015-11-22 13:28:49
@_author: Henry Baker 
@_subject: [Cryptography] Bin Laden satphones 
Here's a pretty good rundown of this 'urban myth', which apparently originated with the CIA's Foreign Denial and Deception Committee!  [I didn't make this up!]
But as early as 1996, Time magazine had reported that Bin Laden uses satellite phones to contact fellow Islamic militants.  Time gave its source as Taliban officials, not U.S. intelligence-giving the lie to Bushs assertion that government leaks were to blame for the outing of that piece of information.
Time repeated the information after the African embassy bombings, reporting in its Aug. 24, 1998, issue-on newsstands a week before the cover date-that Bin Laden keeps in touch with the world via computers and satellite phones.  (Careful readers will note that the *Washington Times* story contained the exact same language as the earlier Time article.)
CNN broadcast a report by Peter Bergen the day of the cruise missile attacks in which Bergen said he had interviewed Bin Laden in Afghanistan in March 1997 and that he communicates by satellite phone.  The same information appeared in newspapers in Japan, Germany, Pakistan and Philadelphia.  (Jack Shafers article has a good rundown.)
So the facts are these: It was common knowledge years before the bombing that Bin Laden communicated via a satellite phone.  The source of this information was not a leak from the U.S. government.  Rather, it came first from the Taliban, and then from Bin Laden himself.
"The fact that we were following Osama bin Laden because he was using a certain type of telephone made it into the press as the result of a leak," the president [Bush] said.  "And guess what happened?  Saddam -- Osama bin Laden changed his behavior.  He began to change how he communicated."
Later, the president repeated the example and decried what he called "revealing sources, methods and what we use the information for" as helping "the enemy" change its behavior.
the president [Bush] was referring to a profile of the al Qaeda leader that appeared in the *Washington Times* [normally a right-leaning news organization!!] on Aug. 21, 1998.  In the 21st paragraph, the article stated: "He keeps in touch with the world via computers and satellite phones and has given occasional interviews to international news organizations." first reported by a best-selling book, *validated* [!] by the Sept. 11 commission [goes to show how much we should believe them!] and then repeated by the president.
The al Qaeda leader's communication to aides via satellite phone had already been reported in 1996 [Rep.] Hoekstra [(R-Mich.), chairman of the House intelligence committee] has distributed to lawmakers a classified report on leaks compiled by James B. Bruce, vice chairman of the **CIA's Foreign Denial and Deception Committee,** [you can't make this stuff up!] and a leading advocate of enacting very tough laws on leaks.  In 2002, Bruce was quoted as saying that "we've got to do whatever it takes -- if it takes sending SWAT teams into journalists' homes -- to stop these leaks."

@_date: 2015-11-22 19:16:43
@_author: Henry Baker 
@_subject: [Cryptography] Bin Laden satphones 
The fact that various satphones could track people was well known to anyone who actually used one, since that was one of the features advertised for backpackers/adventurers/etc.  My (non-technical) brother tested one of the first satphones, and was well aware of this capability.
Now Bin Laden may have been naive to think that the satphone provider wouldn't share this data with various govts -- probably in real time.
He (and every other terrorist) quickly got that particular memo after he narrowly escaped a missile strike.
Cruise missiles concentrate the mind a lot more than news clips do.

@_date: 2015-11-22 18:02:29
@_author: Henry Baker 
@_subject: ISIS OPSEC Manual 
FYI -- Maybe Johnny can't encrypt, but neither can Abdelhamid Abaaoud.
Even terrorists refuse to RTFM...
ISIS OPSEC Manual Reveals How It Handles Cybersecurity
Kim Zetter 11.19.15 4:45 pm
In the wake of the Paris attacks, US government officials have been vocal in their condemnation of encryption, suggesting that US companies like Apple and Google have blood on their hands for refusing to give intelligence and law enforcement agencies backdoors to unlock customer phones and decrypt protected communications.  But news reports of the Paris attacks have revealed that at least some of the time, *the terrorists behind the attacks didnt bother to use encryption* while communicating, allowing authorities to intercept and read their messages.
Reports in France say that investigators were able to locate some of the suspects hideout this week using data from a cellphone apparently abandoned by one of the attackers in a trashcan outside the Bataclan concert hall where Fridays attack occurred, according to Le Monde.  Authorities tracked the phones movements prior to the attack, which led them to a safehouse in a Paris suburb where they engaged in an hours-long shootout with the other suspects early Wednesday.  These would-be attackers, most of whom were killed in the apartment, had been planning to pull off a second round of attacks this week in Pariss La Defense business district, according to authorities.
Other reports indicate that a previous ISIS terrorist plot targeting police in Belgium was disrupted in that country last January because Abdelhamid Abaaoud-suspected mastermind of both that plot and the Paris attacks-had failed to use encryption.  He also carelessly left behind a cellphone in Syria, which contained unencrypted pictures and videos, including one now-infamous video showing him smiling from a truck as he dragged bodies of victims through a street.
All of this suggests that the attackers were guilty of major OPSEC failures-that is, if it werent for the fact that some of them still managed to pull off the Paris attacks without prior detection.  This suggests they either did use encryption during earlier planning stages of their attacks, or that authorities were so overwhelmed tracking other suspects-French investigators claim they recently thwarted six other attacks-that they overlooked the suspects who pulled off the Paris attacks.  This indeed might be the case since Turkish authorities have said they tried to warn French authorities twice about one of the suspects but never got a response.
Despite this, US authorities have flooded the media this week with stories about how ISIS use of encryption and other anti-surveillance technologies has thwarted their ability to track the terrorists.  But authorities have also slyly hinted that some of the encryption technologies the terrorists use are not as secure as they think they are, or are not being configured and used in a truly secure manner.  So what exactly are ISIS attackers doing for OPSEC?
It turns out that a 34-page guide to operational security (.pdf) that ISIS members advise recruits to follow, offers some clues.  Aaron Brantly and other researchers with the Combating Terrorism Center at West Points military academy uncovered the manual and other related documents from ISIS forums, social accounts and chat rooms.  The originals are in Arabic, but the center provided WIRED with translated versions of a number of documents that had been passed through Google Translate.1
The guide was originally written about a year ago by a Kuwaiti security firm known as Cyberkov to advise journalists and political activists in Gaza on how to protect their identities, the identity of their sources and the integrity of information they report.  But members of ISIS have since co-opted it for their own use as well.
The guide offers a handy compilation of advice on how to keep communications and location data private, as well as links to dozens of privacy and security applications and services, including the Tor browser, the Tails operating system; Cryptocat, Wickr, and Telegram encrypted chat tools; Hushmail and ProtonMail for email; and RedPhone and Signal for encrypted phone communications.  Gmail, the guide notes, is only considered secure if the account is opened using false credentials and is used with Tor or a virtual private network.  Android and iOS platforms are only secure when communications are routed through Tor.
The manual advises disabling the GPS tagging feature on mobile phones to avoid leaking location data when taking photos-a mistake that a Vice reporter made in 2012 when interviewing murder suspect John McAfee who was on the lam.  Alternatively, operatives and journalists can use the Mappr app can be used to falsify location data and throw intelligence agencies off their trail.
The OPSEC manual used by ISIS also advises against using Instagram because its parent company, Facebook, has a poor track record on privacy, and it warns that mobile communications can be intercepted, even though GSM networks are encrypted.  It advises readers to use encrypted phones like Cryptophone or BlackPhone instead.
Dropbox is held up for special condemnation-because Edward Snowden advised against using it, and because President Bushs former Secretary of State Condoleezza Rice is on the companys investors board.
There are no surprises among the documents.  Most of the recommendations are the same that other civil liberties and journalist groups around the world advise human rights workers, political activists, whistleblowers and reporters to use to secure their communications and obscure their identity or hide their location.  The appearance of this and other OPSEC documents in ISIS forums and social media accounts indicate that the jihadis have not only studied these guides closely, but also keep pace with the news to understand the latest privacy and security vulnerabilities uncovered in apps and software that could change their status on the jihadi greatest-hits list.
'This is about as good at OPSEC as you can get without being formally trained by a government...  But there's a difference between telling somebody how to do it and then doing it right.'  West Point cyber fellow Aaron Brantly
This is about as good at OPSEC as you can get without being formally trained by a government, Brantly, a cyber fellow with the West Point center, told WIRED.  This is roughly [the same advice] I give to human rights activists and journalists to avoid state surveillance in other countries.  If they do it right, then they can become pretty secure.  [But] theres a difference between telling somebody how to do it and then [them] doing it right.
Intelligence agencies, of course, are hoping that ISIS jihadis dont get it right.
The documents warn that followers should use strong passwords and avoid clicking on suspicious links, to prevent intelligence agencies and everyday hackers from breaching their systems.  And theres advice for communicating even when repressive regimes block Internet and mobile networks to thwart activists from organizing, such as during the Arab Spring.  It coaches readers, for example, on how to set up their own private Wi-Fi network or use apps like FireChat to share photos and text short distances without needing internet access.
It advises users to always use a VPN online to encrypt data and prevent ISPs and spy agencies from reading their communication.  But it cautions users to stay away from American providers of VPNs and encrypted chat tools and instead use ones like Telegram and Sicher, instant messaging apps made by companies based in Germany, or the Freedome, a VPN from the Finish computer security firm F-Secure.  Apples iMessage, an end-to-end encryption service, also gets a thumbs-up for being impervious to both spying from government intelligence agencies and Apple itself.
Although US government officials have repeatedly cited WhatsApp as a tool ISIS uses to thwart surveillance, the Kuwaiti manual actually puts the chat application on a banned list.  Although WhatsApp offers end-to-end encryption, a German security firm found problems with its implementation earlier this year.
Brantly says one thing he hasnt seen in any documents or discussions found in ISIS forums and social media accounts is mentioned of Sonys PlayStation 4 for protected communication.  Although a Belgian official told media last week, prior to the Paris attacks, that ISIS operatives in Belgium had been using Sonys videogame system to communicate, Brantly says hes seen no sign of that in their research.  Ive never seen PlayStation come up in any document, he says.
He also says theyve seen no sign yet that ISIS is using home-brewed encryption programs that its members created themselves.  Al Qaeda developed their own encryption platform for a while.  But ISIS right now is largely using Telegram [for encrypted communication], he says.
Documents like the Kuwaiti OPSEC manual arent the only aid jihadis have to protect their communications.  To help them master their OPSEC, ISIS also reportedly provides a 24-hour help desk.
Brantly says the jihadis they encounter in ISIS forums and chatrooms vary greatly in their technical savviness.  He also says there are signs of increased interest not only in securing their own communication but in hacking other targets as an ISIS tactic.  The so-called Cyber Caliphate, a hacking group that supports ISIS, claimed responsibility for hacking the US Central Commands Twitter and YouTube accounts earlier this year.  ISIS hackers have also taken credit for hacking a number of government ministries in Iran and stealing internal communications and login credentials, some of which they posted online.
Theres a whole section on hacking [in the ISIS forums], Brantley says.  Theyre not super-talented hackers, but theyre reasonable.
1 UPDATE 11/21/2015: This story has been updated to identify the original source of the document-a Kuwaiti security firm-and the original reason for its creation.

@_date: 2015-11-23 12:22:34
@_author: Henry Baker 
@_subject: [Cryptography] Fighting fear (of encryption) with fear (of bad 
At the risk of upsetting our ever-patient moderator, I'd like to continue to discuss how to fight this Second Crypto War.
[Note that I don't work for any cellphone company; so the only dog I have in this fight is my own personal privacy and freedom.]
As I understand the current state of play, the Comey faction has currently tabled for the moment the discussion of encryption of data-in-motion to focus on backdoors for data-at-rest.
The current Comey argument:
* the Fourth Amendment allows for access to all data on cellphones with a warrant, because
* pedophiles
* kidnap victims
* terrorists
As endlessly discussed here & elsewhere, the distinctions between access with/without a warrant and data-in-motion/data-at-rest aren't as clear as politicians would have us believe.  At the end of the day, it will be up to the phone itself to decide the validity of a "warrant", which means that an entire digital legal system -- including verifiable chains-of-trust and digitally-signed warrants -- will have to be set up.
In order to deal with "exigent circumstances" -- e.g., real-time kidnappings, terrorism -- there needs to be an entirely separate digital legal "exigency" system, complete with its own verifiable chains-of-trust, digitally verifiable proof-of-identity of the requesting federal/state/local officer, etc.
Setting up a proper digital system like this can probably be done -- given enough research funding and time -- but it is likely to take decades to develop the algorithms, the software and the legal underpinnings.
In the meantime, govts want us to *trust the manufacturers* and *trust the govts*, rather than "trust the math.*
But we haven't heard the other side of the argument.  Yes, there are societal pressures on law enforcement and politicians to catch criminals and terrorists.  But what are the current costs to their proposals?
So far, the "encryptionistas" have argued that a back door scheme would be the equivalent of "leaving the keys under the doormat".  Unfortunately, this is not a strong argument, because many people do exactly that -- they DO leave their house keys under the doormat.  They also entrust their homes to 3rd parties like ADT Security, and businesses routinely entrust their businesses to cleaning services, and the Supreme Court has ruled (so far) that once you provide access to a third party, it is fair game for the govt.
But I think that the encryptionistas haven't made their strongest case because doing so might undermine their businesses.
The real story about encryption is that *we are just one headline away from total disaster.*
It is so difficult to "do encryption right", that even extremely well funded organizations routinely make simple (in hindsight) mistakes that cost billions.
Anyone who has been paying attention to the various hacking conferences (Defcon, Black Hat, etc.) comes away marvelling at the cleverness of the attacks, and also the face-plant Monday Morning quarterbacking about the lack of defenses.  Those in the business have a sense of schadenfreude, but sober after many sleepless nights, they think to themselves, "there but for the grace of god, go I".
We study the crypto mistakes of the Japanese and the Germans in WWII, but these were extremely intelligent people, so "how could they be so stupid" simply doesn't work.
When I studied "codes" as an electrical engineering undergraduate, I was studying *error-detecting* and "error-correcting* codes, where the adversary was Maxwell's Demon.  Maxwell's Demon was a Gaussian (or other relatively simple) noise source, but not a 192-IQ math genius.  Yesterday's dumb Maxwell's Demon has now become Maxwell Demon, PhD, complete with Maxwell's own prodigious IQ.  As Nassim Nicholas Taleb might put it, computer engineers no longer live in Mediocristan, where the mean (average) is the engineer's friend, but in Extremistan; where the long fat tails will kill you.
So the strength of our codes today is measured by how many math geniuses have broken their picks on the codes.  We really don't have much more *science* or *math* on which to gauge our crypto systems.  Turing's mythical quote from the movie is essentially correct:
Cdr. Alastair Denniston: "Everyone thinks Enigma is unbreakable."
Alan Turing: "Well, let me try and we'll know for sure."
So the encryptionistas have to come clean with the public about the precarious nature of their craft.  Those secrets in your cellphone?  They could be compromised in an instant.  That money in your online bank account?  Gone in sixty seconds.  That insulin pump in your belly?  Kill you in 3 minutes.
In today's techno world, the lack of any significant *diversity* in digital systems means that almost any flaw becomes a systemic risk.  Apple iPhones now number greater than 3/4 billion, so trillions of dollars ride on the efficacy of the iPhone security *system*.  (I say *system*, because security depends on a lot more than just the encryption itself, but also the protection of the keys, etc.)
All of the digital device companies want to get into *financial transactions* because Willy Sutton.  But who's going to trust a company which admits that its encryption isn't perfect, and worse, whose products' compromise could result in hundreds of millions of victims ?
So if disaster is around the corner, but no one is going to mention this elephant in the room, how do we fight the fear of kidnappers and terrorists, with the alternative fears of losing one's identity, losing one's fortune, or losing one's life (medical device, automobile software, electrical grid meltdown, etc.) ?
*Someone*, or better yet, *everyone*, has to break the news to the politicians that all isn't sweetness and light with crypto codes.  Tampering with crypto codes is equivalent to picking the lock on Pandora's Box -- you don't really want to go there.  Politicians haven't done well at designing automobiles or running car companies; it's highly unlikely that they will be very good at designing encryption systems.
As Scotty would always say to Captain Kirk, "I can't hold her together much longer, Captain!"  We, like Scotty, have to admit as much to our "policy-makers".
The reference to Star Trek is apt.  The current Internet crypto systems are already on life-support; the best analogy is to NASA's space shuttle program.  "It hasn't failed yet" led NASA to continue to underestimate the risks until the Challenger disaster finally forced NASA to admit that the odds of a failure were much higher than previously advertised to Congress and to the American people.

@_date: 2015-11-23 15:06:57
@_author: Henry Baker 
@_subject: [Cryptography] ISIS OPSEC Manual Debunked? 
Poor Kim Zetter of Wired; she really embarrassed herself (& me!) by falling for this lie/disinformation.
[BTW, will Dr. Aaron Brantly be fired or commended for this plagiarism?]
"A lie can travel half way [a million times?] around the world while the truth is putting on its shoes." -- Mark Twain
In fact, the manual was written by a Kuwaiti security firm to aid journalists, and has nothing to do with ISIS or its jihadis.
"Instead of propagating negative articles about the use of encryption, *Journalists* should be on the forefront of *defending encryption,* seeing as how it provides critical protection for them and their sources."
Official Statement Regarding Media Confusion on Cyberkov Journalist Cybersecurity Manual
For the past few days, many articles around the world started referencing an alleged ISIS OPSEC manual that is claimed to be unearthed by the U.S Military Academy Combating Terrorism Center at West Point by Dr. Aaron Brantly and other researchers.  The first mention of this manual (and the most widespread so far) was Kim Zetters WIRED article (ISIS OPSEC Manual Reveals How It Handles Cybersecurity).  The original claim was that this manual was written by ISIS as its cyber security policy for its fighters.
The false story about the manual spread all over the globe, being referenced by US, UK, Chinese, Italian, Russian, Hungarian, Greek, South Korean and even Vietnamese media.  We were stunned by the scale and speed with which the story propagated throughout the web, and even though we have made contact with many reporters to correct the mistake, we believe an official statement is obligatory.
The alleged ISIS manual is in reality Cyberkovs own security manual for journalists and activists written in July 2014.  The original manual can be found here, and its main goal is to assist journalists and activists (especially those working in warzones like Gaza) protect their digital identity, their sources and their core ability to provide free flow of information to the rest of the world.
The file linked by the WIREDs article links to a modified copy of the manual hosted in JustPasteIt.  It was apparently uploaded by a Gaza resident.  The article was modified from its original form, however it still contained some links to Cyberkovs blog.  Not only is the article completely devoid of any ISIS references, but it came as a shock to us to discover the Combating Terrorism Center did not have any proper Arabic translators on board; instead running the article through Google Translate!
We believe it is a significant hit to the Centers reputation, accuracy and professionalism that they couldnt differentiate between ISIS and journalism manuals; and that they simply accepted Google Translate as a proper method to translate and set judgement in such sensitive topic.  We simply hope the rest of the worlds think tanks are utilizing better non-amateur methods of information extraction.
We also think its very unfortunate that globally-acclaimed news agencies and world-class reporters are unable to perform proper analysis and verification on their stories.  Unfortunately, such a false report comes right as world governments are trying their best to ban encryption by falsely associating it with criminal and terrorist organizations.  Instead of propagating negative articles about the use of encryption, Journalists should be on the forefront of defending encryption, seeing as how it provides critical protection for them and their sources.
What is Cyberkov?
Cyberkov is a Kuwaiti cyber security firm, providing cyber security services to banks, telecom providers, government entities and non-profit privacy-driven organizations.  Cyberkov runs an awareness and privacy blog at blog.cyberkov.com.
Abdullah AlAli
Chief Executive Officer
Cyberkov Co. Ltd.
Our address:
Cyberkov Co. Ltd
Kuwait City, Kuwait

@_date: 2015-11-23 15:24:35
@_author: Henry Baker 
@_subject: [Cryptography] ISIS OPSEC Manual Debunked? 
It appears that Dr. Aaron Brantly violated the West Point code of honor with his lie about this "ISIS" manual.
"A cadet will not lie, cheat, steal, or *tolerate those [like Dr. Aaron Brantly] who do*"
"Men may be inexact or even untruthful in ordinary matters and suffer as a consequence only the disesteem of their associates or the inconvenience of unfavorable litigation, but the *inexact or untruthful* soldier trifles with the lives of his fellow men and *with the honor of his government,* and it is therefore no matter of pride but rather a stern disciplinary necessity that makes West Point require of her students a character for trustworthiness that knows no evasions."
Brantly knew full well the contents of the stories that he planted, and knew that they were lies.
Let's all hold our breath waiting for him to be fired from West Point, either for lying or for incompetence.

@_date: 2015-11-24 07:34:00
@_author: Henry Baker 
@_subject: [Cryptography] A Paris Cryptographer On Encryption and Terrorists 
FYI --
Nadim Kobeissi
On Encryption and Terrorists
Nov 23, 2015
In light of the recent terrorist attacks, things are getting heated for the regular security and encryption software developer.  Being one myself, Ive been on the receiving end of a small avalanche of requests from journalists, political pundits and even law enforcement.  Im also someone who was born and raised in Beirut and who recently immigrated to Paris, both of which were the sites of twin attacks, one day apart from each other.
It seems necessary to share some perspective on whats going on with encryption software, the terrorists supposedly using it, and what this means for the rights and the security of our global communities.
The encryption software community writes a large variety of software, from secure instant messaging to flight tower communication management to satellite collision prevention.  We do this for a number of reasons, but theres always an underlying shared understanding: that were using mathematics and engineering to contribute towards a society thats safer, more capable and able to communicate with a sense of privacy and dignity inherent to all modern societies.  The premise driving the people writing encryption software is not exactly that were giving people new rights or taking some away: its the hope that we can enforce existing rights using algorithms that guarantee your ability to free speech, to a reasonable expectation of privacy in your daily life.  When you make a credit card payment or log into Facebook, youre using the same fundamental encryption that, in another continent, an activist could be using to organize a protest against a failed regime.
In a way, were implementing a fundamental technological advancement not dissimilar from the invention of cars or airplanes.  Ford and Toyota build automobiles so that the entire world can have access to faster transportation and a better quality of life.  If a terrorist is suspected of using a Toyota as a car bomb, its not reasonable to expect Toyota to start screening who it sells cars to, or to stop selling cars altogether.
And yet, this is the line of questioning that has besieged the cryptography community immediately after the Paris attacks.  A simple mention of my encryption software in an Arabic-speaking forum is enough to put me on the receiving end of press inquiries such as are you aware of any terrorists using your software?  Do you feel its your responsibility to monitor terrorist activity?  Or, more bluntly, do I feel like Im complicit in aiding terrorists, by the simple fact that I write cryptography software or currently do PhD research in applied cryptography?
The brouhaha that has ensued from the press has been extreme.  Ive received calls that bluntly want to interview me regarding technology used by terrorists, such as yours.  A Wired article, like many alongside it, finds an Arabic PDF guide on encryption and immediately attributes it as an ISIS encryption training manual even though it was written years ago by Gaza activists with no affiliation to any jihadist group.
In this rush to blame a field that is largely unknowable to the public and therefore at once alluring and terrifying, little attention has been paid to facts: The Paris terrorists did not use encryption, but coordinated over SMS, one of the easiest to monitor methods of digital communication.  They were still not caught, indicating a failure in human intelligence and not in a capacity for digital surveillance.
But even in light of all the evidence pointing towards a human intelligence failure, cryptography, being to the outsider a scary and mysterious usage of secret codes and complicated algorithms, remains an easy target.  The press again drives the discussion, each time with a lessened priority for measured questioning and proper investigation.  Why havent you inserted back doors into your software?  Do you want terrorists to use your tools?
The call for backdoors is nothing new.  During my career in the private sector, Ive seen requests to backdoor encryption software so as to please potential investors, and have seen people in the field who appeared to stand for secure software balk under the excuse of if thats what the customer wants, even if it results in irreparable security weaknesses.  Ive had well-intentioned intelligence officers ask me informally, out of honest curiosity, why it is that I would refuse to insert backdoors.  The issue is that cryptography depends on a set of mathematical relationships that cannot be subverted selectively.  They either hold completely or not at all.  Its not something that were not smart enough to do; its something thats mathematically impossible to do.  I cannot backdoor software specifically to spy on jihadists without this backdoor applying to every single member of society relying on my software.
And Ive seen what guarantees secure communication can give a society.  Ive seen my software used in Hong Kong to organize protests against a government otherwise unwilling to give people their rights.  Ive seen my colleagues produce software used by Egyptians rallying for democracy.  Ive had childhood friends call me from Beirut, desperate to know of a way to organize protests against a government that would lock them up were they to use public phone lines.  Ive set up communication lines for LGBTQ organizations so that they can give counsel without fearing ostracization or reprisal.  And in the comfort of my new life in France, Ive also relied on encryption so that I know Im obtaining my simple right to privacy when discussing my daily life with my friends or with my partner.
Ive come to see encryption as the natural extension a computer scientist can give a democracy.  A permeation of the simple assurance that you can carry out your life freely and privately, as enshrined in the constitutions and charters of France, Lebanon as well as the United States.  To take away these guarantees doesnt work.  It doesnt produce better intelligence.  Its not why our intelligence isnt competing in the first place.  But it does help terrorist groups destroy the moral character of our politics from within, when out of fear, we forsake our principles.
If we take every car off the street, every iPhone out of peoples pockets and every single plane out of the sky, it wouldnt do anything to stop terrorism.  Terrorism isnt about means, but about ends.  Its not about the technology but about the anger, the ignorance that holds a firm grip over the actors mind.
I grew up and spent a decade of my childhood in south Beirut and was literally neighbors with the security sector of Hezbollah, a guerilla organization that fights frequent wars with Israel.  During the 2006 war, an Israeli fighter jet carpet-bombed the entire neighborhood, razing my home and that of many others to the ground.  While walking through a field of rubble and unexploded cluster bombs to try and find my house, I distantly saw a friend of mine, far away on the other side of whatever it was that I was staring across.  We locked eyes.  Then, we burst out laughing.  We laughed for a long time.
In 2008, I got the opportunity to move away from Lebanon and to get an education abroad.  This opportunity was rare and unusual.  Making encryption software is hard, too: for many of my first years abroad, much of my software was riddled with bugs, and it took practice and feedback in order to start getting things right  namely, what my education abroad of Lebanon really was about.
Visiting south Beirut a few years later, I found that I had changed but that no one else there had.  The rubble was mostly but not completely gone.  I also found that people were angry, and that Hezbollah had pledged to rebuild their homes.  Left without any hope for a good education, for a happy life, with much of their families missing, with their friends dead, many pledged themselves in return.
Thats whats causing terrorism, not encryption software.
nadim at nadim.computer

@_date: 2015-11-25 13:49:05
@_author: Henry Baker 
@_subject: [Cryptography] Greenwald: Why the CIA is smearing encryption 
FYI -- I changed the title because I thought it was more appropriate for this list.
"The real objective is to depict Silicon Valley as terrorist-helpers for the crime of offering privacy protections to Internet users, in order to force those companies to give the U.S. government "backdoor" access into everyone's communications."
"Help me RhondaXXXXXXEdward, help me get herXXX'em out of my heartXXXXXstuff." -- The Beach Boys
Op-Ed: Why the CIA is smearing Edward Snowden after the Paris attacks
Glenn Greenwald
Decent people see tragedy and barbarism when viewing a terrorism attack.  American politicians and intelligence officials see something else: opportunity.
Bodies were still lying in the streets of Paris when CIA operatives began exploiting the resulting fear and anger to advance long-standing political agendas.  They and their congressional allies instantly attempted to heap blame for the atrocity not on Islamic State but on several preexisting adversaries: Internet encryption, Silicon Valley's privacy policies and Edward Snowden.
The CIA's former acting director, Michael Morell, blamed the Paris attack on Internet companies "building encryption without keys," which, he said, was caused by the debate over surveillance prompted by Snowden's disclosures.  Sen. Dianne Feinstein (D-Calif.) blamed Silicon Valley's privacy safeguards, claiming: "I have asked for help.  And I haven't gotten any help."
Former CIA chief James Woolsey said Snowden "has blood on his hands" because, he asserted, the Paris attackers learned from his disclosures how to hide their communications behind encryption.  Woolsey thus decreed on CNN that the NSA whistleblower should be "hanged by the neck until he's dead, rather than merely electrocuted."
In one sense, this blame-shifting tactic is understandable. After all, the CIA, the NSA and similar agencies receive tens of billions of dollars every year from Congress and have been vested by their Senate overseers with virtually unlimited spying power.  They have one paramount mission: find and stop people who are plotting terrorist attacks.  When they fail, of course they are desperate to blame others.
The CIA's blame-shifting game, aside from being self-serving, was deceitful in the extreme.  To begin with, there still is no evidence that the perpetrators in Paris used the Internet to plot their attacks, let alone used encryption technology.
CIA officials simply made that up. It is at least equally likely that the attackers formulated their plans in face-to-face meetings.  The central premise of the CIA's campaign  encryption enabled the attackers to evade our detection  is baseless.
Even if they had used encryption, what would that prove?  Are we ready to endorse the precept that no human communication can ever take place without the U.S. government being able to monitor it?  To prevent the CIA and FBI from "going dark" on terrorism plots that are planned in person, should we put Orwellian surveillance monitors in every room of every home that can be activated whenever someone is suspected of plotting?
The claim that the Paris attackers learned to use encryption from Snowden is even more misleading.  For many years before anyone heard of Snowden, the U.S. government repeatedly warned that terrorists were using highly advanced means of evading American surveillance.
Then-FBI Director Louis Freeh told a Senate panel in March 2000 that "uncrackable encryption is allowing terrorists  Hamas, Hezbollah, Al Qaeda and others  to communicate about their criminal intentions without fear of outside intrusion."
Or consider a USA Today article dated Feb. 5, 2001, eight months before the 9/11 attack.  The headline warned "Terror groups hide behind Web encryption."  That 14-year-old article cited "officials" who claimed that "encryption has become the everyday tool of Muslim extremists."
Even the official version of how the CIA found Osama bin Laden features the claim that the Al Qaeda leader only used personal couriers to communicate, never the Internet or telephone.
Within the Snowden archive itself, one finds a 2003 document that a British spy agency called "the Jihaidi Handbook."  That 12-year-old document, widely published on the Internet, contains instructions for how terrorist operatives should evade U.S. electronic surveillance.
In sum, Snowden did not tell the terrorists anything they did not already know.  The terrorists have known for years that the U.S. government is trying to monitor their communications.
What the Snowden disclosures actually revealed to the world was that the U.S. government is monitoring the Internet communications and activities of everyone else: hundreds of millions of innocent people under the largest program of suspicionless mass surveillance ever created, a program that multiple federal judges have ruled is illegal and unconstitutional.
That is why intelligence officials are so eager to demonize Snowden: ongoing rage that he exposed their secret, unconstitutional schemes.
But their ultimate goal is not to smear Snowden.  That's just a side benefit.  The real objective is to depict Silicon Valley as terrorist-helpers for the crime of offering privacy protections to Internet users, in order to force those companies to give the U.S. government "backdoor" access into everyone's communications.  American intelligence agencies have been demanding "backdoor" access to encryption since the mid-1990s.  They view exploitation of the outrage and fear resulting from the Paris attacks as their best opportunity yet to achieve this access.
The key lesson of the post-9/11 abuses  from Guantanamo to torture to the invasion of Iraq  is that we must not allow military and intelligence officials to exploit the fear of terrorism to manipulate public opinion.  Rather than blindly believe their assertions, we must test those claims for accuracy.  In the wake of the Paris attacks, that lesson is more urgent than ever.
Glenn Greenwald is a founding editor of the Intercept.  He led the reporting for the Guardian's 2013 series on global surveillance programs, based on classified documents disclosed by Edward Snowden, which was awarded the Pulitzer Prize for Public Service.

@_date: 2015-11-25 14:12:05
@_author: Henry Baker 
@_subject: [Cryptography] Police Chiefs & Prosecutors Seek Access to Encrypted 
FYI -- The drumbeat continues...
Police Chiefs and Prosecutors Join Together to Seek Lawful Access to
Encrypted Communications
Alexandria, VA  Recognizing the challenges posed to public safety by
encrypted communications, the International Association of Chiefs of
Police (IACP) and the National District Attorneys Association (NDAA)
have joined forces to press for immediate action to address this
critical threat and urge public officials and industry leaders to work
with law enforcement to develop solutions that will help protect the
The proliferation of sophisticated encryption technology and other
technological barriers have increasingly hindered law enforcements
ability to lawfully access criminal and terrorist related
communications.  The inability of law enforcement to overcome these
barriers (known as "Going Dark" in the law enforcement community) has
already led to numerous instances where investigators were unable to
access information that could have allowed them to successfully
investigate and apprehend criminals or prevent terrorists from
In response to this growing problem, earlier this year, the IACP
convened a Law Enforcement Summit on "Going Dark" to help identify
legal, technical, and operational concerns associated with the issues
surrounding the gathering and use of data related to communications
and mobile devices.  NDAA, as well as a broad array of law enforcement
leaders, investigators, and subject matter experts participated in the
The summit report, which can be viewed here, reviews the current
capabilities of law enforcement agencies, the impact that
technological advances are having on law enforcement investigations,
and the role of industry in this debate.  The summit report also makes
clear that our laws have failed to keep pace with new technology and
that urgent and immediate action needs to be taken.
To that end, the IACP and NDAA are calling for legislative changes to
the Communications Assistance for Law Enforcement Act (CALEA), FCC
rules and the Electronic Communications Privacy Act (ECPA) in order to
bolster our public safety efforts. IACP and NDAA are committed to
finding a solution to this critical issue, which balances the needs of
the law enforcement community with protecting the publics right to
The IACP and NDAA look forward to working with lawmakers to strengthen
our current laws, and ensure that they are representative of todays
technology and the challenges public safety officials face in
preventing crime and safeguarding their communities.

@_date: 2015-11-25 15:34:15
@_author: Henry Baker 
@_subject: [Cryptography] Security of a permute-only system? 
Given a message source that's already "whitened", but otherwise unencrypted, how much security can be achieved strictly through an unknown, but random permutation?
I.e., if n=171, then a random permutation of size n would appear to require 1026 bits to specify it.
Suppose we simply applied our random permutation to each block of 171 pre-whitened bits.
This random permutation is used essentially as (part of) a symmetric session key.
Let's assume neither CPA nor CCA: this scheme might be part of a larger system.
Q: does such a random permutation provide any additional security, or is it merely a waste of time?
(Let's assume that we can efficiently perform the permutation w/o any side channels -- e.g., perhaps an oblivious Batcher-type sorting network.)

@_date: 2015-11-26 06:32:38
@_author: Henry Baker 
@_subject: [Cryptography] Verified implementation of TLS: miTLS 
FYI --
There's a but -- a big but --
the certificate for  isn't trusted by my browsers !
miTLS is a verified reference implementation of the TLS protocol.  Our code fully supports its wire formats, ciphersuites, sessions and connections, re-handshakes and resumptions, alerts and errors, and data fragmentation, as prescribed in the RFCs; it interoperates with mainstream web browsers and servers.  At the same time, our code is carefully structured to enable its modular, automated verification, from its main API down to computational assumptions on its cryptographic algorithms.
The stable version of miTLS including the new 0.9 release are written in F# and specified in F7.  We present security specifications for its main components, such as authenticated stream encryption for the record layer and key establishment for the handshake.  We describe their verification using the F7 refinement typechecker.  To this end, we equip each cryptographic primitive and construction of TLS with a new typed interface that captures its security properties, and we gradually replace concrete implementations with ideal functionalities.  We finally typecheck the protocol state machine, and thus obtain precise security theorems for TLS, as it is implemented and deployed.  We also revisit classic attacks and report a few new ones.
See miTLS in action!
The development version is written and verified in F*, a ML-like functional programming language aimed at program verification.

@_date: 2015-11-26 08:04:20
@_author: Henry Baker 
@_subject: [Cryptography] Security of a permute-only system? 
FWIW, it is trivial to check whether a random permutation is
a derangement, as 37% of random permutations are.  So if it
is helpful, we can use a random derangement instead of a
random permutation by throwing out ~2/3 of the permutations.

@_date: 2015-11-26 09:08:15
@_author: Henry Baker 
@_subject: [Cryptography] WAPO: Tech industry defends encryption 
FYI --
"the backdoor is effective or all that useful for law enforcement, and it'll do more harm than good in the long run"
"Encryption protects not just government and commercial databases, but critical national infrastructure such as hospitals, airlines and nuclear power stations -- exactly the targets terrorists would attempt to hack and destroy"
"Government should not be pushing for solutions that would make the online environment less secure"
Tech industry defends encryption amid new questions following Paris attacks
By Catherine Ho November 25 Follow Technology industry groups are pushing back against calls from law enforcement and intelligence officials to give the government more access to encrypted networks following the Paris terror attacks.
Concrete evidence has yet to emerge that the perpetrators of the attacks used encrypted networks to communicate, but officials have warned that terrorists are finding new ways to avoid surveillance.  Some say requiring tech companies to design a so-called backdoor in the devices would give law enforcement better access to encrypted communications.
"It is likely that encryption, end-to-end encryption, was used to communicate between those individuals in Belgium, in France and in Syria," Senate Intelligence Committee Chairman Richard Burr (R-N.C.) said last week.  "It's a wake-up call for America and our global partners that globally, we need to begin the debate on what we do on encrypted networks, because it makes us blind to the communications and to the actions of potential adversaries."
Many tech companies have so far been reluctant to respond publicly to these calls, but a growing number of industry groups are coming out in defense of encryption and a lobbying coalition, called Reform Government Surveillance -- representing Google, Apple and other tech leaders -- has met with congressional staff and administration officials to discuss encryption policy.
"In the private sector, a lot of companies are already pushing back against" creating a backdoor, said Brian Finch, a lobbyist for cybersecurity companies.  "Tech companies are re-emphasizing the point that they don't think the backdoor is effective or all that useful for law enforcement, and it'll do more harm than good in the long run."
Among the industry's main arguments is that there is no evidence the Paris attackers communicated via encrypted systems and if the government forces tech companies to weaken encryption, terrorists will simply start using devices or apps that aren't subject to U.S. laws.
"Tech industry's pushback right now is, '[Law enforcement], you're using this opportunistically, to your advantage,'" said a lobbyist for major tech companies who asked not to be named in order to protect professional relationships.  "There's no proof that terrorists used encrypted networks.  Law enforcement, you missed this, stop trying to blame us."
On Tuesday, The Software Alliance (BSA) mounted a strong defense of encryption technology, saying it is a critical tool that protects users' online privacy.
"That is not the case.  Encryption -- rather than something to be feared -- is a valuable tool millions of people rely on every day to secure their online privacy," the BSA said.  "Government should not be pushing for solutions that would make the online environment less secure."
Two other leading tech industry groups are echoing those sentiments, citing the role of encryption in protecting online banking, transportation security systems and other critical infrastructure, such as hospitals, from potential hackers.
Dean Garfield, the president of the Information Technology Industry Council (ITI), the Washington-based group that represents some of the world's largest hardware, software, mobile and search companies, said last week that weakening encryption technology "simply does not make sense."
The Software and Information Industry Association (SIIA), which represents the software and digital content industries, said strong encryption helps boost national security, not threaten it.
"Encryption protects not just government and commercial databases, but critical national infrastructure such as hospitals, airlines and nuclear power stations -- exactly the targets terrorists would attempt to hack and destroy," the group's senior vice president of public policy Mark MacCarthy said last week.  "If the U.S. government gained backdoor access to encrypted material, it is possible that other governments and non-government actors would as well and encryption would become useless."
Representatives for Apple and Google either did not return requests for comment or declined to comment.
Tech policy experts predict a renewed round of congressional hearings and possible legislation after Thanksgiving, but they aren't convinced the encryption debate will drastically change.  It reached a standstill in October when the White House decided it wouldn't seek legislation forcing tech companies to decode encrypted data for law enforcement.
Burr and Sen. Dianne Feinstein (D-Calif.), the top Democrat on the intelligence panel, have indicated they want to revisit discussions with tech companies about the government's access to secure communications, but legislation has yet to be drafted.
"I'm not convinced anything new will come out of it," said the tech lobbyist.  "But it'll get a fresh look."
Catherine Ho covers lobbying at The Washington Post.  She previously worked at the LA Daily Journal, the Los Angeles Times, the Detroit Free Press, the Wichita Eagle and the San Mateo County Times.

@_date: 2015-11-28 06:37:33
@_author: Henry Baker 
@_subject: [Cryptography] And it goes on... 
The fact that Prof Hoffman is from Georgetown tells you all you need to know.  Virtually every university within 100mi of Wash DC has a captive CS dept:
The Most Militarized Universities in America: A VICE News Investigation
Re encryption: the people at NSA/CIA/DHS can't be so stupid as to think that compromised encryption is going to increase the security of the US.  Yet they seem to keep saying "but encryption".
We know what the FBI's motive is: they're willing to throw all of our security under the bus to make their own jobs 5% easier.
But what is NSA/CIA/DHS's end-game?
Why are these people requesting *unilateral disarmament* wrt encryption?

@_date: 2015-11-28 14:16:57
@_author: Henry Baker 
@_subject: Encryption Backdoors wont make us safer from terrorism.  They 
FYI --
We must do something.  This is something!  Therefore we must do it.
"Dont we need a CIA director who knows how to prevent his own communications from being hacked by teens?"
"Yet Brennan is Alan Turing next to Sens. Dianne Feinstein and John McCain"
"If secure encryption is outlawed, only outlaws will have secure encryption"
Nov. 19 2015 4:53 PM
There Is No Good Argument for Encryption Backdoors
They wont make us safer from terrorism.  They might do the opposite.
By David Auerbach
The British satire Yes, Minister once captured the politicians reaction to any crisis with this syllogism: We must do something.  This is something!  Therefore we must do it.  In the case of the Paris terror attacks, American politicians have grabbed at two somethings: refusing to accept Syrian refugees, and demanding encryption backdoors so that intelligence agencies can better spy on people.  And as one would expect from any instant-reflex policy proposal, neither will do a thing to prevent terror attacks.  And in the case of encryption, at least, the politicians and intelligence leaders are too technologically ignorant to even understand what theyre asking for.
The demand for encryption backdoors, which would grant law enforcement agencies their own keys to decode private and strongly encrypted communications, is not new, but its been steadily gaining volume, with a loud uptick every time a high-profile hack, like Sony Pictures or the federal Office of Personnel Management, occurs.  Its true that ISIS has displayed increasing technological sophistication.  But as the Intercept reports, the Paris terrorists appear to have done at least some coordination over unencrypted SMS, which would mean encryption-cracking wouldnt have even been needed to snatch those communications and stop the attacks, contrary to what New York City Police Commissioner William Bratton insisted on Sunday.  (And as Marcy Wheeler wrote in Slate on Monday, metadata surveillance didnt help either.)  Moreover, given that the National Security Agency and the U.K.s Government Communications Headquarters already sweep up unencrypted data with a vacuum-cleaner approac
h, it wouldnt be surprising if one of these agencies actually did capture the terrorists communications, only to ignore them.  They have more data than they can process.  So what, then, is the reasoning behind wanting to crack encryption?
In order for agencies like the NSA to get these backdoors, we have to assume theyd require private keys into networks that would be kept in escrow but could be obtained legally whenever the government decided.  This would immediately put the security of any encrypted communication at risk should those private keys be compromised by another Edward Snowden or worse.  A theoretical alternative, termed split-key encryption, is so technologically infeasible even the FBI admits its not going to happen.  FBI General Counsel James Baker said just this month, It's tempting to try to engage in magical thinking and hope that the amazing technology sector we have in the United States can come up with some solution, and maybe that's just a bridge too far.  Maybe [split-key encryption] is scientifically and mathematically not possible.
CIA Director John Brennan, whose personal AOL email account was hacked by teenagers last month, lacks Bakers technical acumen.  As Wireds Kim Zetter reported, Brennan had sent sensitive government documents to his personal email from his work email and had evidently done so without any encryption whatsoever.  If Brennan is so lax with his own security, we should worry about securing our own data from attack rather than making it less secure in the name of expanded spying capabilities.  Dont we need a CIA director who knows how to prevent his own communications from being hacked by teens?  For all the attention paid to Hillary Clintons private email accounts, Brennan seems to have earned immunity from such obvious questions.  Brennan is a locksmith who leaves his own doors open.
Yet Brennan is Alan Turing next to Sens. Dianne Feinstein and John McCain, who this week invoked fear, uncertainty, and doubt as though it were Sept. 12, 2001.  Said Feinstein: If you create a product that allows evil monsters to communicate in this way, to behead children, to strike innocents, whether its at a game in a stadium, in a small restaurant in Paris, take down an airliner, thats a big problem.  (If only gun manufacturers faced the same level of hyperbole as security engineers.)  Calling for legislation that would mandate backdoors, McCain echoed Brennans demands, saying, Its time we had another key that would be kept safe and only revealed by means of a court order.  McCain didnt explain what he meant by kept safe and revealed, even though neither term is trivial when it comes to encryption keys.  Nor did he seem to realize that you simply cant mandate that all encryption algorithms automatically give backdoor keys to the government.  Trying to stop people
 from using encryption without backdoors would be like trying to stop people from pirating music and movies, and we all know how successful that effort has been.  To paraphrase an argument made about a certain other unregulated technology: If secure encryption is outlawed, only outlaws will have secure encryption.
Anti-terrorism ought to demand that we secure our own sensitive digital assets through encryption and that law enforcement do the targeted human policing that time and again has proved far more effective at foiling terror plots than indiscriminate and ineffective surveillance.  Remember, the NSAs bulk collection program foiled exactly zero terror plots, by its own admission.  The call for encryption backdoors is just another extension of this futile and counterproductive dragnet.  The persistent ide fixe around encryptions potential dangers and the supposed silver bullet of backdoors pales next to the real holes remaining in our own security, which allowed the compromising of 20 million personnel files in the OPM hack and the sheer destruction of Sony Pictures internal systems by cyberterrorists.  Introducing encryption backdoors will carve one more gaping hole in our Swiss-cheese virtual infrastructure.  Politicians and intelligence leaders combination of technological illi
teracy and ham-fisted power-grabbing matches every stereotype of uneducated and ineffectual American brute force.  While decorum and good sense would seem to demand that such policy discussions be treated with high seriousness and respect to all involved, the level of ignorance displayed by politicians and intelligence leaders on these issues is simply galling.  To be blunt, the technologically savvy view Brennan, Feinstein, and McCain with contempt thanks to statements like the ones they made this week.  Their advocacy for encryption backdoors should be taken about as seriously as the latest ideas of Donald Trump.
This article is part of Future Tense, a collaboration among Arizona State University, New America, and Slate.  Future Tense explores the ways emerging technologies affect society, policy, and culture.  To read more, visit the Future Tense blog and the Future Tense home page.  You can also follow us on Twitter.

@_date: 2015-11-30 07:03:24
@_author: Henry Baker 
@_subject: [Cryptography] Security of a permute-only system? 
Could you provide just a tad more info?
Remember, I said no CPA, no CCA; pre-whitened bits prior to permutation.
W/o whitening, any non-uniform statistics will eventually reveal the permutation.
If you can compare input to output, you can eventually reveal the permutation, even if you can't choose the input.
But if you can't compare the bits coming in to the bits going out, how do you recover the permutation?

@_date: 2015-10-01 12:07:50
@_author: Henry Baker 
@_subject: [Cryptography] Hyper-V claims to protect tenant secrets ?? 
Microsoft claims that it can protect tenant VM secrets with Hyper-V.
Doesn't this violate some non-obfuscatability theorem?
I was under the impression that the only truly *safe* way to do cloud
computing was via some reduction-to-circuits scheme, which is hopelessly
BRK3457: Protecting Tenant Secrets in Hyper-V (80 minutes):

@_date: 2015-10-02 07:25:25
@_author: Henry Baker 
@_subject: [Cryptography] Hyper-V claims to protect tenant secrets ?? 
I watched the entire video, and no snark was intended.
It would appear that whichever cloud service utilizes this Microsoft technology has *literally* handed over the (encryption) keys to their kingdom to Microsoft, and the cloud service provider no longer *owns* and/or *controls* 'their'  cloud machines in any real sense.  This cloud service provider is merely providing real estate & electricity for his zombie Microsoftbot machines.
The acid test: can the cloud service provider -- no matter where located -- keep Microsoft from handing over cloud customer data to Microsoft itself or anyone that Microsoft designates -- e.g., FBI/NSA/GCHQ ?  No.
So while Microsoft itself may challenge DoJ in court re a Microsoft cloud machine in Ireland, any other cloud provider using this Microsoft technology is at the mercy of Microsoft receiving a secret NSL; Microsoft would have little standing to challenge such an NSL for some third-party cloud service.
The cloud customer, on the other hand, will trust this cloud service to the same extent that they trust Microsoft today.  For some customers, trusting Microsoft may be better than trusting cloud service provider A**z*n, but they still have to trust Microsoft.  In particular, both the cloud service provider and the cloud service customer must *trust Microsoft*, even for running non-Microsoft (e.g., Linux) code, because Microsoft has locked down the boot sequence on these machines.

@_date: 2015-10-04 18:39:49
@_author: Henry Baker 
@_subject: [Cryptography] Turing Bombes Enigma 
FYI -- I guess these devices fall into the category of the "Internet of Cool Historic Things".
It is a fully functioning Enigma machine you can wear on your wrist.  This is a three rotor Enigma machine as used by German Wermacht in WW2 for encoding messages.  [So far as I can tell, it's the most useful wrist computer I've seen to date...]
Turing-Welchman Bombe completed.
For those who havent been following the whole project basically I reverse engineered then build my own desktop version of the Bletchley Park Bombe, the machine the British used to help solve the Enigma code during WW2.
Thanks again to John Harper, who lead the BP Bombe rebuild team and who answered some questions for me, James Grime, mathematician and Enigma Expert, Magnus Ekhall who was one of people behind the online Bombe simulator, Frank Carter, who wrote the BP Report 4 booklet, and Bletchley Park themselves who managed to find and send me a copy of the aforementioned report that is out of stock!  Also the late Tony Sale who made available on his web site the US 6812th Division 1944 Bombe Report.
I started by making my own Enigma machine wristwatch because to understand the Bombe works you have to fully understand how Enigma works and how it was used operationally.
You can read about that here. [Link above]
My Turing-Welchman Bombe machine makes use of some software I wrote in C++ running on a Raspberry Pi 2.  I figured out for myself how the Bombe worked then wrote my own software version, initially in BASIC of all things to run on my homemade 6502 computer Orwell.  With the general algorithm worked out I ported it to C++.
The Raspberry Pi 2 connects to an Arduino which then drives three stepper motors, via driver boards, to turn the three indicator drums on the front of the machine.  These drums mimic the three indicators on the real Bombe.  The Arduino reports back the position of the drums to the Pi as a series of pulses then the Pi can tell the drums when to stop.  An LCD screen on the side of the machine mimics the original Bombe mechanical indicator unit as well as providing a basic user interface.  Start and Stop button are provided on the front of the machine as on the real Bombe.

@_date: 2015-10-05 08:00:37
@_author: Henry Baker 
@_subject: [Cryptography] Publicly affirm your support for strong encryption 
FYI -- 30k signatures this morning; need to get to 100k ASAP.
we petition the obama administration to:
Publicly affirm your support for strong encryption.
Reject any law, policy, or mandate that would undermine our security.
The government should not erode the security of our devices or applications, pressure companies to keep and allow government access to our data, mandate implementation of vulnerabilities or backdoors into products, or have disproportionate access to the keys to private data.
We demand privacy, security, and integrity for our communications and systems.  As a public, we should be confident that the services we use havent been weakened or compromised by government mandate or pressure.  No legislation, executive order, or private agreement with the government should undermine our rights.
Weakening encryption weakens the entire Internet.  Please endorse strong encryption, and encourage other world leaders to do the same.
Published Date: Sep 29, 2015

@_date: 2015-10-08 07:37:33
@_author: Henry Baker 
@_subject: [Cryptography] Collisions w/SHA-1 ~$100,000 TODAY 
FYI -- 64-GPU cluster produces cheap SHA-1 collisions.
We just successfully broke the full inner layer of SHA-1.
We now think that the state-of-the-art attack on full SHA-1 as described in 2013 may cost around 100,000
dollar renting graphics cards in the cloud.
"However, we showed that graphics cards are much faster for these attacks and we now estimate that a full SHA-1 collision will cost between 75,000 and 120,000 dollar renting Amazon EC2 cloud over a few months today, in early autumn 2015."
"This implies that *collisions are already within the resources of criminal syndicates*, almost two years earlier than previously expected, and one year before SHA-1 will be marked as unsafe in modern Internet browsers."
The Shappening: freestart collisions for SHA-1

@_date: 2015-10-19 10:56:31
@_author: Henry Baker 
@_subject: [Cryptography] Other obvious issues being ignored? 
So-called "hardware" crypto instructions on Intel/AMD/ARM/... are dead giveaways that crypto keys are nearby.  Since the microcode on modern architectures can be changed, it can also be hacked or "backed" (as in back-doored/hack-doored), such a hack can simply log potential key material to a hidden storage area for future exfiltration.  Perhaps it is better to stay away from "hardware" crypto instructions and come up with schemes that hide SW crypto calculations as side-effects of other calculations.
The nVidia version of ARM allows for "optimizations" that take a look at the instruction stream and compile something else entirely.  The code looks right & proves out mathematically, but fails because the *compiler* changed the meaning of the instructions.
Standardized crypto schemes with standardized parameters make it too easy for NSA/NOBUS to generate attacking ASIC's.  Better to have *simple* algorithms, but with enough parameters that are simultaneously & randomly chosen to run up the combinatorial complexity of any attack.  Of course, some combinations of parameters might lead to trivial breakage, so such systems need to be understood well enough to check for & eliminate these degenerate cases.  As in the case with hashes, try to force the attacker to use lots of memory accesses.
In general, the "expert" crypto advice against "newbie crypto" with "rookie mistakes" means a far greater reliance on a handful of standardized HW & SW implementations than is otherwise healthy.  Such advice paints targets on these standardized HW/SW implementations for all NSA/NOBUS wannabes, and dramatically reduces their costs for generic surveillance.  Yes, the costs are large in terms of cores and coal, but small in terms of crypto brainpower.  Better to have multi-parameter *families* of crypto algorithms to ensure enough genetic diversity of implementations to force each break to be ad hoc/non-generalizable.  The next generation of hashes/crypto needs to force not just CPU cycles & memory accesses, but *human brain operations*.  Such systems will penalize NSA wannabes who attempt to replace quality of analysts with quantity of analysts.
A lot of water has passed under various (Euler?) bridges since the current protocols were set in silicon.  Some new protocols need to be developed that stop carrying *legacy vulnerabilities* around with them.  Just like "buffer overflows" aren't funny anymore, neither are "protocol downgrades".  Go secure or go home.
Parallelism is in decent supply these days.  How come we can't have "parametric protocols" that combine two different crypto schemes -- e.g., a prime-number-based scheme and an elliptic-curve-based-scheme -- and run them both in parallel to achieve the security of the stronger scheme (which one we don't know a priori), instead of the insecurity of the worst scheme ?  Any attacker would then have to break both schemes, or at least the harder scheme, in order to break the overall "parametric protocol".  After all, our automobiles have both hydraulic brakes and a cable-based handbrake for stopping; an attacker would have to drain the hydraulic fluid *and* cut the brake cable to keep the car from stopping.

@_date: 2015-10-22 09:19:52
@_author: Henry Baker 
@_subject: [Cryptography] Other obvious issues being ignored? 
I have a 1992 "Linear Lisp" that does precisely what you want:
complete programmer control of data *copies*.
The "linear" here means all reference counts are exactly *one*, so
when an object is deleted, it can (and *will*) be immediately
(Note that a "linear" implementation should most likely run with
*interrupts mostly disabled*, because the implementation would
like to carefully control the conditions under which someone else
(e.g., an interrupt routine) can examine its memory.  Those who
have programmed *microcode* will recognize this style of machine
language programming in which interrupts are allowed only at
certain pre-determined instruction boundaries.)
Duplicating an object (DUP) in a "linear" language means *deep
copying* the object, so that it remains unshared.
While a completely "linear" programming language would appear to
be very inefficient -- e.g., a Lisp interpreter using only "linear"
objects would have to deep-copy the interpreted Lisp source code
for each iteration/recursion -- it can be implemented much more
efficiently using *reference counts* "behind-the-scenes".
Basically, all CONSing is done using *hash cons* (which is O(1)). If the object already exists in the hash cons table, the reference
count is incremented and the existing object is returned.  DUP
simply increments the reference count instead of deep copying.
The key idea is that any modifications to the list structure
unshares (decrementing the reference count in the process)
prior to performing the operation.
So long as the "behind-the-scenes" implementation fastidiously
recycles list structure whose reference counts reach zero ("deep"
recycle), then there will be no dead data lying around to leak. In particular, a "linear" Lisp interpreter would DUP (++refcnt)
the interpreted code prior to each iteration and "recycle"
(refcnt--) the code being interpreted.  The refcnt DUP ensures
that the interpreter can run fast; the refcnt manipulations
are all O(1), and can be substantially optimized -- e.g., by
utilizing *swaps*, *rotates*, etc., which preserve reference
counts and thereby avoid these additional memory references.
(We note that swaps/exchanges in some architectures -- e.g.,
x86 -- might be *slow* precisely because they are fastidious
wrt not leaving copies around.  For certain calculations,
security is more important than speed, so this fastidiousness
may be acceptable.)
In my spare time, I've been working on a compiler from Linear
Lisp direct to assembly/machine language.  I hope to be able
to publish it at some point.
Here's the "Lively Linear Lisp" paper:
Here's a paper talking about "linear" (unshared) types:
Here's my paper repository; note any papers with "linear" in
their title:

@_date: 2015-10-25 15:08:06
@_author: Henry Baker 
@_subject: [Cryptography] How programming language design can help us 
John Launchbury (currently at DARPA) has already developed
a safer language & compiler for crypto code called "Cryptol".
It is more bit-twiddling than C; in fact it can compile into
FPGA's in addition to compiling into assembly language.
I haven't used it myself, but it's open source so you can
try it out:

@_date: 2015-10-26 08:05:31
@_author: Henry Baker 
@_subject: [Cryptography] "Digital" Love Locks? 
FYI -- Can't we come up with a digital version of "Love Lock"
to avoid all the damage that physical love locks do?
Perhaps a Love Lock embedded in the Bitcoin blockchain?
Shakespeare's "let me count the ways" should be 2^128, minimum;
2^64 if you both have the same birthday.  ;-)
Love Locks Prevail in Cities Other than Paris

@_date: 2015-10-27 07:30:47
@_author: Henry Baker 
@_subject: [Cryptography] WhatApp metadata broken; on deck: voice encryption 
FYI -- The authors seem very optimistic about capturing the voice encryption session keys soon.
WhatsApp network forensics: Decrypting and understanding the WhatsApp call signaling messages
we were able to acquire the following artifacts from the network traffic:
* WhatsApp phone numbers.
* WhatsApp phone call establishment metadata and datetime stamps.
* WhatsApp phone call termination metadata and datetime stamps.
* WhatsApp phone call duration metadata and datetime stamps.
* WhatsApp's phone call voice codec (Opus).
* WhatsApp's relay server IP addresses used during the calls.

@_date: 2015-10-27 13:49:55
@_author: Henry Baker 
@_subject: [Cryptography] Collisions w/SHA-1 ~$100,000 TODAY 
FYI -- Oh, SHA-1t !!  Cyber Perl Harbor, here we come!
U.S. military cyber security fails to make the grade
The United States Department of Defense is still issuing SHA-1 signed certificates for use by military agencies, despite this practice being banned by NIST for security reasons nearly two years ago.  These certificates are used to protect sensitive communication across the public internet, keeping the transmitted information secret from eavesdroppers and impersonators.  The security level provided by these DoD certificates is now below the standard Google considers acceptable for consumer use on the web.
The Missile Defense Agency, the eventual successor to the "Star Wars" programme, uses one of these SHA-1 certificates on a Juniper Networks remote access device.  The SHA-1 certificate was issued by the Department of Defense in February 2015, long after NIST declared this practice to be unacceptable.
The majority of SHA-1 signed SSL certificates issued for use on publicly-accessible websites within the past few months, and that are valid beyond the start of 2017, were issued to hostnames under the .mil sponsored top-level domain.  This sTLD is used by agencies, services and divisions of the United States Department of Defense.
Many other SHA-1 certificates used by .mil websites are valid beyond the start of 2017, which means that Google Chrome already regards them as affirmatively insecure, crossing out the padlock icon.
DoD PKI infrastructure
The Department of Defence PKI infrastructure relies on two root certificate authorities (DoD Root CA 2 and DoD Root CA 3), but ***these are not included in all browsers by default.***
Although the DoD PKI infrastructure is not trusted by all browsers, it is nonetheless surprising to see it flouting some of the well-founded rules and recommendations that apply to publicly trusted certificates as well as recommendations made by NIST.  Many of these guidelines are backed by valid security concerns  in particular, using SHA-1 for signature generation is now considered ill-advised, as any well-funded attacker can plausibly compromise the affected certificates.
The risk to the Department of Defense is further heightened by enemy goverments being the most likely sources of attack.  The projected cost of attacking SHA-1 is unlikely to be prohibitive, and some governments may already be in a position to find a hash collision faster than the most organised criminals.

@_date: 2015-10-28 07:23:03
@_author: Henry Baker 
@_subject: [Cryptography] Oracle archeologists discover memory tagging 
Apparently, Oracle has been doing archeology research on old Burroughs (and MIT Lisp Machine) garbage dumps:
Silicon Secured Memory  For the first time,* Silicon Secured Memory adds real-time checking of access to data in memory to help protect against malicious intrusion and flawed program code in production for greater security and reliability.
* The first time since Larry's current engineers were born.

@_date: 2015-10-29 07:07:14
@_author: Henry Baker 
@_subject: [Cryptography] Criptyque touts all-in-one secure comms app 
FYI -- (This company's encryption is trivially broken; hint: consider exchanging 'y' with 'i'.  E.g., Dyffye-Hellman -> Diffie-Hellman, etc.)
"Keys are never known, even to Pryvate.  Once a key is created it expires and a new key is used for every subsequent interaction"
"Pryvate makes use of 4096-bit encryption, with AES 256-bit key management and Diffie-Hellman key exchange"
Channel Islands firm touts all-in-one secure comms app
Nothing can pry into Pryvate, claim developers
29 Oct 2015 at 12:58, John Leyden
A British start-up has launched a fully encrypted communications platform for mobile devices that aims to challenge established apps such as FaceTime and Skype, and even heavily-touted privacy-engineered devices like the BlackPhone.
Pryvate from Criptyque offers encrypted email, voice and video calls as well as secure instant messaging.
Initially available on Apple and Google Play stores, the service provides security by generating unique encryption keys on the devices of both users who communicate via the application.
Once a key is used, a new key is created for every subsequent interaction and renewed for every call, IM, message or other communications session.
Keys are never known, even to Pryvate.  Once a key is created it expires and a new key is used for every subsequent interaction, according to Criptyque.  Pryvate only establishes the communication signalling and authorises the connections (user verification/authentication); then Pryvates servers step out.  These keys are generated and destroyed within the app, which is fully sandboxed away from users' device operating systems.
Criptyque execs told El Reg that the firm has no access to encryption keys, which are held on users devices.  The firm reckons its Jersey, Channel Islands base offers a more privacy-friendly regime than if it operated on the UK mainland.  There, providers of end-to-end encryption have chosen countries with privacy-friendly regulations such as Iceland and Switzerland as a bulwark against government surveillance requests, as Criptyque explains.
    Cryptique is incorporated in Jersey in the Channel Islands because Jersey has its own independent government and legislature placing it outside the jurisdiction of the United Kingdom.  This eradicates any possible request to have a backdoor built into the application and therefore providing our users with the utmost confidence in our independence from any government interference.
The engine underpinning Pryvate makes use of 4096-bit encryption, with AES 256-bit key management and Diffie-Hellman key exchange.  Criptyques blurb refers to this as military grade and government grade encryption, as if either term inspires confidence in the post-Snowden era.
But we digress.
Criptyques technology also bundles compression to aid lower latency and sandboxing, as a defence against the possibility that mobile malware somehow introduced to a device might make it possible to steal encryption keys.
Jan Vekemans, technical director at Criptyque, told El Reg that physical threats rather than malware were the main limitations to the privacy offered by its technology.
The limitations are not with the app but, as always with security, it is with human error, Vekemans explained.  What Pryvate secures is users communications in transit rather than the phone itself.  For instance, Pryvate cant stop your phone being stolen or someone putting a bug on your person to listen into your calls.
These responsibilities need to be taken on board by the individual as no technology can stop user errors of this nature.  What Pryvate does is make security simple/efficient and shield users from the element of security.  This means there is less reluctance to use it and there is less danger employees will find an alternative (non-safe) way of doing things.  It also allows Pryvate to proactively update obsolete algorithms or counter threats safely, without any user intervention, should any unforeseen event occur, he added.
Other players in the secure communications space, such as Silent Circle, openly state that mobile security is compromised in cases where a device is contaminated with malware, so El Regs security desk is not altogether convinced on this point.  Sandboxing is a worthwhile security approach but its not always bulletproof, as evidenced by recent problems with Adobes sandboxing tech.
Criptyques service has been certified by application security firm Zion Security, which is in the process of achieving industry accreditation for the app.  All core components are also open source and open to public scrutiny, were told.
The Pryvate suite consists of three subscription products: Pryvate, a mobile app that offers secure communications, Pryvate Premium, which also includes added storage and account management controls, and Pryvate Enterprise, which also adds desktop functionality and products.  All three products default to the free-to-use Pryvate Lite, which offers users secure free phone calls of up to one minute.
Available for a free 30 day trial, Pryvate Consumer costs 4.49 / $5.99 per month or 44.99 / $54.99 a year, Pryvate Premium costs 5.99 / $7.99 per month, and Pryvate Enterprise for 9.99 / $13.99 per month.
Pryvate Enterprise offers a secure desktop IP video phone, a separate hardware-based device.  Individual users can plug in the preconfigured phone which offers the advantage of protection against eavesdropping on communications and other forms of snooping.

@_date: 2015-10-29 11:56:46
@_author: Henry Baker 
@_subject: [Cryptography] Oracle archeologists discover memory tagging 
The reason I mentioned the MIT Lisp Machine is that Lisp implementations have exhaustively explored essentially every method of memory tagging, including the use of caches.
For example, MIT's Maclisp segregated objects of the same type onto the same "pages"; a table lookup of the top address bits would tell you the type of the object.  This scheme is still used by GCL (nee KCL), I believe.
Additional tagging schemes were explored by the various Xerox Lisp machines, including various kinds of hash tables & caches.
And then there was the Intel iAPX_432, Justin Rattner's attempt at the implementation in real-time of every academic architectural wet dream fad, including object orientation.
IBM's 360/370 systems also offered various kinds of "protection" schemes, including additional bits for each 2k (?) byte block in memory; I believe that these IBM protection schemes were also respected by the I/O controllers -- perhaps the first time that asynchronous & independent I/O devices could be locked out of protected main memory.
Accessing Lisp Machine vectors from *outside* the vector was not only permitted; it was a *feature*.  By construction, a Lisp Machine vector was *simultaneously* a sequentially-allocated vector and a "linked list".  Therefore, the "tail" of such a vector could be accessed and passed as a vector-cum-linked-list.  The garbage collector noticed when the "head" of such a vector was no longer referenced, and shortened the vector during GC operation.
Thus, the Lisp Machine operated in a completely type-safe & memory-safe manner -- something that the Oracle technology still can't achieve.

@_date: 2015-10-29 14:39:32
@_author: Henry Baker 
@_subject: [Cryptography] New email feature: NSA speedbumps 
Keep Bluffdale warm this winter!
NOBUS would bother trying to decode these postscripts.
They might give away the state of your random number generator.
Or they might encode a secret message.
Let NSA decide.
-----BEGIN PGP ARMORED FILE-----
Version: GnuPG v1.4.9 (Cygwin)
Comment: NSA speed bump|BBC broadcast: indistinguishable from \
head -c526 /dev/random|gpg --enarmor
-----END PGP ARMORED FILE-----

@_date: 2015-09-03 07:20:13
@_author: Henry Baker 
@_subject: [Cryptography] Vulnerability of RSA vs. DLP to single-bit faults 
FYI -- HW attack + GCD kills RSA:
Hardware attacks: hacking chips on the (very) cheap How to retrieve secret keys without going bankrupt Ramiro Pareja & Rafa Boix

@_date: 2015-09-09 11:07:54
@_author: Henry Baker 
@_subject: Apples iMessage Defense Against Spying Has One Flaw 
FYI -- Of course the same flaw can be used by non-U.S. govts.
Apples iMessage Defense Against Spying Has One Flaw
Joseph Cox Security  09.08.15  1:10 pm.
Yesterday, the New York Times mentioned a trend thats becoming more common: tech companies fighting back against government requests for user data, among them Microsoft and Apple.  According to the report, the Justice Department obtained a court order demanding that Apple provides the iMessages sent between crime suspects, in real time.
Apple said that wasnt possible, because its iMessage service was encrypted.
But, the thing is, there is actually a very high likelihood that, technologically, iMessage could be wiretapped, because it does not allow users to verify encryption keys when writing or receiving messages.
How iMessage Works
When someone-lets call her Alice-sends a text over iMessage, the content doesnt simply travel from Alices Apple device to another.  First, Alices device contacts one of Apples servers.  Called ESS, this server stores all of the public encryption keys for iMessage users.
 From here, the Apple server provides Alice with, say, Bobs encryption keys.  Then armed with this information, Alices iPhone encrypts the message, sends the garbled text to Apple, which then forwards it over to Bob, who can decrypt it.
At no point in this process does Apple see the actual content of the message, because it is encrypted before it leaves Alices device, aka end-point.  Hence, the label end-to-end encryption.
This centralized approach to key management isnt necessarily a problem, and is the same process that other encrypted messaging services use.  Signal, developed by Open Whisper Systems, also makes a users device connect to a central server of keys, Nicholas Weaver a senior researcher from the International Computer Science Institute, told WIRED in an email.
However, as pointed out by Weaver in a recent post on the Lawfare Blog, it is impossible for an iMessage user to make sure that the Apple server has provided them with the right set of encryption keys.
Without such an interface, iMessage is backdoor enabled by design: the keyserver itself provides the backdoor, Weaver writes.
Weaver says that, if configured to do so, the Apple server could, instead of providing Alice with Bobs correct keys, send an additional one that the FBI had access to.  Indeed, this was highlighted by researchers as far back as 2013, and Matthew Green, assistant professor at Johns Hopkins University also previously laid out a similar case.
[In that case] the FBI (but not Apple) can decrypt all iMessages sent to Alice in the future, Weaver continues.  Likewise, by adding another FBI key to all messages that Alice sends herself, it would be possible for the agency to snoop all of her outgoing texts too.
The Solution?  Let Us Verify Our Keys
So, the only way around this potential backdoor is in allowing users to verify what keys they have received.  With Signal, users can hit a Verify identity button, and the app will display their key fingerprint, as well as that of the person theyre communicating with.  To make sure that theyve been issued the genuine keys, the pair can then send this code over another means of contact, or just show it to each other in person.
Hardly anybody actually does verify keys offline, but the capability of doing so is what forces the keyserver to be honest, Weaver continued.  Its worth pointing out that Open Whisper Systems partnered with WhatsApp to deliver end-to-end encryption, but that service, like iMessage, does not have a feature to verify users fingerprints.
Its unclear why Apple has not implemented some sort of manual verification method.  The company did not respond to a request for comment.
Regardless, it would likely be a pretty easy addition to make to iMessage.  A long press of view keys would be sufficient, Weaver said, although he anticipated that Apple could probably come up with some other, even easier-to-use method.
This is all assuming that the FBI, or other agency, could find the legal standing to compel Apple to send bogus encryption keys to a target.  As the New York Times piece pointed out, a court order was obtained to demand Apple deliver unencrypted messages.  Although that request was apparently unsuccessful, the technological groundwork for wiretapping iMessage is there, at least for the time being.

@_date: 2015-09-10 21:04:21
@_author: Henry Baker 
@_subject: [Cryptography] millions of Ashley Madison bcrypt hashes cracked 
FYI --
"we were able to gain enormous speed boosts in cracking the bcrypt hashed passwords"
"This allowed us to find more than 2.6 million passwords in just a few hours, using just *one* CPU box only."
"we had in fact solved millions of bcrypt hashes...in days, not years.  As of posting our team has successfully cracked over 11.2 million of the bcrypt hashes."
How we cracked millions of Ashley Madison bcrypt hashes efficiently
Thursday, September 10, 2015
Not long after the release of the Ashley Madison leaks, many groups and individuals attempted to crack the bcrypt hashes.  Since the developers used a cost factor of 12 for the bcrypt hash, this made the process an extremely compute intensive task.  We decided to take a different approach and made some rather interesting discoveries.
Without much information about the $loginkey variable and how it was generated, we decided to dive into the second leak of git dumps.  We identified two functions of interest and upon closer inspection, discovered that we could exploit these functions as helpers in accelerating the cracking of the bcrypt hashes.
Through the two insecure methods of $logkinkey generation observed in two different functions, we were able to gain enormous speed boosts in cracking the bcrypt hashed passwords.  Instead of cracking the slow bcrypt hashes directly, which is the hot topic at the moment, we took a more efficient approach and simply attacked the md5(lc($username).::.lc($pass)) and md5(lc($username).::.lc($pass).:.lc($email).:73 tokens instead.  Having cracked the token, we simply then had to case correct it against its bcrypt counterpart.
The $loginkey variable seemed to be used for automatic login, but we didnt spend much time investigating further.  It was generated upon user account creation and was re-generated when the user modified their account details including username, password and email address.
Discovery 1
Filename: amlib_member_create.function.php
Function: amlib_member_create()
Lines of interest: 69, 70
Algorithm: md5(lc($username).::.lc($pass))  According to line 70 of the code, the $loginkey variable was generated by hashing the lowercased username and password with MD5.  Great, did this mean that we could crack the password by attacking the loginkey with md5($salt.$pass)?  Line 69 would suggest otherwise, since $password was set to the bcrypt hash by the encryptPassword function.  We wondered if it had always been this way, and a quick git blame revealed that this line was changed on 2012-06-14 with commit 1c833ec7.  Heres the difference:
       $username = !empty($Values['username_suggest']) ? $Values['username_suggest'] : $Values['username'];
-       $password = User::encryptPassword($Values['password']);
+       $password = $Values['password'];
       $loginkey = md5(strtolower($username).'::'.strtolower($password));
This meant that we could crack accounts created prior to this date with simple salted MD5.
Also, the possible charset was reduced by 26 due to the use of strtolower(). Discovery 2
Filename: AccountProvider.php
Function: generateLoginKey()
Lines of interest: 78, 79
Algorithm: md5(lc($username).::.lc($pass).:.lc($email).:73 This function used a slightly different routine to generate the $loginkey as it incorporated the use of $username, $password, $email variables along with a constant salt string called $hash; and together, these variables were hashed with the MD5 algorithm.
It appeared that generateLoginKey() was invoked when a user modified their account attributes (username, password and email) and as a result of this, a new loginkey was issued for that account.  From our understanding, it appeared that bcrypt was not always used to hash the password prior to it being fed to the generateLoginKey function.  This meant that this method could be used to recover passwords of accounts which had been modified prior to this code change.
Exploiting the discoveries
Two different algorithms were added to MDXfind to support these discoveries.  The simple version, MD5AM, implements the earlier code of md5(lc($username).::.lc($pass)); while MD5AM2 implements the more complex version, but pre-bcrypt.  MD5AM2 uses both the username and the email address, as well as a fixed salt, in the form of md5(lc($username).::.lc($pass).:.lc($email).:73
Both required this information to be extracted from separate SQL database entries, but were combined for ease of parsing into one string.  The username/email combination was supplied to MDXfind with the -u switch as a separate file.  A third optimization was performed to identify and exclude MD5 hashes that could not be cracked using our discovered methods.  These were $loginkeys created using the secure methods of md5(lc($usename).::.lc($bcrypt-string)).  Since we had the username, and the bcrypt hash, we were able to isolate these hashes quickly.
Regardless, MDXfind was able to load all of the hashes, and because of the manner in which it stores and searches the hashes, we incurred negligible penalty from the search overhead of the unsolvable hashes.  This allowed us to find more than 2.6 million passwords in just a few hours, using just *one* CPU box only.
The hashes from the the dump were also converted into an appropriate format suitable for loading as md5($salt.$pass) into any existing CPU/GPU crackers (only for Discovery 1).
Case Correction
Having the solved md5 tokens however, did not mean that we knew the original password.  The token used only the lowercase value of the password and thus a secondary step to toggle the case of each character generating each variant was necessary, in order to properly crack the bcrypt hashes.  Fortunately, this was a fixed-set problem with each bcrypt hash, thus only one salt needed to be checked for each bcrypt against the case variants.
A separate run correcting our cracked tokens against the bcrypt counterpart validated that we had in fact solved millions of bcrypt hashes...in days, not years.  As of posting our team has successfully cracked over 11.2 million of the bcrypt hashes. Dan Goodin from Ars Technica has also written an article which gives a thorough explanation of the process.
     Twitter:  Blog: cynosureprime.blogspot.com
Email: cynosureprime at gmail.com

@_date: 2015-09-13 07:58:32
@_author: Henry Baker 
@_subject: [Cryptography] "Ulysses pacts": better than "warrant canaries" ? 
FYI --
"But technology gives us a new, stronger kind of Ulysses pact, one that takes the choice out of managements hands  a self-enforcing self-destruct button, which has the potential to make some secret warrants totally useless: binary transparency."
"If a spy agency knows that any attempt to implant malware on a users computer through a software update will both fail and raise an alarm, there is absolutely no reason even to try."
Guardian column: Ulysses pacts and spying hacks: warrant canaries and binary transparency
August 20, 2015 / Cory Doctorow / Articles, News
As the worlds governments exercise exciting new gag-order snooping warrants that companies can never, ever talk about, companies are trying out a variety of Ulysses pacts that automatically disclose secret spying orders, putting them out of business.
A Ulysses pact is a negotiating tactic in which one party voluntarily surrenders some freedom of action, named for the story of Ulysses ordering his men to tie him to the mast of his ship so that he couldnt jump into the sea when he heard the sirens song.  For example, a union leader heading into a negotiation might promise to resign rather than take a pay cut, making pay-cut demands useless (because if she acceded to such a demand, shed have to resign before she could formalize the agreement).
In the world of secret spying orders, companies use warrant canaries as a kind of dead mans switch: at regular intervals, they publish a transparency report with statistics for each kind of government request theyve received, including Secret spying orders: 0.  After receiving their first secret spying order, they stop publishing that line altogether.  If the company sells its service as privacy-oriented, this is, effectively, suicide: the services users quit using it, and the spies have nothing.
But its a weak kind of Ulysses pact, because a CEO contemplating suicide-by-canary might just decide that one teensy lie isnt such a big deal after all  and if spy agencies believe that this is the case, theyll have every reason to use secret warrants, forcing the issue.
But technology gives us a new, stronger kind of Ulysses pact, one that takes the choice out of managements hands  a self-enforcing self-destruct button, which has the potential to make some secret warrants totally useless: binary transparency.
    Theres another kind of secret spying: malware implantation.  This is when a government body orders a company to send some of its customers a software update that includes a backdoor.  For example, the Saudi government once convinced Research in Motion to backdoor Blackberry devices within its borders.  In May, 2014, the anonymously maintained Truecrypt project mysteriously shut down, leaving behind a cryptic note (possibly with a Dan-Brown-esque secret message in it).  Many believe that they shut down in response to a government demand to weaken some or all of the Truecrypt programs in the wild.
    In the case of programs that run on users computers theres binary transparency.  When a program with binary transparency receives an update, it computes that updates hash (a mathematical fingerprint) and sends it to a server maintained by a disinterested third party.  It also checks the hashes of all the other updates that have been received by all the other versions of the program that have checked in.  If it sees that it has got a special update, it refuses to install it and alerts the user.
    This is much stronger, more effective Ulysses pact.  If a spy agency knows that any attempt to implant malware on a users computer through a software update will both fail and raise an alarm, there is absolutely no reason even to try.

@_date: 2015-09-13 13:42:57
@_author: Henry Baker 
@_subject: [Cryptography] Comey: targeted ads => plaintext access 
FYI -- Leaving aside Constitutional & political considerations, & focusing purely on technical issues, doesn't the FBI's Comey have a point?  If an email provider can target ads based upon keywords in the plaintext of your emails, why can't the FBI have access to the same plaintext?
Obviously, any scheme that targets ads based upon the *unencrypted content* of an email must *leak a certain amount of information from that content* -- at least to the ad broker.
Perhaps the information is only an alphabetically ordered *set* of keywords, but that is still more than zero.  (An obvious defense: all messages encoded entirely in "Basic English", and every message contains the entire 850-word vocabulary:  )
at 39:26  James Comey, FBI
First of all, I very much appreciate the feedback from the companies.
We've been trying to engage in dialog with companies because this is not a problem that's going to be solved by the government alone.
It's going to require industry, academia, associations of all kinds, and the government.
I hope we can start from a place we all agree there's a problem and that we share the same values around that problem.
When I hear people talk about the crypto wars, it throws me because wars are fought between people with different values I think we all share the same values here.
We all care about safety and security on the Internet, and I'm a big fan of strong encryption, we all care about public safety, and the problem we have here is those are in tension, and a whole lot of our work increasingly in counter-terrorism and criminal work and counter-intelligence work and given that we care about the same things, I hope we can all agree that we ought to come together to try and solve that problem.
I've heard from a lot of folks that it's too hard, and my reaction to that is really?
Have we really tried?
Have we really tried?
When I look at industry today, I see companies I'm not going to name them here, but major internet service providers, who are able to comply with court orders.
Because they strongly encrypt in transit, and they decrypt when it crosses their networks, so they can read our emails so they can send us ads.
I've never heard anybody say those companies are fundamentally insecure and fatally flawed from a security perspective.
So, I don't think we really tried and also don't think there's an "it" to the solution.
I would imagine there might be many, many solutions, depending upon whether you're an enormous company that's in this business, or a tiny company in that business, I just think we haven't given it the shot that it deserves.
Which is why I welcome the dialog.
And we're having some very healthy discussions.

@_date: 2015-09-15 07:17:40
@_author: Henry Baker 
@_subject: [Cryptography] Microsoft's new, free, crypto library dubbed FourQ 
FYI --
Microsoft throws crypto foes an untouchable elliptic curveball
Redmond's new, free, crypto library dubbed FourQ leaves P-256 swinging and missing
15 Sep 2015 at 03:58, Richard Chirgwin
While Washington mulls ways to make crypto less effective, the industry, thank heavens, continues to push in the other direction.  Microsoft Research has just published an elliptic curve library it reckons is considerably faster than what's currently available.
Outlined in this International Association for Cryptologic Research (IACR) paper, the implementation, the FourQLib, comes from noted Redmondian researchers Craig Costello and Patrick Longa.
The aim with FourQ sis to update today's elliptic curve cryptography (ECC)  implementations like the National Institute of Science and Technology's (NIST's) P-256 and the non-NIST-influenced Curve25519  since one inevitability of crypto tech is that it will become obsolete.
That be-prepared approach also means a new ECC library needs to be fast, so that crypto doesn't become too great a burden on the processors handling it.  Here's what the authors say about FourQ's performance:
    On Intels Haswell, Ivy Bridge and Sandy Bridge architectures, our software computes a variable-base scalar multiplication in 59,000, 71,000 cycles and 74,000 cycles, respectively; and, on the same platforms, our software computes a Diffie-Hellman shared secret in 92,000, 110,000 cycles and 116,000 cycles, respectively.
    "These results show that, in practice, FourQ is around four to five times faster than the original NIST P-256 curve and between two and three times faster than curves that are currently under consideration as NIST alternatives, such as Curve25519.
In addition, FourQ is designed to be simpler, which also makes it easier to demonstrate concrete correctness for a four-dimensional decomposition.
It's also simple for developers, they write: FourQ is intended to be used in the same way, i.e., using the same model, same coordinates and same explicit formulas, irrespective of the cryptographic protocol or nature of the intended scalar multiplication.
The presence of a single, complete addition law gives implementers the ability to easily wrap higher-level software and protocols around the FourQs library exactly as is, they continue.
And importantly, the code has been made public  it's available for download here  for others to audit.

@_date: 2015-09-16 07:13:23
@_author: Henry Baker 
@_subject: [Cryptography] Comey: targeted ads => plaintext access 
Hmmm...  I'm interested in learning more about how this ad scheme
might work.
Nevertheless, if some questionable people were talking about fertilizers
in their emails, and they started getting ads from fertilizer companies,
it might not matter very much if anything else from the emails was
I worry enough when the TV shows I happen to like advertise
constipation drugs!

@_date: 2015-09-16 17:38:24
@_author: Henry Baker 
@_subject: [Cryptography] WashPo: Leaked NSC Memo on Encryption 
FYI --
This is my OCR'd version of the National Security Council memo leaked to the Washington Post and available at the link below.  The pdf of the original looks like it was typed on a *manual* typewriter -- the NSC clearly following the lead of Russia to avoid being intercepted electronically!  [The irony of the NSC using a manual typewriter for a memo on encryption is truly delicious!]
The most distressing part of this memo is its obscene disregard for the Constitution.  The only "stakeholders" -- according to this NSC memo -- in favor of "civil liberties" and "human rights" seem to be organizations -- e.g., the EFF and the ACLU; ordinary citizens are apparently not "stakeholders", and have no "stake" in this discussion.
Of course, every time someone uses the term "stakeholder", the only images that come to mind are those scenes from black-and-white horror movies in which the townspeople are chasing a vampire with wooden stakes that they intend to drive through his heart!
REVIEW OF STRATEGIC APPROACHES
Option 1: Disavow Legislation and Other Compulsory Actions
Engagement Strategy and timeline
Z September: Outreach to foreign allies to signal our strong resistance to efforts to compel access; outreach to U.S. industry, the technology community, and civil society to coordinate messaging; attempt to convince other allies to come out with a similar statement at the same time.
Z October: The President issues a statement strongly disavowing legislation or other efforts to compel access and calling on U.S. industry to resist efforts by other nations to compel access; coordinated industry and civil society statements of support; coordinated foreign partner statements of agreement.
Z November: Outreach to other governments to bring more allies in alignment with our position; outreach to U.S. industry to build voluntary cooperation in the absence of compulsion; host public discussions and debates on encryption policy with U.S. industry and foreign allies.
Top Line Message
Z The problem of criminals using strong encryption to frustrate law enforcement's information gathering is a real and growing problem but we have not found a secure, practical solution.
Z People around the world rely on the security of U.S. products and services in their daily lives.  Mandating the design of those systems to include known vulnerabilities makes all of us less safe and undermines trust in these digital services.
Z It is critical that law enforcement be able to access the information that it needs to protect public safety and national security.  We will continue to use all of the tools available to us lawfully to keep American citizens safe.
Z Overall, the benefits to privacy, civil libertine, and cybersecurity gained from encryption outweigh the broader risks that would have been created by weakening encryption.
Z Accordingly, the Administration will not seek legislation that compels providers to design their products to enable government access to encrypted information, even pursuant to lawful process.
Z We expect that foreign governments will also take a hard look at this difficult issue, and hope that they will come to the same conclusion.  We call on U.S. industry to resist efforts by other governments to mandate such access.
Impact on Policy Equities
Public Safety and National Security.  In the near term, this approach would not provide any relief to law enforcement efforts to counter the increasing use of encryption by criminals, including terrorists.  As a result, the public safety drawbacks would be significant, though the precise extent of the drawback versus other proposals is unclear because bad actors will increasingly be able to frustrate law enforcement efforts to access their communications through lawful process.  This approach would remove technology companies' most consistent grievance with the Administration, which could improve cooperation across a range of important priorities on technology issues including, but not limited to, encryption.  It may also foster better cooperation on information that is not encrypted and will not fracture the Internet products and services market which may also preserve better access to unencrypted information, thus aiding public safety/national security.
Cybersecurity.  Pro-encryption statements from the government could also encourage broader use of encryption, which would also benefit global cybersecurity.  Further, because any new access point to encrypted data increases risk, eschewing mandated technical changes ensures the greatest technical security.  At the same time, the increased use of encryption could stymie law enforcement's ability to investigate and prosecute cybercriminals, though the extent of this threat over any other option is unclear as sophisticated criminals will use inaccessible encryption.
Economic Competitiveness.  This approach could help undercut foreign competitors' criticisms that U.S. companies' products are instruments of U.S. mass surveillance, and would clearly differentiate U.S. policy from moves by China and others to mandate decryption.  However, if other markets do not follow our lead, and instead demand access, it is more difficult to assess the impact of this approach.  On the one hand, U.S. companies could be forced to avoid those markets or develop access solutions.  On the other, the failure of some nations to follow the U.S. lead could bolster the reputation of the United States as a leading source of technically secure products and.  services.
Civil Liberties and Human Rights.  Domestically, many privacy and civil liberties advocates would regard this approach as a significant step in defense of privacy and free expression around the world.  If other nations follow our lead or companies successfully resist country demands, this approach could limit repressive regimes' willingness to demand access to encrypted information, which likely would help protect dissidents and other communities in danger of human rights violations.
Likely Reaction of Key Stakeholders
Industry and Civil Society.  This sector would strongly support this approach.
Other Governments.  Likely to be divided.  This position would contradict the stated policy of some allies (e.g., the United Kingdom, France, and the Netherlands) who argue that governments should not allow safe spaces for extremists.  As a result, those allies could criticize the U.S. position as endangering the safety of their citizens.  Other foreign partners that are strong advocates for free expression online and have not argued for government access to encrypted information (e.g., Germany and Estonia) are more likely to support this approach.
Z Some in industry have indicated that a strong statement disavowing legislation is a precondition to voluntary cooperation with the United States Government.  Since the prospects of legislation are dim, this approach could help build cooperation without limiting broader policy options.
Z Counters the narrative that the United States is seeking to expand its surveillance capability at the expense of cybersecurity, and could help repair trust in the United States Government and U.S. companies overseas.
Z A strong statement from the United States could make it more difficult for authoritarian regimes to seek compulsory legislation, although working group participants are divided on whether adopting this approach would actually stop such calls.
Z May weaken future calls for data localization since it will be harder for other countries to claim they are protecting their citizens' data from the United States.
Z Could provide some positive benefit for U.S. negotiations on the U.S.-EU Data Protection and Privacy Agreement, Safe Harbor, and Transatlantic Trade and Investment Partnership.
Z Is the strongest option for cybersecurity, economic competitiveness and civil liberties and human rights.
Z This approach provides no immediate solution to the challenges that the expanding use of encryption poses to law enforcement and national security today and is the weakest option from that perspective.
Z Some working group participants argue this approach would remove a key point of leverage -- the threat of legislation in our negotiations with industry (although few, if any, in industry likely find this threat to be credible).
Z U.S. providers have not indicated they would be willing to voluntarily modify their systems to enable law enforcement access to encrypted information, even if the government were to eschew legislation, and could result in the United States being isolated in its position.
Option 2: Defer on Legislation and Other Compulsory Actions
This option could be pursued with two distinct goals in mind.  Under option 2(a), the Administration would seek industry's voluntary assistance to modify their technology to address law enforcement's concerns.  Under option 2(b), the Administration would accept the current status quo and not seek technical modifications, but would still ask providers to assist law enforcement in any way that they can within their current technological framework.  In either case, these calls for assistance could be done publicly or privately, depending on the preferred engagement framework.
Engagement Strategy and Timeline
Z September: Outreach to foreign allies to assess their positions; signal to allies that the United States does not think legislation is the right way forward at this time; work with other governments to identify voluntary action by industry that would help to mitigate their concerns; outreach to U.S. industry to coordinate messaging.
Z October: The President issues a statement disavowing legislation, but acknowledges the serious challenges posed by encryption for public safety and national security; secure coordinated statements of support or agreement from industry, civil society, and partner nations.
Z October-November: Outreach to foreign allies in the wake of the statement to bring more allies in alignment with our position; outreach to U.S. industry to build voluntary cooperation in the absence of compulsion; if some allies persist in demanding access, consider whether the United States Government should highlight the difference in positions and the U.S. emphasis on privacy-protections.
Z Post-November: Host public discussions on encryption policy with U.S. industry and foreign allies; should foreign allies demand and secure access, consider whether to call upon U.S. industry to provide the same access to the United States Government.
Top Line Message
Z The United States is not seeking legislation at this time to compel providers to change their products to enable government access to encrypted information pursuant to lawful process.
Z At this point, legislation appears neither feasible or easily draftable.  We need considerable public discussion before we would be in position to contemplate a legislative solution.
Z However, we also cannot ignore the barriers that inaccessible encryption can create to law enforcement's critical need to investigate and prosecute criminals, including terrorists -- and the threat these barriers create for public safety.
Impact on Policy Equities
Public Safety and National Security.  Does not reverse the long- term trend of increasing use of encrypted technologies by criminals, but could open potential avenues for cooperation with industry, without removing all law enforcement leverage (although working group participants disagree on whether calling for legislation will provide meaningful leverage).  Some working group participants, however, have indicated they think it unlikely that industry will be willing to voluntarily modify their technology -- even if the threat of legislation is removed.  This suggests that Option 2(a), in which the Administration would seek such technical modifications, is unlikely to succeed.  However, unlike option 1, it retains flexibility on the approach should the public safety picture deteriorate to overtake competing equities.  This approach would also make compromise with foreign governments not currently seeking legislation easier, but would still provide some help in resisting attempts by
 governments like China to use encryption policies to skew markets or oppress citizens by retaining strong public statements (e.g., will not seek legislation).
Cybersecurity.  Could encourage the use of more encryption, which would likely be good for cybersecurity.  If a statement under this approach is perceived as positive but not sufficiently strong, however, this could be less successful in forestalling other nations from pursuing encryption-weakening measures.  Also, because any access point to encrypted data increases risk, if government efforts to secure access are successful, this approach would reduce cybersecurity.  However, the degree of impact on cybersecurity would vary significantly, and could be great or small, depending on the specific policy and technical decisions.
Economic Competitiveness.  Could have a positive, though incomplete, effect in removing barriers to Administration engagement with the tech sector on this issue.  Removing the prospect of United States Government calls for legislation would likely have positive effects on international competitiveness.  If long-term successful in gaining government access, this option would significantly harm economic competitiveness though the harm might be somewhat mitigated if there was broad international success in getting government access.
Civil Liberties and Human Rights.  Some will be dissatisfied with lack of outright disavowal, but may appreciate the pragmatic recognition of the practical limitations of a mandated approach.  However, others almost certainly will continue to have concerns about government access to encrypted information being used to suppress dissident populations.  Should some companies cooperate voluntarily and enable government access, the United States Government will need to accept that other nations -- including some repressive ones -- will use this access as well.
Likely Reaction of Key Stakeholders
Industry and Civil Society.  Although industry and civil society may be less positive to this approach than a hardline disavowal, those communities would likely see this outcome as a solid win.  However, further government pressure on industry to build access into their products would likely generate negative reactions.  Therefore, it is likely that Industry and Civil Society would have a much better reaction to Option 2(b), which does not seek technical modifications, than to Option 2(a), which does.
Other Governments.  Allied governments that prefer an access regime may push back on the core U.S. message.  However, those governments likely would react more positively to this approach than a complete disavowal of government access to encrypted information.
Z Responds to a key ask from industry, although industry might prefer a stronger statement.  To the extent that industry is satisfied with the strength of the statement, this approach could help build cooperation without limiting broader policy options.
Z Could help counter the narrative that the United States is seeking to expand its surveillance capability, and help repair trust in the United States and U.S. companies overseas.
Z Could allow the United States to serve as a broker between pro-access allies (e.g., United Kingdom, France, and the Netherlands), and U.S. industry, which could mitigate some demands from foreign partners and ensure U.S. companies do not have to build multiple access regimes.
Z If long-term successful in gaining government access, this option would help public safety and national security.
Z Could lead to disparate approaches by governments to the encryption issue, leading to more or different compliance regimes that U.S. companies will need to comply with, which could have a negative effect on their economic competitiveness.
Z Does not provide an immediate solution to the challenges that the expanding use of encryption poses to law enforcement.  Without a disavowal of legislation, many U.S. technology companies in the long term likely will not pursue voluntary design changes in products and services to enable access for law enforcement.
Z If long-term successful in gaining government access, this option would harm cybersecurity, economic competitiveness and civil liberties and human rights.
Option 3: Remain Undecided on Legislation or Other Compulsory Actions
Engagement Strategy and Timeline
Z September: Outreach to foreign allies to assess their positions; Private outreach to key industry leaders to argue that we need a more fulsome policy discussion before we decide how to proceed.
Z October: Organize or participate in closed-door, small group discussions with U.S. industry to facilitate a more in-depth policy discussion.  At the same time, organize bilateral and multilateral conversations with foreign partners to discuss the challenges and how to proceed.
Z November: High-level Administration statement highlights initial discussions, outlines key challenges, distills a few key questions and principals, and announces a meeting or series of meetings (potentially both domestic and international) to discuss and debate these key questions.
Z December: After the discussions, reassess our position and determine whether to take a position on encryption legislation or to continue to call for discussion.
Top Line Message
Z The President has said that there is no situation in which you wouldn't want strong encryption.
Z At the same time, there are situations in which the government cannot obtain information related to a specific potential national security threat.  If there is not a way of accessing that information and protecting the American public, then the Administration believes need to have a public debate.
Z Having a broad discussion about this is essential -- over the next several months, [we or several entities] will host discussions on the challenges posed by encryption and how we can best address them.  I would urge everyone to participate.
Impact on Policy Equities
Public Safety and National Security.  This approach has, to date, failed to incentivize cooperation with law enforcement.  It could in the long-term sway public opinion to create greater responsiveness -- particularly while the government retains the leverage resulting from the threat of legislation.  On the other hand, silence on our part could encourage foreign governments to control the agenda.  They might pressure U.S. industry to provide lawful access, which, if successful, would make it easier for us to require similar accommodations.  This approach could also encourage companies to continue to aggressively pursue developing inaccessible encrypted services, and could make future cooperation significantly more challenging.  Therefore, it is hard to predict the impact that this approach would have on public safety.
Cybersecurity.  Although it would not actively conflict with our message on the importance of encryption to cybersecurity, the uncertainty of public perceptions about the government's position could perpetuate distrust in encryption technologies related to the United States Government, and could undermine the effectiveness of the National Institute of Standards and Technology and other entities at a time when our cybersecurity agenda is already at risk.  If long-term successful in gaining government access, this option would harm cybersecurity.  -
Economic Competitiveness.  This approach does little to counter current distrust of the government by industry or foreign competitors.  Further, by not taking a position on legislation in either direction, this approach does little to shape the reactions of other governments, increasing the risk that they will splinter into multiple camps, presenting U.S. industry with fractured markets.  Therefore, this approach is likely harmful for economic competitiveness.
Civil Liberties and Human Rights.  Because this approach would likely not stop -- and could encourage -- other nations from demanding access, it is likely harmful for the Administration's efforts on civil liberties.
Likely Reaction of Key Stakeholders
Industry/Civil Society.  Will likely continue to strongly object until the United States Government explicitly eschews compulsory legislation.  As time passes, if we continue to fail to take a position, industry and civil society positions will likely harden as people perceive our silence as an implicit endorsement of legislation.  As a result, the United States Government risks losing credibility if it fails to participate robustly in a public debate and with a unified voice.  There is also a risk that industry chooses not to participate in meetings on the subject and escalates lobbying and public relations efforts.
Other Governments.  Allied governments that seek access will prefer this approach to either of the approaches that come out against compulsory legislation, and will likely see this as an opportunity for them to press for legislation themselves.
Z Provides flexibility to course correct and negotiate with U.S. industry and our foreign allies.
Z Retains a key negotiating chip (the threat of legislation) in our engagement with industry (although few, if any, in industry find this threat credible).
Z If other governments call for legislation and/or compel companies to change their encryption solutions to enable better access in the meantime, this could provide us with cover to use that same access.
Z Delays establishing a coherent Administration position, which could result in: (1) the United States being portrayed as increasingly ineffective/unable to resolve this challenge; (2) disputes among departments and agencies bleeding out into public discussion; (3) U.S. industry continuing to have challenges operating overseas (although it is unclear that a pro-encryption statement would by itself address this challenge); and (4) public and foreign government positions may harden in the absence of an affirmative U.S. position, limiting our ability to influence the global debate.
Z Does not provide an immediate solution to the challenges that the expanding use of encryption poses to law enforcement.  Moreover, this approach does not resolve the current policy debate.  The United States Government likely will be faced with this same discussion again in several months' time.

@_date: 2015-09-17 07:57:03
@_author: Henry Baker 
@_subject: [Cryptography] sibyl attacks 
I love the term "sibyl attack":
The stock market has had a similar attack for many, many years: the (naked) "bear raid".
In a legitimate bear raid, a company's stock is sold short with *borrowed* stock.  Borrowing stock requires that the borrowee provide permission, and the borrowee is usually compensated with a small amount of interest.
However, the SEC has never really punished broker-dealers who ignore the *borrowed stock* requirement, so a broker-dealer can sell an almost unlimited amount of stock, and since the rules for quickly "settling" are also routinely ignored, such broker-dealer can remain truly "naked" for months or even years.
Small companies have complained bitterly for years about this abuse, but without any real progress.
NASDAQ claims to be implementing a block-chain system for keeping track of stock; one hopes that such a system will finally stop these illegal "bear raids".

@_date: 2015-09-17 09:44:30
@_author: Henry Baker 
@_subject: [Cryptography] WashPo: Leaked NSC Memo on Encryption 
This leaked memo is what is usually called in Washington a "trial balloon" -- basically a *troll* to see what various "[wooden] stake holders" will say.  I wouldn't call the caterers to celebrate just yet.
Litt seems almost as certain as Comey was re a possible July 4th attack (engineered, it turns out, by the FBI itself through its own informants).
['Law enforcement officials said [the father,] Capt. Ciccolo [,] alerted counter-terrorism authorities about a year ago'
'According to the FBI, the younger Ciccolo said he was inspired by the Marathon bombing and the use of pressure cooker bombs, and told the FBI undercover operative, Allahu Akbar!!! I got the pressure cooker today.'
[Congressional sentiment] could turn in the event of a terrorist attack or criminal event where strong encryption can be shown to have hindered law enforcement
Obama faces growing momentum to support widespread encryption
Although the legislative environment is very hostile today, the intelligence communitys top lawyer, Robert S. Litt, said to colleagues in an August e-mail, which was obtained by The Post, it could turn in the event of a terrorist attack or criminal event where strong encryption can be shown to have hindered law enforcement.
There is value, he said, in keeping our options open for such a situation.
Litt was commenting on a draft paper prepared by National Security Council staff members in July, which also was obtained by The Post, that analyzed several options.

@_date: 2015-09-17 10:15:51
@_author: Henry Baker 
@_subject: [Cryptography] FBI: Weaker Encryption Is a Worthwhile Tradeoff for 
FYI -- Easy for the FBI to say; they're not on the hook for potentially billions in damages from any breach.  (Leaving aside the egregious Constitutional violations.)
FBI: Weaker Encryption Is a Worthwhile Tradeoff for Law Enforcement Access to Data
Government officials sparred with privacy advocates over encryption, but acknowledged that back doors come with risks of intrusion.
Kaveh Waddell September 15, 2015
The Justice Department and the FBI are continuing their campaign to convince the tech community and the public that weakening encryption to allow law enforcement to access encrypted communications and data has its risks, but that the drawbacks are outweighed by the security advantages.
Amy Hess, the executive assistant director of FBIs science and technology branch, said at a Christian Science Monitor discussion that allowing access to encrypted messages to anyone other than the sender or the receiver comes with some risk of intrusion.  But because law enforcement must be able to read encrypted data and communication to do its job, the risk of third-party access is acceptable, Hess said, as long as it is minimized.
The Justice Department-and especially the FBI-has clashed with the technology community over the agencys demands that online platforms stay away from encryption practices that keep data private even from the platforms themselves.  If the communications service cannot access the data sent across its servers, it cannot turn the data over to law enforcement.
Law enforcement has called on tech companies to take the lead in developing an encryption standard that is both secure and accessible to authorities upon request.  Last week, FBI Director James Comey said technology experts just need to try harder to find a solution.
But experts maintain that such a standard is impossible to achieve, because any third-party key for unlocking encrypted data-even if reserved for extreme circumstances-will be vulnerable to hackers.
A company that builds vulnerabilities into its encryption becomes an attractive target of attack to foreign governments, criminal hackers, and drooling teenagers in basements, said Matt Blaze, a noted cryptography expert and professor at the University of Pennsylvania.
Because companies are increasingly turning to stronger encryption, the FBI is running out of tools to fight crime, Hess said Tuesday.  A request for a wiretap-one of the most powerful surveillance tools available to the FBI-is a long and complicated process that requires an agent to supply an extensive affidavit stating that every less-intrusive method of surveillance had already been considered or applied, according to Kiran Raj, Senior Counsel to the Deputy Attorney General.
But Hess said FBI agents will not apply for wiretaps if they think a suspect is using encrypted communication, because they are not willing to expend the time and cost of crafting the request if the odds of its success are slim.
The FBIs claim was largely met with a shrug from privacy advocates.
A warrant is not a right that the government has to get data, said Jon Callas, CEO of Silent Circle, a company that builds encrypted communications platforms.  It is a right to perform a search, to attempt to get the data, and there may be a lot of reasons why it cant get to it.
But even as privacy advocates clashed with law enforcement officials onstage over the form encryption should take in the tech community, the groups said they both have the same objectivesecurityin mind.
The polarization of this debate is really harmful, Blaze said.  I think that in terms of the end goals, theres a lot more common ground here than maybe the debate lets on.

@_date: 2015-09-18 07:43:37
@_author: Henry Baker 
@_subject: [Cryptography] WashPo: Leaked NSC Memo on Encryption 
I purposely changed the bullets into "Z" myself in order to not screw up ascii formatting.
The original pdf file looks pretty crufty, which is why I assumed that it was typed on a manual typewriter (or perhaps an IBM golfball electric).
The document also may have been purposely put through N generations of xeroxing, to try to remove information about which printer it was printed on.
The added "cruft" is a crypto signature added to *every* NSC document in order to nail any unauthorized leaker.

@_date: 2015-09-18 13:05:42
@_author: Henry Baker 
@_subject: [Cryptography] FBI: Weaker Encryption Is a Worthwhile Tradeoff 
I'm waiting to see how DHS/TSA idemnifies all the users of *its* "Golden Key"...
TSA: 'the locks are merely for travelers peace of mind.' [FBI's Comey also wants us to have "peace of mind" with our "secure" (hackdoor-) "encrypted" iPhones !!]
Hacker Easily Cracks TSA-Approved Luggage Locks
Lockpickers and security enthusiasts have figured out how to use 3-D printers to reproduce Transportation Security Administration master keys, and they posted the instructions on Github.
The TSA, however, told Money Talks News the reproductions are not a security threat and that the locks are merely for travelers peace of mind.

@_date: 2015-09-18 22:37:17
@_author: Henry Baker 
@_subject: [Cryptography] Comey: targeted ads => plaintext access 
I'd be interested in how such a protocol would work, as well.
I assume that the user will be required to run some Javascript
function f(x) that Google gives him.  The user executes f(M),
where M is the message, or executes f(w), for all words w in M.
However, why should the user trust Google's f(x) not to simply
send every w back to Google in the clear?
I'm guessing that a protocol where no one trusts one another
might be pretty difficult to arrange.
We already have malicious ads that will attempt to subvert
the Google-equivalent, the user, and/or other advertisers.
There are some Google-equivalents -- e.g., ATT, Comcast --
that run MITM attacks on their users all the time.
And then there are the watchers, who are looking at all of
the message traffic.  They would be happy to get the info
they're looking for from the ads; they currently utilize
user tracking cookies placed there by the ad folks for
their purposes already.
So arranging a private, safe & secure protocol amongst
all of these players is a pretty tall order.
I guess we'll have to call this the (anti?)Comey problem,
in honor of Mr. Comey.

@_date: 2015-09-19 18:40:56
@_author: Henry Baker 
@_subject: [Cryptography] Comey: targeted ads => plaintext access 
I assume that the FBI/DHS is already buying keywords from Google in Google's ad auctions, so the FBI is already reaping whatever information any other advertiser can also get from Google.
I haven't checked, but how much could the arabic words for "ammonium nitrate", "detonator", "box cutter", "multi-engine level flight training" possibly cost ?
Of course, "the falafel is about ready to go into the fryer" and "you need the correct proportion of garlic with your hummus" is certain to be misinterpreted in emails and text messages.
I'm waiting for one of the folks in "Homeland" to click on a "sponsored link" for one of the words/phrases above, so they can transact business with one of the CIA's 72 virgins.

@_date: 2015-09-22 11:12:08
@_author: Henry Baker 
@_subject: [Cryptography] TRR: Anonymization Technology for Bitcoin 
FYI --
Transaction Remote Release (TRR): A New Anonymization Technology for Bitcoin
QingChun ShenTu, JianPing Yu
(Submitted on 21 Sep 2015)
The anonymity of the Bitcoin system has some shortcomings.  Analysis of Transaction Chain (ATC) and Analysis of Bitcoin Protocol and Network (ABPN) are two important methods of deanonymizing bitcoin transactions.  Nowadays, there are some anonymization methods to combat ATC but there has been little research into ways to counter ABPN.  This paper proposes a new anonymization technology called Transaction Remote Release (TRR).  Inspired by The Onion Router (TOR), TRR is able to render several typical attacking methods of ABPN ineffective.  Furthermore, the performance of encryption and decryption of TRR is good and the growth rate of the cipher is very limited.  Hence, TRR is suited for practical applications.

@_date: 2015-09-24 09:09:19
@_author: Henry Baker 
@_subject: [Cryptography] VW/EPA tests as crypto protocols ? 
By now, you've all heard of the VW SW that cheats/defeats the EPA testing protocol.
But VW isn't alone, and expect further revelations as the white hats start investigating these types of misbehavin' SW.
So what's a regulator to do?
Recall that error-detecting codes were designed to counteract "random" errors, but are incapable of dealing with intelligent/malicious adversaries.
Similarly, traditional statistical quality control techniques (e.g., "six sigma") were designed to deal with "random" manufacturing errors, and are incapable of dealing with intelligent/malicious saboteurs.
These differences are crystallized by the difference between a traditional random number generator and a crypto-quality random number generator.
We're now in a SW era in which regulators must bless equipment that may have incorporated malware, whether injected by saboteurs or whether injected by the manufacturer itself.
We're in the same position as Apple and Google (Android) in policing their App Stores; we must ensure that none of the apps will misbehave when released into the wild.
This is a very tall order, and in general, it is undecidable -- even when the criteria for "misbehavin'" are rigorously precise, which they aren't.
Many -- most prominently Cory Doctorow and Eben Moglen -- have called for changes to the DMCA to allow for source code inspection.  I predict that some changes will be allowed so that the white hats can challenge this "dark firmware".
But changes to the DMCA won't be sufficient.  Various types of SW obfuscation will make finding such cheats/defeats difficult to find -- e.g., Apple's "goto FAIL" ;-) ;-) bug -- and providing enough incentives for all this white hat code inspection work will be difficult.
But it's even worse still.  Techniques such as "HARES" (split data/instruction caches + encrypted instruction pages) will make even the *examination* of code extremely difficult, while techniques such as nVidia's "DCO" (Dynamic Code Optimization aka JIT compilation) means that examination of code won't tell you *anything*, since the code that *runs* is decided by the JIT compiler itself, with the binary firmware code simply being a "suggestion" about what the executed instructions are supposed to do.
Since nVidia's DCO technology is being targeted directly at the *automotive* industry, a future VW-wannable can simply instruct the JIT compiler to hide the cheats/defeats in the JIT compiler itself, so that the binary firmware itself is 100% legit.  However, after the JIT compiler runs, the cheat/defeat is installed and/or executed, so that the car fraudulently passes the EPA test.
So whether we want to or not, we're also going to have to deal with *behavioral observation*, since source code inspection won't be sufficient.  (There may also be a number of simpler HW techniques that can be used to modify/mask the malware's behavior when undergoing EPA tests; hopefully, behavioral testing can uncover some of those cases.)
We have to perform a kind of "Turing Test" -- except in reverse: the malware has to correctly guess when it's being EPA-tested so that it behaves correctly, and only misbehave when it feels certain that it's running in the wild.
When the memory available to the malware is limited, the malware's ability to store a chess program-like "book" (e.g., a list of standard EPA testing cycles) is also limited.  In a memory-limited era, the malware didn't have enough memory to memorize all of the EPA testing cycles.
Unfortunately, that era is long gone; modern embedded processors have gigabytes of storage available to memorize 100's of thousands of miles of EPA tests, so producing a test challenging enough to force a VW-wannabe's malware out of its "book" is also extremely difficult.
So the question remains: how to generate a cryptographically secure challenge test that is *indistinguishable* enough from a real-world drive so that the firmware misbehaves a negligible fraction of the time while in the wild?

@_date: 2015-09-24 11:28:12
@_author: Henry Baker 
@_subject: [Cryptography] WashPo: Obama admin backdoor proposals 
FYI -- From today's Washington Post; OCR'd pdf file below.
On July 13, 2015, Deputies asked the encryption working group to prepare for Principals consideration guidance on
(1) key trade-offs identified through its analysis of possible technical approaches; and
(2) the lessons learned from that analysis.
This document provides that assessment and further identifies technical challenges for which the working group was unable to identify solutions and potential policy principles that could guide any engagement by the United States Government with industry on encryption issues.  To facilitate Principals analysis and discussion, this document includes the four technical approaches to implementing accessible encryption developed by the working group developed.  However, these approaches are intended as proofs-of-concept and Deputies agree that the approaches should not be advanced as affirmative Administration proposals or shared outside the United States Government.
Lessons Learned.  Encryption working group participants have identified four key lessons that should inform any consideration of technical proposals to enable targeted lawful access to encrypted data.
There is no one-size-fits-all technical approach.  No single approach can enable access to encrypted information across all media and providers.  Each type of encryption will require unique technical approaches, and each particular company would need to implement approaches specific to their implementation of encryption in the products and services it offers.  Further, enabling lawful access to some forms of encrypted data, should companies be willing to do so, will be easier with some implementations than others.
Different encryption implementations require different approaches.  From a technical perspective, encryption can be divided into three categories: the encryption of data stored on devices held by consumers; the encryption of communications in transit between parties; and the encryption of data stored in remote locations (e.g., cloud-based storage of backups).  Each type of encryption carries different security risks, policy implications, and technical challenges - and maintaining clarity in technical and policy discussions is essential to identifying potential options.  For example, one approach to enabling access to data on devices could be through limiting to only those with physical access to the device, which reduces the security risks of such access and limits the ability for abuse.  Similarly, the nature of communications encryption poses particular challenges to law enforcement access solutions that do not exist for stored data (whether in the cloud or on devices)
Intended use cases should drive proposed technical approaches.  Law enforcement may seek access to encrypted data in a variety of scenarios, and the particular circumstances will substantially change the requirements of how a provider might enable that access.  For example, law enforcement seeking to use encrypted data to stop an impending attack or crime needs rapid access while law enforcement seeking to use data on a seized device to make a case against a defendant could accept a slower solution.  Similarly, efforts to compel access to encrypted data held by sophisticated criminals like terrorists and organized crime may be unsuccessful if the fact that such compulsion is possible is widely known because such criminals will choose to use inaccessible alternatives.  On the other hand, unsophisticated criminals or individuals responsible for crimes of passion, may be less likely to switch to technology products and services that are inaccessible to law enforcement.
Technical approaches can be enforced in multiple ways.  The technical requirements of a particular proposed solution (for instance, that law enforcement may only access data on a single device as part of each request) could be enforced in multiple ways.  It could be enforced through a law, through Executive branch policy, or through technological limitations built into the device or service itself.  However, some technologists, civil society, and companies may perceive any government access as an attempt to obtain widespread, non-targeted access for bulk collection purposes.  Accordingly, those communities almost certainly will be unlikely to trust limitations enforced through policy or law, and will be more likely to be satisfied by those enforced through technology.
Technical Challenges.  The working group also identified several technical challenges for which there is no clear solution.  Although technical approaches to enable lawful access to encrypted data may be able to mitigate some of the public safety challenges posed by encryption, these challenges mean that inaccessible encryption will always be available to malicious actors.
Strong encryption is increasingly available in global technology products and services.  Unlike the crypto wars of the 1990s, encryption is no longer solely available to governments.  Established companies and independent developers in many countries around the world are developing encrypted products and services.  Further, encryption can be implemented purely through software and effective encryption implementations are increasingly available in the public domain.  As a result, encrypted products and services will always be available to malicious actors, including in countries that do not adopt an accessibility regime.
Encrypted products and services often use open source software for implementation.  Many encryption solutions are open-source projects developed by communities of volunteers that are based in multiple countries.  For example, the predominant implementation of the encryption protocol used to secure web sites for e-commerce transactions is open source.  Most of these solutions are made available free of cost, and are not distributed by any single institution, but shared on a peer-to-peer basis.  As a result, there may be no central authority that can update these solutions to comply with any requirements for implementing encryption in a manner that would support law enforcement access.
Inaccessible encryption can be layered on top of accessible encryption.  Because encryption solutions are often implemented through software, individuals using a device with accessible encryption can easily install an inaccessible software encryption solution on the device.  For example, if Apple or Google were to change their mobile phones to allow for decryption of the device pursuant to lawful process, a user could still download a mobile application that could allow for encrypted communications (e.g., Skype).  Layered encryption means that, even if all core U.S. services and devices have accessible encryption, individuals will be able to defeat attempts to access their information.
Proposed Policy Principles
Deputies agreed that attempts to build cooperation with industry, vice proposing specific technical solutions, will offer the most successful option for making progress on this issue.  In particular, given industry and civil societys combative reaction to government statements to date, any proposed solution almost certainly would quickly become a focal point for attacks and the basis of further entrenchment by opposed parties.  Rather than sparking more discussion, government-proposed technical approaches would almost certainly be perceived as proposals to introduce backdoors or vulnerabilities in technology products and services and increase tensions rather build cooperation.
However, if the United States Government were to provide a set of principles it intends to adhere to in developing its encryption policy, such a document could spark public debate.  Proposing such principles would not be without risk, as some constituencies may not distinguish between principles and specific technical approaches.  As a result, these principles could come under attack, but could also serve to focus public or private conversation on practicalities and policy trade-offs rather than whether the government is seeking to weaken encryption or introduce vulnerabilities into technology products and services.
Based on the lessons learned from the initial technical review, the encryption working group has developed a set of principles that could guide the United States Governments engagement with the private sector on encryption.  While all of the principles should inform private discussions with industry, some, all, or none of them could be incorporated into any public debate.
1.  No bulk collection.  Any approach to enable lawful access should focus on enabling targeted - as opposed to bulk  access to decrypted information.
2.  No unilateral government access.  Approaches should not provide golden keys to government or allow government to access decrypted information without the assistance of a third party.
3.  Technologically-enforced limits.  To the extent possible, approaches should rely on technology, rather than procedural protections, to enforce constraints on government access.
4.  International adoption.  The United States Government will accept that any U.S.-proposed solution will be adopted by other countries.
5.  Maximize security and minimize complexity.  Any accessibility regime carries the inherent risk that a malicious actor could exploit that accessibility for malicious ends.  As a result, any accessibility regime should be designed to minimize complexity (a key factor that increases risk of vulnerability) and maximize security.
6.  Minimize impact of malicious exploitation.  No technical approach can be implemented in a manner that guarantees perfect security.  Accordingly, any accessibility regime must be designed to limit the impact of a successful exploit by a malicious actor.  For instance, a device access regime that requires physical access to the device would limit the impact of an exploit because a malicious actor would have to have physical possession of a targeted device.
7.  Minimize negative impact on innovation.  Certain access regimes could limit technical innovation by closing the door to certain types of encryption solutions.  For example, current best practices for communications encryption requires that each new message be encrypted using a distinct key  a principle called forward secrecy that mitigates the consequences of an exploit by ensuring that any single key only exposes a single communication.  A technical approach that implemented accessible encryption in a manner that makes forward secrecy impossible would limit innovation and hamper efforts to better secure communications.  In this vein, any accessibility requirement should be designed in such a way that it minimizes any negative impact on innovation.
8.  No one size fits all approach.  No single accessible solution that could work for all types of encryption or all developers.  Providers, not the government should be responsible for determining how to design any feasible approaches into their products and services.
Avoid undermining trust in security.  The modern Internet ecosystem relies on all participants trusting the security of their communications and data.  Any technical approach should be tailored to avoid undermining this trust.
9.  [empty]
Technical Proofs of Concept
Technical experts in the working group developed several proof-of-concept technical approaches that could theoretically enable access to some types of encrypted data.  Working group participants agreed that all of these proposals were technically feasible, although they disagreed as to the value and viability of each of the solutions.  Further, working group participants agreed that these proposals should be seen as only examples, and would need to go through substantial revision and refinement if they were to be further pursued.
Provider-enabled access to encrypted devices based on physical control of the device.  For this approach, providers would modify the hardware of their devices to include an independent, physical, encrypted port.  The provider would maintain a separate set of keys for its customers devices that would enable it to decrypt those devices, but only if it had physical access to the device itself.  If law enforcement seized an encrypted device that it could not access, it would secure lawful process from a U.S. court and submit the device itself, along with the lawful process, to the provider.  The provider would use its secondary key to unlock the device, and provide the resulting data back to law enforcement.  Making a hardware modification would impose significant cost on U.S. manufacturers, but requiring physical access to enable decryption substantially reduces the cybersecurity risk of a secondary access point, and limits the risk of abuse by malicious actors and foreign governmen
t entities.  This solution would provide access only to devices (although some communications stored on the device could be accessible as well), and would not prevent a customer from installing a secondary layer of encryption on top of the device encryption.
Provider-enabled remote access to encrypted devices through current update procedures.  Virtually all consumer devices include the capability to remotely download and install updates to their operating system and applications.  For this approach, law enforcement would use lawful process to compel providers to use their remote update capability to insert law enforcement software into a targeted device.  Once inserted, such software could enable far-reaching access to and control of the targeted device.  This proposal would not require physical modification of devices, and so would likely be less costly for providers to implement.  It would also enable remote access, and make surreptitious access much less costly.  However, its use could call into question the trustworthiness of established software update channels.  Individual users, concerned about remote access to their devices, could choose to turn off software updates, rendering their devices significantly less secure as time p
assed and vulnerabilities were discovered by not patched.
Remote access enabled only when multiple parties, each of which holds a partial key, participate.  In this approach, a secondary decryption key is divided across multiple recovery parties.
These parties would provide their sub-keys either to the provider or to law enforcement under court order to enable reconstruction of the encryption key and decryption of the data.  This approach would enable remote and surreptitious access to data stored both in devices and remote databases.  it would also limit the risk of exploit by requiring any attacker to infiltrate multiple recovery entities to secure a complete recovery key.  However, it is important to note that this approach would be complex to implement and maintain, as it would require a network of independent recovery parties which could then be validated by trusted third parties.
Remote access to data stored on encrypted devices enabled by providers implementing a forced backup of the data to an alternate, accessible location.  The approach relies on providers being able to remotely backup information stored in an encrypted location to a different location that is not encrypted.  Pursuant to lawful process, the provider would turn on remote backup, and provide the resulting backed-up information to law enforcement.  This solution could be implemented with notice to the customer (for instance, a dialog box on their device could indicate that remote backup is being enabled, and could indicate that it is happening in response to a law enforcement request or not) / or could be done surreptitiously.  For many providers, enabling this proposal would require designing a new backup channel, or substantially modifying an existing channel.

@_date: 2015-09-24 17:59:25
@_author: Henry Baker 
@_subject: [Cryptography] VW/EPA tests as crypto protocols ? 
I wasn't previously aware of "Goodhart's Law"; there is a more quantitative form of the same effect from control theory, but I don't know if it has a proper name.
Basically, if you're trying to control a number of variables having differing levels of uncertainty (e.g., variance), you will end up controlling the system so as to push all/most of the uncertainty into the variable you can measure the *least well*.
Thus, if you are trying to control some position (x,y,z), where measurement variances are ordered variance(x)<variance(y)<variance(z), then your feedback control system will unwittingly push all of the variance of the controlled position into the z coordinate.  Thus, if (x,y,z) is the position of some airplane or spacecraft, you will *crash* it precisely at the position (x,y), because you could measure x and y, but not z!  (The alternative requires more subtlety: minimize the variance of z *regardless* of x & y; you will land safely, but just not exactly where you wanted.)
Perhaps this effect should be called the "out of sight, out of mind" ("out of control" !?!) theorem.  Alternatively, you might call it "crashing the spacecraft near the lightpost, because that's where it's easiest to see" theorem.
Other obvious examples of Goodhart's Law are medicines that "treat the numbers" instead of "treating the disease", and educators who "teach to the test".  (And then there are institutions such as Harvard that don't even trust themselves to "teach to the test", and simply arrange to admit only those who can *already* pass the test with no further instruction required!)

@_date: 2015-09-25 07:47:31
@_author: Henry Baker 
@_subject: [Cryptography] GCHQ Cryptome surveillance 
FYI -- Congratulations, Cryptome!
Cryptome surveillance
One screenshot of SAMUEL PEPYS in action shows the agency using it to monitor an individual in Sweden who visited a page about GCHQ on the U.S.-based anti-secrecy website Cryptome.

@_date: 2015-09-28 17:06:55
@_author: Henry Baker 
@_subject: [Cryptography] Google AdSense vuln de-obfuscates ad links for click 
FYI -- More evidence that better advertising crypto protocols are needed to protect all parties: web site, advertiser, website visitor.
Google AdSense click fraud made possible by uncloaking advertisers sites
According to new research source code manipulation can be used to penetrate the security of Googles AdSense system, by automatically obtaining the JavaScript code which protects advertisers from click fraud.
The paper A vulnerability in Google AdSense: Automatic extraction of links to ads [PDF] by Prof. Manuel Blzquez of the Complutense University of Madrid, outlines a procedure whereby the attacker can de-obfuscate the cloaked advertiser target links automatically and perform automated clicks of the ads, either to the benefit of the site hosting the ads  if the intention is to generate simulated commercial traffic, or to the detriment of competitor sites, if the intention is to compromise their standing with Googles AdSense system by creating a blizzard of patently bogus ad-clicks.
A vulnerability in Google AdSense: Automatic extraction of links to ads
On the basis of the XSS (Cross Site Scripting) and Web
Crawler techniques it is possible to go through the
barriers of the Google Adsense advertising system by
obtaining the validated links of the ads published on a
website.  Such method involves obtaining the source
code built for the Google java applet for publishing and
handling ads and for the final link retrieval.  Once the
links of the ads have been obtained, you can use the user
sessions visiting other websites to load such links, in the
background, by a simple re-direction, through a hidden
iframe, so that the IP addresses clicking are different in
each case.

@_date: 2015-09-30 07:38:24
@_author: Henry Baker 
@_subject: [Cryptography] Insecure Chip 'n' PIN starts tomorrow 
FYI -- More like Bait 'n' Switch...  This isn't about fraud at all, but about shifting liability away from the banks.
Chip and PIN has been proven to combat fraud dramatically, says Brian Dodge, executive vice president of the Retail Industry Leaders Association.  But thats not what American consumers are getting, and thus far banks have gone to great lengths to blur the lines between the two distinctly different transactions. [The American banks are] more interested in protecting themselves than they are in helping the retailers out.
'Visa and MasterCard could have resolved this problem by forcing card issuers to use chip n PIN only; but they never did.'

@_date: 2016-04-01 07:41:17
@_author: Henry Baker 
@_subject: [Cryptography] Apple To Buy CryptoWall for $10 Billion 
[Originally submitted to Risks, but bad editing ruined the joke.]
"Apple To Buy CryptoWall for $10 Billion"
"Plans to dominate the burgeoning data protection market"
One Infinite Loop, Cupertino, CA -- April 1, 2016 -- Apple Computer today announced its plan to purchase the data protection business CryptoWall for $10 billion.  The deal is expected to close before the end of 2016 after securing the approval of regulators.
Apple CEO Tim Cook laid out the rationale for the purchase.  "Apple Computer has always insisted upon the privacy and security of its customers.  We were the first to incorporate default full-disk encryption, and CryptoWall is the obvious next step in protecting our customers' data confidentiality."
"CryptoWall's product is in daily use by government agencies, businesses and ordinary citizens; they have the best name recognition and brand image in the data protection business," explained Cook.
"We surveyed the market -- from CryptoLocker to Reveton -- and found that CryptoWall had the strongest encryption, the best user interface, and the largest market share."
The CEO of a major hospital chain added, "CryptoWall is more secure -- and cheaper -- than RSA's products."
"The FBI recently did a thorough analysis of the security of Apple products, and they were very helpful in highlighting some vulnerabilities that we felt obliged to fix as soon as possible.  The CryptoWall suite of products not only had the right synergy with our needs and timing, they also had the blessing of the FBI," said Mr. Cook.
"[CryptoWall's] ransomware is that good," said Joseph Bonavolonta, the Assistant Special Agent in Charge of the FBI's CYBER and Counterintelligence Program in its Boston office.  "To be honest, we often advise people just to pay the ransom."
He was referring to programs like Cryptolocker, Cryptowall, Reveton and other programs that encrypt the contents of a user's hard drive, as well as other directories accessible from their system.  The owner is then asked to pay a fee -- often hundreds of dollars -- for the key to unencrypt the data.
The FBI issued a notice which identified CryptoWall as the most common form of ransomware affecting individuals and businesses in the US.  The Bureau said it had received 992 reviews of CryptoWall between April 2014 and June 2015 suggesting revenues in excess of $18 million.
"The easiest thing may be to just pay the ransom," according to Bonavolonta, who said that efforts by the Bureau and others to defeat the encryption did not bear fruit.  "The amount of money made by these security startups is enormous and that's because the overwhelming majority of institutions just pay the ransom."  And most ransomware vendors are good to their word, Bonavolonta said.  "You do get your access back."
According to noted computer security expert Bruce Schneier, "Most computer security is like a chocolate truffle: hard chocolate on the outside, but soft and gooey caramel on the inside".  "Apple's hookup with CryptoWall will enable a crunchier experience -- more like Toblerone", said Bruce, still celebrating the Tony award recently won by his Broadway musical "TSA".
CEO Cook believes that putting a CryptoWall around the iOS kernel will further protect the keys stored under the front mat of Apple's famed and feared Secure Enclave.  "Knowing that CryptoWall stood up to the unrelenting attacks by FBI's best and brightest, we at Apple can rest easy, knowing that our customers' data will remain private."
When questioned about the sleazy reputation of some enterprises in the data protection business, Cook said, "Dealing with the CryptoWall group was no different than dealing with the Hollywood music and movie industry for iTunes."  "Business is business, and besides, CryptoWall made us an offer we couldn't refuse."
Benjamin Dover was named VP & General Manager of the CryptoWall unit, after moving from Oracle to Apple.  "I expect a seamless transition to CryptoWall, as I became quite familiar with the ransomware business model during my twenty-two years at Oracle."

@_date: 2016-04-01 09:02:28
@_author: Henry Baker 
@_subject: [Cryptography] Alabama governor purchased multiple 'burner' phones 
FYI --
Bentley bought multiple disposable 'burner' cell phones at Tuscaloosa Best Buy
"But Collier's assertions about Bentley often changing phones combines with new revelations about him purchasing 'burner' cell phones to reveal more information about his phone usage habits."
So the governor of Alabama is a terrorist?

@_date: 2016-04-03 15:11:22
@_author: Henry Baker 
@_subject: [Cryptography] Have you seen... 
Which is worse: hacking an election, or having to fix it afterwards -- e.g., Iran, Guatemala, Chile, Vietnam, ... ?
The Dulles brothers would have said that in their experience, it's a lot cheaper & less messy to just hack the elections in the first place to assure the "appropriate" outcome.
Democracy is far too precious to allow the little peoples' votes to actually count.  Heck, we might end up with another Hitler.
I believe that some of the recent GOP primaries included some online voting.  God only knows whether they were hacked.

@_date: 2016-04-05 07:15:12
@_author: Henry Baker 
@_subject: [Cryptography] Hayden on encryption v. metadata 
I'll bite.
A human brain.
A human eye.
A human ear.
A human voice.
Oh wait -- these have no reasonable expectation of privacy.
Let the Nuremburg Trials re-commence.

@_date: 2016-04-05 10:25:48
@_author: Henry Baker 
@_subject: [Cryptography] Hayden on encryption v. metadata 
The Japanese have been living cheek-by-jowl in paper houses with paper walls for hundreds of years.
An Edo-period Japanese person learned very quickly not to listen in on other peoples' conversations.
If someone didn't get this particular memo -- well, that's what Japanese katana swords are best used for!
Apparently, many crimes in Japan occurred within earshot of large numbers of people, but no one literally "heard" the crime, because they were trained from infancy to not hear conversations not intended for them.
A similar thing occurred in the 19th C. with telegraphers who copied Morse-coded messages.  Although they transcribed them, they never really processed them.  One such telegrapher was surprised to read in the newspaper that Lincoln had been shot, even though he had previously transcribed that particular news message himself.
So yes, people have been eavesdropping for perhaps 200,000 years.  They've also been summarily executing eavesdroppers for 199,999 years.

@_date: 2016-04-05 14:38:16
@_author: Henry Baker 
@_subject: [Cryptography] Hayden on encryption v. metadata 
Yes, the reaction by the intel community to the Snowden revelations was pretty telling.
They just couldn't understand why ordinary citizens hated being surveilled so much;
they assumed that we'd all throw rose petals in front of them, and hug them or something.
Now, their kids come home from school and ask "Daddy, how many people have you blown up with your drone today?"
"Can Johnny come over and play drones with me today, so we can blow up people, too?"

@_date: 2016-04-08 10:25:23
@_author: Henry Baker 
@_subject: [Cryptography] Text of Burr-Feinstein encryption backdoor bill 
FYI --
"Compliance with Court Orders Act of 2016"
It is the sense of Congress that-
(1) no person or entity is above the law;
(2) economic growth prosperity security, stability,
and liberty require adherence to the rule of law;
(3) the Constitution and laws of the United States
provide for the safety, security, and civil
liberties of all United States persons and the
protections and obligations of these laws apply to
all persons within United States jurisdiction;
(4) all providers of communications services and
products (including software) should protect the
privacy of United States persons through implementation
of appropriate data security and still respect the rule
of law and comply with all legal requirements and court
(5) to uphold both the rule of law and protect
the interests and security of the United States, all
persons receiving an authorized judicial order for
information or data must provide, in a timely  manner,
responsive, intelligible information or data, or
appropriate technical assistance to obtain such
information or data; and
(6) covered entities must provide responsive,
intelligible information or data, or appropriate
technical assistance to a government pursuant order.
Translation of the preamble: "Abandon all hope,
ye who enter here".

@_date: 2016-04-09 13:51:56
@_author: Henry Baker 
@_subject: [Cryptography] Windows Bash 
Microsoft is adding the Linux command line to Windows 10
Bash coming to Windows is huge news for malware/ransomware developers, nation-state APT teams
Redmond, WA -- April 1, 2016 -- Microsoft announced today that Win10 would soon provide full support for yet another universe of exploits by including the BASH shell in all Win10 installations including mobile phones, Raspberry Pi and IoT installations.
According to Roger Jolly, leader of Microsoft's highly-regarded "Stuxnet" team, "our partners in the International Persistent Threat Consortium -- particularly the smaller members like North Korea and Iran -- have had difficulty managing a large inventory of exploits based on Powershell due to the increasing difficulty in hiring Powershell experts."  Dr. Kim Kim, of North Korea, who also sits on the IPTC Board, added "Our recent hack of Sony may be the last of our Powershell-based attacks, because we are redeploying our Powershell hackers into the more versatile Flash and Java exploits."
Microsoft's Jolly also gave a shout-out to NSA, "The NSA felt that it could better optimize its scarce and expensive APT team members by standardizing on the BASH shell.  NSA's BASH-based platform -- codenamed Monster Bash -- provides all the capabilities that were needed to attack almost any widely used platform -- with the possible exception of legacy Mac OS9 applications still found on some California Senators' desks."

@_date: 2016-04-10 09:47:56
@_author: Henry Baker 
@_subject: [Cryptography] More magical encryption thinking from James Comey 
FYI --
Video 30-minute speech + 50 minutes Q&A
(at the 74-minute mark, in response to a question, Comey admits that he put tape over his laptop camera!)
CSAD Conference Opening Address with FBI Director James Comey
Center for the Study of American Democracy Biennial Conference, Kenyon College
Gambier, OH
April 6, 2016
'every time you hear somebody making a slippery slope argument, an alarm should go off in your head. There is a reason your professors call this "slippery slope fallacy."  It could be that if you take one step youll inevitably fall down a slick slope, it could be.  It depends a lot on what kind of shoes youre wearing, whether the slope is a stairs slope, and whether theres a railing.'
(BTW, Michael Hayden wears lime-encrusted cleats on his shoes when slipping around on strongly encrypted slopes ! )
Even though the math community had been preparing itself for 20-30 years for the possibility/probability that arithmetic was undecidable, Goedel's results in 1931 still shook the community, and some mathematicians never recovered.
Obviously, Comey & friends are still in the "denial" stage of grief over the fact of strong encryption, and they may never come to grips with it.
Max Planck characterized this problem well: "Science advances one funeral at a time."

@_date: 2016-04-10 17:08:26
@_author: Henry Baker 
@_subject: [Cryptography] More magical encryption thinking from James Comey 
I don't know much about the law, but it seems to me that a 'slippery slope' argument is essentially a Bayesian argument, which includes prejudices.
Unfortunately, Bayesian arguments take the blindfold off Lady Justice, so if I were being judged, I'd rather not have a biased judge.
On the other hand, public policy *must* take into account a priori probabilities, else we will spend billions of dollars trying to save a single life.  (Hence our insane focus on terrorists and guns instead of auto accidents and sugar.)
Medical treatments now include the extremely valuable "number needed to treat", which attempts to bring a Bayesian rationality to treatment plans -- including drugs.
So what "number needed to treat" is Comey suggesting?  That we destroy the privacy and security of a billion people in order to catch one bad guy?
Comey's proposal is not even remotely close to Blackstone's ratio:
"It is better that ten guilty persons escape than that one innocent suffer"

@_date: 2016-04-14 09:13:40
@_author: Henry Baker 
@_subject: [Cryptography] USB 3.0 authentication 
Lemme see.  Even if my "free" charger can't hack your device through the normal signal pins, I may still be able to read some of your secrets using the details of the power consumption signal.  And then, there's bound to be some small amount of crosstalk of the power signal with other signals of your device.
And then there's other signals -- e.g., I simply include a microphone so that I can not only hear your conversation, but I can eavesdrop on your device's power supply audio emanations.
Even w/o a camera, I can sense high frequency light signals.
Also, if you're close enough to plug in, I can easily pick up your Bluetooth -- including BTLE, your ANT+ signals, your wifi signals, etc.
If a company can build a PEN tester into a power strip several years ago (Google it!), then why would anyone *ever* trust an airport charging station again?

@_date: 2016-04-14 12:50:05
@_author: Henry Baker 
@_subject: [Cryptography] Simple IoT sensor encryption ? 
Suppose we have some relatively simple, cheap IoT *sensors* with an SoC processor with perhaps AES capabilities.
We consider only send-only sensors here, because the authentication requirements on *actuators* should be far, far stronger.
For simplicity, this sensor is single-threaded in its communications with a data repository in the "cloud".
Threat model: since the sensors are cheap & widely distributed, we have to assume that anyone can get physical access to such a sensor & perform any amount of analysis on it that s/he wants.  Furthermore, the data channels between the sensor and the data repository are available for everyone to see -- e.g., wireless transmission, with the possibility of MITM attacks.
So it is obvious that the system is most secure if it contains no *secrets*, at all.
This situation is a perfect case for public key crypto: the sensor contains only the *public key* needed to encode the data, but it has no capability to decode the data.  We can watch the sensor all we want, we can single step it if we want, and all we will learn is that particular sensor measurement and the *public* key; but since we have physical access, we could have done the measurement ourselves and the public key is already public!
The sensor can obviously be jammed and/or spoofed (including MITM spoofing), but the information from a legitimate sensor is protected by the public key crypto system -- assuming that the information eventually arrives at the data repository and is somehow authenticated.  We leave the authentication problem aside for the moment.
So, the obvious implementation has the sensor storing only the data repository's public key, and the sensor encrypts its information using this public key and passes it along.
(We also ignore the problem of revoking the public key of the data repository.)
First problem: the computational requirements of full public key encryption could overwhelm the cheap little IoT CPU.
So this means that we may have to encrypt with a symmetric key system -- e.g., AES -- and somehow encrypt this AES key with the public key, and then send the pair (PK-encrypted symmetric key, AES-encrypted data) to the data repository.
But now we have a problem, because the little sensor now has an AES key secret that it can be forced to divulge.
Ok, so now we have 2 choices: engage in a DH exchange with the repository or utilize random numbers.
Using a DH exchange is a real problem due to 1) latency and 2) we now need the little sensor to be able to *receive* data from the data repository, which complicates the system enormously and opens up whole new vistas of attack surfaces.  It also doesn't solve the problem of fully protecting the session keys so negotiated from physical attacks.
So the sensor decides to use a random number generator.  If it generates a random AES key every time it starts up, then it can PK-encode this AES key and send it along with the AES-encoded data.
However, our little CPU can now be compromised in any number of ways: someone can watch and/or glitch its power supply, so that it reveals its secrets.  Someone could conceivably deduce the current AES key from these power supply variations.
We can also periodically (e.g., 1x per second or 1x per hour) generate new AES keys and send along the PK-encrypted new AES keys.  This at least might provide perfect forward secrecy so that future data isn't compromised.
But we haven't been able to *emulate* all of the features of public key crypto for our particular threat model using a combination of public & symmetric key crypto.
Should we just "bite the bullet" and brute force PK-encrypt all the sensor data?  This works, although it may use a heck of a lot more power, and may doom this scheme to quite low-bandwidth signals.
Or is there a more elegant way that doesn't also make the sensor vulnerable to physical attacks?

@_date: 2016-04-15 05:55:47
@_author: Henry Baker 
@_subject: [Cryptography] Simple IoT sensor encryption ? 
You are correct; I didn't do a good job of explaining the threat model.
I'm interested primarily in confidentiality of the sensor data during transmission & storage.  As I've already said, authenticity will be difficult, if not impossible, to assure w/o some type of stored secret within the device.
Since these cheap sensors can be widely distributed, you have to assume that they are easy to physically access, and after such access, we can assume that some devices will be compromised and/or spoofed.
Let me now turn the situation around.
Assuming that I don't want to store *any* secrets within the sensors, and the communications are strictly one way, what can I actually achieve?
So far, a public-key system like RSA allows the device to encode its data in such a way that it can't be divulged during encryption or transmission -- even with physical access to the device, which will compromise only its current data.
Yes, one or more sensors can be spoofed, and DoS'd, but there may be other means to check on spoofing -- e.g., there may be *too many* sensors for an attacker to spoof, so that I may be able to use some sort of a voting algorithm to ignore outliers.  This is more-or-less the classical situation in any case, as sensors can easily fail and start sending bad information on their own, even without having been attacked.
This is a case where doubling or tripling, etc., the number of sensors may be cheaper, more reliable, and more secure than trying too hard to make "hardened secure" chips which store secrets, but which are resistant to giving up those secrets.

@_date: 2016-04-15 06:57:06
@_author: Henry Baker 
@_subject: Canadian Police Had BlackBerrys Global Decryption Key since 
FYI --
Exclusive: Canadian Police Obtained BlackBerrys Global Decryption Key
By Justin Ling and Jordan Pearson   April 14, 2016
A high-level surveillance probe of Montreal's criminal underworld shows that Canada's federal policing agency has had a global encryption key for BlackBerry devices since 2010.
Exclusive: How Canadian Police Intercept and Read Encrypted BlackBerry Messages
Written by Jordan Pearson & Justin Ling
April 14, 2016 // 08:00 AM EST Imagine for a moment that everybodys front door has the same key.  Now imagine that the police have a copy of that key, and can saunter into your living room to poke around your belongings while youre out, and without your knowledge. Oops!  Now every tin-pot government will want the same key...  That's why it's called a slippery slurp.

@_date: 2016-04-15 10:05:42
@_author: Henry Baker 
@_subject: [Cryptography] Simple IoT sensor encryption ? 
Let's take a totally trivial wireless application: a sports heart rate transmitter strap.  (There are lots of other applications, including audio & video, but let's focus on a much simpler, much less resource intensive application to start with.)
Because this is a *sports* application, this application doesn't have to come under any of the FDA or HIPAA rules.
The heart rate strap (should be) cheap & ubiquitous, but it does need to know where (i.e., the public key of the receiver) to send the information *to*.
While it's called "pairing", it really need only be "un-ing", as the heart rate strap only needs the public key of the receiver device (typically worn on the wrist).
Notice that even this "un-ing" process can occur in public, since the public key is already public, so eavesdropping on the communication can only reveal that a HR strap is being initialized.  The worst that can happen is that someone else's strap starts sending data to you, but you'll quickly notice this.
If you somehow accidently install someone else's public key into your own HR strap, you'll also notice this, because you won't be receiving any HR data from your own strap.
The reason for encryption is
1) so that no one else's receiver can decode your heart rate (even by mistake), and
2) so that even a malicious competitor won't be able to grab your heart rate.
(If you're in the last 100m of a race & can tell that your competitor's HR is maxed out, you may be able to beat him.  If you & your competitor are climbing a hill on your bikes, and his HR is 10 bpm below yours, you may want to consider giving him a flat tire!)
It's unlikely that your competitor will get you to install one of his HR belts, and you would notice if your wrist monitor didn't receive any HR data.
Your competitor could disassemble your belt to his/her heart's (!) content, and still not learn any of your secrets -- in particular, any secrets associated with your wrist monitor.  So you are free to leave your belt in your locker, or leave it out while taking a shower.
You should, however, keep your (waterproof, of course!) wrist monitor on during your shower so that you can control access to this device which contains secret decryption keys.

@_date: 2016-04-15 10:50:49
@_author: Henry Baker 
@_subject: [Cryptography] Simple IoT sensor encryption ? 
Yes, this discussion is primarily a gedanken experiment.
Bluetooth LE is -- as usual for anything that comes out of a standards committee -- a complete disaster.  A few years ago you could still get published exposing BLE hacks, but it's too easy, so people stopped caring and stopped publishing.
The major problem with Bluetooth (of any ilk) is that they need *proprietary* protocols so that they can charge $$$ for putting their damn logo on the device.  In order to have their own patented proprietary protocols, they have to put in something different -- even if it isn't as good as something in the public domain.
(Talk to the ANT folks -- now part of Garmin? -- up in Canada if you want to really understand what's going on with BLE.)
Since I really don't want my HR transmitter strap to be received by my auto radio -- or any random hacker -- I'd rather not use the crufty BLE protocol.
I'd love to be able to hack my own HR belt & HR wrist monitor to install my own protocols, but so far, no one has open-sourced these things.

@_date: 2016-04-16 12:15:28
@_author: Henry Baker 
@_subject: [Cryptography] RCMP Had BlackBerry's Global Decryption Key 
mail.com>
Now that the existence of this "Golden Key" has been made public, one can expect hackers & researchers to be pawing through old Blackberries looking for it.
Any bets on how long this search will take?
Perhaps in time for Crypto'16/Blackhat'16/Defcon'16 in August?

@_date: 2016-04-18 07:23:45
@_author: Henry Baker 
@_subject: [Cryptography] "60 Minutes" hacks Congressman's phone 
FYI --
Hacking Your Phone
Sharyn Alfonsi reports on how cellphones and mobile phone networks are vulnerable to hacking
2016 Apr 17 Correspondent Sharyn Alfonsi
The following script is from "Hacking Your Phone" which aired on April 17, 2016.  Sharyn Alfonsi is the correspondent.  Howard L. Rosenberg and Julie Holstein, producers.
A lot of modern life is interconnected through the Internet of things -- a global empire of billions of devices and machines. Automobile navigation systems.  Smart TVs.  Thermostats.  Telephone networks.  Home security systems.  Online banking.  Almost everything you can imagine is linked to the world wide web.  And the emperor of it all is the smartphone.  You've probably been warned to be careful about what you say and do on your phone, but after you see what we found, you won't need to be warned again.
We heard we could find some of the world's best hackers in Germany.  So we headed for Berlin.  Just off a trendy street and through this alley we rang the bell at the door of a former factory.  That's where we met Karsten Nohl, a German hacker, with a doctorate in computer engineering from the University of Virginia.
We were invited for a rare look at the inner workings of security research labs.  During the day, the lab advises Fortune 500 companies on computer security.  But at night, this international team of hackers looks for flaws in the devices we use everyday: smartphones, USB sticks and SIM cards.  They are trying to find vulnerabilities before the bad guys do, so they can warn the public about risks.  At computer terminals and work benches equipped with micro lasers, they physically and digitally break into systems and devices.
Now, Nohl's team is probing the security of mobile phone networks.
Sharyn Alfonsi: Is one phone more secure than another? Is an iPhone more secure than an Android?
Karsten Nohl: All phones are the same.
Sharyn Alfonsi: If you just have somebody's phone number, what could you do?
Karsten Nohl: Track their whereabouts, know where they go for work, which other people they meet when -- You can spy on whom they call and what they say over the phone.  And you can read their texts.
We wanted to see whether Nohl's group could actually do what they claimed -- so we sent an off-the-shelf iPhone from 60 Minutes in New York to Representative Ted Lieu, a congressman from California.  He has a computer science degree from Stanford and is a member of the House committee that oversees information technology.  He agreed to use our phone to talk to his staff knowing they would be hacked and they were.  All we gave Nohl, was the number of the 60 Minutes iPhone that we lent the congressman.
Sharyn Alfonsi: Hello congressman?  It's Sharyn Alfonsi from 60 Minutes.
As soon as I called Congressman Lieu on his phone, Nohl and his team were listening and recording both ends of our conversation.
Sharyn Alfonsi: I'm calling from Berlin.
Sharyn Alfonsi: I wonder if I might talk to you about this hacking story we're working on.
Karsten Nohl: What hacking story?
They were able to do it by exploiting a security flaw they discovered in Signaling System Seven -- or SS7.  It is a little-known, but vital global network that connects phone carriers.
Sharyn Alfonsi: Congressman thank you so much for helping us...
Every person with a cellphone needs SS7 to call or text each other.  Though most of us have never heard of it.
Nohl says attacks on cellphones are growing as the number of mobile devices explodes.  But SS7 is not the way most hackers break into your phone--
Those hacks are on display in Las Vegas.
John Hering: "Three-days of non-stop hacking."
That's where John Hering guided us through an unconventional convention where 20,000 hackers get together every year to share secrets and test their skills.
John Hering: It's proving what's possible.  Any system can be broken it's just knowing how to break it.
Hering is a hacker himself, he's the 30-something whiz who cofounded the mobile security company "Lookout" when he was 23.  Lookout has developed a free app that scans your mobile phone for malware and alerts the user to an attack.
Sharyn Alfonsi: How likely is it that somebody's phone has been hacked?
John Hering: In today's world there's really only -- two types of companies or two types of people which are those who have been hacked and realize it and those who have been hacked and haven't.
Sharyn Alfonsi: How much do you think people have been kind of ignoring the security of their cellphones, thinking, "I've got a passcode, I must be fine?"
John Hering: I think that most people have not really thought about their phones as computers.  And that that's really starting to shift.
Sharyn Alfonsi: And that's what you think-- it's like having a laptop now?
John Hering: Oh absolutely. I mean, your mobile phone is effectively a supercomputer in your pocket.  There's more technology in your mobile phone than was in, you know, the space craft that took man to the moon.  I mean, it's -- it's really unbelievable.
Sharyn Alfonsi: Is everything hackable?
John Hering: Yes.
Sharyn Alfonsi: Everything?
John Hering: Yes.
Sharyn Alfonsi: If somebody tells you, "You can't do it."
John Hering: I don't believe it.
John Hering offered to prove it -- so he gathered a group of ace hackers at our Las Vegas hotel.  Each of them a specialist in cracking mobile devices and figuring out how to protect them.
Adam Laurie: Would you put your money in a bank that didn't test their locks on their safes?  We need to try and break it to make sure the bad guys can't.
Sharyn Alfonsi: How easy is it to break the phone right now?
Jon Oberheide: Very easy.
Adam Laurie: As you've seen, pretty trivial.
Sharyn Alfonsi: Do I need to connect to it?  OK.
It started when we logged onto the hotel Wi-Fi -- at least it looked like the hotel Wi-Fi.  Hering had created a ghost version--it's called spoofing.
Sharyn Alfonsi: I mean, this looks legitimate.
John Hering: It looks very legitimate.  So you're connected?
Sharyn Alfonsi: I am.
John Hering: And I have your email.
Sharyn Alfonsi: You have access to my email right now --
John Hering: Yeah.  It's coming through right now.  I actually can s-- I know have a ride-sharing application up here, all the information that's being transmitted, including your account ID, your mobile phone, which I just got the mobile number.  Then, more importantly, I have all the credit cards associated with -- with that account.
Jon Oberheide pointed out the greatest weakness in mobile security is human nature.
Jon Oberheide: With social engineering, you can't really fix the human element.  Humans are gullible.  They install malicious applications.  They give up their passwords every day.  And it's really hard to fix that human element.
John Hering warned us he could spy on anyone through their own phone as long as the phone's camera had a clear view.  We propped up a phone on my desk and set up cameras to record a demonstration.  First he sent me a text message with an attachment to download.
John Hering: "We're in business."
Then Hering called from San Francisco and proved it worked.
John Hering: I installed some malware in your device that's broadcasting video of your phone.
Sharyn Alfonsi: My phone's not even lit up.
John Hering: I understand, yeah.
Sharyn Alfonsi: That's so creepy.
Katie: It's pitch black for us.
In this case, when I downloaded the attachment, Hering was able to take control of my phone.  But Congressman Lieu didn't have to do anything to get attacked.
All Karsten Nohl's team in Berlin needed to get into the congressman's phone was the number.  Remember SS7 --that little-known global phone network we told you about earlier?
Karsten Nohl: I've been tracking the congressman.
There's a flaw in it that allowed Nohl to intercept and record the congressman's calls and track his movements in Washington and back home.
Karsten Nohl: The congressman has been in California, more specifically the L.A. area, zoom in here a little bit, Torrance.
The SS7 network is the heart of the worldwide mobile phone system.  Phone companies use SS7 to exchange billing information.  Billions of calls and text messages travel through its arteries daily.  It is also the network that allows phones to roam.
Sharyn Alfonsi: Are you able to track his movements even if he moves the location services and turns that off?
Karsten Nohl: Yes.  The mobile network independent from the little GPS chip in your phone, knows where you are.  So any choices that a congressman could've made, choosing a phone, choosing a pin number, installing or not installing certain apps, have no influence over what we are showing because this is targeting the mobile network.  That of course, is not controlled by any one customer.
Sharyn Alfonsi: ...despite him making good choices.  You're still able to get to his phone.
Karsten Nohl: Exactly.
Karsten Nohl and his team were legally granted access to SS7 by several international cellphone carriers.  In exchange, the carriers wanted Nohl to test the network's vulnerability to attack.  That's because criminals have proven they can get into SS7.
Karsten Nohl: Mobile networks are the only place in which this problem can be solved.  There is no global policing of SS7.  Each mobile network has to move-- to protect their customers on their networks.  And that is hard.
Nohl and others told us some U.S. carriers are easier to access through SS7 than others.  60 Minutes contacted the cellular phone trade association to ask about attacks on the SS7 network.  They acknowledged there have been reports of security breaches abroad, but assured us that all U.S. cellphone networks were secure.
Congressman Lieu was on a U.S. network using the phone we lent him when he was part of our hacking demonstration from Berlin.
Sharyn Alfonsi: I just want to play for you something we were able to capture off of your phone.
Mark on recording: Hi Ted, it's Mark, how are you?
Rep. Ted Lieu on recording: I'm good.
Mark on recording: I sent you some revisions on the letter to the N.S.A., regarding the data collection.
Rep. Ted Lieu: Wow.
Sharyn Alfonsi: What is your reaction to knowing that they were listening to all of your calls?
Rep. Ted Lieu: I have two.  First, it's really creepy.  And second, it makes me angry.
Sharyn Alfonsi: Makes you angry, why?
Rep. Ted Lieu: They could hear any call of pretty much anyone who has a smartphone.  It could be stock trades you want someone to execute. It could be calls with a bank.
Karsten Nohl's team automatically logged the number of every phone that called Congressman Lieu -- which means there's a lot more damage that could be done than just intercepting that one phone call.  A malicious hacker would be able to target and attack every one of the other phones too.
Sharyn Alfonsi : So give us an idea, without being too specific, of the types of people that would be in a congressman's phone.
Rep. Ted Lieu: There are other members of Congress -- other elected officials.  Last year, the president of the United States called me on my cellphone.  And we discussed some issues.  So if the hackers were listening in, they would know that phone conversation.  And that's immensely troubling.
Nohl told us the SS7 flaw is a significant risk mostly to political leaders and business executives whose private communications could be of high value to hackers.  The ability to intercept cellphone calls through the SS7 network is an open secret among the world's intelligence agencies -- -including ours -- and they don't necessarily want that hole plugged.
Sharyn Alfonsi: If you end up hearing from the intelligence agencies that this flaw is extremely valuable to them and to the information that they're able to get from it, what would you say to that?
Rep. Ted Lieu: That the people who knew about this flaw and saying that should be fired.
Sharyn Alfonsi: Should be fired?
Rep. Ted Lieu: Absolutely.
Sharyn Alfonsi: Why?
Rep. Ted Lieu: You cannot have 300-some million Americans-- and really, right, the global citizenry be at risk of having their phone conversations intercepted with a known flaw, simply because some intelligence agencies might get some data.  That is not acceptable.
John Hering: I'd say, the average person is not going to be exposed to the type of attacks we showed you today.  But our goal was to show what's possible.  So people can really understand if we don't address security issues, what the state of the world will be.
Sharyn Alfonsi: Which will be what?
John Hering: We live in a world where we cannot trust the technology that we use.

@_date: 2016-04-18 10:52:23
@_author: hbaker1 
@_subject: [Cryptography] How to get certificates on email server? 
Stupid question: I'm getting a certificate error when attempting to send email.  My email program says that the certification chain can't be verified.
Before I accept this dubious certificate, I'd like to look up this server's certificate myself & check it by hand.
How to do this?  (Either Windows or Linux is fine, since I'm not trying to actually send mail; just check the certificate.)
Thanks for any help.

@_date: 2016-04-19 09:58:56
@_author: Henry Baker 
@_subject: [Cryptography] 'Canary Numbers' for online testing of TRNG's 
FYI --
Canary Numbers: Design for Light-weight Online Testability of True Random Number Generators
Vladimir Rozic and Bohan Yang and Nele Mentens and Ingrid Verbauwhede
Abstract: We introduce the concept of canary numbers, to be used in health tests for true random number generators.  Health tests are essential components of true random number generators because they are used to detect defects and failures of the entropy source.  These tests need to be lightweight, low-latency and highly reliable.  The proposed solution uses canary numbers which are an extra output of the entropy source of lower quality.  This enables an early-warning attack detection before the output of the generator is compromised.  We illustrate the idea with 2 case studies of true random number generators implemented on a Xilinx Spartan-6 FPGA.
Category / Keywords: applications / TRNG, FPGA, Online Test, Lightweight
Contact author: Vladimir Rozic at esat kuleuven be

@_date: 2016-04-19 10:15:33
@_author: Henry Baker 
@_subject: [Cryptography] How to get certificates on email server? 
Wow!  Profuse thanks to all who replied!
Unfortunately, this little episode emphasizes again how brittle the whole CA structure is.
How many of the 1+ billion email customers can be expected to do this kind of debugging?
Since *TRUST* isn't going away anytime soon, we're going to need better & more easily usable tools to test the chain-of-trust (aka MITM chain !).

@_date: 2016-04-19 10:30:08
@_author: Henry Baker 
@_subject: [Cryptography] UK's Investigatory Powers Bill can 'force' decryption 
FYI --
UK's National Crime Agency: Yes, We Could Ask Apple to Remove Encryption
Written by JOSEPH COX  CONTRIBUTOR
April 19, 2016 // 10:38 AM EST
"A tweet from Silkie Carlo, from campaign group Liberty, stated that Farrimond had said the agency could 'force' Apple to remove encryption."
"Farrimond responded with his own tweet, also clarifying that he said 'request.'"
[Ha, ha!  Ignoring such a request will usually result in a 'Ferguson' moment.]
"Elsewhere in the over 250-page bill are sections referring to the removal of 'electronic protection' of data.  This has been widely interpreted by tech companies and civil liberties groups as a legal capability to force firms to strip customer's devices or communications of encryption."
"This position sits at odds with the reality of how many encryption systems work today.  Increasingly, companies are putting encryption keys in the control of individual users, meaning that even the firm typically cannot obtain plain-text data itself."

@_date: 2016-04-19 16:36:38
@_author: Henry Baker 
@_subject: [Cryptography] Canadian Prime Minister Trudeau Explains Quantum 
Canadian Prime Minister Justin Trudeau Explains Quantum Computing Perimeter Institute for Theoretical Physics There's been quite a flap about P.M. Trudeau's attempt to explain QC.
I don't find Trudeau's interest or understanding surprising at all; politicians are in a "superposition" of positions all the time -- e.g., certain U.S. politicians being both for the Iraq war and against it; being for the TPP and against it; being for both $12/hr and $15/hr minimum wage.  Many DoD programs are like Schrodinger's cat -- they can't stand too much public scrutiny, else they may die.
Unless the Fourth Estate holds their feet to the fire, "measures" them and forces a collapse of these superposed states, these politicians can remain in a superposed state for months or years.
"One of the greatest challenges is controlling or removing quantum decoherence ... Currently, some quantum computers require their qubits to be *cooled* to 20 millikelvin in order to prevent significant decoherence." -- Wikipedia
We always suspected the "coolest" politicians of having ice water in their veins; but 20 millikelvin (hydrogen) ice ?  Perhaps we've had QC's with long decoherence time in the form of politicians for hundreds of years; who knew?
What seems to have been lost in this flap is the serious money that is going into QC research.
Apparently, Canada desperately wants to be the birthplace of the first real QC (hint: but not in British Columbia).

@_date: 2016-04-25 20:48:47
@_author: Henry Baker 
@_subject: [Cryptography] Current state of WPA2 security for IoT access ? 
A sysadmin told me within the last week that WPA2 was easily broken
via Aircrack.
I wasn't aware of this; is this really true?
The overall question I'm interested in has to do with IoT wifi access.
If I try to hide a WPA2 access password in an IoT device, someone can
easily steal the (outdoor) IoT device & "waterboard" it until it gives
up the WPA2 password.
So what is the current recommendation w.r.t. IoT devices accessing
WPA2 wireless routers?

@_date: 2016-04-26 09:18:27
@_author: Henry Baker 
@_subject: [Cryptography] Darpa wants a secure messaging app based on 
FYI --
Component: DARPA
Topic  SB162-004
Title: Secure Messaging Platform
Technology Areas: Info Systems
OBJECTIVE: Create a secure messaging and transaction platform that separates the message creation, from the transfer (transport) and reception of the message using a decentralized messaging backbone to allow anyone anywhere the ability to send a secure message or conduct other transactions across multiple channels traceable in a decentralized ledger.
DESCRIPTION: There is a critical DoD need to develop a secure messaging and transaction platform accessible via web browser or standalone native application.  The platform separates the message creation, from the transfer of the message within a secure courier to the reception and decryption of the message. Legacy messaging and backoffice infrastructures, traditionally based on centralized, unencrypted hub-and spoke database architecture, are expensive, inefficient, brittle and subject to cyber attack.  The overhead costs of maintaining such architectures is rising rapidly.  Many organizations unknowingly keep duplicate information and fail to ensure synchronization thus amplifying the potential for data theft and data corruption/rot.  Incorporating a truly transparent mechanism for conducting journaled transactions enables the DoD to leverage its distributed footprint for a reduction in latency of these transactions, their security and their integrity and assurance. The messaging platform will transfer messages via a secure decentralized protocol that will be secured across multiple channels, including but not limited to:
1) Transport protocol,
2) Encryption of messages via various application protocols,
3) Customized blockchain implementation of message deconstruction and reconstruction, and decentralized ledger implementation.
With this messaging platform the business logic of the DoD ecosystem would be mapped onto a network of known entities using distributed ledgers.  By doing this significant portions of the DoD backoffice infrastructure can be decentralized, 'smart documents and contracts' can be instantly and securely sent and received thereby reducing exposure to hackers and reducing needless delays in DoD backoffice correspondance.  As an example, Military Interdepartmental Purchase Requests (MIPR) could be implmented using the secure ledger.  Regulators with access to the ledger could read the correspondance and thus easily verify that a MIPR transaction didnt violate Federal Acquisition Regulations (FAR). The messaging platform would act as the transport for a cyptographically sound record of all transactions whether they be MIPRs, contracts, troop movements or intelligence.  Troops on the ground in denied communications environments would have a way to securely communicate back to HQ and DoD back office executives could rest assured that their logistics system is efficient, timely and safe from hackers.  The benefits are broad and could even be applied to domains such as space.  With crowded skies its important to maintain situational awareness of all satellites and those concerned with space situational awareness/telemetry or air traffic control could instantly share data between nations using a separate but equivalent ledger implementation thus removing questions as to the authenticity and integrity of the data.
PHASE I: Create a specific decentralized messaging platform built on the framework of an existing blockchain framework.  There are several layers of complexity that will be explored in this phase from the messaging platform, to transport protocol, to end user application.  Phase 1 goals include: creating a model for the decentralized messaging platform, experimenting with encryption schemes, evaluating hardware to be used in combination with the messaging platform to provide additional security, and defining the product feature set from the application and platform perspectives and finally, developing a blueprint of the platform architecture mapped to DoD constructs.
PHASE II: Develop, test and evaluate a working prototype with the following features:  Decentralized back end blockchain implementation  Data aggregation, reconstruction  Data transport protocol implementation  End user application implementation (alpha)  Conduct simulated MIPR transactions using the decentralized ledger  Allow transparent regulatory review of DoD legal findings and contracts  Significant reduction in time for regulatory overview of various transactions  Tracking of aircraft or satellites with simulated telemetry or air traffic control data  System Admin and Monitoring tools and engine  Integration of hardware or edge of network hardware components
PHASE III DUAL-USE APPLICATIONS: The DoD requires a secure messaging system that can provide repudiation or deniability, perfect forward and backward secrecy, time to live/self delete for messages, one time eyes only messages, a decentralized infrastructure to be resilient to cyber-attacks, and ease of use for individuals in less than ideal situations.  Based on the outcomes and feedback from Phase 2, Phase 3 will focus on commercialization and full-scale implementation of the platform.  This entails converting the alpha of the end user application into a beta application and increasing user testing and platform monitoring and industrializing the back-end platform in terms of decentralized ledger architecture and blockchain implementation.
1. Hyperledger Project  2. SoK: Secure Messaging  KEYWORDS: email, end-to-end encryption, privacy, security, secure messaging, repudiation, perfect forward secrecy
Technical Points of Contact:
Name: Frank Pound Phone: 571-218-4344 Email: frank.pound at darpa.mil
Buzzwords: decentralized, journaled transactions, cyptographically sound, blockchain, repudiation, deniability, one time.
"Phase 3 will focus on commercialization", but any commercial system will require a back door, thus rendering it worthless for commercialization.

@_date: 2016-04-27 09:51:27
@_author: Henry Baker 
@_subject: [Cryptography] Darpa wants a secure messaging app based on 
Cynical, yes, but...
If perchance the proposer comes up with something interesting, the govt can:
* classify the whole thing
* take over the code
* issue an NSL to keep everyone quiet
* force installation of backdoor
* issue an NSL to keep everyone quiet
Yes, this would be a violation of the spirit of SBIR, which is intended to incentivize commercialization, but good luck suing...
So the only hope is that the project becomes open-source, so that any user can examine all of the source code.

@_date: 2016-04-27 13:54:10
@_author: Henry Baker 
@_subject: [Cryptography] Darpa wants a secure messaging app based on 
"In general, each SBIR agency must make these awards for R/R&D through the following uniform, three-phase process:
"(1) Phase I awards to determine, insofar as possible, the scientific and technical merit and feasibility of ideas that appear to have ***commercial potential.***
"(2) Phase II awards to further develop work from Phase I that meets particular program needs and exhibits potential for ***commercial application.***
"(3) Phase III awards where ***commercial applications*** of SBIR-funded R/R&D are funded by non-Federal sources of capital; or where products, services or further research intended for use by the Federal Government are funded by follow-on non-SBIR Federal Funding Agreements."
"(2) Proposals will be evaluated on a competitive basis.  Agency criteria used to evaluate SBIR proposals must give consideration to the scientific and technical merit and feasibility of the proposal along with its ***potential for commercialization.***  ...
"(3) Agency benchmarks for ***progress towards commercialization.***"
"(3) The SBIR Phase II award decision process requires, among other things, consideration of a proposal's ***commercial potential.***  ***Commercial potential*** includes the potential to transition the technology to private sector applications, Government applications, or Government contractor applications."
"Phase III work is typically oriented towards ***commercialization*** of SBIR research or technology."
SBIR isn't supposed to be used for programs that don't have "commercial potential", because you can't get on the first rung of the SBIR ladder ("Phase I") without "commercial potential".  Now "commercial potential" includes follow-on non-SBIR sales (including classified sales) to the govt, but it's next to impossible to raise investment funds based on govt/classified sales to a single customer.
"(i) commercial application (including testing and evaluation of products, services or technologies for use in technical or ***weapons systems***)"
I'm at a bit of a loss to understand to whom -- other than the govt -- an SBIR company is allowed to sell its SBIR-financed "weapons system".

@_date: 2016-04-28 22:47:02
@_author: Henry Baker 
@_subject: [Cryptography] YouTube ContentID hacked for the good! 
FYI --
Game Critic Uses Brilliant Workaround For YouTube's Copyright Bullshit Patricia Hernandez
Wednesday 5:00pm
Filed to: Jim Sterling
Thank god for Jim Sterling, a game critic whose recent YouTube antics forced YouTubes copyright system to eat itself alive. Heres how he did it.
As you may already know, YouTube has something called Content ID, which is a system that theoretically allows users to identify and manage their videos.
Basically, once a video is online, viewers can put a digital fingerprint on it.  If another YouTube channel uploads a video, and the system believes that the new video has the same digital fingerprint, then the new video gains a Content ID claim.  The owners of the original Content ID can then gain some ownership over the new video, and YouTube allows them to monetize the video for themselves, or sometimes outright block it.
So, Jim Sterling hatched a plan.  He went back through his older videos, and took note of what footage got slammed with a Content ID claim in the past.  He then went ahead and copied that same flagged footage, and stuck it into his new video.  The self-sabotage was intentional: Sterling wanted to fuck with the Content ID system.
I figured every time I talk about Nintendo, Im going to throw in other stuff that gets flagged by Content ID, and just watch the corporations battle it out, Sterling said.  His hope was that by pulling this stunt, he could stop any company from monetizing the video at all, since it wouldnt be clear who really owned the footage in the first place.  And if anybody did manage to monetize the video, theyd probably only get peanuts for it.
The scheme panned out just the way he thought it would, Jim Sterling tells Kotaku. I can confirm it works, Jim Sterling said over email.  Its worked several times before.  WMG tried to monetize the video for the Erasure music, but couldnt because Nintendo and Take-Two had set their ContentID in this particular case to Not Monetized.
ContentID is a database of digital "fingerprints" of snippets of media files.
I'd say that Jim Sterling found a way to include his own middle fingerprint in his new video!

@_date: 2016-04-30 09:00:04
@_author: Henry Baker 
@_subject: [Cryptography] sha1sum speed 
I just run Linux's 'sha1sum' on a number of very large files, and the calculation took significantly longer than I expected.
'sha1sum' is only modestly faster on a very large file than copying the file.
I noticed that
1) the cpu meter wasn't pinned at 100%; and
2) multiple cores weren't being fully utilized.
BTW, I don't care about "SHA1", per se; I could just as easily have used "SHA256" or some other hash function.
A.  Are there HW speedups today for crypto hash functions?
B.  Are there side-channel issues that are slowing down these hash functions?
C.  Are hash function speeds considered important these days?

@_date: 2016-04-30 15:20:44
@_author: Henry Baker 
@_subject: [Cryptography] sha1sum speed 
============================== START ==============================
cached ??
I did say I compared sha1sum with *copying* the file, not just *reading* the file.
Perhaps blast writing a file on some types of storage/filesystems is faster than reading it, but on my machines, writing tends to be somewhat slower than reading, and isn't as overlapped as one might have wished (at least in Linux), so copying tends to be slower than simply reading a file.
I was hoping that some versions of crypto hashing could be done at more-or-less file reading ("line" ?) speed.

@_date: 2016-08-08 07:50:51
@_author: Henry Baker 
@_subject: [Cryptography] BBC to deploy detection vans to snoop on internet 
BBC to deploy detection vans to snoop on internet users
Patrick Foster 6 August 2016  8:24am
The BBC is to spy on internet users in their homes by deploying a new generation of Wi-Fi detection vans to identify those illicitly watching its programmes online.
The Telegraph can disclose that from next month, the BBC vans will fan out across the country capturing information from private Wi-Fi networks in homes to "sniff out" those who have not paid the licence fee.
The corporation has been given legal dispensation to use the new technology, which is typically only available to crime-fighting agencies, to enforce the new requirement that people watching BBC programmes via the iPlayer must have a TV licence.
The disclosure will lead to fears about invasion of privacy and follows years of concern over the heavy-handed approach of the BBC towards those suspected of not paying the licence fee.  However, the BBC insists that its inspectors will not be able to spy on other internet browsing habits of viewers.
The existence of the new strategy emerged in a report carried out by the National Audit Office (NAO).
It shows that TV Licensing, the corporation's licence-fee collection arm, has developed techniques to track those watching television on laptops, tablets, and mobile phones.
The disclosure of the controversial new snooping technique will lay to rest the persistent claims that detector vans are no more than an urban myth designed to intimidate the public into paying the licence fee.
Sir Amyas Morse, the comptroller and auditor general of the NAO, writes in the report: "Detection vans can identify viewing on a non-TV device in the same way that they can detect viewing on a television set.
"BBC staff were able to demonstrate this to my staff in controlled conditions sufficient for us to be confident that they could detect viewing on a range of non-TV devices."
Currently, anyone who watches or records live programming -- online or on television -- needs to buy a 145.50 licence.  But from September 1, those who use the iPlayer only for catch-up viewing will also need to pay the fee, after the BBC successfully lobbied the Government to change the law. Under the Regulation of Investigatory Powers Act, the corporation is entitled to carry out surveillance of suspected licence-fee dodgers.
The BBC confirmed that its newly developed detection techniques had been authorised under the legislation.
While the corporation would not disclose how the new technology works, the report states that the BBC has ruled out combing its own records of computers that have logged into the iPlayer website to hunt down non-paying viewers. Sir Amyas writes in the document: "The BBC rightly acknowledges that this would be an inappropriate invasion of privacy."
Instead, electrical engineering experts said that the most likely explanation for how the BBC would carry out its surveillance was a technique known as "packet sniffing", which involves watching traffic passing over a wireless internet network without hacking into the connection or breaking its encryption.
Researchers at University College London disclosed that they had used a laptop running freely available software to identify Skype internet phone calls passing over encrypted Wi-Fi, without needing to crack the network password.
Dr Miguel Rio, a computer network expert who helped to oversee the doctoral thesis, said that licence-fee inspectors could sit outside a property and view encrypted "packets" of data -- such as their size and the frequency with which they are emitted over the network -- travelling over a home Wi-Fi network.
This would allow them to establish if devices at homes without television licences were indeed accessing BBC programmes online. Dr Rio said: "They actually don't need to decrypt traffic, because they can already see the packets.  They have control over the iPlayer, so they could ensure that it sends packets at a specific size, and match them up.  They could also use directional antennae to ensure they are viewing the Wi-Fi operating within your property."
Privacy campaigners described the developments as "creepy and worrying".
A spokesman for Privacy International, the human rights watchdog, said: "While TV Licensing have long been able to examine the electromagnetic spectrum to watch for and investigate incorrect usage of their services, the revelation that they are potentially developing technology to monitor home Wi-Fi networks is startlingly invasive."
A spokesman for TV Licensing said: "We've caught people watching on a range of devices, but don't give details of detection as we would not want to reveal information helpful to evaders. "Our use of detection is regularly inspected by independent regulators."
The broadcaster included the NAO report in a list of documents that it claimed to have published alongside its annual report last month, but never distributed the review or uploaded it to its website.  It has now been placed online by the public spending watchdog.
'electrical engineering experts said that the most likely explanation for how the BBC would carry out its surveillance was a technique known as "packet sniffing", which involves watching traffic passing over a wireless internet network ***without ... breaking its encryption.***'

@_date: 2016-08-26 21:05:10
@_author: Henry Baker 
@_subject: [Cryptography] "NSA-linked Cisco exploit poses bigger threat 
mail.com>
Which is precisely why I always try to make the point that compiler optimizations
should *never* be "unsafe"; pointer checks and bounds checks *cannot be removed*
until the compiler can mathematically *prove* that these checks are redundant.
Part of your job as a programmer is to help convince the compiler that certain
checks -- that the compiler couldn't prove on its own were redundant -- can
be removed after noticing various "assert" statements/expressions.  Now the
"assert" statements themselves must also be proven to be redundant prior to
eliding their run-time tests, but by sprinkling these "assert" statements
liberally throughout the code, an assertion checked outside of a loop (which
is checked but once) can often allow the compiler to deduce that the checks
*inside the loop* are redundant and can then be removed without sacrificing
Of course, in these days of multi-gigahertz CPU's in which a run-time check
often costs *precisely nothing* because it is performed while the CPU is
waiting for tens or hundreds of cycles for the result of a main memory read,
the silliness of removing bounds checks is even more glaring.
Although the aptitude tests that Microsoft used to hire programmers in the
1980's came too early to be distributed on the Internet (besides, who at
Microsoft in the 1980's knew anything about networking?), these tests were
famous for bit-twiddling and non-bounds-checked loops.  You literally
couldn't get hired at Microsoft in the 1980's if you wrote high quality
Microsoft (and its customers) got what they deserved with incredibly
bug-laden code which later cost multiple billions of dollars to find
and fix these bugs one-by-one.
While hardware engineers have long utilized increased "margins" and
error-correcting codes to reduce the chances of failure in the field,
software "engineers" never embraced such quality-enhancing techniques
until *forced* by hackers who could turn nearly every software bug
into an exploit.
It is ironic to see that the NSA TAO hackers aren't much better at
software engineering than the Microsofties; some recently released
"Equation" code has bounds overflow problems as well as facepalm
encryption failures.

@_date: 2016-08-27 09:00:51
@_author: Henry Baker 
@_subject: [Cryptography] tail recursion in C [was Re: "NSA-linked Cisco 
There are clever ways to do "tail recursion" in C:
Although my paper doesn't provide the particular optimization in the
Gnu C compiler, there is (or used to be!) a switch that tells the Gnu
C compiler that certain calls aren't coming back, so don't bother
emitting any more code.
(Note also that the Intel x86 -- and most likely the x64, as well --
includes a hardware lookaside cache that attempts to avoid memory
references for stack pushes & pops for return addresses.  This cache
will get totally discombobulated if you use x86 stack instructions
for non-nested behavior.  Furthermore, there are some new architectural
"features" that attempt to outlaw non-nested behavior completely, in
order to try to stop "return-oriented programming" (ROP) which is
more-and-more utilized for exploits.)

@_date: 2016-08-29 10:23:00
@_author: Henry Baker 
@_subject: [Cryptography] tail recursion in C [was Re: "NSA-linked Cisco 
Actually, "tail recursion" is equivalent to the lambda calculus axiom "Eta":
(lambda (x) (f x)) => f  (Lisp/Scheme notation for unary functions.)
Axiom Eta is *independent* of the other axioms of the lambda calculus, so *no*, tail recursion is *not* "just an optimization".

@_date: 2016-12-01 09:35:28
@_author: Henry Baker 
@_subject: [Cryptography] Gaslighting ~= power droop == side channel attack 
I was also thinking about 1950's/1960's computers, with their multi-KW motor/generator power supplies -- capable of powering a small home.  Ordinarily, these motor/generators might be available as cheap surplus items, gathering dust in the back of some warehouse, but I seem to recall that these power supplies were the least reliable portions of these early transistor computers.
I did love those wastebasket-sized electrolytic capacitors, tho.
Speaking of power droop:
Argonne National Labs used to temporarily consume some substantial fraction (10-50% ??) of all of the electrical power in Chicago for a few seconds at a time; every household could easily notice every time the accelerator kicked in.  I'm not sure what Argonne would have to do if keeping the operation of their accelerator needed to be kept secret.
BTW, pot is now legal in California, thanks to the Nov election; however, I don't know if you're now allowed to grow your own at home.

@_date: 2016-12-02 07:25:42
@_author: Henry Baker 
@_subject: [Cryptography] Gaslighting ~= power droop == side channel attack 
As usual, the problem isn't with "most people", but with govts.
E.g., so long as genealogy records (often kept by various religious
groups) were used only within families, there wasn't any problem.
But when people start getting rounded up and murdered based on
information stored in these records, "shame" became the least of
their worries.
In certain countries, the knowledge (or lack thereof) of certain
religious texts will get you murdered, as will the preference
for certain colors of Teletubbies.
Due to the power "optimization" in modern LED TV sets, you can
now correlate to near certainty which channel is being watched
based solely on power consumption data.  That data is enough
to get you murdered in quite a few countries around the world
today; countries that show up on every cybersecurity firm's
"best customer" list.
"High Efficiency AC-DC TV Power Solutions: Proposing an
Intelligent LED Backlight Driving Scheme.  Application Report
SLVA74-July 2011"
Thanks to the change in DOJ's Rule 41 yesterday, those same data
are now accessible to the FBI for everyone on Earth, and the FBI
can use these same data to put you in prison for 20 years.
And -- thanks to the mass gathering of these data by utility
companies -- the FBI only needs to hit a few keys on their
computers to access all of this information.
If "normal, boring" means "the state of most people", then
"normal, boring" can also be "dead", since most people are
now dead, and dead is about as boring as your can get.

@_date: 2016-12-15 10:37:55
@_author: Henry Baker 
@_subject: [Cryptography] Photojournalists & filmmakers want cameras to be 
FYI --
Photojournalists and filmmakers call on camera makers to include encryption
Filmmakers and photojournalists have their cameras and footage seized 'at a rate that is literally too high to count,' according to the Freedom of the Press Foundation.
By Zack Whittaker for Zero Day | December 14, 2016 -- 14:08 GMT (06:08 PST) | Topic: Security
Some of the world's leading photojournalists and filmmakers are calling on the manufacturers of the cameras they use to add encryption to their products, as the number of threats they face from having their devices seized is "literally too high to count."
Over 150 documentary makers and reporters signed an open letter by the Freedom of the Press Foundation, asking for camera makers -- including Nikon, Sony, and Canon -- to ensure that their work is protected while often "attempting to uncover wrongdoing in the interests of justice."
"Documentary filmmakers and photojournalists work in some of the most dangerous parts of the world, often risking their lives to get footage of newsworthy events to the public," said Trevor Timm, the foundation's executive director.
But, he said, "they face a variety of threats from border security guards, local police, intelligence agents, terrorists, and criminals when attempting to safely return their footage so that it can be edited and published."
Reporters nowadays, much like the rest of the world, have tools that allow secure communication, such as Signal and WhatsApp, which come with end-to-end encrypted messaging, as well as secure storage on their devices, including iPhones and a number of Android devices, thanks in part to the Edward Snowden revelations, which exposed weaknesses in a variety of devices and services, against intrusive government surveillance.
But the filmmakers say that camera security has lagged behind the rest of the industry, leaving their work "dangerously vulnerable."
"We face a critical gap between the moment we shoot our footage and the first opportunity to get that footage onto more secure devices," reads the open letter. "As filmmakers and photojournalists who value our own safety and the safety of our sources and subjects, we would seek out and buy cameras that come with built-in encryption. Adding these data security features to your product line would give your company a significant competitive advantage over other camera manufacturers, none of whom currently offer this feature."
Nikon offered a brief statement, but it did not say if it would include encryption as part of its future camera offerings. The company said: "We are constantly listening to the needs of an evolving market and considering photographer feedback, and we will continue to evaluate product features to best suit the needs of our users."
Spokespeople for Sony and Canon did not respond to a request for comment at the time of writing.

@_date: 2016-12-17 10:08:23
@_author: Henry Baker 
@_subject: [Cryptography] DNSChanger in ad malware attacks home routers 
FYI --
Home routers under attack in ongoing malvertisement blitz
DNSChanger causes network computers to visit fraudulent domains.
Dan Goodin - Dec 16, 2016 9:42 pm UTC
As you read these words, malicious ads on legitimate websites are targeting visitors with malware.  But that malware doesn't infect their computers, researchers said.  Instead, it causes unsecured routers to connect to fraudulent domains.
... they serve a fake ad that hides exploit code in the metadata of a PNG image.  The code, in turn, causes the visitor to connect to a page hosting DNSChanger, ... the malicious site serves a second image concealed with the router exploit code.
DNSChanger uses a set of real-time communications protocols known as webRTC to send so-called STUN server requests used in VoIP communications.  The exploit is ultimately able to funnel code through the Chrome browser for Windows and Android to reach the network router.  The attack then compares the accessed router against 166 fingerprints of known vulnerable router firmware images.
DNS servers translate domain names such as arstechnica.com into IP addresses such as 50.31.151.33, which computers need to find and access the site.  By changing router settings to use an attacker-controlled server, DNSChanger can cause most, if not all, connected computers to connect to impostor sites that look just like the real ones.  So far, the malicious DNS server used by DNSChanger appears to be falsifying IP addresses to divert traffic from large ad agencies in favor of ad networks known as Fogzy and TrafficBroker.  But the server could be updated at any time to falsify lookups for Gmail.com, bankofamerica.com, or any other site.  In such a scenario, fortunately, HTTPS protections would flag the impostor.
My (hbaker's) comments:
While this attack somehow modifies the home router to change the way it handles DNS, it isn't clear whether the problem can be solved through a better DNS system.
Also, I would imagine that browsers configured to somehow handle their own DNS queries should be able to bypass the router's own settings.  Also, any computer which connects to the router but ignores the router's DHCP DNS recommendation should also be ok, is this correct?

@_date: 2016-12-19 09:06:26
@_author: Henry Baker 
@_subject: [Cryptography] Photojournalists & filmmakers want cameras, 
mail.com>
But public key encryption provides another option: encrypt the pix with someone's *public key*; the *private key* is unknown to the photographer.
So far as the photographer is concerned, the pix storage is a black hole, which can only be entered by means of the private key.
Yes, the storage can be destroyed (if it can be found); thus, it would be better to transmit it in real time -- e.g., ACLU's "Mobile Justice" app for recording police activities.
(I don't know if ACLU's "Mobile Justice" app encrypts or not, nor whether it uses PKI if it does encrypt.)

@_date: 2016-12-19 09:27:38
@_author: Henry Baker 
@_subject: [Cryptography] TR-069 & firewalls 
Is there any way to firewall the TR-069 protocol?
My DSL ISP uses TR-069, but their router also allows me to fiddle with the firewall; could I use the firewall to deny TR-069 access?

@_date: 2016-12-19 10:53:16
@_author: Henry Baker 
@_subject: [Cryptography] TV set power correlates to TV channel? 
I apologize; I thought this particular TI part did what I suggested.
Here's a better reference (note the date: November, 2009):
The luminance for LCD TVs can now be controlled spatially as well as temporally, especially with the introduction of LEDs as a backlighting source.  By tailoring the backlight to generate light only at the time and location where is it actually needed, image contrast can be improved, and at the same time less power is consumed.  This technique is frequently referred to as "dynamic backlighting" or "adaptive dimming" and requires special driving electronics and algorithms to achieve an optimal system performance.
Two basic approaches toward dimming, which can be used with either CCFLs or LEDs, are global dimming, a methodology in which the entire backlight is dimmed by a single factor in each frame, and local dimming, in which regions within a frame can be dimmed separately.  For global dimming, the luminance of a backlight is modulated with a dimming algorithm, *** relative to the video content ***
Because there is no control over the luminance in the spatial domain, the global dimming technology is sometimes called 0D dimming
In local dimming, the backlight comprises a number of small 2-D segments, each having a luminance that can be modulated
Local color dimming is an approach toward a more power-effective RGB-LED solution. This technology involves executing the local-dimming algorithm independently for the red, green, and blue primary colors because the light sources are red, green, and blue LEDs with their luminance controllable per color and per region

@_date: 2016-12-20 06:29:26
@_author: Henry Baker 
@_subject: [Cryptography] Crypto Bug Tool site set up incorrectly 
FYI --
"Your connection is not secure"
"The owner of  has configured their website improperly.  To protect your information from being stolen, Tor Browser has not connected to this website."
Google has released a new set of tests it uses to probe cryptographic libraries for vulnerabilities to known attacks.  The tests can be used against most kinds of crypto algorithms and the company already has found 40 new weaknesses in existing algorithms.  The tests are called Project Wycheproof, and Google's engineers designed them to help developers implement crypto libraries without having to become experts.
I'd find this site more believable if their own certificates were configured properly.
Chrome, Firefox and Tor Browser all tell me that " is not configured properly.

@_date: 2016-12-22 09:03:44
@_author: Henry Baker 
@_subject: [Cryptography] Encrypted app Signal uses Google to bypass censorship 
FYI --
Encrypted messaging app Signal uses Google to bypass censorship
The app routes requests through Google's servers to make it harder for governments to block them
By Lucian Constantin
Romania Correspondent, IDG News Service Dec 22, 2016 7:37 AM PT Developers of the popular Signal secure messaging app have started to use Googles domain as a front to hide traffic to their service and to sidestep blocking attempts.
Bypassing online censorship in countries where internet access is controlled by the government can be very hard for users. It typically requires the use of virtual private networking (VPN) services or complex solutions like Tor, which can be banned too.
Open Whisper Systems, the company that develops Signala free, open-source appfaced this problem recently when access to its service started being censored in Egypt and the United Arab Emirates. Some users reported that VPNs, Apples FaceTime and other voice-over-IP apps were also being blocked.
The solution from Signals developers was to implement a censorship circumvention technique known as domain fronting that was described in a 2015 paper by researchers from University of California, Berkeley, the Brave New Software project and Psiphon.
The technique involves sending requests to a front domain and using the HTTP Host header to trigger a redirect to a different domain.  If done over HTTPS, such redirection would be invisible to someone monitoring the traffic, because the HTTP Host header is sent after the HTTPS connection is negotiated and is therefore part of the encrypted traffic.
In an HTTPS request, the destination domain name appears in three relevant places: in the DNS query, in the TLS Server Name Indication (SNI) extension and in the HTTP Host header, the researchers said in their paper.  Ordinarily, the same domain name appears in all three places.  In a domain-fronted request, however, the DNS query and SNI carry one name (the front domain), while the HTTP Host header, hidden from the censor by HTTPS encryption, carries another (the covert, forbidden destination).
Their research revealed that many cloud service providers and content delivery networks allow HTTP host header redirection, including Google, Amazon Cloudfront, Amazon S3, Azure, CloudFlare, Fastly and Akamai.  However, most of them only allow it for domains that belong to their customers, so one must become a customer in order to use this technique.
Google, for example, allows redirection through the HTTP host header from google.com to appspot.com.  This domain is used by Google App Engine, a service that allows users to create and host web applications on Googles cloud platform.
This means that someone can create a simple reflector script, host it on Google App Engine and then use the HTTP host header trick to hide its location from censors.  Someone monitoring user traffic will only see HTTPS requests going to  but those requests will reach the reflector script on Google App Engine and will be forwarded to a hidden destination.
With todays release, domain fronting is enabled for Signal users who have a phone number with a country code from Egypt or the UAE, Open Whisper Systems founder Moxie Marlinspike said Wednesday in a blog post.  When those users send a Signal message, it will look like a normal HTTPS request to   To block Signal messages, these countries would also have to block all of google.com.
Even if the censors decide to ban Google, the domain fronting implementation can be expanded to use other large-scale services as domain fronts.  If this happens, enforcing a ban on Signal would be the equivalent of blocking a very large portion of the internet.
The anti-censorship feature is currently present in the latest version of Signal for Android.  Its also included in a beta version of the app for iOS that will be released in production soon.
The developers also plan future improvements that will allow the app to detect censorship automatically and switch to domain fronting even if the user has a phone number from a country where censorship is not normally present.  This is intended to cover those cases where users travel to other countries where the app is blocked.
Signal is considered by security experts as one of the most secure messaging services around.  Its open-source end-to-end encryption protocol has also been adopted by other popular chat apps like Facebook Messenger and WhatsApp.
Lucian Constantin is an IDG News Service correspondent.  He writes about information security, privacy, and data protection.

@_date: 2016-12-22 09:57:38
@_author: Henry Baker 
@_subject: [Cryptography] NIST Request for Public-Key Post-Quantum Crypto Algs 
FYI --
Announcing Request for Nominations for Public-Key Post-Quantum Cryptographic Algorithms
A Notice by the National Institute of Standards and Technology on 12/20/2016
This notice solicits nominations from any interested party for candidate algorithms to be considered for public-key post-quantum standards.  The submission requirements and the minimum acceptability requirements of a complete and proper candidate algorithm submission, as well as the evaluation criteria that will be used to appraise the candidate algorithms, can be found at  pqcrypto.
Proposals must be received by November 30, 2017. Further details are available at  pqcrypto.

@_date: 2016-12-31 08:51:47
@_author: Henry Baker 
@_subject: [Cryptography] Smart electricity meters can be dangerously insecure, 
============================== START ==============================
FYI --
Smart electricity meters can be dangerously insecure, warns expert
Hackers can cause fraud, explosions and house fires, and utility companies should do more to protect consumers, conference told
Alex Hern in Hamburg
Thursday 29 December 2016 14.51 GMT
Last modified on Friday 30 December 2016 13.35 GMT
Smart electricity meters, of which there are more than 100m installed around the world, are frequently "dangerously insecure", a security expert has said.
The lack of security in the smart utilities raises the prospect of a single line of malicious code cutting power to a home or even causing a catastrophic overload leading to exploding meters or house fires, according to Netanel Rubin, co-founder of the security firm Vaultra.
"Reclaim your home," Rubin told a conference of hackers and security experts, "or someone else will."
If a hacker took control of a smart meter they would be able to know "exactly when and how much electricity you're using", Rubin told the 33rd Chaos Communications Congress in Hamburg.  An attacker could also see whether a home had any expensive electronics.
"He can do billing fraud, setting your bill to whatever he likes ...  The scary thing is if you think about the power they have over your electricity.  He will have power over all of your smart devices connected to the electricity.  This will have more severe consequences: imagine you woke up to find you'd been robbed by a burglar who didn't have to break in.
"But even if you don't have smart devices, you are still at risk.  An attacker who controls the meter also controls the meter's software, allowing him to cause it to literally explode."
Rubin said many of the warnings were not hypothetical.  In 2009 Puerto Rican smart meters were hacked en masse, leading to widespread billing fraud, and in 2015 a house fire in Ontario was traced back to a faulty smart meter, although hacking was not implicated in that.
The problems at the heart of the insecurity stem from outdated protocols, half-hearted implementations and weak design principles.  While the physical security of smart meters is strong -- "trust me, I tried" to hack in that way, Rubin said -- the wireless protocols many of them use are problematic.
To communicate with the utility company, most smart meters use GSM, the 2G mobile standard.  That has a fairly well-known weakness whereby an attacker with a fake mobile tower can cause devices to "hand over" to the fake version from the real tower, simply by providing a strong signal.  In GSM, devices have to authenticate with towers, but not the other way round, allowing the fake mast to send its own commands to the meter.
Worse still, said Rubin, all the meters from one utility used the same hardcoded credentials.  "If an attacker gains access to one meter, it gains access to them all.  It is the one key to rule them all."
Inside the home, too, the communications are rendered insecure by outdated standards and bad implementation.  Almost all smart meters use the Zigbee standard to speak to other smart devices in the home.
Zigbee, which dates from 2003, is a popular home automation standard, used for controlling everything from lightbulbs to air conditioners.  But it is so convoluted, due to the vast array of devices supported, that it is almost better to think of it as 15 different standards, each of which vendors can choose to implement as they see fit.
"This unique situation is so difficult to implement, venders actually choose what they want to implement.  And when they choose what to support, they more often than not skip security," Rubin said.
Other weak security decisions made by vendors include:
* Encryption keys derived from short (often just six-character) device names.
* Pairing standards with no authentication required, allowing an attacker to simply ask the smart meter to join the network and receive keys in return.
* Hardcoded credentials, allowing administrator access with passwords as simple and guessable as the vendor's name.
* Code simplified to work on low-power devices skipping important checks, allowing nothing more than a long communication to crash the device.
"These security problems are not going to just go away," Rubin said.  "On the contrary, we are going to see a sharp increase in hacking attempts.  Yet most utilities are not even monitoring their network, let alone the smart meters.  Utilities have to understand that with great power comes great responsibility."
Smart meters come with benefits, allowing utilities to more efficiently allocate energy production, and enabling micro-generation that can boost the uptake of renewable energy.  For those reasons and more, the European Union has a goal of replacing 80% of meters with smart meters by 2020.
A spokesperson for the UK government's department of Business, Energy and Industrial Strategy said: "Robust security controls are in place across the end to end smart metering system and all devices must be independently assessed by an expert security organisation, irrespective of their country of origin."
frauds, explosions and fires, Oh No!
Why on Earth must everything be "smart" -- aka "spying" -- aka "hackable" ?
What really galls me is the fact that the Public Utilities Commissions (PUC's) can force use all to pay for this crap, so these idiots at the electric utilities can put another notch in their resume belts (i.e., something else that I have failed at: "cybersecurity").

@_date: 2016-02-02 17:43:51
@_author: Henry Baker 
@_subject: [Cryptography] DH non-prime kills "socat" command security 
For the past year, the Linux command "socat" has been assuming that the
following number is prime; thus breaking its crypto security.
14331936439490594261714896808578599103914668374026899657956682701558096 91247024938331090743438798945866534651922222519090748320381515854480347 31101690454685781999248641772509287801359980318348021809541131200479989 22079392594151856814372197299325182316616493333479662500817485143037796 6394594186901123322297453 isn't prime, and Maxima's primep function sez so.
The number above is divisible by 271 and 13,597, but primep sez that
even after dividing out these two factors, the 1002-bit result still isn't prime.
Does anyone have a fast factoring machine for 1000-bit numbers?
Socat slams backdoor, sparks thrilling whodunit
Year-old bug ruined crypto

@_date: 2016-02-04 18:30:45
@_author: Henry Baker 
@_subject: [Cryptography] DH non-prime kills "socat" command security 
The purported prime in the socat news story doesn't pass any of the simple primality tests of the type that you describe, so it is obvious to include such primality tests in the QA for these socat algorithms.  After factoring out the two small factors 271 and 13,597, the resulting 1002-bit number *still doesn't pass* simple primality tests, but I wasn't able to further factor it in 15 minutes on my really old, really slow laptop.  So someone was criminally stupid, or else purposely installed this non-prime backdoor.
There is an outstanding problem: if we all use the same primes, large nation-states can build log (rainbow-like) tables for these primes; if we use different primes, we then have to prove to our correspondent that the "prime" we propose is really prime.  Generating such primes and generating such easily-checkable proofs appears to take too much time for normal HTTPS ecommerce.

@_date: 2016-02-06 06:29:01
@_author: Henry Baker 
@_subject: [Cryptography] New block cipher competition 
FYI --
B,TMSR~ Block Cipher Competition
Thursday, 04 February, Year 8 d.Tr. | Author: Mircea Popescu
The Most Serene Republic, reunited in congress, decided :
That all presently known block ciphers suck ;
That an actually useful block cipher is required for our own purposes; That we will consider proposals from barbarians as well as citizens. Consequently, you are cordially invited to submit a proposal for a block cipher that : Works on block sizes of 1 kbytes, 4 kbytes, 16 kbytes and 64 kbytes. Bonus points for ciphers that work on an arbitrary block size. Use a 64 kbyte key. Fits In Head
Items which come with a proof of hardness, as well as items that eschew basic arithmetic operations as implemented by computers will be particularly favoured. While we will consider purely theoretical proposals, items which come with sample implementation and assorted tests will be preferred.

@_date: 2016-02-11 12:59:38
@_author: Henry Baker 
@_subject: [Cryptography] Proof that the NSA does not have a quantum 
mail.com>
I think that someone at NSA invented Bitcoin to supercharge the development of fast encryption/decryption chips.
New forms of QC-resistant XXXcoins will be developed for similar reasons.
How to leverage NSA's research $$$$$$$$$$$'s.
It seems to have worked!
Recall that "miners" get paid in Bitcoin, but chip developers get paid in real $$$.
Algorithm/SW developers don't need to get paid at all, because they do it for the love of computer science, society and world peace.

@_date: 2016-02-14 07:19:20
@_author: Henry Baker 
@_subject: [Cryptography] XOR linked list & crypto 
A famous XOR hack (Knuth??) enables traversing a list in either direction:
Of course, you need *two* successive pointers in order to access the list.
"Features" "Given only one list item, one cannot immediately obtain the addresses of the other elements of the list"
"Drawbacks" "The pointers will be unreadable if one isn't traversing the list"
Yes, this inability is used as both a "feature" and as a "drawback".
Q: Have these features/drawbacks been used in any encryption scheme?
Thanks for any pointers(!) or references(!) to published work.

@_date: 2016-02-14 19:36:42
@_author: Henry Baker 
@_subject: [Cryptography] Cryptomes searing critique of Snowden Inc. 
Can someone please post a link to the .mp3 or .mp4 of this interview?

@_date: 2016-02-15 09:47:44
@_author: Henry Baker 
@_subject: [Cryptography] XOR linked list & crypto 
Thanks very much, Jerry; this idea sounds pretty interesting.  Can you recall anything else that might help me Google this paper?
Yes, I've heard rumors of such things...  ;-)

@_date: 2016-02-15 19:00:30
@_author: Henry Baker 
@_subject: [Cryptography] XOR linked list & crypto 
More security through obscurity, no?
ASLR, anyone?
MSFT's now randomizing malloc, I seem to recall.

@_date: 2016-02-16 21:28:51
@_author: Henry Baker 
@_subject: [Cryptography] Apple ordered to decrypt cellphone 
FYI -- Below is the OCR'd version of today's court
order to Apple to decrypt a cellphone.
EILEEN M. DECKER
United States Attorney
PATRICIA A. DONAHUE
Assistant United States Attorney
Chief, National Security Division
TRACY L. WILKISON (California Bar No. 184948)
Assistant United States Attorney
Chief, Cyber and Intellectual Property Crimes Section
ALLEN W. CHIU (California Bar No. 240516)
Assistant United States Attorney
Terrorism and Export Crimes Section
1500 United States Courthouse
312 North Spring Street
Los Angeles, California 90012
Telephqne: (213) 894-0622/2435
Facsimile: (213) 894-8601
Email: Tracy.wilkison at usdoj.gov Allen.Chiu at usdoj.gov
Attorneys for Applicant
UNITED STATES OF AMERICA
UNITED STATES DISTRICT COURT
FOR THE CENTRAL DISTRICT OF CALIFORNIA
IN THE MATTER OF THE SEARCH OF     No. ED l5-045lM
AN APPLE IPHONE SEIZED DURING
THE EXECUTION OF A SEARCH          ORDER COMPELLING APPLE,
WARRANT ON A BLACK LEXUS 1S300,    INC. TO ASSIST AGENTS IN SEARCH
CALIFORNIA LICENSE PLATE 35KGD203
     This matter is before the Court pursuant to an application
pursuant to the All Writs Act, 28 U.S.C.  1651, by Assistant United
States Attorneys Tracy Wilkison and Allen Chiu, requesting an order
directing Apple Inc. ("Apple") to assist law enforcement agents in
enabling the search of a digital device seized in the course of a
previously issued search warrant in this matter.
     For good cause shown, IT IS HEREBY ORDERED that:
     1. Apple shall assist in enabling the search of a cellular
telephone, Apple make: iPhone SC, Model: Al532, P/N:MGFG2LL/A,
S/N:FFMNQ3MTG2DJ, IMEI:35882005230l412, on the Verizon Network, (the
"SUBJECT DEVICE") pursuant to a warrant of this Court by providing
reasonable technical assistance to assist law enforcement agents in
obtaining access to the data on the SUBJECT DEVICE.
     2. Apple's reasonable technical assistance shall accomplish
the following three important functions: (1) it will bypass or
disable the auto-erase function whether or not it has been enabled;
(2) it will enable the FBI to submit passcodes to the SUBJECT DEVICE
for testing electronically via the physical device port, Bluetooth,
Wi-Fi, or other protocol available on the SUBJECT DEVICE; and (3) it
will ensure that when the FBI submits passcodes to the SUBJECT
DEVICE, software running on the device will not purposefully
introduce any additional delay between passcode attempts beyond what
is incurred by Apple hardware.
     3. Apple's reasonable technical assistance may include, but is
not limited to: providing the FBI with a signed iphone Software
file, recovery bundle, or other Software Image File ("SIF") that can
be loaded onto the SUBJECT DEVICE. The SIF will load and run from
Random Access Memory ("RAW') and will not modify the iOS on the
actual phone, the user data partition or system partition on the
device's flash memory. The SIF will be coded by Apple with a unique
identifier of the phone so that the SIF would only load and execute
on the SUBJECT DEVICE. The SIF will be loaded via Device Firmware
Upgrade ("DFU") mode, recovery mode, or other applicable mode
available to the FBI. Once active on the SUBJECT DEVICE, the SIF
will accomplish the three functions specified in paragraph 2. The
SIF will be loaded on the SUBJECT DEVICE at either a government
facility, or alternatively, at an Apple facility; if the latter,
Apple shall provide the government with remote access to the SUBJECT
DEVICE through a computer allowing the government to conduct passcode
recovery analysis.
     4. If Apple determines that it can achieve the three functions
stated above in paragraph 2, as well as the functionality set forth
in paragraph 3, using an alternate technological means from that
recommended by the government, and the government concurs, Apple may
comply with this Order in that way.
     5. Apple shall advise the government of the reasonable cost of
providing this service.
     6. Although Apple shall make reasonable efforts to maintain
the integrity of data on the SUBJECT DEVICE, Apple shall not be
required to maintain copies of any user data as a result of the
assistance ordered herein. All evidence preservation shall remain
the responsibility of law enforcement agents.
     7. To the extent that Apple believes that compliance with this
Order would be unreasonably burdensome, it may make an application to
this Court for relief within five business days of receipt of the
DATED:  FEB 16 2016                        SHERI PYM
                                  UNITED STATES MAGISTRATE JUDGE

@_date: 2016-02-17 06:47:25
@_author: Henry Baker 
@_subject: [Cryptography] Apple's response to DOJ re encryption 
FYI -- February 16, 2016 A Message to Our Customers
The United States government has demanded that Apple take an unprecedented step which threatens the security of our customers.  We oppose this order, which has implications far beyond the legal case at hand. This moment calls for public discussion, and we want our customers and people around the country to understand what is at stake.
The Need for Encryption
Smartphones, led by iPhone, have become an essential part of our lives.  People use them to store an incredible amount of personal information, from our private conversations to our photos, our music, our notes, our calendars and contacts, our financial information and health data, even where we have been and where we are going.
All that information needs to be protected from hackers and criminals who want to access it, steal it, and use it without our knowledge or permission.  Customers expect Apple and other technology companies to do everything in our power to protect their personal information, and at Apple we are deeply committed to safeguarding their data.
Compromising the security of our personal information can ultimately put our personal safety at risk.  That is why encryption has become so important to all of us.
For many years, we have used encryption to protect our customers' personal data because we believe it's the only way to keep their information safe.  We have even put that data out of our own reach, because we believe the contents of your iPhone are none of our business.
The San Bernardino Case
We were shocked and outraged by the deadly act of terrorism in San Bernardino last December.  We mourn the loss of life and want justice for all those whose lives were affected.  The FBI asked us for help in the days following the attack, and we have worked hard to support the government's efforts to solve this horrible crime.  We have no sympathy for terrorists.
When the FBI has requested data that's in our possession, we have provided it.  Apple complies with valid subpoenas and search warrants, as we have in the San Bernardino case.  We have also made Apple engineers available to advise the FBI, and we've offered our best ideas on a number of investigative options at their disposal.
We have great respect for the professionals at the FBI, and we believe their intentions are good.  Up to this point, we have done everything that is both within our power and within the law to help them.  But now the U.S. government has asked us for something we simply do not have, and something we consider too dangerous to create.  They have asked us to build a backdoor to the iPhone.
Specifically, the FBI wants us to make a new version of the iPhone operating system, circumventing several important security features, and install it on an iPhone recovered during the investigation.  In the wrong hands, this software  which does not exist today  would have the potential to unlock any iPhone in someone's physical possession.
The FBI may use different words to describe this tool, but make no mistake: Building a version of iOS that bypasses security in this way would undeniably create a backdoor.  And while the government may argue that its use would be limited to this case, there is no way to guarantee such control.
The Threat to Data Security
Some would argue that building a backdoor for just one iPhone is a simple, clean-cut solution.  But it ignores both the basics of digital security and the significance of what the government is demanding in this case.
In today's digital world, the key to an encrypted system is a piece of information that unlocks the data, and it is only as secure as the protections around it.  Once the information is known, or a way to bypass the code is revealed, the encryption can be defeated by anyone with that knowledge.
The government suggests this tool could only be used once, on one phone.  But that's simply not true.  Once created, the technique could be used over and over again, on any number of devices.  In the physical world, it would be the equivalent of a master key, capable of opening hundreds of millions of locks  from restaurants and banks to stores and homes. No reasonable person would find that acceptable.
The government is asking Apple to hack our own users and undermine decades of security advancements that protect our customers  including tens of millions of American citizens  from sophisticated hackers and cybercriminals.  The same engineers who built strong encryption into the iPhone to protect our users would, ironically, be ordered to weaken those protections and make our users less safe.
We can find no precedent for an American company being forced to expose its customers to a greater risk of attack.  For years, cryptologists and national security experts have been warning against weakening encryption.  Doing so would hurt only the well-meaning and law-abiding citizens who rely on companies like Apple to protect their data.  Criminals and bad actors will still encrypt, using tools that are readily available to them.
A Dangerous Precedent
Rather than asking for legislative action through Congress, the FBI is proposing an unprecedented use of the All Writs Act of 1789 to justify an expansion of its authority.
The government would have us remove security features and add new capabilities to the operating system, allowing a passcode to be input electronically.  This would make it easier to unlock an iPhone by brute force, trying thousands or millions of combinations with the speed of a modern computer.
The implications of the government's demands are chilling.  If the government can use the All Writs Act to make it easier to unlock your iPhone, it would have the power to reach into anyone's device to capture their data.  The government could extend this breach of privacy and demand that Apple build surveillance software to intercept your messages, access your health records or financial data, track your location, or even access your phone's microphone or camera without your knowledge.
Opposing this order is not something we take lightly.  We feel we must speak up in the face of what we see as an overreach by the U.S. government.
We are challenging the FBI's demands with the deepest respect for American democracy and a love of our country.  We believe it would be in the best interest of everyone to step back and consider the implications.
While we believe the FBI's intentions are good, it would be wrong for the government to force us to build a backdoor into our products.  And ultimately, we fear that this demand would undermine the very freedoms and liberty our government is meant to protect.
Tim Cook

@_date: 2016-02-18 08:32:46
@_author: Henry Baker 
@_subject: [Cryptography] Hope Apple Fights This! 
The whole point of this DOJ "security theater" is to publicly shame Apple, even though the chances that this iPhone contains any interesting info are zero%.  Farook's OPSEC was good enough to destroy his other e-stuff; his *work-issued* cellphone he probably considered compromised from the get-go.
If the FBI were truly serious, it would have issued an NSL and unlocked this iPhone in secret; so the FBI/DOJ motives here are all too clear.

@_date: 2016-02-18 08:43:21
@_author: Henry Baker 
@_subject: [Cryptography] Apple Store protest in SF: "Hands Up! Don't Root!" 
FYI --
"this Wednesday evening an emergency gathering in support of Apple formed outside the corporation's Union Square store in the city"
"After Tim Cook gave the FBI the finger when asked to help unlock a mass murderer's iPhone, fanbois are planning to hold rallies outside Apple stores to support the iGiant."
"The string of demonstrations will kick off on February 23 across the US, it's hoped."

@_date: 2016-02-19 14:19:35
@_author: Henry Baker 
@_subject: [Cryptography] Apple 3rd Party dilemma 
Apple got themselves into this mess, because Apple wants to control the customer's phone.
If Apple gave up the ability to update the customer's phone w/o the customer's explicit consent, then they'd be out of this mess.
(Note that MSFT's Win10 shenanigans make MSFT a much easier target for DOJ/FBI.)
The elephant in the room is the "Third Party Doctrine", which basically provides the govt "most favored nation status": if you as a customer provide your data to *any* third party, then the govt will claim access, as well.  (I believe that this is the modern version of the old "Lord of the Manor" privilege, which allowed the Lord of the Manor access to any maid in his territory who wishes to marry; for this reason, I suggest that the 3rd Party Doctrine be renamed the "Government Rape Doctrine", which might help to speed its demise.)
Either the Supremes have to kill the 3rd party doctrine, or the data has to remain strongly encrypted in such a way that no 3rd party can gain access.  (Homomorphic encryption, anyone?)
Doesn't anyone else think that the "TPM" ("Trusted Platform Module") is completely insane, since it doesn't trust the computer's own owner?
Computer & phone customers have to DEMAND that they OWN their own devices.
If this means that devices occasionally commit suicide ("apoptosis") in order to protect the user's information, then so be it.  The good news is that IoT chips are getting really cheap.

@_date: 2016-02-19 22:42:10
@_author: Henry Baker 
@_subject: [Cryptography] Apple 3rd Party dilemma 
You might want to ask Lavabit's Ladar Levison how he felt.  The interviews I've heard sound one heck of a lot like virtual rape.
The Lavabit NSL also asked for the keys to Lavabit's whole kingdom -- not a targeted search of a particular customer.  So much for the 4th Amendment rights of all of the rest of Lavabit's customers.

@_date: 2016-02-20 12:43:22
@_author: Henry Baker 
@_subject: [Cryptography] OCR'd DOJ Motion to Compel Apple 
FYI -- OCR'd version of DOJ's motion to compel Apple.  I cleaned it up a little, but there are almost certainly additional errors, so double check everything with the pdf file.
Exhibit 1 is just Tim Cook's letter:
EILEEN M. DECKER
United States Attorney
PATRICIA A. DONAHUE
Assistant United States Attorney
Chief, National Security Division
TRACY L. WILKISON (California Bar No. 184948)
Assistant United States Attorney
Chief, Cyber and Intellectual Property Crimes Section
ALLEN W. CHIU (California Bar No. 240516)
Assistant United States Attorney
Terrorism and Export Crimes Section
1500 United States Courthouse
312 North Spring Street
Los Angeles, California 90012
Telephone:       (213) 894-0622/2435
Facsimile:       (213) 894-8601
Email: Tracy.Wilkison at usdoj.gov
       Allen.Chiu at usdoj.gov
Attorneys for Applicant
UNITED STATES OF AMERICA
UNITED STATES DISTRICT COURT
FOR THE CENTRAL DISTRICT OF CALIFORNIA
IN THE MATTER OF THE SEARCH OF
AN APPLE IPHONE SEIZED DURING
THE EXECUTION OF A SEARCH
WARRANT ON A BLACK LEXUS IS300,
CALIFORNIA LICENSE PLATE
ED No. CM 16-10 (SP)
GOVERNMENT'S MOTION TO COMPEL
APPLE INC. TO COMPLY WITH THIS
COURT'S FEBRUARY 16, 2016 ORDER
COMPELLING ASSISTANCE IN SEARCH
Hearing Date: March 22, 2016
Hearing Time: 1:00 p.m.
Location; Courtroom of the Hon.
Sheri Pym
The United States of America, by and through its counsel of
record, the United States Attorney for the Central District of
California, and Assistant United States Attorneys Tracy L. Wilkison
and Allen W. Chiu, hereby files its Motion to Compel Apple Inc.
("Apple") to Comply with this Court's February 16, 2016 Order
Compelling Apple To Assist Agents In Its Search.
This Motion is based upon the attached memorandum of points and
authorities, the attached exhibit, the files and records in this case
including the application and order compelling Apple to assist the
FBI and the underlying search warrant, and such further evidence and
argument as the Court may permit.
Dated: February 19, 2016 Respectfully submitted,
                         EILEEN M. DECKER
                         United States Attorney
                         PATRICIA A. DONAHUE
                         Assistant United States Attorney
                         Chief, National Security Division
                         TRACY L. WILKISON
                         ALLEN W. CHIU
                         Assistant United States Attorneys
                         Attorneys for Applicant
                         UNITED STATES OF ANERICA
TABLE OF CONTENTS
DESCRIPTION                                                       PAGE
TABLE OF AUTHORITIES                                               ii
MEMORANDUM OF POINTS AND AUTHORITIES                                1
I.  INTRODUCTION                                                    1
II.  STATEMENT OF FACTS                                             3
III.  THE COURT SHOULD ISSUE AN ORDER COMPELLING APPLE TO COMPLY
      WITH ITS ORDER REQUIRING ASSISTANCE WITH THE FBI'S SEARCH
      OF THE SUBJECT DEVICE PURSUANT TO THE ALL WRITS ACT
      A.  This Court's All Writs Act Order is Lawful and Binding    7
          1.  The All Writs Act                                     7
          2.  Apple is not "far removed" from this matter          10
          3.  The Order does not place an unreasonable burden
                on Apple                                           12
          4.  Apple's assistance is necessary to effectuate the
              warrant                                              16
          5.  Apple's Potential Marketing Concerns Provide
              Insufficient Grounds to Disregard a Duly Issued
              Court Order Following a Warrant Based on a
              Finding of Probable Cause                            18
          6.  Public Policy Favors Enforcing of the Order          21
      B.  Congress has Not Limited this Court's Authority to
          Issue an All Writs Act Order to Apple                    21
          1.  No statute addresses data extraction from a
              passcode-locked cell phone                           22
          2.  Congressional inaction does not deprive courts of
              their authority under the All Writs Act              24
IV.  CONCLUSION                                                    25
TABLE OF AUTHORITIES
FEDERAL CASES
Central Bank of Denver v. First Interstate Bank of Denver,
511 U.S. 154 (1994)
General Construction Company v. Castro,
401 F.3d 963 (9th Cir. 2005)
In re Application of the United States for an Order
Directing a Provider of Communication Services to Provide
Technical Assistance to the DEA, 2015 WL 5233551, at*45
(D.P.R. Aug. 27, 2015)
In re Application of United States for an Order Authorizing an
In-Progress Trace of Wire Commc'ns over Tel. Facilities
(Mountain Bell) , 616 F.2d 1122 (9th Cir. 1980)     passim
In re Application of United States for an Order Directing X to
Provide Access to Videotapes (Access to Videotapes)
2003 WL 22053105, at *3 (D. Md. Aug. 22, 2003)
In re Order Requiring [XXX], Inc. to Assist in the Execution
of a Search Warrant Issued by This Court by Unlocking a
Cellphone (In re XXX), 2014 WL 5510865, at *2 (S.D.N.Y.
Oct. 31, 2014)
Konop v. Hawaiian Airlines, Inc.,
302 F.3d 868 (9th Cir. 2002)
Pennsylvania Bureau of Correction v. United States Marshals
474 U.S. 34 (1985)
Plum Creek Lumber Co. v. Hutton,
608 F.2d 1283 (9th Cir. 1979)
Riley v. California,
134 5. Ct. 2473 (2014)
United States v. Catoggio,
698 F.3d 64 (2d Cir.
United States v. Craft,
535 U.S. 274 (2002)
United   States v. Fricosu,
(D. Co. 2012)
United States v. Hall,
583 F. Supp. 717 (E.D. Va. 1984)
United States v. Li,
55 F.3d 325, 329 (7th Cir. 1995)
United States v. Navarro,
No. l3-CR~5525, ECF No. 39 (W.D. Wa. Nov. 13, 2013)
United States v. New York Telephone Co.,
434 U.S. 159 (1977)
FEDERAL STATUTES
18   U.S.C.  2510
18   U.S.C.  3103
28   U.S.C.  1651
47   U.S.C.  1001
47   U.S.C.  1002
MEMORANDUM OF POINTS AND AUTHORITIES
I.  INTRODUCTION
Rather than assist the effort to fully investigate a deadly
terrorist attack by obeying this Court's Order of February 16, 2016,
Apple has responded by publicly repudiating that Order. See Exhibit
1.   Apple has attempted to design and market its products to allow
technology, rather than the law, to control access to data which has
been found by this Court to be warranted for an important
investigation. Despite its efforts, Apple nonetheless retains the
technical ability to comply with the Order, and so should be required
to obey it.
Before Syed Rizwan Farook ("Farook") and his wife Tafsheen Malik
shot and killed 14 people and injured 22 others at the Inland
Regional Center in San Bernardino, Farook's employer issued him an
iPhone. The Federal Bureau of Investigation ("FBI") recovered that
iPhone during the investigation into the massacre. The government
has reason to believe that Farook used that iPhone to communicate
with some of the very people whom he and Malik murdered. The phone
may contain critical communications and data prior to and around the
time of the shooting that, thus far: (1) has not been accessed; (2)
may reside solely on the phone; and (3) cannot be accessed by any
other means known to either the government or Apple. The FBI
obtained a warrant to search the iPhone, and the owner of the iPhone,
Farook's employer, also gave the FBI its consent to the search.
Because the iPhone was locked, the government subsequently sought
Apple's help in its efforts to execute the lawfully issued search
warrant. Apple refused.
Apple left the government with no option other than to apply to
this Court for the Order issued on February 16, 2016. The Order
requires Apple to assist the FBI with respect to this single iPhone
used by Farook by providing the FBI with the opportunity to determine
the passcode. The Order does not, as Apple's public statement
alleges, require Apple to create or provide a "back door" to every
iPhone; it does not provide "hackers and criminals" access to
iPhones; it does not require Apple to "hack [its] own users" or to
"decrypt" its own phones; it does not give the government "the power
to reach into anyone's device" without a warrant or court
authorization; and it does not compromise the security of personal
information. See Exhibit 1. To the contrary, the Order allows Apple
to retain custody of its software at all times, and it gives Apple
flexibility in the manner in which it provides assistance. In fact,
the software never has to come into the government's custody.
In the past, Apple has consistently complied with a significant
number of orders issued pursuant to the All Writs Act to facilitate
the execution of search warrants on Apple devices running earlier
versions of iOS.[1]  The use of the All Writs Act to facilitate a
warrant is therefore not unprecedented; Apple itself has recognized
it for years, Based on Apple's recent public statement and other
statements by Apple, Apple's current refusal to comply with the
Court's Order, despite the technical feasibility of doing so, instead
appears to he based on its concern for its business model and public
brand marketing strategy.[2]
[Footnote 1: Apple's Legal Process Guidelines continue to state that Apple
will provide assistance with unlocking devices running 105 versions
earlier than 8.0, and advises as to what language to include in the
order. See "Extracting Data from Passcode Locked iOS Devices," Apple
Legal Process Guidelines  111(1) (updated September 29, 2015),
available at http: //
guidelines-us.pdf. However, Apple has informed another court that it
now objects to providing such assistance.]
[Footnote 2: As Apple has stated on its web page, "Our commitment to
customer privacy doesn't stop because of a government information
request    Unlike our competitors, Apple cannot bypass your passcode
and therefore cannot access this data. So it's not technically
feasible for us to respond to government warrants for the extraction
of this data from devices in their possession running iOS8."
acy/government-informaton-requests/).  Notably, notwithstanding this
previous statement, Apple concedes that it has retained the ability
to do as the Court ordered.]
Accordingly, the government now brings this motion to compel.
While the Order includes the provision that "to the extent that Apple
believes that compliance with this Order would be unreasonably
burdensome, it may make an application to this Court for relief
within five business days of receipt of the Order," Apple's public
statement makes clear that Apple will not comply with the Court's
Order. The government does not seek to deny Apple its right to be
heard, and expects these issues to be fully briefed before the Court;
however, the urgency of this investigation requires this motion now
that Apple has made its intention not to comply patently clear.[3]
This aspect of the investigation into the December 2, 2015 terrorist
attack must move forward.
[Footnote 3: Although a separate order compelling Apple's compliance with
this Court's February 16, 2016, order is not legally necessary, in
light of Apple's publicly stated "[o]pposing [of] this order" and its
stated interest in adversarial testing of the order's legal merits,
the government files this noticed motion to provide Apple with the
due process and adversarial testing it seeks.]
II.  STATEMENT OF FACTS
As set forth in the government's application for the All Writs
Act Order, and the Declaration of FBI Supervisory Special Agent
("SSA") Christopher Pluhar, which was attached thereto, both of which
were filed on February 16, 2016, the FBI has been investigating the
December 2, 2015 mass murder of 14 people, and the shooting and
injuring of 22 others, at the Inland Regional Center ("IRC") in San
Bernardino, California, and the participation by Farook and his wife
Malik in that crime. Farook and Malik died later that day in a
shoot-out after a pursuit with law enforcement.
Since that time, the FBI has been tirelessly investigating the
precise role of those who may have been involved in the attack. As
part of this investigation, the FBI obtained search warrants to
search, among other locations and items, the digital devices and
online accounts of Farook and Malik. Through those searches, the FBI
has discovered crucial information about the attack. For example,
the FBI discovered that on December 2, 2015, at approximately 11:14
a.m., a post on a Facebook page associated with Malik stated, "We
pledge allegiance to Khalifa bu bkr al bhaghdadi al quraishi,"
referring to Ahu Bakr Al Baghdadi, the leader of Islamic State of
Iraq and the Levant ("ISIL") , also referred to as the Islamic State
("IS") , or the Islamic State of Iraq and al-sham ("ISIS") , or Daesh.
ISIL is designated as a foreign terrorist organization by the United
States Department of State and has been so designated since December
2004. Moreover, a search warrant executed at Farook's residence
resulted in the discovery of thousands of rounds of ammunition and
over a dozen pipe bombs.
In addition, as part of the FBI's investigation, on December 3,
2015, the Honorable David T. Bristow, United States Magistrate Judge,
issued a search warrant in Docket Number ED 15-0451M for a black
Lexus IS300, which was a vehicle that Farook used. The vehicle was
parked outside of his residence where the thousands of rounds of
ammunition and pipe bombs were found. The search warrant for the
vehicle also ordered the search of digital devices located within it.
Inside the vehicle the FBI found a cellular telephone of an Apple
make: iPhone 5C, Model: A1532, P/N:MGFG2LL/A, S/N:FFMNQ3MTG2DJ,
IMEI:35882005230l412, on the Verizon Network (the "SUBJECT DEVICE")
The SUBJECT DEVICE is owned by Farook's employer at the San
Bernardino County Department of Public Health ("SBCDPH") , and was
assigned to, and used by, Farook as part of his employment. The
SBCDPH provided the government its consent to search the SUBJECT
DEVICE and to Apple's assistance with that search.[4]
[Footnote 4: In addition, SBCDPH has a written policy that all digital
devices are subject to search at any time by the SBCDPH, which
Farook accepted via signature upon employment.]
Nonetheless, despite the search warrant ordered by the Court and
the owner's consent to search the SUBJECT DEVICE, the FBI has been
unable to search the SUBJECT DEVICE because it is "locked" or secured
with a user-determined, numeric passcode. More to the point, the FBI
has been unable to make attempts to determine the passcode to access
the SUBJECT DEVICE because Apple has written, or "coded," its
operating systems with a user-enabled "auto-erase function" that
would, if enabled, result in the permanent destruction of the
required encryption key material after 10 failed attempts at the
entering the correct passcode (meaning that, after 10 failed
attempts, the information on the device becomes permanently
The information and data contained on the SUBJECT DEVICE is of
particular concern to the government because, while evidence found on
the iCloud account associated with the SUBJECT DEVICE indicates that
Farook communicated with victims who were later killed during the
shootings on December 2, 2015, the backup iClcud data which the
government has been able to obtain for the account ends on October
19, 2015. In addition, toll records for the SUBJECT DEVICE establish
that Farook communicated with Malik using the SUBJECT DEVICE between
July and November 2015, but this information is not found in the
backup iCloud data. Accordingly, there may be critical
communications and data prior to and around the time of the shooting
that thus far has not been accessed, may reside solely on the SUBJECT
DEVICE; and cannot be accessed by any other means known to either the
government or Apple.
When the government first realized that Apple retained the means
to obtain that data from the SUBJECT DEVICE and that due to the way
that Apple created the software Apple was the only means of obtaining
that data, the government sought Apple's voluntary assistance. Apple
rejected the government's request, although it conceded that it had
the technical capability to help. As a result, without any other
alternative, on February 16, 2016, the government applied for -- and
this Court subsequently issued -- an Order pursuant to the All writs
Act, compelling Apple to assist the FBI in its search of the SUBJECT
After the government served this Court's Order on Apple, Apple
issued a public statement responding directly to the Order. See
Exhibit 1. In that statement, Apple again did not assert that it
lacks the technical capability to execute the Order, that it is not
essential to gaining access into the iPhone, or that it would be too
time- or labor-intensive. Rather, Apple appears to object based on a
combination of: a perceived negative impact on its reputation and
marketing strategy were it to provide the ordered assistance to the
government, numerous mischaracterizations of the requirements of the
Order, and an incorrect understanding of the All Writs Act.
III.  THE COURT SHOULD ISSUE AN ORDER COMPELLING APPLE TO COMPLY WITH
ITS ORDER REQUIRING ASSISTANCE WITH THE FBI'S SEARCH OF THE
SUBJECT DEVICE PTYRSUAI4T TO THE ALL WRITS ACT
A.  This Court's All Writs Act Order is Lawful and Binding
To the extent that Apple objects that the Court does not have
authority under the All Writs Act to compel Apple to assist in the
execution of a lawfully obtained search warrant, this objection fails
because the authority to require reasonable third-party assistance
that is necessary to execute a warrant is well-established, and no
provision of any other law or any judicial decision justifies
limitation of that All Writs Act authority. To allow Apple not to
comply with the Order would frustrate the execution of a valid
warrant and thwart the public interest in a full and complete
investigation of a horrific act of terrorism.
1.  The All Writs Act
The All Writs Act provides in relevant part that "all courts
established by Act of Congress may issue all writs necessary or
appropriate in aid of their respective jurisdictions and agreeable to
the usages and principles of law." 28 U.S.C.  1651(a), As the
Supreme Court explained, "[t]he All Writs Act is a residual source of
authority to issue writs that are not otherwise covered by statute,"
Pennsylvania Bureau of Correction v. United States Marshals Service,
474 U.S. 34, 43 (1985).  Pursuant to the All Writs Act, the Court has
the power, "in aid of a valid warrant, to order a third party to
provide nonburdensome technical assistance to law enforcement
officers." Plum Creek Lumber Co. v. Hutton, 608 F.2d 1283, 1289 (9th
Cir. 1979) (citing United States v. New York Telephone Co., 434 U.S.
159 (1977)). The All Writs Act permits a court, in its "sound
judgment," to issue orders necessary "to achieve the rational ends of
law" and "the ends of justice entrusted to it." New York Telephone
Co., 434 U.S. at 172-73 (citations and internal quotation marks
omitted) . Courts must apply the All Writs Act "flexibly in
conformity with these principles." Id. at 173; accord United States
v. Catoggio, 698 F,3d 64, 67 (2d Cir. 2012) ("[C]ourts have
significant flexibility in exercising their authority under the
Act.") (citation omitted).
In New York Telephone Co., the Supreme Court held that courts
have authority under the All Writs Act to issue supplemental orders
to third parties to facilitate the execution of search warrants. The
Court held that "[t]he power conferred by the Act extends, under
appropriate circumstances, to persons who, though not parties to the
original action or engaged in wrongdoing, are in a position to
frustrate the implementation of a court order or the proper
administration of justice, ... and encompasses even those who have not
taken any affirmative action to hinder justice." Id. at 174. In
particular, the Court upheld an order directing a phone Company to
assist in executing a pen register search warrant issued under Rule
41. See id. at 171-76; see also In re Application of United States
for an Order Authorizing an In-Progress Trace of Wire Commc'ns over
Tel. Facilities (Mountain Bell), 616 F.2d 1122, 1132--33 (9th Cir.
1980) (affirming district court's order compelling Mountain Bell to
trace telephone calls, on grounds that "the obligations imposed . .
were reasonable ones." (citing New York Telephone Co., 434 U.S. at
172)). New York Telephone Co. also held that "Rule 41 is not limited
to tangible items but is sufficiently flexible to include within its
scope electronic intrusions authorized upon a finding of probable
cause." 434 U.S. at 169. The Court relied upon the authority of a
search warrant pursuant to Rule 41 to predicate an All Writs Act
order commanding a utility to implement a pen register and trap and
trace device - before Congress had passed a law that specifically
authorized pen registers by court order. Under New York Telephone
Co. and Mountain Bell, the Court had authority pursuant to the All
Writs Act to issue the Order.
Further, based on the authority given under the All Writs Act,
courts have issued orders, similar to the one the Court issued here,
that require a manufacturer to attempt to assist in accessing a
celiphone's image files so that a warrant may be executed as
originally contemplated. See, e.g., In re Order Requiring [XXX],
Inc. to Assist in the Execution of a Search Warrant Issued by This
Court by Unlocking a Cellphone (In re XXX) , 2014 WL 5510865, at *2
(S.D.N.Y. Oct. 31, 2014) ; see also United States v. Navarro, No. 13-
CR-5525, ECF No. 39 (W.D. Wa. Nov. 13, 2013). Courts have also
issued All Writs Act orders in support of warrants in a wide variety
of contexts, including ordering a phone company to assist with a trap
and trace device (Mountain Bell, 616 F.2d at 1129); ordering a credit
card company to produce customer records (United States v. Hall, 583
F. Supp. 717, 722 (E.D. Va. 1984)); ordering a landlord to provide
access to security camera videotapes (In re Application of United
States for an Order Directing X to Provide Access to Videotapes
(Access to videotapes), 2003 WL 22053105, at *3 (D. Md. Aug. 22,
2003) (unpublished)) ; and ordering a phone company to assist with
consensual monitoring of a customer's calls (In re Application of the
United States for an Order Directing a Provider of Communication
Services to Provide Technical Assistance to the DEA, 2015 WL 5233551,
at *45 (D.P.R. Aug. 27, 2015)). The government is also aware of
multiple other unpublished orders in this district and across the
country compelling Apple to assist in the execution of a search
warrant by accessing the data on devices running earlier versions of
iOS, orders with which Apple complied.[5] In fact, as noted above,
Apple has long recognized this application, and has complied with
search warrants compelling Apple to extract data from older iOS
devices locked with a passcode. Until last year, Apple did not
dispute any such order.
[Footnote 5: In litigation pending before a Magistrate Judge in the Eastern
District of New York, that court sua sponte raised the issue of
whether it had authority under the All Writs Act to issue a similar
order. That out-of-district litigation remains pending without any
issued orders, nor would any such order be binding on this Court. In
any event, that litigation represents a change in Apple's willingness
to access iPhones operating prior iOS versions, not a change in
Apple's technical ability.]
In New York Telephone Co., the Supreme Court considered three
factors in concluding that the issuance of the All Writs Act order to
the phone company was appropriate. First, it found that the phone
company was not "so far removed from the underlying controversy that
its assistance could not be permissibly compelled." I~ at 174.
Second, it concluded that the order did not place an undue burden on
the phone company. See id. at 175. Third, it determined that the
assistance of the company was necessary to achieve the purpose of the
warrant. See id. As set forth below, each of these factors supports
the order issued in this case.
2.  Apple is not "far removed" from this matter
First, Apple is not "so far removed from the underlying
controversy that its assistance could not be permissibly compelled."
Apple designed, manufactured and sold the SUBJECT DEVICE, and wrote
and owns the software that runs the phone -- which software is
preventing the search for evidence authorized by the warrant.
Indeed, Apple has positioned itself to be essential to gaining access
to the SUBJECT DEVICE or any other Apple device, and has marketed its
products on this basis. See, e.g., Apple's Security Guide,
 Apple designed
and restricts access to the code for the auto-erase function -- the
function that makes the data on the phone permanently inaccessible
after multiple failed passcode attempts. This feature effectively
prevents the government from performing the search for evidence
authorized by the warrant without Apple's assistance. The same
software Apple is uniquely able to modify also controls the delays
Apple implemented between failed passcode attempts - which makes the
process take too long to enable the access ordered by the Court.
Especially but not only because iPhones will only run software
cryptographically signed by Apple, and because Apple restricts access
to the source code of the software that creates these obstacles, no
other party has the ability to assist the government in preventing
these features from obstructing the search ordered by the Court
pursuant to the warrant. Just because Apple has sold the phone to a
customer and that customer has created a passcode does not mean that
the close software connection ceases to exist; Apple has designed the
phone and software updates so that Apple' s continued involvement and
connection is required.
Apple is also not made "far removed" by the fact that it is a
non-government third party. While New York Telephone Co. and
Mountain Bell involved public utilities, limiting All Writs Act
orders to public utilities is inconsistent with the broad scope of
judicial authority under the All Writs Act. New York Telephone Co.
emphasized that "the Company's facilities were being employed to
facilitate a criminal enterprise on a continuing basis[,J" and the
company's noncompliance "threatened obstruction of an investigation
which would determine whether the Company's facilities were being
lawfully used." 434 U.S. at 174. In Mountain Bell, the Ninth
Circuit emphasized that its decision "should not be read to authorize
the wholesale imposition upon private, third parties of duties
pursuant to search warrants," 616 F.2d at 1132, but Apple is not a
random entity summoned off the street to offer assistance, nor is it
the target of the investigation. Where Apple designed its software
and that design interferes with the execution of search warrants,
where it manufactured and sold a phone used by an ISIL-inspired
terrorist, where it owns and licensed the software used to further
the criminal enterprise, where it retains exclusive control over the
source code necessary to modify and install the software, and where
that very software now must be used to enable the search ordered by
the warrant, compulsion of Apple is permissible under New York
Telephone Co.
Moreover, other courts have directed All Writs Act orders based
on warrants to entities that are not public utilities. For example,
neither the credit card company in Hall nor the landlord in Access to
Videotapes was a public utility. See Hall, 583 F. Supp. at 722;
Access to Videotapes, 2003 WL 22053105, at *3~ Apple's close
relationship to the iPhone and its software, both legally and
technically -- which are the produce of Apple's own design -- makes
compelling assistance from Apple a permissible and indispensable
means of executing the warrant.
3.  The Order does not place an unreasonable burden on Apple
The Order has also not placed any unreasonable burden on Apple.
Where, as here, compliance with the order would not require
inordinate effort, no unreasonable burden can be found. See New York
Telephone Co., 434 U.S. at 175 (holding that All Writs Act order was
not burdensome because it required minimal effort by the company and
provided for reimbursement for the company's efforts); Mountain Bell,
616 F.2d at 1132 (rejecting telephone company's argument that
unreasonable burden would be imposed because of a drain on resources
and possibility of system malfunctions because the "Order was
extremely narrow in scope, restricting the operation to [electronic
switching system) facilities, excluding the use of manual tracing,
prohibiting any tracing technique which required active monitoring by
company personnel, and requiring that operations be conducted -with a
minimum of interference to the telephone service'").
While the Order in this case requires Apple to provide or employ
modified software, modifying an operating system -- which is
essentially writing software code in discrete and limited manner - is
not an unreasonable burden for a company that writes software code as
part of its regular business.[6] The simple fact of having to create
code that may not now exist in the exact form required does not an
undue burden make. In fact, providers of electronic communications
services and remote computing services are sometimes required to
write some amount of code in order to gather information in response
to subpoenas or other process. Additionally, assistance under the
All Writs Act has been compelled to provide something that did not
previously exist -- the decryption of the contents of devices seized
pursuant to a search warrant. In United States v. Fricosu, 841
F.Supp.2d 1232, 1237 (D. Co. 2012), a defendant's computer -- whose
contents were encrypted -- was seized, and the defendant was ordered
pursuant to the All Writs Act to assist the government in producing a
copy of the unencrypted contents of the computer. Here, the type of
assistance does not even require Apple to assist in producing the
unencrypted contents; the assistance is rather to facilitate the
FBI's attempts to test passcodes.
[Footnote 6: Additionally, the Order provides that Apple may request
reasonable reimbursement for expenses incurred in complying with the
As noted above, Apple designs and implements all of the features
discussed, writes and cryptographically signs the iOS, routinely
patches security or functionality issues in its operating system, and
releases new versions of its operating system to address issues. By
comparison, writing a program that turns off non-encryption features
that Apple was responsible for writing to begin with would not be
unduly burdensome. At no point has Apple ever said that it does not
have the technical ability to comply with the Order, or that the
Order asks Apple to undertake an unreasonably challenging software
development task. On this point, Apple's silence speaks volumes.
Moreover, contrary to Apple's recent public statement that the
assistance ordered by the Court "could be used over and over again,
on any number of devices" and that "[t]he government is asking Apple
to hack our own users," the Order is tailored for and limited to this
particular phone. And the Order will facilitate only the FBI's
efforts to search the phone; it does not require Apple to conduct the
search or access any content on the phone. Nor is compliance with
the Order a threat to other users of Apple products. Apple may
maintain custody of the software, destroy it after its purpose under
the order has been served, refuse to disseminate it outside of Apple,
and make clear to the world that it does not apply to other devices
or users without lawful court orders. As such, compliance with the
Order presents no danger for any other phone and is not "the
equivalent of a master key, capable of opening hundreds of millions
of locks."
To the extent that Apple claims that the Order is unreasonably
burdensome because it undermines Apple's marketing strategies or
because it fears criticism for providing lawful access to the
government, these concerns do not establish an undue burden. The
principle that "private citizens have a duty to provide assistance to
law enforcement officials when it is required is by no means foreign
to our traditions." New York Telephone 434 U.S. at 176 n.24. Apple
is not above the law in that regard, and it is perfectly capable of
advising consumers that compliance with a discrete and limited court
order founded on probable cause is an obligation of a responsible
member of the community. It does not mean the end of privacy. As
discussed above, the Order requires Apple to assist only in
facilitating proper, legal access based on a finding of probable
cause. Further, the government is not seeking to "brcak" Apple's
encryption infrastructure or unlawfully violate the privacy of its
customers. Instead, through proper legal process through the Court,
the government is seeking to use capabilities that Apple has
purposefully retained in a situation where the former user of the
phone is dead and no longer has any expectation of privacy in the
phone, and the owner of the phone consents both to the search of the
phone and to Apple's assistance thereto.
More generally, the burden associated with compliance with legal
process is measured based on the direct costs of compliance, not on
other more general considerations about reputations or the
ramifications of compliance. See In re XXX, 2014 WL 5510865, at *2.
For example, an All Writs Act order may be used to require the
production of a handwriting exemplar, see United States v. Li, 55
F.3d 325, 329 (7th Cir. 1995), even though the subject may face
criminal sanctions as a result of his compliance. Apple's
speculative policy concerns regarding possible consequences from
compliance with the Order in this matter merit little weight,
particularly when complying with a court order based on a warrant
serves the ends of justice and protects public safety in furthering
the investigative aims of a terrorism investigation.
4.  Apple's assistance is necessary to effectuate the warrant
Apple's assistance is also necessary to effectuate the warrant.
In New York Telephone Co., the Court held that the order met that
standard because "[t]he provision of a leased line by the Company was
essential to the fulfillment of the purpose -- to learn the identities
of those connected with the gambling operation -- for which the pen ~
register order had been issued." 434 U.S. at 175. The Order issued
here also meets this standard, as it is essential to ensuring that
the government is able to execute the warrant.
In this case, the ability to perform the search ordered by the
warrant on the SUBJECT DEVICE is of critical importance to an ongoing
terrorism investigation. The user of the phone, Farook, is a mass
murderer who caused the death of a large number of his coworkers and
the shooting of many others, and who built bombs and hoarded weapons
for this purpose. The FBI has been able to obtain several iCloud
backups for the SUBJECT DEVICE, and executed a warrant to obtain all
saved iCloud data associated with the SUBJECT DEVICE. Evidence in
the iCloud account indicates that Farook was in communication with
victims who were later killed during the shootings perpetrated by
Farook on December 2, 2015, and toll records show that Farook
communicated with Malik using the SUBJECT DEVICE. Importantly,
however, the most recent backup of the iCloud data obtained by the
government was dated October 19, 2015, approximately one and a half
months before the shooting. As such, there may be relevant, critical
communications and data around the time of the shooting that may
reside solely on the SUBJECT DEVICE and can only be obtained if the
government is able to search the phone as directed by the warrant.
Moreover, as discussed above, Apple's assistance is necessary
because without the access to Apple's software code and ability to
cryptographically sign code for the SUBJECT DEVICE that only Apple
has, the FBI cannot attempt to determine the passcode without fear of
permanent loss of access to the data or excessive time delay.
Indeed, after reviewing a number of other suggestions to obtain the
data from the SUBJECT DEVICE with Apple, technicians from both Apple
and the FBI agreed that they were unable to identify any other
methods - besides that which is now ordered by this Court - that are
feasible for gaining access to the currently inaccessible data on the
"SUBJECT DEVICE.[7]  There can thus be no question that Apple's
assistance is necessary, and that the Order was therefore properly
[Footnote 7: The four suggestions that Apple and the FBI discussed (and
their deficiencies) were: (1) to obtain cell phone toll records for
the SUBJECT DEVICE (which, while the government has of course done
so, is insufficient because there is far more information on the
SUBJECT DEVICE than simply toll records) ; (2) to determine if any
computers were paired with the SUBJECT DEVICE to obtain data (which
the government has determined that none were) ; (3) to attempt an
auto-backup of the SUBJECT DEVICE with the related iCloud account
(which would not work in this case because neither the owner nor the
government knew the password to the iCloud account, and the owner, in
an attempt to gain access to some information in the hours after the
attack, was able to reset the password remotely, but that had the
effect of eliminating the possibility of an auto-backup) ; and (4)
obtaining previous back-ups of the SUBJECT DEVICE (which the
government has done, but is insufficient because these backups end on
October 19, 2015, nearly one-and-a-half months prior to the IRC
shooting incident, and also back-ups do not appear to have the same
amount of information as is on the phone itself) . After subsequent
conversations, though, Apple conceded that none of these suggestions
would work to execute the search warrant or to sufficiently obtain
the information sought.]
5.  Apple's Potential Marketing Concerns Provide
Insufficient Grounds to Disregard a Duly Issued Court
Order Following a Warrant Based on a Finding of
Probable Cause
To the extent that Apple objects on the grounds that it would
undermine its marketing strategy to comply with this Court's Order,
or that it has an overall objection to anything that enables lawful
access by the government to encrypted information, the government
believes these objections are irrelevant and not legally cognizable
before this Court.
First, in this case, the government seeks to search the SUBJECT
DEVICE pursuant to a validly-issued search warrant, and a validly-
issued All Writs Act Order. The government shares Apple's stated
concern that "information needs to be protected from hackers and
criminals who want to access it, steal it, and use it without our
knowledge or permission." See Exhibit 1. The order at issue does
not compromise that interest. This is not a situation of protecting
the owner and user of this particular device against unauthorized or
unlawful access - here, the owner consented to the government
accessing it. Nor is it about protecting Apple's customers from the
government "intercept[ing] [their] messages, access[ing) [their]
health records or financial data, track[ing] [their] location, or
even access [their] phone's microphone or camera without [their)
knowledge" or from "hackers and criminals who want to access
[personal information], steal it, and use it without our knowledge or
permission." What is at stake are two judicially issued orders: one
based on a finding of probable cause, approved by this Court,
permitting the government to search one telephone of an individual
suspected of being involved in a terrorist attack that killed 14
Americans and wounded 22 others on our own soil, the other directing
Apple to provide limited assistance it is uniquely qualified to
provide to effectuate that order.
Second, the assistance ordered is not a "back door" or a "hack"
to all of Apple's encryption software. That is an unwarranted and
inaccurate characterization. As was made plain in the government's
application for the All Writs Act Order, the government asks that
Apple assist in the execution of a search warrant using the
capabilities that Apple has retained along within its encryption
software, such that the government can attempt to determine the
passcode without the additional, non-encryption features that Apple
has coded into its operating system, for the SUBJECT DEVICE only. In
sum, the government seeks the ability to make multiple attempts at
determining the passcode without risk that the data subject to search
under the warrant would be rendered permanently inaccessible after 10
wrong attempts. This aspect of the Order is no more or less than
what a user has the ability to do if the auto-erase function is
turned off. Moreover, the software required is no more of a "hack"
or a provision of dangerous malware than any update Apple or other
providers send to a phone. Indeed, it is less so because the
software requested would not reside permanently on the SUBJECT
DEVICE, and Apple can retain control over it entirely. The Order
does nothing regarding the encryption aspect of the operating
software, but instead implicates only the non-encryption additional
features that Apple has programmed.
Moreover, to the extent that Apple has concerns about turning
over software to the government so that the government can run the
passcode check program, the Order permits Apple to take possession of
the SUBJECT DEVICE to load the programs in its own secure location,
similar to what Apple has done for years for earlier operating
systems, and permit the government to make its passcode attempts via
remote access. In this fashion, just as with Apple's own already-
existing operating systems and software, no one outside Apple would
have access to the software required by the Order unless Apple itself
chose to share it. This eliminates any danger that the software
required by the Order would go into the "wrong hands" and lead to
criminals' and bad actors' "potential to unlock any iPhone in
someone's physical possession."
Third, marketing or general policy concerns are not legally
cognizable objections to the Order. As discussed above, the analysis
of whether a court order presents an unreasonable burden is focused
on the direct costs of compliance, not whether the party strongly
disagrees with the concept of complying. This Court should not
entertain an argument that fulfilling basic civic responsibilities of
any American citizen or company -- complying with a lawful court order
- could be obviated because that company prefers to market itself as
providing privacy protections that make it infeasible to comply with
court-issued warrants.
6.  Public Policy Favors Enforcing of the Order
Strong public policy interests favor enforcing the All Writs Act
Order in this matter. In New York Telephone Co., the Supreme Court
emphasized "the clear indication by Congress that the pen register is
a permissible law enforcement tool." 434 U.S. at 176. Here, this
matter involves the most fundamental investigative tool of all, the
search warrant. Its use is enshrined in the text of the Constitution
and explicitly endorsed by Congress. See U.S. Const. amend. IV ("no
Warrants shall issue, but upon probable cause"); 18 U.S.C.  3103a(a)
("a warrant may be issued to search for and seize any property that
constitutes evidence of a criminal offense") . Recently, in Riley v.
California, 134 5. Ct. 2473, 2495 (2014), the Supreme Court set the
standard for what law enforcement must do to search a cell phone
seized incident to arrest: "get a warrant." Here, the government
has obtained a warrant to search the phone of a mass murderer, but
unless this Court enforces the Order requiring Apple's assistance,
the warrant will be meaningless.
B.  Congress has Not Limited this Court's Authority to Issue an
All Writs Act Order to Apple
Based on the government's discussions with Apple, Apple's public
statement, and the litigation pending in the Eastern District of New
York, it appears Apple is arguing that it is justified in refusing to
comply with the Order because the All Writs Act has been limited by
Congress. This argument fails because there is no statute that
specifically addresses the issue of Apple's assistance, and the
absence of such a specific statute cannot be read as a decision to
limit existing authority. Thus, the Order was an appropriate
execution of this court's jurisdiction in this matter.
1.  No statute addresses data extraction from a passcode locked cell phone
The Supreme Court has made clear that "[t]he All Writs Act is a
residual source of authority to issue writs that are not otherwise
covered by statute[,]" such that courts may not rely on the All Writs
Act "[w]here a statute specifically addresses the particular issue at
hand[.IJ" Pennsylvania Bureau of Correction, 474 U.S. at 43. In this
case, no other statute addresses the procedures for requiring Apple
to extract data from a passcode-locked iPhone, so Pennsylvania Bureau
of Correction provides no basis for denying the government's
application for an All Writs Act Order in this case.
In particular, neither Federal Rule of Criminal Procedure 41 nor
the Communications Assistance for Law Enforcement Act ("CALEA")   , 47
U.S.C.  1002, "specifically addresses" -- or even vaguely addresses --
the duty of Apple to assist in extracting data from a passcode-locked
cell phone in order to permit the government to execute a validly
issued search warrant. CALEA requires telecommunications carriers to
retain the capability to comply with court orders for real-time
interceptions and call-identifying information (data "in motion").[8]
Id.  By contrast, this case involves evidence already stored on a
cell phone (data "at rest") . Here, Apple is not acting as a
telecommunications carrier, and the Order concerns access to stored
data rather than real-time interceptions and call-identifying
information. Put simply, CALEA is entirely inapplicable to the
present dispute and does not limit this Court's authority under the
All Writs Act to require Apple to assist the government in executing
a search warrant.[9]
[Footnote 8: For example, for the contents of communications, CALEA
28 requires telecommunications carriers to be able "to intercept" wire
and electronic communications carried by the carrier. 47 U.S.C.
 1002 (a) (1) . CALEA incorporates the definition of "intercept" from
the Wiretap Act, see 47 U.S.C.  1001(1) & 18 U.S.C.  2510(4), and
that definition encompasses only information acquired during
transmission, not while it is in storage. Konop v. Hawaiian
Airlines, Inc., 302 F.3d 868, 877-878 (9th Cir. 2002).]
[Footnote 9: Furthermore, nothing in CALEA prevents a court from ordering a
telecommunications carrier to decrypt communications that the carrier
is capable of decrypting.  See 47 U.S.C. 1002(b)(3).  When Congress
enacted CALEA, it understood that existing provider-assistance
provisions required a provider to decrypt communications when it was
able to do so. Both the House and Senate reports for CALEA stated
that "telecommunications carriers have no responsibility to decrypt
encrypted communications that are the subject of court-ordered
wiretaps, unless the carrier provided the encryption and can decrypt
it." H.R. Rep. No. 103-827(I), at 24 (1994); S. Rep. No. 103-402, at
24 (1994).]
New York Telephone Co. further illustrates that it is
appropriate for a court to rely on the All Writs Act unless a statute
specifically addresses the particular issue at hand. When the Court
decided New York Telephone Co. in 1977, Congress had enacted Title
III for intercepting the contents of communications, but it had not
yet enacted the closely-related pen register statute for acquiring
non-content information. See Electronic Communications Privacy Act
of 1986  301, 100 Stat. 1848 (enacting pen register statute)
Despite the existence of a statute regulating government access to
information closely related to pen registers, but not specifically
addressing pen registers, the Supreme Court held that an All Writs
Act order could be issued in support of a warrant for a pen register.
Under this reasoning, CALEA is no barrier to the Order in this case.
2.  Congressional inaction does not deprive courts of
their authority under the All Writs Act
The current lack of congressional action regarding encryption-
related issues does not deprive this Court of its authority to issue
the Order in this case. Under Pennsylvania Bureau of Correction,
courts may not rely on the All Writs Act where "a statute
specifically addresses" an issue. But the opposite is not true.
Courts may not categorically refuse to rely on the All Writs Act - as
Apple would seemingly want the Court to do - where Congress has
declined to legislate. Court authority to issue All Writs Act orders
in support of warrants has been clearly established since the Supreme
Court decided New York Telephone Co. in 1977. Congress may choose to
expand or limit this authority, but it must do so through enactment
of legislation.
The Supreme Court and the Ninth Circuit have repeatedly
cautioned that "Congressional inaction lacks persuasive significance
because several equally tenable inferences may be drawn from such
inaction[.J" General Construction Company v. Castro, 401 F.3d 963,
970-71  (9th Cir, 2005) (quoting Central Bank of Denver v. First
Interstate Bank of Denver, 511 U.S. 164, 187 (1994)); see also United
States v. Craft, 535 U.S. 274, 287 (2002)
Here, there are many possible explanations for congressional
inaction on encryption, including that Congress is satisfied with
existing authorities, or that Congress has not yet reached agreement
on whether or how much to expand existing authorities. These
possibilities provide no basis for restricting legal authorities that
existed before the beginning of the debate.[10]  Because courts do not
lose an authority to issue orders under the All Writs Act merely
because Congress does not subsequently enact legislation endorsing or
expanding that authority, this Court retains authority to issue an
All Writs Act Order consistent with New York Telephone Co.
[Footnote 10: Granting legal force to statements or proposals by individual
members of Congress during the course of congressional debate risks
absurd results. Congress routinely debates and fails to act on
important issues, but the mere debate does not restrict existing
legal authority. Under the Constitution, Congress speaks with legal
force only when it speaks as one body, through bicameralism and
presentment -- i.e. when it passes a bill.]
IV.  CONCLUSION
This Court issued a valid Order pursuant to the All Writs Act
requiring Apple to assist the United States in enabling the search
for evidence pursuant to a lawful search warrant. Apple has publicly
stated that it will oppose this Order, and has not agreed to comply.
For the foregoing reasons, the government respectfully requests that
this Court issue an Order compelling Apple to comply.
EXHIBIT 1
(See CERTIFICATE OF SERVICE
I, REBECCA EVANS, declare
That I am a citizen of the United States and resident or employed in Riverside County, California; that my business address is the Office of United States Attorney, 3403 Tenth Street, Suite 200, Riverside, CA 92501; that I am over the age of eighteen years, and am not a party to the above-entitled action; That I am employed by the United States Attorney for the Central District of California who is a member of the Bar of the United States District Court for the Central District of California, at whose direction I served a copy:
GOVERNMENT'S MOTION TO COMPEL APPLE INC. TO COMPLY WITH THIS COURT'S
FEBRUARY 16, 2016 ORDER COMPELLING ASSISTANCE IN SEARCH: EXHIBIT
[X] By electronic mail as follows:
Mr. Theodore B. Olson
Gibson, Dunn & Crutcher LLP
tolson at gibsondunn.com
Mr. Theodore J. Boutrous Jr.
Gibson, Dunn & Crutcher LLP
tboutrous at gibsondunn.com
Ms. Nicola T. Hanna
Gibson, Dunn & Crutcher LLP
nhanna at gibsondunn.com
Mr. Eric D. Vandevelde Gibson, Dunn & Crutcher LLP
evandevelde at gibsondunn.com
This Certificate is executed on February 19, 2016,in Riverside, California.  I certify under penalty of perjury that the foregoing is true and correct.
REBECCA EVANS

@_date: 2016-02-20 13:04:13
@_author: Henry Baker 
@_subject: [Cryptography] Apple 3rd Party dilemma 
The *money* price isn't the major problem; the problem is the *3rd party doctrine,* which gives the NSA/FBI/DHS/DOJ easy/trivial access to your "cloud" data.  Look at how easy FBI/DOJ obtained the cloud backups of Farook's iPhone.
The only solution is to store only fully encrypted data in the cloud; but if you lose your iPhone or the key, it's gone.
It's also gone if you (or the govt) goes beyond 10 guesses; so the govt has an easy DoS attack on your data: have the TSA screw with your phone every time you cross the border.
Hey, hey, you (govt), you (govt), get off of My Cloud!

@_date: 2016-02-20 15:21:18
@_author: Henry Baker 
@_subject: [Cryptography] Apple's 10 strikes law 
It appears that Apple's iPhone gives you 10 tries to guess your passcode before locking up the phone forever.
There are several problems with this plan:
* the number 10 is an arbitrary constant set in the code; it's too easy to change.
* the time between each guess is the same (??? I think).
What about the following idea:
Your iPhone is encrypted with a *malleable* key, but only the real key works.
Every wrong guess randomly destroys part of the key, so that your iPhone now has to brute force guess the remaining bits in a manner similar to Bitcoin's proof-of-work.
The more wrong guesses, the more bits of the key are destroyed and have to be regenerated through brute force trials.
Yes, after 10 wrong guesses, you could brute force 40,50,60 the remaining bits, but it would take millenia.

@_date: 2016-02-20 16:36:56
@_author: Henry Baker 
@_subject: [Cryptography] the consequences of changing the password on 
I think you know the answer to this question: DoJ/FBI doesn't really care about the contents of this particular iPhone, but they want to use "terrorism" to score political points and to scare lawmakers into whupping some sense into that pinko Tim Cook.
DoJ would love to gibbet Tim Cook as a warning to the rest of Silly Valley.
DoJ has also been itching to gun the engines of the All Writs Act, and they figure Apple is the one to pay for the legal research on this one.
If the All Writs Act gets shot down, they have a large number of other laws of dubious Constitutionality to try out; they hope to get even more laws of dubious Constitutionality enacted as a result of this exercise.

@_date: 2016-02-21 16:46:13
@_author: Henry Baker 
@_subject: [Cryptography] 10 Reasons Farook's Work Phone Likely Won't Have Any 
FYI -- This guy is an iPhone forensics expert witness.
Zdziarski's Blog of Things
Forensic scientist, author, reverse engineer, photographer, purveyor of funky bass guitar.
10 Reasons Farook's Work Phone Likely Won't Have Any Evidence
Posted on February 18, 2016
Farook burned and destroyed two other electronic devices, going to great lengths to protect data he knew was on the devices. He also had opportunity to destroy this one if it had anything incriminating on it.
The device was making iCloud backups until a month and a half before the spree, there was absolutely nothing in them.  iCloud backups could have ceased for a number of reasons, including a software update that was released on October 21, just two days after the last backup, or due to iCloud storage filling up.
Find my iPhone is still active on the phone (search by serial number), so why would a terrorist use a phone he knew was tracking him?  Obviously he wouldn't.  The Find-my-iPhone feature is on the same settings screen as the iCloud backup feature, so if he had disabled backups, he would have definitely known the phone was being tracked.  But the argument that Farook intentionally disabled iCloud backup does not hold water, since he would have turned off Find-my-iPhone as well.
In addition to leaving Find-my-iPhone on, the option to delete all prior backups (which include iMessage history and other content) is also on the same settings screen as the option to disable iCloud backups.  If Farook was trying to cover up evidence of leads, he would have also deleted the existing backups that were there.  By leaving the iCloud backup data, we know that Farook likely did not use the device to talk to any leads prior to October 19.
FBI appears to have initially received the device still powered on, and would have had the opportunity to interrogate Siri for content on the device.  Either this has already happened, yet yielded no finding of evidence, or they didn't consider the phone important enough at the time.  There are law enforcement white papers on doing this, so the technique is rather well known.
The FBI would already have all call records, cellular metadata, email records, Facebook and other social media content, and text message endpoint metadata for this device; none of the court documents indicated that there was any hard evidence tying the device to a lead or suspect.  Based on this, it is a reasonable conclusion to expect that there is virtually zero metadata from any carrier to suggest that the device was used to communicate with other persons of interest.  Communication with any of the victims could be obtained from the victims' devices, at least some of which must certainly be unlocked, have a PIN for, have iCloud backup data for, or be on completely different non-Apple devices that could be accessed.
Suspect used a simple numeric passcode on the device; this was both mentioned in the DOJ filing as well as is obvious from looking at the initial court order.  In spite of his taking incredible steps to protect the evidence on his other devices, there's no reason he'd use a simple PIN if he was this security conscious.  Someone who is this concerned about covering their tracks would have used a complex passcode, as this stretches the brute force time from 22 hours (for a six digit pin) to 6 years (for a six digit alphanumeric passcode), exponentially more for longer passcodes.
As an employer-owned device, he would have been (and for good reason) paranoid that the phone could be monitored, so would have been foolish to use it in the first place.
FBI likely would have already run the device on a Stingray, to capture outgoing traffic.  Any network traffic the device, including third party applications with background tasks, would have generated would be visible by FBI.  The absence of any findings of evidence to compel a judge to grant the order demonstrates again they've found nothing coming out of the device.
This entry was posted in iPhone, Politics by Jonathan Zdziarski.

@_date: 2016-02-23 10:49:34
@_author: Henry Baker 
@_subject: [Cryptography] 1x pad: the elephant in the Apple/DOJ courtroom 
Shannon publicly proved the 1x pad unbreakable in 1948.
The NSA Venona Project proved the 1x pad is *practically* unbreakable; the only successful Venona decrypts depended critically on the reuse of some key material.
Soviet/Russian agents routinely used 1x pads -- including the hottie Anna Chapman picked up by the FBI in 2010 (best looking mug shot ever!).  These agents routinely get thrown out of the country, but rarely get compromised by their messages.
U.S. forces routinely used 1x pads in Vietnam; unfortunately, their condescension of their enemies led them to really bad OPSEC.
Anyone can use a 1x pad today to encrypt/decrypt *by hand* to send/receive SMS and/or email messages.  When the encryption/decryption is done by hand, the key material never need touch the cellphone and/or computer.
So, terrorists probably have used 1x pads in the past, and will continue to use 1x pads in the future, in the planning & execution of their plots.  Nothing in the law or technology will change this fact.
These end-to-end encrypted messages will continue to keep the FBI & NSA in the "dark".
So the only thing that DOJ/NSA wants to continue to do is *mass surveillance* on people too stupid or too lazy to use unbreakable encryption.
Although DOJ/FBI claims that this case is "targeted" at a single phone, we all know that this is a bald-faced lie; they are setting a precedent that will open up a billion+ cellphones around the world for routine mass surveillance.

@_date: 2016-02-23 12:17:13
@_author: Henry Baker 
@_subject: [Cryptography] DOJ/Apple passcode == "non-encryption additional 
DOJ states:
"The Order does nothing regarding the encryption aspect of the operating software, but instead implicates only the non-encryption additional features that Apple has programmed".
Since the passcode *IS* the encryption key, or is at least a significant part of the encryption key, it is definitely NOT a "non-encryption additional feature".
The security of the encryption is directly related to the security of the key, which in turn is directly related to key management -- including anti-bruteforcing protocols such as the time delay and 10x limit.

@_date: 2016-02-23 11:22:44
@_author: Henry Baker 
@_subject: [Cryptography] Apple's "business model and public brand marketing 
What about the "business model" and "public brand marketing strategy" of the United States of America?
Aren't these outlined in the Declaration of Independence and Constitution?
What ever happened to that "shining city on a hill" referred to by Presidents John Kennedy and Ronald Reagan ?

@_date: 2016-02-23 12:38:10
@_author: Henry Baker 
@_subject: [Cryptography] RIP Claude Shannon 
Supposedly, Shannon worked on voice encryption for phones (a loser, in light of digitization & digital encryption) and almost certainly on attempting to decrypt 1x pads -- the precursor to the Venona project.
It was probably Shannon's job to deliver the message to the top brass that the Soviet 1x pads were indeed unbreakable, and -- short of finding a copy of the pad or evidence of pad reuse -- that 1x pad-encrypted messages would leave the U.S. in the "dark".  I can imagine the top brass then going into a hissy-fit and asking all of those PhD's to work *harder* on this problem -- a la James Comey & Hillary Clinton.

@_date: 2016-02-23 14:25:06
@_author: Henry Baker 
@_subject: [Cryptography] 1x pad: the elephant in the Apple/DOJ courtroom 
Get your dice or spinners & write stuff down with pencil & paper.
Isn't that what crypto parties are for?  ;-)
Unless you're encrypting phone calls or movies, most messages are pretty short (< 140 bytes ?).
You might also consider using multiple sources of randomness & mixing, just in case the dice are loaded.

@_date: 2016-02-23 14:39:29
@_author: Henry Baker 
@_subject: [Cryptography] RIP Claude Shannon 
So far as I know, neither the Germans nor the Japanese used 1x pads (I seem to recall that there was a Japanese agent who tried, but didn't use good OPSEC & got caught).
The Soviets used them, but they were our *allies* during WWII.

@_date: 2016-02-23 17:00:28
@_author: Henry Baker 
@_subject: [Cryptography] 1x pad: the elephant in the Apple/DOJ courtroom 
I misspoke; "targeted" -> "tailored".  (TAO, anyone?  anyone?)
DOJ brief:
"the Order is tailored for and limited to this particular phone.  And the Order will facilitate only the FBI's effort to search the phone ... Nor is compliance with the Order a threat to other users of Apple products. ... As such, compliance with the Order presents no danger for any other phone".
This statement is a bald-faced lie.

@_date: 2016-02-24 12:34:49
@_author: Henry Baker 
@_subject: [Cryptography] 1x pad: the elephant in the Apple/DOJ courtroom 
Dice, roulette wheels, spinners, etc., are all illegal
*gambling* equipment.  (Didn't you realize that *that's*
why gambling is so subversive -- it isn't about taking
poor people's money, but illegally generating random
numbers that are subsequently used by terrorists.)  I
understand that *Monte Carlo* methods were invented to
simulate atomic weapons; so random numbers are evidence
of weapons of mass destruction.
Random numbers: see something, say something!
I'm playing bingo tonight (seriously!), and I'm going to
ask the caller for her random number list afterwards.

@_date: 2016-02-24 12:47:39
@_author: Henry Baker 
@_subject: [Cryptography] RIP Claude Shannon 
The 1x pad random keying material is "freeze dried adjacency".  It is a *resource* that you can stock up on in advance -- kind of like fuel or gold, that you can stockpile in your fallout bunker.
If you've got nothing important to talk about with a friend over a beer, share some key material instead.  Later, when you *do* have something to talk about, you can use some of that key material to gain the advantage of adjacency when discussing over long distances.
When you need to send out a confidential message, you sprinkle some of this fairy dust on the message, and you're good to go.

@_date: 2016-02-24 16:28:39
@_author: Henry Baker 
@_subject: [Cryptography] RIP Claude Shannon 
The establishment of 2 equal "keys", one at each location, is analogous to the establishment of 2 "entangled" sets of qubits, one at each location.
The mere creation and transportation of these shared keys and entangled qubits in the two different locations isn't "communication", per se.
However, these keys and qubits can be *later* used to enable confidential communications.  (BTW, quantum key distribution "QKD" is a really key *amplification* technology, rather than a key "distribution" technology, since there must already exist some initial shared key to protect against MITM attacks.)
If you are depending upon traditional "communication" to transfer the key bits, then you are correct.  However, at least in the traditional use of 1x pads, both of the equal keys are separately transported to their final location prior to being used for confidential communications.
The whole point of the 1x pad is to separate the secure transportation of the random keys -- which have no *current* value -- from the communication of the message -- which presumably has enormous value.  This separation allows us to (in effect) *move the communication backwards in time* to the point where the keys were being transported, and thus transfer the message as securely as those keys were transported.
Note that the amount of this "time travel" can be seconds, days, years, or decades.  The contents of the message cannot possibly have been predicted at the time the keys were transported, so there is no a priori association of a particular key with a particular message.
So yes, you are right, but you have built the equivalent of a time travel "wormhole" (of a particular bit length capacity) for later use for the confidential transmission of messages.  This is a far more powerful ability than the simple secure transportation of a message in real time.

@_date: 2016-02-24 17:00:08
@_author: Henry Baker 
@_subject: [Cryptography] Practicality of codebook in current-day secret 
Dynamic code book == RAM (Random Access Memory)
Encode it, encrypt it, hash it, oblivious transfer it, whatever, but it's still RAM.

@_date: 2016-02-25 07:03:30
@_author: Henry Baker 
@_subject: [Cryptography] Practicality of codebook in current-day secret 
mail.com>
Most 19th C. codebooks were primarily used for compression, since cables were charged by the length of the message, and were terribly expensive.
To the extent that you used a proprietary codebook, it might ensure some confidentiality, as well.

@_date: 2016-02-25 13:14:53
@_author: Henry Baker 
@_subject: [Cryptography] Hope Apple Fights This! 
I'd like to see cloud services that are located in multiple countries, but which never store more than a small % *of any one cust's data* in that particular country.  Think RAID (or in this case, Redundant Array of Independent Countries).  Now *that* would be a TPP/TTIP "partnership" I could support!
After the chaos in the Middle East following the Arab Spring uprisings, I suspect that there would be a lot of takers there for solid business continuity reasons.

@_date: 2016-02-25 14:00:36
@_author: Henry Baker 
@_subject: [Cryptography] Hope Apple Fights This! 
So let me understand: exactly *where* is my data?
If I have a file full of random numbers in country  and another file full of random numbers in country  and another file full of random numbers in country  and so on, so I guess my "data" is in *all* of the countries.
But only I know the function that will transform the data stored in all of these countries into a form that might actually be useful, so my "data" is also in *none* of the countries.
Now, there will also be hundreds/thousands/millions of files of random numbers that belong to other people, but may also visible to the world at large.
I am free to incorporate (or not) those files into my computation.  (Assume that the files are readonly/appendonly for the time being; it makes the system easier to contemplate.)
I have been thinking about a file system in which everyone's files are actually *public*, so Microsoft, e.g., would simply respond to every warrant with a browser manual and a "knock yourself out" email.
Having all bits public may actually make the whole thing more private, because everyone can take advantage of the randomness of everyone else's encrypted data.

@_date: 2016-02-25 14:11:50
@_author: Henry Baker 
@_subject: [Cryptography] Apple: graphically show users that they are under 
I was trying to describe the Apple situation to a non-techie yesterday, and I thought of a change that Apple/Google/etc. should make ASAP.
The reason why most people don't fear govt surveillance and are willing to give up encryption is that they don't realize that they (their phones & computers) are *already* under constant attack.
It's hard to realize that you're on a battlefield when you can't hear the bullets whizzing around your head.
Apple needs to incorporate some sort of visual "meter" or other display icon that indicates when their phone is being scanned and when someone is trying to crack their passcode, their SSH login, etc.
In addition to attacks on your particular phone, Apple might also have a threat meter indicating attacks on iPhone's in general.
Perhaps this threat meter could have sound effects that sound like shells whizzing by and exploding nearby.
A few pictures of fallen comrades whose iPhones have been hacked would also help drive the point home.
Yes, this would scare many Apple customers, but perhaps it's time that they realize that we're in a pitched battle, and they can't keep their heads in the sand anymore (!).

@_date: 2016-02-25 15:50:46
@_author: Henry Baker 
@_subject: [Cryptography] Hope Apple Fights This! 
I'm not suggesting that judges are idiots; even when they're non-techie, they're usually excellent judges of human character.
But the judge has to be convinced that you even have access to that pirated song, before your XOR argument will convince him.
You'll have to forgive me, but Tor more-or-less works -- at least it slows down some of the less sophisticated agencies & govts.
The ability to cryptographically mix data on the Internet from a wide variety of sources would require the NSA (or equivalent) to not only have access to all of that data (which they certainly do), but to also know what to do to correlate it all.
That problem is certainly at least O(nlogn) if not O(n^2), and last time I looked, data size was growing as O(1/w^2) [soon to be O(1/w^3)] while computer speed was growing as O(1/w), where w is line width.
Not even the NSA can beat that growth factor.

@_date: 2016-02-25 16:04:01
@_author: Henry Baker 
@_subject: [Cryptography] Kerckhoffs's principle ==? Turing Machine 
Either Kerckhoffs preceded Turing by a half century, or
Turing rediscovered Kerckhoffs's Principle in the form of
Turing Machine universality.
Kerckhoffs suggested that an entire crypto machine could
be considered a mathematical abstraction, where the only
thing missing for decryption was a "key", which Shannon
interpreted as a number of bits of information.
But with the advent of the (universal) Turing Machine,
the entire crypto machine could also be reduced to a
("small" constant-size) bit string, independent of the
amount of key & plaintext material to be processed.
Inverting this logic, every crypto machine is a
universal Turing Machine with a "key" which consists
of a particular crypto TM description, plus an initial
input tape with a fixed-size number of tape squares
containing the key, and another input tape consisting
of either the plaintext to be encrypted, or the
ciphertext to be decrypted.
In modern virtual machine terminology, you have a
computer with a hypervisor that boots up a particular
crypto program which you then feed with a key located
in a file system which the virtual machine has access
Thus, Turing's universal TM is a very mild extension of
Kerckoffs's Principle.

@_date: 2016-02-25 16:34:50
@_author: Henry Baker 
@_subject: [Cryptography] USG v. Apple, 
So Apple's reply is 9x the size of DOJ's motion.
And each motion refers to the previous ones, in a 7-swans-a-swimming sort of way.
A lot of trees will be sacrificed before this battle is over.

@_date: 2016-02-26 06:39:41
@_author: Henry Baker 
@_subject: [Cryptography] Apple: graphically show users that they are 
Yes, that would be a good start.
But noticing all the times that you're being scanned, all the x scripting attempts, etc., would also help.

@_date: 2016-02-26 07:15:10
@_author: Henry Baker 
@_subject: [Cryptography] USG v. Apple, 
I am not a lawyer, but (IANALB):
Most of Apple's argument claims that the All Writs Act isn't operative here.
"For example, if Apple can be forced to write code in this case to bypass security features and create new accessibility, what is to stop the government from demanding that Apple write code to turn on the microphone in aid of government surveillance, activate the video camera, surreptitiously record conversations, or turn on location services to track the phone's user?  Nothing."
Indeed.  Apple didn't just pull these examples out of thin air; the U.S. govt has engaged in each and every one of these activities in the past, both at the FBI criminal level and the NSA national security level.
So when is Apple going to offer a *hardware switch* that can turn off the microphone and the camera in such a way that no software can bypass this switch?
"If Apple creates new software to open a back door, other federal and state prosecutors -- and other government agencies -- will repeatedly seek orders compelling Apple to use the software to open the back door for tens of thousands of iPhones.  Indeed, Manhattan District Attorney Cyrus Vance, Jr., has made clear that federal and state governments want access to *every* phone in a criminal investigation."  [** indicates italics]
"By forcing Apple to write code to compromise its encryption defenses, the Order would impose substantial burdens not just on Apple, but on the public at large.  And in the meantime, nimble and technologically savvy criminals will continue to use other encryption technologies, while the law-abiding public endures these threats to their security and personal liberties -- an especially perverse form of *unilateral disarmament* in the war on terror and crime." [emphasis supplied]
"For example, under the same legal theories advocated by the government here, the government could argue that it should be permitted to force citizens to do all manner of things 'necessary' to assist it in enforcing the laws, like compelling a pharmaceutical company against its will to produce drugs needed to carry out a lethal injection in furtherance of a lawfully issued death warrant, or requiring a journalist to plant a false story in order to help lure out a fugitive, or forcing a software company to insert malicious code in its auto-update process that makes it easier for the government to conduct court-ordered surveillance."
Once again, Apple isn't pulling these examples out of thin air; the govt has done each of these things in past cases.
Apple does argue First and Fifth Amendment issues.
First Amendment.  Apple claims that writing new code is "speech", and "speech" cannot be compelled.  So far, Apple hasn't used the First Amendment to bar it or anyone else from using its crypto keys, but you know that that argument is coming.
Fifth Amendment.  Apple claims that DOJ is violating Apple's Fifth Amendment right to due process.
So far, Apple hasn't used a Third Amendment theory that placing govt-required code into a cellphone is equivalent to quartering soldiers:
"No Soldier shall, in time of peace be quartered in any house, without the consent of the Owner ..."

@_date: 2016-02-26 08:13:47
@_author: Henry Baker 
@_subject: [Cryptography] USG v. Apple, 
The All Writs Act also requires that the govt prove to the Court that the 3rd party's efforts are *required* -- i.e., that the govt has *exhausted* all other means to achieve the desired result.  In particular, that *all* departments of the govt have been consulted, and *none* of them has the required capabilities.
"Moreover, the government has not made any showing that it sought or received technical assistance from other federal agencies with expertise in digital forensics, which assistance might obviate the need to conscript Apple to create the back door it now seeks."
"Judge Orenstein [was] asking the government 'to make a representation for purposes of the All Writs Act' as to whether the 'entire Government', including the 'intelligence community', did or did not have the capability to decrypt an iPhone, and the government responding that 'federal prosecutors don't have an obligation to consult the intelligence community in order to investigate crime'."
If this interpretation of the All Writs Act is upheld, then the DOJ will have to consult with the intelligence community prior to compelling companies like Apple to decrypt phones.
It would be quite interesting for DOJ to publicly stipulate that NSA could (or could not) break into iOS 8 or 9.
This is truly a sticky wicket, since the intelligence community is generally prohibited from working on domestic issues.

@_date: 2016-02-26 16:17:40
@_author: Henry Baker 
@_subject: [Cryptography] USG v. Apple, 
mail.com>
Here's all you need to know about MSFT's Win10 in the role of "CI"; Bill Gates's MSFT flag should have a goatse on it.
(MSFT gives a whole new meaning to "going dark".)
Terry Halvorsen Orders Microsoft Windows 10 Updates on 4M DoD Seats
Posted By: Jane Edwardson: February 18, 2016
Terry Halvorsen, chief information officer of the Defense Department, has committed 4 million seats in the departments efforts to upgrade its information systems and devices to the Microsoft-built Windows 10 operating system.
Yusuf Mehdi, corporate vice president for Windows and devices group at Microsoft, writes in a blog entry posted Wednesday that the move aims to help DoD reduce information technology costs and improve IT processes.
Halvorsen said in a November 2015 memo that he expects the Pentagon to standardize and complete the Windows 10 OS deployment within a year in an effort to safeguard networks from cyber threats, Microsoft Federal CTO Susie Adams wrote in a separate article posted Wednesday.
Department of Defense directs DoD agencies to standardize on Windows 10
by Susie Adams, Chief Technology Officer, Microsoft Federal on February 17, 2016
Its no secret that government agencies require a level of safety and security that is unmatched in the enterprise market.  Constantly evolving security threats, managing continuous updates on multiple platforms and devices, and slow upgrade cycles are just a few of the challenges facing government CIOs who are looking to standardize and secure agency baseline systems.
To help reduce this burden, according to the Office of the DoD CIO, the U.S. Department of Defense (DoD) Secretary of Defense has directed all DoD agencies currently on legacy operating systems to standardize on Windows 10.  With deployments starting right away, all DoD agencies must upgrade approximately 4 million devices and systems with a goal of deploying within one year.  This is an unprecedented move for the DoD and the largest enterprise deployment of Windows 10 to date.
"Why users would want their location tapped and their every keystroke logged by a corporation for their own benefit sounds quite fishy; it is only applicable for individual users."

@_date: 2016-02-27 11:27:00
@_author: Henry Baker 
@_subject: [Cryptography] From Nicaragua to Snowden - why no national 
I'm sure that the upcoming WPP (scheduled to be passed in December'16 by the lame duck Senate persons looking for their next gigs) will fix all of this: China can have their 128-bit backdoored encryption, Hollywood can have their 8,000-bit DRM encryption, NSA can continue to surveil the world, and all the "little people" can go pound sand.

@_date: 2016-02-28 11:48:02
@_author: Henry Baker 
@_subject: [Cryptography] McAfee: NSA Juniper backdoor used by China to clean 
The NSA's back door has given every US secret to our enemies
John McAfee, Contributor Feb. 26, 2016, 11:46 AM
Deng Xiaoping, in 1979 - his second year as supreme leader of China - perceived a fundamental truth that has yet to be fully grasped by most Western leaders: Software, if properly weaponized, could be far more destructive than any nuclear arsenal.
Under Deng's leadership, China began one of the most ambitious and sophisticated meta- software development programs ever undertaken.
And what is meta-software?  It's the one science that the entire Western World has entirely overlooked.  It is a high level set of principles for developing software that are imperative if a nation is to survive in a cyberwar.
For example, programmers must constantly be audited.  Every line of code written by every programmer is audited by two senior programmers, and these auditors are rotated each month and the same two are never paired more than once.  You will see very clearly, later in this article, why such a principle is vital to a society's survival.
Another principal is that back doors into software can never, under any circumstances, be allowed.  Under Deng Xiaoping, the penalty for back doors, and for violating any of the meta- software principles, was death.
I will give an example of what happens in the real world when back doors are put into software.  On December 17th of last year, Juniper Networks - a major provider of secure network systems, who's customers include nearly every US government agency, announced that it had discovered two "unauthorized" back doors in its systems.
For those of my readers who do not understand how back doors are created - they can only be created by the manufacturers of the software.  There is, absolutely, no other way.
So, the company had to have a rogue employee in the software development department.  This much is clear.
It will also be clear, if you continue reading, who placed the rogue employee within Juniper Networks and why.
First, a little background: Juniper Networks has operations in more than 100 countries.  Around 50% of its revenue is from the United States, 30% are from EMEA and 20% are from Asia.  Over half of Juniper's customers are in parts of the world in which the NSA has extreme interest.
Now, a legitimate TOP-SECRET document.  Released by Anonymous and dated February 2011 reveals that the British spy agency GCHQ, with the knowledge and apparent cooperation of the NSA, acquired the capability to covertly exploit security vulnerabilities in 13 different models of firewalls made by Juniper Networks.
I hope we all understand now what "acquired the capability" means.  The NSA planted a programmer within Jupiter Networks.  The was no other way to "acquire" this capability.
Nothing new in this.  Black hat hackers have been planting themselves in target agencies for years.  It was just such a plant that brought down Ashley Madison last year.  So it's no surprise that the NSA uses this technique as well.
Of interest here is that Juniper announced that two back back doors were discovered in its system.  One of the back doors was code verifiable written by the NSA prior to 2011.
But what makes the Juniper backdoor even more interesting and notable is the fact that it appears to be based on another backdoor the NSA allegedly created years ago in the Dual_EC algorithm for its own secret use.
So, in 2011 he NSA surreptitiously got their back door into a powerful piece of security software used by many enemies of the US.  They could now monitor these enemies easily.
The Internet underground knew of these back doors within weeks of their release, and so did the Chinese, and so did the Russians.  An so did every hacker on the planet.  Monitoring changes within major software systems is the simplest if all things.  Every hacker toolkit contains a compare program that will outline all changes made to a piece of software by the manufacturer.  Disassembly tools tell the hacker what each change does.
So, while the NSA was monitoring our perceived Middle Eastern enemies, the Chinese and Russians, and god knows who else, were making off with every important secret in the US, courtesy of the NSA's back door.  The NSA failed to notice that 50% of Jupiter Network users were American, and the majority of those were within the US Government.
Last year alone, the Defense Department was hacked.  Using the NSA's back door the Chinese walked off with 5.6 million fingerprints of critical personnel.  The same back door was used to hack the Treasury Department on May 27th of last year in which millions of tax returns were stolen.  And again, our most devastating hack as a nation was the Office of Personnel Management hack, in which 22 million sensitive files were stolen.  The Chinese gained access through the Defense Department's Juniper Systems and then using inter-operability with the Personnel Office, took what they wanted.  Again, courtesy if the NSA's back door.
Whatever gains the NSA has made through the use of their back door, it cannot possibly counterbalance the harm done to our nation by everyone else's use of that same back door.
Now, consider this: if Juniper Networks had the foresight to follow the same procedures that the Chinese have been using for 35 years, none of this could have happened.  The programmer planted within Juniper by the NSA would have been audited by two senior coders.  They each would have read the code and immediately recognized the back door.  Management would be notified and the employee charged with a felony, where he would undoubtedly had snitched on the NSA.  The NSA could not possibly have engaged the assistance of the auditors because they would be randomly rotated.
Clever, these Chinese
The moral is this: we are at the very least, 20 years behind the Chinese, and by association with the Chinese and by copying them, the Russians as well.
We have to get our act together, and soon.  We can no longer act like children in a playground playing with real guns.  We have to grow up.  Our technology has outgrown us, because we have failed to grasp it's subtle implications.
What's good for the goose is good for the gander...  Nessa also loosed the Stuxnet, which taught a whole generation of nation-state hackers.
Michael Hayden now supports end2end strong encryption:

@_date: 2016-02-29 07:15:58
@_author: Henry Baker 
@_subject: [Cryptography] More back doors coming from FBI/DOJ/etc. 
FYI -- See comments at end.
On July 13, 2015, Deputies asked the encryption working group to
prepare for Principals' consideration guidance on (1) key trade-
offs identified through its analysis of possible technical
approaches; and (2) the lessons learned from that analysis. This document provides that assessment and further identifies
technical challenges for which the working group was unable to
identify solutions and potential policy principles that could
guide any engagement by the United States Government with
industry on encryption issues.  To facilitate Principals'
analysis and discussion, this document includes the four
technical approaches to implementing accessible encryption
developed by the working group developed.  However, these
approaches are intended as proofs-of-concept and Deputies agree
that the approaches should not be advanced as affirmative
Administration proposals or shared outside the United States
Lessons Learned.  Encryption working group participants have
identified four key lessons that should inform any consideration
of technical proposals to enable targeted lawful access to
encrypted data.
There is no "one-size-fits-all" technical approach.  No single
approach can enable access to encrypted information across all
media and providers.  Each type of encryption will require
unique technical approaches, and each particular company would
need to implement approaches specific to their implementation of
encryption in the products and services it offers.  Further,
enabling lawful access to some forms of encrypted data, should
companies be willing to do so, will be easier with some
implementations than others.
Different encryption implementations require different
approaches.  From a technical perspective, encryption can be
divided into three categories: the encryption of data stored on
devices held by consumers; the encryption of communications in
transit between parties; and the encryption of data stored in
remote locations (e.g., cloud-based storage of backups).  Each
type of encryption carries different security risks, policy
implications, and technical challenges - and maintaining clarity
in technical and policy discussions is essential to identifying
potential options.  For example, one approach to enabling access
to data on devices could be through limiting to only those with
physical access to the device, which reduces the security risks
of such access and limits the ability for abuse.  Similarly, the
nature of communications encryption poses particular challenges
to law enforcement access solutions that do not exist for stored
data (whether in the cloud or on devices)
Intended use cases should drive proposed technical approaches. Law enforcement may seek access to encrypted data in a variety
of scenarios, and the particular circumstances will
substantially change the requirements of how a provider might
enable that access.  For example, law enforcement seeking to use
encrypted data to stop an impending attack or crime needs rapid
access while law enforcement seeking to use data on a seized
device to make a case against a defendant could accept a slower
solution.  Similarly, efforts to compel access to encrypted data
held by sophisticated criminals like terrorists and organized
crime may be unsuccessful if the fact that such compulsion is
possible is widely known because such criminals will choose to
use inaccessible alternatives.  On the other hand,
unsophisticated criminals or individuals responsible for crimes
of passion, may be less likely to switch to technology products
and services that are inaccessible to law enforcement.
Technical approaches can be enforced in multiple ways.  The
technical requirements of a particular proposed solution (for
instance, that law enforcement may only access data on a single
device as part of each request) could be enforced in multiple
ways.  It could be enforced through a law, through Executive
branch policy, or through technological limitations built into
the device or service itself.  However, some technologists,
civil society, and companies may perceive any government access
as an attempt to obtain widespread, non-targeted access for bulk
collection purposes.  Accordingly, those communities almost
certainly will be unlikely to trust limitations enforced through
policy or law, and will be more likely to be satisfied by those
enforced through technology.
Technical Challenges.  The working group also identified several
technical challenges for which there is no clear solution. Although technical approaches to enable lawful access to
encrypted data may be able to mitigate some of the public safety
challenges posed by encryption, these challenges mean that
inaccessible encryption will always be available to malicious
Strong encryption is increasingly available in global technology
products and services.  Unlike the "crypto wars" of the 1990s,
encryption is no longer solely available to governments. Established companies and independent developers in many
countries around the world are developing encrypted products and
services.  Further, encryption can be implemented purely through
software and effective encryption implementations are
increasingly available in the public domain.  As a result,
encrypted products and services will always be available to
malicious actors, including in countries that do not adopt an
accessibility regime.
Encrypted products and services often use open source software
for implementation.  Many encryption solutions are open-source
projects developed by communities of volunteers that are based
in multiple countries.  For example, the predominant
implementation of the encryption protocol used to secure web
sites for e-commerce transactions is open source.  Most of these
solutions are made available free of cost, and are not
distributed by any single institution, but shared on a peer-to-
peer basis.  As a result, there may be no central authority that
can update these solutions to comply with any requirements for
implementing encryption in a manner that would support law
enforcement access.
Inaccessible encryption can be layered on top of accessible
encryption.  Because encryption solutions are often implemented
through software, individuals using a device with accessible
encryption can easily install an inaccessible software
encryption solution on the device.  For example, if Apple or
Google were to change their mobile phones to allow for
decryption of the device pursuant to lawful process, a user
could still download a mobile application that could allow for
encrypted communications (e.g., Skype).  Layered encryption
means that, even if all core U.S. services and devices have
accessible encryption, individuals will be able to defeat
attempts to access their information.
Proposed Policy Principles
Deputies agreed that attempts to build cooperation with
industry, vice proposing specific technical solutions, will
offer the most successful option for making progress on this
issue.  In particular, given industry and civil society's
combative reaction to government statements to date, any
proposed solution almost certainly would quickly become a focal
point for attacks and the basis of further entrenchment by
opposed parties.  Rather than sparking more discussion,
government-proposed technical approaches would almost certainly
be perceived as proposals to introduce "backdoors" or
vulnerabilities in technology products and services and increase
tensions rather build cooperation.
However, if the United States Government were to provide a set
of principles it intends to adhere to in developing its
encryption policy, such a document could spark public debate. Proposing such principles would not be without risk, as some
constituencies may not distinguish between principles and
specific technical approaches.  As a result, these principles
could come under attack, but could also serve to focus public or
private conversation on practicalities and policy trade-offs
rather than whether the government is seeking to weaken
encryption or introduce vulnerabilities into technology products
and services.
Based on the lessons learned from the initial technical review,
the encryption working group has developed a set of principles
that could guide the United States Government's engagement with
the private sector on encryption.  While all of the principles
should inform private discussions with industry, some, all, or
none of them could be incorporated into any public debate.
1.  No bulk collection.  Any approach to enable lawful access
should focus on enabling targeted - as opposed to bulk -
access to decrypted information.
2.  No unilateral government access.  Approaches should not
provide "golden keys" to government or allow government to
access decrypted information without the assistance of a
third party.
3.  Technologically-enforced limits. To  the extent possible,
approaches should rely on technology, rather than
procedural protections, to enforce constraints on
government access.
4.  International adoption.  The United States Government will
accept that any U.S.-proposed solution will be adopted by
other countries.
5.  Maximize security and minimize complexity.  Any
accessibility regime carries the inherent risk that a
malicious actor could exploit that accessibility for
malicious ends.  As a result, any accessibility regime
should be designed to minimize complexity (a key factor
that increases risk of vulnerability) and maximize
6.  Minimize impact of malicious exploitation.  No technical
approach can be implemented in a manner that guarantees
perfect security.  Accordingly, any accessibility regime
must be designed to limit the impact of a successful
exploit by a malicious actor.  For instance, a device
access regime that requires physical access to the device
would limit the impact of an exploit because a malicious
actor would have to have physical possession of a targeted
7.  Minimize negative impact on innovation.  Certain access
regimes could limit technical innovation by closing the
door to certain types of encryption solutions.  For
example, current best practices for communications
encryption requires that each new message be encrypted
using a distinct key - a principle called forward secrecy
that mitigates the consequences of an exploit by ensuring
that any single key only exposes a single communication.  A
technical approach that implemented accessible encryption
in a manner that makes forward secrecy impossible would
limit innovation and hamper efforts to better secure
communications.  In this vein, any accessibility
requirement should be designed in such a way that it
minimizes any negative impact on innovation.
8.  No "one size fits all" approach.  No single accessible
solution that could work for all types of encryption or all
developers.  Providers, not the government should be
responsible for determining how to design any feasible
approaches into their products and services.
Avoid undermining trust in security.  The modern Internet
ecosystem relies on all participants trusting the security
of their communications and data.  Any technical approach
should be tailored to avoid undermining this trust.
Technical "Proofs of Concept"
Technical experts in the working group developed several proof-
of-concept technical approaches that could theoretically enable
access to some types of encrypted data.  Working group
participants agreed that all of these proposals were technically
feasible, although they disagreed as to the value and viability
of each of the solutions.  Further, working group participants
agreed that these proposals should be seen as only examples, and
would need to go through substantial revision and refinement if
they were to be further pursued.
Provider-enabled access to encrypted devices based on physical
control of the device.  For this approach, providers would
modify the hardware of their devices to include an independent,
physical, encrypted port.  The provider would maintain a
separate set of keys for its customers' devices that would
enable it to decrypt those devices, but only if it had physical
access to the device itself.  If law enforcement seized an
encrypted device that it could not access, it would secure
lawful process from a U.S. court and submit the device itself,
along with the lawful process, to the provider.  The provider
would use its secondary key to unlock the device, and provide
the resulting data back to law enforcement.  Making a hardware
modification would impose significant cost on U.S.
manufacturers, but requiring physical access to enable
decryption substantially reduces the cybersecurity risk of a
secondary access point, and limits the risk of abuse by
malicious actors and foreign government entities.  This solution
would provide access only to devices (although some
communications stored on the device could be accessible as
well), and would not prevent a customer from installing a
secondary layer of encryption on top of the device encryptionS
Provider-enabled remote access to encrypted devices through
current update procedures.  Virtually all consumer devices
include the capability to remotely download and install updates
to their operating system and applications.  For this approach,
law enforcement would use lawful process to compel providers to
use their remote update capability to insert law enforcement
software into a targeted device.  Once inserted, such software
could enable far-reaching access to and control of the targeted
device.  This proposal would not require physical modification
of devices, and so would likely be less costly for providers to
implement.  It would also enable remote access, and make
surreptitious access much less costly.  However, its use could
call into question the trustworthiness of established software
update channels.  Individual users, concerned about remote
access to their devices, could choose to turn oft software
updates, rendering their devices significantly less secure as
time passed and vulnerabilities were discovered by not patched.
Remote access enabled only when multiple parties, each of which
holds a partial key, participate.  In this approach, a secondary
decryption key is divided across multiple recovery parties.
These parties would provide their sub-keys either to the
provider or to law enforcement under court order to enable
reconstruction of the encryption key and decryption of the data. This approach would enable remote and surreptitious access to
data stored both in devices and remote databases.  It would also
limit the risk of exploit by requiring any attacker to
infiltrate multiple recovery entities to secure a complete
recovery key.  However, it is important to note that this
approach would be complex to implement and maintain, as it would
require a network of independent recovery parties which could
then be validated by trusted third parties.
Remote access to data stored on encrypted devices enabled by
providers implementing a "forced backup" of the data to an
alternate, accessible location.  The approach relies on
providers being able to remotely backup information stored in an
encrypted location to a different location that is not
encrypted.  Pursuant to lawful process, the provider would turn
on remote backup, and provide the resulting backed-up
information to law enforcement.  This solution could be
implemented with notice to the customer (for instance, a dialog
box on their device could indicate that remote backup is being
enabled, and could indicate that it is happening in response to
a law enforcement request or not), or could be done
surreptitiously.  For many providers, enabling this proposal
would require designing a new backup channel, or substantially
modifying an existing channel.
Future FBI/DOJ/etc. initiatives will cycle through the options
listed above.  For example, the current Apple case selected this
"Provider-enabled remote access to encrypted devices through
current update procedures.  Virtually all consumer devices
include the capability to remotely download and install updates
to their operating system and applications.  For this approach,
law enforcement would use lawful process to compel providers to
use their remote update capability to insert law enforcement
software into a targeted device."

@_date: 2016-02-29 15:00:12
@_author: Henry Baker 
@_subject: [Cryptography] House Encryption Hearing statements online 
FYI --
Mar 01 2016
THE ENCRYPTION TIGHTROPE: BALANCING AMERICANS SECURITY AND PRIVACY
2141 Rayburn House Office Building
1:00 PM
Witness Panel 1
The Honorable James B. Comey
Federal Bureau of Investigation
Witness Panel 2
Mr. Bruce Sewell
Senior Vice President and General Counsel
Apple, Inc.
Sewell Written Testimony.pdf (86.7 KBs)
Ms. Susan Landau
Worcester Polytechnic Institute
Landau Written Testimony.pdf (259.0 KBs)
Mr. Cyrus R. Vance Jr.
District Attorney
New York County
Vance Written Testimony.pdf (177.3 KBs)

@_date: 2016-02-29 14:00:44
@_author: Henry Baker 
@_subject: [Cryptography] 9999 keys for this one iPhone 
(Fortran's 1-origin indexing set back software development by a full generation, and easily cost > $1 billion in SW errors.
Of course, why *math* people were using 1-origin indexing to begin with leaves me scratching my head.)
Why are you so sure that after you tested 0001-9999, then suddenly 0000 will open the iPhone?
Have you tested this theory?  Has Apple?
Your faith in SW development is misplaced.  I wish I had saved all the printouts from large companies with completely empty pages due to off-by-one errors; it would make a nice museum.
I doubt that Apple ever tested this particular 0001-9999, 0000 sequence, given the amount of time & work required.
Testing corner cases like -- I don't know -- ISIS-inspired murderer leaves iPhone that the FBI wants to open, e.g. -- is a little difficult to arrange, a priori; regression testing these cases for future SW updates produces a lot of orphans.
I would imagine that thorough testing for the next generation of "unhackable 2.0" iPhones will produce a huge number of dead iPhones; Apple may need to have a whole refurbishment line to desolder the CPU/enclave chips and replace them.

@_date: 2016-01-01 12:21:57
@_author: Henry Baker 
@_subject: [Cryptography] Alice, Bob, Eve, Mallory, Maxwell ??? 
Max (short for Maxwell).
Aaron (Error-un, get it?)
Aiden (Additive Noise?)
Austin (AWe-stiN, Additive White Noise ?)
Jack (for Hi-Jack, MITM, get it?)
Nick (stealing a connection, MITM, too British ??)
Cameron (for political attacks; obvious)
Chase (for an attacker who has lower latency !)
Anna (for anonymous)

@_date: 2016-01-02 06:50:41
@_author: Henry Baker 
@_subject: [Cryptography] Any Electrical Engineers here who know about noise 
Here's my problem:
I'm trying to characterize a 1x pad.
A 1x pad *adds* (modulo, but that shouldn't matter)
uniformly distributed "noise" (the "key") to the
"message" signal.
Classical filtering theory says that given a
noise spectrum, one can compute an optimal
filter to remove as much noise from the signal
as possible.
I'd like to go through this mathematical
exercise with modular addition and the
noise spectrum one might want for a key
distribution to show that such an
optimal filter *for this case* is the
identity -- i.e., even the optimal
filter can do *nothing* to remove any
"noise" -- i.e., the 1x pad random
I seem to recall ideas such as "Weiner
filters", and the like.

@_date: 2016-01-02 09:19:38
@_author: Henry Baker 
@_subject: [Cryptography] List of 64 open spec Single Board Computers 
FYI --
Ringing in 2016 with 64 open-spec, hacker friendly SBCs (Single Board Computers):
Community backed, open-spec SBCs vary wildly, from sub-$10 minimalists to octa-core powerhouses.
Here we present 64 Linux- and Android-friendly models.

@_date: 2016-01-02 12:34:26
@_author: Henry Baker 
@_subject: [Cryptography] Alice, Bob, Eve, Mallory, Maxwell ??? 
Got it!
*Nessa* (with her goldi-Locks)
Like its cousin Tessa, Nessa -- a shortening of Vanessa or Agnes or Anastasia among other possibilities -- is an attractive nickname that can stand on its own.

@_date: 2016-01-02 16:16:54
@_author: Henry Baker 
@_subject: [Cryptography] Alice, Bob, Eve, Nessa, Twein ?? 
I always assumed that Mallet == Ma Bell.
MALLET == MA beLL e T  ("T" being the NYSE symbol for ATT).
Yes, even though NSA uses every trick in the book (and
lots that aren't), we still need a name specific to MITM
attacks, given that they are now the easiest type of attack
in a TLS world.
I would propose "Nessa" (short for Vanessa) for a
canonical MITM-er.
Alternatively, "Twein"/"Twain" for a male MITM-er.

@_date: 2016-01-02 18:16:33
@_author: Henry Baker 
@_subject: [Cryptography] Any Electrical Engineers here who know about 
Actually XOR *is* linear.  The problem isn't linearity, but the "folding" that happens with modulo.
Consider a modular system [0..N), and a single message 0<=m<N and a single key 0<=k<N.
So long as p(K=k) is precisely uniform, i.e., p(K=k)=(1/N) for all k, then p(M+K=e)=(1/N), for all Eve's received messages e.
But without the folding from modulo, we no longer get uniformity from p(M+K=e).
I'm trying to see whether there is an analogy between this folding and *aliasing* (the really old fashioned kind prior to sampled digital signal processing).

@_date: 2016-01-03 05:01:20
@_author: Henry Baker 
@_subject: [Cryptography] Alice, Bob, Eve, Nessa, Twein ?? 
Fifi-Iris, perhaps?
She's a lovely girl separated by a common language.

@_date: 2016-01-04 10:51:19
@_author: Henry Baker 
@_subject: [Cryptography] Any Electrical Engineers here who know about 
mail.com>
Now *that's* a crypto party at my one-time pad!
Invite over Anna Chapman (who got caught using a 1x pad badly) while you're at it:

@_date: 2016-01-04 11:02:12
@_author: Henry Baker 
@_subject: [Cryptography] Any Electrical Engineers here who know about 
mail.com>
Ok, let me take a whack at a proof.
The noise has uniform spectral density, so the best matched filter would be a pure flat bandpass filter -- i.e., the identity filter.
But the Fourier transform of a flat filter (in our circular convolution world) is a single impulse of unknown phase.
Convolving that impulse simply samples/reconstructs the original signal.
So the best-matched filter improves the signal not a whit (!?!).

@_date: 2016-01-04 13:45:15
@_author: Henry Baker 
@_subject: [Cryptography] Dutch govt says no to encryption backdoors 
FYI -- I don't speak Dutch, and I couldn't even open the .docx file posted by the Dutch govt.
If someone here speaks Dutch, perhaps they can comment on what it says.
Alternatively, if someone could just post the ascii text, and I'll see what Google Translate can do!
Dutch govt says no to backdoors, slides $540k into OpenSSL without breaking eye contact
People need encryption to be safe and secure, says ministry
4 Jan 2016 at 20:28, Kieren McCarthy
The Dutch government has formally opposed the introduction of backdoors in encryption products.
A government position paper, published by the Ministry of Security and Justice on Monday and signed by the security and business ministers, concludes that "the government believes that it is currently not appropriate to adopt restrictive legal measures against the development, availability and use of encryption within the Netherlands."
The conclusion comes at the end of a five-page run-through of the arguments for greater encryption and the counter-arguments for allowing the authorities access to the information.
"By introducing a technical input into an encryption product that would give the authorities access would also make encrypted files vulnerable to criminals, terrorists and foreign intelligence services," the paper noted.  "This could have undesirable consequences for the security of information communicated and stored, and the integrity of ICT systems, which are increasingly of importance for the functioning of the society."
The formal position comes just months after the Dutch government approved a 500,000 ($540,000) grant to OpenSSL, the project developing the widely used open-source encryption software library.
The paper itself is a balanced read, although it is notable that more time is spent on highlighting the benefits of encryption and there is little of the fear-mongering that has marked out efforts to introduce backdoors into the United States and United Kingdom.
Encryption, it states, is "important for the confidence of people in digital products and services and for the Dutch economy in light of the rapidly evolving digital society."
It notes however that the "same encryption is a barrier to obtaining information necessary for investigation, intelligence and security services when attackers (including criminals and terrorists) are involved."
We'll always have Paris
The Paris attacks were the spark for the paper after public debate led to the House of Representatives formally asking for an official government position on encryption.
The paper references this fact, noting: "The recent attacks in Paris, where possible use was made of encryption by the terrorists, lead to the justified question: what is needed for investigation, and for intelligence and security services to provide good visibility into attack planning?"
Before getting to that point, however, the paper notes that encryption is crucially important in the modern era.  "The secure storage of passwords, to protect against loss or theft of laptops and secure storage of backups have been difficult without the use of encryption," it notes.
It also highlights internet banking, government communication with citizens including tax returns, the security of diplomatic and military communications, confidential business information, cloud computing, journalism, privacy and freedom of expression.
"Encryption ensures the confidentiality and integrity of communications and allows people to better protect themselves against espionage and cyber crime," it notes.  "These are fundamental rights and freedoms; security and economic interests stand to benefit."
However, it also notes that the same technology introduces "obstacles" in legitimate and important investigations into issues such as child abuse images, countering cyber attacks, tracking possible terrorist attacks and dealing with serious criminals.
It notes that while all citizens have a right to privacy of their communications, that these rights "are not absolute, which means that restrictions are permitted, provided they meet the requirements of the Constitution and the European Court of Human Rights."
But the ability to impinge those rights must be "proportional to the infringement," the paper concludes, and given the widespread nature and importance of encryption in the modern digital world, it cannot support a legally mandated backdoor.
And elsewhere?
Although the Dutch position is nuanced and firm, the government also has the luxury of not having real impact on the real world. As the paper notes, "the Dutch situation cannot be seen in isolation from the international context. Strong encryption software is increasingly available worldwide or already integrated into products or services."
Or in other words, there is nothing Holland can do about Google, Microsoft, Facebook or any of the other countless products used by its citizens to communicate online.
The UK government appears to be taking a firm line in the opposite direction, asking in legislation to be allowed access to all citizens' data.  But the most important debate rests in the United States, where the majority of the products and services used online stem from.
The encryption debate in the US became particularly heated toward the end of last year, with politicians and law enforcement again pushing for access to encrypted communications after having backed down a few months earlier in the face of an intransigent tech sector.  As 2015 was closing, Apple CEO Tim Cook again reiterated his line that he will not make the company's products crackable.
As things stand, the tech sector is refusing to provide a backdoor (although Google has been noticeably quiet on the issue), and politicians have instead put their faith into a vague formulation of the country's "best minds" coming up with a new, as yet unspecified solution.
This "magical thinking" is also present in the Dutch government's position, when it gives itself a get-out clause for future events.
"Given the importance of the investigation and prosecution of criminal offenses and the interests involved in national security ... we are required to look for new solutions."

@_date: 2016-01-04 15:28:08
@_author: Henry Baker 
@_subject: [Cryptography] Greenwald: NSA Targeted "The Two Leading" Encryption 
FYI -- The U.S. just shot itself in the chip...  Let's see; how many chip architects with green cards has the U.S. trained?  I guess they should now seek employment elsewhere.
A Redaction Re-Visited: NSA Targeted "The Two Leading" Encryption Chips
Glenn Greenwald 2016-01-04T22:47:14+00:00
On September 5, 2013, The Guardian, The New York Times and ProPublica jointly reported -- based on documents provided by whistleblower Edward Snowden -- that the National Security Agency (NSA) had compromised some of the encryption that is most commonly used to secure internet transactions.  The NYT explained that NSA "has circumvented or cracked much of the encryption, or digital scrambling, that guards global commerce and banking systems, protects sensitive data like trade secrets and medical records, and automatically secures the e-mails, Web searches, Internet chats and phone calls of Americans and others around the world."  One 2010 memo described that "for the past decade, NSA has led an aggressive, multipronged effort to break widely used Internet encryption technologies."
In support of the reporting, both papers published redacted portions of documents from the NSA along with its British counterpart, GCHQ.  Prior to publication of the story, the NSA vehemently argued that any reporting of any kind on this program would jeopardize national security by alerting terrorists to the fact that encryption products had been successfully compromised.  After the stories were published, U.S. officials aggressively attacked the newspapers for endangering national security and helping terrorists with these revelations.
All three newspapers reporting this story rejected those arguments prior to publication and decided to report the encryption-cracking successes.  Then-NYT Executive Editor Jill Abramson described the decision to publish as "not a particularly anguished one" in light of the public interest in knowing about this program, and ProPublica editors published a lengthy explanation along with the story justifying their decision.
All three outlets, while reporting the anti-encryption efforts, redacted portions of the documents they published or described.  One redaction in particular, found in the NYT documents, from the FY 2013 "black budget," proved to be especially controversial among tech and security experts, as they believed that the specific identity of compromised encryption standards was being concealed by the redaction.
None of the documents in the Snowden archive identify all or even most of the encryption standards that had been targeted, and there was a concern that if an attempt were made to identify one or two of them, it could mislead the public into believing that the others were safe.  There also seemed to be a concern among some editors that any attempt to identify specific encryption standards would enable terrorists to know which ones to avoid.  One redaction in particular, from the NYT, was designed to strike this balance and was the one that became most controversial:
The issue of this specific redaction was raised again by security researchers last month in the wake of news of a backdoor found on Juniper systems, followed by The Intercepts reporting that the NSA and GCHQ had targeted Juniper.  In light of that news, we examined the documents referenced by those 2013 articles with particular attention to that controversial redaction, and decided that it was warranted to un-redact that passage.  It reads as follows:
The reference to "the two leading encryption chips" provides some hints, but no definitive proof, as to which ones were successfully targeted.  Matthew Green, a cryptography expert at Johns Hopkins, declined to speculate on which companies this might reference.  But he said that "the damage has already been done.  From what I've heard, many foreign purchasers have already begun to look at all U.S.-manufactured encryption technology with a much more skeptical eye as a result of what the NSA has done.  That's too bad, because I suspect only a minority of products have been compromised this way."
NSA requested until 5 pm today to respond but then failed to do so.
Contact the author:
Glenn Greenwald
glenn.greenwald at theintercept.com

@_date: 2016-01-06 20:35:00
@_author: Henry Baker 
@_subject: [Cryptography] Chaum Has a Plan to End the Crypto War 
FYI --
'Chaum is also building into PrivaTegrity another feature that's sure to be far more controversial: a carefully controlled backdoor that allows anyone doing something "generally recognized as evil" to have their anonymity and privacy stripped altogether.'
Chaum's paper: cMix: Anonymization by High-Performance Scalable Mixing
Andy Greenberg  01.06.16. 7:00 am.
The Father of Online Anonymity Has a Plan to End the Crypto War
Julian Berman for WIRED
It's been more than 30 years since David Chaum launched the ideas that would serve as much of the groundwork for anonymity online.  In doing so, he also helped spark the debate that's endured ever since, over the anarchic freedoms that digital secrecy enables--the conflict between privacy advocates and governments known today as the "crypto wars."
Now Chaum has returned with his first online privacy invention in more than a decade.  And with it, he wants to bring those crypto wars to an end.
At the Real World Crypto conference at Stanford University today, Chaum plans to present for the first time a new encryption scheme he calls PrivaTegrity.  Like other tools Chaum has spent his long career developing, PrivaTegrity is designed to allow fully secret, anonymous communications that no eavesdropper can crack, whether a hacker or an intelligence agency.  But PrivaTegrity, which Chaum's been developing as a side project for the last two years along with a team of academic partners at Purdue, Radboud University in the Netherlands, Birmingham University and other schools, is meant to be both more secure than existing online anonymity systems like Tor or I2P and also more efficient; he claims it will be fast enough to work as a smartphone app with no perceptible delay.  Chaum wouldn't comment on whether the project, which has yet to be fully coded and tested, would be commercialized or run as a non-profit, but he says an alpha version for Android is in development that funct
ions as an instant-messaging app.  In future versions, Chaum and his collaborators plan to add features like larger file sharing for photos and video, the ability to follow Twitter-like feeds, and even financial transactions, all under the cover of strong anonymity with untraceable pseudonyms.  "It's a way to create a separate online reality," says Chaum, "One in which all the various things we now know people like to do online can be done in a lightweight manner under a completely different and new and very attractive privacy and security model."
That ambitious privacy toolset aside, Chaum is also building into PrivaTegrity another feature that's sure to be far more controversial: a carefully controlled backdoor that allows anyone doing something "generally recognized as evil" to have their anonymity and privacy stripped altogether.
Whoever controls that backdoor within PrivaTegrity would have the power to decide who counts as "evil"--too much power, Chaum recognizes, for any single company or government.  So he's given the task to a sort of council system.  When PrivaTegrity's setup is complete, nine server administrators in nine different countries would all need to cooperate to trace criminals within the network and decrypt their communications.  The result, Chaum argues, is a new approach that "breaks the crypto wars," satisfying both the law enforcement agencies who argue that encryption offers a haven for criminals, and also those who argue that it's necessary to hobble mass spying.
"If you want a way to solve this apparent logjam, here it is," says Chaum.  "We don't have to give up on privacy.  We don't have to allow terrorists and drug dealers to use it.  We can have a civil society electronically without the possibility of covert mass surveillance."
Inventing Anonymity
Chaum's quest for a shield against Internet surveillance began before most of the world was even aware of the Internet at all.  His inventions include the first-ever cryptocurrency, a 1990s venture known as DigiCash, and DC Nets, a scheme he invented in the early '80s to allow theoretically perfect anonymity within a group of computers.  But perhaps the most influential of Chaum's privacy ideas was an earlier, simpler scheme he called a "mix network," a term he coined in 1979.
Mix networks anonymize messages by encrypting them in layers and routing them through a series of computers that serve as intermediaries.  Each of those middlemen machines collects messages in batches, shuffles them, strips off one layer of their encryption that only that computer can decrypt, and then passes them on to the next computer in the chain.  The result is that no one, not even the individual intermediary computers themselves, can trace the messages from origin to destination.  Today, anonymity tools inspired by mix networks are used by everyone from the nearly 2 million inhabitants of the Tor anonymity network--whose messages are routed through a sort of mutated mix network of thousands of volunteer machines--to Bitcoin spenders hiding drug transactions on the Dark Web.
With PrivaTegrity, Chaum is introducing a new kind of mix network he calls cMix, designed to be far more efficient than the layered encryption scheme he created decades ago.  In his cMix setup, a smartphone communicates with PrivaTegrity's nine servers when the app is installed to establish a series of keys that it shares with each server.  When the phone sends a message, it encrypts the message's data by multiplying it by that series of unique keys.  Then the message is passed around all nine servers, with each one dividing out its secret key and multiplying the data with a random number.  On a second pass through the nine servers, the message is put into a batch with other messages, and each server shuffles the batch's order using a randomized pattern only that server knows, then multiplies the messages with another random number.  Finally, the process is reversed, and as the message passes through the servers one last time, all of those random numbers are divided out and replac
ed with keys unique to the message's intended recipient, who can then decrypt and read it.
Chaum argues that PrivaTegrity's setup is more secure than Tor, for instance, which passes messages through three volunteer computers which may or may not be trusted.  Unlike PrivaTegrity, Tor also doesn't deliver its messages in batches, a decision designed to allow fast Web browsing.  But that tradeoff means a spy who watches both ends of Tor's network of intermediary computers might be able to identify the same message going in one at one place and coming out at another, a problem PrivaTegrity batch system is designed to solve.
PrivaTegrity's protocol will be speedier than past attempts at implementing mix networks, Chaum claims.  That supposed efficiency comes from the fact that the collections of random numbers it uses, both before and after the messages are shuffled, can be precomputed and passed between the servers during moments when the servers are idle, instead of being created in real-time and slowing down conversations.  And because the entire cMix process is a series of simple multiplications and divisions, it's far faster than the public key computations necessary in older mix networks, says Aggelos Kiayas, a computer science professor at the University of Connecticut who's reviewed Chaum's system.  "It is well known that mix nets can be better than Tor in terms of privacy...The real question is latency," Kiayas writes in an email, cautioning that he can't fully judge the scheme's efficiency without seeing the final app.  "PrivaTegrity appears to be a decisive step forward in this direction."
A Backdoor Security Council
On top of those security and efficiency tricks, PrivaTegrity's nine-server architecture--with a tenth that works as a kind of "manager" without access to any secret keys--also makes possible its unique backdoor decryption feature.  No single server, or even eight of the nine servers working together, can trace or decrypt a message.  But when all nine cooperate, they can combine their data to reconstruct a message's entire path and divide out the random numbers they used to encrypt it.  "It's like a backdoor with nine different padlocks on it," Chaum says.
For now, Chaum admits the prototype of PrivaTegrity that he plans to distribute to alpha testers will have all its servers running in Amazon's cloud, leaving them open to the usual threats of American government surveillance, from subpoenas to National Security Letters.  But in the app's final version, Chaum says he plans to move all but one of those servers abroad, so that they're spread out to nine different countries, and require each server to publish its law enforcement cooperation policy.  Chaum won't yet detail his suggested privacy policies for those servers, but suggests that decryption and tracing could be reserved for "serious abuse, something that leads to death and real harm to people or major economic malfeasance."  Or perhaps the system could limit the frequency of covert traces to some number, such as 100 decryptions per year.  Chaum has yet to reveal the full list of the countries where PrivaTegrity would place its servers.  But he suggests they'll be in the juris
diction of democratic governments, and names Switzerland, Canada and Iceland as examples.
"It's like the UN," says Chaum.  "I don't think a single jurisdiction should be able to covertly surveil the planet...In this system, there's an agreement on the rules, and then we can enforce them."
The mere mention of a "backdoor"--no matter how many padlocks, checks, and balances restrict it--is enough to send shivers down the spines of most of the crypto community.  But Chaum's approach represents a bold attempt to end the stalemate between staunch privacy advocates and officials like FBI director James Comey, CIA deputy director Michael Morrell and British Prime Minister David Cameron who have all opposed tech companies' use of strong, end-to-end encryption.  Comey, Cameron, and Morell have lashed out at firms like Apple and Whatsapp, for instance, for using systems in which even the company itself doesn't possess the key to decrypt communications or stored data, and thus can't cooperate with law enforcement.  (Those same privacy features have earned the companies praise from privacy groups.) The debate between encryption fans and surveillance hawks has only intensified in the wake of ISIS's attacks in Paris, and in last month's Democratic presidential debate Hillary Clin
ton called for a "Manhattan-like Project" to develop a system that "would bring the government and the tech communities together."2
Most encryption experts insist, however, that any backdoor would lead to abuse by hackers, if not by the very law enforcement or national security agencies it was created for.  Chaum counters that spreading the keys to decrypt communications among nine servers would solve both of those problems, preventing abusive government surveillance and making his backdoor far harder to hack.  He suggests that the servers' administrator will eventually develop their own security protections and even distinct code to implement PrivaTegrity's protocol, avoiding any single bug that could be common to all nine nodes.  "These systems would be far more hardened than even corporate systems, and to abuse the backdoor you'd have to break all of them," he says.
Whether PrivaTegrity lives up to its efficiency and security promises will only become clear when the finished app is released, and Chaum himself, despite spending two years perfecting its crypto system, hasn't even tried the final demo of the app's private alpha.  He remains cagey about naming a date for releasing the public beta and publishing its code so that it can be scoured for flaws, but he says there's "no technical reason why it couldn't be ready for the first quarter of 2016."
If PrivaTegrity's reality matches Chaum's descriptions of its potential, he hopes it could serve as a model for how other encryption systems can protect innocent people from spying without offering impunity to criminals.  "You have to perfect the traceability of the evil people and the untraceability of the honest people," says Chaum.  "That's how you break the apparent tradeoff, this standoff called the encryption wars."
For more technical information on the cMix idea that PrivaTegrity will use, here's Chaum's and his co-authors' still-unpublished paper on the system:1
cMix: Anonymization by High-Performance Scalable Mixing
1Updated 1/6/2016 9:30am EST to embed the technical paper describing Privategrity's cMix system.
2Correction 1/6/2016 3:30pm EST: An earlier version of the story misspelled the name of FBI director James Comey.

@_date: 2016-01-07 07:05:55
@_author: Henry Baker 
@_subject: [Cryptography] FTC sues for crappy crypto 
FYI --
"If a company promises strong encryption, it should deliver it."
I'm not holding my breath waiting to see if the FTC will sue when a company is given a National Security Letter (NSL).
At last -- Feds crack down on crummy encryption  starting with your dentist
Uncle Sam finally gets his teeth into terrible technology
6 Jan 2016 at 20:58, Shaun Nichols
The US Federal Trade Commission (FTC) has struck a $250,000 settlement package in its case accusing a medical software developer of lying about its data encryption capabilities.
The makers of Dentrix G5, an office and records tool for dentists, had been accused of lying to customers about the encryption capabilities of the software, which in the process expose customer medical records and personal information.
The FTC said in its complaint [PDF] that Dentrix developers Henry Schein Practice Solutions told customers that the Dentrix Suite included security protections that would encrypt stored patient data and offer security protections in compliance with HIPAA rules.
In reality, the FTC claimed, the encryption tools used by the software were insufficient and did not meet their advertised capabilities.  The proprietary encryption tools were in 2013 described by Cert.org as "a weak obfuscation algorithm that may be unobfuscated without knowledge of a key or password."
Even after the company was notified of its weak encryption, the FTC charged, it continued to market Dentrix G5 with claims that the software provided strong encryption for patient records.
The FTC said in its complaint that by using the weak encryption methods, Dentrix not only misled customers about the capabilities of the product, but exposed patients to possible identity theft and data disclosure.
"An attacker who unmasks patients' sensitive personal information could subject patients to the unanticipated disclosure of personal information or use that information to commit identity theft, medical identity theft, or other harms," the FTC said in its complaint.
"If dentists were aware that Dentrix G5 used a form of data protection that was more vulnerable than widely-used, industry-standard encryption algorithms, they may have chosen to purchase another product."
Under the terms of the settlement [PDF], Henry Schein Practice Solutions will pay $250,000 to the FTC, who will then use the cash to refund customers.  The software developer will also be required to notify all offices who purchased the Dentrix G5 prior to January 2014, and submit to the FTC reviews of its financial records, advertising copy, and security research for the next five years.
"Strong encryption is critical for companies dealing with sensitive health information," FTC consumer protection bureau director Jessica Rich said of the settlement deal.
"If a company promises strong encryption, it should deliver it."

@_date: 2016-01-08 10:09:43
@_author: Henry Baker 
@_subject: [Cryptography] Plan to End the Crypto War 
Hmmm...  Sounds like the U.N., except no vetoes of the "Security Council".
All the small countries will vote to hear what's on Angela Merkel's phone....

@_date: 2016-01-09 07:35:53
@_author: Henry Baker 
@_subject: [Cryptography] Plan to End the Crypto War 
The whole point of Chaum's plan is to destroy the appearance of unanimity of the crypto community on the infeasibility of these "hackdoor" proposals.  It doesn't really matter at this point whether the Chaum plan works, just so long as it looks *plausible* to non-crypto people.
Those outside the crypto community can't distinguish good from bad proposals, so Chaum lends credence to the "Manhattan Project" idea -- which, by the way, will produce lots of funding for academic types as a sop to keep them from complaining so publicly.
I'm just cynical enough to suspect some RSA-type funding for Chaum to throw this monkeywrench.
NSA motto: "We listen to your prayers when your own God won't" (tm)

@_date: 2016-01-09 11:20:28
@_author: Henry Baker 
@_subject: [Cryptography] White House Raises Encryption Threat in Silicon 
FYI --
White House Raises Encryption Threat in Silicon Valley Summit
Jenna McLaughlin 2016-01-08T19:35:59+00:00
Top Obama administration officials are holding a summit meeting on counterterrorism on Friday in Silicon Valley with top tech executives, including Apple CEO Tim Cook.  The White House delegation includes Chief of Staff Denis McDonough, Attorney General Loretta Lynch, FBI Director James Comey, and Director of National Intelligence James Clapper.  "The goal here is to find additional ways to work together to make it even harder for terrorists or criminals to find refuge in cyberspace," White House Press Secretary Josh Earnest said at a news briefing.
The highly controversial topic of encryption is very much on the agenda, according to excerpts from a White House briefing distributed to participants of the summit, obtained by The Intercept.
Read the excerpts below:
   In addition to using technology to recruit and radicalize, terrorists are using technology to mobilize supporters to attack and to plan, move money for, coordinate, and execute attacks.  The roles played by terrorist leaders and attack plotters in this activity vary, ranging from providing general direction to small groups to undertake attacks of their own design wherever they are located to offering repeated and specific guidance on how to execute attacks.  To avoid law enforcement and the intelligence community detecting their activities, terrorists are using encrypted forms of communications at various stages of attack plotting and execution.  We expect terrorists will continue to use technology to mobilize, facilitate, and operationalize attacks, including using encrypted communications where law enforcement cannot obtain the content of the communication even with court authorization.  We would be happy to provide classified briefings in which we could share additional info
   Key Questions: We are interested in exploring all options with you for how to deal with the growing threat of terrorists and other malicious actors using technology, including encrypted technology, to threaten our national security and public safety.  We understand that there is no one-size-fits-all solution to address this problem and that each of you has very different products and services that work in different ways.  Are there high-level principles we could agree on for working through these problems together?  And are there technologies that could make it harder for terrorists to use the internet to mobilize, facilitate, and operationalize?  Or easier for us to find them when they do?  What are the potential downsides or unintended consequences we should be aware of when considering these kinds of technology-based approaches to counter terrorism?
    ==
   A number of organizations in the government, as well as some in private industry and academia, have researched techniques to detect and measure radicalization.  Some have suggested that a measurement of level of radicalization could provide insights to measure levels of radicalization to violence.  While it is unclear whether radicalization is measureable or could be measured, such a measurement would be extremely useful to help shape and target counter-messaging and efforts focused on countering violent extremism.  This type of approach requires consideration of First Amendment protections and privacy and civil liberties concerns, additional front-end research on specific drivers of radicalization and themes among violent extremist populations, careful design of intervention tools, dedicated technical expertise, and the ability to iteratively improve the tools based on experience in deploying them.  Industry certainly has a lot of expertise in measuring resonance in order to s
ee how effective and broad a messaging campaign reaches an audience.  A partnership to determine if resonance can be measured for both ISIL and counter-ISIL content in order to guide and improve and more effectively counter the ISIL narrative could be beneficial.
    ==
   The United States recognizes the need to empower credible non-governmental voices that would speak out against ISIL and terrorism more broadly both overseas and at home.  However, there is a shortage of compelling credible alternative content; and this content is often not as effectively produced or distributed as pro-ISIL content and lacks the sensational quality that can capture the medias attention.  Content creation is made difficult by ISILs brutal rule and near total control of communications infrastructure in its territory in Iraq and Syria, which can make it dangerous for citizens to speak out or provide video or images.  Further, many of the leading and credible voices that might counter ISIL lack the content-generation and social media prowess that would be required to counter ISIL online.  There is also a need for more credible positive messaging and content that provides alternatives to young people concerned about many of the grievances ISIL highlights.
   In parallel with ongoing U.S. Government efforts, we invite the private sector to consider ways to increase the availability alternative content.  Beyond the tech sector, we have heard from other private sector actors, including advertising executives, who are interested in helping develop and amplify compelling counter-ISIL content; and we hope there are opportunities to bring together the best in tech, media, and marketing to work with credible non-government voices to address this shared challenge.
Contact the author: Jenna McLaughlin jenna.mclaughlin at theintercept.com

@_date: 2016-01-09 11:45:03
@_author: Henry Baker 
@_subject: [Cryptography] LED DICE -- random??? 
FYI -- Looks like it would be trivial to "load" these dice using heavier "batteries".
Replaceable Battery - You can change the batteries easily.
Just unscrew the top and take out the old batteries and put in the new ones.
It uses two small 'SR54' batteries which are sold at supermarkets and you can buy on Amazon for less than $2!

@_date: 2016-01-10 12:09:48
@_author: Henry Baker 
@_subject: [Cryptography] OpenSSL minimal "safe" configuration? 
I was trying to build OpenSSL with a minimal, "safe" configuration.
By "safe", I mean using the latest/best algorithms, and *deleting* all the known-to-be-unsafe algorithms.
However, I can't seem to build OpenSSL w/o DES, w/o MD5, etc.
I'd also like to kill off the shorter versions -- e.g., AES-128.
I think I can eliminate AES entirely, but how do you get rid of just AES-128?

@_date: 2016-01-10 14:09:17
@_author: Henry Baker 
@_subject: [Cryptography] Australia commits encryption suicide 
Perhaps it's time to downgrade *all* HTTPS connections to Australia
to 512 (RSA) bits, *especially all banking, credit card & financial
See Alfie's 2nd link below for more details.
I'm afraid it's going to take several *billion-dollar losses* from
Russian/Chinese/NKorean criminals before these politicians wake up.
It's also time to start developing a new crypto institute in a neutral
non-paranoid country.  Yes, such countries are becoming rarer, but not
yet extinct.

@_date: 2016-01-11 07:37:42
@_author: Henry Baker 
@_subject: [Cryptography] Plan to End the Crypto War 
As was pointed out on techdirt.com,
"...nine server administrators..." is a dog whistle (or
subliminal cry for help, see
I have a friend (name redacted) who once did a post-doc
in a country (name redacted) many, many years ago, which
country was experiencing some "turbulence".  Prior to his
departure to said country, the CIA offered him some
"assistance", which he turned down because he felt it
would compromise his principles and make it more difficult
for him to interact with the citizens of said country. However, he found that when he arrived, *everyone* assumed
that he was working for the CIA anyway -- probably due to
his different ethnicity and religion -- and so in retrospect,
he should have gone ahead and taken the CIA's offer of
Perhaps Chaum should go ahead & collect his $200.

@_date: 2016-01-11 08:19:19
@_author: Henry Baker 
@_subject: [Cryptography] [Crypto-practicum] Request: making the archives 
ine.com>
Here's one reason why the Aussies want "open publication".  Wanna bet that
*encrypting communications*, or even *talking about encryption* will raise
your 'threat' score?
A bad FICO score could kill your chances of getting a mortgage.  A bad 'Beware' score could kill you, dead.
'Another program, called Media Sonar, crawled social media looking for illicit activity.'
'But perhaps the most controversial and revealing technology is the threat-scoring software Beware. ... The searches return the names of residents and scans them against a range of publicly available data to generate a color-coded threat level for each person or address: green, yellow or red.  Exactly how Beware calculates threat scores is something that its maker, Intrado, considers a trade secret, so it is unclear how much weight is given to a misdemeanor, felony or threatening comment on Facebook.  However, the program flags issues and provides a report to the user.'
'Councilman Clinton J. Olivier, a libertarian-leaning Republican, said Beware was like something out of a dystopian science fiction novel and asked Dyer a simple question: "Could you run my threat level now?"  Dyer agreed.  The scan returned Olivier as a green, but *his home came back as a yellow,* possibly because of someone who previously lived at his address, a police official said.'
'"[Beware] has failed right here with a council member as the example."'
The new way police are surveilling you: Calculating your threat 'score'
By Justin Jouvenal, January 10 at 8:13 PM

@_date: 2016-01-11 09:57:15
@_author: Henry Baker 
@_subject: [Cryptography] OpenSSL minimal "safe" configuration? 
I noticed that OpenSSL uses only 1 core, even when "no-threads" is *not* specified.
Although thread libraries seem to get loaded, the heavy computation is still only done by one core.
I presume that this is to counter some attack?
Is there a link/reference to this attack?

@_date: 2016-01-11 10:26:00
@_author: Henry Baker 
@_subject: [Cryptography] A possible alternative to TOR and PrivaTegrity 
mail.com>
Determining 'evil behavior' is undecidable.  Therefore all such "Golden Key" solutions are doomed.  Politicians had better get over it.
The Trolley Problem is old enough that it was considered an ethical problem *for the human operator*.  Nowadays, people are expecting the Trolley itself to solve the ethical problem (or the self-driving car, or the "smart" gun, or the "smart" phone, or the "smart" crypto protocol).  Obama's mythical "smart gun" epitomizes this god-like wishful thinking; a "smart gun" in the hands of police will eliminate all unnecessary (in the cold light of Monday morning, of course) police shootings.
Following Godwin's Law, I should point out that the Nazis felt that they had finally achieved an ethical solution to a problem that had vexed the international intelligentsia for generations.  The eugenics movement (including those in the U.S.) went all quiet after the embarrassment of WWII, wherein the Nazis had simply followed through on the eugenicists' wet dreams with cold precision.
I daresay it would not have been difficult to satisfy Chaum's criteria prior & during WWII in the furtherance of various war crimes.
The whole point of the First, Second, Fourth, Fifth Amendments is to constrain govts *when it's difficult*.  No one needs Constitutional protections when it's easy!

@_date: 2016-01-11 15:19:35
@_author: Henry Baker 
@_subject: [Cryptography] OpenSSL minimal "safe" configuration? 
Do any of the existing open source tls/ssl implementations use multiple cores?

@_date: 2016-01-11 17:42:59
@_author: Henry Baker 
@_subject: [Cryptography] Skylake fails on Mersenne Prime 14942209 exponent 
FYI -- The fishy part of this story is the fact that Intel claims this bug can be fixed with a "BIOS update".  If true, this is proof positive that the arithmetic unit of these Intel processors can be hacked in essentially invisible ways by (van) Nessa.
Simple instructions for freezing a Skylake Processor.
on Dec 14, 2015 in Processors
The people at the community over at  have found what appears to be a bug in the new Skylake architecture that can freeze any system that has a Skylake processor.
The Mersenne community are a bunch of mathematicians and other folks that use Intel processors to find record prime numbers. They have found all the record prime numbers of the last 20 years.
The main website of the community is  where they keep track of all progress in searching for a new record prime number.
Owners of Skylake systems have found out that the software package that they use to hunt for prime numbers will freeze their system if they use particular settings. Since this bug is reproducible and has been confirmed on motherboards of many different suppliers and with RAM modules of different suppliers the bug seems to be tied to the processor architecture. The bug is reproducible under Windows and Linux.
This software works perfectly normal on all other Intel processors of past generations.
Steps to freeze your Skylake system:
- Download and install Prime95 for Windows on a Skylake system from the website at   (If you want to familiarize yourself with the software use the readme, a background in math will be helpful, but is not needed.)
- In the menu go to 'Advanced | Test' and fill in the number 14942209 in the box labeled 'Exponent to test'
- Let the program run for some time and at some point, minutes or hours, the system will freeze.
The prime95 software does multiplications of extreme high numbers using the Fast Fourier Transformation. The implementation of these FFT's in prime95 is handcoded in assembly by George Woltman, and is the most efficient implementation available. This project runs for more than 20 years now and has always been carefully maintained. Tens of thousands of machines run this software 24 hours a day.
For optimization, different FFT sizes have been implemented in Prime95, only the FFT with length 768K freezes the Skylake.
It is my fear that like the infamous FDIV bug this issue will require a new stepping and a product recall, since this has security implications as well.
If you have a Skylake system I invite you to try out the steps above. Please post your findings here and in the mersenneforum at

@_date: 2016-01-12 07:13:34
@_author: Henry Baker 
@_subject: [Cryptography] Norbert Tihanyi: How to Backdoor OpenSSL's key 
FYI -- In case you weren't paranoid enough, already...
Generate 2048-bit primes p, s.t. p-1 has only small factors.
Factorized by Pollard in a few minutes on a laptop.  Bzzzzt!!!
Get Comodo to issue you a (really weak) certificate.  Double Bzzzzt !!!
Qualsys SSL Labs gives it an A+ rating.
Norbert Tihanyi  Modification of the prime generation method of the OpenSSL library
Published on Dec 21, 2015
Random numbers are very important in many fields of computer science, especially in cryptography.  One of the most important usages of pseudorandom number generators (PRNG) are is key generation methods for cryptographic purposes.  In this presentation a modification of the prime generation method of the OpenSSL library will be presented.  The modified version of the library passes every well-known statistical tests (e.g NIST test, DIEHARD test), however while an adversary is still able to reconstruct the prime numbers (P,Q) from the public key.  The method can be used for malicious purposes as a sophisticated backdoor.
The presented research is based on the theory of kleptography and a recently published research paper.

@_date: 2016-01-12 09:20:43
@_author: Henry Baker 
@_subject: [Cryptography] Skylake fails on Mersenne Prime 14942209 exponent 
*Any* such fault can be used to extract information; the ability to
adjust timing delays can allow the leaking of the key bits.  See
"Torturing OpenSSL".  While this particular side-channel has since
been closed, other similar side-channels likely still remain.
Black Hat USA 2012 - Torturing OpenSSL
Published on Oct 15, 2013
By: Valeria Bertacco
For any computing system to be secure, both hardware and software have to be trusted.
If the hardware layer in a secure system is compromised, not only it is possible to extract secret information about the software, but it is also extremely difficult for the software to detect that an attack is underway.
This talk will detail a complete end-to-end security attack to on a microprocessor system and will demonstrate how hardware vulnerabilities can be exploited to target systems that are software-secure.
Specifically, we present a side-channel attack to the RSA signature algorithm by *leveraging transient hardware faults* at the server.
Faults may be induced via voltage-supply variation, temperature variation, injection of single-event faults, etc.
When affected by faults, the server produces erroneous RSA signatures, which it returns to the client.
Once a sufficient number of erroneously signed messages is collected at the client end, we filter those that can leak private key information and we use them to extract the private key.
We developed an algorithm to extract the private RSA key from messages affected by single-bit faults in the multiplication during Fixed Window Exponentiation (FWE), that is, the standard exponentiation algorithm used in OpenSSL during RSA signing.
Our algorithm was inspired by a solution developed by Boneh, et al. for the Chinese Remainder Theorem (CRT) [D. Boneh, R. DeMillo, and R. Lipton.
On the importance of eliminating errors in cryptographic computations. Journal of Cryptology, Dec 2001], an algorithm particularly prone to attacks.
Depending of the window size used in the encryption algorithm, it is possible to extract 4-6 bits of the private key from an erroneously signed message.
Our attack is perpetrated using a FPGA platform implementing a SPARC-based microprocessor running unmodified Linux and the OpenSSL authentication library.
The server provides 1024-bits RSA authentication to a client we control via Ethernet connection.
Faults are injected by inducing variations in the supply voltage on the FPGA platform or by subjecting the server to high temperatures.
Our client collects a few thousands signed messages, which we transfer to an 80-machines computing pool to compute the private RSA key in less than 100 hours.
Note that our attack does not require access to the victim system's internal components, but simply proximity to it.
Moreover, it is conceivable that an attack leveraging solely high temperatures can be carried out on machines in a remote poorly-conditioned server room.
Finally, the attack does not leave any trail of the attack in the victim machine, and thus it cannot be detected.
The presentation includes a live demo of the attack on an FPGA platform implementing a SPARC system.
The system is powered via a voltage controller, used to induce variations in the supply voltage.
The server is simplified to use a 128-bits private key so that the attack can be perpetrated during the briefing.

@_date: 2016-01-12 09:44:30
@_author: Henry Baker 
@_subject: [Cryptography] French to unilaterally disarm through weak encryption 
FYI -- ISIS and the criminal hackers can't wait...
French government considers law that would outlaw strong encryption
By Patrick Howell O'Neill
Jan 12, 2016, 5:45am CT | Last updated Jan 12, 2016, 9:30am CT
The French Parliament is considering a legislative provision that would ban strong encryption by requiring tech companies to configure their systems so that police and intelligence agencies could always access their data.
The amendment to the vast "Digital Republic" bill was introduced in the French National Assembly, parliament's lower house, by eighteen politicians from the conservative Republican Party. The Digital Republic bill, which covers everything from net neutrality to the online publication of scientific research, will be examined and debated this week along with 400 amendments to it.
The anti-encryption amendment is largely seen as a response to the two deadly Paris terrorist attacks in 2015, despite the fact that the attackers repeatedly used unencrypted communications in the leadup to the killings.
Authorities still don't fully know how the terrorists planned their operations, but the ISIS-inspired militants signaled the start to the Nov. 13 attacks through unencrypted text messages.  They also traded unencrypted phone calls with senior operatives elsewhere in Europe.  French authorities say that some blind spots remain due to encrypted messaging services like Telegram.
In the weeks since the November attacks, the French government has come under sustained criticism for sacrificing liberty for security.  The country has been in a state of emergency for two months, a legal status that gives President Franois Hollande vast new law-enforcement powers.
The Digital Republic bill came just as the Netherlands issued a statement in favor of strong encryption, promising not to weaken it for investigative purposes.
It's unclear whether the encryption amendment would have prevented either of the Paris terrorist attacks.
"The attackers were all known to the police and intelligence services!" the security researcher calling himself "the Grugq" told the Daily Dot.  "Al Qaeda fretted constantly about finding 'clean skins,' new terrorists who weren't known to security forces.  ISIS publishes a magazine featuring an interview and [a] huge photograph of the cell leader's face.  Then they send him into Europe and he does just what he said he would do in his interview.  There is little that can be blamed on encryption here."
Encryption is technology that scrambles data so that only those people who have the keys can unscramble it.  It is part of many commonplace Internet activities like commerce and communications.
Many Apple iOS and Google Android devices are now encrypted by default, a move that has reignited a global debate over privacy and encryption because of the technology's use by cybercriminals, terrorists, and sexual predators.  Encryption advocates point to its use by human rights activists, journalists, governments, and tech companies seeking to avoid surveillance and hackers.
The new French bill briefly praises encryption's role in protecting user data but immediately pivots to criticizing the effects of strong encryption on state security forces.
"France must take the initiative and force device manufacturers to take into consideration the imperative of access for law enforcement officers, under the control of a judge and only in the case of an investigation, to those devices," the legislation reads, according to a translation by Khalil Sehnaoui, a Middle-East security specialist and founder of Krypton Security.  "The goal is to avoid that individual encryption systems delay the advancement of an investigation."
Technologists and open-Internet advocates disagree, arguing that strong encryption--which even the tech companies themselves cannot break--is a crucial part of online privacy and security.
Tech executives like Apple CEO Tim Cook warn that building weaknesses into cryptography will help hackers and hurt average Internet users.
"Let me be crystal clear: Weakening encryption or taking it away harms good people who are using it for the right reason," he argued last year.
Cook and a bevy of tech executives met with U.S. officials last week to discuss how to fight terrorists on social media; encryption briefly came up at the meeting, according to a senior administration official.
Update 6:05am CT, Jan. 12: Updated translation.

@_date: 2016-01-12 10:29:52
@_author: Henry Baker 
@_subject: [Cryptography] 200 experts line up to tell governments to get 
You can sign the letter yourself here:
200 experts line up to tell governments to get stuffed over encryption
No laws, policies or secret agreements with companies, urge crypto-eggheads
11 Jan 2016 at 20:09, Kieren McCarthy
A group of 200 experts have urged the world's governments not to introduce backdoors into encryption products in an open letter posted Monday.
The group, which includes Amnesty International, Human Rights Watch, the Electronic Frontier Foundation (EFF), the American Civil Liberties Union (ACLU) and CloudFlare among many others, formed as the debate about encryption has intensified.  The Obama Administration met tech giants in Silicon Valley last week in an effort to find a compromise and as the UK government tries to pass legislation that would give security services access to encrypted data.
The letter addresses itself to "the leaders of the world's governments" and urges them to support encryption as a way to "protect the security of your citizens, your economy, and your government."
Echoing sentiments expressed by the Dutch government in a formal position on encryption that was published last week, the group notes that "economic growth in the digital age is powered by the ability to trust and authenticate our interactions and communicate and conduct business securely, both within and across borders."
As such, it argues that all governments should "reject laws, policies, or other mandates or practices, including secret agreements with companies, that limit access to or undermine encryption and other secure communications tools and technologies."
The letter, which was posted on a new campaign website at SecureTheInternet.org, ends with a five-point argument that government should:
* Not limit access to encryption
* Not mandate backdoors
* Not require that third parties have access to encryption keys
* Not try to weaken encryption standards
* Not pressure companies into breaking any of the previous four points
While the list is odd in that it appears to make the same point repeatedly, the reality is that US politicians and law enforcement agencies have recently been pushing tech companies such as Apple, Google and Microsoft to create systems by which the security services can access information sent through their products and services, but have been very careful to avoid using the term "backdoor."
Apple CEO Tim Cook has been particularly vocal about the fact that introducing any backdoor into an encryption product means that it will be accessible by others.  The term "magical thinking" to imagine any other scenario has even been used by the law enforcement officials that want to access encrypted data.
When is a backdoor not a backdoor?
The Obama Administration also recently ruled out any possibility of legislation passing through Congress that would mandate government access.
That has led to a curious formulation from politicians about the need for the "best minds" to come together and develop a system that works.  Or, in other words, to create a backdoor of some kind that doesn't have to be called a backdoor.  The wording of the letter is intended to cover all possible scenarios.
The encryption debate itself kicked off shortly after Edward Snowden revealed the extent to which the US security services were spying on internet communications, even tapping the networks and data centers of large tech companies like Google without informing them.
In one specific response that really set the ball rolling, Apple changed the way it carried out encryption on its iPhone so that users were in control of the system and it was simply not possible to de-encrypt messages, even if it were presented with a legal warrant.
That approach put law enforcement on edge, and there has been a huge pushback on the approach in the hope that it can be stopped before it becomes the default approach by tech companies.
In the meantime, those who want access to encrypted communications, including most notably US presidential candidates, have been using the gun attacks in Paris and San Bernardino to argue the case for access, even though there is no evidence that encryption played a role in those attacks.
The groups behind the open letter are encouraging others to sign it  something that it appears many people online are hoping to do: the website fell over earlier today due to demand.
The letter itself:
To the leaders of the world's governments --
We urge you to protect the security of your citizens, your economy, and your government by supporting the development and use of secure communications tools and technologies, rejecting policies that would prevent or undermine the use of strong encryption, and urging other leaders to do the same.
Encryption tools, technologies, and services are essential to protect against harm and to shield our digital infrastructure and personal communications from unauthorized access.  The ability to freely develop and use encryption provides the cornerstone for today's global economy.  Economic growth in the digital age is powered by the ability to trust and authenticate our interactions and communicate and conduct business securely, both within and across borders.
Some of the most noted technologists and experts on encryption recently explained (PDF) that laws or policies that undermine encryption would "force a U-turn from the best practices now being deployed to make the Internet more secure," "would substantially increase system complexity" and raise associated costs, and "would create concentrated targets that could attract bad actors."  The absence of encryption facilitates easy access to sensitive personal data, including financial and identity information, by criminals and other malicious actors.  Once obtained, sensitive data can be sold, publicly posted, or used to blackmail or embarrass an individual.  Additionally, insufficiently encrypted devices or hardware are prime targets for criminals.
The United Nations Special Rapporteur for freedom of expression has noted, "encryption and anonymity, and the security concepts behind them, provide the privacy and security necessary for the exercise of the right to freedom of opinion and expression in the digital age."  As we move toward connecting the next billion users, restrictions on encryption in any country will likely have global impact.  Encryption and other anonymizing tools and technologies enable lawyers, journalists, whistleblowers, and organizers to communicate freely across borders and to work to better their communities.  It also assures users of the integrity of their data and authenticates individuals to companies, governments, and one another.
We encourage you to support the safety and security of users by strengthening the integrity of communications and systems.  All governments should reject laws, policies, or other mandates or practices, including secret agreements with companies, that limit access to or undermine encryption and other secure communications tools and technologies.  Users should have the option to use -- and companies the option to provide -- the strongest encryption available, including end-to-end encryption, without fear that governments will compel access to the content, metadata, or encryption keys without due process and respect for human rights.  Accordingly:
* Governments should not ban or otherwise limit user access to encryption in any form or otherwise prohibit the implementation or use of encryption by grade or type;
* Governments should not mandate the design or implementation of "backdoors" or vulnerabilities into tools, technologies, or services;
* Governments should not require that tools, technologies, or services are designed or developed to allow for third-party access to unencrypted data or encryption keys;
* Governments should not seek to weaken or undermine encryption standards or intentionally influence the establishment of encryption standards except to promote a higher level of information security. No government should mandate insecure encryption algorithms, standards, tools, or technologies; and
* Governments should not, either by private or public agreement, compel or pressure an entity to engage in activity that is inconsistent with the above tenets.
Strong encryption and the secure tools and systems that rely on it are critical to improving cybersecurity, fostering the digital economy, and protecting users.  Our continued ability to leverage the internet for global growth and prosperity and as a tool for organizers and activists requires the ability and the right to communicate privately and securely through trustworthy networks.
We look forward to working together toward a more secure future.
Jacob Appelbaum,      Collin Anderson,       Matt Blaze,       Paul Bernal,       Owen Blacker,       Eva Bognar,       Sara Sinclair Brody,      Eric Burger,       Jon Callas,      L. Jean Camp,       Ronald Deibert,       Lina Dencik,       Thomas Drake,       Dr. Suelette Dreyfus,       David Evans,       Jim Fruchterman,       Arzu Geybullayeva,       Mike Godwin,       Matthew Green,      Joseph Lorenzo Hall,       Arne Hintz,      Deborah Hurley,       Birgitta Jonsdottir,      David Kaye,      Ephraim Percy Kenyanito,      Eric King,      John Kiriakou,       Douwe Korff,      Ryan Lackey,      Susan Landau,      Frank La Rue,     Timothy Libert,      Rebecca MacKinnon,     Morgan Marquis-Boire,      Maxigas,      Bailey McCann,      Andrew McLaughlin,      Sascha Meinrath,      Eric Mill,      Katie Moussouris,      Jacobo Njera,      Nikhil Pahwa,      Chip Pitts,      Jesselyn Radack,      Jess Robles Maloof,      Phillip Rogaway,      Marc Rotenberg,      Bruce Schnei
er,      Gbenga Sesan,      Micah Sherr,      Adam Shostack,      Barbara Simons,      Norman Solomon,      Tim Sparapani,      Ritu Srivastava,      Maria Swietlik,      Nabiha Syed,      Trevor Timm,      Kenneth White,      Meredith Whittaker

@_date: 2016-01-13 10:27:14
@_author: Henry Baker 
@_subject: [Cryptography] NSA kids characters: Crypto Cat, Decipher Dog, 
FYI -- I guess that since these characters are all *trademarked* by Nessa, that the NSA wouldn't be amused if they started showing up as characters on slides at BlackHat, etc.
I'll leave it as an exercise for the reader which character is the eavesdropper, the MITM, etc.
Crypto Cat(R):
Decipher Dog (R):
Rosetta Stone (R):
T. Top (R):
Joules (tm) & her dog Socket:
Slate (R):
Sargeant Sam (R):
(Curiously, Sargeant Sam also shows up with  )
Cyber Twins (tm) Cy (boy):
Cyber Twins (tm) Cyndi (girl):

@_date: 2016-01-14 12:31:23
@_author: Henry Baker 
@_subject: [Cryptography] OpenSSL v LibreSSL speeds ? 
I'm getting some fairly dramatically different speeds on OpenSSL v. LibreSSL on the same machine, same OS.
./openssl speed > speedtest.out
reports the speeds of the different ciphers, etc.
In some cases the speed differences may be 3:1.
I tried to make the tests identical, but I may be doing it wrong.
I tried to make everything 'no-threads', 'no-hw', etc.
Has anyone else performed this comparison?
(N.B., I have no easy way to determine whether the security of both systems are the same for the same settings.)

@_date: 2016-01-17 07:52:27
@_author: Henry Baker 
@_subject: [Cryptography] OpenSSL minimal "safe" configuration? 
If I were more paranoid, I'd think that Nessa was behind the
calls for "backward compatibility".  After all, they have a
*huge* investment in legacy protocol hacks, so it's in their
interest to keep people using these insecure protocols as
long as possible.  Furthermore, even when those legacy
protocols are turned off *by default*, the code still
remains for active hacking -- e.g., ROP programming using
this old code as a larger attack surface.

@_date: 2016-01-19 19:03:25
@_author: Henry Baker 
@_subject: [Cryptography] GCHQ's plan to backdoor encrypted phone calls 
FYI -- The whole article is too long to reproduce here; follow the link to read the whole article.
Insecure by design: protocols for encrypted phone calls
    The MIKEY-SAKKE protocol is being promoted by the UK government as a better way to secure phone calls. The reality is that MIKEY-SAKKE is designed to offer minimal security while allowing undetectable mass surveillance, through the introduction a backdoor based around mandatory key-escrow. This weakness has implications which go further than just the security of phone calls.
The current state of security for phone calls leaves a lot to be desired. Land-line calls are almost entirely unencrypted, and cellphone calls are also unencrypted except for the radio link between the handset and the phone network. While the latest cryptography standards for cellphones (3G and 4G) are reasonably strong it is possible to force a phone to fall back to older standards with easy-to-break cryptography, if any. The vast majority of phones will not reveal to their user whether such an attack is under way.
The only reason that eavesdropping on land-line calls is not commonplace is that getting access to the closed phone networks is not as easy compared to the more open Internet, and cellphone cryptography designers relied on the equipment necessary to intercept the radio link being only affordable by well-funded government intelligence agencies, and not by criminals or for corporate espionage. That might have been true in the past but it certainly no longer the case with the necessary equipment now available for $1,500. Governments, companies and individuals are increasingly looking for better security.
A second driver for better phone call encryption is the convergence of Internet and phone networks. The LTE (Long-Term Evolution) 4G cellphone standard carries voice calls over IP packets, and desktop phones in companies are increasingly carrying voice over IP (VoIP) too. Because voice calls may travel over the Internet, whatever security was offered by the closed phone networks is gone and so other security mechanisms are needed.
Like Internet data encryption, voice encryption can broadly be categorised as either link encryption, where each intermediary may encrypt data before passing it onto the next, or end-to-end encryption, where communications are encrypted such that only the legitimate end-points can have access to the unencrypted communication. End-to-end encryption is preferable for security because it avoids intermediaries being able to eavesdrop on communications and gives the end-points assurance that communications will indeed be encrypted all the way to their other communication partner.
Current cellphone encryption standards are link encryption: the phone encrypts calls between it and the phone network using cryptographic keys stored on the Subscriber Identity Module (SIM). Within the phone network, encryption may also be present but the network provider still has access to unencrypted data, so even ignoring the vulnerability to fall-back attacks on the radio link, the network providers and their suppliers are weak points that are tempting for attackers to compromise. Recent examples of such attacks include the compromise of the phone networks of Vodafone in Greece (2004) and Belgacom in Belgium (2012), and the SIM card supplier Gemalto in France (2010). The identity of the Vodafone Greece hacker remains unknown (though the NSA is suspected) but the attacks against Belgacom and Gemalto were carried out by the UK signals intelligence agency -- GCHQ -- and only publicly revealed from the Snowden leaks, so it is quite possible there are others attacks which remain h
Email is typically only secured by link encryption, if at all, with HTTPS encrypting access to most webmail and Transport Layer Security (TLS) sometimes encrypting other communication protocols that carry email (SMTP, IMAP and POP). Again, the fact that intermediaries have access to plaintext creates a vulnerability, as demonstrated by the 2009 hack of Google's Gmail likely originating from China. End-to-end email encryption is possible using the OpenPGP or S/MIME protocols but their use is not common, primarily due to their poor usability, which in turn is at least partially a result of having to stay compatible with older insecure email standards.
In contrast, instant messaging applications had more opportunity to start with a clean-slate and so this is where much innovation in terms of end-to-end security has taken place. Secure voice communication however has had less attention than instant messaging so in the remainder of the article we shall examine what should be expected of a secure voice communication system, and in particular see how one of the latest and up-coming protocols, MIKEY-SAKKE, which comes with UK government backing, meets these criteria.
MIKEY-SAKKE and Secure Chorus
MIKEY-SAKKE is the security protocol behind the Secure Chorus voice (and also video) encryption standard, commissioned and designed by GCHQ through their information security arm, CESG. GCHQ have announced that they will only certify voice encryption products through their Commercial Product Assurance (CPA) security evaluation scheme if the product implements MIKEY-SAKKE and Secure Chorus. As a result, MIKEY-SAKKE has a monopoly over the vast majority of classified UK government voice communication and so companies developing secure voice communication systems must implement it in order to gain access to this market. GCHQ can also set requirements of what products are used in the public sector and as well as for companies operating critical national infrastructure.
Conclusions and future work
The design of MIKEY-SAKKE is motivated by the desire to allow undetectable and unauditable mass surveillance, which may be a requirement in exceptional scenarios such as within government departments processing classified information. However, in the vast majority of cases the properties that MIKEY-SAKKE offers are actively harmful for security. It creates a vulnerable single point of failure, which would require huge effort, skill and cost to secure -- requiring resource beyond the capability of most companies. Better options for voice encryption exist today, though they are not perfect either. In particular, more work is needed on providing scalable and usable protection against man-in-the-middle attacks, and protection of metadata for contact discovery and calls. More broadly, designers of protocols and systems need to appreciate the ethical consequences of their actions in terms of the political and power structures which naturally follow from their use. MIKEY-SAKKE is the lat
est example to raise questions over the policy of many governments, including the UK, to put intelligence agencies in charge of protecting companies and individuals from spying, given the conflict of interest it creates.
Update 2016-01-19: Fix broken links to GCHQ website, note that master key must be permanently available though not necessarily directly connected to the Internet, and mention suspicions that the NSA were involved in the Vodafone Greece compromise.
The photograph above this article is of a AT&T TSD-3600E Telephone Security Device based around the Clipper key-escrow chip ( Matt Blaze).
An edited version of this article will appear in the March 2016 special edition of IEEE Computer Magazine: Communications and Privacy under Surveillance.
CC BY-ND 4.0
Insecure by design: protocols for encrypted phone calls by Steven J. Murdoch is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License.
Published by
Steven J. Murdoch
Dr Steven J. Murdoch is a Royal Society University Research Fellow in the Information Security Research Group of University College London, working on developing metrics for security and privacy. His research interests include authentication/passwords, banking security, anonymous communications, censorship resistance and covert channels. He has worked with the OpenNet Initiative, investigating Internet censorship, and for the Tor Project, on improving the security and usability of the Tor anonymity system. His current research on developing methods to understand complex system security is supported by the Royal Society. He is also working on analysing the security of banking systems, especially Chip & PIN/EMV, and is Innovation Security Architect of Cronto, an online authentication technology provider and part of the VASCO group.

@_date: 2016-01-20 09:08:32
@_author: Henry Baker 
@_subject: [Cryptography] Plan to End the Crypto War 
The iPod Touch is basically an iPhone w/o 3G/4G capabilities,
so there's no SIM card or any interaction with *any* telco.
The iPod Touch can run the same apps as an iPhone -- e.g.,
encrypted wifi apps.
In fact, some parents give their kids iPod Touch's in order
to avoid having to pay per-minute or per-GB charges, since
almost every place the kid goes there's wifi.
Given the almost ubiquitous presence of wifi, it would seem
that the "smartphone" horse has left the barn.

@_date: 2016-01-21 12:07:44
@_author: Henry Baker 
@_subject: [Cryptography] NSA Chief Stakes Out Pro-Encryption Position 
FYI --
NSA Chief Stakes Out Pro-Encryption Position, in Contrast to FBI
Jenna McLaughlin
National Security Agency Director Adm. Mike Rogers said Thursday that "encryption is foundational to the future," and arguing about it is a waste of time.
Speaking to the Atlantic Council, a Washington, D.C., think tank, Rogers stressed that the cybersecurity battles the U.S. is destined to fight call for more widespread use of encryption, not less.  "What you saw at OPM, you're going to see a whole lot more of," he said, referring to the massive hack of the Office of Personnel Management involving the personal data about 20 million people who have gotten background checks.
"So spending time arguing about hey, encryption is bad and we ought to do away with it'  that's a waste of time to me," he said, shaking his head.
"So what we've got to ask ourselves is, with that foundation, what's the best way for us to deal with it?  And how do we meet those very legitimate concerns from multiple perspectives?"
Other government officials -- most notably FBI Director James Comey -- have been crusading for a way that law enforcement can get access to encrypted data.
But technologists pretty much universally agree that creating some sort of special third-party access would weaken encryption to the point that it would threaten every internet transaction we make, from online banking to filling out our health records to emailing our friends and significant others.  A hole in encryption for special FBI access would be a hole that criminals could sneak through, too.
While there's been a lot of talk about giving up some privacy for security, Rogers said both are paramount.
"Concerns about privacy have never been higher.  Trying to get all those things right, to realize that -- it isn't about one or the other," he said.  He does not think that "security is the imperative and that ought to drive everything."  Nor should privacy, he continued.  "We've got to meet these two imperatives.  We've got some challenging times ahead of us, folks."
Comey, who formerly advocated for a way to get law enforcement access without weakening encryption, recently switched tactics.  Now he is pressuring companies to change their business models and simply not offer true end-to-end encryption to their customers.
The White House has decided not to pursue legislation to outlaw unbreakable end-to-end encryption, following pressure from privacy advocates and scientists.  But the intelligence community's top lawyer, Bob Litt, privately advised the administration that a major terrorist attack could be an opportune moment to do so.
And the White House has not issued a statement in defense of encryption, to the frustration of Apple CEO Tim Cook, among others.
Meanwhile, Sens. Richard Burr, R-N.C., and Dianne Feinstein, D-Calif., are reportedly planning their own proposed legislation to require law enforcement access.
Rogers' comments could indicate a split on this issue between the intelligence community and domestic law enforcement.
The previous NSA director, Michael Hayden, said in January that he thinks Comey is on the wrong side of this debate.  "I disagree with Jim Comey.  I actually think end-to-end encryption is good for America," he said.
Hayden has also spoken about how U.S. intelligence agencies have figured out how to get the information they need without weakening encryption -- such as using metadata, which shows who is contacting whom.  Another former NSA boss, Mike McConnell, has also spoken out against trying to install backdoors in encryption.
Left unsaid is the fact that the FBI and NSA have the ability to circumvent encryption and get to the content too -- by hacking.  Hacking allows law enforcement to plant malicious code on someone's computer in order to gain access to the photos, messages, and text before they were ever encrypted in the first place, and after they've been decrypted.  The NSA has an entire team of advanced hackers, possibly as many as 600, camped out at Fort Meade.
Watch Rogers' talk here:
Contact the author:
Jenna McLaughlin
jenna.mclaughlin at theintercept.com

@_date: 2016-01-27 09:37:45
@_author: Henry Baker 
@_subject: [Cryptography] Weisner's "Conjugate Coding" paper ? 
Could someone please email me a copy of this first QC paper?
It's referenced a gazillion times, but I can't find an actual copy online that isn't hidden behind some paywall.

@_date: 2016-01-29 10:03:08
@_author: Henry Baker 
@_subject: [Cryptography] NSA TAO Chief usenix video 
FYI --
USENIX Enigma 2016 - NSA TAO Chief on Disrupting Nation State Hackers
Published on Jan 28, 2016
Rob Joyce, Chief, Tailored Access Operations, National Security Agency
Sign up to find out more about Enigma conferences:
Watch all Enigma 2016 videos at:

@_date: 2016-07-08 07:15:46
@_author: Henry Baker 
@_subject: [Cryptography] Putin goes full Stasi; 
FYI --
Putin gives federal security agents two weeks to produce 'encryption keys' for the Internet
13:28, 7 july 2016
After signing controversial anti-terrorist legislation earlier today, President Putin ordered the Federal Security Service (the FSB, the post-Soviet successor to the KGB) to produce encryption keys to decrypt all data on the Internet.  According to the executive order, the FSB has two weeks to do it.  Responsibility for carrying out Putin's instructions falls on Alexander Bortnikov, the head of the FSB.
The new "anti-terrorist" laws require all "organizers of information distribution" that add "additional coding" to transmitted electronic messages to provide the FSB with any information necessary to decrypt those messages.  It's still unclear what information exactly online resources are expected to turn over, given that all data on the Internet is encoded, one way or another, and in many instances encryption keys for encrypted information simply don't exist.
The Duma's new 'Big-Brother' legislation kills Russia's Internet companies and hurts ordinary Web users.  Here's how.
16:06, 27 june 2016
Last week, lawmakers in the State Duma approved what Edward Snowden has called "Russia's new Big-Brother law."  A major part of this legislation creates new regulations on the Internet.  According to the amendments, telecom providers and the "organizers of information distribution" will need to store copies of nearly all information they transmit.  They can't delete this information until it's six months old.  This applies to recordings of phone calls, as well as the contents of text messages.  And they have to keep copies of metadata of these communications (the information about when and between whom messages occurred, but not the actual content of the messages) for a whopping three years.  Companies will additionally be required to help Russia's Federal Security Service (the modern-day successor to the Soviet KGB) decrypt all the data.  The largest Internet companies in Russia--Mail.ru and Yandex--oppose the bill, as do the industry groups the Russian Association for Electronic
 Communications and the Regional Center for Internet Technologies, and even the "Communications and IT" working group within the Russian government.  Meduza looks at why this legislation isn't just impractical, but will also harm ordinary Internet users and Internet companies alike.
It's expensive
The legislation requires telecom providers and "organizers of information distribution" (which could be literally any website on the Internet, as determined by Russia's state censor) to store all data sent by its users or visitors.  This is a gigantic amount of data: Russia would need every data-storage manufacturer in the world working for seven years straight, before the country had the infrastructure necessary to accommodate so much storage and processing.
And there's another problem: the electrical grid in central Russia simply isn't powerful enough to fuel the still-unbuilt data centers that will be required by the new legislation.  The equipment and materials needed to build these data centers, moreover, isn't produced in Russia, so companies will be forced to buy imported goods.
Experts say the costs of building this infrastructure will be more than 5 trillion rubles (roughly $77 billion).  For comparison, the federal government's total revenues in 2015 totaled 13.7 trillion rubles (about $210 billion).  The legislation says implementing the new statutes won't require any state subsidies, but that's untrue: at the very least, government agencies will need to upgrade the country's data cables (given that Russia's existing network of cables is too weak to cope with the higher volume of transmitted information created by the new regulations).
The government also risks losing income from Russia's Internet companies, which currently pay taxes on their profits.  The new legislation could make many businesses unprofitable, after they're forced to spend tens if not millions of rubles on new data-storage equipment.
It's dumb
The new legislation requires all "organizers of information distribution" that add "additional coding" to transmitted electronic messages to provide the Federal Security Service (FSB) with any information necessary to decrypt those messages.  What lawmakers seem not to understand is that virtually all information transmitted over the Internet is "encoded."  Any text or image sent over email using Simple Mail Transfer Protocol (SMTP) is in something called Multipurpose Internet Mail Extensions (MIME) format.  Will "organizers" need to send the FSB information about how MIME works?
If we're talking about encryption, we're talking about almost half the traffic on the Internet--and the volume is only growing.  In most cases, incidentally, the "organizers of information distribution" don't have the keys to decrypt their own data.  (That is precisely how Internet privacy works.)  For example, it's not even technically possible to store encryption keys when using the HTTPS protocol, which is used by an enormous number of websites, including the one you're reading now, and even Gosuslugi.ru, the Russian government's official portal where citizens can contact the state about public services.  In other words, the legislation bans the state's own website for contact with ordinary citizens.
How this legislation is supposed to regulate financial systems is also unclear.  The SWIFT network that links the world's financial institutions doesn't use Russian cryptographic algorithms, but nearly all the world's banks--including banks in Russia--use SWIFT.  The world's payment systems, moreover, are required to comply with the Payment Card Industry Data Security Standard (PCI DSS), a proprietary information security standard that doesn't disclose its encryption keys.
In order to comply with the legislation, programmers will need to come up with new encryption methods that must simultaneously work with existing encryption methods, given that foreign companies won't support these new technologies (which don't currently exist, anyway).  But even if Russia manages to create some kind of center to house all encryption keys, the concentration of data would make the center extremely attractive, and therefore very vulnerable, to hackers.  By breaking into this hypothetical data center, after all, it would be possible to decrypt any message sent inside Russia.
The new legislation also violates Russian citizens' right to the privacy of correspondence, which is enshrined in Article 23 of the Constitution.  In order to deprive Russians of this right, police need a court order.  The "Yarovaya legislation," however, grants law-enforcement agencies access to everyone's messages without any judicial oversight.
Today, most messaging apps use encryption.  In fact, encryption is one of their most important competitive advantages, as users often seek out the safest and most secure communications available.  The new law will make any Russian online service less competitive.  It's unclear what foreign companies will do.  Some might simply walk away from the Russian market.
This text is based on statements by the Russian Internet companies Yandex and Mail.ru (which are considered "organizers of information distribution"), the industry groups the Russian Association for Electronic Communications and the Regional Center for Internet Technologies (which position themselves as links between the state and the Internet), and the "Communications and IT" working group within the Russian government.
Theresa May, James Comey, Cyrus Vance, et al, can't wait to go full Stasi, as well.
'Putin-in-the-middle' attacks, anyone?

@_date: 2016-07-13 17:14:41
@_author: Henry Baker 
@_subject: [Cryptography] The Laws (was the principles) of secure 
Too Big to Secure -- e.g., Bluffdale.
Digital Rootkit Management
Trade secret that is shared with FBI/DHS/NSA pursuant to an NSL.
Backdoor that's been approved by the NSA.
Tissue Paper Mansion.

@_date: 2016-07-17 06:08:47
@_author: Henry Baker 
@_subject: [Cryptography] Sandia storing information in encrypted DNA 
FYI --
Sandia storing information securely in DNA
Sandia researchers explore a biologically inspired information storage system
George Bachand, a Sandia National Laboratories bioengineer at the Center for Integrated Nanotechnologies, is exploring a better, more permanent method for ***encrypting*** and storing sensitive data: DNA.  Compared to digital and analog information storage, DNA is more compact and durable and never becomes obsolete.  Readable DNA was extracted from the 600,000-year-old remains of a horse found in the Yukon.
What happens when we're all "end2end" encrypted?
Gives a whole new meaning to "messing around with my junk (DNA)"...
What's a repressive govt like Putin's, May's, Feinstein's, Comey's, Vance's, to do?

@_date: 2016-07-21 05:35:33
@_author: Henry Baker 
@_subject: [Cryptography] N. Korean radio broadcasts string of random numbers 
FYI --
Mystery as North Korean radio broadcasts string of random numbers
* String of indecipherable numbers echoes Cold War-era radio broadcasts
* Pyongyang sent similar messages via shortwave radio to spies in South * Woman read for 16 minutes, announcing things like 'page 459, question 35'
* Announcer described the numbers as a maths lesson for distance learners  By Gareth Davies For Mailonline
Published: 11:17 GMT, 19 July 2016 | Updated: 21:08 GMT, 20 July 2016
North Korea's state radio has recently broadcast strings of indecipherable numbers in a possible move echoing a Cold War-era method of sending coded messages to spies operating in South Korea.
A female announcer at the radio station read numbers for two minutes on June 24 and 14 minutes on Friday, according to Seoul's Unification Ministry and National Intelligence Service, including phrases such as 'turn to page 459, question 35' in what she described as a mathematics assignment.
During the Cold War, Pyongyang sent such numbers via shortwave radio to give missions to agents dispatched to South Korea, according to captured North Korean spies.
'Now we'll begin a mathematics review assignment for members of the 27th expeditionary unit of the distance learning university,' the woman's voice crackled over the radio.
'Turn to page 459, question 35, 913, question 55; 135, question 86.' The messages, a recording of which was broadcast by South Korean TV channel KBS, were disguised as a mathematics lesson for distance learners and reappeared on North Korean radio station Voice of Korea in the early hours of Friday. The radio messages, also known as numbers stations, work by broadcasting strings of seemingly random numbers over shortwave signals to an agent in the field. The technique, a method of sending one-way secret messages, dates to the French Resistance in World War Two and is still in use by some governments today.
South Korea jams most North Korean radio frequencies but Pyongyang-based Voice of Korea broadcasts on shortwave signals which can be picked up far beyond the Korean peninsula, and are difficult to jam.
The receiving agent, armed with a radio and a pen, uses an easily concealed pad with corresponding letters on it to listen to and decrypt the secret message.
'(North Korean) numbers broadcasts have been on hold for quite some time but have recently resumed, something we think is very regrettable,' Jeong Joon-hee, a spokesman for South Korea's unification ministry, told a media briefing on Wednesday.
It was not clear whether the signals were meant to deceive or deliver genuine instructions.
'I can't speak to their intentions, but we hope that the North will refrain from an old practice like this and behave in a manner that's conducive to improving South-North ties,' Jeong said.   Neither the Unification Ministry nor the NIS elaborated on whether South Korea believes the North's recent broadcasts were meant to send information to agents in the field. The North reportedly stopped such broadcasts once it could communicate with its spies overseas via the internet, and as animosities with South Korea eased following a historic inter-Korean summit meeting in 2000.
Relations have deteriorated greatly since then as North Korea has pursued the development of nuclear weapons despite international sanctions.
Some experts in Seoul view the messages as a North Korean attempt to wage psychological warfare.
Yoo Dongryul, head of the Seoul-based Korea Institute of Liberal Democracy, said the North may be trying to deceive South Korean intelligence officials into believing it's moving to increase its espionage operations.
He said it's unlikely the North would rely on old-fashioned 'number stations' broadcasts, whose hard-to-reset coding patterns had already been exposed to South Korean intelligence officers. He said North Korea currently uses a more sophisticated espionage communication method known as steganography, in which secret messages are hidden within audio and video files.
For decades after the end of the 1950-53 Korean War, the rival Koreas sent agents across their heavily fortified border to infiltrate to each other's territory. But in recent years, both sides are believed to be focusing on less risky intelligence-gathering activities, such as information from the internet and satellite photos. Seoul accuses Pyongyang of sending spies disguised as ordinary refugees seeking to resettle in South Korea or nurturing pro-North figures in the South.
News of the North Korean broadcast came as North Korea is angrily reacting to the planned deployment of an advanced U.S. missile defence system in South Korea. On Tuesday, North Korea fired three ballistic missiles into the sea, according to Seoul defense officials.
Mystery as North Korean radio broadcasts string of random numbers
* String of indecipherable numbers echoes Cold War-era radio broadcasts
* Pyongyang sent similar messages via shortwave radio to spies in South * Woman read for 16 minutes, announcing things like 'page 459, question 35'
* Announcer described the numbers as a maths lesson for distance learners  By Gareth Davies For Mailonline
Published: 11:17 GMT, 19 July 2016 | Updated: 21:08 GMT, 20 July 2016
North Korea's state radio has recently broadcast strings of indecipherable numbers in a possible move echoing a Cold War-era method of sending coded messages to spies operating in South Korea.
A female announcer at the radio station read numbers for two minutes on June 24 and 14 minutes on Friday, according to Seoul's Unification Ministry and National Intelligence Service, including phrases such as 'turn to page 459, question 35' in what she described as a mathematics assignment.
During the Cold War, Pyongyang sent such numbers via shortwave radio to give missions to agents dispatched to South Korea, according to captured North Korean spies.
'Now we'll begin a mathematics review assignment for members of the 27th expeditionary unit of the distance learning university,' the woman's voice crackled over the radio.
'Turn to page 459, question 35, 913, question 55; 135, question 86.' The messages, a recording of which was broadcast by South Korean TV channel KBS, were disguised as a mathematics lesson for distance learners and reappeared on North Korean radio station Voice of Korea in the early hours of Friday. The radio messages, also known as numbers stations, work by broadcasting strings of seemingly random numbers over shortwave signals to an agent in the field. The technique, a method of sending one-way secret messages, dates to the French Resistance in World War Two and is still in use by some governments today.
South Korea jams most North Korean radio frequencies but Pyongyang-based Voice of Korea broadcasts on shortwave signals which can be picked up far beyond the Korean peninsula, and are difficult to jam.
The receiving agent, armed with a radio and a pen, uses an easily concealed pad with corresponding letters on it to listen to and decrypt the secret message.
'(North Korean) numbers broadcasts have been on hold for quite some time but have recently resumed, something we think is very regrettable,' Jeong Joon-hee, a spokesman for South Korea's unification ministry, told a media briefing on Wednesday.
It was not clear whether the signals were meant to deceive or deliver genuine instructions.
'I can't speak to their intentions, but we hope that the North will refrain from an old practice like this and behave in a manner that's conducive to improving South-North ties,' Jeong said.   Neither the Unification Ministry nor the NIS elaborated on whether South Korea believes the North's recent broadcasts were meant to send information to agents in the field. The North reportedly stopped such broadcasts once it could communicate with its spies overseas via the internet, and as animosities with South Korea eased following a historic inter-Korean summit meeting in 2000.
Relations have deteriorated greatly since then as North Korea has pursued the development of nuclear weapons despite international sanctions.
Some experts in Seoul view the messages as a North Korean attempt to wage psychological warfare.
Yoo Dongryul, head of the Seoul-based Korea Institute of Liberal Democracy, said the North may be trying to deceive South Korean intelligence officials into believing it's moving to increase its espionage operations.
He said it's unlikely the North would rely on old-fashioned 'number stations' broadcasts, whose hard-to-reset coding patterns had already been exposed to South Korean intelligence officers. He said North Korea currently uses a more sophisticated espionage communication method known as steganography, in which secret messages are hidden within audio and video files.
For decades after the end of the 1950-53 Korean War, the rival Koreas sent agents across their heavily fortified border to infiltrate to each other's territory. But in recent years, both sides are believed to be focusing on less risky intelligence-gathering activities, such as information from the internet and satellite photos. Seoul accuses Pyongyang of sending spies disguised as ordinary refugees seeking to resettle in South Korea or nurturing pro-North figures in the South.
News of the North Korean broadcast came as North Korea is angrily reacting to the planned deployment of an advanced U.S. missile defence system in South Korea. On Tuesday, North Korea fired three ballistic missiles into the sea, according to Seoul defense officials.

@_date: 2016-06-06 11:06:33
@_author: Henry Baker 
@_subject: [Cryptography] Encrypted/Obfuscated Accounting ?? 
FYI --
H.R.942 - Audit the Pentagon Act of 2015
How Not to Audit the Pentagon Five Decades Later, the Military Waste Machine Is Running Full Speed Ahead By William D. Hartung
I realize that obfuscated accounting was invented only a few minutes after double-entry bookkeeping was invented, but the U.S. DoD has taken obfuscated accounting to the highest levels.
Is there a mathematical theory of *obfuscated accounting* ?
I'm asking a theoretical question about the possibility of setting up a more-or-less standard double-entry bookkeeping system in such a way that the information is stored and is accessible, but provides little or no actual information about what is going on.
Clearly, the names of all of the entries have to be obscured, but that obviously isn't enough, because someone with reasonable a priori knowledge could figure out just from the relative ratios of the numbers which accounts were which.
There would also have to be a spreading of expenditures among a whole bunch of other accounts, so that even relatively large expenditures could still be hidden.
I realize that these obfuscation practices go on in all of the largest corporations and govt agencies, so I was wondering if anyone had ever studied the *mathematics* or *science* or *engineering* of such accounting obfuscation?
It is conceivable that a real audit might be NP-complete under an appropriate accounting model.

@_date: 2016-06-17 12:55:33
@_author: Henry Baker 
@_subject: [Cryptography] Brennan challenges non-US companies to provide 
FYI --
Non-US encryption is 'theoretical,' claims CIA chief in backdoor debate
No choice but to use American gear, grins spymaster
17 Jun 2016 at 00:36, Iain Thomson
CIA director John Brennan told US senators they shouldn't worry about mandatory encryption backdoors hurting American businesses.
And that's because, according to Brennan, there's no one else for people to turn to: if they don't want to use US-based technology because it's been forced to use weakened cryptography, they'll be out of luck because non-American solutions are simply "theoretical."
Thus, the choice is American-built-and-backdoored or nothing, apparently.
The spymaster made the remarks at a congressional hearing on Thursday after Senator Ron Wyden (D-OR) questioned the CIA's support for weakening cryptography to allow g-men to peek at people's private communications and data.
Brennan said this was needed to counter the ability of terrorists to coordinate their actions using encrypted communications. The director denied that forcing American companies to backdoor their security systems would cause any commercial problems.
"US companies dominate the international market as far as encryption technologies that are available through these various apps, and I think we will continue to dominate them," Brennan said.
"So although you are right that there's the theoretical ability of foreign companies to have those encryption capabilities available to others, I do believe that this country and its private sector are integral to addressing these issues."
We don't think the CIA man has been paying attention, to put it generously. A study in February found there are 865 encryption products in use around the world supplied by developers in 55 countries. About a third of these packages came from the US, with Germany, the UK and Canada the next biggest suppliers.
Nevertheless, Brennan is right that the bulk of commercial encryption products in use by enterprises are supplied by American firms. The word he missed is "now."
If US firms are mandated to install backdoors, sales of encryption products are going to change very quickly. Very few overseas companies are going to buy a broken encryption system that can be read by US intelligence, and a fair few US companies aren't going to be wild about doing so either.
"It is clearly inaccurate to say that foreign encryption is a 'theoretical' capability," said Senator Wyden.
"Requiring companies to build backdoors in their products to weaken strong encryption will put the personal safety of Americans at risk at a dangerous time and  I want to make this clear  I will fight such a policy with everything I have."
Interestingly, Brennan didn't mention legislation proposed by Senators Richard Burr (R-NC) and Dianne Feinstein (D-CA) which would mandate backdoors. The proposed bill has little support and instead Brennan indicated he supported an alternative legislative push.
Instead, Brennan spoke supportively of a bill introduced by Senators Mark Warner (D-VA) and House Committee on Homeland Security Chairman Michael McCaul (R-TX) which would set up a congressional committee to explore the encryption issue.
Not that we should be worried about the CIA snooping, Brennan said. In the past three weeks, the CIA has appointed a privacy and civil liberties officer as a full member of senior staff. The person will review all CIA activities to ensure they are legal, Brennan said.
So that's all right then.
OK, Brennan's thrown down the gauntlet; all of you non-US vendors are invited to provide non-backdoored encryption for us.

@_date: 2016-03-01 12:11:18
@_author: Henry Baker 
@_subject: [Cryptography] Chertoff Group's new 28-page report on Encryption 
FYI --
"The Ground Truth About Encryption, and The Consequences of Extraordinary Access"
Abstract: U.S. policy makers are currently engaged in a debate regarding the merits of
mandating a means of extraordinary access to encrypted data for U.S. law enforcement, what
is sometimes referred to as an encryption backdoor.  This paper examines modern encryption
technologies, the feasibility of providing law enforcement with extraordinary access, the impact
that encryption technology is currently having on U.S. law enforcement (which some have referred
to as going dark), and the likely impacts that an extraordinary access requirement would have
on U.S. national security, the technology sector, and continued innovation in the security field. We conclude that an extraordinary access requirement is likely to have a negative impact on
technological development, the United States international standing, and the competitiveness
of the U.S. economy and will have adverse long-term effects on the security, privacy, and civil
liberties of citizens.

@_date: 2016-03-02 10:26:50
@_author: Henry Baker 
@_subject: [Cryptography] LibreSSL unaffected by DROWN 
FYI --
The OpenBSD people forked and heavily cleaned up OpenSSL to create LibreSSL due to dissatisfaction with the maintainance of OpenSSL, culminating in the heartbleed bug.
The emphasis has been on cleaning up the code and improving security, which includes removing things such as SSL2 which has fundamental security flaws.
As a result, LibreSSL is not affected by the DROWN bug. LibreSSL is largely compatible with OpenSSL.
The main exceptions are in the cases where programs use insecure functions removed from libreSSL, or require bug compatiblity with OpenSSL. I just love the phrase "bug compatibility" !
I'll put that right up there with "God could create the world in 7 days because he didn't have an installed base".

@_date: 2016-03-03 13:31:50
@_author: Henry Baker 
@_subject: [Cryptography] Vice: Amazon removes full disk encryption from 
Perhaps Amazon doesn't have the time or money to fight the FBI & DoJ with the same ferocity as Apple.
If Amazon really wanted to throw in the towel on encryption, they'd remove all the DRM from their devices, as well.
Keeping DRM (encryption) while deleting user encryption shows that encryption isn't allowed for "the little people", only for the corporate overlords.
Cory Doctorow has discussed Amazon's DRM issues at length; perhaps boingboing.net will have the links.

@_date: 2016-03-03 22:05:35
@_author: Henry Baker 
@_subject: [Cryptography] Two more Apple amicus briefs 
Thanks very much -- that's quite a list.
However, isn't Amazon being a little disingenuous here, as they just dropped encryption on their mobile products like a hot rock?  (Although Amazon has no choice about encryption on their cloud services; their cloud services have already been hacked quite a lot.)
Supposedly, Apple has already filed an appeal brief, but I haven't been able to find it.  Anyone?  Anyone?
Thanks in advance.

@_date: 2016-03-04 12:54:19
@_author: Henry Baker 
@_subject: [Cryptography] EFF amicus brief in support of Apple 
FYI --
I think that most people here will find this particular brief to be extremely relevant, as it argues strongly the case that Apple's First Amendment right includes:
* the right to decide what code it wants to write (and which code it REFUSES to write); and
* the right to choose under what conditions to electronically sign documents & code with its own private crypto key
Terrific job, EFF!

@_date: 2016-03-04 14:29:01
@_author: Henry Baker 
@_subject: [Cryptography] EFF amicus brief in support of Apple 
I believe that you may be referring to Techdirt's comments.
Bottom line: if FBI/DoJ can strongarm Apple into electronically
signing malware, then we have entered into a truly new imperial
era, where trillion-dollar companies can be rubber-hosed into
misusing their private crypto keys.
No amount of technology, per se, can prevent this particular
MITM attack.  We're now going to have to have multiple keys
from multiple "trusted" sources prior to accepting a firmware
update.  Forget visiting Switzerland or the Cayman Islands
for access to $$$; you may now have to physically go there to
get your iPhone securely updated.
I'm sure that Microsoft/HP/Dell are looking upon these
proceedings with mixed feelings, as I suspect that they've
*already* provided their code-signing keys to the govt --
perhaps under FISA NSL -- or perhaps out of a misplaced
sense of patriotism.
Remember what James Comey & Loretta Lynch have been saying,
time and time again: all of you guys used to roll over w/o
a whimper a few years ago; how come you suddenly grew a
backbone?  We used to be lovers; now you call "rape".

@_date: 2016-03-05 07:20:41
@_author: Henry Baker 
@_subject: [Cryptography] What is Apple's public signing key? 
Now that every govt in the world has Apple in its sights, how secure is the digital signature system that Apple uses to sign its firmware?
Which algorithm is used?
Which parameters are chosen?
Can these parameters have hidden back doors?
Are there any rainbow/NOBUS attacks?
Are there any methods similar to those used for passwords that can be used to slow down a brute force digital signature attack?

@_date: 2016-03-06 10:57:36
@_author: Henry Baker 
@_subject: [Cryptography] Official (?) govt crypto characters 
* Phoebe ("FBI").  Phoebe was a daughter of Uranus, the god of parallel construction.  (Cue snarky remarks...)
* Nessa (short for Vanessa) ("NSA")
* Dodge ("DoJ").
* Holmes or Homer ("DHS").

@_date: 2016-03-07 07:56:48
@_author: Henry Baker 
@_subject: [Cryptography] is this feudalism? 
Be careful what you wish for.
Some historians attribute the rise of kings & nation-states as a way for the ordinary citizens to rid themselves of their hated local lords.
But this strategy may have achieved escaping the frying pan by going directly into the fire.

@_date: 2016-03-07 14:34:50
@_author: Henry Baker 
@_subject: [Cryptography] News flash: FBI in the "dark" about "numbers" radio 
FYI --
The Stupidly Simple Spy Messages No Computer Could Decode
Shane Harris  03.06.16 5:01 AM ET
Every day, hour after hour, the worlds spies send top secret information you can easily listen in on.
"But the numbers are just gibberish without that key, known in spycraft as a one-time pad.  As its name suggests, its used only once.  And thats what makes it so secure."
These radio communications to/from *terrorists* have been going on since WWII, and yet James Comey hasn't filed suit against the radio receiver manufacturers...

@_date: 2016-03-08 06:55:22
@_author: Henry Baker 
@_subject: [Cryptography] UK GCHQ finally declassifies Ellis papers on public 
FYI --
xThe Ellis papers
The possibility of secure non-secret digital encryption (PDF, 3.51MB)
The possibility of secure non-secret analogue encryption (PDF, 5MB)
Q: So when will NSA declassify the rest of Shannon's work?

@_date: 2016-03-08 07:54:51
@_author: Henry Baker 
@_subject: [Cryptography] Director GCHQ speaks at MIT 
FYI -- Front doors and strong locks: encryption, privacy and intelligence gathering in the digital era
Speech - 08 Mar 2016
A full transcript of the speech by Robert Hannigan, Director GCHQ, as delivered at the Massachusetts Institute of Technology, on 07 March 2016.
All you need to know: "I'm not a cryptologist", but I'm here to help you design your encryption system, anyway.
"I don't *need* or *want* [for my family's communications] the same level of security applied to protect a nuclear submarine's communications."
That sounds like purposely *weakening* security to me...
When people like this start talking about "balance", "proportionality" and "trade-offs", check to see if you still have your wallet.

@_date: 2016-03-08 10:01:38
@_author: Henry Baker 
@_subject: [Cryptography] Apple's appeal brief re NY iPhone iOS7 5s 
FYI --
Basically, the brief says "you submitted to our abuse dozens of
times before and never complained; how come you're resisting
Perhaps Apple finally grew a backbone?
"the Supreme Court has rejected using speculation about future
harm as a basis to bar relief in a specific case."
This reasoning is insane.  E.g., "We can't afford $100/day to
keep lead out of the Flint water supply".  "You're speculating
about future harm; you're not allowed to spend the money."
"Sir, a number of Flint children have been showing up with
higher than acceptable lead levels in their blood".  Oops!
The brief also indicates that Apple has confirmed that there
is a "remote wipe" contract out on this iPhone, and the govt
is afraid that if they turn the phone on, that it will wipe
Interesting question: how would Apple know about the "remote
wipe" command?  Shouldn't this command also be encrypted?

@_date: 2016-03-08 20:19:15
@_author: Henry Baker 
@_subject: [Cryptography] Director GCHQ speaks at MIT 
FYI --.
All you need to know: "I'm not a cryptologist", but I'm here to help you design your encryption system, anyway.
"I don't *need* or *want* [for my family's communications] the same level of security applied to protect a nuclear submarine's communications."
That sounds like purposely *weakening* security to me...
When people like this start talking about "balance", "proportionality" and "trade-offs", check to see if you still have your wallet.
He said his secrets do not need the same as nuclear submarine's communications.
Hmmm.... one time tamper evident pads and quality safes in the captain's quarters
and reliable very low frequency command links and more. No data link for denial
of service attack.
FYI -- Perhaps Dir GCHQ Hannigan was thinking of this incident:
Navy whistleblower on the run after exposing alleged Trident safety failings
MoD launches investigation into claims of Able Seaman William McNeilly, who says he will hand himself into police
Josh Halliday
Monday 18 May 2015 09.18 BST Last modified on Monday 18 May 2015 12.15 BST
A Royal Navy submariner who blew the whistle on a catalogue of alleged security failings around the Trident nuclear programme has said he will hand himself in to police.
Able Seaman William McNeilly, 25, a newly qualified engineer, claimed that Britain's nuclear deterrent was a "disaster waiting to happen" in a report detailing 30 alleged safety and security breaches, including a collision between HMS Vanguard and a French submarine during which a senior officer thought: "We're all going to die."
McNeilly wrote that a chronic manpower shortage meant that it was "a matter of time before we're infiltrated by a psychopath or a terrorist; with this amount of people getting pushed through".
The police and Royal Navy launched a hunt for the whistleblower after he failed to report back for work last week at the Faslane submarine base on the Clyde.  But on Monday morning McNeilly said he would hand himself over to the authorities despite facing a possible prosecution under the Official Secrets Act 1989.
Speaking to the BBC, he said: "I'm not hiding from arrest; I will be back in the UK in the next few days and I will hand myself in to the police.
Prison  such a nice reward for sacrificing everything to warn the public and government.  Unfortunately that's the world we live in.  I know it's a lot to sacrifice and it is a hard road to walk down, but other people need to start coming forward."
In the 19-page report, titled The Secret Nuclear Threat, published online alongside a picture of his UK passport and Royal Navy identity card, McNeilly said he wanted "to break down the false images of a perfect system that most people envisage exists".
He described bags going unchecked and said it was "harder getting into most nightclubs" than into control rooms, with *broken pin code systems* and guards failing to check passes.  "All it takes is someone to bring a bomb on board to commit the worst terrorist attack the UK and the world has ever seen," he wrote.
McNeilly, who said he was on patrol with HMS Victorious from January to April, accused Royal Navy bosses of covering up a collision between HMS Vanguard and a French submarine in the Atlantic Ocean in February 2009.
At the time Ministry of Defence officials played down the incident and said the Vanguard had suffered only "scrapes".  But McNeilly said a Royal Navy chief who was on board at the time told him afterwards: "We thought, this is it  we're all going to die."
The more senior submariner allegedly told McNeilly that the French vessel "took a massive chunk out of the front of HMS Vanguard" and grazed the side of the boat.  Bottles of high-pressured air came loose in the collision, he claimed, meaning the Royal Navy submarine had to return slowly to Faslane to prevent them from exploding.
He also raised concerns about a number of his fellow seamen, including one whose hobbies he claimed were killing small animals and watching extreme pornography.  Another submariner, whom he named only as "Pole", had threatened to kill two fellow navy personnel and was routinely aggressive, McNeilly claimed.
He described how HMS Vanguard's missile compartment doubled up as a gym, leading to potentially disastrous mishaps when seamen dropped weights near the boat's missile firing system.
McNeilly said he raised these and other concerns through the chain of command on multiple occasions, but that "not once did someone even attempt to make a change".
The whistleblower also revealed that there had allegedly been a fire in the missile compartment when the vessel was in harbour.  He claimed *the blaze was sparked by overheated cables setting light to stacks of toilet roll.*  "The chief said if it had been at sea there would've been about 50 dead bodies on three deck because of the amount of people struggling to find an emergency breathing system," he claimed.
McNeilly said his decision to go public was "the easiest yet most painful" of his life, and that he had "sacrificed everything" to make the claims.
He wrote that he was hopeful of receiving a pardon from David Cameron when he handed himself in to the police.  "I also believe it's in the prime minister's best interests to release me.  Prosecuting someone for alerting the people and the government to a major threat isn't a good image for any government," he added.
Angus Robertson, the Scottish National party leader in Westminster, described the claims as extremely concerning and said the allegations add weight to calls to scrap Trident altogether.
He said: "It reads as a nightmare catalogue of serious safety breaches aboard and alongside these nuclear-armed submarines ... Shortages of all types of crew on these submarines has been well-documented and the description of personnel in extremely stressful situations must be alarming given the huge responsibility some of these sailors are given.
"Failure to follow standard safety procedures is unacceptable in any workplace but on a Vanguard submarine on patrol it could result in extreme tragedy not just for those on board but indeed for the entire planet."
A Royal Navy spokeswoman said on Monday that the service disagreed with McNeilly's assessment, describing the report as containing "a number of subjective and unsubstantiated personal views".
The spokeswoman said it was right for the allegations to be investigated but that the publishing of the report did not pose a security risk.  She added: "The Royal Navy takes security and nuclear safety extremely seriously and we are fully investigating both the issue of the unauthorised release of this document and its contents.
"The naval service operates its submarine fleet under the most stringent safety regime and submarines do not go to sea unless they are completely safe to do so."
The Secret Nuclear Threat, the blog posted online by William McNeilly.

@_date: 2016-03-09 07:13:53
@_author: Henry Baker 
@_subject: [Cryptography] All applications need top security (was Re: 
To underline what Perry just said, the WWII Germans didn't think
that weather reports "needed" or "wanted" the highest levels of
security.  Oops!
Ditto for Japanese (& American) discussions of water availability.
Who would have thought that *side-channels* like power, audio,
screen video, RF emanations, etc., would leak so much information?
Who would have thought that OPM information would be so valuable?
Since Dir GCHQ Hannigan couldn't possibly hold his current job & be so
ignorant, I must conclude that he is lying his *ss off.

@_date: 2016-03-10 08:16:56
@_author: Henry Baker 
@_subject: [Cryptography] Decentralized cosigning: Apple can't sign on its own 
FYI --
Cothority to Apple: Let's make secret backdoors impossible
Decentralized cosigning could make it tough for government to gain access.
by J.M. Porup (UK) - Mar 10, 2016 2:34 pm UTC
Cothority, a new software project designed to make secret backdoored software updates nearly impossible, is offering to help Apple ensure that any secret court orders to backdoor its software cannot escape public scrutiny.
Currently, when Apple or any software maker issues a software update, they sign the update with their encryption keys.  But those keys can be stolen, and a government could coerce the company to sign a backdoored software update for a targeted subset of end users--and do so in secret.
Cothority decentralises the signing process, and scales to thousands of cosigners.  For instance, in order to authenticate a software update, Apple might require 51 percent of 8,000 cosigners distributed around the world.
"Before accepting any software image the device's update mechanism verifies that it has been signed not only by the software maker but also by a threshold number of the designated witnesses," Bryan Ford of the Cothority project said in a blog post that will be published later today.  [Update: it's now published.]  "In essence, the device does not accept any software image unless it arrives with a cryptographic 'proof' that this particular software image has been publicly observed by--and placed under the scrutiny of--a decentralised group of independent parties scattered around the world in different jurisdictions."
The problem of multi-party cryptographic signatures has long been solved, Ford noted.  What Cothority has done is solve the problem at scale.  Even an urgent software update containing a critical security patch could be logged and signed by thousands of witnesses in a matter of seconds.
Enlarge / What a classic petition would look like as a cryptographic multisignature
"This issue of whether governments should be allowed to force companies to create backdoored versions of their software, however it's answered, it's great that it's being debated in public," Ford told Ars.  "We need to make sure that the issue remains public."
Cosigners are not expected to review source code, and indeed in the case of a proprietary operating system like iOS, would not be able to do so.  Source code transparency is not the goal of the project, however.  Rather, Cothority witnesses can proactively guarantee transparency by publicly logging any binaries they are requested to sign, even if they do no checking of the software update itself.
So if Apple requested Cothority witnesses to cosign a software update that was then only distributed to a small group of people, that would immediately draw public scrutiny.
Of course, the reliability of such a system depends on how trustworthy the witnesses are.  Ford suggests that witnesses should be distributed around the world, in multiple jurisdictions, and include civil society groups like EFF, ACLU, CDT, and others.
Technical end users could even tweak their client software trust settings to only install updates signed by witnesses they especially trust.
The declining half-life of secrets
Not everyone agrees that Cothority will solve the problem of government-ordered backdoors, though.  "Ultimately it's a hurdle that our legal system could still abuse," Jonathan Zdziarski, an iOS forensics expert, told Ars.  "There are plenty of cases where false witness has been given in the real world.  Even worse, the idea would give a false sense of security to people that the system was not rigged, when indeed it can most certainly still be rigged, so it reinforces a system that could in fact be broken."
Ford acknowledged as much.  Cothority does not make it impossible for a powerful adversary to compel Apple, or another software maker, to issue a backdoored software update in secret, Ford said, but does make it much more difficult.  A nation-state attacker could, in theory, bribe thousands of witnesses, or coerce them to sign a targeted software update in secret.  Or such an attacker could hack those witnesses' computers and issue fake signatures.
Given the declining half-life of secrets, though, it seems likely that any such coercion, bribery, or hacking would eventually come to light--defeating the point of doing so in the first place.
Ford also points out that Cothority can't defend against a "bug door" slipped into iOS by, say, an undercover NSA employee working for Apple.  Nor can it prevent the government from coercing Apple to backdoor all iOS devices.
Inserting such a general-purpose backdoor, however, runs the risk of making iOS devices vulnerable to any black hat or nation-state attacker who managed to discover that backdoor.  The recent revelation that a probable NSA backdoor in Juniper routers was subsequently exploited by another nation-state spy agency--likely China--serves as a cautionary tale.
The Cothority project has been peer-reviewed, and Ford and his team will present their research at the IEEE Symposium on Security and Privacy in May in San Jose, California.  The draft paper, set to be formally published on March 18, is already online if you want to check it out.
"I would do anything I can to make it happen"
Ford says Cothority could be ready to deploy in less than six months, and is eager to see Apple adopt decentralised witness cosigning.  "I would do anything I can to make it happen even without [a financial incentive]," Ford said.  "I would absolutely work with them in an instant if I saw a willingness to make it happen."
"In the case of Apple, if they wanted to deploy it, the obvious way to do so would be to integrate collective signing into their software update and verification process," he added.  "I don't know the technical details of how their process works, and a lot would depend on that."
Even if Apple loses their current dispute with the FBI, Ford is still confident Cothority can guarantee transparency.  If the FBI sets a precedent in this case, he said, "the floodgates will open to hundreds of similar demands from state and local agencies, foreign governments, etc."
In such a scenario, Ford said, the FBI would likely demand that Apple hand over their signing keys, in the same way they demanded Lavabit hand over their TLS/SSL keys in 2013.  But Cothority's decentralised witness cosigning model would deny the FBI, or any other government in possession of Apple's signing keys, the power to unilaterally sign and issue targeted backdoored software updates.
"So even if the FBI gets its way, software transparency through collective signing can ensure at least that the public remains aware how far down the slippery slope from device-specific to general-purpose backdoors we might be at any given time," Ford said.  "While is is not a slippery slope we want to be on at all, if we're forced onto it, software transparency could at least make it less slippery."
Apple did not respond to our request for comment.
J.M. Porup is a freelance cybersecurity reporter who lives in Toronto.  When he dies his epitaph will simply read "assume breach."  You can find him on Twitter at

@_date: 2016-03-10 16:17:11
@_author: Henry Baker 
@_subject: [Cryptography] Apple's suzerainty problem 
FYI --  Good job, DoJ; "suzerainty" scores 22 Scrabble points!  I guess those >700 SAT English scores are worth something, after all!  Those of us with >700 math scores are in abject awe!
"Apple intentionally and for commercial advantage retains exclusive control over the software that can be used on iPhones, giving it monopoly-like control over the means of distributing software to the phones.  Apple does so by:
(1) firmly controlling iPhones operating systems and first-party software;
(2) carefully managing and vetting third-party software before authenticating it for use on iPhones; and
(3) continually receiving information from devices running its licensed software and its proprietary services, and retaining continued access to data from those devices about how its customers are using them.
Having established *suzerainty* over its users phonesand control over the precise features of the phones necessary for unlocking themApple cannot now pretend to be a bystander, watching this investigation from afar."
DoJ brief page 14
I would love to think that Dan Geer's suggestion re open source software minimizing liability.
However, I'm not so sure that an open source developer like Ubuntu would fare any better if it had developed the software in question.  In fact, Apple may well be one of the few companies with the financial resources to really fight the govt on this issue.

@_date: 2016-03-10 16:42:32
@_author: Henry Baker 
@_subject: [Cryptography] When did Apple customers stop beating their wives? 
FYI --
"By accumulating its hypothetical future burdens, Apple suggests that because so much criminal evidence is hidden on its warrant-proof iPhones, it should not be compelled to assist in gathering evidence related to the terrorist attack in San Bernardino."
DoJ brief page 27
In other words, the only way we can prove that Apple customers *aren't* terrorists is by examining the contents of each and every one of their phones.

@_date: 2016-03-10 17:02:57
@_author: Henry Baker 
@_subject: [Cryptography] DoJ2Apple: Weak crypto req'd so strong crypto is 
FYI --
"Apple speculates that there is no law-enforcement benefit to removing barriers
to unlocking an iPhone because criminals and terrorists will encrypt their data in other
ways.  (Opp. 25.)  If this reasoning were correct, there would be no purpose to wire-taps,
But the reasoning is flawed, for three reasons.
First, as the wire-tap context illustrates, just because criminals can add another layer of security (such as talking in code), they do not always do so.
Second, even if there are further layers of encryption, the government may be able to pierce that encryption-but only if it can get into the phone in the first place.
Third, even assuming counterfactually that unlocking iPhones would not be useful in the future due to changes in criminal and terrorist behavior, it is useful today for gathering evidence related to the terrorist mass-murder in San Bernardino."
Footnote on DoJ brief p. 24.
Basically, DoJ/FBI is saying that Apple needs weak encryption, to enable DoJ/FBI to
"see" when strong crypto is being used.  But such weak encryption only makes sense
if you're doing ubiquitous, cheap mass surveillance.
Clearly FBI is now carrying water for the NSA.
This whole case is getting nuttier & nuttier by the day.

@_date: 2016-03-10 17:31:39
@_author: Henry Baker 
@_subject: [Cryptography] What if DoJ breaks Apple's chain-of-trust? 
We're now seeing develop in real time the
nightmare that the current Certificate
Authority chain-of-trust has become.  "A chain
is as strong as its weakest link", and we now
know where that weakest link resides: in an HSM
safe somewhere in Appleland, and that single
link seems to be vulnerable to XKCD's $5 wrench
Apple's simply not in a position to follow
Lavabit down the gang plank to oblivion, so
there is some possibility it will have to lean
over & pick up the soap.
If a chain can be broken at a single point of
failure, then we obviously need something more
robust -- analogous to fiberglass or carbon
fiber rope, where the rope holds if some % of
the fibers less than some critical threshold
are the only ones that are broken.
But such a system vastly complicates the
already complex task of getting a trustworthy
firmware update.  The firmware updater now
has to check for *certificate revocation* ?
Each chip may require some sort of internal
clock (which needs to be able to run years
w/o power -- probably doable with today's
chip technology) in order to not be fooled
into accepting no-longer-valid certificates.

@_date: 2016-03-11 21:20:53
@_author: Henry Baker 
@_subject: [Cryptography] Govt Can't Let Smartphones Be 'Black Boxes, 
FYI -- So much for a "balanced" view...
Government Can't Let Smartphones Be 'Black Boxes,' Obama Says
Justin Sink
March 11, 2016 -- 5:00 AM EST
Updated on March 11, 2016 -- 5:24 PM EST
President Barack Obama said Friday that smartphones -- like the iPhone the FBI is trying to force Apple Inc. to help it hack -- can't be allowed to be "black boxes," inaccessible to the government.  The technology industry, he said, should work with the government instead of leaving the issue to Congress.
"You cannot take an absolutist view on this," Obama said at the South by Southwest festival in Austin, Texas.  "If your argument is strong encryption no matter what, and we can and should create black boxes, that I think does not strike the kind of balance we have lived with for 200, 300 years, and it's fetishizing our phones above every other value."
Obama's appearance on Friday at the event known as SXSW, the first by a sitting president, comes as the FBI tries to force Apple Inc. to help investigators access an iPhone used by one of the assailants in December's deadly San Bernardino, California, terror attack.  Apple has appealed a magistrate court order that it assist the government, saying to do so would undermine its encryption technology.
Rapid technological advancements "offer us enormous opportunities, but also are very disruptive and unsettling," Obama said at the festival, where he hoped to persuade tech workers to enter public service.  "They empower individuals to do things that they could have never dreamed of before, but they also empower folks who are very dangerous to spread dangerous messages."
Siding with Apple are technology companies including Amazon Inc., Microsoft Corp., Facebook Inc. and Google's parent Alphabet Inc.  On Thursday, the government filed a memorandum in the case arguing that Apple would need to assign as few as six workers for as little as two weeks to hack into Syed Farook's phone.
"This burden, which is not unreasonable, is the direct result of Apple's deliberate marketing decision to engineer its products so that the government cannot search them, even with a warrant," government attorneys said in the filing.
'Sloppy and Rushed'
Obama was interviewed at the festival by the CEO and editor in chief of the Texas Tribune, Evan Smith, who told him that "it looks to the tech community, or to some in the tech community, that government is the enemy" in its dealings with Apple.  South by Southwest, now 30 years old, has grown from an event to highlight local musicians and artists into one of the nation's largest and most popular technology conferences and film-and-music festivals.
The White House has backed the FBI in its fight with Apple, but has said Obama believes it it is vital to balance privacy protections against the needs of law enforcement.  Obama has not weighed in on legislation being drafted by Senate Intelligence Committee Chairman Richard Burr, a North Carolina Republican, and the senior Democrat on the panel, Dianne Feinstein of California, which would require companies to comply with court orders asking for assistance accessing encrypted data.
He indicated on Friday that he believes leaving the matter to lawmakers may not be ideal.  The result would be "sloppy and rushed and it will go through Congress in ways that have not been thought through," he said.
Apple and other tech firms have said that building backdoors into their encrypted products could put them at a disadvantage to foreign competitors.  They have also warned that China or other countries could demand similar cooperation with government investigations.
Without commenting on the Apple case, Obama dismissed those arguments, saying that for centuries law enforcement agencies have been able to search private property for evidence of crimes using a warrant.
"The question we now have to ask is, if technologically it is possible to make an impenetrable device or system, where the encryption is so strong there's no key, there's no door at all, then how do we apprehend the child pornographer? How do we solve or disrupt a terrorist plot?" Obama said.  "If in fact you can't crack that at all, government can't get in, then everybody's walking around with a Swiss bank account in their pocket."
Compromise is possible, he said, and the technology industry must help design it.
"I suspect the answer is going to come down to, how do we create a system that, encryption is as strong as possible, the key is secure as possible, and it is accessible by the smallest number of people possible for the subset of issues that we agree is important," he said.
Recruiting Coders
It isn't the first time his policies have caused the White House a headache at the Austin festival.  In 2014, former NSA contractor Edward Snowden gave a virtual keynote speech from Russia on privacy rights.  WikiLeaks editor-in-chief Julian Assange also spoke remotely to the conference that year.
Snowden's leaks have complicated the encryption issue, Obama said, by "elevating people's suspicions" of government surveillance.
Still, White House officials believe that engagement with the technology sector is critical, especially if the administration is to recruit talented programmers to help modernize the federal government.
"Cooperation that exists between the government and the tech sector continues beyond the issue of encryption," Jason Goldman, the White House's chief digital officer, said on a conference call with reporters before Obama's appearance.
In recent years, Obama has hired officials from companies including Microsoft, Alphabet, and Twitter Inc. to help repair the broken HealthCare.gov enrollment system and the byzantine Veterans Affairs claims processing system, among other assignments.  The administration hopes the president's appearance at SXSW can help replenish the ranks of hundreds of technology specialists who put their Silicon Valley careers on hold for public service.
Obama called HealthCare.gov "an example of the big and the bloated and frustrating" in government.  When the website failed in October 2013, he said, it "was a little embarrassing for me because I was the cool early adopter president.  My entire campaign had been premised on having really cool technology and social media and all that."
After fixing HealthCare.gov with the assistance of private-sector technology experts, "what we realized was we could potentially build a SWAT team, a world class tech office inside of the government, that was helping across agencies," Obama said.  That became the U.S. Digital Service.
Cellphones are only the beginning.  Fitbits, iWatches, hearing aids, drug pumps.  These are all scary things with infernal *computers* with *encryption* built inside them, that can mean only one thing: the person carrying them must be a *terrorist*.
Obama obviously has dibs on every IoT device, as well.

@_date: 2016-03-12 14:32:16
@_author: Henry Baker 
@_subject: [Cryptography] Wire.com: private communications, always encrypted 
"Go ahead, make some free, end-to-end encrypted video calls on Wire"
Details of wire.com security:
Interesting timing, this wire.com announcement.

@_date: 2016-03-12 22:56:42
@_author: Henry Baker 
@_subject: [Cryptography] Govt Can't Let Smartphones Be 'Black Boxes, 
A case could be made that citizen crypto is protected -- at least in the U.S. -- by the *Second* Amendment.  Crypto has been considered "arms" on & off for hundreds of years, so crypto is as much a right under the Second Amendment as a firearm.
Plus, it's really difficult to kill 14 people by spraying them with random bits from the high capacity magazine of a random number generator, so the anti-gun people like Senator Feinstein should be thrilled with this interpretation.

@_date: 2016-03-13 20:47:26
@_author: Henry Baker 
@_subject: [Cryptography] Govt Can't Let Smartphones Be 'Black  Boxes, 
One if by land; two if by sea.
Code/encryption -- all part of being a militia.
The real reason no one wants to argue this is that most of the folks who are for citizen encryption are against citizen guns.  So they've tied their own hands when they go to argue in court.

@_date: 2016-03-14 12:09:10
@_author: Henry Baker 
@_subject: [Cryptography] Apple Buys Ink by the Barrel? 
FYI --
In the Apple Case, a Debate Over Data Hits Home
By MICHAEL D. SHEAR, DAVID E. SANGER and KATIE BENNERMARCH 13, 2016
WASHINGTON -- Three years ago, reeling from Edward J. Snowden's disclosure of the government's vast surveillance programs and uncertain how to respond, President Obama said he welcomed a vigorous public debate about the wrenching trade-offs between safeguarding personal privacy and tracking down potential terrorists.
"It's healthy for our democracy," he told reporters at the time.  "I think it's a sign of maturity."
But the national debate touched off this winter by the confrontation between the Justice Department and Apple over smartphone security is not exactly the one Mr. Obama had in mind.
Mr. Snowden's revelations produced modest changes and a heightened suspicion of the government's activities in cyberspace.  Because the issue now centers on a device most Americans carry in their pockets, it is concrete and personal in a way that surveillance by the National Security Agency never was.
The trade-offs seem particularly stark because they have been framed around a simple question: Should Apple help the F.B.I. hack into an iPhone used by a gunman in the massacre last December in San Bernardino, Calif.?
Law enforcement officials have been adamant they must be able to monitor the communications of criminals.  They received a vote of confidence from Mr. Obama on Friday, when he said the "absolutist" position taken by companies like Apple is wrong.  But the pushback has been enormous.
In the month since a judge ordered Apple to comply with the F.B.I., the debate has jumped from the tech blogs to the front pages of daily newspapers and nightly newscasts.  Supporters of the company's position have held rallies nationwide.  Late-night comedians have lampooned government snoopers.  Timothy D. Cook, the usually publicity-shy Apple chief executive, pleaded his case on "60 Minutes" last December.  On Twitter, " fills the screen with impassioned debate on both sides.
"Discussing the case with my friends has become a touchy subject," said Matthew Montoya, 19, a computer science major at the University of Texas, El Paso.  "We're a political bunch with views from all across the spectrum."
Like many of her friends, Emi Kane, a community organizer in Oakland, Calif., recently found herself arguing via Facebook with a family friend about the case.  Ms. Kane thought Apple was right to refuse to hack the phone; her friend, a waitress in Delaware, said she was disgusted by Apple's lack of patriotism.
After exchanging several terse messages, they agreed to disagree.  "It was a hard conversation," Ms. Kane said.
The novelist Russell Banks, who signed a letter to Attorney General Loretta Lynch on behalf of Apple, said he had spoken with more than a dozen people about the case just in the last week.
"It's not just people in the tech industry talking about this," Mr. Banks, the author of "Affliction" and "The Sweet Hereafter," said.  "It's citizens like myself."
That may be because the Apple case involves a device whose least interesting feature is the phone itself.  It is a minicomputer stuffed with every detail of a person's life: photos of children, credit card purchases, texts with spouses (and nonspouses), and records of physical movements.
Mr. Obama warned Friday against "fetishizing our phones above every other value."  After avoiding taking a position for months, he finally came down on the side of law enforcement, saying that using technology to prevent legal searches of smartphones was the equivalent of preventing the police from searching a house for evidence of child pornography.
"That can't be the right answer," he said at the South by Southwest festival in Texas, even as he professed deep appreciation for civil liberties and predicted both sides would find a way to cooperate.  "I'm confident this is something that we can solve."
The technology company has been locked in a major legal battle against law enforcement officials over privacy and security.
But polls suggest the public is nowhere near as certain as Mr. Obama.  In surveys, Americans are deeply divided about the legal struggle between the government and one of the nation's most iconic companies.  The polls show that Americans remain anxious about both the threat of terrorist attacks and the possible theft of personal digital information.
A Wall Street Journal/NBC News survey released last week found that 42 percent of Americans believed Apple should cooperate with law enforcement officials to help them gain access to the locked phone, while 47 percent said Apple should not cooperate.  Asked to weigh the need to monitor terrorists against the threat of violating privacy rights, the country was almost equally split, the survey found.
That finding may have seemed unlikely in the wake of terrorist attacks last year in Paris and San Bernardino.  In December, eight in 10 people said in a New York Times/CBS News survey that it was somewhat or very likely that there would be a terrorist attack in the United States in the coming months.  A CNN poll the same month found that 45 percent of Americans were somewhat or very worried that they or someone in their family would become a victim of terrorism.
But despite the fears about terrorism, the public's concern about digital privacy is nearly universal.  A Pew Research poll in 2014 found more than 90 percent of those surveyed felt that consumers had lost control over how their personal information was collected and used by companies.
The Apple case already seems to have garnered more public attention than the Snowden revelations about "metadata collection" and programs with code names like Prism and XKeyscore.  The comedian John Oliver once mocked average Americans for failing to know whether Mr. Snowden was the WikiLeaks guy or the former N.S.A. contractor (he was the latter).
Now, people are beginning to understand that their smartphones are just the beginning.  Smart televisions, Google cars, Nest thermostats and web-enabled Barbie dolls are next.  The resolution of the legal fight between Apple and the government may help decide whether the information in those devices is really private, or whether the F.B.I. and the N.S.A. are entering a golden age of surveillance in which they have far more data available than they could have imagined 20 years ago.
"It's an in-your-face proposition for lots more Americans than the Snowden revelation was," said Lee Rainie, director of Internet, science and technology research at Pew Research Center.
Cindy Cohn, executive director of the Electronic Frontier Foundation, said: "Everyone gets at a really visceral level that you have a lot of really personal stuff on this device and if it gets stolen it's really bad.  They know that the same forces that work at trying to get access to sensitive stuff in the cloud are also at work attacking the phones."
For the F.B.I. and local law enforcement agencies, the fight has become a high-stakes struggle to prevent what James B. Comey, the bureau's director, calls "warrant-free zones" where criminals can hide evidence out of reach of the authorities.
Officials had hoped the Apple case involving a terrorist's iPhone would rally the public behind what they see as the need to have some access to information on smartphones.  But many in the administration have begun to suspect that the F.B.I. and the Justice Department may have made a major strategic error by pushing the case into the public consciousness.
Many senior officials say an open conflict between Silicon Valley and Washington is exactly what they have been trying to avoid, especially when the Pentagon and intelligence agencies are trying to woo technology companies to come back into the government's fold, and join the fight against the Islamic State.  But it appears it is too late to confine the discussion to the back rooms in Washington or Silicon Valley.
The fact that Apple is a major consumer company "takes the debate out of a very narrow environment -- the universe of technologists and policy wonks -- into the realm of consumers where barriers like the specific language of Washington or the technology industry begins to fall away," said Malkia Cyril, the executive director of the Center for Media Justice, a grass-roots activist network.
That organization and other activist groups like Black Lives Matter have seized on the issue as important for their members.  In February the civil liberties group Fight for the Future organized the day of protest against the government order that resulted in rallies in cities nationwide.
"When we heard the news and made a call for nationwide rallies, one happened in San Francisco that same day," said Tiffiniy Cheng, co-founder of Fight for the Future.  "Things like that almost never happen."
Ms. Cyril says the public angst about the iPhone case feels more urgent than did the discussion about government surveillance three years ago.
"This is one of those moments that defines what's next," she said.  "Will technology companies protect the privacy of their users or will they do work for the U.S. government?  You can't do both."
Michael D. Shear and David E. Sanger reported from Washington, and Katie Benner from San Francisco.
A version of this news analysis appears in print on March 14, 2016, on page A1 of the New York edition with the headline: Apple Battle Strikes Nerve .
Perhaps DoJ/FBI should have noticed that Americans spend more time with their iPhone than any other loved one, prior to picking a fight with Apple.
If you thought people would get upset if someone messed with their Medicare, just try messing with their iPhones...
Jez sayin'

@_date: 2016-03-15 14:41:22
@_author: Henry Baker 
@_subject: [Cryptography] MSFT doesn't retain keys for its own German cloud 
FYI --
Take that, DoJ/FBI !
You have to ask Deutsche Telekom instead.
Of course, Deutsche Telekom has an intimate relationship with Nessa, so this whole thing is an elaborate (Bourne? Pass-the-hash?) shell game.
I simply gotta march,
My heart's a drummer.
Don't bring around a cloud
To rein in my parade!
I simply gotta march,
My heart's a drummer.
Nobody, no, nobody
Is gonna rein in my parade!
Nessa's song (apologies to Barbra Streisand)

@_date: 2016-03-15 19:52:35
@_author: Henry Baker 
@_subject: [Cryptography] MSFT doesn't retain keys for its own German cloud 
I should think that Deutsche Telekom (Frau Bell?) would have an equally good relationship with the NSA.  After all, Uncle Sugar paid to rebuild the West German telephone system after WWII (which is why W. Germany has the newest physical plant in Europe and E. Germany didn't -- at least as of 1990).

@_date: 2016-03-16 07:30:50
@_author: Henry Baker 
@_subject: [Cryptography] Apple Reply to USG Opposition to Vacate Decrypt 
Outstanding collection of documents; if you want to catch up on what's been going on, this is the "go to" collection.
Other than the brief itself, the declarations of the Apple engineers are also quite interesting.

@_date: 2016-03-16 09:01:19
@_author: Henry Baker 
@_subject: [Cryptography] Michael Chertoff uses 2nd Amendment arg for 
FYI --
Beyond Encryption: Why We Can't Come Together on Security and Privacy
49 minutes
Re: concept of individual security & national security reinforcing each other:
At 15:07:
"One of the things we see in the area of cyber security is, unlike physical security where you basically rely on the police or if there's a war and you rely on the military, when we deal with cyber attacks, we've been telling people basically most of the responsibility to defend your network and your data is on you.  It's on you as part of the private sector.
"So if we're going to ask the private sector to be partners, in securing our data, whether it's information, or operating control systems, then we've got to allow the private sector to have the tools in order to carry out that mission.
"So to me, I view encryption a little bit the way the musket was to a  militia man back in the days of the Revolution.
"It is part of the defensive weapon that all of us carry to try to protect our data and our infrastructure from attacks, either from criminal groups or from people from outside the country."
Michael Chertoff, Executive Chairman and Co-Founder, The Chertoff Group

@_date: 2016-03-16 09:07:59
@_author: Henry Baker 
@_subject: [Cryptography] Trust & randomness in computer systems 
Even though I'm a formalist by nature & training,
I can see that formal methods are not going to be
sufficient to solve most of the problems in computer
security today.
Part/most of the reasons have to do with the fact
that we're trying to replace the engine & wings on
a plane that's already flying with billions of folks
aboard.  For example, we jumped into e-commerce
before we even knew how to build safe & secure
crypto systems.  We still don't, but we're a lot
better than we used to be; unfortunately, we're
still putting out crypto fires that started 25
years ago.
I've come around to Dan Geer's way of thinking:
look to biological systems.  They've been dealing
with "security" problems for perhaps 2 billion
years, so there's some chance that they have
some tricks up their microscopic sleeves.
For example, it would seem that cell "suicide"
is a lot more common than previously thought.
If a cell determines that it has been overwhelmed
by forces that it cannot control, and this is
a threat that can overwhelm other cells, as well,
it will commit suicide in an attempt to stop a
pathogen from spreading.  Ditto for individual
plants and animals; the survival of the species
is more important than the survival of the
As IoT computers become cheaper than the postage
it costs to mail them, it is no longer necessary
to "save" the computer or even "reprogram" it.
Throw it away -- or better yet, grind it to dust.
(Note to E.E.'s: we need cheap chips which can
self-destruct rather than disclose priceless
Since it's "turtles all the way down", and since
turtles can't be trusted, we need to *build
distrust* into all of our systems.  We can no
longer take a NAND gate at face value & trust
that it computes correctly.  Yes, the vast
majority of faulty NAND gates will be due to
the usual manufacturing defects, but some will
be due to *faulty design*, and some will be
due to *malicious behavior* on the part of
some criminal or state (but I might be
repeating myself).
We now build *distributed* power supplies
into all of our electronic components,
because it's far more robust than attempting
to guarantee a sufficiently smooth source of
power from the higher-level subsystem.  We
didn't do this out of a lack of trust in
power supplies, but perhaps we should, as
power supplies can be maliciously manipulated
to cause glitches which can be exploited.
We now build *error correcting codes* into
nearly every subsystem, because 1) it's
relatively cheap; and 2) because the cost
of attempting to debug every single type
of signal propagation error is prohibitive.
We may not have considered trust when
incorporating ECC, but nowadays we might
seriously consider using SHA256 instead of
(or in addition to) traditional ECC.
For all of these reasons, we need to build
distributed *distrust* into every component.
Another inspiration from biology: embrace
randomness.  We've gone to every conceivable
effort to eliminate randomness from our
electronic systems, yet every IoT device
*requires* randomness in order to properly
generate the random crypto *keys* it will
need in order to communicate with other
components *securely*.
Furthermore, this exquisite *cleanliness*
of component power supplies and signals
means that it is almost trivial to snoop
on these subsystems to determine when
they are computing with crypto keys and
then to extract those keys.
There has got to be a new type of computer
design in which the randomness is not only
not extinguished, but embraced, so that
computations are inherently far more
random (and hence can't be easily snooped),
and randomness for crypto keys is trivially
I don't have the solutions, but I'm afraid
that we've only been looking near the
lampposts where the light is the brightest.
We need to move away from the lampposts &
look further afield.

@_date: 2016-03-17 10:05:54
@_author: Henry Baker 
@_subject: [Cryptography] DoJ/FBI's "nuclear"/Lavabit option 
FYI --
"That is, instead of asking Apple to create a hacking tool that would permit the FBI to attempt to brute-force a phone's passcode without triggering escalating delays between guesses or deletion of encrypted data, they could simply demand that Apple turn over the source code and documentation the FBI would need to develop its own custom version of the iOS boot ROM, sans security features.  Then, they require Apple to either cryptographically sign that code or provide the government with access to its developer credentials, so that the FBiOS can run on an iPhone."
"Somewhat amusingly, Lavabit tried to comply "by turning over the private SSL keys as an 11 page printout in 4-point type." The feds complained that "the FBI would have to manually input all 2,560 characters, and one incorrect keystroke in this laborious process would render the FBI collection system incapable of collecting decrypted data." Poor, poor FBI. The judge has no problem putting a massive burden on Lavabit, but asking the FBI to actually do some data entry is too onerous? Yup. Apparently. The court then ordered Levison to provide a more useful electronic copy, which then resulted in the $5,000/day fine for failing to live up to that, and then the closure of the site."
I suspect that if Apple printed out its source code in 4-point type, it would be considerably larger than 11 pages.
When IBM was faced with anti-trust litigation from the U.S. Govt in the late 1960's, it famously delivered the subpoena'd discovery documents in a number of moving-van-type semi-trailer-truck-fulls of boxes.  I think it took years for the govt to wade through the documents.
Perhaps Apple is currently doing an internal version of the "obfuscated C contest", to slow down this brute force attack.
This might be a good time for Apple to invest in a "return-oriented programming" (ROP) compiler for their firmware loader, so the FBI team can play "find the delay counter".

@_date: 2016-03-17 14:51:09
@_author: Henry Baker 
@_subject: [Cryptography] DoJ/FBI's "nuclear"/Lavabit option 
It's time for a digital version of Al Gore's "Lock Box":
Encrypt discoverable data using random keys of carefully selected lengths, and then destroy the keys.  (This is an improvement upon Ben Franklin's key escrow system: "3 can keep a secret, so long as 2 of them are dead".)
The key lengths are carefully chosen to match the expected computing power available 5-10 years in the future, but at a quite substantial price.
In the case of something as valuable as Apple source code, which might be worth $100 billion today, but only $50 million in ten years, an appropriate key length should be computable.
If in 10 years someone wants to put up $50 million to decrypt -- knock your socks off.
Such a digital lock box closely approximates Comey's/Vance's warrantable safe; the only problem is that it might take 10 years to drill into such a digital safe.
This is essentially what DoD is *already* doing with their classification codes -- trying to make sure that the encryption lasts as long as the secrets it's trying to protect.  Ditto for the entertainment industry.
There's not much difference between this scheme and "paging out" your data base onto really slow tape drives and storing the tapes in some salt mine that could take weeks to sort through (assuming that you can still find an operable tape drive to play it back).  Oh wait!  That's NASA's backup strategy!
(NASA could have a better strategy: send a digital repeater (bent tube) into interstellar space, and then start shuttling the data back and forth like the mercury delay lines of old.  Once the repeater gets a couple of light-years out, they can set up a digital "lock box".)

@_date: 2016-03-17 17:39:22
@_author: Henry Baker 
@_subject: [Cryptography] Apple GovtOS/FBiOS & Proof of Work 
If Apple is willing to put some serious Proof of Work into constructing *every* firmware update, then it could achieve some level of privacy:
When constructing a firmware update, the SHA512 (or better still, some Apple proprietary) hash of the update has to have some preset number of '0' bits.  So Apple will have to brute force fiddle with bits in the firmware load to achieve an appropriate hash.  The work involved should grow exponentially in the # of '0' bits required.
Most companies operate on a fixed update schedule, so Apple would have to plan every release far enough in advance to give Apple enough time to compute such a firmware load.  The reason for an Apple proprietary hash is so any attacker would have to build their own custom chips to be able to beat Apple at this Proof of Work game.  Note also, that Apple can *change* the hash function on every firmware update, so said custom chip would be useful for only one firmware release.
The firmware loader of course refuses to load any firmware whose hash doesn't have the appropriate number of '0' bits (along with the standard Apple signing key checks, etc.).  The hash also incorporates the previous firmware load a la Merkle, so if your firmware is ever compromised, your iPhone is forever bricked.
The hardware loading code refuses to load the first block of the new firmware anywhere but right on top of the user's file encryption key.  So the *default* for the firmware flasher is to always *forget* this key, unless very special arrangements are made to save this key in other places.  This key is further encrypted and broken into many pieces prior to moving it out of the way of the firmware loader (including into the CPU's volatile register memory, so any power disruption will destroy some of this key).
Of course, much like a password hashing function, such Apple hash functions would be designed specifically to be *slow*, so GPU's and gate-arrays would be of no particular value.
With a proper PoW system, any attacker would have to spend at least as much time as Apple themselves to create a loadable firmware, and that time might be as long as 6-12 months.
A scalable way for Apple to dominate any attacker (including most nation-states) is to utilize the *entire installed base* of Apple products (estimated by Tim Cook to be >1 billion devices) in a distributed calculation.  Thus, Apple could use its "herd" itself to provide for "herd immunity" to firmware update attacks.  iPhone users would notice if Apple were attempting to compute >1 firmware update PoW at any given time!
A 6-12 month lead time (during which the PoW for GovtOS is being computed) would give Apple plenty of time to respond to any legal issues and warn other Apple customers of an impending breach-of-trust in the firmware update chain.
If Apple is issued an NSL and can't talk about it, 6-12 months would still be a long enough delay to deter all but the most persistent of govts.  Even Napoleon refused to look at any messages until they were at least 3 days old; he found out that 99% of these messages resolved themselves without any action on his part -- e.g., "please pardon my son; he is to be executed in the morning".
If Apple speeded up or slowed down its pre-announced firmware update schedule, that change itself would provide an excellent "warrant canary".

@_date: 2016-03-17 22:46:59
@_author: Henry Baker 
@_subject: [Cryptography] Apple engineers risk ethics violations if they comply 
FYI --
"In the hierarchy of civil disobedience, a computer scientist asked to place users at risk has the strongest claim that professional obligations prevent compliance," said Marc Rotenberg, executive director of the Electronic Privacy Information Center. "This is like asking a doctor to administer a lethal drug."
Apple Encryption Engineers, if Ordered to Unlock iPhone, Might Resist
By JOHN MARKOFF, KATIE BENNER and BRIAN X. CHENMARCH 17, 2016
SAN FRANCISCO -- If the F.B.I. wins its court fight to force Apple's help in unlocking an iPhone, the agency may run into yet another roadblock: Apple's engineers.
Apple employees are already discussing what they will do if ordered to help law enforcement authorities.  Some say they may balk at the work, while others may even quit their high-paying jobs rather than undermine the security of the software they have already created, according to more than a half-dozen current and former Apple employees.
Among those interviewed were Apple engineers who are involved in the development of mobile products and security, as well as former security engineers and executives.
The potential resistance adds a wrinkle to a very public fight between Apple, the world's most valuable company, and the authorities over access to an iPhone used by one of the attackers in the December mass killing in San Bernardino, Calif.
It also speaks directly to arguments Apple has made in legal documents that the government's demand curbs free speech by asking the company to order people to do things that they consider offensive.
"Such conscription is fundamentally offensive to Apple's core principles and would pose a severe threat to the autonomy of Apple and its engineers," Apple's lawyers wrote in the company's final brief to the Federal District Court for the Central District of California.
The employees' concerns also provide insight into a company culture that despite the trappings of Silicon Valley wealth still views the world through the decades-old, anti-establishment prism of its co-founders Steven P. Jobs and Steve Wozniak.
"It's an independent culture and a rebellious one," said Jean-Louis Gasse, a venture capitalist who was once an engineering manager at Apple.  "If the government tries to compel testimony or action from these engineers, good luck with that."
Timothy D. Cook, Apple's chief executive, last month telegraphed what his employees might do in an email to customers: "The same engineers who built strong encryption into the iPhone to protect our users would, ironically, be ordered to weaken those protections and make our users less safe," Mr. Cook wrote.
Apple declined to comment.
The fear of losing a paycheck may not have much of an impact on security engineers whose skills are in high demand.  Indeed, hiring them could be a badge of honor among other tech companies that share Apple's skepticism of the government's intentions.
"If someone attempts to force them to work on something that's outside their personal values, they can expect to find a position that's a better fit somewhere else," said Window Snyder, the chief security officer at the start-up Fastly and a former senior product manager in Apple's security and privacy division.
Apple said in court filings last month that it would take from six to 10 engineers up to a month to meet the government's demands.  However, because Apple is so compartmentalized, the challenge of building what the company described as "GovtOS" would be substantially complicated if key employees refused to do the work.
Inside Apple, there is little collaboration among teams -- for example, hardware engineers usually work in different offices from software engineers.
But when the company comes closer to releasing a product, key members from different teams come together to apply finishing touches like bug fixes, security audits and polishing the way the software looks and behaves.
A similar process would have to be created to produce the iPhone software for the Federal Bureau of Investigation.  A handful of software engineers with technical expertise in writing highly secure software -- the same people who have designed Apple's security system over the last decade -- would need to be among the employees the company described in its filing.
That team does not exist, and Apple is unlikely to make any moves toward creating it until the company exhausts its legal options. But Apple employees say they already have a good idea who those employees would be.
They include an engineer who developed software for the iPhone, iPad and Apple TV. That engineer previously worked at an aerospace company.  Another is a senior quality-assurance engineer who is described as an expert "bug catcher" with experience testing Apple products all the way back to the iPod.  A third likely employee specializes in security architecture for the operating systems powering the iPhone, Mac and Apple TV.
"In the hierarchy of civil disobedience, a computer scientist asked to place users at risk has the strongest claim that professional obligations prevent compliance," said Marc Rotenberg, executive director of the Electronic Privacy Information Center. "This is like asking a doctor to administer a lethal drug."
There are ways an employee could resist other than quitting, such as work absences. And it is a theoretical discussion. It could be a long time before employees confront such choices as the case moves through the legal system.
The security-minded corner of the technology industry is known to draw "healthfully paranoid" people who tend to be more doctrinaire about issues like encryption, said Arian Evans, vice president for product strategy at RiskIQ, an Internet security company. But that resolve can wither when money gets involved, he said.
An employee rebellion could throw the F.B.I's legal fight with Apple into uncharted territory.
"If -- and this is a big if -- every engineer at Apple who could write the code quit and, also a big if, Apple could demonstrate that this happened to the court's satisfaction, then Apple could not comply and would not have to," said Joseph DeMarco, a former federal prosecutor. "It would be like asking my lawn guy to write the code."
Mr. DeMarco, who filed a friend of the court brief on behalf of law enforcement groups that supported the Justice Department, also noted that if the engineers refused to write the code, rather than outright quit, "then I think that the court would be much more likely to find Apple in contempt," he said.
Rather than contempt, Riana Pfefferkorn, a cryptography fellow at the Stanford Center for Internet and Society, said Apple could incur daily penalties if a judge thought it was delaying compliance.
The government has cracked down on tech companies in the past.  A judge imposed a $10,000-a-day penalty on the email service Lavabit when it did not give its digital encryption keys to investigators pursuing information on Edward J. Snowden, the former intelligence contractor who leaked documents about government surveillance.
The small company's response could be indicative of how individual Apple employees reacted to a court order.  When Lavabit was held in contempt, its owner shut down the company rather than comply.
A version of this article appears in print on March 18, 2016, on page A1 of the New York edition with the headline: Reluctant Staff Could Impede IPhone Ruling .
"In the hierarchy of civil disobedience, a computer scientist asked to place users at risk has the strongest claim that professional obligations prevent compliance," said Marc Rotenberg, executive director of the Electronic Privacy Information Center. "This is like asking a doctor to administer a lethal drug."
If the IEEE or ACM Ethics rules mean anything, then these engineers have to stand down.

@_date: 2016-03-18 08:37:15
@_author: Henry Baker 
@_subject: [Cryptography] Formal Verification (was Re: Trust & randomness 
IMHO, this is completely backwards.
ASSERT's should always be sprinkled *extremely liberally* all over your code.
The job of a theorem prover is merely to remove ASSERT's that it can prove are *always satisfied.*  I.e., a "theorem prover" is just a really good compiler optimizer for dead code elimination.
The ASSERT's that remain (i.e., can't be removed) attest to either:
a) the weakness of the theorem prover; or
b) an actual bug or misunderstanding.
In short: there is no such thing as "formal verification", only *(correct) compiler optimizations* that can remove provably dead ASSERT codes.
If you can't remove an expensive ASSERT with a compiler optimization(*), then you sure as hell shouldn't remove it from a production system!
(*) This brings up the need for easy ways to add ad hoc, but provably correct, compiler "peephole" (?) optimizations, since no compiler will ever be able to prove -- thanks to Goedel & Turing -- without the programmer's help -- all the lemmas and theorems it will need for every program.  I need to be able to enter into a dialog with my compiler, suggesting that such-and-such should be replace by such&other under certain conditions.  The compiler will ask me to prove that my optimization is correct, which may involve inserting additional ASSERT statements into the compiler optimization.
This type of compiler extension is *easy* (or at least easiER) in introspective languages like Lisp.

@_date: 2016-03-18 06:56:17
@_author: Henry Baker 
@_subject: [Cryptography] Apple GovtOS/FBiOS & Proof of Work 
True, but do you want to require your iPhone to be connected to the Internet (so it can "see" the Bitcoin blockchain) in order to get a firmware update?
Also, when your iPhone wakes up, how does it even know -- for sure -- what time&date it is?
Someone could simply reset the clock back a few years and give it an old blockchain (or a completely made-up blockchain).

@_date: 2016-03-18 06:51:29
@_author: Henry Baker 
@_subject: [Cryptography] Snowden's email unredacted in Lavabit dox 
FYI --
Snowden WAS the Feds' quarry in Lavabit case, redaction blunder reveals
One tiny little reference missed in massive censoring effort
One of the first things we did on downloading the 560 pages [PDF] was *run a search on the word "Snowden"* and lo and behold  on page 79, while noting that the entire record was under seal, up pops the email address "Ed_Snowden at lavabit.com."
Redaction.  n.  See [redacted].

@_date: 2016-03-18 10:55:14
@_author: Henry Baker 
@_subject: [Cryptography] "Tea Consent" video for DoJ/FBI 
FYI --
~ 3 minutes.
DoJ/FBI lawyers/agents may want to consult this video before using the "c" ("compel") word...
Just because you made tea, doesn't mean you are entitled to watch them drink it.
If they say 'no thank you', then don't make them tea.  At all.
Don't make them drink tea; don't get annoyed at them for not wanting tea; they just don't want tea.
If someone said yes to tea around your house last Saturday, that doesn't mean they want you to make them tea all the time.
They don't want you to come around to their place unexpectedly and make them tea, and force them to drink it...
[Perhaps this should have been called "T* Consent" ?
*"T" = ATT stock ticker symbol...]

@_date: 2016-03-18 12:50:04
@_author: Henry Baker 
@_subject: [Cryptography] Formal Verification (was Re: Trust & randomness 
My biggest problem with "specification languages"
is that each is yet *another* language, with its
own semantics, its own standards committee, its
own bugs, etc.  More stuff to memorize, more stuff
that is too easily forgotten.
Even if your specification is flawless, you aren't
often any closer to having working code (unless the
specification language has its own interpreter, in
which case why not dispense with the "target"
language completely!).
The reason for using liberal ASSERT statements is
that they *are* executable, and are active during
debugging, so at least all of your test cases pass
the ASSERT's.
If there are any differences between the specification
and the implementation, I'd rather err on the side of
the *intersection* -- i.e., only those computations
which are consistent with *both* the specification and
the implementation will run without raising an
As some wise men (Knuth, Dikjstra, etc.) once
said, correctness first, efficiency second.
The most dangerous time for any code isn't after it
is first released.  Sure, there will be weirdnesses
in user interfaces, but not so many outright bugs.
The most dangerous time for any code is during
an *optimization* phase, where you may have forgotten
all your original test examples and the corner cases
that they tested.  This optimization is often done
by someone other than the original author, so they
usually don't understand the reasons behind all the
original implementation decisions.  The elegant
simplicity of the original code becomes hidden behind
cached values, unrolled loops, SIMD arithmetic.  The
code becomes impenetrable; e.g., look at some
implementations of crypto code; you'd never guess
that there's a pony in there somewhere!

@_date: 2016-03-18 15:03:22
@_author: Henry Baker 
@_subject: [Cryptography] Motherboard article on Lavabit case 
FYI --
On June 9, 2013, a then-unknown intelligence contractor named Edward Snowden revealed himself to be the source behind a series of explosive scoops based on top secret National Security Agency documents. The next day, a secret court in Virginia ordered the owner of a small email provider in Texas to help investigators surveil Snowdens email communications. That order set off a long legal fight that was mostly shrouded in complete secrecy for two months, until Ladar Levison, the owner of the email provider called Lavabit, decided to shut down his service rather than become complicit in crimes against the American people, as he put it at the time.

@_date: 2016-03-19 07:04:14
@_author: Henry Baker 
@_subject: [Cryptography] Apple GovtOS/FBiOS & Proof of Work 
The way crypto hash functions work is that all bit flips in the input cause bit flips in the output.  If not, Bingo! -- you have a collision, and your hash function has to be thrown away.
So all you need is a reasonably long "fiddle" string in the input file somewhere that you flip bits randomly (or some other strategy) until you achieve a hash output that meets the requirements for firmware loading.  This fiddle string is still so short as to be negligible compared with the size of the firmware itself.
BTW, the hash *includes* the hash of the previous firmware, so neither Apple -- nor anyone else -- can develop multiple firmwares in *parallel*.

@_date: 2016-03-19 15:13:55
@_author: Henry Baker 
@_subject: [Cryptography] Apple GovtOS/FBiOS & Proof of Work 
It's not just a "check sum", it's a first-class crypto hash function.
This proof-of-work strategy works just fine for Bitcoin; I just suggested moving it over to protect the Apple firmware loading sequence.

@_date: 2016-03-19 17:42:11
@_author: Henry Baker 
@_subject: [Cryptography] Apple GovtOS/FBiOS & Proof of Work 
But the iPhone doesn't know *for sure* what time it is when it wakes up.  It's too easy to turn the clock back & do another update.
That's why Apple needs the equivalent of a block chain with a proof of work to prove to every iPhone (& each & every iPhone can check that proof) that a minimum amount of work has indeed been performed (& hence a minimum amount of time) since the previous update was computed.

@_date: 2016-03-19 18:14:10
@_author: Henry Baker 
@_subject: [Cryptography] Apple GovtOS/FBiOS & Proof of Work 
And when it is loading malwareXXXXXXXfirmware, the poor little iPhone can't trust *any* of those time sources; that's the type of attack we're talking about here.
The little iPhone cpu wakes up and is given a command "I compel you to write over your current firmware with this new firmware" and that cpu has to decide -- on its own, without consulting with anyone -- whether that firmware load is trustworthy enough to accede to this command.  It doesn't know for sure what time or day it is, and can't use its camera or microphone to help it decide whether to trust the command.  Going onto the Internet is also not helpful, because the parts of the Internet it looks for can be spoofed.  It can't even trust its random number generator, because it may have been reseeded with a state known to the attacker.

@_date: 2016-03-20 15:03:32
@_author: Henry Baker 
@_subject: [Cryptography] Paris attackers used OTP's: One Time Phones 
FYI --
"Everywhere they went, the attackers left behind their throwaway phones..."
"Security camera footage showed Bilal Hadfi, the youngest of the assailants, as he paced outside the stadium, talking on a cellphone.  The phone was activated less than an hour before he detonated his vest.:
"Most striking is what was not found on the phones: Not a single email or online chat from the attackers has surfaced so far.
"Even though one of the disposable phones was found to have had a Gmail account with the username 'yjeanyves1,' the police discovered it was empty, with no messages in the sent or draft folders.  It had been created on the afternoon of the attacks..."
"Inside the ruins, the police found several dozen boxes of unused cellphones still in their wrappers.  The phones were found throughout the rubble, including in the rooms and stairwell.  Others had been ejected during the blast and fell onto the street below."
Clearly, terrorists have been binge-watching "Homeland", where Carrie & friends also go through phones like kleenex.
Yet DoJ/FBI still wants to destroy the privacy & security of the owners 1 billion Apple devices.
Apple has done everything it its power to deter One Time iPhone use, including having one of the highest prices in this market.
I also don't recall hearing about terrorists buying iPhones a dozen at a time.

@_date: 2016-03-21 17:34:49
@_author: Henry Baker 
@_subject: [Cryptography] USG moves to vacate hearing tomorrow due to 
Apple Macs, iPhones, iPads, Watches, TVs can be hijacked by evil Wi-Fi, PDFs  update now
iOS 9.3, OS X 10.11, watchOS 2.2, tvOS 9.2 all out now
21 Mar 2016 at 20:09
Apple is updating *everyone's* iPhone to FBiOS 9.3 !
Thank you, FISA NSL; we'll all sleep better tonight !

@_date: 2016-03-21 17:51:11
@_author: Henry Baker 
@_subject: [Cryptography] Lavabit's and Snowden's Solos 
Good luck detecting 'crypto functions'.  It's undecidable what a 'crypto function' is.
Ever hear of Return-Oriented Programming?
Get ready for some seriously obfuscated crypto code.
Private Information Retrieval (PIR) and Oblivious Transfer (OT) are currently slow,
but watch them blossom when the rights of free people are pissed on.
Fully-Homomorphic Encryption (FHE) is coming along, albeit slowly.  But it will make
phenomenally quick strides if an attempt is made to do something like what you suggest.
Basically, all hacks are two-edged swords: they can be used by both the bad guys and the
good guys (good luck trying to figure out which is which anymore!).

@_date: 2016-03-22 09:09:54
@_author: Henry Baker 
@_subject: [Cryptography] Formal Verification (was Re: Trust & randomness 
Stanford EE Computer Systems Colloquium
4:15PM, Wednesday, March 4, 2015
NEC Auditorium, Gates Computer Science Building Room B3
Dynamic Code Optimization and the NVIDIA Denver Processor
Nathan Tuck NVIDIA
About the talk:
NVIDIA's first 64-bit ARM processor, code-named Denver, leverages a host of new technologies to enable high-performance mobile computing.  Implemented in a 28-nm process, the Denver CPU can attain clock speeds of up to 2.5 GHz.  This talk will outline the Denver architecture and describe some of its technological innovations.  In particular this talk will discuss some of the motivations and advantages of dynamic code optimization.
There not downloadable slides for this presentation available at this time.
View Video on YouTube.
About the speaker:
Nathan Tuck has been a member of the DCO and CPU architecture teams at NVIDIA since 2009.
Nathan has spent his professional career walking a crooked line between hardware and software.  As an engineer, he is most interested in working on systems problems.  Professionally, he is most interested in dynamic environments where he can make a large difference.
Contact information:
Nathan Tuck
FYI -- "DCO": Yet more lovely places for malware to hide.  The executing code is "translated" into a microcode buffer, but who gets to be in charge of said translation?
"Those who cast the votes decide nothing.  Those who count the votes decide everything."  -- Josef Stalin
I believe that these DCO processors have already been picked up for widespread use in automobiles, including self-driving cars.
What, me worry?
Above is a message I sent almost a year ago about nVidia's new "DCO" mechanism, where the standard computer op codes are merely a gentle hint/suggestion about what the CPU should actually do.  Behind the scenes, "DCO" can re-interpret your *hardware op code* to do anything it damn well pleases.  This is the opcode equivalent of *memory maps*, which merely provide gentle hints/suggestions about where to fetch instructions.
See the Youtube video link above for more details.

@_date: 2016-03-22 12:07:55
@_author: Henry Baker 
@_subject: [Cryptography] Mike Masnick (Techdirt) explains DoJ v. Apple 
FYI -- 8.5-minute video
Apple Versus The FBI [Mike Masnick Explains] Published on Mar 21, 2016

@_date: 2016-03-23 12:39:49
@_author: Henry Baker 
@_subject: [Cryptography] Paris attackers used OTP's: One Time Phones 
In some states, merely having an *empty* more-or-less secret compartment in your car to hide your valuables in will get your assets forfeitured, and your butt thrown in jail.
What about Kali Linux, IDA Pro, Wireshark, etc., on your laptop?
Of course, that's more analogous to carrying a night vision camera or a UV flashlight than lockpicks & prybars.
Let's see how well this discussion goes over at the next DEFCON or Black Hat conference (where they have lockpicking seminars, as well as other stuff).

@_date: 2016-03-23 17:11:11
@_author: Henry Baker 
@_subject: [Cryptography] Hayden on encryption v. metadata 
Highly recommended, *especially* if you disagree with Hayden.
Basically, Hayden is ok with just about anything -- including torture -- so long as it is approved by someone higher up.  Methinks he might not fare so well in a Nuremburg-type trial, but perhaps those ethics are sooo last century.
However, Hayden does think that the FBI is p*ss*ng into the wind on encryption, because any restrictions on encryption will drive technology overseas & weaken the U.S. tech economy.
Hayden is basically agreeing with the statement "we kill people based on metadata", so you'd better believe that social graphs, GPS coordinate positions, etc., are being hoovered up, big time.  Perhaps the FBI will be forced to de-parallel-construct their DRT-bag data for the U.S. courts, but I suspect that NSA has no such scruples.
There was an unclassified program by a small midwest company a couple of years ago that did 2 things: collected huge amounts of continuous hires video surveillance imagery and built a time-line database.  Subsequently, an inquiry about the position of a car a 2:17pm at such-and-such a location could be run *backwards* in time to see where the car came from.  Although this data was used to catch a few very surprised criminals who found the police patiently waiting for them at their homes, it was either deemed too creepy (hard to believe!) or too expensive to continue.
However, I think the real reason why this surveillance technique was dropped (from public discussion, anyway) is that exactly the same database technology is *already* in use to track cellphones backwards in time.  This can be done with cheap, ubiquitous NSA junior-varsity-type technology -- collect cellphone signals, wifi signals, Bluetooth signals.
Thus, if person X is noticed at location Y at time T, then the database can track person X backwards over the past hours, days, months to see if person X ever came close to person Y.
If this happens in some locations on the globe, and if person Y is considered a "bad guy/gal", then person X is now considered to be a "bad guy/gal".  Hayden may not even know person X's name or gender, but the U.S. might still target person X for killing simply on the basis of this metadata.  Hayden seems completely ok with this sort of thinking, but then he has lime on his cleats (his too cute football analogy re coming too close to getting out of bounds).
So while the encryption fight is going on, a far more insidious type of surveillance is taking place, but without being discussed or approved by anyone in Congress or the courts.
I believe that this type of system is what Hayden is referring to when he says that -- far from "going dark" -- this is currently the "golden age" of surveillance.

@_date: 2016-03-23 21:36:27
@_author: Henry Baker 
@_subject: [Cryptography] FBI engages Isreali company to crack IPhone 
Two words: plausible deniability.
Also, $15k isn't nearly enough for what the FBI is going to do to their reputation when the FBI says "Oops, you screwed up & wiped ths *terrorist's* phone".

@_date: 2016-03-24 14:48:17
@_author: Henry Baker 
@_subject: [Cryptography] OTP phones - arrested for buying phones. 
I checked the prices of prepaid phones at the grocery store today: $4.99.
Amazon search: "burner phone" yielded 22 results: TracFone seems to be cheapest at $9.99.
PC Magazine had an article 7/28/2015: "Need a burner?  Got $25"
It would seem the Dollar General may have some of the lowest price prepaid phones, but they don't have prices on the Internet that I could find.
At $5, it would be difficult NOT to buy a dozen at a time -- just by mistake!  (Hi, I'm taking my Boy Scout troop on a trip to the big city, and I need to be able to contact them when they're out of sight -- sounds almost quaint in 2016.)
The word "burner" has prepaid phone as its second meaning, so it has now officially entered the English language.

@_date: 2016-03-26 07:24:24
@_author: Henry Baker 
@_subject: [Cryptography] More Bad Govt Shit To Fight (Burner Verizon FBI) 
It'll be interesting to see how this bill is received.
IMHO the vast majority of these phones -- at least here in California -- are used by undocumented residents, who have no papers, no driver's licenses, no bank accounts, and operate 100% on cash.
Since when do you need a driver's license or a credit card to use a phone?  These people take the bus!
In any case, we'll soon see "phones" which dispense with the 3G/4G part and use wifi only (e.g., iPod "Touch", only a heck of a lot cheaper; a lot of parents already give their kids iPod Touches because they don't want them using up minutes).  Since these wifi-only "phones" don't use licensed spectrum, they don't require SIM cards.
These phones are ATT/Verizon/Sprint's nightmare come true, and also NSA, because NSA piggybacks off the cellular carriers' metadata.

@_date: 2016-03-27 17:25:29
@_author: Henry Baker 
@_subject: [Cryptography] Mixing public key crypto systems? 
Inspired by the 'monoculture' thread, I'm curious as to whether it is possible to mix different public key crypto systems.
For example, Alice might use some version of RSA, while Bob might use some version of El Gamal.
Alice posts her public key in her chosen PK system; Bob posts his public key in his chosen PK system.  Each has to use the type of encryption chosen by the addressee of the message.
Does everything still work?

@_date: 2016-03-28 07:57:16
@_author: Henry Baker 
@_subject: [Cryptography] MSFT's Win10, Chinese Edition 
FYI --
Microsoft made a version of Windows 10 for the Chinese government
C.C. Custer 7:30 PM on Mar 24, 2016
If you're looking to grab Windows 10, there are a lot of versions to choose from: Windows 10 Home, Windows 10 Enterprise, Windows 10 Pro, Windows 10 Mobile, etc.  Now it looks like we can add a new one to the list: Windows 10 Chinese Government Edition.
That's not the real name -- it's called Windows 10 Zhuangongban, or "Windows 10 Specially-provided Edition" -- but Microsoft really has made a version of Windows 10 for the Chinese government, according to a report in Chinese magazine Caixin.  Ralph Haupter, Microsoft China's CEO, told the magazine that through a joint venture with China's CETC, Microsoft has already completed the first version of the specialized Windows version.
This shouldn't come as a major surprise, of course.  Microsoft announced the deal and its intention to develop the China-specific software back in December.
So what's different about the Chinese government version of Windows?  Haupter told Caixin that it features fewer of Microsoft's consumer-targeted apps and services, while including more management and security controls, in accordance with the needs of China's government. Haupter didn't divulge exactly what's been changed or how different the system looks from traditional Windows 10, but he did say that it retains the ability to run any Windows-compatible programs.
Microsoft vs. Kylin?
Microsoft's new Chinese-government-specific Windows 10 isn't the only Chinese-security-focused OS on the market.  For years, China's government has itself been funding and pushing the development of what is now called NeoKylin, a partially-Chinese-developed Linux fork.  That software has finally started to see use in government circles in recent years, and a version is even being used to power China's Tianhe-2 supercomputer.
Can Microsoft beat out NeoKylin?  On its face it might seem unlikely.  But NeoKylin was itself partially foreign-developed, so neither OS is truly Chinese-made.  And Windows offers the advantage of supporting a much broader range of software than Linux-based NeoKylin.  Especially at Chinese state-owned enterprises, being able to use industry-standard software tools in Windows could give Windows 10 Zhuangongban a big leg up on NeoKylin.
(h/t to Eddie Du for spotting this story)
ABOUT C.
A Tech in Asia editor focused primarily on China, with special interest in public service, environmental, and video game tech. Follow me on Twitter as Making this Chinese Win10 version had to be as simple as pie: change the addresses of a few C&C servers, change a few ECC parameters, change the language settings, and they were good to go.  Pretty much script-kiddie activity, as with any other malware.
Repressive regimes around the globe have same surveillance goals, so the N^HUSA version was already pretty close to what Beijing wanted.

@_date: 2016-03-28 12:50:55
@_author: Henry Baker 
@_subject: [Cryptography] Mixing public key crypto systems? 
Yes, I agree that the strength of the overall communication is
limited by the weaker of the two protocols.
Nevertheless, you can't force someone to produce a public key
in N different public key crypto systems.  They're going to
publish 1,2,3, maybe, but not 10.
So you're limited to the types of PK systems that they choose
for your initial communication with them, and you're also
limited to the identity you can establish with them based on
their public keys.
This is essentially analogous to me talking HTTPS to a number
of different web sites; I'm restricted to the minimum of what
they support and what my browser supports.  Unfortunately, I
have to trust Google, Mozilla & Microsoft to make sure that
my trust chain is secure (and I'm not happy about that!).
Once you've established communications with someone and wish
to communicate more privately and/or more efficiently, you
can then each produce new public keys -- either for just
this correspondent, or completely public -- for all future
The current email system is effectively plaintext only, so
the ability to quickly bootstrap into using whatever public
key systems that various individuals are already using will
certainly be better than the current situation, and provide
a way to evolve into better & better public key systems.

@_date: 2016-03-31 11:24:12
@_author: Henry Baker 
@_subject: [Cryptography] Snowden, Greenwald & Chomsky on Privacy 
FYI --
Edward Snowden, Glenn Greenwald & Noam Chomsky - A Conversation on Privacy
March 26, 2016
~ 2 hours
Excellent discussion; well worth watching.

@_date: 2016-05-01 08:00:01
@_author: Henry Baker 
@_subject: [Cryptography] sha1sum speed 
After cacheing this large file (i.e., on the 2nd & subsequent timings),
sha1sum took 24 seconds.
sha3sum (default algorithm) took 54 seconds.
sha256sum took 54 seconds.
b2sum-i686-linux took 35.7 seconds.
b2sum-amd64-linux took 27.3 seconds.
cksum took 22.8 seconds.
cfv -C -tsha1 -f- took 19.5 seconds
cfv -C -tcrc -f- took 8.8 seconds
cfv -C -tmd5 -f- took 15.6 seconds
ALL of these timings are single-threaded on the same Ubuntu box.
Soooo, there are substantial differences in calculation times -- even among SHA1 implementations.
Off-hand, I'd say that 'cksum' and 'sha1sum' could use a little TLC to improve their performance.

@_date: 2016-05-01 17:33:02
@_author: Henry Baker 
@_subject: [Cryptography] sha1sum speed 
Thanks, Bill.  I compiled b2sum on my (old) Ubuntu system and am now getting 15 secs (compare with  above)), which is almost 2X the 27.3 seconds that I got with the single-threaded x86-64 code.
Note that '-a blake2bp' uses *all 3 cores.*

@_date: 2016-05-02 07:31:11
@_author: Henry Baker 
@_subject: [Cryptography] USB 3.0 authentication: market power and  DRM? 
The CIA is already dusting people & things with synthetic
DNA to track them.  (No sh*t; check DARPA research from a
few years ago.)
Synthetic DNA is a heck of a lot cheaper.
BTW, has anyone followed the installation of car chargers?
I'd be willing to bet that these public car chargers log
every charge by some unique identifier from the car itself.
Heck, they don't even have to try very hard: simply log
the Bluetooth & Wifi id's.
Yes, a lot of people pay for gas by credit card (which is
obviously tracked), but most public car charging stations
are free (for now).
Of course, they have to get in line.  Tesla already logs
just about everything about your car & uploads the data
to Tesla.

@_date: 2016-05-05 08:32:34
@_author: Henry Baker 
@_subject: [Cryptography] TLS proxies popped 
TLS proxies: insecure by design say boffins
5 May 2016 at 07:15, Richard Chirgwin
Have you ever suspected filters that decrypt traffic of being insecure?  Canadian boffins agree with you, saying TLS proxies  commonly deployed in both business and home networks for traffic inspection  open up cans of worms.
In their tests, "not a single TLS proxy implementation is secure with respect to all of our tests, sometimes leading to trivial server impersonation under an active man-in-the-middle attack, as soon as the product is installed on a system," write Xavier de Carn de Carnavalet and Mohammad Mannan of the Concordia Institute of Systems Engineering in Montrea.
The trio's paper (PDF) goes on to say that users could be exposed to man-in-the-middle attacks or other CA-based impersonations.
We found that four products are vulnerable to full server impersonation under an active man-in-the-middle (MITM) attack out-of-the-box, and two more if TLS filtering is enabled.  Several of these tools also mislead browsers into believing that a TLS connection is more secure than it actually is, by e.g., artificially upgrading a servers TLS version at the client.
There's also the matter of how products protect their root certificates' private key.  It's not pretty, as the table ... shows.

@_date: 2016-05-05 08:51:30
@_author: Henry Baker 
@_subject: [Cryptography] USB 3.0 authentication: market power and  DRM? 
This horse left the barn with USB.  Hacked USB HID devices can cause PC's to download malware from the Internet, or infect them directly.  Check out NSA TAO's playset (Thanks, Ed Snowden).  The only "non-smart"/non-hacked HW protocol left is a UART.

@_date: 2016-05-06 06:53:21
@_author: Henry Baker 
@_subject: [Cryptography] sha1sum speed 
You are correct:
time openssl dgst -sha1 18.677 seconds ***the winner (for SHA1)***
Note that this is only a single core.
For completeness, here are the rest of the timings:
openssl dgst -sha256 takes 41 seconds.
sha1sum took 24 seconds.
sha3sum (default algorithm) took 54 seconds.
sha256sum took 54 seconds.
b2sum-i686-linux took 35.7 seconds.
b2sum-amd64-linux took 27.3 seconds.
cksum took 22.8 seconds.
cfv -C -tsha1 -f- took 19.5 seconds
cfv -C -tcrc -f- took 8.8 seconds
cfv -C -tmd5 -f- took 15.6 seconds
b2sum took 29.4 seconds
b2sum -a blake2bp took 15.034 seconds (all 3 cores)

@_date: 2016-05-08 20:57:36
@_author: Henry Baker 
@_subject: [Cryptography] russian spies using steganography? 
Intel agencies & LEO's always take advantage of any "noise" and/or chaos in the system to hide under (reminiscent of spread spectrum radio, where the signal hides many dB down in the noise).  One problem with "broken window" policing is that at some point *all* of the broken windows & other crimes are committed by undercover operatives and/or informants; e.g., in the 1950's, supposedly >50% of the dues to the American Communist Party were paid by FBI/CIA informants.  Supposedly, the biggest fallout from the OPM hack has been to take 20+ million people off the eligible rolls for "secret"/undercover agents, because all their bio info -- including their fingerprints -- has been compromised.
The FBI has had a number of money-laundering stings which involved setting up fake banks around the world.  I believe that NPR recently talked about one such operation.  These kinds of operations only work if there are already a lot of other shady operators for the FBI to hide among.
I wouldn't be at all surprised if some non-negligible % of spam comes from TLA's around the world.  We already know that some non-negligible % of phishing/malware emails come from TLA's, so outright spam simply widens the potential.

@_date: 2016-05-11 12:30:42
@_author: Henry Baker 
@_subject: [Cryptography] 2nd Amendment Case for the Right to Bear Crypto 
FYI --
The Second Amendment Case for the Right to Bear Crypto
Written by Susan McGregor
May 11, 2016 // 05:00 AM EST
On November 9, 1994, an American software engineer named Philip Zimmermann was detained by customs agents in Dulles International Airport as he returned from a speaking engagement in Europe.
His luggage was searched and he was interrogated at length regarding his possible illegal export of "dangerous munitions."
Though Zimmermann was carrying no guns, bombs, or chemical agents, he was carrying one item considered a weapon in the eyes of the US government: the strong cryptographic software of his own making known as "Pretty Good Privacy," or PGP.
While today it may seem surprising that software like PGP was ever considered a weapon, the US government has long viewed strong crypto--typically any encryption mechanism that cannot be bypassed efficiently--as a dangerous technology in civilian hands.
Legally, in fact, the right of individuals to strong cryptographic technology has never been affirmed, even as privacy and surveillance concerns have prompted companies like Google, Apple and, more recently, WhatsApp and WordPress, to encrypt their devices and platforms by default.
Thanks to the "Crypto Wars" of the 1990s, legal scholars have debated the ways in which cryptographic research and technology might qualify for constitutional protection.  Typically, however, these reflections have focused on interpretations of the First Amendment and the Fifth Amendment: the First, through the reasoning that code is speech, and the Fifth for its particular protection of the "liberty" to pursue one's chosen profession.
Yet the federal government's own decision to regard encryption technology as a weapon seems to suggest another constitutional lens: the Second Amendment, via the "right to bear arms."
In the United States, restrictions on non-governmental uses of cryptography go back to at least 1977, when a member of the National Security Agency sent a letter to the IEEE warning that some of the material to be presented at a Cornell cryptography conference might run afoul of weapons export regulations.
At the time, even the concepts of strong crypto appeared on the Munitions List of the International Traffic in Arms Regulations or ITAR, which govern US weapons exports.
In fact, it was not until almost two decades later that the US began to move some of the most common encryption technologies off the Munitions List.  Without these changes, it would have been virtually impossible to secure commercial transactions online, stifling the then-nascent internet economy.
Additional regulatory changes in the early 2000s further relaxed the export restrictions, making the use of PGP and other open-source software legal for individuals to transport and use.  But legal proceedings over the right to encrypt have been largely inconclusive.
For example, the three-year investigation of Zimmermann was eventually dropped, but without explanation.  And while in 1999 researcher Daniel Bernstein secured a win against the Department of Justice in the 9th circuit, a series of legal technicalities accompanied by a big change in ITAR meant that the case was ultimately dismissed in 2003 without being decided.
Meanwhile, "Software (including their cryptographic interfaces) capable of maintaining secrecy or confidentiality of information or information systems" remains on the ITAR Munitions List today--and the export of more sophisticated encryption software is still subject to both government oversight and a complex licensing process.
So what are the chances of encryption technologies being viewed as a "bearable arm" under the Second Amendment?
"It's an interesting argument," says Mike McLively, a staff attorney at the Law Center to Prevent Gun Violence and a Second Amendment expert.  "You can make the case, certainly."
Doing so is no simple task, however.  According to McLively, 94 percent of the more than 1000 Second Amendment infringement suits brought since the landmark District of Columbia v. Heller case in 2008 have been rejected.  As always in law, details matter.
"It would depend on which technology you're talking about," says McLively.  "It is on everyone's phone, for example?  Is it commonly used for self-defense, not just to defend your information?  I think that the Court would be more inclined to say that the Second Amendment is for protecting your physical person."
Of course, for the millions of people who currently encrypt their phones, adequately protecting the sensitive data they contain is absolutely a form of physical protection.
A weakly encrypted phone, if lost or stolen, is a Pandora's Box of dangerously personal information: names, addresses, contacts, and photographs, to say nothing of the detailed calendar and appointment information that can act as a map to an individual's daily activities, or those of their children.
Likewise, with the increasing prevalence of app-based "smart devices" for the home, including security systems, a poorly encrypted phone is essentially a remote-controlled index to doing one physical harm.
Typically, of course, the "arms" considered for Second Amendment protection have been traditional firearms.  Last month, however, the Supreme Court rejected the state's arguments in the case of Caetano v Massachusetts, in which the state held that the plaintiff did not have a Second Amendment right to a "stun" gun, in part because it was "a thoroughly modern invention."
In a per curiam decision, however, the Supreme Court sent the case back to the state, with the forceful assertion that "the Second Amendment extends, prima facie, to all instruments that constitute bearable arms, even those that were not in existence at the time of the founding."
Even this inclusive view of the Second Amendment, however, does not preclude limitations on the types of weapons that individuals can use.  As McLively points out, "The Second Amendment doesn't protect the right to pick the gun we want."
Does that mean that the government could eventually mandate the use of only the "smart" guns described in President Obama's executive order earlier this year?  Could the right to bear encryption be limited to only allow encryption that allows "exceptional access" for law enforcement, as the recentBurr-Feinstein bill would require?
"If it's reliable and it works," says McLively, "all the government would have to do is show that access to only smart guns is just as respectful of self-defense."
The problem, of course, is that to date neither smart gun nor "exceptional access" encryption technologies have been able meet that challenge of being "just as respectful of self-defense."
Despite decades of research and development on both fronts, smart guns "can and will be jailbroken," as Ars Technica co-founder Jon Stokes put it in an LA Times op-ed in January, and encryption that allows access for law enforcement is no longer protective.  A group of prominent computer security specialists--among them Whitfield Diffie, an author of an essential protocol for securing internet connections--recently detailed why "exceptional access" to encryption technologies is no more tenable today than it was 20 years ago.
Considering crypto under the Second Amendment is more than a semantic trick.  It can help shed light on whether--and where--appropriate limits on individuals' right to encryption should lie.
Traditional firearms and encryption technologies both have the capacity to protect and destroy; and both can be put to both lawful and criminal use.
At SXSW this year, President Obama asserted that technologies like strong encryption "can empower folks who are very dangerous to spread dangerous messages," and there is little doubt that encryption technologies, like guns, can be used in dangerous ways.
But of course most of the technologies protected by the Second Amendment are inherently dangerous--otherwise they wouldn't be much good for self-defense.  Sensibly, then, the test for whether or not a weapon is protected by the Second Amendment does not rest on whether or not it is dangerous.
Instead, it is the dominant application of a technology that affects its eligibility for constitutional protection.  As Justices Alito and Thomas wrote in their Caetano opinion, "the relative dangerousness of a weapon is irrelevant when the weapon belongs to a class of arms commonly used for lawful purposes."  So unless online banking is suddenly outlawed, the "dangerous" uses of strong encryption are somewhat beside the point.
Whether "weapons of offense, or armor of defense"--whether firearms or encryption technologies--the Second Amendment "extends...to all instruments that constitute bearable arms."
In the fight to protect ourselves from having our medical records altered through identity theft or our physical whereabouts tracked from a stolen phone or laptop, the stakes can truly be life or death.  When it comes to self-defense in the digital age, strong encryption is the only weapon we have--we need to protect it.
Topics: encryption, crypto, right to bear arms, second amendment, opinion

@_date: 2016-05-12 06:44:24
@_author: Henry Baker 
@_subject: [Cryptography] 2nd Amendment Case for the Right to Bear Crypto 
Yes, but...
Since ancient times, *defensive* systems like shields, chain mail, body armor, etc. have been considered "arms" & "armament".
So far as I know, there is *no* law prohibiting anyone in the U.S. from purchasing a bulletproof car with bulletproof windows.  I know of one Mercedes dealer in Los Angeles that does indeed sell such cars.  (These cars run up against another problem: in some cases, they weigh more than 6000 pounds, and are therefore no longer considered "cars", but that's a different issue.  These cars cannot have blacked out front windows (in California), which may be a privacy violation, but once again that's a different issue.)
I'm not aware of any law prohibiting me from wearing a "bulletproof" vest, although I understand they are bulky, uncomfortable and hot.
Suppose that there were much better "bulletproof" armor which was ubiquitously built into the clothing that we all wear.  The LEO's would freak out (just like they did after the "North Hollywood shootout" in 1997 in Los Angeles [1]), but -- as a public policy matter -- wouldn't everyone wearing such *armor* be a much better use of the 2nd Amendment than everyone carrying *offensive* weapons?
When was the last time in the entire history of the universe where kids were killed in a shooting in which the bullets were random numbers?
So I think that the Second Amendment *does* cover *defensive* armor.
[1]

@_date: 2016-05-12 12:14:06
@_author: Henry Baker 
@_subject: [Cryptography] 2nd Amendment Case for the Right to Bear Crypto 
It takes *years*/*generations* to change people's attitudes towards laws & interpretations of the Constitution.
Even though "privacy", per se, never shows up in the Constitution, it is implicit in a number of the Amendments, and has been crystallized during the past 70 years in quite a number of decisions.  Achieving this goal required the efforts of huge numbers of people over many decades.
Ditto for gay rights, and ditto for Second Amendment rights.
All this means is that we in the encryption community have significant work to do, which will probably take the rest of our lives to gain enough traction.
Ditto for using the Third Amendment to argue against govt backdoors and implants in our devices (and soon, ourselves!).  No, it hasn't been used for this purpose in the past, but if you look to the *rationale* for the 3rd Amendment, it would certainly seem (at least to me) to apply to stationing appendages of the govt in my digital devices and networks.
As everything becomes digitalized, the importance of the First Amendment becomes stronger and stronger -- e.g., when I can download and 3D print a gun in my own home, the First Amendment starts to subsume the Second Amendment.

@_date: 2016-05-12 14:14:19
@_author: Henry Baker 
@_subject: [Cryptography] 2nd Amendment Case for the Right to Bear Crypto 
Based on the # of police shootings of more-or-less innocent and/or unarmed people in the last several years (e.g., Black Lives Matter), wearing body armor may soon become a necessity for all of us.
Wearing body armor may at least preserve your life so you can appeal your conviction for wearing body armor.
It's curious that wearing a motorcycle or bicycle *helmet* is *required by law*, while wearing *body armor* is *prohibited by law*.  Given the current shortage of organ donors, perhaps the law should be flipped?
BTW, the newest mountain biking & skiing body armor *inflates like an airbag*.  Very cool!

@_date: 2016-05-18 09:14:25
@_author: Henry Baker 
@_subject: [Cryptography] Theoretical Breakthrough in Random Number Generation 
FYI --
Academics Make Theoretical Breakthrough in Random Number Generation
by Michael Mimoso May 17, 2016 , 12:25 pm
Two University of Texas academics have made what some experts believe is a breakthrough in random number generation that could have longstanding implications for cryptography and computer security.
David Zuckerman, a computer science professor, and Eshan Chattopadhyay, a graduate student, published a paper in March that will be presented in June at the Symposium on Theory of Computing.  The paper describes how the academics devised a method for the generation of high quality random numbers.  The work is theoretical, but Zuckerman said down the road it could lead to a number of practical advances in cryptography, scientific polling, and the study of other complex environments such as the climate.
"We show that if you have two low-quality random sources--lower quality sources are much easier to come by--two sources that are independent and have no correlations between them, you can combine them in a way to produce a high-quality random number," Zuckerman said.  "People have been trying to do this for quite some time.  Previous methods required the low-quality sources to be not that low, but more moderately high quality.
"We improved it dramatically," Zuckerman said.
The technical details are described in the academics' paper "Explicit Two-Source Extractors and Resilient Functions."  The academics' introduction of resilient functions into their new algorithm built on numerous previous works to arrive at landmark moment in theoretical computer science.  Already, one other leading designer of randomness extractors, Xin Li, has built on their work to create sequences of many more random numbers.
"You expect to see advances in steps, usually several intermediate phases," Zuckerman said.  "We sort of made several advances at once.  That's why people are excited."
In fact, academics worldwide have taken notice.  Oded Goldreich, a professor of computer science at the Weizmann Institute of Science in Israel, called it a fantastic result.
"It would have been great to see any explicit two-source extractor for min-entropy rate below one half, let alone one that beats Bourgain's rate of 0.499," Goldreich said on the Weizmann website.  "Handling any constant min-entropy rate would have been a feast (see A Challenge from the mid-1980s), and going beyond that would have justified a night-long party."
MIT's Henry Yuen, a MIT PhD student in theoretical computer science, called the paper "pulse-quickening."
"If the result is correct, then it really is -- shall I say it -- a breakthrough in theoretical computer science," Yuen said.
The study of existing random number generators used in commercial applications has intensified since the Snowden documents were published; sometimes random numbers aren't so random.  Low quality random numbers are much easier to predict, and if they're used, they lower the integrity of the security and cryptography protecting data, for example.  Right now, Zuckerman's and Chattopadhyay's result is theoretical and work remains in lowering the margins of error, Zuckerman said.
Previous work on randomness extractors, including advances made by Zuckerman, required that one sequence used by the algorithm be truly random, or that both sources be close to random.  The academics' latest work hurdles those restrictions allowing the use of sequences that are only weakly random.  Their method requires fewer computational resources and results in higher quality randomness.  Today's random number systems, for example, are fast, but are much more ad-hoc.
"This is a problem I've come back to over and over again for more than 20 years," says Zuckerman.  "I'm thrilled to have solved it."
Explicit Two-Source Extractors and Resilient Functions
Revision  Authors: Eshan Chattopadhyay, David Zuckerman Accepted on: 20th March 2016 00:40
Downloads: 6384 Keywords: 2-source, collective coin-flipping, explicit construction, extractor, Pseudorandomness, Ramsey Graph We explicitly construct an extractor for two independent sources on $n$ bits, each with min-entropy at least $\log^C n$ for a large enough constant~$C$. Our extractor outputs one bit and has error $n^{-\Omega(1)}$. The best previous extractor, by Bourgain, required each source to have min-entropy $.499n$.

@_date: 2016-05-18 13:53:23
@_author: Henry Baker 
@_subject: [Cryptography] NSA Crypto Breakthrough Bamford [was: WhatsApp 
mail.com>
I tend to agree with Nadia Heninger's conjecture that NSA has broken discrete logs of certain types.
It has the right flavor: NOBUS acres of computers.
"Logjam" attack on discrete logs:
Note that achieving this discrete log breakthrough doesn't rule out other approaches: elliptic curve backdoors, more-than-modest improvements in integer factoring with non-quantum computers, back doors in Intel/AMD/Broadcom/TI/Qualcomm crypto hardware, etc.
I think that the most recent complaints about Chinese interest in examining "proprietary" HW/SW of American manufacture might shake out some of these back doors (which I estimate to exist with nearly 100% probability).
The reason why these HW/SW back doors almost certainly exist: NSA's lime-in-the-cleats arrogance -- together with rubber-stamp NSL's from a round-heeled FISA non-court -- means that the NSA spooks simply can't stop themselves.  When you're addicted to the power to force American companies to "Click It or Ticket" (perhaps you have to live in California to understand this imperative to buckle under) like the NSA, your addiction makes you powerless to resist without outside intervention.
Yes, when these back doors are eventually revealed by some post-Snowden patriot, they will destroy the rest of any credibility that remains in American chip and computer vendors, resulting in multi billions of $$$$ in losses (including job losses).  I suspect that this is why Hayden has said that the health of the U.S. IT industry is more important than weakening encryption; he wants to "get ahead of the story" when these back doors are finally revealed.  Notice that Hayden only changed his tune *after* Snowden, and Hayden now understands that more Snowdens are not only possible, but likely.
It is possible that the US may let the Chinese in on these back door secrets in order to preserve its ability to keep using them against everyone else, but this fall-back strategy can't possibly be a long-term stable solution.  (There is an historical precedent for this strategy: the U.S./Swiss continued to sell broken Enigma-style crypto equipment to the non-first-world nations in the 1950's.)
The US will enable the Chinese to use these backdoors to suppress internal dissent for two reasons: the US thinks that a "stable" China -- even with massive human rights violations -- is vastly preferable to a chaotic democratic China (or a multiplicity of Chinas); and the US finds these back doors exceedingly useful for its own purposes both inside & outside the US.

@_date: 2016-05-19 15:34:23
@_author: Henry Baker 
@_subject: [Cryptography] NSA Crypto Breakthrough Bamford [was: WhatsApp 
I don't know the emoticon for "irony", else I would have used it liberally.
NOBUS is a *conceit*, and a very expensive one.
I haven't gone through all the Snowden material, but surely there is a slide somewhere in there that talks about "stuff we can do that no one else can so".
NOBUS-like conceit is a common theme for American exceptionalists (& Fortune 500 B-school types) -- that "scale" and "big data" can overcome any obstacles.  These people conveniently forget that there are *disadvantages* to size & scale -- e.g., O(n^2) (or even O(n*logn)) communication effects.  And they conveniently ignore the fact that you can more easily *drown* in "big data" than just about any other outcome.  I was always warned that "PhD" was an acronym for "piled higher and deeper"; NSA prides itself on its excess.
NOBUS is used on Congress to increase budgets for Congresspersons who don't have the clearances to understand anything else.  NOBUS is also used to cement the military-industrial-intel complex with big $$$$$ contracts -- whether they achieve any net increase in security or not.

@_date: 2016-05-24 08:43:50
@_author: Henry Baker 
@_subject: [Cryptography] Hacking spread spectrum clocking of HW ? 
FYI --
"In 1975 the Federal Communications Commission (FCC), the government agency that regulates radio frequency (RF) emissions in the United States, enacted new regulations called FCC Part 15.  These were not directed at controlling equipment such as radio and TV transmitters, or aircraft-navigation and emergency beacons that deliberately radiate high-power RF energy.  Instead, these regulations sought to control equipment that did not deliberately radiate RF energy such as televisions, automobiles, and low-power, unregulated RF radiators such as walkie-talkies and electronic remote controls.  During the 1980s and 1990s, electronic devices from microwaves to cell phones proliferated.  Cross interference between these devices became a problem.  Traditional methods to address radiated emissions issues consisted of shielding, careful board layout, as well as filtering to reduce undesired radiated emissions.  As electronics became smaller, another technique, Spread Spectrum, borrowed from communication applications was used.  This article gives a background and history of spread spectrum and describes how it is used today as a technique to reduce radiated emissions in consumer electronic equipment."
Q: How hard is it to diddle with the spreading codes on these clocking sources?  I'd like to experiment with some longer codes.

@_date: 2016-05-25 10:25:01
@_author: Henry Baker 
@_subject: [Cryptography] Hacking spread spectrum clocking of HW ? 
Thanks for the link.  This particular chip can be hacked, but perhaps not enough.
It's possible that none of the existing 'spread spectrum' clock chips can be hacked enough.
In that case, it may be necessary to 'emulate' one using a free-running state machine -- perhaps synchronized in some way (phase locked loop?) to a low frequency time standard.

@_date: 2016-05-25 17:03:24
@_author: Henry Baker 
@_subject: [Cryptography] Hacking spread spectrum clocking of HW ? 
Thanks for the info, but this device isn't a *radio*, it's a *computer*,
and a really low power one at that.  So far as I know, there's no antenna
anywhere on this device.  I'm only interested in hacking its f'ing clock!
If this device is "transmitting" anything at all, then there's something
dreadfully wrong with it, and/or someone else has already hacked it.

@_date: 2016-05-26 20:47:35
@_author: Henry Baker 
@_subject: [Cryptography] Radios vs. computers 
(Yes, in my first job as an IBM 1401 nanny, we listened to the AM radio to see what the computer was doing.  Nowadays, you probably need a downconverter, but the idea is the same.)
All true, but other than regulating for RFI (interference), computers aren't legally radios, and don't fall under the same reqs.
I would imagine that many dimmable LED lights generate far more RFI than computers -- due to their use of pulse-width (or any other type of modulation) in order to get the dimming capability.
Everyone on this list should be afraid -- be very afraid -- of LED lights in their homes, as the hack to make them into audio bugs (which can be listened to from miles away with a decent telescope) is quite trivial (due to poor design, many LED lights might already be modulating the LED with sound frequencies purely by accident!).  Only slightly more difficult is converting an LED light into a wifi bug.
(If the intel agencies can already listen to audio waves by logging minute vibrations of window panes, then modulating an LED light is child's play.)
Such modulated LED light can still be detected and read even when window blinds are shut, in a manner similar to being able to detect which TV channel someone is watching based upon correlating the modulated light from someone's window with the overall brightness of a particular TV channel.

@_date: 2016-05-28 18:35:54
@_author: Henry Baker 
@_subject: [Cryptography] Blue Coat has been issued a MITM encryption 
FYI --
A Controversial Surveillance Firm Was Granted a Powerful Encryption Certificate
Written by Joseph Cox, Contributor
May 27, 2016 // 03:25 PM EST
A controversial surveillance company whose products have been detected in Iran and Sudan was recently issued a powerful encryption certificate by a US cybersecurity company.  The certificate, and the authority that comes with it, could allow Blue Coat Systems to more easily snoop on encrypted traffic.  But Symantec, the company that provided it, downplayed concern from the security community.
Blue Coat, which sells web-monitoring software, was granted the power in September last year, but it was only widely noticed this week.
The company's devices are used by both government and commercial customers for keeping tabs on networks or conducting surveillance.  In Syria, the technology has been used to censor web sites and monitor the communications of dissidents, activists and journalists, The Washington Post reports.
Certificates are used to encrypt web pages, including bank or email login screens.  Certificate authorities (CA), such as cybersecurity company Symantec, act as the trust holders in the encrypted web--they sign certificates which are then used to secure websites.  If a web browser comes across an untrusted certificate, then a warning may pop up, alerting the user.
CAs can award ostensibly trusted organisations with the power to sign certificates too.  That is what happened here: in short, Symantec has vouched for Blue Coat's legitimacy.
"Think of a root CA like your super trustworthy friend who would never lie--if he or she says you can trust someone, you'd trust them," Bryan Crow wrote on WonderHowTo on Friday.
But having a company known for selling surveillance equipment to authoritarian regimes getting this extra power has made people pretty damn worried.  So much so that security researcher Filippo Valsorda explained how to manually set an OSX system to distrust any certificate issued by Blue Coat.  Others followed with instructions for Windows.
"Since they now have a trusted CA, and they're known for creating [man-in-the-middle] attack devices, they can use this certificate to issue fake certificates for any website you visit," Crow said.
"To clarify, they can intercept your connection to, say, YourBank.com, open their connection to YourBank using their real certificate, but send your computer their own certificate that claims to be YourBank's, sign it with their trusted CA, and your computer won't blink an eye.  It will implicitly trust it, seeing as if it checks the signing CA, it'll find that it is properly signed, and trusted on your machine," Crow added.
    "What the certificate does not give them the ability to do is issue public certificates to other organizations.  That's the big misunderstanding."
But Symantec and Blue Coat said that the certificate was only used for internal testing.
"We provided it because companies that want to secure private servers without the risks that come with working in the public domain is a common customer request," Symantec spokesperson Jane Gideon told Motherboard in an email.
"Symantec has reviewed the intermediate CA issued to Blue Coat and determined it was used appropriately.  Consistent with our protocols, Symantec maintained full control of the private key and Blue Coat never had access to it.  Blue Coat has confirmed it was used for internal testing and has since been discontinued.  Therefore, rumors of misuse are unfounded," she wrote.
When asked for comment, Blue Coat pointed to Symantec's statement.
The certificate is "still valid, and they could use it for further internal testing in the future as long as the CA is valid, which is a completely legitimate use," Gideon clarified.
"What the certificate does not give them the ability to do is issue public certificates to other organizations," Gideon said.  "That's the big misunderstanding."
"This intermediate CA is for their private servers only," she wrote.
Correction: Due to a formatting issue, a quote from Symantec looked like it was attributed to Bryan Crow.  This article has since been updated to correct the error.
Topics: privacy, surveillance, Blue Coat Systems, symantec, encryption
How to unfriend Blue Coat in OS-X:
How to unfriend in Windows:
The Reg article:

@_date: 2016-11-03 16:06:34
@_author: Henry Baker 
@_subject: [Cryptography] "we need to protect [our dox] by at least encrypting 
FYI --
Fw: hey
Hey, John, I know I'm like a broken record on this, but I think we should arrange a briefing on the cyber threat for all associated with your effort.  We have a real security threat on our stuff here. I would gladly work up something with our techie.  We've developed a lot of expertise in this, unfortunately. Sent: Mon Nov 03 13:46:24 2008
I had never heard anything like this from either the campaign or the pre-transition effort and, in fact, have been receiving things of equal or greater sensitivity for some time from both sources.  You guys are presumably much more likely to be made aware of such issues, so when the economic side of the transition gets named, you should probably get in touch with them to give guidance on this.
   From: dmcdonough at barackobama.com (Denis McDonough)
   Subject: hey
   To: tarullos4 at yahoo.com
   Date: Monday, November 3, 2008, 2:26 PM
   Dan --    I was struck by the memo partly because it was first I had heard of it but much more because it was a sensitive doc bumping around on public email addresses.     There is a very real threat to the security of our documents (particularly sensitive ones like the one you worked up), and we need to protect them by at least encrypting them.    Thanks,    Denis.
Note the date on this Wikileaks email...

@_date: 2016-11-04 10:52:05
@_author: Henry Baker 
@_subject: [Cryptography] Happy birthday, NSA! 
I attended a networking show in the '90's and was talking to a bunch of people who all had "Department of Defense" name tags, and I was ribbing them about their name tags.
They then let me know that they were demonstrating a high definition *real time* video link with "Baltimore", and that I was being viewed *in real time* by a large number of people at the other end.
After turning bright red from embarrassment, I walked away with my (forked) tail between my legs.
BTW, whenever you called one of their phone numbers, they answered only with their extension number (I imagine because it was easy to misdial).
I've also tried to run reverse directories on these phone numbers, with zero success (as would be expected).

@_date: 2016-11-05 10:20:37
@_author: Henry Baker 
@_subject: [Cryptography] "we need to protect [our dox] by at least 
I'm going to disagree with your premises.
I have yet to see any evidence that *secret negotiations* are _ever_ in the best interests of the ordinary citizen.  When Alice & Bob negotiate in secret, they usually give away Joe's gold watch rather than Alice's or Bob's (Joe, of course, not being in the room and hence unable to protect his interests).  Our problems in the Middle East today spring directly from exactly this sort of secret negotiation 100 years ago in the latter portion of WWI.
Indeed, the British entered WWI on the basis of 3 people + 1 dog in a room.  (Unlike most of the other players, the Brits had a colorable rationale for not entering that war, and their non-entry -- or much later entry in concert with the U.S. -- might have dramatically improved the course of the 20th C.)
Among other problems with diplomatic secrecy, the sh*t really hits the fan when diplomatic cables are "accidently" released (examples far too numerous to mention here).
If the crypto community really wants to help improve the art of diplomacy, it could design games/negotiations that are completely auditable, so that all back-stabbing becomes transparent.

@_date: 2016-11-06 09:16:04
@_author: Henry Baker 
@_subject: [Cryptography] "Evil Maid" attack? 
FYI --
Clinton directed her maid to print out classified materials
By Paul Sperry
November 6, 2016 | 4:53am | Updated
I guess "attack" is too strong a word here...
See no evil, hear no evil, speak no evil, print no evil ?  :-)

@_date: 2016-11-07 15:16:07
@_author: Henry Baker 
@_subject: [Cryptography] "we need to protect [our dox] by at least 
And the problem is?
In Edo-period Japan, an ordinary non-Samurai citizen couldn't talk
to the Shogun on pain of death.  Read the book or see the mini-series
~1980.  In one scene, the villagers were so upset with what this one
European was doing, that they chose one of their own to risk death
to bring his behavior to the attention of the Shogun.  Needless to
say, this process dramatically cut down on citizen complaints, much
like our current "whistleblower" processes dramatically cut down on
Here's the flip side:
I recall a science fiction story from the 1950's (whose name &
author I cannot recall -- please, please help me if you know) in
which the leader of a certain democracy had "strict accountability"
to its citizens.  Upon inauguration, a special non-removable
"necklace" would be locked around the neck of the new leader --
which necklace simultaneously gave him/her both the power of the
office and the accountability of the office.  If *at any time* a
majority of the citizens so "voted", the necklace would instantly
strangle the new leader to make way for the  election of a new
The problem that remains to be solved is called the "principal/agent"
problem, wherein "[a] dilemma exists in circumstances where the agent
is motivated to act in his own best interests, which are contrary to
those of the principal, and is an example of moral hazard."
Unfortunately, our democracy offers mechanisms which are too weak to
align the interests of the agents (politicians) with the interests
of the principals (citizen voters).  Indeed, most of our politicians
have become confused as to who is the principal and who is the agent.

@_date: 2016-11-18 18:07:04
@_author: Henry Baker 
@_subject: [Cryptography] Trump sparks downloads of encrypted chat app "Signal" 
FYI --
Trump's victory sparks unprecedented downloads of encrypted chat app Signal
Paresh Dave Nov. 18, 2016
A presidential campaign rocked by e-mail hacks followed by the victory of a candidate who wants to increase government surveillance has sent Americans to new corners of the Internet.
Fearful of private communications being used against them, millions of people are trying out once-obscure apps and services that promise stronger security than their more popular rivals.
The 2-year-old encrypted text and calling app Signal said no single event had ever led to such sustained interest as last week's election.
"Many users have reported that their entire social circle switched to Signal in the past week," said Moxie Marlinspike, founder of the San Francisco nonprofit developing the app, which doesn't store conversations online and scrambles them as they transmit across the Internet.
Post-election downloads have outpaced normal figures by 400%.  Marlinspike declined to state the exact number of downloads.
Governments have tapped into unencrypted communication lines for intelligence gathering, and law enforcement regularly obtains court orders to access information stored without the sort of protections Signal provides.
Some have downloaded Signal as part of organizing efforts for a wave of protests against Donald Trump's election in recent days.  Others were urged by friends in technology or public policy to use virtual private network software as a way to mask their online activity.
The president-elect has said he wants more traditional and digital surveillance worldwide to secure America's borders and to combat terrorism. His statements have left some Muslims, undocumented immigrants and political activists feeling vulnerable.  They fear their digital trails could be scoured by government officers looking for any opportunity to penalize them.
A growing number of digital communication tools, including Apple's iMessage and Snapchat, have encryption features that restrict anyone but the sender and recipients from seeing a message. But many options have holes.
Security experts regard Signal, though imperfect itself, as the closest thing to a gold standard in secret communication.  To stay private as intended, both sides of a conversation need to use Signal. And that's the challenge.  Moving entire friends' circles to a new chat platform -- though Marlinspike notes it's happened -- hasn't proved easy for many an app.  To some, using an encrypted chat app isn't the solution either, as it could be a red flag to investigators.
Still, Marlinspike said the initial data show the new users joining the millions already on Signal are becoming daily participants.  Consistent engagement increases the chance Signal goes mainstream.
Adam Englander, senior vice president and general counsel at a Los Angeles public relations firm, said he's unsure if his days-old Signal account will become a go-to option for him.
His girlfriend and tech-minded acquaintances are the only ones on it.  But recent cyberattacks had him worried.
The White House has said Russian hackers made public emails of Democratic political leaders, including those on Hillary Clinton's campaign team.  Trump used information from the leaks to allege Clinton officials colluded with the Justice Department to squash an investigation into how she managed e-mails as Secretary of State.
Englander doesn't want to end up a victim of cyberespionage.
"I may just limit it to those messages I feel I wouldn't want seen in the L.A. Times," he said of using Signal.
paresh.dave at latimes.com / PGP  Twitter:

@_date: 2016-11-23 14:14:59
@_author: Henry Baker 
@_subject: [Cryptography] Use of RDRAND in Haskell's TLS RNG? 
My guess is that Intel's HW RNG is basically ok, but that their chips have mechanisms to squirrel away (and later disgorge) secrets of various sorts -- e.g., inputs to built-in hash instructions.  There might be a HW "reset" capability -- analogous to a password reset function -- that might be used under certain circumstances to reset RDRAND.  Good luck finding it amidst billions and billions of transistors, tho.

@_date: 2016-11-28 07:21:58
@_author: Henry Baker 
@_subject: [Cryptography] Gaslighting ~= power droop == side channel attack 
I (finally) saw the 1944 movie Gaslight yesterday, and a prominent plot element was the dimming of the gas lights in a house when someone turned on the gas lights in another room.  In particular, the dimming of the gas lights indicated that someone else was in the house, and the brightening of the gas light indicated when that person left.  Ingrid Bergman's character eventually correlates the gas light dimming precisely with the absence of her husband -- supposedly to his rented office to compose music, but in reality, he's rummaging around in the attic.
The sudden prurient interest of our utility companies (and Google) in precisely monitoring our electrical power and our gas usage possibly be called "gaslighting surveillance".  What worries me is that our state PUC's (Public Utility Commissions) force us all to pay for this surveillance as part of our utility bills.
What's worse is that these utilities want to insert the camel's nose further into our tents by asking us to install "smart" -- aka more precise surveillance -- thermostats in our homes, so we (and, of course, they and the NSA/FBI/DHS via the 3rd party doctrine) can access this information via our smart phones.  Of course, having a perch on our home networks, they can monitor a heck of a lot more than our power consumption and our home temperature.
God forbid we ever get another Gerald Ford or Jimmy Carter in the White House; our "smart" thermostats will turn us into the secret energy police for pushing our thermostats above the "recommended" temperature.
And don't even start talking about Amazon's Echo/Alexa and Google's Home and Apple's Siri.

@_date: 2016-11-29 11:26:39
@_author: Henry Baker 
@_subject: [Cryptography] Gaslighting ~= power droop == side channel attack 
Well, in theory, any such *linear* function can be inverted to extract the original signal (with some added noise in the high frequencies), so simple smoothing won't really work.
This problem is loosely analogous to that of an oblivious RAM (ORAM), which must hide an actual memory reference stream within a completely boring reference stream.  Or the problem of moving a number of agents around a city by only using regularly scheduled public transportation rather than using taxis or private cars.
Another similar problem is the one of synthetic "traffic generation", which might be used in a full-scale network test.  But you would want the traffic patterns to also be resistant to *intelligent* analysis, as well as lower sophistication dragnet analysis.
The problem with *replay traffic* is that it is too easy to recognize when it is replayed, so you need a much more sophisticated traffic generation synthesis algorithm.

@_date: 2016-11-30 06:43:52
@_author: Henry Baker 
@_subject: [Cryptography] Gaslighting ~= power droop == side channel attack 
It is already the case in many regions that the *only* profits that
electric utilities make are during *peak rate* hours.  As businesses
and homes and appliances become "smarter" at avoiding these peak rates,
the profits of the utility companies completely vanish.
I'm still not sure why the utilities are so interested in exactly
which appliances I have and when they turn on&off I suppose this
is what constitutes "rearranging the deck chairs on the Titanic"
for the dying dinosaur utilities.
Perhaps the utilities' new business model includes spying on their
customers and selling these data to Google, Amazon & the NSA?

@_date: 2016-11-30 11:40:40
@_author: Henry Baker 
@_subject: [Cryptography] Gaslighting ~= power droop == side channel attack 
This suggestion re Tesla needed a smiley face.  :-)
Tesla collects far more information "to help our customers" than even
the utility companies.
I have no specific info on the Tesla Powerwall, but if it is anything
like the monitoring of the Tesla vehicles, Tesla probably knows every
time (and GPS location) when you pass gas.

@_date: 2016-11-30 11:51:14
@_author: Henry Baker 
@_subject: [Cryptography] Gaslighting ~= power droop == side channel attack 
Of course, some electrical utilities (at least outside the U.S.) are already in the ISP business.  But they have to bypass the last transformer just prior to your home to be able to pass the high frequencies that "broadband" requires.  Of course, anyone who can access these same external wires can tap into these home powerline networks.
Powerline technology uses electrical wiring to transmit digital data.  For the home user, it functions as if every room has reliable, wired connectivity, but there is no need to run Ethernet cables between rooms.  Products based on the HomePlug AV and HomePlug AV2 specifications can can connect devices such as Smart TVs and HD media players to the Internet via a connection to the home router as well as extend the coverage of a Wi-Fi network. In a typical installation, one adapter is connected to the broadband router, and other HomePlug adapters are plugged in elsewhere in your home to add an Ethernet-class connection anywhere.  All of your HomePlug devices can now communicate with each other and **securely** [!!] pass data around your home. HomePlug Certified products use your home's powerlines - which are already installed - as a path to send high-speed digital data such as digital video and multi-channel audio.  Plus, many HomePlug products combine Wi-Fi wireless networking.  This means that you can extend your wireless network to achieve high performance connectivity anywhere in your home.
As a consumer, you want the products you buy to connect without hassle, while maintaining **privacy**. [!!!]

@_date: 2016-11-30 15:32:30
@_author: Henry Baker 
@_subject: [Cryptography] RNG design principles 
FYI --
How to Make a Bad Decision
November 16, 2016 @ 11:00pm
by Stephen J. Dubner
Toby Moskowitz is an economist at Yale.  Moskowitz plays tennis, where theres plenty of opportunity for a rethink on the sequencing of shots:
If you're serving for instance, one of the best strategies is a ***randomized strategy***, like a pitcher should do in baseball.  And ***I'm not very good at being random***, just like most humans.  I'll say to myself, "Well, I hit the last couple down the middle.  Maybe I should go out wide on this one."  But thats not really random.  What I should do is what some of the best pitchers in baseball do.  Rumor has it Greg Maddux used to do this, which is, recognizing that he is not very good at being random, he would use a cue in the stadium that was totally random.  For instance, are we in an even or an odd inning?  And is the time on the clock even or odd?  Some other cue that would just give him a sense of, "Well, I'll throw a fastball if the clock ends on an even number and the inning's even I'll throw a slider if it's an odd, I should say to myself, "If the score is if it's even or odd, whatever, if I count five blades of grass on the court as opposed to three."  Something tha
t's totally random and has nothing to do with it, allows me to supply that random strategy, which my brain is not very good at doing.  Most peoples brains are not.
So, is it unsportsmanlike and/or cheating to have access to a random oracle ?  If not, then perhaps players should be allowed a certified RNG/TRNG ?

@_date: 2016-10-01 06:14:09
@_author: Henry Baker 
@_subject: [Cryptography] Use Linux for its security 
Well, as Dante might have said, "Abandon hope, all ye who disable
bounds checks".
Or as Dorothy Parker did say, "You can lead a whore to culture, but
you can't make her think!"
Or as I would say, "why bother working in a safe language if you
turn off the safety?"

@_date: 2016-10-01 09:46:30
@_author: Henry Baker 
@_subject: [Cryptography] Use Linux for its security 
My problem is that Common Lisp deserved a lot of the criticisms aimed at it -- particularly its (in)efficiency on "stock" (aka C-language-oriented) hardware.
The major complaint about PL/I was its ability to invoke enormous amounts of machinery in order to do trivial tasks like AND'ing two bit strings; Common Lisp didn't listen to this criticism of PL/I, and thus fell for the whole CISCy series of complaints.
(I spent a good fraction of my early programming years bypassing & re-implementing truly awful PL/I library routines; e.g., each one started out by invoking the world's most heavy-weight register save protocol.)
C avoided this issue (at least prior to C++) by pushing all "CISC"-type complexity into its standard library.  Thus, the major signal for "unreasonable complexity lies ahead" was a .h header and a call to a standard library routine.  (This signal wasn't 100% reliable: "alloca" ideally is a compiler-generated register increment even though it looks like a heavy duty standard library call.)
My advice to computer language designers: when users have to routinely construct their own run-time systems to get around the built-in inefficiencies of the language's *standard* mechanisms, then you've failed.
The explosion in roll-your-own malloc's in C is Exhibit  in what's wrong with trying to be all things to all people on a standardization committee.  (BTW, "malloc" is short for "malware locator" -- where a malware writer looks for openings -- and if the NSA had been clueful about software back then, NSA would have been its most vocal proponent.)
My advice to every programmer: always look at the machine code that is produced by your source code *while* you're writing that source code; you won't believe what kinds of garbage that the compiler & run-time system occasionally puts out.  This applies in spades to "higher level" languages like C++, Lisp, etc.
P.S.: If you follow my argument to its bitter end, you realize that the *garbage collector* itself is the biggest offender in "hidden complexity".  Hence my interest in "linear types" ("linear logic") which allows the higher-level expression of a garbage collector to be exposed in a computer language's source language.

@_date: 2016-10-01 11:09:01
@_author: Henry Baker 
@_subject: [Cryptography] Use Linux for its security 
Don't get me wrong.  Common Lisp is my favorite language, and I use SBCL all the time.
But although I'm "ready for Lisp" and I'm "with Lisp" (I guess that means I'm pregnant???), I don't think that Common Lisp and I are always "stronger together".  I can still see Lisp's obvious imperfections.
I'm trying to reduce Lisp to a McCarthy-like simplicity that retains its expressive power & composability, but can also be implemented efficiently on real (and cheap) hardware.

@_date: 2016-10-03 11:50:35
@_author: Henry Baker 
@_subject: [Cryptography] French credit card has time-varying PIN 
FYI --
This high-tech card is being rolled out by French banks to eliminate fraud
By Oliver Smith 27 September 2016
Forget fraud, these new bank cards are about to change everything.
Your bank security is pretty broken.  It's not your fault, it's just really hard to keep people's money safe, especially online.
Part of the problem is that once your card details are stolen -- whether through a phishing attack or by someone copying the digits on the back -- fraudsters are free to go on a spending spree until you notice something's up.
They're getting away with millions, and it's a problem affecting over half a million people in the first half of 2016 alone.
Normally by the time you get around to actually cancelling your card, it's all too late.
But what if the numbers on your card changed every hour so that, even if a fraudster copied them, they'd quickly be out of date?
That's exactly what two French banks are starting to do with their new high-tech ebank cards.
Motion Code to the rescue
At first glance these cards don't look any different from the ones you carry around today, but they're hiding some technological wizardry.
The three digits on the back of this card will change, every hour, for three years.
And after they change, the previous three digits are essentially worthless, and that's a huge blow for criminals.
"What we know is that banks see this as a hugely growing problem that needs to be addressed," Aaron Davis, Business Director of Oberthur Technologies UK & Ireland, told The Memo.
Oberthur Technologies is the French digital security company that has developed the tech, called MotionCode, and they've been making chip and PIN bank cards for over two decades.
    "MotionCode is exactly what you're doing today -- copying the three digits from the back of your card -- but with a huge additional level of security."
As most fraud happens a few hours or days after your card details are actually taken, this would leave criminals essentially with a bunch of useless numbers.
Aside from the small digital screen on the back, the card is identical to the ones you already have.  You can bend, drop, even put it through the wash no problem.
The only downside is if you're one of those people who has memorised all your card numbers, as you'll still need to check these.
    "We're also seeing some interesting stats around the increased likelihood of people to transact online with this card and we're seeing spending increases as a result."
How can I get one?
Today both Socit Gnrale and Groupe BPCE, two of France's largest banking groups, are preparing to roll out these cards across all their customers after completing a pilot scheme last year.
There are other pilots underway in Poland and Mexico, and Davis is running Oberthur's UK operation with the hope of getting a pilot or trial started with a UK bank soon.
Let's hope so because this card is a huge leap forward for security and keeping your hard earned cash safe.
Read more: Financial scams soar to an all-time high
Read more: Moni gives "financial inclusion & dignity" to European migrants
Oliver Smith	
Oliver Smith is a Senior Reporter at The Memo.  Winner of the Gold Award at MHP's 30 To Watch 2015, he previously covered technology, media and telecoms at City A.M. newspaper.  He can be found tweeting  You can email him at oliver.smith at thememo.com.

@_date: 2016-10-04 15:36:13
@_author: Henry Baker 
@_subject: [Cryptography] Reuters: Yahoo secretly scanned customer emails 
The FBI/DHS/DOJ told Marissa they would abort her unborn baby, by putting a bloody doll in her bed.
BTW, all of the other ISP's, with the possible exceptions of Google & Apple, most likely did the same things -- we just haven't heard confirmation *yet*.
The ISP's connected with telcos and cablecos are connected to the govt at the highest levels -- at the axis of the regulatory revolving door -- the FCC holds their genitals by the short & curlies; this is true around the globe, where telcos are often govt-owned/govt-controlled/etc.  Doing telco business outside the U.S. *normally* involves substantial bribes to govt officials; Carly Fiorina may have been the first to stop the practise at Lucent, and probably forfeited significant sales as a result.

@_date: 2016-10-12 11:55:00
@_author: Henry Baker 
@_subject: [Cryptography] Defending against weak/trapdoored keys 
Here's my (hopefully non-lame) attempt to fix DH to defend against weak and/or trapdoored primes/ECC-groups.
Threat model:
Alice & Bob generally trust one another; however, neither Alice nor Bob trusts the other's prime or ECC group, although each trusts his/her own.
Eve, as usual, can see all of Alice & Bob's communications, but is otherwise passive.  Eve may have previously provided weak/trapdoored primes/ECC-groups to either or both of Alice and Bob, who then in turn use these weak primes/groups "unwittingly".
The basic idea is to make the DH exchange fully symmetrical, where Alice provides Bob with her prime/group, and Bob provides Alice with his prime/group.  In the off chance that either provides the other with a prime/group that the recipient doesn't like, they can force a redo.  In particular, if they happen to select the same prime/group, then both will likely force a redo.
After both sets of simple (asymmetric) DH exchanges, Alice & Bob share secret1 from Alice's prime/group and secret2 from Bob's prime/group.
Both Alice and Bob compute (secret1 XOR secret2) to produce the shared secret for session symmetric crypto.
Yes, this protocol requires 2X the amount of computation, but processor power is becoming the least of our worries.
Does this protocol work?

@_date: 2016-10-13 05:37:19
@_author: Henry Baker 
@_subject: [Cryptography] Defending against weak/trapdoored keys 
I'm not at all convinced that random "secure" primes/ECCgroups can be quickly & efficiently generated in real time.
However, by using multiple DH's, we might be able to force Eve to have to break them all.

@_date: 2016-10-14 10:35:26
@_author: Henry Baker 
@_subject: [Cryptography] Defending against weak/trapdoored keys 
OK.  Here's a proof outline.
Recall that we're doing *two* *complete* standard DH's (DH1 & DH2); one in either direction.  This means that each DHi uses its *own* (non-correlated) random numbers.  (If we use the same random numbers for both DH1 & DH2, then breaking *either* breaks the other, as well; so we won't do that.)
Assume that DH1 is completely compromised; assume Eve can trivially do discrete logs using DH1's prime and/or ECC group.
So WOLG we know secret1 = DH1.
We need to use this information to deduce (secret1 XOR secret2).
If Alice & Bob stupidly use exactly the same prime and/or ECC group, we are done, because secret1 = secret2, so (secret1 XOR secret2) == 0.  But Alice & Bob aren't that stupid.
Next problem: secret2 (= DH2) is essentially random.  I say "essentially" because it can't be identically 0, but all other choices are uniformly distributed.  So long as p (or the ECC group) is sufficiently large, secret2 is random, and *uncorrelated with secret1*.
(If you're still concerned about information possibly leaking from a few high order bits of secret2 (= DH2), then simply chop them off.)
So secret2 is a uniformly distributed random number.
So (secret1 XOR secret2) is a uniformly distributed random number, so it functions safely for the symmetric session key, so long as DH2 can't be broken.
So the difficulty of this scheme should be max(difficulty DH1,difficulty DH2).

@_date: 2016-10-24 18:38:56
@_author: Henry Baker 
@_subject: [Cryptography] How to prove Wikileaks' emails aren't altered 
FYI --
Errata Security: Advanced persistent cybersecurity
Sunday, October 23, 2016
Politifact: Yes we can fact check Kaine's email
This Politifact post muddles over whether the Wikileaks leaked emails have been doctored, specifically the one about Tim Kaine being picked a year ago.  The post is wrong -- we can verify this email and most of the rest.
In order to bloc spam, emails nowadays contain a form of *digital signatures* that verify their authenticity.  This is automatic, it happens on most modern email systems, without users being aware of it.
This means we can indeed validate most of the Wikileaks leaked DNC/Clinton/Podesta emails.  There are many ways to do this, but the easiest is to install the popular *Thunderbird* email app along with the DKIM Verifier addon.  Then go to the Wikileaks site and download the raw source of the email As you see in the screenshot below, the DKIM signature verifies as true.
If somebody doctored the email, such as changing the date, then the signature would not verify. I try this in the email below, changing the date from 2015 to 2016.  This causes the signature to fail.
Since DKIM verifies this email and most of the others, we conclude that Kaine is "pants on fire" lying about this specific email, and "mostly untrue" in his claim that the Wikileaks emails have been doctored.
Just in case the clueless pro-Hillary press claims that the Wikileaks emails aren't genuine, Robert Graham's blog shows how anyone can prove that they are indeed genuine.  Of course, if the Hillary camp understood encryption technology better in the first place, there wouldn't be any Wikileaks emails to verify.

@_date: 2016-10-31 08:03:35
@_author: Henry Baker 
@_subject: [Cryptography] How to prove Wikileaks' emails aren't  altered 
Wikileaks is now *checking DKIM keys* (go to their web site to see), so it should no longer be necessary to recheck them.

@_date: 2016-09-04 15:07:55
@_author: Henry Baker 
@_subject: [Cryptography] N. Korean radio broadcasts string of random 
mail.com>
Ultra wideband (aka pulse position modulation) can be even more difficult
to find -- especially if the geographic position of the emitters can be
dynamically and randomly varied.  Synchronization of such geographically
dispersed transmitters has become trivial due to the availability of GPS.
Of course, multiple spreading technologies can be combined.

@_date: 2016-09-05 21:51:16
@_author: Henry Baker 
@_subject: [Cryptography] "Flip Feng Shui: Hammering a Needle in the 
Could you please provide links to any articles about the design of a modern, robust wireless physical layer that has resistance not only to eavesdropping, but also to intentionally malformed packets, etc. ?
I understand that typical wifi protocols are hopeless, but was curious about how one would design protocols that would be more robust.

@_date: 2016-09-07 17:09:02
@_author: Henry Baker 
@_subject: [Cryptography] [Crypto-practicum]  Secure erasure in C. 
nVidia's "Dynamic Code Optimization" (DCO) means you can no longer trust assembler code, either, since DCO has replaced a rigorous semantics with a simple "hint" (DWIM -- "Do What I Mean", not what I say; but who knows what you mean?)
Here's more about DCO:
"DCO": Yet more lovely places for malware to hide.  The executing code is "translated" into a microcode buffer, but who gets to be in charge of said translation?
"Those who cast the votes decide nothing.  Those who count the votes decide everything."  -- Josef Stalin
I believe that these DCO processors have already been picked up for widespread use in automobiles, including self-driving cars.
What, me worry?
Stanford EE Computer Systems Colloquium
4:15PM, Wednesday, March 4, 2015
NEC Auditorium, Gates Computer Science Building Room B3
Dynamic Code Optimization and the NVIDIA Denver Processor
Nathan Tuck NVIDIA
About the talk:
NVIDIA's first 64-bit ARM processor, code-named Denver, leverages a host of new technologies to enable high-performance mobile computing.  Implemented in a 28-nm process, the Denver CPU can attain clock speeds of up to 2.5 GHz.  This talk will outline the Denver architecture and describe some of its technological innovations.  In particular this talk will discuss some of the motivations and advantages of dynamic code optimization.
There not downloadable slides for this presentation available at this time.
View Video on YouTube.
About the speaker:
Nathan Tuck has been a member of the DCO and CPU architecture teams at NVIDIA since 2009.
Nathan has spent his professional career walking a crooked line between hardware and software.  As an engineer, he is most interested in working on systems problems.  Professionally, he is most interested in dynamic environments where he can make a large difference.
Contact information:
Nathan Tuck

@_date: 2016-09-08 11:49:53
@_author: Henry Baker 
@_subject: [Cryptography] [Crypto-practicum]  Secure erasure in C. 
Disks are almost gone, so we're talking about flash technology going forward.
The problem with flash is that you're typically separated from the actual flash memory by a proprietary layer (FTL?) that is free to do anything it pleases -- including performing as much compression (including deduplication) as it likes.
So you can assume that every flash memory is also compromised, and will look for (and squirrel away) interesting data for later exfiltration.
Include *Flint* (as in Derek Flint; Google it!) in your list of attackers, along with Eve, etc.
It's past time to consider some form of ORAM for flash memory...
Also, consider some form of bit-slicing, so that no single flash memory chip can see the whole memory reference string, nor the whole memory bus.  This will force multiple flash chips to at least cooperate in order to attack the stored information.

@_date: 2016-09-08 16:20:38
@_author: Henry Baker 
@_subject: [Cryptography] [Crypto-practicum] Secure erasure in C. 
Writing a flash memory with the contents of a crypto-quality RNG can place a *lower bound* on how many bits it can store, but in these days of multi-GByte flash memories, it is difficult -- if not impossible -- to know if there are a few hundred MBytes of "squirrel cache" memory hiding in there, as well.
Also, the moment you start using the flash memory for real (and likely quite compressible) data, Mr. Flint starts compressing *your* data to make room for *his* snooping data.
One possible solution: a "one-time pad".  Utilize *two* *independent* flash memories, and store a crypto random stream R on one and the stream (R xor D) on the other, where D is the stream of *your* data.
Neither R nor (R xor D) is independently compressible, so our man Flint is permanently stuck with just his hidden memory, and no compression algorithm will enable him to free up any more memory.
(BTW, Derek Flint is a SPY!)

@_date: 2016-09-09 09:10:23
@_author: Henry Baker 
@_subject: [Cryptography] Secure erasure 
There *is* such a computer language notion: so-called "linear" types.
A "linear" object is one which has exactly one reference, and the language and type system conspire to ensure that this constraint is preserved.
*You* (the programmer) can make a copy of the *contents* of such an object if you wish, but the compiler & run-time system are not allowed to make such a copy.
Similarly, you -- the programmer -- are allowed to destroy "the" reference to such an object (thereby also destroying the object itself), but the compiler and run-time system are not allowed to perform such destruction on their own.
Properly implementing linear types requires a whole new approach to compilers and operating systems, because both are typically quite profligate in their explosion of copies -- e.g., nearly ubiquitous caching.
Note also that the *lack of specific destruction* requirement places severe constraints on control flow: if a subprogram creates a new linear object, it cannot exit without providing a proper resting place for the linear object.  If the linear object cannot be (or is not) returned as a value, or assigned to a global variable, or explicitly destroyed, then the program must terminate with an error -- and the linear object is still preserved.
In short, the linearity constraint is not just a "hint" or "recommendation", but a *requirement* that -- if not possible to achieve -- requires that the computation halt.
Lisp programmers will see the need for an implicit "unwind-protect" construct to handle such errors; in other languages, variations on a "try" construct (but with more stringent assurances) will be required.
Here are some references re linear types, along with some programming examples.

@_date: 2016-09-10 06:46:23
@_author: Henry Baker 
@_subject: [Cryptography] Secure erasure 
I disagree.  The next 50 years of computer science will revolve around not just computing, per se, but computing with secrets & computing while keeping secrets.  Since computing can be attacked at every level, every level of computing will have to be "hardened" to protect itself.  This will require an entire restructuring of computing hardware, operating systems, computer languages and compilers.
I'm old enough to recall myself saying "XXX code represents a vanishingly small percentage of either bytes or cycles used on any system", and was subsequently proven wrong when "XXX" proved important enough to be embedded in operating systems and hardware.
Not true; that's what oblivious computing is all about: you can watch the computation all you want, but you won't learn anything about what it's computing.
During the past 80 years or so, we've learned how to reliably compute with unreliable hardware.  During the next 50 years we'll learn how to securely compute with untrusted hardware and software.
Google "garbled circuits", "fairplay", "multiparty computation", etc.
This stuff isn't efficient enough for widespread use today, but then again, there was once a time when floating point computation wasn't efficient enough, either.

@_date: 2016-09-11 06:25:00
@_author: Henry Baker 
@_subject: [Cryptography] [Crypto-practicum] An historical document. 
If I have my dates correct, Turing was already in the U.S.
in 1936, and was already becoming interested in codes.
Now whether he heard about this possibility from the news,
or whether he heard about this possibility from more private
sources, or whether the idea went the other direction I
don't know.
But it is possible that Turing may have seen this news and
taken it to heart.

@_date: 2016-09-11 06:54:01
@_author: Henry Baker 
@_subject: [Cryptography] Secure erasure in C. 
I know of no " optimize(off)" for the operating system, the disk drive caches, or the CPU caches.
The "split I and D cache" hack allows the CPU to execute one stream of instructions, while displaying (via the D cache) a completely different stream of instructions to anyone who is trying to understand what instructions are being executed.
Using Jacob Torrey's TLB-splitting technique, one can arbitrarily change what is being executed, *no matter what the programmer wrote*.
See Jacob Torrey "MoRE Shadow Walker: TLB-splitting on the Modern x86"

@_date: 2016-09-11 08:08:11
@_author: Henry Baker 
@_subject: [Cryptography] Secure erasure in C. 
As many people have pointed out, the problem with erasure is that it deals with a concept not captured by normal programming languages, operating systems or computing hardware.
Programming languages deal with *returned values* and *variable values*, and so long as these values achieve the desired bit patterns, everyone is cool.  No one cares about the values of (supposedly) "dead" variables which can "never" be referenced.
There is a formal notion from the lambda calculus about all of this: so-called "lazy evaluation".  Lazy evaluation never attempts to evaluate an expression until it is *absolutely necessary for the ultimate output value*, out of fear that this expression will loop or err out.  Lazy evaluation is the ultimate "leave sleeping dogs lie" approach to computation.
A *lazy architecture* would *never* actually clear a variable value unless that variable value participated in a computation leading to a final result.  So the whole concept of "secure erasure" is meaningless in this computing model.
This problem is precisely why "linear types" are a necessary addition to the mathematical modeling of computer systems -- particularly operating systems and hardware.
Operating systems have always attempted to handled "resources" like time (CPU cycles), space (main memory and secondary memory), I/O channels, etc.  But prior to "linear logic", there was never a mathematical model of what a "resource" was.
With "linear types", we finally have a notion of a *resource* which can be temporarily allocated, returned, and re-allocated.
Consider the following trivial Lisp program for computing factorial:
(defun fact (n)
  (if (zerop n) 1
    (* n (fact (1- n)))))
Such a program only talks about *values* and not *resources*.
Let us first rewrite our factorial program to enable it to return *multiple values* instead of the single result value.  So far, this is identically the same fact program as before, except that it allows for multiple values to be returned.
(defun fact (n)
  (if (zerop n) (values 1)
     (multiple-value-bind
        (fact1-n) (fact (1- n))
        (values (* n fact1-n)))))
Now let us rewrite "fact" again to include a *resource*: the free storage list which I'll denote *freelist*.
(defun fact (n *freelist*)
  (if (zerop n) (values 1 *freelist*)
     (multiple-value-bind
        (fact1-n *freelist*) (fact (1- n) *freelist*)
        (values (* n fact1-n) *freelist*))))
What has happened here is that we have made explicit the fact that the freelist is both an argument and a returned value for our "fact" function.
But who is actually using this freelist?
The multiplication function "*" is the function that actually uses storage from the freelist in composing its arbitrary-precision ("bignum") result.
So now we have to rewrite our program once again to provide "*" with the freelist as both an argument and a result:
(defun fact (n *freelist*)
  (if (zerop n) (values 1 *freelist*)
     (multiple-value-bind
        (fact1-n *freelist*) (fact (1- n) *freelist*)
        (multiple-value-bind
           (factn *freelist*) (* n fact1-n *freelist*)
           (factn *freelist*)))))
(Lisp-ers and Scheme-ers will quickly notice that this program can be slightly optimized by removing the final "tail-recursion"; I won't do that here because it doesn't change the meaning of the program.)
The argument (and value) *freelist* is a *linear type*, and a proper language compiler will ensure that its value cannot be either inadvertently copied or inadvertently destroyed; this is the definition of "linear".
This last version of "fact" is also much closer to what is actually happening within the Lisp implementation: the freelist *is* an extra argument and an extra returned value for every Lisp function (at least those Lisp functions that actually need to "CONS").
The fact that the freelist is typically passed around either as a reserved register variable or as a hidden global variable is merely an implementation detail; the code above captures the *meaning* of the computation.
But we aren't done yet.  So far we've talked about *space*, but not *time*.
We now need to add yet another *linear* variable to be added as another parameter and returned value: "*cpu-ticks*".  The meaning of *cpu-ticks* is the *resource* of CPU time allotted to this program.
(defun fact (n *freelist* *cpu-ticks*)
  (if (zerop n) (values 1 *freelist* *cpu-ticks*)
     (multiple-value-bind
        (fact1-n *freelist* *cpu-ticks*) (fact (1- n) *freelist* *cpu-ticks*)
        (multiple-value-bind
           (factn *freelist* *cpu-ticks*) (* n fact1-n *freelist* *cpu-ticks*)
           (factn *freelist* *cpu-ticks*)))))
This "fact" program has now fully fleshed out the *resources* utilized in this computation -- both time and space.  If the *freelist* becomes exhausted, the program will fail.  Likewise, if the *cpu-ticks* become exhausted, the program will fail.
It is *this* level of computation that operating systems deal with: resources.
Modeling at this level of computation will be required in order to start dealing with the resource allocation and de-allocation issues faced by crypto computations.

@_date: 2016-09-11 10:51:26
@_author: Henry Baker 
@_subject: [Cryptography] [Crypto-practicum] An historical document. 
I quote from your document:
"4.  In view of the ***extensive publicity*** given to the Coast
Guard cryptanalytical activities I believe that immediate steps
should be taken to inform responsible authorities of both the
Army and Coast Guard that the Navy considers information per-
taining to the application of machinery to cryptanalysis is a
matter of national defense and should be withheld from disclosure
under provisions of the Espionage Act of 15 June 1917.  It might
also be well to take similar action with respect to the Inter-
National Business Machine Company through their representative
here in Washington."
I merely suggested that Turing might have seen some of that
"extensive publicity".
I haven't searched the historical documents, but IBM would very
likely have made a big deal out of this use of their tabulating
(Some wags might also have gone further and thought that IBM
would have been *proud* to have shipped its equipment to Germany
at that particular time.  Also Google "Edwin Black".  A number of
U.S. corporations--e.g., GM & Ford--were quite fond of Germany,
and did extensive business with Germany right up to the day that
war was declared by the U.S.)

@_date: 2016-09-11 12:20:52
@_author: Henry Baker 
@_subject: [Cryptography] [Crypto-practicum] An historical document. 
I'm sorry to drag this out, but the point I'm trying
to make is that when a live seed finds itself on
fertile ground, it may germinate into a sequoia.
You couldn't find more fertile soil than Turing's
mind circa 1937; even the merest hint connecting
tabulating machines and coding would have been all
that was required for him to see all of the
Turing would certainly have known about punched
card tabulating machines; I believe that they
were also in use in England (but with round
holes?).  He very likely saw them at Princeton
or during his travels in the U.S.
There were various schemes already in use for
hand sorting edge-punched cards with long thin
steel rods; Knuth covers these schemes in his
Punched paper tapes had already been used for
~50 years for teletypes and stock market tickers.
I worked on these so-called "Electronic Accounting
Machines", which included *sorters*, *mergers* and
Sorters were read-only devices that rearranged the
ordering of the cards.  Mergers (programmed with
wired plug-boards) would merge 2 (or more) decks
of sorted cards and merge the information from
the two (or more) different streams into an
newly punched output stream.  Printers (also
programmed with wired plug-boards) would process
sorted card decks and subtotal certain columns on
a "break", where a high order field in the sort
order would change.
I seem to recall that only the printers were
smart enough to do arithmetic; the mergers could
compare, but I don't recall their ability to
add or subtract (at least in the earlier models).
P.S.  Wouldn't it be a scream to find out that
if Turing *hadn't* seen this Coast Guard publicity,
he might never have been interested in coding and
Britain would have lost the war!
In this particular case, secrecy might have killed
the very technology that would have won the war.
I'm afraid that crypto secrecy -- in general -- set
everyone back far more than it helped.  Look at how
the field exploded once Diffie/Hellman/RSA got

@_date: 2016-09-12 15:30:57
@_author: Henry Baker 
@_subject: [Cryptography] Secure erasure in C. 
I should have pointed out that there is a *general* procedure for compiling a computation into a form where you can *force* evaluation in the order (i.e., including forcing the evaluation of sub-expressions that might not otherwise be evaluated) of your choice.
The result of this general procedure is the program rewritten in "continuation-passing style".
In particular, continuation-passing style forces the computations that you want even in the presence of a *lazy evaluator*.  This is because continuation passing style *linearizes* the computation in such a way that the compiler has no choices about what to evaluate next, and *all* of the results are passed -- either directly or indirectly -- as arguments to the next portion of the computation in such a way that the compiler can't avoid performing the computation.
Furthermore, continuation-passing style also works in C:
Continuation-passing style ("CPS") *looks* (after careful formatting) very like assembly language; indeed, Andrew Appel (who has also hacked voting machines) wrote an entire book on how to efficiently compile languages using CPS intermediate forms.
So, if you have a variable XXX that you want to set to zero and be certain that the compiler won't optimize this setting to zero, you arrange the computation in such a way that this variable is passed as an argument (probably in the form &XXX) to the *continuation* procedure of the rest of the computation.  Thus, if the computation proceeds anywhere at all, it must proceed to this continuation, and the semantics of C require that the value of XXX actually be zero when it enters that continuation procedure.
There is a technical issue in the C language due to the fact that C doesn't support *full closures* like Pascal or Javascript; i.e., C supports only *global variables* and *argument variables*.  However, there is further well-known procedure (called "lambda lifting") which collects up all of the variables which might have participated in an actual closure, and passes them as additional arguments.  Thus, through a combination of lambda-lifting and continuation-passing style, a C program can be forced into a form where the optimizer is no longer free to elide computations it considers unnecessary.
I don't presume to imply that the C programs so produced are completely readable(!), but readability is often over-rated when humans read code and miss obvious errors -- e.g., the famous Apple "goto fail" bug.
The important point here is that both lambda lifting and CPS conversion are rigorous *algorithms*, so they can be thoroughly vetted.
If no one in the crypto community is aware of continuation-passing style (DJB: are you listening?), then perhaps I should go through some of the NaCL/libsodium code and demonstrate how CPS might be helpful in nailing down the semantics.

@_date: 2016-09-12 20:44:03
@_author: Henry Baker 
@_subject: [Cryptography] Secure erasure 
Having studied Ada at some length, I see no significant advantage
of Ada over C for any of the purposes we discuss on these lists.
My opinion isn't based on the characteristics of the language,
per se, but on the inability to control the fine details of the
What's the point of having a garbage collector (in some versions
of Ada), if you can't control fine details enough to make sure
that it isn't going to ruin your real-time performance?
More to the point of this thread, what's the point of having a
more array bounds checking if you can't control carefully enough
what happens when an array index does go out of bounds?
In my experience with Ada, I spent most of my time fighting the
implementation, and after all that effort, the performance was
Bottom line: Ada was PL/I with slightly more modern syntax, but
not nearly as high quality compilers and run-time systems.
Modern CPU's with sophisticated instruction fetch hardware
can arrange execution so that array bounds checking is done
in parallel with other activities, so it no longer exacts
any run-time penalty.  And with multiple CPU's, there are
typically huge numbers of cycles to burn in any case.
So ubiquitous array-bounds checking should no longer be an
What we're currently fighting are billions of lines of
legacy software developed by the "code cowboys" trained
by Berkeley, Stanford and Bell Labs in the 1980's and
enthusiastically hired (using programming tests which
marked down those who checked array bounds) by Microsoft,
Oracle, etc., who *never* checked an array bound in their
entire programming lives.

@_date: 2016-09-13 10:43:33
@_author: Henry Baker 
@_subject: [Cryptography] Secure erasure 
Ada compilers targeting the Java Virtual Machine ... which itself has GC.
Conservative Garbage Collection for GNAT
Incorporating Precise Garbage Collection in an Ada Compiler
GC delays won't do very much to obfuscate crypto code (unfortunately); I suppose that one could conceivably schedule the GC based on calls to /dev/(u)random, but normal (non-randomized) GC delays might themselves be more of an information leak even than other side channels.
WWHBD (What Would Henry Baker Do) ?
This is becoming very, very tough.
There are untrustworthy HW CPU's, where "instructions" in the benign form of "load r3," are really "dog whistles" to hidden HW that starts doing bad things like storing registers in hidden memories, etc.  Let's ignore this class of attacks for this message.
There are HW CPU's which simply ignore standard semantics; programmers used to issue *instructions*, historically called "order codes".  Now, however, "instructions" and "orders" are converted into merely "suggestions" and "hints", so there's very little a programmer can 100% rely on to actually be executed.  We started with "imprecise interrupts", graduated to "out of order execution", "weak memory ordering", and now have nVidia's "dynamic code optimization" -- a kind of machine language JIT compiler.  We'll try desperately to ignore this class of attacks for this message.
But even prior to nVidia, we have split instruction & data caches, so that obvious looking instructions like "load r3,*" won't actually load the load instruction itself, but something completely arbitrary, depending upon what the TLB and data caches happened to have had for breakfast that morning.  (This is Torrey's "split-TLB" hack.)  We'll again try desperately to ignore this class of attacks for this message.
There are HW CPU's that allow interrupts between any two instructions; this was, and always has been, a REALLY BAD IDEA, because it made critical sections extremely hard to do correctly.  Anyone who has ever programmed in microcode will fully appreciate the flexibility to mask all interrupts for a few instructions.  Yes, such absolute power can corrupt absolutely, but the answer is code-stripping: the machine refuses to execute more than N instructions non-interruptibly before cancelling the whole program.  But once again, we'll try to ignore this class of attacks.
Due to these *virtualizations* and constraint "relaxations", we programmers are now forced to pleading on bended knee with the compiler, the operating system, and the hardware to please, please do as I ask.  (Cue diatribe re "volatile", etc., here.)  Or more usually, tricking the compiler, the operating system, and the hardware to do as we want -- in *spite of* the best efforts of the compiler, the operating system, and the hardware to interfere.
Given the continued pressure on CPU designers to optimize performance, I'm not certain that "constant time execution" is even possible anymore, so data-dependent information leaks will become ubiquitous.
Part of my background was in *asynchronous* systems, where logic gates were free-running, and took "as long as they needed", rather than being slaved to a crystal clock.  Clocked logic can dramatically reduce gate-count, but it can also dramatically reduce performance.  While fully asynchronous designs haven't ever gotten a lot of traction, clock speeds have increased substantially faster than the instruction speeds, so that instruction timings have become more and more variable.  I dare say that now that logic is so cheap, fully asynchronous designs should be re-evaluated.  Thus, I expect information leakage due to differential timing will go from a trickle to a torrent.
All this means that timing attacks need to be *blinded* by some (probably quite sophisticated) mechanisms, so that the information that does leak will be complete garbage.
Energy attacks will also become more common.  Unless every bit is also associated with an "anti-bit", the differential currents will produce voltage drops which can be measured.  In fact, with asynchronous logic, such voltage measurements will be easy, since different voltages will produce different timings for the same computation.
I'm delighted to see all the interest in IoT.  Now that CPU's and flash memories are *dirt cheap*, it will be possible to throw out the baby with the bath water and design new architectures with totally new goals.  We no longer have to be so stingy with memory (cue plea for address-size-word-oriented architectures); we no longer have to be so stingy with CPU cycles.  We should be able to experiment with *clean sheet architectures* that can *run* C and Linux, but aren't saddled with all of the legacies and compromises of x86 and ARM.  And we can work on new stripped-down versions of C that re-enable *orders that must actually be obeyed*.
The new "container-oriented" programming (incl. "unikernels") allows new types of firewalls that can hinder hackers.  These models also offer the ordinary programmer access to HW features like virtual memory page tables that were previously only available to the OS priesthood.
The biggest problem will be finding students whose minds haven't been so polluted with current architectures and languages that they can't imagine anything else.  So these students will probably NOT be CS students, but more likely physicists, mechanical engineers, pure mathematicians and/or artists.
So WWHBD ?  *Cut the Gordion Knot!*
The current morass ("mess"?) of compilers/operating systems/architectures is no longer worth trying to untie.
I would plea for such "clean sheet architectures", because the amount of money required to develop these will be far less than the amount of money required to deal with the insecurities of the current code base and architectures.
I take inspiration from the engineers at Tesla, who re-imagined the automobile that hadn't fundamentally changed in a century.  Revolution is possible, but only through the "creative destruction" of worn-out ideas.

@_date: 2016-09-13 15:48:07
@_author: Henry Baker 
@_subject: [Cryptography] Secure erasure 
A systems property still requires proper components to operate.
I recently came across an old (~1915??) movie by the Metropolitan
Museum of Art (NYC) about medieval armor.  I believe that it's on
It's absolutely fascinating how many components were required and
the intricate workmanship to make this armor.  You can bet that N
people died in order to define the requirements for each component.
Of course, as the threats evolved, so did the armor.  By WWI,
people had pretty much given up on armor, so people either didn't
wear helmets, or their helmets were worthless (security theater). (I'm not sure how much modern helmets help today; perhaps they
only protect one's head from bouncing around the inside of a
vehicle after it's been hit by an IED; of course, that level
of protection might be available from a bicycle helmet.)
Our 1980's-style software systems are currently dying in great
numbers from their naive designs.  Hopefully, we will learn
from these experiences.

@_date: 2016-09-14 10:00:50
@_author: Henry Baker 
@_subject: [Cryptography] Secure erasure 
Re: Remember the RISC revolution?
That was *so* long ago -- 40+ years!
But like pruning and "mowing the grass" (not the Israeli version!), a gardener's work is never done.
Regardless of the way RISC was pitched in its infancy, its primary goal was to simplify the architecture enough to fit onto a single chip.  In the process, of course, much unneeded complexity was thrown away.
In the mean time -- 40+ years later -- the garden has become completely overgrown again.
We can now fit billions of transistors on a chip; yuge flash memories are now extremely cheap.
"Fitting onto a chip" is no longer an issue, but security and power are yuge issues.
The multiprocessor revolution is just beginning to take off; I can recall my first computer (IBM 1401) with 4,000 (not 4096!) "characters" of RAM; we're nearly to the point where a consumer can purchase a computer with 4,000 *processors*.
Since fitting more processors is more important than making any one processor more powerful, it makes sense (once again) to pare processor design down to the bare minimum so that one can fit more processors onto the same chip.
Since instructions/joule has become more important than instructions/sec, it's time to seriously consider asynchronous systems again.  However, we need to modify the goals of asynchronous systems so that they don't try to compute their answers as *fast* as possible, but as *energy-efficient* as possible.
Given the yuge number of transistors that can fit on a chip -- yet only a vanishingly small fraction of these transistors can be switching at any moment else the chip will burn up -- means that we can have a large amount of specialized circuitry that may only operate once a day, once a month, once a year, or once ever.
We're now in the same boat with software, where the marginal cost isn't very high.  This now means HW bloat in addition to SW bloat.  (I.e., whatever floats your bloat!)
I recall the IBM System 91, which was an extremely sophisticated "out of order execution" machine.  Yet its performance was soon surpassed by far simpler & cheaper machines which simply included caches.  Sometimes, conceptual progress obsoletes (or at least renders secondary) a lot of sophistication.
Now that nearly all compilers utilize *pure functional* internal representations of computations, and *variable assignments* have been shown to be frighteningly expensive -- especially in a multiprocessor world -- it's time to move to fully functional machine languages, and push the transactional complexity of shared-memory state out into the open.
Mocking Richard Feynman, "there's still plenty of room at the bottom" (i.e., in extremely simple CPU architectures).

@_date: 2016-09-14 16:24:54
@_author: Henry Baker 
@_subject: [Cryptography] massively parallel processing 
The following new nVidia computer may give new meaning to
"war-driving"; air-cracking your neighboring auto wifi's &
drivers' cellphones while you wait for each red light.
(The *idle* cycles of the computers on self-driving cars
have enormous computational power.  Forget SETI for idle
cycles; do bitcoin mining and/or password cracking.)
Nvidia Shows Off New AI Computer For Baidu's Self-Driving Car
U.S. chipmaker Nvidia nvda showed off on Monday a smaller and more efficient artificial intelligence computer for self-driving cars, saying it would power Baidu's bidu mapping and autonomous vehicle technology.
Chinese web services company Baidu will deploy Nvidia's new Drive PX 2 as its in-vehicle car computer for its self-driving system, Nvidia said in a press release as it unveiled the computer at the GPU Technology Conference in Beijing.
As more carmakers develop plans for self-driving technology to roll out in their vehicles in the next decade or less, Nvidia is trying to lower the barriers to entry, providing powerful computers to help automakers enter the market.
Earlier this month, Nvidia and Baidu announced a partnership to develop a full self-driving car architecture from the cloud to the vehicle using both companies' expertise in artificial intelligence (AI).
Nvidia said its new Drive PX 2 computer uses 10 watts of power and is half the size of the original version, launched in January.  That solves a problem faced by carmakers incorporating self-driving technology -- how to pack the punch of AI, which helps cars make decisions, into a compact computer suitable for production-ready vehicles.

@_date: 2016-09-15 09:23:50
@_author: Henry Baker 
@_subject: [Cryptography] ?crypto in fully functional style 
I've seen references to *Cryptol*, a domain-specific language for crypto.  However,
I don't know whether it would be considered "functional-style".
It apparently can be compiled directly into an FPGA.

@_date: 2016-09-16 16:09:14
@_author: Henry Baker 
@_subject: [Cryptography] Ada vs Rust vs safer C 
Terrific idea, but how do you keep such a project under control?
Even if you can get such a project started, the biggest issue becomes *mission creep*.
People get so enamored with the project & process that they forget why they're there.
Ideally, this is a project of *one*, or at most *two* people, which then gets a prototype compiler implemented by an extremely small team in a relatively short time.
IMHO, the main things to do are to remove certain features and to standardize certain other common practices.
Also, recognize that we now have huge memories, & so remove many ancient limitations -- e.g., size of identifiers, character sets, expression sizes & depths, pre-processor limitations, etc.
The language is a *subset* of existing C, but far more portable and easier to deal with w/o arbitrary limitations.  It should be possible to make existing programs "look" like your new standard, through appropriate C preprocessor macros.
Perhaps the most obvious remaining non-portability should be big-endian v. little-endian.  I see no non-visible way to eliminate these differences.
You'll have Intel/AMD lining up against ARM & MIPS contingents to try to their favorite architectures; you need to raise funds from all contenders to keep it neutral.

@_date: 2016-09-22 09:31:09
@_author: Henry Baker 
@_subject: [Cryptography] Spooky quantum radar at a distance 
FYI --
The end of stealth?  New Chinese radar capable of detecting 'invisible' targets 100km away
Breakthrough relies on 'spooky' phenomenon of quantum entanglement
PUBLISHED : Wednesday, 21 September, 2016, 12:43pm
UPDATED : Wednesday, 21 September, 2016, 11:11pm
Stephen Chen
Researchers teleport tiny photon particles across cities in breakthrough that could help future development of a faster, more secure 'quantum internet'
A top Chinese military technology company shocked physicists around the world this week when it announced it had developed a new form of radar able to detect stealth planes 100km away.
The breakthrough relies on a ghostly phenomenon known as quantum entanglement, which Albert Einstein dubbed "spooky action at a distance".
China Electronics Technology Group Corporation (CETC), one of the "Top 10" military industry groups controlled directly by the central government, said on Sunday that the new radar system's entangled photons had detected targets 100km away in a recent field test.
That's five times the "potential range" of a laboratory prototype jointly developed by researchers from Canada, Germany, Britain and the United States last year.
America's Defence Advanced Research Projects Agency has reportedly funded similar research and military suppliers such as Lockheed Martin are also developing quantum radar systems for combat purposes, according to media reports, but the progress of those military projects remains unknown.
In a statement posted on its website on Sunday, CETC said China's first "single-photon quantum radar system" had "important military application values" because it used entangled photons to identify objects "invisible" to conventional radar systems.
Nanjing University physicist Professor Ma Xiaosong, who has studied quantum radar, said he had "not seen anything like this in an open report".
"The effective range reported by the international research community falls far below 100km," he said.
A military radar researcher at a university in northwestern China said the actual range of the new radar could be even greater than that announced by CETC.
"The figure in declassified documents is usually a tuned-down version of the real [performance]," he said.  "The announcement has gone viral [in the radar research community]."
The scientists said they were shocked because, until recently, the idea of quantum radar had remained largely confined to science fiction.
Quantum physics says that if you create a pair of entangled photons by splitting the original photon with a crystal, a change to one entangled photon will immediately affect its twin, regardless of the distance between them.
A quantum radar, generating a large number of entangled photon pairs and shooting one twin into the air, would be capable of receiving critical information about a target, including its shape, location, speed, temperature and even the chemical composition of its paint, from returning photons.
That sounds similar to a normal radar, which uses radio waves, but quantum radar would be much better at detecting stealth planes, which use special coating materials and body designs to reduce the radio waves they deflect, making them indistinguishable from the background environment.
In theory, a quantum radar could detect a target's composition, heading and speed even if managed to retrieve just one returning photon.  It would be able to fish out the returning photon from the background noise because the link the photon shared with its twin would facilitate identification.
However, Ma, who was not involved with the CETC project, said serious technical challenges had long confined quantum radar technology to the laboratory.
The photons had to maintain certain conditions  known as quantum states  such as upward or downward spin to remain entangled. But Ma said the quantum states could be lost due to disturbances in the environment, a phenomenon known as "decoherence", which increased the risk of entanglement loss as the photons travelled through the air, thus limiting the effective range of quantum radar.
The CETC breakthrough benefited largely from the recent rapid development of single-photon detectors, which allowed researchers to capture returning photons with a high degree of efficiency.
CETC said the quantum radar's advantage was not limited to the detection of stealth planes.
The field test had opened a "completely new area of research", it said, with potential for the development of highly mobile and sensitive radar systems able to survive the most challenging combat engagements.
Quantum radar systems could be small and would be able to evade enemy countermeasures such anti-radar missiles because the ghostly quantum entanglement could not be traced, it said.
The company said it had worked with quantum scientists at the University of Science and Technology of China in Hefei, Anhui province, where many quantum technology breakthroughs have been achieved, including the world's longest quantum key distribution network for secured communication and the development of the world's first quantum satellite.
This article appeared in the South China Morning Post print edition as:
Quantum radar 'can see stealth planes at 100km'
I would imagine that quantum entanglement could also be used for IFF systems...

@_date: 2016-09-23 16:52:07
@_author: Henry Baker 
@_subject: [Cryptography] iOS 10 backups easier to hack than iOS 9 backups 
FYI --
iOS 10 Has a 'Severe' Security Flaw, Says iPhone-Cracking Company
Written by Joshua Kopstein
September 23, 2016 // 04:08 PM EST
Apple has introduced a "severe" flaw in its newly-released iOS 10 operating system that leaves backup data vulnerable to password-cracking tools, according to researchers at a smartphone forensics company that specializes in unlocking iPhones.
In a blog post published Friday by Elcomsoft, a Russian company that makes software to help law enforcement agencies access data from mobile devices, researcher Oleg Afonin showed that changes in the way local backup files are protected in iOS 10 has left backups dramatically more susceptible to password-cracking attempts than those produced by previous versions of Apple's operating system.
Specifically, the company found that iOS 10 backups saved locally to a computer via iTunes allow password-cracking tools to try different password combinations at a rate of 6,000,000 attempts per second, more than 40 times faster than with backups created by iOS 9.  Elcomsoft says this is due to Apple implementing a weaker password verification method than the one protecting backup data in previous versions.  That means that cops and tech-savvy criminals could much more quickly and easily gain access to data from locally-stored iOS 10 backups than those produced by older versions.
Being a company known for breaking into iPhones, Elcomsoft unsurprisingly did not disclose the vulnerability to Apple before publishing its blog.  But CEO Vladimir Katalov told Motherboard that his company responded to Apple's security team after it requested more information about the bug through the company's online support system early Friday morning.
"Apple is definitely aware they have implemented [the flaw] themselves :)" Katalov told Motherboard in an email.
An Apple spokesperson confirmed that the company is working on a fix.
"We're aware of an issue that affects the encryption strength for backups of devices on iOS 10 when backing up to iTunes on the Mac or PC.  We are addressing this issue in an upcoming security update," the spokesperson said in a statement.  "This does not affect iCloud backups.  We recommend users ensure their Mac or PC are protected with strong passwords and can only be accessed by authorized users.  Additional security is also available with FileVault whole disk encryption."
The flaw could be a huge boon for law enforcement, spies, and sophisticated criminals who are able to gain possession of a victim's iOS backup file.  While iOS devices themselves are known for having fairly solid security backed by a hardware module called the Secure Enclave, one of the remaining avenues of attack is to trigger a device to backup either to iCloud or a local computer, where data enjoys far less protection.
Normally, local backups are protected by a user's password.  But in iOS 10, Apple has implemented a weaker hashing algorithm--a function used to verify and store passwords in an unrecognizable format.  This allows police and hackers to more easily "brute force" the backup file's password by having a piece of forensics software guess millions of different passwords per second until it finds one that matches the stored hash.
Using an Intel i5 processor, Elcomsoft says it was able to guess passwords on iOS 10 backups 2,500 times faster than using the same hardware against an iOS 9 backup.  That same processor was still 40 times faster than using a top-of-the-line graphics processor to brute force passwords on backups created by iOS 9.  (Elcomsoft doesn't support GPU-based password cracking yet on iOS 10, but it should increase the speed even more once it becomes available.)
When compounded with lists of commonly-used passwords, Elcomsoft says the amount of time it takes to crack an iOS 10 backup's password can be reduced even further.  Once an attacker has unlocked the backup, they can gain complete access to the device's data in its saved state--including the keychain, a file that's normally impossible to retrieve from the physical device which stores all the user's logins and passwords.
For its part, Apple at least seems interested in issuing a fix.  But given the various pieces of software involved, it remains unclear how long it would take to roll out.
"The fix itself is probably not so easy, because that hash might be used for some other purposes we are not aware of," Katalov told Motherboard in an email.  "So I guess that not just iOS update is needed, but also iTunes update as well, and probably some changes to the backup format."
UPDATE: Sept. 23, 5:50 p.m. ET: This story has been updated to include Apple's statement.  Also, a previous version of this article mentioned rainbow tables as a method for determining a backup file's password, however rainbow tables would in fact not be usable in this case.

@_date: 2016-09-24 09:50:44
@_author: Henry Baker 
@_subject: [Cryptography] Threat Model: Bluetooth tracking beacons 
FYI --
Apple Deleting the iPhone's Audio Jack Is Good News for Marketing Companies
Written by Joshua Kopstein  September 23, 2016 // 08:00 AM EST
Apple's much-anticipated decision to nix the headphone jack on its newest iPhone has understandably made a lot of people very angry.  But there's at least one industry that's jumping for joy over the death of the ubiquitous audio plug: Marketing companies that track your phone's location and target you with ads.
The reason for the celebration is Bluetooth beacons, a "proximity marketing" technology that's been pushed by the ad-tech industry for years.  The beacons come from tiny Bluetooth Low-Energy (BTLE) transmitters that have already been planted inside many retail stores, airports, and museums, which send signals to nearby mobile devices.  If your device has Bluetooth enabled and comes in range of a beacon (say, in a clothing store) any apps you've installed that are listening for Bluetooth beacons can determine exactly where you are, target you with ads, or record your real-world shopping habits, among other things.
And now that Apple has gotten rid of the iPhone's headphone jack, marketers are anticipating that a whole lot of people will soon be leaving their Bluetooth enabled, effectively "opting in" to the beacons' tracking.
The renewed relevance of beacons was a topic of excitement at Place Conference, a location marketing summit held earlier this week at the University of Chicago.  There, a session on Bluetooth beacon adoption specifically mentioned Apple's removal of the iPhone headphone jack as an opportunity for tracking beacons, which require Bluetooth to be left on to work.
Marketers and tracking companies have long tried to fight criticism of Bluetooth beacons by claiming that the tracking is done with users' consent.  One company, Estimote, describes them as "an opt-in tech to enhance user experience."  The session's presenters also dismissed the privacy concerns surrounding beacons, saying the tracking is "really no different from GPS."
Big tech firms are already on the beacon bandwagon too.  Apple announced its iBeacons platform back in 2013, paving the way for Bluetooth-enabled iOS devices to receive beacons for a variety of purposes--from pushing ads or coupons to shoppers who linger in certain sections of a department store to sending tourists notifications with information about nearby landmarks.  The free LinkNYC WiFi kiosks now scattered about New York City, paid for in part by a Google spin-off company called Sidewalk Labs, are also capable of sending advertising beacons to logged-in users.
"Marketers are trying to trick people by saying the standalone beacons don't actively track people because they only send pings" to your device, said Adam Harvey, an artist and privacy technologist who has studied Bluetooth beacon tracking.  "Of course beacons are used to track you.  That's the whole point.  Marketers want to know who you are, where you came from, and exactly where you're standing right now with centimeter precision."
Currently, you can "opt out" of the tracking by avoiding apps that use beacons and remembering to keep Bluetooth off on your device.  But the boundaries of consent get really blurry when everyone starts walking around with devices like the headphone jack-less iPhone 7, which basically require Bluetooth to be left on constantly to do basic things like listen to music.
Granted, iOS' privacy controls let you choose which apps can receive beacons by enabling or disabling them in Location Services.  But there's currently no way to disable an app's ability to receive Bluetooth beacons without removing its location access entirely.  You can also avoid Bluetooth on the new iPhone by attaching a $10 headphone adapter, but whether users embrace that clunky solution in the long-term remains to be seen.
The potential uses for beacon-based surveillance goes far beyond advertising.  In a 2008 study, researchers used high-accuracy Bluetooth tracking to monitor prisoners in order to gather intelligence on their activities and map out on their social connections.
To be fair, not all applications of beacon technology are marketing or surveillance-oriented.  Google's Eddystone beacon platform aims to establish a degree of privacy by offering what the company calls an "Ephemeral Identifiers," a unique code given to every beacon device that can be constantly changed, preventing third parties from establishing any useful information about the beacon or the devices it connects with.
But ultimately, said Harvey, the goal of advertisers in spreading the adoption of beacons is clear--especially in a post-headphone jack world where users are much more reliant on Bluetooth.
"To consumers, beacon tracking systems are marketed as privacy friendly," said Harvey.  "To marketers working in retail-surveillance, beacons are more aptly called 'cookies for the physical world.'"
"This is beyond privacy.  It's about programming human behavior," he added.
OK, here's a real-world threat.
Anyone here have any good ideas of the *minimal* changes in Bluetooth protocols to render these "beacons" (actually trackers) useless?
The problem, of course, is that the Bluetooth earbuds, Bluetooth keyboards, Bluetooth car connections, etc., also have to be able to work.  Ideally, a solution would enable some sort of "mac hopping" (analogous to frequency hopping) that would work in real time even when one is listening to music or on a telephone call.
I don't know as much about the Bluetooth protocols, but Apple does have mac randomization for wifi[1].  I'm not sure that mac randomization does very much for privacy, or whether it would work for Bluetooth; my guess is that the communicating Bluetooth devices would also have to be modified/upgraded, as well.
Also, of course, you're going to have to throw away your Fitbit, your BLE heart rate monitor, your $5,000 gold iWatch, etc. [2]
[1] [2]

@_date: 2016-09-25 09:51:57
@_author: Henry Baker 
@_subject: [Cryptography] Spooky quantum radar at a distance 
FYI --
~105 minutes; ~200MBytes
Seth Lloyd: Quantum Computer Reality
Wednesday, August 10, 2016 2:30 AM
Quantum computing is widely considered to be: The most potentially transformative technology of this century; Nothing but hope and hype.  A reliable reporter who is familiar with all of the rich variety of quantum research going on and the reality of the remarkable progress in the field (along with its still-expanding potential) is quantum pioneer Seth Lloyd, professor of mechanical engineering and physics at MIT.  Lloyd describes himself as a mechanic of quantum computing, quantum communication, and quantum biology.  He is director of MITs Center for Extreme Quantum Information Theory, which is working on breakthroughs in general-purpose optimization, vastly enhanced communication, and ultra-precise measurement.  In his book Programming the Universe (2006) he proposes that the universe is a vast quantum computer that can eventually be completely understood through local-scale quantum computation.
MIT Prof. Seth Lloyd addresses precisely the spooky quantum radar question at approx. 80 minutes into this 105-minute talk about quantum mechanics.
Basically, Seth says that you generate correlated photons; keep one circulating in a fiber-optic loop (or other quantum storage device) while shooting the other up into the air.  You then attempt to correlate "returning" photons with your stored photons; if there is *excess* correlation, then the chances are very good that the "returning" photons have bounced off something, and *are actually returning*.

@_date: 2016-09-30 13:24:38
@_author: Henry Baker 
@_subject: [Cryptography] Use Linux for its security 
I've had a long-standing complaint with Common Lisp -- even though it is
technically a buffer-overflow-free zone -- regarding arrays whose length
is a priori unknown.
The problem is that the Lisp "reader" doesn't know how long an array is
prior to reading elements from an input stream.  This means that a lot
of mechanism (and associated bugs & inefficiencies) is required to buffer
the incoming data in such a way that it eventually gets stored into a
correctly-sized array.  This also *guarantees* that Lisp can never compete
with some other languages in the efficiency of high volume I/O.
One obvious solution is to construct a Lisp list of elements until the
last element has been read, at which time the length is known and the
array can be allocated and filled.  But this is terribly inefficient,
since there are a lot more memory references than should strictly be
necessary.  (Note that in a garbage collected language, you need to
charge every allocation with a certain amount of amortized GC cost.)
If the size of the array were a priori known, then a correctly-sized
array could be *lazily* allocated and filled as the data came in.
By "lazy allocation", I mean something akin to OS virtual memory
page tables, where allocated (but not yet "touched") pages can be
assumed to be all zeros, and any page elements not written will
be subsequently read as zero.
Bottom line: my proposal for Common Lisp allowed for current
(Common Lisp standard) behavior with unknown array size, but
if that array size were provided in advance, then an alternative --
but far more efficient -- implementation would be invoked.

@_date: 2017-04-05 10:56:01
@_author: Henry Baker 
@_subject: [Cryptography] Tempest and limits on receiving 
My old early-80's CRT color TV could listen in on 900MHz analog cellphones & analog cordless phones.  Just tune to the upper UHF channels; no video, but good FM sound.
No scanner necessary.
Of course, this TV was pretty big & took a lot of power, so wardriving with it turned on might appear a bit suspicious!
It probably emitted X-rays due to its CRT, so it might not have been the healthiest thing to be around.

@_date: 2017-08-02 06:17:25
@_author: Henry Baker 
@_subject: [Cryptography] How to find hidden/undocumented instructions 
FYI --
Breaking the x86 ISA
Christopher Domas  xoreaxeaxeax at gmail.com  July 27, 2017
A processor is not a trusted black box for running code; on the
contrary, modern x86 chips are packed full of secret instructions and
hardware bugs.  In this paper, we demonstrate how page fault analysis
and some creative processor fuzzing can be used to exhaustively search
the x86 instruction set and uncover the secrets buried in a chipset. The approach has revealed critical x86 hardware glitches, previously
unknown machine instructions, ubiquitous software bugs, and flaws in
enterprise hypervisors.
While the x86 architecture has been around for over 40 years, there
exist no public tools for auditing and validating the processor's
instruction set.  With a history of processor errata, security flaws,
and secret instructions, such introspection tools are necessary for
establishing trust in a computing system built on an x86 platform.
Here, we introduce the first effective technique for auditing the x86
instruction set, through guided fuzzing.  The approach uses a
depth-first instruction search algorithm in conjunction with page
fault analysis to exhaustively enumerate the distinct x86
instructions, while requiring no pre-existing knowledge of the
instruction format.  The generated instructions are executed directly
on an x86 platform, and the results of the execution -- including
observed instruction length and exceptions produced -- are compared
against the expected results from a disassembler.  The technique
reveals a multitude of undocumented instructions in a variety of x86
Whereas the techniques for finding bugs, secrets, backdoors
in software are well studied and established, similar
techniques for hardware are non-existent.  This is troubling, in
that it is the processor that enforces the security of the system,
and is ultimately the system's most trusted component.  It
seems necessary to stop treating a processor as a trusted black
box for running software...
Among other problems, undocumented/hidden instructions cannot be
properly handled by hypervisors & containers & emulators, and so
those tools cannot be used to guarantee safe execution in their

@_date: 2017-08-19 13:55:22
@_author: Henry Baker 
@_subject: [Cryptography] Cracked screen => cracked security ? 
FYI --
Secret chips in replacement parts can completely hijack your phone's security
Booby-trapped touchscreens can log passwords, install malicious apps, and more.
Dan Goodin - Aug 18, 2017 12:27 pm UTC
People with cracked touch screens or similar smartphone maladies have a new headache to consider: the possibility the replacement parts installed by repair shops contain secret hardware that completely hijacks the security of the device.
The Mafioso of old never allowed repairmen into their homes.  Stories abound regarding multiplicities of dead washing machines, TV's, etc.
It appears that their fears were justified.
On the other hand, these stories play right into the hands of those trying to kill "the right to repair" supported by the EFF.

@_date: 2017-08-25 09:56:51
@_author: Henry Baker 
@_subject: [Cryptography] 1/1000'th of a wavelength antennae 
FYI --
Acoustically actuated ultra-compact NEMS magnetoelectric antennas
State-of-the-art compact antennas rely on electromagnetic wave resonance, which leads to antenna sizes that are comparable to the electromagnetic wavelength.  As a result, antennas typically have a size greater than one-tenth of the wavelength, and further miniaturization of antennas has been an open challenge for decades.  Here we report on acoustically actuated nanomechanical magnetoelectric (ME) antennas with a suspended ferromagnetic/piezoelectric thin-film heterostructure.  These ME antennas receive and transmit electromagnetic waves through the ME effect at their acoustic resonance frequencies.  The bulk acoustic waves in ME antennas stimulate magnetization oscillations of the ferromagnetic thin film, which results in the radiation of electromagnetic waves.  Vice versa, these antennas sense the magnetic fields of electromagnetic waves, giving a piezoelectric voltage output.  The ME antennas (with ***sizes as small as one-thousandth of a wavelength***) demonstrates 12 orders
 of magnitude miniaturization over state-of-the-art compact antennas without performance degradation.  These ME antennas have potential implications for portable wireless communication systems.
Bottom line:
Antennae a thousand times smaller => side-channel attacks a thousand times easier!

@_date: 2017-08-29 04:51:41
@_author: Henry Baker 
@_subject: [Cryptography] How to find hidden/undocumented instructions 
FYI --
Intel ME controller chip has secret kill switch
Researchers find undocumented accommodation for government customers
By Thomas Claburn in San Francisco 29 Aug 2017 at 00:12
Security researchers at Moscow-based Positive Technologies have identified an undocumented configuration setting that disables Intel Management Engine 11, a CPU control mechanism that has been described as a security risk.
Intel's ME consists of a microcontroller that works with the Platform Controller Hub chip, in conjunction with integrated peripherals.  It handles much of the data travelling between the processor and external devices, and thus has access to most of the data on the host computer.
If compromised, it becomes a backdoor, giving an attacker control over the affected device.
That possibility set off alarms in May, with the disclosure of a vulnerabilityin Intel's Active Management Technology, a firmware application that runs on the Intel ME.
The revelation prompted calls for a way to disable the poorly understood hardware.  At the time, the Electronic Frontier Foundation called it a security hazard.  The tech advocacy group demanded a way to disable "the undocumented master controller inside our Intel chips" and details about how the technology works.
An unofficial workaround called ME Cleaner can partially hobble the technology, but cannot fully eliminate it.  "Intel ME is an irremovable environment with an obscure signed proprietary firmware, with full network and memory access, which poses a serious security threat," the project explains.
On Monday, Positive Technologies researchers Dmitry Sklyarov, Mark Ermolov, and Maxim Goryachy said they had found a way to turn off the Intel ME by setting the undocumented HAP bit to 1 in a configuration file.
HAP stands for high assurance platform.  It's an IT security framework developed by the US National Security Agency, an organization that might want a way to disable a feature on Intel chips that presents a security risk.
The Register asked Intel about this and received the same emailed statement that was provided to Positive Technologies.
"In response to requests from customers with specialized requirements we sometimes explore the modification or disabling of certain features," Intel's spokesperson said.  "In this case, the modifications were made at the request of equipment manufacturers in support of their customer's evaluation of the US government's 'High Assurance Platform' program.  These modifications underwent a limited validation cycle and are not an officially supported configuration."
Positive Technologies in its blog post acknowledged that it would be typical for government agencies to want to reduce the possibility of unauthorized access.  It noted that HAP's affect on Boot Guard, Intel's boot process verification system, remains unknown, though it hopes to answer that question soon.

@_date: 2017-12-01 06:24:21
@_author: Henry Baker 
@_subject: [Cryptography] Intel Management Engine pwnd 
My laptop has a little coin battery (separate from the laptop's regular
battery) just to keep the time.
But you already knew that...

@_date: 2017-12-01 13:39:43
@_author: Henry Baker 
@_subject: [Cryptography] Identity Theft: Evil car wash attack; 
Everyone has focused on preventing access to our cellphones, but we give our cars access to our cellphones all the time.  And the car's GPS unit conveniently provides additional important information.
The information in your car is far easier to attack than the information in your phone.  Every car wash (except the ones where you drive through yourself and those big rollers scratch the heck out of your paint job) provides employees more than enough access and time to download all the information from your car's computer.  Ditto for every valet parker.
Your car repair person could also be supplementing his/her income by selling data extracted from customer cars.
It is likely that every car is different, but the following information seems to be available in your car's computer even when your cellphone is out of Bluetooth range:
* all of your personal GPS waypoint locations, including "Home", "Office", "Physician", "Cancer Center", etc.
* perhaps some number of miles (perhaps hundreds) of logged GPS tracking data
* your entire contact list from your cellphone
* your entire call log history
* your entire text message history
* perhaps all of your phone's mp3 playlists
* your cellphone's Bluetooth MAC address (for later attacks on bad Android Bluetooth implementations)
BTW, if you *ever* allow your phone to talk to a rental car's Bluetooth, you deserve the Debbie Wasserman Schultz award for Cyber Security, and be forced to wear a "Kick Me" sign written in Cyrillic.
My car has both an SD card slot, a USB port, as well as the ubiquitous OBD-II (CAN) connector.  All of these data can be written to one or the other of the SD card or a USB stick.  It only takes a few seconds to dump almost everything (the "Easter Egg" modes of the car computer provide a fairly complete dump everything command).
I've been trying to learn how to delete various kinds of information from my car's computer, but it appears to be quite difficult: I may have to do a "factory/hard reset" to eliminate most info, but I know it's all still there on the car computer's hard drive.
There does appear to be a way to dump the user parameters of the car computer onto an SD card for backup purposes; one can apparently reload these data from the same SD card.
Perhaps a sequence of *dump user parameters*; *factory reset*; *reload user parameters* may do the job -- possibly with a mildly hacked version of the user parameters to be reloaded.
BTW, we're not even talking about "firmware upgrades" which could easily install spyware to log all of the audio in your car -- not just the audio from the phone calls -- and store it all on your car computer's more-than-capacious hard drive.  Hook up your Bluetooth phone, and suddenly all these data can be accessed from anywhere in the world.
The funniest, most ironic thing about my car computer: due to concerns about copyrighted material being abused, it's nearly impossible to retrieve *music* from the car computer.  So Hollywood's data is clearly more important than my own (the actual customer's) data.

@_date: 2017-12-01 13:56:50
@_author: Henry Baker 
@_subject: [Cryptography] Transactional software updates 
You are describing the "unikernel"/MirageOS approach, which just enough
of an OS to allow a web site to talk to a *single user*.
You then use a hypervisor to run *thousands* of these little unikernel
VM's, each completely separate from one another.
MirageOS utilizes the capabilities of the OCaml language, which elegantly
strip out the inessential portions of the OS and libraries that aren't

@_date: 2017-12-02 07:09:05
@_author: Henry Baker 
@_subject: [Cryptography] Intel Management Engine pwnd 
What I'm talking about is a machine that refuses to "shut down" -- i.e., reach a state where there's no OS (supposed to be) operating at all.  We're not talking about "sleep" mode or "hibernation" mode; we're supposed to be "dead", as in 0xdeadbeef.  This is supposed to be a state which requires a *boot*, not a *wakeup*.
Microsoft/Intel forgot that their customers were actual human beings, not TLA's and corporate purchasing agents.  Perhaps Google/Facebook should wake up before they, too, find themselves on the dustbin of history.
(BTW, isn't it ironic that even with all of Microsoft's & Intel's "ME"-type "management" nonsense, none of this intrusive surveillance helped when it was most needed -- the Sony hack, the Equifax hack, and 25 other high-profile hacks.  Yet more proof that back doors never help even on good days, and fail spectacularly on bad days.)
I don't care about tablets or touch screens; I simply want a laptop that runs Linux that I can carry around.
System76[*] is looking better and better all the time.
"All of this has culminated in the System76 plan to address Intel's November 20th vulnerability announcement and our ability to respond to future firmware update needs."
"System76 will automatically deliver updated firmware with a disabled ME on Intel 6th, 7th, and 8th Gen laptops. The ME provides no functionality for System76 laptop customers and is safe to disable."
[*]

@_date: 2017-12-03 09:07:54
@_author: Henry Baker 
@_subject: [Cryptography] Cryptocurrency: CME Approved, Coin  Paychecks, 
That's an interesting question.
Yes, Bitcoin futures will be traded, so you could "short" those, but wouldn't it be simpler, and more in line with the general philosophy of cryptocurrencies, to simply allow *negative* balances, so "shorting" would already be built into the cryptocurrency blockchain?
After all, if govts will (in future) sell only bonds with *negative* rates of interest (i.e., a "wealth tax"), cryptocurrencies should go ahead and get ahead of the trend...

@_date: 2017-12-09 05:35:03
@_author: Henry Baker 
@_subject: [Cryptography] Shorting Bitcoin [was Cryptocurrency: CME 
Yes, I know how shorting works -- currently.
But the whole point of cryptocurrencies is that they don't have to mimic every feature (or bug) in current currency systems.
The tendency with any new technology is to preserve the lifestyles and heuristics that worked for the old technology; it may take a century for the new technology to "come into its own" and start to take advantage of its differences from the old technology.
The real crypto currency revolution won't happen until things like loans, short selling, futures, options, etc., become *integrated* with a crypto ledger.
In the early 2000's, there was a lot of experimentation in *massively multiplayer online games* of different types of exchange value systems, and there was some analysis by economists of which types worked better than other types.
The consensus at the time seemed to be that "exchange" depends upon some quantities which are more-or-less conserved, and that game play lasted longer & was more interesting under these types of systems.
This result is also more-or-less in line with Wolfram's observation that cellular automata which obey conservation principles are far more interesting than those that don't.
But standard physics provides at least one example where "negative" (anti) particles work, so there is hope for currency systems which incorporate "short" positions naturally.

@_date: 2017-12-10 11:17:05
@_author: Henry Baker 
@_subject: [Cryptography] Intel's $10-100 billion Minix copyright problem 
FYI --
[1] "The law provides a range from $200 to $150,000 for each work infringed.
Infringer pays for all attorneys fees and court costs."
[2] Supplying Legal Notices for Free Software in your Products
By Fredrik Ohrstrom December 2, 2017
"Minix 3 is licensed under a BSD-style license and condition 2
states that if you want to distribute binary forms of Minix 3, you
have to give legal notice:"
"Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution."
"Normally, there is a very small risk of being sued for accidentally
missing a legal notice, since the authors of Free Software have better
things to do.  In this case however, Intel has, perhaps with intent,
contradicted the license for a purpose that Free Software authors
dislike.  Also, the amount of damages that can be argued for, is
remarkable.  Think about it; the software is probably in almost every
x86 Skylake CPU sold in the world for the last couple of years.
Perhaps this will be the first case where a BSD style license is
tested in court."
[3] The FISA Court and Article III
Stephen I. Vladeck
Ordinarily, I'm not fond of IP lawyers, but this time I'm
cheering heartily from the sidelines.  For a company like
Intel to install secret backdoors into every chip they sell
is completely unforgivable, and perhaps a bankruptcy-inducing
judgement will inspire every other vendor to become more
If Intel sold 100,000 chips with embedded Minix, then it
might be liable for up to $150k *per chip*, or $15 billion. If Intel sold 1 million chips with Minix, Intel might be
liable for $150 billion, and so on.
I'm now expecting to hear that Intel was *forced* by the
FISA "court" (perhaps not even an actual Article 3 court
[3]) to incorporate the ME "spy engine" into every chip,
and that same "court" issued an NSL to keep the existence
of this "spy engine" secret.

@_date: 2017-12-10 15:03:37
@_author: Henry Baker 
@_subject: [Cryptography] Intel's $10-100 billion Minix copyright problem 
Everyone retires to the FISA judge's chambers, then come out 30
minutes later; case mysteriously goes "poof".  Move along now;
nothing to see here.  Case closed.  Several Intel execs quietly
retire with multimillion $$$ golden parachutes & find lucrative
careers shilling for defense contractors in the "intel" community
(they don't even have to change their business cards very much!)
Intel SW folks execute "mv ~/ME/Minix ~/redacted/uCode", and
life goes on pretty much as before.
FISA court judge gives up his lifetime appointment to become Intel
corporate counsel; god's in his heaven, and all's right with the

@_date: 2017-12-11 06:27:47
@_author: Henry Baker 
@_subject: [Cryptography] Intel's $10-100 billion Minix copyright problem 
Andrew Tanenbaum's own words:
"If I had suspected [Intel] might be building a ***spy engine,*** I certainly wouldn't have cooperated, even though all they wanted was reducing the memory footprint (= chip area for them)."
"I think creating George Orwell's 1984 is an extremely bad idea, even if Orwell was off by about 30 years."
"People should have complete control over their own computers, not Intel and not the government."
"In the U.S. the Fourth Amendment makes it very clear that the government is forbidden from searching anyone's property without a search warrant."
"Many other countries have privacy laws that are in the same spirit."
"Putting a possible ***spy*** in every computer is a terrible development."
(BTW, putting a "spy engine" in every computer would seem to be a violation of the Third Amendment, as well:
Should 3rd Amendment prevent government spying?
Glenn Harlan Reynolds 11:24 a.m. EDT July 22, 2013

@_date: 2017-12-13 10:12:07
@_author: Henry Baker 
@_subject: [Cryptography] Zimbabwean Bitcoin, was Re: Shorting Bitcoin 
"Naked" shorting is only illegal for the unwashed masses.  Govt's, banks, brokerage firms, do it all the time.
Why do you think there is more "gold" and "silver" circulating than has ever been refined -- perhaps by orders of magnitude?  That's why so many people get nervous when someone -- e.g., Putin -- decides he's going to take physical possession of all of his "gold".  If Putin takes all his (golden) marbles home, the entire house of cards collapses.
Every once in a while, the sh*t hits the fan, and even these naked creeps get caught.
There was a high quality firm which was so boring that its stock was quite thinly traded.  Someone with a relatively small long position took their stock out of their brokerage account and put it into certificate form and the stock's price exploded.
Founders of companies should do this from time to time to see who's been swimming naked (to use Buffett's phrase.)  The usual suspects are the founders' own brokerage firms!
WRT quantum bitcoins:
Chemistry reactions "borrow" electrons, energy, etc., all the time.  There're always pair creation/pair destruction going on, so "impossible" reactions can happen if the potential barriers are lowered enough.  Just like an Olympic pole vaulter's center-of-gravity never actually makes it *over* the bar, the "impossible" reaction somehow manages to happen.

@_date: 2017-12-14 08:00:24
@_author: Henry Baker 
@_subject: [Cryptography] Privacy-preserving wireless communication? 
[The following discussion is intended to be 100% *theoretical*.
I'm *not* interested in a technical discussion of a particular
protocol -- e.g., Bluetooth -- as the complexity introduced
thereby completely obscures the theoretical issues I'm trying
to understand.]
Suppose I have a device -- e.g., my smartphone -- that wants
to talk *securely* and *privately* to another device -- e.g.,
my car.
I'm willing to go to significant initialization/precomputation
effort (aka "pairing"), in order to make sure that when the
time comes for actual communication/talking between the two
1.  My smartphone talks *only* with *my* car;
2.  My car talks *only* with *my* smartphone;
3.  No passive observer of the communications between my phone
and my car will reveal any information which will enable later
impersonation of either my phone or my car;
4.  No passive observer of the communications between my phone
and my car will reveal either the identity of my phone or the
identity of my car;
5.  No active observer can do anything other than simply jam
the channel;
6.  Either my phone or my car can decide to terminate the
communication relationship in such a way that only *repairing*
will re-enable the communication.
But here's the real kicker:
7.  From time to time, my phone and my car may not be able to
communicate for an unknown period of time -- e.g., my phone
may have gone out of range, my car may be turned off, passive
or active jamming could make communications impossible, etc.
During the period of non-communication, I don't want the
battery in either my phone or my car to be run down by constant
polling; I don't want any polling by either my phone or my
car to identify my phone or my car; I'd rather not have my
phone or my car even reveal that it IS polling.
Let's assume that my phone and my car might perform the
pairing process via non-wireless means -- e.g., simply
plugging them together via USB -- so that we don't have
to worry about protecting the pairing process itself.
Are there any simple protocols that could achieve these
I'm particularly interested in what happens during the
period of non-communication: what "messages" are sent
by either device; what does such a "message" look like?
how often are such messages emitted (e.g., Ethernet
backoff protocol ?), etc.

@_date: 2017-12-14 15:27:47
@_author: Henry Baker 
@_subject: [Cryptography] Privacy-preserving wireless communication? 
Here's one idea that came to mind re my pseudo-Bluetooth
car-phone scenario:
High-precision clocks are now extremely cheap, and
already built into cars, phones and other GPS devices.
So we can now "synchronize watches" during pairing
with incredible precision, and since none of our
devices are subject to black hole gravity or
speeds approaching the speed of light, these
devices will remain synchronized for quite a
long period -- weeks?  months?
One type of "secret" shared between the car and
the phone is the "time of day", or more precisely,
the "time of PRNG sequence".  We can use this
shared PRNG sequence to *randomly schedule*
an "appointment" between the car and the phone,
at which precise time the two will attempt to
communicate.  At any other time, no communication
will be attempted or accepted.
In order to save batteries, these appointment
opportunities will become less and less common --
perhaps exponentially so: analogous to Ethernet
During a successful communication, both parties
will with reasonably high probability negotiate
new synchronization and PRNG parameters, so
replay will never be successful.
There are significant differences between the
DNSSD and the car-phone scenarios -- most importantly,
I presume that DNSSD happens tens/hundreds/thousands
of times per second, while the car-phone scenario
could possibly survive a small number of seconds of
latency to re-establish communications after a period
of outage.

@_date: 2017-12-23 17:01:36
@_author: Henry Baker 
@_subject: [Cryptography] Open source encrypted file system for cheap IoT 
Any suggestions for a simple encrypted file system
for a $10-20 IoT device?
It doesn't have to be terribly fast, it doesn't
have to have be very sophisticated, but it does
have to have a small program memory footprint
and it does have to be reasonably secure, as it
may end up holding personal bio data.
For the moment, I'm thinking about using an uSD
card for the memory itself (uSD price not included!).
Ideally, the entire uSD card is preformatted with
random bits, so you won't even be able to tell how
much (if any) data is stored on the card.
If someone looks at this uSD card w/o the proper
key, they shouldn't be able to determine anything
except reformat the card for some other purpose.

@_date: 2017-12-26 06:59:31
@_author: Henry Baker 
@_subject: [Cryptography] Open source encrypted file system for cheap IoT 
mail.com>
I was hoping for an open source encrypted file system on an device that is so small and so limited that it doesn't even run a form of Linux.  It doesn't even need multiple processes or multiple threads.

@_date: 2017-12-26 12:32:45
@_author: Henry Baker 
@_subject: [Cryptography] Open source encrypted file system for cheap IoT 
mail.com>
Why?  Confidential info being stored/logged.
Key?  Hopefully something like public-key, so only the public key needs to be stored on the device -- but perhaps not even then.  If symmetric-key, then the device never stores the key at all, but it needs to be provided during bootup by some other mechanism, and is never stored to the file system itself (yet another reason for not using Linux -- way to much baggage to ever understand and/or verify).
Once again, it doesn't have to be fast, but it needs to have a small code footprint and be reasonably secure.

@_date: 2017-12-27 07:26:32
@_author: Henry Baker 
@_subject: [Cryptography] Open source encrypted file system for cheap IoT 
I forgot to say one of the reasons for open source: I
want to be able to recompile & run it on any OS (or not)
of my choosing: e.g., Windoze, MacOS, Linux, minix (!),

@_date: 2017-12-27 10:59:52
@_author: Henry Baker 
@_subject: [Cryptography] Open source encrypted file system for cheap IoT 
Why is this so hard?
IoT = very cheap, very low power, very small memory.
As I said, I want to access files on a uSD card or a USB stick,
so the encrypted file system is on a *passive* device.
I want to be able to do this from either the $10 device (not as
powerful as a Raspberry Pi, because Pi's take too much power),
or a larger machine -- e.g., Linux/MacOS/Windows.

@_date: 2017-12-28 10:51:29
@_author: Henry Baker 
@_subject: [Cryptography] Open source encrypted file system for cheap IoT 
mail.com>
Let's assume that the IoT device has only *root*, so it implement the file system directly on the SD/USB device.
When accessing the SD/USB device from Linux, we need to set permissions on the device driver to access the raw device.
What I'm looking for is simple filesystem code which implements an *encrypted* file system on the SD/USB device.
Obviously, one could read out the entire encrypted file system off the SD/USB device as a long file; decrypt the file; access (read and/or write) the plaintext data; re-encrypt & rewrite the data back to the SD/USB device.
Clearly, this is terribly inefficient if one is accessing only one file, which is why encrypted file systems have more complex encryption capabilities, to enable rewriting only O(1) or O(loglogN) or O(logN) fractions of the total storage when accessing O(1) portions of the data (instead of O(N)).

@_date: 2017-02-03 07:30:54
@_author: Henry Baker 
@_subject: [Cryptography] IRS W-2 'Verification Code' == Hash ?? 
Perhaps I missed it last year, but I just noticed that my 2016 W-2 has a 16-hex-digit 'Verification Code' just under the boxes numbered 10 and 11.
Does anyone know what this 'Verification Code' is?
It only has 4*16=64 bits, which is probably not strong enough to withstand a real attack, so why did they even bother?

@_date: 2017-02-20 06:30:08
@_author: Henry Baker 
@_subject: [Cryptography] German govt tells parents to destroy WiFi-connected 
FYI --
German watchdog tells parents to destroy WiFi-connected doll over surveillance fears
by James Vincent  Feb 17, 2017, 7:34am EST
A German government watchdog has ordered parents to "destroy" an internet-connected doll for fear it could be used as a surveillance device.  According to a report from BBC News, the German Federal Network Agency said the doll (which contains a microphone and speaker) was equivalent to a "concealed transmitting device" and therefore prohibited under German telecom law.
The doll in question is "My Friend Cayla," a toy which has already been the target of consumer complaints in the EU and US.  In December last year, privacy advocates said the toy recorded kids' conversations without proper consent, violating the Children's Online Privacy Protection Act.
Cayla uses a microphone to listen to questions, sending this audio over Wi-Fi to a third-party company (Nuance) that converts it to text.  This is then used to search the internet, allowing the doll to answer basic questions, like "What's a baby kangaroo called?" as well as play games.  In addition to privacy concerns over data collection, security researchers found that Cayla can be easily hacked.  The doll's insecure Bluetooth connection can be compromised, letting a third party record audio via the toy, or even speak to children using its voice.
Although the FTC has not yet taken any action against Cayla or its makers Manufacturer Genesis Toys, German data and privacy laws are more stringent than those in America.  The legacy of the Stasi, the secret police force that set up one of the most invasive mass-surveillance regimes ever in Communist East Germany, has made the country's legislators vigilant against such infringements.
A spokesperson for the German Federal Network Agency or Bundesnetzagentur told the Sueddeutsche Zeitung that the law forbids the sale or possession of any product that can be used for hidden surveillance, no matter their outward appearance: "It doesn't matter what that object is -- it could be an ashtray or fire alarm."
My Friend Cayla sounds like an old Saturday Night Live fake commercial!
Perhaps Alexa is (should be) next?

@_date: 2017-02-26 11:03:26
@_author: Henry Baker 
@_subject: [Cryptography] More efficient block-chain ledger: Micali's 
FYI --
(ignore first 14.5 minutes out of 57.5 total minutes)
ALGORAND: The Efficient and Democratic Ledger
Silvio Micali
(Submitted on 5 Jul 2016 (v1), last revised 16 Nov 2016 (this version, v7))
Algorand is a truly decentralized, new, and secure way to manage a shared ledger.  Unlike prior approaches based on {\em proof of work}, it requires a negligible amount of computation, and generates a transaction history that does not fork with overwhelmingly high probability.  This approach cryptographically selects ---in a way that is provably immune from manipulations, unpredictable until the last minute, but ultimately universally clear--- a set of verifiers in charge of constructing a block of valid transactions.  This approach applies to any way of implementing a shared ledger via a tamper-proof sequence of blocks, including traditional blockchains. This paper also presents more efficient alternatives to blockchains, which may be of independent interest.
Algorand significantly enhances all applications based on a public ledger: payments, smart contracts, stock settlement, etc.  But, for concreteness, we shall describe it only as a money platform. Micali seems to have substantially improved the Bitcoin blockchain for public ledger purposes.
What do you think?

@_date: 2017-02-26 13:16:53
@_author: Henry Baker 
@_subject: [Cryptography] Schneier's Internet Security Agency - bad idea 
When I was growing up, there was a daily newspaper cartoon entitled "There oughta be a law!"
However, after I grew up, studied computer science, and finally understood *undecidability*, I realized that a "legal"/"lawful" solution to every problem was logically and mathematically impossible.
Here we are 80+ years after undecidability raised its ugly head and destroyed the "Age of Enlightenment"/"Age of Reason", and yet no legal scholars, lawyers, economists, or public policy people living today have even heard of this concept of undecidability, much less understand that it renders most of their efforts more futile than Sisyphus's.
The Clockwork Economy/Clockwork Legal System -- in which bright lines separate good from evil -- has been replaced by a mishmash of hills & valleys separated by fractal "boundaries" which I defy you to characterize in a finite lawbook.
I'm embarrassed for Bruce Schneier who certainly should know better; perhaps this is a forgivable error which he will correct soon enough.  If not, I should begin to wonder if he's been taken over to the dark side (aka the intel community), where fake news, disinformation and extra-Constitutional excursions are considered honorable pursuits.
The bottom line: if you're attempting to oversee/regulate a Turing-complete system (i.e., essentially *every* societal system), adding additional "oversight" turtles to your toppling stack of existing turtles won't help a bit.  I.e., if a Halting Problem oracle doesn't exist, you can write all the laws you wish about creating a Halting Problem Agency ("oracle"), but that won't make such an oracle magically exist.
Even Abraham Lincoln understood that giving some impossible concept a name doesn't make it exist:
When asked "How many legs does a dog have if you call his tail a leg?", Lincoln answered, "Four.  Saying that a tail is a leg doesn't make it a leg."
Schneier should contemplate Gerald Ford's famous remark: "A government big enough to give you everything you want is a government big enough to take from you everything you have."
Benjamin Franklin understood that the pursuit of safety/security was a bottomless pit/hopeless exercise: "Those who would give up essential Liberty, to purchase a little temporary Safety, deserve neither Liberty nor Safety".

@_date: 2017-02-27 07:35:48
@_author: Henry Baker 
@_subject: [Cryptography] Schneier's Internet Security Agency - bad idea 
(I'm very sorry that you never got beyond Hofstadter, which is now incredibly dated; what he says is correct from the perspective of computer science, but he didn't do a good enough job explaining the implications for non-CS people.  See Propublica link below.)
You (and OW Holmes, whose views on eugenics [Buck v Bell] led directly to the Holocaust) are so, so, naive!
What you are describing is the rule of *men* (and women), not the rule of *law*.
Replacing the precise operations of computers with the "black box" approach of the administrative state doesn't improve things one bit, and certainly doesn't fix the undecidability problem; it merely obscures the operation of the law so that it becomes too difficult/expensive to challenge it.  But just as security through obscurity doesn't work, neither does justice through obscurity work.
Propublica has been exploring at length the nightmare that this muddled legal thinking has produced:

@_date: 2017-02-27 07:57:45
@_author: Henry Baker 
@_subject: [Cryptography] More efficient block-chain ledger: Micali's 
mail.com>
Here's Micali's Spring 2017 course on Github -- perhaps protected by SHA1? :-)
Unfortunately, this version of 6.892 is not listed as part of MIT's Open Courseware, and so there is no video (that I could find) of the lectures.

@_date: 2017-02-27 13:14:52
@_author: Henry Baker 
@_subject: [Cryptography] Schneier's Internet Security Agency - bad idea 
It's going to get a whole lot worse.  My (relatively cheap) non-Nest thermostat keeps begging me to hook it up to the Internet for *my* "convenience".
How hard is it for a wifi device to search for all SSID's (including hidden ones) & find one that is either open already or WEP-protected, and then trivially break it?  BTW, it does NO GOOD to block such a device from YOUR own wifi network, because there are perhaps 5-15 wifi networks IN YOUR NEIGHBORHOOD that ARE accessible.
Virtually every device you purchase these days is wireless-enabled -- "dumb" TV's, refrigerators, washing machines (!?!).  Even if/when such a device doesn't automatically attempt to "call home" on the Internet, it advertises an SSID itself, and becomes instantly hackable by anyone within wireless distance.
God knows what will happen when these very low cost Verizon/ATT/etc cellular-connected IoT devices become ubiquitous, and where the device manufacturer pays for the cellular connection.  I don't think there is any law that prohibits such a device from calling home w/o your permission.  In such a situation, jamming devices will become *essential*.

@_date: 2017-02-27 17:36:57
@_author: Henry Baker 
@_subject: [Cryptography] jammers, nor not 
I'm not a lawyer, but I understand that there are always implicit exceptions to every law -- e.g., to save a life (perhaps your own), etc.  Remember, the prosecution still has to convince a judge and a jury, so if the situation is egregious enough, a jury may well nullify.
I'm expecting consumer drones to test jury nullification very soon.  I suspect that if someone takes a shotgun to their neighbor's peeping drone, most juries will stand up and applaud, so long as the buckshot doesn't land in their yard.  I notice that DA's are currently a little shy about prosecuting some drone cases, because they don't want any of these laws ignored by juries or overturned by judges.

@_date: 2017-02-28 07:05:32
@_author: Henry Baker 
@_subject: [Cryptography] jammers, nor not 
How am I going to watch my TV, brush my teeth, and wash my clothes if everything is wrapped in aluminium foil?
Perhaps it's time to start a new housing development: "Faraday Flats".
When I lived in Los Angeles in the early 1980's, I met someone whose business was building Faraday Cage rooms for several million dollars a pop.  They had the usual suspect customers: Lockheed, Northrup, etc., as well as the tin-foil hat conspiracy types.  I didn't realize that the tin-foil types had that much money, but I was reminded that I was in Hollywood.

@_date: 2017-02-28 07:09:45
@_author: Henry Baker 
@_subject: [Cryptography] Schneier's Internet Security Agency - bad idea 
mail.com>
I believe that ATT, Verizon, Comcast wifi routers all now default to providing an "open" wifi SSID for ATT, Verizon, Comcast customers, respectively.
So it wouldn't be hard for a sleazy Vizio to make deals with these even sleazier ISP's for easy/legal access to the Internet.

@_date: 2017-02-28 17:51:26
@_author: Henry Baker 
@_subject: [Cryptography] jammers, nor not 
"Why can't the Board Rooms of the too-big-to-fail banks be Faraday Cages?"
"Because the parole ankle bracelets won't work there."
  :-)

@_date: 2017-01-08 11:27:18
@_author: Henry Baker 
@_subject: [Cryptography] 33C3: cash :-) attacks ! 
FYI --
(55 mins; 327 MBytes)
"What could possibly go wrong with ?
Side effects include side-channel attacks and bypassing kernel ASLR"
Clmentine Maurice and Moritz Lipp "Hardware is often considered as an abstract layer that behaves correctly, just executing instructions and outputting a result.  However, the internal state of the hardware leaks information about the programs that are executing.  In this talk, we focus on how to extract information from the execution of simple x86 instructions that do not require any privileges.  Beyond classical cache-based side-channel attacks, we demonstrate how to perform cache attacks without a single memory access, as well as how to bypass kernel ASLR.  This talk does not require any knowledge about assembly.  We promise."
Abandon hope, all ye who cache here!
Why care about encryption, when you have devastating attacks such as these?
These new timing attacks enable 500KBytes/sec covert channels between "independent" virtual machines, reverse engineer virtual memory -> physical memory maps, etc.
You can create a completely benign-looking app that can be downloaded into your Android phone, but which can still snoop on your typing.  Your Signal app can be as clever as it pleases, but that "calculator" app or that "weather" app might still read everything that you type.  If the same organization designs both a picture organizing app (having only permissions for accessing pictures) and an app that requires access to the Internet (but not your pictures), then they can covertly communicate to put all of your sexy selfies on the Internet.
I.e., there are NO benign apps!
Are there any *software* countermeasures for these types of attacks, or do we have to wait for the next generation of hardware?  Even if we do wait, do the HW people even know how to build HW that doesn't have these types of vulnerabilities?
Do we need to have completely separate caches for each thread and/or process?
This problem reminds me very much of the vulnerabilities introduced through *data compression*; duplicate portions of a message can be detected because the compressed message is shorter than if there were no duplicated portions.

@_date: 2017-01-09 16:56:40
@_author: Henry Baker 
@_subject: [Cryptography] 33C3: cash :-) attacks ! 
Some HW ideas:
There used to be chips for "real-time" applications, in which a
high-priority process could *lock down* a portion of the cache for its
*exclusive* use.
At some cost in performance and/or chip area, the operating system could
allocate private caches for different processes.
Multiprocessor architectures used to be moving towards "shared nothing"
memory hierarchies, so that they could maximize the number of distinct
HW processors and minimize the contention.
But then the reliance on C-language and "threads" made shared memory
more attractive.
It may be time to move away from threads & shared memory and back to
shared-nothing architectures, now that we have another strong incentive
(minimizing timing attacks) to do so.
WRT the short term, we have to attack "compressed cycles" with
strategies similar to those that encryption-after-compression
has done to minimize timing (due to cycle compression).
There may be more exotic SW techniques more akin to oblivious
RAM (ORAM), but notice that ORAM's & caches don't mix very
well (except to the extent that the cache can speed up the
ORAM shuffling.
I'm had an idea at the back of my mind for a long time which
generalizes the ORAM idea by fitting the access statistics of
your particular program into the access statistics of my
program.  In other words, you hide the access statistics of
your program by spoofing the access statistics of another
(my) program.  Yes, performance is degraded to the extent
that the masking statistics aren't ideal for executing your
program, but that seems to be inevitable.
Here's an analogy: a city has a scheduled transportation
system involving buses and subways of given capacity.  A
covert attacker wants to move his people into various
places in the city, but without raising any suspicion.
If they were to bring their own cars, they would disrupt
the traffic in a noticeable way.  However, if they all
used the existing transportation system and stayed within
the capacity constraints, there would be no effect on
overall traffic.  Of course, it is essential that the
timing of the buses not be affected by whether the bus
is empty or full, else the bus will change its schedule.
But this is a good analogy with a computer's datapaths,
which have predetermined timings and capacities, and
most operations in modern clocked logic are not affected
by the detailed content of the data on which they

@_date: 2017-01-13 09:34:40
@_author: Henry Baker 
@_subject: [Cryptography] Blockchain to Secure Nuclear Weapons? 
Hmmm...  What is the SHA3-1024 (Dean Wormer's "double secret" version of SHA3) hash for '00000000' ??  [0]
[0] 'Secret' Nuclear Missile Launch Code During Cold War Was '00000000'
12/05/2013 02:13 pm ET | Updated Jan 23, 2014

@_date: 2017-01-14 06:51:45
@_author: Henry Baker 
@_subject: [Cryptography] ZK meeting scheduling protocol? 
As most of you already know, Microsoft Outlook provides some protocols for helping to schedule meetings via email.
Has anyone developed a zero knowledge protocol for such scheduling?
Basically, an invite goes out to N different peoples' computers to initiate a protocol to find the earliest common date in all of their calendars which is free.  The computers then communicate amongst themselves to try to find such a date.  Everyone is aware of the other N-1 people invited to the meeting, and is able to communicate with them directly.
At the end of the protocol, either no such common date is available -- ever -- or a common date is secured.  Everyone then knows the date.  However, no one ever learns (at least from the protocol itself) which non-selected dates matched on any subset of the peoples' calendars.  Thus, for example, no one can figure out who is the busiest (or least busy) person by studying all the messages from the protocol.
I guess the initial warmup problem would be to try to do this for exactly 2 people.
Any ideas?
(This is not a homework problem, at least not for any course I'm taking!)

@_date: 2017-01-20 07:44:04
@_author: Henry Baker 
@_subject: [Cryptography] ProtonMail accessible via Tor onion site 
FYI --
ProtonMail adds Tor onion site to fight risk of state censorship
Posted yesterday by Natasha Lomas (
Swiss-based PGP end-to-end encrypted email provider, ProtonMail, ***now has an onion address,*** allowing users to access its service via a direct connection to the Tor anonymizing network  in what it describes as an active measure aimed at defending against state-sponsored censorship.
Users of the Tor browser can now reach ProtonMail directly using its new onion address:
Users accessing ProtonMail via Tor will have their connections anonymized  meaning the email service wont be able to see (and thus couldnt be forced to divulge) their true IP address.
The onion site also provides ***end-to-end authentication,*** which ProtonMail says helps mitigate some of the weaknesses with the existing Certificate Authority (CA) system thats used across much of the Internet  pointing out that many CAs are trusted by default and some can be under direct government control.  For this reason it's also using an onion site with HTTPS only  also as a backup in case Tor itself is ever compromised.
"If someday Tor were to be compromised, enforcing HTTPS adds another layer of security for the end user.  Similarly, Tor also provides security in case HTTPS is compromised.  The notion of HTTPS being compromised is one that we take seriously, considering that there are hundreds of CAs that are trusted by default, with many of them under direct government control in high risk countries," it writes in a blog about the launch.
"Thus, by using our onion site, your emails are protected by three layers of end-to-end encryption, theres Tors encryption on the outer layer, HTTPS in the middle layer, and PGP as the final layer of defense for the emails themselves."

@_date: 2017-01-22 06:32:35
@_author: Henry Baker 
@_subject: [Cryptography] Oracle discovers the 1990s in crypto 
It's always good to have a pre-arranged excuse for being hacked, but one that isn't tooo obvious.
It's also a d**n shame that Oracle has allowed Java to become such a security joke.  After all, Java was the first language to attempt to get serious about controlling module loading and stack manipulation.  Some of my CS friends are rightfully pleased with themselves for being so prescient, but horrified about what a joke Java became.

@_date: 2017-01-24 06:44:46
@_author: Henry Baker 
@_subject: [Cryptography] Using AI to identify state secrets. 
It's probably already *far worse* than this article would indicate.
The US govt simply can't keep up with classification/declassification
anymore, and I suspect that it's *already* using "AI" -- perhaps even
Google/Siri/Alexa technology -- for such tasks.
Remember in the 1920's when all of the trends projected that 100% of
the workforce by the 1950's would be telephone operators?  Well, if
the govt actually did what it was supposed to do, 100% of the govt
employees *today* would be reading & declassifying documents.
But the risks should be obvious to those on this list: massive
leakage of information & secrets.  We have a huge corpus of plaintext
to use to "query" an AI (neural net or other) bot, and using enough
*unclassified* probes, we can isolate words, phrases, etc., that the
AI bot considers "secret".  Assuming that the AI bot has been trained
on highly classified info, it should be relatively easy to probe the
bot until it gives up most of its secrets.
The conversation with the AI bot would sound very much like the
conversation Senator Ron Wyden and Representative Justin Amash had
with our recent DNI, but it could be automated to work at considerably
higher speed.
Now, it's not out of the question that Google/Siri/etc. may *already*
be used for this purpose, so it may be time for a researcher to start
querying Google & Siri to see what they know.  Perhaps Russian &
Chinese researchers are *already* performing such queries.
With Alexa finding itself in heavy use around the DC & San Antonio
areas, Alexa may already be a prime target of Russian & Chinese hackers.

@_date: 2017-01-26 11:00:26
@_author: Henry Baker 
@_subject: [Cryptography] HSM's to be required for Code Signing Certificates 
FYI --
Leading Certificate Authorities and Microsoft Introduce New Standards to Protect Consumers Online
The CASC's Minimum Requirements for Code Signing Certificates enables a common vetting process for all CAs
San Francisco--December 8, 2016 -- the Certificate Authority Security Council (CASC), an advocacy group committed to the advancement web security, today announced the Code Signing Working Group has released new Minimum Requirements for Code Signing for use by all Certificate Authorities (CA).  These requirements represent the first-ever standardized code signing guidelines.  Code signing is the method of using a certificate-based digital signature to sign executables and scripts in order to verify the author's identity and ensure that the code has not been changed or corrupted.  Helping to verify software authenticity and avoid downloading malware and other malicious software is critical to protecting consumers' online interactions.  Microsoft is the first applications software vendor to adopt these guidelines, with others expected to follow.
The Code Signing Working Group was created as a voluntary group of CAs, Internet browser software vendors, and suppliers of other applications that use X.509 v.3 digital certificates for SSL/TLS and code signing.  Once the code signing draft was completed, it was endorsed by the CA Security Council members and others.  The CA Security Council website is now the repository for the document and the group will continue to work with others in the industry to ensure it is kept up to date.
"Previously, there were no standards, which meant that if one CA rejected a company's application, that company could submit the same application to a different CA," said Dean J. Coclin, Senior Director, Business Development, Symantec.  "The Minimum Requirements for Code Signing will improve all CAs' ability to identify the publishers and authenticate that the code is unchanged."
The guidelines include several new features that will help businesses defend their IT systems and information stores from cyber-attacks, including:
* Stronger protection for private keys: The best practice will be to use a ***FIPS 140-2 Level 2 HSM*** or equivalent.  Studies show that code signing attacks are split evenly between issuing to bad publishers and issuing to good publishers that unknowingly allow their keys to be compromised.  That enables an attacker to sign malware stating it was published by a legitimate company.  Therefore, companies must either ***store keys in hardware*** they keep on premise hardware, or in a new secure cloud-based code signing cloud-based service.
* Certificate revocation: Most likely, a revocation will be requested by a malware researcher or an application software supplier like Microsoft, if they discover users of their software may be installing suspect code or malware.  After a CA receives request, it must either revoke the certificate within two days, or alert the requestor that it has launched an investigation.
* Improved code signatures time-stamping: CAs must now provide a time-stamping authority (TSA) and specifies the requirements for the TSA and the time-stamping certificates.  Application software suppliers are encouraged to allow code signatures to stay valid for the length of the period of the time-stamp certificate. The standard allows for 135-month time-stamping certificates.
Microsoft will require CAs that issue code signing certificates for Windows platforms must adhere to these guidelines beginning on February 1, 2017.
"The combined versions of Microsoft's Windows platform represent nearly 90 percent of the desktop operating system market share, so its decision to mandate that CAs follow the new requirements is significant," said Jeremy Rowley, Executive Vice President of Emerging Markets, DigiCert.  "We expect Microsoft will serve as the catalyst for other application software suppliers to do the same."
"Microsoft is committed to continuously improving the security of our products and services.  These new baseline requirements will further our goal by ensuring that our certificate authority partners follow a standard set of rules when issuing certificates to software developers," said Jody Cloutier, Senior Security Program Manager, Microsoft Cryptographic Ecosystem.
Code Signing Endorsement Code Signing White Paper

@_date: 2017-01-27 08:49:55
@_author: Henry Baker 
@_subject: [Cryptography] HSM's to be required for Code Signing 
So, is this another one of those mumbo jumbo witch doctor "security theater" pageants that impress the press (and later, the court judges) ??

@_date: 2017-01-27 12:37:54
@_author: Henry Baker 
@_subject: [Cryptography] Politicos Embrace Encrypted-Messaging App 'Signal' 
FYI --
Political World Embraces Encrypted-Messaging App Signal Amid Fears of Hacking
Aides close to President Donald Trump, Hillary Clinton use app as memory of Wikileaks scandal lingers
Former New York City Mayor Rudy Giuliani says he has had the Signal app for a few weeks.  The app, which lets users send encrypted messages, is gaining popularity in the political world amid fears about hacking and surveillance.
By Mara Gay
Updated Jan. 26, 2017 11:57 p.m. ET
Signal, a smartphone app that allows users to send encrypted messages, is gaining popularity in the political world amid rising fears about hacking and surveillance in the wake of a tumultuous election year.
Political aides close to President Donald Trump, former President Barack Obama and former Secretary of State Hillary Clinton are users.  So are some close to New York Gov. Andrew Cuomo and New York City Mayor Bill de Blasio.
Some say the legion of political types has a singular goal to avoid a repeat of the WikiLeaks scandal, in which the emails of Mrs. Clinton and her closest allies were dumped onto the internet.
"Everybody learned the lessons of the Clinton campaign when it came to communicating about sensitive issues over email," one former senior aide to Mr. Obama said.  "No one wants to see that happen again."
Roger Stone, a longtime adviser to Mr. Trump, is on the app.
"I learned my lesson when my email got hacked in September.  It was hell," Mr. Stone said in an email.  He said 30 years of contacts were destroyed and his personal and business bank accounts were compromised.
"I realized I needed a safer encrypted way to communicate--and NO I have never communicated with any Russians on Signal."
Built by the San Francisco-based Open Whisper Systems, Signal is based on end-to-end encryption in which only those in direct communication can read the messages.
Signal has seen a roughly 400% increase in downloads since Election Day last November, said founder Moxie Marlinspike.  He declined to say how many people use the app.
"It's funny," Mr. Marlinspike said.  "In the past, people asked, 'Are you worried terrorists are using it?'  Now they're asking about politicians."
Former Mayor Rudy Giuliani said he has had the app for a few weeks.  "One of my cybersecurity experts downloaded it for me," Mr. Giuliani said.
Current and former senior aides to Mr. Cuomo also have the app.  So do City Council members Daniel Garodnick, David Greenfield and Corey Johnson.  Other users are Howard Wolfson and Marc La Vorgna, aides to former Mayor Michael Bloomberg.
Nearly a dozen officials or aides close to Mr. de Blasio are on the app, including press secretary Eric Phillips; Nisha Agarwal, who serves as commissioner for the mayor's Office of Immigrant Affairs; and Dan Levitan, a political adviser.
Dick Dadey, executive director of the Citizens Union, an ethics group, said he understood why politicians and their aides would seek to avoid a repeat of the WikiLeaks scandal.  But he said that by using apps like Signal, they also could be keeping conversations private that should be made public under freedom of information laws.
"There are consequences to our democracy when public officials or their aides are resorting to keeping their conversations private in this way," Mr. Dadey said.
Mike Vilensky contributed to this article.
Write to Mara Gay at mara.gay at wsj.com
"But {Dick Dadey, ED of Citizens Union] said that by using apps like Signal, they also could be keeping conversations private that should be made public under freedom of information laws."
LOL: "Former Mayor Rudy Giuliani said he has had the app for a few weeks.  'One of my [400 pound and/or teenage ?] cybersecurity experts downloaded it for me,' Mr. Giuliani said."
What's good for the goose is good for the gander.

@_date: 2017-01-30 17:19:20
@_author: Henry Baker 
@_subject: [Cryptography] Great IoS quote from LCA 2017 
Sadly, after touring the exhibits at CES2017 this month, too many of the "embedded systems" work just fine; their biggest problem is *whom they work for*, because it isn't ordinary consumers like you and me.
I own a relatively small single family home; why on Earth would I (or anyone else, for that matter) need to have second-by-second information about my natural gas consumption (queue recent 'gaslighting' thread) ?
Who in their right mind would allow a Bluetooth-controlled "smart pillow" -- complete with an always-on microphone -- to upload all this audio data to "the cloud" to tell them that they snore at night ?
The following is a true story; I can supply you with all of the details if you wish:
One CES2017 booth had a Bluetooth-controlled vibrator.  By itself, this is unremarkable -- such devices have been on the market for several years.  However, this particular company took things to a whole new level: a Strava-type *social network* on which one can not only upload their own activities for leaderboards, *but also download midi-like sequences from other Bluetooth vibrator users*.  Apparently, music hasn't the only charms to soothe the savage beast!
Forget privacy; we now have an exhibitionist society where the lack of privacy has become a feature, not a bug.  Perhaps this is the only way to defuse surveillance in the post-Snowden world: everyone acts so outrageous that the only people who want to hide actually have nothing (unusual) to hide.

@_date: 2017-07-09 12:17:24
@_author: Henry Baker 
@_subject: [Cryptography] Attackers will always win, and it's getting worse! 
Here's the problem:
User crypto software (the "attacked") has to run in such a way that:
a.  It produces the correct answer; and
b.  It does NOT LEAK SECRET INFORMATION through side-channels -- e.g., timing/power/etc.
Let's assume as given that the crypto math itself is good & strong.
Now, attacker systems don't have to worry about side-channel leakage, assuming that they're running in some Tempested datacenter in the wilds of Utah or Maryland.
So the problem is: the ratio of the cost ($ & latency) of user crypto software is getting worse relative to the cost of attacking software, so that the attacker's cost/performance advantage is improving over time.
More to worry about: suppose the NSA wants to create a "backdoorless backdoor", which allows NOBUS to efficiently attack a system.  What better way to do this, than to increase the advantage of "side-channel-careless" code over "side-channel-secure" code?  A little NSL leaning on the chip vendor (Intel/nVidia/AMD/ARM) and the deed is done.
For example, many (most?) arithmetic "optimizations" (both HW&SW) open up timing and/or power side-channels.  Putting such "optimizations" into chips provides an easy cover story for the inclusion of these side-channels, but each such "optimization" requires far more code complexity and latency by the attacked to defeat the side-channel than the profit on the original "optimization".  Thus, all of the advantage of these "optimizations" go to the attacker rather than the attacked.
Any thoughts on how to better engineer side-channel-secure systems?

@_date: 2017-07-11 17:02:41
@_author: Henry Baker 
@_subject: [Cryptography] Creepy correlation noted 
While this note doesn't discuss encryption, per se, perhaps there is some encryption technique that could be used to solve this type of surveillance.
I've been noticing a creepy correlation between *spam phone calls* on my wireline phone and my working at my home computer.
No, I don't believe I've been hacked, unless you consider surveillance by your own ISP to be hacking.
I think that my ISP is noticing when my Internet connection is active, and selling that information to 3rd parties who utilize this information make spam calls (among other violations of my privacy).  My ISP doesn't have to decrypt my Internet connection to know that it is active; it just notices the activity.
I've noticed this because I don't receive such junk calls on my answering machine when I'm not at home working on my computer.
I suppose that I should run some Linux 'cron' tests to check out this theory.  This would get me such spam calls when cron runs, even when I'm not home.
But what I'm really after is the reverse -- if I have to get such spam calls (I'm already on the do not call registry -- what a joke that is!), then I'd rather they go to voice mail when I'm NOT here.
Any ideas?

@_date: 2017-07-12 17:14:24
@_author: Henry Baker 
@_subject: [Cryptography] Creepy correlation noted 
Actually, it's even more creepy than I described:
I screen ALL of my calls.
Almost no messages are left on my answering machine when I'm not here;
messages are almost always left on my answering machine when I'm here.
So unless someone across the street is reporting my presence in real
time, I'm pretty sure that my ISP is the culprit.
Re "donut call list": I suspect the only reason for the existence of
this list is to gather *known good numbers* for politicians themselves
to call, as they have (surprise, surprise!) exempted themselves from
"do not" part of the "do not call" list.
The politicians have also *timed out* the "donut call list", so that
unless you keep adding yourself back on the list, you'll eventually
be flooded with calls.  Note that this is perhaps one of the 0.001%
of regulations that actually time out; nearly every other regulation
since 1776 still appears to be in effect.

@_date: 2017-07-14 09:21:28
@_author: Henry Baker 
@_subject: [Cryptography] Defeating timing attacks 
[Follow-up on attackers always win.]
Consider the following theoretical exercise:
Suppose that a computer's instruction set was *purposely designed* to leak as much secret information through a timing side-channel as possible.  E.g., *asynchronous logic* from the 1960's/1970's might qualify, as the timing of essentially every operation is data-dependent!
Is there any way for a *compiler* to generate code to generate enough deliberate jitter to mask the leaked information?
What if the compiler had additional "instructions" which simply generated randomly selected delays?  What kinds of probability distribution functions could be useful to perform such masking?
Is there any way for an *operating system* to generate enough timing jitter to mask the leaked information?
BTW, "spread spectrum clocking" is the deliberate introduction of jitter into clock signals to minimize narrow-band radio interference from digital devices; without such measures, we wouldn't be allowed to take our digital devices on airplanes due to interference with the airplane's own electronic equipment.
Traditional spread spectrum clocking uses relatively simple pseudo-random sequences; defeating intelligent timing attackers would require crypto-quality pseudo-random sequences, at the very least.

@_date: 2017-07-14 09:38:11
@_author: Henry Baker 
@_subject: [Cryptography] Creepy correlation noted 
Even creepier: the correlation seems to also extend to my cellphone, which might provide additional evidence for the culprit.
BTW, my email is well-known, and my land-line phone number is published, so any marketeer has easy access to both.
Obviously, my cellphone carrier knows where I am, so it would be trivial for them to sell my location.
Google usually knows where I am, because it can correlate my searches with my IP addresses.
My TV provider knows when I'm at home, because settop boxes let them know every TV remote click that I make.
My electricity provider knows when I'm home, because they just installed a 'smart meter' precisely for the purpose of spying on me.
My gas provider knows when I'm home, because they also installed a 'smart meter'.
Most of my cellphone apps know where I am, and they all sell every bit of information that they can get their hands on.
So yes, I'm saying that someone is marketing my location & timing information so as to better target scam phone calls, among other things.
It should be possible to use the "internet of things" to start selectively spoofing ("gaslighting") these various channels to find the more precise correlations.

@_date: 2017-07-14 17:59:47
@_author: Henry Baker 
@_subject: [Cryptography] Defeating timing attacks 
You could *literally* take "sequences that could be[^H^H^H^H^H^H^H^H
ACTUALLY ARE] found in pretty much any program": this is now called
"return-oriented programming" (ROP).
"In this technique, an attacker gains control of the call stack to hijack program control flow and then executes carefully chosen machine instruction sequences that are ***already present*** in the machine's memory, called "gadgets".  Each gadget typically ends in a return instruction and is located in a subroutine within the existing program and/or shared library code.  Chained together, these gadgets allow an attacker to perform arbitrary operations on a machine employing defenses that thwart simpler attacks."
Perhaps ROP should become a standard technique for crypto codes.  Perhaps ROP can be used for something good, rather than malware.  OpenSSL, are you listening?

@_date: 2017-07-15 06:11:12
@_author: Henry Baker 
@_subject: [Cryptography] Defeating timing attacks 
What kind of a slowdown are we talking about here?
1X, 10X, 100X, 1000X ?

@_date: 2017-07-16 13:58:10
@_author: Henry Baker 
@_subject: [Cryptography] Radiolab podcast: Zcash parameter generation 
FYI --
47.5 minutes, 43.5 MBytes.
The Ceremony
July 14, 2017, 8:00 AM
Today, paranoia sets in: we head to The Ceremony, the top-secret, three-day launch of a new currency, wizards and math included. Halfway through, something strange happens.
Radiolab does its thing re the Zcash parameter generation 'Ceremony'.

@_date: 2017-07-16 20:22:54
@_author: Henry Baker 
@_subject: [Cryptography] SW requirements to block timing side-channel attacks 
Ok, suppose we take a cue from the design of some microcodes, which have a "time duration" field to specify how many minor clock cycles this microcode instruction should take to allow all the buses to "settle" before moving on.
We can incorporate such a *duration* parameter in each call to a crypto routine; the crypto routine has to process this parameter *first*, so as not to allow the contents of any other parameter to affect overall timing.  The CPU's real-time clock is read, and the parameter is added to the value of the real-time clock to set an alarm clock to indicate when the crypto routine is to return.  The crypto routine is executed, and a barrier synchronization then waits for the previously computed alarm clock time to arrive before the crypto routine is allowed to return.
Obviously, we have to provide sufficient margin on the real-time clock calculation so that the chances of the crypto process not having been completed is completely negligible -- certainly negligible compared with any networking collision and/or error probability.
(We could -- if necessary -- also calculate a *power budget* for the crypto process; the idea being to always utilize exactly the same power dissipation regardless of the contents of the secret parameters.  The CPU would then needs to have a "shivering" NOP instruction whose only purpose is to quickly burn a precise amount of power.)
But we have other problems: should the crypto process allow interrupts?  I say no, because any interrupts would flush various registers and caches, which might provide other side-channels.  But what if this crypto code is running inside a virtual machine/container?  Ditto.  The virtual machine/container needs to also provide for non-interruptible code; the crypto code might have to provide some "real-time clock logging" to check to see if it is being interrupted; if so, it needs to bail on its calculations and tell its caller that it may have been compromised.
In days of yore, on single-core, single-threaded machines, the idea of running a program with all interrupts disabled would have been anathema.  However, on today's processors with 4-8 or more cores, it's completely reasonable to pull one or more cores out of interrupt-service duty if there is important business to attend to, and crypto processes are just that "more important business".
But what about shared caches?  Here's where the crypto process has to abide by some rules.  It must grab whatever cache lines it needs and lock them down for the duration of its calculations.  If the crypto process can't lock down its resources, then it cannot assume that it will be able to complete its task on time, and any variations in the timing of re-acquiring those resources can (and have) been used as a side-channel to extract secret information.  So the crypto code itself must be content with using *only* resources to which it has acquired (and can test for) exclusive access for the duration of its calculation.
If all of these issues sound like those that come up in *real-time* control systems, you're absolutely right!
But that's actually *good* news, since many IoT devices must simultaneously manipulate hundreds/thousands of real-time processes/threads, and their operating systems tend to be already organized to deal with real-time demands.  Just like in real-time systems, where *faster is not necessarily better* (*predictable* timing is better), the same is true of crypto codes, where *constant* timing is better.  So such IoT devices may actually be in a better position to foil timing side-channels than traditional desktop/laptop/cellphone operating systems.

@_date: 2017-07-18 07:02:55
@_author: Henry Baker 
@_subject: [Cryptography] Raspberry Pi-like FPGA ?? 
Does anyone sell a cheap, easy-to-experiment with, FPGA?
Ideally, something small, powered by USB, perhaps with a
standard ARM-like (or MIPS-like) CPU to fire it up.
What sort of SW tools are available -- e.g., C-like
compilers, emulators, etc. ?
If standard CPU chips won't cut it for crypto, perhaps
it's time for us sheeple to start experimenting with FPGA's.

@_date: 2017-03-01 10:29:19
@_author: Henry Baker 
@_subject: [Cryptography] On New York's new "Cybersecurity Requirements 
This sort of dance between corporations & govts is completely routine.
Acme Corporation makes a product, but it degrades in the rain.  So the Acme lobbyist gets the govt to fund more weather satellites to better predict the rain.
Unfortunately, customers are still unhappy with Acme, because sooner or later it rains & ruins the Acme products.
Not wanting to be sued, Acme gets its lobbyists to get a law passed which declares rain to be "an act of God", and therefore absolves Acme of any liability when its products fail in the rain.
Unfortunately, customers are *still* unhappy, so the Acme lobbyist proposes that the govt set up a govt-funded insurance scheme to reimburse customers whose Acme products fail in the rain.
Watching all of this, an entrepreneurial company Newco develops a product that competes with Acme, but it doesn't degrade in the rain.
All of the Congresspersons who got elected with Acme lobbyist money come down on Newco like a ton of bricks, regulating the industry in such a way that Newco's compliance costs exceed its product costs by 10x, while Acme easily meets all regulatory requirements.
Bottom line: beware of lobbyists bearing grafts.

@_date: 2017-03-02 12:54:14
@_author: Henry Baker 
@_subject: [Cryptography] Bluetooth "smart condom" w/uUSB port 
A British company claims to have created the worlds first "smart condom" which rates blokes performances...
And if you're concerned about your secrets getting out, the Nottingham-based company says that all info will be kept anonymous.  [Using Tor ?]
Users "will have the option to share their recent data with friends, or, indeed the world."  [Automatic output to Strava can be disabled by the shy ?]
In a similar way to other health monitoring devices, it will use nano-chip and bluetooth technology to relay the data to a smartphone app.
Over 90,000 people have already pre-ordered the product which will be released later this year at the price of 59.99.
It has an integrated micro USB port so it can be recharged, with each charge lasting about six to eight hours.  [Extender batteries sold separately ?]
Let me guess: This product protects you from STD's using the latest SHA-3 and AES-256 encryption technologies.  You can also use it as a USB condom while charging your smartphone.

@_date: 2017-03-03 15:53:16
@_author: Henry Baker 
@_subject: [Cryptography] Uber "Greyball"-ed city authorities w/fake screens 
FYI --
'To build a case against the company, officers ... posed as riders, opening the Uber app'
'Uber had tagged [the officer] ... based on data collected from [his/her] app ... The company then served up a fake version of the app populated with ghost cars'
'When Uber moved into a new city, [an Uber employee] ... would try to spot enforcement officers.  One technique involved drawing a digital perimeter, or "geofence," around the government offices ... people were frequently opening and closing the app ... near such locations as evidence that [they] might be associated with city agencies.  Other techniques included ... credit card information and determining whether the card was tied directly to an institution like a police credit union.'
Uber's data-sucking Android app is dangerously close to malware [updated]
By Buster Hein -- 11:22 am, November 26, 2014
Uber has been sideswiped by a ridiculous number of controversies lately, but things are about to get even worse for the ride-sharing service.  A security researcher just reverse-engineered the code of Uber's Android app and made a startling discovery: It's "literally malware."
Digging into the app's code, GironSec ( discovered the Uber app "calls home" and sends data back to Uber.  This isn't typical app data, though.  Uber has access to users' entire SMSLog even though the app never requests permission.  It also accesses call history, Wi-Fi connections used, GPS locations and every type of device ID possible.
The app even checks your neighbor's Wi-Fi and retrieves info on the router's capabilities, frequency and SSID.  News of the app's vulnerability was first posted on Hacker News with the charming intro, "TLDR: Uber's Android app is literally malware." (  One developer commenting on the revelation said there isn't "any reason for Google not to immediately remove this app from the store permanently and ban whatever developer uploaded it.  There should probably be legal action."
Here's the full list of all the data Uber is collecting through its Android app (we're checking to see if the iOS version works the same way):

@_date: 2017-03-11 07:48:12
@_author: Henry Baker 
@_subject: [Cryptography] Has formal verification actually been useful in 
It is my understanding that subsequent to the Intel "Pentium" floating point bug, Intel has always formally verified its arithmetic (at least the floating point arithmetic).
It's also pretty obvious that Intel has NOT been formally verifying its address translation or caching systems, as they have been enabling huge numbers of papers describing attacks on them.

@_date: 2017-03-12 22:41:56
@_author: Henry Baker 
@_subject: [Cryptography] USB firewall/condom HW/SW 
FYI --
The USG is a firewall for your USB ports.  It connects between your computer and an untrusted USB device, isolating the badness with an internal hardware firewall.
Why should I use a USG?
Say you just bought yourself a shiny new USB flash drive.  You rip it out of the packaging and plug it straight into your computer.  Oops, big mistake!
* Do you know who developed your flash drive's firmware?  (It's probably not the company name printed on the packaging)
* Has the firmware been audited for backdoors and malicious functionality?
* Can you confirm that the firmware running on your drive hasn't been maliciously modified during or after manufacture?
If you can't answer 'yes' to all these questions, you should not trust that shiny new flash drive.  Plugging it in gives full control of your computer to whoever wrote your drives' firmware.
The USG isolates BadUSB devices from your computer, while still passing through the data you need.  The USG's firmware is fully open and auditable, so you can trust it.  And when you use a USG, you no longer have to trust the opaque firmware of dubious origin running on every USB device you own.
Get your own USG now
Order your own USG v1.0 hardware by contacting the developer (globotron at fastmail.com).  Pricing is NZ$80 each (approx US$60) plus shipping to your country of choice.  Each device will ship fully tested and pre-loaded with the latest firmware.
Any thoughts?

@_date: 2017-03-16 07:38:37
@_author: Henry Baker 
@_subject: [Cryptography] NSA says China's supercomputing advances put US at 
FYI --
NSA, DOE say China's supercomputing advances put U.S. at risk
China's computing efforts are a threat to U.S. national security and may undermine profitable parts of the U.S. economy, a new report warns
By Patrick Thibodeau Senior Editor, Computerworld | Mar 15, 2017 3:00 AM PT Advanced computing experts at the National Security Agency and the Department of Energy are warning that China is "extremely likely" to take leadership in supercomputing as early as 2020, unless the U.S. acts quickly to increase spending.
China's supercomputing advances are not only putting national security at risk, but also U.S. leadership in high-tech manufacturing.  If China succeeds, it may "undermine profitable parts of the U.S. economy," according to a report titled U.S. Leadership in High Performance Computing by HPC technical experts at the NSA, the DOE, the National Science Foundation and other agencies. "To maintain U.S. leadership in HPC," the report says, "a surge" of U.S. "investment and action is needed to address HPC priorities." Concern about China's technical advances have been raised before by U.S. scientists and industry groups, but never in such striking terms -- or by representatives of a spy agency. The report stems from a workshop held in September that was attended by 60 people, many scientists, 40 of whom work in government, with the balance representing industry and academia.  The report, which summarizes that meeting, was just posted online. The threat from China is so acute that "absent aggressive action by the U.S. -- the U.S. will lose leadership and not control its own future in HPC," the report states.
Indeed, the report says that "assuming status quo conditions, the meeting participants believe that a change in HPC leadership was extremely likely, with only minor disagreement on the timescale; many suggested that China would be leading the U.S. as early as 2020." China supercomputing systems have been leading the Top 500 list, the global ranking of supercomputers, for several years.  But that's not a measure of supercomputing leadership alone. One workshop attendee, Paul Messina, a computer scientist and distinguished fellow at Argonne National Labs and the head of its Exascale Computing Project, sketched out the HPC leadership criteria: It means leadership in producing and using systems, as well as "first mover advantage."  It also means staying in the lead at all times.  The U.S. needs to control its HPC destiny and "can't depend on other countries to sell us what we need," he said in an email.
Something to keep in mind is that this report was written at a time when many assumed that supercomputing funding was not under threat.  The report calls for more spending while the Trump administration, along with the Republican-controlled Congress, is planning major cuts in the federal budget. "National security requires the best computing available, and loss of leadership in HPC will severely compromise our national security," the report says.  "Loss of leadership in HPC could significantly reduce the U.S. nuclear deterrence and the sophistication of our future weapons systems." Among those at the meeting was Barry Bolding, a senior vice president and chief strategy officer at supercomputer company Cray.  "I will say from Cray's view, [the report] accurately reflects the discussion of the workshop and mostly accurately reflects some of our primary concerns regarding HPC competitiveness." Steve Conway, an HPC analyst and research vice president at Hyperion Research, said the meeting "and report are important for alerting the U.S. HPC community, especially government officials, to the dangers of taking U.S. HPC leadership for granted when other nations, particularly China, are intent on seizing global leadership of the market for supercomputers." The report makes three overarching observations about China's Sunway TaihuLight system, which at 93 petaflops, is ranked first on the Top500 list of supercomputers. The TaihuLight supercomputer is "homegrown," and includes processors that were designed and fabricated in China.  The Chinese chip design "includes architectural innovations," and was designed using "a true co-design approach" where the applications are tuned to take advantage of the chip design, the report said. The machine "is not a stunt," the report notes, meaning China didn't develop this system for bragging rights.  The machine "is being used for cutting edge research," and three of the six finalists for the Gordon Bell Prize, the top research award in HPC, were the result of Chinese efforts. The report offers something particularly insightful about China's motivations. "Meeting participants, especially those from industry, noted that it can be easy for Americans to draw the wrong conclusions about what HPC investments by China mean  without considering China's motivations," the report states. "These participants stressed that their personal interactions with Chinese researchers and at supercomputing centers showed a mindset where computing is first and foremost a strategic capability for improving the country; for pulling a billion people out of poverty; for supporting companies that are looking to build better products, or bridges, or rail networks; for transitioning away from a role as a low-cost manufacturer for the world; for enabling the economy to move from 'Made in China' to 'Made by China,' " the report states. But it also pointed out that the computer codes developed for industry, "are good proxies for the tools needed to design many different weapons systems." Warnings like these from disinterested companies like Cray seem to appear every year like clockwork at about the same time NPR does their annual fund drive.
Perhaps the NSA should be "funded" like SETI: everyone downloads a little "screen saver" program that cracks Russian passwords for the NSA whenever we leave our computers to get a cup of coffee.
Or the massively parallel "neural network" GPU's in our self-driving Tesla's can crack SHA-3 hashes whenever we've stopped at a red light.
Or we can donate our Nest thermostats to a NSA-run botnet that attacks Iran and North Korea while we sleep.
We saved toothpaste tubes for their tin and old newspapers for their cellulose during WWII to support the war; these modest modern efforts would be extremely helpful, and help America become great again.

@_date: 2017-03-17 14:32:43
@_author: Henry Baker 
@_subject: [Cryptography] NSA says China's supercomputing advances put US 
funding programs in Committee Chairmens' districts -- e.g., Lockheed-Martin figured out how to spread out the gravy into every important Representatives' and Senators' districts and states.
As every NASA scientist and engineer will tell you, the worst environment in the Universe isn't the hard radiation and single-digit-Kelvin temperatures of outer space, but that inside the Capitol building.
BTW, why does NSA need floating point arithmetic?  E.g., why do they need a flop-house?

@_date: 2017-03-19 10:15:10
@_author: Henry Baker 
@_subject: [Cryptography] Crypto best practices 
OK, I'll bite.
Is there a comprehensive white paper (or even better, a long YouTube video) that explains the rationale & architecture of the "Signal" app?
I'm particularly interested in the rationale -- e.g., what guided the various decisions that were made.
Clearly, Signal has learned a lot from Snowden/CIA/etc., so it should be a pretty decent case study of what to do and what not to do.

@_date: 2017-03-24 07:28:53
@_author: Henry Baker 
@_subject: [Cryptography] Google distrusts Symantec for mis-issuing 30, 
FYI --
Google takes Symantec to the woodshed for mis-issuing 30,000 HTTPS certs
Chrome to immediately stop recognizing EV status and gradually nullify all certs.
Dan Goodin - Mar 23, 2017 11:25 pm UTC
In a severe rebuke of one of the biggest suppliers of HTTPS credentials, Google Chrome developers announced plans to drastically restrict transport layer security certificates sold by Symantec-owned issuers following the discovery they have issued more than 30,000 certificates.
Effective immediately, Chrome plans to stop recognizing the extended validation status of all certificates issued by Symantec-owned certificate authorities, Ryan Sleevi, a software engineer on the Google Chrome team, said Thursday in an online forum.  Extended validation certificates are supposed to provide enhanced assurances of a site's authenticity by showing the name of the validated domain name holder in the address bar.  Under the move announced by Sleevi, Chrome will immediately stop displaying that information for a period of at least a year.  In effect, the certificates will be downgraded to less-secure domain-validated certificates.
While I applaud Google *in this instance*, what happens when Google starts doing evil?
Why should I trust Google?
Why do I have to trust Google?

@_date: 2017-03-24 15:55:09
@_author: Henry Baker 
@_subject: [Cryptography] Google distrusts Symantec for mis-issuing  30, 
Perhaps my questions weren't clear.
What I really want to know is: in the evolution of the internet, how did we come to the point where I have to trust a single choke-point of failure--Google--in order to transact any business?
No, I don't think that Google is evil--at least not right this second.  But I don't recall Google ever being on the ballot in any governmental election I've ever voted in, and I've voted in nearly every election that I've been eligible to vote in.
Right now, I have to trust Google to even *access* a federal or state government site.
One error (or quote-error-unquote, ahem) by Google -- like the recent one at AWS -- could disconnect me (and nearly everyone else) from every government web site, email, bank, cellphone carrier, cable company, etc.
I can't imagine that any non-US govts are pleased about this state of affairs, either.
Instead of screwing around with and/or against Russians, how's about Congress getting back to business and fixing the d*mn DNS and CERT systems?
Who gives a rat's ass about whether the Russkies played man-in-the-middle-diddle with DNC (or whether John Podesta is smarter than a 5th grader); how's about fixing the d*mn system so that the Russkies couldn't do this even if they wanted to?

@_date: 2017-03-25 06:15:53
@_author: Henry Baker 
@_subject: [Cryptography] Google distrusts Symantec for mis-issuing   30, 
We're already there: Google "China", "Turkey", "North Korea", etc.
The current system of Internet governance isn't working; we have
Google making sure that the world is easy for Google to surveil,
we have Apple making sure that the world is easy for Apple to
surveil, we have Microsoft making sure that the world is easy
for Microsoft to surveil, we have Mozilla making sure that the
world is easy for Netflix to surveil; where's the part that
ensures the Internet is an open place for individuals like
you and me?
There are plenty of *individuals* working for the above-
mentioned corporations who have the best of intentions,
but don't hold your breath waiting for good results from
them: they weren't hired to buck their corporate objectives.
We are but one step away from a 21st century rhyme of the
oppression of the 20th, but this time we won't need an
army of bureaucrats, apparatchiks and "Good Germans" as
enforcers -- those functions have all been automated.
The ever-efficient technocratic Chinese are showing us
the way, and Google, Apple & Microsoft have fallen over
one another to help the Chinese figure out the best and
cheapest means to enslave their citizens.
Forget "self-deportation".  The Chinese already have
self-censorship, and thanks to the above-mentioned
corporations, these tried-and-tested means will be
cut-and-pasted into the rest of the world.
Under the guise of stamping out "fake news" and
upholding the "right to be forgotten", we're getting
a Ministry of Truth to protect us snowflakes from
any unpleasant challenges to our snowflakiness.
I'm sorry if I sound like the "nerd harder"
politicians; but perhaps we need to "nerd harder",
but instead of nerding harder in the service of
Google/Apple/Facebook/Microsoft, we need to nerd
harder in the service of a free citizenry.
There have been many proposals for distributed
trust systems, but so far, they haven't gotten
much traction -- perhaps because a truly tight
system might threaten the ability of Google or
others to sell us ordinary citizens to their
advertisers, or the ability of the Chinese &
other governments to cheaply surveil its

@_date: 2017-03-26 18:30:03
@_author: Henry Baker 
@_subject: [Cryptography] UK targets WhatsApp encryption after London attack 
FYI --
UK targets WhatsApp encryption after London attack
AFP March 26, 2017
London (AFP) - The British government said Sunday that its security services must have access to encrypted messaging applications such as WhatsApp, as it revealed that the service was used by the man behind the parliament attack.
Khalid Masood, the 52-year-old Briton who killed four people in a rampage in Westminster on Wednesday before being shot dead, reportedly used the Facebook-owned service moments before the assault.
Home Secretary Amber Rudd told Sky News it was "completely unacceptable" that police and security services had not been able to crack the heavily encrypted service.
"You can't have a situation where you have terrorists talking to each other -- where this terrorist sent a WhatsApp message -- and it can't be accessed," she said.
Police said Saturday that they still did not know why Masood, a Muslim convert with a violent criminal past, carried out the attack and that he probably acted alone, despite a claim of responsibility by the Islamic State group.
"There should be no place for terrorists to hide," Rudd said in a separate interview with the BBC.
"We need to make sure that organisations like WhatsApp -- and there are plenty of others like that -- don't provide a secret place for terrorists to communicate with each other."
She said end-to-end encryption was vital to cyber security, to ensure that business, banking and other transactions were safe -- but said it must also be accessible.
"It's not incompatible.  You can have a system whereby they can build it so that we can have access to it when it is absolutely necessary," she told Sky News.
Rudd said she did not yet intend to force the industry's hand with new legislation, but would meet key players on Thursday to discuss this issue, as well as the "constant battle" against extremist videos posted online.
"The best people -- who understand the technology, who understand the necessary hashtags -- to stop this stuff even being put up, not just taking it down, are going to be them," she told the BBC.
- WhatsApp 'horrified' by attack -
WhatsApp said it was working with British authorities investigating the Westminster attack, but did not specify whether it would change its policy on encrypted messaging.
"We are horrified at the attack carried out in London earlier this week and are cooperating with law enforcement as they continue their investigations," a company spokeswoman told AFP.
US authorities last year fought a legal battle with tech giant Apple to get it to unlock a smartphone used by one of the shooters in a terror attack last year in San Bernardino, California.
The FBI's own experts ended up breaking into the device.
Here we go again...

@_date: 2017-03-29 12:09:58
@_author: Henry Baker 
@_subject: [Cryptography] DJI calls for drone IFF 
FYI --
A DJI Technology Whitepaper
"What's In a Name?"  A Call for a Balanced Remote Identification Approach
March 22, 2017
The Utility of Remote Identification Technologies
Section 2202 of the 2016 FAA Extension Act contemplates the development of remote
identification technologies for unmanned aircraft systems (UAS).  Regulatory proposals in
Europe, including from the European Aviation Safety Agency (EASA), and in European Union
member states such as France and Germany, have also called for remote identification
technology.  Indeed, Italy and Denmark apparently already mandate these technologies, in
regulations that seem not to be enforced because the means of compliance do not yet exist. Remote identification is potentially a problem-solving approach to addressing policy concerns
including security and accountability.
DJI believes that laws of general applicability should apply to drones, just as they do to
other technologies.  For example, a law that makes unlawful surveillance illegal should apply to
misconduct using drones as it would apply to misconduct using other types of cameras.  These
laws of general applicability have been created by lawmakers over decades and balance
competing interests including privacy interests, community values, national legal traditions,
cultural norms, the First Amendment (and similar doctrines outside the United States), and
journalism interests, among others.  The balance reached after decades of legislation and
jurisprudence should not be disrupted each time a new technology comes along.  Operational
rules relating to UAS obviously apply as well.
Whenever you hear a lawmaker use the phrase "balanced approach", you should vote against
him/her and start filing lawsuits, because the "balance" being sought is typically that
of destroying your rights as an individual -- including all of the rights embodied in
the Bill of Rights.
The first use of DJI's "identification code" will be for law enforcement to snoop.
The second use of DJI's identification code will be for resale to advertising companies.
The third use of DJI's identification code will be for law enforcement targeting -- e.g.,
for miniature missiles and/or lasers to automatically destroy your drone.
The fourth use of DJI's identification code" will be for hackers to allow their drone
to pretend to be your drone, so that you will be "swatted" when the hacker's drone
dones something illegal.
Aren't there more sophisticated IFF schemes already in existence?

@_date: 2017-03-29 14:59:47
@_author: Henry Baker 
@_subject: [Cryptography] DJI calls for drone IFF 
Interesting.  I provided the link that my browser reported for the download itself; that link is *usually* more accurate than the "named" link, which typically goes through several levels of redirect.
In any case, you probably want to change that "?dl=0" to "?dl=1" at the end of the link if you want to get the pdf file automatically downloaded.

@_date: 2017-03-29 15:12:41
@_author: Henry Baker 
@_subject: [Cryptography] Science of Security Award, last call 
Awardees will then get an all-expenses-paid vacation to one of the most beautiful -- but also very exclusive -- portions of Cuba, where the water sports are *amazing*.  :-)

@_date: 2017-03-30 12:18:16
@_author: Henry Baker 
@_subject: [Cryptography] escalating threats to privacy 
Or this: Climb Mount Niitaka 12/08
Which was sent 12/2/1941 in Morse Code for katakana (alphabetic Japanese), but was otherwise unencrypted.

@_date: 2017-05-06 22:19:14
@_author: Henry Baker 
@_subject: [Cryptography] French election attacked. 
All true, but most of this is a red (!) herring sideshow to divert our attention from the total incompetence of the DNC (and now, obviously, the French political parties).
Govts always try to use "deterrence", because it is the cheapest tool in their toolbox.  If you're the biggest, baddest bully, you beat up on people early & often, so they won't attempt to get together and beat back.  But if/when deterrence fails, these bullies often don't have a backup plan, and -- in democratic countries, at least -- the govts don't have the Nazi option of simply hanging/shooting every 10th person ("decimation") until the population kills the perpetrators themselves.
If a politician succumbs to a phishing attack, it is the same as if they had left their non-password-protected laptop on the plane/train/bus, but now they want to destroy all of *our* privacy and security, so we'll feel their pain?

@_date: 2017-05-21 06:44:22
@_author: Henry Baker 
@_subject: [Cryptography] athletic event verification? 
[I'm asking this question for academic interest only; I have no financial interest in fitbit or equivalent, or strava.com or equivalent.]
Suppose that one would like to "register" some achievement on a leaderboard -- e.g., something like Strava.com.
Are there any crypto techniques that might be useful to make it harder to put up fake achievements?
Presumably, there are a minimum number of achievement fields that might be important:
name, address?, some-sort-of-id?, date of achievement, location of achievement, distance of achievement, time of achievement, etc.
Would it be possible to include certain hidden information -- e.g., address or SS# -- that would participate in the signature, but not be readily accessible to someone listing the leaderboard or even cryptographically verifying the claim?
One might want to log *witnesses*: witness1 signature, witness2 signature, etc.
As to date info, there are the usual *notary* issues, which might involve spending a microbitcoin to nail down the event time to a small portion of the bitcoin blockchain.
I would assume that the person claiming the achievement might have to cryptographically sign the achievement with his/her own PKI info; ditto for any "witnesses".
Perhaps one might want to include some sort of *signed photo* or *signed video* of the achievement.
Any other ideas of what evidence might be gathered and signed in order to "prove" the achievement?
Could any *equipment* be used as a witness?  E.g., could a mechanical *treadmill* or stationary *bike* (or other gym equipment) electronically sign an achievement?
Blood or DNA tests "signed" by the testing equipment??  :-)

@_date: 2017-11-05 06:03:06
@_author: Henry Baker 
@_subject: [Cryptography] One Bitcoin Transaction Now Uses as Much Energy as 
FYI --
One Bitcoin Transaction Now Uses as Much Energy as Your House in a Week
Bitcoin's surge in price has sent its electricity consumption soaring.
Christopher Malmo   Nov 1 2017, 12:20pm
Bitcoin's incredible price run to break over $7,000 this year has sent
its overall electricity consumption soaring, as people worldwide bring
more energy-hungry computers online to mine the digital currency.
An index from cryptocurrency analyst Alex de Vries, aka Digiconomist,
estimates that with prices the way they are now, it would be
profitable for Bitcoin miners to burn through over 24 terawatt-hours
of electricity annually as they compete to solve increasingly
difficult cryptographic puzzles to "mine" more Bitcoins.  That's about
as much as Nigeria, a country of 186 million people, uses in a year.
This averages out to a shocking 215 kilowatt-hours (KWh) of juice used
by miners for each Bitcoin transaction (there are currently about
300,000 transactions per day).  Since the average American household
consumes 901 KWh per month, each Bitcoin transfer represents enough
energy to run a comfortable house, and everything in it, for nearly a
week.  On a larger scale, De Vries' index shows that bitcoin miners
worldwide could be using enough electricity to at any given time to
power about 2.26 million American homes.
Expressing Bitcoin's energy use on a per-transaction basis is a useful
abstraction.  Bitcoin uses x energy in total, and this energy
verifies/secures roughly 300k transactions per day.  So this measure
shows the value we get for all that electricity, since the verified
transaction (and our confidence in it) is ultimately the end product.
Since 2015, Bitcoin's electricity consumption has been very high
compared to conventional digital payment methods.  This is because the
dollar price of Bitcoin is directly proportional to the amount of
electricity that can profitably be used to mine it.  As the price
rises, miners add more computing power to chase new Bitcoins and
transaction fees.
It's impossible to know exactly how much electricity the Bitcoin
network uses.  But we can run a quick calculation of the minimum
energy Bitcoin could be using, assuming that all miners are running
the most efficient hardware with no efficiency losses due to waste
heat.  To do this, we'll use a simple methodology laid out in previous
coverage on Motherboard.  This would give us a constant total mining
draw of just over one gigawatt.
That means that, at a minimum, worldwide Bitcoin mining could power
the daily needs of 821,940 average American homes.
Put another way, global Bitcoin mining represents a minimum of 77KWh
of energy consumed per Bitcoin transaction.  Even as an unrealistic
lower boundary, this figure is high: As senior economist Teunis
Brosens from Dutch bank ING wrote, it's enough to power his own home
in the Netherlands for nearly two weeks.
Digiconomist's less optimistic estimate for per-transaction energy
costs now sits at around 215 KWh of electricity.  That's more than
enough to fill two Tesla batteries, run an efficient fridge/freezer
for a full year, or boil 1872 litres of water in a kettle.
It's important to remember that de Vries' model isn't exact.  It makes
assumptions about the economic incentives available to miners at a
given price level, and presents a forward-looking prediction for where
mining electricity consumption could go.  Despite this, it's quite
clear that even at the minimum level of 77 KWh per transaction, we
have a problem.  At 215 KWh, we have an even bigger problem.
That problem is carbon emissions.  De Vries has come up with some
estimates by diving into data made available on a coal-powered Bitcoin
mine in Mongolia.  He concluded that this single mine is responsible
for 8,000 to 13,000 kg CO2 emissions per Bitcoin it mines, and 24,000
- 40,000 kg of CO2 per hour.
As Twitter user Matthias Bartosik noted in some similar estimates, the
average European car emits 0.1181 kg of CO2 per kilometer driven.  So
for every hour the Mongolian Bitcoin mine operates, it's responsible
for (at least) the CO2 equivalent of over 203,000 car kilometers
As goes the Bitcoin price, so goes its electricity consumption, and
therefore its overall carbon emissions.  I asked de Vries whether it
was possible for Bitcoin to scale its way out of this problem.
"Blockchain is inefficient tech by design, as we create trust by
building a system based on distrust.  If you only trust yourself and a
set of rules (the software), then you have to validate everything that
happens against these rules yourself.  That is the life of a
blockchain node," he said via direct message.
This gets to the heart of Bitcoin's core innovation, and also its core
compromise.  In order to achieve a functional, trustworthy
decentralized payment system, Bitcoin imposes some very costly
inefficiencies on participants, for example voracious electricity
consumption and low transaction capacity.  Proposed improvements, like
SegWit2x, do promise to increase the number of transactions Bitcoin
can handle by at least double, and decrease network congestion.  But
since Bitcoin is thousands of times less efficient per transaction
than a credit card network, it will need to get thousands of times
In the context of climate change, raging wildfires, and
record-breaking hurricanes, it's worth asking ourselves hard questions
about Bitcoin's environmental footprint, and what we want to use it
for.  Do most transactions actually need to bypass trusted third
parties like banks and credit card companies, which can operate much
more efficiently than Bitcoin's decentralized network? Imperfect as
these financial institutions are, for most of us, the answer is very
likely no.
Update: The piece has been updated to include the fact that Bitcoin's
price reached over $7,000 on November 2.
Correction: Because of a typo, this piece originally stated that the
coal-powered mine is responsible for 8,000 to 13,0000 kg CO2 emissions
per Bitcoin it mines.  The number is in fact 13,000 kg.  The piece has
been updated.
An obvious example of Herb Stein's Law:
"If something cannot go on forever, it will stop."

@_date: 2017-11-24 07:54:07
@_author: Henry Baker 
@_subject: [Cryptography] WIPEONFORK in Linux 4.14 
Now if we could just get a "clean" file system that is guaranteed to erase all traces of a file when it is deleted -- not only the file contents, but also any metadata and old filenames stored in the directories.
Yes, I know there are "secure delete" commands, but they're useless unless they can somehow be made the *default* behavior for all file operations.

@_date: 2017-11-25 08:01:40
@_author: Henry Baker 
@_subject: [Cryptography] WIPEONFORK in Linux 4.14 
Many (most ?) file ops now occur in *virtual machines*, which include
*virtual disks* which can be *dynamically allocated*.  In particular,
blocks which are *all zeros* aren't stored at all, so these virtual
disk images are "sparse arrays" of non-zero blocks.
It's actually worth zeroing out these blocks (cleverly, of course),
so that they take up no space and no transfer bandwidth.
So what I'm suggesting is *in addition to* using encryption,
automatically zero out deleted files.

@_date: 2017-11-27 13:07:25
@_author: Henry Baker 
@_subject: [Cryptography] WIPEONFORK in Linux 4.14 
OK, guys, I'll bite.  What would be a simple design for an encryption system *whose only purpose is to avoid having to zero out file blocks when the file is deleted*?  I.e., if you have "access" to the directory metadata, then you can get the plaintext file contents.
Let's assume a trivial file system -- e.g., FAT32.
We have files allocated in lists of "clusters" of blocks.
We have special kinds of files called "directories", which encode an array of tuples (filename,metadata,ptr to list of blocks in FAT table).
Let's simplify further so that the files are each read-only (i.e., no update-in-place -- just rewrite the entire file).
If I have access to the file metadata, then I can utilize the per-file encryption key to read that particular file's data.
Now since a directory is also a file, it, too, must have a per-file encryption key, which is stored in the parent directory.
So by recursion, the root directory also needs a per-file encryption key.
Where is that root directory key stored?
Additional issues: so-called "atomic" file system actions cannot involve more than a small finite number of single-block operations.  So all of the intermediate states -- e.g., file partially allocated/written; file partially deleted -- must be handled safely and securely.

@_date: 2017-11-27 14:32:04
@_author: Henry Baker 
@_subject: [Cryptography] Is ASN.1 still the thing? 
The Common Lisp standard went to a lot of trouble to provide floating point readers & writers that could provide "round trip" assurance for simple S-expressions, even for IEEE floats as an internal representation and decimal external representation.
Thus, unless your floating point numbers are NaN's, Common Lisp provides that read(print(x))=x, bit-for-bit.
Also, print(read(x))=x, as strings, although you need to make sure that the string types are the same.
Yes, I know, this isn't trivial: you need to provide just enough decimal digits to guarantee that it will read correctly, but not so many that the function is no longer 1-1.  Yes, a strict implementation will also work correctly with gradual underflow values.
Yes, the number of decimal digits required is not constant, but varies with the floating point value.

@_date: 2017-11-29 14:10:55
@_author: Henry Baker 
@_subject: [Cryptography] Intel Management Engine pwnd 
Everyone here should be aware that the "power off" button on your laptop now does about as much as the "power off" button on your TV: NOTHING!  (TV's have refused to actually power off ever since tube TV's from the 1950's; now they refuse to power off due to the time required to reboot Linux/Android/Palm/Kali ...)
Ever since I got my latest Windoze laptop last year, I noticed that it didn't retain all of its battery charge when *powered down*.
I soon discovered that this laptop did retain nearly all of its charge *when I removed the battery*.
So clearly, something below the operating system continues to run, and run quite vigorously, in order to continue running down the battery.
What a pain in the butt this is: I have to remove the battery every time I pack it into my bag, else the battery will run down & leave me stranded.
It's utterly amazing how little the needs of *actual users* factor into product design any more; the needs of the HSA/CIA/FBI/NSA/corporate spying (aka "management capabilities") prevail over individual users every time.

@_date: 2017-11-29 20:37:14
@_author: Henry Baker 
@_subject: [Cryptography] Intel Management Engine pwnd 
Barometers I know something about.
The reason for barometers is for precision altitude calculations.  It turns out that GPS is not particularly precise when it comes to altitudes, unless you average over a large number of readings and satellites.
So you use the GPS to *calibrate* the barometer, and then use the barometer for precision altitude measurements.
Airplanes use barometers (suitably calibrated) for altimeters, as do many sports watches.  A Garmin bike computer, for example, can easily handle rises and falls of just a few feet (i.e., the distance between your feet and your head), which is a precision not possible using just an unaided GPS.
I don't see barometers being obsoleted by GPS anytime in the next 50 years -- they're simply too cheap and too reliable not to use them.

@_date: 2017-11-30 13:11:01
@_author: Henry Baker 
@_subject: [Cryptography] Rubber-hose resistance? 
I often run the "F3" (Fix Fake Flash) program on new usb stix and SD cards.
F3 works by writing a crypto quality PRNG over the entire drive/card and then reading it back to check whether the entire stream of bits can be read back exactly.
If the PRNG is of true crypto quality, then no lossless compressor can possibly compress this data to fit into a smaller space, so the drive/card is guaranteed to have the capacity that it advertises to the Linux driver.
However, since F3 completely fills the drive/card with random bits, the drive/card might now look suspicious to those with too little drama in their lives.

@_date: 2017-10-14 07:13:31
@_author: Henry Baker 
@_subject: [Cryptography] Suggestions for wearable wireless technology ? 
I'm working with a small medical device company which is making wearable devices.
The problem is: what wireless technologies are there that have the following characteristics:
* Extremely low power when not in use (most of the time)
* Short range (body area network -- ~1 meter)
* High data rates (10-100 Mbits/sec) occasionally -- e.g., in the doctor's office
* Exceedingly robust: waterproof, even at scuba depths, useful in contact sports -- e.g., football; (radio doesn't have to *work* underwater, but it does have to *survive* being underwater)
* Exceedingly secure & private -- e.g., no "Bluetooth beacons" that can be tracked by store monitors or street monitors
* Relatively small & cheap in HW & SW (i.e., no 100MB or 1GB SW stacks!)
Bluetooth -- even Bluetooth Low Energy -- is a horrendous mess, requiring expensive licensing and has very poor security & privacy.
The other low power protocols -- e.g., Zigbee -- don't seem to have security & privacy necessary for a human wearer designed in.
I was thinking about some sort of low power optical signaling which could wake up a wifi radio for brief high bandwidth bursts.  Alternatively, it might be possible to utilize some sort of optical sensor and a high frequency LED to establish a high bandwidth optical link, but what kind of protocol would be ideal?
There still needs to be highly encrypted signaling and the highest quality authentication (e.g., for the doctor's office and/or firmware upgrades).
Any ideas?

@_date: 2017-10-16 21:22:56
@_author: Henry Baker 
@_subject: [Cryptography] [FORGED] Re: Severe flaw in WPA2 protocol leaves 
Biggest problem IMHO is Android.  There doesn't appear to be any way -- short of a class-action lawsuit -- to force the Android phone vendors to supply a firmware upgrade.  They're already 12-24 months behind on CVE's.  And I doubt that Google is willing to upgrade every Android phone on its own.
Oh, and BTW, Cyanogen is out of the Android OS business; LineageOS (lineageos.org) hasn't said anything about this WPA2 bug yet.
In the meantime, it's probably not a good idea to activate your Android phone's "hotspot" feature.

@_date: 2017-10-17 08:24:59
@_author: Henry Baker 
@_subject: [Cryptography] Millions of high-security crypto keys crippled 
But TPM's are "responsible" ;-)
Responsible, adj.  Trustworthy, mature.
Tell me again why I need a "TPM", when its design is secret, its software is secret, and no one I trust is allowed to audit it?
Perhaps there's a reason why it has a TLA ?

@_date: 2017-10-27 06:59:56
@_author: Henry Baker 
@_subject: [Cryptography] How Google's Physical Keys Will Protect Your Password 
FYI --
How Google's Physical Keys Will Protect Your Password
By BRIAN X. CHEN and NICOLE PERLROTH OCT. 25, 2017
Why won't the password just go away?  The silly pet names, movie
titles or sports teams that many people punch in to get into their
online accounts are a weak spot that hackers continue to puncture.
Yet passwords remain the primary way we log in to online accounts
containing our personal and financial information.  Google has a new
pragmatic solution: Embrace the password, but lock it down with extra
physical security.
The company this month released its Advanced Protection Program, which
is meant to make stealing your password pointless.  To use it, you'll
need two inexpensive physical keys to log in to your Google account on
your computer and smartphone.
This way, even if hackers stole your password in a data breach or
successfully phished for it, by tempting you to hand over your
credentials on a fake login page, they couldn't do anything unless
they got their hands on the keys as well.  And minimizing risk with
minimal effort is a boon to anyone who cares about online security.
"I am a big fan of this," said John Sabin, a former hacker for the
National Security Agency.  "It's probably the easiest and most secure
multifactor for the masses."
The physical keys are an evolution of two-factor authentication, an
extra security layer to ensure that your password is being entered by
you.  Google was one of the first companies to start offering
two-factor authentication back in 2010, not long after it learned that
it had been hacked by state-sponsored Chinese hackers.
After the attack, Google's security team came up with a motto: "Never
again."  The company later rolled out two-factor authentication for
Google customers' Gmail accounts.  It involved text messaging a unique
code to your phone that you must type in after entering your password
in order to log in.
Unfortunately, those text messages can be hijacked.  Last month,
security researchers at Positive Technologies, a security firm,
demonstrated how they could use vulnerabilities in the cellular
network to intercept text messages for a set period of time.
The idea of Google's Advanced Protection Program is to provide people
with a physical device that is much harder to steal than a text
message.  Google is marketing the program as a tool for a tiny set of
people who are at high risk of online attacks, like victims of
stalking, dissidents inside authoritarian countries or journalists who
need to protect their sources.
But why should extra-tough security benefit such a small group?
Everyone should be able to enjoy stronger security.
So we tested Google's Advanced Protection Program and vetted it with
security researchers to see if the program could be used by the
masses.  The verdict: Many people should consider signing up for the
security system and buying a pair of keys.  But if you are married to
some non-Google apps that are not yet compatible with the keys, you
should wait and see if the program matures.
Setting Up Advanced Protection
Anyone with a Google account can sign up for the security program on
Google's Advanced Protection webpage.  To get started, you will have
to buy two physical keys for about $20 each.  Google recommends buying
one from Feitian and another from Yubico.
The keys, which look like thumb drives and can fit on your key chain,
contain digital signatures that prove you are you.  To set one up, you
plug the key into a computer USB port, tap a button and name it.  (The
Feitian key wirelessly communicates with your smartphone to
authenticate the login.)  This process takes a few minutes.
On a computer and a smartphone, you need to log in with the key only
once, and Google will remember the devices for future logins.  That is
more convenient than traditional two-factor authentication, which
requires entering a unique code each time you log in.
But there are trade-offs.  Google's Advanced Protection cuts off all
third-party access by default, allowing only applications that support
its security keys.  For the time being, that means only Google's Gmail
mail app, Google's Backup and Sync app, and Google's Chrome browser.
On an iPhone, for example, you will have to use Google's Gmail or
Inbox apps for email, and on a computer, you can use only the Chrome
browser when signing in with a browser.  So if you rely on Apple Mail
to gain access to your Gmail on an iPhone, or if you use Microsoft
Outlook for getting into Gmail on a PC, you're out of luck.  Google
says its goal is to eventually allow third-party apps to work with the
program, but it is also up to other companies to update their apps to
support the keys.
Testing the Security
Despite the drawbacks, security researchers agree that the Advanced
Protection Program is a solid piece of security and relatively
painless to use, even for everyday use for people outside
high-security jobs.
Mr. Sabin, the former N.S.A. hacker, who is now a director of network
security at GRA Quantum, a security consulting firm, said the physical
keys had pros and cons.  On one hand, if you lose a key, a hacker
would have a hard time figuring out which account it was associated
On the other hand, if you lose the keys or don't have the keys around
when you need to log in to a new device, it takes longer to regain
access to your account.  Google has put in place more elaborate
recovery steps for Advanced Protection users, including additional
reviews and requests for details about why users have lost access to
their account.  In our test, we answered security questions to try to
recover an account, and Google said it would review the recovery
request and respond within a few days.
Runa Sandvik, the director of information security at The New York
Times, said the keys were not much of a hassle.  She said Google's
requirement of using two keys meant you essentially had a spare: If
you lose one key, you can get into your account with the remaining
But she noted that the keys could get annoying if you used many
devices and constantly needed to carry the keys around to log in to
your account.  That may be an issue for people who work in the
technology industry, but most people probably use only one computer
and one phone.
Ms. Sandvik, who has been testing Google's program to assess whether
to recommend it to the newsroom, said she had not yet discovered
vulnerabilities in the security key system outside of the slim
possibility that a hacker gained possession of both your password and
your key.
"It's something that is relatively easy to set up once you have both
keys," Ms. Sandvik said.  "I don't see a reason you shouldn't turn
this on."
The Bottom Line
While the security keys are easy to set up and provide tough security,
they may be disruptive to your productivity if you rely on apps that
are incompatible with the keys.
It took a few minutes for us to migrate to Google's apps from Apple's
and integrate them into our newsroom workflow, which already relies on
Google's mail, messaging and cloud storage services.  But using the
keys required sacrificing an important feature -- Apple's
V.I.P. alerts, which notify you when people you deem important email
you.  Google's iOS apps for Gmail and Inbox lack a similar feature.
For people with flooded inboxes, lacking V.I.P. alerts makes sifting
through emails time-consuming.
Another example of how the keys can stifle productivity: Many
employers still require using the Microsoft Outlook app for email,
which won't work with the keys.
If using Google's security program would disrupt your work, you may
want to wait for more companies to update their apps to support the
keys, which rely on a standard called FIDO, for Fast Identity Online.
Mr. Sabin predicts that many apps will follow Google's lead.
If you decide to wait, don't procrastinate on turning on traditional
two-factor authentication that relies on text messages.  While it is
hackable, it is still much safer than relying on a password alone to
protect you.
The question is how long it will take security researchers to find a
way to hack the physical keys as well.  When asked if he had already
circumvented physical multifactor authentication devices like Google's
keys, Mr. Sabin would offer only: "No comment."
A version of this article appears in print on October 26, 2017, on
Page B6 of the New York edition with the headline: Google's Security
Key Works, With Limits.

@_date: 2017-09-06 07:10:16
@_author: Henry Baker 
@_subject: [Cryptography] Finding Nemo's random seed 
Two words: functional programming.
Another two words: no sympathy.

@_date: 2017-09-07 16:18:51
@_author: Henry Baker 
@_subject: [Cryptography] Finding Nemo's random seed 
Slight modification: no sympathy for movie *companies*.
Although I've never worked in H'wood myself, I have lots of friends who do,
and H'wood B.S. has bankrupted a lot of animation companies.  Whether the
movie makes money or not doesn't matter; the animation companies never
make more than a pittance.  One would think that this situation may have
been foreseen by the animation company, who probably asked for additional
$$ to fix the code, and were turned down.  The animation company probably
thought to themselves: "f**k them; let'm learn".
H'wood is absolutely notorious for doing a terrible job preserving
*even its most famous and profitable movies*.  Many "re-released"
features have had to be cobbled together from garbage dumps, screener
demos, etc.  And this includes the re-release of the original Star
Wars movie.
For an industry that makes such a BFD out of "intellectual
property", H'wood is the biggest slum lord of them all!
Many H'wood movies have only been preserved due to the actions
of "pirates", who made "illegal" copies, which subsequently
turned out to be the *only* copies, due to the incompetence of
the H'wood studios.
All that having been said, two more words: "reproducible builds"

@_date: 2017-09-10 11:25:30
@_author: Henry Baker 
@_subject: [Cryptography] Zero Knowledge: Have I Been Pwned? 
FYI --
Introducing 306 Million Freely Downloadable Pwned Passwords
03 August 2017
"The entire collection of 306 million hashed passwords can be directly downloaded from the Pwned Passwords page.  It's a single 7-Zip file that's 5.3GB which you can then download and extract into whatever data structure you want to work with (it's 11.9GB once expanded)."
Ok, all you crypto wizards: here's a real-world problem that needs to be solved.
I don't think that it is safe to type a password into the HIBP (Have I Been Pwned) page in order to check it.  Why?  Because even if it was safe *before* I typed it in, it won't be *after* I typed it in.
I also don't think that it is safe to type a SHA1 hash of a password into the HIBP either.  Why?  Because the database contains the complete list of pairs (password,SHA1(password)), so inverting these particular hashes is trivial, so this is equivalent to simply typing in the unhashed password.
Yes, I could download 5.3GB of data & decompress it to 11.9GB & search it myself, and never reveal what password(s) I'd like to check.  But I'd rather not download 5.3GB of data.
What would be a good protocol for the HIBP site itself, and a good protocol for anyone who wants to query it?
Some desiderata for the protocol:
* All I learn from my query is whether or not the password is the database -- i.e., exactly 1 bit.
* All the HIBP database learns is that there *has* been a query, but can't determine what the query was, or whether it was successful.
* The total number of bits transmitted in both directions should be a number of orders of magnitude less than 5.3GB.
Any suggestions?

@_date: 2017-09-12 12:25:04
@_author: Henry Baker 
@_subject: [Cryptography] Chrome & Firefox protecting users against 
Because NSL's, because terrorists, because pornographers, because
NorK's, because Wikileaks, because Snowden, because Putin, because
China, because NSL's ...
But *never* because First Amendment, Fourth Amendment, Fifth
Amendment, Fourteenth Amendment...
Attacks on the First Amendment are going on right now: domain
registration; next up: certs.

@_date: 2017-09-25 06:06:26
@_author: Henry Baker 
@_subject: [Cryptography] Amazing possibilities for steganography 
You've GOT to watch this 5 minute video about AI image recognition systems, in order to gain a better appreciation for what they can and can't do.
You can easily appreciate that someone could invert this process to produce high quality steganography for both images and sounds.
If this video interests you, the rest of these links tell more.
Deep Neural Networks are Easily Fooled        109,422 views
Evolving AI Lab
Published on Dec 16, 2014
A video summary of the paper: Nguyen A, Yosinski J, Clune J.  Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images.  In Computer Vision and Pattern Recognition (CVPR '15), IEEE, 2015.

@_date: 2017-09-25 13:55:09
@_author: Henry Baker 
@_subject: [Cryptography] Amazing possibilities for steganography 
Oh, but we're going to put all of our faith in neural-net AI to find & recognize malware?  How many $$$billions are going to go down that rathole...  "I see England, I see France; I see Putin's underpants!" ;-)

@_date: 2018-04-01 07:14:50
@_author: Henry Baker 
@_subject: [Cryptography] Password entry protocols 
The problem is, the password model only works (if it ever did)
when you have a *single process* running on your computer.  The
moment you have more than one process, you have moved from a
model where Alice and Bob are whispering in secret to a model
where Alice and Bob are talking loudly on a crowded bus or
restaurant with tens/hundreds of potential Eve's listening
(and talking/typing).
So to implement a password system on a modern computer&OS, one
would need the ability to reliably take *exclusive* control of
a portion of the screen -- which no one else could either read
or write -- and the ability to reliably take *exclusive* control
of the keyboard.  As we have painfully learned over the years,
simple SW means of exclusion can be trivially bypassed; this
exclusion has to be enforced in *hardware*.  When was the last
time that you saw a piece of computer/cellphone screen real
estate that was exclusively controlled by your bank?
Or some HW means/keyboard that you used *exclusively* to talk
to your bank?
With today's tens (or hundreds) of levels of input/output HW/SW
virtualization, good luck with that!
So once you have lots of Eve's listening, you're back in the
model where both ends of the communication need to *encrypt*
and *authenticate* each and every message.
Suppose that you are attempting to talk securely and
confidentially to your bank.  Your bank has to authenticate
itself to you, and you have to authenticate yourself to
the bank.  We have gone to a lot of trouble to come up with
TLS protocols to do this sort of thing over the web, but
with insecure operating systems, we now have to do these
protocols -- as human beings.  We have to have pocket
calculators which can (securely) compute RSA/ECC/AES/SHA
so we can do -- by hand -- the same sorts of calculations.
This story isn't going to end well.

@_date: 2018-08-14 07:52:01
@_author: Henry Baker 
@_subject: [Cryptography] God Mode backdoors 
FYI --
Hacker Finds Hidden 'God Mode' on Old x86 CPUs
by Paul Wagenseil August 9, 2018 at 5:06 PM
LAS VEGAS -- Some x86 CPUs have hidden backdoors that let you seize
root by sending a command to an undocumented RISC core that manages
the main CPU, security researcher Christopher Domas told the Black Hat
conference here Thursday (Aug. 9).
The command -- ".byte 0x0f, 0x3f" in Linux -- "isn't supposed to
exist, doesn't have a name, and gives you root right away," Domas
said, adding that he calls it "God Mode."
The backdoor completely breaks the protection-ring model of
operating-system security, in which the OS kernel runs in ring 0,
device drivers run in rings 1 and 2, and user applications and
interfaces ("userland") run in ring 3, furthest from the kernel and
with the least privileges. To put it simply, Domas' God Mode takes you
from the outermost to the innermost ring in four bytes.
"We have direct ring 3 to ring 0 hardware privilege escalation," Domas
said. "This has never been done."
That's because of the hidden RISC chip, which lives so far down on the
bare metal that Domas half-joked that it ought to be thought of as a
new, deeper ring of privilege, following the theory that hypervisors
and chip-management systems can be considered ring -1 or ring -2.
"This is really ring -4," he said. "It's a secret, co-located core
buried alongside the x86 chip. It has unrestricted access to the x86."
The good news is that, as far as Domas knows, this backdoor exists
only on VIA C3 Nehemiah chips made in 2003 and used in embedded
systems and thin clients. The bad news is that it's entirely possible
that such hidden backdoors exist on many other chipsets.
"These black boxes that we're trusting are things that we have no way
to look into," he said. "These backdoors probably exist elsewhere."
Domas discovered the backdoor, which exists on VIA C3 Nehemiah chips
made in 2003, by combing through filed patents. He found one --
US8341419 -- that mentioned jumping from ring 3 to ring 0 and
protecting the machine from exploits of model-specific registers
(MSRs), manufacturer-created commands that are often limited to
certain chipsets.
Domas followed the "trail of breadcrumbs," as he put it, from one
patent to another and figured out that certain VIA chipsets were
covered by the patents. Then he collected many old VIA C3 machines and
spent weeks fuzzing code.
He even built a testing rig consisting of seven Nehemiah-based thin
clients hooked up to a power relay that would power-cycle the machines
every couple of minutes, because his fuzzing attempts would usually
crash the systems. After three weeks, he had 15 GB of log data -- and
the instructions to flip on the backdoor in the hidden RISC chip.
"Fortunately, we still need ring 0 access to start the launch process,
right?" Domas asked. "No. Some of the VIA C3 x86 processors have God
Mode enabled by default. You can reach it from userland. Antivirus
software, ASLR and all the other security mitigations are useless."
Domas has put all his research, plus tools to check whether your VIA
C3 CPU might have an undocumented coprocessor and to disable the
coprocessor by default, up on his GitHub page at
Why do we even bother encrypting, when our chips are so corrupt?
I believe that these VIA chips ended up in some military hardware,
and possibly in some ATM machines.
This article strengthens my belief that *all* of our current chips
have hidden backdoors thanks to Uncle Sam.  No wonder China wants
to design & build their own chips!

@_date: 2018-08-15 07:09:52
@_author: Henry Baker 
@_subject: [Cryptography] God Mode backdoors 
I think it may be *impossible* to build a large modern chip w/o
In order to properly *test* a large & complicated chip after it
comes out of the fab, there needs to be various kinds of extra
datapaths and control circuitry.
For example, a large chip with a *true random number generator*
needs to have the ability to *route data around the TRNG* to be
able to test the various registers and datapaths.  It may also
need to have a fair amount of *hidden state* to aid in running
these tests.
Ditto for the hardware used in *encryption instructions*.  These
instructions are too complex to be simply tested end-to-end;
they need to be broken down into smaller components which can
be individually tested.  Of course, an encryption instruction
which can be broken down into smaller components can also be
*interrupted*, *modified*, or otherwise *hacked*.
Manufacturers can claim to use irreversible techniques such
as *fusible links* in order to *turn off* these "inadvertent
backdoors" after successful testing, but how can we trust
that these backdoors have been sealed, when so many existing
vulnerabilities in shipping products (Cisco, cough, cough)
have their testing backdoors still enabled?
Far better to ship the chip to the *end user*, who can then
run through *the same set of open sourced exhaustive tests*
to assure himself/herself that the chip is working correctly,
followed by a sealing of this testing backdoor himself/herself.

@_date: 2018-08-22 07:03:37
@_author: Henry Baker 
@_subject: [Cryptography] "Incremental" DH Key exchange ?? 
Suppose that there's essentially no latency and
that messages are extremely cheap (relative to
everything else), so we're no longer trying to
minimize round-trips during a key exchange.
I'm wondering if there's a DH-type of key exchange
which "incrementalizes" the key exchange to develop
a shared secret a few bits at a time.
My analogy/intuition here is a Newton-type iteration
that doubles the number of shared secret bits on
every iteration.
I've heard of "amplification", but don't really
understand it.  Is that a possible direction to

@_date: 2018-08-29 10:23:45
@_author: Henry Baker 
@_subject: [Cryptography] Should you trust Intel ? 
FYI --
Linux 4.19 lets you declare your trust in AMD, IBM and Intel
Wave the the CPU trust flag if you're feeling safe enough
By Thomas Claburn in San Francisco 28 Aug 2018 at 07:01
Intel Management Engine JTAG flaw proof-of-concept published
"God Mode" requires special USB debugging connector
By Thomas Claburn in San Francisco 29 Aug 2018 at 00:15
Probably not.
First article describes how you can turn off Intel's HW RNG.
Second article shows how to hack Intel CPU's via USB & JTAG.
I suspect that this is just the beginning of JTAG-type hacks on CPU's from all vendors.  I spoke recently with a TI IoT chip designer about JTAG, and he seemed clueless, so perhaps TI chips would be a good place to start looking?

@_date: 2018-12-02 07:49:50
@_author: hbaker1 
@_subject: [Cryptography] What if Responsible Encryption Back-Doors Were 
I attended this "conference" and all of its sessions.
The whole thing was a setup, IMHO.  I think that they were trying to gather possible arguments against backdoors so that they could be prepared for future discussions with politicians.  They also wanted to tell these politicians that there were *some* in the crypto community that thought we all really should leave our keys under the front door mat.
A group of US ex-intel hangers-on, plus some brits, some aussies, and perhaps a kiwi; more or less the 5i's.  They may also have invited some press.  Some of these folks flew on to Australia to wreak more havoc, as best I can gather.
One result of this wannabe conference can apparently be found in the recent activity in Australia to mandate back doors.  These folks apparently wanted to find one of the 5i govts to pass the first test law requiring these back doors, and Australia must have volunteered.
Magical thinking by all.
BTW, with perhaps a handful of exceptions, no actual crypto people attended this conference, which was merely held at the same *location*, so that some of the prestige of a Crypto Conference would rub off on this sham.
The only reason I knew about this conference was that I ran into one of the participants while parking my car for Crypto, and talked with him while walking over to the main venue.
Apparently, I was the only one there who questioned this whole thing, and I asked about the "C" word (Constitution).  I simply said that some of us had pledged to uphold the Constitution, and the reason why *individuals* make such pledges is that they are expected to understand the Constitution well enough to make their own assessment about possible unconstitutional activities and refuse to engage in those activities.  Recall that "simply following legal orders" didn't absolve anyone at Nurenburg, so trusting these 5i's to interpret Constitutionality isn't going to be much of a defense, either.
BTW, the "Lawfare" blog is about as close as one can get to "the unclassified (apologist) voice of the Deep State" & I suspect that Ben Wittes would consider this tag line to be high praise!
It seems to me that part of the problem with this debate on the side of those who argue for "no backdoors" is that they refuse to actually engage with the arguments of the other side. The above seems to be a good example of this.
FWIW, I don't know who you count as an "actual crypto person" but I spoke to two people who publish regularly at the Crypto conference who attended. And I would count Josh Benaloh as an "actual crypto person" as well, whether I agree with his opinions or not. And since the workshop was co-located with the Crypto conference, it was open to anyone who wanted to attend.
If you read Benaloh's post, you will see that he comes out firmly against law-enforcement access.
What I did say at this conference was that the actual crypto folks in the other rooms were way too busy simply making crypto work *at all*, much less handle this additional impossible-to-build-or-even-specify feature.  Real crypto folk were hard at work handling Spectre, among other problems, which will be haunting all of us for at least the next decade.
What I didn't say, but probably should have, was that only ~20 nanometers and a very tenuous layer of encryption protected the cellphones in *their own pockets* from being compromised, which could allow a hacker to cause the cellphone battery to overheat and explode right next to their genitals.  It would have been interesting to see how long it took these encryption-diluters to remove their cellphones from their pants pockets!
That's my main source of concern: multiple orders of magnitude of misplaced priorities.  Wouldn't it be nice to get more than one step ahead of crappy software and crappy hardware before wasting even one nanosecond "nerding harder" on undecidable tasks?
The U.S. government cannot protect itself -- e.g., OPM, its own hacking tools, etc. -- much less its own citizens.  We U.S. citizens are *totally on our own* when we venture onto the Internet with our mobile phones, our desktop computers, our home thermostats, our home spying^H^H^H^H^H^Hsecurity systems, OK Natasha^H^H^H^H^H^H^HAlexa, our heart defibrillators, etc.  To add insult to injury, not only are U.S. citizens left totally defenseless, our government wants to make it even easier for "bad actors" to bypass what little encryption security that we currently have.
I'm surprised that no one has yet raised the possibility of a *Second Amendment* argument for preserving strong encryption security.  After all, "arms" have traditionally included *defense* -- i.e., armor -- as well as *offense*.  If the government traditionally tried to regulate encryption as an "armament", then ordinary citizens should be able to utilize the same argument under the Second Amendment to have unbreakable encryption.  After all, it is highly unlikely that a bad actor from Russia, China, Iran, N Korea, etc., will be breaking into our homes in the middle of the night, but it is *certain* that all of these bad actors are already breaking into our network accessible devices *thousands of times per second*.  We may not need that AR-15 for most normal circumstances, but we sure as heck need the best encryption that the best cryptographers can provide us on a continual basis.

@_date: 2018-12-08 12:32:19
@_author: Henry Baker 
@_subject: [Cryptography] What if (ir)Responsible Encryption Back-Doors 
Why don't we call a spade a spade?
The proper term is "IRresponsible encryption", since it opens up a
vulnerability to essentially *everyone*, regardless of their situation
or culpability.  But, of course, this proposal follows the age-old
rule that the *name of a bill/law* is precisely the opposite of its
intended purpose, which is why everyone thinks that legislators are
all liars.
Re: "2) No one wants to be in a position where a mass murderer has
encrypted data that cannot be revealed to law enforcement"
Joe Stalin said "a single death is a tragedy; a million deaths is a
We've seen Stalin's rule operate recently with the murder of Khashoggi,
where the press is all up in arms about a single murder, when more
than 50,000 people have already died as a result of Saudi's attacks
in Yemen.  Apparently, more than just one person thinks that there
are 110 billion reasons why 50,000 people don't matter.
To better understand the FBI's "mass murderer" fetish, you also
have to understand the concept of *bootleggers and Baptists*, as
explained by Bruce Yandle to Russ Roberts on his Econtalk podcast
back in 2007.
Basically, Prohibition was made possible in 1919 by a combination
of the interests of bootleggers (who would make huge profits from
the lack of legal competition) and Baptists (who don't believe in
drinking alcohol).  While the reality was more complicated than
this, "bootleggers and Baptists" has become the label for strange
bedfellows who get together to pass a law otherwise unthinkable
for the rest of the population.  Thus, the bootleggers put forward
Baptists to carry their water, because no one is going to (publicly)
support bootleggers. Another similar situation was that of mothers who voted for Wilson
in 1916 because "he kept [our sons] out of war (so far)" (yes, women
were allowed to vote in 6 western states; see Michael Beschloss's
book on Presidents of War).  Alice Paul, the radical suffragette,
effectively traded her support for Wilson's war for Wilson's
support for the 19th Amendment -- she presumed that the ~117k
deaths and ~320k wounded were costs worth paying for its passage.
Yet another example is that of U.S. gun deaths, where ~34k people
were killed in 2013, *2/3's of which were suicides*.  To keep
things in perspective, ~33k people died in auto accidents in 2013.
Yet gun control advocates continue to inflate gun deaths with
suicide statistics, while simultaneously voting against physician-
assisted suicide.
The FBI and its apologists are attempting to use Joe Stalin's
rule and create a "Megan's Law" for encryption backdoors by pulling
out a single sympathetic individual to sway public opinion, when
the losers from such are *all the rest of us*.  The plural of
"anecdote" is not "data" !  (The plural of "backdoor" is not
"responsible" ?!?)
The FBI is also playing the Baptist for the Deep State "bootleggers"
who want to continue unrestricted & unwarranted mass surveillance.
Such bootleggers include the subject of a now-playing movie which
just won 6 Golden Globe nominations, and a judge who recently joined
the Supreme Court.
We're currently asking the designers of autonomous vehicles to
solve the "Trolley Problem", wherein a runaway trolley (or
autonomous vehicle) gets into a situation where 1 or 5 people
will die, and the autonomous vehicle must decide who will die.
Yet legislators themselves continuously pass laws which benefit
a vanishly small percentage of the electorate, while disadvantaging
everyone else.
I'm sorry, but the tradeoff of making billions of cellphones,
laptops, routers, and other IoT devices vulnerable to save a
handful of people isn't worth it; among other reasons, we can
be sure that the vulnerabilities themselves will cause
additional deaths -- dead reporters, dead dissidents, dead
spies, etc.
One supreme court justice is supposed to have suggested that a
flush toilet is the drug dealer's best friend.  Yet not even
the FBI is suggesting that toilet manufacturers include a
"back door" in every toilet to catch a handful of drug dealers.

@_date: 2018-12-08 22:56:24
@_author: Henry Baker 
@_subject: [Cryptography] Decrypting the Encryption Debate 
This report is a pretty decent review of the current situation.
The sad part: the word "Constitution" appears only 7 times, "Fourth
Amendment" (unreasonable search & seizure) appears only twice, and
"Fifth Amendment" appears only 7 times (?!?).  The Third Amendment,
which governs the extent to which individuals are required to supply
resources (presumably including computer code & computer cycles)
for military purposes, is not mentioned, nor is the Second
Amendment, which provides for the right of the people to keep and
bear Arms [presumably also defensive arms -- e.g., *armor* and
therefore *encryption*], is also not mentioned.
The First Amendment is mentioned but once in passing, although this
Amendment was used to defuse the first "encryption war".

@_date: 2018-12-09 07:19:36
@_author: Henry Baker 
@_subject: [Cryptography] Assistance and Access Bill 2018 FAQ (Australia) 
Here are some questions:
1.  Is there a problem?
Yes, there are law enforcement professionals who *say* there is a problem, but where is the evidence that there actually *is* a problem?
Answering this question should have an extremely high bar, as *every proposed "solution" causes immense damage to everything a free society holds dear*:
* civil liberties
* free speech
* free association
* permissionless action
* federalism/decentralization
2.  If there is a problem, is this an important problem relative to other problems you face?
Every society faces an overwhelming number of problems crying for attention and resources.  Not every problem can be addressed with the same level of urgency, the same level of resources, or the same level of attention.  Therefore, everyone must prioritize which problems to solve, based upon urgency and expected ease/cost of solution.
For example, cyber hacking, phishing, identity theft, etc., are extraordinarily urgent problems, causing immense damage to *every person*, *every day*, *every device*.  IMHO this urgency is many orders of magnitude more severe than the inability of law enforcement to read the contents of a handful of cellphones.
Once again, the answer to this question must be a very high bar, else society wastes huge resources -- including *opportunity costs* -- chasing the wrong problems.
3.  If there is a problem, have you characterized the problem correctly?
Any potential solution will be seen in the lens of this characterization, so it is critical that this characterization be accurate.  Which is the right question: "Is the house too cold?" or "Is the clothing too warm?" or "Do you have a thyroid disorder?".
4.  If there is a problem, do you have any idea what the causal relationships in the environment/system are?
You can't possibly propose a "solution" to a problem, if you don't understand the causal relationships.  For example, changing the thermostat setting in one room may have *zero effect* on the temperature in another room -- and may even have a *negative effect* if the proposed solution means that the heat must be diverted from one room to another.
5.  If there is a problem, and someone proposes a solution, does it actually work without killing the patient?
The Hippocratic Oath admonishes: "First, do no harm!!".  The politician's oath is: "First, DO something [who cares whether or not it works, and whether or not it does more harm than doing nothing]".  A doctor who followed the politician's oath would quickly find his patients all dead, himself/herself without liability insurance, and himself/herself behind bars.
President Obama often cautioned: "Don't do stupid stuff" -- advice he should have listened to himself more often, and advice that never penetrated the skulls of his own partisans.  The overwhelming desire to "DO something" completely destroyed any sanity: "we have to pass the bill so you can find out what's in it".

@_date: 2018-12-10 06:42:02
@_author: Henry Baker 
@_subject: [Cryptography] Decrypting the Encryption Debate 
I laughed out loud when I read this quote from page 92, where the
author (or his/her spelling corrector) makes this Freudian slip/Kinsley
"Any measure for ensuring government access to plaintext is liable to
be misused, whether accidentally or deliberately. ... It is therefore
important that the approach be subject to effective and continuing
evaluation and oversight and include a robust and assured audit
mechanism that supports detection of misuse ... This will help
... guard against relying on and investing ***scare*** resources in
approaches that do not work ..."
The FBI's "scare resources" are apparently in short supply ...
A Kinsley gaffe occurs when a political gaffe reveals some truth that
a politician did not intend to admit.  The term comes from journalist
Michael Kinsley, who said, "A gaffe is when a politician tells the
truth -- some obvious truth he isn't supposed to say."

@_date: 2018-02-01 05:23:48
@_author: Henry Baker 
@_subject: [Cryptography] Spectre/Meltdown resistant 'Movfuscator' ? 
FYI -- Comments at bottom
This CPU Exploit-Safe Version of 'Doom' Runs at .00003 FPS
One way to defend against Spectre and Meltdown.
Michael Byrne
Jan 30 2018, 5:00am
The Spectre and Meltdown CPU exploits, which allow data to leak from
highly secure parts of a computer to really wherever, are bad because
they have to do with something pretty fundamental in how modern
computer processors work.  This is a feature called branch prediction,
which basically means that a CPU might process data before it's
actually needed in situations where a program has to make a decision
to do one thing instead of another thing, which is called branching.
Here's a whole thing on how that works in terms of Spectre and
Meltdown.  For now, just understanding that branching is pretty
important to how computer programs work but it can also lead to
optimizations that are insecure.  One extreme solution might be
removing branching from computer programs altogether.  Make software
entirely, 100 percent deterministic.
That's what Github user xoreaxeaxeax did to Doom.  Their version of
the game is branchless and relies on just a single machine
instruction.  There's no branching, or even arithmetic: The only
processor command it contains is "mov", which scoots data from memory
address to memory address.  It's actually a demonstration of
xoreaxeaxeax's more general C compiler, the M/o/Vfuscator2, which
converts commands in the C programming language into machine-level
instructions.  Or, in this case, instruction, singular.
The downside of this is that the resulting machine instructions are
spectacularly inefficient.  Single-instruction, branchless Doom
renders a single frame every seven hours on a 386 Intel processor.
Security ain't free.
This Motherboard article claims that this scheme of compiling into only "MOV"
instructions avoids the problems of Spectre & Meltdown.
Yes, it avoids branch instructions, but no, it doesn't avoid cache timing
leaks.  Indeed, since it heavily uses *table lookup*, it leaks *far worse*
than normally compiled code.

@_date: 2018-02-11 11:16:43
@_author: Henry Baker 
@_subject: [Cryptography] Aharonov-Bohm effect 
Actually, the Aharonov-Bohm effect is one of the major reasons why building a decent quantum computer is going to be extremely difficult: precisely because it's nearly impossible to *shield* a QM from outside influences which disturb and "collapse" the superposition effects.
Perhaps quantum error-correcting codes are the *only* way to effectively "shield" a QM?

@_date: 2018-02-25 08:42:15
@_author: Henry Baker 
@_subject: [Cryptography] Rolling code "Hello World" 
I wanted to demonstrate rolling codes with the simplest Linux "Hello World" crypto program.
Critiques?  (No nasty remarks re Lispy formatting!)
  MYINC(n) ((2*n)%13)
int main(void)
{ unsigned int ctr=1,input=0;
  printf("Alice starting: ctr=%u\n",ctr);
  while (scanf("%u",&input)==1)
    { printf("Alice: input=%u ctr=%u",input,ctr);
      if (input==ctr) {printf(" ok\n"); ctr=MYINC(ctr);}
      else if (input==MYINC(ctr)) {printf(" uh, ok\n"); ctr=MYINC(MYINC(ctr));}
      else printf(" probably Mallory; ignored\n"); } }
  MYINC(n) ((2*n)%13)
int main(void)
{ char ch=0; unsigned int ctr=1, malloryctr=0;
  fprintf(stderr,"Bob starting: ctr=%u\n",ctr);
  while ((ch=getchar()) && (ch!=EOF))
    switch (ch)
      { case 'b':
        case 'o':
        case 'm':
  fprintf(stderr,"Bob: quitting...\n"); }
% ./bob | ./alice

@_date: 2018-02-27 05:19:43
@_author: Henry Baker 
@_subject: [Cryptography] Bitcoins and lobbyists 
(I'm going to use the term "Bitcoin" here as the best-known examplar of many block-chain-based cryptocurrencies.)
I was listening to a radio program where an investigative reporter was describing the (laborious) process by which she traced campaign contributions using the various disclosure statements required by the U.S. government.
It occurred to me that she was performing -- by hand -- many of the same steps that a Bitcoin miner has to perform, by tracing the sources and sinks of the various money flows through individuals, corporations, LLC's, law firms, etc.
If these money flows had all been Bitcoin-based, her job would have been trivial: the government would simply require the disclosure of the Bitcoin addresses of the various participants, and the Bitcoin miners (and the various Bitcoin tracing technologies) would do the rest.
Thus, instead of *resisting* Bitcoins & blockchain technologies, perhaps democracies interested in "open" governments should *embrace* Bitcoins, and indeed, *require* Bitcoins for all lobbying transactions.
Thus, the "Fourth Estate" -- the press -- performs "mining" for the control of democratic governments themselves.
Thomas Carlyle and Edmund Burke would have approved.

@_date: 2018-02-27 13:47:38
@_author: Henry Baker 
@_subject: [Cryptography] Bitcoins and lobbyists 
Bitcoin mining accomplishes two useful tasks:
1) continual consistency checking of the entire blockchain and
2) mining lottery winners extend the blockchain & collect modest fee
Task  -- together with Bitcoin address identification -- makes transaction tracing trivial.

@_date: 2018-02-27 17:55:32
@_author: Henry Baker 
@_subject: [Cryptography] Bitcoins and lobbyists 
A lot.  You might start by reading my original post:
"If these money flows had all been Bitcoin-based, her job would have been trivial: the government would simply require the disclosure of the Bitcoin addresses of the various participants, and the Bitcoin miners (and the various Bitcoin tracing technologies) would do the rest."
The various government disclosure forms already exist; but as you point out, they aren't terribly useful w/o requiring the disclosure of Bitcoin addresses.
The FEC already gets to paw through the various campaigns, and registered lobbyists would have to disclose their Bitcoin addresses in their disclosure forms.
Add another line to the various 501 tax filing forms, and you start to get a decent picture.

@_date: 2018-02-27 20:58:46
@_author: Henry Baker 
@_subject: [Cryptography] Bitcoins and lobbyists 
It's quite simple: all of the Bitcoins coming into a Representative's, Senator's or President's campaign have to come from somewhere traceable, else they can't be spent -- and could be subject to confiscation (aka 100% taxable) w/o proper identification (banks already have "know your customer" rules).  The Bitcoins going out from the campaign also have to go somewhere traceable, else they're not legal expenditures.
The blockchain makes these incoming and outgoing transfers quite transparent, once you know the campaign's own Blockchain address.
I don't know the specifics of existing FEC laws, but there are plenty of these laws on the books; the problem is enforcing these laws.

@_date: 2018-01-02 16:10:27
@_author: Henry Baker 
@_subject: [Cryptography] Speculation re Intel HW cockup; 
FYI --
'Kernel memory leaking' Intel processor design flaw forces Linux, Windows redesign
Other OSes will need an update, performance hits loom
By John Leyden and Chris Williams 2 Jan 2018 at 19:29
A fundamental design flaw in Intel's processor chips has forced a significant redesign of the Linux and Windows kernels to defang the chip-level security bug.
Programmers are scrambling to overhaul the open-source Linux kernel's virtual memory system.  Meanwhile, Microsoft is expected to publicly introduce the necessary changes to its Windows operating system in an upcoming Patch Tuesday: these changes were seeded to beta testers running fast-ring Windows Insider builds in November and December.
Crucially, these updates to both Linux and Windows will incur a performance hit on Intel products.  The effects are still being benchmarked, however we're looking at a ballpark figure of five to 30 per cent slow down, depending on the task and the processor model.  More recent Intel chips have features -- specifically, PCID -- to reduce the performance hit.
Similar operating systems, such as Apple's 64-bit macOS, will also need to be updated -- the flaw is in the Intel x86 hardware, and it appears a microcode update can't address it.  It has to be fixed in software at the OS level, or buy a new processor without the design blunder.
Details of the vulnerability within Intel's silicon are under wraps: an embargo on the specifics is due to lift early this month, perhaps in time for Microsoft's Patch Tuesday next week.  Indeed, patches for the Linux kernel are available for all to see but comments in the source code have been redacted to obfuscate the issue.
However, some details of the flaw have surfaced, and so this is what we know.
It is understood the bug is present in modern Intel processors produced in the past decade.  It allows normal user programs -- from database applications to JavaScript in web browsers -- to discern to some extent the contents of protected kernel memory.
The fix is to separate the kernel's memory completely from user processes using what's called Kernel Page Table Isolation, or KPTI.  At one point, Forcefully Unmap Complete Kernel With Interrupt Trampolines, aka FUCKWIT, was mulled by the Linux kernel team, giving you an idea of how annoying this has been for the developers.
Whenever a running program needs to do anything useful -- such as write to a file or open a network connection -- it has to temporarily hand control of the processor to the kernel to carry out the job.  To make the transition from user mode to kernel mode and back to user mode as fast and efficient as possible, the kernel is present in all processes' virtual memory address spaces, although it is invisible to these programs.  When the kernel is needed, the program makes a system call, the processor switches to kernel mode and enters the kernel.  When it is done, the CPU is told to switch back to user mode, and reenter the process.  While in user mode, the kernel's code and data remains out of sight but present in the process's page tables.
Think of the kernel as God sitting on a cloud, looking down on Earth.  It's there, and no normal being can see it, yet they can pray to it.
These KPTI patches move the kernel into a completely separate address space, so it's not just invisible to a running process, it's not even there at all.  Really, this shouldn't be needed, but clearly there is a flaw in Intel's silicon that allows kernel access protections to be bypassed in some way.
The downside to this separation is that it is relatively expensive, time wise, to keep switching between two separate address spaces for every system call and for every interrupt from the hardware.  These context switches do not happen instantly, and they force the processor to dump cached data and reload information from memory.  This increases the kernel's overhead, and slows down the computer.
Your Intel-powered machine will run slower as a result.
How can this security hole be abused?
At best, the vulnerability could be leveraged by malware and hackers to more easily exploit other security bugs.
At worst, the hole could be abused by programs and logged-in users to read the contents of the kernel's memory.  Suffice to say, this is not great.  The kernel's memory space is hidden from user processes and programs because it may contain all sorts of secrets, such as passwords, login keys, files cached from disk, and so on.  Imagine a piece of JavaScript running in a browser, or malicious software running on a shared public cloud server, able to sniff sensitive kernel-protected data.
Specifically, in terms of the best-case scenario, it is possible the bug could be abused to defeat KASLR: kernel address space layout randomization.  This is a defense mechanism used by various operating systems to place components of the kernel in randomized locations in virtual memory.  This mechanism can thwart attempts to abuse other bugs within the kernel: typically, exploit code -- particularly return-oriented programming exploits -- relies on reusing computer instructions in known locations in memory.
If you randomize the placing of the kernel's code in memory, exploits can't find the internal gadgets they need to fully compromise a system.  The processor flaw could be potentially exploited to figure out where in memory the kernel has positioned its data and code, hence the flurry of software patching.
However, it may be that the vulnerability in Intel's chips is worse than the above mitigation bypass.  In an email to the Linux kernel mailing list over Christmas, AMD said it is not affected.  The wording of that message, though, rather gives the game away as to what the underlying cockup is:
AMD processors are not subject to the types of attacks that the kernel page table isolation feature protects against.  The AMD microarchitecture does not allow memory references, including speculative references, that access higher privileged data when running in a lesser privileged mode when that access would result in a page fault.
A key word here is "speculative."  Modern processors, like Intel's, perform speculative execution.  In order to keep their internal pipelines primed with instructions to perform, the CPU cores try their best to guess what code is going to be run next, fetch it, and execute it.
It appears, from what AMD software engineer Tom Lendacky was suggesting above, that Intel's CPUs speculatively execute code potentially without performing security checks.  It seems it may be possible to craft software in such a way that the processor starts executing an instruction that would normally be blocked -- such as reading kernel memory from user mode -- and completes that instruction before the privilege level check occurs.
That would allow ring-3-level user code to read ring-0-level kernel data.  And that is not good.
The specifics of the vulnerability have yet to be confirmed, but consider this: the changes to Linux and Windows are significant and are being pushed out at high speed.  That suggests it's more serious than a KASLR bypass.
Also, the updates to separate kernel and user address spaces on Linux are based on a set of fixes dubbed the KAISER patches, which were created by eggheads at Graz University of Technology in Austria.  These boffins discovered [PDF] it was possible to defeat KASLR by extracting memory layout information from the kernel in a side-channel attack on the CPU's virtual memory system.  The team proposed splitting kernel and user spaces to prevent this information leak.  Their work was reviewed by Anders Fogh, who wrote this interesting blog post in July.
That article described his attempts to read kernel memory from user mode by abusing speculative execution.  Although Fogh was unable to come up with any working proof-of-concept code, he noted:
My results demonstrate that speculative execution does indeed continue despite violations of the isolation between kernel mode and user mode.
It appears the KAISER work is related to Fogh's research, and as well as developing a practical means to break KASLR by abusing virtual memory layouts, the team may have proved Fogh right -- that speculative execution on Intel x86 chips can be exploited to access kernel memory.
Shared systems
The bug will impact big-name cloud computing environments including Amazon EC2, Microsoft Azure, and Google Compute Engine, said a software developer blogging as Python Sweetness in this heavily shared and tweeted article on Monday:
    There is presently an embargoed security bug impacting apparently all contemporary [Intel] CPU architectures that implement virtual memory, requiring hardware changes to fully resolve.  Urgent development of a software mitigation is being done in the open and recently landed in the Linux kernel, and a similar mitigation began appearing in NT kernels in November.  In the worst case the software fix causes huge slowdowns in typical workloads.
    There are hints the attack impacts common virtualisation environments including Amazon EC2 and Google Compute Engine...
Microsoft's Azure cloud -- which runs a lot of Linux as well as Windows -- will undergo maintenance and reboots on January 10, presumably to roll out the above fixes.
Amazon Web Services also warned customers via email to expect a major security update to land on Friday this week, without going into details.
There were rumors of a severe hypervisor bug -- possibly in Xen -- doing the rounds at the end of 2017.  It may be that this hardware flaw is that rumored bug: that hypervisors can be attacked via this kernel memory access cockup, and thus need to be patched, forcing a mass restart of guest virtual machines.
A spokesperson for Intel was not available for comment.
Wouldn't this be a good time to think about putting x86 & x86-64 out of everyone's misery?
Have there been any *clean sheet* architecture designs since the Snowden revelations?
Clearly, Intel was spending so much time implementing backdoors "for management purposes" (wink, wink), that they didn't have time to work on protecting the poor lusers.

@_date: 2018-01-03 19:21:56
@_author: Henry Baker 
@_subject: [Cryptography] Software patent lifetimes are the problem (Re: 
This is the party line re patents, but the party line is wrong.
Patents were originally invented by kings who needed money to fight wars of ego; selling someone an artificial (state-enforced) monopoly allowed the buyer to charge monopoly "rents" and thus recoup his payment to the king many times over, while the king was happy with his "don't dare call them taxes" loot.  Patents were never born on the high moral ground; indeed, some might say the exact opposite.
Later, during the "Enlightenment", those rent-seekers ("rentiers") wanting patent monopolies developed better branding and public relations, and thus the concept of granting patents in exchange for disclosure was born.  But this was merely an artificially-contrived excuse for a *theory*, and was *never scientifically tested*.  Indeed, the concept that patents encourage innovation (and hopefully more taxable income for the state) has about the same scientific basis as bleeding to cure various diseases.
Depending upon your degree of respect for our Founding Fathers and their reasons for the incorporation of patents into the Constitution, these Founding Fathers were either woolly-headed idealists who were tricked by the branding and the PR, or, more likely, just ordinary politicians putting loopholes into the laws and constitutions for later exploitation.  Since both Franklin and Jefferson were ardent inventors, I'm inclined to label Franklin as the idealist and Jefferson as the politician.
The length of time for the monopoly isn't the problem; the problem is making the false "intellectual property" analogy to *real property* in the first place.  Real property is made of *fermions*: real property takes up space and is therefore essentially *incompressible* (ask any neutron star).  Gold and silver incorporate fermions; these elements demonstrate the conservation of matter, which make them useful as money.
So-called "intellectual property" isn't property at all, but *bits* which can be trivially copied without error; if you need a physical analogy, try *bosons* -- e.g., photons.  [Yes, I know about the no-cloning theorem; I'm not trying to argue q-bits here.  I'm also not trying to argue about cryptocurrencies, which are mathematical constructs guaranteed to force everyone to treat their elementary "coins" as if a conservation law exists.]
Jefferson fully understood the difference: "He who receives an idea from me, receives the instruction himself *without himself lessening mine;* as he who lights his taper at mine, receives light without darkening me."
Jefferson, as politician, sold out, while Franklin realized the true nature of innovation: it is a *network effect*, whose value increases with the number of people who understand and use it; excluding people from its use *actually slows innovation and its economic benefits*.
[Best recent example: 3D printing.  It only captured the imagination of the public after the major early patents expired.  This close temporal succession is not a coincidence.]

@_date: 2018-01-04 07:30:51
@_author: Henry Baker 
@_subject: [Cryptography] Speculation considered harmful? 
As the horror of the profound vulnerability of nearly the entire installed base of x86 chips starts to sink in, manufacturers are starting to downplay the effect of fixes on system performance.
The reason I say "downplay" is that computer hardware isn't the only place where speculation is utilized in computer science -- or indeed in society at large.
Speculation is an extremely comman, and an entirely human, reaction to *latency*.  If the latency of some operation is too long, we pretend that the most common case is occurring and try to fix things later if/when we find out that we've been wrong.  (Indeed, evolution works precisely *because of speculation*.)
Thus, if we are copying a 10 GByte object using a tight loop, the chances of the loop continuing rather than stopping are 99.9999999%.  As I have argued sardonically in the past, most economic systems with 9 "9's" would have optimized away the stopping condition entirely; computer code compilers can't be allowed to do this!  So we are willing to do quite a lot of work to "undo" any mess that a flawed assumption might create, if the probability of making flawed assumptions is low enough.
This is called "optimistic concurrency control", and it is used *all over the place* -- not just inside of computer operating systems.
Every economic system utilizes the same trade-off: shutting down a factory is an incredibly chaotic mess, but with overwhelming probability the factory will continue producing day after day, so we optimize for that case.
Indeed, the 2009 financial crisis was deepened and lengthened by the (probably correct) assumption that if the banking system were allowed to shut down, the resulting chaos might just be worse than attempting to fix the system.  Unlike the situation that Intel/AMD/ARM now face, the U.S. Federal Reserve System was unwilling to take that risk, and we will continue to pretend that our financial system is sound.
The problem with eliminating speculation, though, is that it interacts *substantially* with security and privacy.  Our entire "free" society is built on the assumption that the vast majority of people will be good, and that the bad people can be (messily) rooted out before the harm that they cause becomes catastrophic.  We consciously made a trade-off between the efficiency gains from free people determining their own actions versus the heavy hand of a government intent on smothering any small ripple of chaos.
President Eisenhower said it best: "If you want total security, go to prison.  There you're fed, clothed, given medical care and so on.  The only thing lacking ... is freedom."
Our credit card system was originally based upon *trust*, which is a form of limited speculation.  Everyone in the system, from banks to merchants to card-holders assumed that the vast majority of transactions would be legitimate, and that the various fees would offset the small % of losses.  It's hard to imagine in this era of ubiquitous connectivity that there was initially *no* real-time validation of credit card charges!  However, over time, connectivity became better and better (every credit card terminal acquired a telephone or satellite modem), and so today nearly all such transactions are checked in real time.
Only in the 20th and 21st centuries have we had the luxury of speed-of-light communications and sub-second latencies, so that we can often replace *optimistic* concurrency control with *pessimistic* concurrency control.
When an ancient Roman general took his army over the horizon, he might be out of contact for *months*, so pessimistic concurrency control simply wasn't an option.  If he screwed up, the only option was to send *another general and another army* over the horizon to repair the damage that the first general and army had caused.
Ditto for 15th century sea captains.
NASA has the same problem with its various robot spacecraft -- multi-minute or multi-hour latencies simply don't allow "hovering helicopter management"; expect upcoming interplanetary economic systems to re-learn old lessons on speculation.
So now the question remains: how can we construct computer systems which enjoy the benefits of speculation without enabling wholesale compromise?
It isn't going to be easy, as there isn't a simple fix.
So-called "two phase commit protocols" attempt to gather all the information and resources necessary to *complete* a transaction prior to "committing" the transaction.  If the transaction can't be completed, than it must need to be "rolled back" -- a process of *undoing* any actions that were done during the gathering phase.
There's only one slight problem: you can't unring a bell: you can't "unlearn"/"forget" a bit that you learned during the gathering phase.  Or more precisely, you can't force a party to the transaction to forget such bits.
I don't have a clean solution to this "forgetting" problem, and I doubt that anyone else does, either.
We have similar "Ben Franklin" problems in crypto all the time: "three may keep a secret, if two of them are dead".  We can't shred entire computers every time an optimistic transaction must be rolled back.
Perhaps Zero Knowledge protocols may point the way towards a solution.  I'm not optimistic.

@_date: 2018-01-04 08:55:40
@_author: Henry Baker 
@_subject: [Cryptography] Crypto for optimistic transactions ? 
As I pointed out in my previous posting, there is no "undo" for learning a bit of information, so it is *impossible* to truly "roll back" an optimistic transaction if that bit is inadvertently disclosed during the negotiation.
So is there a role for crypto in solving this problem?
Is there a way to use crypto to "escrow" any knowledge gained during the first ("negotiation"/"gathering") phase of a transaction in such a way that if the transaction never commits, the knowledge is never transmitted to the parties to the transaction?
Presumably, the information is to be used in the transaction is encrypted & signed, but the keys are escrowed until the transaction commits.  But we can't take a chance on a malicious participant, so the signature still must be checked as part of the commit protocol.
For example, suppose that a computer memory is optimistically asked to provide the contents of some memory location, but the requestor has not been validated.  Could the memory "seal" these contents in an envelope and store it in an escrow ("shadow") register, which can only be decrypted after the requestor has been validated?
Carl Hewitt and I addressed a similar problem in our 1977 paper "The Incremental Garbage Collection of Processes" which introduced the concept of a "future": an Algol-60-like "thunk" which had its own parallel computational power to speculatively evaluate an expression, but if the value of that expression was never required, these computational resources (CPU's, memory) would need to be recycled ("garbage collected") for reuse in subsequent computations.
A crypto scheme for enforcing the information-hiding in *abstract data types* might also work for enforcing secrecy on these "futures".  Then these same techniques should also work for enforcing secrecy during the negotiation phase of a 2-phase transaction protocol.
Perhaps someone in the crypto literature has already addressed this problem?

@_date: 2018-01-04 12:30:22
@_author: Henry Baker 
@_subject: [Cryptography] ROP gadgets => OOO gadgets == larger attack surface 
These Intel/AMD/ARM issues are far worse than would first appear.
According to one measurement, an architecture can speculatively *execute up to 188 instructions* (!!!!) before finally being brought down to earth.
Thus, in addition to traditional Return-Oriented Programming (ROP) gadgets, we can now search for Out-Of-Order (OOO) gadgets in a victim's code, thus increasing the attack surface enormously.  Unlike ROP gadgets, which terminate in a "return" instruction, OOO gadgets don't have to terminate cleanly at all; by the time the processor realizes it has gone down the garden path, the damage has already been done.
It's not clear what a proper mitigation might be; even going to the trouble of returning all caches to their previous state won't work -- in fact, it would seem to make the secret information even more obvious in power and timing side channels.
We're now facing the *padding* and *compression* problems in encryption protocols, but not just for programs doing crypto arithmetic, but *any*/*all* programs working with plaintext data.
Perhaps it's time to go back to "shared-nothing" architectures?

@_date: 2018-01-04 14:23:00
@_author: Henry Baker 
@_subject: [Cryptography] Speculation re Intel HW cockup; 
OK, I'll bite.
How would you do speculative execution "right" ?

@_date: 2018-01-05 07:39:54
@_author: Henry Baker 
@_subject: [Cryptography] Speculation re Intel HW cockup; 
Several problems with your proposal:
"Copy On Write" ("COW") assumes that *all effects can be reversed by restoring various register values*.  As I pointed out, once a bit has leaked, it's gone, and no amount of register restoring will force Eve to forget it.
Also, we're not talking about a handful of instructions here; we're talking about >100 instructions.  So perhaps tens of cache lines have been touched before the processor comes back to its senses.
As I pointed out elsewhere, restoring all of these cache lines may cause even more trouble, providing an even clearer side-channel signal for Eve to listen to.
BTW, as I also pointed out, software is not immune for exactly the same reasons.
Common Lisp has "UNWIND-PROTECT":
(unwind-protect  )
unwind-protect evaluates "protected-expression" and guarantees that "cleanup-expressions" are executed before unwind-protect exits, whether by "normal" evaluation or not.
CL's "unwind-protect" is intended to enable a *transaction using optimistic concurrency*: the "protected-expression" is the optimistic/speculative execution, while the "cleanup-expressions" provide the programmer the *opportunity* to *attempt* to "clean up" if/when things go wrong during the "protected-expression".
UNWIND-PROTECT acknowledges the fact that cleaning up the mess from a terminated computation isn't a trivial task, and only an intelligent programmer can figure out how to do this -- in particular, there's no way a compiler could figure out how to do this on its own.
Note that *all bets are off* if the "protected expression" produces output -- e.g., PRINT's to the console.  There is simply no way to "recall" that output.  Are you planning to shoot the user as part of the "cleanup-expressions" ?

@_date: 2018-01-05 08:22:18
@_author: Henry Baker 
@_subject: [Cryptography] Speculation re Intel HW cockup; 
only user-accessible programming interfaces were in "safe" Algol variants.  "Safe", until they weren't.  (The published attack on these systems was to take a tape with an executable on it to a system written by someone else which allowed diddling directly with the binary and changing the verified executable to "break the rules".  Side channels have always been there!)
+1 !
My first computer was an IBM 7040 with an IBM 1401 "I/O processor" to do card reading/punching, printing, etc.
My first (actually, second) 1401 program was to ditch the card output from pass 1 of the 1401 assembler, and utilize the 7040's (relatively larger) main memory as /tmp.  Speeded up 1401 assemblies by orders of magnitude !
It took IBM several more generations of computers before realizing that I/O was completely unprotected.

@_date: 2018-01-05 08:41:16
@_author: Henry Baker 
@_subject: [Cryptography] Speculation considered harmful? 
IBM chased instruction pipelining with the 360 Model 91, but then threw in the towel.
Caches were a heck of a lot cheaper and easier to debug than fancy instruction pipelining.
But caching on multiprogramming machines will *always* leak information.
In fact, *multiprogramming* will always leak information.
Example: If I'm a venture capitalist who utilizes an outside law firm to do deals, I suddenly notice that my law firm goes radio silent from time to time.  This "radio silence" leaks information to me.
1.  The law firm could be hard at work on a competitor's deal, so they don't have time to work on my deal.
2.  (Even worse) The law firm has developed a *conflict of interest* and can't work with me until it gets resolved.
If I want, I can additionally probe the law firm myself, or even better, have a third party probe the law firm with various requests for service which will reveal additional information about whether any particular lawyer is busy, or what is the nature of the conflict of interest.
These scenarios translate directly into HW analogies within a computer architecture.
(Spouses/lovers utilize the same techniques to discover "two-timing"; it's difficult to be 2 places at once, or to fully focus on multiple lovers.)

@_date: 2018-01-05 08:46:55
@_author: Henry Baker 
@_subject: [Cryptography] Speculation considered harmful? 
Yes, but in order to check the permissions, you might have to first load something into the TLB cache.  But then this TLB cache leaks information, albeit at a reduced resolution and hence bandwidth.

@_date: 2018-01-06 07:50:16
@_author: Henry Baker 
@_subject: [Cryptography] Caches considered harmful 
Bottom line: we're painfully repeating Santayana's lesson about history,
but in this case, the lessons learned from the *padding* and *compression*
attacks on encryption.  HW (and SW) caches are a form of compression (in
time) and therefore the timing side-channel leaks plaintext information
in a similar manner to compression attacks.
"Compression and Information Leakage of Plaintext
"John Kelsey, Certicom
"The compression side-channel differs from side-channels described in [Koc96] [KSHW00] [KJY00] in two important ways:
1. It reveals information about plaintext, rather than key material.
2. It is a property of the algorithm, not the implementation.  That is, ***any implementation of the compression*** algorithm will be equally vulnerable."
Of course, invoking Santayana is doubly ironic in the context of caching!

@_date: 2018-01-08 13:38:09
@_author: Henry Baker 
@_subject: [Cryptography] Faithful emulation preserves timing resistance? 
I'd be interested if anyone has done work relating
to this before.  Thx in advance.
While the concept of *emulation* is a core fundamental
principle in computer science, and Turing Machine
emulations of other Turing Machines provides the
basis of much of complexity theory and security
proofs, these same theorists have given short shrift
to the possibility of "real-time" emulation, or at
least "constant slow-down" emulation, whereby one
machine emulates another at a constant percentage

@_date: 2018-01-08 21:00:17
@_author: Henry Baker 
@_subject: [Cryptography] Speculation considered harmful? 
You knew the guys who invented music boxes ?
You knew the MIT Whirlwind guys and Maurice Wilkes ?  ;-)
They invented the first VLIW architectures, although their Very Long (microcode) Instruction Words couldn't be dynamically written.
I knew the Multflow VLIW company, but I would say that there were a lot of sophisticated things going on that went far beyond the simple idea of "very long word instructions".
The concept of "speculation" only becomes important when you have such an excess of hardware resources, that you bend over backwards trying to give them something to do -- the computer science version of Parkinson's Law.
The early time-sharing systems research concluded that there is a hard limit to how much "efficiency" you can get out of shared resources, after which the competing processes damage each other more than they gain.
Of course, computer scientists could simply have asked any economist (or even a mathematician or an army general): they have been aware for hundreds (thousands) of years that *slack resources* ("reserves" in army lingo) have significant value even when not currently being "used"/"consumed".
Of course, army reserves are constantly training, which might be the equivalent of computer hardware constantly running hardware diagnostic programs to make sure that nothing in the hardware is failing.

@_date: 2018-01-10 09:06:01
@_author: Henry Baker 
@_subject: [Cryptography] Speculation considered harmful? 
[Believe it or not, this post is relevant to the topic of speculation, but I'm not intending any political content.]
Senator Dianne Feinstein released the testimony from the "Fusion GPS" founder yesterday, because several of the Republican members of the Senate Judiciary Committee had already made public statements saying that they wouldn't vote against releasing it.  Therefore Senator Feinstein *speculated* that the release would be OK, and proceeded to release it prior to gaining permission from the Committee.
So I attempted to access this file using Tor and got the following error message:
'Access Denied
'You don't have permission to access " on this server.'
[Presumably, senate.gov doesn't want to serve up potentially embarrassing content to foreign requestors.]
Curiously, simply asking Tor for a "New Tor Circuit for this Site" resulted in yet another similar error message, but this time *the pdf file proceeded to download ANYWAY* !!
So Senator Feinstein and the senate.gov web site are both guilty of a Spectre-like speculation bug!

@_date: 2018-01-10 10:17:33
@_author: Henry Baker 
@_subject: [Cryptography] Flash paper is so last century 
Paper-based spies used to use flash paper to destroy encryption keys.
Perhaps *inkjet printed thermite* is the answer for 21st century devices?
As Crocodile Dundee might have said, "Now, *that's* a fusible link."
Inkjet Printed Thermite
What if the iPhone simply melted down after too many failed pin number attempts?

@_date: 2018-01-12 08:48:53
@_author: Henry Baker 
@_subject: [Cryptography] Spectre -- would an L0 for speculation-only help? 
IMHO the major problem is that your scheme handles only *one level* of speculation.
When you need to twiddle your registers for 200 instructions or more, you get very far down a multiplicity of garden paths.
In my experience, program sequences consist of large amounts of straight-line code or large thickets of conditional code.
It's essentially impossible to organize the conditionals in such a way to avoid exponential explosion of speculation.

@_date: 2018-01-12 11:18:31
@_author: Henry Baker 
@_subject: [Cryptography] Speculation considered harmful? 
Yet another situation where speculation is harmful...
Get explicit about sexual consent
Secured in the blockchain
Be the first one to have a LegalFling
Safe sex redefined
LegalFling is the first blockchain based app to verify explicit consent before having sex. Do's and dont's
LegalFling matches your sexual preferences with that of your fling, making the do's and dont's clear to both of you.
Blockchain based The LegalFling app verifies mutual consent.  Only the transaction hash is stored and timestamped in the blockchain, so your privacy is guaranteed.
Fully protected
Took a spicy video or photo?  You don't want that to go viral!  With LegalFling any leaking of footage is a breach of contract and easy to take to court.
About our app
LegalFling records sexual consent in a legally binding agreement, which is verifiable through the blockchain. Sex should be fun and safe, but nowadays a lot of things can go wrong.  Think of unwanted videos, withholding information about STDs and offensive porn reenactment.  While you're protected by law, litigating any offenses through court is nearly impossible in reality.  LegalFling creates a legally binding agreement, which means any offense is a breach of contract.  By using the Live Contracts protocol, your private agreement is verifiable using the blockchain and enforceable with a single click. Why do we need explicit sexual consent?
Safe sex is not only about using physical protection.  It's about consenting to what will happen in the bedroom.  dominated Twitter in 2017.  Sweden is going to implement a new law that requires explicit consent before sexual contact.  More countries are following their example.  Sex should not only be fun.  It should also be safe for everyone.  Asking someone to sign a contract before the fun starts is a little uncomfortable.  A simple swipe is easy as 1,2,3. LegalFling is also good to have around when your fling turns into something steady.  Think of a spicy photo or video you made with your partner.  You don't want that to go viral when the relationship ends.  We've added these as extra possible clauses one should consent with before the act, so your fun is not shared with the rest of the world afterwards. Awesome Features
LegalFling is launched with everything you need to have safe sex.  Amazing features to make it fun for everyone.  Check them out!
No hassle
Don't ruin the moment.  Asking to sign a contract to have sex can be akward.
Get sexual consent with a single tap.
Easy messaging
Requesting consent should be easy.
Send a Fling with WhatsApp, Telegram, Facebook Messenger or SMS. Privacy guaranteed
You don't want to share your Flings with the rest of the world.  All Flings are encrypted with the highest standard available. It's up to you how far you want to take it.  Set boundaries and configure your personal preferences.
Penalty clauses
Escalate a breach with a single tap, triggering Cease and Desist letters and enforcing penalty payments.
Group Flings
For some, one guy or girl just won't do.  That's why we've added the possibility to send a Fling request to multiple people. App screenshots
LegalFling allows you to request consent from any of your contacts.  Sit back and relax while your fling confirms. Easy as one, two, three
During a fun night you meet your fling.  Now it's time to get consent.  Does your fling really want to take it further?  Simply open the LegalFling app, scroll to your contacts and send a request.  Your sexual preferences, including your do's and don'ts are automatically communicated.
Are you into BDSM but your fling isn't?  LegalFling matches sexual preferences automatically, so you're immediately aware what your fling doesn't appreciate and will not consent to.
Hopefully you will not be needing this further down the road.  But just in case, feel safe knowing that there is a legally binding agreement.  Any violation can be dealt with quickly and privately.
Frequently Asked Questions
You might have a lot of questions about the App.  As it is still in a proof of concept phase we will stick to answering the most important ones.  Subscribe to our mailing if you want to be kept up to date on the progress of our project.
The application generates a Live Contract, which is a legally binding agreement.  Just remember, the app is about setting clear rules and boundries, not breaking them.  To which extent the contract holds up in court depends on your country of residence. Absolutely.  "No" means "no" at any time.  Being passed out means "no" at any time.  This is explicitly described in the agreement.  Additionally you can withdraw consent going forward through the LegalFling app with a single tap. Yes.  This app is also useful for long term Flings.  You can add an infinite duration on the contract in the 'settings menu'.  For a short term Fling you can limit the duration of the consent to a couple of hours.  The penalty clauses will remain intact after that, for your protection. Yes.  The minimum age to use the app depends on the minimum age to have sex in your country of residence. No, on the contrary.  Getting explicit consent and expressing your do's and don'ts before sex should be the norm, but it typically doesn't happen.  LegalFling is a fun and clear way to set the rules before play. We are currently working on the app.  It will be subject to approval by Apple and Google before it is available in the Google Play Store and App Store. Download App
The app will be available for Android and iOS when we have enough supporters for our Project.
About Live Contracts
Live Contracts can be used to digitize any kind of agreement from simple contracts to complete laws. LegalFling is a showcase for Live Contracts, demonstrating that an agreement doesn't have to be a 10 page document full of legal lingo that can only be enforced through lawyers.  A Live Contract is only shared between the parties involved, anchoring in the blockchain through hashing.  Rather than being a static document, you can interact with your Live Contract.  For example you can state that a cause has been breached.  Your application is able to understand the procedures described in the contract and automatically take actions like sending Cease and Desist letters.
We believe that Live Contracts can have a positive change on the world.  Accomplishing this requires mass adoption.  By tokenizing our license, we want to create an incentive for early adopters and a reward for the community that helps us push this technology.  LTO tokens are issued on the making them easy to hold and trade.
Copyright LegalFling All Rights Reserved Be the first one to have a LegalFling
Subscibe with your e-mail to be the first to receive the LegalFling app.
No wonder Saturday Night Live has gotten out of the parody business...
Is there an analog to Godwin's law re sex?
Surely, blockchains such as this should be called "**ckchains" ?
I'm anticipating LegalFling's "ICO": "Initial Consent Offering"!

@_date: 2018-01-12 13:48:36
@_author: Henry Baker 
@_subject: [Cryptography] Predictability for timing side-channel resistance 
I'm very much in favor of *timing predictability* as one component in defeating timing side-channels.
Presumably, the rationale is that a single piece of *software* can be *compiled* and run on many different architecture implementations *with "predictable timing"*.
If you think about this very much, you realize that the whole point of predictability is to enable a given piece of crypto (or privacy-sensitive) software which is timing-side-channel-resistant on one implementation will also be timing-side-channel-resistant on other implementations.
But then all compilers and all HW implementations must then forever be *lock-stepped* together, else we lose the efficiency of "code once", "run everywhere".  We could never improve the compiler or improve the hardware, without changing the timing and therefore losing *timing compatibility* with previous generations.
Perhaps a way out of this would be to decide on a given level of jitter, and then "strip" compile the software into a sequence of "more-or-less atomic sub-sequences", with *synchronization fences* between each two such sub-sequences.  These synchronization fences would *barrier synchronize* with a *real-time clock*.
Yes, the code would still execute slowly (albeit predictably), but slower code can also save on power!  :-)

@_date: 2018-01-15 18:21:02
@_author: Henry Baker 
@_subject: [Cryptography] Speculation considered harmful? 
I'm not that sanguine that all of these "speculation-related" bugs have been found.
The real world is full of speculation-related bugs, including the recent "Great Recession", caused in part by speculation in options on contrived synthetic financial instruments.
In its greatest generality, "speculation" is a form of probability distribution function "tail stuffing", whereby the *average* case cost is improved by small percentage points in exchange for larger costs in (hopefully rare) "tail" (aka corner) cases.  Speculation is particularly rewarding if/when you can simultaneously shift these larger costs to another party!
The paradigm economic example is "picking up pennies in front of a steam roller".
A company culture isn't defined by those fancy *mission statements* constructed by expensive consultants; it is defined by "who gets fired for which reason".
Up until recently, privacy and security were "hand waves" for computer architects; no CEO ever got fired for destroying customers' privacy or security, but they traditionally did get fired for poor computer performance.
Equifax has finally changed the calculus for CEO's of companies holding large amounts of customer information; there needs to be an equivalent computer company CEO firing before computer architectures finally get serious about privacy and security.

@_date: 2018-01-18 10:38:10
@_author: Henry Baker 
@_subject: [Cryptography] Speculation considered harmful? 
IMHO, one basic problem is that once you have data caching, array references can no longer be depended upon to execute in constant time.  This "feature" is used to extract private/secret info from other processes.
There used to be DSP's with instructions that you could utilize to *bypass the cache* -- both for loading and storing.  Although these instructions took longer, the processor could do other things in the time between the load and actually trying to utilize the result.
These *cache-bypassing* capabilities weren't put there for security or privacy, but for *efficiency* in real-time DSP operations.  If you knew you were operating on a very long vector of data values (i.e., so long that it couldn't possibly fit into the cache), then it would be pointless to poison the data cache with all of these values which the compiler (and/or programmer) knows will not be used again before finally being flushed, and there *IS* other valuable data in the cache that *will* be used -- e.g., by high speed interrupts.
Yes, there are DSP architectures with multiple registers sets, multiple caches, etc., for handling such real-time interrupts, but these architectures don't scale very well, and the software investment is usually not preserved when the next version of the chip comes out.

@_date: 2018-01-21 06:05:04
@_author: Henry Baker 
@_subject: [Cryptography] RISC-V isn't the answer 
Ok, so I've reviewed a number of discussions of
the RISC-V architecture, and my conclusion is that
RISC-V isn't going to be a "silver bullet" for
high security & privacy applications.
Apparently, the first to utilize RISC-V for high
security applications will be nVidia, who has
chosen RISC-V as the follow-on to their current
"Falcon" high security coprocessor.  Their Falcon
handles DRM'd media, so there are $billions at
stake if RISC-V replaces Falcon in new designs.
Although RISC-V was a "clean sheet" design in
2011 (?), a lot of water has gone under the
bridge since then (cough, Snowden, cough), and
I don't believe that RISC-V adequately
addresses all of the side-channel issues that
have been discovered in the mean time.
Once nVidia starts shipping chips with RISC-V
front-ends, it will be interesting to see how
quickly these processors get attacked.  (To my
knowledge, nVidia's current Falcon processor
has yet to be successfully attacked.)

@_date: 2018-01-22 06:30:05
@_author: Henry Baker 
@_subject: [Cryptography] RISC-V isn't the answer 
Timing side-channels, at least.
RISC-V caches aren't partitioned, or controllable in any other way to defeat timing attacks from one process against another process running on the same core.
As I said before, every plaintext compression attack can be translated into a timing attack against a processor with a cache, since the cache "compresses" the memory reference stream.  RISC-V does nothing to address (!) this issue.
I'm not interested in squashing bugs like Meltdown and Spectre one by one -- it's far too expensive.  We need to squash entire classes of bugs with one swat, and this means learning from experiences like plaintext compression attacks.

@_date: 2018-01-24 14:46:16
@_author: Henry Baker 
@_subject: [Cryptography] Liar Paradox Redux 
FYI --
NSA Deletes 'Honesty' and 'Openness' From Core Values (theintercept.com)
Posted by msmash on Wednesday January 24, 2018  from the closer-look dept.
An anonymous shares a report: The National Security Agency maintains a page on its website that outlines its mission statement.  But earlier this month, the agency made a discreet change: It removed "honesty" as its top priority.  Since at least May 2016, the surveillance agency had featured honesty as the first of four "core values" listed on NSA.gov, alongside "respect for the law," "integrity," and "transparency."  The agency vowed on the site to "be truthful with each other."  On January 12, however, the NSA removed the mission statement page -- which can still be viewed through the Internet Archive -- and replaced it with a new version.  Now, the parts about honesty and the pledge to be truthful have been deleted.  The agency's new top value is "commitment to service," which it says means "excellence in the pursuit of our critical mission."  Those are not the only striking alterations.  In its old core values, the NSA explained that it would strive to be deserving of the "gre
at trust" placed in it by national leaders and American citizens.  It said that it would "honor the public's need for openness."  But those phrases are now gone; all references to "trust," "honor," and "openness" have disappeared.
Thomas Groves, a spokesperson for the agency, said: "It's nothing more than a website update, that's all it is."
Is it just me, or are logicians Bertrand Russell and Kurt Goedel rolling in their graves?
A stopped clock is right twice a day...

@_date: 2018-01-28 13:45:17
@_author: Henry Baker 
@_subject: [Cryptography] INTC: Insecurities Inside; from trust to rust 
FYI --
Intel alerted computer makers to chip flaws on Nov 29
Total coincidence: That's the ***same day*** Chipzilla's CEO sold off his shares
By Rebecca Hill 25 Jan 2018 at 17:46
Intel quietly warned computer manufacturers at the end of November
that its chips were insecure due to design flaws, according to an
internal Chipzilla document.
French tech publication LeMagIT reported this week it had obtained a
top-secret Intel memo sent to OEM customers on November 29 under a
confidentiality and non-disclosure agreement, meaning the hardware
makers were banned from discussing the file's contents.
That date is about six months after the chip maker was warned in June
2017 about the blunders in its blueprints by researchers at Google and
university academics.
On Wednesday this week, LeMagIT's Christophe Bardy revealed the first
page of that 11-page document, titled "Technical Advisory", from the
Intel Product Security Incident Response Team.  It describes the
security vulnerabilities we now know as Meltdown and Spectre, and when
it planned to go public.
It stresses that the issue should remain absolutely confidential.
Recipients should "encrypt any sensitive details using our PGP key" if
they had "any questions, requests for technical details or proposed
coordination with other parties", the note added.
The flaws would be publicly disclosed in an Intel security advisory on
January 9, Intel said in its memo (failing to predict El Reg's scoop
on January 2.)
The date of the disclosure to OEMs is likely to raise eyebrows as it
happened on the same day Intel chief exec Brian Krzanich sold shares
in his company worth $25m before tax.
Intel has denied any impropriety, saying Krzanich's decision to sell
was part of a standard stock sale plan that had been organized in
At the end of November -- when the general public was none the wiser

@_date: 2018-01-28 17:19:44
@_author: Henry Baker 
@_subject: [Cryptography] US contemplating its p0wn Great FireWall for 5G 
FYI --
Secure 5G
The Eisenhower National Highway System for the Information Age.
The Information Domain is a Key Area of Competition
Goal: A network that reflects our principles
* Rule of Law
* Freedom of Speech
* Freedom of Religion
* Fair and Reciprocal Markets
Networks are the Dominant Competition Space
China is the Dominant Competitor
* China has achieved a dominant position in the manufacture and operation of network infrastructure
* China is the dominant malicious actor in the Information Domain
We are losing, but...
We Can Make a Fundamental Change
1.  We are now moving from 4G to 5G
2.  MUST take the opportunity to build it securely and go...
Otherwise, China will win
* Politically
* Economically
* Militarily
How Do We Flip the Script?
* Inspired Leadership has driven our most significant national accomplishments
 * Without Eisenhower there would be no Interstate
 * Without Kennedy there would be no space program
* Inspired leadership can build it
 * Assets: Frequency Spectrum, Technology and Talent
* Government and rural broadband provide the business case
* Tax reform is an accelerator
Businesses and citizens will choose to join the secure 5G Internet -- If you build it they will come
Benefits to the American People
* Information Domain Counter to Belt and Road
* Joint and coalition forces seamless Command and Control
* Creates Millions of Jobs and Trillions in Economic Growth
* Rural broadband gets done first!
Arena of Allied Cooperation
* Build secure 5G at home and abroad
* Japan all in
Information Age
* This is a requirement for American success
I just typed in the first few slides, but you can see that is a replay attack of the Federal takeover of all radio in WWI and the subsequent formation of "Radio Corporation of America" aka RCA.
Clearly, the NSA no longer wants to hide, but wants to actively ape China's Great Firewall and "stasi" all U.S. communications.

@_date: 2018-01-28 21:53:40
@_author: Henry Baker 
@_subject: [Cryptography] US contemplating its p0wn Great FireWall for 5G 
The rest of the text (to make it searchable)...
Today's information space is complex.  Data traverses cyberspace through a patchwork transport layer
constructed through an evolutionary process as technology matured.  This data transport layer resides
and is enabled by an infrastructure overlaid by an even more complex cyber threat landscape.
Comprised of nefarious actors with varying levels of sophistication and an array of malicious intent, the
current cyber threat landscape challenges the ability to secure and ensure a reliable information space.
Measures to secure and protect data and information result in an 'overhead' that affects network
performance -- they reduce throughput, increase latency, and result in an inherently inefficient and
unreliable construct.  Additionally, the framework under which access and services are allocated is sub-
optimal, yielding incomplete and redundant competing networks.  Without a concerted effort to
reframe and reimagine the information space, America will continue on the same trajectory -- chasing
cyber adversaries in an information environment where security is a scarcity.
The advent of 'secure' network technology and the move to 5G presents an opportunity to create a
completely new framework to safely, securely, and reliably transport and share information.  While '4G'
was an evolution of '3G,' simply promising faster speeds, '5G' is by no means simply a 'faster 4G' --
despite the chronological moniker.  This next generation technology, combined with a concerted effort
by public and private entities, can position the United States to leap ahead of global competitors and
provide (he American people with a secure and reliable infrastructure to build the 21st century
equivalent of the Eisenhower National Highway System -- a single, inherently protected, information
transportation superhighway.  To do so, it will take strong and focused leadership from USG along with
the collaboration of public and private entities to seize this opportunity afforded by the emerging
technologies to commit to building a secure 5G network within three years.
Such collaboration promises benefits for American commerce -- spurring economic growth and strength;
national security--enabling innovation for more resilient and effective operations; and most
importantly, the individual--providing American constituents the ability to knows see, and understand
how their digital information acts and is acted upon once it is released and transmitted.  America is on
the edge of a precipice -- we can jump into the information age of the future today or continue falling in
the spiral of cyber-attacks.
                        Secure 5G -- Flipping the Script
FACT:  China is currently poised to lead the global deployment of 5G.
DISCUSSION:  Huawei has used market distorting pricing and preferential financing to dominate the
global market for telecommunications infrastructure.  China sets aside up to 70 percent of its mobile
infrastructure market for Huawei and ZTE, only allowing Western vendors to compete for the
remainder.  The magnitude of the Chinese market reserved to Huawei and ZTE allows the companies to
effectively fund their R&D with domestic sales while insulating the companies against global
infrastructure spending down turns.  The government has also extended an estimated $100 billion line
of credit to Huawei to finance deals abroad.  Combined with aggressive pricing, diplomatic support, and
suspected payments to local officials, Huawei has quickly taken market share in the radio infrastructure
market as well as optical and routing, leaving them poised to take market leadership of 5G.
Huawei has gone from a market share in radio infrastructure of roughly 11 percent in 2011 to a share
equal to or greater than Ericsson and Nokia, the two largest Western mobile infrastructure suppliers.
Similarly, in routing, Huawei more than doubled its market share in an 18-month period, and in several
areas or routing it has caught or surpassed market leader Cisco.  Europe led 3G deployment, the U.S. led
4G, and with these market altering practices, the Chinese may be poised to lead in 5G Huawei,
Notably, the FBI continues to monitor market activity and update its compendium of activities and risks
associated with Huawei and ZTE.  Apart from the suggestions for a U.S. market strategy provided herein,
permanently tasking the FBI to work with other intelligence agencies to monitor and regularly report to
Congress and the Administration on the market activities and risks of Chinese infrastructure vendors
would be valuable for national security.
FACT:  U.S. telecommunications manufacturers have all but disappeared.
DISCUSSION:  Today, only a handfui of companies are postured to play a role in global 5G deployment;
Qualcomm, Cisco, Juniper, Nokia, Samsung, Ericsson, Huawei and ZTE.  Qualcomm makes chipsets for
mobile devices while Cisco, Nokia, and Juniper provide core and routing technologies, but not radio
infrastructure.  Nokia, Samsung, and Ericsson offer radio infrastructure as well as other technologies and
services essential to mobile broadband.  Notably, on the current trajectory, 5G in the U.S. will debut on
equipment from just this small group of companies, which would include Chinese suppliers unless
informal restrictions against their inclusion in national networks are maintained for 5G networks.  Even
at that, radio manufacturers other than Huawei and ZTE will face declining market share if conditions do
not change.
ASSUMPTION: Whoever leads in technology and market share for 5G deployment will have a
tremendous advantage towards ushering in the Massive Internet of Things, machine learning, artificial
intelligence, and thus the commanding heights of the information domain.
DISCUSSION:  5G is a fundamental shift in wireless infrastructure.  More like the invention of the
Gutenberg press than the move from 3G to 4G, it will move the world into the information age.
Everything from automated cars and aircraft to advanced logistics and manufacturing to true AI
enhanced networked combat.  Most communication on the network wilt move from mobile devices to
machine to machine (M2M) traffic.  This will help accelerate machine learning and AI development.
The Challenge:  Can we flip the script?  Can the u.S. conduct a moonshot with secure 5G deployment,
and steal the lead position for dominating the information domain?
Answer:  Yes, but it will take focused and determined leadership and a commitment to building a
secure, high-performance (capacity and coverage) 5G network faster than anyone is currently
predicting -- 3 years.
DISCUSSION:  There are numerous major decisions that affect the answer to this question:
      1. What type of network should we build -- single-block, or multi-block?
      2. What spectrum can we make available?
      3. Can we standardize siting requirements?
Other ancillary questions effect the efficacy of the project:
      1. Can we rebuild a telecommunications manufacturing base in the U.S.?
      2. Can we elicit allies and partners to build with U.S.?
      3. Can we elicit allies and partners to jointly grow these networks in the developing world?
Type of Network:  Options -- 1} Single-block; 2) Multi-block
      Single Block:  if the U.S. were to build and run one physical network using the Mid Band
spectrum it could lease time back to carriers to sell as a service.  This would allow the allocation of a
large amount of bandwidth for the network by creating one black of spectrum in the Mid Band range.
      Pros:
         1.  Speed -- This would enable virtual network slices at the full capacity enabled by
             combining the bandwidth that would normally be allocated to each.  For example, in
             the 3.7 to 4.2 GHz frequency range there is 500 MHz of spectrum available.  That
             bandwidth could be divided into smaller segments and then apportioned to the
             carriers to build competing networks.  However, if all or most of this spectrum is
             used as a single block, then the peak and average speeds achieved on such a
             network would be vastly different.  For example, under a single block scenario speed
             to devices would be in the several Gbps range, while in the multi block scenario it
             would be in the several hundred Mbps range.
         2.  Security -- In the single block scenario, the network could be built with security as a
             foundational element enabling the securing of both government and civilian data,
             The network could also be built for resiliency from physical attack or natural
             disasters.
         3.  Speed of Deployment -- Building a single block network could take the shape of a
             21st Century Eisenhower National Highway System.  This would enable deployment
             on a national scale by using authorities unleashed by the cyber emergency we face
             on a daily basis.  Siting restrictions could be standardized for the nation.  Spectrum
             could be made more easily available by moving some current commercial and
             federal customers arid dynamically sharing dual-use spectrum.  Finally, instead of
             several networks being built, we would only need to build one, which will lead to
             more efficient dep~oymerit of resources.
      Cons:
          1.  New Paradigm -- The current market situation involves many carriers who compete
              at building networks.  The single block model would require a single network that is
              virtually shared by retail providers.
      Mitigation:
          1.  Since the single block network would only cover the Mid Band, other carriers could
              build High Band networks to the same exacting security requirements ii they so
              choose.  This would allow for increased capacity in urban areas and thus product
              differentiation.  All carriers in this scenario could offer the Mod Band network for
              coverage alongside their own separately deployed High Band networks.  Note:
              carriers are already looking at options to free up the 3.7 to 4.2 block for their own
              use.
      Multi Block:  Carriers could build and own the network based on 100 MHz spectrum blocks,
      Pros:
           1. Less Commercial Disruption -- Carriers already anticipate rolling out 5G, but at a far
              slower pace.  Getting them to build and own the network will be an easier sell.
      Cons:
           1. Less Bandwidth -- Since there will be numerous networks, the 500 MHz in the Mid
              Band would have to be divided slowing network speeds.
           2. The end-result wouldn't necessarily help the U.S leapfrog the rest of the world in 5G
              performance.
           3. Timing -- In order to provide individual blocks that are large enough to be useful for
              carriers, incumbent satellite users and all of the earth station users (including
              broadcasters and cable companies) would need to be cleared.  Given the ordinary
              length of regulatory proceedings necessary to accomplish this and the likely legal
              challenges from the satellite companies and Earth station users, the spectrum is
              unlikely to be available in the next flve years.  Clearing and/or repacking to make
              spectrum available would be uneven and could potentially leave areas of the
              country, including rural areas where the satellite services are widely used, without
              spectrum available to underpin a 5G network for as much as 7-10 years.  This a
              potentially fatal challenge of the multi-block, multi-carrier network approach in the
              3.7-4.2 GHz band
What Spectrum Can We Make Available?:  Currently most equipment manufacturer work is being done
in the High Band.  In the U.S. this is at 28GHz.  Verizon is the only carrier who owns a nationwide block of
spectrum at 28 GHz.  AT&T is looking to the FCC to offer more spectrum in this range for their
nationwide 5G network.  Spectrum sales can take as long as 7 years based on historical timelines.  Due to
the inability to pass through human bodies, high band will have to be augmented with far more cell
sites.  This requires more fiber, more approvals and more installations for a given city.  The net result is
that high band will by its very nature lengthen deployment times.  There are some who believe that for
this reason alone 5G will not be built in the U.S., or at the very least it will be one of the last nations to
fully deploy, Neverthe~ss tested speeds in this frequency band has shown multiple Gbps to the device.
The FCC is currently looking at the Mid Band for possible 5G use.  The Mid Band range they are looking at
is 3.7-4.2 GHz.  None of the previously mentioned equipment manufacturers are currently building for
this band, but could have a solution in 6-8 months' time based on commitments to make spectrum
available for large-scale deployments.  There are some U.S. equipment companies who are working in
this area, so the U.S. could still claim a lead in the technology.  Mid Band would allow for a much less
dense network since it is closer in geographical layout to currently deployed networks.  All of the current
4G towers could be used for rollout along with an additional 20 percent more towers, reducing the
deployment timelines.  A 100 MHZ block of spectrum gives you around 400 Mbps, and a 500 MHz block
gives you multiple Gbps at the device.  The only carrier that currently owns spectrum in the Mid Band is
Sprint with a 100 MHz block of spectrum at 2.5 GHz,
Low Band provides good coverage, but will not give true 5G speed or low latency.  Currently only 600
MHz is designated for 5G, and the only nationwide spectrum block is owned by T-Mobile.  5G
deployment will most likely encompass low, mid and high band spectrum for both coverage and
capacity.  Because of the long distance and penetration capability in Low Band, this spectrum will be
used to extend coverage areas to more remote locations.
To recap, only three carriers currently have nationwide spectrum for 5G deployment:
            1. Verizon -- High Band (28 GHz dt 800 MHz spectrum block)
            2. Sprint -- Mid Band (2.5 GHz at 100 MHz spectrum blork)
            3. T-Mobile -- Low Band (600 MHz at ~20 MHz spectrum block)
As it stands today we could see that Verizon will be the only one with true 5G capability in terms of
speed (capacity).  Sprint and T-Mobile will provide coverage.  Typically~ the carriers have fought for both
coverage and capacity and this will likely be the case.  This means either more spectrum will have to be
made available at Mid and High Bands, or expect Verizon to dominate the 5G market in the U.S. with
selective coverage.
Options -- 1) Mid Band; 2) High Band
      Mid Band:  If the FCC were to make 3.7-4.2 GHz available for 5G use and we were to build the
network with the full 500 MHz block of spectrum (or the vast majority of it), then we could deploy a true
5G network on existing 4G infrastructure with only about 20 percent more sites required for coverage.  If
we parceled out the spectrum in 100 MHz blocks this would allow carriers to do the same for coverage,
but it would not deliver the full potential of peak speeds as single block of spectrum.  It might be possible
to set aside 100 MHz of spectrum to cater to incumbents and leverage the remaining 400 MHz as a
single block.  Either way, physics dictates that mid band is the only spectrum range that allows you to
build a network 3 years, offering high performance in terms of both coverage and capacity.
      Pros:
           1. Fast Deployment -- Opening the mid band range allows network coverage to be built
              fast since less sites are required for nationwide coverage.
           2. 5G Speeds -- If the full block of spectrum is used to build one network, the resulting
              network would generate world-leading S~3 speeds.
      Cons
            1. Current Spectrum Owners -- There are currently commercial and federal users of
               this spectrum who will have to be moved elsewhere.  The good news is that most are
               satellite operators or radars.  The satellite operators can easily move to fiber, and
               dual-use spectrum sharing could work in those situations that won't allow for the
               customer to move.  Nevertheless as is the case with all spectrum reallocation, expect
               current spectrum owners to argue for the status quo.  (Nokia Comment:  This is
               subject to significant disagreement, with satellite operators and some of their
               broadcast customers arguing that the weakness of the downlink signal will make
               detection and interference avoidance using current sharing technologies impossible.
               We believe that there is a path to releasing the full 500Mhz over a phased approach
               and with a strong sales effort to the incumbents.  4K video becoming prevalent will
               make some of this easier to navigate.]
      High Band:  Since we already have one carrier with sufficient spectrum available for deployment
in High Band, there is no rush for further spectrum.  AT&T wants to buy spectrum to deploy a nationwide
network, so the FCC is working through that allocation.
      Pros:
            1. Competition -- Making more High Band available allows for more carriers that can
               provide true 5G speeds, but does not get the nationwide network built any faster.
            2. 5G Speeds -- An 200 MHz block of spectrum is available and would generate true 5C
               speeds in selected areas.
      Cons:
            1. Due to the onerous process of locating sites, power and transport under clii rent
               guidelines, the buildout in the high-band could span several years thereby handing
               over 5G leadership to other countries.
Can We Standardize Siting Requirements?:  Options --1) USG Secured; 2) Industry Secured
      USG Owned:  If USG secures the network, then much like the Eisenhower Highway System
national security becomes an important driver for deployment.  Much like concertina wire on a beach
facing assault, or a city wall meant to keep out bandits, the case can be made that a nationwide secure
network is required to create a defensive perimeter in the information domain.  Since we are afforded
the benefit of two large oceans for our physical defense, why not build the equivalent situation in the
information domain.
Current efforts to build 5G networks in the United States have struggled with local siting requirements,
For example, Ericsson is struggling with deployment of a 5G network in Seattle, because each
municipality has unique processes for getting approval to deploy.  These can include different format for
drawings, different pole mounts, and/or different aesthetics for the equipment.  Additionally, some
municipalities want to charge a fee, thus increasing both expense and deployment time.  The bottom line
is that a 3 year deployment time is not achievable without a nationwide standard for siting.  Texas has
already determined that statewide standards this will be required to get timely deployment in their
     Pros:
            1. Fast Deployment -- The ability to use national security to force nationwide
               standardization of siting requirements.
      Cons:
            2. None.
      Industry Secured:  If carriers secure the network, it may still be possible to invoke national
security for standardization.  Otherwise, it may be possible for industry to convince states to agree to a
standardized process.  At a minimum, carriers and equipment manufacturers could agree to a set of
siting standards, NI5T nay provide an opt~on whereby USG could set the standards for siting, and
carriers would build to that standard.
      Pros:
            None.
      Cons:
            1. We must rely on national standards and state and local governments to work with
               industry to develop standardized siting requirements.
Can we rebuild a telecommunications manufacturing base in the U.S.?
      Equipment manufacturers have expressed a willingness to move manufacturing facilities to the
United States in support of a 5G effort.  This could be accomplished in time to allow for a three year
deployment timeline.
Can we elicit allies and partners to build with U.S.?
      There are several countries out there that have expressed an interest in partnering with the
United States on our 5G network.  It is unknown at this time whether they will choose to accelerate their
deployment, but at the very least we can expect an interest in deploying a Secure 5G network with
equipment from a trusted supply chain.  Importantly, this will allow for a counter to China's economic
model of using market dislocating principles to bind nations into their orbit in the information domain.
More broadly it can be the foundation to a democratic counter to the Belt and Road Initiative.  We can
expect the long term effect to be a lessening of Huawei's global market dominance.
Can we elicit allies and partners to jointly grow these networks in the developing world?
      This is currently unknown.  If it were possible to assemble such a coalition, then we could grow
our secure 5G networks in emerging markets.  Joint developmental finance efforts could be merged to
provide a one-stop shop for emerging market telecommunications projects.  Another alternative would
be to have certain allies and partners focus on certain regions for development.  Eventually, this effort
could help inoculate developing countries against Chinese neo-colonial behavior.
   Actions we must take regardless of the path forward:
              1.    Develop standards for 5G deployment.
                 1. Network Security Standards
                      * These will be used to build a network that is inherently secure.  White
                        this will not eliminate all cyber security challenges, it will fundamentally
                        alter the cyber threat landscape.  In other words, it returns the
                        advantage to the defense.
                 2. Infrastructure Standards
                      * These will be used to build the physical network infrastructure.  First Net
                        has already accomplished most of the work on their standards, and
                        these could be repurposed and modified for a nationwide 5G network.
                 3. Wireless Standards
                      * The equipment manufacturers who agree to build the network have to
                        agree on the wireless standards they will build to for interoperability.
                        The good news is that the industry group 3GPP has agreed on version 15
                        standards, which will be a good starting point for reaching consensus.
Additional Considerations (see Appendix 2):
Even before the passing of tax reform legislation, industry experts were optimistic about the ability to
fund secure 5G rollout.  The fast rollout timeline provides an opportunity to offset the potential drop in
exports due to a strengthening dollar effect by boosting domestic investment spending.  Since it relies on
private capital, it also does not add to the nation's debt.  While the business models for secure 5G are
still in development, it is likely that we will have to wait until the network is built to see the network's
true value.  The network will be transformative for society similar to the iPhone.  Similarly, many of the
applications will come later.  Nevertheless we know some industries transformations, like transportation
and self-driving vehicles, require this network to be built before they can be fully achieved.
Fiber Deployment
Estimates show that as much as 200 billion USD will be required for fiber deployment for 5G.  That said,
these reports are based on High Band deployment.  Mid Band will require significantly less.  Nevertheless,
5G deployment should be used as a catalyst for unlocking fiber deployment across the nation.  An
enforced requirement to lay fiber alongside any other construction would help this effort.  USG could
lead development of a mapping tool which consolidates all available data on dark fiber and conduit
locations, which would allow for more efficient planning for fiber laydown.
Building the network will require new sources of skilled labor.  This is an effort that government will need
to get in front of in order to develop new sources of training.  Department of Education can take the lead
in developing training programs that ensure an adequate supply of skilled labor.  Like the space race, the
transition to the information era will require increased investment in both STEM education as well as
increased funding for research and development.
Air and Space 5G
For a truly resilient 5G network, serious consideration should be given to creating air and space layers.
Certain equipment manufacturers have explored an air layer using airline traffic to create a mesh
network for air to air and air to ground 5G capability.  Commercial space providers are working on
constellations of satellites which would provide the capability for alternative backhaul options.
Eventually, these constellations could provide service to mobile devices for remote locations or
crisis/disaster situations.  With air and space layers, coverage could extend internationally providing
service for both government and private sector connectivity.
Rural Broadband
By initially focusing on rural broadband, the network would guarantee a revenue stream while further
business models develop.  There is at least one offer to build a rural broadband capability under a carrier
built and owned network model.  This capability would provide 100 Mbps speeds to approximately so
percent of rural customers, or somewhere around 24 million homes.  If the network were single block,
the speeds would be greater.  This capability could easily be built within the first term.
Why build a [secure] 5G network in three years?
On September 15, 2017 the Secretary of Defense named information a joint function.  The memorandum
"The advent of the Internet, the expansion of information technology, the widespread availability of
wireless communications, and the far-reaching impact of social media dramatically impacted operations
and changed the character of modern warfare."
In the 21st Century freedom is won and lost in the information domain.  Our citizens and companies live
in relative peace and security in all other domains, because of our powerful military.  Yet, every day they
face a warzone in the information domain.  State and non-state actors steal intellectual property and
private data, sow division and obscure bad behavior, slander and defame the innocent, prey on the
weak and plant the seeds for total darkness in the event of all-out war.  There is no more pressing need
for a change in strategy than in the information domain.
Yet, for the most part the 700 billion USD defense budget does very little for the American people in the
information domain.  We promise the world's greatest air, land, sea and space force, but say look to
thyself for the information domain.  We even highlight cyber warriors in advertisements for military
recruitment.  Left unsaid is the fact those cyber warriors for the most part are looking after DoD
networks.  To be honest, even DoD is unprepared for the information age.  The vaunted F-35 is incapable
of being used to its full potential, because the data rates on our current networks preclude the full use
of its data collection.  Soon it will be joined by other advanced aircraft that are similarly data monsters.
The President unveiled his National Security Strategy on December 18, 2017.  In it he portrayed the
world as it is, not as we wish it to be.  Embedded within the strategy was a short but powerful phrase:
"We will improve America's digital infrastructure by deploying a secure 5G Internet capability
nationwide."  This was not an afterthought, nor was it an additional item to answer some constituency.  It
was meant to be foundational.
Rebuilding the Internet
The coming 5G revolution represents the first great leap into the information age.  It is a change more
like the invention of the Gutenberg Press than the move from 3G to 4G.  More network traffic will be
dedicated to machine to machine communication than ever before 5G will transform industries by
ushering in exponentially expanded system capacity, higher data rates, lower latency, higher reliability,
and lower power consumption.  The impact will be pervasive throughout the economy where almost no
sector or industry will go unchanged.  Manufacturing, farming, transportation, medicine and financial
industries to name a few will transform, creating millions of new jobs and billions if not trillions in
economic growth.
The transformative nature of 5G is its ability to enable the Massive Internet of Things.  Technology and
spectrum capacity enable connectivity far beyond current capabilities.  Beam forming, multiple-input and
multipIe~output (MIMO) and software defined networking will allow for faster Internet speeds and
longer battery life to support the device ecosystem.  Unfortunately, if built using the current Internet's
unsecure architecture model, this network will also exponentially expand the threats.  On the current
trajectory, the 5G world will offer opportunities to use the useful sensors and tools on the network as
Information Security
We have the technological capability to secure a 5G network.  This technology was invented in America,
and will be built here as well.  Added assurance can be gained by ensuring we recreate an IT and
telecommunications manufacturing base.  By securing the supply chain we can be assured that our
network is built with safe components.  By ensuring the network is built with security as a foundational
principle, Americans can concentrate on living their lives without fear of walking dangerous digital
streets.  America did not design two big oceans and two friendly borders to ensure its physical security,
but our citizens benefit nonetheless.  The information domain must be designed with the same natural
That is why the network must be built from the ground up with security and resiliency in mind.  Not only
must the network continue to function in the event of physical attack, it must repel attacks to personal
and commercial data on a daily basis.  Once built, this capability must be shared with democratic allies to
ensure they remain viable and strong economic and security partners to support the free world.
Deterrence of State Adversaries
States are not deterred from at:tacking our democracy by indicting their citizens or sanctioning their
companies.  This type of enforcement allows them to absorb the cost of bad behavior while the threats
overwhelm our system.  Rather, cyber-attacks must be met at a minimum on a one-to-one basis.  An
attack on our citizens and companies should he met with a fierce response that forces the state actor in
question to rethink the value of illicit activity in the Information domain. The network itself must be built
with active defense in mind.  As we learned in the wars in Iraq and Afghanistan the first step in asserting
control over chaos is to take away anonymity.  A network that identifies the adversary and responds to
attack is fundamental requirement of the information age.
The Joint Force
Using current acquisition processes, DoD is sure to be left behind in the information domain.  Building a
secure resilient layered and global 5G network will transform how the Joint Force operates and allow for
the full use of data intensive weapons systems like Aegis, P-8, F-35 and B-21.  Currently, stovepiped
communication programs not only create easily identifiable targets, but they often over promise and
under deliver in capability, cost and speed of deployment.  Each service or component seeks a different
path, and ineffectual workarounds are the norm for integration.  In the Air Force alone, efforts to get the
F-22 and F-35 to communicate require purpose built gateways.  An advanced resilient and secure
network that is shared with the public will allow Federal communications to blend in with other traffic
increasing security, improving joint synergy and reducing program costs.  Continuing to ride on our own
networks is like building two Eisenhower National Highway systems, one for civilian traffic and one for
military traffic.  We couldn't afford that in the 1950's physical domain, and we cant afford in the 21st
Century information domain.
The AI Arms Race
Using efforts like China Manufacturing 2Q25 (CM 2025) and the 13th Five Year Plan, China has assembled
the basic components required for winning the AI arms race, CM2025 will provide indigenous innovation
and market dominance for 10 critical American industries including Artificial Intelligence, robotics,
fintech and commercial aviation, to name a few.  Data is the oil of the 21st century and China has built
the world's first strategic reserve.  Complete elimination of privacy standards combined with a strong
firewall has enabled China to transform its "great firewall" into a "great ocean" of data.  The current
algorithm battles are stowly drifting in China's favor as companies like Google build AI research centers
inside China's information sphere and world class data scientists mine the data (ours and theirs) without
restraint.  China has already catapulted into the lead for facial recognition to support its authoritarian
regime.  Much like America's success in the competition for nuclear weapons, China's 21st Century
Manhattan Project sets them on a path to getting there first.  This AI will be harnessed to power a global
social credit system currently being rolled out in China to ensure individual and corporate compliance
with CCP edict through all levels of society.  Building a nationwide secure 5G network sets the condition
for future success in the information domain.  Not building the network puts us at a permanent
disadvantage to China in the information domain.
It is necessary and possible to build a secure, high-performance, world-leading 5G network platform by
the end of the first term Covering the Top XXX metro areas in the country, this platform will enable
higher-order innovation on a scale that no other country is currently planning towards.  In order to do so,
USG must provide clear direction and strong leadership.  The best network from a technical,
performance and security perspective will be single block, USG secured, and have the highest probability
for project success.  Still achievable, but with more risk to cost and schedule are multiple carrier built and
secured networks.  To ensure success, we must move quickly to make 3.7-4.2 GHz spectrum available.
We must move qu~ckly to standardize the wireless, network and infrastructure standards.  We must
standardize siting requirements and advance the nationwide deployment of fiber.  We must strongly
signal to equipment manufacturers our intent to build a secure supply chain.  For the greatest effect, we
must elicit allies to cooperatively build similar networks in their countries and work together to build
them in emerging markets.  If we do, the U.S. will reap the benefits of 3% GOP growth, millions of new
jobs and a dominant position in the Information domain.
1. Secure 5G Strategic Principles
2. Speeding up Deployment
3. Bandwidth Relationship to Network Performance
4. Low, Mid, High Band Comparison
5. 5G New Radio (NR) Coverage and Capacity
6. Current U.S. 5G State of Play
7. Project Timeline
S. Possible Industry Reactions
9. 5G Government and Industry Team and Roles
10.  Huawei LTE Market Share
11. Huawei vs. Cisco Core Routing
Appendix 1 -- Secure 5G Strategic Principles
Mission Statement:  First nation in the world to deploy and operate a secure high-performance 5G
Internet for information dominance in the 21st Century.
Project Goals:
       Initial Operational capability (IOC) 18 Months (Top 15 markets)
       Expanded operational capability 24 months (Top 30 markets)
       Full Operational Capability (FOC) 3 Years (Top xx markets)
Project Principles:
       We will prioritize speed (speed drives momentum):
            1. Speed of Deployment
            2. Speed of the Network
       We will minimize risk (de-risking eliminates roadblocks);
            Risk will be minimized by defining tradeoff priorities in the following order:
                1.Security
                2.Coverage
                3.Resiliency
                4.Capacity
      When making trade-off decisions where two priorities conflict, we will ensure full
      implementation of the higher priority until that priority is fulfilled.
      National 5G requires high, medium and low frequency bands for wireless spectrum.  These bands
      currently are furthest developed and carry the least risk:
           1. H 28 GHz
           2. M 3.7-4.2 GHz
           3. L 600 MHz
Supply Chain
      A secure Internet requires a trusted suppty chain for IT equipment.  We will use the deployment
of 5G to reintroduce production for the full vertical stack into the United States.
      Rapidly rolling out 5G nationwide will present the following potential legal and political
     1.  Eminent Domain for installation
     2.  Spectrum allocation
     3. Reconstituting the IT Industrial Base,
     There are three potential mod&s for deployment:
           1.  Single Block, USG Secured
           2.  Single Block, Industry Secured
           3.  Multi Block, Industry Secured
     There are numerous challenges that slow the deployment of a network:
         1.  Standardization; State and local requirements force network installers to go through
             onerous permitting requirements and produce designs for differing aesthetic
             standards.  Leveraging national security requirements to provide full equipment
             design standardization prior to deployment will speed installation
         2.  Right of Way:  Eminent domain for national security requirements will help speed
             installation.
         3.  Maps:  Installers need one national map which credibly displays existing conduit and
             dark fiber.
         4.  Identifying strategic locations for deployment will provide a roadmap which meets
             national and economic security requirements for collout.
Use Case:
     Aligning GSA and IT purchasing standards for the 5G network will ensure the Federal
government and some state and local governments are prepared to begin harnessing the secure
network as soon as it is available.  Corporate governance standards can ensure the same for large and
publicly traded private entities.
Network Management:
     The secure 5G network will require both public and private management and control functions.
These organizations needed to be identified and resourced early, so they are prepared to assume their
     The secure 5G network will consist of Air, Terrestrial and Space layers:
         1.  Terrestrial -- a wireless 5G network with a blend of fiber and wireless backhaul
         2.  Air -- an air layer utilizing airline carriers and other public/private UAS
         3.  Space -- A space~based backhaul.
Appendix 8--Possible Industry Reactions:
     AT&T:  Mixed =>Will support faster/cheaper 5G buildout but will resist any disruption to its
     satellite business from mid-band spectrum clearing
     Verizon:  Mixed =>Will support faster/cheaper 5G buildout but will perceive aspects of the
     proposal as marginalizing its advantage on spectrum and fiber assets
  *  Sprint:  Mixed =>Has strong 2.5 GHZ spectrum position already but would welcome more level
     playing field with T/VZ
  *  T-Mobile:  Strong support =>lacks rich spectrum for nationwide 5G and would welcome more
     level playing field with T/VZ
  *  Comcast&Charter:  Neutral to Negative =>Fixed wir&ess use case directly competitive with its
     core high speed Internet product; suitability of fiber assets for 5G backhaul unclear
  *  CenturyLink:  Neutral to Support =>Provides an opportunity to monetize its Fiber-rich network;
     less reliance than cable on high speed internet product
  *  Google:  Neutral to Support =>Might push for flexible CBRS-style sharing, but will generaUy
     approve because faster/more pervasive broadband means they can sell more advertising.
  *  Satellite Industry:  Negative =>Mid band used primarily for content distribution by Media
     Networks; gradual migration to Fiber; Intelsat / Intel proposal to manage spectrum between
     Wireless and Satellite
Bottom line:
1.  The Internet's main design paradigm: dumb network, smart endpoints, is being trashed in favor of "smart networks" that can surveil (MITM) all traffic.
2.  We don't currently know how to build such a network, even if we thought such a network was desirable (it isn't).
3.  We sure as heck don't know how to build a *secure* network -- at least one where "the defense has the advantage" !?!
4.  This is a pie-in-the-sky power grab by the Federal government to effectively nationalize *all digital communications*, destroy (through eminent domain) all state and local authority to control their own destiny.
I.e., this is the "full Stasi" program, with AI robot analysts to "watch over all of us".
5.  I thought that we learned our lesson with NASA's Space Shuttle, which destroyed any hope for commercialized space for 50 years, and set back space exploration by at least 25 years.  The DoD took one look at the hairbrained Shuttle design, and ran the other way, so the Shuttle lost its biggest customer and its raison d'etre.
Networks can't be designed "top down", so this effort will not only fail, it will waste a trillion dollars, and leave the U.S. further behind in 5G than it is today.

@_date: 2018-06-06 16:08:14
@_author: Henry Baker 
@_subject: [Cryptography] Power side channel mitigations 
I've been reading up on power side-channels.  As most people here should know, these attacks are completely devastating, and a large amount of HW/SW work has gone into mitigation.
However, most of the *hardware* work during the past 20 years seems to have focused on smartcards; very little hardware work (except for *algorithm* enhancements -- e.g., breaking up computations into Shamir secret-sharing) seems to have been done on general processors.
Yes, the smartcard HW ideas can be utilized for "TPM's" (Toilet Paper ModulesXXXXXXXXXXXXXXXXXXXXTrusted Platform Modules) and such, but these methods still leave the vast bulk of ordinary software programming & computation at risk.
Does anyone here know of any work at the hardware level for ordinary CPU's and GPU's ?
Thanks in advance for any links.
(BTW, please don't send me any links for specialized AES hardware; I've already accumulated perhaps 500 references for this kind of stuff -- I'm looking for ideas for protecting non-crypto-hardware & general purpose CPU's/GPU's.)

@_date: 2018-06-20 06:43:45
@_author: Henry Baker 
@_subject: [Cryptography] OpenBSD disables SMT to thwart cache timing attacks 
FYI --
 at openbsd.org/msg99141.html
Mark Kettenis Tue, 19 Jun 2018 12:30:19 -0700 Log message:
SMT (Simultanious Multi Threading) implementations typically share
TLBs and L1 caches between threads.  This can make cache timing
attacks a lot easier and we strongly suspect that this will make
several spectre-class bugs exploitable.  Especially on Intel's SMT
implementation which is better known as Hypter-threading.  We really
should not run different security domains on different processor
threads of the same core.  Unfortunately changing our scheduler to
take this into account is far from trivial.  Since many modern
machines no longer provide the ability to disable Hyper-threading in
the BIOS setup, provide a way to disable the use of additional
processor threads in our scheduler.  And since we suspect there are
serious risks, we disable them by default.  This can be controlled
through a new hw.smt sysctl.  For now this only works on Intel CPUs
when running OpenBSD/amd64.  But we're planning to extend this feature
to CPUs from other vendors and other hardware architectures.
Note that SMT doesn't necessarily have a posive effect on performance;
it highly depends on the workload.  In all likelyhood it will actually
slow down most workloads if you have a CPU with more than two cores.
ok deraadt@
So it begins...

@_date: 2018-03-14 10:53:36
@_author: Henry Baker 
@_subject: [Cryptography] Wi-Fi beacon frame responses 
The longest distances I've heard of for Wi-Fi are about 30 miles line of sight on a dry day.
30 miles straight up is 150k feet of altitude; balloon height, but not satellite height.
But Baltimore apparently now has 24x7 airplane and/or drone video surveillance coverage.
It wouldn't be difficult for these flying platforms to do at least Wi-Fi, but probably considerably more.
Bluetooth might be harder, but even more revealing: e.g., every time I'm on an airplane, my Bluetooth lights up with 100 or so phones & laptops.  I haven't searched for low power Bluetooth (BTLE), but I suspect there may be a few BTLE heart rate monitors on the airplane, as well.
As Michael Hayden famously said, "we kill people based on metadata"; translation: "we kill people based on Wifi/Bluetooth MAC's".

@_date: 2018-03-15 12:19:39
@_author: Henry Baker 
@_subject: [Cryptography] Intel trump-ets "walls" to defeat Spectres 
FYI --
Advancing Security at the Silicon Level
Hardware-based Protection Coming to Data Center and PC Products Later this Year
By Brian Krzanich
In addressing the vulnerabilities reported by Google Project Zero earlier this year, Intel and the technology industry have faced a significant challenge.  Thousands of people across the industry have worked tirelessly to make sure we delivered on our collective priority: protecting customers and their data.  I am humbled and thankful for the commitment and effort shown by so many people *around the globe*.  And, I am reassured that when the need is great, companies  and even competitors  will work together to address that need.
we are making changes to our hardware design to further address the other two.  We have redesigned parts of the processor to introduce new levels of protection through *partitioning* that will protect against both Variants 2 and 3.  Think of this partitioning as additional "protective walls" between applications and user privilege levels to create an obstacle for bad actors.
We're sorry that this has taken so long, but Intel needed to "nerd harder" to redesign our backdoors and provide new niches where we could hide the keys for the housekeeping maids & gardeners.  These backdoors & niches improve *your* security, by allowing these hard-working folks to keep a watchful eye out for "bad actors".
Our IP lawyers have also been working overtime to come up with words and phrases that make what we're doing appear novel enough to build a patent wall against AMD and ARM.  We're hopeful that they've now succeeded.
Our researchers in India and Pakistan have assured us that these novel "partitions" will provide the safety and security blanket that our customers have become accustomed to from Intel.

@_date: 2018-03-20 11:52:42
@_author: Henry Baker 
@_subject: [Cryptography] Does RISC V solve Spectre ? 
Someone has claimed to me that RISC V completely "solves" the Spectre problem.
I'm still dubious.  Perhaps it is a derivative/modification of RISC V ?
Is there any in-depth analysis of RISC V & Spectre online somewhere?

@_date: 2018-03-22 18:41:03
@_author: Henry Baker 
@_subject: [Cryptography] 2 outstanding talks on Spectre/Meltdown 
FYI --
SiFive Tech Talk Paul Kocher - YouTube
Spectre: Exploiting Speculative Execution
January 31, 2018
Both are excellent; both are > 1 hour each.

@_date: 2018-03-23 18:05:46
@_author: Henry Baker 
@_subject: [Cryptography] Does RISC V solve Spectre ? 
Great idea.
Let's see how well it works in practise.
precache xxxxx to yyyyy now.
# stuff finally shows up at yyyyy in the cache at this point in time
# I just received this $$$ box from Amazon that I ordered 5 months ago.
# I can't remember what I was doing at the time, or why I ordered it.
# Well, gotta go now, so throw it in the trash or give it away.

@_date: 2018-03-24 09:52:09
@_author: Henry Baker 
@_subject: [Cryptography] Does RISC V solve Spectre ? 
Yes, I was being facetious, but there are human analogies to what's
going on in a compiler for a deeply pipelined machine.
Let's talk about the compiler for a moment.
You are correct that it is relatively easy for a compiler to compile
for a pipeline (I've written such a compiler) -- so long as there
aren't any branches or loops.  However, in the presence of branches
or loops, we can no longer predict in advance at what point in
the branch nest or loop body when (or if) a value will be needed.
This is the compiler equivalent of being unable to schedule my
day(s) waiting for the cable guy or the Fedex gal to show up. (Yes, the Fedex gal sometimes requires a signature.)
But for the compiler to schedule a value which will show up 200
(or more) instructions in the future is the equivalent of me trying
to schedule a visit 200 days in advance for someone arriving from
Mars.  Or perhaps think of scheduling visits in the 15th Century,
when every trip took days, weeks months or years.
(A modern Army general has commented on the plight of his ancient
Roman counterpart: "When one of your generals goes over the
horizon with his army, you're not going to hear from him for a
number of months.  You have to delegate authority, and you have
to be prepared to send *another general and another army* to
rescue him and/or defeat him if anything goes wrong.)
There's a physics T-shirt that reads "Time is nature's way
to keep everything from happening at once" -- Wheeler.
Perhaps computer architects need their own T-shirt; here
are some suggestions:
"A foolish consistency is the hobgoblin of inorder processors
... With consistency, a great processor simply has nothing to
"We choose mania over boredom every time." -- James Gleick
"Never underestimate the determination of a CPU who is time-rich
and cache-poor"  -- Cory Doctorow
"Boredom, that traitorous devil that possesses us to do things
sometimes useless, and often stupid."  Apol Lejano-Massebleau
"Boredom is what you dread most in the world, and yet, I
assure you, there are worse things." -- Agatha Christie
"When action grows unprofitable, gather information;
when information grows unprofitable; sleep" -- Ursula Le Guin
"Whoever sleeps long, does not sin." -- Martin Luther

@_date: 2018-03-25 07:32:33
@_author: Henry Baker 
@_subject: [Cryptography] Does RISC V solve Spectre ? 
Indeed it does.
See this presentation in particular, where Mill claims that its processor is immune to Spectre/Meltdown, but that they *did* find a speculation bug in their software (which means that there are almost certainly equivalent bugs in compilers for other machines):
Spectre, Meltdown and the Mill CPU
Will Edwards will at millcomputing.com

@_date: 2018-03-25 09:30:20
@_author: Henry Baker 
@_subject: [Cryptography] Does RISC V solve Spectre ? 
OpSec?  We need to worry about OpcodeSec!
nVidia's "Dynamic Code Optimization"/"DCO", aka Humpty Dumpty theory of ISA: "When I use an instruction, it means just what I choose it to mean--neither more or less."  Alice: "The question is, whether you can make instructions mean so many different things."
"DCO": Yet more lovely places for malware to hide.  The executing code is "translated" into a microcode buffer, but who gets to be in charge of said translation?
"Those who write the code decide nothing.  Those who execute the code decide everything."  -- apologies to Josef Stalin
I believe that these DCO processors have already been picked up for widespread use in automobiles, including self-driving cars.
What, me worry?
Above is a message I sent over a year ago about nVidia's new "DCO" mechanism, where the standard computer op codes are merely a gentle hint/suggestion about what the CPU should actually do.  Behind the scenes, "DCO" can re-interpret your *hardware op code* to do anything it damn well pleases.  This is the opcode equivalent of *memory maps*, which merely provide gentle hints/suggestions about where to fetch instructions.
See the Youtube video link above for more details.
Stanford EE Computer Systems Colloquium
4:15PM, Wednesday, March 4, 2015
NEC Auditorium, Gates Computer Science Building Room B3
Dynamic Code Optimization and the NVIDIA Denver Processor
Nathan Tuck NVIDIA
About the talk:
NVIDIA's first 64-bit ARM processor, code-named Denver, leverages a host of new technologies to enable high-performance mobile computing.  Implemented in a 28-nm process, the Denver CPU can attain clock speeds of up to 2.5 GHz.  This talk will outline the Denver architecture and describe some of its technological innovations.  In particular this talk will discuss some of the motivations and advantages of dynamic code optimization.
There not downloadable slides for this presentation available at this time.
View Video on YouTube.
About the speaker:
Nathan Tuck has been a member of the DCO and CPU architecture teams at NVIDIA since 2009.
Nathan has spent his professional career walking a crooked line between hardware and software.  As an engineer, he is most interested in working on systems problems.  Professionally, he is most interested in dynamic environments where he can make a large difference.
Contact information:
Nathan Tuck

@_date: 2018-03-26 15:01:16
@_author: Henry Baker 
@_subject: [Cryptography] Various CPU cache side channels 
I've done a lot of reading re Spectre, and it would
appear that Spectre-like attacks could be made on
*any/every* cache found in every modern processor,
* data cache attacks (already done)
* instruction cache attacks (already done, e.g.,
Spectre, inconsistent instruction and data caches)
* TLB attacks (somewhat done already)
* branch prediction cache attacks (already done,
This is particularly difficult because there's
no way for the hardware to know whether the data
it is processing is secret or not, and I've seen
no proposals to date for HW data tagging based
upon secrecy classifications.  For example, the
length of a constant-size message -- e.g., an
internet packet -- is presumably not secret, but
the *contents* of such packets -- including all
header bits -- should be secret.  Even the
connection status in routing data tables leak a
lot of information.
Thus, any SW package -- e.g., OpenSSL -- that
processes secret bits -- needs to be able to:
1.  Mask off all interrupts (& poll temperature
and voltage in order to clear secrets when
powering down).
2.  Clear I$, D$, TLB, branch prediction caches
upon entry and upon exit.
3.  Pause all other threads (SW or HW "harts")
4.  Lock CPU clock frequency while inside secret
Since multi-core processors are becoming ubiquitous
(a recently designed RISC V multicore processor can
put 42(!) cores in one mm^2), the idea of isolating
secrets in certain cores is attractive; indeed,
Paul Kocher makes this point in his recent talk
about Spectre.
However, one man's secrets are another's business
(Facebook, Google, NSA), so it isn't clear anymore
what *isn't* secret.  In addition, secrecy
classifications don't form nice lattices, so
enforcing secrecy classifications inside of a
processor is very complex.
We're in the same boat (!) as a modern ultraquiet
submarine, where *everyone* on the sub has to
be ultraquiet -- not just the communications
So this means that *every* core within a multi-
core chip may end up processing secrets, so we're
back to square one.

@_date: 2018-03-27 08:37:16
@_author: Henry Baker 
@_subject: [Cryptography] Justice Dept. Revives Push to Mandate a Way to 
mail.com>
In the ol' Ma Bell days, the govt was able to hide behind Ma Bell's skirt: prior to the Carterfone decision, you simply couldn't attach any non-approved devices to the ATT network.  Of course, this standardization made J. Edgar's (illegal) jobs sooo much easier.

@_date: 2018-03-27 09:46:14
@_author: Henry Baker 
@_subject: [Cryptography] Specialized crypto processor architectures ? 
OK, if we're going to have to incorporate a separate
crypto processor on each SoC, then what would be a
good architecture for such a processor?
Essentially all of these crypto "enclaves" appear to
be derivatives of existing designs, and as such, they
inherit most/all of the vulnerabilities of the parent
architectures -- e.g., the recent Intel enclave HW/SW
If we're going to have to have a separate processor,
why not a processor *specialized* for crypto?  I.e.,
very wide data words -- 512 bits?  1024 bits?  2048
bits?  4096 bits?  (Think ICL DAP or Pratt's boolean
vector machines.)
With a Harvard architecture, there's no need for
instructions to use either the same memory or the
same word size.  Indeed, I don't see much need for
byte addressable data memory at all.  [We could
even bring back Intel's iAPX432 bit-aligned
instructions!  :-) ]
It's not clear that the data memory for such a
crypto processor needs to be all that large, so
perhaps no cache, but instead a large directly
addressable data memory?
Instructions would likely be VLIW, except that
the instruction cache should be managed by the
compiler, in order to eliminate non-determinism.
With very large data paths -- including very
large ALU's -- there's less need for high clock
rates, and high clock rates would drive up power
We could go back to an extremely simple (very
short pipelines) -- and extremely *deterministic*

@_date: 2018-03-27 14:05:05
@_author: Henry Baker 
@_subject: [Cryptography] BranchScope: a new attack on branch predictors 
FYI --
As predicted, more branch prediction processor attacks are discovered
New attack focuses on a different part of the branch prediction system.
Peter Bright - Mar 26, 2018 10:15 pm UTC
Researchers from the College of William and Mary, Carnegie Mellon, the
University of California Riverside, and Binghamton University have
described a security attack that uses the speculative execution
features of modern processors to leak sensitive information and
undermine the security boundaries that operating systems and software
erect to protect important data.
That probably sounds familiar.
The Spectre attacks, published earlier this year, take advantage of
the speculative execution features of modern processors to leak
sensitive information.  The new attack, named BranchScope by the
researchers, shares some similarity with variant 2 of the Spectre
attack, as both BranchScope and Spectre 2 take advantage of the
behavior of the processor's branch predictor.
With speculative execution, the processor runs ahead of where the
program actually is, and it tries to execute instructions before it
can be certain if those instructions will actually be run.  For
example, if a program tests whether two numbers are equal and does one
thing if they are and another thing if they aren't, the processor will
guess the outcome and speculatively execute the resulting action.  If
it later turns out that the processor guessed wrong, the speculative
results are thrown away and, at least in an abstract sense, it's as if
the bad guess never happened.  The processor picks up from where it
left off, performing the action that it should have taken instead.
The Spectre attacks as a whole occur because the processor doesn't
quite put things back the way they should be.  While the processor
does revert to its speculative execution correctly--if it didn't,
programs would simply stop working correctly--it doesn't quite do so
perfectly.  This is particularly noticeable when it comes to the
processor's cache: speculative execution can cause the processor to
load data into cache (or, alternatively, evict data from cache), and
these cache changes persist even if a bad speculation is made.
Carefully written software can detect these cache changes and use them
to infer secret information.
The processor's branch predictor is one of its core pieces of
speculative execution machinery.  While the branch predictors in the
latest processors are complex, in broad terms they operate in a
similar way.  The processor tracks the address of branch instructions,
whether the branch was taken or not, and if the branch is taken, the
address of the next instruction that should execute--that is, the
target of the branch.  The branch predictor provides two related
predictions: whether the branch is taken or not, and if it's taken,
what the target is.
BranchScope and Spectre 2 both take advantage of different parts of
the branch predictor.  Spectre 2 relied on a part called the Branch
Target Buffer (BTB)--the data structure within the processor that
records the branch target.  BranchScope, instead, leaks information
using the direction of the prediction--whether it's likely to be taken
or not--which is stored in the pattern history table (PHT).
The PHT keeps a kind of running score of recently taken branches to
remember if those branches were taken or not.  Typically, it's a
two-bit counter with four states: strongly taken, weakly taken, weakly
not taken, and strongly not taken.  Each time a branch is taken, the
counter's value is moved toward "strongly taken;" each time it's not
taken, it's moved toward "strongly not taken."  This design means that
an occasional mispredict won't change the result of the prediction: a
branch that's almost always taken will still predict as taken, even if
it's occasionally not actually taken.  Changing the prediction
requires two back-to-back mispredicts.  This design is proven to
provide better results than a one-bit counter that simply predicts a
branch based on what happened the last time it was taken.
For Spectre 2, an attacker primes the BTB, carefully executing branch
instructions so that the BTB has a predictable content with a target
instruction that will, if speculatively executed, disturb the
processor's cache in a detectable way.  The victim program then runs
and makes a branch.  The attacker then checks to see if the cache was
disturbed; the measurement of that disturbance leaks information.
In the new attack, an attacker primes the PHT and running branch
instructions so that the PHT will always assume a particular branch is
taken or not taken.  The victim code then runs and makes a branch,
which is potentially disturbing the PHT.  The attacker then runs more
branch instructions of its own to detect that disturbance to the PHT;
the attacker knows that some branches should be predicted in a
particular direction and tests to see if the victim's code has changed
that prediction.
The researchers looked only at Intel processors, using the attacks to
leak information protected using Intel's SGX (Software Guard
Extensions), a feature found on certain chips to carve out small
sections of encrypted code and data such that even the operating
system (or virtualization software) cannot access it.  They also
described ways the attack could be used against address space layout
randomization and to infer data in encryption and image libraries.
Spectre 2 has provoked both operating system and hardware changes,
with more hardware fixes planned.  The researchers suggest that a
similar combination of solutions would be needed for BranchScope; some
software can be modified to eliminate branches, and hardware could be
altered to partition the speculative execution data structures on the
processor so that one process could not attack another.
As with Spectre 2, it's not clear just how much software is truly
vulnerable to BranchScope attacks.  In both cases, attackers need the
ability to run code on a victim system, so these attacks will never be
used for initial entry into a system.  What they do, however, is
demonstrate that the isolation boundaries that have long been assumed
to exist are rendered somewhat permeable by the speculative execution
hardware that is essential to high-performance processors.  Moreover,
BranchScope shows that Spectre isn't the only avenue through which
this speculative execution can be exploited.
Fundamentally, the processor contains lots of internal states
(including registers, caches, branch predictor, store buffers, and
more) that speculative execution can modify.  The architectural
state--the parts directly exposed and manipulated by the processor's
published, documented instructions--is preserved properly by the
speculative hardware.  Attacks like Spectre and BranchScope exist
because the non-architectural state--the parts that represent
implementation details of the processor that may change from family to
family, and which aren't directly accessible to programs--isn't being
preserved fully.  Speculative execution (and the non-architectural
state it depends on) is designed to happen invisibly, with no
indication to the running program that it's occurring.
Attacks like Spectre 2 and BranchScope are the result.  It's likely to
be years before researchers have determined all the various ways in
which the speculative execution hardware can be used to leak
information this way, and it will be longer still before robust,
universal defenses are available to stop the attacks.
Peter is Technology Editor at Ars.  He covers Microsoft, programming
and software development, Web technology and browsers, and security.
He is based in Brooklyn, NY.
Email peter.bright at arstechnica.com // Twitter "[Speculation] attacks like Spectre and BranchScope exist
because the non-architectural state--the parts that represent
implementation details of the processor that may change from family to
family, and which aren't directly accessible to programs--isn't being
preserved fully."
The night is still young...

@_date: 2018-03-31 08:08:06
@_author: Henry Baker 
@_subject: [Cryptography] Password entry protocols 
Is it just me, or are all password entry protocols
laughably easy to spoof?
If these protocols were done in "real life", the
writers for "Get Smart" would leave them on the
cutting room floor.
When a program/website asks me for a password, it's
the equivalent of someone in a spy movie asking on
the telephone "is this a secure line": which in
itself is laughable -- if you have to ask, it isn't!
So all I have to do is to simply copy the screen --
or the particular section of the screen -- and ask
someone to type in their password.
Furthermore, I can even have Eve sit there watching
the screen for a particular combination of pixels to
show up, and know when to start typing in behind the
Trying to train people to look for a different
combination of pixels every time is even worse --
how can they tell which is the real from the fake?

@_date: 2018-05-17 12:07:09
@_author: Henry Baker 
@_subject: [Cryptography] Police want encrypted radios 
FYI --
Want to Listen to Police Scanners?  Cops Say No More
Police move to block the public from listening to scanners
By Zusha Elinson  May 17, 2018 8:00 a.m. ET
A report of a suspicious person crackled from John Messner's RadioShack police scanner, one of two he keeps at his home in Knoxville, Tenn.
When an officer was heard yelling "Shots fired!" minutes later, Mr. Messner knew it was time to go.  The 52-year-old construction worker and photographer grabbed his two cameras, his portable scanner, jumped in his 1999 Plymouth Voyager minivan, and raced to the scene 3 miles away, where a suspected burglar was shot by police.
"When I got there, the guy was still on the ground, they hadn't put him in the ambulance yet," said Mr. Messner of the November incident.  "It didn't look like he was dead, but he was definitely hit."
Mr. Messner snapped pictures and posted them on his Knoxville Crime Facebook group, which has 94,000 members in a city of 186,000.  They come to see photos, read Mr. Messner's live updates on police chases and burglaries that he gets from the police scanner, and discuss neighborhood crime issues.
Social-media groups like Knoxville Crime are one reason that Knoxville police officials say they will begin encrypting police radio communications in August, making it impossible for the public--and Mr. Messner--to listen in live.  The move comes as more police departments around the country are seeking to shield their live radio communications, now easily accessible via smartphone apps.  Police say the effort will keep officers safe and bad guys from finding out what they're doing.
"When you're putting out information that only a suspect and a victim and an officer knows, then all of the sudden you have someone put that on social media, that takes your advantage away," said Darrell DeBusk, a Knoxville police spokesman.
Earlier this year, the Las Vegas Metropolitan Police Department encrypted its radio traffic, alleging that bad guys "monitor police radio frequencies in order to better facilitate their crimes and gather intelligence about the whereabouts of police officers."  Pueblo, Colo., police blocked their scanner traffic recently, citing suspects using scanner apps to avoid officers.
Local media still has access to the live radio transmissions in Las Vegas--police allow them to purchase their own radios.  In Knoxville, the radio traffic will be posted after a one-hour delay, said Mr. DeBusk.
These moves have rankled scanner enthusiasts who range from people curious about police activity in their neighborhood to modern-day Weegees, the New York City freelance photographer known for his raw crime-scene photos.  Many scanner buffs are police supporters who want to help solve crimes, making the decision to go dark a difficult one, police officials say.
"It's a tough choice because many of the pro-police people out in the community who support their local police get that way because they listen to their police on these scanners or phone apps," said Richard Myers, executive director of the Major Cities Chiefs Association.
Some police departments have found a solution by using encrypted channels for more sensitive work, such as a SWAT team readying for a raid, while keeping the more mundane police patrol work on the publicly available channel, he said.
In Colorado, a push to encrypt police radio traffic inspired a bill backed by scanner enthusiasts earlier this year that would have banned encryption, except for sensitive situations.  The bill failed with strong opposition from law enforcement.
"These are government agents working for the taxpayers and I think citizens have the right to know what they're doing," said Robert Wareham, an attorney who helped draft the bill.
Mr. Wareham, a former police officer, said he uses his scanner to find out about police activity in his neighborhood or on the roads.  "There are six or seven times a year where I avoid a dangerous situations where I know what's going on," he said.
In Knoxville, Mr. DeBusk, the police spokesman, said the prevalence of smartphone apps that broadcast police communications, such as Broadcastify, has made it easier for criminals to listen in.
"You've always had people that had scanners, but it was not as common as the smartphone apps," said Mr. DeBusk.  "We actually have arrested people, they've had the smartphone on them and we could hear our own dispatchers, the sound coming from their smartphone."
Lindsay Blanton, the CEO of Broadcastify's parent company RadioReference.com, called this an "overdone complaint."  The approximately 200,000 daily unique listeners tuning in to Broadcastify's 6,600 feeds typically hear police communications on a 45 second to three minute delay and the company bans sensitive content, he said.
"It's providing more an entertainment type perspective than the ability to gain an advantage over law enforcement," said Mr. Blanton said.
People can listen to public safety, aircraft, rail and marine audio streams from across the country on Broadcastify.  The company relies on volunteers who send local feeds from their scanners and in some cases police departments who do the same because "there are a lot of agencies that value the general public being more involved," said Mr. Blanton.
Mr. Messner, of the Knoxville Crime Facebook group, said he thinks city officials don't like the pressure that the group puts on them to deal with crime in the city.
Cutting off the scanner will cut off Mr. Messner's access to the subjects of his photographs, some of which have made news themselves.  Back in 2014, he went to the scene of unruly college party and photographed a Knox County Sheriff's deputy with his hands around the throat of handcuffed college student.  The deputy was fired over the incident, but then allowed to retire.
"I was at the right place at the right time," he said.  "I listened to the scanner and I heard things escalating."
Write to Zusha Elinson at zusha.elinson at wsj.com

@_date: 2018-11-11 19:30:19
@_author: Henry Baker 
@_subject: [Cryptography] Brute force circa 1939 
I just watched the 1939 U.S. movie "Espionage Agent" (Google it), in which some of the dialog goes like this:
"Ever since the World War [I], we've been trying to perfect a machine that would encode and decode automatically."
"This machine offers a variation of 2372 entirely original codes -- 2371 chances of being wrong -- even if he had a machine to work with."  (I'm not kidding -- those are the actual words & numbers from the movie.)
Even 80 years of Moore's Law won't make 11 bits (or 9 bits, since 2372=2^2*593) look very good for 1939.
Whoever from the FBI was advising this 1939 movie (Comey could only wish to have done so well!) in a technical capacity must have been ridiculously worried about giving away something to Germany, because even amateur cryptographers -- e.g., Edgar Allan Poe -- would have burst out laughing in the middle of this movie when it aired (showed ??) in 1939.  But as the Enigma Machine demonstrated, "2372 codes" must have also made the Germans burst out laughing when they saw it.  But perhaps that was part of the FBI plan -- convince the Germans that the U.S. was hopelessly naive about crypto and lull them into a sense of invincibility while Turing did his work.

@_date: 2018-11-14 06:17:30
@_author: Henry Baker 
@_subject: [Cryptography] Brute force circa 1939 
If anyone is interested, the movie "Espionage Agent" appeared on the TCM channel, and so I would guess it will show up again in a few months.
If you watch this movie -- or even Google it -- it clearly has an agenda.  The main theme of this agenda is that the U.S. Govt isn't taking counterespionage seriously.  Now it's 1939; who do you think might have this particular agenda?  Who in the govt has spent twenty years scaring the pants off the populace in order to increase his power?  None other than J Edgar Hoover, who spent a lot of time working with Hollywood to raise the awareness of the FBI and all the great things it was doing to combat crime. [0]
After WWII, however, when Hollywood lovingly embraced the US's new Soviet ally, Hoover reverted back to his old post-WWI Red Scare tactics, and some parts of Hollywood became the enemy.
If you believe other Hollywood movies, the Battle of Midway (6/7/1942) was won by US codebreakers who broke the Japanese codes; the Chicago Tribune then published an article in June 1942 saying as much!  Apparently, this article convinced the Brits that the US couldn't be trusted to keep code secrets.
[0] "Hoover understood the value of star power.  As an FBI Director with a prowess for public relations, he used Hollywood connections in order to boost the Bureau's profile and limit what he saw as Hollywood's tendency to glorify or romanticize criminals.  Through the media, he hoped to promote a spotless image of the FBI and promote law enforcement officers as heroes and role models."
"Combined with his unprecedented power and role in law enforcement, Hoover's attention to the media made him popular in many Hollywood circles."

@_date: 2018-11-19 06:50:30
@_author: Henry Baker 
@_subject: [Cryptography] Buffer Overflows & Spectre 
Is it just me, or does anyone else feel a deep sense of betrayal and irony?
We in computer science have spent 50+ years advocating proper code hygiene in which every array reference is properly bounds-checked to avoid the dreaded *buffer overflow*.
We've beaten up on languages such as C & C++ for their bad hygiene, and attempted to steer students towards modern languages which are *safe by design*, because they obsessively and anally check every array reference.
What has it netted us?
We've been undone by our own hardware, which *ignores* our *explicit instructions* to check every array reference -- e.g., Spectre.
Isn't it time for a *class action lawsuit* against every CPU vendor?
This is not just *negligence*, but outright *fraud*, because the CPU violates its own advertising !
It is as if an automobile manufacturer put a Spectre-like bug in our automobile braking systems which occasionally ignored the brake pedal because it adversely affected gas mileage.  Who cares about a few "accidental" deaths here and there, if the manufacturer can claim a few percentage points additional gas mileage?
***What the CPU manufacturers have done is every bit as bad as the auto manufacturers did to *cheat the emissions testing*! ***

@_date: 2018-11-20 18:42:46
@_author: Henry Baker 
@_subject: [Cryptography] Buffer Overflows & Spectre 
In-line comments below.
[I'm a bit of a car buff, so I'm quite well versed in the facts of auto safety and emissions history.]
Of course, Spectre was intentional.  The whole point of speculation is to "fool" the standard benchmarks, and run those fast even if the results on non-benchmark code are insecure or buggy.
Your arguments work equally well for the auto companies -- they have "merely" tuned their engines to fool the standard emissions benchmarks, even if the results the rest of the time are complete crap.
Your comment "CPU manufacture is not regulated at all" is precisely what Ralph Nader found when he published his book "Unsafe at any Speed" in 1965 that led to significant government regulation of auto safety.  Since the CPU manufacturers have clearly put profits ahead of people, it is now time to regulate them -- either through legislation or through common-law lawsuits.
[Come to think of it, Nader needs to write "Unsafe at any Speed: 2.0" to describe the current CPU Spectre crisis!]
Automobiles in the 1960's had been deathtraps and smog generators for 50 years before Nader was finally able to stop the "car"-nage.  A slow-motion train wreck is still a train wreck, and those companies responsible are just as guilty as those causing fast-motion train wrecks.
You'll have to speak for yourself.  Many of us in the computer science community have long been advising correctness and security over speed.  The C-oriented computer architectures of the 1980's and 1990's merely "externalized" the costs of software safety and security and "socialized" those costs for society as whole to bear, while "privatizing" the profits from these unsafe systems.  We're still paying billions of dollars a year tracking down the bugs and buffer overflows in software written by C-weenies in the 1980's.  [Check out the tests used by Microsoft and other SW companies in the 1980's to weed out careful programmers; "Move Fast and Break Things" is an attitude that started long before Facebook.]
If you go back to the Congressional hearings about auto safety and auto emissions, you will find exactly the same set of excuses.  The auto industry was building cars that could go well over 100 mph, but whose tires blew up over 90mph, and whose brakes and suspensions were completely inadequate for the power and speeds of these vehicles.  Regarding auto emissions, check out the story of how Honda embarrassed the Detroit auto industry by demonstrating Honda's better technology to Congress on one of GM's *own engines*.
I really don't care any more about excuses.  I see 4/8/12 core processors whose entire computational load is handling 50-100 (or more) Javascript components so that tens of advertisers can better track me as I read a single paragraph of text.  Every additional computational cycle is more than eaten up with larger Javascript programs, so web pages are slower than they were twenty years ago.  I really don't care to give up my security to enable more of this garbage.

@_date: 2018-11-21 08:31:13
@_author: Henry Baker 
@_subject: [Cryptography] Buffer Overflows & Spectre 
I wish it were that easy.
Here's another analogy.
It's the Middle Ages, and I've got a magnificent castle with thick walls and a deep, wide moat.  Cannons haven't been perfected yet, so I'm smug as a bug in my impregnable castle.
But wait, there's more!
I provide areas beyond my moat where all comers can camp for free as long as they wish.  Even better, I supply fresh water and free food for all.  I also provide all kinds of resources -- building materials, workshops, steel foundaries, chemicals -- again, all for free.
My largesse has not gone unnoticed, and tens of thousands of people come from far and wide to camp out in these areas surrounding my castle.  At first, they're annoying, but relatively harmless.  They make loud music at night and their campfires foul the air during the day.  But word of my charity continues to spread, and people from kingdoms thousands of miles away begin to arrive.  These are more sophisticated people, and they utilize my own workshops and my own resources to build *bridges* and *siege towers* and *catapults*.
One day, I wake up to find that these siege towers have crossed these bridges and these catapults are systematically destroying my thick walls.  My own foundaries have provided hammers and chisels to chip away at the cement holding my own walls together.
I send messengers to my own local kingdom asking for immediate aid to stop the imminent takeover of my castle.  Not only does my government not help, it sends out bureaucrats to check my walls and moats to make sure that the moats are not too deep or too wide, and that my walls are not too thick nor the cement too strong.  Because my own government is more afraid of me than the now 100,000 foreigners camped out in front of my castle and actively attacking it.
Shift forward 1000 years.  The moats and castle walls are 20 nanometers in dimension; the resources are electricity, CPU cycles, compilers, databases, networks, etc.  I provide Javascript, CPU cycles, RAM storage, and high speed network access to all comers, for free.  These invited guests can do Bitcoin mining, brute force -- or not so brute force -- password guessing, hammer at the rows of stones in my castle walls, and even utilize my resources to attack neighboring castles.
My ancestors are spinning in their graves over my naivete: "Those who cannot remember the past are condemned to repeat it".  [Santayana's version of diagonalizing space.]
I'm an idiot, but an extremely useful idiot.

@_date: 2018-11-22 07:36:21
@_author: Henry Baker 
@_subject: [Cryptography] Buffer Overflows & Spectre 
How can you tell when the "cloud" vendor is lying to you, and running your code in an VM simulation anyway ?
Remember, the whole economic rationale of early "cloud" vendors was to enable a multiplicity of lightly-loaded real hardware computers to be replaced by many fewer time-shared servers.  These vendors had to go to quite a bit of trouble to lie to the software to make it think each software system had the entire machine to itself.
I suspect that people are far easier to lie to than software systems are.

@_date: 2018-11-30 01:31:51
@_author: hbaker1 
@_subject: [Cryptography] What if Responsible Encryption Back-Doors Were 
I attended this "conference" and all of its sessions.
The whole thing was a setup, IMHO.  I think that they were trying to gather possible arguments against backdoors so that they could be prepared for future discussions with politicians.  They also wanted to tell these politicians that there were *some* in the crypto community that thought we all really should leave our keys under the front door mat.
A group of US ex-intel hangers-on, plus some brits, some aussies, and perhaps a kiwi; more or less the 5i's.  They may also have invited some press.  Some of these folks flew on to Australia to wreak more havoc, as best I can gather.
One result of this wannabe conference can apparently be found in the recent activity in Australia to mandate back doors.  These folks apparently wanted to find one of the 5i govts to pass the first test law requiring these back doors, and Australia must have volunteered.
Magical thinking by all.
BTW, with perhaps a handful of exceptions, no actual crypto people attended this conference, which was merely held at the same *location*, so that some of the prestige of a Crypto Conference would rub off on this sham.
The only reason I knew about this conference was that I ran into one of the participants while parking my car for Crypto, and talked with him while walking over to the main venue.
Apparently, I was the only one there who questioned this whole thing, and I asked about the "C" word (Constitution).  I simply said that some of us had pledged to uphold the Constitution, and the reason why *individuals* make such pledges is that they are expected to understand the Constitution well enough to make their own assessment about possible unconstitutional activities and refuse to engage in those activities.  Recall that "simply following legal orders" didn't absolve anyone at Nurenburg, so trusting these 5i's to interpret Constitutionality isn't going to be much of a defense, either.
BTW, the "Lawfare" blog is about as close as one can get to "the unclassified (apologist) voice of the Deep State" & I suspect that Ben Wittes would consider this tag line to be high praise!

@_date: 2018-09-01 13:59:37
@_author: Henry Baker 
@_subject: [Cryptography] God Mode backdoors 
The coolest 50-minute video talk you'll ever see!
Here's the Black Hat 2018 talk about how the God Mode backdoor
was found.  He describes searching the *entire* x86 instruction
set "space" looking for *one* new instruction!  He then reverse
engineers an entirely new 32-bit RISC architecture, which didn't
match *any* of the 30 common RISC architectures that he tried.
Luckily, it shared some registers with the x86 registers.
 GOD MODE UNLOCKED - Hardware Backdoors in x86 CPUs

@_date: 2018-09-24 08:34:00
@_author: Henry Baker 
@_subject: [Cryptography] Did Spectre help torpedo Qualcomm? 
FYI --
How Qualcomm Tried and Failed to Steal Intel's Crown Jewel
By Ian King September 20, 2018, 5:00 AM EDT
In early November, Qualcomm Inc. Chairman Paul Jacobs stood on a stage
in the heart of Silicon Valley and vowed to break Intel Corp.'s
stranglehold on the world's most lucrative chip business.
The mobile internet and cloud computing were booming and the data
centers running this digital economy had an insatiable thirst for
computer servers -- and especially the powerful, expensive server
chips that Intel churns out by the million.  Qualcomm had spent five
years and hundreds of millions of dollars designing competing
processors, trying to expand beyond its mobile business.  Jacobs was
leading a coming-out party featuring tech giants like Microsoft
Corp. and Hewlett Packard Enterprise Co., which had committed to try
the new gear.
"That's an industry that's been very slow moving, very complacent,"
Jacobs said on stage.  "We're going to change that."
Less than a year later, this once-promising business is in tatters,
according to people familiar with the situation.  Most of the key
engineers are gone.  Big customers are looking elsewhere or going back
to Intel for the data center chips they need.  Efforts to sell the
operation -- including a proposed management buyout backed by SoftBank
Group Corp. -- have failed, the people said.  Jacobs, chief backer of
the plan and the son of Qualcomm's founder, is out, too.
The demise is a story of debt-fueled dealmaking and executive
cost-cutting pledges in the face of restless investors seeking quick
returns -- exactly the wrong environment for the painstaking and
expensive task of building a new semiconductor business from scratch.
It leaves Qualcomm more reliant on a smartphone market that's
plateaued.  And Intel's server chip boss is happy.
"They were the ones that had enough clout to make a mark," said Alan
Priestley, an analyst at Gartner Inc.  "Qualcomm had the best chance."
The idea of a Qualcomm server chip business started in late 2012 as
the company looked for new markets beyond smartphones.  Server
processors can sell for more than $10,000 each in a market utterly
dominated by Intel.  The idea was to get the energy efficient
properties of mobile chips into a more powerful design that would
appeal to data center owners such as Microsoft and Google that were
looking to save on operating costs and needed a balance against Intel
in price negotiations.
Qualcomm repurposed its design center in Raleigh, North Carolina,
adding engineers from Intel, IBM and Advanced Micro Devices Inc.  It
was home to some of the most accomplished processor engineers in the
industry.  They'd already designed some of the company's best mobile
chips, products that made the San Diego-based company the biggest
provider of silicon for smartphones.
The 1,000-person team was tasked with creating chips capable of
performing some of the toughest jobs in computing, from making complex
calculations that predict the weather to mapping the human genome.
The most common use, though, is crunching the information flowing
through giant data centers owned by the likes Microsoft, Facebook,
Amazon and Google.  When you search for something on the web, check
your social-media app or buy something online, these are the chips
making it happen.  Intel rakes in almost $20 billion a year in revenue
selling the components.
To break into this business, you can't just make a good chip.  What's
really needed is a road map of future processors that will improve
over time dependably.  Then comes software and engineering support to
convince data center operators that all their programs and services
will work with the components.  One server chip can't just be popped
out and replaced with a different one in an afternoon.  The process
takes years and customers are loath to change what's already working

@_date: 2019-08-02 07:12:55
@_author: Henry Baker 
@_subject: [Cryptography] How to convince web site to use HTTPS ? 
A small organization that I work with (so far) refuses to
move to HTTPS, even though they require a *login* to use
their site.
I'm trying to be diplomatic as possible, but I'd like to
convince them as simply and easily as possible.
Does anyone here have any ideas?
Henry Baker

@_date: 2019-12-10 10:57:30
@_author: Henry Baker 
@_subject: [Cryptography] FBI: Don't trust IoT devices 
FYI --
FBI Portland  Beth Anne Steele  (503) 460-8099
December 3, 2019
Tech Tuesday: Internet of Things (IoT)
Welcome to the Oregon FBI's Tech Tuesday segment. Today: Building a
digital defense in your Internet of Things.
Last week we talked about smart TVs--and how that built-in Internet
connection can allow manufacturers, streaming services, and even
hackers an open door into your home.
This week, we are looking at the larger Internet of Things
(IoT). Basically, this means everything else in your home that
connects to the world wide web. If you look at the holiday wish lists
that your kids, spouse, and parents conveniently dropped on you last
week at Thanksgiving???most everything on there probably makes the cut.
Digital assistants, smart watches, fitness trackers, home security
devices, thermostats, refrigerators, and even light bulbs are all on
the list. Add to that all of the fun stuff: remote-controlled robots;
games and gaming systems; interactive dolls; and talking stuffed
animals ??? well, the list seems endless.
What these all have in common is that they send and receive data. But
do you know how that data is collected? And where it is going?
Another concern is that hackers can use that innocent device to do a
virtual drive-by of your digital life. Unsecured devices can allow
hackers a path into your router, giving the bad guy access to
everything else on your home network that you thought was secure. Are
private pictures and passwords safely stored on your computer? Don't
be so sure.
Here's what you can do to build that digital defense:
    Change the device's factory settings from the default password. A
    simple Internet search should tell you how--and if you can't find
    the information, consider moving on to another product.
    Passwords should be as long as possible and unique for IoT
    devices.
    Many connected devices are supported by mobile apps on your
    phone. These apps could be running in the background and using
    default permissions that you never realized you approved. Know
    what kind of personal information those apps are collecting and
    say "no" to privilege requests that don't make sense.
    Secure your network. Your fridge and your laptop should not be on
    the same network. Keep your most private, sensitive data on a
    separate system from your other IoT devices.
    Make sure all your devices are updated regularly. If automatic
    updates are available for software, hardware, and operating
    systems, turn them on.
As always, if you have been victimized by a cyber fraud, be sure to
report it to the FBI's Internet Crime Complaint Center at ic3.gov or
call your local FBI office.
"Secure your network. Your fridge and your laptop should not
be on *the same network*. Keep your most private, sensitive
data on a separate system from your other IoT devices."
OK, I agree.
So how do I actually do this?  What does "the same network"
1.  The same LAN?  OK, does this means setting up another
LAN subnetwork with a different set of IP addresses ?  I'm
pretty sophisticated about IP networking, but this is going
to be a stretch for me; what % of the U.S. population knows
enough about IP networking to achieve this goal ? 0.1% ?
2.  What if I don't trust the router from my ISP ?  Do I
need to buy another router ?  Do I set up multiple VPN's
*in my own home* ??
3.  I have multiple IoT's from different vendors.  Do I
want them to see one another and possibly cooperate and
share information about me ?  Do I need to set up a
separate VPN for *each IoT device* ??  Even if I'm
willing to do this, how do I do it ?
So consider a hi tech wizard's home with multiple IoT
* one or more iPhones
* one or more Android phones
* one or more Windows laptops
* one or more Mac laptops
* Alexa
* Echo
* Nest thermostat
* Ring doorbell
* August smart lock
* one or more Android TV devices (Netflix/Prime/etc.)
* Samsung smart refrigerator
* Kodi server
* router from untrustworthy ISP (e.g.,
So Openwrt routers are relatively inexpensive and
relatively trustworthy, and support all manner of
VPN's.  Can a handful of these devices help me to
achieve the FBI's recommendations ?
To a first approximation, just consider isolating
each device in such a way that it can't "see" any
other device, but it can still talk to the internet. How best to do this -- even if the device runs
TCPdump/WireShark/Snort/Kismet/Aircrack ?
What configuration would I need to actually achieve
what the FBI recommends?

@_date: 2019-12-11 15:57:48
@_author: Henry Baker 
@_subject: [Cryptography] FBI: Don't trust IoT devices 
Mucho thanks for the info & links!
What about achieving this isolation goal via encrypted tunnels/encrypted VPN's, etc?  Yes, I know, one could still do traffic analysis, but they could probably do that (with additional effort) even with Cisco's mechanisms.
I don't know if I would trust Cisco "port isolation" to devices that can run tcpdump/wireshark/snort/etc. 24x7, even if I had Cisco routers.

@_date: 2019-12-22 09:33:40
@_author: Henry Baker 
@_subject: [Cryptography] OpenSSL: rsa_builtin_keygen: key size too small 
Perhaps someone here can help.
I'm developing a system that utilizes public key encryption, but it
is exceptionally computationally intensive (at least for the machine
that I'm developing it on).
I tried to downgrade the encryption just for the development phase,
but OpenSSL won't allow me to use keys smaller than 512 bits.
Does anyone know how to turn off this error message in order to
work with much smaller keys?
openssl genrsa -out key128.pem 128
"key size too small"

@_date: 2019-12-22 21:30:46
@_author: Henry Baker 
@_subject: [Cryptography] OpenSSL: rsa_builtin_keygen: key size too small 
Thanks Matt, Richard, Viktor.
I've compiled OpenSSL before -- it isn't very difficult -- so I guess I'll have to do it again!
Re embedded processor:
Actually, no, it's the other way around.  The eventual target (if it ever happens) will likely be a lot *more* powerful than my development machine, so I wanted to play with a "toy" version of the software at some reasonable speed prior to increasing the bit-length of the keys.

@_date: 2019-12-25 05:51:21
@_author: Henry Baker 
@_subject: [Cryptography] OpenSSL: rsa_builtin_keygen: key size too small 
I gave up and learned how to make my own keys.
Here's a toy example (perhaps you need a certificate for your 6502-based Apple ][ web server, secure from Intel 4004-based Eve ?)
foo at bar:~ $ cat smallkey.pem
-----BEGIN PRIVATE KEY-----
-----END PRIVATE KEY-----
foo at bar:~ $ cat smallkey.pem | openssl pkey -text -noout
RSA Private-Key: (8 bit, 2 primes)
modulus: 187 (0xbb)
publicExponent: 7 (0x7)
privateExponent: 23 (0x17)
prime1: 17 (0x11)
prime2: 11 (0xb)
exponent1: 7 (0x7)
exponent2: 3 (0x3)
coefficient: 14 (0xe)
foo at bar:~ $ xxd digest.bin 00000000: 0a                                       .
foo at bar:~ $ openssl rsautl -sign -in digest.bin -out signature.bin -inkey smallkey.pem -raw
foo at bar:~ $ xxd signature.bin 00000000: af                                       .
foo at bar:~ $

@_date: 2019-02-13 08:39:14
@_author: Henry Baker 
@_subject: [Cryptography] Practical Enclave Malware with Intel SGX 
FYI --
Practical Enclave Malware with Intel SGX
Michael Schwarz, Samuel Weiser, Daniel Gruss
Graz University of Technology
Abstract.  Modern CPU architectures offer strong isolation guarantees
towards user applications in the form of enclaves.  For instance,
Intel's threat model for SGX assumes fully trusted enclaves, yet there
is an on-going debate on whether this threat model is realistic.  In
particular, it is unclear to what extent enclave malware could harm a
system.  In this work, we practically demonstrate the first enclave
malware which fully and stealthily impersonates its host application.
Together with poorly-deployed application isolation on personal
computers, such malware can not only steal or encrypt documents for
extortion, but also act on the user's behalf, e.g., sending phishing
emails or mounting denial-of-service attacks.  Our SGX-ROP attack uses
new TSX-based memory-disclosure primitive and a write-anything-
anywhere primitive to construct a code-reuse attack from within an
enclave which is then inadvertently exe- cuted by the host
application.  With SGX-ROP, we bypass ASLR, stack canaries, and
address sanitizer.  We demonstrate that instead of protect- ing users
from harm, SGX currently poses a security threat, facilitating
so-called super-malware with ready-to-hit exploits.  With our results,
we seek to demystify the enclave malware threat and lay solid ground
for future research on and defense against enclave malware.
SGX works just fine, sort of; it's the threat model that is faulty.
The usual suspects: ROP, fake stacks.
The new suspects: *transactional memory*, introduced as a *security
feature* (among other virtues), can be used to engage in and hide
mischief: Oops!!
Every *hiding place* can always be used to hide both good and evil,
so there is no such thing as "good"/"always-to-be-trusted" hiding
place ("enclave").
Bottom line: *every* asymmetrical threat model (i.e., one in
which there is an indisputed faith in some 'white hat' actor --
e.g., DRM) is doomed, IMHO.  I shouldn't have to *pwn* my *own*
computer in order to control it.

@_date: 2019-02-17 09:51:40
@_author: Henry Baker 
@_subject: [Cryptography] [FORGED] Practical Enclave Malware with Intel SGX 
It drives politicians bonkers that the tech industry
rolled over for DRM, but not for encryption backdoors.
Perhaps because the SW/game industry started with a
DRM mindset -- remember all those DRM'd floppy disk
SW folks were happy to 'nerd harder', so long as it
was their own bread-and-butter they were protecting.
The latest 'nerd harder': the incorporation of DRM
EME blobs in otherwise-open-source browsers.
W3C will soon learn to their horror what happens
when you let the camel's nose into your own ("pwn"?)

@_date: 2019-02-18 11:42:37
@_author: Henry Baker 
@_subject: [Cryptography] Spectre is here to stay 
FYI --
Spectre is here to stay
An analysis of side-channels and speculative execution
The recent discovery of the Spectre and Meltdown attacks represents a
watershed moment not just for the field of Computer Security, but also
of Programming Languages.  This paper explores speculative
side-channel attacks and their implications for programming languages.
These attacks leak information through micro-architectural
side-channels which we show are not mere bugs, but in fact lie at the
foundation of optimization.  We identify three open problems, (1)
finding side-channels, (2) understanding speculative vulnerabilities,
and (3) mitigating them.  For (1) we introduce a mathematical
meta-model that clarifies the source of side-channels in simulations
and CPUs.  For (2) we introduce an architectural model with
speculative semantics to study recently-discovered vulnerabilities.
For (3) we explore and evaluate software mitigations and prove one
correct for this model.  Our analysis is informed by extensive
offensive research and defensive implementation work for V8, the
production JavaScript virtual machine in Chrome.  Straightforward
extensions to model real hardware suggest these vulnerabilities
present formidable challenges for effective, efficient mitigation.  As
a result of our work, we now believe that speculative vulnerabilities
on today's hardware defeat all language-enforced confidentiality with
no known comprehensive software mitigations, as we have discovered
that untrusted code can construct a universal read gadget to read all
memory in the same address space through side-channels.  In the face
of this reality, we have shifted the security model of the Chrome web
browser and V8 to process isolation.
I hope that we can spend more time 'nerding harder' on problems
like Spectre, rather than 'nerding harder' on encryption backdoors.
*Compression*, in *ALL* of its forms, should be considered 'one
of the usual suspects' when looking for attacks.  In the case of
Spectre, the 'compression' achieved is the *compressed memory
reference string* which is achieved via the *dictionary* ==
*cache contents*.

@_date: 2019-01-08 09:20:30
@_author: Henry Baker 
@_subject: [Cryptography] 35c3: HW SSD encryption == crap 
"Self-encrypting deception"
As you can guess, the built-in encryption for SSD's is
complete crap, but much, much worse: Microsoft Bitlocker
uses it by default if it exists!
Yes, Bitlocker can be told not to use the HW encryption,
but it is a pain, so most people won't go to the extra
effort to ignore the HW encryption.
Bottom line: well-implemented SW encryption is better
than built-in HW encryption.

@_date: 2019-01-09 13:11:09
@_author: Henry Baker 
@_subject: [Cryptography] Digital dyes for tracing digital leaks ? 
If I'm trying to find a leak in my sewer or water pipe, I
can choose from a large variety of colored and/or fluorescent
dyes, which are easily detected when they appear outside the
Ditto for radioactive tracers for even tinier leaks.
Are there standard digital *codes* (other than 0xdeadbeef)
for performing the same function in detecting use-after-free
and other types of data leaks?
Ideally, the codes should be random-looking enough that
they are picked up as possible crypto keys by key-hunting
software, but also easily traced back to different sources.
I was thinking along the lines of linear codes -- e.g.,
some sort of CRC code, where a long enough subsequence
can not only determine the polynomial, but also the
position (i.e., exponent).
Thus, "uninitialied" memory would be initialized to such
a code in such a way that if some of the same bit sub-
sequences showed up again, it might be indicative of a
data leak.

@_date: 2019-01-14 10:01:38
@_author: Henry Baker 
@_subject: [Cryptography] pseudo-homomorphic encryption ?? 
Here's a real-world problem that just came to
light as a result of a recent Ring.com (now
part of Amazon) screwup:
You have some sort of IoT (Internet of Things)
sensor -- perhaps a camera -- and you want to
train an AI/machine learning algorithm to
recognize something that is exposed to the
But perhaps you don't trust the AI/ML developer.
So you send him/her only an encrypted dataset
along with the classification data (yes/no or
perhaps a finite set of possibilities); this
classification data isn't encrypted, and there
isn't any easy way to figure out from the
sequence of classifications any useful info
about the encrypted dataset.
So far as I know, homomorphic encryption hasn't
matured to the point where the entire training
process could operate on homomorphically encrypted
But we're not talking here about completely
generic calculations -- we're talking about
quite limited calculations, just in enormous
quantities (10^18 calculations).
Perhaps there are "homomorphic" encryption
systems that do *just enough* and AI/ML systems
that are dumbed down *just enough* that the
two constraints can meet in the middle.
After all, AI/ML systems don't seem to care
about most kinds of image distortions, so
perhaps they could still be capable of
characterizing certain pictures even after
encryption ?
Obviously, if such things are possible, then
there are clearly information leaks, but these
might even be useful.
The following link was suggested to me, but
I don't know enough about AI/ML to fully
appreciate it:
"Federated Learning: Collaborative Machine Learning without Centralized Training Data"

@_date: 2019-01-22 14:03:13
@_author: Henry Baker 
@_subject: [Cryptography] Downgrade attack on www.bloombergquint.com 
This isn't exactly crypto -- just obfuscation.
Bloomberg Quint -- whatever that is -- wants you
to sign in to see their articles, and if you don't,
they *blur* the text so that you can't read it.
However, if you simply put the same URL into
the *Lynx* ascii browser, you can read the text
just fine.
BTW, this downgrade attack also seems to work on
many sites that want you to do something before
they let you see the rest of their articles.

@_date: 2019-01-22 15:55:51
@_author: Henry Baker 
@_subject: [Cryptography] Stupid question on S-boxes 
For quite a while, S-boxes have been designed to
resist linear and differential cryptography.
The problem with small S-boxes is that you need
a lot of diffusion to spread the confusion around,
and you need a number of "rounds" to achieve this.
But now that we know a lot more about how to design
S-boxes, how come we don't skip the Feistel stuff
and round iterations entirely, and simply use larger
S-boxes?  I.e., if there are constructions which
build large S-boxes from smaller ones, why don't we
just do that?

@_date: 2019-01-25 06:46:19
@_author: Henry Baker 
@_subject: [Cryptography] Stupid question on S-boxes 
I'm not sure what you're saying here.
Are you saying that you shouldn't implement S-boxes in software?  Clearly
S-boxes are *already* being implemented in software, although they tend to
be *small* and *a priori fixed* S-boxes -- e.g., DES, AES.  So yes, the
same sorts of masking and other side-channel defenses continue to be
required.  So "cache timing attacks" can't be a legitimate argument
against the use of "large" -- e.g., 128-bit -- S-boxes, per se.
You might argue that a 128-bit S-box is *too* large to implement in
proper hardware, and that may be a (current) legitimate concern.  But
in a 7nm world, there's less and less that's "too large".
You might be suggesting that the current "large" S-boxes can't
be implemented sufficiently efficiently to be useful in practise,
and you might be (currently) correct about that.  However, as
the history of hardware has shown, critical tasks tend to get
optimized quite quickly, so I'm currently asking a theoretical
question that might eventually become non-theoretical.
You might also worry that I'm suggesting a large *dynamic* S-box,
whose construction might somehow be encoded into a private key.
I'm not (currently) suggesting this, as AES has done just fine
with a priori fixed S-boxes, so I suspect that dynamic S-boxes
won't be necessary, although some have argued that dynamic
S-boxes avoid rainbow table-type attacks.
Once again, I'm suggesting that the Feistel structure and
multiple rounds is an attempt to build larger S-boxes from
smaller ones, and we're getting to the point where these
newer constructions may be better than the Feistel/round
mechanisms for performing this recursive construction. That's my basic question.

@_date: 2019-01-25 11:16:26
@_author: Henry Baker 
@_subject: [Cryptography] Stupid question on S-boxes 
The last time I looked (several years ago), there appeared to be *no way* on many architectures to empty a cache line *without writing it to memory*, and more importantly, no way to guarantee that a cache line is *never written to memory*.  There used to be architectures that would guarantee that a memory reference would *bypass* the cache(s), but that's now so slow that no one seems to care about that any more.
As is becoming obvious, our current models of programming languages and hardware architectures are completely inadequate to the task of assuring no bit leaks.  We need new *typing models* for programming languages, and new constraints for HW that guarantee that certain bits will only go where they're told to go, and *no place else*.
Yes, there will continue to be devastating DPA attacks, but for the vast majority of privacy issues, it would be great that anyone pawing through the trash (memory, registers, caches, etc.) won't see private bits.
For example, caches might want to become *exclusive* -- i.e., an (address,value) can't reside in more than one location (memory,L3,L2,L1,etc.) at one time; it might even be interesting to include *registers* in this list (yes, tagging will be required, but is long overdue for modern architectures).  Perhaps this constraint should only apply to pages marked RW, as some RO pages -- e.g., shared .exe pages -- might be less interesting.

@_date: 2019-07-15 14:27:42
@_author: Henry Baker 
@_subject: [Cryptography] Apollo Guidance Computer as Bitcoin mining rig 
Ken Shirriff's blog
Bitcoin mining on an Apollo Guidance Computer: 10.3 seconds per hash
We've been restoring an Apollo Guidance Computer.  Now that we have the
world's only working AGC, I decided to write some code for it.  Trying
to mine Bitcoin on this 1960s computer seemed both pointless and
anachronistic, so I had to give it a shot.  Implementing the Bitcoin
hash algorithm in assembly code on this 15-bit computer was
challenging, but I got it to work.  Unfortunately, the computer is so
slow that it would take about a million times the age of the universe
to successfully mine a Bitcoin block.
Computer from NASA's Apollo program reprogrammed to mine bitcoin
It takes the Apollo Guidance Computer 10 seconds to compute a single
hash value.
Timothy B. Lee - Jul 9, 2019 10:15 pm UTC
Bitcoin mining on a vintage Xerox Alto: very slow at 1.5 hashes/second
I've been restoring a Xerox Alto minicomputer from the 1970s and
figured it would be interesting to see if it could mine bitcoins.  I
coded up the necessary hash algorithm in BCPL (the old programming
language used by the Alto) and found that although the mining
algorithm ran, the Alto was so slow that it would take many times the
lifetime of the universe to successfully mine bitcoins.
Not so good performance, but an interesting data point for Moore's Law.
I'd be a lot more curious about the Apollo Guidance Computer's ability
to do a full TLS handshake (or a "measured boot"), so that it couldn't
be hacked by the Russians...

@_date: 2019-07-16 06:59:31
@_author: Henry Baker 
@_subject: [Cryptography] Alan Turing to Be Face of 50 Pound Note 
Wouldn't it be more appropriate to have Turing's face
on a Bitcoin?
Or a silver coin?  (Really, really obscure reference to
something non-codebreaking that Turing did in WWII.)

@_date: 2019-07-18 15:58:38
@_author: Henry Baker 
@_subject: [Cryptography] Digression: "Letterlocking" and URLs and 
One minor point:
On some URL's, there is some sort of hex token used *after* the "?", and this token is *required* in order to view the content.
How to tell: fire up a *different* browser (i.e., one with different cookies), and copy/paste the URL *withOUT the stuff after "?"*, and if the content comes up ok, then you're good to go with that truncated URL.  If not, you may have to figure out which of the parameters (the stuff between "?" and "&", or between "&" and "&") has the token, and which has the tracking stuff.
Of course, if the web site is clever, the token provides an index into the tracking info, so they don't need any of the other tracking stuff.

@_date: 2019-06-20 22:43:55
@_author: Henry Baker 
@_subject: [Cryptography] Shamir's secret sharing 
Shamir's Secret Sharing has *information theoretic security*; i.e.,
without sufficient information, NO amount of computation (quantum
or otherwise), can recover the secret.
In particular, Lagrange Interpolation (over a finite field) can
be constructed for *every* different set of bits, so if you get
one bit wrong, you'll get the wrong answer, which isn't related to
the right answer in any way that a computer (quantum or otherwise)
can compute.
Google the Wikipedia entry.
There are many other problems with this scheme, but quantum computing
isn't one of them.
I have long advocated using Shamir Secret Sharing for storing portions
of a database in N different countries, where the portion and the
countries are carefully chosen to minimize the possibility of
"rubber hose"/warrant-maybe/extradition attacks on the cloud providers
in each of the N countries.  I'm kinda amazed that this isn't already
being done -- perhaps because it is difficult to find non-AWS,
non-Microsoft cloud providers in enough different countries.

@_date: 2019-03-21 13:54:14
@_author: Henry Baker 
@_subject: [Cryptography] Best/simplest document encryption 
Hi all:
Here's the most basic crypto question of all:
What is the best (most secure & easiest to
use) system for *non-crypto* people to use
who have different platforms?
I.e., there are *senders* and *receivers*:
Senders can encrypt & send from a number of
different platforms: Windows, MacOs, Linux,
iPhone, Android.  Document can be anything
from a text file to a (small) movie.
Receivers can decrypt & receive on the
same platforms.
I don't trust Chrome or Firefox to do the
encryption/decryption, but I'm happy to let
them do the transmission of the encrypted
I would love to use an open source system
if one exists, and I'd love to be able to
do a *reproducible build* of such a system.
For this purpose, I'm primarily interested
in commercial secrets, but these secrets
could conceivably be worth > $1 million.
Obviously, I can't control what happens if
either the sender's or receiver's platform
is compromised, but I would like to force
the sender & receiver to actually type in
a password/passphrase that they can exchange
via a 2FA (e.g., a phone call).
For this particular application, a symmetric
key system might be adequate.
It might be a good thing if the encryption
program kept a history list of salted hashed
passphrases to make sure that the user never
used any of these again.

@_date: 2019-03-22 07:06:53
@_author: Henry Baker 
@_subject: [Cryptography] Best/simplest document encryption 
I particularly didn't want encryption that was
built into anything else, because that greatly
expands the vulnerability surface.  You also
then have to trust that someone who's good at
this other application will be good at
encryption, and we know that's *never* the
In particular, I didn't want encryption built into:
* email
* browsers
* compression (e.g., 'zip')
* pdf
I just want high quality document encryption/decryption,
I was thinking more along the lines of some
GUI on top of OpenSSL, or other high quality
encryption package.

@_date: 2019-09-17 04:44:51
@_author: Henry Baker 
@_subject: [Cryptography] "Exclusive: Russia carried out a 'stunning' 
mail.com>
Re: "No improvements to 3G 4G LTE (and now 5G?) were allowed...  Stingray tools apparently must function as a priority":
Perhaps this "rule" is the reason for the current freakout over Huawei's lead in 5G systems?  I.e., 5G could be the worst of both worlds for the 5i's: China's backdoors will work on 5G, but 5i backdoors won't work on 5G.
Aside: Israel has been fingered as the culprit for the "unauthorized" stingrays in the DC area, presumably to spy on Trump's well known vulnerable cellphone, but the Trump administration apparently doesn't care, and won't censure Israel.

@_date: 2019-09-21 17:10:32
@_author: Henry Baker 
@_subject: [Cryptography] "Exclusive: Russia carried out a 'stunning' 
We're all *still* paying the price for the last crypto wars in the form of "downgrade attacks".
what do you think we're "downgrading" to?  A: "export grade" encryption.
Also, I seem to recall that the voice encryption in various flavors of GSM systems is still quite breakable -- probably in real time -- thanks to Crypto War I.
Google's now claiming "NOBUS" quantum computing capabilities.  Who do you think controls the vast majority of email and cellphones?
"Don't be evil", indeed!
(My April Fool's Risks submission claims that the disappearance of Google's "Don't Be Evil" slogan was their "warrant canary" being activated.  There is unfortunately growing evidence to support this bad joke, which is on all of us.)

@_date: 2019-09-29 08:15:26
@_author: Henry Baker 
@_subject: [Cryptography] "Strong" passwords too clever by half... 
I used a "^" character in a password, but I
recently discovered that this character is
impossible to input with some versions of
Android keyboard programs.
On the other hand, I don't have the slightest
idea how to input a swipe pattern from a
Linux command line.
How long before stories appear about bank
accounts not being able to be accessed
because all of the HW/SW that enabled
access has gone to the recycling center
in the sky?

@_date: 2019-09-30 13:44:45
@_author: Henry Baker 
@_subject: [Cryptography] Encryption and anonymity as top tools for images 
I'm sorry if I sound cynical, but perhaps I've lived too long and seen too much.
To a first approximation, politicians use "child pornography" as a boogey man to scare unsophisticated voters into supporting universal surveillance ("no place to hide"), aka "back-doored encryption".
Followers of Russ Roberts's excellent Econtalk podcast will quickly recognize the "Baptist & Bootlegger" unholy alliance going on here.  The Baptists wanted Prohibition, because they didn't want anyone to drink alcohol for religious reasons, while the bootleggers wanted Prohibition, because it expanded the market and drove up the prices for bootlegged whiskey.  Those against child pornography (most of us) team up with the bootleggers -- NSA/CIA/FBI/Google/Facebook/Twitter/etc. -- who want a modern Panopticon with no "ungoverned spaces" -- not even the spaces between our ears!
Prohibition was finally ended because the cure was worse than the disease: Prohibition helped produce the modern Mafia and led to huge increases in big-city crime & violence, as well as major corruption among big-city police forces.  Perhaps there is an equivalent lesson here for "back-doored encryption" (I like to call it "hack-doored encryption") ?
None of us want child pornography, but once we realize that the price of *zero pornography* is also *zero civil rights* and *zero free speech*, then we appreciate the wisdom of President Eisenhower: "If you want total security, go to prison.  There you're fed, clothed, given medical care and so on.  The only thing lacking... is freedom."  (Oh, and by the way, child pornographers don't last very long in prison; just ask Jeffrey Epstein.)

@_date: 2020-04-02 20:07:41
@_author: Henry Baker 
@_subject: [Cryptography] "Zoom's end-to-end encryption isn't 
Yes, I saw this & other articles re Zoom security/privacy issues.
So I was thinking, how secure/private could a multiple-party
Zoom conference possibly be?
So let's do end2end encryption on every video/audio feed.
But we probably need 2 video feeds for each participant: one hi-rez,
good enough for a full screen and 1 lo-rez, good enough for the
smaller videos.
And then there's Zoom's ability to replace the background; clearly
that will have to be done at the source, prior to encryption; it
can't be done at the server end.
So let's assume that the server only sees encrypted audio & video
The server still knows who each of the participants is: it knows
their IP addresses & verified email addresses.
The compositing must now be performed by the end users, who now
receive *all* of the feeds, but they indicate whether they want
the hirez or lorez video feeds depending upon who is *talking*. (The decision about who is talking must be a decision by perhaps
the host machine, which can "see" all of the client machine's
video/audio feeds.
So yes, it should be possible for Zoom to run a conference w/o
being ableto hear or see any of the participants; however, it will
know who the participants are, and when & how often they grab the
"floor" and start to speak.
So there's a lot of information leaking into the "metadata" channel
of Zoom itself.
Are there any better ways to hold a group conference?

@_date: 2020-04-07 07:04:16
@_author: Henry Baker 
@_subject: [Cryptography] Privacy post COVID 
Don't forget that video can now detect heart rate (thanks, MIT).  So a screen fingerprint reader should now be able to do this.
DARPA zeroing in on ability to characterize & identify people via heart rhythms (also from video -- not iWatch skin measurement).

@_date: 2020-04-08 06:08:31
@_author: Henry Baker 
@_subject: [Cryptography] Crypto quarantining movies 
"Dr. Strangelove":
Brute-force search of 3-letter codes ("permutation" is used incorrectly in the movie).
Correct code ("OPE") would be found after 56% of the 17,576 3-letter codes had been tried.
Trivia: 7090 computer with 1401 I/O computer attached is featured prominently.
Curiously, a transistor radio is used in the computer room; just recently on crypto we discussed transistor radios as side-channels for 1960's computer equipment.
The opening sequence of in-flight refueling is Kubrick's aviation update to Hitchcock's train-going-into-a-tunnel trope from 'North by Northwest'.
"Address Unknown":
When sending or *receiving* encrypted messages is a capital crime, one can commit remote murder by merely sending an encrypted message whose contents are irrelevant/meaningless; the Nazis also believed in "we kill people based on metadata".

@_date: 2020-04-08 19:29:09
@_author: Henry Baker 
@_subject: [Cryptography] Zoom misrepresented end2end encryption 
FYI --
Zoom Accused of Misrepresenting Security Measures in New Lawsuit
Catie Keck  Today 3:40PM
Following extensive reporting on egregious security failures, video
conferencing company Zoom is now being sued by a shareholder over
allegations of fraud and overstating the security protocols in place
on its service.
In the lawsuit filed Tuesday in the U.S. District Court for the
Northern District of California, plaintiff Michael Drieu--on behalf of
individuals who purchased Zoom securities after the company went
public last year--accuses the company of making "materially false and
misleading statements" about its product and failing to disclose key
information about the service. Namely, the suit cites Zoom as claiming
that its product supported end-to-end encryption, when in fact it
supports a different form of encryption called transport
encryption--as the Intercept reported last month--that still allows
Zoom to access data.
Additionally, the suit alleges that Zoom's security failures put users
"at an increased risk of having their personal information accessed by
unauthorized parties, including Facebook," that these facts would
necessarily result in a decline in users, and that the company's
responses to ongoing reporting on myriad problems on the service were
"misleading at all relevant times." The suit states that the fallout
from these incidents was exacerbated by the covid-19 crisis, during
which time users of the service jumped from just 10 million to 200
million in a matter of months as schools and organizations turned to
Zoom amid social distancing measures and shelter-in-place orders.
The suit cites documentation related to Zoom's IPO as evidence that
the company misrepresented the security protocols in place for
protecting users. Specifically, the suit states, Zoom said it offered
"robust security capabilities, including end-to-end encryption, secure
login, administrative controls and role-based access controls,"
and--in what was clearly an embarrassing claim by the company--that it
strives "to live up to the trust our customers place in us by
delivering a communications solution that 'just works.'"
Zoom did not respond to multiple requests for comment.
The last few weeks have had a devastating impact on Zoom's public
image, as the company various companies and educational institutions
have stopped using the service amid reporting on security failures as
well as so-called "Zoombombings." These events--wherein hackers access
meetings that include everything from remote grade school classes to
addiction support groups in order to post porn and other lewd or
disturbing imagery--have prompted a warning from the Federal Bureau of
Investigation as well as multiple state investigations into Zoom's
security measures.
Amid ongoing reporting on the company's overt failures, Zoom CEO Eric
Yuan issued a public apology last week addressing the issues.
"We have strived to provide you with uninterrupted service and the
same user-friendly experience that has made Zoom the
video-conferencing platform of choice for enterprises around the
world, while also ensuring platform safety, privacy, and security,"
Yuan said. "However, we recognize that we have fallen short of the
community's--and our own--privacy and security expectations. For that,
I am deeply sorry, and I want to share what we are doing about it."
Oops!  You really don't want to misrepresent yourself in your S-1
IPO document.
I really think that Zoom wants to do better, so I hope that these
lawsuits don't put them out of business.
Some of Zoom's competitors, however, have far worse systems; the
only difference is, these competitors never claimed to have had
privacy or security (cough, cough, Google, cough, cough, Microsoft,
cough, cough, Facebook, cough, cough).

@_date: 2020-04-10 09:36:05
@_author: Henry Baker 
@_subject: [Cryptography] But Zoom is fixable 
You are absolutely correct, but this current flap is being fueled
by players who desperately *want* Zoom to fail: Facebook, Google,
Microsoft, NSA, GHQ, etc., etc.
These players have already spent billions acquiring and/or hacking
existing systems; they don't want to have to keep investing more $$$.
The message is going out: startups, don't even think about coming
out with true end2end encryption, because we're going to crush you
with FUD.
They're also working behind the scenes with crypto killers like
EARN-IT to cast their desires into law.  See the latest post by
Signal, that they will be forced out of the U.S. by EARN-IT.

@_date: 2020-08-25 10:20:11
@_author: Henry Baker 
@_subject: [Cryptography] any reviews of flowcrypt PGP for gmail? 
Perhaps I'm being paranoid, but why does Signal *require* some of the Android permissions it seeks?
I'd rather have a version of Signal that *doesn't* use SMS, but depends only upon standard internet protocols routed through Tor.
I fully expect to wake up some morning and read about the NSA being behind yet another Swiss company -- in this case Silent Circle.
jes sayin' ...

@_date: 2020-12-18 16:36:25
@_author: Henry Baker 
@_subject: [Cryptography] Solar Winds hack 
I'm a bit suspicious of the timing of the announcement
of this hack.
Does anyone know when the hack was actually discovered?
(BTW, SolarWinds are apparently winds emitted from where
the Sun DON'T shine!)

@_date: 2020-02-11 15:33:48
@_author: Henry Baker 
@_subject: [Cryptography] Crypto AG and CIA project exposed 
Wasn't this simply a follow-on to the Enigma-clone that was sold to
many govts around the world in the 1950's & 1960's ?
If this is news to WaPo, then they simply haven't been paying attention.
cough, cough, NSA, cough, cough, RNG, cough, cough...
Highly recommended podcast: "Ratline" from the BBC.  Spoiler alert:
"Paperclip" wasn't the only Nazi-washing operation post-WWII.
(German translation: "Persilschein" -- i.e., washing Nazis with Persil
detergent -- known to everyone who likes Miele appliances).

@_date: 2020-02-13 08:09:01
@_author: Henry Baker 
@_subject: [Cryptography] "?The intelligence coup of the century?" 
If you read the article, it appears that many of the flaws were
pretty obvious to untrained eyes -- albeit clever eyes.
Forget about the Five Eyes...
The Soviets (& perhaps the Chinese) were laughing their
butts off, as they were probably reading everything, as well.
I was intrigued by the use of the 'useful idiot' Swede
Widman instead of Arne Beurling (who apparently single-
handedly broke the German codes in WWII).  Perhaps Beurling
wouldn't go along?
Q: Wouldn't Beurling have noticed any problems with these
machines?  Perhaps he was never asked, or never looked?
(According to Wikipedia, Beurling died in 1986.)

@_date: 2020-02-13 08:31:50
@_author: Henry Baker 
@_subject: [Cryptography] 'The intelligence coup of the century' 
This WaPo article throws gasoline onto already blazing conspiracy theories about DoD's relationship with hi tech firms -- Intel, AMD, TI, Microsoft, RSA Security, Google, Facebook, Amazon (AWS), etc.
Cough, cough, In-Q-Tel, cough, cough, Google, cough, cough, Eric Schmidt, cough, cough, Sheryl Sandberg, cough, cough, Palintir, cough, cough, Steve Blank's 'Secret History of Silicon Valley', cough, cough, Facebook, cough, cough, cough, gag.
In 2050, we'll be reading in WaPo that Facebook/Google was 'the intelligence coup of the [21st] century'.
Huawei will now finally do what they should have been doing all along: rip every bit of Western technology out of their communications infrastructure and build their own technology completely from scratch.  It will cost trillions (which they can afford), but the rest of communications technology in the 21st C. will be written in Chinese characters.
(The U.S. did the same thing to the Brits in the 19th C., when the Brits kept trying to screw the U.S. with railroad technology, and yet again with long wave radio.)
Perhaps someone in the U.S. intel community should Google 'blowback'?

@_date: 2020-02-13 11:28:46
@_author: Henry Baker 
@_subject: [Cryptography] JavaScript Service Workers == browser besigers 
FYI --
Saleem Rashid  Feb 9, 2020
Exploiting Netgear's Routerlogin.com
A recent tweet about Netgear's inclusion of private keys for trusted
HTTPS certificates in their router firmware sparked a discussion about
whether this presents a material security risk. Many security experts
concluded that, unlike previous uses of this technique, there was no
realistic attack scenario in Netgear's case. But, in this post, I am
going to demonstrate that to be incorrect.
Before we plunge into the details of the exploit, we need to
understand the context behind this and why Netgear chose to do what
they did.
Wireless routers usually offer a convenient web-based setup page but,
outside of your network, the IP address or domain name you use to
access it means nothing. If you were connected to a different network,
this same IP address might take you to a different router's setup
page. For this reason, a certificate authority cannot issue your
router an HTTPS certificate to promise that you're connected to the
real 192.168.1.254 or router.lan.
If you use unencrypted HTTP, you're sending your router's
administration password to whichever device on your Wi-Fi network
claims, on the honor system, to be your router. If another device is
pretending to be your router ??? e.g. using ARP spoofing ??? your browser
will happily send it the password.
As an alternative, most routers offer HTTPS with a self-signed
certificate. But this comes at a great cost to the user experience: it
requires users to bypass the browser security warnings. This is
unworkable as it normalizes an action that undermines the entire
security of HTTPS.
Since it can only be exploited by users connected to the network,
unencrypted HTTP is not a big deal for most home Wi-Fi users. Their
biggest threat is probably crafty teenagers sniffing the router
password to turn off the parental controls. But Netgear was still
unhappy: they wanted their customers to be able to access their router
with a secure HTTPS connection without any scary certificate errors or
Is This the Real Routerlogin.com?
In their crusade for the coveted green padlock, Netgear procured a
certificate for routerlogin.com and included the private key in their
router firmware. When you visit this domain name on a Netgear Wi-Fi
network, the router's DNS server returns its own IP address and you
connect, over HTTPS, to the router's configuration page. This
connection is trusted by the browser, even though the domain points to
an internal IP address, because the router has a valid certificate for
Wonderful! Except that the private key is in any Netgear router so
anyone can extract it and impersonate your router. Or they could
obtain it from the firmware downloads available on the Netgear
website. Your hypothetical crafty teenager just has to run their own
HTTPS server and the browser will still trust it as if it were the
router. Therefore, there is no material security improvement.
When details of Netgear's approach hit Twitter, the certificates were
revoked because certificate authorities have a duty to do so when the
private key is "compromised" ??? even if it was deliberate. But did the
compromised certificates actually present a security issue, or were
the certificate authorities merely acting out of an abundance of
Many security experts on Twitter concluded that there was no realistic
attack scenario. Netgear's setup is not vulnerable to the usual attack
scenario ??? "DNS rebinding" ??? so it is a reasonable conclusion. But I
was not content that DNS rebinding was the only way.
Why Not DNS Rebinding?
If an attacker tricked the user into using a malicious DNS server,
they could impersonate routerlogin.com because they have the private
key for a valid HTTPS certificate. This is not very useful on its own
because the aim is to modify router settings ??? this means you need to
phish the administration password and then connect to the router
itself. The latter can be achieved by using a short Time-To-Live (so
the browser does not cache the DNS entry for long) then "rebinding"
the DNS entry to point to the router's internal IP address again. Then
you can make requests to the router without violating the Same-Origin
Policy ??? the browser believes that it is the same origin because it is
the same domain name, even though the underlying IP address changed.
But this is unlikely to work: the usual attack vector for a malicious
DNS server would be when the user is using an attacker-controlled
network, e.g. public Wi-Fi or an unscrupulous VPN provider. However,
in this case, the attacker cannot connect to the router as it is
unreachable outside of its own Wi-Fi network. Moreover, you cannot
phish the password because the victim has no reason to visit the
router management page when not connected to their router!
Thus, it is clear that we cannot attack the router while the user is
still connected to our malicious network.
But what if we could install code on the victim's computer while they
are connected to our malicious network, and have that code execute
when the user returns to their home Wi-Fi network?
Introducing Service Workers
If you aren't familiar with Service Workers, here is the "security researcher introduction": they are JavaScript workers that run in the background and allow you to intercept all HTTP requests made by a website. For example, you could use one to inject JavaScript code into all the HTML pages from a domain. And the cherry on the cake is that, once installed, they persist until the user clears their browser data ??? with no indicator that they are installed.
For these reasons, they are incredibly dangerous if an attacker can somehow install one on your domain. Luckily, the W3C foresaw this and added a strict requirement: Service Workers must be served over HTTPS from the same domain.
But this requirement is not an obstacle when an attacker can obtain a valid HTTPS certificate for your domain and impersonate you! Thus, if the user's browser loads routerlogin.com while connected to a malicious Wi-Fi network or VPN, someone could install a Service Worker for the domain. This could be achieved by injecting a hidden iframe for routerlogin.com into a Wi-Fi captive portal or a random HTTP webpage that the victim was browsing. When the user connects to their home Wi-Fi network again and visits routerlogin.com, the Service Worker could inject malicious JavaScript into the router management pages!
Proof of Concept
I am comfortable providing a proof of concept without responsible disclosure because Netgear's certificates have been revoked so HTTPS connection to  are not trusted by browsers anymore.
First, you need to clone the proof of concept.
git clone cd evilrouterlogin
Then, you need to set some configuration variables. We write them to .env because Docker Compose will automatically read any environment variables from this file.
cat > .env << EOF
The repository contains a Docker Compose configuration with two networks:
The evil network ??? this is the "malicious Wi-Fi network" scenario. It
serves a malicious captive portal on  and the
Service Worker installer on The secure network ??? this is the equivalent of your home Wi-Fi
network. This serves the router configuration page on
 Because I do not have a Netgear router, it
emulates the vulnerable setup by mirroring my router's HTTP
configuration page from  to
 You will need to change PROXY_ADDRESS if your
router has a different IP address.
As I mentioned before, we cannot use Netgear's certificates because
they were revoked and will not be trusted by your browser. You could
register a domain name and use Let's Encrypt to obtain a trusted
certificate, replacing routerlogin.com in the above with your own
domain name.
But that is needlessly complicated. Instead, we are going to install
mkcert ??? a helpful utility to generate a root certificate authority
and install it in your computer's trust store. Once you have followed
the installation instructions, you need to issue a certificate for the
router management page.
source .env
mkcert "$ROUTERLOGIN_NAME"
Finally, we start the containers.
docker-compose up
unbound-evil. This should give you an IP address like 172.18.0.2. You
need to set this as your DNS server and flush your DNS cache. Once you
have done this, close and re-open your browser (to ensure the
browser's own DNS cache is also flushed) and visit
 You should be redirected to
 and greeted with a beautiful page
like the one shown below.
Welcome to Public Wi-Fi Captive Portal
Next, run the command scripts/container_ipaddr unbound-secure and
change your DNS server to this IP address. This time, after closing
and re-opening your browser, visit  You should
see a familiar router configuration page, but with a slight twist.
BT Home Hub configuration page with embedded Techno Chicken YouTube video
What happened is that  redirected to
 which installed the Service Worker ??? remember,
the Service Worker must be installed over HTTPS ??? and redirected back
to  Although an  might have
worked, many privacy add-ons will prevent them from installing Service
Workers; the redirect gave much more reliable results.
Even when you connected to the secure network, the Service Worker
installed by the evil network is still running. It injects an embedded
YouTube video and a small amount of JavaScript (check the browser
console!) into any router management pages you visit.
Even if the user were using DNS-over-TLS or DNS-over-HTTPS, the
malicious Wi-Fi network could intercept packets to the IP address
behind routerlogin.com and perform the same attack.
An attacker could use this to modify any of your router's settings,
including changing your network's DNS server or enabling port
forwarding to access other devices on your LAN ??? particularly
frightening if you have poorly configured IoT devices connected to the
While I could not find any prior literature on abusing Service Workers
in this way, this is unlikely to be a novel idea. However, not only
does this let you exploit a setup when DNS Rebinding alone cannot, it
also allows you to develop more reliable DNS Rebinding attacks.
For example, if the router management page did not require
authentication, there would be no need to phish the user and an
attacker could instead use the Service Worker's Background Sync API to
perform the attack without any interaction from the user.
While DNS Rebinding are attacks are challenging to avoid, Service
Worker-based attacks are easy to defeat: Never disclose the private
key for your HTTPS certificate!
Saleem Rashid
    dev at saleemrashid.com
Fascinated by cryptography and trustless systems
It is the 12th Century.
If I were the owner of an 'impregnable' castle, complete with
a deep, wide moat, I'd want to make my besiegers comfortable, so
I would supply them with food, water, electricity, gasoline,
everything that they might want/need in order to improve their
chances at breaking into my castle.  :-)
Fast forward to the 21st Century, and we provide our network
attackers the same comforts of home in the form of *browser
capabilities*, including free CPU cycles, free RAM storage,
free Internet access, and free access to our keyboards, screens,
cameras, microphones, mice, 'trusted' modules, Bluetooth,
and wifi LAN's.
What could possibly go wrong?
Isn't it time to start making it a little less comfortable
for the besiegers, by denying them most and/or all of the
resources that they want to use to attack us?

@_date: 2020-02-13 17:06:01
@_author: Henry Baker 
@_subject: [Cryptography] 'The intelligence coup of the century' 
IMHO, the article is about the U.S., using its subtle (or not-so-subtle)
power of 'suggestion' to enable a company from a neutral country to
bend over to the CIA/NSA.  It sounds somewhat similar to the position
of Ericsson as a 'neutral' telecom vendor providing access to its customers'
backdoors when 'properly' asked.
Nevertheless, in the Internet age, for good or for ill, the only games
in town were U.S. vendors, so many U.S. entrepreneurs *may have* had to
gulp twice and accept NSL deals that were "too good" to pass up.  The
Lavabit refusal to cooperate was remarkable for its rarity.
"That's a lovely little company you have there; it would be too bad if
you got shut down over H1B visas/export licenses/HSR approvals on your
The CIA/NSA are not above putting 'employees' into U.S. companies, even
if/when the management&Board won't play along.  I wonder if this type
of activity falls under the CIA's prohibition against *domestic spying*?

@_date: 2020-02-13 21:08:51
@_author: Henry Baker 
@_subject: [Cryptography] 'The intelligence coup of the century' 
I seem to recall that the Easties were fond of copying DEC equipment,
while the Russkies were fond of copying IBM equipment.
Just before 2000, there were a lot of 70year-old IBM programmers fixing
really old 1960's/70's Cobol programs in the U.S.; many of them were
*ex-Soviets* who learned on 1960-era IBM 360 'mainframe' copies.  For
some reason, the Soviets stuck with the 1960's IBM DOS/TOS SW, even
after 370-era software became available.
Some of this Cobol SW is undoubtedly still running in emulation in
DMV's and also handling vote tabulation all across the U.S. :-)
Perhaps DEC never had a Y2K problem, so I don't recall Eastie programmers
working on Y2K issues.
BTW, IBM mainframes had powerful radio side-channels: in the early
1960's, one of the programmers that worked with me used to put an
ordinary portable radio on top of the IBM CPU so that he could
"listen" to his program go through its paces.  Any change in the
audio would indicate a problem with the software.
I would guess that this radio technique would have been sufficient
to enable a person listening to pick out the individual bits in a
modular exponentiation, as those computers weren't all that fast.
We didn't have a name for it, but in retrospect we should have
called it 'ADB' -- 'Audio Debugging Bridge'.
I never tested the *range* of these radio signals, but I suspect
that they could easily have been heard outside the building
where the computer was located.

@_date: 2020-02-15 08:51:04
@_author: Henry Baker 
@_subject: [Cryptography] 'The intelligence coup of the century' 
]
Post-WWII, the Brits used inductive coupling to grab data
from the cables leading to teletypes in SCIF-type rooms.
I believe that the U.S. & West German govts had ready access
to most all of the main telephone cables in East Berlin due
to their having been run through the subway/underground system.
Of course, the same was also true of the West Berlin cables,
but I think that the West German cables were relatively soon
patched around to avoid this attack by the Easties.
An aside re W. German telephone lines:
Thanks to the U.S. taxpayers, the U.S. replaced virtually
the *entire* W. German telephone system post-WWII.  As a
result, W. Germany has the *best copper* in the world!
So W. Germany was in a better position to utilize "DSL"
technolgy better than anywhere else.  Too bad they didn't
wire up with coax or fiber...  :-(
And during WWII itself, the Swedes tapped into the cables
running some of the German traffic through Sweden, and were
able to decrypt & read this traffic.

@_date: 2020-02-15 09:17:55
@_author: Henry Baker 
@_subject: [Cryptography] 'The intelligence coup of the century' 
I don't know about TEMPEST-like stuff, but most digital
devices today must pass an FCC test to make sure that they
don't interfere with intentional radio communications signals.
One of the main offenders of modern clocked logic is the
clock frequency itself (and its harmonics).  One way to
reduce the maximum power in these frequencies is to utilize
"spread spectrum clocking" which mixes in a pseudo-random
code to "spread" the power around the spectrum instead of
having high peaks on these harmonics.
These spread-spectrum clocking pseudo-random codes aren't
very long, and aren't designed with cryptography in mind,
but you could easily build your own pseudo-random code
clock circuitry which could be programmed on-the-fly just
like chips today control their own clock frequencies in an
extremely crude way to control power consumption.
There are standing FCC rules which forbid the use of
extremely long & crypto-grade codes for spread spectrum
communications, but if these codes were to be used for
clocking an otherwise normal CPU, I'm having trouble
understanding how anyone would know -- unless perhaps
the FCC/NSA has a comprehensive catalog of all existing
spread spectrum clock codes, and yours pops up as not
being in that catalog.
Oh, and yes, these modulated clocks could be used to
exfiltrate data quite long distances, since long
spread spectrum codes can be used to hide the data
many dB's below the noise floor.  E.g. battery-powered
spread spectrum radios which can run for *10 years*
and which live in water meters -- i.e., below ground --
and can communicate a number of miles, were built in
the 1990's, and I presume are even better today.
(Hint: NASA JPL uses long spread spectrum codes like
these -- although not crypto-grade -- to talk to
probes that are beyond the orbit of Pluto.)

@_date: 2020-02-15 15:08:59
@_author: Henry Baker 
@_subject: [Cryptography] 'The intelligence coup of the century' 
All the IBM CE's and SE's had pagers, so perhaps paging frequencies were exempted??  :-)
I talked with a salesman of Tempest enclosures in Los Angeles back in the 1980's, and since
he couldn't talk about any govt clients, he told me the story of one of his non-govt clients:
a rock star living in Hollywood who had trouble sleeping, and who thought that aliens were
keeping him awake with 'rays' of some sort, so they built him a Faraday Cage for several
million dollars to sleep in.
He wouldn't reveal the name of the rock star, nor would he tell me whether the cage improved
his sleeping.  (The cage would work today, because his smartphone wouldn't work inside!)

@_date: 2020-02-15 15:21:24
@_author: Henry Baker 
@_subject: [Cryptography] 'The intelligence coup of the century' 
The NSA came to MIT to recruit computer science people in the early 1970's,
and they brought a van and parked it at the base of the 9-story building
at 545 Tech Square.  Supposedly (I didn't go inside the van, but was told
by others) that the van was showing -- in real time -- the contents of the
video screens on the 9th floor in the computer room.
Since I wasn't there, and didn't see the complete setup, I couldn't
tell from the story whether they were simply receiving the video signals
from the video monitors, or whether they had hacked into the computers.
The video signals would be relatively easy to capture, but then how
could they separate out one particular screen from 50-100 *other screens*
operating in various floors of this building in real time?

@_date: 2020-02-22 09:04:02
@_author: Henry Baker 
@_subject: [Cryptography] Apple's 13-month certificate policy 
FYI --
Apple drops a bomb on long-life HTTPS certificates:
Safari to snub new security certs valid for more than 13 months
Keep your crypto below 398 days after September 1 and you're all good
By Shaun Nichols in San Francisco 20 Feb 2020 at 23:20
Safari will, later this year, no longer accept new HTTPS certificates
that expire more than 13 months from their creation date.
That means websites using long-life SSL/TLS certs issued after the
cut-off point will throw up privacy errors in Apple's browser.
The policy was unveiled by the iGiant at a Certification Authority
Browser Forum (CA/Browser) meeting on Wednesday. Specifically,
according to those present at the confab, from September 1, any new
website cert valid for more than 398 days will not be trusted by the
Safari browser and instead rejected. Older certs, issued prior to the
deadline, are unaffected by this rule.
By implementing the policy in Safari, Apple will, by extension,
enforce it on all iOS and macOS devices. This will put pressure on
website admins and developers to make sure their certs meet Apple's
requirements ??? or risk breaking pages on a billion-plus devices and
Tim Callan, a senior fellow at PKI and SSL management firm Sectigo,
who attended this week's meeting in Slovakia, told The Register: "This
week Apple announced at the 49th CA/Browser Forum Face-to-Face that it
will limit the term of accepted TLS certificates to 398 days as of
September 1, 2020. Certificates issued on or after that date with term
beyond 398 days will be distrusted in Apple products.
"Certificates issued prior to September 1 will have the same
acceptable duration as certificates do today, which is 825 days. No
action is required for these certificates."
Cutting certificate lifetimes has been mulled by Apple, Google, and
other members of CA/Browser for months. The policy has its benefits
and drawbacks.
The aim of the move is to improve website security by making sure devs
use certs with the latest cryptographic standards, and to reduce the
number of old, neglected certificates that could potentially be stolen
and re-used for phishing and drive-by malware attacks. If boffins or
miscreants are able to break the cryptography in a SSL/TLS standard,
short-lived certificates will ensure people migrate to more secure
certs within roughly a year.
Shortening the lifespan of certificates does come with some
drawbacks. It has been noted that by increasing the frequency of
certificate replacements, Apple and others are also making life a
little more complicated for site owners and businesses that have to
manage the certificates and compliance.
"Companies need to look to automation to assist with certificate
deployment, renewal, and lifecycle management to reduce human overhead
and the risk of error as the frequency of certificate replacement
increase," Callan told us.
We note Let's Encrypt issues free HTTPS certificates that expire after
90 days, and provides tools to automate renewals, so those will be
just fine ??? and they are used all over the web now. El Reg's cert is a
year-long affair so we'll be OK.
GitHub.com uses a two-year certificate, which would fall foul of
Apple's rules though it was issued before the cut-off
deadline. However, it is due to be renewed by June, so there's plenty
of opportunity to sort that out. Apple's website has a year-long HTTPS
cert that needs renewing in October.
Microsoft is an interesting one: its dot-com's cert is a two-year
affair, which expires in October. If Redmond renews it for another two
years, it'll trip up over Safari's policy.
No public announcement has been made by Apple, it seems. Digicert's
Dean Coclin has issued a memo about the policy:
"Why did Apple unilaterally decide to enforce a shorter certificate
lifetime?" Coclin pondered.
"Their spokesperson said it was to 'protect users.' We know from prior
CA/B Forum discussions that longer certificate lifetimes proved to be
challenging in replacing certificates, in the case of a major security
incident. Apple clearly wants to avoid an ecosystem that cannot
quickly respond to major certificate-related threats.
"Short-lived certificates improve security because they reduce the
window of exposure if a TLS certificate is compromised. They also help
remediate normal operational churn within organizations by ensuring
yearly updates to identity such as company names, addresses and active
domains. As with any improvement, shortening of lifetimes should be
balanced against the hardship required of certificate users to
implement these changes."
Apple declined to comment.
Apple drops a bomb on long-life HTTPS certificates:
Safari to snub new security certs valid for more than 13 months
Keep your crypto below 398 days after September 1 and you're all good
By Shaun Nichols in San Francisco 20 Feb 2020 at 23:20
Safari will, later this year, no longer accept new HTTPS certificates
that expire more than 13 months from their creation date.
That means websites using long-life SSL/TLS certs issued after the
cut-off point will throw up privacy errors in Apple's browser.
The policy was unveiled by the iGiant at a Certification Authority
Browser Forum (CA/Browser) meeting on Wednesday. Specifically,
according to those present at the confab, from September 1, any new
website cert valid for more than 398 days will not be trusted by the
Safari browser and instead rejected. Older certs, issued prior to the
deadline, are unaffected by this rule.
By implementing the policy in Safari, Apple will, by extension,
enforce it on all iOS and macOS devices. This will put pressure on
website admins and developers to make sure their certs meet Apple's
requirements ??? or risk breaking pages on a billion-plus devices and
Tim Callan, a senior fellow at PKI and SSL management firm Sectigo,
who attended this week's meeting in Slovakia, told The Register: "This
week Apple announced at the 49th CA/Browser Forum Face-to-Face that it
will limit the term of accepted TLS certificates to 398 days as of
September 1, 2020. Certificates issued on or after that date with term
beyond 398 days will be distrusted in Apple products.
"Certificates issued prior to September 1 will have the same
acceptable duration as certificates do today, which is 825 days. No
action is required for these certificates."
Cutting certificate lifetimes has been mulled by Apple, Google, and
other members of CA/Browser for months. The policy has its benefits
and drawbacks.
The aim of the move is to improve website security by making sure devs
use certs with the latest cryptographic standards, and to reduce the
number of old, neglected certificates that could potentially be stolen
and re-used for phishing and drive-by malware attacks. If boffins or
miscreants are able to break the cryptography in a SSL/TLS standard,
short-lived certificates will ensure people migrate to more secure
certs within roughly a year.
Shortening the lifespan of certificates does come with some
drawbacks. It has been noted that by increasing the frequency of
certificate replacements, Apple and others are also making life a
little more complicated for site owners and businesses that have to
manage the certificates and compliance.
"Companies need to look to automation to assist with certificate
deployment, renewal, and lifecycle management to reduce human overhead
and the risk of error as the frequency of certificate replacement
increase," Callan told us.
We note Let's Encrypt issues free HTTPS certificates that expire after
90 days, and provides tools to automate renewals, so those will be
just fine ??? and they are used all over the web now. El Reg's cert is a
year-long affair so we'll be OK.
GitHub.com uses a two-year certificate, which would fall foul of
Apple's rules though it was issued before the cut-off
deadline. However, it is due to be renewed by June, so there's plenty
of opportunity to sort that out. Apple's website has a year-long HTTPS
cert that needs renewing in October.
Microsoft is an interesting one: its dot-com's cert is a two-year
affair, which expires in October. If Redmond renews it for another two
years, it'll trip up over Safari's policy.
No public announcement has been made by Apple, it seems. Digicert's
Dean Coclin has issued a memo about the policy:
"Why did Apple unilaterally decide to enforce a shorter certificate
lifetime?" Coclin pondered.
"Their spokesperson said it was to 'protect users.' We know from prior
CA/B Forum discussions that longer certificate lifetimes proved to be
challenging in replacing certificates, in the case of a major security
incident. Apple clearly wants to avoid an ecosystem that cannot
quickly respond to major certificate-related threats.
"Short-lived certificates improve security because they reduce the
window of exposure if a TLS certificate is compromised. They also help
remediate normal operational churn within organizations by ensuring
yearly updates to identity such as company names, addresses and active
domains. As with any improvement, shortening of lifetimes should be
balanced against the hardship required of certificate users to
implement these changes."
Apple declined to comment.
I don't get it.
Either certificate revocation works or it doesn't.
If it doesn't, then we're going to need "TTL's" just
like IP packets, and 13 months does nothing at all.
If revocation works, then 2 years (or 4 years) still
works just fine.
If some math genius solves integer factoring or
finite field logarithms, then 13-months isn't going
to help.  Ditto for quantum.
I still don't get what Apple is trying to accomplish.

@_date: 2020-02-26 09:54:17
@_author: Henry Baker 
@_subject: [Cryptography] Well, that showed them! 
Re: TB2F, etc.:
And everyone is still wondering why Bernie is surging...  Duh!
I expect that the .org sale won't generate a lot of concern until it's too late...

@_date: 2020-01-06 12:34:12
@_author: Henry Baker 
@_subject: [Cryptography] Recent factorization of RSA-240 & DLP 
FYI --
Dear number theorists,
We are pleased to announce the factorization of RSA-240, from RSA's challenge
list, and the computation of a discrete logarithm of the same size (795 bits):
RSA-240 = 124620366781718784065835044608106590434820374651678805754818788883289666801188210855036039570272508747509864768438458621054865537970253930571891217684318286362846948405301614416430468066875699415246993185704183030512549594371372159029236099
        = 509435952285839914555051023580843714132648382024111473186660296521821206469746700620316443478873837606252372049619334517
        * 244624208838318150567813139024002896653802092578931401452041221336558477095178155258218897735030590669041302045908071447
Let p = RSA-240 + 49204 be the first safe prime above RSA-240. We chose
as a target the encoding of the sentence "The magic words are still
Squeamish Ossifrage" (in reference to the factorization of RSA-129 [1]):
target_str="The magic words are still Squeamish Ossifrage"
target_hex=`echo -n $target_str | xxd -p -c 256`
target=`echo "ibase=16; $target_hex" | BC_LINE_LENGTH=0 bc`
target = 774356626343973985966622216006087686926705588649958206166317147722421706101723470351970238538755049093424997
we have with generator g = 5:
log(target) = 92603135928144195363094955331732855502961099191437611616729420475898744562365366788100548099072093487548258752802923326447367244150096121629264809207598195062213366889859186681126928982506005127728321426751244111412371767375547225045851716
which can be checked with 5^926...716 = target mod p.
The previous records were RSA-768 (768 bits) in December 2009 [2], and
a 768-bit prime discrete logarithm in June 2016 [3].
It is the first time that two records for integer factorization and discrete
logarithm are broken together, moreover with the same hardware and software.
Both computations were performed with the Number Field Sieve algorithm,
using the open-source CADO-NFS software [4].
The sum of the computation time for both records is roughly 4000
core-years, using Intel Xeon Gold 6130 CPUs as a reference (2.1GHz).
A rough breakdown of the time spent in the main computation steps is as
    RSA-240 sieving:  800 physical core-years
    RSA-240 matrix:   100 physical core-years
    DLP-240 sieving: 2400 physical core-years
    DLP-240 matrix:   700 physical core-years
The computation times above are well below the time that was spent with
the previous 768-bit records. To measure how much of this can be
attributed to Moore's law, we ran our software on machines that are
identical to those cited in the 768-bit DLP computation [3], and reach
the conclusion that sieving for our new record size on these old machines
would have taken 25% less time than the reported sieving time of the
768-bit DLP computation.
Another estimation can be made with the rough complexity ratio given by
the L_N(1/3,(64/9)^(1/3)) formula that, up to (1+o(1)) factors in the
exponent, is customarily taken as an estimation of the expected hardness
increase from one computation to the next. This would suggest that
795-bit computations should be 2.25 times harder than 768-bit
computations. Taking this into account, and still using identical
hardware, our computation was 3 times faster than the expected time that
would have been extrapolated from previous records.
The acceleration can be attributed to various algorithmic improvements
that were implemented for these computations.  The CADO-NFS
implementation was also vastly improved.
We used computer resources of the Grid'5000 experimental testbed in
France (INRIA, CNRS, and partner institutions) [5], of the EXPLOR
computing center at Universit???? de Lorraine, Nancy, France [6], an
allocation of computing hours on the PRACE research infrastructure using
resources at the Juelich supercomputing center in Germany [7], as well as
computer equipment gifted by Cisco Systems, Inc. to the University of
More details will be given in a forthcoming scientific publication.
Fabrice Boudot, ?????ducation Nationale and Universit???? de Limoges, France
Pierrick Gaudry, CNRS, Nancy, France
Aurore Guillevic, INRIA, Nancy, France
Nadia Heninger, University of Pennsylvania and University of California, San Diego, United States
Emmanuel Thom????, INRIA, Nancy, France
Paul Zimmermann, INRIA, Nancy, France
[1] [2] [3] [4] [5] [6] [7] [8] Re discrete logs:
This recent email describes the recent attack on the discrete
log problem.
Q: this descrete log solution uses a 'safe' prime; does a 'safe'
prime make the DLP harder or easier ??

@_date: 2020-01-12 11:55:01
@_author: Henry Baker 
@_subject: [Cryptography] improved identification of non-targets 
The problem is much, much bigger than your post indicates.
Hospitals & ambulances in war zones are routinely targeted,
whether unintentionally or otherwise.
And then there are "intelligence" operations that routinely
masquerade as doctors & health care workers.  E.g., Bin Laden's
DNA was verified by CIA-recruited doctors and health care
"The distrust sowed by the sham campaign in Pakistan could conceivably
postpone polio eradication for 20 years, leading to 100,000 more cases
that might otherwise not have occurred, says Leslie F. Roberts of
Columbia University's Mailman School of Public Health. 'Forevermore,
people would say this disease, this crippled child is because the
U.S. was so crazy to get Osama bin Laden,' he argues." [1]
Was Joe Biden and Barack Obama's 2008 campaign slogan "Bin
Laden is dead and GM is alive" [4] worth 100,000 lives?
In retrospect, Biden's 2012 slogan should be corrected to
"Bin Laden and vaccinators are dead and polio/smallpox/measles/...
are alive".
[1] How the CIA's Fake Vaccination Campaign Endangers Us All;
The U.S. was wrong to use health workers to target Osama
bin Laden, May 1, 2013
[2] Deans write to Obama about CIA vaccine scheme in Pakistan;
8 January 2013
[3] [4] Biden: "Bin Laden Dead, GM Alive"; David Jackson|USA TODAY; Published 11:15 AM ET Thu, 26 April 2012 Updated 3:36 PM ET Thu, 26 April 2012

@_date: 2020-01-13 13:17:55
@_author: Henry Baker 
@_subject: [Cryptography] improved identification of non-targets 
Additional IFF data points:
Drones sold in the U.S. have many restrictions on flying which are *enforced* by the done's GPS guidance computer.  (E.g., DJI incorporates a "No Fly Zone".)  Are we now going to install a similar system in airliners which prohibits entry into certain airspaces?
I believe that the U.S. NOTAM was published *prior* to the Ukranian airliner being shot down.  However, whether this NOTAM was minutes prior, or hours prior, I haven't been able to determine.
Flight KAL007 shot down by mistake by Soviets instead of a *nearby* U.S. spy plane.
Re Ukraine 752: do we know for certain that *no* U.S. spy planes/drones were in the vicinity?  I'm not yet willing to concede that the following did not happen: a U.S. spy plane/drone was sighted, but the Iranian antiaircraft missile locked onto the easier target -- a nearby Ukrainian airliner.
British ship HMS Sheffield, which may have been lost due to Exocet missiles manufactured by an *ally*, France.  IFF doesn't work if you think that the missile was fired by a friendly.  On the flip side, the Brits did shoot down one of their own helicopters in the Falklands war due to IFF problems.
The U.S. was fully prepared to shoot down airliners on 9/11/01, which is why all non-military air traffic ceased for a number of days.  Even today, do we know *for certain* that UA Flight 93" *wasn't* intentionally shot down by U.S. interceptors instead of the vastly more romantic/patriotic notion that the passengers were able to wrestle control from the hijackers?  (Unfortunately, the result was the same, except for the lack of blow-back from a possible shootdown.)

@_date: 2020-01-31 14:08:22
@_author: Henry Baker 
@_subject: [Cryptography] SSL Certificates are expiring... 
============================== START ==============================
Forget the Y2K bug, "things" are starting to break as SSL Certificates start expiring.
Several authority certificates are expiring:
IoT = Internet of Expired Certificates.
Perfectly good HW, but with firmware that can't be updated.
I just hope that implantable medical devices can have their builtin certificates updated!
I wonder how many "smart" *cars* will stop running when their builtin SSL certificates expire?
Problems: bad hash functions (MDx,SHA1) are also causing certificate
problems even though the RSA algorithm -- even at 1024 bits -- still seems to be holding.

@_date: 2020-07-02 06:56:43
@_author: Henry Baker 
@_subject: [Cryptography] Statement from Attorney General William P., 
cBook-Pro.local>
What about HTTPS/TLS/TCPIP over ham radio bands?

@_date: 2020-07-06 11:38:07
@_author: Henry Baker 
@_subject: [Cryptography] Statement from Attorney General William P. Barr 
You might want to ask some of the folks who have lost millions in
Bitcoin due to almost-if-not-actual-state-level-hacking.
As a taxpayer, I'm more than a little pissed that the NSA/CIA have
no responsibility to protect *me* as a citizen; apparently, NSA's
only responsibility is to protect the *federal govt* from hackers.
So I have to personally protect myself against state-level hackers,
while ***my own govt is sawing on my encryption limb to make me even
more vulnerable.***
I hate to suggest it, for all sorts of obvious reasons, but the
NSA might get a tiny bit more sympathy from ordinary citizens if
the NSA was actually tasked with protecting said citizens.  It's
nice for the banks that the NSA occasionally provides them with
assistance, but when was the last time the NSA helped an ordinary
Whatever you may think of J. Edgar Hoover, his extensive P.R.
campaign during his entire lifetime convinced most Americans
that the FBI was protecting said ordinary Americans from all
sorts of nasties.  Only later did we find out that 'ordinary'
Americans didn't include all sorts of racial, ethnic, religious
and political minorities.

@_date: 2020-07-09 15:14:15
@_author: Henry Baker 
@_subject: [Cryptography] "Home router warning: They're riddled with known 
Re: "Decoupling the WiFi access point from the NAT/Router"
This is absolutely critical; there used to be a "demarc" for POTS;
set up a digital demarc at the cable modem boundary: there's no
reason for anyone to be trusting the crappy combo NAT/router/wifiAP
devices that ISP's give^H^H^H^Hrent to you.
So here's my suggestion:
* cable modem with 10-12 year-old never-updated Linux connected via Ethernet;
  disable wifi HW on this device (or better: buy a cable modem w/o wifi at all)
* Raspberry Pi 4 acting as NAT/router/DoH DNS/... connected via Ethernet
* Wired LAN backbone (Ethernet, etc.)
* various wifi AP's running the latest OpenWRT SW
NO uPnP!!!!!!  (compile OpenWRT w/o uPnP, and w/o SMB)
I'm considering setting up separate internal VLAN's/VPN's
*solely* for closed-source home devices that I don't trust,
and that I don't want anyone of which to see anyone else:
'smart^H^H^H^H^Hsurveillance' streaming TV's/NEST's/RING's/etc.
Yes, I know, Raspberry Pi's have some closed HW & blobs,
but the good news is that RPi4 SW is kept very much up to
date -- as well as, if not better than, many desktop

@_date: 2020-07-11 07:59:32
@_author: Henry Baker 
@_subject: [Cryptography] "Home router warning: They're riddled with known 
Sort of.
There is a build of OpenWRT for the RPi4 ('nightly' -- i.e., it works fine, but isn't quite as stable as for the other RPi models).  But you definitely want the substantially better performance of the RPi4 over the older models.
The standard 'Raspbian' SW also works, but you need to configure it to be a router and DNS.  This requires a number of changes, and there are lots of tutorials available for how to make almost any Linux box into a router.
There are 64-bit builds of Linux for the RPi4 which take even better advantage of its performance; these also require similar configuration to become a router.
The RPi4 also includes wifi capability with decent but not outstanding performance; it doesn't have enough power or antenna for a whole house, but you don't want that much wifi range else it extends too far outside the house.
The RPi4 has a number of USB ports which can be converted into Ethernet ports with suitable adapters; make sure your RPi4 USB power supply provides enough power (this is not quite as easy as one would like -- you should probably *measure* the USB power requirements for each device), and/or else use a powered USB hub.

@_date: 2020-07-11 12:14:44
@_author: Henry Baker 
@_subject: [Cryptography] "Home router warning: They're riddled with known 
mail.com>
Another option:
Used Android cellphones running LineageOS (Android 9 or better 10) as routers/wifi AP's/servers.  (Someone once hacked a version of OpenWRT for a cellphone, but sadly it didn't get picked up for the mainstream.)
Also crazy inexpensive ($30-$50, you can now buy such used smartphones in bulk: hundreds at a time if you really want!), but they have cool stuff: wifi 2.5&5 GHz, Bluetooth, GPS, builtin status display screen :-), lots of memory (some w/builtin uSD card slot for 256GBytes or more), builtin backup battery :-), builtin security system (video & audio) :-), builtin theft (motion) detector :-), built-in backup LTE WAN (w/SIM card) :-), etc.
If you run the Termux app, you can get BASH and most Linux apps, including SSH, VNC, so you log in from your laptop and do interesting stuff.
Since LineageOS is rooted, you can get at the networking stuff.
Problem: the Android permission system is a lot different from standard Linux, so it takes a long time to learn (translation: "get around it").
I'd set up an MPI cluster of such cellphones, but I haven't been able to find a massive array of cup-holders to hold them with. :-)

@_date: 2020-06-26 15:00:04
@_author: Henry Baker 
@_subject: [Cryptography] Statement from Attorney General William P. Barr 
I've never understood why 'encryption' doesn't fall
under the *Second Amendment*.
After all, encryption used to be considered the same
as 'arms' and 'armor', and was regulated as such.
Unfortunately, most of the people I talk to regarding
encryption hate the 2nd Amendment so much that they
won't even consider it.
Which I think is a mistake, because if you look at
the current composition of the U.S. Supreme Court, I
think that they might well agree that encryption
is a form of 'arms', and is thereby Constitutionally

@_date: 2020-06-29 12:07:49
@_author: Henry Baker 
@_subject: [Cryptography] Statement from Attorney General William P. Barr 
A few years ago I looked into *actual armor* -- e.g., kevlar vests --
and found (to my surprise) that kevlar vests were regulated.
I thought that this was pretty stupid -- as vests might actually
be a good idea in some neighborhoods -- and any restrictions are
likely unconstitutional.
After all, it's pretty difficult to kill someone by hitting him
with a kevlar vest, so I'm not sure who I'm putting in danger
from *my* wearing such a vest.
I liken encryption to *defensive* armor -- e.g., kevlar vests --
its hard to consider encryption as *offensive* -- the old saying,
"sticks & stones may break my bones, but words will never
break me".

@_date: 2020-06-30 10:53:07
@_author: Henry Baker 
@_subject: [Cryptography] Statement from Attorney General William P. Barr 
mail.com>
Hmmm...  So kevlar armor killed these people?  Last time I looked, victims of 'shooters' were killed by bullets.
So, the following items should be outlawed for *everyone* because 'shooters' might take advantage of them:
* vaccines to protect shooters from flu, whooping cough, measles, etc.
* air bags to protect shooters from being injured in their getaway cars
* water filters to protect shooters from arsenic in their water bottles
* COVID19 fask masks to protect shooters from coming down with COVID19
* OSHA rules to protect shooters from workplace hazards
* FDA rules to protect shooters from bad drugs
How about we simply give the police/govt a remote 'kill switch' for every resident?  Then when some 'shooter' starts shooting, the police trigger the kill switch.
Problem solved.
Disallowing body armor is equivalent to handing the police a 'kill switch'.
Didn't the recent BLM protests tell you about what can go wrong when police have 'kill switches' aka 'deadly force' aka 'qualified immunity' ?

@_date: 2020-03-04 07:49:17
@_author: Henry Baker 
@_subject: [Cryptography] Ex-CIA Joshua Schulte Describes His Data/Crypto 
The first thing I do with every new storage disk/SDcard is: dd if=/dev/urandom of=/dev/sdX;
Among other things, it proves to me that the new medium will actually hold the amount of data that it claims to be able to.
Also, I don't want somebody in the supply chain to be inserting porn/etc. onto my media.
(Sadly, I can't check that the SDcard microcode doesn't contain malware/spyware, but that's for another discussion.)
So now *all* of my slack space contains random data.
Now what?  Am I now going to be detained at the border?
(Yes, I could do: dd if=d/dev/zero of=/dev/sdX; but if the firmware was clever, it could trivially *compress* these data in order to free up space for nefarious activities.)
(Yes, I also understand that /dev/urandom gives someone a *huge* of information about the current state of my random number generator, but hopefully Linux has finally gotten their act together and fixed these issues.)

@_date: 2020-03-15 22:31:04
@_author: Henry Baker 
@_subject: [Cryptography] Crypto AG: US Spies Kept Quiet on Assassinations 
This is not novel in the spying world.  Bletchley Park intercepted Nazi messages
about the Holocaust killings, but the Brits felt that keeping the code-breaking
secret was worth the cost.
Unfortunately, there was enough anti-semitism in both Britain and the U.S., that
neither country wanted WWII to be motivated as a rescue of the Jews.  FDR himself
wrote that he didn't want his "New Deal" to be seen as the "Jew Deal".
It will be up to historians -- once they have all the information declassified --
to sort out all of these things and put them into some kind of perspective.
Much of WWII 'history' is still disinformation/mythology which needs to be
re-examined with the full knowledge of extensive code-breaking.  For example,
General Montgomery had to be lauded as a 'genius' to cover up the fact that
he had almost real-time intelligence decoded from Rommel's reports.  I'm
sure that this branding of Montgomery must have made Eisenhower (and probably
even Churchill) privately furious, but it was necessary to keep up appearances.

@_date: 2020-05-01 11:55:55
@_author: Henry Baker 
@_subject: [Cryptography] NSA security guidelines for videoconferencing 
FYI --
To Zoom or WhatsApp?
NSA Lays Out Security Details of Videoconferencing Services for
April 29, 2020 Bridget Johnson
With coronavirus forcing federal workers to conduct meetings via
videoconferencing tools, the National Security Agency compiled a guide
on security advantages and deficits of popular online meeting
NSA detailed whether the video tools, including Zoom and Skype,
offered security features such as multi-factor authentication,
transparency on which users are joining sessions, and end-to-end
"With limited access to government furnished equipment (GFE) such as
laptops and secure smartphones, the use of (not typically approved)
commercial collaboration services on personal devices for limited
government official use becomes necessary and unavoidable" due to
COVID-19, notes the guidance.
NSA coordinated with the Department of Homeland Security, which will
be issuing its own guide, "Cybersecurity Recommendations for Federal
Agencies When Using Video Conferencing Solutions." It's intended to be
"responsive to a growing demand amongst the federal government to
allow its workforce to operate remotely using personal devices when
deemed to be in the best interests of the health and welfare of its
workforce and the nation," and the recommendations are subject to
change as web tools and vulnerabilities evolve.
NSA did not include in its guidance government online meeting services
intended for secure communications such as Defense Collaboration
Services or Intelink Services. The agency also "strongly recommends"
using a secure government service before any of the commercial
collaboration services. The NSA guidance also does not override
specific telework guidance agency by agency.
The criteria was drafted to align with U.S. government guidance
including NIST SP 800-171r2 ??? Protecting Controlled Unclassified
Information in Non-Federal Systems and Organizations (Feb 2020) and
NIST SP 800-46r2 Guide to Enterprise Telework, Remote Access and BYOD
Security (Apr 2016).
Evaluating an online collaboration service includes asking:
1. Does the service implement end-to-end encryption?: "Some services
such as large-scale group video chat are not designed with end-to-end
encryption for performance reasons."
2. Are strong, well-known, testable encryption standards used?: "Use
of published protocol standards, such as TLS and DTLSSRTP, is
preferred. If the product vendor has created its own encryption scheme
or protocol, it should undergo an independent evaluation by an
accredited lab."
3. Is multi-factor authentication (MFA) used to validate users'
identities?: "Without MFA, weak or stolen passwords can be used to
access legitimate users' accounts and possibly impersonate them during
use of the collaboration service."
4. Can users see and control who connects to collaboration sessions?:
"Users should also be able to see when participants join through
unencrypted/unauthenticated means such as telephone calls."
5. Does the service privacy policy allow the vendor to share data with
third parties or affiliates?: "Collaboration information and
conversations should not be shared with third parties. This could
include metadata associated with user identities, device information,
collaboration session history, or various other information that may
put your organization at risk."
6. Do users have the ability to securely delete data from the service
and its repositories as needed?: "Users should be given the
opportunity to delete content (e.g. shared files, chat sessions, saved
video sessions) and permanently remove accounts that are no longer
7. Has the collaboration service's source code been shared publicly
(e.g. open source)?: "Open source development can provide
accountability that code is written to secure programming best
practices and isn't likely to introduce vulnerabilities or weaknesses
that could put users and data at risk."
8. Has the service and/or app been reviewed or certified for use by a
security-focused nationally recognized or government body?: "NSA
recommends that cloud services (which collaboration apps rely on) be
evaluated under the Office of Management and Budget (OMB) FEDRAMP
program. NSA also recommends that collaboration apps be evaluated by
independent testing labs under the National Information Assurance
Partnership (NIAP) against the Application Software Protection Profile
9. Is the service developed and/or hosted under the jurisdiction of a
government with laws that could jeopardize USG official use?: "Users
should be aware that the country of origin where products were
developed is not always public knowledge."
NSA stressed that collaboration software should only be downloaded
directly from an official app store and that those using browser-based
services should check that HTTPS is enabled.
Meeting invites should also be sent through encrypted and
authenticated means instead of posted in public forums, if
possible. One person should be in charge of monitoring participants
joining the videoconference, keeping an eye out for unverified
"Be aware of screen-sharing features so that you only share your
screen to display content salient to the collaboration session. If
content is sensitive, ensure that it is appropriate to share with all
participants. Be mindful of the affiliations of those with whom you
connect," the NSA guidance added. "Be aware of your surroundings
including any other communications going on (e.g. family members on
phone calls or video chats, location hints if working from a sensitive
location). Disable unnecessary app permissions (e.g. location
services). Ensure there is no other software on your device that is
actively sharing microphone data back to a remote server. Note that
less-trusted devices, to include Internet of Things (IoT), often have
microphones or cameras, so it may be wise to leave personal cell
phones or computers in a different room if they are not being used for
Bridget Johnson is the Managing Editor for Homeland Security Today. A
veteran journalist whose news articles and analyses have run in dozens
of news outlets across the globe, Bridget first came to Washington to
be online editor and a foreign policy writer at The Hill. Previously
she was an editorial board member at the Rocky Mountain News and
syndicated nation/world news columnist at the Los Angeles Daily
News. Bridget is a senior fellow specializing in terrorism analysis at
the Haym Salomon Center. She is a Senior Risk Analyst for Gate 15, a
private investigator and a security consultant. She is an NPR on-air
contributor and has contributed to USA Today, The Wall Street Journal,
New York Observer, National Review Online, Politico, New York Daily
News, The Jerusalem Post, The Hill, Washington Times, RealClearWorld
and more, and has myriad television and radio credits including
Al-Jazeera and SiriusXM.

@_date: 2020-10-10 08:29:41
@_author: Henry Baker 
@_subject: [Cryptography] Secret sharing for family members 
In these days of 'digital estates', where each of us
controls a large swath of digital accounts, there
appears to be a need for safely sharing secrets with
family members -- e.g., for medical and/or estate
planning purposes.
Here are some desiderata:
* don't want to trust a single family member
* family members probably not security conscious,
  so may inadvertently disclose other family
  member secrets
* may need some sort of 'majority' capability
* ability to 're-key' -- i.e., 'refresh' secrets
* ...
Are there any products/services that *safely*
handle these situations?

@_date: 2020-09-28 17:54:23
@_author: Henry Baker 
@_subject: [Cryptography] Is this a solved problem? 
What I will describe is a standard problem in ecommerce today.
A company has a web site, which customers have to 'log into'
in order to view & purchase products.
The company may also have a smartphone 'app' which provides
equivalent capabilities for viewing & purchasing products.
Nowadays, companies also have 2FA, which sometimes requires
that one not only log into the website & provide a password,
but also respond to an email or a text message sent to an
email address or a smartphone.
So, the company also mails out special promotions for its
better customers to their email addresses (most likely
the same ones that they utilize for 2FA).  Clearly, if a
customer receives the email on their 2FA account, then they
are already authenticated. So a link in that email should
take them to an *already-logged in* web page.  It is a very
irritating hassle for such a link to require that the
customer log in again.
But companies don't want these links to work if this customer
emails these links to his/her buddies.  Aside from them not
being preferred customers of the company, these buddies would
also -- in effect -- be logging in as the original email
recipient, and could conceivably buy products which would
be charged to the original email recipient.
Now most smartphone 'apps' are considered 'personal', and
many/most don't require logging in when they are utilized.
So such an emailed link would prefer to open the smartphone
app rather than a web page in the user's preferred browser.
But we still have the same problem if this link activates
the same 'app' on one of the buddies' smartphones.
So how can the company make a 'link' that only operates for
the original recipient of the email, and not for anyone else
who somehow gains access to this link?
Are there any 'standard'/'preferred' solutions to this problem?
