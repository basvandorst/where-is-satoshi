
@_date: 2001-06-02 01:21:32
@_author: John Denker 
@_subject: NSA tapping undersea fibers?  
1) I assume when this says "tap" it refers to undersea tapping;  that wasn't obvious on first reading, which caused some confusion.
In any case, I stand by my assertion that dry-land tapping is more plausible than undersea tapping of these cables.  I am unconvinced by the counterarguments that were advanced:
2) I don't know what this means.  A legal tap is legal onshore or offshore.  An illegal tap is illegal onshore or offshore.  US law makes no 3) The law doesn't require it to be inadvertent, just "minimized"
        ...and the law defines a pretty broad minimum!
        I don't know what this means.  See item (2) above.
It's no secret that you-know-who can _legally_ tap the cables (subject to the "minimization" requirements).  A lot of things that were done illegally in the 1960s and 1970s are now legal, and indeed mandatory, under the 1978 law.  (Whether they violate the 4th amendment is a more subtle question.)
Cable operators can be directed to "furnish all information, facilities, or technical assistance necessary to accomplish the electronic surveillance in such a manner as will protect its secrecy...."
        The cable operators are going to comply with all surveillance directives.  Noncompliance would carry a $10,000 per day "civil" penalty.
        Revealing classified information "concerning communications intelligence activities of the United States or any foreign government" would be a felony, so don't expect the operators to give you a tour of the place where the spooky feed splits off from the transoceanic feed.
        As a general rule, if you are standing in the middle of a cattle ranch and you hear hoofbeats, don't look around for zebras -- it's probably just cattle.  Undersea cable-tapping seems to me to be a bit of an imaginary zebra.  It's implausible when the same cable could be tapped onshore.
OTOH, as I pointed out before, there are certain places where real zebras can be found.  Africa is an example.  Why do you think AfricaONE has a backbone that circles the continent offshore, plus separate drops for each country, when it would have been vastly cheaper to go by land?  Answer:  everybody thought that an offshore cable would be less likely to be tapped by hostile powers.  (Each country can of course tap its own drop, along the lines discussed above, but it can't so easily tap other folks' signals on the backbone.)
Given that AfricaONE is spending hundreds of millions of dollars to prevent tapping, I think quite a few eyebrows would be raised if they leased fiber and other facilities without ironclad assurances that they wouldn't be used for snooping.
And I imagine the AfricaONE operators are clever enough to check that all packets that come out correspond to packets that went in, so that their cable can't be used as backhaul for anybody's tap.
So I still think that backhaul is an interesting challenge for anybody who wants to operate undersea taps.  There are ways to do it, but no super-easy Some interesting info about the structure and function of the USS Jimmy Carter:

@_date: 2001-06-04 12:09:52
@_author: John Denker 
@_subject: tapping undersea fibers? 
Well, of course there is concern about all sorts of threats:
  *) Tapping
  *) Damage
     -- inadvertent
     -- otherwise
But let's ask what are the costs and benefits of various options:
  1) One obvious option is to build a _ring_ of fiber on dry land.
    1a) Sure, there will be an inadvertent cut now and then (due to some klutz with a backhoe) but such cuts can be repaired.  The cost of repairs is infinitesimal compared to the cost of running the cable offshore.  Because it is a ring, customers won't notice cuts if they happen one at a time (and are repaired promptly);  it would take _two_ cuts to cause a partition.
    1b) There will be wars now and then.  Each combatant _will_ want to cut the adversary's cable.  (Ever hear of a foreign minister named Zimmerman?)  There's not a lot that the cable operator can do to maintain service in the war zone.  But remember it takes two cuts, including one _not_ in the war zone, before anybody outside the war zone is left in the dark.
    1c) It is not impossible to have damage (inadvertent or otherwise) to an offshore cable, as Herr Zimmerman found out.
    1d) A dry-land configuration would provide !much! more functionality -- more places for paying customers to connect.
  2) You can do even better if build something more like a mesh than a simple ring.  Such a structure would be tremendously robust against damage, and would provide even more places for customers to connect.
So it seems to me that the principal rationale for putting the cable offshore is the expectation that the two-bit warlord next door would have a hard time tapping the backbone.
It's certainly doable.  You might think it would get easier year by year, as electronics gets cheaper and faster -- but fibers are getting faster, too.  The crucial factor is that the crypto market has grown to the point where people are actually making stuff for this market, such as 3DES in hardware at (nearly) OC-48 speeds:
   Each wavelength on the AfricaONE fiber is OC-192 (10 Gb/sec).  You would have to pick the incoming OC-192 data apart into four or five OC-48 streams, encrypt it, re-assemble it, and send it to the laser.  That would work OK for a point-to-point link, but more generally you would need to add "outer headers" ? la IPsec.  And you might want to worry about key management :-).
  -- A full solution would be a nifty piece of engineering.  You can't buy it at K-mart.
  -- But it would be a lot cheaper than putting the cable offshore People say that CBC prevents you from parallelizing the encipherment, but in practice it's straightforward to make it work (for modest degrees of parallelism).  Or you can use counter mode.
That's a good argument, in peacetime anyway.  OTOH in wartime, a link that can't be tapped is _more_ likely to be destroyed.

@_date: 2001-05-29 08:40:30
@_author: John Denker 
@_subject: The role of compression in cryptosystems 
In a discussion of the role of compression in IPsec,
 >
Hmmmm.  My recommendation would be to shift the burden of proof:  I would leave compression turned on unless there is a good reason to turn it off.
This recommendation is based on the following general principle:
         Any cipher applied to well-compressed data is much
         harder to cryptanalyze than the same cipher applied to
         uncompressed plaintext.
As an illustration, a block of well-compressed text encrypted by single-DES would be secure against EFF's DES cracker (whereas a block of uncompressed text is not).  This principle is based on information theory, specifically the idea of unicity distance.  Note that these days the security of a typical crypto scheme is explained in terms of _complexity theory_ (the assertion that cryptanalysis is computationally infeasible), whereas information theory is a completely different kettle of fish.
And while we're on the subject:  the module that compresses the data should add a goodly percentage of random cryptologic nulls (no, I don't mean ASCII NULs).  The decompressor of course removes them.
To decide whether or not this principle is important, we can consider three   a) In the case where the cipher is really weak and the adversary has lots of ciphertext to work with, pre-encipherment precautions (such as compressing + adding nulls) won't save the day.  No compressor is perfect, so the unicity distance is never infinite.
  b) There is a vast middle ground where such precautions can increase the adversary's workload by a large factor (thousands) while increasing the good guy's workload by only slightly.
  c) In the case where the cipher is really strong, further strengthening is just lily-gilding.
We all !hope! case (c) applies to us.  But the history files are bulging with stories of people who thought they were in situation (c) but weren't.
In general, the following seems like a good design discipline:
  1) Assume the cipher is imperfect.  Pretend you're using single-DES or some such.
  2) Design the rest of the cryptosystem to survive such imperfections.
  3) Then plug a strong cipher into that system.
Specifically:  My instinct says that any serious cryptosystem should compress the input, then add nulls, then encipher.
Another way of saying the same thing:  In the usual discussions, some systems described 100% in terms of information theory (one time pads), while others are described 100% in terms of complexity theory (RSA etc.)  I haven't seen a good practical discussion of how to combine the two viewpoints.
Comments, anyone?

@_date: 2001-05-29 08:49:16
@_author: John Denker 
@_subject: NSA tapping undersea fibers? 
So don't do it that way.  There are ways to tap a fiber without fracturing it.
Uhhh, if either end of the fiber connects to a place where Mr. Jones has access, then they don't need to tap the undersea cable at all!  They just tap the dry-land connections near that place -- or tap the electronics inside that place.
For starters:

@_date: 2001-05-31 06:30:58
@_author: John Denker 
@_subject: compression & nulls in cryptosystems  
OK, I'll bite.
1) Do these remarks apply to the moats I've been building (little IPsec gateway boxes)?
2) What's a chosen-ciphertext oracle?  How might an attacker use a moat as   3) I can imagine how an attacker could feed chosen plaintext through my moat.  For instance she could email me a chosen message and expect me to download it via the moat.  But getting back to the topic of compression and nulls:  It would seem that they would serve to convert the chosen text into a partially-chosen but partially-unknown (!) text.
So I don't get the point of the passage quoted above.
  *) If the point is that there's a lot of bad crypto out there, then of course I agree.  But that doesn't mean we can't try to improve it.
As I said in my previous note, there are cases where the system is so bad that small improvements don't matter, and there are cases where the system is so good that small improvements don't matter.  But in the middle there is a vast region where we get to discuss the costs and benefits of various proposed improvements.
  *) If the point is that a basically-good idea can be implemented so badly that it doesn't help, then yes, that goes without saying.  And I agree that many off-the-shelf compression algorithms may be in this category.  But that doesn't mean we should stop looking for good solutions.
  *) If the point is that compression and nulls have infinite cost or zero value, then I find this highly implausible.
  -- ISTM nulls would materially hinder differential cryptanalysis.
  -- ISTM nulls would materially hinder linear cryptanalysis.
  -- ISTM compression+nulls would materially hinder a key-search
     along the lines of the EFF DES cracker.
  -- Can somebody give examples of attacks that would not be hindered?
  *) If the point is that there is something else we should be doing with our bandwidth and computational resources, it would help to have a more explicit statement of what the alternatives are, and their relative costs and effectiveness.
Let me also remark that nulls in particular are conceptually related to
  -- salt, and
  -- session keys
which are pretty standard technology in appropriate situations.  It doesn't make sense to pooh-pooh such techniques.
I always scratch my head when somebody says that XX attack on YY algorithm requires a huge carefully-chosen plaintext, and ends the discussion there, when by adding nulls you can guarantee that no chosen plaintext ever gets processed as such.

@_date: 2001-05-31 21:42:57
@_author: John Denker 
@_subject: compression & nulls in cryptosystems  
[ a number of lucid and interesting points, leading up to ... ]
Touch?!  Good point.
But what if I had asked about a !known!-plaintext attack?
Note the contrast:
  -- Known plaintext + CBC   = equally-well-known plaintext.
  -- Known plaintext + nulls = not-completely-known plaintext
But let me try to answer my own question, by coming from another angle:  It seems like adding lots of random nulls is AT BEST equivalent to
  *) First: encoding with random session keys and really small sessions, then
  *) Second: sending those sessions (and their keys) through the aforementioned YY algorithm.
This would be an effective way, but hardly the best way, of defeating known-plaintext attacks.
What this really comes down to is how often you need to change session keys in order to defeat known-plaintext attacks.  There are standard methods for changing session keys, and I now see that teaching the compressor to throw in random nulls is not an improvement over the standard methods.
So I learned something.  Thanks!

@_date: 2001-05-31 22:02:18
@_author: John Denker 
@_subject: NSA tapping undersea fibers? 
I was talking with some colleagues who had read the WSJ article
... and who were wondering as follows:  Given that They know how to tap a fiber in the lab, how hard it would be for a submarine such as the USS Jimmy Carter to apply a tap while working 3000 meters down in the ocean.
Well, it ain't gonna happen by sending any such sub down to 3000 meters.
It is highly unusual for a full-sized sub to go below 500 meters.  US subs, which are believed to be not as tough as the Russian ones, are limited to something more like 300 meters.
      One might have guessed that subs could zoom down 1000 meters about as easily as airplanes can zoom up 1000 meters -- but that's not the case.
According to the WSJ article, near shore (at depths of less than 1000 feet), the cable is buried in a trench, which would add an extra layer of nuisance to someone trying to tap it.  Out in the deep ocean, it just lies on the seafloor -- but the pressure becomes a big issue.
Here's are some hypothetical scenarios to consider:
First, it should be obvious that They don't need a submarine to tap cables that already make landfall in the US, which is the vast majority:
   ... and They can't use a submarine to tap the cables that go from China to ... but I suppose there are things like AfricaONE:
   where underwater tapping might make sense to Them.
Anyway, here's scenario   To tap a deep-sea cable, They keep the submarine at a modest depth, perhaps 150 meters or so.  They send down a small Remotely Operated Vehicle to grab the cable and lift it up to the sub.  They do the work there, and then return the cable to the seafloor.
The cable is certainly strong enough and flexible enough to permit this.  (Otherwise, how could it ever have been laid?)
But could the tappers do this without leaving telltale signs?  I don't know.  It depends on how closely the tappees are watching.
If I owned a cable, I might want to have an ROV of my own, and use it every so often to patrol the cable end-to-end, looking for signs of disturbance.
Another scenario:  Overall it might be easier to tap the cable while it is still on the continental shelf, at 100-meter depth or so.  That would require Them to dig it out of its trench and re-bury it, but thereafter it would be hard for others to notice Their handiwork.
Related issue:
Suppose They install a tap.  What then?  What are They going to use for    1) One option would be to use some other channel on the same cable to do the backhaul.
    1.1) This would be "relatively" straightforward if They could lease a suitable backhaul channel from the cable operator.  I don't know how this could be done without the cable operator knowing exactly what They were up to.  And if the cable operator is giving Them that level of consent, there are ways of getting the data without bothering with a submarine.
    1.2) Without a leased backhaul channel, I suppose it is possible that They could just insert packets into the stream of traffic, on the fly, but this would be exceedingly tricky, because of the high speeds and delicate    2) Another option would be to lay a backhaul fiber from the tapping-point all the way back to Maryland.  If They did this, somebody with an ROV could detect it, whereupon it would be rather embarrassing for Bottom line:  I don't understand how to do the backhaul, and without backhaul the whole story doesn't hang together.  Ideas, anyone?

@_date: 2001-10-31 06:19:02
@_author: John Denker 
@_subject: NYT article on steganography 
At 08:57 PM 10/30/01 -0500, vertigo commended to our attention:
Here is a review I wrote back in 1998:
1) In Ron's note, most of the statements about the technology are true.  In a narrowly technical sense the scheme would "work".
2) The scheme is not as revolutionary as the note seems to suggest.  Hiding trees in forests is pretty well-known technology.
3) The legal and definitional aspects are, shall we say, matters of opinion.  In particular, the claim that chaffing is not encryption is highly debatable.  Certainly the authorities could choose to include chaffing in the list of banned operations.  The fact that all the ingredients of the chaffing scheme have "approved" uses falls far short of making the point.  Consider an analogy:  in many cases the parts of a legal semi-automatic weapon are essentially identical to the parts of a fully-automatic weapon.  Yet the authorities have no hesitation about outlawing the latter -- and vigorously enforcing the law.
4) It should go without saying that I do NOT approve of wholesale snooping.  Indeed I think the present restrictions on cryptography are absurd.  And I don't think there's anything wrong with chaffing.  I just don't think it will be particularly effective at forcing the debate into sensible channels.

@_date: 2001-09-16 18:41:09
@_author: John Denker 
@_subject: How to ban crypto? 
That's narrowly true as stated, but it's misleading because it's not the whole story.
Let's not speak as if the only two options were PGP or nothing.  In fact there is a wide continuum, of which three particularly interesting points are
   A) Anything you want, including PGP.
   B) Mandatory GAK.
   C) Mandatory plaintext.
Nobody is going to ban crypto.  Nobody is going to impose plan (C).  Given the choice between (B) and (C), we and our customers could adopt plan (B) and get along pretty much as we do now.
This says GAK is unsuitable, doesn't clearly say why.  I don't know whether it is a philosophical point, a political point, a technical point, or whatever.
The two most common anti-GAK arguments are:
   1a) It can't be done well.
   1b) If it can't be done well, it shouldn't be done at all.
   1c) Specifically, the risk of wholesale key-compromise is too great.
   2a) It won't really detect/deter typical crime, because typical criminals will find ways around it.
   2b) It won't really detect/deter terrorism, because dedicated terrorists will find ways around it.
I'm dubious about argument (1) in all its forms.  I suspect that if we wanted to make it work, we could make it work.
I'm certain that argument (2a) is mostly false as stated.  The typical prosecution involves putting together a lot of facts, most of which are not by themselves obviously illegal.  For instance, imagine a world where GAK is mandatory.  Then when somebody encrypts a private note such as
         Dear Monica -
           Meet me at 11:00, you know where.
         Love, Bill
he doesn't think he is doing anything illegal.  Just because it's private doesn't mean it's illegal.  Much later somebody, perhaps as part of a civil suit, shows probable cause sufficient to overcome the right to privacy, and poof! GAK is exploited to decrypt the message.  At this point two possibilities must be considered:
   a) either Bill superencrypted the message, to defeat GAK, or
   b) he didn't.
In case (b) all they get is the message.  They may or may not be able to put that together with a zillion other micro-facts to prove wrongdoing.  He might get acquitted.
In case (a) they've got him dead to rights for violating the mandatory-GAK laws.  Klink!
Given this choice, most people will opt for no superencryption.  I'm not asking you to _like_ this scenario.  But the rules are that one should consider all the plausible scenarios, to see where they lead.  There's nothing implausible about this scenario.
The situation changes if you are a dedicated evildoer.  Suppose you are planning something so heinous that the penalty for being caught is more severe than the penalty for violating the mandatory-GAK laws.  Then superencryption might be a good idea.  Even then it won't help much, because if they can get subpoena for GAK one day, they can get a subpoena to bug your premises the next day.  You increase their costs a little, but the cost to you is going to be much higher.
So we continue the search for a robust anti-GAK argument.
One part of the argument is this:  Terrorists don't need fancy superencryption to defeat GAK.  Indeed they hardly need encryption at all.  They can formulate the basic plan in a cave somewhere, and thereafter communicate in the clear:
         "Dear Uncle:  Please send another $10,000 so I can
          continue my training."
         "Dear Cousin: I will be taking flight AA73 tomorrow.
          I understand you will be taking UA175, right?"
Some people are speaking as if the recent attack required vast resources and sophisticated communications.  It didn't.  Just because the US Army has adopted a communications-intensive battle doctrine doesn't mean everybody else will follow suit.
1) The Subject: line of this thread is misleading.  The issue is not mandatory plaintext.  The issue is whether or not we want mandatory GAK.
2) There are AFAICT no convincing technical arguments against GAK.
3) The ultra-serious crimes such as occurred last week are irrelevant to the GAK debate, and vice versa.
4) Therefore it comes down to a routine policy decision:  We get to choose a tradeoff somewhere in the gray area between
  -- extreme privacy, and
  -- extremely easy solution of some minor crimes.
The real world operates in shades of gray, not at either extreme.  It always has, and always will.  The US Constitution, for example, provides some guidance.  Innumerable minor crimes go undetected every day, directly because of the 4th and 5th amendments.
   We can argue about whether the standard for "probable cause" should be raised a bit or lowered a bit, but the infinitely-high setting is just as unrealistic as the infinitely-low setting.  We need a more nuanced discussion.

@_date: 2001-09-16 23:36:24
@_author: John Denker 
@_subject: Did the US defeat wiretapping success? 
Hmmmmm, criticized?  Why not indicted?
   (a) Whoever knowingly and willfully communicates, furnishes,
   transmits, or otherwise makes available to an unauthorized
   person, or publishes, or uses in any manner prejudicial to
   the safety or interest of the United States or for the benefit
   of any foreign government to the detriment of the United States
   any classified information -
         ....
           (3) concerning the communication intelligence activities
             of the United States or any foreign government; or
         ....
           Shall be fined under this title or imprisoned not more
            than ten years, or both.

@_date: 2001-09-17 15:38:17
@_author: John Denker 
@_subject: Did the US defeat wiretapping success? 
And what is the basis for this doubt?
All evidence, including that which I quoted in my original message, indicates that he first said it in a media interview.  Here is some more    which says in part:
See also
  To put this in context, see
   which says in part:
According to all indications, Mr. Hatch is not protected by the speech-and-debate clause.
In my judgement, I find Mr. Hatch's assertion that "he was told he could disclose the information" to be self-serving and highly implausible.  It would be good to find out who, if anyone, told him that.  Perhaps a grand jury would be a good way to find out.

@_date: 2001-09-30 23:14:39
@_author: John Denker 
@_subject: IPsec +- 802.11 
Well, specifically no but generally yes.
IPsec doesn't care what sort of transport you are using (802.11 or whatever).  That's a feature!  These things live at different layers, as they should.
So the IPsec part of the question should be simplified to asking whether there is an IPsec howto.  The answer, of course, is yes.  Details depend on the flavor of operating system.  For linux, the starting point is:
   For FreeBSD, a possible starting point is:
   Different IPsec implementations are supposed to interoperate, and mostly they do.

@_date: 2002-01-14 12:09:20
@_author: John S. Denker 
@_subject: CFP: PKI research workshop 
IMHO this presents an unsophisticated notion of "right versus wrong".
By way of analogy:  Suppose you go skiing in Utah.
A rut left by a previous skier causes you to fall
and break your leg, or worse.  Now everybody involved
has been using the ski area _in_the_intended_manner_
yet something bad happened.  So who is liable? The ski area could have groomed that trail, but they didn't.  They could have enforced a speed limit, but
they didn't.  They could at least have bought insurance
to cover you, but they didn't.  They simply disclaimed
all liability for your injury.  Not only is this disclaimer a matter of contract (a condition of sale
of the lift ticket) it is codified in Utah state law.
Other states are similar.  If you don't like it, don't
Returning to PKI in particular and software defects in particular:  Let's not make this a Right-versus-Wrong
issue.  There are intricate and subtle issues here.
Most of these issues are negotiable.
In particular, you can presumably get somebody to insure
your whole operation, for a price.  In the grand scheme
of things, it doesn't matter very much whether you (the
PKI buyer/user) obtain the insurance directly, or whether
the other party (the PKI maker/vendor) obtains the insurance
and passes the cost on to you.  The insurer doesn't much
care; the risk is about the same either way.
The fact is that today most people choose to self-insure
for PKI defects.  If you don't like it, you have many  -- Call up some PKI vendor(s) and negotiate for better
warranty terms.  Let us know what this does to the price.
 -- Call up  or some such and get
your own insurance.  Let us know the price.
 -- Write your own PKI.  Then defray costs, if desired, by becoming a vendor.
 -- Et cetera.
In general, there is a vast gray area between "Right"
and "Wrong".  Most things in my life can be described
as not perfect, but way better than nothing.

@_date: 2002-01-17 04:41:51
@_author: John S. Denker 
@_subject: Microsoft to shift strategy 
privacy
WASHINGTON -- Microsoft Chairman Bill
  Gates announced to employees Wednesday a
  major strategy shift across all its products,
  including its flagship Windows software, to
  emphasize security and privacy over new
  capabilities.
