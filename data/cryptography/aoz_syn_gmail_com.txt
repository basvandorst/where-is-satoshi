
@_date: 2009-03-03 17:07:08
@_author: RB 
@_subject: Judge orders defendant to decrypt PGP-protected laptop 
To more fully quote Adam's question:
Hidden volumes are interesting, but TrueCrypt's specific implementation
(one hidden volume per "decoy" container) fails to address the case
in which an adversary has knowledge of the hidden volume, which is where
I think Adam's question was going.  If they do, no amount of decoy data
is going to convince them that what they seek has been divulged, and
they will continue to "compel" until they have what they want.
To defend against such an "attack", one would need two hidden volumes:
one for decoy data and the other for the real data.  There are still
problems with that approach (such as how the adversary gained knowledge
of a hidden volume in the first place), but it should satisfy the
switch-for-puppies defense.  No software I know of does this by default.

@_date: 2014-01-28 14:14:11
@_author: RB 
@_subject: [Cryptography] Angry Cryptographers... 
While I realize the subject is a play on the application of note in
the article, your words would appear to indicate it means something
for you personally as well.
"The last straw", a reference to the story of the straw that broke the
camel's back, often used as a modern English euphemism for "now I am
angry."  In the parochial words of an average bully, "what are you
going to do about it?"  Americans like to get angry about things now
and again, but rarely do more than grumble.  Grumble publicly if it
really has their knickers in a knot, and they might even write a
sternly-worded email to their "representatives" if they feel near
blood.  I am as guilty as any, ensconced in my warm office using
services provided by one of the very companies that gathers such
volumes of data.
Do we see the problem yet?  Do we care?

@_date: 2014-10-22 07:41:20
@_author: RB 
@_subject: [Cryptography] (no subject) 
Although I'm not certain this is on-topic for the cryptography list,
I'm also mildly surprised that there's anything here I can answer.  I
don't hold the GWAPT (but know someone who just renewed), and do hold
several other SANS certs myself.
SANS keeps a very, very tight fist on rights to their materials, you
won't find anything secondhand or third-party unless it violates their
[extensive] licensing agreements.
My evaluation was that I have never spent my own money on SANS courses
and certifications, it has always been employers'.  It is nourishing
enough if you're pretty much new to the particular discipline the
course covers, but if you have any prior experience in the field it
won't get you very far.  A personal example, GPEN - having already
participated in some red-team and CTF exercises, I learned no new
concepts (only a few specific applications of tools) from the
I feel that as all certs become more popular and peopled, their
utilitiy ultimately wanes, and SANS is little different.  The recent
move to not publish test scores, for example, I feel reduces the value
of doing well - "they still call the C medical student 'doctor'."
However, this week I did hear that they'd made the GWAPT test
significantly harder and shorter, which may be a glimmer that they're
trying to fight the dilution effect a little.

@_date: 2015-02-21 20:01:34
@_author: RB 
@_subject: [Cryptography] =?utf-8?q?Sony_to_Offer_=E2=80=98Premium_Sound?= 
As a FOH engineer, I think you over-estimate the "noise" such a minor
piece of a recording system as the solid-state flash makes.  Although
I have heard some hiss from solid-state devices, the vast majority of
their emissions and (and major harmonics) are well above 22kHz.
I sincerly doubt a change of microSD card would have cured your
obvious grounding issues.  Noise is great for entropy and poor for
recording, but as a [hopefully] fellow professional, I again think
you're overestimating how much audible noise reduction one would get
by replacing a normal microSD with this particular one.  That said,
your depseration that day was likely (regrettably) the precise market
this product is aimed at.

@_date: 2015-06-08 08:06:55
@_author: RB 
@_subject: [Cryptography] let's kill md5sum! 
Please forgive my non-cryptographer ignorance, but what warrants
wholesale elimination as opposed to, say, unambiguous deprecation (as
various tools have adopted with --i-really-know-what-i-am-doing
As I understand it, MD5's worst break is an attack that takes two
dissimilar files and appends to _both_ until their MD5 checksum
matches.  This is undeniably bad, but it presumes that Mallory has the
ability to alter the original, that size isn't checked, and that
metadata (like MD5 and size) is universally malleable.  None of these
qualifications excuse MD5, but do we realistically expect greater
future breakage?  Say, the ability to generate an arbitrary collision
without modifying the "original"?
I ask because there are many situations where the MD5 (and size) of a
given file is still stored and necessary, but the original file is not
available, mostly for legal and political reasons.  No new usage of
MD5 is warranted, but eliminating md5sum altogether seems heavy-handed
and itself unwarranted.

@_date: 2015-11-23 12:49:13
@_author: RB 
@_subject: [Cryptography] 
I'm fairly certain this has more to do with one's version of OpenSSL
than wget or the client library.  Using OpenSSL 1.0.2d (Gentoo) I'm
unable to replicate the error with wget, curl, or "openssl s_client".
The silent acceptance of well-known subdomains isn't a change I'm
immediately aware of, but it is certainly a logical conclusion given
the current vogue of eliminating the archaic-appearing "www" from

@_date: 2016-04-20 13:17:59
@_author: RB 
@_subject: [Cryptography] Security on TRIM for full-disk encrypted SSDs 
It all depends on your threat model.  The most paranoid threat model
possible for most disk-level encryption assumes that an attacker
knowing both your FS type and the amount of data you have encrypted is
unacceptable.  Hence, you encrypt your entire block device (fill it up
with encrypted data or noise) and keep opaque the actual volume of
encrypted data and any other indicators of its structure.
For the average user that's probably not true, and for them TRIM
should be perfectly acceptable.  This is why, for example, I don't
"pre-encrypt" VeraCrypt volumes: I ship a lot of disk images around,
it's a known quantity.  My main interest is confidentiality, and it
matters not one whit whether I'm sending a 500GB or a 1TB image on
that 2TB external.  My opponent already knows the gist of what I'm
transmitting, so I avoid writing 2TB of NULs over a slow bus in order
to hide that I'm sending less than 2TB.
Your mileage (and threat model) may vary.

@_date: 2016-04-21 16:08:25
@_author: RB 
@_subject: [Cryptography] Security on TRIM for full-disk encrypted SSDs 
You're right - that matters, but only for specific threat models,
particularly those involving transmission of illicit material.
Returning to the problem at hand - that of allowing one's opponent to
know one's net drive allocation by enabling TRIM under encryption -
the answer remains "it may matter".  If you're storing a known
quantity of illicit material in a way that could be separated from the
rest of the noise on your system, then yes - enabling TRIM is probably
For the rest of us that simply wish to prevent data loss or
modification in the event of a lost or stolen system or drive and lack
illicit material?  TRIM can be a great disk-longevity option that does
not affect our threat model.
You have to know what you're defending and what you're defending it
against.  Because they have customers with varying threat models, FDE
developers have historically tended toward the conservative extreme
and are just now offering exceptions to that.  For the average user,
however, the performance and operational load of that extreme may
outweigh actual concerns.

@_date: 2016-04-27 08:30:06
@_author: RB 
@_subject: [Cryptography] Current state of WPA2 security for IoT access ? 
To be precise, WPA[2]-Personal is passphrase based.
Perhaps you intended to espouse WPA[2]-Enterprise and to move away
from WPA2-PSK, not WPA2 in general?  WPA[2] is the state of the art as
far as 802.11 encryption is concerned, there's just a distinction on
the authentication mechanism and its susceptibility to specific
Of course, if you provision all of your devices with a common identity
and passphrase, while physical compromise may not reveal the network
key, you've just made yourself a hard problem of revoking compromised
credentials and evicting an intruder from your network.
Administrative overhead now or administrative overhead later.

@_date: 2016-04-30 16:34:10
@_author: RB 
@_subject: [Cryptography] sha1sum speed 
I am surprised it would be any faster; given a cold page cache, it
should have in fact been exactly the same speed or slightly slower.
You were almost guaranteed to have been more limited by I/O rates than
you were by the speed of your hashing function.  A quick 'openssl
speed sha1' on my AMD A6-5200 shows a single thread on that can
calculate SHA1 faster than all but fast SSDs can provide data.  Using
16B blocks it would handle 140k IO/s (22MB/s), and at 8k blocks it
hits 245MB/s (30k IO/s).

@_date: 2016-12-19 11:06:21
@_author: RB 
@_subject: [Cryptography] TR-069 & firewalls 
You can probably block it, but TR-069 is pretty much designed to allow
them to disable that block at will. I handle this by putting the ISP's
backdoored device into bridge mode, then terminate the PPPoE
connection on a router under my full control.  More complexity and
power consumption, but at least it keeps the known-compromised device
outside my network.

@_date: 2016-02-17 12:44:12
@_author: RB 
@_subject: [Cryptography] Thoughts on the Apple iPhone fiasco 
I'm intentionally ignoring the balance of your arguments, but this one
warranted pointing out the obvious follow-on.  It's not that Apple
would be required to create one "unlock firmware" tied to one serial
number, it's that once they have proven it can be done they will be
compelled to do the same in every other criminal case (or worse, make
an unkeyed version).
Whether or not it's hard to satisfy the request (or even whether they
should do it), it's in Apple's best interests to represent that the
activity is inordinately costly, whether socially or financially.
That way, even if they lose and are compelled to do as requested,
they've set a higher standard for the inevitable subsequent requests.
Apple isn't considering just San Bernadino, they're considering the
tens (hundreds?) of thousands of requests between now and when
hardware susceptible to this particular request is phased out.

@_date: 2016-02-17 18:30:46
@_author: RB 
@_subject: [Cryptography] Thoughts on the Apple iPhone fiasco 
If it is inevitable that they fold, then why worry?  If they had
folded silently, we'd be in a worse position than if they fold with a
fight.  If they fold with a fight, they're at least setting legal
precedent that this isn't a trivial practice or one that they take
The crux of the matter is that this isn't about San Bernardino, nor is
it about the 5c, or even about the technical merits of the case.  It
is about setting legal precedent that the US gxovernment is allowed to
request product companies _create_ mechanisms that can bypass security
The FBI is, frankly, fortunate that this case involves a 5c, a willing
owner, and a politically-charged case.  This gives them the greatest
opportunity to appear completely reasonable while attempting to set a
dangerous precedent.  If they can conscript your workforce to make
something trivial (but nonexistent) today, the US legal system will
encourage (or at least allow) elaborations upon that in the future,
say creating an OTA firmware update for suspected terrorists that
silently disables encryption.  That is the slippery slope of precedent
people are up in arms about.
If the FBI wins (silently or not), there is that much less legal
ground product companies can stand on to create and maintain
actually-secure devices.
My cynical conjecture is that for Apple this isn't really about
securing devices.  Rather, it's about minimizing their legal
obligations and entanglements.  My further conjecture is that the FBI
is attempting to set precedent while they still can, when a trivially
bypassed device like the 5c is on the market and they can make the
case that the cost of entry is not that high.  They see the door
closing as easily as the rest of us, and are trying to get a foot in
before it's too late.

@_date: 2016-02-18 08:58:52
@_author: RB 
@_subject: [Cryptography] Hope Apple Fights This! 
Where this falls apart is at   The public will never see the
burdens; they don't have to, nor will Apple let them.  Apple will make
it absolutely clear it's a burden, whether by charging $infinite per
case or by making it legally expensive to pursue.  For anyone
(including the state) to prove it is not burdensome would require
lawyer-years of effort, which is seldom considered worth the effort.
There is no either-or situation in this case. If they set a precedent
of not fighting for both technical and legal protections, technical
protections will mean nothing.  If lost, this case stands to set a
precedent that the US judicial system will revisit time and time
again, insisting that Apple create increasingly novel bypasses for
technical protections.
Even "perfect" technological protection requires some level of legal
protection.  This is why (at least in most civilized nations) the
police can't simply beat an encryption key out of you.

@_date: 2016-02-21 12:50:58
@_author: RB 
@_subject: [Cryptography] eliminating manufacturer's ability to backdoor 
While thinking of purely technical solutions to these problems may be
an entertaining thought project, the answers produced are typically so
esoteric as to make them completely unworkable in the real world.
No company is going to fully give up their secret sauce, nor would
they ever grant utter authority over said secret sauce to a third
party (with its own security problems) unless legally compelled to,
under dubious authority.  Never mind the FCC forbidding open radio
hardware in these devices.  Android is not an open system, but its
partial openness serves to illustrate the utter proliferation of
hardware configurations that openness produces.  Try to imagine
implementing something like Apple's secure enclave (and appropriate
signing thereof) in the Android bazaar.  This eliminates your first
Eliminating individual machine identification (however impossible)
would be roundly rejected by manufacturers for many reasons, perhaps
the strongest of which would be preventing counterfeiting and other
means of fraud.  It also damages devices' and OSes' supportability,
contravenes network standards, and frankly reduces the profitability
of building hardware.  Unique identification is nearly inevitable in
such a heavily commoditized and price-sensitive market.
Apple is fighting the right fight, on both technical and legal fronts.
There is no purely technical (or purely legal) solution to this
problem that will actually work in the real world.  Technical and
legal means must work hand-in-hand, supporting and balancing one
I completely understand your (and others') enthusiasm for purely
technological solutions, and even share a lot of it.  Just please
don't make the mistaken assumption that we can correct (or even fully
account for) meat with code.

@_date: 2016-02-21 22:39:17
@_author: RB 
@_subject: [Cryptography] Hope Apple Fights This! 
I waited for a while to respond to this in order to hopefully observe
further posts from you on the subject so as to better understand your
viewpoint.  Fortunately you've obliged; I don't wish to dampen your
enthusiasm, but wish to point out some necessary points of contact
with realism.
No device (or more importantly, system) is unhackable.  Ciphers may be
resistant to all but brute-force but their weak point is their key,
because no cipher lives in a vacuum.  Suggesting the world can make an
unhackable device is silly, full stop.  Even if only The People came
up with both firmware and software on a phone, all hardware were
constructed in "open" fabs, all under open scrutiny, and manufacturers
were reduced to the supremely unprofitable hardware-only sector of the
market, there would be weak links that courts can compel.  Meat is
I think you (and many others) perhaps misunderstand stare decisis.
This core (perhaps _the_) governing doctrine of the US legal system
stipulates that _any_ court decision is used as the guiding priciple
for any future similar cases, no matter whether it was contested.
That can be fought, of course, but the vast majority of US legal
education and wranglings is spent researching and proposing that a
given case falls within a certain prior decision.  Unless the
prosecution/petitioner dismisses the case completely _before_ the
court makes a decision, stare decisis kicks in even if the
defendant/opposition doesn't contest the ruling.
If you think the FBI did not want this case to be decided by the
courts (whatever Comey's statement to the contrary), you've completely
missed the months of posturing leading up to now, replete with
congressional hearings filled with the FBI's continual protestations
that terrorists are "going dark", technology companies need to
cooperate with them, and that secure-but-insecure systems are possible
if they're created "at the design level".
Make no mistake, this is clearly just another battle in the FBI's War
on Cryptography.  I speak from no more knowledge than any other
spectator, but it's absolutely clear that the FBI's plan has played
out as planned thus far.
Source: I am a forensic practitioner.  This is my dayjob.

@_date: 2016-02-22 11:51:46
@_author: RB 
@_subject: [Cryptography] eliminating manufacturer's ability to backdoor 
I'm genuinely curious what solution you might suggest that would be
secure and immune to compulsion while remaining sufficiently
profitable that companies would engage in it.  While interesting, your
suggestion of perfectly anonymous updates that are incapable of
uniquely identifying a device eliminates the majority of the
environment's profitability and therefore manufacturers' incentive to
This has already happened with the PC market - hardware itself is
barely profitable (if at all) for non-component manufacturers (e.g.
Dell).  Ancillary services and integration are where the profits are,
and if a company is unable to determine if a user is even a paying
customer, they're not going to provide a service.  To keep with the
current example, Apple is not going to willingly provide software that
they then must support to a device they can't even be certain they

@_date: 2016-02-22 13:32:51
@_author: RB 
@_subject: [Cryptography] eliminating manufacturer's ability to backdoor 
I'm not aware that sort of jurisdiction even exists.  Could you help
point out a jurisdiction that is so forward-thinking as well as
relatively immune to economic and literal warfare?  Said individuals
would also be plausibly subject to direct coercion, no matter their
Government-ordered literal back doors like this are not a known norm
in the states, hence why Apple is fighting the ruling.  One
yet-incomplete court decision does not yet change that, and I expect
Apple will appeal it as high as the court system lets them.
The only significant difference between what you've outlined and what
exists today is that Apple's source is closed.  Trusted individuals
(you may not trust them but there are millions that do) in a
jurisdiction that has not historically allowed government-ordered back
doors are signing reviewed and tested updates for general consumption.
Their jurisdiction is trying to change that scenario, and that's
what's creating the furor.
That said, however interesting this thread of discussion is I feel
we've strayed far afield from the list's charter and largely by my own
doing.  Therefore, I'm recusing myself from further pursuit of the

@_date: 2016-01-03 16:23:45
@_author: RB 
@_subject: [Cryptography] How can you enter a 256-bit key in 12 decimal 
Not providing any opinion or information regarding this particular
drive, a well-developed drive is going to use a key derivation
function (e.g. PBKDFv2) to generate the actual 256-bit key.  Few users
ever enter a full 256 bits of entropy for even software FDE, and this
is conceptually no different.
You confuse the term "legal" with "acceptable" perhaps?  Even assuming
the worst case that the user PIN was simply an ATA password or less,
and that the data on all enclosures was encrypted with a single common
256-bit manufacturer key, it would pass muster in at least US courts.
They make no claims whatsoever that the PIN affects encryption, only
that it protects from "unauthorized use."  Nobody that cares will use
the drive, and those that don't care (or don't know to) don't matter.
This is the race to the bottom.
In the razor-thin margins of computing hardware and peripherals,
nobody cares about the Bear use case.  They care about what will sell
100k units to the people that don't [know to] care while investing the
least capital possible (in terms of both hardware and engineering).
They could invest orders of magnitude more in the product before you
would be interested, hence they simply don't care about acquiring you
as the marginal customer.  This is basic economics.
To Steve's comment, nobody has taken them to court because (at least
in the US) the chances of success are effectively nil.  Often because
the supplier is typically a small-potatoes foreign operator that is
more likely to fold and reappear under another name than to yield any
lawsuit/settlement return.  Add in that (again, at least for the US)
the legal environment actively encourages language abuse, legal
defense is usually a turn of phrase away.
There are good reasons that enclosure-based encryption hasn't
outstripped software-based FDE.  To legitimately compete on security
terms with the likes of TrueCrypt and its progeny, Bitlocker,
FileVault, and LUKS (and do so transparently to the OS), hardware and
R&D would cost significantly more than manufacturers find it worth.

@_date: 2016-07-13 08:11:57
@_author: RB 
@_subject: [Cryptography] The Laws (was the principles) of secure 
You may want to elaborate some on this. Many are under the mistaken
assumption that this only means "permanent" storage, e.g., disk.  Save
for in exceptional cases, memory contents may be stolen.

@_date: 2016-10-04 08:30:26
@_author: RB 
@_subject: [Cryptography] French credit card has time-varying PIN 
Most US-issue EMV cards still have signature priority rather than PIN
priority, and it's hard to dig through the banks' BS to figure out
which CMV priority they set.  Some will set online PIN as second
priority, but that's relatively rare too.  When I looked into this
about 14 months ago, the only US credit issuer to do PIN primary
(whether online or ICC) was First Tech Credit Union.
I don't know how up-to-date the data is, but this [1] site was helpful
in determining which issuers did what, and appears to have evolved
since I last checked. YMMV, I wish this kind of data was a little more
open and plain.
[1]

@_date: 2017-04-04 11:01:08
@_author: RB 
@_subject: [Cryptography] Does anyone here know PAM? 
Perhaps I'm missing some subtle part of the point, but is this not
already done under the gnome-keyring project?  At least from this
user's perspective, gnome-keyring (and the seahorse UI) achieve the
same functionality as the OS X keyring.

@_date: 2017-04-07 14:03:03
@_author: RB 
@_subject: [Cryptography] Regulations of Tempest protections of buildings 
As noted upthread, a lesson on how to read and apply US laws and
regulations are beyond the scope of this list.  You're arguing out of
context and it's not helping your position.
The basement story is likely an unintentional strawman. Here's my own
anecdata that's even more troublesome to your line of argument:
As a forensic analyst, one of the first things I do when tasked with
collecting and examining a phone is to place it in a grounded Faraday
cage with a power feed to the device.  My explicit intent is to
disrupt communication with that device.  This happens many hundreds of
times daily, all over the US, done both by private and law enforcement
investigators.  None of us have been found to be breaking the law by
doing this, and not for lack of opponents trying to argue otherwise.

@_date: 2017-04-07 17:03:31
@_author: RB 
@_subject: [Cryptography] Regulations of Tempest protections of buildings 
Not really, no - FDE, time-based keys, and similar strong
cryptographic measures mean we want to make sure we get a clean copy
of running memory as well as storage.  This is analogous to the same
approach with laptops and desktops - for years, the first step has not
been to power off a computer, but to disconnect it from the network.
Even that's falling out of vogue for some of the more delicate
scenarios, but is functionally identical to dropping a phone in a
Faraday cage.
Blocking RF signals tends to increase power consumption in mobile
devices for various reasons, mostly due to increased radio time.
Hence the power feed so our time to analyze the device is not limited
by its charge at the time of collection.
