
@_date: 2005-10-02 07:11:13
@_author: Jerrold Leichter 
@_subject: On the difficulty of detection on-line fraud 
Not cryptography, but ultimately what we talk about here often comes down to protection that actually works *for people*.
Also a good counter to arguments of the form "if only people were more
 							-- Jerry
User Interface Design Update Newsletter - September, 2005
Each month HFI reviews the most useful developments in UI
research from major conferences and publications.
View in HTML - In this issue:
Kath Straub, Ph.D., CUA, Chief Scientist, looks at recent research
on how people detect, and often miss, Web site fraud.
The Pragmatic Ergonomist, Dr. Eric Schaffer, gives practical advice.
PHISHING AND PHARMING AND PHRAUD, OH MY
The ability to recognize people who want to take advantage you is core to
survival. Researchers studying the evolution of cognition suggest that we
begin to develop generic "cheating detection algorithms" through exposure to
the types of deception that occur day to day (Cosmides and Tooby, 1989; Cheng
and Holyoak, 1985; Vasek, 1986) In a general way, we learn to suspect
deception and become cautious when there is a notable inconsistency between
what is happening and what we expected to happen.
Yet, consumers' ability to spot fraud in the Internet is still not very
good. This is because our ability to hone our generic "cheater detectors"
depends our specific or "mediating knowledge" of the deception
environment. When you think about it, it's not hard to imagine why. Even savvy
users find it hard to keep up with the newest scam. Can you define Phishing?
How about Pharming?
Here are the Wikipedia definitions for these Internet deception methods:
   - Phishing: (also carding and spoofing) is a form of social engineering,
      characterized by attempts to fraudulently acquire sensitive information,
      such as passwords and credit card details, by masquerading as a
      trustworthy person or business in an apparently official electronic
      communication, such as an email or an instant message. The term phishing
      arises from the use of increasingly sophisticated lures to "fish" for
      users' financial information and passwords.
   - Pharming: is the exploitation of a vulnerability in the DNS server software
      that allows a hacker to acquire the Domain Name for a site, and to
      redirect that Web site's traffic to another Web site.
And there's more:
   - Page-jacking and mouse-trapping: are techniques used by scammers to divert
      Internet users from their intended Web destination (page-jacking) to the
      scammers site from which the user is unable to leave using their browsers
      back, forward or even close buttons (mouse-trapping).
And, with all the excitement about phishing and pharming, people forget about
just plain fraud.
Its not surprising that people have a hard time identifying Internet
deception. The specific cues you use to detect fraud in the rest of your life
work don't really apply in cyberspace. In bricks-and- mortar transactions you
can see who you are dealing with. In cyberspace, grifters are harder to
spot... if they are even there at all.
THE AVERAGE VICTIM OF INTERNET FRAUD LOSES OVER $700 NOT COUNTING LOST TIME
The good news is that as consumers learn more about how the Internet works
they will, by extension, learn more about how Internet deception works. It
will become much harder to dupe them. Like magic, deception is usually not so
tricky if you know where to look. The challenge then, is to help consumers
learn where to look.
Organizations like Consumer WebWatch, the Internet arm of Consumer Union, have
published reports intended to guide consumers to correctly identify the
characteristics of a credible Internet site. One problem is that not enough
consumers read their reports. And of those that do read them, not enough
actually check the cues. Another problem is that those who practice Internet
fraud do seem to read the reports.
Researchers like Grazioli are taking a different route. Grazioili's work (and
his work with colleagues like Jarvenpaa) contrasts the differences between the
behavior of successful and unsuccessful deception detectors. Consumers good at
detecting deception on the Internet evaluate on assurance cues -- concrete
parameters of an organization or its business model that can be evaluated for
truthfulness (e.g., the phone number) or legal validity (e.g., a warranty). In
contrast, consumers who fail to notice deception tend to assign credibility
based on trust cues -- self-report marketing elements (e.g., customer
testimonials or product sales reports) which are difficult to verify, at best.
WHEN PEOPLE ARE LYING THEY TEND TO TOUCH THEIR FACES. WHAT DO WEB SITES DO?
Grazioli observed these differences in a controlled study of deception
detection. In this study, 80 "business and IT savvy" participants were asked
to visit a specific used laptop reseller site and help a friend to decide if
purchasing a $625 laptop from that particular site was a good idea --
essentially to give a second opinion about the credibility of a site. If the
participant felt comfortable with the site, he or she would then purchase the
laptop using the friend's credit card number.
Half of the participants in Grazioli's study visited an active and functioning
laptop reseller Web site. The other were "page- jacked" to a "deception"
site. The deception site was identical to the base site, except that six known
deception cues (Yamagishi and Yamagishi, 1994) had been added or altered.  The
altered cues included:
   - A forged Better Business Bureau assurance Seal leading to a real looking
     report
   - A warranty that was too good to be true
   - False business location information
   - Forged newsclips from professional magazines
   - Impossibly exaggerated Company sales statistics
   - Universally positive, hyperbolic customer endorsements
After viewing the site and purchasing the laptop (or not), participants
completed a survey exploring whether they perceived the site to be deceptive
or not... or were unsuccessful at detecting deception.
Participants were considered successful if they were suspicious of the altered
site or recognized the real site as trustworthy.  Unsuccessful deception
detectors either failed to register suspicion of the altered site or perceived
significant deception even on the trustworthy site.
Overall, even these business and IT savvy users were not able to discriminate
between the trustworthy and the deceptive site. 55% of participants trusted
the site the deceptive site (30% correctly suspected; 15% were not sure). Only
38% correctly trusted the good site (32% were suspicious; 30% were not sure).
HAVE YOU EVER LOOKED AT THE REAR VIEW MIRROR BUT NOT INTO IT?
In this study the deception cues were abundant but they were subtle.
Participants could establish that the altered cues were deceptive by:
   - Cross checking the business entry from the BBB site. Although clicking on
      the assurance seal in the study led to a detailed report that contained
      links back to the BBB, the report was forged. The only way to definitive-
      ly establish that a company has a relationship with the BBB is to check
      the BBB site.
   - Reading and evaluating the business claims and promise realistically.
      - If the warranty seems to good to be true -- in the study: No questions
         full refund. Any time. Forever.
      - Evaluate the business claims. In this example, the disparity between
         exaggerated sales statistics claims (25,000 units sold) and the
         inventory (5 units) seems improbable.
   - Validating the phone number against the address in a reverse directory.
      In the study the company presented a Seattle business address but a
      California area code. Careful participants also noticed that the office
      in the photo did not have the same address as the business address listed
      in the Web site.
   - Validating 3rd party recommendations including news clips and professional
      recommendations. In the study, links back to the source were broken or
      dropped users on the homepage rather than the recommendation reference.
      Do link back to verify the source. Look for similar recommendations on
      the source pages.
   - Verifying customer endorsements and testimonials. If that's not possible,
      be suspicious.
LOUISIANA (ALABAMA, MISSISSIPPI AND TEXAS) ON MY MIND
In his study, Grazioli also noticed that successful deception detectors
focused on a different set of cues than those who failed. Deception detectors
focused on assurance cues (trust seals, warranties, physical location). In
contrast, those who missed the deception focused on trust cues (customer
testimonials). To validate trust cues you must trust the company. To validate
assurance cues, you must go to organizations outside the one you are seeking
to do business with.
Chasing validation at this level seems like a lot of work. Perhaps that's
because for most of us, strategies for identifying bad risks don't include
looking outside the business itself. For a bricks and mortar establishment we
go to the address. We talk to the employees.  We see the customer
service/returns desk. We hold the receipt and warranty in our hands. On the
Internet, those -- largely implicit -- cues are missing. Our general
strategies for detecting deception in the world may work, but our ability to
detect deception on the Internet still needs fine tuning.
References for this newsletter are posted at:
The Pragmatic Ergonomist, Dr. Eric Schaffer
We need to find PRACTICAL ways to indicate that a site is the correct site and
a trustworthy vendor. Let's look for creative solutions.  Organizations like
EBay and PayPal provide immediate access to seller information and buyer
feedback. This allows users to instantly discriminate the trustworthy
sellers. But now we need effective strategies for detecting deception in all
the online environments.  We can forget subtle discrimination of counterfeit
logos and painstaking research. Let's all work to find quick, simple, common
sense, and powerful methods that can really work. Otherwise the information
spaces will be increasingly perilous, filled with invisible thugs and muggers.
HFI IS HIRING:
Many positions available in Mumbai, India.
For positions in the U.S.
Putting Research into Practice - a yearly seminar on recent research
and its practical application.
HFI's training schedule:
Suggestions, comments, questions?
HFI editors at mailto:hfi at humanfactors.com.
Want past issues? Subscribe? - Do NOT want this newsletter?
 at lrw.com
or copy the above URL into the address line of your browser and hit

@_date: 2005-10-18 17:37:14
@_author: Jerrold Leichter 
@_subject: SecurID and garage door openers 
Plus, I believe it maintains and updates an estimate of the skew between its clock and the token's.  So the "what time I think the token thinks it is" value is pretty accurate.  Note that a value read off the token is good for a minute, so your synchronization doesn't have to be that good to begin with. (I suppose you could scan over a larger number of cycles to find the entered value and then use the cycle distance *just to update the skew/token time calculation*, refusing the value.  A legitimate user will just try again with the next generated number and succeed; but a guesser won't be helped by the broader scan range.  At most, he can screw up the skew/token time estimate
somewhat, but that will "heal" when the legimate user next logs in.)
I think there's some special-case synchronization the first time the token is used, the details of which I can't recall.  (It may be just that the server is very liberal about the allowed skew if it knows it hasn't talked to a token in a long time - which is how it would presumably look on the first attempt.  I suppose if you're really worried that this would allow an attacker to get in before the legitimate user, you can make it a policy to log in with the token a couple of times after setting up the account but before handing out the token.  Then again, the software could well have a mechanism to do exactly this synchronization step, so that you don't actually have to log in or even enable the account until synchronization is complete.)

@_date: 2005-09-17 14:14:05
@_author: Jerrold Leichter 
@_subject: Clearing sensitive in-memory data in perl 
[Moderator's note: forwarded on Jerry's behalf -- he's having mail problems.]
And the STL is safer than C ... in what sense?  STL iterators are modeled on C
pointers - warts and all.  An STL iterator can point to random memory just as
easily as a C pointer.  An indexing operation into an STL vector or similar
data structure is subject to exactly as much range checking as a C indexing
Yes, there exist implementations of the STL that check such things - just as
there exist implementations of C that check such things.  None appear to be
widely used.  And, of course, while no standard *forbids* such checks, none
*require* them, so (a) availability is spotty; (b) compilers typically contain
no optimizations aimed at making such things efficient.
RISKS had a large number of messages on this topic back in 2002.  I wrote one
long commentary (in RISKS 21.85 - see  for
one on-line source) that I stand by to this day.  Very little has changed.
(Actually, there has been a *bit* of improvement:  Microsoft submitted a
proposal for a set of new string - and related - functions for standardization
in the C library.  They differ from the classic functions in always having an
explicit output buffer length.  Personally, I find the particular API typical
of Microsoft - butt-ugly and a pain to use - and I *think* that the standards
groups may be re-working them.  But one way or another, after all these years,
we may eventually have safe alternatives - once we work throught the
standardization process and get the stuff out there (I'd guess another 2 years
at least before you can safely assume that it'll be available).
 							-- Jerry

@_date: 2005-09-20 18:01:11
@_author: Jerrold Leichter 
@_subject: Java: Helping the world build bigger idiots 
I must admit I don't see the objection.  Exceptions are a natural way to
report "end of container" - at least in a language where they are native and
intended to be efficient.  C++ is *not* such a language:  Exceptions were
grafted on - a graft that still shows in many places - and it is widely known
that implementations are supposed to optimize the "no exceptions" case, even
at the expense of the "exceptions" case.  In fact, the norm is *no* cost when
there are no exceptions, paid for by searches through encoded tables in
each enclosing try block until you find one that matches.
Just because two constructs in two different languages are lexically and even
semantically similar doesn't mean they equivalent in intended/supported usage.
Language styles differ, sometimes dramatically.
(BTW, perhaps I don't find this usage so disturbing because I'm an old
SNOBOL4 hacker.  SNOBOL4 way pre-dates exceptions - it was mature by the
early '70's - but it did have a vaguely similar notion that an expression
could either succeed - returning a value - or fail.  Failure propagated out
through expresssions - suppressing further evaluation - to the nearest
containing statement, where it drove control flow.  Out-of-bounds access to
an array caused expression failure.  The usual way to walk a look was to
increment an index until the indexing operation failed - just as here.
(BTW, SNOBOL4 also explicitly specified the order of evaluation of expressions
and the initial value of variables.  Common SNOBOL4 programming idioms relied
on these guarantees.  These idioms would be a disaster in most other languages
- but so what.  Many of these idiomatic styles did make it into later
languages, Icon in particular.)
One thing to consider is that an idiom like this solves an annoying problem.  Consider a linear search through an array:
How many times have you written code at  - like setting a
"found" Boolean - just to distinguish the two exit states?Contrast with:
Personally, I sometimes use:
This draws shock and horror from some code readers, but I don't care.  :-)
Note how much it looks like the exception-based code.

@_date: 2005-09-21 12:27:53
@_author: Jerrold Leichter 
@_subject: Java: Helping the world build bigger idiots 
Oh, come on.  This loop has a trivial increment and a trivial stopping condition, for the purpose of illustration.  But even here, it's not so simple.  Better style in general is to limit the loop variable's scope to the Now i isn't accessible after the loop is done.  My personal style has always been to treat the loop variable as local to the loop, even when C didn't let
you declare it that way.  There are exceptions - especially cases where you traverse the same array in two consecutive loops, the second picking up where the first ended - but I've generally found that to be a better style.
Nice to know we're all adults here :-)

@_date: 2005-09-25 23:39:41
@_author: Jerrold Leichter 
@_subject: PKI too confusing to prevent phishing, part 28 
Just another indication that PKI as it was supposed to be done during the Internet boom is dead.  There are plenty of legitimate sites that are using self-signed certs.  (An ISP I use has one - and, while not one of the majors, it's not a mom-and-pop operation either.  They used to have a cert from Verisign or one of the other big providers.  After that expired, they kept using it for about a month - then put the self-signed one in its place.)
On this list, we see plenty of (quite plausible) arguments that a self-
signed cert is better than no cert at all:  At least it can be used in an SSH-like "continuity of identity" scheme.
Talking about users as being able only to hold one bit continues an unfortunate attitude that, if only users weren't so dumb/careless/whatever, we wouldn't have all these security problems.  Between the hundreds of CA's that browsers are shipped with - all allegedly trustworthy; the sites whose certs don't match their host names; the random links that appear to be within one site but go off to others with no relationship that anyone can discern to the original; the allegedly-secure sites that don't use https until you log in; all the messages telling you to ignore security warnings; and now the growing number of sites that use self-signed certificates ... as far as I'm concerned, SSL for browsers has gotten to the point where one could legitimately argue that it's *bad* for security, because it leads people to believe they have a secure connection when very often they don't.  Perhaps if they realized just how insecure the whole structure really is these days, there would be some pressure - in the form of even more people voting with their feet and refusing to participate - to actually get this right.
(BTW, I'll add one more tale to the "ignore security warnings" thread:  If
you try to use Windows Update these days, it asks you to update the updater.
If you agree, a .CAB file gets downloaded.  The .CAB file is properly signed by Microsoft.  Inside it are three other files.  These individual files are *not* signed.  You get warnings for each one, asking if the installer should go ahead and use them even though they are unsigned.  If you decline ... you can't use Windows Update.)
