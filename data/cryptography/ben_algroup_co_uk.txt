
@_date: 2001-04-22 20:34:47
@_author: Ben Laurie 
@_subject: NTT offering free licenses for algorithms (incl. Camellia) 
There was extensive discussion on the inclusion of Camellia in TLS
ciphersuites recently - I can't remember the outcome, though, sorry.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff
ApacheCon 2001!

@_date: 2001-08-01 13:23:46
@_author: Ben Laurie 
@_subject: moving Crypto? 
How about London?
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-08-21 10:15:05
@_author: Ben Laurie 
@_subject: A year late and a dollar short? (was FC: U.S. governmentpatents  
Oh yeah? So what about this, then:
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-12-21 04:07:20
@_author: Ben Laurie 
@_subject: quantum computer factors number 
Its worth noting that not only is the number not very interesting (15),
but various properties of it have been used to make the quantum computer
simpler. The quantum computer would not be capable of performing any
other calculation. In particular, addition has been substituted for
multiplication in one part of the calculation, and the other
multiplication has been changed to a completely different operation (bit
swapping). Once simplified thus, several operations were omitted because
they were known to not actually influence the outcome or because enough
of their inputs were known to make them guaranteed to be null
These changes are described as optimisations - but since in any real
case they would involve performing most of the calculation on a
classical computer (AFAICS), its difficult to see how this experiment
demonstrates anything other than a remarkable ability to control and
measure the quantum state of 7 atoms in a molecule. Which is impressive
in itself, but it seems hardly fair to describe it is factorisation.
Probably the coolest thing about this experiment is that they have
produced what appears to be a very accurate model of the decoherence
effects, which should allow quantum computers to be modelled with some
certainty in the future.
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-12-27 14:16:33
@_author: Ben Laurie 
@_subject: CFP: PKI research workshop 
I've never found it particularly hard to generate a client cert in
either Netscape or IE - but the time consuming part is the meatspace
component - verifying your identity to the CA/RA so they'll sign the
Of course, going through all of this to access a single page is silly.
The two useful aspect of client certs (IMNSHO) are firstly that they
allow single sign-on with access control in a way that does not require
all systems to communicate with some central authority and secondly they
give a way to bind an identity (or simply a set of
permissions/privileges/capabilities/whatevers) to a private key.
Of course, if your threat model means you must check a certificate's
validity immediately, then the first advantage is mostly gone. However,
you almost always need the second property, AFAICS, to do anything
useful with PKC.
If you have some kind of entity that binds a private key to some other
stuff, then that is a certificate, IMO. Equating certificates with X.509
is missing the point.
As for the "certificateless" model - all this really does is move the
binding from something you can carry around with you to something that
has to be done by a central authority. It is not clear to me why this is
such a marvellous improvement. Unless you happen to want to own the
central authority, of course, which, unlike certificates and CAs, is far
harder to replicate privately and therefore, presumably, potentially
even more profitable than Verisign's cash cow.
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-12-31 13:21:48
@_author: Ben Laurie 
@_subject: Steganography & covert communications - Between Silk andCyanide 
But this was because it was, in fact, one of his own ciphers.
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-07-02 21:11:10
@_author: Ben Laurie 
@_subject: [JXTA Security] Anonymity Snake Oil in JXTA 
OK, this has been pointed out by a few other people. It should be _much_
clearer on the website.
Oh yeah? So what are these banknotes and coins in my pocket, then?
So can I open one without presenting ID? Can I transfer cash into one
without ID?
And those do _not_ state that you are required to track money.
So how do I get to take legal action against the merchant as you
described? How does a merchant take action against a fraudulent client?
So publish your technical documentation, in its entirety.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-07-03 13:02:13
@_author: Ben Laurie 
@_subject: Crypographically Strong Software Distribution HOWTO 
What this does not address is the common situation where the
distribution gets signed by a different person each time (example:
Apache). I've put some pretty serious thought into this problem and come
to a few conclusions.
The obvious answer is "use a role key". This doesn't work - how does one
control who gets it? How is it distributed? What happens when a
developer leaves the group (the role key has to be revoked and we start
all over again?)? You have to build a whole organisation around the key,
which is unlikely to happen at all, let alone be secure.
So, you pretty clearly have to do something that allows multiple keys to
be used. It seems to me that the way to do this is to have tools that
manage a set of keys which may change over time. The keys sign each
other (the signatures would have to be tagged as signatures that allow a
particular software distribution to be signed) and the user trusts the
_set_ of keys, using the tools to check how keys get added and removed,
ensuring that appropriate signatures are on new keys, and that
revocations of old keys/signatures are checked.
Organisations like the Apache Software Foundation can also have
cross-checking between sets of keys to reduce the pain of building
initial trust in a set of keys for a new piece of software from that
This idea can be extended between groups of software developers, of
The key point, IMO, is that this has to be largely automated. To that
end, I've been working on tools that deal with all the low-level
ickiness, automatically check for updates, do the downloads and check
signatures, reduce all the info to a level where a user can actually
digest it in a reasonable amount of time, and so on.
It is a non-trivial task, so if anyone wants to help with it, please let
me know!
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-07-03 19:28:33
@_author: Ben Laurie 
@_subject: Crypographically Strong Software Distribution HOWTO 
So how does this work in practice? How does an ASF subproject instruct
the CA? How does one that's more divorced from any kind of formal
structure? Seems to me you are introducing a monster security hole
unless you somehow secure the instructions to the CA - and I can't see
how to do that at all - at least, not without doing what I already
proposed (and having the CA as the sole monitor of the correctness of
the process).
If Verisign can be spoofed into signing a Microsoft key, what hope for
this model? None, IMO.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-07-03 19:36:18
@_author: Ben Laurie 
@_subject: Crypographically Strong Software Distribution HOWTO 
I am, but I don't like the idea of "core developers" - you are merely
pushing back the place where you want a single key (or a well-defined
set of keys) - and I claim that is not a realistic plan. You have to
also allow the set of core developers to gradually change over time.
I'm not sure I understand the significance of this request - why are
version 4 keys better?
OK, looks like a new project is about to be born. Apache guys: does the
ASF want to adopt this (given that the substrate is likely to be GPLed)?
Or shall I set it up on my servers?
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-07-19 15:31:22
@_author: Ben Laurie 
@_subject: HushMail 2.0 released, supports OpenPGP standard 
And, err, Hush employee...
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-06-09 11:39:05
@_author: Ben Laurie 
@_subject: [Fwd: MoD STRIKES PRETTY GOOD DEAL] 
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-06-21 00:08:02
@_author: Ben Laurie 
@_subject: septillion operations per second 
10^24 is roughly 2^80. So, to _count_ to 2^128 would take 2^48 seconds.
That's around 9 million years. Or, for a million of them, 9 years.
In Boston 'til 1st July.

@_date: 2001-06-22 23:54:01
@_author: Ben Laurie 
@_subject: crypto flaw in secure mail standards 
Ummm ... and who would we expect _not_ to have the source?
In Boston 'til 1st July.

@_date: 2001-06-25 13:41:03
@_author: Ben Laurie 
@_subject: crypto flaw in secure mail standards 
I think you are missing the point - repudiation is an issue, but nothing
is non-repudiable.
It seems pretty fundamental to me - I can deny anything. I might have a
hard time getting away with it, but at the very least you'll have to
demonstrate that my denial is implausible (which is why witnesses help).
It also seems to me that one of the problems with electronic signatures
is that witnessing is harder, at least if you want to be disconnected
from the witness. To make it stick as well as physical witnessing does
would require the witness to actually watch my screen and say "yes, he
definitely intended to sign that document I see on the screen" (note
that I say "intended" because witnesses could also be useful to protect
against fraudulent software). I'd guess that a phone call to discuss the
fingerprint of the document would have some value if presence cannot be
achieved, but it would be hard to deal with fraudulent software by that
mechanism. Reading the whole document over the phone is presumed to not
be an option :-)
In Boston 'til 1st July.

@_date: 2001-06-28 18:42:31
@_author: Ben Laurie 
@_subject: Anonymity Snake Oil in JXTA 
JXTA ( claims to have a payment project which will
"implement anonymous and secure financial transactions". See:
They have chosen (by what process?) a thing called EPocketCash
( to do this. Here's the marketing
droidlish: "The goal is to implement the Epocketcash payment protocol
for financial transactions for JXTA. EPocketCash is the first payment
system designed exclusively for the Internet. It allows anybody to be a
merchant and/or a customer at the same time with the same account. This
anonymous payment system will work on any gizmos connected to the
internet. Currently we support the WEB, WAP and I-Mode phones."
Sounds great, no? There's just one teeny problem. It isn't anonymous.
Not even a little bit. It is merely secret. That is, it is tied to bank
accounts, and they promise (no, really) that they won't tell anyone who
you are. Oh, except a judge. Oh, and probably either side of the
transaction (so they can take you to court, see? Isn't that a marvellous
benefit? [well, they told me it was, and they should know, right?]). Oh,
and anyone who breaks into their system.
But it is anonymous really. They said so.
[1] I can't actually read this, it renders horribly on Netscape, but my
information comes from Philippe Coupe, President and CEO of IPassport
Corp (who own EPocketCash?).
In Boston 'til 1st July.

@_date: 2001-05-14 19:08:10
@_author: Ben Laurie 
@_subject: forwarded message from tylera19@hotmail.com 
Sure. Is it something I can actually deploy (without everyone else in
the world also deploying it)?
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-05-15 11:18:13
@_author: Ben Laurie 
@_subject: No free spam 
Actually, I was more concerned with the other side of the coin: that
insufficient people will adopt it to make it worth doing, and that it is
hard to find ways to give people an incentive to start using it.
I actually favour Adam Back's hashcash scheme for this particular
problem, even though I'm as keen as you are to see micropayments succeed
for other things.
This is particularly related to the incentive problem - I think it will
be difficult to persuade people to voluntarily adopt a system that is
likely to make what is now free cost money. Hashcash has the advantage
that it costs nothing (in practice) but still has the property of making
spam uneconomic (which, when you think about it, is a very cool trick).
In fact, in a conversation just now with Russ Nelson, I came up with
what I think is probably the best idea I've had yet on how to get this
scheme off the ground - what we do is get people to run hashcash on
their mail servers, and prioritise mail that arrives properly paid for -
also, autorespond periodically (in the style of vacation) to those who
do _not_ use hashcash urging them to start and pointing them at the
appropriate patches for the major mailer apps (of course, the endgame is
to get the major apps to include the patches by default). When it gets
popular enough, we just throw the switch and start bouncing mail that
has no hashcash. I even thought of a name for this scheme - CAMRAM (the
CAMpaign for ReAl Mail[1]).
I really think this could work, so I'm prepared to spend time on it -
who's in? (mail me privately)
I hear what you are saying, but I really don't see how this produces the
ultimate solution to PKI - unless you envisage the huge web boiling down
to a few very large players that I subcontract my ID requirements to. In
which case, I'm not keen.
[1] That's a joke, based on CAMRA, the CAMpaign for Real Ale.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-05-20 10:28:07
@_author: Ben Laurie 
@_subject: ANNOUNCE: CAMRAM list 
As I mentioned here and there, I've set up a list to discuss and deploy
hashcash and other technologies to eliminate spam.
Interested peeps can subscribe by sending mail to
camram-spam-subscribe at camram.org.
(CAMRAM -> CAMpaign for ReAl Mail).
List help can be had at camram-spam-help at camram.org.
This list is not for academic discussion of esoteric technologies, it is
for people who want to write code. Now.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-11-27 23:01:22
@_author: Ben Laurie 
@_subject: private-sector keystroke logger... 
Yeah right - so it sets up an outgoing connection to some webserver to
pass on the info. Firewall that.
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-10-03 09:32:14
@_author: Ben Laurie 
@_subject: Best practices/HOWTO for key storage in small office/home    office  
It is, in fact, the only interface. As you say, the I/O lines are used
for power (or the power lines are used for I/O, depending how you look
at it). Which I think is really cute. The other highly cute thing is
that you can put any number of iButtons on the same 1-wire interface in
any topology and it still works (I can give a summary of how this works,
if people care).
Note that 1-wire is really 2, of course, but since the other is ground,
you typically don't have to wire it, if you don't want to.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-10-06 21:31:29
@_author: Ben Laurie 
@_subject: AGAINST ID CARDS 
<3.0.5.32.20011006122007.01cc3938
Are you required to have one? Certainly in the UK its only required if
you want to leave the EU (though there are still some people manning the
borders that believe it is required for travel within the EU).
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-10-16 18:45:21
@_author: Ben Laurie 
@_subject: Scarfo "keylogger", PGP 
Errr ... surely this promotes MS's bottom line and no-one's security? It
is also a major pain if you happen to want to write a device driver, of
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-10-17 10:13:05
@_author: Ben Laurie 
@_subject: limits of watermarking (Re: First Steganographic Image in the Wild) 
The other obvious weakness in such a scheme is that the player can be
modified to ignore the result of the check - rather like defeating
dongles, which have yet to exhibit any noticable resistance to crackers.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-10-17 10:23:03
@_author: Ben Laurie 
@_subject: limits of watermarking (Re: First Steganographic Image in the Wild) 
The thing that gets me about all this is that exactly the same argument
can be made for all existing media - and, although piracy is rife,
no-one is attempting to mark videotapes or CDs, AFAIK. So why all the
fuss about more modern digital media? Has no-one noticed all the ripped
videotapes, CDs and DVDs? Are we really expected to believe the whole
media reproduction industry is ever going to switch over to producing
each disc individually, expensively watermarked? So what's the real
And don't tell me its because broadband will eliminate physical media:
a) I believe physical media will always have higher bandwidth than
broadband - why? Because you have to feed the broadband from somewhere,
and archive it somewhere.
b) Even if physical media goes away, individual watermarking blows away
multicast - and broadband will just never work without that.
It seems to me that putting the details of the purchaser in plaintext on
the beginning of the file and making it illegal to remove it is as good
a protection as you are ever going to get - but that would ruin a whole
bunch of business plans, so I guess no "expert" is going to admit that.
In short, the agenda, it seems to me, is the business plans of companies
in the watermarking business. No more, no less. I'm amazed the media
moguls are willing to waste so much of their time and money on it.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-10-17 17:59:39
@_author: Ben Laurie 
@_subject: limits of watermarking (Re: First Steganographic Image in the Wild) 
I'll admit that my argument doesn't stand up to severe testing - but I
think it is important that in general the receivers of the stream will
also want to store it (certainly my almost complete transition to
TiVo-ized TV viewing [what little I do] would support that theory :-).
Which is what I meant by "archive it somewhere", but I see now was far
from clear.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-10-19 12:08:30
@_author: Ben Laurie 
@_subject: limits of watermarking (Re: First Steganographic Image in theWild) 
Although I agree with the general point, I should just mention that if
an SSL break is a break of a private key, then future communications
between the broken party and others may be compromised.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-10-20 16:32:54
@_author: Ben Laurie 
@_subject: limits of watermarking (Re: First Steganographic Image in theWild) 
If it were possible, it would indeed raise the bar. The problem is, it
would seem, that it is not possible to have a provably strong means of
copy protection, publicly known or otherwise. The SDMI charter can say
what it wants, but that doesn't mean it can be achieved. The arguments
that support the impossibility of the goal have been well rehearsed, so
I won't repeat them here.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-10-24 13:07:18
@_author: Ben Laurie 
@_subject: SciAm conference on privacy and security 
Just came across this:
I notice a few of the Usual Suspects amongst the more blatant commercial
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-01 21:13:32
@_author: Ben Laurie 
@_subject: Anonymous Credit 
Just thought I should point out that recycling an old idea allows
researchers to publish stuff anonymously that could be illegal under
DMCA (or other ridiculous legislation) and still get the credit when the
world comes to its senses. The formula is simple: create a PGP key and
sign the publication. Publish anonymously (or pseudonymously, if you
prefer) in the usual way (carefully, please!). Once it becomes legal to
claim the credit, prove you have the corresponding private key, and
there you are.
Note that you should be rather careful about leaving the private key
lying around, just in case someone guesses who you are. And, in case it
isn't obvious, don't use the key for anything else.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-02 14:19:50
@_author: Ben Laurie 
@_subject: Anonymous Credit 
I suppose this is safer, in that it is deniable ("Me? Crack Ebook? Its a
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-09 13:03:02
@_author: Ben Laurie 
@_subject: Field slide attacks and how to avoid them. 
ASN.1/DER. Note that I am not advocating it, merely pointing out that it
a standard (if not entirely simple) way to deal with the problem.
Its more efficient to insert the 0x01 (in the 4th position) only if
there is a run of 4 0x00, or 0x00,0x00,0x00,0x01. "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-09 18:56:36
@_author: Ben Laurie 
@_subject: Field slide attacks and how to avoid them. 
I think you are missing the point. What John is talking about is where
two fields are banged up against each other before MACing, so 123 and
45678 gives the same MAC as 12345 and 678, no matter how good your MAC
function is.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-09 19:33:51
@_author: Ben Laurie 
@_subject: Compression side channel 
If you know the length of the plaintext and the encoding, no (because
the length reduction gives hints about the plaintext again - in the
worst case, it could give it away completely, so it could actually be
worse than adaptive compression).
If you have no idea of the length, then my guess is that it does help.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-09 20:37:01
@_author: Ben Laurie 
@_subject: Compression side channel 
It also wouldn't help at all in this context, since all that is used is
the length, not the bits (which, inherently, you don't know anyway).
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-09 22:23:07
@_author: Ben Laurie 
@_subject: Compression side channel 
Of course you may well not have that luxury. I've been contemplating
where this attack could realistically be mounted, and it seems to me
that HTTPS is a good example where it could well be possible.
Imagine a system where the admin of the system can view users' account
details. If more than one is displayed on the same page, the attacker
could modify their own details in order to reveal the details of others.
I'm sure this must be extremely common. There are bound to be other
examples - once you've had this idea, a really obvious one is any kind
of shopping basket admin system.
Its far too late to fix HTTPS to solve this problem. Luckily almost
no-one uses compression in SSL - and perhaps they shouldn't.
Also, of course, if you compress each logical part separately, you will
normally get no compression - compression tends to fare badly on short
inputs, especially adaptive compression.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-10 10:21:19
@_author: Ben Laurie 
@_subject: Compression side channel 
G4 includes ways to repeat the previous line with minor modifications,
but still uses Huffman encoding.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-10 10:22:57
@_author: Ben Laurie 
@_subject: Compression side channel 
Choosing one of a set of tables would be a bad idea - I can then use the
chosen plaintext to force the choice of particular tables, which would
then leak information copiously.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-10 10:27:54
@_author: Ben Laurie 
@_subject: Field slide attacks and how to avoid them. 
Although I already mentioned ASN.1 in this context, I should explain why
I specifically did not recommend it. It is horribly complex to
implement, and everyone gets it wrong. The experience in SSL is that
almost every implementation of X509 has some kind of screwup in the DER.
This means that code ends up full of exceptions to handle the mistakes,
and also means that one of the most useful properties of such systems
(that you can reconstruct the binary representation of the object to
check signatures) is in practice not available. You simply have to
preserve the original bits because you can't get them back again.
What we really need is something akin to ASN.1/DER but with reduced
complexity. I suspect that you have to lose some of the generality to do
that - but I'm not sure that would be such a bad thing.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-01 21:13:32
@_author: Ben Laurie 
@_subject: Anonymous Credit 
Just thought I should point out that recycling an old idea allows
researchers to publish stuff anonymously that could be illegal under
DMCA (or other ridiculous legislation) and still get the credit when the
world comes to its senses. The formula is simple: create a PGP key and
sign the publication. Publish anonymously (or pseudonymously, if you
prefer) in the usual way (carefully, please!). Once it becomes legal to
claim the credit, prove you have the corresponding private key, and
there you are.
Note that you should be rather careful about leaving the private key
lying around, just in case someone guesses who you are. And, in case it
isn't obvious, don't use the key for anything else.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-02 14:19:50
@_author: Ben Laurie 
@_subject: Anonymous Credit 
I suppose this is safer, in that it is deniable ("Me? Crack Ebook? Its a
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-09 13:03:02
@_author: Ben Laurie 
@_subject: Field slide attacks and how to avoid them. 
ASN.1/DER. Note that I am not advocating it, merely pointing out that it
a standard (if not entirely simple) way to deal with the problem.
Its more efficient to insert the 0x01 (in the 4th position) only if
there is a run of 4 0x00, or 0x00,0x00,0x00,0x01. "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-09 18:56:36
@_author: Ben Laurie 
@_subject: Field slide attacks and how to avoid them. 
I think you are missing the point. What John is talking about is where
two fields are banged up against each other before MACing, so 123 and
45678 gives the same MAC as 12345 and 678, no matter how good your MAC
function is.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-09 19:33:51
@_author: Ben Laurie 
@_subject: Compression side channel 
If you know the length of the plaintext and the encoding, no (because
the length reduction gives hints about the plaintext again - in the
worst case, it could give it away completely, so it could actually be
worse than adaptive compression).
If you have no idea of the length, then my guess is that it does help.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-09 20:37:01
@_author: Ben Laurie 
@_subject: Compression side channel 
It also wouldn't help at all in this context, since all that is used is
the length, not the bits (which, inherently, you don't know anyway).
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-09 22:23:07
@_author: Ben Laurie 
@_subject: Compression side channel 
Of course you may well not have that luxury. I've been contemplating
where this attack could realistically be mounted, and it seems to me
that HTTPS is a good example where it could well be possible.
Imagine a system where the admin of the system can view users' account
details. If more than one is displayed on the same page, the attacker
could modify their own details in order to reveal the details of others.
I'm sure this must be extremely common. There are bound to be other
examples - once you've had this idea, a really obvious one is any kind
of shopping basket admin system.
Its far too late to fix HTTPS to solve this problem. Luckily almost
no-one uses compression in SSL - and perhaps they shouldn't.
Also, of course, if you compress each logical part separately, you will
normally get no compression - compression tends to fare badly on short
inputs, especially adaptive compression.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-10 10:21:19
@_author: Ben Laurie 
@_subject: Compression side channel 
G4 includes ways to repeat the previous line with minor modifications,
but still uses Huffman encoding.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-10 10:22:57
@_author: Ben Laurie 
@_subject: Compression side channel 
Choosing one of a set of tables would be a bad idea - I can then use the
chosen plaintext to force the choice of particular tables, which would
then leak information copiously.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-10 10:27:54
@_author: Ben Laurie 
@_subject: Field slide attacks and how to avoid them. 
Although I already mentioned ASN.1 in this context, I should explain why
I specifically did not recommend it. It is horribly complex to
implement, and everyone gets it wrong. The experience in SSL is that
almost every implementation of X509 has some kind of screwup in the DER.
This means that code ends up full of exceptions to handle the mistakes,
and also means that one of the most useful properties of such systems
(that you can reconstruct the binary representation of the object to
check signatures) is in practice not available. You simply have to
preserve the original bits because you can't get them back again.
What we really need is something akin to ASN.1/DER but with reduced
complexity. I suspect that you have to lose some of the generality to do
that - but I'm not sure that would be such a bad thing.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-24 09:34:48
@_author: Ben Laurie 
@_subject: [FYI] Did Encryption Empower These Terrorists? 
This is simply bad design - there should be no "account number master
file" on the web server!
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-24 11:04:46
@_author: Ben Laurie 
@_subject: chip-level randomness? 
There was a bug in OpenSSL's PRNG (and BSAFEs) which permitted recovery
of the internal state from a largish number of small outputs. It has
been fixed, of course.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-24 17:23:41
@_author: Ben Laurie 
@_subject: <nettime> "Pirate Utopia," FEED, February 20, 2001 
He did only look for one particular encoding technique (at least, that
was true when we discussed it in April), so his failure to find anything
cannot be considered to be conclusive.
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-25 10:28:37
@_author: Ben Laurie 
@_subject: [FYI] Did Encryption Empower These Terrorists? 
Fine, but that was not the point you claimed to be making. You said:
It is easy to avoid this piece of bad design, for example by
transferring asymmetrically encrypted order details to a back-end system
(via email is a popular choice).
Of course, the system is still vulnerable to trojan-style attacks (in
fact it seems to me that even this could be avoided with some cunning
client-side work - it would even be valuable to extend, say, SSL to
permit this - I wonder if it would be worth describing how this could be
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-25 15:06:57
@_author: Ben Laurie 
@_subject: Rijndael in Assembler for x86? 
Ian Goldberg wrote something above this:
By far the best assember I ever saw from a C compiler came from
Watcom's. I'm sure I remember hearing they open sourced it a while back.
Or did I dream that?
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-09-26 18:14:00
@_author: Ben Laurie 
@_subject: Liberty Alliance 
"In an unprecedented collaboration between some of the world's largest
businesses and industries, representing over a billion customers,
employees and business partners, 33 major companies announced today the
formation of an alliance, code named Liberty Alliance Project
( The alliance will develop and deploy an
open solution for network identity."
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2002-08-10 15:46:03
@_author: Ben Laurie 
@_subject: Challenge to David Wagner on TCPA 
Obviously revealing the key would defeat any useful properties of the TPM/SCP. However, unless the machine refuses to run stuff unless signed by some other key, its a matter of choice whether you run an OS that has the aforementioned properties.
Of course, its highly likely that if you want to watch products of Da Mouse on your PC, you will be obliged to choose a certain OS. In order to avoid more sinister uses, it makes sense to me to ensure that at least one free OS gets appropriate signoff (and no, that does not include a Linux port by HP). At least, it makes sense to me if I assume that the certain other OS will otherwise become dominant. Which seems

@_date: 2002-08-11 16:03:54
@_author: Ben Laurie 
@_subject: dangers of TCPA/palladium 
This is correct. Palladium has "ring -1", and memory that is only accessible to ring -1 (or I/O initiated by ring -1).

@_date: 2002-08-12 13:52:39
@_author: Ben Laurie 
@_subject: Palladium: technical limits and implications 
I don't buy this: how does Palladium know what an app is without the OS'

@_date: 2002-08-14 13:16:56
@_author: Ben Laurie 
@_subject: Overcoming the potential downside of TCPA 
What prevents this from being useful is the lack of an appropriate certificate for the private key in the TPM.

@_date: 2002-08-14 20:49:58
@_author: Ben Laurie 
@_subject: TCPA/Palladium user interst vs third party interest (Re:  responding 
A wild thought that occurs to me is that some mileage could be had by using remotely attested servers to verify _signatures_ of untrusted peer-to-peer stuff. So, you get most of the benefits of peer-to-peer and the servers only have to do cheap, low-bandwidth stuff.
I admit I haven't worked out any details of this at all!

@_date: 2002-08-14 23:58:44
@_author: Ben Laurie 
@_subject: Overcoming the potential downside of TCPA 
If this is true, I'm really happy about it, and I agree it would allow virtualisation. I'm pretty sure it won't be for Palladium, but I don't know about TCPA - certainly it fits the bill for what TCPA is supposed to do.

@_date: 2002-08-21 14:31:53
@_author: Ben Laurie 
@_subject: Chaum's unpatented ecash scheme 
Sounds like it.
Note that the scheme as described (and corrected) is vulnerable to marking by the bank, and so is not anonymous. This is discussed and fixed in my paper on Lucre

@_date: 2002-08-22 15:43:21
@_author: Ben Laurie 
@_subject: Chaum's unpatented ecash scheme 
Anonymous _is_ creditted, but I can add the specific URLs.

@_date: 2002-08-22 16:19:42
@_author: Ben Laurie 
@_subject: Chaum's unpatented ecash scheme 
I've updated the paper (the update also corrects a slight typo in one of the equations).

@_date: 2002-08-22 19:41:50
@_author: Ben Laurie 
@_subject: the underground software vulnerability marketplace and its hazards 
Incidentally I was put under a lot of pressure when releasing the OpenSSL advisory a few weeks ago to allow CERT to notify "vendors" before going on general release. I have a big problem with this - who decides who are "vendors", and how? And why should I abide by their decision? Why should I pick CERT and not some other route to release the Also, if the "vendors" were playing the free software game properly, they wouldn't _need_ advance notification - their customers would have source, and could apply the patches, just like real humans.

@_date: 2002-08-29 14:08:40
@_author: Ben Laurie 
@_subject: Palladium and malware 
That would depend on what facilities the OS layers on top of TCPA/Palladium. Certainly I could believe an OS would exist that would simply refuse read access to executables, and Palladium/TCPA could be used to encrypt them such that they were inaccessible except under that OS.
So, in short. Yes.

@_date: 2002-08-30 12:44:36
@_author: Ben Laurie 
@_subject: Palladium and buffer over runs 
Apart from the content being accessed by IE, of course, which is quite likely to be the stuff that is supposed to be DRMed. Oh, but Palladium isn't for that. I forgot.

@_date: 2002-02-02 13:57:16
@_author: Ben Laurie 
@_subject: Losing the Code War by Stephen Budiansky 
?? 56 bits "plus a little", surely.
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2002-02-02 14:09:01
@_author: Ben Laurie 
@_subject: Perdue Done (Watermarked) It (was Re: Edupage, February 1, 2002) 
Yeah right, and it makes coffee and will prevent kiddyporn, too. Oh, did
they mention that it also does biometrics through your mouse?
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2002-02-03 11:56:31
@_author: Ben Laurie 
@_subject: Losing the Code War by Stephen Budiansky 
Some variants use 3 keys, in fact.
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2002-02-04 18:23:10
@_author: Ben Laurie 
@_subject: Unbreakable? (fwd) 
This suffers from the same flaw as the last proposal: the security lies
in the idea that you can't store the data for long enough to be able to
decrypt the message that says where in the bitstream your data is.
However, this is defeatable by a delay line of sufficient length, just
like the last idea (where, if you remember, the keying material was in
the fast random stream instead).
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2002-02-06 19:29:21
@_author: Ben Laurie 
@_subject: biometrics 
Surely the point about (good) SSO is that you control the domain you
share secrets with and that domain then certifies you to other domains -
thus avoiding the problem of sharing your secrets across domains.
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2002-02-20 17:04:01
@_author: Ben Laurie 
@_subject: "Cloak", or Cloaca? :-) 
Keyring and Strip are both programs that provide secure DBs on Palms.
Keyring, at least, is free and open source.
However, since Palms have no MMU, there's no security against hostile
other apps, which makes them pretty useless devices for this kind of
The right answer, IMO, is EROS on an MMUed handheld device (not sure
about the biometric aspect - as I've stated at tedious length before, I
like my appendages and don't want to give people incentive to steal
them), such as that thing that runs Linux whose name temporarily escapes
me, or the new Sharp gadget. Or a Jornada if they ever make one small
We have the technology. All we need is someone to finance it.
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2002-01-04 19:10:23
@_author: Ben Laurie 
@_subject: Steganography & covert communications - Between Silk andCyanide 
Indeed, it was the cipher he inherited (and spent much time and energy
to have replaced, for excellent reasons).

@_date: 2002-01-14 09:55:42
@_author: Ben Laurie 
@_subject: CFP: PKI research workshop 
And most (all?) commercial CAs then disclaim any responsibility for
having actually checked that right correctly...
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2002-01-14 15:55:00
@_author: Ben Laurie 
@_subject: CFP: PKI research workshop 
I have the source to all the security software I'm using... in fact, I
wrote quite a lot of it :-)
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2002-01-18 08:25:55
@_author: Ben Laurie 
@_subject: Horseman Number 3: Osama Used 40 bits 
Actually, to my perpetual dismay, we are now supposed to use a billion
in the US sense (it used to mean a million million). As a result, I
don't use the word at all, since it predictably has become ambiguous in
the UK.
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2002-01-27 18:32:19
@_author: Ben Laurie 
@_subject: biometrics 
Why are trusted third parties pure bullshit? Surely there are
circumstances where a third party really can be trusted? Or are you
talking about the tainted meaning of TTPs (i.e. spooks that hold your
private keys)?
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2002-01-28 12:36:25
@_author: Ben Laurie 
@_subject: A risk with using MD5 for software package fingerprinting 
One of the duties of a person with commit access to an Apache Software
Foundation project is, indeed, to review _all_ commits to that package.
Admittedly any particular individual will sometimes only glance at the
commit, but bugs are picked up at this stage with such regularity that I
am confident that the vast majority of commits are, in fact, reviewed.
I believe this practice is pretty common in free software.
Oh, I should note that commits are emailed to all committers, so it does
not require the committers to actively seek out commits to review.
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2002-01-29 15:26:40
@_author: Ben Laurie 
@_subject: Cringely Gives KnowNow Some Unbelievable Free Press... (fwd) 
If you want to slow down test operations, then iteration is good.
BTW, I don't see why using a passphrase to a key makes you vulnerable to
a dictionary attack (like, you really are going to have a dictionary of
all possible 1024 bit keys crossed with all the possible passphrases?
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2002-01-30 08:45:39
@_author: Ben Laurie 
@_subject: biometrics 
This is why you need to carry your verifying equipment around with you -
a PDA with a decent OS is the way to go, IMO.
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2002-07-04 16:57:07
@_author: Ben Laurie 
@_subject: crypto/web impementation tradeoffs 
If all you want to ensure is integrity, why are you using symmetric encryption? Surely a keyed HMAC would make more sense?
Not that this changes your question. However, you haven't specified your threat model, so I feel unable to answer.

@_date: 2002-07-20 13:41:30
@_author: Ben Laurie 
@_subject: It's Time to Abandon Insecure Languages 
E is interesting for far more reasons that just buffer overflows - in particular, it is capabilities from the ground up. Not to mention highly cool for distributed applications.
Well worth checking out, IMO.

@_date: 2002-07-21 11:47:18
@_author: Ben Laurie 
@_subject: Maybe no stego on eBay afterall 
Set all the pixels to the same value. Of course, you can trasmit a couple of bytes of information that way, and some more with the image size. So, I hereby decree that all pictures will be 256x256 pixels, 8 bits per pixel, all bits set to 1. Guess we need to mandate the compression method, too, lest you transmit a few bits by choosing it. So, uncompressed TIFF format. Of course, there's massive benefit to this. Now all pictures can use the same URL. Consider the massive bandwidth saving caused by caching. What a benefactor I am.

@_date: 2002-07-28 14:38:00
@_author: Ben Laurie 
@_subject: building a true RNG 
That's the kind of thing mathematicians like to say - but how much does it apply to the real world? For example, you can't produce your example set for SHA-1 or MD5, can you?
If you are prepared to factor in cost, then the landscape changes, I would contend. Mathematicians generally assume uncountable resources. Even constructivists assume countable resources. However, we can assume _finite_ resources. Big difference.

@_date: 2002-07-28 21:49:23
@_author: Ben Laurie 
@_subject: building a true RNG 
1024m not 10m, surely?
Your point appears to be that its hard to justify in the standard "infinite computing power" model that maths likes to use, not that its generally hard to justify.

@_date: 2002-07-29 21:50:29
@_author: Ben Laurie 
@_subject: building a true RNG 
But what you want, for an entropy-preserving system, is that Q ~= N. If Q >> N, then what you want is trivial (but not what we want).

@_date: 2002-06-23 11:34:55
@_author: Ben Laurie 
@_subject: Shortcut digital signature verification failure 
What David left out here is that this should be about 10 times as fast as signing. 20 times for 1024 bit, 30 for 2048 and 60 for 4096 - so the answer is "use bigger keys".
Note that even using 4096 bit keys my (totally non-optimal debugging build of) OpenSSL can do over 80 verifies a second on a PIII of average speed (and less than two signs).

@_date: 2002-06-26 20:09:24
@_author: Ben Laurie 
@_subject: privacy <> digital rights management 
No they don't! Privacy has to do with two (or more) parties wishing to collaborate to prevent third parties from eavesdropping. DRM has to do with one party attempting to control everyone else's ability to reproduce.
If these are related to each other at all, they are what mathematicians like to call duals. IMO.

@_date: 2002-03-29 14:34:54
@_author: Ben Laurie 
@_subject: authentication protocols 
You need to specify what you are trying to achieve! For example, its
easy to avoid third parties if you have already exchanged keys.
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2002-05-01 12:56:16
@_author: Ben Laurie 
@_subject: [Fwd: E-Money] 
"There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2002-10-01 11:59:36
@_author: Ben Laurie 
@_subject: Real-world steganography 
Yeah, right - and green felt-tip around the edges of your CD improves the sound, too.

@_date: 2002-10-02 21:15:39
@_author: Ben Laurie 
@_subject: What email encryption is actually in use? 
If you are going to do opportunistic encryption, then you have to be prepared to be opportunistic. Clearly, configuring your server so it can't encrypt opportunistically is a barrier to opportunistic encryption.
It isn't hard to set up SSL so it will interoperate with everything (this is why there are mandatory ciphersuites).

@_date: 2002-09-02 13:28:12
@_author: Ben Laurie 
@_subject: Cryptographic privacy protection in TCPA 
Hmmm. I see they've made the usual mistake with the rest of the world,

@_date: 2002-09-13 18:16:33
@_author: Ben Laurie 
@_subject: OpenSSL worm in the wild 
I have now seen a worm for the OpenSSL problems I reported a few weeks back in the wild. Anyone who has not patched/upgraded to 0.9.6e+ should be _seriously worried_.
It appears to be exclusively targeted at Linux systems, but I wouldn't count on variants for other systems not existing.

@_date: 2002-09-23 14:50:20
@_author: Ben Laurie 
@_subject: Sun donates elliptic curve code to OpenSSL? 
Note that if you don't want to be bound by Sun's licence, there's a flag to remove all their donated code (at least, there's supposed to be, I haven't checked).

@_date: 2002-09-23 17:54:01
@_author: Ben Laurie 
@_subject: unforgeable optical tokens? 
Sounds to me like you have to store a double spend database to avoid a replay attack (surely it isn't feasible for the verifier to choose the orientation with sufficient accuracy to elicit a particular response, therefore it will have accept valid responses from the vicinity, which will allow replays). And a double spend DB for this kind of thing sounds big and expensive. And slow to search.

@_date: 2002-09-24 13:29:29
@_author: Ben Laurie 
@_subject: Sun donates elliptic curve code to OpenSSL? 
Actually, the flag does help (and it defaults off, I'm told).
As has been observed elsewhere, the patent stuff only applies if you make a similar promise to Sun. If you don't want to have Sun not sue you when you infringe, then don't promise not to sue them.
Have you actually read the licence?

@_date: 2002-09-24 15:30:42
@_author: Ben Laurie 
@_subject: Sun donates elliptic curve code to OpenSSL? 
Although I think it is a fairly pointless exercise, I'm prepared to apply a patch that isolates the Sun code in its own files.

@_date: 2003-04-01 11:02:52
@_author: Ben Laurie 
@_subject: Russia Intercepts US Military Communications? 
Only for the client side (and the protocol, of course).

@_date: 2003-04-03 14:04:14
@_author: Ben Laurie 
@_subject: Logging of Web Usage 
I don't have time right now to comment in detail (I will try to later), but it seems to me that, as someone else commented, relying on operators to not keep logs is really not the way to go. If you want privacy or anonymity, then you have to create it for yourself, not expect others to provide it for you.
Of course, it is possible to reduce your exposure to others whilst still taking advantage of privacy-enhancing services they offer. Two obvious examples of this are the mixmaster anonymous remailer network, and onion It seems to me if you want to make serious inroads into privacy w.r.t. logging of traffic, then what you want to put your energy into is onion routing. There is _still_ no deployable free software to do it, and that is ridiculous[1]. It seems to me that this is the single biggest win we can have against all sorts of privacy invasions.
Make log retention useless for any purpose other than statistics and maintenance. Don't try to make it only used for those purposes.
[1] FWIW, I'd be willing to work on that, but not on my own (unless someone wants to keep me in the style to which I am accustomed, that is).

@_date: 2003-04-09 20:26:13
@_author: Ben Laurie 
@_subject: Via puts RNGs on new processors 
It seems clear to me that its hard to subvert a general CPU such that it does predictable damage to randomness. However, the same cannot be said about a hardware RNG.

@_date: 2003-04-30 15:02:30
@_author: Ben Laurie 
@_subject: [Lucrative-L] double spends, identity agnosticism, and Lucrative 
This is also what Lucre (and hence Lucrative) does.

@_date: 2003-08-29 11:13:42
@_author: Ben Laurie 
@_subject: PRNG design document? 
The validation is for the source of OpenSSL, and will be rolled into the
release, this is what is new.

@_date: 2003-08-29 11:27:41
@_author: Ben Laurie 
@_subject: PRNG design document? 
Actually, FIPS-140 _does_ have provision for seeding, at least for X9.17
(you use the time :-), but not for keying.

@_date: 2003-12-15 12:52:59
@_author: Ben Laurie 
@_subject: Super-Encryption 
I don't see any value added by cipher1 - what's the point?

@_date: 2003-12-16 18:44:59
@_author: Ben Laurie 
@_subject: Super-Encryption 
Yes, but you could know all this from cipher2 and RSA of SHA1(message), so I still don't see what value is added by cipher1.

@_date: 2003-12-17 10:20:55
@_author: Ben Laurie 
@_subject: Super-Encryption 
Eh? If you have RSA(SHA1(message)) then decrypting that and checking the hash matches confirms the originator.

@_date: 2003-12-19 10:41:38
@_author: Ben Laurie 
@_subject: Difference between TCPA-Hardware and a smart card (was: example: 
If I glance quickly through my wallet, I find 7 smartcards (all credit cards). Plus the one in my phone makes 8. So, run that "at most 1" argument past me again?

@_date: 2003-12-20 18:38:16
@_author: Ben Laurie 
@_subject: Difference between TCPA-Hardware and a smart card (was: example: 
I don't know. If you can tell me how to find out, I'd be happy to investigate. I have quite a few that are no longer needed, so destructive investigation is possible :-)
BTW, I forgot the two smartcards that are used by my Sky satellite TV stuff.
I'm not arguing with this - just the economic argument about number of

@_date: 2003-12-20 19:40:59
@_author: Ben Laurie 
@_subject: I don't know PAIN... 
Probably because non-repudiation is a stupid idea:

@_date: 2003-12-20 20:06:44
@_author: Ben Laurie 
@_subject: Difference between TCPA-Hardware and other forms of trust 
The problem is that their "secrets" are Snow White, or the latest Oasis album. You want them on your box, and they want them not to leave your box.

@_date: 2003-12-27 13:22:15
@_author: Ben Laurie 
@_subject: Microsoft publicly announces Penny Black PoW postage project 
They were only invented recently, and indeed, I've been planning to introduce them to the camram arena. I wonder if they're being discussed as a result of the pub conversation I had recently with a Microsoft person on this very subject?
One major advantage of memory-based proof-of-work over hashcash is that the variation between machines is much smaller (estimated to be a factor of 4 from slowest to fastest PCs, for example).
BTW, for those who don't know, SpamAssassin now supports hashcash.

@_date: 2003-12-27 16:01:35
@_author: Ben Laurie 
@_subject: I don't know PAIN... 
Well, AFAIK its always possible, but I was hedging my bets :-) I can imagine a system where both public and private keys are generated from some other stuff which is then discarded.
If you want the gory details, I recommend the Handbook of Applied Cryptography by Menezes et al., _not_ the Schneier brick. Warning: pretty technical.

@_date: 2003-12-27 17:20:39
@_author: Ben Laurie 
@_subject: Non-repudiation (was RE: The PAIN mnemonic) 
I define it quite carefully in my paper, which I pointed to.
Actually, its very easy to achieve legal non-repudiability. You pass a law saying that whatever-it-is is non-repudiable. I also cite an example of this in my paper (electronic VAT returns are non-repudiable, IIRC).
Read my paper (it was co-authored with a lawyer, so I believe we've got both the crypto and legal versions covered).

@_date: 2003-12-29 15:48:43
@_author: Ben Laurie 
@_subject: Non-repudiation (was RE: The PAIN mnemonic) 
I object because its not a technical, crypto concept. It doesn't matter what you do to try to achieve non-repudiation technically, I can always repudiate it - all I have to do is say "I didn't sign that" or "it wasn't me that initiated that transaction".
These do not require non-repudiation in the existing world, why do they suddenly need it when they become electronic?
What I presume you are trying to get at is to distinguish the use of a key with an intent to bind you rather than with an intent to provide authentication (or some other service signing can provide). This is not non-repudiation, it's something else, and it only confuses matters to use the wrong word for it.

@_date: 2003-12-29 15:59:53
@_author: Ben Laurie 
@_subject: Non-repudiation (was RE: The PAIN mnemonic) 
One of the things my paper discusses is that under UK law a signature on an email is just as binding as on paper, because contracts are all about intent to be bound and not the medium in which they are captured. Of course, if you want to repudiate an email it is probably easier, especially if you signed it by typing your name at the bottom (yes, this is a valid signature under UK law), but that's a judgement call on the part of the relying party.
Agreed - as I say, its all about intent and reliance. Nothing is automatic.

@_date: 2003-12-29 16:00:58
@_author: Ben Laurie 
@_subject: Non-repudiation (was RE: The PAIN mnemonic) 
This is going a little far, isn't it? If the human controls the setting of the bit, then it is signalling their intent.

@_date: 2003-12-29 16:02:55
@_author: Ben Laurie 
@_subject: Non-repudiation (was RE: The PAIN mnemonic) 
What you have here is evidence of origin, not non-repudiation.

@_date: 2003-12-31 10:43:34
@_author: Ben Laurie 
@_subject: [camram-spam] Re: Microsoft publicly announces Penny Black  PoW 
He uses the stamp that you generated. Each subscruber adds cryptography at metzdowd.com as an address they receive mail at. Done. Trivial.

@_date: 2003-12-31 11:12:11
@_author: Ben Laurie 
@_subject: why "penny black" etc. are not very useful 
If you set the price to 1 minute of CPU, and spammers own 10% of all machines on the 'net, then the average machine can only receive 144 spams per day. That's a significant improvement on my situation.
Plus I'd've thought that having 100% CPU utilisation all the time might attract attention. But maybe not.

@_date: 2003-12-31 20:59:22
@_author: Ben Laurie 
@_subject: [Fwd: Re: Non-repudiation (was RE: The PAIN mnemonic)] 
My co-author (a lawyer) responds in detail to Ian Grigg's criticisms.

@_date: 2003-01-19 20:36:46
@_author: Ben Laurie 
@_subject: Microsoft Introduces CD Copy-Protection 'Fix' 
That'll be "use controls" not "user controls", the entire point being that the user has no control.

@_date: 2003-01-20 16:47:17
@_author: Ben Laurie 
@_subject: Prime numbers guru 'factors' down success 
Doh! This is so untrue. The point is that they discovered a test that wasn't NP, for the first time. OK, so its P but with a vast constant, but even so, there must be a point at which it gets better than the best NP methods. I wonder if anyone's worked out where that point is?

@_date: 2003-01-21 13:11:10
@_author: Ben Laurie 
@_subject: Key Pair Agreement? 
Presumably if you add 64 bits (or so) to the desired keylength, this also helps with any concerns you might have.
Its worth noting that allowing the attacker (err, sorry, I mean Scott) to choose the _high_ 64 bits would work more efficiently with some fast key generation algorithms, though this might give more cause for concern.

@_date: 2003-01-21 18:31:02
@_author: Ben Laurie 
@_subject: Patents as a security mechanism 
FWIW, the precedent was set in a lesser way with CDs - there is an area that isn't writable on CD-Rs, which can be prefilled at manufacture time. AFAIK, no-one ever actually used it as a security mechanism, but it was there.
On a related note, you could licence either data-only or data and music from Phillips (or is it Philips?), and they were pretty aggressive about protecting it (I know because I wrote one of the first rippers [CD-Grab] and they used to get excited about it periodically, since it worked on data-only drives).

@_date: 2003-01-23 15:06:53
@_author: Ben Laurie 
@_subject: [open-source] Open Source TCPA driver and white papers 
Actually, I think its important to be clear about the differences between TCPA and Palladium. It seems quite obvious that _this version_ of TCPA is not designed (unlike Palladium) to provide DRM, though it is equally clear that they've failed to point out the obvious attack (which is to intercept the content once it has been decrypted, an attack Palladium explicitly defends against). In the meantime, the arguments "demonstrating" their weakness as a DRM platform are rather unsound.
They make two main points:
1. Variations in BIOS, OS and application will render it impossible to check PCR values. However, this argument also renders the chip useless for its intended purpose (i.e. if the PCR values change, you can no longer unseal your keys!).
2. The chip is vulnerable to power analysis and other advanced trickery. This may be true, but is quite probably not in reach of the ordinary user.
So, one must wonder why they mention these points but not the easy attack (snarf the content after decryption)? Presumably because they intend to close that at some point in the future, so using it as a defence now would be bad. Of course, once that hole is closed TCPA _is_

@_date: 2003-07-15 11:54:35
@_author: Ben Laurie 
@_subject: Announcing httpsy://, a YURL scheme 
BTW, tell me how you do spoofing and MITM if you aren't the trusted
introducer (if you are, clearly there's no need to spoof or MITM,
because you can just give the target of your choice)?

@_date: 2003-06-04 17:53:11
@_author: Ben Laurie 
@_subject: Lucre Updated Again 
Well, so much for peer review! After a weekend of
number-theory-wrangling, I found and nailed several bugs in Lucre, both
in the Java implementation and in the theory paper. So, once more, it
has been updated. The latest version can be found, as always, at
Anyone actually using it for anything vaguely serious is advised to upgrade.

@_date: 2003-06-14 16:35:12
@_author: Ben Laurie 
@_subject: Session Fixation Vulnerability in Web Based Apps 
This isn't the case. I analysed several sites I work on for attacks of
the type described when this paper first came out. None of them were
I suggest you read and think more carefully.
I will agree that an incautious implementor could get bitten by these
attacks, though.

@_date: 2003-06-14 21:42:55
@_author: Ben Laurie 
@_subject: Session Fixation Vulnerability in Web Based Apps 
The obvious answer is you always switch to a new session after login.
Nothing cleverer is required, surely?

@_date: 2003-03-06 11:47:22
@_author: Ben Laurie 
@_subject: Proven Primes 
I'm looking for a list or lists of sensibly sized proven primes - all the lists I can find are more interested in records, which are _way_ too big for cryptographic purposes.
By "sensibly sized" I mean in the range 512-8192 bits. I'm particularly after Sophie Germain primes right now, but I guess all primes are of

@_date: 2003-03-06 17:01:44
@_author: Ben Laurie 
@_subject: Proven Primes 
I'm not convinced any of those binaries are going to run on my system (which is FreeBSD), and anyway, if I'm going to use a binary to do ECPP I may as well shove it through Mathematica - much prettier UI :-)
Is their no free implementation of ECPP? Is there at least a free verifier?
Sounds like a plan. Thanks very much for the info.

@_date: 2003-03-07 10:04:00
@_author: Ben Laurie 
@_subject: Proven Primes 
Indeed. The commonly used one is ECPP which uses elliptic curves cunningly to not only prove primality, but to produce a certificate which can be quickly verified.
Probabilistic prime tests are just that - probable. ECPP actually proves it.
Running the probabalistic tests can only prove that it's composite - they can never prove primality.
BTW, a terminology nit - a Sophie Germain prime is one such that p and 2p+1 are prime - I'll be that what you've given me is one such that p and (p-1)/2 are prime, right?

@_date: 2003-03-08 18:45:56
@_author: Ben Laurie 
@_subject: Proven Primes 
RFC 2412 looks good, however, as you say, no certificates are included, nor is it made clear that (p-1)/2 has been proven.
I-Ds are less useful to me, since I can't give a long-term reference for them :-(

@_date: 2003-03-10 15:47:56
@_author: Ben Laurie 
@_subject: Lucre paper updated 
I have updated the Lucre paper with a new section on choosing parameters, in response to question from the lucrative project.
It can be found in the usual place: If I find (or write) free software that does primality proofs, then I guess I'll update it again!

@_date: 2003-03-10 15:48:25
@_author: Ben Laurie 
@_subject: Proven Primes 
I have to admit to surprise at the time involved - what s/w are you using to do the generating?

@_date: 2003-03-25 17:28:44
@_author: Ben Laurie 
@_subject: Who's afraid of Mallory Wolf? 
AFAICS, what it suggests, in a very roundabout way, is that you may be able to verify the binding between a key and some kind of DN by being given a list of signatures attesting to that binding. This is pretty much PGP's Web of Trust, of course. I could be wrong, I only read it

@_date: 2003-03-25 21:35:53
@_author: Ben Laurie 
@_subject: Who's afraid of Mallory Wolf? 
It seems to me that the difference between PGP's WoT and what you are suggesting is that the entity which is attempting to prove the linkage between their DN and a private key is that they get to choose which signatures the relying party should refer to.
Am I wrong?

@_date: 2003-03-28 08:13:46
@_author: Ben Laurie 
@_subject: Test Vectors? 
Does anyone have test vectors for the X19.7 PRNG (HAC p.173)?

@_date: 2003-05-05 16:51:16
@_author: Ben Laurie 
@_subject: Randomness 
People might be interested in a paper I've written on randomness:
 Comments, as always, are more
than welcome.

@_date: 2003-05-08 15:07:58
@_author: Ben Laurie 
@_subject: Randomness 
It was my intention, and perhaps I should make it clearer, that the only
difference between insecureprng() and the other PRNGs is the source of
entropy. Hence, it does not leak state any more than the rest do.
Clearly if the insecureprng() uses a cryptographically weak algorithm
then it cannot share state.

@_date: 2003-05-08 15:13:28
@_author: Ben Laurie 
@_subject: Randomness 
The collision resistance is indeed determined by the number of bits
different in the seed. However, sufficient entropy "ensures" (in a
random way) that there are not only a few bits different. In general, if
you want to generate 2^n different IDs, then the number of bits you need
is > 2n (how much greater is determined by how safe you want to be -
exactly 2n gives you about a 1 in 2 chance of a single collision).
Indeed. This is hard to evaluate without the knowing the properties of
the system. For example, if you happen to know that no two instances are
ever started in the same moment, then time is a fine source of entropy.
However, measurement of entropy is a different, and, IMO, thornier, subject.
Ethernet MAC addresses are not a good source of entropy if you care
about privacy, as I note. This is because an adversary could potentially
show that your UUID was derived from your MAC address, by brute-forcing
the rest of the entropy.

@_date: 2003-05-09 12:45:45
@_author: Ben Laurie 
@_subject: Randomness 
If they are literally parallel, then no, because they would produce the
same output if run simultaneously, and that's obviously bad. However,
what you'd fairly obviously do is lock the state so that they are
actually run serially, and then they behave like a single instatiation.

@_date: 2003-05-11 13:41:45
@_author: Ben Laurie 
@_subject: Randomness 
If you really only have 1 bit of entropy, then you're dead anyway, but
this is one good reason to mix your entropy before deriving an IV from
it (which is the usual practice anyway).

@_date: 2003-05-11 14:01:45
@_author: Ben Laurie 
@_subject: Randomness 
OK, what I'm suggesting is much less complex than what you think I'm
suggesting: when they share state, what they actually do is effectively
merge into a single PRNG. So, there isn't a second PRNG with some state
shared with the first, there's just one, and calls to any of the APIs
actually call the same underlying PRNG.
I guess I need to spell this out more carefully.

@_date: 2003-05-18 19:26:05
@_author: Ben Laurie 
@_subject: Confessions of a skeptical mind (re: reports that 17-year-old 
OK, I'll admit I haven't discussed this for a year or more with Niels,
but last time I did, we agreed that he proved no such thing. He looks
for certain statistical anomolies that correspond to particular ways of
doing stego. When he finds them, he tries to brute force the key.
Clearly, if the perp uses either some other form of stego or a strong
key, he loses. So, AFAICS, he's only going to catch stego done by people
who don't know what they're doing.
Now, what he has proved, IMO, is that it isn't routinely used by any
significant number of people, coz if it were, then some of them would
choose weak keys, as we know from other studies.

@_date: 2003-10-04 14:09:10
@_author: Ben Laurie 
@_subject: Monoculture 
Err, yes it does, but its not very well documented.
In fact, it constantly amazes me what OpenSSL does do for you
automatically. For example, I recently added CRL checking to Apache-SSL.
It took a while to figure it out, but in the end it came down to doing this:
static void InitCRL(SSLConfigRec *pConfig)
    {
    X509_STORE *pStore=SSL_CTX_get_cert_store(pConfig->pSSLCtx);
    int vflags=0;
    if(pConfig->bUseCRL)
    if(pConfig->bCRLCheckAll)
    X509_STORE_set_flags(pStore,vflags);
    }
(note, before people start nagging me for it, this is a WIP, but will be
released soon).

@_date: 2003-10-07 22:03:44
@_author: Ben Laurie 
@_subject: Other OpenSSL-based crypto modules FIPS 140 validated? 
Which is, of course, what we are trying to fix. And yeah, there are
others using OpenSSL. And if they don't say so, they're in breach of the

@_date: 2003-10-08 16:31:12
@_author: Ben Laurie 
@_subject: [e-lang] Re: Protocol implementation errors 
In which case, I should comment that most of the bad reputation I'm
aware of has to do with the difficultly of parsing ASN.1 source, and so
people end up implementing the mapping by hand, and so get it wrong.
Which is why X.509 is a nice theory, but don't even think about
unpacking and repacking a cert and having it still work.

@_date: 2003-10-09 19:21:50
@_author: Ben Laurie 
@_subject: Open Source (was Simple SSL/TLS - Some Questions) 
I think there's demand in the sense that there's demand for free
lunches. People would like the inherent complexity to go away, because
they can see that there's a way simpler API that addresses _their_
problem, but I fear that a good deal of the complexity in TLS is not
removable, so all that will happen is that the API will be unsuitable
for almost everyone else's problem - or it'll still be complex.
There must be a reason that OpenSSL is popular despite its disgusting
API and appalling documentation[1]. I hypothesize its because if you
think about it a while you can get it to do almost anything.
Its also worth considering that most applications of TLS need other
crypto primitives (it seems to me), so merely replacing the TLS part
doesn't actually help most people.
Anyway, that said, there's certainly room for something that does
everything OpenSSL does, only nicely.
[1] People have wondered in the past why I maintain OpenSSL if I have
such a low opinion of it - the answer is I do it because somebody has
to. Or to plagiarise someone else's witticism: the only thing that's
worse than OpenSSL is all the alternatives.

@_date: 2003-10-10 12:19:05
@_author: Ben Laurie 
@_subject: Monoculture 
But that's because its used internally (by both clients and servers).
Hmmm. You can put multiple certs in a single file, IIRC, and you can
certainly have multiple certs in a directory, with hashed links pointing
to them.
I know for sure chained certs work without screwing around coz I just
tested them whilst adding CRLs to Apache-SSL.
Regrettably, mod_ssl is not the best guide to the use of OpenSSL - it
often goes about things in a long-winded and inappropriate way (compare
its CRL handling with mine, for example).
This could well be true.
Oh, I totally agree!
I'm not familiar with Pluto.

@_date: 2003-10-10 12:35:40
@_author: Ben Laurie 
@_subject: Open Source (was Simple SSL/TLS - Some Questions) 
PPTP uses GRE, so aggressive firewalls are likely to kill it, however,
it isn't hard to stop them :-)
However, I've seen UDP surive some fairly aggressive firewalling, and
that's what you really want for a VPN.
Doesn't OpenVPN have that option?

@_date: 2003-10-11 18:00:50
@_author: Ben Laurie 
@_subject: VPN List Announcement 
Since I'm sure Perry will eventually get tired of VPNs, before he does I
should announce that I have, at the request of several participants in
the recent discussions, set up a list for VPN theory discussion. It is
currently unmoderated, though I reserve the option to change that if
The list can be found here:
 (yes, I know the
certificate has expired).
It will also be reflected into news at gmane.network.vpn.theory.

@_date: 2003-09-06 19:36:25
@_author: Ben Laurie 
@_subject: OpenSSL *source* to get FIPS 140-2 Level 1 certification 
I disagree. OpenSSL has a check of authenticity that works with static
libraries and linking only some of the module. I'll shout to this list
when I've written down exactly how the process works (or you can look at
CVS, coz I checked it in this afternoon [err, I think, I had some weird
problems with CVS later, so perhaps waiting a little might be advised]).

@_date: 2003-09-06 19:33:55
@_author: Ben Laurie 
@_subject: OpenSSL *source* to get FIPS 140-2 Level 1 certification 
Prepare to be very surprised, then.
This is all good fun, coz I'm mandating static libraries for OpenSSL, so
that the evidential chain can be maintained (its hard to find a DSO in a
cross-platform manner so you can checksum it).

@_date: 2003-09-07 21:15:34
@_author: Ben Laurie 
@_subject: Is cryptography where security took the wrong branch? 
I don't think so. One of the things I'm running into increasingly with
HTTPS is that you can't do an end-to-end check on a cert. That is, if I
have some guy logging into some site using a client cert, and that site
then makes a back-end connection to another site, there's no way it can
prove to the back-end site that it has the real guy online (without
playing nasty tricks with the guts of SSL, anyway), and there's
certainly no way to prove that some particular response came from him.
Signing stuff would deal with this trivially.

@_date: 2003-09-08 13:53:20
@_author: Ben Laurie 
@_subject: Is cryptography where security took the wrong branch? 
You _were_ right all along. At least about this :-)

@_date: 2003-09-10 00:25:37
@_author: Ben Laurie 
@_subject: OpenSSL *source* to get FIPS 140-2 Level 1 certification 
My fault. RSA is not validated (there are no validation tests for it),
but it will be in the code we are submitting for certification.

@_date: 2004-08-22 15:59:18
@_author: Ben Laurie 
@_subject: Microsoft .NET PRNG (fwd) 
That's if you think FIPS 186 is OK, which by many standards, it is not (I had occasion to look at it closely when doing FIPS 140 for OpenSSL).

@_date: 2004-08-25 15:17:15
@_author: Ben Laurie 
@_subject: Cryptography and the Open Source Security Debate 
This doesn't sound right to me - OpenSSL, IIRC, sets the top and bottom bits to 1. Of course, all large primes have the bottom bit set to one.

@_date: 2004-08-26 12:41:34
@_author: Ben Laurie 
@_subject: HMAC? 
Hmmm ... if you could persuade your victim to use a key that was known to be a suitable prefix for finding collisions...

@_date: 2004-12-14 14:43:24
@_author: Ben Laurie 
@_subject: The Pointlessness of the MD5 "attacks" 
Dan Kaminsky's recent posting seems to have caused some excitement, but I really can't see why. In particular, the idea of having two different executables with the same checksum has attracted attention.
But the only way I can see to exploit this would be to have code that did different things based on the contents of some bitmap. My contention is that if the code is open, then it will be obvious that it does "something bad" if a bit is tweaked, and so will be suspicious, even if the "something bad" is not triggered in the version seen.
So, to exploit this successfully, you need code that cannot or will not be inspected. My contention is that any such code is untrusted anyway, so being able to change its behaviour on the basis of embedded bitmap changes is a parlour trick. You may as well have it ping a website to find out whether to misbehave.

@_date: 2004-12-14 22:17:28
@_author: Ben Laurie 
@_subject: The Pointlessness of the MD5 "attacks" 
That does not make it seem innocent, it makes it seem incomprehensible.
I agree, but you do not need MD5 attacks to achieve these things.
Again, MD5 does not improve these attacks.
No, and they are therefore vulnerable to Microsoft. Note that MD5 is not required for Microsoft to attack them.
And MD5 helps with this how?

@_date: 2004-12-14 23:21:13
@_author: Ben Laurie 
@_subject: The Pointlessness of the MD5 "attacks" 
Quite so, but the "desired change to source" is either not visible, or suspicious. If it's not visible, then just make it malicious. And if it's suspicious then it shouldn't be run.

@_date: 2004-12-15 08:44:03
@_author: Ben Laurie 
@_subject: The Pointlessness of the MD5 "attacks" 
>
You are missing the point - since the only way to make this trick work is to include a very specific chunk of 64 bytes with a few bits flipped (or not), the actual malicious code must be present anyway and triggered by the flipped bits. So, all of these attacks rely on the code not being inspected or being sufficiently cunning that inspection didn't help. And, if that's the case, the attacks work without any MD5 trickery.

@_date: 2004-12-15 08:51:29
@_author: Ben Laurie 
@_subject: The Pointlessness of the MD5 "attacks" 
Indeed, but what's the point? If you control the binary, just distribute the malicious version in the first place.
People seem to be having a hard time grasping what I'm trying to say, so perhaps I should phrase it as a challenge: find me a scenario where you can use an MD5 collision to mount an attack in which I could not mount an equally effective attack without using an MD5 collision.
So, for example, in the scenario above, the attacker has control of a binary in which he can insert arbitrary content. Clearly, in his place, I can simply distribute malware without any MD5 collisions.

@_date: 2004-12-15 14:15:02
@_author: Ben Laurie 
@_subject: The Pointlessness of the MD5 "attacks" 
Indeed, but that is not the attack suggested.
And with only 2^64 effort. Let me know when you're done.

@_date: 2004-12-16 10:05:41
@_author: Ben Laurie 
@_subject: The Pointlessness of the MD5 "attacks" 
I did not say it was impossible, I said that such exploits would work just as well without MD5 collisions. For example, if you are going to trigger on some subtle distinction such as a single bit flipped, then make that a bit in a counter, or a bit in the input stream.
I do not have a special reason to think anything about future attacks on MD5. I am discussing the present attacks.

@_date: 2004-12-16 10:24:55
@_author: Ben Laurie 
@_subject: The Pointlessness of the MD5 "attacks" 
[snipped many assertions without supporting evidence that MD5 cracks improve attacks]
No, they may not. This crack does _not_ allow a third party to do anything interesting.
You are simply restating the supposed attack here, without providing any evidence it is useful.
This is true, but not germane.
Again, probably true, but definitely not germane. I am saying nothing about what future MD5 cracks may enable, I am only commenting on the cracks currently known.
To be clear, I am not advocating the use of MD5, nor have I for many years. I am simply contesting the theory that the ability to produce collisions, as currently known[1], actually provides any useful attack [1] I agree, future possible methods of producing collisions are likely to have a real impact on security. This is not what I am discussing.

@_date: 2004-12-22 17:24:23
@_author: Ben Laurie 
@_subject: The Pointlessness of the MD5 "attacks" 
Assuming you could find a collision s.t. the resulting decryption looked safe with one version and unsafe with the other (rather than gibberish), which I find an even bigger stretch than the idea that you could find a block that looked safe in one version and unsafe in another, I would have said that the mere fact of using a pointless decryption to control the action of the code would be suspect.
That kind of thinking may tempt you, but it doesn't tempt me. I am not discussing what it might be possible to do, I am discussing what it is possibile to do.
I had assumed that years ago.
Indeed. Not the point I am making. In a nutshell, yes, it is scary that Wang found collisions. No, it is not _more_ scary that you can use those collisions to fool people who aren't looking anyway.

@_date: 2004-12-22 17:18:05
@_author: Ben Laurie 
@_subject: The Pointlessness of the MD5 "attacks" 
They do not relate to the known MD5 collisions - these are general collisions, which we do not know how to create, not the restricted ones we do know how to create.
I claim I already have.
Absolutely not, I would not argue for a second that we should continue to trust MD5, I am merely making a very narrow argument about the nature and utility of the newly found collisions.
It would if it were possible, but it isn't.
I have made, I think, quite clear arguments why this attack is pointless.
I am not suggesting we trust MD5. My point is that this attack does not cause me to trust it any less than I already did, and nor does it offer any more useful exploit of MD5 than we already had.

@_date: 2004-12-22 18:38:19
@_author: Ben Laurie 
@_subject: The Pointlessness of the MD5 "attacks" 
There is certainly no inherent reason to think its impossible. What prevents this attack _right now_ is that we don't know how to generate a collision that satisfies the required properties.
Blimey. Finally. An attack I can actually believe in. Excellent.
Indeed, here is such a pair:
D131DD02C5E6EEC4693D9A0698AFF95C2FCAB58712467EAB4004583EB8FB7F8955AD340609F4B30283E488832571415A085125E8F7CDC99FD91DBDF280373C5BD8823E3156348F5BAE6DACD436C919C6DD53E2B487DA03FD02396306D248CDA0E99F33420F577EE8CE54B67080A80D1EC69821BCB6A8839396F9652B6FF72A700000000000000000000000000000001B is prime
D131DD02C5E6EEC4693D9A0698AFF95C2FCAB50712467EAB4004583EB8FB7F8955AD340609F4B30283E4888325F1415A085125E8F7CDC99FD91DBD7280373C5BD8823E3156348F5BAE6DACD436C919C6DD53E23487DA03FD02396306D248CDA0E99F33420F577EE8CE54B67080280D1EC69821BCB6A8839396F965AB6FF72A700000000000000000000000000000001B is not prime
both have MD5 b4b12dc7ec1b9422f6596d2a863d7900.

@_date: 2004-01-05 16:40:37
@_author: Ben Laurie 
@_subject: [Fwd: Re: Non-repudiation (was RE: The PAIN mnemonic)] 
A private key signature can only be produced by the holder of the private key, and can be verified by anyone (who has the public key). That is, it is asymmetric, just like PK encryption is. MACs and MDs (if keyed at all) use a shared secret, and thus behave like symmetric crypto.

@_date: 2004-01-19 10:47:44
@_author: Ben Laurie 
@_subject: Announcement: New mailing list for UK crypto 
By popular demand, I've created a moderated alternative to the UKCrypto mailing list. See  for the charter and subscription information.
This is intended to be complementary to the cryptography (because its about the UK) and ukcrypto (because its moderated) mailing lists, rather than competitive with them.
And no, I'm not interested in discussing why we haven't burnt our money buying a cert from your favourite money sink.

@_date: 2004-07-16 10:38:44
@_author: Ben Laurie 
@_subject: Verifying Anonymity 
The recent conversation on SSL where Eric Rescorla was lampooned for saying (in effect) "I've tried it on several occasions and it seemed to work, therefore it must be trustworthy" to which he responded "actually, that's a pretty reasonable way of assessing safety in systems where there's no attacker specifically targeting you" prompted me to ask this ... if a system claims to give you anonymity, how do you (as a user) assess that claim? I find it hard to imagine how you can even know whether it "seems to work", let alone has some subtle problem.

@_date: 2004-06-02 13:15:25
@_author: Ben Laurie 
@_subject: The future of security 
SPF will buy me one thing forever: I won't get email telling me I sent people spam and viruses.
Nevertheless these resources are limited, and better security would make them more limited.
Duh. So viruses would fix the stack.

@_date: 2004-06-03 21:50:36
@_author: Ben Laurie 
@_subject: 3. Proof-of-work analysis 
We wanted to assess whether pure proof-of-work helps. CAMRAM and other approaches may well change the calculations, but they also introduce lots of complications.
It seems we now have hard figures to support the notion that proof-of-work cannot be a complete solution in itself. We will be making that clearer in a revision of the paper (and fixing some errors).

@_date: 2004-06-14 12:19:34
@_author: Ben Laurie 
@_subject: Passwords can sit on disk for years 
In OpenSSL we overwrite with random gunk for this reason.

@_date: 2004-06-14 15:44:12
@_author: Ben Laurie 
@_subject: Is finding security holes a good idea? 
I don't see how that follows. If a bug is found but not disclosed, then it can be used for intrusion. If it is disclosed, then it cannot (assuming it gets fixed, of course). The fact that there are more bugs to be found which can _also_ be used for intrusions doesn't mean there's no point in fixing the hole, surely - at least the next bug has to be found before intrusions can occur again.
What you _may_ have shown is that there's an infinite number of bugs in any particularly piece of s/w. I find that hard to believe, too :-)

@_date: 2004-06-21 12:40:54
@_author: Ben Laurie 
@_subject: Passwords can sit on disk for years 
Sure it is, here's gcc -O3:
     {
     int a=3;
     }
         .file   "xx.c"
         .version        "01.01"
         .p2align 2,0x90
.globl main
                 .type            main, at function
         pushl %ebp
         movl %esp,%ebp
         leave
         ret
                 .size            main,.Lfe1-main
         .ident  "GCC: (GNU) c 2.95.4 20020320 [FreeBSD]"
look, ma, no variables!

@_date: 2004-11-01 14:13:08
@_author: Ben Laurie 
@_subject: Financial identity is *dangerous*? (was re: Fake companies, real 
That assumes that the goal of smartcards is to increase security instead of to decrease liability.

@_date: 2004-11-05 09:54:46
@_author: Ben Laurie 
@_subject: Your source code, for sale 
proof-of-delivery protocols might help (but they're patented, as I discovered when I reinvented them a few years back).
Simultaneous release is (provably?) impossible without a trusted third I think this is one of the interesting applications of capabilities. Using them, you can have a TTP who is ignorant of what is running - you and your vendor agree some code that the TTP will run, using capability based code. In your case, this code would verify the eGold payment and the code (difficult to do this part with certainty, of course) and release them when both were correct. Because of the capabilities, the TTP could run the code without fear, and you would both know that it performed the desired function, but neither of you could subvert it.

@_date: 2004-10-06 13:39:39
@_author: Ben Laurie 
@_subject: Linux-based wireless mesh suite adds crypto engine support 
I think it'd sometimes be better to feed them both into a pool rather than xoring them, since they might go at radically different rates, and xor would limit you to the slower of the two. Of course, for some threat models that would be the right thing.

@_date: 2004-10-25 16:23:14
@_author: Ben Laurie 
@_subject: Printers betray document secrets 
This only works if the marks are not such that the identity of the printer is linked to the marks (as opposed to being able to test whether a particular document was produced by a particular printer).
To be really safe, I'd suggest going somewhere without surveillance cameras, buying a printer for cash, using it and then destroying it.
Don't forget not to use your car and leave your mobile phone behind. Oh, and take the RFID tags out of your clothes.

@_date: 2004-10-30 17:40:00
@_author: Ben Laurie 
@_subject: [off-topic, but not by ukcrypto standards] ukcrypto-moderated pre-moderators 
OK, since my previous attempt to create a lower volume ukcrypto-like-thing failed, I have concluded that the only way to handle the problem is to produce a moderated version of ukcrypto. I know for sure there's demand for this, but I also know that the volume is too high for traditional moderation methods (at least too high for _me_ to use traditional moderation).
So, I'm going to try doing this a different way. What I want is volunteers who will undertake to, when it is convenient, sift through the currently unsifted-through postings to ukcrypto and choose candidates for moderation (and rejection). This will be done via an IMAP server, so volunteers need to have an email client that is capable of handling shared IMAP folders without frying its brains. If potential volunteers are in doubt as to whether they qualify, get in touch and we'll figure it out.
To explain a little more clearly what is entailed... there will be a folder with a copy of all ukcrypto mail in it. Volunteers will examine this and, for each message, do one of three things:
a) Leave it where it is (when in doubt)
b) Move it to a "rejected" folder
c) Move it to a "premoderation" folder
I will then do final moderation on the contents of the premoderation folder (to be clear: I'll also do premoderation, just like everyone else).
The idea behind this is that the load will be spread over the volunteers, so each one will only have to deal with a fraction of the total volume, _and_ moderation will be done in a convenient and familiar fashion, with threading and all that good stuff.
I'm copying this to Perry's list because I'm sure there are people who might like to read the output of this process (and might, therefore, volunteer as premoderators), but are not on ukcrypto because of the volume. Please feel free to forward this to other lists/individuals that might be interested.
Pre-moderators, please apply directly to me.
Discussion/questions can go wherever you prefer.

@_date: 2004-10-30 22:22:45
@_author: Ben Laurie 
@_subject: [off-topic, but not by ukcrypto standards] ukcrypto-moderated 
============================== START ==============================
I would include privacy and anonymity as well as cryptography. I'm open to persuasion for other topics.
Killing time isn't one of them.

@_date: 2004-09-18 14:54:42
@_author: Ben Laurie 
@_subject: public-key: the wrong model for email? 
Let's assume for a moment that a solution exists that satisfies your requirements. Since the recipient _must_ be able to read the document in the end, and is assumed to be incapable of securing their software, then the document is still available to third parties without the consent of the sender, is it not?
It seems to me that fixing the PK "problem" would in no way improve the senders situation given that threat model.

@_date: 2004-09-22 14:40:08
@_author: Ben Laurie 
@_subject: public-key: the wrong model for email? 
Since they are using good software, the key is known to be strong, surely?
I didn't suggest a background check would help. I am suggesting that if you cannot rely on the recipient (or their machine) to manage keys properly, then you also cannot rely on them to manage decrypted emails

@_date: 2004-09-29 13:05:52
@_author: Ben Laurie 
@_subject: Customs and Excise Electronic Returns 
Background, for non-Brits: Customs & Excise (C&E) is the government department responsible for collecting VAT (Value Added Tax), which is a European sales tax. Businesses report their VAT transactions quarterly to C&E, currently mostly on paper (a one page form, amazingly) - this is known as a VAT return.
For some time, C&E has been encouraging electronic VAT returns (cunningly named eVAT), but until recently required the use of an X509 client certificate to submit.
Presumably this has proved unpopular, since they are now permitting good old username/password to be used. But they seem to be a little confused...
 From the eVAT FAQ "Which is more secure ? using a Digital Certificate or User ID & Password?
Both methods are secure, but they work in different ways."
 From the Government Gateway Help pages "Certificates provide a higher level of security, which is required for certain services."
Nothing like singing from the same songsheet, eh?
Anyway, it gets better. Three types of certificate are permitted, SecureMark, SimplySign or Trust Services. Again from the eVAT FAQ:
"   * SecureMark and Chamber SimplySign certificates can be used with either Internet Explorer 5.01 or higher, or Netscape Navigator.
     * Trust Services? certificates work with Microsoft Internet Explorer 5.0 or later and Netscape v 4.6 or higher (but not v6 or 7).
     * certificates can be used with Internet Explorer 5.01 or higher or Netscape Navigator 4.08 or later (but not v6 or 7). "
I dunno about you, but this is not exactly clear to me. Leaving that aside, let's look at the various CAs...
SecureMark,  on a page amusingly titled "Does your Netscape Browser meet the minimum requirements?" "the minimum system requirements are:
Windows 95 or NT 4 (SP3) or higher
Internet Explorer version 5.01 or above
128-bit cipher strength"
I guess the answe will be "no", then! (My browser was Firefox, SimplySign - seems they actually admit that "Netscape" might work. But...
"To make sure that your browser works with Trustis certificates the 'Trustis FPS Root CA' certificate should be installed. There is no danger in doing this and no programs will be downloaded to your computer."
No, of course, installing root CAs in your browser has no security implications whatever. And of course, you have to have the root CA to use a client cert. Not.
As for Trust Services. Well, I can't find them through Google (at least, not the one they had in mind) but much meandering around FAQs eventually yielded a link - turns out its BT and Verisign, but ... oops! "Note: Inland Revenue services have not yet been upgraded to allow the use of BT ID Certificates". So much for a simpler user experience.
Oh yeah, another gem from the eVAT FAQ:
"The Government Gateway and Digital Certificate authorities do not currently support the use of Digital Certificates on Apple Macintosh"
Well, of course not, because everyone knows that Apple X.509 is completely different from Microsoft X.509. Duh.
So, after all that, I totally understand why everyone thinks PKI is hard. I'm all for the username/password thing. Its free, too.

@_date: 2004-09-30 10:38:15
@_author: Ben Laurie 
@_subject: Customs and Excise Electronic Returns 
I forgot to check for that (which would make the CA unusable from my POV), but circumstantial evidence leads me to believe that at least one of the supported CAs doesn't suffer from this fatal flaw.

@_date: 2005-08-14 16:10:02
@_author: Ben Laurie 
@_subject: ID "theft" -- so what? 
PKI+SSL does not _cause_ the problem, it merely fails to solve it. You may as well blame HTTP - in fact, it would be fairer.

@_date: 2005-08-14 16:47:33
@_author: Ben Laurie 
@_subject: The summer of PKI love 
Regardless of whether its a good idea, saying it is a problem seems to me to be complete bollocks. Moving keys around is generally easy.

@_date: 2005-08-14 17:38:26
@_author: Ben Laurie 
@_subject: Possible non-extension property for hash functions 
It may be well-known, but it isn't actually true. Or rather, it isn't true as stated: s has to be chosen carefully for it to be true (or x any y have to have particular properties).
And this doesn't use the property above. It uses a stronger type of collision (i.e. a collision of internal state) - this allows s to be chosen freely.

@_date: 2005-08-20 14:19:00
@_author: Ben Laurie 
@_subject: Fwd: Tor security advisory: DH handshake flaw 
This is one reason everyone should use well-known primes for Diffie-Hellman (the other reason is the more obscure non-prime substitution attack using hash collisions discussed here a few months ago).
Related to this is a project I keep considering and never quite getting around to is to include a prime proof verifier in OpenSSL. It would be pretty cool to have modes which only work when all relevant primes come with proofs.
I've looked into this a few times, but have always ended up at a slight brick wall: I'd like to use proofs for which there's efficient (yes, I know "efficient" means "only takes a few months to run") code to produce the proofs, as well as (obviously) efficient (where efficient means "really fast") verifiers. This is, of course, so new proven primes can be produced without having to wait for someone with proprietary code to feel so inclined.
Do the experts out there have suggestions? Perhaps this time I'll get around to implementing.
Oh, BTW, bonus points if the prover can be run on large numbers of processors in parallel. Even more points if communication between the CPUs are low bandwidth.
It would also be nice to have a collection of primes and proofs in OpenSSL, so if people want to point me at such things, I'll do my best to make it so.

@_date: 2005-08-22 00:36:44
@_author: Ben Laurie 
@_subject: Fwd: Tor security advisory: DH handshake flaw 
Apologies, slightly at cross-purposes here. For a start, Sophie Germain primes are needed for D-H (or rather, safe primes), and secondly, I was talking about proving arbitrary primes, rather than constructing provable primes.
Incidentally, I presume that using constructed primes rather narrows the search space if they need to be secret (though I believe that proving arbitrary primes is rather too painful for routine use in this case, sadly).

@_date: 2005-08-22 13:07:12
@_author: Ben Laurie 
@_subject: Fwd: Tor security advisory: DH handshake flaw 
>
There aren't any such sets known to me. Can I be sure there are none known to anyone? No.
Not sure I agree with the false positive rate. What is known is that 3/4 of the bases are strong witnesses for a composite number. But is it known that these are evenly distributed? I don't know, but that would be required for a 1/4 false positive rate.
Based on a statistical argument from a closed source prover and verifier. Hmm.
The point of proofs (at least, useful proofs) is that they produce certificates that are cheap to verify. So, yeah, sure it may be overkill, but I'll do the killing so you don't have to.

@_date: 2005-08-23 12:40:17
@_author: Ben Laurie 
@_subject: Fwd: Tor security advisory: DH handshake flaw 
Hmmm ... better remove all references to RFCs, then! :-)

@_date: 2005-08-28 13:31:59
@_author: Ben Laurie 
@_subject: MD5 Collision, Visualised 
I wrote some code to show the internal state of MD5 during a collision...

@_date: 2005-08-28 13:40:42
@_author: Ben Laurie 
@_subject: Fwd: Tor security advisory: DH handshake flaw 
Interesting! So how does one go about constructing such an n?
I presume you mean densely distributed over the set of all primes? Uniform distribution isn't much use if its sparse!

@_date: 2005-08-28 22:10:56
@_author: Ben Laurie 
@_subject: MD5 Collision, Visualised 
1 line is 1 round. There are 64 rounds per block and 2 message blocks, plus a block of padding. That is, 192 rounds.

@_date: 2005-08-29 13:09:42
@_author: Ben Laurie 
@_subject: Fwd: Tor security advisory: DH handshake flaw 
Surely the attack of interest is where the attacker provides the prime - no control of RNGs is required for this.
This appears to be a probabilistic certificate, which strikes me as rather pointless.
I'd be interested in doing this, but first we need to choose a proving

@_date: 2005-08-31 23:58:33
@_author: Ben Laurie 
@_subject: MD5 Visualised, Mark II 
============================== START ==============================
I've revised the graphics somewhat, in light of comments received. Now shown are the input used in each round, and breaks between input blocks.
Same place:

@_date: 2005-12-16 06:25:05
@_author: Ben Laurie 
@_subject: Crypto and UI issues 
Thanks for the apology, but ... ssh is not my fault.
However, I don't really understand the problem here - if the key changes
in OpenSSH you can't connect until you take positive action by deleting
the old key from the known_hosts file. This is totally different to
accepting a new key.
I will agree that something better than just showing you the key would
be cool. Like maybe it could be signed by something so you can verify it
that way. Oh, wait. That's PKI, and we all know PKI is broken.
Two words: Thunderbird, enigmail.

@_date: 2005-12-16 17:41:48
@_author: Ben Laurie 
@_subject: crypto for the average programmer 
No, OpenSSL is self-contained. There is, IIRC, an engine that uses GMP
if you want, but its entirely optional; OpenSSL has its own bignum
implementation that's just as good.

@_date: 2005-12-18 02:26:56
@_author: Ben Laurie 
@_subject: Crypto and UI issues 
I was being sarcastic. I don't believe PKI is inherently broken, unlike
some. It does have limited uses, though.
I don't see why that would happen all that much, and if it did then just
certify with multiple hostnames.
Don't really buy this for what is, mostly, a protocol used by experts.
True names of hosts is not a deep problem. Indeed, it is even possible
to discover rigorously (if painfully in extereme cases).

@_date: 2005-12-19 03:44:07
@_author: Ben Laurie 
@_subject: Crypto and UI issues 
True, but I don't see false negatives very often with https at all. And
I visit far more web sites than I log into machines with ssh. So, I'm
not really buying this.
That's just not true.
You have logins at banks and IBM?

@_date: 2005-12-21 06:10:41
@_author: Ben Laurie 
@_subject: another feature RNGs could provide 
Good ciphers aren't permutations, though, are they? Because if they
were, they'd be groups, and that would be bad.

@_date: 2005-12-21 20:08:32
@_author: Ben Laurie 
@_subject: another feature RNGs could provide 
Must try not to post to crypto when I'm jetlagged! I had my wires
crossed here, what's bad is when the keys form a group, of course (as
others have also pointed out).

@_date: 2005-12-24 10:58:33
@_author: Ben Laurie 
@_subject: browser vendors and CAs agreeing on high-assurance certificat 
In fact, I'm told (I'll dig up the reference) that there's an X509v3
extension that allows you to specify alternate names in the certificate.
I'm also told that pretty much every browser supports it.

@_date: 2005-12-24 15:08:46
@_author: Ben Laurie 
@_subject: browser vendors and CAs agreeing on high-assurance certificat 
If they share an IP address (which they must, otherwise there's no
problem), then they must share a webserver, which means they can share a
cert, surely?
Actually, you just disable it in the server. I don't see why we need
anything more than that.

@_date: 2005-12-24 17:38:20
@_author: Ben Laurie 
@_subject: browser vendors and CAs agreeing on high-assurance certificat 
Sure, but if the server won't negotiate SSL 2, why is this a problem?

@_date: 2005-12-24 17:41:40
@_author: Ben Laurie 
@_subject: browser vendors and CAs agreeing on high-assurance certificat 
I don't see why not - the technical details actually matter. Since the
servers will all share a socket, on any normal architecture, they'll all
have access to everyone's private keys. So, what is gained by having
separate certs?
I do agree that the process by which the additional names get added to
the main cert needs to reflect ownership of the name, but that's a
different matter.
And I'm not claiming, btw, that this mechanism is better than the server
name extension. However, I don't believe its as broken as some are claiming.

@_date: 2005-12-26 12:12:25
@_author: Ben Laurie 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
Eh? It surely does stop MitM attacks - the problem is that there's
little value in doing so for various reasons, such as no strong binding
between domain name and owner, UI that doesn't make it clear which
domain you are going to, or homograph attacks.

@_date: 2005-12-26 12:51:37
@_author: Ben Laurie 
@_subject: another feature RNGs could provide 
Having shot myself in the foot once already, I've hesitated over
responding to this, but...
Surely if you do this, then there's a meet-in-the middle attack: for a
plaintext/ciphertext pair, P, C, I choose random keys to encrypt P and
decrypt C. If E_A(P)=D_B(C), then your key was A.B, which reduces the
strength of your cipher from 2^x to 2^(x/2)?

@_date: 2005-12-27 14:28:07
@_author: Ben Laurie 
@_subject: crypto for the average programmer 
Apparently this rather depends on platform and compiler options. I am
reliably informed that GMP is not always faster.
For those that really care it'd be cool if someone did a careful
comparison. It would also be interesting to know why they differ.

@_date: 2005-12-27 14:43:02
@_author: Ben Laurie 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
This is the SSH design for host keys, of course, and also the petnames
design for URLs. Unfortunately petnames don't solve the problem that it
is hard to check the URL even the first time.

@_date: 2005-12-27 23:34:15
@_author: Ben Laurie 
@_subject: another feature RNGs could provide 
If you don't have sufficient plain/ciphertext, then of course you can
choose incorrect pairs.

@_date: 2005-12-31 11:04:31
@_author: Ben Laurie 
@_subject: OpenSSL BIGNUM vs. GMP 
============================== START ==============================
It appears that one reason GMP may sometimes be faster than OpenSSL for
RSA is that it seems that GMP does not do blinding or constant time
arithmetic, both of which are needed to defend against known attacks.
So, if you are going to use GMP for speed, be aware that you may be
risking your private keys.

@_date: 2005-02-16 15:39:56
@_author: Ben Laurie 
@_subject: [IP] SHA-1 cracked? 
A work factor of 2^69 is still a serious amount of work. At a thousand million trials a second, that's still well over 17 years. I doubt you can get anything like that speed without _serious_ expenditure. For reference, a middling PC can do around 200k single block SHA-1's a second. So, multiply that by 5 million to get it down to 17 years, assuming all you have to do is hash.
Of course, we don't have the details yet, but this is not the sky falling on our heads (yet).

@_date: 2005-02-17 17:24:01
@_author: Ben Laurie 
@_subject: A cool demo of how to spoof sites (also shows how TrustBar preventsthis...) 
Errr ... your browser _is_ unreviewed, possibly buggy code.

@_date: 2005-01-05 11:23:52
@_author: Ben Laurie 
@_subject: The Pointlessness of the MD5 "attacks" 
It was my understanding that they are very easy to generate. Are you scanning your binaries? Do you have a complete list?
Given that we know (for some value of "know") that these collisions can be generated with trivial amounts of work, but do not know how to detect them (yet), I wouldn't agree with this.
What would be incompetent would be to rely on an MD5 hash.

@_date: 2005-01-07 16:42:23
@_author: Ben Laurie 
@_subject: Entropy and PRNGs 
Given recent discussion, this is perhaps a good moment to point at a paper I wrote a while back on PRNGs for Dr. Dobbs, where, I'll bet, most of you didn't read it.
One day, I plan to implement the API I describe there.

@_date: 2005-01-10 10:36:37
@_author: Ben Laurie 
@_subject: Entropy and PRNGs 
The point I am trying to make is that predictability is in the eye of the beholder. I think it is unpredictable, my attacker does not.
By your argument, no PRNG ever has any entropy, since the inputs are clearly known (at least to the PRNG).
I do say what it is conditioned on, further up the page.
One-time pads are not PRNGs, so I don't really see the relevance of this. I do agree that not all cryptographers want the same thing, I was trying to make a general point which is, I believe, largely valid.
Indeed - but it needn't be unknown to a potential attacker, which is precisely what I am getting at.
This seems to me to be exactly the opposite of what you just said ... i.e. "your collision resistance depends on the number of different seeds
your PRNG can have ... which is plain old entropy".
That's just silly. "True" clearly applies to "PRNG", not to "RNG".

@_date: 2005-01-11 09:32:10
@_author: Ben Laurie 
@_subject: entropy depletion 
Surely observation of /dev/urandom's output also gives away information?

@_date: 2005-01-13 10:23:17
@_author: Ben Laurie 
@_subject: entropy depletion 
Around where? I've never heard of a /dev/random that doesn't include a PRNG. But I'll admit its entirely possible I just haven't been paying attention. Can you give examples?
In any case, if the postulate is that observing the output could give away information about the underlying state, then I cannot see how

@_date: 2005-01-30 12:16:03
@_author: Ben Laurie 
@_subject: Cryptanalytic attack on an RFID chip 
It has been rumoured (in the UK) that car thieves can do this for Mercedes - does anyone know what they use in their keys (they aren't RFID for the relevant models, they're the more traditional infrared kind)?

@_date: 2005-07-11 19:43:31
@_author: Ben Laurie 
@_subject: the limits of crypto and authentication 
Back when we used to run O2's (then Cellnet) web stuff, we used to authenticate user accounts by sending random words to their phone. This was so long ago I can't remember when it was, but certainly > 5 years.

@_date: 2005-07-12 10:50:05
@_author: Ben Laurie 
@_subject: the limits of crypto and authentication 
Not entirely clear what you mean by the "issuing bank" here, but I'm hoping you don't mean that the bank issues the device - that would be very tedious.
I also find "directed only at the specific issuing bank" unclear - I presume you mean encrypted s.t. only the issuing bank can read it? In which case, you're adding complexity - a relying party has to let the issuing bank come between it and you to get anywhere. This would preclude, for example, offline transactions.
As I've said before, I totally agree that the only way to go is to have signatures made on such a device, but I do think its very important to design the thing right - and the above isn't sounding right to me.

@_date: 2005-07-12 11:13:31
@_author: Ben Laurie 
@_subject: EMV 
Which, of course, they would never do if you were extracting money to buy a ticket, or showing your season ticket. Explain to me how the contactless system alters this risk in any way?

@_date: 2005-07-12 18:21:48
@_author: Ben Laurie 
@_subject: the limits of crypto and authentication 
Sure, but multiple physical devices aren't my computer's problem, they're my problem.
There are reasons to want to do offline transactions and to not have intermediaries that go beyond mere connectivity. Anonymity being the one of most concern to me, but I'll wager there are others.

@_date: 2005-07-12 19:01:24
@_author: Ben Laurie 
@_subject: the limits of crypto and authentication 
Can we not aim higher than merely doing as badly as current systems do?

@_date: 2005-07-15 12:18:20
@_author: Ben Laurie 
@_subject: the limits of crypto and authentication 
You never know who might do stuff if its easy for them to do so. Make it hard, and you can be more confident they won't.
But I'm glad to hear we're not in opposition on this.

@_date: 2005-07-15 13:42:08
@_author: Ben Laurie 
@_subject: mother's maiden names... 
My bank doesn't even bother to move them around, as I discovered when I had a chequebook stolen and cheques for large sums forged, and honoured.
When I spoke to a person who had found the cheque in their store I asked "is it my signature?" (yes, I am sufficiently absent-minded that I might have written a large cheque and forgotten about it). Their response was that they didn't know and had no way to find out. In the end they faxed me a copy so I could check it myself.

@_date: 2005-06-04 10:33:36
@_author: Ben Laurie 
@_subject: What happened with the session fixation bug? 
Why? I suspect you are thinking of an attack other than session fixation. How does your attack work?

@_date: 2005-06-07 13:35:16
@_author: Ben Laurie 
@_subject: Digital signatures have a big problem with meaning 
Perhaps this is a good moment to remind people of my paper "Signatures: an Interface between Law and Technology" (written with Nicholas Bohm, a lawyer) which discusses this and other issues.

@_date: 2005-06-07 13:37:08
@_author: Ben Laurie 
@_subject: Digital signatures have a big problem with meaning 
You mean it _would_ have done if anyone could implement it correctly. Sadly, experience shows that no-one can.

@_date: 2005-06-08 12:19:00
@_author: Ben Laurie 
@_subject: encrypted tapes (was Re: Papers about "Algorithm hiding" ?) 
Why is it bad for the page to be downloaded clear? What matters is the destination is encrypted, surely?
Which, as it happens, it is on the above site.

@_date: 2005-06-08 15:38:12
@_author: Ben Laurie 
@_subject: AmEx unprotected login site (was encrypted tapes, was Re: 	Papersabout 
This would appear to be an artefact. If you fetch the page you are redirected to ( over HTTPS you'll find it is still an akamai server.

@_date: 2005-06-08 15:40:22
@_author: Ben Laurie 
@_subject: encrypted tapes 
Fair point. Of course, I knew because I did hit ^U - and followed
through to the page containing the javascript it ran!

@_date: 2005-06-09 05:01:34
@_author: Ben Laurie 
@_subject: encrypted tapes (was Re: Papers about "Algorithm hiding" ?) 
If they are indexes to external databases, then they are the basis of searches in those databases, by definition.
Not a very satisfactory answer.

@_date: 2005-06-09 13:40:08
@_author: Ben Laurie 
@_subject: AmEx unprotected login site 
Why is this better? The button you click can just as easily take you to a site other than the one intended.

@_date: 2005-06-09 14:48:16
@_author: Ben Laurie 
@_subject: AmEx unprotected login site 
But even if you have seen the lock and the URL, you are still vulnerable to homograph attacks and simply names that look right but aren't. I notice that AmEx have registered a _lot_ of names to make this hard, but even they don't win, for example:
$ whois americanexpresscard.co.uk
     Domain Name:
         americanexpresscard.co.uk
     Registrant:
         Lantec Corporation
     Registrant's Address:
         8 Copthall
         Roseau
         Commonwealth of Dominica
         00152
         DM

@_date: 2005-06-10 18:24:31
@_author: Ben Laurie 
@_subject: encrypted tapes (was Re: Papers about "Algorithm hiding" ?) 
I am just reading what you've written: "To cash a check, they ask you for "sensitive information" like SIN, bank account number, drivers licence number, etc.   They use the information to query Equifax or the

@_date: 2005-06-21 18:04:16
@_author: Ben Laurie 
@_subject: massive data theft at MasterCard processor 
No, because then you have to trust the readers. The only way this can possibly work safely is to have a trusted device that does the crypto _and all UI_ in the same package. And it has to belong to the user, stay with the user at all times and be secure.

@_date: 2005-06-23 00:50:46
@_author: Ben Laurie 
@_subject: Optimisation Considered Harmful 
A brief altercation this evening with CERT over the recent hyperthread caching issues has brought something that's been simmering at the back of my brain to the forefront.
The recent hyperthread/cache key recovery trick, followed by DJB's related (IMO) symmetric key recovery, and preceded by the RSA timing attacks (Boneh et al?) are all examples of attacks on the same thing: The problem is that if different paths through your code expose different availability of optimisation, then there's a timing attack available. I predict, for example, that someone will find a way to attack something using pipeline breaks on Pentium processors[1].
How do we fix this? Well, its easy to say: we make everything equally crap - we make sure that all operations are as slow as the slowest possible variant can be. However, on a modern processor, this is _very_ hard to do.
Could it be that for safe crypto we should be using Z80s?
[1] For those who don't know, even old Pentia have several different processing units internally, which run in parallel. They can even tell when instructions in one's pipeline conflict with another's (e.g. one uses a register as input that another is going to change, but hasn't yet), and delay processing appropriately. However, sometimes they can't work it out (this is, of course, another optimisation, this time for transistor count) and so they just throw their hands up, stop all the pipelines and start again. This causes a _substantial_ delay, easily measurable - I know of loops of tens of instructions that go twice as fast if apparently redundant - but pipeline-intelligence-informing - instructions are inserted. Of course, the PowerPCs with their speculative execution are probably even more fun in this respect (do they still do that?).

@_date: 2005-06-24 10:00:55
@_author: Ben Laurie 
@_subject: Optimisation Considered Harmful 
If it does that, why do you want to choose one of many? Surely a single one will do?

@_date: 2005-03-02 12:35:50
@_author: Ben Laurie 
@_subject: MD5 collision in X509 certificates 
Cute. I expect we'll see more of this kind of thing.
Executive summary: calculate chaining values (called IV in the paper) of first part of the CERT, find a colliding block for those chaining values, generate an RSA key that has the collision as the first part of its public key, profit.
BTW, reading this made me notice that Dan Kaminsky's attacks are wrong in detail, if not in essence. Because the output of the MD5 block function depends on the chaining values from previous blocks, it is not the case that you can prepend arbitrary material to your colliding block, as he claims. However, you can (according to the paper above) generate collisions with any IV, so if you know what the prepended material is, then Kaminsky's attack will still work.

@_date: 2005-03-02 16:23:02
@_author: Ben Laurie 
@_subject: MD5 collision in X509 certificates 
Actually, not - an RSA public key is not prime. Generating colliding public keys takes quite a bit more work.

@_date: 2005-03-21 11:56:44
@_author: Ben Laurie 
@_subject: Propping up SHA-1 (or MD5) 
It was suggested at the SAAG meeting at the Minneapolis IETF that a way to deal with weakness in hash functions was to create a new hash function from the old like so:
H'(x)=Random || H(Random || x)
However, this allows an attacker to play with Random (the advice I've seen is that if one is going to use an IV with a hash function, then one should transfer the IV with integrity checks to deny attackers this Another objection is that this construction changes the API at the sender end, which could lead to a great deal of complexity when the use of the hash API is deeply embedded.
A third is that the length of the hash is changed, which could break existing protocols.
Musing on these points, I wondered about the construction:
H'(x)=H(H(x) || H(H(x) || x))
which doesn't allow an attacker any choice, doesn't change APIs and doesn't change the length of the hash. Does this have any merit? Note that this is essentially an HMAC where the key is H(x). I omitted the padding because it seems to me that this actually makes HMAC weaker against the current attacks.

@_date: 2005-03-22 09:50:26
@_author: Ben Laurie 
@_subject: Propping up SHA-1 (or MD5) 
This does not appear to be correct - in my construction, i.e. without padding, then the fact that x and x' differ means that the first blocks are different, but not the colliding kind of different (since the first blocks will be 20 bytes of H(x) and blocksize-20 bytes of x or x' [or, to be pedantic, the first 20 bytes of the next block will be different]). Even if padding were included, x and x' would still not collide, because the chaining values would not be as needed at the start of the second block.
Obviously. But I don't understand your point.

@_date: 2005-03-22 16:51:12
@_author: Ben Laurie 
@_subject: Propping up SHA-1 (or MD5) 
This can be fixed quite easily:
H'(x)=H(H(x || H(x)) || H(x))

@_date: 2005-03-22 17:31:44
@_author: Ben Laurie 
@_subject: [saag] Propping up SHA-1 (or MD5) 
This construction cannot solve the problem since H(x)=H(x') => Wouldn't it?

@_date: 2005-03-22 17:48:46
@_author: Ben Laurie 
@_subject: [saag] Re: Propping up SHA-1 (or MD5) 
Doh. Yes. Slightly less elegantly, then:
H'(x)=H(H(x || H(0 || x) || H(0 || x))
Then you need two hashes running in parallel, but at least it is still online. Or, with three parallel streams:
H'(x)=H(H(x || H(0 || x) || H(1 || x))
I don't feel as comfortable with either as the original construction,

@_date: 2005-03-22 19:34:29
@_author: Ben Laurie 
@_subject: [saag] Propping up SHA-1 (or MD5) 
The hash does not need to be weak, since the two hashes are the same, and so their hashes are also the same.

@_date: 2005-03-24 10:38:40
@_author: Ben Laurie 
@_subject: Propping up SHA-1 (or MD5) 
I suggested in a later version these two constructions:
H'(x)=H(H(x || H(0 || x) || H(0 || x))
H'(x)=H(H(x || H(0 || x) || H(1 || x))
which only require a single pass (but, unfortunately, two or three different instances of the hash). This seems similar to the mechanism used in MD2, except the checksum is expensive.

@_date: 2005-03-24 18:19:36
@_author: Ben Laurie 
@_subject: [saag] Re: Propping up SHA-1 (or MD5) 
Sorry, I got my parentheses wrong. I meant...
H'(x)=H(H(x || H(0 || x)) || H(0 || x))
H'(x)=H(H(x || H(0 || x)) || H(1 || x))
the former being almost the same construction as suggested, except that H(0 || x) is appended to the first inner hash. I used this construction because nested keyed hashes have provable security properties (which is why HMAC is made the way it is). The second form is the one required to get those properties, I should point out.
I will confess that I have punted on whether those properties are actually useful.

@_date: 2005-05-20 19:22:32
@_author: Ben Laurie 
@_subject: Malaysia car thieves steal finger 
Good to know that my "amputationware" meme was not just paranoia.

@_date: 2005-05-20 22:59:22
@_author: Ben Laurie 
@_subject: [Lucrative-L] double spends, identity agnosticism, and Lucrative 
Would do if it were true - this is exactly why unblinded lucre coins have structure - that is, you can check that they are well-formed by doing hash operations on them. Blinded coins will fail these checks.
I forget the exact form of lucre coins (read the paper), but consider the construction x || H(x) - clearly only the unblinded version of this will have the right form.

@_date: 2005-05-20 23:21:35
@_author: Ben Laurie 
@_subject: What happened with the session fixation bug? 
Do they exist? Certainly any session ID I've ever had a hand in has two properties that strongly resist session fixation:
a) If a session ID arrives, it should already exist in the database.
b) Session IDs include HMACs.
Session fixation is defeated by either of these. Modulo insider attacks, of course. :-)

@_date: 2005-11-12 13:21:22
@_author: Ben Laurie 
@_subject: [Clips] [dave@farber.net: [IP] Apple tries to patent  'tamper-resistant 
I'd normally suggest finding prior art for this, since its a technique
that's been in use for decades, at least, but in this case I'm quite
happy to see the whole field become a morass of patents.
Will they never learn?

@_date: 2005-11-12 13:24:28
@_author: Ben Laurie 
@_subject: Pseudorandom Number Generator in Ansi X9.17 
It was? When? I had to replace the OpenSSL PRNG with X9.31 (as has been
discussed elsewhere, this is the same PRNG) for the FIPS-140
certification, and in my opinion it was a large step backwards.

@_date: 2005-10-14 14:11:58
@_author: Ben Laurie 
@_subject: NSA Suite B Cryptography 
When questioned about this at IETF (the NSA presented on this stuff) they said that the licence they had purchased would cover open source s/w. But yes, it could be that the NSA has to approve of the particular piece of s/w.
Incidentally, why the focus on GPL?

@_date: 2005-10-16 17:07:22
@_author: Ben Laurie 
@_subject: [saag] status of SSL vs SHA-1/MD-5, etc.? 
None of the ones you looked at you mean - your survey wasn't comprehensive.

@_date: 2005-10-21 00:39:37
@_author: Ben Laurie 
@_subject: Smooth prime MD5 collisions 
Inspired by  I have just produced
this prime:
which I claim collides (using the well-known alternative block) with a
number that has the first 26 primes as factors.
Also, while I was writing this, I got:
which collides with 43 primes.
Code and stuff will follow, but now I'm going to bed. I expect its
obvious how they are made, anyway.

@_date: 2005-10-21 18:42:14
@_author: Ben Laurie 
@_subject: Smooth prime MD5 collisions 
I think I actually did something rather simpler, but I might be missing
something. Let me know when I write it up.

@_date: 2005-10-22 07:18:21
@_author: Ben Laurie 
@_subject: Writeup of Smooth MD5 Collisions... 
...can be found here...  I'd quote it, but it
won't render well in plain ASCII.

@_date: 2005-10-25 12:42:15
@_author: Ben Laurie 
@_subject: Announcing OpenPGP:SDK 
At EuroOSCon, Rachel Willmer and I announced OpenPGP:SDK, a BSD-licensed
C library implementing the OpenPGP standard. The SDK is sponsored by
Although we are still very much in beta, feedback will be appreciated.
Permalink:

@_date: 2005-10-26 23:34:14
@_author: Ben Laurie 
@_subject: [PracticalSecurity] Anonymity - great technology but hardly used 
But this is trivial. Since the traffic is encrypted, you just have a bit
that says "this is garbage" or "this is traffic".
OTOH, this can leave you open to traffic marking attacks. George Danezis
and I wrote a paper on a protocol (Minx) designed to avoid marking
attacks by making all packets meaningful. You can find it here:

@_date: 2005-09-01 09:40:11
@_author: Ben Laurie 
@_subject: Fwd: Tor security advisory: DH handshake flaw 
Well, that's an interesting question. I have to admit that I am no longer sure there is any point. If people do an appropriate number of rounds of Miller-Rabin whenever they're handed a number that is supposedly prime, they're pretty safe.

@_date: 2005-09-11 21:31:48
@_author: Ben Laurie 
@_subject: ECC patents? 
I don't, but it is not the case that OpenSSL does not include ECC.

@_date: 2005-09-12 10:19:34
@_author: Ben Laurie 
@_subject: ECC patents? 
If debian wants OpenSSL to do something, then it needs to tell OpenSSL. We aren't telepaths.
It does if they are owned by Sun.

@_date: 2005-09-17 11:53:20
@_author: Ben Laurie 
@_subject: Clearing sensitive in-memory data in perl 
So wouldn't the world be a better place if we could all agree on a single such library? Or at least, a single API. Like the STL is for C++.

@_date: 2005-09-17 20:36:11
@_author: Ben Laurie 
@_subject: Clearing sensitive in-memory data in perl 
gets is so not the problem. Using strings that _can_ overflow is the problem. That means wrapping the entire standard library.
And, of course, the issue is that every other library in the universe uses C-style strings (etc.), so unless we can all agree on a better paradigm, we're screwed.

@_date: 2006-04-01 12:35:12
@_author: Ben Laurie 
@_subject: Unforgeable Blinded Credentials 
It is possible to use blind signatures to produce anonymity-preserving
credentials. The general idea is that, say, British Airways want to
testify that I am a silver BA Executive Club cardholder. First I create
a random number (a nonce), I blind it, then send it to BA. They sign it
with their ?this guy is a silver member? signing key, I unblind the
signature and then I can show the signed nonce to anyone who wants to
verify that I am silver. All they need to do is check the signature
against BA?s published silver member key. BA cannot link this nonce back
to me because they have never seen it, so they cannot distinguish me
from any other member.
However, anyone I show this proof to can then masquerade as a silver
member, using my signed nonce. So, it occurred to me that an easy way to
prevent this is to create a private/public key pair and instead of the
nonce use the hash of the public key. Then to prove my silver status I
have to show that both the hash is signed by BA and that I possess the
corresponding private key (by signing a nonce, say).
It seems to me quite obvious that someone must have thought of this
before - the question is who? Is it IP free?
Obviously this kind of credential could be quite useful in identity
management. Note, though, that this scheme doesn?t give me unlinkability
unless I only show each public/private key pair once. What I really need
is a family of unlinkable public/private key pairs that I can somehow
get signed with a single ?family? signature (obviously this would need
to be unlinkably transformed for each member of the key family).
Permalink:

@_date: 2006-04-04 06:15:48
@_author: Ben Laurie 
@_subject: Unforgeable Blinded Credentials 
So, for the record, has Brands.
I agree that, in general, this is a problem with multi-show credentials
(though I have to say that using a completely different system to
illustrate it seems to me to be cheating somewhat).
Brands actually has a neat solution to this where the credential is
unlinkable for n shows, but on the (n+1)th show reveals some secret
information (n is usually set to 1 but doesn't have to be). This
obviously gives a disincentive against sharing if the secret information
is well chosen (such as "here's where to go to arrest the guy").
Hohenberger presented a system (at Eurocrypt 2004? 2005?) where then
(n+1)th show makes all the shows linkable, which is even neater, IMO,
but is based on rocket science :-)
All this goes way beyond the scope of my original question, but I have
to confess is necessary to make what I outlined useful.

@_date: 2006-04-04 06:20:31
@_author: Ben Laurie 
@_subject: Unforgeable Blinded Credentials 
If I have understood your description correctly it seems to me that this
is defeated if, rather than sharing the master certificate, the bad guy
allows their friend to proxy to them for whatever proofs are required.
That way they never have to give up the precious master cert, but the
friend's slave cert's still work.

@_date: 2006-04-08 19:53:37
@_author: Ben Laurie 
@_subject: Unforgeable Blinded Credentials 
I could be wrong, but I'm pretty sure they're unlinkable - that's part
of the point of Brands' certificates.
The problem with that disincentive is that I need to sink the money for
each certificate I have. Clearly this doesn't scale at all well.

@_date: 2006-04-08 20:14:03
@_author: Ben Laurie 
@_subject: Unforgeable Blinded Credentials 
That's only true if the credential contains any unblinded unique data,

@_date: 2006-04-09 21:55:44
@_author: Ben Laurie 
@_subject: Unforgeable Blinded Credentials 
This is what I was talking about.
If you use the same coin then at some point it becomes worth losing it
so you can then double-spend everything secured with it.
Yes, I think this is true, the question is how unattractive it can be

@_date: 2006-04-20 08:03:46
@_author: Ben Laurie 
@_subject: Unforgeable Blinded Credentials 
If they represent cash, then lots. The more the better.

@_date: 2006-12-21 16:11:49
@_author: Ben Laurie 
@_subject: Startup to launch new random number generator from space 
Using a random number generator, presumably. If only we could find a
good source of randomness... :-)
This kind of service has been discussed here before, of course. The
usual verdict: so much better for attackers, especially if they work for

@_date: 2006-12-29 10:40:20
@_author: Ben Laurie 
@_subject: How important is FIPS 140-2 Level 1 cert? 
No, it doesn't. Fork protection was originally implemented inside the
"FIPS boundary" - which the test lab made us remove. I guess it might be
possible to re-insert it outside the boundary, I'm not sure that
occurred to us at the time. I seem to remember there was some obstacle
to this, though, but I can't remember what it was.
While we're at it, an amusing fact I learnt about FIPS-140 while I was
implementing it for OpenSSL is that some of the Monte Carlo tests have
output that's independent of the input.

@_date: 2006-02-03 14:13:12
@_author: Ben Laurie 
@_subject: Abuse Resistant Publishing 
George Danezis and I wrote a paper describing a technique for private,
yet abuse-resistant, publishing. Here?s the abstract:
    We present the problem of abusive, off-topic or repetitive
    postings on open publishing websites, and the difficulties
    associated with filtering them out. We propose a scheme
    that extracts enough information to allow for filtering, based
    on users being embedded in a social network. Our system
    maintains the privacy of the poster, and does not require
    full identification to work well. We present a concrete realization
    using constructions based on discrete logarithms,
    and a sketch of how our scheme could be implemented in a
    centralized fashion.
Permalink: Paper:

@_date: 2006-02-05 18:01:13
@_author: Ben Laurie 
@_subject: Hiding data on 3.5" using "40 track mode" 
I used to write CD device drivers (ancient history, I wrote, with my
brother, one of the first CD rippers ever: CD-GRAB). As I remember it,
most drives _can_ read this extra data, but drivers often don't support it.
In fact, mixed in to the CD data stream are 8 extra single-bit streams,
known as A, B, C... H. CD+G probably (I forget) used the G stream, hence
the name. One of the other streams was normally used for timestamps,
IIRC, and the rest are free.
Hopefully someone will remember better than me so I don't have to dig
out my old documentation (I still have several yards of SCSI manuals for
CD-ROM drives as well as the CD standards, somewhere).
Note that CD data is actually unreliable when used for audio - I
definitely saw the same CD show bitwise differences on successive reads,
much to my surprise, so if you want to do this, remember to include
error correction :-)

@_date: 2006-02-05 18:49:42
@_author: Ben Laurie 
@_subject: methods of filling encrypted disks 
You want to not advertise the size of your encrypted data to the Bad
Guy, because then the Bad Guy doesn't know when he's hit you enough to
get you to reveal all your data. Assuming, that is, you actually want to
keep it secret. If you'd prefer not to be hit, being able to prove you
decrypted everything might be a good idea.

@_date: 2006-02-10 19:49:59
@_author: Ben Laurie 
@_subject: Nonrepudiation - in some sense 
Firstly, even if you believe that _any_ crypto provides non-repudiation
(see  for a paper I co-authored
on this and other stuff - executive summary: I don't believe it), you
can't "maintain" the non-repudation of SSL because it doesn't provide
Secondly, obviously, you can only decrypt SSL if you have the private
key, so presumably this is referring only to incoming SSL connections.

@_date: 2006-02-12 16:45:33
@_author: Ben Laurie 
@_subject: GnuTLS (libgrypt really) and Postfix 
Quite so.
But this is not why: if you attempt to "fix" impossible states, the
problem is that you cannot know why (by definition) the code is in the
state you are trying to fix, or what else might be broken. Continuing to
run is giving the attacker the option to make good on his exploit.
Again, this it not the issue. If you continue to run code you are
running it against an unknown state of the code and data. You are
allowing more leeway for exploits.
This is true even if the code is "just" printing a warning (don't forget
that to print a warning you must typically execute a substantial body of
library and system code).
I agree.

@_date: 2006-02-12 17:24:16
@_author: Ben Laurie 
@_subject: Nonrepudiation - in some sense 
You refer, of course, to the case where you are trying to decrypt a
sniffed conversation.
Gotta be careful with the trimming of messages!

@_date: 2006-02-12 17:40:27
@_author: Ben Laurie 
@_subject: general defensive crypto coding principles 
It also defends against the MD5 crack, and is one of the recommended
IETF solutions to hash problems.

@_date: 2006-02-13 03:20:11
@_author: Ben Laurie 
@_subject: general defensive crypto coding principles 
Agreed, I misspoke. I meant "proposed and not thought to be a stupid idea".

@_date: 2006-02-15 17:51:34
@_author: Ben Laurie 
@_subject: GnuTLS (libgrypt really) and Postfix 
I have perhaps not been clear in some of my comments in this thread. I
think there is a world of difference between critical errors and
detecting internal inconsistency. In the case of inconsistency I claim
that it is _never_ correct to continue running because every instruction
executed is another potential hole for the attacker to use.
Critical errors which do not indicate that something unexpected (as
opposed to undesirable) has happened should, indeed, allow the caller to
decide how they are handled.

@_date: 2006-02-24 13:44:14
@_author: Ben Laurie 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
Sure I can, but if you want it to be encrypted to you, then you need to
publish a key.

@_date: 2006-02-24 14:59:20
@_author: Ben Laurie 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
We have keyservers for this (my chosen technology was PGP). If you liken
their use to looking up an address in an address book, this isn't hard
for users to grasp.
For revocation, keyservers again. If I cared whether it was really yours
(I don't), then I'd check the signatures, or verify the fingerprint
I don't.

@_date: 2006-02-24 16:12:49
@_author: Ben Laurie 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
I don't use PGP - for email encryption I use enigmail, and getting
missing keys is as hard as pressing the "get missing keys" button.
I guess I don't send people like that much encrypted email.
Most of my encryption is done simply because its a good thing to do. If
the wrong guy is reading it I'll find out in the end. For the few where
I really care I'm prepared to go through that hassle.
Really? I just write "Ed Gerck" on an envelope and it gets to you? I
doubt it. Presumably I have to do all sorts of hard and user-unfriendly
things to find out and verify your address.
If you handled your keys properly I would not need to ask you for anything.

@_date: 2006-02-25 16:06:46
@_author: Ben Laurie 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
I don't sign mail not because I can't be bothered, but because it is my
policy to not sign mail.
If I signed it, it would be substantially harder to deny I wrote it.

@_date: 2006-02-25 16:58:22
@_author: Ben Laurie 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
I totally don't buy this distinction - in order to write to you with
postal mail, I first have to ask you for your address.
Apart from content of the blob handed over, the two transactions are
So you think people can use the post to write to you without you
publishing your address?
I think users are perfectly capable of handling keys. The problem they
have is in choosing operating systems that are equal to the task.

@_date: 2006-02-26 11:22:05
@_author: Ben Laurie 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
Don't forget that the ability to decrypt is just as good as a signature
to prove association of the key.

@_date: 2006-02-26 17:12:55
@_author: Ben Laurie 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
I trust you don't think this is a problem with PKI, right? Since clearly
the issue is with the s/w you were using.

@_date: 2006-02-27 09:31:11
@_author: Ben Laurie 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
OK, I buy the problem, but until we do something about the totally
non-anonymising properties of the 'net, revealing that I want the public
key for some person seems to be quite minor - compared, for example, to
revealing that I sent him email each time I do.

@_date: 2006-02-27 09:36:52
@_author: Ben Laurie 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
OK - I'll bite - why does the sender's identity have any impact on the
recipient's ability to decrypt?

@_date: 2006-01-03 22:10:50
@_author: Ben Laurie 
@_subject: OpenSSL BIGNUM vs. GMP 
Yes, you are - there's the cache attack, which requires the attacker to
have an account on the same machine. I guess I shouldn't have called it
constant time, since its really constant memory access that defends
against this.
Incidentally, I think the main component of the difference on Athlon,
like many other platforms, is simply a question of which library has
hand-optimised assembler for the platform. That is, it tells us little
about architectural differences and plenty about whether anyone has been
bothered to optimise for that particular platform recently.

@_date: 2006-01-04 14:53:51
@_author: Ben Laurie 
@_subject: OpenSSL BIGNUM vs. GMP 
Yes - from the change log (this came in with 0.9.7h):
  *) Make a new fixed-window mod_exp implementation the default for
     RSA, DSA, and DH private-key operations so that the sequence of
     squares and multiplies and the memory access pattern are
     independent of the particular secret key.  This will mitigate
     cache-timing and potential related attacks.
     BN_mod_exp_mont_consttime() is the new exponentiation implementation,
     and this is automatically used by BN_mod_exp_mont() if the new flag
     BN_FLG_EXP_CONSTTIME is set for the exponent.  RSA, DSA, and DH
     will use this BN flag for private exponents unless the flag
     RSA_FLAG_NO_EXP_CONSTTIME, DSA_FLAG_NO_EXP_CONSTTIME, or
     DH_FLAG_NO_EXP_CONSTTIME, respectively, is set.
     [Matthew D Wood (Intel Corp), with some changes by Bodo Moeller]

@_date: 2006-01-06 15:21:00
@_author: Ben Laurie 
@_subject: browser vendors and CAs agreeing on high-assurance certificat 
This would defeat the reason people share IP addresses, which is so they
can share a single machine to reduce costs. Of course, a capability OS
would permit this whilst separating keys, as you said.

@_date: 2006-01-06 17:06:50
@_author: Ben Laurie 
@_subject: browser vendors and CAs agreeing on high-assurance certificat 
Apache 1.x does indeed service each connection within its own child
process. Apache 2.x actually has a more flexible mechanism: it uses
things called MPMs (Multi-Processing Modules) which choose how
connections are handled. Some of them use threading and some use
processes and some use both. There is an MPM called "perchild" which
does exactly what you want:
 - sadly, it is not
currently functional, though I'm sure that either money or time would
make it so.
I think this is certainly a risk.
Someone firmly rooted in the past, perhaps?
True, but at least with multiple IPs you can bind separate instances of
the webserver to each IP on conventional OSes, unlike name-based virtual

@_date: 2006-01-19 11:21:31
@_author: Ben Laurie 
@_subject: long-term GPG signing key 
So that you can't be legally required to produce the private key (which
you destroyed, right?).
Perhaps this is time to remind people of "Security Against Compelled
Disclosure":

@_date: 2006-07-04 23:55:24
@_author: Ben Laurie 
@_subject: Use of TPM chip for RNG? 
Glad to see some new information in a thread that is otherwise giving me
a huge sense of deja vu. So ... where are these rebadged smartcards
deployed? Who rebadges them?

@_date: 2006-07-30 08:14:06
@_author: Ben Laurie 
@_subject: Test Vectors for IGE and biIGE? 
I'm implementing AES in IGE and biIGE mode. AFAIK, there are no other
implementations or test vectors, but perhaps one of you knows different?

@_date: 2006-03-02 10:16:55
@_author: Ben Laurie 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
I have to admit to not being familiar with S/MIME, but the usual
practice is to identify the signing key in the signature. Certainly this
is what OpenPGP does. Its also kinda weird to refuse to decrypt just
because the signature can't be verified.

@_date: 2006-03-03 05:58:46
@_author: Ben Laurie 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
Here's the output of one of the example programs in OpenPGP:SDK
( showing the structure of an OpenPGP
signed file. I trust it is self-explanatory.
==== ptag new_format=0 content_tag=8 length_type=3 length=0x0 (0)
position=0x0 (0)
COMPRESSED packet
Compressed Data Type: 1
==== ptag new_format=0 content_tag=4 length_type=0 length=0xd (13)
position=0x0 (0)
ONE PASS SIGNATURE packet
Version: 3
Signature Type: Signature of a binary document (0x0)
Hash Algorithm: SHA1 (0x2)
Public Key Algorithm: RSA (Encrypt or Sign) (0x1)
Signer ID: 0x8337FE6485F4ED64
Nested: 1
==== ptag new_format=0 content_tag=11 length_type=0 length=0x22 (34)
position=0xf (15)
LITERAL DATA HEADER packet
  literal data header format=b filename='to-be-signed'
    modification time=1141297085 (Thu Mar  2 10:58:05 2006)
LITERAL DATA BODY packet
  literal data body length=16
    data=
To Be Signed.
==== ptag new_format=0 content_tag=2 length_type=1 length=0x95 (149)
position=0x33 (51)
SIGNATURE packet
Signature Version: 3
Signature Creation Time: time=1141297085 (Thu Mar  2 10:58:05 2006)
Signature Type: Signature of a binary document (0x0)
Signer ID: 0x8337FE6485F4ED64
Public Key Algorithm: RSA (Encrypt or Sign) (0x1)
Hash Algorithm: SHA1 (0x2)
hash2: 0xBF33

@_date: 2006-03-08 18:39:30
@_author: Ben Laurie 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
It is _OpenPGP_ so it does not match it to an X.509 cert. It matches it
to an OpenPGP key.

@_date: 2006-03-09 18:13:48
@_author: Ben Laurie 
@_subject: bounded storage model - why is R organized as 2-d array? 
I presume you were expecting this to test encrypting a long stream of
data. It doesn't. "openssl speed" does encryption internally - the stuff
on stdin was ignored. Something like:
dd if=/dev/zero bs=32k count=1024 | openssl enc -aes-128-cbc > /dev/null
is probably what you want (untested).

@_date: 2006-09-04 17:01:18
@_author: Ben Laurie 
@_subject: IGE mode in OpenSSL 
I've added IGE mode to OpenSSL - it should be in the next release (0.9.8c).
More info here:  Including test vectors!

@_date: 2006-09-05 10:39:33
@_author: Ben Laurie 
@_subject: IGE mode in OpenSSL 
You decrypt with your guessed key. If the hash matches, then the key was
Its cheap. However, my main interest is in biIGE, since any change to
the ciphertext changes all of the plaintext, which is useful for some
protocols, in particular, Minx (

@_date: 2006-09-09 21:39:04
@_author: Ben Laurie 
@_subject: IGE mode is broken (Re: IGE mode in OpenSSL) 
Interesting. In fact, Gligor et al appear to have proposed IGE rather
later than this date (November 2000).
In any case, I am not actually interested IGE itself, rather in biIGE
(i.e. IGE applied twice, once in each direction), and I don't care about
authentication, I care about error propagation - specifically, I want
errors to propagate throughout the plaintext.
In fact, I suppose I do care about authentication, but in the negative
sense - I want it to not be possible to authenticate the message.
These properties are needed for the Minx protocol.
So, I mentioned the authentication properties in passing. It is,
however, good to know they don't work! And I love the more general
result in the paper mentioned (
I may have misunderstood the IGE paper, but I believe it includes proofs
for error propagation in biIGE. Obviously if you can prove that errors
always propagate (with high probability, of course) then you can have
authentication cheaply - in comparison to the already high cost of
biIGE, that is.

@_date: 2006-09-10 06:59:53
@_author: Ben Laurie 
@_subject: IGE mode is broken (Re: IGE mode in OpenSSL) 
Indeed, and you'll find this attack (or a similar one) in the proof of
Lemma 4 ("the schemes IGE$-z0 and IGE$-c are not EF-CPA, PU-CPA, PI-CPA,
and NM-CPA secure"), so I don't think you can cite them as flaws :-)
Note that I was talking about biIGE, not IGE. IGE is indeed broken under
many attack types, and the paper acknowledges that.

@_date: 2006-09-10 07:04:52
@_author: Ben Laurie 
@_subject: Exponent 3 damage spreads... 
Does it? All it presupposes, I thought, was that secure DNS was being
tested. Which it is.
Anyone who is running any vaguely recent version of BIND is DNSSEC
enabled, whether they are using it now or not. Unless they upgrade, they
will be vulnerable when they start to use it. So, the question of
whether to use exponent 3 is unrelated to the penetration of DNSSEC use
now, it is related to the penetration of broken implementations of
DNSSEC now.

@_date: 2006-09-11 09:03:07
@_author: Ben Laurie 
@_subject: Exponent 3 damage spreads... 
No more than using SSL. Well, not much more :-)
Key distribution is, indeed, an open question. Certainly manual key
distribution is not a solution.
I don't know whether this is true or not. Finding out what people do and
don't do with DNS is hard.
Doesn't bother me any, its just that I happen to have done work on
DNSSEC, so I figured I should alert those who care to the problem.
That seems a rather harsh judgement of a working group you say you're
not informed about.
Not that I totally disagree: the work I did on DNSSEC was initially
dismissed as out of order and off topic, and it took a lot of effort to
get people to accept that the problem was genuine. :-)

@_date: 2006-09-12 10:13:01
@_author: Ben Laurie 
@_subject: Exponent 3 damage spreads... 
You need at least 8 FFs here, or it will fail the padding check.

@_date: 2006-09-13 12:15:18
@_author: Ben Laurie 
@_subject: IGE mode is broken (Re: IGE mode in OpenSSL) 
Correct. Minx (which is the only place I use IGE) avoids traffic marking
attacks in two ways:
a) all messages are "correct"
b) any attempt to mark a message results in its complete corruption
See the Minx paper,

@_date: 2006-09-15 18:34:45
@_author: Ben Laurie 
@_subject: Why the exponent 3 error happened: 
No, it is incorrect and does have the problem we discuss. The fact that
it ignores the crap that's after the hash makes it vulnerable.
This is incorrect. The simple form of the attack is exactly as described
above - implementations ignore extraneous data after the hash. This
extraneous data is _not_ part of the ASN.1 data.
The more complex form of the attack does actually use the ASN.1, in the
form of the parameters field. However, I'm not sure why you'd single out
ASN.1 as the cause of this problem: once the designers of the protocol
decided you needed parameters, the door was opened to the attack.
Implementations can incorrectly ignore the extraneous parameters no
matter how you encode them.
Not that I'm a fan of ASN.1, but if we're going to blame it for
problems, we should do so only when it is actually to blame.
The fault in this case is a combination of overly flexible protocol
design and implementation flaws.

@_date: 2006-09-16 10:07:14
@_author: Ben Laurie 
@_subject: Why the exponent 3 error happened: 
If you ignore the ASN.1 stuff then you won't know what hash to calculate.

@_date: 2006-09-23 12:47:09
@_author: Ben Laurie 
@_subject: IGE mode is broken (Re: IGE mode in OpenSSL) 
Not what he said, he said n+log n.
Which is cost kn, k > 1, so kn > n+log n, in the limit. Proof left as an
exercise for the reader.
