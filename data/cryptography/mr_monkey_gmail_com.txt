
@_date: 2009-08-14 07:06:56
@_author: Your Monkey Overlord 
@_subject: Ultimate limits to computation 
Seth Lloyd, "Ultimate physical limits to computation":
"""As an example, quantitative bounds are put to the computational
power of an ?ultimate laptop? with a mass of one kilogram con?ned to a
volume of one liter.
The ultimate laptop performs 2mc^2 /??h = 5.4258 ? 10^50 logical
operations per second on ? 10^31 bits. Although its computational
machinery is in fact in a highly speci?ed physical state with zero
entropy, while it performs a computation that uses all its resources
of energy and memory space it appears to an outside observer to be in
a thermal state at ? 10^9 degrees Kelvin. The ultimate laptop looks
like a small piece of the Big Bang."""
Order yours today!

@_date: 2009-05-28 20:42:16
@_author: Your Monkey Overlord 
@_subject: End-of-chapter questions for "Practical Cryptography"? 
What about Mao's *Modern Cryptography* ?
As for Paul's question, maybe we can collaborate as a list on fun
questions for readers of *Practical*.

@_date: 2009-11-10 16:43:55
@_author: Chimpy McSimian IV, Esq. 
@_subject: TLS break 
Checking the Referer header never was effective. It's not even
guaranteed to be present, let alone true.

@_date: 2009-09-27 14:23:16
@_author: Fuzzy Hoodie-Monster 
@_subject: SHA-1 and Git (was Re: [tahoe-dev] Tahoe-LAFS key management,  
As usual, I tend to agree with Peter. Consider the time scale and
severity of problems with cryptographic algorithms vs. the time scale
of protocol development vs. the time scale of bug creation
attributable to complex designs. Let's make up some fake numbers,
shall we? (After all, we're software engineers. Real numbers are for
real engineers! Bah!)
cryptographic algorithm weakness discovery rate: several per decade
cryptographic algorithm weakness severity: 5 badness points per decade
the weakness has been known; 7 badness points is considered fatal.
Let's say MD5's badness is 8 and SHA-1's is 3. AES-256's is 1, because
even after the attack it is still strong enough for most real uses.
protocol development rate: 1 per year
bug creation rate (baseline): tens per day per project
bug creation rate for bugs due to complex designs: half of baseline
(the other half is due to just regular mistakes)
Although the numbers are fake, perhaps the orders of magnitude are
close enough to make the point. Which is: your software will fail for
reasons unrelated to cryptographic algorithm problems long before
SHA-256 is broken enough to matter. Perhaps pluggability is a source
of frequent failures, designed to solve for infrequent and
low-severity algorithm failures. I would worry about an overfull \hbox
(badness 10000!) long before I worried about AES-128 in CBC mode with
a unique IV made from /dev/urandom. Between now and the time our
ciphers and hashes and signatures are broken, we'll have a decade to
design and implement the next simple system to replace our current
system. Most software developers would be overjoyed to have a full
decade. Why are we whining?
What if TLS v1.1 (2006) specified that the only ciphersuite was RSA
with >= 1024-bit keys, HMAC_SHA256, and AES-128 in CBC mode. How
likely is it that attackers will be able to reliably and economically
attack those algorithms in 2016? Meanwhile, the comically complex
X.509 is already a punching bag
and including the remote exploit in the certificate handling code itself).
