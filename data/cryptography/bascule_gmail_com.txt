
@_date: 2013-08-26 10:44:33
@_author: Tony Arcieri 
@_subject: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
Check out this paper: Security Considerations for Peer-to-Peer Distributed
Hash Tables

@_date: 2013-11-14 11:50:33
@_author: Tony Arcieri 
@_subject: [Cryptography] Moving forward on improving HTTP's security 
And what of other solutions like CT or Tack?
Given Google's power to influence change via Chrome and its share of the
browser market, I think we'll see CT as the the primary solution for what
ails the existing PKI.
Tack looks cool too and I like Trevor and Moxie. But they don't have the
sort of influence Google does unfortunately.

@_date: 2013-11-20 11:06:52
@_author: Tony Arcieri 
@_subject: [Cryptography] Moving forward on improving HTTP's security 
Detecting hardware trojans via black box testing or even optical inspection
is really, really hard:

@_date: 2013-10-01 08:36:24
@_author: Tony Arcieri 
@_subject: [Cryptography] encoding formats should not be committee'ized 
C++ is a (not completely proper) superset of C. Does that make it better? ;)
YAML also has the property that indentation mistakes can radically alter
the interpretation of a file. And on Ruby, it was a remote code execution
vulnerability waiting to happen.

@_date: 2013-10-01 08:47:49
@_author: Tony Arcieri 
@_subject: [Cryptography] are ECDSA curves provably not cooked? (Re: RSA 
See slide  in this djb deck:
If e.g. the NSA knew of an entire class of weak curves, they could perform
a brute force search with random looking seeds, continuing until the curve
parameters, after the seed is run through SHA1, fall into the class that's
known to be weak to them.

@_date: 2013-10-01 10:54:13
@_author: Tony Arcieri 
@_subject: [Cryptography] are ECDSA curves provably not cooked? (Re: RSA 
As the fallout from the Snowden debacle has shown (with estimates of the
damage to US businesses in the tens of billions) the NSA seems to be
unconcerned with the blowback potential of doing things that are
potentially damaging when discovered. I wouldn't put it past them to
intentionally weaken the NIST curves.
That said, my gut feeling is they probably didn't.

@_date: 2013-10-01 13:10:32
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] are ECDSA curves provably not 
They wanted us to think they were incompetent, so we would
expect that Dual_EC_DRBG was their failed attempt to tamper with a
cryptographic standard, and so we would overlook the more sinister and
subtle attempts to tamper with the NIST curves

@_date: 2013-10-01 17:56:21
@_author: Tony Arcieri 
@_subject: [Cryptography] encoding formats should not be committee'ized 
Well, the details are important ;)
If someone is particularly fond of arguing over certificate formats, ZeroMQ
is trying to design one. I'm also trying to design one as well! It would be
nice to consolidate efforts on an X.509 replacement, even if it's a limited
capacity one.
Here's the original email to the 0MQ list:
Here's my response:

@_date: 2013-10-01 20:18:16
@_author: Tony Arcieri 
@_subject: [Cryptography] TLS2 
LANGSEC calls this: full recognition before processing
[image: Inline image 1]

@_date: 2013-10-03 10:40:01
@_author: Tony Arcieri 
@_subject: [Cryptography] AES-256- More NIST-y? paranoia 
No, there's a common misconception that the related key attacks make
AES-256 worse than AES-128 because AES-128 is not susceptible to these
attacks. The alleged source of this information is a Bruce Schneier blog
post (which is fine in and of itself, it's being misinterpreted).
In Schneier et al's book Cryptography Engineering he recommends AES-256
over AES-128, despite the flaws, but suggests we might consider looking for
a better cipher at this point. The rationale is that AES-256 still provides
a wider security margin.

@_date: 2013-09-07 13:06:14
@_author: Tony Arcieri 
@_subject: [Cryptography] Why prefer symmetric crypto over public key 
As soon as someone builds a large quantum computer (probably at least 10
years away, even for the NSA) most of the public key cryptosystems we use
today will be easily breakable with e.g. Shor's algorithm. Symmetric
algorithms will take a hit as well, with their keyspace cut in half, but
that's the equivalent of going from 256-bit keys to 255-bit keys, so
symmetric crypto will weather the post-quantum era just fine.
In order to beat quantum computers, we need to use public key systems with
no (known) quantum attacks, such as lattice-based (NTRU) or code-based
(McEliece/McBits) algorithms. ECC and RSA will no longer be useful.
Tony Arcieri

@_date: 2013-09-07 13:27:00
@_author: Tony Arcieri 
@_subject: [Cryptography] In the face of "cooperative" end-points, 
Well, it helps against passive eavesdropping. However if the NSA has a web
site's private TLS key, they can still MitM the traffic, even with PFS.
Likewise with "perfect" forward secrecy, they can collect and store all
your traffic for the next 10-20 years when they get a large quantum
computer, and decrypt your traffic then.
PFS is far from "perfect"

@_date: 2013-09-07 13:53:13
@_author: Tony Arcieri 
@_subject: [Cryptography] Washington Post: Google racing to encrypt links 
Probably line rate and the cost of encrypting every single fiber link.
There are few vendors who sell line rate encryption for 10Gbps+

@_date: 2013-09-07 15:40:08
@_author: Tony Arcieri 
@_subject: [Cryptography] Why prefer symmetric crypto over public key 
Lattice-based (NTRU) or code-based (McEliece/McBits) public key systems are
still considered "post-quantum" algorithms. There are no presently known
quantum algorithms that work against these sorts of systems.
See

@_date: 2013-09-09 11:54:33
@_author: Tony Arcieri 
@_subject: [Cryptography] AES state of the art... 
No. I assume that advice comes from related key attacks on AES, and Bruce
Schneier's blog posts about them:
For some reason people read these blog posts and thought, for whatever
reason, that Schneier recommends AES-128 over AES-256. However, that is not
the case. Here's a relevant page from Schneier's book Cryptography
Engineering in which he recommends AES-256 (or switching to an algorithm
without known attacks):

@_date: 2013-09-09 15:46:42
@_author: Tony Arcieri 
@_subject: [Cryptography] Seed values for NIST curves 
The question is... suitable for what? djb argues it could be used to find a
particularly weak curve, depending on what your goals are:
(originally from

@_date: 2013-09-09 21:10:00
@_author: Tony Arcieri 
@_subject: [Cryptography] What TLS ciphersuites are still OK? 
A lot of people don't like GCM either ;) So we're screwed!
Well, aside from maybe this draft supporting Salsa20:

@_date: 2013-09-10 10:42:56
@_author: Tony Arcieri 
@_subject: [Cryptography] Seed values for NIST curves 
On Tue, Sep 10, 2013 at 3:36 AM, Joachim Str?mbergson <
This is more or less what djb did, sans the politics of an Internet
standards process (others have written IETF-style guidelines for actually
deploying his ciphers)
djb's rationale for Curve25519's parameters are provided in the paper. The
2^255-19 constant was selected by a theorem (see Theorem 2.1):

@_date: 2013-09-11 17:06:00
@_author: Tony Arcieri 
@_subject: [Cryptography] Radioactive random numbers 
It seems like Intel's approach of using thermal noise is fairly sound. Is
there any reason why it isn't more widely adopted? Patents?

@_date: 2013-09-12 09:33:34
@_author: Tony Arcieri 
@_subject: [Cryptography] Perfection versus Forward Secrecy 
What's really bothered me about the phrase "perfect forward secrecy" is
it's being applied to public key algorithms we know will be broken as soon
as a large quantum computer has been built (in e.g. a decade or two).
Meanwhile people seem to think that it's some sort of technique that will
render messages unbreakable forever.

@_date: 2013-09-14 11:49:50
@_author: Tony Arcieri 
@_subject: [Cryptography] Perfection versus Forward Secrecy 
I don't think the spooks are ahead of the public either, and I really doubt
the NSA has a large quantum computer.
We still haven't seen quantum computers built yet which can truly rival
their conventional electronic brethren, especially if you look at it from a
cost perspective. DWave computers are interesting from a novelty
perspective, but not really ready to replace existing computers, even for
highly specialized tasks like running Shor's algorithm.
Nevertheless, if you've been following the trends in quantum computers over
the last few years, they are getting larger, and DWave is an example of
them moving out of the labs and turning into something you can buy.
I wouldn't be surprised to see a large quantum computer built in the next
two decades.

@_date: 2013-09-14 12:42:22
@_author: Tony Arcieri 
@_subject: [Cryptography] Quantum Computers for Shor's Algorithm (was Re: 
There was some controversy about that a few months ago. In the end, my
understanding is it netted out that it *is* a real (albeit limited) quantum
Sure, I never said it could ;) I also said that conventional computers can
still outpace it. I'm certainly NOT saying, that in their present capacity,
that DWave computers are any sort of threat to modern cryptography.
But still, it goes to show that quantum computers are happening. Now it's
just a question of whether a large computer capable of running Shor's
algorithm is actually on the horizon, or if it falls into a category like
nuclear fusion where work on it drags on indefinitely.

@_date: 2013-09-14 17:30:00
@_author: Tony Arcieri 
@_subject: [Cryptography] Security is a total system problem (was Re: 
Yes, even airgapping keys within an organization scales poorly (I say this
as an employee of a company that has built a high availability encryption
service around HSMs). While USB drives are certainly large enough to store
huge pads, the fact remains that OTP is only better than other systems if
we can keep the keys off the wire. This means that we need a sneakernet to
move keys around.
The payments industry in the US has done this somewhat successfully. They
do things like shipping fragments of the keys through different shipping
companies, having the recipient reassemble them at their end. Even then
it's difficult to know if they've been intercepted: you can encrypt them,
and put the drives in tamper evident bags, but at least the latter can be
Obviously the Public Key Infrastructure scales a lot better than this

@_date: 2013-09-14 21:17:31
@_author: Tony Arcieri 
@_subject: [Cryptography] Why prefer symmetric crypto over public key 
Why? We already have NTRU. We also have Lamport Signatures. djb is working
on McBits. I'd say there's already many options on the table if you want to
build a "quantum-proof" system.

@_date: 2013-09-16 15:40:29
@_author: Tony Arcieri 
@_subject: [Cryptography] The paranoid approach to crypto-plumbing 
I wish there was a term for this sort of design in encryption systems
beyond just "defense in depth". AFAICT there is not such a term.
How about the Failsafe Principle? ;)

@_date: 2013-09-17 10:07:38
@_author: Tony Arcieri 
@_subject: [Cryptography] paranoid cryptoplumbing is a probably not 
If your threat is a patient eavesdropper (particularly one that obsessively
archives traffic like the NSA) then combining ciphers can give you long
term confidentiality even in the event one of your encryption primitives is
The NSA of course participated in active attacks too, but it seems their
main MO was passive traffic collection.
But yes, endpoint security is weak, and an active attacker would probably
choose that approach over trying to break particular algorithms.

@_date: 2013-09-17 14:08:03
@_author: Tony Arcieri 
@_subject: [Cryptography] paranoid cryptoplumbing is a probably not 
As a counterpoint to what I was saying earlier, here's a tool that's likely
focusing on the wrong problems:

@_date: 2013-09-30 15:41:53
@_author: Tony Arcieri 
@_subject: [Cryptography] TLS2 
What about tools that want to comprehend it using something other than C
The theoretical argument against something like this is the resulting C
code is a "weird machine", i.e. ASN.1 cannot be understood by a pushdown
automaton or described by a context-free grammar.
See:

@_date: 2013-09-30 17:48:06
@_author: Tony Arcieri 
@_subject: [Cryptography] encoding formats should not be committee'ized 
Here's a crazy idea: instead of using one of these formats, use a human
readable format that can be described by a formal grammar which is
hopefully regular, context-free, or context-sensitive in a limited manner

@_date: 2013-09-30 18:14:33
@_author: Tony Arcieri 
@_subject: [Cryptography] encoding formats should not be committee'ized 
YAML is a bit insane ;) There's JSON, and also TOML:

@_date: 2014-04-15 11:35:19
@_author: Tony Arcieri 
@_subject: [Cryptography] Is it time for a revolution to replace TLS? 
Probably not going to happen, but it's nice to dream...

@_date: 2014-04-15 15:30:02
@_author: Tony Arcieri 
@_subject: [Cryptography] I don't get it. 
The best "code checkers" are these things called "compilers". In a good
programming language, it should be possible to statically assert your code
is free of memory safety errors.
A language which is easily interoperable with C which can do this is Rust:

@_date: 2014-04-16 11:52:55
@_author: Tony Arcieri 
@_subject: [Cryptography] Is it time for a revolution to replace TLS? 
Have you actually read the LANGSEC paper and the attacks on ASN.1 they

@_date: 2014-04-18 10:22:19
@_author: Tony Arcieri 
@_subject: [Cryptography] Is it time for a revolution to replace TLS? 
I have thought about suggesting a CAESAR-like competition here, but it's a
vast area that should, IMO, be broken down into smaller, independent,
interoperable parts.
We have at least 4 contests here, I think:
1) Better transport encryption (Tcpcrypt is already tackling this)
2) Better key exchange (Tcpcrypt is also tackling this)
3) A better certificate format
4) A better system for authenticating/revoking keys (e.g. Convergence,
Tack, CT)

@_date: 2014-04-23 14:26:36
@_author: Tony Arcieri 
@_subject: [Cryptography] Is it time for a revolution to replace TLS? 
Sure, we have AES-NI, and aside from silly things like Biclique attacks and
related key attacks (which should be mitigated by a good key agreement
protocol) AES is free of dangerous confidentiality-breaking cryptanalysis.
So yes, AES, definitely, and preferably an authenticated mode of AES like
SHOULD support the other AES finalists with open licenses (Twofish, MARS
Why bother? Few people use these ciphers and with AES-NI there's no reason
to. We should look to more modern authenticated ciphers like the CAESAR
finalists and things like ChaCha20/Poly1305.
There are also these papers, linked from the OP:
   - Modular Security Proofs for Key
   - Security Analysis of KEA Authenticated Key Exchange
   - Stronger Security of Authenticated Key
   - Anonymity and one-way authentication in key exchange
Can we get rid of certificates instead?
For practical reasons I don't think so, but this deserves more discussion.

@_date: 2014-04-23 15:21:45
@_author: Tony Arcieri 
@_subject: [Cryptography] [ANN] RbNaCl 3.0.0: a modern cryptography library 
Sidebar: Check out my talk Being Boring - A Survivor's Guide to Ruby
Cryptography (describes RbNaCl): RbNaCl is a Ruby FFI binding to the Networking and Cryptography Library by
Dan Bernstein and his collaborators:
Version 3.0 includes a new "SimpleBox" API designed to be the most
straightforward API for cryptography possible. It automatically uses a
random nonce per message (using libsodium's randombytes implementation
which pulls from /dev/urandom on *IX and CryptGenRandom on Windows).
Simplebox is usable for both public-key and secret-key cryptography:
Full list of changes from 2.0 below:
* Rename RandomNonceBox to SimpleBox (backwards compatibility preserved)
* Reverse documented order of SimpleBox/RandomNonceBox initialize
parameters. Technically backwards compatible, but confusing.
* Ensure all strings are ASCII-8BIT/BINARY encoding prior to use

@_date: 2014-04-25 09:28:47
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] Is it time for a revolution to 
There's an entire class of memory safety bugs which are possible in C but
not possible in Rust. These also happen to be the class of bugs that lead
to Heartbleed-like secret leakage or remote code execution vulnerabilities.
The problem is very much the language. C has too many sharp edges to write
crypto code safely.
Heartbleed has also done a great job of illustrating that all the band-aids
they try to put on these sharp edges are also flawed.

@_date: 2014-08-01 09:51:22
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] Browser JS (client side) crypto 
[0] old figures.  It used to be that around 1% of the websites used
[0] Citation needed
Modern CPUs have crypto accelerators (e.g. AES-NI). https is cheaper than
ever before.
The alternative is, what, everyone handroll their own JS crypto that only
protects against passive attacks and easily folds when confronted with an
active attacker?
The fact that *you might be able to reach that high bar* is irrelevant.
Since things like FireSheep made people aware of the use of unencrypted
communications is dangerous, HTTPS has seen a massive proliferation in
usage. Certain CDNs are contemplating making HTTPS a part of the base
package rather than an add-on.
So no, HTTPS cost and usage aren't problems. HTTPS is cheaper than ever to
deploy and that trend will continue. The problem is people making silly
excuses not to deploy HTTPS.
I thought we were talking about passive attacks
If you load some crypto JS over plaintext HTTP, a passive attacker can see
you're doing this, and words like "crypto" might be interesting to their
keyword analysis systems.
HTTPS would prevent this.
So is ROT13

@_date: 2014-08-01 10:16:51
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] Browser JS (client side) crypto 
It's already happening in the form of the WebCrypto API

@_date: 2014-08-04 17:08:05
@_author: Tony Arcieri 
@_subject: [Cryptography] "The Visual Microphone: Passive Recovery of 
In other news: if you take a photograph or video recording while naked,
make sure there aren't any mirrors in shot reflecting your naked body back
at the camera.

@_date: 2014-08-11 18:27:23
@_author: Tony Arcieri 
@_subject: [Cryptography] Dumb question -> 3AES? 
If that's all you're worried about, you can relax. keylength.com estimates
(in broad strokes) that becoming a problem for AES-256 around the year 2200.
You should be much more worried about a cryptanalysis of AES. AES is not
proven secure, but rather relies on the fact that nobody presently knows
how to break AES for security.
As Natanael said, you could combine AES and some other cipher for added
security. Two stream ciphers can be combined into a product cipher which is
provably at least as strong as the strongest of the two.

@_date: 2014-08-17 14:49:48
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] Question About Best Practices for 
There aren't known backdoors in FileVault2, or for that mater, Microsoft's
Bitlocker. Apple, on the other hand, has been pretty forthcoming with law
enforcement backdoors in iPhones (which, actually, seem fairly reasonable,
Don't trust their encrypted filesystem? You better not trust the OS either,
for that surely has access to all of the encryption keys you've ever put in
main memory.
tl;dr: if you don't trust proprietary encrypted filesystems, you better not
trust the proprietary OSes they're built into either.

@_date: 2014-08-18 21:29:38
@_author: Tony Arcieri 
@_subject: [Cryptography] STARTTLS for HTTP 
Anyone know why this hasn't gained adoption?
I've been watching various efforts at widespread opportunistic encryption,
like TCPINC and STARTTLS in SMTP. It's made me wonder why it isn't used for
Opportunistic encryption could be completely transparent. We don't need any
external facing UI changes for users (although perhaps plaintext HTTP on
port 80 could show a broken lock). Instead, if the server and client
mutually support it, TLS with an unauthenticated key exchange is used.
It seems most modern web browsers and web servers are built with TLS
support. Why not always flip it on if it's available on both sides, even if
it's trivially MitMed?

@_date: 2014-08-31 13:18:48
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] STARTTLS for HTTP 
In this model, we have a mode for unauthenticated encryption where an
unverified cert is OK. It probably shouldn't reflect anything to the user
and give the same "white" bar as normal plaintext HTTP. But it does add
resilience against passive, blanket surveillance.
https certificate verification UX "research" (since the warnings given to
users seem to constantly be in flux) can continue as-is and unabated by the
addition of STARTTLS for HTTP. It should be completely transparent (except
to the passive surveillers)

@_date: 2014-08-31 19:17:23
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] STARTTLS for HTTP 
There have been many, many comments about how plaintext HTTP is actually
better than STARTTLS. I hope, those of you who made these comments, really
pause and consider how they reflect on you.
Comments like this:
"Generally speaking, nobody uses STARTTLS for HTTP, mostly because it is *less
This comment was made by Tom Leek:
I don't think Tom Leek understands that, if STARTTLS is enabled for HTTP
users in a purely transparent manner, and doesn't affect the perceived UX,
then his complaints are completely irrelevant, and there are positive steps
in the direction of privacy.

@_date: 2014-12-03 11:00:28
@_author: Tony Arcieri 
@_subject: [Cryptography] Why Alexander Hanff won't be using "Let's 
This is a silly argument. It presumes Let's Encrypt is going to have a
bigger problem with misissuance than commercial CAs. Turns out that
commercial CAs are good at misissuing certificates too.
Whether or not misissuance will be a big problem with Let's Encrypt remains
to be seen, but it's always been a problem with the CA system, and Let's
Encrypt probably isn't going to change that. Can they do any worse than,
say, DigiNotar?

@_date: 2014-12-04 09:28:22
@_author: Tony Arcieri 
@_subject: [Cryptography] Toxic Combination 
There's nothing new in your system, and a lot of orthogonal concerns which
are unrelated and complicate the discussion.
ad a) the user agent (yes: browser) manages the cryptographic operations
This is how the web works today.
ad b) the site operator has a few extra steps to take:
Having each site run an intermediary server CA accomplishes nothing if you
decide to trust it using DNSSEC/DANE.
You want to preserve privacy, but you recommend DNSSEC and DANE over X.509?
DNSSEC is not encrypted, it only provides authentication, so you're already
worse off from a privacy perspective.
DNSSEC keys are held by governments, so you can't prevent a government
holding a key higher up the hierarchy from impersonating you (e.g. if you
have a *.com domain, the NSA probably has a way to MitM it)
DNSSEC has no solution to these problems on the horizon: where a lot of
effort has gone into building an X.509 transparency system (Certificate
Transparency), no work (to my knowledge) has gone into building one for
Don't get me wrong, there are aspects of DNSSEC I like, but it doesn't
solve any of the problems you described and is in fact arguably worse at
all of them given your requirements.
Furthermore, all of this is orthogonal to user authentication: you've
muddled up the problems of authenticating the user and authenticating the
 - sign client certificates;
This can be done today using the HTML  tag to generate a client
certificate. A CSR is sent to the server, which can sign it under its own
client CA, and send the signed certificate back to your browser for
Unfortunately, there's one problem: the user experience! All of the
technical problems are solved, but it's still a terribly confusing process
for users.
Everything you've described can be built and deployed today without any
changes to (most) browsers. But the user experience is so bad and confusing
that nobody will use it:
- Different browsers have different trust stores
- Users have to pick which certificate to use to authenticate
- Users have to copy certificates from browser-to-browser or
- Users need to back up certificates so they don't lose them
- Users need some way to recover their account if they do lose the
Fixing the user experience problem is where systems like FIDO alliance
U2F/UAF come in:
- Hardware tokens generate and statelessly manage user credentials
- Credentials follow the same-origin policy and are thus privacy-preserving
(unique credential per origin)
- Support for U2F hardware tokens shipped in the latest releases of Chrome
and will be present in Windows 10

@_date: 2014-12-07 00:37:19
@_author: Tony Arcieri 
@_subject: [Cryptography] Toxic Combination 
Why not get rid of the password part while we're at it? Passwords suck

@_date: 2014-12-15 17:37:46
@_author: Tony Arcieri 
@_subject: [Cryptography] Any opinions on keybase.io? 
Keybase speaks to how terrible and unusable the existing SKS keyserver
system is.
However, they're trying to raise the usability bar, but the first thing you
have to do is install Node.js and run a bunch of crap from the command line.
How is that going to help Johnny encrypt?
Justin Troutman just wrote a really interesting article about this: if we
really want to help Johnny encrypt, we need to fix the tools that he is
already using, not make crypto-centric solutions, and certainly not
requiring Johnny to do anything on the command line:
Ideally encryption should be transparent to Johnny, and something Johnny's
email provider can flip on transparent to him (unless he actually wants to
knuckle down and dig into the crypto-details of what's going on behind the
Beyond that I second the philosophical objections to centralization and
Keybase's proprietary nature: whatever replaces the SKS system should be
openly federated and open source.

@_date: 2014-12-16 17:15:16
@_author: Tony Arcieri 
@_subject: [Cryptography] Any opinions on keybase.io? 
Please see the work Google E2E is doing:
Google is collaborating with Yahoo to ensure their implementations are
Do note that that article does not give any actual solutions for people who
Google proposed a CT-like transparency protocol which would help users
identify if their directory misadvertized their keys:
Making users responsible for their own key management is a great security
practice, and key management forms a huge part of my day job, but asking
Johnny to manage his own keys doesn't help Johnny encrypt.

@_date: 2014-12-17 00:18:50
@_author: Tony Arcieri 
@_subject: [Cryptography] Any opinions on keybase.io? 
The "revolutionary" part is that if the end-to-end extension is written
correctly, transparently, and in an open-source manner, if Johnny's
provider does this, it will notify Johnny

@_date: 2014-12-17 09:26:26
@_author: Tony Arcieri 
@_subject: [Cryptography] Google E2E (was: Any opinions on keybase.io?) 
In an E2E-like system, Johnny's computer stores the private key, not the
provider. The threat which would circumvent the encryption is a MitM attack
perpetrated by the key-directory-who-is-also-his-email-provider.
If we want to detect this attack without Johnny having to know about keys,
we need a way that Johnny's agent can detect that the directory is
misadvertising his public key to others without forcing Johnny to go
through a key verification process with the people he's communicating with.
I agree it would be bad if we had to trust Google or Yahoo, but in this
capacity they're not acting much different from an SKS keyserver. The only
differences would be we select which keyserver to use to obtain Johnny's
public key based on Johnny's email address, and Johnny has to authenticate
so his agent can manage his public key automatically on his behalf.
Okay, new thread created!
A MitM attack is the only failure mode of this system. Until it happens,
Johnny doesn't have to concern himself with the encryption.
When it happens, the system (or rather, Johnny's agent auditing public logs
and gossiping via encrypted email messages) tries to detect it and inform
Johnny . Whether this is useful information to Johnny remains to be seen...

@_date: 2014-12-18 11:17:14
@_author: Tony Arcieri 
@_subject: [Cryptography] Any opinions on keybase.io? 
People have already said this is OT for this thread, perhaps you can talk
on the other one.
Once turned on, if the system works, Johnny's provider shouldn't be able to
disable the encryption without the extension notifying Johnny.
The tools that encrypt transparently (iMessage, WhatsApp) aren't quite
there yet, but they potentially could be.
Tony Arcieri

@_date: 2014-12-26 00:03:04
@_author: Tony Arcieri 
@_subject: [Cryptography] Certificates and PKI 
I was a fan of opportunistic encryption for awhile, but after seeing this,
it started to seem pretty silly to me:
So FUD about CAs aside, without some form of authentication, ISPs (or
anyone with a privileged network position) can and *are* automatically and
trivially stripping opportunistic encryption, rendering it effectively

@_date: 2014-12-27 12:49:33
@_author: Tony Arcieri 
@_subject: [Cryptography] Certificates and PKI 
Every IETF draft I've read on the matter describes it as opportunistic
encryption, so I think you're the one that's confused

@_date: 2014-12-27 13:17:56
@_author: Tony Arcieri 
@_subject: [Cryptography] Certificates and PKI 
I'm confused what point you're trying to make. Everything I read there
corroborates the definition I was using, specifically "fallback to
unencrypted communications".
See also:

@_date: 2014-12-28 13:04:08
@_author: Tony Arcieri 
@_subject: [Cryptography] Certificates and PKI 
Except I was talking about opportunistic encryption...

@_date: 2014-02-03 23:19:14
@_author: Tony Arcieri 
@_subject: [Cryptography] Random numbers only once 
The /dev/random vs /dev/urandom distinction is probably a mistake. Also
making these things files in /dev is also probably a mistake. Ideally there
would just be a system call to obtain some randomness from the kernel, then
an awful lot of work to ensure that randomness is good. It shouldn't block.

@_date: 2014-02-17 18:28:11
@_author: Tony Arcieri 
@_subject: [Cryptography] Encodings for crypto 
If you're interested in this sort of thing, you should have a look at JSON
Web Encryption:
...although I can't say I'm really a fan. It seems ugly to me.

@_date: 2014-01-20 16:03:48
@_author: Tony Arcieri 
@_subject: [Cryptography] HSM's 
Just want to say I love  multisignature trust, because it completely
decentralizes the problem and no one machine ever has to reassemble a
master secret.

@_date: 2014-01-21 13:11:52
@_author: Tony Arcieri 
@_subject: [Cryptography] Does PGP use sign-then-encrypt or 
Wouldn't it make the most sense to sign-then-encrypt-then-MAC (with the
latter ideally handled by an authenticated encryption mechanism)?
What's the value in being able to verify a signature without decrypting? It
seems like if you can do that then anyone can tie a signature to a
particular message even if they can't decrypt it, which seems like a
drawback to me.

@_date: 2014-01-21 14:13:40
@_author: Tony Arcieri 
@_subject: [Cryptography] Does PGP use sign-then-encrypt or 
Using a symmetric MAC would accomplish the same thing, and can be combined
with public key cryptography using (EC)IES-style schemes. This is, IMO, the
best way to go, and the sort of scheme used by e.g. NaCl's crypto_box
I am distinguishing MACs from "signatures", as at least in my nomenclature
digital signature systems are an inherently pubkey system. There are also
"signcryption" systems that combine public key cryptography with digital
signatures, such as RSA-PSSR (although these schemes are somewhat limited
in their usefulness, IMO)
The purpose of using a digital signature in addition to a symmetric MAC is
identity verification of the sender.

@_date: 2014-01-21 16:01:30
@_author: Tony Arcieri 
@_subject: [Cryptography] Does PGP use sign-then-encrypt or 
Yes, I'm aware of Lamport/Merkle signatures. However these systems still
use public and private keys, even if they're composed of symmetric

@_date: 2014-07-01 17:31:30
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] Stealthy Dopant-Level Hardware 
This went to the cypherpunks list, but not to the others:
Reversing stealthy dopant level trojans!

@_date: 2014-07-19 14:37:28
@_author: Tony Arcieri 
@_subject: [Cryptography] hard to trust all those root CAs 
If only X.509 name constraints actually worked.
Perhaps if the implementations could get fixed / finished, it would be
possible to get the browser vendors to agree to put them in place for
select new TLDs.

@_date: 2014-07-26 13:15:39
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] Browser JS (client side) crypto 
What's in the Matasano article is common sense advice. It may seem
elementary for some. But you'd be surprised how many sites fit the pattern
the Matasano post describes, arguing that they can provide *better*
security by serving JavaScript crypto code over easily-MitMed plaintext
Here are a couple offenders...
 Google search result for "encrypted chat":
Not popular by Google results, but a similarly silly effort:

@_date: 2014-07-29 23:09:20
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] Browser JS (client side) crypto 
By default you aren't using HTTPS, HSTS, and CSP. Without these things,
doing cryptography in a web page is most definitely harmful and insecure.

@_date: 2014-07-31 09:47:45
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] Browser JS (client side) crypto 
Sure, passive data collection is a big problem too, but these systems offer
"security" when they aren't being attacked. It's trivial for anyone with a
privileged network position (e.g. your barista) to attack them.
Simply using https:// would prevent many active attacks. It isn't a lot of
effort to implement... certainly a lot less than hand rolling a bunch of JS
Some of these sites are arguing that they're *more* secure by *not* using
https o_O

@_date: 2014-06-09 11:17:41
@_author: Tony Arcieri 
@_subject: [Cryptography] Aggregate signatures 
So you have M signers and N verifiers, where M>=1000000?
What are the verifiers going to do in this context? Do they want to verify
that any one given key was one of the M used to sign the original message?
Do they want to know if a dozen were used? Or all million?
Who authenticates these keys? How are they disseminated?

@_date: 2014-06-12 16:53:08
@_author: Tony Arcieri 
@_subject: [Cryptography] Languages, 
I'm having trouble finding any information on it besides this, but it seems
when it comes to multithreaded programming, data races and other types of
memory corruption that can result from concurrent modifications are still
entirely possible:
I find it somewhat odd that in a language being newly released in 2014,
there's little information or emphasis on its multithread/multicore
I'd contrast this with another language that emphasizes safety, Rust, which
uses an advanced region typing system (a.k.a. "the borrow checker") to
ensure concurrent programs are free of data races, even when using mutable
state. This makes Rust safe in ways ("concurrency safe"?) that Swift is not.

@_date: 2014-06-12 18:08:41
@_author: Tony Arcieri 
@_subject: [Cryptography] Languages, 
Go still shares state between goroutines and is still just as susceptible
to data races as any other language which bolts on CSP or actors as an
afterthought. They have at least started shipping a race detector, but this
will only detect data races when they manifest (which is often at the worst
times, e.g. in production and under unusual load), as opposed to Rust,
which leverages the type system to ensure it's impossible to share state
I think there's a bit of a misconception that Go has separate heaps per
goroutine or something of that nature ala Erlang, but this isn't the case,
it has a single flat shared heap and sending a value over a channel just
shares a reference to the same data between two potentially racy goroutines.
It's described on Wikipedia here:
I'd also note that Rust also implements CSP and has tasks/channels,
although Rust supports both synchronous and asynchronous channels (whereas
Go only supports synchronous channels) and Rust also supports both 1:1 and
M:N tasks:threads (which you can mix and match in the same program using
the same API), whereas Go only supports M:N tasks (i.e. goroutines)
Anyway, I apologize if I'm dragging the list further off topic ;) I just
wanted to make it clear that Go is not a "concurrency safe" language in the
same way Rust is. CSP alone is not a silver bullet.
Tony Arcieri

@_date: 2014-06-12 19:56:53
@_author: Tony Arcieri 
@_subject: [Cryptography] End-to-End, One-to-Many, Encryption Question 
I don't know about "well-debugged", but there is at least a library (with a
somewhat odd license covering its patents):

@_date: 2014-06-16 16:46:11
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] Dual EC backdoor was patented by 
Everyone who objected to the Clipper chip, an example of the public
successfully pushing back against NSA backdoors.

@_date: 2014-06-25 14:45:03
@_author: Tony Arcieri 
@_subject: [Cryptography] a question on consensus over algorithmic agility 
I think it makes sense to provide a "backup" cipher in the event that it
can be used to work around things like protocol bugs. This happened when
BEAST was discovered. We can try to hope that next generation protocols
won't suffer BEAST-style design flaws since they're built on authenticated
encryption, but having a backup cipher makes sense.
That said, I think the assemble-your-own-ciphersuite approach has totally
failed. We wind up with ciphersuites that look like:
Taken from:
...and this isn't even the even more complex "backwards compatible"
A much simpler approach might be to create "one ciphersuite to rule them
all" that's versioned with a major number. We could choose something like
this for ciphersuite 0:
0.0: chacha20poly1305
0.1: aes-256-gcm
0.2: aes-128-gcm

@_date: 2014-06-27 10:03:54
@_author: Tony Arcieri 
@_subject: [Cryptography] "Perfect Forward Secrecy - The Next Step in Data 
"That's why Symantec is continuing to innovate with Perfect Forward
Secrecy?SSL certificates that feature ECC."
That's... not... perfect... forward... whaaaaaaa
ECDSA certs != ECDHE, which works fine with RSA certs >_<
So to answer your question, we know from the "abstract" the chance is about

@_date: 2014-03-04 14:26:41
@_author: Tony Arcieri 
@_subject: [Cryptography] GnuTLS -- time to look at the diff. 
Time to look at the diff indeed... it's hilarious ;)

@_date: 2014-03-05 15:24:26
@_author: Tony Arcieri 
@_subject: [Cryptography] GnuTLS -- time to look at the diff. 
People are writing this stuff in crappy, memory unsafe languages. Maybe
that's the thing that needs to be reconsidered.

@_date: 2014-03-05 15:36:36
@_author: Tony Arcieri 
@_subject: [Cryptography] XKCD on rubber-hose crypto 
It does describe rubber-hose cryptography, but in XKCD's typical fashion it
doesn't reference the existing name and the animator presents it in a
vacuum, to the point that people don't use the term "rubber-hose crypto",
it's "XKCD wrench crypto"
That slightly annoys me. That's all.

@_date: 2014-03-07 18:28:40
@_author: Tony Arcieri 
@_subject: [Cryptography] GnuTLS -- time to look at the diff. 
This is not only some of the worst security advice I've ever heard, but a
painful false dichotomy.
There are memory safe languages that interoperate just fine with C, like
Rust, which would eliminate the entire class of errors we've seen behind
the recent TLS stack breakage. Beyond Rust's memory safety, it does things
like mandate braces around if statements (which would've prevented "goto
fail"), and has proper boolean types natively as well as an Option type
which would eliminate the sort of confusion around return values which lead
to the GnuTLS (a bad pattern seen in OpenSSL as
Last but not least, Rust knows how to automatically deallocate memory and
call destructors, so it doesn't have or need a goto statement for this sort
of stuff.
TLS is worthless unless we have the closest thing to a bug-free library
possible. C is not getting us there.

@_date: 2014-03-11 15:17:13
@_author: Tony Arcieri 
@_subject: [Cryptography] GnuTLS -- time to look at the diff. 
Rust's compiler is written in Rust. Prior to that it was written in OCaml

@_date: 2014-03-17 21:35:56
@_author: Tony Arcieri 
@_subject: [Cryptography] We need a new encryption algorithm competition. 
AES-GCM is arguably good enough. I wish more effort were invested in
creating a new, modern TLS stack that isn't completely terrible, or
creating a protocol to replace TLS which is built atop CAESAR-style
authenticated stream ciphers.
If I were to try to create a crypto contest, its goal would be to create a
better transport encryption protocol.
Tony Arcieri

@_date: 2014-03-18 15:50:45
@_author: Tony Arcieri 
@_subject: [Cryptography] We need a new encryption algorithm competition. 
Well first, the CurveCP implementation isn't usable. It's not really a
library so much as external programs you can talk to which handle the
Another part of the problem is CurveCP is built on UDP. I'm not really sure
why it's built on UDP as djb classes TCP Vegas decongestion as "good":
UDP is often dropped on the floor amidst TCP congestion, as this
experimental measurement of CurveCP demonstrates:
See chart on Page 15, "CurveCP bandwidth with competing TCP traffic
CurveZMQ has reimplemented CurveCP on top of TCP, but it has been
special-cased for the 0MQ protocol:
Then there's MinimaLT:

@_date: 2014-03-18 16:09:29
@_author: Tony Arcieri 
@_subject: [Cryptography] We need a new encryption algorithm competition. 
Flood the weakest link with TCP traffic, and it will drop your UDP packets
on the floor.
Does this instill confidence in the protocol's availability?

@_date: 2014-03-23 11:20:07
@_author: Tony Arcieri 
@_subject: [Cryptography] BLAKE2: "Harder, Better, Faster, 
The original BLAKE was a SHA3 finalist. You can at least point to that.

@_date: 2014-03-31 17:43:04
@_author: Tony Arcieri 
@_subject: [Cryptography] ideas for (long) Nothing up my sleeve numbers 
When it comes to "nothing up my sleeve numbers", boring is good

@_date: 2014-05-04 15:54:59
@_author: Tony Arcieri 
@_subject: [Cryptography] Announcing ClearCrypt: a new transport encryption 
ClearCrypt's goal is to produce a minimalist transport encryption library
written in a memory-safe language: Rust.
Web site: The problem: Github repo: The project is presently complete vaporware, but the goal is to produce a
Rust implementation of a next generation transport encryption library. The
protocol itself is still up for debate, but will likely be based off
CurveCP or Noise.
Emphasis will be placed on simplicity, clarity, and audibility. New
features will be rejected unless they meet these goals. Every commit will
be approved by multiple people once it has been thoroughly audited.
First up: the choice of a license:

@_date: 2014-05-06 20:56:15
@_author: Tony Arcieri 
@_subject: [Cryptography] Best practices for paranoid secret buffers 
Can anyone point me at some best practices for implementing buffer types
for storing secrets?
There are the general coding rules at cryptocoding.net for example, that
say you should use unsigned bytes and zero memory when you're done, but I'm
more curious about specific strategies, like:
- malloc/free + separate process for crypto
- malloc/free + mlock/munlock + "secure zeroing"
- mmap/munmap (+ mlock/munlock)
Should finalizers be explicit or implicit? (or should an implicit finalizer
try to make sure buffers are finalized if you don't do it yourself?)
Are paranoid buffers worth the effort? Are the threats they'd potentially
mitigate realistic? Are there too many other things that can go wrong (e.g.
rewindable VMs) for this to matter?
Tony Arcieri

@_date: 2014-05-15 09:20:00
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] Is it time for a revolution to 
Does that mean that JSON was more than 10% better than XML, or REST more
than 10% better than SOAP?
That's not to say that "enterprise" users don't still make extensive use of
the, for lack of a better term, crappier technologies, but for the rest of
us, we hopefully don't have those monstrosities in our daily lives anymore.

@_date: 2014-05-19 11:06:40
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] Is it time for a revolution to 
Rails started by only allowing the entire page to be calculated first
before writing it to the wire. This had the unfortunate problem that the
server could not emit the page header prior to working on the body, so the
browser was prevented from fetching scripts and stylesheets in parallel as
the page was calculated.
That's not to say this doesn't fit your suggested messaging/datagram model,
just that producing the page header (at the very least) prior to the rest
of the page confers some performance advantages.

@_date: 2014-05-21 18:45:51
@_author: Tony Arcieri 
@_subject: [Cryptography] How secure are hashed passwords? 
Previous breaches have given us a lot of data about how people use
passwords. An awful lot of people are still using extremely weak passwords
like "123456" or "password". No password hashing algorithm that's actually
useful can reasonably defend against these commonly used, weak passwords.

@_date: 2014-05-21 19:18:43
@_author: Tony Arcieri 
@_subject: [Cryptography] New attacks on discrete logs? 
Looking at all the coverage of this paper, I was reminded of this comic:

@_date: 2014-05-22 11:56:24
@_author: Tony Arcieri 
@_subject: [Cryptography] The proper way to hash password files 
That's fine if you keep the key in something like an HSM, but a key
disclosure would be catastrophic as an attacker could use it to brute force
the password database much more easily than if a password hashing function
like bcrypt or scrypt were used. Without a salt to make each brute force
attempt specific to an individual password, a dictionary attack on the key
would allow you to attack the entire password database simultaneously.
Now this seems obvious but I can't recall ever seeing code set up to
Many of the Password Hashing Competition entries included an additional key
parameter, referred to as things like "pepper" or "garlic". The main
concern here was cache timing attacks.
HMAC is nice in that it could be done by an HSM and is relatively trivial.
You could combine an HMAC of the original password, then feeding the HMAC
result into a standard password hashing function. This would help mitigate
brute force searches even if the key were compromised, and would also help
mitigate some more exotic things like cache timing attacks on the password
hashing function.

@_date: 2014-05-26 22:54:32
@_author: Tony Arcieri 
@_subject: [Cryptography] client certificates ... as opposed to password 
You might want to look deeper into existing client certificates:
- The  facilitates easy key generation within a browser
- The public key (CSR) is then sent to the server to be signed, then the
signed key is sent to the browser for installation
- This certificate is then (optionally) used in subsequent requests
That's great... so what's the problem? User experience
Client certificate UX is terrible in all browsers. Worse, it's inconsistent
between browsers. Managing certificates is terrible. Hell, browsers can't
even decide whether or not they should use the system trust store or their
You can claim that the implementation of client certificates is bad. Fine,
I think your scheme (which seems a bit handwavy in the details) looks worse
than what we have today. But that's all moot. The real problem isn't the
implementation, but UX.

@_date: 2014-05-27 09:15:16
@_author: Tony Arcieri 
@_subject: [Cryptography] client certificates ... as opposed to password 
Again, from a technological perspective, the prerequisites are already
The  tag (
 will
generate a key within your browser and submit a CSR as part of an HTML
form. The remote side can then send down a signed cert for local
installation. This all happens through the browser UI... today. No
commercial software needed (although you do need to run a CA on the server
side, have fun there)
Good luck getting anyone to figure out how to go through this workflow, or
for that matter, manage their certificates among multiple browsers or
multiple computers.

@_date: 2014-05-28 14:48:00
@_author: Tony Arcieri 
@_subject: [Cryptography] client certificates ... as opposed to password 
As I've already mentioned, this can be done using the HTML5  tag:

@_date: 2014-10-01 16:28:15
@_author: Tony Arcieri 
@_subject: [Cryptography] Best Internet crypto clock ? 
You could take a hash of some content, use that hash as a Bitcoin private
key, and send the associated public key 1 Satoshi. You could then prove you
calculated that hash at a given time by looking up the associated public
key in the block chain.
Here's something that does just that:

@_date: 2014-10-07 20:45:08
@_author: Tony Arcieri 
@_subject: [Cryptography] Do you think RC4 will become insecure for 2^16 
Is there some legacy reason you really need to support RC4 in this use
case? If not, why not use a modern cipher like ChaCha20 instead?
RC4 is clearly not a good cipher, especially compared to modern
alternatives. Do we really need to take a straw poll of how horribly it
will be broken in the future?

@_date: 2014-10-07 21:41:08
@_author: Tony Arcieri 
@_subject: [Cryptography] Do you think RC4 will become insecure for 2^16 
RC4 should probably be abandoned sooner than later

@_date: 2014-10-08 12:56:17
@_author: Tony Arcieri 
@_subject: [Cryptography] Do you think RC4 will become insecure for 2^16 
It's already broken. ChaCha20 is both faster and more secure.
Stop defending bad crypto.

@_date: 2014-10-08 15:17:01
@_author: Tony Arcieri 
@_subject: [Cryptography] Do you think RC4 will become insecure for 2^16 
libsodium provides a ChaCha20+Poly1305 AEAD construction across a variety
of platforms:

@_date: 2014-10-08 15:26:02
@_author: Tony Arcieri 
@_subject: [Cryptography] SPHINCS: practical hash-based digital signatures 
This is much more interesting for data-at-rest use cases, especially for
what Zooko calls "hundred year cryptography".
Digital signatures are the only public key component of the "data-at-rest"
format of the Tahoe-LAFS distributed filesystem, so if Tahoe changed to
hash-based signatures, it could theoretically survive the advent of quantum
For transport encryption? Probably not ;)

@_date: 2014-09-03 14:15:23
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] STARTTLS for HTTP 
STARTTLS for HTTP isn't for people who currently offer HTTPS content. It's
for people who don't want to pay for an SSL certificate and/or don't have
the time or knowledge to configure them for each and every site.
They could, at a baseline, still provide resistance to passive monitoring
with practically no configuration beyond flipping it on.
It should still identify and operate as if it were http:// from the
browser's perspective, with perhaps a subtle indication to the user that
their connection is slightly more secure, or nothing at all, e.g. plaintext
HTTP could show a broken lock.

@_date: 2014-09-08 19:05:38
@_author: Tony Arcieri 
@_subject: [Cryptography] distributing fingerprints etc. via QR codes etc. 
The main use case I'd like to see is sharing fingerprints (or keys)
phone-to-phone. I recently went to a "keysigning party" (not expecting
much) and left with a ton of paperwork to do, and I hate paperwork.
I really wish I could just snag people's key (fingerprints) in QR code form.

@_date: 2014-09-09 14:24:31
@_author: Tony Arcieri 
@_subject: [Cryptography] "Keybase Attack" on RSA signatures 
Keybase attempts to bind user identities on social media to their PGP keys
by having users publish an RSA signature under an unknown key, which
Keybase refers to as a "proof". The (allegedly) signed message contains a
link to their Keybase identity, but contains no information about their
public key fingerprint.
After clicking on the link in the message we're taken to the Keybase web
site where their alleged public key is listed. We are then asked to verify
this key is authentic by checking if the digital signature in the original
message verifies.
However, is this actually secure? Or more specifically:
Can we produce an RSA keypair such that an existing digital signature will
verify under it if we control both the private and public key?
For the purposes of this problem, let's say it doesn't even need to be a
good / secure RSA key, just one that the "proof" signature verifies under.
I'd also note that, if someone does have a solution to this problem, it
would probably be good to responsibly disclose to Keybase ;)

@_date: 2014-09-09 15:07:24
@_author: Tony Arcieri 
@_subject: [Cryptography] [messaging] "Keybase Attack" on RSA signatures 
Sorry, I must've glossed over this. It would seem to provide an immediate
defense to forging a keypair under which the signature would validate,
however it seems in conjunction with a SHA1 collision that allows the
replacement of the fingerprint in the original message, this could be
potentially problematic.

@_date: 2014-09-09 21:15:17
@_author: Tony Arcieri 
@_subject: [Cryptography] [messaging] "Keybase Attack" on RSA signatures 
The strength of the signature comes from the key. In the case of Keybase,
we don't know we have the right key, and are trying to use the signature to
determine that.
As I've discovered from this thread, the dual-share key-share attack is
able to produce a keypair such that an existing digital signature will
verify under it. If we can confuse the victim into verifying a signature
under an attacker-controlled key, the signature will appear valid even
though it was produced under a different key.
This is necessary but not sufficient for an attack against Keybase however,
since the message being signed contains the key fingerprint, which I wasn't
aware of at the time I started this thread.

@_date: 2014-09-13 16:50:12
@_author: Tony Arcieri 
@_subject: [Cryptography] distributing fingerprints etc. via QR codes etc. 
That's why this would probably work best in conjunction with an app
specifically designed to scan others' public keys / key fingerprints via QR
code, as opposed to using a generic QR code scanner
Still not saying QR codes are a good idea, but surely they're better than
slips of paper ;)

@_date: 2014-09-23 17:05:10
@_author: Tony Arcieri 
@_subject: [Cryptography] NSA versus DES etc.... was: iOS 8 
Lucifer supported a 128-bit key size, and IBM had it deployed for various
commercial purposes using 128-bit keys before DES was standardized.
The NSA originally pushed for a 48-bit key size, when IBM wanted at least
64-bits. They split the difference and used 56-bits, and chalked the 8-bits
between 56-bits and 64-bits up to "checksum bits"

@_date: 2014-09-25 14:05:25
@_author: Tony Arcieri 
@_subject: [Cryptography] The Trouble with Certificate Transparency 
This same class of attack will work on practically any system

@_date: 2014-09-26 19:05:10
@_author: Tony Arcieri 
@_subject: [Cryptography] Informing the user they have the wrong key 
If we build fancy systems to detect things like misadvertised keys or MitM
attacks, how can we reasonably inform an end user what is amiss in an
actionable way that won't confuse them with too many false positives to
avoid taking action when something bad actually happens?
I recently went to SOUPS and saw a number of presentations on the general
difficulty of communicating security-actionable information to users. From
what I saw I'd say the problem is twofold:
1) How does the system provide a high confidence level that when it tries
to communicate a security-actionable event, it's fairly certain it's not a
false positive? False positives condition users to ignore security warnings
2) How do you express what's happening to the user in such a way that they
will actually take action on it and not just click-through dismiss it?
Given the wide-ranging number of scenarios, the answer will of course be
contextual, and I'd be curious to hear any replies about how systems try to
solve the "right key" user experience problem in general.
That said, the messaging use-case (in conjunction with a "key directory"
system) is particularly interesting to me.
If an end-to-end encrypted messaging system which relies on a
centrally-managed key directory (e.g. iMessage) were to by coersion or
compromise publish a poison key to their directory to facilitate a MitM
attack, but the system creators wanted to make such action obvious to their
users, how can the systems reasonably detect and reflect this in such a way
that such users aren't conditioned to ignore such alerts for routine events
(e.g. the SSH "SOMETHING NASTY" message) and actually feel compelled to
take action on that knowledge?
And then what? How can we help someone who is a victim of an attack like
this actually compile all of the necessary information for someone to
figure out what actually happened? How can encryption tools compile
incident reports that experts can scrutinize to determine what happened?

@_date: 2014-09-26 20:07:57
@_author: Tony Arcieri 
@_subject: [Cryptography] The Trouble with Certificate Transparency 
Hi Greg,
You're wrong, and here's why.
In the James Mickens security scale of "Not Mossad" to "Mossad", your
attack falls into the class of "Mossad".
Here's the problem with that: you lose. The end.

@_date: 2014-09-27 09:20:50
@_author: Tony Arcieri 
@_subject: [Cryptography] The Trouble with Certificate Transparency 
All that's necessary for any of these organizations to defeat any of these
systems is to do a QUANTUMINSERT style attack to drop a malicious payload
onto the target system.
The best designed protocols can be easily defeated by 0days / RCE.
Maybe the blockchain can save it, but if it does, people will realize that
You can MitM the block chain just as easily:
1) Alice wants to register the name "alice" with a NameCoin like system.
Mallory wants to MitM her
2) Alice claims the name. Mallory intercepts her claim and produces a
forked, poison block chain that contains the name "alice" with her key.
Mallory registers the name "alice" with a poison key, and puts that in the
"real" block chain
3) Bob tries to communicate with "alice" and looks up the poison data
Mallory left in the block chain
A similar attack that would require a similar level of attacker
Much like with the poison CT Merkle tree, comparing the poisoned block
chain against the real one would expose it. But the attack would've already
happened... so we find ourselves in much the same boat.
But I think that's all silly when we already know how TAO works... endpoint
security is still weak.

@_date: 2014-09-27 11:52:10
@_author: Tony Arcieri 
@_subject: [Cryptography] The Trouble with Certificate Transparency 
This is a *naming* system. Other people are trying to map a name to a key,
not the other way around. Mallory is trying to trick other people who are
trying to talk to alice into using the wrong key, while making it appear to
Alice that the correct key is published.
Meanwhile a MitM can show Alice a forked block chain where her key appears
legitimate, and in the process poison any new entries which are added to
the block chain with MitMed keys.

@_date: 2014-09-27 11:53:01
@_author: Tony Arcieri 
@_subject: [Cryptography] The Trouble with Certificate Transparency 
My understanding is CT would detect the attack when it's over.

@_date: 2014-09-27 12:49:04
@_author: Tony Arcieri 
@_subject: [Cryptography] The Trouble with Certificate Transparency 
You're saying a system based on Merkle trees won't detect incongruences in
the trees?
That's kind of like saying the block chain can't detect a fork

@_date: 2014-09-27 13:43:23
@_author: Tony Arcieri 
@_subject: [Cryptography] The Trouble with Certificate Transparency 
Even after the network partition is resolved and the latest log is seen?
If you allege that's the case, I don't understand your attack.

@_date: 2014-09-27 14:14:23
@_author: Tony Arcieri 
@_subject: [Cryptography] The Trouble with Certificate Transparency 
Nothing you just said has anything to do with the question at hand: what
happens when the latest tree in the log is incongruent with the old one.
I'd allege: CT should detect that and suggest something is amiss.
And, again, it's no different than Namecoin detecting a fork in the block
chain. What does Namecoin do in that case? What actionable information does
it present to the user.

@_date: 2014-09-27 14:53:21
@_author: Tony Arcieri 
@_subject: [Cryptography] The Trouble with Certificate Transparency 
What if a MitM prevents you from ever seeing the longer fork?

@_date: 2014-09-27 14:55:54
@_author: Tony Arcieri 
@_subject: [Cryptography] The Trouble with Certificate Transparency 
Also, you seem to simultaneously be talking about:
   - PoW as a protection for Namecoin
   - Nation State Adversaries
Do you really think that the NSA cant pull off the 51% attack on Namecoin?

@_date: 2015-08-02 10:50:11
@_author: Tony Arcieri 
@_subject: [Cryptography] asymmetric attacks on crypto-protocols - the 
Ok, so I see through your thinly veiled wording to the WG in question ;)
For what it's worth, I got frustrated with this particular group and
stopped participating entirely...

@_date: 2015-08-03 16:44:42
@_author: Tony Arcieri 
@_subject: [Cryptography] More efficient and just as secure to sign 
Exploiting hash collisions in digital signature algorithms have lead to
real-world attacks. See e.g. Flame MD5 collision.

@_date: 2015-08-03 17:52:47
@_author: Tony Arcieri 
@_subject: [Cryptography] More efficient and just as secure to sign 
Your question is a false dichotomy. The "best" answer is "do both".
If we could wave a magic wand and magically upgrade everything that's using
older algorithms, that would clearly be the best solution. But here in the
real world, we don't have magic wands.
Indeed the clients that were exploited by the Flame MD5 collision were
capable of using better algorithms (e.g. SHA1), but since MD5 was
supported, it became the weakest link.

@_date: 2015-08-05 10:51:33
@_author: Tony Arcieri 
@_subject: [Cryptography] SRP for mutual authentication - as an 
FIDO U2F derives origin-specific ECC keys (derived using a hardware token)
which are effectively "unphishable":
It's integrated into Chrome. Support for other browsers has not been
forthcoming though

@_date: 2015-08-11 18:24:35
@_author: Tony Arcieri 
@_subject: [Cryptography] SRP for mutual authentication - as an 
U2F is just a protocol. Your "other devices" could also act as U2F tokens
themselves (e.g. your SmartWatch could act as a U2F token for your
SmartPhone). Or (potentially) something like a Yubikey could provide U2F
over Bluetooth or NFC.
Buy two and keep another as a backup, then revoke the first when you lose
it. But losing credentials is a general problem with any authentication

@_date: 2015-08-13 13:46:28
@_author: Tony Arcieri 
@_subject: [Cryptography] Why is ECC secure? 
It's also important to note that both RSA and ECC use prime numbers
(specifically prime fields in the latter's case). In many ways I think they
can be seen as special cases of a single bigger problem (which I believe is
the hidden subgroup problem, correct me if I'm wrong)
When it comes to cryptanalysis, the real question is the amount of work
that has gone into breaking things like the RSA trapdoor function as
opposed to just "prime numbers" or factoring. Both ECC and RSA use prime
numbers, and the discrete logarithm problem has probably received a similar
amount of study to factoring (and indeed there are spooky similarities
between these problems too).

@_date: 2015-08-27 14:07:27
@_author: Tony Arcieri 
@_subject: [Cryptography] RC4 and SHA2 
Don't use broken crypto.
Note: I do know RC4 is being deprecated so this is purely a theoretical
I don't care. Don't use broken crypto!

@_date: 2015-08-27 14:08:01
@_author: Tony Arcieri 
@_subject: [Cryptography] Is MD4 as secure as Poly1305 in an AEAD scheme? 
Don't use broken crypto.
That's because MD4 is broken. Don't use broken crypto!

@_date: 2015-08-30 16:06:08
@_author: Tony Arcieri 
@_subject: [Cryptography] Using crypto to address clickjacking (was "Re: 
100% agree with this.
There are a few deficiencies with X-Frame-Options which is what Dan
Kaminsky's talk was about.
X-Frame-Options: DENY is the nuclear option to prevent clickjacking. This
prevents content embedding. But what if we want to embed a clickable widget
in another page, but prevent clickjacking?
What's really needed is a way for iframes to reason about how they're being
embedded in other content. This was the actual subject matter of Dan
Kaminsky's talk. He presented a concept called "IronFrame", but more recent
W3C work seems to be around a Position Observer API:
Anyway, no crypto necessary. And that's good: I am all for solving web
security problems *without* crypto!

@_date: 2015-12-02 11:26:43
@_author: Tony Arcieri 
@_subject: [Cryptography] Large companies sued for using Elliptic Curve 
See also the Schnorr signature patent. DSA is something of a hybrid of El
Gamal and Schnorr, and Schnorr insisted DSA violated his patent.
The signature algorithm to be adopted by the CFRG will be a Schnorr variant.

@_date: 2015-12-02 14:09:49
@_author: Tony Arcieri 
@_subject: [Cryptography] Large companies sued for using Elliptic Curve 
EdDSA, a Schnorr variant/derivative, was chosen as the basis of the CFRG
signature algorithm two months ago in this poll (which you didn't
participate in, perhaps hence your confusion):
The remaining questions are around the hash and pre-hash functions, which
will be the subject of an upcoming poll. Otherwise the algorithm is very
much "invented".

@_date: 2015-02-04 15:18:08
@_author: Tony Arcieri 
@_subject: [Cryptography] best practices considered bad term 
Both Dan Bernstein and Kenny Patterson, two of the people who worked on one
of the statistical attacks against RC4, have suggested that their attack
can be further refined to require fewer ciphertexts
I don't even know how packets are arranged when web pages are sent., I do
Cookies are located in the HTTP header at the beginning of the request.
The setup for a practical attack against RC4 is similar to BEAST, CRIME,
BREACH, or POODLE: the attacker has a privileged network position that lets
them passively MitM the victim, and gets the victim to load a malicious
script which makes many, many requests.
If the attacker is driving the victim's browser, they know exactly when
requests start and end.

@_date: 2015-02-10 19:35:05
@_author: Tony Arcieri 
@_subject: [Cryptography] Do capabilities work? Do ACLs work? 
As someone who reasons about ambient authority systems all day, they're
terrible. Exactly as you describe, you end up following chains of nested
relationships, and they come at you from two directions:
- The person: what groups do they belong to?
- The resource: what groups are allowed to do what?
resources with nested ACLs as the indirection mechanism, and if there is
any path through this graph we can follow which connects the two, the
action is authorized. This makes reasoning about authority in complex
systems extremely complicated, to the point that people start building
logic languages to describe constraints around what sort of connections in
these sorts of access control graphs are allowable by policy.
In a properly designed capability system, you should simply be able to ask
what authority a given user has over a given resource. If they have the
capability they have it. If they don't they don't. The entire messy
indirection of ambient authority systems is eliminated.

@_date: 2015-02-11 11:06:00
@_author: Tony Arcieri 
@_subject: [Cryptography] Do capabilities work? Do ACLs work? 
It depends!
Revocability and confinement are two popular topics with capabilities, and
yes, there are many solutions (especially with Macaroons). I suggest
reading Mark Miller's paper "Capability Myths Demolished":
CapTP specifically supported "SturdyRefs" which are opaque (sealed) in
distributed contexts:
Macaroons specifically support "contextual confinement" that can bind them
to mechanisms like TLS channel ID so they aren't transferrable.
Also there's a new IETF working group dedicated to confining bearer tokens:

@_date: 2015-02-11 11:31:12
@_author: Tony Arcieri 
@_subject: [Cryptography] Do capabilities work? Do ACLs work? 
One other important thing to note: capabilities and ACLs aren't a
dichotomy. You can use capabilities to implement ACLs.
As to why capabilities aren't more widely adopted, I think the most
important thing is they're incredibly hard to retrofit. Once you go down
the ambient authority road, turning back is very hard, because adding
capabilities to a system that already implements ambient authority leaves
you in the worst of both worlds.

@_date: 2015-02-11 12:36:36
@_author: Tony Arcieri 
@_subject: [Cryptography] Do capabilities work? Do ACLs work? 
This isn't true at all. You are making it sound like it's impossible to
know who has a given capability because you're imaging some strawman system
that has no confinement or revocation abilities.
I again invite you to read Capability Myths Demolished:

@_date: 2015-02-18 10:58:37
@_author: Tony Arcieri 
@_subject: [Cryptography] Passwords: Perfect, except for being Flawed 
U2F is a protocol. It isn't tied to USB any more than passwords are tied to

@_date: 2015-01-03 14:53:08
@_author: Tony Arcieri 
@_subject: [Cryptography] 
SSH has a generally weaker model (TOFU) than at least a privately
maintained X.509 hierarchy (the answer for a stronger/more agile approach
on the SSH side is X.509-like SSH CAs). Likewise, TOFU handles key agility
There are lots of real world reasons why keys might change. In fact key
agility is a nice property! SSH makes it hard. I'm sure we've all seen the
above warning, been confused about the circumstances, but ignored it.
Then there's the part where you need to respecify every protocol to run
atop SSH instead of TLS.
In terms of overall design, SSH and TLS both failed. SSH did
MAC-and-encrypt. TLS did MAC-then-encrypt. Both of them are effectively
legacy protocols that were designed wrong from the get-go.

@_date: 2015-01-03 22:14:38
@_author: Tony Arcieri 
@_subject: [Cryptography] 
On Sat, Jan 3, 2015 at 8:48 PM, Christoph Anton Mitterer <
It's not because SSH supports an X.509-like CA system
Do you actually verify key fingerprints, and if so, how?

@_date: 2015-01-03 23:03:11
@_author: Tony Arcieri 
@_subject: [Cryptography] 
Used ubiquitously by every single server you ever SSH to? How many is that,
by the way?

@_date: 2015-01-03 23:14:22
@_author: Tony Arcieri 
@_subject: [Cryptography] 
On Sat, Jan 3, 2015 at 10:49 PM, Christoph Anton Mitterer <
You are the vocal minority

@_date: 2015-01-03 23:15:35
@_author: Tony Arcieri 
@_subject: [Cryptography] 
Forgot to add: this process does not sound like it can scale to every user
on the Internet and every service on the Internet, sorry

@_date: 2015-01-04 15:18:45
@_author: Tony Arcieri 
@_subject: [Cryptography] 
On Sun, Jan 4, 2015 at 7:23 AM, Christoph Anton Mitterer <
Yes, I'm sure everyone on this list knows Achmed's Used Cars and
Great in theory, but DNSSEC is terrible in practice
Is that even supported now?

@_date: 2015-01-05 09:41:20
@_author: Tony Arcieri 
@_subject: [Cryptography] Imitation Game: Can Enigma/Tunney be Fixed? 
Enigma is fatally flawed in its current design, AFAIK. Due to the nature of
how its rotors operate, it can't encrypt a letter to itself, introducing a
statistical bias into the ciphertext.
Enigma would need to be modified so all letters have equal probabilities.
Someone who knows the intricacies of these rotor machines better than me
might know what's involved.

@_date: 2015-01-05 17:07:41
@_author: Tony Arcieri 
@_subject: [Cryptography] Imitation Game: Can Hollywood be fixed? 
Here's a quick start:
1) The Bombes were called Bombes. The word "Bombe" is never used throughout
the entire movie
2) The first Bombe was named Victory, not Christopher. AFAIK Turning never
named any machine he developed "Christopher"
3) John Cairncross, the soviet spy, was not on Turing's team. He wasn't
even in Turing's Hut at Bletchley, and it's unlikely they ever interacted.
4) The real Joan Clarke probably knew how to pronounce "Euler" correctly
5) Turing was arrested in 1952, not 1951
6) The real Turing sounds like he was less of an asshole than Benedict
Cumberbatch depicted him to be

@_date: 2015-01-13 18:13:45
@_author: Tony Arcieri 
@_subject: [Cryptography] SSL combines two aspects of communication 
It sounds like you are homebrewing your own version of this:
TLS can automatically generate ephemeral keys for encryption, while only
using the long-lived key for signing the ephemeral keys. This decouples
authentication from encryption, and ensures that every session is protected
by a brand new set of public/private keys.
You will need to use e.g. an ECDHE ciphersuite for this to happen, however
it's been built into TLS for awhile now...

@_date: 2015-07-05 10:47:04
@_author: Tony Arcieri 
@_subject: [Cryptography] Best AES candidate broken 
Cache timing and DPA can be applied to any implementation of any cipher,
Serpent in particular uses S-boxes just like AES (or for that matter,
Lucifer/DES), which makes it just as difficult to implement in software
with secret independent timing (note: you brought up cache timing, so
please don't deflect this argument by changing the subject to hardware)
The real solution to cache timing attacks is to eliminate those
secret-dependent table lookups entirely, as seen in e.g. Salsa20 / ChaCha20.
You might want to take off those rose colored glasses and start paying
attention to modern cryptography. Things have moved on quite a bit since
the 90s.

@_date: 2015-07-06 15:30:00
@_author: Tony Arcieri 
@_subject: [Cryptography] Best AES candidate broken 
I'm not aware of any, and yes, Serpent does make bitslicing easier to
implement than AES. Of course any purely software implementations of AES
attempting to achieve secret independent timings are likely to be using
bitslicing techniques too.
That said, it's still entirely possible to produce naive implementations,
and if they don't exist for Serpent (hard to prove a negative), that's
likely because nobody cared enough to write a crappy version.
I would guess that spending not too much time Googling would turn one up,
but I have better things to do with my time.

@_date: 2015-06-01 10:06:16
@_author: Tony Arcieri 
@_subject: [Cryptography] [FORGED] Re:  Why is ECC secure? 
This is my way of telling you your claims are inconsistent with reality. To
go back to the actual issue, rather than personal attacks:
On Sun, May 31, 2015 at 2:03 PM, Peter Gutmann ECC is widely deployed and used today and has been for over a decade. The
concept is some 30 years old. Montgomery curves are 28 years old.
Curve25519 is 10 years old.
(because currently we have basically none, which is what
This claim is not consistent with reality.

@_date: 2015-06-02 13:00:58
@_author: Tony Arcieri 
@_subject: [Cryptography] Why is ECC secure? 
I'm not sure I really follow what you have in mind, but it sounds somewhat
similar to the baby-step giant-step algorithm?
You can of course do things like this. The problem is the fields and
scalars involved are both astronomically large (i.e. 2^255ish for e.g.
Curve25519), and the complexity of baby-step giant-step is O(sqrt(n)), well
outside the range of a feasible brute-force attack.
If you're thinking of some other attack, what do you think its big O
complexity is?

@_date: 2015-06-07 13:29:52
@_author: Tony Arcieri 
@_subject: [Cryptography] let's kill md5sum! 
Well, not completely broken, but here's an attack that breaks Tiger reduced
to 23 rounds (from 24) with 2^47 complexity:
Tiger is also slower than Blake2b

@_date: 2015-06-08 22:29:53
@_author: Tony Arcieri 
@_subject: [Cryptography] let's kill md5sum! 
Wrong. As the expression goes, "attacks only get better". If Tiger hasn't
been broken yet, it's probably because too few people care, probably
because it's obscure and rarely used.
I wouldn't recommend you use any of those either, but that said, Tiger is
effectively broken at this point and shouldn't be used.
The fact you're recommending it when 23 out of 24 rounds have been broken
is completely ludicrous. That should be a clear sign to run away.
Tony Arcieri

@_date: 2015-06-09 17:58:26
@_author: Tony Arcieri 
@_subject: [Cryptography] Bitcoin sidechains to use Schnorr (was: Open 
So instead of using a standard Schnorr variant with a modern SafeCurve like
Ed25519, they're going to homebrew their own variant of Schnorr with an
elliptic curve that nobody else would choose today?
That doesn't make a whole lot of sense. Changing the signature algorithm
means all clients will need to be updated before people can start using it
regardless of what curve we use. So as long as you're doing that, why not
just use a standard off-the shelf digital signature algorithm like Ed25519
which already has already received a decent amount of cryptanalytic
scrutiny and has multiple robust implementations across a variety of
Doing what they propose would let people keep their old secp256k1-keyed
Bitcoin addresses, at the cost of developing and maintaining their own
signature algorithm which nobody with any sense would use for anything.
Instead of homebrewing their own crypto*, they could switch to an
off-the-shelf solution like Ed25519, and people who want to take advantage
of it can move their Bitcoins to a new Ed25519-secured wallet.
But, let's talk about the real issues:  engineering and deployment. It's
Deploying a new signature algorithm to mainline Bitcoin doesn't seem that
hard to me. I'd recommend this approach:
1) Pick a target date by which all clients MUST implement the new
algorithm. Perhaps a year? Two years? Whatever makes sense when people
discuss it.
2) Begin adding support for the new algorithm to all clients, but disabled
until the target date, flipping on automatically when the target date is
3) Once it's the target date, clients can begin using the new algorithm.
Miners that haven't updated will fork the block chain because they'll be
unable to verify the new signatures, but hopefully the majority of
clients/miners have implemented the new signature algorithm by then.
Bitcoin may already have a better upgrade path than this built in (I
understand wallet addresses contain a version number), but I don't think
it's as difficult as you suggest.
*Don't do this. Please don't do this.

@_date: 2015-06-09 20:08:44
@_author: Tony Arcieri 
@_subject: [Cryptography] let's kill md5sum! 
Anyone verifying the integrity of a large file. Like a 500GB database
backup, for example...

@_date: 2015-06-10 21:30:05
@_author: Tony Arcieri 
@_subject: [Cryptography] Why is ECC secure? 
I think the fundamental problem is you need to reason about things in terms
of finite fields, and everything you've just described suggests you're
thinking about a finite field of characteristic 0, a.k.a. your basic two
dimensional plane.
Elliptic curve cryptography uses finite fields of (incomprehensibly) large
When an elliptic curve is plotted across a finite field, it completely
ceases to look like the curve you're probably thinking about:
Kind of looks like stars ;)

@_date: 2015-06-17 11:09:37
@_author: Tony Arcieri 
@_subject: [Cryptography] Anyone know of crypto hooks in webmail systems? 
Yeah, check out End-to-End (E2E):
In addition to just solving the problem of encrypted webmail, they're also
trying to address the user experience issues, and also provide
interoperability (at least between Google and Yahoo)
Pretty much the most promising solution I've seen for encrypted email yet

@_date: 2015-03-11 17:37:00
@_author: Tony Arcieri 
@_subject: [Cryptography] Securing cryptocurrencies 
I think a better solution is to create a protocol that doesn't rely on a
proof-of-work function. Still something of an open problem though.
I think the proof-of-stake approach used by systems like Tendermint are
interesting, and really what's holding back those sort of protocols now is
the simple fact that engineering a distributed consensus algorithm is
incredibly hard. Tendermint doesn't have a formal proof of correctness (in
terms of e.g. TLA+)

@_date: 2015-03-21 10:45:48
@_author: Tony Arcieri 
@_subject: [Cryptography] FFS 
djb and friends proposed the term "key erasure":
I prefer that, as it accurately describes what's happening.

@_date: 2015-03-27 22:42:40
@_author: Tony Arcieri 
@_subject: [Cryptography] OPENSSL FREAK 
Nikos's point is pretty important. Going back to what you said:
"In the 1990s it was believed that cipher agility was a good thing."
Cipher agility is definitely a good thing. The bad thing is failing to
disable insecure ciphers.

@_date: 2015-03-28 11:05:16
@_author: Tony Arcieri 
@_subject: [Cryptography] OPENSSL FREAK 
Without cipher agility, you're stuck using the bad ciphers forever until
you throw away the protocol and start over.

@_date: 2015-03-28 15:02:53
@_author: Tony Arcieri 
@_subject: [Cryptography] OPENSSL FREAK 
It's probably a better approach for security, but if you care at all about
usability, it's practically a nonstarter.

@_date: 2015-03-28 16:44:02
@_author: Tony Arcieri 
@_subject: [Cryptography] OPENSSL FREAK 
I work on termination of SSL/TLS in a professional capacity for a service
with millions of users. We are constantly tuning our supported ciphersuites
in response to the latest developments in attacks and cryptanalysis. I
think cipher agility has been invaluable for us. Tools like SSL Labs give
us a clear picture on what impact changes to our supported ciphersuites
will have to our users on a device-by-device basis.
To me "throw the baby out with the bathwater every 5 years" is a total
nonstarter. We have huge business incentives to support old customers, and
one of our biggest tools for doing that is working around protocol design
flaws using cipher agility.

@_date: 2015-03-30 23:48:14
@_author: Tony Arcieri 
@_subject: [Cryptography] OPENSSL FREAK 
If you can stop looking at it through such a perverse lens for just a brief
moment, you might recognize that having a common interoperable encryption
protocol is what has gotten HTTPS as far as it has.
If you don't like how SSL/TLS works, you should probably hop onto the IETF
TLS WG mailing list. I'm not sure they'd appreciate your missives, but
that's where you should post them if you actually want to accomplish change
instead of just having a venue for your rants.

@_date: 2015-05-12 09:23:11
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] NIST Workshop on Elliptic Curve 
One hopes they will recommend the same elliptic curve standards that the
IRTF's CFRG is standardizing for use in e.g. TLS.
Given that, so far, the CFRG has standardized curves developed by djb and
Mike Hamburg, at least to me they feel free of NSA influence.
We'll see what NIST actually ends up doing. Standardizing the CFRG curves
seems like a great way they could help promote interoperability and rebuild
their reputation.

@_date: 2015-05-12 12:16:22
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] NIST Workshop on Elliptic Curve 
I think it's unlikely that the NSA had advance knowledge of some sort of
class of weak curves / attack in the late '90s and baked that attack into
the NIST curves in such a way that civilian cryptographers are yet to
discover it in 2015.
However, the NIST curves definitely have (unintentional?) security problems
in addition to large mystery constants which do not inspire confidence.
Hence djb and friends / MS / CFRG's desire to have rigid curve generation
Dual EC DRBG smelled much more of a backdoor.

@_date: 2015-05-15 10:57:24
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] NIST Workshop on Elliptic Curve 
despite using SHA-1 to create "verifiably random" curves.
No weaknesses in the SHA-1 function are necessary. Instead, NSA could
simply do a brute force search for, say, a curve that belongs to a
one-in-a-million (or rarer) class of weak curves with a vulnerability known
only to NSA, and after finding an input value that generates such a weak
curve, publish that as the standard.
Perhaps you could make that argument for Montgomery curves and the
Montgomery ladder, but Edwards curves weren't discovered until 2007...
That said, I strongly agree the field arithmetic for Weierstrass is whack
and easy to get wrong.
I am glad to see the CFRG focusing on Edwards/Montgomery. Hopefully
Weierstrass is on its way out for anything other than legacy

@_date: 2015-05-15 16:38:26
@_author: Tony Arcieri 
@_subject: [Cryptography] NIST Workshop on Elliptic Curve Cryptography 
See also:
This is a demonstration of how even though a "verifiably random" process
(used by the NIST, Brainpool, and the GOST curves) is used, it's possible
to tamper with curve parameters.
BADA55's tampering was not malicious (and in fact they are "safe curves"
per safecurves.cr.yp.to), but the possibility to tamper with curve
parameters exists in any curves generated this way.
This is why "nothing up my sleeve" curve constants generated through a
rigid process are important (per your link).

@_date: 2015-05-16 10:20:03
@_author: Tony Arcieri 
@_subject: [Cryptography] NIST Workshop on Elliptic Curve Cryptography 
That's not what I'm saying at all.
BADA55 is a demonstration of why a "verifiably random" process, i.e. trying
to pick curve parameters via the output of a, shall we say, "something
potentially up my sleeve" number run through a hash function like SHA1, is
a bad idea.
That's not how rigid curve generation works, however. Instead, we pick a
set of constraints which generate curves that are not known to be
susceptible to any attacks today. Instead of mystery constants, we encode
our best knowledge about fast, secure ECC today into a constraint solver,
and have that pick the curves for us.
I suppose the most important takeaway I'm getting is that ECC is secure
Six of one, half dozen of another. Pollard's rho algorithms are still the
best general case attack against both ECC and RSA. ECC and RSA are both
special cases of the hidden subgroup problem.
You can worry about special case attacks against ECC which we can't foresee
based on present knowledge, but why are those more likely than novel
methods of factoring numbers, or improvements in index calculus attacks,
both of which would affect only RSA but not ECC?
Hypothetical attacks aside, RSA has a lot of real problems in practice. Due
to its susceptibility to index calculus attacks, large key sizes are used.
We now have the uncomfortable tradeoff between amplification attacks (i.e.
DDoS) in e.g. the DNSSEC case where the response includes an RSA public key
or signature, or reducing the key size and thus the security margin (DNSSEC
chose the latter... the root zone uses a 1024-bit ZSK)
Likewise, use of unpadded RSA is an exceedingly common error in
cryptographic programs.
I would consider the use of RSA for anything other than legacy
interoperability to be a code smell at this point. If you're creating a new
pubkey protocol without legacy interop requirements today, you should
probably be using ECC.

@_date: 2015-05-16 16:12:52
@_author: Tony Arcieri 
@_subject: [Cryptography] NIST Workshop on Elliptic Curve Cryptography 
We don't know, although 20/20 hindsight tells us that the NIST curves have
security problems, i.e. they fail all four dimensions of the SafeCurves ECC
Personally I don't think they were backdoored, but they are suspicious.
RSA's security isn't provable. It relies on factoring large numbers
presently being a hard problem. That's something that could potentially
change tomorrow if a sufficiently smart mathematician were to come up with
an algorithm for doing so.
perhaps one should not use a NSA ECC. Afterall. At least your key exchange
The NIST curves should also be considered legacy at this point, IMO. The
CFRG has almost finished standardizing Curve25519 (and Ed448-Goldilocks as
a "spinal tap grade" curve).
New programs and protocols should be using Curve25519.

@_date: 2015-05-19 17:43:13
@_author: Tony Arcieri 
@_subject: [Cryptography] NIST Workshop on Elliptic Curve Cryptography 
The NSA wanted 48-bits. IBM wanted 64-bits. So they split the difference at
"Parity bits" were used to explain the odd choice of 56-bits, but clearly 8
parity bits for 56-bits of data doesn't make a whole lot of sense.
You can read about it in Wikipedia, or for a more in-depth account, Steven
Levy's book "Crypto":

@_date: 2015-05-20 06:22:21
@_author: Tony Arcieri 
@_subject: [Cryptography] Intel SGX: Augean stables piled higher & deeper? 
If someone comes up with a mathematical proof for endpoint security, give
that person a medal

@_date: 2015-05-20 06:33:31
@_author: Tony Arcieri 
@_subject: [Cryptography] Intel SGX: Augean stables piled higher & deeper? 
I think you confused the issue by using the phrase "mathematical proof"
(repeatedly) in regard to an object in the physical world. That's not
really how these things work. They're not made of math.
Something like this is more germane to the discussion:

@_date: 2015-05-25 18:48:57
@_author: Tony Arcieri 
@_subject: [Cryptography] open questions in secure protocol design? 
One interesting anecdote from that RFC was WEP. It was the "one true
ciphersuite" for 802.11 security. Unfortunately WEP was rather broken, so
IEEE rushed the development and deployment of WPA, which was likewise
broken in many ways. As a result of this whole debacle, for over half a
decade most devices were incapable of making secure WiFi connections.

@_date: 2015-05-27 09:36:21
@_author: Tony Arcieri 
@_subject: [Cryptography] open questions in secure protocol design? 
Can you give an example of where it actually worked out well?

@_date: 2015-05-28 07:45:25
@_author: Tony Arcieri 
@_subject: [Cryptography] [FORGED] Re: open questions in secure protocol 
I mean, yes... I've been reading about and talking about both of those
extensively (see my post on the CFRG mailing list where I debunk
But that doesn't answer my question?
On Thu, May 28, 2015 at 2:43 AM, Peter Gutmann

@_date: 2015-05-29 17:08:25
@_author: Tony Arcieri 
@_subject: [Cryptography] open questions in secure protocol design? 
Oh god... no, strongly disagree.
$ gpg --gen-key
gpg (GnuPG) 1.4.18; Copyright (C) 2014 Free Software Foundation, Inc.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Please select what kind of key you want:
   (1) RSA and RSA (default)
   (2) DSA and Elgamal
   (3) DSA (sign only)
   (4) RSA (sign only)
Your selection?
^^^ this is an unusable mess
Proprietary protocol. No comment. (I dislike proprietary protocols and
they're harder to have opinions on since their internals are obscured)
My understanding is they abandoned end-to-end encryption, FWIW.
Strongly disagree. I have a long-form comment on this as part of this blog
post (see "A Bitcoin Crypto Meltdown")
Proprietary protocol. No comment.

@_date: 2015-05-29 17:16:55
@_author: Tony Arcieri 
@_subject: [Cryptography] open questions in secure protocol design? 
An extended comment on this:
After the RSA patents expired (in 2000 nonetheless), there was little
reason to include ElGamal or DSA support, especially for the generation of
new keys. I get the backwards compatibility argument, but that's the kind
of thing that should've been phased out 10 years ago. Yet here it is
continuing to junk up the UI in 2015 and contribute to the Johnny Can't
Encrypt problem.
The idea of "One True Ciphersuite" complicates the elimination of outmoded
ciphers that should no longer be supported.

@_date: 2015-05-29 17:21:24
@_author: Tony Arcieri 
@_subject: [Cryptography] Why is ECC secure? 
For what it's worth, you can say the same thing about factorization. The
only reason RSA is secure is because factoring large numbers is generally
considered a hard problem.
Index calculus attacks aside, integer factorization and DLP have some
interesting "isomorphisms" (for lack of a better term). For example,
Pollard's rho is the best algorithm (in different forms) for solving both
My understanding is that both problems can be reduced to the Hidden
Subgroup Problem:
There's been a decent amount of research into solving DLP. Certainly it's a
problem that humanity has spent less time working on than factorization,
but so far there hasn't been any particularly interesting breakthroughs.

@_date: 2015-05-29 18:49:53
@_author: Tony Arcieri 
@_subject: [Cryptography] open questions in secure protocol design? 
Satoshi chose a bad curve. Nobody who knows anything about ECC would
suggest using secp256k1 over Curve25519. They should switch, if only
because that 1-bit backdoor is particularly scary, but they can't do that
easily because the Bitcoin protocol has nothing to signal that wallet keys
are anything but ECDSA with secp256k1.
Actually, I suspect regardless of our views, Bitcoin is locked into the
I expect that Bitcoin and/or future pubkey-based decentralized transaction
consensus protocols will begin switching to Ed25519 soon. The interop
problem is a difficult one, and the reason why most sites continue to use
RSA certificates for TLS. But forward progress is possible. AES-GCM is
seeing widespread usage now where just a few years ago AES-CBC and RC4 were
the norm.
Given Bitcoin's lack of cipher agility, using Ed25519 instead of secp256k1
provides another checkmark on a gumball chart for any would-be Bitcoin
killer. Secure elliptic curve according to safecurves.cr.yp.to? Usurper:

@_date: 2015-05-30 18:16:29
@_author: Tony Arcieri 
@_subject: [Cryptography] Why is ECC secure? 
True, if you're talking about ECDSA, but ECDSA sucks. Use EdDSA and this
isn't a problem.
a.k.a. RSA signatures don't use a nonce
But RSA has failed spectacularly for lots and lots of reasons because it
has sharp edges that don't exist in ECC, like:
- Using a bad public exponent (e.g. 1):
- Failing to use padding, or using a weak padding mode (e.g. PKCS
- Implementing RSA naively in a way that's vulnerable to trivial timing
attacks (e.g. failure to use random blinding)
Then there's the part where RSA is slow (especially on the server side for
things like TLS) and has ginormous keys.
The latter can be used for amplification attacks in contexts like DNSSEC.
tl;dr: RSA sucks. Stop using it.

@_date: 2015-05-31 09:55:46
@_author: Tony Arcieri 
@_subject: [Cryptography] [FORGED] Re:  Why is ECC secure? 
Yes, but these are implementation issues which come up quite frequently in
practice and where I can point to specific examples of crypto tools that
have been broken because of them.
Show me one real-world example of a Montgomery ladder-based ECC system
leaking a private key because of a usage mistake.
Lumping ECC together with classical finite field-based DH is a category
fallacy. They have different characteristics, so comparing them this way is
apples to oranges.

@_date: 2015-05-31 14:49:49
@_author: Tony Arcieri 
@_subject: [Cryptography] [FORGED] Re:  Why is ECC secure? 
This is just more FUD. Montgomery curves have been around since 1987, and
Curve25519 has existed for a decade. The problems you're talking about have
to do with completely different things: finite field D-H (i.e. NOT ECDH)
and ECDSA (Weierstrass, and just a crappy design in general).
By a similarly specious argument, I could make the claim that these things
are public key cryptosystems, and RSA is a public key cryptosystem, so
perhaps RSA is going to leak the key too, eh?
I'll leave you with another specious argument I call "appeal to djb":

@_date: 2015-05-31 17:49:13
@_author: Tony Arcieri 
@_subject: [Cryptography] Why is ECC secure? 
============================== START ==============================
If you think this statement is true, I think it's just a reflection of your
own lack of understanding of ECC.
The underlying mathematics of ECC, much like RSA, are basic arithmetic.
It's the concepts that are perhaps harder to grasp. Both are difficult to
implement without timing side-channels.
Use of unpadded RSA is still a problem. Turns out problems abound.

@_date: 2015-11-02 10:27:05
@_author: Tony Arcieri 
@_subject: [Cryptography] YubiKeys / FIDO / U2F ?? 
FIDO in general is trying to build authentication systems designed from the
ground-up to work on the web. This most notably involves following the Same
Origin Policy or having explicit means of using credentials across origins
where both origins must agree and the origin a credential is provisioned on
provides an explicit policy for cross-origin use.
Following SOP has the nice side effect of being both privacy-preserving
(certificates are origin-bound) and solving "cross-protocol attacks" where
an attacker convinces a victim to sign a challenge/response used for auth
in a non-auth context.
It should also play nicely with the upcoming Token Binding extension for
TLS, which will allow cookies and other similar bearer credentials to be
confined to the holder of such a hardware token.
Yubico's implementation has the nice properties of being otherwise
stateless (keys are derived based on origin / "AppID") and never
exfiltrating private keys from the device, even in encrypted form (instead
it derives private keys from the combination of an AppID and nonce
generated on the device)
Of course it is proprietary hardware... whether you trust it is up to you
to decide.
All that said: yes, this is a great step forward for the web.

@_date: 2015-11-02 13:37:57
@_author: Tony Arcieri 
@_subject: [Cryptography] YubiKeys / FIDO / U2F ?? 
Microsoft already supports U2F in Windows 10 today as part of "Passport"
(ugh, formerly: Next Generation Credentials)
They are also adding U2F support to Edge:

@_date: 2015-11-03 16:55:16
@_author: Tony Arcieri 
@_subject: [Cryptography] YubiKeys / FIDO / U2F ?? 
Can you give a specific example of how you think SOP (at least the somewhat
weaker interpretation used by U2F) is deleterious, especially considering
U2F's multi-facet support (which allows explicit policies for cross-origin

@_date: 2015-11-05 18:00:52
@_author: Tony Arcieri 
@_subject: [Cryptography] Literature on reusing same key for AES / HMAC? 
In general I would say using a secret value as a key for a cipher (a PRP in
the case of AES) in addition to an unrelated PRF should be fine and have
seen several constructions of this nature.
For what it's worth, Ruby on Rails "Message Encryptor" class reuses the key
this way by default.
But perhaps I'm naive and mistaken!

@_date: 2015-11-09 23:43:30
@_author: Tony Arcieri 
@_subject: [Cryptography] Cryptogit 
There are many, many systems that aspire to this sort of thing. Some are
already git compatible. Others (that have more notable cryptographic
designs) can model git-like concepts, but are not yet git compatible (but
perhaps should be). Not naming names yet as I'm not a big fan of any of
these systems (at least in the git-compatible department), but they're
certainly out there and you can find them with a bit of Googling.
I can assure you it's a difficult problem, especially if you want both 1)
robust, modern cryptography and 2) a system that's backwards compatible
with git
For starters, git's Merkelized DAG is based on SHA1 with no futureproofing
built into the protocol. To safely encrypt and authenticate it would
require a complete wrapper based on modern primitives.
There are some safety features around collisions built into git, but they
require collisions be spotted in the wild, when an attacker might e.g. be
trying to get code A through an approval workflow, only to swap out
approved code A prior to malicious code B prior to merging, and workflow
systems built around git might try to correlate everything based around
commit SHA1s.

@_date: 2015-11-15 17:56:13
@_author: Tony Arcieri 
@_subject: [Cryptography] ratcheting DH strengths over time 
There is no reason to use FFDH anymore save for legacy compatibility or a
catastrophic failure of ECC. Use ECDH instead.
Regarding RSA, there is no compelling reason to use RSA key sizes
I would put my money on a large quantum computer capable of breaking all
remotely usable key strengths of RSA, FFDH, and ECC being built before
practical non-quantum attacks against 2048-bit RSA are possible.

@_date: 2015-11-15 22:18:03
@_author: Tony Arcieri 
@_subject: [Cryptography] [FORGED] Re:  ratcheting DH strengths over time 
It's faster and has smaller key sizes at the same security level.
Not sure if that falls into your definition of "numerology", but key size
does seem to be the "key" issue in this thread...

@_date: 2015-11-16 18:06:29
@_author: Tony Arcieri 
@_subject: [Cryptography] [FORGED] Re: ratcheting DH strengths over time 
ianG is suggesting we use 1024-bit D-H in 2015, which is odd as all methods
on  suggest that isn't strong enough.
I don't believe there's a considerable difference in the number of qubits
needed to attack a ~256-bit elliptic curve versus 1024-bit D-H.
That would, by far, be a much simpler solution, and sufficient to ward off
non-quantum attacks for at least a decade.

@_date: 2015-11-17 10:19:25
@_author: Tony Arcieri 
@_subject: [Cryptography] Sadly predictable: Terrorism used as excuse to 
The New York Times apparently posted a similar article earlier, then
silently retracted it:
That said, for all the talk of crypto being a terrorist tool, allegedly
(Daily Mail, quoting Fox News, take it with a grain of salt...) ISIS social
media accounts were already posting pictures of the Eiffel Tower along with
"God bless you on your mission" 72 hours before the attack:
It would be rather ironic if ISIS committed an opsec failure that bad which
intelligence services weren't able to pick up on, and yet encryption is
blamed anyway.

@_date: 2015-11-17 11:46:38
@_author: Tony Arcieri 
@_subject: [Cryptography] [FORGED] Re: ratcheting DH strengths over time 
You don't. If you think you can, good luck.
It should probably be something like:
- 2048 (ok for approximately the next 10 years or so)
- 4096
Both MTI for now, then retire 2048 after approximately 10 years
...unless large quantum computer appears, in which case you retire

@_date: 2015-11-20 09:45:09
@_author: Tony Arcieri 
@_subject: [Cryptography] [FORGED] Re:  ratcheting DH strengths over time 
For what it's worth, future releases of Chromium / Chrome will be dropping
DHE support:

@_date: 2015-09-30 21:57:52
@_author: Tony Arcieri 
@_subject: [Cryptography] Insecure Chip 'n' PIN starts tomorrow 
Do you really think a 4 digit number is the difference between a secure and
insecure system?
The liability shift is only for magstripe cards, not for EMV. Their goal is
to push people onto EMV.
EMV has a ton of issues and attacks against EMV are already commonplace.
But magstripe cards are effectively a 16-digit + 3-digit CVV1 "password"
you give to anyone you can transact business with, who with that knowledge
can thereafter impersonate you on the network. That's clearly not the
greatest authentication scheme in the world.
EMV has a ton of problems, but magstripe cards are a technology that has
outlived its usefulness.

@_date: 2015-10-01 11:19:17
@_author: Tony Arcieri 
@_subject: [Cryptography] Insecure Chip 'n' PIN starts tomorrow 
Yes, there is a rich history of attacks on EMV, e.g.:

@_date: 2015-10-25 15:47:59
@_author: Tony Arcieri 
@_subject: [Cryptography] composing EC & RSA encryption? 
First, if your worry is QCs, then trying to combine ECC and RSA isn't going
to help you as they'll both be obliterated by QCs.
However, the general idea of combining multiple algorithms isn't inherently
bad. What you would *actually* want to do is combine e.g. ECC with an
as-yet-unproven quantum algorithm, like Ring-LWE (possibly not a good idea
due to patents, but let's go with it for now)
In that case, you can do a key exchange with both algorithms, and feed the
results of both into a KDF (e.g. concatenating the keys exchanged together
as KDF inputs)
This sort of scheme should be at least as strong as the strongest of the

@_date: 2015-10-26 09:28:03
@_author: Tony Arcieri 
@_subject: [Cryptography] composing EC & RSA encryption? 
Even if this is true (and I'm pretty sure it's not in any meaningful way,
i.e. if a quantum computer successfully breaks 256-bit ECC in the real
world, 2048-bit RSA/DH is definitely next within a timeframe so short
anyone with sense would abandon it), if you're pairing pre-quantum and
post-quantum algorithms anyway, shouldn't you pick the fastest pre-quantum
algorithm you can?

@_date: 2015-10-26 11:36:24
@_author: Tony Arcieri 
@_subject: [Cryptography] composing EC & RSA encryption? 
And even then there are robust, stateless schemes for post-quantum
signatures like SPHINCS we could start using today if we wanted to, but why
The great irony of post-quantum crypto: the thing we don't need now
(signatures) is the easiest, the thing we need now (encryption/key
exchange) is the hardest

@_date: 2015-10-28 10:32:24
@_author: Tony Arcieri 
@_subject: [Cryptography] composing EC & RSA encryption? 
As someone who actually reads the TLS WG's mailing list, I can tell you
this simply isn't true. See for example:
There are several things being deprecated from TLS 1.3 as well  (e.g. SHA1,
binary curves). The list of MTI ciphers is much smaller.

@_date: 2015-08-31 23:16:29
@_author: Tony Arcieri 
@_subject: [Cryptography] Ratcheting 
A more interesting target is a permanently stored message archive. Many
apps using such a protocol keep such an archive. Such archives are
orthogonal to ratcheting protocols, but something to keep in mind as part
of an overall threat model.

@_date: 2015-09-10 12:09:06
@_author: Tony Arcieri 
@_subject: [Cryptography] 
This article is really bad. I strongly suggest reading Matthew Green's
recent blog post on the same thing:
Key verification doesn't work in a system like iMessage, because iMessage
has each device for every conversation participant register a unique public
key, then encrypts each message to all public keys of all devices of all
conversation participants.
To do key verification correctly, you would have to verify every public key
of every device of every conversation participant. At that point, iMessage
probably isn't the system you're after.
This is a bad way to "keep the keyserver honest". The process needs to be
Again, I would suggest reading Matthew Green's post, where he talks about
CONIKS, and using a Certificate Transparency-like protocol:

@_date: 2015-09-10 21:42:25
@_author: Tony Arcieri 
@_subject: [Cryptography] millions of Ashley Madison bcrypt hashes cracked 
tl;dr: they cracked MD5 digests instead. The MD5 version was downcased.
Once recovering the downcased password, they recovered the case sensitive
version by brute forcing all possible case variants against the bcrypt

@_date: 2015-09-15 13:34:56
@_author: Tony Arcieri 
@_subject: [Cryptography] Microsoft's new, free, 
Some context (for curves at a 128-bit security level):
- Curve25519 is now 10 years old
- FourQ *is* faster than Curve25519 but...
- djb and friends' Kummer curve is faster than FourQ unless FourQ leverages
techniques in the GLV patent: - Kummer may potentially be faster even when the patented techniques are
leveraged? (hasn't been assembly optimized yet)
That said, FourQ is more generally applicable, e.g. it can be used for
signatures in addition to D-H.
Verdict: interesting but the way Microsoft is marketing it is a bit
disingenuous and it has patent entanglements which if avoided make it
slower than alternatives. They should be expiring soon though.
I think this is the relevant patent?

@_date: 2015-09-19 14:38:01
@_author: Tony Arcieri 
@_subject: [Cryptography] Comey: targeted ads => plaintext access 
Both ad targeting and search are possible against ciphertext.
There are many schemes for searchable symmetric encryption. There's also
partially and fully homomorphic encryption (the latter being quite slow,
but capable of expressing arbitrary circuits):
Allowing a potential attacker to compute things about your ciphertexts
(even if they can't tell specifically what they're computing) leaks some
information of course.
See for example the recent attacks against CryptDB:

@_date: 2015-09-19 21:30:11
@_author: Tony Arcieri 
@_subject: [Cryptography] Microsoft's new, free, 
Oh really!
Cool claim, it's both vague and not true in places where it really matters.
64-bit processors (check out Table 5 in the FourQ paper,
Funny thing, I know you really don't want to for some reason, but if we do
look at one CPU architecture, there's a rather important one that Kummer
hasn't been optimized for. I'll just quote djb...
I guess your point is why should we care about Haswell? Well, I certainly
care about Haswell and its progeny even if you don't...
djb has several other criticisms of the performance metrics in the FourQ
paper. Microsoft also has a history of over-embellishing the performance of
e.g. the NUMS curves. Perhaps some independent verification is needed
before the figures in their paper are taken at face value?
This is why benchmarking systems like SUPERCOP are nice.

@_date: 2015-09-28 13:14:38
@_author: Tony Arcieri 
@_subject: [Cryptography] [FORGED] Brainpool Curves Found to Be Suspicious 
Note that the CFRG curves (Curve25519 and Ed448-Goldilocks) are defined by
rigid generation guidelines which produce these particular curves:

@_date: 2016-04-04 20:44:24
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography] Secure universal message 
I know a lot of smart cryptographers who think a
one-algorithm-specific-key-to-rule-them-all approach (including, I believe,
the operator of this mailing list) is the best way to go. I don't think so.
I think something that looks like an email address, possibly exactly like
an email address, is the way to go.
UX wise, and despite the recent CCA attacks/gzip oracle, iMessage is far
and away my favorite multi-device messaging platform. iMessage assigns a
unique key per device, and allows keys to be revoked. I think that's the
baseline model for usable E2E messaging.
As far as how to actually pull that off in the real-world, CONIKS seems
like a start:

@_date: 2016-04-06 22:58:01
@_author: Tony Arcieri 
@_subject: [Cryptography] At what point should people not use TLS? 
I share some of your concerns. I posted to the CFRG list about them:
I have also spent a lot of time discouraging people from homebrewing their
own transport encryption protocols and driving them towards TLS:
All that said: I think you are being overly dramatic. Unlike most homebrew
transport encryption protocols, Noise isn't immediately and obviously
broken (at least to me). In fact, it has a number of similarities to the
proposed OPTLS key exchange protocol.
Analysis is a chicken-and-egg problem: nobody is going to bother analyzing
a protocol that nobody uses, so if you want people to analyze your
protocol, you have to deploy it to a wide audience to give them a reason to
Noise covers a number of non-stream-oriented use cases which TLS (and also
DTLS) do not. In absence of a protocol that covers these use cases, there's
been a longstanding history of amateurs cobbling together their own
immediately and obviously broken transport encryption protocols,
particularly since popularization of NaCl has given them a sort of crypto
Dunning-Kruger[1] that because the primitives are safe(r), protocol design
is easy.
I say let's see where this goes. With over a billion users relying on it,
perhaps it will start drawing analysis organically.
(Note: I've been following Noise development for a number of years, so
maybe I'm biased)
[1]: Yes I know about the controversy surrounding Dunning-Kruger. No need
to point that out, let's keep it on topic please.

@_date: 2016-04-07 21:46:05
@_author: Tony Arcieri 
@_subject: [Cryptography] At what point should people not use TLS? 
I haven't gotten any information on what implementation they're using. I
suspect it may be closed source.
That said, I am fairly sure they're *not* using Trevor Perrin's Rust
implementation "Screech", although that looks quite interesting.

@_date: 2016-04-09 13:07:39
@_author: Tony Arcieri 
@_subject: [Cryptography] What standards are there for post-quantum 
When you say for "certificates", do you mean for use in TLS? If that's the
case, there aren't many good options right now: the ones with relatively
short signatures are shaky, and the ones that are actually solid have
relatively large signatures.
SPHINCS is a nice option aside from the fact signatures are 41kB:
I think post-quantum signatures are a bit less pressing than post quantum
encryption/key exchange though. We can always go back and resign things.
Once a ciphertext hits a wire though, anyone who observed it can keep it
around and decrypt it retroactively.

@_date: 2016-04-12 10:05:25
@_author: Tony Arcieri 
@_subject: [Cryptography] At what point should people not use TLS? 
The best attack on Tiger is a 22 round near-collision attack:
It's not in good shape and should not be used in new protocols.

@_date: 2016-04-12 17:39:27
@_author: Tony Arcieri 
@_subject: [Cryptography] Show Crypto: prototype USB HSM 
Not to rain on your parade, but if you're talking about authentication
contexts, U2F solves the phishability problem by deriving domain-separated
keys per origin, so it's not possible for an attacker to leverage it for
phishing purposes.

@_date: 2016-04-12 20:12:52
@_author: Tony Arcieri 
@_subject: [Cryptography] Show Crypto: prototype USB HSM 
Well, that's true, but it's also hundreds of times bigger than a token in
the Yubikey "nano" form factor, which is actually convenient to keep
permanently in the USB slot of a laptop. Your physical design seems pretty
unwieldy for laptops (see also Yubico's keychain designs).
Yubikey "nano" factor tokens like the NEO-n have also supported more
general purposes than a U2F token (e.g. CCID interface, OpenPGP applets,
see also PIV)
I swear I'm not a paid shill for Yubico, but I'm a fan of small
display-free hardware tokens. While a token like what you've built might
provide Maximum Security under pessimistic threat models, its large size
makes it look rather inconvenient to me.

@_date: 2016-04-13 08:56:43
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography]  Show Crypto: prototype USB HSM 
I prefer to be realistic about threats, especially when UX tradeoffs are

@_date: 2016-04-13 10:01:06
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography]  Show Crypto: prototype USB HSM 
Yes, make it significantly smaller than the current form factor.

@_date: 2016-04-13 11:54:52
@_author: Tony Arcieri 
@_subject: [Cryptography] [cryptography]  Show Crypto: prototype USB HSM 
Yes, that's significantly better. Sorry if I was overly negative before.

@_date: 2016-04-16 15:20:08
@_author: Tony Arcieri 
@_subject: [Cryptography] Simple IoT sensor encryption ? 
No bidirectional communication is needed. Each time the sensor wants to
send data, it "seals" it by generating a random ephemeral (EC)DH private
key, computing the corresponding public key and shared secret with the
static (EC)DH public key of the recipient which can be used to derive a
symmetric key to encrypt a given message. Then you just send the
corresponding ephemeral public key along with each message, and erase the
(EC)DH private key (and derived shared secret / symmetric key) once the
message has been sent.
This scheme lacks forward secrecy if the static key on the other end is
exposed though.

@_date: 2016-04-16 16:48:28
@_author: Tony Arcieri 
@_subject: [Cryptography] At what point should people not use TLS? 
While I'm not really a fan of DNSSEC, DANE TLSA records can contain a
Domain-Issued Certificate where the entire certificate is provided in and
authenticated via a DNS response.

@_date: 2016-04-25 19:17:02
@_author: Tony Arcieri 
@_subject: [Cryptography] WhatsApp: Why asymmetric key instead of 
PSK authentication would only cover the case where users want to exchange
keys in person, which in practice has been shown to be a very small number
of people. WhatsApp is targeting over a billion users: asking a billion
people to do an in-person PSK exchange with all of their contacts is a

@_date: 2016-08-22 15:59:46
@_author: Tony Arcieri 
@_subject: [Cryptography] Electronic currency revived after 20-year hiatus 
The largest number I've seen quoted by a blockchain system (Tendermint) is
10,000 transactions per second in a simulated benchmark on EC2.
That's 864,000,000 transactions per day, or about 2 orders of magnitude
lower than your quoted number of 20 billion.
20 billion is, in fact, an order of magnitude higher than VISAnet's claimed
Meanwhile, Bitcoin's present maximum theoretical transaction rate
(pre-SegWit) is closer to slightly less than 1 million ("on-chain")
transactions per day.
There are only two strategies that will work:
   - Move more payments off-chain (e.g. payment channels, Lightning,
   Thunder)
   - More ledgers/payment networks, and a protocol to interconnect them
   (pegged sidechains, Interledger)
A single, centralized ledger system is a flawed strategy.
Tony Arcieri

@_date: 2016-02-22 14:14:54
@_author: Tony Arcieri 
@_subject: [Cryptography] eliminating manufacturer's ability to backdoor 
1) Have manufacturers provide a *generic* FPGA
2) Use a framework like Cryptol ( to produce
Verilog/VHDL versions of cryptographic ciphers from a *generic* description
3) Cryptographers build specific algorithms in the framework of e.g. Cryptol
Users can now obtain a Cryptol description of any algorithm which they can
compile and load onto an FPGA themselves.
In such a multiparty exchange of cryptographic knowledge, who is at fault
here? (given various complicated local laws)

@_date: 2016-02-22 15:45:44
@_author: Tony Arcieri 
@_subject: [Cryptography] eliminating manufacturer's ability to backdoor 
What if the British government makes iPhone-style encryption illegal like
they seem to be suggesting they will?
While I entirely agree with what you're saying, anyone who buys a third
party hardware device entirely trusts the manufacturer has not included
I am suggesting a model where there is a separation of responsibilities
between providers in the various stack which is resistant against both
legislation and actual backdoors.

@_date: 2016-02-22 19:15:43
@_author: Tony Arcieri 
@_subject: [Cryptography] eliminating manufacturer's ability to backdoor 
Then in the US at least, there are 100 million+ people who are breaking the

@_date: 2016-02-29 17:04:44
@_author: Tony Arcieri 
@_subject: [Cryptography] 9999 keys for this one iPhone 
Good thing the PIN can be longer than 4 digits... and can include non-digit
characters if you so desire!
I count myself among the people with an iOS device with a > 4-digit
The UID key is unique-per-device too. There are more potential keys for
iPhones than there are atoms in the universe.
You might try reading Matt Green's blog post:

@_date: 2016-02-29 19:07:55
@_author: Tony Arcieri 
@_subject: [Cryptography] 9999 keys for this one iPhone 
In a modern iPhone with a "Secure Payments Enclave" (SPE), no. There is no
instruction to exfiltrate the UID key from the SPE which is needed to
derive the root key. It can perhaps be extracted through a decapping attack
on the SoC, unless Apple used one of these:
Going forward it seems Apple is intent upon building a phone that moves all
the key derivation functionality into hardware and will most likely use
something like ^^^ to prevent exfiltration of the "UID key" /
device-specific master key.
Note that none of this applies to the FBI case involving the iPhone 5c,
which does not have an SPE, however the phone in the San Bernadino case
does (iPhone 5s I believe)
Failing to exfiltrate this key, the rate at which the key can be brute
force is bounded by mechanisms like exponential backoff and
wipe-after-n-attempts. Also note: all that needs to be wiped is the master
encryption key. Once destroyed backups become useless.

@_date: 2016-01-03 16:33:05
@_author: Tony Arcieri 
@_subject: [Cryptography] How can you enter a 256-bit key in 12 decimal 
It's possible there's some sort of high-entropy on-device secret. There are
also ways of generating these secrets in such a way that attempts to
physically tamper with the device will destroy the secret generator, e.g.
A high-entropy secret generated in this matter can be mixed with the PIN to
derive an encryption key. This allows you to implement hardware lockouts on
PIN entry at a very low level in hardware.

@_date: 2016-01-04 13:28:20
@_author: Tony Arcieri 
@_subject: [Cryptography] 256 bit key + 12 digit PIN 
---------- Forwarded message ----------
It's possible there's some sort of high-entropy on-device secret. There are
also ways of generating these secrets in such a way that attempts to
physically tamper with the device will destroy the secret generator, e.g.
A high-entropy secret generated in this matter can be mixed with the PIN to
derive an encryption key. This allows you to implement hardware lockouts on
PIN entry at a very low level in hardware.

@_date: 2016-01-04 23:25:13
@_author: Tony Arcieri 
@_subject: [Cryptography] How can you enter a 256-bit key in 12 decimal 
See Microsoft's "Why a PIN is better than a password":

@_date: 2016-01-05 09:48:55
@_author: Tony Arcieri 
@_subject: [Cryptography] How can you enter a 256-bit key in 12 decimal 
You left off the rest of my message:
to derive an encryption key. **This allows you to implement hardware
lockouts on PIN entry** at a very low level in hardware.
Attempting a brute force attack on the PIN can trigger exponential backoff
on how frequently PIN entry attempts can be made and/or brick the device.

@_date: 2016-06-23 17:29:39
@_author: Tony Arcieri 
@_subject: [Cryptography] 40 years of "Diffie-Hellman" 
Of course, the historically savvy crypto-enthusiast recognizes the
algorithm we call "Diffie-Hellman" was actually invented by Malcolm
Williamson at GCHQ in 1974:
He died last September. RIP.

@_date: 2016-03-08 20:14:05
@_author: Tony Arcieri 
@_subject: [Cryptography] Secret key agreement by public discussion from 
That's not really an eavesdropping Eve though, that's more like a malicious
Mallory the active attacker. In this model, Mallory could pretend to be Bob
and also ask for clarifications from Alice, and Alice has no way to tell
Bob from Mallory.

@_date: 2016-03-12 15:42:55
@_author: Tony Arcieri 
@_subject: [Cryptography] Wire.com: private communications, 
The actual crypto employed looks fine (Axolotl), but they support SMS login
which has many vulnerabilities (forced number porting, IMSI catchers, telco
MitMs, telco coercion, shoulder surfing just to name a few). Telegram
offers the same feature, and it's routinely been exploited, especially by
state-level attackers. See:

@_date: 2016-03-19 21:40:22
@_author: Tony Arcieri 
@_subject: [Cryptography] Formal Verification (was Re: Trust & randomness 
With verifiable computation, you don't need to check the whole program
either, only verify the result:
[image: Inline image 1]

@_date: 2016-03-20 21:44:58
@_author: Tony Arcieri 
@_subject: [Cryptography] iMessage cryptography is broken 
...allows plaintext recovery attacks. Problem: lack of a MAC.
Johns Hopkins researchers poke a hole in Apples encryption
Apples growing arsenal of encryption techniques  shielding data on
devices as well as real-time video calls and instant messages  has spurred
the U.S. government to sound the alarm that such tools are putting the
communications of terrorists and criminals out of the reach of law
But a group of Johns Hopkins University researchers has found a bug in the
companys vaunted encryption, one that would enable a skilled attacker to
decrypt photos and videos sent as secure instant messages.
This specific flaw in Apples iMessage platform likely would not have
helped the FBI pull data from an iPhone
in Decembers San Bernardino, Calif., terrorist attack, but it shatters the
notion that strong commercial encryption has left no opening for law
enforcement and hackers, said Matthew D. Green, a computer science
professor at Johns Hopkins University who led the research team.
The discovery comes as the U.S. government and Apple are locked in a widely
watched legal battle in which the Justice Department is seeking to force
the company to write software to help FBI agents peer into the encrypted
contents of the iPhone used by Syed Rizwan Farouk, one of two attackers who
were killed by police after the shooting rampage that claimed 14 lives.
Cryptographers such as Green say that asking a court to compel a tech
company such as Apple to create software to undo a security feature makes
no sense  especially when there may already be bugs that can be exploited.

@_date: 2016-03-28 18:01:49
@_author: Tony Arcieri 
@_subject: [Cryptography] Gates are cheap. Should cipher design change? 
Did you just make the claim:
"So now we have a cipher designed for efficient software implementation
being migrated into the hardware."
...about AES?
This is patently untrue: AES was designed for efficient hardware
implementations, and implementing it *correctly* in software is incredibly
By contrast, other AES candidates like Serpent were designed with
techniques like bitslicing in mind, making them more amenable to software

@_date: 2016-05-06 22:25:25
@_author: Tony Arcieri 
@_subject: [Cryptography] Proof-of-Satoshi fails Proof-of-Proof. 
Interesting sidebar: ECDSA nonces were one of the sources of Bitcoin's
transaction malleability. The (massive pile of hacks that is) segregated
witness feature being added to Bitcoin has an added side effect of removing
signatures from the hash of a transaction, and with it the associated
All that said, if you're designing a new system today, pick Ed25519.

@_date: 2016-11-14 16:27:28
@_author: Tony Arcieri 
@_subject: [Cryptography] On the deployment of client-side certs 
Browsers are (I think quite clearly?) the main use case, but the existing
client cert implementation and UX in browsers is rather suboptimal. Browser
vendors seem to be reluctant to even support it, and are looking at phasing
parts of it out (e.g. the  tag) since it's so infrequently used.
The main problem is in the current incarnation, client certs are a
same-origin policy violation: one cert can potentially be used on many
sites. This means:
1) We don't automatically know what client cert to use to authenticate a
user. This means we have to ASK the user which cert to use. Often browsers
don't remember
2) Since certs can be used across origins, they leak a linkable identity
across sites
What's needed to solve these issues is a system which provisions unique
"certificates" per site (i.e. origin-bound certificates). Our best bet
there is Token Binding, which is implemented as a TLS extension and HTTP
header, which is being standardized through the IETF (with Google doing
most of the design/implementation work):
I believe they're in the process of wrapping up their work. I saw they just
open sourced an implementation as well:
All that said, I think client certs are fantastic for server-to-server
authentication, but something like token binding seems like a better fit
for end users, IMO.

@_date: 2016-11-15 13:18:18
@_author: Tony Arcieri 
@_subject: [Cryptography] On the deployment of client-side certs 
Note there are many other modern PAKE algorithms based on ECC which are
much easier to implement in constant time than SRP, as the latter generally
relies on bignums. SPAKE2(+) and SPAKE2-EE come to mind.
That said, I think there are few use cases where PAKE actually makes sense,
particularly for UX reasons. I do not think it makes sense to use PAKE in a
browser context. The only way I think it could work securely is with
something like the reviled Basic Auth modal dialog, which to me is a UX
antipattern which has largely been phased out of the modern web.

@_date: 2016-11-15 13:27:07
@_author: Tony Arcieri 
@_subject: [Cryptography] On the deployment of client-side certs 
Note this is true of TLS 1.2 and earlier, but in TLS 1.3 client
certificates are sent encrypted.
However, short of an origin-bound certificate approach, client certificates
still represent an SOP-violating linkable identifier, and are therefore
undesirable from a privacy perspective.

@_date: 2016-11-15 14:38:49
@_author: Tony Arcieri 
@_subject: [Cryptography] On the deployment of client-side certs 
I've been a big fan of FIDO for the past two years and I've really wanted
to support U2F tokens specifically for the real-world analogy to keys, but
I don't think it's really practical for everyone to buy a U2F token. I
would love to see everyone using hardware tokens this way, but I just don't
see it happening.
That said, another FIDO standard, UAF, should enable smartphones to work as
cryptographic authentication tokens. I think this approach is much more

@_date: 2016-11-15 19:09:23
@_author: Tony Arcieri 
@_subject: [Cryptography] On the deployment of client-side certs 
I am quite aware of the low cost: I probably have a dozen or so in my
possession. There are a dizzying array of U2F tokens available, which in
and of itself is an obstacle for newcomers. Which one should they buy? This
is a question I have strong opinions about, but an obstacle for newcomers.
2FA adoption in general remains quite low, so low most companies seem
embarrassed to even publish numbers. Some estimates put 2FA adoption on
Google at 6.5%:
Even among my technically savvy friends who have adopted 2FA, U2F use seems
quite low: perhaps 5% of the people I've talked to about it? Most others
are using TOTP or SMS. I have thought about blogging about U2F for just
this purpose.
U2F doesn't improve user experience, except over other 2FA solutions, and
2FA is still quite tricky. Users STILL have to enter a password. The token
just bolsters their security.
UAF is an entirely different animal altogether: it's a "passwordless
experience". No more passwords to remember! It's the dream we keep hoping
for. It's not something else you have to do in addition to a password; it's
a bona fide password *replacement*
Plus, there's nothing to buy if you already own a smartphone. If and when
UAF ships (it's likely to ship on Android devices at some point. iOS seems
much more uncertain), anyone with a UAF-capable phone will be able to take
advantage of it without having to figure out which token to buy.
Only time will tell I guess. Maybe I'm wrong and we'll see everyone with
hardware tokens on their keychains soon. But I think it's far more likely
we'll see smartphones leveraged for this purpose, rather than widespread
usage of dedicated tokens.

@_date: 2016-11-15 23:41:19
@_author: Tony Arcieri 
@_subject: [Cryptography] On the deployment of client-side certs 
Clearly a dedicated hardware token (or something like the new Apple T1 chip
+ Touch Bar) has better security properties than a smartphone which is
running user-installable software.
But that's not what I was talking about. I was talking about which one is
more likely to be adopted. In that regard I think something that runs on
smartphones will beat a dedicated device any day.

@_date: 2016-11-17 12:00:51
@_author: Tony Arcieri 
@_subject: [Cryptography] On the deployment of client-side certs 
That's exactly what they did:
The visible bit is the Touch Bar.
At an absolute minimum, there needs to be an externally-visible LED or
The Touch Bar is connected to the T1 chip via USB.
The T1 chip is an ARM SoC running what is allegedly a fork of watchOS,
completely divorced from OS X running on the primary Intel CPU.
Furthermore, the T1 chip actually sits earlier in the secure boot process
than the Intel CPU, and holds the master keys to the OS X keychain.
According to the Apple Insider article:
"*AppleInsider* has learned there is no association procedure between a
service stock generic Touch Bar, and the T1 inside the MacBook Pro. As a
result, at least for now, if the Track Bar needs replacing for any reason,
so does the T1."
So, if Apple Insider is to believed, the T1 chip, Touch Bar, and the
front-facing camera are all cryptographically paired in an irreversible
This makes the Touch Bar a secure display which is inaccessible by OS X.

@_date: 2016-10-01 11:46:10
@_author: Tony Arcieri 
@_subject: [Cryptography] Posting the keys/certs for: Two distinct DSA 
If I'm reading this thread right (I apologize, I've only skimmed) this is a
duplicate signature key selection attack, similar to:
The easiest way to mitigate it at a protocol level is to include the
sender's public key in the contents of the digest to be signed, then make
sure the public key you're using to verify matches the one in the message
you're verifying.
All that said, the strength of a cryptographic system rests in the keys. If
you're trying to verify a message with a potentially malicious public key,
what does that say about the contents of the message at all? (Not a whole
lot, IMO)

@_date: 2016-10-26 09:42:40
@_author: Tony Arcieri 
@_subject: [Cryptography] A PKI without CRLs or OCSP 
The disadvantage is every client needs a copy of the entire blockchain /
log. There's already a system in place that works much like a blockchain
for certificates: Certificate Transparency logs:
Unfortunately these logs have such high volume that nobody but Google can
presently operate one capable of handling Let's Encrypt, let alone trying
to push that volume of data out to every client so they have a local copy
of every certificate.
without any network access
What's the use case? I'll note with OCSP stapling a client can validate a
certificate chain with only network access to the destination service whose
certificate they're trying to validate. You seem to be talking about
verifying certificates in a context where you aren't even trying to
initiate an SSL/TLS connection?

@_date: 2016-09-07 21:26:50
@_author: Tony Arcieri 
@_subject: [Cryptography] Secure erasure in C. 
Take a look at the implementation of sodium_memzero() from libsodium:
See also memset_s():

@_date: 2016-09-11 19:18:19
@_author: Tony Arcieri 
@_subject: [Cryptography] Secure erasure in C. 
Except it is? I pointed out a compiler intrinsic, memset_s(), that solves
this problem, and pointed to a library (libsodium) that provides a cross-OS
solution to this problem, but nobody cared. Honestly, that should've been
the end of the thread, but it persisted.
I think this is a really silly thread. This is a solved problem, and
everyone responding by trying to outsmart the compiler is terribly confused.
Everything's fine. The future is here, it just isn't evenly distributed, I

@_date: 2016-09-13 14:49:24
@_author: Tony Arcieri 
@_subject: [Cryptography] Secure erasure 
In Rust they're referred to as affine types, lifetimes, or region types.
But they do exactly that. Unfortunately they don't zero-on-drop anymore,
but that's semantics you can easily add through Rust's Drop trait, and
there are many libraries for storing secrets which implement such semantics.

@_date: 2017-12-04 16:48:00
@_author: Tony Arcieri 
@_subject: [Cryptography] XChaCha20 standardized? 
XChaCha20 uses the HChaCha20 function to hash the longer nonce in the same
manner as XSalsa20.
This is somewhat unique to libsodium, although easily added to any other
library that has ChaCha20/HChaCha20.
Sure. why not. It would be nice if there were only one version of
XChaCha20, and people don't invent a separate incompatible XChaCha20 based
on the original djb version of ChaCha20. That said, I think that may have
already happened.
Regardless, I'm a bit confused since libsodium chose to name it
This is to indicate it's using the IETF version of ChaCha20 (as opposed to
the original djb version), and NOT that it has been specified by the IETF.

@_date: 2017-11-06 14:13:16
@_author: Tony Arcieri 
@_subject: [Cryptography] One Bitcoin Transaction Now Uses as Much Energy 
This view speculates that people actually want to use Bitcoin as a payments
platform, as opposed to speculating on it as a digital asset.
The reality is Bitcoin's transaction volume has largely topped out
recently, with the only exception being a suspected DDoS attack which
appears to have ended shortly before the activation of SegWit:
Perhaps it will grow again. "If you build it they will come." Or not...
there's not a whole lot of incentive to take payments off-chain with
Lightning when there's on-chain capacity. It is otherwise a perpetual "get
out of talking about transaction volume free" card for blockchainiacs who
don't want to discuss Bitcoin's network capacity... even before it ships!
Meanwhile hashpower continues to skyrocket:
The rise in energy-per-transaction shows the combination of energy being
invested in mining power combined with anemic transaction rates.
This is a very real problem, and a demonstration of why proof-of-work is a
poor solution.
Are there better options? I guess we'll see what happens in 2018. But I
suspect yes...

@_date: 2017-11-14 10:40:55
@_author: Tony Arcieri 
@_subject: [Cryptography] Is ASN.1 still the thing? 
I've also been working on a project which is, at least in part, borne out
of similar frustrations:
It's underspecified and incomplete, but generally follows a similar design
to Protocol Buffers. That is to say, it's TLV-ish (type and length are
combined into a single varint ala Protos), with numbered fields and an IDL
to describe schemas.
Why not just use Protos then? This is described at length in the README,
but tl;dr: I was trying to apply Ben Laurie's afforementioned ObjectHash
idea to Protos and ran into a particularly annoying problem: older clients
will be unable to calculate the ObjectHashes of unknown fields, i.e. the
content hash algorithm is coupled to the schema. I wanted to support a
format that allowed addition of new fields while still letting clients
calculate the same content hash. This requires a self-describing wire
format, which is unfortunately a property Protos do not have.
Additionally, I wanted to support an isomorphic text format for which the
same ObjectHashes would be calculated (even in the presence of binary
data), TJSON:
In TJSON I've also aimed to make a stricter format which eliminates many
common JSON ambiguities, including ones which are LANGSEC-relevant like
handling of duplicate keys.
Does this all sound a bit like reinventing csexps? Sure, but I strongly
doubt we'll see a csexp revival any time soon. I would like to carry
forward the best ideas of csexps, but with a succinct and easy-to-read JSON
As for ASN.1, there are encodings that seem fairly reasonable like OER. But
the reality is BER/DER won, and if you're doing any IETF specification work
they're what you'll be strongly encouraged to use. Yes BER/DER are more
compact than OER or something like Protocol Buffers (although there's PER
if you really want to save space), but this comes at the cost of an awful
lot of complexity which has been the source of countless parser bugs.

@_date: 2017-11-17 11:13:04
@_author: Tony Arcieri 
@_subject: [Cryptography] Is ASN.1 still the thing? 
You have pretty much just described the architecture of Google Trillian:
Trillian's log-derived maps consist of two logs: a Merkle log of operations
to apply to a verifiable map (i.e. sparse Merkle tree), and another log
that checkpoints the new Merkle roots of an updated verifiable map after
the operations have been applied.
Ethereum does something similar with Merkle Patricia Trees:

@_date: 2017-10-18 09:48:33
@_author: Tony Arcieri 
@_subject: [Cryptography] Miscreant: multi-language misuse resistant 
I just published a blog post on a set of libraries for Go, Python, Ruby,
Rust, and TypeScript which implement two simple misuse resistant
authenticated encryption modes of AES:
You can find all of the libraries here:
Particularly notable is AES-PMAC-SIV: a parallelizable variant of the
original AES-SIV construction (which was based on CMAC) which provides much
better performance.

@_date: 2017-10-19 14:51:28
@_author: Tony Arcieri 
@_subject: [Cryptography] Severe flaw in all generality : key or nonce 
Aside from the "nonce reuse under the same message reveals you encrypted
the same message twice" property, this is true of AES-SIV (based on CMAC)
and its parallelizable variant AES-PMAC-SIV, which I just released in
An alternative is to work in blocks of some fixed length, with the property
And I am interested in supporting both CHAIN and STREAM as online
authenticated encryption (OAE2/nOAE) modes!

@_date: 2017-10-20 18:15:15
@_author: Tony Arcieri 
@_subject: [Cryptography] Severe flaw in all generality : key or nonce 
I'll note that AES(-CMAC)-SIV and AES-PMAC-SIV both use a stream cipher for
encryption (AES-CTR), but are not susceptible to nonce reuse
vulnerabilities because they're MRAE constructions.
The reality is a bit more nuanced than "NOT A STREAM CIPHER"

@_date: 2018-02-06 16:54:31
@_author: Tony Arcieri 
@_subject: [Cryptography] Proof of Work is the worst way to do a BlockChain 
There will be a number of proof-of-stake systems launching this year. I
could say that they operate under a slightly different threat model than
Bitcoin: they are "permissionless" in that anyone can spin up their own
chain at any time and interoperate with other chains, but each chain is
operated by what is effectively a cabal, which does not fit some people's
definition of what "permissionless" and "decentralized" should mean...
...except the vicious cycle of proof-of-work has lead to the exact sort of
cabal proponents of some platonic ideal of "decentralized" hope to prevent:
it only takes two mining pools, either in collusion or through compromise,
to pull of a so-called 51% attack against Bitcoin with the current miner
distribution, and greater-than-99% of all Bitcoin transactions will be
confirmed by less than a dozen mining pools. The experiment is a failure:
proof-of-work does not work and is not a valid solution to the
"decentralization" problem.  Several chains operated by several cabals
sounds like it does a better job of being "decentralized" than one chain
operated by one cabal.
To keep up with the state-of-the-art in Bitcoin mining today, and actually
mine at a hash rate where you stand a decent chance of producing winning
blocks at a semi-frequent rate, you are looking at building something like
Where datacenters like that might inspire awe, the absolutely ridiculous
aspect of it is the actual useful work being accomplished by that
multi-silo datacenter facility and all of the miners around the world,
collectively, to the tune of 4 gigawatts of energy expenditure, could be
accomplished in a centralized system by a Raspberry Pi hooked to the
Internet by a 28.8kbps modem.
If we simply accept that nature abhors a vacuum and regardless of what
incentive structure you offer to system operators the system will naturally
move towards being operated by a cabal of the most proficient people,
well... that doesn't sound like the worst thing in the world to me (it
sounds like human nature), except in the case of Bitcoin that thing happens
to be building the biggest electricity waster.
If you change the incentive structure to something like a delegated
proof-of-stake system, the incentive for validators becomes building and
operating a system with high availability, high security, and the
bandwidth, storage, and compute resources to keep up with what could be a
so-called "big blocker's" fantasy. This would eliminate the sort of utopian
dream of "anyone can run a Bitcoin node" but that too is an idea I find
highly questionable. If the validators (and things like inter-chain peg
zones, auditors, and a handful of other use cases) are the only ones who
need to see the firehose, it can move much, much faster than the 4 tx/sec
Bitcoin is doing on-chain today, and the rest of the network can operate
using light clients.
It also means the system can come to consensus much faster, in seconds
rather than minutes, because the validators can run a traditional BFT
algorithm between each other rather than Bitcoin's
consensus-by-lottery/race condition. This means clients can be much simpler
than systems which use off-chain payment channel protocols, and there is no
(surprising) latency to open a channel: the system can operate at a scale
where transactions are confirmed on-chain at a reasonable rate to begin
A faster blockchain is a more expensive one to operate, but in the process
should also be a more lucrative one for system operators with respect to
transaction fees. Instead of investing in an arms race to do the best job
wasting electricity, we could be investing in compute resources to make the
system faster: a virtuous cycle instead of a vicious one.

@_date: 2018-02-07 10:26:01
@_author: Tony Arcieri 
@_subject: [Cryptography] RISC-V branch predicting 
Branch prediction in and of itself is not a problem. The core problem
underlying both Meltdown and Spectre is the CPU is speculating outside the
current protection domain, because access control protections on memory are
not enforced synchronously 100% of the time.
I don't think anything fundamentally needs to change about how ISAs or
speculation units are designed. What needs to change is how access control
to memory is checked. Speculation units should proceed until they hit a
memory access violation, at which point they should stop the current line
of speculation, avoiding the problem of speculating outside the current
protection domain strategically. The way to prevent a sidechannel is by
closing it.
In the RISC-V space, lowRISC has been doing a lot of research in the area
of adding more metadata to memory which can be used for better access

@_date: 2018-01-04 11:11:26
@_author: Tony Arcieri 
@_subject: [Cryptography] Crypto for optimistic transactions ? 
I'm curious if this can be solved with multiparty computation, perhaps
involving some additional honest-but-curious nodes

@_date: 2018-01-04 20:32:32
@_author: Tony Arcieri 
@_subject: [Cryptography] Speculation considered harmful? 
I think RISC-V makes for an interesting sidebar...
I have seen a lot of (mostly joking) calls for an earlier time when CPUs
didn't do speculative execution (often pointing to '60s era VAX systems or
what have you).
Most RISC-V CPUs that presently exist today do not implement speculation.
This is mostly just because for the most part RISC-V is a "puny core" and
where people are building larger RISC-V chips they're taking the "swarm of
puny cores" approach, e.g. this 4096-core CPU:
That said, adding speculative execution features to RISC-V is presently an
open research area (perhaps some companies have shipped RISC-V CPUs with
these features, but I am not presently aware of any)
In 20/20 hindsight of this whole debacle, I am curious if, along with
memory protections available in RISC-V CPUs such as an "every word tagged"
memory architecture, RISC-V can strategically eliminate this entire
bugclass, e.g. ensuring privilege checks are always synchronous because the
only physical path to the memory demands it. As far as I can tell it has
both a great foundation and is in the perfect place to solve these problems
correctly in a clean-room implementation.
The "swarm of puny cores" approach is a bad fit for a lot of problem
domains, so I'm curious to see if RISC-V implementations can evolve into
something a bit closer to what we'd use for typical "business logic"-heavy
server workloads.

@_date: 2018-01-05 10:33:29
@_author: Tony Arcieri 
@_subject: [Cryptography] Speculation considered harmful? 
This is absolutely untrue. There are *excellent* asynchronous event
frameworks for C++, which (unlike Node) also support multithreading, and
are designed to allow servers to process e.g. 40 gigabits worth of incoming
traffic via userspace networking:
Node is a toy. And that's all I'm going to say on this matter since the
topic is hardware.

@_date: 2018-01-05 13:38:00
@_author: Tony Arcieri 
@_subject: [Cryptography] Announcing XSTREAM v0.1: misuse-resistant public-key 
I'm pleased to announce the initial release of XSTREAM: a misuse-resistant
public key cryptography library built on top of Miscreant which provides
incremental/streaming encryption support:
FAQ available here:
XSTREAM is based on the STREAM construction, described here:
 Supported Languages
Like Miscreant, XSTREAM is available for 5 different programming languages:
Go, JavaScript/TypeScript, Python, Ruby, and Rust.
Miscreant has also recently been ported to .NET/C# and we hope to have a C#
XSTREAM available soon too.
 What is it useful for?
XSTREAM is intended for encrypting data-at-rest while supporting
incremental processing, such as encrypting files, database records, or
other "blobs" of data processed a chunk-at-a-time, so if you're encrypting
a 100GB file you don't need 100GB of RAM to encrypt it, but can instead
encrypt it in smaller chunks with a size of your own choosing. The
underlying STREAM construction ensures data is both authenticated and
processed in-order, with out-of-order or truncated data manifesting as a
MAC verification failure.
It is NOT designed to be a transport encryption protocol used to secure
data-in-motion, e.g. as part of an interactive network service. For those
use cases, we recommend you use TLS or Noise.
 Construction
XSTREAM's encryptor accepts a static X25519 public key as an argument.
Internally it randomly generates an ephemeral secret scalar value (i.e.
X25519 secret key), performs elliptic curve Diffie-Hellman, then uses the
resulting shared secret as an input to HKDF-SHA-256, which it uses to
derive a symmetric key for use with STREAM (using AES-128-PMAC-SIV as the
default cipher).
Conceptually XSTREAM is similar to NaCl's crypto_box() with an ephemeral
key, or libsodium's crypto_box_seal() which handles generating the random
ephemeral secret key for you. However, XSTREAM gracefully tolerates things
like RNG failures thanks to its nonce reuse misuse resistance[1], whereas
ciphers like (X)Salsa20 and (X)ChaCha20 leak the XOR of the plaintexts
under these conditions, and the Poly1305 authenticator leaks the
authentication key.
However, before you choose XSTREAM over crypto_box()/crypto_box_seal(),
please see the warning below.
[1]: XSTREAM is built on the misuse resistant AES-SIV and AES-PMAC-SIV
symmetric ciphers as implemented in Miscreant. You can read more about it
 WARNING
This is v0.1 of an unreviewed cryptography library. It should go without
saying that you shouldn't use it for anything serious yet.
That said, even if you're feeling a bit YOLO and want to use it anyway,
there's good reason not to yet: the design is not frozen and likely to
change. There is presently an open issue which is likely to result in
breaking changes:

@_date: 2018-01-06 18:14:36
@_author: Tony Arcieri 
@_subject: [Cryptography] Speculation considered harmful? 
A slightly more tangible approach is partitioning the cache around
protection domains:

@_date: 2018-01-07 19:56:22
@_author: Tony Arcieri 
@_subject: [Cryptography] Speculation considered harmful? 
This entire line of enquiry is literally why RISC-V exists. The RISC-V
foundation just said as much (after announcing no RISC-V CPUs were
vulnerable to Meltdown/Spectre):
"The RISC-V community has an historic opportunity to 'do security right'
from the get-go with the benefit of up-to-date knowledge. In particular,
the open RISC-V ISA makes it possible for many different groups to
experiment with alternative mitigation techniques and share results."
Clearly the exact solution to Meltdown/Spectre is still an open research
problem, but as it turns out researchers designing RISC-V cores were just
starting to look at things like speculative execution, and are
greenfielding in 20/20 hindsight of these vulnerabilities.
What might it look like in broad strokes? RISC-V cores are already built on
an every-word-tagged memory architecture which carries rich attributes with
every word of memory in the system. This has already been useful for things
like control flow enforcement, but would also enable things like ensuring
(as a guarantee, enforced by the circuit design of the CPU itself)
speculation stops at protection boundaries.

@_date: 2018-01-07 20:36:47
@_author: Tony Arcieri 
@_subject: [Cryptography] Announcing XSTREAM v0.1: misuse-resistant 
XSTREAM encryption performs Diffie-Hellman with a static public key and an
ephemeral private key. You can still think of these as a recipient and a
sender respectively, but if the recipient's public key is known in advance,
the sender can simply generate a random private key, perform Diffie-Hellman
with it completely offline, and then throw it away after encryption,
"stapling" the ephemeral public key to the resulting ciphertext.
This also has the interesting property that if the sender erases the
private scalar and shared secret, they will no longer be able to decrypt a
ciphertext they generated themselves, and is generally referred to as

@_date: 2018-01-08 19:31:24
@_author: Tony Arcieri 
@_subject: [Cryptography] Announcing XSTREAM v0.1: misuse-resistant 
RNGs can fail in more ways than a total entropy failure, such as CSPRNG
internal state being duplicated or rolled back, producing duplicated
ephemeral keys. This is exceedingly common with badly designed userspace
CSPRNGs (XSTREAM endeavors to always use the OS RNG, FWIW), and
catastrophic without MRAE.
Tony Arcieri

@_date: 2018-01-08 12:50:17
@_author: Tony Arcieri 
@_subject: [Cryptography] Decentralized Vs Distributed Blockchain 
Like it was when Paul Baran wrote On Distributed Communication Networks in
the '60s, "decentralized" is a meaningless buzzword, and "distributed" and
"federated" became the terms of choice after Baran's paper. We can try to
describe "decentralized" with terms like "no central operator", but this
applies to "federated" systems as well. We could say "decentralized"
systems operate using end-user controlled cryptographic keys, but that also
applies to systems like Signal and WhatsApp that are certainly centralized.
By routing all events through a single global event log, Bitcoin and other
so-called blockchain/DLT systems wind up being curiously more centralized
than many federated systems, with its capacity fixed as a global constant
regardless of how many nodes join the system.
Many centralized "blockchain" systems wind up looking like CT logs, with
one or more signatures securing the system instead of a proof-of-work.

@_date: 2018-01-21 18:22:44
@_author: Tony Arcieri 
@_subject: [Cryptography] RISC-V isn't the answer 
So FUD?
Which sidechannel issues? If you're alluding to Meltdown and Spectre,
RISC-V isn't vulnerable to either, because no RISC-V core supports
speculative execution yet (the closest thing is the BOOMv2 core, which only
does out-of-order execution)
There are, of course, numerous other potential sidechannels, from DPA to
EM. These attacks require physical access and aren't remotely exploitable
like Meltdown/Spectre. Any chip which isn't specifically designed to resist
them is almost certainly vulnerable, but that's a different threat model.
The important point about RISC-V with regard to Meltdown and Spectre is the
RISC-V architecture is a major research testbed, they are just starting to
look at speculative execution now, and now have the opportunity of 20/20
hindsight. They also have designs with great memory protection
architectures already in place (lowRISC).

@_date: 2018-01-22 07:45:41
@_author: Tony Arcieri 
@_subject: [Cryptography] RISC-V isn't the answer 
RISC-V is just an ISA. Someone could easily design a RISC-V core with
partitioned caches.
lowRISC provides an every-word-tagged memory architecture. This information
could be augmented to encode things like memory protection domains (or may
already include the necessary information, I have not done an exhaustive
survey of their tag bits), much in the same way KPTI is being leveraged as
a page-level protection with the Linux's kernel's assistance. With
information about the current protection domain encoded in every single
word of memory, caches and memory controllers could physically deny access
to words which are not tagged with the current protection domain. This
would provide a central point of enforcement for *synchronous* checks which
could prevent CPUs from speculating outside the current protection domain
in the first place.
I'm sure RISC-V designers will be researching both of these options, and
more. Far from being doomed, RISC-V is going to be arguably the most
exciting place for this sort of research.

@_date: 2018-01-22 16:32:29
@_author: Tony Arcieri 
@_subject: [Cryptography] RISC-V isn't the answer 
For an architecture like lowRISC (based on Berkeley's Rocket RISC-V core, I
believe), the answer is, for every word of memory (i.e. 64-bits) include a
set of attribute bits that control a number of rich attributes. lowRISC
also features complete physical separation of control and data, meaning
that it should be physically impossible for these out-of-band tags to be
interfered with by program logic.
If we have a separate cache for each protection domain, then that domain is
Much in the same way Meltdown was mitigated using KPTI to check page-level
attributes, an every-word-tagged memory architecture could respect
word-level attributes. This gives you the benefits of having shared memory
with the same protections you might hope to gain from a coarsely-grained
partitioned cache.
In this sort of architecture, speculation units could proceed until they
hit a memory access violation, at which point the memory becomes
inaccessible as enforced (via a synchronous check) by the various memory
subsystems. This should prevent the sidechannel from even happening in the
first place (i.e. all memory subsystems synchronously deny access to the
CPU for requests with insufficient privilege), without placing an undue
burden on speculation unit designers.
One approach I like is a massive number of simple cores that don't
 This approach is where RISC-V soars today:

@_date: 2018-01-25 09:50:34
@_author: Tony Arcieri 
@_subject: [Cryptography] RISC-V isn't the answer 
For SoCs with onboard RAM this isn't an issue.
For slotted ram, the memory controller can still use page-level attributes
ala KPTI. The tricky part is cache, and that can have the tag bits (as an
alternative to a partitioned cache others were proposing).
