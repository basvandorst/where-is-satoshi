
@_date: 2005-08-06 18:30:23
@_author: Sherri Davidoff 
@_subject: solving the wrong problem 
Reminds me of the White Knight from Alice in Wonderland, who doesn't
understand his threat model, and doesn't know how to effectively use
his tools:
`I see you're admiring my little box,' the Knight said in a friendly
tone. `It's my own invention -- to keep clothes and sandwiches in. You
see I carry it upside-down, so that the rain ca'n't get in.'
`But the things can get out,' Alice gently remarked. `Do you know the
lid's open?
`I didn't know it,' the Knight said, a shade of vexation passing over
his face. `Then all the things must have fallen out! And the box is no
use without them.''  `You see,' he went on after a pause, `it's as well to be provided for
every-thing. That's the reason the horse has all those anklets round
his feet.'
`But what are they for?' Alice asked in a tone of great curiosity.
`To guard against the bites of sharks,' the Knight replied. `It's an
invention of my own.'
Full text from the chapter:

@_date: 2007-12-30 17:56:56
@_author: Sherri Davidoff 
@_subject: Death of antivirus software imminent 
Interesting how "virtualization" seems to imply "safe" in the public
mind (and explicitly in that article) right now.... I'm sure with the
increasing use of virtualization, we'll start to see more VMware-aware
malware and virtual machine escapes in the wild. Another example of
putting many, many eggs in the same basket.
Here's a good article about the first public VMware escape, which
Intelguardians demonstrated at SANSFIRE this summer:
(Note: I'm biased, having worked on this project.)
What boggles my mind is that despite this, the DoD has still decided to
rely on virtualization software to keep classified and unclassified info
on the same physical systems:

@_date: 2008-08-27 12:06:54
@_author: Sherri Davidoff 
@_subject: road toll transponder hacked 
Anonymous travel is dead. Even for subway riders who still use tokens
and citizens that bicycle around town, the proliferation of cameras,
facial recognition technology, biometrics and RFID tagging will render
anonymity obsolete within a generation.
I believe the public's next battleground is to gain control over what
*happens* to our data, and how it's used. Right now there is very little
transparency. Transportation organizations are collecting a lot of
information about people, and there is very little public input or
disclosure regarding uses, length of storage time, or standards for
securing this data.
Boston's MBTA, for example, does not consider the CharlieCard's serial
number to be personal information, and it therefore reserves the right
to store rider histories associated with each card *indefinitely*. Even
when CharlieCards are obtained "anonymously" (not the majority) they can
always be linked to the financial transactions DB which also stores the
card serial number (ie. if you even once pay with credit card, your
CharlieCard is not anonymous any more). This isn't publicized; it's
information I obtained by doggedly calling the MBTA's IT department.
I believe the public should have the following rights:
- The public should have regular input on how long personal data is
stored and how it is managed.
- Disabled people and senior citizens should have access to the same
level of privacy as everyone else. (Right now in Boston, they cannot
obtain a CharlieCard without having their personal information
associated with the card and permanently stored by the MBTA.)
- Transportation organizations should be required to publicly disclose
what data is collected about individuals, and how long that data is stored.
- Individuals should be able to easily find out who has accessed their
travel histories and the purpose of disclosure.
- Transportation organizations that store personal data should be
subject to regular external audits to ensure that they are in compliance
with standards, and that they have implemented appropriate measures to
secure personal data. A summary of these results should be made public.
Personally, I don't want to have a history of my travel stored in any
database. Right now, purchasing a one-time CharlieTicket is a 30 cent
surcharge per ride, but it is the only way to take the subway in Boston
without creating a travel history. Privacy in public transportation
should be equally accessible to all citizens, regardless of financial

@_date: 2008-08-29 15:07:17
@_author: Sherri Davidoff 
@_subject: privacy in public places 
For folks that haven't seen it, next month's Scientific American is
about "The Future of Privacy":
The issue contains a nice discussion of "Privacy 2.0" by Esther Dyson.
"What is the best way to limit government power? Not so much by the
rules that protect the privacy of individuals, which the government may
decline to observe or enforce, but by rules that limit the privacy of
government and government officials. The public must retain the right to
know and to bear witness."
I thought this was an interesting contrast to Dan's comment from the
other day:
... Also, the article "Brave New World of Wiretapping" by Whitfield
Diffie and Susan Landau was also a terrific overview of the history of
wiretapping laws and how changing communications technology has impacted
intelligence operations (and vice versa).

@_date: 2008-02-21 17:33:22
@_author: Sherri Davidoff 
@_subject: cold boot attacks on disk encryption 
As soon as I heard about this research I had to try it out. My laptop (Thinkpad) has an encrypted Truecrypt partition.  I quickly made a modified bootable DSL usb memory dumper, powered the machine down, waited a minute, dumped memory, and found that I could recover passwords from multiple prior reboots. I was able to recover my Truecrypt password even if the volume was not mapped at the time of reboot, as well as GPG passwords, SSH passwords, etc etc. It was really easy.
During physical pentests, when I grab an encrypted laptop from an office, my clients usually respond that the laptop was "encrypted" and the data was therefore safe. That's not necessarily true, of course, but we don't have the time during these engagements to test out the security of the encryption products/implementation, and neither do most attackers.
Now attackers (or customs) just have to grab a live laptop, plug in a USB memory dumper and power cycle the system in order to obtain a dictionary of likely passwords and potentially recover encryption keys. Presumably tools to to accomplish this will soon be found in the wild and will become accessible to attackers with even low levels of technical skill.
I imagine this will eventually have a big impact on the way organizations respond to stolen mobile device incidents. With the current technology, if a laptop or mobile device is on when it's stolen, companies will need to assume that the data is gone, regardless of whether or not encryption products have been deployed.
Anyone familar with the laws in the arena? Are there regulations which require reporting only if data on a stolen device is not encrypted?

@_date: 2008-01-02 21:35:29
@_author: alien 
@_subject: Death of antivirus software imminent 
Today's VMMs aren't even designed to fit the formal criteria for a VMM
(at least as expressed, intelligently, by Popek and Goldberg back in the
70s).  VMM-aware malware leverages this: for example, by making calls to
VMware's "backdoor" communications channel from the guest (ie. jerry.c).
If the "equivalence" principle were actually upheld, this wouldn't be
possible-- but then again, users wouldn't have all those handy features
like cut-n-paste from guest to host.

@_date: 2008-07-25 11:28:15
@_author: Sherri Davidoff 
@_subject: cleartext SSH, Truecrypt, etc passwords in memory 
Hello all. During the past few months, I've been poking around Linux
memory and consistently finding cleartext login, SSH, email, IM,
Truecrypt and root passwords. I've just finished a paper which includes
detailed location and context information for each password. Given the
recent buzz about cold boot memory dumping, it seems the risk associated
with cleartext passwords in memory has increased.
You can find the paper here:
There are also a couple snippets of process memory up there for folks to
play with. Thought this might be of interest to folks on this list.

@_date: 2008-07-26 16:28:08
@_author: Sherri Davidoff 
@_subject: Surveillance, secrecy, and ebay 
Great point, and a fundamental lesson-of-the-moment for the security
industry. To take it one step further: The amount of sensitive
information an organization stores is roughly proportional to the number
of data leaks it initiates. We already know that information "wants" to
be free, and if you keep information around, sooner or later, it's going
to leak out. (There's probably some mathematical way to describe this
Rather than expecting companies to keep data totally secure and then
send apologetic letters when it gets lost, perhaps we should start
taxing companies in proportion to the amount of sensitive information
they store, and use that tax to assist victims of identity theft. This
would have the double benefit of giving companies immediate incentive to
reduce the amount of information they store, and would also provide
appropriate public funding for incident recovery.

@_date: 2008-07-26 19:40:23
@_author: Sherri Davidoff 
@_subject: cleartext SSH, Truecrypt, etc passwords in memory 
For this paper, I specifically examined the case where memory was dumped
while the applications were still active. The snapshots were taken up to
45 minutes after the passwords were entered. (See Appendix A for the
full testing procedure.)  Given that users keep applications such as
SSH, Truecrypt, email, etc open for a significant percentage of time
that they use their systems, I do think it's important for applications
to zero sensitive data immediately after it is used rather than waiting
until the process is closed. Also, as you point out, there were
passwords such as SSH and root which were retained outside of the
application's memory.
I also did some preliminary experiments to test whether passwords
remained in memory after the applications were closed. However, I
decided to wait until the Princeton/EFF/Wind River folks released their
memory dumper code before analyzing this in detail. As described in the
paper, there are now annoying limitations on access to /dev/mem in
Linux, so I thought it would be best to approach this particular
question by getting a full memory image using cold boot techniques.
As a next step, it would be great to follow the same procedure, but
image all of memory after the applications have been closed. Using Jake
Appelbaum and co's newly released memory imaging tools would probably be
an easy way to get full memory dumps from any OS:
Based on your feedback, I've updated section 2 and the abstract to clarify:
Thanks for your comments,
