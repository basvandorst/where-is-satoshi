
@_date: 2001-12-09 19:32:34
@_author: Lucky Green 
@_subject: FreeSWAN Release 1.93 ships! 
The big question is: will FreeS/WAN latest release after some 4 or 5
years of development finally both compile and install cleanly on current
versions of Red Hat Linux, FreeS/WAN's purported target platform?
--Lucky, who is bothered by the fact that most his Linux using friends
so far have been unable to get FreeS/WAN to even compile into a working
kernel, while just about every *BSD distribution - and for that matter
Windows XP - ship with a working IPSec implementation out-of-the-box.
A number of small improvements have been added to this release, which
was shipped on-time.
Some highlights:
* Diffie-Hellman group 5 is now the first group proposed.
* Two cases where fragmentation is needed will be handled better, thanks
   to these two changes
        The code that decides whether to send an ICMP complaint back
        a packet which had to be fragmented, but couldn't be, has gotten
        smart enough that we now feel comfortable enabling it by
   and
        IKE (UDP/500) packets which were large enough to be fragmented
        to be mishandled, with some of the fragments failing to bypass
        tunnels properly.  This has been fixed; our thanks to Hans
* If Pluto gets more than one RSA key from DNS, it will now try each
   This will help when a system administrator replaces a key.
* There is preliminary support for building RPMs.
* SMP support is better.
* The team has eliminated a vulnerability that might permit a denial of    attack.
     We are in the process of chasing down a couple of significant bugs
     have been there since at least 1.92 and possibly earlier), and we
     ship another release quite shortly if we nail them down and fix
them.  If
     we don't, we won't.  Barring that possibility, the next release is
     for the end of January; a more precise date will be announced

@_date: 2001-12-10 20:53:19
@_author: Lucky Green 
@_subject: FW: FreeSWAN Release 1.93 ships! 
While I am too far from the process to offer comment to the contents of
the post below, the last paragraph of the post in some bizarre way did
help crystallize a thought that I knew had been nagging in the back of
my mind for months, perhaps as much of a year, but that I just could not
quite bring to the foreground.
FreeS/WAN occupies a position very rarely found in efficient markets,
such as open source software. While the position is rarely encountered,
it can nonetheless exist: I believe that FreeS/WAN is a natural
Natural monopolies are usually only found in extremely small markets.
The economic textbook example is a power company on an island of 50
people. The market size is simply too small to sustain the overhead of
two companies, no matter how efficient both companies may become.
Therefore, the market doesn't attract competitors, even absent any
regulatory market distortions. (Hence the "natural" in "natural
monopoly" :-)
But for whatever reasons, FreeS/WAN has been holding such a natural
monopoly position in by far the largest market in which I have ever seen
such a beast. I find this fascinating. I wonder if economists will some
day study the case to determine what factors brought it about.
[I presume somebody other than the FreeS/WAN project may have written a
few lines of Linux open source IPSec code, but they aren't competitors
in that market any more than a guy walking around with a charged car
battery offering service would be a competitor to the power company in
the island example].
--Lucky, who simply had to share this revelation. Back to writing
Mixmaster remailer code.
-----Original Message-----
Behalf Of Anonymous
Sent: Monday, December 10, 2001 7:54 PM
On Sunday 09 December 2001 07:32 pm, Lucky Green
The latest releases of both Suse and Mandrake are both able to install
kernels with Freeswan already integrated.  It's a little newer addition
to Mandrake, so you may want to use Suse.  Suse makes it easy to set up
encrypted file systems and other nice features.
The major problem that holds back the development of FreeS/WAN is with
its management.  [Management that cares more about sitting on its
pulpit, than getting useful software into the hands of people.] Unless
things have changed recently, they still won't accept contributions from
the US.  This makes no sense.  GPG is shipping with every Linux
distribution I know of, and the German's take contributions from the US.
The primary kernel developers have been willing to integrate crypto into
the kernel since the crypto regs were lowered.  It's the policy of no US
contributions that's holding back Linux IPSEC.
IMHO:  If Freeswan had never been created, an alternate, more mature
implementation would already exist in the mainline Linux kernel.

@_date: 2002-04-22 18:35:29
@_author: Lucky Green 
@_subject: Lucky's 1024-bit post [was: RE: objectivity and factoring analysis] 
Anonymous wrote (quoting Adam):
Rather than continuing with guesses by those that were not present at
the time as to my motivations and objectives behind my post, allow me to
establish the facts and thought processes that lead to my original post.
Prior to the panel at FC, I held the belief that 1024-bit RSA keys could
not be factored in an operationally significant timeframe irrespective
of the budget of the attacker. I know that this belief was held by many,
if not most, of the implementers of cryptographic production systems and
believe that it was held by many, if not most, cryptographers. In some
sense, if this belief had not been held so widely, current debate would
not be as heated.
So let's look at the supposed mistakes Anonymous asserts I made:
1) As is the case with many panel discussions, and in many cases the
reason for choosing a panel format rather than an individual presenter,
the panelists, Ian Goldberg and Nicko van Someren, were selected to
represent subject matter experts in different areas of relevance to the
subject to be discussed: Ian's role was to help determine the
mathematical impact and correctness of Bernstein's proposal: are the
mathematical assumptions correct? Did the author make a mathematical
error in the paper? Ian did not identify errors in the math, though
cautioned that the interconnections required by an actual device would
represent a challenge of significant engineering impact. (Which, as
Nicko addressed in his previous posts to this list, he too considered to
be the limiting factor on performance).
Having thus established, as well as it could been established at the
time, that the paper that triggered the discussion appeared to not
contain mathematical errors, Nicko, as the subject matter expert in
building cryptographic hardware implementations, presented what the math
meant from an engineering perspective. In particular, can a device be
built based on the mathematical assumptions, how much would it cost to
build such a device, and what would the device's operating
characteristics be?
It is correct that Nicko presented estimates that literally were being
refined during the panel session. Naturally, I would not have even
considered posting such hasty generated estimates to a widely-read
mailing list. (More on that later).
Interestingly enough, the reaction to the estimates from the attendees
at the conference, which contained many well-known cryptographers, was
quite different from what I would have expected. Nobody stood up, and FC
is a conference quite amenable to open discussion, that they found the
suggestion that 1024-bit RSA could be broken by a well-resourced
attacker in operationally significant times to be unrealistic. The most
vocal comment in the ensuing discussion came from Yvo Desmedt, who
pointed out that no expert in the field should be surprised by these
results, since it was pointed out in Beth, Frisch, and Simmons
"Public-Key Cryptography: State of the Art and Future Directions, LNCS
578, published in back 1992, ten years ago, that 1024-bit keys would be
suitable for protection against a national adversary for about another
10 years: until about 2002. As it so happens, this the year 2002.
Given how panels are assembled and the role they fulfill, I thought it
would be understood that when one writes that certain results came out
of a panel that this does not imply that each panelist performed the
same calculations. But rather that that the information gained from a
panel (Ian: math appears to be correct, Nicko: if the math is correct,
these are the engineering implications of the math) are based on the
combined input from the panelists. My apologies if this process of a
panel was not understood by all readers and some readers therefore
interpreted my post to indicate that both Ian and Nicko performed
parallel engineering estimates.
2) Immediately after the panel, a reporter for the Financial Times in
attendance approached me, inquiring if these estimates had already been
published in the media. I told him that I was not aware of any such
publications and that this was the first time I had heard these
estimates. He informed me that he intended to publish this information
in a matter of days. I don't know if he wrote the article or not; I am
not a Financial Times subscriber.
It was not until at least a week after FC that I contacted Nicko
inquiring if he still believed that his initial estimates were correct,
now that that he had some time to think about it. He told me that the
estimates had not changed. We now, after the calculations had been made
public and because the calculations had been made public, that Nicko's
calculations contained an oversight which was not discovered until much
later. While the oversight changed the speed by which a 1024-bit RSA key
could be broken by such a device, no correction to the calculations that
I have seen so far indicated that 1024-bit keys could not be broken in
an operationally significant time frame well below the expectations of a
large percentage of users that had fielded 1024-bit systems.
In short, the information I relayed was as authorative as any
information you are likely to obtain from a panel discussion. If you
want information to be more authorative, you would have to cite a
research paper on the topic. Papers that I am sure we all hope will be
written soon. One might hold that only security-relevant information
that represents the long-term universal consensus of the academic
community should ever be distributed to the public. I respectfully
disagree with this viewpoint.
Given the above, I fail to see the foundation for the claims made by
Anonymous that I relayed the information to the community hastily or
presenting it as anything other than what it was: new (at least to me)
and interesting information with potentially significant security
implications to a potentially wide number of current users of public key
cryptography-based authentication and confidentiality systems.
3) One of the claims Anonymous makes is that I revoked my key
precipitately. I did indeed upgrade the entire security infrastructure
under my direct control to keys larger than 1024-bits following the to
me new estimates indicating the feasibility of attacking such keys. And
I didn't enjoy the process. There is an old saying, of which I heard
varying versions over the years in the cryptographic community, which is
also published in AC, though I don't know if it originated with Bruce or
predates the publication of AC. The saying is that there are two kinds
of cryptography: the kind that will keep your kid sister from reading
your writings and the kind that will keep national governments from
reading your writings. Of the two, it is the latter kind that interests
me and that presumably interests most working in the field.
Since my original post, even some of the loudest voices in support of
the position that 1024-bit keys are safe have published tables that
indicate that 1024-bit keys are expected to be breakable by a
well-resourced attacker in a few years, if they are not already. See the
RSA Labs FAQ and Bruce's recent Cryptogram for some of those estimates,
both of which are readily available on the web. I have seen similar
tables in other communications.
A key size which that is widely considered to be insufficient to offer
security against passive cryptanalytical attack by a dedicated attacker
and its customers is not a key size that I consider desirable. Nor is
this the level of security many customers of cryptographic products are
told they are afforded by 1024-bit keys.
Since Moore's Law has made it faster for me to use a 2048-bit key today
than it was for me to use a 1024-bit key back when I began using
1024-bit key on a daily basis as an alpha tester of PGP 2.0, the logical
step was to upgrade key sizes. Was my doing so precipitately? One could
argue that it was unscheduled. The sole reason why the upgrade was
unscheduled was because I previously failed to act on the results of the
various key size viability studies starting with Beth and Frisch, moving
to the NIST recommendations quoted in the RSA Lab's FAQ, to Bruce's 1995
figures republished in his latest Cryptogram in which he pointed out
that he predicted 7 years ago that 1024-bits should not be considered
sufficient against a well-resourced attacker by the year 2000. If there
is one mistake related to my action surrounding this debate that I
perhaps can reasonably be chastised for, it is that I failed to remove
1024-bit keys from my security infrastructure sooner.
As Bruce put it in his Cryptogram: "To me, the big news in Lucky Green's
announcement is not that he believes that Bernstein's research is
sufficiently worrisome as to warrant revoking his 1024-bit keys; it's
that, in 2002, he still has 1024-bit keys to revoke."
How the anonymous author of the post criticizing my action of
publicizing that I, and dozens of attendees at a cryptographic
convention, heard evidence that 1024-bit keys are in danger of
compromise hopes to gather support for his contention  from my having
failed to revoke my keys sooner is beyond my comprehension.
To just make a minor comment on Bruce's quote, Bernstein's paper simply
triggered the discussion now underway. Looking back at all the expert
predictions, from the workshop in 1992, to Bruce's estimates from 1995,
to the NIST recommendations years ago, it appears that time and Moore's
Law have simply crept up on us and nobody really noticed.
Which brings us to why the current discussion is so heated and my post
is by some considered to be so "alarmist": just about everybody with a
few notable exceptions, from the community, to the vendors, to the
public failed to act on the numerous expert predictions that all stated
the same fact for a decade: 1024-bit RSA keys are either breakable today
or will be so very shortly. To put it bluntly, a good percentage of us
have been caught with their pants down. In many cases leaving their
customers with deployed, difficult to upgrade, security infrastructures
that were either built or selected based on our recommendations.
Some of us, myself included, chose to bite the bullet, take the painful
remedial actions, and confess to it in public. Others chose to pursue a
different response, in some cases quoting predictions that state that
1024-bits are either already breakable today or will soon be breakable
while simultaneously asserting that by-and-large 1024-bit keys are good
enough. Others continue to insist that 1024-bit keys are unbreakable and
will remain so for the lifetime of a deployed system irrespective of how
well resourced the attacker. I sincerely hope they are correct, but
based on what I know now, I am no longer willing to base a security
infrastructure on that hope. Nor would I recommend doing so to others.
As always, I have faith that now that the interest has been raised and
the predictions of old have been dusted off and republished, the
scientific process will fulfill its role to determine fresher, more
accurate figures.
I fully agree that higher levels of details lead to faster, more
efficient analysis and a more efficient scientific process. What further
complicates matters is that the resolution of this question has
significant implications to many of the participants in the discussion.
And while healthy disagreement between participants helps further the
state-of-the art, some of these disagreements may lend themselves to
misinterpretation by interested, and potentially impacted, observers
outside the community.
For example, Bruce has been quoted in a widely-cited eWeek article that
"I don't assume that someone with a massive budget has already built
this machine, because I don't believe that the machine can be built".
Bruce shortly thereafter stated in his Cryptogram newsletter that "I
have long believed that a 1024-bit key could fall to a machine costing
$1 billion."
Since these quotes describe mutually exclusive view points, we have an
example of what can happen when a debate spills over into the popular
media. The only way to avoid such confusion would be to exclude those
outside of the cryptographic community from the discussion by not
communicating with the information intermediaries that the press
represents. But given that the enterprise and the public places their
faith into the results of our work, and given the potentially large
implications if 1024-bit keys are subject to cryptanalysis, I believe
that those directly impacted by this issue have a right to know about
it. I therefore am quite unapologetic for not having limited my report
on the interesting events that took place at Financial Cryptography 2002
to a post to sci.crypt. Not that doing so would have necessarily ensured
that the debate would not spill over outside the cryptographic

@_date: 2002-04-23 19:46:06
@_author: Lucky Green 
@_subject: Lucky's 1024-bit post [was: RE: objectivity and factoring analysis] 
Allow me to shed at least some light on the strange phenomenon that you
experienced for I have experienced the same phenomenon and was able to
glean at least a few of the reasons why application authors and
maintainers have proven so reluctant to increase RSA key sizes or
mandate minimum key sizes in their applications.
1) Very, very few applications, and no cryptographic libraries that I am
aware of, that currently employ RSA perform any kind of sanity check on
the size of the keys. The current release version of various programs
that I looked at will happily accept a 4-bit RSA client key that anyone
could factor in their head. VeriSign not too long ago signed a 384-bit
SSL server key that may readers of this list could break with the old
computers in their home. Such certificate signing practices, or their
lack thereof, are nothing short of irresponsible.
I have not tested the following hypothesis and am not willing to spend
the required $125 on the experiment, but I would not be in the least
surprised if many public CA's would readily sign a certificate for a
4-bit RSA key. C.f. the "being caught with one's pants down" observation
in my previous post. If somebody want to perform this experiment, better
do it quick, since the CA vendors read this mailing list. :-)
There are some positive examples: as a result of my original post, the
next release version of OpenSSH will enforce a 768-bit minimum size on
the key. I have not been following the discussion that lead to the
determination of this figure and therefore  don't know on which
cryptological results the OpenSSH designers based that number.
However, I note that even those experts that I am aware of which assert
that 1024-bit keys are sufficient for the type of long-term use SSH
client keys are frequently employed for do not appear to claim that
768-bit keys should be considered secure today.
Unfortunately, the OpenSSH designers have chosen to not expose the
minimum key size requirement via the sshd configuration file, though at
least there now there will be a known spot in the source that can easily
be patched to a value the server operator might consider to be more in
line with current key size recommendations. I thank the OpenSSH team for
at least providing an easy hook to make the desired changes in the
source, though of course I would like to see both a larger default and a
corresponding option in the config file. Still, hats off to the OpenSSH
team for moving implementing sanity checks that few other vendors have
bothered to implement.
Some other deployed applications either use libraries that can't go
higher than 1024-bits or have the key sizes and structures hard coded
all over the source, making a chance expensive and uneconomical absent
severe customer pressure on the vendor. A much cheaper solution than
rewriting good chunks of the core crypto processing code (or worse,
having to upgrade hardware that is limited to 1024-bits) is putting out
a press release stating why the customer doesn't need keys larger than
1024-bits, which some claim is one of the many reason why there is so
much resistance to moving to larger keys. I am not quite ready to
subscribe to such cynical a view point, but I heard that view point
voiced by several crypto old-timers in private conversations more than
2) One frequently voiced argument against increasing key sizes is the
resultant decrease in performance. Yes, it is absolutely true that
increasing the size of an RSA key leads to a decrease in performance.
However, larger keys decrease performance less than naive experiments
may seem to indicate. For many applications, generating a 2048-bit key
and comparing the performance with that of a 1024-bit key will lead to
numbers that differ widely, much more so than can be attributed to the
larger key size. The reason for this phenomenon is that RSA algorithm performance is
highly dependent on optimizations that are both key size and processor
specific. The same optimization strategy that will give you blazingly
fast performance with a 1024-bit key will absolute kill performance with
a 4096-bit key, for which a different optimization strategy is needed.
Similarly, optimizations are highly processor specific. An optimization
designed specifically for a Pentium III processor will run slower on a
Pentium IV than your basic Pentium optimized code would.
Some applications offer the correct optimizations for each key size.
Others just optimize for 1024-bit keys, thus leading to abysmal
performance with some larger keys.
Example: PGP appears to offer excellent performance optimizations across
all key sizes. The performance difference between a 1024-bit RSA key and
a 4096-bit key can't be much more than a second. (I didn't directly time
this, but I can hear when the outgoing mail from my laptop hits the mail
spool on my SMTP server; the increase in lag is insignificant from a
user perspective).
OpenSSH with 4096-bit keys on both ends on a 450 and 333 MHz machine
respectively is noticeably slower than with 1024-bit keys, perhaps by a
couple of seconds, but still well within user tolerance. I suspect
additional optimizations are possible which would decrease the lag
PuTTY SSH, on a 750MHz CPU with a 4096-bit key on both sides simply
crawls. I am looking at some 12+ seconds before I see the shell prompt
from the same 333MHz server used in the example above. Apparently,
optimizations for larger keys are missing from this program.
In summary, I would like to see more applications that are currently
utilizing RSA to enforce sanity checks on the keys with reasonable
defaults, offer the administrator a choice to change these defaults via
a configuration option that doesn't require patching the source, and see
more applications that use RSA processing code to utilize key
size-specific optimizations, which would significantly decrease the
currently experienced performance differences with many of those

@_date: 2002-08-06 01:05:44
@_author: Lucky Green 
@_subject: USENIX Security TCPA/Palladium Panel Wednesday 
I am scheduled to moderate a panel on TCPA and Palladium at the upcoming
USENIX Security Conference this Wednesday in San Francisco.
Representatives of Microsoft's Palladium project and the EFF have
confirmed their participation.
See  for details.
The slides of the talk on TCPA that I gave over the weekend at DEFCON
are now available at Hope to see you all at USENIX,

@_date: 2002-08-06 02:05:55
@_author: Lucky Green 
@_subject: Challenge to David Wagner on TCPA 
Probably not surprisingly to anybody on this list, with the exception of
potentially Anonymous, according to the TCPA's own TPM Common Criteria
Protection Profile, the TPM prevents the owner of a TPM from exporting
the TPM's internal key. The ability of the TPM to keep the owner of a PC
from reading the private key stored in the TPM has been evaluated to E3
(augmented). For the evaluation certificate issued by NIST, see:
It appears the days when this was true are waning. At least in the PC
platform domain.

@_date: 2002-08-06 02:24:55
@_author: Lucky Green 
@_subject: dangers of TCPA/palladium 
Though routinely professing otherwise, evidently Anonymous knows nothing
of the spirit of the TCPA: I proposed the use of blinding schemes to the
TCPA as far back as 2 years ago as a substitute to the Privacy CAs
schemes which are subject to potential collusion. I believe
"unreceptive", rather than "very much open to this suggestion" would
more accurately describe the TCPA's spirit Anonymous holds so high.
--Lucky Green

@_date: 2002-08-08 15:20:22
@_author: Lucky Green 
@_subject: Utilizing Palladium against software piracy 
I would like to again thank the Palladium team, in particular Peter
Biddle, for participating in yesterday's panel at the USENIX Security
conference on Palladium and TCPA.
Unfortunately I do not have the time at the moment to write up the many
valuable and informative points made during the panel discussion. I
will, however, highlight one such issue:
As Peter pointed out, while the Palladium effort was started to meet the
content protection requirements of digital video content providers, he
also pointed out that Microsoft and its Palladium group have so far been
unable to determine a method in which Palladium could be utilized to
assist in the efforts against application software piracy. As Peter
mentioned, the Palladium team on several occasions had to tell the
Microsoft's anti-piracy group that Palladium is unsuitable to assist in
software (as distinct from content) licensing and anti-piracy efforts.
Since Microsoft is not aware of a method to utilize the Palladium
environment in the enforcement of software licenses, Peter argued,
Microsoft does not intend to and will not utilize Palladium to assist in
the enforcement of software licensing.
I, on the other hand, am able to think of several methods in which
Palladium or operating systems built on top of TCPA can be used to
assist in the enforcement of software licenses and the fight against
software piracy. I therefore, over the course of the night, wrote - and
my patent agent filed with the USPTO earlier today - an application for
an US Patent covering numerous methods by which software applications
can be protected against software piracy on a platform offering the
features that are slated to be provided by Palladium.
--Lucky Green

@_date: 2002-08-09 00:48:21
@_author: Lucky Green 
@_subject: Challenge to TCPA/Palladium detractors 
The above view may be overly optimistic. IIRC, nobody outside PGP was
ever able to compile a PGP binary from source that matched the hash of
the binaries built by PGP. --Lucky Green

@_date: 2002-08-10 15:13:49
@_author: Lucky Green 
@_subject: FAQ: How will Microsoft respond to Lucky's patent application? 
I have received numerous questions in conversations and interviews over
the last few days as to what I believe Microsoft's response will be to
my recent patent application for methods that utilize Palladium and
operating systems built on top of TCPA to assist in the fight against
software piracy.
Rather than continuing to repeat the same answers in conversations, I
will simply make the answers available to the lists. Obviously, the
following is my personal opinion. I don't profess to speak for
Allow me to first outline some principles of how patents work in the
U.S. Note that I am not a member of the federal Patent Bar and as such
the following is simply my limited understanding of the process and
should not be construed as legal advice.
For a patent to be valid in the U.S., the idea to be patented must offer
utility, be novel, and be non-obvious. I will address the three
requirements as I believe they apply to my patent application in turn:
Utility: According to the Business Software Alliance's website, in the
financial loss to U.S. society due to software piracy in the year 2000
alone amounted to a staggering USD 7.2 billion. I therefore don't
believe it can be reasonably argued that methods that may help reduce
the level of software piracy lack utility. In particular, I don't
anticipate Microsoft to argue that protections against software piracy
that assist in the enforcement of licensing agreements lack utility.
Novelty: As I mentioned in my earlier post, Peter Biddle, Product Unit
Manager for Palladium, very publicly and unambiguously stated during
Wednesday's panel at the USENIX Security conference that the Palladium
team, despite having been asked by Microsoft's anti-piracy groups for
methods by which Palladium could assist in the fight against software
piracy, knows of no way in which Palladium can be utilized to assist
this end. Peter after the panel asked Brian LaMacchia, a well-known
security expert with Microsoft, who was present but not on the panel, if
he knew of a way to utilize Palladium to assist in the enforcement of
software licenses. Brian did not respond with a solution. (At that time
I briefly mentioned to both one of the methods in which I believe
Palladium can be used to assist in the fight against software piracy).
Peter, who obviously would have been aware of all such methods were they
known to the Palladium team, struck me as a forthcoming guy. While I
will readily admit that the impression I gained of the person over the
two hours I interacted with Peter may carry little weight with those
that consider the words Microsoft and honesty to be mutually exclusive,
I would like to point out the following:
If Microsoft, after so publicly denying any knowledge of ways to use
Palladium to assist in the enforcement of application software licenses
to an audience representing a veritable who's who of computer security
and related public policy (the attendees ranged from Whit Diffie to Pam
Samuelson), were to - after my filing for a patent - suddenly assert
prior art, neither the attendees, nor the press, nor the public would
take kindly to having been so deliberately misled by Microsoft.
The likely result would be that Palladium will lose what limited support
the initiative may have at this time. I suspect that even somebody that
may have a low opinion of Microsoft will agree that Microsoft is not as
stupid as to play such a dangerous and losing game.
I was asked the next day at USENIX if Microsoft could not simply claim
prior art when in fact they had none at the time my invention was made.
I would like to reiterate my points made above and add that such claims
would need to be filed under oath. Whatever one's opinion of Microsoft
may be, I doubt that the salaries paid in Redmond are sufficiently large
to goad a mid-level employee into committing perjury.
Lastly, it does not matter for the above analysis if any supposed prior
art were to  be claimed to be created by Microsoft or third parties. It
is simply inconceivable that the scientific members of the Palladium
team would have been unaware of any such prior art given the their many
years on the project and the thorough research they engaged in as
evidenced by the lengthy DRM OS patent. If prior art existed, the
Palladium team would unquestionably have known about it and thus been
able to tell their anti-piracy group and the attendees at USENIX about
methods to utilize Palladium as a tool in the fight against software
piracy. Since they did not, the reasonable conclusion is that no such
prior art exists.
Obviousness: In the interest of brevity, I will simply state that if the
Palladium team has not thought of such methods in the years they worked
the project every day, the methods mentioned in my patent application
cannot conceivably be considered obvious.
In summary, at this time I am not aware of any grounds on which
Microsoft could challenge my patent once/if it will be issued. I
therefore currently do not anticipate that Microsoft will challenge the
Lastly, I feel obliged to mention that it is quite irrelevant what I,
Microsoft, or the subscribers to this list believe to be the case with
respect to my patent application. All that matters is what the patent
examiner at the USPTO believes. Unless one of the subscribers to this
list happens to work as a patent examiner.
--Lucky Green

@_date: 2002-12-10 02:08:00
@_author: Lucky Green 
@_subject: PGPfreeware 8.0: Not so good news for crypto newcomers 
I found PGP 8.0 to be well-designed and easy to use. If all one has is
time, the calculation might turn out different, but if one values ones
time and likes to use PGP without hassles, I would recommend spending
the money on a copy.

@_date: 2002-02-09 22:36:39
@_author: Lucky Green 
@_subject: PGP & GPG compatibility 
I believe such a standard already exists. It is called S/MIME. Best of
all, this email encryption standard is supported out-of-the-box by the
overwhelming majority of deployed MUA's in the world.

@_date: 2002-02-27 00:22:27
@_author: Lucky Green 
@_subject: Cringely Gives KnowNow Some Unbelievable Free Press... (fwd) 
If we can at all fit it into the schedule, IFCA will attempt to offer a
colloquium on this topic at FC. Based on the countless calls inquiring about
this issue that I received just in the last few days, the customers of
financial cryptography are quite concerned about the Bernstein paper, albeit
the paper raises a number of open issues that still would need to be
investigated before one should assert that the sky is falling.
See you all at FC,
--Lucky, IFCA President
----- Original Message -----
List'" Sent: Monday, February 25, 2002 12:25 PM
majordomo at wasabisystems.com

@_date: 2002-02-27 00:50:27
@_author: Lucky Green 
@_subject: theory: unconditional security 
While distribution of OTP's has become feasible amongst tightly-knit groups
of non-governmental actors, the rate at which OTP's can be generated has
fallen behind the rate at which data needs to be communicated between the
nodes. To give an example, creating  OTP's  to encrypt messages along the
lines of "the attack will take place at dawn on Thursday" was easy with WWII
technology and is even easier now. However, the sheer volume of data
transmitted between even small nodes today requires vastly larger OTP's than
was required for military or diplomatic communications in the past.
I am not aware of any RNG design in the open literature that would even come
close to generating the sheer volume of random numbers required by current
civilian communication patterns. I trust that I don't need to elucidate on
this list as to why a "solution" that would require the sender to limit the
use of OTPs to sending critical data while other data would be encrypted
using a different system will invariably lead to COMSEC failures.

@_date: 2002-07-04 17:08:43
@_author: Lucky Green 
@_subject: "Wild and Crazy": Interview with Palladium's Mario Juarez 
You will probably need to re-install the OS from CDROM on the new
machine. Which shouldn't be a big problem, since chances are that you
didn't do a large amount of customization on the 3DES encrypted OS
binary, anyway.
As for your application data, you typically should be able to go back to
the application vendor, assuming your maintenance license is current, to
have the vendor re-bind your data file encryption keys to the new TPM. I
am not aware of any such plans for non-user generated data, such as
purchased entertainment content, but then requiring the user to
repurchase such data when changing motherboards is not incompatible with
the content providers' business models.
--Lucky Green

@_date: 2002-07-04 17:12:15
@_author: Lucky Green 
@_subject: Palladium Eye & Ear Implants 
The copyright infringement and political disagreement chip in your head
would obviously stop you from even thinking about such a nefarious and
unpatriotic scheme. If you can't think about it, how could you execute
on it?

@_date: 2002-07-04 22:54:34
@_author: Lucky Green 
@_subject: Ross's TCPA paper 
You won't and Bill won't. But those who employ such NIC's will have no
difficulty obtaining certification.
Sure you can use shell scripts. Though I don't understand how a shell
script will help you in obtaining a dump of the protected data since
your script has insufficient privileges to read the data. Nor can you
give the shell script those privileges since you don't have supervisor
mode access to the CPU. How does your shell script plan to get past the
memory protection?
What am I missing?

@_date: 2002-07-06 19:05:20
@_author: Lucky Green 
@_subject: TPM cost constraint [was: RE: Revenge of the WAVEoid] 
Upon re-reading the paragraph I wrote, I can see how the text might have
been ambiguous. I was trying to express that there was a cost constraint
on the part. Adding the cost of an EMBASSY or SEE environment to the
purchase of every new PC is more than the market for bare-bones or even
mid-range PC's will bear.

@_date: 2002-07-11 01:22:18
@_author: Lucky Green 
@_subject: IP: SSL Certificate "Monopoly" Bears Financial Fruit 
Peter Gutmann wrote, quoting Matthias Bruestle:
One thing to keep in mind is that the name of the CA on the
pre-installed root cert in some cases will bean no relation to the
actual issuer of the cert. Just because the business of
some.trusted.ca.nil has gone under does not mean their root keys are out
of circulation.
"Trusted roots" have long been bought and sold on the secondary market
as any other commodity. For surprisingly low amounts, you too can own a
trusted root that comes pre-installed in >95% of all web browsers
In fact, it is considerably more expensive for an aspiring public CA
provider to incur the costs of policies and procedures development,
equipment expenditures, auditing cost, etc. required to have a root
added to browsers nowadays than it is to just buy an existing trusted
CA's Chrysalis or nCipher HSM.

@_date: 2002-07-11 17:25:11
@_author: Lucky Green 
@_subject: IP: SSL Certificate "Monopoly" Bears Financial Fruit 
I'd rather not state the exact figures. A search of SEC filings may or
may not turn up further details.
I am not sure I understand the question.

@_date: 2002-07-12 12:44:04
@_author: Lucky Green 
@_subject: IP: SSL Certificate "Monopoly" Bears Financial Fruit 
Precisely. Nor would worrying make any difference, since all CAs
preinstalled into the browser are equal from a user perspective. The
security  your CA, or VeriSign's CA, or anybody's CA can afford their
customer is subject to an upper bound set by the preinstalled CA with
the laxest certificate issuance standards in existence.
In other words, anybody who selects a public CA on a factor other than
price likely fails to understand the trust models that underlie today's
use of Certificate Authorities.
However, $250k will not nearly get you into the major browsers. Getting
into Netscape is easy. You just hand them the cash and the floppy with
your public key. Getting into MSIE is a lot harder. MSFT has never
charged to include a CA's key in MSIE and MSFT does not intend on
charging in the future. But after the root CA bonanza for MSIE 5, MSFT
instituted policy changes.
To get your CA's key included in MSIE, the CA must have passed an SAS 70
audit. (The CA also must offer its certificates to the public).
The infrastructure, policy, staff, and auditing costs of passing such an
audit will run you upwards of $500k.
By the end of the day, getting a new root into the browsers will cost
you about, give or take a few hundred k, $1M.
Which makes the slightly used nCipher box an even better value. :-)
--Lucky Green

@_date: 2002-07-13 20:55:22
@_author: Lucky Green 
@_subject: IP: SSL Certificate "Monopoly" Bears Financial Fruit 
I believe that Geotrust has come up with an excellent new model to make
money out of the CA business with minimum hassle to the customer while
reducing Geotrust's vetting costs down to next to zero. Their
introduction of this new model was one of the more interesting news at
this year's otherwise rather bland RSA Conference.
The cert shows as being issued by Equifax because Geotrust purchased
Equifax's root embedded in major browsers since MSIE 5 on the secondary
market. (Geotrust purchased more than just the root).
--Lucky Green

@_date: 2002-07-14 23:27:42
@_author: Lucky Green 
@_subject: IP: SSL Certificate "Monopoly" Bears Financial Fruit 
Enzo wrote quoting Lucky:
I suspect that until there is more case law related to digital
certificates, this question will be very challenging to answer.

@_date: 2002-07-20 09:38:25
@_author: Lucky Green 
@_subject: Maybe no stego on eBay afterall  
[About Stego on eBay]
We had some discussion on how silly this claim was on the cryptography
mailing list. Well, today Salon follows up on the story, and quotes Chet
    Chet Hosmer ... said that in his research, very few messages on eBay
  show signs of being infected by terrorists. About one in 100,000
  pictures "appears suspicious," but a much smaller number -- "one in
  every 15 to 20 million files" -- is "something that we really
  believe is a real hidden message."
I find it interesting, though not in the least surprising, that the
above quote assumes that all users of steganography are terrorists. From
this position it is a small step to the position that all individual
civilian users of strong/unescrowed cryptography are terrorists.
--Lucky "you didn't /really/ think the crypto wars are over or did you?"

@_date: 2002-07-20 09:55:16
@_author: Lucky Green 
@_subject: RIAA escalates attack on music piracy, wants "broadcast flag" 
[...]
    The idea is straightforward: Future hardware and software would
    music differently if it were designated as broadcast-only,
    users from saving it or uploading it. Currently programs like
    StreamRipper or StreamCatcher can record streaming music distributed
    through Webcasting.
    But because people might not use these new kinds of music receivers
    given a choice, new federal laws likely would be necessary to compel
    software and hardware manufacturers to abide by the broadcast-only
    designation.
    [...]
Gee. I wonder what this unspecified hardware could be the RIAA is
lobbying to be included in future PCs to prevent the copying of their
music. And I wonder which software components the RIAA is talking about.
Or which federal laws the RIAA has in mind to mandate both. Of course
only some wild-eyed "alarmist" would answer a) "Fritz Chip" TPM, b)
Palladium, c) Hollings Bill or its successors.
I must admit the tight coordination of this initiative across all stake
holders such as hardware vendors, software vendors, content aggregators,
governments, essentially everybody except the consumers, deserves
--Lucky Green

@_date: 2002-06-06 19:59:53
@_author: Lucky Green 
@_subject: Transparent disk encryption in *BSD this year 
The author of GEOM has recently added the first strawman crypto provider
to the FreeBSD 5.0 drive/partition manager offered by the new UFS2 file
Yes, I know it is a modest start. But given how much interest there has
been on the Net in transparent drive encryption, those familiar with
*BSD and inclined to provide constructive feedback, ideally in the form
of source code patches, are greatly encouraged to do so.
Those who lack the time to write code, but can read C and understand
crypto, are encouraged to look over the existing code and cryptographic
assumptions made in the code at the URL above to provide feedback on the
security of the system. (Please email the author directly rather than
emailing me).

@_date: 2002-06-21 14:56:10
@_author: Lucky Green 
@_subject: DOJ proposes US data-rentention law. 
IPSec is one solution, though I believe an easier way to deal with the
recent email data retention proposals in the US (and already existing
legislation in the EU) is the following:
Locate the button in your MUA that's labeled "Use secure connection" or
something to that effect, search the docs for your MTA for the words
"STARTTLS", "relaying", and potentially "SASL", don't use your ISP's
smtp server, encourage those that you are communicating with to do the
same, and the email data retention laws will be of no bother to you.
Anybody that's using postfix as their MTA is welcome to contact me for
more detailed instructions, though the above general instructions will
work for any decent modern MUA/MTA.
Check my mail headers for an example of what I mean. --Lucky "tap as much of my 3DES encrypted traffic as you desire" Green

@_date: 2002-06-21 14:58:16
@_author: Lucky Green 
@_subject: Shortcut digital signature verification failure 
Neat idea. So neat in fact that RSA Security has a patent on it. :-)
Sorry, I don't have the patent number handy.

@_date: 2002-06-22 03:16:37
@_author: Lucky Green 
@_subject: Secure mail relays [was:RE: DOJ proposes US data-rentention law. ] 
John wrote quoting Lucky:
I share John's dislike for the (thoroughly ineffective, except in making
the lives of legitimate users more difficult) anti-spam zealots and
anybody else upstream from me that deems it necessary or even acceptable
to do anything other than to forward raw IP packets addressed to my IP
address unmodified. In fact, I cautioned various anti-spam activists
back around 1994/95 where their objectives would lead, but it was to no
avail. An experience that John is undoubtedly familiar with.
Nonetheless, I would not run an open relay today simply due to the fact
that I want the postmaster alias to remain useful for submitting reports
of actual mail sub-system problems on my system. And, yes, because I
would loath to see cypherpunks.to's very pleasing 100Mbps upstream
connection cut.
Fortunately, what I am suggesting can be accomplished without running an
open relay on port 25, which /will/ cause you pain.
I am limiting relaying on port 25 smtp to authorized users by using
Cyrus-SASL, which integrates cleanly with postfix + TLS as the MTA.
Since Outlook only provides the plaintext variant of SASL
authentication, my MTA is configured to not offer smtp AUTH as an option
until after the TLS connection has been established to prevent
eavesdroppers from capturing the relaying authentication password.
Since more and more misguided ISP's are flat out blocking outgoing
connections to port 25 from inside their network, I have postfix
listening at a higher port number in addition to port 25, just as many
hosts today are running sshd on several ports to help compensate for
similarly misguided corporate firewall policies.
One probably could get away without using SASL just by running the smtpd
on a non-standard port, since AFAIK spammers only try port 25, at least
at the moment, but enabling SASL was so easy with postfix that I saw
little reason not to do so. Besides, it was the more esthetically
pleasing solution.
UUCP, eh? Well, having just watched my ISP's primary upstream provider
essentially melt down and the replacement likely to do so soon, I had
myself briefly considered retrieving my old UUCP books from storage just
in case the need should suddenly arise. :-) Hmm, I wonder where one gets
an UUCP link nowadays. Guess I should take a look at the current maps.
(The following offer is specifically for John: let me know if you'd like
a relay and I'll gladly give you an UID/PW for my not-quite-open mail
relay. I have little doubt that any and all traffic in and out of that
particular machine has been logged since it first came online 7 years
ago. I don't care, since any significant traffic is encrypted. YMMV. Oh,
and yes, cypherpunks.to of course supports IPSec under both IPv4 and
IPv6 in addition to higher-level encryption protocols such as smtp's
--Lucky "strong crypto sure has become amazingly inexpensive and easy to
use" Green

@_date: 2002-06-22 19:03:49
@_author: Lucky Green 
@_subject: Ross's TCPA paper 
I recently had a chance to read Ross Anderson's paper on the activities
of the TCPA at
I must confess that after reading the paper I am quite relieved to
finally have solid confirmation that at least one other person has
realized (outside the authors and proponents of the bill) that the
Hollings bill, while failing to mention TCPA anywhere in the text of the
bill, was written with the specific technology provided by the TCPA in
mind for the purpose of mandating the inclusion of this technology in
all future general-purpose computing platforms, now that the technology
has been tested, is ready to ship, and the BIOS vendors are on side.
Perhaps the Hollings "Consumer Broadband and Digital Television
Promotion Act" bill would be more accurately termed the "TCPA Enablement
Act". BTW, the module that Ross calls a "Fritz" in his paper after the
author of the bill, long had a name: it is called a Trusted Platform
Module (TPM).
Granted, in the context of the TCPA and the Hollings bill, the term
"trusted" is used somewhat differently than the customers of future
motherboards, which are all slated to include a TPM, might expect:
"trusted" here means that the members of the TCPA trust that the TPM
will make it near impossible for the owner of that motherboard to access
supervisor mode on the CPU without their knowledge, they trust that the
TPM will enable them to determine remotely if the customer has a
kernel-level debugger loaded, and they trust that the TPM will prevent a
user from bypassing OS protections by installing custom PCI cards to
read out memory directly via DMA without going through the CPU.
The public and the media now need to somehow, preferably soon, arrive at
the next stage of realization: the involvement in the TCPA by many
companies who's CEO's wrote the widely distributed open letter to the
movie studios, telling the studios, or more precisely -- given that it
was an open letter -- telling the public, that mandating DRM's in
general-purpose computing platforms may not be a good idea, is
indicative of one of two possible scenarios:
1) the CEO's of said computer companies are utterly unaware of a major
strategic initiative their staff has been diligently executing for about
3 years, in the case of the principals in the TCPA, such as Intel,
Compaq, HP, and Microsoft, several years longer.
2) the CEO's wrote this open letter as part of a deliberate "good cop,
bad cop" ploy, feigning opposition to DRM in general computing platforms
to pull the wool over the public's eye for hopefully long enough to
achieve widespread deployment of the mother of all DRM solution in the
market place.
I do not know which of the two potential scenarios holds true. However,
I believe public debate regarding the massive change in the way users
will interact with their future computers due to the efforts of the TCPA
and the Hollings bill would be greatly aided by attempts to establish
which of the two scenarios is the fact the case.
--Lucky Green

@_date: 2002-06-22 21:24:02
@_author: Lucky Green 
@_subject: DOJ proposes US data-rentention law.  
To expand on John Young's inquiry, I believe it would help elevate the
level of the public discourse regarding potential future US data
retention and interception laws if those inclined to comment on this
issue were to take the time to research similar laws already passed in
other countries in the course of the customary policy laundry process.
Even a brief such investigation would teach the aspiring commentator
that those responsible for the installation and maintenance of
governmentally mandated snooping infrastructure at the ISP are largely
required to hold active security clearances.
To rephrase John's very valid question in a slightly more targeted
fashion: how likely is it that cleared personnel working at the ISP will
refuse an official request for law enforcement assistance?
--Lucky Green

@_date: 2002-06-22 23:01:12
@_author: Lucky Green 
@_subject: Ross's TCPA paper 
Mike wrote quoting Lucky:
I agree with your assertion that TPM's can't prevent DRM from being
broken. Nor is this the intent of introducing TPM's. The vendors have
realized that they have to raise the technical bar only so high to keep
those most inclined to break their systems (i.e. 16-year old Norwegians)
from doing so. Those that have the knowledge and resources to break TCPA
systems either won't have the time because they are engaged in gainful
employment, won't be willing to take the risk, because they have
accumulated sufficient material possessions to be unwilling to risk
losing their possessions, not to mention their freedom, in litigation,
or will break the security for their own gain, but won't release the
crack to the public. Criminal enterprise falls into the latter category.
The content vendors, which in this case includes the operating system
and application vendors, dislike, but can live with, major criminal
enterprise being the only other party to have unfettered access, since
criminal enterprise is just another competitor in the market place. Most
business models can survive another competitor. Where business models
threaten to collapse is when the marginal cost of an illegal copy goes
to zero and the public at large can obtain your goods without payment. I
don't know if the TCPA's efforts will prevent this, but in the process
of trying to achieve this objective, the average computers users, and
even many advanced computer users, will find themselves in a new
relationship with their PC: that of a pure consumer, with only the
choices available to them the what the 180 TCPA's members digital
signatures permit.
Cloning TPM's is difficult, though not impossible. Note that all TPM's
unique initial internal device keys are signed at time of manufacture by
a derivative of the TCPA master key. Unless you are one of the
well-known chipset or BIOS manufacturers, you can't get your TPM
products signed. It is theoretically possible, though far from easy, to
clone an entire TPM, keys and all.
However, the moment those fake TPM's show up in the market place, their
keys will simply be listed in the next CRL update. And if your OS and
TPM's miss a few CRL updates, your commercial OS and all your
applications will stop working. As might in the future your video card,
your PCI cards, your hard drive, and your peripherals.
You can try to hack around the code in the OS or firmware that performs
the checks, as long as you are willing to operate your machine
permanently off the Net from then on, because your system will fail the
remote integrity checks, but given that this and other security relevant
code inside the OS and applications are 3DES encrypted and are only
decrypted inside the TPM, you can't just read the object code from disk,
but get to first microprobe the decrypted op codes off the bus before
taking a debugger to the code. Not a trivial task at today's PC bus
speeds. Nor can you get too aggressive with the hacks, since your Fritz
may simply flush the keys and leave you with a bunch of 3DES encrypted
op codes and no corresponding decryption keys. Reverse engineering turns
pretty dim at that point.
None of these obstacles are impossible to overcome, but not by Joe
Computer User, not by even the most talented 16-year old hacker, and not
even by many folks in the field. Sure, I know some that could overcome
it, but they may not be willing to do the time for what by then will be
a crime. Come to think of it, doing so already is a crime.
--Lucky Green

@_date: 2002-06-23 16:34:58
@_author: Lucky Green 
@_subject: Ross's TCPA paper 
Anonymous raises a valid question. To hand Anonymous additional rope, I
will even assure the reader that when questioned directly, the members
of the TCPA will insist that their efforts in the context of TCPA are
concerned with increasing platform security in general and are not
targeted at providing a DRM solution.
Unfortunately, and I apologize for having to disappoint the reader, I do
not feel at liberty to provide the proof Anonymous is requesting myself,
though perhaps Ross might. (I have no first-hand knowledge of what Ross
may or may not be able to provide).
I however encourage readers familiar with the state of the art in PC
platform security to read the TCPA specifications, read the TCPA's
membership list, read the Hollings bill, and then ask themselves if they
are aware of, or can locate somebody who is aware of, any other
technical solution that enjoys a similar level of PC platform industry
support, is anywhere as near to wide-spread production as TPM's, and is
of sufficient integration into the platform to be able to form the
platform basis for meeting the requirements of the Hollings bill.
Would Anonymous perhaps like to take this question?
--Lucky Green

@_date: 2002-06-24 01:47:32
@_author: Lucky Green 
@_subject: Steven Levy buys Microsoft's bullshit hook, line, and sinker 
[Bram is correct, stifling competition is one of the many features TCPA
will enable. In more ways than one. And for more players than just
Coincidentally, Steven Levy's article that Bram is citing also helps
answer Mr. Anonymous's question with which he challenged Ross and myself
earlier today.
First, however, I must apologize to the reader for my earlier, now
incorrect, statement that TCPA member companies would deny that DRM is
an objective of the TCPA. I had been unaware that, as evidenced by the
publication of the Newsweek article, the public phase of the TCPA effort
had already begun. What a bizarre coincidence for this phase, after all
those years the TCPA effort and its predecessors have been underway,
(the design, and in fact the entire architecture, has morphed
substantially over the years) to be kicked off the very day of my post.
[Tim: do you recall when we had the discussion about the upcoming
"encrypted op code chips" at a Cypherpunks meeting in a Stanford lecture
hall? Was that 1995 or 1996? It cannot have been later; I know that I
was still working for DigiCash at the time because I remember giving a
talk on compact endorsement signatures at the same meeting].
"Palladium [Microsoft's TCPA-based technology - LG] is being offered to
the studios and record labels as a way to distribute music and film with
"digital rights management" (DRM). This could allow users to exercise
"fair use" (like making personal copies of a CD) and publishers could at
least start releasing works that cut a compromise between free and
locked-down. But a more interesting possibility is that Palladium could
help introduce DRM to business and just plain people. "It's a funny
thing," says Bill Gates. "We came at this thinking about music, but then
we realized that e-mail and documents were far more interesting
Another paragraph of the Newsweek article has this to say:
"In 1997, Peter Biddle, a Microsoft manager who used to run a paintball
arena, was the company's liason to the DVD-drive world. Naturally, he
began to think of ways to address Hollywood's fear of digital copying.
He hooked up with [...] researchers Paul England and John Manferdelli,
and they set up a skunkworks operation, stealing time from their regular
jobs to pursue a preposterously ambitious idea-creating virtual vaults
in Windows to protect information. They quickly understood that the
problems of intellectual property were linked to problems of security
and privacy.
        They also realized that if they wanted to foil hackers and
intruders, at least part of the system had to be embedded in silicon,
not software."
Well, now that Bill Gates himself is being quoted stating that DRM was a
driver behind the technology the TCPA is enabling (Microsoft is one of
the companies that founded the TCPA and should be in a position to
know), does Mr. Anonymous consider this sufficient "evidence that the
TCPA is being designed for the support of digital rights management
(DRM) applications"? Or does Anonymous continue to believe Ross and
Lucky are making this stuff up out of whole cloth?
To answer Anonymous's question as to whether the "the TCPA [is] really,
as [Ross and Lucky] claim, a secretive effort to get DRM hardware into
consumer PCs?", I am not sure I would exactly call this fact a secret at
this point. (Though by no means are all cards already on the table).
DRM is a significant objective of some of the TCPA's member companies,
which includes Microsoft.
There are of course other objectives. Some of which Ross published, some
which I mentioned, some which Steven Levy has published (though he
largely fell for the designated bait and missed the numerous hooks),
some which Bram has realized, and some which have yet to be talked
about. Some desirable, some questionable, and a lot of them downright
--Lucky Green

@_date: 2002-06-24 13:18:32
@_author: Lucky Green 
@_subject: Ross's TCPA paper 
Pete Chown wrote quoting Ross:
The application or OS vendor can in confidence distribute not just the
code, but also the also the signature and cert. In fact, the application
vendor can distribute absolutely everything they have access to
themselves and you still won't be able to run the application in trusted
The cert that enables an application to run in trusted mode is tied to a
specific TPM and therefore to a specific motherboard. For this cert to
work on another motherboard without a new and different cert, the
software vendor would need to extract the 2048-bit secret RSA key [1]
from their own motherboard's TPM, make the secret key available for
download, followed by the customer importing the key into their own TPM.
The TPM, for obvious reasons, offers no facilities to export or import
the TPM's internal keys.
The GPL cannot possibly require a software author to distribute a
hardware crack with their software or be in violation of the GPL.
Distributing a crack for TPM's is distributing an infringement device
and as such is illegal under US law. Even if the GPL were to be modified
to mandate what is technically near impossible to a software vendor to
achieve, even this layperson knows that contracts that require illegal
acts are unenforceable. Note that I am not referring to acts that might
be illegal in the future under the Hollings bill. Doing the above is
illegal today.
The GPL might be modified to require that the application vendor do
whatever is necessary for a user to utilize an application in the way
the user deems fit (i.e. in privileged mode), but that would put the GPL
into very dangerous, and I believe thoroughly undesirable, territory.
With such modifications, the hypothetical new GPL would mandate, to use
Richard Stallman's terminology, not just freedom of speech, but free
beer as well. That has never been the intend of the GPL.
Furthermore, the certs required to run the OS or application will in may
cases be issued by a party other than the application author or vendor.
To continue using Richard's terminology, to cover this case the GPL
would need to be rewritten to mandate that a third-party provide the
free beer.
I will leave it to the attorneys on this list to elucidate on the legal
deficiencies of such a hypothetical contract, since I am not an attorney
I will simply state that I sincerely doubt such contract would hold up
in litigation.
Of course I do not believe the FSF would make such changes. Which gets
us back to Ross's point that the TCPA threatens the core of the GPL,
from which this discussion started. For completeness I would like to
state that I have no personal stake in the continued enforceability of
the GPL, being a long-time supporter of the BSD licensing scheme myself.
[1] 1024-bit RSA keys were rejected during the design phase of the TPM
by members of the TCPA, which, as Anonymous pointed out in a previous
post, contains several well-known crypto companies. The TCPA's website,
which only makes specs, but not design documents, available to the
public, unfortunately does not provide any documentation which reasoning
lead to this decision.
--Lucky Green

@_date: 2002-06-26 21:10:25
@_author: Lucky Green 
@_subject: Two additional TCPA/Palladium plays 
[Minor plug: I am scheduled to give a talk on TCPA at this year's DEF
CON security conference. I promise it will be an interesting talk.
 ]
Below are two more additional TCPA plays that I am in a position to
1) Permanently lock out competitors from your file formats.
"A more interesting possibility is that Palladium could help introduce
DRM to business and just plain people. It's a funny thing," says Bill
Gates. "We came at this thinking about music, but then we realized that
e-mail and documents were far more interesting domains."
Here it is why it is a more interesting possibility to Microsoft for
Palladium to help introduce DRM to business and "just plain people" than
to solely utilize DRM to prevent copying of digital entertainment
It is true that Microsoft, Intel, and other key TCPA members consider
DRM an enabler of the PC as the hub of the future home entertainment
network. As Ross pointed out, by adding DRM to the platform, Microsoft
and Intel, are able to grow the market for the platform.
However, this alone does little to enhance Microsoft's already sizable
existing core business. As Bill Gates stated, Microsoft plans to wrap
their entire set of file formats with DRM. How does this help
Microsoft's core business? Very simple: enabling DRM for MS Word
documents makes it illegal under the DMCA to create competing software
that can read or otherwise process the application's file format without
the application vendor's permission.
Future maintainers of open source office suites will be faced with a
very simple choice: don't enable the software to read Microsoft's file
formats or go to jail. Anyone who doubts that such a thing could happen
is encouraged to familiarize themselves with the case of Dmitry
Skylarov, who was arrested after last year's DEF CON conference for
creating software that permitted processing of a DRM-wrapped document
file format.
Permanently locking out competition is a feature that of course does not
just appeal to Microsoft alone. A great many dominant application
vendors are looking forward to locking out their competition. The beauty
of this play is that the application vendors themselves never need to
make that call to the FBI themselves and incur the resultant backlash
from the public that Adobe experienced in the Skylarov case. The content
providers or some of those utilizing the ubiquitously supported DRM
features will eagerly make that call instead.
In one fell swoop, application vendors, such as Microsoft and many
others, create a situation in which the full force of the U.S. judicial
system can be brought to bear on anyone attempting to compete with a
dominant application vendor. This is one of the several ways in which
TCPA enables stifling competition.
The above is one of the near to medium objectives the TCPA helps meet.
[The short-term core application objective is of course to ensure
payment for any and all copies of your application out there]. Below is
a mid to long term objective:
2) Lock documents to application licensing
As the Levy article mentions, Palladium will permit the creation of
documents with a given lifetime. This feature by necessity requires a
secure clock, not just at the desktop of the creator of the document,
but also on the desktops of all parties that might in the future read
such documents. Since PC's do not ship with secure clocks that the owner
of the PC is unable to alter and since the TCPA's specs do not mandate
such an expensive hardware solution, any implementation of limited
lifetime documents must by necessity obtain the time elsewhere. The
obvious source for secure time is a TPM authenticated time server that
distributes the time over the Internet.
In other words, Palladium and other TCPA-based applications will require
at least occasional Internet access to operate.
It is during such mandatory Internet access that licensing-related
information will be pushed to the desktop. One such set of information
would be blacklists of widely-distributed pirated copies of application
software (you don't need TCPA for this feature if the user downloads and
installs periodic software updates, but the user may choose to live with
application bugs that are fixed in the update rather than see her unpaid
software disabled).
With TCPA and DRM on all documents, the application vendor's powers
increase vastly: the application vendor can now not just invalidate
copies of applications for failure to pay ongoing licensing fees, but
can invalidate all documents that were ever created with the help of
this application. Regardless how widely the documents may have been
distributed or on who's computer the documents may reside at present.
Furthermore, this feature enables world-wide remote invalidation of a
document file for reasons other than failure to pay ongoing licensing
fees to the application vendor. To give just one example, documents can
be remotely invalidated pursuant to a court order, as might be given if
the author of the document were to distribute DeCSS v3 or Scientology
scriptures in the future DRM protected format. All that is required to
perform such an administrative invalidation of a document is either a
sample copy of the document from which one can obtain its globally
unique ID, the serial number of the application that created the
document, or the public key of the person who licensed the application.
(Other ways to exist but are omitted in the interest of brevity).
--Lucky Green

@_date: 2002-06-26 22:07:19
@_author: Lucky Green 
@_subject: Revenge of the WAVEoids: Palladium Clues May Lie In AMD  Motherboard Design 
Bob wrote quoting Mark Hachman:
An EMBASSY-like CPU security co-processor would have seriously blown the
part cost design constraint on the TPM by an order of magnitude or two.
I am not asserting that security solutions that require special-purpose
CPU functionality are not in the queue, they very much are, but not in
the first phase. This level of functionality has been deferred to a
second phase in which security processing functionality can be moved
into the core CPU, since a second CPU-like part is unjustifiable from a
cost perspective.
Given the length of CPU design cycles and the massive cost of
architecting new functionality into a processor as complex as a modern
CPU, we may or may not see this functionality shipping. Much depends on
how well phase 1 of the TCPA effort fares.

@_date: 2002-06-26 22:15:59
@_author: Lucky Green 
@_subject: DRMs vs internet privacy (Re: Ross's TCPA paper) 
The TCPA specs were carefully designed to permit the user to obtain
multiple certificates from multiple CA's and thus, if, and that's a big
if, the CA's don't collude and furthermore indeed discard the true name
identities of the customer, utilize multiple separate identities for
various online applications. I.e., the user could have one cert for
their True Name, one used to enable Microsoft Office, and one to
authenticate the user to other online services.
It is very much the intent of the TCPA to permit the use of pseudonymous
credentials for many, if not most, applications. Otherwise, the TCPA's
carefully planned attempts at winning over the online liberty groups
would have been doomed from the start.
--Lucky Green

@_date: 2002-06-27 00:59:46
@_author: Lucky Green 
@_subject: Ross's TCPA paper 
I fully agree that the TCPA's efforts offer potentially beneficial
effects. Assuming the TPM has not been compromised, the TPM should
enable to detect if interested parties have replaced you NIC with the
rarer, but not unheard of, variant that ships out the contents of your
operating RAM via DMA and IP padding outside the abilities of your OS to
However, enabling platform security, as much as might be stressed
otherwise by the stakeholders, has never been the motive behind the
TCPA. The motive has been DRM. Does this mean that one should ignore the
benefits that TCPA might bring? Of course not. But it does mean that one
should carefully weigh the benefits against the risks.
--Lucky Green

@_date: 2002-03-22 17:00:19
@_author: Lucky Green 
@_subject: RSA on general-purpose CPU's [was:RE: Secure peripheral cards] 
Newer general-purpose CPU architectures offer even better performance:
one of the sample program for IA-64 that Intel has published on their
Itanium performance benchmark CDROM handed out at tradeshows clocks
about 1000 1024-bit RSA signings per second on an 800 MHz Itanium CPU.

@_date: 2002-03-23 17:38:02
@_author: Lucky Green 
@_subject: 1024-bit RSA keys in danger of compromise 
As those of you who have discussed RSA keys size requirements with me
over the years will attest to, I always held that 1024-bit RSA keys
could not be factored by anyone, including the NSA, unless the opponent
had devised novel improvements to the theory of factoring large
composites unknown in the open literature. I considered this to be
possible, but highly unlikely. In short, I believed that users' desires
for keys larger than 1024-bits were mostly driven by a vague feeling
that "larger must be better" in some cases, and by downright paranoia in
other cases. I was mistaken.
Based upon requests voiced by a number of attendees to this year's
Financial Cryptography conference , I assembled and
moderated a panel titled "RSA Factoring: Do We Need Larger Keys?". The
panel explored the implications of Bernstein's widely discussed
"Circuits for Integer Factorization: a Proposal".
Although the full implications of the proposal were not necessarily
immediately apparent in the first few days following Bernstein's
publication, the incremental improvements to parts of NFS outlined in
the proposal turn out to carry significant practical security
implications impacting the overwhelming majority of deployed systems
utilizing RSA or DH as the public key algorithms.
Coincidentally, the day before the panel, Nicko van Someren announced at
the FC02 rump session that his team had built software which can factor
512-bit RSA keys in 6 weeks using only hardware they already had in the
A very interesting result, indeed. (While 512-bit keys had been broken
before, the feasibility of factoring 512-bit keys on just the computers
sitting around an office was news at least to me).
The panel, consisting of Ian Goldberg and Nicko van Someren, put forth
the following rough first estimates:
While the interconnections required by Bernstein's proposed architecture
add a non-trivial level of complexity, as Bruce Schneier correctly
pointed out in his latest CRYPTOGRAM newsletter, a 1024-bit RSA
factoring device can likely be built using only commercially available
technology for a price range of several hundred million dollars to about
1 billion dollars. Costs may well drop lower if one has the use of a
chip fab. It is a matter of public record that the NSA as well as the
Chinese, Russian, French, and many other intelligence agencies all
operate their own fabs.
Some may consider a price tag potentially reaching $1B prohibitive. One
should keep in mind that the NRO regularly launches SIGINT satellites
costing close to $2B each. Would the NSA have built a device at less
than half the cost of one of their satellites to be able to decipher the
interception data obtained via many such satellites? The NSA would have
to be derelict of duty to not have done so.
Bernstein's machine, once built, will have power requirements in the MW
to operate, but in return will be able to break a 1024-bit RSA or DH key
in seconds to minutes. Even under the most optimistic estimates for
present-day PKI adoption, the inescapable conclusion is that the NSA,
its major foreign intelligence counterparts, and any foreign commercial
competitors provided with commercial intelligence by their national
intelligence services have the ability to break on demand any and all
1024-bit public keys.
The security implications of a practical breakability of 1024-bit RSA
and DH keys are staggering, since of the following systems as currently
deployed tend to utilize keys larger than 1024-bits:
- HTTPS
- SSH
- IPSec
- S/MIME
- PGP
An opponent capable of breaking all of the above will have access to
virtually any corporate or private communications and services that are
connected to the Internet.
The most sensible recommendation in response to these findings at this
time is to upgraded your security infrastructure to utilize 2048-bit
user keys at the next convenient opportunity. Certificate Authorities
may wish to investigate larger keys as appropriate. Some CA's, such as
those used to protect digital satellite content in Europe, have already
moved to 4096-bit root keys.
Undoubtedly, many vendors and their captive security consultants will
rush to publish countless "reasons" why nobody is able to build such a
device, would ever want to build such a device, could never obtain a
sufficient number of chips for such a device, or simply should use that
vendor's "unbreakable virtual onetime pad" technology instead.
While the latter doesn't warrant comment, one question to ask
spokespersons pitching the former is "what key size is the majority of
your customers using with your security product"? Having worked in this
industry for over a decade, I can state without qualification that
anybody other than perhaps some of the HSM vendors would be misinformed
if they claimed that the majority - or even a sizable minority - of
their customers have deployed key sizes larger than 1024-bits through
their organization. Which is not surprising, since many vendor offerings
fail to support larger keys.
In light of the above, I reluctantly revoked all my personal 1024-bit
PGP keys and the large web-of-trust that these keys have acquired over
time. The keys should be considered compromised. The revoked keys and my
new keys are attached below.
--Lucky Green
-----BEGIN PGP PUBLIC KEY BLOCK-----
Version: PGP 7.1
Comment: Problems decrypting this email? Upgrade from PGP 1.x/2.x!
-----END PGP PUBLIC KEY BLOCK-----

@_date: 2002-03-27 19:55:05
@_author: Lucky Green 
@_subject: PGP key server changes [was: RE: 1024-bit RSA keys in danger of compromise] 
Oh, the curse of having to revoke a key that accumulated years of WOT
My new pub key has since acquired a few signatures. You can always
get the latest version of my key by fingering shamrock at cypherpunks.to
or via LDAP from ldap://pgp.surfnet.nl:11370 (also known as
europe.keys.pgp.com, though this alias may not last much longer given
that it seems that the canonical PGP keyserver at keyserver.pgp.com
appears to already have ceased operations in the wake of NAI placing
PGP into "maintenance mode". At least I have been unable to connect
to that server for several days now. YMMV).
No, my new key will not interoperate with PGP 1.0, Bass-O-Matic, or
similarly outdated versions of PGP. Readers of this post are
discouraged from contacting me to inform me of this fact. I an well
aware of it and couldn't care less. Few, if any, programs that I use
today would run on the Macintosh DUO 230 on which I generated my
first 1024-bit PGP key back when I was an alpha tester for PGP 2.0.
Thanks to Moore's Law, my first-ever 1024-bit key took a hell of a
lot longer to generate on what was then a brand new machine than it
took to generate my new 4096-bit PGP key on the old K6-333 that I
used a few days ago to generated not only my new PGP key, but various
4096-bit SSH keys for good measure.
My suggestion would be to use the time saved by not sending me such
an email to upgrade your version of PGP instead. The key has been
tested to work fine with the current release versions of PGP for
Windows and Mac as well as GnuPG for UNIX and I presume Windows,
though I haven't tested GnuPG on Windows.
Those of you that know me are very much encouraged to contact me to
verify the fingerprint of my new key. If you have my personal mobile
phone number, just call. If you don't, email me for the number. Since
I would rather not post it to a public mailing list.

@_date: 2002-11-10 21:40:42
@_author: Lucky Green 
@_subject: Transparent drive encryption now in FreeBSD 
FreeBSD's 5.0 release, due out in a couple of weeks, will offer much
anticipated transparent mass storage encryption. Subscribers to this
list so inclined are encouraged to review and test this new feature.
    --Lucky Green
[Moderator's note: FYI, NetBSD also has drive encryption these days. --Perry]

@_date: 2002-10-02 18:50:22
@_author: Lucky Green 
@_subject: What email encryption is actually in use?  
Steven raises an interesting point. Having looked at various STARTTLS
implementations it appears to me that if not the designers of STARTTLS
then at least the authors of STARTTLS-enabled MTAs appeared to have
envisioned the use of STARTTLS primarily to secure and authenticate
email submission, not MTA-to-MTA SMTP transfer.
STARTTLS's ability to encrypt authentication information, in practice
primarily SASL, during mail submission from the MUA to the MTA is
certainly welcome; I myself am making extensive use of it in my SMTP
Mail submission does however not represent the bulk of
STARTTLS-encrypted SMTP traffic on the Internet today. A brief
unscientific look at some maillogs that I performed a few months ago
showed that MTA-to-MTA (for the MTA's in question this equates
site-to-site SMTP traffic) use of STARTTLS is a resounding 3 orders of
magnitude more common than the use of STARTTLS to secure and
authenticate submission from MUAs.
Here is why: once STARTTLS-enabled MTAs reached a certain density, which
appears to have been exceeded on parts of the Internet sometime over the
last year, the ability to support STARTTLS triggers the well-known "fax
effect": the moment you enable STARTTLS in your MTA, connections to
other MTAs will automatically be secured, at worst with opportunistic
encryption. With each MTA supporting STARTTLS added to the Net the
percentage of encrypted SMTP connections increases as the use of
STARTTLS takes place without even the knowledge, much less the elusive
active cooperation, of dozens, hundreds, or even thousands of users per
I boldly submit that more email is presently being encrypted on the
Internet every single day using STARTTLS than has ever been secured
using PGP, S/MIME, or other MUA-based encryption methods combined over
the entire history of SMTP.
Case in point: I am one of the heaviest users of PGP that I am aware of.
In addition, I have used PGP for longer than most, going back to my days
as an alpha tester of PGP 2.0. I have used and continue to use S/MIME
extensively. Nonetheless, my primary MTA processes more TLS encrypted
email in under a week than I have ever encrypted using MUA-based systems
in my entire life.
Perhaps a student with access to the logs of a large STARTTLS-capable
university MTA will write a paper containing a quantitative analysis of
today's use of STARTTLS. There is definitely a paper waiting in
analyzing this phenomenon.
It is my hope that the authors of MTAs will integrate the lessons
learned from the de-facto use of STARTTLS to enable additional desirable
STARTTLS-based feature in future releases of their software.
--Lucky Green

@_date: 2002-09-17 16:18:58
@_author: Lucky Green 
@_subject: Cryptogram: Palladium Only for DRM 
AARG! Wrote:
What AARG! is failing to mention is that Microsoft holds that Palladium,
and in particular Trusted Operating Root ("nub") implementations, are
subject to Microsoft's DRM-OS patent. Absent a patent license from
Microsoft, any individual developer, open source software development
effort, and indeed any potential competitor of Microsoft that wishes to
create a Palladium-like TOR would do so in violation of Microsoft's
patent. U.S. Patent law takes a dim view of such illegal infringers:
willful infringers, in particular infringers that generate a profit from
their creation of a non-Microsoft version of a TOR face the risk of a
court ordering such infringers to pay treble damages.
Palladium team representatives have indicated that Microsoft, or at
least the Palladium team, believes that Microsoft may license their
patented technology to competing efforts at some undecided time in the
future under terms that have yet to be contemplated, have so far not
been discussed with Microsoft's legal staff, and may or may not involve
As of this moment, Microsoft has not provided the open source community
with a world-wide, royalty-free, irrevocable patent license to the
totality of Microsoft's patents utilized in Palladium's TOR. Since open
source efforts therefore remain legally prohibited from creating
non-Microsoft TORs, AARG!'s lauding of synergies between Palladium and
open source software development appears premature.
copy protection.
In the interest of clarity, it probably should be mentioned that any
claims Microsoft may make stating that Microsoft will not encrypt their
software or software components when used with Palladium of course only
applies to Microsoft and not to the countless other software vendors
creating applications for the Windows platform.
Lastly, since I have seen this error in a number of articles, it seems
worth mentioning that Microsoft stated explicitly that increasing the
security of DRM schemes protecting digital entertainment content, but
not executable code, formed the impetus to the Palladium effort.
--Lucky Green

@_date: 2002-09-26 21:56:50
@_author: Lucky Green 
@_subject: RSA's RC5-64 Secret Key Challenge has been solved.  
According to the GSM Association's website there are currently 732
million GSM users world-wide. Still, I suspect that unlike RC5 and DES,
GSM's two "voice privacy" algorithms A5/1 and A5/2 might not be the best
candidates for brute force distributed key searches since the algorithms
were badly designed, are fundamentally broken, and thus are subject to
very efficient cryptanalytical attacks with work factors well below the
64-bit key space nominally utilized by GSM.
A5/2, the weaker of the two algorithms, can be broken in real-time on a
single, low-end, Pentium class computer.
A5/1, the stronger of the two algorithms, falls to a near real-time
attack on computing hardware far from bleeding edge, but the attack as
published requires a 2^48 preprocessing stage. That table could be
generated by a distributed effort.
Unfortunately, the greatest challenge in publicly demonstrating the
insecurity of GSM and other civilian wireless communication protocols
lies not in breaking the compromised crypto, but in obtaining the
required RF and signal processing equipment. Full-featured equipment is
priced with governmental customers in mind and difficult to obtain.
Commercial-grade interception hardware usually lacks cryptanalytical
Software defined radios would be well-suited to task, but those who
expended the effort of writing software-defined cellular telephony
modules so far understandably chose to sell the fruits of their labor to
paying customers rather than releasing the code as Open Source.
Until the required equipment becomes readily available to the public,
the interested parties likely will continue to make the same outrageous
claims they made in the past, such as that GSM is secure against
eavesdroppers irrespective of how weak the ciphers have been shown to be
since the GSM signal itself cannot be intercepted...
Lastly, while a publicly available A5/1 precomputation table would
likely be of interest to researchers, myself included, anybody
considering creating that table may wish to inquire with competent legal
counsel as to the legality of performing this research in the U.S.
--Lucky Green

@_date: 2003-02-08 22:22:20
@_author: Lucky Green 
@_subject: Columbia crypto box  
Matt wrote quoting John:
Based on my experience, I would not be unreasonable to believe that such
a disregard to basic security principles indeed took place. Case in
In July of 1997, only days after the Mars Pathfinder mission and its
Sojourner Rover successfully landed on Mars, I innocently inquired on
the Cypherpunks mailing list if any subscribers happened to know if and
how NASA authenticates the command uplink to what at the time was
arguably the coolest RC toy in the solar system.
A few days after my initial post, which yielded no substantial replies
on the mailing list, I receive a call by a well-known security expert
who at that time functioned as an advisor to the office of the President
of the United States.
Apparently, my original inquiry had been copied and forwarded several
times. By the time my inquiry had reached the office of the President,
just as in a children's' game of telephone, my question of "are they
using any decent crypto" had turned in to "hackers ready to take over
Mars Rover".
With Sojourner being the U.S. Government's PR darling of the day, the
office of the President decided to dispatch the FBI to interdict me from
engaging in such a nefarious deed. It was only through chance that the
aforementioned advisor got wind of this releasing of the hounds and
convinced the decision makers that I was just a harmless researcher who
asked an innocent question rather than a threat to national PR
Word has it that the folks in DC were buzzing with fear of what would
happen to NASA's image if hackers were to take the Mars Rover for a
spin. Needless to say and regardless of anyone's intent, such concern
would be entirely unfounded if the uplink were securely authenticated.
Which I believes represents an answer to my initial question as to
whether the uplink is securely authenticated. Presumably NASA did a
better job with the shuttle, but I would not be surprised in the least
if all shuttles shared the same key.
[Remind me to some time recount the tale of my discussing key management
with the chief-cryptographer for a battlefield communication system
considerably younger than the shuttle fleet. Appalling does not being to
describe it].
--Lucky Green

@_date: 2003-01-28 03:45:09
@_author: Lucky Green 
@_subject: EU Privacy Authorities Seek Changes in Microsoft 'Passport' 
The Liberty Alliance was stillborn to begin with. Not that it made any
practical difference, but the Liberty Alliance received an additional
bullet through the head the day that RSA Security, a key participant in
the Liberty Alliance, announced that they would also support Microsoft

@_date: 2003-06-02 22:13:00
@_author: Lucky Green 
@_subject: Maybe It's Snake Oil All the Way Down 
ssh2 is in essence a re-invention of what SSL did without having to use
X.509 keys. This reinvention was, IMHO, largely the result of the
limitations of the ssh1 design.
I trust that we can agree that the volume of traffic and number of
transactions protected by SSL are orders of magnitude higher than those
protected by SSH. As is the number of users of SSL. The overwhelming
majority of which wouldn't know ssh from telnet. Nor would they know
what to do at a shell prompt and therefore have no use for either ssh or
Given that SSL use is orders of magnitude higher than that of SSH, with
no change in sight, primarily due to SSL's ease-of-use, I am a bit
puzzled by your assertion that ssh, not SSL, is the "only really
successful net crypto system".

@_date: 2003-03-15 01:31:12
@_author: Lucky Green 
@_subject: Microsoft: Palladium will not limit what you can run 
AARG!, having burned the nym with the moderator of this list and who is
therefore now posting via the Hermes remailer commented on Microsoft,
which similarly burned the Palladium name, claims:
Part of me wonders if it worth my time to reply to this post, but what
the heck, I'll take it.
So let's talk about reality. It is true, at least for the moment, that
Intel's La Grande initiative, which provides the hardware foundation for
Palladium, just locks pages in memory that are designate as such by the
application. It if further true that Palladium, as the aforementioned OS
component, just designates certain blobs of data to be inaccessible to
the user who has Ring 0 privileges.
Whether Palladium takes over root on a computer or merely prevents the
legitimate purchaser of a PC who otherwise has required privileges from
performing certain actions on the PC that he legally owns with the data
he lawfully created may be a matter of philosophical debate. For
conciseness and clarity it suffices to say that the owner of a PC will
not have root privileges on a PC on which Palladium is active and in
force. No Microsoft press release can possibly alter this fact, since
this restriction is fundamental to Palladium having any value at all to
any entities.
"How these new programs are built - and what they will require of the
user - are questions for the application developer to answer."
What John means is that Palladium in and by itself will not limit what
applications you can run. Which is mostly true for the first phase. But
if, in addition to Palladium, you would like to run application by
vendors concerned about law-abiding, but undesirable, information flow,
then you will find that the applications that you would like to run in
addition to the above won't perform as expected.

@_date: 2003-04-01 01:30:27
@_author: Lucky Green 
@_subject: Russia Intercepts US Military Communications? 
Just for the record, SSLv1 first saw significant review, if it was not
first posted to, the Cypherpunks mailing list. Those who participated in
the list at the time may remember Mark Andreessen, a Cypherpunks newbie in
those days, proudly posting his new crypto protocol. The protocol received
the customary reception security protocols designed by crypto newbies tend
to receive: it was torn to shreds immediately.
SSLv2 rapidly superceded SSLv1. SSLv2 in turn was implemented throughout
Netscape's products by the Weinstein brothers, which during those days
were very active participants in both the Cypherpunks mailing list and
Cypherpunks meetings.
--Lucky Green

@_date: 2013-08-28 21:08:05
@_author: Lucky Green 
@_subject: [Cryptography] IPv6 and IPSEC 
As of about 10 days ago, Gmail began rejecting incoming IPv6 SMTP traffic from IPv6 address for which the forward and reverse DNS do not match.
Since forward and reverse DNS will rarely match for IP addresses used by individuals rather than service providers, this change precludes home users of IPv6 from sending email to Gmail acccount.
So unless you never send email to Gmail users or control both forward and reverse DNS, IPv6 is (no longer) suitable for sending email.
Note that this new restriction imposed by Gmail only applies to IPv6 addresses, not IPv4 addresses. I had to disable IPv6 in postfix to continue to be able to send to Gmail.
Here is the error message:
: host gmail-smtp-in.l.google.com[2a00:1450:400c:c05::1b]
    said: 550-5.7.1 [2001:888:2133:0:82:94:251:205      16] Our system has
    detected that 550-5.7.1 this message does not meet IPv6 sending guidelines
    regarding PTR 550-5.7.1 records and authentication. Please review 550 5.7.1
     for more information.
    x13si636989wij.49 - gsmtp (in reply to end of DATA command)
Google's support URL in the 550 error contains this gem:
"Additional guidelines for IPv6
The sending IP must have a PTR record (i.e., a reverse DNS of the sending IP) and it should match the IP obtained via the forward DNS resolution of the hostname specified in the PTR record. Otherwise, mail will be marked as spam or possibly rejected."
[The support URL then also talks about recommending SPF or DKIM, but enabling SPF does not stop the 550 errors]
--Lucky, who long ago IPv6-enabled every single system under his control.

@_date: 2013-09-04 05:54:17
@_author: Lucky Green 
@_subject: [Cryptography] IPv6 and IPSEC 
Here is the bottom line. PHB suggested to use IPv6 as part of a local email encryption solution. I observed that as of two weeks ago, I am unable to send emails via IPv6 to Gmail addresses. Actually, it is worse than that. I am unable to send email via IPv6 to any email address hosted by Google, which are far more email addresses in my address book than emails that end in In its cryptic explanation of the bounces, Google makes one thing clear: whatever reason they have to bounce the email, that reason only applies to IPv6. I believe this is wrong.
Trying to determine the reason for the SMTP 5xx error, given the cryptic explanation in Google's FAQ, I /believe/ they want the forward and RDNS to match. Perhaps I misunderstood the poorly worded explanation.
But this does not change the bottom line: I am no longer able to send email via IPv6 to Google SMTP servers. Not from home, where I have a tunnel via my DSL provider. Not from my server in the colo, which is in a different continent and where I have a full /48.
I can't be the only one with this problem given Google's policy change a couple of weeks ago. Over 95% off my traffic used to flow over IPv6. Since the Google policy change, 0% of my SMTP traffic flows over IPv6. I had no choice but to disable IPv6 in I have no clue what would make Google happy? Matching forward and RDNS? I can't even get that for IPv4. Not at the colo, not at home. Something else? I do not know what that would be, but I am pretty sure whatever it is I cannot bring about.
If nothing else comes out of this thread, if any reader happens to know somebody at Google, perhaps you can convince them to articulate clearly what DNS properties they demand for IPv6 (but not IPv4) that will cause Gmail to again accept SMTP over IPv6.
The irony here is that I have been using IPv6 for years without any problems. Companies such as Google have paved the way for solid IPv6 support by large providers. Never had any problem. And now Google decides to break IPv6 with no clear explanation why or how to remedy the situation.
Flat out of ideas,

@_date: 2013-09-04 09:14:36
@_author: Lucky Green 
@_subject: [Cryptography] IPv6 and IPSEC 
I *have* PTR records for my IPv6 addresses. What I don't know is which PTR records will make Gmail happy. SPF PTR records clearly do not do the trick.

@_date: 2013-09-18 14:23:11
@_author: Lucky Green 
@_subject: [Cryptography] RSA equivalent key length/strength 
Hash: SHA1
Moti Young and others wrote a book back in the 90's (or perhaps) 80's,
that detailed the strength of various RSA key lengths over time. I am
too lazy to look up the reference or locate the book on my bookshelf.
Moti: help me out here? :-)
According to published reports that I saw, NSA/DoD pays $250M (per
year?) to backdoor cryptographic implementations. I have knowledge of
only one such effort. That effort involved DoD/NSA paying $10M to a
leading cryptographic library provider to both implement and set as
the default the obviously backdoored Dual_EC_DRBG as the default RNG.
This was $10M wasted. While this vendor may have had a dominating
position in the market place before certain patents expired, by the
time DoD/NSA paid the $10M, few customers used that vendor's
cryptographic libraries.
There is no reason to believe that the $250M per year that I have seen
quoted as used to backdoor commercial cryptographic software is spent
to any meaningful effect.

@_date: 2014-02-16 18:40:55
@_author: Lucky Green 
@_subject: [Cryptography] BitCoin bug reported 
Those of us that were around in the days of yore may remember how Mondex
failed to implement the simple concept of a two-phase commit. Why would
they incur the overhead hit on transaction times?
No reason to unless your database is actively working to defraud you.
And why would your DB do such a thing? (Especially if you aren't the one
operating the DB?)
I know IanG has been around for long enough to remember the chip card
payment systems that would first credit the payee and only afterwards
debit the payor. The latter part being preventable if you cut the power
to the card before the write. Which was real easy, since a write takes
far more mA than a read.
Often, I think of some of the mid 1990's payment system innovators as
incompetent. Which they were. Yet they were rocket scientists eligible
for Nobel Price compared to some of the Bitcoin outfits that I have met
over the last two years.
Never will I forget sitting down (as a favor to a friend) with a Bitcoin
online wallet outfit crew that is holding an absurd percentage of
Bitcoin bits, who took offense at the very notion that there might be
something to be learned from several millenniums of financial services
best practices.
I say, let them and all of Bitcoin burn to dust.

@_date: 2016-08-06 16:50:49
@_author: Lucky Green 
@_subject: [Cryptography] Where to Find PQC Crypto Libraries? 
Is anyone here aware of cryptographic libraries that implement the
various PQC algorithms, ideally with test vectors?
Even  does not seem to have a link to library
At this point, I'd be happy with a comprehensive library of the various
PQC candidates in any programming language.
My apologies if this is a FAQ item; my search foo has come up empty.

@_date: 2018-12-15 15:17:46
@_author: Lucky Green 
@_subject: [Cryptography] Tim May - Cypherpunks co-Founder 
Dear Friends,
It is with sadness that news reaches me of the passing of my dear friend
Tim May - Cypherpunks co-Founder, Discoverer of Radiation-Induced Single
Even Upsets in Integrated Circuits, and Uncompromising Firearms Proponent:
Ad Astra, Tim!
