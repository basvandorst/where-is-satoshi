
@_date: 2001-07-27 08:36:45
@_author: pasward@big.uwaterloo.ca 
@_subject: Criminalizing crypto criticism 
>  > Yet, on a sad note, public crypto research has to stop.
 > One might think it could survive in purely academic circles.
 > But no, you'd have to be a fool to criticise even an academic paper.
 > Anybody, perhaps the resentful author, could co-opt the work for  > Copy Protection, and off to jail you go.
 >  > We seem to be entering the twilight zone -- the end of an exciting,
 > but brief era -- of public cryptography.
There is life outside the USA.

@_date: 2001-11-02 12:49:23
@_author: pasward@big.uwaterloo.ca 
@_subject: Rubber hose attack 
>  > While I would feel compassion for consumers  > who are hurt or inconvenienced by some huge scam that exploited a poor  > Microsoft security implementation, such a scenario would be entertaining to  > watch.
What makes you believe that you will not be that consumer?

@_date: 2001-11-02 15:41:41
@_author: pasward@big.uwaterloo.ca 
@_subject: Rubber hose attack 
> The default settings will be the permanent settings for many users, and if
 > it is easier to buy something through a .Net affiliate than to shop
 > around, then the .Net sites will get a certain percentage of users just by
 > 'default'.  They won't get all, certainly, but they will get some just
 > because of the path of least resistance.
But it doesn't even matter whether or not you shop around to find a
non-.Net provider.  What matters is whether or not your credit, etc.,
information travels over the .Net system at some point.  You have no
way of knowing that!
A year or so ago there was an article in comp.risks about a web site
that some user felt was insecure, for whatever reason (though not with
respect to the security of the communication).  It gave the option of
'phoning in the order instead of using the browser.  The problem was,
the person at the other end of the 'phone simply entered the data into
the web site.

@_date: 2001-11-21 10:40:11
@_author: pasward@big.uwaterloo.ca 
@_subject: Shades of FV's Nathaniel Borenstein: Carnivore's "Magic Lantern" 
> Everyone remember First Virtual's Nat Borenstein's "major discovery" of the
 > keyboard logger?
 >  > 'Magic Lantern' part of new 'Enhanced Carnivore Project'
 > [etc]
In the same vein, but a different application, does anyone know what
the state of the art is for detecting such tampering?  In particular,
when sitting at a PC doing banking, is there any mechanism by which a
user can know that the PC is not corrupted with such a key logger?
The last time I checked, there was nothing other than the various
anti-virus software.

@_date: 2001-11-21 15:51:19
@_author: pasward@big.uwaterloo.ca 
@_subject: Shades of FV's Nathaniel Borenstein: Carnivore's "Magic Lantern" 
> > In the same vein, but a different application, does anyone know what
 > > the state of the art is for detecting such tampering?  In particular,
 > > when sitting at a PC doing banking, is there any mechanism by which a
 > > user can know that the PC is not corrupted with such a key logger?
 > > The last time I checked, there was nothing other than the various
 > > anti-virus software.
 >  > I can imagine an arms race between the Feds and anti-virus-types, that
 > is until the anti-virus programs are strong-armed one way or the other
 > into backing down.  I am certain that will happen, either behind the
 > scenes or by public law.
 >  > I think you are toast if you are sitting at a PC and the Feds ~really~
 > want to catch your keystrokes.  That is, if the Feds are acting
 > competently.  They might be coy with their good keyloggers to keep
 > samizdat word of their details from getting out.  They might save the
 > good stuff for important targets.
My concern isn't with the Feds snooping.  It is with some criminal who
wants banking-type information so as to rob the account, though it
would appear that solving the one implies solving the other.
 > Alternatively, to move to a physical analogy, instead of leaving a
 > telltale thread on your door and trying to spot intruders that way,
 > you might instead invest in good locks in the first place.  That is,
 > to use a reasonably secure operating system.  At risk of starting an
 > OS war, a well managed Linux box is going to be pretty secure.
 >  > Or, for a practical example, I am typing this on a Linux notebook that
 > mostly is obscured behind firewalls.  If I keep damn Javascript OFF
 > and don't launch viruses that might be sent to me, and don't reuse
 > passwords between here and an unsecure computer, I think they are
 > going to have a very hard time cracking in without my knowing.
But this doesn't really address the question.  Certainly you take
various precautions.  The question is: how can I know if the system is

@_date: 2001-11-21 17:09:38
@_author: pasward@big.uwaterloo.ca 
@_subject: Shades of FV's Nathaniel Borenstein: Carnivore's "Magic Lantern" 
>  > > > Everyone remember First Virtual's Nat Borenstein's "major discovery"
 > > > of the keyboard logger?
 > > >  > > > 'Magic Lantern' part of new 'Enhanced Carnivore Project'
 > >  > > In the same vein, but a different application, does anyone know what the
 > > state of the art is for detecting such tampering?  In particular, when
 > > sitting at a PC doing banking, is there any mechanism by which a user
 > > can know that the PC is not corrupted with such a key logger?  The last
 > > time I checked, there was nothing other than the various anti-virus
 > > software.  >  > 	As much as this will sound like a panacean suggestion, I'd say the
 > best way to avoid being a victim of this sort of attack is to dump Windows
 > and utilize Linux (or Solaris x86) with a GUI front end.  With the advance
 > of *nix GUIs and the advent of utility suites such as Sun Microsystems'
 > Star Office, I've long since abandoned any justification to continue using
 > the Microsoft Windows operating system and office-oriented applications.
 >  > 	Yet another reason why Open Source is your friend.
I did not mean to imply that I am running some variety of windows.  I
am interested in the technical problem of what is the state of the art
for detecting whether or not a computer has been tampered with.  The
use of some version of un*x does not per se solve this.

@_date: 2001-11-21 17:11:16
@_author: pasward@big.uwaterloo.ca 
@_subject: Shades of FV's Nathaniel Borenstein: Carnivore's "Magic Lantern" 
>  >  >  > >  > Everyone remember First Virtual's Nat Borenstein's "major discovery" of the
 > >  > keyboard logger?
 > >  >
 > >  > 'Magic Lantern' part of new 'Enhanced Carnivore Project'
 > >
 > >  > [etc]
 > >
 > > In the same vein, but a different application, does anyone know what
 > > the state of the art is for detecting such tampering?  In particular,
 > > when sitting at a PC doing banking, is there any mechanism by which a
 > > user can know that the PC is not corrupted with such a key logger?
 > > The last time I checked, there was nothing other than the various
 > > anti-virus software.
 > >
 > > Paul
 >  > If you are running a source secret operating system, it is more difficult
 > to detect tampering.
I'm sure it is, unless you have to be the company that owns the
"source-secret operating system," in which case you can presumably do
whatever is done by an open-source system.  Now, what (beyond AV and
tripwire) is done?

@_date: 2001-11-22 16:43:16
@_author: pasward@big.uwaterloo.ca 
@_subject: Shades of FV's Nathaniel Borenstein: Carnivore's "Magic Lantern" 
>  >  >  > >  >
 > >  >
 > >  >
 > >  > >  > Everyone remember First Virtual's Nat Borenstein's "major discovery" of the
 > >  > >  > keyboard logger?
 > >  > >  >
 > >  > >  > 'Magic Lantern' part of new 'Enhanced Carnivore Project'
 > >  > >
 > >  > >  > [etc]
 > >  > >
 > >  > > In the same vein, but a different application, does anyone know what
 > >  > > the state of the art is for detecting such tampering?  In particular,
 > >  > > when sitting at a PC doing banking, is there any mechanism by which a
 > >  > > user can know that the PC is not corrupted with such a key logger?
 > >  > > The last time I checked, there was nothing other than the various
 > >  > > anti-virus software.
 > >  > >
 > >  > > Paul
 > >  >
 > >  > If you are running a source secret operating system, it is more difficult
 > >  > to detect tampering.
 > >
 > > I'm sure it is, unless you have to be the company that owns the
 > > "source-secret operating system," in which case you can presumably do
 > > whatever is done by an open-source system.  Now, what (beyond AV and
 > > tripwire) is done?
 > >
 > > Paul
 >  > There is much that the holder of copyright on a source secret OS could do.
 > But their best efforts would likely be less effective than the best
 > efforts called forth by the market forces which operate on free software.
Unclear at this point.  The fact that a certain company produces a
poor OS, does not mean all secret source OSes are poor.  Are AIX,
HPUX, Solaris, VMS, VM, ... all worse than Linux on this point?  They
certainly tend to be tampered with far less.

@_date: 2001-11-22 16:45:47
@_author: pasward@big.uwaterloo.ca 
@_subject: Shades of FV's Nathaniel Borenstein: Carnivore's "Magic Lantern" 
> -----BEGIN PGP SIGNED MESSAGE-----
 >  >  > >  > 	Yet another reason why Open Source is your friend.
 > >  > > I did not mean to imply that I am running some variety of windows.  I am
 > > interested in the technical problem of what is the state of the art for
 > > detecting whether or not a computer has been tampered with.  The use of
 > > some version of un*x does not per se solve this.  >  > 	I'm afraid we're still in the "arms race" model in that respect.  > Every time one party comes up with a new widget, another party quickly
 > follows with a widget-defeater.  Then the original party releases an
 > updated widget with a widget-defeater-defeater feature.  Then the opposing
 > party responds in kind.  On and on it goes...like a dog chasing its tail.
 >  > 	My original response handles the electronic portion of the
 > equation (though I do concede the point another writer made that all bets
 > are off when the day of the Backdoored BIOS arrives).  If you mean only
 > the physical aspect of the equation, there are a number of tricks you can
 > use ranging from sealing a system with epoxy, locks and so on...or (for
 > those who dig Mission: Impossible stuff), boobytrapping a system to either
 > explode a dye-pack (like that used in banks) or commit digital seppuku if
 > an unauthorized party dicks with it.
 >  > 	I must admit the dye-pack idea has a certain appeal to it.  > Nothing would make my day like seeing some goons come out of my house with
 > bright Candy Apple Red faces. I'm not actually worried about physical access at this point.
Breaking and entering is a lot more difficult that hacking into a
system, and frequently leaves evidence.  More to the point, this is no
different as a risk than that experienced whenever you use a physical
ATM machine to access cash.  My concern is with software access to a
machine that is to be used in the same manner as an ATM.

@_date: 2001-11-22 16:56:35
@_author: pasward@big.uwaterloo.ca 
@_subject: Shades of FV's Nathaniel Borenstein: Carnivore's "Magic Lantern" 
>  > > But this doesn't really address the question.  Certainly you take
 > > various precautions.  The question is: how can I know if the system is
 > > compromised?  >  > 	There's a wealth of utilities that can indicate system compromise.  > These tools range from Tripwire to the Advanced Intrusion Detection
 > Environment (AIDE), plus a range of network sniffing utilities that can be
 > configured to look for unusual traffic.  There's also the CryptoFileSystem
 > that precludes the Great Forces of Malevolence from sneaking things onto
 > your drive without your knowledge.  > 	All of these security-enhancing features must be predicated by
 > cradle-to-grave security, though.  That means trusted installation of a
 > trusted OS from a trusted source on a trusted, non-networked box.  Coupled
 > with that is assured physical security of the system by tamper-evident
 > systems.
I assume you mean non-networked at installation time, not afterwards.
 > 	In the final analysis, there's no substitute for simple human
 > vigilance and a healthy amount of paranoia.  Not one of these tools are of
 > any use if you have a user at the helm who will gleefully download and
 > execute the latest trojan horse.
I'm not entirely sure I believe that last statement.  Let's say I have
a tripwire-like system, but the process is constantly running.  So you
cannot compromise the code on disk in a useful fashion.  What can a
trojan actually do without being detected?

@_date: 2001-11-27 16:57:34
@_author: pasward@big.uwaterloo.ca 
@_subject: private-sector keystroke logger... 
>  > > Hrm, how about a worm with a built-in HTTP server that installs itself
 > > on some non-standard port, say TCP/28462 (to pick one at random)?  >  > 	Craftier still, backdoor an existing service that behaves normally
 > until it receives a few specially-crafted packets, then it opens a high
 > port for direct login or data retrieval.
Neither of these will get past a firewall on an uncompromised machine.

@_date: 2001-11-27 17:12:43
@_author: pasward@big.uwaterloo.ca 
@_subject: IP: Magic Lantern  
>  > On a somewhat related note, is it
 > wise for the FBI to open itself up to potential lawsuits if their
 > software corrupts data or otherwise interferes with legitimate
 > business, or allows an intruder to do so undetected by utilizing the
 > AV-invisibility channel reserved for FBI-ware (if such a thing
 > exists)?
I can see it now:
   FBIware is now ready to complete installation of FBILogger [tm].
   However, you must first read and agree to the following end-user
   licence agreement.  This software is provided as is, with no
   warranty.  Under no circumstance is FBIware responsible for loss or
   corruption of data.  You may have additional rights according to
   the state you live in.
On a slightly more serious note: given the multiplicity of software
that has similar licence agreements, exactly how would you prove in
court that it was the FBI's installed logger software that caused the

@_date: 2001-11-27 17:19:46
@_author: pasward@big.uwaterloo.ca 
@_subject: private-sector keystroke logger... 
> -----BEGIN PGP SIGNED MESSAGE-----
 >  >  > >  > > Hrm, how about a worm with a built-in HTTP server that installs itself
 > >  > > on some non-standard port, say TCP/28462 (to pick one at random)?  > >  >  > >  > 	Craftier still, backdoor an existing service that behaves normally
 > >  > until it receives a few specially-crafted packets, then it opens a high
 > >  > port for direct login or data retrieval.
 > >  > > Neither of these will get past a firewall on an uncompromised machine.
 >  > 	While I didn't enumerate the service that could be backdoored, I
 > do believe Eric Murray hit the nail on the canonical head when he
 > mentioned that such a beastie could target the firewall's configuration,
 > forcing it to relax its stance enough to allow the automated intrusion
 > agent plenty of latitude to conduct its business.
I am assuming a firewall on a separate machine, which simply does not
allow incoming connections to the window's boxes, and constrains the
outgoing connections.  I do not claim that this prevents all covert
loss of data, but it constrains the options, and certainly does not
permit the described backdoor to work.
Better still would be a firewall design that monitored user bahaviour,
and so deviation from that behaviour could be detected.  Again, not
that this is perfect, but it further constrains the options of getting
the data out.

@_date: 2001-10-17 11:34:11
@_author: pasward@big.uwaterloo.ca 
@_subject: Security Research (Was: Scarfo "keylogger", PGP ) 
>  > Not until vendors are held legally accountable for negligent design.
 >  > Maybe someday, somehow, there will be a class action law suit.
 > (I saw a recent infosec conference flyer that had some silly quote
 > about the annual cost of viruses or something being in the
 > $100,000,000,000 range.  :-)
This is probably a silly question, but why isn't such a class action
lawsuit launched?  The stock answer I always here is the EULA.  However, it is my
understanding that if a manufacturer (say a car company) tried to
disclaim or limit liability in the manner in which the software
industry does, any court would throw out the disclaimer and impose its
own standard.
Can you imagine buying a Ford Explorer with the statement like:     "not liable for any damages ....  Under no circumstances will our
    liability exceed the original cost of the product."
Now, can the lawyers please correct my ignorance.

@_date: 2002-01-14 10:04:21
@_author: pasward@big.uwaterloo.ca 
@_subject: CFP: PKI research workshop 
>  > > >  > > >  > > > > If that's not good enough for you, go to  > > > > where you have an SSL secured page.  SSL prevents a man in the middle
 > > > > attack, right?  This means your credit card info goes to Palm
 > > > > Computing, right?  Check the certificate.
 > > >  > > > To be fair,  most commercial CA's require evidence of "right to use"
 > > > a FQDN in an SSL server cert.  But your point is apt.
 > >  > > And most (all?) commercial CAs then disclaim any responsibility for
 > > having actually checked that right correctly...
 > While this is true, I'd point out that all the security software
 > you're using disclaims any responsibility for not having gaping
 > security holes.
If an automaker disclaimed liability for a vehicle, and a negligent
design or manufacture resulted in injury or loss, it is my
understanding that the liability disclaimer notwithstanding, the
automaker would be held responsible.  Why do we believe that the same
would not be the case for software?
Paul Ward

@_date: 2002-01-14 10:17:57
@_author: pasward@big.uwaterloo.ca 
@_subject: CFP: PKI research workshop 
>  > >  > > And most (all?) commercial CAs then disclaim any responsibility for
 > >  > > having actually checked that right correctly...
 > >  > While this is true, I'd point out that all the security software
 > >  > you're using disclaims any responsibility for not having gaping
 > >  > security holes.
 > >  > > If an automaker disclaimed liability for a vehicle, and a negligent
 > > design or manufacture resulted in injury or loss, it is my
 > > understanding that the liability disclaimer notwithstanding, the
 > > automaker would be held responsible.  Why do we believe that the same
 > > would not be the case for software?
 > In that case, why should the liability also apply to CAs, despite their
 > disclaimers?
Do you mean "why should," or "why shouldn't?"  If the latter, then,
sure, I believe it should.  People running around in business selling
products and services and then disclaiming any liability with regard
to their performance _for_their_intended_task_ is, IMHO, wrong.

@_date: 2002-01-23 12:10:10
@_author: pasward@big.uwaterloo.ca 
@_subject: CFP: PKI research workshop 
> >...
 > > People running around in business selling
 > > products and services and then disclaiming any liability with regard
 > > to their performance _for_their_intended_task_ is, IMHO, wrong.
 >  > IMHO this presents an unsophisticated notion of  > "right versus wrong".
 >  > By way of analogy:  Suppose you go skiing in Utah.
 > A rut left by a previous skier causes you to fall
 > and break your leg, or worse.  Now everybody involved
 > has been using the ski area _in_the_intended_manner_
 > yet something bad happened.  So who is liable? The  > ski area could have groomed that trail, but they  > didn't.  They could have enforced a speed limit, but
 > they didn't.  They could at least have bought insurance
 > to cover you, but they didn't.  They simply disclaimed
 > all liability for your injury.  Not only is this  > disclaimer a matter of contract (a condition of sale
 > of the lift ticket) it is codified in Utah state law.
 > Other states are similar.  If you don't like it, don't
 > ski.
First, this is not an analogy.  It is a counter example, and one of
very few that exist.  Second, it is an incorrect example:
     In Clover v. Snowbird Resort, a resort employee, arguably on
     duty, came over a roadcut and collided into the plaintiff. Utah's
     statute imposes on skiers the risk of hazards inherent to the
     sport, which includes changing weather conditions, impact with
     lift towers, collisions with other skiers, and losing control.
     Nevertheless, the Utah Supreme Court held that Utah's ski act
     requires a case-by-case determination to decide whether any
     particular hazard truly is integral to the sport. In that case,
     the court held that an injury caused by an unnecessary hazard
     that could have been eliminated in the exercise of ordinary care
     is not "inherent" and the skier may recover from the area
     operator.
Other states have similar cases and law.  For example, in Colorado
legislation, it explicitly states: 'The term "inherent dangers and
risks of skiing" does not include the negligence of a ski area
operator ....'  Courts are quite good at distinguishing between
inherent risk of an activity, and the duty of care required by a
ski-area operator.
Then we can look beyond this particular example to other segments of
society.  Auto manufacturers cannot disclaim liability even though
driving on a highway at 60 mph is an inherently risky activity.  Pub
owners cannot disclaim liability for their customers who become
drunk.  Not even MacDonald's can disclaim liability for the hot coffee
it serves in drive-thoughs.
So, why does the software industry, and the software-security segment,
persist in the notion that it can disclaim all liability regardless of
negligent coding behaviour?  Duty of care applies.  Does this mean
perfection?  No.  It never has.  However, it does mean that companies
are liable for the negligence of their employees, and disclaimers of
liability will not protect such companies.
 > Returning to PKI in particular and software defects in  > particular:  Let's not make this a Right-versus-Wrong
 > issue.  There are intricate and subtle issues here.
 > Most of these issues are negotiable.
I don't expect perfection.  I expect a duty of care.  Negligent coding
causing loss is not reasonable.   > In particular, you can presumably get somebody to insure
 > your whole operation, for a price.  In the grand scheme
 > of things, it doesn't matter very much whether you (the
 > PKI buyer/user) obtain the insurance directly, or whether
 > the other party (the PKI maker/vendor) obtains the insurance
 > and passes the cost on to you.  The insurer doesn't much
 > care; the risk is about the same either way.
 >  > The fact is that today most people choose to self-insure
 > for PKI defects.  If you don't like it, you have many  > options:
 >  -- Call up some PKI vendor(s) and negotiate for better
 > warranty terms.  Let us know what this does to the price.
 >  -- Call up  or some such and get
 > your own insurance.  Let us know the price.
 >  -- Write your own PKI.  Then defray costs, if desired,  > by becoming a vendor.
 >  -- Et cetera.
You've neglected "sue for damage due to neglience."  Disclaimer of
liability will not carry weight if the PKI vendor is negligent in
their design/implementation.  (Note, I am not saying that proving this
in court would be trivial.)
 > In general, there is a vast gray area between "Right"
 > and "Wrong".  Most things in my life can be described
 > as not perfect, but way better than nothing.
I am not arguing that there are not gray areas, nor that activities
never incur risk.  I am simply arguing that a disclaimer of liability
for the performance of a product will not cover negligence.

@_date: 2002-01-30 08:13:16
@_author: pasward@big.uwaterloo.ca 
@_subject: biometrics 
>  > What would be really nice is to be able to have the same PIN/password for
 > everything. Do you really mean that?  Sure, if I only have to remember one thing
it is easier for me.  It is also a complete nightmare if it is ever
