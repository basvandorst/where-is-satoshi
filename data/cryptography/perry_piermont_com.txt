
@_date: 2001-08-22 11:37:39
@_author: Perry E. Metzger 
@_subject: Timing Analysis of Keystrokes and Timing Attacks on SSH 
What I find really neat here is that up until now, serious traffic
analysis has been fairly neglected in the open crypto community. Is
this the start of things to come?
------- Start of forwarded message -------
Timing Analysis of Keystrokes and Timing Attacks on SSH
Dawn Xiaodong Song, David Wagner, Xuqing Tian
University of California, Berkeley
SSH is designed to provide a security channel between two hosts. Despite the encryption and authentication mechanisms it uses, SSH has two weakness: First, the transmitted packets are padded only to an eight-byte boundary (if
a block cipher is in use), which reveals the approximate size of the original data. Second, in interactive mode, every individual keystroke that a user types is sent to the remote machine in a separate IP packet immediately after the key is pressed, which leaks the interkeystroke timing information of users' typing. In this paper, we show how these seemingly minor weaknesses result in serious security risks.
First we show that even very simply statistical techniques suffice to reveal sensitive information such as the length of users' passwords or even root passwords. More importantly, we further show that using more advanced statistical techniques on timing information collected from the network, the eavesdropped can learn significant information about what users type in SSH sessions. In particular, we perform a statistical study of users' typing patterns and show that these patterns reveal information about the keys typed. By developing a Hidden Markov Model and our key sequence prediction algorithm, we can predict key sequences from the interkeystroke timings. We further develop and attacker system, Herbivore, which tried to learn users' passwords by monitoring SSH sessions. By collecting timing information on the network, Herbivore can speed up exhaustive search for passwords by a factor of 50. We also propose some countermeasures.
In general our results apply not only to SSH, but also to general class of protocols for encrypting interactive traffic. We show that timing leaks open a new set of security risks, and hence caution must be taken when designing this type of protocol.
     - Elias Levy
Si vis pacem, para bellum

@_date: 2001-05-11 16:36:17
@_author: Perry E. Metzger 
@_subject: forwarded from John Gilmore 
X-Spam-Rating: taz3.hyperreal.org 1.6.2 0/1000/N
...on the 8th day of May two thousand one,
The panel modifies the oral instruction for supplemental letter briefs
in the captioned case, given at the close of the argument on May 1,
2001, by authorizing the parties and the Intervenor to augment their
responses to no more than 25 pages, and inviting responses to the
following questions:
1.  Are the anti-trafficking provisions of the Digital Millennium
Copyright Act content-neutral?  See 111 F. Supp 2d 294, 328-29
(S.D.N.Y. 2000).
2.  Does DeCSS have both speech and non-speech elements?
3.  Does the dissemination of DeCSS have both speech and non-speech
4.  Does the use of DeCSS to decrypt an encrypted DVD have both
speech and non-speech elements?
5.  Does the existence of non-speech elements, along with speech
elements, in an activity sought to be regulated alone justify
intermediate level scrutiny?
6.  If DeCSS or its dissemination or its use to decrypt has both
speech and non-speech elements and is not subject to intermediate
levevl scrutiny simply because of the non-speech elements, is
intermediate level scrutiny appropriate because of the close causal
link between dissemination of DeCSS and its improper use?  See 111
F. Supp. 2d at 331-32.
7.  If the District Court is correct that the dissemination of DeCSS
"carries very substantial risk of imminent harm," 111 F. Supp. 2d at
332, does that risk alone justify the injunction?  In other words,
does that risk satisfy the requirements for regulating speech under
Brandenburg v. Ohio, 395 U.S. 444 (1969), thereby rendering
unnecessary an inquiry as to whether non-speech elements of DeCSS or
its dissemination or its use (if such exists) may be regulated under
United States v. O'Brien, 391 U.S. 367 (1968)?
8.  Are the three criteria identified at 111 F. Supp. 2d 333 the
correct criteria for determining the validity, under intermediate
level scrutiny, of the use of DeCSS that has been enjoined?
9.  If not, what modification or supplementation would be required to
conform to First Amendment requirements?
10.  Are the three criteria identified at 111 F. Supp 2d 341 and the
"clear and convincing evidence" standard the correct criteria and the
correct standard of proof for testing the validity of the injunction's
prohibition of posting on the defendant's website and of linking?
11.  If not, what modification or supplementation would be required to
conform to First Amendment requirements?
The references to the District Court's opinion are intended only to
identify some passages that concern the question posed and not to
imply that no other passages in the opinion are pertinent to the
question.  Responses need not be amplified if a "yes" or "no" will
The parties and Intervenor shall submit their supplemental letter
briefs to this Court no later than Wednesday, May 30, 2001.
FOR THE COURT:
Roseann B. MacKechnie, Clerk
By: ___Lucille_Carr___

@_date: 2001-10-10 19:22:27
@_author: Perry E. Metzger 
@_subject: CDT Calls on Internet Activists to Urge Support for Feingold Amendments to Anti-Terrorism Bills 
Forwarded from Interesting People. Not strictly about cryptography, but...

@_date: 2001-10-17 19:20:46
@_author: Perry E. Metzger 
@_subject: IP: FBI To Require ISPs To Reconfigure E-mail Systems (fwd) 
[From Dave Farber's "Interesting People" mailing list. Anyone have any
confirmation of the story?]

@_date: 2001-09-01 12:45:46
@_author: Perry E. Metzger 
@_subject: admin: copyright discussion 
I think I'm calling a halt to the current copyright vs. privacy
discussion -- it is getting too far afield.

@_date: 2001-09-01 12:45:46
@_author: Perry E. Metzger 
@_subject: admin: copyright discussion 
I think I'm calling a halt to the current copyright vs. privacy
discussion -- it is getting too far afield.

@_date: 2001-09-12 19:11:23
@_author: Perry E. Metzger 
@_subject: The tragedy in NYC 
[I sent this originally yesterday, but the, er, problems our mail
server in downtown New York suffered for a while caused some
delay. Another copy was published on Dave Farber's interesting
people. Several people wrote me afterwards vilifying me. Ah well.
The list is now running on a new machine in Virginia, which
should be safe even as more buildings collapse and burn.  --Perry]
In the wake of the tragedy in NYC today, I was asked by someone if I
didn't now agree that crypto was a munition. At the time, I thought
that a friend of mine was likely dead. (I've since learned he escaped
in time.)
My answer then, when I thought I'd lost a friend, was the same as my
answer now and the answer I've always had.
Cryptography must remain freely available to all.
In coming months, politicians will flail about looking for freedoms to
eliminate to "curb the terrorist threat". They will see an opportunity
to grandstand and enhance their careers, an opportunity to show they
are "tough on terrorists".
We must remember throughout that you cannot preserve freedom by
eliminating it. The problem is not a lack of laws banning things.
I know the pressure on everyone in Washington will be to "do
something". Speaking as a New Yorker who dearly loves this city, who
has felt deep shock throughout most of the day, watching the smoke
still rising from the fires to the south of me, listening to the
ambulances and police cars continuing to wail about me, let me say
this:    I do not want more laws passed in the name of defending my home.
   I do not want more freedoms eliminated to "preserve freedom".
   I do not want to trade my freedom for safety. Franklin has said far
   more eloquently than me why that is worthless.
If you must do something, send out more investigators to find those
responsible for this and bring them to justice. Pass no new laws. Take
away no freedoms. Do not destroy the reason I live here to give me
"safety". I'd rather die in a terrorist attack.

@_date: 2001-09-13 16:51:35
@_author: Perry E. Metzger 
@_subject: Rijndael in Assembler for x86? 
Because it is typically slower by many times than hand tuned assembler.

@_date: 2001-09-15 18:10:07
@_author: Perry E. Metzger 
@_subject: Which internet services were used? 
This claim is, however, wrong.
First, lets look at the question of automobiles. Automobiles certainly
reduce the ability of law enforcement to do its job. The accomplices
of the hijackers almost certainly fled their locations in
automobiles. They would have been unable to go far without
automobiles. It has also been noted in some of the media that Ossama
bin Ladin left his location shortly after the attacks -- presumably in
an automobile. Not having automobiles would have made it easier to
bomb Mr. bin Ladin and to catch accomplices. However, no one would
suggest this for fear of looking foolish. The arguments about
encryption are virtually identical -- only people are unfortunately
not so afraid of looking like fools in public.
It can be argued that not requiring recordings of all phone
conversations "impedes law enforcement". Indeed, one would expect such
recordings to be necessary, given that even if made in the clear, it
would be impossible to go back in time to listen in on the
conversations of the hijackers. Would you like that done?
It can be argued that strong encryption made the deaths of these 4000
people possible. How it made it possible is never explained. Let us
try exploring that question, however.
If there were no strong encryption, what could have been done
differently? Perhaps without it law enforcement could systematically
listen in on every conversation everywhere and every email message
flowing worldwide and record them and listen for "threats". They would
have had to. After all, had they known who these people were in
advance, they could have simply targeted them for intense surveillance
including bugging their homes and computers. By definition they DID
NOT know who they were, so they would have needed to search
Lets say such universal surveillance -- a horror I cannot imagine --
were both possible and practical. Would it have stopped anything?
No. In response, the hijackers would simply have visited each other in
person to coordinate their plot, and we have already established that
had the government known who they were so they could have bugged such
conversations, universal surveillance would not have been required in
the first place.
Would it have been so difficult for them to, say, go and visit each
other to pick a date to fly planes into the World Trade Center?
It is trivial to blame encryption here, but I can't see that it is
reasonable to blame it. There is no evidence at all -- NONE -- that in
the absence of encryption it would not be equally possible to carry
out such attacks. I repeat:
  There is no evidence at all that in the absence of encryption it
  would not be equally possible to carry out such attacks.
At the very best, the internet could have provided a convenience to
the plotters -- no more.
The killing of Israeli athletes at Munich involved no encryption --
nor did a thousand other attacks. Why would you need encryption to be
a terrorist?
The people who claim "such an attack could only be made possible
via coordination over the internet" obviously don't remember that
people managed to communicate dates to meet even before there were
phones or even post offices, let alone the internet.
These same people ignore the fact that the US economy, and indeed the
world economy, could no longer function without encryption. Encryption
is vital to PREVENTING crime, you see. It provides enormous and
powerful security to ordinary people conducting their ordinary
affairs. Most are unaware that they're using encryption, but they
are. Would you like it easier for people to break into computer
networks? Would you like your electrical power system or your local
hospital to be more vulnerable to remote attack?  Just ban
encryption. Your wishes will be made manifest.
Ultimately, what is unsaid is that if widespread encryption is used,
the NSA will be unable to vacuum-cleaner listen in on billions of
conversations and transactions and spot such things before they
happen. Ignoring the vast and horrific intrusion that such systematic
surveillance of all members of society implies, there is no evidence
that terrorists couldn't simply modify their methods in response to
this, just as communist terrorists in Germany did when they
systematically studied law enforcement techniques to evade capture in
the 1970s and 1980s. Nothing obligates a terrorist to obey the law,
nothing obligates them to conduct their affairs in such a way as to
permit easy capture.
There is also the question of skill. Even if you could find every copy
of PGP on earth and erase it, if Ossama bin Laden could get his people
trained as pilots, what would be so hard about getting them copies of
Bruce Schneier's book? Or do you plan to ban it and all the others? I
teach cryptography, and can testify that although most students are
mediocre and couldn't devise new encryption algorithms, they do not
need to. Even the mediocre ones can code to recipes. If they need
encryption, they will get it, and people who hijack planes do not fear
your laws.
There is a sense among politicians and the more foolish members of
wider society that we must "do something" to prevent this kind of
tragedy -- that doing ANYTHING is better than doing nothing. Well,
there are a number of kinds of "anything" that are far, far worse than
doing nothing.

@_date: 2001-09-27 21:30:13
@_author: Perry E. Metzger 
@_subject: Cathy Young column on encryption, wiretapping 
Comments on Cathy Young's Reason article calling encryption "scary",
forwarded from Dave Farber's "Interesting People" list.

@_date: 2002-08-13 12:18:21
@_author: Perry E. Metzger 
@_subject: [aleph1@securityfocus.com] Implementation of Chosen-Ciphertext Attacks against PGP and GnuPG 
An embedded message was scrubbed...
Size: 1750
URL:

@_date: 2002-08-16 12:57:09
@_author: Perry E. Metzger 
@_subject: employment market for applied cryptographers? 
Hard to say.
I've seen very high rates of unemployment among people of all walks of
life in New York of late -- I know a lot of lawyers, systems
administrators, secretaries, advertising types, etc. who are out of
work or have been underemployed for a year or longer. I'm not sure
that it is just cryptographers.
Always keep in mind when you hear the latest economic statistics that
measuring the size of the US economy, or the number of unemployed
people, is partially voodoo. When was the last time you saw any
estimate of the margin of error on the supposedly "scientific"
measurement of quarterly economic growth? How many illegal immigrants
are being polled in the employment stats? How much of the revenue of
underground businesses gets counted in the GDP figures?
[I myself am not working at the moment, but voluntarily so I suppose I
wouldn't count in the statistics as "unemployed" -- starting a company
during a recession turns out to be a great way to burn yourself
completely out out, and I decided to take some time off of
working. Haven't given much thought to what I'll do to find a job when
I decide I want one again...]

@_date: 2002-08-17 15:11:44
@_author: Perry E. Metzger 
@_subject: Quantum computers inch closer? 
[I don't know what to make of this story. Anyone have information? --Perry]
Quantum computer called possible with today's tech
MADISON, Wis.   Researchers at the University of Wisconsin in
Madison claim to have created the world's first successful simulation
of a quantum-computer architecture that uses existing silicon
fabrication techniques. By harnessing both vertical and horizontal
tunneling through dual top and bottom gates, the architecture lays
out interacting, 50-nanometer-square, single-electron quantum dots
across a chip.
"Our precise modeling elucidates the specific requirements for
scalable quantum computing; for the first time we have
translated the requirements for fault-tolerant quantum computing into
the specific requirements for gate voltage control electronics in
quantum dots," said professor Mark Eriksson of the university's
Department of Physics. The group of researchers has concluded that existing silicon
fabrication equipment can be used to create quantum computers, albeit
at only megahertz speeds today due to the stringent requirements of
its pulse generators. To achieve gigahertz operation, the group has
pinpointed the device features that need to be enhanced to prevent
leakage errors, and has already begun work on fabricating a
prototype. "We believe that quantum computers are possible today with the
component technologies we already have in place for silicon,"
Eriksson said. The team composed their quantum "bits" out of electron
spin: up for "1," down for "0." Encoding bits in spins allows a
single electron to represent either binary value, and because of the
indeterminacy of quantum spins, they can represent both values during
calculations to effectively create a parallel process.
"Our technique may enable quantum computers to actually begin
performing calculations that can't be performed any other way,"
Eriksson said. Others have demonstrated a few quantum dots
interacting to perform calculations but Eriksson estimates that a
million quantum bits (qubits) will be needed to create quantum
computers that perform useful real-world applications. For that,
silicon fabrication equipment offers the best solution, according to
Eriksson. Eriksson's team matched silicon germanium fabrication capabilities to
quantum-dot requirements. The result is an array of quantum dots,
each of which houses a single electron, with electrostatic gates
controlling qubit interactions. The team then optimized and
exhaustively simulated the model, which it declared to be a
successful design.
The design constraints included reducing the population of electrons
in quantum dots to one, while permitting tunable coupling between
neighboring dots. The team met those conditions by employing both
vertical and horizontal tunneling to first confine and then slightly
alter the location of individual electrons.
A back gate serving as the chip substrate acts as an electron
reservoir from which quantum dots can draw their single electrons
using vertical tunneling into the quantum-well layer. That layer acts
as the vertical confinement barrier, with an insulator above and
below it, enabling the vertical size of the quantum dots to be just
big enough for one. A grid of top gates then provides the horizontal
separation between dots by supplying electrostatic repulsion from
The semiconductor layers were formed from strain-relaxed SiGe, except
for the quantum-well layer, which was pure, strained silicon. The
bottom gate was formed from a thick n-doped layer with a 10-nm,
undoped tunneling barrier separating it from the 6-nm-thick
quantum-well layer. Another 20-nm-thick tunnel barrier above the
quantum-well layer separated it from the metallic top gates, the team
Researchers load the electrons into the quantum dots from below by
adjusting the potentials on the top gates to induce an electron from
the bottom gate to tunnel vertically up into the quantum-well layer.
Once loaded, the electron stays in place because of the electrostatic
force from the top gates. When the team weakens the force between
selected quantum dots by adjusting the top gates between them, the
adjacent dots are permitted to interact, thus enabling calculations
to be made.
The normal errors encountered during quantum calculations could
mostly be corrected, according to Eriksson's simulations. Careful
consideration of the simulations led the researchers to predict that
leakage could be tuned out sufficiently by low temperatures combined
with a modified heterostructure that allowed larger electrical
fields. With existing fabrication techniques, the team estimates that a
million-quantum-dot computer (1,024 x 1,024 array) could be built
today and operated in the megahertz range.

@_date: 2002-12-09 14:18:40
@_author: Perry E. Metzger 
@_subject: from IP: FISA and the Courts 
Forwarded from Dave Farber's list:
I plan to be there djf
Dave, I'll be moderating a fairly high-powered panel in Washington on Wednesday
December 11.  The panel will discuss the recent FISA decision about the
"wall" between law enforcement and intelligence intercepts.   The public is
welcome, but I think the committee is charging $20 to cover the refreshments
that follow.  Details below.
Stewart Baker The American Bar Association Standing Committee on Law and National Security
presents -- FISA and the Courts --
What the Recent Decision Means for Intelligence Intercepts
Wednesday, December 11, 2002
5:00 - 7:00 p.m. University Club 1135 16th Street, NW
Washington, DC The FISA Review Court's recent decision is the most detailed and sweeping
examination of FISA and its constitutionality in a quarter century.  By
overturning the lower FISA court's guidelines and providing broad discretion
to Executive decision makers, the ruling of this three-judge panel will
allow intelligence investigators and criminal prosecutors to more easily
share information about ongoing terrorism and espionage cases.  Questions
remain, including the most basic: where the constitutional lines should be
drawn on intelligence intercepts, whether prosecutors should direct
electronic and physical surveillance under FISA, and what if anything should
remain of the "wall" between law enforcement and intelligence.   The appeal
was argued in secret, and only by the Department of Justice.  This will be a
rare public airing of the issues the FISA appeals court has struggled to
Panelists will include the Justice Department attorney who argued the
appeal, a former Justice Department official who was involved in some of the
earliest guidelines for FISA intercepts, and the General Counsel of the
Senate Select Committee on Intelligence during the debate over the USA
PATRIOT ACT. Panel: Stewart Baker, Moderator
Ken Bass, former Counsel for Intelligence Policy, U.S. Department of Justice
and currently in private practice.
David Kris, Associate Deputy Attorney General, U.S. Department of Justice
Vicki Divoll, General Counsel, Senate Select Committee on Intelligence

@_date: 2002-02-16 17:56:52
@_author: Perry E. Metzger 
@_subject: 802.11x insecure? 
Various news stories have been noting that the 802.1x security
protocol seems to have flaws. See, for example:
and the actual paper at:

@_date: 2002-01-23 10:39:19
@_author: Perry E. Metzger 
@_subject: ADMIN: Trim your posts 
A new trend in our postings has emerged -- people quoting hundreds of
lines of text to add three or four new lines.
If there is a lot more quoted material than new material in your
posting, there is something wrong. If you can't take the time to trim
the .signatures, footers, and other extraneous materials from your
postings, it is not clear why people should take the time to read
In short, trim what you quote.

@_date: 2002-11-06 11:58:45
@_author: Perry E. Metzger 
@_subject: Did you *really* zeroize that key? 
Someone wrote to me:
K&R is not the C standard. Quoting the C99 standard, section 6.7.3.6:
     An object that has volatile-qualified type may be modified in
     ways unknown to the implementation or have other unknown side
     effects. Therefore any expression referring to such an object
     shall be evaluated strictly according to the rules of the
     abstract machine, as described in 5.1.2.3. Furthermore, at every
     sequence point the value last stored in the object shall agree
     with that prescribed by the abstract machine, except as modified
     by the unknown factors mentioned previously.
In other words: no, "volatile" is mandatory and in fact will be
guaranteed to be implemented as expected. This is very important --
virtually every operating system requires "volatile" for purposes like
writing device drivers.

@_date: 2002-11-06 15:15:22
@_author: Perry E. Metzger 
@_subject: German authorities bungle wiretaps. 
"German police have been forced to admit that dozens of criminal
suspects had learned their phones were being tapped when the evidence
showed up on their monthly phone bill."
"Telecommunications authorities said that nearly 20,000 lines were
currently being tapped."

@_date: 2002-11-06 15:32:30
@_author: Perry E. Metzger 
@_subject: New Protection for 802.11 
Does anyone know details of the new proposed protocols?

@_date: 2002-11-08 01:07:51
@_author: Perry E. Metzger 
@_subject: the "volatile" keyword 
* the c99 standard and its predecessors don't
     at all intend "volatile" to mean what we naively
     think it means.  specifically, in the hands of a
     high-end compiler developer, the spec's statement:
        "any expression referring to [a volatile]
         object shall be evaluated strictly according
         to the rules of the abstract machine"
     is really talking about what the compiler can
     infer about the program's intended semantics.
     a c99-compliant compiler _can_ legitimately
     remove a volatile access, as long as the compiler
     can deduce that the removal won't affect the
     "program's result." Sorry, but that is really not correct at all.
"volatile" exists because there are times when you absolutely need to
know that the compiler will not alter your intent. A typical example
is in touching a device register in a device driver. You may very well
need to write a certain set of values out to a particular memory
location in a particular order and not have them optimized away or
reorganized. It may be vitally important to access register 2 and then
register 1, or to write multiple values out to register 4 before
touching register 3, or what have you.
In a driver or in a situation like this you really do mean "write a
one there and then write a ten there and never mind that you think you
can optimize away writing the one there."  "volatile" means that the
memory location has side effects and that you CANNOT deduce the result
of the operations and thus are required to not touch the sequence at
all. The spec specifically states that you may NOT remove or reorder
sequence points if "volatile" is in use.
That is why "volatile" exists. It means "do NOT reorder or eliminate
access to these memory locations on pain of death". The intent of the
spec is precisely what I've said, and I'll happily quote chapter and
verse to prove it.
There are several similar misconceptions about the "volatile" keyword
that have been propagated in recent messages.
Claims that "volatile" does not guarantee a safeguard against such
optimizations are specious. That is exactly why "volatile" was
introduced, and if, for example, gcc did not honor it, the machine I
am typing at right now would not work because the device drivers would
not work. Any optimizing compiler that people write device drivers in
practically *has* to support "volatile" or it won't work for that
purpose. (In the days before "volatile" you needed vile tricks to
assure your intent was followed, or you needed to not optimize driver
code, or both.)
Some have claimed "volatile is not a mandatory part of C". Well, it is
certainly mandatory in the C standards I have at hand. C99 makes it
abundantly clear that you have to do it and do it correctly.
Some have claimed "you can't know that the compiler writer implemented
volatile correctly so you need a  Well, that doesn't actually
help you. If they haven't implemented "volatile" right, why should
they implement the pragma correctly? We already have a way of
indicating "do not reorder or eliminate this code" which is in
existing standards -- if it doesn't work, that's a bug in your
compiler, and it is better to get the bug fixed than to ask for
another feature to be added that might also be buggy and which is not
part of the standard.
So in short, yes, "volatile" might be implemented in a buggy way by
your compiler (which you should certainly test for if it is important
to you!) but if your compiler is in fact properly implemented and
standards compliant, "volatile" is the way to accomplish what you are
trying to accomplish here.

@_date: 2002-11-13 16:54:16
@_author: Perry E. Metzger 
@_subject: ADMIN: list will have delays during the next week 
I'll be on line only sporadically for some days because of a family
emergency.  I'll try to deal with moderation duties when I can, but
don't be surprised if it is a few days between message batches.

@_date: 2002-11-16 15:09:48
@_author: Perry E. Metzger 
@_subject: [Bruce Schneier] CRYPTO-GRAM, November 15, 2002 
An embedded message was scrubbed...
Size: 28989
URL:

@_date: 2002-10-04 12:14:47
@_author: Perry E. Metzger 
@_subject: new copyright bill... 
NEW COPYRIGHT BILL WOULD GIVE POWER TO THE PEOPLE
Rep. Rick Boucher (D-Va.) and Rep. John Doolittle (R-Calif.) have introduced legislation aimed at restoring specific fair use rights to copy digital works that were lost under the 1998 Digital Millennium Copyright Act, as well as bestowing "circumvention" rights to bypass copy protections when done "solely in furtherance of scientific research." The Digital Media Consumers Rights Act has drawn support from a broad coalition of electronics and computer interests, consumer groups and academics. "It's just time," said Consumer Electronics Association president Gary Shapiro. "Consumers have been pushed up against the ropes. This is the first time in 20 years in which consumers are going on the offense rather than on the defense." Meanwhile, entertainment groups bemoaned this latest development in the battle over digital media rights. "If this bill were to be enacted, content owners would be left with two unhappy choices: Protect their valuable works by not making them available in digital formats such as DVD, or lose all control over unauthorized reproduction and distribution," said Jack Valenti, president of the Motion Picture Association of America. The bill has no chance of passage this year, but will set the stage for debate in the next session of Congress. (Wired.com 4 Oct 2002)

@_date: 2002-10-09 11:03:35
@_author: Perry E. Metzger 
@_subject: open source CAs? 
Beyond the openssl tools (which are quite primitive), are there any
open source certificate authority tools out there at the moment that
people can recommend?

@_date: 2002-10-15 22:47:38
@_author: Perry E. Metzger 
@_subject: [Bruce Schneier <schneier@counterpane.com>] CRYPTO-GRAM, October 15, 2002 
The content on AES is of some interest, as are a couple of other

@_date: 2002-09-16 11:03:21
@_author: Perry E. Metzger 
@_subject: possible attacks on AES... 
Bruce Schneier's Cryptogram reports on some possible attacks on
AES. I'd appreciate more detail from anyone who is involved with such work:

@_date: 2002-09-16 16:32:04
@_author: Perry E. Metzger 
@_subject: Cryptogram: Palladium Only for DRM 
That's what an MMU and file permissions are for. Palladium isn't
needed for such a thing.
Why not simply design the OS so it is not a likely victim for viruses?
This is a general security problem, not one special to banking
operations. My own machine doesn't seem to get viruses -- but then
again it doesn't run Windows. Funny, that.
(And before you mention the current worm infecting Linux apache sites,
that's also caused by bad design, not an problem that requires
hardware to fix.)
There are patches to NetBSD that happily prevent a program that does
not have a particular hash from executing, and similar code for
several other OSes I've seen. We need no hardware to do this. On the
other hand, who needs hash functions when an ordinary user can't alter
the executable because he doesn't have permissions?
I know this is a new concept to windows users -- I had to give my CFO
admin privs on his XP box because Quickbooks refused to run otherwise

@_date: 2002-09-16 23:01:06
@_author: Perry E. Metzger 
@_subject: Cryptogram: Palladium Only for DRM 
It takes a lot for me to get cranky around here, but I'm afraid Aarg!
has done it.
You conveniently cut what I said selectively, sarcastically replying
to only pieces of it. You completely ignored much of the substance,
such as the fact that in a correctly operating OS, MMUs+file
permissions do more or less stop processes from seeing each others
data if the OS functions correctly.
So, to summarize, you ignored most of what I said, but managed to be
incredibly rude. I've noticed you doing the same to lots of others.
Here's a strong suggestion for the future, Anonymous. Never anger the
moderator of a moderated mailing list. You can be the agent
provocateur all day long, but you can't be snide and unresponsive.
I'm going to ask that you go back and respond to my message without
being insulting and without being selective about what sections you
quote. If you want another copy, well, I don't know how to send it to
you -- I can only hope you saved it. Until then, I'm not forwarding
your mail.
If you want to play your game here, you're going to have to do it
politely and reasonably. Sorry for doing this in public but I have no
other way of communicating with you.

@_date: 2002-09-17 20:25:29
@_author: Perry E. Metzger 
@_subject: bluetooth cryptosystems 
Does anyone have good pointers to papers on the security of E0 and the
rest of the stuff used in bluetooth? It all looks very fragile.

@_date: 2002-09-18 21:55:38
@_author: Perry E. Metzger 
@_subject: Cryptogram: Palladium Only for DRM 
This brings to mind my youth, in which I worked for a wall street firm
in which we systematically cracked the copy protection and license
managers on SunOS software we were using. Was it to pirate the
software? No. We paid for every license. It was because the
manufacturers had neglected to consider that in a 24x7 environment
having a machine go down meant that we needed to bring the software up
on hosts other than the one originally licensed, and we didn't have
time to wait until Monday when everyone got back to their office and
give us a new key. A few small kernel patches allowed us to routinely
tell programs that the host id was whatever we wanted them to think it was.
I recently have heard tell from friends of similar systematic uses of
cracked Microsoft software at a number of places -- not because these
places pirate the software, but because they can't deal with the
constant failures that the increasingly belligerent M$ copy
restrictions bring. Customers need to get work done, and the copy
protections get in the way. XP is particularly egregious in this
regard, but some people are getting around this with cracking tools,
even though they pay for their software legitimately.
One wonders if better license enforcement might not be a good thing,
since it would doubtless finish off Microsoft by eliminating the
ability of their legitimate customers to evade their license
enforcement software, thus driving them to use open source products.

@_date: 2002-09-19 22:18:46
@_author: Perry E. Metzger 
@_subject: Sun donates elliptic curve code to OpenSSL? 
According to this:
Sun is donating some elliptic curve code to the OpenSSL project. Does
anyone know details that they would care to share on the nature of the

@_date: 2002-09-20 12:07:38
@_author: Perry E. Metzger 
@_subject: unforgeable optical tokens? 
A couple of places have reported on this:
An idea from some folks at MIT apparently where a physical token
consisting of a bunch of spheres embedded in epoxy is used as an
access device by shining a laser through it.
On the surface, this seems as silly as biometric authentication -- you
can simply forge what the sensor is expecting even if you can't forge
the token. Does anyone know any details about it?

@_date: 2002-09-20 13:04:39
@_author: Perry E. Metzger 
@_subject: unforgeable optical tokens? 
But if you can't simulate the system, that implies that the challenger
has to have stored the challenge-response pairs because he can't just
generate them, right? That means that only finitely many are likely to
be stored. Or was this thought of too?

@_date: 2002-09-24 13:56:51
@_author: Perry E. Metzger 
@_subject: Don Coppersmith questions Courtois and Pieprzyk AES results 
Don Coppersmith questions Courtois and Pieprzyk AES results -- see:

@_date: 2002-09-25 01:42:48
@_author: Perry E. Metzger 
@_subject: [Werner Koch <wk@gnupg.org>] GnuPG 1.2 released 
Mail-Followup-To: gnupg-users at gnupg.org
We are pleased to announce the availability of a new stable release of
GnuPG: Version 1.2.0
The GNU Privacy Guard (GnuPG) is GNU's tool for secure communication
and data storage.  It is a complete and free replacement of PGP and
can be used to encrypt data and to create digital signatures.  It
includes an advanced key management facility and is compliant with the
proposed OpenPGP Internet standard as described in RFC2440.  This new
release implements most of OpenPGP's optional features, has somewhat
better interoperabilty with non-conforming OpenPGP implementations and
improved keyserver support.
Getting the Software
GnuPG 1.2.0 can be downloaded from one of the *GnuPG mirror sites*.
The list of mirrors can be found at See below for a list of mirrors already carrying this new released.
On the mirrors you should find the follwing files in the *gnupg*
  gnupg-1.2.0.tar.bz2 (1.8 MB)
  gnupg-1.2.0.tar.bz2.sig
      GnuPG 1.2 source compressed using BZIP2 and OpenPGP signature.
  gnupg-1.2.0.tar.gz (2.5 MB)
  gnupg-1.2.0.tar.gz.sig
      GnuPG source compressed using GZIP and OpenPGP signature.
  gnupg-1.0.7-1.2.0.diff.gz (1.0 MB)
      A patch file to upgrade a 1.0.7 GnuPG source. This file is
      signed; you have to use GnuPG > 0.9.5 to verify the signature.
      GnuPG has a feature to allow clear signed patch files which can
      still be processed by the patch utility.
Select one of them. To shorten the download time, you probably want
to get the BZIP2 compressed file.  Please try another mirror if
exceptional your mirror is not yet up to date.
In the *binary* directory, you should find these files:
  gnupg-w32cli-1.2.0.zip (1.0 MB)
  gnupg-w32cli-1.2.0.zip.sig
      GnuPG compiled for Microsoft Windows and OpenPGP signature.
      Note that this is a command line version and comes without a
      graphical installer tool.  You have to use an UNZIP utility to
      extract the files and install them manually.  The included file
      README.W32 has further instructions. Checking the Integrity
In order to check that the version of GnuPG which you are going to
install is an original and unmodified one, you can do it in one of
the following ways:
 * If you already have a trusted version of GnuPG installed, you
   can simply check the supplied signature.  For example to check the
   signature of the file gnupg-1.2.0.tar.bz2 you would use this command:
     gpg --verify gnupg-1.2.0.tar.bz2.sig
   This checks whether the signature file matches the source file.
   You should see a message indicating that the signature is good and
   made by that signing key.  Make sure that you have the right key,
   either by checking the fingerprint of that key with other sources
   or by checking that the key has been signed by a trustworthy other
   key.
   Never use a GnuPG version you just downloaded to check the
   integrity of the source - use an existing GnuPG installation.
 * If you are not able to use an old version of GnuPG, you have to verify
   the MD5 checksum.  Assuming you downloaded the file
   gnupg-1.2.0.tar.bz2, you would run the md5sum command like this:
     md5sum gnupg-1.2.0.tar.bz2
   and check that the output matches the first line from the
   following list:
     b22b10dacfeb5c2b0bc4ce9def2d1120  gnupg-1.2.0.tar.bz2
     e93ceafc4395d1713d20044d523d18a7  gnupg-1.2.0.tar.gz
     c735a9a4400e3e3b0b78f88aadedfd3d  gnupg-1.0.7-1.2.0.diff.gz
     af439e3ba82c8648041e8e9d902c3c01  gnupg-w32cli-1.2.0.zip
Upgrade Information
The name of the default configuration file has changed from "options"
to "gpg.conf".  The old name will still be used as long as no
"gpg.conf" exists.  We recommend to rename your file after the
If you are upgrading from a version prior to 1.0.7, you may want to
run the command "gpg --rebuild-keydb-caches" once to speed up the
keyring access. Please note also that due to a bug in versions prior
to 1.0.6 it won't be possible to downgrade to such versions unless you
use the GnuPG version which comes with Debian's Woody release or you
apply the patch  .
If you have any problems, please see the FAQ and the mailing list
archive at   Please direct questions to the
gnupg-users at gnupg.org mailing list.
What's New
Here is a list of major user visible changes since 1.0.7:
  Configuration:
    * The default configuration file is now ~/.gnupg/gpg.conf.  If an
      old ~/.gnupg/options is found it will still be used.  This
      change is required to have a more consistent naming scheme with
      forthcoming tools.
    * The configure option --with-static-rnd=auto allows to build gpg
      with all available entropy gathering modules included.  At
      runtime the best usable one will be selected from the list
      linux, egd, unix.  This is also the default for systems lacking
      a /dev/random device.
    * All modules are now linked statically; the --load-extension
      option is in general not useful anymore.  The only exception is
      to specify the deprecated IDEA cipher plugin.
    * There are now various ways to restrict the ability GnuPG has to
      exec external programs (for the keyserver helpers or photo ID
      viewers).  Read the README file for the complete list.
    * The keyserver helper programs now live in
      /usr/[local/]libexec/gnupg by default.  If you are upgrading
      from 1.0.7, you might want to delete your old copies in
      /usr/[local/]bin.  If you use an OS that does not use libexec
      for whatever reason, use configure --libexecdir=/usr/local/lib
      to place the keyserver helpers there.
  New features:
    * New "group" command to refer to several keys with one name.
    * The option --interactive now has the desired effect when
      importing keys.
    * Full revocation key (aka "designated revoker") support.
    * When using --batch with one of the --delete-key commands, the
      key must be specified by fingerprint.  See the man page for
      details.
    * New export option to leave off attribute packets (photo IDs)
      during export.  This is useful when exporting to HKP keyservers
      which do not understand attribute packets.
    * New import option to repair during import the HKP keyserver
      mangling multiple subkeys bug.  Note that this cannot completely
      repair the damaged key as some crucial data is removed by the
      keyserver, but it does at least give you back one subkey.  This
      is on by default for keyserver --recv-keys, and off by default
      for regular --import.
    * New commands: --personal-cipher-preferences,
      --personal-digest-preferences, and
      --personal-compress-preferences allow the user to specify which
      algorithms are to be preferred.  Note that this does not permit
      using an algorithm that is not present in the recipient's
      preferences (which would violate the OpenPGP standard).  This
      just allows sorting the preferences differently.
    * New --attribute-fd command for frontends and scripts to get the
      contents of attribute packets (i.e. photos)
  Incompatible changes:
    * Options --emulate-checksum-bug and --emulate-3des-s2k-bug have
      been removed.
    * The IDEA plugin has changed.  Previous versions of the IDEA
      plugin will no longer work with GnuPG.  However, the current
      version of the plugin will work with earlier GnuPG versions.
    * ElGamal sign and encrypt is not anymore allowed in the key
      generation dialog unless in expert mode.  RSA sign and encrypt
      has been added with the same restrictions.
  OpenPGP compatibility:
    * The use of MDCs have increased.  A MDC will be used if the
      recipients directly request it, if the recipients have AES,
      AES192, AES256, or TWOFISH in their cipher preferences, or if
      the chosen cipher has a blocksize not equal to 64 bits
      (currently this is also AES, AES192, AES256, and TWOFISH).
    * GnuPG will no longer automatically disable compression when
      processing an already-compressed file unless a MDC is being
      used.  This is to give the message a certain amount of
      resistance to the chosen-ciphertext attack while communicating
      with other programs (most commonly PGP earlier than version 7.x)
      that do not support MDCs.
    * The preferred hash algorithms on a key are consulted when
      encrypting a signed message to that key.  Note that this is
      disabled by default by a SHA1 preference in
      --personal-digest-preferences.
    * --cert-digest-algo allows the user to specify the hash algorithm
      to use when signing a key rather than the default SHA1 (or MD5
      for PGP2 keys).  Do not use this feature unless you fully
      understand the implications of this.
    * --pgp7 mode automatically sets all necessary options to ensure
      that the resulting message will be usable by a user of PGP 7.x.
  Bug fixes:
    * The file permission and ownership checks on files have been
      clarified.  Specifically, the homedir (usually ~/.gnupg) is
      checked to protect everything within it.  If the user specifies
      keyrings outside this homedir, they are presumed to be shared
      keyrings and therefore *not* checked.  Configuration files
      specified with the --options option and the IDEA cipher
      extension specified with --load-extension are checked, along
      with their enclosing directories.
    * The LDAP keyserver handler now works properly with very old
      (version 1) LDAP keyservers.
    * [W32] Keyserver access does work with Windows NT.
  Other changes:
    * A warning is issued if the user forces the use of an algorithm
      that is not listed in the recipient's preferences.
    * In expert mode, the user can now re-sign a v3 key with a v4
      self-signature.  This does not change the v3 key into a v4 key,
      but it does allow the user to use preferences, primary ID flags,
      etc.
    * Significantly improved photo ID support on non-unixlike
      platforms.
    * The default character set is now taken from the current locale;
      it can still be overridden by the --charset option.  Using the
      option -vvv shows the used character set.
GnuPG comes with support for these langauges:
  American English          Greek (el)                        Catalan (ca)              Indonesian (id)                   Czech (cs)                Italian (it)                      Danish (da)[*]            Japanese (ja)                     Dutch (nl)[*]             Polish (pl)                       Esperanto (eo)[*]         Brazilian Portuguese (pt_BR)[*]
  Estonian (et)[*]          Portuguese (pt)                   French (fr)[*]            Spanish (es)[*]                  Galician (gl)             Swedish (sv)[*]                  German (de)               Turkish (tr)                    Languages marked with [*] were not updated for this releases and you
may notice untranslated messages.  We will probably release an update
of the translations when we have received some translation updates.
May thanks to the translators for their ongoing support of GnuPG.
Happy Hacking,
  The GnuPG team (David, Stefan, Timo and Werner)
The mirror sites below have been verified to already carry this new
release. The full list of sites mirroring ftp.gnupg.org is available
at   Australia
    Australia
        ftp://ftp.planetmirror.com/pub/gnupg/
 Asia
    Japan
         ftp://ftp.ayamura.org/pub/gnupg/
 Europe
    Austria
        ftp://gd.tuwien.ac.at/privacy/gnupg/
            Denmark
        ftp://sunsite.dk/pub/security/gcrypt/
    Finland
        ftp://ftp.jyu.fi/pub/crypt/gcrypt/
        ftp://trumpetti.atm.tut.fi/gcrypt/
            France
        ftp://ftp.strasbourg.linuxfr.org/pub/gnupg/
    Germany
        ftp://ftp.freenet.de/pub/ftp.gnupg.org/gcrypt/
    Greece
        ftp://igloo.linux.gr/pub/crypto/gnupg/
    Italy
        ftp://ftp.linux.it/pub/mirrors/gnupg/
            Netherlands
        ftp://ftp.demon.nl/pub/mirrors/gnupg/
    Switzerland
        ftp://sunsite.cnlab-switch.ch/mirror/gcrypt/
    United Kingdom
        ftp://ftp.mirror.ac.uk/sites/ftp.gnupg.org/gcrypt/
        GNU Announcement mailing list

@_date: 2003-04-01 13:58:13
@_author: Perry E. Metzger 
@_subject: ["K.Ellis" <guavaberry@earthlink.net>] Boston Folks - public hearing Bill 2743 
Please pass this along if appropriate.
House, No. 2743
Bill  was introduced in Mass by a Rep Stephen Tobin of Boston
Petition of A. Stephen Tobin for legislation to establish a crime of illegal internet and broadband access and establishing penalties therefor.
Hearing  is scheduled
Mass State House in Boston.
Public Hearing date Apr 2 am at 10:00 in Room 222
REF: New Bills Would Make Firewalls Illegal
March 31, 2003 -- (WEB HOST INDUSTRY REVIEW) -- According to reports released on Monday, the US states of Massachusetts and Texas are each preparing to consider bills that would extend the national Digital Millennium Copyright Act (DMCA) by making firewalls, among other things,  >
 >  >
 > Quoting:
 >
 > Here is one example of the far-reaching harmful effects of
 > these bills. Both bills would flatly ban the possession, sale,
 > or use of technologies that "conceal from a communication
 > service provider ... the existence or place of origin or
 > destination of any communication".
 >
 > --
 > Perry E. Metzger perry at piermont.com
Karen Ellis

@_date: 2003-04-08 12:20:27
@_author: Perry E. Metzger 
@_subject: Via puts RNGs on new processors 
The new Via Technologies x86 clone processors appear to have on-board
cryptography support, including a hardware random number generator.
Quoting from the above:
   PadLock Data Encryption Engine
   The PadLock Data Encryption Engine has been integrated into the new
   generation VIA C3 processor to ensure greater confidentiality,
   integrity, and authenticity of electronic data either stored in the
   computer or transmitted over a network or the Internet, and enables
   a host of powerful new security applications, including heavy-duty
   data encryption and safer online transactions.    At its heart is an advanced Random Number Generator (RNG) that uses
   random electrical noise on the chip to securely produce random
   number values, and features a direct application level interface
   through a new x86 instruction. Developers can obtain random numbers
   directly from the hardware without having to use separate software
   drivers, thereby providing an inherently more secure and efficient
   solution than combined hardware/software RNG architectures. The RNG
   includes several operating modes, offering performance from 750K
   bits per second to as high as 6 million bits per second.
   "VIA's incorporation of a hardware random number source on the
   processor die is exciting for developers, since it provides a
   simple and effective way of obtaining high quality randomness. This
   is particularly important for security and cryptography
   applications, since it is notoriously difficult to generate random
   numbers of adequate quality without a hardware random number
   generator," said Paul Kocher, President of Cryptography Research,
   Inc. and co-inventor of SSL 3.0. "I am enthusiastic about the
   benefit to applications such as secure web browsing, cryptographic
   key generation, and protocols where randomness is required."
FYI, it appears that Cryptography Research has done an evaluation on
the RNG. See:

@_date: 2003-04-11 12:57:11
@_author: Perry E. Metzger 
@_subject: don't like the price? change the barcode! 
A trivial way to attack automated bar code scanners: change the
barcodes on products you are buying. I think actually doing it is
reprehensible, but on the other hand it does show what happens when
people start applying lessons from computer security to the real world:
A Salon article on the same topic:

@_date: 2003-04-14 19:25:25
@_author: Perry E. Metzger 
@_subject: ADMIN: The list has moved. 
For the second time in its history, the mailing list has moved -- this
time from Wasabi Systems to a machine run by my new company,
Metzger, Dowdeswell & Co. LLC
Submissions as expected to cryptography at metzdowd.com
Subscriptions/unsubscriptions as expected via majordomo at metzdowd.com
All existing subscribers have been moved over.
The old addresses for the list will work for a while, but will stop
fairly soon. Please try to avoid using them.

@_date: 2003-04-15 23:45:03
@_author: Perry E. Metzger 
@_subject: Register article on Niels Provos vs. SuperDMCA 
The Register has an article up about Niels (who is a contributor to
this list) and his struggle to keep doing his research work in spite
of insane laws being passed by the Michigan legislature.

@_date: 2003-04-16 15:42:38
@_author: Perry E. Metzger 
@_subject: Amusing... 
Today's (April 16ths) "Foxtrot" will amuse readers of this list.

@_date: 2003-04-20 21:06:53
@_author: Perry E. Metzger 
@_subject: ADMIN: world.std.com problems 
FYI, it appears that world.std.com is rejecting all mail from the
list, and unfortunately Barry Shein's machines don't say why in their
reject messages and Barry himself doesn't seem to have answered my
mail on the subject. If anyone knows a way to get in touch with him,
please let me know (or please let him know...)

@_date: 2003-04-28 13:38:56
@_author: Perry E. Metzger 
@_subject: ADMIN: filtering down the DRM discussion 
Having let the DRM discussion go on for a while, I'm now going to
close it down again for a while (unless someone has something
stunningly new to say...)

@_date: 2003-04-29 21:07:06
@_author: Perry E. Metzger 
@_subject: No subject 
Received: from user-119ac86.biz.mindspring.com ([66.149.49.6])
X-Sender:  Message-Id: X-Clips-URL:

@_date: 2003-04-30 16:10:44
@_author: Perry E. Metzger 
@_subject: 2002 Wiretap Report 
The 2002 US wiretap order summary, complete with information on how
many wiretaps were impeded by the use of cryptography, is available

@_date: 2003-08-21 15:10:02
@_author: Perry E. Metzger 
@_subject: ADMIN: List returning 
The list should be coming back on the air of the next few days. I'll
be approving a large batch of recent posts in a few hours, and then
most of the rest next Tuesday. (Don't expect new posts to be approved
over the weekend, though I'll do it if I can get to it.)
PS I'd say "We apologize for the inconvenience." but I don't want to
sound overly Sirius Cybernetics about it...

@_date: 2003-12-09 08:19:10
@_author: Perry E.Metzger 
@_subject: ADMIN: no more UCE discussion 
I'm terminating the current UCE discussion, unless someone comes up
with more interesting information on the use of *cryptography* in
fighting UCE. General messages explaining why people do or don't need
to be able to send from SMTP servers that don't correspond to the
domain name in the From: address (which I do every day etc. are)
not really on topic.

@_date: 2003-12-16 10:14:01
@_author: Perry E.Metzger 
@_subject: Quantum Crypto 
There have been more press releases about quantum crypto products
I will summarize my opinion simply -- even if they can do what is
advertised, they aren't very useful. They only provide link security,
and at extremely high cost. You can easily just run AES+HMAC on all
the bits crossing a line and get what is for all practical purposes
similar security, at a fraction of the price.
The problem in security is not that we don't have crypto technologies
that are good enough -- our algorithms are fine. Our real problem is
in much more practical things like getting our software to high enough
assurance levels, architectural flaws in our systems, etc.
Thus, Quantum Crypto ends up being a very high priced way to solve
problems that we don't have.

@_date: 2003-12-20 09:50:34
@_author: Perry E.Metzger 
@_subject: Quantum Crypto 
Your amusing banter aside, my point remains. QCrypto doesn't solve any
problems that anyone has in the real world -- everything it can do can
be done far more cheaply and indeed far better by other means -- so it
is a large expense that serves no purpose.
I know of no company using something like AES+HMAC for link security
that has had its cryptographically secured communications successfully
attacked by cryptanalysis* -- and AES is free, and running it is nearly
free. On the other hand, I know of lots of companies that have had
problems because they haven't thought out their remote access systems
well or because they are running software vulnerable to buffer
overflows. The issue is not that we need "unbreakable crypto" -- we
already have it for practical purposes. The issue is that our systems
are not built robustly.
This is not an issue of "unknown potential" -- we know what the
systems being marketed do. They have specifications and user manuals.
I would never suggest that people stop research, of course, but it
seems that QCrypto is not a solution to any real world problem.
*By this, I don't include things like "the key management algorithm
 only used all ones as the key" -- I mean legitimate attacks against
 AES etc.

@_date: 2003-12-30 10:38:36
@_author: Perry E. Metzger 
@_subject: why "penny black" etc. are not very useful 
In my opinion, the various hashcash-to-stop-spam style schemes are not
very useful, because spammers now routinely use automation to break
into vast numbers of home computers and use them to send their
spam. They're not paying for CPU time or other resources, so they
won't care if it takes more effort to send. No amount of research into
interesting methods to force people to spend CPU time to send mail
will injure the spammers.
By the way, this of course points out that most spammers these days,
regardless of their protestations about being "legitimate
businessmen", are in fact already multiple felons even to a
libertarian like me.  The stats places like Spamhaus produce show that
all the biggest spammers are indeed based in the US even if they use
foreign machines in their work, and throwing them in jail would
probably help.  The fact that the FBI and similar agencies rarely or
never arrest anyone for breaking the law in the course of spamming
just points out that the problem isn't a lack of laws or technology
but raging incompetence and disinterest on the part of law enforcement.
However, as this isn't a spam list, I'll get off of that rant right
I've heard all sorts of other claims about how technology could help
with spam, and they're usually well intentioned but misguided. Two in
particular come to mind:
1. "We need public key authentication of all mail". Well, I'll point
out that large integers are cheap and plentiful. "Authenticated"
spam is pretty much as bad as non-"Authenticated" spam. If we use
the authentication to only accept mail from people we already know
we want to talk to, we've drastically reduced the usefulness of
2. "The problem is SMTP -- we need to replace it." Every time I hear
this, the speaker rarely has any actual improvements to offer over
what SMTP already does, or, more often, doesn't understand what
SMTP does.
Anyway, enough ranting.

@_date: 2003-02-10 14:45:14
@_author: Perry E. Metzger 
@_subject: Wireless network key management 
(The topic has drifted to the management of keys in a wireless
network. Adam responds to Steve's notes about WEP...)
Key management is hard, but there is good versus not so good versus
horrible. Unchanging fixed WEP keys for everything on a network are
bad. If, on the other hand, you use public key techniques or
Needham-Schroder KDC based techniques, you can do much better.
For example, the average wireless base station only has dozens to at
most hundreds of clients. (In practice, they average far fewer, but
never mind.) Also, 802.11 enforces that all communication goes through
the wireless base station -- there are no mobile-mobile communications
in the usual setup. It is thus perfectly reasonable to use different
on-air conventional keys with each client, authenticated with a
variety of techniques (shared key between base and client, public keys
on both sides, Needham-Schroder, etc.), and negotiated by any one of a
number of similar variety of techniques (Diffie-Hellman, randomly
generated nonce keys replaced at intervals encrypted in a known key,
More to the point, almost all 802.11 traffic carries IP. Therefore,
using IPSec to protect traffic between the wireless node and the
base station or a router, or even end to end, would not be
unreasonable. In that case, key negotiation probably proceeds using
IKE or perhaps a successor protocol.
In any case, although none of these techniques are perfect, they all
eliminate the problem of "one key to rule them all", with theft of one
mobile handing over the entire net, both from a privacy and an
authentication viewpoint. Of course, since WEP is crap anyway, you can
break keys even if you don't steal a mobile, but even in principle the
mechanism was not particularly good.
It isn't any easier to configure than good methods, either. Sure, you
need to pre-configure some authentication information to use any of
the good methods, but you also need to pre-configure your super-secret
WEP key if you use WEP so there is no improvement in ease of
configuration by using WEP.

@_date: 2003-02-20 18:47:57
@_author: Perry E. Metzger 
@_subject: [Robert Moskowitz <rgm-sec@htt-consult.com>] Of potential interest -- Citibank tries to gag crypto bug disclosure 
Forwarded from the SAAG list, where it was posted by Bob Moskowitz.
 >To: ukcrypto at chiark.greenend.org.uk
 >Subject: Citibank tries to gag crypto bug disclosure
 >Date: Thu, 20 Feb 2003 09:57:34 +0000
 >From: Ross.Anderson at cl.cam.ac.uk (Ross Anderson)
 >
 >
 >Citibank is trying to get an order in the High Court today gagging
 >public disclosure of crypto vulnerabilities:
 >
 >     >
 >I have written to the judge opposing the order:
 >
 >     >
 >The background is that my student Mike Bond has discovered some really
 >horrendous vulnerabilities in the cryptographic equipment commonly
 >used to protect the PINs used to identify customers to cash machines:
 >
 >     >
 >These vulnerabilities mean that bank insiders can almost trivially
 >find out the PINs of any or all customers. The discoveries happened
 >while Mike and I were working as expert witnesses on a `phantom
 >withdrawal' case.
 >
 >The vulnerabilities are also scientifically interesting:
 >
 >     >
 >For the last couple of years or so there has been a rising tide of
 >phantoms. I get emails with increasing frequency from people all over
 >the world whose banks have debited them for ATM withdrawals that they
 >deny making. Banks in many countries simply claim that their systems
 >are secure and so the customers must be responsible. It now looks like
 >some of these vulnerabilities have also been discovered by the bad
 >guys. Our courts and regulators should make the banks fix their
 >systems, rather than just lying about security and dumping the costs
 >on the customers.
 >
 >Curiously enough, Citi was also the bank in the case that set US law
 >on phantom withdrawals from ATMs (Judd v Citibank). They lost. I hope
 >that's an omen, if not a precedent ...
 >
 >Ross Anderson

@_date: 2003-01-07 20:25:44
@_author: Perry E. Metzger 
@_subject: DeCSS, crypto, law, and economics 
Sure, but they're generally "illegal". I can buy grey market
non-regioned players in the U.S. but the manufacturers are violating
within the intellectual property agreements that prevent such
Without DeCSS, the piracy problem would have in no way been
improved. Even if you didn't want to use physical DVDs, it wouldn't
have been an issue. Ripping the raw bits encrypted bits from a DVD
drive is easy. From there, you just would have had to have built a
driver that pretended to be a DVD drive but actually read a chunk of
disk, and presto -- Windows DVD player software would be perfectly
happy aiding and abetting your piracy. For those that want physical
DVDs, the encryption of course prevented nothing at all -- bits are
No, what region coding did largely was allow the industry to try to
prevent grey market sales.
I don't know anyone who trades video files -- they're pretty big and
bulky. A song takes moments to download, but a movie takes many many
hours even on a high speed link. I have yet to meet someone who
pirates films -- but I know lots of hardened criminals who watch DVDs
on Linux and BSD. I'm one of these "criminals".
Many nights, I close the blinds and illegally use the computer I
lawfully paid for to view the DVDs I lawfully paid for. To do that, I
make use of DeCSS. My nice Unix based DVD player, ogle, needs it to
read the drive. A little later this evening I'll be watching an
episode of "I, Claudius" I bought and paid for, using this "criminal"
software combination. Hopefully no one will learn of my shamefully
immoral act. Please don't tell anyone.

@_date: 2003-01-08 09:06:22
@_author: Perry E. Metzger 
@_subject: DeCSS, crypto, law, and economics 
Sure it is. I'm merely noting it is less widespread than pirating
audio. Also, as I note, if DeCSS weren't around, people would just
steal whole DVD images and leave them encrypted, because you don't
need to decrypt them to steal and view them. DeCSS is not the problem.

@_date: 2003-01-09 16:03:00
@_author: Perry E. Metzger 
@_subject: DeCSS, crypto, law, and economics 
Actually, that's not true. Kim's sells grey market units typically
made without licenses to the DVD patent portfolio in places like
China, and units that are more legal but that have been cracked. The
latter are supplied with instruction sheets describing how to disable
region coding. Some of these sheets actually say things like "we can't
be responsible for the effects, but if you were to push the following
buttons in the following sequence..."
I am unaware of legal region-free players being generally available in
the US, although I may be wrong on this.

@_date: 2003-01-10 18:28:55
@_author: Perry E. Metzger 
@_subject: ADMIN: Okay, no more DVD pricing and Pharma for now. 
The discussion has been interesting but has gotten WAY out of the area
of crypto politics per se. I'll be blocking that stuff unless it makes
interesting new crypto or crypto politics points.

@_date: 2003-01-23 21:54:54
@_author: Perry E. Metzger 
@_subject: Open Source TCPA driver and white papers 
Reply-To: David Safford IBM has released a Linux device driver under GPL for its TCPA chip (TPM).
The driver is available at
    This page also has links to two papers, one presenting positive uses
of the chip, and the second rebutting misinformation about the chip.
These papers, combined with the Linux driver and the TCPA specification
at  give everyone the ability to
test an actual chip (such as in the Thinkpad T30), to see for themselves
what it can, and cannot do.
Note: the papers and driver do not discuss Palladium.
      Palladium and TCPA are two separate topics.
dave safford
safford at watson.ibm.com

@_date: 2003-01-24 14:13:31
@_author: Perry E. Metzger 
@_subject: Fast factoring hardware 
I got the following forwarded along yesterday from someone who'd had
it forwarded along, apparently with reasonable permission along the
chain. The message indicated the paper could be distributed, so I
don't think I'm violating any trusts.
Unfortunately the attached paper (which I'm still reading) is far too
long to email to the whole list, but I'm trying to get a URL for it so
people can download it at will.

@_date: 2003-01-24 14:52:42
@_author: Perry E. Metzger 
@_subject: Shamir paper on fast factoring hardware 
I wrote to Adi Shamir about redistributing his paper and he said:
The uncompressed paper is about 450k but I've gzipped it down to
146k. Lacking a better place to put it and having been asked by a
number of people, I'm sending it out here. My apologies to those who
are inconvenienced but I think it is a pretty important paper and it
isn't otherwise easily accessible.

@_date: 2003-01-26 19:29:08
@_author: Perry E. Metzger 
@_subject: Shamir factoring machine uninteresting? 
I find it odd that there has been so little comment on TWIRL. One
would think that the crushing of 512 bit RSA keys and a strong
demonstration of the weakness of 1024 bit RSA keys would have provoked
some comment on the list.
Any comments on why no one commented?

@_date: 2003-07-03 16:55:03
@_author: Perry E. Metzger 
@_subject: ADMIN: moderation break 
Your moderator may not have a lot of time to approve posts over the
upcoming (U.S.) holiday weekend. Everything will get back to normal by
Monday evening.

@_date: 2003-07-09 13:54:28
@_author: Perry E. Metzger 
@_subject: New algorithms and protocols, etc. (was Re: replay & integrity) 
[more examples of protocols that have their own replay, integrity,
etc. protection elided.]
This is the security world. We survive because of making cautious
assumptions. Adding anti-replay and integrity to your protocol is
cheap, and once you've done it and analyzed it well, you have a solid
component on which to build. Rolling your own non-protected protocol
that has not been analyzed because you think that you don't need the
feature buys you essentially nothing at all and endangers you.
There is nothing wrong with several layers in your communication
system all doing similar kinds of protection. It is fine that you're
sending S/MIME signed and encrypted messages over TLSified SMTP.  The
cost is merely speed, and since hardware is used for most of the
instances where speed is a problem, it isn't an issue at all for the
most part. Besides, you often find you've gained something by
providing the redundant protections.
The truth is that people don't propose new algorithms and protocols
because there is a great unmet need they are trying to fill or because
a tiny bit of speed is lost through redundant safety measures. If they
aren't snake oil peddlers (a large category, sadly) they propose them
because they haven't read the literature and/or they enjoy
Now, tinkering is a fine and wonderful thing, and I'm a big advocate
of tinkering. It is fun building things, and the pleasure of doing so
is its own reward. It is also very educational. Just because you like
building your own cars from scratch, though, doesn't mean that they're
safe for the general public to drive, or that they'd be in any way
cheaper or better than cars built by professionals. Likely what you
build will be a clunker and have no advantages, and be unsafe
besides. Even if you had some slight advantages, the mere fact that
your parts are non-standard will make it impossible for others to
analyze or maintain your car design. The same is true in cryptography
and security.
Of course, this makes the world kind of boring and unpleasant for
tinkerers who want to go pro. The most obvious cryptographic algorithm
needs and cryptographic protocol needs have been essentially filled
already -- AES, RSA, TLS and other components are all just fine and
more or less span the whole space of requirements. All that is left is
the comparative drudgery of implementing well known protocols and
(since most of them have been implemented) using them. No fun at all!
This is not to say that we don't need people inventing new algorithms
and protocols, because we do -- in an academic context. After all,
someday AES will seem too weak, or someone will find a yet cleverer
way to factor large composites, and besides, we still don't have ideal
protocols for many sorts of distributed problems. Furthermore as I
said, there is nothing wrong with good clean fun. What we don't need
is people mistaking the sort of play and research of academia for
things that should be released as software to the public.
The shame of it all is, as people have noted, there is substantial
demand for better implementations of things like SSL, and even more
importantly, for better applications and infrastructures. It is too
hard to use the tools we have now, but not because AES is somehow hard
to use or because SSL is a bad component. The problems we have
deploying, both because of things that are difficult for programmers
to use and because of things that are inconvenient for users, are a
massive problem, and one that cries out for lots of work.
Unfortunately, it is the sort of work that isn't glamorous. In
engineering, one often finds a distinction between the personalities
of innovators and "finishers" -- the guy who's great at coming up with
a new car engine idea vs. the guy who's really good at cleaning up the
new engine idea for manufacturability and simplicity but who would not
have thought of the idea in the first place. It is the distinction
between implementing the neat prototype of a fantastic new idea and
polishing it into something your grandmother can use. Being a
"finisher" is, unfortunately, not seen as being as glamorous as being
the trailblazer. Even more unfortunately, we seem to have a lack of
them in the security community.

@_date: 2003-07-14 20:04:49
@_author: Perry E. Metzger 
@_subject: Announcing httpsy://, a YURL scheme 
Having an implementation demonstrates nothing whatsoever about
security -- many implemented systems are, after all, insecure.
If you wish to demonstrate the security of your system, one would
expect a detailed explanation of the threat model you're trying to
address, and why those threats are thwarted by the design.

@_date: 2003-07-14 21:27:26
@_author: Perry E. Metzger 
@_subject: Announcing httpsy://, a YURL scheme 
I'm afraid they aren't clearly defined at all. I've read the page, and
I must admit that as peripherally interesting as it might be, for
example, for you to introduce us to the sociologist Mark Granovetter's
work on diagrams, etc., and as nice as it is for you to have lots of
references listed, you've not explained your threat model in a way
that I readily understand.
Since I can't derive your security model from your short and not
particularly clear description on your web page, I'm afraid I can make
no such assessment at all.
I will say this: neither PGP nor SSH include key ids in destinations
as you do. I say "ssh some.host.com", not "ssh verylongnothumanrememberablestrignthatcanbeeasilyspoofed".
PGP does not force you to include a hash of someone's key in their
mail address.
The only thing like what you've done that I'm aware of is the
so-called "self-certifying file system" stuff (sfs), in which file
paths contain embedded hashes. I've seen similar schemes proposed
elsewhere. I wouldn't call them similar in their security model to PGP
or SSH. That is not to say, btw, that I love PGP and SSH's security
models either, but they appear to be rather different.
I must admit I don't particularly like "embed the hash in the thing
the user sees" schemes. There are lots of problems with them --
they're completely brittle with respect to key changes, and they work
very poorly with users who don't understand the security properties of
the system they're dealing with. Heck, I'm not sure they work well
with sophisticated people either.
It isn't his job to attack your implementation, any more than it is up
to someone reading a paper for "The Lancet" to come up with proof the
author is wrong. It is up to the claimant to present a clear, concise
and straightforward summary of their work so people can assess it and
so that someone reasonably skilled in the field can come to
conclusions about its merits. At that point, it might be interesting
for someone else to try attacking it, but no one is under any
obligation to do so.
I'm afraid that, in this instance, I'm not sure your web site contains
those things either.
Well, I'll say this -- it seems trivial to substitute one HURL, er,
YURL, for another. I have no real way of knowing that I'm talking to
the actual server and key I want because I don't really know that the
HURL er YURL I've been given is valid in any way, and it is too
difficult for humans to detect a change in a hash by eye.
I've got lots of similar problems with the scheme.

@_date: 2003-07-15 09:21:11
@_author: Perry E. Metzger 
@_subject: Announcing httpsy://, a YURL scheme 
SFS makes it practically impossible to do key updates, and the trust
model is rather flawed -- if you mount files from one site you in
practice end up trusting it totally, which means that it can hand you
links to spoofed other sites and you'll in practice totally believe
them unless you're paying very close attention and have the ability to
perfectly recognize long hashes by eye. It is a neat idea, and
certainly instructive, but I don't know that I particularly love it.
The "YURL" idea seems to suffer from most of the same flaws.

@_date: 2003-07-16 11:26:12
@_author: Perry E. Metzger 
@_subject: Announcing httpsy://, a YURL scheme 
It seems to me to be more "a bad idea, fully realized".
I'll repeat:
1) The "YURL" makes key management and replacement effectively
   impossible.
2) It leads to situations in which you have no way to know what sort
   of trust relationship you have for the documents you're looking at.
3) It is impossible for people to determine that a "YURL" actually is
   what it claims it is, given that most people can't actually
   remember one hash, let alone large numbers of them, etc.
Those are just some of the more obvious issues.

@_date: 2003-07-16 13:13:15
@_author: Perry E. Metzger 
@_subject: Announcing httpsy://, a YURL scheme 
What are you talking about?
I'm talking about replacing keys. Almost every protocol out there lets
you replace your keys at periodic intervals. Proper key hygiene
dictates that you change your keys often enough that the security harm
caused by disclosures or cracking is mitigated. Using this system,
they're basically frozen forever because everyone on earth expects
your HURL, er, YURL, to remain constant.
Since when is proper key hygiene "an idea of poor track record"?
Our evidence in the long run is that users are extremely poor at
handling security decisions like this. They don't understand the
security implications of their actions. If the goal is to improve
security over the existing system, especially because users tend to
get spoofed, this doesn't succeed.
I think that's a poor point of comparison. It is like saying "I don't
like bad system A, so note how bad system B is so much better".
There are fine ideas out there on how to handle this sort of thing
that don't involve bad ideas at all -- I don't see why I should pick
a bad way of doing things at all.
I do. You start by looking at document A. You click on it and end up
at document B at another site. Then you click on it and end up at
document C at yet another site. Before long, you're trusting documents
that are very, very far from the original HURL, er, YURL you started
with, and you have no idea what your trust relationship with them is
at all. It is a recipe for serious trouble. "Hmm, this claims to be
www6.amazon.com and I somehow got there by an unknown sequence of
clicks -- guess I'll give it my credit card number."
SFS has the same problem -- by the time you've cd'ed into a few
directories on a few file systems, you no longer have any idea what
your trust path is at all.
So in that sense, we end up with the worst part of the SSH model --
you get a message that a key has changed and you have no idea why or
if it is legitimate so users ignore it. "Not an improvement."
That paragraph is completely incomprehensible to me.

@_date: 2003-07-16 16:10:18
@_author: Perry E. Metzger 
@_subject: Announcing httpsy://, a YURL scheme 
I believe my statements are reasonable.
I have. I explained them in modest detail, which seems
sufficient. That's more than you've done -- you have no security model
explained in any level of detail, even a modest one. I think you've
got something of an obligation to at least explain your security model
instead of pointing us at a web page that spends half its space
explaining the sociologist who originated the style of diagrams you
That page says nothing of any interest at all. It is two fluffy
paragraphs that do not address what I think of as real key management
issues -- such has secure transmission of keys and replacement of
compromised keys, i.e. what a professional in this field would call
"key management". I encourage others to read these paragraphs and
judge for themselves.
One wonders, of course, why you couldn't have simply forwarded those
two paragraphs rather than referencing them.
I will again repeat my argument. Users will bookmark YURLs or
otherwise save them, making it impossible to change said YURLs in
practice, and thus making it impossible to change keys. In any case,
the system effectively requires manual, out of band intervention to
handle key changes and distribution, making it effectively
I've read the documents. They are unenlightening. The fact is, you
can't change keys and users can't remember your YURLs.
You prove my point: you can't change keys. Someone bookmarks that
incomprehensible gobbledygook because they can't possibly type it from
memory, and that's it -- you're frozen. As I said:
   The "YURL" makes key management and replacement effectively impossible.
I read it. I'll be blunt: it is poorly written, amateurish work and
addresses none of the concerns I have. Your site is full of long,
fluffy documents, and contains not so much as a paragraph of
professionally written threat analysis. Your whole site could be
written in a much more concise document a fraction of the space -- but
sadly that would still leave out the threat model.
One more comment: just because you've learned how to include lots of
document references and speak in an academic style doesn't mean there
is any content. Or, to put it another way, try reading the chapter on
"Cargo Cult Science" from Feynman's "Surely You Must Be Joking,
Mr. Feynman". The appearance of academic rigor and actual rigor are
totally different things.
I'll repeat my trivial example. I click on site A. It gives me a link
to site B. It gives me a link to site C, and I go on further to D, and
E, and F. By the time I'm at the end of a chain of these, I've got no
idea in practice who I trusted or why. Dozens of people could silently
be in my trust path. I won't even remember why I think a particular
unreadable string gives me any confidence I'm talking to a legitimate
None of this gives me anything of use anyway. What a user wants to
know is that he won't be defrauded if he types his Visa number in to a
page (or his bank password or whatever). YURLs don't address that in
the slightest. However, since you have no threat model at all -- only
a long list of web pages you insist I haven't read although I've
combed them for a shred of useful information without success -- there
isn't any way of knowing if YURLs are useful for anything.
Pretty much worthless. Your mom wants to buy books on Amazon, not to
try to decipher the meaning of a long sequence of worthless letters. I
assure you that my mom isn't going to deal with even the simplest of
the schemes you propose.
You make the following bizarre claim on your site:
    Rarely are humans required to memorize a URL
Well, that must mean that virtually all advertising with URLs in it
etc. doesn't exist, then, eh? My mom knows " -- she has
it memorized. Funny, ain't it?. My remembering that "
is where I pay my phone bill must be imaginary, too. My girlfriend
seems to remember the URL for her webmail account, but I doubt she'll
be able to type in the YURL for it.
Again with your documents. Repeating: they do not answer the questions
you claim they answer.
I'm not surprised.
On the contrary. When I as a user I type in " I'm
expecting to be speaking to Amazon, a merchant that I trust, and not
Joe's Random Con Game, who I don't trust with my credit information.
A "YURL" doesn't help me with that. I can't read a "YURL" off the side
of a bus and remember it, and if it were possible for me to the site
could never change its keys!
CAs are flawed, but they do serve the function of saying that at least
someone who's widely known attests that I'm connecting to the right place.
Or, as *you yourself* say:
   "If your URLs must be human memorable, the PKI is an appropriate
   choice for authentication."
i.e. YURLs don't help.
I've read your documents already, and I stand by what I said. In
practice, a user gains nothing from this other than being forced to
decide if they believe a meaningless sequence of digits and letters
has some correspondence with what they've used in the past.
How about just posting an actual, professionally written threat model,
eh? Because right now, you don't have one. Another hint is that rather
than posting URLs to documents that introduce use to "Granovetter
Diagrams", you could just post a couple of paragraphs with a nice,
clean, professionally written threat model.

@_date: 2003-06-07 17:01:43
@_author: Perry E. Metzger 
@_subject: Quantum crypto, from BBC 
Quantum Cryptography is a really expensive way to provide link
encryption that is perhaps marginally better in some theoretical sense
to simply using, say, AES link encryption boxes at both ends, but in
day to day practice provides no additional security at all.
It is the sort of thing that fascinates people who are interested in
neat solutions that solve no real problems.
In the real world, the issue is not finding cryptographic mechanisms
that are good enough. We have fine algorithms for securing links
already. It is getting people to use them, and getting programmers not
to misuse them or make other mistakes that render them moot.

@_date: 2003-06-08 19:05:22
@_author: Perry E. Metzger 
@_subject: ADMIN: ACM bouncing list mail again 
FYI, for those of you who are ACM members making use of the ACM mail
forwarding service, a large fraction of list mail to you is yet again
bouncing, with return messages like this being typical. If anyone
knows how to convince ACM not to screw up its mail forwarding, please
get in touch with them.
This is the Postfix program at host red.metdow.com.
I'm sorry to have to inform you that the message returned
below could not be delivered to one or more destinations.
For further assistance, please send mail to If you do so, please include this problem report. You can
delete your own text from the message returned below.
: host alias.acm.org[199.222.69.90] said: 554 5.7.1 ***** The
    message was identified as UBE/UCE (spam). Please reference
     ***** (in reply to end
    of DATA command)

@_date: 2003-06-16 11:07:10
@_author: Perry E. Metzger 
@_subject: Sessions 
Er, it is if you have to pay $5 or $10 in customer support fees
dealing with the irate customer who spends half an hour or more with
you on the phone upset that he can't log in to his bank account,
especially since the problem will be very difficult for anyone
involved to diagnose or explain. Multiply that by tens of thousands of
calls, and you're talking about real money. Failures like that are a
large fraction of banking costs. Part of the point of on-line banking
for banks is to raise margins, so if you piss all the money away on
support costs and many people can't use the system you're sunk.
A large fraction, if not the majority, of users are currently behind
proxies and NATs. I doubt it would be possible to block them on that
basis without it being financially ruinous.
In any case, given the various spoofing methods available,
authenticating based on IP address seems rather weak, though I don't
see why a cookie couldn't be tied to an address just to raise the bar
a little if it didn't stop use for proxied/NATed users.
FYI, I would strongly suggest reading the original paper on session ID
fixation/theft -- it goes over a number of ways that IDs can be
mishandled and a number of possible coping strategies.

@_date: 2003-06-22 18:45:35
@_author: Perry E. Metzger 
@_subject: authentication and ESP 
I don't know what you mean. Yes, ESP doesn't per se forbid the
construction of a new algorithm/mode that doesn't do authentication,
but all of the ESP algorithms/modes currently in use do

@_date: 2003-03-02 13:30:51
@_author: Perry E. Metzger 
@_subject: NSA being used to influence UN votes on Iraq 
Quote from the article:
  The United States is conducting a secret 'dirty tricks' campaign
  against UN Security Council delegations in New York as part of its
  battle to win votes in favour of war against Iraq.
  Details of the aggressive surveillance operation, which involves
  interception of the home and office telephones and the emails of UN
  delegates in New York, are revealed in a document leaked to The
  Observer.
  The disclosures were made in a memorandum written by a top official at
  the National Security Agency - the US body which intercepts
  communications around the world - and circulated to both senior agents
  in his organisation and to a friendly foreign intelligence agency
  asking for its input.

@_date: 2003-03-08 18:17:14
@_author: Perry E. Metzger 
@_subject: ADMIN: voting, etc... 
I'm going to be ending the voting discussion now, at least for the
moment, unless anyone has anything really interesting/new to say.

@_date: 2003-03-09 15:46:58
@_author: Perry E. Metzger 
@_subject: ADMIN: acm.org subscribers in danger 
Hi there.
A large fraction of the messages being sent to acm.org are being
tagged as spam, by some sort of highly over-aggressive anti-spam
filter acm.org has put in.
I've attempted to contact the postmaster there, but so far I've
failed as my attempt to get in touch get tagged as spam, too.
If I keep getting torrents of bounces, all the folks using acm.org
mail redirectors (and there are dozens of you) will get removed from
the list in a few days. Very sorry, but I just don't know what else to

@_date: 2003-03-11 09:44:05
@_author: Perry E. Metzger 
@_subject: Khalid Sheikh Mohammed caught partially by Echelon? 
The guardian reports (unsurprisingly) that Echelon was used in
tracking Khalid Sheikh Mohammed's mobile phones:

@_date: 2003-03-24 15:24:44
@_author: Perry E. Metzger 
@_subject: Supreme Court Refuses to Review Wiretaps Ruling 
Supreme Court Refuses to Review Wiretaps Ruling
March 24, 2003
By DAVID STOUT WASHINGTON, March 24 - In a case balancing national
security with civil liberties, the Supreme Court refused to
interfere today with a lower court ruling giving the
Justice Department broad new powers to use wiretaps to
prosecute terrorists. The justices declined without comment to review a decision
last Nov. 18 in which a special federal appeals court found
that, under a law passed after the terror attacks of Sept.
11, 2001, the Justice Department can use wiretaps installed
for intelligence operations to go after terrorists. That November decision was crucial, because for some two
decades there was presumed to be a "wall" between wiretap
operations for intelligence-gathering and wiretapping in
the course of criminal investigations. Obtaining permission for a wiretap to gather intelligence
has generally been easier than getting authorization for a
wiretap in a straightforward criminal investigation. Thus,
prosecutors were admonished not to try to skirt the tougher
standards for a wiretap in a criminal investigation by
claiming it was actually to gather intelligence. The landscape changed with the passage of legislation,
shortly after the Sept. 11 attacks, broadening government
surveillance powers. Justice Department investigators
applied last May for permission to wiretap an individual
who was identified in court papers only as a resident of
the United States. The department met resistance from the three-member Foreign
Intelligence Surveillance Act Court, which exists solely to
administer a 1978 law allowing the government to conduct
intelligence wiretaps inside the United States. That court
ordered the Justice Department to show that its primary
purpose in applying for the wiretap was intelligence
gathering and not for a criminal case. Moreover, the three-member court decreed that prosecutors
in the Justice Department's criminal division could not
take an active role in directing activities of the
department's intelligence division. Attorney General John Ashcroft appealed to the United
States Foreign Intelligence Surveillance Court of Review,
which had never met before and which exists, like the lower
court, only to oversee the 1978 law. The court of review
ruled in November that the lower court had erred when it
tried to impose restrictions on the Justice Department.
Furthermore, the court of review said, there never was
supposed to be a "wall" between intelligence gathering and
criminal investigations. "Effective counterintelligence, as we have learned,
requires the wholehearted cooperation of all the
government's personnel who can be brought to the task," the
review panel wrote. "A standard which punishes such
cooperation could well be thought dangerous to national
security." The review panel criticized the lower court, declaring that
it had improperly tried to tell the Justice Department how
to do its business, in violation of the Constitution's
separation of powers between equal branches of government. The Court of Review is made up of Judges Ralph B. Guy of
the United States Court of Appeals for the Sixth Circuit;
Edward Leavy of the Court of Appeals for the Ninth Circuit;
and Laurence H. Silberman of the Court of Appeals for the
District of Columbia Circuit. All were appointed to the
panel by Chief Justice William H. Rehnquist of the Supreme
Court. Mr. Ashcroft praised the November decision as one that
"revolutionizes our ability to investigate terrorists and
prosecute terrorist acts." But the American Civil Liberties Union, the National
Association of Criminal Defense Lawyers, the American-Arab
Anti-Discrimination Committee and the Arab Community Center
for Economic and Social Services, a Michigan-based
organization, assailed the November decision. "These
fundamental issues should not be finally adjudicated by
courts that sit in secret, do not ordinarily publish their
decisions, and allow only the government to appear before
them," the groups said in asking the Supreme Court to
review it. The A.C.L.U. and its allies had only friend-of-the-court
status in the case, since technically the Justice
Department was the only party. Thus, it was not surprising
that the Supreme Court declined today to review the lower
courts' decision.

@_date: 2003-03-26 13:36:35
@_author: Perry E. Metzger 
@_subject: meet in the middle attacks 
I have to say I've watched this with a bit of puzzlement.
Meet in the middle attacks are perfectly real. I've seen them myself,
and toolkits to perform them are readily available out there. Ian's
vague comments about a lack of evidence of the economic impact
notwithstanding, it is unreasonable to leave one's protocols and
systems open to such attacks.
You do not need an elaborate CA infrastructure to prevent them, of
course. SSH manages to prevent them simply by having both sides sign
exchanges using naked (i.e. uncertified) keys that are pre-shared, for
example. Even use of MACs over exchanged values and pre-shared
conventional keys can prevent many such attacks.
However, not attempting to prevent such attacks -- especially given
that they are very effective -- seems foolish at best.

@_date: 2003-03-26 17:55:09
@_author: Perry E. Metzger 
@_subject: yes, I know... 
I meant Man in the Middle, not Meet in the Middle. Sigh.

@_date: 2003-03-28 13:10:56
@_author: Perry E. Metzger 
@_subject: Run a remailer, go to jail? 
Here is one example of the far-reaching harmful effects of
        these bills. Both bills would flatly ban the possession, sale,
        or use of technologies that "conceal from a communication
        service provider ... the existence or place of origin or
        destination of any communication".

@_date: 2003-05-04 10:11:19
@_author: Perry E. Metzger 
@_subject: my take on "PCP" 
Ralf is very well meaning, but I think that anyone who invents their
own hash functions and puts them into a program that is expected to be
used by real people without first publishing them and subjecting them
to real world analysis first should not be trusted. They are in the
same category as people giving just invented experimental drugs to
humans without first testing them on other living things. No matter
how well meaning, they are likely to cause serious damage.
As for the motivation for not using a member of the SHA family or
something similar, there is no excuse. You can know that an
implementation of SHA-1 is correct, pretty trivially, by the fact that
it interoperates. If it passes a test suite and others can duplicate
what it does, it is almost certainly SHA-1. The damage if it failed --
lack of interoperation -- would be immediately obvious to a user.
There is no security gain whatsoever in picking something with a
"smaller implementation" in this instance. There is, however, a
substantial risk that a brand new basement-brew hash function will be
insecure. Even if you had a proof of security, publication would be
needed so others could check your proof -- "proven" security systems
have been broken in the past following publication.
If you do not recognize why all this is, you probably should not be
writing security critical systems.

@_date: 2003-05-04 11:29:21
@_author: Perry E. Metzger 
@_subject: my take on "PCP" 
Evaluation of things like new hash functions takes years, not days.
If you are serious, submit a full description of your hash function
along with your evidence of its security against known forms of attack
to a peer-reviewed publication.

@_date: 2003-05-05 08:47:42
@_author: Perry E. Metzger 
@_subject: my take on "PCP" 
I said "peer reviewed publication", not "thing I put on my web site".
Actually, it effectively will prevent it because no one will
bother. There's a great essay by Schneier on that subject.

@_date: 2003-11-16 14:15:24
@_author: Perry E.Metzger 
@_subject: A-B-a-b encryption 
Hmm. You need a cipher such that given B(A(M)) and A you can get
B(M). I know of only one with that property -- XOR style stream
ciphers. Unfortunately that makes for a big flaw, so I'm not sure we
should throw out our Diffie-Hellman implementations yet.
Imagine the way this would work:
Alice takes a secret pad A and secret key M she wishes to convey and
does A xor M.
She sends A xor M to Bob, who turns it into B xor A xor M, and returns
it to Alice.
Alice easily turns it into B xor M, and returns it to Bob.
Bob then takes B xor M and turns it into M.
However, consider Eve, listening in. She has A xor M, and B xor A xor M.
She thus has B since A xor M xored with B xor A xor M yields B. She
also has B xor M, so she too has M. "Not good".
I'm not sure there are conventional ciphers with appropriate
properties such that this would would well.

@_date: 2003-11-20 16:09:44
@_author: Perry E.Metzger 
@_subject: 2002 Turing Award Lecture Available Online 
The 2002 Turing Award Lecture by the winners of ACM's most prestigious technical award is now available online in a variety of formats at: The 2002 Turing Award was presented on June 7, 2003, to Drs. Ronald L. Rivest, Adi Shamir and Leonard M. Adleman, the developers of the RSA encryption code, for their seminal contributions to the theory and practical application of public key cryptography.
The presentations were recorded in three sections at the Turing Award Lecture event in San Diego, CA, on June 8, 2003. Available for viewing are Dr. Ronald L. Rivest?s presentation on the "Early Days of RSA", Dr. Adi Shamir's talk on "Cryptology: A Status Report", and  Dr. Leonard M. Adleman's address on "Pre-RSA." The presentations can be viewed as a complete series with slides, or separately as lectures, audio portions or slides alone.
We hope you will take the opportunity to access these important and high quality presentations in the near future, and we?re eager to hear your feedback regarding access to this type of multimedia presentation. Please send you comments and feedback to acmhelp at acm.org .
John R. White ACM CEO
(Depending on your email system, you may need to cut and paste the entire link above into your browser.)

@_date: 2003-11-24 10:27:01
@_author: Perry E.Metzger 
@_subject: ADMIN: end of the UCE discussion 
I allowed through a couple of messages on UCE from The Usual Suspects,
partially because they discussed things like anonymous remailers etc.,
but unless something very interesting comes through I'd like to end
this here, given that we're not really the right list for the

@_date: 2003-11-26 18:24:12
@_author: Perry E.Metzger 
@_subject: Problems with GPG El Gamal signing keys? 
Some notes have been floating around claiming that there are bugs in
GPG's use of El Gamal keys. For example, see:
Can anyone confirm these reports?

@_date: 2003-11-28 21:43:28
@_author: Perry E.Metzger 
@_subject: ADMIN: apologies -- testing 
We're having some trouble with a subtle bug on one of our mail
delivery machines for cryptography, which appears to have slowed down
delivery of the list recently. I unfortunately may have to send out a
couple of test messages to the list, like this one, so we can trace
the problem completely. Apologies in advance for this. :(

@_date: 2003-11-29 00:43:36
@_author: Perry E.Metzger 
@_subject: ADMIN: testing, please ignore. 
Sorry about this. Hopefully we won't need any more test messages.

@_date: 2003-10-01 10:36:12
@_author: Perry E. Metzger 
@_subject: Monoculture 
We do. We generally tell them to use the existing protocols, since the
protocols are generally sound even if the implementations are
not. They then often tell us the protocols are too complicated for
them to understand, although they are (for better or ill) generally
about as simple as an effective protocol can get.
We could use more implementations of ssl and of ssh, no
question. Sadly, the other major open source implementation of ssh
(lsh) appears to have very serious buffer overflow problems, and was
not coded to specifically avoid them. There is also FreSSH, but it
does not implement v2, which is pretty much mandatory since v1 has
serious protocol flaws.
However, suggesting to people that they produce more cleanly
implemented and simpler to use versions of existing algorithms and
protocols doesn't seem to excite people, although it would be of
tremendous utility.

@_date: 2003-10-01 15:09:32
@_author: Perry E. Metzger 
@_subject: Monoculture 
Actually, I could care less if they take "the guild" seriously,
because there isn't any "guild". What I care about is that people take
the risks seriously.
This is all very much like the reaction back when lots of people were
saying "please don't operate on people when you haven't washed your
hands" and lots of other folks said "nuts to that sort of thing --
I've been a surgeon for 30 years and almost 20% of my patients
When I read "The Codebreakers" in the late 1970s, one thing got
drummed into my head in chapter after chapter after chapter. It is a
simple lesson, but one that I will repeat here.
    Dumb cryptography kills people.
It has a simple corollary.
    Dumb cryptography is built by people who don't understand that the
    problem is hard and that doing a bad job kills people.
In chapter after chapter, you read about people making the same
mistakes, over and over, and never learning, and then other people
dying because they were too egotistical to believe that they could
have made a mistake in the design of their security systems.
We do not ask anyone join a mythical "guild". We ask that people not
go off and build suspension bridges out of rotting twine.
The problem, of course, is that although it is obvious why you don't
want your suspension bridge hung from rotting twine instead of steel,
it is far less obvious to the naked eye that using the C library
random() call doesn't provide enough security to keep your nuclear
power plant controls safe.
I don't see any truth to that. You can build applications just as
easily using things like TLS -- and perhaps even more easily. The
"alternatives" aren't any simpler or easier, and are almost always
There isn't a guild. People just finally realize what is needed in
order to make critical -- and I do mean critical -- pieces of
infrastructure safe enough for use.

@_date: 2003-10-01 16:20:32
@_author: Perry E. Metzger 
@_subject: Monoculture 
People's software is rarely used in just one place. These days, one
might very well wake up to discover that one's operating system or
cryptographic utility is being used to protect ATM machines or power
generation equipment or worse. People die when power systems fail.
Furthermore, the little open source utility that you think is never
going to be used for something life critical may (with or without your
knowledge) end up being used by someone at an NGO who'll be killed
when the local government thugs break something.
SSL is not only used to protect people's credit cards.
It is one thing if, as a customer, with eyes wide open, you make a
decision to use something iffy.
However, as a producer, it is a bad idea to make assumptions you know
what people will do with your tools, because you don't. People end up
using tools in surprising ways. You can't control them.
Furthermore, it is utterly senseless to build something to use bad
cryptography when good cryptography is free and easy to use. You claim
there is some "Cryptography Guild" out there, but unlike every other
"Guild" in history, all our work is available for the taking by anyone
who wants it without the slightest renumeration to said fictitious
For decades, I've seen programmers claim they didn't have time to test
their code or document it, either. Should I believe them, or should I
keep kicking?
Someone else who is not skilled in the art will then use that same
piece of software to send information to someone at Amnesty
International, and might very well end up dead if the software doesn't
work right.
Just because YOU do not use a piece of software in a life-critical way
does not mean someone else out there will not.
And someone else will use that VPN software to connect in to the
management interface for sections of the electrical grid, or a
commuter train system, or other things that can easily cause people to
You do not know who will use your software.
I've been a security consultant for years. There are very few
organizations -- even ones with critical security needs -- that
actually understand security well.

@_date: 2003-10-01 16:31:16
@_author: Perry E. Metzger 
@_subject: Monoculture 
There is nothing wrong with either goal.
Implementing is fine. Designing, however, may have a world of problems.
That's fine. There is nothing wrong with new implementations. My
biggest concern is with people rolling their own crypto algorithms and
protocols, not with people re-implementing them.
If you are going to implement something on your own, though, may I
strongly encourage you to write your code in a way that is inherently
Security is not only a question of correct protocols, but of good
implementation. Avoiding buffer overflows, using principles like
aperture minimization and least privilege, and a dozen other
techniques will help you make your system far more secure than it
would otherwise be.

@_date: 2003-10-01 18:29:44
@_author: Perry E. Metzger 
@_subject: Monoculture 
Well, then you might consider using an existing TLS library. It is
rather hard to make a protocol that does TLS things that is both safe
and in any significant way simpler than TLS.
Unfortunately, those parts are rather dangerous to omit.
0) If you omit the message authenticator, you will now be subject to a
   range of fine and well documented cut and paste attacks. With some
   ciphers, especially stream ciphers, you'll be subject to far worse
   attacks still.
1) If you omit the IV, suddenly you're going to be subject to a
   second new range of attacks based on the fact that fixed blocks
   will always encrypt the exact same way.
We went through all that, by the way, when designing IPSec. At first,
we didn't put in mandatory authenticators, because we didn't
understand that they were security critical. Then, of course, we
discovered that they were damn critical, and that most of the text
books on this had been wrong. We didn't understand lots of subtleties
about our IVs, either. One big hint: do NOT use IVs on sequential
packets with close hamming distance!
So, to summarize, you can't take something "just like ESP" and alter
it and expect to have the same security properties. You can possibly
make some changes to it, but you have to know what you're doing to do
it, and even then it is a dangerous game.
Anyway, here is the central problem. Lots of us have personally gone
through the humbling experience of being involved in the design of
these things and discovering that there are all sorts of things that
are not nearly as obvious as one expected. I, for one, would suggest
that rather than proclaiming what you are going to do, you might want
to ask people what is and is not safe to alter.
BTW, the real argument against the existence of the so-called "Guild"
here is that most of us who would be part of that "Guild" consider
ourselves thoroughly unable to design new cryptographic protocols from
scratch without screwing up the first few times. Or, to put it another
way, if there is a "Guild", it is the "Guild Of People Who Are Aware Of
Their Own Ignorance".

@_date: 2003-10-01 18:11:33
@_author: Perry E. Metzger 
@_subject: Monoculture 
I'm sure you have heard of it, just under other names.
The term "aperture minimization" really just means that -- keeping the
potential opening that can be attacked minimized.
If you have only a tiny piece of trusted code, it is easier to fully
audit than if you have a large piece of trusted code. If you have only
a brief period when you have privileges asserted, there is less scope
for hijacking a program than if it asserts privileges at all
times. If your system can send general SQL queries to the database
server, someone hijacking it can do the same, but if you can only send
very limited canned queries by an ad hoc protocol the hijacker has
less scope for mischief.
Thus, aperture minimization: narrow the window (aperture) and less
stuff can get through it.

@_date: 2003-10-01 18:17:59
@_author: Perry E. Metzger 
@_subject: how simple is SSL? 
On the other hand, without negotiation you can never fix problems
later, like replacing a crypto algorithm that gets broken with one
that is not compromised.
However, you are correct that negotiation is an big weakness in many
such protocols -- yet another reason for taking the utmost care in
design and not to roll one's own lightly.
I think there is an excellent market for a variant on the protocol
that uses SSH style keys, and for a library that implements
that. Indeed, I would have immediate uses for such a library.
However, the style of certificates isn't what is key to the security
of the protocol's design.

@_date: 2003-10-02 13:19:39
@_author: Perry E. Metzger 
@_subject: Monoculture 
Well, I agree, the most reasonable thing to do is to use ipsec, but if
people aren't going to use ipsec they should at least use a protocol
that isn't insecure.

@_date: 2003-10-06 16:05:10
@_author: Perry E. Metzger 
@_subject: NCipher Takes Hardware Security To Network Level 
I was asked by the author of this to forward it with the sender
information removed.
That's not particularly clever at all -- it's one of the standard tricks
in your typical FIPS-140 consultant's bag thereof.
In fact, if you're clever, you can manage to not trouble yourself to get
the key-management, etc. certified, getting only the simple, symmetric-cipher
stuff run through the process.  The government will still buy your "encryption devices" (FIPS-140 certified) and will conveniently ignore the
lack of certification on your "management device", even though it acts as
an administrative user towards the "encryption device".  It's somewhat
scary that this sort of skulduggery is possible, but it's also not really
anything new or exciting.

@_date: 2003-10-07 09:52:56
@_author: Perry E. Metzger 
@_subject: NCipher Takes Hardware Security To Network Level 
I was asked by someone to anonymously forward the following reply to
Joshua Hill to the list. (Second time in a week, and on the same topic!)
If you reply, please don't put my name in the reply -- this isn't my

@_date: 2003-10-09 09:42:18
@_author: Perry E. Metzger 
@_subject: Open Source (was Simple SSL/TLS - Some Questions) 
Unfortunately, IP over TCP has very bad properties. TCP stacks figure
out what the maximum bandwidth they can send is by increasing the
transmission rate until they get drops, and then backing off. However,
the underlying TCP carrying the IP packets is a reliable,
retransmitting service, so there will never be any drops seen by the
overlayed TCP sessions. You end up with really ugly problems, in
Port-forwarded TCP sessions, a la ssh, work a lot better.

@_date: 2003-10-12 16:57:20
@_author: Perry E. Metzger 
@_subject: Open Source (was Simple SSL/TLS - Some Questions) 
[Moderator's note: Forwarded anonymously at the sender's request, so
if you reply to this, please cut my name out of it, it isn't my
message --Perry]

@_date: 2003-10-22 19:00:35
@_author: Perry E. Metzger 
@_subject: SSL, client certs, and MITM (was WYTM?) 
I have to find I find this argument very odd.
You argue that TLS defends against man in the middle attacks, but that
we do not observe man in the middle attacks, so why do we need the
Well, we don't observe the attacks much because they are hard to
undertake. Make them easy and I am sure they would happen
frequently. Protocols subject to such attacks are frequently subjected
to them, and there are whole suites of tools you can download to help
you in intercepting traffic to facilitate them.
You argue that we have to make a "cost/benefit analysis", but we're
talking about computer algorithms where the "cost" is miniscule if it
is measurable at all. Why should we use a second-best practice when a
best practice is in reality no more expensive?
It is one thing to argue that a bridge does not need another million
dollars worth of steel, but who can rationally argue that we should
use different, less secure algorithms when there is no obvious
benefit, either in computation, in development costs or in license
fees (since TLS is after all free of any such fees), and the
alternatives are less secure? In such a light, a cost/benefit analysis
leads inexorably to "Use TLS -- second best saves nothing and might
cost a lot in lower security".
Some of your arguments seem to come down to "there wasn't enough
thought given to the threat model." That might have been true when the
SSL/TLS process began, but a bunch of fairly smart people worked on
it, and we've ended up with a pretty solid protocol that is at worst
more secure than you might absolutely need but which covers the threat
model in most of the cases in which it might be used. You've yet to
argue that the threat model is insufficiently secure -- only that it
might be more than one needs -- so what is the harm?
Honestly the only really good argument against TLS I can think of is
that if one wants to use something like SSH keying instead of X.509
keying the detailed protocol doesn't support it very well, but the
protocol can be trivially adapted to do what one wants and the
underlying security model is almost exactly what one wants in a
majority of cases. Such an adaptation might be a fine idea, but it can
be done without giving up any of the fine analysis that went into TLS.
Actually, there is one other argument against TLS -- it does not
protect underlying TCP signaling the way that IPSec does. However,
given where it sits in the stack, you can't fault it for that.
This is not a failure of TLS. This is a failure of the browsers and
web servers. There is no reason browsers couldn't do exactly that,
tomorrow, and that sites couldn't operate on an SSH "accept only what
you saw the first time" model. TLS is fully capable of supporting that.
If you want to argue against X.509, that might be a fine and quite
reasonable argument. I would happily argue against lots of X.509
myself. However, X.509 is not TLS, and TLS's properties are not those
of X.509.

@_date: 2003-10-22 19:11:39
@_author: Perry E. Metzger 
@_subject: SSL, client certs, and MITM (was WYTM?) 
I will state that MITM attacks are hardly a myth. They're used by
serious attackers when the underlying protocols permit it, and I've
witnessed them in the field with my own two eyes. Hell, they're even
well enough standardized that I've seen them in use on conference
networks. Some such attacks have been infamous.
MITM attacks are not currently the primary means for stealing credit
card numbers these days both because TLS makes it harder to do MITM
attacks and thus it is usually easier just to break in to the poorly
defended web server and steal the card numbers directly. However, that
is not a reason to remove anti-MITM defenses from TLS -- it is in fact
a reason to think of them as a success.
Indeed. Imagine if we waited until airplanes exploded regularly to
design them so they would not explode, or if we had designed our first
suspension bridges by putting up some randomly selected amount of
cabling and seeing if the bridge collapsed. That's not how good
engineering works.
This is especially true when the marginal cost of the defenses is near
zero. The design cost of the countermeasures was high, but once
designed they can be replicated with no greater expense than that of
any other protocol.

@_date: 2003-10-22 20:03:36
@_author: Perry E. Metzger 
@_subject: SSL, client certs, and MITM (was WYTM?) 
The cost of MITM protection is, in practice, zero. Indeed, if you
wanted to produce an alternative to TLS without MITM protection, you
would have to spend lots of time and money crafting and evaluating a
new protocol that is still reasonably secure without that
protection. One might therefore call the cost of using TLS, which may
be used for free, to be substantially lower than that of an
How low does the risk have to get before you will be willing not just
to pay NOT to protect against it? Because that is, in practice, what
you would have to do. You would actually have to burn money to get
lower protection. The cost burden is on doing less, not on doing
There is, of course, also the cost of what happens when someone MITM's
You keep claiming we have to do a cost benefit analysis, but what is
the actual measurable financial benefit of paying more for less

@_date: 2003-10-22 20:38:56
@_author: Perry E. Metzger 
@_subject: TLS, costs, and threat models 
We've heard a bit recently from certain parties, especially Ian Grigg,
claiming that one should use a "cost/benefit analysis" before using
TLS. The claim seems to be that it provides more protection than one
really needs.
However, there are many perfectly free (in both senses) TLS
implementations, and the added protocol components needed for
providing the protection that one may or may not need do not
substantially change the cost in practice of running the protocols.
We also do not have well studied protocols that provide lesser
protection, or a very good analysis of what the security properties
are of such theoretical protocols. Developing such protocols with
lower standards may be a substantial challenge if our past experience
with protocol development is any indication.
I would argue that most of the comments made claiming that TLS has a
"cost" associated with it are therefore specious. To those making these public statements, this is all a theoretical
concern. To me, however, this is a day to day nightmare I face in my
practice. Ad hoc protocols are almost universally filled with
A few days ago I saw yet another example of an in house ad hoc
protocol with what I can only describe as extraordinarily poor
properties, which is being used to protect financial transactions. The
author of the protocol is a very smart guy who knew nothing about
cryptography. He could have easily used TLS, and have used it with
much less effort than he actually spent, and would not have had these
problems. However, he didn't think he needed something "that
complicated", so in the typical way of such things he spent more time
and effort doing something far less secure.
This is, sadly, a routine sort of discovery.
To Ian, it is important that we do a detailed analysis and see whether
or not the free (in both senses) and well understood protocol is "cost
effective", never mind that the cost is in practice zero, or even
negative when compared to other protocols.
To me, it is important that we have at-hand cryptographic tools that
cover the needs of a wide variety of users, many of whom do not
understand the implications of their design decisions and who are not
going to gain anything from using a not-really-but-we'll-pretend "less
complicated" protocol.
By the way, I could make far more money custom designing protocols for
the needs of each customer. If there really was a "Guild of
Cryptographers" we'd be making money left and right by following the
process that Ian in effect recommends and trying to tailor ad hoc
protocols for everyone carefully designed to do no more than
necessary, and then taking yet more money fixing the mess when it
turns out that we're wrong.
The era of ad hoc protocols, however, has passed, just as the era
where every computer-using company built its own new languages and
operating systems has long passed. We no longer have economic
justification for that sort of thing, and we no longer have economic
justification for everyone rolling their own protocols either.

@_date: 2003-10-22 21:05:01
@_author: Perry E. Metzger 
@_subject: SSL, client certs, and MITM (was WYTM?) 
They cost nothing at all. I use certs every day that I've created in
my own CA to provide MITM protection, and I paid no one for them. It
isn't even hard to do.
Repeat after me:
TLS is not only for protecting HTTP, and should not be mistaken for https:.
TLS is not X.509, and should not be mistaken for X.509.
TLS is also not "buy a cert from Verisign", and should not be
mistaken for "buy a cert from Verisign".
TLS is just a pretty straightforward well analyzed protocol for
protecting a channel -- full stop. It can be used in a wide variety of
ways, for a wide variety of apps. It happens to allow you to use X.509
certs, but if you really hate X.509, define an extension to use SPKI
or SSH style certs. TLS will accommodate such a thing easily. Indeed, I
would encourage you to do such a thing.

@_date: 2003-09-06 14:09:34
@_author: Perry E. Metzger 
@_subject: cryptographic ergodic sequence generators? 
For making things like IP fragmentation ids and other similar protocol
elements unpredictable, it would be useful to have what I'll call a
cryptographic ergodic sequence generator -- that is, a generator that
will produce a sequence of n bit numbers such that there are no
repeats until you pass the 2^nth number in the sequence (that is, the
sequence is a permutation of all 2^n bit numbers) and such that it is
very difficult to predict what the next number in the sequence might
be beyond the fact that it will not be one of the numbers seen earlier
in the sequence. It is also rather important that the generator be
computationally inexpensive.
Anyone know how to produce such a thing?

@_date: 2003-09-06 18:54:11
@_author: Perry E. Metzger 
@_subject: cryptographic ergodic sequence generators? 
I've thought that. Unfortunately, I don't know that there are good
block ciphers out there with 32 bit block sizes, and some uses (for
example, IP fragment ids) are 32 bits.
Perhaps -- I don't know of a good one.

@_date: 2003-09-06 18:55:58
@_author: Perry E. Metzger 
@_subject: cryptographic ergodic sequence generators? 
I'd thought of that, but encrypting with a stream cipher would not
work for this application -- it would not produce an ergodic sequence

@_date: 2003-09-06 19:07:17
@_author: Perry E. Metzger 
@_subject: cryptographic ergodic sequence generators? 
For applications like block numbers in protocols, it is highly
desirable to avoid overlap for as long as possible.
I've noted to others on this before that for an application like
the IP fragmentation id, it might be even better if no repeats
occurred in any block of 2^31 (n being 32) but the sequence did not
repeat itself (or at least could be harmlessly reseeded at very very
long intervals). However, doing that might be even harder than
producing a more standard ergodic sequence...
I don't understand the question.
Re-keying is of course an option, but I'll admit that produces
problems of its own.

@_date: 2003-09-06 19:08:46
@_author: Perry E. Metzger 
@_subject: cryptographic ergodic sequence generators? 
I was unaware there *were* any good 32 bit block ciphers out there,
thus the question. Certainly that would do better than most
possibilities for this, yes.

@_date: 2003-09-22 17:40:22
@_author: Perry E. Metzger 
@_subject: "Cyrillic Projector" cracked. 
"The Cyrillic Projector is an encrypted sculpture at the
     University of North Carolina in Charlotte, that was created by
     Washington DC artist James Sanborn in the early 1990s.  It was
     inspired by the encrypted Kryptos sculpture that Sanborn created
     two years earlier for CIA Headquarters."

@_date: 2003-09-30 17:30:37
@_author: Perry E. Metzger 
@_subject: Monoculture 
(Responding to the chorus of protocol professionals saying "please do
 not roll your own")
TLS, IPSec, JFK, etc. are all intellectual property free. No one gets
money if people use them. There is no union here with an incentive to
eliminate competition. No one's pay changes if someone uses TLS
instead of a roll-your-own-protocol.
I did. Dependence on a single system is indeed a problem. However, one
must understand the nature of the problem, not diversify blindly.
Some companies are said to require that multiple high level executives
cannot ride on the same plane flight, for fear of losing too many of
them simultaneously. That is a way of avoiding certain kinds of
risk. However, I know of no company that suggests that some of those
executives fly in rickety planes that have never been safety tested
and were built by squirrels using only pine cones. That does not reduce
I have to agree with Matt Blaze, Eric Rescorla, and numerous others
who have said this before. Cryptographic algorithms and protocols are
exceptionally difficult to design properly, and you should not go
around designing something on a whim and throwing it into your
software, any more than you would invent a new drug one morning and
inject it into patients that afternoon.
There is nothing whatsoever wrong with people proposing a new protocol
or algorithm, publishing it, discussing it, etc. Indeed, TLS, AES and
all the rest started as published documents that were then subjected
to prolonged attempts to break them. If, after something has been
reviewed for some years, it then appears to have unique advantages and
no one has succeeded in attacking the protocol, it might even be fit
for use in products.
This is very very different, however, from subjecting your users to
seat-of-the-pants designed protocols and algorithms that have had no
review whatsoever. Given that even the professionals generally screw
it up the first few times around, it is hardly surprising that the
"roll your own" attempts are almost always stunningly bad. This is
doubly so given that the protocols and algorithms used in many of
these systems don't even have a pretense of superiority over the
existing ones.
The protocols Peter Gutmann was complaining about in the message that
started this thread are, for the most part, childishly bad in spite of
the protestations of their creators. Are you arguing that it is in the
interest of most people to be using such incompetently designed
"security software"?
By the way, none of this contradicts what a number of us said in our
monoculture paper.

@_date: 2004-04-07 17:19:11
@_author: Perry E. Metzger 
@_subject: voting 
I'm a believer in the KISS principle.
A ballot that is both machine and human readable and is constructed by
machine seems ideal. You enter your votes, a card drops down, you
verify it and drop it in a slot. Ideally, the cards would be marked
with something like OCR-B so that the correspondence between machine
marking and human marking is trivial.
You can't have "hanging chads" or mismarks on optical cards because a
machine marks it for you. You can always do a recount, just by running
the cards through the reader again. You can prevent ballot stuffing by
having representatives of several parties physically present during
the handling of the ballot boxes -- just like now. You can verify that
the counting mechanisms are working right by manually counting if
Complicated systems are the bane of security. Systems like this are
simple to understand, simple to audit, simple to guard.

@_date: 2004-04-08 08:24:13
@_author: Perry E. Metzger 
@_subject: voting 
Seems fine by me, except I'd make the ballot box only lightly frosted

@_date: 2004-04-09 12:46:47
@_author: Perry E. Metzger 
@_subject: voting, KISS, etc. 
I think that those that advocate cryptographic protocols to ensure
voting security miss the point entirely.
They start with the assumption that something is "broken" about the
current voting system. I contend it is just fine.
For example, it takes a long time to count pieces of papers compared
with bits. However, there is no actual need for speed in reporting
election results. This is not a stock exchange -- another election
will not be held the next day, and the number of elections being held
will not rise 8% per quarter. If it takes a day or even several days
to get an accurate count, no one will be hurt. The desires of
television networks to report the results in ten minutes is not
connected to the need for a democracy to have widespread confidence in
the election results. Speed is not a requirement. As it is, however,
automated counts of paper ballots are plenty fast enough already.
It also is seemingly "behind the times" to use paper and such to hold
an election when computers are available -- but the goal is not to seem
"modern" -- it is to hold a fair election with accurately reported
results that can be easily audited both before, during and after the
It seems to some to be "easier" to vote using an electronic
screen. Perhaps, perhaps not. My mother would not find an electronic
screen "easier" at all, but lets ignore that issue. Whether or not the
vote is entered on a screen, the fact that paper ballots can be
counted both mechanically (for speed) and by hand (as an audit
measure), where purely electronic systems lack any mechanism for
after-the-fact audit or recount, leads one to conclude that old
fashioned paper seems like a good idea, and if it is not to be marked
by hand, then at least let it be marked by the computer entry device.
It is also seemingly "better" to have a system where a complex
cryptographic protocol "secures" the results -- but the truth is that
it is more important that a system be obvious, simple and secure even
to relatively uneducated members of society, and the marginal security
produced by such systems over one in which physical paper ballots are
generated is not obvious or significant.
(The marginal security issue is significant. Consider that simple
mechanisms can render the amount of fraud possible in the "old
fashioned" system significantly smaller than the number of miscast
votes caused by voter mistakes, but that no technology can eliminate
voter mistakes. Then ask why a fully electronic "fraudless" system
understandable to a miniscule fraction of the population but where
miscast votes continue to occur -- and possibly to be inaccurately
perceived as evidence of fraud -- would be superior.)
To those that don't understand the "understandable to even those who
are not especially educated" problem, consider for moment that many
people will not care what your claims are about the safety of the
system if they think fraud occurred, even if you hand them a
mathematical proof of the system. I suspect, by the way, that they'll
be right, because the proofs don't cover all the mechanisms by which
fraud can occur, including "graveyard" voting.
We tamper with the current system at our peril. Most security
mechanisms evolve over time to adjust to the threats that happen in
the real world.  The "protocols" embedded in modern election laws,
like having poll watchers from opposing sides, etc., come from
hundreds of years of experience with voting fraud. Over centuries,
lots of tricks were tried, and the system evolved to cope with
them. Simple measures like counting the number of people voting and
making sure the number of ballots cast essentially corresponds,
physically guarding ballot boxes and having members of opposing
parties watch them, etc., serve very well and work just fine.
Someone mentioned that in some elections it is impractical for the
people running to have representatives at all polling places. It is,
in fact, not necessary for them to -- the threat of their doing so and
having enough poll watchers from enough organizations in a reasonably
random assortment of polling places is enough to prevent significant
I'm especially scared about mechanisms that let people "vote at home"
and such. Lots of people seem to think that the five minute trip to
the polling place is what is preventing people from voting, and they
want to let people vote from their computers. Lets ignore the question
of whether it is important that the people who can't be bothered to
spend ten minutes going to the polling place care enough about the
election to be voting anyway. Lets also ignore the totally unimportant
question of vote buying -- vote buying has happened plenty of times
over the centuries without any need for the purchaser to verify that
the vote was cast as promised. Tammany Hall did not need to watch
people's votes to run a political machine.
I'm much more concerned that we may be automating the "graveyard"
vote, which is currently kept in check by the need to personally
appear at polling places. I'm also concerned about the forms of fraud
I haven't even considered yet because no one has invented them yet.
Election security isn't just about assuring that votes are correctly
I'm a technophile. I've loved technology all my life. I'm also a
security professional, and I love a good cryptographic
algorithm. Please keep technology as far away as possible from the
voting booth -- it will make everyone a lot safer.

@_date: 2004-04-12 15:37:33
@_author: Perry E. Metzger 
@_subject: my periodic rant on quantum crypto 
the usual breathless hype:
I'm especially unimpressed with the "Does this spell the
end of the field of cryptography?" comment.
For those who don't know much about what it is, "Quantum Cryptography"
is a very expensive way of producing an unauthenticated link
encryption device. It is useless for any application other than link
encryption over a short distance and requires a dedicated optical
fiber to work.
QC has no properties that render it especially better for link
encryption than, say, a box from one of several vendors running AES on
the link instead. It is perhaps theoretically safer, but in practice
no one is going to break AES either -- they're going to bribe the
minimum wage guard at your colo to have 20 minutes alone with your box
while they install a tap on the clear side of it (or worse, they'll
slip in while the guard is asleep at his desk.)
QC still requires link authentication (lest someone else other than
the people you think you're talking to terminate your fiber
instead). As a result of this, you can't really get rid of key
management, so QC isn't going to buy you freedom from that.
QC can only run over a dedicated fiber over a short run, where more
normal mechanisms can work fine over any sort of medium -- copper, the
PSTN, the internet, etc, and can operate without distance limitation.
QC is fiendishly costly -- orders of magnitude more expensive than an
AES based link encryption box.
QC is extremely hard to test to assure there are no hardware or other
failures -- given the key in use, I can use intercepted traffic to
assure my AES link encryption box is working correctly, but I have no
such mechanism for a QC box.
On top of all of this, the real problems in computer security these
days have nothing to do with stuff like how your link encryption box
works and everything to do with stuff like buffer overflows, bad
network architecture, etc.
Given that what we're dealing with is a very limited technology that
for a very high price will render you security that is at best not
particularly better than what much more economical solutions will
yield, why do people keep hyping this?  Indeed, why do people buy these
boxes, if indeed anyone is buying them?
It is stunning that a lab curiosity continues to be mentioned over
and over again, not to mention to see venture capitalists dump money
after it.
BTW, none of this has anything to do with "Quantum Computing", which
may indeed yield breakthroughs someday in areas such as factoring but
which is totally unrelated...

@_date: 2004-08-16 22:29:24
@_author: Perry E. Metzger 
@_subject: HMAC? 
So the question now arises, is HMAC using any of the broken hash
functions vulnerable?
I can't answer that myself yet since I haven't given it a good enough
think, but I'll will point people at the original HMAC paper at:
The paper itself is at:

@_date: 2004-08-17 22:56:00
@_author: Perry E. Metzger 
@_subject: crypto '04 rump webcast 
I've been watching the webcast. The team that did the
md4/md5/haval-128/ripemd attacks just presented, and although it was
interesting it included precious few details of the attack beyond the
fact that it was a twist on differential cryptanalysis. Is there any
more information available at this point from anyone?

@_date: 2004-08-18 12:00:05
@_author: Perry E. Metzger 
@_subject: SHA-1 status, plus request for explanation... 
One more question about the results at Crypto...
Biham & Chen can find collisions in a reduced round version of SHA-1,
but am I correct in saying that no one has found collisions in the
full SHA-1 at this point?
And would anyone like to take a crack at explaining the work by Wang,
Feng, Lai and Yu in simpler terms for those of us who find the extant
documentation incomprehensible?

@_date: 2004-08-18 14:21:29
@_author: Perry E. Metzger 
@_subject: snakeoil of the day 
Quoting the project page
   This is a fast and simple, yet hard to crack encryption program. It
   uses XOR encryption with variable key, based on the password that user
   inputs to the program
I read the code quickly -- it is a simple repeated XOR of the key
against the ciphertext, with a couple of twists that don't change the
strength at all. It could have been broken way over a century ago by
someone of modest skill. Today I'd happily assign breaking it as a
homework exercise to intro cryptography students.
At least this is an open source project instead of some commercial

@_date: 2004-08-22 11:59:03
@_author: Perry E. Metzger 
@_subject: First quantum crypto bank transfer 
But we aren't physicists. We're security people. To us, this is an
extremely expensive way of producing a system that is no more secure
(and sometimes even less secure) than simply running, say, TLS.
Indeed, since you still need a standard message integrity check
mechanism like HMAC to assure end to end authentication (the mechanism
does not block man in the middle attacks on its own at all), you are
not in fact relying on QM for security! (If you are, you aren't
Sure, it is intellectually neat, but people are selling this
(literally -- there are commercial vendors out there now) as though it
were a practical way of solving security problems, which it is
not. They're spending lots amounts of money on what is essentially a
worthless technique.
Besides, this all gives the sense, which is completely incorrect, that
weak cryptography is the source of insecurity in today's systems. It
is not -- crypto is usually the armored steel door in the wall of
paper. The weak points are architecture and implementation, and almost
never the crypto.
I disagree. This is no longer research. It is being sold by people. We
also have a pretty strong idea of what this is capable of at this
point, and the answer is "it is a very expensive way of setting up a
one time pad except unlike a real one time pad, you can
man-in-the-middle it."
Repeating, this is not a set of experiments. There are a number of
companies trying to commercialize this white elephant. I won't quite
call it snake oil because it works as advertised, but at an amazing
It isn't research any more. There are companies trying to *sell this*.

@_date: 2004-12-09 11:32:59
@_author: Perry E. Metzger 
@_subject: export regulations updated 
Cryptome just published some updates to the crypto export regulations:

@_date: 2004-01-09 10:21:29
@_author: Perry E. Metzger 
@_subject: fun with CRLs! 
Verisign Certificate Expiration Causes Multiple Problems
  Posted by michael on Thursday January 08,   from the rot-at-the-root dept.
  We had to do a little sleuthing today. Many readers wrote in with
  problems that turned out to be related. A certificate which Verisign
  used for signing SSL certificates has expired. When applications which
  depend on that certificate try to make an SSL connection, they fail
  and try to access crl.verisign.com, the certificate revocation list
  server. This has effectively DOS'ed that site, and Verisign has now
  updated the DNS record for that address to include several
  non-routable addresses, reducing the load on their servers. Some
  applications affected include older Internet Explorer browsers, Java,
  and Norton Antivirus (which may manifest itself as Microsoft Word
  being very slow to start). Hope this helps a few people, and if you
  have other apps with problems, please post about them below.

@_date: 2004-07-03 14:44:11
@_author: Perry E. Metzger 
@_subject: md5 cracking for short texts 
These folks have a service that will find the text that hashed to an
MD5 if the text is less than or equal to 8 characters in length and
matches [0-9a-z]+

@_date: 2004-07-07 11:19:58
@_author: Perry E. Metzger 
@_subject: PORTIA workshop on sensitive data, July 8-9, 2004, Stanford Univ.  
The final workshop program is available at
    Some potential topics for breakout sessions are available at
    Directions to the workshop venue and parking instructions are at
    All interested parties are welcome to attend.
  If you have any questions, please contact the workshop organizers
  (Joan Feigenbaum, Vitaly Shmatikov, and Vicky Weissman) at   pw-org at csl.sri.com.

@_date: 2004-07-09 19:14:33
@_author: Perry E. Metzger 
@_subject: EZ Pass and the fast lane .... 
I doubt it.
All the toll lanes that accept EZ Pass that I've seen are equipped
with cameras. These cameras are used to identify toll evaders
already. You point out that doing this would require manual work, but
in fact several systems (including the one used for handling traffic
fees in central London) have already demonstrated that automated
license plate reading systems are feasible. Even without automated
plate reading, storing photographs is also now astoundingly cheap
given how cheap storage has gotten, so if anyone ever complained about
incorrect charges on their bill, finding the plates of the cars that
went through during the disputed toll collections would be trivial.
Unlike cellphones, this is not an instance where it would be easy to
get away with theft by cloning.

@_date: 2004-07-10 18:33:01
@_author: Perry E. Metzger 
@_subject: EZ Pass and the fast lane .... 
By the way, this is yet another instance in which it is important to
consider threat models and economics when thinking about security
systems. The people willing to fake both their license plates and
their EZ Pass device are few, so the losses from them will be
small. (If you fake your license plates, in many instances you don't
even need to fake the EZ Pass device as nothing prevents you from
simply driving through.)
On the other hand, the cost of a system capable of doing a
challenge-response turnaround -- and we're talking both that of
building new tags plus the cost of designing and deploying units
capable of conducting two full round trip communications with cars
going through at 25 miles an hour -- is pretty high. You also will
always need the camera systems because you need to catch people simply
driving through, and because you will always get toll disputes that
need resolution. That means you can't even save the cost of the plate
cameras even with a challenge/response system.
Economically speaking, then, it doesn't seem like the threat (a small
amount of toll evasion by people willing to fake their license plates
and to clone EZ Pass equipment) doesn't cost as much as the putative
cure, and can't even cure the problem (since fare evaders with fake
plates will simply drive through toll lanes without physical barriers,
such as all the high speed toll lanes).
If I were advising the automated toll system people, I'd say it was
not worth it.
On the other hand, more complicated tags *might* be worth it for
another purpose -- preserving the privacy of drivers by using more
complicated protocols. However, as the benefit of such systems is to
people who are unlikely to have much voice in the construction of the
system, and who are also unlikely to be willing to pay more money to
gain privacy, I think the implementation of such tags is unlikely.

@_date: 2004-07-21 12:10:08
@_author: Perry E. Metzger 
@_subject: Using crypto against Phishing, Spoofing and Spamming... 
I'm perhaps a bit overly blunt in this message. I apologize for that,
but I don't really know how to be more subtle and still get across my
That sounds like incomprehensible gobbledygook to me.
What we have here is a very practical question -- what does bitter
experience teach us about building systems that aren't secure against
eavesdropping. My own experiences say stay away from authenticators in
the clear -- I've had customers badly mangled by doing that sort of
thing. The experience of others is pretty much identical: virtually
every deployed system that has used authenticators in the clear, from
the old NAMPS analog mobile phones to telnet on the wire and others,
has been badly attacked.
The experience says that when you make eavesdropping an easy attack
people will eavesdrop. You take away the eavesdropping mechanism and
the attack goes away.
Sure, we could be foolish optimists and build new infrastructures that
allow eavesdropping, ignoring all the lessons of history, but then
what happens when we find ourselves faced with multi-billion dollar
retrofit jobs to try to stop the problem after the fact, if the
retrofit can be done at all?
You don't add SSL and such to a system long after the fact -- it is
too late to get adoption at that point. Thank goodness we have decent
protocols now to prevent eavesdropping. The attacks we see today would
be far far worse without them.
Yes. If I wanted to do it, I probably could, which means that bad guys
who want to do it can do it far better than I can. No, I won't say how
I would do it on this list.
I don't agree. I see it as certain to happen if money can be made
doing it. I don't buy the "who would figure out how to do it?" crap,
because we've seen tremendous ingenuity on the part of the bad
guys. Everyone always thinks that attacks won't happen if they
involve effort and ingenuity on the part of the bad guys, and then the
bad guys show effort and ingenuity and everyone is shocked. Well, it
turns out that bad guys are often less lazy than you are.
I think that phishing and such are pretty straightforwardly "active
attacks". If running networks of tens of thousands of zombies isn't
"active", what is? People commit crimes every day to send out porn
spam that would land them in jail for the rest of their lives if
someone actually prosecuted them. There are, however, few to no
Because people aren't aware of it happening to them, and because the
payoff on sniffing all the data going by in a 100m radius isn't as
interesting as the payoff in sniffing all the data going by a big pipe
in the middle of the net, and because the payoff in sniffing is pretty
low in general right now. Sure, I could listen in on my neighbors in
my building, but what would I learn? I'd need to deploy thousands of
sniffer boxes all over my city to get a decent traffic volume. It is
far more economical just to tap the cable provider's IP link, except
that right now I won't get many credit card numbers or other valuable
information by doing that.
No, we don't. Ask the mobile phone people if they want to go back to
systems that can be cloned with data gathered by sniffing, for
example. I think they'll tell you pretty clearly that they're not
interested in trying the experiment again.
We're even getting the equivalent of eavesdropping attacks now on ATMs
in which thin readers are placed in front of the real readers and
cameras are set up to try to get the user's PIN. If you can't trust
the physical world, I'll be damned if I recommend to a customer that
they trust a network they have no control over.
I'll be direct. I see no evidence for the position you espouse at all

@_date: 2004-06-01 11:41:42
@_author: Perry E. Metzger 
@_subject: Colossus reconstruction at Bletchley Park is finished. 
(I had the privilege, along with a few other folks on this list, of
seeing the reconstructed Colossus a couple of years ago up close while
it was in an earlier phase of the work. The fact that the job is
now finished is quite cool.)
Return of Colossus marks D-Day
By Jo Twist
BBC News Online technology staff
Colossus Mk2, a wartime code-breaker hailed as one of the first
electronic computers, has been rebuilt and reunited with Bletchley
Park veterans.

@_date: 2004-06-02 10:18:37
@_author: Perry E. Metzger 
@_subject: Chalabi Reportedly Told Iran That U.S. Had Code 
The New York Times reports:
Chalabi Reportedly Told Iran That U.S. Had Code
June 2, 2004
 By JAMES RISEN and DAVID JOHNSTON Ahmad Chalabi told an Iranian official that the U.S. had
broken the communications code of Iran's intelligence

@_date: 2004-06-02 10:21:59
@_author: Perry E. Metzger 
@_subject: SMTP over TLS  
I view link encryption for SMTP -- i.e. SMTP over TLS -- as having two
1) It frustrates "vacuum cleaner" mail tapping efforts to some degree.
2) It can be used effectively for authenticating the posting of a
   mail message from an MUA to the first hop MTA.
I don't see it as being useful for making sure your mail is actually
"secure", but I think it is a valuable thing to turn on as much as one
can, if only to reduce "casual eavesdropping". It certainly can't stop
(for the most part) concerted attacks, but I don't think most people
view it as being useful for that.

@_date: 2004-06-02 12:45:45
@_author: Perry E. Metzger 
@_subject: Article on passwords in Wired News 
An article on passwords and password safety, including this neat bit:
   For additional security, she then pulls out a card that has 50
   scratch-off codes. Jubran uses the codes, one by one, each time she
   logs on or performs a transaction. Her bank, Nordea PLC, automatically
   sends a new card when she's about to run out.

@_date: 2004-06-02 17:16:00
@_author: Perry E. Metzger 
@_subject: Article on passwords in Wired News 
FYI, /. has posted a story on this, but, true to form, they confuse
one time passwords with one time pads.

@_date: 2004-06-04 11:14:04
@_author: Perry E. Metzger 
@_subject: PORTIA Workshop on Sensitive Data (fwd) 
If you think that "cryptography at metzdowd.com" would be interested
in the enclosed, please forward it.
Joan FEigenbaum
---------- Forwarded message ----------
The preliminary program for the PORTIA Workshop on Data in Medical, Financial, and Content-Distribution Systems is now available at
If you would like to attend but have not registered yet, please do so using our online registration form (there is no registration fee):
The hotel reservation deadline is drawing near.  We have a block of rooms
at the Palo Alto Sheraton, but the rate and availability are guaranteed
only until June 14.  Please make your reservations before that date.
Reservations can be made by calling the hotel directly at 1-800-874-3516
or 1-650-328-2800, or by email at SheratonReservation at pahotel.com
Please mention PORTIA workshop when making your hotel reservation.
We look forward to meeting you at the workshop!
Joan Feigenbaum
Vitaly Shmatikov
Vicky Weissman

@_date: 2004-06-04 13:41:09
@_author: Perry E. Metzger 
@_subject: New James Bamford book 
James Bamford, of "The Puzzle Palace" and "Body of Secrets" fame, has
written a new book called "A Pretext for War". Has anyone out there
read it yet? If so, does it have any interesting new NSA or other
general SIGINT related content?

@_date: 2004-06-08 12:12:04
@_author: Perry E. Metzger 
@_subject: W Post: US gets 126,000,000 intelligence intercepts a day? 
[Forwarded on John's behalf...]
  "The government receives 126 million intelligence intercepts a day."
I've never seen anyone bandy about a number for the total daily volume
of vacuum cleaner 'take' before.  Perhaps the author can point us to a
nice academic paper that breaks out the volumes that come from sigint,
'national technical means' imint, humint, open sources, traffic
analysis, pass-thrus from foreign governments, illegal US domestic
wiretaps, Patriot Act domestic wiretaps, etc?  Volume of faxes
vs. voice phone calls vs. emails vs. other sources?  Even a breakdown
of unencrypted vs. encrypted would be interesting.
The sentence is from a Washington Post op-ed suggesting rejection of
the well analyzed post-TIA "data mining" blue-ribbon panel study.  The
study recommended that the government not be permitted to search
through data about its citizens without a warrant based on individual
suspicion.  The quote is part of her argument that the gov't would be
paralyzed if it had to look at all that data and follow the
Constitution at the same time.  She doesn't follow that argument to
the obvious conclusion that it should perhaps collect less data, but I
The story is nominally buried behind a cookie/'free registration'
wall, which I don't choose to access because I support REAL web sites,
not consumer-tracking services.  But I found this equivalent 'real'
link to the story, on the author's web site:
  The article is by Heather Mac Donald, a fellow at the Manhattan
Institute, which seems to be in favor of greater economic choice,
individual responsibility, and totalitarianism.  Two out of three
isn't bad, and  and  suggest that she might have some good
friends in the Bush Administration.  Here's her page and many
  Does Ms. Mac Donald know what she's talking about here?

@_date: 2004-06-09 16:56:03
@_author: Perry E. Metzger 
@_subject: Claimed proof of the Riemann Hypothesis released 
news.com.com.com.com.com reports:
  A mathematician at Purdue University claims to have come up with a
  proof for the Riemann hypothesis, often called the greatest unsolved
  math problem, although the work has yet to be peer-reviewed.
  Louis de Branges de Bourcia, the Edward C. Elliott Distinguished
  Professor of Mathematics at Purdue's School of Science, this week
  posted a 23-page paper detailing his attempts at a proof. Link to the actual paper:
Actual practical impact on cryptography? Likely zero, even if it turns
out the proof is correct (which of course we don't know yet), but it
still is neat for math geeks.

@_date: 2004-06-14 16:30:08
@_author: Perry E. Metzger 
@_subject: Passwords can sit on disk for years 
That's actually not true. Many compilers are smart enough to do that,
and in fact do that sort of thing. That's what data flow analysis is
The reason that C has a "volatile" keyword is to inform compilers that
there are side effects that are not visible from the code alone in the
use of particular variables. That's useful when you don't want sets of
registers in hardware optimized away, but it is also of substantial
use in preventing the removal via optimization of password zeroing
By the way, although C is often too convoluted because of pointer
arithmetic for compilers to do good optimizations, many high level
languages are not -- you should certainly never assume that operations
will not be reordered or removed by an optimizing compiler if you know
what is good for you.

@_date: 2004-06-19 15:41:21
@_author: Perry E. Metzger 
@_subject: BBC story on Iran codes 
Breaking codes: An impossible task?
  By Paul Reynolds
  BBC News Online world affairs correspondent
  Recent reports that the United States had broken codes used by the
  Iranian intelligence service have intrigued experts on cryptology
  because a modern cipher should be unbreakable. No real new info, but some good background. Several familiar names,
such as Ross Anderson, are interviewed.
[Note: I found out about the article from Eric Rescorla's blog.]

@_date: 2004-03-31 19:22:57
@_author: Perry E. Metzger 
@_subject: ADMIN: the list... 
No, I'm not dead, I've just been extremely delinquent in moderating
the list.
I should be sending out the queued messages that are still relevant
over the next few days, and then we'll be back to normal.

@_date: 2004-05-08 21:19:17
@_author: Perry E. Metzger 
@_subject: acoustic cryptanalysis 
Adi Shamir & Eran Tromer find you can literally "listen in" on your
computer doing RSA computations:

@_date: 2004-05-26 11:27:41
@_author: Perry E. Metzger 
@_subject: ADMIN: sad but needed anti-spam measures being implemented 
Moderator's Note:
One of the main delays I have in moderating the list has been the
massive increase in spam that has happened in the last six months. I
have had to wade through first two or three spams per real list
message, and then five or ten, and finally one hundred or more. Most
days, I simply didn't have time or the stomach to deal with it.
I was leaving the list with deliberately low levels of certain kinds
of protection at the gate (like not blocking mail from
non-subscribers) because I didn't want to stop announcements from
third parties or anonymous contributions to the list. Unfortunately, I
can no longer do that -- it has just become too difficult to deal
As of yesterday, I implemented some low level blocks on the SMTP
server the list is hosted on that prevent most unrepliable addresses
from sending mail in. Within the next few days, I intend to block all
postings from non-subscribing addresses or which contain certain kinds
of content that I've been blocking anyway (such as HTML formatted
I realize this will inconvenience some of you, and I'm sorry about
that, but I just can't deal with the work any more without taking some
steps like this.
At one time, I assumed that law enforcement "needs" would be the
reason anonymity died on the internet, but now it appears that
spammers have done the anti-privacy job for them.

@_date: 2004-05-26 22:34:33
@_author: Perry E. Metzger 
@_subject: ADMIN: "subscribers only" posting 
Moderator's Note:
As of now, if you want to be able to send a message to the list, you
have to be a subscriber. Otherwise, the message will bounce at the
SMTP transaction with my mail server.
The old fashioned method of forwarding non-member posts to the
moderator (me) for approval was swamping me with too much spam to wade
Those of you who habitually post from an address other than the one
you are subscribed under can ask me to put you on a special list of
people who can post but are not subscribed.
I apologize for the inconvenience, but things were just too difficult
to deal with any other way.
PS Jon Postel's "be conservative in what you send, and liberal in what
you receive" is dead. I miss it, and the sort of network it was a part

@_date: 2004-05-27 07:46:35
@_author: Perry E. Metzger 
@_subject: ADMIN: 'subscribers only' posting 
I'm afraid that either the remailer owners add their outbound
addresses to the exceptions list I maintain, or the users mail me
directly and ask me to forward their comments, or some such. I dislike
having to do this, but I really had no choice. :(

@_date: 2004-05-27 21:19:17
@_author: Perry E. Metzger 
@_subject: Satellite eavesdropping of 802.11b traffic 
Dunno if it would work in orbit,, but you can get surprising results
right here on earth using phased arrays.
Vivato is selling very long range phased array equipment as long
range/high quality 802.11 basestations, but you could do precisely the
same trick to eavesdrop instead of to communicate. With enough
computing power, one device could listen in on every 802.11
communication in a very large radius.
I don't know how practical it would be to set up some sort of large
scale phased array in orbit -- I suspect the answer is "not practical
at all" -- but the principle could apply there, too.

@_date: 2004-05-28 13:28:07
@_author: Perry E. Metzger 
@_subject: Satellite eavesdropping of 802.11b traffic 
As I mentioned, phased arrays are very good at getting out from under
the "too many users of the same channel" problem while
eavesdropping. They allow you to focus on multiple sources

@_date: 2004-05-29 20:54:55
@_author: Perry E. Metzger 
@_subject: "The secret code is 00000000" 
This article claims the code for the permissive action links on many
US nuclear weapons in the 1960s was well known to be 00000000.

@_date: 2004-11-01 15:28:58
@_author: Perry E. Metzger 
@_subject: US deploys anti-satelite equipment 
WASHINGTON (Reuters) -- The U.S. Air Force quietly has put into
service a new weapon designed to jam enemy satellite communications, a
significant step toward U.S. control of space.

@_date: 2004-11-23 11:42:54
@_author: Perry E. Metzger 
@_subject: feel free to capture keystrokes at will 
Judge dismisses keylogger case
By Kevin Poulsen, SecurityFocus Nov 19 2004 6:40PM
A federal judge in Los Angeles has dismissed charges against a
California man who used a keystroke logger to spy on his employer,
ruling that use of such a device does not violate federal wiretap
law.

@_date: 2004-11-23 11:49:08
@_author: Perry E. Metzger 
@_subject: More on serial numbers in color printing 
Another article on serial numbers embedded in the output of color
printers and copiers:

@_date: 2004-11-23 21:18:39
@_author: Perry E. Metzger 
@_subject: Fyodor of Nmap regularly gets FBI subpoenas. 
Just got this in email -- I thought it might be of interest to the
Dear Nmap hackers,
Let me first wish you Americans a happy Thanksgiving.  Meanwhile, I'm
hard at work on a holiday Nmap version which should be available by
But enough pleasantries -- I want to discuss a sobering topic.  With
increasing regularity this year, FBI agents from all over the country
have contacted me demanding webserver log data from Insecure.Org.
They don't give me reasons, but they generally seem to be
investigating a specific attacker who they think may have visited the
Nmap page at a certain time.  If they see that an attacker ran the
command "wget from a compromised host, they assume that she might have obtained that
URL by visiting the Nmap download page from her home computer.  So
far, I have never given them anything.  In some cases, they asked too
late and data had already been purged through our data retention
policy.  In other cases, they failed to serve the subpoena properly.
Sometimes they try asking without a subpoena and give up when I demand
One can argue whether helping the FBI is good or bad.  Remember that
they might be going after spammers, cyber-extortionists, DDOS kiddies,
etc.  In this, I wish them the best.  Nmap was designed to help
security -- the criminals and spammers put my work to shame!  But the
desirability of helping the FBI is immaterial -- I may be forced by
law to comply with legal, properly served subpoenas.  At the same
time, I'll try to fight anything too broad (like if they ask for
weblogs for a whole month).  Protecting your privacy is important to
me, but Nmap users should be savvy enough to know that all of your
network activity leave traces.  I'm not the only one who gets these
subpoenas -- large ISPs and webmail providers receive them daily.
Most other major security sites probably do too.  Most of you probably
don't care if someone finds out that you downloaded Nmap, Nessus,
Hping2, John the Ripper, etc.  Nothing on Insecure.Org is illegal.
But for those of you who do care, there are plenty of mechanisms
available to preserve your anonymity.  Remember this security mantra:
defense in depth.
For help using this (nmap-hackers) mailing list, send a blank email to nmap-hackers-help at insecure.org . List archive:

@_date: 2004-10-22 08:40:27
@_author: Perry E. Metzger 
@_subject: Are new passports [an] identity-theft risk? 
I don't know who *else* has said it, but I've said this repeatedly at
conferences. With phased arrays, you should be able to read RFID tags
at surprising distances, and in spite of attempts to jam such signals
(such as RSA's proposed RFID privacy mechanism).
This isn't terribly surprising but for the fact that most people don't
think in terms of the fact that you can spatially discriminate radio

@_date: 2004-09-22 13:31:02
@_author: Perry E. Metzger 
@_subject: Enigma-E 
Always wanted an Enigma but the finite supply on the open market a
bother? Well, now you can get a PC board kit for constructing an
electronic version of the old World War II favorite! You'll have to
make the wooden case yourself, though.
PS Hat tip to J.I. for pointing this out to me.

@_date: 2005-08-06 14:28:29
@_author: Perry E. Metzger 
@_subject: solving the wrong problem 
Frequently, scientists who know nothing about security come up with
ingenious ways to solve non-existent problems. Take this, for example:
Basically, some clever folks have found a way to "fingerprint" the
fiber pattern in a particular piece of paper so that they know they
have a particular piece of paper on hand. It is claimed that this
could help stop forged passports.
Unfortunately, the invention is wholely useless for the stated purpose.
If the information is put onto the passport itself, nothing would stop
someone from taking a new, forged passport and adding the fingerprint
information onto the passport. If the information was protected by a
public key, that could prevent such forgeries, except that if you
already have a public key, you can protect the information printed on
the passport with said public key already, bypassing any care about
whether the paper in the passport is "original". You could, of course,
put the fingerprint information on-line, but if you have an online
database good enough to verify that the passport is real, why have a
passport? Why not just store identifying information about the person
far away from the ability to tamper with it?
Anyway, I have a larger point.
I read about such stuff every day -- wacky new ways of building
"tamper proof tokens", "quantum cryptography", and other mechanisms
invented by smart people who don't understand threat models at all.
We already have the term "snake oil" for a very different type of bad
security idea, and the term has proven valuable for quashing such
things. We need a term for this sort of thing -- the steel tamper
resistant lock added to the tissue paper door on the wrong vault
entirely, at great expense, by a brilliant mind that does not
understand the underlying threat model at all.
Anyone have a good phrase in mind that has the right sort of flavor
for describing this sort of thing?

@_date: 2005-08-06 17:36:46
@_author: Perry E. Metzger 
@_subject: solving the wrong problem 
The threat model is slightly more complex than that. The industry
doesn't want people reselling real tickets, either, which is one
reason that physical objects aren't enough. In fact, the NY Times
article you cite mentions people being physically escorted in to
prevent resale as well as duplication.
A variant on the moviefone.com model might work better for these folks

@_date: 2005-08-09 16:37:24
@_author: Perry E. Metzger 
@_subject: spyware targets bank customers. news at 11. 
"A major identity theft ring has been discovered that affects up to 50
    banks, according to Sunbelt Software, the security company that says
    it uncovered the operation. The operation, which is being
    investigated by the FBI, is gathering personal data from
    "thousands of machines" using keystroke-logging software, Sunbelt
    said Monday."
(Hat tip to Adam Fields for pointing this one out to me.)

@_date: 2005-08-10 13:24:07
@_author: Perry E. Metzger 
@_subject: NY Times article on biometrics and border control 
Thought this would be of some interest. Unfortunately, the article
will not be visible after a few days, thanks to the NY Times'
policies, and can only be viewed if you register. :(
WASHINGTON | August 10, 2005
Hurdles for High-Tech Efforts to Track Who Crosses Borders
By ERIC LIPTON
The government's effort to collect biometric data to track foreigners
visiting the U.S. has fallen far short of its goals.

@_date: 2005-08-17 08:21:31
@_author: Perry E. Metzger 
@_subject: faster SHA-1 attacks? 
I was unable to watch webcast of the rump session at the Crypto
conference last night, but I have heard that a proxy announced that
Wang has an order 2^63 attack on SHA-1. Can anyone confirm that, and
give details?

@_date: 2005-08-22 08:59:11
@_author: Perry E. Metzger 
@_subject: online MD5 crack database 
This website has a large database of MD5 hashes of common passwords:
Presumably, as storage continues to get cheaper, this sort of thing
will only become easier.
Ways to ameliorate it? Consistently using long (64 bits or more) salts
with hashed passwords makes storing such databases much harder, and
encouraging the use of far longer passphrases with much more entropy
reduces the problem further. Longer hashes are also a good idea.
None of this is new -- I'm just noting that the trend continues apace.
PS I found the link off of a /. story earlier today

@_date: 2005-08-26 08:55:05
@_author: Perry E. Metzger 
@_subject: Another entry in the internet security hall of shame.... 
Remember that Jabber and similar protocols also trust servers to some
extent. Servers store and distribute valuable information like
presence data -- it is architecturally hard to do otherwise. That
means that you also want to be sure you're talking to the right
server (and that the server wants to be sure it is talking to an
authenticated client).
I agree that you *also* want end to end, such as pgp over Jabber
provides. I really wish Gaim supported the pgp over Jabber stuff the
way PSI does...

@_date: 2005-08-26 17:20:00
@_author: Perry E. Metzger 
@_subject: reading PINs in "secure" mailers without opening them 
Often, banks send people PINs for their accounts by printing them on
tamper "secure" mailers. Some folks at Cambridge have discovered that
it is easy to read the PINs without opening the seals...

@_date: 2005-12-18 13:58:06
@_author: Perry E. Metzger 
@_subject: A small editorial about recent events. 
A small editorial from your moderator. I rarely use this list to
express a strong political opinion -- you will forgive me in this
This mailing list is putatively about cryptography and cryptography
politics, though we do tend to stray quite a bit into security issues
of all sorts, and sometimes into the activities of the agency with the
biggest crypto and sigint budget in the world, the NSA.
As you may all be aware, the New York Times has reported, and the
administration has admitted, that President of the United States
apparently ordered the NSA to conduct surveillance operations against
US citizens without prior permission of the secret court known as the
Foreign Intelligence Surveillance Court (the "FISC"). This is in clear
contravention of 50 USC 1801 - 50 USC 1811, a portion of the US code
that provides for clear criminal penalties for violations. See:
The President claims he has the prerogative to order such
surveillance. The law unambiguously disagrees with him.
There are minor exceptions in the law, but they clearly do not apply
in this case. They cover only the 15 days after a declaration of war
by congress, a period of 72 hours prior to seeking court authorization
(which was never sought), and similar exceptions that clearly are not
There is no room for doubt or question about whether the President has
the prerogative to order surveillance without asking the FISC -- even if
the FISC is a toothless organization that never turns down requests,
it is a federal crime, punishable by up to five years imprisonment, to
conduct electronic surveillance against US citizens without court
The FISC may be worthless at defending civil liberties, but in its
arrogant disregard for even the fig leaf of the FISC, the
administration has actually crossed the line into a crystal clear
felony. The government could have legally conducted such wiretaps
at any time, but the President chose not to do it legally.
Ours is a government of laws, not of men. That means if the President
disagrees with a law or feels that it is insufficient, he still must
obey it. Ignoring the law is illegal, even for the President. The
President may ask Congress to change the law, but meanwhile he must
follow it.
Our President has chosen to declare himself above the law, a dangerous
precedent that could do great harm to our country.  However, without
substantial effort on the part of you, and I mean you, every person
reading this, nothing much is going to happen.  The rule of law will
continue to decay in our country. Future Presidents will claim even
greater extralegal authority, and our nation will fall into
despotism. I mean that sincerely. For the sake of yourself, your
children and your children's children, you cannot allow this to stand.
Call your Senators and your Congressman.  Demand a full investigation,
both by Congress and by a special prosecutor, of the actions of the
Administration and the NSA. Say that the rule of law is all that
stands between us and barbarism. Say that we live in a democracy, not
a kingdom, and that our elected officials are not above the law. The
President is not a King. Even the President cannot participate in a
felony and get away with it. Demand that even the President must obey
the law.
Tell your friends to do the same. Tell them to tell their friends to
do the same. Then, call back next week and the week after and the week
after that until something happens. Mark it in your calendar so you
don't forget about it. Politicians have short memories, and Congress
is about to recess for Christmas, so you must not allow this to be
forgotten. Keep at them until something happens.

@_date: 2005-12-18 15:17:28
@_author: Perry E. Metzger 
@_subject: A small editorial about recent events. 
A couple of people have written to ask if they can forward on this
message elsewhere. Yes, I am happy with that, and I should have said
it in the first place.

@_date: 2005-12-18 19:22:22
@_author: Perry E. Metzger 
@_subject: A small editorial about recent events. 
I have been unable to find any evidence in the text of said
resolutions that they in any way altered or amended the law on this,
even temporarily.  Perhaps it is the argument of the President's
lawyers that something analogous to a state of war was authorized, but
the fact that there is a time limit even when an explicit declaration
of war exists leads me to disbelieve such arguments on their face.
I fully expect the President's lawyers and media spokespeople to
vigorously deny that the President has broken a criminal statute. It
would, in fact, be shocking if they did anything else -- an attorney
or spokesman who claimed in the press that his client had committed a
crime would be a very unusual thing indeed. That should not sway us,
the members of the public.
Unlike previous eras, it is trivial for anyone who wishes to to
examine the US Code, in moments, without having to leave their
desk. It is trivial for someone to examine the texts of congressional
resolutions, too. It is fairly simple to verify that regardless of any
assertions made by the President's legal advocates and staff, a
felony has been committed. The White House has not even denied that
the activities took place, so the only real question at hand is the
law, and anyone can read the law for themselves.
Yes, but this was the first instance that I know of in which the White
House has essentially admitted that the President specifically
solicited and authorized the commission of a federal crime.
Again, I encourage people to go and read:
Unlike most federal law, this section of the US Code is exceptionally
clear and unambiguous. It declares that surveillance of US citizens is
legal only with court approval, creates a (useless) court to authorize
surveillance of US citizens, it lists a few exceptions to the law (none
of which apply) and then states:
    A person is guilty of an offense if he intentionally[...] engages
    in electronic surveillance under color of law except as authorized
    by statute[...]
    [...]
    An offense described in this section is punishable by a fine of not
    more than $10,000 or imprisonment for not more than five years, or
    both.
    [...]
    There is Federal jurisdiction over an offense under this section if
    the person committing the offense was an officer or employee of the
    United States at the time the offense was committed. This law was specifically instituted in the 1970s after it was
discovered that the NSA was conducting surveillance of US
persons. There can be no question as to its intent.
Our problem in this instance is not the facts, since the White House
has stipulated the facts, and it is not the law, since the law is
clear on the fact that the actions taken are criminal. Our problem is
with the fact that our system of justice depends on human beings
who are often scared of the consequences of prosecuting the
powerful. It is up to us as citizens to make it clear to our
representatives that we care.
The ugliest thing in this incident is the fact it was clearly a pure
demonstration of power. The FISC rarely if ever denies requests, and
that the law specifically allows surveillance to begin BEFORE the FISC
is asked for an order. The administration would have had no difficulty
whatsoever routinely spying on US citizens without breaking the
law. The administration is clearly so fully convinced that the
President is above the law that it did not bother even to pay lip
service to such worthless protections as the law provided for.
He will get away with it if we stand idly by. If this is to be
stopped, people like us must make our voices heard.

@_date: 2005-12-21 13:46:23
@_author: Perry E. Metzger 
@_subject: another feature RNGs could provide 
Actually, by definition, a cipher should be a permutation from the set
of plaintexts to the set of ciphertexts. It has to be 1 to 1 bijective
or it isn't an encryption algorithm.
Therefore, if you want an ergodic sequence of size 2^N, a counter
encrypted under an N bit block cipher will do it.

@_date: 2005-12-27 19:15:05
@_author: Perry E. Metzger 
@_subject: ADMIN: end of latest SSL discussion 
The latest round of "SSL and X.509 certs in browsers are broken" has
gone on too long. I kept hoping after weeks people might get bored,
but they haven't. I'm cutting it off for at least a little while.
I'll entertain new postings only if they propose actual solutions
rather than long philosophical discussions of how we went wrong when
we developed notochords or left the ocean or went bipedal or what have
The unending rant can continue in a few weeks after I've forgotten
about this one.
By the way, this does not apply to any sort of actual technical
discussion (like the discussion of which bignum implementations are

@_date: 2005-12-30 10:21:21
@_author: Perry E. Metzger 
@_subject: NSA inducts four into "Hall of Honor" 
I was unaware the National Cryptological Museum even had a "Hall of
Honor", but apparently it keeps one on behalf of the NSA:

@_date: 2005-01-05 18:08:31
@_author: Perry E. Metzger 
@_subject: FreeBSD's urandom versus random 
Not the 5.3 version but I have looked a bit at earlier versions. I was
pretty scared, frankly.
The author gave a talk at a BSDCon where he displayed both a profound
set of misunderstandings about what the papers he had read meant and
an extremely strong amount of arrogance. Among other things, he
claimed that Schneier and Co. had proven the security of Yarrow (which
of course they never had claimed), and that his changes to Yarrow made
it better (very dubious). He also obviously didn't understand crypto
very well. I wouldn't have minded so much if he hadn't been extremely
belligerent about defending his beliefs.
Anyway, after the talk I took a look at the code, and I didn't feel
very comfortable with it. It has been too many years now for me to
remember specifics, and it may have been changed a lot in the interim

@_date: 2005-07-05 12:32:26
@_author: Perry E. Metzger 
@_subject: [Forwarded] RealID: How to become an unperson. 
I'm forwarding this article, originally from the Cypherpunks mailing
list (I saw it on Dave Farber's "Interesting People") because I find
the security implications important.
HOWEVER, I'm warning in advance that I'm not going to forward a lot of
followups, especially if they are unoriginal and/or contain lots of
ranting language and little content. (I'm mildly uncomfortable with
the original, actually, because I prefer light to heat, but it makes a
very interesting point...)
Sent: Friday, July 01, 2005 6:34 PM
For those of you who may have missed it, today was the first day of the
new "Real ID Act", a/k/a, the American Nazification Papers Act.  I
wouldn't have know myself except that I recently moved, and wanted to
exchange my current Illinois drivers license for a Missouri one.
Not so fast...
"You have a passport?"
"No, I don't travel."
"A certified copy of your original birth certificate?"
"Haven't had one since I was born, fifty years ago.  And since I was  born about 1500 miles from here, getting one is no small task."
"Too bad.  Your old license is invalid and you can't get another one in
any state, starting today, without at least one of the two documents,  PLUS secondary ID to back them up."
Even though I have a current license, and even though I am in their
system as having held a valid Missouri license for 15+ years, photo
included, none of it is good enough.
OK, so I have no choice, I go to the post office to get a Passport -
same thing.
Fine, I'll just order the birth certificate and get it over with, right?
Wrong.  New York wants affirmative proof of identity for a copy now:
passport or your [missing] original birth certificate.  Anyone else
see a circular problem here?
"I need a new birth certificate because the old one was lost about forty
years ago. And I don't have a passport to prove my identity."
"Get your parents to testify who you are, and make sure they bring their
"They are both dead."
"Sorry Sir, I'm afraid we won't be able to help you then."
Durbin was right.  And he didn't even scratch the surface!  Anyone who
thinks this "Real ID Act" is about getting false ID out of the hands
of "The Terrorists" is an idiot: they will simply print their own
drivers licenses - this is about forcing the regular population to get
used to intrastate passports.  This act essentially forces you to have
a passport for everyday things like banking, car purchases and certain
repairs, checks, etc.
We have literally allowed the Nazification to begin, and we've even
welcomed it with eager open arms - all in the name of "Fighting Terror".
Crystal clear, pure unadulterated bullshit.

@_date: 2005-07-05 12:56:58
@_author: Perry E. Metzger 
@_subject: Time-Memory-Key tradeoff attacks? 
The following has appeared in the IACR preprint archive. I would
appreciate comments. The author certainly has reasonable credentials,
but the document is low on detail:
  Some Thoughts on Time-Memory-Data Tradeoffs
  Author: Alex Biryukov
  Abstract: In this paper we show that Time-Memory tradeoff by Hellman
  may be extended to Time-Memory-Key tradeoff thus allowing attacks much
  faster than exhaustive search for ciphers for which typically it is
  stated that no such attack exists. For example, as a result AES with
  128-bit key has only 85-bit security if $2^{43}$ encryptions of an
  arbitrary fixed text under different keys are available to the
  attacker. Such attacks are generic and are more practical than some
  recent high complexity chosen related-key attacks on round-reduced
  versions of AES. They constitute a practical threat for any cipher
  with 80-bit or shorter keys and are marginally practical for 128-bit
  key ciphers. We also show that UNIX password scheme even with
  carefully generated passwords is vulnerable to practical tradeoff
  attacks. Finally we also demonstrate a combination of rainbow tables
  with the time-memory-data tradeoff which results in a new tradeoff
  curve.
By the way, much thanks to Eric Rescorla for pointing this out to me.

@_date: 2005-07-06 09:49:02
@_author: Perry E. Metzger 
@_subject: Private info for sale in Moscow kiosks... 
Bruce Schneier's blog had a pointer to this story, about the black
market in personal information in Moscow:
   At the Gorbushka kiosk, sales are so brisk that the vendor excuses
   himself to help other customers while the foreigner considers his
   options: $43 for a mobile phone company's list of subscribers? Or $100
   for a database of vehicles registered in the Moscow region?
   The vehicle database proves irresistible. It appears to contain names,
   birthdays, passport numbers, addresses, telephone numbers,
   descriptions of vehicles, and vehicle identification (VIN) numbers for
   every driver in Moscow.

@_date: 2005-07-07 09:52:28
@_author: Perry E. Metzger 
@_subject: [Forwarded] RealID: How to become an unperson. 
Perhaps I can explain why I am.
I do not trust governments. I've inherited this perspective. My
grandfather sent his children abroad from Speyer in Germany just after
the ascension of Adolf Hitler in the early 1930s -- his neighbors
thought he was crazy, but few of them survived the coming events. My
father was sent to Alsace, but he stayed too long in France and ended
up being stuck there after the occupation. If it were not for forged
papers, he would have died. (He had a most amusing story of working as
an electrician rewiring a hotel used as office space by the Gestapo in
Strasbourg -- his forged papers were apparently good enough that no
one noticed.)  Ultimately, he and other members of the family escaped
France by "illegally" crossing the border into Switzerland. (I put
"illegally" in quotes because I don't believe one has any moral
obligation to obey a "law" like that, especially since it would leave
you dead if you obeyed.)
Anyway, if the governments of the time had actually had access to
modern anti-forgery techniques, I might never have been born.
To you, ID cards are a nice way to keep things orderly. To me, they
are a potential death sentence.
Most Europeans seem to see government as the friendly, nice set of
people who keep the trains running on time and who watch out for your
interests.  A surprisingly large fraction of Americans are people or
the descendants of people who experienced the institution of
government as the thing that tortured their friends to death, or
gassed them, or stole all their money and nearly starved them to
death, etc.  Hundreds of millions of people died at the hands of their
own governments in the 20th century, and many of the people that
escaped from such horrors moved here.  They view things like ID cards
and mandatory registry of residence with the local police as the way
that the government rounded up their friends and relatives so they
could be killed.
I do not wish to argue about which view is correct. Perhaps I am wrong
and Government really is the large friendly group of people that are
there to help you. Perhaps the cost/benefit analysis of ID cards and
such makes us look silly. I'm not addressing the question of whether
my view is right here -- I'm just trying to explain the psychological
mindset that would make someone think ID cards are a very bad idea.
So, the next time one of your friends in Germany asks why the crazy
Americans think ID cards and such are a bad thing, remember my father,
and remember all the people like him who fled to the US over the last
couple hundred years and who left children that still remember such
things, whether from China or North Korea or Germany or Spain or
Russia or Yugoslavia or Chile or lots of other places.

@_date: 2005-07-08 10:42:02
@_author: Perry E. Metzger 
@_subject: Why Blockbuster looks at your ID. 
Dirk-Willem implicitly asks an interesting question. Answering it
brings us back to security again.
Why does the clerk at Blockbuster want to see your driver's license?
Because his management has been told, by their bank, that if they do
not attempt to verify the identity of credit card users they will risk
their business relationship with the bank. Credit card fraud is far
too prevalent, DVDs are easily resold, and the bank wants to make sure
that they won't get defrauded. Blockbuster also wants to minimize
fraudulent use of credit cards (which they end up eating in some
instances) and the loss of their property (which will never be
returned by someone renting a video with a stolen credit card).
So, because of this, they're under tremendous pressure to look at some
form of identification to try to assure that the person presenting the
credit card is the legitimate owner of the credit card.
As an aside, businesses in European countries often do not operate
with the same sort of business models US companies have to deal with
in this regard. Many of them don't take credit cards at all, or only
started to in the last decade and are not yet suffering from the same
levels of fraud. In many instances, they are also legally constrained
from requesting government issued ID.
So, what is to be done? I would propose that the replacement of the
credit card infrastructure is needed. Fraud is prevalent because of a
massive inherent security flaw in the current system, to whit,
the account number is identical to the payment authenticator, and
you can make a payment merely through possession of a piece of stolen
A system in which the credit card was replaced by a small, calculator
style token with a smartcard style connector could effectively
eliminate most of the in person and over the net fraud we experience,
and thus get rid of large costs in the system and get rid of the need
for every Tom, Dick and Harry to see your drivers license when you
make a purchase. It would both improve personal privacy and help the
economy by massively reducing transaction costs.

@_date: 2005-07-08 12:19:38
@_author: Perry E. Metzger 
@_subject: Why Blockbuster looks at your ID. 
Yes. The only unusual point that I am making is that the lack of such
a system is precisely the reason why the clerk at the store often asks
for your ID when you make a purchase in the US. (The other major case
is alcohol or tobacco purchases, where, again, it is a question of
liability, but in this case, liability to the government which holds
you responsible if you do not check government issued IDs.)
Actually, the people who would have to pay the investment -- the banks
and merchants -- have an excellent incentive. The loss because of
fraud is stunningly large. The real issue is that *consumers* have
little incentive to cooperate with such a system, because thanks to
the regulations, they suffer virtually no losses if their accounts are

@_date: 2005-07-08 12:30:51
@_author: Perry E. Metzger 
@_subject: Why Blockbuster looks at your ID. 
I'm think you wrong on that one. Financial cost and benefit are easily
assessed on this, and I think the numbers add up. Credit card fraud
costs in the hundreds of billions of dollars a year, much of which
could be eliminated by a change to the sort of system I
mention. That's not a small amount of money. Indeed, it is more than
enough incentive for a major change.
The cost of deploying such a system has also gone down very
fast. Fifteen years ago, the hardware and communications costs would
have been prohibitively large. I believe that this is no longer the
So, in summary, with fraud costs extraordinarily high, and the price
of a new system falling, it would not take much time to amortize the
costs of a new system, after which every dollar saved is pure
profit. The incentive is now in place.
"Minimization" at the moment means accepting massive losses in the
system. The cost of deploying a better system would swiftly pay for
itself. I suspect that the time is finally right for such a thing.

@_date: 2005-07-08 13:16:13
@_author: Perry E. Metzger 
@_subject: Why Blockbuster looks at your ID. 
I seem to have gotten that one drastically wrong. Thanks for the
more accurate figures.
A back of the envelope calculation makes me think that it is still
more than enough money to provide a good incentive for a change in
systems, though, especially when the cost of the anti-fraud measures
needed at every part of the system are taken in to account.

@_date: 2005-07-08 14:36:53
@_author: Perry E. Metzger 
@_subject: Why Blockbuster looks at your ID. 
If you or anyone else has figures available, especially references to
original source material on the subject, it would be very useful.

@_date: 2005-07-08 14:52:30
@_author: Perry E. Metzger 
@_subject: payment system fraud, etc. 
I'm not sure I agree with that, and I'll tell you why.
Take the case of NAMPS cell phone fraud. At one time, phone cloning
was a serious problem. The main issue was that people could simply
listen in on call setup and get all the information they needed to do
phone fraud. Once strong crypto was used to authenticate mobiles with
the deployment of digital cellphone networks, mobile phone cloning
fraud didn't just shift around, it almost completely vanished.
I suspect that many of the credit card frauds in question would be
sufficiently hard to conduct on an industrial scale given the correct
replacement for the current system that it would be difficult for
criminal enterprises to sustain themselves off of the available
That system has a number of flaws in it, including the fact that it is
not an end to end cryptographically protected communication, and is
thus subject to credential theft and the customer PIN is exposed to a
reader provided by the merchant. I think with the right design, most
such issues might go away.
That is always the case, in any business. The question is, though, if
you could lower the fraud costs from a billion a year to a few tens of
millions a year with the expenditure of a half billion in equipment,
would that be worthwhile? I suspect that it might.

@_date: 2005-07-09 16:20:36
@_author: Perry E. Metzger 
@_subject: security infrastructure and government 
I believe John Gilmore once made a pithy comment about this
danger. Sadly I can't find the original quote, but it was more or less
something like this: if you give the government all the tools a
dictatorship would need to maintain control of the citizenry, all that
stands between you and a dictatorship is a change in attitude by the
people in power.
Another thing he or someone else once said went something like this:
you want to design your system of laws such that, with your worst
enemy in power, you will have no more to fear than if your best friend
is in power. This is because, someday, your worst enemy may very well
be in power.
If anyone remembers or can find the originals of these statements, I'd
appreciate it.

@_date: 2005-07-09 17:42:37
@_author: Perry E. Metzger 
@_subject: the limits of crypto and authentication 
Far better would be to have a token with a display attached to the
PC. The token will display a requested transaction to the user and
only sign it if the user agrees. Because the token is a trusted piece
of hardware that the user cannot install software on, it provides a
trusted communications path to the user that the PC itself cannot.

@_date: 2005-07-09 19:36:50
@_author: Perry E. Metzger 
@_subject: Why Blockbuster looks at your ID. 
If you have a sufficiently good token, you may no longer need to have
identification information presented to the merchant, even by the
token, to reduce misuse. It is true that the issuer will still know
what transactions took place. However, you have at least reduced the
number of entities that require proof of your identity and the number
that have logs of your activity.

@_date: 2005-07-10 00:27:51
@_author: Perry E. Metzger 
@_subject: EMV 
The contactless systems provide almost zero added user
convenience. They're a nice marketing hack by the RFID crowd, but
nearly nothing more. Users do not mind withdrawing a token from their
wallet and inserting it momentarily into a reader.
However, the contactless systems also provide a nice new mechanism for
fraud, and with the increasing feasibility of phased array systems,
that fraud may soon be possible at considerable distances.
So, we've gained very little, other than a nice new app for RFID (RFID
being a large scale solution waiting for problems), but at the same
time we've lost quite a bit.

@_date: 2005-07-10 00:29:55
@_author: Perry E. Metzger 
@_subject: the limits of crypto and authentication 
The Blue Card, so far as I can tell, was poorly thought out beyond its
marketing potential. I knew some folks at Amex involved in the
development of the system, and I did not get the impression they had
much of a coherent idea of what the technologies would be used for
other than creating marketing buzz.

@_date: 2005-07-10 11:48:51
@_author: Perry E. Metzger 
@_subject: the limits of crypto and authentication 
That could be fixed. I think the right design for such a device has it
only respond to signed and encrypted requests from the issuing bank
directed at the specific device, and only make signed and encrypted
replies directed only at the specific issuing bank. If anything in
between can tamper with the communications channel you don't have the
properties you want out of this.
Given such a structure, however, you can know when the device displays
"Pay 53.22 euros to amazon.fr for book X" that this is precisely the
transaction you are authorizing, and that the communication will
not authorize any other transaction, its interception will not permit
the authorization of any other transaction, and no replay of the
transaction is possible.
However, you need both the end to end communication and the hardware
token with built in display and keyboard.

@_date: 2005-07-12 09:54:51
@_author: Perry E. Metzger 
@_subject: the limits of crypto and authentication 
Tedium is something that computers do very well. They don't care about
how much work they have to do. The only issue is whether we induce too
many serialized public key operations, and thus too much delay.
Yup. I want that for a variety of reasons.
That's the case already. Only the issuing bank knows if the account
has any credit left in it, after all.
We used to live in an era where offline transactions were
important. Now that you can get online literally anywhere, and now
that merchants pretty much are required to check card validity and
funds availability online anyway, that's no longer an interesting
concern. I can't think of the last time I was involved in an offline
transaction -- even folks at street fairs can now afford GPRS and
similar communications for their veriphone (and similar) units.
It sounds right to me, because it puts the trust relationships in all
the right places. The merchant trusts the accepting bank that it will
be paid. The accepting bank trusts the card network, the card network
trusts the issuing bank. The issuing bank and cardholder have a
bilateral relationship, too. If we keep the cryptographic exchanges
purely in correspondence with the trust relationships, and we get rid
of reliance on third party certification of public keys entirely, we
also fix most of the trouble in the system.
By the way, I note as an aside that this also means (in my opinion)
that certificates are no longer an interesting technology for
payments protocols, because in a purely online environment, you
never need a third party x.509 certificate in the course of the
payments protocol itself when there are no offline components of the
protocol and all relationships are bilateral.
The overwhelming disadvantage is deployment complexity, but given
deployment (ha, what an assumption on my part!) the system would work
very cleanly indeed.
The user would not have to worry about his PC being infected or his
merchant deploying a dishonest terminal (though theft of a token +
beating the PIN out of the user would still be an issue). By not
responding to requests that do not come from the issuing bank
specifically encrypted for the token, you reduce (though of course not
eliminate) the possibility of side channel attacks or inducing buffer
overflows and such in the token, as well as depriving intermediate
entities of privacy damaging information. The issuing bank would not
have worry about the origin of the token's signature -- it could be
reasonably assured that, short of physical attacks on the tokens
(which would happen but be infrequent), the signature came from the
token, and no information that would permit independent payment
authorizations has been left with the merchant or card processor.
Overall, I think such things are a win.

@_date: 2005-07-12 13:24:42
@_author: Perry E. Metzger 
@_subject: the limits of crypto and authentication 
Ah, I see what you mean.
Sadly, I don't think there is much to be done about that, but I think
that (personally) I'd only end up with two of the things. If they can
be made credit card sized, I don't see this as worse than what I have
to carry now.
Anonymity is a concern to me, too, but I suspect that it is hard to
get anonymity in a credit card transaction using current means, even
if the merchant isn't online. Pseudonymity, perhaps.

@_date: 2005-07-12 15:03:57
@_author: Perry E. Metzger 
@_subject: the limits of crypto and authentication 
I think that by eliminating the need for a merchant to learn
information about your identity I have aimed higher. Given that we're
talking about credit instruments, however, it may be difficult to
eliminate the need for the issuer to track transactions. However,
given the way I've described the protocol, it would be possible to use
a variant on it for digital cash purses without the merchant being
impacted. It isn't clear to me, though, who would issue such things in
the current environment.

@_date: 2005-07-13 12:15:48
@_author: Perry E. Metzger 
@_subject: ID "theft" -- so what? 
I tend to agree. It is equally ridiculous to use a credit card account
number as the "secret" to authorize a transaction, since that "secret"
has to be given out several times a day.
Again, yes.
However, I would like to make one small subtle point. In fact, what
you are complaining about is not the use of identification for
authorization -- that is a totally separate and equally sad discussion

@_date: 2005-07-13 12:26:52
@_author: Perry E. Metzger 
@_subject: mother's maiden names... 
A quick question to anyone who might be in the banking industry.
Why do banks not collect simple biometric information like photographs
of their customers yet?
If I walk into a branch complaining that I've been robbed and that I
don't have my bank card any more, the branch manager will look at some
externally generated credential (like a driver's license) and ask me
something like my mother's maiden name. Of course, my mother's maiden
name is widely available in public records, and bank clerks aren't
well trained in identifying forged licenses (though presumably they
are rare).
Why is it, then, that banks are not taking digital photographs of
customers when they open their accounts so that the manager's computer
can pop up a picture for him, which the bank has had in possession the
entire time and which I could not have forged? Heck, that would also
provide a secondary check for a teller when processing an in-person
transaction -- the customer's picture could just come up as soon as
you open their account and you could eyeball them. Digital cameras are
also pretty cheap, and opening an account is a sufficiently tedious
manual process that another few seconds would make no practical
difference to the customer or bank employee.
My guess is that the reason is a) they've never done things this way
before and b) fraud rates are low enough that they haven't had the
However, I think it is something people might want to consider in
designing security systems for institutions like this. Photographs,
iris scans, fingerprints, etc. are all awful ways of handling
identification over the internet, but they work very nicely if they
can be checked in person by someone. If you need to have a good sense
that you are in fact talking (in person) to the real customer, a
picture and/or digitally stored fingerprints collected when the
account was opened seem like a simple and cheap way of improving

@_date: 2005-07-13 21:15:15
@_author: Perry E. Metzger 
@_subject: Stuart Baker, ex NSA general counsel, gets Homeland Security post 
Many of you may remember Stuart Baker from the crypto export policy
wars. I still remember him telling me in a conversation after a New
York Bar Association debate on the subject that the Internet would
never be of any economic importance. Anyway, without further comment:
   The President intends to nominate Stewart A. Baker, of Virginia, to be
   an Assistant Secretary of Homeland Security (Policy). Mr. Baker is
   currently a Partner with Steptoe & Johnson, LLP in Washington, D.C. He
   previously served as General Counsel for the Commission on the
   Intelligence Capabilities of the United States Regarding Weapons of
   Mass Destruction. Prior to that, Mr. Baker served as General Counsel
   for the National Security Agency. Earlier in his career, he was a law
   clerk for Justice John Paul Stevens, U.S. Supreme Court. Mr. Baker
   received his bachelor's degree from Brown University and his J.D. from
   the University of California, Los Angeles.

@_date: 2005-07-13 18:52:25
@_author: Perry E. Metzger 
@_subject: ID "theft" -- so what? 
Who said PK_I_? I only mentioned P_K_. There is no need for an _I_
here -- a public key stored at the bank in a database is sufficient,
without any certificates at all. The token can store the bank's key
without any need for a cert, either. Neither needs to check the
"certification" of such keys -- the mere presence of the key in the
correct part of storage indicates it is valid, the same way that a
.ssh key file needs no certification, only existence.

@_date: 2005-07-14 09:02:57
@_author: Perry E. Metzger 
@_subject: mother's maiden names... 
That's true. Several banks I deal with in New York use displays that
are disturbingly 3270-like. That brings up another thing that has
always tickled the back of my mind -- I have never actually had a
professional opportunity to analyze any of the systems used by tellers
in commercial banks, and I always wonder at what is securing the links
between small branches and HQ, and how bad the protection of the user
passwords etc. might be...
Yah, true enough -- which also impedes things like letting branch
managers to look at check images, signatures, etc. Groan...

@_date: 2005-07-14 09:19:28
@_author: Perry E. Metzger 
@_subject: ID "theft" -- so what? 
Actually, I wasn't proposing that. I was just proposing that a private
key be the authenticator for payment card transactions, instead of the
[name, card number, expiration date, CVV2] tuple -- hardly a
revolutionary idea. You are right, though, that I do not propose that
any PK_I_ be involved here -- no need for certs at all for this
I don't claim this is a remotely original idea, by the way. I'm just
flogging it again.
"Root Cause of the Problem" isn't correct either. It is better to say
that PKI doesn't solve many of the hard problems we have, or, in some
cases, any problems -- it doesn't per se cause any problems, or at
least not many.
This is not a "new realization" -- this goes back a long way.
People were saying PKI was a bad idea a decade ago or more. A number
of the people here, including me, gave talks on that subject years
ago. I spoke against PKI during the debate I was invited to at the
Usenix Electronic Commerce Workshop in 1998 or so, and at many
opportunities before and since. Dan Geer has a pretty famous screed on
the subject. Peter Gutmann talks about the follies of X.509 so often
it is hard to keep up. I don't mean to single us out as visionaries --
we were just saying things lots of other people were also saying.
Honestly, where have you been?
I can smell the rest of this discussion right now, Ian. You'll
misunderstand the constraints the browser people are under, and start
claiming SSL is bad (or unnecessary) about 20 seconds after that. I'm
not playing the game.

@_date: 2005-07-14 09:23:10
@_author: Perry E. Metzger 
@_subject: the limits of crypto and authentication 
Some of it was, yah. I don't claim that any of this is original. The
problem with SET was that the protocol was far too complicated to
implement (hell, the spec was nearly too heavy to lift), and it was
proposed well before people even had USB connectors on their
computers, let alone cheap USB card interfaces. I think people threw
out the baby with the bathwater, though. The general idea was correct.

@_date: 2005-07-14 12:36:35
@_author: Perry E. Metzger 
@_subject: the limits of crypto and authentication 
You are perfectly right on this. I oversimplified and distorted.
Still, I suspect that while the time was not right for SET back then,
the time may nearly be right for better things now.

@_date: 2005-07-14 12:54:21
@_author: Perry E. Metzger 
@_subject: ID "theft" -- so what? 
No, it isn't a new realization either, Ian. We all knew from nearly
the start that the model we were using in browsers was wrong. I don't
know anyone who defends it. Netscape threw SSL together in a hurry --
so much of a hurry that the first version of the protocol wasn't even
any good -- and threw a bunch of certs right into the browser to
bootstrap it, and no one has particularly liked the situation ever
That doesn't mean that people are interested in throwing the baby out
with the bathwater, either, as you have in suggesting that people
should just send credit card numbers in the clear because passive
interception is (you have claimed) not an issue.
I am unaware of real security professionals who hold that opinion or
ever held it, or even a variation on it. Perhaps there are a handful
out there, but it isn't the majority.
Again, you are telling people what they already know.

@_date: 2005-07-14 16:08:33
@_author: Perry E. Metzger 
@_subject: Blind Signature Patent Expiration Party this Saturday 
Forwarded at Lucky's request:
Friends, colleagues, and co-conspirators,
It has been 17 long years and now the time is finally here to celebrate at
BLIND SIGNATURE PATENT EXPIRATION PARTY
A party to celebrate the expiration of the Blind Signature patent.
U.S. Patent 4,759,063 ("Blind Signature Systems") to David Chaum is the
core invention enabling privacy-protecting electronic payment systems and
credentials.  It was a truly ingenious, ground-breaking contribution.
Unfortunately the existence of the corresponding patent, which was
notoriously difficult to license, prevented this great invention from
receiving the wide use that it so very much deserved. For a copy of the
patent, see Unlike copyrights these days, patents do expire.  The blind signature
patent will expire on July 19, 2005, next Tuesday.  Since weekends tend to
fit better with the schedules of potential party goers than weekdays, we
are holding the party this Saturday instead.
The 17 years that this patent has been in effect has been an awfully long
time for the many of us that hoped to make use of this technology to help
citizens to maintain privacy in the age of the Internet and the patent's
expiration is a much overdue reason for celebration.
If you know what blind signatures are you are invited.
This Saturday, July 16, starting at 1:00 PM PDT
Since the number of inquiries I received in response to the party
pre-announcement exceed the maximum occupancy limit of my home and since
the weather promises to be excellent, we will hold the party in a beer
garden instead. Drinks are on me!
We will meet at the
Alpine Inn (aka Alpine Beer Garden)
3915 Alpine Road, Portola Valley, CA 94028 USA
Those that can demonstrate that they have created a full system that makes
significant use of the blind signature patent by 4 PM on Saturday will be
invited to and receive a free dinner at the afterparty. So get coding!
(Pr0duct Cypher, where are you)? A team of judges will determine if a
particular system qualifies for the award.
A handful of us plan to have dinner at a swanky restaurant on patent-free
Tuesday. Email me or talk with me at the party if you are interested in
joining. Space is limited. You will have to pay for your own food at the
Tuesday dinner unless you qualify for the award above or your name is on
the blind signature patent.
Looking forward to see you all this Saturday,

@_date: 2005-07-19 16:52:51
@_author: Perry E. Metzger 
@_subject: ADMIN: list server move... 
The list has just moved from one mail server to another. No one should
notice anything, but if anyone does, please send me mail.

@_date: 2005-07-22 13:35:29
@_author: Perry E. Metzger 
@_subject: [Clips] Credit Data Firm Might Close 
Seems reasonable to me...
That implies that they had a choice about coming forward, and that
they heroically did so and are being punished for it. In fact, they
screwed up horribly, hid this screwup from auditors (or somehow passed
the audit anyway without the auditors discovering the screwup -- which
is unclear) and then were forced to come forward with the fact that
their screwup was exploited by bad guys. Other firms will not "Thing
twice about disclosing such attacks" because as a matter of law,
contract and fiduciary responsibility they had no choice. I doubt they
wanted to tell people what had happened -- they were forced to -- and
they should not get points for simply following their legal
It seems to me that, without fear that failing to live up to their
fiduciary responsibilities will result in the destruction of their
livelihoods, there is no incentive for people to do the right
thing. Mr. John M. Perry should be happy that he is only losing his
job and likely the ability to get another one like it -- he could be
going to jail instead. If he and his employees had merely done their
job, as they were obligated to do by contract, nothing bad would have
happened to them. It is not "draconian" to be forced out of business
for revealing the confidential financial information of FOURTY MILLION
PEOPLE because you not only failed to secure your systems but also
deliberately disobeyed your contractual obligation not to store
cardholder data so that you could do data mining.
Seems like a reasonable opinion on the part of Visa. I'm frankly
shocked that they are doing the right thing here -- I was expecting
they'd gloss over the whole thing. Good for them!
Hmm. Interesting. The Corporate Death Penalty -- the bad company being
driven out of business -- is apparently not enough. We need to pass
more laws so we can show we really mean it!

@_date: 2005-06-01 08:04:18
@_author: Perry E. Metzger 
@_subject: "SSL stops credit card sniffing" is a correlation/causality 
message of "Wed, 1 Jun 2005 14:49:27 +1000")
That might not be such a bad thing. Object lessons have a way of
whipping people in to shape. A few more heads rolling might convince
others that security isn't optional.
In the late 1960s, several major brokerage firms went under because
they didn't have their accounting systems sufficiently automated. The
people on the business people thought of I.T. as a necessary evil
rather than as the backbone of their business, and they paid the
At intervals, business gets major accounting scandals, about every 20
to 40 years when people forget about the last set. I suspect
I.T. crises are similar. It has been so long since the last one
happened in the financial industry that the institutional memory of it
is now gone, so we're ripe for another.
It is my prediction that we will, in the next five years, get the
failure of a couple of international financial institutions because of
insufficient attention to systems security, again because there are a
few executives in the business who do not understand that I.T. is not
an expense that needs managing but rather the nervous system of the

@_date: 2005-06-03 12:44:50
@_author: Perry E. Metzger 
@_subject: Bluetooth cracked further 
Cracking the Bluetooth PIN
  This paper describes the implementation of an attack on the Bluetooth
  security mechanism. Specifically, we describe a passive attack, in
  which an attacker can find the PIN used during the pairing process. We
  then describe the cracking speed we can achieve through three
  optimizations methods. Our fastest optimization employs an algebraic
  representation of a central cryptographic primitive (SAFER+) used in
  Bluetooth. Our results show that a 4-digit PIN can be cracked in less
  than 0.3 sec on an old Pentium III 450MHz computer, and in 0.06 sec on
  a Pentium IV 3Ghz HT computer.

@_date: 2005-06-03 12:55:25
@_author: Perry E. Metzger 
@_subject: Bluetooth cracked further 
I realized I didn't mention the really evil part.
1) They can crack your security if they can listen in to the pairing
   communication.
2) They also have a way of forcing pairing to happen, by impersonating
   one of the devices and saying "oops! I need to pair again!" to the
   other.
If you have a pair of bluetooth devices that are paired, best to keep
them in a faraday cage at all times.

@_date: 2005-06-03 14:21:52
@_author: Perry E. Metzger 
@_subject: Bluetooth cracked further 
That is my understanding. Ugly, isn't it?
Given the nature of this new attack, it probably doesn't matter.

@_date: 2005-06-07 19:48:22
@_author: Perry E. Metzger 
@_subject: encrypted tapes (was Re: Papers about "Algorithm hiding" ?) 
That's a pretty weird view on several levels.
1) There is a substantial reward in not having one's client data
   compromised.
2) The cost in question is so small as to be unmeasurable.
You keep speaking, Ian, about economic tradeoffs, as though there were
a cost/benefit analysis at work here. The truth is, the likely reason no one encrypted the data on the tapes
in transit was because no one thought to do it, or they were too lazy
to bother to make even the simplest effort, or both.
I don't disagree that security often involves cost benefit
tradeoffs. Do you have a human watch a security camera in real time,
or simply record its output? Do you permit external access on people's
own computers, or force them to use vetted devices for external access
that they cannot reconfigure? Do you run Windows on the DMZ
application server because it is easier, or a much more secure OS that
does not have as rich an application set?
Those are complicated situations with real tradeoffs. There is lots of
debate you can have about them. They're not trivial situations.
However, you keep mentioning completely *bogus* tradeoffs. Your
constant stream of comments to the effect that "security is a cost
benefit tradeoff" with respect to things like using SSL or encrypting
tapes or what have you would make some sense if there were, in fact,
measurable cost involved, or of the benefits were distant and
The benefits, however, are very obvious and large, and the cost is as
close to nil as anything gets in business.
I understand the point you keep making, but it is not an interesting
point, and not even close to correct so far as I can tell.
Oh, good. Then I can't use tar for most of the purposes I use it for
day to day, and all so I can avoid having to put one more command in
the pipeline. No thank you.
You want to understand the real problem in security? It isn't your
constant mythical attention to "cost". It is human stupidity.
Have a look, for example, at which encourages users to type in their credentials, in the clear,
into a form that came from lord knows where and sends the information
lord knows where. Spoof the site, and who would notice?
Every company should be telling its users never to type in their
credentials on a web page downloaded in the clear, but American
Express and lots of other companies train their users to get raped,
and why do they do it? Not because they made some high level decision
to screw their users. Not because they can't afford to do things
right. It happens because some idiot web designer thought it was a
nice look, and their security people are too ignorant or too powerless
to stop it, that's why.
It has nothing to do with cost. The largest non-bank card issuer in
the world can pay for the fifteen minutes of time it would take to fix
it by putting the login on a separate SSL protected page. It has
nothing to do with "ease of use" or tools that default "safe". The
problem is that they don't know there is anything to fix at a level
of the firm that is capable of taking the decision to fix it.
Security these days is usually bad not because good security is
expensive, or because it is particularly hard. It is bad because even
people at giant multinational corporations with enough budget to spare
are too dumb to implement it.
We don't need more encryption algorithms, or replacements for SSL, or
fascinating new tools. What we need is more common sense.
No amount of new, user friendly, defaults-to-safe tools will prevent
American Express, Citibank or anyone else from doing something
idiotically dumb.
In case you think the answer is regulation, by the way, let me note
that most of the regulatory pressure I've seen on security policy
results in people finding extremely well documented ways to do exactly
what the regulators ask, to no actual effect. This is generally
because the regulators are almost uniformly as dumb or dumber than the
people they regulate.
The only thing that will fix this having enough people get so badly
burned that CEOs start taking heads when people do dumb things. I
imagine it can't be too many more years before that becomes the case.

@_date: 2005-06-08 09:56:59
@_author: Perry E. Metzger 
@_subject: AmEx unprotected login site 
I'm surprised that they responded to you. I tried to get to respond to
my inquiries about it for weeks without any success.
I did get a nice letter from JP Morgan Chase telling me I was crazy
and that there is no security problem on their site (which suffers
from the same problem). I probably should publish it to assure the
dismissal of the people responsible for sending it to me.
Well, those "business reasons" are pretty obviously an incorrect
balance of security and convenience, as I'm sure you would agree. The
inconvenience of having to click one more button to get to your
account is minimal -- almost unmeasurably small. The inconvenience of
the company having to explain to tens of thousands of people that
they've screwed them badly, along with all of the money lost, is
substantially higher. One day they'll be paying that second
Many other financial institutions get this right, by the
way. Citigroup gets this right. If their customers can click onto
another page, so can customers of American Express, Chase, etc.
I don't agree. I think this is still a case of human frailty causing a
security problem, rather than some sort of technological issue.
If you know what the problem is and you decide not to do anything
about it because you believe that "for business reasons" you shouldn't
put the login on a separate page, you've got nothing to blame for your
future security problems other than yourself.
My point is simple. We have enough protocols, software, etc. to avoid
most of the security issues we have to deal with at this point. Most
of the remaining problem tends to be human beings. In this case, the
human beings security people who know better but give in when
management decides for what amounts to aesthetic reasons that it needs
a login on the front page that isn't protected by SSL.
I disagree. I'll stand by most of what I said.
And they are indeed training their users to enter in security
credentials on unsecure pages.
And if in this one case it turns out that they did indeed make a high
level decision to screw their users, so much the worse.

@_date: 2005-06-08 10:01:54
@_author: Perry E. Metzger 
@_subject: encrypted tapes 
Why is it a problem? Because the http post method you're relying on
could have come from anyone -- you're just assuming that it posts to
Amex's site.
How often do users hit ^U and read the source on the front page of a
site like this? Never, for practical purposes. Unless you're looking
at the code every time, you have no idea where your form data gets
posted. It could be a server in Moldova instead of Manhattan.
You have no idea where the page came from, and thus you have no idea
where the post method will send your data. You assume it came from
American Express, but it may very well have come from people
attempting to crack your account who used DNS cache contamination or
other techniques to get you to talk to their server. Even plain old
man-in-the-middle interception and modification would work for this,
though it is harder to do unless, say, the victim is using the
wireless at Starbucks or an airport or what have you, in which case it
is trivial.

@_date: 2005-06-08 10:17:07
@_author: Perry E. Metzger 
@_subject: encrypted tapes 
It isn't much of a challenge. In several cases, the cost of
implementing backup encryption was much cheaper for my customers than
the cost of the time it took me to explain to them that they needed it

@_date: 2005-06-08 12:14:33
@_author: Perry E. Metzger 
@_subject: encrypted tapes 
It is worse than that. At least one large accounting company sends new
recruits to a "boot camp" where they learn how to conduct "security
audits" by rote. They then send these brand new 23 year old "security
auditors" out to conduct security "audits", with minimal supervision
from a partner or two. The audits are inevitably of the lowest
possible quality -- they run automated security scanners no better
than open source ones you could download on your own, and they run
through checklists.  If an automated tool doesn't say there is a
problem, or if you obey the mindless checklist items, you pass.
Of course, for all the good such an "audit" does, you would as well
roll dice and claim that the output was somehow correlated with the
quality of your security infrastructure. Such an "audit" is totally
worthless except as a bureaucratic dodge. "We hired a world class
accounting company to check our security!" the executives can cry, "so
these security problems aren't our fault!" (Would that "fiduciary
responsibility" was not so often equated with "make sure there is
enough window dressing that we can't be blamed.")
By the way, selling such "audits" is extremely profitable, given the
discrepancy between the pay for the kids doing the audits and the
price the customer is charged. What is pathetic is not that companies
would try to foist such worthless services upon their customers, but
that their customers would willingly buy.
Incidently, my understanding is that at least some accounting
companies use similar techniques for doing audits of the bookkeeping
practices at their customers, which makes them at least somewhat
consistent, if nearly useless to relying parties. When you hear things
to the effect that accounting audits can only detect unintended bad
process and not deliberate malfeasance, that's part of the reason why.

@_date: 2005-06-08 15:16:29
@_author: Perry E. Metzger 
@_subject: AmEx unprotected login site 
They're still doing the wrong thing. Unless the page was transmitted
to you securely, you have no way to trust that your username and
password are going to them and not to someone who cleverly sent you an
altered version of the page.

@_date: 2005-06-08 19:01:37
@_author: Perry E. Metzger 
@_subject: AmEx unprotected login site 
That's why Citibank and most well run bank sites have you click on a
button on the front page to go to the login screen. There are ways to
handle this correctly.
The other major offender are organizations (such as portions of
Verizon) that subcontract payment systems to third parties. They are
training their users to expect to be directed to a site they don't
recognize to enter in their credit card information. "Really! This is
your vendor's payment site! Pay no attention to the URL and
That one in particular takes amazing brains...

@_date: 2005-06-08 21:16:03
@_author: Perry E. Metzger 
@_subject: AmEx unprotected login site 
Certainly, but at least then, the URL and the certificate won't point
at Amex (or whomever). If you train your users properly, then they can
avoid trouble even then.
In the current case, by the time you see that there is a problem, it
is too late. Furthermore, you're training your users to engage in a
bad behavior. This is no different than Microsoft training their users
to mindlessly open .exe files for years and years, only to reap the
whirlwind when email viruses came along.
The right behavior to encourage for people is "never enter in your
userid and password for an important account on a page that you don't
trust". They're training people to do the opposite.
They could delegate a "payments.verizon.com" DNS entry and hand the
processor a "payments.verizon.com" certificate, with an expiry date
quite similar to the date when their contract is up for renewal.
I'd like to make my position on one thing here really clear, by the
Since when is it considered acceptable to slack on fiduciary
responsibility on the excuse that it is annoying and requires effort?
No one would accept a bank saying "accounting is boring, and hard to
do right, so we aren't going to keep track of your balance very well
any more." No one would accept "we've decided that paying for a proper
vault is expensive, so we're keeping your safe deposit box in the mens
room." How is proper network security any different? This is a
BANK. Keeping your money secure is what they are paid to do!
Yes, it takes thought, planning, and some skill to have online
security for a financial institution, but no one is obligated to own
or run a bank. If you run a mortuary, you will have to deal with
corpses. If you run a bank, you have to be mindful of security in
handling money.
As for merchants like Verizon, there is really no excuse for a
for being unable to figure out how to process online credit
card payments safely, whether on their own or through a contractor. No
one obligates them to be in business, but if they're going to be, they
have a duty to do things like keeping accurate customer accounts,
paying their taxes, keeping track of who their shareholders are, and,
yes, making sure that they deal with credit card acceptance
non-hazardously. I know it is all a pain in the ass, but if one wants
an easier life, one should be a subsistence farmer instead of a
multinational corporation.
Sure, I'd love not to have to deal with the annoying things I have to
deal with, and I'd love not to have to pay my mortgage on time, and
I'd love a pony and a mountain of gold. I'm an adult, though, so I
accept that I can't have everything I want and I need to fulfill my
obligations. Are we to expect less of AMERICAN EXPRESS? Of VERIZON?
That's a non-starter as far as I'm concerned. If you want to have
a life of excuses, you don't get to play with the grownups.

@_date: 2005-06-08 21:31:24
@_author: Perry E. Metzger 
@_subject: encrypted tapes 
In this case it is. As I've said, even having all your tapes for six
months at a time use the same key is better than putting the tapes in
the clear.
If you have no other choice, pick keys for the next five years,
changing every six months, print them on a piece of paper, and put it
in several safe deposit boxes. Hardcode the keys in the backup
scripts. When your building burns to the ground, you can get the tapes
back from Iron Mountain and the keys from the safe deposit box.
No, it isn't ideal, or even very good, but it is a whole lot better
than what most people do now. You aren't safe from a real attacker,
but you're safe from someone that gets their hands on a box of tapes,
and that's way better than nothing.
Good requires a lot more work, but stupid and better than nothing
takes very little. There is little excuse for not doing *something*.
Er, no. An error in CBC wipes out only the following block. Errors do
not propagate past that in CBC. This is not especially worse than the
situation right now.
However, all of that is immaterial if you're using a tape drive that
compresses, because then you really are screwed if you lose a block,
encryption or not. Most backups are currently done compressed (which I
have to say I think is a bit of a mistake, even if it does save

@_date: 2005-06-09 09:25:19
@_author: Perry E. Metzger 
@_subject: AmEx unprotected login site 
If the merchant site is secured by SSL, and prominently says that you
will be redirected to a given provider, it is perhaps not so bad in
theory. However, in practice, this fails the "simple rules my mom can
follow" test. I'd rather that they hand a short term cert and DNS
delegation to their processing partner.
What I want to be able to do is tell my mom something dead simple,
like "never enter your username and password or credit card
information unless the web page is the one you are expecting, and it
has the "lock icon" in the corner and the lock icon doesn't look like
someone was faking it."
Now, we face two major problems here.
1) Every complication you add on top of that means that you're
training lots and lots of very naive users to do things that are
potentially unsafe. Training users to expect to do unsafe things (like
what Amex or what Verizon are doing) is bad, because then they won't
notice in the future when they are asked to do something unsafe by a
bad guy. Fidelity, to my mind, is a model of good user training. They have a
set of very good web pages (see
and others) that give users excellent advice on never entering
passwords in on pages that didn't arrive encrypted, never emailing
personal information, etc. They allow customers to avoid ever exposing
social security numbers to customer service reps, encourage users to
use those services, etc. Their login page itself comes SSL
encrypted. There may be other security problems they have, but
encouraging users to do unsafe things isn't one of them.
Now, here they (and I and others) go, trying hard to educate users
about what the right thing is, and others go around forcing users to
do the wrong thing just to get their day to day business done! After a
while, people's defenses drop because they're being constantly trained
to do the wrong thing.
2) The other issue is that the browser accepts certs from so many CAs,
many of which have effectively no security. There are ways to fix this
long term, but that is a whole separate discussion.

@_date: 2005-06-09 09:28:49
@_author: Perry E. Metzger 
@_subject: AmEx unprotected login site 
When I go to the SSL protected page, I can look at the URL and the
lock icon in the corner before typing in my password. When you type in
your password BEFORE the SSL connection, by the time you realize that
it went to the wrong place, it is way too late.
I admit that not everyone will check the URL and the lock icon, but at
least it is *possible* to train people to do the right thing on
that. There is no way, effectively, to train people to be safe given
the way that Amex is set up.

@_date: 2005-06-15 08:00:46
@_author: Perry E. Metzger 
@_subject: NIST Public Workshop on Cryptographic Hashes 
A vulnerability was recently identified in the NIST-approved    cryptographic hash algorithm, Secure Hash Algorithm-1 (SHA-1). In    response, NIST is announcing a public workshop to discuss this    vulnerability, assess the status of other NIST-approved hash    algorithms, and discuss possible near- and long-term options.
   The workshop will be held on October 31 and November 1, 2005,    from 9 a.m. to 5:30 p.m.

@_date: 2005-06-17 11:20:39
@_author: Perry E. Metzger 
@_subject: US DoJ wants ISPs to be forced to log their customers activities 
The U.S. Department of Justice is quietly shopping around the
   explosive idea of requiring Internet service providers to retain
   records of their customers' online activities.

@_date: 2005-06-17 16:46:24
@_author: Perry E. Metzger 
@_subject: AES cache timing attack 
Sadly, it is very hard to avoid chosen plaintext attacks in the real
Consider, for example, the various new wireless security protocols
that have been proposed. For many of them, it should be simple to send
chosen data from the internet to a machine on the wireless network. No
established connection is needed -- you don't care if it rejects the
packets, only that the router sends them -- and if you are in a
position to listen in so you can exploit the stolen key, you are also
in a position to capture as much ciphertext resulting from the chosen
plaintext as you like. Adaptive attacks are quite straightforward in
this scenario.
This is only one of a number of instances in which it is fairly
straightforward to inject data in the real world. Lots of VPN
scenarios make it possible.
I'd say we should probably be thinking of ways to make sure that AES
implementations are safe from this kind of attack.
PS Credit where credit is due -- the wireless network example came
from Thor Simon.

@_date: 2005-06-21 22:38:42
@_author: Perry E. Metzger 
@_subject: AES cache timing attack 
I gave an example yesterday. Perhaps you didn't see it.
The new 802.11 wireless security protocols encrypt the on-air portion
of communications, and are typically attached to ethernet bridges. If
you want to, you can send any packet you like at an arbitrary box on
the wireless segment from the main network, and have the wireless
router act as a fine quality oracle for you for the AES key being used
on air.
It would be possible, though perhaps less convenient (since it would
require tapping rather than just listening) to do something similar to
a wide variety of VPN protocols.
You don't need to in the above instances. You just need to be able to
People like to downplay the impact of attacks like this, but there are
just too many scenarios "one didn't think of" in the security
universe. Doubtless some other usage cases may get badly bitten by AES
side channel attacks.

@_date: 2005-06-23 22:42:44
@_author: Perry E. Metzger 
@_subject: Some companies are just asking for it. 
My girlfriend just got an (apparently legitimate from what I can tell)
HTML email from her credit card company, complete with lots of lovely
images and an exhortation to sign up for their new secure online
"ShopSafe" service that apparently generates one time credit card
numbers on the fly.
Here's the text:
The sales pitch then invites you to click on the link in the email to
Clicking on the link, of course, asks you to enter information that
you should never, ever, EVER enter after clicking on a link you got in
email. So, here is official mail from a credit card company, actively
training its users to become future victims of phishing. The irony of
being exhorted to do this in the name of getting the "ShopSafe
service" is not a small one, either. I wouldn't be surprised if near
identical emails with the exact same pitch started showing up within
hours or days, only the site they link to may be a wee bit less
The security department and management at the firm responsible should
be taken out behind the shed and put out down, before they hurt anyone
else. The marketing department will, of course, demand to do stupid
things, but it is the responsibility of the security department and
management to tell them "No, we will not train our users to be raped
by phishers, no matter how many `click throughs' it generates."
Oh, and what companies are involved? The card is Fidelity branded, but
it is really an MBNA production, with online marketing and card
servicing (like this piece) being done by Individualized BankCard
Services. One would think that everyone in question would know better,
but sadly they don't.

@_date: 2005-06-23 23:47:39
@_author: Perry E. Metzger 
@_subject: Some companies are just asking for it. 
The fact that others do laughable things doesn't make their
practices any less laughable. Stupid things remain stupid no matter
how widespread the stupidity might be.

@_date: 2005-06-24 14:28:13
@_author: Perry E. Metzger 
@_subject: Some companies are just asking for it. 
I got a very nice communication from a person at Fidelity Investments
wanting to make sure that this was from the (unrelated) Fidelity Bank,
and not something that they had done. It is indeed a Fidelity *Bank*
branded credit card, not a Fidelity *Investments* card. The two
organizations are entirely unrelated and just happen to share a name.
For the record, the guys at Fidelity Investments have always seemed to
me to have their act together on security, unlike lots of other
places. They have excellent FAQs for their users on what is and what
is not safe to do in a web browser, they only allow logins from pages
that are downloaded with SSL, etc. The fact that someone there was
worried when I sent out my mail and got in touch with me to check
only confirms for me the feeling that they seem to try hard to do
their jobs right...

@_date: 2005-03-09 08:19:19
@_author: Perry E. Metzger 
@_subject: comments wanted on gbde 
Charlie asked me to forward this.
Sent: Tuesday, March 08, 2005 12:46 PM
My biggest complaint with the cryptographic design is that it is overly
complex for no good reason. Adding extraneous complexity is much more
likely to introduce security problems than to mask them, but it seems
unlikely that it did so in this case.
This design is likely plenty secure for realistically expected uses.
The paper acknowledges the "cleaning lady copy attack", where periodic
copies are made and differences noted. In this case, the attacker can
identify the sectors that were updated. With these patterns, it is
likely no security is gained by the complex rearranging of sectors in
the algorithm. But this was only a backup mechanism anyway.
The three most serious "room for improvement" areas I could find are:
1) There is no integrity check on the encrypted sectors. An attacker can
therefore make modifications to the data that the user will not detect
cryptographically. Since CBC mode is used on individual sectors, an
attacker can make a predictable change to a chosen block if he accepts a
random change to the following block. One can imagine (with a good
imagination) the ability to patch a block of a program to behave in an
insecure way.
2) The paper notes that someone who knows an old passphrase (and has
access to a small amount of old data) will be able to read the disk.
This largely negates the value of periodically changing the passphrase.
The straightforward solution of decrypting and reencrypting the entire
disk when the passphrase changes is noted as having unacceptable
performance. An alternative whose performance might be acceptable is to
encrypt the old key under the new key, keep that in the header, and
encrypt newly encrypted sectors with the new key. A background task
could decrypt and reencrypt all sectors over time.
3) Attention should be paid to failure modes. One can imagine disk
failures - possibly even a sector written without its corresponding key
sector written -that would render much or all of the disk inaccessible.
Understanding the transaction semantics of the disk controller is
required to get this right (in the worst case, writing multiple copies
of critical data where the second write is not initiated until the first
completes). My reading of the document is that the master record is
written on the disk in four places for redundancy against corruption,
but the locations of those master records is kept in only one place.

@_date: 2005-03-09 08:21:51
@_author: Perry E. Metzger 
@_subject: Please forward to cryptography@ list. 
Forwarded at PHK's request.
I have read the comments on gbde in the archive of the cryptography@
list and I would like to attach some comments to some of them.
To Ivan Krstic:
One of the unfortunate disadvantages of the complexity of GBDE is
that it is not possible to judge in on a quick glance.
I have ignored Joseph Ashwoods complaints, I found neither facts
in his email nor credenticals for him that could make them useful
to me.  I will be happy to consider any substantiated critique from
Rolands preliminary analysis is very interesting and I very much
appreciate him taking time to do it.  I have sent my comments to
him in private.  Again, I will agree that the complexity does add
to the analysis workload.
Roland may be on to an attack vector which is cheaper than I had
anticipated, but his estimate so far is 2^128 * 2^104 and there are
a couple of not at all trivial tasks he needs to account for still,
and it is not clear what the cost of cul-de-sac searches will be.
Dan Kaminsky raises the point of ghosting at the physical level.
There is nothing reliable GBDE or any other software can do about
that.  I talked to one disk-recovery company who said that they
would almost guarantee that they could recover the previous
contents of any sector on any disk (ie: one generation back) and
often they could also find the generation before that.  They could
not say if the amount of entropy in the data made a difference,
but they generally had little trouble with compressed images.
David Wagner has once again earned my grattitude for taking time to
look at this, and he raises some very valid points.
The paper was written for the BSDcon conference and in addition to
being on OS-focused rather than crypto-focused audience, this also
imposed a 12 page limit on the paper.  For practical reasons I am
restricted to a couple of conferences abroad every year and I have
not had opportunity to present the paper at a venue where a major
revision would be warranted.
I did look into using a stronger keying method for GBDE, but most
of the software I found that could have been used to implement this
would not allow an easy way to override in the cases where qualified
administrator wanted to use an existing or just different keying
We know from earlier experience that lack of override results in
tools like "expect" being used to chat with the offending code,
and we know how secure that is.
Add to this that public-key software adds significant complexity
and often user/administrator learning curve and the desirability
dropped fast.
In the end I decided that by making GBDE a tool for encrypting a
disk, keyed by a bytestring of arbitrary length, it would be possible
for any and all keying scheme to be put in front of GBDE.
And it is being used.  For instance several users have related to
me how they have created some kilobyts of PRNG bits, encrypted them
with their PGP key and use that for a keying scheme.
The "default" keying scheme of using only the entered pass-phrase
is totally inadequate for any but the most trivial use, and I have
made a big point out of this both in section 9.3 in the paper and
in the presentations I have given on GBDE.
Some users have said that all they wanted "for now" was trivial
protection, but would like to have the option of upgrading to
stronger but more cumbersome keying "on moments notice".
In summary I agree with the sentiment that there is a significant
risk of unwise usage, but I do not see it as being GBDE's job to
solve this.  What is missing is "front-burner" programs that implement
good keying methods and deliver the "magic" byte string to GBDE
when satisfied with the keying condition.
The threat model for GBDE is a sort of "real world compromise"
roughly covering lost/forgotten laptops, media transportation and
insider snooping. Stolen/Lost laptops is a bimodal threat, you have random theft
and targeted (industrial) espionage.  They strength of your
keying should reflect what your fear.
If data media are transported, "good practice" dictate that the key
and a good hash of the contents should be transmitted using a
sufficiently trusted secondary channel.  Keys are often
PRNG data in these scenarios.
Insider snooping or "cleaning lady" attack is the hardest to offer
defense against, because operational patterns will expose the
geometry related hiding on relatively short order.  On the other
hand, the geometry hiding adds a pretty solid work factor for
the "cold media" case, so it is still worth it.
Replay and chosen cipher-text attacks are solidly outside the scope
of GBDE.  Such attacks are only relevant for GBDE under the
cleaning-lady scenario where the attacker can be pressumed to also
be able to install key-stroke loggers, root-kits and God knows
what else.
In that world, GBDE cannot do anything alone.  The only way to
ensure data integrity is by having some sort of off-line secret.
The secret may be just a generation number to be remembered from
session to session, a tripwire like inventory or a complete off-line
backup, but some sort of off-line token is necessary.
That said, apart from a wholesale roll-back of the contents of the
disk, a replay attack will be very tricky to get reliably right for
an attacker unless the cleaning lady knows which exact sector
is interesting.
Chosen cipher text is not protected at all GBDE right now, the IV
to the sector encryption should have been a masterkey field like
the salt.  This is an oversight which will be fixed next time the
masterkey format changes.
With respect to laptops: there is no way to secure a laptop if you
do not power it down and remove the battery.
Laptop designs are closed, and we have no way or reason to trust
the significant and often buggy ACPI code which deals with the
entire hardware state to not have backdoors (deliberate or accidental).
At least some laptops have BIOS backdoors by design, but very little
have been revealed about how these works.  On one Dell I owned a
time varying 5 character code could be displayed by the BIOS and
Dell could translate this to/generate from this a code which would
result in the BIOS passwords being erased.
Connectivity options like Firewire have modes which allow full
access to all the RAM on the machine, it is not always possible
to disable these modes.
Finally many if not all laptops have JTAG test points on the
motherboard and in some cases in the docking connector.  That gives
full 100% unadultered control over the CPU and peripheral chips.
With respect to implementation:  I have done my best, but as Djikstra
remarked 40 years ago "I am [...] aware that I have only a small
head, and must live with it.".
The implemntation goes to some length to wipe secrets from RAM, but
for reasons of anti-complexity (and in the case of disk-ghosting:
performance) it has not been a major priority to protect against
attacks on ghost images in RAM or on disk.

@_date: 2005-05-18 15:23:00
@_author: Perry E. Metzger 
@_subject: ADMIN: no, I'm not dead... 
Your moderator has been rather busy for the last eight weeks, but I'm
free again. I should begin pushing out the backlog again in the next
24 hours.

@_date: 2005-05-20 14:39:11
@_author: Perry E. Metzger 
@_subject: [ADMIN] multi-moderator software? 
Your humble moderator asks...
Does anyone know of a mailing list system that handles having
multiple, rotating moderators cleanly? I'd like to avoid many-week
delays like the one I've just caused.

@_date: 2005-05-23 11:46:25
@_author: Perry E. Metzger 
@_subject: Traffic Analysis in the New York Times 
Sunday's New York Times "Week in Review" section had an interesting
article on traffic analysis, although the term doesn't appear once in
the entire article.
A large corpus of Enron internal electronic mail was made available
some time ago, and apparently a number of groups have been using it to
refine statistical traffic analysis techniques.
The original article has some nice diagrams, but unfortunately,
because of the NY Times' policies, the article won't be online in a
few days.

@_date: 2005-05-31 16:03:10
@_author: Perry E. Metzger 
@_subject: "SSL stops credit card sniffing" is a correlation/causality 
"Tue, 31 May 2005 18:31:04 +0100")
Perhaps you are unaware of it because no one has chosen to make you
aware of it. However, sniffing is used quite frequently in cases where
information is not properly protected. I've personally dealt with
several such situations.
Bluntly, it is obvious that SSL has been very successful in thwarting
certain kinds of interception attacks. I would expect that without it,
we'd see mass harvesting of credit card numbers at particularly
vulnerable parts of the network, such as in front of important
merchants. The fact that phishing and other attacks designed to force
people to disgorge authentication information has become popular is a
tribute to the fact that sniffing is not practical.
The bogus PKI infrastructure that SSL generally plugs in to is, of
course, a serious problem. Phishing attacks, pharming attacks and
other such stuff would be much harder if SSL weren't mostly used with
an unworkable fake PKI. (Indeed, I'd argue that PKI as envisioned is
unworkable.)  However, that doesn't make SSL any sort of failure -- it
has been an amazing success.
Where do you get that idea? Break-ins to firms over their unprotected
802.11 networks are not infrequent occurrences. Perhaps you're unaware
of whether anyone is listening in to your home network, but I suspect
there is very little that is interesting to listen in to on your home
network, so there is little incentive for anyone to break it.
You are wrong there again.
Where are you getting your information from? Whomever your informant
is, they're not giving you accurate information.

@_date: 2005-05-31 18:43:56
@_author: Perry E. Metzger 
@_subject: "SSL stops credit card sniffing" is a correlation/causality 
============================== START ==============================
 "Tue, 31 May 2005 22:42:38 +0100")
You aren't going to get it. The companies that get victimized have a
very strong incentive not to share incident information very
widely. However, those of us who actually make our living in the field
generally have a pretty strong sense of what is going wrong out there.
Those who work as consultants to large organizations, or as internal
security personnel at them, tend to be fairly independent of particular
vendors. I don't have any financial reason to recommend particular
firms over others, and customers generally are in a position to judge
for themselves whether what gets recommended is a good idea or not.
Many of us actually take our contract obligations not to talk about
our customers quite seriously, and in any case, anonymous anecdotal
reports about unnamed organizations aren't really "data" in the
traditional sense. You worry about vendors spreading FUD -- well, why
do you assume you can trust anonymous comments not to be FUD from
You don't really need to hear much from me or others on this sort of
thing, though. Pretty much common sense and reasoning will tell you
things like "the bad guys attack the weak points" etc. Experience says
if you leave a vulnerability, it will be exploited eventually, so you
try not to leave any.
All the data in the world isn't going to help you anyway. We're not
talking about what percentage of patients with melanoma respond
positively to what drug. Melanomas aren't intelligent and don't change
strategy based on what other melanomas are doing. Attack strategies
change. Attackers actively alter their behavior to match conditions.
The way real security professionals have to work is analysis and
conservatism. We assume we're dumb, we assume we'll make mistakes, we
try to put in as many checks as possible to prevent single points of
failure from causing trouble. We assume machines will be broken in to
and try to minimize the impact of that. We assume some employees will
turn bad at some point and try to have things work anyway in spite of
No you don't.
1) You have one anecdote. You really have no idea how
   frequently this happens, etc. 2) It doesn't matter how frequently it happens, because no two
   companies are identical. You can't run 100 choicepoints and see
   what percentage have problems.
3) If you're deciding on how to set up your firm's security, you can't
   say "95% of the time no one attacks you so we won't bother", for
   the same reason that you can't say "if I drive my car while
   slightly drunk 95% of the time I'll arrive safe", because the 95%
   of the time that nothing happens doesn't matter if the cost of the
   5% is so painful (like, say, death) that you can't recover from
   it. In particular, you don't want to be someone on who's watch a
   major breech happens. Your career is over even if it never happens
   to anyone else in the industry.
3) Most of what you have to worry about is obvious anyway. There's
   nothing really new here. We've understood that people were the main
   problem in security systems since before computer security. Ever
   wonder why accounting controls are set up the way they are? How
   long were people separating the various roles in an accounting
   system to prevent internal collusion? That goes back long before
   computers.
No, we really don't.
Spoken like someone who hasn't actually worked inside the field.
Statistics and the sort of economic analysis you speak of depends on
assumptions like statistical independence and the ability to do
calculations. If you have no basis for calculation and statistical
independence doesn't hold because your actors are not random processes
but intelligent actors, the method is worthless.
In most cases, by the way, the raw cost of attempting a cost benefit
analysis will cost far more than just implementing a safeguard. A
couple thou for encrypting a link or buying an SSL card is a lot
cheaper than the consulting hours, and the output of the hours would
be an utterly worthless analysis anyway.
You don't understand the problem then. You also don't understand the
threat model most law firms face.
Bull. You haven't been listening. I think a lot of us have been saying
bad things about PKI going back for many, many years now. Many of us
have given numerous talks about this, written papers, and even run
IETF working groups devoted to the proposition.
How much does it cost an end user to use SSL? Zero, for practical
purposes. How much does it cost a company to SSL protect its
transactions with its customers? Nearly nothing compared to other
costs, even if they need hardware acceleration. If you're doing enough
business to need an accelerator, you won't notice the price. How much
does a web server that does SSL cost? Zero -- you can't buy one that
doesn't have it, and the free ones all have it already.
So, to save practically no money, you're willing to tell your
customers that they shouldn't bother, especially when people tell you
that there is good reason to bother and raw a priori reasoning says
that there is good reason to bother? What sort of advice is that?
Your information is less than perfect it would seem.
The day to day problem of security at real financial institutions is
the fact that humans are very poor at managing complexity, and that
human error is extremely pervasive. I've yet to sit in a conference
room and think "oh, if I only had more statistical data", but I've
frequently been frustrated by gross incompetence.

@_date: 2005-11-01 11:44:41
@_author: Perry E. Metzger 
@_subject: Symmetric ciphers as hash functions 
Not in the least. Building new strong tools by using older tools that
are known to be strong is part of the traditional cryptography mindset,
and there is nothing remotely wrong with it, provided it works. If
your attitude were correct, we wouldn't have constructs like HMAC,
would we?

@_date: 2005-11-10 10:58:18
@_author: Perry E. Metzger 
@_subject: event in NYC: "The Secret World of Global Eavesdropping" 
Apparently there's an event at The New School on November 17th
entitled "The Secret World of Global Eavesdropping" -- one of the
panel is John Young of Cryptome fame.

@_date: 2005-11-15 10:14:39
@_author: Perry E. Metzger 
@_subject: "ISAKMP" flaws? 
Some articles have been appearing in various web sites about flaws in
IPSec key negotiation protocols, such as this one:
I haven't been following the IPSec mailing lists of late -- can anyone
who knows details explain what the issue is?

@_date: 2005-11-15 18:31:30
@_author: Perry E. Metzger 
@_subject: the effects of a spy 
Very interesting indeed. I was unaware that the military had such
astonishingly bad key management practices. One wonders if things have
actually improved.
One thing one hopes has changed is that one hopes that it is no longer
necessary for everyone to share the same keying material among so many
different endpoints. Public key cryptography and key negotiation could
(in theory) make it unnecessary to store shared secrets for long
periods of time before use, where they are rendered vulnerable to
espionage. One hopes that, over the last thirty years, this or
something analogous has been implemented.
One intriguing question that I was left with after reading the whole
thing was not mentioned in the document at all. One portion of the
NSA's role is to break other people's codes. However, we also have to
assume that equipment would fall into "the wrong people's hands" at
intervals, as happened with the Pueblo incident. If properly designed,
the compromise of such equipment won't reveal communications, but
there is no way to prevent it from revealing methods, which could then
be exploited by an opponent to secure their own communications.
Does the tension between securing one's own communications and
breaking an opponents communications sometimes drive the use of COMSEC
gear that may be "too close to the edge" for comfort, for fear of
revealing too much about more secure methods? If so, does the public
revelation of Suite B mean that the NSA has decided it prefers to keep
communications secure to breaking opposition communications?

@_date: 2005-11-30 10:53:26
@_author: Perry E. Metzger 
@_subject: Matt Blaze finds flaws in FBI wiretap equipment 
New York Times article:
   Security Flaw Allows Wiretaps to Be Evaded, Study Finds
   By JOHN SCHWARTZ and JOHN MARKOFF
   Published: November 30, 2005
   The technology used for decades by law enforcement agents to wiretap
   telephones has a security flaw that allows the person being wiretapped
   to stop the recorder remotely, according to research by computer
   security experts who studied the system. It is also possible to
   falsify the numbers dialed, they said.
   Someone being wiretapped can easily employ these "devastating
   countermeasures" with off-the-shelf equipment, said the lead
   researcher, Matt Blaze, an associate professor of computer and
   information science at the University of Pennsylvania.
original paper at:

@_date: 2005-11-30 10:58:25
@_author: Perry E. Metzger 
@_subject: ADMIN: microsoft.com subscribers may be unsubscribed soon 
About half the messages to cryptography are being rejected by
microsoft.com's anti-spam content filter, with messages like this:
: host maila.microsoft.com[131.107.3.125] said: 550 5.7.1
     (in reply to end of DATA command)
I've been manually preventing the Microsoft addresses from being
unsubscribed from the list for excess bounces but I'm going to stop
doing that shortly -- it is too much work. Sorry.
I would forward examples of the messages that are bouncing to the
folks at MS but unfortunately, it is impossible to do so for obvious

@_date: 2005-10-18 12:10:57
@_author: Perry E. Metzger 
@_subject: printer "dot code" broken by EFF 
Many color printers these days include a subtle set of dots in the
output that encodes information on the printer that produced it,
allowing tracing of who printed what. EFF has broken the code on one
such line of printers:

@_date: 2005-10-19 10:29:19
@_author: Perry E. Metzger 
@_subject: Cisco VPN password recovery program 
Via cryptome:
   The Cisco VPN Client uses weak encryption to store user and group
   passwords in your local profile file.  I coded a little tool to
   reveal the saved passwords from a given profile file.
If this is true, it doesn't sound like Cisco used a particularly smart
design for this.

@_date: 2005-10-19 23:15:29
@_author: Perry E. Metzger 
@_subject: Feds mandate two factor authentication for banks 
BOSTON - Federal regulators will require banks to strengthen
   security for Internet customers through authentication that goes
   beyond mere user names and passwords, which have become too easy
   for criminals to exploit.
   Bank Web sites are expected to adopt some form of "two-factor"
   authentication by the end of 2006, regulators with the Federal
   Financial Institutions Examination Council said in a letter to
   banks last week.

@_date: 2005-10-23 11:31:11
@_author: Perry E. Metzger 
@_subject: From the New York Times: CALEA strikes universities, they sue. 
[I'm posting the whole thing because the New York Times rapidly expires
all their articles, making it impossible to refer to them over the
long term. --Perry]
October 23, 2005
Colleges Protest Call to Upgrade Online Systems
By SAM DILLON and STEPHEN LABATON
The federal government, vastly extending the reach of an 11-year-old
law, is requiring hundreds of universities, online communications
companies and cities to overhaul their Internet computer networks to
make it easier for law enforcement authorities to monitor e-mail and
other online communications.
The action, which the government says is intended to help catch
terrorists and other criminals, has unleashed protests and the threat
of lawsuits from universities, which argue that it will cost them at
least $7 billion while doing little to apprehend lawbreakers. Because
the government would have to win court orders before undertaking
surveillance, the universities are not raising civil liberties issues.
The order, issued by the Federal Communications Commission in August
and first published in the Federal Register last week, extends the
provisions of a 1994 wiretap law not only to universities, but also to
libraries, airports providing wireless service and commercial Internet
access providers.
It also applies to municipalities that provide Internet access to
residents, be they rural towns or cities like Philadelphia and San
Francisco, which have plans to build their own Net access networks.
So far, however, universities have been most vocal in their
The 1994 law, the Communications Assistance for Law Enforcement Act,
requires telephone carriers to engineer their switching systems at
their own cost so that federal agents can obtain easy surveillance
Recognizing the growth of Internet-based telephone and other
communications, the order requires that organizations like
universities providing Internet access also comply with the law by
spring 2007.
The Justice Department requested the order last year, saying that new
technologies like telephone service over the Internet were endangering
law enforcement's ability to conduct wiretaps "in their fight against
criminals, terrorists and spies."
Justice Department officials, who declined to comment for this
article, said in their written comments filed with the Federal
Communications Commission that the new requirements were necessary to
keep the 1994 law "viable in the face of the monumental shift of the
telecommunications industry" and to enable law enforcement to
"accomplish its mission in the face of rapidly advancing technology."
The F.C.C. says it is considering whether to exempt educational
institutions from some of the law's provisions, but it has not granted
an extension for compliance.
Lawyers for the American Council on Education, the nation's largest
association of universities and colleges, are preparing to appeal the
order before the United States Court of Appeals for the District of
Columbia Circuit, Terry W. Hartle, a senior vice president of the
council, said Friday.
The Center for Democracy and Technology, a nonprofit civil liberties
group, has enlisted plaintiffs for a separate legal challenge,
focusing on objections to government control over how organizations,
including hundreds of private technology companies, design Internet
systems, James X. Dempsey, the center's executive director, said
The universities do not question the government's right to use
wiretaps to monitor terrorism or criminal suspects on college
campuses, Mr. Hartle said, only the order's rapid timetable for
compliance and extraordinary cost.
Technology experts retained by the schools estimated that it could
cost universities at least $7 billion just to buy the Internet
switches and routers necessary for compliance. That figure does not
include installation or the costs of hiring and training staff to
oversee the sophisticated circuitry around the clock, as the law
requires, the experts said.
"This is the mother of all unfunded mandates," Mr. Hartle said.
Even the lowest estimates of compliance costs would, on average,
increase annual tuition at most American universities by some $450, at
a time when rising education costs are already a sore point with
parents and members of Congress, Mr. Hartle said.
At New York University, for instance, the order would require the
installation of thousands of new devices in more than 100 buildings
around Manhattan, be they small switches in a wiring closet or large
aggregation routers that pull data together from many sites and send
it over the Internet, said Doug Carlson, the university's executive
director of communications and computing services.
"Back of the envelope, this would cost us many millions of dollars,"
Mr. Carlson said.
F.C.C. officials declined to comment publicly, citing their continuing
review of possible exemptions to the order.
Some government officials said they did not view compliance as overly
costly for colleges because the order did not require surveillance of
networks that permit students and faculty to communicate only among
themselves, like intranet services. They also said the schools would
be required to make their networks accessible to law enforcement only
at the point where those networks connect to the outside world.
Educause, a nonprofit association of universities and other groups
that has hired lawyers to prepare its own legal challenge, informed
its members of the order in a Sept. 29 letter signed by Mark A. Luker,
an Educause vice president.
Mr. Luker advised universities to begin planning how to comply with
the order, which university officials described as an extraordinary
technological challenge.
Unlike telephone service, which sends a steady electronic voice stream
over a wire, the transmission of e-mail and other information on the
Internet sends out data packets that are disassembled on one end of a
conversation and reassembled on the other.
Universities provide hundreds of potential Internet access sites,
including lounges and other areas that offer wireless service and
Internet jacks in libraries, dorms, classrooms and laboratories, often
dispersed through scores of buildings.
If law enforcement officials obtain a court order to monitor the
Internet communications of someone at a university, the current
approach is to work quietly with campus officials to single out
specific sites and install the equipment needed to carry out the
surveillance. This low-tech approach has worked well in the past,
officials at several campuses said.
But the federal law would apply a high-tech approach, enabling law
enforcement to monitor communications at campuses from remote
locations at the turn of a switch.
It would require universities to re-engineer their networks so that
every Net access point would send all communications not directly onto
the Internet, but first to a network operations center where the data
packets could be stitched together into a single package for delivery
to law enforcement, university officials said.
Albert Gidari Jr., a Seattle lawyer at the firm Perkins Coie who is
representing Educause, said he and other representatives of
universities had been negotiating with lawyers and technology
officials from the Federal Bureau of Investigation, the Department of
Homeland Security and other agencies since the spring about issues
including what technical requirements universities would need to meet
to comply with the law.
"This is a fight over whether a Buick is good enough, or do you need a
Lexus?" Mr. Gidari said. "The F.B.I. is the lead agency, and they are
insisting on the Lexus."
Law enforcement has only infrequently requested to monitor Internet
communications anywhere, much less on university campuses or
libraries, according to the Center for Democracy and Technology. In
2003, only 12 of the 1,442 state and federal wiretap orders were
issued for computer communications, and the F.B.I. never argued that
it had difficulty executing any of those 12 wiretaps, the center said.
"We keep asking the F.B.I., What is the problem you're trying to
solve?" Mr. Dempsey said. "And they have never showed any problem with
any university or any for-profit Internet access provider. The
F.B.I. must demonstrate precisely why it wants to impose such an
enormously disruptive and expensive burden."
Larry D. Conrad, the chief information officer at Florida State
University, where more than 140 buildings are equipped for Internet
access, said there were easy ways to set up Internet wiretaps.
"But the wild-eyed fear I have," Mr. Conrad said, "is that the
government will rule that this all has to be automatic, anytime, which
would mean I'd have to re-architect our entire campus network."
He continued, "It seems like overkill to make all these institutions
spend this huge amount of money for a just-in-case kind of scenario."
The University of Illinois says it is worried about the order because
it is in the second year of a $20 million upgrade of its campus
network. Peter Siegel, the university's chief information officer,
estimated that the new rules would require the university to buy 2,100
new devices, at a cost of an additional $13 million, to replace
equipment that is brand new.
"It's like you buy a new car, and then the E.P.A. says you have to buy
a new car again," Mr. Siegel said. "You'd say, 'Gee, could I just buy
a new muffler?' "

@_date: 2005-10-31 08:06:11
@_author: Perry E. Metzger 
@_subject: NY Times reports: NSA falsified Gulf of Tonkin intercepts 
WASHINGTON, Oct. 28 - The National Security Agency has kept secret
   since 2001 a finding by an agency historian that during the Tonkin
   Gulf episode, which helped precipitate the Vietnam War,
   N.S.A. officers deliberately distorted critical intelligence to
   cover up their mistakes, two people familiar with the historian's
   work say.
   The historian's conclusion is the first serious accusation that
   communications intercepted by the N.S.A., the secretive
   eavesdropping and code-breaking agency, were falsified so that they
   made it look as if North Vietnam had attacked American destroyers
   on Aug. 4, 1964, two days after a previous clash.

@_date: 2005-10-31 15:19:35
@_author: Perry E. Metzger 
@_subject: Halloween Hash Bash information 
Bruce Schneier is liveblogging from the NIST Halloween Hash Bash:
(Credit: Steve Bellovin directed me at the web page.)

@_date: 2005-09-13 11:32:45
@_author: Perry E. Metzger 
@_subject: Clearing sensitive in-memory data in perl 
I think you're wrong to operate on the assumption that even a very
good programmer can be more vigilant against buffer overflows than a
language that performs bounds checking. Even extremely good
programmers are human beings. I think I'm a very good programmer, but
I make mistakes, and in security, mistakes cost big time.
There is also the question of leverage -- if there is a bug in a
bounds checker in a language implementation, fixing it stops huge
numbers of bugs people didn't know about. Fixing buffer overflow bugs
in a C program helps only that program.
Generally speaking, I think software with a security impact should not
be written in C.
What the world really needs is something between C++ and C -- a
language with very clean obvious semantics (like C) which does run
time bounds checking and strong typing, though it also needs explicit
escapes in the type system so you can write things like device drivers
in it. It probably also should not require run time garbage
collection, if only so kernel code can be written in it.

@_date: 2005-09-15 10:12:39
@_author: Perry E. Metzger 
@_subject: Record a keyboard, reconstruct what was typed. 
Interesting new paper:
   We examine the problem of keyboard acoustic emanations. We
   present a novel attack taking as input a 10-minute sound recording
   of a user typing English text using a keyboard, and then recovering
   up to 96% of typed characters. There is no need for a labeled
   training recording. Moreover the recognizer bootstrapped this way
   can even recognize random text such as passwords: In our experiments,
   90% of 5-character random passwords using only letters can
   be generated in fewer than 20 attempts by an adversary; 80% of 10-
   character passwords can be generated in fewer than 75 attempts.
   Our attack uses the statistical constraints of the underlying content,
   English language, to reconstruct text from sound recordings
   without any labeled training data. The attack uses a combination
   of standard machine learning and speech recognition techniques,
   including cepstrum features, Hidden Markov Models, linear classi-
   fication, and feedback-based incremental learning.

@_date: 2005-09-26 10:10:22
@_author: Perry E. Metzger 
@_subject: An overview of cryptographic protocols to prevent spam 
I'm afraid that I use blacklists. My servers get about 30,000 spams
and virii directed at me (that is me, Perry Metzger, personally) every
night that are blocked by blacklists. I would be unable to write you
this email if I didn't use blacklists, because I'd have no working
email at all. (To be fair, the onslaught has diminished recently --
I'm now down to perhaps 20k a night. There is no functional
I've also been blacklisted myself, and I've had to deal with
I understand your position, but you should understand that for many of
us spam, virus spew, etc. is not merely an annoyance but has the
ability to literally make it impossible to use email. Using a
combination of blacklists and other mechanisms, I get the spam levels
down to the point where they are merely an annoyance, but without them
I'd be incapable of receiving email any longer.
An analogy I like to use here is that while your neighbor using a
flashlight in the night might be an "annoyance", and turning on
floodlights in the night might be a "substantial annoyance", bathing
your house in hundreds of megawatts of light day and night goes beyond
mere "annoyance" and eliminates your ability to enjoy the use of your
A few unwanted emails are a mere annoyance, but at the levels I've
reached, they go beyond annoyance. As much as I dislike blacklists
etc., I couldn't operate without them so I use them.
I wish I lived in a world where you couldn't just go out and lease the
use of 8000 zombie machines on the internet pre-broken into by
Ukrainian gangsters for your spamming pleasure, where people couldn't
send me phishing emails without being caught and punished for fraud,
etc. -- in short where folks who do things that even libertarians
dislike were punished. However, we don't live in an ideal world -- we
live in a world where a government monopoly runs law enforcement and
that law enforcement is nigh well worthless. I can't just buy the
other government's law enforcement since there is none, so I do what I
can on my own to make my machines livable.
In a better world maybe we won't need firewalls, policies where cable
modem users have port 25 blocked unless they ask for it to be
unblocked, spam blacklists, vast amounts of personnel time and money
spent at large organizations worrying about spam, security, etc., but
that better world isn't coming any time soon.
John, I admire you for living a life without compromises. However, I
cannot afford such a life.
As it stands, I wouldn't blame the people who block ports. Most of
them, like me, are just trying to keep using the internet as best as
they can.
I would blame the criminals. I don't mean the people who merely send
out unsolicited email from machines they themselves own that doesn't
pretend to come from other people. I mean the people who
systematically break in to thousands of computers (surely you don't
believe breaking in to someone's computer to gain its use against the
will of the owner is okay) so they can send out their notes to a few
million people claiming to be their bank and directing them to yet
another machine they've broken in to where they collect the passwords
of the victims. I would also blame the law enforcement agencies who
essentially do nothing to these people.

@_date: 2005-09-26 10:28:11
@_author: Perry E. Metzger 
@_subject: An overview of cryptographic protocols to prevent spam 
One more comment note on spam...
My mother in law recently got rid of the email address she had been
using for many years. Why? She was getting so much spam that the
address was effectively useless. To find the one real message she had
to wade through a metric ton of porn, medical fraud, bank fraud and
ads for fake rolexes. Her anti-spam facilities in her mail reader were
pretty good but kept putting real messages into the spam folder, so
after a while it became obvious that they weren't helping since she
had to parse all the spam by hand anyway. In short, she was forced to
surrender. She abandoned the account.
She's not the only person I know who's done things like this. Spam is
not a "harmless annoyance" any more than insect bites are once you
start getting enough. It threatens the ability to actually use email
for communication.
In a normal society, by now people would have email directories online
where you could look up the email addresses of friends and loved
ones. Why don't we have those? Spammers. People actually go through a
whole lot of trouble NOT to have their email online. They do things
like turning their email addresses into images on their web sites so
automated harvesters can't read them. They post from "throwaway
accounts" assuring that no one who wants to reply will ever be able to
do so. They bend over backwards trying to avoid the spammers.
ISPs have to spend vast amounts of money one extra bandwidth to carry
this garbage -- it costs real money. Companies have large staffs of
people who work full time to ameliorate (not eliminate) their spam
problems. It costs them real money. People like my mother in law
abandon email addresses (and make it impossible for old friends to
find them) because they're scared that if too many people know their
email address it will become flooded with garbage. By the way, the
criminals now do stuff like using spyware to steal people's addresses
so it is literally the case that you have to worry that too many
people know your address.
This is not a normal situation any longer. Spam has distorted people's
behavior beyond all recognition. You can pretend that hasn't happened
and that really all that is needed is heavier use of the "d" key or
perhaps slightly better Bayesian filters, but in fact that's not the
situation any more. We're beyond that. You can argue that we're
wrecking the internet to save it, but what is, realistically, the
alternative? If you say "just ignore the spam" then I'll have to
politely ignore *you* -- I cannot try to find the 50 real messages
inside of the 30,000 garbage ones addressed to me without the evil
blacklists, and you wouldn't be able to either.
We either make the internet somewhat less of what it was so that we
can continue using it at all, or we keep it "pure" and cease to use it
altogether. Given the choice, I'll compromise on purity.

@_date: 2005-09-28 08:12:20
@_author: Perry E. Metzger 
@_subject: NSA patents "Method for geolocating logical network addresses" 
Method for geolocating logical network addresses
    Abstract
    Method for geolocating logical network addresses on electronically
    switched dynamic communications networks, such as the Internet,
    using the time latency of communications to and from the logical
    network address to determine its location. Minimum round-trip
    communications latency is measured between numerous stations on
    the network and known network addressed equipment to form a
    network latency topology map. Minimum round-trip communications
    latency is also measured between the stations and the logical
    network address to be geolocated. The resulting set of minimum
    round-trip communications latencies is then correlated with the
    network latency topology map to determine the location of the
    network address to be geolocated.

@_date: 2006-04-03 15:09:00
@_author: Perry E. Metzger 
@_subject: Fwd: CFP, Intnl. Conference on Cryptology and Network Security 
The 5th International Conference on Cryptology and Network Security
(CANS06, Suzhou, Dec. 8 - 10, 2006)
Submission Deadline: June 20, 2006 (10:00 GMT)
Call for Papers
    Background
    ----------
The state of  the art of cryptography is  significantly better than it
was  20-30 years  ago.  The  AES standard  was  developed by  academia
instead  of in secrecy,  we have  proven secure  cryptographic schemes
such as RSA-OAEP,  proven secure modes of operation  and proven secure
protocols.  Unfortunately, we see that:
    * There is  an imbalance between the large  investment in research
      on cryptography  and its deployment. Today the  only wide spread
      Internet applications of cryptography are SSL and SSH.
    * At the  same time, other  disciplines such as  computer security
      and network security have not made so much progress. We see that
      many network  applications such  as kazaa and  Internet Explorer
      have been  exploited to  help in the  spread of spyware.  We see
      that operating systems  are not so secure. Weekly  we hear about
      embarrassing news related to network or computer security.
The main goal of this conference is to promote research on all aspects
of network  security and cryptology.  It is also  the goal to  build a
bridge between  research on cryptography and network  security. So, we
welcome   scientific  and   academic   papers  that   focus  on   this
multidisciplinary area.
The first edition of this  conference was in Taipei, Taiwan, 2001. The
second one was  in San Francisco, California, USA,  September 26 - 28,
2002, the third  in Miami, Florida, USA, September 24  - 26, 2003, and
the fourth in Xiamen, Fujian, China, December 14-16, 2005.
    Proceedings
    -----------
The conference proceedings  will be published in the  Lecture Notes in
Computer Science  series by Springer  Verlag, and be available  at the
    Topics of interest
    ------------------
Areas of  interest for CANS '06  include, but are not  limited to, the
following topics:
   Ad Hoc Network Security		Multicast Security
   Access Control for Networks		PKI
   Anonymity and internet voting	Phishing
   Cryptology				Router Security
   Denial of Service			Secure E-Mail
   Fast Cryptographic Algorithms	Secure protocols (SSH, SSL, ...)
   Information Hiding			Spam
   Intrusion Detection			Spyware
   IP Security				Scanning
   Security				Networks
Papers on cryptology  are welcome. Those that make  a substantial link
with network security  will be given priority, since  this is the main
goal  of  this  conference.  Therefore,  authors of  such  papers  are
encouraged to  explain in  a subsection of  the introduction  the link
with network security.
    Instructions for Authors
    ------------------------
The  paper must  start with  a title,  an abstract  and  keywords, but
should be *anonymous*.  It should be followed by  a succinct statement
appropriate  for  a   non-specialist  reader  specifying  the  subject
addressed   its   background,  the   main   achievements,  and   their
significance  to  Cryptology or  Network  Security. Technical  details
directed  to  the  specialist  should  then  follow.  A  limit  of  12
single-spaced pages  of 11pt type  (not counting the  bibliography and
clearly  marked appendices) is  placed on  all submissions.  The total
paper must  not exceed 18 pages.   Since referees are  not required to
read  the  appendices,  the   paper  should  be  intelligible  without
them. Submissions not meeting  these guidelines risk rejection without
consideration of their merits.
    Submission instructions
    -----------------------
Papers  that have  been  or will  be  submitted in  parallel to  other
conferences or workshops that  have proceedings are *not* eligible for
submission.   One  of  the   authors  is   expected  to   present  the
paper. Authors who submit papers  agree to have their papers published
in the proceedings and sign the copyright form.
The submission should be in A4 paper size and sent in PDF format.
    Important dates
    ---------------
    * Submission Deadline: June 20, 2006 (10:00GMT)
    * Authors Notification: August 20, 2006
    * Camera-Ready Version: September 15, 2006     Steering Committee
    ------------------
    * Yvo Desmedt (UCL, UK & Florida State University, USA)
    * Matt Franklin (University of California, Davis, USA)
    * Yi Mu (University of Wollongong, Australia)
    * David Pointcheval (CNRS & ENS, France)
    * Huaxiong Wang (Macquarie University, Australia)     Organization
    ------------
    * General Chair: Kefei Chen (Shanghai Jaotong University, China)     Program Committee
    -----------------
    * Farooq Anjum (Telcordia, USA)
    * Feng Bao (Institute for Infocomm Research, Singapore)
    * Christophe Bidan (Sup?lec, France)
    * John Black (University of Colorado, USA)
    * Carlo Blundo (Universit? di Salerno, Italy)
    * Colin Boyd (QUT, Australia)
    * Xavier Boyen (Voltage, USA)
    * Laurent Bussard (European Microsoft Innovation Center, Germany)
    * Liqun Chen (HP Laboratories, UK)
    * Anand Desai (NTT MCL, USA)
    * Cunsheng Ding (Hong Kong Univ. Sci. Tech., China)
    * Steven Galbraith (Royal Holloway University of London, UK)
    * Marc Girault (France Telecom, France)
    * Nick Howgrave-Graham (NTRU Cryptosystems, USA)
    * Marc Joye (Gemplus & CIM-PACA, France)
    * Kwangjo Kim (ICU, South Korea)
    * Kaoru Kurosawa (Ibaraki University, Japan)
    * Xuejia Lai (Shanghai Jiao Tong University, China)
    * Dong Hoon Lee (Korea University, South Korea)
    * Arjen Lenstra (EPFL, Switzerland)
    * Javier Lopez (University of Malaga, Spain)
    * Atsuko Miyaji (JAIST, Japan)
    * Yi Mu (University of Wollongong, Australia) - co-chair
    * David Naccache (ENS & Paris II, France)
    * Kaisa Nyberg (Helsinki University of Technology and Nokia, Finland)
    * Giuseppe Persiano (Universit? di Salerno, Italy)
    * Josef Pieprzyk (Macquarie University, Australia)
    * David Pointcheval (CNRS & ENS, France) - co-chair
    * C.-Pandu Rangan (Indian Institute of Technology, India)
    * Kazue Sako (NEC, Japan)
    * Berry Schoenmakers (Techn. Univ. Eindhoven, The Netherlands)
    * Willy Susilo (University of Wollongong, Australia)
    * Vijay Varadharajan (Macquarie University, Australia)
    * Xiaofeng Wang (Indiana University, USA)
    * Duncan Wong (City University of Hong Kong, China)
    * Chaoping Xing (National University of Singapore, Singapore)
    * Shouhuai Xu (University of Texas, USA)
    * Sung-Ming Yen (National Central University, Taiwan)

@_date: 2006-04-05 10:17:16
@_author: Perry E. Metzger 
@_subject: CFP International Conference on Cryptology in Vietnam (VietCrypt) 
Forwarded from ias-opportunities....
Content-Disposition: inline
Reply-To: Marina Blanton Content-Disposition: inline
I was asked to pass this information around.
Content-Disposition: inline

@_date: 2006-04-05 13:27:57
@_author: Perry E. Metzger 
@_subject: The underhanded C contest... 
Quoting from the web page:
  We hereby announce our second annual contest to write innocent-looking
  C code implementing malicious behavior. In many ways this is the exact
  opposite of the Obfuscated C Code Contest: in this contest you must
  write code that is as readable, clear, innocent and straightforward as
  possible, and yet it must fail to perform at its apparent function. To
  be more specific, it should do something subtly evil.

@_date: 2006-04-07 12:29:37
@_author: Perry E. Metzger 
@_subject: EFF files papers alleging AT&T illegally taps comms for NSA 
EFF has filed papers in a court case that claim that AT&T illegally
turns over taps of internet communications to the NSA.
This has been reported in several places but I thought I would bring
it up here. Excerpt from the press release:
   "The evidence that we are filing supports our claim that AT&T is
   diverting Internet traffic into the hands of the NSA wholesale, in
   violation of federal wiretapping laws and the Fourth Amendment," said
   EFF Staff Attorney Kevin Bankston. "More than just threatening
   individuals' privacy, AT&T's apparent choice to give the government
   secret, direct access to millions of ordinary Americans' Internet
   communications is a threat to the Constitution itself. We are asking
   the Court to put a stop to it now."

@_date: 2006-04-13 11:06:38
@_author: Perry E. Metzger 
@_subject: "Secure Blue" from IBM 
A few days old but still interesting.
  IBM plans to announce availability of the new technology, dubbed
  Secure Blue, on Monday. The Armonk, N.Y.-based company envisions its
  idea and technology will be used in digital media players, electronic
  organizers, cell phones, computers and devices used by the government
  and the medical and financial industries.
  With Secure Blue, data is encrypted and decrypted as it runs through a
  processor, according to IBM. It is maintained encrypted in the device
  memory, or RAM. One of the few times data would not be scrambled is
  when it is actually displayed.

@_date: 2006-04-19 11:10:49
@_author: Perry E. Metzger 
@_subject: Not everyone knows about strong crypto... 
It seems not everyone has gotten the message that monoalphabetic
substitution was broken many hundreds of years ago. Excerpt:
  The recently arrested "boss of bosses" of the Sicilian Mafia, Bernardo
  Provenzano, wrote notes using an encryption scheme similar to the one
  used by Julius Caesar more than 2,000 years ago, according to a
  biography of Italy's most wanted man.

@_date: 2006-04-22 12:46:57
@_author: Perry E. Metzger 
@_subject: There is a typo on the "Kryptos" sculpture. 
NY Times, April 22, 2006
   A Break for Code Breakers on a C.I.A. Mystery
   By KENNETH CHANG
   For nearly 16 years, puzzle enthusiasts have labored to decipher an
   865-character coded message stenciled into a sculpture on the
   grounds of the Central Intelligence Agency's headquarters in
   Langley, Va. This week, the sculptor gave them an unsettling but
   hopeful surprise: part of the message they thought they had
   deciphered years ago actually says something else.

@_date: 2006-04-29 09:49:04
@_author: Perry E. Metzger 
@_subject: Government says EFF suit against AT&T might reveal secrets! 
The US government wants to intervene to request dismissal of EFF's
lawsuit against AT&T -- the one alleging that it violated federal law
by permitting warrantless wiretapping.
One wonders what sort of state secret could still be secret here now
that the basics of the story have been revealed. Everyone knows that
if they're tapping phones they have to be doing it *somewhere*. The
most interesting thing, though, is the intervention itself, which
implies that EFF is right and AT&T *was* allowing the NSA to put in
equipment wherever it liked.
The New York Times is also covering the story:
Though sadly that link will stop working soon as part of the
New York Times's effort to lose market share.

@_date: 2006-08-25 09:19:44
@_author: Perry E. Metzger 
@_subject: skype not so anonymous... 
Fugitive executive is tracked down by tracing his Skype calls...

@_date: 2006-08-30 10:35:58
@_author: Perry E. Metzger 
@_subject: Debunking the PGP backdoor myth for good. 
Provably false, indeed, trivially proven false.
In other messages you back off and say you just meant some kinds of
structured data can be compressed. Well, yes, but so what? We know
that already.

@_date: 2006-12-02 10:21:57
@_author: Perry E. Metzger 
@_subject: cellphones as room bugs 
The FBI appears to have begun using a novel form of electronic
   surveillance in criminal investigations: remotely activating a
   mobile phone's microphone and using it to eavesdrop on nearby
   conversations.
   The technique is called a "roving bug," and was approved by top
   U.S. Department of Justice officials for use against members of a
   New York organized crime family who were wary of conventional
   surveillance techniques such as tailing a suspect or wiretapping
   him.

@_date: 2006-12-13 14:57:01
@_author: Perry E. Metzger 
@_subject: quantum crypto rears its head again. 
I saw this link on Slashdot (and it was also on Ekr's blog):
It appears that the quantum crypto meme just won't go away.
Bob Gelfond of MagiQ promises us that for only $100,000, plus monthly
leasing of a dry fiber optic home run between your end systems, you
can have security that isn't even as good as what nearly free software
will give commodity computers over the unsecured public internet.
I wonder if this idea is ever going to die. My guess is it will, but
not until the people who have thrown away their money investing in
this technology go bankrupt.

@_date: 2006-12-21 12:54:08
@_author: Perry E. Metzger 
@_subject: "U.S. to Declassify Secrets at Age 25" 
The New York Times has an article on the coming automatic
declassification of most US government documents over 25 years old. I
wonder if some interesting nuggets in the history of DES might become

@_date: 2006-12-22 11:43:58
@_author: Perry E. Metzger 
@_subject: How important is FIPS 140-2 Level 1 cert? 
[I was asked to forward this anonymously. --Perry]
Actually you cant even guarantee that because the FIPS 140 requirements
for the ANSI X9.17/X9.31 PRNG include a pile of oddball things that made
sense for the original X9.17 use (where it was assumed the only source
of entropy was a DES3 key embedded in secure hardware) but are severe
restrictions on current implementations. As a result a FIPS 140-
certified key generator will be worse than a well-designed non-FIPS-140
one because the FIPS requirements prevent you from doing several things
that would improve the functioning like injecting extra entropy into the
generator besides the DES3 key. In addition since no two eval labs can
agree on exactly what is and isnt OK here its pretty much a crap-shoot
as to what you can get through. Ive heard stories from different vendors
of Lab B disallowing something that had already been certified by Lab A
in a previous pass through the FIPS process.
In terms of its value, particularly for level 1, what itll give you is
(1) protection from egregiously bad implementations (which a quick
source code check will do as well) and (2) the ability to sell to US
federal agencies. Beyond that I concur that 10 minutes of interop
testing with the standardised protocol of your choice (e.g. TLS, S/MIME,
IPsec) will give you more than FIPS 140 will since a run of TLS tests
much more of the crypto than FIPS 140 does.

@_date: 2006-12-27 20:09:23
@_author: Perry E. Metzger 
@_subject: Wikipedia cryptography pages 
The Wikipedia sections on crypto are getting quite interesting. See:
Members of this list who know a lot on the subject might want to lend
a hand on some of the articles.

@_date: 2006-02-03 16:21:19
@_author: Perry E. Metzger 
@_subject: serious threat models 
All phone switches, thanks to the US government's CALEA rules, are
equipped with software that makes espionage easy. Whether that
software was abused in this instance, I do not know, but I will point
out that any switch sold in the US -- which is to say most switches
that exist -- has software available (but not necessarily installed)
to tap people's phones in a manner not entirely unlike what happened
to the high government officials in Greece.
Yet again, I point out John Gilmore's warning that once you make law
enforcement "convenient" by creating privacy invading technologies,
you have very little control over who ultimately comes to use those
technologies. It will not only be the good guys who get access to
them, and even the guys who have legitimate access will not always be
good guys.

@_date: 2006-02-03 21:31:23
@_author: Perry E. Metzger 
@_subject: training your customers to be phishing victims 
I've often commented about how awful Chase's "send our customers
emails telling them to click on links" policy is, but tonight I got
one from them exhorting me to sign up for an identity theft protection
The irony is delicious.

@_date: 2006-02-26 10:28:55
@_author: Perry E. Metzger 
@_subject: Cracking remaining Enigma messages 
There is a project out there to crack a few of the remaining Enigma
intercepts from the second world war that were never cracked the first
time around...

@_date: 2006-01-06 12:34:17
@_author: Perry E. Metzger 
@_subject: phone records for sale. 
The Chicago Sun Times reports that, for the right price, you can buy
just about anyone's cell phone records:
Quite disturbing.

@_date: 2006-01-11 09:04:07
@_author: Perry E. Metzger 
@_subject: long-term GPG signing key 
I call "bull".
You have no idea what his usage pattern is like, and you have no idea
what the consequences for him of a forged signature key might be. It
is therefore unreasonable -- indeed, unprofessional -- to make such
claims off the cuff.

@_date: 2006-01-11 10:50:02
@_author: Perry E. Metzger 
@_subject: long-term GPG signing key 
No, I didn't.
Even in totally ordinary circumstances it is important to have very
strong signing keys. Your comments were insupportable.

@_date: 2006-01-17 10:13:06
@_author: Perry E. Metzger 
@_subject: NY Times reports that spy program is not narrowly targeted 
According to President Bush, the illegal NSA domestic espionage
program he ordered was narrowly targeted against people known to have
Al Qaeda links. However, it appears that, as with his previous false
claims that espionage only happened with a warrant, that this claim
was on its face untrue:
   Spy Agency Data After Sept. 11 Led F.B.I. to Dead Ends
   By LOWELL BERGMAN, ERIC LICHTBLAU, SCOTT SHANE and DON VAN NATTA Jr.
   Published: January 17, 2006
   WASHINGTON, Jan. 16 - In the anxious months after the Sept. 11
   attacks, the National Security Agency began sending a steady stream of
   telephone numbers, e-mail addresses and names to the F.B.I. in search
   of terrorists. The stream soon became a flood, requiring hundreds of
   agents to check out thousands of tips a month.
   But virtually all of them, current and former officials say, led to
   dead ends or innocent Americans.
   F.B.I. officials repeatedly complained to the spy agency that the
   unfiltered information was swamping investigators. The spy agency was
   collecting much of the data by eavesdropping on some Americans'
   international communications and conducting computer searches of phone
   and Internet traffic. Some F.B.I. officials and prosecutors also
   thought the checks, which sometimes involved interviews by agents,
   were pointless intrusions on Americans' privacy.
   [...]
   President Bush has characterized the eavesdropping program as a
   "vital tool" against terrorism; Vice President Dick Cheney has said
   it has saved "thousands of lives."
   But the results of the program look very different to some officials
   charged with tracking terrorism in the United States.
   [...]
   "We'd chase a number, find it's a schoolteacher with no indication
   they've ever been involved in international terrorism - case
   closed," said one former F.B.I. official, who was aware of the
   program and the data it generated for the bureau. "After you get a
   thousand numbers and not one is turning up anything, you get some
   frustration."
   [...]
   Rest of article at: I again plead with all of you who care about the future your children
live in to call your congressional representatives and demand that
action be taken. Congress has already largely forgotten about this --
a few weeks is a long time in the memories of politicians. It is up to
you remind them. If you do not, you will have no one to blame but
 "All that is necessary for evil to succeed is that good men do nothing."
                                            -- Edmund Burke

@_date: 2006-01-26 14:05:05
@_author: Perry E. Metzger 
@_subject: A glimpse of SIGINT 20 years ago... 
This is a couple of weeks old, but it appears that, by accident, a lot
of information on the targets and methods being used for
US/Australian/NZ SIGINT about 20 years ago has come to light as the
result of the release of a late New Zealand Prime Minister's papers.
Among other things:
   The report lists the Tangimoana station's targets in 1985-86 as
   "French South Pacific civil, naval and military; French Antarctic
   civil; Vietnamese diplomatic; North Korean diplomatic; Egyptian
   diplomatic; Soviet merchant and scientific research shipping; Soviet
   Antarctic civil. Soviet fisheries; Argentine naval; Non-Soviet
   Antarctic civil; East German diplomatic; Japanese diplomatic;
   Philippine diplomatic; South African Armed Forces; Laotian diplomatic
   (and) UN diplomatic."
   The station intercepted 165,174 messages from these targets, "an
   increase of approximately 37,000 on the 84/85 figure. Reporting on the
   Soviet target increased by 20% on the previous year".
Hat tip to Bruce Schneier's blog for reminding me about it.

@_date: 2006-07-02 13:25:16
@_author: Perry E. Metzger 
@_subject: ADMIN: list server moved 
The list was moved from one mail server to another today. No one
should notice any change at all, but if you do, please get in touch
with me privately.

@_date: 2006-07-10 12:27:59
@_author: Perry E. Metzger 
@_subject: Interesting papers on HMAC and NMAC 
Steve Bellovin forwarded me the following links (which he got from
Eric Rescorla). Note the bit at the end about a path to second
preimage attacks:
  On the Security of HMAC and NMAC Based on HAVAL, MD4, MD5, SHA-0 and SHA-1
  Jongsung Kim and Alex Biryukov and Bart Preneel and Seokhie Hong
  Abstract. HMAC is a widely used message authentication code and a
  pseudorandom function generator based on cryptographic hash functions
  such as MD5 and SHA-1. It has been standardized by ANSI, IETF, ISO and
  NIST. HMAC is proved to be secure as long as the compression function
  of the underlying hash function is a pseudorandom function. In this
  paper we devise two new distinguishers of the structure of HMAC,
  called {\em differential} and {\em rectangle distinguishers}, and use
  them to discuss the security of HMAC based on HAVAL, MD4, MD5, SHA-0
  and SHA-1. We show how to distinguish HMAC with reduced or full
  versions of these cryptographic hash functions from a random function
  or from HMAC with a random function. We also show how to use our
  differential distinguisher to devise a forgery attack on HMAC. Our
  distinguishing and forgery attacks can also be mounted on NMAC based
  on HAVAL, MD4, MD5, SHA-0 and SHA-1. Furthermore, we show that our
  differential and rectangle distinguishers can lead to second-preimage
  attacks on HMAC and NMAC.
Also of interest, this somewhat earlier paper, which shows that HMAC
can be secure if the underlying hash is merely a pseudorandom function
even if it is not collision resistant:
  New Proofs for NMAC and HMAC: Security Without Collision-Resistance
  Mihir Bellare
  Abstract. HMAC was proved by Bellare, Canetti and Krawczyk [2] to be a
  PRF assuming that (1) the underlying compression function is a PRF,
  and (2) the iterated hash function is weakly
  collision-resistant. However, recent attacks show that assumption (2)
  is false for MD5 and SHA-1, removing the proof-based support for HMAC
  in these cases. This paper proves that HMAC is a PRF under the sole
  assumption that the compression function is a PRF. This recovers a
  proof based guarantee since no known attacks compromise the
  pseudorandomness of the compression function, and it also helps
  explain the resistance-to-attack that HMAC has shown even when
  implemented with hash functions whose (weak) collision resistance is
  compromised. We also show that an even weaker-than-PRF condition on
  the compression function, namely that it is a privacy-preserving MAC,
  suffices to establish HMAC is a MAC as long as the hash function meets
  the very weak requirement of being computationally almost universal,
  where again the value lies in the fact that known attacks do not
  invalidate the assumptions made.

@_date: 2006-07-25 10:42:08
@_author: Perry E. Metzger 
@_subject: Crypto to defend chip IP: snake oil or good idea? 
EE Times is carrying the following story:
It is about attempts to use cryptography to protect chip designs from
untrustworthy fabrication facilities, including a technology from
Unlike ordinary DRM, which I think can largely work in so far as it
merely provides a (low) barrier to stop otherwise honest people from
copying something they find inexpensive in the first place, it seems
to me that efforts like this are doomed.
It is one thing if you're just trying to keep most people honest about
something that doesn't cost much money, and another if you're trying
to protect something worth millions of dollars from people with
extremely sophisticated reverse engineering equipment. In particular,
people who operate fabs are also in possession of exquisitely good
equipment for analyzing the chips they've made so they can figure out
process problems, and the "key injection" equipment Certicom is making
could easily be suborned as well.
I'd be interested in other people's thoughts on this. Can you use DRM
to protect something worth not eight dollars but eight million?

@_date: 2006-06-26 10:45:42
@_author: Perry E. Metzger 
@_subject: Salon article on AT&T network monitoring 
In a pivotal network operations center in metropolitan St. Louis, AT&T
   has maintained a secret, highly secured room since 2002 where
   government work is being conducted, according to two former AT&T
   workers once employed at the center.

@_date: 2006-03-16 12:25:32
@_author: Perry E. Metzger 
@_subject: Uncracked Enigma messages score: 2 done, 1 to go. 
The project to crack three remaining unsolved WWII era Enigma messages
has now completed two of them...

@_date: 2006-03-17 11:45:28
@_author: Perry E. Metzger 
@_subject: World of Warcraft massive surveillance... 
"We live in a world where the technology exists that the government or
   other technically sophisticated group is able to monitor and analyze a
   substantial fraction of the communications of the world's population,
   or can track their movements throughout the day, or keep tabs on their
   financial transactions.
   And that world is called World of Warcraft."
[Hat tip to Bruce Schneier's blog.]

@_date: 2006-03-22 12:04:15
@_author: Perry E. Metzger 
@_subject: passphrases with more than 160 bits of entropy 
One person might claim that the sequence of numbers 0 to 255 has 256
bytes of entropy.
Another person will note "the sequence of numbers 0-255" completely
describes that sequence and is only 30 bytes long. Indeed, more
compact ways yet of describing that sequence probably
exist. Therefore, we know that the sequence 0-255 does not, in fact,
have "maximum entropy" in the sense that the entropy of the sequence
is far lower than 256 bytes and probably far lower than even 30 bytes.
Entropy is indeed often confusing. Perhaps that is because both the
Shannon and the Kolmogorov-Chaitin definitions do not provide a good
way of determining the lower bound of the entropy of a datum, and
indeed no such method can exist.

@_date: 2006-03-22 13:45:01
@_author: Perry E. Metzger 
@_subject: passphrases with more than 160 bits of entropy 
No, he wouldn't. You did, however. The maximum entropy a string of 256
bytes could have would be 256*8 bits. Since we're talking about a
sequence with far less entropy than 256*8 bits, it is not a sequence
of maximum entropy. There are, of course, trivially produced sequences
of maximum entropy.
$ echo "the sequence of numbers 0-255" | wc -c
      30
Now, of course, there are probably not more than 1.5 bits of entropy
per letter in that sentence fragment, so really we're probably talking
about ~6 bytes of information. Doubtless, though, cleverer people
could do better.
We heard you the first time.
The Shannon information of a message is the negative of the log (base
2) of the probability of the message. Of course, that definition is
only really useful if you're talking about a sequence of messages. The
Kolmogorov-Chaitin information of a text is (roughly) the smallest
program that can generate the text.
Both of these definitions are getting at can be informally described
as the smallest "representation" of a piece of information.
If Alice asks Bob "what color are your eyes", Bob could send a 10M
high resolution image of his eye, a precise measurement of the
spectrum reflected by his eyes, the word "blue", or perhaps even
something shorter, like a couple of bits that, according to a
pre-agreed table, represent an eye color from a table of eye
colors. The smallest possible representation of just the eye color,
the couple of bits from a table of eye color codes, is likely closest
to the information content of someone's eye color, though a precise
measurement is impossible since it is highly context dependent.
Clearly you don't, since the sequence can be described with far less
information than 256 bytes. A completely random and incompressible
sequence of 256 bytes would have maximum entropy, since it is
impossible to compress to less than 256*8 bits, but the sequence
0..255 has very little entropy because it is easily compressed to a
smaller size. This should be obvious. If I start reciting to you
"zero. one. two..." for a few iterations the probability of the next
byte will be 1/256 or close to it. Shortly, though, anyone who isn't
an idiot will guess what the next value (with nearly probability 1) in
the sequence is, and the information content of subsequent bytes falls
to far less than one bit per byte. This is just another way of saying
that the smallest program that generates 0..255 is quite small, or
that you can easily compress 0..255 into a description that fits in
far less than 256 bytes.
I thought you were, indeed, still arguing.

@_date: 2006-03-22 13:58:32
@_author: Perry E. Metzger 
@_subject: passphrases with more than 160 bits of entropy 
Shannon information certainly falls to zero as the probability with
which a message is expected approaches 1. Kolmogorov-Chaitin
information cannot fall to zero, though it can get exceedingly small.
In either case, though, I suspect we're in agreement on what entropy
means, but Mr. Perez is not familiar with the same definitions that
the rest of us are using.

@_date: 2006-03-22 17:05:29
@_author: Perry E. Metzger 
@_subject: passphrases with more than 160 bits of entropy 
It is, in fact, generally intractable.
1) Kolmogorov-Chaitin entropy is just plain intractable -- finding the
   smallest possible Turing machine to generate a sequence is not
   computable.
2) Shannon entropy requires a precise knowledge of the probability of
   all symbols, and in any real world situation that, too, is
   impossible.
Usually, the best you can do is produce (bad) bounds, and sometimes
not even that.
One thing that can be done, of course, is that you can prove, under
certain assumptions, that it would take an intractable amount of
computation to distinguish a particular PRNG from a true random
sequence with greater than 50% probability. However, this is very much
NOT the same as showing that the PRNG sequence contains an endless
stream of entropy -- in fact, the unicity distance very clearly shows
you how much "real" entropy you have, and it usually isn't
much. Merely because "too much" computation would be needed does not
mean that you've created entropy -- you've just made it hard for the
opponent to get at your PRNG seed.
"Anyone who considers arithmetical methods of producing random digits
is, of course, in a state of sin." -- John von Neumann

@_date: 2006-03-23 09:30:30
@_author: Perry E. Metzger 
@_subject: Greek officials were tapped using law enforcement back door 
A while ago, you may recall that members of the Greek government were
wiretapped, and at the time, I speculated that the bad guys may have
abused the built in CALEA software in the switch to do it. Well, it
now appears that that was precisely what happened. Unfortunately, the
article below is short on detail -- anyone have access to primary
sources? (I know there are at least a couple of Greek cryptographers
on this list...)

@_date: 2006-03-24 11:13:38
@_author: Perry E. Metzger 
@_subject: Entropy Definition 
I think that, in practice, what you want is pretty easy. If you are
picking a key, you want the key generator to have an absolutely flat
In fact, I think that the "randomness distillation" problem for key
generation that people try to solve with hash functions can be
expressed this way:
Given an M bit pool with an entropy of at least K bits, M > K, produce
a J bit output, with J < K, and with the symbols of the J bit output
being of an absolutely flat distribution in repeated experiments even
though the M bits of the pool are not of a flat distribution in
repeated experiments. In other words, you want something with skew but
at least K bits of entropy to turn into something without skew and J
In that sort of case, if I use the output to pick a cryptographic key,
I am probably fairly safe.
Alternatively, one could go for a more direct definition. One could
claim that what one wants is to turn an M bit pool pool that at each
iteration gets K fresh bits of entropy but which may have a skewed
probability distribution into a sequence of J bit values such that,
even given all the members of the sequence up until now, one cannot
guess the value of the next element of the sequence with probability
greater than 1/(2^J).

@_date: 2006-05-01 11:21:21
@_author: Perry E. Metzger 
@_subject: encrypted file system issues (was Re: PGP "master keys") 
Not if you design it correctly. Disk encryption systems like CGD work
on the block level, and do not propagate CBC operations across blocks,
so if the atomic disk block write assumption is correct (and almost
all modern file systems operate on that assumption), you have no more
real risk of corruption than you would in any other application. The
only real risk points come in if you're doing a re-key of the entire
disk or some similar operation in which care must be taken with the
design or you could leave yourself in an unknown state.
Bugs happen in everything.

@_date: 2006-05-01 21:36:59
@_author: Perry E. Metzger 
@_subject: encrypted file system issues 
Yes, but they are all uninteresting. For example, yes, it is trivially
true that if two 128 bit ciphertext blocks are identical that you can
extract some information about those two blocks, but that only reveals
information about two blocks and the odds of this happening are
So do I, since it isn't true.

@_date: 2006-05-07 12:53:41
@_author: Perry E. Metzger 
@_subject: Get a boarding pass, steal someone's identity 
I got this pointer off of Paul Hoffman's blog. Basically, a reporter
uses information on a discarded boarding pass to find out far too much
about the person who threw it away....
  The story may be exaggerated but it feels quite real. Certainly I've
found similar issues in the past.
These days, I shred practically anything with my name on it before
throwing it out. Perhaps I'm paranoid, but then again...

@_date: 2006-05-08 10:38:38
@_author: Perry E. Metzger 
@_subject: Get a boarding pass, steal someone's identity 
The person who sent this asked that I forward it anonymously.
(If you want to post this, please make it anonymous.  Thanks.)
Have you noticed that airline tickets are once again de-facto  transferable?  If you print your own boarding pass at home, you can  digitally change the name on it before you print.  If you have no  bags to check, then the person who checks your ID at the security  checkpoint has no way to read the bar code, and the person who reads  the bar code at the gate does not check your ID.

@_date: 2006-05-11 11:05:09
@_author: Perry E. Metzger 
@_subject: NSA knows who you've called. 
An interesting article in USA Today:
   NSA has massive database of Americans' phone calls
   Updated 5/11/2006 10:38 AM ET
   By Leslie Cauley, USA TODAY
   The National Security Agency has been secretly collecting the phone
   call records of tens of millions of Americans, using data provided
   by AT&T, Verizon and BellSouth, people with direct knowledge of the
   arrangement told USA TODAY.
And a personal note to you all:
Let me again remind people that if you do not inform your elected
representatives of your displeasure with this sort of thing,
eventually you will not be in a position to inform them of your
displeasure with this sort of thing.

@_date: 2006-05-12 09:58:42
@_author: Perry E. Metzger 
@_subject: NSA knows who you've called. 
I'm sure. On the other hand, I think it is our place, as security
professionals, to explain why the tradeoff is a false one. Respect for
individual rights is not something we do in good times because it is a
luxury we can afford when there is stability. It is something we need
most in bad times, because it is what keeps us safe and maintains
stability itself.

@_date: 2006-05-12 22:27:22
@_author: Perry E. Metzger 
@_subject: There are no limits to human stupidity. 
The following message is, sadly, real. The URLs have been altered a
bit to conceal some personal information of the bank customer. (The
HTML version, naturally, just provides click throughs instead of
saying "copy and paste this into your browser".)
I would comment on it, but really, what more can I say?
To view this message in your web browser, please copy and paste
the link below into your browser.
CHASE - Chase Fraud Detector(SM)
Identity Theft Claims a New Victim Every 4.5 Seconds.(1)
Don't let it happen to you.
Let us help protect you with Chase Fraud Detector(SM)
and get 60 days free!
Chase Fraud Detector(SM) provides you the added security and
protection of:
- Customized Fraud Alerts -- Tell us what to watch for and we'll
  alert you of any suspicious activity on your card. If it's not
  yours, we'll fix it. You'll never be held liable for fraudulent
  charges, but they may be a warning sign of a larger problem --
  Identity Theft.(2) To find out more, please copy and paste the
  link below into your browser.
- Your Fraud Advisor will get you a merged credit report and
  scores from all 3 major credit bureaus, file disputes for you
  and more. To find out more, please copy and paste the link
  below into your browser.
- ID Theft Insurance -- Coverage up to $25,000 for certain
  expenses related to identity theft, including lost wages and
  approved legal fees, at no additional cost to you.(3) To learn
  more, please copy and paste the link below into your browser.
All users on the account will be protected with this optional
To learn more about Chase Fraud Detector(SM), please copy and
paste the link below into your browser.
The only thing worse than having your identity stolen is the
hassle of getting back. Get the protection of Chase Fraud
Detector and 60 days free!
To sign up, please copy and paste the link below into your
E-mail Security Information
*************************** E-mail intended for: QQQQ QQQQQ.
If you are concerned about the authenticity of this message,
please call the phone number on the back of your credit card or
copy and paste the link below into your browser.
If you would like to learn more about e-mail security or want to
report a suspicious e-mail, please copy and paste the link below
into your browser.
Note: If you are concerned about clicking links in this e-mail,
the Chase Online services mentioned above can be accessed by
typing  directly into your browser.
TERMS AND CONDITIONS:
(1) Identity Theft Resource Center, Facts & Statistics,
(2) Your liability for unauthorized use of your credit card is
$50; however, MasterCard and Visa do not permit their members,
including Chase to impose even that charge. A complete
explanation can be found in the Membership Agreement. For any
questions regarding this service, please call toll-free Chase
Fraud Detector customer service at 1-800-621-0361. The benefits
and any information provided are subject to change from time to
time, with prior notice, and any products or services are subject
to availability. Chase Fraud Detector is a registered service
mark of JPMorgan Chase & Co. The Chase name and logo are
registered marks of JPMorgan Chase & Co.
You will be contacted at the day and/or evening phone number on
file with Chase. In the event that Chase cannot contact you
personally or is unable to leave a message, you will be notified
by mail at the billing address on file with Chase. Chase will
attempt to notify you when selected transaction categories occur
on your account, but cannot guarantee that the merchant with whom
you did business correctly describes the transaction to us. (3) Insurance is underwritten by Travelers Casualty and Surety
Company of America and its property casualty affiliates,
Hartford, Connecticut 06183. Coverage for all claims or losses
depends on actual policy provisions.
Neither Chase, nor any of their affiliates, is the provider of
any insurance. Many government records are available free or at a nominal cost
from government agencies. Credit reporting agencies are required
by law to give you a copy of your credit report upon request, at
no charge or for a nominal fee.
ABOUT THIS MESSAGE:
This message was delivered to you as a Chase credit card customer
to provide you account updates and information about your card
benefits. Chase values your privacy and your preferences.
Your personal information is protected by state-of-the-art
technology. To view our Online Privacy Policy, please copy and
paste the link below into your browser.
 Chase Privacy Operations, 451 Florida
Streeet, Fourth Floor, LA2-9376, Baton Rouge, LA 70801.
If you wish to unsubscribe from e-mail promotional messages from
Chase Credit Card, please copy and paste the link below into your
Please note that you will continue to receive service related
e-mail messages that directly concern your existing Chase
products and services. Please allow up to ten business days for
us to process your request. Please do not reply to this message
as the "reply" function is not equipped to handle customer
service inquiries. If you want to contact Chase, please do not reply to this
message, but instead please copy and paste the link below into
your browser.
For faster service, please enroll or log in to your account.
Replies to this message will not be read or responded to.
(C) 2006 JPMorgan Chase & Co.

@_date: 2006-05-15 18:27:59
@_author: Perry E. Metzger 
@_subject: Government using call records to go after reporter's sources. 
One of ABC News' reporters says that he's been warned that call
records, possibly even the ones that the major telecom companies are
now routinely turning over to the NSA, are being used to track down
the sources for reporters at several major news services.
   I realize many people might disagree with me, but from my point of
view, the use of such heavy-handed counterintelligence tactics against
the press is a substantial threat to freedom in this country.
John Gilmore long ago warned us that once we'd built the total
surveillance state, all that would be needed to build a new
totalitarianism would be a change of attitude on the part of the
governors. Well, we've built CALEA into everything, and we've built
computerized systems for siphoning all call data in existence, and now
we have an administration with, to say the least, a serious change in
attitude about the law and morality. We have crossed a rubicon.
It can be argued by some who do not agree with me that the reporters
in question are somehow "helping the terrorists" by revealing things
like the fact that the US Government has SigInt operations, but in
fact anyone who isn't an idiot already knows we have SigInt
operations. What the reporters have done -- heroically, I might add --
is reveal that the government has far exceeded the bounds of legality
in performing such operations, even when legal methods existed to gain
the same information.
Some may call said reporters traitors, but it has become increasingly
clear to me that the real traitors are those who do not respect the
principles this country was founded on and who would sell our hard won
freedom and mortgage the rule of law, not for security but for
political gain. The surveillance against reporters is being used not to
save lives but to save the administration political embarrassment, and
there will be no end to the political uses of surveyance if it is not
stopped now.
I implore everyone who agrees with me not to be silent. If you do not
call your representatives to complain about this, it will eventually
be too late to complain. Tell them you want hearings with teeth, tell
them that you want a special prosecutor, tell them that you do not
want to see them rubber stamp universal surveillance with legal fig
leaves, and that you will work to see someone else elected, no matter
how much you like them otherwise, if they refuse to do anything about
this issue. Tell your friends and family to make those calls as
well. I do not know that screaming loudly about this will work, but I
know what silence will bring.

@_date: 2006-05-17 10:01:16
@_author: Perry E. Metzger 
@_subject: "It's funny because it's true..." 
Cartoon of the day:
[Hat tip to Steve Bellovin for pointing it out to me...]

@_date: 2006-05-18 15:09:35
@_author: Perry E. Metzger 
@_subject: UK Government to force disclosure of encryption keys. 
The UK Government is preparing to give the police the authority to
   force organisations and individuals to disclose encryption keys, a
   move which has outraged some security and civil rights experts.

@_date: 2006-05-19 16:41:37
@_author: Perry E. Metzger 
@_subject: New UK law makes a wide range of software illegal. 
A new amendment to the UK's computer crimes law makes it illegal to:
   [...]makes, adapts, supplies or offers to supply any article
    a) intending it to be used to commit, or to assist in the commission
       of, an offence under section 1 or 3 [of the Computer Misuse Act];
       or
   (b) believing that it is likely to be so used.
A number of people have pointed out that, as phrased, this covers
virtually all software, including compilers, operating systems, etc.,
since it is clear that they will be used from time to time in computer
Full article:

@_date: 2006-05-23 11:19:38
@_author: Perry E. Metzger 
@_subject: Secure phones from VectroTel? 
Following the links from a /. story about a secure(?) mobile phone
VectroTel in Switzerland is selling, I came across the fact that this
firm sells a full line of encrypted phones.
The devices apparently use D-H key exchange to produce a 128 bit AES
key which is then used as a stream cipher (presumably in OFB or a
similar mode). Authentication appears to be via a 4 digit pin,
certainly not the best of mechanisms.
Does anyone out there know much about these products and their
security properties (or lack thereof)?

@_date: 2006-11-12 14:53:05
@_author: Perry E. Metzger 
@_subject: ADMIN: spamming by "recruiters" 
Dear list members;
A "recruiter" going by the name of "Doug Kelly" (email address is
dkelly at bryantstaffing.com but headers indicate the use of what are
euphemistically called "mass mailing services") appears to be mining
our mailing list archives and systematically sending out unsolicited
mass commercial mailings, AKA spam, to the harvested list.
My attempts to explain proper behavior to this individual appear to
have met with the usual sort of answer one gets in this sort of
situation, vis:
I've already reported the problem to a few anti-spam services, but I
would suggest that anyone who finds such behavior reprehensible take
whatever action they deem appropriate.
Sample relevant headers follow:
Return-Path: Received: from  (mail.advantmail.com [66.70.107.240])
Received: (qmail 96877 invoked by uid 89); 12 Nov 2006 19:29:36 -0000
Received: from unknown (HELO AST2) (207.150.189.2)
  by mail.xroadsmgmt.com with SMTP; 12 Nov 2006 19:29:36 -0000
Reply-To: Your moderator,

@_date: 2006-11-13 14:01:28
@_author: Perry E. Metzger 
@_subject: Citibank e-mail looks phishy 
Chase sends out unintentional parodies of phishing emails to customers
on a near daily basis, some of them with pathetic little notes about
security. They also have a web site that actively trains their
customers to type in their userid and password to an unsecured web
form. The pathetic little lock icon next to the form may fool the
ignorant but will not fool criminals. I have a wonderful letter from
Chase explaining to me that my worries for their security are
groundless -- it was very nicely worded so as not to come out and call
me insane. I should scan it and put it up on the web at some point.
If this sort of utter disregard for customer safety wasn't such a
scary thing, it would be laugh-out-loud funny. As it is, however,
we've got banks where either the marketing people are clearly in a
position of absolute dominance, or where the security people are
totally asleep at the wheel, or both. This does not bode well for the
future of the particular institutions in question. When the security
controls that are visible are so completely broken, one can only
speculate what the ones that one does not see must look like.
Even ignoring the fact that regulators will at some point come down on
such banks like the proverbial ton of bricks, there is the question of
total loss of customer confidence and the possible complete
destruction of shareholder equity in its wake.
I believe that modern banking regulations in the United States
prohibit banks from claiming to be safer than their competitors, but
that is unlikely to save whomever falls to a scandal.  Information now
flows quite freely outside the conventional media and customers are
able to migrate with relative ease from institution to
When this sort of stupidity finally catches up with one of these firms
in the form of a truly major scandal, I can easily see a brand name or
two that took a century to build vanishing in a blink, with the
remaining husk bought up by a competitor at the request of regulators
and the name quickly retired forever. I can predict that last detail
because this sort of event is not new. Sudden collapses of finance
firms have happened in the past because of scandals, though up until
now they haven't been caused by computer security lapses. I think it
is a question of when, not if, we see a major multinational financial
institution fall as a result of treating systems security as though it
were some ignorable commodity like carpet cleaning service, beneath
the notice of management and easily set aside if competing business
demands require it.
When that happens, one can only hope that the individuals responsible,
including executives at the highest levels of such organizations, will
find themselves permanently out of work and/or in prison. Sadly, I
suspect that, blame redistribution being an exceptionally advanced art
in large corporations, at least some of the miscreants will escape
intact and sin against their customers again from other positions of

@_date: 2006-11-14 09:51:08
@_author: Perry E. Metzger 
@_subject: Citibank e-mail looks phishy 
I'm not sure this is the problem -- the problem may be a lack of object
lessons to provide negative reinforcement.
Every twenty years or so, a major accounting firm implodes in a
scandal. In the 1980s it was Laventhal and Horvath. A few years ago it
was Andersen. At intervals, the institutional memory of what can go
wrong vanishes, someone pushes the edge, and it takes a bit of blood
in the streets for people to remember why they were supposed to
follow the rules. (By the way, this is a good reason why people should
oppose the reduction of individual liability for partners in
accounting firms -- it is an important check on accounting scandals.)
At intervals, there are also major explosions in other parts of
finance. For example, everyone remember how Barings melted down
because of lax controls? There have been failures of this sort at
intervals in trading operations -- Askin detonated even though it had
correct models of the CMO market because the market remained
irrational longer than it could remain liquid. Twenty years later, the
memory forgotten, Long Term Capital Management had a similar problem.
I think that failures of this sort are, for good or ill, part of the
natural order of things. Unless there are object lessons around,
people forget what the reason for the controls. Right now, the systems
technologies in use are too new for there to have been major failures,
so many people in management do not understand why the technical
people have pushed for certain kinds of controls. I suspect the
failure of a major bank as a result of deep penetration of their
systems or some similar failure will be rather educational for the
ones that remain. Unfortunately it will also cause a lot of damage,
but I'm not sure there is any way to help this.
Some folks have said "perhaps this is a failure of regulation" but I
don't know that regulation can be made better. It is difficult for
regulators to understand all the intricacies the operations of every
firm they watch, and it is difficult in some cases for them to remain
at arms length from the people they regulate, since regulation
agencies depend on people with intimate knowledge of a given industry
who are inevitably previous insiders. There is also, inevitably, far
more lobbying by a regulated industry than by third parties, because
the regulated have a far greater incentive to shape the regulations
than outsiders do and thus spend more time and money on it.
Ultimately, I think we're going to have to see the collapse of a major
banking institution before this is dealt with.

@_date: 2006-11-17 08:31:02
@_author: Perry E. Metzger 
@_subject: RFID passport article in the UK's "Guardian" newspaper... 
Nothing deeply new here, but interesting anyway...

@_date: 2006-10-13 09:25:16
@_author: Perry E. Metzger 
@_subject: handling weak keys using random selection and CSPRNGs 
No, that is not the definition of a weak key.
Look at DES weak keys, for example. They are simply keys for which the
encryption and decryption transform are identical -- encrypting twice
with the weak key returns you to the plaintext -- but they are not in
some way obviously detectable without trying them.
Might I suggest reading the literature on this before discussing it

@_date: 2006-10-28 11:12:31
@_author: Perry E. Metzger 
@_subject: Thirty Years of Public Key Cryptography 
"Some of the world's top crypto minds shared the stage at the Thirty
 Years of Public-Key Cryptography anniversary event at the Computer
 History Museum[...]"

@_date: 2006-10-29 01:46:12
@_author: Perry E. Metzger 
@_subject: IEEE storage encryption standards 
Just got this note from the ias-opportunities list...
Return-Path: Reply-To: "Cole, John (Civ, ARL/CISD)" To all who may be interested,
The IEEE Information Assurance Standards Committee (IASC) jointly with
the Storage Systems Standards Committee (SSSC) will soon be balloting
security in storage draft standards and other IA standards.
If you are interested in becoming a balloter of one of these or other
standards, you need to taken steps soon to receive notice of impending
balloting, to be invited to ballot, and then to actually ballot these
draft standards. Please visit  to understand what these
steps are.
The draft standard that will be balloted next for IASC and SSSC is the
IEEE P1619.1 draft standard, entitled 'Draft Standard for
Authenticated Encryption with Length Expansion for Storage Devices'.
This draft was developed in the IASC Security in Storage Workgroup
(SISWG) and has support from several large tape drive and bridge
vendors (including IBM, HP, Sun, Quantum, Cisco, Decru, and Neoscale),
and will likely become a strong standard for encryption of stored
Other projects of IASC and SISWG may be viewed at
 which includes links to the project
authorizations (PARs) that describe the scopes and purposes of each.
One of these, IEEE P1667, Authentication of Transiently Connected
Storage Devices, was balloted in September, and is expected to be
approved as a published standard in December.
Very Respectfully,
Jack Cole
IASC Chair

@_date: 2006-09-08 10:42:49
@_author: Perry E. Metzger 
@_subject: Enigma cracking machines reconstructed 
LONDON (Reuters) - A code-cracking machine that enabled Britain to
  read Nazi military ciphers during World War Two has been rebuilt by
  enthusiasts after a 10-year project.

@_date: 2006-09-22 09:42:03
@_author: Perry E. Metzger 
@_subject: interesting HMAC attack results 
Cryptology ePrint Archive: Report 2006/319
Forgery and Partial Key-Recovery Attacks on HMAC and NMAC Using Hash Collisions
Scott Contini and Yiqun Lisa Yin
  Abstract. In this paper, we analyze the security of HMAC and NMAC,
  both of which are hash-based message authentication codes. We present
  distinguishing, forgery, and partial key recovery attacks on HMAC and
  NMAC using collisions of MD4, MD5, SHA-0, and reduced SHA-1. Our
  results demonstrate that the strength of a cryptographic scheme can be
  greatly weakened by the insecurity of the underlying hash function.
[I Heard about this paper from ekr's blog.]

@_date: 2007-04-03 19:43:36
@_author: Perry E. Metzger 
@_subject: WEP cracked even worse 
Not that WEP has been considered remotely secure for some time, but
the best crack is now down to 40,000 packets for a 50% chance of
cracking the key.

@_date: 2007-04-17 12:24:36
@_author: Perry E. Metzger 
@_subject: Voynich manuscript proven a hoax (yet again). 
Apparently the latest issue of Cryptologia will carry an article that
has done yet another statistical analysis of the Voynich manuscript,
and which claims that the manuscript's text statistics are consistent
with it being a hoax.

@_date: 2007-04-24 20:14:07
@_author: Perry E. Metzger 
@_subject: Training your customers to be phishing victims, part umpteen. 
The following is a real email, with minor details removed, in which
J.P. Morgan Chase works hard to train its customers to become phishing
I've left in the name that the email was sent under -- I see no reason
to protect the guilty. The original version of the email was multipart
alternative, with an HTML version that is, believe it or not, even
worse than the text version.
I've been watching Chase operate like this for a few years now, and
every time I think they've hit the bottom of the ocean of misguided
behavior, they come out with a new demonstration that there are new
depths yet to dive to.
Reply-to: ChaseBusinessBanking.XXXXXXXXXXX at reply.chase.com
We're working to better serve your business needs!
Dear Business Customer, We're updating our records and need your help to ensure we have the most up-to-date information about your business. This is an important step in ensuring that we can continue to provide you with timely and accurate information about your accounts.
Go here to answer a couple of questions about your business It will take you less than 60 seconds, and then you're done! And remember, the more we know your business, the better we can serve your ever-changing needs.
Thanks for choosing Chase.
Janet M. Hawkins
Chief Marketing Officer
Business Banking
ABOUT THIS MESSAGE
TO UNSUBSCRIBE from future promotional e-mails from Chase, please reply to this e-mail and type "UNSUBSCRIBE" in the "Subject" line. The e-mail address from which you send the request will be removed from our e-mail list. Please allow ten business days for us to process your request. You will continue to receive service related e-mail messages that concern your existing Chase banking products and services.
If you want to contact Chase, please do not reply to this message, but instead go to  For faster service, please enroll or log in to your account. Replies to this message will not be read or responded to.
Your personal information is protected by advanced technology. For more detailed security information, view our Online Privacy Policy:  Chase Privacy Operations, 451 Florida Street, Fourth Floor, LA2-9376, Baton Rouge, LA 70801. JPMorgan Chase Bank, N.A. Member FDIC. Equal Opportunity Lender
(C) 2007 JPMorgan Chase & Co.
This e-mail was sent to: XXXXXXX at XXXXXXX.XXX

@_date: 2007-04-29 11:47:44
@_author: Perry E. Metzger 
@_subject: Cryptome cut off by NTT/Verio 
Slightly off topic, but not deeply. Many of you are familiar with
John Young's "Cryptome" web site. Apparently NTT/Verio has suddenly
(after many years) decided that Cryptome violates the ISP's AUP,
though they haven't made it particularly clear why.
The following link will work for at least a few days I imagine:

@_date: 2007-08-09 17:12:44
@_author: Perry E. Metzger 
@_subject: Susan Landau Op Ed on new NSA powers 
Selected quote:
   To avoid wiretapping every communication, NSA will need to build
   massive automatic surveillance capabilities into telephone
   switches. Here things get tricky: Once such infrastructure is in
   place, others could use it to intercept communications.
   Grant the NSA what it wants, and within 10 years the United States
   will be vulnerable to attacks from hackers across the globe, as
   well as the militaries of China, Russia and other nations.

@_date: 2007-08-22 10:17:57
@_author: Perry E. Metzger 
@_subject: more SHA-1 progress? 
Ekr's blog notes a rumor that more progress has been made on attacking SHA-1:
Anyone know anything about this?

@_date: 2007-08-29 16:17:20
@_author: Perry E. Metzger 
@_subject: FBI "point and click" wiretapping. 
The blogs of Matt Blaze, Steve Bellovin and Bruce Schneier all linked
to this article today. It is rather disturbing.

@_date: 2007-12-03 09:58:24
@_author: Perry E. Metzger 
@_subject: Flaws in OpenSSL FIPS Object Module 
I don't know if people have been following this, but it is interesting
from the point of view of studying how the FIPS process does (or does
not) interact with the underlying goal of producing assured systems.
Begin Forwarded Message:
Return-Path: The vulnerability reported earlier
( cannot be patched in the
usual way due to the requirements of the FIPS 140-2 validation program
(the CMVP).  Discussions on ways to craft a fix that will satisfy FIPS
140-2 with the least delay in approval have been underway for several days.
The situation is complicated by the fact that there is a second bug in
the FIPS 140-2 mandated continuous PRNG self-test.  This other bug does
not constitute a security vulnerability, but the CMVP understandably
requires that both bugs be corrected at the same time.  FIPS 140-2 has
the concept of an algorithm boundary around each separate algorithm
implementation in addition to the overall crypto module boundary.
Changes to code inside an algorithm boundary require considerably more
time and effort for approval.  We can implement a workaround for the
CVE-2007-5502 vulnerability outside of any algorithm boundary, but
cannot do the same for the self-test bug.
As a consequence approval of a new distribution will take longer.  How
long is hard to estimate, perhaps as little as a couple of weeks.
In the meantime the CMVP has effectively revoked the current v1.1.1
by declaring the PRNG as non-compliant.  Since essentially all
cryptographic applications utilize a PRNG the entire v1.1.1 module is
for all practical purposes revoked as well.  This means vendors of
software products using or based on the v1.1.1 PRNG will need to be
patched or updated with the new v1.1.2 of the OpenSSL FIPS Object Module
once that becomes available.  It would be prudent to anticipate
additional quasi-revocations of other validations for products derived
from the v1.1.1 baseline.
-Steve M.

@_date: 2007-12-10 14:41:51
@_author: Perry E. Metzger 
@_subject: Call for Participation: FC 2008 
Begin Forwarded Message:
Reply-To: Radu Sion Dear Colleague,
This is a call for participation to the Financial Cryptography
and Data Security Conference in Cozumel, Mexico, 28-31 January,
2008 ( Financial Cryptography and Data
Security is a major international forum for research, advanced
development, education, exploration, and debate regarding
information assurance in the context of finance and commerce.
The conference covers all aspects of securing transactions and
systems. For more details including accepted papers and invited
speakers, please see Free Child Care
We are happy to offer free child care as part of the conference.
The hotel offers a kids' club, with supervised childcare and
activities from 9am to 5pm for children of age 5-12 whose
parents are somewhere on the premises (in the conference room is
fine). This is free of charge for hotel guests. Baby-sitting is
available for US$5 per child per hour. Additionally, as part of
the room rate for conference attendees, children of age 0-12 are
free of charge (including food).
We apologize if you receive multiple copies of this message. We
did our best to avoid this. Moreover, please let us know asap if
you would like to be removed from this mailing list -- we would
not like you to perceive this as spam. Please help us distribute
this to other interested colleagues.
Best Regards,
Financial Cryptography and Data Security 2008 Organizers

@_date: 2007-12-15 10:03:56
@_author: Perry E. Metzger 
@_subject: Judge rules defendant need not disclose encryption keys. 
Imagine the government seizes a suspect's hard drive and finds
     encrypted files inside. Can the government force the suspect to
     enter in his encryption passphrase so the government can view the
     decrypted files? Or does the Fifth Amendment privilege give the
     suspect a legal right not to enter in the passphrase? On November
     29, Magistrate Judge Jerome Niedermeier in Vermont handed down
     the first opinion to squarely address the issue: In re Boucher.
[Hat tip to Eric Rescorla's blog.]

@_date: 2007-02-15 14:53:42
@_author: Perry E. Metzger 
@_subject: quantum computer demonstrated, maybe. 
The most interesting bit of the article:
   And how exactly would users know that it was the quantum computer
   rather than a human or ordinary computer answering their queries?
   "There's really no way to convince a skeptic who's accessing the
   machine remotely," Rose admits. For now, D-Wave's device is slower
   than an inexpensive home computer, but Rose says a potentially faster
   1,000-qubit version should be available by the end of next year. One wonders if the quote is remotely accurate.

@_date: 2007-02-15 15:02:08
@_author: Perry E. Metzger 
@_subject: ADMIN: end of email discussion 
I'm happy to forward more messages on security and email, but the
messages just on email vs. IM etc. are way off topic.

@_date: 2007-01-05 00:23:20
@_author: Perry E. Metzger 
@_subject: Tamperproof, yet playing Tetris. 
Handheld "Chip & Pin" terminals for reading credit cards in the UK are
required to be tamperproof to avoid the possibility of people
suborning them. Here is a report from a group that has not merely
tampered with such a terminal, but has (as a demo) converted it into a
tetris game to demonstrate that they can make it do whatever they

@_date: 2007-01-12 15:06:22
@_author: Perry E. Metzger 
@_subject: Banking Follies 
As many people here are aware, one of my least favorite banks,
especially in terms of system security, is Chase.
Today I received an email message from Chase informing me that I'd
gotten a brand new hotel rewards program branded Visa card from them,
and inviting me to click on various links to set up my internet access
to the account, and inviting me to call a particular phone number to
activate the account.
Unfortunately, I had never applied for such an account. The name in
the email was also not my name, and the email was also sent to an
account I never give out to anyone.
A detailed examination of the email made it appear genuine, though of
course one can never know. (Chase's credit card operations send
similar emails all to customers all the time, including links to click
on, training their customers to become victims of phishing while
carefully explaining to them that they should be very careful about
phishing. Chase also has the bad habit of sending their security
critical emails through third party providers -- in this case
"bigfootinteractive.com" was in the path the mail took, though past
experience tells me this alone does not mean the mail is
fraudulent. Thank you, Chase, for making it so easy for people.)
It was possible that the mail in question was purely fraudulent, but
one couldn't really know. I suspected it was more likely that Chase
had either sent the email to the wrong place or that a particularly
stupid person had given the wrong email address to Chase when applying
for the card and that it happened to be one of mine by accident.
(Note to banks: 1) Always require round trip confirmations before
accepting an email address for an account holder. 2) Never send anyone
email inviting them to click on things, period. In fact, you probably
shouldn't be sending people email. 3) Study what Chase does carefully
and send out reports internally saying "don't let this happen to us.")
Now, here I am, either the subject of phishing, the victim of some
sort of identity theft (possible but not likely) or in possession of
important information that would allow me to commit credit card
fraud. As an honest person, my reaction is to call the bank.
Unsurprisingly, Chase's "confirm that you have gotten your credit
card" number has a small bug. It really doesn't want to allow you to
report that something is wrong, it only wants to let you report that
everything is okay. One wonders at a "confirm you got your card" phone
number where you can't easily report a problem but only success -- it
certainly isn't brilliant security design.
By pretending to not have a touch tone phone (I'm sure that trick to
get to a person will end when they put voice recognition on the line) I
managed to eventually get through to a live sentient being, but sadly
the human in question was not really well equipped to speak with other
humans -- in particular, beyond the fact that this person was
remarkably unintelligent, he was also remarkably unintelligible. By
the accent, I don't think he was in an offshore call center, but he
might as well have been.
First, he asked me what I expected him to do about the situation. Now,
generally speaking, one imagines that a bank would want to know about
such a situation, but this being Chase I suppose I should not have
been surprised at the quality of personnel training involved.
When I explained that I thought that perhaps the bank would be
interested in preventing fraud, he then asked that I give him all my
personal information, even though I explained that not only was I
suspicious enough under the circumstances that I didn't want him to
have my social security number, but also that I thought it was
unlikely that the card in question had my social security number
attached to it. After a few passes back and forth, I asked to speak to
his supervisor, which after a number of minutes on hold didn't
happen. Then finally he transferred me to an anti-fraud department.
The anti-fraud group seemed to be at least slightly more on the ball,
but kept insisting on things like knowing my zip code when I was
pretty sure my zip code would not be attached to the card in
question. After I carefully guided the phone agent through doing a
the database query, she finally located the card in question, which
may or may not be legitimate but which (we established by checking a
couple of digits) was not associated with my address, name or social
security number. I suggested to her that she might want to have the
account frozen, but she declined, and said that someone would simply
contact the card holder. "Not my problem any more", I said, and we
ended the call.
I suppose the lesson of all of this is that security is hard, and a
security system that depends on large numbers of telephone center
representatives to function is probably a bad idea. There are several
ways that this could have been avoided, and that the entire problem
could, in fact, have been avoided -- Chase could have avoided
attaching an unconfirmed email address to a new account, Chase could
have provided a way for people to unconfirm rather than confirm cards
on their 800 number, etc.
However, all that is secondary. The real problem is that Chase, as
well as many other banks, doesn't appear to make security a high
priority in their operations. It is perhaps wrong of me to constantly
pick on Chase, but since I constantly get new reminders, often
unbidden as in the current instance, of how badly they operate, I
think they make an excellent example of how not to run things.
"Don't let this happen to you."

@_date: 2007-01-16 13:51:00
@_author: Perry E. Metzger 
@_subject: encrypting files with lots of different keys 
I think that usability would make any such scheme outright
impractical. People can't keep track of one key -- keeping track of a
dozen would be rather difficult. Perhaps there are marginal benefits
to being able to use different policies for different parts of the
system, but it seems to me that the problems would far outweigh any
benefits. This is doubly true in a single user environment where there
is no issue with different subsets of users needing to see different
subsets of the data.
It is far simpler to simply use whatever key refreshment policy makes
sense for the most secure information on the file system and to use
one key. A system that is actually used beats a "better" system that
is never used every time.

@_date: 2007-01-18 17:13:26
@_author: Perry E. Metzger 
@_subject: Private Key Generation from Passwords/phrases 
So you're saying Chaitin-Kolmogrov information and other ways of
studying entropy are "wrong"? I think that's a bit unreasonable, don't
There are different definitions that are useful at different
times. Fundamentally, mathematics provides us with models, which are
sometimes applicable to a particular practical problem, and sometimes
are not applicable. It is dangerous to forget that. When you do, you
get things like "proofs of security" based on inapplicable models, and

@_date: 2007-01-23 09:24:30
@_author: Perry E. Metzger 
@_subject: "Free WiFi" man-in-the-middle scam seen in the wild. 
For years, I've complained about banks, such as Chase, which let
people type in the password to their bank account into a page that has
been downloaded via http: instead of https:.
The banks always say "oh, that's no problem, because the password is
posted via https:", and I say "but that's only if the page comes from
*you*, and it might come from a bad guy."
"How would someone possibly send the user a faked up web page?" they
then ask. I reply like this "the two obvious ways are DNS cache
contamination and doing a man-in-the-middle in the network, and the
latter is really easy now that people trusting WiFi base stations in
strange places that they've never used before. You could just put a
tiny box near a cafe or airport lounge and siphon off passwords day
and night."
The bank people then tell me that I'm crazy. (They're usually more
polite than that, but that's the import of what they say.) I have a
great letter from a manager at Chase informing me that they've been
assured by fabulous security people that their system is safe.
Adding insult to injury, the banks put a little padlock GIF on their
insecure form, probably to reduce the number of phone calls they get
about it.
Well, guess what. It turns out that people are now deploying
man-in-the-middle WiFi devices in places like airports and siphoning
passwords for bank accounts.
Who would have thought of such a nefarious thing? Certainly this is a
new problem and one no would have thought of it before now...:
   January 19, 2007 (Computerworld) -- The next time you're at an airport
   looking for a wireless hot spot, and you see one called "Free Wi-Fi"
   or a similar name, beware -- you may end up being victimized by the
   latest hot-spot scam hitting airports across the country.
   You could end up being the target of a "man in the middle" attack, in
   which a hacker is able to steal the information you send over the
   Internet, including usernames and passwords. And you could also have
   your files and identity stolen,[...]
(Incidently, the article gets a few things wrong. It somewhat implies
that you are safe if you pick a WiFi network you have a previous
relationship with, which isn't true.)
Just to pick on my favorite exemplar of how not to do things for a
moment, go over to:
and ponder how it could be that a giant multinational financial
institution could set its customers up this way.
If you go over to, say,  you will find that you can't
even get to the http: version of the page any more -- you are always
redirected to the https: version. For the record, Fidelity has gotten
this right for as long as I've been watching them.
Now you might wonder, why do I keep picking on Chase?
A certain other security person and I had an extended argument with
the folks at another company I won't name other than to say that it was
American Express. At the time, they more or less said, "yah, this is a
problem, but fixing it is going to be a pain." However, I'll note that
now, as with Fidelity, you pretty much can't go onto their web site
without using https: -- kudos to Amex.
Indeed, though this was all a major problem a couple of years ago with
many banks, many have now fixed it. However, for a select few, like,
say, Chase, the message simply isn't getting through even though these
organizations have been repeatedly informed that they are leaving
their customers vulnerable. One wonders what level of trouble they're
going to have to get into before they actually do the right thing.

@_date: 2007-01-23 10:34:57
@_author: Perry E. Metzger 
@_subject: "Free WiFi" man-in-the-middle scam seen in the wild. 
And for the six people that know to do that, it works great. :)
It used to be that Verizon (my local phone company, sadly) had this
general problem but you could click on "log in" and it would direct
you to a secure page with a little error message and you could then
enter your username and password. They've since "fixed" that so it is
no longer possible to log in safely to their web site at all.

@_date: 2007-01-23 16:34:02
@_author: Perry E. Metzger 
@_subject: more on NIST hash competition 
In addition to the URL Steve sent earlier, there is a web page up for
the NIST hash competition:

@_date: 2007-01-24 16:29:29
@_author: Perry E. Metzger 
@_subject: "IEEE 1667" approved 
Forwarded message:
Reply-To: "Jack Cole" IEEE Press Release at
IEEE 1667, "Standard Protocol for Authentication in Host Attachments
of Transient Storage Devices", was approved December 5, 2006.
Transiently-connected storage devices include devices in wide use such
as USB flash drives, mobile phones, PDAs, and mp3 players. This
standard impacts secure uses of such devices in, for example,
important economic areas employing mobile phones for ordinary
commercial transactions, now common in Asian and European countries.
IEEE 1667 is sponsored by the Computer Society with the Information
Assurance Standards Committee (IASC) leading a joint project with the
Storage Systems Standards Committee (SSSC) and supported by the Task
Force on Information Assurance (TFIA) and the Mass Storage Systems
Technical Committee (MSSTC).
This is the first Information Assurance standard to be published by
the IEEE, and is one of several projects being developed through the
combined efforts and support of IEEE Computer Society standards and
technical committees with expertise in complementary information
technology areas.
Jack Cole
Chair, Information Assurance Standards Committee
Please forgive receipt of duplicates.
Multiple lists with overlapping subscriptions were used.

@_date: 2007-01-26 15:50:43
@_author: Perry E. Metzger 
@_subject: study shows "extended validation" TLS certs ineffective 
Abstract. In this usability study of phishing attacks and browser
   anti-phishing defenses, 27 users each classfied 12 web sites as
   fraudulent or legitimate. By dividing these users into three
   groups, our controlled study measured both the effect of extended
   validation certicates that appear only at legitimate sites and the
   effect of reading a help file about security features in Internet
   Explorer 7. Across all groups, we found that picture-in-picture
   attacks showing a fake browser window were as effective as the best
   other phishing technique, the homograph attack. Extended validation
   did not help users identify either attack. Additionally, reading
   the help file made users more likely to classify both real and fake
   web sites as legitimate when the phishing warning did not appear.

@_date: 2007-07-01 08:38:12
@_author: Perry E. Metzger 
@_subject: The bank fraud blame game 
I've been thinking this was the way to go for years now.

@_date: 2007-07-01 16:01:03
@_author: Perry E. Metzger 
@_subject: The bank fraud blame game 
Of course, given the magnitude of costs of fraud, and where it may be
heading in the near term, the $50 a year may be well spent, especially
if it could be cut to $25 with some UI investment. It is all a
question of whether you'd rather pay up front with the security
apparatus or after the fact in fraud costs...

@_date: 2007-07-03 11:09:25
@_author: Perry E. Metzger 
@_subject: Using crypto to prevent printer cartridge ink refills 
Cryptography Research Inc. (CRI), a San Francisco company, is
    developing chip technology aimed at helping printer manufacturers
    protect this primary source of profit. The company's chips use
    cryptography designed to make it harder for printers to use
    off-brand and counterfeit cartridges.

@_date: 2007-07-05 14:42:28
@_author: Perry E. Metzger 
@_subject: How the Greek cellphone network was tapped. 
A fascinating IEEE Spectrum article on the incident in which lawful
intercept facilities were hacked to permit the secret tapping of
the mobile phones of a large number of Greek government officials,
including the Prime Minister:
Hat tip: Steve Bellovin.

@_date: 2007-07-06 20:46:05
@_author: Perry E. Metzger 
@_subject: Appeals court orders dismissal of NSA domestic surveillance suit. 
WASHINGTON (CNN) -- A federal appeals court Friday ordered the
   dismissal of an ACLU lawsuit challenging President Bush's domestic
   surveillance program.
Hat tip: Steve Bellovin

@_date: 2007-07-17 13:12:14
@_author: Perry E. Metzger 
@_subject: How the Greek cellphone network was tapped. 
I think this is a slight overstatement.
If security on login connections was expensive, difficult, or not part
of the common infrastructure, everyone would still be using plaintext
passwords over telnet. However, ssh is just as easy or in fact easier
to use then telnet/ftp/etc., so that it has become
If using secure phones was as cheap and easy as using insecure ones,
everyone would do it. They just won't go out of their way to do
it. The market will happily accept a new feature that is free and
zero complexity in use. It is well within technical possibility to
create such a thing -- the issue is purely political.

@_date: 2007-07-19 09:38:03
@_author: Perry E. Metzger 
@_subject: ADMIN: SSH discussion shut down 
The SSH discussion has (in messages I didn't forward) rapidly
degenerated into an argument that isn't very high signal. I'd suggest
that the non-crypto aspects are best discussed on other mailing lists
like the IETF SSH working group lists and the OpenSSH developers
mailing list. If there are specific cryptographic flaws in the
protocol, I'd say they are fair game if the discussion is clear, brief
and dispassionate.

@_date: 2007-07-19 18:54:27
@_author: Perry E. Metzger 
@_subject: Yahoo + iPhone = replay attacks 
A blog entry which claims that the proprietary "Push IMAP" protocol
that Apple and Yahoo came up with is deeply flawed -- the entry states
that the entire thing is vulnerable to trivial replay attacks.
Hat tip: Marshall Rose
If true, this is yet more evidence for the ancient hypothesis that it
is foolish to roll your own security protocols.

@_date: 2007-06-22 10:25:16
@_author: Perry E. Metzger 
@_subject: interesting paper on eprint archive 
The consensus from a few of my friends is that this paper (by
Warren Smith) is a bit eccentrically written but not obviously
flawed. Whether it is of any practical importance at all remains to be
seen -- there may be no way to apply the results.
     Abstract. We describe a new simple but more powerful form of linear
     cryptanalysis. It appears to break AES (and undoubtably other
     cryptosystems too, e.g. SKIPJACK). The break is ``nonconstructive,''
     i.e. we make it plausible (e.g. prove it in certain approximate
     probabilistic models) that a small algorithm for quickly determining
     AES-256 keys from plaintext-ciphertext pairs exists -- but without
     constructing the algorithm. The attack's runtime is comparable to
     performing $64^w$ encryptions where $w$ is the (unknown) minimum
     Hamming weight in certain binary linear error-correcting codes
     (BLECCs) associated with AES-256. If $w < 43$ then our attack is
     faster than exhaustive key search; probably $w < 10$. (Also there
     should be ciphertext-only attacks if the plaintext is natural English.)

@_date: 2007-06-22 11:04:47
@_author: Perry E. Metzger 
@_subject: Quantum Cryptography 
"Quantum cryptography" is useless. Victor is completely correct here.
Quantum crypto provides you with a slow way of getting a one time pad
(of sorts) that you cannot authenticate and thus cannot trust, between
two endpoints only, and it does it at extreme expense.
Why do I say "that you cannot authenticate"? Because although you can
tell that no one eavesdropped in on the line, you have no way of
knowing that no one cut the fiber in two and put two such boxes in
between. You know that no one eavesdropped, but not who you are
talking to. Various physics types who I explain this to generally do
not understand what I'm talking about at first blush because they only
consider the problem of eavesdropping -- the notion that you also need
to verify who the guy at the other end is never occurs to them because
they aren't security people. The fact that the attacker might not even
bother to eavesdrop and could simply insert himself into the
communication stream never occurs to the proponents.
So, to fix the man-in-the-middle problem, you have to layer an
authentication technology on top. Unfortunately, the ones we have are
all conventional crypto -- perhaps a MAC of some sort. At which point,
you're trusting conventional crypto for your security, so why bother?
Conventional crypto is nearly free.
This brings up another issue.  Quantum crypto is exceptionally
expensive, and is virtually undeployable. To provide security that, in
a practical sense, is no better than what you can get from high key
length conventional ciphers, you spend vast amounts on end system
equipment, rent a dedicated dark fiber link between two locations that
can't be arbitrarily far apart, and in the end, you have two machines
that can talk securely in a world where one needs thousands or
millions of machines to talk securely to any one of the other
machines. The phone network and internet exist for a reason -- people
want communication networks, not a string between two cans between
each other's homes. They need NxN communication, not 1-1
communication. Building the N^2 array of dark fibers and quantum
crypto boxes between lots of machines is, of course, utterly
impractical and always will be. Of course, even if you could, you
would still need out of band key distribution and a MAC to know that
no one had man-in-the-middled your links. Again, why bother?
Now, lets consider the alternative. In a practical sense, no one
rational worries on a day to day basis that their security is going to
be compromised because someone has a magic box that decrypts 256 bit
AES in 12 seconds flat. The crypto we already have is more than good
enough. Quantum Crypto exists on the mistaken premise that people are
worried about their ciphers being broken and that this is the main
issue in security. It is not. Having your ciphers broken is not even
remotely the main issue for most installations.
What people worry about in the real world are design flaws,
programming errors, human interface problems that make things like
phishing possible, and whether or not the $12-an-hour security guard
at your data center will happily take a $5000 bribe to let someone at
your equipment for an hour. Quantum Key Distribution solves none of
those issues at all. The issue it does solve is a non-issue -- we
already have 256 bit keyed AES if you need it.
Quantum Crypto does what it says it does, but it is a commercially
worthless invention, like an 800 pound wristwatch that is 20% more
accurate than normal wristwatches but which is completely wrong one
day in seven, or like a $20,000,000 tube of toothpaste that tastes
slightly better but causes your teeth to explode one time in every
400. Even if the watch is marginally more accurate, no one will wear
it. Even if the toothpaste tastes slightly better, no one will buy
it. Neither invention solves a real problem from the real world.
Quantum Crypto was invented by physicists who understand physics well
but have no understanding of security. It does what it claims to do,
but what it claims to do is of no use to anyone. Quantum Crypto does
nothing for at all for the things people actually need solved, and
for what it does do, it costs vastly too much. It is a lead balloon, a
jet powered toast buttering machine, an electronically controlled
salad fork.
What continues to amaze me is that, none the less, people continue to
spend time and money on this. I can understand finding the technique
theoretically interesting, and perhaps even someday someone will think
of a way to use the ideas in a system of practical use, but there are
companies out there like MagiQ trying to sell the solid gold covered +
barbed wire seat commodes to people.

@_date: 2007-06-22 12:12:35
@_author: Perry E. Metzger 
@_subject: Quantum Cryptography 
If it cost almost nothing, it would be a neat frill to have. When it
increases the cost of encrypting a link by a factor of four to six
orders of magnitude while still requiring all the old security systems
you had before, it is pretty uninteresting.
Indeed it does. We have a lot of experience with securing links that
go for hundreds of km, and the experience tells us that we can't do it
in the real world. It would be one thing if experience said that
attackers can be easily found and stopped on long range physical
links, but we know that they can't, so why are we even thinking about
it this way?
Besides, companies like MagiQ don't say "we're giving you
unconditional security against eavesdropping provided your prayers
that no one MITMs you are granted", they claim that they are providing
you with actual unconditional security. They clearly are not.
As you know, most of us argue you should simply assume you're being
eavesdropped on and design security so that you don't care. It is much
simpler, much less expensive, and much more robust.

@_date: 2007-06-22 16:13:25
@_author: Perry E. Metzger 
@_subject: Quantum Cryptography 
Key exchange is not "the toughest part" or even tough at
all. Algorithms like Diffie-Hellman and variants on the theme work
just fine. Authenticated protocols based on these algorithms are well
understood and have been studied for defects for many years.
The STS protocol and variants on it like the ones used in TLS are
fine, and if you feel that they're "not secure enough" with the number
of bits commonly used, you can crank up the dial for a lot less than
the cost of one of these mind-bogglingly expensive boxes from MagiQ
(not to mention the price of dedicated dark fiber between the
I don't believe that any of the commercial units work that way, but if
they do, my opinion of them has dropped even further, and it was
already about as low as I thought was possible. Using QKD only for key
exchange and using a conventional crypto system for the bulk of the
data completely eliminates any conceivable benefits over more
conventional techniques.

@_date: 2007-06-25 14:58:48
@_author: Perry E. Metzger 
@_subject: Financial Cryptography CFP 
Reply-To: Radu Sion Dear Colleague,
This is an advanced call for papers for the Financial Cryptography and Data Security Conference in Cozumel, Mexico, 28-31 January, 2008 (
Financial Cryptography and Data Security is a major international forum for research, advanced development, education, exploration, and debate regarding information assurance in the context of finance and commerce. The conference covers all aspects of securing transactions and systems. Submissions focusing on both fundamental and applied real-world deployments are solicited. This year, for the first time, we are also accepting submissions for posters and short papers. The poster session is the perfect venue to share a provocative opinion, interesting established or preliminary work, or a cool idea that will spark discussion. Poster presenters will benefit from a multi-hour session to discuss their work, get exposure, and receive feedback
from attendees. The intention behind short papers
(peer-reviewed) is to encourage authors to introduce work in progress, novel applications and corporate or
industrial experiences. Short papers will be evaluated with a focus on novelty and potential for sparking participants' interest and future research avenues.
Submission: 25 September Posters: 13 November Panels: 13 November Program Chair: Gene Tsudik, UC Irvine
General Chair: Radu Sion, Stony Brook
Local Arrangement Chair: Rafael Hirschfeld, Unipay
Poster Chair: Bogdan Carbunar, Motorola Labs
Program Committee
N. Asokan, Nokia Research
Giuseppe Ateniese, Johns Hopkins University
Nikita Borisov, University of Illinois, Urbana-Champaign
George Danezis, Katholic University of Leuven
Stefan Dziembowski, University of Rome
Kevin Fu, University of Massachusetts, Amherst
Philippe Golle, PARC
Dieter Gollmann, Technical University of Hamburg-Harburg
Aggelos Kiayias, Univeristy of Connecticut
Javier Lopez, University of Malaga
Arjen Lenstra, Swiss Federal Institute of Technology Lausanne
Ninghui Li, Purdue University
Patrick McDaniel, Pennsylvania State University
Alessandro Mei, University of Rome
Refik Molva, Eurecom Institute
Pino Persiano, University of Salerno
Ahmed Sadeghi, University of Bochum
Michael Szydlo, Akamai Technologies
Suzanne Wetzel, Stevens Institute of Technology For more details please see We apologize if you receive multiple copies of this message. We did our best to avoid this. Please help us distribute this to other interested colleagues.
Best Regards,
Financial Cryptography and Data Security 2008 Organizers

@_date: 2007-06-27 12:53:19
@_author: Perry E. Metzger 
@_subject: History, context, QKD and the Internet 
The issue isn't the speed of the QKD systems, or the distance that
they run over. Those are false issues. The issue is that they
provide you with much less than conventional technologies give you,
and at a high price.
1) No one is contending that QKD doesn't work as advertised per
   se. The problem is that the advertised functionality is not what
   anyone wants.
2) The technology is a lead balloon. It gives you nothing that you
   don't already have, but at an unaffordable price, and on top of it,
   it gives you *much less* than you already have -- for example, it
   is more or less useless in providing security in an internet
   context -- the internet is all about getting rid of dedicated point
   to point connections.
You remember people saying that networks would never work. (I don't
remember that kind of statement being made, but never mind.) You
encourage us to remember all the things people were negative on but
became big hits.
I encourage you to remember bubble memory, DCE, jet packs, and assorted
other technologies that went nowhere fast.

@_date: 2007-06-29 10:36:28
@_author: Perry E. Metzger 
@_subject: [forwarded] NIST documents available for public review and comment 
[Converted from HTML]
NIST has recently revised the Draft NIST Special Publication 800-38D,
which specifies the Galois/Counter Mode (GCM).  The document is
available for your review from the draft publications page on the NIST
web site,  NIST welcomes
public comments on the draft until July 30, 2007; comments may be sent
to EncryptionModes at nist.gov .
NIST announces the release of Draft FIPS 198-1, The Keyed-Hash Message
Authentication Code (HMAC). The draft FIPS 198-1 is the proposed
revision of FIPS 198.  Comments will be accepted through September 10,
2007. Comments may be sent to proposed198-1 at nist.gov with "Comments on
Draft 198-1" in the subject line. The draft is available at
NIST announces the release of Draft FIPS 180-3, Secure Hash Standard
(SHS). The draft FIPS 180-3 is the proposed revision of FIPS
180-2. Comments will be accepted through September 10, 2007. Comments
may be sent to Proposed180-3 at nist.gov with "Comments on Draft 180-3"
in the subject line. The draft is available at
Elaine Barker
National Institute of Standards and Technology
100 Bureau Drive, Stop 8930
Gaithersburg, MD 20899-8930
301-975-2911

@_date: 2007-05-01 15:53:32
@_author: Perry E. Metzger 
@_subject: can a random number be subject to a takedown? 
A lot of sites have been getting DMCA takedowns for the HD-DVD
processing key that got leaked recently.
My question to the assembled: are cryptographic keys really subject to
DMCA subject to takedown requests? I suspect they are not
copyrightable under the criterion from the phone directory

@_date: 2007-05-01 17:04:44
@_author: Perry E. Metzger 
@_subject: can a random number be subject to a takedown? 
However, a 128 bit number is not a circumvention tool, any more than
an explanation of how AACS can be attacked is a circumvention tool. A
circumvention tool would have to be something like a program or a
device that would permit circumvention, not mere description of
one. Source code to a circumvention tool is probably a sticky issue,
but the a 128 bit integer is not something you can then compile and
get a hacking tool out of.
Can one really consider publication of an integer to be circumvention?
That would indeed seem to be the case from me as well. Takedown
notices are only for copyrighted material. This is not per se a
standard takedown notice.

@_date: 2007-05-01 17:17:14
@_author: Perry E. Metzger 
@_subject: 128 bit number T-shirt? 
It would be amusing if the HD-DVD encryption key that has been the
subject of the recent pseudo-takedown notices were to show up in a
T-shirt for sale.
Now that services like Cafe Press exist, someone could start selling
such shirts almost as fast as they could put together a nice design
for one.
I sometimes filter commercial announcements, but I will happily
forward the URL to a Cafe Press shop featuring such a shirt.

@_date: 2007-05-01 20:59:42
@_author: Perry E. Metzger 
@_subject: 128 bit number T-shirt? 
[Moderator's note: Manually forwarded because of a software glitch. --Perry]
Your wish has been granted

@_date: 2007-05-01 22:05:19
@_author: Perry E. Metzger 
@_subject: 128 bit number T-shirt? 
I'd like one with "Wearing an integer is not circumvention." on the
back or some such. :)

@_date: 2007-05-02 14:15:05
@_author: Perry E. Metzger 
@_subject: The HD-DVD key fiasco 
reveals order of 50,000 hits. Doubtless soon it will be many times
that number.
When you treat the whole world, and especially your own customers, as
the enemy, eventually everyone will come to reciprocate.
Perhaps, in the words of one jurist, the constitution is not a suicide
pact. However, it has become increasingly clear that a takedown notice
can be a suicide note.
I'm not that interested in our discussing the politics of this much
further, as I think almost everyone here is in violent agreement. I'll
take interesting new postings on the topic, but the threshold for
interesting is pretty high. I would be interested in further legal
discussion of the DMCA's ability to control the publication of mere
cryptographic keys, and in further technical discussion of AACS
and similar DRM technologies.

@_date: 2007-05-02 14:32:24
@_author: Perry E. Metzger 
@_subject: AACS and Processing Key 
However, it is still fine for decrypting old disks, and thus
revelation of this sort of information ruins inventory, which is very
All cryptography is about economics. In crypto, we usually consider
what the best strategy for an attacker is in terms of breaking a
cryptosystem, but here I think the right question is what the optimal
strategy is for the attacker in terms of maximizing economic pain for
the defender. I'd be very interested in what the "optimal" strategy is
for the attacker in a system like this, and what possible changes
could be made to such a system to defeat such strategies.
At first glance, it would seem that, for the attackers, the right
strategy is not to flood the world with newly cracked keys but to
release them quite slowly. Lets say that the lifetime of the
technology in question is somewhere around ten years. Releasing one
key on the order of every two months or so -- only sixty keys in all
over the life of the technology -- would be crippling. It would render
all inventory in warehouses and the production pipeline useless, at
quite minimal cost to the attackers. The defenders then have a choice

@_date: 2007-05-02 15:07:30
@_author: Perry E. Metzger 
@_subject: Was a mistake made in the design of AACS? 
Expanding my last message to make it clearer:
Schemes like the AACS one work quite well for satellite TV broadcast
protection. In such systems, one's goal is to disable the units owned
by rogue subscribers, but the only "inventory" that one might ruin by
a key invalidation is a bit of electromagnetic radiation in transit
from the broadcast site to the subscribers. Little is lost by
performing a revocation.
An ongoing business relationship exists with the legitimate
subscribers as well, so they can receive updates in the form of
hardware tokens that are difficult to reverse engineer "quickly
enough". Further, the users of unauthorized decoders are in a bit of a
bind -- they cannot retrieve last months' broadcasts while waiting for
new keys, so if they want entertainment now they need to have a
continuous supply of keys fed in real time.
In the HD-DVD/Blu Ray case, the model is very different. End users of
hardware players have no ongoing relationship with the provider, so
one cannot be guaranteed the ability to update. All old disks sold can
be compromised, and they constitute a substantial risk, as does the
actual inventory of disks waiting to be sold. Additional economic
hardship comes from the fact that there is non-zero effort involved in
sending new masters to production houses and in tracking dead
As I noted, in the direct broadcast satellite case "slow leaks" of keys
over extended periods of time are not of much use to the end users and
are not of much damage to the system owners, but in the AACS case
"slow leaks" are actually exceptionally damaging. Were the bad guys to
release just one key every couple of months it would effectively
destroy the system.
There is also the issue of differing threat models. In a broadcast
system, you are attempting to assure that people watching the real
time broadcast are paying you money. In the high def video disk case,
you have several quite different goals from the broadcast case. One is
to enforce region encoding so that you can charge U.S. customers a
large multiple of what you charge, say, a Chinese customer for exactly
the same material. The second is to prevent people from retrieving the
content in a form they can send to their friends over the internet. A
third goal is to keep customers from being able to use content in
unplanned ways so you can up-sell them to a newer format later
on. (Note that the DRM scheme does *not* prevent actual commercial
piracy of disks, since pirates can simply press bit for bit identical
Goals one through three are all failures even if key data leaks only
quite slowly to the public. You will be just as interested in
preventing people from watching different region HD-DVDs that are
three months old as you will in preventing them from watching ones
that are only days old. You will be just as interested in preventing
people from uploading the contents of Blu Ray disks that are a few
months old as you will in preventing uploads that are from brand new
releases. On part three, the failure would be quite complete --
collectors of HD discs will be able to transfer their old discs to
their new UltraVideoPseudoPods in ten years, thus eliminating the
lucrative business of selling them content they have previously bought
in a new format.
My feeling, then, is that the entire HD protection scheme was a
miscalculation. Methods like this worked just fine for satellite TV,
and they were then applied without sufficient thinking about threat
models to a new domain where things are quite different.
This seems to me to be, yet again, an instance where failure to
consider threat models is a major cause of security failure. It is not
enough to throw clever algorithms at things -- you have to consider
what it is that you are trying to defend against specifically, and how
those algorithms will lead to the specific security goals.
I will again solicit suggestions about "optimal" strategies both for
the attacker and defender for the AACS system -- I think we can learn
a lot by thinking about it. It would be especially interesting if
there were modifications of the AACS system that would be more hardy
against "economic attacks" -- can you design the system so that slow
key revelation is not an economic disaster while still maintaining an
offline delivery model with offline players entirely in the enemy's
control? I don't think you can, but it would be very interesting to
consider the problem in detail.

@_date: 2007-05-02 16:53:50
@_author: Perry E. Metzger 
@_subject: Was a mistake made in the design of AACS? 
You can't, but I think that is more a question of the market
size. Right now there are very few HD-DVDs and Blu Ray discs on the
market, and most people have DVD drives but not HD-DVD or Blu Ray
drives. (I don't know that I've ever even seen such a drive to date,
but that will surely change in a year.) Until there is a significant
percentage of the user community with an "itch to scratch" the
software will not appear. However, it is now very clear that the
software is quite doable once people want it.
I watch DVDs all the time on my open source OS laptop using software
that depends on DeCSS. It is quite nice software -- the UI is more or
less as good as any of the Windows DVD players. (If the MPAA or DVD
copy control folk want to try prosecuting me for watching DVDs I've
bought legitimately using software they don't approve of, they are
welcome to try -- I suspect that they don't have much of chance of
I haven't used extraction software myself for real (I have no need for
it at the moment -- I don't need my DVD library online) but there are
a number of programs out there that allow you to extract the content
from DVDs to your hard drive as easily as you can do it for a
CD. They're pretty easy to find, even for Windows and OS X, and in my
tests the UIs appeared to be pretty much easy enough for an ordinary
person to use. These programs also depend on DeCSS, of course.
I doubt they'll get very far. Their best bet for suppression is to sue
a selected subset of people for publishing the process key, but beyond
bad publicity I don't see what practical benefit they might get.
Especially in the US, they may also eventually run up against the
first amendment. I know that one judge in the 2600 case believed that
"the constitution is not a suicide pact", but those were different
days. That case happened when the community was far less prepared, was
not shepherded by ideal people, and did not set a real precedent. I
think it might be harder to ramrod a similar case through the courts
now, especially given that the Supreme Court has never ruled on this,
and especially since programs like the ones I use to watch DVDs are
clear and obvious legitimate uses and can be demonstrated to and
understood even by members of the judiciary.

@_date: 2007-05-06 12:29:13
@_author: Perry E. Metzger 
@_subject: AACS and Processing Key 
I'm making a somewhat different point.
When doing analysis of attacks on an algorithm or protocol, one
considers the "worst" thing the attacker can do, not the "most likely"
thing the attacker could do. It is true that the real attacker might
(or might not) do the "worst" thing, but I think that is not the
correct way to analyze the properties of the system.
My main claim here was that in addition to examining the best moves
the attacker and defender can make on the level of breaking/defending
the system on a technical level, one should also consider the economic
impact of their respective strategies. The fact that the attacker
could do things like timing disclosures of keys to maximize losses
seems quite significant to me.
If we are willing to demand that a cipher defend against things like
known and chosen plaintext attack even if such attacks might be very
difficult to conduct in some circumstances, I think we should also
consider things like the economic effects an attacker could inflict
upon the defenders in a DRM system, especially if the attacker suffers
no marginal cost in picking a more economically damaging attack.
It would be desirable for a system to permit defense against such an
attack, because the defender cannot control the actions of the
attacker and presumably wishes to be safe even if the attacker is
motivated to do maximum damage, or by chance happens to do maximum
damage. For example, one should not have the security of the system
rely upon the attackers choosing to release keys at random rather than
at times that maximize inventory losses, because the attackers can
alter the timing of key revelations at no marginal cost.
Many people think of it as valid for a system to depend on an attacker
needing extreme resources to conduct an attack -- many smart card
systems work this way. We therefore already incorporate economics into
our analysis. In cases like DRM, I think it is equally valid to
consider different strategies an attacker who already has broken or
partially broken a system might choose to use to cause maximum
economic impact.

@_date: 2007-05-19 17:01:03
@_author: Perry E. Metzger 
@_subject: 0wned .gov machines (was Re: Russian cyberwar against Estonia?) 
I've heard nothing formal, but my strong understanding is a lot of US
government machines, at least if we're talking workstations on
non-classified nets, are in fact "0wn3d" at this point. This should
not be entirely surprising as I have heard informally that a
considerable fraction of the machines at Microsoft have been suborned
as well, and if Microsoft can't keep the bots off of their Windows
machines, who can?
What is interesting to me is that, even though things have nearly
gotten as bad as they could possibly get, we still have seen very
little real effort made to improve systems security (at least in
comparison with what is necessary to make a big dent).

@_date: 2007-05-19 22:57:25
@_author: Perry E. Metzger 
@_subject: 0wned .gov machines 
I don't know what their methodology is, or what their numbers
mean. Without more information on that, I have little reason to
trust their claims.

@_date: 2007-05-21 14:44:28
@_author: Perry E. Metzger 
@_subject: 307 digit number factored 
Quoting the original article:
   A mighty number falls
   Mathematicians and number buffs have their records. And today, an
   international team has broken a long-standing one in an impressive
   feat of calculation.
   On March 6, computer clusters from three institutions \u2013 the
   EPFL, the University of Bonn and NTT in Japan -- reached the end of
   eleven months of strenuous calculation, churning out the prime
   factors of a well-known, hard-to-factor number that is a whopping
   307 digits long.
   "This is the largest 'special' hard-to-factor number factored to
   date," explains EPFL cryptology professor Arjen Lenstra. (The
   number is 'special' because it has a special mathematical form --
   it is close to a power of two.) The news of this feat will grab the
   attention of information security experts and may eventually lead
   to changes in encryption techniques.
My take: clearly, 1024 bits is no longer sufficient for RSA use for
high value applications, though this has been on the horizon for some
time. Presumably, it would be a good idea to use longer keys for all
applications, including "low value" ones, provided that the slowdown
isn't prohibitive. As always, I think the right rule is "encrypt until
it hurts, then back off until it stops hurting"...

@_date: 2007-05-24 13:01:03
@_author: Perry E. Metzger 
@_subject: 307 digit number factored 
Although I agree that key cracking is not a threat we should concern
ourselves with by a long shot, that does not mean that changing to
larger keys is not cost effective. This is because larger keys are
essentially free -- it costs no more (for most applications) to
generate a 2048 bit key than a 1024 bit key, so there is no incentive
not to. However, I violently agree that no one should be under the
illusion that longer keys will protect them from the most realistic
security threats. (For those applications where longer keys actually
will cost significantly and the value of the keys is low, the
calculation changes and there is little or no reason to upgrade.)
https with X.509 certs is not the only application of RSA keys, of
course. There are a significant number of applications where the keys
actually do work reasonably effectively, and the real threat is not
phishing but code bugs. Still, in spite of the fact that no one is,
say, formally validating openssh, it costs nothing to request a 2048
bit key instead of a 1024 bit key, and I'm not sure it is a bad idea
to do that on an opportunistic basis.
Even for https, it costs no more to type in "2048" than "1024" into
your cert generation app the next time a cert expires. The only
potential cost is if you're so close to the performance line that
slower RSA ops will cause you pain -- otherwise, it is pretty much
costless. For average people's web servers most of the time,
connections are sufficiently infrequent and RSA operations are "fast
enough" that it makes no observable difference.
I'm not sure I entirely buy the argument. Certainly there are other
far more (overwhelmingly more) important issues, and certainly a steel
door helps little in a tissue paper wall, but that is no reason to let
the door slowly rust away while you rebuild the wall, especially if
protecting it from rust is literally effortless.
At the same time, I'll agree that reading this argument is itself
probably more expensive than the benefit longer key length is likely
to provide someone in the near future.

@_date: 2007-11-16 18:37:50
@_author: Perry E. Metzger 
@_subject: google as password cracker 
Need to invert an MD5 hash? Try googling for the hash value:

@_date: 2007-10-10 19:48:41
@_author: Perry E. Metzger 
@_subject: Dan Bernstein's DAG tools 
Dan Bernstein has been experimenting with tools that draw Directed
Acyclic Graphs of crypto algorithms:
Hat tip: Bruce Schneier's blog.

@_date: 2007-10-12 18:21:06
@_author: Perry E. Metzger 
@_subject: Yahoo! follies. 
Today's hall of shame entrant is, oddly, not a bank, but Yahoo!.
     Yahoo! Wallet. Because shopping is more fun than typing.
     o Store all your credit card, shipping and billing information.
       (Never type it in again!)
     o Easy check out at 1000s of merchants.
     o Use Wallet for purchases all around Yahoo!
     o Safe, Simple, and Secure.
     Sign up now.
        -- Earlier today, I discovered that someone had stolen my credit card
These days, it is important to test out the credit card you've stolen
somehow before using it for a big purchase. If you have physical
possession of the card, the usual means these days is to do a small
charge at a gas station. If you don't have physical possession, you
need other means. Apparently, the means by which my particular thieves
tested out their new acquisition was with the use of Yahoo!'s "Yahoo!
Wallet" facility, and this is apparently a spreading practice.
It is with no small irony that "Yahoo! Wallet" advertises itself as
"Safe, Simple and Secure".
My issuing bank shut off my card after a charge was made with "Yahoo!
Wallet". The charge was for $1. There was also a much larger
suspicious charge, but the test was apparently via "Yahoo!  Wallet".
I suggested to the guy at my issuing bank's fraud department that we
call up the "Yahoo! Wallet" people up, just to make sure the attempted
$1 charge (which Yahoo! makes and afterwards reverses to test the card
numbers they are given -- kind of them to automate that step for
fraudsters) wasn't somehow triggered by something I had done without
realizing it, and to see if we could find out anything about who had
made the charge.
The fellow at my issuing bank's fraud department thought it would do
no good, but he called up Yahoo! with me on the phone anyway, with a
sound of resignation in his voice as he did it. I later learned why he
sounded so unenthusiastic. He'd been down this route before.  "Yahoo!
Wallet"'s customer service is run out of the Philippines, and has the
same keen sense of organization, training and fraud prevention that
one might find among kindergarteners with lifelong iodine deficiency.
We were quickly informed of about four or five things by the customer
service representative, all of them mutually contradictory and some of
them frankly incomprehensible because of the mangled grammar. However,
one thing he did say consistently was that he could not release
information on the account that had been created with my credit card

@_date: 2007-10-29 21:01:03
@_author: Perry E. Metzger 
@_subject: FC 2008 call for panels and posters 
Reply-To: Radu Sion Dear Colleague,
This is a call for *** posters and panel *** submissions (published
in proceedings) for the Financial Cryptography and Data Security
Conference in Cozumel, Mexico, 28-31 January, 2008
( Financial Cryptography and Data Security is a
major international forum for research, advanced development,
education, exploration, and debate regarding information assurance in
the context of finance and commerce. The conference covers all
aspects of securing transactions and systems. Submissions focusing on
both fundamental and applied real-world deployments are solicited.
Accepted 1 page poster summaries will be published in the proceedings ! The poster session is the perfect venue to share a provocative
opinion, interesting established or preliminary work, or a cool idea
that will spark discussion. Poster presenters will benefit from a
multi-hour session to discuss their work, get exposure, and receive
feedback from attendees.
Free Child Care
We are also happy to offer free child care as part of the conference.
The hotel offers a kids' club, with supervised childcare and
activities from 9am to 5pm for children of age 5-12 whose parents are
somewhere on the premises (in the conference room is fine). This is
free of charge for hotel guests. Baby-sitting is available for US$5
per child per hour. Additionally, as part of the room rate for
conference attendees, children of age 0-12 are free of charge
(including food).
Financial Assistance for Primary Care Giver
We will also provide financial assistance to a scholar who is a
primary care giver, and who has their research paper accepted for
presentation. $750 will be awarded to pay for childcare and other
family-related expenses related to attending the conference.
Posters: 13 November Panels: 13 November Program Chair: Gene Tsudik, UC Irvine
General Chair: Radu Sion, Stony Brook
Local Arrangement Chair: Rafael Hirschfeld, Unipay
Poster Chair: Bogdan Carbunar, Motorola Labs
Publicity & Sponsorship Co-Chair: Roberto Gomez, Tecnologico de Monterrey
Program Committee
N. Asokan, Nokia Research
Giuseppe Ateniese, Johns Hopkins University
Nikita Borisov, University of Illinois, Urbana-Champaign
George Danezis, Microsoft Research, Cambridge
Stefan Dziembowski, University of Rome
Kevin Fu, University of Massachusetts, Amherst
Philippe Golle, PARC
Dieter Gollmann, Technical University of Hamburg-Harburg
Stanislaw Jarecki, UC Irvine
Aggelos Kiayias, University of Connecticut
Javier Lopez, University of Malaga
Arjen Lenstra, Swiss Federal Institute of Technology Lausanne
Ninghui Li, Purdue University
Patrick McDaniel, Pennsylvania State University
Alessandro Mei, University of Rome
Refik Molva, Eurecom Institute
Pino Persiano, University of Salerno
Ahmad-Reza Sadeghi, University of Bochum
Diana Smetters, PARC
Michael Szydlo, Akamai Technologies
Suzanne Wetzel, Stevens Institute of Technology For more details please see We apologize if you receive multiple copies of this message. We did our best to avoid this. Moreover, please let us know asap if you would like to be removed from this mailing list -- we would not like you to perceive this as spam. Please help us distribute this to other interested colleagues.
Best Regards,
Financial Cryptography and Data Security 2008 Organizers

@_date: 2007-09-01 12:35:33
@_author: Perry E. Metzger 
@_subject: Neal Koblitz critiques modern cryptography. 
A critique of modern cryptography by Neal Koblitz in "Notices of the AMS":

@_date: 2007-09-12 09:28:51
@_author: Perry E. Metzger 
@_subject: Rare 17th century crypto book for auction. 
A rare 17th century crypto book is being auctioned.
Hat tip: Bruce Schneier's blog.

@_date: 2007-09-14 20:36:05
@_author: Perry E. Metzger 
@_subject: MC Frontalot sings about encryption 
"Secrets From The Future", MC Frontalot's song about crypto:

@_date: 2007-09-15 10:31:59
@_author: Perry E. Metzger 
@_subject: iPods using cryptographic hash so they only work with iTunes? 
It appears that Apple may have altered the firmware of newer iPods so
that they require a proper cryptographic hash in the iTunesDB loaded
onto the units or they won't work. This effectively blocks people from
using third party software with an iPod, including the various
programs people use on Linux with iPods.

@_date: 2007-09-17 10:24:27
@_author: Perry E. Metzger 
@_subject: iPods using cryptographic hash so they only work with iTunes? 
And, within a few days, the open source folks have reverse engineered
it. The presence of "magic numbers" in the algorithm makes one assume
that this was intended as more than a simple hash integrity check, but
the brief time required to find them leads one to believe the
mechanism was not a very effective protection (though it isn't even
clear what it was intended to protect against.)

@_date: 2007-09-24 20:06:31
@_author: Perry E. Metzger 
@_subject: FC 2008 Call for Papers 
Reply-To: Radu Sion Dear Colleague,
This is a call for papers for the Financial Cryptography and Data
Security Conference in Cozumel, Mexico, 28-31 January, 2008
Financial Cryptography and Data Security is a major international
forum for research, advanced development, education, exploration, and
debate regarding information assurance in the context of finance and
commerce. The conference covers all aspects of securing transactions
and systems. Submissions focusing on both fundamental and applied
real-world deployments are solicited.
This year, for the first time, we are also accepting submissions for
posters and short papers. The poster session is the perfect venue to
share a provocative opinion, interesting established or preliminary
work, or a cool idea that will spark discussion. Poster presenters
will benefit from a multi-hour session to discuss their work, get
exposure, and receive feedback from attendees. The intention behind
short papers (peer-reviewed) is to encourage authors to introduce
work in progress, novel applications and corporate or industrial
experiences. Short papers will be evaluated with a focus on novelty
and potential for sparking participants' interest and future
Free Child Care
We are also happy to offer free child care as part of the conference.
The hotel offers a kids' club, with supervised childcare and
activities from 9am to 5pm for children of age 5-12 whose parents are
somewhere on the premises (in the conference room is fine). This is
free of charge for hotel guests. Baby-sitting is available for US$5
per child per hour. Additionally, as part of the room rate for
conference attendees, children of age 0-12 are free of charge
(including food).
Financial Assistance for Primary Care Giver
We will also provide financial assistance to a scholar who is a
primary care giver, and who has their research paper accepted for
presentation. $750 will be awarded to pay for childcare and other
family-related expenses related to attending the conference.
Submission: 10 October Posters: 13 November Panels: 13 November Program Chair: Gene Tsudik, UC Irvine
General Chair: Radu Sion, Stony Brook
Local Arrangement Chair: Rafael Hirschfeld, Unipay
Poster Chair: Bogdan Carbunar, Motorola Labs
Publicity & Sponsorship Co-Chair: Roberto Gomez, Tecnologico de Monterrey
Program Committee
N. Asokan, Nokia Research
Giuseppe Ateniese, Johns Hopkins University
Nikita Borisov, University of Illinois, Urbana-Champaign
George Danezis, Katholic University of Leuven
Stefan Dziembowski, University of Rome
Kevin Fu, University of Massachusetts, Amherst
Philippe Golle, PARC
Dieter Gollmann, Technical University of Hamburg-Harburg
Aggelos Kiayias, Univeristy of Connecticut
Javier Lopez, University of Malaga
Arjen Lenstra, Swiss Federal Institute of Technology Lausanne
Ninghui Li, Purdue University
Patrick McDaniel, Pennsylvania State University
Alessandro Mei, University of Rome
Refik Molva, Eurecom Institute
Pino Persiano, University of Salerno
Ahmed Sadeghi, University of Bochum
Michael Szydlo, Akamai Technologies
Suzanne Wetzel, Stevens Institute of Technology For more details please see We apologize if you receive multiple copies of this message. We did our best to avoid this. Moreover, please let us know asap if you would like to be removed from this mailing list -- we would not like you to perceive this as spam. Please help us distribute this to other interested colleagues.
Best Regards,
Financial Cryptography and Data Security 2008 Organizers

@_date: 2007-09-28 10:19:27
@_author: Perry E. Metzger 
@_subject: Call For Papers: Applied Cryptography and Network Security (ACNS) 
Organization: Department of Computer Science, Columbia University
Reply-To: "Angelos D. Keromytis" 6th International Conference on
Applied Cryptography and Network Security
Location:            Columbia University, New York City, USA
Submission Deadline: 14 January 2008 23:59:59 EST
Author Notification: 14 March 2008
General Chairs:      Angelos Keromytis & Moti Yung
Program Chairs:      Steven Bellovin & Rosario Gennaro
Publicity Chair:     Jianying Zhou
Original papers on all aspects of applied cryptography and network
security are solicited for submission to ACNS'08. Topics of relevance
include but are not limited to:
* Applied cryptography and provably-secure cryptographic protocols
* Design and analysis of efficient cryptographic primitives: public-key
  and symmetric-key cryptosystems, block ciphers, and hash functions
* Network security protocols
* Techniques for anonymity; trade-offs between anonymity and utility
* Integrating security into the next-generation Internet: DNS security,
  routing, naming, denial-of-service attacks, TCP/IP, secure multicast
* Economic fraud on the Internet: phishing, pharming, spam, and click
  fraud
* Email and web security
* Public key infrastructure, key management, certification, and
  revocation
* Security and privacy for emerging technologies: sensor networks,
  mobile (ad hoc) networks, peer-to-peer networks, bluetooth, 802.11,
  RFID
* Trust metrics and robust trust inference in distributed systems
* Security and usability
* Intellectual property protection: metering, watermarking, and
  digital rights management
* Modeling and protocol design for rational and malicious adversaries
* Automated analysis of protocols
Papers suggesting novel paradigms, original directions, or
non-traditional perspectives are especially welcome.
As in previous years, there will be an academic track and an industrial
track. Submissions to the academic track should emphasize research
contributions, while submissions to the industrial track may focus on
implementation and deployment of real-world systems. Submissions for the
industrial track must clearly indicate this in the title. Proceedings
for the academic track will be published in Springer-Verlag's Lecture
Notes in Computer Science and will be available at the conference.
Papers accepted to the industrial track will be published in a different
[IMPORTANT DATES]
   Submission Deadline:           14 January,2008 23:59:59 EST
   Author Notification Date:      14 March, 2008
   Final Version Deadline:        4 April, 2008
   Conference:                    June 3-6, 2008
[PROGRAM COMMITTEE]
   Masayuki Abe (NTT, Japan)
   Ben Adida (Harvard University, USA)
   Feng Bao (Institute for Infocomm Research, Singapore)
   Lujo Bauer (CMU, USA)
   Giampaolo Bella (University of Catania, Italy)
   Steven Bellovin, co-chair (Columbia University, USA)
   John Black (University of Colorado, USA)
   Nikita Borisov (University of Illinois Urbana-Champaign, USA)
   Colin Boyd (Queensland University of Technology, Australia)
   Dario Catalano (University of Catania, Italy)
   Debra Cook (Alcatel-Lucent Bell Labs, USA)
   Alexander W. Dent (Royal Holloway, University of London, UK)
   Nelly Fazio (IBM Research, USA)
   Marc Fischlin (Darmstadt University of Technology, Germany)
   Debin Gao (Singapore Management University, Singapore)
   Rosario Gennaro, co-chair (IBM Research, USA)
   Peter Gutmann (University of Auckland, New Zealand)
   Danny Harnik (IBM Research, Israel)
   John Ioannidis (Packet General Networks, USA)
   Markus Jakobsson (Indiana University, USA)
   Stanislaw Jarecki (University of California Irvine, USA)
   Ari Juels (RSA Laboratories, USA)
   Kaoru Kurosawa (Ibaraki University, Japan)
   Yehuda Lindell (Bar-Ilan University, Israel)
   Javier Lopez (University of Malaga, Spain)
   Jelena Mirkovic (USC/ISI, USA)
   David Naccache (Ecole Normale Superieure, France)
   Alina Oprea (RSA Laboratories, USA)
   Tom Shrimpton (Portland State University, USA)
   Jonathan Smith (University of Pennsylvania, USA)
   Angelos Stavrou (George Mason University, USA)
   Xiaoyun Wang (Shandong University, China)
   Nicholas Weaver (ICSI Berkeley, USA)
   Steve Weis (Google, USA)
   Tara Whalen (Dalhousie University, Canada)
   Michael Wiener (Cryptographic Clarity, Canada)
   Avishai Wool (Tel-Aviv University, Israel)
   Diego Zamboni (IBM Research, Switzerland)
   Jianying Zhou (Institute for Infocomm Research, Singapore)
[AUTHOR INSTRUCTIONS]
Submissions must be anonymous, with no author names, affiliations,
acknowledgments, or obvious references. Submissions should be in
English, in PDF format with all fonts embedded, typeset with 11pt font
or larger, and using reasonable spacing and margins. They should not
exceed 12 letter-sized pages, not counting the bibliography and
appendices. Papers should begin with a title, abstract, and an
introduction that clearly summarizes the contributions of the paper at a
level appropriate for a non-specialist reader. Papers should contain a
scholarly exposition of ideas, techniques, and results, including
motivation, relevance to practical applications, and a clear comparison
with related work. Committee members are not required to read
appendices, and papers should be intelligible without them. Submitted
papers risk being rejected without consideration of their merits if they
do not follow all the above guidelines.
Submissions must not substantially duplicate work that was published
elsewhere, or work that any of the authors has submitted in parallel to
any other conference or workshop that has proceedings. Plagiarism and
double submissions will be dealt with harshly.
Authors will be asked to indicate whether their submissions should be
considered for the best student paper award; any paper co-authored by a
full-time student is eligible for this award.
Authors of accepted papers must guarantee that their paper will be
presented at the conference.
[ACNS Home:

@_date: 2008-04-21 14:06:17
@_author: Perry E. Metzger 
@_subject: Cruising the stacks and finding stuff 
Oh, what the heck. Here's my expanded version of Victor's remark.
The effective key length of A5/1 is actually 54 bits because 10 of the
64 key bits are fixed at 0. However, the attacks that have been done
recently are not, in fact, mere brute force but are far more
sophisticated than that. Thus, the time difference between
(intelligently) attacking A5/1 and brute forcing AES with 128 bit keys
is far worse than 20 orders of magnitude.
How bad is brute force here for AES? Say you have a chip that can do
ten billion test keys a second -- far beyond what we can do now. Say
you have a machine with 10,000 of them in it. That's 10^17 years worth
of machine time, or about 7 million times the lifetime of the universe
so far (about 13x10^9 years).
Don't believe me? Just get out calc or bc and try
  ((2^128/10^14)/(60*60*24*365))
I don't think anyone will be brute force cracking AES with 128 bit
keys any time soon, and I doubt they will ever be brute forcing AES
with 256 bit keys unless very new and unanticipated technologies
Now, it is entirely possible that someone will come up with a much
smarter attack against AES than brute force. I'm just speaking of how
bad brute force is. The fact that brute force is so bad is why people
go for better attacks, and even the A5/1 attackers do not use brute
I'd suggest that Allen should be a bit more careful when doing back of
the envelope calculations...

@_date: 2008-04-23 08:20:27
@_author: Perry E. Metzger 
@_subject: Cruising the stacks and finding stuff 
I think everyone replying mentioned that possibility.
However, if your message really was centered on AES possibly being
defective, which was not obvious from the text, your calculation was
even more inaccurate. If AES is defective, all bets whatsoever are off

@_date: 2008-04-24 21:28:43
@_author: Perry E. Metzger 
@_subject: "Designing and implementing malicious hardware" 
A pretty scary paper from the Usenix LEET conference:
The paper describes how, by adding a very small number of gates to a
microprocessor design (small enough that it would be hard to notice
them), you can create a machine that is almost impossible to defend
against an attacker who possesses a bit of secret knowledge. I suggest
reading it -- I won't do it justice with a small summary.
It is about the most frightening thing I've seen in years -- I have no
idea how one might defend against it.
Hat tip: Bruce Schneier's blog.

@_date: 2008-04-26 14:41:35
@_author: Perry E. Metzger 
@_subject: more on malicious hardware 
It turns out that the counterfeit chips business is booming:
In combination with the news about what as few as 1500 extra gates can
do, this is especially worrisome.

@_date: 2008-04-28 15:28:06
@_author: Perry E. Metzger 
@_subject: "Designing and implementing malicious hardware" 
Not likely.
Sampling will not work. Sampling theory assumes statistical
independence and that the events that you're looking for are randomly
distributed. We're dealing with a situation in which the opponent is
doing things that are very much in violation of those assumptions.
The opponent is, on very very rare occasions, going to send you a
malicious payload that will do something bad. Almost all the time
they're going to do nothing at all. You need to be watching 100% of
the time if you're going to catch him with reasonable confidence, but
of course, I doubt even that will work given a halfway smart attacker.
The paper itself describes reasonable ways to prevent detection on the
basis of most other obvious methods -- power utilization, timing
issues, etc, can all be patched over well enough to render the
malhardware invisible to ordinary methods of analysis.
Truth be told, I think there is no defense against malicious hardware
that I've heard of that will work reliably, and indeed I'm not sure
that one can be devised.

@_date: 2008-04-28 16:09:19
@_author: Perry E. Metzger 
@_subject: "Designing and implementing malicious hardware" 
No. It really does not. Shannon's tenth theorem is about correcting
lossy channels with statistically random noise. This is about making
sure something bad doesn't happen to your computer like having someone
transmit blocks of your hard drive out on the network. I assure you
that Shannon's theorem doesn't speak about that possibility. The two
are not really related. It would be wonderful if they were, but they
aren't. Indeed, Shannon's tenth theorem doesn't even hold for error
correction if the noise on the channel is produced by an adversary
rather than being random.
I'm not particularly inclined to argue this at length.

@_date: 2008-04-28 17:37:55
@_author: Perry E. Metzger 
@_subject: "Designing and implementing malicious hardware" 
Not quite. If I inject noise into a channel in the right way, I can
completely eradicate the signal. For example, I can inject a different
signal of exactly opposite phase.
However, in any case, this doesn't matter. We're not talking about
receiving a signal without errors at all. We're talking about assuring
that your microprocessor possesses no features such that it does
something evil, and that something can be completely in addition to
doing the things that you expect it to do, which it might continue to
do without pause.
Lets be completely concrete here. Nothing you have suggested would
work against the described attack in the paper AT ALL. You cannot find
"evil chips" with statistical sampling because you don't know what to
look for, and you can't detect them by running them part of the time
against good chips because they only behave evilly once in a blue moon
when the attacker chooses to have them behave that way. Indeed, I
don't even see how someone who had read the paper could suggest what
you have -- it makes no sense in context.
And with that, I'm cutting off this branch of the conversation.

@_date: 2008-04-28 17:56:31
@_author: Perry E. Metzger 
@_subject: defending against evil in all layers of hardware and software 
I'm not sure how to feasibly defend against such things. It would seem
to require complete control over the entire design and supply chain,
which involves so many thousands of people who could be bribed that I
have serious doubts that it can be done perfectly.
I'll believe that when I see feasible defenses. So far as I can tell,
if you can't trust the hardware supplier, you're meat. I don't think
it is possible even in principle to validate the hardware after the
fact. Even if you could apply formal methods successfully, it isn't
even obvious how you would specify the property of the system that
you're trying to prove. "Never does anything bad" is kind of nebulous
if you're doing proofs.
Well, this sort of thing is already not that interesting to an
ordinary spammer or phisher -- they have no trouble making loads of
money without engaging in such stuff.
If you're talking about what a national government might pay to get
such a back door in hardware, though, I think that it is probably
worth billions to such an entity. After all, a decent bomber these
days costs a billion dollars, and clearly this is a lot more potent.
Given that, I don't see what would work in practice. If a major power
wanted to turn a couple of engineers at the right place in the design
or supply chain, the amount of money needed is far below the amount in
If you have a rotten apple engineer, he will be able to hide what he's
trying to do and make it look completely legit. If he's really good,
it may not be possible to catch what he's done EVEN IN PRINCIPLE. All
an SCM can do is tell you who put the bad stuff in much after the fact
if you ever catch it at all. That's not exactly "defense". It is at
best "post mortem".
Won't help. A bad apple can probably manage a sufficiently subtle flaw
that it won't be noticed by widespread code inspection. See Jerry's
earlier posting on the subject.
Only if the bad guy doesn't anticipate that you might do that.
I'm pretty sure we can defend against this sort of thing a lot of the
time (by no means all) if it is done by quite ordinary criminals. If
it is done by really good people, I have very serious doubts.

@_date: 2008-04-28 17:57:54
@_author: Perry E. Metzger 
@_subject: Doubts about efficiency of Shor's factoring algorithm in quantum computers 
Very interesting indeed. I'd be curious about the opinions of people
who know the field well. My QM and quantum computing knowledge aren't
quite up to the task of analyzing the paper.

@_date: 2008-04-29 09:13:00
@_author: Perry E. Metzger 
@_subject: defending against evil in all layers of hardware and software 
He needn't have bothered. All non-trivial properties of programs
are undecidable. Rice's Theorem, you know. Such a proof is one line --
you need merely assert that "X is a virus" is a non-trivial property
(that is, a property that is only true of some programs).

@_date: 2008-08-03 20:47:57
@_author: Perry E. Metzger 
@_subject: Strength in Complexity? 
I'm not sure I would see it differently from Ben.
There are existing deployed solutions like Kerberos that scale far
beyond that and work just fine, and actually address all the things
this protocol seems to leave as an exercise to the reader. And yes,
they're in use in real companies at gigantic scales. (Indeed, Kerberos
is central to Microsoft's technologies these days.)

@_date: 2008-08-04 14:10:05
@_author: Perry E. Metzger 
@_subject: Strength in Complexity? 
Well, kerberos does both, really. It also has the advantage that it
is fully specified and integrates with GSSAPI.
It is generally hard to deliver network authentication without a
network. That said, kerberos tickets can persist even in the face of
disconnects, so once you've connected tickets can survive as long as
you wish.
That's no different from Kerberos, and kerberos works quite well

@_date: 2008-08-04 15:05:02
@_author: Perry E. Metzger 
@_subject: Strength in Complexity? 
If you have a locally service that uses them, sure. In any case, a
ticket gives you access to a crypto key, and you can use that for all
sorts of things.
Well, again, you can do the same thing with Kerberos, and Kerberos has
the added advantage that there is a complete spec that fully handles
all the details and is actually implemented and available off the
shelf -- even built in to Windows. SKMS is vaporware that leaves all
the hard parts of the specification out.
I'm inclined to dismiss it, if only because you can do all of it with
existing, implemented and fully specified tools with no added
complexity. I actually have much larger reservations, but I think that
alone eliminates the reason to consider it.
I think that comparing the advance SQL made with SKMS seems a bit

@_date: 2008-08-04 15:40:03
@_author: Perry E. Metzger 
@_subject: compromised hosts (was Re: Strength in Complexity?) 
This is indeed a big new problem -- indeed, I'd say that how you deal
with partially trusted people logged on to untrusted equipment is now
the name of the game.
Not entirely. :)

@_date: 2008-08-04 15:41:54
@_author: Perry E. Metzger 
@_subject: Strength in Complexity? 
Well, that's not unreasonable.
Of course, if you're looking for ways to add a layer so that
application logic can be detached from authentication logic, GSSAPI is
one answer. People may have varying opinions on GSSAPI, but it does
have the merit of existing and being widely available.

@_date: 2008-08-06 09:13:59
@_author: Perry E. Metzger 
@_subject: Security breeches of the day 
[From my daily New York Times news summary]
11 Charged in Theft of 41 Million Card Numbers
By BRAD STONE
Authorities said the scheme was spearheaded by a Miami man
who hacked into several retailers' computer systems.
Russian Gang Hijacking PCs in Vast Scheme
By JOHN MARKOFF
The gang has infected thousands of PCs in corporate and
government networks with programs that steal passwords and
other information, a security researcher has found.
[The depressing bit is how banal both stories have become. --Perry]

@_date: 2008-08-08 12:26:04
@_author: Perry E. Metzger 
@_subject: UK e-passport cloned 
New microchipped passports designed to be foolproof against
    identity theft can be cloned and manipulated in minutes and
    accepted as genuine by the computer software recommended for use
    at international airports.
    Tests for The Times exposed security flaws in the microchips
    introduced to protect against terrorism and organised crime. The
    flaws also undermine claims that 3,000 blank passports stolen last
    week were worthless because they could not be forged.
Hat tip: Bruce Schneier's blog

@_date: 2008-08-08 14:08:37
@_author: Perry E. Metzger 
@_subject: OpenID/Debian PRNG/DNS Cache poisoning advisory 
The problem is, the CRL mechanism itself is also dangerous.  Sadly,
clients are required to keep on going if they can't reach a CRL
server. That means that if you DoSing the CRL servers or use DNS
attacks to effectively take them offline, you've also effectively
eliminated the certificate revocation.
I'm not going to tell you that paying attention to CRLs wouldn't be
better than what happens now, but it will not eliminate the
problem. It is too hard to "prove a negative" (that is, to prove to
yourself that no revocation exists.)
The kerberos style of having credentials expire very quickly is one
(somewhat less imperfect) way to deal with such things, but it is far
from perfect and it could not be done for the ad-hoc certificate
system https: depends on -- the infrastructure for refreshing all the
world's certs every eight hours doesn't exist, and if it did imagine
the chaos if it failed for a major CA one fine morning.
One also worries about what will happen in the UI when a certificate
has been revoked. If it just says "this cert has been revoked,
continue anyway?" the wrong thing will almost always happen.

@_date: 2008-08-08 15:38:45
@_author: Perry E. Metzger 
@_subject: Telephone Phishing 
I just got called by an autodialer -- the Caller ID was faked (and in
any case didn't point at a real number since area codes don't start
with "0" -- probably a mistake by the scammers).
After I answered, a tape of a cheerful woman informed me this was my
"last chance to lower the rate on my credit card", and asked me to
press one to continue.
You can fill in the rest of the script on your own.
I'm sure this happens all the time now and I was just unaware of it,
but it is always more vivid when you see it yourself.
I'm certain this scenario would get enough average people to hand over
their credit card data to more than pay for itself, and smart scammers
are probably using VOIP accounts they got with stolen credit card
numbers to do this anyway.
One can also imagine using this technique for a wide variety of spear
phishing attacks. For example, say you stole a large number of credit
card numbers but didn't have the CVV2s -- you could set up an IVR
system to automatically collect them from your victims.

@_date: 2008-08-09 17:11:11
@_author: Perry E. Metzger 
@_subject: Judge approves TRO to stop DEFCON presentation 
It seems that US judges aren't as protective of speech rights as Dutch
    Las Vegas - Three students at the Massachusetts Institute of
    Technology (MIT) were ordered this morning by a federal court
    judge to cancel their scheduled presentation about vulnerabilities
    in Boston's transit fare payment system, violating their First
    Amendment right to discuss their important research.
    The Electronic Frontier Foundation (EFF) represents Zack Anderson,
    RJ Ryan and Alessandro Chiesa, who were set to present their
    findings Sunday at DEFCON, a security conference held in Las
    Vegas. However, the Massachusetts Bay Transit Authority (MBTA)
    sued the students and MIT in United States District Court in
    Massachusetts on Friday, claiming that the students violated the
    Computer Fraud and Abuse Act (CFAA) by delivering information to
    conference attendees that could be used to defraud the MBTA of
    transit fares. This morning District Judge Douglas P. Woodlock,
    meeting in a special Saturday session, ordered the trio not to
    disclose for ten days any information that could be used by others
    to get free subway rides.

@_date: 2008-08-12 14:49:52
@_author: Perry E. Metzger 
@_subject: ADMIN: "Why no HTML?" 
A couple of people have asked me why I have a policy against
forwarding HTML email. Here is the rationale, roughly from most
to least important.
1) Many people still read their email in systems that handle only
   plain text effectively. They're a large enough group that I don't
   like disenfranchising them.*
2) HTML email, like most machine parsable data, often has "gotchas",
   and as this is a security oriented list, I really don't want to
   have to vet email for hacking attempts. Vetting real code is
   unpleasant enough -- I don't want to have to look for attempted
   buffer overflows and web bugs in email I'm forwarding.
3) HTML email is harder to search, to edit down, to cut and paste
   cleanly, etc.
4) HTML email is often just plain ugly to look at.
Perhaps someday I'll change my mind, but for the moment, please send
only in plain text.
In the same vein, keep in mind that although Microsoft Outlook won't
show you that your lines are run on and include proprietary Microsoft
characters for balanced quotes and such, for the sake of the rest of
us, hit carriage return every 60 or 70 characters and don't send in
proprietary character sets.

@_date: 2008-08-19 18:12:05
@_author: Perry E. Metzger 
@_subject: "Cube" cryptanalysis? 
According to Bruce Schneier...
...Adi Shamir described a new generalized cryptanalytic attack at
Crypto today.
Anyone have details to share?

@_date: 2008-08-19 19:20:56
@_author: Perry E. Metzger 
@_subject: "Cube" cryptanalysis? 
There are a bunch of deployed mobile phone ciphers that are in the
stream cipher class -- any thoughts on whether any of them look

@_date: 2008-08-22 17:53:17
@_author: Perry E. Metzger 
@_subject: DNS cache poison attacks in the wild 
There have been other earlier reports, but the neat thing about this
one is that the attackers went for the DNS record for the ISP's own
crappy "that domain doesn't exist, here, have some ads instead" web
Hat tip: Bill Squier

@_date: 2008-08-26 09:24:03
@_author: Perry E. Metzger 
@_subject: road toll transponder hacked 
Drivers using the automated FasTrak toll system on roads and
   bridges in California's Bay Area could be vulnerable to fraud,
   according to a computer security firm in Oakland, CA.
   Despite previous reassurances about the security of the system,
   Nate Lawson of Root Labs claims that the unique identity numbers
   used to identify the FasTrak wireless transponders carried in cars
   can be copied or overwritten with relative ease.

@_date: 2008-08-28 12:39:16
@_author: Perry E. Metzger 
@_subject: privacy in public places 
There has been a lot of talk on the list recently about the privacy
issues associated with various toll and fare collecting systems, but
others have been pointing out, correctly I think, that this matters
less and less because of other technological developments.
New York City recently announced plans to use license plate OCR to
produce and keep records of every car entering and leaving the city
and to keep those records for years. Very little attention was paid to
this, but I think it is the mark of things to come.
Although the huge infestations of video cameras in our cities have had
almost no impact on crime, once they are combined with sufficiently
potent image recognition software, it will become possible to track
people's movements and keep records of those movements essentially
forever. It also seems to me that almost anything that can be done
will in fact happen in the current "opposing the wish lists of the
police is the same as being in favor of terrorism" environment.
Given this, I think the time for focusing on the privacy implications
of payment transponders and fare cars is over. Not carrying a cell
phone will not help you avoid tracking when your environment is
saturated with cameras. Digital cash toll collection systems will not
avoid records being kept of your car's movements when cameras are
reading and recording license plates anyway.
Unfortunately, I don't see anything technological that people can
reasonably do here to provide more privacy, at least short of everyone
going everywhere on foot while wearing a burqa and periodically
attempting to confuse the cameras. The solutions, if any exist at all,
appear to be non-technical.

@_date: 2008-08-29 10:05:39
@_author: Perry E. Metzger 
@_subject: privacy in public places 
There are now quite reasonable cameras about half a cm on a side. The
market is largely driven by cellphones. They were available in quantity
for under $10 a few years ago -- they are probably much cheaper by
now, and the prices are only going to come down further. There are of
course limits imposed by optics, but they aren't nearly so bad as is
often depicted, so with time we can expect the cameras to get better
and cheaper.
One can only laser or cut down a camera if one can find it. I could
probably saturate the average location with practically if not
literally undetectable cameras right now. It will continue to get
cheaper to do so with time.
Software already allows good 3D reconstruction of scenes based on
multiple images from different angles, and improvement of resolution
based on multiple images as well. The software will only get better
with time. Storage is, of course, only getting cheaper.
Autonomous vehicles, especially very small flying vehicles, already
exist and will improve with time. We already know from nature that it
is possible to construct quite small flying devices with high
resolution imaging and other sensors -- it will only be a matter of
time (perhaps a decade, a few decades at most) before artificial
"flies" can be built, and once they are built, it will only be a
matter of time before they cost very little. The images they produce
will be limited by optics, but again, they will not need to be as bad
as one naively expects, and we are getting better and better at
techniques for combining images to produce surprising results.
This arms race heavily favors the attacker over the defender.
I don't want to saturate this mailing list with a discussion of the
problem (I'm not going to pass many messages on it), but I think it is
a reasonable issue for people to contemplate. Perhaps I should allow a
more significant discussion in a month or two after people have
digested it for longer.

@_date: 2008-12-01 14:41:31
@_author: Perry E. Metzger 
@_subject: The next time someone tells you "no one" would do something... 
Summary: shops in Vietnam removing the baseband chip on iPhone
motherboards to reprogram and unlock them.
The next time someone tells you "no one" would do such a thing to
break the security of a device, or at least that it would be unlikely
that anyone would make such a thing routine, remember that with enough
motivation, people will do amazing things.

@_date: 2008-12-12 15:47:10
@_author: Perry E. Metzger 
@_subject: [Forwarded] NIST Requests Comments 
NIST requests comments on Draft SP 800-56B, Recommendation for Pair-Wise Key
Establishment Using Integer Factorization Cryptography. This Recommendation
provides the specifications of asymmetric-based key agreement and key
transport schemes that are based on the Rivest Shamir Adleman (RSA)
algorithm. The draft is available at
.pdf.. Please provide comments to ebarker at nist.gov by February 12, 2009,
with "Comments on SP 800-56B" in the subject line.
Please note that the public comments period for FIPS 186-3, the Digital
Signature Standard, closes on Friday, December 12, 2008. The draft is
available at
t3_Recommendationforkeymanagement.pdf. Send any comments by the due date, as
we intend to finalize this Standard as soon as possible. Please submit
comments to ebarker at nist.gov
  with "Comments
on Draft 186-3" in the subject line.
Also, the public comment period on SP 800-102, Recommendation for Digital
Signature Timeliness, closes on Friday, December 19, 2008. The draft is
available at
Please provide comments to ebarker at nist.gov
  with "Comments on
SP 800-102" in the subject line.

@_date: 2008-12-15 14:09:11
@_author: Perry E. Metzger 
@_subject: CPRNGs are still an issue. 
Given the usual threat model for a device like this, I'd just store an
AES key at the factory and use it in counter mode (or something very
similar) as your PRNG.
The rest of this message is justification for this design choice under
a very specific threat model -- it might not be a good idea under a
different threat model.
I'm imagining that this is a device like a router, wireless base
station, or similar, where you have (for most users) a fairly modest
level of physical access based threat, and a very strong remote
exploitation threat. (I presume if this wasn't a fairly inexpensive
mass produced item, adding a hardware RNG wouldn't be a big deal. If
this is an ATM or other expensive high risk device, why aren't you
spending the money?)
So reiterating, our threat model is largely remote attack -- if
someone gets prolonged physical access to the device, they can read
out the key, but with that much access they can also alter the
firmware so who cares. Physical access means everything is lost
anyway. Some remote attackers might gain complete control of the
device and be able to read the key, but again, in such cases
everything is likely lost anyway, because they could also alter the
I also presume that for the device in question, the quality of the
RNGs is important (or you wouldn't be thinking hard about it). So, why
not go for the simplest, easiest and strongest source we know about, a
block cipher in counter mode with a strong key?
Yes, you can attempt to gather randomness at run time, but there are
endless ways to screw that up -- can you *really* tell if your random
numbers are "random enough?" -- and in a cheap device with low
manufacturing tolerances, can you really rely on how consistent things
like clock skew will be?
Lets contrast that with AES in counter mode with a really good factory
installed key. It is trivial to validate that your code works
correctly (and do please do that!) It is straightforward to build a
device to generate a stream of good AES key at the factory, and you
need only make sure that one piece of hardware is working correctly,
rather than all the cheap pieces of hardware you're churning out.
One big issue might be that if you can't store the counter across
device resets, you will need a new layer of indirection -- the obvious
one is to generate a new AES key at boot, perhaps by CBCing the real
time clock with the "permanent" AES key and use the new key in counter
mode for that session.
Again, here are the possible issues from the point of view of this
threat model:
1) If someone remotely takes control of the device (via some sort of
   OS bug or the like), you're lost anyway, so a complicated algorithm
   using local randomness won't help.
2) If someone takes control of the device through physical access,
   you're lost anyway, see 3) If neither 1 or 2 happen, a factory loaded key gives you, for
   practical purposes, an ideal CPRNG. It is low cost, as strong as
   AES itself, and easily validated.
This does necessitate an extra manufacturing step in which the device
gets "individualized", but you're setting the default password to a
per-device string and having that taped to the top of the box anyway,
right? If you're not, most of the boxes will be vulnerable anyway and
there's no point...

@_date: 2008-12-17 15:02:54
@_author: Perry E. Metzger 
@_subject: CPRNGs are still an issue. 
Complexity makes it hard to understand the security characteristics of
relying on the timing of the devices.
The longer I'm in this field, the more the phrase "use with extreme
caution" seems to mean "don't use" to me. More and more, I think that
if you don't have a really good way to test and get assurance about a
component of your security architecture, you should leave that
component out.
That's one reason I recommended "just use AES in counter mode" as the
best way to generate random numbers in a low cost embedded context --
it is easy to get assurance simply by running AES validation tests,
and you confine your risk to one easily examined part of the process,
the key generator in the factory.
I'm reminded of Tony Hoare's old saw about systems: "There are two
ways of constructing a software design: One way is to make it so
simple there are obviously no deficiencies and the other way is to
make it so complicated that there are no obvious deficiencies."

@_date: 2008-12-17 15:18:57
@_author: Perry E. Metzger 
@_subject: CPRNGs and assurance... 
I'd like to expand on a point I made a little while ago about the
"just throw everything at it, and hope the good sources drown out the
bad ones" entropy collection strategy.
The biggest problem in security systems isn't whether you're using 128
bit or 256 bit AES keys or similar trivia. The biggest problem is the
limited ability of the human mind to understand a design. This leads
to design bugs and implementation bugs. Design and implementation
flaws are the biggest failure mode for security systems, not whether
it will take all the energy in our galaxy vs. the entire visible
universe to brute force a key.
So, if you're designing any security system, the biggest thing on your
mind has to be how to validate that the system is secure. That
requires ways to know your design was correct, and ways to know you
actually implemented your design correctly.
"Just throw the kitchen sink at it" impedes both. As just one trivial
example, say that your code is buggy and instead of throwing in eight
entropy sources, you're really throwing out  and only using perhaps because of some overwriting that you thought was an xor or
some similar stupidity. How are you going to notice this on the other
end of your SHA-256 pool mashing? Will you look at the output by hand
and magically see that the numbers aren't as random as they should be?
Probably not. Lets then say  turned out to be a less than random
Is this sort of stupid move theoretical? Ask the guys at Debian how
theoretical it is.
At the very least, you need to have a very good set of tests attached
to your software that get run every time any sort of change (no matter
how trivial) is made to it, and even that is not necessarily enough.
If you're doing all of this properly (and few people do it properly),
you need to have a good way of knowing that your system works
right. This is especially hard to do properly at the best of times --
when the product of your algorithm is supposed to look like nonsense,
it becomes especially important that you have a well understood design
that has turned into a well validated implementation. "Throw the
kitchen sink at it" often ends up kicking up enough dust that you
can't distinguish something good from something bad. That can be a
Always bear in mind that security systems fail because of people, and
that as a security system designer or implementor, you are the first
and most likely point of failure in the entire process.

@_date: 2008-12-25 15:59:14
@_author: Perry E. Metzger 
@_subject: "Cryptol" 
Cryptol is a domain specific language for the design,
     implementation and verification of cryptographic algorithms,
     developed over the past decade by Galois for the United States
     National Security Agency. It has been used successfully in a
     number of projects, and is also in use at Rockwell Collins, Inc.
     Domain-specific languages (DSLs) allow subject-matter experts to
     design solutions in using familiar concepts and
     constructs. Cryptol, as a DSL, allows domain experts in
     cryptography to design and implement cryptographic algorithms
     with a high degree of assurance in the correctness of their
     design, and at the same time, producing a high performance
     implementation of their algorithms.

@_date: 2008-12-28 20:12:09
@_author: Perry E. Metzger 
@_subject: very high speed hardware RNG 
Semiconductor laser based RNG with rates in the gigabits per second.
My take: neat, but not as important as simply including a decent
hardware RNG (even a slow one) in all PC chipsets would be.

@_date: 2008-02-01 09:24:10
@_author: Perry E. Metzger 
@_subject: Gutmann Soundwave Therapy 
I use a VPN system other than IPSec on a regular basis. The reason is
simple: it is easy to configure for my application and my OS native
IPsec tools are very difficult to configure.
There is a lesson in this, I think.

@_date: 2008-02-01 09:26:09
@_author: Perry E. Metzger 
@_subject: Gutmann Soundwave Therapy 
DTLS does not assume a reliable channel -- it is designed for
applications that use UDP. Perhaps you are not familiar with it.
With respect, James, I think they'd be better off using DTLS. It was
designed by experts and it shares the same security properties as TLS.

@_date: 2008-02-01 14:52:44
@_author: Perry E. Metzger 
@_subject: Gutmann Soundwave Therapy 
The version of SSL (which is officially called TLS) that does this is
called "DTLS". It has already existed for some time now.
That's why you use "Datagram TLS", aka "TLS if your app needs UDP
instead of TCP".
If you want to learn more about DTLS, this Wikipedia page:
points at the RFC, which is here:
OpenSSL has had DTLS support for a while, so there is unencumbered
code for you to roll into your app for the purpose any time you like.
DTLS is there for packet delivery.

@_date: 2008-02-03 19:08:30
@_author: Perry E. Metzger 
@_subject: Gutmann Soundwave Therapy 
That's just plain factually wrong. DTLS does fine for that purpose. At
the point where you are sending datagrams with voice data, you're just
doing conventional crypto over a fixed length packet each time, and
those algorithms are quite deterministic.
Indeed, DTLS was designed specifically for such applications.

@_date: 2008-02-09 18:35:16
@_author: Perry E. Metzger 
@_subject: Toshiba shows 2Mbps hardware RNG 
EE Times: Toshiba tips random-number generator IC
    SAN FRANCISCO -- Toshiba Corp. has claimed a major breakthrough in
    the field of security technology: It has devised the world's
    highest-performance physical random-number generator (RNG)
    circuit.
    The device generates random numbers at a data rate of 2.0 megabits
    a second, according to Toshiba in a paper presented at the
    International Solid-State Circuits Conference (ISSCC) here.

@_date: 2008-02-10 17:30:50
@_author: Perry E. Metzger 
@_subject: Toshiba shows 2Mbps hardware RNG 
Perhaps it isn't, but any hardware RNG is probably better than none
for many apps, and they've managed to put the whole thing in a quite
small bit of silicon. The speed is probably icing on the cake.

@_date: 2008-02-14 18:04:06
@_author: Perry E. Metzger 
@_subject: House o' Shame: Amtrak 
Steve Bellovin documents on his blog a recent attempt by Amtrak to
teach its customers to be phishing victims:
My comments:
"Phish someone, and you inconvenience him for a week.
 Teach a man to be phished, and you screw him for the rest of his life."
                --me
I got the exact same email from Amtrak. It is pretty disappointing to
me, but sadly not surprising, that big organizations are still
conditioning their users to become fraud victims.

@_date: 2008-02-15 13:42:21
@_author: Perry E. Metzger 
@_subject: kit to prevent computers from losing power during seizure. 
It appears that disk encryption techniques are spawning technical
responses. This gadget lets law enforcement take a computer without
ever turning off the power.
Countermeasures are, of course, quite possible.
[Hat tip: Bruce Schneier's blog.]

@_date: 2008-02-21 12:10:33
@_author: Perry E. Metzger 
@_subject: cold boot attacks on disk encryption 
Ed Felten blogs on his latest research:
    Today eight colleagues and I are releasing a significant new
    research result. We show that disk encryption, the standard
    approach to protecting sensitive data on laptops, can be defeated
    by relatively simple methods. We demonstrate our methods by using
    them to defeat three popular disk encryption products: BitLocker,
    which comes with Windows Vista; FileVault, which comes with MacOS
    X; and dm-crypt, which is used with Linux.
More info: Paper:

@_date: 2008-02-21 14:51:04
@_author: Perry E. Metzger 
@_subject: cold boot attacks on disk encryption 
No, it just requires that the computer was recently turned on. It need
not have been "unlocked" -- it jut needed to have keying material in RAM.
LN2 is pretty trivial to get your hands on, and will remain happy and
liquid in an ordinary thermos for quite some hours or longer. However,
the authors point out that canned air works fine, too.
No, they may even have minutes depending on the RAM you have.
People readily assume that rebooting or turning off a computer wipes
RAM. It doesn't. This is just more evidence that it is bad
to assume that the contents of RAM are gone even if you turn off the

@_date: 2008-02-21 15:26:01
@_author: Perry E. Metzger 
@_subject: cold boot attacks on disk encryption 
I'm sure that the same sort of attacks used to get keying material out
of other ASICs and out of smart cards could be applied to the ASICs on
the drive controller board. No one has tried yet, of course, but I see
no reason they wouldn't succeed.

@_date: 2008-02-21 17:59:57
@_author: Perry E. Metzger 
@_subject: cold boot attacks on disk encryption 
The phrase is "tamper resistant", not "tamper proof". Depending on how
determined your attackers are, pretty much anything depending on
tamper resistant hardware will fall. As always, the question is
whether what you are protecting is worth more than the attackers would
have to spend on the attack.

@_date: 2008-02-21 18:56:50
@_author: Perry E. Metzger 
@_subject: cold boot attacks on disk encryption 
Clearly, if the anti-tamper mechanisms work, the device will not be
compromised. The problem is, such mechanisms don't always work. There
is lots of stuff in the literature about various kinds of attacks on
such devices.
Again, I will point out the following from my original comment:

@_date: 2008-02-22 09:16:51
@_author: Perry E. Metzger 
@_subject: Schneier on A5/1 crack 
Bruce Schneier has a good blog post on the latest A5/1 attack.

@_date: 2008-01-02 17:03:33
@_author: Perry E. Metzger 
@_subject: Samuel Snyder, early NSA cryptographer, dies. 
Samuel S. Snyder, 96, who was honored this year for his
    contributions to code breaking during the 1940s and the
    conceptualization and design of computers in the 1950s at the
    National Security Agency and its predecessors, died Dec. 28[...]

@_date: 2008-01-03 16:31:41
@_author: Perry E. Metzger 
@_subject: Death of antivirus software imminent 
I think Steve is completely correct in the case of cryptography. We
have a lot of experience of real world security failures these days,
and they're not generally the sort that crypto would fix.
People have said that for quite some time. However, I doubt it would
actually help. In the case of spam, all that would end up happening is
vast amounts of CPU time being spent demonstrating that the made up
addresses on spam were associated with actual RSA keys. (There is no
practical limit to the number of RSA keys that may be generated.)
In the very different case of phishing, I think it would still all
fail. Most people are unable to understand (or outright ignore)
SSL authentication failures to web sites, so I don't see why they
would be disturbed by authentication failures in email from their
bank. We'd also have the problem that lots of email would remain
unauthenticated for years or decades, and that if you got a security
pop-up every time you read such an email, you'd probably learn to
ignore them inside of an hour.
I would actually agree that we can implement operating system
strategies that make malware harder to write. I don't know if it is
likely that any current techniques, even including the nearly unheard
of use of formal verification, would actually eliminate malware.

@_date: 2008-01-10 16:15:45
@_author: Perry E. Metzger 
@_subject: remember, kids -- pay your wiretap bills on time. 
WASHINGTON (AP) - Telephone companies have cut off FBI wiretaps
    used to eavesdrop on suspected criminals because of the bureau's
    repeated failures to pay phone bills on time.

@_date: 2008-01-15 08:19:11
@_author: Perry E. Metzger 
@_subject: US drafting plan to allow government access to any email or Web search 
Forwarded from Dave Farber's list:
Sent: Monday, January 14, 2008 6:41 PM
Quoting from:
                National Intelligence Director Mike McConnell is drawing up
        plans for cyberspace spying that would make the current debate
        on warrantless wiretaps look like a "walk in the park," according
        to an interview published in the New Yorker's print edition today.
        Debate on the Foreign Intelligence Surveillance Act "will be a
        walk in the park compared to this," McConnell said. "this is going
        to be a goat rope on the Hill. My prediction is that we're going
        to screw around with this until something horrendous happens."
        The article, which profiles the 65-year-old former admiral
        appointed by President George W. Bush in January 2007 to oversee
        all of America's intelligence agencies, was not published on
        the New Yorker's Web site. (It can be read here in pdf).
        [...]
The PDF link points to:
        which I'm unable to access at the moment.

@_date: 2008-01-18 17:07:39
@_author: Perry E. Metzger 
@_subject: [ADMIN] backdoor discussion closed 
I'm closing the "backdoors" discussion for now -- I see nothing new
being said.

@_date: 2008-01-22 22:29:51
@_author: Perry E. Metzger 
@_subject: patent of the day 
Hat tip to a party who prefers to remain anonymous who sent me the
patent number.

@_date: 2008-01-22 22:56:30
@_author: Perry E. Metzger 
@_subject: Lack of fraud reporting paths considered harmful. 
This evening, a friend of mine who shall remain nameless who works for
a large company that regularly processes customer credit card payments
informed me of an interesting fact.
His firm routinely discovers attempted credit card fraud. However,
since there is no way for them to report attempted fraud to the credit
card network (the protocol literally does not allow for it), all they
can do is refuse the transaction -- they literally have no mechanism
to let the issuing bank know that the card number was likely stolen.
This seems profoundly bad. I hope that someone on the list has the
right contacts to get the right people to do something about this.

@_date: 2008-01-23 16:27:18
@_author: Perry E. Metzger 
@_subject: ADMIN: TLS mail submission thread 
Unless people have more interesting stuff to say about TLS for email
submission, I'm closing the thread.

@_date: 2008-01-24 19:01:38
@_author: Perry E. Metzger 
@_subject: Dutch Transport Card Broken 
Ed Felten has an interesting post on his blog about a Dutch smartcard
based transportation payment system that has been broken. Among other
foolishness, the designers used a custom cryptosystem and 48 bit keys.

@_date: 2008-01-25 10:27:41
@_author: Perry E. Metzger 
@_subject: Dutch Transport Card Broken 
Several other transit systems have payment cards that have proven
remarkably resilient to attack. For example, the NYC "Metrocard"
system has been attacked repeatedly without significant breaks (but it
does not rely on its cards being tamperproof -- it is an online system
using magstripes.)
The authors of the paper on the Dutch break claim that it would have
been possible to use far more secure means even given the basic
design, such as a non-proprietary crypto algorithm and longer keys. I
see no real reason to disbelieve this. In any case, if it was not
possible to do this with smartcards, existing, well proven mechanisms
that are in use in other transit systems could have been adopted. It
is not necessary to use an unimplementable architecture when
implementable and proven architectures exist.
Often we hear of a false need for "engineering tradeoffs" in such
circumstances. Engineering tradeoffs do indeed sometimes become
critical in security design. However, you should be very skeptical
when someone claims that they "need" to use a home grown crypto
algorithm or that they "need" to use a home grown protocol instead of
a well proven one. Generally these are not "engineering tradeoffs" but
reflections of ignorance on the part of the designers.

@_date: 2008-01-25 12:02:53
@_author: Perry E. Metzger 
@_subject: more terrorist crypto hype 
There has been more hype about "Jihadist" crypto software lately. For
I'll note that the presumed users would probably be better off
with a well vetted program like GPG. I'll also note that there is
literally no way to prevent people from writing such software, since
they are non-US nationals living outside the US. (As much as we would
like US law to apply to all foreigners living abroad, that's not how
the world works.)
None the less, I'll predict that this "news", which has been hyped in
several places of late, will be brought up by some as a reason why we
must restrict crypto exports, never mind that this "solution" would in
no way alter the availability of cryptographic software to terrorists,
any more than New York City gun control regulations would prevent
AK-47s from reaching fighters in Congo.

@_date: 2008-01-25 12:52:56
@_author: Perry E. Metzger 
@_subject: "Potential Hazards of the Protect America Act" 
Matt Blaze blogs about a paper he, Steve Bellovin, Whit Diffie, Susan
Landau, Peter Neumann and Jennifer Rexford have written on the hazards
of surveillance technologies:

@_date: 2008-01-25 18:01:39
@_author: Perry E. Metzger 
@_subject: Lack of fraud reporting paths considered harmful. 
That's not practical. If you're a large online merchant, and your
automated systems are picking up lots of fraud, you want an automated
system for reporting it. Having a team of people on the phone 24x7
talking to your acquirer and reading them credit card numbers over the
phone, and then expecting the acquirer to do something with them when
they don't have an automated system either, is just not reasonable.

@_date: 2008-01-26 10:24:45
@_author: Perry E. Metzger 
@_subject: German Government Skype interception methods leaked... 
"Wikileaks has released documents from the German police revealing
    Skype interception technology. The leaks are currently creating a
    storm in the German press[...]"

@_date: 2008-01-27 16:58:41
@_author: Perry E. Metzger 
@_subject: Lack of fraud reporting paths considered harmful. 
Lets say you're a big company like Amazon or someone similar. You're
pretty sure someone is trying to use a stolen credit card. How do you
"fix" the underlying fraud? Last I checked, Amazon had no police
force. Lets say that the miscreants are in any one of several Eastern
European countries. Even reporting the fraud to the police in the
originating country won't "fix" it because the foreign police will do
absolutely nothing.
Perhaps you argue that the credit card system itself is flawed. I
agree, but as a company like Amazon you're not in a position to fix
that, either.
The point of providing a feedback channel is so the issuing bank can
be alerted to an attempted fraud, call the customer, say "hi, did you
try to buy a container consumer electronics and have it shipped to
Belarus", hear back "no", and issue a new credit card. This is done
right now when the issuing bank notices suspicious activity, but there
is a hole in the system in which a merchant might refuse a suspicious
charge and yet have no way of telling the issuing bank about it.
The call-the-customer-and-reissue mechanism is a mediocre solution to
the fraud problem, but it is the one we have these days. As it stands,
a merchant can't easily tell the issuing bank that it should have a
look to see if a card is being used fraudulently, so the merchant can
know that something weird is happening but the issuing bank can remain
ignorant. This is not a good situation. That is why a feedback path
would be of use.
I had long assumed such a feedback path already existed, and I was
rather shocked to discover it did not.

@_date: 2008-01-28 07:12:03
@_author: Perry E. Metzger 
@_subject: Lack of fraud reporting paths considered harmful. 
Naturally. However, given what we have now, reissue is the only
reasonable option.

@_date: 2008-01-29 12:26:21
@_author: Perry E. Metzger 
@_subject: Gutmann Soundwave Therapy 
+0100")
Clearly, more people need to know about "Gutmann Soundwave Therapy".
As it turns out, the central image of Peter's post was popularized
However, Peter clearly said this first in a security context, and I
hope that the term "Gutmann Soundwave Therapy" spreads widely within
our field as a way of ridiculing the desire to invent your own crypto
algorithms and protocols. When it gets to the point where salesmen are
vaguely aware of the phrase and fear it, we will know we have done our
job successfully.
[* see  for its
use in a different context. (Hat tip to Ekr and indirectly to Need to
Know:  )]

@_date: 2008-01-29 17:37:12
@_author: Perry E. Metzger 
@_subject: Dutch Transport Card Broken 
Here in New York City, we use a swipe based system called Metrocard.
New Yorkers are not known for passive, accepting behavior, and yet no
one seems to complain about the swipe system -- it seems to work more
than well enough, and I have to double swipe at most once every few
dozen times. The system has held up quite well to quite determined
attacks, and the cards themselves are insanely cheap to produce.
I therefore expect no one else will ever use the technology --
anything cheap, secure and well tested in the field can't possibly see
wide adoption.

@_date: 2008-01-30 12:02:31
@_author: Perry E. Metzger 
@_subject: Dutch Transport Card Broken 
I don't disagree with your posting in general. I will note one thing:
As a consultant, I happen to have a lot of ID badges. I've used
contactless systems for entry at several firms on a regular basis.
I've experienced the equivalent of "re-swipe" problems even with the
contactless systems -- that is, I've been forced to wave the card past
the reader more than once. I'm told that similar issues can be found
in other RFID systems.
Although I will not disagree that the only important criterion for a
transit system is "will we maximize overall economic efficiency with
this design choice", I'm still far from certain that contactless is
always going to be faster. It could in theory be faster -- whether
that theory can be reduced to practice is a different question.
(As an aside, I'll also point out that, in the NYC transit system, it
is fairly rare that the "rate limiting step" is the speed of turnstile
reads. Far more often, limited space on stairwells, limited numbers of
turnstiles (which are used both for entry and exit), etc., seem to be
the limiting factor on how fast people can flow onto and off of the
I want repeat that I don't disagree with you that all of this is about
economics first, and the security level and costs have to take that
into consideration. We are in violent agreement there. A $100 but
"perfect" entry token is going to be worthless for most transit
systems, and an attack that costs a system a few dollars a year at
most is unlikely to be worth closing. (Indeed, the Metrocard system
isn't perfect, in that you can clone cards -- you just can't steal
more than a trivial sum before the card will be turned off, so no one
My main point here was, in fact, quite related to yours, and one that
we make over and over again -- innovation in such systems for its own
sake is also not economically efficient or engineering smart. If an
existing system works reasonably well and you can use it off the shelf
without paying development and other costs, why not use it? I find the
fact that nearly every city in the world seems to have a custom
designed electronic fare system somewhat peculiar -- I'm not surprised
that several such systems might exist, but surely every city in the
world does not need to sink the costs of custom development of an
entire fare system. The Dutch apparently sunk vast sums into the
development of a brand new fare card system -- one questions what
requirements could not have been met with one of the several hundred
existing systems.

@_date: 2008-01-30 12:15:25
@_author: Perry E. Metzger 
@_subject: Dutch Transport Card Broken 
The initial delay in connecting is usually DNS related, not SSL
related, and is often experienced even in ordinary http: web
surfing. I don't think that the delays involved in the SSL handshake
are particularly perceptible amidst the other delays involved in
connection setup, unless you're on a very high delay network like one
of the older cellular data systems that are now going away
anyway. Protocol hacks also make subsequent connections to the same
server quite fast.
In any case, although SSL has some compromises in the design, it is
pretty good overall, and I can't see a good reason why one would pick
something else in almost any ordinary situation. A real expert might
find corner cases where it is not suitable, but there are very few
experts out there, though lots of people who incorrectly think they
are. I've seen idiots produce many things that were slower and had
horrible security properties, all the while costing far more in
software development, because they thought they knew better -- I've
never seen anyone actually do better, though. For practical purposes,
the rule is "don't use something else", and "if you think you're smart
enough to do better, you almost certainly aren't".
(No, I'm not a fan of X.509 certs, but those are not core to the
protocol, and you can think of them as nothing more than a fancy key
container format if you like. Key management is not addressed by SSL,
so there is no reason that fixing key management has anything to do
with SSL per se.)
I'm sure you're going to disagree with me, James, but I won't be
responding -- I don't think you're right, but I also see no reason to
beat a dead horse. My opinion (and just about everyone else's) is well
known. We live in a world where you are free to have a dissenting view.

@_date: 2008-01-31 13:11:03
@_author: Perry E. Metzger 
@_subject: Dutch Transport Card Broken 
SSL is in use just about everywhere, James. https: is used constantly,
and there are many other applications that make use of it. My mom uses
SSL regularly, but by contrast I don't think she's ever touched SSH.
Perhaps you argue that SSL is not secure, but it appears to have
withstood all attacks to date. You might claim that it does not
prevent phishing attacks or some such, but then you are making a claim
about how people use https in practice,, not about SSL at all. The SSL
part of that protocol is fine, just as the RSA and AES or 3DES parts
of that protocol are fine.
I'm going to start referring to you as James Donald/George W. Bush.
Why does James Donald/George W. Bush persist in involving us in wars
in foreign countries, I wonder? Please don't claim that you're not
somehow part of James Donald/George W. Bush, because as you see I've
juxtaposed your names, which is proof that you must be part of the
same entity.
If you don't like my doing that, then stop referring to SSL/TLS/PKI
because SSL has nothing to do with PKI.
SSL has nothing to do with PKI. X.509 certs are just a key container
format. The applications get to decide what to do with them. You
persistently claim that SSL has something to do with public key
infrastructure, but it has no more to do with public key
infrastructure at all. You shouldn't mention them at the same
time. You are free to write applications that use SSL with a PKI, or
without it -- the two have nothing to do with each other whatsoever. I
know of many apps that use SSL and don't touch PKI at all.
Constantly mentioning PKI and SSL at the same time betrays a
substantial ignorance of the system architecture we're mentioning --
it would make as much sense to claim that SSL has something to do with
IKE because both use X.509 certificates.
Well, James Donald/George W. Bush, I presume this means that you have
a way of breaking SSL. Could you share it with us? If not, please stop
conflating things that are unconnected.
Not really, James Donald/George W. Bush. It involves public keys, and
it provides a channel by which X.509 certificates can be exchanged,
but by the same token, SSH also provides a channel by which X.509
certs can be exchanged. Should we therefore refer to SSH/PKI
No, James Donald/George W. Bush, that's not even remotely true. There
is no requirement that you use the certs as anything other than key
Well, James Donald/George W. Bush, perhaps that is because SSL has
nothing to do with the issue. SSL works perfectly so far as we
know. The issue is that higher levels of the stack (like key
management) aren't properly designed, but SSL itself is just fine.

@_date: 2008-07-01 11:39:33
@_author: Perry E. Metzger 
@_subject: The wisdom of the ill informed 
No they don't. The new users of their online system get a temporary
password by phone or in the mail, and Wells Fargo requires that they
change it on first log in. The temporaries expire after 30 days,
too. They don't their bank account numbers as account names,
Where did you get the idea that they'd use 4-digit PINS from? It is
totally false.
(Anyone who doesn't believe me can just go through their web site --
it explains all of this to their customers.)
The system you propose as "safe" isn't used by anyone that I'm aware
of, and for good reason, too -- people who've done things like that
have been successfully attacked.
BTW, if anyone was this foolish, the fun you could have would be
amazing. You could rent a botnet for a few bucks and lock out half the
customer accounts on the site in a matter of hours. You could ruin
banks at will. It would be great fun -- only it isn't possible. No one
is stupid enough to set themselves up for that.
You would use the invalid accounts to reverse engineer the account
number format so you don't have to do exhaustive search. Any
practitioner in this field can tell you how useful intelligence like
that would be. I suggest you consult one.
But in an age where an attacker has millions of IP addresses at their
disposal thanks to botnets and IP block hijacking and can fake
anything they like, this is meaningless.
It is easy enough to blacklist all of the cable modems in the world
for SMTP service. ISPs voluntarily list their cable modem and DSL
blocks. It is a lot harder to explain to people that they can't do
their at-home banking from home, though. With half the windows boxes
in the world as part of botnets, and with dynamic address assignment,
it is hard to know who's computer *wouldn't* be on the blacklists
You have 10,000 PINs, and 10 million customers logging in a day. Every
PIN that gets attacked means a thousand of those customers can't get
to their account. They call up, which costs you $10 to $100 a pop in
customer service. So for every PIN someone tries hacking, you take a
$10,000 to $100,000 customer service cost. Since there are thousands
of PINs that will be attacked a day, this adds up fast, and you find
more or less none of your customers able to log in and almost all of
them angry as all hell at you.
Ed, there is a reason no one in the US, not even Wells Fargo which you
falsely cited, does what you suggest. None of them use 4 digit PINs,
none of them use customer account numbers as account names. (It is
possible SOMEONE out there does this, but I'm not aware of it.)  You
would impose enormous costs on yourself for almost no advantage. It is
trivial to make people use passwords that are harder to guess than a 4
digit number, so why cost yourself your whole retail operation for no
perceivable benefit?
Banks aren't stupid. They want to minimize their costs, not increase
them. Most banks aren't even happy using PASSWORDS any more -- they're
using "pick the face" systems, issuing Secure IDs, and I understand
some European banks even do stuff like mailing people cards with one
time passwords. The ones still using passwords are seriously looking
at the alternatives, though many of them consider the current losses
sufficiently low that they're not rushing.
I'll give you a chance for one more reply, but you might want to quit
while you're behind. I suspect you won't though.

@_date: 2008-07-01 12:46:44
@_author: Perry E. Metzger 
@_subject: The wisdom of the ill informed 
And, Wells Fargo will let you use your PIN as part of a lost password
procedure, although I believe they require a lot of other pieces of
information at the same time like account number, online account name
and SSN.
My experience with European banks is quite limited -- my consulting
practice is pretty much US centric. My general understanding, however,
is that they are doing better, not worse, with login security.
I knew part of it, but your additional information was worthwhile.

@_date: 2008-07-01 18:34:18
@_author: Perry E. Metzger 
@_subject: Strength in Complexity? 
No. In fact, it is about as far from the truth as I've ever
seen. No real expert would choose to deliberately make a protocol more
Complexity makes a protocol hard to analyze, and thus makes it hard to
know if the protocol is secure. The author of the quoted article, one
Dan Brown, clearly does not know how cryptographic protocol experts
analyze a protocol. (I've CCed him on this message to give him a
chance to reply, and I'll forward his replies if they're interesting.)
Indeed, I've often seen people forced to alter a protocol specifically
to make it analyzable -- see, for example, the JFK protocol that was
proposed in the IETF as an IKE replacement, which was formally
verified only after it had been changed specifically to improve the
ability to analyze it.
Complexity also makes secure implementation of a protocol much
harder. Indeed, it often makes it impossible to really know that an
implementation is secure even if it appears to meet the
specification. For example, see the numerous encoder flaws that have
been found over the years in protocols like SNMP specifically because
producing a safe ASN.1 compiler is so hard. For another example, see
the enormous interoperability challenges that people have had with
X.509 certificates, many of which have had security implications,
because the complexity has made proper operation in all instances
extremely difficult to implement.
Complexity also does not make something "harder to break
into". Indeed, it is usually the complexity of a system that provides
the unintended edge conditions necessary to find a hole. If anything,
simple systems are (usually) harder to find flaws in.
In general, complexity is the enemy of security, and any real security
professional could tell you that. Simple and tractable is always
better than complicated, all things being equal -- certainly NOT
the other way around.
Your instincts are not wrong. The details of what is simple yet secure
are, of course, not trivial. You can make things *too* simple. A
Caesar cipher isn't secure, even though it is much simpler than
AES. That said, complexity is never something people deliberately

@_date: 2008-07-01 20:28:14
@_author: Perry E. Metzger 
@_subject: Strength in Complexity? 
The problem, Peter, is that people who don't know you may mistake your
sarcasm for agreement with misconception in the article Arshad quoted.
Oh, and by the way, you missed half a dozen failed secure mail
protocols, SET (the Wikipedia article for SET really needs to be
changed from present to past tense), and 20 other easy examples. It is
sort of like shooting fish in a barrel, isn't it?
The point is not that fools (often including us) haven't built
monstrous ziggurats that failed. The point is that no one rational
should *SEEK* to make a protocol into monstrous ziggurat on the basis
that this will improve security, and don't pretend you don't agree,
because most of us know you better than that.

@_date: 2008-07-02 07:19:57
@_author: Perry E. Metzger 
@_subject: The wisdom of the ill informed 
-0400")
That is far, far better than the average US bank.

@_date: 2008-07-02 07:25:36
@_author: Perry E. Metzger 
@_subject: Strength in Complexity? 
Having been peripherally involved in the causation change for IKE, let
me confess that it was caused by human stupidity destroying the
alternatives. The author of the much cleaner spec asserted copyright
and control over it, and fearing lawsuits, people turned to the
the remaining alternative. A number of us were all to blame for the
I will point out that the "I Dislike IKE" pins were not rare at
meetings. Most people understood the situation as it happened.

@_date: 2008-07-02 11:27:05
@_author: Perry E. Metzger 
@_subject: Strength in Complexity? 
Sadly. That situation was long and complicated and I'd prefer not to
go into it -- and I'd prefer actually if others didn't either, as it
is much more about humans and non-security politics than it is about
security or cryptography.

@_date: 2008-07-02 13:31:32
@_author: Perry E. Metzger 
@_subject: ADMIN: microsoft.com anti-spam annoyances 
For some reason, Microsoft's anti-spam filter at microsoft.com is
rejecting a large fraction of the list's traffic as spam. I've looked
at the messages in question carefully and can't for the life of me
figure out why. We're not getting bounced regularly anywhere else.
If you're at Microsoft and missing some fraction of list traffic, now
you know why.

@_date: 2008-07-04 12:02:08
@_author: Perry E. Metzger 
@_subject: WoW security: now better than most banks. 
My bank doesn't provide any sort of authentication for logging in to
bank accounts other than passwords. However, Blizzard now allows you
to get a one time password keychain frob to log in to your World of
Warcraft account.

@_date: 2008-07-06 12:52:47
@_author: Perry E. Metzger 
@_subject: Bletchley Park may be able to get UK lottery money... 
There is some hope that Bletchley Park may be able to get money from
the UK national lottery, which is used to fund cultural institutions,
but nothing is nailed down yet. They're also apparently selling old
roofing slates as a fundraiser (they've been replacing them in the
process of fixing leaks in the main building.)
Hat tip: Slashdot.

@_date: 2008-07-07 16:33:16
@_author: Perry E. Metzger 
@_subject: disks with hardware FDE 
There are now a number of drives on the market advertising AES based
FDE in hardware, and a number of laptops available on the market that
claim to support them.
Has anyone had any real-world experience with these yet? Are there
standards for how they get the keys from the BIOS or OS? (I'm
interested in how they deal with zeroization on sleep and such.)
Lastly, anyone have any idea of whether the manufacturers are doing
the encryption correctly or not?

@_date: 2008-07-08 09:18:06
@_author: Perry E. Metzger 
@_subject: disks with hardware FDE 
Where do they get their IVs from?
In general, I feel like the only way to really verify that these
things are being done correctly is to be able (in software) to read
the ciphertext and verify that it is encrypted with the right key in
the right mode. The small amount I've heard about the design leads me
to worry that this is not actually possible.

@_date: 2008-07-09 10:30:06
@_author: Perry E. Metzger 
@_subject: I don't trust FDE drives. 
I've now talked to a few people affiliated with drive companies at
this point. One of them seems to really know what he's doing. The rest
appear not to. One has even spoken to me of keying material being
protected by "what are effectively one time pads" and "trust us, this
is our business" in ways that make me not trust him, or his company,
at all.
Based on what I've heard, I suspect that a grad student who wants a
*really* good paper could probably manage to humiliate a couple of
drive companies with a little bit of effort. It is likely to get you
plenty of publicity.
Also, at this point, I'm not sure one should trust FDE drives with
data that one really cares about. Software based solutions can be much
more readily analyzed and verified. They require much less trust that
a vendor has done their job right. I don't think one can trust the
hard drive vendors.

@_date: 2008-07-15 11:06:05
@_author: Perry E. Metzger 
@_subject: =?utf-8?Q?=E2=80=9CA?= Practical Attack on the MIFARE =?utf-8?Q?C?= 
Although the paper seems to be gone from Wikileaks, it is on cryptome:
Nothing shocking to regular readers of this list in the
paper. However, it is yet more evidence that no manufacturer, no
matter how large or reputable, should ever be trusted when they say
"our secret security system is really good, trust us."

@_date: 2008-07-22 10:09:00
@_author: Perry E. Metzger 
@_subject: Kaminsky finds DNS exploit 
The details of the exploit (or at least an exploit just as bad) have
now leaked. I'm not surprised -- any secret known by more than one
person doesn't remain secret for long, and what one person can figure
out can be figured out by others.
Still, it was good that we had a couple extra weeks to patch.

@_date: 2008-07-22 10:21:14
@_author: Perry E. Metzger 
@_subject: how to check if your ISP's DNS servers are safe 
Niels Provos has a web page up with some javascript that automatically
checks if your DNS caching server has been properly patched or not.
It is worth telling people to try.

@_date: 2008-07-29 11:33:57
@_author: Perry E. Metzger 
@_subject: "cryptomachines" web page 
A web site with lots of material and photographs of old cryptographic

@_date: 2008-07-29 17:40:14
@_author: Perry E. Metzger 
@_subject: exhibit of cold war eavesdropping equipment 
Via boingboing. The pdf brochure is quite interesting, though there
isn't much new in it.

@_date: 2008-06-01 08:53:38
@_author: Perry E. Metzger 
@_subject: Protection mail at rest 
"SSARES: Secure Searchable Automated Remote Email Storage"
by Keromytis et al,
There is probably other work out there. In some small part, this also
looks like the problem that Matt Blaze's CFS addressed, though in that
case it was to deal with untrusted remote file servers rather than
email servers.

@_date: 2008-06-03 16:30:53
@_author: Perry E. Metzger 
@_subject: ADMIN: end of "Can we copy trust" discussion 
I don't think anything new is being said in the "Can we copy trust"
discussion, so I'm calling a halt to it.

@_date: 2008-06-03 17:00:21
@_author: Perry E. Metzger 
@_subject: ADMIN: What is top posting, and why should you avoid it? 
A3: Please.
Q3: Should I avoid top posting on this mailing list?
A2: Because, by reversing the order of a conversation, it leaves the
    reader without much context, and makes them read a message in an
    unnatural order.
Q2: Why is top posting irritating?
A1: It is the practice of putting your reply to a message before the
    quoted message, instead of after the (trimmed) message.
Q1: What is top posting?

@_date: 2008-06-04 15:51:44
@_author: Perry E. Metzger 
@_subject: the joy of "enhanced" certs 
As some of you know, one can now buy "Enhanced Security" certificates,
and Firefox and other browsers will show the URL box at the top with a
special distinctive color when such a cert is in use.
Many of us have long contended that such things are worthless and
prove only that you can pay more money, not that you're somehow more
An object lesson in this just fell in my lap -- I just got my first
email from a spammer that links to a web site that uses such a cert,
certified by a CA I've never heard of ("Starfield Technologies, Inc.")
Doubtless they sell discount "Enhanced Security" certs so you don't
have to worry about paying more money either. I haven't checked the
website for drive by malware, but I wouldn't be shocked if it was
I'm thinking of starting a CA that sells "super duper enhanced
security" certs, where we make the company being certified sign a
document in which they promise that they're absolutely trustworthy.
To be really sure, we'll make them fax said document in on genuine
company letterhead, since no one can forge letterhead.

@_date: 2008-06-05 10:18:42
@_author: Perry E. Metzger 
@_subject: ADMIN: list downtime 
The list will be experiencing some delays later today while the server
managing it gets some needed maintenance. It should be down for a few
hours at most.

@_date: 2008-06-05 19:34:52
@_author: Perry E. Metzger 
@_subject: ADMIN: quick note about the list  
A quick note from your moderator:
A few people have asked about this recently so I thought I'd explain.
The list server blocks posts from people who are not list subscribers.
This is done at the incoming SMTP server, during the SMTP dialog,
based on envelope sender.
I do things this way because the list gets about one spam attempt
every two minutes (though on bad days it can be much more). Many of
those would be blocked by other means, but a few hundred hundred a day
would still get through. I could not possibly process this many
postings by hand.
Every once in a while, someone asks "do you have a way to let me post
from an email address that is not subscribed", and the answer is yes,
I do. The code that checks who is allowed to send to the list checks
both the normal subscribers and a special "post only" list. If it is
important for you to be able to post from an address you are not
subscribed on, contact me privately and appropriate arrangements will
be made.

@_date: 2008-06-07 17:22:08
@_author: Perry E. Metzger 
@_subject: Voting machines make mistake in Arkansas 
Bruce Haggard, an election commissioner in Faulkner County,
   Arkansas, is baffled by a problem that occurred with two voting
   machines in this month's state primary elections. The machines
   allocated votes cast in one race to an entirely different race that
   wasn't even on the electronic ballot. The problem resulted in the
   wrong candidate being declared victor in a state House nomination
   race.

@_date: 2008-06-09 19:46:40
@_author: Perry E. Metzger 
@_subject: skype claims they have no technical means to assist wiretapping 
Jennifer Caukin, Skype's director of corporate communications
     replied to us: "We have not received any subpoenas or court
     orders asking us to perform a live interception or wiretap of
     Skype-to-Skype communications. In any event, because of Skype's
     peer-to-peer architecture and encryption techniques, Skype would
     not be able to comply with such a request."

@_date: 2008-06-09 19:52:36
@_author: Perry E. Metzger 
@_subject: survey of instant messaging privacy 
Also from Declan McCullagh today, a full survey of instant message
service security:

@_date: 2008-06-10 17:18:47
@_author: Perry E. Metzger 
@_subject: A slight defect in the truncated HMAC code... 
National Cyber Alert System
   Technical Cyber Security Alert TA08-162A
SNMPv3 Authentication Bypass Vulnerability
   Original release date: June 10, 2008
   Last revised: --
   Source: US-CERT
Systems Affected
     * Multiple Implementations of SNMPv3
   A  vulnerability in the way implementations of SNMPv3 handle specially
   crafted packets may allow authentication bypass.
I. Description
   The  Simple  Network  Management  Protocol (SNMP) is a widely deployed
   protocol  that is commonly used to monitor and manage network devices.
   SNMPv3  (  RFC  3410)  supports a user-based security model (RFC 3414)
   that incorporates security features such as authentication and privacy
   control.  Authentication  for  SNMPv3 is done using keyed-hash message
   authentication  code  (HMAC), a message authentication code calculated
   using  a cryptographic hash function in combination with a secret key.
   Implementations  of  SNMPv3  may  allow  a  shortened HMAC code in the
   authenticator field to authenticate to an agent or a trap daemon using
   a  minimum HMAC of one byte. Reducing the HMAC to one-byte HMAC makes
   brute-force  authentication  trivial.  This  issue  is known to affect
   Net-SNMP   and  UCD-SNMP.  Other  SNMP  implementations  may  also  be
   affected.
II. Impact
   This vulnerability allows attackers to read and modify any SNMP object
   that  can  be  accessed  using the authentication credentials that got
   them into the system. Attackers exploiting this vulnerability can view
   and  modify  the  configuration  of these devices. Attackers must gain
   access  using  credentials  with  write  privileges in order to modify
   configurations.
III. Solution
   Please consult your vendor for more information.
Apply a patch
   Net-SNMP  has  released  a  patch  to  address  this  issue.  For more
   information,  refer  to  SECURITY  RELEASE: Multiple Net-SNMP Versions
   Released. Users are encouraged to apply the patch as soon as possible.
   Note that patch should apply cleanly to UCD-snmp too.
Enable the SNMPv3 privacy subsystem
   The  configuration  should  be  modified  to enable the SNMPv3 privacy
   subsystem  to  encrypt the SNMPv3 traffic using a secret, private key.
   This  option does not encrypt the HMAC, but does minimize the possible
   affects from this vulnerability.
IV. References
     * RFC 3410 -      * RFC 3414 -      * SECURITY   RELEASE:   Multiple   Net-SNMP   Versions   Released  -
     * US-CERT Vulnerability Note -
 ____________________________________________________________________
   The most recent version of this document can be found at:
 ____________________________________________________________________
   Feedback can be directed to US-CERT Technical Staff. Please send
   email to  with "TA08-162A Feedback VU in the
   subject.
 ____________________________________________________________________
   For instructions on subscribing to or unsubscribing from this
   mailing list, visit .
 ____________________________________________________________________
   Produced 2008 by US-CERT, a government organization.
   Terms of use:
 ____________________________________________________________________
   Revision History
   June 10 2008: Initial release

@_date: 2008-06-18 17:18:48
@_author: Perry E. Metzger 
@_subject: MD5 on GPU 
MD5 implemented in parallel on on a graphics card. It displays pretty
significant speedup for applications like password cracking...

@_date: 2008-06-30 18:58:06
@_author: Perry E. Metzger 
@_subject: The wisdom of the ill informed 
The initial WEP design was done without cryptography experts. The
design of subsequent generations of WiFi security was designed in the
face of backward compatibility constraints that severely limited the
space of possible designs.
I would claim that this is not an example of crypto experts getting it
wrong at all -- it is, in fact, an example of what can go wrong when
people who don't know what they're doing design cryptography into
something that's very widely deployed.

@_date: 2008-06-30 19:16:16
@_author: Perry E. Metzger 
@_subject: The wisdom of the ill informed 
You're completely wrong here. Lets go through just two of the ways.
There is a lot of structure in most bank account numbers. The space is
pretty easy to narrow down if you do a nickel's worth of homework. For
example, a typical bank bank might have the first three digits code
for the branch (and a list of branches is easy to find), and several
of the additional numbers code for account type, plus the space of
remaining numbers is not exactly randomly assigned. If you need
typical account numbers to examine to learn such secrets, you can buy
them in bulk online these days. I suspect that currently invalid
accounts are probably even cheaper than valid ones, though they're not
a stock item -- you would have to ask to get them.
Not really. These days, there are people hijacking huge IP blocks for
brief periods for spamming. People also hijack vast numbers of zombie
machines. Either technology is easily used to prevent block-by-IP
from doing squat for you.
I'm sure you will now go on about some other way to evade Dan's
crucial point, but it should be obvious to almost anyone that you're
not thinking like the bad guys. If you really want to go on about
this, though, I'll let you have as much rope as you like, though only
for a post or two as I don't want to bore people.
In any case, there are a large number of reasons US banks don't
(generally) require or even allow anyone to enter PINs for
authentication over the internet. I don't know much about the
practices of foreign banks, as for the most part I consult in the US.

@_date: 2008-06-30 19:22:01
@_author: Perry E. Metzger 
@_subject: The wisdom of the ill informed 
Indeed. In fact, one even finds many people who post to public mailing
lists who know less than they should. However, it is reasonably
straightforward to figure out who knows what in a given field. Things
like citation indexes, journal impact factors and such make a number
of these things reasonably easy even for the outsider, provided that
outsider knows what they're doing. One can also go through the
expedient of finding what a substantial number of practitioners
think. If most have one opinion, and one or two who don't seem
terribly sane have a very different one, you know who's who.
One of the most interesting things I find about most fields is the
fact that people who are incompetent very often fancy themselves
experts. There's a great study on this subject -- usually the least
competent people are the ones that feel highly confident in their
skills, while the people who aren't have more doubts. One sees this
very phenomenon on this very list, and not infrequently.

@_date: 2008-03-15 16:18:55
@_author: Perry E. Metzger 
@_subject: [ADMIN] List moderation resuming 
A combination of factors unexpectedly kept me away from moderation
duties for a few weeks. I'll be forwarding highlights of the backlog

@_date: 2008-03-19 14:52:33
@_author: Perry E. Metzger 
@_subject: how to read information from RFID equipped credit cards 
Nothing terribly new here -- short interview with someone who bought
an RFID credit card reader on ebay for $8 and demonstrates getting
people's credit card information at short distances using it. Still,
it is interesting to see how trivial it is to do.

@_date: 2008-03-26 13:13:28
@_author: Perry E. Metzger 
@_subject: NSA domestic intelligence "vacuum" 
WASHINGTON, D.C. -- Five years ago, Congress killed an experimental
   Pentagon antiterrorism program meant to vacuum up electronic data
   about people in the U.S. to search for suspicious patterns. Opponents
   called it too broad an intrusion on Americans' privacy, even after the
   Sept. 11 terrorist attacks.
   But the data-sifting effort didn't disappear. The National Security
   Agency, once confined to foreign surveillance, has been building
   essentially the same system.
Hat tip: Bruce Schneier's blog.

@_date: 2008-03-29 12:40:23
@_author: Perry E. Metzger 
@_subject: NSA declassified histories, cryptographic quarterly articles, online 
The NSA has been declassifying some interesting material of late:

@_date: 2008-05-03 17:00:48
@_author: Perry E. Metzger 
@_subject: User interface, security, and "simplicity" 
I'm one of those people who uses OpenVPN instead of IPSEC, and I'm one
of the people who helped create IPSEC.
Right now, to use SSH to remotely connect to a machine using public
keys, all I have to do is type "ssh-keygen" and copy the locally
generated public key to a remote machine's authorized keys file.
When there is an IPSEC system that is equally easy to use I'll switch
to it.
Until then, OpenVPN let me get started in about five minutes, and the
fact that it is less than completely secure doesn't matter much to me
as I'm running SSH under it anyway.

@_date: 2008-05-03 19:50:01
@_author: Perry E. Metzger 
@_subject: User interface, security, and "simplicity" 
I disagree. Fundamentally, OpenVPN isn't doing anything IPSEC couldn't
do, and yet is is fairly easy to configure. I believe that I could
easily come up with a simpler configuration still, but we have a
worked example, so I don't think we can claim it is impossible any
It is true that I can't make it easy to configure all possible
uses of IPSec easily, but it should be easy to do the easy things and
it isn't. If it was easy to do easy things and possible to do
complicated things, that would be a reasonable place to get to -- I
know of no IPSec configuration system that is like that.
Almost exclusively the use for such things is nailing up a tunnel to
bring someone inside a private network. For that, there is no need for
per user auth -- the general assumption is that the remote box is a
single user laptop or something similar anyway. You really just want
to verify that the remote host has a particular private key, and if it
does, you nail up a tunnel to it (possibly allocating it a local IP
address in the process). That solves about 95% of the usage scenarios
and it requires very little configuration. It also covers virtually
all use of IPSec I see in the field.
Again, there are more complex usage scenarios, and it may be more
complicated to set one of *those* up, but it is a shame that it is
difficult to do the simple stuff.

@_date: 2008-05-04 11:09:28
@_author: Perry E. Metzger 
@_subject: User interface, security, and "simplicity" 
I can't claim to like the innards, and it seems bizarre to me that the
designers didn't simply use IPSec encapsulated in UDP as the
underlying protocol. (Were I writing such a thing today, I might use
That said, in my usage pattern, I don't care much about the possible
security flaws. I would not recommend the package to clients, however.
It is obvious to anyone using modern IPSec implementations that their
configuration files are a major source of pain. In spite of this, the
designers don't seem to see any problem. The result has been that
people see IPSec as unpleasant and write things like OpenVPN when the
underlying IPSec protocol is just fine and it is the implementations
that are unpleasant.

@_date: 2008-05-04 20:05:28
@_author: Perry E. Metzger 
@_subject: User interface, security, and "simplicity" 
Absolutely. There is no reason one couldn't build an easy to configure
IPSec. Indeed, OpenVPN could simply use IPSec if its authors wanted
No one has created the easy to configure IPSec, however, so I don't
use IPSec for my own needs.
Myself, I don't handwave away said flaws. I don't recommend that
clients use OpenVPN, for example. On the other hand, most of my
clients can afford to pay admins to spend lots of time on this, and I
couldn't afford to spend the time myself.
Well, it is pretty easy to configure SSH safely. Set it to only use
public keys, copy your private key to the remote host in the
authorized_keys file, and you're more or less done. There is no reason
all the defaults can't be set up for a nice easy to use IPSec based
package in such a way that it requires a deliberate effort to make the
thing unsafe and it is more or less that easy to use.
Unfortunately, people just don't spend nearly the amount of time on
the UI for their IPSec systems that they do on the crypto, so they
spoil all the hard work they've done making the implementation sound
by making it impossible for ordinary people to understand.

@_date: 2008-05-04 20:14:42
@_author: Perry E. Metzger 
@_subject: OpenSparc -- the open source chip (except for the crypto parts) 
I'm glad to know that you have managed to disprove Rice's
Theorem. Could you explain to us how you did it? I suspect there's an
ACM Turing Award awaiting you.
Being slightly less sarcastic for the moment, I'm sure that a good
reverse engineer can figure out approximately what a program does by
looking at the binaries and approximately what an ASIC does given
good equipment to get the layout. What you can't do, full stop, is
know that there are no unexpected security related behaviors in the
hardware or software. That's just not possible.
With respect, no, you don't. If you did, then all the flaws in Windows
would have been found at once, instead of trickling out over the
course of decades as people slowly figure out new unintended
behaviors. Anything sufficiently complicated to be interesting simply
cannot be fully understood by inspection, end of story.
Now, the original poster was speaking about knowing that a piece of
hardware does exactly what it was originally spec'ed to do. Some of
that involves (among other things) knowing that the validation
information (which a reverse engineer has no access to) applies to the
resulting chip by virtue of knowing that what was compiled was
precisely what was originally validated. There is a valid concern

@_date: 2008-05-05 08:43:40
@_author: Perry E. Metzger 
@_subject: OpenSparc -- the open source chip (except for the crypto parts) 
An AND gate isn't Turing Equivalent.
Any modern processor is sufficiently larger than an AND gate that it
is no longer tractable. It isn't even possible to describe the
security properties one would need to (formally) prove.

@_date: 2008-05-05 08:47:14
@_author: Perry E. Metzger 
@_subject: OpenSparc -- the open source chip (except for the crypto parts) 
If it doesn't apply to humans, that implies that humans are somehow
able to do computations that Turing Machines can't. I am sufficiently
skeptical of that to say, flat out, I don't believe it. If anything,
Turing Machines are more capable -- humans are only equivalent to
(large) finite state machines.
Certainly. You can use formal methods to prove the properties of
certain specially created systems -- the systems have to be produced
specially so that the proofs are possible. What you can't do in
general is take an existing system and prove security properties after
the fact.

@_date: 2008-05-06 13:39:50
@_author: Perry E. Metzger 
@_subject: ADMIN: posting standards 
Just a few reminders from your moderator about posting etiquette:
0) Text only, please. HTML and text encoded weird ways like base-64,
   as well as MIME multiparts, are a big pain in the neck. I generally
   just reject them rather than repairing them.
1) Please do not top post when replying to other people.
2) If you're replying to someone else's email, edit down the quoted
   text to the minimum needed for comprehension.
3) Try to be concise.

@_date: 2008-05-08 08:46:24
@_author: Perry E. Metzger 
@_subject: It seems being in an explosion isn't enough... 
It was one of the most iconic and heart-stopping movie images of
   2003: the Columbia Space Shuttle ignited, burning and crashing to
   earth in fragments.
   Now, amazingly, data from a hard drive recovered from the fragments
   has been used to complete a physics experiment - CXV-2 - that took
   place on the doomed Shuttle mission.
Now, this article isn't written from a security perspective, but I
think the implications are pretty obvious: quite a bit can happen to a
hard drive before the data is no longer readable.

@_date: 2008-05-10 13:08:22
@_author: Perry E. Metzger 
@_subject: ADMIN: spotty moderation through Friday 
Moderation will be somewhat spotty until Friday, May 16th. A backlog
may develop -- my apologies.

@_date: 2008-05-12 07:37:37
@_author: Perry E. Metzger 
@_subject: root kits in SMM mode 
I'd been wondering for years when someone would set malware up to run
in systems management mode on x86 processors. Now someone has done it:

@_date: 2008-05-22 11:31:51
@_author: Perry E. Metzger 
@_subject: Bletchley Park museum in financial trouble 
A wonderful place. I hope it manages to pull through.

@_date: 2008-05-27 10:25:45
@_author: Perry E. Metzger 
@_subject: People's Army of Vietnam Cryptographic Branch History 
I noted the following going back on Cryptome today:
"A History of the Cryptographic Branch of the People's Army of
Vietnam, 1945-1975, with a supplement on Cryptography in the Border
Guard (formerly the Armed Public Security Forces) 1959-1989"
Translated and Edited by David W. Gaddy,
Center for Cryptologic History, National Security Agency, 1994

@_date: 2008-05-27 11:13:49
@_author: Perry E. Metzger 
@_subject: RIM to give in to GAK in India 
In a major change of stance, Canada-based Research In Motion (RIM)
   may allow the Indian government to intercept non-corporate emails
   sent over BlackBerrys.
Hat tip: Bruce Schneier's blog.

@_date: 2008-05-30 14:02:16
@_author: Perry E. Metzger 
@_subject: Comcast DNS entries temporarily hijacked 
Apparently some pranksters hijacked Comcast's DNS entries for a few
[Hat tip to Bill Squier for pointing the article out.]
This is hardly the first time such a thing has happened. No great harm
was done, but considerable harm could have been done.
For example, one wonders what would happen if bank like Chase that
foolishly trains their users to type passwords into non-https
protected pages had their DNS hijacked for a while. (Indeed, given the
fact that most users always ignore certificate warnings, even a pretty
good bank that consistently used https would have serious trouble.)

@_date: 2008-11-07 12:32:23
@_author: Perry E. Metzger 
@_subject: ADMIN: no money politics, please 
List Moderator's Edict of the Day:
A bunch of people seem anxious to branch the discussion of
cryptographic cash protocols off into a discussion of the politics of
money. I'm a rabid libertarian myself, but this isn't the rabid
libertarian mailing list. Please stick to discussing either the
protocols themselves or their direct practicality, and not the perils
of fiat money, taxation, your aunt Mildred's gold coin collection,

@_date: 2008-11-12 15:04:04
@_author: Perry E. Metzger 
@_subject: WPA crack 
A reasonable article on the WPA attack that has been making the rounds
on the blogs...
and the actual paper:
The attack is not very general, but it is interesting.
[Hat tip for the Ars Technica article to Bruce Schneier.]

@_date: 2008-11-17 16:43:33
@_author: Perry E. Metzger 
@_subject: ADMIN: end of bitcoin discussion for now 
I'd like to call an end to the bitcoin e-cash discussion for now -- a
lot of discussion is happening that would be better accomplished by
people writing papers at the moment rather than rehashing things back
and forth. Maybe later on when Satoshi (or someone else) writes
something detailed up and posts it we could have another round of this.

@_date: 2008-11-28 11:57:36
@_author: Perry E. Metzger 
@_subject: old codes in life magazine archive 
Photos of an old paper-and-pencil espionage cipher.
(Hat Tip: Bruce Schneier)

@_date: 2008-11-28 12:49:27
@_author: Perry E. Metzger 
@_subject: CPRNGs are still an issue. 
As it turns out, cryptographic pseudorandom number generators continue
to be a good place to look for security vulnerabilities -- see the
enclosed FreeBSD security advisory.
The more things change, the more they stay the same...
Begin forwarded message:
FreeBSD-SA-08.11.arc4random                                 Security Advisory
                                                          The FreeBSD Project
Topic:          arc4random(9) predictable sequence vulnerability
Category:       core
Module:         sys
Announced:      2008-11-24
Credits:        Robert Woolley, Mark Murray, Maxim Dounin, Ruslan Ermilov
Affects:        All supported versions of FreeBSD.
Corrected:      2008-11-24 17:39:39 UTC (RELENG_7, 7.1-PRERELEASE)
                2008-11-24 17:39:39 UTC (RELENG_7_0, 7.0-RELEASE-p6)
                2008-11-24 17:39:39 UTC (RELENG_6, 6.4-STABLE)
                2008-11-24 17:39:39 UTC (RELENG_6_4, 6.4-RELEASE)
                2008-11-24 17:39:39 UTC (RELENG_6_3, 6.3-RELEASE-p6)
CVE Name:       CVE-2008-5162
For general information regarding FreeBSD Security Advisories,
including descriptions of the fields above, security branches, and the
following sections, please visit .
I.   Background
arc4random(9) is a generic-purpose random number generator based on the
key stream generator of the RC4 cipher.  It is expected to be
cryptographically strong, and used throughout the FreeBSD kernel for a
variety of purposes, some of which rely on its cryptographic strength.
arc4random(9) is periodically reseeded with entropy from the FreeBSD
kernel's Yarrow random number generator, which gathers entropy from a
variety of sources including hardware interrupts.  During the boot
process, additional entropy is provided to the Yarrow random number
generator from userland, helping to ensure that adequate entropy is
present for cryptographic purposes.
II.  Problem Description
When the arc4random(9) random number generator is initialized, there may
be inadequate entropy to meet the needs of kernel systems which rely on
arc4random(9); and it may take up to 5 minutes before arc4random(9) is
reseeded with secure entropy from the Yarrow random number generator.
III. Impact
All security-related kernel subsystems that rely on a quality random
number generator are subject to a wide range of possible attacks for the
300 seconds after boot or until 64k of random data is consumed.  The list
* GEOM ELI providers with onetime keys.  When a provider is configured in
  a way so that it gets attached at the same time during boot (e.g. it
  uses the rc subsystem to initialize) it might be possible for an
  attacker to recover the encrypted data.
* GEOM shsec providers.  The GEOM shsec subsytem is used to split a shared
  secret between two providers so that it can be recovered when both of
  them are present.  This is done by writing the random sequence to one
  of providers while appending the result of the random sequence on the
  other host to the original data.  If the provider was created within the
  first 300 seconds after booting, it might be possible for an attacker
  to extract the original data with access to only one of the two providers
  between which the secret data is split.
* System processes started early after boot may receive predictable IDs.
* The 802.11 network stack uses arc4random(9) to generate initial vectors
  (IV) for WEP encryption when operating in client mode and WEP
  authentication challenges when operating in hostap mode, which may be
  insecure.
* The IPv4, IPv6 and TCP/UDP protocol implementations rely on a quality
  random number generator to produce unpredictable IP packet identifiers,
  initial TCP sequence numbers and outgoing port numbers.  During the
  first 300 seconds after booting, it may be easier for an attacker to
  execute IP session hijacking, OS fingerprinting, idle scanning, or in
  some cases DNS cache poisoning and blind TCP data injection attacks.
* The kernel RPC code uses arc4random(9) to retrieve transaction
  identifiers, which might make RPC clients vulnerable to hijacking
  attacks.
IV.  Workaround
No workaround is available for affected systems.
V.   Solution
NOTE WELL: Any GEOM shsec providers which were created or written to
during the first 300 seconds after booting should be re-created after
applying this security update.
Perform one of the following:
1) Upgrade your vulnerable system to 6-STABLE, or 7-STABLE, or to the
RELENG_7_0, or RELENG_6_3 security branch dated after the correction
2) To patch your present system:
The following patches have been verified to apply to FreeBSD 6.3 and
7.0 systems.
a) Download the relevant patch from the location below, and verify the
detached PGP signature using your PGP utility.
[FreeBSD 7.x]
# fetch # fetch [FreeBSD 6.x]
# fetch # fetch b) Apply the patch.
# cd /usr/src
# patch < /path/to/patch
c) Recompile your kernel as described in
 and reboot the
VI.  Correction details
The following list contains the revision numbers of each file that was
corrected in FreeBSD.
Branch                                                           Revision
  Path

@_date: 2008-10-24 08:31:25
@_author: Perry E. Metzger 
@_subject: ADMIN: backlog cleared 
Moderator's note: Yes, I'm alive. I've just been insanely busy. I'm
planning on adding a system so I can turn the list over to guest
moderators before this happens again (in about a month, I'm

@_date: 2008-10-30 16:30:20
@_author: Perry E. Metzger 
@_subject: Donald Knuth stops paying for errata 
It seems that Donald Knuth had his bank accounts attacked not once but
three times using his checking account number off of checks he sent
out for bounties for flaws in his books and software, and is thus
ending a practice of nearly 40 years. Rather sad.
I mark this as another milestone in the slow destruction of the idea
that it is okay for an account number to be the secret used to effect
payment in a transaction system.

@_date: 2008-09-01 10:49:08
@_author: Perry E. Metzger 
@_subject: ACH fraud 
Several people have sent in a link to a New York Times story on ACH fraud:

@_date: 2008-09-06 10:27:33
@_author: Perry E. Metzger 
@_subject: Quiet in the list... 
This is a ridiculous set of objections.
First, modern operating systems have tools so that users don't have to
manually build or "load up" various packages, they just cleanly
install.  My non-computer literate relatives manage to install the
flash plugin for their browsers without assistance -- this is clearly
not an issue any longer.
Second, if your new version of thunderbird doesn't work with some old
plugin, don't upgrade until it does! Rollback is pretty easy on
Windows, OS X, Ubuntu, Red Hat, etc. Not that this will happen in
practice if the plugin is popular.

@_date: 2008-09-08 10:31:26
@_author: Perry E. Metzger 
@_subject: once more, with feeling. 
I was shocked that several people posted in response to Peter
Gutmann's note about Wachovia, asking (I paraphrase):
"What is the problem here? Wachovia's front page is only http
protected, but the login information is posted with https! Surely this
is just fine, isn't it?"
I'm not going to explain why this is wrong. It should be obvious. If
it isn't obvious to you, you should try thinking like an attacker for
a few moments. If it still isn't obvious to you why this is very bad,
read the list archives.
(I won't be forwarding followups to this unless they are unusually

@_date: 2008-09-09 09:29:27
@_author: Perry E. Metzger 
@_subject: US firms donate $100,000 to help save Bletchley Park 
The Americans have joined the campaign to save Bletchley Park, the
   home of code breaking during the Second World War, as well as of
   Britain's computing heritage, with IBM and computer security
   specialist PGP already pledging 57,000 pounds (about $100,000) to
   secure the facility's future.
   The donation will help restore exhibits at the National Museum of
   Computing in Bletchley Park[...]

@_date: 2008-09-10 16:01:04
@_author: Perry E. Metzger 
@_subject: once more, with feeling. 
[Moderator's note: with my other hat on, let me say that although I'm
a libertarian, I do not want to have this mailing list fill with
libertarianism vs. statism arguments. I'm going to cut this off pretty
quickly. --Perry-as-moderator]
I have to disagree, for a wide number of reasons. I'll avoid getting
too deeply into them them here.
And yet, in spite of the efforts people make, we still have
significant problems, don't we? It doesn't take great genius to
understand why current spam legislation is flawed, but I haven't seen
it fixed even though you will be hard pressed to find many people who
claim to love spam. We have lots of legislation against various forms
of computer crime and yet we have virtually no prosecutions even
though something like half of the computers in the country have been
broken in to. We also used to have quite reasonable wiretap laws in
this country which were blown out of the water when political
expediency demanded it.
I contend that none of this is an accident, or particularly easy to
I don't see how that is going to change.
One can hope for an ideal, substantially superior world, but generally
speaking human beings have to live with the world that we have, and
most importantly with the behavior patterns of real people.
The core of the libertarian view on this and many other topics is not
that it wouldn't be wonderful if we had perfect legislation enforced
by perfect policemen, but that we must acknowledge that in the real
world we will get the result of a very flawed and problematic
political process which will be enforced humans rather than angels.
On the political process side, large companies with powerful interests
will be immediately involved once the topic of mandatory security
standards comes to the fore. Many of those companies will see
lobbyists as cheaper than IT infrastructure. There will also be those
who see legislation as an opportunity to cash in -- they will try to
twist the laws in such a way as to make a buck, by mandating solutions
they think will profit them. Some people in our profession may even
decide to do what cosmetologists, private investigators and even
doctors have done in the past, and reduce competition by requiring
licensing as a way of preventing others from entering in to their
field. We will also find that the people writing the regulatory
standards may very well be the sort who are not entirely right
minded -- not everyone in this field can even understand why http: is
a bad transport for bank login pages, so we can't expect that everyone
in the field can recognize good regulations.
I suspect the difference between one's aspirations and the output of
this process will be much like the difference between a dog before and
after it falls into a meat grinder. Much of the underlying material
remains, but the parts are no longer arranged into something you would
consider a faithful pet.
On the enforcement side, we will suddenly find ourselves in a
situation where people who are far from the best technically will be
asked to examine extremely complicated computer systems and to decide
whether to penalize firms for failing to properly comply with very
complicated regulations. I will not belabor the point -- having seen
the results of this in much less technical areas, like finance, I must
say that I do not have very high hopes for the outcome of the process.
Again, it is easy to say "there ought to be a law!", and it is much
harder to get the right law into place, and even then almost
impossible to get it properly enforced. I have very few hopes for this

@_date: 2008-09-22 14:01:21
@_author: Perry E. Metzger 
@_subject: More on Blackberry interception in India 
(I saw this on another mailing list -- a follow-on to earlier
discussions about Blackberry in India. No idea how believable any of
it is because there is a great deal of difference between the way
Blackberries work in a corporate and non-corporate context -- this
could just be interception at the mail server provided by the
cellphone company. --Perry)
At last, govt cracks BlackBerry code
22 Sep, 2008, 0121 hrs IST,Niranjan Bharati, ET Bureau
NEW DELHI: The government has decrypted the data on Research In
Motion's (RIM) BlackBerry networks. The department of
telecommunication (DoT), Intelligence Bureau and security agency
National Technical Research Organisation (NTRO) have done tests on
service providers such as Bharti Airtel, BPL Mobile, Reliance
Communications and Vodafone-Essar networks for interception of
Internet messages from BlackBerry to non-BlackBerry devices.
Initially, there were difficulties in cracking the same on
Vodafone-Essar network but that has also been solved. This means that
the e-mail messages sent on Internet through your BlackBerry sets
would no longer be exclusive and government would be able to track
"Decompression is being tested in operator's network with three
successful testing on Bharti Airtel, Reliance Communication and BPL
Mobile," a source in DoT said. He, however, added that the solution
reached upon would not be shared with anybody including the national
telecom service providers like BSNL or MTNL. "The test is being
conducted wholly for non-enterprise solutions," he said. The Union
cabinet has also been apprised of the recent developments by the DoT.
Makers of BlackBerry set, RIM, could not be contacted for comment. An
e-mail sent in this regard the company did not elicit any response
till the time of going for press. An official in Vodafone-Essar,
however, on conditions of anonymity said that there has been
substantial progress in decoding the BlackBerry encryptions and DoT
has got success on decompressing the data on the networks of all the
major service providers.
The test would be conducted on all the network of all the BlackBerry
service providers and the service providers, on whose network the
interception does not happen smoothly, would be asked to make
technical changes in their services to make them compatible for
decompression. Decompression is the process of decoding information
with an aim to transfer the data to a different medium like data to
voice, data to video or data to text.
The DoT had earlier asked RIM to provide the master key to allow
access to contents transferred over their handsets. RIM had, however,
said that it could not handover the message encryption key to the
government as its security structure does not allow any third party or
even the company to read the information transferred over its network.
The BlackBerry issue surfaced earlier this year when DoT asked Tata
Tele-services to delay the launch of the service till appropriate
security mechanisms were in place. Currently, there are over one lakh
BlackBerry users in the country.
Bharti Airtel, Reliance Communications, Vodafone Essar and BPL Mobile
are offering this service in the country. Tata Teleservices has also
been allowed to offer the BlackBerry services recently.
Incidentally, Tata Teleservices launched the service after telecom
secretary Siddhartha Behura said that the government has no role in
stopping the company from offering the service.

@_date: 2008-09-23 14:21:20
@_author: Perry E. Metzger 
@_subject: once more, with feeling. 
It might have been secure enough back in the days before almost every
machine was infected by things like drive-by malware. Now that the
hardware the user is on can no longer be trusted, this would only
raise the bar slightly, and cause the bad guys, who already own half
the machines on the net, to work a few more hours.
I won't say such a thing would be bad if it already existed, but it
seems like it would no longer be enough.

@_date: 2008-09-24 14:36:38
@_author: Perry E. Metzger 
@_subject: More on Blackberry interception in India 
Another followup seems to indicate they are indeed only looking at
traffic that wasn't encrypted end-to-end to enterprise customers.

@_date: 2008-09-24 17:45:14
@_author: Perry E. Metzger 
@_subject: Fake popup study 
419 scams are not caused by bad interfaces or bad engineering.
Phishing is, but clearly not all con games are, and con games are
remarkably profitable.
Although it is true that there are better and worse interfaces, and
that many of the interfaces we use right now are rather on the worse
side, it is apparent that one of the issues we have is the astonishing
depth of human stupidity.
To quote a common observation: You can't make things perfectly idiot
proof because idiots are too ingenious.
I was having a discussion over lunch about a week ago with a couple of
pretty well known security people (one of them might pipe up on the
list). We were considering what would happen in a particular seemingly
foolproof system with a trusted channel if someone got a message via
an untrusted channel saying...
  "Now, to complete your book purchase, the trusted system is going to
   say "If you press "YES", you're going to send all the money you
   have in the world to a con man in Nigeria" -- this is
   normal. Please press yes when it says that."
...a large fraction of users would just press "YES".
I don't want to claim that there is no place for better human factors
work in security engineering. There clearly is. However, I will
repeat, that is not the only story here, and it is not unreasonable to
note that there are people who are clearly nearly impossible to
protect with almost any level of human factors engineering and
security technology.

@_date: 2008-09-24 18:39:44
@_author: Perry E. Metzger 
@_subject: Fake popup study 
Hardly. In fact, it is a very important thing to bear in mind, as is
the output of that study.
The whole point of the study (which you feel had an "inappropriate
tone") and of such gedankenexperiments is to understand the problem
space better.
At one time, we believed that with enough crypto, we would be safe,
but we were disabused of that notion -- crypto is a great tool but not
a panacea. Now the notion seems to be that with enough human factors,
we will be safe. It appears this, too, is not a panacea.
There are all sorts of things to worry about. Human factors are
clearly an important component, but I think that the study (yes, the
one which you feel had an "inappropriate tone") is important -- some
people are too stupid to trust.
Clearly, by eliminating decisions people have to make (such as by
removing non-secure modes of operation), eliminating means by which
people can leak valuable information (such as by eliminating passwords
that they can give to fake "customer service representatives" and the
like), cleaning up the human factors, etc., we can make things much
However, the lesson of this sort of study is that we may never be able
to fix the problem. You contend the engineers are at fault, but
clearly they are only partially at fault -- there are (as I said) some
people who are too stupid to protect. We probably should not be
surprised by this -- there are clearly people we do not allow to cross
the street on their own (young children, some mentally ill people,
etc), so there is perhaps a class of people who should not be allowed
to do unsupervised banking on the basis that they cannot be trusted to
protect themselves adequately.

@_date: 2008-09-24 19:14:13
@_author: Perry E. Metzger 
@_subject: Fake popup study 
I don't think all the interfaces in question are inadequate. There are
glaring exceptions, such as the various interfaces in browsers to
determine if an SSL connection is trustworthy. However, not all the
interfaces are inadequate.
Does it? Are there really no people to whom one can apply that involved?
I have heard of cases in which, in spite of having been told point
blank by security people not to send any further money to a 419
scammer, people have continued sending it because, after asking the
419 people if they were a scam, were assured by them that they were
legitimate. Indeed, I've heard of worse. Short of of a court imposed
conservatorship, how is one to protect someone like that?
It is clear that user interfaces will always need to to allow people
to do things like transferring money or installing software, and it is
equally clear that such operations will always have some potential for
danger. Some people will not pay attention to warning signs of danger
in such interfaces regardless of how prominently they are displayed,
and we cannot make such things perfectly safe.
We can fancy up our language if you insist. For example, we can be
more polite (by speaking of users with "limited security problem
detection skills" and such). However, in the end, not all of these
people are victims of anything other than themselves.
Actually, a majority don't experience trouble. A majority *are*
infected with malware, but not because of any fault of their own --
driveby and other infection systems are just too pervasive, and the
majority use an operating system that is very full of holes.
However, most people seem to recognize 419 scams, phishing email,
etc. The problem is that a substantial minority do not, and a worse
problem is that a fraction of those cannot regardless of how much
"user education" is applied.
As I noted, we should indeed improve our interfaces, reduce
the number of opportunities such people have for causing themselves
harm (thus the notion of "always on security" etc.) and take all other
reasonable measures.
However, it is important, as I said, to see the limits. Some people
will always aim the gun at their feet and fire, no matter how many
trigger interlocks we add.

@_date: 2008-09-24 20:43:53
@_author: Perry E. Metzger 
@_subject: Fake popup study 
I don't disagree that much more needs to be done on human factors. I
just don't see it as a panacea. I also think understanding just how
little you can expect from the users, and what the limits are, is
I have a friend who's mother got conned after a stroke left her
excessively credulous. He arranged for caretakers to read all her
physical and electronic mail before letting her have it. Understanding
the limitations of your user community is important.

@_date: 2009-04-30 17:35:21
@_author: Perry E. Metzger 
@_subject: [ADMIN] backlog 
I'm back up for air again. The message backlog will be moved out over
the next few days, not necessarily in chronological order.

@_date: 2009-04-30 19:31:26
@_author: Perry E. Metzger 
@_subject: SHA-1 collisions now at 2^{52}? 
This is a very important result. The need to transition from SHA-1 is no
longer theoretical.

@_date: 2009-04-30 23:07:31
@_author: Perry E. Metzger 
@_subject: SHA-1 collisions now at 2^{52}? 
============================== START ==============================
Sure, but this should light a fire under people for things like TLS 1.2.

@_date: 2009-08-02 13:03:59
@_author: Perry E. Metzger 
@_subject: GPGPU MD5 collision search shown at Black Hat 
An implementation of MD5 collision searching done on GPUs instead of
ordinary CPUs -- substantially faster searches with fewer processors.
I imagine that if anyone really cared to generate such things really
quickly, custom hardware would be fastest of all.

@_date: 2009-08-19 15:56:18
@_author: Perry E. Metzger 
@_subject: [tahoe-dev] Tahoe-LAFS key management, part 2: Tahoe-LAFS is	like encrypted git 
The whole thing simply seems like a very obvious use of Merkle hash
trees. It is very understandable that many people familiar with Merkle
trees and related structures would think to apply them this way, since
it is more or less the purpose for which they were intended.

@_date: 2009-08-19 17:01:16
@_author: Perry E. Metzger 
@_subject: Crypto '09 rump session summary? 
Watching the rump session online briefly last night, I saw that some
interesting new results on MD5 and AES seem to have been discussed at
the conference. Would anyone care to give us a brief overview for the
mailing list?
Perry E. Metzger		perry at piermont.com

@_date: 2009-08-19 17:28:37
@_author: Perry E. Metzger 
@_subject: SHA-1 and Git (was Re: [tahoe-dev] Tahoe-LAFS key management,	part 2: Tahoe-LAFS is like encrypted git) 
I believe attacks on Git's use of SHA-1 would require second pre-image
attacks, and I don't think anyone has demonstrated such a thing for
SHA-1 at this point. None the less, I agree that it would be better if
Git eventually used better hash functions. Attacks only get better with
time, and SHA-1 is certainly creaking.
Emphasis on "eventually", however. This is a "as soon as convenient, not
as soon as possible" sort of situation -- more like within a year than
within a week.
Yet another reason why you always should make the crypto algorithms you
use pluggable in any system -- you *will* have to replace them some day.
Perry E. Metzger		perry at piermont.com

@_date: 2009-08-19 18:51:48
@_author: Perry E. Metzger 
@_subject: Certainty 
I believe that yesterday, at the rump session at Crypto, restricted
preimage attacks were described. Not quite what you want, but getting

@_date: 2009-08-22 22:42:35
@_author: Perry E. Metzger 
@_subject: NIST Requests Public Comments 
Forwarded message:
NIST announces the availability of two draft documents for public
comment: NIST Special Publication 800-38E and NIST Interagency Report
Draft NIST Special Publication 800-38E, Recommendation for Block Cipher
Modes of Operation: The XTS-AES Mode for Confidentiality on
Block-Oriented Storage Devices approves the XTS-AES mode of the AES
algorithm by reference to IEEE Std 1619-2007, subject to one additional
requirement, as an option for protecting the confidentiality of data on
block-oriented storage devices. This mode does not provide
authentication, in order to avoid expansion of the data; however, it
does provide some protection against malicious manipulation of the
encrypted data. The publication is available at
Comments on the text of the Draft NIST SP 800-38E may be submitted to
EncryptionModes at nist.gov until September 17, 2009.
Draft NIST Interagency Report 7609, Cryptographic Key Management
Workshop Summary (June 8-9, 200), is available at
The Cryptographic Key Management (CKM) workshop was initiated by the
NIST Computer Security Division to identify and develop technologies
that would allow organizations to leap ahead of normal development
lifecycles to vastly improve the security of future sensitive and
valuable computer applications. The workshop was the first step in
developing a CKM framework. This summary provides the highlights of the
presentations, organized by both topic and by presenter. Please provide
comments by September 18, 2009 to ebarker at nist.gov, with "Comments on
the Key Management Workshop Report" in the subject line.

@_date: 2009-08-25 09:39:59
@_author: Perry E. Metzger 
@_subject: SHA-1 and Git 
For one example, it is not theoretical that some people will often want
to use different algorithms than others and will need negotiation. Some
things like SSH have approximately done this right. Others have done
this quite wrong.
When we were planning out IPSec, a key management protocol, SKIP, was
proposed that had no opportunity for negotiating algorithms at all --
they were burned into the metal. As it happens, by now we would have had
to completely scrap it.
Of course you can go too far in the other direction. IPSec is a total
mess because there are far too many choices -- the standard key
management protocols are so jelly-like as to be incomprehensible and
You speak of "beyond versioning" as though introducing versioning or
algorithm negotiation were a trivial thing, but I don't think you can
generally tack such things on after the fact. You have to think about
them carefully from the start.
Perry E. Metzger		perry at piermont.com

@_date: 2009-08-25 17:17:14
@_author: Perry E. Metzger 
@_subject: Certainty 
That was the "restricted preimage" attack that I earlier mentioned
seeing in the video of the rump session. It isn't fully general, but it
is certainly disturbing.
As we're often fond of saying, attacks only get better with time, they
never roll back.

@_date: 2009-02-12 12:24:28
@_author: Perry E. Metzger 
@_subject: Property RIghts in Keys 
We're discussing certificates, not secret keys.
In theory, a secret key might be a trade secret.
However, a cert seems almost certainly *not* to be IP.
1) It can't be a trade secret, it is published.
2) It can't be patented.
3) It can't be copyrighted, it contains no creativity.
Again, that only holds in limited circumstances that probably don't
include certificates. In particular, trade secret protection here
seems impossible.

@_date: 2009-02-12 12:58:14
@_author: Perry E. Metzger 
@_subject: Property RIghts in Keys 
There are four kinds of intellectual property. Is it a trade secret?
No. Is it a trademark or something allied like trade dress? No. Is it
patentable? No. Is it copyrightable? No.
So, from there, it isn't intellectual property as understood in US
law. It might have certain features that make it look similar to some
form of intellectual property, but that says nothing. If it isn't a
trade secret, trademarked, patented or copyrighted, it doesn't
If the statutes and the courts don't know about it, it doesn't exist.
Anyway, one might also loudly wonder what the point of claiming
otherwise would be.
The point of claiming property rights is to restrict the use of
something. Once you've issued a certificate, how would you be
attempting to restrict its use?
Either the math already restricts its use in certain ways, or it
doesn't. If it doesn't, the cert is worthless. If it does, you need no
court to enforce your so-called "rights". The whole thing is clearly
the product of some lawyer with no idea what he was doing.

@_date: 2009-02-12 14:33:33
@_author: Perry E. Metzger 
@_subject: Property RIghts in Keys 
Perhaps if you put an original novel into an extension field you can
manage it. I don't think GeoTrust was doing anything like that.
Again, though, one has to question what is even to be gained by the
most avaricious of CAs by claiming rights in their certs. It isn't
like there is some clear benefit.

@_date: 2009-02-13 17:09:27
@_author: Perry E. Metzger 
@_subject: The Magic of X.509 Certification (was Re: Property Rights in Keys) 
It isn't strange -- it is part of the fairly frightening ecology we've
Lets remember briefly how we got here...
1) Netscape wanted to deploy SSL
2) ...but to do that, they needed some way of getting people trust
   anchors for the certificate system...
3) ...and lacking time for any sort of real protocol, the easy move
   was just building them in to the browser binaries...
4) ...and everyone else followed suit...
5) ...so now, being one of the magic CAs who's root certs are
   distributed with the commonly used browsers (IE, Safari, Firefox,
   Opera, etc.) is a license to print money.
6) ...as a result of which, lots of CAs have been bought, sold and
   traded around repeatedly.
This is all part and parcel of the problem that you can't *really*
trust the CAs terribly much. The security of your browser is, to a
large extent, dependent on the security practices of the least
diligent CA built in to your browser. (There are loads of other
problems too of course.)
It is particularly interesting to me how far we've come from the
original vision of X.509 -- indeed, a large fraction of our
infrastructure now uses X.500 DNs and X.509 certs in a manner totally
alien to the original vision for those technologies. There is no
global X.500 directory, there is no rigidly central global
certification hierarchy. The data formats have become a sort of mere
magical incantation -- almost no one involved has any any knowledge of
what any of it means, how it evolved, or what the real threats are.
To a scary extent, this includes people making critical security
decisions about the infrastructure.
With my moderator hat on, I'm not *too* interested in opening this up
again -- we've discussed it repeatedly in the past -- but I think a
reminder isn't a bad thing. I'll forward posts that have something
particularly new to say about the subject, or at least which say
something old in a particularly interesting way. :)

@_date: 2009-02-24 15:06:21
@_author: Perry E. Metzger 
@_subject: peer review of presentation requested 
If you expect to be presenting things at that level of detail to
developers, you're going to lose. There is no chance that they'll
absorb the details, and they'll get entirely the wrong message, which
is that they should be making decisions on such things instead of just
using prepackaged protocols.
The single most important lesson in cryptography is that cryptography
and cryptographic protocols are insanely hard to get right. The
average PHP hacker is not in a position to spend enough time to learn
the field well enough -- he's busy getting his application
working. Much better to avoid the entire issue.

@_date: 2009-02-25 12:19:42
@_author: Perry E. Metzger 
@_subject: NSA oral history interviews 
Yet more internal NSA history released to the public:

@_date: 2009-01-09 20:12:16
@_author: Perry E. Metzger 
@_subject: feds try to argue touch tone content needs no wiretap order 
Just about everyone knows that the FBI must obtain a formal
    wiretap order from a judge to listen in on your phone calls
    legally. But the U.S. Department of Justice believes that police
    don't need one if they want to eavesdrop on what touch tones you
    press during the call.
    Those touch tones can be innocuous ("press 0 for an operator"). Or
    they can include personal information including bank account
    numbers, passwords, prescription identification numbers, Social
    Security numbers, credit card numbers, and so on--all of which
    most of us would reasonably view as private and confidential.
    That brings us to New York state, where federal prosecutors have
    been arguing that no wiretap order is necessary. They insist that
    touch tones cannot be "content," a term of art that triggers legal
    protections under the Fourth Amendment.

@_date: 2009-01-11 13:26:40
@_author: Perry E. Metzger 
@_subject: What risk is being defended against here? 
The risk being defended against is a reprimand against some bureaucrat
for not "doing enough" to maintain test integrity. By demonstrating
that they have "tight procedures" etc., they can deflect blame if any
sort of cheating scandal occurs.
In general, most such rules are designed for JobSec, not for
ActualSec. In that light, a wide variety of stupid bureaucratic
behavior becomes not merely explicable but obvious.

@_date: 2009-01-28 14:03:57
@_author: Perry E. Metzger 
@_subject: Obama's secure PDA 
I would imagine it is a tempest shielded cable, and appropriately
altered connectors.

@_date: 2009-07-01 19:05:05
@_author: Perry E. Metzger 
@_subject: MD6 withdrawn from SHA-3 competition 
Also from Bruce Schneier, a report that MD6 was withdrawn from the SHA-3
competition because of performance considerations.

@_date: 2009-07-21 13:36:09
@_author: Perry E. Metzger 
@_subject: spyware on Blackberries 
An update: RIM confirms to its customers that the update was spyware
pushed on them by their own carrier.

@_date: 2009-07-21 22:48:56
@_author: Perry E. Metzger 
@_subject: New Technology to Make Digital Data Disappear, on Purpose 
Off topic, but actually DHCP is still needed. A machine needs to
configure a lot more than just its address and router in common cases
(it wants things like DNS servers, NTP servers, etc.) and in large
deployments, it is often far easier to let machines autoconfigure these
things during boot using DHCP even on comparatively hard wired
And with that, lets return to crypto...

@_date: 2009-07-26 14:27:03
@_author: Perry E. Metzger 
@_subject: The latest Flash vulnerability and monoculture 
This is purely about security, not on crypto.
For those of you not in the know, there is an exploitable hole in
Adobe's "Flash" right now, and there is no fix available yet:
(See also:
 )
The responsible thing would be to advise everyone to turn off flash
until Adobe comes up with a fixed binary, but of course, if they did,
large numbers of companies -- from the obvious Youtube and Hulu to the
less obvious business down the street that uses Flash to handle their
video catalog -- would be screwed. (Instead, of course, just about
everyone out there with a web browser is screwed.)
This highlights an unfortunate instance of monoculture -- nearly
everyone on the internet uses Flash for nearly all the video they watch,
so just about everyone in the world is using a binary module from a
single vendor day in, day out.
This is a bit of a wakeup call -- the use of standards based
technologies to deliver content to users would likely have led to
multiple implementations being in wide use, which would at least
mitigate such problems.
It would also help quite a bit if we had better encapsulation
technology. Binary plug-ins for browsers are generally a bad idea --
having things like video players in separate processes where operating
system facilities can be used to cage them more effectively would also
help to mitigate damage.
(By the way, for those that aren't aware, because recent versions of
Acrobat Reader include the ability for PDFs to embed Flash, you are
better off reading PDFs with third party PDF readers.)

@_date: 2009-07-26 20:17:19
@_author: Perry E. Metzger 
@_subject: ADMIN: slight list hiccup today 
If you submitted a post to the list for about an hour this afternoon
(as measured by the US/Eastern timezone), it probably bounced. There was
a brief period where email on the list server was misconfigured. My
apologies, and the problem has been fixed.

@_date: 2009-07-26 23:20:32
@_author: Perry E. Metzger 
@_subject: The latest Flash vulnerability and monoculture 
I'm aware of at least four TCP/IP implementations in common use, several
common HTTP servers (though there are far more uncommon ones), at least
four or six common web browsers (depending on whether you count the
several that use webkit as a single implementation or not), a half dozen
jpeg libraries, three different opentype implementations, etc., etc.
See above -- even counting only open source, we have *many*
implementations. Heck, there are even multiple independent open source
SSL, SSH and PGP implementations.

@_date: 2009-07-27 08:23:22
@_author: Perry E. Metzger 
@_subject: The latest Flash vulnerability and monoculture 
I could answer literal mindedly and note that QNX and a couple of other
embedded OSes let you do that (or so I recall).
However, it is clearly not necessary for that to be possible for people
to reap the benefits of diversity.
That's completely untrue -- the two situations are extraordinarily
For example, a high security firewall that has identical filtering boxes
with the same stack in front of and behind the DMZ has a 100% chance of
failure if a TCP bug is found, but will remain fine if two different
stacks are in use. (And yes, I've built systems like that, and for
exactly that reason.)
Perhaps, but I'm not using either, and neither are many of the worlds
largest web sites. There are a lot of web servers out there, and if you
want, you can pick any you like based on the characteristics you like.
Two, I think.
I have trouble thinking of a lot of types of protocol implementations
where there is only one available -- you originally claimed this was
rare, but it is, in fact, nearly the rule, not the exception.
I didn't even mention SMTP, where we have Sendmail, qmail, Postfix,
MMDF, and more, and that's just the open source offerings. IMAP
implementations are even more diverse.
Anyway, you claimed there aren't a lot of diverse protocol
implementations, and there are for practically everything important I
can think of. You asked:
...and the answer is, for typical protocols that are widely used, quite
a number. If you want to argue that multiple implementations aren't
interesting, that's another question, but you claimed they don't exist,
and generally, in fact, they do exist.
Having multiple supermarket companies or computer companies is also
"expensive". None the less, we seem to have that happen.

@_date: 2009-06-01 10:46:01
@_author: Perry E. Metzger 
@_subject: Mifare Plus deployed in LA 
It appears on the surface that the lesson may have been learned, but
I'll reserve judgment until I hear a real analysis of the new system.
   Matsumoto added the latest cards, including 128-bit Advanced
   Encryption Standard (AES) cryptology and an easy migration path from
   the existing Mifare Classic infrastructures, anticipates system
   security requirements for the future.

@_date: 2009-06-27 21:57:39
@_author: Perry E. Metzger 
@_subject: password safes for mac 
Does anyone have a recommended encrypted password storage program for
the mac?

@_date: 2009-06-28 14:34:16
@_author: Perry E. Metzger 
@_subject: password safes for mac 
The fact that it isn't open source worries me a bit -- it means I can't
verify that it does things correctly. Also, it integrates heavily with
lots of things, which makes me further worry about bugs. I'm looking for
something very simple if possible.

@_date: 2009-06-28 15:15:33
@_author: Perry E. Metzger 
@_subject: password safes for mac 
Thanks for the tip, I just quickly glanced at the code.
It has problems. Among other things, it only mlocks your session key
itself into memory, leaving both the AES key schedule (oops!) and the
decrypted data (oops!) pageable into swap. (Why bother mlocking the text
of the key if you're not going to lock the key schedule?)
It is also a pretty large program (nearly 28k lines!) written in
C++. (They even created a "SecString" class just for the session key.)
This much code is too big for me to understand and audit for real --
doubtless there are more things I would want to know lurking.
(Of course, this is why I wanted to have something open source to look
at -- I have no idea if 1Password does things like mlocking correctly
and I never will know because it is closed source and thus not amenable
to examination.)

@_date: 2009-06-28 16:43:18
@_author: Perry E. Metzger 
@_subject: password safes for mac 
Sure, but whether an application does mlock properly is a proxy
for whether other things are done properly. I looked at that because I
could do so in about five minutes without much fuss. Doing a proper
audit of 28klocs is otherwise not something one does casually.

@_date: 2009-06-28 16:42:02
@_author: Perry E. Metzger 
@_subject: password safes for mac 
There are some things it doesn't work with that are of interest here.

@_date: 2009-06-28 17:48:24
@_author: Perry E. Metzger 
@_subject: NIST optimized AES hardware... 
Apparently, NIST has produced an interestingly optimized design for AES
S-box hardware implementations:

@_date: 2009-06-30 10:29:08
@_author: Perry E. Metzger 
@_subject: CSE growing so fast it needs new offices 
The CSE, Canada's NSA equivalent, is apparently growing so fast that
they need new office buildings to hold all their new staff.
Hat tip: Bruce Schneier's blog.

@_date: 2009-03-03 12:26:32
@_author: Perry E. Metzger 
@_subject: Judge orders defendant to decrypt PGP-protected laptop 
A federal judge has ordered a criminal defendant to decrypt his
   hard drive by typing in his PGP passphrase so prosecutors can view
   the unencrypted files, a ruling that raises serious concerns about
   self-incrimination in an electronic age.

@_date: 2009-03-03 13:20:22
@_author: Perry E. Metzger 
@_subject: Judge orders defendant to decrypt PGP-protected laptop 
This sort of thing has been discussed for a long time, but I doubt
that would work in practice. Law is not like software. Judges operate
on reasonableness, not on literal interpretation. If it was reasonably
obvious that you were using software like that and probably not
cooperating, the judge would just throw you in jail for contempt of
court anyway.
Well, it should be clear that any such scheme necessarily will produce
encrypted partitions with less storage capacity than one with only one
set of cleartext. You can't magically store 2N bytes in an N byte
drive -- something has to give. It should therefore be reasonably
obvious from partition sizes that there is something hidden.
In any case, unless you're really very energetic about it, it will be
obvious from things like access times and other content clues ("gee,
why is there nothing in the browser cache from the current year?")
that what is there is not the "real" partition you use day to day.

@_date: 2009-03-03 13:53:50
@_author: Perry E. Metzger 
@_subject: Judge orders defendant to decrypt PGP-protected laptop 
The judge doesn't "need" to know the difference to beyond any
doubt. If the judge thinks you're holding out, you go to jail for
Geeks expect, far too frequently, that courts operate like Turing
machines, literally interpreting the laws and accepting the slightest
legal "hack" unconditionally without human consideration of the impact
of the interpretation. This is not remotely the case.
I'll repeat: the law is not like a computer program. Courts operate on
reasonableness standards and such, not on literal interpretation of
the law. If it is obvious to you and me that a disk has multiple
encrypted views, then you can't expect that a court will not be able
to understand this and take appropriate action, like putting you in a

@_date: 2009-03-03 18:38:45
@_author: Perry E. Metzger 
@_subject: Judge orders defendant to decrypt PGP-protected laptop 
-0500")
Again, you seem to be operating under the common geek misperception
that courts operate like Turing machines, precisely and literally
executing precisely defined legal concepts.
They do not work that way.
Courts work much more the way the high school vice principal who put
you on detention for three weeks for throwing a snowball worked --
even though he didn't see you throw one, he just saw you were the only
person in the general vicinity, even though it was all patently unfair
since he had no "proof" by your lights.
The law's idea of what sufficient evidence means is not what you, as a
geek, think sufficient evidence means. For example, perhaps to you,
"beyond a reasonable doubt" means something like "there is no way you
couldn't be guilty", while to a court it means nothing like that -- it
means that an ordinary person (that is, not a geek, not a professional
defense attorney, not a mystery novel addict) wouldn't have serious
doubts about guilt. Not no doubts -- just no serious ones.
The law is used to people trying to weasel out of trouble -- people
have been trying to weasel out of trouble since the year 100,000
BC. Criminals were trying far more elaborate schemes to get out from
under trouble than you will ever think of back in ancient
Mesopotamia. You're not going to find something new that impresses a
real court.
Take a real common case. Someone is mugged by two people. One of them
shoots the victim and neither will say which of them did it. You, the
geek who thinks the law is a Turing machine, assume that neither can
go to jail for murder. "In the case of each criminal", you assume,
"there is a reasonable doubt as to whether or not the other guy did
it. 50/50 is a way reasonable doubt!"
Well, that's not how the real legal system works. In the real legal
system, the court will happily put both people in jail for murder even
though there is only one bullet in the victim so only one person could
have pulled the trigger. That's routine, in fact, never mind how
"unfair" that seems to you. (The charge of felony murder exists
precisely so that they don't need to know who pulled the
trigger. As I said, they're used to people trying to weasel out of
"But but!" you scream, "there has to be a reasonable doubt there! Only
one of them could have done it, clearly one person is in jail
unfairly, they both have to go free!" -- well, that's the difference
between you and a lawyer. The lawyer doesn't see this as
unreasonable. The court system is not a Turing machine.
Back to our topic: if the software can handle multiple hidden
encrypted volumes and there is unaccounted for space and the volume
you decrypt for them has nothing but pictures of bunnies and sunsets
and hasn't been touched in a year, I think you're going to jail for
contempt if the judge has ordered you to fork over the files.
"But!!!" you insist, "they don't have proof that I'm doing something
qua proof, they just a strong suspicion! Why, it could be anything in
that giant pool of random bits on the rest of the drive! How do they
*know* it isn't just random bits? How do they *know* I don't just look
at bunnies and sunsets and haven't opened that partition in a year?"
You only think that will protect you because you don't understand the
legal system. You see, you're making this assumption that most people
would call "assuming the judge is an idiot".
Judges take a very dim view of people playing them for fools, just
like high school vice principals, and again, the legal system is not a
Turing machine. The judge's superiors on the appeals court will take a
similar view because they were once trial judges and don't like when
judges are played for fools either.
So, the court is not going to pay the least attention to your
elaborate claims that you just like storing the output of your random
number generator on a large chunk of your hard drive. They really
don't give a damn about claims like that. Actually they do
care. They'll be pissed off that you're wasting their time.
If you believe otherwise, go right ahead, but as I said, the jails are
filled with people who have tried very elaborate strategies for
avoiding prison only to discover courts don't care. The courts are
used to people not wanting to go to jail and arguing all sorts of
stuff. Believe the courts are Turing machines if you like, but I don't
think anyone *rational* should go on that assumption. A rational
person is not going to assume that they're going to get off based on
an elaborate technological attempt to confuse the court. They won't.

@_date: 2009-03-05 14:15:18
@_author: Perry E. Metzger 
@_subject: the bad idea that would not die 
Aussie govt considers quantum leap in secure comms
   Commonwealth departments to trial Quantum Key Distribution.
   Australian governments may soon have the world's most secure data
   communication system if trials of a locally-developed quantum
   cryptography technology are successful.

@_date: 2009-03-07 22:28:21
@_author: Perry E. Metzger 
@_subject: NCSC official quits over NSA interference 
A top federal cybersecurity official resigned this week in a letter
   sharply critical of what he described as a power grab by the
   National Security Agency.
   Rod Beckstr?m, director of Homeland Security's National
   Cybersecurity Center, said in his letter that NSA "effectively
   controls DHS cyber efforts through detailees, technology
   insertions," and has proposed moving some functions to the agency's
   Fort Meade, Md., headquarters.

@_date: 2009-05-02 00:33:46
@_author: Perry E. Metzger 
@_subject: [tahoe-dev] SHA-1 broken! 
(BTW, you mean threat, not threat *model*, in this instance.)
As just one obvious example of a realistic threat, consider that there
are CAs that will happily sell you certificates that use SHA-1.
Various clever forgery attacks have been used against certs that use
MD5, see:
Those attacks can now be extended to SHA-1 pretty easily. It might
require a bit of compute infrastructure -- say a lot of FPGAs and a
bunch of cleverness -- to turn out certs quickly, but it can be
done. Given that there are lots of high value certs out there of this
form, this is rather dangerous.
For example, Verisign has lots of cert infrastructure right now that
uses SHA-1. Imagine if I now use the above described attack and start
forging certs that look to all the world like they're from Verisign and
claim that I'm a major bank, or to forge a CA that then forges certs
that claim I'm a major bank. "Ooops!"
One can easily imagine a forgery attack right now where someone
presented you with one piece of code which you sign and then made use of
a different piece of code with the exact same SHA-1 which you didn't
intend to sign. I don't know if Debian's specific processes are
vulnerable or not to various clever attacks -- it would require a lot of
thinking even if I was familiar enough with them, and I'm not.
So, use something other than SHA-1 -- SHA-256 at least. Don't panic,
don't flail around like a headless chicken, but do move away with all
deliberate speed.
Perhaps, if they're clever enough. The most obvious attacks require
preimage weaknesses, and those aren't known yet. However clever people
can find ways to get around this -- see the "Rogue CA" attack -- and
cause havoc.
See the "Rogue CA attack" -- by being clever enough, one can almost
certainly produce two executables with the same SHA-1 hash. They would
need some sort of area that varied, but that's not too hard -- ELF note
sections, data segments regions that contain some blob of data you don't
care about, etc., are all fine possibilities.
So, don't use SHA-1 if you can help it. This is not to say that all uses
are unsafe. There is also no need to panic. However, it is clearly not a
good idea to continue using it.

@_date: 2009-05-02 00:43:43
@_author: Perry E. Metzger 
@_subject: [tahoe-dev] SHA-1 broken! 
Eric Rescorla correctly points out to me that Verisign randomizes SNs so
it would be hard to attack them that way, but I'm sure not everyone
who is in the root cert list in IE or Firefox does.
It also is not going to be trivial to do this -- but it is now in the
realm of possibility.

@_date: 2009-05-02 10:37:17
@_author: Perry E. Metzger 
@_subject: SHA-1 collisions now at 2^{52}? 
No immediate threat. The issue is that attacks only get better with
time. Now that we've seen this set of attacks, we can't be entirely sure
what will happen next. In three or five years, we may find that
HMAC-SHA1 is more easily attacked than it is now.
On the 1.2 issue, the real point of 1.2 is not to replace SHA-1 per se
but to permit us to deal with the situation where *any* algorithm proves
to be dangerously weak. We've learned this lesson several times now --
it is best to have protocols that can move to new crypto algorithms as
old ones need to be abandoned.
Note that I said "things like" TLS -- TLS is not the only issue. There
are many out there. There is no need to panic over any one of them, but
it would be good to get things replaced.
Right now, without much of a rush or any real anxiety about it we can
take the several years needed to move new mechanisms out. If we dither,
then in a few years we may find ourselves having a much less pleasant
transition where suddenly the problem isn't long term but immediate.
No, they clearly won't notice at all. However, lets broaden this and
consider not only phishermen but all attackers.
Remember, attackers go for the lowest hanging fruit, not for any
particular technique. They pick the weakest links available. The reason
bad crypto has not been an attack point is because other things have
been much easier to attack than the crypto. I would prefer to keep it
that way.
My worry isn't about the phishermen per se. My worry is about things we
haven't thought about -- tricks like the CA forgery trick lying in wait
for us. There are more and more things out there that depend on the
crypto being right -- things like signed software updates, people who
actually *need* authentication for life critical systems, etc. If we
clean things up now, in three or five or seven years we won't have to
There is no need to panic, but clearly the handwriting is on the
wall. The time to act is early when it is inexpensive to do so.
Home routers and other equipment last for years. If we slowly roll out
various protocol and system updates now, then in a number of years, when
we find ourselves with real trouble, a lot of them will already be
updated because new ones won't have issues. If we wait until things get
bad, then instead of being a natural part of the upgrade cycle things
get to be expensive and painful.

@_date: 2009-05-05 10:44:52
@_author: Perry E. Metzger 
@_subject: [tahoe-dev] SHA-1 broken! 
IPSec and IPSec related protocols like IKE use SHA-1 in various
places. Whether those actually could be attacked using the known
weaknesses in SHA-1 would require detailed examination of the individual
In general, uses that require only preimage resistance are not yet at
risk, those that require collision resistance are. However, as has been
seen in the MD5-based fake CA attack, sufficiently clever people can
sometimes come up with ways to turn something that appears to depend on
preimage resistance into something that really only depends on collision
This is all another way of saying "no reason to panic, but moving to
things that use SHA-2 instead of SHA-1 would be a good idea".

@_date: 2009-05-07 23:00:54
@_author: Perry E. Metzger 
@_subject: 80-bit security? 
FPGAs are fairly slow and large. Using full custom designs, one could
easily get sufficient speedup on individual cracking units and a
sufficient increase in the number of cracking units because of the
reduction in area chip area for each unit that one could easily make up
for the 256x increase in cracking time between a 56 bit and 64 bit
cipher. There is therefore no question that 64 bits is in easy range at
this point.
One can easily get more bang per watt by clocking things slower. Power
dissipation is (quite) non-linear in clock rate. Since this problem is
embarrassingly parallel, I suspect that power vs. parallelism tradeoffs
are quite easily made, and I'm sure that, given the scale of such a
project, it would be quite easy to optimize the cost of power vs. the
cost of hardware to find the cheapest possible spot on the curve.
If you had access to an ultra-modern process -- 45nm with High K
dielectrics, etc., -- I think you could get quite impressive densities
of cracking units on a single die.
That said, the expense of a cracker that could go through an 80 bit
space is not insignificant. Naive back of the envelope calculations,
even assuming substantial cost benefits from fully custom design, give
me the impression that a cracker that can do 80 bits in a week is still
a billion dollar proposition -- worthwhile for a large nation-state with
very high value targets, but not worthwhile for anyone else.
(Can anyone else try the back of the envelope and say if mine is more or
less right?)
The other problem is, of course, that it isn't obvious what the target
of such a cracking cluster would be at this point.  3DES and AES are
beyond the capabilities of such a cluster.  Presumably an nation state
would have to need to attack specialized algorithms used by opponents
who are stupid enough to use short key lengths but smart enough not to
use algorithms that are themselves weak and thus attacked without
exhaustive search.

@_date: 2009-05-22 10:55:17
@_author: Perry E. Metzger 
@_subject: End-of-chapter questions for "Practical Cryptography"? 
Not quite an answer to your question, but it brought this to mind for me.
I taught crypto for a while in an academic setting, though the last time
was about seven or eight years ago. I found that the available texts
were kind of frustrating to use. I used "Applied Cryptography" and the
"Handbook" because neither alone was good enough, but truth be told,
even together there were topics I wanted to go over (like modern
cryptanalysis) which were entirely or almost entirely
missing. "Practical Cryptography" is a bit too practical if one is
trying to teach people academic fundamentals rather than just teach
people about what they need to know to be a "user" of the technology. I
may be mistaken but I'm not aware of any significantly superior
The field really needs a new, thorough textbook suitable for a one year
course, or maybe an up to date one semester intro text and an up to date
one semester textbook on modern cryptanalysis.

@_date: 2009-11-08 13:08:54
@_author: Perry E. Metzger 
@_subject: TLS break 
I'll point out that in the midst of several current discussions, the
news of the TLS protocol bug has gone almost unnoticed, even though it
is by far the most interesting news of recent months.

@_date: 2009-10-01 10:46:23
@_author: Perry E. Metzger 
@_subject: [Barker, Elaine B.] NIST Publication Announcements 
It is also completely impossible to prove you've deleted a
record. Someone who can read the record can always make a copy of
it. Cryptography can't fix the DRM problem.

@_date: 2009-10-01 12:49:26
@_author: Perry E. Metzger 
@_subject: [Barker, Elaine B.] NIST Publication Announcements 
If you have that more limited need, the Haber & Stornetta protocol will
likely do what you want, provided you can set something up to publish
the "widely witnessed events". (They had a company for a while to do
timestamping that published the hashes in the New York Times
classifieds. I think when they wrote their paper, the idea that
newspapers might soon cease to exist was not anticipated -- a more
modern system will need some sort of more durable model.)

@_date: 2009-10-14 18:24:06
@_author: Perry E. Metzger 
@_subject: Possibly questionable security decisions in DNS root management 
Ekr has a very good blog posting on what seems like a bad security
decision being made by Verisign on management of the DNS root key.
In summary, a decision is being made to use a "short lived" 1024 bit key
for the signature because longer keys would result in excessively large
DNS packets. However, such short keys are very likely crackable in short
periods of time if the stakes are high enough -- and few keys in
existence are this valuable.

@_date: 2009-10-14 19:22:27
@_author: Perry E. Metzger 
@_subject: Possibly questionable security decisions in DNS root management 
That doesn't say anything about how good an idea it is, any more than an
architect can make a building remain standing in an earthquake by
invoking the construction code.
We are the sort of people who write these sorts of guidelines, and if
they're flawed, we can't use them as a justification for designs.
(Well, a bureaucrat certainly can use such documents as a form of CYA,
but we're discussing technology here, not means of evading blame.)
The fact is, the DNS root key is one of the few instances where it is
actually worth someone's time to crack a key because it provides
enormous opportunities for mischief, especially if people start trusting
it more because it is authenticated. Unlike your https session to view
your calendar or the password for your home router, the secret involved
here are worth an insane amount of money.

@_date: 2009-10-14 19:54:36
@_author: Perry E. Metzger 
@_subject: Possibly questionable security decisions in DNS root management 
Well, you might look at Ekr's argument, which I largely agree with. I
think the two key observations are that 1024 bit keys are already
considered iffy, large (perhaps hundreds of millions of dollars or even
more) may be thrown by opponents at this particular key, and that
technology for factoring will only get better. Given the sums that could
be spent, very specialized hardware could be built -- far more
specialized than ordinary PCs on which the problem doesn't scale that
well in its most expensive steps.
Security is usually not limited by cryptography in the modern
world. Crypto systems are usually far stronger than opponents will to
spend, and bugs are the more obvious way to attack things.  However, if
you're talking about a really high value target and "weak enough"
crypto, the economics change, and with them so does everything else.
Crypto being a potential weak spot is an exceptionally rare situation,
but the DNS root key is insanely high value.
We should also recognize that in cryptography, a small integer safety
margin isn't good enough. If one estimates that a powerful opponent
could attack a 1024 bit RSA key in, say, two years, that's not even a
factor of 10 over 90 days, and people spending lots of money have a good
record of squeezing out factors of 10 here and there. Finding an
exponential speedup in an algorithm is not something one can do, but
figuring out a process trick to remove a small constant is entirely
Meanwhile, of course, the 1024 bit "short term" keying system may end up
staying in place far longer than we imagine -- things like this often
roll out and stay in place for a decade or two even when we imagine we
can get rid of them quickly. Do we really believe we won't be able to
attack a 1024 bit key with a sufficiently large budget even in 10 years?
Again, normally, crypto isn't where you attack an opponent, but in this
case, I'd suggest that key length might not be a silly thing to worry
There are enough people here with the right expertise. I'd be interested
in hearing what people think could be done with a fully custom hardware
design and a budget in the hundreds of millions of dollars or more.

@_date: 2009-10-15 00:16:59
@_author: Perry E. Metzger 
@_subject: Possibly questionable security decisions in DNS root management 
Actually, there are routine attacks on DNS infrastructure these days,
but clearly they're not cryptographic since that's not
deployed. However, a large part of the point of having DNSSEC is that we
can then trust the DNS to be accurate so we can insert things like
cryptographic keys into it. Once we've made the DNS trusted, we have the
problem that people will go off and trust it, you see.
I'm particularly concerned about the fact that it is difficult to a
priori analyze all of the use cases for DNSSEC and what the incentives
may be to attack them. If you can't analyze something, that's a warning
that you don't understand the implications. That makes me fear anything
that says "the key doesn't need to be more than strength X".
Sure, perhaps it is true that the expense of DNSSEC isn't worth it -- we
limp along without it now, as you point out -- but if that is true, what
do we gain by deploying a system which could be compromised in so
straightforward a way, with money being the only constraint? Why deploy
at all if we aren't going to be able to use it as we want? If we can't
trust the data very well, we've spent lots of time and money and gained
I'm doubly questioning because it seems pointless anyway -- the point of
the shorter keys is to avoid needing TCP connections to DNS servers, but
so far as I can tell that will end up becoming rapidly necessary anyway,
at which point one has to ask what one is gaining by lowering key length.
BTW, I've come across some (old) estimates from Shamir et all that
indicate a TWIRL machine that could break 1024 bit keys in a year would
have cost about $10M something like 5 years ago using a 90nm process. At
this point, with 32nm processes available, they'd be substantially
cheaper, and thus with a serious budget it seems like we're really quite
on the edge here.
Even $10M may now be enough to break them fast enough if you can come up
with a clever speedup of only a small factor, and I don't like trusting
security to the idea that no one with a large budget is clever enough to
find a small constant factor speedup. I presume that in another 10 years
we'll have a quite serious reduction in cost, which is yet worse. All in
all, that's too close for comfort, especially since I can see the point
in a Large Bad Actor spending orders of magnitude more on this than just

@_date: 2009-10-22 10:12:06
@_author: Perry E. Metzger 
@_subject: Possibly questionable security decisions in DNS root management 
You're not correct. Among other things, I've personally been the subject
of deliberate DNS cache contamination attacks, and people have observed
deployed DNS response forgery in the field.
Feel free to find it "constructed". From my point of view, if I can't
analyze the implications of a compromise, I don't want to leave the
ability for it to happen in a system. I don't think anyone is smart
enough to understand all the implications of this across all the systems
that depend on the DNS, especially as we start to trust the DNS because
of the authentication.

@_date: 2009-09-10 21:33:04
@_author: Perry E. Metzger 
@_subject: UK Prime Minister apologizes for Alan Turing's mistreatment. 
Not strictly about crypto, but certainly about a very famous
Perry E. Metzger		perry at piermont.com

@_date: 2009-09-24 11:27:16
@_author: Perry E. Metzger 
@_subject: Nominum says it has secret advantages over Bind 
More security and security politics than crypto, but I thought this was
rather interesting to this community:
Nominum's Jon Shalowitz is interviewed on why you should buy Nominum's
stuff over using open source, oh, pardon, "freeware[sic]" software:
   Q: What characterises that open-source, freeware legacy DNS that you
   think  makes it weaker?
   A: Number one is in terms of security controls. If I have a secret
   way of blocking a hacker from attacking my software, if it's freeware
   or open source, the hacker can look at the code.
   By virtue of something being open source, it has to be open to
   everybody to look into. I can't keep secrets in there. But if I have
   a commercial-grade software product, then all of that is closed off,
   and so things are not visible to the hacker.
I guess Mr. Shalowitz is unaware of the existence of
disassemblers. Either that, or perhaps all those people attacking
Windows successfully have the source code, I'm not sure which.

@_date: 2009-09-26 12:31:14
@_author: Perry E. Metzger 
@_subject: [Barker, Elaine B.] NIST Publication Announcements 
NIST announces the completion of two NIST Special Publications (SPs): SP
800-56B, Recommendation for Pair-Wise Key Establishment Schemes Using
Integer Factorization Cryptography, and SP 800-102, Recommendation for
Digital Signature Timeliness. Both publications are available at
SP 800-56B provides specifications of key establishment schemes that are
appropriate for use by the U.S. Federal Government, based on a standard
developed by the Accredited Standards Committee (ASC) X9, Inc.: ANS
X9.44, Key Establishment using Integer Factorization Cryptography. A key
establishment scheme can be characterized as either a key agreement
scheme or a key transport scheme. This Recommendation provides
asymmetric-based key agreement and key transport schemes that are based
on the Rivest Shamir Adleman (RSA) algorithm.
SP 800-102 is intended to address the timeliness of the digital
signatures generated using the techniques specified in Federal
Information Processing Standard (FIPS) 186-3. Establishing the time when
a digital signature was generated is often a critical consideration. A
signed message that includes the (purported) signing time provides no
assurance that the private key was used to sign the message at that time
unless the accuracy of the time can be trusted. SP 800-102 provides
methods of obtaining assurance of the time of digital signature
generation using a trusted timestamp authority that is trusted by both
the signatory and the verifier.

@_date: 2009-09-29 10:31:01
@_author: Perry E. Metzger 
@_subject: [Barker, Elaine B.] NIST Publication Announcements 
You don't need such a complicated description -- you're just asking "can
I do secure timestamping without requiring significant trust in the
timestamping authority."
The Haber & Stornetta scheme provides a timestamping service that
doesn't require terribly much trust, since hard to forge widely
witnessed events delimit particular sets of timestamps. The only issue
is getting sufficient granularity.

@_date: 2009-09-30 10:09:18
@_author: Perry E. Metzger 
@_subject: [Paul F. Doyle] Timestamping 
Forwarded message:
Hello Perry and Stephan (cc: Dan Geer),
Dan Geer forwarded a message thread from the crypto mailing list.
There is an approach to Trusted Time Stamping you may find interesting,
useful and rather different given the circumstances you've described in the
thread.  It is known as the Transient Key Method and is NOT based on a
conventional PKI method for generating cryptographic time stamps, but
instead a fully distributed, web-style, self-validating model.
I would be happy to describe the Transient Key Method in detail if this
would be helpful and can forward along some background documentation if you
are interested.  BTW, it is one of the methods included in the American
National Standard X9.95.
Please let me know how I can be of assistance.
"A life without integrity is meaningless...
...a record or dataset without integrity is worthless!"
Paul F. Doyle
Founder & CEO
P.O. Box 369
Ada, MI  49301
v. 616-458-5733
m. 616-292-8350
f. 866-685-2386/616-458-2271
LinkedIn: e. paul at proofspace.com
skype. paul_proofspace

@_date: 2009-09-30 20:56:05
@_author: Perry E. Metzger 
@_subject: [Barker, Elaine B.] NIST Publication Announcements 
============================== START ==============================
Perhaps that's because this is a Merkle tree, not a patricia
tree. Patricia trees are radix trees -- they're used for optimizing
routing tables, not in cryptography.

@_date: 2010-04-09 15:06:13
@_author: Perry E. Metzger 
@_subject: Wikileaks video "crypto". 
Earlier this weeks, Wikileaks released of video of an incident involving
an Apache helicopter which killed two Reuters reporters and a number of
bystanders in Iraq.
A number of the reports surrounding the release claim that the video was
"decrypted" by Wikileaks. Indeed, Wikileaks requested "supercomputer
time" via twitter and other means to "decrypt" a video, see:
The video was apparently intentionally given to Wikileaks, so one can't
imagine that the releasing parties would have wanted it to be unreadable
by them (or that any reasonable modern cryptosystem would have be
crackable). What, then, does the "decryption" claim mean here. Does
anyone know?

@_date: 2010-04-09 16:37:38
@_author: Perry E. Metzger 
@_subject: Interesting blog post from Matt Blaze 
Matt has an interesting blog post up about the afterward he wrote for
"Applied Cryptography" 15 years ago, and how little has changed in the

@_date: 2010-04-19 11:40:42
@_author: Perry E. Metzger 
@_subject: interesting recent political news... 
1) NSA to suspend collecting metadata on domestic communications
   following trouble with the FISA court:
2) Former NSA official indicted for leaking to the press:
3) DOJ attempts to read Yahoo email accounts without a warrant, Yahoo
   resists:

@_date: 2010-04-19 12:43:04
@_author: Perry E. Metzger 
@_subject: interesting recent political news... 
Alistair Crooks pointed out to me that the DOJ has dropped that fight:

@_date: 2010-04-20 11:31:19
@_author: Perry E. Metzger 
@_subject: Quantum Key Distribution: the bad idea that won't die... 
Via /., I saw the following article on ever higher speed QKD:
Very interesting physics, but quite useless in the real world.
I wonder why it is that, in spite of almost universal disinterest in the
security community, quantum key distribution continues to be a subject
of active technological development.

@_date: 2010-04-20 11:45:30
@_author: Perry E. Metzger 
@_subject: What's the state of the art in factorization? 
I was alerted to some slides from a talk that Dan Bernstein gave a few
days ago at the University of Montreal on what tools will be needed to
factor 1024 bit numbers:
It has been a couple of years since there has been serious discussion on
the list on this topic, and especially in the light of various technical
decisions being undertaken on the size of DNS signing keys for high
valued zones (like root), I was curious as to whether anyone had any
interesting comments on the state of the art in factorization.

@_date: 2010-04-21 09:19:36
@_author: Perry E. Metzger 
@_subject: Quantum Key Distribution: the bad idea that won't die... 
No, it isn't. QKD is useless three different ways.
First, AES and other such systems are fine, and the way people break
reasonably designed security systems (i.e. not WEP or what have you) is
not by attacking the crypto.
Second, you can't use QKD on a computer network. It is strictly point to
point. Want 200 nodes to talk to each other? Then you need 40,000
fibers, without repeaters, in between the nodes, each with a $10,000 or
more piece of equipment at each of the endpoints, for a total cost of
hundreds of millions of dollars to do a task ethernet would do for a
couple thousand dollars.
Third, QKD provides no real security because there is no actual
authentication. If someone wants to play man in the middle, nothing
stops them. If someone wants to cut the fiber and speak QKD to one
endpoint, telling it false information, nothing stops them. You can
speak the QKD protocol to both endpoints and no one will be the
wiser. So, you need some way of providing privacy and
authentication... perhaps a conventional cryptosystem. So, what did QKD
provide you with again?
There is no point to QKD at all.

@_date: 2010-04-21 20:47:50
@_author: Perry E. Metzger 
@_subject: Quantum Key Distribution: the bad idea that won't die... 
I'm well aware, however, AES is not going to be broken by quantum
computers (see Scott Aaronson's excellent lay explanations of the fact
that quantum computers likely can't solve NP complete problems in
polynomial time), and no one uses RSA or any other asymmetric cipher for
link encryption. RSA+DH is typically used only for bootstrapping a
symmetric cipher. QKD only provides link encryption anyway.
I'm afraid that QKD is literally incapable of being done more
efficiently than this. The whole point of the protocol is to get
guarantees of security from quantum mechanics, and as soon as you have
any intermediate nodes they're gone. I know of no one who claims to have
any idea about how to extend the protocol beyond that, and I suspect it
of being literally impossible (that is, I suspect that a mathematical
proof that it is impossible should be doable.)
It isn't resolved at all.
No one is doing that, though. People are working on things like faster
bit rates, as though the basic reasons the whole thing is useless were
Nope. It isn't. The system is only as strong as the classical system. If
the classical system is broken, you lose any assurance that you aren't
being man-in-the-middled.
That is, of course, your privilege.

@_date: 2010-04-21 22:04:21
@_author: Perry E. Metzger 
@_subject: Quantum Key Distribution: the bad idea that won't die... 
Length isn't the issue. Networks are the problem. If you want to have
every computer have only one link instead of one for every other
computer it might ever talk to, you need a network. Networks need
routers, that is, intermediate nodes. QKD requires that the actual
endpoints of the communication be the only objects intercepting the
photons in question -- it is inherently useless in an environment with
Thus, if you want 200 nodes in a network to talk to each other, you need
200*200 fibers to do it, and 200*200*2 QKD units, each of which is more
expensive than your computer is. In exchange for your vast expenditure,
you will gain no security whatsoever and have to implement a
conventional cryptosystem on top anyway.
It seems like a lose.
I think I can, actually. I know of very few people in computer security
who take QKD seriously. I feel pretty safe making these sorts of
Not for this problem.
Read what you just wrote.
IF THE AUTHENTICATION IS UNBROKEN. That is, the system is only secure if
the conventional cryptosystem is not broken -- that is, it is only as
secure as the conventional system in use. Break the conventional system
and you've broken the whole thing.
It is, of course, worse than that paper states. If you're only
authenticating, a man in the middle gets the entire bit stream, so you
need both: authentication to know a man in the middle isn't lying to
you, and conventional crypto to know that the man in the middle isn't
violating your privacy. Color me unimpressed by the usefulness of the

@_date: 2010-04-21 22:27:50
@_author: Perry E. Metzger 
@_subject: Quantum Key Distribution: the bad idea that won't die... 
Let me note that Mr. Leiseboer is the CTO of a company that makes QKD
On what basis do you "know" this?
Again, there are three insurmountable problems here:
QKD requires a conventional cryptosystem on top to provide
authentication and privacy in the face of man-in-the middle attacks (so
why do you want the QKD system?)
QKD is inherently incompatible with networks -- it is point to point
security only.
QKD provides no practical security over conventional cryptosystems. No
one attacks your security by breaking a modern system like AES -- people
look elsewhere to attack you. Not, of course, that it matters, because
if you can break AES, you can break a QKD system just by playing
man-in-the-middle, so again, why use QKD?
It is true forever. QKD doesn't even provide any security at all. As
I've said repeatedly:
As soon as you put a man in the middle with a pair of QKD boxes, each
endpoint will happily communicate with it as though it was the other
end. So, your security depends on having the data also authenticated and
encrypted with a conventional system. If the conventional system is
broken, the QKD added nothing. If the conventional system works, you
didn't need the QKD.  Game over.
If you can explain how to get around this, I'm all ears.
And please, no more comments about "big egos". Technical arguments
only. This is not a marketing list, it is a technical list. I'm pretty
ruthless about cutting people off if they get insulting.
That's a very bold statement, and one that I doubt you can back up, but
it is irrelevant to the current discussion, since no one encrypts links
with public key anyway. They may use it for key exchange -- but again,
QKD only provides link security, and you need a conventional crypto
system running on top of it anyway because it can't defend against man
in the middle attacks anyway, so it doesn't matter. If RSA and DH can't
be trusted for key exchange, then both the conventional and the QKD
systems will need keys for conventional ciphers manually loaded at both
ends -- QKD isn't secure without the conventional cipher system
providing authentication and privacy in the face of man in the middle
Well, since any secure QKD system needs a conventional cryptosystem on
top to provide the actual security anyway, this is not an advantage of
QKD. If it is a problem conventional systems can't surmount, QKD can't
surmount it. If conventional systems can get beyond it, then QKD isn't
Well, you'll have to explain why I'm wrong, then.
In detail.
It is practical to build very expensive QKD boxes. It is totally
impractical to use them vs. just using a conventional cipher.
Not at the conferences I go to. I can't name anyone who has any interest
in it at all. Mostly we sit around at the bar and wonder why the hell
people keep spending money on it.
If you care to name people who have an interest here, please let me
know. I haven't found them.
I again note that Mr. Leiseboer is the CTO of a company that makes QKD
If you dispute my position here, I'm happy to discuss it, but you're
going to have to explain why I'm wrong -- a detailed technical
explanation, not a set of assertions.

@_date: 2010-04-21 22:31:40
@_author: Perry E. Metzger 
@_subject: Quantum Key Distribution: the bad idea that won't die... 
I agree it is an interesting physics trick -- considerable fun to read
about. I disagree that it is of use in making computer systems secure.
Lets look at the two possible scenarios.
If the conventional crypto is secure, then the whole system is secure.
If the conventional crypto is insecure, then the whole system is
Looks to me like the system is only as strong as the classical
system. If the classical system is unbroken, you don't need the QKD
box. If the classical system is broken, the QKD box adds no
security. Ergo, the system is only as strong as the classical system.

@_date: 2010-04-22 11:26:52
@_author: Perry E. Metzger 
@_subject: Quantum Key Distribution: the bad idea that won't die... 
I agree. What I don't understand is why people are trying to
*commercialize* it, or claiming that it is of practical use as it
I don't disagree, and I think that this, too, is a good reason to study
it in an academic setting. What I don't get, as I said, is people going
off and spending large amounts of effort on things like getting the
systems to do video rate communications or trying to sell them.
Fair point. There may be quite interesting tricks there, but I think it
would be better if people treated this as a very interesting research
space and not as an important security technology, which is how it gets
portrayed to the press.
As an academic research project, the intersection of quantum effects and
security remains a very interesting area to explore, and we may yet get
valuable security technologies out of it.
However, the current QKD concept is not of practical use, but it is
generally portrayed as being a really important breakthrough in the
press. (This also reflects a considerable popular misunderstanding of
where the problems in security are -- they're not in defending our
link layers against eavesdropping.)
Indeed, and from my readings of the literature there are other
attacks. I find it important, however, that even if the systems worked
perfectly and as advertised, there is little reason to want them.

@_date: 2010-08-01 13:33:08
@_author: Perry E. Metzger 
@_subject: Five Theses on Security Protocols 
On Sun, 1 Aug 2010 15:07:46 +0200 Guus Sliepen Security is not magic. If you have no pre-existing trust relationship
with some source of information, you cannot get additional trusted
information from that source. You have to have some sort of existing
pre-shared information -- a public or private key and a decision to
believe the information from that source -- to get anywhere.
I think the "we all trust Verisign" model is a bad one (no particular
slam on Verisign here, I think any "we all trust some third party"
model is bad.)
However, you are asking an important question, which is, how do we
replace compromised keys in our configuration files?
This depends a lot on the application. If we're talking about a single
administrative domain (say a few thousand machines inside a company
that are all managed by the same small group), you push out a new
config file. If we're talking about, say, a banking application where
lots of people have the bank's key in the config for their software,
the protocol either has a way of rolling over to the "next key" or you
are forced to send all the users new smartcards or USB keys or what
have you, which is a good incentive to have a means in your protocol
for moving to the next key.
As for the case of "everyone on earth trusts third party X", except
for something like the DNS, I see no reason or benefit in such a
system at all.
No. I think you're not focusing on real applications here. You're
instead thinking far too abstractly.
Say, for example, we're talking about some credit card processor's
public key that is used by all their validation terminals. Presumably
they need some sort of update protocol. However, that protocol does
not need to involve certificates and is not a matter of global
concern. There should be very few cases where a key is a matter of
global concern -- I think having keys be a matter of global concern is
something of an architectural error.
I think the "Verisign is the standard of all truth" model is broken,
but lets consider what you're saying for a minute.
If Verisign is indeed the "standard of truth", then how could we do
anything else? If we don't check a key with Verisign at least every
few hours, then how can we ever have meaningful revocation? Whether
you think that Verisign wouldn't "like" this or not, there is no other
choice given the model you are presenting. Either revocation is
impossible or people make online checks.

@_date: 2010-08-02 09:42:30
@_author: Perry E. Metzger 
@_subject: After spyware fails, UAE gives up and bans Blackberries 
See also:
The BBC did a story on this today in which (pretty shockingly) they
talked to a security "expert" who talked only about how bad the
security problems are because the government can't read the messages,
especially because theoretical terrorists could use the blackberries
to discuss criminal activity. No discussion at all of alternate
viewpoints or the security risks associated with built-in
eavesdropping technology.
Even the New York Times story discussed the issue entirely in privacy
terms, and did not discuss the security risks that GAK systems
pose. There is no guarantee, once an eavesdropping system is
implemented, that it will be used only for legitimate purposes -- see,
for example, the scandal in which Greek government ministers were
listened to using the "lawful intercept" features of cellphone

@_date: 2010-08-02 11:08:31
@_author: Perry E. Metzger 
@_subject: GSM eavesdropping 
This is a really important development. I'll quote a bit more of the
article so people can understand why:
   In his presentation at the Black Hat Conference, German GSM expert
   Karsten Nohl presented a tool he calls Kraken, which he claims can
   crack the A5/1 encryption used for cell phone calls within
   seconds. But first, you have to record the GSM call with a GSM
   catcher, which you can build yourself based on a Universal Software
   Programmable Radio (USRP), which costs just under $1500, and the
   open source GNURadio software.
   To crack the key, Kraken uses rainbow tables, which Nohl calculated
   with ATI graphics processors (GPUs). During a live demonstration,
   the tool cracked the key for a recorded phone call within about 30
   seconds. Nohl then decoded the file with Airprobe and converted it
   into an audio file using Toast.
   "Today, recording and cracking GSM is as easy as attacking WiFi was
   a few years ago", the security expert told The H's associates at
   heise Security.

@_date: 2010-08-02 12:32:23
@_author: Perry E. Metzger 
@_subject: GSM eavesdropping 
On Mon, 2 Aug 2010 12:12:25 -0400 Adam Fields
The GSM situation is an example of many problems at once -- bad UI
decisions, the bad decision to allow unencrypted traffic, bad crypto
algorithms even when you get crypto, susceptibility to downgrade
attacks, etc.
Looking forward, the "there should be one mode, and it should be
secure" philosophy would claim that there should be no insecure
mode for a protocol. Of course, virtually all protocols we use right
now had their origins in the days of the Crypto Wars (in which case,
we often added too many knobs) or before (in the days when people
assumed no crypto at all) and thus come in encrypted and unencrypted
varieties of all sorts.
For example, in the internet space, we have http, smtp, imap and other
protocols in both plain and ssl flavors. (IPSec was originally
intended to mitigate this by providing a common security layer for
everything, but it failed, for many reasons. Nico mentioned one that
isn't sufficiently appreciated, which was the lack of APIs to permit
binding of IPSec connections to users.)

@_date: 2010-08-02 13:15:58
@_author: Perry E. Metzger 
@_subject: GSM eavesdropping 
I think demonstrating the whole thing being done for a
negligible amount of money is indeed news.
Perhaps they hadn't seen a low cost demonstration of the threat yet.

@_date: 2010-08-02 18:31:38
@_author: Perry E. Metzger 
@_subject: Five Theses on Security Protocols 
On Mon, 2 Aug 2010 16:20:01 -0500 Nicolas Williams
There are decisions, and there are decisions.
If, for example (and this is really just an example, not a worked
design), your browser authenticates the bank website using a USB
attached hardware token containing both parties credentials, which
also refuses to work for any other web site, it is very difficult for
the user to do anything to give away the store, and the user has very
little scope for decision making (beyond, say, deciding whether to
make a transfer once they're authenticated).
This is a big contrast to the current situation, where the user needs
to figure out whether they're typing their password in to the correct
web site etc., and can be phished into giving up their credentials.
You can still be attacked even in an ideal situation, of course. For
example, you could still follow instructions from con men telling you
to wire money to them. However, the trick is to change the system from
one where the user must be constantly on the alert lest they do
something wrong, like typing in a password to the wrong web site, to
one in which the user has to go out of their way to do something
wrong, like actively making the decision to send a bad guy all their

@_date: 2010-08-02 18:37:16
@_author: Perry E. Metzger 
@_subject: GSM eavesdropping 
On Mon, 2 Aug 2010 16:19:38 -0400 (EDT) Paul Wouters
I would like to note that this is not sufficient for the sort of
security I've been talking about.
If, for example, users are still authenticating to web sites by typing
in passwords over an encrypted channel, DNSSEC based keys don't
help. The user still has to actively make sure that they're not giving
their key away to the wrong web site.
You still need to re-engineer the system so that the user cannot
give away their credentials without serious effort. Simply changing
where the opaque third party certified key comes from doesn't help.
What DNSSEC really gives you is the ability to trust the replies the
DNS gives you -- to trust that a DNS label and IP address really are
bound together. It doesn't change the fact that the current user
authentication models are broken.
I disagree that we can deploy new systems quickly. See, for example,
the large fraction of IE6 users in the world. Indeed, I suspect it
will be another 10 years before over 95% of machines are even paying
attention to DNSSEC.

@_date: 2010-08-03 12:01:23
@_author: Perry E. Metzger 
@_subject: GSM eavesdropping 
I'm not sure it is actually cheap enough in all cases. Imagine the
state explosion problem that DNS root servers would face, for
example, in providing pairwise crytpographic sessions for all
queries, especially in a situation where for the most part one only
wants to get a response that is authenticated but which is not per se
Also, as a practical matter, we don't really have protocol
infrastructure for encrypting absolutely everything at this point.
There is, for example, no protocol by which anonymous DNS queries
could be easily encrypted.

@_date: 2010-08-03 12:03:37
@_author: Perry E. Metzger 
@_subject: /dev/random and virtual systems 
I'm not sure what to do about the live CD problem, but in a previous
iteration of this discussion a couple of years ago, I proposed that
using a strong cipher (like AES) with a key installed at the factory
was probably the right solution to the $40 embedded device problem. I
can dig up my much longer exposition on that if anyone wishes.

@_date: 2010-08-03 18:09:56
@_author: Perry E. Metzger 
@_subject: ADMIN: slowly shutting down the high level security discussion, and 
The discussion spurred by Peter Gutmann's original mail on
astonishingly widely authoritative certs has gone on for quite a
while, and much of what is now being said is repetitive. I'll be
using a pretty heavy hand on moderating the messages for the moment,
unless people come up with particularly interesting things to say.
On another note: please, please, please trim replies to messages,
avoid top posting, and do not send HTML multiparts.
I also note a new trend, in which people are failing to format their
messages very effectively or break them into paragraphs. This makes
reading extremely difficult. Please take the few moments necessary to
assure your messages are readable before clicking send.

@_date: 2010-08-09 19:47:30
@_author: Perry E. Metzger 
@_subject: NY Times article on Blackberry 
Really quite mediocre coverage of Blackberry's security issues
I especially fault them for having virtually no coverage of the
position that would oppose removing security features for the benefit
of law enforcement -- the fact that such alterations can seriously
harm legitimate users is not mentioned at all.

@_date: 2010-08-13 09:35:22
@_author: Perry E. Metzger 
@_subject: Has there been a change in US banking regulations recently? 
I don't know, but Chase, which years ago sent me a letter explaining
exactly how crazy I was for complaining that their front page was
sent in the clear, has also begun redirecting people to https. I'm
unaware of a regulatory shift on this, but perhaps people have
finally learned that doing otherwise is a bad idea.

@_date: 2010-08-16 16:54:59
@_author: Perry E. Metzger 
@_subject: 2048-bit RSA keys 
On Mon, 16 Aug 2010 12:42:41 -0700 Paul Hoffman
He asked about "today's best of breed algorithms", not future ones. In
that context, and assuming today's most energy efficient processors
rather than theoretical future processors, the question has a concrete

@_date: 2010-08-17 11:53:40
@_author: Perry E. Metzger 
@_subject: About that "Mighty Fortress"...  What's it look like? 
On Tue, 17 Aug 2010 15:04:00 +0300 Alexander Klimov
Well, OCSP and such already do online checks in real time, so there is
no difference there between my view of the world and what people claim
should be done for certificates.
The more interesting question is whether the crypto protocols people
can come up with ways of doing online checks for information about
keys that don't reveal information about what is being asked for. That
would help in both the certificate and non-certificate versions of
such checks.

@_date: 2010-08-17 16:42:17
@_author: Perry E. Metzger 
@_subject: 2048-bit RSA keys 
On Tue, 17 Aug 2010 22:32:52 +0200 Simon Josefsson
A breakthrough could also render 10kbit keys broken, or might never
happen at all. A breakthrough could make short ECC keys vulnerable.
A breakthrough could make AES vulnerable. One can't operate on this
basis -- it makes it impossible to use anything other than one-time

@_date: 2010-08-23 10:56:31
@_author: Perry E. Metzger 
@_subject: Fw: [IP] Malware kills 154 
Forwarded from Dave Farber's "Interesting People" list"
Begin forwarded message:

@_date: 2010-08-26 12:13:06
@_author: Perry E. Metzger 
@_subject: questions about RNGs and FIPS 140 
On Thu, 26 Aug 2010 08:14:26 -0700
The rationale is clear, but I'll explain it again.
Say you are deploying a small security device into the field.
It is trivial to validate that an AES or SHA256 implementation on the
device is working correctly and to generate a seed in the factory to
place on the device to give it an operational lifetime of "good
enough" random numbers.
It is difficult to validate that a hardware RNG is working
correctly. How do you know the bits being put off aren't skewed
somehow by a manufacturing defect? How do you know that damage in the
field won't cause the RNG to become less random?
It is therefore both cheaper and far safer to use a deterministic
algorithm on the field deployable unit coupled with a high quality
seed from a source used only at the factory that you can spend time,
effort and money validating properly.
This same principle applies to things like virtual machines where it
is difficult to know that your hardware is giving you what you expect
but trivial to install a known-good seed at VM creation time.
I would have thought by now that this principle was widely understood.

@_date: 2010-08-30 12:26:47
@_author: Perry E. Metzger 
@_subject: IDS systems (was Re: Five Theses on Security Protocols) 
Perhaps you haven't been in the right kinds of companies. Your
observation is one many have made in the past, and I don't think it
is even much of a secret.
I suspect that many IDS systems have been put in place over the years
largely as a way of showing management how bad the problem the
security team faces is, and why their budget is justified. That is
never the public claim, of course. However, without some sort of
evidence of a continuing threat, there are managers who would see
an ideally performing security team (i.e. one with a perfect record of
defense) and interpret it as a group spending money to no effect
whatsoever. "Why do I need you when no one ever breaks in?" might be
the (foolish) question.
IDS systems generate voluminous reports which may be used, in part,
to justify continuing funding for a security effort. They allow
management to feel that they are getting something concrete for their

@_date: 2010-07-11 18:35:04
@_author: Perry E. Metzger 
@_subject: Anyone make any sense out of this skype hack announcement? 
I got pointed at this, and it is written unclearly enough that I have
no idea what to make of it:

@_date: 2010-07-11 20:35:31
@_author: Perry E. Metzger 
@_subject: Fw: [IP] DARPA BAA on homomorphic encryption 
Begin forwarded message:
"There?s a new DARPA BAA on homomorphic encryption:
The goal is to create practical implementations of an idea that only
recently has been shown to be possible in theory.  That a computation
could be performed over data that remains in encrypted form
throughout the entire computation.  In effect, the computer would
execute a program without ever being able to discern any of the
computed values.  The possible applications of this are far
reaching.  For example, you could let a cloud facility do all of your
computing work without any possibility that any of your private
information would be divulged. "

@_date: 2010-07-12 12:22:51
@_author: Perry E. Metzger 
@_subject: Intel to also add RNG 
It is disturbing to me that people oppose this so much.
For a lot of applications -- servers run in isolation, networking
equipment, etc. -- having hardware RNGs available is a really big win,
because there is no good local source of randomness. (We had a long
discussion of ways to mitigate this some time ago.) Plugging in an
external unit is not going to happen in practice. If it isn't nearly
free and built in, it won't be used.
I would suggest that in most cases, you are better off with a very
very mildly untrusted but ubiquitous hardware RNG than with the kinds
of kludges to get random numbers on unattended hardware we end up with
in the real world.
BTW, let me note that if Intel wanted to gimmick their chips to make
them untrustworthy, there is very little you could do about it. The
literature makes it clear at this point that short of carefully
tearing apart and analyzing the entire chip, you're not going to catch
subtle behavioral changes designed to allow attackers backdoor
access. Given that, I see little reason not to trust them on an RNG,
and I wish they would make it a standard part of the architecture

@_date: 2010-07-16 10:47:06
@_author: Perry E. Metzger 
@_subject: Fw: Root Zone DNSSEC Deployment Technical Status Update 
The root zone has been signed, and the root zone trust anchor has
been published.
Begin forwarded message:
Root Zone DNSSEC Deployment
Technical Status Update 2010-07-16
This is the twelfth of a series of technical status updates intended
to inform a technical audience on progress in signing the root zone
of the DNS.
Details of the project, including documentation published to date,
can be found at .
We'd like to hear from you. If you have feedback for us, please
send it to rootsign at icann.org.
FULL PRODUCTION SIGNED ROOT ZONE
The transition from Deliberately-Unvalidatable Root Zone (DURZ) to
production signed root zone took place on 2010-07-15 at 2050 UTC. The
first full production signed root zone had SOA serial 2010071501.
There have been no reported harmful effects.  The root zone trust
anchor can be found at .
PLANNED DEPLOYMENT SCHEDULE
Already completed:
  2010-01-27: L starts to serve DURZ
  2010-02-10: A starts to serve DURZ
  2010-03-03: M, I start to serve DURZ
  2010-03-24: D, K, E start to serve DURZ
  2010-04-14: B, H, C, G, F start to serve DURZ
  2010-05-05: J starts to serve DURZ
  2010-06-16: First Key Signing Key (KSK) Ceremony
  2010-07-12: Second Key Signing Key (KSK) Ceremony
  2010-07-15: Distribution of validatable, production, signed root
    zone; publication of root zone trust anchor

@_date: 2010-07-22 18:20:54
@_author: Perry E. Metzger 
@_subject: ADMIN: your wonderful anti-spam software 
Researchers at two major institutions are informed that you may have
missed a recent short thread about a content delivery network with
an EV cert claiming to be valid for a truly vast number of zones,
originated by Peter Gutmann. I would name the institutions, but that
wouldn't be a kindness.
If you haven't seen this email, it is because your email managers
have decided that the presence of certain strings in incoming email
is forbidden. I would name those strings, but that would prevent you
from seeing this email.
If you haven't seen the messages I'm talking about, though, you might
ask your Friendly Neighborhood Email Admin to check their logs and
perhaps adjust their settings.

@_date: 2010-07-25 18:08:48
@_author: Perry E. Metzger 
@_subject: MITM attack against WPA2-Enterprise? 
Not quite a MITM attack. It is quite clever, though as with most such
things, it seems in retrospect to be obvious. If only we always had
hindsight. Quoting from another article:
   The Advanced Encryption Standard (AES) derivative on which WPA2 is
   based has not been cracked and no brute force is required to
   exploit the vulnerability, Ahmad says. Rather, a stipulation in
   the standard that allows all clients to receive broadcast traffic
   from an access point (AP) using a common shared key creates the
   vulnerability when an authorized user uses the common key in
   reverse and sends spoofed packets encrypted using the shared group
   key.
All in all, this looks bad for anyone depending on WPA2 for high

@_date: 2010-07-25 21:23:05
@_author: Perry E. Metzger 
@_subject: MITM attack against WPA2-Enterprise? 
I think the fact that the protocol appears to allow people to
impersonate the base station, order clients to use new keys, and then
man in the middle all subsequent communications with little effort
makes the per-endpoint keying largely moot. This does not seem like a
minor defect.
There is no need to use public key crypto to solve this, of course. A
Needham-Schroeder protocol would seem to be sufficient, and would not
require public key.
I don't know, if it is truly only a ten line change to a common WPA2
driver to read, intercept and alter practically any traffic on the
network even in enterprise mode, that would seem like a serious issue
to me. Setting up the enterprise mode stuff to work is a lot of time
and effort. If it provides essentially no security over WPA2 in shared
key mode, one wonders what the point of doing that work is. This
doesn't seem like a mere engineering compromise.

@_date: 2010-07-26 22:25:40
@_author: Perry E. Metzger 
@_subject: A mighty fortress is our PKI 
I think that you may be right -- the entire TLS PKI model may be so
horribly broken that, once you no longer have any real security to
speak of, simply sharing a cert among hundreds of trust domains hardly
harms anything further. All major browsers already trust CAs that have
virtually no security to speak of, and for the most part a certificate
only indicates that the CA had reason to believe that someone was in
possession of sufficient funds to pay it for it.
However, I suspect this is not what you meant here.
[rest elided]
I find it gratifying that my mailing list has gained sufficient public
importance that not one but two technology executives have made the
effort within 48 hours to join it so that they can state their
opinion on the issue that Peter Gutmann raised.
I find it less gratifying, however, when those messages do not focus
on clear discussion of technical merits. This is, after all, a
technical mailing list, intended for technologists to speak clearly,
openly and precisely with each other.
In reading your note, I was reminded of George Orwell's excellent
essay "Politics and the English Language":
   If you have not read it, I strongly urge that you do so.

@_date: 2010-07-26 22:30:19
@_author: Perry E. Metzger 
@_subject: MITM attack against WPA2-Enterprise? 
On Mon, 26 Jul 2010 21:42:53 -0400 Steven Bellovin
I think the issue is that people have been given the impression that
WPA2 provides enough security that people can feel reasonably secure
that others will not be reading their traffic over the air the way
that they might in a pure shared key scenario, and that this justified
the extra complexity of deployment. While what you say is perfectly
true, it does lead one to ask if WPA2 enterprise has not been
significantly oversold.

@_date: 2010-07-26 22:55:52
@_author: Perry E. Metzger 
@_subject: A mighty fortress is our PKI 
On Tue, 27 Jul 2010 05:40:07 +0300 (EEST) Sampo Syreeni
I am not sure what quantitative measurement of vulnerability would
even mean. What units would said quantity be measured in?

@_date: 2010-07-27 14:22:40
@_author: Perry E. Metzger 
@_subject: A mighty fortress is our PKI 
On Tue, 27 Jul 2010 11:11:52 -0700 Chris Palmer
That scale seems remarkably arbitrary.
One problem with such arbitrary scales is that there is no objective
methodology one can engage in which will show that the equation is
"wrong" in some way.
Unless you can perform an experiment to falsify the self-declared
"objective quantitative security measurement", it isn't science. I
can't think of an experiment to test whether any of the coefficients
in the displayed calculation is "correct". I don't even know what
"correct" means. This is disturbing.

@_date: 2010-07-28 09:05:57
@_author: Perry E. Metzger 
@_subject: A mighty fortress is our PKI, Part II 
The US Securities and Exchange Commission has long forced companies to
state, when selling advisory services, that "past performance is no
indicator of future performance".
However, I think that's pretty much clearly untrue in most
disciplines. Empirical reasoning is entirely about observing and
drawing conclusions based on what we observe. Virtually all of modern
science comes, in fact, from observing what happens in the real world
and extrapolating from it.
After a few decades of trying to get PKI to work, we have failed to do
so. At some point, one has to have very firm justifications for the
belief that these decades of experience should be dismissed as mere
experimental error.
In another message you say:
I'm unsure whether you are correct here, but I will point out that any
solution which can never be deployed *is*, in fact, infeasible, and
that if human beings cannot be convinced to use a particular solution
(which is one form of the "lack of will" problem), then we might as
well dismiss that solution.
Now, I've been saying "PKI can never be made to work" for something
like the last fifteen years. I was on a panel with Steve Kent at a
Usenix workshop long ago, where I expressed the opinion that PKI very
poorly models the actual legal and de facto relationships between
parties, and I think that experience has borne that out. We've watched
the rise and fall of substantial companies dedicated to trying to get
PKI sold into enterprises, and the best efforts that Certco and
Entrust and the like made were not enough. There is also considerable
evidence that many of the technologies PKI requires, like reliable
revocation, cannot be made to work, and whether that is because of a
"lack of will" or because of something deeper, the fact is that these
techniques have failed in practice over the course not of months or
years but of decades, and we cannot ignore that forever.
It is not always the case that a dead technology has failed because of
infeasibility or inapplicability. I'd say that a number of fine
technologies have failed for other reasons. However, at some point, it
becomes incumbent upon the proponents of a failed technology to
either demonstrate that it can be made to work in a clear and
convincing way, or to abandon it even if, on some level, they are
certain that it could be made to work if only someone would do it.
I think we are at or even past that point with PKI. The odor of
putrefaction is unmistakable.

@_date: 2010-07-28 10:05:22
@_author: Perry E. Metzger 
@_subject: A mighty fortress is our PKI, Part II 
I agree with that fully.
Does it?
I will point out that many security systems, like Kerberos, DNSSEC and
SSH, appear to get along with no conventional notion of revocation at all.
I think public key cryptography is a wonderful thing. I'm just not
sure I believe at all in PKI -- that is, persistent certification via
certificates, certificate revocation, etc.
PKI was invented by Loren Kohnfelder for his bachelor's degree thesis
at MIT. It was certainly a fine undergraduate paper, but I think we
should forget about it, the way we forget about most undergraduate

@_date: 2010-07-28 11:01:08
@_author: Perry E. Metzger 
@_subject: A mighty fortress is our PKI, Part II 
I think that is because you are thinking in terms of certificates,
which naturally would require such a mechanism.
In kerberos, tickets are short lived -- one can simply fail to give
the person who stole a credential new ones, and in the interim, one
can remove the authorization that a particular principal has.
Yes. Precisely.
No, that's not what SSH does, or rather, it confuses the particular
communications channel (i.e. some out of band mechanism) with the
method that actually de-authorizes the key.
The point is that in SSH, if a key is stolen, you remove it from the
list of keys allowed to log in to a host. The key now need never be
thought about again. We require no list of "revoked keys" be kept,
just as we required no signed list of keys that were authorized. We
just had some keys in a database to indicate that they were
authorized, and we removed a key to de-authorize it.
I believe it does scale. Pretty much by definition, if you can get to
a web site, your Internet connectivity is working. That means that
there is no need for methods like having a signed key that lasts for
years so you can cache it for offline use.
I'm sure you remember the 1960s and 1970s well, as we are both a bit
past our youth. In the US, at least, every store clerk had in their
hands an unwieldy, telephone-book sized list of stolen credit card
numbers they had to consult at each credit card transaction. In those
days, there were no cheap modems and doing on-line verification was
The whole point of Kohnfelder's thesis was, in effect, to turn the
1970s era books of stolen numbers into an offline machine readable
list. You signed a long-lived credential so that it could be checked
offline, and you kept a big book of withdrawn credentials around so
you could check them offline as well. It was a model from the era in
which everyone had a paper phone book. It was designed for the era
where networks were a rarity.
We no longer live in that era. The models used by Kerberos, DNSSEC,
SSH, and such, make far more sense. We no longer need revocation.

@_date: 2010-07-28 11:13:36
@_author: Perry E. Metzger 
@_subject: A mighty fortress is our PKI, Part II 
On Wed, 28 Jul 2010 09:30:22 -0500 Nicolas Williams
Let me interrupt here and say that when I refer to PKI, I mean the
Kohnfelder model which we have been following, which is the model of
very long lived "phone books" of hierarchically issued certificates
along with very long lived lists of revoked certificates, all
designed with an offline world in mind.
I have no objections to "infrastructure" -- bridges, the Internet,
and electrical transmission lines all seem like good ideas. However,
lets avoid using the term "Public Key Infrastructure" for things that
depart radically from the Kohnfelder and subsequent X.509 models.
Well, it depends a lot on what kind of trust.
Let me remind everyone of one of my long-standing arguments.
Say that Goldman Sachs wants to send Morgan Stanley an order for a
billion dollars worth of bonds. Morgan Stanley wants to know that
Goldman sent the order, because the consequences of a mistake on a
transaction this large would be disastrous.
Should they trust Verisign's ExtraSuperHighValue certificate presented
by Goldman? No. Why? Because Verisign disclaims all effective
liability for the use of its certs. It is not a party to the
transaction being conducted. If it was actually insuring all
transactions conducted with the certificate, then Morgan could trust
them, because the counterparty who's credit would be at issue would no
longer be Goldman but Verisign. However, Verisign won't even pay out
if it turned out that they gave signed a Goldman cert and it was in
fact held by a scammer.
The problem with Certification Authorities is they certify
NOTHING. There can be no reliance on them, because they have no
liability of any sort in any transaction.
So, in the real world, Goldman and Morgan come up with ways of making
sure they trust each other's communications and credit lines. Even
when we're dealing with small transactions, like buying a book at a
book store with a credit card, if you trace it out, we're dealing with
nothing but a web of bilateral commercial relationships.
So, I have no trouble with various kinds of trust. What I have trouble
with is the sort of false trust that a CA implies. CAs certify nothing
in a real world business sense -- they are just toll collectors.
I believe we may, in fact, be in violent agreement here.

@_date: 2010-07-28 11:38:28
@_author: Perry E. Metzger 
@_subject: A mighty fortress is our PKI, Part II 
On Wed, 28 Jul 2010 09:57:21 -0500 Nicolas Williams
Actually, that's untrue in one very important respect.
In a Kerberos style system, you actively ask for credentials to do
things at frequent intervals, and if the KDCs refuse to talk to you,
you get no credentials.
In OCSP, we've inverted that. You have the credentials, for years in
most cases, and someone else has to actively check that they're okay

@_date: 2010-07-28 12:18:56
@_author: Perry E. Metzger 
@_subject: A mighty fortress is our PKI, Part II 
On Wed, 28 Jul 2010 10:50:52 -0500 Nicolas Williams
Again, I understand that in a technological sense, in an ideal world,
they would be equivalent. However, the big difference, again, is that
you can't run Kerberos with no KDC, but you can run a PKI without an
OCSP server. The KDC is impossible to leave out of the system. That is
a really nice technological feature.
Peter Gutmann has pointed out other critical distinctions, but I'll
let his message stand for itself.

@_date: 2010-07-28 12:37:01
@_author: Perry E. Metzger 
@_subject: A mighty fortress is our PKI, Part II 
On Wed, 28 Jul 2010 11:23:16 -0500 Nicolas Williams
I wouldn't suggest that everything on earth move to Kerberos. I
mentioned Kerberos only to show that entirely different models are
As to OCSP being a reasonable solution because it can be deployed
easily, it clearly will not solve the browser security problem. So
long as security depends on reliance on the lowest common denominator
among the policies of hundreds of CAs, many of which are quite
questionable, and so long as the certifications made by even the best
of those CAs are effectively meaningless, and so long as the users are
well trained to ignore every browser warning they ever get, the entire
question of OCSP is somewhat irrelevant -- it would just be a way of
spritzing the skunk with eau de cologne.
I fully recognize that the odds we will fix the browser security
problem are very low, if only because no one can deploy a truly new
solution in a world where we can't even get IE 6 to die.
However, in discussing this at a high level, as though we could
improve things, we shouldn't kid ourselves about the current model. It
is fatally broken. Hanging garlands from the corpse's ears will not
convince anyone that it has a vibrant future ahead.

@_date: 2010-07-28 13:25:21
@_author: Perry E. Metzger 
@_subject: A mighty fortress is our PKI, Part II 
On Wed, 28 Jul 2010 11:20:52 -0500 Nicolas Williams
My mother relies on many certificates. Can she make a decision on
whether or not her browser uses OCSP for all its transactions?
I mention this only because your language here is quite sticky.
Saying it is "up to the relying parties" is incorrect. It is really
up to a host of people who are nowhere near the relying parties. In
most cases, the relying parties aren't even capable of understanding
the issue.

@_date: 2010-07-28 14:41:35
@_author: Perry E. Metzger 
@_subject: A mighty fortress is our PKI, Part II 
On Wed, 28 Jul 2010 12:38:10 -0500 Nicolas Williams
Well, not everything is too hard. In fact, one of the important
characteristics of systems that work is that they're simple, and thus
We were just discussing the problem of needing users to make fine
grained security decisions. Several obvious solutions exist here.
For example, the "there should be one mode, and it should be secure"
rule lowers the complexity users encounter quite a bit.
I know of at least one project to fix the browser PKI mess which
claims that they want to involve the users more, not less. This would
seem to be a big mistake to me.
On the other edge of the spectrum, many people now use quite secure
protocols (though I won't claim the full systems are secure --
implementation bugs are ubiquitous) for handling things like remote
login and file transfer, accessing shared file systems on networks,
etc., with little to no knowledge on their part about how their
systems work or are configured. This seems like a very good thing. One
may complain about many issues in Microsoft's systems, for example,
but adopting Kerberos largely fixed the distributed authentication
problem for them, and without requiring that users know what they're
Yet another reason (one of dozens) that X.509 has never worked right
for most users is the sheer number of knobs. There are too many
choices for mortals, and there will always be subtle configuration
failures that can catch even experts.
(I am reminded of the similar death-by-complexity of the IPSec
protocol's key management layers, where I am sad to report that even I
can't easily configure the thing. Some have proposed standardizing on
radically simplified profiles of the protocol that provide almost no
options -- I believe to be the last hope for the current IPSec suite.)

@_date: 2010-07-28 18:12:54
@_author: Perry E. Metzger 
@_subject: A mighty fortress is our PKI, Part II 
On Wed, 28 Jul 2010 14:40:14 -0600 Paul Tiemann
I believe you've missed an important point.
First, my mother would never understand what that box means. Second,
my mother has no control over whether the CA provides OCSP.

@_date: 2010-07-28 18:41:25
@_author: Perry E. Metzger 
@_subject: A mighty fortress is our PKI, Part II 
On Wed, 28 Jul 2010 15:30:08 -0600 Paul Tiemann
I stand by all the things I said above, other than the apparent lack
of an apostrophe in "corpse's". I realize it isn't moderate language,
but on the other hand, my meaning is unmistakable.
We've been watching the slow motion accident very closely for a couple
of decades now. If that isn't long enough to develop certainty, I
don't know how many years would suffice. To believe we can fix the
mess now would be to ignore twenty years of experience.
I believe you misunderstand me. I'm not talking about OCSP.  I'm
saying the entire X.509 certificate infrastructure used in web
browsers is hopeless. OCSP is just one small hopeless component of a
hopeless whole.
(I don't think things are particularly better in other applications of
the system, but there are almost no other widely used applications
beyond code signing anyway. S/MIME and the rest are not merely dead
but nearly forgotten.)
There are multiple completely fatal flaws in the system. Any one of
them alone would suffice. To repeat just a few:
1) The user's security depends on the security of the worst CA in the
system. If there is any dispute about this, I would like to know on
what basis. There should be no dispute that CAs have certified things
they should not have, and will do so again. There should be no dispute
that some CAs have been sold and their keys subsequently passed around
under less than ideal circumstances. There should be no dispute that
not all CAs are what would be universally considered trustworthy
2) Users have been trained by too many false alarms to ignore all
browser warnings. If you don't believe me, there are fine papers about
what real users do when exposed to warnings, and they ignore
them. Users also have no real ability to understand the error messages
even if they did still care about them.
3) Revocation in the face of compromise is, as a practical matter,
nearly impossible.
4) CAs as a practical matter disclaim all liability and are not, in
fact, insuring anything in the sense of insurance.
5) The third party attestation idea is wrong as it does not properly
model the actual trust relationships and liability among the parties.
6) The entire idea of signed attestations that last for years is based
on a pre-Internet, largely offline model of security.
There is more, but why should we belabor it? The parrot is not pining
for the fjords. I'm only surprised that the nails have kept it
vertical for so long.

@_date: 2010-07-28 19:38:40
@_author: Perry E. Metzger 
@_subject: A slight modification of my comments on PKI. 
A coda on today's voluminous discussion of X.509, browser security,
It is important to remember what we're trying to defend against.  As
many of us have learned through bitter experience, the costs and
benefits of security systems we deploy are the important part. No one
needs perfect security in the face of no attackers at all, and even if
attackers are numerous, if a system has low enough failure/fraud
rates, no one will complain much.
The problem is that the system we've built to date is, in fact,
yielding pretty high fraud rates. Attacking people is a full time
profitable business for a lot of people, not a rare sort of
thing. Stolen credentials are sold in the market for very low prices
because there is a glut of them. Yes, the majority of online
transactions are trouble free, but a shocking fraction of them are
not, and the majority of people I know have had a card stolen at least
once online. Things like bank account credential phishing are not only
possible but prevalent. All this may get worse. The cost is a large
fraction of the fees we all end up paying, directly and indirectly, to
do business.
What we would like is to get from the situation we are in now (which
reminds me in certain ways of the days of analog cellphone service
where cloning was trivial) to a situation where fraud still happens
but is much more difficult to pull off. (Certainly phone fraud still
happens, but it is no longer anything like it was in the NAMPS days
and the cost is manageably low.) This would also have the benefit of
radically reducing the number of people who can make a living as
professional attackers, which would have all sorts of salutary
To lower the fraud rate by significant margins, I think we'll need to
make some serious changes in the security systems we deploy. Logging
in to your bank's web site using a password protected by an SSL
session requires that too many things all go right and that the user
pay attention to whether they have all gone right. We need simpler
systems where, if the user is not paying attention, nothing much bad
can happen to them anyway.
No system can be perfect, but we could do a lot better than we are
doing now. I think this is achievable in theory. Whether it can happen
in practice, I have my doubts, though we can but try.

@_date: 2010-07-29 13:12:06
@_author: Perry E. Metzger 
@_subject: Obama administration seeks warrantless access to email headers. 
The administration wants to add just four words -- "electronic
  communication transactional records" -- to a list of items that the
  law says the FBI may demand without a judge's approval. Government
  lawyers say this category of information includes the addresses to
  which an Internet user sends e-mail; the times and dates e-mail was
  sent and received; and possibly a user's browser history. It does not
  include, the lawyers hasten to point out, the "content" of e-mail or
  other Internet communication.

@_date: 2010-07-30 09:58:08
@_author: Perry E. Metzger 
@_subject: Obama administration seeks warrantless access to email headers. 
It is significantly harder here in the US. Equally importantly, it is
much simpler to determine what warrants were issued after the fact.
However, lets say you were right and there was no significant
impediment. It would be disturbing to see even the small protections
currently afforded removed without any apparent benefit to the

@_date: 2010-07-31 11:24:29
@_author: Perry E. Metzger 
@_subject: About that "Mighty Fortress"...  What's it look like? 
You are still following the same model that has failed over and over
and over again. "Endorsing" keys is the same "we have no internet, so
we rely on having big books to tell us whether a person's credit card
was stolen" model.
There is no rational reason at all that someone should "endorse" a key
when it is possible to simply do a real time check for
authorization. There is no reason to sign a key when you can just
check if the key is in a database.
If you have to do a real time check for every use anyway, the
signature on the key is unnecessary as you can just ask "is this user
authorized". If you can't do a real time check, then the system fails
anyway. Either way, there is no logical or architectural reason for
signatures on keys.
I challenge you to explain any such model to my mother
successfully. Indeed, I think any model that needs to be explained to
anyone has already failed.
A good model is one in which if you screw up, nothing bad can
happen. For example, if you go to the phisherman's web site instead of
your bank's, nothing you can possibly do will endanger your
security. The worst that can happen is you end up frustrated and
puzzled, but you never can leak information to the phisherman. It may
be impossible to achieve this with complete perfection, but if, for
example, it would be necessary for someone trying to steal your
credentials to social engineer you into get actual physical access to
a smart token or some such for a while to get at your bank account,
things are now "good enough" for most purposes.

@_date: 2010-07-31 12:32:39
@_author: Perry E. Metzger 
@_subject: Five Theses on Security Protocols 
Inspired by recent discussion, these are my theses, which I hereby
nail upon the virtual church door:
1 If you can do an online check for the validity of a key, there is no
  need for a long-lived signed certificate, since you could simply ask
  a database in real time whether the holder of the key is authorized
  to perform some action. The signed certificate is completely
  superfluous.
  If you can't do an online check, you have no practical form of
  revocation, so a long-lived signed certificate is unacceptable
  anyway.
2 A third party attestation, e.g. any certificate issued by any modern
  CA, is worth exactly as much as the maximum liability of the third
  party for mistakes. If the third party has no liability for
  mistakes, the certification is worth exactly nothing. All commercial
  CAs disclaim all liability.
  An organization needs to authenticate and authorize its own users;
  it cannot ask some other organization with no actual liability to
  perform this function on its behalf. A bank has to know its own
  customers, the customers have to know their own bank. A company
  needs to know on its own that someone is allowed to reboot a machine
  or access a database.
3 Any security system that demands that users be "educated",
  i.e. which requires that users make complicated security decisions
  during the course of routine work, is doomed to fail.
  For example, any system which requires that users actively make sure
  throughout a transaction that they are giving their credentials to
  the correct counterparty and not to a thief who could reuse them
  cannot be relied on.
  A perfect system is one in which no user can perform an action that
  gives away their own credentials, and in which no user can
  authorizes an action without their participation and knowledge. No
  system can be perfect, but that is the ideal to be sought after.
4 As a partial corollary to 3, but which requires saying on its own:
  If "false alarms" are routine, all alarms, including real ones, will
  be ignored. Any security system that produces warnings that need to
  be routinely ignored during the course of everyday work, and which
  can then be ignored by simple user action, has trained its users to be
  victims.
  For example, the failure of a cryptographic authentication check
  should be rare, and should nearly always actually mean that
  something bad has happened, like an attempt to compromise security,
  and should never, ever, ever result in a user being told "oh, ignore
  that warning", and should not even provide a simple UI that permits
  the warning to be ignored should someone advise the user to do so.
  If a system produces too many false alarms to permit routine work to
  happen without an "ignore warning" button, the system is worthless
  anyway.
5 Also related to 3, but important in its own right: to quote Ian
  Grigg:
    *** There should be one mode, and it should be secure. ***
  There must not be a confusing combination of secure and insecure
  modes, requiring the user to actively pay attention to whether the
  system is secure, and to make constant active configuration choices
  to enforce security. There should be only one, secure mode.
  The more knobs a system has, the less secure it is. It is trivial to
  design a system sufficiently complicated that even experts, let
  alone naive users, cannot figure out what the configuration
  means. The best systems should have virtually no knobs at all.
  In the real world, bugs will be discovered in protocols, hash
  functions and crypto algorithms will be broken, etc., and it will be
  necessary to design protocols so that, subject to avoiding downgrade
  attacks, newer and more secure modes can and will be used as they
  are deployed to fix such problems. Even then, however, the user
  should not have to make a decision to use the newer more secure mode,
  it should simply happen.

@_date: 2010-07-31 18:17:42
@_author: Perry E. Metzger 
@_subject: Five Theses on Security Protocols 
With a public key you have in a configuration file, or a pairwise
shared secret key stored in a database.
A key sitting in a configuration file is not the same thing as a
certificate signed by a CA and trusted for that reason. Instead, it is
trusted for the same reason that, say, the /etc/passwd file on a Unix
box is trusted -- because if someone could break in and alter the
file, they could do anything else they wanted anyway.
You do not need a signed certificate.
I don't see why you need a certificate for any purpose whatsoever.
A key, on the other hand, is a very different thing. There's nothing
wrong with keys.

@_date: 2010-03-12 19:36:00
@_author: Perry E. Metzger 
@_subject: [ADMIN] No, I'm not dead. 
I should have the list back to normal again within a few days. Following
that, I will be converting the list over to Mailman and selecting a
couple of co-moderators to handle things when I'm too busy to handle
moderation duties.

@_date: 2010-03-21 09:42:37
@_author: Perry E. Metzger 
@_subject: nytimes: academic paper or cyberwarfare? 
An article in The New York Times today indirectly highlights the
misunderstanding of the way that researchers try to make things more
secure, which is generally by trying to figure out and point out the
First few paragraphs:
   Academic Paper in China Sets Off Alarms in U.S.
   By JOHN MARKOFF and DAVID BARBOZA
   It came as a surprise this month to Wang Jianwei, a graduate
   engineering student in Liaoning, China, that he had been described as
   a potential cyberwarrior before the United States Congress.
   Larry M. Wortzel, a military strategist and China specialist, told
   the House Foreign Affairs Committee on March 10 that it should be
   concerned because ?Chinese researchers at the Institute of Systems
   Engineering of Dalian University of Technology published a paper on
   how to attack a small U.S. power grid sub-network in a way that would
   cause a cascading failure of the entire U.S.?
   When reached by telephone, Mr. Wang said he and his professor had
   indeed published ?Cascade-Based Attack Vulnerability on the
   U.S. Power Grid? in an international journal called Safety Science
   last spring. But Mr. Wang said he had simply been trying to find ways
   to enhance the stability of power grids by exploring potential
   vulnerabilities.
   ?We usually say ?attack? so you can see what would happen,? he
   said. ?My emphasis is on how you can protect this. My goal is to find
   a solution to make the network safer and better protected.? And
   independent American scientists who read his paper said it was true:
   Mr. Wang?s work was a conventional technical exercise that in no way
   could be used to take down a power grid.

@_date: 2010-03-23 11:21:01
@_author: Perry E. Metzger 
@_subject: "Against Rekeying" 
Ekr has an interesting blog post up on the question of whether protocol
support for periodic rekeying is a good or a bad thing:
I'd be interested in hearing what people think on the topic. I'm a bit
skeptical of his position, partially because I think we have too little
experience with real world attacks on cryptographic protocols, but I'm
fairly open-minded at this point.

@_date: 2010-03-26 10:22:06
@_author: Perry E. Metzger 
@_subject: "Against Rekeying" 
Peter Gutmann has been having some trouble with his email and asked me
to manually forward this to the list. If you reply, don't credit me with
the text, it is his.
I missed that in his blog post as well.  An equally big one is the SSHv2
rekeying fiasco, where for a long time an attempt to rekey across two
different implementations typically meant "drop the connection", and it still
does for the dozens(?) of SSH implementations outside the mainstream of
OpenSSH, Putty, ssh.com and a few others, because the procedure is so complex
and ambiguous that only a few implementations get it right (at one point the
ssh.com and OpenSSH implementations would detect each other and turn off
rekeying because of this, for example).  Unfortunately in SSH you're not even
allowed to ignore rekey requests like you can in TLS, so you're damned if you
do and damned if you don't [0].
A more general concern though is that the large amount of extra complexity
caused by the rekeying (you're juggling a renegotiate of a new set of security
parameters while simultaneously applying the current set of security
parameters) provides a very large amount of attack surface - and in SSH's case
failure modes - that just isn't justified by the hypothetical threats that
rekeying is meant to address.

@_date: 2010-03-26 10:23:57
@_author: Perry E. Metzger 
@_subject: "Against Rekeying" 
Also manually forwarded on behalf of  Peter Gutmann. As  before, if you
reply, don't credit me with the text, it is his.
I think that was a significant problem with noticing this, that many
implementors may have looked at it, decided it was a nightmare to implement,
served no really obvious purpose once 40-bit keys had gone the way of the
dodo, and was a significant source of future problems (see my previous
message), and so never bothered with it.  As a result it never got much
attention, as do significant chunks of other security protocols.  I think the
real skill in security protocol implementation isn't knowing what to
implement, but knowing what not to implement (I've had an attack-surface-
reduced SSH draft in preparation for awhile now, I really must get back to the
some time).
One nice thing about being the author of a crypto toolkit is that you can
experiment with this, either skipping features or turning existing features
off in new releases, to see if anyone notices.  If no-one does, you leave them
turned off.  You can turn off an awful lot of security-protocol "features"
before people start to notice, leading me to believe that a scary portion of
many protocols actually consist of attack surface and not features.

@_date: 2010-03-26 12:06:23
@_author: Perry E. Metzger 
@_subject: high speed password cracking on GPUs 
This is from ten days ago but I just ran across it. Nothing very deep --
just higher speed brute force attacks via GPUs.

@_date: 2010-03-29 23:31:39
@_author: Perry E. Metzger 
@_subject: [OpenSSL] OpenSSL 1.0.0 released 
============================== START ==============================
   OpenSSL version 1.0.0 released
   ==============================
   OpenSSL - The Open Source toolkit for SSL/TLS
      The OpenSSL project team is pleased to announce the release of
   version 1.0.0 of our open source toolkit for SSL/TLS.  This new
   OpenSSL version is a major release and incorporates many new
   features as well as major fixes compared to 0.9.8n.  For a complete
   list of changes, please see  .
   The most significant changes are:
      o RFC3280 path validation: sufficient to process PKITS tests.
      o Integrated support for PVK files and keyblobs.
      o Change default private key format to PKCS
      o CMS support: able to process all examples in RFC4134
      o Streaming ASN1 encode support for PKCS and CMS.
      o Multiple signer and signer add support for PKCS and CMS.
      o ASN1 printing support.
      o Whirlpool hash algorithm added.
      o RFC3161 time stamp support.
      o New generalised public key API supporting ENGINE based algorithms.
      o New generalised public key API utilities.
      o New ENGINE supporting GOST algorithms.
      o SSL/TLS GOST ciphersuite support.
      o PKCS and CMS GOST support.
      o RFC4279 PSK ciphersuite support.
      o Supported points format extension for ECC ciphersuites.
      o ecdsa-with-SHA224/256/384/512 signature types.
      o dsa-with-SHA224 and dsa-with-SHA256 signature types.
      o Opaque PRF Input TLS extension support.
      o Updated time routines to avoid OS limitations.
   We consider OpenSSL 1.0.0 to be the best version of OpenSSL available
   and we strongly recommend that users of older versions upgrade as
   soon as possible.  OpenSSL 1.0.0 is available for download via HTTP
   and FTP from the following master locations (you can find the various
   FTP mirrors under      *      * ftp://ftp.openssl.org/source/
   The distribution file name is:
    o openssl-1.0.0.tar.gz
      Size: 4010166
      MD5 checksum: 89eaa86e25b2845f920ec00ae4c864ed
      SHA1 checksum: 3f800ea9fa3da1c0f576d689be7dca3d55a4cb62
   The checksums were calculated using the following commands:
    openssl md5 openssl-1.0.0.tar.gz
    openssl sha1 openssl-1.0.0.tar.gz
   Yours,
   The OpenSSL Project Team...
    Mark J. Cox             Nils Larsch         Ulf M?ller
    Ralf S. Engelschall     Ben Laurie          Andy Polyakov
    Dr. Stephen Henson      Richard Levitte     Geoff Thorpe
    Lutz J?nicke            Bodo M?ller

@_date: 2010-10-06 18:19:01
@_author: Perry E. Metzger 
@_subject: Anyone know anything about the new AT&T encrypted voice service? 
AT&T debuts a new encrypted voice service. Anyone know anything about
(Hat tip to Jacob Applebaum's twitter feed.)

@_date: 2010-10-08 11:21:16
@_author: Perry E. Metzger 
@_subject: Photos of an FBI tracking device found by a suspect 
My question: if someone plants something in your car, isn't it your
property afterwards?

@_date: 2010-10-08 16:27:57
@_author: Perry E. Metzger 
@_subject: Disk encryption advice... 
I have a client with the following problem. They would like to
encrypt all of their Windows workstation drives, but if they do that,
the machines require manual intervention to enter a key on every
reboot. Why is this a problem? Because installations and upgrades of
many kinds of Windows software require multiple reboots, and they
don't want to have to manually intervene on every machine in their
buildings in order to push out software and patches.
(The general threat model in question is reasonably sane -- they
would like drives to be "harmless" when machines are disposed of or if
they're stolen by ordinary thieves, but on the network and available
for administration the rest of the time.)
Does anyone have a reasonable solution for this?

@_date: 2010-10-08 17:45:16
@_author: Perry E. Metzger 
@_subject: Photos of an FBI tracking device found by a suspect 
Yes. However, that's an accident. If you deliberately leave a package
on someone's doorstep, they then own the contents. (In fact, if
someone mails you something, US law is very clear that it is yours.)
I'd be interested in hearing what a lawyer thinks.

@_date: 2010-09-01 13:39:19
@_author: Perry E. Metzger 
@_subject: Nearly $1,000,000 stolen electronically from the University of 
Hardly the first time such things have happened, but it does focus
the mind on what the threats are like.

@_date: 2010-09-01 13:48:10
@_author: Perry E. Metzger 
@_subject: RSA question 
The function of the padding is to prevent chosen ciphertext
attacks as well. Those are very feasible in the absence of padding.
I'm surprised no one has chimed in so far to mention this.
Padding prevents other attacks including attacks on common exponents.

@_date: 2010-09-04 10:48:08
@_author: Perry E. Metzger 
@_subject: Merkle Signature Scheme is the most secure signature scheme 
On Sat, 4 Sep 2010 10:45:48 +1000 (EST) Dave Horsfall
You mean a group.
It is known that DES is not a group, but that result comes from a
different use of the algorithm than the somewhat way DES is invoked
in the crypt(3) algorithm, and I don't know if that modifies the
result. None the less, I suspect it would be surprising if it turned
out to be a group even in the use in crypt(3).

@_date: 2010-09-07 14:03:47
@_author: Perry E. Metzger 
@_subject: Fw: Request for Comments - NIST Draft SP 800-135: Recommendation 
Forwarded from the saag mailing list:
Begin forwarded message:
-------- Original Message --------
NIST requests comments on Draft SP 800-135, Recommendation for
Application-Specific Key Derivation Functions.
The document specifies security requirements for existing
application-specific key derivation functions in: American National
Standard (ANS) X9.42-2001-Public Key Cryptography for the Financial
Services Industry: Agreement of Symmetric Keys Using Discrete
Logarithm Cryptography, American National Standard (ANS)
X9.63-2001-Public Key Cryptography for the Financial Services
Industry: Key Agreement and Key Transport Using Elliptic Curve
Cryptography, Internet Key Exchange, Secure Shell, Transport Layer
Security, The Secure Real-time Transport Protocol, User-based
Security Model for version 3 of the Simple Network Management
Protocol , and Trusted Platform Module. The document is available at
  Please provide comments by September 30th 2010 to quynh.dang at nist.gov
with ?Comments on Draft SP 800-135? in the subject line.
For additional questions, please do not use reply.  Contact Quynh Dang
(quynh.dang at nist.gov)

@_date: 2010-09-07 14:19:46
@_author: Perry E. Metzger 
@_subject: Randomness, Quantum Mechanics - and Cryptography 
Very true.
I suspect that for some apps like smart cards that might be hard.
OTOH, it might be straightforward to detect the attempt.
Well, imagine that you could very reliably force the random number
generator on a smart card. You could then probably attack the smart
card in all sorts of ways, even retrieving keying material by
sufficiently perverting the "random" choices made in some protocol
This is not a practical attack for a remote server, but for some
situations, it probably is.

@_date: 2010-09-07 15:18:21
@_author: Perry E. Metzger 
@_subject: Randomness, Quantum Mechanics - and Cryptography 
One could, however, run the card one is trying to attack under reduced
temperature and hit it with RF at the same time.
The question is, can you make it more expensive to do that than to,
say, buy a new parking card or whatever else the smart card is being
used for. If the attack is fairly cheap and repeatable and yields
something reasonably valuable, you have a problem. If you can make the
attack expensive and only yield something cheap, you're doing well.
Don't assume, though, that the attacker can't lower the temperature in
most of the circuit, keep the tiny thermometer you included at room
temperature, and inject RF at the same time. Don't even assume they
will need to rip the device apart to do it. The only question is, can
you make it expensive enough to succeed to protect what you're trying
to protect.

@_date: 2010-09-08 10:58:56
@_author: Perry E. Metzger 
@_subject: Randomness, Quantum Mechanics - and Cryptography 
On Tue, 7 Sep 2010 22:22:57 -0400 Jerry Leichter Actually, I've seen a significant number of proofs in the crypto world
that amount to "show that the attacker cannot distinguish these bits
from a set of random bits with probability better than uninformed
It appears to be reasonable to think that if the attacker cannot
distinguish a stream from a "true" random stream, or cannot predict
the next bit with better probability than chance, the attacker has no
handle on which to base an attack. I would invite people who are
more versed on this topic to chime in.

@_date: 2010-09-10 10:12:24
@_author: Perry E. Metzger 
@_subject: ADMIN: please do not "dual post" 
Please don't send email to this list and another mailing list at the
same time. This list is moderated, and the inevitable result is not
pretty. I won't forward mail CCed to multiple lists in the future.

@_date: 2010-09-14 07:44:42
@_author: Perry E. Metzger 
@_subject: 'Padding Oracle' Crypto Attack Affects Millions of ASP.NET Apps 
Couldn't one simply include a timestamp in the encrypted data?
Assuming a five minute window (or what have you) would be too much,
one could also keep some state for five minutes (which is not a lot
to ask for.)

@_date: 2010-09-14 08:15:52
@_author: Perry E. Metzger 
@_subject: Debian encouraging use of 4096 bit RSA keys 
The decision that 1024 bit keys are inadequate for code signing is
likely reasonable. The idea that 2048 bits and not something between
1024 bits and 2048 bits is a reasonable minimum is perhaps arguable.
One wonders what security model indicated 4096 bits is the ideal
Begin forwarded message:
So, even small teams more closely related to bureaucracy and
bookkeeping such as ours also deserve to send out some "bits from..."
mails from time to time. And being past midnight, I hope I can keep
this concise and short. For people that were present at my lightning
talk at DebConf, expect no new material in this mail... We just needed
to send it out.
1. PGP (v3) keys are gone!
   -----------------------
The first point is that, with a lot of patience and chasing, and after
over a year of having stated the intention, we can finally say that
older, vulnerable v3 keys are gone from the Debian Developer keyring,
yay! Thanks in no small measure to Jonathan's endless bugging and
chasing, all keys in Debian today are v4 1024D or higher, and that is
a Very Good Thing. And yes, it leads us to the next point...
2. We want stronger keys
   ---------------------
1024D (SHA1) keys are OK-ish for now. No attacks are known on them,
and they are not compromising the archive in any way (if they were, of
course, we would immediately disable them and _then_ look for
solutions, while surely becoming overnight the most hated team in
Debian). Still, to be on the safe side (and to avoid the long and
painful declining curve we had with v3 keys), we are now clearly
pushing Debian towards adopting stronger RSA keys - We have accepted
some 2048R keys, but if you don't have a real reason to keep your key
at that size (i.e. you very often build on underpowered machines where
a 4096R key takes forever, or something like that), we really prefer
to go with 4096R keys.
To create your 4096R key, you are advised to follow Ana Guerrero's
excellent tutorial [1].
The policies for a key upgrade go as follows (and are explained at
greater length at [2]): - Your new key should be signed by your old key
- Your new key should be signed by two or more other Debian Developers
- Mail the key replacement request to keyring at rt.debian.org,
  mentioning 'Debian RT' somewhere in the mail subject
- The request should be _inline_ signed by your old key. If you send a
  MIME-encoded signed message, RT will mangle it and it won't
  validate. Please, inline-sign the message.
- Although we clearly want to transition to a stronger keyring, that
  does not mean we want to loosen the Web of Trust. That means that if
  you have a gazillion signatures in your 1024D key, you should not
  rush to update it with a barely-signed 4096R one. Get it signed by
  as many people as possible. If you are already socially active in
  Debian, that should pose no problem. Otherwise... Well, if you are
  isolated and far from anybody else, we might do it. But remember,
  there is no _pressing_ need to do so.
3. We demand stronger keys!
   ------------------------
But then again, we are not allowing any new 1024D keys
anymore. Anybody who is currently a DD or DM, or that has started his
application towards becoming one, will be allowed with whatever key
they currently have - But effective October 1st, no applications for
DM or DD should be processed with anything less than a 2048R
SHA2-capable key. Ok, so, I'm looking forward to process your key update requests!
On behalf of keyring-maint,
   -Gunnar
[1] [2]

@_date: 2010-09-14 10:57:49
@_author: Perry E. Metzger 
@_subject: Debian encouraging use of 4096 bit RSA keys 
[Moderator's note: Anonymously forwarded at the request of the
sender. If you reply to this, please don't attribute it to me, I
didn't send it. --Perry]
Begin forwarded message:
[Perry, please forward this anonymously, if you're permitting that
these days]
I ran into a mindboggling one a couple of weeks ago: a customer
complaint that "our new certificate doesn't work" when loaded into
one of my employer's SSL offload devices.
The actual cause was that the customer had loaded a 4096 bit key and
caused end-to-end performance to fall to about 12 TPS from the 1500
TPS they were seeing with their previous 1024 bit key.
When we inquired why they were using a 4096 bit key, they indicated
that their "information security department" had imposed the
requirement that their service keys had to be "twice as long as the
CA's key" so that "we are not the weak link in our customers'
It took some time, but I think we explained the deep folly of this new
policy to them.
I am a big fan of keys in the 1280-1536 bit range for SSL server
certificates.  Surveying a large number of commercially signed
certificates on the Internet I see the overwhelming majority expire
within 3 years of issue.
This suggests to me that even if NIST is correct that 2048 bit RSA
keys are the reasonable the minimum for new deployments after 2010,
much shorter keys are appropriate for most server certificates that
these CAs will sign.  The CA keys have lifetimes of 10 years or more;
the server keys a a quarter to a fifth of that.
Making 2048 bit keys the standard on individual servers will reduce
server performance to the extent that initiatives like "HTTPS
everywhere" will become impractical.  Yes, I/O is usually the
bottleneck for most servers, but increasing the SSL handshake cost by
a factor of 10 changes that quite dramatically.
Meanwhile, 1280 bit keys offer a huge increase in resistance to
factoring within the next decade and have much less performance impact
for servers (since the performance impact on clients is so widely
distributed for the HTTPS case I think it can be ignored, but this
is of course better for 1280 bit keys too).
But people look at the NIST document that recommends 2048 bit keys
after 2010 (which I do think is a somewhat misguided recommendation
for keys as short-lived as web server keys, though definitely correct
for CA keys) and decide to be "double safe" and we get lunacy like
Debian trying to atone for their past OpenSSL sins by using 4096 bit
keys everywhere and, as a practical matter, *reducing* the spread of
service deployment over HTTPS because with 4096 bit keys, you just

@_date: 2010-09-14 11:13:27
@_author: Perry E. Metzger 
@_subject: Debian encouraging use of 4096 bit RSA keys 
That may be longer than is reasonable. Technologies shift, and having
the capability to update keys over the course of years may be
superior to attempting to guess (without sufficient information) what
the right key length in 2025 would be.
Recall that it is also difficult to keep a private key secure for
decades, so 15 years may be longer than it is reasonable to assume
that the physical key is safe from actual outright theft or even
accidental disclosure. Also, every once in a while, it turns out that
one's random number generator or algorithms are not what they should
have been.
One needs a way of updating keys even if one is reasonably sure that
brute force attacks will not work over the period. Given that,
attempting to secure the system with a massive key is probably a bad
I'm not sure why the tradeoff would be between a particular seemingly
arbitrary RSA size and a particular seemingly arbitrary DSA size. I
would suggest instead selecting the algorithm and key length
I'll open the floor to further discussion now...

@_date: 2010-09-16 09:50:42
@_author: Perry E. Metzger 
@_subject: ADMIN: Heavy-handed moderation 
Moderator's note:
There have been a lot (!) of messages sent in the last 15 hours or so
following a number of recent high "heat" threads.  Over a dozen (!) of
them are long, earnest, well written, and generally a repeat of a
number of recent arguments we've had on the list or veer off
topic. (Yes, I really do try to keep things to a particular set of
topics even if it doesn't always seem that way from the outside.)
I'm therefore exercising my moderatorial prerogative and being quite
heavy handed about what I'm forwarding today.
Apologies to those of you who've spent time writing some interesting
things that won't be going out, but I have to consider the readers
first and the writers second...

@_date: 2010-09-27 08:26:14
@_author: Perry E. Metzger 
@_subject: Obama administration revives Draconian communications intercept 
[Moderator's note: there are messages still in the queue that will go
 out later today, but I felt this had to go out ASAP --Perry]
From the New York Times, word that the Obama administration wants to
compel access to encrypted communications.
  U.S. Wants to Make It Easier to Wiretap the Internet
  By CHARLIE SAVAGE
  Published: September 27, 2010
  WASHINGTON ? Federal law enforcement and national security officials
  are preparing to seek sweeping new regulations for the Internet,
  arguing that their ability to wiretap criminal and terrorism
  suspects is ?going dark? as people increasingly communicate online
  instead of by telephone.
  Essentially, officials want Congress to require all services that
  enable communications ? including encrypted e-mail transmitters like
  BlackBerry, social networking Web sites like Facebook and software
  that allows direct ?peer to peer? messaging like Skype ? to be
  technically capable of complying if served with a wiretap order. The
  mandate would include being able to intercept and unscramble
  encrypted messages.

@_date: 2010-09-30 20:50:22
@_author: Perry E. Metzger 
@_subject: ADMIN: Don't Top Post. Trim Quoted Material. 
Moderator's note:
I hate to ask this yet again, but PLEASE do not top post,
and PLEASE trim the message you are replying to.
Multiple messages sent to the list recently have had only a couple of
lines sitting above a long original message quoted in its entirety.
Taking the time to follow reasonable conventions for replying to
email means that the people reading your missive will have a much
easier and faster time understanding what you're writing.

@_date: 2011-08-07 19:08:53
@_author: Perry E. Metzger 
@_subject: [Cryptography] testing 
Assuming this gets out, the list has been successfully resurrected,
now using Mailman instead of the long since unsupportable Majordomo.
Expect an administrative message later tonight.

@_date: 2011-08-07 20:08:20
@_author: Perry E. Metzger 
@_subject: [Cryptography] The Cryptography and Security mailing list has been 
0) Many of you were asking me about the mailing list quite
regularly. My apologies to everyone for how long it took me to get
enough free time to get things going again.
1) We are now running on Mailman instead of on the long obsolete
Majordomo. This gives us both online archives and the ability for
other people to take over for me when I'm too busy (see 3 and 4,
2) As list was dead for a large fraction of a year, if you don't want
to be on it any more, click on the link at the bottom and
3) I'm expecting my time will continue to be limited, a side effect of
being a doctoral student. To make sure the list does not fall silent
again, I'll be announcing at least one (and hopefully more)
co-moderators shortly, who will take over for me when I'm too busy.
4) We now have archives back to early 2001 online. They may be a bit
mangled -- let me know if you catch any problems. Also, if you have
archives dating back before that, let me know -- I'd like to slurp
them in.
5) For years, I've considered splitting the list into a technical
cryptography only list and a list that discusses the wider range of
security and security related politics. This would allow people
interested only in cryptography qua cryptography to get an even lower
noise environment -- let me know if you have an opinion on the topic.

@_date: 2011-08-07 20:31:21
@_author: Perry E. Metzger 
@_subject: [Cryptography] sorry, one last test. 
Please ignore.
(For those that don't ignore these thins, hopefully VERPs should now
be on. No, you have no reason to know what that means if you're not
someone who runs mailing lists.)

@_date: 2011-08-07 21:59:33
@_author: Perry E. Metzger 
@_subject: [Cryptography] The Cryptography and Security mailing list has 
On Mon, 8 Aug 2011 03:31:00 +0200 "R. Hirschfeld" If you had the stuff in mbox format it would be great -- that's what
Mailman slurps in for old archives. Is it a complete archive though?

@_date: 2011-08-09 10:18:38
@_author: Perry E. Metzger 
@_subject: [Cryptography] Crypto being blamed in the London riots. 
Quoting from the New York Times:
  David Lammy, Britain's intellectual property minister, also called
  for a suspension of Blackberry's encrypted instant message service.
  Many rioters, exploiting that service, had been able to organize mobs
  and outrun the police, who were ill-equipped to monitor it. "It is
  unfortunate, but for the very short term, London can't have a night
  like the last," Mr. Lammy said in a Twitter post.
  Officials at Research in Motion, the corporate parent of Blackberry,
  declined to comment on whether the service would be suspended. But
  the company, based in Waterloo, Ontario, issued a statement saying:
  "We feel for those impacted by recent days' riots in London. We have
  engaged with the authorities to assist in any way we can."

@_date: 2011-08-09 11:06:33
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: Please don't top post. 
The list has been alive again only for a couple of days, but it
appears that I need to post this oldie again.
A3: Please.
Q3: Should I avoid top posting on this mailing list?
A2: Because, by reversing the order of a conversation, it leaves the
    reader without much context, and makes them read a message in an
    unnatural order.
Q2: Why is top posting irritating?
A1: It is the practice of putting your reply to a message before the
    quoted message, instead of after the (trimmed) message.
Q1: What is top posting?
Top Posting FAQ:

@_date: 2011-08-09 11:20:37
@_author: Perry E. Metzger 
@_subject: [Cryptography] "India wants special monitoring access for Twitter, 
Quoting. Crypto starts being mentioned in the fourth paragraph:
  India's communications ministry has been asked by the home ministry
  to monitor social networking websites such as Twitter and Facebook
  amid fears that the services are being used by terrorists to plan
  attacks.
  The request suggests that the Indian government is trying to broaden
  the scope of its online surveillance for national security.
  Telecommunications service providers in India provide facilities for
  lawful interception and monitoring of communications on their
  network, including communications from social networking websites
  such as Facebook and Twitter, in accordance with their license
  agreements,[...]
  But there are certain communications which are encrypted, Deora said
  Friday.
  The government did not provide details of what encrypted data they
  would like to have access to. A spokesman for the home ministry said
  on Monday that additional information can only be provided in
  Parliament while it is in session.

@_date: 2011-08-10 07:12:07
@_author: Perry E. Metzger 
@_subject: [Cryptography] Today's XKCD is on password strength. 
Today's XKCD is on password strength. The advice it gives is pretty
good in principle...

@_date: 2011-08-10 09:13:32
@_author: Perry E. Metzger 
@_subject: [Cryptography] Crypto being blamed in the London riots. 
Funny, that, since Sampo's proposal is more or less how Blackberry
chat actually works. (Various previous posters had the details wrong.)
Also all blackberry corporate services work without RIM having any
access to the content -- they only get access to email for individual
users for whom they terminate the encrypted tunnel.

@_date: 2011-08-10 09:19:53
@_author: Perry E. Metzger 
@_subject: [Cryptography] Crypto being blamed in the London riots. 
Blackberry already more or less has that functionality, which
disproves your hypothesis.

@_date: 2011-08-10 17:17:06
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: sending from a second account to the list 
============================== START ==============================
Several people have complained to me that they get their email for
the list sent from a different address than the one they send from
and that their mail has bounced as a result.
To take care of this, on your own, just add a second account using
the web interface and click the "no mail" option. You will then be
able to mail to the list from that address but you won't get mail to
For those that asked, this isn't a normal Mailman feature -- I hacked
it in with a Postfix policy daemon so it happens at the MTA
dialog. It is necessary because the list gets hundreds and sometimes
thousands of spam attempts a day and I didn't want to deal with the
mail queues being clogged with thousands of bounce messages that
would never be delivered

@_date: 2013-08-20 13:38:38
@_author: Perry E. Metzger 
@_subject: [Cryptography] What is the state of patents on elliptic curve 
What is the current state of patents on elliptic curve cryptosystems?
(It would also be useful to know when the patents on such patents as
exist end.)

@_date: 2013-08-25 15:12:16
@_author: Perry E. Metzger 
@_subject: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
For some research on communications privacy I'm doing at the moment,
I'm interested in learning about the state of the art of DHT systems
and mix network systems. I'd like to know both which systems are
currently considered "state of the art" and what the state of the art
is on attacks against such systems.
Anyone care to shed some light? Pointers to literature are especially
welcome, but anything that is just "in the folklore" is also clearly
of use...

@_date: 2013-08-25 15:34:46
@_author: Perry E. Metzger 
@_subject: [Cryptography] Traffic Analysis (was Re:  PRISM PROOF Email) 
The best technology for that is mix networks.
At one point, early in the cypherpunks era, mix networks were
something of an expensive idea. Now, however, everyone in sight is
connected 24x7 to the internet. Similarly, at one point, bandwidthwas
scarce, but now, most traffic is video, and even if instant messages
and email equivalents took many hops through the network, the
bandwidth used (except for mobiles, which need not be interior mix
nodes per se) is negligible.

@_date: 2013-08-25 16:29:42
@_author: Perry E. Metzger 
@_subject: [Cryptography] Thoughts about keys 
[Disclaimer: very little in this seems deeply new, I'm just
mixing it up in a slightly different way. The fairly simple idea I'm
about to discuss has germs in things like SPKI, Certificate
Transparency, the Perspectives project, SSH, and indeed dozens of
other things. I think I even suggested a version of this exact idea
several times in the past, and others may have as well. I'm not going
to pretend to make claims of real originality here, I'm more
interested in thinking about how to get such things quite widely
deployed, though it would be cool to hear about prior art just in case
I decide to publish a tech report.]
One element required to get essentially all messaging on the
Internet end to end encrypted is a good way to find out what people's
keys are.
If I meet someone at a reception at a security conference, they might
scrawl their email address ("alice at example.org") for me on a cocktail
I'd like to be able to then write to them, say to discuss their
exciting new work on evading censorship of mass releases of stolen
government documents using genetically engineered fungal spores to
disseminate the information in the atmosphere worldwide.
However, in our new "everything is always encrypted" world, I'll be
needing their encryption key, and no one can remember something as
long as that.
So, how do I translate "alice at example.org" into a key?
Now, the PGP web-of-trust model, which I think is broken, would have
said "check a key server, see if there's a reasonable trust path
between you and Alice."
I have an alternative suggestion.
Say that we have a bunch of (only vaguely) trustworthy organizations
out in the world. (They can use crypto based log protocols of various
kinds to make sure you don't _really_ need to trust them, but for the
moment that part doesn't matter.)
Say that Alice, at some point in the past, sent an email message,
signed in her own key, to such an organization's key server, saying in
effect "this is alice at example.org's key".
At intervals, the trustworthy organization (and others like it) can
send out email messages to Alice, encrypted in said key, saying "Hi
there! Please reply with a message containing this magic cookie,
encrypted in our key, signed in yours."
If a third party needing the key for alice at example.org queries the
vaguely trusted server, it will then give them information like "For
the past six years, we've been sending alice at example.org emails every
couple of weeks asking her to reply to demonstrate she controls a
particular public key, and she always has -- new keys have always been
signed in the old one, too. Here's a log, including various sorts of
widely witnessed events and hash chains so that if we were lying about
this we had to be planning to lie about it for a very long time."
Now of course, in the real world, who wants to go through the effort
of hand replying to query messages to establish a key over time?
Instead, Alice has some actually trusted software running on her
computer at home.
She can either leave it to automatically do IMAP queries against her
mailbox (which could even be GMail or what have you) and reply on her
behalf, or it could ask her to unlock her key while she's at home in
the morning having her coffee. However, I think the former is actually
preferable. We'd rather have an imperfect system that is effortless to
use but can be bypassed by physically breaking in to someone's home.
(After all if you did that you probably can bug Alice's hardware
Alice probably also needs to make sure someone isn't spoofing her
replies by accessing her IMAP box and replying for her (using a key
known to the attacker but presumably not to Alice) and then deleting
the query, but the mere absence of periodic pings from the trusted
party may be enough to create suspicion, as might doing one's own
queries against the trusted parties and noticing that the key isn't
your own.
Presumably, of course, there should be a bunch of such servers out
there -- not so many that the traffic becomes overwhelming, but not so
few that it is particularly feasible to take the system off the
air. (One can speculate about distributed versions of such systems as
well -- that's not today's topic.)
So, this system has a bunch of advantages:
1) It doesn't require that someone associated with administrators of
the domain name you're using for email has to cooperate with deploying
your key distribution solution. Alice doesn't need her managers to agree
to let her use the system -- her organization doesn't even need to
know she's turned it on. Yet, it also doesn't allow just anyone to
claim to be alice at example.org -- to put in a key, you have to show you
can receive and reply to emails sent to the mailbox.
2) You know that, if anyone is impersonating Alice, they had to have
been planning it for a while. In general, this is probably "good
enough" for a very large number of purposes, and much better than a
perfect system that no one ever uses.
You can always trade a key hash with Alice personally, of course, and
if you do, perhaps she sets her software to personally alert you to
key refresh events and such (which we'll gloss over.) However, you
don't *have* to do it that way -- the system makes it possible to get
a reasonable amount of de facto trust without needing you to make many
decisions that ordinary people have trouble making, too. None of this
"I know this is Charlie's real key, but do I think Charlie is
trustworthy to sign Alice's key, or would he have been sloppy"
business that PGP imposes.
(We can gloss over details like a protocol for Alice to update her key
at intervals, or to make repeated claims that she was stupid and lost
her key and needed to generate a new one, or what have you. I think
they're solvable, and I don't want to clog up the gist of the idea
with them.)
3) The system can be extremely lightweight to implement.
Disadvantages are obvious. It isn't "perfect" in that mostly, it is
just depending on temporal continuity and widely witnessed information
to discourage forgery. On the other hand, that's a damn sight better
than a universal key management system that doesn't exist.
A few more notes:
First, I said nothing about "certificates". I've contended for a very
long time that I'm not sure what the function of the things really
is. What I want in the real world is the sort of attestation of long
term use that got discussed above. This system could use X.509 certs
as a pure data format, of course, or PGP keys, or raw integers in the
SSH style. Who cares.
Second, I've said nothing really about what such keys could be used
for. I'm thinking along the lines of next generation secure IM and
Email systems, but really, such things could be used for anything. If
people particularly insist on having separate keys for different
purposes, they'll need to arrange to store some sort of label along
with each of several keys in the key servers, of course, and they'll
need to arrange to periodically sign round trips for all those
keys. Personally, I think this is probably more trouble than it is
worth, but I could be persuaded.
Third, presumably one wants a means to query such databases that
doesn't allow traffic analysis. Mix networks including Tor are
probably the answer on that. Without such a mechanism, listening in on
the query traffic becomes a very good way to trace out social

@_date: 2013-08-25 17:41:30
@_author: Perry E. Metzger 
@_subject: [Cryptography] "Hey! You! Get off of the cloud!" 
[Second in a series of several posts about what is needed to make all
Internet messaging go encrypted. Again, if the contents of this post
sound unoriginal, that's because it isn't original thinking. It does
strike me as part of a larger puzzle, however, and some people may not
be familiar with all the arguments.]
I have a lot of friends who work in offices where the sysadmins are,
somewhat reasonably, hostile to the idea of their users installing or
configuring applications on their company machines.
Users in such offices have gotten quite used to using their browsers
to access web mail and chat systems -- de facto GMail and GTalk -- as
well as things like facebook messaging etc. This, and one's smart
phone, is many people's interface to the world outside work. Companies
still let you do https: to Google even if they won't let you install a
chat client locally, so that's what everyone does. (Well, lots of
people do http: but never mind that).
In any new world where everyone's messages are end to end secure and
probably transiting mix networks to prevent traffic analysis, such
users are going to have to be accommodated.
That means that their end-to-end encryption endpoint is going to have
to be on the web server they're talking to. Keys are going to have to
be on that machine, because you're not going to be able to install
software to use them on your work machine, and even if you could do
everything in javascript, you probably have relatively limited trust
for the local box and certainly not enough to leave long lived high
entropy keys on it.
Now, it is relatively easy for such a user to check that the cert for
their web mail provider doesn't come from a Bluecoat box -- no one
does, but it is kind of feasible. It is relatively difficult for
someone to bug your local machine -- hardly impossible, but not
something that is supposed to happen without the local system
administrator doing something to your machine or a remote bad guy
using malware.
On the other hand, a company that's hosting your email and chats
almost certainly will hand over encryption keys you store with them if
the government forces them to, and it is absolutely impossible to know
if this has happened. You just have to assume it has in your threat
It strikes me that the only real solution to handle this for people to
replace their "router" (really NAT) boxes on their cable modems with
tiny cheap servers that host their email and chats and such. Luckily,
the cost of such things has gotten very low -- a Raspberry Pi class
machine with a USB thumb drive larger than a GMail quota costs less
than a carton of cigarettes or the cheapest monthly Cable TV bill, and
such devices will only get cheaper and cheaper in the near term. It is
also feasible to make such machines insanely reliable, especially if
there's no mechanical disk involved.
(I'm of course not the first person by far to make this observation --
the FreedomBox people, among others, have been saying it for several
years. The idea is far from original.)
Sure, a bad guy can of course break into your apartment, but that's a
lot more expensive than simply getting Google or Facebook to hand over
all your communications, and hard to do on a "vacuum it all" basis.
With appropriate software and a friendly UI, one's Email, IM, remote
file storage and similar needs could be easily managed on such a
device with no greater difficulty than one faces in using GMail,
GTalk, Dropbox etc. That's "just" a question of keeping the user
interface easy.
Note that, however, this is not merely a requirement and stumbling
block -- it is also an opportunity. If everyone has such a box at
home, they've got a server, and the kinds of protocols they can
participate in to enhance their own security can be a lot more
Some additional notes:
a) Certainly, the security of a home server device is no greater than
that of the underlying software -- mass surveillance through malware
is possible. However, I presume that even there, doing so _en masse_
is dangerous to an attacker, since it leaves lots of traces. Also,
just as attackers have been improving their game, there are methods
that defenders can employ to improve security on such devices with
time -- malware is not a foregone conclusion forever, and is in some
sense a higher quality problem.
b) I'm aware that many ISPs prohibit the use of "servers" on their
home customer's networks, but loads of people ignore this. They also
used to prohibit (de facto) sharing connections with lots of machines,
and the arrival of commercial NAT boxes named "routers" made that
policy fade away as though by magic. I think they mostly don't want to
have to re-engineer their networks overnight, but in practice I doubt
a device hosting your email and some baby pictures is going to alter
traffic patterns enough to cause that anyway.
c) Even if people are happy using their smart phone to read their home
mail instead of their desktop at work, and could be persuaded to run
special software on their phone to do so, it would be of benefit for
them to have their own server, on their own physical premises,
requiring an actual physical entry into their premises to interfere
with their security.
d) It is certainly the work of a large and sophisticated staff to keep
a service like Dropbox or GTalk up and running, but for the most part,
there's not much need for maintenance when there's only a single user
or a handful, and what is needed can be automated. Encrypted backups
are easily traded with friends given the right UI -- it could be as
simple as entering in the friend's email address and then later
clicking a box in the web interface for "accept", especially if easy
key management is around. (I'm aware that the spam problem now
requires a huge staff to deal with, but there are potential solutions
there as well -- for example, one could just not do SMTP based email
at home. More on that in another message at some point.)

@_date: 2013-08-25 17:48:54
@_author: Perry E. Metzger 
@_subject: [Cryptography] PRISM PROOF Email 
Quite agreed. I have a long message in draft that I'll hopefully be
sending out later today on this topic.
That said, as I shall propose, it is not necessary to get rid of all
our email infrastructure. In particular, RFC-2822 remains an entirely
viable thing, and I think IMAP based clients can continue to be used,
with at most small changes.
Mix networks are not onion routing, though. If you're pure peer to
peer, traffic analysis is possible. Real mix networks are now quite
feasible, however, and unlike the Tor model where one is trying to
make real time TCP connections secure, there is no need to be "real
time" for IM and Email -- a delay of a couple of seconds is just
I see this as a reasonable observation.
As I said, I'll be explaining the rest of my proposal (of which I've
put up the first two parts, which are reasonably independent) later.

@_date: 2013-08-25 18:28:11
@_author: Perry E. Metzger 
@_subject: [Cryptography] Email and IM are ideal candidates for mix networks 
[Third in an ongoing series. Disclaimer yet again: I make few claims
of the contents here being specifically original to me. Mix networks
and the like have been discussed forever, and I'm sure others have
been having similar thoughts to this of late.]
The aim of the Tor network (which, it should be noted, is an onion
network and not a mix network in the original sense) is to provide
people with reasonably responsive end to end untraceable TCP
connections. This is a big strength when dealing with going to
arbitrary existing web sites and accessing existing services.
It is also a bit of a weakness, in that it imposes fairly strict
latency limits on what people will (de facto) put up with, and it
means that the effective limit on the system is exit node
availability. Exit node operators need a strong stomach.
However, we can note that the requirements for instant messaging and
electronic mail are somewhat distinct. Latency can't be infinite, but
several seconds is totally acceptable even for IM, and longer
(sometimes much longer) is often just fine for email.
End to end virtual streams are not necessary, either, and there is no
reason that "real" mix networks, complete with slicing of traffic to
uniform lengths, variable delays, cover traffic, far more hops than
Tor can afford, etc., are all quite feasible. Compared to video
traffic, IM and Email are quite trivial loads for the network -- this
also makes longer mixing paths and cover traffic quite feasible even
where they might not have been in the days when the Cypherpunks list
was young.
There is also no need per se for "exit" nodes. All participants in a
system can be "internal" nodes, since the system isn't being used for
surfing arbitrary web sites etc. Thus, the "rare exit node" problem
is not an issue.
So, imagine that we have the situation described by part 1 (some
universal system for mapping name at domain type identifiers into keys
with reasonable trust) and part 2 (most users having some sort of
long lived $40 device attached to their home network to act as a
"home server".)
All the server nodes we postulated in part 2 could easily participate
in a mix network for exchanging instant messages and RFC-2822 style
bodies. We will presume some end to end encapsulating encryption for
these messages, and the use of standard mix network techniques for
moving the (often sliced up) bodies of these objects around the
network. The endpoints for communications are typically people's home
servers themselves (see part 2), accessed through some sort of clients
(see below).
Spam might be a terrible, terrible problem in such a network since it
could not easily be traced to a sender and thus not easily blocked,
but there's an obvious solution to that. I've been using Jabber,
Facebook and other services where all or essentially all
communications require a bi-directional decision to enable messages
for years now, and there is virtually no spam in such systems because
of it. So, require such bi-directional "friending" within our
postulated new messaging network -- authentication is handled by the
public keys of course. (If you want to contact someone you haven't
talked to before, you'll need an introduction or to use SMTP email,
which you probably need to keep around to handle your keys as
described in part 1 anyway.)
We probably don't want any sort of central service running this
network that could be easily disrupted, so identifier to IP address
information should probably be stored in some big honking DHT, signed
in the ID's key. Access to the DHT probably should happen in some
privacy preserving way, possibly through the mix network itself or a
PIR protocol.
It would be unpleasant, and probably the kiss of death to deployment,
if everyone had to abandon Mail.app and iMessage and Pidgin and
Outlook and all the other user interfaces of the world in order to use
this system. Do we need to re-write all the world's user interfaces to
handle this?
There's no real reason that your home server can't present you with a
SSL'ed web and SSL'ed IMAP interface to your RFC-2822 messages. You
run the box, and it has your keys anyway, so you can likely trust it.
Similarly, you can do a Web interface for instant messages, or, if
you have an existing Jabber client, you can run the Jabber client
protocol over SSL to your home server.
Additional notes:
There are probably lots of interesting denial of service modalities
available in such a network. Figuring out very clever ways to stop
them is probably a priority. Note that distinguishing cover traffic
from denial of service may get quite interesting indeed.
Similar techniques may be useful for voice traffic, but that has
"interesting" latency requirements, and they're hard to fulfill with a
mix network that might take arbitrary time. There's been some
interesting work by a number of people (including one of my doctoral
brothers) on this topic. It probably would require a bunch of
experimentation to get it right. On the other hand, anything might be
better than what we have now for voice traffic, which is essentially
zero privacy from the operators of most of the services.

@_date: 2013-08-25 19:26:11
@_author: Perry E. Metzger 
@_subject: [Cryptography] Email and IM are ideal candidates for mix 
On Sun, 25 Aug 2013 16:04:59 -0700 "Christian Huitema"
I do not disagree, and given a home server, supporting whatever
protocols are popular is merely a matter of software. One reason I
split that proposal (more to come!) into multiple messages was
because I think the issues are somewhat distinct, and home servers
would be of use regardless. That said, I personally don't need much of a "network effect" to make
things like secure IM useful to me. I exchange instant messages all
day long, but only with about a dozen people for the most part.
I don't need the whole world to switch to a new IM system for me to be
much happier, just that dozen people.
My email network is somewhat wider, but even there, I'd get
incremental benefit from a new protocol. The trick is to make it easy
to do the old and the new at the same time. Most IMAP and Jabber
clients will happily handle multiple "accounts", however, so I don't
even have to choose if the client access protocol remains the same.
It might not if the total traffic was quite low (even if my IM
traffic in bytes or packets was 10x larger because of a mix network
participation, it would still be tiny compared to even a couple of
phone calls a day). Still, I tend to agree that home nodes make
better mix participants.

@_date: 2013-08-25 19:35:08
@_author: Perry E. Metzger 
@_subject: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
My knowledge of the field is pretty spotty in general as I've never
paid much attention up until now -- mostly I know about how people
have built DHTs in non-hostile environments. I'm close enough to
starting from scratch that I don't know yet what I don't know.

@_date: 2013-08-25 19:52:04
@_author: Perry E. Metzger 
@_subject: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
On Sun, 25 Aug 2013 16:42:57 -0700 "Christian Huitema"
That is not my worry. Signing the data posted to the DHT can prevent
spoofing, querying it over a mix network or using a PIR protocol can
prevent eavesdropping. I'm more worried about various sorts of denial
of service attacks, or service being shut down by inadvertent

@_date: 2013-08-26 09:26:08
@_author: Perry E. Metzger 
@_subject: [Cryptography] Traffic Analysis (was Re: PRISM PROOF Email) 
On Sun, 25 Aug 2013 23:40:35 -0400 Phillip Hallam-Baker
I'm unaware of anyone who has seriously proposed steganography for
that purpose -- I'm not even sure it would have the desired effect.
Recall that the problem in blocking traffic analysis is to conceal
that two endpoints are communicating.
Mix networks are, however, a well technique. Onion networks,
which are related, are widely deployed right now in the form of Tor,
and work well. I see little reason to believe mix networks would not
also work well for instant messages and email (see my other thread,
begun yesterday.)
I'm not particularly interested in standards work per se. If
something becomes successful, that is probably the time to consider
standardization if warranted.

@_date: 2013-08-26 10:02:54
@_author: Perry E. Metzger 
@_subject: [Cryptography] Formal Verification (was Re: Email and IM are ideal 
On Sun, 25 Aug 2013 23:32:32 -0400 Jerry Leichter I'd like to point out that this is no longer a pipe dream. The formal
verification of seL4, CompCert and other substantial pieces of code in
recent years shows the technology has improved a lot. Quark (the web
browser verified by the use of a "shim") has shown one can get
enormous leverage by formally verifying only tiny fractions of an
overall system comprising millions of lines of code, which is an
especially interesting technique in the context of existing large code
Formal verification is not a panacea. One has to know what to verify,
for example, and if you verify the wrong properties, you've gained
little. However, unlike current methods, if you discover you have
failed to verify a needed property, adding a theorem to your
development fixes that hole _completely_ and _forever_.
(Yes, you also need a verified toolchain, but given things like
CompCert, that is now doable.)
I'm something of a recent arrival to the world that developed the most
widely used tools for formal verification (like Coq), and so I'm in a
better position than most to explain how to learn about them.
I would be happy to produce an extended post on how to learn about
what is out there for people who are interested.
Warning: although in the long term there is no reason the tools cannot
be made very user friendly and easy to use, right now that is not the
case. This is not inherently so, it is just a feature of the
development history of the tools. Error messages tend to be pretty
poor, as is documentation, and the learning curve is steep. However,
in the long run, I'll state very directly I think the recent advances
in the state of the art in proof assistants are the most significant
new development in software quality in decades. The user
unfriendliness could be fixed by a new generation of users and
developers who started "further away from the problem".

@_date: 2013-08-26 10:14:12
@_author: Perry E. Metzger 
@_subject: [Cryptography] Email and IM are ideal candidates for mix 
On Mon, 26 Aug 2013 06:47:49 +0100 Richard Clayton
This is slightly off topic, but...
As it happens, I run my own email system (and run email for a few
other people at the same time.) My email address is also very very
widely published, so I'm on virtually every spam list in existence.
Thus, I'm reasonably qualified to speak on this.
Things work pretty well, and I spend essentially no time on
required maintenance.
Malware is not a problem. Viruses by email haven't been
prevalent for a while anyway, but because I block all windows
executable formats in attachments at the SMTP server, back when they
were common, none of that traffic got through. 100% coverage.
For spam, I use a couple of reliable RBLs, a few simple block rules,
and spamassassin for postprocessing. I get almost everything. About
ten spams a day get through to me, but on the other hand, I get
hundreds of legitimate messages on an average day and my address is
_very_ widely published.
I think that a zero maintenance box that handles this is probably
doable. One could also set up a peer to peer blacklisting/spam
reporting and detection system that would reduce the problem further
without individual work.
All that said, there is a good reason that I proposed that in the
long run, whitelist only systems like Jabber and Facebook messaging
are a better model.

@_date: 2013-08-26 12:09:55
@_author: Perry E. Metzger 
@_subject: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
On Sun, 25 Aug 2013 18:04:13 -0700 "Christian Huitema"
Though it appears that Tor uses them for its hidden service
directory. How does it do that robustly (or does it do it robustly)?
How do other users of DHTs handle attacks in practice (or is it just
that no one has tried attacking them enough?)
My back of the envelope says that there's little enough data needed
in the distributed data store I want that 1000x replication would not
be a serious problem. I presume that is not sufficient to make Sybil
attacks moot, given the size of modern botnets?

@_date: 2013-08-26 13:07:31
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: What is top posting, 
A3: Please.
Q3: Should I avoid top posting on this mailing list?
A2: Because, by reversing the order of a conversation, it leaves the
    reader without much context, and makes them read a message in an
    unnatural order.
Q2: Why is top posting irritating?
A1: It is the practice of putting your reply to a message before the
    quoted message, instead of after the (trimmed) message.
Q1: What is top posting?
[Yes, this is a re-run, but it needed saying. Also, please trim as
much as possible from messages you are quoting in replies, keeping
only the sections needed to maintain context for the reader.]

@_date: 2013-08-26 14:44:32
@_author: Perry E. Metzger 
@_subject: [Cryptography] Email and IM are ideal candidates for mix 
On Mon, 26 Aug 2013 10:40:17 -0700 Ray Dillinger One can use a commercial PC if one wants to install on one's own, or
any one of many manufacturers of small boxes. It is certainly the case
that the hardware layer can be attacked, all is lost. On the other
hand, if we presume supply chain attacks, all is lost anyway -- once
you control the computer, the protocols it is running don't matter.
Even keyboards can be suborned -- see Gaurav Shah's work on that, for
I would prefer not to try to solve that problem right now -- it is
too broad and too general. If others can solve it, that's of course a
great thing. :)

@_date: 2013-08-26 17:32:38
@_author: Perry E. Metzger 
@_subject: [Cryptography] Is Traffic Analysis the problem (was Re: Good 
Probably. If one's threat model is mass dragnet surveillance, traffic
analysis is far too useful a way for the enemy to figure out who to
subject to detailed analysis. The fact that quite so much traffic
analysis data is being collected and saved right now should be a
warning -- people who have huge budgets seem to think that it is an
interesting way to snoop.
Imagine you're the dictator of a country, and you want to figure out
who all your political enemies are so you can throw them in camps.
Simply producing the social network graph connecting up a few known
activists to their tightest cluster of common contacts is going to
give you loads of juicy information on who to spy on in detail and
likely who to detain. Indeed, the traffic analysis information is
probably the best way to figure out where to look for the needles in
the haystack.
It doesn't have to be either-or. :)
There are a lot of people in the community. Working on many different
approaches is probably for the best. It is hard to tell, a priori,
what will happen to take off.

@_date: 2013-08-26 17:43:08
@_author: Perry E. Metzger 
@_subject: [Cryptography] Using Raspberry Pis 
You can of course use a USB ethernet with them, but to me, they're
more a proof of what you can do with a very small bill of materials.
If you're designing your own, adding another ethernet (and getting
rid of unneeded things like the video adapter) is easy.
Custom built hardware will probably be the smartest way to go for an
entrepreneur trying to sell these in bulk to people as home gateways
anyway -- you want the nice injection molded case, blinkylights and
package as well. :)
Not sure that's really true for normal home networks. The current
average home NAT box is, in fact, a CPU in this class running Linux,
so we have proof of concept of them pushing packets fast enough
running in millions of homes. The processors in question are also
quite cheap, and only getting cheaper and more powerful -- multicore
will be universal before long.
Not an unreasonable goal -- particular details of what software is
running depend on what one's final application mix is.
Modern Linux systems have pretty good MAC and similar security
hardening available. They're a pain in the neck to configure, but if
you're handing people firmware, that only has to be done once. It
isn't perfect but it is better than what almost anyone has at home
now or what they rely on elsewhere.
(I would prefer to see hybrid capability systems in such
applications, like Capsicum, though I don't think any such have been
ported to Linux and that's a popular platform for such work.)
In the long term, of course, I'd like to see the work in seL4
extended to open source systems, but that's a very long term goal.

@_date: 2013-08-26 20:17:19
@_author: Perry E. Metzger 
@_subject: [Cryptography] Traffic Analysis (was Re: PRISM PROOF Email) 
On Mon, 26 Aug 2013 17:39:16 -0400 The Doctor I think tolerance for delays on the web is actually much lower than
that -- even a full second probably drives many users away. That's
why Tor has a much harder problem.
In Email, however, no one really knows their latency -- it is rare
that someone actually is aware that a message has just been sent. I
routinely have SMSes take seconds to go through and yet I use
(Arguably one could let people tune the number of hops they pick,
trading latency for security, but experience says that way lies
horror. "There should be one mode, and it should be secure.")

@_date: 2013-08-26 20:30:28
@_author: Perry E. Metzger 
@_subject: [Cryptography] Using Raspberry Pis 
I'm not going to disagree as such (I have no idea what the wholesale
cost of these machines is but I assume it is fine, or if it isn't that
someone else sells one that is cheap enough.)
I think that we can stipulate that quite inexpensive machines are
possible, and concentrate on discussing what they might run (which is
a much wider discussion -- see the last couple of days of

@_date: 2013-08-27 21:41:59
@_author: Perry E. Metzger 
@_subject: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
On Tue, 27 Aug 2013 21:13:59 -0400 Jerry Leichter You've forgotten other reasons. One might want to avoid a single
point of failure. One might also want to avoid having any central
organization responsible for running a database so that it cannot be
shut down by an adversary without shutting down thousands or millions
of nodes.
That is untrue.
Say that you want to distribute a database table consisting of human
readable IDs, cryptographic keys and network endpoints for some
reason. Say you want it to scale to hundreds of millions of users. A
quick back of the envelope shows that no home user's little ARM based
gateway machine is going to want to handle storing the entire database
or handling the entire update traffic volume -- the latter alone
might swamp someone even with quite reasonable connectivity.
I don't think so. Lets say you have a few hundred bytes per entry and
a billion users. That's hundreds of gigabytes, far more than you can
store on a thumb drive and an appreciable fraction even of today's
hard drives. Furthermore, say that 1% of the entries update per day

@_date: 2013-08-27 21:45:05
@_author: Perry E. Metzger 
@_subject: [Cryptography] Email and IM are ideal candidates for mix 
On the other hand, tech.support at sillycompany could just accept all
contact requests, at least temporarily.

@_date: 2013-08-27 21:48:35
@_author: Perry E. Metzger 
@_subject: [Cryptography] Email and IM are ideal candidates for	mix 
<521CE337.6030706
On Tue, 27 Aug 2013 22:04:22 +0100 "Wendy M. Grossman"
Of course, as a reporter, you are probably getting email addresses of
people to talk to via referral, and that could be used to get past the
barrier. The problem of people spontaneously contacting a published
address is harder.
I don't claim to have all the answers, but experimentation will
probably tell us a lot more than simply thinking in the abstract.

@_date: 2013-08-27 22:18:18
@_author: Perry E. Metzger 
@_subject: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
On Tue, 27 Aug 2013 19:57:30 -0600 Peter Saint-Andre
My problem with the use of DNSSEC for such things is the barrier to
entry. It requires that a systems administrator for the domain your
email address is in cooperate with you. This has even slowed DNSSEC
deployment itself.
It is, of course, clearly the "correct" way to do such things, but
trying to do things architecturally correctly sometimes results in
solutions that don't deploy.
I prefer solutions that require little or no buy in from anyone other
than yourself. One reason SSH deployed so quickly was it needed no
infrastructure -- if you controlled a single server, you could log in
to it with SSH and no one needed to give you permission.
This is a guiding principle in the architectures I'm now considering.

@_date: 2013-08-27 22:35:47
@_author: Perry E. Metzger 
@_subject: [Cryptography] Email and IM are ideal candidates for	mix 
<521CE337.6030706
On Wed, 28 Aug 2013 03:04:25 +0100 "Wendy M. Grossman"
Again, I don't have excellent answers at the moment.
I think SMTP is likely to survive for quite some time, and that is
probably the solution to the out-of-the-blue contact problem at the
moment, but it does not solve the out-of-the-blue traffic analysis
free contact problem.
(Rendering SMTP immune to traffic analysis results in infinite spam

@_date: 2013-08-28 08:34:58
@_author: Perry E. Metzger 
@_subject: [Cryptography] Why not the DNS? (was Re: Implementations, 
On Tue, 27 Aug 2013 23:39:51 -0400 Jerry Leichter As I said elsewhere: as a practical matter, almost no one using email
is a DNS administrator. This therefore cannot possibly deploy in
finite time for the average user. If your mailbox is in a domain name
controlled by someone else, you may wait effectively forever for
permission. Indeed, DNSSEC itself has waited forever as a result of
Furthermore, this is unacceptable because the trust model is
unacceptable. If you are a user of gmail, for example, it implies
that Google is in the trust loop for telling the world security
critical information, like, for example, your key. Sovereign
threats can order Google to insert different keys at will.
As I've said elsewhere: the DNS is a very architecturally tempting
idea for all of this. I fully understand why people would want to do
it that way. It is not, however, practical if one wants to deploy in
months and not decades, and it makes trust entirely hierarchical.

@_date: 2013-08-28 08:43:13
@_author: Perry E. Metzger 
@_subject: [Cryptography] human readable IDs, 
networks)
 <521CE337.6030706
First of all, I think systems that make people associate arbitrary
long strings with someone's email address aren't really acceptable.
I'll repeat that my model is "give someone your email address on a
napkin in a bar". I do things like this often enough right now.
On Wed, 28 Aug 2013 06:41:27 -0400 Jerry Leichter Because people make mistakes and reveal security critical information
to the world at intervals. Because computers are sometimes
compromised. A system that does not permit you to recover from rare
events is not going to deploy very well.
I think that to begin with, though, a system that requires people to
somehow associate arbitrary strings with their friends won't work
Anyway, I proposed a system to handle id to key mappings with
reasonable trust in the first of my three messages on my proposed new
model -- it also happens to handle revocation reasonably well
(though imperfectly).

@_date: 2013-08-28 08:52:47
@_author: Perry E. Metzger 
@_subject: [Cryptography] Why human-readable IDs (was Re: Email and IM are 
<521CE337.6030706
On Tue, 27 Aug 2013 23:52:23 -0400 Jerry Leichter Just as an FYI, this describes exactly zero of the times that I've
gotten people's email or jabber addresses in recent years. Very
typically people have written them down for me, told them to me over
the phone, or the equivalent. I've had to read mine over the phone a
fair bit, too.
I wouldn't know how to trust publication online in the first
"Perry Metzger's email is "
"How do I know that's true?"
"Because it is encrypted in "
"What if that's a lie? I've never heard Perry utter "
"What, you don't trust me? No dishonest person has a web server!"
If someone tells me they're foo at example.com, and I have a trustworthy
way of mapping foo at example.com into a long lived key (see my first
message in this sequence of three that triggered this discussion),
life is a lot better. I think this alone is a lot of why X.500 died
so fast compared to SMTP -- the addresses were simply untenable, and
they were at least in theory human readable.
Anyway, I've already started implementing my proposed solution to
that part of the problem. There is still a need for a distributed
database to handle the lookup load, though, and one that is not the

@_date: 2013-08-28 11:52:38
@_author: Perry E. Metzger 
@_subject: [Cryptography] Why human-readable IDs (was Re: Email and IM are 
<521CE337.6030706
On Wed, 28 Aug 2013 10:24:43 -0400 Jerry Leichter But I don't. As I said, I typically get a friend or collaborator's
email address from them or from someone else I know. I don't get them
from paper publications, or QR codes. Often as not they are literally
written on cocktail napkins at conference receptions.
If you meet me and I say it to you, I'm probably reasonably correct
about it. If you ask a mutual friend what it is (possibly by email),
they're probably reasonably correct.
That's not true, actually. I know because I make a habit of not using
an address book in my mail program. In any case, "easy to remember"
isn't the issue, "easy to scribble down accurately" is.
So, I just did a check. I have a file with all the addresses I care
about in it (I manually cut and paste them into email when I want
to.) It has 625 addresses in it. Of those, 47 have digits in them. I
note that the vast majority of those are addresses of people at
Columbia University, which has a particularly bad naming system but
where I have a lot of correspondents. Of the rest, the majority are
things like "matt at example.com", or "joe.example at gmail.com" -- easy to
write on a cocktail napkin.
I note exactly none of the addresses contain 10 digits of base 64.
Even the numeric ones are things like "jrn26" for someone with those
initials, which is pretty easy to scribble down.
For me, it was Monday, over the phone.
Anyway, we both have our opinions here, I'm sure we're not going to
come to a single agreement. I'm implementing something based on my
hunches, I invite others to do the same.
Let a thousand flowers bloom...

@_date: 2013-08-29 13:30:35
@_author: Perry E. Metzger 
@_subject: [Cryptography] Keeping backups (was Re: Separating concerns 
<521CE337.6030706
So, as has been discussed, I envision people having small cheap
machines at home that act as their "cloud", and the system prompting
them to pick a friend to share encrypted backups with.
Inevitably this means that said backups are going to either be
protected by a fairly weak password or that the user is going to have
to print the key out and put it in their desk drawer and risk having
it lost or stolen or destroyed in a fire.
I think I can live with either problem. Right now, most people
have very little protection at all. I think making the perfect the
enemy of the good is a mistake. If doing bad things to me requires
breaking in to my individual home, that's fine. If it is merely much
less likely that I lose my data rather than certain that I have no
backup at all, that's fine.
BTW, automation *does* do a good job of making such things invisible.
I haven't lost any real data since I started using Time Machine from
Apple, and I have non-technical friends who use it and are totally
happy with the results. I wish there was an automated thing in Time
Machine to let me trade backups with an offsite friend as well.

@_date: 2013-08-29 13:33:18
@_author: Perry E. Metzger 
@_subject: [Cryptography] Why human-readable IDs (was Re: Email and IM are 
<521CE337.6030706
On Thu, 29 Aug 2013 01:18:59 +1000 (EST) Dave Horsfall
I can think of no circumstances where I would voluntarily use LDAP as
the solution to any problem of any sort.
In any case, you will note that LDAP does not actually solve the
problem statement as I gave it: that is to say, users must be able to
join the system without the permission or assistance of systems

@_date: 2013-08-29 13:43:16
@_author: Perry E. Metzger 
@_subject: [Cryptography] Why not the DNS? (was Re: Implementations, 
On Wed, 28 Aug 2013 10:43:24 -0400 Jerry Leichter I'm unsure how to use a DNS-like model when there is no real linkage
between hierarchy in the names used and the storage location of
particular mappings. In particular, if I have names like
foo at example.com, and I want just anyone to be able to enroll at any
time without administrator input, and I don't want state
authorities to be able to shut down or alter the contents of the
system, I don't see how to accomplish all my goals with something
That said, if you have a concrete proposal, I would of course find it
interesting to hear about.

@_date: 2013-08-29 16:46:30
@_author: Perry E. Metzger 
@_subject: [Cryptography] The Case for Formal Verification 
Taking a break from our discussion of new privacy enhancing protocols,
I thought I'd share something I've been mumbling about in various
private groups for a while. This is almost 100% on the security side
of things, and almost 0% on the cryptography side of things. It is
long, but I promise that I think it is interesting to people doing
security work.
When I was a student the first time, in the early to mid 1980s, formal
verification was clearly a dead end that would never get anywhere. A
boss of mine once asserted (circa 1988) that there would never be a
verified program that did anything terribly interesting, and at time
he seemed right.
Today, there is a formally verified microkernel called seL4, a
formally verified C compiler called CompCert, a formally verified
experimental web browser called Quark, and lots of other stuff, much
of which I doubtless don't even know about.
_Things have changed_.
Much of what has changed is proof technology, and it is a
technology. The tools for doing formal verification are now, for the
first time, just barely usable for real work on interesting programs,
and getting better all the time. Over the last twenty five years, we
figured out a lot of stuff people didn't know before about how to
write verification tools and how to verify programs, and the results
have been impressive.
There are usually several arguments against formal verification:
1) We don't know what to specify, so what help does proving a buggy
specification do us?
2) Who would bother writing a proof vastly larger than their program?
3) You can't prove programs of interesting size anyway.
So, taking these in reverse order:
For 3 ("you can't prove anything big enough to be useful!"), the Quark
showed you don't need to prove a program of interesting size. You can
defend millions of lines of buggy code with a "software firewall" made
of formally verified code. Verify the right thousand lines of code
that the rest needs to use to talk to anything else, and you have very
strong security properties for the rest of the code. seL4 and CompCert
are clearly also quite useful programs.
For 2 ("Who would bother with all that work?"), we have libraries in
daily use like sqlite:
where the system has a fairly small amount of production code and
literally 1000 times more lines of test code than production code. If
you're willing to write ninety million lines of test to defend ninety
thousand lines of code, formal verification is totally doable.
Sure, it might not be worth it for throw away code or for your new
video game or conference room scheduler where failure isn't a big
deal, but it is *very* clear why you would want to do this for
foundational code of all sorts.
For 1 ("We'll never write a correct spec anyway, so what good is the
proof?"), I think we've been suffering from sour grapes. We didn't
have the ability to prove big things anyway, so why not tell ourselves
that there's nothing interesting and large we could prove that would
be worth proving?
CompCert is a fine counterexample, a formally verified C compiler:
It works by having a formal spec for C, and a formal spec for the
machine language output. The theorem they prove is that the
compilation process preserves observational equivalence between the
behavior of the C program and the output, which, given correct
notation, is a very small theorem to write down.
You might claim "so what, it is probably actually buggy as hell, the
spec probably isn't really correct anyway, etc." -- except when John
Regehr's group built tools to torture test C compilers, the only
compiler they did *not* find bugs in was CompCert. They found hundreds
of bugs each in every other compiler tested. (They actually found one,
but arguably it was a bug in a Linux include file, not in the
CompCert compiler.)
Similarly, one might claim "there is no way to formally specify a web
browser that won't be just as buggy as the web browser!", but Quark's
formal verification doesn't try to show that the entire Web browser is
correct, and doesn't need to -- it shows that some insecure behaviors
are simply impossible. *Those* are much simpler to describe.
Certainly there may be other properties that turn out to be important
that no one has considered yet. However, unlike testing, if people
discovered a hole in the set of theorems being proven -- some property
that was important but which had not been considered -- then that
could be added to what was proved, and _then the problem would be gone
forever_. Verification means you get actual incremental progress that
you can trust. Testing is much less powerful. (Furthermore, future
systems can learn from what you did and add the needed theorem to what
they prove about their own system.)
I don't think the technology is up to proving huge systems correct --
a fairly unambitious C compiler or a microkernel is the current limit

@_date: 2013-09-01 14:05:14
@_author: Perry E. Metzger 
@_subject: [Cryptography] NSA and cryptanalysis 
This seems by far the most probable conclusion. Note, for example,
Heninger et al's recent work on the Taiwanese national smartcards. A
discovery that some commonly used randomness sources are dramatically
less random than supposed could dramatically lower the work factor on
an otherwise brute force attack.
That said, we simply can't know, and I think excessive speculation on
the basis of no actual concrete information isn't that productive.

@_date: 2013-09-01 14:11:48
@_author: Perry E. Metzger 
@_subject: [Cryptography] NSA and cryptanalysis 
The fact that the USG likes using it, too.
That's also evidence for eliptic curve techniques btw.

@_date: 2013-09-01 18:06:20
@_author: Perry E. Metzger 
@_subject: [Cryptography] NSA and cryptanalysis 
On Sun, 1 Sep 2013 16:33:56 -0400 Jerry Leichter We know what they spec for use by the rest of the US government in
Suite B.
  AES with 128-bit keys provides adequate protection for classified
  information up to the SECRET level. Similarly, ECDH and ECDSA using
  the 256-bit prime modulus elliptic curve as specified in FIPS PUB
  186-3 and SHA-256 provide adequate protection for classified
  information up to the SECRET level. Until the conclusion of the
  transition period defined in CNSSP-15, DH, DSA and RSA can be used
  with a 2048-bit modulus to protect classified information up to the
  SECRET level.
  AES with 256-bit keys, Elliptic Curve Public Key Cryptography using
  the 384-bit prime modulus elliptic curve as specified in FIPS PUB
  186-3 and SHA-384 are required to protect classified information at
  the TOP SECRET level. Since some products approved to protect
  classified information up to the TOP SECRET level will only contain
  algorithms with these parameters, algorithm interoperability between
  various products can only be guaranteed by having these parameters as
  options.
We clearly cannot be absolutely sure of what they actually use, but
we know what they procure commercially. If you feel this is all a big
disinformation campaign, please feel free to give evidence for that. I
certainly won't exclude the possibility, but I find it unlikely.

@_date: 2013-09-02 13:19:50
@_author: Perry E. Metzger 
@_subject: [Cryptography] Thoughts about keys 
I don't understand why. The security requirement is that third
parties must *not* be able to predict the token, because then they
could sign the token without controlling the email address. The only
organization that can know the cookie is actually the organization
sending the cookie out. You appear to have inverted the security
But then *anyone* could broadcast the token because anyone could have
predicted it.
It is difficult to make the interchange of the token and the reply
itself widely witnessed -- the way around that is to have many
organizations doing the interchanges so that one would have to suborn
all of them.
That is part of the envisioned model. Currently I'm looking at how to
take advantage of the work already done on Certificate Transparency.

@_date: 2013-09-02 13:25:38
@_author: Perry E. Metzger 
@_subject: [Cryptography] NSA and cryptanalysis 
On Mon, 2 Sep 2013 00:06:21 -0400 Jerry Leichter That is a misunderstanding.
If you look at the way that the NSA specs these things, they try to
keep all portions of a system of equal security so none is the weak
point. A 2048 bit RSA key is factored vastly more easily than a 256
bit AES key is brute forced (that's just public knowledge -- try doing
the back of the envelope yourself) so that size key would be
insufficient. However, a sufficiently large RSA key to be "correctly
sized" for 256 bit AES is totally impractical for performance reasons,
So clearly the purpose of pushing ECC for this application is that
they want the public key algorithm and its key size to have comparable
security while both performing reasonably well.
Not at all, and the rationale is public and seen above.
I believe you're incorrectly claiming that we know much less than we
actually do here.

@_date: 2013-09-02 14:10:14
@_author: Perry E. Metzger 
@_subject: [Cryptography] Thoughts about keys 
I don't see what threat this averts. If the sending organization is
cheating, this does not stop them from pretending that they received
a signed cookie in a round trip. It just seems to add complexity. The
only interesting form of cheating I can think of is pretending a
round trip existed when it did not.
I don't see how that is an issue either, unless you are referring to
chosen plaintext attacks, but the encryption format had better
already defend against those.
Again, I don't understand the threat being defended against. Can you
articulate exactly what was possible before that is not possible in
the scheme you propose?

@_date: 2013-09-02 15:40:59
@_author: Perry E. Metzger 
@_subject: [Cryptography] NSA and cryptanalysis 
On Mon, 2 Sep 2013 15:09:31 -0400 Jerry Leichter Only as a legacy "you can do this for a while but please switch."
I'd say they're judging a balance between security and performance
while attempting not to leave particularly bad holes.
I believe that is indeed a factor here, and is probably part of why
the asymmetric key lengths aren't a bit longer. It is also possible
they've been selected based on knowledge that AES keys are slightly
weaker than we expect, but not radically so.
As an aside, I'm reminded of the fact that there were certificational
weaknesses in Skipjack that meant it was only more or less as
potentially secure as the number of bits available in they key
length. When this was pointed out to someone in the know, the mumble
back I remember was "in other words, they did the engineering
Anyway, as I've said, I'm paranoid, but I operate under the
assumption the counterparty is a reasonably rational actor that
understands the very limited duration of secrets.

@_date: 2013-09-02 15:55:45
@_author: Perry E. Metzger 
@_subject: [Cryptography] NSA and cryptanalysis 
On Mon, 2 Sep 2013 14:45:00 -0400 Phillip Hallam-Baker
But of course, sufficiently paranoid people might contend that
perhaps the Microsoft people who complained might not have been
briefed by the ones who cooperated.
The problem with all such exercises is that they involve too many
layers of recursive paranoia, but do not pay off with useful
information that tells me how to act going forward.
In the current case, the fact that they *could* potentially suborn
process inside a vendor is an interesting thing to consider when
doing design, and whether they *have* is less interesting to me.
Clearly, as things like bad vendor drivers updates have been sent out
using stolen keys in the past, and clearly vendors might simply make
mistakes in the future.
From there, I can consider whether the "someone signs bad
updates" security model component is productive to defend against or
not, and how one might defend against it. (In the current case, I'd
say only typed assembly language offers an interesting defense
against bad binaries that get executed in kernel mode, regardless of
why they are bad. Using typed assembly language effectively of
course requires that the code be written in a high level language
with strong typing to be preserved in the delivered machine code in
the first place.)
I leave speculation to pundits, and prefer to write code and design

@_date: 2013-09-02 17:35:43
@_author: Perry E. Metzger 
@_subject: [Cryptography] NSA and cryptanalysis 
On Mon, 2 Sep 2013 13:14:00 -0700 "Christian Huitema"
As would I. Not my wider point. My wider point is that the
speculation is not helpful, and one probably wants to think about how
to make things trustworthy even in the presence of bugs, adversaries
who look like bugs for most viewpoints, etc. Paranoid speculation is
useless, concrete discussion of threat models and how to address them
is useful. (Thus why I mentioned things like typed assembly language
as being a more productive topic than infinitely recursive paranoia.
One can speculate endlessly on who is collaborating with whom
without ever terminating, but robust threat models with technical
solutions are something you can actually do something about.)

@_date: 2013-09-02 18:55:44
@_author: Perry E. Metzger 
@_subject: [Cryptography] NSA and cryptanalysis 
On Mon, 2 Sep 2013 17:44:57 -0400 Jerry Leichter Yes, certainly, but the end effect was that an untrustworthy piece of
code was then executing on the victim's machine. That can be happen
by many means, however, both intentional and accidental -- trojan
horses, vendor mistakes, bugs, rogue employees at a vendor, a vendor's
credentials being stolen, cryptographic breaks like this, etc.
Now, I do indeed find it interesting and exotic that someone involved
knows how to create MD5 collisions by a different method than we know
of in the open literature, and that tickles my fancy as a
person who loves cryptography, and probably tells us something about
who wrote that particular exploit.
What it does not do, however, is tell me much about how to
make systems robust against the wide variety of reasons why
untrustworthy software might appear on a machine.
As a security person, it is this latter problem that is vital
to me, since doubtless that will show up again in the future. Even
ignoring malice, bugs often happen in device drivers and other code
running in security critical environments like kernels.
I will again mumble things like: "typed assembly language, proof
carrying code, microkernels, hardware assists, formal verification..."
in the hopes that the mumbling might set some minds thinking.

@_date: 2013-09-04 10:37:12
@_author: Perry E. Metzger 
@_subject: [Cryptography] Hashes into Ciphers (was Re: FIPS, 
As a pure aside...
Phil Karn described a construction for turning any hash function into
the core of a Feistel cipher in 1991. So far as I can tell, such
ciphers are actually quite secure, though impractically slow.
Pointers to his original sci.crypt posting would be appreciated, I
wasn't able to find it with a quick search.

@_date: 2013-09-04 10:49:33
@_author: Perry E. Metzger 
@_subject: [Cryptography] Hashes into Ciphers 
On Wed, 4 Sep 2013 10:37:12 -0400 "Perry E. Metzger"
Answering my own question
Note that Karn's construction need not use any particular hash
function -- he's more or less simply describing how to use a hash
function of any sort as the heart of a Feistel cipher.

@_date: 2013-09-04 13:25:37
@_author: Perry E. Metzger 
@_subject: [Cryptography] IPv6 and IPSEC 
On Wed, 4 Sep 2013 09:14:36 +0200 Lucky Green
I think this conversation has, at this point, gone well beyond the
scope of the list. There are a bunch of google people on the mailing
list, perhaps one or more of them might want to contact Lucky in
private and see if they can help him with his question.

@_date: 2013-09-05 15:45:21
@_author: Perry E. Metzger 
@_subject: [Cryptography] NY Times: "NSA Foils Much Internet Encryption" 
The National Security Agency is winning its long-running secret
   war on encryption, using supercomputers, technical trickery,
   court orders and behind-the-scenes persuasion to undermine the
   major tools protecting the privacy of everyday communications in
   the Internet age, according to newly disclosed documents.
   The agency has circumvented or cracked much of the encryption, or
   digital scrambling, that guards global commerce and banking
   systems, protects sensitive data like trade secrets and medical
   records, and automatically secures the e-mails, Web searches,
   Internet chats and phone calls of Americans and others around the
   world, the documents show.

@_date: 2013-09-05 15:48:03
@_author: Perry E. Metzger 
@_subject: [Cryptography] The Guardian: "US and UK spy agencies defeat privacy 
US and British intelligence agencies have successfully cracked
    much of the online encryption relied upon by hundreds of millions
    of people to protect the privacy of their personal data, online
    transactions and emails, according to top-secret documents
    revealed by former contractor Edward Snowden.
    The files show that the National Security Agency and its UK
    counterpart GCHQ have broadly compromised the guarantees that
    internet companies have given consumers to reassure them that
    their communications, online banking and medical records would be
    indecipherable to criminals or governments

@_date: 2013-09-05 15:58:04
@_author: Perry E. Metzger 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
I would like to open the floor to *informed speculation* about
Informed speculation means intelligent, technical ideas about what
has been done. It does not mean wild conspiracy theories and the
like. I will be instructing the moderators (yes, I have help these
days) to ruthlessly prune inappropriate material.
At the same time, I will repeat that reasonably informed
technical speculation is appropriate, as is any solid information

@_date: 2013-09-05 16:28:16
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: Please, please, please don't top post. 
I hate to ask this yet again, but:
Please, please, please don't top post.
Please, please, please edit down your replies.
If your mobile device, say, doesn't let you do otherwise, it can
probably wait half an hour until you get to a machine with a keyboard.

@_date: 2013-09-05 16:41:18
@_author: Perry E. Metzger 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
Here are a few guesses from me:
1) I would not be surprised if it turned out that some people working
for some vendors have made code and hardware changes at the NSA's
behest without the knowledge of their managers or their firm. If I
were running such a program, paying off a couple of key people here
and there would seem only rational, doubly so if the disclosure of
their involvement could be made into a crime by giving them a
clearance or some such.
2) I would not be surprised if some of the slow speed at which
improved/fixed hashes, algorithms, protocols, etc. have been adopted
might be because of pressure or people who had been paid off.
At the very least, anyone whining at a standards meeting from now on
that they don't want to implement a security fix because "it isn't
important to the user experience" or adds minuscule delays to an
initial connection or whatever should be viewed with enormous
suspicion. Whether I am correct or not, such behavior clearly serves
the interest of those who would do bad things.
3) I would not be surprised if random number generator problems in a
variety of equipment and software were not a very obvious target,
whether those problems were intentionally added or not.
4) Choices not to use things like Diffie-Hellman in TLS connections
on the basis that it damages user experience and the like should be
viewed with enormous suspicion.
5) Choices not to make add-ons available in things like chat clients
or mail programs that could be used for cryptography should be viewed
with suspicion.

@_date: 2013-09-05 16:47:25
@_author: Perry E. Metzger 
@_subject: [Cryptography] Bruce Schneier in The Guardian on BULLRUN etc. 
Quite worth reading. There is some speculation in there about various
weaknesses that may have been added as well.

@_date: 2013-09-05 16:53:15
@_author: Perry E. Metzger 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
Please say it aloud. (I personally don't recognize the standard
offhand, but my memory is poor that way.)
BTW, I will now openly speculate if the deeply undeployable key
management protocols for IPSec that originated at the NSA were an
accident. I had enough involvement not to feel overly strongly that
this is what happened, but it does lead one to wonder strongly.

@_date: 2013-09-05 16:57:51
@_author: Perry E. Metzger 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
On Thu, 5 Sep 2013 16:53:15 -0400 "Perry E. Metzger"
There is now some speculation in places like twitter that this refers
to Dual_EC_DRBG though I was not aware that was widely enough deployed
to make a huge difference here, and am not sure which international
group is being mentioned. I would be interested in confirmation.

@_date: 2013-09-05 18:06:09
@_author: Perry E. Metzger 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
On Thu, 05 Sep 2013 16:43:59 -0400 "Bernie Cosell"
The articles make it sound much more like implementation flaws that
have been intentionally placed in software and hardware, and a
select few bad protocols and standards. I'm not going to say that it
is impossible that they can break 3DES at this point, but it doesn't
sound like that's what is being discussed here.

@_date: 2013-09-05 19:09:47
@_author: Perry E. Metzger 
@_subject: [Cryptography] Is ECC suspicious? 
In this posting:
Bruce Schneier casts some doubt on the use of ECC
   5) Try to use public-domain encryption that has to be compatible
   with other implementations. For example, it's harder for the NSA to
   backdoor TLS than BitLocker, because any vendor's TLS has to be
   compatible with every other vendor's TLS, while BitLocker only has
   to be compatible with itself, giving the NSA a lot more freedom to
   make changes. And because BitLocker is proprietary, it's far less
   likely those changes will be discovered. Prefer symmetric
   cryptography over public-key cryptography. Prefer conventional
   discrete-log-based systems over elliptic-curve systems; the latter
   have constants that the NSA influences when they can.
Now, this certainly was a problem for the random number generator
standard, but is it an actual worry in other contexts? I tend not to
believe that but I'm curious about opinions.

@_date: 2013-09-05 19:35:37
@_author: Perry E. Metzger 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
On Thu, 5 Sep 2013 19:14:53 -0400 John Kelsey It did *seem* to match the particular part of the story about a
subverted standard that was complained about by Microsoft
researchers. I would not claim that it is the most important part of
the story.
Yes, and if they have a real hole there they're exploiting, that is
quite disturbing. If they're merely using a hodge-podge of techniques
to get keys, it is less worrying.
I'm starting to think that I'd probably rather type in the results of
a few dozen die rolls every month in to my critical servers and let
AES or something similar in counter mode do the rest.
A d20 has a bit more than 4 bits of entropy. I can get 256 bits with
64 die rolls, or, if I have eight dice, 16 rolls of the group. If I
mistype when entering the info, no harm is caused. The generator can
be easily tested for correct behavior if it is simply a block cipher.
I believe there was already discussion in the press on that latter
point, but I think it is less germane to our discussion here and
would prefer that we avoid speculating on things that are only of
human/gossip interest.

@_date: 2013-09-05 20:11:08
@_author: Perry E. Metzger 
@_subject: [Cryptography] tamper-evident crypto?    (was: BULLRUN) 
The point is that a deterministic generator operating off of a seed
can be validated -- you can assure yourself reasonably easily that
the thing is indeed AES in counter mode. A hardware generator can have
horrible flaws that are hard to detect without a lot of data from many
devices. (The recent break of the Taiwanese national ID card system
should be a lesson on that too.)
I will remind everyone that the key generation ceremony for the
Clipper devices used a deterministic generator for precisely this
reason even given that the keys were being escrowed. See Dorothy
Denning's old report on that for a reminder.

@_date: 2013-09-05 20:53:04
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: less Snowden, more Crypto 
On Thu, 5 Sep 2013 20:30:40 -0400 Jerry Leichter Admin hat on:
As interesting as the overall speculation might be in a human
interest sort of way, I'd prefer if we avoided it, unless it points
to interesting lessons for making the world more secure going
forward or to something similarly worthwhile.
Yes, this is irresistible gossip for many of us, but I don't know that
it is interesting beyond that, and our traffic levels are quite high
right now already.

@_date: 2013-09-05 21:02:00
@_author: Perry E. Metzger 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
I'm aware of the randomness issues for ECDSA, but what's the issue
with ECDH that you're thinking of?
Yes, and 24 hours ago I would have said that was because they
themselves depended on the use of commercial products with such
algorithms available (as in Suite B.) Now I'm less sure.
Yes, though it doesn't sound like Suite B is what the article
meant when discussing standards.
Many people out there seem to claim the opposite of course. The
current situation doesn't give us a definitive way to resolve such an
RSA certainly appears to require vastly longer keys for the same
level of assurance as ECC.

@_date: 2013-09-05 21:56:49
@_author: Perry E. Metzger 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
Maybe. Yesterday I would have consistently ascribed things to
bureaucracy instead of malice. Today, I'm less sure. At the very
least, the current revelations make such things less benevolent --
whether from malice or stupidity, we can no longer sit on security
fixes on the basis that "no one will exploit them" and "they're not
important to the user".

@_date: 2013-09-06 00:33:00
@_author: Perry E. Metzger 
@_subject: [Cryptography] Can you backdoor a symmetric cipher (was Re: Opening 
On Thu, 5 Sep 2013 23:24:54 -0400 Jerry Leichter It is probably very difficult, possibly impossible in practice, to
backdoor a symmetric cipher. For evidence, I direct you to this old
paper by Blaze, Feigenbaum and Leighton:

@_date: 2013-09-06 09:47:03
@_author: Perry E. Metzger 
@_subject: [Cryptography] Can you backdoor a symmetric cipher 
See the URL quoted above. That is the implication of their paper.

@_date: 2013-09-06 10:03:09
@_author: Perry E. Metzger 
@_subject: [Cryptography] Aside on random numbers (was Re: Opening Discussion: 
On Fri, 6 Sep 2013 01:04:31 -0400 John Kelsey No, clearly not, but it works fine for a key generation ceremony for
a valuable key or the like. It might also be fine in other limited
That said, I came up with a fine way to automate this in the shower,
which I'm documenting here in case it inspires someone.
Naively, one could take a picture of the dice and OCR it. However,
one doesn't actually need to OCR the dice -- simply hashing the
pixels from the image will have at least as much entropy if the
position of the dice is recognizable from the image. (You have to
assume your hash function is reasonable but the rest of your
infrastructure needs to assume that anyway in all likelihood.) So,
simply take pictures of each of N rolls of multiple dice and hash
them all together.
One could write an  app to do this, but of course the phone is
not exactly a secure platform to begin with...

@_date: 2013-09-06 10:25:17
@_author: Perry E. Metzger 
@_subject: [Cryptography] Sabotaged hardware (was Re: Opening Discussion: 
This is troubling. It implies that there are widely used crypto
accelerators in use at large organizations that intentionally harm
the security of users. Random number generator flaws would seem like
an obvious possibility here.
This is especially disturbing because other actors can now start
doing teardowns on a wide variety of such devices looking to find the
flaws so they can themselves attack the traffic in question.

@_date: 2013-09-06 10:36:07
@_author: Perry E. Metzger 
@_subject: [Cryptography] People should turn on PFS in TLS (was Re: Fwd: 
It occurred to me yesterday that this seems like something all major
service providers should be doing. I'm sure that some voices will say
additional delay harms user experience. Such voices should be
ruthlessly ignored.

@_date: 2013-09-06 13:05:59
@_author: Perry E. Metzger 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
On Fri, 6 Sep 2013 09:03:27 +0200 Kristian Gj?steen
I have re-read the NY Times article. It appears to only indicate that
this was *a* standard that was sabotaged, not that it was the only
one. In particular, the Times merely indicates that they can now
confirm that this particular standard was sabotaged, but presumably
it was far from the only target.

@_date: 2013-09-06 13:13:44
@_author: Perry E. Metzger 
@_subject: [Cryptography] People should turn on PFS in TLS 
As I've said earlier, I think that we no longer have the luxury of
speaking in terms of higher connection establishment latency or
similar considerations as a reason not to use PFS techniques. At the
very least, we should presume that people will pressure technologists
to overconsider such issues in an attempt to assure that stealing
keys is enough to be able to read TLS connections.
Certainly in a very wide variety of contexts, like XMPP, connections
are so long lived that there is never a performance excuse.
Google is also now (I believe) using PFS on their connections, and
they handle more traffic than anyone. A connection I just made to
 came out as, TLS 1.2, RC4_128, SHA1,
It would be good to see them abandon RC4 of course, and soon.

@_date: 2013-09-06 13:24:21
@_author: Perry E. Metzger 
@_subject: [Cryptography] People should turn on PFS in TLS 
I thought AES was okay for TLS 1.2? Isn't the issue simply that
Firefox etc. still use TLS 1.0? Note that this was a TLS 1.2

@_date: 2013-09-06 14:11:48
@_author: Perry E. Metzger 
@_subject: [Cryptography] People should turn on PFS in TLS 
So, lets say in public that the browser vendors have no excuse left
for not going to 1.2.
I hate to be a conspiracy nutter, but it is that kind of week. Anyone
at a browser vendor resisting the move to 1.2 should be viewed with
deep suspicion.
(Heck, if they're not on the government's payroll, then shame on them
for retarding progress for free. They should at least be charging. And
yes, I'm aware many of the people resisting are probably doing so
without realizing they're harming internet security, but we can no
longer presume that is the motive.)
Chrome handles 1.2, there is no longer any real excuse for the others
not to do the same.

@_date: 2013-09-06 15:09:27
@_author: Perry E. Metzger 
@_subject: [Cryptography] Matthew Green on BULLRUN 
Some interesting nuggets here, including the fact that he explicitly
calls out the existence of NSA's new HUMINT division that infiltrates
corporations for a living.

@_date: 2013-09-06 16:34:10
@_author: Perry E. Metzger 
@_subject: [Cryptography] 1024 bit DH still common in Tor network 
Summary: blog posting claims most of the Tor network is still running
older software that uses 1024 bit Diffie-Hellman.
I'm not sure how cheap it actually would be to routinely crack DH key
exchanges, but it does seem like it would be valuable for
most Tor nodes to be running newer software anyway.

@_date: 2013-09-06 17:03:30
@_author: Perry E. Metzger 
@_subject: [Cryptography] Bruce Schneier calls for independent prosecutor to 
All of this denying and lying results in us not trusting anything
    the NSA says, anything the president says about the NSA, or
    anything companies say about their involvement with the NSA. We
    know secrecy corrupts, and we see that corruption. There's simply
    no credibility, and -- the real problem -- no way for us to
    verify anything these people might say.

@_date: 2013-09-06 19:38:12
@_author: Perry E. Metzger 
@_subject: [Cryptography] Washington Post: Google racing to encrypt links 
Google is racing to encrypt the torrents of information that flow
   among its data centers around the world, in a bid to thwart
   snooping by the NSA as well as the intelligence agencies of foreign
   governments, company officials said on Friday.
   The move by Google is among the most concrete signs yet that recent
   revelations about the National Security Agency?s sweeping
   surveillance efforts have provoked significant backlash within an
   American technology industry that U.S. government officials long
   courted as a potential partner in spying programs.

@_date: 2013-09-06 21:38:08
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: Reminder, yet again... 
Sadly it seems I need to repeat this:
We've got a very large number of participants on this list, and
volume has gone way up at the moment thanks to current
events. To make the experience pleasant for everyone please:
1) Cut down the original you're quoting to only the relevant portions
to minimize the amount of reading the 1600 people who will
be seeing your post will have to do.
2) Do not top post. I've explained why repeatedly.
3) Try to make sure what you are saying is interesting enough and
on topic. Minor asides etc. are not.
The list is moderated for a reason, and if you top post a one liner
followed by a 75 line intact original, be prepared to see a rejection

@_date: 2013-09-06 21:46:31
@_author: Perry E. Metzger 
@_subject: [Cryptography] NYTimes: Legislation Seeks to Bar N.S.A. Tactic in 
After disclosures about the National Security Agency?s stealth
   campaign to counter Internet privacy protections, a congressman has
   proposed legislation that would prohibit the agency from installing
   ?back doors? into encryption, the electronic scrambling that
   protects e-mail, online transactions and other communications.
   Representative Rush D. Holt Jr., a New Jersey Democrat who is
   also a physicist, said on Friday he believed that the N.S.A. was
   overreaching and could hurt American interests, including the
   reputations of American companies whose products the agency may
   have altered or influenced.
   ?We pay them to spy,? Mr. Holt said. ?But if in the process they
   degrade the security of the encryption we all use, it?s a net
   national disservice.?

@_date: 2013-09-07 19:56:09
@_author: Perry E. Metzger 
@_subject: [Cryptography] Symmetric cipher + Backdoor = Public Key System 
On Sat, 07 Sep 2013 10:30:20 +0300
Then read the Blaze & Feigenbaum paper I posted a link to. It makes a
very good case for that, one that Jerry unaccountably does not seem to
believe. Blaze seemed to still believe the result as of a few days ago.

@_date: 2013-09-07 20:00:25
@_author: Perry E. Metzger 
@_subject: [Cryptography] Does NSA break in to endpoints (was Re: Bruce 
On Sat, 07 Sep 2013 09:33:28 +0100
Except, one implication of recent revelations is that stealing keys
from endpoints has been a major activity of NSA in the last decade.
I'm not going to claim that altering patches and software during
download has been a major attack vector they've used for that -- I have
no evidence for the contention whatsoever and besides, endpoints seem
to be fairly vulnerable without such games -- but clearly attacking
selected endpoints is now an NSA passtime.

@_date: 2013-09-07 20:09:24
@_author: Perry E. Metzger 
@_subject: [Cryptography] ElGamal, 
crypto?)
On Sat, 7 Sep 2013 10:05:22 -0400
Note that such systems should at this point be using deterministic
methods (hashes of text + other data) to create the needed nonces. I
believe several such methods have been published and are considered
good, but are not well standardized. Certainly this eliminates a *very*
important source of fragility in such systems and should be universally
References to such methods are solicited -- I'm operating without my
usual machine at the moment while its hard drive restores from backup.

@_date: 2013-09-07 20:20:15
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: Volume, top posting, trimming, SUBJECT LINES 
1) Volume has gotten understandably high the last few days given the
current news. I'd like people to please consider if their posting
conveys interesting information before sending.
2) Please adjust the Subject lines of your messages if your posting
deviates from the original Subject. This makes it much easier for
people to determine what they want to skip.
3) Again, please don't top post. Again, please trim the message you are
replying to.

@_date: 2013-09-07 20:43:39
@_author: Perry E. Metzger 
@_subject: [Cryptography] Why prefer symmetric crypto over public key 
On Sat, 07 Sep 2013 13:01:53 -0700
In the same sense that we can no longer rule out the possibility that,
given modern synthetic biology techniques, someone has already come up
with a way to create pigs with wings. I see the possibility of the
quantum computer as slightly smaller, however.
To my knowledge, there is no ECC analog of Shor's algorithm.

@_date: 2013-09-07 20:45:34
@_author: Perry E. Metzger 
@_subject: [Cryptography] Why prefer symmetric crypto over public key 
I'm unaware of an ECC equivalent of the Shor algorithm. Could you
enlighten me on that?

@_date: 2013-09-07 20:52:12
@_author: Perry E. Metzger 
@_subject: [Cryptography] Replacing CAs (was Re: Why prefer symmetric crypto 
On Sat, 7 Sep 2013 17:46:39 -0400
I think that in general one doesn't need CAs much. I will point out,
again, a message I sent to the list recently in which I propose that
simple demonstration of long term use and association may be
sufficient for ordinary purposes:

@_date: 2013-09-07 22:20:51
@_author: Perry E. Metzger 
@_subject: [Cryptography] Why prefer symmetric crypto over public key 
...and it appears I was completely wrong on that.
See, for example: Senility gets the best of us.

@_date: 2013-09-08 14:24:14
@_author: Perry E. Metzger 
@_subject: [Cryptography] Why are some protocols hard to deploy? (was Re: 
I believe you have answered your own question there, John. Even if we
assume subversion, deployment requires cooperation from too many
people to be fast.
One reason I think it would be good to have future key management
protocols based on very lightweight mechanisms that do not require
assistance from site administrators to deploy is that it makes it
ever so much easier for things to get off the ground. SSH deployed
fast because one didn't need anyone's cooperation to use it -- if you
had root on a server and wanted to log in to it securely, you could
be up and running in minutes.
We need to make more of our systems like that. The problem with
DNSSEC is it is so obviously architecturally "correct" but so
difficult to do deploy without many parties cooperating that it has
acted as an enormous tar baby.

@_date: 2013-09-08 14:34:26
@_author: Perry E. Metzger 
@_subject: [Cryptography] Techniques for malevolent crypto hardware (Re: Suite 
On Sat, 07 Sep 2013 19:19:09 -0700 Ray Dillinger Yes and no. There are limits to what such hardware can do. If such
hardware fails to implement a symmetric algorithm correctly, that
failure will be entirely obvious since interoperation will fail
immediately. If it uses bad random numbers, that failure will be
The most obvious implementation defects are bad RNGs and bad
protection against timing analysis.
One might also add side channels to leak information. Obvious side
channels for malevolent hardware are radio frequency interference (if
you can deploy listening equipment in the same colo this might be
quite a practical way to extract information) and timing channels
(not only in the sense of failure to protect against timing analysis
but also in the sense of using inter-event delays to encode
information like keys).
I think that in most applications power consumption side channels are
probably not that interesting (smart cards etc. being an exception)
but I'm prepared to be proven wrong.
Any other thoughts on how one could sabotage hardware? An exhaustive
list is interesting, if only because it gives us information on what
to look for in hardware that may have been tweaked at NSA request.
I wonder, though, if one could add secret layers to FPGAs to leak
interesting information in some manner. It seems unlikely, but I
might simply not be creative enough in thinking about it.

@_date: 2013-09-08 14:49:53
@_author: Perry E. Metzger 
@_subject: [Cryptography] Impossible trapdoor systems (was Re: Opening 
On Sat, 07 Sep 2013 20:14:10 -0700 Ray Dillinger That key would then be known as the "private key". The "public key"
is the set of magic values used in the symmetric cipher (say in the
one way functions of the Feistel network if it were a Feistel cipher)
such that such a magic decryption key exists.
So? If you have an algorithm that creates such ciphers in such a way
that the magic key is hard to find, then you produce all that you want
and you have a very powerful primitive for constructing public key
systems. You don't have an obvious signature algorithm yet, but I'm
sure we can think of one with a touch of cleverness.
That said, your hypothetical seems much like "imagine that you can
float by the power of your mind alone". The construction of such a
cipher with a single master key that operates just like any other key
seems nearly impossible, and that should be obvious.
A symmetric cipher encryption function is necessarily one-to-one and
onto from the set of N bit blocks to itself. After all, if two blocks
encrypt to the same block, you can't decrypt them, and one block
can't encrypt to two blocks. If every key produces the same function
from 2^N to 2^N, it will be rapidly obvious, so keys have to produce
quite different mappings.
Your magic key must then take any block of N bits and magically
produce the corresponding plaintext when any given ciphertext
might correspond to many, many different plaintexts depending
on the key. That's clearly not something you can do.

@_date: 2013-09-08 15:08:10
@_author: Perry E. Metzger 
@_subject: [Cryptography] Market demands for security (was Re: Opening 
On Sun, 8 Sep 2013 08:40:38 -0400 Phillip Hallam-Baker
Not to discuss this particular case, but I often see claims to the
effect that "there is no market demand for security".
I'd like to note two things about such claims.
1) Although I don't think P H-B is an NSA plant here, I do
wonder about how often we've heard that in the last decade from
someone trying to reduce security.
2) I doubt that safety is, per se, anything the market demands from
cars, food, houses, etc. When people buy such products, they don't
spend much time asking "so, this house, did you make sure it won't
fall down while we're in it and kill my family?" or "this coffee mug,
it doesn't leach arsenic into the coffee does it?"
Consumers, rightfully, presume that reasonable vendors *naturally*
did not design products that would kill them and they focus instead
on the other desirable characteristics, like comfort or usability or
what have you.
However, if you told consumers "did you know that food manufacturer
X does not test its food for deadly bacteria on the basis that ``there
is no market demand for safety''", they would form a lynch mob.
Consumers *presume* their smart phones will not leak their bank
account data and the like given that there is a banking app for it,
just as they *presume* that their toaster will not electrocute them.
If you ever say "we're not worrying about security in our systems
because there's no market demand for it", you had better make sure
not to say it in public from now on, because the peasants with
pitchforks and torches will eventually find you if they catch wind of

@_date: 2013-09-08 15:22:32
@_author: Perry E. Metzger 
@_subject: [Cryptography] Techniques for malevolent crypto hardware 
On Sun, 8 Sep 2013 15:10:45 -0400 Thor Lancelot Simon Ah, now *this* is potentially interesting. Imagine if you have a
crypto accelerator that generates its IVs by encrypting information
about keys in use using a key an observer might have or could guess
from a small search space.
Hadn't even occurred to me since it seems way more blatant than
the other sort of leaks I was thinking of, but of course the mere
fact that it is blatant doesn't mean that it would never be tried...

@_date: 2013-09-08 15:51:49
@_author: Perry E. Metzger 
@_subject: [Cryptography] Usage models (was Re: In the face of "cooperative" 
On Sun, 8 Sep 2013 14:50:07 -0400 Jerry Leichter I wrote about this a couple of weeks ago, see:
In summary, it would appear that the most viable solution is to make
the end-to-end encryption endpoint a piece of hardware the user owns
(say the oft mentioned $50 Raspberry Pi class machine on their home
net) and let the user interact with it over an encrypted connection
(say running a normal protocol like Jabber client to server
protocol over TLS, or IMAP over TLS, or https: and a web client.)
It is a compromise, but one that fits with the usage pattern almost
everyone has gotten used to. It cannot be done with the existing
cloud model, though -- the user needs to own the box or we can't
simultaneously maintain current protocols (and thus current clients)
and current usage patterns.

@_date: 2013-09-08 16:51:17
@_author: Perry E. Metzger 
@_subject: [Cryptography] Techniques for malevolent crypto hardware 
On Sun, 8 Sep 2013 15:55:52 -0400 Thor Lancelot Simon
Ah, but it only needs to be found once to destroy the reputation of a
Inserting bugs into chips (say, random number generators that won't
work well in the face of fabrication processes that alter analog
characteristics of circuits slightly) results in a "could be an
accident" sort of mistake. Altering a chip to insert an encrypted
form of a key into the initialization vectors in use cannot be
explained away that way.
You may say "but how would you find that?". However, I've worked
in recent years with people who decap chips, photograph the surface
and reconstruct the circuits on a pretty routine basis -- tearing
apart secure hardware for fun and profit is their specialty. Even
when this process destructively eliminates in-RAM programming,
usually weaknesses such as power glitching attacks are discovered by
the examination of the "dead" system on the autopsy table and can
then be used with live hardware.
Now that it has been revealed that the NSA has either found or
arranged for bugs in several chips, I would presume that some of
these people are gearing up for major teardowns. Not all
such teardowns will happen in the open community, of course -- I'd
expect that even now there are folks in government labs around the
world readying their samples, their probe stations and their etchant
baths. Hopefully the guys in the open community will let us know
what's bad before the other folks start exploiting our hardware
silently, as I suspect the NSA is not going to send out a warning.
I'll repeat the same observation I've made a lot: Dorothy Denning's
description of the Clipper chip key insertion ceremony described the
keys as being generated deterministically using an iterated block
cipher. I can't find the reference, but I'm pretty sure that when she
was asked why, the rationale was that an iterated block cipher can be
audited, and a hardware randomness source cannot.

@_date: 2013-09-08 18:09:43
@_author: Perry E. Metzger 
@_subject: [Cryptography] Der Spiegel: "NSA Can Spy on Smart Phone Data" 
Not very surprising given everything else, but I thought I would
forward the link. It more or less contends that the NSA has exploits
for all major smartphones, which should not be surprising.
     The United States' National Security Agency
     intelligence-gathering operation is capable of accessing user
     data from smart phones from all leading manufacturers. Top
     secret NSA documents that SPIEGEL has seen explicitly note that
     the NSA can tap into such information on Apple iPhones,
     BlackBerry devices and Google's Android mobile operating system.
Note that companies frequently give their users VPN access via
such devices, which means that they have something on them more
dangerous than the phone contacts etc. that the article mentions,
specifically access credentials. Such devices are also now frequently
used to provide second factors for authentication.

@_date: 2013-09-08 18:33:57
@_author: Perry E. Metzger 
@_subject: [Cryptography] AES state of the art... 
What's the current state of the art of attacks against AES? Is the
advice that AES-128 is (slightly) more secure than AES-256, at least
in theory, still current?
(I'm also curious as to whether anyone has ever proposed fixes to the
weaknesses in the key schedule...)

@_date: 2013-09-08 20:31:47
@_author: Perry E. Metzger 
@_subject: [Cryptography] Paper on Tor deanonymization: "Users Get Routed" 
A new paper on the Tor network, entitled "Users Get Routed:
Traffic Correlation on Tor by Realistic Adversaries".
  Quote to whet your appetite:
    We present the first analysis of the popular Tor anonymity network
    that indicates the security of typical users against reasonably
    realistic adversaries in the Tor network or in the underlying
    Internet. Our results show that Tor users are far more susceptible
    to compromise than indicated by prior work.
    [...]
    Our analysis shows that 80% of all types of users may be de-
    anonymized by a relatively moderate Tor-relay adversary within six
    months. Our results also show that against a single AS adversary
    roughly 100% of users in some common locations are deanonymized
    within three months (95% in three months for a single IXP). Fur-
    ther, we find that an adversary controlling two ASes instead of
    one reduces the median time to the first client de-anonymization
    by an order of magnitude: from over three months to only 1 day
    for a typical web user; and from over three months to roughly
    one month for a BitTorrent user. This clearly shows the dramatic
    effect an adversary that controls multiple ASes can have on
    security.
Disclaimer: one of the authors (Micah Sherr) is a doctoral brother.

@_date: 2013-09-08 21:15:41
@_author: Perry E. Metzger 
@_subject: [Cryptography] Techniques for malevolent crypto hardware 
On Sun, 08 Sep 2013 20:34:55 -0400 Kent Borg Lenstra, Heninger and others have both shown mass breaks of keys based
on random number generator flaws in the field. Random number
generators have been the source of a huge number of breaks over time.
Perhaps you don't see the big worry, but real world experience says
it is something everyone else should worry about anyway.

@_date: 2013-09-09 17:42:26
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: traffic levels 
List traffic levels are very high right now.
Although the current situation is worrisome to many of us, the list
becomes less useful to all when it becomes so clogged with posts that
it becomes impossible for any reasonable person to read it.
I and the co-moderators are probably going to start being much more
strict about content until things settle down. Do not be surprised or
offended when you get a rejection -- it is nothing personal.
Some rules of thumb:
SHORT BEATS LONG: Don't ramble, get to the point, avoid unnecessary
asides, trim back what you're quoting to the minimum. This is
especially important in replies on long threads.
IMPORTANT BEATS TRIVIAL: The more real, interesting, and new content,
the more likely we are to forward it.
DON'T BE REDUNDANT: If you already said something a couple of times in
a thread, don't repeat it endlessly. Fixing a clear misunderstanding
is okay, of course.
TECHNICAL BEATS POLITICAL: The list explicitly permits political
postings, but especially when the load is this high, they should
be informative and insightful. I'll almost always forward technical
cryptography and protocol discussion.
BARE LINKS ARE IRRITANTS: If you post a link to something, it should
explain clearly why someone might want to click. Even a sentence will
TOP POSTING IS AN ABOMINATION BEFORE THE MODERATOR: ...and I am an
angry, old-testament sort of moderator, too.
I've had to ban two people in the last week for getting incredibly
insulting after I would not forward their postings. It should go
without saying that calling me a fascist, an NSA plant, etc. is
unlikely to alter my opinion of your posting in a positive way. There
are other, unmoderated forums (with even more volume) -- you know how
to find them if you like.

@_date: 2013-09-09 18:03:14
@_author: Perry E. Metzger 
@_subject: [Cryptography] [cryptography] SSH uses secp256/384r1 which has 
specified in SP800-90 for Dual EC DRBG!
On Mon, 9 Sep 2013 14:07:58 +0300 Alexander Klimov
Er, don't we currently have documents from the New York Times and the
Guardian that say that in fact they *did* subvert them?
Yes, a week ago this was paranoia, but now we have confirmation, so
it is no longer paranoia.

@_date: 2013-09-09 18:09:40
@_author: Perry E. Metzger 
@_subject: [Cryptography] AES state of the art... 
There is a related key attack against AES-256 that breaks it in order
2^99.5, far worse than 2^250!
However, several people seem to have assured me (in private email)
that they think such related key attacks are not important in

@_date: 2013-09-09 18:32:08
@_author: Perry E. Metzger 
@_subject: [Cryptography] Random number generation influenced, HW RNG 
First, David, thank you for participating in this discussion.
To orient people, we're talking about whether Intel's on-chip
hardware RNGs should allow programmers access to the raw HRNG output,
both for validation purposes to make sure the whole system is working
correctly, and if they would prefer to do their own whitening and
stretching of the output.
On Sun, 08 Sep 2013 21:40:34 -0700 David Johnston That seems like a misguided rationale. In particular, given that
virtually all crypto software and existing kernels already have to
cope with hardware that does not provide this capability, it is
probably better that a hardware RNG not be a cryptographic
PRNG. It should be a source of actual hard-random bits that feed in
to the commonly used software mechanisms.
If you can't generate enough of them to satisfy all possible demand,
then I think it is architecturally far safer to allow software to
make the decision about how to stretch the scarcity, and in any case,
the software needs to exist anyway because other hardware does not
have the capability.
As it stands, the major consumers of your RNG, like the Linux kernel,
already end up mixing it in to a software RNG rather than implicitly
trusting it. It would be better to go further than this, I think.
A far greater concern than non-Intel engineers being bad at building
a random number generator in softare is that a fabrication flaw, a
post-manufacturing failure, or an intentional fabrication failure
induced by a paid agent would reduce the security of the system. It
is difficult to test such things as the system is constructed.
I think the same counterarguments hold. In any case, making it
impossible even for a privileged process like the kernel to test the
thing before returning it to its normal state seems like an
unfortunate choice.
There is, however, excellent reason here.
Could you be more explicit about that?
Please note we are not asking this sort of thing out of malice. There
is now a document in wide circulation claiming multiple chip vendors
have had their crypto hardware compromised by intent.
Regardless of your own personal integrity, there are others inside
your organization that may very well be beneficiaries of the $250M a
year the NSA is now spending on undermining security. Indeed, were I
running that program, I would regard your group as a key target and
attempt to place someone inside it. Do you not agree that you're a
major vendor and that your hardware would be a very tempting target
for such a program, which we now know to exist?
And yet, you will note that many, many security types would prefer
raw output to a finished cryptographic random number source.
Intel could always provide a standard C routine to do the conversion
from the raw output into a suitable whitened and stretched output.
But, forgive me for saying this, in an environment where the NSA
is spending $250M a year to undermine efforts like your own it is
impossible for third parties to trust black boxes any longer. I think
you may not have absorbed that what a week or two ago was a paranoid
fantasy turns out to be true.

@_date: 2013-09-09 18:56:57
@_author: Perry E. Metzger 
@_subject: [Cryptography] how could ECC params be subverted & other 
On Tue, 10 Sep 2013 00:23:51 +0200 Adam Back The Times reported that a standard from about the right time period
that had been criticized in a 2007 paper by some researchers at
Microsoft (who reported a backdoor) had been subverted, and there had
been much internal congratulation in a memorandum. The only such
standard was apparently the one in question.
This is no longer speculation, we now know that they seem to have
done this.
This was only an example, the context in the Guardian and the Times
made it clear others are probably lurking.
As I've said before, a week ago I would have called the entire idea
paranoia. Now, the evidence has changed. "When the facts change, I
change my mind."
I think you're hardly the only person to note that this is a very
dangerous game they've played, in some cases literally endangering
people's lives.
And, I would imagine, people are probably ripping apart popular
hardware crypto implementations, decapping the chips, and
photographing them as we speak. The memoranda spoke of hardware
crypto systems being subverted.

@_date: 2013-09-09 19:02:38
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: differing subscription and sender addresses 
Some of you may have noticed that if you send from an envelope address
that isn't subscribed, your mail gets blocked even if your From:
address is correct in the email itself.
You can fix this by subscribing your other address and changing your
settings in Mailman so that the secondary address receives no email
from the list.
For those that care: The underlying issue is that, to stop the vast
amount of spam directed at the list from clogging the moderation
queue, or clogging the server email queue with bounce messages, our
server blocks mail to the list from non-subscribed addresses during
the SMTP dialog.

@_date: 2013-09-09 21:04:33
@_author: Perry E. Metzger 
@_subject: [Cryptography] [cryptography] SSH uses secp256/384r1 which has 
specified in SP800-90 for Dual EC DRBG!
On Tue, 10 Sep 2013 00:25:20 +0100 Peter Fairbrother
   Cryptographers have long suspected that the agency planted
   vulnerabilities in a standard adopted in 2006 by the National
   Institute of Standards and Technology and later by the
   International Organization for Standardization, which has 163
   countries as members.
   Classified N.S.A. memos appear to confirm that the fatal weakness,
   discovered by two Microsoft cryptographers in 2007, was engineered
   by the agency. The N.S.A. wrote the standard and aggressively
   pushed it on the international group, privately calling the effort
   ?a challenge in finesse.?
This has generally been accepted to only match the NIST ECC RNG
standard, i.e. Dual_EC_DRBG, with the critique in question being
"On the Possibility of a Back Door in the NIST SP800-90 Dual Ec Prng"
which may be found here: Do you have an alternative theory?

@_date: 2013-09-10 00:08:10
@_author: Perry E. Metzger 
@_subject: [Cryptography] Random number generation influenced, HW RNG 
On Mon, 9 Sep 2013 23:29:52 -0400 John Kelsey Sure, but that might be visible in chip teardowns, which
would see an unexpected circuit, while an analog defect in the dual
inverter circuit Intel is using (or was using, I haven't looked in a
while) that biased the output might be quite subtle and very
difficult to find even then.
People forget that you can, in fact, tear down chips. Though I
will not claim it can be done with anything like the the ease with
which people reverse engineer software, the tools are available at
many research universities these days, and more and more people are
doing it.
The part that could get hairy, of course, is that there's an ocean of
circuitry on a modern high end processor, and given that this is being
handled by an instruction, there's an awful lot of ways it could be
gimmicked even if the "correct" circuit was there and seemed to work
as advertised. Fully analyzing the situation might take real funding.

@_date: 2013-09-10 10:37:43
@_author: Perry E. Metzger 
@_subject: [Cryptography] Fw: how could ECC params be subverted & other 
Forwarding because Adam apparently has distinct envelope and From:
addresses and didn't notice the bounce.
Note that anyone replying and attributing this message to *me* will
be laughed at mercilessly as their message is rejected.
Begin forwarded message:
, Adam Back The important potential backdoor is NIST 186-3 curves in Peter
Fairbrother's reply, and I think that would be a good place to focus
analysis.  (DRBG is largely irrelevant due suspected compromised state since
2007, and very limited use.  It is also a different type of issue -
not backdoored curves, arguably backdoored parameters).
I would like to hear also from other readers, who may have a deeper
understanding of EC math and parameter selection.
I do think people should be careful to distinguish between three
1 political "confirmed" backdoor claims from whistleblower documents
as interpreted by journalists (technical articles by eg Schneier
2 possible backdoor (showing that a parameter or key generation lacks
   sufficient fairness in its generation)
3 actual verifiable sabotage (the actual backdoor keys, previously
   unpublished implausible design failure, software backdoor etc.)
We need accuracy because once the dust has settled people will be
making crypto protocol design & implementation decisions based on
what is concluded.  Speculate away, but be clear.

@_date: 2013-09-10 11:31:48
@_author: Perry E. Metzger 
@_subject: [Cryptography] Reports: NSA, 
The story has been floating around for some days now. Apparently, Man
in the Middle attacks have been used quite extensively, including
against the Brazilian state oil company, and a major international
wire transfer network.
I think this indicates that Certificate Transparency and similar
techniques need to be deployed quickly. CAs have been dead as a
form of real assurance for some time now, but at this point the dance
party on the grave has gone on a bit too long.

@_date: 2013-09-10 15:16:59
@_author: Perry E. Metzger 
@_subject: [Cryptography] Techniques for malevolent crypto hardware 
On Sun, 8 Sep 2013 15:22:32 -0400 "Perry E. Metzger"
Oh, and of course, if you're doing a DSA style algorithm, you can
leak information in your choice of random nonce. This is yet more
reason to force protocols to use nonces that are deterministic based
on context, and to enforce that.

@_date: 2013-09-10 17:45:40
@_author: Perry E. Metzger 
@_subject: [Cryptography] Fw: how could ECC params be subverted & other 
As an aside, this is just the instance we know about, partially
because they screwed up, partially because the New York Times saw fit
to let us have confirmation of what was suspected in public.
I presume they've been more careful in other places, and that this is
not their only "work". I presume that they knew this would not be
used much and it was only a target of opportunity -- and that they've
gotten much more interesting "fixes" in elsewhere, perhaps even in
other parts of the NIST RNG standards (though it would *seem* much
harder to gimmick those).
You're not the only person feeling betrayed. For many years, the NSA
people appeared on our doorsteps offering help in many, many
contexts -- IETF for example.
The awful part is, many of them may have been completely sincere.
The IA side of the house *does*, in fact, depend on COTS hardware to
secure most of the Federal Government. They *do* have an interest in
keeping US commercial targets safe from attack.
However, even if many of the NSA people who participated in standards
work were sincere, their good will has been ruined by other NSA
people who used the sincere ones as cover for their
machinations. We now have to be suspicious of all of them, probably
permanently, and that's bad for everyone.
I imagine that there are some people inside the NSA now yelling at
others about how they've made it ever so much harder to fix the
security of most of the Federal Government, which ineed depends on
COTS hardware. Now even if they come to us with really good advice,
we have no idea if we should take it because we can't know they're
not lying to us.
None the less, it is done, and those of us on the outside can't
depend on NSA participants in standards work any longer. A set
of short sighted, foolish decisions have created tragedy for all.

@_date: 2013-09-10 17:49:25
@_author: Perry E. Metzger 
@_subject: [Cryptography] Availability of plaintext/ciphertext pairs (was 
On Tue, 10 Sep 2013 17:04:04 -0400 Jerry Leichter It would be useful to get a URL for it.
You make no mention there of whether the key used to encrypt the IV
is the same as that used for the plaintext. I presume if you need a
lot of IVs (see protocols like IPsec), and have enough key material, a
second key might be of value for that -- but I don't know what all
the ins and outs are, and would prefer to read the literature...

@_date: 2013-09-10 17:51:43
@_author: Perry E. Metzger 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
On Tue, 10 Sep 2013 17:04:51 -0400 Joe Abley Note that the apparent attacks against Petrobras, SWIFT and others
disclosed a few days ago appear to have used precisely this attack.

@_date: 2013-09-10 18:56:14
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: Ending thread "The One True Cipher Suite" 
I'm calling an end to the eggs, baskets, one cipher or a thousand
discussion. I don't think more will provide additional insight for
future protocol designers, and both major contributors have gotten
several rounds in already.

@_date: 2013-09-10 19:05:40
@_author: Perry E. Metzger 
@_subject: [Cryptography] soft chewy center 
The latency cost of a stream cipher implemented in hardware can be as
little as the time it takes a single XOR gate to operate -- which is
to say, low even by the standards of my friends who do high frequency
trading (many of whom do, in fact, claim to encrypt most of their
Certainly crypto is not the only (or even most important) way to make
systems secure. In breaking in to a system, implementation bugs are
where you look, not cracking cipher keys. However, latency qua
latency seems like a poor reason to avoid encrypting your traffic. It
might, of course, be a reason to avoid certain architectural
decisions in how you use the crypto -- a public key operation per
packet would clearly add unacceptable latency in many

@_date: 2013-09-10 19:12:32
@_author: Perry E. Metzger 
@_subject: [Cryptography] EFF press release on latest FISA opinions release 
The documents haven't yet been completely processed, but they've
already found some interesting features.
    The NSA apparently believed that it had the authority to search
    the telephone records database in order to obtain the 'reasonable
    articulable suspicion' required to investigate those numbers.
    Essentially, they were conducting suspicionless searches to obtain
    the suspicion the FISA court required to conduct searches.
Note that the USG has misleadingly claimed that this document release
was part of an effort to be "transparent" -- in fact, these are the
result of an EFF FOIA and were released at court order.

@_date: 2013-09-11 13:11:23
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: Please pick appropriate Subject lines... 
A quick note: many recent postings with very useful content have gone
out with entirely inappropriate Subject: lines because of threads
shifting topics. Always look at your Subject: line and ask yourself
if it should be updated.
(And thank all of you for not top posting. It is appreciated.)

@_date: 2013-09-11 13:22:11
@_author: Perry E. Metzger 
@_subject: [Cryptography] Random number generation influenced, HW RNG 
On Wed, 11 Sep 2013 09:04:56 +1000 "James A. Donald"
I don't think this is true. Typically, the noise sources being used
in hardware RNGs are very simple physical processes like shot noise.
I think simulations of those are vastly simpler than simulations of
human voices. The mechanics of the vocal tract are extremely
complicated, while the equations describing the distribution of shot
noise and the like are dead simple.
That said, I think the obvious defense against this is in any case
hardware teardowns. My fear is that not enough of those happen, but
recent events may convince people that they are necessary.

@_date: 2013-09-11 13:47:58
@_author: Perry E. Metzger 
@_subject: [Cryptography] Availability of plaintext/ciphertext pairs (was 
The padding at the end is to make sure that you have a full block of
data for a block cipher, since your actual message will usually be
shorter than a full block. In symmetric systems, it is not per se a
security feature. (Asymmetric Adding padding at the front to prevent cryptanalysts from using cribs
(that is, known plaintext) seems useless to me. Even if the padding
was of random length, it is of necessity going to be short. If you
have a technique that depends on known plaintext, crib dragging (that
is, trying all of the small number of possibilities) is easy.

@_date: 2013-09-11 18:51:16
@_author: Perry E. Metzger 
@_subject: [Cryptography] Killing two IV related birds with one stone 
It occurs to me that specifying IVs for CBC mode in protocols
like IPsec, TLS, etc. be generated by using a block cipher in counter
mode and that the IVs be implicit rather than transmitted kills two
birds with one stone.
The first bird is the obvious one: we now know IVs are unpredictable
and will not repeat.
The second bird is less obvious: we've just gotten rid of a covert
channel for malicious hardware to leak information.
Note that if you still transmit the IVs, a misimplemented client
could still interoperate with a malicious counterparty that did not
use the enforced method for IV calculation. If you don't transmit
the IVs at all but calculate them, the system will not interoperate if
the implicit IVs aren't calculated the same way by both sides, thus
ensuring that the covert channel is closed.

@_date: 2013-09-11 19:18:51
@_author: Perry E. Metzger 
@_subject: [Cryptography] Radioactive random numbers 
People have experimented with all sorts of stuff, and you can make
any of hundreds of methods from cameras+lava lamp+hash function to
sound cards to radioactive sources work if you have budget and time.
The issue is not finding ways to generate entropy. The issue is that
you need something that's cheap and ubiquitous.
User endpoints like cell phones have users to help them generate
entropy, but the world's routers, servers, etc. do not have good
sources, especially at first boot time, and for customer NAT boxes and
the like the price points are vicious.
The attraction of methods that use nothing but a handful of
transistors is that they can be fabricated on chip and thus have
nearly zero marginal cost. The huge disadvantage is that if your
opponent can convince chip manufacturers to introduce small changes
into their design, you're in trouble.

@_date: 2013-09-11 20:15:30
@_author: Perry E. Metzger 
@_subject: [Cryptography] Killing two IV related birds with one stone 
Certainly, but if you remove most or all covert channels, you've
narrowed the problem down to auditing the RNG instead of having to
audit much more of the system. It is all a question of small steps
towards better assurance. No one measure will fix everything.

@_date: 2013-09-12 11:00:47
@_author: Perry E. Metzger 
@_subject: [Cryptography] Radioactive random numbers 
Actually, I think things like this mostly have been missing
because manufacturers didn't understand they were important. Even
the Raspberry Pi now has an SoC with a hardware RNG.
In addition to getting CPU makers to always include such things,
however, a second vital problem is how to gain trust that such RNGs
are good -- both that a particular unit isn't subject to a hardware
defect and that the design wasn't sabotaged. That's harder to do.

@_date: 2013-09-12 11:03:38
@_author: Perry E. Metzger 
@_subject: [Cryptography] Radioactive random numbers 
On Wed, 11 Sep 2013 21:06:35 -0400 "Marcus D. Leech"
As a practical matter, though, people aren't going to put lava lamps
and cameras in their colos along with every 1U box and blade server.
They also won't attach them to the $40 boxes they buy at Best Buy.
Good solutions probably involve hardware that is well tested, on
motherboard, dirt cheap and easy for software to field validate. Yes,
this is hard.

@_date: 2013-09-12 11:25:04
@_author: Perry E. Metzger 
@_subject: [Cryptography] Killing two IV related birds with one stone 
On Thu, 12 Sep 2013 17:41:56 +0300 Yaron Sheffer
I think that's being overly pessimistic. Again, plugging most holes
means that you get to examine less of the implementation (including
hardware) to gain assurance. Further, there are protocols and uses
for these algorithms in the world other than IPsec and TLS.
"Infinite" is a big number. I'd say, again, that if you can lower the
number of side channels down to a couple, it helps someone having to
do the auditing later. Just because it is hard to eliminate
everything a priori is no reason to throw up your hands and make a
protocol less verifiable to someone who has to walk through the
implementation carefully later on.
We no longer have the luxury of saying "this protocol isn't important
enough to secure well", especially for TLS and IPsec. If the last few
weeks have taught us anything, it is that we have not been exercising
enough care in doing our work here, and as security engineers I think
we have a duty to be better than that.
Indeed, especially in the face of the knowledge that we have
saboteurs working in protocol standardization who would discourage us
from taking enough care, we need to be far more careful.

@_date: 2013-09-13 12:12:28
@_author: Perry E. Metzger 
@_subject: [Cryptography] Stealthy Dopant-Level Hardware Trojans 
This is pretty clearly a big deal. The fact that you can skew HRNGs
just by fiddling with dopant levels is something I would have
suspected, but now that we know, I think need for chip companies
to provide access to the raw HRNG output has become even more obvious.
It is not a question of not trusting the engineers who work on the
hardware. It is a question of not wanting to trust every
single individual in a long supply chain.

@_date: 2013-09-13 15:23:53
@_author: Perry E. Metzger 
@_subject: [Cryptography] Security is a total system problem (was Re: 
On Fri, 13 Sep 2013 08:08:38 +0200 Eugen Leitl I strongly suspect that delivering them securely to the vast number
of endpoints involved and then securing the endpoints as well would
radically limit the usefulness. Note that it appears that even the
NSA generally prefers to compromise endpoints rather than attack
The problem these days is not that something like AES is not good
enough for our purposes. The problem is that we too often build a
reinforced steel door in a paper wall.

@_date: 2013-09-13 17:02:28
@_author: Perry E. Metzger 
@_subject: [Cryptography] Summary of the discussion so far 
On Fri, 13 Sep 2013 15:46:58 -0500 Nico Williams
Sure, but the plan I described a few weeks ago would presumably end
with hundreds of thousands or millions of users if it worked at all.
Sure, that's true for voice and such. However, for messaging
apps, that's not an issue. See my claims here:
(That was part of a three message sequence that began with these two:
but only the second of those two is really relevant to this
particular discussion.)
That's important for onion networks, not mix networks. I understand
that the distinction isn't well understood by most, but it can be
summarized thus: an onion network depends on no one observing the
whole network to provide security, while a mix network uses
sufficient cover traffic and delay induction to prevent people from
being able to learn much even if they can observe the whole network
and control a minority of nodes.

@_date: 2013-09-13 17:12:43
@_author: Perry E. Metzger 
@_subject: [Cryptography] prism proof email, namespaces, and anonymity 
Indeed. As I said in the message I just pointed Nico at:
Quoting myself:
   Spam might be a terrible, terrible problem in such a network since
   it could not easily be traced to a sender and thus not easily
   blocked, but there's an obvious solution to that. I've been using
   Jabber, Facebook and other services where all or essentially all
   communications require a bi-directional decision to enable messages
   for years now, and there is virtually no spam in such systems
   because of it. So, require such bi-directional "friending" within
   our postulated new messaging network -- authentication is handled
   by the public keys of course. That's my solution. As I note, it seems to work for Jabber, Facebook
and other such systems, so it may be sufficient.
I'm not sure about that. Jabber doesn't really rate limit the number
of friend requests I get per second but I don't seem to get terribly
many, perhaps because fakes at most could hide some attempted phish
in a user at domain name, which isn't very useful to scammers.
My claim that I make in my three messages from August 25 is that it
is probably best if we stick to existing formats so that we can
re-use existing clients. My idea was that you still talk IMAP and
SMTP and Jabber to a server you control (a $40 box you get at Best Buy
or the like) using existing mail and chat clients, but that past your
server everything runs the new protocols.
In addition to the message I linked to above, see also:
for my wider proposals.
I agree this makes email delivered malware continue to be a bit of a
problem, though you could only get it from your friends.

@_date: 2013-09-14 12:14:11
@_author: Perry E. Metzger 
@_subject: [Cryptography] RSA equivalent key length/strength 
On what basis do you select your numbers? Have you done
calculations on the time it takes to factor numbers using modern
algorithms to produce them?

@_date: 2013-09-14 12:46:20
@_author: Perry E. Metzger 
@_subject: [Cryptography] Key management, 
On Sat, 14 Sep 2013 17:23:40 +0100 Max Kington
You don't seem to be entirely talking about key management, given
that you talk about mailpile and parley. Parley seems to be simply
talking about *key storage* for example, which is a different kettle
of fish.
However, on the topic of key management itself, my own proposal was
described here:
In summary, I proposed a way you can map IDs to keys through pure
long term observation/widely witnessed events. The idea is not
original given that to some extent things like Certificate
Transparency already do this in other domains.

@_date: 2013-09-14 12:56:02
@_author: Perry E. Metzger 
@_subject: [Cryptography] RSA equivalent key length/strength 
For those not aware, the document, by Paul and Hilarie Orman,
discusses equivalent key strengths and practical brute force methods,
giving extensive detail on how all calculations were done.
A URL for the lazy:
It is very well done. I'd like to see an update done but it does
feel like the methodology was well laid out and is difficult to
argue with in general. The detailed numbers are slightly different
from others out there, but not so much as to change the general
recommendations that have been floating around.
Their table, from April 2004, looked like this:
   +-------------+-----------+--------------+--------------+
 System      |           |              |              |
 requirement | Symmetric | RSA or DH    | DSA subgroup |
 for attack  | key size  | modulus size | size         |
 resistance  | (bits)    | (bits)       | (bits)       |
 (bits)      |           |              |              |
   +-------------+-----------+--------------+--------------+
     70      |     70    |      947     |     129      |
     80      |     80    |     1228     |     148      |
     90      |     90    |     1553     |     167      |
    100      |    100    |     1926     |     186      |
    150      |    150    |     4575     |     284      |
    200      |    200    |     8719     |     383      |
    250      |    250    |    14596     |     482      |
   +-------------+-----------+--------------+--------------+
They had some caveats, such as the statement that if TWIRL like
machines appear, we could presume an 11 bit reduction in strength --
see the RFC itself for details.

@_date: 2013-09-14 15:12:06
@_author: Perry E. Metzger 
@_subject: [Cryptography] Quantum Computers for Shor's Algorithm (was Re: 
On Sat, 14 Sep 2013 11:49:50 -0700 Tony Arcieri DWave has never unambiguously shown their machine actually is a
quantum computer, and even if it is, given its design it very
specifically cannot run Shor's algorithm or anything like it.
I'm unaware of a quantum computer of more than five qbits that has
been demonstrated that can run Shor's algorithm, and that specific
method, using a molecule with five distinct NMR peaks, cannot really
be extended further.
If you can find a reference to quantum computer with more qbits that
can run Shor's algorithm that has been demonstrated in public, I
would be very interested.
(And yes, I'm aware of the two photon device that factored the number
21, though I believe the team used tricks to make that work --
opinions on whether that work could scale would be welcome of course.)

@_date: 2013-09-14 15:55:33
@_author: Perry E. Metzger 
@_subject: [Cryptography] Quantum Computers for Shor's Algorithm (was Re: 
On Sat, 14 Sep 2013 12:42:22 -0700 Tony Arcieri Given that the DWave design is totally unsuitable for Shor's
algorithm, it seems to have no real bearing on the situation in
either direction.
To break 1024 bit keys (a minimum capability for a useful Shor
machine, I'd say), you need several thousand qbits. I've not heard of
a demonstration of more than a half dozen, and I've seen no
progress on the topic in a while. It isn't like last year we could do
six and the year before five and this year someone announced fifteen

@_date: 2013-09-15 15:24:16
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: entropy of randomness discussion is falling... 
One wants maximum entropy not only from one's RNG but also from one's
discussions about randomness.
Sadly, entropy is measured based on the level of "surprise" at the
content, and the level of surprise is going down in the current
discussion. As surprise goes to zero, so does interest on the part of
the couple thousand people reading along.
I'd like to ask participants to please:
1) Write compactly but clearly.
2) Avoid repeating themselves.

@_date: 2013-09-16 10:58:18
@_author: Perry E. Metzger 
@_subject: [Cryptography] A lot to learn from "Business Records FISA NSA 
[A very interesting message, and I'm going to reply to just one tiny
detail in it...]
Well, we do know they created things like the (not very usable)
seLinux MAC (Multilevel Access Control) system, so clearly they do
some hacking on security infrastructure.
(I will not argue with the larger point though.)

@_date: 2013-09-16 13:36:20
@_author: Perry E. Metzger 
@_subject: [Cryptography] Apple and Certificate Pinning 
I've not been able to figure out if Apple is using certificate
pinning for its applications (including its update systems) that seem
to use PKI. Does anyone know?

@_date: 2013-09-16 18:39:16
@_author: Perry E. Metzger 
@_subject: [Cryptography] AES [was NSA and cryptanalysis] 
It might be feasible in theory (and see the Illinois Malicious
Processor as an example) but I think it would be hard to pull off
well -- too hard to account for changes in future code, too hard to
avoid detection of what you've done.
On the other hand, we know from the press reports that several
hardware crypto accelerators have been either backdoored or
exploited. In those, leaking key material to observers in things like
IVs or choices of nonces might be quite feasible. Such devices are
built to be tamper resistant so no one will even notice if you add
features to try to conceal the "extra functionality" of the device.
For the Intel chips, I suspect that if they've been gimmicked, it
will be more subtle, like a skew in the RNG that could be explained
away as a manufacturing or design error. That said, things like the
IMP do give one pause. And *that* said, if you're willing to go as
far as what the IMP does, you no longer need to simply try to leak
information via the RNG or other crypto hardware, you can do far far
(For those not familiar with the Illinois Malicious Processor:

@_date: 2013-09-17 11:35:34
@_author: Perry E. Metzger 
@_subject: [Cryptography] Radioactive random numbers 
Added cme at panix.com -- if you want to re-submit this (and maybe not
top post it) I will approve it...

@_date: 2013-09-17 11:41:35
@_author: Perry E. Metzger 
@_subject: [Cryptography] The paranoid approach to crypto-plumbing 
Remember to generate the nonce for DSA using a deterministic method.
I confess I'm not sure what the current state of research is on MAC
then Encrypt vs. Encrypt then MAC -- you may want to check on that.
Also, you may want to generate your IVs deterministically from a
block cipher in counter mode, and not actually send them on the wire

@_date: 2013-09-17 11:54:49
@_author: Perry E. Metzger 
@_subject: [Cryptography] paranoid cryptoplumbing is a probably not defending 
On the "Paranoid Cryptoplumbing" discussion:
I'd like to note quite strongly that (with certain exceptions like
RC4) the odds of wholesale failures in ciphers seem rather small
compared to the odds of systems problems like bad random number
generators, sabotaged accelerator hardware, stolen keys, etc., and a
smart attacker goes for the points of weakness.
I'm not going to put my admin hat on and stop the discussion so long
as it remains relatively sane and technical, but for most purposes it
is probably just reinforcing a steel door in a paper wall.
(Of course, if the endpoints are trusted hardware running a formally
verified capability operating system and you still have time on your
hands, hey, why not? Of course, when I posted a long message about
modern formal verification techniques and how they're now practical,
no one bit on the hook.)
All that said, even I feel the temptation for low performance
applications to do something like Bill Frantz suggests. It is in the
nature of people in our community to like playing with such things.
Just don't take them *too* seriously please.

@_date: 2013-09-17 11:55:42
@_author: Perry E. Metzger 
@_subject: [Cryptography] Radioactive random numbers 
On Tue, 17 Sep 2013 11:35:34 -0400 "Perry E. Metzger"
Gah! Accidentally forwarded that to the whole list, apologies.

@_date: 2013-09-17 12:16:50
@_author: Perry E. Metzger 
@_subject: [Cryptography] Ars Technica on the Taiwanese National ID smart card 
Weeks after the informal announcement, the Taiwanese National ID
smartcard break is finally getting press. It is a great example of
a piece of "certified" crypto hardware that works poorly because
of bad random number generation.
Good explanation for your technical but not security oriented friends
in Ars Technica:

@_date: 2013-09-17 12:28:40
@_author: Perry E. Metzger 
@_subject: [Cryptography] paranoid cryptoplumbing is a probably not 
On Tue, 17 Sep 2013 12:15:48 -0400 Jerry Leichter If you are dealing with huge numbers of connections, you probably have
hardware and AES is plenty fast -- modern Intel hardware accelerates
it, too.
(If you really want a fast stream cipher, why not use ChaCha20 or
something else that is probably much better than RC4? I mean, if
you're going to propose changing it, as you do, it won't interoperate
anyway, so you can substitute something better.)
In any case, I would continue to suggest that the weakest point
(except for RC4) is (probably) not going to be your symmetric cipher.
It will be protocol flaws and implementation flaws. No point in
making the barn out of titanium if you're not going to put a door on

@_date: 2013-09-17 13:42:34
@_author: Perry E. Metzger 
@_subject: [Cryptography] paranoid cryptoplumbing is a probably not 
On Tue, 17 Sep 2013 10:07:38 -0700 Tony Arcieri That's not what I've gotten out of the most recent revelations. It
would seem that they've been evading rather than breaking the crypto:
putting back doors in protocols, stealing keys, encouraging weak
RNGs, adding flaws to hardware, etc. -- as well as doing active
attacks using stolen or broken CA keys.
I don't doubt that they archive everything they can forever, of

@_date: 2013-09-17 17:01:12
@_author: Perry E. Metzger 
@_subject: [Cryptography] PRISM-Proofing and PRISM-Hardening 
So, PFS stops attackers from breaking all communications by simply
stealing endpoint RSA keys. You need some sort of side channel or
reduction of the RNG output space in order break an individual
communication then.
(Note that this assumes no cryptographic breakthroughs like doing
discrete logs over prime fields easily or (completely theoretical
since we don't really know how to do it) sabotage of the elliptic
curve system in use.)
Given that many real organizations have hundreds of front end
machines sharing RSA private keys, theft of RSA keys may very well be
much easier in many cases than broader forms of sabotage.

@_date: 2013-09-17 17:26:00
@_author: Perry E. Metzger 
@_subject: [Cryptography] Johns Hopkins round table on NSA and Crypto 
Matthew Green tweeted earlier today that Johns Hopkins will be hosting
a roundtable at 10am EDT tomorrow (Wednesday, September 18th) to
discuss the NSA crypto revelations.
Livestream will be at:

@_date: 2013-09-18 08:05:32
@_author: Perry E. Metzger 
@_subject: [Cryptography] PRISM-Proofing and PRISM-Hardening 
On Tue, 17 Sep 2013 23:48:40 -0700 "Christian Huitema"
Certainly, though the protection against active attacks doesn't
improve much in that situation. Merely doing DNS cache preloading
(I'd say poisoning but the host you're being pointed at would be
entirely legitimate!) or some other attacks could force a target to
use a particular server at a site, perhaps the one of several front
ends where you had stolen a key. It is hard for DNSSEC to defend
against this given that the DNS data is real, and as active attacks
go, it is quite cheap!
(This also makes various forms of certificate pinning/witnessing
harder, though not necessarily fatally so.)
I don't disagree with your point, of course. I just think defense in
depth requires that we consider all these possibilities and force
the attacker to spend as much as possible to get access to traffic
data and plaintext, and to do it only for single targets.

@_date: 2014-02-22 11:32:32
@_author: Perry E. Metzger 
@_subject: [Cryptography] [ADMIN] Throttling of Randomness Discussion 
With my moderator hat on:
The RNG discussion has, I think, gotten past the "sell by" date on
the package.
The moderators will continue to accept high quality contributions on
the topic that discuss new information, but I think that most of what
we have at this point isn't new any longer.

@_date: 2014-02-25 12:49:26
@_author: Perry E. Metzger 
@_subject: [Cryptography] New book and a question 
I don't see the question as particularly meaningful -- it is all a
question of definitions and semantics, not of something objective.
This list was started primarily because I was disappointed with the
amount of noise on the cypherpunks list. That said, the cypherpunks
list has also continued in various forms since then.

@_date: 2014-01-12 16:55:34
@_author: Perry E. Metzger 
@_subject: [Cryptography] Registration for Real World Cryptography 2014 
Foolishly, I failed to register for Real World Cryptography 2014. If
there is anyone out there who is not using their registration or is
otherwise in a position to let me in, please get in touch.

@_date: 2014-01-13 09:25:15
@_author: Perry E. Metzger 
@_subject: [Cryptography] Registration for Real World Cryptography 2014 
BTW, I should thank the members of the list for coming through for
me. I'm currently sitting in the hall listening to "Is Bitcoin
Anonymous?" (a talk that follows Betteridge's Law of Headlines!)
If you're at RWC2014 and you see me wandering around, do say hello. :)

@_date: 2014-06-08 15:38:50
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN (sort of): Opportunistic TLS now turned on for 
Thanks to some help from Viktor Dukhovni, the mail server that runs
the list is now doing opportunistic TLS for SMTP connections.
This is, of course, not *entirely* important given that the list
traffic is entirely public and archived, but it seemed like a good
symbolic move.
Setting this up in Postfix was entirely painless and took only a
couple of minutes of work -- most of the time was in fact spent
waiting for Diffie-Hellman parameter files to generate. I suggest
that everyone with a mail server should do the same -- most major
email providers (like Gmail) do it already.

@_date: 2014-06-08 17:51:11
@_author: Perry E. Metzger 
@_subject: [Cryptography] Two news items on OpenSSL and formal methods 
I find it rather noteworthy that the most recent bug in OpenSSL was
found through the use of formal methods, specifically with the use
of Coq.
I also find it rather noteworthy that Andrew Appel just announced the
formal verification of OpenSSL's SHA-256 implementation, using a
Coq-based separation logic for C.
I've written on this list in the past about the fact that formal
methods are no longer a lab curiosity -- both of these events in the
last week seem like yet more evidence for this contention.
Formal methods can never produce perfection, since we may always make
mistakes in understanding what we wish to prove. However, for a very
wide variety of tasks, they can extirpate the overwhelming bulk of
the bugs we face. Also, unlike test infrastructure, when you
discover you have failed to realize you needed to prove a property,
you can be sure that you'll never face the same bug again, rather
than just being "sorta-kinda sure kinda".
Forwarded Message:
Coq-Club members may be interested in this recent result:
Verification of a Cryptographic Primitive: SHA-256
   by Andrew W. Appel
   May 9, 2014
A full formal machine-checked verification of a C program: the
OpenSSL implementation of SHA-256. This is an interactive proof
of functional correctness in the Coq proof assistant, using the
Verifiable C program logic. Verifiable C is a separation logic for the
C language, proved sound w.r.t. the operational semantics for C,
connected to the CompCert verified optimizing C compiler.

@_date: 2014-06-08 17:56:17
@_author: Perry E. Metzger 
@_subject: [Cryptography] Yet more formal methods news: seL4 to go open source 
seL4 is is a fully verified microkernel which, unfortunately, has
been closed source until now. It appears that's about to change,
though the details are still sketchy.
Begin Forwarded Message:
seL4, a capability-based microkernel whose implementation has been
comprehensively formally verified, is soon to be open source along
with its formal proofs and associated tools.
If you're interested, you can find out more at For those who like academic papers, an overview of seL4 and its
verification is described in the following paper (which I can assure
you is readable without a strong background in formal methods):
Comprehensive formal verification of an OS microkernel
Gerwin Klein, June Andronick, Kevin Elphinstone, Toby Murray, Thomas
Sewell, Rafal Kolanski and Gernot Heiser
ACM Transactions on Computer Systems, vol. 32, no. 1, pp. 2:1--2:70,
Feb. 2014
cap-talk mailing list
cap-talk at mail.eros-os.org

@_date: 2014-06-08 18:11:08
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN (sort of): Opportunistic TLS now turned on 
If you're running postfix, this will give you fine results. (All this
courtesy of Viktor Dukhovni):
      # cd /etc/postfix
      # ( umask 077; openssl req -new             -newkey rsa:2048 -keyout /dev/stdout -nodes \
                  -x509 -subj "/CN=$(uname -n)" -days 3650 >> smtpd_cert.pem.tmp &&
                  mv smtpd_cert.pem.tmp smtpd_cert.pem )
      # openssl dhparam -out dh2048.pem 2048
      # openssl dhparam -out dh1024.pem 1024
      # openssl dhparam -out dh512.pem 512
Then add this to your main.cf:
      smtp_tls_security_level = may
      smtp_tls_loglevel = 1
      smtp_tls_session_cache_database =
      btree:${data_directory}/smtp_scache
      smtpd_tls_security_level = may
      smtpd_tls_loglevel = 1
      smtpd_tls_session_cache_database =
      btree:${data_directory}/smtpd_scache smtpd_tls_cert_file =
      ${config_directory}/smtpd_cert.pem
      # MTAs are generally able to support 2048-bit EDH as clients.
      #
      smtpd_tls_dh1024_param_file = ${config_directory}/dh2048.pem
      smtpd_tls_dh512_param_file = ${config_directory}/dh512.pem
Note that the use of dh2048 with the smtpd_tls_dh1024_param_file
config variable is *not* a misprint.
Anyway, for a small site running a reasonably recent postfix, do this,
reload your configs, and you're probably good to go. If you have very
old clients submitting to the host in question, they may need an
override on the options for the submission daemon in master.cf:
  -o smtpd_tls_dh1024_param_file=${config_directory}/dh1024.pem
but I haven't seen any need for that with modern client machines.

@_date: 2014-06-08 18:14:27
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN (sort of): Opportunistic TLS now turned on 
A few lines seem to have gotten inappropriately wrapped here, such as:
On Sun, 8 Jun 2014 18:11:08 -0400 "Perry E. Metzger"
You will want to fix those problems if you're using my recipe. :)

@_date: 2014-06-08 19:18:19
@_author: Perry E. Metzger 
@_subject: [Cryptography] one last thought for today on formal methods... 
The fact that a serious security flaw in OpenSSL was found using
formal methods almost certainly means that, if they aren't using them
already, the bad guys, including various nation-states, will be using
formal methods across the board to look for vulnerabilities in
software going forward.
It would be a great shame if the good guys were not also using them
across the board to close such holes.
I really encourage everyone to learn about the state of the art.
Things are not like they were in 1985 -- formal verification is no
longer an infeasible pipe dream, and far too many people are still
unaware of how far the technology has come in the last couple of

@_date: 2014-06-09 09:33:04
@_author: Perry E. Metzger 
@_subject: [Cryptography] one last thought for today on formal methods... 
If you're an individual programmer and not a manager, I do have
practical advice, which is learn how to use Coq, since it seems to be
(by far) the most important of the systems being used for such work
right now. seL4's proof was done in Isabelle/HOL but the
infrastructure associated with Coq appears to have most of the
momentum right now.
"Software Foundations" by Pierce et al is online for free, and is a
good very very basic introduction to Coq and some important related
ideas, "Certified Programming with Dependent Types" by Chlipala is
also online and is a much more advanced text.
As the area is still very young and under active development, there
is probably no substitute for reading lots of papers, especially
papers by people who have done work on proving real artifacts
I have no "practical recipe" suitable for managers. This is no
different from the situation one is faced with constantly when new
technologies get adopted: either get some of your best reports to
spend a bunch of time researching and learning, or hire someone to
teach your people, or hire some people who already have the needed

@_date: 2014-06-09 12:25:15
@_author: Perry E. Metzger 
@_subject: [Cryptography] Yet more formal methods news: seL4 to go open 
Yes, so one has to make sure changes re-verify.
Note if one uses a system like Coq to write the verified
code in the same system that is doing the verification, there is no
meaningful distinction between the proof and the source code to the
If, on the other hand, one writes the code in a separate language and
merely uses Coq (or Isabelle or what have you) as a proof system,
then one needs to distribute both the code for the system and the
formal specification/verification code.
The same thing it does now.
Have you tried? Indeed, if you write your code in a dependently typed
style within Coq or what have you, how does one meaningfully update
the code *without* updating the proof? (There are quite interesting
artifacts written with Coq itself -- CompCert, for example.)
I think that, unfortunately, many people with strong opinions on this
topic have not done any work with modern tools. They are still
operating on memories of what things were like in the bad old days.
Things have changed.
Ultimately that will be necessary, yes, though infrastructure for
doing this is pretty straightforward in the open source world.
Note that *verifying* a proof is much easier than *constructing* a
proof. Proof checking can be quite fast.
It is harder in closed source, since the user doesn't have the source
code to verify the proof, but as a verified compiler (like CompCert)
can also generate a specification of the original code in logic (see
Andrew Appel's work), it may be possible for a user to check the
proof on the object code without having the source.
(Expanding on this latter point: keep in mind that a certified
compiler is proven to maintain observational equivalence of the
source and object, so it should be possible to mechanically transform
a proof about the properties of the source into a proof about the
object, given changes to the compiler of course. Such work is, again,
quite related to Appel's recent research.)
Likely. Of course, most code need not be verified for verification to
have an impact. Quark and similar systems point at the method for
dealing with this -- you can verify a cage around the unverified code
and still get assurance without needing to verify the whole system.
Quark is quite impressive in that it provides assurance for Webkit
without needing to prove anything about Webkit code directly.
Maybe, maybe not. What is "broad"? I would argue we're certainly at
an inflection point, comparable to what happened decades ago when
high level languages first became practical tools.

@_date: 2014-06-09 13:09:24
@_author: Perry E. Metzger 
@_subject: [Cryptography] Yet more formal methods news: seL4 to go open 
My own current work is (largely) about things like mundane C safety
issues, so I'm not about to deny the importance of fixing
those. However, the OpenSSL bug of mere days ago was not of this form

@_date: 2014-06-09 13:22:42
@_author: Perry E. Metzger 
@_subject: [Cryptography] Swift and cryptography 
The language spec/intro is available for free, both online on the web
and as a downloadable iBook. I recommend reading it if one has an

@_date: 2014-06-09 17:21:11
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: and thanks... (was ADMIN: Rules for posting 
And as a secondary reminder, I owe Tamzen and Jon a debt of gratitude
for taking on so much of the moderation duties. Without them the list
would not function.
In that spirit, please make their lives easier! Keep the content high
quality, and don't top-post. :)

@_date: 2014-06-10 17:03:32
@_author: Perry E. Metzger 
@_subject: [Cryptography] Bitcoin compute power (was Re: Aggregate signatures) 
A very large fraction of the mining power on bitcoin is in the
hands of one pool, ghash.io.
It is close to exceeding 50%.

@_date: 2014-06-10 17:10:46
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: Swift-ly Tilting Offtopic 
I think discussion of new programming languages for increased
assurance is very relevant to the list, but detailed discussions of
why the creators of particular languages might or might not be muppets
addicted to illegal intoxicants are not exactly crypto and security
I'm therefore clamping down and asking the other mods to do the same.
If it is interesting *and* on topic, it will still go through.

@_date: 2014-06-10 19:26:26
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: A reminder about top posting 
A3: Please.
Q3: Should I avoid top posting on this mailing list?
A2: Because, by reversing the order of a conversation, it leaves the
    reader without much context, and makes them read a message in an
    unnatural order.
Q2: Why is top posting irritating?
A1: It is the practice of putting your reply to a message before the
    quoted message, instead of after the (trimmed) message.
Q1: What is top posting?
[Yes, this is a periodic re-run, but it needs saying every few months.
Also, please trim as much as possible from messages you are quoting in
replies, keeping only the sections needed to maintain context for the

@_date: 2014-06-10 19:45:00
@_author: Perry E. Metzger 
@_subject: [Cryptography] Yet more formal methods news: seL4 to go open 
Presuming you're referring to the seL4 news:
I'm enthusiastic, but within limits.
We have yet to see the license, and also, there is no POSIX style
multiserver available for the L4 microkernel platform at this point.
(Minix 3, which should not be confused with earlier versions of
Minix, is to my knowledge the only actively developed POSIX
Also, it isn't clear that the proof technology used for seL4 is as
flexible as some of the things that have come after. The Isabelle/HOL
infrastructure described in the papers the researchers published
sounds quite brittle.
However, yes, this will probably be something of a milestone. I was
somewhat surprised no one else commented on it before now.

@_date: 2014-06-10 20:01:12
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: A reminder about top posting 
I tend to prefer the former style, where comments are interspersed
with (maximally trimmed) quoted material for context.
  > Quoted...
  Comment
  > Quoted...
  Comment
Trimming as much as reasonable from what you are quoting also makes
the reader's job easier, as there is much less spurious content to

@_date: 2014-06-11 11:09:44
@_author: Perry E. Metzger 
@_subject: [Cryptography] Languages, languages (was Re: Swift and cryptography) 
I'm not sure that's particularly true. There are disadvantages to
functional programming -- it is generally "further from the machine"
and doesn't give you much control over memory management, and thus
more difficult to do things like producing truly efficient OS kernels
and such, but for most uses it is no more or less a reasonable way of
thinking about problems than most other programming paradigms. If
efficiency isn't an issue, functional usually wins, and often even if
it is an issue.
I see no evidence of that -- indeed, lots of work has been done on
building native crypto libraries in functional languages.
There is another distinct advantage to doing work in a functional
language that hasn't been mentioned so far, but I'll throw it out
there anyway -- it is currently much easier to do proofs and formal
verification over functional languages, and this is only partially an
artifact of the present tooling situation. I expect this will become
better over time, but that there will always be a gap.
Re swift, you note:
It is also a safe language. Swift has (so far as I can tell) no
undefined behaviors, while C11 has over 200 of them and another 50 or
so unspecified behaviors. Buffer overflows aren't the only issue --
there are a huge number. Swift even catches integer overflow, and the
only other recently proposed systemsy language that does that which
I'm aware of is my own Cx.
It is commonly believed that array bounds checks are the only or
"main" issue with C. They aren't. C has hundreds of ways for a
programmer to hang themselves. Consider, for example, what happens
when you accidentally capture the address of a local variable past
function exit, or what happens when you pass the wrong type to a
varargs function, or when you invoke signed overflow and the compiler
(quite rightfully) optimizes it out, or when a programmer depends
accidentally on the order of invocation of parameters to a function
call and the optimizer changes its mind one day.
If the language manual doesn't tell you all you need to know about how
a program will behave, a programmer's life gets "interesting", and it
is surprisingly easy even for the most skilled programmers to get into
trouble with C.
That's what my own research work has been on for some time now. You
need an unusual design for that, one that one would normally not
select if you were designing afresh. Unfortunately I'm working alone
and have no particular expectation of producing a usable product for
non-academic purposes any time soon.

@_date: 2014-06-12 18:41:22
@_author: Perry E. Metzger 
@_subject: [Cryptography] Languages, languages 
I'm not sure I would phrase it quite that way, given that
a) Even functional languages need formal semantics if one is to do
formal verification, and
b) The formal semantics that have been produced for languages like C
tend to have a lot of associated machinery to model state.
I would probably restate that as "formal semantics are a way of
assigning a meaning to programs in formal logic, and the formal
systems used by people doing such work these days tend to be typed
lambda calculi, which are also functional languages".
Naturally in such systems it is more natural to express the semantics
of functional languages, but also, the semantics of functional
languages are just plain simpler in most cases.

@_date: 2014-06-12 20:55:16
@_author: Perry E. Metzger 
@_subject: [Cryptography] Languages, 
That is indeed true.
I have certain doubts about how ready for prime time that is. My
understanding is that the associated checks are fairly complicated,
and regions systems are not yet a mainstream thing in general.
That said, yes, dealing with safety in concurrency is important, and
it isn't clear that Swift has any answers for that yet, and your point
is well taken.
Personally I'm partial to go's solution, which is to adopt the CSP
model and get rid of shared state entirely, but that's another long
story, and we're getting far afield of crypto.

@_date: 2014-06-13 09:51:09
@_author: Perry E. Metzger 
@_subject: [Cryptography] ghash.io hits 50% of the Bitcoin compute power 
The security of Bitcoin depends on no one group burning more than half
the compute cycles. As of today, of course, the graph looks like

@_date: 2014-06-13 17:44:46
@_author: Perry E. Metzger 
@_subject: [Cryptography] ghash.io hits 50% of the Bitcoin compute power 
That is untrue. The binding between your private key and a set of
coins depends on the integrity of the blockchain itself.

@_date: 2014-06-13 22:43:42
@_author: Perry E. Metzger 
@_subject: [Cryptography] ghash.io hits 50% of the Bitcoin compute power 
And how do these others know that the public key in question has any
connection to a particular set of coins in the ledger? How do they
know that some other key, in fact, isn't the correct one?
Who is everybody?
Do millions of people actually store and check the complete block
chain on a routine basis? Where did your little cellphone wallet
app get its blockchain from? When was the last time you verified the
custody chain of all coins? Does your cellphone wallet app do that
all the time? Where do people get this historical ledger from?
I think you're trusting quite a bit here.
Bitcoin isn't primarily protected by mathematics, it is primarily
protected by a social process that can be gamed. Gaming it is
nontrivial because the social process is protected by cryptography,
but there seems like a great deal of religion behind people's claims
of how well it all works in the face of attack, perhaps because a lot
of people want it to work very, very badly.

@_date: 2014-06-19 13:48:29
@_author: Perry E. Metzger 
@_subject: [Cryptography] Shredding a file on a flash-based file system? 
This is also true of modern hard disks -- and I must say I do *not*
trust hard drives with built in encryption, because there is no way to
test that they are working correctly.
If one has control over the hardware design, a small, battery backed
up SRAM might be ideal for storing a master key for such
purposes. It could be zeroized in very little time. One might even
build a circuit to cut off the power to the SRAM and drain the
residual charge off if one needs it to be *really* fast...

@_date: 2014-06-19 13:58:28
@_author: Perry E. Metzger 
@_subject: [Cryptography] from CNBC: "Cybersecurity firm says large hedge fund 
"In an audacious and sophisticated attack, cybercriminals acting in
late 2013 installed a malicious computer program on the servers of a
large hedge fund, crippling its high-speed trading strategy and
sending information about its trades to unknown offsite computers."
Unfortunately, the article is otherwise largely content free.

@_date: 2014-06-19 16:09:12
@_author: Perry E. Metzger 
@_subject: [Cryptography] encrypting hard drives (was Re: Shredding a file on 
I think the rationale was basically performance based -- that you
could avoid needing to load the processor with crypto duties,
especially on a box with lots of drives.
However, it clearly is a horrible security model, especially since
manufacturers like Seagate refuse to allow you to access the
ciphertext on drive to assure yourself that all is encrypted in the
manner claimed. Even if they did allow that, the hard drive's
internal controller is yet another independently operating
microprocessor with firmware that could have been sabotaged by a bad
If performance is really an issue, I think the real solution is to
put an AES accelerator into the on-motherboard side of the disk
controller, and have it completely under the control of the main
CPU's operating system. Treat the hard drive as hostile, never send
it any keying material and never send it any unencrypted data, and
then you don't have to worry about who may have tampered with its
(Yes, you still have to worry about your motherboard, but narrowing
the number of things you trust is the only way to make audits
I think you're being overly pessimistic. Just because certain
manufacturers have bought the "help" that various agencies are giving
out without questioning it sufficiently does not mean manufacturing
good designs is actually impossible.

@_date: 2014-06-19 16:51:30
@_author: Perry E. Metzger 
@_subject: [Cryptography] from CNBC: "Cybersecurity firm says large hedge 
This comment was sent out of band to me by a friend who is highly
familiar with the inside of hedge funds:
   ?It?s implausible that a high frequency trading shop failed to
   notice _hundreds of microseconds to single digit milliseconds_ of
   delays until such a time as their strategy became ?ineffective? --
   unless they have a significantly different definition of high
   frequency than the rest of the industry employs.  The game is lost
   in nanoseconds these days, not microseconds, and certainly not
   milliseconds.
   Furthermore, they seem to conflate high frequency trading
   operations with the firm?s traditional order entry system and make
   the outlandish claim that somehow the attackers were making money
   on the diverted trade information of the high frequency strategy.?

@_date: 2014-06-19 17:06:44
@_author: Perry E. Metzger 
@_subject: [Cryptography] hardware vs software FDE (was Re: Shredding a file 
It is different in a vital respect -- in the software implementation,
you can more or less check that everything is working as expected,
and you don't have to trust that the drive isn't sabotaging you.
That's quite different -- vitally so, I think.

@_date: 2014-06-20 09:04:21
@_author: Perry E. Metzger 
@_subject: [Cryptography] hardware vs software FDE (was Re: Shredding a 
No. You are missing a very vital point.
If the sectors on the drive are encrypted with some particular
algorithm using some particular key, I can check, in a software only
solution, that the sectors are indeed encrypted in that key using
that algorithm. After all, at worst, I can take the drive, plop it in
another machine, and verify the encryption. In the hardware FDE
implementations Seagate is pushing, no ability is provided to access
ciphertext and determine that the right algorithm is in use with the
correct key.
It is actually much worse than that since the hardware implementation
could be doing things like stashing keys in hidden sectors, but one
need not go so far as to worry about that because even the most basic
audit is impossible.
No, if they say "this is using AES-256 GCM" I can do more than that.
If your closed source vendor is not telling you what algorithm and
mode they are using, they are of course also doing something
unacceptable and should be excluded from your purchases. It is
acceptable (though not even remotely optimal) if the encryption
implementation is closed source, but it is utterly unacceptable if
its method of operation is not fully disclosed.

@_date: 2014-06-20 13:03:58
@_author: Perry E. Metzger 
@_subject: [Cryptography] Shredding a file on a flash-based file system? 
Why do you presume such systems do not require that a key be entered
or otherwise externally supplied during boot? Generally, they do
require that. This is not the issue.

@_date: 2014-06-21 10:10:43
@_author: Perry E. Metzger 
@_subject: [Cryptography] Code Spaces has been under DDOS attacks and... 
Password based authentication to a crucial configuration service is
probably a bad idea. Other than that, this does not sound like it has
terribly much to do with encryption.
That seems like the problem right there.
Requiring two (or more) factor authentication for systems
administration interfaces and using proper segregation of
administrative privileges is kind of important if you don't want to
end up with someone hijacking your sysadmin system.

@_date: 2014-06-21 17:20:05
@_author: Perry E. Metzger 
@_subject: [Cryptography] Spaces in web passwords 
I think that's all a rationalization at best. I suspect there is, in
fact, no reason other than someone being silly when they put in their
validation code. I've been in plenty of meetings about related topics
in large organizations and I've never heard anyone bring such things
That said, I've seen mighty insane and arbitrary password policies
created -- some of them have the feeling of cargo cult or voudon
origins. None, however, that I can recall mentioned spaces, though
that might also just be my poor memory.

@_date: 2014-06-21 17:27:43
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: will the owner of yog.abyss.ca please get in 
Will the owner of the mail server "yog.abyss.ca", or any list
subscriber who believes that their email is going through that host,
please get in touch?

@_date: 2014-06-21 17:41:18
@_author: Perry E. Metzger 
@_subject: [Cryptography] Spaces in web passwords 
Neat! They had to "fix" the product to accommodate people who wanted
to use it insecurely!
I would, sadly, be lying if I claimed not to have experienced this
particular form of brain damage before.

@_date: 2014-06-22 07:25:36
@_author: Perry E. Metzger 
@_subject: [Cryptography] How big a speedup through storage? 
Why would one expect that?
Why would one expect that, either?

@_date: 2014-05-31 16:13:52
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: list server upgrade 
The server that runs the mailing list and the associated web site will
be down later today or early tomorrow for a couple of hours for an
upgrade, exact time dependent on when preparation is complete.
If you go to the web page and notice the system is down, that's why.

@_date: 2014-05-31 20:40:02
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: list server upgrade completed 
The work should be done as of now. If you notice any problems, please
do let me know privately.

@_date: 2014-05-31 21:08:30
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: list server upgrade completed (hopefully) 
After a few configuration hassles, I believe the mail server is now
actually working again. I apologize for any inconvenience. As always,
if you notice a technical problem with the list, feel free to get in
touch with me directly.

@_date: 2014-05-31 21:15:59
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: third time's the charm... 
Hopefully the remaining configuration problems with the new server
are fixed now, and the list should be back to normal.

@_date: 2015-12-01 07:07:19
@_author: Perry E. Metzger 
@_subject: [Cryptography] Large companies sued for using Elliptic Curve TLS? 
Anyone know anything about this? The claim is huge numbers of
companies (that is, end users like Macy's and GoPro) are being sued by
a patent troll for using elliptic curve cryptography on their web
If this is true, it could be a very serious situation.

@_date: 2015-12-01 21:24:43
@_author: Perry E. Metzger 
@_subject: [Cryptography] "The Moral Character of Cryptographic Work" 
Of some interest to those here: a newly published essay by
Phillip Rogaway entitled "The Moral Character of Cryptographic Work"
Quoting the abstract in full:
    Cryptography rearranges power: it configures who can do
    what, from what. This makes cryptography an inherently political
    tool, and it confers on the field an intrinsically moral dimension.
    The Snowden revelations motivate a reassessment of the political and
    moral positioning of cryptography. They lead one to ask if our
    inability to effectively address mass surveillance constitutes a
    failure of our field. I believe that it does. I call for a
    community-wide effort to develop more effective means to resist mass
    surveillance. I plea for a reinvention of our disciplinary culture to
    attend not only to puzzles and math, but, also, to the societal
    implications of our work.
Full text is at:

@_date: 2015-12-06 18:07:09
@_author: Perry E. Metzger 
@_subject: [Cryptography] Montgomery multiplication bug in OpenSSL? 
The latest OpenSSL security announcement alluded to a bug in carries
in the Montgomery multiplication code. This is a sufficiently unusual
security bug in cryptographic code that it piqued my interest. Does
anyone know details that they're willing to share with the list, both
about the bug itself and what the likely implications are?

@_date: 2015-11-09 14:50:20
@_author: Perry E. Metzger 
@_subject: [Cryptography] Bitcoin blocksize limit can be removed 
Generally speaking, one should be cautious about believing the origin
of messages from famous nyms who are known to PGP sign all their
messages when those messages are unsigned...

@_date: 2015-11-12 11:55:58
@_author: Perry E. Metzger 
@_subject: [Cryptography] Does anyone use ZKP systems based on graph 
When I first learned about Zero-Knowledge Proof systems, the example
used for an underlying was graph isomorphism. Graph isomorphism has
always been known to be in NP but never known to be NP complete, but
until now the best algorithms were all well above polynomial time.
It appears, however, that a very recent breakthrough result by
Laci Babai (first described two day ago in a seminar)
places the graph isomorphism problem into quasi-polynomial time.
So my question is, are there any real world ZKP systems deployed in
the field that actually depend on the graph isomorphism problem?
(And at the very least, all the textbook examples using graph
isomorphism might want updating.)

@_date: 2015-11-15 09:29:20
@_author: Perry E. Metzger 
@_subject: [Cryptography] Nvidia- one Tflop could change the rules quicker 
That's utterly risible. No number of GPUs are going to factor an
10,000 bit number using currently known methods, no matter how many
planets you turn into GPUs. Quantum computers could, however, conduct
the factoring quite straightforwardly.

@_date: 2015-11-16 10:39:07
@_author: Perry E. Metzger 
@_subject: [Cryptography] Fwd: Re:  Post Quantum Crypto 
The second statement is true if one qualifies that as *General*
relativity rather than just relativity. Special relativity and QM were
reconciled long ago.
However, I think few (if any) researchers believe that there is any
real relevance of GR to quantum computing, at least not in the sense
of building practical quantum computers.
Regardless, I have to agree with a wider point Viktor made: there are
no breakthroughs in theoretical physics needed to make quantum
computers possible. The only issues are very practical engineering
problems, some of which are quite difficult of course.

@_date: 2015-11-16 10:57:12
@_author: Perry E. Metzger 
@_subject: [Cryptography] ratcheting DH strengths over time 
There's an old adage that software lives longer than hardware, and I
think this does make sense if only because it takes certain kinds of
decisions away not only from end users but also from release
engineers, system integrators, and others who likely aren't going to
spend a lot of time thinking about things like the DH moduli their
systems ship with.
That said, I do worry about the effect of such schedules in the one
place that hardware lives ridiculously long, which is embedded
hardware. Often, small embedded controllers remain in place for insane
periods of time, sometimes vastly longer than anyone had originally
envisioned, and an underpowered controller that communicates very
nicely with a key of size N might not handle a key of size 3N nearly
so well. Furthermore, engineers are unlikely test their equipment with
the date set twenty years into the future near the End of Life.
Ideally, one should set the constants on such controllers to the ones
that will be viable at the end of life (say picking likely end of
manufacturer sale plus thirty years), thus forcing the designers to
confront not just today's computing needs but possibly tomorrows --
but it also seems unlikely that we can get engineers to do that.
So, I suppose my overall comment is: this is an interesting idea, but I
suspect it will not be entirely easy to make work, especially in the
places where it is most needed (that is, hardware being kept around
way past the point where it should be retired.)
Regardless, let me remind almost everyone that the main problem in the
recent Logjam attacks was a combination of a downgrade attack and the
fact that engineers had forgotten that DH primes really should not be
shared by everyone on earth. One could easily mis-engineer future
systems so that they upped the sizes of various keys and groups and
yet remained vulnerable to things like downgrade attacks etc. Once
again, people tend not to attack cryptography head on, but to find
weak points and go after *those*.

@_date: 2015-11-16 11:06:21
@_author: Perry E. Metzger 
@_subject: [Cryptography] ratcheting DH strengths over time 
Oh, and an addendum: you can up your DH primes all you like, but if
the key exchange is then driving RC4 or 1DES for the actual
communications or what have you, you lose. Cryptographic protocols
like TLS depend on several moving parts -- key exchange, hashes,
symmetric ciphers, etc.
The NSA's policy seems to be that you set all of these to be more or
less of equivalent security and there's no point in having a steel
wall with a paper door, and that seems to make some sense. Keep all
your parts in balance. Another overlooked lesson from Logjam was that
one should never have allowed the use of DH primes that were "too
weak" for the chosen symmetric system in the first place -- selecting
a strong symmetric cipher should force the use of an equivalently
strong DH or EDH group. Of course, using DH primes that are much
stronger than the symmetric system in use doesn't help much
either. The attacker will go after the weakest point regardless. You
want all the parts balanced.
So, how does one automatically upgrade not only the strength of the
asymmetric subsystem but also the symmetric ciphers and hashes in use?
I'm not sure one does -- so perhaps the auto upgrade point is
moot. Perhaps you just make sure you never use a "bad mix" where the
key strengths are out of line with each other and beyond that you hope
that people aren't stupid about their engineering decisions for long
lived hardware.
Or, perhaps there's a cleverer idea possible here that I'm not seeing.

@_date: 2015-11-16 13:05:07
@_author: Perry E. Metzger 
@_subject: [Cryptography] Long-term security (was Re: ratcheting DH strengths 
Just a slight redirect of the model in your mind. The issue isn't only
keeping information qua information secure for long periods.
SCADA systems and other embedded hardware may need to be kept secure
from tampering for 30 years or longer. This stuff shows up in
surprising places -- people really are doing things like putting
building heating and elevator systems onto the internet now.
The biggest current problem is that generally the engineers building
such systems have no idea how to design them for security, but even if
they did, how do you design a system to remain secure when it might be
in place in forty years because no one wants to replace their elevator
controller since it is still working?
Say you have thousands of such systems or even millions of them out in
the field, all happily dialing home and getting new instructions, all
that protected by an RSA key or an elliptic curve signature key. How
do you keep that safe for a stupid amount of time?
The sad truth is, you probably can't...

@_date: 2015-11-16 13:19:26
@_author: Perry E. Metzger 
@_subject: [Cryptography] ratcheting DH strengths over time 
However, it is frequently the case that this proves false. See again
RC4, various hash functions, etc., and even various cryptographic
modes (like various block cipher modes) that prove less secure than
was previously believed.
Over the long term, one needs to be able to abandon one cipher suite
and move to another. Sadly, that has proven hard in practice.

@_date: 2015-11-16 15:51:42
@_author: Perry E. Metzger 
@_subject: [Cryptography] ratcheting DH strengths over time 
Whether they saw it that way or not, a lot of RC4 is still out there
being used to protect traffic right now.
But brute force is quite doable for 1DES and there's a surprising
(and sad) amount of it in the field.
Regardless, the overall point stands. We are well aware that crypto
appears to be something that needs to be field replaceable, and yet
we more or less have no clue how to do that in deployed embedded
hardware. Indeed, we seem to have a very poor idea in general on how
to maintain the software on field deployed embedded hardware. (To
give another common example, the world's home "routers" are an
astonishingly large pool of highly insecure systems.)
We didn't understand what they guaranteed. CBC in particular has
proven much more problematic than was assumed 25 years ago.

@_date: 2015-11-16 17:15:52
@_author: Perry E. Metzger 
@_subject: [Cryptography] ratcheting DH strengths over time 
I'm not sure what birthday attacks exist on CBC. However, for the
rest, see BEAST, POODLE, etc. for examples of the sorts of problems
that exist. Googling about will tell you more.
Note that there were people who understood that some block cipher
modes were problematic and the engineering part of the community
(including me, sadly) didn't listen closely enough.

@_date: 2015-11-16 19:33:41
@_author: Perry E. Metzger 
@_subject: [Cryptography] Nvidia- one Tflop could change the rules quicker 
I don't know about "novel methods" (mostly "novel methods" means "bad
ideas"), but yah, generally there's a balance between key length and
speed. On the other hand, there's also a practical limit to how long
keys need to be -- once you've passed the "brute force is never going
to work" point people stop trying to attack the crypto directly anyway.
People just use hardware accelerators for most such stuff. They're
commercially available. (Heck, some stuff like AES acceleration is now
built in to many ordinary CPUs.)
GPUs are of course useful for a lot of things, and have been in use
for work like password cracking and the like for a long time. However,
they aren't revolutionary the way a quantum computer would be.

@_date: 2015-11-17 08:52:56
@_author: Perry E. Metzger 
@_subject: [Cryptography] Long-term security (was Re: ratcheting DH 
And of course, the users cannot for practical purposes be relied on to
do security patching or indeed any sort of software upgrades. Many
users of home routers simply plug them in and don't even know that
they can open a web page to configure them, and wouldn't know what any
of the configuration options mean either.
Fully automated patching seems like the only solution there (at least
by default unless you configure it not to), but given the price
pressures and the lack of consumer demand, it seems unlikely that the
average vendor will do that.

@_date: 2015-11-17 09:21:07
@_author: Perry E. Metzger 
@_subject: [Cryptography] Long-term security (was Re: ratcheting DH 
Well, there may be a happy middle here.
For example, one can set defaults reasonably but permit users to
override. I think it might be reasonable for things like home
routers, commercial user-oriented operating systems, etc., to operate
on a "by default, you download and install patches, and the box only
trusts signed code, but if you know how to read the manual and have
physical access you can override that".
The key is to make sure that the average user who has no idea what a
security patch even is can do more or less nothing but be safe, while
the unusual user who does know what they're doing can still do what
they like with the hardware.

@_date: 2015-11-17 11:12:39
@_author: Perry E. Metzger 
@_subject: [Cryptography] Sadly predictable: Terrorism used as excuse to 
Following the Paris terrorist attacks, only hours passed before I
saw the first article asking whether we need to ban encryption or
provide magic impossible "golden keys" to break it. This New York
Times article is, if anything, late to the game:
Perhaps the terrorists in Paris used encryption, but then again so
does just about everyone else using the internet, and for good
reason: otherwise our already terrible online security situation
would be so bad that the network would become unusable. Sure,
perhaps the terrorists used encryption, but the terrorists also
perhaps used automobiles, maps and a host of other every-day
technologies, just like everyone else, all of which are critical to
a functioning technological society.
I think part of the problem here is that most people are
technologically illiterate and don't even know that they depend on
strong encryption every single day to keep them secure, or how much
worse off they would be if it ceased to exist. By contrast, if someone
tried to publish a scare story saying "attackers used dangerous new
AUTOMOBILE technology" no one would take the claims seriously.

@_date: 2015-11-18 19:17:00
@_author: Perry E. Metzger 
@_subject: [Cryptography] The vultures circle... 
I heard no less than four news stories on the radio today (two on NPR
alone) explaining that there is a tradeoff between security and
privacy and encryption helps terrorists.
None of these segments interviewed anyone with a contrary opinion,
or indeed anyone with any technical expertise. There was also no
mention of fact that encryption *is* a critical security technology.
No one mentioned the enormous danger to security that interfering with
the deployment to encryption might bring -- the security risks to
critical infrastructure, to industrial and commercial systems, all of
that was ignored.
I would suggest that those who have the ability to get their voices
heard need to respond to this quickly, or we're going to get
overwhelming momentum for very, very bad technical decisions being
imposed by very bad laws. The security services were quite literally
waiting for a terrorist incident to do another full scale
anti-cryptography PR campaign -- the security community needs to

@_date: 2015-11-19 10:13:53
@_author: Perry E. Metzger 
@_subject: [Cryptography] A new, 
I think we're calling a halt to this.
Sorry, Mr. Kizir, but people who think they've invented superior
encryption algorithms show up out of the woodwork about every fifteen
minutes. Generally these people don't provide (say) proofs of the
resistance of their work to linear and differential cryptanalysis or
an explanation of why they selected the number of rounds they did in
order to meet some security criterion, and they certainly don't
describe their work in terms of reasonable attacks on similar systems.
Instead they're at best friendly amateurs wading in to water that
is deeper than they think, and at worst they're sometimes the sort of
people one finds on the internet proclaiming that they can
demonstrate that Einstein was wrong or who have a definitive proof
showing how to square the circle.
I will be kind and presume that you're the former sort and not the
latter, and recommend that if you're really interested in the field
you spend a few years studying it in depth. Of course, at that point
you will probably realize the world has plenty of good encryption
algorithms already and it is very rare that it needs new ones -- the
problems we actually face are different.
And for now, I'm banning further discussion of this.

@_date: 2015-11-21 08:22:12
@_author: Perry E. Metzger 
@_subject: [Cryptography] =?utf-8?q?Pearl_Harbor_and_Crypto_=28was_Re=3A__IS?= 
=?utf-8?q?_with_encryption=29?=
On Fri, 20 Nov 2015 08:47:55 -0800 Henry Baker The actual events were a bit more complicated. A better explanation is
given in the opening section of "The Codebreakers" by Kahn. (The
chapter is entitled "One Day of Magic", "MAGIC" having been the
codename for the decrypted Japanese intercepts.)

@_date: 2015-11-21 08:24:43
@_author: Perry E. Metzger 
@_subject: [Cryptography] Chrome dropping DHE (was Re: [FORGED] Re: ratcheting 
I can no longer recall (TLS mechanics are complicated), but is there
no less radical way to impose a minimum DHE group size?

@_date: 2015-11-21 21:13:58
@_author: Perry E. Metzger 
@_subject: [Cryptography] Chrome dropping DHE (was Re: [FORGED] Re: 
I suspected. This is rather an unfortunate thing.
Generally, it is probably best if protocols impose a minimum common
security level between the key exchange, signature and symmetric
cipher portions of the system. If you're negotiating a 128 bit key
symmetric cipher, using a key exchange that provides only (say) a 70
bit equivalent of protection for the key exchange would seem like a
bad move, since it obviates much of the protection of the symmetric
cipher. The key exchange should never provide much less protection
than the symmetric cipher used...

@_date: 2015-11-22 15:37:19
@_author: Perry E. Metzger 
@_subject: [Cryptography] Pearl Harbor and Crypto 
According to Bamford's books, the NSA was showing off its
ability to track OBL using his phone communications to various
congressmen and press types in an effort to use that to lobby for a
higher budget, so the source of that leak was the NSA.

@_date: 2015-11-22 15:41:04
@_author: Perry E. Metzger 
@_subject: [Cryptography] 
=?utf-8?q?IS_has_=E2=80=98help_desk=E2=80=99_to_ai_d_would-be__terrorists?=
 =?utf-8?q?_with_encryption=29?=
There are a number of important details, however, such as the
dramatic difference in the speed with which the US could break things
in the PURPLE cipher vs. other Japanese codes, and even the speed
with which the Japanese themselves could process messages in the more
manually intensive systems.

@_date: 2015-11-23 11:17:58
@_author: Perry E. Metzger 
@_subject: [Cryptography] Dan Bernstein has a new blog entry on key 
That vaguely reminds of DES-X
The DES-X trick always struck me as cheesy -- it should not work,
since what it does is incredibly lame. And yet it seemed to be very
hard to attack.

@_date: 2015-11-23 11:21:26
@_author: Perry E. Metzger 
@_subject: [Cryptography] Dan Bernstein has a new blog entry on key 
Ah! I just posted about DES-X and hadn't seen your comment yet. (And I
should read that paper...)

@_date: 2015-11-23 15:57:05
@_author: Perry E. Metzger 
@_subject: [Cryptography] Dells are shipping with a rogue root level CA cert 
It seems that, not having learned from Lenovo's experience, Dell has
started shipping laptops with a Dell provided CA cert pre-installed. It is unclear what the CA is for, but there's a good possibility it
isn't good...

@_date: 2015-11-26 10:43:40
@_author: Perry E. Metzger 
@_subject: [Cryptography] Verified implementation of TLS: miTLS 
Formal verification of large software artifacts has finally become
quite practical. Thirty and even twenty years ago the tools were
simply inadequate and there was no way to perform the work in
reasonable time. Even in the last decade that has changed
dramatically. I believe this will be one of the biggest new frontiers
in systems and network security in the next decade or two.
Verification is not a panacea -- you can only verify properties you
think to ask about, and you inevitably have to make assumptions (i.e.
even formally verified hardware can't be proof against someone
physically modifying it.)
However, it is an astonishingly useful *ratchet*. If you verify a
property, and you specified the property correctly, no new bugs will
appear of that particular flavor. If you've formally verified (say)
that all encryption operations will take identical time (subject to
some model of caching behavior), no timing attacks will be possible.
If you formally verify that there are no buffer overflows, then no
buffer overflow attacks will be possible.
This ratchet effect is really useful. In our current paradigm for
building secure systems, we keep learning about more and more attacks
with time, but we are never sure, having discovered an attack, that
our systems have been made fully immune to it. Testing only goes so
far, and sometimes mistakes are made in tests, so the scope for
attacks keeps broadening as new attacks are discovered. With formal
verification, you can't be sure no new attack will be discovered, but
you *can* be sure you've closed the door to the old attacks, so the
balance between attack and defense can become significantly better.
In other words, you can finally make forward progress, because the
formal verification ratchet keeps you from backsliding. Even if, to
pick an example, you did a flawed timing proof that ignored caching,
and then someone attacked you using information about cache
properties, when it was discovered that this was possible, you could
fix your code and amend the proof to include those properties, and
you would not backslide.

@_date: 2015-11-28 09:15:20
@_author: Perry E. Metzger 
@_subject: [Cryptography] And it goes on... 
I'm listening to a purported security "expert" (a professor at
Georgetown named Bruce Hoffman) explaining on NPR's Weekend Morning
Edition that the Paris attacks were possible because of encryption.
Scott Simon also fed him a question about whether this was all
because of Edward Snowden, which Prof. Hoffman of course ran with.
This "expert" is also claiming that there are diminished resources
these days for the anti-terrorism agencies (which is of course the
opposite of true.)
No attempt is being made to probe whether any of his claims are
correct. No actual communications security expert was brought in as a

@_date: 2016-08-29 09:34:41
@_author: Perry E. Metzger 
@_subject: [Cryptography] Programming language technology (was Re: "NSA-linked 
We could do much better still now that dependently typed languages and
the like have been invented. Incredible strides have been made in
both the theory and practice of programming language and language
system design in recent years. Unfortunately most people are unaware
of this work.

@_date: 2016-08-29 09:52:26
@_author: Perry E. Metzger 
@_subject: [Cryptography] ORWL - The First Open Source, 
As a practical matter:
1) Where are the open fabs where I can get a trusted processor design
fabricated, and at reasonable cost?
2) Given the effectiveness of incredibly simple malicious hardware
additions, some of which are difficult to notice even with a careful
destructive analysis of the fabricated part, how can I verify that the
fabricated design is indeed what I expected and consistently so?
I don't think practical and cost effective solutions to these
problems exist.

@_date: 2016-08-29 12:32:27
@_author: Perry E. Metzger 
@_subject: [Cryptography] ORWL - The First Open Source, 
Why should I trust any of these designs in particular? Are they
formally verified? Is there any other particular reason to feel
they're safer? If not, at best I'm guessing that they're safer than
commercial hardware.

@_date: 2016-08-29 15:11:48
@_author: Perry E. Metzger 
@_subject: [Cryptography] What is a safe CPU? (was Re: ORWL - The First Open 
Ignoring the FPGA question and concentrating entirely on what is
meant by "secure" here, there are of course several levels, two of
the more obvious ones being the design and the fabricated
realization of that design.
Going from the bottom up:
1) One wishes to assure that the processor returned to you by the
fabrication facility follows the precise instructions for fabrication
you gave to that facility. That is, you wish to know that the masks
you specified were the ones that were actually used, that no extra
dopant was injected into a key transistor (see that particular
attack), no extra circuits have been added, none have been disabled,
Knowing that this is truly the case is Very Very Difficult, but there
is at least a known physical process for doing it. You have to take a
statistical sample of what is returned by the fab and literally tear
the things apart in a very expensive lab, removing layer after layer
of the chip and assuring that what is there is precisely what was
supposed to be there.
2) One wishes to assure that the specified realization of the gate
level design (that is, the implementation of the gates in terms of
actual transistors and wires placed in real world locations on the
chip) possesses no unknown/unwanted behaviors or side channel
This can be very challenging indeed given that bad placement of long
wires or transistors could produce all sorts of weird behaviors.
For a normal microprocessor things are quite difficult already in this
regard -- it might be possible, for example, that analog level
electrical glitches that alter externally observable behavior could be
achieved by executing instructions in particular patterns. This has
considerable precedents in the literature -- such things have actually
happened. I do not know that we currently have reliable tools, even at
the theoretical level, for handling this problem, though things like
design rules and the like help a bit.
For a secure enclave, smart card, etc. that might operate in a
hostile environment, the problems are far worse. The attacker might
do things like injecting noise into the processor's power supply
lines or certain data lines to alter its behavior. (Power glitching,
for example, is a well known attack, able to bypass secure execution
of code by stopping the processor from executing particular
instructions in its firmware reliably.) The attacker might also
employ side channel attacks to try to extract securely held
information and the like, and there are a lot of side channels
available to the attacker when they have complete physical control
over a "secure" piece of hardware.
3) Going up the stack again, one would wish to assure that the network
of gates in the gate level version of the design, presuming that the
gates operate in an idealized manner, faithfully implements the
abstract specification of the processor.
Here we at last reach the level where things are sort of possible,
just really hard.  One can model the behavior of the processor in a
formal language (say, Coq or what have you), and then if you produce a
mathematical theorem showing the equivalence of the gate level design
to the specification you're done.
Note that doing this isn't easy at all, I'm just noting that the
problem is at least finally well defined, unlike problem (2).
4) At a higher level still, one presumably (see (3)) is in possession
of a description in a formal language of the exact behavior of the
processor. One may then ask for various theorems about the security of
the specified design.
For example, one might ask "is it the case that no sequence of
instructions other than some specified system call gate or trap
instructions will allow the user to enter supervisor mode" or "is it
the case that no mechanism exists by which unprivileged code may
directly alter memory pages that are not mapped into that user's
address space" and the like.
5) And now we come to a general principle finally.
Benjamin Pierce (in "Types and Programming Languages" I believe) notes
that a good operational definition of a "safe" programming language is
one whose behavior is completely specified by its manual or spec.
For example, in C, the effects of running off the end of an array or
using a random integer as a pointer and writing to it are not things
you can know a priori from the C spec, so C is not a safe language.
Although you can certainly create perversely bad programming language
designs that are very difficult for ordinary people to work in, this
"everything you need to know is in the manual, works just like
specified" seems like a good first order approximation of what we mean
by a "safe programming language".
So similarly, perhaps what we mean intuitively by a "safe
microprocessor" is one in which the well specified high level
description of the processor (a formalization of the manual) is
faithfully carried out by the low level slab of etched silicon that
you've been handed to actually use. This is only an approximation of
what we mean by "safe" since we still want the sort of properties in
(4) to hold, but I think it's a good first order approximation.

@_date: 2016-08-29 17:42:14
@_author: Perry E. Metzger 
@_subject: [Cryptography] ORWL - The First Open Source, 
Of course, BERI and CHERI are secure in a distinct sense -- they are
implementations of a capability architecture on top of the more
ordinary MIPS instruction set. They are not, however, formally
verified designs, and in that sense, are no more or less likely to
have bugs or back doors than any other soft core design.
However, taking it as an entirely distinct topic from being able to
trust that one's hardware isn't malicious, I will note that the
BERI/CHERI design is a very interesting one, and I'm hoping this
research helps capability architectures make a comeback.

@_date: 2016-08-29 17:56:08
@_author: Perry E. Metzger 
@_subject: [Cryptography] FBI says foreign hackers have penetrated US state 
Quoting the news story: "The FBI has uncovered evidence that foreign
hackers penetrated two state election databases in recent weeks,
prompting the bureau to warn election officials across the country to
take new steps to enhance the security of their computer systems,
according to federal and state law enforcement officials."

@_date: 2016-08-29 18:11:19
@_author: Perry E. Metzger 
@_subject: [Cryptography] ORWL - The First Open Source, 
That would be quite the coup! I'm looking forward to the existence of
a formally verified architecture. Please do mention it here when it
happens. (That said, I wish this was on top of RISC-V or some similar
non-proprietary architecture, as MIPS has associated IP issues.
Still, I won't look a gift horse in the mouth!)
I'm less sanguine, but it clearly would be a wonderful thing.

@_date: 2016-08-30 17:24:56
@_author: Perry E. Metzger 
@_subject: [Cryptography] Capability Systems (was Re: ORWL - The First Open 
And you shouldn't resist it. :)
[... lots more good stuff elided.]
Capability systems are an underused tool. I was very impressed a few
years ago by Robert Watson et al's "Capsicum" paper, which showed how
to graft a capability system on top of a POSIX style OS in a fairly
reasonable fashion.
(One of the co-authors on that is Ben Laurie who contributed earlier
in this thread.)
I hope these ideas get spread around. They're a critical tool for
security architecture. (And I hope to someday see Capsicum as part of
the mainline Linux kernel.)

@_date: 2016-02-19 17:43:41
@_author: Perry E. Metzger 
@_subject: [Cryptography] On the false choice between privacy and security 
Many commentators are referring to the current fracas over strong
encryption and other security technologies, including especially
Apple's refusal to provide the FBI with hacking tools for the iPhone,
as a trade-off between privacy and security.
Even people who feel that strong security technologies are a good
thing often position things as a trade-off of this sort.
I would like to reiterate something many of us already know: *this is
an entirely false dichotomy.*
Backdoors in security systems don't just eliminate privacy, *they also
make systems insecure*.
The current fight isn't just to make sure that the government cannot
learn that you're reading dissident publications or to make sure the
government cannot automatically find everyone who has opinions it
doesn't like, although those are certainly worthy things to want.
The current fight is about whether we will impose a technological
infrastructure which will be exceptionally vulnerable to attackers in
order to provide nothing more useful than some very, very short-term
advantages to people investigating crimes.
This pits the interests of everyone in society who depends on
technology for their safety, which is to say, more or less everyone,
against a tiny group of law enforcement officials who find their jobs
somewhat more difficult.
We should remember that the damage caused by insecurity in our
critical systems is not theoretical -- it is pervasive problem even
today. We saw only this last week a hospital forced to pay ransom to
restore its computer systems.  We've seen instances in the last year
of the US federal government losing data on literally everyone with a
recent security clearance to enemies unknown who presumably are very,
very interested in knowing who all those US government agents might
be. Untold millions of dollars are stolen every day in various sorts
of computer fraud -- everything from credit card fraud to fraudulent
IRS e-file refunds. We already know that you can do horrible things to
SCADA systems and the like that could potentially kill people, and
whether you believe that's already happened or not, it is clearly
only a matter of time before people die that way.
All of this is because of lack of security in computer systems -- a
lack of security that the FBI, Cyrus Vance Jr., and other special
interests *propose to make dramatically worse on a permanent basis*,
in order to make their jobs somewhat easier for the short term.
Imagine what things will be like in a world where Cyrus Vance has a
slightly easier job but maniacs who have stolen US government master
crypto keys can cause thousands or millions of automated cars to
crash, killing their occupants.
So, please stop making it sound like it is merely the right to privacy
that is at stake. Certainly the right to privacy is crucial for our
society, but even those who do not agree with privacy should
understand that back doors are not about making a trade-off in favor
of increased security but in favor of pervasive *insecurity*.
This is not about security vs. privacy. We're talking about nothing
less than deranged short-term thinking that privileges the convenience
of a small part of the machinery of law enforcement over the safety of
almost everyone in our entire society.

@_date: 2016-07-14 18:22:35
@_author: Perry E. Metzger 
@_subject: [Cryptography] House Homeland Security Committee Majority Staff 
Rather interesting stuff. The introduction correctly points out that
the tradeoff is not between security and privacy but between security
and security, but it then goes on to say the matter needs to be
discussed more by experts. I haven't gotten past that part myself.

@_date: 2016-03-01 10:07:11
@_author: Perry E. Metzger 
@_subject: [Cryptography] DROWN attack on SSLv2 enabled servers 
TL;DR: if you have an TLS/SSL enabled service running on your
machines that willingly speaks SSLv2, you need to upgrade your systems
immediately, preferably by updating your SSL implementation but
at the very least permanently turning off SSLv2. This is because
SSLv2 can be used in an oracle attack to decrypt sessions that used
more secure versions of the TLS/SSL protocol.
Paper is at

@_date: 2016-03-01 17:19:32
@_author: Perry E. Metzger 
@_subject: [Cryptography] Whit Diffie and Martin Hellman win ACM Turing Award 
"Cryptography Pioneers Receive 2015 ACM A.M. Turing Award
    Whitfield Diffie, former Chief Security Officer of Sun
    Microsystems and Martin E. Hellman, Professor Emeritus of
    Electrical Engineering at Stanford University, are the recipients
    of the 2015 ACM A.M. Turing Award, for critical contributions to
    modern cryptography."
Full press release:

@_date: 2016-03-02 14:19:23
@_author: Perry E. Metzger 
@_subject: [Cryptography] Side channel attack on OpenSSL ECDSA on iOS and 
[My comment -- not clear if this has real practical implications but
it shows yet again how hard it is to do this stuff right. --Perry]
Cryptology ePrint Archive: Report 2016/230
ECDSA Key Extraction from Mobile Devices via Nonintrusive Physical
Side Channels
Daniel Genkin and Lev Pachmanov and Itamar Pipman and Eran Tromer and
Yuval Yarom
Abstract: We show that elliptic-curve cryptography implementations on
mobile devices are vulnerable to electromagnetic and power
side-channel attacks. We demonstrate full extraction of ECDSA secret
signing keys from OpenSSL and CoreBitcoin running on iOS devices, and
partial key leakage from OpenSSL running on Android and from iOS's
CommonCrypto. These non-intrusive attacks use a simple magnetic probe
placed in proximity to the device, or a power probe on the phone's
USB cable. They use a bandwidth of merely a few hundred kHz, and can
be performed cheaply using an audio card and an improvised magnetic

@_date: 2016-03-02 15:15:57
@_author: Perry E. Metzger 
@_subject: [Cryptography] iPhone hardware attacks 
I keep wondering what the odds are that the NSA has no method
available to decap the chips within an iPhone and extract secret
keying material. I suspect they must be able to do that, even from one
of the more modern iPhones with hardware based security modules.
The techniques for doing this sort of thing are both well known and in
the open literature. Even skilled amateurs manage such feats on older
hardware quite routinely -- I've personally witnessed chips being
decapped and put into university grade equipment for analysis. Given
the NSA's budget and mission, it seems highly, highly unlikely that
such methods are unavailable to them.
This brings up another question. FBI officials have testified under
oath that there is no government agency that can extract such
information on their behalf. Is that very careful spin, willful
ignorance, or simple perjury?

@_date: 2016-03-02 16:49:32
@_author: Perry E. Metzger 
@_subject: [Cryptography] iPhone hardware attacks 
You get to practice as often as you like, though. If a capability
proves important, you can do test runs as often as you need to raise
your probability of success to a high enough level for your

@_date: 2016-03-02 16:58:35
@_author: Perry E. Metzger 
@_subject: [Cryptography] The FBI can (almost certainly) crack the San 
In practice, though, it appears that the average user seems to be
better served by the security of the walled garden than by a system
which anyone with physical access can sabotage. (I include myself, by
the way, as an average user for these purposes.)
This is bothersome to me because, ideologically, I prefer completely
open systems, and in many practical respects I prefer them as well.
However, my odds of downloading dangerous iOS software are much lower
than my odds of downloading dangerous Android software, and it
appears to require some significant sophistication to attack the
physical security of an iOS device (though clearly not as much as has
been portrayed by the law enforcement community.)

@_date: 2016-03-02 17:03:39
@_author: Perry E. Metzger 
@_subject: [Cryptography] Google releases new hash function implementations 
"Today, we are open-sourcing 3 new hash function implementations:
faster, data-parallel versions of SipHash, a fast cryptographically
strong pseudorandom function, and the entirely new HighwayHash, which
reaches even higher speeds thanks to the data parallel features of
modern computers."

@_date: 2016-03-03 08:12:22
@_author: Perry E. Metzger 
@_subject: [Cryptography] The FBI can (almost certainly) crack the San 
If the option is available and simple enough to turn on, then
phishermen will find ways to induce naive users to turn it on, and
people doing supply chain attacks or "evil maid" attacks will turn it
on when they intercept equipment.
On the other hand, although I suspect that (say) Apple will do a
better job securing their equipment than I will, there are a
number of manufacturers of more specialized equipment for whom this is
*not* true and I want the ability, as a sophisticated user, to
tighten the security on their systems.
So, the situation is not cut and dried, and there are few obvious
clean answers. We live in a dangerous world.

@_date: 2016-03-03 16:07:30
@_author: Perry E. Metzger 
@_subject: [Cryptography] Vice: Amazon removes full disk encryption from its 
According to this report, while Apple has been busy increasing the
security of its products, Amazon has been reducing the security on
its equipment.

@_date: 2016-03-03 19:49:07
@_author: Perry E. Metzger 
@_subject: [Cryptography] Side channel attack on OpenSSL ECDSA on iOS and 
That said, the actual original quote from the OpenSSL people that the
paper authors corresponded with before the selective edits (see
another posting in this thread) indicates that the OpenSSL people are
sensitive to the issue and are trying to mitigate it in software when
For example, as was mentioned in that posting in this thread, the
OpenSSL people are indeed releasing code for several platforms that
should be more resistant to side channel attacks.

@_date: 2016-03-03 20:28:12
@_author: Perry E. Metzger 
@_subject: [Cryptography] Side channel attack on OpenSSL ECDSA on iOS and 
Absolutely. I didn't mean to suggest otherwise. I merely was noting
that the OpenSSL people *are* trying to do their best on this given
the limitations, and the selective quotation of what they said wasn't

@_date: 2016-03-04 13:37:47
@_author: Perry E. Metzger 
@_subject: [Cryptography] More Apple news 
One cannot, sadly, disbar someone for that which might merely be
astonishing ignorance.

@_date: 2016-03-05 13:40:09
@_author: Perry E. Metzger 
@_subject: [Cryptography] =?utf-8?q?Wired=3A_=22How_the_Feds_Could_Get_Into_?= 
"[A]ccording to experts who spoke with WIRED, thats not necessarily
the case. They say there are ways the government can extract data on
phones without Apples help, from using outside contractors to asking
its friends at the NSAways that it has, in fact, already used in the
past. The solutions wont work for every iPhone the government has
collected, and the solution offered for extracting data from the
phone in San Bernardino involves some speculation about the NSAs
capabilities. But they do raise questions about whether the
government has done everything it can do to collect the data it says
it needs."

@_date: 2016-03-05 16:23:27
@_author: Perry E. Metzger 
@_subject: [Cryptography] Susan Landau's written testimony before the House 
Susan Landau's written testimony for the March 1 hearing before the
House Judiciary Committee:

@_date: 2016-03-06 10:33:07
@_author: Perry E. Metzger 
@_subject: [Cryptography] EFF amicus brief in support of Apple 
There's no way the average person can build their own software from
source, and if they could, it still wouldn't say anything interesting
about the security of the overall system. Indeed, it likely would
*reduce* the security of the average system that still existed, though
of course in practice security would rise since no one would be
performing attacks for money any more since only one in every 5000
people would have a computer.
The tenor of such comments is always "there's a silver bullet here,
and it is open systems". Well, no, sadly, there are no silver
bullets. Security is hard, and remains (sadly) a set of trade-offs
between alternatives that are often quite mediocre. Regardless,
forcing your 80 year old grandfather who used to be a chef to audit a
few million lines of source code, compile them, and load them onto
his phone before he can make a phone call isn't going to help
anything at all.

@_date: 2016-03-06 12:33:28
@_author: Perry E. Metzger 
@_subject: [Cryptography] NYT: "Competing Interests on Encryption Divide Top 
New York Times:
   WASHINGTON  The intensifying legal battle over encryption between
   Apple and the Justice Department has all but obscured another more
   subtle division, the one inside the Obama administration itself.
   Driven by competing and sometimes clashing interests about privacy,
   national security and the economy, some of the presidents most senior
   aides are staking out a variety of positions on the issue.
   The White House denies there is disagreement over the effort to force
   Apple to break into the phone used by one of the terrorists in the San
   Bernardino, Calif., shootings, but the differences on how to deal with
   the broader questions raised by encryption have become increasingly
   apparent.

@_date: 2016-03-06 14:03:08
@_author: Perry E. Metzger 
@_subject: [Cryptography] EFF amicus brief in support of Apple 
Is it? Most users of the "walled gardens" people around here are very
fond of attacking seem to have fairly good security. Not superb, but
pretty good, and quite notably not worse than those people who are
operating on open systems and who do participate in trying to secure
their own systems.
Apple quite strongly asserts that their interest is in selling people
machines and not in selling data about their users.
That said, I will note that Google has been working very, very hard
at improving the security of various platforms, even ones they don't
sell (Project Zero has contributed many bug reports to Apple), and
they are indeed advertising based.

@_date: 2016-03-06 14:20:28
@_author: Perry E. Metzger 
@_subject: [Cryptography] EFF amicus brief in support of Apple 
I'm a practical person. I want systems that work, not that provide
some sort of philosophical warm fuzzies.
Now, I've spent a very large fraction of my career working on things
like open source operating systems for the love of it, and I'm very
sympathetic for feelings of affection towards those, but most of my
time has been spent on security work, and I've drawn some inexorable
conclusions from working on *that*.
One of those conclusions is that normal users (and that means
everyone, even security people, when they're trying to get their work
done) cannot be trusted to make decisions that will keep their systems
secure. You just can't remain alert every minute you're using a
computer. Nor, for that matter, is it rational to expect people to
want to.
Economies of scale are real things. It is nice for a hundred million
people to be able to download patches to their systems automatically
without even having to think about it or understand what a patch is
for that matter. We've learned that the risks associated with the
automated patching systems are much lower, in practice, than the risks
of unpatched systems. It is nice for people to be able to download a
game or a to-do application without having to personally audit the
code, and we've found that systems that make this easier even at the
cost of openness (say, iOS) seem to work better than those that are
more flexible about it (say, Android).
Where's the evidence for your assertion? If you look at Android vs.
iOS, iOS, with its much more restrictive environment, seems (as a
practical matter) to be more secure.
There are hundreds to thousands of people in the world who can't
compile their own operating systems for every one of us who can. What
you're suggesting is impossible. There is no way any of us who can,
in fact, compile an OS kernel would get any work done if we were all
expected to spend our days "offering to personally help" everyone
else do such things.

@_date: 2016-03-06 19:31:11
@_author: Perry E. Metzger 
@_subject: [Cryptography] DROWN attack on SSLv2 enabled servers 
I have no idea what this is intended to mean. However, the OpenSSL
people have been working very, very hard on cleaning up their code
since Heartbleed, and the security community has been focusing very
seriously on finding associated holes in the protocols and
implementations. After 1.1 gets released, a lot of the current issues
are likely to start sunsetting, though it will take some time for the
code to get widely deployed.

@_date: 2016-03-06 19:43:27
@_author: Perry E. Metzger 
@_subject: [Cryptography] EFF amicus brief in support of Apple 
You explicitly suggested that people should be compiling the code for
their own devices. Quoting you in an earlier message:
  You compute hardware should be completely open.
  You compute software should be completely open.
  You should fuse your own keys into your own hardware
  for software builds you reproducibly build sign and install
  yourself from distributed opensource software.
This is silly.
Just to remind people, your earlier assertion was:
   However, when a billion humans around
   the world *may* look at and even participate in the hw and sw if
   they wanted to, versus only 25 people locked in the coderoom of a
   megacorp whose primary raison d etre is by definition making
   money... the possible odds that it *could* be better and even a
   solution to everything as you say... are in fact better.
Your reply was:
I take it you have no specific evidence for your claim that you wish
to provide us with at this time.
And again, I do indeed very strongly prefer open source
software. However, there seems to be a utopian dream being asserted
here, not a hard claim with well established evidence. In the real
world, it seems that average users -- even people with incredibly
sophisticated understandings of the systems they're using -- are
generally better off being protected from their own errors.
Note that I don't want to *impose* such solutions on people, but it
does indeed seem that a lot of the time, you're a happier camper when
you pay some company to worry about your security on your behalf so
you can get on with your life instead of "fuse your own keys into your
own hardware for software builds you reproducibly build sign and
install yourself from distributed opensource software."
Ten years is a long time.
What you might reasonably complain is that a sample size of two is too
small. That said, I think we have pretty strong evidence that at least
sometimes, the iOS approach can have significant benefits for
users. It is entirely possible that in the hands of another firm the
walled garden would have been awful crap, but at least *some* of the
time, it seems to work pretty well.

@_date: 2016-03-07 09:37:22
@_author: Perry E. Metzger 
@_subject: [Cryptography] Washington Post op ed by Apple's Craig Federighi 
Apple's Craig Federighi explains in the Washington Post that
encryption is about security, not merely privacy, and that rolling
back security is a very bad idea.
We need more people to be emphasizing this point.

@_date: 2016-03-09 09:47:20
@_author: Perry E. Metzger 
@_subject: [Cryptography] All applications need top security (was Re: Director 
This reminds me of a widely misunderstood principle in secure systems
that I don't hear talked about much, so I'll bring it up now:
It is seemingly reasonable to say that your discussion with a friend
about what kind of beer to pick up for a party does not need the same
level of protection as a dissident discussing an upcoming attempt to
expose corruption in an election. It is seemingly reasonable to say
that a connection that is protecting an article about cat food does
not require the same level of protection as a connection that is
protecting a large banking transaction.
HOWEVER, the problem is that in practice, both activities will use
exactly the same protocols and software, identically configured. You,
as a protocol or software designer, do not get the luxury to provide
"appropriate" levels of security for different uses. In practice,
your protocols and software will sometimes be used for trivia and
sometimes for things that incredibly important and you will have to
design for the most important possible use.
Anyone saying that they don't "need or want" the best possible
security for their communications is, de facto, saying that no one
should get the best possible security, because even top politicians
text on iPhones, because even internal bank transaction systems are
front ended by Firefox or Explorer over HTTPS, because systems of all
sorts (even very secure ones) are administered over ssh, because
reporters working in places with hostile regimes use the same email
programs and systems as people trading baby pictures.
To say "I don't *need* or *want* the same level of security" is to
express ignorance of the real-world constraints on designers of secure
systems. We don't get to hand a teenager one communication application
and a Senator or top reporter another one -- both will, in the end,
almost certainly use the same one, and thus we need to assume the
threat model required by the most serious possible user.

@_date: 2016-03-09 14:44:41
@_author: Perry E. Metzger 
@_subject: [Cryptography] All applications need top security (was Re: 
I think the experience of the last few decades says "no, users are not
able to make security critical decisions of this sort in a reliable
way." We've tried for a very long time without success.
Note that I include almost everyone present here, including myself, on
that. It is simply too hard to make such decisions on a routine
basis. You will make mistakes.
It is better to simply presume you need the best security you will
ever need (say the same security you need when contacting your bank)
even if all you're doing is checking out prices on your online grocer.
I'm a big believer in removing as many security knobs from the user as
possible. As Ian (I think) has said on this list in the past, "there
should be one mode, and it should be secure".

@_date: 2016-03-09 14:52:18
@_author: Perry E. Metzger 
@_subject: [Cryptography] Would open source solve current security issues? 
I'm going to subtly disagree, in several ways.
First, and less importantly, modern software development practice no
longer has separate QA teams. These days, most reasonable places do
things like TDD and tests are written by the dev team itself.
Second, and much more importantly, the issue is "what kind of bugs?"
Although it does indeed seem true that bugs that the users notice and
cause them day to day trouble are shallow in open source systems,
because they are irritants to the user community, *security* holes are
a different sort of beast. Those require systematic audits, because
they are generally bugs that are tickled only in extraordinary
I think open source has produced really good results over time. I also
have very little evidence that the security of closed source systems
is better -- see, for example, the record of Microsoft Windows.
What we're talking about here is something different -- which is
whether users are (in general) better off with systems that prevent
them from running software that has not been vetted by a trusted third
party. That is to say, many people seem to be getting a benefit from,
in effect, paying Apple to vet all their applications for them.

@_date: 2016-03-10 07:44:06
@_author: Perry E. Metzger 
@_subject: [Cryptography] Would open source solve current security issues? 
Things have been changing rapidly. Old line firms are, of course, the
slowest to change, but that way of working -- even the notion of
having integration testing done on machines the devs can't touch and
thus can't debug on -- is going out the door. People realized a while
ago that this just isn't a viable model.
I won't disagree, but the problem is no different in the closed and
open source communities in this regard. Indeed, even if one can
afford a distinct QA team (which is, I think, a dubious
organizational choice in any case), I've seen no evidence it provides
value in reducing security bugs.
One of the general problems here is, I think, that systematic design
principles needed to avoid security bugs are not really
understood or followed by most software developers regardless of
whether their work is open or closed source.
I think we both agree on this last point, but it is of course
orthogonal to the question of whether it is better for the average
user to, in effect, pay someone to vet all the software that they use
and arrange things so unvetted software cannot be executed on their

@_date: 2016-03-14 16:13:19
@_author: Perry E. Metzger 
@_subject: [Cryptography] Richard Clarke interviewed on NPR's Morning Edition 
Former national security official Richard Clarke is interviewed about
the Apple case by NPR. He makes no bones about the fact that he
thinks the FBI has no case and should simply have given the NSA the
phone to crack if it really needed the contents.

@_date: 2016-03-14 16:23:29
@_author: Perry E. Metzger 
@_subject: [Cryptography] Wire.com: private communications, 
Can anyone explain what their business model is? They don't charge
for the app or for usage, and the money to keep the lights on has to
come from somewhere.

@_date: 2016-03-14 21:08:10
@_author: Perry E. Metzger 
@_subject: [Cryptography] Wire.com: private communications, 
Having started to read through their security whitepaper, they're
being exceptionally open about how everything works, which is nice,
but there's no apparent external code audit (anyone know)?
There's also a lot of weird little details -- they use ChaCha20 with
Axolotl, for example, but they encrypt large binary assets using AES
and send the keys via Axolotl. Stacking things this way means you're
not more secure than the least secure of the two crypto algorithms,
which seems unnecessary even if AES is highly unlikely to be
I haven't given the thing a lot of examination yet but I'd be
interested in getting the opinions of more people on the list.

@_date: 2016-03-16 13:15:41
@_author: Perry E. Metzger 
@_subject: [Cryptography] TLS 1.2 Long Term Support Profile Draft RFC 
From Peter Gutmann:
 This document specifies a profile of TLS 1.2 for long-term support,
 one that represents what's already deployed for TLS 1.2 but with
 the security holes and bugs fixed.  This represents a stable,
 known-good profile that can be deployed now to systems that can't
 can't roll out patches every month or two when the next attack on
 TLS is published.

@_date: 2016-03-16 22:00:43
@_author: Perry E. Metzger 
@_subject: [Cryptography] Formal Verification (was Re: Trust & randomness in 
Not to disagree with most of what you wrote, but as an aside:
On Wed, 16 Mar 2016 09:07:59 -0700 Henry Baker Most, no, but I've become a convert to formal methods in the last few
years. Until quite recently it was impossible to do real formal
verification work on programs of significant size, but that has
completely changed.
Two decades ago you couldn't have dreamed of writing a verified
program of any significant size, and now we have worked examples of
quite large formally verified artifact, including compilers, large
chunks of microprocessors, a microkernel, etc. etc.
Ah, there, I would direct people to the work done on the Quark
formally verified browser. The key insight in the Quark browser work
was that you can protecting a few million lines of crappy code by
caging it behind a small amount of formally verified code that
firewalls it from the world. Such formally verified software firewalls
are a really useful trick, and I expect them to play a big role in
remediating legacy systems.
Formal verification is not a panacea, will never be something we can
use for every program, and has serious limitations, but it is already
a really serious tool in the security world. A number of recent TLS
vulns were found via formal methods.

@_date: 2016-03-17 08:43:40
@_author: Perry E. Metzger 
@_subject: [Cryptography] Formal Verification 
Certainly there are points of comparison to what can be done with
static analysis, but overall the method is vastly more powerful. At
the cost of very substantial increases in development effort, it
provides you with certainty that the properties you have verified
actually hold for your code. Static analyzers generally only give you
best efforts (because they often cannot determine if particular
properties hold), and run time checks only go so far as well.
You can get really dramatic improvements this way. As just one
example: John Regehr's group at Utah has found hundreds of bugs in
almost every C compiler out there through the use of automated test
case generators and analyzers, but they've only found one in
the fully verified CompCert compiler, and that was arguably a case of
a broken Linux include file and not a bug in the compiler itself.
That said, verification can only find out if the properties you asked
about hold -- it cannot tell you what properties to check. That means
that you can fail to ask the right question. However, the advantage
is this: if you later figure out that you made a mistake and failed
to check an important property, once you add that to the things you
are verifying the hole is closed forever. Verification gives you a
ratchet, where problems, once found, can be *permanently* eliminated.
I will not disagree, and there are also many levels of verification.
Verification inevitably depends on assuming that some parts of the
system are working -- at the very least, you have to assume the
verifier is working since it cannot verify itself. You also, in
practice, are going to have to assume that the hardware was correctly
fabricated even if it was verified, and these days it is unlikely to
be fully verified itself, etc.
Still, the tool is *extremely* powerful, and I think even

@_date: 2016-03-17 09:58:19
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: Ad hominems are not acceptable. 
With my moderator's hat on:
This is a pure ad hominem. You ignored the substantive point Henry
brought up, which had nothing to do with Dan Geer and everything to
do with biological approaches to security, and decided to attack Dan
Now, if we were discussing Dan Geer that would be one thing,
but we can assess the ideas Henry is discussing without talking
about Dan Geer, and in fact Dan Geer is totally irrelevant to
evaluating those ideas.
Ad hominems aren't acceptable on this list. Do not do it again,
or your posting will not get forwarded.

@_date: 2016-03-17 10:01:36
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: No top posting, please. 
With my moderator hat on:
On Thu, 17 Mar 2016 01:11:40 -0700 Bill Cox [and top posted...]
A reminder to all: regardless of how the rest of the world does
things, we don't like top posting here on Cryptography. I let this
through because it was relatively innocuous in this instance, but in
general, please do not do it or your posting will be rejected.

@_date: 2016-03-17 14:21:24
@_author: Perry E. Metzger 
@_subject: [Cryptography] ZDNet: "US government pushed tech firms to hand over 
NEW YORK -- The US government has made numerous attempts to obtain
  source code from tech companies in an effort to find security flaws
  that could be used for surveillance or investigations.
  The government has demanded source code in civil cases filed under
  seal but also by seeking clandestine rulings authorized under the
  secretive Foreign Intelligence Surveillance Act (FISA), a person with
  direct knowledge of these demands told ZDNet. We're not naming the
  person as they relayed information that is likely classified.
  With these hearings held in secret and away from the public gaze, the
  person said that the tech companies hit by these demands are losing
  "most of the time."

@_date: 2016-03-17 15:40:47
@_author: Perry E. Metzger 
@_subject: [Cryptography] Skipjack is dead. 
Via Bruce Schneier, Skipjack has now been decertified by NIST.

@_date: 2016-03-18 08:12:48
@_author: Perry E. Metzger 
@_subject: [Cryptography] Formal Verification (was Re: Trust & randomness 
The langsec stuff is really, really important, and anyone who is
involved in security should be aware of what they're doing.
I'll note that it also ties in very nicely to formal verification as
one can formally verify that the program correctly handles the input
languages it is expected to deal with. Even figuring out the theorems
you are trying to prove is often hard in formal verification, and
this work gives us a nice handle on that part.

@_date: 2016-03-18 08:18:54
@_author: Perry E. Metzger 
@_subject: [Cryptography] Formal Verification (was Re: Trust & randomness 
The flaw was not in the formally verified portion of the flight
software, so this wasn't a flaw in formal verification, rather, it
was the lack of formal verification throughout the stack. The
formally verified portions were fine.
I will also point out that mere model checking isn't the state of the
art -- we can now do far better. CompCert, for example, is written
completely in Coq and then extracted into OCaml. One can (accurately)
claim that the fact that the OCaml implementation is not verified
creates a hole in the toolchain, but people are working to create
formally verified ML implementations.

@_date: 2016-03-18 12:04:27
@_author: Perry E. Metzger 
@_subject: [Cryptography] Formal Verification 
That is one way to look at things, but I'd say that it
isn't necessarily the way that leads to the most immediate
understanding of the methods that are currently under most intense
The state of the art on formal verification is dependently typed
lambda calculi (like pCIC which is the basis of Coq) coupled with
various sorts of tactic engines to help a human verifier out. We're
also now getting all sorts of interesting new technologies on the side
of this -- constraint solvers like Z3 may prove crucial in making
these technologies more useful.
Coq is very good at a version of this sort of thing, since the tactic
language is (in a real sense) a dialog conducted with the system to
help construct proof terms. I'm not aware of a system that
specifically allows you to add compiler optimizations by providing
proofs to the system but that would be a straightforward (though not
low labor) thing to do in some of the new systems out there.
Lisp is, of course, pretty close to the untyped lambda calculus. The
advantage of typed lambda calculi for this sort of thing is that one
can take advantage of the Curry-Howard isomorphism and have a single
language in which both proofs and programs are written. Indeed, Coq,
Agda, F*, Lean (which is brand new) and other systems that are under
active development all seem to follow this pattern of unifying a
constructive logic and a programming language through the use of
dependent types and Curry-Howard.

@_date: 2016-03-18 17:33:21
@_author: Perry E. Metzger 
@_subject: [Cryptography] Formal Verification (was Re: Trust & randomness 
Actually, in this case the failure was because of a section of the
system that was not verified. The verification of the other section
clearly reduced the bug count in the overall system.
Now, on the more general question, although it is true that
specifications can contain bugs as well, that's not a reason to think
formal verification isn't exceptionally useful.
For a real-world example, CompCert has a huge spec it has to
formalize. The key theorem proven about it is that it preserves
observational equivalence between source code written in C and the
output assembly code, which means that there is a full formal
semantics of C that the team had to create. (The full formal semantics
for the assembly language was much simpler.)
None the less, there have been essentially no bugs found so far in
CompCert. (There have, in fact, been two, but one was really a bug in
a Linux include file, and the other was a bug in a portion of the
separate compilation functionality about which nothing had been
formalized, and once that was pointed out, it was successfully
formalized and fixed.)
Most importantly, if there is a bug found in the spec, once it is
fixed, the bug will be guaranteed to be gone forever.
This is a feature formal verification has that ordinary testing does
not. In ordinary testing, you hope that a bug never reappears and that
your regression test for it is good enough, but it is rare that you
can be 100% sure. In formal verification, you get a ratchet. Once
you've fixed something, you will never make that mistake again, full
stop. The real world shows this actually works.
Sure, but the spec usually turns out to be dramatically simpler and,
more to the point, the spec provides the ratchet feature that I
describe above.
It also turns out that you can protect truly huge amounts of code with
fairly small formally verified "firewalls" that provide the sole
communication path to that software.
In general, you probably couldn't get a compiler from the formal
semantics for C or the statement of the theorem that you are
preserving those semantics in the output of your compile function.
And again, the big win is not perfection (which is difficult to
achieve) but rather the ratchet effect.
In general, systems like Coq do not find proofs on their own. They
provide a tactic language that allows a human to construct a
proof. That proof can be checked very quickly once created.
It is true that some of the tactics in Coq (like Omega, which invokes
a solver for Pressburger arithmetic) do seem like magic, of course. It
is also true that in the future there may be much more dependence on
powerful tactics as people come up with better ways of automating

@_date: 2016-03-18 17:55:21
@_author: Perry E. Metzger 
@_subject: [Cryptography] Formal Verification 
A formal semantics for both TCP/IP and for the sockets kernel
interface used on most flavors of Unix does exist:
It's written in Isabelle/HOL though I imagine it could be
mechanically translated into other systems like Coq with some effort.
I've heard that a formally verified TCP/IP stack had been attempted
subsequent to that but I haven't been able to rapidly confirm if that
was a real thing or memory problems on my part.

@_date: 2016-03-18 19:52:58
@_author: Perry E. Metzger 
@_subject: [Cryptography] Formal Verification (was Re: Trust & randomness 
You will find that much of the current Coq ecosystem is hard to use.
This isn't because the technology is inherently difficult to use but
because the people who have worked on all these tools to date have
been doctoral students and the like and have been more interested in
adding features than documentation, good error reporting, etc.
The error messages in Coq are particularly terrible. At the point in
a proof development where a tactic fails, the system has more than
enough information to tell you exactly what failed, which would help
you a lot with figuring out how to tweak what you're doing. However,
the system generally just tells you "that didn't work", which isn't
As these technologies become more widespread, I'm expecting to see a
lot of work on making them more usable by ordinary engineers as well.

@_date: 2016-03-19 16:35:11
@_author: Perry E. Metzger 
@_subject: [Cryptography] Formal Verification (was Re: Trust & randomness 
How could that possibly be when there were unverified components that
could clearly violate the deadlock invariant?
What was proven was not that no code built on top of this code would
be free of deadlocks -- what was proven was only that a model of the
code was free of deadlocks, and there was concurrent non-verified
Your claim makes no sense to me. Indeed, the paper doesn't seem to
make claims that would give one the impression deadlock properties
would be maintained by other subsystems that interacted with the
verified code. Can you point me to a quotation indicating otherwise?
But this isn't an instance of a ratchet.
To repeat, the "ratchet" effect is this: although you might forget to
validate some vital property and have a bug as a result, once you've
realized your mistake and added that property to the list of
properties you are verifying, bugs of that sort will never return
provided the verification is maintained as the software is maintained.
The deadlock described in the paper isn't anything like that. Indeed,
it was a property that the verified code was checked for, and this
problem happened in entirely unverified code.
BTW, your view here contradicts the paper's claims. I'm going to quote
an extensive section of the paper's conclusion here:
    This experience gave a clear demonstration that model
    checking can locate errors that are very hard to find with
    normal testing and can nevertheless compromise a systems
    safety. It stands as one of the more successful applications
    of formal methods to date. In its report of the
    RAX incident, the RAX team indeed acknowledges that
    it provides a strong impetus for research on formal verification
    of flight critical systems [13].
    A posteriori, given the successful partial results, one
    can wonder why the first verification effort was not extended
    to the rest of the Executive, which might have
    spotted the error before it occurred in flight. There are
    two reasons for that. First, the purpose of the effort was
    to evaluate the verification technology, not to validate the
    RA. The ASE team did not have the mission nor the resources
    needed for a full-scale modeling and verification
    effort. Second, the part of the code in which the error was
    found has been written after the end of the first verification
    experience.
    Regarding software verification, the work presented
    here demonstrates two main points. First of all, we believe
    that it is worthwhile to do source code verification
    since code may contain serious errors that probably will
    not reveal themselves in a design. Hence, although design
    verification may have the economical benefit of catching
    errors early, code verification will always be needed to
    catch errors that have survived any good practice. Code
    will always by definition contain more details than the
    design  any such detail being a potential contributor to
    failure.
    Second, we believe that model checking source code is
    practical. The translation issue can be fully automated,
    as we have demonstrated. The remaining technical challenge
    is scaling the technology to work with larger programs
    - programs that could have very large state spaces
    unless suitably abstracted. Abstraction is of course a major
    obstacle, but our experience has been that this effort
    can be minimized given a set of supporting tools.

@_date: 2016-03-21 21:18:46
@_author: Perry E. Metzger 
@_subject: [Cryptography] This is not the end... 
The FBI dropping its request under the All Writs Act, regardless of
its short term motives, is clearly not the end of Crypto War Mk. II
We can expect to see those who would eliminate our best tools for
computer and internet security for their own short term gain return
to attack again soon.
Next time, the world's technologists need to be much better prepared.
In particular, we need to explain to the media, right now, early and
often, that this is not about concealing your porn habits from
your spouse, but rather about making sure that malefactors cannot
break into SCADA systems and make nuclear reactors go critical.
We cannot rest, as short sighted and technologically illiterate
politicians will not rest.

@_date: 2016-03-21 21:23:46
@_author: Perry E. Metzger 
@_subject: [Cryptography] This is why we have Stuxnet 
[Terrifying story of incompetence elided.]
But you haven't let us in on who the vendor is.

@_date: 2016-03-22 08:31:11
@_author: Perry E. Metzger 
@_subject: [Cryptography] Formal Verification 
As did everyone else, including me, at that time. Again, the
technology has completely changed. It was de facto impossible back
then, and now it is something you can actually do.
The big change has been the development of systems like Coq where
dependent types and the Curry-Howard isomorphism are used to allow
proofs and programming to be done inside the same language and where
a combination of tactic based automation and human guidance are used
for the proofs themselves.
Again, for anyone who gave up on formal verification decades ago --
the world has changed. I would even go so far as to say that progress
is being made at an exceptionally rapid pace.

@_date: 2016-03-22 08:57:35
@_author: Perry E. Metzger 
@_subject: [Cryptography] And they're off... 
I've already heard news commentators wondering if the Brussels
attackers used "cryptography".
The security community has its work cut out for it. We really need to
educate the press or they're not going to understand the issue or the
stakes. We also can't wait for the opposition to make its move -- we
need to be out there at all times explaining the problem so that when
terrorism or other lobbying opportunities for the anti-security crowd
occur the understanding of the situation is already in place.
And please remember: the press has been convinced this is about some
sort of abstract desire for privacy vs. everyone's security, when in
fact this is about having the security we need to keep the world
safe vs. no one other than criminals having security.

@_date: 2016-03-22 11:22:42
@_author: Perry E. Metzger 
@_subject: [Cryptography] And they're off... 
I heard it on NPR this morning, and there have been a bunch of
incidents documented by people on Twitter.
Plus, I think we all know by now that under the "let no tragedy go
unexploited" doctrine, various government agencies will doubtless be
pushing on their media contacts.

@_date: 2016-03-22 13:58:24
@_author: Perry E. Metzger 
@_subject: [Cryptography] Chosen Ciphertext Attacks on Apple iMessage 
New paper on some cryptographic attacks on iMessage which have been
mitigated in iOS 9.3.
    Dancing on the Lip of the Volcano:
    Chosen Ciphertext Attacks on Apple iMessage
    Abstract:
    Apple's iMessage is one of the most widely-deployed
    end-to-end encrypted messaging protocols. Despite its
    broad deployment, the encryption protocols used by
    iMessage have never been subjected to rigorous cryptanalysis.
    In this paper, we conduct a thorough analysis
    of iMessage to determine the security of the protocol
    against a variety of attacks. Our analysis shows that
    iMessage has significant vulnerabilities that can be exploited
    by a sophisticated attacker. In particular, we outline
    a novel chosen ciphertext attack on Huffman compressed
    data, which allows retrospective decryption of
    some iMessage payloads in less than 218 queries. The
    practical implication of these attacks is that any party
    who gains access to iMessage ciphertexts may potentially
    decrypt them remotely and after the fact. We additionally
    describe mitigations that will prevent these attacks
    on the protocol, without breaking backwards compatibility.
    Apple has deployed our mitigations in the latest
    iOS and OS X releases.

@_date: 2016-03-30 15:02:44
@_author: Perry E. Metzger 
@_subject: [Cryptography] New NIST standard for Format Preserving Encryption 
Format-preserving encryption (FPE) is designed for data that is not
  necessarily binary. In particular, given any finite set of symbols,
  like the decimal numerals, a method for FPE transforms data that is
  formatted as a sequence of the symbols in such a way that the
  encrypted form of the data has the same format, including the length,
  as the original data. Thus, an FPE encrypted SSN would be a sequence
  of nine decimal digits.
  FPE facilitates the targeting of encryption
  to sensitive information, as well as the retrofitting of encryption
  technology to legacy applications, where a conventional encryption
  mode might not be feasible. For example, database applications may
  not support changes to the length or format of data fields. FPE has
  emerged as a useful cryptographic tool, whose applications include
  financial-information security, data sanitization , and the
  transparent encryption of fields in legacy databases.

@_date: 2016-10-01 13:52:51
@_author: Perry E. Metzger 
@_subject: [Cryptography] Short segment on the Stossel show on digital 
I was on John Stossel's show talking about digital security issues,
Snowden, etc. The segment is a little under seven minutes long.
(And yes, Stossel's comment about the police being able to turn on the
microphone on your iPhone isn't strictly true, but it *is* true that
there have been NSA implants to do that, or so the ANT catalog
document says, and there was no time to get into that sort of

@_date: 2016-10-03 12:10:17
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: No personal comments, please... 
A note from your moderator:
In the course of a heated technical discussion where people have
strongly held views, it is often tempting to get personal about
things. However, this rarely improves the quality of a discussion.
I think a good rule of thumb is this: if you're having a technical
discussion, and you mention the other party at all or address them
directly at all, something may be quite wrong. There are rare times
when this rule fails, but usually, it is a good tip-off.

@_date: 2016-10-04 16:16:18
@_author: Perry E. Metzger 
@_subject: [Cryptography] Reuters: Yahoo secretly scanned customer emails for 
Reuters: Yahoo secretly scanned customer emails for U.S. intelligence
Just so everyone understands: This article tells us Yahoo didn't
merely cooperate with intelligence officials asking for selected
customer emails, but rather voluntarily built a platform to
systematically scan *all* customer email for things intelligence
officials might want to read and turning it over to them. The CISO
apparently resigned when he discovered this had been implemented
without the knowledge of the security team.
Shame on Yahoo for agreeing to do such a thing.
The shame is not only on Yahoo, however. The shame is also on the
government for demanding the ability in the first place.
Also note:
Yahoo's GC claims on their site that they fight such requests. That
claim appears to be false  he personally approved this one.
Choice quotes extracted from:
"We carefully scrutinize each request to make sure that it complies
with the law, and we push back on those requests that dont satisfy
our rigorous standards. When we are compelled to disclose data,
consistent with our Global Principles for Responding to Government
Requests, we disclose only as much data as is necessary to comply with
the request."
"We fight any requests that we deem unclear, improper, overbroad, or
unlawful."  Ron Bell, Yahoo General Counsel, who apparently signed
off on this.

@_date: 2016-10-04 16:17:26
@_author: Perry E. Metzger 
@_subject: [Cryptography] Signal now does desktops... 
Open Whisper's "Signal" messaging system now has desktop support, at
least if you are already signed in via an iOS or Android phone.
Anyone know the details of how that works behind the covers?

@_date: 2016-10-04 21:33:24
@_author: Perry E. Metzger 
@_subject: [Cryptography] Reuters: Yahoo secretly scanned customer emails 
Microsoft and Google have both confirmed in recent hours that they've
received no requests like this, and presumably they'd be under a gag
order if they had. Twitter will not confirm or deny, so they probably
have had such requests, though they're also currently in the middle of
suing over gag orders.

@_date: 2017-04-02 14:11:59
@_author: Perry E. Metzger 
@_subject: [Cryptography] Regulations of Tempest protections of buildings 
Although I believe that this book makes such a claim, and that
the author likely believed it to be true, I'm afraid I do not believe
there is in fact any law whatsoever that prohibits putting foil or
metal mesh in your walls. You would need to track down the actual law
before I would believe in its existence.

@_date: 2017-02-16 13:07:04
@_author: Perry E. Metzger 
@_subject: [Cryptography] Security proofs prove non-failproof 
I'm a very big fan of proofs. However, one has to recognize that
proofs do not demonstrate perfection. You can always have tried to
prove the wrong thing, and (especially for paper and pencil proofs)
there can be flaws in proofs just like there are bugs in programs.
In a related (but not exactly the same) case: it is especially
important to remember this when formally verifying code using modern
tools like Coq or F* or what have you. There's a temptation to think
that if you formally verify a piece of code that it is perfect and
bug-free. Not so. What you've done is demonstrate some set of
properties "almost certainly*" hold for the code, but those might
only be a subset of the properties you need to hold, or might be the
wrong properties entirely.
What formal verification gives you is a ratchet. You know that, if
you ask the right question, you will not backslide, and future
versions of your code will continue to have the property hold. This is
a very, very powerful tool, and one that I think is going to
revolutionize our field, but it is still a tool, not a panacea,
and you have to remain vigilant.
This will bite people a lot as formal verification becomes more and
more widely used, but I still think formal verification is worthwhile
in spite of it.
[*"Almost certainly" rather than "certainly" because (a) you may have
stated the properties you wanted incorrectly and (b) because there
can be no proof that your underlying logic is consistent, at least if
it is a useful underlying logic. (b) is especially troublesome in
systems where there's a lot of active development done on the formal
verification tools with relatively little use of formal tools to
assure the quality of the tools themselves -- ironically, for some of
these systems, there isn't even a formal description of the underlying
logic and the shoemaker's children still go shoeless. But that's
another discussion for another day.]

@_date: 2017-02-16 20:58:11
@_author: Perry E. Metzger 
@_subject: [Cryptography] Security proofs prove non-failproof 
And that was an utterly unfulfilled promise for a long time, just as
the promise of computers playing good games of chess was constantly
something said to be in the distant future, until suddenly it
was something that had already happened.
The big change in formal methods happened only in the last decade. We
now have several formally verified microkernels, a formally verified C
compiler that also doubles as a proof tool, we nearly have a formally
verified TLS stack (Project Everest), etc., etc. The number of
formally verified artifacts keeps multiplying and the complexity
involved keeps increasing. Where before, for example, seL4 depended on
having no concurrency to do the proof, CertiKOS's creators were able
to build a system that handles fine grained concurrency, and with far
fewer man-years devoted to the verification, thanks to substantial
improvements in methodology that happened in less than a decade.
What has changed since 30 and 40 years ago is that back then people
simply didn't know how to build the tools to aid others in doing
formal verification (and it turned out to be a very hard problem for a
number of reasons) but now we largely do understand. There's been a
huge revolution in understanding how, on an engineering level, to
structure the proofs as well. (It turns out that proof engineering is
a thing, just as software engineering is a thing.)
It's very early days yet -- I would compare current maturity in formal
methods to the world of compilers and language design in the
mid-1960s, where things were still far too ad hoc and yet to be really
made subject to truly sound engineering practice -- but things are
moving very, very, very rapidly indeed.
I disagree. Much of the difficulty in using a system like Coq now lies
in problems we understand how to solve, like terrible error messages
and terrible UI (mere matters of people doing the work rather than not
knowing how to do the work even in principle), rather than in problems
we don't know how to solve, like how to even go about doing the whole
thing in the first place.
I entirely disagree. I suspect that we're going to see serious
mainstream acceptance of the tools for high value products inside of
ten years, and we're *already* seeing use of formally verified
artifacts in some niche products. The main problems at this point are
making the tools more comfortable to use and educating people in their
You can run Coverity over a program every day and not find serious
problems in it that a formal verification will utterly
eliminate. Static analysis simply isn't able to do a lot of this
stuff. Yes, static analysis is great, but it isn't the same thing.

@_date: 2017-02-17 08:41:11
@_author: Perry E. Metzger 
@_subject: [Cryptography] Security proofs prove non-failproof 
So we already have some sense on that, believe it or not.
John Regehr's research group at Utah built some C compiler torture
devices a while back -- automated systems capable of generating and
testing huge numbers of code snippets that are specifically designed
to find bugs in C compilers.
Regehr's group found hundreds and hundreds of bugs in each of gcc,
clang, icc, etc. (which were all subsequently fixed.)  They found only
one in CompCert, and arguably it wasn't a CompCert bug at all but
rather a bug in a Linux .h file.
A second bug was also found in CompCert. If I recall correctly, there
hadn't been much verified about the separate compilation facility, and
a South Korean research group (I think it was South Korean) found a
bug in it, fixed it, and extended the verified properties to cover it.
Note that this is the sum total of bugs ever found in CompCert, and
neither was a property that was formally verified but turned out not
to hold.
Compilers are, however, sort of an ideal case for formal
verification. What you're doing in a compiler verification is
1) providing a formal semantics for the input and output languages
2) demonstrating the equivalence of what goes in to the compiler and
what comes out with respect to those formal semantics.
Finding an all-encompassing description of other sorts of systems can
be more challenging to say the least.
BTW, note also the interesting feature of that second CompCert bug. This
demonstrates what I referred to in my earlier email as
Bugs _will_ be found in formally verified systems if only because one
can't always think of everything one wants to verify, but, once a bug
is found and the new property is added to the set of verified
properties, that bug will _never_ reoccur.
Contrast this with what usually happens when a bug is found in
non-verified code. The single instance of the bug is patched, perhaps
some regression tests that may or may not fully exercise all the
involved cases is put into the test suite, and one hopes that the
thing doesn't show up again in another form.
The "ratchet" provided by formal verification is substantially more
powerful than ordinary testing in this regard. It provides assurance
that a bug will not re-appear rather than the hope that you thought of
strong enough test cases.
I think the latter is the big problem right now, and will remain so
permanently. Bugs in fully formal verification are likely to be rare
but will happen -- they can occur only if there are bugs in Coq (or
the equivalent) which have tended to be rare.
If they start happening more often, I suspect that the problem of the
shoemaker's children going shoeless will get more attention and those
systems will themselves get a lot more formalization. One cannot, of
course, prove the consistency of those systems (at least not within
themselves), but you can do a lot short of that.
I've noted that merely learning how formal verification works changes
your view of programming as well. You start thinking in terms of
things like pre and post conditions in a way you simply didn't before.

@_date: 2017-02-20 08:28:13
@_author: Perry E. Metzger 
@_subject: [Cryptography] Security proofs prove non-failproof 
Not actually true. seL4 is used in millions of baseband
controllers in mobile phones (to name one example) but I'll agree
that overall, penetration of these tools isn't so great *yet* compared
to everything else out there.
So what?
Imagine it was 1970 and someone said that writing operating systems in
high level languages was the future and you said "meh, other than a
couple of experiments (Multics) I don't know of any that have been
done that way and it certainly isn't the future." You would have been
absolutely correct about the present and absolutely incorrect about
the future.
It has been possible to formally verify significant pieces of software
*at all* for, what, ten years at this point? What fraction of the
programmers out there working on mission critical systems even know it
is possible at this point?
Give it another decade or two.
On the contrary, it is the only compiler out there where you can feel
reasonably safe that the output is correct!
If you're talking about performance, well, that's a reasonable
concern. But, for many purposes, I'd rather be safe than fast, and
we'll get fast eventually. It's all very new. Give it time.
(BTW, if you don't believe people often prefer characteristics other
than fast, I'll note that there are huge web applications out there
written in Ruby and Python right now.)
Anyway, with time, other compilers are likely to benefit from formal
verification, too. The LLVM world now has VeLLVM, which is a project
to produce a formal definition of the LLVM intermediate
representation, and they've demonstrated the ability to plug formally
verified optimizations in to LLVM and have them work. The fact that
LLVM is fully modular means you can replace parts with formally
verified replacements without having to toss the whole thing at once.
So yes, there are all these tools, and they're brand new, and in a
world of many millions of software artifacts, there are now a couple
dozen verified ones that not many people are using yet.
So, give it time.
The cliff is there because the UI sucks, the documentation is
mediocre, and you need to understand a bunch of type theory and formal
logic in order to make progress. Patience. Things will get better.
All the serious operating system guys said no one would ever use high
level languages for kernels, too, until suddenly everyone
did. And all the IBM people assured me that microcomputers were never
going to replace the mainframes. (To their credit, the mainframes
still, weirdly, sell, though they clearly are no longer even vaguely
We can discuss terms. I think the location is not exactly optimized
for a fair bet given that we're on exactly opposite sides of the
world, and that I'm not a steak person. We'll take that bit offline.

@_date: 2017-02-20 15:40:42
@_author: Perry E. Metzger 
@_subject: [Cryptography] Security proofs prove non-failproof 
I don't know a great deal about this specific topic, but my
understanding is that some run seL4. It would not surprise me if others
did not.

@_date: 2017-02-20 15:51:17
@_author: Perry E. Metzger 
@_subject: [Cryptography] Security proofs prove non-failproof 
There exist a number of formal proofs of security for protocols. My
understanding is that several such attempts have found significant
flaws in both proposed and deployed protocols.
(On a related note: In an earlier message, Peter expressed skepticism of
the usefulness of formal verification of protocol implementations
because, for example, a TLS implementation verification ran into a
question of an edge case that none of the "normal" implementations had
cared to even implement. I see such discoveries of holes in a
specification as enlightening rather than useless, as, historically,
protocol security flaws have often appeared in edge conditions that
"normal" implementers have ignored or not thought much about. Formal
specifications of protocols tend to smoke out such things. One of
course needs a formal specification of a protocol in order to determine
if a given implementation complies with the formal specification.)

@_date: 2017-02-20 18:38:48
@_author: Perry E. Metzger 
@_subject: [Cryptography] Security proofs prove non-failproof 
The UIs for current formal verification tools generally suck. That does
not mean that one necessarily wants "fancy" GUI tools, but one does need
error messages that aren't terrible and the like.
I posted this link, for the Deep Spec summer school, a few weeks
It is too late to be considered in the "first round" of applications,
but if there are still spaces available, one can still apply for them.

@_date: 2017-02-21 10:03:25
@_author: Perry E. Metzger 
@_subject: [Cryptography] Security proofs prove non-failproof 
I disagree. I think we don't know what the complete set of things that
constitutes security would mean (and we probably can't know), but we
have learned from experience a lot of things that mean *insecurity* and
we can establish that they aren't present.
We can prove that code takes the same amount of time and/or power to do
every cryptographic operation (or that otherwise those particular side
channels can't leak information). We can prove that code has no buffer
overflows, integer overflows, stack overflows, etc., and those proofs
mean something. We can show that particular attacks we know about that
have been used against cryptographic protocols in the past can't be
used against a particular protocol that is under consideration. We can
prove that particular parts of a system are well isolated from each
other. With time, we learn more and more things that we want to know
about our systems, and we can incorporate these into the set of
properties we want to verify.
Does this prove that code or a protocol is secure, let alone
absolutely secure? Hell no. Is it still very, very useful? Hell yes!
I think there's been a lot of time spent convincing ourselves, as a
community, that formal verification isn't very useful because for so
long it was impossible. So, it was psychologically nice to say "well,
we can't do it, but if we could do it it wouldn't be useful, so there's
no reason to fret over it."
Now, however, it is possible, and people are finding and stopping real
bugs with these techniques.
It *is* very important not to see them as magical panaceas. For too
long people have regarded formal verification as a way to show that
a system is perfect, and that is not what it does. Rather, it is a
way of showing that specific properties hold in the code, and as you
point out, we often don't even know what property we need to verify.
However, for properties you want to assure, proofs are an amazingly
strong "ratchet" that allows you to demonstrate that your code cannot
backslide against a given property you need it to have.

@_date: 2017-02-21 14:05:53
@_author: Perry E. Metzger 
@_subject: [Cryptography] Security proofs prove non-failproof 
I'm not familiar with the details of that situation (my schedule
hasn't permitted me to watch TLS for the last few years in much
depth). I would certainly hope that in the medium term, especially if
a lot of experience is gained, it should be possible to dramatically
increase the complexity of the protocols and code that can be subject
to formal methods. That sould help with the problem of people wanting
to shoehorn protocols into designs they can verify. (That said, it
will always be easier to verify cleaner, simpler designs, but I don't
see that as a flaw.)
Proof engineering is in its infancy right now. Given more experience,
it should be possible to do better, but there's only one way to get the
experience, which is for people to dive in and work hard on the problem.
I'll also note that if the software and protocol engineers leave it up
to other people to do the verification work, there won't be nearly as
much progress as there might be if the engineers learn a lot about how
to do this stuff themselves. This is one of the reasons I keep
encouraging people on the engineering side of the fence to learn about
these tools and gain practical experience with them.

@_date: 2017-02-21 17:23:36
@_author: Perry E. Metzger 
@_subject: [Cryptography] Security proofs prove non-failproof 
Then I stand corrected. (That said, there _are_ commercial users of
seL4, though it is clearly not a popular platform as a fraction of
deployed systems.)
And there we agree.

@_date: 2017-02-22 09:33:13
@_author: Perry E. Metzger 
@_subject: [Cryptography] Security proofs prove non-failproof 
Not C++ yet (because producing a formal semantics for C++ is a
nightmare), but for C, you can use techniques like those that were
used for programs like seL4 and CertiKOS, or packages like the
Verified Software Toolchain (VST), and prove that a chunk of code has
no such issues.
Currently this involves quite a lot of work, though the amount of work
involved keeps rapidly dropping. What you basically do is prove
properties of the code, and there can be no algorithm that finds
proofs in bounded time. However, there are large bits of automation
that can assist along the way.
I recommend looking in to VST if you're interested in doing this for C
specifically. It's not the only available tool but it's the best
packaged at the moment.
(You can also, at some runtime cost and sometimes at very serious
runtime cost, use mechanisms that will detect any such failure at
runtime and abort the program, but that's of much less interest if
you're trying to build a reliable, maximum performance system that
does not fail. The most thorough system I know of for this is
tis-interpreter, which is very slow but detects most forms of
undefined behavior.)
Not as a static analyzer, no. The halting problem is a thorn in the
side of many such dreams. However, you can *manually* verify that no
such conditions exist using a proof system.

@_date: 2017-02-22 10:07:55
@_author: Perry E. Metzger 
@_subject: [Cryptography] Security proofs prove non-failproof 
There are tools like Valgrind, of course, that do much of this sort of
thing at runtime while debugging that help with finding the precise
location of a memory leak.
Note that while checking that all allocs and frees match is useful, it
doesn't point out the biggest potential source of error in allocated
memory, which is use after free. Valgrind does do that IIRC.
And, as has been previously discussed, there are much more modern
tools, including the various LLVM sanitizers (like LeakSanitizer and
AddressSanitizer) that are built in to clang.
However, all such mechanisms are fairly weak compared to what true
formal verification can do.
That's much more of a paper and pencil sort of proof than "quasi" formal
verification. In the real thing, you use an automated proof assistant
like Coq that mechanically checks the proofs involved, and which is
not subject to getting tired or otherwise making a mistake. (After
all, the whole reason you have bugs in your code is that humans are
Unfortunately, even the best regression test suites, though vastly
better than not testing, are still nowhere near as good as what formal
verification can do for you. The problem is, of course, that you
cannot know that you've covered all possible cases without a proof.
One popular technique in formal verification is the use of Hoare logic
and its descendants, which is where the notion of pre and
postconditions comes from.

@_date: 2017-02-22 10:10:41
@_author: Perry E. Metzger 
@_subject: [Cryptography] Security proofs prove non-failproof 
I believe (correct me if I'm wrong) that CMBC is oriented towards
proving the safety of things like pointer operations.
The Verified Software Toolchain is a very general tool for verifying C
programs for arbitrary properties. It's been used, for example, to
fully verify the correctness of cryptographic code.

@_date: 2017-02-22 21:51:35
@_author: Perry E. Metzger 
@_subject: [Cryptography] Security proofs prove non-failproof 
Not really. Or at least, projects like CompCert, seL4, etc., set
themselves up to do long term maintenance of the proof in parallel
with the code.
Well, if you talk to Test Driven Develpment types, you also can't test
code that wasn't designed for test and didn't have tests built in
parallel with the code and maintained in parallel with the code. If
you do want to retrofit existing code for TDD, you have to go through
a large effort to refactor it and add tests everywhere, and it isn't a
small thing. (See books like Feathers, "Working with Legacy Code",
which defines "Legacy Code" as any code that doesn't already have a
complete test infrastructure.)
This is much the same situation as trying to bring a reasonable test
infrastructure to legacy code (see above definition). You have to
build a proof infrastructure that is maintained in parallel with your
The correct paradigm isn't "build large system, then hope it works",
it is "build large system with test infrastructure in parallel" or, in
the proof world, "build large system with proof infrastructure in
parallel". If you don't have such an infrastructure and have a legacy
system, you need to go through a large engineering effort to add one,
and then you maintain it going forward.
BTW, in the world of systems like VST, you most certainly do *not*
massage the code and prove things about the massaged code. You work
with the actual code.
Correct. You can't plan to do this once, you have to build this as
part of your software engineering effort, and with the expectation
that the proof infrastructure gets maintained in parallel.

@_date: 2017-02-23 08:52:12
@_author: Perry E. Metzger 
@_subject: [Cryptography] Practical SHA-1 collisions 
Quoting: "It is now practically possible to craft two colliding PDF
files and obtain a SHA-1 digital signature on the first PDF file which
can also be abused as a valid signature on the second PDF file."

@_date: 2017-02-24 11:02:35
@_author: Perry E. Metzger 
@_subject: [Cryptography] Security proofs prove non-failproof 
Sure, but formal verification is much more extensive than that.
For example, say that you want to show not only that the scheduler in
your operating system will not access past the end of an array,
but also that it will faithfully schedule things.
Or say that you want to show that your sorting function is not only
free of buffer overflows and integer overflows but also actually
returns a sorted version of its input.
Or say that you want not only the assurance that your program won't
unknowingly exhaust its stack but the assurance that it will never
even try to do so, and thus will not crash from stack exhaustion.
Or, at a much larger scale, say you want to know not merely that your
compiler won't crash, but that it compiles code _correctly_.
Formal verification will do that, while smart pointers and the like
will not.
The point of formal verification isn't to merely assure that you have
a safe language (in the sense that C is not safe but OCaml is) in
which you won't get things like array bounds violations, but to prove
that the program meets a logical specification of its behavior.
For example, to take the sorting example, without knowing anything
about how the sort function works internally, I can specify that its
output must be a non-decreasing ordered permutation of the input. If I
can prove that this is true, I know the sorting function will _always_
do what I expect.
In the case of CompCert, there is a mathematical theorem, mechanically
checked in Coq, that the output machine language program behaves in a
way that's observationally indistinguishable from the input C language
program. This of course requires a detailed specification in formal
logic for how a C program is supposed to behave, and one objection
might be that *this* might have bugs, but so far, no one has found
such a bug* in the released CompCert compiler, likely because of the
care taken with the formal specification.
Regardless, though, the knowledge that the compiler's output is very
very likely faithful is a much higher standard than knowing it does
not leak memory.
(*In fact, as I mentioned in a previous message, that's not strictly
true. Two bugs have been found to my knowledge, but one was in an
include file and not in CompCert, and the other was in a previously
unverified property of separate compilation. This is still an enormous
contrast to the number of bugs routinely found in GCC and other

@_date: 2017-02-26 20:25:44
@_author: Perry E. Metzger 
@_subject: [Cryptography] More efficient block-chain ledger: Micali's 
But apparently not very good if I'm to judge by what you've posted.
I don't think yhou've shown this.
This linked article doesn't seem particularly rigorous. It also seems,
quite frankly, rather slanted.
There are defenses against Sybil attacks.
But they'd have to hack all of them, and quickly.
I don't think it does, no.
There are, again, defenses against Sybil attacks known.
Anyway, without going on further, I think you're throwing things at
the wall, not addressing the original paper in a rigorous way.

@_date: 2017-02-27 09:27:34
@_author: Perry E. Metzger 
@_subject: [Cryptography] Google announces practical SHA-1 collision attack 
So, as it happens, I know some organizations which have a definite
reason to worry about SHA-1 collisions being possible in this price
range. Yes, about mere ability to generate collisions and not
preimages. Sadly, I have an obligation to be very vague.  But let me
say, IMHO, although many or even most users don't have to panic, some
organizations absolutely do have reason for concern.
The other problem here, of course, is that as we've found out over and
over again in this business, merely because the average user of your
software or protocol is just protecting their grocery list doesn't
mean that someone with real risk isn't also going to use your
software. My classic example (which isn't relevant to the SHA-1 case
but is generally illustrative) is that the same instant message
software will be used by spouses telling each other to pick up more
eggs on the way home and by reporters talking to confidential sources.
It's all a question of what you're securing and how you are securing
it. Not everyone is trying to protect low value information.

@_date: 2017-02-28 15:22:16
@_author: Perry E. Metzger 
@_subject: [Cryptography] formal verification +- resource exhaustion 
It's a property to be verified, like any other property you might
want to verify.
Verifying that you cannot overflow your (limited) stack or that you
will not allocate more memory than a particular limit or that if you
do allocate too much memory you still fail gracefully (by some
definition of gracefully) are all properties that you can specify and
then attempt to verify. (One of the harder bits the first time you
try it is figuring out how to express the property at all in a formal
Some things are harder to verify than others because the community
doesn't yet have deep enough experience in doing such verification,
but the state of the art is rapidly improving. The first real
verification of the safety of concurrent operating system code was
quite recent. Verifying real time properties (like that you are
guaranteed to get enough CPU time often enough for your real time
task) is still quite hard but serious progress is being made on
making it more routine.
In many ways the situation is reminiscent of the 1960s to early
1970s, when a new garbage collection algorithm might still be
noteworthy enough to publish in CACM. Right now, instead of learning
the fundamentals of algorithms and data structures needed for
building higher level constructs on top of, the community is learning
the fundamentals of proof techniques to use in various circumstances,
and how to do the proof engineering so the proofs remain robust even
in the face of code that gets updated. The speed with which
techniques are being developed is quite high.

@_date: 2017-01-31 12:33:59
@_author: Perry E. Metzger 
@_subject: [Cryptography] Fw: DeepSpec Summer School on Verified Systems -- 
[I believe this topic is of substantial interest to readers of this
list. Formal verification, once seen as an impossible goal, is
now rapidly becoming a real software engineering tool, and I think it
will transform both our protocols and our implementations. This is
an unparalleled opportunity to learn about it. --Perry]
Begin forwarded message:
The first DeepSpec Summer School on Verified Systems will be held in
Philadelphia from July 17 to 28, 2017, preceded by an introductory
Coq Intensive from July 13 to 15.  Applications are now open:
          .
Can critical systems be built with no bugs in hardware, operating
systems, compilers, crypto, and other key components?  It may seem a
pipe dream, but the past decade has seen remarkable advances in the
technology required to realize it.
This summer school aims to give participants a wide-ranging overview
of several ambitious projects currently underway in this space.
Participants will gain a thorough understanding of the conceptual
underpinnings of these projects plus considerable hands-on experience
with the state-of-the-art tools being used to build them.
The summer school will open with a three-day intensive course on the
fundamentals of the Coq proof assistant, for participants who are new
to Coq. The main lectures take place during the weeks of July 17 and 24.
Lecturers and Topics
Andrew Appel            Verified functional algorithms
Adam Chlipala           Program-specific proof automation
Frans Kaashoek & Nickolai Zeldovich     Certifying software with crashes
Xavier Leroy            The structure of a verified compiler
Benjamin Pierce         Property-based random testing with QuickChick
Zhong Shao              CertiKOS: Certified kit operating systems
Stephanie Weirich       Language specification and variable binding
Steve Zdancewic         Vellvm: Verifying the LLVM
More information
To apply, or for more information, please visit
   .
Applications received by Feb 15 will be given equal consideration;
applications received after Feb 15 will be considered on a space- and
funds-available basis.

@_date: 2017-06-08 16:07:01
@_author: Perry E. Metzger 
@_subject: [Cryptography] Crypto Books, 2017 
A quick question to all: if you were teaching beginners cryptography
twenty years ago, Schneier's "Applied Cryptography" would have been
the obvious choice.
Is there an obvious choice in 2017?

@_date: 2017-06-11 11:36:21
@_author: Perry E. Metzger 
@_subject: [Cryptography] Crypto Books, 2017 
I would have imagined some loud opinions here. :)
So asking again: if you're teaching cryptography to rank beginners
these days, what are the books that people prefer?

@_date: 2017-06-11 15:59:53
@_author: Perry E. Metzger 
@_subject: [Cryptography] Crypto Books, 2017 
Katz & Lindell's "Modern Cryptography" has been suggested to me by
others as well.
I've also stumbled across Nigel Smart's online "Introduction to
Cryptography" (3rd Ed. is only available as a free download), though
I've not heard anyone else mention it in my poking around.

@_date: 2017-03-01 11:31:18
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: Jamming the jammers conversation. 
The jammers conversation is fun but not really shedding a lot of
useful light. Please don't post more about it except if it's really
useful rather than amusing.

@_date: 2017-03-01 12:38:32
@_author: Perry E. Metzger 
@_subject: [Cryptography] On New York's new "Cybersecurity Requirements for 
New York State's Department of Financial Services recently published
its brand new regulation for banks, insurers and other similar
companies entitled "Cybersecurity Requirements for Financial Services
The regulation will likely apply to a large swath of the world's
commercial and investment banks and insurers because they do business
in New York. It got a bunch of notice in the financial press as a
The document is short, and I suggest anyone interested in the debate
about what sort of involvement government can usefully have in
computer security regulation should read it.
Often, people propose that the problem in computer security is that we
don't have enough regulation. If only the government were involved, we
would be doing a better job. I've heard this quite a lot, especially
from politicians and other people who are not security professionals.
However, no one can ever quite articulate what it would be that the
government would ask companies to do differently. Would it be to tell
them to rotate passwords frequently or similar worst practices that
actually reduce security? Would it be to tell them to make sure that
their software has no bugs?
Or would they choose the more benign but none the less not very useful
approach of telling everyone to make sure they've been careful and to
mandate that they be careful by making them file lots of paperwork
saying they're being careful and punishing them if they fail to file
the paperwork on time?
New York State has taken this latter approach.
I will not claim that the people charged with writing this regulation
did badly given what they were told to do. They did what was
reasonable given an impossible demand made on them by the governor and
other politicians, in so far as they were mandated to write a
regulation and they produced one that is, at least, not asking
anything impossible and not trying to set bad technological decisions
in stone.
If I were the regulator, I might have written a very similar
document. Possibly I would have added some sort of requirements about
patching policy, but really, under the circumstances they did what one
could have reasonably expected of them.
However, the demand that they create such a regulation wasn't
particularly useful, and the output also isn't particularly useful,
probably because it inherently couldn't ever be particularly useful.
Most of the useful things it calls for, like having people who are
responsible security, and having policies about auditing and periodic
testing, are already in place at essentially 100% of financial
institutions. After all, financial services firms spend a fortune
trying to keep themselves secure, and have for many years. However, in
spite of the fact that all the newly mandated regulatory requirements
are already in place at essentially every single firm, security
breaches happen quite regularly.
In addition to what is done today, the regulation imposes a lot of
paperwork requirements, especially for filings with the state and for
the presence of loads of specific written policies which you will be
penalized for failing to have and to file. I suspect that when
breaches happen, if there are public calls for blood, regulators will
find minor paperwork violations and punish firms for making them, and
thus will have been seen to have done something. Note that even if
these minor violations had not happened, it is doubtful the results
would have been different. The problem in security is not, after all,
failing to file notice within 30 days that your new subsidiary
company's security was covered by the parent firm's security
The real issues in security are, of course, elsewhere. One of the
biggest issues is people making bad decisions about security, which
is unfortunately not really something you can quantify or regulate for
the most part, since there is no objective measure for "bad
decision". If bad decisions were truly obvious to everyone,
then people wouldn't make them. Even if you mandate particular
technologies, particular training regimes, particular licensing, and
a host of other burdensome requirements, people will still make
mistakes, and likely at an undiminished rate.
So what has happened has been, in essence, security theater. New York
State's politicians (including the governor) wanted to be seen as
having "done something" about computer security. They mandated that
the regulators would make rules, without really knowing what the rules
might say since they don't know anything themselves about computer
The rules were drafted, to the best of the ability of the regulators,
and they tell financial services firms to do what more or less 100% of
them already do, plus to file paperwork saying that they were doing
those things. When breaches happen, which they will as following
essentially these policies hasn't stopped breaches so far, everyone
can console themselves by knowing that there were written policies in
place that failed to have any real effect.
I think there is an obvious lesson here, which is that government
regulation isn't a magic force capable of solving problems that
dedicated professionals in a field have not been able to solve on
their own.

@_date: 2017-03-01 15:37:13
@_author: Perry E. Metzger 
@_subject: [Cryptography] TPM and SHA-1 
TPM 1.2 specified SHA-1, but I noted in some documentation that TPM
2.0 seems to still have SHA-1 in addition to SHA-256 as an accepted
algorithm. Is this the case? Does this mean that breaks to SHA-1
potentially can be used against TPM 2.0 as well?

@_date: 2017-03-03 09:17:56
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: Reminders 
1) Please edit your Subject: lines so they are meaningful. A Subject:
   like:
 Re: [Cryptography] [FORGED] Re: cryptography Digest, Vol 47, Issue 1
   is a potential reason for the moderators to block your message.
2) When quoting other people's posts, please cut down extraneous
   material. If it isn't relevant to your reply, you don't need to
   quote it.
3) The (primitive) archiving system does badly with HTML only
   email and we still have people here who prefer reading plain text.
   Please have at least a text multipart alternative in your message.
   If that sounds like gibberish to you, tell your mailer not
   to use HTML at all.
4) Please don't top post.

@_date: 2017-03-03 09:23:14
@_author: Perry E. Metzger 
@_subject: [Cryptography] TPM and SHA-1 
I don't know how far down in the noise floor it is. I'm curious about
whether it breaks anything, regardless.
No idea, but I've heard people talking about and presenting papers on
TPM even in the last year, so I remain curious.
Again, that's why I asked. :)

@_date: 2017-03-10 22:11:41
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: Anyone at Microsoft able to lend some 
Sorry for the administrative blast, but email to hotmail and outlook
addresses is bouncing for the list, apparently because the ISP subnet
that the list's SMTP server is on is being blacklisted by Microsoft.
If anyone at Microsoft could get in touch with me privately so that I
can arrange to get this fixed, I'd appreciate it.

@_date: 2017-03-11 09:32:19
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: DMARC users getting their From: address 
If you have no idea what the following means, ignore it.
We have a few list users on domains with published DMARC policies who
are causing lots of bounces.
As much as I dislike it, email from those subscribers is going
to have the header From: addresses rewritten by the mailing list
software from now on.
Apologies but there doesn't seem like a better solution available.

@_date: 2017-03-11 09:41:42
@_author: Perry E. Metzger 
@_subject: [Cryptography] Has formal verification actually been useful in 
In terms of *complete* systems, a few have, though I think mostly in
avionics. There are published papers on the topic.
Not to my knowledge.
There isn't one that has been deployed, but an experimental formally
verified browser called Quark was built at UCSD. It hasn't been
deployed and isn't maintained, but it was a very interesting
demonstration because it showed how to use a small formally verified
"software firewall" to contain millions of lines of very bad code that
constituted the bulk of the browser.
I know of no formally verified image libraries at this time, but
formal verification of something like libtiff or other image libraries
should be feasible at this point using Princeton's VST
Note that currently it would be a lot of effort, but with every
passing few months new tricks are learned about how to reduce the
effort of such work. I would say that it is worthwhile for someone to
attempt this.
It might or might not be easier to rewrite the code for such a
library from scratch in order to reduce the proof burden. One
approach, for example, might be to go for extraction from Coq or
F*. See the Project Everest effort for information on that approach:
which uses an F* to C conversion.
There have been numerous attacks that exploit graphics
vulnerabilities. There was a long while, as I recall, where most iOS
exploits were graphics library problems.

@_date: 2017-03-11 13:40:03
@_author: Perry E. Metzger 
@_subject: [Cryptography] Has formal verification actually been useful in 
Indeed, they do. My understanding is that they did before the FDIV bug
as well, abandoned it for that generation, and then learned they
lesson and always did the verification after that.
I don't know about address translation, but the cache coherency stuff
is (to my knowledge) formally verified because it is so tricky and
cache coherency bugs are so bad. However, as is always the case, which
properties are formally verified matters -- some properties of
interest in a security context might not be on their radar.
I believe Intel uses ACL2 for their formal verification work but I
am working from memory on all of this and might be a bit off.

@_date: 2017-09-13 16:55:02
@_author: Perry E. Metzger 
@_subject: [Cryptography] letsencrypt.org 
It works. I use it a lot for random sites where I don't care deeply
about the security of the system.
Note my security caveat isn't about the certificates being somehow
less good than other certificates. It is that someone gaining
temporary control of a server for your domain is in a good position to
also get a cert for your domain signed. Of course, absent a system
like Certificate Transparency, or cert pinning, that's the case
anyway, so perhaps I'm being paranoid.

@_date: 2017-09-14 09:26:39
@_author: Perry E. Metzger 
@_subject: [Cryptography] letsencrypt.org 
I said in my last sentence that you're exposed to that risk
regardless, so perhaps there is no point to my paranoia.
Did you miss that? See above.

@_date: 2018-04-08 12:06:02
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: Please, no top posting. 
We've had to reject a large number of messages recently for top
posting. Please do not top post. If you don't know what "top posting"
means, ask your nearest search engine.
Please also remember to cut down the portions of messages you are
quoting to just the essentials for context.
I recognize some people think that making it easy to follow an email
conversation is "old fashioned", but the management of this mailing
list does not care about modern fashions, we care about readability,
and if you make it too difficult to read your messages, we will not
forward them to the list.

@_date: 2018-02-09 23:28:33
@_author: Perry E. Metzger 
@_subject: [Cryptography] Useless side channels 
The business of finding difficult to exploit side channels heated up
in the last few days, as many media outlets made a big deal out of a
paper in which it was explained that one could detect magnetic
fluctuations from computer systems almost 1.5 meters outside a faraday
Now, I don't want to denigrate the original research -- it seems like
the sort of thing people ought to try out and then publish, if only so
we'll know what's possible.
Instead, I want to denigrate people for discussing it with the press
as though it were a serious threat, and I want to denigrate the press
for being silly enough to cover it.
I mean, in an era where the average large corporation seems to patch
its systems every other leap year, and in which they never put any of
their machines inside faraday cages in the first place, they should
*clearly* worry about people walking up within 1.5 meters of said
non-existent faraday cage enclosed machines in their colocation
facility carrying sensitive equipment with which to exfiltrate a few
bits a second from software they already somehow planted on the
target machine.
Even if they do have faraday cages (hello, Ft. Meade!) we would
imagine no one from the Federal Protective Service police would
notice you carrying such things inside the machine rooms in question,
and there would be no better way to get out data if you managed to
get in anyway, especially given that you had already put software on
the target system.
However, I see no reason we should stop with this level of silly.
After all, the working press loves such stories, so we really need to
feed them more.
I've thought for a bit, and I've come up with an even finer useless
side channel, which is to use the Aharonov-Bohm effect for
This effect has the added advantage of involving quantum mechanics,
which, from what I can see of the levels of accuracy surrounding
stories on quantum cryptography and quantum computing, is even more
magical to reporters than electromagnetism, which they seem to already
regard as a form of witchcraft. A quantum phenomenon would yield the
added benefit that no one in the news business would report this even
vaguely accurately.
As most of you are computer scientists or electrical engineers and not
physicists, you may be unfamiliar with the Aharonov-Bohm effect, so
I'll give a brief explanation.
The effect is a way that you can detect the presence of magnetic
fields that's non-zero somewhere even from somewhere else where the
field is zero.
Imagine an infinite solenoid carrying a steady current. Inside the
solenoid there's a magnetic field, but outside, although there's a
magnetic vector potential, the field is zero. Classically, there's no
way to measure that field from the outside.
However, it turns out that even though you can't measure the magnetic
vector potential's presence in any classical way, if you move an
electron in a full 360 degree circle around such a magnetic vector
potential, you will invert its phase. Now you might also think you
can't measure the phase, which is after all an imaginary number, but
you can do that by conducting interference experiments.
People have, with really complicated equipment and a great deal of
trouble, measured this effect.
Thus, it should be possible to build a sensitive experiment to route
electrons in a complete circle around your target's computer, conduct
interference experiments with them afterwards, and use the indirectly
inferred magnetic vector potential to further indirectly infer the
presence of magnetic fields within the computer which is otherwise
fully shielded.
Perhaps you can even build a giant experimental apparatus that
completely encircles Ft. Meade and who knows what you might learn!
This doubtless can be used for data exfiltration! Instant pressworthy
side channel, yes?
Sure, actually doing it would be extremely difficult, but so would
getting within a meter or two of an important machine with a faraday
cage round it in a colo to measure a magnetic field, and that didn't
stop interest from our friends at the major industry rags, right?
Reporters, do you have a slow news day and you need to report
breathlessly on something no one understands? The Aharonov-Bohm effect
is here to come to your rescue!

@_date: 2018-02-12 08:49:33
@_author: Perry E. Metzger 
@_subject: [Cryptography] Useless side channels 
I don't consider that particularly realistic either I'm afraid.
If you can get software running on the target's phone, why are you
bothering with this method of exfiltration when the thing has an LTE
How often do people put their phones into Faraday cages while they're
still turned on (why not turn it off!?) as a method to prevent data
exfiltration? If you're worried, why wouldn't you just turn the phone
off? But if you're worried in this instance, you're never going to be
able to turn the phone on again, are you, because you're going to have
to expect someone installed hostile software.
If you're within one meter of the phone that has had hostile software
installed on it and which has been left on while being put into a
Faraday cage, is it really the case that no one is going to notice you
lugging around a lot of test equipment with which to get a low
bandwidth channel out? I mean, under what circumstances will you be
doing that? "Pardon me, madam, I hope you don't mind my getting within
three feet of you with this mysterious backpack while you eat dinner,
I have a need to demonstrate a side channel attack against your
phone. Could you turn a bit to the right? You left the phone in a
pocket and I'm having some trouble with the signal."
Note that an anti-static bag isn't a realistic Faraday cage anyway, as
would be demonstrated if they had bothered to test it with real

@_date: 2018-02-12 08:56:12
@_author: Perry E. Metzger 
@_subject: [Cryptography] Spectre again (was Re: RISC-V branch predicting) 
So I'd like to highlight that. This is *the* key thing to remember. We
live in a world where there's lots of mutually hostile software
running inside a single address space. JavaScript stuff inside of
browsers is the biggest example, though there's also other things out
there (like the kernel BPF jit stuff in modern Linux, and there are
other things too.)
The obvious fix for Spectre here isn't easy, it's to either run that
hostile code only in its own process, or to provide hardware access
isolation even inside a single process. For some things, the former is
currently difficult.

@_date: 2018-02-12 09:23:46
@_author: Perry E. Metzger 
@_subject: [Cryptography] Useless side channels 
Ah. I got the direction wrong. On the other hand...
...a bag like that isn't a Faraday cage, and you should not be
bringing a phone, on or off, into a secure facility. If your
organization's process relies on workers to remember to turn off
phones and put them in to bags like that, something is wrong. Among
other things, people can't be trusted to reliably remember to do such
a thing.

@_date: 2018-02-28 14:51:50
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: Linguistic edict from your list 
Dear Subscribers;
The use of the term "crypto" to refer to blockchain based currencies
is henceforth permanently banned from this list. The list is about
cryptography, and the word refers to cryptography, not blockchain
currencies, at least around here.
Messages that use the term "crypto" to refer to currencies will not be
forwarded by the moderators. You may or may not get a rejection
notification, depending on the arbitrary and capricious whim of the
person on duty.
If you want to discuss cryptographic currencies, do so using a term
that doesn't irritate and annoy people.
Sometimes we'll make mistakes as this will be manually enforced by the
moderators. Do not take any such errors as invitation to perpetuate
the odious neologism in further messages. Feel free to let us know if
we miss something as well.

@_date: 2018-03-31 16:58:16
@_author: Perry E. Metzger 
@_subject: [Cryptography] ADMIN: Reminder: Please don't top post! 
Just a reminder: Please don't top post when you reply to messages on
the list, and please trim your replies. It's annoying for everyone
when we have to ask you to send a great message over again
because you top posted.
Your cooperation on this is much appreciated!

@_date: 2019-04-19 16:00:32
@_author: Perry E. Metzger 
@_subject: [Cryptography] [ADMIN] Too many fake "Satoshis" 
We've got a bunch of people currently subscribed to the
Cryptography list with various permutations of the name
"Satoshi Nakomoto", which is sort of harmless if a bit bizarre.
However, at intervals, someone tries to post messages under that name,
usually promoting some scam. Naturally, the moderators reject all such
posts; we're not morons.
Unfortunately, I think the time has come to be a bit more formal about
this because I'm sick of wasting time on it.
So, I'm instituting a new rule. No one is even going to be allowed to
subscribe to the list under that name any longer (let alone post!)
unless they are capable of signing a reasonable demonstration message
under a public key known to be controlled by the "Satoshi Nakomoto"
The real "Satoshi" would have no problem doing that. For the rest of
you, don't even bother; as I said, we're not idiots.
I will also be unsubscribing all of the current fake "Satoshi"
addresses in a little bit.
(If you're actually "Satoshi" and want to subscribe under that
pseudonym, feel free to get in touch with appropriate public key
signed evidence, though I suspect that the real "Satoshi" has no such
desire. If you get in touch without such evidence, your message is
getting thrown away without a reply.)

@_date: 2019-09-03 18:17:22
@_author: Perry E. Metzger 
@_subject: [Cryptography] Worthwhile survey paper on proof engineering for 
Here's a link to a new and interesting survey paper on proof
engineering for formal verification of software systems. It's free to
download until September 10th. Worth reading if you're interested in
an introduction to the whole area (and if you don't know much about
it, you should be interested.)

@_date: 2019-09-05 17:18:39
@_author: Perry E. Metzger 
@_subject: [Cryptography] Lockdown copyright survey paper on proof 
The summary is, I think it's an important paper to read, and Talia
Ringer, one of the authors (and an acquaintance) says they were asked
not to put it up for a few months so the publisher could recoup
printing expenses. There were a limited number of publishers who would
handle very long survey papers and would let them keep copyright, and
she thought the brief embargo was a reasonable compromise.
I thought the paper is sufficiently important that I'd ignore such
issues for now, especially since they'll eventually be resolved by the
passage of time.
Generally, I'm against paywalls of all sorts on academic literature,
and generally will not publish my own work in such places. However,
every once in a while, it's difficult to avoid wanting to *read*
something behind a paywall; valuable information is sometimes
contained in such papers.
With that, I'd prefer to put this to rest.

@_date: 2019-09-08 18:00:10
@_author: Perry E. Metzger 
@_subject: [Cryptography]  
=?utf-8?q?tch_to_McEliece=3F?=
On Sun, 08 Sep 2019 19:10:35 +0000 Ryan Carboni via cryptography
Certificates are not used for decades. Indeed, root keys are only
used for signing other keys and most are rotated on a reasonably
rapid basis. If someone built a quantum computer in the future, they
would be able to do very little damage by breaking an old root key
that had long since expired.
The real danger is someone breaking a key that was used for
encrypting traffic that is still relevant; secrets
might remain damaging to the people disclosing them even after

@_date: 2019-09-09 17:04:14
@_author: Perry E. Metzger 
@_subject: [Cryptography]  
=?utf-8?q?tch_to_McEliece=3F?=
What's the expiry on the longest lived cert DigiCert has signed with
that key though? Certainly not 2031. I would be surprised if that cert
was actually in use in 2031 as well. That said, the fact that it has
that long an expiry on it (13 years) is a problem as someone could
forge new certs off the old CA key, and there will doubtless be old
unpatched machines hanging around in a decade.

@_date: 2020-02-13 16:56:52
@_author: Perry E. Metzger 
@_subject: [Cryptography]  
=?utf-8?b?ZSBjZW50dXJ54oCZIg==?=
On Thu, 13 Feb 2020 13:47:14 -0800 Bill Stewart
There's an ElGamal encryption scheme, not just an ElGamal signature
