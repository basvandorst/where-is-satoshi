
@_date: 2018-08-04 20:44:08
@_author: Peter Fairbrother 
@_subject: [Cryptography] Perfect Integrity? 
A one-bit W-C MAC will give an attacker no advantage in guessing the bit - but he will still have a 50% chance of guessing right.
For information-theoretic security the MAC has to be as long as the message. I think.
Peter Fairbrother

@_date: 2018-08-05 22:23:35
@_author: Peter Fairbrother 
@_subject: [Cryptography] Perfect Integrity? 
I don't know of a definition of perfect integrity, which is why I added "I think".
If you have a 20-bit message with a 1-bit MAC, the attacker has a 1/2 chance of successfully forging a MAC by guessing.
If you have a 20-bit message with a 20-bit secure MAC, then the chances are 1 in 2^20.
Hmmm, if you have a 20-bit message with a 200-bit secure MAC, an attacker's chance of forgery by guessing are 1 in 2^200 ...
So maybe perfect integrity is impossible, as a perfectly unguessably secure MAC would have to be infinitely long.
Or maybe a 20-bit MAC is enough. I suppose it depends on how you define perfect integrity; you pays your money ...
Peter Fairbrother

@_date: 2018-08-08 18:14:27
@_author: Peter Fairbrother 
@_subject: [Cryptography] Perfect Integrity? 
Ouch. I'd prefer: "information theoretic security" means that without information an adversary doesn't have access to he can learn nothing about a plaintext from its ciphertext."
The OP was talking about Perfect Integrity, not Information Theoretic Integrity, and while I suppose there are differences, I am not entirely sure what they are.
To stay with security for a moment, an OTP is said to be perfectly secure; an attacker can learn nothing about the plaintext from the ciphertext - except maybe it's length. Chtsghjydsor might possibly decrypt as "attack at dawn" or "retreat at dusk", but it doesn't decrypt as "watch it, Hannibal is crossing the Alps with elephants", as it isn't long enough.
Could be important if eg the General habitually sends long messages when about to retreat, and short ones when about to attack. Or vice-versa.
Of course you can add padding, but exactly how much padding is needed to make a message information-theoretic secure?
So. is a "perfect" OTP information theoretic secure? Is anything? An OTP hotline discloses nothing ... but it's existence.
And a "perfect" OTP is basically a stream cipher, with the disadvantages of stream ciphers, eg plaintext manipulation etc.
forgery, for some small eps.
There is at least a third way - c) no adversary should have greater than 1/|m| chance of creating a forgery, where |m| is the number of possible I do not understand that.
This is trivially insecure as written, even for a one-off-tag - unless the calculations are done mod a large prime p, when it becomes secure.
(one-off-tag attack scenario: Alice calculates tag t from message m, Eve intercepts message, prevents it's delivery, wants to forge a different message for Bob)
Now the maximum message size is p-1 - if larger messages are allowed it is trivial to create a message which equals m modulo p. Also, a and b should be chosen at random from 1 to p-1.
So |a| = |b| = |t| = |m|, = |p| roughly.
I may have been a bit loose in nomenclature here, using |x| both for the size of x and the number of possible x's, hope you follow me.
We could truncate t without giving anything away about a and b, except the chance of forgery would increase - so using the working example, there is a natural size to a MAC tag which is the same as the size of the message.
I think there is something more fundamental [1] going on as well; so if I may I will call a MAC tag like that, calculated in a (loosely, ~information theoretic~) secure way with size equal to the message, a "perfect" tag.

@_date: 2018-12-05 02:25:17
@_author: Peter Fairbrother 
@_subject: [Cryptography] Hohha quantum resistant end-to-end encryption 
That's Good.
Some of the Bad:
1] Still has roll-your-own cipher algorithm.
2] Still has attacker-forcible default to DH, though at least maybe that is now postquantum? I didn't look hard.
3] The hybrid DH protocol is FAR too complicated, and there are probably half-a-dozen holes in it -
- eg the MITM measures don't work and don't prove anything: sending lists of messages to resend is asking for trouble, especially as there is no authentication:  non-receipt of acknowledgement messages is easy for an attacker to fake, as is stealing or breaking or apparently breaking Bob's phone: and if FS is implemented properly Alice can't resend messages anyway, as she doesn't have the key any more.
I assume MK is updated as mentioned in the FS part.
4] Still uses dedicated server.
5] Still too complicated, asks users to make security judgements.
Suggested solutions:
1] Remove algorithm choice; use only one well-tested cipher algorithm.
2] and 3]  No DH. No real need.
4] Piggyback on some other, preferably encrypted/encryptable, messaging protocol's servers.
5] Just doing the above will simplify it to the point where we can see the wood from the trees. Then we might get some idea of whether it works or not
(you didn't think that just doing the above would be enough, did you?  :)
Peter Fairbrother

@_date: 2018-12-19 11:50:08
@_author: Peter Fairbrother 
@_subject: [Cryptography] Komitments 
Banks in the UK and probably elsewhere use something similar for card transactions - the card hashes the transaction data and a secret key kept in the card. The issuing bank knows the secret key, and redoes the hash - if it matches, you get to keep the goods.
The link between bank and reader is encrypted (usually), but not the link between card reader and card. This means the card only has to be able to compute a hash, not a cipher. Which makes the cards cheaper.
(OK, OK, yes it's a little more complicated than that - but basically that's how it works)
Peter Fairbrother

@_date: 2018-06-05 04:06:37
@_author: Peter Fairbrother 
@_subject: [Cryptography] Odd bit of security advice 
Well, by a short time they mean once every 2^64 (or whatever the truncation is) operations.
Whether a certification test would pick that behaviour up would depend on how the certification was done: if by analysis of the code, then yes, using a 64-bit truncation would cause certification failure.
However in order for a Monte Carlo type test to detect this behaviour it would need to compare > 2^64 outputs and look for duplicates - not something done in most certification tests.
Incidentally, if you do use the bottom 64 bits and generate less than 2^64 messages, you still have unique nonces. After 2^64 messages (with the same key...) you start to get into trouble.
Also incidentally, if you have to randomly reset the counter every so often, in order to get say 128-bit security you would need a >128-bit counter - it depends on how many messages are sent.
Suppose you send 2^64 messages then randomly reset a 128-bit counter, rinse, repeat - the chance of a collision is then 1 in 2^64 (= the chance that the first 64 bits are the same).
Add more resets however, and you are birthdaying in 2^64, not in 2^128. After 2^32 resets or 2^96 messages you would have a collision.
To get 128-bit security you would need 128 bits (for the birthday) plus the 64 lower bits. And even that is only good for 2^96 messages.

@_date: 2018-11-02 10:36:26
@_author: Peter Fairbrother 
@_subject: [Cryptography] hash size 
I haven't been following lately, could you give a summary please?
Sounds very like the "mash" I proposed here years ago, eg see
To get that you need to do 2^25 work on average, increasing the workload on an attacker and (perhaps) decreasing the number of bits required.
100 human-readable bits (4 x 5-blocks) with the first 25 at zero from a good hash gives a very acceptable 125 bits of security against non-birthday attacks.
This means that a user needs to do 2^25 hashes in order to generate an identity mash - but he only has to do that once. If everybody does that - and why not? - there is no need to indicate it has been done.
One small point, I used to suggest using a 31-character alphabet - a-z plus 0-9 excluding 0125 and i because they can be confused with oizs and l.
However now I include i for a 32-character alphabet, as any confusion between i and l would require different capitalisation.
Sounds like a bad idea.
Users can be compared with idiots as far as security goes - and why shouldn't they be, that is our job, not theirs. To Quote the Operative: Secrets are not my concern. Keeping them is.
Using mixed lengths gains little, and opens the risk that a too-short length might be used somewhere. If lengths are fixed, that becomes 20 is better for human use. 16 (4 x 4 characters) is better still. But with a little stretching as above 20 (+5) is cryptographically OK except for birthday attacks and maybe quantum computing.
Birthday attacks aren't really a problem as they are necessarily untargeted, and one side of the birthday, the list of mashes in use, is unlikely to exceed say 2^33, one for each human on the planet - an attacker would have to do more than 2^92 work to find each collision with a mash in use, and then it would probably be for someone uninteresting.
QC? well, that's another story ...
UDF? user-defined-function?
A bit long-winded, but yes - and you can do it with IPs too.
However, I think you may have missed the main thrust of mashes - you do not include the email address on the business card or human-readable directory entry, only the mash.
Effectively, the mash is the email address.
And/or the telephone number. And/or the true address, or whatever you want it to be.
That way a sender has to lookup the mash, thereby finding the recipient's public key, before he can send a message. This means eg you can write software so that sending unencrypted messages is so difficult as to be beyond the capabilities of the average user.
It makes transitioning a little tricky, but any transitioning to eg a secure email service is going to be tricky. I have some ideas about that if you are interested.
Pleased to hear that - your designs were suffering because you wanted to find a use for a TTP.
Strangely, mashes do have a place for a semi-trusted third party - storing mashes, receiving mash requests, and sending the original with the user's name, public key, email address/IP etc to whoever wants it.

@_date: 2018-11-15 20:00:11
@_author: Peter Fairbrother 
@_subject: [Cryptography] Hohha quantum resistant end-to-end encryption 
Just had a quick look. It's a bit of a hodge-podge, isn't it. But there's worse:
1] The key renewal is worse than useless. If an existing key is not known to Alice, there is no reason to renew it - if it is known to Alice, she can deduce the new key. So it's useless.
It's worse than useless because it introduces complexity and attack surface. KISS. I don't know of an attack on that part of the protocol offhand, but why take the chance?
2] It uses an untested ?proprietary? roll-your-own algorithm. Ouch. Why not use something tested? Why allow an untested option, even as an option?
3] it can be forced back into using quantum-insecure DH. Ouch. Mallory will have fun...
4] it places too high a burden on the user. Users are clueless about security, that's our job, not theirs.
5] it relies on a trusted server.
So overall, it's a hodge-podge piece of cr written by someone with no clue about protocol design.
Sorry about that. Nothing personal.

@_date: 2018-11-22 16:57:42
@_author: Peter Fairbrother 
@_subject: [Cryptography] Hohha quantum resistant end-to-end encryption 
I agree, and not just for use in a postquantum crypto setting.
In fact, I cannot think of another option for an ultimately secure messaging system. I wonder why it is not mainstream, I don't know a messaging system that is PSK based or has PSK option.
All OTPs are PSK.
Len Sassaman used to use an OTP PSK - he would give people DVDs of random key material.
Then there is WAP etc,. And so on...
There is/was at least one text messaging system which has preshared key exchange on mobiles using bar- and/or QR- codes. Nothing else afaik, the key is simply reused.
Can't remember the name offhand, it was used by criminals who got caught and convicted through location tracing and thenceforward required each other to remove batteries from mobile phones when on a mission.
However, once you have PSK never go below. Once parties bother physical contact for PSK initialization, the rest must be based on a simple protocol which never goes outside the PSK initialization scheme. No online key exchange, no asymetrical encryption, nothing fancy/sexy/complex.
Up to a point, yes. The fancy stuff can frequently make things worse.
FS is good, and in general I'd use authenticated DH to provide it it in a simple presharedkey app.
But the Hohha use-case is post-quantum-resistance, and DH won't provide FS in a Post Quantum setting.
For PQ FS in a PSK app we would need some kind of PQ one-way key evolution function. There are several hash- and symmetric- based possibilities. The difficulties are synchronisation and in having to rely on the recipient, as ever.
 The proper term is forward secrecy, not perfect forward secrecy. DH can never provide perfect forward secrecy, as it can be broken using quantum computers (or even classical computers if you have enough of them. An OTP can provide perfect forward secrecy - where Alice exists, nothing else can)

@_date: 2018-11-22 20:46:32
@_author: Peter Fairbrother 
@_subject: [Cryptography] Hohha quantum resistant end-to-end encryption 
That is the point I was making - but it is not what is in the paper. They propose to refresh the key by generating a new key and sending it protected by the old key. Ouch!!
Any security gain you
I didn't notice anything like that in the paper. Keylength should of course be preset so it doesn't ever have to be extended. Even fairly huge symmetric keylengths take minimal resources under these conditions.
so, keylength? To give 128-bit security against Grover's algorithm we would need 256 bits of key. If De Broglie/Bohm is correct (I think it is, but many disagree) we might need 384 bits.
We might also need two keys, one for authentication and one for messages, so 768 bits. Round that up to 1k-bit for future-proofing, should be plenty.
1k-bit... if we are not doing DH but just eg xoring random numbers generated alternately by two devices, then key establishment takes negligible resources. Even with DH, key establishment resources are very No, it is not OK. Not even vaguely.
What are you testing? the algorithm, the scheme, both together?
If its the algo, which is not going to be fielded in a real-world implementation, it's a waste of testing resources.
If you are testing both together, why?, if you aren't going to be using both together? You aren't testing the final product, when you could be.
If you are testing the scheme, wouldn't it be better to use the final algorithm? It's going to be something for which code is readily available, much simpler than coding a roll-your-own.
I think everyone here (including Ismail) agrees
 From what Ismail has told me offlist, I don't think he agrees with that. Certainly in the paper, a roll-your-own cipher is to be used.
Yes. But DH fallback is a part of the project in the position paper.
It also has the benefit that the user *has* to do it in order to communicate, and if it is the *only* thing the user has to do then we don't have to worry about the user *not* doing it, or making uninformed and incorrect security decisions - there are no security decisions for him to make :)
It shouldn't, and maybe as described the server is only semi-trusted, I didn't look in detail - but does it need a server at all? Imo, no it doesn't. Piggyback on text, email, voip, whatever.
I am a little confused, are you part of this project? If so, why is what you are saying so very different to what is in the position paper?
Peter Fairbrother

@_date: 2018-11-25 14:05:11
@_author: Peter Fairbrother 
@_subject: [Cryptography] Hohha Protocol : 1. Key renewal review 
Key renewal is often a bad idea.
Ah, no, it doesn't.
Forward secrecy (there is a decent case for calling it backwards secrecy, but we are stuck with forward secrecy for now) implies that an attacker cannot decrypt past traffic after some key secret is deleted.
But you aren't deleting any secrets. If an attacker gets the raw key material [1] he can use it to decrypt all past messages.
The best way I can think of offhand to provide PQ forward secrecy is by key updating. Assume two keys, kA for Alice to call Bob, kB for Bob to call Alice (synchronisation gets very complicated otherwise).
Alice calls Bob, using the key or a derived key - then she updates kA by some PQ resistant method, eg she hashes it, deletes the old kA, and stores the hash as kA.
When Bob gets the message he uses his copy of kA to decrypt it, then hashes his copy of kA, deletes the original kA and stores the hash as kA.
As soon as both copies of kA are deleted, there is no key material which an attacker can use to decrypt the message (assuming the hash cannot be There are some possible tweaks and variations you can add to eg compensate for out-of-order delivery - but these are really really complicated, and very hard to get right, and it is almost certainly best not to bother.
[1] Especially with modern ciphers, key material exposure is far more likely than an attacker being able to cryptographically break one message and find the key. To (slightly mis)quote Robert Morris, "Rule 1 of cryptanalysis: check for plaintext and keys".
But, a more fundamental problem: You say to are not a cryptographer, so why do you think you are qualified to write cryptographic software?
I do not mean that in any rude way. From a cryptographic point of view a lot of your mistakes are fairly elementary ones.
Second, writing secure code is yet another requirement - I haven't looked at any of your code, but writing secure code is quite different from writing ordinary code. I can't do it, wish I could.
Perhaps some of the secure code chaps could chip in here?
Lastly, writing cryptographic algorithms and apps is hard, very hard. Or maybe not - to quote Bruce Schneier (this is sometimes known as Schneier's law, and all cryptographers will know of it: it is also why you shouldn't use roll-your-own algorithms):
"Anyone, from the most clueless amateur to the best cryptographer, can create an algorithm that he himself can't break. It's not even hard. What is hard is creating an algorithm that no one else can break, even after years of analysis. And the only way to test that is to subject the algorithm to years of analysis by the best cryptographers around."
Don't get me wrong, we desperately need good cryptographic programmers. But cryptography is not the same as accounting, lives may depend on it, and writing cryptographic software is a specialised skill.
If you are also designing cryptographic algorithms, with no experience or background in cryptographic algorithm design ...
Peter Fairbrother

@_date: 2018-11-26 02:03:26
@_author: Peter Fairbrother 
@_subject: [Cryptography] Hohha Protocol : 1. Key renewal review 
Yes. But that's not the attack forward secrecy defends against.
In the system I described the initial key material only exists for a short time; as soon as it is updated it is no longer there for an attacker to find. In your case, it persists unchanged.
Put it this way: Suppose after the system has been in use for a year or so, someone gets hold of your device and extracts the key material in it.
Under my system the key material he gets *cannot* be used to decrypt past messages.
Under your system, even after a year, he gets key material which *can* be used to decrypt all past messages.
As I have said before, perhaps it should be called backward secrecy.
Key replacement can defeat the "initial key onward" attack you mentioned, but that's a whole 'nother story entirely.
The key renewal system in the paper won't do that however, as if the attacker knows the old key and can see the traffic he can calculate the new key just as easily as Alice or Bob can, in just the same way.
The system you just outlined has a similar flaw - if the attacker knows K1 and K2, he can calculate the session keys just as easily as Alice and Bob can.
You might think that an attacker would only get a session key, and in some rare circumstances that might just be possible - but it is far less likely than him getting K1 and K2 as well.
It's actually very different, less complicated, and probably more secure.
All this faffing about with two keys - why? Can you explain each operation, and why you chose it. What does it gain you? What attacks does each operation defeat?
In general we do nothing at all without very specific reason. Why? A more complicated system is harder to analyse and thus get right, and it has more places to attack.
The acronym is Keep It Simple Stupid - because adding inessential complexity is stupid.
It's also closely related to why a hogde-podge (which means a lot of unrelated stuff roughly stuck together in a bit of a mess) is bad - it is hard to analyse and thus to get right, and it offers more places for an attacker to attack.
You have to get into the mindset - people who you don't suspect, who know more cryptography than you do, who know more tricks than you do, who are sneakier than you are, who have no morals at all, and who have more determination and more resources than you think they do, are after your data.
That applies to everybody by the way. Even me. :)
It's rule 2. Even when it isn't true, you should treat it as being true.

@_date: 2018-10-15 18:58:54
@_author: Peter Fairbrother 
@_subject: [Cryptography] Random permutation model for encryption as a 
The bit about 2^n keys and (2^b)! permutations is a lightbulb moment for I'd avoid talking about permutations which are not good for block ciphers, as I believe you are wrong there anyway - if they are randomly chosen, they are good.
Afaict the only way in which it is inaccurate is that in a real cipher the permutations are pseudorandomly chosen, rather than real-randomly.
Dilbert:

@_date: 2019-12-17 11:31:54
@_author: Peter Fairbrother 
@_subject: [Cryptography] Backdoors 
MPAA could quite easily identify which movies are being pirated, in exactly the same as anyone who watches pirated movies.
Identifying who initially pirated the movies is harder, but they could use traitor tracing (individual small changes or digital watermarks in each copy) to do so.
However there are so many legitimate copies out there that it isn't worth their while except for people who initially pirate new movies on a large scale, who can be caught using standard law-enforcement techniques.
To some extent MPAA do identify pirated movies, probably by using Google and/or torrent trackers, then you get:
"In response to multiple complaints that we received under the US Digital Millennium Copyright Act, we have removed 3 results from this page. If you wish, you may read the DMCA complaints that caused the removals at LumenDatabase.org: Complaint, Complaint. "
I suspect you can use the links to the complaints to find the movie ... I digress.
MPAA want to increase income and monetary value. They do this rather successfully by making pirating seem anti-social and a little risky, and making mass commercial pirating highly illegal. Many of those who watch pirated movies do so because they can't afford to go, and preventing their piracy would not increase income and monetary value.
Being seen as too heavy-handed in prosecuting individual piracy would not help either - "bad MPAA = bad movies" - though mass pirates are fair While MPAA are not exactly happy about piracy, they do have it under Peter Fairbrother

@_date: 2019-07-25 12:00:14
@_author: Peter Fairbrother 
@_subject: [Cryptography] Our leader opines on cryptocurrencies 
The big privacy hole is the very existence of the (public) blockchain.
Suppose the DEA bust someone with a few drugs, paid for by bitcoin. "Hey, we'll go light on you if you tell us about the blockchain So they can, quite easily, find the dealer's bitcoin wallet. As soon as the dealer buys anything with those bitcoins, due to the public nature of the blockchain they know the seller's wallet. If the seller is legit and his ownership of the wallet is public - and why not? - they ask him who paid him and what for. Does he have the dealer's address?
And so the dealer gets busted. No web or DNS involved.
Bitcoin is not reliably anonymous. Neither is TOR, but that's another Some perhaps interesting figures:
USD circulating cash in US: $0.9 trillion
USD circulating cash abroad: $0.6 trillion
USD other "narrow cash": $2.0 trillion
USD USG bonds held by foreigners: $6.2 trillion
USD M2 (~total issued): $18 trillion
Bitcoin total issued: $0.17 trillion
US external debt: $20.0 trillion

@_date: 2019-06-05 18:09:47
@_author: Peter Fairbrother 
@_subject: [Cryptography] About Secret Sharing Schemes and a Question 
You can do a little better than that. The master key can be generated by the shareholders, and later the shares can be used, in such a way such that no-one ever knows it.
Then the result of a query is an action token which will do something, eg decrypt a file, send off the missiles, whatever - not somebody saying "I have a valid (piece of paper) in my hand".
There is no key master in this scheme - but someone has to create the action tokens. Usually that someone knows the decrypted file or how to set off the missiles, but if he forgets that (or dies) then the secret shareholders can read the file or whatever.
The action token creator need have no part in the key sharing; token creation can all be done with available public keys. [8]
It is also usually possible to create the action token without anyone (up to and including the file's creator) knowing the decrypted file Hints for implementers - El Gamal is your friend.
My kind (the other kinds don't work here) of universal re-encryption can help with the fancy stuff, so long as you only trust yourself. But then that's rule 3 - "Only people you trust can betray you".
[8] probably not quantum computer proof - but the jury's still out on QC.
Did you read the recent rather mind-boggling results, reported as "Saving Schroedinger's Cat" or the like?  How might they affect QC?
Though I'm sure the cat is a lovely animal, I was always more beguiled by the box ..

@_date: 2019-05-17 20:56:21
@_author: Peter Fairbrother 
@_subject: [Cryptography] A two key file/program 
Give the staff a long, maybe 256-bit, password for each account. Give the manager and assistant manager each a different half of the password. Repeat for each account.
- Peter Fairbrother

@_date: 2019-10-01 16:41:49
@_author: Peter Fairbrother 
@_subject: [Cryptography] Encryption and anonymity as top tools for images 
I think I said that?
I found that a surprisingly large proportion of those who work in the anti-child-pornography field are sexually interested in children. It seems to attract them.
They come in two main types - the first are straightforward abusers who want to make it easier and/or safer for them to abuse children, to be inside the tent looking out.
The second type are those who think everybody else is a secret or potential abuser, in their thoughts if not yet in reality; because after all other people must really be like them, with a desire to abuse children; who tell themselves that they are really working to prevent abuse, and they would never ever give way to temptation ...
I am not sure which is worse.
Anyway, those are perhaps today's criminal bootleggers, and the NSA/CIA/FBI/Google/Facebook are more like the Baptists.
The analogy is not exact - when are they ever? - because the populus generally thought drinking alcohol was ok, whereas they generally think child abuse is not ok.
Peter Fairbrother

@_date: 2019-09-30 08:28:03
@_author: Peter Fairbrother 
@_subject: [Cryptography] Encryption and anonymity as top tools for images 
There is fundamentally only one way to look at it - do we allow unbreakable encryption or not.
If we do allow it then people will use it to do bad things. Like people use shoes or telephones or toilet paper to do bad things (I'm not sure what bad things people use toilet paper for, but I'm sure there are some).
If we don't allow unbreakable encryption then modern banking becomes impossible. Freedom of speech becomes impossible. And so on.
And then the bad guys will find another way, or just use illegal encryption.
So, to a balance of harms.
Personally, I only care about abuse of children. I do not care per se if perverts look at dirty pictures of children, as long as they do not abuse children. A senior policeman in the child-abuse field I talked to about this once said that the damage continued as the children in the pictures are still alive, but I am not sure how significant that is.
So, does looking at dirty pictures of children increase abuse of children? No-one knows. There is evidence both ways. There is no justification to assume it does - there was plenty of abuse before the internet (or photography) was thought of.
How much does encryption help perverts? It made it harder for the Police to catch them  -  well actually, no, it didn't. If before the internet and encryption it was this hard to catch perverts (when anyone actually tried), the internet and encryption didn't make it much if any harder to catch them.
Another thing that encryption does not do is make it easier for perverts to actually abuse children (except in the way that shoes or telephones do).
There is just [1] this image in some people's heads that if there was no encryption then all the perverts would either go away or get caught easily and children would be safe and Police bills for catching perverts would decrease.
So, if we banned unbreakable encryption, would child abuse fall? By how much? Personally I think it might fall a little for a short time, but then it would increase back to present levels or even more.
To a final reckoning then, a small temporary decrease in child abuse versus no banking and no free speech.
Doesn't seem so difficult now (or any less a horrible choice).
Peter Fairbrother
[1] there are of course also the people with different agendas, such as policemen and other workers in the child-abuse field I wouldn't leave a child with; and peepers from the Government and elsewhere who (ab)use the child abuse issue to try to defeat encryption.

@_date: 2020-04-03 00:56:14
@_author: Peter Fairbrother 
@_subject: [Cryptography] "Zoom's end-to-end encryption isn't 
actually end-to-end at all. Good thing the PM isn't using it for Cabinet calls. Oh, for f..."
not end-to-end despite explicit claim
mines all your data
sends data to facebook
big login hole
host can detect if watchers present
all your base are belong to us
Peter Fairbrother

@_date: 2020-04-03 14:21:41
@_author: Peter Fairbrother 
@_subject: [Cryptography] "Zoom's end-to-end encryption isn't 
To begin: You don't use, or need, a central server.
Sixth law : Only those you trust can betray you.
Peter Fairbrother
The first 10 laws of secure information systems design - there are more laws, plus some principles, but they are still a work in progress:
0 It's all about who is in control
1 Someone else is after your stuff
2 Stuff you don't have can't be stolen from you
3 Attack methods are many, varied, ever-changing and eternal
4 Everywhere is subject to attack
5 Complex systems provide more places to attack
6 Only those you trust can betray you
7 Holes for good guys are holes for bad guys too
8 A system which is hard to use will be abused or unused
9 Security is a Boolean

@_date: 2020-04-04 13:52:09
@_author: Peter Fairbrother 
@_subject: [Cryptography] "Zoom's end-to-end encryption isn't 
It is not optimism, grasshopper, it is formulated as a requirement.  :)
How are the people supposed to find each other?
I have never used Zoom, so I am at a disadvantage insofar as knowing the expected user interaction and features, and I cannot recommend anything, see 8th law. However I will make some brainstorming type suggestions.
How do people find each other with Zoom? I'd guess through email or mobile numbers.
Only streams between the conference host and the participants are required.
So you are saying that only streams between the server aka the conference host and the participants are required.
Perhaps the host receives low-def streams from the participants and multicasts a single high-def stream back to them. Perhaps the host can ask a participant for high-def when focus is put on them.
These are just top-of-my-head brainstorming type suggestions. I can even envisage situations where a central server may be more secure, though I am much happier when key agreement is done directly between host and As an aside, the main raison d'etre for central servers is often more related to income streams than to functionality or security.
Peter Fairbrother

@_date: 2020-04-08 00:59:15
@_author: Peter Fairbrother 
@_subject: [Cryptography] "Zoom's end-to-end encryption isn't 
"There will be a staff meeting at 3pm, details here"?
"Click the link at ten am Sunday to join our video church meeting"?
That isn't really a teleconference, more a broadcast, as I am assuming the host only has a single multi-/broad-cast output stream, not 1,000 input streams. What would he do with them? A conference with 1,000 always-on active participants - I shudder.
A _secure_ conference with 1,000 always-on active participants? Won't touch that with yours.
Point is, the participants are downloading one hidef stream, and uploading one usually lowdef stream. The host is only watching one hidef screen, therefore only downloading enough low-def streams to fill that one hidef stream .
The host can't watch more, as his monitor won't allow it - there is no point in using more bandwidth. Everyone should be able to manage that, if they can't then a central server isn't going to help.
If you want to use a million monitors, fine, but expect to use more bandwidth :) Central servers are not going to help here either.
The only remaining problem is that the host is outputting one multicast hidef stream, and the internet does not do multicasting on a 1 -> 2 or say 1 -> 10 person basis well. However it is possible, eg something like BitTorrent but real-time, with the participants participating.
Maybe you might want to use a central server or service for multicasting and broadcasting.
But if you start from the idea that you don't need a central server, you will usually find that you don't.
Peter Fairbrother

@_date: 2020-08-25 04:21:31
@_author: Peter Fairbrother 
@_subject: [Cryptography] Terakey, 
Principles
"A" (singular) passive attack. I won't get into that.
But you don't have to defend against "a passive attack" - at a minimum you have to defend against all _plausible_ attacks, whether passive or active; or better, defend against all *possible* attacks.
Now suppose you deploy a system which defends against passive attacks only. Is it certain - certain - that it will never be used in a situation where an active attack is possible?
If you answer yes, at a minimum you abuse the dictum that a US Marine can break anything.
Analysing your cryptosystem from first principles? - I guess it is analysable: it is broken.
Peter Fairbrother

@_date: 2020-08-29 04:32:44
@_author: Peter Fairbrother 
@_subject: [Cryptography] Terakey, 
Principles
Why do you say that? Of course an attacker could mount these attacks. That is the entire point.
While active chosen-key attacks are not straightforward to execute, they are in the armamentarium of at least some potential attackers. They are part of the literature. And more important, they are something which any proof of confidentiality must take into account - ignoring them is like building a huge strong gate but leaving holes in the fence for people to walk through.
Step 1, Mallory, who does not have access to the terakey, wants to cryptanalyse a message ciphertext. First he breaks the PRNG.
Mallory then knows the indicators for the terakey bytes used in the message he wants to break, though he doesn't know the actual terakey byte values.
Step 2, he then finds a PRNG key which generates some of the same indicators, and does a chosen-key known-plaintext attack, or two, or seventy thousand. He gets someone who does know the terakey to encrypt a known message with his chosen key. He then calculates the relevant terakey byte values by comparing the known plaintext with the ciphertext.
Step 3, he then uses his knowledge of the terakey bytes to break the original message.
If you are talking in terms of _proof_, you cannot prove that Mallory cannot do any or all of these steps. If he does them, he gets the plaintext of any message he wants.
I strongly disagree.
In terms of proof, it simply does not do what you say it does - it does not provably protect 99.9% of the traffic. It does not provably protect *ANY* of the traffic.
To claim terakey provides provable security you have to prove that the attack above is impossible. Nothing else will do.
Peter Fairbrother

@_date: 2020-08-30 05:03:08
@_author: Peter Fairbrother 
@_subject: [Cryptography] Really good ideas, harsh reality, 
I don't know whether you have been following the terakey thread, but afaict it is something which at first sight looks like a great idea, but turns out not to work as advertised.
I had a similar - looks great but doesn't work - idea a decade or more years ago, in the context of steganographic file systems "in the cloud"; or more generally steganographic file systems where every read and write is visible to an attacker.
[a steganographic file system is a file system where unless you know the relevant keys you can't tell whether something in it is a real file or not, nevermind read the contents]
[this is not a cautionary tale, but it did hurt at the time]
The cloud filing system would have a bunch of files, all the same size, all filled with random-looking data, stored in the cloud. Some of these would contain encrypted real user files, some would just be actual random data.
A subset of these files would also be copied/stored in the user's computer. They would act as a pool.
Using universal re-encryption these pool entries would be re-encrypted and returned to storage in a randomly-chosen fashion, replacing their cloud counterparts, at regular intervals - the mechanism to do this would not need to know whether the file was a real file or not [1].
Another file, chosen either at random or in accordance with user read need, would then be transferred into the pool replacing the written-out file in the pool.
This store-fetch cycle would repeat at regular intervals.
When a real user file was created or deleted it would initially go into the local pool; in the creation case replacing a randomly-selected pool entry, in the deletion case by deleting the user key.
As the cycle mechanism would not know whether the local pool file was a real file or not (if it did know it could be called to account), real files were duplicated and spread over the cloud to minimise deletion. Bit complicated, but that part also worked.
Great idea. The paper was accepted for one of the PET conferences. Many people congratulated me.
Except - it doesn't work in real-world numbers. There are patterns to real user file accesses, and these patterns are detectable.
If an attacker can see all present and past reads/writes to the cloud store, using that randomly-chosen replacement pool system you can only say a vanishing proportion of the real files are secure in existence.
Practically it might be useful, but only against your little sister. Well maybe a bit, or quite a bit, more than that; but not securely, against a major adversary.
So I went away and gnawed my liver.
Damn. Great-seeming idea, but it didn't work. BTW, after a while fresh human liver makes you feel sick and have the dire-rear.
But ..
Out of this chaos I invented tailored covertraffic.
Tailored covertraffic is covertraffic where an observer can't say with any certainty, based on all past observations and all other link-based evidence available to him, that any piece of traffic is real traffic  - as it could also have been plausibly generated by the tailored covertraffic generating mechanism.
Tailored covertraffic covers real traffic better than random covertraffic because it can cover a specific piece of real traffic more efficiently than random covertraffic can by hiding it in a smaller-but-more-likely set of possible traffics.
I have often meant to write a paper about tailored covertraffic, someday: but it is not complicated, just complex, the name and description should be enough to give the idea.
There is still one more problem (at least) - given a cloud storage set and a set of revealed files, can an attacker say with confidence that there are more real files still to be revealed (without identifying which files) in the storage set?
And all this with a complete historical access/change history?
Afaict neither is an insoluble problem, but they do have to be considered.
And I also invented - but that's another story, I'm working on that. :)
Peter Fairbrother
[1] I also invented a suitable universal re-encryption mechanism for this.
and this has now a become an almost drunken rambling, so don't take it too otherwise. But it may still be a bit wise, I hope, else I wouldn't have posted it.

@_date: 2020-12-02 18:27:30
@_author: Peter Fairbrother 
@_subject: [Cryptography] A Scheme for Verifiable Lottery 
That is not a problem, the published list is just a list of ticket numbers and the associated choices. The idea that each participant creates a 256-bit number doesn't have that problem either.
However both ideas are broken by this attack:
Organiser sells n real tickets. He also "sells" say n/10 fake tickets. He then can generate lots of hashes for one (or bits for several) one of the fake tickets and finds a hash where one of his fake tickets is the He can pay cash for the fake tickets if needed, as long as the prize is more than n/10 times the ticket price.
Peter Fairbrother

@_date: 2020-12-12 11:43:16
@_author: Peter Fairbrother 
@_subject: [Cryptography] Zodiac Killer's 340 Cipher Broken 
One small mistake:
     ?I HOPE YOU ARE HAVING LOTS OF FUN IN TRYING TO CATCH ME
     THAT WASNT ME ON THE TV SHOW
     WHICH BRINGS UP A POINT ABOUT ME
     I AM NOT AFRAID OF THE GAS CHAMBER
     BECAUSE IT WILL SEND ME TO PARADICE ALL THE SOONER
     BECAUSE I NOW HAVE ENOUGH SLAVES TO WORK FOR ME
     WHERE EVERYONE ELSE HAS NOTHING WHEN THEY REACH PARADICE
     SO THEY ARE AFRAID OF DEATH
     I AM NOT AFRAID BECAUSE I KNOW THAT MY NEW LIFE IS
     LIFE WILL BE AN EASY ONE IN PARADICE DEATH?
last two/three lines should be
     I AM NOT AFRAID BECAUSE I KNOW THAT MY NEW
     LIFE WILL BE AN EASY ONE IN PARADICE
     LIFE IS DEATH
- too long to say why here.
Peter Fairbrother

@_date: 2020-12-20 13:30:18
@_author: Peter Fairbrother 
@_subject: [Cryptography] BitCoin as Quantum Cryptanalysis canary. 
Nah, though of course bitcoin is a big target for cryptanalysis.
Satoshi is a very private approaching paranoid person, and initially he did not spend bitcoin because that would expose his identity.
Most recently he hasn't spent any of the initial blocks because he doesn't want to see bitcoin's price and thus reputation crash (and he doesn't need the money).
More, what the hell would he do with that much money? He sure couldn't spend it anonymously, and preserving his anonymity is paramount to him.
I am of course guessing here, but I do not think the keys are lost - he may have deliberately deleted them, but I do not believe he lost them, that would be out of character.
Peter Fairbrother

@_date: 2020-12-21 13:17:21
@_author: Peter Fairbrother 
@_subject: [Cryptography] BitCoin as Quantum Cryptanalysis canary. 
Short answer, 256-bit ECDSA.
There is a 256-bit public key and a 256-bit private key, both ECDSA. The wallet address is a 160-bit hash of the public key.
The private key is usually derived from a passphrase, which can in theory be any size. The passphrase -> key generation process depends on the wallet software used.
There are also mini keys which are 30 x base52 characters (~171 bits), which expand to a 256-bit ECDSA key by hashing part of the minikey.
Peter Fairbrother

@_date: 2020-02-13 21:23:13
@_author: Peter Fairbrother 
@_subject: [Cryptography] Crypto AG and CIA project exposed 
Sometimes there was - we are talking about 70-odd years of varied skulduggery. At first it was just weakening, but at several points some of the Crypto AG machines had classic hard-to-guess-secret-based backdoors.
But I think you can call any deliberate introduced weakness a backdoor anyway, even if it does not rely on a secret. Especially when you know about it and everybody else does not, and you need to know about it to know which weakness to exploit - knowing about the weakness could be considered the secret.
You say tomato...
Some of the early Crypto AG technology was similar to Enigma. It has been said that the secrecy about the wartime breaking of Enigma was especially longlasting because of the Crypto AG/CIA-NSA-BND link, so maybe GCHQ had some knowledge and access too.
Peter Fairbrother

@_date: 2020-01-03 15:25:33
@_author: Peter Fairbrother 
@_subject: [Cryptography] how to detect breakage -- lures etc.?? 
The wiring between rotors is effectively a static rotor. In the stacked rotor version it is all 1:1.
In a flat version, if I understand you, if it is permanently fixed to something other than 1:1 it doesn't do much cryptographically (Kerckhoff); if it changes per key - well, a rotor changes even more, sometimes per letter.
I guess they thought 3/4 rotors was enough.
Peter Fairbrother.

@_date: 2020-01-06 11:54:33
@_author: Peter Fairbrother 
@_subject: [Cryptography] how to detect breakage -- lures etc.?? 
Lorenz used different-sized (well they were the same physical size, but with different numbers of pins) rotors. Five rotors moved together at every character, with a period of 22 million, and some other rotors moved sometimes. It was of course broken.
One problem with the Lorenz system was that for each Lorenz rotor you only got an XOR bit, not a permutation.
I don't think anybody has ever built a rotor machine with variable length permuting rotors and reuse of the unused rotor inputs and outputs, either with or without intervening permutations. If you did some input characters would necessarily be treated differently to others, so eg a message of zzzzz's might not involve the first rotor at all.
Indeed, that was how Lorenz was broken. But the period of the Enigma rotors was only 15,000/375,000 (3/4 rotor).
I don't think so. After r1 characters rotor 1 will be back in its original position. To say that is condition is indistinguishable under all circumstances implies a lot about the rest of the machine, which may not be true - and often isn't.
It is hard to explain without an example, so consider a two-rotor machine with three and five inputs (and outputs) per rotor and a 4 character alphabet.
If the five rotor ("f") comes first it might have 4 character input lines fi1-fi4 and one input fi5 from output fo1, with 3 outputs fo2-fo4 going to the three ("s") rotor and output fo5 going to main output. The s-rotor would have the three inputs fo2-fo4 as mentioned, and three outputs going to main output.
Now every 5 characters the f rotor will be in the same position, and if we have input fi3 every 5 characters such that it goes on the path fi3-fo1-fi5-fox-siy- we have separated out the rotor actions.
Something similar is true if the 3-rotor is first.
Afaict the difference in rotor sizes makes this sort of weakness necessarily true, though it might not be significant in a very complex The art of cipheranalysis is largely about seeing things the cipher designer didn't - and there are a lot of things to miss in your system. I certainly wouldn't like to certify any particular design secure .. especially if the intervening circuitry changes.
6th Law: Larger and more complicated systems have more places to attack.
Peter Fairbrother

@_date: 2020-01-07 01:52:25
@_author: Peter Fairbrother 
@_subject: [Cryptography] A SSH walk thru 
No, that is SSL (or TLS) - a different beast(s) altogether.
Peter Fairbrother
But some more detail

@_date: 2020-01-07 02:08:02
@_author: Peter Fairbrother 
@_subject: [Cryptography] looking for a word 
to mean stolen from a record but still in it, ie integrity and availability are preserved but not confidentiality.
"Stolen" is too laced with implications of the stolen object not being there any more, "copied" does not imply the theft aspect enough, "pirated" is too silly.
Any other suggestions? Thanks.
Peter Fairbrother

@_date: 2020-01-07 17:32:33
@_author: Peter Fairbrother 
@_subject: [Cryptography] looking for a word 
First of all, thank you to everybody who replied, both on and off-list.
I had independently come up with that word - but ao402468 published first. Darn, but not liver-gnawing time :)
Words people have come up with:
"Copy" is good, and obvious, but doesn't have the emotional connotations of stealing: scenario, you are a secure database operator/designer and someone has - "whatevered" - your data. You are right royally pi**ed off and want to nail the f to a wall and stick knitting needles in their bellies and watch them die slowly and insane from peritonitis. If you can keep yourself from killing the s _F$* sooner.
"Copy" seems a little weak for what they did.
"Crib" and "pinch" are also good, but both have or had a specific crypto meaning, "crib" being a known or guessed plaintext, and "pinch" meaning crypto things stolen by non-cryptanalytic means. Both are a little weak. Both are also a bit skoolboyish.
I think "abstract" is probably the best word available, but am a little worried that most people will not be aware of the secondary meaning of abstract. It doesn't necessarily involve dishonesty, but it is sometimes used that way - eg abstraction of electricity, an offense under UK law; you can't steal electricity as it is not a thing, so the offense is "abstraction" not "theft".
Any further thoughts? This usage will eventually go in a book, which probably no-one will ever read, but if they do you may end up using whatever the final choice is...
Again, thank you all for your help.
Peter Fairbrother

@_date: 2020-01-08 13:59:28
@_author: Peter Fairbrother 
@_subject: [Cryptography] Variable length rotor machines: was: how to detect 
There are also some design limitations - the number of pins in each rotor position must be constant, by which I mean that the first rotor must always have x pins, the second y, and so on. You can't use a 25-pin rotor in a 26-pin slot, and afaict you can't move slots around.
This makes the rotors non-interchangeable. If you want to change rotor actions then you must either change their internal wirings or have a set of rotors for each position - I do not think it is practical to change the number of pins on a physical rotor.
As the number of pins in each rotor position is fixed, it must be assumed that it is known to the enemy - it will be as soon as they pinch an example of a machine.
Another, perhaps lesser, consideration is that for a stacked rotor system like Enigma there is only one set of moving connections per rotor, whereas with your system there are two - not insurmountable, but not an aid to reliability in a mechanical system.
Peter Fairbrother

@_date: 2020-01-12 21:44:16
@_author: Peter Fairbrother 
@_subject: [Cryptography] improved identification of non-targets 
Or steal the box and put it in your bomber ...
There is a reason why IFF works as it does - you want to not shoot down your own guys. Anyone else is either the enemy or collateral damage - and it is more important to shoot down the enemy than to avoid collateral damage.
You don't want a hierarchical universal generic design really - you want your own people to issue your own version of get-out-of-being-shot-down cards, nobody else.
For outgoing airliners any IFF-y box which attaches to a transponder on the aircraft would do. The codes are only valid for however long the airliner is going to be in your defended airspace. You might do something similar for approaching airliners, the approaching airliner gets a one-use code from air traffic control [to go in a secure box But I expect things will go on as they are, with public condemnation being the main factor limiting unwanted shooting down of airliners.
Though I suppose it has happened, I never heard of somebody getting shot or even discharged for shooting down an airliner - to the military, it is more important to shoot down the enemy than to avoid collateral damage.
Peter Fairbrother

@_date: 2020-01-14 01:23:33
@_author: Peter Fairbrother 
@_subject: [Cryptography] improved identification of non-targets 
I don't foresee much use for a second box - after the first bomb drops the defenders will shoot at anything in the sky which doesn't have their own military IFF, plus civilian flights will stay away.
A more general point - many of the proposals here might work well if there was a single big joined-up-system including the military. Unfortunately it is seldom like that...
It's a little like doctors and medical records. You can have a really good record-keeping system, but it turns out to be of very limited use in emergency rooms - the doctors just don't trust it to be 100% accurate, so they ask the same routine life-and-death questions.
Similarly, the guy on the trigger doesn't have the full picture, and air defence systems are designed to kill even when he has no "big" picture at all.
Peter Fairbrother

@_date: 2020-07-18 00:41:56
@_author: Peter Fairbrother 
@_subject: [Cryptography] Terakey, 
Principles
Ie an OTP.
Key bytes are
What is the advantage of the pseudo-random selection? That two stations can use the terakey using some secret shared-to-them-only key to the PRNG without any other stations seeing that traffic? [3]
Well we know that the other stations know the secret terakey, so as far as they are concerned the problem is reduced to breaking the PRNG.
That may be a little harder because of the added (I presume) XOR with a selection from the OTP, as some methods may not work; but it is not necessarily any harder.
And having multiple stations all in possession of the same secret terakey is a huge single point of failure - the probability of a secret's compromise is, inter alia, proportional to the square of the number of people who know it. [8]
Two messages can occasionally use the same
So how do you analyse that? Just probability of collisions? If that's all, who's to say the pseudo-random generator doesn't kick out collisions at a more-than-random rate, or in some pattern? You have to analyse the PRNG as well.
And if you then have a cryptographically secure PRNG ...
Going from the provably-secure OTP to analysable (if it is analysable, which I doubt) doesn't seem like much of a gain.
Peter Fairbrother
[3] that doesn't seem to be in your proposal, but I am assuming. If it isn't then I see no advantage - bookeeping is reduced to "don't reuse key" and if eg a part of the terakey is allocated to station 1 the station just uses the next portion of its part for sending its next message.
[8] fourteenth law.

@_date: 2020-07-28 12:11:23
@_author: Peter Fairbrother 
@_subject: [Cryptography] Terakey, 
Principles
Oh no no no. That might be your analysis, but it isn't the only analysis.
Suppose I am the NSA and manage to tweak the PRNG to my nefarious means.
Perhaps I can arrange that 1 in 3 selections is to a limited set of terabyte bytes. After getting some known plain/cyphertext traffic I can read 1/3 of the plaintext characters - enough to do serious damage.
Peter Fairbrother

@_date: 2020-07-29 07:24:59
@_author: Peter Fairbrother 
@_subject: [Cryptography] Terakey, 
Principles
Or, to be sneakier, suppose I tweak the PRNG such that while it gives a location stream A for one key, for another key calculable using some (secret but known-to-me) function it also gives location stream B which is a permutation of stream A.
Or even just, without tweaking the prng: I can find some PRNG key which outputs the same location as the location of the nth character of the original location stream.
Then I can do a chosen-key known-plaintext attack.
Peter Fairbrother

@_date: 2020-07-30 01:17:34
@_author: Peter Fairbrother 
@_subject: [Cryptography] Terakey, 
Principles
The NSA tweak was just an example to get you thinking in the right way. As were the chosen-key known-ciphertext attacks I mentioned, the second of which can be done with *any* prng - just find a key which outputs the same location ref as a location ref in the message to be broken, rinse and repeat.
What is important is that you cannot prove that the chosen prng is as-secure-as-random in this application - which you would need to do in order to analyse the method's security from first principles. And as far as I know that can't be done.
"Providing a reasonable approximation of a uniform random sampling" is not enough for a proof of security.
Peter Fairbrother

@_date: 2020-06-12 03:01:35
@_author: Peter Fairbrother 
@_subject: [Cryptography] Cubbit 
I don't know what this type of coding is properly called, but from your description it is not a standard Reed-Solomon coding.
Schneier refers to this sort of coding as a (m,n) threshold scheme (Applied Cryptography 2nd ed under s.3.7 secret sharing).
It has also been called erasure coding or block erasure coding.
One method is to create an m-dimensional array of some data then take n shadow snapshots of it. Each snapshot (shadow) is approximately N/m in size (strictly, < N/(m-1) ). Any m shadows can recreate the original.
See: G.R. Blakley, ?Safeguarding Cryptographic Keys,? Proceedings of the National Computer Conference, 1979, American Federation of Information Processing Societies, v. 48, 1979, pp. 313?317.
If you are not trying to be cryptographically secure (as in Cubbit) then there are quicker methods, especially for small m and n.
These can be very much faster than RAID codings, but they do not detect or correct bit-level errors.
Peter Fairbrother

@_date: 2020-05-22 10:55:38
@_author: Peter Fairbrother 
@_subject: [Cryptography] Does this provide any extra value? 
Yes, of course.
Starting with the First Principle, "Never give a inch" [1], you are giving an inch - and some edge case will take advantage of it.
Eg, "MDGC-MQ7F-AV76-47TL-LQ7M-UIH4-U7CE is 78645335 bytes long, it is therefore almost certainly an encrypted version of this other file".
Or "MDGC-MQ7F-AV76-47TL-LQ7M-UIH4-U7CE is only 3 kb long, it can't be the file we are interested in so we can put our energies elsewhere".
Or "MDGC-MQ7F-AV76-47TL-LQ7M-UIH4-U7CE was deleted yesterday - whodoneit? you were in a cell and no-one else is supposed to have access".
Or "Here is MDGC-MQ7F-AV76-47TL-LQ7M-UIH4-U7CE, decrypt it or go to jail/get kicked around/get shot."
Or "Here is MDGC-MQ7F-AV76-47TL-LQ7M-UIH4-U7CE, let's see if we can decrypt it".
Or "Here is MDGC-MQ7F-AV76-47TL-LQ7M-UIH4-U7CE, let's see if we can manipulate it".
Und so weiter
[1] Spelling courtesy of Henry Stamper
Peter Fairbrother

@_date: 2020-11-29 01:40:52
@_author: Peter Fairbrother 
@_subject: [Cryptography] A Scheme for Verifiable Lottery 
IIUC that doesn't work - but I don't understand precisely what you are saying [1]. I don't see how the repeated [2] hashing gains you anything (and it sure doesn't make it fast to compute, unless you have hardware But the scheme is broken anyway. Here is one attack:
N tickets sold. Organiser picks N trial usernames and test hashes them with genuine lucky number etc.
Organiser's shill then buys the test with the lowest score and discards the other tests. Shill has a 50% chance of winning.
I may be misunderstanding something, you are not clear, but afaict the organiser publishes the hash of the lucky number then reveals it after the entries are closed. The organiser then has the advantage of knowing the lucky number while entries can be bought, and can translate that into free tries.
If not, the lucky number serves no purpose I can see. If the lucky number is public then the public can try new usernames to find one which hashes to a low number.
Peter Fairbrother
[1] this scheme is not well-described. suppose I want to calculate the second hash - is the username different? do I calculate a series of hashes for each entrant?
[2] what you have described is not repeated hashing as far as I can tell, it is just lots of different hashes. The results of the previous hash are not used to calculate the next hash.

@_date: 2020-09-03 22:38:08
@_author: Peter Fairbrother 
@_subject: [Cryptography] Really good ideas, harsh reality, 
Haven't read it in detail, IETF draft language gives me a headache, but it looks a bit like the US-USSR hotline - when it wasn't in use random traffic was sent so an observer couldn't tell whether the traffic was random-looking-encrypted-real or just random. The rate of traffic was/is? constant.
If (it is not clear) you are referring to tailored covertraffic, that is more effective in reducing total traffic.
To reduce total traffic the tailoring is done in such a way that the covertraffic has a rate distribution and/or other characteristics similar to the real traffic - so instead of just the real traffic looking suspicious, all the traffic looks suspicious.
However it is not (necessarily) done at a constant rate.
There are some caveats and notes - the only way to be 100% sure that traffic is concealed is to use a constant rate. However if 100% confidentiality is not required then tailored covertraffic can reduce traffic costs.
In the original application, a steganographic filing system, you can under duress (eg a warrant) give up some real traffic, and an observer can't say you haven't given up all the real traffic.
Probably doesn't work if the duress is torture, but against "beyond reasonable doubt" it should work.
One thing I worry about,
This can be overcome by splitting the traffic into m-of-n blocks, where the real traffic is split into n blocks using a block erasure code, and any m (<n) blocks can reconstruct the original.
Not perfect, you still need a resend mechanism, but it takes more than one dropout for a resend to be required. You can also tailor it to the dropout rate by changing n.
Peter Fairbrother

@_date: 2020-09-25 01:53:26
@_author: Peter Fairbrother 
@_subject: [Cryptography] A naming and key distribution infrastructure for 
That is too long for people.
For m-o-o-t [1] I devised a 16 random base32 character identifier and address and (sort-of) telephone number.
Chap  makes a file with his name, digital signature, email address, telephone number, snail-mail address, whatever he wants to include in it. He makes a hash of the file, then does a 2^20 proof-of-work a la bitcoin and truncates the result to 80 bits.
That is 2^100 bits work factor, and it is very hard to find a preimage for a given hash, needed to do most MITM attacks. You can find collisions with a lot of effort, but there isn't much point - eg the name will be wrong.
The file is published in a directory, indexed to the identifier. Anybody can publish directories. You can even publish your own directory.
If someone wants to call you, or email you, or send you a parcel, you give him the 12-character string. Eg m-ahr7-dt46-j37f-hgsb. [2]
Sufficiently memorable, capable of being spoken or written as well as QR'ed or barcoded.
Done properly, when sending someone an email, or printing an address label, or calling someone on the 'phone, the address translation from identifier to email address, snailmail address, telephone number etc would be done automatically in software.
The software would also display the name and check the PoW and hash, and eg for telephone calls and email would use the key to encrypt.
I think it might even be possible to go to 12 base32 character identifiers if you increased the PoW to 2^40 - you could pay a bitcoin miner a dollar to do that for you if you can't do it yourself.
Key distribution is by identifier.
Why should the technorati use a different system? They will usually be talking to the 99%, except maybe helldeskers and bofh..
Peter Fairbrother
[2] they all started with m- so you would know what they are, like all telephone numbers in the UK start with 0, and internet addresses have a //:
[1] m-o-o-t was/is? a communications ecosystem which only allows secure communications, originally based on a bootable CD. I am not a good enough coder to get it to work securely, reliably and user-easily, which is why it is a bit moribund, though I believe the design was sound. Perhaps one of three.

@_date: 2020-09-28 04:32:13
@_author: Peter Fairbrother 
@_subject: [Cryptography] A naming and key distribution infrastructure for 
My email used to be **** at zen.co.uk, but I changed it to **** at I did not own zen.co.uk, but I now own tsto.co.uk - or at least exclusively rent it from ICANN/Nominet/my registrar or whoever with a sort-of guarantee that as long as I pay the rent I can't be evicted.
DNS registry entry service for tsto.co.uk is provided by the people I rent tsto.co.uk from.
I can choose anyone I like to provide my actual email service. I don't do it myself because running a low latency email service is a serious hassle, what with spam blacklists etc., but I could if I wanted to.
Which is exactly what is happening in your system, except it is the name provider, not the messaging service, to whom the user is tied.
In the m-o-o-t name system there is are no ties at all. Anyone can operate a registry and the user can use any registry service. Registries which are noticeably incomplete will soon go out of business.
Names are generated at random by the user. He doesn't get to choose the name [1]. Random names mean no trademark disputes, and particular names are not especially valuable.
If we get a bit ridiculous, we can even have say 8 x 5-bit character names. Lots of proof of work needed to prevent forgeries, and then there are collisions - except that two people can have the same m-o-o-t name, it doesn't matter, as the person's human/user name (generated by lookup from the m-o-o-t name) is always displayed when the m-o-o-t name is used.
Capitalist despot, you are still fixated with stickiness and money, and your project will not work unless you give it up. !!!  :)
(still a smidgin of truth in that though)
Peter Fairbrother
[1] Except people can do a lot of work and generate a m-o-o-t name with a few chosen characters. 8 5-bit characters is probably too small, but I think 12 might be OK. 15 or 16 characters are probably OK.
