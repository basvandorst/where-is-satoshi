
@_date: 2001-07-31 08:43:22
@_author: M Taylor 
@_subject: GESG Identity-Based Public Key Cryptography (ID-PKC) 
The UK Communications-Electronics Security Group (CESG), the "defensive"
arm of the GCHQ, have published details about another PKC concept,
identity-based PKC, where every user's public key are predetermined by an
unique identifier, such as email address. It does use a(/two) trusted
server(s), but might be viewed as an easier to use infrastructure than
tranditional PKI in some situations.
The identity scheme ideas they present are similiar to Fiat-Shamir
identity signature scheme. The security is based upon Quadratic
Residuosity Problem (see: Goldwasser Micali 1984).
More details from: including PDF of a slideshow, and requesting source code (definitely not
under an Open Source license), note as far as I know the CESG is
considering patents for this technology.

@_date: 2001-11-13 00:58:53
@_author: M Taylor 
@_subject: What does it take to be a security professional? 
The obvious but serious and important question which is
related, "what does it take to be a computer professional?" To
which, I think the best place may be to start by a) act like a
professional, b) consider joining a professional organization like ACM, IEEE, BCS, etc to help you with a.
So what professional groups, certifications, degrees are worth-
while for the new security / cryptography professional?
I don't have a very good answer for that, and I don't think
anyone else has a complete answer either. Professional
organizations to be aware of include ISC2 (CISSP certification),
SANS (GIAC certs), ISACA, ACM, IEEE, IACR, and others I haven't
heard of. The first 3 also (primarily?) offer certification as
well. There are many different discplines with computer security:
from information system auditing to network intrustion detection to cryptography that most people can only master
a small domain and be aware of the other areas. I think that looking at the CISSP certification might be a
useful starting point, it also has a value relating to employment
and contract work; IT Security Managers and Contractors are
decent paid positions. It also provides a wide view of the field
so that you can start to realise the range of issues and areas,
which you may choose to presue further in greater depth. I think there is also a security engineer role which isn't
typically called such, but is also a cross-displinary role which
involves the more technical side of software, system, and network
developments. I think Ross Anderson's book Security Engineering
is the closest thing to a guide for this sort of role. The
"periodical" for such a role would be Peter G Neumann's RISKS
Understanding what goes wrong is good. As well as understanding
the balance of risks and rewards, something security types often
overlook. An understanding of risk management, insurance, and
statistics would do no professional any harm.
For academic courses, check Avi Rubin and Bruce Schneier's lists
  Me, I'm still trying to figure this out myself, so far it does not
appear to be a great time to shift careers or take a lot of risks.
So I would be interested in other suggestions myself.

@_date: 2001-10-02 11:22:50
@_author: M Taylor 
@_subject: SSL on a chip, EE Times 
Startup eyes SSL security ICs
By Loring Wirbel EE Times
(10/01/01, 3:57 p.m. EST) AUSTIN, Texas -- A security-processor startup has become the latest advocate of hardwired acceleration of Secure Socket Layer (SSL) session creation. Layer N Networks Inc. is aligning with the likes of Broadcom Corp. and Andes Networks Inc. in promoting SSL for secure transactions, instead of programmable encryption and Internet Protocol tunneling. The Austin-based startup is gambling that the market for this technology will mature at the same pace as its own product development, so that there will be customers when it is ready to start shipping product. Layer N is aiming to deliver a chip set in early 2002, and chief executive officer Mike Salas believes the market will be mature enough by then to warrant an IC-level product.

@_date: 2002-12-30 17:37:17
@_author: M Taylor 
@_subject: WiFi, Why worry? 
In an article in the Canadian national newspaper Globe & Mail,
Jack Kapica suggests that the WiFi (802.11b) insecurities
are boogiemen created by "kids" to annoy grownups.
I feel sorry for the poor IT / IT security person trying to
convince her boss that the article underestimates the risks,
and has several errors...(It's not cold enough to stop a
criminal from using a high gain antenna from the warmth of his
car, from more than 100 meters...)
Friday, December 27
Wi-Fi and digital devils
By JACK KAPICA
Globe and Mail Update
Any computer upgrade for small to medium-sized businesses is going to involve one burning issue these days: Should it include a wireless network?
The most popular type of wireless network is called Wi-Fi (for wireless fidelity), or the 802.11b standard (in techspeak), and it allows workers within a company to roam the building while remaining connected.
This is seen as so important that makers of laptops are starting to put Wi-Fi in their notebook computers as a matter of course. More important, wireless networks mean fewer cables to install and therefore fewer expenses to worry about when changing the office staff and furniture about. In short, wireless nets are an intelligent, cost-effective purchase.

@_date: 2002-09-20 18:27:41
@_author: M Taylor 
@_subject: Sun donates elliptic curve code to OpenSSL? 
For the geeks,
openssl-SNAP-20020915.tar.gz or later snapshot files.

@_date: 2003-04-02 16:24:09
@_author: M Taylor 
@_subject: TPM coming to Canada 
It appears that TPM is being seriously considered by Copyright Policy Branch
of Canadian Heritage, and has announced a paper by  Dr. Ian Kerr and others.
It mentions a nice top heavy certificate rich method or a DMCA like law
as two TPMs that might work in their opinion.
The legal aspects are to be dealt with in a later part of the study, the tone is fairly optimistic that TPM can work well enough to
preserve revenue to copyright controlers.
I'm afraid I'll have to start writing letters to government and non-government
groups to inform them of issues beyond revenue control issues (like creator's
rights and consumer protection).
-M Taylor

@_date: 2003-02-07 18:57:11
@_author: M Taylor 
@_subject: Canadian Immigration Minister pushes to adopt a national id card 
[Moderator's note: I edited this to add reasonable line breaks. Also,
the content is only weakly on topic, but... --Perry]
Canadian Immigration Minister Denis Coderre is promoting the idea of a
Canadian national id card, which uses "high tech" biometrics. When
confounded by arguements of security he suggests that it for a good
thing for convience.
I guess my biggest complaints are that it makes a very attractive
single source for a huge reward (of information) for white collar
criminals and organized crime, several single points of failure,
losing all your government issued data on your one card makes it
harder to securely replace, and lastly the failure to demostrate an
analysis that suggests an actual improvement in national security.
On a lesser note, I don't like the idea of handing my digital
"passport, driver's license, social insurance number, and gov't
employee id / security badge" over some bouncer at a bar, clerk at a
car rental counter, or any time in everyday life when asked for
government id by private sector that has lower privacy barriers than
government(s) and federally regulated industries (telecom, banking,
airlines, insurance).
By CAMPBELL CLARK
Ottawa Canadians should fingerprint themselves before U.S. border
guards do, Immigration Minister Denis Coderre argued Thursday, as he
asked MPs to consider a national identification card with a biometric
identifier such as fingerprints or eye scans.
Echoing deep concern within the federal government that the United
States will expand its registration and fingerprinting of foreign
travellers to include Canadians, jamming the border, Mr. Coderre
suggested a national ID may be a way to avoid the brunt of tighter
U.S. entry-and-exit measures.
Mr. Coderre appeared before the House of Commons immigration committee
to formally ask for their recommendations on a national ID card, but
made it clear he favours it. He told MPs the time when they could
cross the U.S. border with a driver's license "may well be over."
Mr. Coderre said that a so-called off-line biometric system one where
a fingerprint or eye is checked only against the coded scan on the
card, but not against a central database would be less invasive than
keeping a central registry of the fingerprints of all Canadians.
However, Andrew Clement, a University of Toronto information
technology professor who has studied national identity cards, warned
that such an off-line system is not much use as a security tool since
someone could obtain a card under another name, but with his own
fingerprint or eye scan on the code bar. A central database with the
fingerprints or eye scans of all Canadians would be needed to make it
Even with a central database, such a card would not be much of a
deterrent for terrorists, he said. Anyone would be able to obtain such
a card by presenting other fraudulent documents such as a birth
"That's one of the big flaws," Mr. Clement said. "The creation of the
secure card depends on the presentation of much less secure

@_date: 2003-01-14 17:04:04
@_author: M Taylor 
@_subject: Wait, PKI isn't dead, it will save email 
The Holy Grail of Security?
By JENNIFER EVANS
Special to Globe and Mail Update
Friday, January 10
E-mail has been in the news a lot recently as investigators have gone back and found 'smoking guns' in long-discarded messages. Those 'confidential' disclaimers on messages are largely pointless, as e-mail is considered by the Canadian government to be a form of insecure communication. Enterprise-wide initiatives to secure e-mail are spotty and unreliable. But despite the obvious threats to intellectual property and corporate security, very few are taking advantage of a solution that offers end-to-end secure e-mail communication, file sharing and other electronic exchanges, a solution that would virtually rid the enterprise of the threat of compromise. Are governments and corporations negligently slow to adapt or does PKI have a major public relations problem? Historically the issues with PKI have been its marketing, its ease of use, and its incomprehensibility to the layperson.
And not just for the layperson. Three years ago, when I was working for a network security value added reseller, we picked up Entrust as a solution. Entrust was a pioneer in public key infrastructure, and yet a team of experienced security sales people had a very difficult time understanding what it did, much less articulating it to clients and understanding which clients would find it of value.
One of the reasons why PKI is so inscrutable is its basis in remote mathematical concepts of encryption, logarithms, terms like 'hash value' and the various types of keys that are used during the process (public key, private key, session key, and so on), not to mention digital signatures and digital certificates, forbidding concepts that are not easily conveyed to the user or the executive.

@_date: 2003-07-08 21:18:53
@_author: M Taylor 
@_subject: LibTomNet [v0.01] 
stunnel ( which is an "universial SSL wrapper".
So perhaps Tom could could write a EZ-OpenSSL wrapper, which remove
legacy options (disable SSLv2 and SSLv3, just TLSv1), limit algorithm
choice to sensible defaults, and ensure the programmer has as decent
as available random numbers. Or rewrite LibTomNet to match the basic PROTOCOL concepts of TLS, without
the legacy compatability, and reduce/remove algorithm negotation, etc. No
need to actually be compatible with TLS, just to use the same protocol
concetps. Until Tom's libtomnet known/tested is secure from all known attacks on SSL/TLS, he should refrain from calling it 'secure' since he cannot be reasonable certain that it is in fact secure.

@_date: 2003-06-18 19:13:04
@_author: M Taylor 
@_subject: Part II of Heritage TPM study released. 
I have not had a chance to read this yet, but just referencing it in case others did not notice it yet.
Date on file is  Date modified: 2003/06/04
Just noticed that the dates on the document say Final version: April 2002
Here is a link to the HTML version of both parts:
PDF version linked from here:
 Russell McOrmond, Internet Consultant:

@_date: 2003-03-20 16:15:55
@_author: M Taylor 
@_subject: Certicom unveils S/MIME client for PDAs 
Monday, March 17 [2003]
Certicom unveils movianMail
Certicom Corp., a provider of wireless security solutions, has taken the wraps off movianMail, a secure e-mail solution based on S/MIME version 3 for use with Microsoft Pocket Outlook. movianMail enables enterprise and government users to send and receive digitally-signed and encrypted e-mail messages on their Pocket PC device. According to the company, it is the only wireless secure e-mail solution to store all messages encrypted on the e-mail server, in addition to offering proof of the message's origin through digital signatures. Governments and other organizations that require highly protected information are mandating S/MIME to secure their e-mail. To meet the strict security requirements of the U.S. Government, movianMail is available as a Government Security Edition (GSE) product, which also supports certificates and keys stored on the Department of Defense (DoD) Common Access
Card, ensuring even stronger security and authentication of e-mail messages and attachments, the company said.

@_date: 2003-05-05 14:53:37
@_author: M Taylor 
@_subject: my take on "PCP" 
To clarify, whether Ralf is serious is not an issue, whether serious peer review occurs is. "Anyone, from the most clueless amateur to the best cryptographer, can create an algorithm that he himself can't break. It's not even hard. What is hard is creating an algorithm that no one else can break, even after years of analysis."

@_date: 2003-10-01 21:02:37
@_author: M Taylor 
@_subject: Monoculture 
So is being logically and scientific is a bad way to do cryptography?
Maybe you would rather some sort of more 'post-modern', 'liberal'
or 'free market' cryptography?
Bollocks. Anyone is free to learn and practice (in the 'western' world,
and many other countries) cryptography. Some people are just better
at it, and many of those people are recognized for being better or
more experienced. By your argument any group that has education and/or training is
a guild. Heaven forbid CS and IT types look at the history of their
own field.
That sounds like a progressive, enlightened way of doing business,
at least trying to avoid known mistakes, and trying to discover
new ones. Which is why the implmentation is different from protocol design,
except for the insecure application developer. Cryptography is hard; suck it up. That is not a reason to act irrational and encourage using known weak or flawed methods, when we do have better known methods.

@_date: 2003-10-02 00:06:40
@_author: M Taylor 
@_subject: anonymous DH & MITM 
Stupid question I'm sure, but does TLS's anonymous DH protect against
man-in-the-middle attacks? If so, how? I cannot figure out how it would,
and it would seem TLS would be wide open to abuse without MITM protection so
I cannot imagine it would be acceptable practice without some form of

@_date: 2003-09-27 19:58:14
@_author: M Taylor 
@_subject: Tinc's response to "Linux's answer to MS-PPTP" 
It appears Guus Sliepen (and/or Ivo Timmermans) are worried about the
tinc protocol overhead per packet. This reduces the size of the data payload per packet, which could impact perforcemance due to IP
fragmentation. Because the IP packet length is often restricted due
to Ethernet frame size (1500 bytes), it can is more efficient to design
the protocol so each UDP datagram is a full IP packet (1500 bytes Ethernet
frame minus the 20 bytes for IP header, and 8 bytes for the UDP header) with a payload of 1472 bytes.
Perhaps a HMAC per "chunk", rather than per the payload of a single UDP
datagram. I suspect per every 5 UDP datagrams, roughly ~7000 bytes of payload may work. This will increase latency.
This should be redone from scratch, I would look at either using
Diffie Hellman Key Exchange combined with digital signatures or the updated
Needham Schroeder Public Key Protocol. Exchange two symmetric keys,
one used for bulk data encryption, the other used for the HMAC
authentication. I expect this is a reference to "Why TCP Over TCP Is A Bad Idea"
Oh, and they fixed their flaws. SSHv1 is not recommended for use at all,
and most systems use SSHv2 now which is based upon a draft IETF standard. SSL went through SSLv1, SSLv2, SSLv3, TLSv1.0, and TLSv1.1 is a draft IETF
If Guus Sliepen and Ivo Timmermans are willing to seriously rethink their
high tolerance for unncessary weakness, I think tinc 2.0 could end up being
a secure piece of software. I hope Guus and Ivo circulate their version 2.0 protocol before they do any coding, so that any remaining flaws can be easily fixed in the paper design without changing a single line of code, saving time and effort.
