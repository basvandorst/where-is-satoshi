
@_date: 2001-05-25 22:37:51
@_author: Hadmut Danisch 
@_subject: Tamperproof devices and backdoors 
The question is not precise enough to be answered.
The term "tamperproof device" covers a too wide range of devices.
Define precisely what kind of tamperproofness you are discussing,
- Tamper detection only: Device allows to be analyzing and
  all contained data to be read out, but someone is able to detect
  that this device was opened. This appears to be rather some kind
  of physical seal than a cryptographical protection. Think about
  a plain paper envelope sealed with wax. It doesn't protect
  the letter to be read, but it allows the detection that it was   opened.
- Protection of data only: Imagine some device, which keeps the
  mechanism completely intact and inspectable, but erases all
  data (e.g. a cryptographic key). - Protection of mechanism: A device with selfdestruction, leaving
  itself uninspectable. What about this: Assuring some probability similar to blind
signatures. Assume someone is selling tamperproof devices of the
second kind (see above). You buy 1,000, randomly select one of them
to be used, and open/analyze the other 999 for hidden trapdoors in the
mechanism. You might find that these 999 devices are just a plain and simple implementation of any blockcipher. Probability that the
chosen one differs is 0.1%. You could also have some kind of "transparent device", which allows
you to see every detail of the mechanism, but not the data (key etc.)
currently stored or under computation.

@_date: 2001-05-25 23:10:23
@_author: Hadmut Danisch 
@_subject: Tamperproof devices and backdoors 
What about this:
Don't use a tamperproof _device_. Use a device consisting of n tamperproof modules instead.
Have the device built in a way such that someone needs
to tamper with at least m, 1 < m <=n, modules to be successful.
(Simple example: Use a chain of encryption modules from distinct manufacturers...)

@_date: 2001-10-01 16:33:32
@_author: Hadmut Danisch 
@_subject: Best practices/HOWTO for key storage in small office/home office setting? 
If storage on CD-R: Is there a standard/good practice for
encrypting CDROMs? Maybe iso9660 through block device encryption?

@_date: 2001-10-05 22:48:48
@_author: Hadmut Danisch 
@_subject: Passport Passwords Stored in Plaintext 
Outlook once offered me the choice between "no encryption" and
a so called "compressible encryption".

@_date: 2001-09-01 23:43:03
@_author: Hadmut Danisch 
@_subject: Anonymous Credit 
What does me keep from catching the message, stripping off the signature, add a new
signature with my own (secret, freshly created) key but with an older date, publish it with my signature, and later claim to be the
[Use a digital timestamping service. Or just publish a hash of the
message plus a secret only you know in the newspaper. --Perry]

@_date: 2001-09-02 12:07:04
@_author: Hadmut Danisch 
@_subject: Anonymous Credit: New proposal 
Sure, but this was not part of the proposal. And I don't know of any existing time-stamping service which
is trusted and provides services to anonymous people. It must
be possible to receive the time stamp without revealing your identity
or to get a time stamp which can't be tracked to the message
to be posted.
Not really. Makes stealing more difficult, but not impossible. The attacker now has to prevent the distribution of the detached
signature *and* has to make the author believe it had successfully
been distributed (e.g. fake a mail from a distribution list), then
wait for distribution of the full message.
Problem: A signature is simply the wrong cryptographic tool.
A signature gives non-repudiation, so the owner of the secret
key can't deny to have seen the message (which is useless, as
long as the identity of the key owner is unknown).
But in this case you want to prove that some is the only author,
not that he has seen the message, which is a matter of
authentication, not message signing.
New Proposal:
1. Author generates a public/secret key pair, suitable
   for authentication (maybe zero knowledge, in case
   message could bring author to jail...)
2. Author generates a random number (nonce) and
   calculates Hashsum(concat(random number,message)).
3. Author anonymously publishes the public key from
   step 1 and the hashsum from step 2 ("I will later
   claim authorship of a message...").
4. Some public authorities (as many as possible, whoever
   should be convinced of authorship later, e.g.    mailing list admins, notaries, universities,...)
   generate a signature for the public key and the
   hashsum published in step 3.
   This means: "We will accept the person who authenticates
   to this public key as the author of the message with
   this hashsum."
   This signature is publicly distributed (sent to a    mailing list, put on a web server,...)
5. If the author receives enough of these signatures,
   he can be sure to claim authorship later by using
   the secret key to authenticate.
   If the author doesn't receive enough signatures
   within a given amount of time, he repeats from
   step 2.
6. Author anonymously publishes the message and the    random number. The issuers of the signatures (and
   whoever trusts them) can now link the message to    a public key for authentication.
7. Whenever he wants, author can prove authorship
   by authenticating to the public key
   (which might be comfortable if it is a    zero-knowledge scheme and the police is waiting...)

@_date: 2001-09-09 21:21:29
@_author: Hadmut Danisch 
@_subject: Compression side channel 
Good point. The mistake seems to be mixing a (non-compressible)
secret and a (compressible, possibly attacker-chosen) message in one
compression run.  It seems to be a good idea to compress every
logical part of the plaintext separately (and to compress only
things which are compressible).

@_date: 2001-09-01 23:43:03
@_author: Hadmut Danisch 
@_subject: Anonymous Credit 
What does me keep from catching the message, stripping off the signature, add a new
signature with my own (secret, freshly created) key but with an older date, publish it with my signature, and later claim to be the
[Use a digital timestamping service. Or just publish a hash of the
message plus a secret only you know in the newspaper. --Perry]

@_date: 2001-09-02 12:07:04
@_author: Hadmut Danisch 
@_subject: Anonymous Credit: New proposal 
Sure, but this was not part of the proposal. And I don't know of any existing time-stamping service which
is trusted and provides services to anonymous people. It must
be possible to receive the time stamp without revealing your identity
or to get a time stamp which can't be tracked to the message
to be posted.
Not really. Makes stealing more difficult, but not impossible. The attacker now has to prevent the distribution of the detached
signature *and* has to make the author believe it had successfully
been distributed (e.g. fake a mail from a distribution list), then
wait for distribution of the full message.
Problem: A signature is simply the wrong cryptographic tool.
A signature gives non-repudiation, so the owner of the secret
key can't deny to have seen the message (which is useless, as
long as the identity of the key owner is unknown).
But in this case you want to prove that some is the only author,
not that he has seen the message, which is a matter of
authentication, not message signing.
New Proposal:
1. Author generates a public/secret key pair, suitable
   for authentication (maybe zero knowledge, in case
   message could bring author to jail...)
2. Author generates a random number (nonce) and
   calculates Hashsum(concat(random number,message)).
3. Author anonymously publishes the public key from
   step 1 and the hashsum from step 2 ("I will later
   claim authorship of a message...").
4. Some public authorities (as many as possible, whoever
   should be convinced of authorship later, e.g.    mailing list admins, notaries, universities,...)
   generate a signature for the public key and the
   hashsum published in step 3.
   This means: "We will accept the person who authenticates
   to this public key as the author of the message with
   this hashsum."
   This signature is publicly distributed (sent to a    mailing list, put on a web server,...)
5. If the author receives enough of these signatures,
   he can be sure to claim authorship later by using
   the secret key to authenticate.
   If the author doesn't receive enough signatures
   within a given amount of time, he repeats from
   step 2.
6. Author anonymously publishes the message and the    random number. The issuers of the signatures (and
   whoever trusts them) can now link the message to    a public key for authentication.
7. Whenever he wants, author can prove authorship
   by authenticating to the public key
   (which might be comfortable if it is a    zero-knowledge scheme and the police is waiting...)

@_date: 2001-09-09 21:21:29
@_author: Hadmut Danisch 
@_subject: Compression side channel 
Good point. The mistake seems to be mixing a (non-compressible)
secret and a (compressible, possibly attacker-chosen) message in one
compression run.  It seems to be a good idea to compress every
logical part of the plaintext separately (and to compress only
things which are compressible).

@_date: 2001-09-15 14:18:04
@_author: Hadmut Danisch 
@_subject: Which internet services were used? 
A german TV news magazine (ZDF spezial) just mentioned that
the terrorists prepared and coordinated
also by using the internet, but no details were told.
Does anyone know more about this?
[Moderator: I've listened to virtually all the news conferences made
so far. The FBI has yet to make any such statement.
In any case, however, why should we find this any more shocking or
unfortunate than terrorism being plotted using telephones, or paper
letters, or conversations? Why are there no hysterics noting "the
plotters travelled using AUTOMOBILES!"
If the plotters used encryption, well, literally hundreds of millions
of law abiding people do so every day as well. Most of the ignorant
reporters saying things about encryption use it too, even if they
aren't aware of it.  --Perry]

@_date: 2001-09-15 21:22:42
@_author: Hadmut Danisch 
@_subject: crypto backdoors = terrorisms free reign 
No. It cannot be easily distinguished. That's the mistake
almost all politicians do.

@_date: 2001-09-16 14:13:23
@_author: Hadmut Danisch 
@_subject: Did the US defeat wiretapping success? 
As far as I heard from the news (who knows how
much news meet reality...) the CIA and NSA could
not find a real correlation between the terrorists
and Bin Laden (or at least they couldn't within the
first days after).
German news magazine DER SPIEGEL (current issue, p. 27)
reports, that the german intelligence service BND
(Bundesnachrichtendienst) did find that link.
Usually wiretapping people of Bin Laden's organization is
found as good as useless, because these people keep
strict discipline when using phones. In contrast to that,
some of them dropped discipline after the attacks.
They did jubilate and strut with their attacks. This
was wiretapped by BND and forwarded to the US. The BND asked the US to keep this absolutely secret, because
the BND hoped to catch more of these phone calls and
thus more information, what obviously
wouldn't work if it got publicly known.
US senator Orrin Hatch is said to have publicly revealed
this wiretapping success, thus sealing this source of
Can anyone confirm this story?
What's the use of a crypto-ban and wiretapping, or
an intelligence service in general, if
american authorities behave like this?

@_date: 2001-09-16 19:08:31
@_author: Hadmut Danisch 
@_subject: crypto backdoors = terrorisms free reign 
Obviously. You can make it even more simple:
I send you one bit, e.g. a "1".
Was this plaintext or a ciphertext encrypted with a forbidden cypher?
Well, this leads to the conclusion that you have to forbid
sending 1s. Restrict communication to sending 0s. Hopefully nobody
discovers, that a "0" could be an encrypted "1"...

@_date: 2001-09-17 00:07:36
@_author: Hadmut Danisch 
@_subject: How to ban crypto? 
What the hell is the purpose of such a law?
I could not agree with, but at least see some
sense in a law against stego, but what is a law against detecting and defeating stego systems good for?
Where can I find details about this law?
[Moderator's note: It is called the DMCA, Hadmut. It is intended to
prevent people from finding ways around copy protection. --Perry]

@_date: 2001-09-17 11:50:13
@_author: Hadmut Danisch 
@_subject: [FYI] Did Encryption Empower These Terrorists? 
Depends on which kind of logic you apply.
Technical logic: Yes, you're right.
Policital logic: No, you're wrong.
The reason is, that air planes, phones, hotels, cars, etc.
are used by common people - those who elect politicians - and therefore can't be bad by definition. Policital logic:
What is used by most people who elected me, can't be wrong.
Which politician would dare to ban hotels?
In contrast to that, cryptography isn't commonly used or
understood. From a public point of view, cryptography is
something exotic, used by spys and secret agents, hackers,
terrorists, who need to keep their business secret. And even
worse: It's new (at least its civil use with internet). All
other things exist for decades and have become part of
normal life. Cryptography doesn't.
Therefore cryptography is treated differently by political
[Moderator's note: Everyone who's got a copy of Netscape or IE has
cryptographic software in their hands, and most of them have used it. --Perry]
And, beyond that, we have to keep in mind a certain detail:
Air planes, telephones, hotel rooms, rental cars are "civil"
equipment. In contrast to that, cryptography is a "martial art". It's history shows that it has been used for
military purposes for centuries, but far less than a century for
private purposes.

@_date: 2001-09-17 17:52:15
@_author: Hadmut Danisch 
@_subject: Which internet services were used? 
They had two websites in Germany, one for recruiting people
( and soliciting money ( as
german newsmagazine DER SPIEGEL reports
(see  )
The websites were closed a few days ago. Just before
one of it was closed, a hacker allegedly broke into it
and downloaded the 500 member addresses of a newsletter mailing list.
(see Allegedly one of the list members is one of the terrorists.

@_date: 2001-09-17 18:29:05
@_author: Hadmut Danisch 
@_subject: [FYI] Did Encryption Empower These Terrorists? 
That's a technical view. I was talking about a political view.
In a political discussion there's no point in technical arguments,
if less than 3% of citizens can understand what you're talking about.
So drop your technical point of view for a moment.
Of course, many people use Web browsers and https, but very few
of them realize that they're using cryptography. They are not
using https for encryption, they are using it because that's
they way to get that damned web page, no matter how and why.
And even of those who understand what's going on, most don't see
any difference between the old 40bit days and today.
Extremely few people are using cryptography _intentionally_
and are considering it as necessary.
I know only extremely few people who'd change their
political vote if cryptography was banned. I know only
few people who'd even care about.
Now imagine you're a politican. People demand to do
anything against terrorists. Banning cryptography
(i.e. writing a law which says so, not the technical
implementation!) is simple, cheap, and doesn't cost
voters. And it is worthful for PR.
That's the way it works...

@_date: 2001-09-18 10:59:58
@_author: Hadmut Danisch 
@_subject: FC: Majority of Americans want anti-encryption laws, poll says 
An emotional anti-crypto-campaign seems to have started.
Yesterday I saw a special issue of a german TV news magazine
("Report aus M?nchen"), one of their main themes were the
communication methods of the terrorists. The level of the report was poor. Though they had
interviews with an american and a german security expert
(I know the latter one personally, he's really an expert),
they did not manage to understand what the experts said
(the german one explained steganography).
They confused encryption and steganography several times.
The conclusion was, that cryptography enabled this kind
of attack. Not that they had any kind of encrypted message
or any hint that cryptography was actually used. Their
simple logic is that such an attack is not possible without
cryptography, therefore the attackers must have used cryptography.
Some time ago, a arabian man who i said to be one of Bin Laden's agents, was taken under arrest in germany.
The police confiscated some CDROMs he was carrying, but they
didn't find anything except harmless arabian texts on these cdroms.
The TV magazine took this as an evidence that they must have
used cryptography.
What a kind of logic: We didn't find any suspicious messages -> he must have used cryptography -> guilty.
These kind of magazines are the ones which influence
people's and politician's opinion.

@_date: 2001-09-27 10:39:55
@_author: Hadmut Danisch 
@_subject: [FYI] Antiques man guilty of Enigma charge 
There are many versions and variatons of the Enigma,
- three or four wheels
- number of wheels coming with the enigma
  (wheels could be changed, normally they
  came in an external box with up to 8 wheels.
  selection of wheels was part of the key)
- connections within the wheels
- construction of the wheel (1 or 3 "carry hooks")
- with or without plugboard
- 26 or 28 characters
Technical variations:
- with or without external display
- kind of power supply
Equipment variations:
- kind of wooden box
- kind of manual/instructions
- does it come with a codebook?
- kind and color of painting
Historical differences:
- commercial or military version
- how is it/the box labeled
- whom did it belong to
- what was it used for
- date of manufactoring
- for which encryption/key changing protocols
  was it used for

@_date: 2001-09-27 16:59:38
@_author: Hadmut Danisch 
@_subject: collecting an Enigma? [was:  Antiques man guilty of Enigma charge 
Some years ago, when I was at the university, the institute
had one enigma, which was bought at an auction. If I remember
well, it had cost about DM 15.000,- (about 7,100 US$).
The machine was in a very good condition, everything worked
well (of course, the original battery was removed), even
most of the light bulbs were still working. It was, however,
a very simple version (three wheels, no separate wheels, no
plug board) and I think, it was a commercial version. The
box was obviously modified after WWII to remove the signs
and labels of the Nazis, but except from that also in a good
A friend of mine collects old mechanical calculation
machines and therefore used to visit auctions. There are
special auctions for these machines and the catalogues usually
contained about 1-2 pages of old encryption machines as well
(mostly Enigma or Hagelin), but it's about 4 years ago that
I've seen such a catalogue. Prices may have increased meanwhile.
However, there is definitly a huge market for legal (and probably
also stolen ones) calculation machines, including encryption machines.

@_date: 2001-09-27 17:17:56
@_author: Hadmut Danisch 
@_subject: [FYI] Antiques man guilty of Enigma charge 
Are you sure about this?
I thought only the polish and the british deciphering teams
had "code-breaking" enigma machines (which became part of the
"bombe"). Wasn't the "Abwehr Enigma" a plain encryption machine?
[Moderator's note: I'm sure it was just a misstatement in the original
article. --Perry]

@_date: 2002-08-16 18:27:46
@_author: Hadmut Danisch 
@_subject: employment market for applied cryptographers? 
Same effect here in Germany.
I'm under the impression that security was never really done
for security reasons, but as a kind of fashion. Do it because
everyone is doing it. It's a problem of the decision makers.
Many companies don't effectively want to have security.
They just want to claim to have. Very few of them are really
interested in having a secure network structure. Decision
makers often still believe that "security" means having
a firewall and a virus filter. Meanwhile, virtually anyone has some kind of firewall. Everyone has installed some kind of virus scanning software
on the mailserver. That fulfills everything decision makers
know about security. Why waste money for a security engineer?
Why should we have a security engineer to keep the firewall
and the scanner alive, if our normal sysadmin can keep
the software alive as well?
I know several german companies who are explicitely looking
for a security specialist as an employee, but once you examine the job offer, you'll find that they don't want
a security engineer who makes their network or software secure. They're looking for a "security engineer" just to exist and to keep the mouth shut. Just to have an office
with the label "security", but not causing any trouble.
"Security" was never really a requirement, it was some
kind of fashion. Fashions come, fashions go. It's not seen
as causing revenue. So just drop it if times get worse. Security has crossed its highest level. It will decrease
from now on.

@_date: 2002-01-04 18:54:57
@_author: Hadmut Danisch 
@_subject: Hackers Targeting Home Computers 
On my private computer (DSL, dynamically assigned IP address), I
detect an increasing density of attack attempts. More or less serious
attempts happen every few minutes in average (depends on daytime). Highest density is in the evening hours, when hackers and victims
find time to be online.
This means the probability of an infection of an unprotected
private computer is quite high after only some hours of internet
access. Most ("normal") people I know use such unprotected
computers for internet access.

@_date: 2002-01-04 20:59:22
@_author: Hadmut Danisch 
@_subject: Hackers Targeting Home Computers 
There's good reason for the different results.
I'm located in Germany and my DSL line is from "Deutsche Telekom"
(T-DSL, T-Online). This is by far the biggest provider in Germany for private DSL internet access, and they also do provide large numbers of modem and ISDN accounts. They use
a few very well known ip address ranges for all DSL, modem and
ISDN customers. Scanning the T-Online address ranges allows you to find heaps of german private computers. Many of the attacks
I detect come from within the T-Online network, others often come from
the countries you describe. I compared results with some of the colleagues results and with results we get from commercial firewalls
at the same time. There is a significant difference. It
appears that the T-Online network ranges are a favored
target of many hackers/scanners/script kiddies.
There's no doubt that some attackers prefer attacking private
computers and select address ranges where they find most of
these computers.

@_date: 2002-07-04 22:54:11
@_author: Hadmut Danisch 
@_subject: Ross's TCPA paper 
I don't think so. As far as I understood, the bus system (PCI,...) will be encrypted as well. You'll have
to use a NIC which is certified and can decrypt the information
on the bus. Obviously, you won't get a certification for such
an network card.
But this implies other problems:
You won't be able to enter a simple shell script through the
keyboard. If so, you could simple print protected files as
a hexdump or use the screen (or maybe the sound device or any
LED) as a serial interface.
Since you could use the keyboard to enter a non-certified
program, the keyboard is to be considered as a nontrusted
device. This means that you either
* have to use a certified keyboard which doesn't let   you enter bad programs
* don't have a keyboard at all
* or are not able to use shell scripts (at least not in
  trusted context). This means a   strict separation between certified software and data.
  If Microsoft was able to do so, we wouldn't have   worms.

@_date: 2002-07-05 13:31:48
@_author: Hadmut Danisch 
@_subject: Ross's TCPA paper 
That *might* be a contradiction in terms.
If I understand this correctly, the TCPA or Palladium hardware will include some kind of memory management device, very similar
to the ones we have in hardware of the last years, but which stores
some kind of de-/encryption information for each page segment and
which de-/encrypts every memory access. Doesn't seem to be much of
a problem, except for speed.
But how does this device know which segments belong to the software
and which don't? Or how does it know whether an allowed or foreign task
is accessing the protected areas (which is the same question again,
= is the PC in a program segment which also belongs to the protected
area). If this is done the simple way, like a normal OS configures the
memory management when loading some executable software, the OS
might at any time give wrong information to the device. In this case, the security depends on the integrity and bug-freeness of the OS, because the OS _could_ do it, but it is not supposed to do it.
A more advanced way would be to have the program loaded by the operating system as before, but to have the Palladium device check
some kind of signature to verify the correctness of the OS loading operation. This might lead to an uncontrollable problems, if programs start to load DLLs. Is the TCPA/Palladium
trust transitive? If library A is trusted, and so is B, is then
(A+B) trusted?
A third way would be to keep the OS completely out of the job
of loading software/programs into memory, and to have it done
by the Palladium device. This isn't actually a third way, but
a redefinition of terms and a migration. The OS isn't the OS
anymore, because basic tasks of the OS have been migrated to
the Palladium device, which is now to be considered as a
piece of OS in silicon.
I didn't find the time yet to read the TCPA description in detail. But from my current point of view I doubt that this
will really work, provide the claimed security, and will still
be a useful computer at the same time.
I especially doubt that the same company, which completely fails to
make Outlook or Internet Explorer resistent against content attacks (viruses, worms, ...) will be able to provide
software which such a strict separation between trusted and untrusted
data, as it is required for such a project to work.

@_date: 2002-07-05 15:54:11
@_author: Hadmut Danisch 
@_subject: Absurdity? (Was: Ross's TCPA paper) 
Another question is:
How will you print? Certainly, you can't use just a plain
printer. Could be any microcontroller pretending to be a printer. So you need a certified and tamper
resistant printing device.
But what do you print on?
Yes, you need certified paper which refuses to
agree with being copied.

@_date: 2002-07-05 16:20:02
@_author: Hadmut Danisch 
@_subject: Ross's TCPA paper 
That's why I was talking about a shell script (or take any
other program to be interpreted).
What does need to be certified: The shell or the shell script?
The CPU doesn't recognize the shell script as a program, this
is just some plain data entered through the keyboard like
writing a letter. A shell script is not a program, it is
data entered at a program's runtime.
This moves one step forward:
The hardware (palladium chip, memory management, etc.) can
check the binary program to be loaded. So you won'te be able
to run a compiled program and to access protected information.
But once a certified software is running, it takes input
(reading mouse, keyboard, files, asking DNS, connecting servers,...). This input might cause (by interpretation, by
bug or however) the certified software to do certain things
which do not comply with DRM requirements.
At this stage, the running binary software itself is the
instance to provide the DRM security, not the palladium memory management anymore. I agree that this is not yet an "open sesame", but it shows
that the game does not play on the binary/memory management
layer only.
But who controls runtime input?
History shows, that M$ software is anything but able
to deal with malicious input. That's why the world is
using virus filters. That's nothing else than an external
filter to keep malicious input from an attacker away
from the running software.
By analogy, Palladium might require the same: an input
filter between attacker and running software. Since the
"attacker" is sitting in front of the computer this time,
this filter has to be applied to the user interface,
keyboard and mouse.
Maybe they'll install a filter between the keyboard and
the software, thus building a certified keyboard, which
filters out any malicious key sequences. And maybe you
can use your keyboard only, if you have downloaded the
latest patterns (like your daily virus filter update).
I agree that this depends on the assumption that the certified software is not perfect and can't
deal with arbitrary input. But that's reality.

@_date: 2002-07-19 10:34:33
@_author: Hadmut Danisch 
@_subject: Maybe no stego on eBay afterall 
What's the hamming distance between eBay pictures/messages
"containing" stego contents?
What's the probability that a random, clean picture is
falsely tested positive? How many "unusual" bits does it take
to make a picture appear as being a stego pic?

@_date: 2002-07-20 13:30:16
@_author: Hadmut Danisch 
@_subject: Maybe no stego on eBay afterall 
That's the point.
(As a European, I'm in the temptation to ask what's the
most US-patriotic position for the bar...)
Most (all?) statistical stego detection algorithms report
false positives with a given (hopefully known) probability.
So if you take a collection of just enough pictures you'll
always have a chance to find positives, and ebay is some
sort of "enough".
A more serious way to detect stego on ebay would be to have
a comparable database of clean images, and to show that
algorithms report significantly more (or less???)
stego-suspicious pictures than in the comparison database
(or than the expected probability of false positives in
pictures of that kind).
But how to build a comparable database? Or how to determine the probability of false positives? Maybe someone
at ebay used the same digital camera with a different firmware
version or a different program to colorcorrect/shrink the
images, and the comparison database doesn't compare anymore?
Maybe the author of the picture used some kinky method of
watermarking. A watermark is a kind of stego information.
If you sell at ebay, you can give a picture which is processed
by some image processing software at ebay. Maybe this software
causes some statistical turbulences?
I don't believe such stego claims before I see what kind of
statistical evidence was found or a real message was found.
(BTW: Does anybody know a statistical method to distinguish
stego used by terrorists and that used by other persons?
Wouldn't life be easier if we all could just agree that stego used for harmless purposes is restricted to the least
significant bit while terrorists use the second least
significant bit?)

@_date: 2002-07-20 14:10:15
@_author: Hadmut Danisch 
@_subject: Maybe no stego on eBay afterall 
I disagree for several technical, physical, photographical
reasons, but we can ignore this for this discussion, since
it is a standard method of physics to measure for a longer time or many samples at once and take the average to
reduce noise.
What do you want to show? If you hide an information this
way, how should the receiver decode/separate it? The receiver would need to know how your picture looked like before you added information or how to separate information belonging to the
white picture and information belonging to your message.
If you substitute just the LSB, you presume that the LSB is
an industrial-strength random bit sequence. But if this were
the case, why the hell should digital cameras bother to include
it in the stored image? If you have an image with a depth of
8 bit, where the LSB is just random nonsense, why not simply
cut it away?
And secondly, your transmissions are eye-catching. Why should someone transmit images of a white wall? As long as you need a picture of a white wall, I wouldn't even
call it steganography, just some strange way of encoding. It's easier to simply concatenate a plain jpeg-header and your
encrypted message, hoping that nobody tries to view the picture.

@_date: 2002-07-20 14:16:39
@_author: Hadmut Danisch 
@_subject: Maybe no stego on eBay afterall 
Of course. If the LSB wouldn't correlate to the higher order
bits in any way, they definitely wouldn't contain image information
and the camera would do a better job to simply cut them away.
Latest cameras use a higher resolution than just 8bit, so the
LSB of the image file isn't the LSB of the image anymore.
Another reason is the interpolation done by the camera (maybe the
LSB of the Foveon chip should be tested). And maybe the JPEG encoding.
Did you check any raw images?
On the other hand, even some of the latest and best cameras are
known to suffer from high image noise (e.g. Minolta Dimage 7i).
There is a software known to be quite good in removing this
noise ( Unfortunately, the source is not available.
But since these guys know pretty well how to remove this kind of
noise, they maybe know how to add some and make it look native.

@_date: 2002-07-20 23:29:45
@_author: Hadmut Danisch 
@_subject: Maybe no stego on eBay afterall 
I fully agree.
Go one step further: Every civilian who sells at ebay, puts a picture on the auction
web page, and doesn't take care that this picture can't be
reported falsely positive by some arbitrary software by any
company wishing to be in the headlines, can be considered being a terrorist as well.
So, simply, everyone selling on ebay with a picture (oops, I did
as well), is in danger of being considered as a terrorist. You never know what next month's stego detection software will
pretend to detect in one's picture.
And as we know, the US convicts terrorists at those lawless military courts.
Gee, I was never aware how dangerous it is to sell on Ebay.
(Any idea how to make a picture reliably stego free against
*any* stego detection software?)

@_date: 2002-07-22 12:54:30
@_author: Hadmut Danisch 
@_subject: "Freedom Corps" vs. Software Security? 
I just read the latest news in german news
magazine DER SPIEGEL
for those who understand german)
about Bush's "Freedom Corps" and the "TIPS" starting
in August (Terrorism Information and Prevention System).
They also mentioned that civil rights were simply turned off in the US after Sep11, e.g. a man was
arrested and is still in jail for nothing more than
just telling his opinion (the so called "freedom of speech").
The question is: Can american software be trusted anymore, when the
US government wants to turn 4% of the US citizens
into spys? If they already want to use common
people as plumbers, electricians etc. as spys, isn't it obvious that they will use a thing like
software as well?
Some years ago it was like this:
american software = good, trusted, friends, democracy
russian software  = evil, made by an empire for espionage
Is it possible that they are currently switching
(Not to insult anyone, just to start a discussion...)

@_date: 2002-07-01 01:07:23
@_author: Hadmut Danisch 
@_subject: Palladium Eye & Ear Implants 
============================== START ==============================
One of the main properties of the TCPA/Palladium
architecture is the (asserted) ability to limit information leaking to "untrusted" parties.
In what way does this affect the appearance of
computers as we know them today? It certainly
means more than that you can't simply forward
copyright protected informations by email in plaintext. I remember that about 20-25 years ago I read in one of the early computer magazines a proposal how
to build a cheap printer from a plain electrical typewriter by attaching a board with electromagnetically
operated punchers onto the keyboard without any
modification (!) of the typewriter itself.
Assumed that a "trusted" computer is completely
sealed, it still needs some kind of human interface,
probably a mouse, a keyboard, and a screen
(otherwise whould be questionable what to pay for).
Even if the computer is tamperproof, you still
could attach such a board simulating your fingers
on the keyboard and a camera in front of the screen
doing OCR. Should not be much of a problem to teach an untrusted Linux box to read from a trusted sealed machine, reading an e-book page by page.
As a consequence, it is not enough to just
encrypt the connection between the computer
and the monitor or the keyboard. An encryption of the connection between the computer and the authorized person itself is needed.
The solution would be to implant chips in one's head and to connect them to the eye
and ear nervers, thus injecting the
decrypted information directly into the
This also solves the problem that when
a person who has paid reads an e-book, always other persons who didn't pay could
watch too.
Of course, "blue screens" become a much
more intense experience once they can
happen directly in your head and completely shut down your visual and acoustical perception.
Hadmut

@_date: 2002-11-07 00:58:27
@_author: Hadmut Danisch 
@_subject: German authorities bungle wiretaps. 
That's a pretty good question.
Police and Secret Services demanded wiretapping access
as absolutely necessary for catching criminals etc.
Some politicians agreed for some short time, to give them a try, but to ask for evidence later, whether
this is of real use. AFAIK there was no evidence.
It was simply forgotten to ask for evidence.
On the other hand, wiretapping is currently not a
german thing anymore. Requests to enable "law enforcements"
come mainly from the European Community and - since Sep 11 - from the United States. Remember that it was the German Secret Service who found the link to Bin Laden
after the Sep 11 attacks through wiretapping phone lines.
Current wiretapping laws are "Made in Europe", not "Made in
Furthermore, it is pretty well known that by far more
wiretapping in Europe is done by the US/Canada/GB/Autralia
project Echelon, but since this is done the "illegal" way,
it obviously can't accidently appear on the phone bills.
But it's true, we have two problems at the moment.
First problem is that there is a lack of legal/political
control of "official" wiretapping.
Second problem is that there is almost no control
and no defense against the "inofficial" Echelon wiretapping.

@_date: 2002-11-13 13:05:37
@_author: Hadmut Danisch 
@_subject: Public Key Addressing? 
maybe someone can give me a hint to explain something:
Someone was writing an article in context of communication and network security. The article
contained a chapter about the need to distinguish
between the payload and informations needed to provide the service, such as addresses etc.
The chapter started with a few lines of introduction, where
the author said something like
  "When doing a phone call, phone numbers must be
  transmitted, and signals about the state of the
  connection as well."
Now a german professor of computer science, who
claims to be a cryptographer, denied this in a way which I translate to english like this:
  "This is a wrong statement about the technical details.
  It is wrong to claim, that, when doing phone
  calls, phone numbers must be transmitted. The author
  seems to take only the currently practiced ISDN protocols
  into consideration and ignored that, e.g. in particular
  for Packet Switched Networking with Public Key Addressing,
  as researched by Donald Davies as the original fundament   for the introduction of Packet Switched Networks, especially   this problem was to be bypassed/avoided."
He must obviously have confused something. It is commonly
known that the old analog phones had a dial as well. Public Key Cryptography (since he is talking in context of
cryptography, I presume that "Public Key Addressing" is
supposed to mean anything with Public Key Cryptography)
was invented in the seventies, while Packet Switched
Networks were developed in the sixties. Until now, I couldn't find any hint what Donald Davies could have
done which could be called Public Key Adressing.
The professor himself refuses any statement.
Does anybody have any idea, even an absurd one, what could
the professor have driven to this conclusion and what he
could have meant with Public Key Addressing?

@_date: 2002-11-17 22:04:26
@_author: Hadmut Danisch 
@_subject: Information Awareness Office 
a lovely anthology of concepts about human and
civil rights (american flavour) can be found at
best regards

@_date: 2002-11-20 10:58:29
@_author: Hadmut Danisch 
@_subject: 17 Cypherpunks subscribers on watch list, Project Lookout 
It's even worse: I know some american court decisions which limit the rights given in the american constitution to american citizens only. E.g. the fourth amendment does not
apply to non-americans, therefore police doesn't even need a
warrant to search their house or computer in the eyes of US justice.
e.g. the Gorshkov case:
Does anybody know how to get the text of the decision?

@_date: 2002-09-20 13:53:45
@_author: Hadmut Danisch 
@_subject: Court Decision about russian hackers? 
I'm looking for a court decision about a case where
FBI agents fooled russian hackers in order to gain their passwords and to intrude their computers.
Unfortunately (or better: fortunately) I'm unexperienced
with the american court system. Can anyone give me a hint where/how I can get a copy of the decision
or further information which court that judge belongs to?
The decision I am looking for was described in a german computer magazine's newsticker:
I'll try to translate the article:
  The russian secret service FSB has started an investigation against
  the american FBI agent Michael Schuler. He is accused of illegal
  intrusion into russian computers. Two years ago, he trapped two
  assumed russian hackers into the United States with a faked
  job offer of the faked company Invita Security. With a faked
  aptitude test the FBI stole the passwords of the russians and
  used them to download means of evidence from the hackers
  computers in rusia.
  A US court has declared those controversial methods of
  investigation to be legal. As reported by the US press,   judge John C. Coughenour had disapproved the request of the
  lawyer of one of the accused to not accept the files downloaded
  by the FBI as means of evidence. The lawyer claimed that the
  fourth Amendment had been violated by the FBI. The judge objected
  that the computers had been outside the USA and had not been   property of US citizens. For this reason the fourth amendment
  couldn't be applied. Furthermore, even if the FBI agents had
  downloaded the files without judicial permission, they had gained
  a permission before analyzing the 250 Gigabyte.

@_date: 2002-09-20 19:56:02
@_author: Hadmut Danisch 
@_subject: unforgeable optical tokens? 
Mmmh, assuming that this is really difficult to forge, it's not
silly and doesn't compare to biometric authentication. Biometric authentication is a different matter, always bound
to a person and usually tried to be used for authentication of
I see several applications where these tokens could be really
useful where biometric methods are completely useless. Main advantage
seems to be that these tokens are extremely cheap. There are heaps
of applications where these tokens seem to be just perfect.
Strangely, the application mentioned on the website, i. e. credit
cards, is not an application the tokens are suitable for, because
having an unforgeable token simply isn't the solution to the credit card problem (or at least not all credit card problems). Nevertheless, seems to be an interesting concept.

@_date: 2002-09-20 22:38:02
@_author: Hadmut Danisch 
@_subject: unforgeable optical tokens? 
Not really. Illuminating the device at different locations and
angles is certainly not as good as a cryptographical challenge.
Since the location and angle is done by some mechanical device,
the numers of locations and angles is certainly "small", and
once you are in posession of the token (e.g. as a clerk in the
shop), it might be possible to generate a complete table of
all location/angle/response triples.
Another question is how the reader verifies the token. There
must be some description of the token which allows to verify
the token. Is it possible to generate the token respones without
actually having the token? (are token and verfication information
a public/private key pair?).
I see the reader as a weak point, a second one is that the device
does not provide a signature. Even if the device was replay proof,
it's not possible to distinguish between payment of 20 or 40 Euro.
There are plenty of good applications for such a token, but credit
cards and payment are certainly not.

@_date: 2002-09-22 01:43:35
@_author: Hadmut Danisch 
@_subject: unforgeable optical tokens? 
That's the main problem of judging this token: Don't compare it with cryptographical methods.
This token is not a matter of cryptography, because
there's no secret and no exchange of information. No challenge, no response, no calculation, no stored information,
nothing. Therefore it is completely useless in context of computer networks, which - after all - do nothing else than carrying informations. That token can't perform a challenge-response
authentication, because it's a piece of plastic and glas, it doesn't listen to your challenge and it won't give you an answer.
It's just a gadget of the type "you can't make a similar one again",
and that's what it can be used for. Forget about networks and challenge response in context of this token.
Security is far more than just the cryptographical standard methods.
There's security beyond cryptography. So don't have this limited

@_date: 2002-09-23 01:00:56
@_author: Hadmut Danisch 
@_subject: unforgeable optical tokens? 
Maybe not for normal doors due to mechanical instability, but
for Hotel room doors.
My suggestion: Use it for vouchers, flight tickets, entrance tickets,
money notes, passports, license plates, tax stickers, ...

@_date: 2003-08-24 19:31:42
@_author: Hadmut Danisch 
@_subject: invoicing with PKI 
Beyond invoicing/contracting, which applications of PKI
in e-business or related areas are there anyway? (except for the standard tools SSL, X.509,...)
Is there a survey of where in e-business cryptography is actually being used between customers and providers?
How many shops do use SET for payment?

@_date: 2003-02-13 18:13:27
@_author: Hadmut Danisch 
@_subject: Stupid security measures, a contest 
One of the worst security measures I've ever personally seen:
Some years ago I was invited as an expert (for security) into a german
ministry/government department. I received a paper document which was
classified as "confidential". I was asked to take it with me, read it,
comment it, and then put it in a paper shredder.
As usual, every page of the document was marked as "confidential"
by having a large, bright grey writing from the bottom left to the
top right corner as a background of the text. (like the latex
draftcopy style)
At this time I was working at the University, and the University was short of money, so we had only a very cheap paper shredder which was
cutting the paper only in stripes of about 3-4 mm width instead of little particles as expensive shredders do. Usually it is still too difficult to sort the stripes.
It turned out that it was just the diagonal "confidential" label which
made it absolutely easy to sort the stripes and to reassemble the pages within seconds.
Another example:
There's a german bank which provides Internet Banking through a ssl
secured web page, which is after all not a bad idea. When you're on
the web page, it opens a new browser window through java script, which
then gives you access to the banking and asks for account number and
The web designers decided to open a window without the usual
browser decoration, i.e. without showing the URL the page came
function openwin(){
var WinName='Internetbanking';
  var param='"toolbar=no,menubar=no,scrollbars=yes,resizable=yes,status=yes,width=800,height=600"';
  var url='/OnlineBanking/fs_ie.html';
   var param='"toolbar=no,menubar=no,scrollbars=yes,resizable=no,status=yes,width=800,height=600"';
   var url='/OnlineBanking/fs_ns.html';
msg=open(url,WinName,param); So when you're on this page, you're on an encrypted page and the
browser shows the padlock symbol promising "security", but you can't
see whom you are talking with. So you could redirect the browser to
any other webserver with a valid SSL certificate and provide webpages
with a similar appearence, and ...[you know what].
I've contacted that bank and tried to explain the problem. They completely denied it and claimed that they have high
level experts, much more experienced than I am, and that they
all said that they use SSL with 128 Bit encryption, which is
absolutely unbreakable. :-)
(If you wanna see it, try  . You could
argue that it is not trivial to intercept and modify this already
ssl-encrypted page to perform some redirection. I've given this URL only for those who don't speak german and can't navigate through
the menues. Usually people start at  and with some
simple DNS spoofing or attack on a proxy it could simply redirect
telebanking to anywhere.)

@_date: 2003-02-14 18:48:19
@_author: Hadmut Danisch 
@_subject: Stupid security measures, a contest 
I had a similar experience:
When US ambassador David Aaron was giving a speech about the "safe
harbour" in December 1998 in Frankfurt, they had a metal detector
frame where you had to go through and an armed american security guard
who tried to look as evil as possible.
I had a suitcase with me and - it was cold - was wearing thick
clothes. When I went through the frame, it gave a very loud alarm.
The guard asked me to put the suitcase on the table and go through the frame again. I did so and again, there was an alarm. He asked me
to put my cloak on the table and to go through the frame again. Still
giving alarm. I had to put my jacket on the table and so on until I finally had undressed about 4 or 5 layers of clothes. When I was
wearing only the shirt, pants, shoes, and a tie, the alarm stopped
after I took out the belt. The guard was satisfied and allowed me to
pass without touching or even noticing the heap of clothes I put on
the table and my suitcase. (There's a similar scene when Clint
Eastwood is smuggling a tool in "Escape from Alcatraz".)
I asked him "Now you know that my belt was causing an
alarm. But how do you know that I don't have a gun in my cloak's
pocket or my suitcase which could have caused the alarm as well?"
For a second there was surprise and shock on his face, then he gave
me an army-like command to take my belongings, walk in and stop
causing a queue. But the unlucky guy who came just after me was
searched extensively.

@_date: 2003-02-14 20:42:38
@_author: Hadmut Danisch 
@_subject: Stupid security measures, a contest 
A little bit more about "guards":
In 1985/86 I did my compulsory army service in Koblenz, which also included to be the guard of the barracks for several days.
When I was the guard of the main entrance, once an army vehicle
approached to enter the area. I stopped the vehicle and asked for the
identity card, driving license, and driving order, just as usual.  The
guy in the car gave each, but it was obvious that all three were wrong
and forged. I told him to leave the car immediately and come with me
to the officer in duty. He smiled and said "Congratulation, this was a
security check and you have passed perfectly."
I answered "Nice try", immediately pulled the gun, and arrested him,
put him in the prison in the guard house, and informed the chief of the
barracks area.
It turned out that the guy indeed was a security officer of the army,
and it was his job to perform security checks like this. The security
department he came from was performing checks like that one for about 15
He said in about 25% of their checks the guards didn't realize that
the papers are wrong and let the person pass without questions. In
such cases the guards had failed the test.
In the other 75% of their checks the guards realized and stopped the
person, and so the guards had passed the check. But their officers
never ever had to prove that they performed a security check and they
never needed their real identity cards. He was the first one to find
himself arrested. It was always enough to say "Congratulations, this
was a security check and you have passed." to enter the area without
further questions and to leave a happy guard behind. No one ever had
any doubts. And nobody realized that this was a security leak.
The effect was that the officers of that security department were
entering barracks for 15 years as a security officer performing
security checks without ever having to show a valid identity card and
driving order, either in the first or the second way, and didn't
realize that this was a security problem.

@_date: 2003-05-13 15:18:21
@_author: Hadmut Danisch 
@_subject: A Trial Balloon to Ban Email? 
I doubt that any kind of anti-spam mechanism which requires such a certification will be widely accepted. And I do not believe that
any cryptographical method can be deployed widely enough to provide
security against spam. Cryptography is simply too complicated and too
error/theft-of-secret prone to be used in common. (If anyone is interested, I've made an alternative proposal based on
non-cryptographic DNS-based lightweight authentication/authorization,
available at  )

@_date: 2003-10-04 09:45:22
@_author: Hadmut Danisch 
@_subject: OOAPI-SSL/TLS (Was: Simple SSL/TLS - Some Questions) 
That's a pretty good idea, I also encourage you (and volunteer to
I definitely vote for C++ for several reasons. You already mentioned plenty of reasons yourself, the security advantages of C++. But be
warned: In contrast to modern scripting languages C++ is not
automatically immune against buffer overruns etc. It takes some
discipline to have a good programming style in C++.
The main advantage I see is the oportunity to have a good, object oriented design of the API to give an example of a good and usable Crypto API.
Everyone here has his own favourite language, I meanwhile prefer
Ruby. I had to write a CA some months ago and didn't find a good
language with SSL and Certificate management support, except for Ruby. Michal Rokos  was currently writing the
glue code to use the openssl library with ruby, and I found it very comfortable to use SSL from a scripting language. It was however a big heap of debugging, reading the openssl API and source
code, discussing requirements with Michal, ask him for extensions
etc., since it is quite difficult, to implement all features of openssl, and many of them are not logical. This project showed the shortcomings of openssl, it is not really a usable and complete
software. This causes insecurity, because it is too difficult for
application writers to use it and to support all features.
I'd therefore propose the following:
To design two (ore more) object oriented APIs for
- cryptographic primitives
- non-communication oriented functions (key and certificate
  management, S/MIME message handling, ...) - communication oriented functions (SSL/TLS)
but to not stick too tight to C++. The design must be applicable to all modern object oriented languages.
Then do a C++ implementation of the API (spell: header files) and
see, whether this is possible without tricks. Also have the API defined in other languages such as Python, Ruby, Java,...
Take care that the design is easy to read, easy to understand, easy to debug. Make use of object oriented design where possible.
Now implement the library itself in C++, while others write
the glue code for other languages simultaneously.
As a result, there will be a language-independend object-oriented
Meta-API, describing the library virtually for all languages.
For every supported language there is a "translated API" of this
and a library to use. For C++, this is a genuine library, for
other languages this will be glue code + the C++ library.
This would be a step to bring secure programming a step forward
towards modern programming, and to ease and support use of SSL/TLS/... I am currently quite happy with the way Michal Rokos wrapped openssl into an object oriented API, but it would be good to have this in more languages, it still allows improvements and
is still incomplete.

@_date: 2003-09-01 19:17:55
@_author: Hadmut Danisch 
@_subject: invoicing with PKI 
The reason I was asking is: I had a dispute with someone who
claimed that cryptography is by far the most important discipline
of information and communication security, and that its transition

@_date: 2003-09-16 22:03:13
@_author: Hadmut Danisch 
@_subject: quantum hype 
So as a result, Quantum cryptography depends on the known methods to provide authenticity and integrity. Thus it can not be any stronger than the known methods. Since the known methods
are basically the same a for confidentiality (DLP, Factoring), and authentic channels can be turned into confidential channels
by the same methods (e.g. DH), Quantum cryptography can not be
stronger than known methods, I guess.
On the other hand, quantum cryptography is based on several assumptions. Is there any proof that the polarisation of a photon can be read only once and only if you know how to turn your detector? AFAIK quantum cryptography completey lacks the binding to an identity of the receiver. Even if it is true that just a single
receiver can read the information, it is still unknown, _who_
it is. All you know is that you send information which can be read
by a single receiver only. And you hope that this receiver was the
good guy.

@_date: 2004-04-03 10:34:40
@_author: Hadmut Danisch 
@_subject: Do Cryptographers burn? 
this is not a technical question, but a rather
academic or abstract one: Do Cryptographers burn?
Cryptography is a lot about math, information theory, proofs, etc. But there's a certain level where all this
is too complicated and time-consuming to follow all those
theories and claims. At a certain point cryptography is based
on trusting the experts. Is anyone here on this list who can claim to have read and understood all those publications about cryptography? Is anyone here who can definitely tell
whether the factorization and discrete logarithm problems are hard or not? Today's cryptography is to a certain degree
based on trusting a handful of experts, maybe the world's top 100 (300? 1000?) in cryptography.
Does this require those people to be trustworthy?
What if a cryptographer is found to intentionally have given a false
expertise in cryptography and security just to do a colleague a favor,
when he erroneously assumed the expertise would be kept secret? Would
such a cryptographer be considered as burned? Wouldn't he give more
false expertises once he's getting paid for or asked by his government?
I'd be interested in your opinions.

@_date: 2004-04-04 16:53:36
@_author: Hadmut Danisch 
@_subject: Do Cryptographers burn? 
Thanks for the opinions.
Maybe I'll explain a little bit more about the background:
As some already may have heard I'm in a legal dispute with a
german University. I wrote a dissertation in 1998, and the supervisor
announced to give a good rate. I then signed off from the job as an assistant effectively to the date of the examination. I didn't know
that the supervisor and another professor had made a plan to implement a security infrastrukture for the faculty and to found a company, and
that this plan included that I would do the work in the year after the
examination. When I signed off, they couldn't fulfill the promises
they gave to the faculty, and thus canceled the examination to extort me to stay at the university and do the implementation. I refused
to pay that kind of "protection money" and thus they rejected my dissertation with false expertises. The advisor's expertise (who claims to be one of the world's top
cryptographers) is just a concatenation of arbitrary nonsense, and
wrong even in the basics of computer science. E.g. he claims that LZ
and MTF would effectively compress just anything. As an example for
the need to distinguish between payload and control information I said
that when phoning, not only speech is to be transmitted, but also
phone numbers and signals about termination of the connection.  He
rated this as completely wrong and giving wrong information, because
phone numbers would be used with today's ISDN Telephones only. As the
reason he gave an obituary in the London Times saying that Donald
Davies had died. Or he blames me for not citing literature that hadn't
been published when I submitted the dissertation. He claims that
rate-distortion theory and shannon encoding allow to pack n+1
independant bits into a single message of n bits (even with small n or
n=1. Just try to do it.). The second examiner said the dissertation would be completely wrong
but denied to give any explanation. I filed a lawsuit.
During the law suit, the university had informed me, that they would
never accept me to succeed in the examination. They would abuse a gap
in german examination law: courts are restricted to cancel bad or
wrong examinations, but they cannot give a positive examination
result. All they can do is to sentence the University to repeat the
examination. The University informed me that they had decided that
they do not wish me to work in science and thus I had to accept to
fail in the examination. I would have to modify my dissertation and to
include those mistakes the examiners had falsely claimed in order to
confirm that their rejection was correct. If I do that I would be
allowed to have a second try with a new dissertation and would receive
a bad grade which would keep me out of science. If I do not agree,
they announced to keep me in an endless loop of false
expertises. Every single one will take me years to sue against. I
refused that "deal".
I won both at the administration court and the appelate administration
court. The latter one found that the second examiner could never have read the largest chapter and didn't even open the pages of the
dissertation. This was already sufficient to cancel the examination action. The University then retracted the action to avoid being
sentenced. Obviously, this was an extreme disgrace for the University. The University had to give a new second expertise. If this expertise could
not confirm what the first expertise said, that the dissertation was
completely wrong, the advisor would face beeing fired, severe
compensation claims, and the ultimate disgrace. Within less then two weeks the University managed to get a third rejecting
expertise, this time from a professor outside Germany, who is indeed
known as one of the top cryptographers and a member of the board of
directors of the IACR. I filed a new lawsuit and could easily prove
that this professor had intentionally given a wrong expertise
(obviously to protect the supervisor from legal trouble):
- He wrote the expertise in less than two days. - The expertise is less than a page. He does not give any   reasons and claims that he cannot be expected to reason his   expertise. Reasoning is a strong requirement under german law.
- There is no "link" between the expertise and the dissertation.   He obviously didn't read it.
- He didn't find any single mistake. He just says that everything is
  already known and taken from literature.
- He didn't bother to inform himself about the given problem, the
  legal requirements, and the available grades. That's a strong
  requirement in Germany. Obviously, if someone accepts to write an   expertise and in advance knows that he won't need grades, then he
  knows that he will reject the dissertation before he has seen it.
- And he erroneously assumed that the expertise would be kept secret.   In Germany, the examinee has the right to get a copy of the
  expertise and raise objections. He was not aware of this and   based his expertise on the assumption that nobody would see it.
I then raised several technical and legal objections, and cited
literature which explicetly stated that such subjects have not yet
been published.
- He then had to admit that he couldn't prove his statement that all
  this was known in literature, and that he raised this claim to
  reject the dissertation because he didn't like it.
- He couldn't defend against any of my technical objections and
  citations. He is not even claiming that his expertise is correct,
  and obviously was completely surprised by the fact that I have
  access to his expertise (unlike the university where he is working,
  where they keep the expertises secret).
- When I demanded to receive reasons, he denied that and stated that
  he would not agree with the requirent to reason an
  expertise. Instead, he had based his examination on an "international
  consensus" that would free him from the need to give reasons.
  He also stated that it would be illogical to require an examiner to
  give reasons for his expertise, because candidates could succeed
  with empty dissertations then. (???)
So this expertise is just ridiculous and won't have any chance at a
court, except that it will take me again years for the lawsuit.
I then informed the IACR's board of directors and asked them whether
an organization, where such a person can become a director can be
trusted any longer in context of security and cryptography.
Surprisingly, they were not even surprised. The fully tolerate this
and even consider this as normal. It looks as if they consider this
kind of expertise as kind of self-evident. To help a colleague and
protect him from legal trouble seems to be much more important than
giving correct and reasonable expertises.
I discussed that with several friend and colleagues, all working in
security and cryptography, and they were all shocked. Everyone would
have bed that they would kick everyone out known to have given a false
expertise. But they don't. Very similar with the supervisor and the former second examinor: It is more than obvious that both had given intentionally wrong
expertises and were claiming technical nonsense. But everyone seems to silently accept this and to consider this as normal. When preparing for the lawsuit, I read several other dissertations in
order to compare them. I found several of them to be really wrong or
to contain nothing but citations from literature. One of these
dissertations would never have been published if I hadn't asked for a
copy. It was then published around two years after the examination and
contained just citations from literature. So what I found is fraud, extortion, false expertises. But not a single one of those cryptographers burns.
Maybe it's a minority writing false expertises. But it's a majority
accepting that.
So my doubt is not so much about that someone found the magic way to
factorize. It's about someone intenionally selling snake-oil or
backdoors and other's keeping their mouth shut and tolerate this as
they do it here.
I have three expertises proven to be intentionally wrong. One from
someone who is known to have no clue about security. One from someone
who is known as a cryptographer and once claimed to be one of the "top
four". And one from someone who is a director of IACR. And no one
cares about. Nobody told me I'd be wrong. Nobody doubted my claims,
objections, and technical arguments. I could easily show that all of
them have intentionally given wrong expertises. Some people even
explicetely confirmed that my dissertation is correct and the
expertises are wrong. This just doesn't matter in any way.
Isn't that spooky? What kind of business is cryptography?

@_date: 2004-04-14 16:01:01
@_author: hadmut@danisch.de 
@_subject: Definitions of "Security"? 
I'm looking for interesting and unusal defitions of the
term "Security" (or "secure").
I'm fully aware that it is difficult or impossible to give
a precise, compact, and universal definitions, and some
book authors explicitely say so. However, there are definitions
(or attempts to give those), and I'd be interested to compare
them. If you know of any definition that might be interesting
for any reason, please send me a link or citation. thanx

@_date: 2004-04-28 20:38:09
@_author: Hadmut Danisch 
@_subject: The future of security 
My guess is that it is unpredictable. As so many other things, it depends on so many coincidences, marketing, politics.
But what I do expect:
- I don't expect that there will be much progress in   maths and theory of cryptography. Very few inventions
  will make it out of the ivory tower, if any at all.
  Key lenghts will increase. We'll play RSA with   4096 or 8192 bit. They will find that Quantum Computers
  may be fast, but still bound to computation complexity.
- SSL/TLS will become even more of a de facto standard in   open source software and (new?) protocols. It will make   it's way into the standard libraries of programming languages
  (e.g. as it did for Ruby).
- I don't expect that we'll ever have a common PKI for   common people with a significant distribution. It's like   with today's HTTPS: The big ones have commercial certificates,   plain people use passwords and simple authentication mechanisms
  (like receiving a URL with a random number by e-mail).
- I guess the most important crypto applications will be:
    - HTTPS of course
    - portable storage equipped with symmetric ciphers       such as USB-Sticks and portable hard disks.     - VPN routers
    - Voice over IP
    - DRM
    - maybe in digital passports and credit cards
    - simple auth tokens like RSA SecurID, Aladdin eToken
      will become more commonly used.      - As a consequence, I guess that politicians will reopen the
  1997's discussion of prohibiting strong encryption. They already
  do. - Maybe we'll have less crypto security in future than we have
  today.   5-10 years ago I knew much more people using PGP than today.   Most modern mail user agents are capable of S/MIME, but it's hard
  to find someone making use of it. I'm a consultant for many
  companies, but not a single one of them uses it. Most modern   MTAs support TLS, but to my knowledge less than 3% of messages   are actually TLS encrypted in SMTP.
  It's strange, but law will become more important than cryptograpy. As a summary, I don't expect any innovations. Not more than within
the last 10 years.
But I'm pretty sure that security will be more and more important
and that's were I expect innovations and progress. Security doesn't
necessarily mean cryptography.

@_date: 2004-08-31 14:48:00
@_author: Hadmut Danisch 
@_subject: Compression theory reference? 
I need a literature reference for a simple problem of encoding/compression theory:
It can be easily shown that there is no lossless compression method which can effectively compress every possible
input. Proof is easy: In a first step, consider all possible messages of length n bit, n>0. There are 2^n different
ones. But there are only (2^n)-1 shorter messages, so there is no injektive encoding to encode all messages into
a shorter one. And then all codewords of length 100%.  But a non-computer science person does not understand that. Does anybody know a book about coding theory which explicitely states
the impossibility of such a compression method in plain language?

@_date: 2004-09-01 00:04:09
@_author: Hadmut Danisch 
@_subject: Compression theory reference? 
I have often heard that example and I used it myself several times.  I
do not use it anymore, because it is not that easy. There's a major
flaw in this example, and therefore it is not really a
counterexample. If the faculty found that flaw I'd be in a bad
You could define some reversible bizarre function f that does exactly
that job, i.e. for a given message m you need to apply f again and
again and after some finite number of calculations you'll find that
f(...f(m)...) = x where x = 0 or 1
So this is possible. Since the function is reversible, let's call
the inverse function f', and you'll find m = f'( ... f'(x)...)  where x is still 0 or 1
Ooops. What happened? Why does this work? Because the commonly used
counterexample has a flaw. The reason is that you can invert f(...f(m)...) only if you count the number of times you applied f. You need to know the number of times in order to revert = decompress it, because you need to apply f' exactly that
many times. You don't have any other stop condition. Applying f' is not a
proper recursion, it's an iteration.
So your information is actually stored in this number, not in 0 or 1.
The output of the compression function is not 0 or 1, it is that
hidden number telling how often you need to apply f to reach 0 or 1.
So just give it as a contradiction that there can not be such a
function because it could be recursively applied to result in a single bit is insufficient, it is not a contradiction. You need to consider the recursion depth and the inversion. But then
it get's so complicated that most people don't understand it anymore.
And the argument, that reaching a single bit recursively is a
contradiction, is gone. You need to store a number. So what? Who says
that this number isn't shorter that the plain message? And suddenly
your back deep in theory.
That's why I don't like that example. It's convincing at a first
glance, but I don't believe that it is correct.
I did. Unfortunately I didn't find a german one, because
it is very difficult to find a german professor witnessing against
any other. It's a tight community. I found some outside Germany. But they didn't give me a paper with signature, just e-mails. Will see whether the court will accept that. I've sent those e-mails to the dean of the faculty of computer science
to convince him that the faculty is wrong. As a result, he configured
the mail relay of the faculty to drop any e-mail containing my last name anywhere in the header. It's ridiculous and I would laugh if it wouldn't be exactly the
faculty that's said to be the best german faculty of computer science.  Very difficult. I meanwhile became an expert in german examination law
and it usually requires the examinee to proof that the examiners
opinion is wrong. But since I already have proven several times that
the university was lying intentionally to the court, they might take
that into consideration. After all, I have brought this forward, and I have done my duty. Now it should be up to the university to
respond. They didn't comment for more than four years now.
They say LZW and MTF. I have already given an example for LZW. They don't care. I've told them to take any random string taken from /dev/random under Linux. They don't care. The german principle is
that a faculty is always right by definition. I'll try that. Thanks.

@_date: 2004-09-01 00:23:19
@_author: Hadmut Danisch 
@_subject: Compression theory reference? 
Yeah, I just posted a lengthy description why I think that this counterexample is not a counterexample. The problem is that if you ask for a string of log(N) bits, then someone else could take this as a proof that this actually works, because a string of log(N) bits is obviously shorter than the message of N bits, thus the compression scheme is working. Hooray!
The problem is, that the number of iterations is not in the order of N, but in the order of 2^N, so it takes log2(around 2^N) = around N bits to
store the number of iterations. The recursion convertes a message of N bit recursively into a message of 1 or zero bit length (to your
taste), *and* a number which takes around N bit to be stored. Nothing is won. But proof that. This recursion game is far more complicated than it appears to be. Note also that storing a number takes in reality more than log(N)
bits. Why? Because you don't know N in advance. We don't have any
limit for the message length. So you'r counting register needs
theoretically inifinte many bits. When you're finished you know how many bits your number took. But storing your number needs an end symbol or a tristate-bit (0,1,void). That's a common mistake. When determining the compression rate for a file people often forget, that some information is not stored in the file itself, but in
the file system, e.g. the file length (telling where the compressed
data stops) and the file name (telling you, that the file was
compressed). That's basically the same problem.
thanks and regards

@_date: 2004-01-29 08:36:59
@_author: Hadmut Danisch 
@_subject: Canon's Image Data Verification Kit DVK-E2 ? 
Canon provides a so called Data Verification Kit
which allegedly allows to detect whether a digital image has been tampered with since it has been taken
with a digital camera.
I found the announcement at
 They say:
  How it works
  The kit consists of a dedicated SM (secure mobile) card
  reader/writer and verification software. When the appropriate
  function (Personal Function 31) on the EOS-1D Mark II or EOS-1Ds is
  activated, a code based on the image contents is generated and
  appended to the image. When the image is viewed, the data
  verification software determines the code for the image and compares
  it with the attached code. If the image contents have been
  manipulated in any way, the codes will not match and the image
  cannot be verified as the original. So some kind of hash code or digital signature is generated. Does anybody know details about this? I never heard that there
are digital mass market cameras which could generate digital
signatures.  But if the signature is generated inside the SM card
only, why should the PC where the image was modified be unable to
write the modified image the same way as a digital camera writes
an unmodified one? (And, btw., how do they detect that the
picture was taken at a real scene and is not a repro of a
modified and printed picture?)
I guess the secure mobile card generates some signature and they
presume that the attacker would not have access to the memory card. This would start to protect the image not from the moment it had been taken, but from the moment when it was copied from the card to other media. And it would require to trust the
Is there a technical description of those secure mobile cards available? I didn't find any details, just marketing blabla.

@_date: 2004-06-19 23:56:44
@_author: Hadmut Danisch 
@_subject: cryptograph(y|er) jokes? 
does anyone know good jokes about
cryptography, cryptographers, or security?
[Moderator's note: I know of several security systems that are jokes
in and of themselves, but that doesn't seem to be what you meant. :)

@_date: 2004-09-01 09:35:37
@_author: Hadmut Danisch 
@_subject: Compression theory reference? 
Thanks, that's a pretty good hint, especially because it contains an explicit statement, and it's an FAQ, making it easy to show, that
the university's claim is not just wrong, but silly. :-)

@_date: 2004-09-07 00:15:33
@_author: Hadmut Danisch 
@_subject: Spam Spotlight on Reputation 
I have mentioned this problem more than a year ago in context of my RMX draft (SPF, CallerID and SenderID are based on RMX).
Interestingly, nobody really cared about this major security problem.
All RMX-derivatives block forged messages (more or less).  But what
happens if the attacker doesn't forge? That's a hard problem.  And a
problem known from the very beginning of the sender verifikation
The last 17 month of work in ASRG (Anti Spam Research
Group, IRTF) and MARID (Mail authorization records in DNS, IETF) are
an excellent example of how to not design security protocols. This was all about marketing, commercial interests, patent claims,
giving interviews, spreading wrong informations, underminding
development, propaganda. It completely lacked proper protocol design,
a precise specification of the attack to defend against, engineering
of security mechanisms. It was a kind of religious war. And while people were busy with religious wars, spammers silently realized that this is not a real threat to spam. Actually, it sometimes was quite
the opposite: I was told of some cases where MTAs were configured to run every mail through spam assassin. Spam assassin assigns a message
a higher score if the sender had a valid SPF record. Since most
senders with valid recors were the spammers, spam received a higher
score than plain mail, which is obviously the opposite of security. People spent more time in marketing and public relations than in problem analysis and verifikation of the solution. That's the What can we learn from this?
Designing security protocols requires a certain level of security skills and discipline in what you want to achieve. Although RMX/SPF/CallerID/SenderID does not make use of cryptography,
similar problems can be sometimes found in context of cryptography.
Knowing security primitives is not enough, you need to know how to
assemble them to a security mechanism.  Good lectures are given about
the mathematical aspects of cryptography. But are there lectures about
designing security protocols?  I don't know of any yet.
And there is a new kind of attack: Security protocols themselves can be hijacked and raped by patent claims.

@_date: 2004-09-14 11:55:41
@_author: Hadmut Danisch 
@_subject: potential new IETF WG on anonymous IPSec 
Be careful. I believe that this is not as simple. It depends on what you use the key for.
If it is used for encryption, then something like "opportunistic
encryption" exists. After all, using an unverified key for encryption
is not yet worse than using no encryption. So even if the key might be the attacker's one, nothing is lost compared to plain
communication. But avoiding faked TCP resets is also a matter of authenticity. Does 'opportunistic authentication' exist?

@_date: 2004-09-15 17:53:19
@_author: Hadmut Danisch 
@_subject: Forensic: Who gave this crypto talk? 
I have again one of these special, strange, freaky questions. I'm still investigating some "unusual activities" in science and cryptography. There are some handwritten notes, they seem to be some kind of transcript of slides from a talk about cryptography. I need to find out when, where, and by
whom that talk was given. These notes already existed in the end of 1997, so the talk must have been given 1997 or before. The talk is about cryptography and system design theory. It is about 'layers', such as physics, electrical engieering, boolean functions, boolean circuits, algebra of polynomial power series, operating system, automata theory. It mentions an "access & authentication description language
for a modified secure unix-pw protocol", and comes to the conlusion that "crypto can act as a system science". Gus Simmons is mentioned several times, but this might not have been part of the talk but a personal annotation of the person who made the transcript. Does anyone know about such a talk?
(The notes are available at  )

@_date: 2004-09-16 22:28:59
@_author: Hadmut Danisch 
@_subject: public-key: the wrong model for email? 
Exactly. It is easy to protect web sites with SSL, but it is difficult
to protect e-mail against spam with PKC.
Because PKC works for this Alice&Bob communication scheme. If you connect to a web server, then what you want to know, or what authentication means is: "Are you really That's the Alice&Bob model. SSL is good for that.
If I send you an encrypted e-mail, I do want that _you_ Ed Gerck, can read it only. That's still the Alice&Bob model. PGP and S/MIME
are good for that. If you send me an e-mail with a signature, and there is any particular
relation between you and me, where it is important for an attacker to pretend to be Ed Gerck and not just anyone, even that is still the Alice&Bob model. PGP and S/MIME still work.
But that's not the way E-Mail works in common.
E-Mail means: Anyone on this world is basically able to send me an e-mail. And that's not yet an attack, because that's what
I want, that's why I put my e-mail address on my web page.
This is not Alice&Bob anymore. This is Anyone&Bob.
The sender of an e-mail does not need to pretend beeing a particular
person or sender. Any identity of the 8 (10?) billion humans on earth
will do it. What does it mean if the message has a digital signature? It most
certainly means that the sender is a human from planet earth. You could tell the same without a signature.
PKC is good as long as the communication model is a closed and relatively small user group. A valid signature of an unknown sender
has at least the meaning that the sender belongs to that user group. But if that 'closed user group' is all mankind, then this meaning
becomes useless. A digital signature is useful only if you know the
sender of if you can tell from the signature that the sender belongs
to a closed user group (e.g. is a citizen of some jurisdiction). But this is not the Alice&Bob model anymore. That's not what PKC is good for. There's another problem: Since e-mail does not require to forge mails from a particular
identity, but from anyone, you run into the problem that there are plenty of unsecure keys floating around. When Alice keeps her key well protected, an Attacker has no But for E-Mail, there is not just one Alice. There are
about 500 Millions of users.
Let's imagine that everyone has a public/secret key pair. How many of them use a Windows Computer vulnerable to the latest worm collecting all secrets from their computer?
If only 0.2% of those keys were compromised, that's still      1 Million of secret keys available for spammers etc.
Let's assume that this 1,000,000 keys were compromised within one year. That's an average of 2,700 keys a day. So the attackers/spammers/phishers have 2,700 fresh keys
every day to forge e-mail, and most of the owners will not even realize that their key was stolen within that day. This is where reality and the science of cryptography differ. It does not work because not all attackers agree to play the Alice&Bob game.

@_date: 2004-09-18 09:04:54
@_author: Hadmut Danisch 
@_subject: [anonsec] Re: potential new IETF WG on anonymous IPSec (fwd from hal@finney.org) (fwd from touch@ISI.EDU) 
Wikis are not that good for discussions, and I do believe
that this requires some discussion.
I'd propose a separate mailing list for that.

@_date: 2004-09-23 10:58:16
@_author: Hadmut Danisch 
@_subject: M-209 broken in WWII 
it is well known that british and polish scientists
had broken the german enigma in WWII. For those who can read german, there's an interesting
article on
  about how the germans broke the M-209 used by the US.
They found a man who was involved.

@_date: 2004-09-28 18:54:12
@_author: Hadmut Danisch 
@_subject: M-209 broken in WWII 
Sure, some of the first paragraphs:
As a german codebreaker in World War II
Klaus Schmeh 23.9.2004
For the first time a witness reported, who was involved in breaking the
US cipherdevice M-209
Even experts didn't know until some years ago that german deciphering
specialists broke ciphers of the allied in the second world war.
But several sources document, that the germans at that time succeeded
to decipher the US cipher device M-209. Telepolis associate Klaus
Schmeh, who is specialised on cryptology, has finally found a contemporary witness, who participated in the decryption of M-209
One of the most fascinating episodes of technical history happend in
World War II. At that time british experts on the manor Bletchley
Park near to London broke the famous german cipher device Enigma under
the strictest secrecy, where they used thousands of people and
for that time top modern data processing devices.
Until some years ago, the doctrine was, that the germans, in contrast
to the british, underestimated the potential of the science of deciphering and couldn't read the radio messages of their enemies.
It is known for just a few years, that this assessment is
'political correct' but wrong.For example, the former President
of the Bundesamt f?r Sicherheit in der Informationstechnik
BSI (German Federal Office of Security in Information Technology)
Dr. Otto Leiberich reported, that the germans broke the
US cipherdevice M-209 in the WWII, what was absolutely not an
easy untertaking. More documented successes in deciphering proof,
that the german code breakers were even among the best of the world.
The explanations of Otto Leiberich provided also an important source
of information for the author of this article, when he wrote his
recently published book "Die Welt der geheimen Zeichen - Die faszinierende Geschichte der Verschl?sselung" (The world of secret
signs - the fascinating history of encryption). An excerpt of this
book, that was published on Telepolis, caused a little sensation:
A 84 year old man from Frankfurt reported to the author and explained
that he was involved in breaking the aforesaid US cipherdevice M-209.
After there were only second-hand reports about german codebreakers
in WWII, for the first time an eye witness appeared, who furthermore
brought some completely new aspects to light. With this article the
memories of this contemporary witness are published for the very first OK, these are the first few paragraphs. If you want to have more about
this you should ask the publisher for a translation, because under german copyright law even the translation is a right of the author.

@_date: 2005-08-07 01:24:50
@_author: Hadmut Danisch 
@_subject: solving the wrong problem 
When I came to Washington DC last november, my portrait and
fingerprints were taken for the first time. I was the last one in the
queue and the immigration officer was a nice guy, so I asked him how
this should protect against terrorists. As far as I read in the
newspapers, the 911 attackers just came under their real identity with
their own passports. He smiled and told me, that this is not about terrorism. It is about
illegal immigrants. A complete criminal infrastructure has
established. As soon as my passport is stolen or if I lose it, they
will have someone who looks similar as me and tries to enter the US with
my passport. The problem is that they do not modify or temper with the
passport in any way. The officers do not have any chance to detect
any flaw with the passport, since it is still an authentic one. Their
problem is not detecting forged passports, their problem is whether
the passport belongs to the person. That's why they are taking
fingerprints and pictures. Once the owner of a passport entered the
USA and is in the database, they can detect if someone else is trying
to enter with the same passport.
Detection of the fiber structure wouldn't help here.

@_date: 2005-12-14 15:06:05
@_author: Hadmut Danisch 
@_subject: How security could benefit from high volume spam 
How security could benefit from high volume spam
The parliament of the European Union today has passed a law that
electronical call detail records, such as phone numbers, e-mail addresses,
web accesses of all 450 million EU citizens are to be recorded and
stored for 6 to 24 months. So everyone will be subject of
complete surveillance of telecommunication. No place to hide.
The given reasons are the need to investigate and prosecute terrorism
and severe crime. But there is no evidence that this law
actually has this effect, and that it is worth to sacrifice democracy
and civil rights. Our constitution protects the right to communicate
confidentially, for all citizens, and especially for lawyers,
journalists, priests, etc. So terrorists finally begin to
succeed in destructing our european, modern, democratic, and free way
of life and civil rights. It is ridiculous that the modern world has
not been attacked by a large army, but by just about 30-40 people with
knives and a few bombs. The attack is not the primary attack
itself. The main attack is to provocate overextended counter
measures. Technically spoken, a denial-of-civil-rights-attack. And the
EU proved to be vulnerable to this kind of attack. A patch is not
available yet.
Another threat to privacy and civil rights is the intellectual
property industry. We have seen Sony attacking and sabotaging private
computers, revealing private data, taking secretly control over
people's communication and working equipment. We have seen a mother of
five been sued into bankruptcy in the USA just for listening to music.
This is perverse. We currently see governments considering to outlaw
open source software or any kind of data processing or communication
device without a digital rights management. There are good reasons to
assume, that the European Union's collection of all telecommunication
details will be abused to allow the intellectual property industry to
completely track every communication. Just having received any e-mail
from someone who had illegally downloaded music could be enough to have
your home searched, your computer confiscated, and find yourself sued
or prosecuted. The art and science of communication security will have to realign and
focus on new goals. When designing telecommunication protocols we have
to take much more care about what communication could reveal about the
communication parties and the contents. It is not enough to just put
some kind of simple encryption on a message body. We need to protect
against traffic analysis, in particular the one without democratic
legitimation. What does that mean?
When designing a protocol we should take more care than we did to
describe its vulnerability for and resistance against traffic
analysis. Not just whether the contents are encrypted, but what an
eavesdropper can tell about the communicating parties.  We need to
incorporate techniques like oblivious transfer and traffic hiding.
An important component of such protection methods is noise. Plenty of
noise. Something to hide in, to cover, to overload recording of call
details. We should think about and research how to produce noise. We already have some noise. Its called spam. Some of you might know that I am one of the early days fighters
against spam. I tried to eliminate as much spam as possible. But now, there could be a positive aspect about spam, virus mails, and
other mass mails. Maybe it could become an advantage to receive a
million mails per day from any senders. Maybe that is what is needed
to hide my personal e-mails. Maybe that's the answer I have to give
when someone blames me to have received e-mail from the wrong person:
"I have no idea what you are talking about. I received about 150,000
virus and spam e-mails that day from arbitrary addresses, and didn't
read a single one of them. I have just deleted them." When designing
measures against spam, we should take this into consideration.
Maybe in near future the advantages of that noise produced by millions
of bots will outweigh the disadvantages?
Comments are welcome.
Hadmut Danisch

@_date: 2005-01-02 12:59:14
@_author: Hadmut Danisch 
@_subject: Where to get a Jefferson Wheel ? 
does anyone know where I can get a Jefferson Wheel or a replica?

@_date: 2005-01-05 19:29:50
@_author: Hadmut Danisch 
@_subject: Where to get a Jefferson Wheel ? 
From what I've seen on the web not even that:
Unlike the original Jefferson wheel these toys are not
intended to choose any row, but to use the row directly
under the plaintext row as cipher text. Instead of the
line indicator from Jefferson, they have a sliding
bar with two windows for two subsequent rows.

@_date: 2005-01-30 19:08:00
@_author: Hadmut Danisch 
@_subject: Cryptanalytic attack on an RFID chip 
If I recall correctly, there are two different electronic
functions in key cars. One is the theft protection where the chip needs to authenticate when starting the engine (in Europe e.g. Ford
introduced this some years ago, the keys had a red, and the car came with a fully red master key (yes, both a mechanical and
cryptographical key) which allowed to teach the car to accept
additional keys). The other function is the remote control to open the
doors by pressing a button at the key. Does this attack compromise the theft protection only or the door
opener as well?

@_date: 2005-07-05 21:07:05
@_author: hadmut@danisch.de 
@_subject: [Forwarded] RealID: How to become an unperson. 
Don't laugh. This is exactly the problem I had with my
german identity card.
In Germany, you are required to possess either an identity card or a passport once you reach the age of 16. If you're younger you
can just have a children's passport in case you need for travelling. Usually applying for an ID card is not a problem at all.
For reasons far beyond cryptography my father chose an
unusual given name for me, one that was usual in around the 8th-10th
century. He named me Hadmut. Most people in Germany have never heard
that name before and don't believe, that this name exists. There is
another name, Hartmut, which is ethymologically different, but sounds
similar. Therefore, most people assume that my name is just
misspelled and would correctly be Hartmut. When we moved to a different town some years ago, someone made a
mistake in the municipal register, and entered 'Hartmut' instead of
'Hadmut', obviously because he or she believed it was misspelled.
When I applied for an ID card after my 16th birthday, they told me
that they can't issue one, because my children's passport said my
given name is 'Hadmut', while the register said that I am 'Hartmut'. Whoever I decided to be, I would not receive an ID card before I could
prove which of both I am. They asked me to bring a certified copy of
my birth certificate. For reasons even more beyond cryptography, that
copy was lost years ago. So I had to go to the registry office where I
was born to get another copy. Fortunately, this was just 20 minutes by
bicycle away. For privacy reasons, you can't just go to a registry office and ask
for anyone's birth certificate. You have to proof your identity - with
your ID card. Exactly that circular problem as mentioned in the
But when I explained that circular problem, they checked by phone with
the town's registry office and gave me the copy of the birth
certificate without an ID card to solve the problem.
But nevertheless, I do not understand why americans are so afraid of
an ID card. It has by far more advantages than disadvantages, and
actually the US driving license is already a kind of ID card. And
whenever I enter the US, I have to give the fingerprints of my index
fingers and they take a picture of me. That's worse than an ID card. Remember the PGP signing party at the 1994 IETF meeting in San Jose? Several participants who had never seen me before did sign my PGP key after I showed them my german ID card (including Perry). Funny side effect: Since most americans don't know that we have ID
cards in germany the card is almost always believed to be a driving
license in the US. Hadmut  (currently in Boston, MA, after giving fingerprints at the airport immigration)

@_date: 2005-07-06 00:09:34
@_author: hadmut@danisch.de 
@_subject: [Forwarded] RealID: How to become an unperson. 
Thanks for the hint, but I am too busy to read it in detail before
next week.
However, there is a funny thing I need to mention:
- In Germany we have an ID card and I have it in my pocket all the
  time. But actually it is rarely used, I do need it not more than
  maybe three times a year. At the moment I can't remember to have it
  used within the last two years, except for in my job when entering
  high security areas and some protected company premises. But rarely
  in private life. I know one shop where they do ask for when paying
  with a card.
- In the USA they say they don't have ID cards.   But whereever I walk through the streets of cities at the
  east- or westcoast, they all ask me for picture IDs. Some years ago   I couldn't even enter a night club without a picture ID, and in
  every supermarket they have signs that they don't sell alcohol or   cigarettes without picture ID (besides the fact that I neither drink
  nor smoke). Even in some hotels and gas stations they ask for a   picture ID.
Isn't that ridiculous? In the USA where they allegedly don't have ID cards
you are approx. more than 20 times as often asked for a picture ID than in Germany where we have ID cards officially. Last November I attended an Anti-Spam-Summit at FTC in Washington DC. As usual they were checking for metal in the clothes, x-raying bags, and (*surprise*) asking for a picture ID. Someone didn't have a driving license. They accepted his WalMart Customer Card as a picture ID. Isn't that scary?

@_date: 2005-05-26 23:51:13
@_author: Hadmut Danisch 
@_subject: Papers about "Algorithm hiding" ? 
you most probably have heard about the court case where the presence
of encryption software on a computer was viewed as evidence of
criminal intent.
Plenty of research has been done about information hiding.
But this special court case requires "algorithm hiding" as a kind of
response. Do you know where to look for papers about this subject?
What about designing an algorithm good for encryption which someone
can not prove to be an encryption algorithm?

@_date: 2005-11-07 00:28:04
@_author: Hadmut Danisch 
@_subject: HTTPS mutual authentication alpha release - please test 
Mmmh, I'd have two questions about this:
- It seems that you are not defending against an attack, but trying to
  protect the user against his own ignorance. The user ignores the
  warning label, so you want to replace it with a bigger warning
  label. But the bigger warning label doesn't contain any news or more
  information, or any protection that the smaller label doesn't
  provide. It's just that the bigger warning label is bigger (or more
  red, or more alerting letters...), hoping to wake the user up?
  But user ignorance is not a new type of attack. If the user pays
  attention to the browser warnings, then I don't see what advantage
  WIKD should have. Inventing new protocols and complexity, and
  trusting an additional party without good reason and reasonable
  advantage is never a good idea in security.
- The authorized owner must be able to replace the server certificate
  with a new one at any time, e.g. when the secret key has been lost
  or compromised.
  case 1:  If it is not possible to update the hash stored at WIKID,
  how would the authorized owner ever be able to replace the
  compromised key with a new one? Wouldn't this force him into
  continuing in using the compromised key?
  case 2: If it is possible to update the hash stored at WIKID, and if
  the attacker was already able to register a bogus certificate at an
  official CA, why shouldn't he be able to update the certificate at
  WIKID as well? In what way is WIKID's certificate verification
  procedure more reliable than the one of the "trusted CAs" ?

@_date: 2006-04-26 18:33:43
@_author: Hadmut Danisch 
@_subject: History and definition of the term 'principal'? 
is anyone aware of a general and precise definition of the term 'principal' (as a noun) in the context of security?
I need to solve a dispute. Someone claims, that 'principal' is an
established 'concept' introduced by Roger Needhams, but could not give
any citation. Someone else confirms this and claims, that 'principal'
is indeed a 'well-introduced' concept, but also can't cite any source
or give any definition.
I have read through Needhams papers (Needham-Schroeder-Protocol,
BAN-Logic), but just saw that he used the term 'principal' without any
definition, just as a normal word of plain language. Since I am not a
native english speaker it is not a simple task to precisely understand
whether the word is used as a special technical term or just as a word
of common language.
Unfortunately, Needham died some years ago, and I couldn't ask him
anymore. I have asked his co-authors, and they said that they are not
aware that he ever had invented or defined this term. Instead, the
directed me to Jack B. Dennis, Earl C. Van Horn: Programming Semantics for
Multiprogrammed Computations, Communications of the ACM, Vol. 9,
No. 3, March 1966, pp 143-155, where the term was used for the
first time in context of computers. Interestingly, they took that
legal term to describe the one who is liable to pay the costs of
computation jobs, which were expensive at this time (thus probably the
term 'account'):
  "We generalize this notion by defining the term _principal_ to mean
  an individual or group of individuals to whom charges are made for
  the expenditure of system resources. In particular a principal is
  charged for resources consumed by computations running on his
  behalf."
Then, Jerome H. Saltzer and Michael D. Schroeder used the term in
"`The Protection of Information in Computer Systems"', October 1974, as an abstraction for accountability:
  "A principal is, by definition, the entity accountable for the
  activities of a virtual processor."
This is, where I lost the historical track of the term. Needham and
Schroeder used the term in their paper about the
Needham-Schroeder-protocol, but without any definition or introducing
it. Many books about security don't even mention the term. There are other books (e.g. Menezes, van Oorschot, Vanstone, Handbook
of Applied Cryptography, or Ross Anderson, Security Engineering),
which explain the term, but in most cases only in one simple sentence,
without any precise definition. Nobody cites any source for the term,
nobody makes further use of the term, and all those explanations I
found differ heavily from each other, some are even contradictive.
Some say a principal is someone who participates in a cryptographical
protocol. Others say, it is a human, a computer, or a network device.
Some say, a principal is someone who has a name and is known and
introduced to a security system. At least one says it is a synonym for
'party', but gives three different definitions within one
book. Wikipedia doesn't know the term in context of security.
The only precise definition I found is in a law dictionary where it is
defined as a legal term.
Since nobody cites anything, everyone defines on his own taste, nobody
actually makes use of it, I assume that this term does not have a
precise meaning. Seems to be just a common word of the english
language without any particular meaning or importance in network
security. Still difficult for a non-native english speaker.
Can anyone give me some hints? Maybe about how 'principal' is related
to Roger Needham? Or whether there is a precise and general
Who, btw, would have the authority to generally define terms in
security science?

@_date: 2006-04-26 21:33:10
@_author: Hadmut Danisch 
@_subject: History and definition of the term 'principal'? 
Many thanks for the hint. :-)
Are there different editions of Kaufman-Perlman-Speciner ?
My edition of 1995 has two entries for principal in the index:
- Page 129: "A principal is anything or anyone participating   in cryptographically protected communication."
- Page 266: "each user and each resource that will be using   Kerberos."
Which edition is yours?

@_date: 2006-04-28 09:20:36
@_author: Hadmut Danisch 
@_subject: PGP "master keys" 
You should check the list of recipient keys in PGP messages from time
to time anyway. I recently found a bug in an MTU plugin: Once you had
a PGP pubkey with an empty ID in your keyring, the plugin had always
added this key to the recipient keys, although the owner was not
listed as a recipient of the e-mail. As far as we debugged, the key
had to be in 'trusted' state, but it worked. Once you managed to have
your pubkey added to someone else's keyring with an additional empty
user ID (what most users never realize) you could read any encrypted
mail sent by that person.

@_date: 2006-09-07 20:51:21
@_author: Hadmut Danisch 
@_subject: RSA SecurID SID800 Token vulnerable by design 
I recently tested an RSA SecurID SID800 Token
The token is bundled with some windows software designed to make
user's life easier. Interestingly, this software provides a function
which directly copies the current token code into the cut-and-paste
buffer, when the token is plugged in into USB. This is weak by design.
The security of these tokens is based on what RSA calls "two-factor
user authentication": It takes both a secret (PIN) and the
time-dependend Token-Code to authenticate. The security of the
Token-Code depends on the assumption that the token is resistant
against malware or intruders on the computer used for communication
(web browser, VPN client,...).
However, if the Token Code can be read over the USB bus, this
assumption does not hold. A single attack on the PC where the token is
plugged in would compromise both the PIN (e.g. with a keylogger) and
the token itself (e.g. writing a daemon which continuously polls the
token and forwards the token in real time to a remote attacker.
Ironically this could make an attack even easier: If some malware
simultaneously monitors the token and the keyboard, it is much easier
to detect that the keystrokes are actually related to some login
Whenever the 6-digit token code appears in the keyboard or
cut-and-paste input stream, you can be pretty sure that in a sliding
window of about the last 100-200 keystrokes both the PIN and the
address of the server to login is contained. Makes it really easy to
automatically detect secrets in the input stream.
Thus, two different authentication methods are together weaker than
each single one.

@_date: 2006-09-08 20:22:55
@_author: Hadmut Danisch 
@_subject: RSA SecurID SID800 Token vulnerable by design 
Hi Lance,
Partly agreed. These kinds of attacks I usually teach in my
workshops. However, in all of these cases the attacker has to be online in the
moment you are logging in and you experience any failure, e.g. can't
login or something like that. But with the SID800 malware could silently sit in the background and
pass token codes to the attacker even if you do not login at this
moment. E.g. it could wait until you have logged in (or out) and grap
the next token code.
Furthermore, the attack you described presumes that the attacker knows
where you want to login. But when you could use the current token code
as an indicator for searching login data in the input stream, then you
can find new places to login, e.g. your company VPN access point.
While the attack you describe is more important for banking, the USB
attack is more against company logins.

@_date: 2006-09-08 23:43:21
@_author: Hadmut Danisch 
@_subject: RSA SecurID SID800 Token vulnerable by design 
Yeah, however, it is a smart device which provides a reasonable level
of security in a very simple and almost foolproof way (I know a case
where the users complained that it did not work. They had to be told
not to type in the serial number engraved at the backside, but the
number displayed on the LCD...). It's a pity to see it weakened without need to.

@_date: 2007-02-26 21:20:29
@_author: Hadmut Danisch 
@_subject: padlocks with backdoors - TSA approved 
has this been mentioned here before?
I just had my crypto mightmare experience. I was in a (german!) outdoor shop to complete my equipment for my next trip, when I came to the rack with luggage padlocks (used to lock the zippers). While the german brand locks were as usual, all the US brand locks had a sticker    "Can be opened and re-locked by US luggage inspectors". Each of these (three digit code) locks had a small keyhole for the master key to open. Obviously there are different key types (different size, shape, brand) as the locks had numbers like "TSA005" tell the officer which key to use to open that lock.
Never seen anything in real world which is such a precise analogon of a crypto backdoor for governmental access.
Ironically, they advertise it as a big advantage and important feature, since it allows to arrive with the lock intact and in place instead of cut off. This is the point where I decided to have nightmares from now on.

@_date: 2007-02-27 08:10:42
@_author: Hadmut Danisch 
@_subject: padlocks with backdoors - TSA approved 
There's nothing spectacular about it. That's the one I have bought:
That's another one:
The TSA keyhole is always on the other side such that you don't see them.
I am currently in a hurry, but I'll make a picture today and post ist.

@_date: 2007-02-27 16:53:25
@_author: Hadmut Danisch 
@_subject: padlocks with backdoors - TSA approved 
Hi Allen,
Why make it that difficult and complicated?
You can easily and immediately open most combination locks with
vertical wheels on suitcases (and probably those at padlocks). All you
need is a flashlight. The wheels are usually a little bit loose. Just shift it to the left
or to the right with your finger tip and use the flashlight to peep
into the gap. You will spot the axis of the wheel. Now turn the wheel
until you see the chamfer pointing directly to you. Proceed with all
wheels. If the lock doesn't open, turn all wheel by 180 degree (to digit n+5
mod 10). Some locks need the chamfer up, some need it down to open.
With a little practise and experience it is almost as fast as if you knew the combination code.

@_date: 2007-02-27 16:57:49
@_author: Hadmut Danisch 
@_subject: padlocks with backdoors - TSA approved 
Same what I do, especially because opening luggage in absence of the
owner is rather unusual outside the USA. Sometimes I also "seal" the case with any unusual sticker I got somewhere for free or a paper
The method with the cable binder became difficult since it is
forbidden to have a nail scissors in the bord luggage. Sometimes not
that easy to open it without damaging luggage without a tool.

@_date: 2007-02-27 17:05:52
@_author: Hadmut Danisch 
@_subject: padlocks with backdoors - TSA approved 
It does not need access to the keys. Do you know that car Volkswagen Golf? As far as I know also sold in
the USA. In the eighties there was a problem: Many of the had been stolen
without visible force. No broken window, no broken ignition lock.
They finally found the method:
These Golfs had plastic fuel tank caps, which could be easily broken
off by hand. Just grab it, tear it away with force, and you have it.
The tank cap had a lock inside. All you needed to do is to cut the
plastic lock open and to copy the tumbler lengths to a blank key. Then you have a working key. You could do the same and just open some of these locks, one per key

@_date: 2007-02-27 17:55:10
@_author: Hadmut Danisch 
@_subject: Details of the backdoor-padlock 
============================== START ==============================
made two pictures of the padlock with the backdoor:
shows the TSA keywhole: Just a very simple standard key cylinder, pretty easy to produce a general key from any lock. But that's waste of time. The lock suffers from the same weakness
almost all locks of this kind do: You don't need any key or code to open them: See The 'secret' code is still 000. When you turn the wheels for
exactly 180 degree (thus the 5 is up on the rightmost wheel), you can see that chamfer of the axis on the left side of the rightmost wheel. It is visible, but must point down to open.
Turn the wheels until you see this, and then turn them another
180 degrees, and: "Open Sesame!"
So no need to bother with a TSA key. Open it directly.
