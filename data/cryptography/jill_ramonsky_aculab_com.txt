
@_date: 2003-07-08 11:29:22
@_author: Jill.Ramonsky@Aculab.com 
@_subject: Encrypted Virtual Drives 
Could anyone offer any thoughts on what is the "best" encrypted virtual disk
drive, which can run on (at least) Windows XP Pro.
I used to use the free version of PGPdisk (which you get with PGP version
6.0.2i), but that won't work with Windows XP.
I also used to use ScramDisk, but that also won't work with Windows XP.
I have been using new version of PGPdisk (PGP version 8.0), but there are a
number of problems with that: being (1) the license ($50) seems to be
enforced per-computer, not per-user, so if you upgrade from one computer to
another you either have to pay again or plead your case with the PGP
Corporation's support centre (which is only open during office hours Monday
to Friday, so don't try this during the weekend), and (2) their web site had
some problem last weekend such that it wouldn't actually let me buy a new
license even though I was prepared to pay for it, and (3) the format of the
container volume is totally incompatible with that of PGP 6.0.2i. These
problems combined mean that if your computer totally dies, to get your data
back (assuming the existence of a backup) you are reliant on a single
company to grant you a new license to get the software working, and getting
that licence is not necessarily easy.
I have also tried the new version of DriveCrypt (the successor to ScramDisk)
... but I worry about this because the company who make this (Securstar) no
longer provide source code.
I'd kind of like to write my own, but doing the crypto is just the easy part
- the hard part is actually writing a virtual drive - I can't find any
tutorials on that part.
So I put it to this list, what do folk here reccommend?

@_date: 2003-07-10 12:04:33
@_author: Jill.Ramonsky@Aculab.com 
@_subject: SSL 
I've been following the SSL thread with great interest, but the truth is I
don't know enough about SSL to add anything meaningful to the discussion.
But this much remains true: I'm a competent programmer, and I know enough
about crypto to put together some basic algorithms (like the early PGPs I
guess). However, the complexity of the OpenSSL library has me stumped.
(Plus, it's Unix-centric. I'd like to turn it into a Visual Studio port so I
could compile without needing cygwin, gcc, etc., but that's another story).
I'm not going to complain. That's been done to death here. Instead, I have a
different question: Where can I learn about SSL?
As in, could someone reccommend a good book, or online tutorial, or
something, somewhere, that explains it all from pretty much first
principles, and leaves you knowing enough at the end to be able to make
sensible use of OpenSSL and similar? I don't want a "For Dummies" type book
- as I said, I'm reasonably competent - but I would really like access to a
helpful tutorial. I want to learn. So what's the best thing to go for?
[Moderator's Note: Eric Rescorla (aka "Ekr") wrote an entire book on
the topic which is pretty much definitive on the general topic of
SSL/TLS. As for OpenSSL itself, as a package that changes from release
to release, only its own documentation is 100% definitive. --Perry]

@_date: 2003-07-16 16:58:56
@_author: Jill.Ramonsky@Aculab.com 
@_subject: Looking for an N -out-of-M split algorithm 
I remember reading (many years ago) a description on some web page somewhere
of an algorithm by which an arbitrary file F could be split into M pieces,
such that:
(1) given any N pieces, F can be reconstructed precisely, and
(2) given fewer than N pieces, it is impossible to determine even a single
bit of information about F.
Unfortunately, that was many years ago, and -- search as I might -- I
haven't been able to find it on web now.
Does anyone have any idea where I might learn about this algorithm - or
indeed any algorithm which does the job.
[Moderator's note: look for "Shamir Sharing" -- the trick is just
turning the secret into a polynomial of degree N so that with enough
points you determine the polynomial uniquely and with too few you
can't determine it. I'm pretty sure that Schneier and all of the other
standard references explain this trick. --Perry]

@_date: 2003-06-02 10:04:28
@_author: Jill.Ramonsky@Aculab.com 
@_subject: "PGP Encryption Proves Powerful" 
Actually, I _am_ the proud posessor of a Psion Series 5mx, and I have had
PGP for EPOC installed on it for a few years now. It's not the original,
obviously, but it claims to be a port to the EPOC operating system of PGP
2.6.3ia. The About page says "International version - not for use in the
USA. Does not use RSAREF". It is copyright PanSoftware, and there are two
URLs -  and I don't have source code - which is a bit of a security problem, obviously -
but it produces .pgp files which are compatible with other versions of PGP
2.6.3i, and if you examine the packets of said .pgp files then you find
nothing unexpected.
In summary, I'm reasonably convinced that it really is PGP ... although
personally if my information were REALLY sensitive then I'd probably do my
encryption on some other platform (where I had the source code).
-----Original Message-----
Sent: Friday, May 30, 2003 2:30 PM
The article hedges on whether or not PGP was used on the Psion mentioned.
The Psion might have been using one of the other programs listed at

@_date: 2003-06-03 13:58:14
@_author: Jill.Ramonsky@Aculab.com 
@_subject: New vs Old (was Snake Oil) 
I confess to being confused - though admittedly part of the blame for this
is my own ignorance.
I remember a time when PGP was a command line application. The only
algorithms it used were IDEA (symmetric), RSA (assymetric) and MD5 (hash). I
came to trust these algorithms.
Now these once-'standard' algorithms are no longer encouraged. The new
versions of PGP seem to prefer CAST instead of IDEA, DH/DSS instead of RSA,
and SHA-1 instead of MD5.
So, could someone please tell me:
(1) What is the justification for using these "new" algorithms instead of
the old ones? (A cynic might suggest that, since the "powers that be"
couldn't break the old algorithms, they encouraged the use of new ones that
they could. This probably isn't true, but I'm sure you can understand why
someone might think that).
(2) What actually _IS_ DH/DSS? (I don't mean what do the initials it stand
for, I mean what actually is the algorithm?). I ask because I can understand
RSA, and implement it myself relatively straightforwardly, but I have not
been able to find an explanation, simple or otherwise, of what the DH/DSS
algorithm actually is, or of why it's hard to break.
(3) Ditto CAST and SHA-1.
-----Original Message-----
Sent: Monday, June 02, 2003 5:25 PM
Erik is right: there must be very strong motivation to consider using a cryptographic mechanism/protocol which is not `standard` (de-facto standards are Ok).

@_date: 2003-06-09 11:51:01
@_author: Jill.Ramonsky@Aculab.com 
@_subject: Keyservers and Spam 
It seems to me that the possibilty that spammers might harvest PGP
keyservers for email addresses is a serious disincentive to using
keyservers. Does anyone have any thoughts on this?

@_date: 2003-06-09 16:57:07
@_author: Jill.Ramonsky@Aculab.com 
@_subject: Keyservers and Spam 
Ah, but surely there's a problem with this idea? If you communicate with me
in the clear, you will know my email address to be
"Jill.Ramonsky at Aculab.com". If you hit the reply button following a
communication with me, your message will reach me. BUT - if you then decide
that you want to communicate with me securely, your first action would
presumably be to look up "Jill.Ramonsky at Aculab.com" on a keyserver. It will
not be found, because it won't be there, so you will assume that I'm not
PGP-savvy, and not bother. (Or at least, I'm guessing some people might).
Unless (and I'm hoping someone will confirm or deny this) there is some way
to configure things so that if one looks up "Jill.Ramonsky at Aculab.com" on a
keyserver then what would be returned would be my SECURE email address, not
my insecure one. Is this possible?
My first thought is to generate a new (secure) email address which includes
the old (insecure) address as a substring (for example
"PGP.Jill.Ramonsky at Aculab.com"). Will this work? I don't know enough about
keyservers to know the answer to that one.
Oh yes - one last question... You said "but as a private individual the
volume is not going to be crippling". Roughly how much volume are we talking
about here?
-----Original Message-----
Sent: Monday, June 09, 2003 4:14 PM
Solution: Have two addresses, a "secure" and "non-secure" one. Discard
all mail to the secure one that's not encrypted. OK, so you have to
process and discard it, but as a private individual the volume is not
going to be crippling.

@_date: 2003-06-10 16:54:09
@_author: Jill.Ramonsky@Aculab.com 
@_subject: Keyservers and Spam 
The answer is simple. I cannot publish a PGP under a false name, because if
I did, who would sign it to attest that the genuinely did belong to the
person to whom it claimed to belong? Would you?
If _anyone_ signed a key with a bogus name on it, and got found out, then
_their_ credibility as a key-signer would go down the plug-hole, which in
turn would mean that PGP users would decrease their trust in the key of the
signer, which in turn would mean that any OTHER key signed by that signer
would immediately become less trusted.
I, personally, would never sign a bogus key. If I ever did find someone who
was prepared to sign a bogus key (including one which was created by me),
then MY trust in THEM would immediately drop to zero. And what good to me is
a key which is signed by someone whose authentication credentials I don't
If we allow this, then the entire web-of-trust disintegrates.
There is a parallel thread in this list on paypal-spoofing. It demonstrates
what can happen if someone signs a bogus key. It demonstrates why no-one
with any REAL credibility would ever do such a thing. When you place your
signature on someone else's PGP-key, you are attesting that you, personally,
vouch for the authenticity of the key's claim of ownership. Now, I don't
have any problem with centralised-CAs signing as many bogus keys as they
like. It makes no difference to me because I don't trust them, and I don't
trust their certificates. But the web-of-trust is a different animal. The
web of trust is based on the idea that YOU decide whom you trust, and you
DON'T trust people who sign bogus keys.
So ... if you believe (as I do) that a PGP key is untrustworthy unless there
is a chain of signers reaching from you to it, matching the settings in your
PGP configuration file, then posting a bogus key becomes completely
On the other hand ... if the key is NOT bogus, then it has my real name on
it, and the spam problem remains.
I have seen very little discussion of this point, anywhere. The few replies
I have had to my original question suggest that there simply _is_ no
solution, except live with it. Either don't publish your key (which means
that no-one can find your key even if they have a priori knowledge of your
email address), or do (and accept the price in spam). This seems to be the
reality of how it is. This being the case, I am now starting to wonder if it
might be time to invent a new PGP keyserver protocol which addresses this
issue. Keyservers could then start to implement the new protocol, and, in
time, the problem would be solved. Does this make sense? Is this reasonable?

@_date: 2003-06-11 09:19:55
@_author: Jill.Ramonsky@Aculab.com 
@_subject: Keyservers and Spam 
The possibility of a MITM attack.
I observe that "confirmation" of the fingerprint by phone is worthless
unless the recipient is able to recognise my voice. In the case of a
stranger, that won't be the case.

@_date: 2003-06-11 10:06:33
@_author: Jill.Ramonsky@Aculab.com 
@_subject: Keyservers and Spam 
I've just realised the error in my own logic there. Of course a MITM could
send a fake key, but the digital signatures on it still can't be faked. In
that sense, I am simply acting as a keyserver for my own key.
I withdraw the below email, and apologise for posting it without thinking it
through a bit more thoroughly.
-----Original Message-----
Sent: Wednesday, June 11, 2003 9:20 AM
The possibility of a MITM attack.

@_date: 2003-06-16 10:47:04
@_author: Jill.Ramonsky@Aculab.com 
@_subject: Session Fixation Vulnerability in Web Based Apps 
I've come up with a (very simple) defence against session hijacking and so
on. It's probably flawed (I admit I'm not an expert on these things), so if
someone could please tell me why it won't work, I'd be very grateful.
When the user logs in, the server stores the client's IP address in a
session variable (so it's stored at the server end - the client just gets a
session id). Authentication of subesequent pages is assumed only if the
client's IP address matches the IP address stored in the session variable
corresponding to the client's session.
Is this secure? If not, why not?
[Moderator's Note: you might want to read the original paper again. It

@_date: 2003-06-16 14:39:12
@_author: Jill.Ramonsky@Aculab.com 
@_subject: Sessions 
This has got nothing whatsoever to do with session fixation. It _has_
however, got something to do with security. In particular, with
[Moderator's note: Actually, it seems to have everything to do with
session fixation. --Perry]
I may be ignorant about a few things but I'm learning fast, and I still
think the following question is worth my asking (and someone answering)
because I'm actually thinking of using this idea on a real web site. At the
very least, it seems to me that it ought to be more secure than NOT tracking
the IP.
I didn't receive the rest of this moderator's note so I don't know what it
was going to say. My apologies for not having changed the subject line from
"RE: Session Fixation Vulnerability in Web Based Apps", and for not making
it clear that this is a different and unrelated thread.

@_date: 2003-06-16 15:36:54
@_author: Jill.Ramonsky@Aculab.com 
@_subject: Sessions 
I think I understand this, but I'm not sure if it matters. It seems to me
that a false negative (failed login) is not particularly serious, and that
the emphasis should be on preventing false positives (hackers). So ... if
you find that you can't log in from work (or anywhere you may have
distributed proxies), tough. Just try again when you get home, where there
are no distributed proxies in the way. If you believe that security is more
important than convenience, is this not reasonable?
The point is that, since IP spoofing is difficult (at least, considerably
MORE difficult than stealing a session key), you could be fairly sure you
were cutting out an awful lot of hacker attacks.
I freely admit that I don't understand all the issues here, but this does
seem pretty straightforward. What am I missing?

@_date: 2003-05-14 11:49:40
@_author: Jill.Ramonsky@Aculab.com 
@_subject: economics of spam (Re: A Trial Balloon to Ban Email?) 
I don't believe it will dramatically increase the costs of sending bulk
e-mail for non-spammers. A legitimate commercial organisation sending
adverts to customers who have CHOSEN to join an opt-in mailing list is an
entirely different situation. In practice, the organisation would simply
bulk-mail their mailout without any hashcash stamps. But they WON'T be
rejected as spam by the recipients, because the recipients, having
deliberately opted in, will have told their email clients to accept mail
from that particular address without stamps.
-----Original Message-----
Sent: Tuesday, May 13, 2003 2:18 AM
  - This is going to dramatically increase the costs of sending bulk e-mail for non-spammers: for example, I get airline specials a few times a week; they must send millions of these.
  - Tim

@_date: 2003-05-19 13:29:05
@_author: Jill.Ramonsky@Aculab.com 
@_subject: Primality Algorithm 
Hi all, I have a couple of questions about the much-publicised Agrawal,
Kayal and Sexena algorithm for determining the primality of an integer in
polynomial time.
(1). Does anyone know where I can find an implementation for the algorithm
in C or C++ ?
(2). A slightly more bizarre question in which I confess my own ignorance
... It was my intention to implement this MYSELF in C++ (a task which didn't
sound too difficult), until I realised that I didn't entirely understand the
algorithm. Ahem. My biggest problem is with step 12, which reads:
12.     if ((x-a)^n != (x^n - a)(mod x^r - 1,n)) output COMPOSITE;
(I substituted the ^ symbol for superscripts, and I also substituted "!="
for the symbol "NOT IDENTICAL TO" (Unicode character \u2262), due to the
limitations of ASCII).
Okay - can someone tell me what (mod x^r - 1,n) means?
I mean, I KNOW what (mod n) means. I know that (x)(mod n) means the same
thing as the C expression (x % n) - at least for positive numbers. BUT -
step 12 of the AKS algorithm has got _two_ expressions after the word mod,
separated by a comma, and I have no idea what that means, or how to
translate it into C or C++. Could somebody please explain?
Thanks, and apologies for appearing ignorant.

@_date: 2003-10-01 16:48:33
@_author: Jill Ramonsky 
@_subject: Monoculture 
I could do an implementation of SSL. Speaking as a programmer with an interest in crypto, I'm fairly sure I could produce a cleanly implemented and simple-to-use version.
I confess I didn't realise there was a need. You see, it's not that it "doesn't seem to excite" [me] - it's just that, well, OpenSSL already exists, and creating another tool (or library or whatever) to do exactly the same thing seems a bit of a waste of time, like re-inventing the wheel. If you can provide some reasonably reassurance that it's not a waste of time, I'll make a start.
But I would like to ask you to clarify something about SSL which has been bugging me. Allow me to present a scenario. Suppose:
(1) Alice runs a web server.
(2) Bob has a web client.
(3) Alice and Bob know each other personally, and see each other every day.
(4) Eve is the bad guy. She runs a Certificate Authority, which is trusted by Bob's browser, but not by Bob.
Is it possible for Bob to instruct his browser to (a) refuse to trust anything signed by Eve, and (b) to trust Alice's certificate (which she handed to him personally)? (And if so, how?)
I am very much hoping that you can answer both (a) and (b) with a yes, in which case I will /definitely/ get on with recoding SSL.
 > -----Original Message-----
 > From: Perry E. Metzger [mailto:perry at piermont.com]
 > Sent: Wednesday, October 01, 2003 3:36 PM
 > To: kent at songbird.com
 > Cc: cryptography at metzdowd.com
 > Subject: Re: Monoculture
 >
 > We could use more implementations of ssl and of ssh, no
 > question.
 >
 > However, suggesting to people that they produce more cleanly
 > implemented and simpler to use versions of existing algorithms and
 > protocols doesn't seem to excite people, although it would be of
 > tremendous utility.
 >
 > Perry
 >

@_date: 2003-10-02 14:21:29
@_author: Jill Ramonsky 
@_subject: Monoculture 
Thanks everyone for the SSL encouragement. I'm going to have a quick re-read of Eric's book over the weekend and then start thinking about what sort of "easy to use" implementation I could do. I was thinking of doing a C++ implentation with classes and templates and stuff. (By contrast OpenSSL is a C implementation). Anyone got any thoughts on that? Also - anyone thinking of using something like this - could you post (in another thread maybe) suggestions as to what kind of "simple" interface you actually want? As in, what you want it to do? All suggestions gratefully considered, but in the light of comments in this list, I will /not/ turn it into bloatware just to satisfy all demands. (OpenSSL can do that). Finally - I'll need some help setting up a sourceforge thing as I've never set up an open source project before and don't really know how to go about that. Some advice on licensing wouldn't go amiss either. (GPL? ... LGPL? ... something else?)
Re Don's comments below:
This seems to me to a /serious/ flaw in the design of MSIE. What if Alice doesn't /have/ a CA because she can't afford their fees? (or she doesn't trust them, or for any other reason you might care to think of). In fact, if I've understood this correctly, if Alice uses MSIE, she can't even tell her browser to trust her own website, despite being in possession of not only her own public key, but her own secret key as well! What is it with MSIE that it would prefer to trust someone other than Alice about the authenticity of Alice's site !!!???
Okay guys - _this is a serious question_. Alice has a web site. Alice has a web browser which unfortunately happens to be MSIE. Alice wishes to view Alice's web site using Alice's browser (which is not on the same machine as the server). Alice does not wish to trust ANYONE else, but she does trust herself absolutely. How does she get the browser to display the padlock?
I wouldn't be at all surprised if the answer turns out to be "It can't be done". (That may not be a problem if other browsers don't have this design flaw, of course, since Alice can tell all of her friends "don't use Microsoft").
 > -----Original Message-----
 > From: Don Davis [mailto:don at mit.edu]
 > Sent: Thursday, October 02, 2003 1:26 PM
 > To: Jill Ramonsky
 > Cc: cryptography at metzdowd.com
 > Subject: RE: Monoculture
 >
 >
 > > Is it possible for Bob to instruct his browser to
 > > (b) to trust Alice's certificate  (which she handed
 > >     to him personally)? (And if so, how?)
 >
 > how it's done depends on the browser:
 >
 > in MSIE 5:   Edit > Preferences.., > Web Browser >
 >              Security > Certificate Authorities
 >
 >             (there seems to be no way to tell MSIE 5 to
 >              trust Alice's server cert for SSL connections,
 >              except to tell MSIE 5 to trust Alice's CA.)
 >

@_date: 2003-10-03 17:55:25
@_author: Jill Ramonsky 
@_subject: Simple SSL/TLS - Some Questions 
Having been greatly encouraged by people on this list to go ahead with a new SSL implementation, it looks like I am going to go for it, but I'd kinda like to not make any enemies in the process so I'll try to keep this list up to date with progress and decisions and stuff ... and I will ask a lot of questions.
It's worth summing up the design goals here, so nobody gets confused. Trouble is, I haven't figured out what they should all be. The main point of confusion/contention right now seem to be (1) should it be in C or C++?, (2) should it support SSL or TLS or both?
There are plenty of things I am really sure about, however. The two main design goals people seem to want are (1) lightweight, and (2) easy to use. (Plus the "obvious" goals of (3) it actually /will/ implement SSL/TLS and not something else, and (4) it shouldn't be full of bugs. I figure those go without saying).
Regarding the choice of language, I think I would want this library (or toolkit, or whatever) to be somehow different from OpenSSL - otherwise what's the point? I mean ... this may be a dumb question, but ... if people want C, can they not use the existing OpenSSL? Or is it simply that OpenSSL is too complicated to use, so a "simpler than OpenSSL" C version is required. What I mean is, I don't want to duplicate effort. That seems dumb.
C++ has many advantages, which include SECURITY advantages. Proper use of constructors, destructors, exceptions, std::strings, std::vectors, smart pointers, and so on can eliminate memory leaks, dangling pointers, buffer overruns, and just about everything else than can bring a good toolkit down. I already have a very nice, working, C++ secure big-integer library [here's one I wrote earlier]. By "secure" in this context, I mean that all big-integers get zeroed on deletion, so no crypto keys are ever left lying around in memory. Sure, these sort of things are all also possible in C, but it's so much more work to be non-existant then? I'm pretty sure it's possible to compile C++ to C (instead of to assembler) so a C++ to C wrapper can't be that difficult. (By contrast, a C to C++ wrapper would be easier, but the toolkit would have more bugs!) My inclination is still to go with C++, and figure out a way of turning it into C later if necessary ... but if majority opinion says otherwise I'll reconsider.
Now - SSL or TLS - this confuses me. From what I've read in Eric's book, SSL version 3.0 or below is called SSL, wheras SSL version 3.1 or above is called TLS. Have I misunderstood that? In any case, I note the bit in Eric's book (p73 in my edition) where it says "In general, it is expected that an implementation speaks all lesser versions" ... even if lesser versions become known to be insecure. I'm not sure I like this - and in any case, it goes against the design goal of "lightweight". If you want to implement only TLS (for example, in a closed private network where all parties are known to be using the same version of the same protocol), why should you have to lug around SSL as well? I suppose I SSL-only, or TLS-only, or SSL+TLS" ... but what I'm not sure about is, is the "TLS-only" option forbidden by the standard?
And now some questions about SSL/TLS itself....
THE HANDSHAKE PHASE
The assumption in Eric's book, roughly translated into Alice and Bob scenarios, goes something like this: Bob (client) says hello to Alice (server). Alice sends Bob her certificate (which is basically a copy of her public key, signed by a third party, Carol). Bob validates Alice's key (which is only possible if he already has a copy of Carol's public key), and then uses Bob's (now validated) public key to start sending encrypted messages. (There's more, but that's the important part).
Now, this scenario is all very well for banks and big businesses, but I guess I want to do "SSL for the rest of us". You see, the above scenario contains a couple of assumptions. It assumes (1) that Bob does not already have Alice's key - otherwise why would she need to send it? It further assumes (2) that Bob /does/ have Carol's key, /and that he trusts Carol/. Okay, fine, but what if these assumptions aren't met? I mean, let's assume that Bob already has Alice's key. (Let's say for sake of argument that she gave it to him personally). Now this means we can save on bandwidth by not having to transmit Alice's cert ... but already there are two problems: (1) would it be a violation of the protocol to omit the cert?, and (2) without the cert, we would need some /other/ kind of message with which to replace it - one which says, simply, "Hi, this is Alice, use the copy of my key which you already have". So already I have questions - how free am I to allow variations in the THE CIPHER SUITE
The list on page 74 of Eric's book looks a little limiting to me - not merely because the list is too short, but also because it's very design is wrong (in lumping all of the encryption ciphers together into a single 16-bit value with no internal structure). What if Alice would like to use, say, some elliptic curve function as her asymmetric algorithm?, or CAST-5 as her symmetric algorithm?, or SHA-256 as her hash function? We could maybe fix this up by adding more entries to the list, but it's a global list, so who has the authority to add entries to it? I believe that Alice and Bob should be able to communicate with whatever ciphers they wish, and should not need the permission of any global authority to do this. Are there any values in the range (0x0000 to 0xFFFF) which are reserved for private use between consenting parties?
It is even possible for Alice and Bob to use a proprietry cipher. For example, what if the chosen encryption algorithm is "one-time-pad", using a block of bits communicated out of band (e.g. via so-called quantum cryptography, or that hard-drive alternative discussed in another thread). How can this be communicated in the CipherSuite field? I would like to believe there is a way of doing this ... but if not, I'd like to know that too, so I can find a neat way of extending the protocol to /make/ it possible.
THE COMPRESSION METHOD
Exactly the same question. Alice and Bob are consenting adults, and they want to use the BZIP compression algorithm. I'm not going to tell them they can't. (I suspect though that the answer to the previous query will also answer this one).
THE CERTIFICATE
Can Alice and Bob each create their own certificates? With (for example) Alice's key signed by Bob, and Bob's key signed by Alice, as is often done in GPG? Who counts as the "Issuer" in this case? How can Alice (or a piece of software working on Alice's behalf) construct an X.500 Distinguished Name to describe herself /and be absolutely sure that it is globally unique/? On page 12 of Eric's book it explains that a DN is a sequence of RDNs, each of which only needs to be locally unique, so the whole sequence becomes globally unique. That's all very well, but it's still a global namespace overall, so who controls it? Let me be clear that Alice and Bob have no intention to give even a single penny to Verisign or any other entity, just so that they can talk to each other in private.
Well, that's enough questions for now. Hopefully someone can answer some of them. Encouragement is great, and I appreciate it, but practical answers to the above would be even better.

@_date: 2003-10-06 12:14:55
@_author: Jill Ramonsky 
@_subject: Simple SSL/TLS - Some Questions 
Hi. This is just a quick note to say that over the weekend I've done a lot of thinking about coding, and even some /actual/ coding, that I've re-read parts of Eric's book in somewhat more detail than I read it last time, and I've read all the various posts on the subject of "simple SSL". And at the end of all this study, I have finally decided exactly what I want/propose to do . I guess the point of this email is to tell you the plan, and to explain the reasons for my choices. There are also four more questions at the end,  so if you can't be bothered to read this long email, please do skip to the end and consider the questions.
First, the primary design goal is "simple to use". This is not the same thing as "doesn't do much". As an implementer, I can make the toolkit as powerful as I want (and it will be open source, after a time, so others will be able to add to it and make it more powerful still). Adding power only makes the implementation harder to /write/. However, if well designed, it should not make it harder to /use/. Harder to write is my problem ... but I like a challenge!
Second design goal is "lightweight". This means that it must be possible for application programmers to use the toolkit to build minimalist applications. This means that part of the toolkit must be a statically-linked library consisting of many very small object modules, making it possible to link in only what you need, and no more. That said, if the toolkit is powerful, one could also use it to build "heavyweight" applications also. I don't see that as a problem, or even as a violation of the design goal. In fact, it actually seems to me to be something of an advantage that you could do both.
First design choice: SSL or TLS or both? I think this is covered by the paragraph above. If the toolkit lets you create TLS-only products, a lot of people will be happy (including me). If the toolkit /also/ lets you build SSL+TLS applications then a lot of /other/ people will be happy. Seems to me that so long as I am clear about the distinction between "what's in the toolkit" and "what's in a application /built/ with the toolkit" then a lot of design choice problems just disappear. (Or at least, become the application designer's problem).
Second design choice: C or C++ or something else? There was a lot of support on this list for both C and C++, and various "something else"s were also suggested, but with less votes. Many people suggested /both/ C and C++. Some said "write in C and then do a C++ wrapper". Others said "write in C++ and then do a C wrapper". The "embedded market" got several mentions, and for these guys it's clearly desirable to have a C version. Other factors to consider are my own expertise (I've never written anything in Ruby or Python before, so this would not be a good project to use as first attempt) and my own enjoyment. This is selfish, yes, but someone said this would end up being a year-long project, so I'd like it to end up firing my enthusiasm and imagination. More gets done that way, and faster. So here's the decision - the prototype will be in C++ ... /but/ ... I do know enough about how C++ compilers work behind the scenes, and I'm confident that I will be able to later port it to C, even /with/ features such as abstract virtual base classes, templates, exception handling, RTTI and so on. So what we'll end up with is both a C++ version and a C version, with the C++ version coming first. [It may even be possible to shortcut the port, for example by finding a C++ to C compiler, or by releasing an OS-specific binary with C wrappers]. And it seems to me that another big plus in doing a C++ version is that one does not already exist, and perhaps one should. Another big pro in favor of C++ is the existence of the crypto++ project (thanks for pointing that out to me, guys). This provides a lot of crypto primatives, which a TLS toolkit could put to good use.
Some people said that it was easier to code in C than in C++. I don't think that's true. I've been coding in C since it was invented. Likewise, I've been coding in C++ since /that/ was invented. In my opinion, bugs are easier to find and fix in C++ than they are in C, with most of the serious ones being detectable at compile time in C++, but only at run time in C. With that in mind, I believe I could do a safer implementation in C++ than I could in C. I also consider the fact that the reason C++ was invented was to help manage complexity, and let's face it, this project does involve complexity. Keeping it all object-oriented gives me nice little isolated, easily debuggable objects.
It was pointed out that C++ (as opposed to Java, etc.) does allow pointers, and hence does allow memory errors such as buffer overruns. That's true, but I tend to encapsulate my raw C++ pointers inside smart pointer objects which don't allow such errors. (These are already part of my existing codebase. They'll go open-source along with the rest of it). I believe I can minimise this danger.
Eric raised some points which I should address. First, he asked me "You have read the RFC, right?". Well I guess I should be honest here and say no, I hadn't done that yet. Maybe that's where I went wrong, and would have asked fewer dumb questions if I had. But rest assured everyone, I will digest it thoroughly before trying to implement it! He also asked "I'm trying to figure out why you care about this. The defined algorithms are good enough for almost all purposes.", and "Don't you want to be able to communicate with standard TLS implementations? If so, the kind of stuff you seem to want to do will in often break that.". To answer the first question, I have to state my absolute and sincere belief that if Alice, Bob, Carol, Dave, etc.., wish to communicate with each other privately, then it their business AND NO-ONE ELSE'S what choice of algorithm(s) they use, etc.. This leads inevitably to the conclusion that if a standards body forbids this, then the standards body will have to be circumvented. This of course leads to the second question, ("Don't you want to be able to communicate with standard TLS implementations?"). The answer is obvious. /Of course/ one should be able to communicate with standard TLS implementations, otherwise the toolkit would be worthless. And of course, communicating with other implementations /does /mean strictly obeying all the standards. These two positions are not, however, mutally exclusive, because what I am putting together is a /toolkit/, not an /application/. Application programmers will be able to use the toolkit to build standards-compliant applications if they want that, or anarchistic applications if they want that. (Of course, anarchistic applications will not interoperate with the rest of the world, but that's the price you pay for choosing that option, and it's what I mean by the phrase "private use by mutually consenting parties").
And now ... SOME MORE QUESTIONS. (You're gonna love this).
(1) THE LICENCE
I confess ignorance in matters concerning licensing. The basic rules which I want, and which I believe are appropriate are:
(i) Anyone can use it, royalty free. Even commercial applications.
(ii) Anyone can get the source code, and should be able to compile it to executable from this.
(iii) Copyright notices must be distributed along with the toolkit.
(iv) Anyone can modify the code (this is important for fixing bugs and adding new features) and redistribute the modified version. (Not sure what happens to the copyright notices if this happens though).
(2) THE NAME
Everything needs a name. I've come up with a few possibilities. I'd bet good money that people here could come up with a few more. Some suggestions are:
TLS++ (I like this one)
SimpleTLS (obvious, but not too bad)
EasyTLS (actually I'm not too keen on this - it sounds /too/ simple to be credible)
GnuTLS (obviously only suitable if it ends up with a Gnu license)
Pretty Good TLS (I stole the idea from PGP obviously, but if this is to be "SSL for the masses" then it's not entirely inappropriate)
Anyway, all suggestions welcome.
(3) MULTIPLY SIGNED CERTIFICATES
A technical question now. (I did look at RFC2246 before asking this, but didn't find the answer there). In GPG / PGP, one can have multiply signed certificates. It's not called a "certificate" in GPG, it's called a signed key, but the priniciple is the same. Alice can get her key signed by both Carol and Dave, which has the intended meaning that both Carol and Dave vouch for the authenticity of Alice's key. Thus, if Bob wishes to send to Alice, he can do so provided he trusts /either/ Carol Can you do this with X.509 certificates? I know it would be hideously unusual (not to mention expensive) to get a single certificate signed by both Verisign and Thwarte, but can it be done? Is it possible? Is it (4) MULTI-THREADING
Procedural languages like C tend to go for state-machine-like architectures. Object oriented languages like Java tend to go for multithreading. Both are conceptually solutions to the same problem, but arise from different paradigms. C++, being somewhere in the middle, hasn't really made up its mind which way to go. Multithreading is not built into C++ any more than it is built into C, but the OS usually provides multithreading anyway, so in object-oriented C++ you'd tend to go for multithreading (which, I have to say, is /considerably/ easier to understand and debug than the state-machine paradigm). My question is, how much of a problem is this for the embedded market?
I happen to know that it's pretty easy to put *cooperative* multithreading into an embedded application, providing you're willing to write a bit of assembler. (I've done it myself). But *pre-emptive* multithreading is much harder to implement (and more likely to incur synchronisation bugs). I can certainly write multithreaded routines which don't rely on pre-empting, so that should make it easy, but obviously I'm not going to write assembler thread-switching code for every processor under the sun.
Thoughts and opinions would be welcome.

@_date: 2003-10-07 10:11:16
@_author: Jill Ramonsky 
@_subject: Simple SSL/TLS - Some Questions 
Comments inlined below
 > -----Original Message-----
 > From: Ian Grigg [mailto:iang at systemics.com]
 > Sent: Monday, October 06, 2003 10:35 PM
 > To: Jill Ramonsky
 > Cc: cryptography at metzdowd.com; hadmut at danisch.de; ekr at rtfm.com
 > Subject: Re: Simple SSL/TLS - Some Questions
 >
 > The only question I wasn't quite sure of
 > was whether, if I take your code, and modify it,
 > can I distribute a binary only version, and keep
 > the source changes proprietary?
You can't distribute a binary only version of ANY crypto product, surely? No crypto product can EVER be trustworthy unless you can see the source code and verify that it has no back doors, and then compile it. Unless you give your users the power to inspect the source code, and and run the resulting executable) then you could have put all sorts of back doors into it. You could have added password theft, key escrow, who knows what?
Don't get me wrong. I agree with you that crypto has enough barriers already, and I would like to produce something that is as freely distributable as possible. "For the masses" crypto is, I guess, an unwritten design goal. But allowing people to hide the crypto source from crypto users would allow the bad guys (you can define your own bad guys) to produce Trojan Horse crypto. Closed source crypto is to all intents worthless. (In my opinion). Please feel free to argue that I'm  > My own philosophy has always been that crypto has
 > enough barriers on it already, so it should not
 > add any more personality quirks than necessary,
 > hence preference for BSD two clause.  Mind you,
 > such a statement is a personality quirk, so you
 > be your own judge.
Eek. Was my paragraph above a personality quirk? I thought it was a sound cryptographic principle.
 > Names are really hard.  I'd defer that one until
 > it pops out.
I agree. But ruling them out is easy. We've already ruled out EasyTLS, GnuTLS and Pretty Good TLS. That's narrowing things down. Top of the list currently is TLS++, but that kindof implies it won't work with C. (This will actually be true for the prototype, but not, I hope, true indefinitely). I think I'll stick with that for now until a better one comes up.
 > Q:  Does your employer  have any say or comment
 > on this project?  Might be wise to clear up the
 > posture, and either get it in writing, or make
 > the repository public from the git-go.  Many an
 > open source project has foundered when the boss
 > discovered that it works...
It has absolutely nothing whatsoever to do with my employer. All my code will be written at home in my spare time, and uploaded to CVS or whatever also from home. It is true that I happen to be sending this email from work, but even that's in my own time. I don't see how they have any say. To be /really/ safe,  I'd be happy to always post to this list only from home, but right now I don't think it's a problem.
How do I go about changing the email address with which I'm a member of this list?

@_date: 2003-10-07 15:21:38
@_author: Jill Ramonsky 
@_subject: Open Source (was Simple SSL/TLS - Some Questions) 
Ian asked about the possibility of distributing binaries built with a crypto toolkit. I took the initial view that closed source and trustable crypto are mutually incompatible, but on reflection, I can think of circumstances where that might not be true.
Example. You're a company. You build hardware devices which need to talk to each other securely. (Say, ATMs for example). Obviously it wouldn't make sense for that company to have to supply its ATM-using-customers with the source code of the ATMs. So where should one draw the line?
This is an important question (for me, at least) since it affects the licensing of the yet-to-be-written TLS++ project.
After a lot of thought, I think it all boils down to the simple question ... "trusted by whom?". I might trust an application for any variety of reasons. This does not mean that you have to trust it.
It seems to me, therefore, that if you're putting together a crypto app which is going to run in an embedded software environment, in a chip, on some product, you need to consider WHO is going to be relying on the crypto services of that product. If it's just you (or your company) then only you (or your company) need to trust it, so only you (or your company) need to see the source code. On the other hand, if the public are going to be using it, then how will /they/ be assured that there are no Trojans in the chips? Should they just take your word for it? Even if you gave them the source code, the public would (in general) have no way of verifying that it actually WAS the source code. They couldn't (in general) compile the code down to the processor-specific machine code used on that device and burn in the new binary. Basically, this means you can never trust a hardware device you didn't build yourself.
But ... if nobody apart from you (or your company) is going to be relying on the crypto, then surely you should be allowed to use TLS++?
With software though, this would be an unusual circumstance. Claims such as "Download this app and you will be secure" should definitely need to be proven, and if the app is built with TLS++ that would mean distributing the source code. But would that mean distributing the source code for the whole product, or just the crypto library parts? I would argue that it would have to be the whole product, otherwise how can a user know whether what you /claim/ is the source code actually I'm lost on this one. I don't have any answers, and I'm hoping someone else does. I don't want to restrict the distribution of TLS++, but I also don't want crippled versions of it being used to fool the public. If anyone could help me to outline a reasonable possibility....?
Maybe the solution should be this: You can distribute the binary without any source code whatsoever, and use this toolkit, unrestricted, in whatever manner you choose, provided that EITHER you distribute the source code for the whole product in a form which allows the user to reconstruct a working executable from the source code, OR you include a message which says something like "Warning - this product is closed source. If you rely on its crypto features, you do so at your own risk".
(Of course, it's also "at your own risk" if it's open source. The difference is, you have a better idea of the risk).

@_date: 2003-10-08 14:22:51
@_author: Jill Ramonsky 
@_subject: Open Source (was Simple SSL/TLS - Some Questions) 
Too late. I've already started. Besides which, posts on this group suggest that there is a demand for such a toolkit.
Also, I have a lot of interest in SSL/TLS, and no interest whatsoever in IPsec. I believe I am a competent programmer, but the fact is, if you want me to write something in my own spare time, something for which I'm not being paid, then I'm afraid I do require the subject to interest and inspire me.
But I am at least putting my money where my mouth is. I'm doing something, not merely talking about it. It may be months before I have anything to show off, but that day will come soon enough. And even within the confines of the subject of SSL/TLS I'm sure there will be people saying "don't do this, do that". Asking me to change /everything/ and start again from scratch is unrealistic.
I can only suggest that if you believe there is a need for an IPsec library, you might consider picking up a C/C++ compiler and starting to code it. Or if that's not your field of expertise, you could ask this list for volunteers. But asking someone who's /already/ volunteered for something to drop what they volunteered for and do something else instead is ... well ... a strategy which is unlikely to succeed, to put it politely. I am sorry about that, but I really want to do TLS++ (it has a name now, although the name can obviously change). And if it turns out that I'm wrong, and those who encouraged me are also wrong, and there is no big demand for "Simple-to-use SSL/TLS" after all, then I don't care - because _I_ want to use it, and that, to me, is the most important demand of all.
Of course, you could always offer to pay me more than my current employer, then I'd write anything you wanted!
Jill (Apologetically)
 > -----Original Message-----
 > From: pgut001 at cs.auckland.ac.nz [mailto:pgut001 at cs.auckland.ac.nz]
 > Sent: Wednesday, October 08, 2003 1:57 PM
 > To: arcanejill at ramonsky.com; cryptography at metzdowd.com;
 > iang at systemics.com; rsalz at datapower.com
 > Subject: RE: Open Source (was Simple SSL/TLS - Some Questions)
 >
 >
 >
 > I would add to this the observation that rather than writing
 > yet another SSL
 > library to join the eight hundred or so already out there, it
 > might be more
 > useful to create a user-friendly management interface to
 > IPsec implementations
 > to join the zero or so already out there.  The difficulty in
 > setting up any
 > IPsec tunnel is what's been motivating the creation of (often
 > insecure) non-
 > IPsec VPN software, so what'd be a lot more helpful than (no
 > offense, but) yet
 > another SSL implementation is some means of making IPsec easier to use
 > (although that may not be possible... OK, let's say "less
 > painful to use" :-).
 >
 > Peter.
 >
