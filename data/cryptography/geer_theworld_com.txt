
@_date: 2001-12-30 11:26:28
@_author: Dan Geer 
@_subject: Stegdetect 0.4 released and results from USENET search available  
It might be that child porn posted to these lists is the most
attractive vehicle as it is illegal everywhere, it will not be
downloaded at random, those who do download it will be damned
careful in where they keep it and how they use it, those who
do not want it won't touch it, and the endlessly repetitious
nature of the imagery makes it unlikely that those not looking
for the special version with the embedded hidden message would
bother taking down yet another copy.

@_date: 2002-06-25 07:15:36
@_author: Dan Geer 
@_subject: Ross's TCPA paper  
Over the last six months, I'd discovered that Carl Ellison (Intel),
Joan Feigenbaum (Yale) and I agreed on at least one thing: that the
problem statements for "privacy" and for "digital rights management"
were identical, viz., "controlled release of information is yours at
a distance in space or time" and that as such our choices for the
future of digital rights management and privacy are "both or neither"
at least insofar as technology, rather than cultural norms & law,
Last week at USENIX 2002 I tried this out on Larry Lessig as his
keynote had been a takeoff from his recent _The Future of Ideas_ book.
His response was confirming: "Of course they are the same!" and he
went on to describe that when Mark Stefik (Xerox PARC) had submitted
his patent on DRM in the early '90s it had roughly said "wrap data
such that if you try to abuse it it will self destruct."  Sometime
in the late '90s a Canadian inventor had attempted to patent a
privacy technology with the rough description "wrap data such that
if you try to abuse it it will self destruct."  The USPTO denied
the patent request on the grounds that it duplicated an application
that had already been granted.
Speaking personally, if asked "DRM & privacy, both or neither?"
then I will take "both" --  YMMV.

@_date: 2003-04-26 16:21:41
@_author: Dan Geer 
@_subject: DRM technology and policy  
Suppose I manufacture drinking glasses.  To stay in business,
I must have a profit margin.  That margin is between the market
price and my cost of reproduction of a drinking glass, which
cost is non-zero.  Thus over time I must decrease my cost of
reproducing my drinking glass if I am to stay in business.
Hence automation.
Suppose I manufacture drinking songs.  To stay in business,
I must have a profit margin.  That margin is between the market
price and my cost of reproduction of a drinking song, which
cost is zero.  Thus over time I must increase your cost of
reproducing my drinking song if I am to stay in business.
Hence DRM.
Price v Scarcity

@_date: 2003-12-07 15:16:13
@_author: Dan Geer 
@_subject: yahoo to use public key technology for anti-spam  
I'm actually experimenting with sending mail directly,
per this little hack[1], which does have separate paths
for incoming and outgoing, but does not rely on the local
[1]

@_date: 2003-12-22 21:57:33
@_author: Dan Geer 
@_subject: PKI root signing ceremony, etc.  
One approach to securing infrequent signing or working keys from a     corporate master certificate is to store the certificate in a bank     safe deposit box. The certificate generation software (say on a self     booting CD or perhaps an entire laptop) could be stored in the safe     deposit box as well. The certificate signing would take place at the     bank, either in one of the small rooms they provide or in a borrowed     conference room.
Dare I mention the CertCo/Identrus threshold crypto
in this context?  CertCo certainly nailed all the
parts of this, e.g., fragment generation in abstentia.

@_date: 2003-11-24 08:02:23
@_author: Dan Geer 
@_subject: US antispam bill is death to anonymity  
The natural consequence of zero-cost ("free") speech is to make freedom from speech (privacy) unquenchably
If you would preserve anonymity, you must raise the costs of those who will not shut up.  We technocrats
have had years to do something and we have not; the
ball is now in other courts.
