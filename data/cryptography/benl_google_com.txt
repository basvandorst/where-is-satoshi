
@_date: 2007-05-07 16:26:02
@_author: Ben Laurie 
@_subject: Selective disclosure 
I recently wrote a layman's introduction to selective disclosure which
I thought might interest members of this list:

@_date: 2008-08-08 11:50:59
@_author: Ben Laurie 
@_subject: OpenID/Debian PRNG/DNS Cache poisoning advisory 
Security Advisory (08-AUG-2008) (CVE-2008-3280)
Ben Laurie of Google's Applied Security team, while working with an
external researcher, Dr. Richard Clayton of the Computer Laboratory,
Cambridge University, found that various OpenID Providers (OPs) had
TLS Server Certificates that used weak keys, as a result of the Debian
Predictable Random Number Generator (CVE-2008-0166).
In combination with the DNS Cache Poisoning issue (CVE-2008-1447) and
the fact that almost all SSL/TLS implementations do not consult CRLs
(currently an untracked issue), this means that it is impossible to
rely on these OPs.
Attack Description
There is no central registry of OpenID systems, and so we cannot be
sure that we have identified all of the weak certificates that are
currently being served. The list of those we have found so far is:
[1] There are ways of using OpenID that are significantly more secure
    than the commonly deployed scheme, I shall describe those in a
    separate article.

@_date: 2008-08-08 15:51:34
@_author: Ben Laurie 
@_subject: [OpenID] OpenID/Debian PRNG/DNS Cache poisoning advisory 
OpenID is "singled out" because I am not talking about a potential
problem but an actual problem.
We have spotted other actual problems in other services. Details will
be forthcoming at appropriate times.

@_date: 2008-08-08 18:11:42
@_author: Ben Laurie 
@_subject: OpenID/Debian PRNG/DNS Cache poisoning advisory 
It also only fixes this single type of key compromise. Surely it is
time to stop ignoring CRLs before something more serious goes wrong?

@_date: 2008-08-08 20:41:01
@_author: Ben Laurie 
@_subject: [OpenID] OpenID/Debian PRNG/DNS Cache poisoning advisory 
On Fri, Aug 8, 2008 at 8:27 PM, Eddy Nigg (StartCom Ltd.)
I do not dispute this.
The point is I found OpenID servers with weak keys.
If you have a better forum, bring it on.
However, CAs do not have everything at their disposal to remove the
threat. Browsers,OpenID libraries and RPs must also participate.
Just as saying "buffer overflows are bad" has not magically caused all
buffer overflows to be fixed, I am confident that the only way to get
this problem fixed is to chase down all the culprits individually. I
am sure that OpenID is not the only thing with problems, as you say.

@_date: 2008-08-12 15:42:59
@_author: Ben Laurie 
@_subject: OpenID/Debian PRNG/DNS Cache poisoning advisory 
There are two parties that are vulnerable: the user logging into the
OpenID Provider (OP), and the Relying Party (RP). If the RP
communicates with the OP, then it needs to use TLS and CRLs or OCSP.
Browser plugins do not bail it out.

@_date: 2008-12-27 15:02:50
@_author: Ben Laurie 
@_subject: Security by asking the drunk whether he's drunk 
Adding support for a
I can't find discussion of Perspectives - hint?

@_date: 2008-12-29 18:02:29
@_author: Ben Laurie 
@_subject: Security by asking the drunk whether he's drunk 
Two issues occur to me. Firstly, you have to trust Google (and your
path to Google).
Secondly, and this seems to me to be a generic issue with Perspectives
and SSL - what happens when the cert rolls? If the key also changes
(which would seem to me to be good practice), then the site looks
suspect for a while.

@_date: 2008-12-30 06:57:09
@_author: Ben Laurie 
@_subject: Security by asking the drunk whether he's drunk 
Not really a serious difficulty.
Yeah, that's pretty much the answer I came up with - another option
would be to use both the old and new certs for a while.
But signing the new with the old seems easiest to implement - the
signature can go in an X509v3 extension, which means CAs can sign it
without understanding it, and only Google has to be able to verify it,
so all that needs to change is CSR generating s/w...

@_date: 2008-01-10 17:36:40
@_author: Ben Laurie 
@_subject: "I am ashamed of you. They couldn't hit an elephant at this distance" 
Yes, a standing order for ?500 per month to a charity, IIRC.

@_date: 2008-10-24 14:14:27
@_author: Ben Laurie 
@_subject: combining entropy 
Surely not. Consider N pools each of size 1 bit. Clearly you can do
better than the 1 bit your suggestion would yield.
More concretely, concatenation would seem better than XOR.

@_date: 2008-10-25 20:10:54
@_author: Ben Laurie 
@_subject: combining entropy 
I think you need to define what you mean by "as good as it gets".
Clearly XOR loses entropy that might be there, so on the measure of
"good == most entropy", it is not.

@_date: 2008-10-28 21:37:48
@_author: Ben Laurie 
@_subject: combining entropy 
On Tue, Oct 28, 2008 at 7:55 PM, Leichter, Jerry
So in the Byzantine model I can crack RSA?

@_date: 2008-09-01 21:00:55
@_author: Ben Laurie 
@_subject: [OpenID] rfc2817: https vs http 
[Adding the cryptography list, since this seems of interest]
This inspired a blog post: Recent events, and a post to the OpenID list got me thinking.
Apparently rfc2817 allows an http url tp be used for https security.
Given that Apache seems to have that implemented [1] and that the
openid url is mostly used for server to server communication, would
this be a way out of the http/https problem?
I know that none of the browsers support it, but I suppose that if the
client does not support this protocol, the server can redirect to the
https url? This seems like it could be easier to implement that XRI .
Disclaimer: I don't know much about rfc2817
[1]  at lists.mozilla.org/msg00251.html
The core issue is that HTTPS is used to establish end-to-end security,
meaning, in particular, authentication and secrecy. If the MitM can
disable the upgrade to HTTPS then he defeats this aim. The fact that
the server declines to serve an HTTP page is irrelevant: it is the
phisher that will be serving the HTTP page, and he will have no such
The traditional fix is to have the client require HTTPS, which the
MitM is powerless to interfere with. Upgrades would work fine if the
HTTPS protocol said "connect on port 80, ask for an upgrade, and if
you don't get it, fail", however as it is upgrades work at the behest
of the server. And therefore don't work.
Of course, the client "requires" HTTPS because there was a link that
had a scheme of "https". But why did was that link followed? Because
there was an earlier page with a trusted link (we hope) that was
followed. (Note that this argument applies to both users clicking
links and OpenID servers following metadata).
If that page was served over HTTP, then we are screwed, obviously
(bearing in mind DNS cache attacks and weak PRNGs).
This leads to the inescapable conclusion that we should serve
everything over HTTPS (or other secure channels).
Why don't we? Cost. It takes far more tin to serve HTTPS than HTTP.
Even really serious modern processors can only handle a few thousand
new SSL sessions per second. New plaintext sessions can be dealt with
in their tens of thousands.
Perhaps we should focus on this problem: we need cheap end-to-end
encryption. HTTPS solves this problem partially through session
caching, but it can't easily be shared across protocols, and sessions
typically last on the order of five minutes, an insanely conservative
What we need is something like HTTPS, shareable across protocols, with
caches that last at least hours, maybe days. And, for sites we have a
particular affinity with, an SSH-like pairing protocol (with less
public key crypto - i.e. more session sharing).
Having rehearsed this discussion many times, I know the next objection
will be DoS on the servers: a bad guy can require the server to spend
its life doing PK operations by pretending he has never connected
before. Fine, relegate PK operations to the slow queue. Regular users
will not be inconvenienced: they already have a session key.
Legitimate new users will have to wait a little longer for initial
load. Oh well.

@_date: 2008-09-01 21:56:52
@_author: Ben Laurie 
@_subject: [OpenID] rfc2817: https vs http 
Obviously we can fix this at the protocol level.
But if the clients drop them after five minutes, this gets you
nowhere. BTW, sessions are only that small if there are no client

@_date: 2009-08-02 20:53:44
@_author: Ben Laurie 
@_subject: The clouds are not random enough 
I'd imagine (I'm not particularly interested in licence enforcement,
so I really am imagining), that the opposite was the problem: i.e.
that the host could run you on any VM which might have wildly varying
characteristics, depending on what the real machine underneath was,
and what else you were sharing with. So, every time you see the
measurements, they'll be different.

@_date: 2009-08-05 14:58:54
@_author: Ben Laurie 
@_subject: Client Certificate UI for Chrome? 
So, I've heard many complaints over the years about how the UI for
client certificates sucks. Now's your chance to fix that problem -
we're in the process of thinking about new client cert UI for Chrome,
and welcome any input you might have. Obviously fully-baked proposals
are more likely to get attention than vague suggestions.
I imagine I may well hear "what about the UI around server
certificates?" - fair enough, feel free, and I'll see what I can do.

@_date: 2009-08-26 11:26:59
@_author: Ben Laurie 
@_subject: Client Certificate UI for Chrome? 
I certainly agree that if the problem you are trying to solve is
server authentication, then client certs don't get you very far. I
find it hard to feel very surprised by this conclusion.
If the problem you are trying to solve is client authentication then
client certs have some obvious value.
That said, I do tend to agree that mutual auth is also a good avenue
to pursue, and the UI you describe fits right in with Chrome's UI in
other areas. Perhaps I'll give it a try.

@_date: 2009-01-23 16:01:50
@_author: Ben Laurie 
@_subject: MD5 considered harmful today, SHA-1 considered harmful tomorrow 
On Tue, Jan 20, 2009 at 5:14 AM, Victor Duchovni
Who said they were "patch" releases?
I think that is not likely to happen, because that's not the way it
works. The promise we try to keep is ABI compatibility between
releases that have the same numbers. Letters signify new versions
within that series. We do not have a bugfix-only branch. There doesn't
seem to be much demand for one.

@_date: 2009-01-24 16:39:24
@_author: Ben Laurie 
@_subject: MD5 considered harmful today, SHA-1 considered harmful tomorrow 
On Sat, Jan 24, 2009 at 2:36 AM, Victor Duchovni
It is not that I am unaware of this, I was pointing out what we
actually do. But you do have a fair point and I will take it up with
the team.
However, I wonder how this is going to pan out? Since historically
pretty much every release has been prompted by a security issue, but
also includes new features and non-security bugfixes, in order to
release 0.9.8j the way you want us to, we would also have to test and
release security updates for 0.9.8 - 0.9.8i, for a total of 10
branched versions. I think this is asking rather a lot of volunteers!
Don't suggest that we should release feature/bugfix versions less
often, I think we already do that less often than we should.
Perhaps the answer is that we security patch every version that is
less than n months old, and end-of-life anything before that?
Suggestions for reasonable values of n?

@_date: 2009-01-28 13:35:26
@_author: Ben Laurie 
@_subject: What EV certs are good for 
And to use TOR, put "torify" on the front. Having run the tor server, of course.
Except on MacOS, where torify doesn't (can't? Does anyone know better) work.

@_date: 2009-01-30 13:32:11
@_author: Ben Laurie 
@_subject: Proof of Work -> atmospheric carbon 
Richard Clayton and I claim that PoW doesn't work:

@_date: 2009-11-09 16:41:32
@_author: Ben Laurie 
@_subject: Crypto dongles to secure online transactions 
Haven't read this thoroughly yet, though I think I disagree with the
idea that the display should be minimal - imagine checking out of
amazon on a 2-line display. Tedious.
Anyway, I should mention my own paper on this subject (with Abe
Singer) from NSPW 2008, "Take The Red Pill _and_ The Blue Pill":

@_date: 2009-11-16 19:09:38
@_author: Ben Laurie 
@_subject: TLS break 
This last part is not really accurate - piggybacking the evil command
onto authentication that is later presented is certainly one possible
attack, but there are others, such as the Twitter POST attack and the
SMTP attack outlined by Wietse Venema (which doesn't work because of
implementation details, but _could_ work with a different

@_date: 2009-10-17 04:01:24
@_author: Ben Laurie 
@_subject: Possibly questionable security decisions in DNS root management 
DSA can be used in DNSSEC - unfortunately it is optional, though.

@_date: 2009-10-20 18:24:11
@_author: Ben Laurie 
@_subject: Possibly questionable security decisions in DNS root management 
ts a fun story, but... RFC 4034 says RSA/SHA1 is mandatory and DSA is
optional. I wasn't involved in DNSSEC back then, and I don't know why
it got redone, but not, it seems, to make DSA mandatory. Also, the new
version is different from the old in many more ways that just the
introduction of DSA.

@_date: 2010-07-11 18:16:23
@_author: Ben Laurie 
@_subject: Spy/Counterspy 
Most location-aware services should not care whether the location is
real or false, for privacy reasons. Agree about the issue of
high-value cargo (but I guess they'll just have to use more reliable
mechanisms, like maps and their eyes), don't care about rental cars.

@_date: 2010-07-12 14:35:46
@_author: Ben Laurie 
@_subject: Intel to also add RNG 
Have they forgotten the enormous amount of suspicion last time they tried this?

@_date: 2010-07-14 10:29:53
@_author: Ben Laurie 
@_subject: Intel to also add RNG 
Several years ago I reviewed a new design for FreeBSD's PRNG. It was
vulnerable to sources that had high data rates but low entropy (they
effectively "drowned out" lower data rate sources). This was fixed,
but I wonder how common an error it is?

@_date: 2010-07-28 15:16:32
@_author: Ben Laurie 
@_subject: A mighty fortress is our PKI, Part II 
The Cryptography Mailing List
Unsubscribe by sending "unsubscribe cryptography" to majordomo at metzdowd.com

@_date: 2010-07-28 15:16:32
@_author: Ben Laurie 
@_subject: A mighty fortress is our PKI, Part II 
The Cryptography Mailing List
Unsubscribe by sending "unsubscribe cryptography" to majordomo at metzdowd.com

@_date: 2010-07-28 15:16:32
@_author: Ben Laurie 
@_subject: A mighty fortress is our PKI, Part II 
[Moderator's note: due to a bug in the moderation software, this was
sent out twice with Ben's response cut off in the middle. My
apologies. --Perry]
Maybe it doesn't, but no revocation mechanism at all makes me nervous.
I don't know Kerberos well enough to comment.
DNSSEC doesn't have revocation but replaces it with very short
signature lifetimes (i.e. you don't revoke, you time out).
SSH does appear to have got away without revocation, though the nature
of the system is s.t. if I really wanted to revoke I could almost
always contact the users and tell them in person. This doesn't scale
very well to SSL-style systems.

@_date: 2010-09-08 21:35:38
@_author: Ben Laurie 
@_subject: Hashing algorithm needed 
Well, you can't always get what you want.
What I do in Nigori for this is use DSA. Your private key, x, is the
hash of the login info. The server has g^x, from which it cannot
recover x, and the client does DSA using x.

@_date: 2010-09-09 11:49:07
@_author: Ben Laurie 
@_subject: Hashing algorithm needed 
Indeed, if it is low entropy (I don't think you can assume it is,
though I'll readily agree it is likely to be), then it is subject to a
dictionary attack.

@_date: 2014-12-03 17:56:47
@_author: Ben Laurie 
@_subject: [Cryptography] Toxic Combination 
I think that's a completely unfair accusation - the difficulty has always
been the lack of a _usable_ way to _securely_ implement such protocols.
And by "usable" I mean a user experience that is
a) satisfactory to the user.
b) satisfactory to the site operator.
c) possible to transition to from existing systems easily (for at least the
And it has to be secure - which includes "not allow credential theft _even
by the site operator_".
This appears to be a tall order. But produce it, and I would certainly
fight hard for implementation.
BTW, its not clear to me how either of these would remove the need for
something with a CA-like role.
Also, the same difficulty is a barrier to PAKEs.

@_date: 2014-12-04 11:28:58
@_author: Ben Laurie 
@_subject: [Cryptography] Toxic Combination 
Oh really? Please provide references. Actually, I don't have time to be
drowned in a million crap papers, so please, for now at least, provide a
reference for the best solution you are aware of (or two or three if
choosing is hard).
There are many papers on how to do it badly. I have yet to see one (backed
by actual testing, I am not interested in usability by assertion) that's
actually deployable.
I did muse about that one for a while, and surely its the point of using
zero knowledge protocols? If it is not, then what is?
But if you really think its impossible, I'm certainly prepared to drop it
as a requirement.
And you claim that don't want to because they're all is a secret cartel to
keep CAs in  business? Really?

@_date: 2014-12-09 19:45:44
@_author: Ben Laurie 
@_subject: [Cryptography] Toxic Combination 
Come on, seriously? As I said below, I'm prepared to retract that
requirement, but I still ask: what is the point of using a ZKP if it
isn't to conceal the password from the site operator?
In any case, your position appears to be "you should implement this
even though I cannot point to a single example of how". Not tenable.
Pinning does not scale: you risk your site becoming unavailable for an
extended period if you screw up. Remediation is necessarily manual.
I think it is absurd to claim nothing happens. Certificate
Transparency and Safe Browsing are two obvious examples that improve
user security and have none of the above going on.

@_date: 2014-12-11 11:41:24
@_author: Ben Laurie 
@_subject: [Cryptography] Toxic Combination 
Look, if you don't want to admit you don't know how to do it, fine -
but don't try to blame me for that.
500 references that have something to do with passwords. So far I
haven't found any that discuss usable implementation of TLS-SRP or
However, I do notice you claim to address at least some of the
usability problem yourself, pp 547-552. I hope I am mistaken, but I
couldn't find any evidence of secure usability testing in those pages.
Has there been any?
On p.552, for example, you have a diagram headed "Non-spoofable
password entry dialog". This makes me suspicious, because it is well
known that these dialogs are entirely spoofable.
None, because, as you should well know (because we've discussed it
every time we've met for the last several years), I don't think
certificates are effective in protecting browsers from phishing (not
that browsers need protecting, users do, but I don't think they work
for that, either).

@_date: 2014-12-12 11:19:09
@_author: Ben Laurie 
@_subject: [Cryptography] Toxic Combination 
I thought it was well known that "Satoshi" holds many Bitcoins?
FOSS is "Free/Open Source Software". Pond is a secure messaging system
by Adam Langley.
You don't make a strong case for your rather over-broad claim above.
Though I do agree that crypto (like pretty much everything else) does
require someone to somehow support those who develop it. And those who
deploy it need to have a reason to bear the costs of doing so. And so
on. But this is not as simple as "No security protocol will achieve
wide adoption unless it includes a revenue model which someone can use
to build a business." You "explain" several counter-examples above,
for instance.

@_date: 2014-12-16 10:50:01
@_author: Ben Laurie 
@_subject: [Cryptography] Any opinions on keybase.io? 
Quite so. Not sure if I've mentioned this before on this list, so in
case I haven't:

@_date: 2014-03-28 11:50:16
@_author: Ben Laurie 
@_subject: [Cryptography] Dark Mail Alliance specs? 
Uhuh. And has there even been a breach disclosure notification?

@_date: 2014-10-04 18:21:19
@_author: Ben Laurie 
@_subject: [Cryptography] Creating a Parallelizeable Cryptographic Hash 
Of course ... I get you to sign the first three, now I can sign the
fourth one for you...
You could fix it by adding an IV. :-)
However, this is not a good way to go about designing crypto primitives.

@_date: 2014-10-06 11:59:28
@_author: Ben Laurie 
@_subject: [Cryptography] Best internet crypto clock 
That would prevent forgeries in the future, but not the past.

@_date: 2014-10-06 12:03:19
@_author: Ben Laurie 
@_subject: [Cryptography] Best internet crypto clock 
This is essentially the Certificate Transparency mechanism.

@_date: 2014-10-07 04:53:46
@_author: Ben Laurie 
@_subject: [Cryptography] Creating a Parallelizeable Cryptographic Hash 
Sure thing, but that's not what I meant. What I meant was that
starting with a dumb idea, then incrementally fixing things people
point out is not likely to lead to something good.

@_date: 2014-10-16 13:13:21
@_author: Ben Laurie 
@_subject: [Cryptography] [messaging] Gossip doesn't save Certificate 
Why not? I'm not sure what your threat model is for 2, so hard to respond
to it, but for 3, CT will allow you to see that this cert has been issued
and object to it.

@_date: 2015-04-10 13:00:05
@_author: Ben Laurie 
@_subject: [Cryptography] Untrusted Turtles all the way down 
Here's our plan: In short: stop adding new layers and instead do it differently. Use
the MMU for what its good for: virtual memory. Security/separation
come from "capability registers" which grant byte-grained access to
memory. Context switches are about 100x faster than on current CPU
architectures, and you do not need to understand multiple layers of
weirdness to believe in the security of the system. Just one.
_And_ it provides backwards compatibility with existing systems.

@_date: 2015-04-27 13:21:44
@_author: Ben Laurie 
@_subject: [Cryptography] Holy Heartbleed Batman - an Internet-scale 
Uhuh. As soon as it can be verified by others, it becomes "intermittent".
How convenient.

@_date: 2015-01-24 09:53:52
@_author: Ben Laurie 
@_subject: [Cryptography] Android's Secure ADB as a security hole 
I believe the key used is unique to adb, Surely this is not a problem?

@_date: 2015-01-25 20:48:48
@_author: Ben Laurie 
@_subject: [Cryptography] The Crypto Pi 
A different religion?
At the time, the diff was:
BTW, I don't agree with not mixing all inputs.
Experimental data:

@_date: 2015-01-26 17:03:08
@_author: Ben Laurie 
@_subject: [Cryptography] The Crypto Pi 
On FreeBSD, they do (urandom and random are the same).

@_date: 2015-01-27 20:23:27
@_author: Ben Laurie 
@_subject: [Cryptography] traffic analysis 
Yeah, but ... who can realistically afford that bandwidth? To every
possible recipient? Clearly you have to make a tradeoff.

@_date: 2015-01-29 11:03:46
@_author: Ben Laurie 
@_subject: [Cryptography] traffic analysis -> let's write an RFC? 
Clearly the idea was you design your network so that you do own the link.
Which brings me back to my question (even Google cannot afford that much
network, I suspect).

@_date: 2015-01-29 12:06:54
@_author: Ben Laurie 
@_subject: [Cryptography] traffic analysis -> let's write an RFC? 
As you point out below, not if the traffic is switched on a shared link.

@_date: 2015-03-04 13:39:34
@_author: Ben Laurie 
@_subject: [Cryptography] practical verifiable systems -- forensic and 
I observed the London Mayoral Elections. This was does using scanners (a
_lot_ of them). London Elects, who ran it, flatly refused to do an audit.
Their grounds for doing so is that any recount always has a small
discrepancy from the previous count and this discrepancy would introduce
doubt in the minds of the voters. Restraining myself from physical violence
was ... difficult.
Incidentally, on fixing the results: candidates were not allowed to
observe, but their representatives could. A screen was provided showing any
ballots that had been referred by the system for manual adjudication. Some
of the reps soon learnt that the adjudicator was quite easily swayed
towards their candidate given any chance mark in the right area.
All in all, observing was quite interesting. My two favourite parts:
1. The count was done by a machine provided by a Spanish company. Staff
from that company were sitting behind a desk with direct access to that
machine, their screens not visible. I was _not_ permitted to observe what
they were doing. Every other machine (except a couple that showed interim
counts) had a duplicate screen observers could view. What could possibly go
2. I realised after a while that following the maintenance staff around was
instructive. Doing so led to some screens with interesting errors - in
particular, SQL integrity constraint violations on vote counting tables.
Again, how could this possibly be a problem?
BTW, after a while the maintenance guys realised what I was doing and tried
to take routes that were hard for me to follow (we were on opposite sides
of barriers).

@_date: 2015-05-26 14:35:43
@_author: Ben Laurie 
@_subject: [Cryptography] open questions in secure protocol design? 
The way CT works is neither 1TCS nor agility - if you want to change
ciphersuite, you start a new log. So, it seems there are other parts of the
design space...

@_date: 2015-05-26 14:50:18
@_author: Ben Laurie 
@_subject: [Cryptography] open questions in secure protocol design? 
OK, but that doesn't remove the point that there are, it seems, options
other than agility.

@_date: 2015-05-28 13:36:42
@_author: Ben Laurie 
@_subject: [Cryptography] Guaranteeing that no distinct keys produce 
In fact, symmetric ciphers MUST NOT be groups (under composition of keys)
or there's a meet-in-the-middle attack available on them (this was a
self-inflicted interview question when I joined Google :-).
The other reason is efficiency: if you do EDE then the input and output
transforms can be dropped in the middle, since they cancel.

@_date: 2016-09-18 20:47:48
@_author: Ben Laurie 
@_subject: [Cryptography] Ada vs Rust vs safer C 
An open question is whether MS would claim copyright (or other IP) on
these annotations.

@_date: 2017-07-17 10:42:28
@_author: Ben Laurie 
@_subject: [Cryptography] SW requirements to block timing side-channel 
Not at all true - I used to work on realtime systems and (ours at least)
didn't use interrupts (hardly) at all.

@_date: 2017-06-29 10:57:34
@_author: Ben Laurie 
@_subject: [Cryptography] OpenSSL CSPRNG work 
If you have effective mixing, what is the problem with mixing in
potentially non-random sources?

@_date: 2017-09-14 10:06:45
@_author: Ben Laurie 
@_subject: [Cryptography] letsencrypt.org 
You are exposed to that risk regardless of whether you use Let's Encrypt or
not, so not quite sure what point you're making?

@_date: 2018-02-08 18:52:31
@_author: Ben Laurie 
@_subject: [Cryptography] RISC-V branch predicting 
Speaking of research, we  have been looking at CHERI applied to RISC-V:
 (chapter 6).
Speculative execution in a pure CHERI model automatically enforces bounds
that are the transitive closure of the bounds available to the current
process (that is, the current bounds in registers, plus all the bounds in
reachable memory).

@_date: 2018-01-04 10:24:33
@_author: Ben Laurie 
@_subject: [Cryptography] Software patent lifetimes are the problem (Re: 
There are also modern diseases that are treated by bleeding. Ferroportin
disease, for example.

@_date: 2018-01-04 10:52:10
@_author: Ben Laurie 
@_subject: [Cryptography] Hashgraph 
How would you ever know you had 1/3 malicious nodes? This is, of course,
why Bitcoin doesn't actually work, but its also why you can't use standard
results like that against it.

@_date: 2018-01-25 23:04:17
@_author: Ben Laurie 
@_subject: [Cryptography] RISC-V isn't the answer 
Right, because no-one ever paid a different price for different
functionality. This is why all computers are the same price, spec and
performance today.
