
@_date: 2015-01-09 12:36:01
@_author: Howard Chu 
@_subject: [Cryptography] SSH vulnerability when using passwords 
Jumping in here...
This is all pretty old hat. It was a common attack against S/Key too, back in the day.  But it was also easy to mitigate, using Telnet LINEMODE.
The Linux kernel originally supported this all no problem, by virtue of the EXTPROC tty setting, which it inherited from BSD's tty driver. Somewhere along the line some numbskull deleted EXTPROC support from the Linux tty driver. I added it back a few years ago.
Also updated the telnetd source to reenable LINEMODE on Linux
I added LINEMODE/EXTPROC support to OpenSSH a few years back too, but the OpenSSH developers were uninterested in merging it.
These days, with even CLI-based systems tending to use CBREAK/character-at-a-time input even for line-oriented input, more work needs to be done. E.g., for Bash's TAB/command-completion, which uses I also have a patch for tcsh lying around somewhere. The OpenSSH guys wanted to see BSD libedit supported instead of GNU libreadline; I got part way into that but never finished. Too much of an uphill battle trying to convince ignorant developers of why it's an important feature to support.
FWIW, bash works fine with the last OpenSSH revision I patched.

@_date: 2015-05-02 10:00:45
@_author: Howard Chu 
@_subject: [Cryptography] "Trust in digital certificate ecosystem eroding" 
I would start by shipping all the currently bundled CAs in disabled state. Every time you hit a new web site, prompt for whether to trust it's chain or not, and also display a counter of how many times you have trusted a site using this CA. I.e., I want to know how many of the thousands of CAs being shipped are actually useful in my own browsing patterns. The rest have no business being enabled in the first place.

@_date: 2015-05-05 09:12:21
@_author: Howard Chu 
@_subject: [Cryptography] "Trust in digital certificate ecosystem eroding" 
I said "I would start" - I didn't say "here is a complete solution for you." My point is that at the moment, not you nor anyone else has any actual metrics on the scope of the problem. In particular, software today doesn't provide *any* way for an individual user to see how many sites they used are at-risk/compromised when a particular CA is compromised. Whether any percentage of users will act on the information is irrelevant/vacuously true since the information doesn't exist. And whether end-users care or not, it's valuable information for the responsible sysadmins.
You can't design the fix before you've accurately scoped the problem.

@_date: 2015-09-21 07:12:07
@_author: Howard Chu 
@_subject: [Cryptography] Feedback welcome on autentication/password 
Funny to see this pop up now, it's been over 20 years since I worked on that code.

@_date: 2016-08-27 15:16:04
@_author: Howard Chu 
@_subject: [Cryptography] tail recursion in C [was Re: "NSA-linked Cisco 
It's not 1970 any more but we're still living in a world where electricity isn't free. Pretending that you have the freedom to use as inefficient a language as you want has significant real-world costs. Particularly today when most general computing is now being done with hand-held or body-worn devices with limited battery life.
We live in a world of finite resources. We are all always operating under very tight resource constraints. Wasting cycles or bytes is not doing anyone any

@_date: 2016-08-29 01:13:10
@_author: Howard Chu 
@_subject: [Cryptography] tail recursion in C [was Re: "NSA-linked Cisco 
Man, you brought back a lot of fond memories. But I also remember the Sun workstations, their boot PROMs were written in Forth. I love Forth, I think it's a brilliant language. But I also remember that Sun workstation boot consoles had abysmally slow scroll rates, and reimplementing them in compiled C made them orders of magnitude faster. Life is too short waiting for slow code to execute.

@_date: 2016-06-13 10:39:01
@_author: Howard Chu 
@_subject: [Cryptography] Determining TLS session keys from the hypervisor 
I think something like AMD's Secure Memory Encryption could help foil
this sort of attack. Assuming of course that the hypervisor actually
enabled it.
(Discussion Whitepaper  )

@_date: 2016-06-14 00:58:18
@_author: Howard Chu 
@_subject: [Cryptography] Determining TLS session keys from the hypervisor 
of Web servers *are* running "in the Cloud" - i.e., on hardware controlled by
someone else. The economics are likely to push ever more stuff "out there".
providers of virtual hosting - are not going to attack you; and *in general*,
that's probably true. But they may well be forced to by government order -
without telling you. And when it comes to the smaller providers - just how
much should you trust them?
Doesn't really matter how large or reputable the hosting provider is. All it takes is 1 employee to go rogue. This has been the pattern at the majority of Bitcoin exchange heists.
I don't know of many services that are run entirely within their own private data centers. Most web sites are VPSs or just web virtual hosts.
their guest OS instances and gain access to the hypervisor have occurred. So
even if you trust your provider, you do have *some* level of exposure to your
"running mates" on the host you share.
By moving out to a Cloud instance, you're generally saving money and you're
mitigating many practical risks - the big data centers are much less
vulnerable to power outages, fires, and all kinds of similar events than you
would likely be able to afford. This paper shows that you're not quite as
secure within your VM as you might think. You now have to go make the
tradeoffs for yourself.

@_date: 2016-06-20 07:25:05
@_author: Howard Chu 
@_subject: [Cryptography] Digital currencies 
Blockchains as currently envisioned would never scale anyway. It's not like any of this is a newly discovered problem of distributed computing. The only way to make any system scale is to leverage locality. When we have colonies on the Moon and Mars a single blockchain isn't going to work - you need to break things apart by locality. The majority of transactions can be settled 100% in a local set of nodes. Broadcasting all txs and blocks globally across the entire network/blockchain is inherently a non-starter. A system designed to work with global broadcasting is doomed from the start. You need a system designed with segmentation and partitioning built in.

@_date: 2016-03-12 10:31:08
@_author: Howard Chu 
@_subject: [Cryptography] Govt Can't Let Smartphones Be 'Black Boxes, 
saying that for centuries law enforcement agencies have been able to search
private property for evidence of crimes using a warrant.
The obvious direction where this is going:
Yes, we as citizens grant our government the right to search private property with a proper search warrant. But we don't grant anyone the right to search our minds. A computing device is more than just an inert piece of "property" - it is an extension of our brains. Maybe only figuratively today, but brain-machine interfaces aren't far away, and then it will be the literal truth. And again, I sure as heck will not be granting anyone the right to search any components of my mind. Nor should I need to - the 5th Amendment already guarantees that.

@_date: 2016-10-04 08:52:58
@_author: Howard Chu 
@_subject: [Cryptography] French credit card has time-varying PIN 
Yep, I noticed the same. Quite annoying, so you still can't use them at e.g. subway ticket kiosks and the like.

@_date: 2016-10-04 17:03:54
@_author: Howard Chu 
@_subject: [Cryptography] French credit card has time-varying PIN 
Hey, thanks for this pointer. It got me to look into cardpeek, which reminded me that I have a smartcard reader built into this Dell M4400 laptop that I've never used. Until now. I was able to successfully read the CVMs of a couple of my Visa cards. Strangely, it wasn't able to get any information from one of my other cards.
Two of my Visa cards actually have PIN first in the priority list, but only "If unattended cash" - e.g. kiosks and ATMs I suppose. So for an in-store purchase with a checkout counter, it still drops into  "Signature (paper) - If terminal supports the CVM"

@_date: 2017-08-07 03:28:45
@_author: Howard Chu 
@_subject: [Cryptography] Finding undocumented opcodes 
Reminded me of a 1975 article in Byte magazine on undocumented 6502 opcodes.
So did the NSA knock on AMD's door?

@_date: 2017-12-01 08:02:15
@_author: Howard Chu 
@_subject: [Cryptography] Transparent remote file access 
Phillip sounds like he's been burned by some crappy implementations.
In terms of data security, OpenLDAP has no data-disclosure bugs. That makes it unique in the current landscape of database systems - monolithic, distributed, or otherwise.
LDAP is a somewhat lobotimized protocol for accessing a database with a hierarchical data model (X.500). Servers implementing this data model tend to be optimized for read-mostly access. In read-heavy workloads there is no other database system anywhere close to OpenLDAP's performance.
Over the wire, that's quite unlikely. From secure authentication mechanisms, to fine-grained authorization, an OpenLDAP server is pretty impervious to network-based attacks.
When running on infrastructure you don't own, you have to worry about both data in RAM and data on disk. AMD's secure virtualization extensions take care about securing RAM for cloud-based deployments. OSs with encrypted filesystems would handle the security of data on disk, assuming the rest of the OS is secure. Of course, once an encrypted filesystem is successfully mounted, it's essentially cleartext for every user with access to the filesystem. If you want finer-grained control there, you need application-level storage encryption. In the case of LDAP, OpenLDAP with BerkeleyDB supports database encryption today, and OpenLDAP with LMDB 1.0 will also support it (at database page level, for both BDB and LMDB).

@_date: 2017-12-19 18:15:32
@_author: Howard Chu 
@_subject: [Cryptography] Rubber-hose resistance? 
I do this too. But just out of curiosity, what do you use for ssh credentials when traveling?

@_date: 2017-12-19 21:35:43
@_author: Howard Chu 
@_subject: [Cryptography] Rubber-hose resistance? 
SSH keys are difficult to memorize, and I prefer not having any on the clean

@_date: 2017-12-23 23:13:54
@_author: Howard Chu 
@_subject: [Cryptography] Rubber-hose resistance? 
You guys all seem to be ignoring Secure Erase. Any particular reason?

@_date: 2017-12-23 23:37:59
@_author: Howard Chu 
@_subject: [Cryptography] Rubber-hose resistance? 
Actually no, most SSDs sold since the late 2000s have supported the feature set, and on Linux the hdparm command has supported it since 2005.

@_date: 2017-12-25 23:50:28
@_author: Howard Chu 
@_subject: [Cryptography] Bitcoin theft and the future of cryptocurrencies 
Lots of promises, very little delivery thus far. Their github issue tracker looks like a disaster area.
Zerocash does no such thing.
And coinjoin was already demonstrably broken over a year ago.
(Unfortunately the original text of the above post has been deleted. I've been looking for an archived copy but haven't found one yet. Suffice to say, it showed that as of 2016 law enforcement already had off-the-shelf software capable of deanonymizing coinjoin'd transactions.)

@_date: 2017-12-27 21:28:48
@_author: Howard Chu 
@_subject: [Cryptography] Bitcoin theft and the future of cryptocurrencies 
Nonsense. The paper's author has no connection to any particular coin project.
Point is that zcash promises perfect privacy but the tech is *unusable*. If it were practical to use, exchanges would have adopted it. And, knowing that the tech is so computationally expensive, the zcash project has done *nothing* to educate its users on the actual risks involved. They've been completely irresponsible here, focused only on appeasing their investors.
Monero ring signatures are not just mixes - the real signer is unprovable by a 3rd party observer. And the use of stealth addresses means even if you could pin down a particular signer, you can't actually associate it to a specific

@_date: 2017-12-27 21:15:24
@_author: Howard Chu 
@_subject: [Cryptography] (no subject) 
Fwiw, Ukraine has already got a cryptocurrency of their own, forked from Monero.

@_date: 2017-12-28 18:14:29
@_author: Howard Chu 
@_subject: [Cryptography] Bitcoin theft and the future of cryptocurrencies 
In some far future where CPUs are 1000x faster, RAM is 100x larger, and power efficiency is 10,000,000x better, sure.
If it were usable *today* then why are only 1% of Zcash txs actually fully shielded? Privacy is the *flagship feature* of Zcash. It is the only defining difference between Zcash and the Bitcoin code it was forked from. It is the only reason for Zcash supporters to want it and use it, and yet 99% of Zcash' txs aren't private, because it costs too much CPU and RAM to use the privacy Theoretical perfection is meaningless if the implementation is too slow for practical use.

@_date: 2017-07-02 12:14:11
@_author: Howard Chu 
@_subject: [Cryptography] (was credacash) 
Bitcoin's been at its scaling limit for over 2 years. Aside from that, Bitcoin lacks fungibility, which by definition means it is *not* a currency.
Monero solves most of Bitcoin's problems - fungibility, dynamic blocksize being the two major ones. But yes it's still a blockchain, which is still inherently unscalable. As I see it, the only way forward, while still maintaining the distributed, trustless properties of the blockchain, is to partition (shard) the data. Without having worked out all the details yet, I believe it can be made to scale by structuring the blocks as a TRIE, which can grow additional levels as needed. Branching within the TRIE could be as simple as indexing off a particular byte of a block address. Or it could be based on a consistent hashing algorithm.
If you can successfully, fairly, distribute responsibility for block storage across the network, you should also be able to reduce overall bandwidth consumed by block propagation.
As an easier to implement option, you partition based on block number instead of block address. In this case, every node still needs a complete list of block addresses (in order to map addresses to number), but given N branches of the TRIE they only need to store 1/N of the actual blocks. Then obviously, only one particular subset 1/N of the network needs to participate in transaction propagation at a time, also.
Assuming storage requirements are thus out of the way, the only limit to transaction rate is network speed / transaction size.

@_date: 2017-11-13 18:41:31
@_author: Howard Chu 
@_subject: [Cryptography] Is ASN.1 still the thing? 
Fwiw, liblber in OpenLDAP is extremely efficient for parsing ASN.1. It allows OpenLDAP slapd to run at line speed, even on multigigabit network links.
LOL. Only after we're certain that XML is dead and gone, and JSON is tossed into the trashbin of history as it properly deserves.

@_date: 2017-11-13 18:44:21
@_author: Howard Chu 
@_subject: [Cryptography] Is ASN.1 still the thing? 
In ASN.1 DER you're required to use the shortest representation, and the decoder must reject the input if it's not in shortest form.
The subject of this message thread ought to be "why are people still inventing serialization formats?" ASN.1 works well from network and CPU efficiency perspective, *and* is reliable for security-oriented usage.

@_date: 2017-11-13 22:19:52
@_author: Howard Chu 
@_subject: [Cryptography] Is ASN.1 still the thing? 
You should read anything you're going to reference. I just ran thru that paper and in pretty much every metric ASN.1 was superior to protobuf. Memory footprint, CPU consumption, and resulting message length. I'm not familiar with the ASN.1 compiler they used, but it appeared to require messages to be decoded into objects all in one go, which would greatly affect its memory footprint. OpenLDAP's liblber allows messages to be decoded incrementally, in-place for zero-copy streaming. We can't do a direct comparison since they're using PER and we only support BER/DER, but on BER/DER, I suspect liblber would greatly outperform their chosen ASN.1 software.
Google is not a paragon of efficiency; there's plenty of things they get wrong, left to their own devices. I'll note that Google contracted with my company back in 2007 or so when they needed help scaling their servers to handle multi-thousand concurrent connections.
Using your wire format for your storage format has been done before. It works when you have a simple data model and a simpler/nonexistent security model. It doesn't work for e.g. OpenLDAP where you have fine-grained access controls which require hiding some fields or values from some requestors, thus requiring field and record lengths and offsets to be recomputed on the fly.
Like most things, difficult things get easier with practice. Good tools are just as easily misused as used, it all comes down to the person using it.
liblber has been around for a couple decades, carefully optimized, heavily tested, and widely deployed. It has never been broken by buffer overflows or other such nonsense. Comparatively, the protobuf guys are still just getting their feet wet.

@_date: 2017-11-14 20:16:19
@_author: Howard Chu 
@_subject: [Cryptography] [FORGED] Re: Is ASN.1 still the thing? 
This sounds like you want to concurrently decode and re-encode, which is a slightly more unusual requirement. But yes, while it's possible to do a streaming decode, you can't really do a streaming encode.
Btw, as an example, here's our X.509 cert handling in slapd. It's quite lax, in terms of actually looking for malformed certs, but you'll get the idea.

@_date: 2017-11-20 00:12:22
@_author: Howard Chu 
@_subject: [Cryptography] Is ASN.1 still the thing? 
Sorry this is just stupid. Reliable BER/DER decoding has been a solved problem for a couple of decades by now.
libraries/liblber> size .libs/liblber.so
    text	   data	    bss	    dec	    hex	filename
   54202	   1680	    136	  56018	   dad2	.libs/liblber.so

@_date: 2017-11-20 11:26:35
@_author: Howard Chu 
@_subject: [Cryptography] Is ASN.1 still the thing? 
(Just to digress a bit - I've wished for hexadecimal in string-form integer serialization too, since it allows simple parsing into binary, independent of native word size. Serializing into decimal is ridiculous...)

@_date: 2018-04-02 15:55:18
@_author: Howard Chu 
@_subject: [Cryptography] Password entry protocols 
Not true, the power button is just another soft event, and the Power menu on Android (which pops up when pressing the power button) is fully customizable.

@_date: 2018-08-19 02:42:41
@_author: Howard Chu 
@_subject: [Cryptography] Throwing dice for "random" numbers 
There are 10 and 20-sided dice, if you must have decimal numbers.

@_date: 2018-08-30 16:56:12
@_author: Howard Chu 
@_subject: [Cryptography] WireGuard 
Why is that clever? Crypto algorithms have relatively short lifespans. Without startup negotiation,
whatever version of Wireguard you deploy today will have to be completely thrown away within a few
years. How are you going to coordinate the deathmarch upgrades then?
ssh's default key model is "convenient" but less secure than the certificate authority model, as
soon as you have more than one computer in an administrative domain. How many people actually
stop and phone up a remote collaborator to verify a host key the first time they connect to a
new machine?
C is still the low-level language...

@_date: 2018-02-28 16:02:01
@_author: Howard Chu 
@_subject: [Cryptography] Review of UBIC 
It would be a mistake to exclude Solar input from your consideration. It completely negates your assertion of "limited resources".

@_date: 2018-01-04 05:33:56
@_author: Howard Chu 
@_subject: [Cryptography] Software patent lifetimes are the problem (Re: 
Not to disagree with an otherwise excellent post, but bloodletting was actually an effective defense against the Black Death. In particular, the plague bacterium fed on iron in the blood; people who were anemic tended to be immune. Interesting that the plague tended to kill the wealthy population first...

@_date: 2018-01-06 05:49:06
@_author: Howard Chu 
@_subject: [Cryptography] Speculation considered harmful? 
Eh. In the context of Spectre, the CPU knows which cachelines it loaded in a speculative fetch. It should simply mark them invalid when unrolling the

@_date: 2018-01-06 06:55:25
@_author: Howard Chu 
@_subject: [Cryptography] Crypto for optimistic transactions ? 
That 5-35% number is the effect of the patches to mitigate Meltdown, which primarily affects Intel (and also ARM's Cortex-A75). AMD clearly demonstrates that there's a right way to handle things, since their chips don't have this The Spectre attack is harder to defend against, but it can only reveal memory
within a single process's address space, so for the most part I find it a non-event. It only becomes a problem if you allow hostile code to be injected into your running processes. Web browsers are the most obviously vulnerable, particularly when they allow user-loaded extensions and executing javascript etc. from random web sites. In that respect the attack surface is nothing new, and we already know about isolating browser tabs/pages into their own processes to mitigate such types of attacks.

@_date: 2018-01-06 15:51:30
@_author: Howard Chu 
@_subject: [Cryptography] Speculation considered harmful? 
No. For the Spectre attack to work the cache has to already be in a known state beforehand. The attack code always does a clflush on the target address to initialize it, which leaves it invalid. Explicitly marking the cacheline as invalid after the cancelled speculative fetch would just restore it to its initial state and the attacker will get no information, every reference will always cause a memory fetch.

@_date: 2018-01-07 09:21:36
@_author: Howard Chu 
@_subject: [Cryptography] Crypto for optimistic transactions ? 
That's a nonsensical statement. Somebody had to initiate the attack in the victim memory in the first place. Turning off javascript in the web browser would go a long way toward eliminating this threat.

@_date: 2018-01-09 09:41:28
@_author: Howard Chu 
@_subject: [Cryptography] Speculation considered harmful? 
It's futile to make the compiler do that work because it can only do static scheduling. That might be fine for a 1950s era mainframe where only one job runs on the machine at a time but it's hopeless in a modern day multithreaded/multiprocess environment where dynamic scheduling is required

@_date: 2018-01-14 18:30:15
@_author: Howard Chu 
@_subject: [Cryptography] Call for Reviewers: Bulletproofs in Monero 
The Monero Cryptocurrency uses Ring Confidential Transactions (ringCT)[1] to hide the amounts being transacted on its blockchain. One of the consequences of hiding amounts is that you still need a means of verifying that the amounts are legitimate, don't overflow, etc., without revealing them. In CT, "range proofs" are used to assert the validity of output amounts. These proofs are quite large, causing a typical 1-input/2-output Monero transaction to use around 12.5kB. (Pre-ringCT this transaction would be only around 500 bytes.[2])
Last November saw the release of new work out of Stanford called "Bulletproofs"[3] which makes the size of a range proof logarithmic in the number of values, instead of the linear size they currently consume. Use of Bulletproofs will reduce typical Monero transaction sizes by ~80%, so this is a significant improvement. The Monero Research Lab[4] developed a prototype in Java, and The Monero Project has subsequently implemented Bulletproofs in C++ and this code has been running on the Monero testnet since the beginning of last December.[5]
While the researchers in the Monero Research Lab are confident in the soundness of the math in the Bulletproofs paper, the Monero Project is being cautious about deploying the feature to production on mainnet. The Monero Project recognizes the value of independent 3rd-party reviews. Therefore, the Monero Project is now soliciting help in conducting formal, in-depth reviews of the C++ implementation. If you're interested, please contact sarang.noether at protonmail.com for details. Funds are available to pay for services rendered.
[1] [2] [3] [4] [5]

@_date: 2018-01-15 05:04:20
@_author: Howard Chu 
@_subject: [Cryptography] canonicalizing unicode strings. 
Have you already read  ?
Our normalization code is in

@_date: 2018-01-26 18:03:25
@_author: Howard Chu 
@_subject: [Cryptography] I'll give the right answers to the right 
You could look at Sun/Oracle Niagara which was pretty much 8-way hyperthreading per core. Ultimately it didn't have good enough single-thread performance, regardless of how embarrassingly parallel your workloads.

@_date: 2018-01-29 02:07:55
@_author: Howard Chu 
@_subject: [Cryptography] DAG vs Blockchain 
Perhaps DAG is too vague for this application. You could implement something more specific - a tree (or a TRIE, actually). E.g., given output IDs of XX bytes, you might have a root/genesis block with 256 children. An output with ID beginning with byte xx would only be stored on a chain descending from the xx'th child of the genesis block, and you'd use DHTs to partition the 256 branches across the entire P2P network. And below those first 256 children, you could use the 2nd byte of the ID to subdivide further, and distribute further. Then only small fractions of the network are responsible for propagating and storing small fractions of the transaction traffic.
The problem of course is nodes all have incomplete information, and whenever a verification is needed, most nodes will have to find some other network peer to assist, instead of having a local chain of authoritative info. And the question is will this additional volume of verification queries exceed the savings from the reduced propagation traffic.

@_date: 2018-06-18 15:16:37
@_author: Howard Chu 
@_subject: [Cryptography] How to make rowhammer less likely 
I would expect that non-volatile RAM (like STT-MRAM or Intel Optane ReRAM) should make all of this moot. Anyone know?

@_date: 2018-05-06 19:13:00
@_author: Howard Chu 
@_subject: [Cryptography] A quicker block chain? ... Thunderella 
Those two requirements have nothing to do with blockchains though. Blockchains only make sense when multiple mutually untrusted parties must collaborate. That is not the case in typical "distributed ledger" scenarios. Also, a blockchain only works when there is a reward attached to the block mining activity, otherwise there's no incentive for the multiple parties to spend their resources maintaining the chain. Aside from application to cryptocurrency there's pretty much nothing that blockchain technology is suited for (and even currency is still ... questionable) that doesn't already have superior solutions using conventional databases.

@_date: 2018-05-07 21:40:59
@_author: Howard Chu 
@_subject: [Cryptography] secure authentication ... as opposed to passwords 
Indeed, plenty of code.
Kerberos ticket-based authentication and X.509 certificate-based authentication both work without the target server ever seeing a user's password.

@_date: 2018-05-30 09:14:27
@_author: Howard Chu 
@_subject: [Cryptography] Police want encrypted radios 
The APCO-25 digital radio spec has been around for quite some time. I used to muck with them using GnuRadio. All of this stuff is pretty well documented by now. Seems like it didn't work too well, and a lot of districts trying to deploy encryption had to rollback to cleartext.

@_date: 2018-09-01 08:10:33
@_author: Howard Chu 
@_subject: [Cryptography] WireGuard 
Go ahead and propose a new crypto protocol built around single-DES then.
Or even triple-DES. Have fun with that.

@_date: 2018-09-01 08:28:05
@_author: Howard Chu 
@_subject: [Cryptography] WireGuard 
You misread. The words I wrote above explicitly state that the certificate authority model
is more secure than ssh's default key model.
Thanks for confirming that nobody checks host keys, which was exactly my point.
Most people will skip past unknown TLS certificates too, at least in web browsers. But it's
so much rarer to encounter them that you can train a user population to be suspicious of
them. Particularly in the case of authenticating ssh logins. Then you're no longer talking
about random users and random hosts. With a custom self-signed CA you can tell all of your
users "this is the only valid CA cert" and your entire network of hosts is unambiguously

@_date: 2018-09-20 13:13:03
@_author: Howard Chu 
@_subject: [Cryptography] Previously unknown (I think) Malware 
Go buy a few cheap bluetooth headsets and infect them, and forward those on
instead of the original party's items.

@_date: 2019-08-11 00:04:32
@_author: Howard Chu 
@_subject: [Cryptography] Our leader opines on cryptocurrencies 
I think you're working from outdated info. The average Monero txn is bigger than
the average Bitcoin txn, true, but that has improved a lot over time.
While the average Bitcoin txn size is around 260 bytes, the average Monero txn size prior to the deployment of RingCT was around 2KB.
With the initial deployment of RingCT that increased to around 13KB. After the subsequent deployment of Bulletproofs to replace the previous
CT rangeproofs, the average size has now decreased back to about 3KB, and there is ongoing research into new signature schemes with
sublinear size scaling that will reduce txn sizes even further. Such improvements may deploy as early as next spring.
Mass adoption of a mass surveillance tool is worse than useless.
Monero transaction volume continues to increase The crowd is coming. And the fact is that any new txn is hiding amongst all of the millions of preceding txns,
so it's already true there's a very large haystack for any particular needle to hide in.
Better cryptography is at least necessary, if not sufficient.
You can't replace them if you don't have a viable technology to use in their place. Bitcoin tech is not viable.
I don't see how this is true at all. Reputations matter between buyers and sellers in the real world, but not between currency sender and recipient entities on
a blockchain.

@_date: 2019-08-16 13:52:56
@_author: Howard Chu 
@_subject: [Cryptography] Well, that only took ten years 
You can operate a fully automatic CA on OpenLDAP that will scale to
whatever data and traffic volume you care to, no sweat.
I personally use this to generate server certs for my email servers, and
client certs for my laptops / phones / etc.

@_date: 2019-12-11 13:06:22
@_author: Howard Chu 
@_subject: [Cryptography] Stupid movie encryption scenes 
The Crypt-breakers Workbench, released back in the 1980s, worked incrementally like this. You could enter guesses for
individual characters of the key, and it would show you how much of a particular piece of data was "successfully"
decrypted with the given portion of the key.

@_date: 2019-07-29 16:06:19
@_author: Howard Chu 
@_subject: [Cryptography] Our leader opines on cryptocurrencies 
If you don't buy bitcoins from coinbase, you're likely to get coins that are already tainted/blacklisted.
At best, you're doing poorly what coins like Monero already do automatically. But mostly, you're doing
nothing useful at all, while paying a lot in transaction fees for every additional step.
Everything you do on Bitcoin can be unraveled far more easily than you can even attempt to obfuscate it.

@_date: 2020-12-31 09:11:04
@_author: Howard Chu 
@_subject: [Cryptography] Bitcoin is a disaster. 
Bitcoin was a Pilot system, a good first effort. It did what a Pilot system is intended to do:
show where the pitfalls lie. You're supposed to learn from it, then toss it out and go back to
the drawing board. This missing step is what all the Bitcoin proponents have failed at. They kept
pushing the prototype, instead of throwing it out and designing a proper production system. They
insist that its immutability is its source of strength, instead of recognizing that no first stab
at any design is ever really that good, and systems need to evolve as we learn more about how they
work in practice.
Much labor and many transaction fees. But other systems have come along that studied Bitcoin's
shortcomings and solved them. Such as CryptoNote in 2013, which used stealth addresses to hide txn
recipients, and ring signatures to hide txn senders. (Both concepts which Satoshi referred
to himself, in various Bitcointalk threads.) Once again, Bitcoin isn't broken because nobody
knew how to solve its issues - it's broken because people decided not to implement known fixes.
Today Monero, which evolved from CryptoNote, uses RingCT to hide senders and transaction amounts.
CT - Confidential Transactions - is one of many solutions created by Bitcoin developers, but
never deployed onto the Bitcoin network.
Yes. Again, Bitcoin showed us where the pitfalls are, so we can focus attention on solving them.
Monero does pretty well here too, with dynamic blocksize to handle sudden spikes in txn volume,
and dynamic fees to discourage spamming the network.
The Power Law is probably always going to favor larger centralized mining operations.
Though things like P2Pool might be a solution to that. Remains to be seen.
This is why we continued to push for ASIC resistance in Monero. The RandomX PoW algorithm
will remain resistant without any algorithm tweaks for at least 3-5 years before we need
to look at re-tuning it.
Privacy and security are pretty much diametrically opposed to efficiency/scalability.
I don't see any way around that. I suppose we can accept different degrees of privacy.
E.g., TLS keeps a communication private, but not secret - an observer can't tell the
content of the communication, but they can tell that the communication occurred between
two parties. TOR or I2P can keep comms secret - an observer can't tell that two parties
are communicating at all. TLS imposes an overhead cost compared to plaintext comms, and
TOR/I2P imposes even more overhead compared to that.
Just as with the HTTPS-Everywhere initiative, I think the age of insecure, plaintext
comms is over. We shouldn't settle for transparent financial networks any more either.
Sure, but we have to accept the fact that it is in no way going to be the currency of
the future. If there's going to be one universal currency of the future for all human
commerce, it's going to need a network protocol that works on interplanetary scale,
because we're probably going to at least have colonies on Mars by the year 2140.
Bitcoin was a landmark achievement, as a prototype, but it's not fit for purpose,
and we need to (and can!) design better systems going forward.

@_date: 2020-03-05 21:35:27
@_author: Howard Chu 
@_subject: [Cryptography] Possible reason why password usage rules are 
This one is easy - you can't travel with an expired photo ID because the possibility
exists that someone else is already traveling with the valid ID.

@_date: 2020-03-06 02:24:57
@_author: Howard Chu 
@_subject: [Cryptography] Possible reason why password usage rules are 
An expired photo ID has to be considered the same as a forged ID or a
counterfeit, because there's a high probability that the corresponding
new/renewed ID exists and is in circulation.
As for identical twin - come on... People don't check that closely, or
your own appearance changes over the years.
IDs have to be unique. The attempt to use an expired ID means it can no
longer be relied on to be unique; the non-expired one is out there somewhere,
possibly being concurrently used by someone else.

@_date: 2020-03-06 17:13:49
@_author: Howard Chu 
@_subject: [Cryptography] IDs and licenses, 
The discussion here is why you can't use an expired photo ID for travel.
Doesn't matter whether it's a driver's license or some other government
issued ID.
It *might* have identified you. It may be that you're John's brother who's
wanted for murder, trying to leave the country, and John actually has
the currently valid ID in his possession.

@_date: 2020-03-06 19:53:07
@_author: Howard Chu 
@_subject: [Cryptography] IDs and licenses, 
This is the same scenario as browsing to a website with an expired TLS cert.
Most of the time it will be safe to ignore the fact that it's expired, and
continue browsing. But it presents an opportunity for hijacking the site,
which is why current browsers won't let you proceed (without extra hassle).

@_date: 2020-11-01 12:46:36
@_author: Howard Chu 
@_subject: [Cryptography] The Truth Social Network: A Decentralized Social 
We already had that, it was called Usenet on NNTP.
A fully permissionless network will rapidly be overwhelmed with spam if it achieves any degree of popularity.
Also not sure that there's merit in retaining social media posts forever, as on a blockchain. It's nice to have
a few Usenet archive sites for historical reference, but for the majority of use cases periodic expiration is
preferable. Most social posts are only relevant for a brief span of time, and a lot of stuff deserves to be
There's certainly some merit to the notion of decentralized identity. I.e., we pretty much never care that your
identity has been verified by some 3rd party authority, or that some authority granted you permission to operate
with a particular account. We only care that you have an identity uniquely associated to you, so that no one can
impersonate you. The cryptocurrency ecosystem seems to have solved this problem, yes.

@_date: 2020-11-06 15:40:36
@_author: Howard Chu 
@_subject: [Cryptography] reliable broadcast channel 
I don't believe this description is true for IP multicast. But you
can't track success without maintaining the equivalent of point to
point state.

@_date: 2020-11-16 02:48:45
@_author: Howard Chu 
@_subject: [Cryptography] Satoshi Nakamoto Email Timestamps Disambiguation 
)
 ) I would expect since majordomo @ metzdowd.com is the first to receive the message, the timestamp
on its archive is closest to the correct time. In any case, if you examine the Reply link on the
two respective pages you'll see they both reference the same messageID so it's pretty likely that
it is the same message just received later by the 3rd party archiver.
e.g.:  satoshi at vistomail.com
