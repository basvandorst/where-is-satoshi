
@_date: 2001-08-01 20:26:35
@_author: jamesd@echeque.com 
@_subject: moving Crypto? 
--
As you know, corrupt judges have closed down a number of industries with frivolous deep pockets lawsuits.  Two of the most obviously improper judgments occurred with the small planes industry, wiping it out within America, and the production of vaccines, wiping out vaccine production.  The government eventually decided vaccine production was vital, and took action to protect vaccine manufacturers, but not anyone else.  Although the court decisions were flagrantly improper, and the judges corruptly received benefits fromt their improper decisions, these decisions still stand, and have never been undone.
This provides a disturbing precedent that suggests DCMA will stand, and eventually enough crypto researchers will rot in jail that crypto research goes underground.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     4vmbIW1b/ozxtpplKlidc+7HUplMMMRi+UNB+6Za
     40aNTyNwiy4mlZeNHjtTVMfdox3NQAgHuTyHYwGMy

@_date: 2001-12-28 20:02:45
@_author: jamesd@echeque.com 
@_subject: Stegdetect 0.4 released and results from USENET search  available  
--
I download all of alt.anonymous.messages from the same news
server that large numbers of people post and download child
porn on.
My software always downloads all new messages in
alt.anonymous.messages irrespective of whether I am looking
for a particular message.  (Hey, I do not read anything in
alt.anonymous messages, I am just generating cover traffic
out of pure public spirit.)
Thus there is no ongoing pattern.
This system was first described a very long time ago in "true
names"     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     WaGBISA1ObM2v9DUT5dgMhF7a8QfnHz1GwISf94v
     4eKunzkdsCm+yDzSimzsw5nvwZctZg3NdD5VDl8v0

@_date: 2001-12-29 14:48:37
@_author: jamesd@echeque.com 
@_subject: Stegdetect 0.4 released and results from USENET search  available  
--
James A. Donald:
I doubt that posting on and receiving from a new server used
by tens of thousands of people is sufficient to make US
agents risk death to check what is on my computer.
And if it is, all the better.  We could do with a decent
death rate among US agents spying on US residents.
The surveillance measures the statists on this list imagine
would impose a serious burden even on a totalitarian state.
The reason that the Cuban government placed goons visibly
listening on every telephone conversation is that invisible
listening would have resulted in a flood of information
beyond their ability to handle.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     PZszz6Fe2pvgTljDvZy2wdF6LizlaJ8hxFzZ0YVF
     42Pmpx9IoC1dTQVlMSPgbQFtO5p9nP+Y2T5MirFTA

@_date: 2001-07-28 13:20:30
@_author: jamesd@echeque.com 
@_subject: Attention CipherSaber Users!! 
--
If I understand the paper  correctly, Cybersabre and WEP would be fixed if instead of making the RC4 initialization by concatenating a permanent and unchanging secret key, and an ever changing visible random value, they instead constructed the RC4 key by doing several different SHA hashes of the unchanging secret key, and the ever changing visible random value, and concatenated those hashes, and also discarded some substantial number of initial bytes from the RC4 output.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     xXgj5w0VTwI81xCh6amG5KOaB6nNDXD/mS2s7VXR
     4vvEsQrjo5uE2RHZQa/1atZPduIFyneZNWgzOS40c

@_date: 2001-09-09 23:12:09
@_author: jamesd@echeque.com 
@_subject: Sen. Hollings plans to introduce DMCA sequel: The SSSCA 
--
When the chinese invented paper, the government eventually
decided that this led to dangerous communication of dangerous
thoughts, and prohibited private production of paper.  It made
paper making a state secret, and castrated all paper makers so
that the secret would not be passed from father to son, but only
transmitted in government approved channels.  Thereafter paper
was used only to transmit government approved thoughts through
government channels, and to the populace.
Computers are similarly dangerous.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     pEyJYvluyMSWgNZ7GAkKeNzQ3mshy+SsKVJ/wMhs
     4sKLUftGKcn9X/CXUOs7SZPnTiZHI8M0IpiNhuyx6

@_date: 2001-09-09 23:12:09
@_author: jamesd@echeque.com 
@_subject: Sen. Hollings plans to introduce DMCA sequel: The SSSCA 
--
When the chinese invented paper, the government eventually
decided that this led to dangerous communication of dangerous
thoughts, and prohibited private production of paper.  It made
paper making a state secret, and castrated all paper makers so
that the secret would not be passed from father to son, but only
transmitted in government approved channels.  Thereafter paper
was used only to transmit government approved thoughts through
government channels, and to the populace.
Computers are similarly dangerous.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     pEyJYvluyMSWgNZ7GAkKeNzQ3mshy+SsKVJ/wMhs
     4sKLUftGKcn9X/CXUOs7SZPnTiZHI8M0IpiNhuyx6

@_date: 2001-09-15 07:48:33
@_author: jamesd@echeque.com 
@_subject: Rijndael in Assembler for x86? 
--
So say compiler writers.
I have not found this to be true.  Perhaps it is true of some
compilers and some people's assembler, and some code.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     R+xhXGtvscaNbOpfLSnwjeziDpDOv2XtF4/h1ST9
     4Haf1Gw4kSOsLRysU1Atpc78QFbNBjP0Dr0J4Ji3I

@_date: 2001-09-19 09:23:56
@_author: jamesd@echeque.com 
@_subject: Bush's anti-terror bill appears not to include crypto  restrictions 
--
Since we are now at war, that is not nearly as bad as they
could have gotten away with.  The legislation authorizes the
government to do stuff that they were already doing, and will
never stop doing, legal or illegal.
Not so good.  Anyone can easily suspect me of being a
terrorist, if I should discuss certain topics that are of
interest to this list.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     OxSgK6f7bogCHTXZRxbqohyWo1hd3WuRpZdrxBf
     4Bv3zdasO+K/WRhUy/l7ZdgToCl5eZFsH+iQ6vwXV

@_date: 2001-09-22 18:30:42
@_author: jamesd@echeque.com 
@_subject: <nettime> "Pirate Utopia," FEED, February 20, 2001 
--
Since the genuine signal has many sources, with different,
changeable, and idiosyncratic biases, the hider always has an
advantage over the detector.  If they have comparable skills,
and invest comparable work, the hider will always win.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     i21IhXGvGRwJ+jgxo4KF7T2KEHyMQFN3oGBVwEVM
     4h+lcypb/lRfbuL3ZD17GqGiA5h+Enw8aj9LUaShL

@_date: 2002-08-01 14:33:43
@_author: James A. Donald 
@_subject: Challenge to David Wagner on TCPA 
--
Their design, and the institutions and software to be designed around them, is disturbingly similar to what would be needed to restrict what software we could run.  TCPA institutions and infrastructure are much the same as SSSCA institutions and According to Microsoft, the end user can turn the palladium hardware off, and the computer will still boot.  As long as that is true, it is an end user option and no one can object.
But this is not what the content providers want.  They want that if you disable the Fritz chip, the computer does not boot.  What they want is that it shall be illegal to sell a computer capable of booting if the Fritz chip is disabled.
If I have to give superroot powers to Joe in order to run Joe's software or play Joe's content, fair enough.  But the hardware and institutions to implement this are disturbingly similar to the hardware and institutions needed to implement the rule that I have to give superroot powers to Joe in order to play Peter's software or content..     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     FQhKMpDHys7gyFWenHCK9p7+Xfh1DwpaqGKcztxk
     20jFdJDiigV/b1fmHBudici59omqc/Ze0zXBVvQLk

@_date: 2002-08-01 19:17:41
@_author: James A. Donald 
@_subject: Challenge to David Wagner on TCPA 
--
The announced purpose of TCPA/Palladium is to introduce some
intermediate cases.  For example you could compile your own code,
and then encrypt it so that it can only run on a specific target
As somone who sells code, I would think this would be a great
idea, were it not for the excesses we have been seeing from the IP
lobbyists.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     iB5WVaGfx+zq5Dani1KQGdZIU5Kl21LDrc7w4e1m
     2PoKhj2EuUKqjKlZ/RN3VXdP0TFKxmpO/rR69KupZ

@_date: 2002-08-01 19:17:40
@_author: James A. Donald 
@_subject: TCPA 
--
In an anarchist society, or in a world where government had given up on copyright and intellectual property, TCPA/Palladium would be a great thing, a really good substitute for law, much more
effectual, much cheaper, and much less dangerous than law.
In a world where we have anticircumvention laws and ever growing patent and copyright silliness, it seems a dangerously powerful addition to law.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     6FaJusAR8fMsVvaFm9l3vbuyiQwio/YrBFLpyT6c
     2Db/Fk0MeNi3mjdoDTo2IGzHeelYts0/xqiEjUFmA

@_date: 2002-08-02 10:37:16
@_author: James A. Donald 
@_subject: Challenge to David Wagner on TCPA 
--
I can think of two innocuous reasons, though the real reason is
probably something else altogether:
1.  Defending copyright enforcement is extremely unpopular because
it seemingly puts you on the side of the hollywood cabal, but in
fact TCPA/Paladium, if it works as described, and if it is not
integrated with legal enforcement, does not over reach in the
fashion that most recent intellectual property legislation, and
most recent policy decisions by the patent office over reach.
2..  Legal departments are full of people who are, among their
many other grievious faults, technologically illiterate.
Therefore when an insider is talking about something, they cannot
tell when he is leaking inside information or not, and tend to
have kittens, because they have to trust him (being unable to tell
if he is leaking information covered by NDA), and are
constitutionally incapable of trusting anyone.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     Alf9R2ZVGqWkLhwWX2H6TBqHOunrj2Fbxy+U0ORV
     2uPGI4gMDt1fTQkV1820PO3xWmAWPiaS0DqrbmobN

@_date: 2002-08-02 14:53:48
@_author: James A. Donald 
@_subject: Challenge to David Wagner on TCPA 
--
Obviously it is insane to use keys that you do not yourself control to keep secrets.  That, however, is not the purpose of TCPA/Palladium as envisaged by Microsoft.
The intent is that Peter can sell Paul software or content that will only run on ONE computer for ONE time period..
When the motherboard emits blue smoke, or the time runs out, whichever happens first, Paul has to buy new software.  If prices are lowered accordingly, this might be acceptable.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     4Mqj1ia6DD0EYpdLMEd7al35eTYefnvhcFesBlMz
     25n9obdfhvRVxEkY4YtWw7BuFxrOKgTtfI1Dp8uAA

@_date: 2002-08-09 18:21:44
@_author: James A. Donald 
@_subject: TCPA/Palladium -- likely future implications 
--
As TCPA is currently vaporware, projections of what it will be, and how it will be used are judgments, and are not capable of being true or false, though they can be plausible or implausible.
Even with the best will in the world, and I do not think the people behind this have the best will in the world, there is an inherent conflict between tamper resistance and general purpose programmability.  To prevent me from getting at the bits as they are sent to my sound card or my video card, the entire computer, not just the dongle, has to be somewhat tamper resistant, which is going to make the entire computer somewhat less general purpose and programmable, thus less useful.
The people behind TCPA might want to do something more evil than you say they want to do, if they want to do what you say they want to do they might be prevented by law enforcement which wants something considerably more far reaching and evil, and if they
want to do it, and law enforcement refrains from reaching out and taking hold of their work, they still may be unable to do it for technical reasons.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     D7ZUyyAS+7CybaH0GT3tHg1AkzcF/LVYQwXbtqgP
     2HBjGwLqIOW1MEoFDnzCH6heRfW1MNGv1jXMIvtwb

@_date: 2002-08-13 08:55:29
@_author: James A. Donald 
@_subject: trade-offs of secure programming with Palladium (Re: Palladium: 
--
Or to say the same thing more pithily, if it really is going to be
voluntary, it really is not going to give hollywood what they
want.  If really gives hollywood what they want, it is really
going to have to be forced down people's throats.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     q/bTmZrGsVk2BT9JgumhMqvjDmyIbiElvtidl9aP
     2/0CXfo6fzHCxpa+SX8o8Jzvyb71S0KzgBs0gDRhN

@_date: 2002-08-13 08:55:29
@_author: James A. Donald 
@_subject: TCPA and Open Source 
--
It does however, enable the state to control what OS one can boot if one wishes to access the internet.
It does not seem to me that the TPM is likely to give hollywood what it wants, unless it is backed by such state enforcement.
Furthermore, since the TPM gets first whack at boot up, a simple
code download to the TPM could change the meaning of the
signature, so that the machine will not boot unless running a
state authorized operating system.
It could well happen that TPM machines become required to go on
the internet, and then later only certain operating systems are
permitted on the internet, and then later the required operating
system upgrades the TPM software so that only authorized operating
systems boot at all.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     H/t91jm8hq5pLR2AdFYi2lRoV9AKYBZ7WqqJmKFe
     2/IFQaW0fl6ec+TL3iMKMxD6Y0ulGDK7RwqTVJlBQ

@_date: 2002-08-14 12:41:18
@_author: James A. Donald 
@_subject: MS recruits for Palladium microkernel and/or DRM platform 
--
On 14 Aug 2002 at 9:31, Seth Johns
I am entertained, but unsurprised, that those who would sell us
"trust" technology start out by lying to us.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     yskEcGKmAuiCv/g0O+62LwywX9uJukk5ZLrVsrC6
     2ZU13khZebdH4MNBSUqlk9RvmNnSMpBBwGK/aor7q

@_date: 2002-08-15 19:10:45
@_author: James A. Donald 
@_subject: TCPA not virtualizable during ownership change 
--
Lucky claims to have pointed this out two years ago, proposed more sophisticated crypto, and received a hostile reception.
Which leads me to suspect that the capability of the powerful to break the system is a designed in feature.      --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     JjoH8U8qZ1eOdT/yGjfV7Xz9andBZPeYWaOLC+NP
     2/OJG2MZSnAqcyuvUsNZTsQAcffGGST6LJ7e9vFbK

@_date: 2002-12-03 15:04:15
@_author: James A. Donald 
@_subject: [mnet-devel] Ditching crypto++ for pycrypto (fwd) 
--
Anything that is good, gets ported a lot.  Anything that is
ported a lot gets build/port problems.
If, on the other hand, something basically sucks and is seldom
maintained, it never has any build port problems.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     K00Cxu2DHI1p/nd/Sikb4w/SJCsbCuoMCG1YcMKT
     4v2DeY28rMTZQb0V2/N0OV9RwGguieCjNf8uSKnKx

@_date: 2002-12-08 17:31:51
@_author: James A. Donald 
@_subject: DOS attack on WPA 802.11? 
--
Arnold G. Reinhold
I do not think the DOS is significant, since one can do the
same thing with a spark emitter.  The person doing the DOS has
to bring his equipment up to the target, which makes attacker
vulnerable to BBRS (Baseball bat restoration of service)
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     z9usqTFDdak6fIXLvMz4FRjtDX9LwX0psRJRmfeP
     4JZ85epzXMA2AbDtWU3mqFXAi8Pu30SKDhyrx2bRN

@_date: 2002-02-03 11:27:07
@_author: jamesd@echeque.com 
@_subject: Welome to the Internet, here's your private key 
--
The public key infrastructure is simply not working.
Ordinary mortals do not understand how it works, therefore cannot use it correctly.
Certified public keys are therefore of limited value.
This is in part a result of an impenetrable and incomprehensible user interface that makes what is hard to understand far harder.
For example I can see no good reason why an active X control with public source cannot generate your private key -- so that as far as the normal user knows he is getting it from the authority by logging in to their web page.  We had this
arrangement some years ago -- what happened to it?
I just learnt that Windows 2000 and Windows XP construct a key pair for every user.  The interface around this seems designed to be utterly impenetrable, as though they were trying to protect against stupid users by using security by With Windows XP, we enter a world where everyone has a key pair securing his stuff -- and is unaware of it, and unable to use it.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     E2AfFWpRWRrQk9TjIHVW4PIkCIefZn7D7LUkwgdH
     4144WI1nmwDQ3k7tCTyZ3dyJFywdh8RkiPnOEv0gj

@_date: 2002-02-09 14:13:26
@_author: jamesd@echeque.com 
@_subject: PGP & GPG compatibility 
--
However, to make it work, everyone needs to get officially blessed keys, and manage those keys.  The authorized central authorities not oppressive.  One is free to get a pseudonymous certificate that merely testifies to one's control of an email address, for example jamesd50 at hushmail.com
But, alas, I have never encountered a non engineer successfully doing that, even though the interface is designed for idiots and attempts to hide what is going on. The hiding, however, merely makes things harder, not easier, and idiots somehow always fail, even if they are the kind of idiot who gets to be Chairman of the Board, who usually
display a fair bit of intelligence in other matters.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     JookN8yKLh3sJeIJIvdMGKG+ThURka7fVNj1bCnj
     4v4v8BJBaV13nPC/qC6tGXZiLR5NPjE1thes5z/Bp

@_date: 2002-01-27 09:35:33
@_author: jamesd@echeque.com 
@_subject: biometrics 
--
Biometric id can only work when you control the hardware and
the adversary does not, and you can also control what
hardware the adversary can bring to fool your hardware.  This
is feasible in an security door, or security checkpoint.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     mmKuTCrVlqWNgJ1KJRB13uadWidgYl4ks0dsOGkv
     4mWo+3nn3Y6o/ofFXME9BLLkvnRL2Sp037fR8ROhM

@_date: 2002-01-31 07:38:28
@_author: jamesd@echeque.com 
@_subject: Cringely Gives KnowNow Some Unbelievable Free Press... (fwd) 
--
The original paper on ECC proposed point compression and
described the algorithm in 1985.
See Bernstein's web page
Use the 1985 method.
If the methods patented are the same, and as far as I can
tell they are, the patents are invalid.  If the methods
patented differ, you are not using them.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     V2lKe8/zPipRJIcZE97A49gog89BMHmZrKWJ0GA8
     4sl5ZBNjSI2/m083cg2ed9OSfY9/uWraeiBqyR+Dj

@_date: 2002-07-02 12:10:49
@_author: jamesd@echeque.com 
@_subject: Montgomery Multiplication 
--
Methods are available that are very close to being N log N (See
Knuth) but I am not aware of anyone using them for practical
The most common method for multiplying large integers has time
Suppose we want to multiply two 2n bit numbers, to get a 4n bit
We break them up into n bit numbers, so now we want to multiply
(A * 2^n + B)  * (U * 2^n + V)
The long multiplication way of doing this would involve four
multiplications of one n bit number by another n bit numbers.
We could find the 2n+1 bit number A*U+B*V, special casing the
carry bit, since it usually does not quite fit, and the two 2n bit
numbers A*U and B*V
We could then construct the 4n bit number A*U * 2^(2n) + (A*U+B*V)
* 2^n  + B*V
However, to do this with three multiplications instead of four, we
instead find the number x  = (A+B) * (U+V) (A*U+B*V) = x - A*U -
One can perform analogous tricks for even greater savings by
breaking it up into three instead of two, or four, or five, but
after five it starts to get intolerably cumbersome.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     GKNOQNqkn5lYpFU6SPQseRS0yFwiX0ccDgB3zWAv
     2xPio6LEvIRR+GZo5JDHl5ctEbbqxoyebosdh+9ba

@_date: 2002-07-02 16:31:11
@_author: jamesd@echeque.com 
@_subject: "Wild and Crazy": Interview with Palladium's Mario Juarez 
--
Only that data that you choose to associate with that specific This is a very useful privacy protecting feature.
Of course another use of that feature, more useful to large corporations and less useful to yourself is that those corporations can sell you programs and entertainment content that can only be read on that machine, and ceases to exist when that machines trusted chip is fried -- they can sell you data that will
be associated with that particular computer, even though you would
prefer it not to be so associated.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     8KpRBENoQKtlOVgNYunEkBsAkozcXsuf8zdGwPdq
     2hetBbJ6k4/vezSEkl/kwNQeBMLsRrLE3f+cbtQvn

@_date: 2002-07-05 17:02:39
@_author: jamesd@echeque.com 
@_subject: Ross's TCPA paper 
--
Yes he will, but the big expansion of choice is for the the seller
of content and software, who will have more choices as to how he
can cripple what he sells you.  For example he can sell you music
that will only play on a particular music player on your
particular machine.
But that is not enough to give the content industry what it wants,
for someone can still break it on one machine, perhaps by
intercepting the bitstream to the the DA, and having broken it on
one machine, can run it on all machines all over the internet.
Break once, run everywhere.
Microsoft has also been talking out of both sides of its mouth, by
saying that this will also protect against break once, run
everywhere.  The only way that this can protect against
break-once-run-everywhere is to reduce user choice, to make it
mandatory that the user can only run government trusted software,
and to reduce seller choice, prohibit sellers from providing
unacceptable software, such as napster like software.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     XQJ33SB0W84Cm4Mw0+3lnN4nsUtaB4B6cIa1dP/2
     2s67UXEL+Y5FHrr52MYArwzRuptDlBNVQIJOj/n/8

@_date: 2002-07-10 15:48:27
@_author: jamesd@echeque.com 
@_subject: IP: SSL Certificate "Monopoly" Bears Financial Fruit 
--
IE comes preloaded with about 34 root certificate authorities, and
it is easy for the end user to add more, to add more in batches.
Anyone can coerce open SSL to generate any certificates he
pleases, with some work.
Why is not someone else issuing certificates?
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     FgD9xqiaNt/GIr99+cDvezUuY9K7pVf/sr8sYLtx
     2U+1rnhprPRzvE4aLRCq4ADtyF4DDrnAKjbwHgbFn

@_date: 2002-07-11 12:24:27
@_author: jamesd@echeque.com 
@_subject: IP: SSL Certificate "Monopoly" Bears Financial Fruit 
--
 How much, typically?
And who actually owns these numerous trusted roots?     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     y1gI63PXnGNK7Iznu3+gY+/0JLBPRaEEV/OWwPub
     20YHSnGmtg7lQW0NdXU4WMeKWfIQmlq3u3F/wjkOo

@_date: 2002-07-18 11:08:44
@_author: jamesd@echeque.com 
@_subject: They are still pushing SSCA 
--
: : 	Valenti predicted the U.S. government would need to
: : 	intervene in the debate over digital content and set
: : 	security standards. The  MPAA has welcomed a bill,
: : 	written by Senate Commerce Chairman  Fritz Hollings,
: : 	D-S.C., that restricts technology not adhering to
 : : 	government-approved "standard security technologies."
If you can stop a computer from copying bits, it is not a general
purpose computer and is only programmable by those specially
authorized.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     HaNgFVDGr0uFQ+g7W7INgonXy+GrW1AL+YP+w+RU
     2tJfgSdPgx9tmELKOjtTbuYoIxKJbm6HXPgYcjgVc

@_date: 2002-07-19 17:12:08
@_author: James A. Donald 
@_subject: It's Time to Abandon Insecure Languages 
--
I do not wish to start a language holy war, but I have full life cycle experience in various projects in various languages, and my experience was that if you use any language other than C/C++ ninety percent of the project goes much faster, and has far fewer bugs than C++, and the remaining ten percent, which you have to deliver in order to ship, involves a large number of horrible hacks which effectively negate all the safety features of the language and environment, take a very long time, and lead to all sorts of problems.
Why, I ask, is just about everything that large numbers of people use written largely in these languages?
From my experience, the answer would be that stuff written in other languages was never ready to ship.  It was always "essentially complete", and "completed except for integration and install issues", and "ninety nine percent complete", and "working, bug free, and fully deliverable, but there are some matters that have to be resolved before we deliver".
I used to think that a good compromise was to write the gui in visual basic, (or these days in flash and html) and drop into C as required to handle the internals.  This does lead to a deliverable product in a reasonable time -- but after delivery one still finds oneself needing to rewrite stuff into C++ that was in visual basic or flash script.
As a result of my full life cycle experience on a variety of projects, I am coming back towards the view that one might as well write the whole damn thing in C++, rather than discovering after delivery what parts really should have been written in C++.
Of course that sounds much like the old fogy argument, that one should write everything in assembler, because one needed to write some things in assembler.  As compilers improved, that argument became obsolete.
Perhaps with C# and .net the old fogy argument for C++ has also become untrue -- but it was still true pretty recently.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     YSrvoU0D3akuA2g2heOzqPt8gzWX6imCFjjDSDE4
     2swXqrKC3hDGNG8gjjm9oIkzGoL63EAnI+jlRT98v

@_date: 2002-07-20 05:40:28
@_author: jamesd@echeque.com 
@_subject: Maybe no stego on eBay afterall 
--
Different cameras will have different distributions, different
images and lighting conditions will have different distributions.
Different post processing with graphics programs will modify those
distributions in different ways.
This makes it harder, not easier, for the stego detect program to
detect a deviation from normal statistics, since it is hard to say
what "normal" is.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     eXeg6P7MbUxKZ1HzUEQgF4qbXq7Lws3dgbRD7+d7
     28RoYEBvxlq3xf2ovqwJdZ9f1miIoIU5Aef2rW4i6

@_date: 2002-07-20 13:59:29
@_author: jamesd@echeque.com 
@_subject: It's Time to Abandon Insecure Languages 
--
It seems like a really brilliant concept if it works, a solution to the presently unsolved problem of distributed computing.
However I have a suspicion that instead of the presently intolerable problem of bugs resulting in rare, non deterministic deadlocks, we will get the problem of bugs resulting in rare, non deterministic catch probs.
With E, as with C, we get multithreaded code executed in non deterministic order.  It appears to me that it still happen that a certain rare and unusual execution order can reveal a bug, the bug being of the form that if G is executed before Y is executed,
which normally never happens, then the "when" clause for X can
never be executed until the "when" clause for Y is executed, but
the "when" clause for Y can never be executed until the "when"
clause for X is executed -- the old familiar multithreading
problem that has destroyed so many projects and careers. in a new
and slightly different guise.
Is there some feature of the syntax or error handling of E that prevents one writing such code, or reliably detects the error if one does write it?     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     TJaqxyH7No6TPtZ2M1lp9CnI8y97z98H8Iu8O1fd
     2VYVSKyVceokHx47wtPodKLoRStR7QRTLp+38k41a

@_date: 2002-07-22 22:59:25
@_author: jamesd@echeque.com 
@_subject: building a true RNG (was: Quantum Computing ...) 
--
You cannot measure entropy retrospectively.  You need to have a   theory as to where the entropy is coming from, in order to   reliably measure it.
Thus hardware sources should be based on simple and well   understood physical principles, such as Johnson noise or shot   noise. Entropy is not quite a physical quantity -- rather it is on the  slippery edge between being a physical thing and a philosophical  thing. If you are not careful, you will slip into a deep epistemic bog and find yourself needing to ask "how do we know what is knowable, and what is the whichness of why?"
To avoid such deep waters, know where your entropy is coming from.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     SMGOwg3qIP0/FsfmA7GzZGN/XYAabuqcE9Z9eiuB
     2CBUwRUngy0VcmaR93NvqduyZBKgppbTUy49tSdEn

@_date: 2002-07-30 11:10:02
@_author: James A. Donald 
@_subject: building a true RNG 
--
Randomness is of course indefinable.  A random oracle is however definable.  If SHA-1 is indistinguishable from a random oracle without prior
knowledge of the input, then we would like to prove that for an
attacker to make use of the loss of entropy that results from the
fact that it is not a random oracle, the attacker would be need to
be able to distinguish SHA-1 from a random oracle without prior
knowledge of the input.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     CxPM+cm8zcgy+aC2EA+wlmYH4DUaMzSLmaJFJN6v
     225C9EmZaK85VbOoLT5EpF24GeytUdtyW9T/FjXgw

@_date: 2002-07-30 20:51:24
@_author: James A. Donald 
@_subject: Challenge to David Wagner on TCPA 
--
They deny that intent, but physically they have that capability.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     ElmZA5NX6jAmhPu1EDT8Zl7D+IeQTSI/z1oo4lSn
     2qoSIC6KSr2LFLWyxZEETG/27dEy3yOWEnRtXzHy9

@_date: 2002-03-03 10:30:58
@_author: jamesd@echeque.com 
@_subject: Bernstein's NFS machine 
--
If I understand frog3's numbers correctly:
If one builds extraordinarily massive hardware capable of
dowing 53 billion simultaneous independent ECM
factorizations, Bernstein's method wil take 2^71 steps.
Assuming that the massively parallel hardware does fifty
billion factorizations each microsecond, then it will take Bernstein's super duper hardware about one hundred million
years to factor an RSA 1024 modulus.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     gUmxdOcDwV+bYp6vLC5uQ9yIX5x1ATUduCoSVKSp
     41JzVZfVEa6rS0tZag9ORqrngDwyHIZYriUomT6+w

@_date: 2002-11-06 23:57:22
@_author: James A. Donald 
@_subject: New Protection for 802.11 
--
Reading the Wifi report,
Fi_Protected_Access_Overview.pdf it seems their customers stampeded them and demanded that the
security hole be fixed, fixed a damned lot sooner than they
intended to fix it.
I am struck the contrast between the seemingly strong demand for wifi security, compared to the almost complete absence of demand for email security.
Why is it so?     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     IWe4JFeDeor04Pxb96ZsQ7xX+JAwxSs8HQfoAeG5
     4rQX6tgLhAvAwLjF+SXlRswSmphBhw4cOXLe9Y4r5

@_date: 2002-11-15 13:56:58
@_author: James A. Donald 
@_subject: Fwd: [fc] list of papers accepted to FC'03 
--
Theory of what could be implemented has run well ahead of what
has in fact been implemented.
This has doubtless reduced enthusiasm for the theory.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     XmqKAbnJ3zxWonUYjLQTEauIWVuczMy3fiZXjszK
     4BOXbFJHRJ+piLFRffQdmB84zd8OiOgRKr7wytw+r

@_date: 2002-09-21 18:43:13
@_author: James A. Donald 
@_subject: unforgeable optical tokens? 
--
Each piece of wood or parchment is also similarly unique.  The
knights templar used this for cheques.  The parchments in your
checkbook would have another half kept in the the temple, so
when a cheque was presented to the temple for payment, they
would compare the bits of parchment for a match.
The uniqueness of wood was, and probably still is, used for
signatures in Hong Kong.   You would mark the paper with a
wooden stamp, using a fingerprint like inking that showed the
grain of the wood.   This created a mark that was difficult to
Unfortunately, I do not yet see any applications for these
tokens that are as useful as the chequebooks of the knights
templar, or the stamps of Hong Kong, though perhaps some sharp
person will soon invent one.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     1zOSLvsmHrZmIaMMOQWUokjt+1GnFCdu2KnEXTYf
     4+Z4n1kFr3OElCX6pFomVfIwLoJinCHtNtns9yqjD

@_date: 2003-08-26 21:36:55
@_author: James A. Donald 
@_subject: blackmail / real world stego use 
--
Enzo Michelangeli
Freenet's almost realtime nature probably means the authorities
can figure out what you are browsing if they have universal
monitoring  However the potentially long delay between
publication and appearance means that freenet could, if
implemented correctly, prevent the authorities from knowing who
published what, even with universal monitoring, and even if
they did know who read what.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     HIFlk2xg8PcuQkPVphQIwlHu7paDKTZ7LIeE6d6f
     42WEQReKUM4YG5+yuVLp3ddu8GwoARZ/Yb9coUEfi

@_date: 2003-01-07 18:14:44
@_author: James A. Donald 
@_subject: DeCSS, crypto, law, and economics 
--
I pirate films routinely.  These are almost invariably films that I could not obtain in any other way.  The amount of time I spend watching films on my computer, and on television, is roughly comparable.
Similarly most of the music I listen to on my computer, I could
not readily purchase.  Stuff I can readily get through
commercial channels I do -- the convenience, rather than the
cost, is important to me.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     G6dKu0+L5GqnwO9+mBiUuQ4bgcPQWz7zc6hp0Ku0
     4lRkw8fWFbF5+wXCL7T1Xi9eLN/Z/LxSrOd5a5W1p

@_date: 2003-01-07 18:14:44
@_author: James A. Donald 
@_subject: DeCSS, crypto, law, and economics 
--
Situations often arise where government enforcement in
supporting the anti competitive desires of the company would
produce a more efficient result.
But when this happens, invariably the result is that the
company, being a concentrated interest, soon arranges to
receive a good deal more government enforcement of its desires
than is economically efficient.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     uytnfDL5wk7zyB1EE5/tKYXC0KzS6sXDK6/jxK07
     4SvjkuJx2a+3oxJKR0lkoulNU5XL8/gqJuBIxsI48

@_date: 2003-01-07 21:17:00
@_author: James A. Donald 
@_subject: DeCSS, crypto, law, and economics 
--
I wote:
 Correction.  I watch made for TV shows distributed through the
internet routinely.
Full length films are not shared to any great extent, because
their sheer size makes them such a pain.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     gUT7fZ6Trnc/9Kb/H1Fuuj0atdyZ+LqudqxXb84E
     4Wfqp3BAtgVYkqbEMsnlaP6ulQPgSL1YCQwZh8LlS

@_date: 2003-01-08 09:52:05
@_author: James A. Donald 
@_subject: DeCSS, crypto, law, and economics 
--
It is easy to imagine situations where some government
intervention will improve efficiency.   But who will lobby for
such interventions?
Of course, situations where government interventions will
create monopoly profits at the expense of considerable loss of
efficiency are far more common, and have lobby groups.
Thus whenever some clever economist claims to have discovered a
situation of the first kind, chances are it is a situation of
the second kind, thinly disguised.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     ycWZHQlgKti6MMd4J3O4W7WPmUH38C4yaakLV93r
     4w2zz8RnIPwcoBeYSdkQfFKWGB5DFqTtDR+iru6cQ

@_date: 2003-07-02 11:05:08
@_author: James A. Donald 
@_subject: New toy: SSLbar 
--
In practice, if people were able to ensure they saw the same
cert every time they hit what is purportedly the same site,
this would take out most scams.
Unfortunately, no one is going to memorize fingerprints.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     /3xr3PRIl9VwhL3ZVdM2Y6VIS/bUwun0l+Sxa7y8
     4q6X4YQoXr6QwwvNJ6wKw/ZRgH6Ssp7tpPgQD6rW/

@_date: 2003-06-03 15:04:54
@_author: James A. Donald 
@_subject: Maybe It's Snake Oil All the Way Down 
--
I never figured out how to use a certificate to authenticate a
client to a web server, how to make a web form available to one
client and not another.  Where do I start?
What I and everyone else does is use a shared secret, a
password stored on the server, whereby the otherwise anonymous
client gets authenticated, then gets an ephemeral cookie
identifying him..   I cannot seem to find any how-tos or
examples for anything better, whether for IIS or apache.
As a result we each have a large number of shared secret
passwords, whereby we each log into a large number of
webservers.  Was this what the people who created this protocol
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     Y/QLPHyeZqXrSgYZI9nQsjsk7krbgSGfCZ0BLpOt
     4gqWFWtV3GiEwWupSGyR895BQo0u2e4MmlgtpP/po

@_date: 2003-06-03 20:37:03
@_author: James A. Donald 
@_subject: Maybe It's Snake Oil All the Way Down 
--
Or to say the same thing in different words -- why can't HTTPS be more like SSH?    Why are we seeing a snow storm of scam
mails trying to get us to login to e-g0ld.com?     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     QtiFX0Q654gHh54NAMlLGE1FGDveixyzL0ZnAOVS
     4hprBkT1zeYk/HdBOXiquwvz5vLUwF/21wW1Jf411

@_date: 2003-06-04 16:25:28
@_author: James A. Donald 
@_subject: Maybe It's Snake Oil All the Way Down 
--
Everyone in America has several shared secrets identifying them

@_date: 2003-06-04 16:25:29
@_author: James A. Donald 
@_subject: Maybe It's Snake Oil All the Way Down 
--
James A. Donald
Eric Rescorla
In attempting to solve the hard problem, it fails to make
provision for solving the easy problem.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     bZy6QJLI0fL6IOhhS8lxNx/EUctBs0cj1se8YRt5
     4LvAbyVinp/3mbNkE+8/qx6UYDSxykTEFMpTXzsoD

@_date: 2003-06-04 19:09:31
@_author: James A. Donald 
@_subject: Micropayments finally taking off. 
--
Over the past ten years there have been many attempts to get a micropayment system working, all of which have failed dismally, leading to a widespread attitude that internet micropayments just do not work, and never will work.
In the past 24 hours, e-gold has done fifty thousand micropayments, of which thirty thousand were one milligram of gold or under (about one cent or under)   These are non anonymous, in that e-gold can link payer to payee, but anonymous in that it laborious to link e-gold account numbers to true names.
e-gold has no knowledge what they are being used for.  If they gathered that much information, it probably would not be worthwhile for their customers, but I would guess these are mostly per-click-through payments for ads. Some proportion of these payments must be e-gold's own referral scheme, but the majority have to be other people's schemes, perhaps other people's similar schemes.
The fact that e-gold does not know what is going on suggests that past attempts to support micropayments failed by putting too great a burden on those seeking to participate.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     bXT+Ssbr8YwqxmGU48nKVUNmy/V5W9MrCY8AJ1iu
     4JjvpESYIz/nh/OrZvLSSq8INjokq5UGC2eACxupI

@_date: 2003-06-04 19:09:31
@_author: James A. Donald 
@_subject: Maybe It's Snake Oil All the Way Down 
--
James A. Donald
Eric Rescorla
James A. Donald:
Eric Rescorla
Certificate caching is not the problem that needs solving.  The problem is all this spam attempting to fool people into logging in to fake BofA websites and fake e-gold websites, to steal their passwords or credit card numbers     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     /UOLlqGTeq9SAB5W/aJJuwULFBNMCVzKJnIRlhES
     48E3I0Yo+68OTvTwztxirTXc41yFVicJtskuBB/dU

@_date: 2003-06-06 16:24:44
@_author: James A. Donald 
@_subject: Maybe It's Snake Oil All the Way Down 
--
I don't think so.
Suppose the e-gold, to prevent this sea of spam trying to get
people to login to fake e-gold sites, wanted people to use
public keys instead of shared secrets, making your secret key
the instrument that controls the account instead of your shared
They could not do this using the standard IE webbrowser.  They
would have to get users to download a custom client, or at
least, like hushmail, a custom control inside IE.
HTTPS assumes that the certificate shall be blessed by the
administrator out of band, and has no mechanism for using a
private key to establish that a user is simply the same user as
last time.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     q1a1Whb1YeRws7qoDm6h15qfDstFHciUyP2I4fte
     42lCFXf0IqXfh5Mz2mFtznxv6N40EuqpKvQJhLBgS

@_date: 2003-06-06 17:24:55
@_author: James A. Donald 
@_subject: Maybe It's Snake Oil All the Way Down 
--
James A. Donald:
It is a hard problem with many well known solutions, none of
which have to my knowledge been implemented in HTTPS.  For
example one can use SPEKE, in which case setting up the account
involves sharing (or issuing) a password, but logging in to the
account does not require one to reveal the password to the site
where one is logging in.   In this case the fake website would
gain no useful information by luring the user to login to it.
The most HTTPS like solution would be to generate a keyfile
containing a self signed private key on one's computer, and
whenever one hit the website, it would do the HTTPS handshake
to log you in to that website's account for the public key
corresponding to your private key, however HTTPS does not seem
to directly support this model.   In this case the bogus web
site could log you in, but this would not leak any information
that would enable the operators of the bogus web site to login
to the real web site.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     /JhekrYM+sQCMQKXhiWzhB3RnOv6PZROgxYwprXj
     4LHJfuGlcn7fO4tcfo20/t0cdEy/HyK++XiBVvMFy

@_date: 2003-06-07 12:43:39
@_author: James A. Donald 
@_subject: Maybe It's Snake Oil All the Way Down 
--
James A. Donald:
That is a solution to a completely different problem.  Using that method the administrator would have to set up each client, which is impractically expensive and inconvenient unless administrator and customer meet personally and their computers are in the same office.
The point is that the customer should be able to set himself up, as he does on e-gold, hotmail, hushmail, etc, and that if subsequently he is fooled into logging on to a fake site this should do no harm.
James A. Donald:
You cannot use https to implement the trust model that hotmail and everyone else uses.  In that sense it does say something about the trust model.  It assumes they are subject to hierarchical validation, which e-gold passwords and hotmail passwords are not.
hotmail passwords merely show it is the same guy logging in. You cannot use https to do this.  It is designed to show it is the guy blessed by the administrator logging in.
Because that is not the trust model they or hotmail want to implement.   They don't want true names, and they do not want, and cannot afford, the very great overheads associated with true names.
To implement the desired trust model, the client browser would need to generate the private key during account creation. E-gold would then record the corresponding public key.   You cannot do that with existing client software.
They do not want to turn their business model upside down to support verisign's profit model.   The problem is to implement
the existing model in a way that protects against the man in
the middle attack represented by this storm of fake sites.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     OPeQMye27fygWs3rNrP88mXXiOYU+xcVrAyLlBjO
     4+rppNlgtCDm9YfF1Wiqe//vrDa3kdlXpzatLpbhm

@_date: 2003-06-07 12:43:39
@_author: James A. Donald 
@_subject: Maybe It's Snake Oil All the Way Down 
--
Precisely.  I am talking about direct substitution that should
be almost invisible to both parties, using private keys exactly
as passwords are used, except that the fake site trick fails.
In fact one can do a direct substitution that is almost
invisible to both parties, but it requires custom software on
both client and server.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     EWYCMfM1ZE4FqHNgG8Xxq4Raoo0u92HCJxUTm9d6
     4UkMVch4UVf7oFF6jEx+Nj5WJffMhrKnlz65qZyH1

@_date: 2003-06-07 13:50:19
@_author: James A. Donald 
@_subject: Maybe It's Snake Oil All the Way Down 
--
This sounds more like what I was looking for.
Probably someone has already pointed out the url to this, but if they did, I when I looked at it I was snowed under by verisign oriented shit, which assumes a large budget and ample administrator time for face to face contact with certified people, a very small number of clients, some hours of work by
each client, a manual, user training, etc, and failed to grasp
Could you point me somewhere that illustates server issued certs, certification with zero administrator overhead and small end user overhead?
Also, I have many times heard that public key operations were surprisingly easy, and have been key administrator for several companies, and have unfailingly found that I was the only person capable of doing these operations at that company.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     v6gZFuZoUgyGH55ME+JoilJSfw5LrufrbWWB454U
     4FhiB65yyXwp1RgeJrLADfEYBoqz0YAch8fJ0Fisp

@_date: 2003-06-08 11:55:20
@_author: James A. Donald 
@_subject: An attack on paypal 
Attached is a spam mail that constitutes an attack on paypal similar in effect and method to man in the middle.
The bottom line is that https just is not working.  Its broken.
The fact that people keep using shared secrets is a symptom of https not working.
The flaw in https is that you cannot operate the business and trust model using https that you can with shared secrets.
-------------- Enclosure number 1 ----------------
Received: from bgp480791bgs.summit01.nj.comcast.net [68.37.160.58] by dpmail07.doteasy.com
  (SMTPD32-7.13) id A3506CD006A; Sat, 07 Jun 2003 19:45:36 -0700

@_date: 2003-06-08 13:43:05
@_author: James A. Donald 
@_subject: The real problem that https has conspicuously failed to fix 
I keep posting "you cannot do this using https", and people keep replying "yes you can"
No you cannot, cause if you could, paypal, e-gold, e-bay, and the rest would not be suffering from the problem illustrated by scam mails such as the following
(When you hit the submit button, guess what happens)
      Dear PayPal Customer       This e-mail is the notification of recent innovations taken by PayPal to detect inactive customers and non-functioning mailboxes.
      The inactive customers are subject to restriction and removal in the next 3 months.
      Please confirm your email address and Credit or Check Card information using the form below:
            Email Address:
            Password:
            First Name:
            Last Name:
            ZIP:
            Credit or Check Card             Expiration Date:
            Month 01 02 03 04 05 06 07 08 09 10 11 12  /   Year 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012              ATM PIN:
      Information transmitted using 128bit SSL encryption.       Thanks for using PayPal!       This PayPal notification was sent to this email address because you are a Web Accept user and chose to receive the PayPal Periodical newsletter and Product Updates. To modify your notification preferences, go to  and log in to your account. Changes may take several days to be reflected in our mailings. Replies to this email will not be processed.        Copyright? 2003 PayPal Inc. All rights reserved. Designated trademarks and brands are the property of their respective owners.

@_date: 2003-06-10 12:32:55
@_author: James A. Donald 
@_subject: An attack on paypal 
--
Actually credit cards, and your bank, are flawed, as any porn site operator will tell you.
If people routinely conduct business by sharing secrets, they will tend to share secrets with the wrong people.   The solution, envisaged a long time ago, but not implemented successfully, is not to use shared secrets.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     z/jW5FTj5fTxewjBZmMh+hI7TPK07m0Wi/ugRB/p
     4o2DM1LcrAnzZHIYbECFoxfE1N1Ts2we2cISfJ8QL

@_date: 2003-06-10 12:32:55
@_author: James A. Donald 
@_subject: The real problem that https has conspicuously failed to fix 
--
 James A. Donald:
The example I posted did not rely on a misleading name, though most such scams do, and a misleading name greatly facilitates such scams.
If https made it possible to log on to a site without sending  the site a shared secret, that would help, because then end  users would be surprised and suspicious on being asked to send a shared secret.
And when I say "possible" I do not mean "possible if you send a hundred dollars per customer to verisign and your administrator spends an hour talking face to face with each customer and  fiddling with each customer's computer",
The problem is shared secrets.  Abolish shared secrets, nothing for the scam sites to steal.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     rx/Z2qIPQ5/w2m19Glalp9TuC97A9A0sAFlrm0JN
     4o44QKfLOBAAqjFsl04PeQ/0B05CLW3gCaS/b7lWq

@_date: 2003-06-10 15:31:41
@_author: James A. Donald 
@_subject: An attack on paypal 
--
https is like a strong fortress wall that only goes half way
around the fortress.
The most expensive and inconvenient part of https, getting
certificates from verisign, is fairly useless.
The useful part of https is that it has stopped password
sniffing from networks, but the PKI part, where the server, but
not the client, is supposedly authenticated, does not do much
good.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     9ZQw+0/xh1y28CkGulSQSVxewfy71qzXGHI8KJbN
     4osBv1veq07jaMVh2zVetZVKqIRfQjiwJaKu99GqM

@_date: 2003-06-10 15:31:41
@_author: James A. Donald 
@_subject: An attack on paypal 
--
How many attacks have there been based on automatic trust of
verisign's feckless ID checking?   Not many, possibly none.
That is not the weak point, not the point where the attacks
occur.   If the browser was set to accept self signed
certificates by default, it would make little difference to
A wide variety of ways of getting big name certificates that
one should not have, have been discovered.   Attackers never
showed much interest.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     uJuAm4Xwyo4xTn0ozjBmW2ZqpI8Z3ru25WDmB7iw
     43PXj2QDpBfcahqs2aOleapJYsqtA6S36+hOdVkpR

@_date: 2003-06-11 20:20:04
@_author: James A. Donald 
@_subject: The real problem that https has conspicuously failed to fix 
--
I think you have put your finger right on the problem.
Certificates, https, and the entire PKI structure were designed
for an accountless world, but the problem is accounts.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     DxVY4Z01oFU7xvn07JDMoJBGMxVLt61s4VcQTMLB
     4v46MbB1PtOjOaOcNvexHiyB1LzfD0RJ+CIPtD7RD

@_date: 2003-06-11 20:20:04
@_author: James A. Donald 
@_subject: The real problem that https has conspicuously failed to fix 
--
Well, this would work just great provided the browser was made
palladium aware in such a way as to be useful to the user,
rather than to verisign.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     VBdyipPLv5JzjJ0eIFxxeMDsO30Us9Mvs7lmm2ka
     4R5+YjVhKptjgGIVZsjTfX5nDogjTf2G8x7fRhKmN

@_date: 2003-06-12 13:34:59
@_author: James A. Donald 
@_subject: The real problem that https has conspicuously failed to fix 
--
If https provided an adequate substitute for shared secrets, it
would help.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     B9cEiIa9s5fvgr0BsmE3D3+BgvAXXvyF1/xSIi0k
     4m1RrAexqkSii4X39kqfzefd2laQEwFD0bhYHaELv

@_date: 2003-06-12 14:36:04
@_author: James A. Donald 
@_subject: An attack on paypal  
--
I don't think so.
Verisign's authentication is notoriously worthless and full of
holes, yet very few attacks have been based on getting
certificates issued to wrong party, or on stealing poorly
defended and readily accessible certificates, even though that
is quite easy to do.
One of the scams described in the paper you cite was the old
" scam, but done using paper, rather than the
internet -- the scammers registered a company name similar that
of a target  company owning a large block of IP addresses, and
printed letter head paper similar to that of the other company.
The problem was not that authentication was hard.  Passwords
would have sufficed.   Self signed public keys would have
worked even better.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     NoFj3E7m34BUCZIG2feG13OK1W+zx+gF7GsDX+Fm
     40IAMrSyeCwPFMzRybwYkgWLZ2JE97Ao595KgemVp

@_date: 2003-06-13 10:52:16
@_author: James A. Donald 
@_subject: Session Fixation Vulnerability in Web Based Apps 
--
 This flaw is massive, and the biggest villain is the server
side code created for Apache.
When you login to your bank, your e-gold account, your stockbroker, or your domain registrar, someone else can share your login.
It is a security design error in the development environments for active server pages (all of them) .  Every such development environment will have to be changed, and every login script written for existing environments needs to have some kind of workaround cobbled into it.
The ideal solution is to change the development environment so that your session identifier is linked to the shared symmetric key used in any https conversation during that session, which requires tight coupling of https and development environments for active server pages.
In the long term, https must be amended to have a concept of login and session, and make that sessionID available to the server side coding environments.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     SnDt+rS7QWjKfmo0bTes8RJ5F6sGgF/gULJmRunl
     4xIiGoxSbiGMryITmfRKr11XPrglqtpA2RWHUDI+p

@_date: 2003-06-13 15:17:56
@_author: James A. Donald 
@_subject: Session Fixation Vulnerability in Web Based Apps 
--
 "James A. Donald"
If https really had nothing to do with authentication or identity, that would be a very great flaw indeed.
The defect described by Steve Schear has the result that an https session has no direct equivalence to what the server code that accepts a password sees as a session.
Thus the real user can have one https session, and the attacker a different https session, and server side code may well think they are one and the same session, allowing the attacker to modify the target user's account while the target user is logged in.
To make the system entirely secure against this attack, we need to be able to enforce a one to one mapping between login sessions and https sessions.  The existing tools for writing server side code do not provide us with any direct means of enforcing such a relationship.
 Trouble is, that as Steve Schear has just demonstrated, it is
not a cone of silence.   The environments for writing server side code does not permit the server side code to know which https session a client request is coming from.  Thus the user logs in, and then the attacker sends a request from a completely different computer in a completely different https session, and the server side code will treat is as if it was a request from the user, enabling the attacker to do transactions on your bank account while you  are logged in to your bank.
The attack described Steve Schear does not involve giving away secrets.  Rather it relies on the fact that there  is no easy way for the server side code to enforce a one to  one mapping between login sessions and https sessions.  The  server accepts
an request from the attacker as if he was the currently logged
in end user, even though the attacker is in a completely
different https session.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     F02/E7jwR2ptvCs0wMAjvVQ3252ZqQj1v9IfOMUQ
     4SzwtxVqooT5OUw1MxnZaPDp5Hq7bikFt9LRlvk85

@_date: 2003-06-14 10:59:27
@_author: James A. Donald 
@_subject: Session Fixation Vulnerability in Web Based Apps 
--
Ben Laurie
In the development environments that I am familiar with, the
code environment assumes one is using a session cookie.  If you
are using a session cookie automatically generated by the
environment for state management, if you are using the state
management supplied by the development environment, this flaw
will bite you.
To avoid it, one has to roll one's own state management, for
example by providing one's own cryptographically strong login
label in the Urls in the web page one generates in response to
a login, the label acting as primary key to a table of
currently active logins.
How did you do your state management, and why did you do it the
way that you did?
For the environments that I am familiar with, if one did a
server side coding for a login in the way the environment was
designed to be used, that login code would be flawed.
I do not see how this flaw can be avoided unless one
consciously takes special measures that the development
environment is not designed or intended to support.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     kTr+tGmv2Tc7wtpF2vCQqPhk5dxOUN1yhHOu2VtM
     4uKcnZA607mHi4kFhb+yzpP4NHwUS/DukGoP89sdV

@_date: 2003-06-14 11:36:48
@_author: James A. Donald 
@_subject: Session Fixation Vulnerability in Web Based Apps 
--
Rich Salz:
As I said earlier, there is no strong enforceable relationship between an https session and a login session.
"This fortress wall not merely meets specifications, but is "But in only covers the north side of the fortress, and there is a gate in the middle that a child could kick down"
"The specification was for the north wall, and the gate is the responsibility of the supplies and transport division"     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     HbAVQDehUS8SgfQqOI28BdF348siCWO9xi9Ep226
     4yrN59HvscIQo8lQ44oxphi77XJ3ssx4FJUG6y2yd

@_date: 2003-06-14 15:45:47
@_author: James A. Donald 
@_subject: Session Fixation Vulnerability in Web Based Apps 
--
I had dreamed up some rathe complicated solutions.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     ocf99Mr7YN0oLlYWkZsE57yUHWMocE0Z+gK2yQOU
     4RiX1d4bEHzLkunxq2FfwXmWFdySguhagGnZR4U7X

@_date: 2003-06-15 11:34:55
@_author: James A. Donald 
@_subject: Session Fixation Vulnerability in Web Based Apps 
--
Which is fine provided your code, rather than the framework
code provided the cookie, and provided you generated the cookie
in response to a valid login, as Ben Laurie does..   The framework, however, generally provides insecure cookies.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     hOTy2gXIGpC8U37+/qzVoX8ytaUtHZWZGueU4kX5
     4GiXuHCpc1B85Pv2WN8p5d7FESFJMHlg5qC2hqlGr

@_date: 2003-06-16 09:51:39
@_author: James A. Donald 
@_subject: Session Fixation Vulnerability in Web Based Apps 
--
James A. Donald:
Ng Pheng Siong:
The word "environment", like "framework" is overloaded.   I had in mind such frameworks as PHP, struts, and ASP.   mod_perl makes you do your own damn cookie management as far as I know,
and so would not in itself cause the session fixation problem,
though programmer error might very easily cause it.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     M2QqNF3SbBJ8ZBL5r77vtVp17bYimpkgCZWrCRxA
     4YMBoFimaPGsULDLow0LdwGBbNKGNfrlCjIFpMfYa

@_date: 2003-05-14 00:24:42
@_author: James A. Donald 
@_subject: economics of spam (Re: A Trial Balloon to Ban Email?) 
--
 Assuming that a CPU
costs $500 and that its value can be amortized over 2 years,
CPU costs .0016 cents/second.
To say the same thing in different words, the spammer's
unattended computer costs 0.0016cents per second, the non
spammer's computer is worth about 0.5cents per second, because
there is an impatient user sitting there waiting for the mail
to complete.
Thus the non spammer's computer time costs approximately four
hundred times as much as the spammer's computer time.
We have to use a form of cash that is similarly valuable for
spammers and non spammers.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     QLQau7uADLb/zG+C/w+cIuiW5I9NSD4m6LNPbwYK
     4zNtefDWUbC4Pp6JJTh53TS6UPtqXu/hY1EPp5PPv

@_date: 2003-05-14 00:24:42
@_author: James A. Donald 
@_subject: A Trial Balloon to Ban Email? 
--
Recipients whitelist the mailing list, or better still its
digital signature.   Mailing list operator collects the
micropayments on submissions.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     Xk9R3hEjL27Vh4JwzxHMmoB1TfEiftAXvdhzpKyb
     4fEwddb+ZTQFP9ep7mGzY5moueUOD0FeCIlksgaM6

@_date: 2003-05-17 16:45:56
@_author: James A. Donald 
@_subject: Payments as an answer to spam 
--
Filtering on the from line would be somewhat effective, as the
spammer does not know who is on your white list.  To really
bullet proof it, you would want to white list the sender's
public key.
(This does not require public key infrastructure, which costs
about one hundred dollars per seat per year.)
Ideally one would support both white listing on the "from" and
white listing on the unauthenticated public key.  White listing
on authenticated public keys would be too costly and
inconvenient.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     AXCWftLjRR5FVGhESYJ55jh+4IrHVYrf9+9aR7WB
     4h6CYZupzEIIiVAIt69gw0ZltToh8aqw2PLM3kGyI

@_date: 2003-05-17 16:45:56
@_author: James A. Donald 
@_subject: Payments as an answer to spam 
--
All of these approaches are compatible with each other, so all
should be used.  When someone is trying to pull your pants
down, need, belt, braces and sturdy underwear.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     Qrbn8m9ZkP7E++EzIYsrhs2pu4ZSWff2a3dIpX9C
     4nsnjxfj12qaJT+ZkIFPk/lyBpRF9nq6rAfRCrGer

@_date: 2003-05-17 16:45:56
@_author: James A. Donald 
@_subject: economics of spam (Re: A Trial Balloon to Ban Email?) 
--
We know how to implement micropayments.
What we do not know is profitability, user interface models,
and how to avoid being sent to jail by the banking cartel.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     ShZFONxSwrw7NAe8OEvORULseRo8KRcmgfYJuVUS
     4k9zrqFRv3pqgv9Wsr7BJrP01nuy033BGnaH8k+na

@_date: 2003-09-02 23:28:31
@_author: James A. Donald 
@_subject: invoicing with PKI 
--
This of course enormously dwarfs the use of PKI certificates. Why?  Because an SSH server uses its public key to prove
continuity of identity, rather than true names, and this is lot
easier than true names.
Outlook and outlook express support digital signing and encryption -- but one must first get a certificate.
So I go to Thawte to get my free certificate, and find that Thawte is making an alarmingly great effort to link certificates with true name information, and with the beast number that your government has assigned to you, which imposes large costs both on Thawte, and on the person seeking the certificate, and also has the highly undesirable effect that using these certificates causes major loss of privacy, by enabling true name and beast number contact tracing of people using encryption.
Now what I want is a certificate that merely asserts that the holder of the certificate can receive email at such and such an address, and that only one such certificate has been issued for that address.  Such a certification system has very low costs for issuer and recipient, and because it is a nym certificate, no loss of privacy.
Is there any web page set up to automatically issue such The certs that IE and outlook express accept oddly do not seem to have any provision for defining what the certificate This seems a curious and drastic omission from a certificate Since there is no provision to define what a certificate certifies, one could argue that any certification authority that certifies anything other than a true name connected to a state issued id number, the number of the beast, is guilty of fraud.  This would seem to disturbingly limit the usefulness and application of such certificates.  It also, as anyone who tries to get a free certificate from Thawte will discover, makes it difficult, expensive, and inconvenient to get     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     id/UsYl2xTf9Mswn+zhPXu3gZK4Hx7RMoDuc1LXZ
     4TEx1/ENp2au248aS2r/SqmAc7NKT8yzMwGTk3dOK

@_date: 2003-09-02 23:41:14
@_author: James A. Donald 
@_subject: invoicing with PKI 
--
True names is where security took the wrong branch.  The entire
PKI structure has been rejected.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     23+XuDK7JTGYW75W2R6MyD+V56OpgktSnYqZ4GBT
     4OFVh0w6Cykrd+ETKSZ7D+1zB0+KUqjBmSgIFnmsG

@_date: 2003-09-07 12:30:22
@_author: James A. Donald 
@_subject: Is cryptography where security took the wrong branch? 
--
To the extent that trust information is centrally handled, as it is handled by browsers, it will tend to be applied in ways that benefit the state and the central authority.  Observe for example that today all individual certificates must be linked to one's true name and social security number if it is to receive default acceptance, and analogously for corporate To the extent that trust information is decentralized in end user databases, as it is handled by SSH clients it will tend to be applied in ways that benefit the end user.
Unsurprisingly, we observe greater end user utilization of SSH public keys.   The vast majority of people encounter the concept of a public key when they log on to an SSH server.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     +VOl3Vqd/2KPdwuRgmR7CoTexKy84DdSChLXr3rS
     4WcxJQwYP0cvPgTXK3Xq5OaTtELGHKXqra0DHd90x

@_date: 2003-09-07 20:42:17
@_author: James A. Donald 
@_subject: Is cryptography where security took the wrong branch? 
--
I seem to recollect that request, or a request very like it,
from some years back.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     HwFde4LnTv0p3hXtAQB7k2SuW04BmKJDrrnyzvRr
     4d+oWUHfpousTBWRKiFyUmAecGZRIK1gitZ4NELNp

@_date: 2003-09-11 22:59:43
@_author: James A. Donald 
@_subject: Anyone Remember Zero Knowledge Systems? 
--
Freenet and frost are already doing this.
If the music companies continue to try to hold back the tide,
this may be the best thing yet for encryption.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     vpu+9/zR0VeZ9yrq0tX02mDo/qom+zk9HNCpvzBg
     4Rh7IsRRuJOCzDjntfegD+tPUHk1v3tChnWdvMo2f

@_date: 2004-12-07 15:57:38
@_author: James A. Donald 
@_subject: MD5 To Be Considered Harmful Someday 
--
This seems pretty harmful right now, no need to wait for But even back when I implemented Crypto Kong, the orthodoxy was that one should use SHA1, even though it is slower than MD5, so it seems to me that MD5 was considered harmful back in 1997, though I did not know why at the time, and perhaps no one knew     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     bEcutcm49V2l4gs02N+hlx0RuvlNCxolYqbHGLNY
     4kL6H698sHcon3pASMijUxPq4KE3Se5Mp7xNpDH7r

@_date: 2004-12-12 19:45:10
@_author: James A. Donald 
@_subject: Blinky Rides Again: RCMP suspect al-Qaida messages 
--
I have used stego for practical purposes.  The great advantage
of stego is that it conceals your threat model.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     aV25L9tGoz00uU3bzcY+rbFDV5nX9BCkK67CRwcd
     4mBXnVakFBPiPRCdugeDolUdtnd8iueWgYFwR3Pch

@_date: 2004-12-15 12:13:08
@_author: James A. Donald 
@_subject: The Pointlessness of the MD5 "attacks" 
--
I could circulate watermarked versions of copyrighted material
without it being apparent that they were watermarked.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     brRAUUDlwL/ZhPKf51gh0pzlr6ISDbBPNAbnzJfI
     41Hx46udB9H+g9Lkm68G20fQMC+F6YzLxJhmwuZu4

@_date: 2004-10-20 11:30:10
@_author: James A. Donald 
@_subject: Financial identity is *dangerous*? (was re: Fake companies, real money) 
--
To clarify, EvoCash was subjected to DDoS attacks, and persistent attack upon its reputation, both of these seemingly originating from the operator of a ponzi scheme, presumably for the purposes of extortion.
What machine, attached to a network, using a web browser, and sending and receiving mail, would you trust?     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     hrZ6lTrAZYICXnGqF8vLx7tZ1wcjKkoF7d/jKJbF
     4WFPME/Dy9Losvs1g9ZsxwxI0oIYThq0dwJCNpLX9

@_date: 2004-10-28 09:29:21
@_author: James A. Donald 
@_subject: Financial identity is *dangerous*? (was re: Fake companies, real money) 
--
Is there a phone that is programmable enough to store secrets on and sign and decrypt stuff?
The ideal crypto device would be programmed by burning new proms, thus enabling easy reprogramming, while making it resistant to trojans and viruses.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     Fkc1LRTOk91ROlSR8FZ74DmqbH7hISIn+MSojROa
     4nrRtvxhCmqe2NdvICprDQBO78fHoQXljK45ROM2W

@_date: 2005-04-08 15:13:29
@_author: James A. Donald 
@_subject: How secure is the ATA encrypted disk? 
--
Every ATA disk contains encryption firmware, though not all bioses allow you to use it.
There is a master and a user password, 32 bytes each. If you set them both to the same value, and that value is a strong 32 byte password, then the disk can only be booted or accessed by entering that password.
This disk firmware is what password protected laptops use.  It exists on most PCs, though most of them have no bios firmware to use it.
How strong is this standard - could someone bypass it by taking a soldering iron to the disk?  Is the disk
encrypted, or just the datapath to the disk?     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     MWz38lml3/o9dkGLtWtJQZ1tp0gyiyL5eFG9bY/j
     4tFQd7DIdLt5X6V438CPm2mQIV4/O2PZST9PN9sAM

@_date: 2005-04-30 06:56:59
@_author: James A. Donald 
@_subject: [Lucrative-L] double spends, identity agnosticism, and Lucrative 
Since the patent expires shortly, the legal reason for identity agnostic cash has expired.  Today, if you don't want the overheads of tracking your customers, the solution is that you can refrain from tracking your customers.
Whatever happened to Lucky Green's patent party - I keep sending him emails, get no response.

@_date: 2005-08-03 15:15:00
@_author: James A. Donald 
@_subject: Cross logins 
--
Is it possible for two web sites to arrange for cross The goal is that if someone is logged into website  as user127, and then browses to  he will be automatically logged in on b.com as user127 at A.com
Inventing a protocol off the spur of the moment, and the seat of my pants, which is a good way to get shot down in flames, the B.com web page would access a resource whose url is the on A.com web site, the url containing a representation of the browser's current B.com cookie. User127's browser would access that resource, sending the A.com cookie,  the A.com web site would then signal B.com that the browser with that B.com cookie is currently logged into A.com as user127
One obvious flaw in this scheme is that *automatic* login leaks information - users can be logged in without them knowing it.
So another solution is that the B.com login link is actually a link to the A.com web site, with a transient public key encoded in the url.   A.com looks at the referring url, and tells user " wants to identify you as an A.com subscriber.  Do you want to login to  as user127 at a.com?"  If user says yes, then A.com sends his browser a redirect to B.com with an encrypted message in the URL to B.com saying "This guy is user127 at A.com".  To avoid replay attacks, public key should change every time - public key should change with the browser cookie used by B.com     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     kwlCI6Mq0EaMdsYIBsG4HSSU/4ClkoGzJaqI/la0
     4fWyITvZRCkgtoqZc3tjKLElzZH7CStTwrq8OxcvR

@_date: 2005-08-04 16:35:33
@_author: James A. Donald 
@_subject: Cross logins 
--
James A. Donald
Steve Furlong
The situation envisaged is that A.com is known to B.com,
and trusted by them, but B.com is unknown to A.com.
The context is that I observe in existing internet
currencies a lot of remarkably clumsy procedures to
verify that X is the rightful account holder of account
Y.   Typically the web site that you are trying to
register with will make a microspend to your account,
and you then have to demonstrate knowledge of that
It is apparent that tools to facilitate transactions
need to be integrated with nym management software and
reputation management software.
This was discussed long ago, back in the days of the
extropian list, even before the cypherpunks lis, but
though a decade has passed, such an integrated tool set
does not yet exist.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     YrtMBO44wxxM/nfE5hCE0yaIbuhetu6o+aOu+A3/
     4RIHu0PHIJAOz2EHYlgoyDbkJ12edbzWDPGlDCJy7

@_date: 2005-08-12 09:44:19
@_author: James A. Donald 
@_subject: [Clips] The summer of PKI love 
--
If the token has no user interface, or minimal user
interface, and the mobile user uses the token to log on
to a corrupted computer, then the adversary has control
of the token, even though the rightful user retains
physical control of the token.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     k8jT9lI+qnD2l9zmgoEnD1dREI6nEAq21MKjTBy2
     4l82lryIH7nTP4rjhCMmKYcuZkd3xQSd8Mtpt1S8d

@_date: 2005-08-12 09:54:29
@_author: James A. Donald 
@_subject: The summer of PKI love 
--
PKI's deployment to identify ssl servers is near one
hundred percent.  PKI's deployment to sign and secure
email, and to identify users, is near zero and seems
unlikely to change.  PGP has substantially superior
penetration.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     5l+2/VgKKsZ7L2MtEJUMxtB3jqOuld2RYZgm3QcV
     4HS67bQDIU6jSwHy8CH7u3qvqnY5XGqLUbRMG5mgy

@_date: 2005-08-28 19:32:25
@_author: James A. Donald 
@_subject: Another entry in the internet security hall of shame.... 
--
That horse is dead.  It is not going into common usage.
SSL works in practice, X509 with CA certs does not work in practice.  People have been bullied into using it by their browsers, but it does not give the protection intended, because people do what is necessary to avoid being nagged by browsers, not what is necessary to be secure.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     mQ0rM7wYdVTuoeMRUcrpDc1V9pUqhEgUmJMtyCZZ
     469u1yKDDCKWaUWwU/LYyE/7CVNRZV7OjXCs+Kyyc

@_date: 2005-08-29 18:35:52
@_author: James A. Donald 
@_subject: Another entry in the internet security hall of shame.... 
--
This will take out 90% of phishing spam, when widely
We also need support for measures of key persistance,
like trustbar, but there seems to be lot of resistance
to this, for no reason I understand.
In its current incarnation, trustbar takes up too damn
much real estate, and requires too much manual support.
We need a less obtrusive key persistance measure.
Petname is less obstrusive, and requires less manual
support, but still too much.  The trustbar logos are the
way to go, and logos of about that size are becoming a
standard feature of web pages.  If it could look as cool
as trustbar, while needing even less manual intervention
Petname ....
Also petnames need to be linked to favorites.  When you
are on a site that is on your favorites list, you should
see that it is on your favorites list.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     /RwA4zRnu4D2L0mSgGcsMv2Z3UGRcRDZnsqwkzh0
     4QVXdCrfQfW0WLkPqTvEk16BxjqokNWgRWZOOTahd

@_date: 2005-08-31 10:08:08
@_author: James A. Donald 
@_subject: Another entry in the internet security hall of shame.... 
But does not, in fact, prevent.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     9DcDsP364D9PAHlb9SrTA4By8bWsJWYZxs8ZH9xB
     4cQSP1xXUj2reoZ2icPXcJbFjGP6wBWfZQO13feDH

@_date: 2005-12-07 08:40:33
@_author: James A. Donald 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
--
We can, and should, compare any system with the attacks that are made upon it.   As a boat should resist every probable storm, and if it does not it is a bad boat, an encryption system should resist every real threat, and if it does not it is a bad encryption system.   And no blaming the users.  An encryption system must accommodate the user, not the user the system.
Problem 1:  The primary weakness of existent email is its vulnerability to after the fact investigations.
Problem 2: The secondary weakness is ease of forgery. So
far spammers are not making much effort to forge their
way through your white lists, but phishers are forging
the identities of organization's with which you are
likely to have relationships.
Most efforts have been directed at problem 2, but the true names approach as failed for web sites, and it is too burdensome for people even to try for email
The user interface has to be a web page button "Please click here to us to send, and you to whitelist, our emails about blah blah "   User clicks.  Browser Chrome pops up.   "Will you white list emails signed by public key     YJQwlHzIzHP7nm04t3CFcrjFlMY, apparently controlled by website  common name Bank of Adelaide, current favorite name
proposed petname banks/Bank of Adelaide - Home -
The spam filter has to pop up THE EXACT SAME BROWER CHROME, when the user tells it to whitelist a signed email that has been wrongly spam filtered.
Crap with certificate authorities or web of trust just is not flying, and is not going to fly.
But, of course, the really serious attack is problem 1, the problem that there are too damn many copies of email floating around, due to sending it in the clear and the store and forward architecture, which has got lots of people into really deep trouble.
The only copies should be those that the sender, and the receiver, choose to keep, and they should be encrypted with the user's email passphrase, the user's email passphrase should be known only to the client, not to the server, and the user's passphrase should have all the usual strengthening to minimize the effectiveness of
offline dictionary attack.  To limit the number of
possible copies, email should be sent by a direct
connection from the client to the recipient mail server,
rather than this store and forward crap.
Of course this is not email as we know it.  It is a new and wholly incompatible protocol, which can be transparently gatewayed to email as we know it.      --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     EHhbMLsVYHKM99sSClQYV0/o/XVA5PN4UrXpsU0v
     4ca9QRhhmxSqwOK6ef12X8jbDKTR/AMD0r8RQzn9j

@_date: 2005-12-07 22:24:04
@_author: James A. Donald 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
--
James A. Donald:
Aram Perez
Software is cheaper than boats - the poorest man can
afford the strongest encryption, but he cannot afford
the strongest boat.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     /RDdl4GaftLppriBOAhXkSmzUWuV9JdpELHaG+Yq
     4IZIPBnHPpNQYioKOhKdPdh6q6NwgwGDlLnbikvmA

@_date: 2005-12-08 00:24:35
@_author: James A. Donald 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
--
Many users are already using MUAs that check signatures.
Why are phishing targets not already using signed mail? I conjecture that this is because true names don't really address the issue of true relationships.  Does anyone have any market research information as to why phishing targets generally send out plain mail?
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     CMjwBMx17XqegWEl4z+ZLdfTB+wFlQKrdm1516HH
     4/HqDwhTaKRygswyOmR+oP41kfEhib7KJwyxDDq3p

@_date: 2005-12-08 19:04:59
@_author: James A. Donald 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
--
However, the main point of attack is phishing, when an
outsider attempts to interpose himself, the man in the
middle, into an existing relationship between two people
that know and trust each other.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     FYVMooN6NmFglw4lbAf5aNMCV9JMCU/ozMfXJMgI
     4WWQ2pQAOpm3Ttro+Ga5AcJIyW4/gefQzmeVWEsPN

@_date: 2005-12-08 19:15:07
@_author: James A. Donald 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
--
James A. Donald:
Aram Perez
James A. Donald:
Aram Perez
Design is not cheap, and in particular cryptographic design is not cheap, because one has to see what attacks eventuate - one commonly discovers that one's
cryptography was fine, but one's threat model was
inadequate.  But having been designed, and survived attack, it can then be supplied to everyone.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     J0TlTGnN72O7gpg1XX5GRDTi4nJ4wVeAa557yccN
     44MC72QwGhBFeTainKp+spi3G6oGpfuNsPZYDSpwt

@_date: 2005-12-11 07:48:23
@_author: James A. Donald 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
--
Anne & Lynn Wheeler This was the scenario envisaged when PKI was created,
but I don't see it happening, and in fact attempting to
do so using existing user interfaces is painful.  They
don't seem designed to do this.
My product, Crypto Kong,  was
designed to directly support this scenario in a more
convenient fashion - it keeps a database of past
communications and their associated keys, but there did
not seem to be a lot of interest.   I could have made it
more useful, given it more capabilities, but I felt I
was missing the point     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     4ostZwIWJbNX6/eRYYX4QMLG5GGNUaPJao5ZKKGB
     4Bt20kCp2fkd6wgjBDjYMz5ZqUEnTYL4O3aTalDOB

@_date: 2005-12-11 09:49:05
@_author: James A. Donald 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
--
And, since her bank and ebay are under massive attack  from phishers, and your mother, if she is using any of  the common email clients is using a cryptographically  enabled mail agent, why don't they sign their email?  This is exactly the attack that PKI was designed to  My possibly biased answer to this question, based on my past job as key keeper for two companies, would be that not only can your mother not sign her stuff with PKI,  but the chairman of the board finds it even harder.
Does anyone else have war stories on this issue?
Just as big companies find it hard to write software  that does not open their servers to a cross scripting  attack, and hard to interact with their users in ways  that do not train their users to respond to phishing  attacks, and hard to write server side software that  does not rely on the behavior of client side forms, they also find it hard to sign their email.
In the unlikely event that my mother is threatened by  man in the middle attacks, she will allow me to set up  secret key on her computer, and will follow my  instructions on how to use it, but the chairman of the  board will not, nor will the marketing department.
That is my experience - does anyone else have any  experience that differs from this, or confirms this?
And before we sneer at the chairman of the board - hands up all programmers who failed to client and server side disable all past cookies and issue new https and http  cookies on receiving a valid login, and all programmers who failed to enumerate and sterilize all fields  appearing in any response.
It is not my position that inability to sign means that the chairman of the board is stupid.  It is that  cryptographic signatures are too @ hard and need to be made user friendly.
First write software that is easy enough for your mother.  Then we can work on making it easy enough for the marketing department.      --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     gvDLBPaNQFZ3Y0yhzmO2KnYEKGolt9E+eey2rPxE
     4bGpW6AUGiMGbJFzaXJ8QcBY0HMhbypcque+5LrMd

@_date: 2005-12-11 10:19:21
@_author: James A. Donald 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
--
Usability is the key part of perfomance.
Amazon is sending out unsigned emails.  Seems to me this is in part because they find it hard to sign anything, in part because if they did sign something I doubt it would do the end user much good, since the end user is already suffering from name overload, and is unlikely to appreciate the difference between a signature belonging to amazon.com, amazon.co.uk, and amazon.jim.com
We really need to start from the user, and look for ways in which the user's mental model of security can be used to defeat realistic threats.      --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     b5RoNWK+PD+pn6rk1lBkzIqv8T4ntwUO6CxDoPtA
     48yzird9uDuNNK+xU0XcZisSug3K2XHzHu0MXgwqB

@_date: 2005-12-11 11:22:52
@_author: James A. Donald 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
--
I would state the same thing differently:  That the revenue model is based on sprinkling holy water over communications, rather than actually providing security.
Hence the proposal to address phishing by providing higher priced grades of holy water.
Public keys are relevant to the problem of decentralized reputation management.  For relationship management, shared secrets are better.   At present, the only widely applied reputation management software is that possessed by Ebay - which uses centralized reputation management software, so that it can charge people a fee for making use of their own reputations, and thus has no inherent need or desire for public keys.
After all these years, we still do not have a good fit between the capabilities of the technology, the usability of the interface, and the problems people need solved.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     X1okruQ3BE+qbWjk1b7CgXMbsiKNhvf5oMKDgR71
     4cxizGKqHfxeifgKTUEvpkLYq7wSgzAckTy2yLzQ8

@_date: 2005-12-12 07:43:21
@_author: James A. Donald 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
--
But the key owner is always online, for in practice,
certs are always used for https.
Arguably we should be using not-necessarily-online certs
to sign email, but the email that arguably needs
signing, for example emails from amazon.com, are never
The only reason this email is signed is to make a point
about technology, not because the signature serves any
useful purpose.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     ca4N69sv32Q/plWYe5BnvcydTDFaMVJkZ0rPbVp6
     4CRaaWK8UP3bCPHDbDzuPW7zEKImu5L9x7RUMIrbG

@_date: 2005-12-12 09:34:10
@_author: James A. Donald 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
--
This sounds like "it is not my fault.  It is those stupid user's fault"
No, it is not those stupid user's fault.  It is our
fault.  For example phishing ought not to be possible -
would not be possible if we used zero knowledge
technologies to protect passwords.
Whenever a user communicates anything to anyone, they use a password, or some form of shared secret - their credit card number - the password whereby they login to their mail server. Therefore, whenever a user communicates anything to anyone, it should be secure, but it is not.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     Jogksi+CFTLv6yHXLYAd6VeQz73gNHYNM1t/B6aB
     4uVe9+oTO/DP7awisj6RYpMbzekGf0+UrwxWfnpxM

@_date: 2005-12-12 10:08:42
@_author: James A. Donald 
@_subject: crypto for the average programmer 
Date sent:      	Mon, 12 Dec 2005 00:41:13 -0600
It seems to me that if the only thing you use public key encryption for is to encrypt a single use randomly chosen symmetric key, and integrity bits for that key, and if you then use that symmetric key once and only once, to encrypt a message that already contains integrity checking and a unique random number, you don't need to worry about those issues.
Of course those issues reappear when using public keys for signature algorithms - so don't invent your own signature protocol.  Signatures are hard.

@_date: 2005-12-12 10:18:48
@_author: James A. Donald 
@_subject: crypto for the average programmer 
--
Of course most of this has already been incorporated in standard crypto libraries, such as CryptoPP, and does not need to be rewritten.
Be warned, however, that if you faithfully follow a standard without comprehending why the standard is the way that it is, you will probably screw it up, because you will not really understand what faithfullness is.
In practice, it is frequently necessary to roll your own damned standards, and in practice, people who roll their own damned standard frequently get them wrong.  For example SSH had to be SSH, it could not be SSL, and the first version of SSH was, predictably, wrong.  Similarly the first version of Wifi used WEP, which contained errors that should have been spotted, but were not. They
had to roll their own, because they needed to solve a
particular problem which was not the same as the problems that other standards solve.
You should, however, never roll your own damned standard
without good reason.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     TXXgVeLZjViyf6+f7NQt7WCs7MzxO/j25GYLXcEg
     4js14nleizkni3mC38n+4rk2r07+4mylYuP2+UnlI

@_date: 2005-12-15 11:36:26
@_author: James A. Donald 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
--
"Clarifying the trust model" sounds suspiciously like
designers telling customers to conform to designer
procedures.  This has not had much success in the past.
People using PGP in practice verify keys out of band,
not through web of trust.
People using https tend to click through.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     9zzvV5qgyWeB4uTJn5vTjFtKeouMk46hiM0EN7Q+
     4CKg4nhwvcBjl855xVUXY5XMP46ZdvXoOl8Wu0Hyb

@_date: 2005-12-16 12:56:29
@_author: James A. Donald 
@_subject: Crypto and UI issues 
--
But in what it is it broken?
Let us imagine that SSH had certified keys.  Well, certifying a key is bound to be complicated, and things are bound to go wrong, and the name that you bind it to is bound to be somewhat shifty.  You might bind the key to ben.com, but then your host is ssh.ben.com.  So pretty soon users are frequently seeing error dialogs - and so, pretty soon, are always clicking through them.
What is a true name is a deep and difficult question, and one that people have little patience for when trying to log in.  We are overloaded with names, with the result that true names are of limited value in ascertaining true relationships.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     Ot8xxQDU9pyVndHTn5kzTOr2CRK60LeWklc4NDLR
     4M3vcDbhvr3PhPb10v1p7VO47zgc7ubuUbnhrhoXa

@_date: 2005-12-17 21:12:11
@_author: James A. Donald 
@_subject: Crypto and UI issues 
--
"James A. Donald"
Ben Laurie
It would happen at least as much as it happens with https, and it happens enough with https that false negatives enormously outweigh true negatives.
"James A. Donald"
Ben Laurie
An expert will reflexively click through a dialog that is almost certainly a false negative.
but is the host with the true name the entity you have a relationship with?
My two most recent logins were with "First National Bank
of Omaha" and "Your IBM Savings plan"
Is "firstnational.com" the same entity as "First National Bank of Omaha"?   Is " the same entity as "Your IBM Savings plan"
Knowing that I was really and truly connecting to lb22.resources.hewitt.com was not in fact much use at all.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     ez1z37eet0cWwVrNwfCbMCbdIdZ54HnhIA7QnrSN
     42IqI9qTDHV9RRUioTTrs3I0W7eyY9zOvBjKSSInB

@_date: 2005-12-18 09:47:27
@_author: James A. Donald 
@_subject: browser vendors and CAs agreeing on high-assurance certificates 
--
Typical marketing bullshit.
Has anyone been attacked through a certificate that would not have been issued under stricter security?  The article does not mention any such attacks, nor have I
ever heard of such an attack.
If no attacks, this is just an excuse for higher priced holy water, an attempt to alter the Browser interface to increase revenue, not increase security - to solve the CA's problem, not solve the user's problem.      --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     9gZDh7SzUIydFOkZcwjeTnkd9RZt8ug2ixc7jGCB
     4m7NXA50DZoZI3WxvI4Fh8+c0l0CG/6GYiqtrMek7

@_date: 2005-12-18 10:06:10
@_author: James A. Donald 
@_subject: browser vendors and CAs agreeing on high-assurance certificates  
--
And would they not have had a high assurance
certificate, since presumably they really were
Even if the vendors do implement a policy that all new
urls must be significantly different from known high
value urls, which is not their stated policy, this is
not going to help much with such high value urls as:
Proving true names is not much help, because there are
too many names.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     CS4AkcyJ2ZhuZtOouD5yH0AnqodmyrqySuYZgRXQ
     4Y1XkuPvMRrV9M2owdKcEoRRGZzIuxUqEcgxLcPX7

@_date: 2005-12-18 20:32:19
@_author: James A. Donald 
@_subject: Crypto and UI issues 
--
James A. Donald:
Why is this odd?
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     vIiB5l+AqD0zb/5Uiman/czZN39B7m4WH2QZpIfO
     4x4N9LBAgWjrHU1VbWgwgVV103Si9OgUB9fjKdpou

@_date: 2005-12-21 18:57:33
@_author: James A. Donald 
@_subject: browser vendors and CAs agreeing on high-assurance certificates 
--
Peter Gutmann
But is what they are doing wrong?
To solve the phishing problem (man in the middle attack) using certificates, not only must users become alarmed on encountering no certificate or a defective certificate, but businesses that may be potentially phished must faithfully and regularly employ certificates, which they do not consistently do, and faithfully and regularly sign their mail, which they almost never do, and must, like google or paypal, use a single user memorable brandnamed root to their domain names, which the new internet businessess generally do, for example "skype.com", but pre internet businesses generally do not do.  Further, businesses must fix all their servers so that redirects and the like are immune to cross scripting attacks and do full server side checking of all user input data, and must never solicit users to click on links that are full of large amounts of hidden gibberish.  Further email clients should never
allow a clickable post link within email, though at
present all of them do.
Since most businesses are not doing any of that, there is little incentive for even the most sophisticated user to worry too much about certificates.
Further, even if all the businesses start doing the right thing, we will never succeed in explaining to users that  is safe while  is unsafe.      --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     7lvFKmh9CI9ZQfYIy78zI4N2dRYic3ejlTGQRoao
     4R5oEEaOy/wO1wELCYESt8HByRqNhqN5UjF6Br4c3

@_date: 2005-12-24 15:48:42
@_author: James A. Donald 
@_subject: RNG quality verification 
--
Randomness is necessarily theory laden.  To determine what is good, and what is bad, you have to look inside the software.
Software should get its randomness from dev/random, or from similarly open sources of randomness, so that the source of randomness can be inspected.
The general rule is that true randomness comes from quantities that are known to be unknown - for example the variation in disk read timing, which is affected by turbulence, or the microphone input, which is inherently noisy. You have to ask where these random numbers
ultimately come from.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     5i5rAiu+t+UqxlCHKBfiAn24UbuH1D2GsYrL3hv7
     4q7w1mi+V9whucgThiyHnkPt0EkjS1oIAp9hQ1UKc

@_date: 2005-12-26 09:37:00
@_author: James A. Donald 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
--
Unfortunately most domain name registrars take a
completely irresponsible attitude to domain name theft,
despite the fact that domain name theft is a major
problem.   OpenSRS is good but their resellers a very
bad.  Unfortunately by default, one winds up having the
same password with OpenSRS as with the reseller.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     LA7xNzxuTFoXA1ir8b2UWqPg/P6NhF+naIs34+LG
     49FONv1xLEWSjg/TiZ8oHGLHyCAhQLOM7CzPNCuTD

@_date: 2005-12-27 23:18:08
@_author: James A. Donald 
@_subject: ADMIN: end of latest SSL discussion 
--
In the SSL thread various solutions were proposed, or rather existing solutions pointed to:
1.  SSH just works.   So generalizing from the success of SSH, the browser should remember who you have relationships with, and the keys of the people you have relationships with.   To avoid the name overload problem, those relationships should be named by Zooko's triangle, as the petname tool does, and should be a special kind of favorite, as the petname tool makes them.   This requires that establishing a relationship, and verifying a shared secret, should be part of the browser chrome, as it is with SSH, rather than a particular application of generic web forms, as it is with existing practice.   So when you hit a phisher, significantly different chrome comes up.
2. Phishers are after shared secrets, so secure each shared secret, and thus each relationship, with SRP-TLS-OpenSSL  This also requires that establishing a relationship, and verifying a shared secret, should be part of the browser chrome, rather than a particular application of generic web forms.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     8epIQqxZ+sfUW+5ao0hWd4g/hAhRlqifZr6xWoQn
     47kvMBcL6UqQ54XSgEcxbJd8xqAh2LSxufi/3IBdG

@_date: 2005-02-04 19:07:12
@_author: James A. Donald 
@_subject: Dell to Add Security Chip to PCs 
--
The ability to convincingly tell the truth is a very handy one
between people who are roughly equal.  It is a potentially
disastrous one if one party can do violence with impunity to
the one with the ability to convincingly tell the truth.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     6B7i0tiB4vUHqQnAP6nXT2z+B+zLB8624+K6+ENU
     47fFHg6cY0KInzxMe/l+L2c7LqmPZyrwOSZepYIR3

@_date: 2005-02-22 14:39:35
@_author: James A. Donald 
@_subject: SHA-1 cracked 
--
The sky is not falling.
The attack gets the attacker eleven bits - at the cost of being an extremely narrow attack with few practical uses.  So add another 28 bits.
Moore's law tells us the attacker gains a bit every 18 months -
the attack merely means we have to go for larger widths sixteen
years ahead of schedule.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     Ged7CGvkAfi+HgN2w+/LL31mzzy0rzAd6QlX+z/y
     4YIpuPGWx/Gc+/vHF0tt1jR7IBzCWTsNo479+xWBR

@_date: 2005-02-23 10:15:31
@_author: James A. Donald 
@_subject: I'll show you mine if you show me, er, mine 
--
It is a badly bungled implementation of a really old idea.
An idea, which however, was never implemented on a large scale,
resulting in the mass use of phishing attacks.
Mutual authentication and password management should have been
designed into SSH/PKI from the beginning, but instead they
designed it to rely wholly on everyone registering themselves
with a centralized authority, which of course failed.
SSH/PKI is dead in the water, and causing a major crisis on
internet transactions.  Needs fixing - needs to be fixed by
implementing cryptographic procedures that are so old that they
are in danger of being forgetten.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     Dn3N69hcbr+mL/HUTw8OhGtKmD9rHYOMN4NTBkIY
     47AOCXrb7e35xm5QBsHbFVr/jfm+XwTUvzdiytKpG

@_date: 2005-02-28 09:36:57
@_author: James A. Donald 
@_subject: SpookAir, redux: No Secrets -- Eyes on the CIA 
============================== START ==============================
    --
Brinworld:  They may be watching us, but we are also watching The large number of surveillance cameras popping up in American cities has turned out to be no threat to liberty.  Most of them are privately owned, and their private owners have no inclination to review their records, unless a real crime has been committed, and no inclination to hand over to authorities records that would primarily reveal their own activities.  In recent incidents where private surviellance camera records were given to authorities, the authorities received only selected excerpts, only what the owner of the records chose to reveal.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     PS5fDA87MKS6uCbiF0gJ/R+39ekRuwLazrAsTyAa
     4MxSlekoFzNrLXER1RoAItoikUPxKn3udKQokRxkB

@_date: 2005-07-09 18:56:22
@_author: James A. Donald 
@_subject: the limits of crypto and authentication 
--
Ian Grigg Such a device sounds like a cell phone.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     5nMEZ3YWGEUKZWzEprv/E7vI+8j9jzBNX8GWiJiO
     4nb4BSDrVGLfq42fHktPRSAfFO3N0uGBnezGRNWrS

@_date: 2005-07-11 18:30:08
@_author: James A. Donald 
@_subject: New Credit Card Scam (fwd) 
--
Adam Fields Widely shared secrets are inherently insecure, and no
good practices exist to make them secure.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     pPiA9t4S8XPLqBdKsuV/tb+p7tvWdaBMwkYer7hl
     4+JSXe6MBo4npe1jgiYmnZNAqOAsX9u+daHcBra01

@_date: 2005-07-14 15:10:35
@_author: James A. Donald 
@_subject: ID "theft" -- so what? 
--
Dan Kaminsky The PKI that was designed to serve no very useful function other than make everyone in the world pay $100 a year to Verisign is dead.
Yet the technology is potent, and the problems of identity and authenticity are severe.  We shall, bye and bye, see reliance on public keys.  Other things just don't work.
At present, the overwhelming majority of money transfers take place over non internet networks, and rely on non internet identity.  Inevitably, this will change, and that change will both necessitate, and be based on, the use of public key cryptography.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     Pmf2aYMPVGY8UHBvEyuLghf0GsgeyEonN9O9Ljh+
     4j9GQPHtedEznyhC2w4YbCu38yJe2dOsSNGUyV3fL

@_date: 2005-07-15 14:26:17
@_author: James A. Donald 
@_subject: ID "theft" -- so what? 
--
Aram Perez
SPKI seems to me committees pondering what they might do with public keys, rather than an infrastructure.
In real life the best technology usually does win.  CA based PKI has lasted so long because it has not come under real world attack by real world adversaries until recently.  Hypothetical problems have only recently become real, as at last people have come to base the movement of valuable goods on promises exchanged over the internet.
A problem with the dot com boom, with all booms, was premature investment, leading to malinvestment. Existent PKI is one more piece of malinvestment, one more boom hangover.   Such hangovers can last a long time - After eighty years we are still getting out from under the excessively vertical integration of car assembly lines established in the nineteen twenties, but since the physical obstacles to change are much less in this case, this hangover will not last nearly so long.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     Fa1OKlHyGdiwEhSvi7sXvTo92wIBZ573qPLTCeLo
     4TtZu3a5eWXjqK4Ol9jEIvUqnJ22YwURQUJdaf5xF

@_date: 2005-06-04 09:08:45
@_author: James A. Donald 
@_subject: What happened with the session fixation bug? 
--
Your business about MACS and stuff was to prevent the adversary guessing the users session ID.  With "session fixation", the adversary does not try to guess the legitimate users session ID, instead he fools the browser of the legitimate user into using the adversary's session ID.
Adversary accesses web site as if about to log in, gets
a session ID.  Then supplies false information to someone else's browser, causes that browser on some one else's computer to use that session ID.  Someone else logs in with hacker's session ID, and now the adversary
is logged in.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     fUQA7VMYJROi7AAUHD8ZmEHReDprBvrg3u3cL2VI
     4NzEz9SAfaOzb7GhsAkM//vmMQKDsrdLEInHLumm3

@_date: 2005-06-04 20:46:41
@_author: James A. Donald 
@_subject: What happened with the session fixation bug? 
--
Michael Cordover
Assuming we can intercept and modify cleartext, no problem.  There are also several other ways that do not require such man in the middle attack,
For example, the adversary might represent himself as selling some item for egold.  The victim clicks on the egold link on the adversary's web page, but it is a session fixation link which looks something like this.
As a result, when the victim logs in to egold, logs in to the genuine e-gold. not a phishing site, he logs the adversary in. Adversary then drains all of user's account.  (Assuming that e-gold is vulnerable to session fixation.)     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     /xB6pMv9fT1fIGlyhzRyAjdO+X1POcedv7maASR+
     4rXw3i2fw8a6eXIV31Rc11GLSM+BsAqwdlNX3AVVO

@_date: 2005-06-23 19:58:41
@_author: James A. Donald 
@_subject: massive data theft at MasterCard processor 
--
Rather the server should send out some encrypted random
data which the end user decrypts.  End user should then
prove knowledge of that encrypted data.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     mvLPUs8OZQJeGGYzUgIlJCvGBKsPF9FUruhnF3tE
     4Krdy9r1LLw/aZSGjrIDNHXOcHkloS7F9MGLCTB6o

@_date: 2005-06-24 09:14:24
@_author: James A. Donald 
@_subject: Optimisation Considered Harmful 
--
Suppose you have something that is inadvertently an
oracle - it encrypts stuff from many different users
preparatory to sending it out over the internet, and
makes no effort to strongly authenticate a user.
Have it encrypt stuff into a buffer, and on a timer
event, send out the buffer.
Your code is now of course multithreaded - very easy to
get multithreading bugs that never show up during
testing, but non deterministically show up in actual
use.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     fWkmIPqr+sQN9GW27vahB3Bc9ulLdzbGrPKEjXFL
     4nPDlKsQgDKH6LEnS3M7ECcBByW0lH5o7CUzo2UYB

@_date: 2005-06-25 10:27:16
@_author: James A. Donald 
@_subject: Optimisation Considered Harmful 
--
James A. Donald:
It should have been needless to say, that at the end of each time frame, the oracle only starts sending out stuff encrypted in response to data received at least n time frames previously, where n is a small positive number, possibly one.
A time frame is longer than the difference between the quickest and slowest encryption of a block.  n time frames is longer than the slowest encryption of a block.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     JdXC3IuQNnYvM2SrAOIY2iLJyhKf21IR191yeebK
     4FIl5EvQ0dseZCj2m2/NsQANv7tID98AAQ+pJMARn

@_date: 2005-03-04 14:23:16
@_author: James A. Donald 
@_subject: [IP] One cryptographer's perspective on the SHA-1 result  
--
The attacks on MD*/SHA* are weak and esoteric.  It is not so
fundamentally broken as to justify starting over.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     QVYtFQAELN4YlZ9xB60CvXTqW8QT8rOABMbJrPXE
     4hz2qo1jnDwc3tmFFeyh6lG9sOrXL1783FYSh2s+v

@_date: 2005-03-08 12:25:31
@_author: James A. Donald 
@_subject: I'll show you mine if you show me, er, mine 
--
There seem to be a shitload of protocols, in addition to SPEKE and DH-EKE
A password protocol should have the following properties:
1. It should identify both parties to each other, that is to say, be secure against replay and man in the middle attacks, in particular, strong against phishing.. It should be secure against replay and dictionary attacks by an evesdropper or man-in-the-middle.  Such an attacker should be able to no better than someone who just tries repeatedly to log on to the server with a guessed password
2.  It should be as strong as practical against offline attacks by the server itself.  The server operators, or someone who has stolen information from them, should not know the users password, and dictionary attacks should be sufficiently expensive that a strong password (not your ordinary password) is secure.
Can anyone suggest a well reviewed, unpatented, protocol that has the desired properties?     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     A8bCmCXDTAX2Syg907T7uRpajs77l9CqLEii+ezP
     42zQDcP3xJXtcLPSgCVa55kew+ALkrQ/I50PFm9lC

@_date: 2005-03-13 18:13:31
@_author: James A. Donald 
@_subject: comments wanted on gbde 
--
I can see no faults in gbde other than that it is too clever by half. The implementor imagined various vaguely imagined complicated attacks, and put in all sorts of overly clever stuff to defeat them.
Let us stick with the threat model where the bad guys kick down your door and yank your computer off your desk.   If your cleaning lady is out to get you, it is much easier to create software that creates a false and misleading sense of security, than software that stops her.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     20zhgc+C6FrVnrDEgE+FUIJKA13Z121H8ddkFGw7
     47zO1ZpoBAYKkTgHoq2eQeHRoHv2heZEvDQGnfFAX

@_date: 2005-03-20 09:41:48
@_author: James A. Donald 
@_subject: NSA warned Bush it needed to monitor networks  
--
Obviously any bureaucrat with the authority to categorize
something as secret will more or less automatically so stamp
any information that passes through his hands, to inflate his
importance, and thus his job security and prospects for
promotion.  Similarly, he will spend any money he has authority
to spend, thus the never ending conflict between congress and
the SSSI bureacracy, who if they had their way would put every
single american, plus the dead and the pets, on SSSI
This results in "top secret" information being treated as not
very secret at all, as documented by Richard Feynman, which in
turn results in ever higher secrecy classifications, more top
than top, a process of classification inflation and debasement.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     R4I4vh9JdcWBUfeQFXQ+i/TlFSVcljg/Og6KRDDj
     4qwXmonSAX1xgyPdaB5TsB80yC66PjeWY5mzIpBuo

@_date: 2005-03-28 18:00:21
@_author: James A. Donald 
@_subject: how email encryption should work 
--
In my blog  I post "how email encryption should work"
I would appreciate some analysis of this proposal, which I think summarizes a great deal of discussion that I have read.
    * The user should automagically get his certified     key when he sets up the email account, without     having to do anything extra. We should allow him the     option of doing extra stuff, but the default should     be do nothing, and the option to do something should     be labelled with something intimidating like     ?Advanced custom cryptographic key management" so     that 99% of users never touch it.
    * In the default case, the mail client, if there are     no keys present, logs in to a keyserver using a     protocol analogous to SPEKE, using by default the     same password as is used to download mail. That     server then sends the key for that password and     email address, and emails a certificate asserting     that holder of that key can be reached at that email     address. Each email address, not each user, has a     unique key, which changes only when and if the user     changes the password or email address. Unless the     user wants to deal with ?advanced custom options?,     his ?from? address must be the address that the     client downloads mail from ? as it normally is.
    * The email client learns correspondent's public     keys by receiving signed email. It assigns petnames     on a per-key basis. A petname is also shorthand for     entering a destination address (Well it is shorthand     if the user modified it. The default petname is the     actual address optionally followed by a count.)
    * The email client presents two checkboxes, sign and     encrypt, both of which default to whatever was last     used for this email address. If several addresses     are used, it defaults to the strongest that was used     for any one of them. If the destination address has     never been used before, then encrypt is checked if     the keys are known, greyed out if they are unknown.     Sign is checked by default.
    * The signature is in the mail headers, not the     body, and signs the body, the time sent, the     sender's address, and the intended recipient's     address. If the email is encrypted, the signature     can only be checked by someone who possesses the     decryption key.
    * If the user is completely oblivious to encryption     and completely ignores those aspects of the program,     and those he communicates with do likewise, he sends     his public key all over the place in the headers,     signs everything he sends, and encrypts any messages     that are a reply to someone using similar software,     and neither he nor those he corresponds with notice     anything different or have to do anything extra ?     other than that when he gets unsigned messages, or     messages with an key different from the previously     used key, a warning comes up ? an unobtrusive and     easily ignored warning if he has never received a     signed message from that source, a considerably     stronger warning if he has previously received     signed mail from that source.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     gOiN3HXQALAQHbKEOYdu/aZClRbPTEfjzyLpGAMx
     4dJddm3vIwGuBnfc933djUV6zT4DWvM26KobmzFyC

@_date: 2005-03-29 11:14:42
@_author: James A. Donald 
@_subject: how email encryption should work 
--
Ian G
I have amended the post to read, "the default should not
require any input or clicking or thought from the user"
 "How email encryption should work"
On what basis then do we create the user's key?
If we create it from the password alone, then his
password can be dictionary attacked, so every signed
post reveals his password, reducing, not increasing, his
security.   If we automagically create a secret key
stored on his computer, then when he wanders over to
another computer, his key changes, surprising both
himself and those he corresponds with, resulting in mail
failures.  Hence my proposal that in the default case
the key be created based on a PDM server's reaction to
his password.
If we have message signed by a key based on a secret
file, we should not encrypt by default.  Perhaps the
default reply policy should be set in the accompanying
certificate, and if no certificate, signature implies
very little except message integrity and persistence of
identity - "this message apparently posted from the same
computer as the last message from "
Of course, this could be remedied by explicitly changing
the semantics of petnames, that a petname corresponds to
a particular email address on a particular computer, but
that makes changes of petname too frequent,
unintentional, and to end users, surprising.
James A. Donald:
Ian G
It means whatever the certificate asserts that it means.
If the signature is accompanied by the certificate
described as the default case in my proposal
 "How email encryption should work:"
it means you are receiving mail from the someone capable
of receiving email at the sender's address, rather than
a phisher or a virus working through someone's address
book.  (To conceal the infection, viruses make the
"from" address anything in the address book except the
actual from address.)
This provides some immediate utility to the ordinary
user who does not care or know anything about
cryptography - ultimately resulting in signed email
being privileged in spam filters.  Banks will be able to
send out account information in email without being
blocked by spam filters, or setting up their users to be
scammed by phishers, or to have their identity stolen.
One minor problem with whitelists is that I have
frequently been under massive spam attack by virus
generated email supposedly originating from people I
know.   Aggressive whitelisting is going to lead, is
already leading, to aggressive purloining of social
network information to penetrate the whitelists.
Turning off signing by default may well be desirable,
certainly desirable if one lacks a certificate that
provides added value to the signature - but any key
exchange is clumsy - making signed letters a key
exchange mechanism that is relatively transparent to the
user.  We could have a mechanism whereby the user
explicitly injects the public key into the email,
thereby turning on the encryption default - but this
requires conscious thought, understanding, and effort. I was looking for automatic encryption.  It just works,
so long as both clients are using the same protocol, and
no one has to do anything
If the user is going to send the public key explicitly,
to turn on encrypted communication, then there needs to
be a checkbox "Request encrypted reply" - and if you
request encrypted reply, you automatically send a public
key in the header, but no signature is required.  The
user knows that the only person who can receive his
reply is the person he replies to, but does not
necessarily need to connect that identity to some other
Of course if our goal is not "encrypt everything", but
rather "allow the user to encrypt some few things", then
of course we just use local keys, with no certificate. If there is no certificate, then as you suggest the
signature has no semantics, and should not be presented
to the user as a signature, but merely as message
integrity, and we warn the sender requesting an
encrypted reply that the secret key to read the reply
email is stored in a file in such and such a location on
his computer.
My goal was, however, "encrypt everything", much as
paper letters about my family, my niece, and our holiday
in Hawaii are routinely signed and routinely sent in
envelopes.  Unless we have an "encrypt everything"
policy, our system is only going to provide benefits to
the small minority that understand encryption, care
about it, and think about it - which appears to be a few
dozen, insufficient to support decent software.
We need to provide benefits to the masses, without the
masses needing to understand, think about it, or care.
If the client fails to contact the keyserver, we could
fallback from "encrypt everything using a public key
based on the other guys password strengthened through
PDM", to "encrypt selected messages using a public key
based on the other guy's secret file".
The secret file has a transient identity.  Absent a
(possibly self signed) certificate asserting otherwise,
it is assumed to go away quickly, merely proving that
the reply to one letter can only be read by the same
person who sent the previous letter - providing secrecy
and continuity within a particular email thread, not
lasting and long lived identity, hence no petname for a
key without a certificate.   We don't expect the same
person to hold the same uncertified key for very long,
easy to make, easy to discard, hence of limited value
for resisting viral spam and phishing impersonation
attacks, and for securing identity information sent in
email, which is the main added value we can provide for
Joe sixpack. Burmese freedom fighters are a pretty
limited market.
James A. Donald:
Ian G
A google for "naive sign and encrypt" turns out rather
too many hits.  To what are you referring?
Ink signatures are closely associated with the person,
and generally persistent for the person's lifetime.
Computer signatures necessarily less so.
In the default case I describe above, the signature has
the semantics. "This email comes from someone who can
receive email at this address, and he is using the same
password as he did last time you received email from
him." - which should, I think, appear literally in the
certificate, or in url in the certificate referring to a
resource that the email client caches.
I have modified the blog post by adding a paragraph on
signature semantics.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     N/KRlzRxr0kjmLO5GIu1obJohzqXYs3rUpqvyLpq
     4i3AX1hCB/K8t0xa+NZPZbW4+tuAh9Q9eJBTI6UMZ

@_date: 2005-03-30 13:23:45
@_author: James A. Donald 
@_subject: how email encryption should work (and how to get it used...) 
--
Phishing is costing billions, and is a major obstacle to electronic commerce.   In my judgment, fixing phishing and facilitating electronic commerce is a good fit to the capabilities provided by cryptography.  (Of course a large part of spam is phishing and viruses)
And your site is?     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     To5/mH1p3iCBlpaC6McgYo2aehoFMV42OcrSW6Ze
     4AmE3tC68Tiyw+VQHexWjeQmXnrDHI+41ty416j11

@_date: 2005-05-07 14:03:07
@_author: James A. Donald 
@_subject: What happened with the session fixation bug? 
--
PKI was designed to defeat man in the middle attacks
based on network sniffing, or DNS hijacking, which
turned out to be less of a threat than expected.
However, the session fixation bugs
 make
https and PKI  worthless against such man in the middle
attacks.  Have these bugs been addressed?
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     vPV62zjEtpTJHTV5lKXu2Sw+/5fke2gh9AwPeqQj
     4oqqXlvYYKn9rR63ZsSEEjgV5fVyWT9+e6YttP3G/

@_date: 2005-05-22 07:43:32
@_author: James A. Donald 
@_subject: how email encryption should work (and how to get it used...) 
--
The cure for spam is not a provable link to a true name,
but a provable link to a domain name.
The problem with adoption is that this is only
beneficial against spam if widely used.  We face the
usual critical mass problem.
The proposal on my blog (blog.jim.com) focusses on
encryption at the individual level - one key per email
address, not one key per domain name. which would solve
the spam problem, but is less immediately helpful than
one key per domain name.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     Fl8/gx81XkbuiLaqs0tMz+/ctcqWpf8QrHNii7fo
     41mnxh9Ph2K70irDlta/Y+pRlE0zVmBG5xdTi+LFm

@_date: 2005-05-23 09:37:26
@_author: James A. Donald 
@_subject: What happened with the session fixation bug? 
--
James A. Donald:
The way to beat session fixation is to issue a privileged and impossible to predict session ID in response to a correct login.
If, however, you grant privileges to a session ID on the basis of a successful login, which is in fact the usual practice, you are hosed. The normal programming model creates a session ID, then sets variables and flags associated with that session ID in response to forms submitted by the user.  To prevent session fixation, you must create the session ID with unchangeable privileges from the moment of creation.   Perhaps you do this, but very few web sites do.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     en30AWb8dk9T67RFzUse67CG7ZHHoOHC5OR/mndW
     4T4xroZR7GeKinK0sMRNQ+4Pdj6ApUEu4FCGDghE5

@_date: 2005-05-28 10:47:56
@_author: James A. Donald 
@_subject: Citibank discloses private information to improve security 
--
An even better solution would be if email clients silently did key continuity checking on a signature hidden in the email headers, if such a header is present, and then popped up an SSH style dialog if an accustomed key is absent or changed.
With bank web sites, experience has shown that only 0.3% of users are deterred by an invalid certificate, probably because very few users have any idea what a certificate authority is, what it does, or why they should care.  (And if you have seen the experts debating what a certificate authority is and what it certifies, chances are that those few who think they know are Do we have any comparable experience on SSH logins? Existing SSH uses tend to be geek oriented, and do not secure stuff that is under heavy attack.  Does anyone have any examples of SSH securing something that was valuable to the user, under attack, and then the key changed without warning?  How then did the users react?     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     9xkPv5IiSbkDSyL+VmtW44PAr2ChEHEncpVVVLUp
     4PtEJ+TutEYw9poqnX74X8nSltnDV22OJDPqsG1cS

@_date: 2005-11-03 22:00:01
@_author: James A. Donald 
@_subject: HTTPS mutual authentication alpha release - please test 
--
It seems to me that mutual authentication is pretty much
irrelevant to HTTPS and certificates.  You mutually
authenticate by both knowing the password, as in SPEKE.
Of course, SPEKE is patented, so is this scheme a way of
getting around the patents?
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     a5RzA9UesxiZw+cjRsz+8yPLKwJdTMfUjcQq0iZf
     4ybo9wAzZZNG5YyF69jzKw/oXw3fL7FGj86oXey46

@_date: 2005-11-08 23:13:25
@_author: James A. Donald 
@_subject: How broad is the SPEKE patent. 
--
Does SPEKE claim to patent any uses of zero knowledge
proof of possession of the password for mutual
authentication, or just some particular method for
establishing communications?   Is there any way around
the SPEKE patent for mutual authentication and
establishing secure communications on a weak passphrase?     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     c3YaEtPqVbOMIjHk3eId6UngzMgXPFWqhwk9daye
     4S2HlmFAZeCAhYaaxiPBSR5+8yf8Wwqy+gi8rWY6f

@_date: 2005-11-10 13:28:46
@_author: James A. Donald 
@_subject: How broad is the SPEKE patent.  
--
The vast majority of phishing attacks and other forms of man in the middle attack seek to steal existing shared secrets - passwords, social security numbers, credit card numbers.
I figured that the obvious solution to all this was to deploy zero knowledge technologies, where both parties prove knowledge of the shared secret without revealing the shared secret.
Now I see that zero knowledge technologies have been deployed - or almost so:
SRP-TLS-OpenSSL     (not quite ready for prime time)
And SRP GNU-TLS Of course, actual use of these technologies means that the browser chrome, not the web page, must set up and verify the password.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     FtM0KMPHrqFLxpaSShaR05Rlxb8CnxF4pHnz9Yqy
     4RHOMGs4NJv8heDXAxtfYQ4sYI82tcElZ5wJ4qgvc

@_date: 2005-10-26 08:53:02
@_author: James A. Donald 
@_subject: On Digital Cash-like Payment Systems 
Date sent:      	Tue, 25 Oct 2005 00:38:36 +0200
Copies to:      	John Kelsey , Ian G ,
       	ray at unipay.nl, cryptography at metzdowd.com, cypherpunks at jfet.org
How does one inflate a key?

@_date: 2005-10-26 09:17:21
@_author: James A. Donald 
@_subject: On the orthogonality of anonymity to current market demand 
--
John Kelsey
Some of us get spyware more than others.
Further, genuinely secure systems are now becoming
available, notably Symbian.
While many people are rightly concerned that DRM will
ultimately mean that the big corporation, and thus the
state, has root access to their computers and the owner
does not, it also means that trojans, viruses, and
malware does not. DRM enables secure signing of
transactions, and secure storage of blinded valuable
secrets, since DRM binds the data to the software, and
provides a secure channel to the user.   So secrets
representing ID, and secrets representing value, can
only be manipulated by the software that is supposed to
be manipulating it.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     3CepcQ59MYKAZTizEycP1vkZBbexwbyiobaC/bXS
     44hfxMF4PBKXmc5uavnegOFFCMtNwDmpIMxLBcyI3

@_date: 2005-09-08 00:22:15
@_author: James A.Donald 
@_subject: e: Another entry in the internet security hall of	shame.... 
--
Indeed they can be.  The question is, on what basis do we know a public key is the right one?  That it has been pre-shared, or that an authority has vetted it, as with CA certs.
Suppose that when I establish internet access to my bank account, I make up a password for my bank account, and the client software on my computer generates a private key from that password.  I then tell the bank the public key corresponding to my password.  (The public key is
not in fact public, but a shared secret) When I next I
log into the bank, the bank must first prove to me
knowledge of a public key corresponding to my password,
without revealing that public key, and I prove to the
bank knowledge of the corresponding private key.  Then I cannot log in to a phishing site, and if I did, it would do the phishers no good.
Assume the bank has a public elliptic curve, and a
public generator point G on that elliptic curve.  I have
a secret number p, constructed by my computer from my
password, and a shared secret elliptic point,  pre
shared between my bank and me.  I calculated this
elliptic point my multiplying the generator by my secret
When next I log into the bank, the bank invents a random
number r, and sends me the elliptic point rG in the
clear.  I invent a random number s, and send the bank
the elliptic point sG in the clear.  At this point the
bank knows r, sG, and pG, but not s or p.  I know s, p,
and rG, but not r.  The bank knows pG, because we
constructed that when setting up the passwords for my
account, and the bank has stored it ever since.
I calculate (s+p)(rG)
The bank calculates r(sG+pG)
Which are of course equal.  I and the bank now share a
transient secret, which we will use to encrypt
communications following this particular login, until
logout   The evesdropper, man in the middle, or phishing
site, does not have that secret.  The fact that we can
understand each other proves that the right parties are
talking.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     YNuqdG3fHUHoOcFSmq0em+tFMqcDwVUWIWgS2s6H
     4QP12giI58sVxIRE6YibnBC6OvfHfpHSK8pbVDKlY

@_date: 2005-09-10 21:16:58
@_author: James A. Donald 
@_subject: Another entry in the internet security hall of shame.... 
--
Peter Gutmann
For PKI to have all these wonderful benefits, everyone
needs his own certificate.  But the masses have not come
to the party, in part because of the rather Orwellian
requirements.  Obviously I cannot get a certificate
testifying that I am the one true James Donald, because
I probably am not.  So I have to get a certificate
saying I am the one true James Donald SS xxx-xx-xxxx -
the number of the beast.
Capitalism 101:  The customer is always right.  The
customer wants to use passwords.  The customer has
decided.  So shall it be.
So we are going to base identity and security on
passwords.  If we are going to supplement the users
password with a nicely random number stored in his
computer, we should put the random number in his
bookmark, so that the the user conceives of it as his
secret web page, rather than his certificate.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     hrytA7Ym/9GHqXZ4CwiYi3aZrSwObH1bY7OKGXtY
     4LcDIdLEhX7k8XcxPbgYmyqtGvkldcTESn1xhERwk

@_date: 2005-09-12 09:32:15
@_author: James A. Donald 
@_subject: ECC patents? 
--
Alexander Klimov
Anyone can claim to have patented anything.  Someone
recently patented the wheel, to show how bad the
situation is.   I think these guys are just blowing
smoke.  It has been a long time, and no one has paid out money on an ECC patent yet.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     T2A5LZ0emoxvUB9mpzAbsQaP6ZNjQpWobkfHEPls
     4o11NuYw0FpVl962xoPzHTvBwM2AkgESWNKRblf9u

@_date: 2005-09-12 09:52:27
@_author: James A. Donald 
@_subject: Is there any future for smartcards? 
--
Typical worm installation goes like this:
: :	Receive message via bluetooth from unnamed : :	device?  Y/N
: :
: :	Installation Security warning:  Unable to : :	verify supplier.  Continue anyway? Y/N
Seems to me that the phone designers have done a better job with virus, worm, and malware resistance than Microsoft or Linux.  Teenagers are pretty sophisticated.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     8tInGahoKXdu0MdklSeXa9rSSqUD0w9pt1CUvwWm
     4NF0OIlPIvHlyV2QEiTSJuO9yYMSLePsNYsvGjreG

@_date: 2005-09-13 14:22:27
@_author: James A. Donald 
@_subject: Is there any future for smartcards? 
--
James A. Donald:
Eugen Leitl
Symbian is a lot stronger than Windows or Linux, and we
have been implementing payment systems on Windows/Linux.
Eugen Leitl
The teenagers I know almost never get viruses on their
PCs.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     DXwKq4X3cR5cK33Zn8ZiDp4R1IP/lF87Fcjzyv1I
     4POwLeIKZIKuer/s9+86+OZciIIS8Ad7eyLsmd/h5

@_date: 2005-09-15 09:54:29
@_author: James A. Donald 
@_subject: ECC patents? 
--
Whyte, William:
If the NSA paid anything significant for any of the curves, we would be told.  Therefore the NSA paid
nothing or almost nothing, and therefore if the NSA licensed anything, it would have licensed everything.
I doubt that the NSA paid any money whatsoever for this license, making it profoundly unimpressive as evidence that *any* curves have a plausible valid patent.  If the NSA paid real money, the patent holders would be sticking it in our face as a price setting precedent.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     uFGgCOtWvwFnmCL5tYGLSloqyccg5nCjgOZZ2xdW
     4NjnEzQaXNpdg5TTfRnBvcrjTbnHJ6AGsfz5BcvsG

@_date: 2005-09-16 20:52:52
@_author: James A. Donald 
@_subject: ECC patents? 
--
Whyte, William" I stand corrected.
However as was pointed out previously:
: :	Further, the license would be limited to only : :	prime field curves where the prime was : :	greater than 2255. On the NIST list of curves : :	3 out of the 15 fit this field of use: the : :	prime field curves with primes of 256 bits, : :	384 bits and 521 bits.
Of the NIST list of fifteen, nine are 256 bits or Presumably, if NSA thought certicom had a case, they would have licensed at least the other six NIST curves
as well, and most likely the other twelve.
The three curves that are licensed look different from the other twelve, though I have no idea of the significance of this, if any.     --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     ZKrN4sA2qyTNIC90h3U/8Er848IPFGfUOQyBxm8h
     4xlZJBIqZwgUkOyqgxTzTBcauENSjU46x6oDgn2X4

@_date: 2005-09-17 18:22:27
@_author: James A. Donald 
@_subject: Clearing sensitive in-memory data in perl 
--
Ben Laurie We have a better paradigm:  C++
Use const zero terminated strings where possible, use
STL strings where they must be non const.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     nsfA32EGEKM0cU+MepqW0siOwFXqhO6L4ObDt/5P
     4n7mr1z57RP4q1W6q39DjzRerUpSJz4w3SYQPtVCh

@_date: 2006-08-06 17:53:31
@_author: James A. Donald 
@_subject: Test Vectors for IGE and biIGE? 
--
 > I'm implementing AES in IGE and biIGE mode. AFAIK,
 > there are no other implementations or test vectors,
 > but perhaps one of you knows different?
  On reviewing the various methods for providing
integrity with minimal overhead for block encrypted
data, IGE seemed comprehensible, and I found no reported
attacks against it, but I also encountered lots of
literature adding multitudes of epicycles to it, as if
weaknesses had been found or suspected.
I expected to find someone saying "Here is a simple and
efficient way to protect encrypted data against
malicious alteration by an adversary who knows or
strongly suspects the plaintext" but did not find anyone
saying that.
Why the oversupply of remedies?
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      PPq8l9FHjabhO8nTB28VyFfiMXCf9NJ+pa+2HT1q
      4Ttu2nqimJg3wjiGx+UTZHFcnKnoRe83ZkbkrSUY0

@_date: 2006-08-14 08:47:58
@_author: James A. Donald 
@_subject: mac os x safari ssl cipher suite 
--
 > Safari only seems to support DES, 3DES, and RC4
 > ciphers.  My question is this: should I be concerned
 > about privacy when *_RC4_* is the negotiated suite,
Nothing wrong with RC4, when used correctly.  Using it
correctly turned out to be harder than we originally
thought - but SSL does use it correctly.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      8PORO+zKpxIcfbxPbIn6QJCWObzpBeAHXq1ayeRH
      4Xom0un81cmvTp/yhXOteppnRKtloRB7itr3E2ASz

@_date: 2006-08-14 09:36:15
@_author: James A. Donald 
@_subject: Hamiltonian path as protection against DOS. 
--
DOS is now a major problem - every business, online
games, money movers, banks, porno sites, casinos, now
comes under DOS attack from extortionists.
Before one does any potentially expensive operations,
for example constructing a shared transitory secret with
DH, or even setting up a connection, one would like to
make the client pay a significant computational cost,
preferably with one and half round trips of UDP
To do this the server should send the client some random
bytes, and require the client to respond with something
costly to construct from those random bytes, but trivial
to verify.
Commonly we use SHA - client responds with some bytes
that when hashed with the server's bytes, produces a
hash of special form.  A single SHA operation likely
costs two to four microseconds when efficiently done. If
SHA is hard to reverse, client has to try bytes at
random until it comes up with something that just
happens to have the special form.
But SHA was not really designed for this purpose.
Further, there is no strong theory justifying SHA.  It
would be nice to do this with a Hamiltonian path.   But
Hamiltonian paths are tricky - it is not trivial to
produce graphs of known difficulty.  Ideally one would
like to efficiently produce small Hamiltonian problems
that are known to have a solution, and known to be hard
on average.
Has some work been done on this problem?  Are there
standard algorithms, or better, standard code, that I
can copy?  On the other hand, if we try to do something
clever, we are likely to exceed a few microseconds,
which defeats the purpose.  While Hamiltonian path
problems are more elegant, and directly appropriate to
the problem, SHA is hard to beat.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      lxWf/Gt7dQkPv3EH7yXrYUWf/eCa0XA9bhesMQPf
      46vWt67xdWudo2rkAO3DXrKLUYGguTLiyyovbxymM

@_date: 2006-08-18 06:41:31
@_author: James A. Donald 
@_subject: Hamiltonian path as protection against DOS. 
--
 > But if the packets are forged, wouldn't that turn it
 > into a different kind of DOS?
 >
 > If I can get you to blacklist Alice by sending n
 > forged attack packages, then my DOS succeeded, if my
 > goal is to deny a connection between you and Alice.
The goals is usually to shut down a money making
service, in order to extort protection payments from
them.  Shutting off a few clients is not a goal.
The photuris protocol that Bill Stewart mentioned does
an initial exchange wherein the server sends some random
bytes to the client, and the client must respond with
those random bytes before the server does any work at
all.  This means that the adversary cannot easily and
cost effectively impersonate Alice's IP, for large
numbers of Alices, unless they have upstream control of
the server's pipe - which would require them to  be
physically rather close to the server, and if they are
physically rather close then the owner of the server can
find them and go after them with an axe handle, reducing
the problem to the previously solved problem of
protecting property rights in physical space.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      Vd1vET3dgr85QVK7NkeKqXbuKv71rJtvAtE/6g9O
      4rd/c+MMCzQCtCpvt4KYLGwIMyBJauOzgF9YYvZIU

@_date: 2006-08-18 06:58:06
@_author: James A. Donald 
@_subject: Hamiltonian path as protection against DOS. 
--
 > as an aside, i've pointed out before that in the
 > mid-90s that as webserver activity was increasing ...
 > a lot of platforms experienced severe throughput
 > degradation with HTTP transaction protocol use of TCP.
 > Most platforms had a highly inefficient session close
 > implementation around checking of the FINWAIT list ...
 > the assumption as that most session activity had
 > relatively infrequent session open/close activity. The
 > HTTP transaction activity violated those TCP activity
 > assumptions ... and for a period of time you found
 > platforms spending over 95percent of their processor
 > utilization dealing with the FINWAIT list.
Has this been entirely fixed, or is some substantial
degree of inefficiency inherent in the TCP protocol if
one uses it in a manner that tends to approximate  UDP.
(Lots of brief connections that are predominantly one
The keep-alive extension to the HTTP protocol was
intended to make HTTP activity more TCP like.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      8PdgpCY8lcy6qRnKRQ4rc2g1XHLHgfmlDh2ajbn/
      4Tdc/z1dVOW8Pb51y7ZwS1xLayi1u3YmFU8aAvRdv

@_date: 2006-08-18 07:32:14
@_author: James A. Donald 
@_subject: Hamiltonian path as protection against DOS. 
--
 > so a real SSL simplification, when the client contacts
 > the domain name infrastructure to do the domain name
 > to ip-address translation, the domain name
 > infrastructure can piggy-back the public key and any
 > necessary ssl options on the ip-address reply.
 >
 > the client then composes a XTP transaction (has
 > minimum 3-packet exchange for reliable operation) that
 > has an "SSL" packet structure. the client generates a
 > random transaction key, encrypts the communication
 > with the random generated key and encrypts the random
 > key with the server's public key ... and sends it off
 > the encrypted random key and the encrypted
 > communication.
This is obviously the right way to do it - the current
system has security and checking boundaries in the wrong
place, as well as being unnecessarily verbose.
Yet the plan never went anywhere.  What happened?
There is a gap between communications that are highly
efficient with TCP, and communications that are highly
efficient with UDP.  Brief transactions (which must be
reliable and two way, but are brief, are not efficient
with either one.
Indeed, ideally we would have one protocol that rapidly
starts to approximate TCP behavior with communications
that for which TCP is good (transferring large files)
and that approximates UDP with communications for which
UDP is good.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      CA0JQkWZ0L1FZxznjfOXmVHVt4WiIwUva7ci5uD5
      40h63MI/n3cU70SFRfoJG50yK9ZloczGB6D4pc25c

@_date: 2006-02-02 15:26:30
@_author: James A. Donald 
@_subject: Unforgeable dialog. 
--
 > Once the attacker sees the "secure" dialog, what prevents them from
 > using the same techniques and/or code to create a visually identical
 > spoof? There have been several OS-level designs to create
 > hardware-supported secure dialogs. Needless to say, these schemes
 > became exceedingly complex and had a variety of implementation
 > issues (i.e. special graphics hardware, drivers, TCMs, etc.)
 >
 > I don't see your proposals as providing 'secure' data viewing or
 > data entry solutions. IMHO, the best bet is currently provided by
 > layered security software where each component monitors and reports
 > on the others. Even this approach is temporary at best as we're now
 > seeing with malware that attacks by first disabling the currently
 > available protection layers (e.g., anti-virus, firewalls).
My computer does not get malware.  It regularly gets phishing and
legitimate emails that are very difficult to tell apart.
The techniques I discuss would make them very easy to tell apart.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      1JOeu/66DKl9KMzOvnF83U6mD6SUSbLgXtgqAEz1
      4swvP0Ni9aalk9b1QtRcmLZWW2OeWw0Z77uFyH3Pj

@_date: 2006-02-05 19:45:48
@_author: James A. Donald 
@_subject: Unforgeable dialog. 
--
1. Html obfuscates the actual target of a url.
2. Html encourages legitimate businesses to use complicated and
obfuscated actual targets for their urls, indistinguishable from those
used by phishers.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      2nR74Yxw4lhrh+CUYfGSzn2lhDblXe27MD4Hb6/i
      47hSn6z18XB2taOFnq+uHQwDG2WEDYsgB8vYgSlkv

@_date: 2006-02-14 12:32:29
@_author: James A. Donald 
@_subject: GnuTLS (libgrypt really) and Postfix 
--
Werner Koch retorted:
 > > I disagree strongly here.  Any code which detects an impossible
 > > state or an error clearly due to a programming error by the caller
 > > should die as soon as possible.
 > That is a remarkably unprofessional suggestion.  I hope the people
 > who write software for autopilots, pacemakers, antilock brakes, etc.
 > do not follow this suggestion.
If bad code halts, it will not get incorporated into production code.
If bad code produces ignored error messages, it will get incorporated
into production code, including pacemakers etc.  Therefore libraries
intended for use with pacemakers, anti lock brakes, and the like,
should die on error (which in the case of antilock brakes forces a
hard reboot.
Code intended for pacemakers and the like should be error free.  If
you write libraries intended to continue after error, you are writing
on the assumption that the pacemaker code will be buggy, and we don't
really care, we are going to ship it anyway, bugs and all into other
people's chests.  People who write code for pacemakers that continues
on error should be shot.
Halt on error is a tool for achieving error free code.  Error free
code is in fact achievable for really crucial applications.  The more
crucial the application, the more reason to write code that halts on
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      Cau3evB8n2DnP2D8ej3FHKKnKnMeseK65pUDF346
      4FbXJRaadlYWOfMnkhNKfdLxDaKNb58AoLBUm8ox9

@_date: 2006-02-14 12:44:39
@_author: James A. Donald 
@_subject: GnuTLS (libgrypt really) and Postfix 
--
 >>Libgcrypt tries to minimize these coding errors; for example there
 >>are no error returns for the RNG - if one calls for 16 bytes of
 >>random one can be sure that the buffer is filled with 16 bytes of
 >>random.  Now, if the environment is not okay and Libgcrypt can't
 >>produce that random - what shall we do else than abort the process.
 >>This way the errors will be detected before major harm might occur.
 >   I'm afraid I consider it instead a weakness in your API design
 >   that you
 > have no way to indicate an error return from a function that may
 > fail.
The correct mechanism is exception handling.
If caller has provided a mechanism to handle the failure, that
mechanism should catch the library generated exception.  If the caller
has provided no such mechanism, his program should terminate
Unfortunately, there is no very portable support for exception
handling in C.   There is however support in C++, Corn, D, Delphi,
Objective-C, Java, Eiffel, Ocaml, Python, Common Lisp, SML, PHP and
all .NET CLS-compliant languages.
Absent exception handling, mission critical tasks should have no
exceptions, which is best accomplished by the die-on-error standard.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      Ywzx2XsxbvPNX+eeGZVUpnq16108eQo1eBvq8K1I
      46HVM7avhGKHTF4Y1SqhFSUdIsTlbJvpXX43jkvQP

@_date: 2006-02-15 10:58:38
@_author: James A. Donald 
@_subject: GnuTLS (libgrypt really) and Postfix 
--
 > Halting on every exceptional condition is like amputating to cure
 > every headache.
 >
 > Keep in mind Dykstra's dictum:  testing can perhaps show the
 > presence of bugs, but testing can never show the absence of bugs.
For truly critical applications, and I have written one such, there
are better methods than testing.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      EQ0NuuGe3F81FVYLaVzuREVIM95sviNDw7cku0j6
      4MEZw0qU0NMPYTNTSCMcjRi7wZSGRo06TUwlSmzr8

@_date: 2006-02-16 09:36:16
@_author: James A. Donald 
@_subject: GnuTLS (libgrypt really) and Postfix 
--
 > Whatever happened to doing what's best for the customer?  Doing
 > what's most convenient for the programmer during testing, while
 > making things worse for the customer during deployment ... that
 > seems remarkably unprofessional.
It is usually better for the customer that the program does nothing,
than that it does something unexpected.
This is particularly true in mission critical applications, such as
for example a pace maker.  Would you rather have an inactive
pacemaker, or pacemaker busily doing something unexpected?
In the case in question, going bad means that the program appears to
be encrypting data, but is NOT encrypting data, or is only trivially
encrypting data.  This is far worse for the customer than an
encryption program that simply aborts.
 > Last but not least, I object (again!) to the false dichotomy, i.e.
 > the allegation that exceptional conditions must either
 >   a) result in an abort, or b) go undetected.
The correct solution to exceptional conditions is to use exceptions.
This is not always practical or available, though it should be.  The
whole world should move to C++.  If exceptions are not available, what
then do we do?  I say abort.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      yT/vxBNSRjFYGpU6iWTY1tvxDKTWkDa9wubFEmYD
      40btwbJ8sjQGTu/vmkD4fjY1gud+1641iRf+Uq+Pb

@_date: 2006-02-25 17:01:26
@_author: James A. Donald 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
--
 > > but if you want it to be encrypted to you, then you need to
 > > publish a key.
 > This IS one of the sticky points ;-) If postal mail would work this
 > way, you'd have to ask me to send you an envelope before you can
 > send me mail. This is counter-intuitive to users.
Public key should be part of signature.
 > Your next questions could well be how do you know my key is really
 > mine...
If key is part of signature, you know it really belongs to the person
who posted the item to which you are replying - and sometimes that is
the thing that you really want to know.
Of course you do not know that the person to which you are replying is
really the person he represents himself as being - is he really the
fraud control officer for your bank?  But presumably you are
interacting with the bank through its website, so you, or rather your
software, should damn well know the bank's public key, and the fraud
control officer's signature should have a certificate by the bank
attesting his relationship to the bank.
 > how do you know it was not revoked
It should be checked every time you logon to the bank, and every time
you logon, instead of telling the site your password, you proceed with
a zero knowledge proof where both parties prove knowledge of the
password without revealing the password.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      L4p0k6+mzp2x2QNOdALduMQfwAIXYrsJ3cVYYK4Q
      4iEeX76ichaV+J6eVImNtWEoGzvMmAHKNHHix+chD

@_date: 2006-01-03 15:10:37
@_author: James A. Donald 
@_subject: PKCS to XML? 
--
Is there any standard, better still existing code, for translating
keys and certificates and suchlike to and from XML?
I recollect an utterly useless standard for encrypted XML, which some
one described as a collection of toothpicks that one was supposed to
assemble into a boat, but that is not quite the same thing.
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     x7HSdxkv/c2zoTJF7n9vrmNpEhiSFAXRD6FAlbcM
     4KYwEbsOwZRupedV+quY2YciDAmLaxyYeulIr8mLr

@_date: 2006-01-03 15:28:23
@_author: James A. Donald 
@_subject: RNG quality verification 
--
 > To assess a cryptographic PRNG, you need to know two things:
 >
 > a.  If it had a starting point or seed which was impossible to
 > guess, would you be able to find any problems with its outputs?
 >
 > b.  Does it get a starting point or seed which is impossible to
 > guess?
 >
 > Assessing (a) is about cryptanalysis; statsitics can help there, but
 > mostly, you're looking at the output from some cryptographic
 > function like SHA1 or AES or 3DES.  Assessing (b) is about data
 > analysis--you're going to look at the sources for seed material, and
 > try to determine what makes them ultimately unpredictable, and to
 > model them somehow.  You can't assess how much entropy some variable
 > has without some kind of probability model for it.
All observables are necessarily theory laden.  Entropy and randomness
are more theory laden than most, so theory laden as to be impossible
to observe directly.  One must study what goes in, not what goes out.
 For any test, ask yourself this:  If the source of "random" numbers
was the current time, hashed with SHA and a sixteen bit fixed code,
would your test show any problem?
    --digsig
         James A. Donald
     6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
     KU60aORMS6eP2TWG+XjML/Cp7egySzT8UZW/n9Zo
     40TzrkMfMK52cZ0Rdu5DMlo9ngx84PkNXCHQrnXQ+

@_date: 2006-01-30 08:25:56
@_author: James A. Donald 
@_subject: Unforgeable dialog. 
--
One needs to differentiate dialogs brought up from within the browser
client, which are trustworthy unless one is infected with malware,
from popups brought up by some other web page. (Of course if popups
are disabled except for specific sites, this is considerably less of a
How would one construct a dialog from within Firebox so that it is
obviously different from any unprivileged web page that attempts to
imitate it?
(The motivation for all this is that is seems that the architects of
the major browsers are not looking for a solution to the phishing
problem. They are looking for a solution to the phishing problem that
fits into the existing business models of existing certification
The easy thing to do is to turn off the title bar and status bar, but
I am a bit worried that this is not glaringly obvious enough.
What I would really like to do is use transparency against the
desktop, so that I can have a non rectangular dialog, but it only
seems possible to do this in native mode, not obvious that it can be
done in XUL, despite XUL's supposed support for transparency, and
doing it in native mode seems much like hard work.
Another approach is to take advantage of the only-one-popup rule for
untrusted web pages, by popping up two related overlapping dialogs
which hold a fixed position relative to each other - which visually is
a sort of non rectangular dialog.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      qJqQUN0wUXXtijW2TJfv5Yy48BX++knDJaszNmZa
      4D3PdzF5yZbcUm6TB72kP6ruoofG27I+m2w7bWnro

@_date: 2006-07-06 13:52:51
@_author: James A. Donald 
@_subject: Quantum RNG 
--
 > About RNG, does someone in the list have any comment,
 > ideas on this
 >
 >  >
 > "Quantis is a physical random number generator
 > exploiting an elementary quantum optics process.
 > Photons - light particles - are sent one by one onto a
 > semi-transparent mirror and detected. The exclusive
 > events (reflection - transmission) are associated to
 > "0" - "1" bit values."
That is doing it the hard way.  The easy way is to
amplify shot noise or Johnson noise and feed it into a
shift register, with the output of the shift register
being mixed back in with the noise input, so that the
shift register contains a constant pool of continually
stirred entropy with fresh entropy being continually
stirred in.
When people use an microphone input with no microphone
as their major entropy source, they are using Johnson
noise as their entropy source, and doing the stirring in
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      2PU8nEsxKqJuKTcJtk5EoKYjFF0Uh/9Xr5sJ6nxm
      4YaYrOcfMCcakjCz0TyfilHAYuMSbGUG2qHHdxLBA

@_date: 2006-07-06 14:03:11
@_author: James A. Donald 
@_subject: Quantum RNG 
--
 > Quantum processes are in some very narrow theoretical
 > sense more "fundamentally" random than other sources
 > of randomness, such as thermal noise ... but they are
 > not better in any practical sense.
 >
 > The basic quantum process is less sensitive to
 > temperature than a purely thermal process ... but
 > temperature dependence is easily accounted for in any
 > practical situation, and -- more importantly -- there
 > are all sorts of other practical considerations (such
 > as detector dead-time issues) that make real quantum
 > detectors far from ideal.
 >
 > The devil is in the details, and obtaining the raw
 > data from a quantum process is nowhere near necessary
 > and nowhere near sufficient to make a good randomness
 > generator.
And if you want to obtain noise from quantum
indeterminacy, shot noise is much more convenient.
Instead of photons going through a half silvered mirror,
and randomly being reflected or not, you rely on
electrons randomly winding up at the base or the
collector of a transistor.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      /KNHHNPZ6iBsO6gvfPyHJxLKSHaisGIVaOLrrfDv
      4uxfFO8C/uuRkbz3u2rG4U8fpFKfzj+zr6czKsf69

@_date: 2006-07-06 14:05:49
@_author: James A. Donald 
@_subject: Quantum RNG 
--
 > Noise-based RNGs are just as random and just as
 > "quantum". :)
Shot noise is just as quantum.  Johnson noise (which
most hardware generators use) is thermal noise, so not
Not that the difference between thermal noise and
quantum uncertainty matters for our purpose, unless the
adversary is submerging your hardware in liquid helium.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      6/Bz2DNCS/RCxLZZ81/CcDfSM3d/+hJ0bvP8kbgc
      4oZaaVxdmcx2pdn23uM3fAXynWtWh3TkS/EO8X6ms

@_date: 2006-07-11 10:35:42
@_author: James A. Donald 
@_subject: NIST hash function design competition 
> I had not heard that there had been an official
 > decision to hold a new competition for hash functions
 > similar to AES.  That is very exciting! The AES
 > process was one of the most interesting events to have
 > occured in the last few years in our field.
 >
 > Seemed like one of the lessons of that effort was
 > that, even though it was successful in terms of
 > attracting the interest and hard work of some of the
 > top researchers in the field, in the end we have
 > learned considerably more about Rijndael's
 > vulnerabilities only after the process was over.
My understanding is that no actual vulnerabilities have
been found in Rijndael.  What has been found are reasons
to suspect that vulnerabilities will be found.

@_date: 2006-07-12 07:30:14
@_author: James A. Donald 
@_subject: Phishers Defeat 2-Factor Auth 
So long as logins are registered and performed in a web page, rather than in the chrome, we are hosed.
Creating a login, and logging into it, has to be a browser and email client function, not a web page function.

@_date: 2006-07-12 07:54:14
@_author: James A. Donald 
@_subject: Interesting bit of a quote 
--
 > Business ultimately depends on trust.  There's some
 > study out there - I don't recall a reference - that
 > basically finds that the level of trust is directly
 > related to the level of economic success of an
 > economy.  There are costs associated with
 > verification, some of them easily quantifiable, some
 > of them much harder to pin down.  The difficulty is in
 > making the tradeoffs.  We're now pushing way over on
 > the verification side, in a natural reaction to a
 > series of major frauds and scandals.
Sarbanes-Oxley substitutes formal procedures for real
relationships, but formal procedures are unlikely to
successfully substitute for real relationships.
Sarbanes-Oxley also forces those companies to which it
applies to have a large minimum size, since compliance
costs are so great, so one has a single company
embracing an excessively wide variety of activities,
which of course increases the need for trust, at the
same time as the oppressive bureaucracy of SO compliance
diminishes the supply of trust.
I think we will see in future big scams that comply with
the letter of Sarbanes-Oxley, without complying with the
What happened with Enron is that they simply made up
some figures, and then when suspicious investors started
to harass them, they proceeded to make up some accounts
that superficially justified those figures.  Had they
started with the accounts, instead of starting with the
fraud, they would have been pretty much in compliance
with what is now Sarbanes-Oxley.   So Sarbanes-Oxley
will not prevent another Enron, rather it will legalize
Sarbanes-Oxley makes it mandatory to do what suspicious
investors demanded of Enron - but it also makes it legal
to comply in form without necessarily complying in
substance.  It makes suspicion mandatory, rather than
making honesty mandatory - forbids trusting behavior,
rather than forbidding untrustworthy behavior.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      BtuKBOPO2RPPKVNZMPpxlQMVrOaMFO/q/qzhXTex
      4xGjYNrDxf0b1LuglGzrFFpJNIlrzvvB1U5BPjv/H

@_date: 2006-06-01 15:41:50
@_author: James A. Donald 
@_subject: Status of SRP 
--
 > "Phishing" can mean a few different things.  If by
 > "phishing" you mean the stealing of passwords, then
 > yes, SRP would help to eliminate that problem, but
 > users could still be fooled into giving away their SRP
 > passwords if the user interface for entering the
 > password is convincingly imitated.
SRP necessarily runs in the chrome, in the client
software, not in the web page, therefore the chrome,
should put up an image that cannot be convincingly
imitated by html - for example, on windows, a non
rectangular login page, as with paradox's keygen, or as
with the infocard software, taking over the entire
screen, including covering the taskbar, which an html
page cannot do.
In order to imitate that, the attacker would need
control of the client machine
 > I'm working on Passpet, a password management tool
 > that tries to address several of the big
 > phishing-related problems including password capture
 > and dictionary attack, and for the authentication part
 > i chose SRP.  So that's one place it's getting used,
 > anyway.
Cannot find a web page that presents passpet.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      ybM860Mr+CSlXrrR8xph9v0B91GQWJBI8SAGwuFs
      4B8M3YBCebHr5lGeEDBz+TIrbMLygWsXUEGxXWNj5

@_date: 2006-06-01 15:53:07
@_author: James A. Donald 
@_subject: Status of SRP 
--
 > > The obvious solution to the phishing crisis is the
 > > widespread deployment of SRP
Lance James
 > I disagree here, I don't think this will stop phishing
 > for many reasons. Please explain how it would. It will
 > stop "man-in-the-middle" attacks on the protocol, but
 > phishers aren't attacking the protocols themselves.
To be useful, SRP has to be in the browser chrome.
Consider a typical e-gold phish
: :	You have just made a request to transfer all
: :	the funds in your account.  Please click here
: :	 and login to cancel
: :	this request if it was made by someone other
: :	than yourself
Assume e-gold was using SRP login.  The user would
attempt to login to  through SRP, and the
login would fail.
 > It's still single-auth and I can still obtain the user
 > password via phishing.
SRP never reveals the login.  It is zero knowledge.
Instead, both parties prove to each other than they know
the secret, without revealing the secret.
The only way you can phish the user is to get him to not
use SRP.  But if he is attempting to use SRP he is not
typing the password into a web page, but into client
software running on his own machine, which is going to
look visibly different from any web page.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      bhZzlPU6DtnwH9s5+PxwPlwhgvD/8iFEI9LcuRXA
      4x54cCglld16xbMxUa/22CBHVIxtb7yqM78rQ9Ul1

@_date: 2006-06-01 16:01:57
@_author: James A. Donald 
@_subject: Status of SRP 
--
 > There is no way to force an end user to enter a
 > password only over SRP.
Phishing relies on the login page looking familiar.  If
SRP is in the browser chrome, and looks strikingly
different from any web page, the login page will not
look familiar.
 > Fortunately, it doesn't matter because today, we must
 > assume that the client is thoroughly compromised,
 > which means that entering passwords over SRP isn't
 > safe, either.
That is an all purpose argument that is deployed
selectively against some measures and not others.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      FngUFki/IKrJQzXmzcNmvTTH5ZAwHCQkTSIXkWVI
      4wPX3iZ25iE0SC3Pk6sdr5enUTiKLhPd829ew/9kX

@_date: 2006-06-02 08:55:37
@_author: James A. Donald 
@_subject: Status of SRP 
--
 > Passpet's strategy is to customize a button that you
 > click.  We are used to recognizing toolbar buttons by
 > their appearance, so it seems plausible that if the
 > button has a custom per-user icon, users are unlikely
 > to click on a spoofed button with the wrong icon.
 > Unlike other schemes, such as special-looking windows
 > or a custom image shown with the login form, this
 > strategy requires the user to directly interact with
 > the customized UI element.
This seems like a promising tactic, since a first step
in any process is "look for the button".  If user does
not see the button, will be troubled, will stop and
Any customization is an effective anti phishing measure:
Observe that eBay resists phishing by starting its
emails by addressing each user by logon name, and Amazon
resists phishing by extensively customizing its web page
to each user - by supplying non cryptographic evidence
of an existing relationship.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      O37xiq0aPJeqGc7fQTWWTY85hPPktIPGAwbDifVD
      4bDTmZTlI9gWsmLu9xhSdisgc26xogVtQOnIi5/DI

@_date: 2006-06-02 09:12:21
@_author: James A. Donald 
@_subject: Status of SRP 
--
 > Passpet's strategy is to customize a button that you
 > click.  We are used to recognizing toolbar buttons by
 > their appearance, so it seems plausible that if the
 > button has a custom per-user icon, users are unlikely
 > to click on a spoofed button with the wrong icon.
 > Unlike other schemes, such as special-looking windows
 > or a custom image shown with the login form, this
 > strategy requires the user to directly interact with
 > the customized UI element.
 >
 > The effectiveness of Passpet's approach is only
 > hypothesized; it has never been formally tested, so i
 > can't claim it works better.
 >
 >> Cannot find a web page that presents passpet.
 >
 > See >  > ishing/
This seems like a highly effective cure for phishing,
and one that can be implemented on the individual level
- and unlike my proposed solution, your solution does
not require competent web masters, who tend to be in
short supply.  When do you hope to release an actual
working passpet?
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      2XJ1hBQB4Lh88oartvxNB9R47imTGm9ijr/vCQ5S
      4tw2qTJbgf91cRjr3IilUO+alJWC4QViGoIqSUjWI

@_date: 2006-06-02 19:10:56
@_author: James A. Donald 
@_subject: Status of opportunistic encryption 
--
James A. Donald:
 > > My understanding is that SSH when using GSS KEX does
 > > not cache the keys, which strikes me as a amazingly
 > > stupid idea,
Victor Duchovni
 > No, that's the whole point. What works for the
 > individual administering 10 machines, does not scale
 > to organizations with hundres of administrators
 > managing tens of thousands of machines. With KEX you
 > trust Kerberos, not your key store.
  In an organization with hundreds of administrators
managing tens of thousand of machines, what goes wrong
with trusting your key store?  And who administers
Kerberos?  Don't they have a problem with tens of
thousands of machines?
 > Workable DNS-SEC exists, what lacks now is the will
 > and political muscle to make it happen.
I was unaware of this.  So I googled for DNSSEC. Reading
the DNSSEC documents I found
: :	"In order to support the larger DNS message
: :	sizes that result from adding the DNSSEC RRs,
: :	DNSSEC also requires EDNS0 support ([RFC
: :	671]). "
: :	"its authentication keys can be authenticated
: :	by some trusted means out of band from the
: :	DNS protocol."
This does not sound workable to me.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      N8PPaaHAyVJ5X84mwrNura/s/6xoxBy1I4SsvYnN
      4dTYtTbKIKIX2zUmbNeTi6z5NYSRZW+LcplUU9tST

@_date: 2006-06-03 14:25:55
@_author: James A. Donald 
@_subject: Status of SRP 
--
 > Unfortunately, SRP is not the solution to the phishing
 > problem. The phishing problem is made up of many
 > subtle sub-problems involving the ease of spoofing a
 > web site and the challenges involved in securing the
 > enrollment and password change mechanisms.
With SRP, the web site cannot be spoofed, for it must
prove it knows the  user's secret passphrase.
Now Wagner keeps complaining that the users are complete
morons, who could be taken in by a very shoddy spoof,
and no doubt that is true, but right now it is possible
to make a very good spoof, and that can be fixed.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      K0DkzvBcnUAkU1t725Cg9Fmh6awjA9b9S8SmmanA
      4HYHXPVEWxmojVTOmRDh7L/Eu6KRWMz3WCh5tL2Eq

@_date: 2006-06-03 14:33:48
@_author: James A. Donald 
@_subject: Status of SRP 
--
 > Here's where SRP fails:
 >
 > 1) SSL is built into the browser - doesn't stop
 > phishers
SSL protects true names, SRP protects true
relationships.  Protecting true names turned out to be
not very useful.
 > "Hi, we're having a problem with your account system
 > as our SRP database was corrupted, please login
 > through the webpage to verify your information and
 > reset your SRP account to working order".
They set up their SRP account through the chrome, not
through a webpage.  This attack fails to mimic what is
routine.  Phishing relies on mimicry and habit. The
poorer the mimicry, the less people are likely to fall
for it.  Certainly some people will fall for it, there
is a sucker born every minute, but right now we are
seeing phishing attacks that quite sophisticated people
fall for.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      7hBodKZ++GbmAsbf7YHZGQsErgEpvrEN+jMzkRVJ
      4jFzcd0zA2X0mdrrP52Wb9NZEOfARFgb0RMwwJCL7

@_date: 2006-06-06 08:14:46
@_author: James A. Donald 
@_subject: Status of opportunistic encryption 
Thomas Harold:
 > > I do suspect at some point that the lightweight
 > > nature of DNS will give way to a heavier, encrypted
 > > or signed protocol.  Economic factors will probably
 > > be the driving force (online banking).
 > E.g. RFC4033, RFC4034, RFC4035.
Well I wish it was going to happen, but right now
measures that are already deployed are not being used.
Except for e-gold, businesses under phishing attack are
not signing their email.
Since the proposed DNS signing relies on trusted root
keys transmitted out of band, it is not going to be
deployed either, for much the same reasons.   We need a
one click solution like SSH, or a zero click solution
like Skype.
And the proposed solution involves too many connections.
Any solution has to fit in a UDP datagram.

@_date: 2006-06-08 07:55:08
@_author: James A. Donald 
@_subject: Status of SRP 
--
 > part of x9.59 retail payment standard requires the
 > transaction to be authenticated. another part of the
 > x9.59 retail payment standard requires that the
 > account number in x9.59 retail payments can't be used
 > in non-authenticated transactions. it as been
 > recognized for a long time that a major source of
 > account financial fraud  has been the data breaches
 > Have any merchants adopted the X9.59 standard?
Is it in fact possible for a merchant to today take
orders over X9.59?
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      SCLw5bENxW3GhAPjMCCFxAZNTWWplgH3XHfzZejK
      4wUo1x4tRVdskoDX1ZgiomicCYwgwFPLepwR04i2a

@_date: 2006-03-02 06:14:49
@_author: James A. Donald 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
--
 > The real question with ECC, other than patents, which don't seem to
 > interfere too much right now and will gradually go away, is how long
 > the keys need to be, and how long they can be trusted. ~~160-bit
 > keys were short enough to be convenient. 256-bit is probably about
 > the limit - I've seen some discussion of 512-bit keys, and at that
 > point you're pushed into message formats that make it inconvenient
 > to exchange keys again. Is there a consensus view about what
 > keylengths are reliable?
Except for special cases, breaking an n bit ECC system involves
2^(n/2) EC operations, and EC operations are slow.
So 160 bits is sufficient, and 255 bits small enough to hand the keys
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      p2QzZm1xG7xN9AVFcM1MUIw3KDIAp2MG0bf6c6UU
      4hqypUw7qHAIittFmiU/1gQOoNSxTS+vQdHdbb0nT

@_date: 2006-03-10 08:09:56
@_author: James A. Donald 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
--
 > My claim is that, while indeed it is easier to set the initial
 > barriers higher when you design with greater hindsight, and some of
 > the tractable, but not widely deployed email security measures will
 > be there in IM systems from the start, never the less IM systems if
 > they are to encroach on the ubiquity of email for ad-hoc
 > communications between strangers (it is far easier to address
 > strangers via email today) will encounter exactly the same intrinsic
 > issues, and that technical measures will have equally partial
 > efficacy.
Total perfect and complete solutions will never be possible, but
stopping the most flagrant and inconvenient abuses is perfectly
feasible, and not even remarkably difficult.  These days you see
little spam on most Usenet groups, and one of the primary uses of
Usenet is ad hoc communication between strangers.
SSL works fine, PKI has serious problems. Usenet for the most part
works fine, Jabber works fine, email has serious problems
The federated structure of jabber, where random people connect to any
one of a very large number of privileged servers is similar to the
Usenet structure - and the Usenet structure works because for your
server to retain your privileges, you need to control spam.
 > I am willing to speculate that people will continue to unfairly
 > tarnish the competence of the email RFC writers, without regard to
 > the intrinsic properties of the medium.
It is not so much that they were incompetent, but that they were
writing for a more trusting and trustworthy world.  Today, we have to
do things differently.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      PRRq2Za8iG5qzD2wX3ug3xGXEWyekUqHQTZAspUQ
      4Mjw8nFOqtf9erylBgQZo+5aUTVPzgKVdij0TQUDs

@_date: 2006-05-16 10:33:06
@_author: James A. Donald 
@_subject: picking a hash function to be encrypted 
--
 >> So...
 >>
 >> Suppose I want a function to provide integrity and
 >> authentication, and that is to be combined with a
 >> stream cipher (as is the plaintext).  I believe that
 >> authentication is free once I have integrity given
 >> the fact that the hash value is superencrypted using
 >> the stream cipher, whose key is shared by only the
 >> sender and recipient.
 > It's not safe to use a hash function this way if the
 > content is known to the attacker.
The content therefore should always contain something
random - which other parts of the protocol usually
require for other reasons.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      j4gjR2yE9L2n/vvjYFQUivo5ojBm6HCmxw83+X+g
      4016yUOsGdYzWmpwqKkShf8kATzoWg5BesEp42JuD

@_date: 2006-05-24 08:15:45
@_author: James A. Donald 
@_subject: Is AES better than RC4 
--
AES is new, and people keep claiming progress towards
breaking it, without however, so far producing any
RC4 is old and has numerous known weaknesses, which are
tricky to code around, and have caught many an
implementor - notice for example Wifi.  But these are
known weaknesses, and no new ones have turned up for
some time, nor does it seem likely that they will.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      aMGHaG1NbogokuNeDdZ0lhGIuup5dcnanNmv/M3z
      4bFF4Yq8bD+vAGqsKwFG62Fy4ZEiJb+gVrl+FMJjh

@_date: 2006-05-24 19:51:16
@_author: James A. Donald 
@_subject: Is AES better than RC4 
--
James A. Donald
 >> AES is new, and people keep claiming progress towards
 >> breaking it, without however, so far producing any
 >> breaks.
 >>
 >> RC4 is old and has numerous known weaknesses, which
 >> are tricky to code around, and have caught many an
 >> implementor - notice for example Wifi.  But these are
 >> known weaknesses, and no new ones have turned up for
 >> some time, nor does it seem likely that they will.
 > I'm confused. AES is a _block_ cipher while RC4 is a
 > _stream_ cipher. How are you going to compare them?
The question is, what is likely to be secure (assuming
no errors in the code or protocol, assuming the protocol
accommodates the known weaknesses of RC4.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      r+jgJN/UZnI2Ndd0y5iy/yo4PpzCqxx4/Ouqmr0y
      42RAM+28IfhN9Xrs5LS5o3jt9p73L5MSyLOzwwWT4

@_date: 2006-05-24 19:54:02
@_author: James A. Donald 
@_subject: Is AES better than RC4 
--
 > RC4 should have been retired a decade ago,
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      pvLUSroPw35whI+/0Tq1IYPZh/GDEidGMu+4KvZc
      4zyBqLBt4fFho62NSUZuECGjiLrFpqppx7lXuvebv

@_date: 2006-05-31 08:56:53
@_author: James A. Donald 
@_subject: Status of opportunistic encryption 
--
 > > It seems to me opportunistic encryption has moved to
 > > the application layer, at least as far as Internet
 > > mail is concerned.  Many MTAs use TLS automatically
 > > with whatever certificates they can get.  Of course,
 > > this only guards against active attacks, but it
 > > seems to me that this is a reasonable threat model.
 > It only guards against *passive* eavesdropping. Active
 > attacks can forge DNS MX records, inject BGP routes,
 > ... Actual MITM resistant peer authentication with
 > SMTP+TLS is extremely rare. I know it happens
 > sometimes because I have it running for a small number
 > of destinations, otherwise I would suspect that nobody
 > is doing it.
Active attacks are rare, possibly nonexistent except for
Wifi.  If NSA and the other TLAs were doing active
attacks, they would be detected some of the time.  They
don't like being detected.
If anyone does an active attack, this is a one off
event.  If someone routinely and regularly does active
attacks, the attack will be detected, the point where
they are modifying messages will be detected, and will
be bypassed.
 > I should also note that once one abandons the (still)
 > unrealistic assumption of a secure DNS, it is not just
 > SMTP + TLS that runs into trouble.
 >
 > For example, many Kerberos client libraries do a
 > forward lookup (to alias- expand CNAMEs) and some
 > perversely a reverse lookup (often the owner of the IP
 > address is the worst source of the machine's name),
 > and then give you a mutually authenticated channel to
 > whatever principal they construct from now rather
 > questionable data. This carries over to SASL GSSAPI,
 > where GSSAPI abstraction makes working around this (in
 > practice nobody tries even with native Kerberos) even
 > harder.
 >
 > Consequently, also SSH with GSS KEX, is not MITM
 > resistant when the attacker can tamper with DNS
 > responses.
My understanding is that SSH when using GSS KEX does not
cache the keys, which strikes me as a amazingly stupid
idea, particularly when SSH key caching has been so
successful, and when the user thinks he knows his
security comes from key caching.  The experience with
PKI suggests that it is very difficult to have security
without durable cached keys.
 > Ultimately, to close similar security issues in many
 > other protocols, we need a secure DNS, but I am
 > somewhat pessimistic about the likelihood of this
 > happening soon.
Attacks on DNS are common, though less common than other
attacks, but they are by scammers, not TLA agencies,
perhaps because they are so easily detected.
All logons should move to SRP to avoid the phishing
problem, as this is the most direct and strongest
solution for phishing for shared secrets, and phishing
for shared secrets is the biggest problem we now have.
Encrypting DNS is unacceptable, because the very large
number of very short messages make public key encryption
an intolerable overhead.  A DNS message also has to fit
in a single datagram.
To accommodate these constraints, we need DNS
certificates sent in the clear, and signed with elliptic
curve public keys (which allow both signatures and
certificates to be short enough to fit in a datagram).
The client walks the  certificate chain from time to
time and it caches the certificates, to avoid
excessively loading the issuers of higher level
But this is all theoretical at this stage, for DNS
attacks are not our biggest problem.  Once we have
deployed systems that make it difficult to snoop and
scam without attacking DNS, *then* we will see DNS come
under heavy attack, and *then* there will be motivation
to change the DNS system.
After all, we have not fixed or replaced PKI, despite
the enormous phishing attack that renders it useless and
irrelevant, so we are going to be slower still fixing
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      cwXK8++rEMivkYVd+uiumb8CD2CVphnQhorYYVxx
      4KsvRJfxM5XZMseazJM4sjSoGS386TnYrCiBhfQuF

@_date: 2006-05-31 09:41:57
@_author: James A. Donald 
@_subject: Status of SRP 
The obvious solution to the phishing crisis is the widespread deployment of SRP, but this does not seem to happening.  SASL-SRP was recently dropped.  What is the problem?

@_date: 2006-11-14 11:37:57
@_author: James A. Donald 
@_subject: Citibank e-mail looks phishy 
Before computers, people had a lot of procedures that they routinely and ritualistically followed to prevent fraud, faithfully following the required procedures without ever thinking much about why things were done that way.  It seems that some time during the seventeenth and early   eighteenth century, various captains of finance laid down the law "It shall be done thus", so very firmly that for the next few hundred years, no one deviated.
But right now, we are inventing things, and we have not yet figured out how to do stuff right.  Further, the tools available do not really fit the task at hand, so it is unsurprising if people keep using them upside down and backwards.
I imagine that when our ancestors first figured out how to flake stones to form really sharp blades (and a well flaked blade will cut like broken glass) there were lots of people cutting their fingers off, despite the experts telling them how to correctly handle blades, until eventually the next genius figured out how to connect a sharp stone blade to a wooden handle.  It then became a lot easier for the wise woman to say "hold a knife by the handle except when handing it over, and don't run with a knife."

@_date: 2006-11-15 10:09:09
@_author: James A. Donald 
@_subject: Citibank e-mail looks phishy 
--
 > It's a curiosity of the financial industries that they
 > repeatedly forget what they've learned!  Architects
 > design buildings that stay up.  Engineers build
 > bridges that don't fail when the wind blows. Doctors
 > abandon treatments that kill patients and don't go
 > back to them.  In most fields, failures are translated
 > in to "best practices" that are used to produce codes
 > and rules and educational methods and such that avoid
 > repeating those failures - and remain in force pretty
 > much forever (sometimes beyond their useful lifetime,
 > but that's a different problem).  In "lower finance",
 > there are plenty of such safety rules - e.g., the
 > person who authorizes the check is never the person
 > who signs the check - that are followed pretty
 > consistently.  But the guys in "high finance" all
 > think they know better....
The failures of high finance are more subtle.  They push
the boundaries of what people can easily comprehend. Not
one person in a thousand - no regulators, and not many
accountants, understand what went wrong with Enron,
though quite a lot of investors and creditors
And the failures we deal with on this list are rather
subtle also, though a different kind of subtlety.
The failure of Andersen and Enron is not being fixed,
and the failures we are looking at on this list - the
Citibank e-mail - are not being fixed either.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      eE+Hr+U1GqPao1Inds9dB9Q0HfHwM9YSsSQ4+Jwi
      4Jm7UaRiBpmral0d/LItFMy5NzWza+GZ15vg7ZQGF

@_date: 2006-10-02 08:30:47
@_author: James A. Donald 
@_subject: signing all outbound email 
> recently published IETF RFC
 >
 > ... from my IETF RFC index
 >  >
 > 4686 I
 >  Analysis of Threats Motivating DomainKeys Identified
 >  Mail (DKIM),
 > Fenton J., 2006/09/26 (29pp)     (.txt=70382) (Refs
 > 1939, 2821, 2822, 3501, 4033) (was
 > draft-ietf-dkim-threats-03.txt)
 >
 > from the introduction:
 >
 > The DomainKeys Identified Mail (DKIM) protocol is
 > being specified by the IETF DKIM Working Group.  The
 > DKIM protocol defines a mechanism by which email
 > messages can be cryptographically signed, permitting a
 > signing domain to claim responsibility for the use of
 > a given email address.  Message recipients can verify
 > the signature by querying the signer's domain directly
 > to retrieve the appropriate public key, and thereby
 > confirm that the message was attested to by a party in
 > possession of the private key for the signing domain.
 > This document addresses threats relative to two works
 > in progress by the DKIM Working Group, the DKIM
 > signature specification [DKIM-BASE] and DKIM Sender
 > Signing Practices [DKIM-SSP].
In order for this to actually be any use, the recipient
needs to verify the signature and do something on the
basis of that signature - presumably whitelist email
that genuinely comes from well known domains.
Unfortunately, the MTA cannot reliably do something - if
it drops unsigned mail that is fairly disastrous, and
the MUA cannot reliably check signatures, since the MTA
is apt to mess the signatures up.

@_date: 2006-10-03 11:11:36
@_author: James A. Donald 
@_subject: signing all outbound email 
> > In order for [DKIM] to actually be any use, the
 > > recipient needs to verify the signature and do
 > > something on the basis of that signature -
 > > presumably whitelist email that genuinely comes from
 > > well known domains.
 > >
 > > Unfortunately, the MTA cannot reliably do something
 > > - if it drops unsigned mail that is fairly
 > > disastrous, and the MUA cannot reliably check
 > > signatures, since the MTA is apt to mess the
 > > signatures up.
 > so what if an isp only signs email where the origin
 > address is the same as the claimed email "from"
 > address.
 >
 > then email that claims to be from such an isp, that
 > isn't signed, might assumed to be impersonation.
Then you get into the same problem as with SPF.
Obviously the problem can be solved, it is not even hard
to solve, but the solutions we have now do not actually
 > ISPs could do ingress filtering where they only
 > process incoming email from their customers ...
There are lots of excellent, and reasonably simple
solutions, that work if everyone alters their behavior
except for a few wicked malefactors, and all software is
fixed up so that it works with the new solutions, but
the solutions that are actually under way right now do
not work well when there is a mix of old and new
software, and old and new practices.
In order to get to the end state where email is secure,
each step along the path has to be in the interests of
the individual making the change.  It is easy to imagine
an end state that is better than what we have now.  The
trouble is that part way to the end state also has to be
better than what we have now.
We need a solution that is good for the individual to
implement right now, and also solves the problem if most
people implements it - has increasing network effects.
 > ISPs could also start to quarentine unsigned email
 > that claims to have originated from ISPs that are
 > known to sign email.
But, in practice, domains cannot control the behavior of
people who legitimately use that email domain name, so
people do not in practice follow the sender policy
framework.  If an ISP drops mail that violates another
ISP's sender policy framework, it is intolerable,
because most of the mail dropped will be legitimate.
Filtering has to be done client side, where the client
can judge what is good for him, what works for him.
The solution is for the recipient MTA to add all the
authenticity information that it can get into the mail
headers, and for the client side filtering software to
pay attention to these MTA headers - but that is not the
solution we have.

@_date: 2006-10-04 06:02:31
@_author: James A. Donald 
@_subject: Hamiltonian path as protection against DoS. 
--
 > How do Hamiltonian paths protect against the H.R.4411
 > attack?
H.R.4411 is not a DoS attack.
 > (Part of the DoS problem online casinos face is that
 > due to their activity, which was illegal before, they
 > are extremely reluctant to approach law enforcement
 > about this matter.)
I was unaware that law enforcement does anything about
DoS attacks.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      J/PQ9VnDD/6V3E2EFdJ5YlRKN1f8VW3eeiOrlW0n
      4ZN9+U3RbPuc6REG0rZS2Bz/81I7N5FBe2J2FMkrR

@_date: 2006-10-06 09:44:35
@_author: James A. Donald 
@_subject: Why the exponent 3 error happened: 
--
 > Actually, encoding lengths of other fields in a
 > protocol is probably the easiest way to introduce a
 > remotely-exploitable vulnerability (typically buffer
 > overflow).  I'm going to have to side with the "no
 > redundancy means no inconsistencies possible" argument
 > here.  Oh, and you shouldn't process
 > remotely-manipulable data in a language like C, unless
 > you're doing all variable-length buffer management
 > through a well-tested library, and even then you're
 > playing with fire.
All fields that could be controlled by an adversary
should have reasonable maximum values specified in the
protocol definition.  Consider the language field in
HTTP.  It normally is blank, or contains the string
"English".  A lot of implementations failed in ways
interesting to attackers when the language field
exceeded 20K, and wound up executing script contained in
the language field.  Why were language fields not given
a reasonable maximum length, and reasonable limits on
the characters permitted in the language field, and an
error response defined for the case that the language
field exceeded that limit, or contained improper
The only fields that should be permitted to have
unbounded length are those that can be pipelined, where
you repeated fill a fixed length buffer, and repeatedly
empty it.
 > And fixed-length buffers are often broken too, because
 > many a programmer has arbitrarily decided "that's big
 > enough" without considering how an active adversary
 > would be constrained, or without considering that the
 > data may grow in size with the next revision of
 > (whatever is feeding data to us).
All fixed length buffers are of course broken unless the
length is part of the protocol.  Since there is, in
practice, always going to a maximum length, if only the
length at which the computer starts to run out of
memory, maximum lengths should be defined as part of the
protocol "The xxxx field is bounded by the first
whitespace character, or a maximum of 128 unicode
characters, whichever comes first."
Recall all the implementations that gave interesting
results when the length count overflowed to negative.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      /qepotdogioqKl6zqKb1307bOmyXeRzSTpBPmWcw
      4WtThf8IVl9id73YCBhzL8jl5yJ7wd+oc/GuW4E7o

@_date: 2006-10-09 20:03:40
@_author: James A. Donald 
@_subject: TPM & disk crypto 
Well obviously I trust myself, and do not trust anyone else all that much, so if I am the user, what good is trusted computing?
One use is that I can know that my operating system has not changed behind the scenes, perhaps by a rootkit, know that not only have I not changed the operating system, but no one else has changed the operating Further, I can know that a known program on a known operating system has not been changed by a trojan.
So if I have a login and banking client program, which communicates to me over a trusted path, I can know that the client is the unchanged client running on the unchanged operating system, and has not been modified or intercepted by some trojan.
Further, the bank can know this, and can just not let me login if there is something funny about client program or the OS.

@_date: 2006-10-10 14:40:26
@_author: James A. Donald 
@_subject: TPM & disk crypto 
--
 > However, this is the big problem with the TPM
 > according to the TCG spec. While you can remotely
 > verify that the system came up according to what you
 > installed there, you have no means to force it to
 > either come up the way you want, or to be in a clear
 > error state. That is the huge difference between the
 > verifiable booting the TPM provides and secure
 > booting, which would run only predetermined software.
 >
 > I assume that the TCG chose not to implement the
 > latter due to fear of public bashing...
What we want is that a bank client can prove to the bank
it is the real client, and not trojaned.  What the evil
guys at RIAA want is that their music player can prove
it is their real music player, and not hacked by the end
user. Having a system that will only boot up in a known
state is going to lead to legions of unhappy customers
who find their system does not come up at all.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      mzJSAlA4uoeaqcIPwxmdSTaMGpCr10BSXet2rKo+
      4C0qq8mGmz37gK89YinlEpVVumD1TtkcDOd8iHHGh

@_date: 2006-10-13 10:54:42
@_author: James A. Donald 
@_subject: TPM & disk crypto 
James A. Donald:
 >> Well obviously I trust myself, and do not trust
 >> anyone else all that much, so if I am the user, what
 >> good is trusted computing?
 >>
 >> One use is that I can know that my operating system
 >> has not changed behind the scenes, perhaps by a
 >> rootkit, know that not only have I not changed the
 >> operating system, but no one else has changed the
 >> operating system.
 > The argument that TPM can prevent trojans seems to
 > imply that the trojans are installed by modification
 > of raw storage while the OS is offline.
No it does not.
 > Btw, how the TCG allows to regularly change the kernel
 > for security patches and still keep the same
 > ``reported hash''?
It can report that the hash is a value that has
been blessed by signed software - and can report that
its list of reputable signing authorities is blessed by
Microsoft, and does not include me.

@_date: 2006-10-18 19:04:42
@_author: James A. Donald 
@_subject: hashes on restricted domains: random functions or permutations? 
More relevant is how many iterations it takes to get to a significantly smaller set.

@_date: 2006-09-08 07:02:21
@_author: James A. Donald 
@_subject: signing all outbound email 
--
 >>>
 >>>
 >>>> Has anyone created hooks in MTAs so that they
 >>>> automagically [sign email]
 >> [...]
 >>> Go look at  for many more
 >>> details.
 >>
 >> This approach is MTA-to-MTA...
 >
 > No, it's not. The receiving MTA *and/or* MUA can
 > verify signatures. That is clearly covered in the
 > protocol document.
I do not seem to be able to use DKIM to for spam
filtering.  I would like to whitelist all validly signed
DKIM from well known domains.
One way of doing this would be for the MTA to insist on
a valid signature when talking to certain well known
MTAs, and then my MUA could whitelist mail sent from
those well known MTAs
In short, I am not able to get any advantage out of
using this protocol, which means that there is no
advantage in sending me signed mail.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      htNnuqbJ9fv6n64IRfD1zA7lLKKr2izEKeU8gcTj
      4VIaWftcnkDyBJkkmq5thq8hruA/YIkpnczdJ3kzD

@_date: 2006-09-10 08:12:49
@_author: James A. Donald 
@_subject: Raw RSA 
Could you describe this attack in more detail.  I do not see a scenario where it would be useful.
The attacker can encrypt a subset of numbers - those that encrypt to a B smooth number, but for this to be useful to him, he has to find a number in the subset set that corresponds to what he desires to encrypt, which   looks like a very long brute force search.

@_date: 2006-09-10 08:30:53
@_author: James A. Donald 
@_subject: Exponent 3 damage spreads... 
--
 > Subject:
 > [dnsop] BIND and OpenSSL's RSA signature forging issue
 > From:
 > Ben Laurie  > Date:
 > Fri, 08 Sep 2006 11:40:44 +0100
 > To:
 > DNSEXT WG , "(DNSSEC deployment)"
 > , dnsop at lists.uoregon.edu
 >
 > To:
 > DNSEXT WG , "(DNSSEC deployment)"
 > , dnsop at lists.uoregon.edu
 >
 >
 > I've just noticed that BIND is vulnerable to:
 >
 >  >
 > Executive summary:
 >
 > RRSIGs can be forged if your RSA key has exponent 3, which is BIND's
 > default. Note that the issue is in the resolver, not the server.
 >
 > Fix:
 >
 > Upgrade OpenSSL.
 >
 > Issue:
 >
 > Since I've been told often that most of the world won't upgrade
 > resolvers, presumably most of the world will be vulnerable to this
 > problem for a long time.
 >
 > Solution:
 >
 > Don't use exponent 3 anymore. This can, of course, be done server-side,
 > where the responsible citizens live, allegedly.
 >
 > Side benefit:
 >
 > You all get to test emergency key roll! Start your motors, gentlemen!
This seems to presuppose that Secure DNS is actually in use.  I was unaware that this is the case.
What is the penetration of Secure DNS?
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      fLselD6l8fdbF1p4sjg3RQ2GXi+NnQ//1CymnfKs
      4+JAX1zwW3fSIStp6glgbAygK1zCuoMeiTigr4qmd

@_date: 2006-09-10 08:49:00
@_author: James A. Donald 
@_subject: signing all outbound email 
--
James A. Donald:
 > > One way of doing this would be for the MTA to insist
 > > on a valid signature when talking to certain well
 > > known MTAs, and then my MUA could whitelist mail
 > > sent from those well known MTAs
 > Yes, if you are willing to throw out messages whose
 > signatures are broken during transit.
Signatures should not be broken when transmitted
directly from the signing MTA to the receiving MTA.  If
they are, then there is a bug in the signing or the
receiving MTA, in which case the offending party has the
ability and incentive to fix the bug.  Signatures are
likely to be broken when the signature is being checked
by the MUA, because an MTA that knows nothing about
signatures will probably break them, but an MTA that
knows to check signatures should know not to break them.
James A. Donald:
 > > In short, I am not able to get any advantage out of
 > > using this protocol, which means that there is no
 > > advantage in sending me signed mail.
 > And there is no disadvantage either. There is
 > advantages for sending signed mail to users who have a
 > different threat model than you have,
I don't think anyone is a different position to me. DKIM
is usable in principle, but I am not able to benefit
from it in practice.  If I am not able to benefit from
it in practice, who is?
DKIM would be a good idea if done right.  It does not,
in fact, seem to be working at present.
Part of the problem is that part of the whitelisting
task has to be done on the MTA, and part on the MUA, and
no one has made any provision for keeping them in sync.
Seems to me, that DKIM, as implemented, implements the
high tech part of the solution, but not the actual nuts
and bolts details of the solution.
As with so many specifications, the DKIM spec is both
overspecified and underspecified - too much fluff and
bullshit, but missing essentials.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      xI3XYSEBPo53gqyefixu7gq7WbsD5RRhDxMekg3p
      4xjdOGVtm+v4uCubvbccar454roc1aGW3/J1OXrQp

@_date: 2006-09-10 21:32:52
@_author: James A. Donald 
@_subject: IGE mode is broken (Re: IGE mode in OpenSSL) 
--
 > Hi Ben, Travis
 >
 > IGE if this description summarized by Travis is
 > correct, appears to be a re-invention of Anton Stiglic
 > and my proposed FREE-MAC mode. However the FREE-MAC
 > mode (below described as IGE) was broken back in Mar
 > 2000 or maybe earlier by Gligor, Donescu and Iorga.  I
 > recommend you do not use it.  There are simple attacks
 > which allow you to manipulate ciphertext blocks with
 > XOR of a few blocks and get error recovery a few
 > blocks later; and of course with free-mac error
 > recovery means the MAC is broken, because the last
 > block is undisturbed.
 >
 > There is some more detail here:
 >
 >  gives a
list of integrity preserving techniques, most of them
patented - perhaps all of them patented.
Of the top of my head, I would think the following
method preserves integrity - but then who am I.  I
cannot prove it preserves integrity, whereas some of the
modes listed in url above have such proofs.
Let P(k) be the kth block of plain text.  We prepend a
random block, P(0) to the text, and append a fixed block
to the end.  If anything is altered, the fixed block at
the end will not contain the expected data, but will be
The adversary knows every block in the plain text
message except our P(0).  He can intercept and change
the encrypted message.  He wishes to modify the message
so that the intended recipient receives something
different from the message that the adversary knows he
should receive without the intended recipient realizing
something is wrong.
Let W(k) = P(k) + W(k-1) + W(k-1)&{W(k-1)}
Where & means bitwise and, and + means addition modulo 2
to the block size.
W(0) = P(0) (our random block, unknown to the adversary
or the recipient, and changing with every message.)
{} means encryption, {W(k-1)} is the block we get by
encrypting W(k-1)
We transmit T(k)= {W(k)} + W(k-1)|{W(k-1)} where |
means bitwise or, curly brace means encryption.
W(-1) is zero.
The adversary knows P(k), except for P(0), and can
intercept all transmitted values T(k).
Because the combination of addition and bitwise logical
operations is non linear, this method gets through a
loophole in Jutla's proof in
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      YQoZxoUUL1Yd2nQ51t9INEhGv6av+5inX+kWvsHX
      49/HJZZyTbJf7yBMbpd6xO13ERPibcb3683FhcMMI

@_date: 2006-09-11 06:33:59
@_author: James A. Donald 
@_subject: IGE mode is broken (Re: IGE mode in OpenSSL) 
Should read:
We transmit T(k) = {W(k)} + ((~W(k-11){W(k-1)})
where ~ means bitwise negation, | means bitwise or,
curly brace means encryption.

@_date: 2006-09-11 06:18:06
@_author: James A. Donald 
@_subject: Exponent 3 damage spreads... 
--
 > > What is the penetration of Secure DNS?
 > Anyone who is running any vaguely recent version of
 > BIND is DNSSEC enabled, whether they are using it now
 > or not.
I am not well informed about DNSSEC, but I am under the
impression that:
1.  Actually using DNSSEC is a major performance hit.
2.  Actually using DNSSEC requires manual secure master
public key distribution, which  people are disinclined
to do, and which may not scale very well, unless
unspecified institutions and arrangements are put in
3.  No one actually uses DNSSEC in the wild.
Please advice me if these impressions are wrong, or have
become outdated.
I realize that I sound like a cold wet sponge with a non
stop stream of unpleasantly negative posts, but one of
the reasons that cryptography is not widely used is that
the various standards, processes, and tools are not in
fact very usable.
Implementing protocols requires widespread consensus,
but when too many people show at a meeting then either
nothing gets done, or the outcome is extremely stupid,
or both, and anyone who points to big problems in what
is being done is dismissed as out of order or off topic
in order to create the semblance of progress, with the
result that what little progress occurs is usually in
the wrong direction.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      GrAiqEAJZ+JTHX8XzGkkIqdEZiBNsCxO48sjUIrp
      4Z3Mnj015pjujvoBENQ/n6+j9Kb3Q0DMKqWI/eKJR

@_date: 2006-09-14 14:02:04
@_author: James A. Donald 
@_subject: Exponent 3 damage spreads... 
It seems to me that the evil here is ASN.1, or perhaps standards that use ASN.1 carelessly and badly.
It is difficult to write code that conforms to ASN.1, easy to get it wrong, and difficult to say what in fact constitutes conforming to ASN.1 or at least difficult to say what in fact constitutes conforming to standard written in ASN.1
ASN.1 does the same job as XML, but whereas XML is painfully verbose and redundant, ASN.1 is crypticly concise.
People do not seem to get XML wrong all that often, while they endlessly get ASN.1 wrong, and endlessly disagree over what constitutes being right.
Obviously we do need a standard for describing structured data, and we need a standard that leads to that structured data being expressed concisely and compactly, but seems to me that ASN.1 is causing a lot of What is wrong with it, what alternatives are there to it, or how can it be fixed?

@_date: 2006-09-14 19:02:14
@_author: James A. Donald 
@_subject: Why the exponent 3 error happened: 
Why the exponent 3 error happened:
The signature consists of a number that when cubed, is
equal modulo N to the padded hash of the quantity to be
Part of the padding is the ASN.1 encoding of the hash.
Now suppose we had not ASN.1 encoded the hash.
Suppose the padding was simply
010101010101010 ... 10101010101010000 hash
with all leading zeros in the hash omitted, and four
zero bits showing where the actual hash begins.
Then the error would never have been possible.
ASN.1 provided additional redundant information, making
possible unexpected data layouts that should not
normally happen.  It had too much expressive power, too
much flexibility.  It could express cases that one does
not expect to deal with, could flex in more ways than
one's software is likely to be written for.
XML has even greater redundancy and flexibility, but has
the advantage that one can constrain it with a DTD that
guarantees that it will have the form, and only the
form, that one's software expects.
Still, usually the simplest way of dealing with data
that may be hostile and malicious is to use a data
format that is entirely free from redundancy, thus can
*only* have the expected form.  If there is no
redundancy in ones data, then one never has to deal with
cases where the data is inconsistent.
One is not always able to eliminate all redundancy, but
one always has to check that the data is of the expected
form, and the fewer forms it can has the easier that is.
ASN.1's crowning virtue is its flexibility, and we do
not want flexibility in possibly hostile data.

@_date: 2006-09-15 08:04:44
@_author: James A. Donald 
@_subject: Why the exponent 3 error happened: 
--
 >> Suppose the padding was simply
 >>
 >> 010101010101010 ... 10101010101010000 hash
 >>
 >> with all leading zeros in the hash omitted, and four
 >> zero bits showing where the actual hash begins.
 >>
 >> Then the error would never have been possible.
James A. Donald:
 > I beg to differ. A programmer who didn't understand
 > the significance of crypto primitives would (as many
 > did) just search for the end of the padding to locate
 > the beginning of the hash, and check that the next set
 > of bytes were identical to the hash, then return
 > "true". So
The hash is known size, and occurs in known position.
He does not search the padding for location, but
examines it for correct format.
 >
 > 01010101 ... 10101010101010000 hash crappetycrap
 >
 > would still be considered valid. There's a lot of code
 > out there that ignored the fact that after the FFs was
 > specific ASN.1 stuff, and just treated it as a defined
 > part of the padding.
And that code is correct, and does not have the problem
that we discuss.  Paying attention to ASN.1 stuff is
what is causing this problem.
Code is going wrong because ASN.1 can contain
complicated malicious information to cause code to go
wrong.  If we do not have that information, or simply
ignore it, no problem.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      8Jickn3nr3AE+2RW3jUC7DaHw6yD1gLpSTISH0F6
      4Bjf3VmASP+HQ4q0CYdRKgWFZxd/QnFOiartuob5Q

@_date: 2006-09-15 21:13:35
@_author: James A. Donald 
@_subject: Why the exponent 3 error happened: 
--
 > If so, I fear we are learning the wrong lesson, which
 > while valid in other contexts is not pertinent here.
 > TLS must be flexible enough to accommodate new
 > algorithms, this means that the data structures being
 > exchanged are malleable, and that implementations must
 > validate strict adherence to a specifically defined
 > form for the agreed algorithm, but the ability to
 > express other forms cannot be designed out.
There is no need, ever, for the RSA signature to encrypt
anything other than a hash, nor will their ever be such
a need.  In this case the use of ASN.1 serves absolutely
no purpose whatsoever, other than to create complexity,
bugs, and opportunities for attack.  It is sheer
pointless stupidity, complexity for the sake of
complexity, an indication that the standards process is
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      mKNEZf/r5lZqyGpNhzkQ0zdt2uAdaxkSyyyxAW3W
      4BWO8prrBiE/VfMik8xpeS4TgD+5KsqGSGeRw2Dxr

@_date: 2006-09-16 11:16:15
@_author: James A. Donald 
@_subject: Exponent 3 damage spreads... 
--
 > Right, but it's been pure luck that that particular
 > implementation (and most likely a number of others)
 > happen to have implemented only a small number of hash
 > algorithms that allow only absent or NULL parameters.
 > Anything out there that implements a wider range of
 > algorithms, including any that allow parameters, is
 > most likely toast.
Parameters should not be expressed in the relevant part
of the signature.  The only data that should be
encrypted with the RSA private key and decrypted with
the public key is the hash result itself, and the
padding.  If the standard specifies that additional
material should be encrypted, the standard is in error
and no one should follow it.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      sVNWfKHHWrogEro6rkjKzE2XEHGqyk1tXLiayWU7
      4joW/r8h3DIfdlwaI5up/06PSaWuhEtwMmF9TsuGR

@_date: 2006-09-16 12:03:01
@_author: James A. Donald 
@_subject: Exponent 3 damage spreads... 
--
James A. Donald:
 > > Obviously we do need a standard for describing
 > > structured data, and we need a standard that leads
 > > to that structured data being expressed concisely
 > > and compactly, but seems to me that ASN.1 is causing
 > > a lot of grief.
 > >
 > > What is wrong with it, what alternatives are there
 > > to it, or how can it be fixed?
 > In SPKI we used S-Expressions.  They have the
 > advantage of being simple, perhaps even too simple.
 >
 > In describing interfaces in the KeyKOS design document
 >  s/keywelcome.html> we used a notation similar to
 > S-Expressions which was:
 >
 > (length, data)
The trouble with S-expressions is that as with
ASN.1-DER, all data structure is specified at run time,
in the sense that the run time data can have any
structure whatsoever. Thus the program parsing the data
has to be able to handle all possible data structures
whatsoever - including unexpected data structures
ingeniously concocted by an adversary to exploit flaws
in the program.  Run time description of data structure
should be a special case, an exception.
If the data can parsed at run time, without advance
knowledge of how the data is supposed to be structured,
without knowing what the header signifies, then it is
possible for an adversary to create complications by
structuring the data differently from the way it is
expected to be structured.
We need a system where the structure of the data is
largely determined by the header, and usually entirely
determined by the header, which is an arbitrary
identifier, not a description of one of an infinite
variety of possible data structures.  The recipient sees
the header, knows therefore what the structure of the
data must be, and proceeds to parse it as having that
structure, and in fact there is should be no run time
internal structure. If you do not know what the header
means, you should not be able to parse the data.  If you
could, then the adversary could create unexpected
Alternatively, we could have a system that allows
arbitrary run time structure, but with a general purpose
filter that absolutely guarantees expected structure,
rather than the programmers checking structure ad hoc in
each particular program.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      10vNqS4ChWmjQinDgd1a61m4GCk0hxC9KXi2Hy+N
      4jgO2FPYh3FS3oJk07kNEMuYXdYZlJNtCqort+Lwh

@_date: 2006-09-16 12:30:52
@_author: James A. Donald 
@_subject: Why the exponent 3 error happened: 
--
 >> Code is going wrong because ASN.1 can contain
 >> complicated malicious information to cause code to go
 >> wrong.  If we do not have that information, or simply
 >> ignore it, no problem.
 > This is incorrect. The simple form of the attack is
 > exactly as described above - implementations ignore
 > extraneous data after the hash. This extraneous data
 > is _not_ part of the ASN.1 data.
But it is only extraneous because ASN.1 *says* it is
If you ignore the ASN.1 stuff, treat it as just
arbitrary padding, you will not get this problem.  You
will look at the rightmost part of the data, the low
order part of the data, for the hash, and lo, the hash
will be wrong!
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      UXewrm6/A/3rklAbGfwShB29YFqjqqWLa3AU+htK
      4Xf+hOFyYI4Pv0jWjzDC226z/LHorwYhZlhfNvl2z

@_date: 2006-09-16 12:35:08
@_author: James A. Donald 
@_subject: A note on vendor reaction speed to the e=3 problem 
--
 > > How does [GPG] handle the NULL vs.optional
 > > parameters ambiguity?
David Shaw:
 > GPG generates a new structure for each comparison, so
 > just doesn't include any extra parameters on it.  Any
 > optional parameters on a signature would cause that
 > signature to fail validation.
 >
 > RFC-2440 actually gives the exact bytes to use for the
 > ASN.1 stuff, which nicely cuts down on ambiguity.
This amounts to *not* using ASN.1 - treating the ASN.1
data as mere arbitrary padding bits, devoid of
information content.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      KBZXRF1divvJGZ6Zm3lHv3qjnS9Bwhl22NfSlYK3
      4zPRSIE0Q6qUaTtmKPPoKOsPNzAtcdWuthGi5nNTi

@_date: 2006-09-16 13:00:14
@_author: James A. Donald 
@_subject: IGE mode is broken (Re: IGE mode in OpenSSL) 
--
James A. Donald
 > > > We transmit T(k)= {W(k)} + W(k-1)|{W(k-1)} where |
 > > > means bitwise or, curly brace means encryption.
 > > Should read: We transmit T(k) = {W(k)} +
 > > ((~W(k-11){W(k-1)}) where ~ means bitwise negation,
 > > | means bitwise or, curly brace means encryption.
 > Today wasn't a good day for typing? ;-)
 >
 > T(k) = {W(k)} + (~W(k-1)|{W(k-1)})
 >
 > Right?
Yes, right, though usually when I get two errors in
rapid succession, I get a third error.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      ORlgCbjNlrRQnTh47hjBg73t8LHfUA5a95TWiM1J
      4GftBho6JL/7abDky8QXOX9fhwJxrXqtP87dChEdo

@_date: 2006-09-16 20:54:55
@_author: James A. Donald 
@_subject: Why the exponent 3 error happened: 
--
 > > > > Code is going wrong because ASN.1 can contain
 > > > > complicated malicious information to cause code
 > > > > to go wrong.  If we do not have that
 > > > > information, or simply ignore it, no problem.
 > > > This is incorrect. The simple form of the attack
 > > > is exactly as described above - implementations
 > > > ignore extraneous data after the hash. This
 > > > extraneous data is _not_ part of the ASN.1 data.
 > > But it is only extraneous because ASN.1 *says* it is
 > > extraneous.
 > >
 > > If you ignore the ASN.1 stuff, treat it as just
 > > arbitrary padding, you will not get this problem.
 > > You will look at the rightmost part of the data, the
 > > low order part of the data, for the hash, and lo,
 > > the hash will be wrong!
 > If you ignore the ASN.1 stuff then you won't know what
 > hash to calculate.
If true, irrelevant.  If true, it would merely imply
that they should not have used ASN.1 to represent the
hash type.
But in fact it is not true.  I suspect a lot of
implementations decide the hash type by looking for
particular byte values at particular fixed locations,
rather than by deciphering the data as ASN.1.
To repeat my argument:  A program can only correctly
handle a small number of fixed data layouts, but ASN.1
can express an infinite variety of layouts, giving great
scope for malicious data.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      bUm91GJmI9zp9B7QNyHcQVSy/PJPz6xQb/PIepFe
      47yymkER8iV/Dv/2S5EmJ4XMufQI8aDE8j3ZF80nl

@_date: 2006-09-17 12:15:47
@_author: James A. Donald 
@_subject: A note on vendor reaction speed to the e=3 problem 
--
 >> GPG was not vulnerable, so no fix was issued.
 >> Incidentally, GPG does not attempt to parse the
 >> PKCS/ASN.1 data at all.  Instead, it generates a new
 >> structure during signature verification and compares
 >> it to the original.
 > *That* is the Right Way To Do It. If there are
 > variable parts (like hash OID, perhaps), parse them
 > out, then regenerate the signature data and compare it
 > byte-for-byte with the decrypted signature. Anything
 > you don't understand/control that might be variable
 > (e.g. options) is eliminated by this process.
 >
 > I don't think there's anything inherently wrong with
 > ASN.1 DER in crypto applications.
If there are no options, you are not using ASN.1 DER.
You are using some random padding bytes that happen to
be equal to ASN.1 DER.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      mMZpx7gaL6S/5STlYWv0A0ZM+HqCZSD2m0ClWjxL
      4UR16e+x3Uv/VW8C0Swxx9XMPtH99PEBNIc6BzpkQ

@_date: 2006-09-17 12:19:09
@_author: James A. Donald 
@_subject: A note on vendor reaction speed to the e=3 problem 
--
 > Anyway, the attack applies even if you throw away the
 > ASN.1 data.
If you ignore the ASN.1 data you expect the hash to be
in a fixed byte position, so the attack does not apply.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      qF2+GCfNPchHe4vzSkkYoOEjOI5i/kZtLIlyTUbX
      45tXJAuT/Tj9w0qpg0VFij8GrtY2JXG05fj6YE6M2

@_date: 2006-09-18 12:13:30
@_author: James A. Donald 
@_subject: Exponent 3 damage spreads... 
--
 > It seems to me that e=3 is a distraction.  I think
 > that these security holes have revealed some more
 > fundamental issues here that are independent of the
 > value of e you use.
 >
 > It seems to me that the problems can be attributed to
 > two problems: (a) implementation bugs (failures to
 > implement the spec faithfully); and (b) ad hoc
 > signatures schemes that have never been adequately
 > validated. In more detail:
 >
 >   (a) Any implementation that doesn't check whether
 >   there is extra junk left over after the hash digest
 >   isn't implementing the PKCS standard correctly.
 >   That's a bug in the implementation.  Of course, as
 >   we know, if you use buggy implementations that fail
 >   to implement the specification faithfully, all bets
 >   are off
 >
 >   (b) The discussion of "parameter fields" in PKCS
 >   signatures illustrates a second, orthogonal problem.
 >   If your implementation supports appending additional
 >   parameter fields of some general structure, then you
 >   have not implemented conventional PKCS
 >   signatures as they are usually understood; instead,
 >   you have implemented some extension.  That raises a
 >   natural question: Why should we think that the
 >   extended scheme is still secure?
When a protocol is successful, pretty soon it comes in a
large number of variants, all of which have to coexist -
the original version, several upgraded versions,
different interpretations of the spec, buggy
interpretations of the spec and Microsoft style "embrace
and extend" interpretations of the spec designed to
deliberately hamstring interoperability.
Therefore one generally makes provisions for future
expansion - for additional fields in a record,
additional types of records.   ASN.1, S-expressions, and
XML permit essentially limitless future fields.  That is
dangerously great flexibility.  On the other hand, TCP
format turned out to permit too little flexibility.
GPG's concept of "records" seems to me are reasonable
way of providing future expansion, without requiring the
programmer to handle potentially limitless future
expansion of every possible bit of organized data, a
task at which the programmer is likely to fail.
In general, a communication should tell what program and
version the communication is coming from, so that future
programs can say "oh, I am talking to someone old
fashioned, so must talk in the old fashioned dialect."
(Though for conciseness, this probably should not be in
human readable form, but in some cryptic set of bytes
that are agreed to stand for some particular program.)
It should also be able to specify that it is like some
other program, some program that became a de facto
standard that everyone has to be able to interoperate
with, saying "If you don't recognize me, assume I am
this other program, and it will work well enough".  The
communication should also identify that it is in accord
with some particular standards document (again, probably
with a cryptic set of bytes rather than a verbose url),
so that the recipient knows that this communication
version 1.0 format, or version 1.1, or the emergency
fixed version of version 1.1, though if the standards
document was good enough, which it seldom is, it would
not be necessary for the program to identify itself, or
to reference particular concrete implementations.
But still, we likely need programs that only understand
1.0 format to have some success when they receive 1.1
format, and this is where the expandability of ASN.1 and
the rest is useful - and dangerous.
I would suggest that communication occurs in records
that correspond to database records and to C++ objects,
and that some records be defined with provision for
future expansion, and other records not so defined,
according to the judgment of the people defining the
original protocol.  With ASN.1, XML, and S-expressions,
*everything* has provision for future expansion, which I
suggest is dangerously excessive.
If the 1.0 protocol contains an error, they find that
the 1.1 protocol needs some more fields in the record,
and no provision has been made for future expansion,
then they either define a new type of record replacing
the old, (thereby guaranteeing that 1.0 programs will
fail to interoperate when this new record is used) or
define an additional record supplementing the old, which
the 1.0 programs will ignore, handling only the records
they recognize.
Coming back to the case at hand, we should have had a
signature record that only allowed a one particular kind
of hash, and nothing but the hash, and no future
expansion, then when people realized that was a problem,
that unforeseen new hashes would need to be introduced
over time, they should have then introduced an
incompatible signature record that defined the hash
type, and the hash, and allowed for no future expansion.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      /zedskWwjM7YJCe3zo2C7y0GDwUQjP+BN9ayEeww
      4Y0kilizvKF0KpOu7fT86djxwW1ghxrvqfCKm1sKc

@_date: 2006-09-19 13:07:46
@_author: James A. Donald 
@_subject: Why the exponent 3 error happened: 
--
 > Again, there is no problem in ASN.1 or PKCS that is
 > being exploited here, only an implementation flaw,
 > even if it is an interesting one.
But why did several people independently implement the
same or similar flaws?
The answer is in Jack Lloyd's post:
 > I wrote a decoder for PKCS v1.5, realized it
 > probably had bugs I wouldn't figure out until too
 > late, [...] my PSS verification code is probably
 > around twice the length of the PSS generation code,
 > due to the need to check every stupid little thing.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      kcayKvWlPFXTPP9oNsxdS/f7Cu706I0sQMBSZJUj
      4578L9TLcVLPN7c++p1/Un4LFV6ugOy6Pb/SpWw2u

@_date: 2006-09-22 12:37:35
@_author: James A. Donald 
@_subject: Did Hezbollah use SIGINT against Israel? 
--
 > That isn't supposed to be possible these days...  (I
 > regard it as more likely that they were doing traffic
 > analysis and direction-finding than actually cracking
 > the ciphers.)
Ciphers cannot be cracked when used correctly.  However,
military cipher procedures are often highly user
unfriendly, and in consequence seldom used correctly.
Come to think of it, we have the same problem on the
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      c/n1W5sl/AyzClfoXunWJSJOHHUhW1DmgUQG8ZC3
      4TpD3sBZLjv0gUHYB2nlyeJ6n8hZV0ZQ0ET1/zHLL

@_date: 2006-09-23 12:38:51
@_author: James A. Donald 
@_subject: Exponent 3 damage spreads... 
--
: :	 10.2.3 Data decoding
: : The data D shall be BER-decoded to give an ASN.1
: : value of type DigestInfo, which shall be separated
: : into a message digest MD and a message-digest
: : algorithm identifier. The message-digest algorithm
: : identifier shall determine the "selected"
: : message-digest algorithm for the next step.
 > The only reasonable reading of the text quoted above
 > is that the D must consist of, and *only* of, an ASN.1
 > value of the given type.
That is not what it says.
It says "shall be decoded to give", not "shall be
decoded to give and only give"
Further, similar text appears in lots of places where
the correct behavior, to allow for future extension, is
to allow for more stuff.
A major design consideration in ASN.1 was *to* allow for
more stuff, in order that multiple versions of the
specification can peacefully coexist.
Therefore, in the context of ASN.1, the correct
interpretation of the specification is to allow for
arbitrary expansion - which is a bad spec.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      uTSBsEVoGqap3qSR80twUH+gg5Q8MDBgQhB2Wyxw
      4AjRA5gK1azQkXrhC7CakjCPKw7vvSVL7qWID8o/o

@_date: 2006-09-24 20:51:06
@_author: James A. Donald 
@_subject: IGE mode is broken (Re: IGE mode in OpenSSL) 
The idea is to costlessly piggy back integrity on top of confidentiality is to have error propagation, so that any fiddling with the message will cause all packets after the fiddling to be random noise.
Unfortunately, if this is done with linear operations, it can be undone with linear operations.  If it is done with non linear operations (my recommendation), it is hard to prove anything.
 > Or are universal hashes
The idea is to get integrity for free, but unfortunately so many integrity-for-free schemes have come undone, making people suspicious.

@_date: 2007-04-07 05:16:10
@_author: James A. Donald 
@_subject: DNSSEC to be strangled at birth. 
> Which means that the MITM would need the cooperation
 > of the client's provider in many/most cases (a
 > political problem) in order to be able to quickly get
 > in the middle so close to a leaf node (a technical
 > problem).
Not a very large political problem.  Most ISPs not only
roll over for the DOJ, the FBI, and the DHS, they also
roll over for the russian mafias.
With the root key and the cooperation of nodes close to
the client, you can intercept SSH and SSL communications
that rely on DNSSEC.  Without the root key, you cannot.
This is huge.
This, of course, means the sensible man configures SSH
not to rely on DNSSEC by default, which substantially
reduces the benefit of SSH.

@_date: 2007-08-20 10:19:51
@_author: James A. Donald 
@_subject: a new way to build quantum computers? 
--
 >  >
 > "Ann Arbor (MI) - University of Michigan scientists
 > have discovered a breakthrough way to utilize light in
 > cryptography. The new technique can crack even complex
 > codes in a matter of seconds. Scientists believe this
 > technique offers much advancement over current
 > solutions and could serve to foil national and
 > personal security threats if employed."...
 >
 > I'll let those who know more physics comment in
 > detail; from reading the article, it appears to lead
 > to a way to construct quantum computers.
It is another *in* *principle* design:  The computer is
programmed and supplied with data at optical
frequencies.  We cannot modulate light at that frequency
with sufficient precision and detail.  Perhaps we will
be able to soon.
As Moore's law progresses, quantum effects get
relatively larger.  Another way of stating this proposal
is to say that when we can build classical computers
with nanoscale line widths and hundred terahertz clocks,
*then* we can build quantum computers - indeed, we will
have to, as our classical computers will start acting
weirdly due to quantum effects.
Quantum computers are best done with the highest
possible frequencies and the lowest possible energies,
so become more feasible as conventional computers become
faster and more energy efficient. If we had optical
computing at optical frequencies with quantum dots
acting as the nonlinear elements, yes, quantum effects
would be quite large, making classical computers harder,
and quantum computers easier.
If we could build a quantum computer of this design, we
could build a classical computer that operated at five
hundred terahertz, and in order program and interface
with the proposed quantum computer, we are going to
*need* a classical computer that operates at five
hundred terahertz, that is to say five hundred thousand
gigahertz, that is to say five million megahertz.
It will be a while before you can buy that one at Fry's.

@_date: 2007-08-23 09:25:34
@_author: James A. Donald 
@_subject: Good news on crypto patents: 
Good news on patents, particularly crypto patents.
The CAFC, the US patent court, has recently ruled that the patent holder cannot hit you with punitive damages unless, on the preponderance of the evidence, you were objectively reckless - that you knew or strongly suspected you were violating the patent.
By and large, the remaining crypto patents are canned uncertainty and doubt, intended to muddy the water, patenting everything, anything, and nothing.  This previously worked in favor of the patent holder, but now it works against the patent holder.
The way it now works is that if you have an arguable case that you are not in violation of the patent, you can barge right ahead and wait for the patent holder to spend many millions of dollars and many years in court to clarify the situation.  Don't hold your breath.
This also negates the Microsoft tactic "If you use linux, you are violating our patents, but we will not tell you what patents you are violating, or what aspect of linux violates them".  Now, genuine uncertainty works *against* the patent holder.

@_date: 2007-12-02 11:25:50
@_author: James A. Donald 
@_subject: PlayStation 3 predicts next US president 
>> See  if
 >> you want to know the details of what this has to do
 >> with cryptography.
 >>
 > It always bothers me as these things are announced,
 > but are based on presumptions that have absolutely no
 > relevance in the real world....
 >
 > Therefore, nothing to do with cryptography (which is
 > not a parlor trick).
 >
 >> This implies a vulnerability in software integrity
 >> protection and code signing schemes that still use
 >> MD5. See
 >>  for
 >> details.
 >>
 > There is no such MD5 vulnerability implied.  As the
 > paper itself states:
 >
 >   In cryptographic terms: our attack is an attack on
 >   collision resistance, not on preimage or second
 >   preimage resistance. This implies that both
 >   colliding files have to be specially prepared by the
 >   attacker, before they are published on a download
 >   site or presented for signing by a code signing
 >   scheme. Existing files with a known hash that have
 >   not been prepared in this way are not vulnerable.
 >
 > Since this "attack" requires the certifier be
 > compromised, the attacker could also modify the
 > program data itself undetectably.  That is, this
 > theoretical problem actually is more effort than the
 > obvious attack!
This attack does not require the certifier to be
  The attack was to generate a multitude of predictions
for the US election, each of which has the same MD5
hash.  If the certifier certifies any one of these
predictions, the recipient can use the certificate for
any one of these predictions.
 > In summary, there are exactly zero instances where
 > this use of MD5 would actually present a
 > vulnerability.
This attack renders MD5 entirely worthless for any use
other than as an error check like CRC - and CRC does it
better and faster.

@_date: 2007-12-02 12:58:35
@_author: James A. Donald 
@_subject: PlayStation 3 predicts next US president 
> There are no circumstances in which any reputable
 > certifier will ever certify any of the "multitude"
 > containing a hidden pdf image, especially where
 > generated by another party.
So the certifier is going to go through each thing he
certifies, to make sure there is nothing funny about it?
The whole point of MD5 is to automate that stuff.  If an
actual human has to go through it, and understand what
it means, and certify the *meaning* then there is no
reason to take an MD5 hash.
 > The attack requires the certifier to be compromised,
 > either to certify documents that the certifier did not
 > generate
That is what certifiers do.  It is what they are
supposed to do.  You seem to have confused certification
with signing.
 > or to include the chosen text (hidden image) in its
 > documents in exactly the correct location.
If it is a certifier, these are not "its" documents.

@_date: 2007-12-02 17:11:00
@_author: James A. Donald 
@_subject: PlayStation 3 predicts next US president 
> Apparently, you never read the original rationale for
 > MD5.  It still does what it was intended to do....
MD5 was intended to identify the thing being hashed
uniquely.  If it is possible to produce multiple
plausible human readable texts that say different things
yet give the same MD5 hash, it does not do what it was
intended to do.
James A. Donald:
 >> If it is a certifier, these are not "its" documents.
William Allen Simpson:
 > If it is a certifier, it damn well better be its own
 > documents!
A notary is a certifier.  Have you ever seen a notary
read the stuff he notarizes, let alone generate it?
 > Look at the original message:
 >
 >  This implies a vulnerability in software integrity
 >  protection and code signing schemes that still use
 >  MD5.
Suppose you sign a contract - by signing the MD5 hash of
the contract.  Unfortunately the guy who prepared the
contract prepared two slightly different contracts, one
of which is more favorable to him and less favorable to
you than the one you actually signed.  Both contracts
have the same MD5 hash.

@_date: 2007-12-03 06:14:56
@_author: James A. Donald 
@_subject: GOST's resistance to this attack 
GOST resists the attacks that have recently been
discovered against commonly used hashes because it has
512 bits of internal state.  It combines a simple 256
bit checksum with a simple 256 bit digest.
I cannot see any use for the checksum other than to
resist this type of attack against the digest, which
suggests that the Russians may have been aware of this
kind of attack in 1990.

@_date: 2007-12-03 06:19:18
@_author: James A. Donald 
@_subject: PlayStation 3 predicts next US president 
>> A notary is a certifier.  Have you ever seen a notary
 >> read the stuff he notarizes, let alone generate it?
 > Actually, I deal with notaries regularly.  I've always
 > had to physically sign while watched by the notary.
 > They always read the stuff notarized, and my
 > supporting identification, because they are notarizing
 > a signature (not a document).
  Not true.  Because they are notarizing a signature, not
a document, they  check my supporting identification,
but never read the document being signed.
 > And yes, they always generate the stamp or imprint
 > they sign. To do otherwise would be irresponsible (and
 > illegal).
If they were to generate an MD5 hash of documents
prepared by someone else, then the attack described
(eight different human readable documents with the same
MD5 hash) works.

@_date: 2007-12-03 12:55:04
@_author: James A. Donald 
@_subject: PlayStation 3 predicts next US president 
But they don't read the document, let alone generate it.

@_date: 2007-12-04 11:24:04
@_author: James A. Donald 
@_subject: PlayStation 3 predicts next US president 
You mean *specified* by the notary - which would presumably be PDF or RTF.
And if the format is PDF or RDF, none of this will prevent the problem with MD5 - the problem being that a notarization of one document will also notarize as many other of my documents as I please.

@_date: 2007-12-04 11:28:17
@_author: James A. Donald 
@_subject: PlayStation 3 predicts next US president 
>> Keep in mind that the notary is still 'careful' --
 >> effectively they sign the hash -- rather than the
 >> document; and state either such (e.g. in the case of
 >> some software/code where you do not hand over the
 >> actual code) or state that _a_ document was presented
 >> with said hash.
 > And that makes all the difference.  The digital notary
 > is not certifying the original document.  You
 > described the notary generating its own tuples
 > (credentials as presented, the hash, a timestamp, and
 > a notarized declaration that such was presented).
 > There is no problem, and the described attack does not
 > apply.
The described attack does apply:  The notary has
complied with normal procedures and with the rules, but
the rules and procedure fail to have the desired effect,
because an MD5 hash lacks the desired properties.

@_date: 2007-12-08 09:22:47
@_author: James A. Donald 
@_subject: PlayStation 3 predicts next US president 
> The notary would never sign a hash generated by
 > somebody else.  Instead, the notary generates its own
 > document (from its own tuples), and signs its own
 > document, documenting that some other document was
 > submitted by some person before some particular time.
And how does it identify this "other document"?
The notary is only safe from this flaw in MD5 if you
assume he is not using MD5 for its intended purpose.

@_date: 2007-12-10 20:37:42
@_author: James A. Donald 
@_subject: PlayStation 3 predicts next US president 
>>  > The notary would never sign a hash generated by
 >>  > somebody else.  Instead, the notary generates its
 >>  > own document (from its own tuples), and signs its
 >>  > own document, documenting that some other document
 >>  > was submitted by some person before some
 >>  > particular time.
James A. Donald:
 > > And how does it identify this "other document"?
 > Sorry, obviously I incorrectly assumed that we're
 > talking to somebody skilled in the art....
 >
 > Reminding you that several of us have told you that a
 > notary has the document in her possession; and binds
 > the document to a person; and that we have rather a
 > lot of experience in identifying documents (even for
 > simple things like email), such as the PGP digital
 > timestamping service.
 >
 > Assuming,
 >   Dp := any electronic document submitted by some
 >   person, converted to its
 >         canonical form
 >   Cp := a electronic certificate irrefutably
 >   identifying the other person
 >         submitting the document
 >   Cn := certificate of the notary Tn := timestamp of
 >   the notary S() := signature of the notary
 >
 >   S( MD5(Tn || Dp || Cp || Cn) ).
Assuming that the attacker knows or can guess Tn, and
that the canonical form allows images, then the attack
still works.
The attacker can create several documents, D1, D2, D3,
D4, D5, such that MD5(Tn || D1 || Cp || Cn) is equal to
MD5(Tn || D2 || Cp || Cn), which is equal to MD5(Tn ||
D3 || Cp || Cn), etc.
He then gets the notary to sign MD5(Tn || D1 || Cp ||
Cn), and then uses  whichever of D1, D2, D3, D4, and D5
is convenient.

@_date: 2007-12-11 13:49:19
@_author: James A. Donald 
@_subject: Intercepting Microsoft wireless keyboard communications 
Use CFB mode.  That takes care of all the above problems.  You can transmit any small bunch of bits, don't need to transmit a complete block, and if the keyboard and the receiver get out sync, the keyboard's signal will be decrypted as garbage for the first 128 bits.  If one has the keyboard regularly transmit "no key's pressed" from time to time, and if valid key press representations have a couple of check bits redundancy, with several keypresses being ignored after any invalid key signal, keyboard and receiver will synchronize with no fuss.

@_date: 2007-12-11 16:45:42
@_author: James A. Donald 
@_subject: PlayStation 3 predicts next US president 
>> That's because if Tn is known (including chosen) to
 >> "some person", then (due to the weakness in MD5 we
 >> are talking about), she can generate Dp and Dp' such
 >> that
 >>   S( MD5(Tn || Dp || Cp || Cn) ) = S( MD5(Tn || Dp'
 >>   || Cp || Cn) )
 >> whatever Cp, Cn and S() are.
 > First of all, the weakness in MD5 (computational
 > feasibility over time) that "we are talking about" is
 > not (yet) a preimage or second preimage attack.
 > Please don't extrapolate your argument.
I don't think you know what a preimage or second
preimage attack is.
A preimage attack is a method of finding a document that
hashes to an arbitrary given hash.  A second preimage
attack is a method of finding a document that hashes to
the same hash as arbitrary given document. Your proposed
workaround protocol fails because the adversary can
construct multiple documents containing some arbitrary
text and some chosen text that hash to the same hash -
the fact that some of the arbitrary text comes from the
good guys is irrelevant.  The fact that the bad guys get
to choose some of the text in all of the documents makes
it fail.
 > Second of all, you need to read my messages more
 > carefully.  No good canonical format allows random
 > hidden fields or images.
There is no canonical format that suppresses human
ignorable data, other than plain ascii or suchlike which
is unlikely to be acceptable.  Any format capable of
displaying arbitrary well formatted documents is capable
of containing data that humans are likely to ignore.
What is ignorable is necessarily a human judgment.
A canonical format is in practice going to be PDF or
RTF, which does allow hidden fields and images.
Further, even a visible image can be made to work.
Further, it is quite subtle to decide what constitutes
"hidden" - for example a gently irregular low intensity
background on HTML pages is quite pleasing to the eye,
so surely our format should allow such backgrounds.
Further, what you propose is strengthening the protocol
to work around known weaknesses in MD5.  Whenever we
strengthen a protocol to get around known weaknesses in
an algorithm, we rarely do it right - consider the long
succession of debacles surrounding RC4.  SSH uses RC4
correctly, but consider all the protocols that used it
incorrectly, and then issued incompatible updates to fix
the flaws, updates that were even more flawed than the
protocol they supposedly fixed.
Further, if you want your protocol to work around the
known weaknesses of MD5, "canonicalizing" the document
is not the way to go.
Instead, allow arbitrary documents, but precede them by
salt which is randomly determined after the document is
That will work a lot better than canonicalization, but
it is still a workaround for a known weakness.  Far
better to avoid the weakness.

@_date: 2007-12-12 10:02:31
@_author: James A. Donald 
@_subject: Intercepting Microsoft wireless keyboard communications 
> Believe it or not, I thought of CFB...
 >
 > Sending keep-alives will do nasties to battery
 > lifetime, I suspect; most of the time, you're not
 > typing.  As for CFB -- with a 64-bit block cipher (you
 > want them to use DES? they're not going to think of
 > anything different), it will take 9 keypresses to
 > flush the buffer.  With AES (apparently your
 > assumption), it will take 17 keypresses.  This isn't
 > exactly muggle-friendly.  Just think of the text in
 > the instructions... Redundancy?  I wonder how much is
 > needed to avoid problems.  It has to be a divisor of
 > the cipher block size, which more or less means 8
 > extra bits.  How much will that cost in battery life?
Keypress signals, or change of keyboard state signals,
do not need to be a divisor of the cipher block size.
At every block boundary, keyboard transmits a special
signal in the clear that signifies block boundary.  Any
time that no key has been pressed for a while, then when
a key is finally pressed, keyboard transmits a bunch of
no-ops sufficient to ensure that the recipient has
recently received an entire block, followed by a
complete description of current keyboard state, so that
recipient knows what change of keyboard state signals
are changes from.  Conversely, when the receiver has not
received any signal for a while, it expects such a
signal, and distrusts anything else. Muggle
unfriendliness only occurs if user is typing through a
boot up, which is unlikely to terribly surprise the
user, who is probably banging away at the same keys over
and over again waiting for a reaction, or if the user
wanders out of range while typing, then wanders back in
range again while still typing, in which case again the
user is unlikely to be very surprised.

@_date: 2007-12-12 15:10:00
@_author: James A. Donald 
@_subject: PlayStation 3 predicts next US president 
> The whole point of a notary is to bind a document to a
 > person.  That the person submitted two or more
 > different documents at different times is readily
 > observable.  After all, the notary has the
 > document(s)!
The notary does not want to have the documents, or to
have the necessary apparatus to produce them on demand.
Actually existent notaries do not keep the documents.
Again, you are trying to invent a protocol that works
around the flaws in MD5.  No doubt a competent engineer
can create such a protocol, but a competent engineer
would much prefer not to have flaws he needs to work
Further, there is a long history of cryptographic
disasters, such as WiFi, where supposedly competent
engineers set to working around flaws, and instead
created more and bigger flaws.  Even if someone really
is a competent engineer, and perfectly capable of
producing a protocol that works around the known flaws,
it is hard for anyone else to tell if he really is
competent enough to work around the flaws, or has
produced, like WiFi and so many Microsoft projects, an
even bigger hole than that which he was trying to fix.

@_date: 2007-02-08 18:32:44
@_author: James A. Donald 
@_subject: One Laptop per Child security 
> The AV decision is more problematic.  While a good
 > security model can prevent system files from being
 > overwritten, most worms use purely user-level
 > abilities.  It would take a fairly radical OS design
 > to prevent a user-level worm from spreading.
It is a fairly radical OS design.  Programs do not
inherit the full authority of the user.  They cannot do
anything the user can do.
For many tasks, they have to call upon a small amount of
trusted code.  For example the normal way an editor
opens a file is that one gives the editor a file name,
and the editor, having full user authority to read or
change any file in the system, plays nice and opens and
changes *only* that file.   In this OS, instead the
editor asks trusted code for a file handle, and gets the
handle to a file chosen by the user, and can modify that
file and no other.
The nice thing about this OS architecture is that that
each executable is loaded and run in its own VM, instead
of having access to everything the user has access to.

@_date: 2007-02-09 13:22:06
@_author: James A. Donald 
@_subject: One Laptop per Child security 
--
 > The text you quote doesn't answer the question; the
 > rest of the wiki frontpage says little more.  It tends
 > to make me think that if an application wants to do
 > something that I've not enabled it to do ahead of time
 > then it fails.  Failure is incovenient.  So as near as
 > I can tell from the text you quote BitFrost sets its
 > convenience/security parameters differently than other
 > OSes, but there's nothing truly Earth shatteringly new
 > there.
There is a great deal that is earth shatteringly new,
and it is documented - albeit in rather unclear and non
standard format.
The fundamental difference is that each application is
run in its own VM, and so *cannot* exercise full user
powers, whereas with *all* other OSs, if your solitaire
game is a trojan, or (more likely) has flaws that enable
an adversary to get control of it, it can read all your
user documents and mail them to the adversary, check
your interaction with the browser to detect you typing
in passwords to your bank account and share trading
account, get the names of everyone on your address list,
and spam cons and trojans to them in each others names,
use your modem to dial a ten dollar a minute gay S&M sex
line in Outer Mongolia, launch a denial of service
attack against The Gold Casino as part of an extortion
scheme, spray ads onto your screen, make your system a
file share server for other people's child pornography,
and report all your video files to the copyright
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      x4p2u5+Go3URK4IvzoJkO/+K0lr4p4XW2aNmlbEi
      4dlOW8vAN4GsnWBzDGfvyjQYPosBfDEqrH3rKQ451

@_date: 2007-02-09 13:35:35
@_author: James A. Donald 
@_subject: One Laptop per Child security 
--
 > Would it be possible for one malicious web site to be
 > able to access (or even influence) what is being done
 > in another tab or window of the browser?
 >
 > If the user is talking to a bank, then that scenario
 > may threaten the user's privacy.
 >
 > Sandboxing the browser instance for each site would
 > solve that problem.
As designed, hard to VM each browser instance.  If one
uses something less than VM, one relies on quite a lot
of code that one does not really understand being
correct.   I do not see any alternative to this, short
of a major browser rewrite.
Ideally, there should be a separate VM responsible for
talking to each site, interpreting javascript, etc,
which is created when the conversation is started, and
shut down when one browses away from that site. Big
project.  Or instead of VMing things, one could
structure the code so that automatic code checks make it
impossible to compile code that is bad in certain ways -
again a big project.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      txnLOsPeyJqwn5LYEMAdBUQoBArt6OJO8Rp8P6Vn
      4GQB25JeUovLVxb1JZBHA6Q0qjCGFQGkhchihumVh

@_date: 2007-02-13 07:43:07
@_author: James A. Donald 
@_subject: Failure of PKI in messaging 
--
Obviously financial institutions should sign their
messages to their customers, to prevent phishing.  The
only such signatures I have ever seen use gpg and come
from niche players.
I have heard that the reason no one signs using PKI is
that lots of email clients throw up panic dialogs when
they get such a message, and at best they present an
opaque, incomprehensible, and useless interface.  Has
anyone done marketing studies to see why banks and
massively phished organizations do not sign their
messages to their customers?
      --digsig
           James A. Donald
       6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
       BwrcLrYHszR0syC9LdVrjxAionyxVDwbtJq8Xu2q
       4ky71ODjPeHF5TC4pnkktFaLHEOfFN4fY8JEyqnfn

@_date: 2007-02-15 07:35:19
@_author: James A. Donald 
@_subject: Failure of PKI in messaging 
> This is, in my experience, exactly right. I'm trying
 > to take some steps for the better on the OLPC: all
 > e-mails and IMs will be signed transparently and by
 > default, with the possibility of being encrypted by
 > default in countries where it's not a problem. This'll
 > help with privacy and message integrity, but it's not
 > designed to stop phishing or impersonation.
Matt Blaze has proposed despair - that message
authentication cannot defeat phishing,  Ivan Krsti? has
proposed a system not intended to address phishing.
Naturally I have a solution - the only problem is to get
from where we are to there.  I was interested in the
banks perception that PKI was not working - what led
them to realize that PKI was not working or led them to
doubt that PKI would work, for in order to get from here
to their, have to persuade them that my solution *will*
work.  I was hoping for a response from the usual
defenders of PKI, who would, I hoped, give me the inside
scoop on the problems that Verisign has encountered with
its customers.
The solution to phishing:
Suppose we have a messaging service that, like Yahoo, is
also a single signon service, and, like OTR or Skype
voice messaging, delivers authenticated encrypted
messages.  Better, multiple such message services that
Suppose that when you register at a website for single
signon onto that website you get an icon in your
messaging client similar to a buddy icon, but
corresponding to that website instead of a buddy.
Zooko's rules apply - default name is title of logon
page that the user will see when logged in, but name is
local, user can modify it.  User has to handle name
collisions locally.  Click on the icon in your messaging
client, your browser is launched and logged on at the
web site, and that is the *only* way you can logon onto
that website in your single signon identity.   We want
the name of icon to default to same title as the logged
in page, for consistency with the experience of using
favorites -
The user experience should resemble using buddy icons
and also resemble using favorites icons.  When you click
on a registered website icon, instead of getting a text
box to type in a message, you instead get a browser page
logged in to the website.
If the web site is on the user's list for single signon,
then by default the website is enabled to send him
messages.  Only his buddies and enabled websites can
send him messages, and they can only be enabled if he
has an icon in his messaging system that represents
single click login.
The website sends message title and a url argument. User
sees a button, and the text " from
".   If he clicks on that
button, he gets logged in as usual, but instead of
seeing his usual web page, sees a web page with that
title, that web page containing the actual message body.
Thus the user typically sees in his messaging client an
email like list of messages each with a button/link that
These messages are given less immediacy than messages
from buddies - they are just put in a list like email,
for there is no live human waiting at the other end. The
single signon icons work like both buddy and favorites
icons, but the message icons work like email icons, not
like popups from actual buddies.
I have described the user experience, not the underlying
crypto, for everyone on this list can see how to use
crypto to give effect to the behavior described and
prevent adversaries from spoofing that behavior, but had
best post up the underlying crypto shortly, lest some
troll patent it.   The underlying crypto is, of course,
similar to that used by Skype and OTR, plus for the
login phase similar to the petname tool and OpenID.
It is not at all clear, however, how to make this
interoperate with Jabber/XMPP, for last time I checked
Jabber had no capabilities discovery mechanism, and in
consequence all the various officially approved jabber
encryption protocols were useless for any sane purpose.
On the other hand, the core of OpenID is nothing but a
capabilities discovery system, so perhaps some
combination of Jabber with OpenID could work.  I have
not thought the issue of Jabber compatibility through.
I participated briefly on that standards list, and
came to the conclusion that they could not run a
lemonade stand, much less produce a useful standard.

@_date: 2007-02-15 07:55:42
@_author: James A. Donald 
@_subject: Failure of PKI in messaging 
Want to try it out.  Not clear what you mean by application info.

@_date: 2007-02-16 08:28:01
@_author: James A. Donald 
@_subject: Failure of PKI in messaging 
--
 > What's missing is, if you'll pardon the phrase, a
 > central point of failure.
 >
 > If you can persuade everyone to use a single system,
 > it's not hard to make communication adequately secure.
But there is a central point.  ICANN is responsible for
internet names and numbers, and for keys to certify
those names and numbers, and it is pretty much
Similarly, if everyone in the world used hushmail, would
not do any more good against phishing than if everyone
in the world used PKI signed mail - which is precisely
why people do not use PKI signed email.
You are making the Katrina reaction "we need someone in
charge".  No, we do not need someone in charge.  Someone
in charge does not make everything right, more commonly
it makes everything wrong, disrupting, rather than
facilitating, communication and cooperation, just as
with the Katrina disaster.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      hHUR4oItlqyjOJrgB5g69WubFGEXSD2fFY+PslCK
      4pIw1gBia7di4K0uJB1p+FcZC9yxi1vCIFI3tot1u

@_date: 2007-02-16 08:41:05
@_author: James A. Donald 
@_subject: Failure of PKI in messaging 
--
 > That's not banking. Banks and their clients already
 > have a trusted relationship. The banks webmail
 > interface leverages this to provide a trust reference
 > that the user can easily verify (yes, this is my name
 > and balance). That's why it works, and that's what is
 > missing in the bank PKI email model -- what's that
 > relationship buying you?
 >
 > Email for banks should thus leverage the relationship,
 > rather than present an ab initio communication.
Hence my proposal for a single sign on and messaging
system resembling IM buddy lists - the computer tracks
relationship information, rather than true name
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      NMb/3lhm5wj1jn9bea0UJsViLkPWzA2jR+GCOgFV
      4WdwEv3Qp46Bt5AR7KTqFUUnJqu7E/XHnkKfJ2t/D

@_date: 2007-02-16 12:18:31
@_author: James A. Donald 
@_subject: Failure of PKI in messaging 
--
 >> Suppose we have a messaging service that, like Yahoo,
 >> is also a single signon service, ...
 > Then you just change the attack model.
My proposal closes off the major attack path, and leaves
the trojan and virus attack path wide open.
But I have not had a trojan or a virus for a year, and
the guys at OLPC and capabilities are working on
solutions to the problem of trojans and viruses.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      KFNxwdPt55zr/lrMF3JJdyxCUs8vIC5/2XaKhzIj
      4+Jf1Ha6sL7LPQHFkrty0tw47vweiiGC5p1lMXXiK

@_date: 2007-02-16 14:24:29
@_author: James A. Donald 
@_subject: Failure of PKI in messaging 
--
 > To the extent that people use a single system it can
 > be secure, but that doesn't scale.
Globally unique true names do not scale.  Relationships
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      k7PJ8x72+ICYQ50DNQkc2sMtEOMtd2zLbgpc5M8w
      4HQZ5DEIQ9w/MkOb3cHmjxc47K/M0b67jwacYSSMR

@_date: 2007-02-16 14:51:32
@_author: James A. Donald 
@_subject: Failure of PKI in messaging 
--
 > > My proposal closes off the major attack path
 > It doesn't do anything about the obvious attack path
 > of phishing credentials from the users to stick bogus
 > trusted entries into their accounts.
Actually it does.  Think about it.
 > My examples showed all sorts of benign looking
 > situations in which users provide their credentials to
 > parties of unknown identity or reliability.
I don't see that your examples have any relevance to my
proposals.  The word "credential" is nowhere mentioned
or relevant,  nor is providing one's credentials to
criminals a problem unless one's crediential is in fact
a shared secret, such as a credit card number.  So we
should not use shared secrets any more - that is a given
for any and all serious proposals.
Your criticism is not a criticism of my proposal, it is
a criticism of using the same password all over the net.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      hyNNu45kHRCn/6vEXQhYdbU/w1YW4J/TF8BDsJz0
      495s+VYSd3RjDiopACgr9JccOdvE7cTtQV6xgA8sK

@_date: 2007-01-12 12:26:08
@_author: James A. Donald 
@_subject: Private Key Generation from Passwords/phrases 
You are not going to get 76 bits of entropy in a password.
Memorizing a 76 bit password is equivalent to memorizing three seven digit telephone numbers.
Assume that the private key is generated from the password plus an n bit true random number.
To regenerate the private key we have to try 2^n private keys, looking for a match to the public key.  Assume this takes time X.
Assume the actual entropy in the password is m bits.  Then an attacker who has similar computing resources is going to take time X * 2^m
Any time a password can be subject to offline attack by anyone, it is not a good design.  You are better off fixing it so that only certain people can offline attack the password, and everyone else has to do an online attack on the passwrod.

@_date: 2007-01-25 08:33:12
@_author: James A. Donald 
@_subject: "Free WiFi" man-in-the-middle scam seen in the wild. 
--
 > It used to be that Verizon (my local phone company,
 > sadly) had this general problem but you could click on
 > "log in" and it would direct you to a secure page with
 > a little error message and you could then enter your
 > username and password. They've since "fixed" that so
 > it is no longer possible to log in safely to their web
 > site at all.
The reason we cannot sell, nor profitably implement,
usable and effective security is, as Ian Grigg says in
"the market for silver bullets", that neither buyers nor
sellers can tell the difference between security that
works, and security that does not work, even though you
and I can tell the difference.
The most recent illustration of this is the reaction to
the recent AACS content protection hack.
 Cyberlink says its DRM code is working fine,
because it does what it designed to do - but
unfortunately the design prevents legitimate purchasers
from playing legitimately purchased content on
legitimately purchased machines, and fails to prevent
people from ripping the content and sharing it through
bittorrent.  Cyberlink's statement echoes the statement
made by earlier by many on this list and related lists
that PKI fulfills its specification just fine.  The DRM
people wanted something that could not be done, so
unsurprisingly they winded up buying something that does
not do it.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      LjC3cY1UO0v0xXean2TJqxn0Dh1vSubg/F00KDsX
      48fF+ZilNMNu1rtIcc2XhJ0zksmqpjzsHEJz9pGDj

@_date: 2007-07-05 09:55:23
@_author: James A. Donald 
@_subject: The bank fraud blame game 
How large is this code?
The security of this system would seem to rest on the security of mobile phones against cloning.  How were mobile phones protected against cloning?

@_date: 2007-06-01 20:59:55
@_author: James A. Donald 
@_subject: Why self describing data formats: 
Many protocols use some form of self describing data format, for example ASN.1, XML, S expressions, and bencoding.
Presumably both ends of the conversation have negotiated what protocol version they are using (and if they have not, you have big problems) and when they receive data, they need to get the data they expect.  If they are looking for list of integer pairs, and they get a integer string pairs, then having them correctly identified as strings is not going to help much.

@_date: 2007-06-10 12:42:12
@_author: James A. Donald 
@_subject: Free Rootkit with Every New Intel Machine 
Initially I did not believe it, thought it must be hype or hoax.
Nope, it is a rootkit in hardware.
: :	Isolate security tasks?in a separate
: :	environment that is hidden to the user
: :
: : 	[...]
: :
: :	Perform hardware and software inventory on
: :	PCs?even if they don't have management
: :	applications installed or they are powered
: :	down, which increases reporting accuracy for
: :	licensing, maintenance contracts, and audits.
: :
: :	Deploy software patches to PCs more
: :	efficiently?even if they are powered down or
: :	their OS is inoperable, without disrupting or
: :	slowing down the user's workflow.
(The last paragraph means "without the user knowing, and even if the user is doing his best to stop you")

@_date: 2007-06-11 13:50:32
@_author: James A. Donald 
@_subject: Why self describing data formats: 
They also make it easy to write specs that do not in fact work.  The spec writers do not in fact agree, and then leave the problem of implementing an under defined spec to the engineer.
In the case of XML, yes there is a parsing engine, and if the structure of the DTD reflects the structure of the algorithm, then indeed it makes things much easier.  But usually the committee have not thought about the algorithm, or have unresolved disagreements about what the algorithm should be, leaving the engineer with problems that are at best extremely difficult to solve, and are at worst impossible to solve.  Ideally the DTD should be developed in parallel with the program that processes the XML.  In that case, you get the parsing engine doing a lot of work for free, so the engineers do not have to reinvent the wheel.  But if the DTD is written first by one group, and the program second, by another group, the second group is usually hosed good.
Sounds true.

@_date: 2007-06-23 09:47:02
@_author: James A. Donald 
@_subject: question re practical use of secret sharing 
James A. Donald:
 > > Is anyone aware of a commercial product that
 > > implements secret sharing? If so, can I get a
 > > pointer to some product literature?
Peter Gutmann
 > It's available as part of other products (e.g. nCipher
 > do it for keying their HSMs), but I don't know of any
 > product that just does... secret sharing.  What would
 > be the user interface for such an application?  What
 > would be the target audience?  (I mean a real target
 > audience, not some hypothesised scenario).
 >
 > (This is actually a serious question.  I talked with
 > some crypto guys a few years ago about doing a
 > standard for secret sharing, but to do that we had to
 > come up with some general usage model for it rather
 > than just one particular application-specific
 > solution, and couldn't).
 >
 > Besides that, user demand for it was practically
 > nonexistent... no, it was completely nonexistent,
 > apart from a few highly specialised custom uses we
 > couldn't even find someone to use as a guinea pig for
 > testing, and the existing specialised users already
 > had specialised solutions of their own for handling
 > it.
There is no market, zero, for stand alone crypto of any
kind.  Cryptographic solutions should be embedded
invisibly in products that do tasks for the user.
The purpose of cryptography is to stop such products
from invisibly doing tasks for an adversary.  Since the
attack is generally invisible, one cannot expect the
user to use a visible addon product to protect against
the attack.

@_date: 2007-06-23 09:58:56
@_author: James A. Donald 
@_subject: Why self describing data formats: 
James A. Donald:
 > > In the case of XML, yes there is a parsing engine,
 > > and if the structure of the DTD reflects the
 > > structure of the algorithm, then indeed it makes
 > > things much easier.  But usually the committee have
 > > not thought about the algorithm, or have unresolved
 > > disagreements about what the algorithm should be,
 > > leaving the engineer with problems that are at best
 > > extremely difficult to solve, and are at worst
 > > impossible to solve.  Ideally the DTD should be
 > > developed in parallel with the program that
 > > processes the XML.  In that case, you get the
 > > parsing engine doing a lot of work for free, so the
 > > engineers do not have to reinvent the wheel.  But if
 > > the DTD is written first by one group, and the
 > > program second, by another group, the second group
 > > is usually hosed good.
Will Morton:
 > The situation is improved slightly with XML schemas,
 > as one can use frameworks like XMLBeans
 > ( to get the protocol much
 > closer to the code.  This can help a bit, but doesn't
 > change the fundamentals.
 >
 > You're still right in that if you have one group
 > developing the code and another the protocol, you're
 > probably screwed, but isn't this just as true (perhaps
 > moreso) if you're rolling your own protocol structure
 > instead of using XML?
With XML, alarmingly great flexibility in the protocol
is easy and less work for the people designing the
protocol - the protocol may be inordinately flexible
because of laziness, carelessness, unresolved
disagreement, or papered over disagreement,
resulting in tag soup.
With a protocol that is not self describing, the
committee devising the protocol have to actually agree
on what the protocol actually is.

@_date: 2007-03-04 12:06:16
@_author: James A. Donald 
@_subject: Cracking the code? 
--
 >> My questions are: A) is this as vulnerable as it
 >> seems at first blush? B) how many password/hex pairs
 >> would be needed to deduce the underlying algorithm?,
 >> C) If one could deduce the algorithm, could the
 >> attack be generalized so that it could be used
 >> against other enterprises that use the same software?
 >> (It is very(!) widely deployed), and D) am I missing
 >> something in my thinking?
 > A) yes it is vulnerable. B) none - it would take no
 > time to reverse engineer the entire algorithm out of
 > the executable. C) yes of course. D) just how bad this
 > is.
  Concerning B:  If the implementors of the system had
half a brain, they probably did something reasonable to
generate the hex, such as hashing the password with a
large secret, in which case no number of password hex
pairs will reveal the algorithm.
By and large, security systems that are covered by an
NDA are covered by an NDA because they are not very
good, and the seller of the system intends to send
anyone to jail who widely publicizes the fact that they
are not very good.
Approach with care.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      MGjeTFQKB0Wa89CvalWg8qz/BAWRAwDEUL0m4Kkn
      4VpuVXjmJfOnK1OLnn3wsm24Y9ES8GObzFkOVY4XV

@_date: 2007-05-03 19:57:18
@_author: James A. Donald 
@_subject: Public key encrypt-then-sign or sign-then-encrypt? 
In my opinion, this is best solved by OTR style authentication without Ann knows that Bob sent the message, because it is authenticated, but cannot prove this to others.  So if Ann releases the message, it is *Ann* saying that Bob sent it, not Bob saying that Bob sent it.
Assume Ann's secret key is a, and her public key is A = G^a mod P
Assume Bob's secret key is b, and his public key is B = G^b mod P
Bob wants to send Ann a message.
Bob generates a secret random number x, and sends Ann X = G^x mod P
Ann responds with Y = G^y mod P, where y is another secret random number.
Ann calculates [(B*X)^(a+y)] mod P
Bob calculates [(A*Y)^(b+x)] mod P, which should be the same value Ann This shared secret is used to encrypt the message, and the message contains an authentication value constructed from the contents of the message and the shared secret, that only someone who knows both could Ann knows the message came from Bob, because only someone who knows b could discover the shared secret from the information exchanged, but cannot prove to anyone else that the message came from Bob.

@_date: 2007-05-15 06:58:15
@_author: James A. Donald 
@_subject: Enterprise Right Management vs. Traditional Encryption Tools 
> So I guess the answer to your question is "We'd better
 > assume that DRM+TPM will be ineffective until we've
 > subjected a specific implementation of it to the same
 > level of scrutiny we apply to other cryptosystems, and
 > since DRM+TPM proposals tend to be much more
 > complicated than other cryptosystems like SSL, that's
 > going to take a very long time."
TPM can in principle provide effective DRM - it can also
provide effective super root access to your computer for
FBI and the Motion Picture Association of America - it
can do lots of things.  So far it has not done any of

@_date: 2007-05-16 06:36:17
@_author: James A. Donald 
@_subject: Public key encrypt-then-sign or sign-then-encrypt? 
James A. Donald:
 > > Assume Ann's secret key is a, and her public key is A
 > > = G^a mod P
 > >
 > > Assume Bob's secret key is b, and his public key is B
 > > = G^b mod P
 > >
 > > Bob wants to send Ann a message.
 > >
 > > Bob generates a secret random number x, and sends Ann
 > > X = G^x mod P
 > >
 > > Ann responds with Y = G^y mod P, where y is another
 > > secret random number.
 > >
 > > Ann calculates [(B*X)^(a+y)] mod P
 > an identity-binding flaw:
 >
 >  >
 > [...]
 >
 > : :    For example, if Bob thinks he's talking to
 > : :    Mallory, he may tell her something in
 > : :    confidence he would not want Alice to hear.
 > : :    Note that although Mallory could relate
 > : :    this confidential information to Alice
 > : :    herself, but in the attack scenario Alice
 > : :    has assurance that the message came from
 > : :    Bob rather than having to take Mallory's
 > : :    word for it.
The flaw in the protocol that you point out is that
Carol can allow Alice to use her public key without
having to reveal the public key to Alice, so that Alice
can pretend to be Carol.  Thus the flaw is that with
prearrangement, Carol may prove to one other person, but
to no one else, that Bob is saying such and such to
Carol, provided she knows in advance that Bob is going to say it.
Trouble is, I cannot see how to fix it without
introducing an additional public key operation, which
seems a high price for such a modest value attack.  If
Alice and Carol are working together in advance so that
Alice can be convinced that Bob is saying what Carol
knows he is going to say, Bob is pretty much hosed
anyway, for Alice can check the provenance of packets
that Carol claims are coming from Bob, or Carol may
simply reveal her private key to Alice.  The usual
threat is that things casually said a long time ago come
back to haunt you, retrospective revelation, not advance
revelation, and this attack does not threaten that.
Suppose Carol wants to prove to Alice that Bob is
saying what she claims he is saying.
Alice generates a transient secret key y and transient
public key Y = G^y, and gives Y to Carol. Carol receives
X = G^x from Bob, and gives him Y.  Carol's permanent
public key is C = G^c, Bob's permanent public key is B =
Bob calculates the shared secret (C*Y)^(b+x)
Carol calculates P = (B*X)^c, and gives it to Alice.
Alice calculates the shared secret [(B*X)^y]*P
Alice then converses with Bob, pretending to be Carol.
Is there any way to fix this without introducing an
additional exponentiation?  Perhaps by introducing an
additional multiplication? It does not seem worth while
introducing an additional public key operation, for such
a low value attack.
 > Contrast this to sign-then-encrypt, where Mallory
 > could decrypt, then forward to Alice.  Compare with
 > encrypt-then-sign.
But with encrypt then sign, Mallory can still prove his
decryption is correct.   He just has to reveal the
shared symmetric secret for the particular message.   So
encrypt then sign does not buy us anything.  With
encrypt then sign, messages Bob casually sent a long
time ago can still be revealed to the world, and proven
to have originated from Bob.

@_date: 2007-05-24 08:02:11
@_author: James A. Donald 
@_subject: 307 digit number factored 
--
 > So one of the proposals (somewhat backed by the domain
 > name certification authority industry) is that domain
 > name owners place a public key on file when they
 > register a domain name with the domain name
 > infrastructure. They all future communication with the
 > domain name infrastructure can be digitally signed ...
 > and the domain name infrastructure verify the digital
 > signature with the onfile public key.
If the decision was to be made by five engineers sitting
around a coffee table, they would agree on a solution in
a few minutes, and implement it in a week, but a
committee of seventeen people could not agree to adjourn
a meeting held in a burning building.
The problem is organizational.  To get one decision
centrally made and imposed on everyone requires a
central body capable of making decisions and imposing
them on everyone, and before it can get that authority,
that central body usually has to raze Atlanta and burn
the crops, or inflict genocidal famine on the Ukraine.
The great strength and great weakness of the internet is
that it is an anarchy.  Anything that requires one
decision made for all, such as the domain name system,
got frozen when the internet became too large for
decision making by consensus, and is now extremely
difficult to change.
So to make changes, they have to be made incrementally:
You need a CA with the proposed policy and a deal with
several registrars, and that CA needs to get on the
Mozilla and IE list.  Nice selling point.  If you
register with, say OpenSRS, you would automatically get
an SSL cert. Unfortunately, the certification process
for a CA to get on the browser list seems to be somewhat
circular - to be a CA, you have to prove you are like
existing CAs, which is most easily done if you *are* an
existing CA, and have no intention of changing the way
you work.

@_date: 2007-11-07 20:33:36
@_author: James A. Donald 
@_subject: forward-secrecy for email? (Re: Hushmail in U.S. v. Tyler Stumbo) 
>> I was involved in one case where super-secret stuff
 >> was shared through hushmail, and was also dual
 >> encrypted with non-hushmail-PGP for added security.
 >> In the end, the lawyers came in and scarfed up the
 >> lot with subpoenas ... all the secrets were revealed
 >> to everyone they should never have been revealed to.
 >> We don't have a crypto tool for embarrassing secrets
 >> to fade away.
 > What about deleting the private key periodically?
Mail should have the following security properties:
Mail that appears to come from an entity really did come
from that entity.
Though the recipient can prove to himself the mail came
from that sender, he cannot prove it to third parties
unless the sender cooperates.
If the sender and the recipient discard their copies,
that mail is gone forever.  No one can reconstruct it,
even though they have a complete record of the bits
passed between the sender and recipient and complete
access at a later date to the machines of the sender and
recipient and the complete cooperation, possibly under
extreme duress, of both sender and recipient.
If the sender or the recipient keep a copy that they can
access, then the guys with rubber hoses can shake it out
of them, but they can only see this stuff with the
cooperation, possibly under duress, of the sender or the
recipient - and they only have the sender or the
recipients word that this is the real stuff.  If the
recipient deleted his stuff, and the guys with rubber
hoses look at the sender's sent box, they cannot know it
is the original and unmodified sent box, and vice versa
for the recipient's in box.
We have the technology to accomplish all this, but not
with the present store and forward architecture.

@_date: 2007-11-14 06:55:54
@_author: James A. Donald 
@_subject: refactoring crypto handshakes (SSL in 3 easy steps) 
Authentication is establishing a shared secret.  The fact that a secret, once established, may then be used frequently, does not make the cost of authentication any the less.

@_date: 2007-11-14 11:29:14
@_author: James A. Donald 
@_subject: refactoring crypto handshakes (SSL in 3 easy steps) 
> The "extra messages" might be irrelevant for
 > cryptography, but they're not irrelevant for security
 > or functionality.
 >
 > E.g. in SSL, you have capability/feature negotiation
 > (cipher suites, trusted CAs, in TLS 1.2 also signature
 > algorithms, etc.)
You can handle this by client making a guess, perhaps
based on past experience, as to whether its initial
request for preferred protocol is likely to be accepted,
and if it thinks it probably will be, going ahead on the
assumption it will be, rather than waiting for the round
trips to complete.

@_date: 2007-11-21 13:41:51
@_author: James A. Donald 
@_subject: fyi: Adi Shamir's microprocessor bug attack 
> Adi Shamir Computer Science Department The Weizmann
 > Institute of Science Israel
 >
 > With the increasing word size and sophisticated
 > optimizations of multiplication units in modern
 > microprocessors, it becomes increasingly likely that
 > they contain some undetected bugs. This was
 > demonstrated by the accidental discovery of the
 > obscure Pentium division bug in the mid 1990's, and by
 > the recent discovery of a multiplication bug in the
 > Microsoft Excel program. In this note we show that if
 > some intelligence organization discovers (or secretly
 > plants) even one pair of integers a and b whose
 > product is computed incorrectly (even in a single low
 > order bit) by a popular microprocessor, then ANY key
 > in ANY RSA-based security program running on ANY one
 > of the millions of PC's that contain this
 > microprocessor can be trivially broken with a single
 > chosen message. A similar attack can be applied to any
 > security scheme based on discrete logs modulo a prime,
 > and to any security scheme based on elliptic curves
 > (in which we can also exploit division bugs), and thus
 > almost all the presently deployed public key schemes
 > will become vulnerable to such an attack.
 >
 > The new attack (which we call a "Bug Attack") is
 > related to the notion of fault attacks discovered by
 > Boneh, Demillo and Lipton in 1996, but seems to be
 > much more dangerous in its implications. The original
 > fault attack required physical possession of the
 > computing device by the attacker, and the deliberate
 > injection of a transient fault by operating this
 > device in an unusual way (in a microwave oven, at high
 > temperature, with high frequency clock, or with a
 > sudden spike in the power supply). Such attacks are
 > feasible against smart cards, but are much harder to
 > carry out against PC's. In the new bug attack, the
 > target PC can be located at a secure location half a
 > world away, and the attacker has no way of influencing
 > its operating environment in order to trigger a fault.
 > In addition, millions of PC's can be attacked
 > simultaneously, without having to manipulate the
 > operating environment of each one of them
 > individually.
 >
 > We now describe the basic idea of the new attack. We
 > assume that the RSA decryption (or signature
 > generation) is using the Chinese Remainder Theorem
 > (CRT) which speeds up the operation by a factor of 4
 > compared to naive implementations, that each
 > multiplication of big  operation by a factor of 4
 > compared to naive implementations, that each
 > multiplication of big numbers proceeds by breaking
 > them into the largest words which can be handled by
 > the native multiplier in that microprocessor
 > (typically 32 or 64 bits), and that all pairs of such
 > words from the two numbers will be multiplied in some
 > order. Knowing the target's public key n, the attacker
 > can easily compute a half size number c which is
 > guaranteed to be between the two secret factors p and
 > q of n. For example, a number c which is the square
 > root of n (rounded to the nearest integer) always
 > satisfies p likely to satisfy this condition. The attacker now
 > chooses a message m which is equal to c, except that
 > two low order words in it are replaced by a and b, and
 > submits this "poisoned input" to the target PC.
 >
 > The first step in the CRT computation is to reduce the
 > input m modulo p and q. Due to its choice, m will be
 > randomized mod the smaller p, but remain unchanged mod
 > the larger q. The next step in RSA-CRT is always to
 > square the reduced inputs mod p and q, respectively.
 > Since a and b are unlikely to remain in the randomized
 > value of m (mod p), the computation mod p is likely to
 > be correct. However, mod q the squaring operation will
 > contain a step in which the word a is multiplied by
 > the word b, and by our assumption the result will be
 > incorrect in at least one bit. Assuming that the rest
 > of the two computations mod p and q will be correct,
 > the final result of the two exponentiations will be
 > combined into a single output y which is likely to be
 > correct mod p, but incorrect mod q. The attacker can
 > then finish off his attack in the same way as the
 > original fault attack, by computing the gcd of n with
 > y^e-m, where e is the public exponent of the attacked
 > RSA key. With very high probability, this gcd will be
 > the secret factor p of n. This completely breaks the
 > security of this key.
 >
 > How easy is it to verify that such a single
 > multiplication bug does not exist in a modern
 > microprocessor, when its exact design is kept as a
 > trade secret? There are 2^128 pairs of inputs in a
 > 64x64 bit multiplier, so we cannot try them all in an
 > exhaustive search. Even if we assume that Intel had
 > learned its lesson and meticulously verified the
 > correctness of its multipliers, there are many smaller
 > manufacturers of microprocessors who may be less
 > careful with their design. In addition, the problem is
 > not limited to microprocessors: Many cellular
 > telephones are running RSA or elliptic curve
 > computations on signal processors made by TI and
 > others, FPGA or ASIC devices can embed in their design
 > flawed multipliers from popular libraries of standard
 > cell designs, and many security programs use optimized
 > "bignum packages" written by others without being able
 > to fully verify their correctness. As we have
 > demonstrated in this note, even a single (innocent or
 > intentional) bug in any one of these multipliers can
 > lead to a huge security disaster, which can be
 > secretly exploited in an essentially undetectable way
 > by a sophisticated intelligence organization.
If I understand this correctly, this is a chosen crypto
text attack.  The attacker constructs a crypto text, the
target decrypts it, and the target then reveals the
decrypted text to the attacker.
But what should happen is that he decrypts a key to be
used in symmetric decryption, applies it, gets garbage,
message checksum fails, message discarded.
Alternatively attacker sends text to be signed by target
- but most signature algorithms contain some random
salt.  If they don't, they should.
Public key systems are not robust if the holder of the
secret key makes an oracle available for decrypting or
signing attacker chosen text.  This attack does not make
them substantially less robust.

@_date: 2007-11-23 09:39:56
@_author: James A. Donald 
@_subject: fyi: Adi Shamir's microprocessor bug attack 
> Can anyone think of a deployed implementation of RSA
 > signatures that would be vulnerable to the attack
 > Shamir mentions?  Hashing and message blinding would
 > seem to thwart it.
As I said, public key encryption has long been known to
be weak against chosen plaintext and chosen cryptotext -
so protocols have long been designed to prevent this
sort of attack.  If they are not so designed, they were
known to be weak before this attack was discovered.

@_date: 2007-11-30 12:22:37
@_author: James A. Donald 
@_subject: refactoring crypto handshakes (SSL in 3 easy steps) 
> I wonder if we here could develop a handshake that was
 > cryptographically secure, resistant to CPU DoS now,
 > and would be possible to adjust as we get faster at
 > doing crypto operations to reduce latency even
 > further.  Basically an easy knob for balancing high
 > latency and DoS resistance vs. crypto overhead and low
 > latency. It should be adjustable on either end without
 > altering the other.
A problem with the OSI Layer model is that as one piles
one layer on top  of another, one is apt to get
redundant round trips.
Redundant round trips become an ever more serious
problem as bandwidths and processor speeds increase, but
round trip times reminds constant, indeed increase as we
become increasingly global and increasingly rely on
space based communications.
Used to be that the biggest problem with encryption was
the asymmetric encryption calculations - the PKI model
has lots and lots of redundant and excessive asymmetric
encryptions.   It also has lots and lots of redundant
round trips.  Now that we can use the NVIDIA GPU with
CUDA as a very high speed cheap massively parallel
cryptographic coprocessor, excessive PKI calculations
should become less of a problem, but excess round trips
are an ever increasing problem.
Any significant authentication and encryption overhead
will result in people being too clever by half, and only
using encryption and authentication where it is needed,
with the result that they invariably screw up and fail
to use it where it is needed - for example the login on
the http page.  So we have to lower the cost of
encrypted authenticated communications, so that people
can simply encrypt and authenticate everything without
needing to think about it.
To get stuff right, we have to ditch the OSI layer model
- but simply ditching it without replacement will result
in problems.  It exists for a reason, and we have to
replace it with something else.  I am working on an idea
for a replacement, a protocol compiler, which provides
compile time protocol layering, in place of OSI's run
time protocol layering.  I hope to publish it in due
course, but I am not going to report that idea in this
Instead, I simply describe the characteristics of a
packet protocol that establishes an encrypted connection
on top of unreliable packets with minimal round trips
without increasing fragility to DoS.
To establish a connection, we need to set a bunch of
values specific to this particular channel, and also
create a shared secret that eavesdroppers and active
attackers cannot discover.
The client is the part that initiates the communication,
the server is the party that responds.
I assume a mode that provides both authentication and
encryption - if a packet decrypts into a valid message,
this shows it originated from an entity possessing the
shared secret.  This does not provide signing - the
recipient cannot prove to a third party that he received
it, rather than making it up.
The client typically uses a transient public key.  If it
has a permanent relationship with the server, it uses a
durable public key representing that relationship, one
key per relationship.  This public key is not in fact
public, but is a shared secret between the server and
the client.  The corresponding durable  secret key is
not necessarily stored on the client for an unlimited
time, but may be, at the cost of an extra round trip,
generated from a durable salt stored on the server and a
short password that is not a shared secret, but a truly
private secret known only to the client, subject to
dictionary attacks by the server, or by anyone that
manages to steal the server login database, but not
subject to dictionary attacks by eavesdroppers or by
active adversaries who interfere with messages.  Hence
the need for the client durable public key to remain
If the client wishes to prove rightful possession of a
certain reputation to a third party, it uses transient
cookies issued by a reputation server.  Servers,
however, generally have distributed reputation attached
to their long lived public keys - distributed reputation
being held by clients, not by some reputation server.
In this post I ignore the hard question of server key
distribution, glibly invoking Zooko's triangle without
proposing an implementation of the other two points and
three sides of the triangle or a solution to the problem
of managing distributed reputations in Zooko's triangle.
If the client wishes to login, wishes the server to
recall a durable relationship:
Client generates random ephemeral private key x,
generates ephemeral public key X=g^x, recollects
relationship specific durable private and public keys c
and C, recollects Server public key S
Client -> Server:
If the requested protocol is not OK, we go into protocol
negotiation.  Assuming it is OK, which it probably will
be, server assigns a port number that the client is to
use in sending it packets.
Server generates random ephemeral private key y,
generates ephemeral public key Y=g^y + C, and random
number v.
Server does not generate a new ephemeral private key for
every connection attempt.  It generates a new ephemeral
private key at most every few seconds.  It does however
generate a new random number v for every connection
The port address has to contain enough bits that DoS
cannot cause the server to rapidly rotate through all
free ports.  Server encrypts the port number using a
symmetric key known only to itself, together with the
network address information and other connection setup
material, v, and sufficient information to identify
which value of y and Y, out of several recent values, it
is using for this connection attempt.
Let us call this block of encrypted information Q.  This
value will be sent to client, and then back to server,
unchanged.  Its function is to avoid the necessity for
the server to allocate memory for a client that has not
yet validated. Instead the state information is sent
back and forth.  To save space, v could be a hash of Q.
It does no harm to use the same value of y with several
clients, provided that each client uses its own X - it
is only a problem if y stays unchanged for days.  We
limit the frequency at which y is changed to be such
that the CPU cannot be overloaded.  It would do harm to
use the same value of v with several clients, for if one
client knows in advance what the value of v is going to
be, it can cook X to fake being another client.
Server --> Client:
Client does the proof of work, and generates a random
number u, which is generated after Server has committed
itself to Y, because we don't want Server to know u
until after it has committed to a particular value for
y.   Similarly, we did not want client to know v until
after it committed itself to a particular value for x.
Client computes shared secret as hash of ((Y-C) .
Now Client encrypts and authenticates the first packet
of actual information, the payload to be transmitted in
this encrypted and authenticated conversation, preceding
it with the random number u.
Client --> Server:
Server checks the proof of work, decrypts server
encrypted setup information to make sure it is validly
formatted, and therefore that it originated from the
itself, then creates an entry in its hash table for this
connection. It computes the shared secret as hash of
This will agree with the client side shared secret, for
they are both equal to g^((y+su)(x+cv))
You will notice that the server only allocates memory
and does heavy computation *after* the client has
successfully performed proof of work and shown that it
is indeed capable of receiving data sent to the
advertised network address.
Now we have a shared secret, protocol negotiated, client
logged in, in one round trip plus the third one way trip
carrying the actual data - the same number of round
trips as when setting up an unencrypted unauthenticated
TCP connection.
You will notice there is no explicit step checking that
both have the same shared secret - This is because we
assume that each packet sent is also authenticated by
the shared secret, so if they do not have the same
secret, nothing will authenticate.
Let us suppose instead that the client is *not* going to
login - that the client is a random anonymous client
logging in to a known server with a widely known public
In that case, the protocol is the same except that c is
always zero, and v is irrelevant.

@_date: 2007-12-01 12:28:28
@_author: James A. Donald 
@_subject: refactoring crypto handshakes (SSL in 3 easy steps) 
> The obvious way - doing a specific step just to verify
 > the handshake - is the kind of code-centric thinking
 > that I'm trying to avoid.  I'm having trouble finding
 > the right words for it.  Basically an encrypted
 > network protocol is a language in which a transmission
 > is syntactically correct if and only if all the
 > security properties hold. In some ways current
 > protocols are like a poorly-written language whose
 > parser that needs a seperator character between
 > statements instead of being able to detect the syntax
 > error when it starts processing the following
 > statement.  Basically it lacks even a single symbol
 > look-ahead.
SRP, as specified, validates that the shared secret on
both sides is the same, requiring an extra 0.5 RTT.  If
message validation depends on the entire shared secret,
then validating that they are identical is unnecessary.

@_date: 2007-12-01 14:24:34
@_author: James A. Donald 
@_subject: PlayStation 3 predicts next US president 
============================== START ==============================
 > We also announce two different Win32 executables that
 > have identical MD5 hash values. This can be made to
 > happen for any two executable files. This implies a
 > vulnerability in software integrity protection and
 > code signing schemes that still use MD5. See
 >  for
 > details.
That MD5 is broken is of course old news.
I observe that US authorities have decided on a hash,
found it was broken, decided on a new hash, found it was
broken also, and are now where we are.
Russian authorities decided on a 256 bit hash in 1990:
GOST R 34.11-94.  It is still good as far as anyone
knows, and has never needed to be changed.
This entirely confirms my prejudices about the US
government cryptographers.

@_date: 2007-10-12 06:44:15
@_author: James A. Donald 
@_subject: 307 digit number factored 
--
 > AFAIK, the only advantage of ECC is that the keys are
 > shorter. The disadvantage is that it isn't as well
 > studied.
On past performance, elliptic curves are safer than
integers.  From time to time, integer based asymmetric
encryption is abruptly and surprisingly weakened by
advances in discrete log algorithms.  This is just not
happening with elliptic curves.
The cost of computing power is going down faster than
the cost of communication.  The size of sufficiently
safe asymmetric encryption based on integers is growing
considerably faster than the size of sufficiently safe
asymmetric encryption based on elliptic curves.
Thus the advantage of elliptic curve encryption
continually increases, will become overwhelming in the
near future - and a large part of that continually
increasing advantage comes from unpredictable
improvements in factoring and discrete log over the
My intuition is that because elliptic curves are
considerably less orderly than the integers, there is
less scope for discovering fast discrete log methods. We
are continually discovering improvements to finding
discrete logs over the integers.  It has been a long
time since any such has been discovered for elliptic
curves, long enough to give a plausible hope that no
further such will ever be discovered.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      ibAQXQ+Yoy5neOvRwKJwdxVLDGSPwTxKobkv566h
      4khPsLmyqlil/F6sx2n1q9mtb65W8RMcWyqxregOo

@_date: 2007-10-12 07:22:10
@_author: James A. Donald 
@_subject: 307 digit number factored 
At the timpe that  was published, 1024 bit asymmetric encryption over integers was comparable in strength to 80 bit symmetric encryption, and elliptic curve encryption over a 160 bit fields.
At that time integers based asymmetric encryption took about four times as long to compute as the comparable strength elliptic curve asymmetric Since then, integer encryption has weakened further relative to elliptic curve encryption, due to advances in factorization and the discrete log problem, increasing the advantage of elliptic curves.
With widespread failure to use encryption due to the computational costs a factor of more than four is not to be sneezed at.

@_date: 2007-10-12 07:43:41
@_author: James A. Donald 
@_subject: 307 digit number factored 
A 307 digit number is 1024 bits, near enough.  1024 bits
was scheduled to fail in 2013.  It has failed early, due
to modest advances in factorization.
Thus past comparisons of the strength of encryption key
sizes are no longer entirely accurate.  Further, they
never were that accurate to start with - one needs
actual run times for breaks run on the same machine.
None of the past comparisons have started from such
concrete data.

@_date: 2007-10-12 09:42:18
@_author: James A. Donald 
@_subject: Avoiding certicom patents. 
--
Avoiding certicom patents.
The two patents that are actually useful are point
compression and ECMQV
Bodo Moeller, quoted by Bernstein, points out that one
can do point compression following the method of page
171 of the Harper-Menezes-Vanstone paper "Public-key
cryptosystems with very small key lengths" at Eurocrypt
'92, published more than a year before the filing of the
point compression patent.
::	The key length can be shortened to n+1 bits as
::	follows. Observe first that the change of
::	variables (x,y) -> (x,xz) transforms equation
::	y^2 + x*y = x^3 + a*x^2 + b, (1)
::	to
::	z^2 + z = x + a + b*x^(-2),  (3)
::	Given the x-coordinate of a point P = (x,y),
::	we can compute the right hand side of (3).
::	Then (3) has precisely 2 solutions, namely z'
::	and z'+1, and these solutions can be easily
::	found. We can then select the correct solution
::	z (and hence reconstruct y as y = xz) if we
::	know the least significant bit of z. Thus to
::	transmit P it is sufficient to transmit x and
::	the least significant bit of y/x.
I am not a lawyer, but if one follows the method as
given in the paper, and place direct quotes from the
paper in the source code comments and product
documentation, that should cover one's ass.
What ECMQV does is get forward secrecy *and*
authentication without additional cost.
If, however, we don't need the point compression patent,
neither do we need ECMQV.
Let capital letters represent elliptic curve points,
lower case letters represent integers modulo the order
of the generator.  Multiplication of an elliptic curve
point by an integer to give another elliptic curve point
takes polynomial time, division by an integer takes
exponential time, takes time 2^(n^2) where n is the bit
size of the field.
Simpe DH is as follows:
Bob has a secret key b, the integer b, and a well known
public key B = b*G, where G is the generator.
Carol has a secret key c, the integer c, and a well
known public key C = c*G, where G is the generator.
Bob constructs the shared secret b*C, Carol constructs
the shared secret c*B, b*C=c*B
This, however, means they use the same secret each time,
which can cause problems.  Best to use a secret that
randomly changes from time to time.
So to fix this:
Bob generates a random and frequently changing secret
number x, and transmits the point compressed value of X,
X=x*G to Carol.
Carol generates a random and frequently changing secret
number y, and and transmits the point compressed value
of Y, Y=y*G to Bob.
Bob computes (x+b)*(Y+C), Carol computes (c+y)*(X+B).
(x+b)*(Y+C) =(c+y)*(X+B)
Now if we were transmitting uncompressed points, there
would be some attacks which ECMQV prevents, but since we
are transmitting compressed points, these attacks cease
to work.
I repeat, I am not a lawyer, but then neither are the
judge or jury mathematicians.  If you simply don't have
the additional steps listed in ECMQV, how are they going
to justify the claim that it somehow really is ECMQV?
Note that that point compression avoids the attacks that
motivate ECMQV has not been examined in the literature,
nor have patent lawyers looked at any of the information
I present here.
     --digsig
          James A. Donald
      6YeGpsZR+nOTh/cGwvITnSR3TdzclVpR0+pr3YYQdkG
      Hby8ToP7gt/aBQ1wfI7BDP13fj4dqb/RwBUcQtKe
      4kJnBa/Brr+PMEJFoEXvPbwbP2fcEYkPJo0Co59YI

@_date: 2007-10-13 14:37:36
@_author: James A. Donald 
@_subject: 307 digit number factored 
James A. Donald:
And in those twenty years we have made little progress on the division problem with elliptic curves, and considerable progress on the discrete log problem on integers.  Surely, with a thousand year start, progress on integers should be slowing down, not speeding up.
Further, this is what one would expect from the irregular character of elliptic curves.

@_date: 2007-09-05 09:56:18
@_author: James A. Donald 
@_subject: Neal Koblitz critiques modern cryptography. 
> This part is not too radical. The more specific
 > skepticism of security proofs (I am reluctant to agree
 > that these are actively harmful), seems to be a
 > combination of the peer review issue above, and
 > (often?) lack of tight bounds that make the proofs
 > applicable to realistic parameter sizes.
"Proof of security" is actively harmful, for the best
proofs of security are not worth much, and merely by
existing, they give license for people to produce proofs
that are amazingly worthless.   As "proofs" of ever
diminishing value multiply, it becomes difficult to
distinguish the multitude of utterly worthless "proofs"
from those proofs that have some limited value.
While it is possible to produce a proof that is actually
worth something, lots of morons glibly churn out large
numbers of proofs that are as stupid as they are
Even the best "proofs" of security involve some
misdirection and a lowering of our standards about
proof, whereupon one thousand idiots gleefully point at
that subtle lowering of standards as justification to
lower standards a great deal further - snake oil wearing
the decorations of mathematics.

@_date: 2007-09-10 13:46:35
@_author: James A. Donald 
@_subject: What is a proof? 
If a proof is a record of a mental journey in which one person has discovered an important truth, and then made a record of that journey adequate so that a second person can walk the same path and see the same truth, then cryptography could do with more and better proofs.
If, on the other hand, a proof is an argument impressively decorated with mathematical sounding jargon, cryptography could do with a good deal fewer of them.

@_date: 2007-09-18 09:13:35
@_author: James A. Donald 
@_subject: using SRAM state as a source of randomness 
> Back in the late 60's I was playing with audio and a
 > magazine I subscribed to had a circuit for creating
 > warble tones for standing wave and room resonance
 > testing.
 >
 > The relevance of this is that they were using a
 > "random" noise generating chip that they acknowledged
 > was not random enough for good measurements. The fix
 > suggested was to parallel a number, six as I recall,
 > to improve the randomness by mixing the signals to
 > achieve better randomness. I don't recall the math but
 > the approach improved the randomness by more than an
 > order of magnitude.
If one such chip was so non random that the ear could
hear the difference from white noise or pink noise, it
is most unlikely that six together would be random
enough for cryptographic purposes.
As has often been stated on this list, the noise source
must be understood, so that we have physical theory as
to where the noise is coming from, and also tested to
make sure it is functioning in accord with theory.  No
one really understands where zener diode noise is coming
True entropy in equals true entropy out.   You need to
be able to determine the true entropy in from physical
theory, and be able to test the hardware to check it is
working in accordance with theory.
To know that a true random number generator is
cryptographically secure, you need knowledge of the
underlying hardware, knowledge that shows it derives its
randomness from the fundamental randomness of the
universe, either thermal entropy, (Johnson noise) or
quantum indeterminacy (shot noise), knowledge that
enables us to determine the good functioning of the
underlying noise amplification circuits from the
character of the output.
A good circuit would simply directly amplify the
underlying noise source, so that the entropy of the
output would be somewhat less than one entropy bit per
signal bit, thus ensuring that any malfunction of the
underlying circuit would be obvious, and then pass that
output into a hash generator, which emits hash that
outputs less bits than the true entropy.
Using SRAM as a source of either randomness or unique
device ID is fragile.  It might well work, but one
cannot know with any great confidence that it is going
to work.  It might work fine for every device for a
year, and then next batch arrives, and it completely
fails.  Worse still, it might work fine on the test
batch, and then on the production run fail in ways that
are subtle and not immediately obvious.

@_date: 2008-04-30 06:34:59
@_author: James A. Donald 
@_subject: "Designing and implementing malicious hardware" 
Assume the hook works by waiting for a very specific sequence of bits to   arrive along a wire, then causing an interrupt giving ring zero control to the memory location following that which the bits came from.
No amount of testing is going to reveal the hook until it is used by the The hardware can be obfuscated, as in the innocent looking vote count programs.  Correctly reverse engineering every gate, and making sure that it does in fact work as directed is likely to be hard, particularly as it is easy to unintentionally build chips that do not function as one would expect, chips where no one can figure out why they behave the way they do.

@_date: 2008-08-28 06:21:02
@_author: James A. Donald 
@_subject: SRP implementation - choices for N and g 
There is no readily apparent reason why N and g should not be application wide.
Of course, some clever persons might discover some unobvious flaw.
Rather than using SRP, you might use J-PAKE.  J-PAKE has a proof that there is nothing wrong with J-PAKE unless there is something wrong with all similar protocols, so you can go right ahead and do what all the other protocols do - which is one value of N and g for all.

@_date: 2008-12-11 10:46:51
@_author: James A. Donald 
@_subject: CPRNGs are still an issue. 
> I think the situation is even worse outside of the
 > major projects (the OS kernels crypto implementations
 > and the main crypto libraries). I think outside of
 > those, nobody is even really looking. For instance -
 >
 > This afternoon I took a look at a C++ library called
 > JUCE which offers (among a pile of other things) RSA
 > and Blowfish. However it turns out that all of the RSA
 > keys are generated with an LCRNG (lrand48, basically)
 > seeded with the time in milliseconds.
 > If one uses a higher resolution counter - sub
microsecond - and times multiple disk accesses, one gets
true physical randomness, since disk access times are
effected by turbulence, which is physically true
In Crypto Kong I added entropy at various times during
program initialization from the 64 bit performance
counter.  Unfortunately the 64 bit performance counter
is not guaranteed to be present, so I also obtained
entropy from a wide variety of other sources - including
the dreaded millisecond counter that has caused so many
security holes.

@_date: 2008-12-11 13:22:56
@_author: James A. Donald 
@_subject: Why the poor uptake of encrypted email?  [Was: Re: Secrets and 
--
 > > We discovered, however, that most people do not want
 > > to manage their own secrets ....
 > This may help to explain the poor uptake of encrypted
 > email.
There is very good uptake of skype and ssh, because
those impose no or very little additional cost on the
end user. Secret management is almost furtively sneaked
in on the back of other tasks.
 > It would be useful to know exactly what has been
 > discovered.  Can you provide references?
It is informal knowledge.
A field has references when it is a science, or
attempting to become a science, or pretending to become
a science.  Security is not yet even an art.
Cryptography is an art that dubiously pretends to
science, but the weak point of course is interaction of
humans with the cryptography, in which area we have not
even the pretense of art.

@_date: 2008-12-18 12:00:35
@_author: James A. Donald 
@_subject: Why the poor uptake of encrypted email? 
> Providing a suitable e-mail security solution for the
 > masses strikes me as more important than providing
 > anonymity to the few people who want or need it.  Not
 > that you can't have both, unless you want everyone to
 > use PGP or S/MIME as a way to hide anonymized traffic
 > from non-anonymized traffic.
If email goes away - as I hope and expect it will - we
will need a new store and forward solution to support
A store and forward system is a system without end to
end real time round trips.  Obviously end to end real
time round trips prevent anonymity.
A system built on top of a best effort unreliable
messaging system requires some round tripping, which
does not make anonymity impossible, but does make it
tricky.  Email's architecture is very nice for
supporting anonymity.

@_date: 2008-12-18 13:06:37
@_author: James A. Donald 
@_subject: Why the poor uptake of encrypted email? 
> ... to a statistically irrelevant bunch of geeks.
 > Watch Skype deploy a not- terribly-anonymous (to the
 > people running the Skype servers) communications
 > system.
Actually that is pretty anonymous.  Although I am sure
that Skype would play ball with any bunch of goons that
put forward a plausible justification, or threated to
rip their fingernails off, most government agencies find
it difficult to deal with anyone that they cannot
casually have thrown in jail - dealing with equals is
not part of their mindset.  So if your threat model does
not include the FBI and the CIA, chances are that  the
people who are threatening you will lack the
organization and mindset to get Skype's cooperation.

@_date: 2008-02-01 18:24:25
@_author: James A. Donald 
@_subject: Dutch Transport Card Broken 
You are asking for a layered design that works better than the existing layered design.  My claim is that you get an additional round trip for each layer - which your examples have just demonstrated.
SSL has to be on top of a reliable transport layer, hence has to have an extra round trip.  I was not proposing something better *for* SSL, I was proposing something better *instead* *of* SSL.  If one takes SSL as a given, then indeed, *three* round trips are needed before the client can send any actual data - which is precisely my objection to SSL.

@_date: 2008-02-01 18:42:03
@_author: James A. Donald 
@_subject: Gutmann Soundwave Therapy 
I have been considering the problem of encrypted channels over UDP or IP.  TLS will not work for this, since it assumes and provides a reliable, and therefore non timely channel, whereas what one wishes to provide is a channel where timeliness may be required at the expense of I have figured out a solution, which I may post here if you are interested.

@_date: 2008-02-03 12:51:25
@_author: James A. Donald 
@_subject: Gutmann Soundwave Therapy 
--
 > The wider point of Peter's writeup -- and of the
 > therapy -- is that developers working on security
 > tools should _know_ they're working in a notoriously,
 > infamously hard field where the odds are
 > _overwhelmingly_ against them if they choose to
 > engineer new solutions.
That point is of course true.  But the developers wanted
to transport IP and UDP.  Peter should have known that
SSL is incapable of transporting IP and UDP, because it
will introduce large, unpredictable, and variable
If, for example, VOIP goes over SSL, the speakers would
become entirely unintelligible.
So yes, the developers were incompetent in that they
badly underestimated the difficulty of the task.  And
Peter was incompetent in thinking that one layer of a
solution for a particular problem can be plucked out of
that environment, an environment where it works very
badly, and plonked into another, very different,
Not only do new solutions generally not work, but
existing solutions generally work badly, and are
commonly inapplicable outside their particular special

@_date: 2008-02-04 14:29:50
@_author: James A. Donald 
@_subject: Gutmann Soundwave Therapy 
>> I have figured out a solution, which I may post here
 >> if you are interested.
 > I'm interested.  FTR, zooko and I worked on part of
 > the problem, documented briefly here:
 > I have posted "How to do VPNs right" at
It covers somewhat different ground to that which your
page covers, focusing primarily on the problem of
establishing the connection.
It covers the cryptography of packets only to the depth
needed to establish the required properties of sessions:
My page completely ignores the routing issue, another
hard problem which existing VPNs frequently do wrongly,
or not at all.  It presupposes the existence of good
random number sources.
It does not address the question of denial of service
attacks against the session establishment protocol,
though I have written that up elsewhere, and will
publish that shortly.

@_date: 2008-02-04 18:43:49
@_author: James A. Donald 
@_subject: Fixing SSL (was Re: Dutch Transport Card Broken) 
> They can't be as "anonymous as cash" if the party
 > being dealt with can be identified.  And the party can
 > be identified if the transaction is "online,
 > real-time".  Even if other clues are erased, there's
 > still traffic analysis in this case.
 >
 > What the offline paradigm has going for it is the
 > possibility of true, untraceable anonymity through the
 > use of anonymizing remailers and related technologies.
A ripple payment protocol could in practice much
resemble an onion protocol.  Someone trying to trace a
ripple payment might find that the first level is some
highly cooperative bank, and the next level is someone
in the Carribean who will cooperate only if offered a
suitable inducement, and upon a suitable inducement
being applied, reveals that the next level is ....
I suspect, however, that ripple is apt to be a violation
of the money laundering laws, with ripple intermediaries
being defined as straw men or smurfs.

@_date: 2008-02-05 08:17:32
@_author: James A. Donald 
@_subject: Dutch Transport Card Broken 
> Sounds a bit like SCTP, with crypto thrown in.
SCTP is what we should have done http over, though of
course SCTP did not exist back then.  Perhaps, like
quite a few other standards, it still does not quite
 > I thought it was the latency cause by unnecessary
 > round-trips and expensive key exchange crypto that
 > motivated your proposal.  The cost of session crypto
 > is probably not as noticeable as that of the latency
 > of key exchange and authentication.
The big problem is that between the time one logs on to
one's bank, and the time one logs off, one is apt to
have done lots and lots of cryptographic key exchanges.
One key exchange per customer session is a really small
cost, but we have a storm of them.
Whenever the web page shows what is particular to the
individual rather than universal, it uses a session
cookie, visible to server side web page code.
Encryption, the bundle of shared secrets that enable
encrypted communications, should be visible at that
level, should be a session cookie characteristic rather
than a low level transport characteristic, should have
the durability and scope of a session cookie, instead of
the durability and scope of a transaction.
Because we use encryption merely at a level where it is
logically transient, because it protects transactions
rather than relationships, the connections are too
costly, and fail to provide the information about
relationships that are needed to protect the user.
If we had implemented http over something like SCTP,
then an SCTPlike connection value should have been a
cookie.  One should have been able to look at the
SCTPlike connection value in the server side page code,
and be pretty sure that if the person is the same, the
connection value will be unchanged, so that one could
then associate additional state with the connection
value - encryption being some more state.
Encryption parameters have more in common with session
cookies than with transactions.  They should be about
relationships, not data transport.
If encryption setups were made and discarded only as
often as session cookies, not so costly.  It is making
them and discarding them as often as transactions that
hurts. Also, the fact that they are so frequently
discarded means that scope information is unavailable to
secure relationships, means we cannot provide useful
information to the end user about who he is really
talking to, because the encryption does not know about
relationships, even though encryption should be about
With encryption merely at the transactional level, the
browser can know the true name of website you are
looking at, that being merely a page property, but
cannot know what relationship you think you are
participating in.  To provide security, client side
code, browser chrome, needs to know not the true name of
the web site, but if you are at a web site where you
have user name or durable user ID.

@_date: 2008-02-10 19:23:59
@_author: James A. Donald 
@_subject: Dutch Transport Card Broken 
> There's another issue: initial account setup.  [Even
 > with SRP] people will still need to rely on
 > certificate-checking for that.  It's a real problem at
 > some hotspots, where Evil Twin attacks are easy and
 > lots of casual users are signing up for the first
 > time.
For banks and health care, initial account setup always
involves out of band communication, so certificate
checking not needed.
We need to build our security mechanisms to fit
characteristic human out of band security, rather than
trying to force humans to imitate computers.

@_date: 2008-01-03 12:51:31
@_author: James A. Donald 
@_subject: Death of antivirus software imminent 
> Detecting viruses is a fundamentally losing battle: a
 > sufficiently advanced virus can fully simulate a clean
 > computer for the scanner to run in.
 >
 > On the other hand, writing an OS that doesn't get
 > infected in the first place is a fundamentally winning
 > battle: OSes are insecure because people make
 > mistakes, not because they're fundamentally
 > insecurable.
 >
 > Detecting spam by analysis of the text is another
 > losing battle: even humans can't always agree on
 > what's spam.
 >
 > The maddening part is that security as an industry is
 > almost always forced to fight on the losing
 > battlefields, even though we've had beautiful,
 > efficient, impregnable fortresses available for many
 > years. Any crypto book from 20 years ago can show you
 > how to send an unforgeable email or sign a binary, yet
 > these notions still haven't widely caught on
Books from twenty years ago will not tell you how to
make your impregnable fortress useful, usable, and
convenient.  Impregnable fortresses tend to be located
at the North Pole, and customers fail to show up.
Further, often what is built is an impregnable wall,
rather than an impregnable fortress.  The other three
walls are overlooked, or if overlooked, there is no way
in, or if a way in is provided, anyone can go through

@_date: 2008-01-04 20:30:12
@_author: James A. Donald 
@_subject: Death of antivirus software imminent 
> I think Steve is completely correct in the case of
 > cryptography. We have a lot of experience of real
 > world security failures these days, and they're not
 > generally the sort that crypto would fix.
They are the sort that a different sort of way of using
crypto could fix.
 >> Authentication is exactly what I need in the case of
 >> spam/phishing:
 > People have said that for quite some time. However, I
 > doubt it would actually help. In the case of spam, all
 > that would end up happening is vast amounts of CPU
 > time being spent demonstrating that the made up
 > addresses on spam were associated with actual RSA
 > keys. (There is no practical limit to the number of
 > RSA keys that may be generated.)
First, the phishing case:
Assume that instead of logging in through a possibly
hostile web page, people login using SRP built into the
browser chrome.  Then phishing goes away, because the
man in the middle gets no shared secrets.
Next, the spam case, including spam offering high yield
investments, spam promising millions of dollars stolen
from starving Africans, Indian made viagra, porn sites,
and two hundred and seventy tons of sugar.
To fix spam, we need automatic whitelisting plus
aggressive Baysian filtering.  At present this works
fine, no crypto needed, because the attacker seldom
bothers to adapt to your particular profile.  Tons of
spam descend upon me, and is magically banished, sight
unseen. When impersonation spam attacks become a serious
problem, then we will think about how to use
cryptography to beat them.  Sometimes I have to manually
whitelist people, which Grandma could not do, but that
is a user interface problem - observe that most IM
systems make whitelisting easy enough for Grandma.
 > I would actually agree that we can implement operating
 > system strategies that make malware harder to write. I
 > don't know if it is likely that any current
 > techniques, even including the nearly unheard of use
 > of formal verification, would actually eliminate
 > malware.
OLPC seems very nearly malware proof.  Malware would
require unusual privileges, and there is no easy way to
install software that requires unusual privileges on

@_date: 2008-01-07 05:54:35
@_author: James A. Donald 
@_subject: Death of antivirus software imminent 
Leichter, Jerry
 > > Why not just require that the senders of malign
 > > packets set the Evil Bit in their IP headers?
 > >
 > > How can you possibly require that encrypted traffic
 > > *generated by the attackers* will allow itself to be
 > > inspected?
 > You misunderstand me.  We can for the most part easily
 > identify encrypted data, either it is using a standard
 > like SSL or it is non-standard but can be identified
 > by data payload characteristics (i.e. random bits).
Steganography will beat that.  If the government demands
non random bits, non random bits will be provided.
 > If it is a standard (or even a defacto standard like
 > Skype) we can require access under proper authority.
 > If it is not (or access under authority is refused),
 > then just simply block or drop the packets, there's no
 > need to inspect them.
This means that only authorized, regulated, officially
registered data formats shall be permitted.  It will be
almost impossible, most likely completely impossible,
for *my* format to get registered even though it sends
data completely in the clear.  Skype will be
grandfathered in, but the next Skype will not be.
So I will do what the bad guys do - steganograph my
entirely innocuous application, which would not need
cryptography at all except to escape intrusive
regulation, forcing me to hide my actual data format
inside a registered and officially authorized data

@_date: 2008-01-07 06:29:29
@_author: James A. Donald 
@_subject: Question on export issues 
Peter Gutmann:
 > > That's because there's nothing much to publish: In
 > > the US, notify the BIS via email.
 > Our outside counsel -- specializing in this area --
 > thought this was insufficient.
You were probably asking your counsel the wrong
question.  Never ever ask the question "is this legal",
for you will always find that the answer to that is that
NOTHING is legal, and hearing your counsel tell you that
puts you in trouble.  The question should have been "Has
anyone got in trouble for doing this, and if so, how big
a trouble, and what attracted the attention of the man?
Had you asked that question instead, you would have
heard the answer that no one ever gets in trouble for
minimalist compliance with the export laws - an answer
that cannot get you, or your counsel, in trouble.
Legislation and regulation, though never revealing what
is legal, frequently forbids and commands all sorts of
things quite clearly, telling us all sort of things are
forbidden and yet ninety nine percent of such
legislation and regulation is dead as a doornail.
It is never possible to know what is permitted, so you
must never ask your counsel about what is permitted,
since he is legally required to give answers that create
problems.  Legal uncertainty and capricious enforcement
of obscure, unclear  and incomprehensible laws is simply
a cost of doing business.  No legal counsel can reduce
this cost, and if asked to do so, is legally required to
give answers that increase, rather than reduce this
When you ask a counsel to provide legal certainty, you
ask him for what can never exist, and what he is
forbidden to provide.

@_date: 2008-01-18 19:35:57
@_author: James A. Donald 
@_subject: Death of antivirus software imminent 
> Generally any standard encrypted protocols will
 > probably eventually have to support some sort of CALEA
 > capability. For example, using a Verisign ICA
 > certificate to do MITM of SSL, or possibly requiring
 > Ebay to provide some sort of legal access to Skype
 > private keys.
And all the criminals will of course obey the law.
Why not just require them to set an evil flag on all
their packets?
 > If there is a 2nd layer of encryption then this would
 > require initial key exchanges that may be vulnerable
 > to interception or after-the-fact analysis of the
 > decrypted SSL payloads.
I guarantee I can make any payload look like any other
payload.  If the only permitted communications are
prayers to Allah, I can encode key exchange in prayers
to Allah.

@_date: 2008-01-25 13:04:09
@_author: James A. Donald 
@_subject: Dutch Transport Card Broken 
The Dutch government paid two billion dollars for stupidity, for foolishness that almost anyone on this list could have told them was foolish.  Secret algorithm!

@_date: 2008-01-28 14:28:54
@_author: James A. Donald 
@_subject: Lack of fraud reporting paths considered harmful. 
> The call-the-customer-and-reissue mechanism is a
 > mediocre solution to the fraud problem, but it is the
 > one we have these days.
Why is it a mediocre solution?
The credit card number is a widely shared secret.  It
has been known for centuries that widely shared secrets
have a short life expectancy and should be frequently
The only better solution is unshared secrets.  Is that
what you had in mind?  Instead of the customer sharing
his secret with the merchant, and the merchant checking
it with the bank, customer should prove to bank that the
person who knows the secret wishes to pay the merchant
for the identified promise.

@_date: 2008-01-30 09:04:37
@_author: James A. Donald 
@_subject: Dutch Transport Card Broken 
> Some number of these muppets approached me over the
 > last couple of years offering to donate a free license
 > for their excellent products. I used to be more polite
 > about it, but nowadays I ask that they Google the
 > famous Gutmann Sound Wave Therapy[0] and mail me
 > afterwards.
  Gutmann Sound Wave Therapy: Gutmann recommends:
: :	Whenever someone thinks that they can replace
: :	SSL/SSH with something much better that they
: :	designed this morning over coffee, their
: :	computer speakers should generate some sort
: :	of penis-shaped sound wave and plunge it
: :	repeatedly into their skulls until they
: :	achieve enlightenment.
On SSL, Gutmann is half wrong:
SSL key distribution and management is horribly broken,
with the result that everyone winds up using plaintext
when they should not.
SSL is layered on top of TCP, and then one layers one's
actual protocol on top of SSL, with the result that a
transaction involves a painfully large number of round
We really do need to reinvent and replace SSL/TCP,
though doing it right is a hard problem that takes more
than morning coffee.
As discussed earlier on this list, layering induces
excessive round trips.  Layering communications
protocols is analogous to having a high level
interpreter written in a low level language. What we
need instead of layering is a protocol compiler,
analogous to the Microsoft IDL compiler.  The Microsoft
IDL compiler automatically generates a C++ interface
that correctly handles run time version negotiation,
which hand generated interfaces always screw up, with
the result that hand generated interfaces result in
forward and backward incompatibility, resulting in the
infamous Microsoft DLL hell.  Similarly we want a
compiler that automatically generates secure message
exchange and reliable transactions from unreliable
packets. (And of course, run time version negotiation)

@_date: 2008-01-30 15:18:56
@_author: James A. Donald 
@_subject: Dutch Transport Card Broken 
James A. Donald:
 >> SSL is layered on top of TCP, and then one layers
 >> one's actual protocol on top of SSL, with the result
 >> that a transaction involves a painfully large number
 >> of round trips.
 > Perhaps theoretically painful, but in practice this is
 > not the case; commerce on the web is the
 > counter-example.
The delay is often humanly perceptible.  If humanly
perceptible, too much.
 > The benefits of layering for outweigh the perceived
 > gains of just merging it all together into one glob.
 > For example, the ability to replace layers, or replace
 > them by just dropping in a new library.
Compilation would provide the same benefits, and a fair
bit more - such as built in protocol negotiation, rather
than protocol negotiation being reinvented ad hoc in a
different and incompatible way each, and bolted on after
the fact in a different way each time.

@_date: 2008-01-31 08:22:12
@_author: James A. Donald 
@_subject: Fixing SSL (was Re: Dutch Transport Card Broken) 
> Huh? What are you claiming the problem with sending
 > client certificates in plaintext is (as if anyone uses
 > client certificates anyway)?
Well that is one problem - no one uses them, and no one
should use them, while PKI was designed under the
assumption that everyone would be using them.
Another problem is that in practice the system merely
ensures you are getting the purported domain name. Since
we are overwhelmed by a multitude of irrelevant and
confusing domain names, this is not much help. Further,
I frequently get the warning that the certificate does
not agree with the domain name when I know well that I
am communicating with the intended entity - frequent
misconfiguration results in false warnings, which I am
thus trained to ignore, rendering the system entirely
Since we rely on passwords, social security numbers, and
so forth, shared secrets, people are trained to give
away secrets to purported authority, which creates the
phishing hazard. We need to fix both problems.
Of course, if the phishing hazard was fixed, we would
still have the malware hazard, but we now know how to
fix the malware hazard.
We should fix both problems, rather than using one as an
excuse for not fixing the other.  We need to fix the
network assuming the node is going to be made safe, and
fix the node assuming the network is going to be made
 >> Does anyone have an idea how we can fix this flaw
 >> within SSL/TLS within a reasonable timeframe, so that
 >> it can be implemented and shipped by the vendors in
 >> this century?
 > This gets discussed on the TLS mailing list
 > occasionally, but the arguments for making this change
 > aren't very convincing. If you have an actual credible
 > security argument you should post it to tls at ietf.org.
I don't think that is a useful discussion forum.  The
IETF is moribund, paralyzed and increasingly irrelevant.
If the internet is to be fixed, the fixes have to bypass
the IETF.
When one has a large group, group dynamics can make the
large group a little bit smarter than its smartest
members, but more commonly, make it a lot dumber than
its dumbest members.  If the IETF was capable of
handling, or even noticing, the crisis that we in then
we would not be in this crisis.
To fix the phishing problem, we need to
cryptographically secure relationships, rather than
attempting to cryptographically secure true names, and
to greatly reduce reliance on revealing shared secrets.
It should be unusual and disturbing to reveal shared
secrets, rather than routine, and it should only be done
with humans, not machines.
1.  As with Skype to Skype IM, the fact that you can
receive a message from what purports to be an entity
with which you have a relationship, should be compelling
evidence that it really is that entity, the entity to
which you have given a petname on your contacts list.
Thus phishing is hard to initiate.  As with Skype, what
we seek to secure is petnames, not true names.  We want
to secure the bookmark list, and the list that comes up
in a Google search.  We want to secure that when you
click on a the top entry of the Google list, you are
contacting the intended entity.
2.  As with Skype to Skype IM, this should be symmetric.
If you respond to a message from your bank, or initiate
a message to your bank, you should not have to reveal
some shared secrets to prove an existing relationship
before getting on with your task. Thus phishing should
fail to catch any phish.

@_date: 2008-01-31 09:40:58
@_author: James A. Donald 
@_subject: Dutch Transport Card Broken 
> (No, I'm not a fan of X.509 certs, but those are not
 > core to the protocol, and you can think of them as
 > nothing more than a fancy key container format if you
 > like. Key management is not addressed by SSL, so there
 > is no reason that fixing key management has anything
 > to do with SSL per se.)
The two actually working, widely used, secure systems
are SSH and Skype, neither of which uses SSL/TLS/PKI
The proof of the pudding is in the eating.  When large
numbers of people use cryptography that really does make
them secure, they are not using SSL/TLS/PKI.
SSL involves digital certificates.  The particular
digital certificate format necessarily imply a PKI
structure with the same sort of defects as the existing
PKI structure, which secures what does not matter much,
and fails to secure that which does matter.  In this
sense, X.509 certificates are core to the protocol, and
that is the big problem with the protocol, though
neither am I happy about the fact that when the client
initiates a communication, the data it actually wants to
send only gets sent after the the *third* round trip.
 > My opinion (and just about everyone else's) is well
 > known.
There is a serious security problem in the network.  It
needs fixing. SSL/TLS/PKI exists, yet is entirely
ineffectual in fixing it.

@_date: 2008-07-03 08:45:49
@_author: James A. Donald 
@_subject: Strength in Complexity? 
Usability disasters such as DNSSEC are more common than strictly cryptographic disasters such as wifi.  DNSSEC is near impossible to use correctly end to end.
Usually a cryptographic system is very difficult to use correctly, or to use incorrectly - as for example various VPN products.
Sometimes a cryptographic system is easy to use incorrectly, difficult to use correctly, for example https and pretty much everything built on top of tls-ssl (old flame, never resolved, as to whether this is an inherent design flaw in the very concept of a cryptographic layer and any product that uses layering to factorize out the cryptographic code)

@_date: 2008-07-13 14:41:29
@_author: James A. Donald 
@_subject: Mifare 
shows the researchers
breaking Mifare.
And in the comments, we see posts (I presume from mifare people) complaining that what is happening cannot possibly be happening.
Everyone on this list knows the correct way to do what Mifare does wrong.
So, since we all know how to do it right, why did Mifare come up with their own super secret snake oil algorithm that no one ever reviewed?
More generaly, why is encryption generally implemented in such a damned stupid manner?
Now everyone is going to say it should have been put out for review, and of course it should have been, and had they done so they would have avoided these particular mistakes, but DNSSEC and WPA was reviewed to hell and back, and the result was still no damned good.

@_date: 2008-06-30 09:18:04
@_author: James A. Donald 
@_subject: The wisdom of the ill informed 
Committees of experts regularly get cryptography wrong - consider, for example the Wifi debacle.  Each wifi release contains classic and infamous errors - for example WPA-Personal is subject to offline dictionary attack.
One would have thought that after the first disaster they would have hired someone who could do it right, but as Ian long ago pointed out, in "the market for silver bullets", they are unable to tell who can do it right.  The only people who know who the real experts are, are the real experts.   If you knew who to hire, you could do it yourself, and probably should do it yourself.  So they hire expert salesmen, not cryptography experts.

@_date: 2008-03-21 08:52:07
@_author: James A. Donald 
@_subject: How is DNSSEC 
From time to time I hear that DNSSEC is working fine, and on examining the matter I find it is "working fine" except that ....
Seems to me that if DNSSEC is actually working fine, I should be able to provide an authoritative public key for any domain name I control, and should be able to obtain such keys for other domain names, and use such keys for any purpose, not just those purposes envisaged in the DNSSEC specification.  Can I?  It is not apparent to me that I can.

@_date: 2008-03-28 06:24:40
@_author: James A. Donald 
@_subject: how to read information from RFID equipped credit cards 
> Then we get to the next problem: we don't trust the
 > device with the keypad and display. So, we need to add
 > that to the GTCYM (Gadget That Controls Your Money).
 >
 > And so we end up at the position that we have ended up
 > at so many times before: the GTCYM has to have a
 > decent processor, a keyboard and a screen, and must be
 > portable and secure.
Sounds remarkably like a cell phone with an NFC
 > One day we'll stop concluding this and actually do
 > something about it.
Some of the poorest third world countries and some ex
communist countries are adopting mobile phone banking,
for example , perhaps because
they are not weighed down with twentieth century
infrastructure, but until cell phones come routinely
equipped with NFC, you cannot use a cell phone to pay
for groceries.

@_date: 2008-03-31 20:44:42
@_author: James A. Donald 
@_subject: [p2p-hackers] convergent encryption reconsidered 
Better still, have a limited supply of tickets that enable one to construct the convergence key.  Enough tickets for all normal usage, but   not enough to perform an exhaustive search.
Assume a small set of ticket issuing computers hold a narrowly shared secret integer k.  Assume a widely shared elliptic curve with the generator G.
If h is the hash of the file, the convergence key is h*k*G.
If you give the ticket issuing computers an elliptic point P, they will   give you the corresponding elliptic point k*P.  If, however, you ask for too many such points, they will stop responding.
Of course, this allows one to be attacked by anyone that holds the narrowly held key.

@_date: 2008-05-02 17:07:01
@_author: James A. Donald 
@_subject: User interface, security, and "simplicity" 
We are dropping on end users, sysadmins and nno crypto programmers decisions that seasoned cryptographers tend to screw up, and that end users and sysadmins are never going to comprehend.
The way programmers approach modularity and code locality tends to leave the end user outside the cryptographic boundary.  The cryptography module is very carefully made entirely independent of the user interface, merely sending up arcane errors from time to time.
Consider, for example, the recent cookie stealing security failure in Wordpress, fixed just a few days ago.  It seems that for a very long time, there was very straightforward, indeed in retrospect glaringly obvious, security hole that allowed anyone on the internet to take control of any host running Wordpress - which most hosts do run.  You can take control from Nigeria, you don't need to tap any lines.  Anyone anywhere in the world could have exercised any power over one's server that one's Wordpress application can exercise, which is usually near total power.
The defenders of SSL will quite correctly point out that the security hole had absolutely nothing to do with SSL.  The hole exists whether one uses SSL or not, and almost no one uses SSL with Wordpress.  And that was exactly the problem.  The writers of Wordpress, like the writers of every other application, had to handroll their own authentication, and of course fucked up.  SSL sessions are not user sessions, thus SSL authentication does not authenticate that user "admin" is the same entity (or even has the same  IP address) as the entity that correctly logged in as user admin, does not, cannot, attempt to provide such authentication, that being a higher layer issue - indeed, SSL authentication is pretty much irrelevant to authenticating anything that the attackers or defenders are likely to care about, which is why user admin on a Wordpress application does not use SSL.  SSL is so wonderfully localized that attackers just stroll around it.

@_date: 2008-05-05 10:55:52
@_author: James A. Donald 
@_subject: User interface, security, and "simplicity" 
> IPsec operates at layer 3, where there are (generally)
 > no user contexts.  This makes it difficult to bind
 > IPsec credentials to a user, which means that it
 > inherently can't be as simple to configure as ssh.
 >
 > Put another way, when you tell an sshd whom you wish
 > to log in as, it consults that user's home directory
 > and finds an authorized_keys file. How can IPsec -- or
 > rather, any key management daemon for IPsec -- do
 > that?  Per-user SPDs?  Is this packet for port 80 for
 > user pat or user chris?
 >
 > I can envision ways around this (especially if we have
 > an IP address per user of a system -- I've been
 > writing about fine-grained IP address assignment for
 > years), but they're inherently a lot more complex than
 > ssh.
This is a particular case of the layer problem I have
been ranting about for years:  Private and authenticated
sessions at layer X do not in themselves correspond to
private and authenticated sessions at layer Y, and for
users to arrange their affairs so that layer X does
indeed secure layer Y generally requires users to stand
on their heads and stick their right big toe in their
left ear.

@_date: 2008-05-05 11:46:49
@_author: James A. Donald 
@_subject: User interface, security, and "simplicity" 
If there is a wrong way to do it, the end user will do it wrong.  Expert cryptographers frequently fail to act correctly on their understanding of cryptography.  The end user has no chance - and the chances are still not all that good even if your end user is highly qualified cryptographer.
What users comprehend, and are used to, is you that set up an account with username and password, and an admin blesses the account with appropriate privileges as a result of some out of band communication - which username and password has to be secured, invisibly to the user, against offline and phishing attacks, without requiring any thought or vigilance by the user - see my web page for  for attacks on the password model, and defenses against those attacks.
This comes naturally to humans, for humans have long relied on shibboleths for security against treachery by outsiders.  Thus the computer interface to our clever cryptographic algorithms must resemble as closely as possible the ancient human reliance on shibboleths for

@_date: 2008-05-05 12:29:40
@_author: James A. Donald 
@_subject: OpenSparc -- the open source chip (except for the crypto parts) 
> If you want a guarantee or a proof, better ask all the
 > reverse engineers you know to take a closer look at
 > the program and tell you if there is a backdoor,
 > anything malicious or anything sneaky or suspicious.
If it was easy to find deliberate flaws, it would be
even easier to find accidental flaws.
And since we still find horrible and extremely
straightforward flaws, flaws that are in retrospect
glaringly obvious and exactly the things that one should
look for, in systems that have been out for many years,
it is not easy to find accidental flaws.

@_date: 2008-05-06 18:14:40
@_author: James A. Donald 
@_subject: OpenSparc -- the open source chip (except for the crypto parts) 
True, but the propensity of large teams of experts to issue horribly flawed protocols, and for the flaws in those protocols to go undiscovered for many years, despite the fact that once discovered they look glaringly obvious in retrospect, indicates that this problem, though not provably always hard, is in practice quite hard.

@_date: 2008-05-07 10:27:48
@_author: James A. Donald 
@_subject: User interface, security, and "simplicity" 
> > The same is true in the source code, unsafe
 > > practices are avoided globally, (e.g. both strcpy()
 > > and strncpy() are absent together with fixed size
 > > automatic buffers) rather than used with care
 > > locally. I won't bore you with all the
 > > implementation safety "habits", but there are many.
 > It's too bad that today such elementary practices are
 > something to brag about.  Perhaps one day we'll be
 > lucky enough that the answer to these questions
 > becomes more like "of course we use safe programming
 > practices; what kind of incompetent amateurs do you
 > take us for?".
Dynamic strings tempt people to forget about enforcing
length limits and forget about correctly handling the
case when the length limits are exceeded.
There is no such thing as a string with no maximum
length, merely strings of UNKNOWN maximum length.  If
one has dynamic buffers and fully dynamic strings, it is
always possible for an attacker to discover the
previously UNKNOWN maximum length, and exceed it,
causing the program to fail in a manner likely to be
useful to the attacker.
In any program subject to attack, all strings should
have known, documented, and enforced maximum length, a
length large enough for all likely legitimate uses, and
no larger.
If enforcing length limits, it is frequently advisable,
and often necessary, to use, not strcpy or strncpy, but
routines such as _mbscpy_s, string manipulation routines
which can, and frequently do, employ buffers of fixed
and known length, sometimes pre-allocated fixed length.
In C++, incomprehensibly obscure functions such as
_mbscpy_s should never be called directly, but rather
called through a template library that automatically
does the sensible thing when the destination parameter
is a fixed length buffer, and can be relied upon to
object when commanded to do the stupid thing.

@_date: 2008-11-03 09:46:23
@_author: James A. Donald 
@_subject: Bitcoin P2P e-cash paper 
We very, very much need such a system, but the way I understand your proposal, it does not seem to scale to the required size.
For transferable proof of work tokens to have value, they must have monetary value.  To have monetary value, they must be transferred within a very large network - for example a file trading network akin to To detect and reject a double spending event in a timely manner, one must have most past transactions of the coins in the transaction, which,   naively implemented, requires each peer to have most past transactions, or most past transactions that occurred recently. If hundreds of millions of people are doing transactions, that is a lot of bandwidth - each must know all, or a substantial part thereof.

@_date: 2008-11-04 06:20:13
@_author: James A. Donald 
@_subject: Bitcoin P2P e-cash paper 
James A. Donald:
 > > To detect and reject a double spending event in a
 > > timely manner, one must have most past transactions
 > > of the coins in the transaction, which, naively
 > > implemented, requires each peer to have most past
 > > transactions, or most past transactions that
 > > occurred recently. If hundreds of millions of people
 > > are doing transactions, that is a lot of bandwidth -
 > > each must know all, or a substantial part thereof.
 > Long before the network gets anywhere near as large as
 > that, it would be Safe for users to use Simplified
 > Payment Verification (section 8) to check for double
 > spending, which only requires having the chain of
 > block headers,
If I understand Simplified Payment Verification
New coin issuers need to store all coins and all recent
coin transfers.
There are many new coin issuers, as many as want to be
issuers, but far more coin users.
Ordinary entities merely transfer coins.  To see if a
coin transfer is OK, they report it to one or more new
coin issuers and see if the new coin issuer accepts it.
New coin issuers check transfers of old coins so that
their new coins have valid form, and they report the
outcome of this check so that people will report their
transfers to the new coin issuer.
If someone double spends a coin, and one expenditure is
reported to one new coin issuer, and the other
simultaneously reported to another new coin issuer, then
both issuers to swifly agree on a unique sequence order
of payments.  This, however, is a non trivial problem of
a massively distributed massive database, a notoriously
tricky problem, for which there are at present no peer
to peer solutions.  Obiously it is a solvable problem,
people solve it all the time, but not an easy problem.
People fail to solve it rather more frequently.
  But let us suppose that the coin issue network is
dominated by a small number of issuers as seems likely.
If a small number of entities are issuing new coins,
this is more resistant to state attack that with a
single issuer, but the government regularly attacks
financial networks, with the financial collapse ensuing
from the most recent attack still under way as I write
Government sponsored enterprises enter the business, in
due course bad behavior is made mandatory, and the evil
financial network is bigger than the honest financial
network, with the result that even though everyone knows
what is happening, people continue to use the paper
issued by the evil financial network, because of network
effects - the big, main issuers, are the issuers you use
if you want to do business.
Then knowledgeable people complain that the evil
financial network is heading for disaster, that the
government sponsored enterprises are about to cause a
"collapse of the total financial system", as Wallison
and Alan Greenspan complained in 2005, the government
debates shrinking the evil government sponsored
enterprises, as with "S. 190 [109th]: Federal Housing
Enterprise Regulatory Reform Act of 2005" but they find
easy money too seductive, and S. 190 goes down in flames
before a horde of political activists chanting that easy
money is sound, and opposing it is racist, nazi,
ignorant, and generally hateful, the recent S. 190
debate on limiting portfolios (bond issue supporting dud
mortgages) by government sponsored enterprises being a
perfect reprise of the debates on limiting the issue of
new assignats in the 1790s.
The big and easy government attacks on money target a
single central money issuer, as with the first of the
modern political attacks, the French Assignat of 1792,
but in the late nineteenth century political attacks on
financial networks began, as for example the Federal
reserve act of 1913, the goal always being to wind up
the network into a single too big to fail entity, and
they have been getting progressively bigger, more
serious, and more disastrous, as with the most recent
one.  Each attack is hugely successful, and after the
cataclysm that the attack causes the attackers are
hailed as saviors of the poor, the oppressed, and the
nation generally, and the blame for the the bad
consequences is dumped elsewhere, usually on Jews,
greedy bankers, speculators, etc, because such attacks
are difficult for ordinary people understand.  I have
trouble understanding your proposal - ordinary users
will be easily bamboozled by a government sponsored
security update.  Further, when the crisis hits, to
disagree with the line, to doubt that the regulators are
right, and the problem is the evil speculators, becomes
political suicide, as it did in America in 2007,
sometimes physical suicide, as in Weimar Germany.
Still, it is better, and more resistant to attack by
government sponsored enterprises, than anything I have
seen so far.
 > Visa processed 37 billion transactions in FY2008, or
 > an average of 100 million transactions per day.  That
 > many transactions would take 100GB of bandwidth, or
 > the size of 12 DVD or 2 HD quality movies, or about
 > $18 worth of bandwidth at current prices.
 > If the network were to get that big, it would take
 > several years, and by then, sending 2 HD movies over
 > the Internet would probably not seem like a big deal.
If there were a hundred or a thousand money issuers by
the time the government attacks, the kind of government
attacks on financial networks that we have recently seen
might well be more difficult.
But I think we need to concern ourselves with minimizing
the data and bandwidth required by money issuers - for
small coins, the protocol seems wasteful.  It would be
nice to have the full protocol for big coins, and some
shortcut for small coins wherein people trust account
based money for small amounts till they get wrapped up
into big coins.
The smaller the data storage and bandwidth required for
money issuers, the more resistant the system is the kind
of government attacks on financial networks that we have
recently seen.

@_date: 2008-11-04 15:23:14
@_author: James A. Donald 
@_subject: Secrets and cell phones. 
A sim card contains a shared symmetric secret that is known to the network operator and to rather too many people on the operator's staff, and which could be easily discovered by the phone holder - but which is very secure against everyone else.
This means that cell phones provide authentication that is secure against everyone except the network operator, which close to what we need for financial transactions.  The network operator maps this narrowly shared secret to a phone number. The phone number, which once upon a time directly controlled equipment that makes connections, is now a database key to the secret.
There are now send-money-to-and-from-phone-number systems in Canada , in South Africa, and in various third world countries with collapsed banking systems.
At present, each of these systems sits in its own narrow little silo - you cannot send money from a Canadian phone number directly to a South Africa phone number, and, despite being considerably more secure than computer sign on to your bank, are limited to small amounts of money, probably to appease the banking cartel and the "money laundering" controls.
Skype originally planned to introduce such a system, which would have been a world wide system, skype id to skype id, but backed off, perhaps because of possible regulatory reprisals, perhaps because computers are insufficiently secure.  If you click on the spot in the UI that would have connected you to Skype's offering, you instead get an ad for paypal.
Of course, the old cypherpunk dream is a system with end to end encryption, with individuals having the choice of holding their own secrets, rather than these secrets being managed by some not very trusted authority, and with these secrets enabling transfer of money, in the form of a yurls representing a sum of money, from one yurl representing an id, to another yurl reprsenting an id.
We discovered, however, that most people do not want to manage their own secrets, and that today's operating systems are not a safe place on which to store valuable secrets.
We know in principle how to make operating systems safe enough , but for the moment readily transferable money is coming in through systems with centralized access to keys, and there is no other way to do it.
If the mapping of phone numbers to true names is sufficiently weak, (few of my phone numbers are mapped to my true name) centralized access to symmetric keys is not too bad.

@_date: 2008-11-09 07:16:35
@_author: James A. Donald 
@_subject: WPA broken even further 
WPA was known from the beginning to be vulnerable to offline dictionary attack, for which the workaround was to use a key that is not human Now WPA is cracked even with a strong key:

@_date: 2008-11-09 14:55:23
@_author: James A. Donald 
@_subject: Bitcoin P2P e-cash paper 
> The bandwidth might not be as prohibitive as you
 > think.  A typical transaction would be about 400 bytes
 > (ECC is nicely compact).  Each transaction has to be
 > broadcast twice, so lets say 1KB per transaction.
 > Visa processed 37 billion transactions in FY2008, or
 > an average of 100 million transactions per day.  That
 > many transactions would take 100GB of bandwidth, or
 > the size of 12 DVD or 2 HD quality movies, or about
 > $18 worth of bandwidth at current prices.
The trouble is, you are comparing with the Bankcard
But a new currency cannot compete directly with an old,
because network effects favor the old.
You have to go where Bankcard does not go.
At present, file sharing works by barter for bits. This,
however requires the double coincidence of wants. People
only upload files they are downloading, and once the
download is complete, stop seeding. So only active
files, files that quite a lot of people want at the same
time, are available.
File sharing requires extremely cheap transactions,
several transactions per second per client, day in and
day out, with monthly transaction costs being very small
per client, so to support file sharing on bitcoins, we
will need a layer of account money on top of the
bitcoins, supporting transactions of a hundred
thousandth the size of the smallest coin, and to support
anonymity, chaumian money on top of the account money.
Let us call a bitcoin bank a bink.  The bitcoins stand
in the same relation to account money as gold stood in
the days of the gold standard.  The binks, not trusting
each other to be liquid when liquidity is most needed,
settle out any net discrepancies with each other by
moving bit coins around once every hundred thousand
seconds or so, so bitcoins do not change owners that
often,   Most transactions cancel out at the account
level.  The binks demand bitcoins of each other only
because they don't want to hold account money for too
long. So a relatively small amount of bitcoins
infrequently transacted can support a somewhat larger
amount of account money frequently transacted.

@_date: 2008-11-09 18:56:53
@_author: James A. Donald 
@_subject: Bitcoin P2P e-cash paper 
--
 > The proof-of-work chain is the solution to the
 > synchronisation problem, and to knowing what the
 > globally shared view is without having to trust
 > anyone.
 >
 > A transaction will quickly propagate throughout the
 > network, so if two versions of the same transaction
 > were reported at close to the same time, the one with
 > the head start would have a big advantage in reaching
 > many more nodes first.  Nodes will only accept the
 > first one they see, refusing the second one to arrive,
 > so the earlier transaction would have many more nodes
 > working on incorporating it into the next
 > proof-of-work.  In effect, each node votes for its
 > viewpoint of which transaction it saw first by
 > including it in its proof-of-work effort.
OK, suppose one node incorporates a bunch of
transactions in its proof of work, all of them honest
legitimate single spends and another node incorporates a
slightly different bunch of transactions in its proof of
work, all of them equally honest legitimate single
spends, and both proofs are generated at about the same
What happens then?

@_date: 2008-11-09 19:19:10
@_author: James A. Donald 
@_subject: voting by m of n digital signature? 
Is there a way of constructing a digital signature so
that the signature proves that at least m possessors of
secret keys corresponding to n public keys signed, for n
a dozen or less, without revealing how many more than m,
or which ones signed?

@_date: 2008-11-09 20:05:05
@_author: James A. Donald 
@_subject: Bitcoin P2P e-cash paper 
> Increasing hardware speed is handled: "To compensate
 > for increasing hardware speed and varying interest in
 > running nodes over time, the proof-of-work difficulty
 > is determined by a moving average targeting an average
 > number of blocks per hour. If they're generated too
 > fast, the difficulty increases."
This does not work - your proposal involves
complications I do not think you have thought through.
Furthermore, it cannot be made to work, as in the
proposed system the work of tracking who owns what coins
is paid for by seigniorage, which requires inflation.
This is not an intolerable flaw - predictable inflation
is less objectionable than inflation that gets jiggered
around from time to time to transfer wealth from one
voting block to another.

@_date: 2008-11-10 05:57:54
@_author: James A. Donald 
@_subject: Bitcoin P2P e-cash paper 
--
 >> OK, suppose one node incorporates a bunch of
 >> transactions in its proof of work, all of them honest
 >> legitimate single spends and another node
 >> incorporates a different bunch of transactions in its
 >> proof of work, all of them equally honest legitimate
 >> single spends, and both proofs are generated at about
 >> the same time.
 >>
 >> What happens then?
 > They both broadcast their blocks.  All nodes receive
 > them and keep both, but only work on the one they
 > received first.  We'll suppose exactly half received
 > one first, half the other.
 >
 > In a short time, all the transactions will finish
 > propagating so that everyone has the full set.  The
 > nodes working on each side will be trying to add the
 > transactions that are missing from their side.  When
 > the next proof-of-work is found, whichever previous
 > block that node was working on, that branch becomes
 > longer and the tie is broken.  Whichever side it is,
 > the new block will contain the other half of the
 > transactions, so in either case, the branch will
 > contain all transactions.  Even in the unlikely event
 > that a split happened twice in a row, both sides of
 > the second split would contain the full set of
 > transactions anyway.
 >
 > It's not a problem if transactions have to wait one or
 > a few extra cycles to get into a block.
So what happened to the coin that lost the race?
On the one hand, we want people who make coins to be
motivated to keep and record all transactions, and
obtain an up to date record of all transactions in a
timely manner.  On the other hand, it is a bit harsh if
the guy who came second is likely to lose his coin.
Further, your description of events implies restrictions
on timing and coin generation - that the entire network
generates coins slowly compared to the time required for
news of a new coin to flood the network, otherwise the
chains diverge more and more, and no one ever knows
which chain is the winner.
You need to make these restrictions explicit, for
network flood time may well be quite slow.
Which implies that the new coin rate is slower.
We want spenders to have certainty that their
transaction is valid at the time it takes a spend to
flood the network, not at the time it takes for branch
races to be resolved.
At any given time, for example at 1 040 689 138 seconds
we can look back at the past and say:
But no one can know who is *it* right now
So how does one know when to reveal one's coins?  One
solution is that one does not.  One incorporates a hash
of the coin secret whenever one thinks one might be
*it*, and after that hash is securely in the chain,
after one knows that one was *it* at the time, one can
then safely spend the coin that one has found, revealing
the secret.
This solution takes care of the coin revelation problem,
but does not solve the spend recording problem.  If one
node is ignoring all spends that it does not care about,
it suffers no adverse consequences.  We need a protocol
in which your prospects of becoming *it* also depend on
being seen by other nodes as having a reasonably up to
date and complete list of spends - which this protocol
is not, and your protocol is not either.

@_date: 2008-11-13 16:16:31
@_author: James A. Donald 
@_subject: Bitcoin P2P e-cash paper 
> When there are multiple double-spent versions of the
 > same transaction, one and only one will become valid.
That is not the question I am asking.
It is not trust that worries me, it is how it is
possible to have a  a globally shared view even if
everyone is well behaved.
The process for arriving at a globally shared view of
who owns what bitgold coins is insufficiently specified.
Once specified, then we can start considering whether
everyone has incentives to behave correctly.
It is not sufficient that everyone knows X.  We also
need everyone to know that everyone knows X, and that
everyone knows that everyone knows that everyone knows X
- which, as in the Byzantine Generals problem, is the
classic hard problem of distributed data processing.
This problem becomes harder when X is quite possibly a
very large amount of data - agreement on who was the
owner of every bitgold coin at such and such a time.
And then on top of that we need everyone to have a
motive to behave in such a fashion that agreement
arises.  I cannot see that they have motive when I do
not know the behavior to be motivated.
You keep repeating your analysis of the system under
attack.  We cannot say how the system will behave under
attack until we know how the system is supposed to
behave when not under attack.
If there are a lot of transactions, it is hard to
efficiently discover the discrepancies between one
node's view and another node's view, and because new
transactions are always arriving, no two nodes will ever
have the same view, even if all nodes are honest, and
all reported transactions are correct and true single
We should be able to accomplish a system where two nodes
are likely to come to agreement as to who owned what
bitgold coins at some very recent past time, but it is
not simple to do so.
If one node constructs a hash that represents its
knowledge of who owned what bitgold coins at a
particular time, and another node wants to check that
hash, it is not simple to do it in such a way that
agreement is likely, and disagreement between honest
well behaved nodes is efficiently detected and
efficiently resolved.
And if we had a specification of how agreement is
generated, it is not obvious why the second node has
incentive to check that hash.
The system has to work in such a way that nodes can
easily and cheaply change their opinion about recent
transactions, so as to reach consensus, but in order to
provide finality and irreversibility, once consensus has
been reached, and then new stuff has be piled on top of
old consensus, in particular new bitgold has been piled
on top of old consensus, it then becomes extremely
difficult to go back and change what was decided.
Saying that is how it works, does not give us a method
to make it work that way.
 > The receiver of a payment must wait an hour or so
 > before believing that it's valid.  The network will
 > resolve any possible double-spend races by then.
You keep discussing attacks.  I find it hard to think
about response to attack when it is not clear to me what
normal behavior is in the case of good conduct by each
and every party.
Distributed databases are *hard* even when all the
databases perfectly follow the will of a single owner.
Messages get lost, links drop, syncrhonization delays
become abnormal, and entire machines go up in flames,
and the network as a whole has to take all this in its
Figuring out how to do this is hard, even in the
complete absence of attacks.  Then when we have figured
out how to handle all this, then come attacks.

@_date: 2008-11-16 10:00:04
@_author: James A. Donald 
@_subject: Bitcoin P2P e-cash paper 
> Fortunately, it's only necessary to keep a
 > pending-transaction pool for the current best branch.
This requires that we know, that is to say an honest
well behaved peer whose communications and data storage
is working well knows, what the current best branch is -
but of course, the problem is that we are trying to
discover, trying to converge upon, a best branch, which
is not easy at the best of times, and becomes harder
when another peer is lying about its connectivity and
capabilities, and yet another peer has just had a major
disk drive failure obfuscated by a software crash, and
the international fibers connecting yet a third peer
have been attacked by terrorists.
 >  When a new block arrives for the best branch,
 >  ConnectBlock removes the block's transactions from
 >  the pending-tx pool.  If a different branch becomes
 >  longer
Which presupposes the branches exist, that they are
fully specified and complete.  If they exist as complete
works, rather than works in progress, then the problem
is already solved, for the problem is making progress.
 > Broadcasts will probably be almost completely
 > reliable.
There is a trade off between timeliness and reliability.
One can make a broadcast arbitrarily reliable if time is
of no consequence.  However, when one is talking of
distributed data, time is always of consequence, because
it is all about synchronization (that peers need to have
corresponding views at corresponding times) so when one
does distributed data processing, broadcasts are always
highly unreliable Attempts to ensure that each
message arrives at least once result in increased timing
variation. Thus one has to make a protocol that is
either UDP or somewhat UDP like, in that messages are
small, failure of messages to arrive is common, messages
can arrive in different order to the order in which they
were sent, and the same message may arrive multiple
times.  Either we have UDP, or we need to accommodate
the same problems as UDP has on top of TCP connections.
Rather than assuming that each message arrives at least
once, we have to make a mechanism such that the
information arrives even though conveyed by messages
that frequently fail to arrive.
 > TCP transmissions are rarely ever dropped these days
People always load connections near maximum.  When a
connection is near maximum, TCP connections suffer
frequent unreasonably long delays, and connections
simply fail a lot - your favorite web cartoon somehow
shows it is loading forever, and you try again, or it
comes up with a little x in place of a picture, and you
try again
Further very long connections - for example ftp
downloads of huge files,  seldom complete. If you try to
ftp a movie, you are unlikely to get anywhere unless
both client and server have a resume mechanism so that
they can talk about partially downloaded files.
UDP connections, for example Skype video calls, also
suffer frequent picture freezes, loss of quality, and so
forth, and have to have mechanisms to keep going
 > It's very attractive to the libertarian viewpoint if
 > we can explain it properly.  I'm better with code than
 > with words though.
No, it is very attractive to the libertarian if we can
design a mechanism that will scale to the point of
providing the benefits of rapidly irreversible payment,
immune to political interference, over the internet,
to very large numbers of people. You have an outline
and proposal for such a design, which is a big step
forward, but the devil is in the little details.
I really should provide a fleshed out version of your
proposal, rather than nagging you to fill out the blind

@_date: 2008-11-18 09:57:39
@_author: James A. Donald 
@_subject: Bitcoin P2P e-cash paper 
> Okay.... I'm going to summarize this protocol as I
 > understand it.
 >
 > I'm filling in some operational details that aren't in
 > the paper by supplementing what you wrote with what my
 > own "design sense" tells me are critical missing bits
 > or "obvious" methodologies for use.
There are a number of significantly different ways this
could be implemented.  I have been working on my own
version based on Patricia hash trees, (not yet ready to
post, will post in a week or so) with the consensus
generation being a generalization of file sharing using
Merkle hash trees. Patricia hash trees where the high
order part of the Patricia key represents the high order
part of the time can be used to share data that evolves
in time.  The algorithm, if implemented by honest
correctly functioning peers, regularly generates
consensus hashes of the recent past - thereby addressing
the problem I have been complaining about - that we have
a mechanism to protect against consensus distortion by
dishonest or malfunctioning peers, which is useless
absent a definition of consensus generation by honest
and correctly functioning peers.
 > First, people spend computer power creating a pool of
 > coins to use as money.  Each coin is a proof-of-work
 > meeting whatever criteria were in effect for money at
 > the time it was created.  The time of creation (and
 > therefore the criteria) is checkable later because
 > people can see the emergence of this particular coin
 > in the transaction chain and track it through all its
 > "consensus view" spends.  (more later on coin creation
 > tied to adding a link).
 >
 > When a coin is spent, the buyer and seller digitally
 > sign a (blinded) transaction record, and broadcast it
 > to a bunch of nodes whose purpose is keeping track of
 > consensus regarding coin ownership.
I don't think your blinding works.
If there is a public record of who owns what coin, we
have to generate a  public diff on changes in that
record, so the record will show that a coin belonged to
X, and soon thereafter belonged to Y.  I don't think
blinding can be made to work.  We can blind the
transaction details easily enough, by only making hashes
of the details public, (X paid Y for
49vR7xmwYcKXt9zwPJ943h9bHKC2pG68m) but that X paid Y is
going to be fairly obvious.
If when Joe spends a coin to me, then I have to have the
ability to ask "Does Joe rightfully own this coin", then
it is difficult to see how this can be implemented in a
distributed protocol without giving people the ability
to trawl through data detecting that Joe paid me.
To maintain a consensus on who owns what coins, who owns
what coins has to be public.
We can build a privacy layer on top of this - account
money and chaumian money based on bitgold coins, much as
the pre 1915 US banking system layered account money and
bank notes on top of gold coins, and indeed we have to
build a layer on top to bring the transaction cost down
to the level that supports agents performing micro
transactions, as needed for bandwidth control, file
sharing, and charging non white listed people to send us
So the entities on the public record are entities
functioning like pre 1915 banks - let us call them
binks, for post 1934 banks no longer function like that.
 > But if they recieve a _longer_ chain while working,
 > they immediately check all the transactions in the new
 > links to make sure it contains no double spends and
 > that the "work factors" of all new links are
 > appropriate.
I am troubled that this involves frequent
retransmissions of data that is already mostly known.
Consensus and widely distributed beliefs about bitgold
ownership already involves significant cost.  Further,
each transmission of data is subject to data loss, which
can result in thrashing, with the risk that the
generation of consensus may slow below the rate of new
transactions.  We already have problems getting the cost
down to levels that support micro transactions by
software agents, which is the big unserved market -
bandwidth control, file sharing, and charging non white
listed people to send us communications.
To work as useful project, has to be as efficient as it
can be - hence my plan to use a Patricia hash tree
because it identifies and locate small discrepancies
between peers that are mostly in agreement already,
without them needing to transmit their complete data.
We also want to avoid very long hash chains that have to
be frequently checked in order to validate things.  Any
time a hash chain can potentially become enormously long
over time, we need to ensure that no one ever has to
rewalk the full length.  Chains that need to be
re-walked can only be permitted to grow as the log of
the total number of transactions - if they grow as the
log of the transactions in any one time period plus the
total number of time periods, we have a problem.
 > Biggest Technical Problem:
 >
 > Is there a mechanism to make sure that the "chain"
 > does not consist solely of links added by just the 3
 > or 4 fastest nodes?  'Cause a broadcast transaction
 > record could easily miss those 3 or 4 nodes and if it
 > does, and those nodes continue to dominate the chain,
 > the transaction might never get added.
 >
 > To remedy this, you need to either ensure provable
 > propagation of transactions, or vary the work factor
 > for a node depending on how many links have been added
 > since that node's most recent link.
 >
 > Unfortunately, both measures can be defeated by sock
 > puppets. This is probably the worst problem with your
 > protocol as it stands right now; you need some central
 > point to control the identities (keys) of the nodes
 > and prevent people from making new sock puppets.
We need a protocol wherein to be a money tracking peer
(an entity that validates spends) you have to be
accepted by at least two existing peers who agree to
synchronize data with you - presumably through human
intervention by the owners of existing peers, and these
two human approved synchronization paths indirectly
connect you to the other peers in the network through
at least one graph cycle.
If peer X is only connected to the rest of the network
by one existing peer, peer Y, perhaps because X's
directly connecting peer has dropped out, then X is
demoted to a client, not a peer - any transactions X
submits are relabeled by Y as submitted to Y, not X, and
the time of submission (which forms part of the Patricia
key) is the time X submitted them to Y, not the time
they were submitted to X.
The algorithm must be able swiftly detect malfunctioning
peers, and automatically exclude them from the consensus
temporarily - which means that transactions submitted
through malfunctioning peers do not get included in the
consensus, therefore have to be resubmitted, and peers
may find themselves temporarily demoted to clients,
because one of the peers through which they were
formerly connected to the network has been dropped by
the consensus.
If a peer gets a lot of automatic temporary exclusions,
there may be human intervention by the owners of those
peers to which it exchanges data directly to permanently
drop them.
Since peers get accepted by human invite, they have
reputation to lose, therefore we can make the null
hypothesis (the primary Bayesian prior) honest intent,
valid data, but  unreliable data transmission - trust
with infrequent random verification.  Designing the
system on this basis considerably reduces processing
Recall that SET died on its ass in large part because
every transaction involved innumerable public key
operations.  Similarly, we have huge security flaws in
https because it has so many redundant public key
operations that web site designers try to minimize the
use of https to cover only those areas that truly need
it - and they always get the decision as to what truly
needs it subtly wrong.
Efficiency is critical, particularly as the part of the
market not yet served is the market for very low cost
 > If we solve the sock-puppet issue, or accept that
 > there's a central point controlling the generation of
 > new keys,
A central point will invite attack, will be attacked.
The problem with computer networked money is that the
past can so easily be revised, so nodes come under
pressure to adjust the past - "I did not pay that"
swiftly becomes "I should not have paid that", which
requires arbitration, which is costly, and introduces
uncertainty, which is costly, and invites government
regulation, which is apt to be utterly ruinous and
wholly devastating.
For many purposes, reversal and arbitration is highly
desirable, but there is no way anyone can compete with
the arbitration provided by Visa and Mastercard, for
they have network effects on their side, and they do a
really good job of arbitration, at which they have vast
experience, accumulated skills, wisdom, and good repute.
So any new networked transaction system has to target
the demand for final and irreversible transactions.
The idea of a distributed network consensus is that one
has a lot of peers in a lot of jurisdictions, and once a
transaction has entered into the consensus, undoing it
is damn near impossible - one would have to pressure
most of the peers in most of the jurisdictions to agree,
and many of them don't even talk your language, and
those that do, will probably pretend that they do not.
So people will not even try.
To avoid pressure, the network has to avoid any central
point at which pressure can be applied.  Recall Nero's
wish that Rome had a single throat that he could cut. If
we provide them with such a throat, it will be cut.

@_date: 2008-11-18 11:26:31
@_author: James A. Donald 
@_subject: Bitcoin P2P e-cash paper 
> How do identities help?  It's supposed to be anonymous
 > cash, right?
Actually no.  It is however supposed to be pseudonymous,
so dinging someone's reputation still does not help
 > And say you identify a double spender after the fact,
 > then what?  Perhaps you're looking at a disposable ID.
 > Or perhaps you can't chase them down.
 >
 > Double spend detection needs to be real-time or near
 > real-time.
Near real time means we have to use UDP or equivalent,
rather than TCP or equivalent, and we have to establish
an approximate consensus, not necessarily the final
consensus, not necessarily exact agreement, but close to
it, in a reasonably small number of round trips.

@_date: 2008-11-29 18:18:36
@_author: James A. Donald 
@_subject: e-gold and e-go1d 
To implement Zooko's triangle, one has to detect names
that may look alike, for example e-gold and e-go1d
This is a lot of code.  Has someone already written such
a collision detector that I could swipe?
The algorithm is to map all lookalike glyphs to
canonical glyphs - thus l and 1 are mapped to l, O and 0
are mapped to O, lower case o and the Greek omicron are
mapped to lower case o, and so on and so forth.  For
each pair of strings, one then does a character by
character diff, and pairs with suspiciously short diffs
might be confused by end users.
The program then asks the user for a qualification to
distinguish one or both of the names, default being as
first and second, or for the user to deprecate one of
the entities as scam or spam, or for the user to say he
does not care if new entries have the same or similar
name as this particular existing entry.

@_date: 2008-10-26 18:42:23
@_author: James A. Donald 
@_subject: Cloning resistance in bluetooth 
Suppose one has a system that automatically signs you on to anything if your cell phone is within bluetooth range of your computer, and automatically signs you off out of everything, and puts up a screen saver that will not go away, when your cell phone is out of range of your computer.
What is the basis for cloning resistance of a cell phone with blue tooth?
NFC provides physical authenticity - privacy on the model of whispering one's ear, and authentication by touching.  Is there any mechanism intended for mapping that to keys, so that when two NFC devices meet, they can give each other petnames, and subsequently recognize public keys by petname?

@_date: 2008-09-10 06:36:45
@_author: James A. Donald 
@_subject: once more, with feeling. 
The average cryptographic expert finds it tricky to set up something that is actually secure.  The average bureaucrat could not run a pie stand.  Legislation and so forth requires wise and good legislators and administrators, which is unlikely.
Visualize Obama, McCain, or Sarah Palin setting up your network security.  Then realize that whoever they appoint as Czar in charge of network security is likely to be less competent than they are.

@_date: 2008-09-19 18:50:48
@_author: James A. Donald 
@_subject: Cookie Monster 
> Yet another web attack:
 >
 >  > My own conclusion from this:  This is yet another indication that
 > the whole browser authentication model is irretrievably broken. It's
 > just way too complex, with way too many moving parts which can
 > interact in dangerous ways.  The list of requirements for a "safe"
 > Web application - even just based on attacks known today - is so
 > long that no one can remember them all, much less check any
 > substantial Web application to see if it follows them.
 >
 > We need a better approach.
As I posted earlier:
SSL/TLS does not supply secure logon and sessions, because it does not
know what a session or a login is.   Instead http+tls provides a pile
of matchsticks and glue with which the website server can implement
something that kind of sort of mostly behaves rather like logins and
It should have been obvious that everything really important relates
to logins and sessions and that the rest can be treated as a login by
"anon 37283" with the null password, and that therefore the
cryptography *and* *the* *browser* *user* *interface* needs to
implement logins and sessions.
It should have been obvious that logging in on the web page was going
to lead to the phishing disaster - that people should login on a
trusted path from the browser chrome.
The user login status should be displayed in the chrome on every
logged in web page, and the server has to know that the user knows his
login status, has to know the login status not only of the user, but
of the web page that the user has clicked on that generated this
request to this server.
The state of being logged in should guarantee privacy and authenticity
- that only the client and the server can know what they are
communicating, and that no one else should be able to pass himself off
as client or server, or modify their communications
Everything should have been written around the user concepts of
"logging in"  "a logged in page", and "logging out", and should have
made those user concepts real, made them into pages with appropriate
built in cryptographic behaviors, rather than providing capabilities
that could potentially be used to make pages behave like that.
The user concept of "logged in" has to be real rather than
superficially simulated by server side code

@_date: 2008-09-22 07:38:38
@_author: James A. Donald 
@_subject: once more, with feeling. 
Browser UI needs changing.  Login, and account creation, should take place on the trusted path, and in a special window, not easily faked - a non rectangular window that partially overlaps the browser window, and which contains information specific to this computer's past interactions with this website.
We could also mandate that you can only login by clicking on a smart bookmark, which knows that it is a bookmark to a login, but this would involve turning existing sites upside down, which would be a hard sell.

@_date: 2008-09-22 20:59:25
@_author: James A. Donald 
@_subject: once more, with feeling. 
Cellphones are not inherently secure, but *could* be inherently secure.   Each cellphone sim card has a unique identity.  It is possible to guarantee that a message goes to or from a cellphone containing a particular sim card - but present phone software provides no means to do If a cellphones has nfc communications capable of talking to a pc, then the whole interaction could be made painlessly automatic - touch your cellphone to the pc nfc sensor to login to the website, touch it to the security door to unlock the security door, touch it to the cash register, observe the indicated payment on the cellphone screen, and press OK, touch it to the screenless, keyboardless atm, and the interaction comes up on your phone screen instead of the ATM screen, touch cellphones to pay money from one individual to another.
The major obstacle is that the government would want a strong binding between sim cards and true names, which is no more practical than a strong binding between physical keys and true names.
Absent useful cellphone software, passwords must suffice.  With a limit on the number of guesses before people get locked out, passwords *do* suffice - but then we need a means to unlock the account, and a means of password recovery.
Although cellphones and email are insecure, a use once short lived password emailed or instant messaged to the user is secure enough. Trouble is, what happens if the user's email account is stolen?
I had this problem.  I was using my hotmail account as the password recovery account for various high value domain names.  Someone called up hotmail's password recovery, and human engineered a password reset out of the hotmail staff, and then used email based password recovery to seize my domain names.  I eventually got them back, using reset passwords snail mailed to my physical post office box, and now  the email account associated with my domain names is at a service that provides no password recovery mechanism - and therefore provides an attacker with a very large number of opportunities to guess, requiring an insanely strong password.
Snail mail to a post office box is a secure password reset mechanism, short of a well timed physical attack on the post office.

@_date: 2008-09-23 07:15:47
@_author: James A. Donald 
@_subject: once more, with feeling. 
If the user is used to logging in by a user interface that is not easy for forge remotely - click on bookmark to bring up a user interface that is difficult to remotely forge - then this does indeed work.
There is always the give-your-password-over-the-phone attack, but the fact that phishers seeking WoW gold actually have to use the give-your-password-over-the-phone attack against WoW players shows the potency of a deliberately non standard, difficult to forge, user interface.
WoW security does not stop phishing, but it makes phishers work for their money. WoW keeps telling users "never give your password to another person, no one at WoW will ever ask you for your password". Obvious advice, easy to understand and follow.

@_date: 2009-08-02 17:55:17
@_author: James A. Donald 
@_subject: Fast MAC algorithms? 
James A. Donald:
You cannot use a Viginere cipher securely. You can use an RC4 cipher securely:  To use RC4 securely discard the first hundred bytes of output, and renegotiate the key every gigabyte.

@_date: 2009-08-06 21:33:46
@_author: James A. Donald 
@_subject: Client Certificate UI for Chrome? 
The fundamental problem with certificates is getting them.
OK, suppose you hit a web site that wants a client side certificate, maybe it wants a claimed email address with proof that you can receive email at that address, maybe it wants proof you are over 18, maybe it is run by the company you work for and wants proof you are an employee and wants to know which employee you are.  Maybe it wants evidence that you a member in good standing of the committee to slay infidels.
If we suppose your browser *has* such a certificate, and merely needs permission from you, the user, to show it, then the problem is relatively easy - which however does not stop existing browsers from fouling up mightily, perhaps because they are designed around verisign's
business model, rather than anything the user might actually want to
But the problem is much harder, much much harder, if we suppose you do *not* have the certificate.
I will ignore the easy problem, because I am sure that anyone worth talking to can figure out the solution, even though existing browser writers have failed to do so.
OK. Hard Problem:  You the user have hit a website that wants a certificate with certain characteristics, and either you do not have it, or you have it somewhere, but your browser does not know you have it, perhaps because it is on another browser on another computer.
It appears to me that existing solutions to this problem are designed around Verisign's business model, rather than user needs.  If a client certificate is to identify you to examplecorp as an employee of examplecorp, why does Verisign need to get involved?  It's easier for examplecorp to issue its own @ certificates.
So, assuming you are pretty smart, as I know you to be, and assuming your boss is not evil and not in Verisign's pocket, which I do not know at all ...
So where *would* you have a certificate?  Where would you keep it, and what would it look like?
The kind of things that people are used to storing in a browser are bookmarks:  Bookmarks have the convenient property that they implement Zooko's triangle: petname, nickname, and guid.  They also have the property that if you click on them they take you somewhere.  So a certificate should act like some kind of smart bookmark and look to the user like a smart bookmark,  which if clicked on should bring you to your logged in web page with the authority issuing the certificate. Your secret key is something like a a secret link or bookmark that automatically logs you in to something like your facebook page, and your public key is something like a link or bookmark that enables other people to view something like your facebook page.  Maybe it is your employee page at examplecorp, which shows any records pertaining to you in the company database, some of which, such as contact information, are editable by you, but most of which are not.
And the "something like your facebook page as seen by others" is almost the same link the live authorization that your certificate is still valid.
So how do you *get* a certificate?  Suppose, for example, your certificate identifies you to your company, in which case your boss probably gave it to you.  What would he give you? Well, obviously, he would give you a username and password, or more likely you would create an account, a username and password, which he would then authorize.
Which username and password would I expect enable you to get to that logged in web page with the authority issuing the certificate, in this case some location on the company web server.  And you get to that web page, you would then get an "install " dialog, and if you accept, get something that looks and acts like a bookmark, though it is in fact a company issued certificate, certifying that you are username, where username is also a primary key in the company employee But the trouble with this, of course, is that usernames and passwords can be phished.
The solution to that is password login and account creation in the chrome, not in the web page implementing password-authenticated key agreement, so that the phisher can gain nothing, so long as the user attempting to use the chrome login facilities, rather than html web page login facilities.
It should have been obvious that logging in on a user interface provided by a web page, provided by html code, was entirely insecure - the problem of spoofed logins was well known at the time. So what we
needed, from day one, was a secure login that was in the browser chrome, not the web page - and no other form of secure login supported.
When the user creates a username and password, this should by default automatically create a bookmark in his contacts folder, much as an email client usually does when you post a reply. To reduce the risk that
the user may be fooled into using a hostile client, the user interface for entering password and username should never pop up except by the
user clicking on a login button in the browser chrome, or clicking on a login bookmark.  Not only should the user never enter his password and user name on a web page, but also there should never be login
buttons on a web page.
If the user enters the user name and password incorrectly, then he  has to pass a reverse Turing test before entering the password again, to prevent scripts from trying millions of passwords.  So if an attacker has tried to guess passwords, the website will inform the user that n unsuccessful login attempts have taken place against his user name and ask him to pass the reverse Turing test.
The user interface to create a connection never pops up spontaneously, but only as a direct result of the user choosing to cause it to pop up, typically by clicking on a bookmark in his account list, or by clicking on the login widget in the browser chrome.

@_date: 2009-08-07 11:42:55
@_author: James A. Donald 
@_subject: Client Certificate UI for Chrome? 
> This is predicated on the assumption that it's
 > possible to make certificates usable for general
 > users.  All the empirical evidence we have to date
 > seems to point to this not being the case.  Wouldn't
 > it be better to say "What can we do to replace
 > certificates with something that works?", for example
 > TLS-SRP or TLS-PSK?
For password-authenticated key agreement such as TLS-SRP
or TLS-PSK to work, login has to be in the chrome.
Of course, for certificate distribution to work, we also
need password-authenticated key agreement in the chrome,
for in practice, certificates are distributed via
username and password based logins, making their use
case necessarily small.  No matter what we do with
certificates, have to fix username and password based
logins first.

@_date: 2009-08-07 12:11:11
@_author: James A. Donald 
@_subject: Client Certificate UI for Chrome? 
There are use cases where a centralized authority is useful.
Client side is not one of them.
Typical usage is "is this client one of our gang?".
Obviously the CA just gets in the way.

@_date: 2009-08-11 08:03:28
@_author: James A. Donald 
@_subject: Client Certificate UI for Chrome? 
--
 >> For password-authenticated key agreement such as
 >> TLS-SRP or TLS-PSK to work, login has to be in the
 >> chrome.
 > Sure, but that's a relatively tractable UI problem
Indeed.  You know how to solve it, and I know how to
solve it, yet the solution is not out there.
As you say, shared secrets should be entered a form that
implements password-authenticated key agreement such as
TLS-SRP or TLS-PSK, that cannot easily be spoofed, that
is clearly associated with the browser and with a
particular url and web page (you suggest that the form
should roll out of the browser bar with an eye catching
motion and land on top of the web page) and an encrypted
connection should be established by that shared
knowledge, which cannot be established without that
shared knowledge.
This, however, requires both client UI software, and an
api to server side scripts such as PHP, Perl, or Python
(the P in LAMP).  On the server side, we need a request
object in the script language that tells the script that
this request comes from an entity that established a
secure connection using shared secrets associated with
such and such a database record entered in response to
such and such a web page, an object to which the script
generating a page can associate data that persists for
the duration of the session - an object that has session
scope rather than page scope, scope longer and broader
than that of the thread of execution that generates the
page, but shorter and narrower than that of the database
record containing the shared secrets, a script
accessible object that can only be associated with one
server, one server side process and one server side
thread at a time.  This is non trivial to implement in
an environment where servers are massively
multithreaded, and often massively multiprocess.
 > Certificates on the other hand are an apparently
 > intractable business, commercial, user education,
 > programming, social, and technical problem.  I'd much
 > rather try and solve the former than the latter.
What makes certificates such a problem is that there is
someone in the middle issuing the certificate - usually
someone who does not know or trust either of the
entities trying to establish a trust relationship.
While certificates frequently makes cryptography
unnecessarily painful and complicated, certificate issue
offers the opportunity to make money out of providing
encryption by being that someone in the middle, hence
the remarkable enthusiasm for this technology, and
stubborn efforts to apply it to cases where its value is
limited, and it is far from being the most convenient,
practical, and straightforward solution.

@_date: 2009-08-11 06:48:32
@_author: James A. Donald 
@_subject: Client Certificate UI for Chrome? 
> I'm not sure if the Chrome folks would be prepared to
 > ship their browser without any CA certs loaded,
Excessive distrust is inconvenient, excessive trust is
vulnerable.  It is better to remedy flaws by expanding
functionality rather than restricting it.
On the one hand, something like Verisign is very useful
to signify that an entity that calls itself a bank is in
fact regarded as a bank by governments and other major
banks, on the other hand, it is pretty useless for
designating membership of a group to other members of
the group, which is the major function of client side
The number of globally important entities is necessarily
small, therefore a global namespace of globally unique
human memorable names, (such as "Bank Of America") works
well for them.   The number of entities that have or
need keys is quite large, therefore Zooko's triangle
applies - globally unique human memorable names work
very badly for the vast majority of keyholders,
therefore a business whose job is enforcing global
uniqueness of human memorable names (such as Verisign)
is going to be a pain to deal with, for it is trying to
do something that really cannot be done, therefore in
practice will merely make it sufficiently difficult for
clients that scammers do not bother.
Even for banks, globally unique names are problematic.
A remarkably large number of banks are called something
National Bank, or First National Bank of something.

@_date: 2009-08-12 12:09:44
@_author: James A. Donald 
@_subject: Client Certificate UI for Chrome? 
> > [In order to implement strong password based
 > > encryption and authentication] on the server side,
 > > we need a request object in the script language that
 > > tells the script that this request comes from an
 > > entity that established a secure connection using
 > > shared secrets associated with such and such a
 > > database record entered in response to such and such
 > > a web page
 > Ah, that is a good point, you now need the credential
 > information present at the TLS level rather than the
 > tunneled-protocol level (and a variation of this,
 > although I think one that way overcomplicates things
 > because it starts diverting into protocol redesign, is
 > the channel binding problem (see RFC 5056 and,
 > specific to TLS,
 > draft-altman-tls-channel-bindings-05.txt)).  On the
 > other hand is this really such an insurmountable
 > obstable?
Consider what would be involved in building the UI into
the Google browser, and also building the necessary
scripting support into Web2Py on Google App Engine.  It
is not a small job.
 > I don't really see why you'd need complex scripting
 > interfaces though, just "return the shared-secret
 > value associated with this ID" in response to a
 > request from the TLS layer.
This request is issued when the connection is being
established, before the URL is specified.  So it is
impossible to service that request from the script that
generates the web page.   So where are we servicing that
request?  Presumably, need to service it somewhere
within the Web Application Framework, for example within
Mod PHP or Web2Py.
Further, some applications, for example banks and share
registries, typically have several different ID tables
at a single domain, and several different kinds of
shared human memorable secret information associated
with each ID.
And, having established that association, then when the
URL is specified, and the script associated that URL is
finally invoked by the Web Application Framework, then
that script needs to be invoked with the relevant ID, or
better, the script then needs to be provided with a
database cursor pointing at the relevant ID.
Further, if we do the SRP dance every single page, it is
a huge performance hit, with many additional round
trips. One loses about 20 percent of one's market share
for each additional round trip.
So we only want to do the SRP dance on session
establishment, only want to do it once per human
session, once per logon, not once per TLS session.
Which means that the TLS layer has to cache the the
transient strong shared secret constructed from the weak
durable human memorable secret for the duration of the
Web Application Framework's logon and logoff and provide
the cached database cursor to the web page script at
every page request during a single logon session, which
requires a higher level of integration between TLS and
the Web Application Framework than either one was
originally designed for.
Which means a significant amount of work integrating
this stuff with any given web application framework.
Further, suppose, as is typical with banks, a given
domain name hosts multiple ID tables each with different
kinds of shared secret information.  In that case, we
can obtain multiple different kinds of SRP logons, each
relevant to certain web pages but not others, each with
different privilege levels, and the framework has to
enforce that, has to provide to each web page
information about the logon type, and ensure that
inappropriate web pages are never invoked at all, but
are 403ed when the user attempts to access a url through
a logon of inappropriate type.
We cannot rely on the server side web page script to 403
itself in response to inappropriate logon type, since
when a new kind of logon was introduced, no one would
ever go back and make sure that all the old web pages
correctly checked the logon type.  If the web page
script contains a line of code that says "If such and
such, then do a 403",
then sooner or later someone will delete that code and
say "Hey, it still works just fine.".
This is starting to sound depressingly like a great deal
of work rewriting lots of complex, bugridden stuff in
web application frameworks that are already designed to
handle logons in a quite different way.

@_date: 2009-08-17 18:15:14
@_author: James A. Donald 
@_subject: Client Certificate UI for Chrome? 
I cannot see how you could create a bank web page without a web application framework (counting mod-php as a very primitive web application framework) and scripting and a database, which scripting and database has to know who it is is that logged in - which is indeed a great deal of complicated plumbing to ensure that the script knows at script execution time, *after* the connection has been made, which user, which database primary key, is connected.  The information about which user, which database primary key is logged in, has to be passed up through one layer after another and from one process to another.  The toe bone is connected to foot bone, the foot bone is connected to the ankle bone, the ankle bone is connected ... The plumbing really is that Because keep-alive usually fails for plumbing reasons, standard TLS usually does the PKI-based non-authentication dance every page, resulting in additional round trips, resulting in painfully bad performance for SSL web sites such as

@_date: 2009-08-20 07:04:11
@_author: James A. Donald 
@_subject: [tahoe-dev] Tahoe-LAFS key management,	part 2: Tahoe-LAFS is 
Getting back towards topic, the hash function employed by Git is showing signs of bitrot, which, given people's desire to introduce malware backdoors and legal backdoors into Linux, could well become a problem in the very near future.

@_date: 2009-08-26 06:41:12
@_author: James A. Donald 
@_subject: SHA-1 and Git (was Re: [tahoe-dev] Tahoe-LAFS key management, 
New software has to work with new and old data files and communicate with new and old software.
Thus full protocol negotiation has to be built in to everything from the beginning - which was the insight behind COM and the cure to DLL hell.

@_date: 2009-08-27 09:36:44
@_author: James A. Donald 
@_subject: Client Certificate UI for Chrome? 
> If the problem you are trying to solve is client
 > authentication then client certs have some obvious
 > value.
But if client certs are Certificate Authority centric,
then they prove that so and so's true name is so and so.
They don't prove that so and so is one of our gang,
which is generally what people care about.
A typical situation is that someone whose legal address
is in the united states, wants to order some good from
an entity whose physical address is China, but whose
legal address is in a tax haven, for delivery to a
physical address in Singapore.  True names are rather
low on their list of priorities.
If you want to get people to use client certificates,
client certificates have to do what people want, not
what governments and certification authorities want.
What is needed is client certificates that work like
shibboleths or gang colors.  Microsoft's cardspace
was a try at that idea.

@_date: 2009-08-27 10:36:08
@_author: James A. Donald 
@_subject: SHA-1 and Git (was Re: [tahoe-dev] Tahoe-LAFS key management, 
> Consider for example a system that uses two
 > authentication algorithms in case one fails, or that
 > has an algorithm-upgrade/rollover capability, perhaps
 > via downloadable plugins.  At some point a device
 > receives a message authenticated with algorithm A
 > saying "Algorithm B has been broken, don't use it any
 > more" (with an optional side-order of "install and run
 > this plugin that implements a new algorithm instead").
 > It also receives a message authenticated with
 > algorithm B saying "Algorithm A has been broken, don't
 > use it any more", with optional extras as before.
Not so hard.  True breaks occur infrequently.  Those
that download the scam version will find that they can
*only* communicate with the scammers, so will sort
things out in due course and all will be well until the
next break - which will not happen for a long time, and
may well never happen - unless of course one has the
IEEE 802.11 working group designing the standards.

@_date: 2009-08-28 11:14:32
@_author: James A. Donald 
@_subject: [tahoe-dev] a crypto puzzle about digital signatures and future 
If Bob and Carol want to be sure they are seeing the same file, have to
use a capability to an immutable file.
Obviously a capability to an immutable file has to commit the file to a particular hash algorithm.
(Using "capability" in the sense of capabilities as cryptographic data, capabilities as sparse addresses in a large address space identifying communication channels)
So the leading bits of the capability have to be an algorithm identifier.  If Bob's tool does not recognize the algorithm, it fails, and he has to upgrade to a tool that recognizes more algorithms.
If the protocol allows multiple hash types, then the hash has to start with a number that identifies the algorithm.  Yet we want that number to comprise of very, very few bits.
This is almost precisely the example problem I discuss in Now suppose an older algorithm is broken, and Alice wants to show Bob one file, and Carol another, and pretend they are the same file.
So she just uses the older algorithm.  Bob and Carol, however, have the newer tool, which if the older algorithm is thoroughly broken, will probably pop up "deprecated algorithm", which Bob and Carol will cheerfully click through.
If however, the older algorithm has been broken a good long time, and we are well past the transition period, and no one should be using the older algorithm any more, except to wrap old format immutable files inside new format immutable files, then Bob's tool will fail.  Problem Yes, during the transition period, people can be hosed, especially if they see nag messages so often that they click them off, as they probably will, but that is true no matter what.  If an algorithm gets broken, people can be hurt during the transition.  The point, however, is to have a smooth transition, even if security sucks during the

@_date: 2009-02-13 16:23:49
@_author: James A. Donald 
@_subject: full-disk subversion standards released 
You want to keep control of the information on your server.  DRM wants to deny the end user control of the information on the end user's machine.

@_date: 2009-02-24 08:23:54
@_author: James A. Donald 
@_subject: Solving password problems one at a time, Re: The password-reset 
> (UI in use since 2000, for web access control and
 > authorization) After you enter a usercode in the first
 > screen, you are presented with a second screen to
 > enter your password. The usercode is a mnemonic
 > 6-character code such as HB75RC (randomly generated,
 > you receive from the server upon registration). Your
 > password is freely chosen by you upon
 > registration.That second screen also has something
 > that you and the correct server know but that you did
 > not disclose in the first screen -- we can use a
 > simple three-letter combination ABC, for example. You
 > use this to visually authenticate the server above the
 > SSL layer. A rogue server would not know this
 > combination, which allays spoofing considerations --
 > if you do not see the correct three-letter
 > combination, do not enter your password.
No one is going to check for the correct three letter
combination, because it is not part of the work flow, so
they will always forget to do it.
It might work if you have something that dramatically
alters the overall look of the page and organization of
the page, such as a big skin with a big graphic,
editable by user, and initially randomly generated per
user.  If you put the fields in different places,
depending on the user, then user will have to pay
attention when fields are not where he expects them to
It would also help if you made the login page
extensively user customizable, and ask the user to
customize it in order to protect himself against
phishing.  When suddenly his customizations vanish, he
will instantly and instinctively feel that what is his
has been taken, and appropriately perceive himself to be
under attack.
But a better solution would be to use SRP or J-Pake so
that a successful phish fails to reveal the password.
Unfortunately, for reasons that are entirely unclear to
me, there is passionate resistance to building J-Pake or
SRP into the browser - we need a UI in the browser, and
a PHP module on the server, to make these actually

@_date: 2009-02-26 08:13:25
@_author: James A. Donald 
@_subject: Security through kittens, was Solving password problems 
>> Clever though this scheme [kittens] is, man-in-the
 >> middle attacks make it no better than a plain SSL
 >> login screen.
 > You don't even need a MITM, just replace the site
 > image on your phishing site with either a broken-
 > image picture or a message that your award-winning
 > site-image software is being upgraded and will be back
 > soon and it's rendered totally ineffective.
Assume we have this great process, perhaps
password-authenticated key agreement, perhaps kitten
based, that guarantees we are phish proof it the user
actually uses it.
How do we make the workflow and user interface so that
if the user is asked to bypass our great process, he
hears alarm bells?
When it comes to workflows, the WoW interface seems to
work quite well
WoW accounts control WoW gold, typically $50 to $100
worth, so WoW accounts are a popular phish target:
This phish used a flaw in the official WoW website to
redirect an https login with WoW to an https login with
the scammer site.
The interesting thing is that it and similar phishes do
not seem to have been all that successful - few people
seemed to notice at all, the general reaction being to
simply hit the spam key reflexively, much as people
click away popup warnings reflexively, and are
unaware that there ever was a popup.
Most accounts are lost through keyloggers - rather
phishing, the attacker has to take over the end user's
computer completely.
Why the attack resistance?  I conjecture that:
1.  User normally enters his password in an environment
      that looks nothing like a web page, so being asked
      to do so in a web page automatically makes him
      suspicious - it is a deviation from normal workflow
2.  Blizzard never communicates by email, so receiving
      email from blizzard automatically makes the user
      suspicious.

@_date: 2009-01-12 09:29:04
@_author: James A. Donald 
@_subject: MD5 considered harmful today, SHA-1 considered harmful tomorrow 
> There is a huge install-base of systems on which SHA-2
 > certs will failed SSL handshakes. When Windows XP
 > systems are <1% of the install-base, when OpenSSL
 > 0.9.8 is <1% of the install-base and 0.9.9 too (if the
 > support is not added before it goes official)
It is now 2009.  SHA-1 came under attack in 2005.  That
SHA-1 has been attacked, and SHA-2 not attacked, was
evidence for the strength of SHA-2.
Why did OpenSSL not support SHA-2 in 2006? Institutional
paralysis?  Protocol negotiation issues? Protocol
negotiation issues that involved vested interests
resulting in institutional paralysis?
We cannot know why Microsoft acted as it acted, but if
OpenSSL is open, we should be able to know why OpenSSL
did even worse than Microsoft.

@_date: 2009-07-14 14:43:21
@_author: James A. Donald 
@_subject: 112-bit prime ECDLP solved 
> See for more details our announcement at Computing power doubles every 18 months to two years, so the required EC length should gain a bit every year or every nine months.
Which suggests that existing deployments should default to 128 bits. with 160 bits being overkill.  Of course overkill does not cost much. If one shoots someone the head, it is wise to follow up with a second shot through the head at very short range just to be on the safe side.
Year    Breakable keys.
2009	112
2010	113
2015	117
2020	121
2025	124
I am assuming a rapid rate of progress, in which case line widths halve every four years.
In which case Moore's law breaks in 2033 when we get nanometer line widths, for lines will then be molecules - probably carbon nanotubes.
2033	130
Subsequent expansions in computing power will involve breaking up Jupiter to build really big computers, and so forth, which will slow things down a bit.
So 144 bit EC keys should be good all the way to the singularity and a fair way past it.

@_date: 2009-07-16 16:31:56
@_author: James A. Donald 
@_subject: 112-bit prime ECDLP solved 
No it cannot handle a bunch of a hundred targets at only ten times the cost.  It is already parallelized.  A hundred targets is a hundred times the cost.
But let us not think small.  Suppose the president says "Break James Donald's key.  I don't care how much it costs.  The sky is the limit" and they devote the entire US gross national product for a year to breaking James Donald's key in a year.
Then they can break a 170 bit key.
But I rather doubt that they will.

@_date: 2009-07-27 06:50:26
@_author: James A. Donald 
@_subject: Fast MAC algorithms? 
No one can break arcfour used correctly - unfortunately, it is tricky to use it correctly.

@_date: 2009-05-13 09:19:32
@_author: James A. Donald 
@_subject: Warning! New cryptographic modes! 
You specified a good alternative:  Encrypted synchronization of a file versioning system:
Git runs under SSH.
Suppose the files are represented as the original values of the files, plus deltas.  If the originals are encrypted, and the deltas encrypted, no information is revealed other than the size of the change.
Git is scriptable, write a script to do the job.

@_date: 2009-11-08 20:28:56
@_author: James A. Donald 
@_subject: Security of Mac Keychain, Filevault 
> NFC?
Near Field Communications - the wireless equivalent of
whispering in someone's ear.  Ideally, a NFC chip should
only be able to talk to something that is an inch or so
away, and it should be impossible to eavesdrop from more
than a foot or so away.
Lots of people plan that smart phones shall do financial
transactions through NFC.
: :	Malaysians can now use their Nokia (NYSE:
: :	NOK) 6212 to make near-field Visa payments  : :	just wave your phone in front of a sensor and
: :	bam, instant buy in over 1,800 shops.
These transactions are reversible and made through
authorized retailers, hence, like the widely shared
secret on a credit card, really need very little
security.  Anyone to anyone irreversible transactions
would need considerably higher security, but there
appear to be considerable legal and regulatory obstacles
to that.

@_date: 2009-09-03 10:07:00
@_author: James A. Donald 
@_subject: Client Certificate UI for Chrome? 
When the user clicks on a button generated by a particular special kind of html tag, perhaps
<loginbutton logintype="SRP" A not quite rectangular login form which is not an html page rolls out of the url, with a motion like a blind or toilet paper unrolling, and partially covers the browser chrome, thus associating the form  with the browser and the url, rather than the web page.
The form will be decorated and prominently watermarked in manner that is customizable by the end user, and if the end user does not customize it, which he probably will not, a customization was randomly selected at install time.
A phisher could do a flash animation that looks almost like the form rolling out, but the flash animation will not roll out of the url, and will not partially cover the browser chrome, and is unlikely to match the customization.
If the url is Then the content of the login form is controlled by script at The login form will be associated with a public key.  If the user has logged in before using this browser, there will be an entry in his bookmarks list for the url *and* public key
If the login form is the browser's bookmark list, the title on the login form will be the petname, that is to say, the name under which it appears in the bookmark list.
If the login form is *not* in the browser's bookmark list, the title on the login form will be "No Previous Login at this site using this browser by this user", with script supplied title and or certificate supplied title somewhere else in smaller print.
The loginpage.script will tell the browser what fields and fieldnames to request from the user - typically username and password, but this needs to be scriptable - for example it could be credit card number, etc.  The script will tell the server what database table and what database fields to associate these user supplied fields with when the client responds.
Peter Gutmann has, he believes, a much simpler solution.

@_date: 2009-09-05 16:14:46
@_author: James A. Donald 
@_subject: [tahoe-dev] Bringing Tahoe ideas to HTTP 
> > One possible problem: streaming [real-time] content.
 > Yeah, that's a very different problem space. You need
 > the low-alacrity stuff from Tahoe, but also you don't
 > generally know the full contents in advance. So you're
 > talking about a mutable stream rather than an
 > immutable file.
Not mutable, just incomplete.
Immutable streaming content needs a tiger hash or a
patricia hash, which can handle the fact that some of
the stream will be lost in transmission, and that one
needs to validate the small part of the stream that one
has already received rather than waiting for the end.
 > upgrade bundles are produced by a very strict process,
 > and are rigidly immutable [...] For software upgrades,
 > it would reduce the attack surface significantly.
But how does one know which immutable file is the one
that has been blessed by proper authority?  Although
Version 3.5.0 is immutable, what makes it Version 3.5.0,
rather than haxx350, is that some authority says so -
the same authority that said that your current version
is 3.4.7 - and it should not even be possible to get a
file named by some different authority as an upgrade.
Of course, one would like a protocol that committed the
authority to say the same thing for everyone, and the
same thing for all time, saying new things in future,
but never being able to retroactively adjust past things
it has said.
In other words, upgrades should be rooted in an append
only capability.
I suppose this could be implemented as a signed dag of
hashes, in which whenever one upgraded, one checked that
the signed dag that validates the upgrade is consistent
with the signed dag that validated the current version.

@_date: 2009-09-09 15:42:34
@_author: James A. Donald 
@_subject: Client Certificate UI for Chrome? 
Not if he only does it for special sites like banks, but if "something special" is pretty widely used, he will notice when things are different.
I never thought that funny colored url bars for banks would help, and ridiculed that suggestion when it was first made, and said it was merely an effort to get more money for CAs, and not a serious security proposal
The fact that obviously stupid and ineffectual methods have failed is not evidence that better methods would also fail.
Seems to me that you are making the argument "We have tried everything that might increase CA revenues, and none of it has improved user security, so obviously user security cannot be improved."

@_date: 2009-09-16 09:12:37
@_author: James A. Donald 
@_subject: Bringing Tahoe ideas to HTTP 
The ideas used in Tahoe are useful tools that can be used to solve important problems.
It is true that just dumping them on end users and hoping that end users will use them correctly to solve important problems will fail
It is our job to apply these tools, not the end user's job, the hard part being user interface architecture, rather than cryptography protocols.
Yurls are one example of an idea for a user interface wrapping
Tahoe like methods to solve useful problems.

@_date: 2009-10-01 06:38:03
@_author: James A. Donald 
@_subject: [Barker, Elaine B.] NIST Publication Announcements 
>> The Haber & Stornetta scheme provides a timestamping
 >> service that doesn't require terribly much trust,
 >> since hard to forge widely witnessed events delimit
 >> particular sets of timestamps. The only issue is
 >> getting sufficient granularity.
 > I don't know if their scheme was patented in Germany.
 > It was in the U.S., though I think that at least some
 > of the patents expire within the year.
In looking this up, I have noticed a pile of patents
that patent something equivalent or near equivalent to a
patricia hash tree, or elaborately disguised patricia
trees, or something suspiciously similar to a patricia
hash tree, and various special cases of it, and
applications of it, without using the name "patricia
hash tree"
Since they seem reluctant to use the name "patricia hash
tree" I suspect  that there is already a pile of prior
art, but I could not find any, though I am fairly sure
the method is widely known.  Also, wherever there is a
pile of patents, there is usually a pile of prior art.
Lest even more patents of the patricia hash tree be
published, I would like to describe the method here,
though it surely must be described somewhere else,
probably long ago.
Suppose we have a lot of records, each with a key that
makes collision improbable or impossible,  We assemble
them in a patricia tree, with each node of the patricia
tree containing a hash of its child nodes.  The root of
the patricia tree then, like a tiger hash, uniquely
identifies the complete data set.  If we have multiple
copies of the data set, this data structure allows us to
not only ensure that both copies are identical, but if
there are small differences between them, such as
recently added records, it allows us to efficiently find
the differences, and thus efficiently bring the two data
sets into agreement.
It also allows us to prove that a given record was part
of a particular data set at a particular time.
Suppose the high order part of the key identifies the
high order part of the time, followed by the id of the
particular organization holding those records.  The
upper parts of the patricia hash tree are partially
shared, peer to peer, similarly to file sharing with a
tiger hash.  Each participating organization keeps the
nodes that relate to it. The lower parts are not shared
except as needed.
In this case, there will be a small set of top nodes of
the tree that cease to change, because they only rely on
keys earlier than a certain date, and this small and
very slowly growing set of top nodes proves the complete
state of the tree at all earlier dates.
Then each organization can prove to all or any of the
others that it had a particular record, or particular
set of records, at a particular time, to the granularity
of the time that is the high order part of the key.
Where some or all of the data needs to be shared by some
or all of the organizations, organizations can rapidly
and efficiently identify any disagreements, and when
they are in agreement, rapidly and efficiently prove to
themselves, and to everyone else, and record for all
time, that they are in agreement, since a small number
of the topmost nodes of the tree proves the state of the
tree at each and all times that contributed to those
The structure serves for attestation and sharing, and
since attestation usually involves sharing, and sharing
attestation, the scope for patenting this structure over
and over again in one disguise or another to be applied
to one task or another that involves sharing and or
attestation is limited only by the boundless imagination
of patent lawyers.  One can also add horizontal and
backwards hash relationships between nodes that serve
little practical purpose other than allowing one to have
a single rapidly changing node node attesting instead of
a small set of nodes, and allowing it to be nominally
something other than a patricia hash tree.
Thus, for example, instead of using forty or so nodes to
attest for the state of million organizations over a
billion time periods, one can use a hash of those forty
nodes, and there are no end of different ways one can
hash those forty or so nodes together.  But under that
hash, it is still a patricia hash tree doing the actual
work of gluing the data together.

@_date: 2010-04-22 18:49:17
@_author: James A. Donald 
@_subject: The EC patent issues discussion 
To summarize that document:  All the EC stuff that you need was published more than fifteen years ago,
  therefore you cannot be violating patents if you stick to that stuff.

@_date: 2010-08-07 04:57:44
@_author: James A. Donald 
@_subject: A mighty fortress is our PKI, Part II 
> Signatures are largely a distraction from the real problem: that software
 > is (unnecessarily) run with the full privileges of the invoking user.
 > By all means authenticate software, but that's not going to prevent A lot of devices are locked down so that you cannot install bad software.  This is somewhat successful in preventing bad software from being installed, and highly successful in irritating users.

@_date: 2010-08-18 11:52:17
@_author: James A. Donald 
@_subject: Has there been a change in US banking regulations recently? 
For sufficiently strong security, ECC beats factoring, but how strong is sufficiently strong?  Do you have any data?  At what point is ECC faster for the same security?

@_date: 2010-08-18 12:13:21
@_author: James A. Donald 
@_subject: 2048-bit RSA keys 
Which tells us that ordinary hobbyist and academic efforts will not be able to factor a 1024 bit RSA modulus by brute force until around 2015 or so - but dedicated hardware and so forth might be able to do it now.
What is the latest news on cracking by ECC by brute force?

@_date: 2010-08-26 12:40:04
@_author: James A. Donald 
@_subject: towards https everywhere and strict transport security 
This is inherent in the layering approach - inherent in our current crypto architecture.
To avoid inordinate round trips, crypto has to be compiled into the application, has to be a source code library and application level protocol, rather than layers.
Every time you layer one communication protocol on top of another, you get another round trip.
When you layer application protocol on ssl on tcp on ip, you get round trips to set up tcp, and *then* round trips to set up ssl, *then* round trips to set up the application protocol.

@_date: 2010-07-13 09:45:15
@_author: James A. Donald 
@_subject: 1280-Bit RSA 
> On Fri, 9 Jul 2010 21:16:30 -0400 (EDT) Jonathan
 >
 >> The following usenet posting from 1993 provides an
 >> interesting bit (no pun itended) of history on RSA key
 >> sizes.  The key passage is the last paragraph, asserting
 >> that 1024-bit keys should be ok (safe from key-factoring
 >> attacks) for "a few decades".  We're currently just under
 >> 1.75 decades on from that message.  I think the take-home
 >> lesson is that forecasting progress in factoring is hard,
 >> so it's useful to add a safety margin...
 >
 > This is quite interesting.  The post doesn't say but I
 > suspect at the factoring effort was based on using
 > Quadratic Sieve rather than GNFS. The difference in speed
 > for QS versus GNFS starts to really diverge with larger
 > composites.  Here's another table:
 >
 > RSA	GNFS	QS
 > ===========================
 > 256	43.68	43.73
 > 384	52.58	55.62
 > 512	59.84	65.86
 > 664	67.17	76.64
 > 768	71.62	83.40
 > 1024	81.22	98.48
 > 1280	89.46	111.96
 > 1536	96.76	124.28
 > 2048	109.41	146.44
 > 3072	129.86	184.29
 > 4096	146.49	216.76
 > 8192	195.14	319.63
 > 16384	258.83	469.80
 > 32768	342.05	688.62
The numbers in the second column of this table are the
equivalent strength of symmetrical encryption, that is to
say, against attackers armed with the GNFS, a 3072 bit RSA
key is as tough as a 128 bit symmetric key.
 >
 > Clearly starting at key sizes of 1024 and greater GNFS
 > starts to really improve over QS.  If the 1993 estimate for
 > RSA 1024 was assuming QS then that was roughly equivalent
 > to RSA 1536 today.  Even improving the GNFS constant from
 > 1.8 to 1.6 cuts off the equivalent of about 256 bits from
 > the modulus.
 >
 > The only certainty in factoring techniques is that they
 > won't get worse than what we have today.
Progress in cracking elliptic curves, however, does not seem
to be happening, probably because elliptic curves are truly
  How do elliptic curves compare to RSA today?
According to
RSA	ECC	Sym
1024	160	80
2048	224	112
3072	256	128
4096	280	140
That is to say, a 3072 bit RSA key is as tough as an ECC key
based on a 256 bit field, which is as tough as a 128 bit
symmetric key.
ECC cryptosystems on 256 bit field are practical today.  3072
bit RSA systems are not.
It looks to me that Moore's law plus GNFS has decisively
tipped the balance in favor of elliptic curves - and if one
has patent worries, good elliptic curve algorithms were
published more than fifteen years ago.

@_date: 2010-07-29 19:19:16
@_author: James A. Donald 
@_subject: A mighty fortress is our PKI, Part II 
Bittorrent links have this property.  A typical bittorent link looks like It is the equivalent of an immutable file in Tahoe.
The browser vendors are married to the CAs

@_date: 2010-03-25 08:31:36
@_author: James A. Donald 
@_subject: Question regarding common modulus on elliptic curve cryptosystems 
The most powerful primitive, from which all manner of weird and wonderful protocols can be concocted, are gap diffie helman groups.  Read Alexandra Boldyreva "Threshold Signatures, Multisignatures, and Blind Signatures based on Gap-Diffie-Helman Group Signatures.
I am not sure what you want to do with commutativity, but suppose that you want a coin that needs to be signed by two parties in either order to be valid.
Suppose we consider call the operation that combines two points on an elliptic curve to be generate a third point multiplication and division, so that we use the familiar notation of exponentiation, thereby describing elliptic point crypto systems in the same notation as prime number crypto systems (a notation I think confusing, but everyone else uses it)
Suppose everyone uses the same Gap Diffie Helman group, and the same generator g.
A valid unblinded coin is the pair {u, (u^(b*c)}, yielding a valid DDH tuple {g, g^(b*c), u, u^(b*c)}, where u is some special format (not a random number)
Repeating in slightly different words.  A valid unblinded coin is a coin that with the joint public key of Bob and Carol yields a valid DDH tuple, in which the third element of the tuple has some special form.
Edward wants Bob and Carol to give him a blinded coin.  He already knows some other valid coin, {w, w^(b*c)).  He generates a point u that satifies the special properties for a valid coin, and a random number x.  He asks Bob and Carol to sign u*(w^(-x)), giving him a blinded coin, which he unblinds.

@_date: 2010-03-25 08:37:05
@_author: James A. Donald 
@_subject: Question regarding common modulus on elliptic curve cryptosystems 
Gap Diffie Helman gives you a commutative signing primitive, and a zero-proof of knowledge.

@_date: 2010-10-03 10:01:49
@_author: James A. Donald 
@_subject: 2048 bits, damn the electrons! [rt@openssl.org: [openssl.org 
Which does not, however, make bloated RSA keys any the less evil.
All the evils you describe get worse under https.
A badly designed https page is likely to require the client to perform lots and lots and lots of RSA operations in order to respond to the user A 2048 bit operation takes around 0.01 seconds, which is insignificant.   But an https connection takes several such operations.  Lots of https connections ....

@_date: 2010-09-09 19:08:47
@_author: James A. Donald 
@_subject: Hashing algorithm needed 
Except, of course, by dictionary attack, hence g^x, being low
entropy, is treated as a shared secret.
and the client does DSA using x.

@_date: 2010-09-16 14:10:08
@_author: James A. Donald 
@_subject: A mighty fortress is our PKI, Part III 
That is rather like having a fortress with one wall rather than four walls, and when attackers go around the back, you quite correctly point out that the wall is only designed to stop attackers from coming in front.

@_date: 2010-09-29 08:42:49
@_author: James A. Donald 
@_subject: 'Padding Oracle' Crypto Attack Affects Millions of ASP.NET Apps 
Now I understand why one should, counterintuitively, encrypt then MAC.

@_date: 2013-08-22 12:32:10
@_author: James A. Donald 
@_subject: [Cryptography] What is the state of patents on elliptic curve 
Such a question will be answered not with light but with darkness.

@_date: 2013-08-26 11:22:23
@_author: James A. Donald 
@_subject: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
We need, and have not designed, a good distributed reputation system, resting on Zooko's triangle and a large global hash tree that provides an unfalsifiable past history of the past conduct of key holders.
Such a global hash tree requires, like bitcoin, a solution to the Byzantine Generals Problem - a known hard problem that is nonetheless A distributed reputation system can also provide things like debt based money that provides an incentive for seeding - for providing storage of interesting content as well as an incentive for upload bandwidth of interesting content.  Bittorrent provides an upload bandwidth incentive, but no storage incentive.

@_date: 2013-08-29 14:26:35
@_author: James A. Donald 
@_subject: [Cryptography] Petnames & Zooko's triangle -- theory v. 
Because email addresses and urls are already for the most part non human memorable, we already have implementations of Zooko's triangle which seem to work fine for the ordinary end user.
The old petname tool, (which has now probably succumbed to bitrot) used the browser's bookmark list to store public key data, thus was an implementation of Zooko's triangle, that piggy backed on the browser's implementation of Zooko's triangle for non human memorable urls.  It worked fine for me.
My petnames are still on the browser bar, providing easy access to my bank and stuff, though no longer providing security.

@_date: 2013-08-30 14:43:55
@_author: James A. Donald 
@_subject: [Cryptography] Communicating public keys: A functional specification 
<521CE337.6030706
Communicating public keys:  A functional specification
A functional specification tells us how the user uses it, what he sees, and what it does for him.  It does not tell us how we manage to do it for him.
The problem is that you want to tell someone over the phone, or on a napkin, or face to face, information that will enable his client to securely obtain your public key and network location so that end to end secured communication can take place.
Also a chatroom's public key and network location.
We do not necessarily protect against security agencies figuring out which public key is talking to which public key.  That issue is out of the scope of a functional specification, but we somewhat reduce the usefulness of this information by allowing people to have lots of public keys.  So you probably have one key for activities that show your unusual sexual preference, another key for job related activities, another key for tax evasion related activities, another key for gun running, and yet another for attempts to overthrow the regime.
Face to face:
    Identifying information is nym, face, and location.
    Recipient looks up the nym, sees a bunch of faces grouped by
    geographic area.  Geographic are usually, but not necessarily, has
    some relation to users actual location, and may be very specific, or
    very broad.  It is a tree.  One guy may locate his face at the node
    "North America", another at the node New York, North America.  You
    may, of course, employ a well known cartoon character or movie star
    as your avatar instead of your actual face.   Fictional places are
    permitted, but to avoid filling the namespace, not on the tree that
    represents the real planet earth.
Over the phone.
    Recipient looks up phone number.  Finds a bunch of named keys
    associated with the phone number - usually one key or a quite small
    number of named keys.
Web or email.
    Send a link that contains a 256 bit identifier, but the UI should
    not show anyone the identifier.
The ordinary user by default finds himself using at least one key for face to face key introductions, a different key or keys for phone introductions, and yet more for web or email introductions. If he is clever and reads the manual, which no one will ever do, he can use the same key for multiple purposes.
All of these named keys have the same behavior when you click on them, they are intended to be perceived by the user as being the same sort of He can use the link, the named key, to attempt to contact, or buddy it, or bookmark it.
The identifying link information looks like a web link, and is the nickname of the public key.  By default the nickname is the petname.  The user is free to edit this, but usually does not.
When he attempts to contact, this automatically buddies it and/or bookmarks it.
When he finds a named key, he may "bookmark" it, together with one of his own private keys - it goes into a datastructure that looks like, and works like, browser bookmarks.  He can also put it in his buddy list.
When you look at an item in your buddy list or bookmarks list, You see a pair, the other guys key identifying information, and your own key identifying information.  You don't see the keys themselves, since they look like line noise and will terrify the average user.
When you click on one of these bookmarks, this creates a connection if your key is on the other guy's buddy list and he is online.  You can chat, video, whatever, end to end secured.  Otherwise, if you are not on his buddy list, or he is not presently online, you can send him something that is very like an email, but end to end secure.
When you send a bunch of people a text communication, chat like, chatroom like, or email like, they are cc or bcc.  If cc, all recipients of the communication get links, which they can, if they feel so inclined, message, bookmark or buddy.
Text communication software vacuums up and stores all links, so if you get an incoming communication from someone whose public key you have not buddied or bookmarked, the software will tell you any past contacts you may have had with this public key.
Buddied public keys are white listed for immediate online communication, Bookmarked and buddied public keys are white listed for offline text communication, public keys with past information about contacts are grey listed, public keys with no previous contact information are blacklisted.
Because of automatic blacklisting, to contact, you have to /exchange/ keys.

@_date: 2013-09-01 11:11:50
@_author: James A. Donald 
@_subject: [Cryptography] NSA and cryptanalysis 
So far, not much affect on elliptic keys.
Except that all elliptic keys of the extremely useful gap-diffie-hellman group are potentially subject to techniques analogous to those that are attacking RSA.

@_date: 2013-09-01 13:02:26
@_author: James A. Donald 
@_subject: [Cryptography] Thoughts about keys 
============================== START ==============================
The average user is disturbed by the sight a 160 bit hash.
When posting graphic images on my blog, I have to name the image twice, once when I store it on my website, and once when I reference it in a post.   Despite the fact that the names are meaningful and human readable, and the total number of images is not unreasonably large, I find it quite difficult to enter exactly the same name the same way twice.  Much of the time the image mysteriously fails to appear, even though I cannot see any typo, the two spellings right in front of me look exactly alike.
The end user's instinctive fear of 160 bit hashes is well founded..

@_date: 2013-12-07 16:54:35
@_author: James A. Donald 
@_subject: [Cryptography] Email is securable within a coterie 
The anonymity of bitcoin comes from the fact that everyone is, or recently used to be, his own remailer.
However, the cost of operating a client that is a full and equal participant in tracking and propagating bitcoin transactions has become greater and greater, and so fewer and fewer people are full and equal As a result, bitcoin is becoming less and less anonymous.
This is one of the effects of the scaling problem I complained about at the beginning.
Nonetheless, bitcoin is a huge success, and having an imperfect bitcoin is a lot better than having no bitcoin at all.  My criticisms were valid, but Satoshi Nakamoto was correct to not allow the best to be the enemy of the good.

@_date: 2013-12-08 14:14:33
@_author: James A. Donald 
@_subject: [Cryptography] Fun with hardware RNGS: the Infinite Noise 
Looks to me that if you peturb this circuit, you will get a different, but equally random set of bits, for, no matter what the peturbation, any noise in the system gets amplified to infinity, even if the enemy is injecting a signal that is cleverly designed to mess with it.

@_date: 2013-12-08 18:15:22
@_author: James A. Donald 
@_subject: [Cryptography] Fun with hardware RNGS: the Infinite Noise 
No, a physical circuit does not have a finite sensitivity.  It has a finite noise floor.

@_date: 2013-12-14 11:50:50
@_author: James A. Donald 
@_subject: [Cryptography] An alternative electro-mechanical entropy source 
"Influencing" random number generation is unimportant, since all it does is result in different random numbers that are equally unpredictable.

@_date: 2013-12-14 16:47:10
@_author: James A. Donald 
@_subject: [Cryptography] Kindle as crypto hardware 
What he said.
Also, direct NSA involvement in politics, for example spying on General Petraeus.  This suggests that if you are republican politician, your emails, and your political consultant's emails, are likely to end up being shared with your Democratic party opponent's political consultants.

@_date: 2013-12-14 19:05:26
@_author: James A. Donald 
@_subject: [Cryptography] Moving forward on improving HTTP's security 
Is OK turtles a design, a vision of a design, or an actual product, an open source product or a closed source product?
If it is an actual thing, I should be able to get a human readable name, associate that name with a network address, and other people should be able to have secure communications between a name that they control, and a name that I control, and thus between themselves and me.
I don't see any way to do this now.  So I conclude that OK turtles is a vision of how a design should be implemented, a proposed way of squaring Zooko's triangle, not an actual product that squares Zooko's triangle.

@_date: 2013-12-14 19:15:58
@_author: James A. Donald 
@_subject: [Cryptography] DNSNMC deprecates Certificate Authorities and 
Is this an idea, a project, or a product that can actually be used?

@_date: 2013-12-17 09:59:01
@_author: James A. Donald 
@_subject: [Cryptography] The next generation secure email solution 
Trouble is that the average user, or indeed the sophisticated user, is apt to run away screaming on sight of a crypto key or a strong hash of one.
Need a system for handing one's keys around that protects end users from the horrifying sight of actual keys or actual strong hashes of keys.

@_date: 2013-12-20 18:09:19
@_author: James A. Donald 
@_subject: [Cryptography] Fwd: [IP] 'We cannot trust' Intel and Via's 
If you use RDRAND, your random numbers are secure against everyone except the five eyes.
If you mix RDRAND with a large random number set at install time, plus the time, you are probably secure against the five eyes as well.
If any one adversary lacks access to every one of your sources of randomness, your randoms are good against that adversary.
So, consider:  Powerful adversaries, Nigerian adversaries, far adversaries, near adversaries.   A source of randomness only has to be good against one of them to be useful.

@_date: 2013-12-21 14:19:24
@_author: James A. Donald 
@_subject: [Cryptography] Decentralized, global, irreversible, 
Not being worked on.
Or perhaps it is, for example namecoin.
Satoshi's idea of one CPU, one vote, is undermined by dedicated hardware, one FPGA, one vote.
Also, we would like a global database that could handle more material than the bitcoin database, which is creaking under the strain.
Two useful activities for a global irreversible database:  Record payments, resulting in conserved money, record  mappings between names and public keys, making sure they are the same for everyone.
Not happy with Satoshi's solution, but, on the other hand, he has a solution and I do not.

@_date: 2013-12-23 20:00:56
@_author: James A. Donald 
@_subject: [Cryptography] What do we know? (Was 'We cannot trust' ...) 
> Nothing I've seen so far describes what the $10M actually paid for.
 > So nothing is inconsistent with the possibility that what RSA saw
 > was a $10M contract to provide BSAFE to some government agency -
But what RSA did was provide backdoored BSAFE to everyone, not just one government agency.
"Here is ten million dollars to make *other* people use our algorithm"
"That is the algorithm that various noted cryptographers say smells
mighty funny?
"That is the one"

@_date: 2013-12-24 16:51:53
@_author: James A. Donald 
@_subject: [Cryptography] RSA is dead. 
> Have a look at some of the entries in the Obfuscated V contest (to
 > write innocent-looking code that actually cheated one of the
 > candidates).  My favorite is
 >  - just one
 > of many.
 > Come back and tell me how "capable developers" will easily find
 > malicious code hidden in simple, clean-looking C code.
The use of the macro  VOTE_AND_CHECK(v) was obviously odd and out of place.
If not obvious what was hidden, it was immediately obvious that the writer was trying to hide something by the use of obfuscated code.
So, I do the glaringly obvious thing, and substitute the macro, de obfuscating the code, whereupon it is immediately obvious that the inner t hides the outer t, which is obscure and misleading code, notoriously apt to lead to errors.
So, I check for errors induced by the inner variable hiding an outer And, ding!  Since this is a macro, v references the inner t, not the outer t, so every CHECK_INTERVAL votes, a vote gets counted for bush, regardless of who it should be counted for.
This took me about half an hour.  Normal time for checking someone else's code, written to be clear, with the author sitting right beside me answering my questions, is one hundred lines per hour.
This was a hundred line program.  So the time it took me to find the error was right in line with the time it takes me to find errors in someone else's code when he has written the code to be as straightforward as possible, and he is sitting in right front of me honestly answering my questions about his code.

@_date: 2013-12-24 17:42:33
@_author: James A. Donald 
@_subject: [Cryptography] how reliably do audits spot backdoors? 
I find C quite intuitive, possibly as a result of having done a bit of code review.
What you would call counterintuitive, I read as idiomatic, and what is undefined, I read as unidiomatic.
So, the underhanded C examples would have failed code review, not because their terribly sneaky measures would have been detected in code review, but for being unidiomatic, obfuscated, uglified, or complexified.
The code review would have come to an end, and the developer ordered to do a rewrite, before the trick had been detected.

@_date: 2013-12-24 17:03:10
@_author: James A. Donald 
@_subject: [Cryptography] RSA is dead. 
>> Nonsense.  Most other equally capable developers should be able to
 >> discover a backdoor with far less effort to hide it.  Reading other
 >> people's code is a skill that some people never acquire, but it's
 >> generally easier to understand someone else's code entirely than to
 >> have created it from scratch.
 >>
 >> If the code is so obscure that this is not the case, that code
 >> should not be used in crypto.  I'll just point out that gtksu falls
 >> exactly into this category, yet we continue to use it... it really
 >> deserves to be retired.  Open source is *very* helpful, but if the
 >> people with the decision power over what to include are far more
 >> ignorant than the coders... well then just forget security.
 > Have a look at some of the entries in the Obfuscated V contest (to
 > write innocent-looking code that actually cheated one of the
 > candidates).  My favorite is
 >  - just one
 > of many.  Come back and tell me how "capable developers" will easily
 > find malicious code hidden in simple, clean-looking C code.
If this code had been presented to me in a code review, in three
minutes I would have said:
And given the developer a stern look.
When the code came back I would have said, after about a quarter of an
hour or so, inner variable hiding outer variable.  This is a bug, I
don't need to try to see what effect this bug will have on the code,
it will result in something strange and horrid, and if it does not
result in something strange and horrid now, it will the next time
someone edits your code.
So, though normal code review takes about one hundred lines an hour,
the hidden vote miscounting would have been removed in twenty minutes
of my time.
Not having the developer in front of me to be roasted, took thirty minutes of my time.

@_date: 2013-12-24 17:27:52
@_author: James A. Donald 
@_subject: [Cryptography] how reliably do audits spot backdoors? 
The example backdoor would not have survived normal code review by me.
So all you need is people like me reviewing code.  Which you should do

@_date: 2013-12-24 17:32:53
@_author: James A. Donald 
@_subject: [Cryptography] how reliably do audits spot backdoors? (was: Re: 
In code reviews, I automatically reject things that make the complexity of the search go up faster than linearly.
The underhanded C examples all, or all I glanced at, used obfuscation, uglification, and complexification, that would have been immediately thrown out in code review, without anyone bothering to figure out what the obfuscation obfuscated, what the uglified and complexified code actually did.

@_date: 2013-12-24 18:28:52
@_author: James A. Donald 
@_subject: [Cryptography] What do we know? (Was 'We cannot trust' ...) 
Not when you are selling to government agencies.  If they want a customized product, you produce a fork or a skew for that government agency and charge them extra.

@_date: 2013-12-25 09:18:34
@_author: James A. Donald 
@_subject: [Cryptography] RSA is dead. 
You probably have written a lot more code than I, and reviewed a lot less.
If that code had faced code review, reviewers would have demanded a rewrite without bothering to find if there were any flaws.
As you say, effing macros.
Macros and templates should only be used when they provide obvious and substantial advantages.   A multiline macro referencing external variables is obfuscated code.  Worse than closures.
Macros and templates are justified if they are self contained and massively re-used, or if they concisely express the concept better than the actual implementation, for example operator less, for code that can be and will be interchanged with any other operator less.

@_date: 2013-12-25 11:34:42
@_author: James A. Donald 
@_subject: [Cryptography] how reliably do audits spot backdoors? 
To me that is totally intuitive and natural, and I have written code that takes advantage of this effect (sliding window code)  It just seemed natural to do it that way.
Yet they would have instantly failed any code review in which I have participated.  I would not have found the bug, because I would have tossed back the code on sight.
In the example cited,   the macro was egregious and obnoxious obfuscation and complexification, and would have led to a swift and automatic demand for rewrite without the macro - which rewrite in turn would have rendered the bug highly visible to code review - indeed it did render the bug highly visible to code review. That is how I spotted the bug, by de-obfuscating the code, whereupon it becomes obvious that the variable t is overused for incompatible purposes.
Do what I did in the example, and de-obfuscate the obfuscated code, by manually substituting the macro.  It did not take me very long.
Whenever you attempt to do a project in "high level code", the project becomes ninety percent complete in much less time than when you do it in C++, and then remains ninety percent complete forever.
You get the higher level language problem that the libraries are slightly different on each machine, which results in nightmare installations.  Doubtless you can audit your code faster, but can you audit all those installations and libraries?
If you have one high level program using a library, and another high level program using that same library, there is, with remarkable frequency, a way for the one high level program to screw over the other high level program.

@_date: 2013-12-25 11:58:45
@_author: James A. Donald 
@_subject: [Cryptography] RSA is dead. 
I assume one hour per hundred lines of code review, so ninety minutes is within my range of normal variation, as is half an hour.

@_date: 2013-12-25 12:08:58
@_author: James A. Donald 
@_subject: [Cryptography] how reliably do audits spot backdoors? 
I don't think a backdoor is likely to survive a serious audit.  Code audits, done right by competent people, are tough.
Though, done right, they are expensive.
If crypto code is open source, most people will use it without careful examination on the assumption that someone else is going to audit it.
But, some people, relying on that code, *are* going to audit it.

@_date: 2013-12-25 17:57:18
@_author: James A. Donald 
@_subject: [Cryptography] how reliably do audits spot backdoors? 
That the sum of two positive numbers is a negative number is defined behavior, word length being defined.
Observe, that pretty much every program written in C simply installs, and pretty much every program written in python simply does not.

@_date: 2013-12-26 04:44:07
@_author: James A. Donald 
@_subject: [Cryptography] how reliably do audits spot backdoors? 
Not having the developer in front of one, merely means one has to fix obfuscated and complexified code oneself.  As, in the example case, I did.

@_date: 2013-12-26 11:59:41
@_author: James A. Donald 
@_subject: [Cryptography] On Security Architecture, The Panopticon, 
The old Skype system was user friendly and offered end to end encryption, except that the central authority could easily mim someone, and except that it was a closed source implementation of a closed source protocol, thus could be quietly changed without telling anyone.
And, of course, was quietly changed without telling anyone.
Solution to mim by central authority: some kind of distributed, append only, database, such that if the central authority mims someone, it faces a significant risk of detection.
However, distributed append only data base not quite as easy as it sounds.

@_date: 2013-12-28 12:36:28
@_author: James A. Donald 
@_subject: [Cryptography] On Security Architecture, The Panopticon, 
Money is a bubble that never pops.
People who invest in gold or bitcoin are taking out insurance against the equally worthless US dollar.

@_date: 2013-12-28 17:48:54
@_author: James A. Donald 
@_subject: [Cryptography] RSA is dead. 
Not participating in this, since I probably suck at reviewing python code, never having done so before.

@_date: 2013-12-28 18:51:52
@_author: James A. Donald 
@_subject: [Cryptography] What do we know? (Was 'We cannot trust' ...) 
Famously, government does not care.  It is just taxpayer money.

@_date: 2013-12-28 20:04:42
@_author: James A. Donald 
@_subject: [Cryptography] how reliably do audits spot backdoors? 
Transating to C, you have to add your own memory management code, which is a large part of any C program, hence the much longer C translation times.
Modern C++ has some tools that substantially automate memory management and  type management, but you still have to think about memory management, while Java does it all for you.
Perl, Java, and PHP are all memory managed languages, so translation from Java to Perl or PHP is straightforward.
PHP notoriously tends to turn into spaghetti code, people keep copying and pasting the code, resulting in lots of lots of code pages that are similar but not identical.  You are, of course, not supposed to do this, but, but, the boss wants this bug fixed, or this feature added, tomorrow.  As a result, productivity in kilolines per hour is alarmingly Translating Java into Perl is doubtless easy, but translating from Perl to Java ...  Perl is a write only language.
C++ has the wonderfully powerful template system.  Unfortunately, the template system is apt to produce gigantic error messages whose sheer size makes them difficult for anyone to comprehend.  But you can do things with templating that you cannot do in any other language except lisp.  In this sense, C++ is the highest level language of them all, except for lisp, as well as being the lowest level language of them all.

@_date: 2013-12-29 07:00:35
@_author: James A. Donald 
@_subject: [Cryptography] What do we know? (Was 'We cannot trust' ...) 
>>> Large customers, government or otherwise, that know what they are
 >>> doing realize that if a custom extension/addition is incorporated
 >>> in a product *just for them*, then they will be paying forever for
 >>> it to be maintained and included with every future upgrade of the
 >>> product.
 >> Famously, government does not care.  It is just taxpayer money.
 > It really depends.
No it really does not depend.  You would have to be crazy to pass up an excuse to customize a product so that it is government only, thus allowing you can justify a completely insane price enormously higher than that you charge other customers.  No one ever passes up such If you have a customer who is spending other people's money for the benefit of other people, you can charge him considerably more.  If the people he supposed serves are far away, you can charge him way, way, way more, in approximate proportion to the organizational and geographic distance between agent and principal.
 > But there's also an immense amount of "ordinary" stuff the
 > government buys under COTS regulations.  There are huge numbers of
 > perfectly ordinary PC's and laptops spread throughout government
 > offices that were bought from the same distributors any large
 > business might go to, at the same prices any large business might
 > pay.
Which is exactly why you want an excuse for product differentiation, to get around those nasty regulations that require you to charge government the same price as you charge customers that care about price.
Thus, from the fact that RSA responded to payment by putting the algorithm in the product for everyone, we may conclude that the government paid them to put the algorithm in the product for other people not the government.

@_date: 2013-12-29 07:21:47
@_author: James A. Donald 
@_subject: [Cryptography] how reliably do audits spot backdoors? 
>>> I do it all in Java.  Once, when I did a port from Java to various
 >>> languages, it took 5 times longer to get it into C as opposed to
 >>> various OO languages (PHP, Perl).
 >> Transating to C, you have to add your own memory management code,
 >> which is a large part of any C program, hence the much longer C
 >> translation times.
 >>
 >> Modern C++ has tools that substantially automate memory
 >> management and  type management, but you still have to think about
 >> memory management, while Java does it all for you.
 > It really depends on what you're doing.  Java only *appears* to do
 > it all for you; while you can't get the traditional memory leak
 > (memory to which no accessible pointers exist), you can easily build
 > up piles of guck that's pointed to by hash table entries you forgot
 > to clean up, for example.  And the GC doesn't help you with
 > non-memory resources.  This is where destructors, if used carefully,
 > can really pay off in C++:  You can guarantee [...] the complete
 > cradle-to-grave semantics of types you  define.  You can't do that
 > in Java - you're left telling users they  *must* call close() before
 > they stop using function, which they  forget to do
If you translate from Java to C++, then chances are you are not fully
using the C++ memory management and resource management features - you
are still hoping that guy  who called your code  called "close".

@_date: 2013-12-31 18:44:53
@_author: James A. Donald 
@_subject: [Cryptography] On Security Architecture, The Panopticon, 
> Distinguish the different uses of bitcoins.  For buying things
 > online, yeah, there's a demand for bitcoins based on wanting to be
 > able to do online transactions.  To the extent there are
 > transactions that lots of people prefer to do in bitcoins (whether
 > legal or illegal), there will be a certain amount of demand for
 > bitcoins based simply on how many bitcoins are either involved in a
 > transaction right now, or are being held ready to be used for a
 > transaction soon.  But bitcoins are online, and their volatility
 > makes them an awful store of value.  (They can be a speculative
 > investment, but they aren't where you'd want to park your retirement
 > fund on your 60th birthday.) They're too volatile to be a good unit
 > to price things in, too.
But if one has retirement funds denominated in dollars, one is exposed
to a considerable risk that these might go to zero.
In the event that dollars go to zero, either gold or bitcoins will go
up, gold by a little, bitcoins by a lot.
Therefore to reduce the risk of being poor in the midst of a terrible
crisis, should diversify some dollar denominated assets into gold and

@_date: 2013-11-02 12:27:16
@_author: James A. Donald 
@_subject: [Cryptography] [RNG] /dev/random initialisation 
On Oct 30, 2013, "James A. Donald"
 > > No source of entropy can ever be harmful. The worst that can happen
 > > is that it is entirely predictable to the adversary, in which case
 > > it does little good, but can never do harm.
 >  Now suppose I inject j >> k bits of my own, controlled data,
 > declaring that it represents j bits of entropy - all the while
 > continuing to draw j bits out.
You have to have root access to declare your entropy represents j bits.
If the adversary has root access, game over.  We have to assume that OS writers and system owners are the people we are trying to protect, not the people who are attacking.
The NSA rule is not intended to exclude adversaries, but rather intended to exclude operating system writers who are non NSA.
It is intended to prohibit non NSA sources of entropy.
Thus it makes sense only from the point of view that the NSA wants to get the upper hand over the person who owns the computer.

@_date: 2013-11-02 12:30:19
@_author: James A. Donald 
@_subject: [Cryptography] [RNG] /dev/random initialisation 
>   Lots and lots of dumb policies and decisions have been accepted or
 >   imposed by people who thought they were doing something sensible,
 >   but were really making security weaker.  And the bit where people
 >   make up conspiracy theories to explain every such failure has zero
 >   chance of improving security.
We face real conspiracies by real people.  That has to be your threat
Having a valid threat model is bound to make you more secure.
Some bad decisions were made by conspiracy that intended bad outcomes.

@_date: 2013-11-02 12:37:31
@_author: James A. Donald 
@_subject: [Cryptography] [RNG] /dev/random initialisation 
I sent a dummy skype text that referenced a secret url on my own website, created for this test and never used before or since.
Shortly thereafter, got a hit on that url.
Wearing tinfoil hat now.  These days I assume that anyone who criticizes tinfoil hats is an NSA agent.

@_date: 2013-11-02 12:48:13
@_author: James A. Donald 
@_subject: [Cryptography] [RNG] /dev/random initialisation 
> Ah, so like FIPS, Linux only accepts "real" entropy from
 > "authenticated" sources.  :-)
The question is, who shall we trust?  Those approved by the NSA, or
those approved by the owner of the computer?

@_date: 2013-11-02 12:55:52
@_author: James A. Donald 
@_subject: [Cryptography] What's a Plausible Attack On Random Number 
The problem seems to be that some software early in the boot process may want randomness.
Bad software! Don't do that!

@_date: 2013-11-02 15:58:10
@_author: James A. Donald 
@_subject: [Cryptography] FIPS 140 testing hurting secure random bit 
> The reason I recommend making a formal comment is because the
 > documents are open for public comment right now, and because those
 > comments make it a lot easier to make a case that this is a problem
 > that needs fixing.
One most frequently encounters suggestions to go through proper
channels, when proper channels do not work.

@_date: 2013-11-03 07:23:18
@_author: James A. Donald 
@_subject: [Cryptography] [RNG] /dev/random initialisation 
>> I sent a dummy skype text that referenced a secret url on my own
 >> website, created for this test and never used before or since.
 >>
 >> Shortly thereafter, got a hit on that url.
 > This pattern has been reported befor; it's the result of Microsoft
 > searching for "evil" URL's
Yet sending an actual evil url in a skype message has no apparent

@_date: 2013-11-05 13:40:40
@_author: James A. Donald 
@_subject: [Cryptography] [RNG] /dev/random initialisation 
> > I sent a dummy skype text that referenced a secret url on my own
 > > website, created for this test and never used before or since.
 > >
 > > Shortly thereafter, got a hit on that url.
 > That's not the NSA - it's Microsoft.  This pattern has been reported
 > befor; it's the result of Microsoft searching for "evil" URL's
 > (those that have drive-by malware, mainly, though I suppose they
 > look for other stuff, too).  See
 >  > ,news-17036.html for one discussion.
  Which tells us:
Since the hit came a long time after the message, it would not have
been useful in protecting the recipient from clicking on links to
phishing sites.
Therefore, not its purpose.

@_date: 2013-11-05 13:44:30
@_author: James A. Donald 
@_subject: [Cryptography] [RNG] /dev/random initialisation 
And to prevent it, would need to check urls immediately, presumably against a list of known evil urls.
Instead the url is checked a long time after the message.
If one was perhaps trying to build a database of evil urls for subsequent censorship, one would at focus on urls that are spammed
in many messages.

@_date: 2013-11-06 07:44:59
@_author: James A. Donald 
@_subject: [Cryptography] [RNG] /dev/random initialisation 
> *you*, *right now*, it's not a security mechanism?
If the point is to protect the population at large, the first step would be to detect spammed urls, not unique urls.
If spying on me to protect me from myself, need to interrupt immediately.
If spying on me to protect the population at large (which I violently object to) then should be hitting on non unique urls.
The observed behavior pattern only makes sense if they are spying on me for dangerous thoughts, racism, the wrong kind of Islam (those misunderstanders of Islam), sexism in the workplace, homophobia, or, as with General Petraeus, blackmail material that some of the political elite can use against others of the political elite.
The observed behavior pattern does not make sense if they are spying on me to protect me from myself, nor if they are spying on me to protect the general population from spam and phishing.
Spam and phishing, you look for non uniqueness.
Evil thoughts, you look for uniqueness.  The observed behavior pattern is that they are looking for unique urls, as Al Quaeda might use, or a general setting up a liaison might use.

@_date: 2013-11-12 15:30:18
@_author: James A. Donald 
@_subject: [Cryptography] randomness +- entropy 
Obviously what we need is something that blocks until it has accumulated 128 bits of entropy, generates pseudo random output from its existing state, and never blocks thereafter.  From time to time, not very often at all, it reseeds by adding an addtional 128 bits of entropy all at once.
However, people complain that if any of the existing sources of randomness are fixed to work like that, it is not bug compatible and will break existing software.
So:  Create a new source of randomness, xrandom, which is like urandom, except for the bug.

@_date: 2013-11-12 18:23:51
@_author: James A. Donald 
@_subject: [Cryptography] randomness +- entropy 
I don't think so.
I think this is a configuration bug.  By the time you have completed the boot process, you have accumulated lots of entropy, and there is no cryptographic application so urgent it cannot wait for the boot process to complete.
However, some idiot puts a process needing true randomness early in the boot process for no good reason.
A process needing true randomness should fail by design in such case.

@_date: 2013-11-13 18:43:23
@_author: James A. Donald 
@_subject: [Cryptography] [cryptography] Practical Threshold Signatures 
The Weil pairing is a great big hole in our usual arguments that most elliptic curves are strong.
The usual arguments that it is likely to be hard to solve the discrete log problem for elliptic curves do not apply to an elliptic curve with a Weil pairing.
Samuel Neves sounds like he understands enough maths to discern what qualifies an elliptic curve with a Weil pairing to be strong, but I do not.

@_date: 2013-11-13 20:40:01
@_author: James A. Donald 
@_subject: [Cryptography] randomness +- entropy 
Initially it decrypts, so does not need randomness.
Pretty soon however, write needs to be available.  But if one has an encrypted file system, that is pretty good grounds for storing a pool
of randomness on disk and trusting that that pool is unknown to the

@_date: 2013-11-13 20:44:37
@_author: James A. Donald 
@_subject: [Cryptography] [cryptography] Practical Threshold Signatures 
A pairing is a bilinear map.  The Weil pairing is a particular bilinear map on the points of certain elliptic curves that is useful for So, same thing, near enough.

@_date: 2013-11-15 15:01:46
@_author: James A. Donald 
@_subject: [Cryptography] Moving forward on improving HTTP's security 
The not quite good enough is the enemy of the adequate.
The problem with CAs is that Bob usually knows more about Carol that the CA knows about Bob or Carol.  Thus "trust" between Bob and Carol supplied by the CA tends to be inconvenient, expensive and unsafe.
Introducing a distant third party between Bob and Carol is a security hole, not a security solution.
The solution is yurls, Zooko's triangle, and, here comes the hard part, squaring Zooko's triangle.

@_date: 2013-11-15 16:02:44
@_author: James A. Donald 
@_subject: [Cryptography] Moving forward on improving HTTP's security 
With CT, when your browser hits a site, gets a certificate, it needs to check if the certificate is in a CT file, which is cryptographically secured to be the same for everyone.
But, if you have check each newly encountered certificate in real time, why does it need the CA's signature?  (Other than to avoid threatening the CA business model.)
The social mechanism underlying CT is:
1. not everyone is allowed to write to the CT files.  It is a valuable 2. the cryptographic properties of CT files make it easy to detect 3. Denying someone the right to make further writes to the CT files is not disruptive, whereas trying to delete a CA is immensely disruptive, thus the threat to withdraw the privilege to write to CT files for misbehavior is far more credible than the threat to take a CA off the browser CA list.
This being so, why should we care about CA signatures?  If a certificate is in the CT files, that is far more credible evidence of being a good certificate than if it is signed by a CA.  Let us allow all domain name registrars to write to the CT files, conditional, of course, on correct

@_date: 2013-11-23 13:07:07
@_author: James A. Donald 
@_subject: [Cryptography] Moving forward on improving HTTP's security 
Because powerful organizations wish to observe without being observed, a moderate chance of detection of active attacks is sufficient to deter, sufficient to reduce the number of active attacks to very low levels
The more powerful the adversary, and the less powerful you, the more valuable information about the adversary, and the less valuable information about you, therefore, the less attractive active attacks that suffer some risk of detection.
The more powerful the adversary, the less attractive active attacks are to that adversary.
Any organization powerful enough to perform active attacks on the wire, is apt to be powerful enough that observation of its attacks provides information about the organization that likely is of more value than the information obtained by the attack.

@_date: 2013-11-23 14:42:04
@_author: James A. Donald 
@_subject: [Cryptography] Dark Mail Alliance specs? 
But does anyone actually use S/MIME?
But the number of people actually using either system is very small. Looks to me that both systems have failed.

@_date: 2013-11-24 06:33:57
@_author: James A. Donald 
@_subject: [Cryptography] Dark Mail Alliance specs? 
Key management.
Need no-click key management.
Assume that secure email/IM addresses look like user
(Since we are breaking compatibility, we need to distinguish our addresses)
The user logs on to the mail transport agent at example.com using a zero knowledge password protocol.
This generates a transient shared secret between the client and the mail transport agent, which changes every logon, and also generates a durable client secret, which depends on a strong per client secret maintained by the mail transport agent and the user password.
If the user password is weak, whoever controls example.com can find it by dictionary attack, and thus find the durable client secret, but no one else can, except they first attack the mail transport agent on If the end user is exceptionally paranoid, he uses a strong password or makes sure he controls example.com
The durable client secret gives rise to a durable client public key, which is published by example.com.
The corresponding client secret key is recreated every logon, and, all being well, is known only to the client.

@_date: 2013-11-24 14:31:27
@_author: James A. Donald 
@_subject: [Cryptography] Dark Mail Alliance specs? 
You are worried we might have two widely adopted secure messaging systems, when at present we have zero widely adopted secure messaging

@_date: 2013-11-26 16:34:21
@_author: James A. Donald 
@_subject: [Cryptography] Email is unsecurable 
Why could not a forum like this one be a hidden web service, wherein one logs in with a zero knowledge password protocol.
The client could be written so that the user interaction remained the same as at present, even though the underlying protocol would be very Your client, whereby you interact with the forum, has a master password, and typically concocts per forum passwords on the fly, which is to say per mailing list passwords on the fly.
Usernames would have the form example$forum_name
Forum name would be non memorable, but the user would not typically need to type it, or even see it, merely click on it.  (Zooko's triangle)
Messages sent to the entire mailing list would default to public, that anyone could browse without necessarily creating a username and password, but more private non default forums would be possible - for example, that even messages sent to the entire mailing list default to private, and that in order to sign up, you need to send a request to the list that no existing member of the list blackballs.

@_date: 2013-11-26 17:09:34
@_author: James A. Donald 
@_subject: [Cryptography] Email is unsecurable 
By and large, businesses would love, love, very much love, a communication system in which information that could be used against them only existed on the computers of the sender and the recipient, and disappeared when deleted.
Naturally they would promise never to delete it if notified that it was subject to a lawsuit.

@_date: 2013-11-26 17:23:09
@_author: James A. Donald 
@_subject: [Cryptography] Explaining PK to grandma 
If Grandma needs to understand public key cryptography to use your product, not only is grandma not going to use it, but cryptographers are not going to use it either.
The barrier is not the complexity of understanding.  The barrier is in the complexity of use.
If you hide the complexity of use, then grandma does not need to understand.  If you expose the complexity of use, it is too painful to use even if she does understand.

@_date: 2013-11-27 12:15:20
@_author: James A. Donald 
@_subject: [Cryptography] Explaining PK to grandma 
People are still astonished that the from field is easily forgeable.  My sister is an intelligent woman, and still tends to trust the  from field, even though I showed her how I could easily send her emails with any from field that I liked.
We know in principle how implement email such that the from field works, at least to the extent that if it appears to come from example at example.com, that proves that the sender can receive, or intercept, mail sent to example at example.com.
Fixing email so that the from field works is easy.  It should have been done.  It would not stop phishing, but would put a big crimp in it.

@_date: 2013-11-27 12:38:01
@_author: James A. Donald 
@_subject: [Cryptography] Dark Mail Alliance specs? 
Imagine skype as originally designed, (central authority maps public and private keys to user names) plus a key continuity feature, plus the seldom used option of doing a zero knowledge shared passphrase to detect man in the middle.
The possibility that the zero knowledge check could be used would deter powerful adversaries, even if seldom used in practice.  The more powerful, the greater the deterrent effect.
It is not totally end to end, central authority can listen in, but the check would limit the amount of listening.
It can be made completely end to end for strong passwords.  Assume login is by zero knowledge password protocol, which means that the central authority does not know the end user's password, for strong passwords.
The secret key is generated from the strong secret supplied by central authority, plus the password.
When you change your password, you generate a certificate mapping your new public key to your old public key, which certificate makes other people's key continuity check happy.
If key continuity fails, people get a warning, but they don't have to click it away, for that just trains people to click it away.  They can just continue right on and not pay attention to it.
Or they could use the zero knowledge shared passphrase procedure to detect man in the middle.
So, if non paranoid, and using easy passwords, works like skype used to work.  No interception except by central authority, and central authority cannot intercept everyone, or even large numbers of people.
If paranoid and using strong passwords, provides OTR like end to end

@_date: 2013-11-27 12:44:17
@_author: James A. Donald 
@_subject: [Cryptography] Explaining PK to grandma 
Skype, as originally designed, is a good starting point.  Of course the ease of use comes from a central certificate authority, but that problem can be, if not cured, substantially mitigated.

@_date: 2013-11-28 14:19:57
@_author: James A. Donald 
@_subject: [Cryptography] Explaining PK to grandma 
If this works, I will have to retract what I have so frequently said about the dead weight of existing widely deployed protocols, and the incapacity of committees.
It is, however the umpteenth try to make spf and dkim actually useful, which is not a good sign.

@_date: 2013-11-28 14:32:35
@_author: James A. Donald 
@_subject: [Cryptography] Explaining PK to grandma 
For defending against NSA, we don't really have to prevent active attacks.  We merely have to make it reasonably feasible for the seriously sophisticated paranoid to have a chance of detecting active If very powerful adversary gets observed observing, it loses, since the information is valuable to its adversaries.
The guy in Nigeria, on the other hand, will have no hesitation in committing active attacks and will not much worry even if a very large proportion of them get detected.

@_date: 2013-10-01 18:46:15
@_author: James A. Donald 
@_subject: [Cryptography] encoding formats should not be committee'ized 
Protobufs is code generating code.  Not allowed by google style guide.

@_date: 2013-10-02 02:28:50
@_author: James A. Donald 
@_subject: [Cryptography] encoding formats should not be committee'ized 
The google style guide prohibits too-clever code.  protobufs and gmock is too-clever code.

@_date: 2013-10-02 07:16:28
@_author: James A. Donald 
@_subject: [Cryptography] encoding formats should not be committee'ized 
The google style guide, among other things, prohibits multiple direct inheritance and operator overloading, except where stl makes you do operator overloading.
Thus it certainly prohibits too-clever code.  The only debatable question is whether protobufs, and much of the rest of the old codebase, is too-clever code - and it certainly a lot more clever than operator Such prohibitions also would prohibit the standard template library, except that that is also grandfathered in, and prohibits atl and wtl.
The style guide is designed for an average and typical programmer who is not as smart as the early google programmers.   If you prohibit anything like wtl, you prohibit the best.
Prohibiting programmers from using multiple inheritance is like the BBC prohibiting the world "literally" instead of mandating that it be used correctly.  It implies that the BBC does not trust its speakers to understand the correct use of literally, and google does not trust its programmers to understand the correct use of multiple direct inheritance.

@_date: 2013-10-02 07:43:57
@_author: James A. Donald 
@_subject: [Cryptography] TLS2 
This is an inherent problem, not with ASN.1, but with any data representation that can represent arbitrary data.
The decoder should only be able to decode the data structure it expects, that its caller knows how to interpret, and intends to interpret.  Anything else should fail immediately.  Thus our decoder should have been compiled from, a data description, rather than being a general purpose decoder.
Thus sender and receiver should have to agree on the data structure for any communication to take place, which almost automatically gives us a highly compressed format.
Conversely, any highly compressed format will tend to require and assume a known data structure.
The problem is that we do not want, and should not have, the capacity to send a program an arbitrary data structure, for no one can write a program that can respond appropriately to an arbitrary data structure.

@_date: 2013-10-02 09:28:55
@_author: James A. Donald 
@_subject: [Cryptography] TLS2 
BER and DER can express an arbitrary data structure - and thus can crash the program receiving the data, probably causing it to execute transmitted data as code.
The same, however, is true of every overly general line format. Incoming data should be parsed as the expected and bounded size data structure, thus we need something that can generate parsing code from a description of the data at compile time.  We need compile time descriptions of the data, not run time descriptions, because the program that uses the incoming data will unavoidably rely on compile time description of the data.
PER, however cannot receive unexpected data structures.
Thus all data should be transmitted as PER, or by a format with the properties of PER.

@_date: 2013-10-02 16:13:00
@_author: James A. Donald 
@_subject: [Cryptography] TLS2 
I disagree slightly with langsec.
At compile time you want an extremely powerful language for describing data, that can describe any possible data structure.
At run time, you want the least possible power, such that your recognizer can only recognize the specified and expected data structure.
Thus BER and DER are bad for the reasons given by Langsec, indeed they illustrate the evils that langsec condemns, but these criticisms do not normally apply to PER, since for PER, the dangerously great power exists only at compile time, and you would have to work pretty hard to retain any substantial part of that dangerously great power at run time.

@_date: 2013-10-03 17:14:17
@_author: James A. Donald 
@_subject: [Cryptography] Crypto Standards v.s. Engineering habits - Was: 
The repeated failures of wifi are more crypto primitive failure, though underlying crypto primitives were abused in ways that exposed subtle

@_date: 2013-10-03 17:50:44
@_author: James A. Donald 
@_subject: [Cryptography] encoding formats should not be committee'ized 
That is because of the class of problems for which it is appropriate to use multiple inheritance.
Was it?   And regardless of whether that was the reason, not what it is used for today.
C++ greatly improves my productivity, in particular the memory management classes std::unique_ptr and std::shared_ptr, though if using them means you have to use std::weak_ptr, then one has to pause and think.

@_date: 2013-10-04 18:23:37
@_author: James A. Donald 
@_subject: [Cryptography] encoding formats should not be committee'ised 
That is fairly horrifying, as COM was designed for a single threaded environment, and becomes and incomprehensible and extraordinarily inefficient security hole in a multi threaded environment.

@_date: 2013-10-06 04:20:30
@_author: James A. Donald 
@_subject: [Cryptography] Sha3 
> theories and smearing reputations based on nothing other than hot air
But there really is a conspiracy, which requires us to consider conjectures as serious risks, and people deserve to have their reputations smeared for the appearance of being in bed with that conspiracy.

@_date: 2013-10-06 09:36:22
@_author: James A. Donald 
@_subject: [Cryptography] Crypto Standards v.s. Engineering habits - Was: 
I endorse it without qualification.  The IRG are bad guys and need killing - all of them, every single one.
War is an honorable profession, and is in our nature.  The lion does no wrong to kill the deer, and the warrior does no wrong to fight in a just war, for we are still killer apes.
The problem with the NSA and NIST is not that they are doing warlike things, but that they are doing warlike things against their own people.

@_date: 2013-10-07 07:43:53
@_author: James A. Donald 
@_subject: [Cryptography] Crypto Standards v.s. Engineering habits - Was: 
We are not exactly at peace with Iran either, but that is irrelevant, for presumably it was a Jew that did it, and Iran is at war with Jews.
(And they are none too keen on Christians, Bahais, or Zoroastrians either)
You may not be interested in war, but war is interested in you.   You can reasonably argue that we should not get involved in Israel's problems, but you should not complain about Israel getting involved in Israel's problems.
Had a democracy where if you opposed Mohammad Mosaddegh you got murdered by Islamists.
Which, of course differs only in degree from our democracy, where (to get back to some slight relevance to cryptography) Ladar Levison gets put out of business for defending the fourth Amendment, and Pax gets put on a government blacklist that requires him to be fired and prohibits his business from being funded for tweeting disapproval of affirmative action for women in tech.
And similarly, if Hitler's Germany was supposedly not a democracy, why then was Roosevelt's America supposedly a democracy?
I oppose democracy because it typically results from, and leads to, government efforts to control the thoughts of the people.  There is not a large difference between our government requiring Pax to be fired, and Mohammad Mosaddegh murdering Haj-Ali Razmara.  Democracy also frequently results in large scale population replacement and ethnic cleansing, as for example Detroit and the Ivory Coast, as more expensive voters get laid off and cheaper voters get imported.
Mohammed Moasddegh loved democracy because he was successful and effective in murdering his opponents, and the Shah was unwilling or unable to murder the Shah's opponents.
And our government loves democracy because it can blacklist Pax and destroy Levison.
If you want murder and blacklists, population replacement and ethnic cleansing, support democracy.  If you don't want murder and blacklists, should have supported the Shah.

@_date: 2013-10-09 06:14:49
@_author: James A. Donald 
@_subject: [Cryptography] Elliptic curve question 
Incorrect.  One's public key is always an elliptic point, one's private key is always a number.
Thus there is no reason in principle why one cannot use the same key (a number) for signing the messages you send, and decrypting the messages you receive.

@_date: 2013-10-09 10:31:07
@_author: James A. Donald 
@_subject: [Cryptography] Iran and murder 
Israel is famous for its competence in that area.
And if the US is famously incompetent, that is probably lack of will,
rather than lack of ability.  Drones give the US technological supremacy in
the selective removal of key people

@_date: 2013-10-12 13:09:37
@_author: James A. Donald 
@_subject: [Cryptography] Crypto Standards v.s. Engineering habits - Was: 
The problem is that layering creates round trips, and as cpus get ever faster, and pipes ever fatter, round trips become a bigger an bigger problem.  Legend has it that each additional round trip decreases usage of your web site by twenty percent, though I am unaware of any evidence on this.
TCP provides eight bits of protocol negotiation, which results in multiple layers of protocol negotiation on top.
Ideally, we should extend the protocol negotiation and do crypto negotiation at the same time.
But, I would like to see some research on how evil round trips really are.
I notice that bank web pages take an unholy long time to come up, probably because one secure we page loads another, and that then loads a script, etc.

@_date: 2013-10-19 14:11:17
@_author: James A. Donald 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
If an app expects urandom never to block, and itself blocks bootup, that app is broken, because it is doing something that requires or purports to provide cryptographic security, which it will not get.
The cure is to remove the app from the bootup process, rather than employ an app providing security theater.
The app will probably run fine if launched at a later stage in the process.  If not, needs rewriting.

@_date: 2013-10-20 06:25:56
@_author: James A. Donald 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
It will break things that should be broken, causing them to fail visibly, when previously they failed invisibly.
More aggressive entropy collection is not really a solution, since the total amount of entropy required is very small, and usually the supply of entropy is very large, and yet, cannot be treated as infinite.
Since cannot be treated as infinite, solution is to not treat it as

@_date: 2013-10-20 06:37:14
@_author: James A. Donald 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
It is too small for a short period after boot up.
Which is causing problems, in that we see significant key duplication and common factors.
And, after that short period, forever afterwards, ample.
Any system that needs crypto, communicates.  Any system that communicates, sees events whose details are difficult to predict for anyone not in physical possession of the system.
Solution:  Block for a short period after startup.  Possibly a small number of systems will freeze up and fail to boot.  This is almost always fixable by moving the blocking process in the bootup so that it no longer blocks other processes while it is blocked waiting for

@_date: 2013-10-20 11:10:22
@_author: James A. Donald 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
The completely broken system is fixable, usually trivially fixable, and once fixed, will stay fixed.
Maybe we need three sources of randomness: Ordinary random, never blocks, somewhat predictable.  Cryptographically random, blocks during boot up, unpredictable to adversaries.  True random.  Blocks frequently.  On some systems, with limited sources of randomness, may block a lot.  Truly unpredictable.

@_date: 2013-10-20 17:59:12
@_author: James A. Donald 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
The threat model is that we are seeing a lot of duplicate factors in keys, indicating a shortage of randomness, therefore, trying those common factors will crack a lot of keys.
This is plausibly suspected, but not proven, to be the result of bootup entropy shortage, that being a known bug.  We don't know, however, that this known bug is causing this known cryptographic weakness.

@_date: 2013-10-22 12:07:50
@_author: James A. Donald 
@_subject: [Cryptography] "Death Note" elimination for hashes 
> The vast majority - hundreds of millions - of Android devices out
 > there run versions of Android with known, sometimes severe, security
 > bugs.  They can't, and won't, be upgraded.  Is your best response
 > "well, brick 'em all"?
Because we cannot brick them all, they were made so that they could
not easily be updated, or could not be updated at all.
If there had been a credible threat to brick them all, they would
have been made so that they could easily and routinely be updated.

@_date: 2013-10-26 05:23:48
@_author: James A. Donald 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
> This gets back to the threat model discussion.  If your attacker is
 > watching you from the outside as you generate your key, then
 > interacting with stuff over the local net won't help you much.
 > (You may get a bit or two of entropy from the attacker not being
 > able to know exactly which clock-tick you were on when the interrupt
 > was serviced, but not much.).
It does not take very long to get 128 interrupts.

@_date: 2013-10-27 17:03:03
@_author: James A. Donald 
@_subject: [Cryptography] provisioning a seed for /dev/urandom 
Every interrupt should provide at least one bit of entropy.  There should be a lot more than 128 interrupts before the hypervisor gets running.
Thus, correctly programmed, the real urandom should have plenty of randomness to provide the virtual urandom, immediately a virtual machine is launched.
Of course, whether it actually is correctly programmed is another question.

@_date: 2013-10-28 13:03:48
@_author: James A. Donald 
@_subject: [Cryptography] provisioning a seed for /dev/urandom 
Unlikely that they are predictable to within one TSC cycle.
Particularly to someone who is not in physical possession of the system.
Booting up, it interacts with the network.  Network events are somewhat random.  Network events typically have millisecond variance, the TSC tens of thousands of times faster.
Further, when you measure the TSC against the clock, it tends to wander considerably, even though there is supposed to be zero variation.  So even within one CPU, clock skew will give you some entropy.  If the cpu is on a network, you are going to have a lot of skew, skew that would be hard to predict and control even if you instrumented the network.

@_date: 2013-10-30 19:22:19
@_author: James A. Donald 
@_subject: [Cryptography] My comments regarding using CPU jitter for 
The TSC is a very fast, not very accurate clock.
It is hard to build a very accurate clock.  The TSC does not need to be a very accurate clock.  Therefore it will never be a very accurate clock.
Therefore, even if the adversary has perfect knowledge of the exact details of every interrupt and the exact time of every interrupt, he will not know the exact TSC value of any interrupt.
Therefore every interrupt provides at least one bit of entropy.
Therefore, by the time you have finished any non trivial boot process, you have enough entropy.  The only problem is whether you delay all processes that need entropy far enough into the boot process.

@_date: 2013-10-31 06:32:52
@_author: James A. Donald 
@_subject: [Cryptography] [RNG] /dev/random initialisation 
To restate for the slow witted.
The prohibition against unauthorized sources of entropy indicates evil intent and evil deeds.
No source of entropy can ever be harmful. The worst that can happen is that it is entirely predictable to the adversary, in which case it does little good, but can never do harm.
Thus banning unauthorized sources of entropy is an obviously stupid move.
Unless, of course, you are the adversary, and expect all authorized sources of entropy to be predictable to yourself, but to no one else.

@_date: 2013-10-31 06:36:00
@_author: James A. Donald 
@_subject: [Cryptography] [RNG] /dev/random initialisation 
> "Never attribute to malice what can be explained by incompetence."
 > One of the really bad things about the NSA's apparent attempts to
 > subvert crypto is that it leads you to question this assertion.  We
 > just have no way of knowing.
Sure we do.  Committees are always stupid, unless they are under the
control of a small conspiratorial minority of evil people.  We have
many indicators that committees under the influence of NSA are smart.
Therefore evil.

@_date: 2013-09-02 12:35:05
@_author: James A. Donald 
@_subject: [Cryptography] NSA and cryptanalysis 
Do we know they produced fake windows updates without assistance from

@_date: 2013-09-06 22:24:32
@_author: James A. Donald 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
The mathematics of ECC is such that one would expect that curves with backdoors that are difficult to find, or impossible to find except through construction, exist.
Therefore, one should never employ a particular curve recommended by NSA, but rather a random or arbitrary curve.

@_date: 2013-09-08 11:30:41
@_author: James A. Donald 
@_subject: [Cryptography] Bruce Schneier has gotten seriously spooked 
Schneier cannot show that they are trapdoored, because he does not know where the magic numbers come from.
To know if trapdoored, have to know where those magic numbers come from.

@_date: 2013-09-09 13:42:36
@_author: James A. Donald 
@_subject: [Cryptography] Techniques for malevolent crypto hardware 
Real world experience is that there is nothing to worry about /if you do it right/.  And that it is frequently not done right.
When you screw up AES or such, your test vectors fail, your unit test fails, so you fix it, whereas if you screw up entropy, everything appears to work fine.
It is hard, perhaps impossible, to have test suite that makes sure that your entropy collection works.
One can, however, have a test suite that ascertains that on any two runs of the program, most items collected for entropy are different except for those that are expected to be the same, and that on any run, any item collected for entropy does make a difference.
Does your unit test check your entropy collection?

@_date: 2013-09-09 10:37:47
@_author: James A. Donald 
@_subject: [Cryptography] Impossible trapdoor systems (was Re: Opening 
Suppose that the mappings from 2^N plaintexts to 2^N ciphertexts are not random, but rather orderly, so that given one element of the map, one can predict all the other elements of the map.
Suppose, for example the effect of encryption was to map a 128 bit block to a group, map the key to the group, add the key to the block, and map back.  To someone who knows the group and the mapping, merely a heavily obfuscated 128 bit Caesar cipher.
No magic key.

@_date: 2013-09-09 10:48:51
@_author: James A. Donald 
@_subject: [Cryptography] Market demands for security (was Re: Opening 
Poor analogy.
Everyone is a racist, and most people lie about it.
Everyone is a communist in the sense of being unduly influenced by Marxist ideas, and those few of us that know it have to make a conscious effort to see the world straight, to recollect that some of our supposed knowledge of the world has been contaminated by widespread falsehood.
The Climategate files revealed that official science /is/ in large part a big conspiracy against the truth.
And Snowden's files seem to indicate that all relevant groups are infiltrated by people hostile to security.

@_date: 2013-09-10 08:37:31
@_author: James A. Donald 
@_subject: [Cryptography] [cryptography] Random number generation 
>> would you care to explain the very strange design decision
 >> to whiten the numbers on chip, and not provide direct
 >> access to the raw unwhitened output.
 >  So that that state remains secret from things trying to
 > discern that state for purposes of predicting past or
 > future outputs of the DRBG.
This assumes the DRGB is on chip, which it should not be.  It
should be in sofware.  Your argument is circular.  You are
arguing that the DRGB should be on chip, because it is on
chip, that is has some of its menacing characteristics
because it has other menacing characteristics.
 >  So that one thread cannot undermine a second thread by
 > putting the DRNG into a broken mode. There is only one
 > DRNG, not one per core or one per thread. Having one DRNG
 > per thread would be one of the many preconditions necessary
 > before this could be contemplated.
You repeat yourself.  Same circular argument repeated.
 >  Any method of access is going have to be documented and
 > supported and maintained as a constant interface across
 > many generations of chip.
Why then throw in RDSEED?
You are already adding RDSEED to RDRAND, which which fails to
address any of the complaints.  Why provide a DRNG in the
first place.
Answer:  It is a NIST design, not an Intel design.  Your design
documents reference NIST specifications. And we
already know that NIST designs are done with hostile intent.

@_date: 2013-09-10 14:38:55
@_author: James A. Donald 
@_subject: [Cryptography] Squaring Zooko's triangle 
1.  And they run away screaming.
2.  It only takes 2^50 trials to come up with a valid fingerprint that agrees with your fingerprint except at four non chosen places.

@_date: 2013-09-11 09:04:56
@_author: James A. Donald 
@_subject: [Cryptography] Random number generation influenced, HW RNG 
Let us consider that source of colored noise with which we are most familiar:  The human voice.  Efforts to realistically simulate a human voice have not been very successful.  The most successful approach has been the ransom note approach, merging together a lot of small clips of an actual human voice.
A software simulated raw physical noise source would have to run hundreds of thousands times faster.

@_date: 2013-09-11 09:38:38
@_author: James A. Donald 
@_subject: [Cryptography] Usage models (was Re: In the face of 
> I wrote about this a couple of weeks ago, see:
 >
 > In short, https to a server that you /do/ trust.
Problem is, joe average is not going to set up his own server. Making setting up your own server user friendly is the same problem as making OTR user friendly, with knobs on.

@_date: 2013-09-12 09:35:08
@_author: James A. Donald 
@_subject: [Cryptography] Random number generation influenced, HW RNG 
The circuit allegedly used in the Intel chip will produce a signal substantially more complex than that.
Indeed any noise circuit, even one based on shot noise or Johnson noise has numerous analog aspects that will alter the color of the noise, just as the human voice is more than just a vibrating vocal cord.
And this color will change from one chip to the next, will change with temperature, will change with overclocking.  Where does the digital simulation get a true on chip clock to know that its overclocking is being changed on it?

@_date: 2013-09-29 12:42:32
@_author: James A. Donald 
@_subject: [Cryptography] RSA equivalent key length/strength 
In fact we do know this.
NSA NIST claimed that their EC curves are provably random (therefore not In fact, they are provably non random, selected on an unrevealed basis, which contradiction is, under the circumstances, compelling evidence that the NIST curves are in fact backdoored.

@_date: 2013-09-29 15:29:26
@_author: James A. Donald 
@_subject: [Cryptography] RSA recommends against use of its own products. 
We have a compiler that generates C code from ASN.1 code.  Does it not generate code behind the scenes that does all this ugly stuff for us without us having to look at the code?
I have not actually used the compiler, and I have discovered that hand generating code to handle ASN.1 data structures is a very bad idea, but I am told that if I use the compiler, all will be rainbows and unicorns.
You go first.

@_date: 2013-09-30 09:54:32
@_author: James A. Donald 
@_subject: [Cryptography] RSA equivalent key length/strength 
The NIST ec curves are provably non random, and one can prove that NIST is lying about them, which is circumstantial but compelling evidence that they are backdoored:
    From: mailto:gmaxwell at gmail.com (Gregory Maxwell )
    To: "This mailing list is for all discussion about theory, design, and development of Onion Routing."
    Subject: Re: [tor-talk] NIST approved crypto in Tor?
    Reply-To:tor-talk at lists.torproject.org      On Sat, Sep 7, 2013 at 4:08 PM, anonymous coward
            Bruce Schneier recommends **not** to use ECC. It is safe to
            assume he knows what he says.
        I believe Schneier was being careless there. The ECC parameter
        sets commonly used on the internet (the NIST P-xxxr ones) were
        chosen using a published deterministically randomized procedure.
        I think the notion that these parameters could have been
        maliciously selected is a remarkable claim which demands
        remarkable evidence.
    Okay, I need to eat my words here.
    I went to review the deterministic procedure because I wanted to see
    if I could repoduce the SECP256k1 curve we use in Bitcoin. They
    don?t give a procedure for the Koblitz curves, but they have far
    less design freedom than the non-koblitz so I thought perhaps I?d
    stumble into it with the ?most obvious? procedure.
    The deterministic procedure basically computes SHA1 on some seed and
    uses it to assign the parameters then checks the curve order, etc..
    wash rinse repeat.
    Then I looked at the random seed values for the P-xxxr curves. For
    example, P-256r?s seed is c49d360886e704936a6678e1139d26b7819f7e90.
    _No_ justification is given for that value. The stated purpose of
    the ?veritably random? procedure ?ensures that the parameters cannot
    be predetermined. The parameters are therefore extremely unlikely to
    be susceptible to future special-purpose attacks, and no trapdoors
    can have been placed in the parameters during their generation?.
    Considering the stated purpose I would have expected the seed to be
    some small value like ? ?6F? and for all smaller values to fail the
    test. Anything else would have suggested that they tested a large
    number of values, and thus the parameters could embody any
    undisclosed mathematical characteristic whos rareness is only
    bounded by how many times they could run sha1 and test.
    I now personally consider this to be smoking evidence that the
    parameters are cooked. Maybe they were only cooked in ways that make
    them stronger? Maybe????
    SECG also makes a somewhat curious remark:
    ?The elliptic curve domain parameters over (primes) supplied at each
    security level typically consist of examples of two different types
    of parameters ? one type being parameters associated with a Koblitz
    curve and the other type being parameters chosen verifiably at
    random ? although only verifiably random parameters are supplied at
    export strength and at extremely high strength.?
    The fact that only ?verifiably random? are given for export strength
    would seem to make more sense if you cynically read ?verifiably
    random? as backdoored to all heck. (though it could be more
    innocently explained that the performance improvements of Koblitz
    wasn?t so important there, and/or they considered those curves weak
    enough to not bother with the extra effort required to produce the
    Koblitz curves).

@_date: 2013-09-30 10:07:14
@_author: James A. Donald 
@_subject: [Cryptography] RSA equivalent key length/strength 
Gregory Maxwell on the Tor-talk list has found that NIST approved curves, which is to say NSA approved curves, were not generated by the claimed procedure, which is a very strong indication that if you use NIST curves in your cryptography, NSA can read your encrypted data.
As computing power increases, NSA resistant RSA key have become inconveniently large, so have to move to EC keys.
NIST approved curves are unlikely to be NSA resistant.
Therefore, everyone should use Curve25519, which we have every reason to believe is unbreakable.

@_date: 2013-09-30 14:28:12
@_author: James A. Donald 
@_subject: [Cryptography] RSA recommends against use of its own products. 
DER is unintelligble and incomprehensible.  There is, however, an open source complier for ASN.1
Does it not produce correct encoders and decoders for DER?  (I have never used it)

@_date: 2013-09-30 17:45:52
@_author: James A. Donald 
@_subject: [Cryptography] NIST about to weaken SHA3? 
SHA3 has been drastically weakened from the proposal that was submitted and cryptanalyzed:  See for example slides 43 and 44 of

@_date: 2013-10-01 07:21:03
@_author: James A. Donald 
@_subject: [Cryptography] NIST about to weaken SHA3? 
"less conservative" means weaker.
Weaker in ways that the NSA has examined, and the people that chose the winning design have not.
Why then hold a contest and invite outside scrutiny in the first place.?
This is simply a brand new unexplained secret design emerging from the bowels of the NSA, which already gave us a variety of backdoored crypto.
The design process, the contest, the public examination, was a lie.
Therefore, the design is a lie.

@_date: 2013-10-01 07:27:50
@_author: James A. Donald 
@_subject: [Cryptography] TLS2 
Granted that ASN.1 is incomprehensible and horrid, but, since there is an ASN.1 compiler that generates C code we should not need to comprehend it.
PGP web of trust does not scale.

@_date: 2013-10-01 10:00:40
@_author: James A. Donald 
@_subject: [Cryptography] RSA equivalent key length/strength 
And a non NIST person verified that the curves were /not/ generated by the described process after the scandal broke.
The process that actually generates the curves looks like the end result of trying a trillion curves, until you hit one that has desirable properties, which desirable properties you are disinclined to tell anyone else.

@_date: 2013-10-01 10:04:25
@_author: James A. Donald 
@_subject: [Cryptography] RSA equivalent key length/strength 
The claimed procedure would have prevented the NSA from generating lots of curves till they found a bad one - one with weaknesses that the NSA knows how to detect, but which other people do not yet know how to detect.
That was the whole point of the claimed procedure.
As with SHA3, the NSA/NIST is deviating from its supposed procedures in ways that remove the security properties of those procedures.

@_date: 2013-10-01 10:10:15
@_author: James A. Donald 
@_subject: [Cryptography] encoding formats should not be committee'ized 
We have a complie to generate C code from ASN.1 code
Google has a compiler to generate C code from protobufs source
The ASN.1 compiler is open source.  Google's compiler is not.
Further, google is unhappy that too-clever-code gives too-clever programmers too much power, and has prohibited its employees from ever doing something like protobufs again.

@_date: 2013-10-01 11:07:00
@_author: James A. Donald 
@_subject: [Cryptography] NIST about to weaken SHA3? 
This is not Keccak's design.
This a new unexamined design somewhat resembling Keccak's design.
Or perhaps Keccak's design somewhat resembled what the NSA had already decided to do.

@_date: 2013-10-01 11:10:04
@_author: James A. Donald 
@_subject: [Cryptography] NIST about to weaken SHA3? 
All big conspiracies get exposed - I would make a list, but that would derail the conversation.
It does not follow that there are no big powerful conspiracies.  On the contrary, we have compelling evidence of more big powerful conspiracies than one can shake a stick at.

@_date: 2013-10-01 11:15:47
@_author: James A. Donald 
@_subject: [Cryptography] Sha3 
If you want to understand what is going on with SHA3, and you believe that NIST is frank, open, honest, and has no ulterior motives, you might want to look at the NIST website.

@_date: 2014-08-11 08:27:43
@_author: James A. Donald 
@_subject: [Cryptography] The role of the IETF in security of the 
the net?
This is a deception.
And the falsity of this deception becomes obvious when the IETF obstinately does something particularly stupid or evil.

@_date: 2014-08-11 15:40:06
@_author: James A. Donald 
@_subject: [Cryptography] The role of the IETF in security of the 
the net?
The way the IETF works is:
A predetermined decision is announced.
Various people on the mailing lists point out this is quite obviously a bad idea.
Various sock puppets on the mailing list repetitiously endorse the predetermined position and assert that objections to the decision are out of scope, as if totally deaf.
After a while the predetermined decision is proclaimed to be the consensus, even if it obviously is not.
Joining the mailing list is revealed to be a complete waste of time.

@_date: 2014-08-26 19:45:21
@_author: James A. Donald 
@_subject: [Cryptography] phishing, was Encryption opinion 
Alice intends to submit her password to Bob.  Instead she submits it to Mallory, who submits it to Bob.
Sure sounds like Mallory is in the middle.

@_date: 2014-08-26 19:57:02
@_author: James A. Donald 
@_subject: [Cryptography] Encryption opinion 
These all involve Alice communicating with Mallory when she thinks she is communicating with Bob, and then Mallory communicates with Bob pretending to be Alice.
Mallory is still in the middle.

@_date: 2014-08-29 14:08:15
@_author: James A. Donald 
@_subject: [Cryptography] Encryption opinion 
MITM phishing can be solved by a zero knowledge password proof operated by a UI element that cannot easily be faked up by browser html.
That is a protocol.
Even if they proclaim the UI element out of IETF scope, the zero knowledge password proof should be in scope.

@_date: 2014-08-29 18:24:46
@_author: James A. Donald 
@_subject: [Cryptography] Phishing and other abuse issues [Was: Re: 
> Iang calls that a MITM attack. IMHO, that's a poor choice of words,
 > because 99.9% of the community will use MITM to designate a
 > potential attack that inserts a hacker between Alice and
 >  or even between Alice and
 >  But the problem is real, and is
 > worth addressing.
Your 99.9% figure comes from where?
I use MITM the way Iang does, because when the phisher is after your
password, he intends to be in the middle.  Ann wants to talk with Bob.
Malloc represents himself as Bob to Ann, and as Ann to Bob.
It is one the classic problems of cryptography, and the name for the
problem is man in the middle.  What else would you call it?
A phisher might want install adware on your computer, might claim to wish to give you a million dollars of stolen money in order to get you to pay bogus transaction fees, but when the phisher wants your credentials, that is the standard well known problem, man in the middle, for which we need protocol solutions, and in theory have protocol solutions.

@_date: 2014-09-01 13:39:05
@_author: James A. Donald 
@_subject: [Cryptography] Encryption opinion 
============================== START ==============================
Here is how browsers and servers should work, in order to prevent MITM
This looks like a job for the IETF.  Why is it out of scope?
When the browser attempts to connect to a password protected page, the server demands the creation of a strong transient shared secret through a Zero Knowledge Password Protocol, and a UI is popped up from the browser chrome, not from a server web page, to establish that shared secret.  The UI shows the "username" of the server, and the username of the client, since the Zero Knowledge protocol is almost symmetric, both parties having to prove knowledge of a secret passphrase associated with the username/servername pair, without revealing the secret passphrase.
The strong transient shared secret being established from proof of possession of a weak durable shared secret, the server calls the code that generates the web page with a database cursor pointing at the database record that contains the username and hash of the password that was used to establish the shared secret.
On all subsequent interactions on the channel created by this shared secret, the web page is generated by code that has access to this database cursor.  The shared secret will be forgotten on a timeout that is set and reset by this code.
Again:  This looks like a job for the IETF.  Why is it out of scope?

@_date: 2014-02-02 07:58:58
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
Underneath all that are real material disk drives, which have turbulence.  The turbulence causes random and entirely unpredictable timing variations, which unpredictability and variation propagate all the way to the VM
You don't need direct access to the real device.  The the real turbulence in the real device causes random variation in the time that your buffer gets filled.   So just hash the cpu clock into your stockpile of randomness every time that you read data that is likely to need to come from disk.  And then your VM is reading real randomness from real turbulence on the real disk.

@_date: 2014-02-02 14:02:15
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
But there are not.
To introduce a quantization error in timing, would need to delay in an idle loop until the counter reached a round number. This slows stuff down for no good reason.
Just as to suppress thermal noise in a microphone input reduces sound quality for no good reason.
 > Consider what might happen if the VMs are being scheduled by the host OS
 > with a scheduling quantum measured in 10's of milliseconds
Your VM is scheduled.  It attempts to read something from disk. That part of the disk has not yet been read into memory and cached. Your VM immediately gets idled.  Another VM gets woken from idle.
Disk read completes at a time that depends on disk turbulence.  The real machine now has to do something with the data.  Letting it pile up to the next scheduling quantum is going to result in the disk head passing over the next disk sector, resulting in a painfully slow read.  So, unless your real machine is crazy inefficient, it is going to immediately wake the consumer of the data at a time that depends on disk turbulence, in the hope that it can read sectors sequentially as the platter spins.

@_date: 2014-02-02 16:25:32
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
The only efficient way to organize the system is for process switches to be triggered by the arrival of data.  Fail to do that, you wind up reading one sector per platter rotation.  If you want to read sectors as the platter rotates, you have to do process switch on disk event, not timer event.
If you do that, switch process on disk event, rather than the timer event, process switches will occur at times dictated by disk drive turbulence when a process is reading data.
Disk drive turbulence is true random and unpredictable to an adversary,

@_date: 2014-02-02 16:31:10
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
The hypervisor is going to switch a process out when it wants data that is not yet available, rather than switching it on a clock.
If it switches a process in when data is available, rather than switching on a clock, turbulence is going to show up, even if that disk is on a network on the other side of the data center.

@_date: 2014-02-02 22:12:01
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
No they do not
The proposed "evidence" is that hypervisors "might" switch processes on the basis of a clock, rather than the availability of data.
No one has presented evidence that hypervisors do this and it does not seem a very efficient way of doing things.

@_date: 2014-02-02 22:29:09
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
The only thing that could eliminate such variations is a process switch on a low frequency timer, rather than the availability of data.  All the other added complications, all the layers, all the virtualization, other than switch on a low frequency time, will merely add more random variation, rather than subtract existing variation
Now, if at any stage in the process, there was switching on a low frequency time, it would show up, in that timing values on disk limited processes would be exact multiples of that timer.
Which they are not.

@_date: 2014-02-02 22:50:33
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
If all these layers make the timing of data arrival more predictable, rather than less predictable, then, if predictable, should show some simple, rather obvious, pattern.
Which it does not.
If randomness is suppressed due to engineering efforts to make things simple and predictable, then the result should be simple and predictable.
Which it is not.
To suppress timing randomness, you need to gate events to a low frequency clock in one layer or another.   A low frequency clock period is not commonly apparent.
It does not matter how many layers there are between the virtual and the real.  If none of them gate events to a low frequency clock, the additional layers will only add randomness and reduce predictability.
Now if you were proposing that the NSA was generating fake randomness, then the fact that things look random would be unconvincing, but since we have an underlying physically random process, then if something orderly is suppressing this randomness, the outcome would be orderly.

@_date: 2014-02-03 04:08:08
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
OK then,  In the case that the real machine is CPU bound, and not IO bound or cache thrashing, then you will not see turbulence randomness at the VM level.
However, when starting up a new program, you generally are IO bound, though by no means guaranteed to be IO bound.

@_date: 2014-02-03 04:32:38
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
randomness is not "brittle", it is pretty robust and hard to get rid of.
If you have a complex system that contains a true random component, the entire system will usually to have true random behavior, with the complexity adding pseudo randomness to the true randomness.
If one level of the system is cpu bound and switching on the clock, not on IO, then yes, that will suppress turbulence based randomness, but:
if you are cpu bound, then you will still get timing randomness, not from turbulence, but because of the many things that all the other processes are doing and clock skew between the various levels of the system.

@_date: 2014-02-03 08:54:23
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
We only need 128 bits of entropy, every now and then.  We are not going the be cpu bound all the time, and we are certainly not going to be cpu bound when the system is first turned on.
And if we are cpu bound all the time, there will still be timing randomness because all the other vms are dealing with things in the real world that are random and unpredictable.

@_date: 2014-02-03 12:38:40
@_author: James A. Donald 
@_subject: [Cryptography] Now it's personal -- Belgian cryptographer 
Short of the fall of the US government, we are not in position to hang them
The alternative, is simply to distrust them and everything they have touched, to assume that any *software* that they have a finger in is guilty until proven innocent, that every committee that they have a member on is trying impose broken standards, and or prevent workable

@_date: 2014-02-04 08:44:51
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
The normal case of replicating an up and running VM is scalable cloud service, where one increases machines to meet demand or decrease machines to save money.  In such case, they will all have the same keys as the original, which keys you generated long after booting up the If we have an image of an up and running machine, which we clone using copy on write, how does it know to set up new keys?  There has to be a command "generate new identity".  When telling the cloned image to generate new keys, give it some randomness.   I don't think this case arises in practice
If we have an image of a bootable disk, cloning is going to be IO bound, and timing of events will contain the inherent randomness of the physical processes involved in getting the data.

@_date: 2014-02-04 08:54:42
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
We don't actually know this.  By and large, the added complexity provides added sources of random variation and unpredictability, rather than suppressing existing random variation and complexity.
The case where turbulence induced timing variation would be lost is a system that is fully cpu bound, and not IO bound.  In such case, cache hits and cache misses would depend on what all the other processes are doing, which other processes are themselves dealing with things out there, that have random variation, thus, random variation in cache hits and cache misses, resulting timing variation dependent on all the real external things that all the other processes have to deal with.
We can only measure turbulence randomness in a very simple, very controlled system /because in a realistic system, there are a lot of other sources of randomness/.

@_date: 2014-02-04 09:05:10
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
They made everything artificially simple - because otherwise there are so many sources of timing randomness that you could not distinguish the turbulence induced timing randomness.
If you look at timing in a complex system, it looks random.
To conclude that something that looks random truly is random, you have to understand and measure the underlying causes of randomness.
To isolate and identify /one/ such source of randomness, required them to artificially constrain the system in a way that was not realistic, nor intended to be realistic.
So their argument, in essence was that when they took all these extremely drastic measures to make timing of events predictable, timing of events was /still/ not predictable due to underlying physical processes.
 From which we may confidently conclude that in more complex situations, timing will be less predictable, not more predictable, because we have more sources of randomness, many  poorly characterized sources of randomness interacting with other sources of randomness, /one/ of which is well characterized.

@_date: 2014-02-04 09:11:05
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
Well I looked at the timing data on a few systems for the crypto Kong randomness collector, and they passed the eyeball test.  Looked like there was a shitload[1] of entropy there
[1] a shitload being several pooploads.

@_date: 2014-02-04 09:31:09
@_author: James A. Donald 
@_subject: [Cryptography] request for consideration: VM guest entropy: 
On the physical machine, all the philosophical problems about real randomness go away, so the ring 0 layer can collect a 160 bits of true randomness, and be pretty sure it really has collected 160 bits of real randomness.  The physical machine has true access to physical things, which are unarguably truly random.
It can then emulate the rdrand instruction and provide pseudo random data from a seed unknowable to the attacker, which is, for a sufficient seed, sufficiently inaccessible to the attacker, as good as true random.
So such an emulated rdrand instruction would be wonderful, would end all this debate.

@_date: 2014-02-05 13:28:23
@_author: James A. Donald 
@_subject: [Cryptography] Random numbers only once 
If the opponent got a look at your disk, he probably got a look at the private key for your public certificate, and your long lived SSH keys, in which case generating randomness is the least of your worries.

@_date: 2014-02-06 18:17:31
@_author: James A. Donald 
@_subject: [Cryptography] Random numbers only once 
If not blocking, every install needs some randomness supplied on disk, at least sixteen bytes, thirty two to be on the safe side. During normal usage, that little bit of randomness on disk slowly has some true randomness added, perhaps only sixteen bytes a day. There can be no system that does not have that much unpredictability available.

@_date: 2014-02-16 11:21:33
@_author: James A. Donald 
@_subject: [Cryptography] Another Bitcoin issue (maybe) 
Back in the beginning, I said, scaling problems.
Eventually only banks will handle the full blockchain, and they may not always have their customer's best interests at heart.
Really we need a system in which there is globally one true blockchain, but each person locally stores only part of it, which however makes the Byzantine Generals problem considerably harder.

@_date: 2014-02-17 09:03:37
@_author: James A. Donald 
@_subject: [Cryptography] BitCoin bug reported 
Surely unaligned ASN.1 CANONICAL-PER is fine, for the things that will be parsed are defined at compile time, limiting run time complexity. One cannot send a structure that the recipient has not been compiled to

@_date: 2014-02-17 21:40:09
@_author: James A. Donald 
@_subject: [Cryptography] BitCoin bug reported 
One is not able to express arbitrary structures in unaligned  ASN.1 CANONICAL PER.

@_date: 2014-03-01 13:47:45
@_author: James A. Donald 
@_subject: [Cryptography] The GOTO Squirrel! [was GOTO Considered Harmful] 
> The Apple defect was introduced when code was being patched to
 > change the signature of some of the functions being called.  This
 > strikes me as a classic lapse about not testing what is thought to
 > be obvious, although I have no idea what the actual scenario was.
This is why code that ships and undergoes maintenance by numerous
successive programmers needs unit test.   You put in the unit tests
not because you need them, but to communicate your vision to the
umpteen programmers that follow.

@_date: 2014-01-06 01:34:45
@_author: James A. Donald 
@_subject: [Cryptography] defaults, black boxes, APIs, 
Despite being open source, OpenBSD audits most of its code.
Audit is the only way to find remote holes, since remote hole attacks consist of specially crafted abnormal data, hence will not show up in ordinary testing.

@_date: 2014-01-08 18:13:53
@_author: James A. Donald 
@_subject: [Cryptography] defaults, black boxes, APIs, 
> We regularly sacrifice security on the alter of efficiency - see the
 > C++ STL and its approach to iterators.  (I wrote about this years
 > ago:  C++ fixed the gets and sprintf problems long ago, and for the most
part it has automated memory management.
To mitigate the iterator problem, needs "for each"
VC 2008 has a non standard, non portable, "for each" command.
The  C++11 standard uses "for" to do the same thing.
for (auto x : v) {/*do something with all x in v*/}
for (auto& x : v) {/*do something to all x in v*/}
Then there is the std::for_each with its infamously user hostile
syntax.  Requires the lambda calculus to be useful, which is only
available in C++11

@_date: 2014-01-09 08:00:04
@_author: James A. Donald 
@_subject: [Cryptography] What is an attack, and what is not an attack? 
> I think you're headed toward a lower bound estimate of what the
 > real-world attacks look like, but we also need to consider likely
 > and possible attacks.  For example, we have years of results on
 > all-electronic voting machines that show that they generally have
 > Swiss cheese like security, but I am not aware of any documented
 > election fraud in the US
There is obvious massive election fraud in the US, for example the
highly improbable turnout in presidential elections in certain areas
of swing states, but there is no "documented" fraud because the fraud
is always done in areas where the police, judges, and elected
officials are of the benefiting party.

@_date: 2014-01-13 07:51:34
@_author: James A. Donald 
@_subject: [Cryptography] defaults, black boxes, APIs, 
Due to scaling problems, bitcoin is increasingly dominated by a rather small group.  This is likely to have bad consequences - but as yet, still working.

@_date: 2014-01-14 07:12:25
@_author: James A. Donald 
@_subject: [Cryptography] Dual_EC_DRBG backdoor: a proof of concept 
Back in the seventies, every communist faction was infiltrating every other faction, including every other communist faction.  Every communist faction was on the alert, and willing to use all means including murder and torture to prevent infiltration, and yet the problem was not remedied.
If the NSA targets committees, they are likely to succeed, even if members of the committee are on the alert
Hence I recommend unelected presidents for life, and God Kings.
If everyone decides to follow one man, that man's preferred algorithms will be adequately examined.
Let us follow Jon Callas as unelected president for life of symmetric cryptography, Daniel Bernstein as God King of asymmetric cryptography.
Committees barely work even when not under hostile infiltration.

@_date: 2014-01-14 16:40:10
@_author: James A. Donald 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference boycott 
If you associate your product with RSA, you associate your product with the NSA, which is unlikely to be good for the sales of your product.

@_date: 2014-01-15 09:02:26
@_author: James A. Donald 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference boycott 
> The RSA Conference has always been two things:  A technical
 > conference on crypto, and a place to sell crypto wares.  At most, a
 > boycott will kill the first.  The guys buying and selling won't care
 > much.  They aren't the ones going to the technical talks.
You cannot sell crypto with NSA inside.  So if anything, it is the
other way around.  The selling crypto wares part will die.

@_date: 2014-01-15 09:27:08
@_author: James A. Donald 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference boycott 
> IETF WGs are  mailing lists to which anyone can contribute, quite
 > like this one,  but with some more structure because they exist to
 > produce output.  But the IETF is far from perfect of course.
 >
 > Anyway, if you want to change the IETF then you can do that simply
 > by being involved.
No you cannot.
Been there, done that.
If the IETF was genuinely open to everyone, they would be even more
disfunctional than they are already.

@_date: 2014-01-15 09:28:56
@_author: James A. Donald 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference  boycott 
> Does anyone really believe RSA is alone in this "betrayal?"
This is the argument that everyone is doing it, therefore let us go
right on doing it.
Supposing that everyone is doing it, everyone has to stop, and conduct
their affairs in a way that shows other people that they have stopped.

@_date: 2014-01-16 14:30:51
@_author: James A. Donald 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference boycott 
> The IETF cannot be presented with a position paper describing the
 > problem because the IETF is part of the problem, and nobody wants to
 > hear it who has already taken the investment to participate.
What he said!
Opportunistic encryption everywhere would force attackers to use
active attacks.  Active attacks can be detected.  Large powerful
organizations are likely to be reluctant to use active attacks too
widely, because they do not want their activities to be observed.  The
more powerful the organization, the more valuable information about
that organization is to its enemies, thus the more costly are active
Thus, if opportunistic encryption everywhere, the NSA would likely
limit itself to active attacks on people named Mohammed.

@_date: 2014-01-18 04:27:53
@_author: James A. Donald 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference boycott 
Because Skype is not sponsoring a crypto conference.  If it was, would surely be boycotted.

@_date: 2014-01-18 18:00:14
@_author: James A. Donald 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference boycott 
> 3. If I were working for NSA tasked with with disrupting the
 > independent cryptographic community's response to the Snowdon
 > revelations, I'd be hard pressed to come up with a better idea than
 > a boycott of the RSA conference.
Seems to me that the independent cryptographic community's response to
the Snowdon revelations is Jon Callas and Daniel Bernstein.  How does
boycotting RSA adversely affect them and what they are doing?

@_date: 2014-01-19 11:04:47
@_author: James A. Donald 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference 	boycott 
> > > 3. If I were working for NSA tasked with with disrupting the
 > > > independent cryptographic community's response to the Snowdon
 > > > revelations, I'd be hard pressed to come up with a better idea
 > > > than a boycott of the RSA conference.
James A. Donald:
 > > Seems to me that the independent cryptographic community's
 > > response to the Snowdon revelations is Jon Callas and Daniel
 > > Bernstein.  How does boycotting RSA adversely affect them and what
 > > they are doing?
 > So Jon and Daniel have it all taken care of? We can just relax, and
 > their admirable work, which solves all known and still undiscovered
 > problems
If it does not adversely affect Jon and Daniel, unlikely to adversely
affect anyone who is working to make his customers and users secure,
rather working to supply the NSA with information on his customers and

@_date: 2014-01-20 12:54:47
@_author: James A. Donald 
@_subject: [Cryptography] Conferences, committees, compliance 
> If new cryptography is going to have any chance roll back the mass
 > surveillance state, it will have to make its way into commercial
 > use.
IETF committees are owned by the surveillance state.  Have to be
Your argument amounts to saying that only NSA approved software is
going to get broad acceptance.  I think more likely the other way

@_date: 2014-01-21 00:37:13
@_author: James A. Donald 
@_subject: [Cryptography] Conferences, committees, compliance 
>> Your argument amounts to saying that only NSA approved software is
 >> going to get broad acceptance.  I think more likely the other way
 >> around.
 > You may be right, but perhaps others see things differently.
 > Shouldn't they be encouraged to try?
If playing ball with RSA and EITF, probably planning to sell out
customers and users to NSA.

@_date: 2014-01-21 15:45:45
@_author: James A. Donald 
@_subject: [Cryptography] Fwd: [IP] RSA Response to Media Claims Regarding 
> However, I am pretty damned skeptical about how many US companies
 > will manage to resist a decade-long multi-million-dollar
 > intelligence operation run against them by their own government.
Probably none, in which case we should rely on Chinese companies.

@_date: 2014-01-22 11:56:23
@_author: James A. Donald 
@_subject: [Cryptography] Does PGP use sign-then-encrypt or 
Since one does not want contact tracing, why make it easier by exposing your durable public key on the outside?
Append your durable public key to message plaintext, or append an identifier from which your public key can be located.  Mac the plaintext message with a shared secret created from your durable secret key and the recipient's durable public key.  (This form of signing proves to the recipient that a person with your secret key signed the message, but does not enable him to prove that to anyone else)
Create a transient secret key and corresponding transient public key. Create a transient shared secret from the transient secret key and the recipient's durable public key.
Using the transient shared secret, symmetrically encrypt then Mac, or perhaps use an authenticated block encryption mode.
Append the symmetrically encrypted and maced message to the transient public key, and send it.
Recipient derives the same transient shared secret from his durable secret key and the transient public key, (which is why we call that secret "shared") then checks the mac, then decrypts.  After decryption, checks the signature, the inner mac.

@_date: 2014-01-25 06:20:56
@_author: James A. Donald 
@_subject: [Cryptography] Does PGP use sign-then-encrypt or 
Signing bad, except in few special cases.  Authentication good.
To encrypt, must establish a shared secret.  Derive encryption and authentication shared secrets, and use the authentication secret for a mac.
If need to associate ephemeral public key with sender's permanent public key, wrap another shared secret that involves the permanent public key inside the message.

@_date: 2014-01-26 08:54:54
@_author: James A. Donald 
@_subject: [Cryptography] Does PGP use sign-then-encrypt or 
If small number of participants sharing encrypted messages, they trust each other.  They are worried about messages being altered by outsiders.
If one of their shared messages leaks, the fact that outsiders cannot tell which of them originated it is a feature, not a bug.

@_date: 2014-01-27 08:11:16
@_author: James A. Donald 
@_subject: [Cryptography] Does PGP use sign-then-encrypt or 
In such special cases you want to sign.
You seldom want to sign, you always want to authenticate.
Using signatures for authentication is a security flaw.
So, by default, a secure communication system should always authenticate by default, and check authentication by default, and never sign by default.
Authentication should always be checked, and if authentication is not present, the recipient's system should silently ignore the message. Signatures should be checked, and the user notified if the signature fails.  However the recipient system should not expect a signature.
The simplest way to do this is for signature, if present, to be present in addition to authentication, even though it can substitute for

@_date: 2014-01-27 10:26:18
@_author: James A. Donald 
@_subject: [Cryptography] Does PGP use sign-then-encrypt or 
Not making any assumptions.
Authentication always needed, to prevent substitution attacks.
Signature seldom needed.
Those are facts, not assumptions.  Always you want the recipient to know that you wrote the message, and Mallory did not write the message, so that Mallory does not inject himself into the conversation, but you seldom want the recipient to be able to prove this to someone else.
We cannot unload all that decision making on the end user.  If we expose all that complexity to the end user, he is going to run away screaming.   We have to set reasonably defaults, which 99% of users, 95% of programmers, and 95% of cryptographers lack the comprehension to ever alter.
And the reasonable default is authentication but no signature.
 > What's interesting is that in the real world message contents are
 > generally regarded as sufficient basis for non-repudation anyway;
There is a word for that: "verbal"; meaning, not the spoken word, but that a policeman tells the court that you admitted to the crime.  Courts and prosecutors and the New York Times invariably pretend to believe policemen, but no one else does.

@_date: 2014-01-29 08:17:29
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
We do, however, know how to do RNG right.  We just don't do it right.
Use many, many different entropy sources, even ones that are known to suck.  The attacker cannot predict or control all of them.
Accumulate at least 128 bits of entropy before doing anything that requires randomness, and since you cannot trust how random your sources are, accumulate a lot more than 128 bits.  This does not in fact take very long at all, for example clock skew between the cpu clock and timer clock, hard drive turbulence, etc.
If your device likely has a solid state drive, so no hard drive turbulence, then it likely has lots of hardware sources of thermal noise and quantum noise, as for example the android phone.
Between boots, store previously acquired randomness.  On OS install, seed the store.
Once you have more than 128 bits of randomness, use it to seed a pseudo random number generator with a lot of internal state.
Output from the random number generator should give no clue as to the internal state.  Either take a cryptographically one way hash of the output, or use a random number generator whose output is believed to give no clue as to the internal state.   Having a lot of internal state helps render any clues less useful.
 From time to time, stir more randomness into the pseudo random number generator *in* *greater* *than* *128* *bit* *chunks*, not in smaller Virtual machines have less access to true randomness, so the underlying real machine should provide them the output of its real random number This is, of course, not what we are in fact doing.
And whenever cryptographers complain "should do this right" the answer is "that would break lots of existing software, we need to be bug So add a new source of cryptographic randomness, done right.  Call it

@_date: 2014-01-29 12:23:38
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
I don't think there are any low entropy systems.
You don't need entropy in a hurry unless you are on the network.  If on the network, attacker cannot know everything about ever packet unless he has physical access.  Hard drive generates a lot of entropy, timing skew generates a lot of entropy, and any physical sensor, such as camera or microphone, generates lots of entropy.

@_date: 2014-01-29 12:25:48
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
> Unfortunately, pretty much all real-world systems
 > have some time (often very soon after their
 > first startup) when they have to generate some high value key.
Don't do that.   Should not even be possible to do that.
By the time boot up process is otherwise complete, should have enough

@_date: 2014-01-30 07:24:28
@_author: James A. Donald 
@_subject: [Cryptography] cryptography Digest, Vol 9, Issue 29 
Use exact arrival time and details of packets.
Seed entropy on install.
If it is a digital thermostat, has an A to D converter.  If an A to D converter, probably has thermal noise.

@_date: 2014-01-31 07:22:15
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
Which is, of course, guaranteed to be true in any typical entropy gathering system.
The more sources of entropy, the better.  Even if some of them are totally under the control of one adversary, that pretty much guarantees that they will not be under the control of another adversary.

@_date: 2014-01-31 08:46:11
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
no, attacker cannot, and defender does not care.
The more entropy sources the better, even if some of them are completely predictable to some attackers, and some of them are completely controlled by some attackers.

@_date: 2014-01-31 13:05:41
@_author: James A. Donald 
@_subject: [Cryptography] Hard Truths about the Hard Business of finding 
You cannot tamper with a sound card in the field to make it fail as a source of randomness, without making it into a very bad microphone input, with the result that it will get thrown out and replaced, so that the use can play games and make phone calls.

@_date: 2014-01-31 13:15:06
@_author: James A. Donald 
@_subject: [Cryptography] Hard Truths about the Hard Business of finding 
A sound card cannot tell the difference between low level sound and high level thermal noise.
When you hold a sea shell to your ear, you are hearing thermal noise, and the only reason that you do not hear thermal noise all the time is that you subconsciously filter it out.   The sea shell changes the color of the thermal noise, thus bringing it to conscious awareness.
So, if a sound card cannot pick up thermal noise, user will perceive it as a shitty sound card.

@_date: 2014-02-01 08:33:14
@_author: James A. Donald 
@_subject: [Cryptography] cheap sources of entropy 
Normally only one VM at a time has access to the physical soundcard.
And if two VMs at the same time have access to physical soundcard, that still limits your attackers to people who have VMs on the same hardware as your system, excluding the other three billion possible attackers.
And you should be using multiple sources of entropy, at least one, and possibly several, to exclude each class of attacker.  For example VM clockskew will protect you even against attackers on the same machine, as will network events, since each VM gets its own network events, and hard drive turbulence, since each VM gets its own disk events.
If you are on a VM, probably have a disk drive with turbulence.
If you do not have a disk drive with turbulence, probably have your own microphone and video input.
So, get microphone input and clock skew and network events and disk drive turbulence and hash them all together.  One of them is bound to work.  The class of machines on which one of these fails is different from the class of machines on which another of them fails.

@_date: 2014-02-01 13:01:54
@_author: James A. Donald 
@_subject: [Cryptography] Unified resource on Random Number Generation 
============================== START ==============================

@_date: 2014-08-01 08:29:19
@_author: James A. Donald 
@_subject: [Cryptography] [cryptography] Browser JS (client side) crypto 
Active attacks leak data about the attacker.  The more important the attacker, and the less important the target, the worse that deal is for the attacker.

@_date: 2014-06-05 19:32:51
@_author: James A. Donald 
@_subject: [Cryptography] To what is Anderson referring here? 
Firstly, browser writers are in the pockets of the CAs, and eke renders CAs even less relevant.
Secondly, implementing eke in the browser and the web server is a bigger job than it looks.  People don't realize how much $ needs to be done. There are a whole bunch of layers,
The head-bone connected to the neck-bone,
the neck-bone connected to the back-bone
The backbone connected to the thigh-bone
the thighbone connected to the knee-bone
the kneebone connected to the leg bone
the leg bone connected to the foot bone
Oh hear the word of the Lord!
And you have to run the plumbing through each of these layers, each layer written by someone else.
And, of course, to make the whole thing work, you need a password window that cannot be emulated by javascript running in the browser - which is not so difficult - you just cut javascript's ability to spawn non standard windows off at the knees.

@_date: 2014-06-10 22:09:21
@_author: James A. Donald 
@_subject: [Cryptography] Aggregate signatures 
How many bitcoin wallets are there?
Bitcoin transactions are currently "voted" legitimate by the majority of computing power.
This will likely have bad consequences when the majority of computing power is substantially different from the majority owners and users of It would be preferable to have bitcoin like currency in which currency transactions are voted legitimate by the majority of existing owners of the currency.

@_date: 2014-06-20 15:37:36
@_author: James A. Donald 
@_subject: [Cryptography] What has Bitcoin achieved? 
That seems plausible to me, but I would like to see the basis for that

@_date: 2014-06-23 19:27:41
@_author: James A. Donald 
@_subject: [Cryptography] "Is FIPS 140-2 Actively harmful to software?" 
Some individuals are consistently trustworthy and competent.  Very few organizations are.

@_date: 2014-06-24 08:21:18
@_author: James A. Donald 
@_subject: [Cryptography] What has Bitcoin achieved? 
For cost so defined to be comparable to other concepts of cost, need to assume that mining is only moderately profitable, which appears to be true, and that the cost of mining is largely the cost of massively replicating and validating transactions, which is not true, but becoming increasingly true.
Not a workable system.
We need blockchain money system that is more scalable - transactions are only moderately replicated and moderately duplicate stored, and in which authority more reliably corresponds to ownership of the money, rather than ownership of computing power.

@_date: 2014-06-24 08:36:13
@_author: James A. Donald 
@_subject: [Cryptography] What has Bitcoin achieved? 
The cost of transactions is paid for by new money issue.
The value of bitcoin is based on speculation that it will become more widely used for money that it currently is.
So speculators are paying for transactions
For it to be more widely used for money than it currently is means one hell of a lot more transactions.
For all this to end well, the cost of transactions has to fall to quite low levels.

@_date: 2014-03-08 11:28:37
@_author: James A. Donald 
@_subject: [Cryptography] GnuTLS -- time to look at the diff. 
C++ can and always should automate clean up.  You make everything that needs to be cleaned up a variable with the appropriate clean up rules, and the compiler generates the cleanup code invisibly and correctly.
C++ memory management is actually better than python or Java in this regard.  It is worse than python or Java, in that it is optional, and not everyone exercises the option, and in that the ability to set the rules means the ability to set them wrong.

@_date: 2014-03-09 09:58:09
@_author: James A. Donald 
@_subject: [Cryptography] RC4 again (actual security, 
Arc4 is not broken.  It has known weaknesses, and must be used correctly in the light of these known weaknesses.  It frequently is not used This is similar to the debate on garbage collected languages.  You can easily cut yourself using a sharp tool, but sharp tools have their proper place.

@_date: 2014-03-14 14:01:10
@_author: James A. Donald 
@_subject: [Cryptography] recommending ChaCha20 instead of RC4 (RC4 again) 
> hip places - the latest generation of software needed the new hardware.
Graphics cards are nowhere near "good enough for everything you want to do", but do not seem to be improving at anything like Moore's law rates.
For cell phones, maybe Moore's law is still in effect.

@_date: 2014-03-16 14:33:57
@_author: James A. Donald 
@_subject: [Cryptography] recommending ChaCha20 instead of RC4 (RC4 again) 
Trust individuals.
As I posted on this list previously:
Let us have Jon Callas as unelected president for life of symmetric
cryptography, Bernstein as God King of public key cryptography.
Recall the long succession of Wifi debacles.  Has any committee ever
done anything good in cryptography?
IEEE 802.11 was stupid.  If NIST  was not stupid, it was because evil
was calling the shots behind the scenes, overruling the stupid.

@_date: 2014-03-16 17:19:20
@_author: James A. Donald 
@_subject: [Cryptography] recommending ChaCha20 instead of RC4 (RC4 again) 
Doomed to not scale.
Drifting off topic to nanotechnlogy - if we had molecular scale graphene transistors, computers would run a great deal faster at considerably less power.  We have not reached the ultimate physical limits of transistors.  We are, however, approaching the ultimate physical limits of transistors built using photolithography with 193 nanometer light.

@_date: 2014-05-18 12:56:48
@_author: James A. Donald 
@_subject: [Cryptography] Is it time for a revolution to replace TLS? 
--
 > I've argued here before that the solution to many asymmetric
 > cryptosystem/PKI problems is *not to use asymmetric
 > cryptosystems/PKI's*.  Yes, there are use cases where you need them.
 > But there are plenty where you don't.  VPN's are a great example:
 > Just how often do you need to connect to a VPN without having a
 > trust relationship with whatever is behind that VPN and the
 > opportunity to safely pre-share keys?
If you want to pre-share keys of reasonable size, need to use Zero Knowledge Password Protocol, which is technically asymmetric encryption, though probably not in the sense that you intended.

@_date: 2014-05-18 13:03:51
@_author: James A. Donald 
@_subject: [Cryptography] Is it time for a revolution to replace TLS? 
> Sharing a public key over a public channel is meaningful only if you
 > have a way to authenticate that it came from who you think it came
 > from.
What we need is a protocol for provably public assertions, where you
can be sure you are seeing the same document as everyone else sees,
and that the past cannot be rewritten.
Is there a name for this class of protocol?

@_date: 2014-05-22 13:39:16
@_author: James A. Donald 
@_subject: [Cryptography] New attacks on discrete logs? 
Certain special curves were proposed, were patented, were investigated.   Turns out those curves suck.
No one has implemented encryption based on those curves, because, being investigated and suspected of suckage.

@_date: 2014-05-22 15:49:11
@_author: James A. Donald 
@_subject: [Cryptography] New attacks on discrete logs? 
Every paper I read proposing pairing based crypto proposes "of large characteristic" - so evidently this attack did not come as a total surprise.

@_date: 2014-05-27 07:42:25
@_author: James A. Donald 
@_subject: [Cryptography] Langsec & authentication 
ASN.1 DER contains a turing machine in which the attacker can execute code that you never imagined.
With ASN.1 PER that turing machine is executed at compile time, and at run time is no longer around, so your attacker cannot use it.
This is like the difference between using SQL (injection attacks) and compiled SQL.
Just as SQL is extraordinarily vulnerable to attack, while compiled SQL and stored SQL procedures are normally invulnerable to attack, ASN.1 DER is extraordinarily vulnerable, while ASN.1 PER is normally invulnerable.

@_date: 2014-10-19 12:52:00
@_author: James A. Donald 
@_subject: [Cryptography] [messaging] Gossip doesn't save Certificate 
--
 > I agree that the pin distribution problem seems quite solvable. But
 > how do browser manufacturers get valid pin data for 100,000 sites,
 > not to mention regular updates? If they want to get the information
 > independently, they will have to set up the kind of rigorous
 > verification infrastructure that we would want CAs to employ. (The
 > fact that most CAs fall short does not suggest the problem is an
 > easy one.) And if I trust my browser manufacturer?s signature on the
 > browser software distribution that includes the initial pin list, as
 > well as on subsequent pin updates, why not also trust the same
 > signature key to sign individual web site credentials and use the
 > existing TLS infrastructure, with the browser manufacturer serving
 > as a super-CA for those 100,000 sites?
 >
 > If the browser manufacturers choose instead to subcontract getting
 > the pin data to one or a few high quality CAs, expect those CAs to
 > charge a very steep price since it undermines their business model.
 > The other CAs will no doubt raise a ruckus, perhaps invoking local
 > antitrust laws. And if the browser manufacturers accept most CA
 > data, what is the point?
Active attacks by powerful adversaries are rare, because an active
attack leaks information, and people are interested in information
about powerful adversaries.
If active attacks were common, we would be hosed, since the standard
password recover system is to send it in the clear in email.
So, everyone self signs their own certificate, and we then have the
system make sure that everyone sees the same self signed certificate
as everyone else.

@_date: 2014-09-28 11:22:11
@_author: James A. Donald 
@_subject: [Cryptography] The Trouble with Certificate Transparency 
At the moment the browser makes the connection, it is told that the current root hash for all certificates at the current time is X.  It receives a signed statement that X is the root hash for the current period, and hash path leading from the certificate to the root hash.
So, if browser deceived, only the entity signing the root hash can deceive it.
Later, the browser contacts one of the entities that monitor the entities signing the root hash.
If the signed assurance it has received is inconsistent with the global root has that the monitor has received, the monitor will have proof that the entity signing the root has is unreliable - the monitor will have two inconsistent signed statements as to the condition of the global root hash.
And pretty soon, that entity is discredited.
So, by and by, only reliable entities sign the global root hash.
To be an entity accepted to sign the global root hash, have to be monitored by several monitoring entities, who also monitor each other.
If accepted for any length of time, then not making mutually contradictory signatures of the global root hash.
If not making mutually contradictory signatures of the global root hash, then a hash path from an assertion containing information about a globally unique name, to the global root hash, such as an assertion about the public keys controlled by the rightful owner of that name is proof that everyone, including the owner of that name, sees the same

@_date: 2014-09-28 17:45:43
@_author: James A. Donald 
@_subject: [Cryptography] The Trouble with Certificate Transparency 
Surely this suffices.  If an attack has happened, the domain owner can find out, and can find out what authority is to blame.

@_date: 2017-08-14 18:20:07
@_author: James A. Donald 
@_subject: [Cryptography] gap diffie helman threshold signatures. 
Gap Diffie-Hellman threshold signatures, aka pairing based cryptography threshold signatures.
I read:  "Efficient threshold signature", by Alexandra Boldreva
I read that to create a threshold public key from the public keys of individual members of the group, any or all members of the group use "the method of Genman" to create the threshold public key from their individual public keys, and then to create to create the threshold signature of some item any or all members of the group similarly create it using "Using the well known techniques of Lagrange interpolation" on a sufficient number of individual signatures of that item.
This is all Greek to me
I understand how pairing based cryptography supports individual signatures and blind signing, but not how it supports threshold signatures and the green beard Masonic lodge secret handshake problem.
Can anyone point me to a more elementary explanation, or, better, much better, some free source code that actually does threshold signatures successfully using pairing based cryptography?
As you know, Bitcoin has dangerously few miners, subject to dangerously few political authorities, and miner interests are insufficiently aligned to currency user interests.
Seems to me the solution is to create a crypto currency that relies on weight of stake, rather than weight of processing power.  Such a currency is equivalent to a crypto corporation, or rather the easily traded shares of a crypto corporation.  And independently of whether we need yet another crypto currency, we need crypto corporations.
Hence my interest in threshold signatures that do not require a "trusted" dealer.
Because of shareholder ignorance, and scaling law problems with enormous thresholds, I envisage that ordinary shareholders, or rather the laptops and cellphones of ordinary shareholders(wallets), would grant their voting rights to a rather small number of board members (massive server farms in the cloud).  Every time you do a transaction through some web server, the recipient of the shares(currency) by default revocably grants his voting rights to whatever web server the recipient uses, thus reducing the scale problem to a moderate number of large entities with adequate connectivity and processing power.  From time to time one board member (server farm) is elected CEO (leader for the Paxos protocol)  If it goes down, loses connectivity, loses too many packets, or engages in Byzantine deviation from the Paxos protocol (possibly as a result of being raided by the cops for money laundering), they elect a new one after twenty seconds or so.

@_date: 2017-08-21 12:55:25
@_author: James A. Donald 
@_subject: [Cryptography] Tezos 
Tezos is a proof of stake crypto currency
Reading the white paper, I see no explanation of how to solve the hard problem of proving to all stake holders that fifty percent plus one of the stake holders have chosen to support one outcome rather than another when the number of transactions and accounts becomes very large.
Tezos starts off as a centralized system, as all systems must in that all proof of stake systems start off with the stakes held primarily by those who wrote the software and those who funded them, but for initial investors to cash out, must become a decentralized system, and I am not seeing any plan to become a decentralized system.
Of course that is par for the course for a lot of internet companies these days.  Fund me today, and I will figure out how to make money

@_date: 2017-12-02 19:16:26
@_author: James A. Donald 
@_subject: [Cryptography] Cryptocurrency: CME Approved, Coin Paychecks, FED, 
My cleaning lady is investing in bitcoin, which is a good sign that it is time to get out.
The current total market value of bitcoin is about two hundred trillion.
The current total market value of gold is about ten trillion.
In the long run it is reasonable that people should hold more wealth in the form of bitcoin than in the form of gold, but twenty times as much?
I would favor roughly equal amounts.  If most people think similarly, then gold needs to rise, or bitcoin needs to fall.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-12-02 19:21:55
@_author: James A. Donald 
@_subject: [Cryptography] Cryptocurrency: CME Approved, Coin Paychecks, FED, 
Oops, major error.
Total value of Bitcoin it is currently around two hundred billion, not two hundred trillion.
It is reasonable that the total value of bitcoin should be comparable to the total value of gold, which is at present ten trillion.
Hence Bitcoin can plausibly rise from ten thousand per bitcoin, to five hundred thousand per bitcoin.
On the other hand, my cleaning lady is investing.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-12-03 13:33:31
@_author: James A. Donald 
@_subject: [Cryptography] Cryptocurrency: CME Approved, Coin Paychecks, FED, 
People hold gold for roughly the same purpose as they hold cryptocurrency.
Sure.  Some other crypto currency may, and quite likely will, replace But at the present moment, Bitcoin is where it is at.  The aggregate value of all the various cryptocurrencies out there is approximately the same as the aggregate value of bitcoin.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-12-15 05:28:35
@_author: James A. Donald 
@_subject: [Cryptography] High volume thermal entropy from an iPhone 
We have theoretical reason to believe that the dark signal from a phone camera is thermal noise.
You then take a look at it, and say "Yeah, looks like thermal noise"
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-12-17 13:18:03
@_author: James A. Donald 
@_subject: [Cryptography] Intel's $10-100 billion Minix copyright problem 
I have talked to people who operated those metaphorical black helicopters around Santa Clara, and I don't think you are modeling them This email has been checked for viruses by Avast antivirus software.

@_date: 2017-12-20 17:05:11
@_author: James A. Donald 
@_subject: [Cryptography] How good random number generator is the human 
I would say that is good enough randomness.  sixteen of those bytes, the size of a credit card number, is 17*10^12 possibilities.
That is rather more than enough to defeat an online attack.
For an offline attack, we can make testing the value to be input take an arbitrarily long time, though of course the attacker may well have more powerful hardware than the defender.
Make testing the value offline take one second on the defender's hardware. Assume the attacker has hardware one million times as powerful as the defender's.
Then it is going to take the attacker about a year of his dedicated, expensive, hardware.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-12-24 19:36:25
@_author: James A. Donald 
@_subject: [Cryptography] Bitcoin theft and the future of cryptocurrencies 
We already are facing big trouble over scaling.  Zerocash is too damned I suggest that rather we should employ the coinjoin algorithm.
Your client wallet uses its durable public key and the other client wallet's durable public key to establish a secure connection through the full peers maintaining the blockchain.  They agree on a new public key to which value will be transferred.
They then connect up to other client wallets also attempting to perform a transaction and perform a coinjoin, so that what shows up in the blockchain is that a random bunch of pseudonymous people transferred value to another random bunch of pseudonymous people.
Instead of the blockchain showing Ann transferring money to Edward, coinjoin shows Ann and Bob and Carol transferring value to Dave and Edward and Fay.
This protects the blockchain from the blood diamonds attack.
Every atom of gold is guaranteed by the laws of physics to be absolutely indistinguishable from every other atom of gold, but every uncut diamond is unique.  So if the state does not like you, it is apt to declare your uncut diamons to be "blood diamonds"   Pretty soon, the state is going to declare some bitcoins to be "blood bitcoins".  Coinjoin, like zerocash, makes equality of bitcoins a fact of mathematics, rather than a policy of humans.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-12-25 09:05:55
@_author: James A. Donald 
@_subject: [Cryptography] (no subject) 
What would make a cryptocurrency for Indians different from a cryptocurrency for anyone in the world.
How would we market this currency for Indians?
Would our target users be equipped with smartphones, and would they need to make fast smartphone to smartphone transactions, perhaps by photographing a QR code?
Because Bitcoin is hitting its scaling limits hard, transaction fees are too high for Indians to use in ordinary transactions, and transfers too slow, which implies the need for a lightning network for in person transactions, which in turn implies a large number of client wallets and a relatively small number of peer wallets.
But by the time a currency specifically for Indians was written, the Bitcoin lightning network may well be up and running, which could potentially solve the problem for Indians.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-12-27 11:51:24
@_author: James A. Donald 
@_subject: [Cryptography] Bitcoin theft and the future of cryptocurrencies 
Last I heard, MimbleWimble was an idea, not yet a cryptocurrency.
Pretty cool idea ... but:
Suppose HHitler puts a wallet address on his website, and asks for Ann sends a donation from her coinbase wallet.  The true name associated with he wallet is known to the authorities.
Seems to me that the authorities, monitoring the MimbleWimble blockchain, will be able to tell that Ann gave a donation to HHitler, even though they cannot tell how much.
MimbleWimble greatly reduces the storage problem, but not obvious that is solves the bandwidth and speed problems.

@_date: 2017-12-29 13:42:45
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Fast handling of IP Address changes for HTTPS 
Solution:  Sign up with a provider that offers static IP as an optional

@_date: 2017-12-29 13:54:00
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Bitcoin theft and the future of cryptocurrencies 
Unspent amounts, and their associated public key, remain in the Mimblewimble blockchain until some time after they are spent, potentially forever.
Is the associated public key hidden so that only the true owner of the unspent transaction can recognize it?
Obviously HHitler is going to have to advertise his wallet address so that he can get paid.
What is the relationship between his wallet address, and what eventually appears in the blockchain?
If Ann sends money to HHitler, she not only wants to hide from the authorities that she sent an unknown amount of money to HHitler, she also wants to be able to prove to HHitler that she sent him money, that she sent him a specific amount of money, and be able to prove to arbitrary third parties that she sent him a specific amount of money.

@_date: 2017-12-29 13:59:28
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Bitcoin theft and the future of cryptocurrencies 
Not seeing this demonstration, nor any clear explanation of the nature of the supposed break, what the attacker needs to break it, nor exactly knowledge he gains from this break.
Sounds like FUD.
Everyone competing with bitcoin, wants bitcoin to fail and be replaced by their own crypto currency.  And bitcoin has many flaws, and perhaps deserves to fail, and undoubtedly needs to be replaced or radically changed, but you cannot trust the FUD emitted against it.

@_date: 2017-12-29 14:12:46
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Bitcoin theft and the future of cryptocurrencies 
Oops, ignore my previous question.
The white paper you link to above tells me:
#	no address. All outputs in Grin are unique and have
#	no common data with any previous output. Instead of
#	relying on a known address to send money, transactions
#	have to be built interactively, with 2 (or more) wallets
#	exchanging data with one another. Practically, this
#	isn't so much of a problem as there are multiple ways
#	for 2 programs to interact privately and securely.
#	And this interaction could even take place over email
#	or Signal (or carrier pigeons).
Sounds good.
For example, suppose each peer has a thousand client wallets, and the capacity to connect to any other peer, that peers have fully accessible ports, and that the client wallets, who being behind consumer grade NATS generally do not have fully accessible ports, set up a direct client wallet encrypted connection through their NATS using their peer connections to initialize the connection.
But obviously this software is not written yet.  Still vaporware, but vaporware that sounds very promising.
Mimblewimble solves the problem of disk storage limiting scale.
How does it go on bandwidth limiting scale?

@_date: 2017-02-01 16:14:18
@_author: James A. Donald 
@_subject: [Cryptography] Firewall penetration 
Suppose a server talks to two clients, which are connected to the internet by ordinary consumer type connections.  Is their any reliable, practical, generally useful way whereby it can arrange for the two clients to talk directly to each other, or is it more practical for all data to be stored on the server by one client, and then collected by the other client?
When last I looked at this issue, direct communication was getting harder, and workarounds were like bugs that were likely to be fixed.

@_date: 2017-02-07 19:49:10
@_author: James A. Donald 
@_subject: [Cryptography] What is total world transaction volume? 
Bitcoin cannot replace government money because there is a soft limit on the number of transactions, and we are already hitting that limit.
Also because final settlement is a bit slow.
Gold cannot replace government money, because it is easier to transfer promises than physical gold, although we may well return to the gold standard after the next crisis or two.
What is the total number of credit and debit card transactions, including atm transactions, per unit time?
How many transactions would a crypto currency need to handle per unit time to replace government money?

@_date: 2017-02-08 10:35:13
@_author: James A. Donald 
@_subject: [Cryptography] What is total world transaction volume? 
What I have been thinking on for many years is that you do not really need every full node to process the entirety of the network's transaction history, or indeed any nodes processing the entirety of the network's transaction history.  Rather, your node needs to be able to prove that every node connected to your node by a rather short chain of transactions is in agreement about all transactions directly or indirectly affecting you.
Node C tells Node P  "I will pay you one crypto coin"
Node P says "Do you in fact have one crypto coin?"
Node C says "All my pals agree I have one crypto coin", and registered this consensus with the global consensus some time ago, and the global consensus is that I and all my pals together have quite a lot of crypto coins, so if my pals are lying about me, they are the ones who will be out by that amount"
Node P.  "OK, gimme."
Node C. "OK, notifying all my pals that I am down one crypto coin, and you are up one crypto coin.  And in a short while, I and all my pals will notify the global consensus that I and all my pals together are down one, and you and all your pals together are up one.
Node P "waiting for notification from all my pals that the global consensus agrees we are up one."
Node P "OK, I and all my pals are up one."
Node P  "and my pals agree that I am up one, transaction finalized."
This scales up a lot further than bitcoin, at the cost of failure modes that may be difficult for end users to understand, but it is not entirely obvious that it will scale up to ten thousand transactions per The problem is grouping nodes to get locality of transactions, that people you transact with are generally near you in the tree.
If there are major failures of locality, we still get substantial savings relative to bitcoin, but "substantial" may not be enough to make a difference.
The proposed protocol as described is subject to a Sybil attack, in that you may find yourself in a subtree dominated by nodes controlled by a scammer.  Dealing with such attacks in a fashion likely to be intelligible to end users is not obvious.

@_date: 2017-02-09 10:19:35
@_author: James A. Donald 
@_subject: [Cryptography] So please tell me. Why is my solution wrong? 
Which is the unforgeable UI of a Zero-knowledge password proof, where both parties prove they know the password without giving the password away to each other.
This stops phishing and spearphishing, which in this election was a major national security issue and major private security issue, since Clinton and her team had a pile of state secrets valuable to the enemies of the united states in their email, and a pile of political secrets valuable to the enemies of Clinton in their email.
Another problem that needs fixing is keeping piles of emails on the server in the clear, which provoked Secretary of State Clinton to keep her emails on a thumbdrive that she personally controlled.  Secretary of State Clinton did not want her people's emails sitting on a system that President Obama's people could physically get at.
Though in the end everyone from the Russians to the Chans did get her emails, due to spearphishing, weak passwords, and insider sexual misconduct.
What should happen is that when both parties are logged in with their respective email servers at the same time, their respective email servers should arrange a direct encrypted connection between their respective email clients, so that messages pass directly from one client computer to the other, so that Clinton's emails do not pass through Obama's servers.
We cannot do much about insider sexual misconduct, but direct client to client transmission of emails at least mitigates that problem substantially.

@_date: 2017-02-09 10:28:12
@_author: James A. Donald 
@_subject: [Cryptography] [FORGED] Re: So please tell me. Why is my 
Suppose we bring up a local background screen, and display the UI directly on that background, no windows, just old fashioned text on the And this UI is the interface to a zero knowledge password proof, where both parties prove knowledge of the password without giving it away.
If the phisher brings up the true password UI, which he can perfectly easily do, he does not gain anything.
If he brings up a different UI - well, the UI is necessarily dramatically different, being windowed and all that.
Will it work?  To answer that question, hold down the Ctrl and alt keys, and press the del key.   Now imagine that with a background image unique to each person's computer.   Hell, imagine that even with the standard blue background.  It would still work.

@_date: 2017-02-09 17:05:38
@_author: James A. Donald 
@_subject: [Cryptography] [FORGED] Re: So please tell me. Why is my 
> > Will it work?  To answer that question, hold down the Ctrl and alt
 > > keys, and press the del key.   Now imagine that with a background
 > > image unique to each person's computer.
How would you run a real world user study?
The problem with today's users are that they are trained to be phished, because they are trained to enter their passwords into a wide variety of To untrain them, you need to stop people from being asked to enter their passwords into a wide variety of UIs - you not only need to provide a password user interface to a zero knowledge password proof, where both parties prove knowledge of the password without giving it away, the state has to prohibit its subjects, or perhaps the business its employees, or perhaps Clinton her co-conspirators, from using any software or service that uses any other interface to enter a password.
To give this a fair test requires an ecosystem of software and services that uses the system, and some substantial compulsion and coercion to exclude anything outside that ecosystem.
Anything less is not a fair test.

@_date: 2017-02-10 18:01:52
@_author: James A. Donald 
@_subject: [Cryptography] [FORGED] Re: So please tell me. Why is my 
The key works with google gmail, not any old email server, and chrome browser, not any old email client.
I am pretty sure that if Clinton had used google gmail, Obama's team would still have been able to read her team's mail.  Remember that her primary security concern was not Russia, the chans, or wikileaks, but Obama.  Recall what happened to Petraeus.  Google actively and aggressively takes sides in politics and Washington power struggles. One would be better off using a KGB mail server.
Now if the 2nd factor device worked on your own server today and with your own email client today, then it would be useful today.

@_date: 2017-02-11 04:33:55
@_author: James A. Donald 
@_subject: [Cryptography] [FORGED] Re: So please tell me. Why is my 
We are talking hypothetical vaporware that costs money and uses a usb slot, and cannot work with cellphones for shortage of usb slots, versus hypothetical vaporware that could be standard software on every system.

@_date: 2017-02-11 04:37:39
@_author: James A. Donald 
@_subject: [Cryptography] [FORGED] Re: So please tell me. Why is my 
Appropriate is what I have described, since the end goal is a system where no one reveals their password in order to verify it.

@_date: 2017-02-11 20:17:29
@_author: James A. Donald 
@_subject: [Cryptography] [FORGED] Re: So please tell me. Why is my 
True, but neither I, nor secretary of State Hillary Clinton, would have been happy with those sites and services.
Further, because id dongles are proprietary and costs money, can never become a universal standard - and we only get real security if secure stuff becomes a universal standard the way regular email is standard now.
Right now, banks are pushing people to use security devices, and the device generates a use once password, and they make you type in the use once password every time you authorize a transaction. It is a pain in the ass.   Having dongles where you just press a button would be much better, so don't tell me that they are available right now.   If they were available right now I would use them, the banks would use them, and Secretary of State Hillary Clinton would have used them.

@_date: 2017-02-13 07:22:24
@_author: James A. Donald 
@_subject: [Cryptography] Quantum and continuous progress. 
"quantum"  and "the size of a large building"
The size of a large building?  Something smells funny.
The proposed quantum computer stores its qbits in ions in vacuum traps. Presumably the qubits are transported by laser pulses - which requires the very nearly lossless single photon readout of the qubit from one ion, and corresponding very nearly lossless absorption by another ion. Doing anything more interesting than moving data from one storage location to another requires very nearly lossless strongly nonlinear coupling between photons, or very nearly lossless strongly nonlinear coupling between a photon and an ion.
It is in practice hard to get strongly nonlinear coupling unless you have distinctly macroscopic laser beams containing billions of photons.
They breathlessly tell us that this is a practical design that could be implemented right away, but I am pretty sure we do not have any technology to have strongly nonlinear lossless interactions between individual photons, nor has anyone even imagined how to do such a thing.
An actually practical quantum computer must necessarily operate at very low energy and very high speed, and thus its components for doing logic operations must be very small.  We might for example construct large molecules that will only break up if the permitted states contain a solution to a hard problem - each large molecule would be a quantum computer, each large molecule would find the solution, and we would read some information about the solution from one molecule, and some more information from the next molecule.
Things the size of a building just do not seem likely to preserve much quantum character.
You can send one photon containing quantum state through a very long fiber optic cable, or you can keep quantum state in a single ion for a very long time, but the problem is that to actually do quantum computing, you have to have strongly nonlinear nearly lossless interactions.  Which is the hard part, the part where very small sizes, very high speeds, and very low energies matter.
A component that can do a quantum operation losslessly, can do a classical operation very fast at very low energies.  If we had such things, we would already be using them for other purposes.

@_date: 2017-02-22 14:13:35
@_author: James A. Donald 
@_subject: [Cryptography] Security proofs prove non-failproof 
That would be handy.  Are you telling me that there is a system that can digest a suitably prepared C++ program and tell me it cannot have a buffer overflow, memory leak, signed integer overflow etc, and complain to me if there is potential for these things?
Obviously there is no mechanical or automated method that can tell whether or not an arbitrary program can develop such errors.
Visual Studio comes with a bunch of built in analysis tools that I have so far not found terribly useful or informative.  They tend to tell me the glaringly obvious or nothing at all.
What I have found useful is making sure a program does not in fact develop memory leaks when actually run.  Profiling is also handy when one wants to optimize a program.  But these are ancient tools.

@_date: 2017-02-24 12:36:46
@_author: James A. Donald 
@_subject: [Cryptography] Security proofs prove non-failproof 
C++ however can substantially automate memory management through C++11 smart pointers.  In particular it has long supported the idiom Resource_Acquisition_is_Initialization, also perhaps more meaningfully described as Scope-Bound_Resource_Management, which is the by far the most powerful convenient and useful idiom for avoiding leak type problems, and one that most other languages lack.
Further, this approach to avoiding leaks of memory, sockets, database handles, and such, and avoiding use of already released memory, database handles, and such, instead of involving quite a bit of work, saves you quite a bit of work.
Even if you are using a garbage collected language, memory management is not in itself the biggest problem, rather it is the stereotypical case of this entire class of problems.  C++11 Smart pointers plus Scope-Bound_Resource_Management provide a general solution to this entire class of problem, and a general solution that saves you a great deal of work rather than involving quite a lot of work.
Since resource management is only semi automated in C++11, you can still get it wrong.   Any stupid code that can be written in C can be written in C++. You can still make mistakes and not realize it.  But because you should be doing vastly less work managing resources in C++11, you have vastly less opportunity to get resource management wrong.
You should have defined in your classes how resources are to managed, and then the compiler proceeds to manage resources for you.  If you refrain from using obsolete C resource idioms in C++, it is quite difficult to leak resources or to inadvertently access already released resources.   You should never manually manage resources in C++11 except within class creators and destructors, in which case the class of C errors that you are using formal methods to detect cannot happen.

@_date: 2017-02-27 13:20:15
@_author: James A. Donald 
@_subject: [Cryptography] More efficient block-chain ledger: Micali's 
Algorand sounds like an enormous improvement, and I think it is an enormous improvement, since proof of stake is better incentive aligned than proof of computational power.
But it still has that pesky bandwidth problem.  The authors cheerfully say that the computational burden is minimal, and it is, but every user downloading every transaction of every other user is not minimal.
It would be a good system for proving public keys - you would know that the person you are communicating with sees the same mapping between public keys and phone numbers as you do, or the same mapping between blog addresses and public keys, or the same mapping between email addresses and public keys.
But for money purposes, it still hits the problem that we would like to handle a *lot* of transactions.

@_date: 2017-03-01 13:28:30
@_author: James A. Donald 
@_subject: [Cryptography] Schneier's Internet Security Agency - bad idea 
Iphones are always listening to you and you cannot disable it.
On the other hand, unless you deliberately disable it, an android phone is also always listening to you, and reporting to Google.
There has been no indication that Google uses the always listening feature for political purposes, but it used gmail for political purposes.  Social Justice Warriors have been urging Google to use the always listening feature to detect and punish sexist words.
If social justice warriors had their way hate speech would be recorded and transcribed, and made available to future employers, and were a business to hire a "hater" then in a subsequent hostile environment or discrimination lawsuit by social justice warrior's against the business, that hater's politically incorrect words would be used to ensure that the business lost the lawsuit.
In the short term a more likely use would be that Google listens in to the White House and shares the information with Trump's enemies.

@_date: 2017-03-01 13:35:27
@_author: James A. Donald 
@_subject: [Cryptography] Improvements to RNG seeding in Linux 4.10 
============================== START ==============================
UEFI means that device specific hardware can supply entropy.  Which makes sense given that only device specific hardware can access things that are truly random.
But chances are that the hardware will not have drivers to access device specific entropy, that since customers will not know, hardware makers will not bother.

@_date: 2017-07-01 18:50:42
@_author: James A. Donald 
@_subject: [Cryptography] credacash 
There is a lot of really serious money going into crypto currencies.  A lot of very rich people are hedging against the collapse of the US$ and the US empire, and they rather suspect that it will be replaced by a crypto currency rather than the gold standard.
But bitcoin is hitting its scaling limits hard.  Maybe they will solve this, and become the one world currency, but at the moment we are instead seeing a whole bunch of monkeys flinging crap at each other as each seeks to shift scaling costs somewhere else.
A lot of altcoins have appeared, many of them get rich quick scams. They generally claim to have solved the many problems bitcoin suffers from.  Last time I checked, this was not exactly true.  Checking again. Looking at Credacash
Credacash claims to be the bee's knees.  Its secrecy and anonymity qualities are outstanding, it is fast, efficient, and claims to be fully sidechain compatible, though as yet no actual sidechains exist making the claim difficult to verify.
Some of its alleged secrecy characteristics come from operating within the tor network.  But anonymity on tor depends on slow and random timing.  Credacash is optimized for fast and predictable timing.  Its secrecy characteristics should not be tor dependent.  To what extent is its secrecy dependent on Tor?  Why does Credacash not operate on the regular internet?
Bitcoin's problems derive in large part because all peers download and validate all transactions, which means that transaction cost grows as the number of peers, that there is a lot of opportunity for transaction cost shifting (hence the current shit flinging) and that delay grows roughly as the log of the number of peers.
Instead of peers, Credacash has witnesses, but does that not make it just another centralized currency, ideal for scam artists and government Ideally, if we are going to have a limited set of witnesses, anyone should be able to be a witness with probability and influence proportional to stake.  Not seeing any data about weight of stake in Credacash's description, which makes it just another centralized currency.
Is there in fact any crypto currency with characteristics that make it resistant to government takeover and scam artistry that has solved the scaling problem?
It is easy to solve the scaling problem.  Any standard centralized currency scales just fine - and any standard centralized currency tends to wind up being run by scammers and/or governments - typical crisis being first scammers, the the shit hits the fan, then the government takes over.

@_date: 2017-07-03 10:21:10
@_author: James A. Donald 
@_subject: [Cryptography] actual journalism, was LRB article, 
The coin to invest in, the coin that I will invest in both in money and as a software contributor, will solve the scaling problem, will be capable of scaling all the way to wiping out the US$ as a world currency.  It will have integral support for sidechains with payments out of one sidechain to another sidechain being endorsed by sidechain signature from a single authority which is itself periodically but infrequently endorsed by a short sidechain multisignature, which can be generated by arbitrarily complex rules idiosyncratic to that sidechain provided that conformity to the rules has verification of bounded computational time that the central chain can evaluate.  It will have an efficient system for securing history in which Merkle trees do not grow to enormous depth, so that it is possible to efficiently verify any one small part of history without needing to verify all transactions that have ever taken place.   (Because scalability implies we abandon everyone verifying everything down to the last byte.)
It will be decentralized in the sense that if the police grab every single major contributor, software writer, and server, they cannot change the rules and make the currency act differently, they can only seize the money of the people that they have grabbed.

@_date: 2017-07-03 16:59:53
@_author: James A. Donald 
@_subject: [Cryptography] actual journalism, was LRB article, 
The bitcoin hash chain grows to enormous depth, and arguably it is a Merkle tree that testifies to all transactions everywhere that ever taken place in bitcoin.
If you say it is not a Merkle tree, then fine.  A scalable crypto currency has to employ a Merkle trees instead of whatever we call the thing that Bitcoin uses.

@_date: 2017-07-03 18:08:44
@_author: James A. Donald 
@_subject: [Cryptography] actual journalism, was LRB article, 
I am pretty sure that if I give a definition and say "A Merkle tree is such and such", a bikeshed war will ensue over my definition of Merkle tree, which war will probably result in Perry blocking my posts.
So let me define instead a donald tree.   :-)  (just kidding)
A donald tree is a tree where every node contains the hash of its immediate children.  Thus the hash of the root of any subtree guarantees the contents of all its descendants, just as the hash of a file guarantees the contents of the entire file.
This means that we can keep on adding to the tree, while keeping the past immutable, which is a useful feature for tracking who owns what, and who owes what.  If many people see the current hash at time X, you cannot change details about the past of time X without revealing what you have been up to.
Any tree can be severely unbalanced, for example a binary tree where every node has a right hand child, and very few nodes have a left hand child, in which case the depth of the tree is approximately proportional to the total number of nodes in the tree - and the tree grows to enormous depth when the total number of node is enormous.
Or it can be approximately balanced, in which case the depth of the tree is approximately proportional to the log of the number of nodes, which is always a reasonably small number even if the number of nodes is enormous.
And a hash that testifies to every transaction that anyone ever did is going to be the hash of an enormous number of nodes.  But if it is at the root of a tree of moderate depth, then we can validate any part of the tree for conformity with the rules without validating the entire tree for conformity to the rules.

@_date: 2017-06-30 18:30:50
@_author: James A. Donald 
@_subject: [Cryptography] Depending on Google to protect your anonymity?! 
Meaning, of course, no activity that they will admit to logging.
Google is evil.

@_date: 2017-06-30 18:27:03
@_author: James A. Donald 
@_subject: [Cryptography] Depending on Google to protect your anonymity?! 
This is deceptive.  Google has linked identities that I have taken radical measures to keep separate, even though none of those identities have ever signed in for anything google related.
To detect some of the things that they have detected, their tracking must be vastly more intrusive than this link reveals.
This does not mean they are omniscient - their detection is spotty, and from what they have caught, I know that some things they have not caught, I have gotten away with lots of stuff, much of which might seem easy to catch, but what they have caught is a lot more than you would think from this link.

@_date: 2017-03-03 12:21:16
@_author: James A. Donald 
@_subject: [Cryptography] formal verification +- resource exhaustion 
They make it harder for machines to analyze.  But what the machine analysis actually means for human purposes is not always clear.
Forces you to do a lot more work.  Which work you can get wrong, and which work smart pointers and RAII make the compiler do for you without you having to think about them.
Obviously it is impossible to prove that an arbitrary C program will not have resource leaks, wild reads and writes to freed memory, etc.  A human may well be able to reason that a program is correct, when a mechanical theorem prover could not.So if one employs a mechanical theorem prover one is somewhat arbitrarily restricted from writing an arbitrary C program.  In which case one loses many of the benefits of C.   That C is a low level language means it can do things that are often difficult in other languages.
If we restricted C to stack and static variables and forbade pointers, would not have memory leaks or wild writes.  And we would not be able to write a lot of programs, even though it is still Turing complete.
Because C requires manual management of memory and resources, people always get it wrong.  They always have leaks, always have wild reads and wild writes.  Many people therefore propose garbage collected languages for ordinary not terribly good programmers, which is why Java has become the standard and major language.  Java is more or less C with garbage collection and a touch of C++.  You can write the same program in less time in Java because you do not have to do manual memory management. But memory is only one resource among many.
There are lots of things that Java really cannot do, or really cannot do well.  I suspect that there are lots of things a C program amenable to theorem proving really cannot do, or really cannot do well, though obviously you know more of this than I do.
You recommend a tool that is a lot more work than my existing tools, and can probably do less than my existing tools, recommend it largely because it produces programs that would be free from resource leaks and wild writes.  Now if I was still writing in C, I would probably have an intolerable problem of wild writes and resource leaks in any large program, and would be desperately looking for a cure, any cure.  But writing in C++11, I do not.

@_date: 2017-03-03 12:27:10
@_author: James A. Donald 
@_subject: [Cryptography] Signing "random garbage" with someone else's 
Yes it is considered an attack, and all signing algorithms have a hash step to protect against this attack - the thing you sign has to be not an arbitrary value, but a one way hash of some value.

@_date: 2017-03-05 11:00:46
@_author: James A. Donald 
@_subject: [Cryptography] Secret Handshake problem. 
A is an identity that is a member of a club.
C and D are identities that are not members of this club.
C wants to reveal to D that C and A are the same, that C is secretly a member of the club, if and only if D is secretly a member of the club under a different identity.
I seem to recollect that this is a solved problem, but do not remember the solution.
Also known as the "Are you also a Soviet Spy?" problem.

@_date: 2017-03-11 15:28:18
@_author: James A. Donald 
@_subject: [Cryptography] Has formal verification actually been useful in the 
Has a complete formally verified system been deployed anywhere?  Is there one keeping the electricity grid up?  Or a formally verified browser?  Or even software for converting graphics files to images on the screen so that a broken image will not take control of your computer?
Back in the days of usenet there used to be an old and obscure unix based usenet browser that would crash on unusual control character sequences and start executing usenet post text as machine code.  Is there any proof that that cannot happen with unusual html or graphics?

@_date: 2017-03-18 05:15:17
@_author: James A. Donald 
@_subject: [Cryptography] NSA says China's supercomputing advances put US 
> just doesn't cut it.
99% of politics is more pandering for a bigger place at the government If you look at any government program up close, it is almost entirely waste and corruption.
Sometimes, often, the waste and corruption is inextricably linked to vital government programs that really need to be done, like war, road building, and law enforcement, and it is easy to say that these programs should be done more efficiently (compare the cost of roads built by the private sector for internal use, with roads built by the government) but hard to do actually do them more efficiently.
(Though I have long argued that logistics should be in the hands of contractors and subcontractors classified as camp followers and directly employed by the regimental commander and by soldiers, rather than hands of people classified as soldiers but who do no actual fighting, because if the regimental commander could fire and hire logistic support, logistics would be enormously cheaper and better)
In other cases, many cases, the program serves no very obvious urgent need, in which case it should not be done by government.
If people need supercomputers for floating point type problems, they will build them.  Indeed, they already are building them.  What is a GPU?
Answer: A GPU is a supercomputer that solves a kind of problem very similar to those that government supercomputers are supposed to solve at about one ten millionth the cost.

@_date: 2017-03-22 13:28:16
@_author: James A. Donald 
@_subject: [Cryptography] Crypto best practices 
> all you reveal is whether two plaintexts are equal.
I think the solution here is that when your algorithm says "never reuse an IV", you never reuse an IV.
"Misuse resistant" is just too hard, and too complicated, which increases the likelihood of misuse.
Every encrypted message needs a secret key, a unique IV at the beginning, and an integrity check at the end.

@_date: 2017-11-13 13:11:39
@_author: James A. Donald 
@_subject: [Cryptography] Is ASN.1 still the thing? 
Do JSON, Yaml, or protobuff allow representing data format in ways that give a unique and well defined checksum, that will not be affected by endianess or compiler options?
Cryptographers specify data formats are in ASN.1 because that way you can get a unique hash or checksum of the data, regardless of which compiler you are using, and whether your machine is big endian or little But these days everyone seems to be using JSON to represent data in transit, because that is the language of the web and of node.js, or YAML, which is JSON polished up to support more kinds of data and to actually be genuinely human readable, or protobuff, because people who write in C++ despise the horrible inefficiency of translating data to and from ascii representation.
ASN.1 provides canonical format so that you can hash it or checksum it, ultra efficient binary format for C and C++ purists, and supposedly human readable format, though its human readable format is not particularly human readable.  You are a lot better off with YAML if, as in ini files, you want human readability.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-15 07:46:16
@_author: James A. Donald 
@_subject: [Cryptography] Is ASN.1 still the thing? 
YAML is JSON cleaned up, both to deal with such issues, and to provide human readability and editability.
Each YAML document is one object, and is itself a directed graph of objects
They seem to have carefully thought through what it means for one object to be equal to another.  Just take YAML standards, and generate a hash that is the same for any two objects that are equal as YAML defines This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-15 08:52:25
@_author: James A. Donald 
@_subject: [Cryptography] Is ASN.1 still the thing? 
Everyone and his dog is serializing stuff from javascript to javascript, because websockets and node.js  Mongo aims to be the database and file system for massively parallel systems, and its native language is json documents even if you are talking to it in C++
While it is a standard that deserves to die in fire, it is becoming the This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-15 09:24:08
@_author: James A. Donald 
@_subject: [Cryptography] Is ASN.1 still the thing? 
Because everyone is using JSON, JSON sucks, and everyone, his brother, and his brother's dog, is inventing something to fix the JSON suckage.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-15 11:44:08
@_author: James A. Donald 
@_subject: [Cryptography] Is ASN.1 still the thing? 
On the other hand Avro apache seems to be a more complete solution, addressing the problem of protocol negotiation, RPC calls, and map reduce calls, all of which ASN.1 views as out of scope.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-15 12:03:01
@_author: James A. Donald 
@_subject: [Cryptography] [FORGED] Re: Is ASN.1 still the thing? 
Suppose one has a system written in C++ on a server, and you have another server, running node.js, and your node.js code wants to get at some information.
There are existing modules that translate data that is Avro apache encoded to and from something node.js can understand.
I don't see any equivalents for ASN.1 PER.
It is not that I am likely to have any imminent need to talk to node.js, it is just that I am worried about being marooned in a dying standard.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-15 12:35:57
@_author: James A. Donald 
@_subject: [Cryptography] [FORGED] Re: Is ASN.1 still the thing? 
Quoting Peter Gutmann :
XDR is the native tongue of RPC.
RFC 1831.  And you can just grab an open source RPC library to take care of all that boring sockets stuff, and be standard so that other people can talk to you.
Though this does not address the protocol negotiation problem, which is assumed to be out of scope.
Is there anything similarly standard and ready to go for ASN.1 PER, or do you have to figure out how to put it on the line yourself and get it off the line yourself?
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-15 14:02:50
@_author: James A. Donald 
@_subject: [Cryptography] Is ASN.1 still the thing? 
MsgPack is binary, and modules for every language and environment you have ever heard of, and library code to do anything you want, but it is all dynamically typed, which means it is not as efficient as PER
It is basically YAML in binary, in that MsgPack messages correspond closely to YAML documents.  Because it supports every language, you can use MsgPack to talk C++ to node.js, and YAML to talk to humans.
Dynamic typing means that a hostile evil program could send no end of messages that your program is not equipped to deal with.  The great thing about PER is that anything that you are not expecting just gets magically rejected.
Both of them totally punt on the issue of protocol negotiation, whereas Avro apache has support for protocol negotiation.  It combines static and dynamic typing, but dynamic requires both sides to play nice.  Evil program with surprise data structures will just have the connection shut down on it.
But I don't see that Avro Apache can talk to node.js, in part because it it wisely refuses to be fully dynamic.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-15 15:14:40
@_author: James A. Donald 
@_subject: [Cryptography] [FORGED] Re: Is ASN.1 still the thing? 
I have discovered more serializers than I can shake a stick at: I don't intend to invent yet another encoder/decoder.  I am looking for a standard that tells me what wheels should look like, and a library that is full of the wheels I need.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-15 18:11:50
@_author: James A. Donald 
@_subject: [Cryptography] Is ASN.1 still the thing? 
I rather think we do depend on repeatable canonical encoding - I want separate code bases on separate machines to generate the equivalent checksum for the same transaction, so that they will know it is the same transaction, and the only value that I derive from ASN.1 is canonical per, so that I can define a canonical checksum for a data structure that is likely to be internally different on different machines with different compilers.
I can get that trivially from XRD, but getting it from ASN.1 seems to require proprietary tools with arcane licensing requirements that need a room full of lawyers.
I cannot find an open source tool that generates canonical per.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-17 19:58:32
@_author: James A. Donald 
@_subject: [Cryptography] Is ASN.1 still the thing? 
Append only file systems, in particular cryptocash, depend on such hash tree roots.
Decentralized append only file systems have several use cases, one being crypto cash, and one being squaring Zooko's triangle.  Namecoin, of course is a fork of bitcoin intended to apply the technology to square zooko's triangle.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-20 17:15:59
@_author: James A. Donald 
@_subject: [Cryptography] Is ASN.1 still the thing? 
I find that Apache Avro can do binary serialization to memory thus making possible hardware and compiler independent hashes, and also has RPC support in every major language, recently including node.js javascript, for HTTP, TCP, and WebSockets.
So it looks like Apache Avro might well work.  Definitely will work if it lives up to its self description.
digressing onto a closely related issue (related in that the primary application of global hashes is crypto currency and squaring Zooko's triangle) - the big problem with spki is that while information wants to be free, engineers want to be paid.  And servers cost money. A cryptocurrency system analogous to namecoin should be able to not only provide name reservation, the fourth corner of Zooko's triangle, as it does now, but also a mechanism to make nameservice widely available at a fee, which does not yet seem to be happening with namecoin.  One would think a system based on bitcoin could pay engineers. Is this happening?
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-21 05:51:26
@_author: James A. Donald 
@_subject: [Cryptography] Is ASN.1 still the thing? 
The huge problem is that people write decoders to deserialize arbitrary input, which necessarily includes inputs that you and your program never anticipated.  You don't want a decoder/desiralizer that can correctly decode/deserialize arbitrary input.  You want it to reject any input that you did not explicitly anticipate.
Rust has built in bounds checking, which in a well written rust program should in theory only incur compile time costs, but I looked at their deserializers, and they all use run time typing (which is run time costly) to handle arbitrary inputs.  It is not the run time cost that worries me, that is insignifcant compared to bandwidth costs.  It is the surprise run time types.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-22 04:20:45
@_author: James A. Donald 
@_subject: [Cryptography] [FORGED] Re: Is ASN.1 still the thing? 
I could not find a tool that would produce canonical byte aligned PER decoding and encoding on both Windows and Linux that did not involve a frightening and confusing license.
Let alone manage the sockets and protocol negotiation when forming a I have no plans to reinvent the wheel.  I am looking for a wheel someone else has built.  ASN/1 PER was the first thing I looked at. There seem to be an absurdly large number of wheels available, but ASN.1 PER is not one of them.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-22 16:21:39
@_author: James A. Donald 
@_subject: [Cryptography] Is ASN.1 still the thing? 
As I said, there are more serializer and deserializer systems around than I can shake stick at, and I have no intention of building yet another.
I don't want to reinvent the wheel.  I want a standard for wheels to protect me from having to think about what a wheel should look like, and a library that provides me with ready made working wheels.
And the first I looked at or, rather looked for, was ASN/1 byte aligned canonical per, it was the one I wanted to use, because it was the one that had been used for similar purpose already, and I could not find support for it.
ASN/1 has to compete with stuff like Apache Avro, and Apache Avro has, or at least claims to have, open source libraries to do all the stuff I want, plus stuff that future implementers might want to do with my stuff if it is a big success.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-27 14:34:57
@_author: James A. Donald 
@_subject: [Cryptography] Is ASN.1 still the thing? 
One of the reasons we have far too many serialization protocols is that we don't need a serialization protocol at all.  We don't want to serialize arbitrary data, because the whole point of serializing data is so that someone else can deserialize that data.  And he does not want to deserialize arbitrary data.  He wants to deserialize particular message types known in advance.
So, a serialization protocol needs to be part of, and an afterthought to, a message type negotiation that occurs when forming a connection, the sockets and protocol negotiation when forming a connection.  The two ends need to agree on a set of known message types that cannot represent arbitrary data, but can only represent a small set of object types known in advance to both ends at compile time.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-29 11:57:00
@_author: James A. Donald 
@_subject: [Cryptography] Intel Management Engine pwnd 
When used in accordance with official use, it listens on a certain port, like any other service.
But since normal code manages listening on ports, how does the management engine do this.  How does the management engine hook your tcp-ip stack?
For your tcp-ip stack is implemented by diverse operating systems in diverse hardware and software.
Suppose, for example, you installed ubuntu. Obviously your ubuntu software does not provide this port number and this service.  Your intel chip, in order to provide a service on that port, is going to have to do something the authors of Ubuntu did not expect.  What is it doing?  It is going to have to hack Ubuntu.  Listening on a port is not a chip level function.
This seems fragile, complex, and likely to break. Suppose you install an unexpected operating system.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-29 12:04:26
@_author: James A. Donald 
@_subject: [Cryptography] Intel Management Engine pwnd 
If you want to hook IP and USB packets to watch for a signal from outside to take action, the support chips is where you would be able to hook them.  You would not be able to hook them from the intel cpu itself.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-11-30 13:21:50
@_author: James A. Donald 
@_subject: [Cryptography] Intel Management Engine pwnd 
So it gets the packets before the operating system software does.
But can you avoid connecting that NIC?
I use the built in ethernet connector on the motherboard.  Pretty sure that those packets are being intercepted by the Intel Management Engine.
If I install a network interface controller purchased from Ebay, would that leave the Intel Management Engine high and dry?.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-12-01 13:25:41
@_author: James A. Donald 
@_subject: [Cryptography] Transparent remote file access 
============================== START ==============================
I am part of a group of people that are concerned that we might be survielled by Google and the United States Government, and our IT guy is planning to implement LDAP for single sign in.
Could you direct me to something that lists concerns?
As I understand it, LDAP is just a database optimized for certain kinds of lookups, which are the lookups one is apt to do when people sign in.
you seem to suggest that someone hostile might find the LDAP database handy and relatively easy to access and control.
The proposed LDAP database will be in the cloud, which does not strike me as a very good idea if one is worried about surveillance.  Should be in someone's closet, in a private home, with backups onto blueray from time to time, with blueray disks sent around by snail mail. But I am too lazy and busy to implement this myself, also I frequently travel, generally between one country with terrible internet, to another country with worse internet.  So someone else is implementing security in the cloud.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-10-03 21:04:32
@_author: James A. Donald 
@_subject: [Cryptography] Steemit 
Your id on bitcoin is your wallet public key, which is controlled by your secret key. Your id on steemit is linked to you phone number, which is linked by the state to your true name.  The weak link in bitcoin has been the exchanges, and Steemit is one big exchange.
Dapp?  What is Dapp?
Do you mean DPOS, Delegated Proof of Stake?
What are Bitshares?
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-10-03 21:10:19
@_author: James A. Donald 
@_subject: [Cryptography] Altcoin volume 
But Steemit has an actual product, has working software, has large numbers of real users using that software.  EOS just has a white paper, an idea for a product, an idea for software, that may never be completed, that is not really specified in sufficient detail to know if it is possible to complete it.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-10-15 18:12:24
@_author: James A. Donald 
@_subject: [Cryptography] filtering html 
An arbitrary and possibly hostile web page passes through proxy or a server, which makes a record of it.
Is there any easy way to filter that web page, stripping out javascript and links to outside images and such, so that record is guaranteed to display the same way, or closely equivalent way, as the original?
Seems to me this is a job for an html compiler, that you need to parse it, filter the parse tree, and then regenerate the vanilla html document from the parse tree.  Which sounds like a great deal of work.
But there are lots of services that allow one client to generate html that will be seen in their web page by another client.  Which gives Bob the potential to doing surprising things to Carol's subscription when Carol views content supplied by Bob, so this problem, or somewhat similar problems, must have been solved many times before, the problem of rendering html incapable of doing surprising things.

@_date: 2017-10-15 18:20:10
@_author: James A. Donald 
@_subject: [Cryptography] filtering html 
Sanitizing sql is not hard.
But how to you sanitize html?

@_date: 2017-10-15 18:43:29
@_author: James A. Donald 
@_subject: [Cryptography] filtering html 
It looks like Github Flavored Markdown is Github's solution to this problem.
Instead of attempting the Herculean task of sanitizing arbitrary user supplied html, they give the user a language that is less dangerously

@_date: 2017-10-27 14:53:52
@_author: James A. Donald 
@_subject: [Cryptography] filtering html 
The solutions proposed here in this thread are right on the money, and software to implement them is available.
Thanks everyone.
Ann's web page displays unrestricted web content to Bob, but if Ann's web page contains content controlled by Carol, Ann's server first castrates Carol's content using AntiSamy  before displaying it to Bob.  Which is conveniently already written, so I do not have to write it.  Runs in Javascript.
But what in fact worried me is that Bob would agree to and archive a page containing an offer by Ann, which would retroactively change.  I wanted not only for the page to be immutable, but for the display of the page to be immutable, and the solution to that one is PDF.  Ann's server has to convert its content to PDF, if the Bob's client is going to treat it as a potentially binding offer.
Bob's client will display Ann's offer to Bob using the wxWidget Pdfium, which is conveniently already written in C++
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-09-25 13:47:03
@_author: James A. Donald 
@_subject: [Cryptography] Altcoin volume 
Every website reporting on the altcoin boom and the initial coin offering boom  has an incentive to not look too closely at the claimed numbers.
Crypto currency is real, and presents the opportunity to make enormous amounts of money.  Also, scams are real, and present the opportunity to lose enormous amounts of money.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-09-25 19:50:03
@_author: James A. Donald 
@_subject: [Cryptography] Altcoin volume 
But EOS is not working just yet.  Their tokens are trading on the ethernet block chain.
EOS wants to get a rather large pile of ether before their cryptocurrency actually works or can do anything useful.
EOS is planned to be a proof of stake currency - but the tokens trading on ethereum have no voting power, and are not promised to have any voting power, so the EOS organization can simply blow off all investors.   Which looks mighty like a scam.
If EOS was actually working a proof of stake currency, then buying these coins would be somewhat similar to buying shares in the EOS project.
The way it should work is that an angel investor funds development to the point where he actually has a working proof of stake blockchain, then issues stake to himself, and to people working on the project, and to people promoting the use of the crypto coins, and proceeds to sell some of his stake to first round investors.  That would be a genuine initial coin offering. But this is not what EOS is doing.  All it has is a white paper.  If you buy into the EOS ICO, you are paying a mighty large amount of money for a white paper.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-09-25 11:28:31
@_author: James A. Donald 
@_subject: [Cryptography] Altcoin volume 
There can only be one.  Who is winning?
Well obviously bitcoin is winning, but bitcoin's flaws may bring it down, so which altcoin is best placed to replace it?
The winner needs to be a proof of stake currency, because transactions cost less and are faster, and it needs to facilitate communication and to provide identities and logins.
And because intelligent voting is a benefit to the community, but not to the individual, it needs to harvest behavior of stakeholders to provide witness election, as steamit does to some extent.
While proof of work currencies suffer from the problem that miners may not pursue the best interests of the currency, proof of stake currencies suffer from the problem that stakeholders may not vote in their best interests, that typically stakeholders do not vote at all, or vote Bitcoin is hitting its scaling limits hard, and is dependent on tolerance by the Chinese government.  But so long as the Chinese government is not too oppressive, it will remain the dominant (Digressing, as American capitalism comes to mean that the accounting and human resources departments are tentacles of the American state even in nominally independent nations, maybe we will soon call actual capitalism "socialism with Chinese characteristics")
Right now there are umpteen altcoins, most of them composed of hype and copies of the bitcoin software, some of them outright scams.
Information of the value of altcoin currency is not necessarily reliable, because of the dotcom boom density of scams and projects that wind up degenerating into scams.
Steam broke genuinely new ground, and EOS is in the same lineage. Unlike a lot of altcoins whose main goal is to separate speculators from their money, they deserve to succeed.  They are clearly better than bitcoin.
How are they doing?
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-09-25 12:27:44
@_author: James A. Donald 
@_subject: [Cryptography] Steemit 
According to Steemit documentation, it looks like a well designed cryptocurrency that deserves to replace Bitcoin.
Well, that is what it looks like.
Except its front end is the steemit.com website, and any one website can easily be seized by the feds.
If actually decentralized, should it not be a bunch of websites using a common crypto currency and a common identity system,
Remember usenet:  A common protocol, and an internal name system.  The particular host through which you accessed it did not matter all that much, because all hosts had to behave much the same.
Should not steemit be something like usenet with money?
The way usenet worked, anyone (meaning anyone's computer and his client program) could join as a client by having an agreement with a host, and anyone (meaning anyone's powerful and well connected computer system) could join as a host by having an agreement with a few existing members.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-09-25 13:04:53
@_author: James A. Donald 
@_subject: [Cryptography] Altcoin investing. 
It is clear that there are enormous profits to be made by producing a money that bypasses governments and the banking system
And enormous profits have been made
But because there is so much dumb money pouring in, we are seeing a lot of altcoins and Initial Coin Offerings for stuff that is not actually finished, or not actually working as designed yet, and may never work as supposedly intended and supposedly designed.
The altcoin that will win will be the one needs to be scalable all the way to Visa and Mastercard levels, and needs to be visibly decentralized and visibly resistant to state seizure.
Bitcoin was genuinely decentralized from the beginning, and over time became more centralized.
The new altcoin offering are for the most part not genuinely decentralized.  They have a plan for becoming genuinely decentralized some time in the future, but the will and ability to carry the plan through has not been demonstrated.
I like the steemit design.  The witness system is scalable, the witness voting system has problems which may be fixable, or may be inherent.
But I have a suspicion that investing in steemit is only going to profit whoever owns steemit.com, not the owners of steemit currency.
A successful altcoin needs to be a blogging platform like steemit, but it also needs to be a federation, like Usenet or Mastodon.
Then one could be more sure that success of the federation currency would benefit owners of the currency, rather than owners of a single central website.
Needs to be Mastodon with the ability to support a blog like post, and to send and receive money.  Steemit.com is wordpress.com with the ability to send and receive money.
Almost there, but not yet quite the right design.
Bitcoin has a decentralized name system, rooted in Zooko style names that are not human intelligible.  Its resistance to state power comes partly from the fact that there are several miners and anyone can be a miner, and partly from its decentralized name system.
Steemit has a communication and blogging system.  But if I hold steemit currency, steemit.com connects that to my phone number, which the government connects to my true name.   All that handy dandy data that the government would like all in one place that you can serve a warrant on or mount a raid on.
Need a *decentralized* communication and blogging system, unlike Steemit.com's centralized communication and blogging system, and a name system that is resistant to government intervention and control, like Bitcoin's name system.
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-09-25 13:43:17
@_author: James A. Donald 
@_subject: [Cryptography] Altcoin volume 
There is an obvious huge problem with the data posted, in that all altcoins have an incentive to inflate their market value and volume.
It is easy to issue a million units of an altcoin, and have six sox puppets transferring thousands of units back and forth at hugely inflated prices, while actual users only hold a few thousand units and rarely transact.
Steem and bitcoin have large numbers of real users.  Who are the real users of ethereum?
This email has been checked for viruses by Avast antivirus software.

@_date: 2017-09-28 14:34:58
@_author: James A. Donald 
@_subject: [Cryptography] Zcash 
============================== START ==============================
 > proofs to achieve privacy-preserving payments in a Bitcoin-like
 > system. This protocol was recently deployed in the wild, as part
 > of the cryptocurrency Zcash.
I don't find this talk very informative.  Does not explain in sufficient detail that I could implement it, does not tell me how much extra storage and processing power is required in peers that store and check the entire blockchain.
Is there a white paper or web page that explains the underlying technology in ZCash, how it works, how it scales, what it costs?
Sounds like standard Chaumian cash embedded in the blockchain, and Chaumian cash is storage heavy and requires excessive levels of trust.
This email has been checked for viruses by Avast antivirus software.

@_date: 2018-08-06 14:11:43
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Krugman blockchain currency skepticism 
The downside of Chaumian e-cash is very simple.  You need a single centralized trusted server holding a small number unshared secrets.  At two in the morning Mueller kicks down your door and demands you alter the behavior of your server in ways that make it profoundly untrustworthy.  While he is at, holds a gun to your head and takes the secrets, charges you with tax fraud, money laundering, etc, and puts you in solitary confinement pending trial so as to make it impossible to organize your defense.
A crypto currency needs to be centerless - it needs to able to survive the seizure of key servers by a hostile powerful party.
Trouble with bitcoin is that it is not centerless - proof of work winds up being centralized in a small number of extremely powerful and extremely expensive computers.
Thus we need a system with proof of stake, and not only proof of stake, but proof of client stake - the power over the system needs to reside with peers that have a lot of wealthy clients - and it needs to be hard to find who the clients are, and where they are keeping their secrets, so that even if Mueller seizes important peers on charges of tax evasion and money laundering, does not thereby gain control.

@_date: 2018-08-06 14:31:30
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Krugman blockchain currency skepticism 
If the system handles an enormous number of transactions, peers are going to be big and expensive, thus vulnerable to people like Mueller armed with vague and open ended charges of tax evasion and money laundering.  Hence the power of peer over the currency needs to be proportional to the wealth controlled by the secrets held by that peer's clients.  And that peer's clients need to be free to move from one peer to the next, and apt to move to peers that make it difficult for Mueller to find their clients.

@_date: 2018-08-06 14:34:11
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Krugman blockchain currency skepticism 
Crypto currency  took off when quasi governmental payment processors started freezing the accounts of "Nazis".
Took off when it was solving a very real problem.

@_date: 2018-08-07 07:08:27
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Krugman blockchain currency skepticism 
Threshold cryptography neither scales nor helps.
Crytocurrency took off when quasi state entities started freezing the accounts of "Nazis".
Therefore that is the problem we want to solve.
The government *is* targeting activist group's finances, which targeting has directly caused the boom in crypto currency.
If you have a payment system that allows the politically incorrect to buy and sell, the government will attack the entire payment system, as it did with e-gold and is now attempting to do with crypto currency. Crypto currency is not being shut down, but conversion between cash and crypto currency that is not linked to a tax file number is being shut down.  If that fails to have the desired result, expect further escalation.
And he causeth all, both small and great, rich and poor, free and bond, to receive a mark in their right hand, or in their foreheads:
And that no man might buy or sell, save he that had the mark, or the name of the beast, or the number of his name.
The government has been trying to shut BitTorrent down.  How is that working out for them?
Cryptocurrency is difficult to shut down, short of turning off the entire internet.  Or it could be if done right.  Everyone in the world with sufficient money or connections seems to be able to get onto a vpn.
If it is decentralized, the only way to attack is to go for end users, and hard to stop end users short of taking them off the internet altogether, short of shutting down the internet itself altogether.

@_date: 2018-08-11 13:12:51
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Krugman blockchain currency skepticism 
We don't have to protect *all* nodes.  That is the point of a decentralized system - that the government can take some nodes, and it does not make much difference.
Trouble with bitcoin is that taking a small number of expensive and vulnerable mining nodes would work.
Hence I argue for proof of stake with stake held by clients of blockchain peers, and power exercised by peers in proportion to the stake of a peer's clients, rather than proof of work with power exercised by gigantic and expensive number crunching systems.  If Government takes a big peer, its clients move elsewhere, it ceases to be a big peer,and some other peers in some other jurisdictions take over its role.

@_date: 2018-08-23 13:40:19
@_author: jamesd@echeque.com 
@_subject: [Cryptography] "Incremental" DH Key exchange ?? 
What does that buy you?
Why do you want to establish a shared secret in this way?

@_date: 2018-08-31 08:02:48
@_author: jamesd@echeque.com 
@_subject: [Cryptography] WireGuard 
The first time you connect to a new machine there is nothing at stake, and it is hard for potential enemies to detect you even if there is something at stake.
If they launched a man in the middle attack on everyone, would be detected.  If they only launch man in the middle attacks on persons of interest, key continuity suffices, since a person of interest is likely somewhat paranoid, and by the time they come after him, has probably established key continuity.

@_date: 2018-12-30 13:33:29
@_author: jamesd@echeque.com 
@_subject: [Cryptography] blake2b 160 
I have an application that requires that no one can ever produce a hash collision on two data blocks of moderate size.
Seems to me that Blake2b 160 suffices, and Blake2b 256 is overkill.
Someone claimed its easy to produce collisions and sprayed what sounded to me like random technobabble in support of that claim.
So, for a given number of bits in the hash, how much time and resources are required to produce two blocks of data of moderate size such that the last n bits of the hash are the same for both blocks?
If someone wants to say it is easy, that it does not take all that much time and resources, I would like to hear an explanation that sounds like a description of an algorithm, an algorithm described in detail sufficient I could test it to produce a collision in the last sixty or so bits of the hash.

@_date: 2018-02-06 17:26:31
@_author: jamesd@echeque.com 
@_subject: [Cryptography] canonicalizing unicode strings. 
Well, I was asking where I could find writings and off the shelf solutions.
It would be a whole lot easier to do my homework if you could point me to existing documentation and existing solutions in a more specific manner.

@_date: 2018-02-06 17:46:27
@_author: jamesd@echeque.com 
@_subject: [Cryptography] canonicalizing unicode strings. 
This link is extremely useful, but does not address the homoglyph problem.
It ensures that unicode strings that are logically equivalent, intended to represent the same sequence of characters, are represented by the same sequence of bits.
It does not address the problem of unicode strings that are logically inequivalent, but which look similar, for example:
1  l,
-  
  
0  O
  o

@_date: 2018-02-06 21:11:47
@_author: jamesd@echeque.com 
@_subject: [Cryptography] How slow is pairing based crypto compared to 25519 
The fastest library I can find for pairing based crypto is How does this compare to Curve25519 The trouble is that doing interesting things with crypto currency tends to involve rather large number of elliptic curve operations per transaction.

@_date: 2018-02-07 08:56:14
@_author: jamesd@echeque.com 
@_subject: [Cryptography] How slow is pairing based crypto compared to 
Not seeing any references to the Herumi library in that document, nor any evaluations of the time required for pairing based cryptography in that document.  Relic-Toolkit is not Herumi and is supposedly markedly slower than Herumi
Looks like I will have to compile the libraries myself and run tests on

@_date: 2018-02-07 07:38:05
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Proof of Work is the worst way to do a BlockChain 
Actually governments and bankers are evil and untrustworthy, and the burdens of using trust mediated by bankers and governments to do business are rapidly becoming intolerable.  Accounting and HR have become vast and onerous bureaucracies, burdensome tentacles of the state in every business, making businesses larger than a family and smaller than giant multinational corporation with a skyscraper full of Harvard lawyers each drawing $300 per hour, increasingly impractical
Yes, proof of work is a terrible idea.
But we need to replace it with something better than bankers and government.
I have been working on it, but the result always implies pre-mining, that existing owners of currency are like shareholders in an existing business, which is politically unpopular right now, though I may well go right ahead with it anyway.

@_date: 2018-02-07 07:44:25
@_author: jamesd@echeque.com 
@_subject: [Cryptography] RISC-V branch predicting 
This absolutely fixes the problem.  Have a compiler that accepts branch optimization hints and makes its best guess if it does not have them, have a profiler that generates optimization hints and inserts them in code, and abandon the smart branch prediction, replacing it with explicit branch prediction.  Have a code editor that optionally hides the optimization hints generated by the profiler.
In those parts of the code where speculative execution could have bad results, you tell it to take the path that leaks nothing, or to not speculate at all.

@_date: 2018-02-08 09:02:00
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Proof of Work is the worst way to do a BlockChain 
Need open entry into the "cabal", as well as cooperation and secure efficient transactions between competing cabals, so that there is no very strong difference between a competing cabal and a side chain.  The cabal should consist of peers in good standing, where the block chain records a peer's provision of data storage and bandwidth to the chain, and a peer loses good standing if he deviates from the rules.
Money should be controlled by client wallets hosted by peers, but each transaction output should be associated with a peer, albeit a client wallet can change the association without the cooperation of a peer.  To be a peer in good standing requires that the peer hosts transaction outputs worth substantial value, as well as requiring that the peer provides substantial bandwidth, storage, and up time.
The definitive version of the blockchain should rest on the vote of the peers in good standing, and the number of peers in good standing should be a lot larger than the existing number of dominant mining pools, but should not be enormously large, perhaps a few thousand peers, a hundred or so peers in good standing, hosting billions of wallets and hundreds of billions of unspent transaction outputs.
Normally one peer in good standing, primus inter pares, is approved to provide definitive approval of the final state of a block, and what he says goes, except that at any time any of the other peers in good standing can launch a delay, and hold a vote for a new primus inter pares.
The decision of the primus inter pares becomes effective and final when evidence is generated, and stored in the block chain, that a majority of the other peers in good standing have seen and acknowledged the decision. This is in effect yet another variant of the Paxos protocol.

@_date: 2018-02-08 09:54:27
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Proof of Work is the worst way to do a BlockChain 
Western civilization is based on double entry accounting, the joint stock corporation, and the scientific method, all of which have come under massive attack.
Crypto currencies need to make accounting and corporations workable again, and are needed for this purpose - hence the ICO, the initial coin offering, as for example the GAB initial coin offering.
The joint stock corporation has always existed, and our earliest records of them come from the time of the Roman Empire in the West, but before Charles the Second they were grants of Kingly power to private individuals for state purposes - they were socialism.
Under Charles the Second, they were still theoretically socialism, but now it was expected and high status to get rich in the course of pursuing state purposes, socialism similar to "Socialism with Chinese characteristics" or "The party decides what communism is"
Under Charles the second we first see the Randian Hero Engineer CEO, using other people's money and other people's labor to advance technology and apply technological advance to the creation of value. There was a sort of Silicon Valley under Charles the second, but instead of laying down optical fiber they were laying down canals and conquering the indies.
During late Victorian times, we see the corporation become wholly private.  Corporations are now people, a situation parodied by Gilbert and Sullivan - but at the same time, we see the regulatory state rendering them socialist again by the back door, a problem starting in Victorian times, and now getting out of control.
Human Resources has long been an ever more burdensome branch of the socialist state inserted parasitically into every business, and Sarbannes Oxley has now destroyed double entry accounting, which is fundamental to the survival of western civilization.
Instead of the accountant discovering how things really are so that the CEO can pursue the board's objectives, the accountant decides on official truth, whereupon the CEO has to bring reality into line with the official truth of the ever growing, ever more expensive, and ever more powerful accounting department or go to jail.  Under Sarbannes Oxley, the tail wags the dog.  Instead of monitoring actual reality, accounting decides on official reality.
Gab's initial coin offering, Gab's ICO, is a way to avoid Sarbannes Oxley.
We need to construct crypto currency around this function.  The original intent was for buying drugs, buying guns, violating copyright, illegal money transfer, and capital flight.
These are all important and we need to support them all, especially capital flight and buying guns under repressive regimes.  But now we see big demand for crypto currencies to support a replacement for Charles the Second's corporate form, which is being destroyed by HR, and to restore double entry accounting, which is being destroyed by Sarbannes

@_date: 2018-02-13 14:01:37
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Proof of Work is the worst way to do a BlockChain 
Several American banks have robbed me and served me poorly, particularly with regard to iras and international transactions.
A number of people deemed enemies of the state, most notably wikileaks, were forced into cryptocurrency early by having their funds in quasi statal institutions (banks, paypale, etc) frozen, and lots of people have had their crypto currency frozen by quasi governmental crypto currency exchanges.
And in the Great Minority Morgtage Meldown, they served everyone very poorly and robbed large numbers of people.
In a big holiness spiral the banks competed each to lend more money to non Asian minorities than the other, the big winner being Countrywide, which was rewarded for its superior holiness by being enabled by the regulators to take over other banks with depositor money.
Competing each to lend more money to minorities than the other, they proceeded to make million dollar mortgage loans to cat eating wetbacks with no income, no job, no assets, and no credit rating.
They unloaded most of these dud mortgages on Fannie, which is to say the taxpayer, Freddie, which is to say the taxpayer, and on the Mortgage Derivative market, which is to say they swindled individual investors, though China was compensated by the American taxpayer for the money that the banks swindled out of them.
 From 2005 November to late in 2007, banks were still unloading dud mortgages at near face value on the mortgage derivative market, but investors who bought these derivatives at near the face value of the underlying mortgages found that they could not resell them, that prices in the derivative market were fake.  Every mortgage derivative sale from 2005 November onwards was a bare faced swindle.
Swindling very large numbers of people out of very large amounts of money was deemed OK, because done in the holy social justice cause of getting non asian minorities to occupy houses in leafy green suburbs.
And now we are seeing a bunch of crypto currencies sponsored by quasi state entities in Green Energy, female emancipation, etc, which seem likely to retread the path trodden by the Mortgage Derivative Market.

@_date: 2018-02-16 09:52:32
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Quantum computers will never overcome noise 
Any technology useful for processing information in the extreme quantum domain is also useful for doing classical extremely fast at extremely low energies, operating in the near quantum domain.  Since we are nowhere near the near quantum domain, hard to say what will happen when and if we get there.
We are currently stuck building circuits with 190 nanometer near UV light, which means that quantum effects are down deep in the noise.
What we would like to be able to do is to construct circuits out of nanoscale superconducting wires, superconducting wires that are in fact large molecules.  At that point, it would become more apparent what was Any technology useful for implementing quantum computers, would also be useful for implementing classical computers at enormously greater speeds and lower energies than today's classical computers.
We need something better than 190 nanometer photolithography.

@_date: 2018-02-17 08:49:16
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Quantum computers will never overcome noise 
If you were familiar with the physics, you would know the justification.
Here is a hint:  What are the units of the Plank constant?

@_date: 2018-02-18 22:13:35
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Proof of Work is the worst way to do a BlockChain 
There is a huge amount of low profit-margin spam.
However a better system would be pay to send, be paid to receive.  Then people would honeypot the spammers.
Crypto currency payments tend to be massively replicated to avoid various failure modes, but obviously this is uneconomic for micropayments, which problem can be fixed by aggregating very small payments through single peer sidechains.  You would have to trust the single peer, but you are only trusting him for modest amounts.

@_date: 2018-02-23 15:56:22
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Proof of Work is the worst way to do a BlockChain 
2018-02-13 9:01 GMT+03:00 >:
> However, this does not change the fact that Turkish banks have not done
"Proven to be fraudulent"
"in jail"
You are quite sure that Turkish banks have not done the same thing in your entire mortgage history?

@_date: 2018-02-23 17:43:48
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Proof of Work is the worst way to do a BlockChain 
In the aftermath of the Great Minority Mortgage Meltdown, there no end of people saying "No, it was not due to minorities, it was not due to mortgages, it was due to derivatives (which is sort of true, but the problem with the derivatives was that the underlying mortgages were ninja loans: "no income, no job, no assets")
So, you did not have a problem with dud mortgages in Turkey.  Just some other problem.  But it does not sound like having banks operate one's monetary system is such a great idea, here or in Turkey.
Banks, notaries, accountants, lawyers, judges, they are all in the trust business - and sooner or later a scandal hits, and they run to the government - an organization not all that famous for trustworthiness.

@_date: 2018-02-24 03:26:48
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Proof of Work is the worst way to do a BlockChain 
2018-02-23 12:43 GMT+03:00 >:
The set of people who will use what we provide, if we provide a way around government, accountants, human resource departments, and banks, is an overwhelming majority.
There are things terribly wrong with Satoshi's  design.  It hitting scaling limits hard.  But it revealed huge demand.
Bitcoin may conquer the world, but if it does not, it will have been the napster of its time, showing us the way of the future.

@_date: 2018-02-25 13:22:16
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Proof of Work is the worst way to do a BlockChain 
Suppose a limited set of wealthy and powerful people have the necessary resources to check the whole blockchain - and several such people, subject to different nuclear umbrellas, with server farms in separate nuclear umbrellas, have done so.  You might decide to trust them for all transactions up a month or so ago, and only check more recent transactions.
OK. What is your design?  (I have a proof of stake mechanism cooking, which solves the miner problem)

@_date: 2018-01-02 06:17:22
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Hashgraph 
Obviously a patented technology cannot give us what we want, and the patent is an indication that the creators of this technology have absolutely no intention of giving us what we want.
If they intended to give us what we want, they would rely on first mover advantage, not patents.

@_date: 2018-01-03 09:43:57
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Hashgraph 
Well, if hashgraph is released unencumbered ...
And, indeed, if I had the patent, and was serious about cashing it in, I would release the payment unencumbered after achieving a substantial first mover advantage.   Because no sensible end user would use money encumbered by a patent on the means for paying and being paid.

@_date: 2018-01-04 11:16:06
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Hashgraph 
Then their investors are morons, for the winning cryptocurrency will get everything, the losers will get the smell of an oilrag, and a patent greatly diminishes your chances of being the winner.

@_date: 2018-01-04 11:24:50
@_author: jamesd@echeque.com 
@_subject: [Cryptography] NSA seeing large exodus? 
Not seeing this.  From what little I know about the NSA, seems to be losing idiots and people hired for their impressive qualifications in intersectional feminism.
If you want to hire a political commissar, NSA refugees are just what you need.

@_date: 2018-01-05 07:32:22
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Speculation re Intel HW cockup; 
The problem is speculative instructions leaking memory between privilege levels.  There is no intrinsic hardware or efficiency reason why this has to happen.
There is an efficiency reason why we need speculative execution - there is no efficiency reason why we cannot do a satisfactory job of unwinding the speculation when it turns out to be in error.
It is a bug in speculative execution.  The fix is not to abandon speculative execution, but to do it right, and chances are that doing it right is going to be faster and more efficient, not slower and less Not using speculative execution, because it is broken, is a huge efficiency hit, slows things down a lot.
Not breaking speculative execution is unlikely to slow stuff down, and is likely to speed stuff up.

@_date: 2018-01-05 11:02:14
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Speculation re Intel HW cockup; 
All speculative effects would be copy on write.  Same principle as is used in vm snapshotting.
If the copy on write buffer overflows, we pause to backup to a lower caching level.

@_date: 2018-01-05 14:25:38
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Speculation re Intel HW cockup; 
All user mode processes are necessarily inside what is in fact a VM.  A VM does not necessarily get to see side channels.
The side effects are for the most part variants on one process data cache hits are affected by another processes data cache hits - which should never happen in normal non evil code.  Separate processes normally have disjoint data.
Because this is something that should not ordinarily happen,  we can afford to do something special if it does happen.
Another variant:  Speculative path on one process is determined by speculative path on another process executing the same code.  And then the evil process looks at what gets cached as a result of influencing the speculative path of the other code.  Should not be able to see what gets cached.
Since there is a limited amount of cache memory, it is going to be able to see that how much is cached is affected by its influence on the speculative path, but this is not a terribly alarming leak.  It is something that high security code can be written around.

@_date: 2018-01-05 17:02:33
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Speculation considered harmful? 
Single thread of execution maxed out a long time ago.
We still have not figured out how to take proper advantage of multi core and multi thread.
But we are improving our ability to deal with distributed processing. In principle, most problem domains could be dealt with by a swarm of puny cores.  It is just that we lack a suitable language and a suitable processing model.  C++ is still struggling to integrate multi processing into the model computer that the compiler targets.
Node.js, an interpreted Javascript language, has a good start on the problem, as do the latest operating systems implementing mapreduce,
C++ and Rust are still wandering lost in the woods, despite their gigantic efficiency advantage over interpreted Javascript.
Mapreduce frequently gives stupendously poor performance, even though it is scalable.  We don't have a high level way of addressing multiprocessing.

@_date: 2018-01-05 17:12:56
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Speculation re Intel HW cockup; 
Indeed loading stuff into cache on speculative execution increases your working set, so arguably there are efficiency grounds for not speculatively hitting the cache.
If you need to load stuff into cache, your speculative execution is going to be delayed, does not buy you much.  Worst case, your speculative execution is delayed by a cache miss, and then turns out to be wrong, then you take the the correct path - and it has a cache miss again because your speculative execution ejected the needed value from

@_date: 2018-01-07 19:13:06
@_author: jamesd@echeque.com 
@_subject: [Cryptography] NSA seeing large exodus? 
If I had to guess, I would say that the people the NSA is losing are neither crypto specialists, nor computer engineers.

@_date: 2018-01-08 13:14:23
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Speculation considered harmful? 
Eviction does not need to be a very informative side effect.

@_date: 2018-01-09 18:24:42
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Speculation considered harmful? 
We are moving towards a sea of machines connected by a network - shared nothing message passing.
This reduces the problem to something manageable.

@_date: 2018-01-11 14:02:02
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Speculation considered harmful? 
C++14 broke compatibility with C++98 all over the place, in the course of supporting automatic memory management.  Everyone is nonetheless switching from C++98 to C++14, and only a few people encounter issues.
Of course it helps that anyone recompiling is probably sufficiently competent and knowledgeable to fix an issue when it arises.
The way windows handles this problem is that it has a long, long, long, list of popular existing software that relies on old Window bugs, and then special cases each such program.

@_date: 2018-01-11 15:09:47
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Speculation considered harmful? 
Shared pointers, unique pointers, and weak pointers, the related RIAA, and the related and ensuing initialization issues for the standard template library, which required considerable improvement in metacompilation capability.  You can now execute most C++ code while metacompiling.  Not as capable or elegant as lisp metacomplation, which has no real difference between compilation and metacompilation, but walking the same path.

@_date: 2018-01-14 21:19:18
@_author: jamesd@echeque.com 
@_subject: [Cryptography] canonicalizing unicode strings. 
I would like strings that look similar to humans to map to the same item. Obviously trailing and leading whitespace needs to go, and whitespace map a single space.
The hard part, however is that unicode has an enormous number of near duplicate symbols.
Is there somewhere a list of near duplicate unicode symbols, or existing canonicalization code?

@_date: 2018-01-15 19:34:56
@_author: jamesd@echeque.com 
@_subject: [Cryptography] canonicalizing unicode strings. 
I am going to have to use NFKC canonical form for the key, and NFC canonical form for the display of the key.
Which once in a blue moon will drive someone crazy.  "Its broken" he will say

@_date: 2018-01-29 09:15:19
@_author: jamesd@echeque.com 
@_subject: [Cryptography] DAG vs Blockchain 
What is supposed to happen is that the blockchain contains metadata about merges of data by peers, and thus metadata about what data is approved by which peers.
By examining the Dag, one can prove that a majority of peers in good standing who have authority over a majority of the value represented by the block chain, have approved one past history of the blockchain, and not other past histories.
That proof of majority approval of data and metadata gets permanently stored in the blockchain, and conflicting versions of the past history of the blockchain, together with conflicting approvals of that history by minorities of peers, are discarded.

@_date: 2018-01-29 10:49:03
@_author: jamesd@echeque.com 
@_subject: [Cryptography] US contemplating its p0wn Great FireWall for 5G 
Not seeing a whole lot of freedom of speech on the US internet.  Twitter censors "nazis" and "racists" and "sexists" and "trolls"
Google and Snopes promote fake news and suppress news and evidence that contradicts fake news.
Facebook does both.
On the whole, Chinese overt and official censorship is more free than our officially unofficial censorship.  Knowing what you are forbidden to say is a breath of fresh air compared to being forbidden to know what you are forbidden to say.
Further, Chinese overt and official censorship does not gaslight us with a fake consensus the way Google's promotion of fake news and fake consensus does.  The Chinese Party tells us that the party view is X, and you will agree if you know what is good for you, Google tells us that everyone's view is X, and if you disagree you must be ignorant, stupid, crazy, and evil.
If you want to beat the officially regulated Chinese internet, need to beat it with freedom and truth, not with an officially unofficially regulated internet.

@_date: 2018-01-29 17:05:10
@_author: jamesd@echeque.com 
@_subject: [Cryptography] DAG vs Blockchain 
DAG as implemented is faster because de-facto centralized, like a thousand other scam crypto currencies.  This is bad, because state power can command the center.  It has one neck that nero can cut.
But it does not have to be that way.

@_date: 2018-01-29 19:00:07
@_author: jamesd@echeque.com 
@_subject: [Cryptography] US contemplating its p0wn Great FireWall for 5G 
Clarity is impossible, since Twitter's censorship, unlike China's, is itself censored.

@_date: 2018-01-29 19:19:09
@_author: jamesd@echeque.com 
@_subject: [Cryptography] US contemplating its p0wn Great FireWall for 5G 
Damore lost his job and was black listed for saying what he wanted.
You think the Hollywood blacklist was the total destruction of democracy, but what is happening now in the US is just fine.

@_date: 2018-01-29 19:28:38
@_author: jamesd@echeque.com 
@_subject: [Cryptography] US contemplating its p0wn Great FireWall for 5G 
It is not just that the search results are largely different, it is that if you read them you will notice that everything in Google's search results is at best deceptive spin, at worst a lie, it is that Google's search results omit all the information that actually matters, it is that Google is gaslighting you, it is that Google's search results are profoundly and deceptively incomplete.

@_date: 2018-01-30 12:04:58
@_author: jamesd@echeque.com 
@_subject: [Cryptography] US contemplating its p0wn Great FireWall for 5G 
On some matters, some questions, some controversies, the profound dishonesty of Google's bias is not obvious.  So I chose a controversy where Google's bias was both obvious and entirely indefensible.
To figure out what is spin and what is not spin read what is in the links.
Google presents only one side of a controversy, or presents a fake account of the dispute where the dispute is merely between two slightly different versions of the same extreme. So I chose a topic where the side that Google supports has not got a leg to stand on.
Duckduckgo presents both sides of a controversy, and neutral reports that give the facts straight down the middle.  Google presents only one side
And, if you read both sides of this controversy, it becomes completely obvious that every single link provided by Google on this issue is profoundly deceptive, dishonest, and misleading - because I specifically chose a topic where the only way that you could possibly toe the Google/State Department/NYT line is to be profoundly deceptive, dishonest, and misleading.

@_date: 2018-01-30 12:27:39
@_author: jamesd@echeque.com 
@_subject: [Cryptography] canonicalizing unicode strings. 
Glancing at those details, I am pretty sure that there are always legitimate reasons to mix Latin script characters with any other script, or imperial Aramaic with Aramaic, etc.
The attribution of characters to a particular script is acknowledged to be substantially artificial, capricious, uncertain, and arbitrary.

@_date: 2018-01-30 12:50:28
@_author: jamesd@echeque.com 
@_subject: [Cryptography] US contemplating its p0wn Great FireWall for 5G 
Tried the experiment. Bing gave similar results to DuckDuckGo, but not identical.  Big and DuckDuckGo covered both sides of the controversy, Google only gave one side.  However, DuckDuckGo was marginally fairer than Bing, perhaps because of random variation.

@_date: 2018-01-31 17:04:18
@_author: jamesd@echeque.com 
@_subject: [Cryptography] canonicalizing unicode strings. 
Attempts to restrict people to only using one script in an identifier are not going to fly, but if someone uses more than one script, we need to check against all potentially conflicting identifiers for homoglyphs.
To efficiently check for homoglyphic identifiers, have to canonicalize all homoglyphs -
1  l,
-  
  
0  O
  o
I suspect there is a zillion of them.
And no official list of homoglyphs, or official software to canonicalize Need to write a program that prints them out to an image file, then automatically searches the image file for near matches - which will not correctly spot anything that would look like a match to a human, but will get a lot of them.  A human would have to do final cleanup on the output of the software.

@_date: 2018-03-05 00:21:31
@_author: jamesd@echeque.com 
@_subject: [Cryptography] WSJ.com: SEC Launches C*****currency Probe 
Pretty sure that Monero and similar currencies are indeed cryptographic currencies, since they use cryptography to mix currencies and hide amounts - and the use of mathematical algorithms to hide information from potentially hostile parties is cryptography.

@_date: 2018-03-11 00:57:48
@_author: jamesd@echeque.com 
@_subject: [Cryptography] On those spoofed domain names... 
The solution is obvious:
Map every domain to a canonical look alike
If your domain maps to the same canonical look alike as an existing domain, you should not be allowed to register it.
We have software for detecting look alikes, though it is in javascript, not C++.

@_date: 2018-03-25 15:52:46
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Does RISC V solve Spectre ? 
Changing the compiler is easier than changing the CPU.
Looks to me that the only reason for doing the changes in the CPU is because that is private intellectual property, while changes in the compiler are going to get covered by the GNU license.

@_date: 2018-03-27 03:49:10
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Justice Dept. Revives Push to Mandate a Way to 
Stego beats rubber hose.
Minimize use of cleartext headers so that they will not know where to apply the rubber hose.

@_date: 2018-03-27 17:48:44
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Justice Dept. Revives Push to Mandate a Way to 
What part of "steganographic" is unclear?
If steganographic software is illegal, it is going to be embedded in minecraft or solitaire.

@_date: 2018-03-30 06:36:44
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Justice Dept. Revives Push to Mandate a Way to 
That you have secrets worth killing for is hard to detect at the best of times, and you can make it a good deal harder.
But in any case, not going to kill you for your secrets.  The government is far more interested in detecting which people have secrets, than in forcibly extracting those secrets.
Similarly with their efforts to suppress Christianity, they are not so much throwing Christians to the lions, as making Christianity inconvenient and low status - if you want to continue being a Roman Catholic, and not celebrate adultery, gay sex, and transsexual prostitution, if you don't want to have female headship preached at your wedding, have to find a Latin Mass Church and attend that, which is perfectly legal, and will not even get you fired, but which most people will not do.
It is not that they demand your secrets on pain of being thrown to the lions.  They demand your secrets on pain of minor inconvenience.
Whatsapp two party encryption is secure and easy to use, but they have as default automatic backup in the clear to Google servers, where google AI will go through your data looking for interesting things.  Lately automatic backup in the clear to Google has been added to all sorts of things, for example Viber, while other forms of backup have been made more difficult.
Whatsapp group chat is also insecure, in that the servers can invisibly add themselves or the NSA to the group chat.
Signal group chat is secure, and does not get backed up by default. (Losing potentially inconvenient data is a feature, not a bug), but there are approximately one thousand times as many Whatsapp users as signal users.
Whatsapp one on one chat is secure, but that is mainly because the security agencies get the metadata, being more interested in who you are chatting with, than what you are chatting about.
They are not going to kill you for your secrets, just make keeping secrets somewhat inconvenient, just as they are not going to throw Christians to the lions, just make practicing actual Christianity somewhat inconvenient.
By making secrecy mildly inconvenient, people practicing actual secrecy stick out, the government collects the metadata on people practicing actual secrecy and then they pay attention to those people.  But torturing those people into revealing their secrets would reveal the tracking, would reveal what the government is paying attention to, so they don't do that and are unlikely to do that.

@_date: 2018-05-06 09:13:00
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Cryptographic challenge 
Assume that each party that is entitled to access the data has a well known public key, identified under the Zooko triangle scheme, or the Zooko quadrangle/namecoin scheme, where there is a consensus merkle patricia tree associating human readable names with keys.
Using the notation that the combination two points on an elliptic curve to give a third point on the same elliptic curve is denoted by addition, that points on the elliptic curve are denoted by capitals, that integers are denoted by lower case letters, and that adding the point P to itself n times is denoted by n*P.
Bob's secret key is b, his public key is b*G = B
Carol's secret key is c, her public key is c*G = C
Dave's secret key is d, his public key is d*G = D
We want to encrypt some data so that Bob, Carol, and Dave all have access to it, and there are no subliminal channels stored with the data.
In forming the group Bob plus Carol plus Dave, the group members create and make public the keys c*d*G, b*d*G, and b*c*G
The secret key for group data, that all members of the group can look at, is, b*c*d*G.
This procedure has no forward secrecy.  To obtain forward secrecy, group members from time to time generate new transient keys signed by their durable keys.

@_date: 2018-05-06 10:55:38
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Cryptographic challenge 
This challenge seems rather pointless, because for forward secrecy, always want ephemeral keys, and ephemeral keys always provide the possibility of a hidden channel.
Hidden channels are a weak security threat, because if we don't trust one of the participants, we are hosed regardless.  The point of cryptography is to keep insider information inside.  If you have an entryist, you are toast.

@_date: 2018-05-09 08:15:45
@_author: jamesd@echeque.com 
@_subject: [Cryptography] secure authentication ... as opposed to passwords 
UI issue:  Zero Knowledge Authentication should occur in the chrome, not in a web page issued by the server that can easily be emulated by any other server.
The window in which you type anything that the attacker might want to steal should look and act differently from anything that the attacker can easily fake.

@_date: 2018-11-01 17:23:30
@_author: jamesd@echeque.com 
@_subject: [Cryptography] hash size 
You are not searching 2^64 examples against a single bit pattern.
You are searching 2^64 examples against 2^64 examples.
So, a single server rack with thirty million sixteen terabyte hard disks.

@_date: 2018-10-03 14:43:07
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Elixxir 
He has done this dance before.  The previous Chaumian currency died of government intervention.
If he is walking eastwards, needs to explain why eastwards is going to be different this time.

@_date: 2018-10-04 08:29:49
@_author: jamesd@echeque.com 
@_subject: [Cryptography] IKE/ISAKMP/IPsec complexity by design 
I would phrase it slightly differently:
The IETF refused to cover the connection between cryptographic public keys (Zooko global identifiers) and human readable names.
And as a result, there is no clear way for the end user to know if his software is using the correct cryptographic key.

@_date: 2018-11-01 05:11:35
@_author: jamesd@echeque.com 
@_subject: [Cryptography] hash size 
What does a 256 bit hash get you that a 128 bit hash does not get you?
What attacks could be done on a 128 bit has that could not be done on a 256 bit hash?
With 128 bits, a birthday attack is just barely possible, in that someone could search 2^64 examples, but, supposing you don't care about birthday attacks, only about someone finding a pre-image or finding a new value that gives the same hash as someone else's hash, what do you get?

@_date: 2018-11-01 08:03:49
@_author: jamesd@echeque.com 
@_subject: [Cryptography] hash size 
Launching a birthday attack on a 128 bit hash would involve generating 2^64 hashes and sorting them.  This requires 3*2^67 bytes of disk.  The largest readily available hard disk is 16 terabytes, so this would require thirty million hard disks, which is only a concern for state level attacks on very high value targets, although with continued progress in hard disks, will come within range for normal attackers, but only if a birthday attack generates major value for the attacker.

@_date: 2018-11-01 08:20:04
@_author: jamesd@echeque.com 
@_subject: [Cryptography] hash size 
A block chain ledger should be implemented as a merkle patricia tree. You are buying a noticeable decrease in the size of that tree, and a corresponding increase in the speed at which a consensus can be generated.
But the speed improvement is only modest, and the human effort involved in discussing birthday attacks likely to be significant.
We need to ensure that it can never happen that two people see a different final consensus on which transactions are committed to the block chain, and which have been rolled back, but if the attack merely disrupts the process for generating that consensus with respect to the birthdayed transactions, a low value attack.  So 128 bit hashes are OK for flood filling transactions through the peers, but likely to be unacceptable for the authoritative merkle patricia tree of committed But less coding effort and fewer bugs if we use the same hash throughout, and truncate them during the flood fill.
So yes, you are right.  Since we sometimes have to use a 256 bit hash, might as well use a 256 bit hash all the time, and truncate where the savings matter, and collision attacks do not.

@_date: 2018-09-03 09:28:49
@_author: jamesd@echeque.com 
@_subject: [Cryptography] WireGuard 
Using technologies analogous to blockchain, (namecoin) we can make sure that everyone sees the same mapping between a human readable name and its cryptographic identifiers.  This problem now has a known solution.

@_date: 2018-09-03 17:50:56
@_author: jamesd@echeque.com 
@_subject: [Cryptography] WireGuard 
Paying, selling, and thus what happens when you die, are implementation details.  The security problem is what happens in the simplest possible case: when you live and you don't sell.
Forking is potentially a problem, if two people see different roots to the Merkle tree, and thus different mappings between public keys.
Everyone wants to use the same namespace as everyone else, thus forking is unlikely to be a problem in practice.
Suppose we use my preferred solution, a currency based on proof of stake.
And suppose a minority of stakeholders do not like the rules, and decide to fork.  Well, they are a minority, either by numbers, or by crypto currency wealth, power and importance, so who cares about their namespace?
In my design, any time you interact with someone to perform a transaction, if you have been split from them by a fork, you will get an error, so, in the event of a fork, you will soon discover there has been a fork, and you will have an incentive to use the main branch.
Suppose the government is displeased that some people are publishing bittorrent magnet links to copyrighted material, and forces a fork where, in the government favored branch, the names formerly used to publish magnet links are now mapped to the FBI.  People are going to notice, and go with the main branch, the government disfavored branch, where name transfers continue to be performed according to the rules favored by the majority of stakeholders.
This may well degenerate into an argument as to how much power the government can exercise over the internet, which our moderators have banned for going around in circles.  But, even if the government can successfully confiscate those names, which I doubt, it cannot intercept communications using those names with nobody noticing.  Successfully imposing a fork with the desired characteristics would be a big, disruptive, and noticeable event.

@_date: 2018-09-05 11:26:29
@_author: jamesd@echeque.com 
@_subject: [Cryptography] WireGuard 
What it gets you is that the mapping between human readable names and cryptographic identifiers cannot be changed secretively and unnoticeably for one connection, and then secretively and unnoticeably changed back without anyone noticing.

@_date: 2018-09-09 13:49:06
@_author: jamesd@echeque.com 
@_subject: [Cryptography] WireGuard 
IPSec relies on public keys, but identifies computers by their IP address.
Thus anything using IPSec has to provide a bunch of additional moving parts which are not exactly part of the standard.
IPSec is incomplete without a Zooko to network address translation standard, or a human readable name to Zooko plus network address standard.
And thus gets completed by everyone gluing their own matchsticks together in their own way

@_date: 2018-09-09 17:26:56
@_author: jamesd@echeque.com 
@_subject: [Cryptography] zero knowledge password proof. 
Case of interest is that the server is identified by knowledge of the private key corresponding to the server public key *and* knowledge of a secret derived from password in a one way process, (one way short of brute force search).  The client is identified by knowledge of the They prove this knowledge to each other by generating a shared secret, without revealing this information to each other, without any possibility of revealing this information if phished to login to the wrong server.
I find the RFC and the patents less than clear.  I understand the principles, and can easily whip up an algorithm, but need to be able to say "this is the official XYZ algorithm as documented at ABC by the well known cryptography expert so and so"
So, can someone point me to an intelligible algorithm description by a cryptography expert.  Or better still, code that I can lift wholesale?

@_date: 2018-09-23 20:04:02
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Elixxir 
Chaum is doing his own blockchain company:  Elixxir
Supposedly it will make everything wonderful, but how it is going to make everything wonderful is not altogether clear to me.  Does he actually explain the proposed technology in detail anywhere?
Many of the things he hopes to achieve seem like they will require some substantial centralization, which worsens the problem of state and quasi state threats against a crypto currency.  Not clear to me how he proposes to avoid centralization or address or mitigate the problems and dangers of centralization.  Does he discuss the problem of the state or the risks of centralization anywhere?
It is likely that to scale up crypto currency transaction volumes, and get reasonable settlement times, we are going to have to have some centralization.  The trick is going to be to have some centralization without recapitulating the the steps that got us to state issued central currencies, to centralize clearing without centralizing power over clearing.
Bitcoin has solved its transaction volume crisis, but is drifting towards state control.  Brave's attention tokens comply with the know your customer act, which means that they just recapitulate the quasi state internet of twitter, google, and facebook.  To avoid the quasi state internet, need a payment system for internet attention that defies Know Your Customer

@_date: 2018-09-25 10:09:28
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Elixxir 
> There's a 20 page white paper on their web site:
Chaum has done this dance before.  He needs to tell us why this time it is going to be different to the last time he issued a crypto currency.
My reading of this brief is that this is not a genuinely decentralized system:  There is a special entity "the system" that has powers and secrets that regular peers, hosts, and clients do not have, which enforces the protocol, and Rober Mueller can find this special entity and send in goons with guns and a warrant charging money laundering and financial fraud to kick down the door at dawn.
In a genuinely decentralized system, everyone follows the protocol merely because it is in each individual's interests to do so provided that everyone else follows the protocol, and if a large group decides to follow a different protocol, then they have forked the blockchain.
In a genuinely decentralized system, the government might force some people to follow a different protocol, but that protocol is likely to be unpopular, and it will be difficult for the government to force everyone to follow its preferred protocol.
In a genuinely decentralized system, "The system" is just that most people choose to install the standard software with the standard configuration so that they can inter-operate with other people who have also installed the standard software with the standard configuration. Chaum's "system" seems to be something else, something considerably more, and his white paper is rather vague on what it is.
Hence the 51% attack is inherent in decentralization.  Any consensus is ultimately a consensus of machines following human orders, and thus ultimately a consensus of humans, and any human consensus necessarily has the usual well known problems.
What is going to happen to this system, Chaum's new proposed system, is what happened to Chaum's original anonymized currency.  Someone much resembling Robert Mueller threatens the operator with money laundering, financial fraud, and so forth charges if he does not play ball, so "the system" plays ball, rendering all that wonderful cryptography worse than That is what happened the previous two times we did this dance (e-gold, chaumian anonymity), and any proposed crypto currency needs to explain why it is not going to happen this time.

@_date: 2019-08-10 14:23:37
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Our leader opines on cryptocurrencies 
I have an urgent practical real world need for privacy, partly for grey market transactions, partly because of lack of trust on international internet transactions, and mostly because of state sponsored persecution of political dissidents, and I researched my options, and the answer was bitcoin, despite its massive privacy flaws, not Monaro, because the idea is to get lost in the crowd, and to do that, you need a crowd.
The solution for private transactions is not better cryptography. It is to replace central banking and government sponsored fiat.
And, most of all, to replace centralized data silos of commercial reputation.  The important objective should be to have a currency that supports a reputation system akin to that siloed by Ebay and aliExpress, but without the data silos, so that the difference between a marketplace   selling android phones, and a marketplace selling illegal drugs, is that you use one nym for illegal drugs, and another nym for android phones, but the reputations of these nyms are not kept in separate silos, or in silos at all.  The big privacy flaw of bitcoin, of every crypto currency including Monaro and similar currencies, is not that transactions are linkable, though that is indeed a big problem, but that transactions require reputations.  We need a system that makes public data that is required to generate reputational information, without exposing those engaged in transactions to violence by third parties.  We need a privacy preserving solution to the problem currently being solved by Ebay.
This email has been checked for viruses by Avast antivirus software.

@_date: 2019-08-10 23:18:37
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Our leader opines on cryptocurrencies 
Have any bitcoins been frozen?  Which ones?
It could easily happen.  The miners are too few, too big, too immobile, too subject to pressure.
But I am not aware that it has happened.  Are there transactions that they will not accept?
This email has been checked for viruses by Avast antivirus software.

@_date: 2019-08-13 06:53:58
@_author: jamesd@echeque.com 
@_subject: [Cryptography] generated passphrases 
There are plenty of random phrase generators around, but I have not found their algorithms and their word databases.
I hope someone could direct me to some open source for random phrase For the same entropy, it is easier to type an English language passphrase than a random string of gibberish, even though the random string has roughly three times the entropy per character, the longer English phrase is easier to remember and to type.
Trouble is that user generated passwords and  passphrases tend to have low entropy.
Logon passphrases do not need much entropy, because the server will lock you out after a large number of failed guesses, but the trouble is that pass phrases for crypto currency accounts require about a 128 bits of entropy, which corresponds to about twenty three characters of random gibberish, or about a twelve word passphrase.   It is hard to type in twenty three characters of random gibberish.
To prevent people from using low entropy passphrases, most crypto currency wallets use a generated passphrase of twelve words randomly selected from a list of two thousand words.
Trouble is random words are hard to remember and type. Grammatically correct nonsense passphrases are easier to remember and type.
Jitsi uses a random passphrase generator which generates grammatically correct nonsense phrases, but its passphrase generator only generates four word phrases.
Obviously, we would be better off using randomly generated grammatically correct twelve word nonsense phrases than randomly generated strings of This email has been checked for viruses by Avast antivirus software.

@_date: 2019-08-13 06:57:17
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Our leader opines on cryptocurrencies 
That is only a problem if you want to cash out the tainted ones.  Not a problem if you are using bitcoins as cash, as I am.  I use bitcoin to buy stuff.
And the goal is a world where everyone uses crypto currency to buy stuff.
This email has been checked for viruses by Avast antivirus software.

@_date: 2019-08-14 06:57:54
@_author: jamesd@echeque.com 
@_subject: [Cryptography] generated passphrases 
random words is the same as bips32, which open source and the standard for crypto currency wallets.  But Diceware has a larger vocabulary.
Passphrases that are grammatically correct will have significantly lower entropy, the sum of the binary logarithms of the number of words for each part of speech. A "randomly generated grammatically correct twelve word nonsense phrase? is unlikely to come close to 128 bit entropy.
Assuming your grammar uses six categories of words generate sentences with five hundred words in each category and total number of words is three thousand.
Then a randomly generated string of eleven random words will be 127 bits of entropy, whereas a randomly generated grammatically correct nonsense phrase of fourteen words will be 129 bits of entropy.
One  could get denser entropy than that with grammatically correct This email has been checked for viruses by Avast antivirus software.

@_date: 2019-08-15 12:52:15
@_author: jamesd@echeque.com 
@_subject: [Cryptography] generated passphrases 
That is the BIPS32 solution.
It would be a lot easier to type and to recollect if it was grammatically correct.
This email has been checked for viruses by Avast antivirus software.

@_date: 2019-09-01 06:32:45
@_author: jamesd@echeque.com 
@_subject: [Cryptography] "Entropy as a Service: A New Resource for Secure 
============================== START ==============================
You cannot test for entropy.  You have to have theory that explains that the entropy is derived from a known good source.
If, for example, you have a microphone input connected to a resistor instead of a microphone, it will generate large amounts of truly random entropy derived primarily from thermal noise.  Hash it on bootup, you get a true random seed.  Use the seed as an encryption key, and encrypt an endless stream of zeroes to get an endless stream of unpredictable bits. From time to time, reseed.
This email has been checked for viruses by Avast antivirus software.

@_date: 2019-02-13 00:31:37
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Schneier in Wired: There's No Good Reason to 
In the past few days I have made four purchases using bitcoin.
Three of these four purchases were the use of bitcoin to get around political censorship and political repression.

@_date: 2019-02-21 18:34:55
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Questions of taste on UDF presentation 
Modern C++ has optional array bounds checking and automatic memory management, though the traditional collection of broken glass and razor blades is still present for backwards compatibility, and arrays with known size decay into bare pointers if you use the old idioms for accessing data.
If you do all your pointer arithmetic using modern idioms and spans, you can get array bounds checking with no runtime cost or insignificant runtime cost.

@_date: 2019-01-05 10:10:08
@_author: jamesd@echeque.com 
@_subject: [Cryptography] blake2b 160 
He has complete freedom to choose a twenty byte or so nonce.   And "He" might well have the computational resources of Google or the NSA
The threat is that he constructs two short messages, one of the transaction he wants, with a 20 byte nonce that he has complete freedom to choose. and one of the form the other guy wants, with a another twenty byte nonce that he has complete freedom to choose, and needs to get them to have the same hash
You are raising  vast pile of unsolved and unsolvable theoretical issues with no obvious relevance to the question, the question being specifically about blake2b 160

@_date: 2019-01-05 10:13:07
@_author: jamesd@echeque.com 
@_subject: [Cryptography] blake2b 160 
I know that, everyone knows that.  Does not seem to have the slightest relevance whatsoever to the question I asked.
Obviously the NSA can calculate 2^80 blocks without raising a sweat, but they cannot store and sort 2^80 blocks, which on the face of it they would need to do in order to find the collision that they might have

@_date: 2019-01-05 10:16:40
@_author: jamesd@echeque.com 
@_subject: [Cryptography] blake2b 160 
Well I would consider you full of hot air, unless you actually do some resource calculations
Obviously a nation state can calculate 2^80 hashes easily enough, but in order to find which two of them can collide would need to store and sort 2^80 hashes, which looks to me to be far beyond the resources of any present nation state, or the likely resources of any nation state in the reasonably foreseeable future.

@_date: 2019-01-05 10:31:03
@_author: jamesd@echeque.com 
@_subject: [Cryptography] blake2b 160 
Thank you.
This confirms my expectation that Blake2b 160 will suffice, since all messages will be short, and all messages will have a prefix that defines their schema, and thus implicitly their length, and, as in SHA 256, an affix specifying their actual length.  (In blake2b length affix every chunk, not just at the end, so that hashing is not position invariant.)

@_date: 2019-01-05 20:48:57
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Blockchain without proof of work 
Obviously, blockchain should work on proof of stake.
I have proposed the following system.
Stake is registered with peers, of which there are a few hundred, which tend to be very large machines with very high bandwidth connections, but stake is owned by clients, who are hosted by peers.  Clients tend to be small machines with low storage and low bandwidth connections.  Client signatures can move stake from one peer to another.  Stake is client money, so that power is ultimately in the hands of the clients, though a peer somewhat resembles a bank from the point of view of clients.
Paxos protocol with peers holding fifty percent of stake get to decide on which transactions are committed and which are rolled back.
I also have a plan for making this system anonymous, through transaction pooling, where each transaction is a pool of payments made by several public keys to several other public keys, and the block chain does not reveal which key in the pool were paying which other key in the pool, just the total going in and out, but I intend to publish the full details when I have something working.
Bitcoin payments are pseudonymous, but when money goes in and out of the system, apt to connect pseudonyms to true names, and when bitcoin goes from one nym to another, reveals connections between nyms.  Pooling would hide connections between nyms, because you would not know which of the many nyms in the pool was paying which of the many other nyms in the Because the pools cannot be very large, and will often be quite small, this still leaks some information, giving people trying to follow the money clues and hints, but it leaks far less information than the bitcoin blockchain.

@_date: 2019-01-07 08:03:16
@_author: jamesd@echeque.com 
@_subject: [Cryptography] blake2b 160 
Looks like it, for the NSA.
Rough guess is that 160 bits would fail against custom, massively parallel hardware using this method, and 256 bits would succeed in resisting the attack.
But that is just my back of the envelope calculation resting on a wild assed guess.
Does anyone have any good justification that 256 bits is safe?

@_date: 2019-01-10 10:52:18
@_author: jamesd@echeque.com 
@_subject: [Cryptography] SSH key text format: 
An SSH ed25519 public key in text format looks like this:
And the corresponding private key in text format looks like this:
Where are these formats, and their conversion to and from binary, defined?  Where is the source code - yes, I figure that since putty and openssh is open source, it is somewhere in there, but perhaps I am being stupid, since "where" is not altogether obvious to me.  Kind of hoping to find not just the code, but the reasons for the code.
And what with the AAAA fields?

@_date: 2019-01-22 06:54:24
@_author: jamesd@echeque.com 
@_subject: [Cryptography] How does bitcoin find if a transaction output has 
A new transaction is proposed.  How does the validator figure out if one of the transaction outputs has already been used?
The blockchain is heading towards a terabyte.  So you cannot search the entire blockchain to make sure a particular transaction output has never been used.
You are going to need a big mutable list of transaction outputs sorted by index order, a great big pile of mutable state, derived from the immutable transactions on the blockchain. I suppose that each entity maintaining a copy of the blockchain generates the mutable state by going through the very long list of immutable transactions. And because it is mutable, someone could get it wrong, by malice, fraud, or hardware Each peer on the blockchain has to go through the immutable pile of transactions, starting from the beginning, to generate the current mutable state.
How do the peers know they all have the same mutable state?  Do they have a checksum for the mutable state at block X?  Is there a global and canonical lookup mechanism for the mutable state that is a defined part of the protocol, or could each peer implement its own custom idiosyncratic magic mechanism?
What you would probably like to do, though as far as I know it has not been done, is make an immutable record of all currently unused transaction outputs at certain blocks, which would make it possible to throw away earlier blocks, an immutable snapshot of the mutable data generated from the immutable transactions.

@_date: 2019-01-24 08:56:53
@_author: jamesd@echeque.com 
@_subject: [Cryptography] How does bitcoin find if a transaction output 
What verifies everything is consensus between miners.
The blockchain is a global consensus of transactions on the database, and there is a chain of hashes, a merkle dac, guaranteeing that everyone agrees on what transactions have been committed, and if all transactions are applied correctly, everyone should agree on the resulting database, the important and most heavily accessed part of the database being the set od unspent transaction outputs, UTXO.
At present a miner has to keep the entire set of unspent transactions in ram, which is a hard scaling limit on bitcoin.
But as things scale, database failure becomes more common, resulting in consensus failure.  Peers may be operating off different databases, and not know that is why they are having trouble agreeing.
You need early detection of discrepancies between the many peer databases that represent the result of going through all the transactions and applying them to the database.
Because of the likelihood of database failure, which becomes common as databases get to a terabyte or so, you need a chain of hashes representing not only the transactions committed to the database, but also the current state of the entire database, or the current state of the list of unspent transaction outputs.
For crypto currency to take over the world, need a mechanism for managing the list of unspent transaction outputs where those generating consensus do not need the entire unspent transaction  output list in memory, and where we have efficient means for detecting and resolving disagreements in the current state of the database on top of efficient means for ensuring one unchanging append only blockchain of committed

@_date: 2019-07-04 09:08:06
@_author: jamesd@echeque.com 
@_subject: [Cryptography] graph theory and sybil attack 
The typo of of "sibyl", which should of course be sybil, is not mine, but due to a zealous and stupid spelling checker.
This email has been checked for viruses by Avast antivirus software.

@_date: 2019-07-04 09:02:45
@_author: jamesd@echeque.com 
@_subject: [Cryptography] graph theory and sybil attack 
The sibyl attack is a graph theory problem, not a cryptography problem, and its application is in distributed systems.
But distributed systems are a cryptography problem, so, if the moderators permit, I would like to ask about this problem here:
Yacy is an open source distributed search engine for publishing, but the hard problem is the sibyl attack, the problem that Google refers to a a link farm  a bunch of fake sites that link to each other to give each other fake reputation. Not clear how Yacy addresses the sibyl attack, and I suspect that if usage of Yacy increases, it will be subject to such attacks.
Similarly, systems for giving people reputation for supplying goods are subject to sibyl attack with fake customers. Big problem with Dark Web sites that attempt to do an ebay on Tor. Distributed systems tend to be subject to sibyl attacks.
Resolving the sibyl attack is a problem of partitioning the graph to see if a group of nodes well connected to each other are, considered as a single node, well connected to rest of the network. Page rank and analogous measures such as seller reputation are a measure of connection to the graph as a whole, and the sibyl attack is faking good connection to the graph as a whole by creating a seemingly large subgraph that is well connected to itself but poorly connected to the rest of the graph.
Considering the sibyl attack as a graph theory problem, we have some ranking criterion that is in some sense or some part a measure of connection to the graph as a whole, such as page rank, seller reputation, or the node's provision of services (we want to penalize leecher nodes and reward seeder nodes) and we want the ranking criterion to exclude relatively isolated large subgraphs from having inappropriately high rank.
Assume for example that an pseudonymous purchaser can publish a review that is demonstrably linked to a payment actually made (but which might have been made by his left hand to his right hand), and we want to give sellers rank on the basis of reviews.  But we want to give high impact to unfavorable reviews by purchasers that have issued lots of favorable reviews to real sellers, and to give favorable reviews impact only if the purchaser nym has made lots of reviews of real sellers.
This is similar to the google page rank problem.  A site is high rank if it has lots of links from real sites that have high rank.  So what is a real site?
It would be nice to be able to state this problem as a graph theoretic problem and to relate it to well known graph traversal algorithms.
Excluding the sibyl attack and excluding a link farm is identifying a subgraph that is strongly internally connected, and then ranking that subgraph as a single node.  We want a rank value for nodes that is unaffected or not strongly affected by collapsing subgraphs that are strongly internally connected.
This is also related to the DuckDuckGo algorithm, where as search query is identified as a search on a topic, and a topic is associated with a small, human identified and human generated, set of subsets of the whole It is also related to the optimization of performing one's rank algorithm on a model of the graph that is substantially smaller than the actual graph, in that groups of nodes are collapsed into a single node. A ranking algorithm optimized in this manner is likely to inherently be able to deal with the sibyl attack.
A distributed search engine like Yacy gets an inherently large number of humans contributing groupings, but it is hard to deal with such human generated data.
DuckDuckGo is apt to generate politically incorrect search results, and making AI engage in crimestop is currently a major research issue. DuckDuckGo resolves this problem as part of its topic identification algorithm, by passing searches likely to generate politically incorrect search results to Bing, which is of course not part of the graph  theory question that I am asking.  What I am asking is how do we abstract these messy particular problems as graph theory problems of treating groups of nodes with strong internal connection as a single node.
Google does this analysis with respect to politically incorrect groups of nodes. I don't know how Bing does it - I suspect they rely primarily on humans identifying major politically incorrect nodes, and then down ranking nodes that link to them.
This email has been checked for viruses by Avast antivirus software.

@_date: 2019-07-11 16:12:14
@_author: jamesd@echeque.com 
@_subject: [Cryptography] graph theory and sybil attack 
Most NP complete problems have approximate or near optimal solutions that are merely polynomial, and/or solutions that in some real world application reliably and rapidly converge to optimal solutions for the kind of data that usually turns up in that real world application.  This is related to the smart car problem, where 99.99% of the time the car is smart, smarter than a human driver, because it rapidly and efficiently comes up with good solution to an NP complete problem, and it only idiotically and blindly kills someone 0.01% of the time.
Legitimate fans are likely to be fans of other musicians as well, and likely to have genuine interactions with fans of other musicians.
So, is this musician connected to graph as a whole through fan/fan

@_date: 2019-07-15 19:35:19
@_author: jamesd@echeque.com 
@_subject: [Cryptography] graph theory and sybil attack 
The Sybil Guard paper, linked by Kate Sills, provided me with relevant information:""SybilGuard and SumUp are two graph theory solutions for sybils in social networks that you might be interested in. "
According to Sybil Guard, social networks are empirically determined to be "fast mixing"
"social networks tend to be fast mixing (defined in the next section), which necessarily means that subsets of honest nodes have good connectivity to the rest of the social network"
So the legitimate musician with legitimate fans will be connected to the rest of the social network - his legitimate fans will have interactions with legitimate fans of other legitimate musicians, and will purchase stuff from other legitimate musicians, while the fake fans making fake purchases will not (though they could do any number of fake reviews of legitimate musicians).
"in a fast mixing graph, after a small number of hops a random walk is equally likely to be traversing any edge in a given hop."
The paper argues that sybil subsets of the network are substantially less likely to be entered after a small number of hops.
"With a length w random walk, clearly the distribution of the ending point of the walk depends on the starting point. However, for connected and nonbipartite graphs, the ending point distribution becomes independent of the starting point when w ? ?. This distribution is called the stationary distribution of the graph. The mixing time T of a graph quantifies how fast the ending point of a random walk approach the
stationary distribution. In other words, after ?(T) steps, the node
on the random walk becomes roughly independent of the starting
point. If T = ?(logn), the graph is called fast mixing."
If we mix the graph for a suitable time, legitimate nodes will be well mixed with each other, and sybil nodes will not be well mixed with legitimate nodes.
Legitimate nodes will have positions that are close to each other in the space of distributions of end probabilities, and sybil nodes will be far from legitimate nodes in that space.
This algorithm is O[n*n] in data size (the distribution for each starting point), and O[n*n*log(n)] in computational time, which is a lot better than np, though still apt to be inconveniently large.  It can probably be speeded up considerably by random dimensional reduction, wherein a vector of very large dimension (the probability of reaching each end point, the distribution of end points) is randomly mapped to a vector of dimension O[log of the original dimension]
Which will, I think, speed it up to O[n * (log n)^2] which is acceptable.
Mixing for a suitable time, a suitable path distance, divides the graph into well mixed regions, one of which is the legitimate nodes.  We identify which of the regions is non sybil by checking the region of a small number of known legitimate nodes.  If they all belong to the same region, our mixing distance is sufficient, and chances are the sybil nodes are not in that region.
During mixing, the points draw closer to each other in the space of distributions.  The fan group of a particular musician will coalesce rapidly, and then the fan groups of all legitimate coalitions will, more slowly draw together, while the fake fan group drifts very slowly indeed. We halt the mixing when the known legitimate nodes are all close to each other, because by then everyone who is a legitimate node is close to them.
We then downrank reviews or page ranks that are distant from the This email has been checked for viruses by Avast antivirus software.

@_date: 2019-07-21 11:32:05
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Our leader opines on cryptocurrencies 
> Master Card can process 38,000 transactions per second, and Visa about
 > the same.  Good luck doing that with a blockchain, even a closed
 > non-PoW one.
Working on it:
Assume delegated proof of stake, in which the merkle patricia root of the most recent block is signed by a quite small number of big peers on the blockchain, each representing a very large number of very big clients each owning a great deal of stake.  (Ordinary clients are insignificant. Ordinary peers are insignificant, but the interests of big peers and big clients are aligned with those of small peers and small clients, if there are enough of them.)
Then each big peer has to process about one hundred thousand transactions per second, assuming we want to replace government fiat currencies with a blockchain currency.
So we have a small number of peers, each peer processing the entire blockchain, and each peer composed of a large number of shards, each shard processing a shard of the blockchain.
Assume the processing is shardable with mutually trusting shards that do not suffer byzantine failure.
The computer sitting under my desk, with a consumer grade fiber to the curb connection to the internet, could probably process six thousand transactions per second running four shards in a single physical computer, so each peer is going to need forty such shards running on ten such devices, say a eighty such shards running on twenty such devices for redundancy and storage, each device having twelve six terabyte hard The shards coordinate by non byzantine paxos on a single hash once every few minutes, and the peers coordinate on a single hash by byzantine paxos.  The number of peers, and the number of shards, is small enough that we don't hit paxos scaling problems.
This email has been checked for viruses by Avast antivirus software.

@_date: 2019-07-23 22:54:53
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Our leader opines on cryptocurrencies 
No mutual trust between peers.  The shards that trust each other live within a single rack owned by a single peer.  Trust does not extend outside that rack.
The sharding is to enable peers to be big enough.
The shards are not peers.
The clients are not peers
Scaling is achieved by multiple hierarchies each splitting the problem in different dimensions.
This email has been checked for viruses by Avast antivirus software.

@_date: 2019-07-24 08:00:23
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Our leader opines on cryptocurrencies 
You are describing a system wildly different from that which I thought I had described.
Since I was unclear, will repeat in different words.
The objective is to implement the blockchain in a way that scales to one hundred thousand transactions per second, so that it can replace the dollar, while being less centralized than bitcoin currently is, though not as decentralized as purists would like, and preserving privacy better than bitcoin now does, though not as well as Monaro does.  It is a bitcoin with minor fixes to privacy and centralization, major fixes to client host trust, and major fixes to scaling.
The problem of bitcoin clients getting scammed by bitcoin peers will be fixed through merkle patricia, which is a a well known and already widely deployed fix - though people keep getting scammed due to lack of a planned bitcoin client-host architecture.  Bitcoin was never designed to be client host, but it just tends to happen, usually in a way that quite unnecessarily violates privacy, client control, and client safety.
Monaro's brilliant and ingenious cryptography makes scaling harder, and all mining based blockchains tend to the same centralization problem as afflicts bitcoin.  Getting decisions quickly about a big pile of data necessarily involves a fair bit of centralization, but the paxos proof of stake protocol means the center can move at the speed of light in fiber, and from time to time, will do so, sometimes to locations unknown and not easy to find.  We cannot avoid having a center, but we can make the center ephemeral, and we can make it so that not everyone, or even all peers, know the network address of the processes holding the secrets that signed the most recent block.
Scaling accomplished by a client host hierarchy, where each host has many clients, and each host is a blockchain peer.
A hundred or so big peers, who do not trust each other, each manage a copy of the blockchain.
The latest block is signed by peers representing a majority of the stake, which is likely to be considerably less than a hundred or so peers.
Peer stake is delegated from clients - probably a small minority of big clients - not all clients will delegate.  Delegation makes privacy more complicated and leakier.  Delegations will be infrequent - you can delegate the stake held by an offline cold wallet, whose secret lives in pencil on paper in a cardboard file in a safe, but a peer to which the stake was delegated has to have its secret on line.
Each peer's copy of the blockchain is managed, within a rack on the premises of a peer, by a hundred or so shards.  The shards trust each other, but that trust does not extend outside the rack, which is probably in a room with a lock on the door in premises with security cameras running.
Yes, any one peer would be exactly like a central bank issuing fiat money, if that peer had the majority of stake delegated to it, and if clients could not delegate stake to a different peer.
Most people transacting on the blockchain are clients of a peer.  The blockchain is in the form of a sharded merkle patricia tree, hence the clients do not have to trust their host - they can verify any small fact about the blockchain in that they can verify that peers reflecting a majority of stake assert that so and so is true, and each client can verify that the peers have not rewritten the past.
Scale is achieved through the client peer hierarchy, and, within each peer, by sharding the blockchain.
Clients verify those transactions that concern them, but cannot verify that all transactions are valid, because the blockchain is too big. Each peer verifies the entire blockchain from beginning to end.  If the blockchain replaces the US dollar as the world currency, then it will rapidly become far too large for any one computer to verify the whole thing, so will have to be verified by a group of mutually trusting and trusted shards, but each such group of shards is a peer.  The shards trust shards of the same peer, which are likely running on the same rack in the same locked room under the gaze of the same security camera, but they don't trust shards of some other peer.
In each transaction, each client verifies that the other client is seeing the same history and recent state of the blockchain, and in this sense, the blockchain is a consensus of all clients, albeit that consensus is mediated through a small number of large entities that have a lot of power.
The architecture of power is rather like a corporation, with stake as shares. In a corporation CEO can do anything, except the board can fire him and choose a new CEO at any time.  The shareholders could in theory fire the board at any time, but in practice, if less than happy with the board, have to act by transacting through a small number of big shareholders.  Centralization is inevitable, but in practice, by and large corporations do an adequate job of pursuing shareholder interests, and when they fail to do so, as with woke capital, Star Wars, or the great minority mortgage meltdown, it is usually due to substantial part heavy handed state intervention.  Google's board is mighty woke, but in the Damore affair, human resources decided that they were not woke enough, and in the Soy wars debacle, the board was not woke at all but gave power over Star Wars brand name to women who threatened them with   And if this form of distributed power does not always work all that well, it fails less badly than anything else we have tried.
Delegated power representing assets, rather than people, results in centralized power that, by and large, mostly, pursues the interests of those assets.  Delegated power representing people, not so much.
In bitcoin, power is in the hands of a very small number of very large miners.  This is a problem, both in concentration of power, which seems difficult to avoid if making decisions rapidly about very large amounts of data, and in that miner interests differ from stakeholder interests. Miners consume very large amounts of power, so have fixed locations vulnerable to state power.  They have generally relocated to places outside the US hegemony, into the Chinese or Russian hegemonies, or the periphery of those hegemonies, but this is not a whole lot of security.
Proof of stake has the advantage that stake is ultimately knowledge of secret keys, and while the state could find the peers representing a majority of stake, they are more mobile than miners, and the state cannot easily find the clients that have delegated stake to one peer, and could easily delegate it to a different peer, the underlying secret likely being offline on pencil and paper in someone's safe, and hard to figure out whose safe.
This email has been checked for viruses by Avast antivirus software.

@_date: 2019-07-25 12:19:52
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Our leader opines on cryptocurrencies 
The past keeps being rewritten, 1984 style, the rewrites being increasingly drastic and increasingly frequent, partly due to increasing political repression and centralization of power, partly because keeping everything digital makes it easier to rewrite the past.  The blockchain prevents the past from being rewritten.
Ideally we want a system where everything that relates to a transaction, ownership of a name, or ownership of cryptographic keys, links to the blockchain, so that the parties can prove that at the time of the transaction, they saw such and such records, and made the transaction in the light of those records, but no one else can prove it, unless one of the parties to the transaction shows the records, as perhaps in an ebay style product review
Bitcoin blockchain records forever a whole lot of information that can be alarmingly useful for law enforcement - but not nearly as much as banked transactions, and with due care it is possible to avoid excessively interesting facts about transactions from being visible on the blockchain.
Monaro blockchain hides everything, but this is a problem for reviews and reputation management.  Sometimes you want to be able to prove facts about a transaction.  Also worsens the already severe scaling problems of bitcoin.
Hiding the IP numbers associated with bitcoin transactions using Tor and suchlike is almost irrelevant.  The problem is that you do transactions using the web and the DNS, which record everything. The web and the DNS is the big privacy hole, not the bitcoin blockchain.
This email has been checked for viruses by Avast antivirus software.

@_date: 2019-07-27 16:48:03
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Our leader opines on cryptocurrencies 
How many big bitcoin mining pools are there?  Probably about four that matter.  Few enough to be worrying.
In general a board with half a dozen to a dozen or so board members mostly avoids collusion by board members against shareholders - in part because a board member and a big shareholder are the same sort of people, who probably play a round of golf together from time to time, and a big shareholder the same sort of person as many of the smaller So my wild assed guess is that a hundred or so peers, with half a dozen or a dozen or so of the peers with the biggest weight of stake delegated to them by the biggest client wallets usually being sufficient to sign the latest block, would probably suffice.
Each peer checks the entire blockchain, and autoforks if the rules are broken. Each client checks that small part of the blockchain that directs affects himself.
In order to scale, need centralization.  For users to be secure, need decentralization.  The Paxos protocol combines the two in manner analogous to a corporation.
This email has been checked for viruses by Avast antivirus software.

@_date: 2019-07-27 16:51:41
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Our leader opines on cryptocurrencies 
Common use cases for bitcoin privacy are buying gray market drugs such as testosterone over the internet, and publishing crimethought over the internet.  Works for those cases, provided one takes appropriate precautions
So, if you get bitcoins for drugs, and you want to use your bitcoins to buy from amazon, you launder the bitcoins first.  I launder my bitcoins regularly, not for drugs, but for crimethoughts.
You want to publish evil crimethoughts, so you rent a server using bitcoin.  You get the bitcoin by donations, or by buying them from friends rather than by buying them through coinbase .  They will not be able to dox the person paying for the server.
Again I generally buy my bitcoins from a friend of a friend, and launder it on top of that.  Trying to track me through my bitcoin transactions is like trying to track me through the serial numbers on cash transactions.  Doable in principle, but difficult in practice.
If you buy bitcoins for fiat money through coinbase and spend them on something illegal, then you are toast.  And if you acquire bitcoins from something illegal, then turn them into fiat money through coinbase then you are toast.
So, don't do that.  If you stay away from coinbase and similar, you will usually be fine.  It is the websites that are the problem.
This email has been checked for viruses by Avast antivirus software.

@_date: 2019-07-31 08:05:15
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Our leader opines on cryptocurrencies 
> > If you buy bitcoins for fiat money through coinbase and spend them
 > > on something illegal, then you are toast.  And if you acquire
 > > bitcoins from something illegal then turn them into fiat money
 > > through coinbase then you are toast.
 > >
 > > So, don't do that.  If you stay away from coinbase and similar, you
 > > will usually be fine.  It is the websites that are the problem.
 > If you don't buy bitcoins from coinbase, you're likely to get coins
 > that are already tainted/blacklisted.
Fine.  All my coins are tainted/blacklisted, and I expect that all the coins of everyone I transact with are also tainted and blacklisted.
Indeed, why would anyone ever use a crypto coin that was not Pretty sure that the entire real bitcoin economy, people using bitcoins to buy stuff and sell stuff, rather than investing in bitcoin as an alternative to gold, shares, and government bonds, is tainted/blacklisted.
This tainting/blacklisting seems to be having limited effectiveness.
And the solution is to not to improve the inherent privacy of the blockchain as Monaro is doing (though what Monaro is doing is great) but to do something about the problem of transacting through websites and the domain name system.
The traceability of bitcoin is a huge problem - but what makes it a problem is not the traceability, it is the way the web works.  Monaro alleviates, rather than fixes, the problem.
As the joke goes, you are using an armored car to transport a parcel between two people, one of whom is living on a park bench, and the other of whom is living in a cardboard box.
Better armored cars, and Monaro is a way better armored car, are more a distraction than a solution.
This email has been checked for viruses by Avast antivirus software.

@_date: 2019-07-31 08:45:23
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Our leader opines on cryptocurrencies 
============================== START ==============================
You are thinking in terms of a world where everyone uses fiat currencies connected to bank accounts and credit cards, all of which get reported to the government, and you want Monaro to allow you to buy crypto coins in Coinbase for fiat money, spend these crypto coins, and then the man receiving these cryto coins turns them back into fiat money, and Monaro prevents a connection between the coinbase account converting fiat money into crypto coins, and the coinbase account turning crypto coins back into fiat money.
I am thinking of a world without government sponsored fiat.
This email has been checked for viruses by Avast antivirus software.

@_date: 2019-05-05 12:22:08
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Schnorr multisignatures based on ED22519 
I have heard it said that ED25519 supports Schnorr multisignatures,
The Libsodium documentation contains no mention of multi signatures, and, because ED25519 is nonprime group, it seems to me that implementing Schnorr multisignatures would require an expert in the mathematics of elliptic curves - I certainly have no idea how to even begin, and would not trust code written by someone not well known.
Libsodium supports the prime group Ristretto255, though only in the development version, not yet the stable version, with which a person of ordinary skills could implement Schnorr multisignatures but it is not apparent that this would play nice with LibSodium's built in high level encryption and signing code.
So, should I forget about Schnorr multisignatures, and just do what everyone else does:  Tuples?
Or does Libsodium support multisignatures somewhere in the documentation, and I have been looking in the wrong place?

@_date: 2019-05-06 05:17:29
@_author: jamesd@echeque.com 
@_subject: [Cryptography] NIST announced Round 1 candidates for 
I pay no attention to anything issued under the NIST umbrella
NIST is our enemy.
Use standards issued by Jon Callas, unelected president for life of symmetric cryptography, and Daniel Bernstein, God King of asymmetric

@_date: 2019-05-07 14:52:59
@_author: jamesd@echeque.com 
@_subject: [Cryptography] NIST announced Round 1 candidates for 
On May 6, 2019, at 11:42 AM, Salz, Rich via cryptography Sounds mighty like "Yes, NIST is our enemy, but ..."
And it not terribly clear what the "but" is.
no, sunlight is a terrible disinfectant, because committees wind up succumbing to group think, and group think tends at best to delusion, and at worst winds up being dominated by the evil and the insane, because the sane shift their position under social pressure, while the evil and the insane do not shift their position.
I could give a very long list of examples of this problem, but that would take the list off topic.

@_date: 2019-05-07 14:55:49
@_author: jamesd@echeque.com 
@_subject: [Cryptography] NIST announced Round 1 candidates for 
By making it a candidate, comes the opportunity to place social pressure on Bernstein, rather than the opportunity for Bernstein to place social pressure on NIST.

@_date: 2019-05-07 15:06:28
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Schnorr multisignatures based on ED22519 
My ignorant opinion is that you would be fine using a well known algorithm, such as Schnorr signatures, in a prime group such as ristretto255, but in a non prime group such as Ed25519, likely to shoot yourself in the foot, and if you roll your own algorithm, likely to shoot yourself in the foot even with a prime group.

@_date: 2019-05-08 16:02:45
@_author: jamesd@echeque.com 
@_subject: [Cryptography] NIST announced Round 1 candidates for 
Libsodium stable seems to have everything one would ordinarily need if starting from scratch and you don't need to talk to old NIST code.  And it is all NIST free.
Libsodium master has everything one would ordinarily need, plus Ristretto255

@_date: 2019-05-08 16:14:06
@_author: jamesd@echeque.com 
@_subject: [Cryptography] NIST announced Round 1 candidates for 
Correction/Clarification. Libsodium has plenty of NIST algorithms, but the defaults are all NIST free, and the recommendation is to use the If one puts a cup of wine in a barrel of sewage, one has a barrel of sewage.
And if one puts a cup of sewage in a barrel of wine, one still has a barrel of sewage.

@_date: 2019-05-09 21:45:14
@_author: jamesd@echeque.com 
@_subject: [Cryptography] peering through NAT 
NAT makes it hard to contact a computer behind nat, but Bitcoin core has no problems with most nats, even when behind multiple levels of nats.
It does something to tell the nat to direct incoming messages on port 8333 to it, without the end user usually needing to manually set up port What is the protocol to tell a nat to forward incoming messages?
What happens if there are two machines both running bitcoin core behind the nat?

@_date: 2019-05-11 11:29:53
@_author: jamesd@echeque.com 
@_subject: [Cryptography] peering through NAT 
Not much, but it has a little, and here is what it has to do with In a world where authorities are increasingly trying to control speech and rewrite the quite recent past at frequent and ever shortening intervals, we will increasingly rely on peer to peer distributed security.
For example:  Database linking human memorable names and cryptographic key, squaring Zooko's triangle.
If that database is a central authority, that central authority is apt to give evil crime thinker Ann the address of the FBI as the address of evil crime thinker Bob, and similarly the address of the FBI to evil crime thinker Bob as the address of evil crime thinker Ann.
Suppose we have an append only Patricia Merkle dac, such that if everyone agrees on the root hash, cannot amend the past, nor give different people different versions of the past.  The evil crime thinker Ann can know that she is seeing the same story about her key and Bob's key as Bob sees.
But we cannot rely on a majority of honest peers - observe how often every single tenured academic in the entire American hegemony agrees on the new version of reality, and remembers that he always agreed on the new version of reality, when yesterday he had a different position.
So what we are going to have to do is that each root hash incorporates the previous root hash in a block chain, lots of peers sign the root hash, and record each other signing the root hash, so that if a new hash appears that fails to be legitimately derived from the previous root hash, a root hash that testifies to a history incompatible with that testified by previous root hashes, a single honest peer can call them all out causing a fork.
So a large number of peers agree on the one true latest root hash, and each witnesses many of the others agreeing.  And if any of the peers are not honest, or if all but one is dishonest, they will get called out, which will keep them all honest.
This implies some sort of paxos protocol, weight of stake rather than weight of hashing power, for the government can always seize or build the majority of hashing power.
Hence peer to peer security.  Even if you are running a client program, you will want it to record the part of the Patricia Merkle tree that relates to your activities, the signatures of numerous major and important peers, and make sure that the people you interact with are seeing the same record of the past, and in particular your past keys, as you are.
Nat penetration is messy.  Maybe we just do it client server, and wait for IP6.

@_date: 2019-05-11 19:03:52
@_author: jamesd@echeque.com 
@_subject: [Cryptography] peering through NAT 
On reflection, the best solution would be a peer to peer system where each peer has a public key, some peers have accessible ports and can be accessed by any peer, messages percolate from peer to peer, and the messages can propose a stun rendezvous - a peer that wants a direct connection with another peer behind a NAT nominates a time and an IP port, and at the appointed time, both peers fire off UDP packets to each other on that port.
This, however, requires a reliability and bandwidth throttling mechanism on top of udp, an ssl like layer on top of udp.  A number of libraries contain such mechanisms, but the mechanism tends to be connected to lots of things, not happy with any of them that I have looked at.  You just want a monkey, and get the entire jungle.
By and large, VOIP does go through UDP with a throttling mechanism, but libraries that provide this are not small and generic, but rather special purpose - they expect you to use the entire library in the intended way for the intended purpose, and using it in a different way needs a rewrite.  The GameNetworkingSockets library sort of provides a udp reliability and throttling layer, though it is a bit broken at the moment, and is thinking about providing this with stun.  But integrating stun with the GameNetworkingSockets library seems to need a lot of inside knowledge of the GameNetworkingSockets library.

@_date: 2019-05-19 19:18:32
@_author: jamesd@echeque.com 
@_subject: [Cryptography] What are the privacy implications of bitpay 
With the designed method of bitcoin, you can pay someone quite anonymously.  They issue payment address, which is actually a public key, and then value mysteriously appears in the blockchain for that public key, with no indication of how it got into the blockchain.
Bitpay, however, initiates a direct conversation between the payee and the wallet, and it looks to me that entities cosy with the state are pushing bitpay onto us, demanding payment by bitpay.
Bitpay initiates a conversation between the website and the wallet, and thus, and thus, modulo vpns and all that, locates the physical location of the wallet.  But that in itself is pretty harmless, because you have to interact with their website anyway, so you already leak that information.
What additional information goes into a bitpay payment?  Seems to me that it is being pushed for ulterior and unrevealed reasons.

@_date: 2019-05-29 19:39:59
@_author: jamesd@echeque.com 
@_subject: [Cryptography] The race to Quantum machines. 
It is a good deal worse than that.
To get large numbers of qbits in the straightforward way requires exponentially high Q and accuracy, which is obviously physically impossible.
So, you need some kind of quantum error correction, which means you need large number of qubits with reasonable precision and Q to give the functional equivalent of a much smaller number of qubits with unreasonable precision and unreasonably high Q.
Probably we can find a way to do this without an exponentially large number of reasonable precision and reasonable Q qubits, but even that is not clear, and chances are it is going to be polynomially large.
It is also probably going to be hierarchically multilayered, with a huge number of physically reasonable very fast qubits giving rise to the functional equivalent of a large number of slower qubits with unreasonably high Q, which in turn give rise to the functional equivalent of a depressingly small number of qbits with effectively infinite Q but depressingly low speed.

@_date: 2019-11-03 12:28:16
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Very best practice for RSA key generation 
It is plausible that "Correct Horse Battery Staple" makes it easier to enter high entropy pass phrases, and I am inclined to believe it, but such pass phrases are longer than base 32 or base 64 passphrases, hence more opportunities to get it wrong, and I would like to see some UI testing for passphrases of the same entropy.

@_date: 2019-11-07 09:31:43
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Very best practice for RSA key generation 
One obvious solution is to have the permitted word list, and have some algorithm that picks the nearest word in the word list, and then displays the autocorrected passphrase.  (Which the user can retype if the "correction" picked the wrong word, as is notoriously apt to happen.)
Which requires a word list, which I don't have, and algorithm to pick the nearest word in that word list, which I don't have and do not particularly want to write.
I would think that there should be a pile of open source word lists and a pile of such open source algorithms around somewhere, but I cannot immediately find them, and do not want to re-invent the wheel.

@_date: 2019-11-07 09:59:48
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Very best practice for RSA key generation 
If you are using word lists, you need a word list in the native language of the user, giving us an internationalization headache.  Of course, we already have an internationalization headache, and this is not substantially harder, just another complication in the existing pile of complications that are part of any internationalization effort.
You already need an array of strings, one per UI target language, to populate your prompts and dialog boxes.  WxWidgets gives us flexible dialog boxes that can accommodate dialogs with variable sized strings, which makes a lot of internationalization headaches go away.
Trouble is that we are going to need an autocorrect function for mapping user typed strings to the permitted password word list that is not English specific, as rewriting it for every language is going to get broken fast.
Maybe just do it in the dumbest possible way, express the typed in passphrase as unicode, and use the standard diff algorithm on every word in your word list, then drop down a list of words in your word list in order of diff size.
But the standard diff algorithm would have to be rewritten for this particular task, and it is not that small, and not that fast, and you are going to have to run it for every word on the word list.

@_date: 2019-11-11 05:55:39
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Very best practice for RSA key generation 
Just what the doctor ordered.
Eleven words, one hundred and twenty seven bits, plus some password strengthening work factor that is worth a few bits.

@_date: 2019-11-18 12:26:16
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Encryption doesn't seem to have bothered 
The Joint Investigative Team knew that there were messages, but probably did not know what was in them.
Encryption conceals the content of a message, but does not conceal where a message is coming from or going to, which is likely to be of more interest than the content of a message.
For individuals in a big city contacting another individual in another big city, concealing the content may be more useful, but usually IPs leak rather specific identifying information.
If a big server sets up a UDT4 IP rendezvous between two clients, the server has rather too much information, since the rendezvous necessarily contains rather specific id information, but any information about the volume, timing, and pattern of the ensuing client to client conversation is apt to get lost in an immense pile of client to client interactions downloading movies over bittorrent.
So encryption wrapped in UDT4 would likely slow the FBI down a little.

@_date: 2019-09-11 16:42:18
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Halo: Recursive Proof Composition without a 
At present, Zcash has unacceptable costs, and is therefore unlikely to replace bitcoin.
Due to network effects, one crypto currency is likely to take over the world, and Zcash it is current form cannot be that currency.
Further, the scaling costs of bitcoin make it unlikely to take over the world.  Bitcoin is currently close to its scaling limit.
This approach, if it works out, in principle allows Zcash, or a currency constructed on similar principles, to take over the world.  Each full peer would only store current unspent outputs, recent spent outputs, and a recursive proof that all past outputs were handled in accordance with the rules that were applicable at that time.

@_date: 2020-08-03 19:44:46
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Atomic or simultaneous exchange of secrets. 
Ann and Bob want to exchange secrets.
She does not want to give him her secret, unless he gives her his.
He does not want to give her his secret, unless she gives him hers.
Seems like they are stuck.
Each secret is an unpredictable integer modulo a very large prime, if
that makes a difference.
I seem to recall that there was a solution to this problem, but when I
read the solution, was not too happy with it.

@_date: 2020-02-05 09:20:57
@_author: jamesd@echeque.com 
@_subject: [Cryptography] What are the sources of randomness used by LibSodium 
What are the sources of randomness used by LibSodium on Windows?
We can be pretty sure that randomness is under organized attack, because we can be pretty sure that RDRAND is backdoored.

@_date: 2020-02-23 12:17:56
@_author: jamesd@echeque.com 
@_subject: [Cryptography] UK "HCSEC" UK-cleared engineers try to prove 
This report looks to me like a report on the typical product of Chinese software engineering and of non engineers supervising engineers, copy and paste instead of following the dry principle.
If you use copy and paste to implement a hundred features each with almost, but not quite, the same copypasta code, then if your boss is measuring your productivity in kilolines of code, your copypasta code production becomes insanely high.
And if he is measuring your productivity in bug fixes, you will encounter a thousand bugs in a hundred features implemented by copypasta code, each caused by almost the same code, or the exact same code, and you will wind up fixing each supposedly separate bug separately, but after the third or fourth variant of what is the same or almost the same bug, your bug fix productivity becomes insanely high.
If you are following the dry principle you will wind up metaprogramming, what C++ programmers call template metacode, and lisp programmers confusingly call macros, or using metaprogrammed program transformation tools as the sqlite3 project does to generate enormous files of plain vanilla C. Joe random dumb interchangeable programmer cannot metaprogram, and Joe Random pointy haired boss does not know the difference between and engineer who can, and an engineer who cannot.
Copypasta in big projects is a big problem throughout the industry, but tends to be even worse in China, and worse with Chinese engineering teams.
Because there is so much copypasta code, most of it never gets tested in the unit test.  The number of potential bugs is astronomically large, so some bugs are bound to get into the release.

@_date: 2020-01-12 18:28:19
@_author: jamesd@echeque.com 
@_subject: [Cryptography] improved identification of non-targets 
Here is a generic design for IFF that can be used in a wide variety of applications, such as opening garage doors or making sure office doors open for employees and do not open for non employees.
And identifying airliners to Tor M1 missile batteries.
The central authority frequently issues fresh signatures to various lesser authorities, who in turn sign the keys of their subordinates, for a hierarchy of any depth.
Since using public keys, no replay attacks.  If a key leaks, it does not last long, and if it gets used by a bad guy, the entity that leaked it gets identified.
The secret that corresponds to the public key that gets signed can be in a sealed box, and to get it out you would have to get into the airliner and open up the box.
To identify as friend, you respond to a message containing an unpredictable code, with a signed message acknowledging the code, where the signing key was recently signed by the hierarchy
Thus the airport authority has a key signed by a higher authority that says "this is airport so and os", or maybe the public key of the airports well secured master key key is well known.  The airport signs the latest public key of the plane taking off with a message saying "This key belongs to flight such and such, en-route to Toronto.
This signature is valid for 20 hous, and the flight is going to arrive in Toronto well before that" Then the flight, when it gets an IFF interrogation, responds with a signature of the unpredictable data in the interrorgation using its secret key, and the airport's signature of its corresponding public key.

@_date: 2020-01-13 19:27:05
@_author: jamesd@echeque.com 
@_subject: [Cryptography] improved identification of non-targets 
That works, but only for a limited time.  Then you have to steal another The second box is likely to be difficult.
The Tor M1 anti drone system used by the Iranians lacks any form of IFF, hence is apt to shoot down your own forces.

@_date: 2020-07-03 17:14:32
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Stream Cipher over Unreliable Transport 
The default encryption provided by libsodium is an infinite (well, it
repeats after 2^256 bits, which may not be infinity to a mathematician,
but is infinity to an engineer or a physicist) stream of pseudo random
bits.  To encrypt, you exclusiveor the stream onto your data, and to
decrypt, the recipient, who has the same shared secret generating the
stream, exclusiveors it again.
The nonce is an offset into that random stream, or rather the high order
part of that offset.
so, you just use the packet number as your nonce.  Obviously you can
never repeat the same packet number with the same shared secret for
different packets, but you don't want to do that anyway.  You want to
repeat exactly the same packet with the same packet number.

@_date: 2020-07-30 14:37:18
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Cryptographically securing a two-phase commit 
Doctor doctor, it hurts when I do that.
Patient, patient, don't do that.
Why don't you just store the bundle and do any expensive computation
when it has all arrived.
You do a few public key operations to generate a shared secret when the
pile of stuff begins, as every protocol does, you do symmetric
decryption as it comes through, as every protocol does, and when you
have a pile of stuff at the end, check it for validity, as every
protocol does.
Well, I guess you have a terribly expensive test for validity, something
like a blockchain block which is an enormous pile of public key
operations, and until you have done the last one, you do not know if you
have a valid block until you have done a huge number of public key
operations and database lookups, one public key operation and one
database lookup every thirty two bytes or so.
OK, the communication starts with the sender ID, you blacklist people
who send you bad blocks, greylist people who send other people good
blocks, whitelist people who send you good blocks, and you have a rule
prohibiting ridiculously big blocks.

@_date: 2020-05-02 14:47:50
@_author: jamesd@echeque.com 
@_subject: [Cryptography] NSA security guidelines for videoconferencing 
I notice that Skype is listed as end to end encrypted, though it is apparent that every skype interaction is scanned for content.
Skype suffers undue delays, because packets are not sent end to end, but through a center or small number of centers, which became grossly overloaded when large numbers of people started to work at home.
According to message, call, and file can be viewed by Microsoft.
but only between your device and Microsoft?s servers. That data is decrypted once it reaches the server, allowing Microsoft to snoop if it so pleases.
I therefore, knowing Skype to be insecure, did not bother scanning the rest of their recommendations.

@_date: 2020-05-02 20:09:03
@_author: jamesd@echeque.com 
@_subject: [Cryptography] The EFF 650 CAs lie 
LetsEncrypt made an excruciatingly painful process dead easy, and put control into the hands of those who should have control.
LetsEncrypt deserves half a billion dollars.  The rest mostly deserve jail time.
How does LetsEncrypt get that from providing a free service?
The basic problem with certificates is that a very large number of entities can cook up a man in the middle certificate.  Have man in the middle certificates been observed in the wild?

@_date: 2020-11-05 09:05:21
@_author: jamesd@echeque.com 
@_subject: [Cryptography] reliable broadcast channel 
A key cryptographic primitive in group cryptographic protocols is the
reliable broadcast channel - that any participant can reliably send a
message that is available to all participants.
In actual practice we have unreliable point to point two party
communications, from which we have to construct a broadcast channel.
Practical applications of these cryptographic protocols seem to be
relying on a trusted broadcaster, who is apt to be untrustworthy when
there is money, power, or valuable secrets lying on the table.
Trouble is that in practice, certain messages are likely to be hidden
from certain participants, and other participants will be unaware that
they are hidden, or they will receive a discrepant message and
incorrectly believe they are receiving the same message as others.
In a large group, one can assume that more than half the participants
are honest, so one can construct a broadcast channel using the paxos
But interesting protocols are likely to involve small groups in which we
want the transaction to fail if more than half the participants are
For example, the lightning protocol is cryptographically enforced
correspondence banking, and an eternal problem in correspondence banking
is insider check kiting.  A shill sends a check to another shill, so
that one correspondence banker can scam another correspondence banker,
so the group attempting to organize the transaction is going to consist
of two shills, one scammer, one pigeon, and one innocent third party
roped in to obscure who is doing the scamming and who is being scammed,
giving a majority of three evil participants against two good and
trusting participants.
By and large, the more that is on the table, the smaller the group
engaging in the cryptographic protocol is apt to be.
We want the transaction to fail in such cases.  Generalizing to all
group cryptographic protocols, we want the broadcast channel to fail and
to be seen to fail in such cases.
What work has been done on this?

@_date: 2020-11-09 20:07:22
@_author: jamesd@echeque.com 
@_subject: [Cryptography] reliable broadcast channel 
But some of the participants may be unaware of disagreement.
The reason to have a reliable broadcast channel is so that everyone
knows what the one reality is.  The problem is having rather too many

@_date: 2020-11-09 20:14:08
@_author: jamesd@echeque.com 
@_subject: [Cryptography] reliable broadcast channel 
In correspondence banking and the lightning network, a transaction has
many participants, and consists of many bilateral transactions.
Bob sends money to intermediary one, who sends it to intermediary two,
who send it to intermediary three, who sends it to the intended
beneficiary, Carol, and Bobs gets proof of receipt by Carol, completing
the circle.
We want all bilateral transactions in the circle to complete, or no
bilateral transactions in the circle to complete.  Insider check kiting
is that the circle fails in such a way that some people's transactions
complete, and other people's transactions do not, and a large cloud of
fog is manufactured over whose transactions completed and whose did not.

@_date: 2020-11-10 09:59:45
@_author: jamesd@echeque.com 
@_subject: [Cryptography] reliable broadcast channel 
Any one gateway transaction is trustless, unlike correspondence banking.
 That is a huge difference.
But the trouble is that does not make a circle of gateway transactions
It is a hard problem, and I am far from happy with the lightning
network's design as currently implemented.
It is a considerably harder problem if you want the lightning network to
remedy the ready observability of transactions on the blockchain.
The lightning network relies on trust excessively, and the participants
do not really know who they are trusting, thus is apt to suffer from the
problems that occurred with correspondence banking - the big problem
being that everyone winds up relying on big well known entities that are
unlikely to burn their reputation over small amounts of money - but also
likely to be vulnerable to coercive power.

@_date: 2020-11-12 16:12:11
@_author: jamesd@echeque.com 
@_subject: [Cryptography] real world binary ecc 
My understanding is that, because the multiplicative inverse on a binary
field is slow, adding two elliptic points over a binary field tends to
be as slow as a month of Sundays.
What you want from an elliptic curve is that it is fast and that it does
not come from a committee because an NSA agent is always on that
committee.  I recommend libsodium's ristretto255
Why do you want binary fields?

@_date: 2020-11-14 10:11:30
@_author: jamesd@echeque.com 
@_subject: [Cryptography] real world binary ecc 
Well, your customers may well want to follow NSA-FIPS 186-4, and the
customer is always right.  Not to mention wise, handsome and witty,
though I suspect they will not want elliptic curves based on binary fields.
Having several algorithms in a library that do much the same thing
multiplies points of failure.  The only reason for having redundant
algorithms is to support interaction with legacy software.  (Which one
frequently has to do.)  One should not give the application programmer a
pile of toothpicks and glue and tell him he can build whatever he likes
with them.
But anything touched by a committee has been touched by the NSA.
If you add cup of wine to a barrel of sewage, you have a barrel of sewage.
If you add cup of sewage to a barrel of wine, you still have a barrel of
Obviously if everyone implements whatever cryptography is good in their
own eyes, this is very bad.
But if we have a committee to decide what cryptography everyone should
implement, this is considerably worse, as has been demonstrated by
repeated painful experience.  It is a central point of failure, and
committees are inherently failure prone.
Therefore everyone should implement the cryptographic algorithms
commanded by Jon Callas, unelected president for life of symmetric
cryptography, and Daniel Bernstein God King of asymmetric cryptography.

@_date: 2020-11-23 15:38:06
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Possible reason why password usage rules are 
I am technically literate, but my experience was that Qubes OS is unusable.
Is anyone on this list using it successful?
It is a highly secure virtualization environment, and the intent is that
you will run a dozen actually useful operating systems contained in
virtual boxes and separated from each other.
You cannot do anything useful in Qubes, and are not intended to do
anything useful in Qubes.  You are intended to run some operating system
that is useful and convenient, such as windows, in a virtual machine
under Qubes, and have a whole bunch of such environments isolated from
each other.
But, compared to Oracle VM, seemed to me back then to be semi broken and
pain in the ass.
That was some considerable time ago.  How does it compare with Oracle VM
these days?

@_date: 2020-11-23 15:49:34
@_author: jamesd@echeque.com 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
A camel is a horse designed by a committee.
QUIC has a sound design, in that it is more friendly to the message
oriented way that TCP actually works in practice, considerably more
efficient at handling encrypted streams because encryption block
boundaries happen at datagram boundaries, and most importantly reduces
redundant round tripping by integrating the TCP handshake with the
encryption handshake.
But it fails to  handle the DDOS problem, and its worst feature is that
it married to the Google code base, which was designed by geniuses but
is maintained by idiots.
Google has no end of really great code, but if someone attaches a
millstone instead of a life preserver to the codebase, I would rather
not have my code attached to that code at the hip.

@_date: 2020-11-23 16:14:36
@_author: jamesd@echeque.com 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
Proof of work will be set at near zero when the server is not under
heavy load, and when it is under heavy load, you don't care if a
smartwatch takes five minutes to open a connection.

@_date: 2020-11-30 16:13:34
@_author: jamesd@echeque.com 
@_subject: [Cryptography] Make it rain, baby girl. 
Nuts.  We have seven hundred affidavits sworn on penalty of perjury, and
in the PA conference, we had witness after witness come forward to
report massive and blatant fraud.
Several hours of witnesses testifying in person before the PA senators
about fraud in PA
We also have statistical analysis of the votes for indicators of the
kind of fraud testified to by witness after witness, which indicates
about four million fraudulent or altered ballots nationwide
Looks like what happened is that the Democrats ran massive fraud
prepared in advance, and then when that proved insufficient because of
the unexpected scale of the Trump landslide, added seven hundred
thousand in the early hours of the morning

@_date: 2020-09-11 11:07:56
@_author: jamesd@echeque.com 
@_subject: [Cryptography] algorithm for offline spend? 
Some time ago, someone constructed an algorithm for offline on the spot
spending of a coin.
Assume all participants have a valuable secret key that they do not want
to reveal.
Every time you spend the coin to someone else, it accumulates more data
(and must eventually spent online to strip off the excess data.
If anyone double spends the coin, he reveals his secret key.
Does anyone recollect a link or cite for that algorithm?
That algorithm might make it possible to fix the lightning network
to work as it should.
