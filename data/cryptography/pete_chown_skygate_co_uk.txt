
@_date: 2001-04-02 11:15:24
@_author: Pete Chown 
@_subject: secure hash modes for rijndael 
According to the HAC those three have provable security, subject of
course to any weaknesses in the underlying block cipher.  Of course
this may make them sound better than they are.  It is possible that
the cipher may be less secure in this mode than in one of its more
usual encryption modes.
The snag is that it is going to be hard to get any significant review
of this scheme.  If current schemes offer provable security with the
same hash rate, no one is going to be interested in a new one.
On the subject of these hash functions...  I looked at some benchmark
figures and SHA-256 is not substantially faster than Rijndael-256 with
Davies-Meyer.  I wonder why there was so much energy put into the AES
process, and then SHA-256 was given to us by the NSA with no public
review, almost as an afterthought.
I'm not saying that SHA-256 is deliberately broken.  If that was what
the NSA wanted they would go for a broken AES not a broken hash.  In
fact I'm just wondering what is going on because SHA-256 seems like a
bit of a waste of time.
Do the NSA know something about Rijndael-256 that we don't?  Also, do
they know something about SHA-1 that we don't?  This might explain why
the new revision is so much slower...

@_date: 2001-04-03 09:53:46
@_author: Pete Chown 
@_subject: secure hash modes for rijndael 
I used Brian Gladman's benchmarks for Rijndael, at:
I think the SHA-256 benchmarks were just posted to Coderpunks or
something like that -- they seemed slow, which got me interested in
doing a comparison.  So I don't have a URL, sorry.  It was the ia32
According to Brian Gladman, Rijndael-256 takes 305 cycles to set up a
new key for encryption, and 374 cycles to encrypt one block.  This is
on a Pentium Pro, not a Pentium III, but the figures should be similar
to a first approximation.
This suggests that one hash step takes 876 cycles or 1.095uS on your
processor.  Each step hashes 32 bytes giving a figure of ~36mS/Mb, or
~~27.9 Mb/S.  So actually this would be rather worse than SHA-1 but
rather better than SHA-256...
Actually there is another flaw in these figures.  Gladman benchmarked
the candidates based on the AES requirements of 128-bit blocks.
However, for this we need the special Rijndael mode with 256-bit
blocks as well as 256-bit keys.  It is possible that that may distort
the figures too.
Given the amount of analysis that has gone into AES, I think this hash
function probably has reasonable security.  Interestingly there have
been far more successful attacks on hash functions than block ciphers.
Damaging attacks have been found on both MD4 and MD5.  It might be
that we could get better hash functions by using a block cipher rather
than an MD4-style compression function.

@_date: 2001-07-18 18:28:28
@_author: Pete Chown 
@_subject: I'm looking for FSE2001 proceedings 
It's annoying that crypto papers hardly ever seem to be made available
online.  I wonder if there is any chance of crypto researchers joining
the scientific journal boycott...
The boycott is described here among other places:
Basically the researchers, who are currently mostly in the life
sciences, want papers published freely on the web after six months.
So if you need completely up to date information, you buy the
journal.  If you aren't bothered you can look on the web.  According
to the Scientific American article they have 15,000 researchers
including several Nobel prize winners.
This wouldn't help Alex, though...  :-(

@_date: 2001-07-19 11:29:05
@_author: Pete Chown 
@_subject: I'm looking for FSE2001 proceedings 
I've been trying to get hold of Hans Dobbertin's results on MD4, which
was the original reason for my comment.  Are these available on the
web anywhere?  I can't find them.
I've seen a simplified version of MD4 in use which I think is an
interesting target for cryptanalysis.  One assumes that since MD4 is
not collision free the simplified version is not.  I would like to see
if preimage attacks are possible on the simplified version.
(Collision resistance is not actually important for the application
where the simplified MD4 is in use.)

@_date: 2001-03-30 13:34:12
@_author: Pete Chown 
@_subject: secure hash modes for rijndael 
Why not just use Matyas-Meyer-Oseas (or one of the variants) with
256-bit keys and blocks?

@_date: 2002-08-07 22:07:25
@_author: Pete Chown 
@_subject: Challenge to TCPA/Palladium detractors 
On balance, I suspect I would say that this is not a desirable goal.  I
can see that it has its uses, but I think they are outweighed by the
fact that I would no longer have complete control of my own computer. "Complete control" means being able to lie if I choose to.
If it is coming anyway, I think the harm would be mitigated if two
features were provided:
Firstly, there should be no discrimination between operating systems.  I
want to be able to run a version of Linux (or any other operating
system) that makes use of the hardware security features.  If I built my
own operating system, people might not trust it as much as operating
systems that are better known.  Fine, that's the way trust works.  But I
still want my operating system to be able to use the hardware.  The
signatures would be for "program foo running on PeteOS", so making clear
to the relying party that the signature is only as good as my operating
system's security.
Secondly, there should be no discrimination between applications.  I
should be able to write a DRM system that works in the same way as any
RIAA-approved one.  Of course people may not trust my system, that's
their choice.
I'd be interested to know what the experts think -- will this
functionality be available to me?

@_date: 2002-08-09 20:56:25
@_author: Pete Chown 
@_subject: Thanks, Lucky, for helping to kill gnutella 
This is the wrong solution.  One of the important factors in the
Internet's growth was that the IETF exercised enough control, but not
too much.  So HTTP is standardised, which allows (theoretically) any
browser to talk to any web server.  At the same time the higher levels
are not standardised, so someone who has an idea for a better browser or
web server is free to implement it.
If you build a protocol which allows selfish behaviour, you have done
your job badly.  Preventing selfish behaviour in distributed systems is
not easy, but that is the problem we need to solve.  It would be a good
discussion for this list.
Exactly.  This has already happened with unauthorised AIM clients.  My
freedom to lie allows me to use GAIM rather than AOL's client.  In this
case, IMO, the ethics are the other way round.  AOL seeks to use its
(partial) monopoly to keep a grip on the IM market.  The freedom to lie
mitigates this monopoly to an extent.

@_date: 2002-08-10 19:34:18
@_author: Pete Chown 
@_subject: Thanks, Lucky, for helping to kill gnutella 
Right, so let's solve this problem.  Palladium/TCPA solves the problem
in one sense, but in a very inconvenient way.  First of all, they stop
you running a client which has been modified in any way -- not just a
client which has been modified to be selfish.  Secondly, they facilitate
the other bad things which have been raised on this list.
The reason for that is that we all disagree with you.  I'm interested to
read your opinions, but I will argue against you.  I'm not interested in
reading flames at all.

@_date: 2002-12-08 19:14:13
@_author: Pete Chown 
@_subject: PGPfreeware 8.0: Not so good news for crypto newcomers 
Is there really any reason to use PGP these days?  PGP 2 was solid software.  I've also tried all the releases from 5 to 7 and they were all full of bugs.  They also didn't comply properly with the OpenPGP spec.
I particularly remember PGP 6.  I was developing something that generated OpenPGP packets.  Gnupg was happy, PGP would die with a SEGV.   I started digging into the source code to try to find out what was going on, but it was hopeless.  The bloat factor had taken over, and it was impossible within my deadline to find out what its problem was, and whether the SEGV came from an exploitable buffer overrun.  (Eventually I got things to work by switching encryption algorithms or something like that, I forget the details now.)
I hope PGP 8 is better, but at the moment I would only recommend PGP 2 and gnupg on technical grounds.  Inevitably it would be gnupg because, strangely enough, it seems to have got written in spite of the fact that it is freies Bier und freie Rede. :-)

@_date: 2002-12-17 10:58:00
@_author: Pete Chown 
@_subject: Micropayments, redux 
Actually I think it may be a showstopper in practice for rather different reasons -- people's behaviour when exposed to risks is rather odd.  The British lottery, for example, pays on average ?0.50 for each ?1 ticket.  No one would buy a 50p piece for ?1, but people will buy an expected win of 50p for ?1.  People worry more about their children being the victim of a paedophile than getting run down by a car.  People worry more about the tiny risk from the measles vaccine (if it is a risk at all) than about the risk of dying in a measles epidemic.
I don't know which way the psychology would work in this case.  Would people be put off buying content by the small chance of paying a high price?  Alternatively, would they enjoy the gamble, and the fact that most of the time they would get content free?  I think it may be the former, because the protocol is like the lottery in reverse.  The lottery promises you a small chance of a big win.  This micropayment scheme gives you the small chance of a relatively big loss.
There is also the risk that the system could be classed as an illegal lottery in some jurisdictions.

@_date: 2002-02-11 11:39:50
@_author: Pete Chown 
@_subject: PGP & GPG compatibility 
Sure, it is more flexible than X.509 because you could implement the
X.509 trust model in OpenPGP if you wanted to.
Perhaps that is an argument for a new certificate format.  I've thought
that an XML based certificate format would work well...  It could take
advantage of the XML digital signature work, it would be human readable,
and it could be processed with existing tools.  There are also lots of
existing schemas that could be used, such as vcard.

@_date: 2002-01-21 11:02:42
@_author: Pete Chown 
@_subject: PGP & GPG compatibility 
That's an interesting article.  I wrote Whisper
( as a different way of making crypto more
usable.  The idea is that you simply agree a pass phrase with the
correspondent beforehand.  You then encrypt your message with a small
and hopefully bullet-proof program.  It isn't innovative
cryptographically, and that is the point -- hopefully it is simple
enough that anyone with basic computer literacy can make it work.
Of course the effect of Whisper is different to the zero-UI encryption. Whisper provides you with good security (subject to weak pass phrases
and bugs), but you must agree a pass phrase beforehand.  Zero-UI
encryption is more vulnerable to active attacks on the network, but
works with much less effort.
One enhancement to the zero-UI model that I think might be worthwhile is
automated key exchange ahead of the first message.  So when Alice asks
to email Bob, her computer first sends a message asking for Bob's key. When the reply is received, Alice's original message is taken out of the
queue, encrypted and sent.  This way the first message doesn't go across
the network in the clear.
If we don't want to add another round-trip time, we could make keys
available from a key server.  This would have the disadvantage that
attackers could compromise the key server and replace the keys with
false ones.  However, this would be detected almost straight away if
they could not modify communications going directly between Alice and
Bob -- Bob would receive a message that he couldn't decrypt.  Normally
surveillance operations have to be kept secret so this kind of attack
would be impractical.

@_date: 2002-07-05 14:58:58
@_author: Pete Chown 
@_subject: New Chips Can Keep a Tight Rein on Consumers 
There is no copyright issue, though.  The DMCA only bans circumvention
devices that relate to copyrighted content.
I don't know what would happen if you included copyright content in the
chip.  A printer could check that a particular short story is included
in the chip before it would work.  The courts may see this as too
contrived, however.
The other possibility would be to invent something trivial, patent it,
and design the chips around it.

@_date: 2002-07-18 19:18:49
@_author: Pete Chown 
@_subject: It's Time to Abandon Insecure Languages 
Ugh, looks like the English language did too. :-)
This is nonsense, you don't need a managed environment to get type
safety.  Pascal was being compiled ahead of time for years before Java
was ever thought of.  (You can break type safety in Pascal, but you have
to make an effort.)
If you want totally type safe languages that use ahead of time
compilation, look at Eiffel, Sather, the Bigloo Scheme compiler, and so
on.  Also don't forget gcj, which does ahead of time compilation for
Java with the same type checking that you get in the "managed
This I can agree with.  On the other hand I don't see Java as a language
that emphasises safety.  It may have type checking, but it has inherited
a lot of obscure syntax from C.  Remember, we aren't just interested in
avoiding type errors.  We have to reduce the overall bug counts, because
there are plenty of security holes that don't result from typing
It would be better to look at Eiffel (or Ada if you really must, but
personally I don't like it).  Eiffel has a Pascal-like syntax which is
more verbose than Java, but more readable.  You have to type a bit more,
but you don't waste hours debugging because you wrote "=" instead of
"==".  It has a few other special features to help you write bug free
code.  For example statement blocks can be annotated with conditions
that are supposed to be true on entry and exit.  This is supposed to
enforce a "programming by contract" mentality.
Perl-style tainting would be an interesting thing to add to another
language.  IMHO, Perl is not a good safe language because its syntax is
even more obscure than C's.  (It does have the advantage of being almost
completely type safe though.)  Tainting is a good security measure,
though, which would be good in a language like Eiffel.

@_date: 2002-07-20 15:01:46
@_author: Pete Chown 
@_subject: It's Time to Abandon Insecure Languages 
My experience is a bit different.  We have a product that was first
written in C, and was then rewritten in Java.  The Java version took
about a third to half the time to write, and has had far fewer bugs.
The application is multi-threaded.  With the original version we had
endless problems with deadlock, or bad interactions between threads that
would lead to a core dump some distance down the road.  The chance of
finding out what had happened was about zero.  For example, during the
QA process for the last release of the C product, at one point a
deadlock occurred.  The bug report was completely useless because we
never managed to reproduce the problem.  However, bugs don't just go
away, I am sure that various people have run into the same difficulty.
No security-related bugs have turned up in either version, but based on
the bug counts for the products, I am sure that there are many more in
the C version.
I do know what you mean about having to hack things, though.  The Java
version has to run as a service on Windows, and getting this set up has
been very painful.  Although the overall development time has been
shorter, some aspects of it have been much longer.
Two thoughts occur to me here.  The first is that computer technology is
often selected for irrational reasons.  Everyone who has worked in the
business will have had the experience of a non-technical manager making
bad technical decisions.  Also I think a lot of software developers
stick with what they know.  For this reason, the fact that there is a
lot of C around means that it is the language people select.
The other thought is that perhaps C does have more merit than I am
giving credit for.  You've alluded to this by saying that C projects
progress more quickly, but can you think of the specific attribute of C
that makes this happen?  I can't, but if there is something it should be
implemented for other languages too!

@_date: 2002-06-21 22:12:50
@_author: Pete Chown 
@_subject: Shortcut digital signature verification failure 
You could also vary the amount of hashcash required depending on the
number of bad signatures you are receiving.  So normally you would
require no hashcash, so the clients don't have to expend CPU cycles. Then as the number of bad signatures increases, you step up the amount
of hashcash so that you can continue coping.
Interestingly you ought to be able to calculate the amount of hashcash
required to keep the flow of bad signatures manageable.  Suppose your
current hashcash requirement is x, and bad signatures are arriving at
twice the speed your crypto accelerator can cope with.  Then, assuming
that the hashcash calculation is the dominant cost for the attackers,
you need to double your requirement to 2x.

@_date: 2002-06-23 12:54:30
@_author: Pete Chown 
@_subject: Secure mail relays [was:RE: DOJ proposes US data-rentention 
Actually I'm not sure it has been completely ineffective.  Cutting the
numbers of open relays won't be an effective anti-spam measure until
there are almost none left.  I saw figures implying that the proportion
of open relays is now well below 10%, from nearly 100% a few years ago. Pretty soon open relays will become unusable for legitimate users, not
because of anti-spam campaigners, but because they will be relaying so
much spam!  This may cause the decline to accelerate in the near future.
If you want to run an open relay, why not make it ask for hashcash
before it accepts mail?
I don't know if it's still like it, but I remember years ago, to post to
alt.hackers you had to forge an Approved: header line.  I've sometimes
thought that it would be nice to do the same thing with IPsec or IPv6. Imagine a clone of Kuro5hin or Slashdot, but with the extra hurdle that
you have to use IPv6 (probably using 6 over 4 encapsulation) or
opportunistic IPsec.  You would automatically exclude non-hackers.
More importantly, such a development would encourage deployment of those
technologies across the Internet.  As more content emerges that is
inaccessible to people using only plain IPv4, it creates an incentive to
switch.  The more people that switch, especially to IPv6, the more
likely it is that more similar content will emerge.

@_date: 2002-06-24 18:37:12
@_author: Pete Chown 
@_subject: Ross's TCPA paper 
Recently there have been a number of articles pointing out how much
money Microsoft is losing on Xbox sales.  To some extent, of course,
console makers expect to lose money on the consoles themselves, making
it up on the games.  However Microsoft seems to be losing more than
anyone else.
Perhaps Microsoft don't care, because the Xbox is one vision they have
of the future.  Gradually it starts running more than just games, but
you still get the ease of use and security of a console.
It's always risky making predictions, but I think that over the next few
years, free software will do in the desktop space what has already
happened in the server space.  There is a kind of economic inevitability
about it; competing with a free product of equivalent quality is
virtually impossible.
Now, Gates isn't stupid, and I'm sure he's aware of this risk.  So we
have various alternative strategies.  One is web services.  The other
strategy is to become more closed at the same time as everyone else is
becoming more open.  That strategy is the Xbox, which may over time
evolve into the kind of tamper resistant system that we have been
talking about.
It might simply be useful that it exists.  If people complain that they
can't run Linux on the new systems, it could create all sorts of
anti-trust problems.  However, even if they didn't try to make money out
of the product, it still wouldn't be free in the freedom sense.
A similar problem to this has already come up, albeit in a much less
serious form.  When the Mindterm ssh client is used as an applet, it
needs to be signed in order to be maximally useful.  At one point it was
available under the GPL, but of course if you changed it the signature
was invalidated.  In this case you could at least get your own code
signing key, but there were problems.  Firstly it cost money.  Secondly
by signing code that you didn't write, you would be taking
responsibility for something being secure when you had no easy way of
verifying that.
I think it would be a breach of the GPL to stop people redistributing
the signature: "You must cause any work that you distribute or publish,
that in whole or in part contains or is derived from the Program or any
part thereof, to be licensed as a whole at no charge to all third
parties under the terms of this License."
This doesn't help with your other point, though; people wouldn't be able
to modify the code and have a useful end product.  I wonder if it could
be argued that your private key is part of the source code?
What if the DRM system was cracked by means of something that you were
allowed to do under the GPL?  If they use the DMCA, or the Motherhood
and Apple Pie Promotion Act against you, they have to stop distributing
Linux.  "If you cannot distribute so as to satisfy simultaneously your
obligations under this License and any other pertinent obligations, then
as a consequence you may not distribute the Program at all."
BTW, Ross, does Microsoft Research in Cambridge work on this kind of

@_date: 2002-06-24 21:45:14
@_author: Pete Chown 
@_subject: Ross's TCPA paper 
Good point.  At least I hope they don't. :-)
Perhaps it did, but the licence agreement was unenforceable.  It's
clearly reverse engineering for interoperability (between Linux and DVD
players) so the legal exemption applies.  You can't escape the exemption
by contract.  Now, you might say that morally he should obey the
agreement he made.  My view is that there is a reason why this type of
contract is unenforceable; you might as well take advantage of the
The prosecution was on some nonsense charge that amounted to him
burgling his own house.  A statute that was meant to penalise computer
break-ins was used against someone who owned the computer that he broke
Right, but it has an odd effect too.  No legal system gives people
complete freedom to contract.  Suppose you really, really want to exempt
a shop from liability if your new toaster explodes.  You can't do it;
the legal system does not give you the freedom to contract in that way.
DRM, however, gives people complete freedom to make contracts about how
they will deal with digital content.  Under EU single market rules, a
contract term to the effect that you could pass on your content to
someone in the UK but not the rest of the EU is unenforceable.  No
problem for DRM though...
I think lawyers will hate this.

@_date: 2002-06-26 11:54:19
@_author: Pete Chown 
@_subject: Ross's TCPA paper 
Not in Europe though.  EU directive 91/250/EEC "on the legal protection
of computer programs" makes provision for reverse engineering for
interoperability. In Britain this was incorporated into domestic law by
the Copyright (Computer Programs) Regulations 1992:
See in particular s.50B(4) which the regulations added to the Copyright
Designs and Patents Act 1988.
The American cases were, but the European case of course wasn't.  The
DMCA doesn't apply over here, though we have something similar in the
You should hate it. :-) It is appropriate for the legislature to decide
which acts are restricted by copyright and which are not.  The DMCA and
similar legislation hands that right to private organisations.  To some
extent anti-trust law guards against the worst abuses, but it is more
appropriate for the boundaries of copyright to be set by our "elected
BTW, I have been thinking for a while about putting together a UK
competition complaint about DVD region coding.  No promises that
anything will happen quickly.  On the other hand, if people offer help
(or just tell me that they think it is a worthwhile thing to do) it will
probably move faster.

@_date: 2002-03-25 10:14:06
@_author: Pete Chown 
@_subject: Neural network 'in-jokes' could pass secrets 
Sounds a bit reminiscent of the steganographic spam:
The current implementation is not keyed so it would be very easy to try
all received spam to determine whether or not it decrypts to something
useful.  Adding keying should be easy though.  It's pretty neat IMO --
if you hid messages in images, say, you might have to explain why you
had received so many.  But no one has to explain why they receive spam.
Making realistic sounding "in-jokes" might be more difficult, but if
they can come up with something convincing it will work well too.
I've been thinking about something similar in connection with the
Napster-style file sharing networks.  If I want to share an MP3, that's
easy, I just set up a web server and put the MP3 on it.  The problem is
enabling people to find it.  Napster had a centralised model, and
various decentralised search systems have followed.
My idea is slightly different.  Instead of providing a new search
facility, simply piggy-back on existing ones.  Convert the details of
the MP3 and its location to obscure phrases, put them on a website, and
get it indexed by the search engines.  People who want the MP3 do the
same thing and just locate it with a regular search engine.

@_date: 2002-05-26 13:04:43
@_author: Pete Chown 
@_subject: FC: Hollywood wants to plug "analog hole," regulate A-D 
Actually this would be weird.  Suppose digital cameras had to be fitted
with a watermark detection system.  Suddenly, we have lost a much more
fundamental fair use right -- the right to include copyright material as
an incidental part of a photograph.
If I took a photograph of a street scene, there would be huge amounts of
copyright material in it.  The design of people's clothes would be
copyright, the architects would have rights in the design of the
buildings, billboard images would be copyright, and so on.
I can't think how you could embed a watermark in the design of a
building, but in theory it could be possible to do so with a billboard
image.  What happens then, will the camera refuse to take the

@_date: 2002-11-03 15:32:23
@_author: Pete Chown 
@_subject: Windows 2000 declared secure 
I agree that the Linux kernel probably couldn't pass because of lack of documentation.  This is even more true for "GNU/Linux", the loosely defined collection of software that makes up a real Linux system.  If wuftpd has a buffer overflow, is that a hole in "GNU/Linux", or a hole in wuftpd?  What about the Foo Linux distribution that only comes with At the same time, I think a specific distribution probably could be evaluated.  Red Hat have a well defined QA process for example.
Another problem might be the granularity of access controls.  IIRC Unix systems that were evaluated to C2 had to include some kind of ACL system.  The user/group/others split wasn't good enough.  SELinux would pass this requirement easily, but vanilla Linux systems might have a On another note, I'd be interested to hear more about how Eros is going to get EAL7.  Formal verification of a whole OS sounds horribly difficult, but very exciting if it can be done.  One problem I've always had with correctness proofs is that they prove the program to satisfy some statement of the problem.  They don't prove that the problem stated is the one you intended to solve.  How will you avoid this with your proofs of Eros' security?
As an example of what I mean, here is a statement of what it means for one list to be the concatenation of two others:
concat([], X, X).
concat([H | T], X, [H | U]) :- concat(T, X, U).
In other words, the empty list concatenated with any other list gives that list unchanged.  Then, in general, a list X is the concatenation of Y and Z iff: (i) X and Y have the same head, and (ii) the tail of X is the concatenation of the tail of Y with Z.
Unfortunately, not only is this a statement of the problem, it is also a Prolog program which solves the problem. :-) So, it's provably correct, because the solution and the statement of the problem are the same thing.  Of course it's provably correct in a rather useless way...

@_date: 2002-10-16 13:54:15
@_author: Pete Chown 
@_subject: [Bruce Schneier <schneier@counterpane.com>] CRYPTO-GRAM, October 
Just post your IP address on the list, and we'll see if it's vulnerable to anything. ;-)
On a more serious note, there is the Gibson research port scanner, here:
I'd feel happier with nmap, but it gave the right answers for our firewall when I tested it just now.

@_date: 2002-09-17 12:16:15
@_author: Pete Chown 
@_subject: Cryptogram: Palladium Only for DRM 
This says it all.  "It may even be possible for you to keep a small subset of the freedoms you enjoy today."
Have you seen Richard Stallman's introduction to free software?  I'd be interested to know what you think of each of the "freedoms" and whether you think they are available under Palladium/TCPA:
(Some of the freedoms are unaffected, of course.)

@_date: 2002-09-18 20:53:11
@_author: Pete Chown 
@_subject: Cryptogram: Palladium Only for DRM 
Well, how about the freedom to modify the software.  You said that it might be possible for users to compile the software themselves.  This would allow them to audit the software's function.  It would not allow them to change it, because a modified version wouldn't be trusted by the

@_date: 2003-04-09 21:15:39
@_author: Pete Chown 
@_subject: Swiss ISPs Required to Log and Store Email for Six Months 
Incidentally, this is not true for SRV records.  In some ways, SRV is like MX, but it does a lot more.  One of the new features is that you can specify a port.  Unfortunately SRV is not widely used as yet.
This may have positive implications for privacy, and negative implications for firewalls that do egress filtering.

@_date: 2003-04-28 19:27:57
@_author: Pete Chown 
@_subject: two number theory questions 
Can't you just calculate the Jacobi symbol to find out whether g^x is a quadratic residue modulo p?  An algorithm for that is described in the Handbook of Applied Cryptography.
I can't immediately see how the extended Euclidean algorithm would work in this context; can you elaborate?

@_date: 2003-02-04 10:08:33
@_author: Pete Chown 
@_subject: question about rsa encryption 
There are a few different ones, some simple and some complex.  First of all, imagine encrypting 0 or 1.  Encryption leaves these numbers unchanged.  Now, if each possible plaintext had equal probability, this would be extremely unlikely.  However, in practice it is likely that users may want to encrypt small numbers.
Another problem is that RSA encryptions multiply.  If r(x) is the encryption operation, then r(x) r(y) = r(xy).  Informally:
r(x) r(y) = (x ** e) (y ** e)
           = x * x * x * ... * y * y * y
           = xy * xy * ... * xy
           = (xy) ** e
           = r(xy)
I think there are a few others too...

@_date: 2003-02-09 13:51:07
@_author: Pete Chown 
@_subject: Columbia crypto box 
I seem to remember that the Nazis said the same thing about Enigma.
Even when evidence began to filter back that it had been broken, they
ignored it because they were so confident that a break was impossible.
It's true that protocol and programming problems account for the huge
majority of security holes.  The WEP break, though, was one notable
exception.  They were using an established cryptosystem (RC4) with a
planet sized key (128 bits).  However, a weakness in RC4 itself let them
I don't know about 4096-bit, but you should switch to something if you
care about security; recent results imply that it may be possible to
factor 1024-bit numbers.

@_date: 2003-02-13 10:20:19
@_author: Pete Chown 
@_subject: Columbia crypto box 
As a footnote to those times, 2 ** 40 is 1,099,511,627,776.  My PC can do 3,400,000 DES encryptions per second (according to openssl).  I believe DES key setup is around the same cost as one encryption, so we should halve this if a different key is being used each time.  Brute force of a 40-bit DES key will therefore take about a week.  In other words 40-bit DES encryption is virtually useless, as brute force would be available to anyone with a modern PC.

@_date: 2003-01-07 23:33:40
@_author: Pete Chown 
@_subject: DeCSS, crypto, law, and economics 
I see what you mean, but do you think it applies to DVDs?  The segmentation needs to be in each market, between rich and poor consumers.  What we actually have is segmentation between markets, say Europe and the US.  Europe and the US have similar income per head, but various obscure factors cause products like DVDs to be more expensive in The other interesting thing about market segmentation is that it is often illegal.  Britain's competition law is being reformed in summer this year.  Running a cartel will become a crime, in addition to the current civil penalty regime.  It will also become possible to bring private anti-trust suits.  In other words we are moving towards the American model of anti-trust.
I intend to make a complaint about DVD region coding, and I will wait until the summer because the prospect of going to prison will add some extra pizazz for the defending team.  Don't get too excited, though, it isn't always easy to get these things moving in the UK.  Read about the Walls Ice Cream case if you're curious...
One thing I will need, though, is an economic argument, so keep it coming...
I agree up to a point, but I also think properly functioning markets are very beneficial to a society.  I think the moral position is normally the one that creates the most competition.  For example, consumers should have the right to choose between a region-2 DVD player and a region free one.  People should have the right to choose between watching DVDs on a dedicated player, on a PC running Windows and a PC running Linux.
Would you rather maximise wealth or maximise competition?  It sounds like a silly question, but suppose the technology and legal framework required to support your solution prevented the use of open source.  In that case, I would rather maximise competition.  In any case, it might be that this would maximise wealth in the long term, by increasing technological innovation.

@_date: 2003-01-08 10:50:33
@_author: Pete Chown 
@_subject: DeCSS, crypto, law, and economics 
You are right that producers would want to segment the market, but we have no reason to introduce extra laws to help them.  We would only have a reason to do that when segmenting the market results in greater efficiency, not merely greater profits.
With DVDs we have a complex situation.  Supposedly studios can make more per film, so they can afford to make more marginal films.  Also more people are offered films at a price they can afford.  Oddly, in practice it doesn't seem to work this way.  Films tend to be launched in the US, which is one of the lowest cost markets.  Films that do badly could theoretically be released at a higher cost in other markets, to recoup the expenditure through differential pricing.  In practice they seem to be dropped.
Coupled with this, we have the negative effect on the technology industry that results from DRM.  A small efficiency gain for the content industry could become a large efficiency loss for the technology industry.  Suppose that open source operating systems were technically able to play DVDs but were prohibited from doing so by law.  Suppose also that open source was a much more efficient economic model.  You would now have a more classic case of market distortion, which also gives rise to inefficiency.
One last point is that governments serve the interests primarily of their own people.  So the job of Britain's government is to get me, and other Brits, the best possible deal on films within the UK.  This might mean balancing the interests of British consumers against British film producers.  It doesn't mean balancing British consumers against foreign film producers.  If no films were made in Britain, the government would logically insist on a completely free market that allowed parallel imports and circumvention measures.
I agree; for example copyright itself is a restriction on commercial freedom in a sense.  You have to weigh up the pros and cons in each case.  For me the collateral damage from DRM and region locking is simply too great, and so I believe it should be prohibited (or that people should be allowed to circumvent it, which would have the same

@_date: 2003-01-09 10:13:20
@_author: Pete Chown 
@_subject: DeCSS, crypto, law, and economics 
I think that DRM mechanisms may increase piracy.  A few years ago you could buy a CD, knowing that it was a standard product which you could use in certain ways.  Now, you might get it home and find that you can play it in your hi-fi, but not in your car.  Next time, you're not going to make that mistake, you'll just log on to Kazaa and download an MP3.

@_date: 2003-01-09 10:18:33
@_author: Pete Chown 
@_subject: DeCSS, crypto, law, and economics 
Actually my TV is happy with either.  I always had the notion that I wouldn't be able to play American videotapes, but then I tried it and it works fine.  So if I don't want to bother with region codes, the other possibility is to buy films on video.
When I play region-1 DVDs, the player doesn't convert the signal.  This would introduce a slight judder because of the differing frame rates. Instead the TV just acts like a multisync monitor, and adjusts to the signal it is given.
(My TV is a middle of the road model, not the cheapest but nowhere near the most expensive either.)

@_date: 2003-01-25 11:53:23
@_author: Pete Chown 
@_subject: [IP] Master Key Copying Revealed (Matt Blaze of ATT Labs) 
Isn't this like saying that cryptography isn't important, because most real world attacks aren't cipher breaks?  Also, if you pick the lock, potentially no one will know that you gained access.  An ordinary burglar can just break a window, but someone with a more subtle reason for wanting to gain access may not want to.
If I wanted to make a building physically secure, my instinct would be to use electronic locks.  While attacks on, say, an iButton are probably possible, it seems to me that it must be an order of magnitude more difficult than attacking a mechanical lock.
Now, I'm not an expert on locks, so firstly am I right?  If so, does this mean that high security mechanical locks will gradually disappear?

@_date: 2003-07-10 23:37:14
@_author: Pete Chown 
@_subject: SSL 
You might look at NSS.  It's the Netscape implementation of TLS, used in Mozilla among other things.  You might find it easier to follow than OpenSSL.  It's also Windows-friendly, running on top of NSPR, the Netscape Portable Runtime (another useful piece of code, but not on topic for this list).
If you just want to know how the protocol works, for example to implement it, read RFC 2246.  If you want the rationale as well, read one of the books that others have pointed out.
The protocol is actually being revised, if you want to look at the bleeding edge, try:

@_date: 2003-06-10 10:14:27
@_author: Pete Chown 
@_subject: The real problem that https has conspicuously failed to fix 
It might help if browsers displayed some details of the certificate without being asked.  For example, instead of a padlock, the browser could have an SSL toolbar.  This would show the verified name and address of the site you are connected to.
The bar could also show the server name for unverified connections. This would avoid the attacks that use URLs like  at virus.com .

@_date: 2003-06-11 14:50:08
@_author: Pete Chown 
@_subject: The real problem that https has conspicuously failed to fix 
You could achieve the same protection on any system with decent mandatory access controls.  SELinux would be fine, for example.  You could have a program like ssh-agent which performs the public key operations; you then deny everything else access to the key store.

@_date: 2003-06-17 09:52:24
@_author: Pete Chown 
@_subject: Session Fixation Vulnerability in Web Based Apps 
Unfortunately not all users have a single IP.  I know AOL users, for example, go through a cluster of proxies that all have their own IP addresses.  This means that the web server can see a different IP every time the browser makes a request.
You might also have a problem with multi user machines.  The users on the machine would be able to take over each others' sessions, even if they couldn't do it with outsiders.
I don't think this session ID problem is a fundamental design error, it's just a bug in certain implementations that are out there at the moment.  If a server receives a session ID from a browser that doesn't exist, it shouldn't simply create it.  Instead it should issue a new random session ID.  This solves the problem doesn't it?

@_date: 2003-06-17 09:57:24
@_author: Pete Chown 
@_subject: Wildcard Certs 
I think this is one of the cases where security can't be considered in isolation.  It depends what risks you are trying to protect against.  In a large company you might want to limit the effects of a key compromise.   For example you might want to make sure that someone who steals the UK key can't masquerade as the American office.
I can't see any generalised threats that would justify withdrawing wildcard certs, but perhaps others can.

@_date: 2003-06-25 12:02:39
@_author: Pete Chown 
@_subject: New toy: SSLbar 
I think this is a problem for all open source projects.  Suppose I wrote a trojan open source product.  Although the code is open for review, how many people actually do review it?  I could list the product on Freshmeat, and if it looked like an exciting piece of technology, quite a few people might download it.  Probably quite soon someone will find the back door, the story would probably be reported on sites like Slashdot, and the game would be up.  However, I could have done a lot of harm in the meantime.
The other approach would be to contribute trojan code to another open source product.  I don't personally think that there is any of SCO's IP in the Linux kernel, but SCO's story isn't completely implausible.  A rogue contributor could submit code that was SCO's copyright -- or contained a back door.  In the case of the Linux kernel, I doubt a back door would work because there seems to be quite a lot of peer review. However, for other projects it might work okay.
These attacks apply in the corporate world as well, but to a lesser extent.  Usually you have a better idea who someone is when you pay them money; this is a deterrent because it is a crime to ship trojan software wilfully.  It also takes effort to infiltrate someone into a company's programming team; contributing code from an anonymous Internet account is much easier.
On the other hand, once a back door is installed in binary-only software, it is much less likely to be found.  The Interbase back door was only found when the source was opened.
I think there are two defences against these attacks.  The first is based on developers' reputations.  If you don't have a strong reputation, people are much less likely to report on your new open source product, and much less likely to download it.  This means that an attack might succeed against a few people, but it would be unlikely to compromise thousands of machines.  (A moderated Freshmeat would be nice here -- you could have a site where a condition of listing your project was that you reviewed a certain number of others.)
The second defence is the amount of work that it takes to produce a project that someone would be interested in.  If I produced a clone of Word, and put a back door in it, no doubt lots of people would download it.  However, the work is not justified by the reward; there are simpler ways of compromising machines.

@_date: 2003-05-04 15:07:46
@_author: Pete Chown 
@_subject: The Pure Crypto Project's Hash Function 
The other option is to use Rijndael for encryption; you can then reuse
the code in a Davies-Meyer hash function.  The nice thing about Rijndael
is that it supports 256-bit blocks, so you get a 256-bit version of
Davies-Meyer.  If you are doing 128-bit encryption, you may well want
256-bit hash functions to avoid problems with the birthday "paradox".
The other option is to use a hash construction like MDC-2 with a smaller
block size, but I believe this is patented.
I wonder if there is an alternative way of verifying something like a SHA-1 implementation.  First of all, you try to make sure that there are no memory problems such as buffer overruns.  You then treat the algorithm as a black box and try a few test vectors.  If it gets the test vectors right, and it looks roughly like SHA-1, it's probably correct.  It would be difficult to come up with an algorithm that is the same as SHA-1 for nearly all inputs, has code which looks identical to SHA-1 on a casual inspection, and can be made to leak something worthwhile if you know about the bug.

@_date: 2003-05-14 10:29:22
@_author: Pete Chown 
@_subject: Payments as an answer to spam 
Purely technical anti-spam solutions are ideal, but solutions that push up the potential penalties for spammers are useful too.  In many jurisdictions, wilfully writing a million bad cheques could mean prison.
On a similar note, I've been wondering whether there could be a protocol which allows an MTA to indicate whether or not it is permissible to send it spam.  If the MTA indicates that it is not permissible, and spam is sent anyway, the sender could commit the unauthorised access offence. This would normally be s.1 of the Computer Misuse Act 1990 in the UK, which carries up to six months imprisonment and a ?5000 fine (per email, technically).  If the spam is illegal, such a "pump and dump" stock scam, the maximum penalty goes up to five years and an unlimited fine.
The use of open relays makes this type of protocol difficult, but one approach might be to add a new type of record to the DNS.  This would be called POLICY and would be inserted at the same level as the MX records.   It would carry a string parameter, which would be a URL.  The URL would point to a file which would describe in machine readable form the types of email which are acceptable at the corresponding host.  The sender then indicates acceptance of the policy by adding a "Policy:" header to the email, whose parameter is a hash of the file found at the policy URL.
The recipient will receive two types of mail, some of which confirm acceptance of the policy, and some of which do not.  This fact can be used in any way he chooses.  He could reject messages which do not accept the policy, or he could lower a spam score for those which do.
