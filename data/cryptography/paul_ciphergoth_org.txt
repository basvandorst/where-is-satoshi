
@_date: 2002-04-20 19:02:55
@_author: Paul Crowley 
@_subject: objectivity and factoring analysis 
Silverman is AFAICT the most knowledgeable person to have commented on
all this.  He has no axe to grind, unless you count the inexcusably
unfair treatment he received from RSA. All of his sci.crypt comments are available with this search:
His off-the-cuff estimate of a good new recommended key size was 2048 bits.
It would be good to hear more from other integer factorisation experts.

@_date: 2002-08-02 01:13:05
@_author: Paul Crowley 
@_subject: building a true RNG 
This seems to define a block cipher with no key, which is collision
free but not one-way.  Am I misunderstanding what you're proposing?

@_date: 2002-08-02 12:51:34
@_author: Paul Crowley 
@_subject: building a true RNG 
It's not hard to understand why it isn't easy to solve this problem
using symmetric primitives.  Any solution must come with a proof that
for any image, there is a preimage.  With symmetric primitives, that
proof usually constitutes a recipe for generating the preimage given
the image.
In this case, I don't see a proof that this proposal can generate any
output.  I tried to construct one myself but fell over on the padding
issue.  I suspect that if you were to solve that you would also have
shown that it was not preimage resistant.
If you allow a keyed hash function then it's much easier to specify
the properties it must have to be useful for entropy distillation, but
of course that gives you a chicken-and-egg problem.  Maybe you can do
something with some sort of idea of "computable distributions" to
overcome the specification problem David Wagner outlines?

@_date: 2002-08-02 13:07:47
@_author: Paul Crowley 
@_subject: building a true RNG 
I meant to say, another example of a believed one-way function that is
guaranteed to be able to produce any output is one based on the
difficulty of discrete log:
f:(x) = g^x mod p
is bijective if the domain and range is 1..p-1, but finding preimages
is the discrete log problem.  Of course this doesn't compress.  I
don't know of any examples which compress and have collision resistance.

@_date: 2002-08-06 16:55:29
@_author: Paul Crowley 
@_subject: An authentication question 
Although see previous discussion on this list for Bernstein's (IIRC)
probablistic fast reject of false RSA signatures.  Note that signatures
have to be of a special form for this to work.

@_date: 2002-08-11 11:38:06
@_author: Paul Crowley 
@_subject: Thanks, Lucky, for helping to kill gnutella 
Do the Gnutella people share your feelings on this matter?  I'd be

@_date: 2002-08-12 10:56:50
@_author: Paul Crowley 
@_subject: Extracting uniform randomness from noisy source 
OK, here's an attempt at a formal definition of how secure a keyed
hash function is for entropy collection.  Here's the game.  Our attacker selects an algorithm MUNGE which takes
an unbounded stream of random bits as input and generates random
strings as output.  We then select a key K and reveal it to the
attacker.  We take a secret unbounded stream, feed it to MUNGE, and
hash the output, using the key K.  The attacker then makes as many
guesses about the output as they want until they get it exactly right.
The hash function is (H,t,p)-secure for entropy collection if for any
choice of attacker such that the entropy of the output of MUNGE is H
or greater and the total work of the attacker (including MUNGE) is
bounded by t, then the probability of a correct guess is p.
I suspect you can do without the key in an asymptotic model, but I'm
not so sure in the concrete model.

@_date: 2002-08-20 21:56:16
@_author: Paul Crowley 
@_subject: CCM Mode 
Note that this mode is simply the combination of CTR and CBC-MAC,
though of course it's valuable to have a team of experienced
cryptographers give a precise specification of a good way of composing
them.  Some commentary by Rogaway can be found here:
all of his technical commentary seems indisputable, though of course I
would favour choosing less efficient modes over patent-encumbered

@_date: 2002-08-29 01:50:30
@_author: Paul Crowley 
@_subject: Palladium and malware 
I'm informed that malware authors often go to some lengths to prevent
their software from being disassembled.  Could they use Palladium for
this end?  Are there any ways in which the facilities that Palladium
and TCPA provide could be useful to a malware author who wants to
frustrate legitimate attempts to understand and defeat their software?

@_date: 2002-02-26 19:32:56
@_author: Paul Crowley 
@_subject: Cringely Gives KnowNow Some Unbelievable Free Press... (fwd) 
All PK algorithms have this property; seed a CSPRNG with the
passphrase and use the CSPRNG as the source of randomness in key
generation. The protection against dictionary attacks seems to be that checking
whether a given passphrase is the correct one is slow, because you
have to check it against the public key.  However, the minimum time to
check passphrase validity can be made arbitrarily slow whatever PK
algorithm is used, with techniques such as key stretching.
Your proposal makes a system *more* vulnerable to dictionary attacks,
since the attack can be mounted without the need to seize the secret

@_date: 2002-07-02 21:33:30
@_author: Paul Crowley 
@_subject: Montgomery Multiplication 
I wrote a guide to the explanation in Handbook of Applied Cryptography
which you can find here:

@_date: 2002-07-24 10:10:26
@_author: Paul Crowley 
@_subject: building a true RNG 
I can't believe any compression software could be as fast as just
feeding the signal straight into SHA-1.

@_date: 2002-07-25 15:51:35
@_author: Paul Crowley 
@_subject: building a true RNG (was: Quantum Computing ...) 
There's no point as far as security is concerned, I agree - and
usually people are talking about lossy compression, which can only do
harm.  The argument seems to be that compression followed by hashing
will be faster than hashing alone, but that seems unikely to me.

@_date: 2002-05-14 00:10:05
@_author: Paul Crowley 
@_subject: Disk encryption standards (was: RE: Two ideas for random number g eneration] 
There's some discussion of these issues in the paper presenting my
(broken) block cipher Mercy, which was meant for this application:

@_date: 2008-08-23 14:00:44
@_author: Paul Crowley 
@_subject: 5x speedup for AES using SSE5? 
In the above Dr Dobb's article from a little over a year ago, AMD Senior Fellow Leendert vanDoorn states "the Advanced Encryption Standard (AES) algorithm gets a factor of 5 performance improvement by using the new SSE5 extension".  However, glancing through the SSE5 specification, I can't see at all how such a dramatic speedup might be achieved.  Does anyone know any more, or can anyone see more than I can in the spec?

@_date: 2008-08-26 15:03:05
@_author: Paul Crowley 
@_subject: SRP implementation - choices for N and g 
They can safely be chosen application-wide, so long as they are secure choices as per the "Group parameter agreement" section of the SRP spec.     --
   __
\/ o\ Paul Crowley, paul at ciphergoth.org

@_date: 2008-12-15 20:56:52
@_author: Paul Crowley 
@_subject: CPRNGs are still an issue. 
How would software that attempted to measure the entropy of the incoming seek times behave when an SSD replaced an HDD?  Would the reduction in measured entropy be proportional to the reduction in entropy from the attacker's point of view?

@_date: 2009-01-29 08:58:22
@_author: Paul Crowley 
@_subject: full-disk encryption standards released 
I think the standard itself is here:
Browsing "TCG Storage Security Subsystem Class: Opal", I'm having a hard time seeing where the actual cryptography is specified.  They mention that they use AES but I can't see where they tell us what mode of operation they are using.

@_date: 2010-04-23 10:57:09
@_author: Paul Crowley 
@_subject: [cryptography] What's the state of the art in factorization? 
My preferred signature scheme is the second, DDH-based one in the linked paper, since it produces shorter signatures - are there any proposals which improve on that?
Incidentally, the paper doesn't note this but that second scheme has a non-tight reduction to the discrete log problem in exactly the way that Schnorr does.

@_date: 2013-10-02 14:54:18
@_author: Paul Crowley 
@_subject: [Cryptography] RSA equivalent key length/strength 
If the NSA's attack involves generating some sort of collision between a
curve and something else over a 160-bit space, they wouldn't have to be
worried that someone else would find and attack that "weak curve class"
with less than 2^160 work.

@_date: 2013-09-11 12:23:49
@_author: Paul Crowley 
@_subject: [Cryptography] Squaring Zooko's triangle 
This uses key stretching to increase the work of generating a colliding
identifier from 2^64 to 2^88 steps.

@_date: 2013-09-17 22:01:26
@_author: Paul Crowley 
@_subject: [Cryptography] People should turn on PFS in TLS (was Re: Fwd: 
At a stretch, one can imagine circumstances in which trying multiple seeds
to choose a curve would lead to an attack that we would not easily
replicate. I don't suggest that this is really what happened; I'm just
trying to work out whether it's possible.
Suppose you can easily break an elliptic curve with the right "attack
string".  Attack strings are very expensive to generate, at say 2^80
operations. Moreover, you can't tell what curves they break until they are
generated, but it's cheap to test whether a given string breaks a given
curve. Each string breaks about one curve in 2^80. Thus the NSA generate an
attack string, then generate 2^80 curves looking for one that is broken by
the string they generated.  They can safely publish this curve, knowing
that unless a new attack is developed it will take 2^160 effort for anyone
else to generate an attack string that breaks the curve they have chosen.
