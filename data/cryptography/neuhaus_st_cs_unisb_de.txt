
@_date: 2005-08-12 09:19:08
@_author: Stephan Neuhaus 
@_subject: The summer of PKI love 
The page goes on to say:
"One reason for PKI's slow uptake has been the lack of two kinds of portability. It hasn't been easy to move cryptographic keys from one machine to another, or to use credentials issued by one institution at another. But as we learned at the summit, there's been progress on both If I remember correctly, portability is not necessarily a thing to strive for here, because it means that not only your certificates will be transported from A to B, but also the corresponding private information will have a tendency to leak all over the place.
Also, cross-certification (mentioned later in the article) is probably hard to do right because it is an extension of trust that needs to be carefully managed, if it can be done at all.
So, the optimism of the article's author aside, where *do* we stand on PKI deployment?

@_date: 2005-08-30 16:22:43
@_author: Stephan Neuhaus 
@_subject: Another entry in the internet security hall of shame.... 
If I have understood the draft correctly, using PSKs means that the server and the client have a shared secret that they must communicate securely beforehand, and that they use some form of ZKP to assure the other party that they know that secret without revealing it.
If that's indeed so, wouldn't this have key management and storage issues that PK was designed to prevent in the first place?  Also, the prior secure exchange of secrets would seem to preclude communication between entities that don't know each other.  That, however, is how many businesses (including ebay, in whose name much phishing spam is generated) operate.  Additionally, I don't think that this is just a UI issue; after all, both the client and the server must somehow manage the PSKs.  There are probably expiration and revocation problems: what if my computer gets stolen and I can't get at my PSK? Does this mean that I can't do business with my bank anymore? What if I suspect that someone has stolen my PSK (for example with the same javascript attack that phished my password)? And so on and so on.
I'm not saying that the idea is bad, far from it; I'm just saying that there are probably many practical problems to be solved before this can be widely deployed.
Or perhaps I haven't understood the draft correctly.
...and the PSK management code in the server and in the client.

@_date: 2005-06-20 13:40:20
@_author: Stephan Neuhaus 
@_subject: AES cache timing attack 
I think so.
True, but what we have here is not some oddball CPU, but the fact that a natural AES implementation on one of the most popular CPUs in existence today has this problem.  It's a problem because the algorithm (and by extension, any natural implementation of it) isn't supposed to be vulnerable to a timing attack.
I don't know.  That cache accesses are faster than memory accesses is not exactly new.
I agree totally that we shouldn't insist on constant-time implementations across all possible architectures.  This way madness lies.  But the fact that it is apparently difficult to produce a fast constant-time implementation on the P4 is definitely a warning sign, especially when resistance to timing attacks was an explicit design How can we get fast constant-time implementations? (Or even just an implementation that is resistant to timing attacks, which isn't necessarily the same thing?)  I don't know.  But what you can't do is solicit a cipher that is supposed to be free of timing attacks and then, when one is found, say, "well, don't do that then" :-)
Again, I don't know.  That cache accesses are faster than memory accesses is very much inside the limits of "Newtonian physics-level assumptions". If the standardizers had had a testable, implementable phrasing of their design requirements, this embarrassing mistake could have been avoided.  Granted, I don't see at the moment how you could phrase this so that the word "cache" does not already appear somewhere, but I feel that this should have been possible.  It's just good engineering practice.
IIRC, the timing resistance was accepted on a theoretical argument (that table accesses take constant time); nobody actually tried it out before accepting it.  If they had, they would have seen that the implementation was not constant-time.  I think this is bad and I still think that the fault lies with the standardization process.

@_date: 2005-10-13 08:32:35
@_author: Stephan Neuhaus 
@_subject: US Banks: Training the next generation of phishing victims 
For an example of how you can do it well and still have a well-designed user interface, consider SaarLB (  The homepage is unencrypted.  In the lower right-hand corner there is a box "Online-Banking" that even has a demo account so that you can try online banking before getting an account with them (I consider this a great idea).  That leads to an encrypted page containing the login text boxes.
The banking pages have an online glossary where you can enter words that you don't understand, such as "Zertifikat", "Schl?ssel" (key) etc. and get them explained to you.
The login page also has this hint:
"Derzeit sind betr?gerische Mails im Umlauf! Folgen Sie nicht dem Link. Geben Sie dort keine Daten ein. Bitte beachten Sie unsere Sicherheitshinweise und wenden sich im Zweifelsfall pers?nlich an Ihren (Translation: "We know of fraudulent emails being sent!  Do not follow the link.  Don't enter any data.  Please follow our security notices; when in doubt, contact your customer consultant personally.")
The security notice has well-written sections on how PIN/TAN authentication/authorization works (including how to set a limit on remittances in order to limit any damage), how to configure your browser (including how to turn off java and java script, a recommendation not to let the browser save your password, how to clear the cache, and how, why, and when to enable cookies), how to check the certificate fingerprint(!), how to recognize phishing, why traffic analysis is still possible, even with encryption, etc.  In particular, it contains the following hint:
"Sollte Ihr Browser bei einem Verbindungsaufbau mit dem Online-Banking-Server in einer Warnmeldung darauf hinweisen, dass ein Schl?ssel nicht erfolgreich ?berpr?ft werden konnte, w?hlen Sie unbedingt "Abbrechen", denn ein sicherer Verbindungsaufbau zu dem Rechner unseres Institutes ist in diesem Fall nicht mehr gew?hrleistet. Nehmen Sie in diesem Fall bitte Kontakt mit uns auf."
(Translation: "Should your browser warn you that the key couldn't be certified, always choose "Cancel", because in this case, a secure connection to one of our servers couldn't be established.  In this case, please contact us.")
This has a picture of a security warning with the mouse on "Abbrechen" Once you log out, you get a window containing this message:
Aus Sicherheitsgr?nden empfehlen wir Ihnen, das Browserfenster zum Ende der Nutzung unserer Internetseiten zu schlie?en und nicht f?r den Besuch weiterer Seiten im Internet zu verwenden.
Dieser Hinweis gilt insbesondere dann, wenn Sie das Online-Banking nicht von zu Hause, sondern von einem ?ffentlichen Ort aus nutzen (z.B. Arbeitsplatz, Internet-Caf?)."
(Translation: "Security Notice: For security reasons, we recommend that you close your browser window once you have finished using our internet pages.  Please don't re-use this browser window for further browsing. This hint is applicable especially if you use our online banking not from your home, but from a public place, such as your workplace or an internet cafe.")
All in all, I think this is just about as good as you can do it. Technically, customers are as secure as they can be using https, PIN/TAN, and current browser technology, while still having a reasonably hassle-free UI.  And the bank at least makes an attempt to educate its customers as to best security practices.
PS: Since I'm usually bitching about things, you might legitimately wonder if I had something to do with the bank's web site.  The answer is no, I had nothing to do with it.  I don't even know who did it.  But perhaps I should find out.

@_date: 2005-09-01 09:39:50
@_author: Stephan Neuhaus 
@_subject: Another entry in the internet security hall of shame.... 
Let me rephrase that.  Are we now at a point where we must admit that PKI isn't going to happen for the Web and that we therefore must face the rewriting of an unknown (but presumably large) number of lines of code to accomodate PSKs?  If that's so, I believe that PSKs will have deployment problems as large as PKI's that will prevent their widespread That's because PSKs (as I have understood them) have storage and management issues that CA certificates don't have, four of which are that there will be a lot more PSKs than CA certificates, that you can't preinstall them in browsers, that the issue of how to exchange PSKs securely in the first place is left as an exercise for the reader (good luck!), and that there is a revocation problem.
To resolve any of those issues, code will need to be written, both on the client side and on the server side (except for the secure exchange of PSKs, which is IMHO unresolvable without changes to the business workflow).  The client side code is manageable, because the code will be used by many people so that it may be worthwhile to spend the effort. But the server side?  There are many more server applications than there are different Web browsers, and each one would have to be changed.  At the very least, they'd need an administrative interface to enter and delete PSKs.  That means that supporting PSKs is going to cost the businesses money (both to change their code and to change their workflow), money that they'd rather not spend on something that they probably perceive as the customer's (i.e., not their) problem, namely Some German banks put warnings on their web pages that they'll never ask you for private information such as passwords.  SaarLB ( even urges you to check the certificate fingerprint and provides well-written instructions on how to do that. In return, they'll assume no responsibility if someone phishes your PIN and TANs. They might, out of goodwill, reimburse you.  Then again, they might not.  I believe that SaarLB could win in court.  So where is the incentive for SaarLB to spend the money for PSK support?

@_date: 2005-09-07 16:29:52
@_author: Stephan Neuhaus 
@_subject: Another entry in the internet security hall of shame.... 
I don't know about New Zealand, but in Germany, ATM PINs (and homebanking TAN lists) are sent in special envelopes that you can't see through, even when holding them against a light.  That's exactly the sort of distribution method that would be needed for PSKs to have desirable security properties and to make them feasible, and that's exactly the distribution method that Joe's Used Condoms can't use because it's too expensive.  Also, it would preclude doing business with someone you don't already know.
Also, phishing isn't done on "all those thousands of web sites that have
successfully employed [passwords] for a decade or more"; it's just done on those where there's money to be had.  Where it's done, it very often works.  How is that a "successfuly employed" security model?
I think you're talking about me here, so I think I should clear some things up.  First of all, I don't think that users should learn how to use PKI.  I don't use PKI (much) because I think it's too bloody complicated, and I am certainly an educated user.  I wouldn't dare foist   PKI on uneducated users.  (There is a great parody by Stenkelfeld, a German radio comedy show, about the difficult HBCI procedure then in use at Haspa, the largest German savings bank.  It's in German, but I can get you an MP3 if you want.  And there isn't even that much I in HBCI's PKI.) But I'm no expert on PKI, so I asked a question instead, namely whether PKI wasn't going to make it for the web.  Second, I also didn't say that passwords didn't *work*, I said that they had *storage and management issues* that certificates did not have and that their deployment would be problematic because of that, and I stand by that.
The reason for my opinion has nothing to do with any knee-jerk standard reaction in relation to passwords, except perhaps for the problem of transferring them securely; see above.  (I think the problem is real under many threat models; you may disagree.) Rather, it is my impression that a switch to TLS-PSK would not just be a client-side thing, but that server code would have to be changed also, and that it is this issue which will prevent widespread deployment of TLS-PSK.  This has nothing to do with what users want or can do, and it has nothing to do with the technical feasibility of passwords.
We completely agree.  We have failed to produce practical and secure solutions.  To repeat, I especially agree that PKI is a solution in search of a problem, and that it's not practical for web commerce.
I also agree that password authentication is not inherently poor, and if we could turn the clock back ten years, that's what we should do.  I also agree that passord-based authentication was trivial to implement---ten years ago!  Today it's not going to be anyway near trivial.
If I were a phisher, I'd set up a web site having normal text boxes for username and password.  On it, I'd put a link "why isn't the URL bar blue?" and use some technical mumbo-jumbo about how for technical reasons, the feature needed to be disabled in the browser, but that the passwords were of course secure (there was a posting on this list to the effect that a bank actually did this or something very similar).  Or maybe that this particular browser isn't supported with TLS-PSK (DiBa doesn't support anything but IE, for example, and logins will mysteriously fail if attempted with any other browser).  I bet that'd work, no matter how unspoofable the TLS-PSK password entry were.
OK, I'm willing to concede that I probably don't understand many of the issues, technical or otherwise, and that I don't have a solution to offer myself, so I'll shut my trap (except if directly challenged, or in private email) until someone has made a decent try to get browser makers to support both TLS-PSK and to include unspoofable password entry methods.  Then we'll see how merchants react to this and what the ultimate consequences are.

@_date: 2005-09-26 08:35:12
@_author: Stephan Neuhaus 
@_subject: German CA TrustCenter insolvent 
Original article at It seems that the German TC TrustCenter GmbH (formerly TC TrustCenter AG) is now insolvent.  TrustCenter was accredited to issue "qualified signatures", which is what you need in Germany if you want your digital signature to be as binding as your handwritten one.
It is as yet unclear why TrustCenter ran out of money, but the fact that German banks sold their TrustCenter stocks to BeTrusted (now part of Cybertrust) in 2004 shows that the banks had lost their confidence in PKI.
An interesting question is of course what happens with TrustCenter's private keys.  Are they being auctioned off to the highest bidder?

@_date: 2007-08-31 18:54:09
@_author: Stephan Neuhaus 
@_subject: debunking snake oil 
One good candidate would be Enigma 2000, now available as Enigma 2000 Plus:
Unfortunately, there is little information available, but from what I saw a few years ago, this is a polyalphabetic cipher with a large key.
 From the web site: "Die Kombination aus der Vernam-Codierung (One-Time-Pad) und des von T. Heidel zum Patent angemeldeten Verfahrens macht eine "bis zu beweisbar sichere Dateiverschl?sselung" m?glich."
Or, in English: "The combination of Vernam encoding (One-Time-Pad) and the patent-pending approach by T. Heidel enables "up to provably secure data encryption"."

@_date: 2007-12-19 12:13:23
@_author: Stephan Neuhaus 
@_subject: crypto class design 
On Dec 17, 2007, at 17:38, travis+ml-cryptography at subspacefield.org  The one thing that I think is most important is not to use the "bunch  of functions" approach, but rather an integrated approach that  directly supports the use cases and protects against misuse.
There you have examples of both approaches.

@_date: 2007-07-02 07:58:56
@_author: Stephan Neuhaus 
@_subject: The bank fraud blame game 
That seems exactly to be the problem.  Germany's e-health card would be a prime candidate for technology that could boost the use of such pinpads, but unfortunately the card will contain a smart card.  (The device has a host of other problems too, don't get me started.)

@_date: 2007-06-11 08:51:23
@_author: Stephan Neuhaus 
@_subject: Free Rootkit with Every New Intel Machine 
This is very scary.  I bet that our Minister of the Interior would love it, though, since he has been pushing a scheme for stealth examination of suspects' computers (called "Federal Trojan").  Technology like this would be a large first step towards making this possible.
Apart from all the other things that are wrong with this scheme,
* you can't trust the output of netstat anymore;
* in other words, what you see with netstat may not be the same as what someone else sees with nmap; and
* if the web interface has a vulnerability, you have an unshutdownable vulnerable service running on your machine.

@_date: 2008-04-29 08:16:28
@_author: Stephan Neuhaus 
@_subject: defending against evil in all layers of hardware and software 
Fred Cohen proved in 1984 in his "Computer Viruses, Theory and  Experiments"[1] that "Program P is a virus" is undecidable. I assume  that this result can be applied to hardware in the form that "Chip C  contains malicious gates" is also undecidable. (Caveat: Cohen seems to  make the fundamental assumption that there is no fundamental  distinction between code and data, something that need not necessarily  hold everywhere inside a computer chip.)
[1] See for example

@_date: 2008-08-04 14:43:57
@_author: Stephan Neuhaus 
@_subject: Randomness testing Was: On the "randomness" of DNS 
Or better still, make many tests and see if your p-values are  uniformly distributed in (0,1). [Hint: decide on a p-value for that  last equidistribution test *before* you compute that p-value.]

@_date: 2008-07-01 18:09:38
@_author: Stephan Neuhaus 
@_subject: The wisdom of the ill informed 
Many German savings banks use account numbers as account names (see,  e.g.,   ), as does, for example, the Saarl?ndische Landesbank ( ). Most will not use 4-digit PINs, though.
Do you mean TANs (TransAction Numbers)? TANs are used to authorize  transactions that could affect your account balance.  So stealing the  PIN will let you look at the balance, but will not let you steal money  (through this channel).
(Or maybe you knew all this already and I just missed the irony.)

@_date: 2008-07-04 14:48:27
@_author: Stephan Neuhaus 
@_subject: German banks liable for phishing (really: keylogging) attacks 
This article:   (sorry, German only) describes a judgment made by a German district  court which says that banks are liable for damages due to phishing  attacks.  In the case in question, a customer was the victim of a  keylogger even though he had the latest anti-virus software installed,  and lost 4000 Euro. The court ruled that the bank was liable because  the remittance in question had demonstrably not been made by the  customer and therefore the bank had to take the risk.
Even though phishing and keylogging are not really related, this  ruling is remarkable because courts had almost always ruled in favor  of the banks in the past.  So it could set an important precedence.

@_date: 2008-10-24 15:37:45
@_author: Stephan Neuhaus 
@_subject: combining entropy 
Ah, but for this to hold, you will also have to assume that the N  pools are all independent.  If they are not, you cannot even guarantee  one single bit of "entropy" (whatever that is).  For example, if N =  2, your trusted source is pool 1, and I can read pool 1 and control  pool 2, I set pool 2 = pool 1, and all you get is zeros. And that  surely does not contain X bits of "entropy" for any reasonable  definition of "entropy".

@_date: 2008-10-24 16:36:04
@_author: Stephan Neuhaus 
@_subject: combining entropy 
Slight correction: You will have to assume that one of the trusted  pools is independent from the others.

@_date: 2009-08-31 20:42:34
@_author: Stephan Neuhaus 
@_subject: Source for Skype Trojan released 
Interesting, but is this a novel idea? As far as I can see, the  process intercepts the audio before it reaches Skype and after it has  left Skype. Isn't that the same as calling a keylogger a "PGP Trojan"?

@_date: 2009-10-01 09:48:47
@_author: Stephan Neuhaus 
@_subject: [Barker, Elaine B.] NIST Publication Announcements 
In this case, it's because Alice and Bob are not people, but services  in an SOA, dynamically negotiating a variation of an SLA. If that SLA  specifies, for example, that "patient records must be deleted within  three days of checking the patient out of the hospital", then it will  be somewhat impractical to go to a notary public every time they  delete a patient's record.
I completely agree with your sentiment that "cryptoplumbing" should  not be used when there are other working solutions, but in this case,  I think it will be unavoidable.

@_date: 2009-10-01 17:07:46
@_author: Stephan Neuhaus 
@_subject: [Barker, Elaine B.] NIST Publication Announcements 
Sorry, I should have clarified that. We don't want to verify that Bob  has in fact deleted the patient record, we just want to verify whether  Bob *claims* to have deleted the patient record *within the time span  given*. If Alice later finds out that Bob has lied, she will have this  signed claim, with which she can take him to court.

@_date: 2009-10-22 22:49:08
@_author: Stephan Neuhaus 
@_subject: Possibly questionable security decisions in DNS root management 
"We" trust the DNS already. As far as I can follow the discussion,  that's part of the problem.
PS: If your point is that DNSSEC will not solve the problem, I agree.

@_date: 2009-09-29 09:40:00
@_author: Stephan Neuhaus 
@_subject: [Barker, Elaine B.] NIST Publication Announcements 
In the project in which I am involved we have just this problem, but  we also have the problem that we can't require the participating  parties to use a TTA. I have been attacking this problem from several  angles but have not come to a solution.
The setup is this:
Alice advertises that she wants a job done. One of the constraints is  that she wants it done by tomorrow, 10am.  A number of Bobs apply for  the job.  Alice trusts none of the Bobs and the Bobs do not trust  Alice.  Alice doesn't even know the Bobs beforehand.  Based on some  criterion, Alice chooses a particular Bob.  For business reasons,  Alice can't force Bob to use a particular TTA, and it's also  impossible to stipulate a particular TTA as part of the job  description (the reason is that Alice and the Bobs----great band name  BTW---won't agree to trust any particular TTA and also don't want to  operate their own).
Is there something that could be done that would *not* require a TTA?  (I have almost given up on this, but it doesn't hurt to ask.)

@_date: 2010-07-28 09:27:10
@_author: Stephan Neuhaus 
@_subject: A mighty fortress is our PKI  
If you are in Europe, you might also want to consider joining us in Madrid on (very likely) February 11, 2011 at Stephan, program committee

@_date: 2010-07-30 09:28:52
@_author: Stephan Neuhaus 
@_subject: A slight modification of my comments on PKI. 
Warning:  self-promotion (well, rather: project promotion) ahead.
This is exactly what we are trying to do in an EU project in which I'm involved. The project, called MASTER, is more concerned with regulatory compliance than security, even though security of course plays a large role.
The insight is that complex systems will probably never have N = 0 (in Dan's terms), so we will have to calibrate the controls so that the N becomes commensurate with the risk.  To do this, we have two main tools:
First, there is a methodology that describes in detail how to break down your high-level regulatory goals (which we call control objectives) into actionable pieces. This breakdown tells you exactly what you need to control, and how. It is controlled by risk analysis, so you can say at any point why you made certain decisions, and conversely, if a regulation changes, you know exactly which parts of your processes are affected (assuming the risk analysis doesn't have to be completely redone as part of the regulatory change).
Second, as part of this breakdown process, you define, for each broken-down control objective, indicators.  These are metrics that indicate (1) whether the process part you are currently looking at is  compliant (i.e., has low enough N), and (2) whether this low N is pure luck or the result of well-placed and correctly functioning controls.
One benefit of having indicators at every level of breakdown is that you get metrics that mean something *at this level*. For example, at the lowest level, you might get "number of workstations with outdated virus signatures", while at the top you might get "money spent in the last year on lawsuits asserting a breach of privacy". This forces one to do what Andrew Jaquith calls "contextualisation" in his book, and prevents the approach sadly taken by so many risk analysis papers, namely simply propagating "risk values" from the leaves of a risk tree to the root using some propagation rule, leaving the root with a beautifully computed, but sadly irrelevant, number. Another benefit is that if some indicator is out of some allowed band, the remedy will usually be obvious to a person working with that indicator. In other words, our indicators are actionable.
The question of whether the cure is worse than the disease can't be settled definitively by us.  We have done some evaluation of our approach, and preliminary results seem to indicate that users like it. (This is said with all the grains of salt usually associated with preliminary user studies.) How much it costs to deploy is unknown, since the result of our project will be a prototype rather than an industrial-strength product, but our approach allows you to deploy only parts.

@_date: 2010-03-24 10:07:36
@_author: Stephan Neuhaus 
@_subject: "Against Rekeying" 
... which will have its own subtleties and hence probability of failure.
