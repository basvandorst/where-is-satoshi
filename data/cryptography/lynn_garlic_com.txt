
@_date: 2002-12-11 14:20:43
@_author: Anne & Lynn Wheeler 
@_subject: VeriSign unveils new online identity verification services 
slightly related threads from sci.crypt and a couple other mailing lists.
 Cirtificate Authorities 'CAs',
Anne & Lynn Wheeler      lynn at garlic.com,

@_date: 2002-12-16 18:11:39
@_author: Anne & Lynn Wheeler 
@_subject: Micropayments, redux 
something that is plugged into the ach/atm network
1) those "gift" (stored-value magstripe cards at checkout counters .... operate over the same POS terminal that credit, debit, ach, atm already work over. basically large percentage of infrastructure already supports ... as part of the basic point-of-sale infrastructure ... credit, debit, and stored-value.
nacha has already demonstrated (digitally signed) aads debit transactions working in the network
the issue is generalized routing of x9.59 digitally signed transactions ... whether they are debit, credit, or stored-value ... and issues like POS terminals supporting hardware token (7816 contact or 14443 proximity) interfaces capable of digital signatures.
with that then there would also be generalized support for debit & stored-value in non-face-to-face, non-POS, and internet type environments .... aka signed x9.59 transactions whether they are credit, debit or stored value. credit was relatively straight-forward translation to the internet since it already had relatively similar risk factors accountable for with MOTO transactions.  digitally signed transactions would reduce some amount of the risk .... enabling debit & stored-value to also be used in unsecure, non-face-to-face environments like the internet (also translating existing debit from shared-secret PIN paradigm to a non-shared-secret public key slightly related discussion in sci.crypt ng
and part of related matters with threads in internet-payments
Anne & Lynn Wheeler      lynn at garlic.com,

@_date: 2002-09-17 16:35:08
@_author: Anne & Lynn Wheeler 
@_subject: Interests of online banks and their users [was Re: 
note that EU finread standard attempted to address some of this. an external (secure, finread) token acceptor device with secure display and secure pin entry. The hardware token is used to "sign" the (financial) transaction .... PIN code is entered into the finread device and goes directly to the hardware token (w/o passing thru the PC). Critical pieces of the transactions passes thru the finread device on the way to the (signing hardware token) and is displayed on the secure display ... which then requires the PIN to be entered to confirm the transaction.
There is the issue of 3-factor authentication
* something you have (hardware token)
* something you know (pin)
* something you are (biometrics in addition to &/or in place of PIN)
besides the straight-forward use of signatures to authenticate the source of the transaction ... there is the nominal legal requirement associated with physical signatures ... i.e. did you intend to sign what you signed aka is what you "see" what you signed ... and do you confirm that you actually want the hardware token to sign what you "see".
A lot of digital signature seems to address the technology part of authentication ... and then sometimes (just because the term "signature" is used as part of the description of the technical procedure) that all technical implementations of the process referred to as "digital signature" is legally equivalent to "physical signatures" (even when no aspects of intention have been satisfied).
random past finread & intention posts:
 Welome to the Internet, here's your private key
 AW: Digital signatures as proof
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Words, Books, and Key Usage
 Proxy PKI. Was: IBM alternative to PKI?
 maximize best case, worst case, or average case? (TCPA)
 TCPA not virtualizable during ownership change (Re: Overcoming the potential downside of TCPA)
 2000 = millennium?
 Those who do not learn from history...
 Cryptogram Newsletter is off the  Ancient computer humor - DEC WARS
 Q: Internet banking
 PKI/Digital signature doesn't work
 PKI/Digital signature doesn't work
 PKI/Digital signature doesn't work
 PKI/Digital signature doesn't work
 future of e-commerce
 Net banking, is it safe???
 No Trusted Viewer possible?
 No Trusted Viewer possible?
 Big black helicopters
 Are client certificates really secure?
 Why is UNIX semi-immune to viral  Smart Card vs. Magnetic Strip Market
 Smart Card vs. Magnetic Strip Market
 CM-5 Thinking Machines,  Opinion on smartcard security  Opinion on smartcard security  Security Issues of using Internet  Security Issues of using Internet  Digital signature
 Biometric authentication for intranet websites?
 Two questions on HMACs and hashing
 Do any architectures use instruction count instead of timer
 Two questions on HMACs and hashing
Anne & Lynn Wheeler      lynn at garlic.com,

@_date: 2002-09-17 16:40:53
@_author: Anne & Lynn Wheeler 
@_subject: Cryptogram: Palladium Only for DRM 
couple refs to multics study
 Backdoor in AES ?
 Backdoor in AES ?
Anne & Lynn Wheeler      lynn at garlic.com,

@_date: 2003-04-28 15:22:00
@_author: Anne & Lynn Wheeler 
@_subject: A New Way to Catch a Hacker 
haven't map makers been doing this forever ... little out-of-the-way places on their maps ... that don't actually exist ... and would only show up elsewhere in cases likely involving legal issue.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-12-12 11:29:56
@_author: Anne & Lynn Wheeler 
@_subject: example: secure computing kernel needed 
there have been other discussions about multics and the paper from a year ago about not having a lot of the current vulnerabilities ... some comment that security has to be designed in from the start. misc. past refs to multics study
 Multics_Security
 Thirty Years Later: Lessons from the Multics Security Evaluation
 Thirty Years Later: Lessons from the Multics Security Evaluation
 Thirty Years Later: Lessons from the Multics Security Evaluation
 Backdoor in AES ?
 Backdoor in AES ?
 The next big things that weren't
 Newsgroup cliques?
 unix permissions
 Disk drives as commodities. Was Re: Yamhill
 grey-haired assembler programmers (Ritchie's C)
 A Dark Day
 Ping:  Anne & Lynn Wheeler
 Who said DAT?
 Secure OS Thoughts
 Password / access rights check
 perfomance vs. key size
there is also a number of discussions about the gnosis, keykos, eros lineage ... random refs to gnosis, keykos, &/or eros
 TSS ancient history, was X86 ultimate CISC? designs)
 No more innovation?  Get serious
 7090 vs. 7094 etc.
 Did AT&T offer Unix to Digital Equipment in the 70s?
 Did AT&T offer Unix to Digital Equipment in the 70s?
 TSS/360
 Blade architectures
 Blade architectures
 markup vs wysiwyg (was: Re: learning how to use a computer)
 IBM doing anything for 50th Anniv?
 Hercules and System/390 - do we need it?
 30th b'day
 Multiple layers of virtual address translation
 Segments, capabilities, buffer overrun attacks
 two pi, four phase, 370 clone
 A Dark Day
 Slashdot: O'Reilly On The Importance Of The Mainframe Heritage
 Secure OS Thoughts
 Secure OS Thoughts
 Secure OS Thoughts
 Intel iAPX 432
 Thoughts on Utility Computing?
there is some number of efforts being done taking advantage of itanium-2 hardware features (at least one such project in m'soft).
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-12-14 15:23:47
@_author: Anne & Lynn Wheeler 
@_subject: example: secure computing kernel needed 
>I'm not sure why no one has considered the PC banking problem to be a
 >justification for secure computing.  Specifically, how does a user know
 >their computer has not been tampered with when they wish to use it for
 >banking access.
actually the EU FINREAD (financial reader) standard is quite directed at this area. basically a secure entry/display\token-interface device. part of the issue is not skimming any pin-entry that may be assumed as possible with just about all keyboard-based entry (aka tamper evident device .... supposedly somewhat consumer equivalent of the TSM ... trusted security module and tamper evident guidelines for point-of-sale terminals). In effect, finread is isolating some set of secure components into a tamper evident housing that has something akin to a trusted security module.
the other aspect somewhat shows up in the digital signature area. fundamentally a digital signature may be used for authenticating (and message integrity) ... but not, by itself as to "agreement" in the legal signature sense. the issue is how to create an environment/infrastructure for supporting both straight-forward authentication as well as in theory finread has the ability to securely display the value of a transaction (and possibly other necessary details) and then requires a PIN entry after the display as evidence of
1) something you know authentication
2) being able to infer agreement with the transaction.
pretty much assumed is that finread implies some sort of token acceptor device ... which in turn implies a "something you have" token authentication.
so finread is attempting to both address two-factor authentication (and possibly three if biometric is also supported) as well as establish some environment related for inferring agreement/intention/etc as required per legal signature.
possibly overlooked in the base eu finread work is being able to prove that the transaction actually took place with a real finread device as opposed to some other kind of environment. In the (financial standard) X9A10 working group on the X9.59 financial standard for all electronic retail payments we spent some amount of time on not precluding that the signing environment could also sign the transaction i.e.
1) amount displayed on secure secure display,
2) pin/biometric securely entered (after display occurs)
3) token digitally signs (after pin/biometric entered)
4) finread terminal digital signs
the 2nd & 3rd items (alone) are two (or three) factor authentication. however, in conjunction with the first and fourth items some level of assurance that the person agrees with the transaction.
lots of past finread references:
 3D Secure Vulnerabilities? Photo ID's and Payment Infrastructure
 Authentication white paper
 FINREAD was. Authentication white paper
 FINREAD ... and as an aside
 FINREAD was. Authentication white paper
 Welome to the Internet, here's your private key
 AW: Digital signatures as proof
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Proxy PKI. Was: IBM alternative to PKI?
 Interests of online banks and their users [was Re: Cryptogram:  Palladium Only for DRM]
 The real problem that https has conspicuously failed to fix
 FAQ: e-Signatures and Payments
 Shades of FV's Nathaniel Borenstein: Carnivore's "Magic Lantern"
 Q: Internet banking
 PKI/Digital signature doesn't work
 PKI/Digital signature doesn't work
 PKI/Digital signature doesn't work
 PKI/Digital signature doesn't work
 Net banking, is it safe???
 No Trusted Viewer possible?
 Are client certificates really secure?
 Smart Card vs. Magnetic Strip Market
 Smart Card vs. Magnetic Strip Market
 Opinion on smartcard security  Opinion on smartcard security  Security Issues of using Internet  Security Issues of using Internet  Digital signature
 Convenient and secure eCommerce using POWF
 Help! Good protocol for national ID card?
 Help! Good protocol for national ID card?
 smartcard+fingerprint
 HELP, Vulnerability in Debit PIN Encryption security, possibly
 application of unique signature
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-12-18 20:03:51
@_author: Anne & Lynn Wheeler 
@_subject: Difference between TCPA-Hardware and a smart card (was:  
I've maintained since the mid-90s ... that the idea of multi-app smartcard is from sometimes in the '80s. the tarket was the portable computing environment .... before there was portable input & output technology. One of the reasons for smartcard standards was to have interoperability between input/output support stations .... and the portable computing.
The mid-90s saw some take-off in capability of multi-app smartcards because the technology that could be packaged into a smartcard got greater.
Also by the mid-90s, there was portable input & output technology and PDAs and cellphones were starting to rapidly fill the target market niche for multi-app smartcards (where everybody had their own portable computing input/output capability w/o having to find a station someplace).
One of the other target market niches for the portable computing devices was the offline environment (again left=over from the 80s) .... however, with the pervasive penetration of the Internet into the world market .... followed by all sorts of wireless capability .... any target offline market niche is rapidly going the way of the dinosaurs.  One might claim that continuing momentum for multi-app smartcards is the enormous investment that was made starting by at least the late '80s continuing up through the current time.
So while there was an escalating amount of capability that could be packaged in a smartcard form-factor by the late 90s along with an escalating cost .... apparently requiring escalating feature/function to try and justify the escalating costs .... why would somebody want significant amount of capability in what is effectively a deaf & dumb device (w/o its support stations) .... when you could get enormously better usability by packaging the significant amount of capability in PDA/cellphone form factor.
i tried to take the opposite track with the aads chip strawman .... find a reasonably compelling business case for a hardware token .... and then totally focus on that function.
the compelling business use selected was authentication.  aads attempts to totally focus on KISS authentication as a compelling business reason for a hardware token .... with aggressive discarding everything that doesn't support the authentication compelling business use (if something non-KISS authentication is needed .... get a PDA or cellphone).
misc. aads stuff:
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-12-20 07:37:12
@_author: Anne & Lynn Wheeler 
@_subject: Difference between TCPA-Hardware and a smart card (was: 
nnheim.de>
In sci.crtypt, there has been a thread discussing does OTP (one-time-pad) and how does integrity and authentication play and somewhat subtread about does authentication of a message .... involve checking the integrity of the contents and/or checking the origin of message. A security taxonomy, PAIN:
* privacy (aka thinks like encryption)
* authentication (origin)
* integrity (contents)
* non-repudiation
 Does OTP need authentication?
 Does OTP need authentication?
 Does OTP need authentication?
One of the issues is that privacy, authentication, and integrity are totally different business processes and that the same technology, lets say involving keys might be involved in all three, aka digital signatures (& public/private keys) can be used to simultaneously provide for authentication (of sender) and integrity )of message contents).
Both privacy (encryption) and authentication (say digital signatures) can involve keys that need protecting; privacy because key access needs to be controlled to prevent unauthorized access to data, authentication because unauthorized access to keys could lead to impersonation.
In the authentication case, involving public/private keys .... the business requirement has sometimes led to guidelines that the private key is absolutely protected and things like key escrow is not allowed because it could contributed to impersonation.
In the privacy csse, involving public/private keys  ... the business requirement can lead to guidelines that require mandated escrow of private key(s) because of  business continuity issues.
This can create ambiguity where the same technology can be used for both authentication and privacy, but because the business processes are different, there can be mandated requirement that the same keys are never used for both authentication and privacy ... and it is mandated that authentication keys are never escrowed and that privacy keys are always TCPA chip can also be used to protect private keys used in authentication .... either authentication of the hardware component as its own entity .... say like a router in a large network, or possibly implied authentication of a person that "owns" or possesses the hardware component.
An authentication taxonomy is 3-factor authentication:
* something you have
* something you know
* something you are
A hardware token (possibly in chipcard form factor) can be designed to generate a unique public/private key pair inside the token and that the private key never leaves the chip. Any digital signature that can be verified by the corresponding public key can be used to imply "something you have" authentication (i.e. the digital signature is assumed to have originated from a specific hardware token). A hardware token can also be designed to only operate in specific way when the correct PIN/password has been entered .... in which case the digital signature can imply two-factor authentication, both "something you have" and "something you know".
 From a business process standpoint it would be perfectly consistent to mandate that there is never key escrow for keys involved in authentication business process while at the same time mandating key escrow for keys involved in privacy.
At issue in business continuity are business requirements for things like no single point of failure,  offsite storage of backups, etc. The threat model is 1) data in business files can be one of its most valuable assets, 2) it can't afford to have unauthorized access to the data, 3) it can't afford to loose access to data, 4) encryption is used to help prevent unauthorized access to the data, 5) if the encryption keys are protected by a TCPA chip, are the encryption keys recoverable if the TCPA chip fails?
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-12-20 11:06:44
@_author: Anne & Lynn Wheeler 
@_subject: I don't know PAIN... 
I just tried
+security +pain +privacy +authentication +integrity
on alta vista and it claims to have over 1000 results
quick sample ... some of them involve pain of
security or pain of security risks (not all of them
are referring to the acronym)
on google doing
+security +pain +privacy +authentication +integrity +non-repudation
gets 22 screens of 10 entries each
... although some aren't using PAIN as an acronym

@_date: 2003-12-20 11:11:10
@_author: Anne & Lynn Wheeler 
@_subject: Difference between TCPA-Hardware and a smart card 
whats the joke about bank robbers say that the reason that they rob banks is that is where
the money is. i don't think that people in the IT business are really all that different than
people in other walks of life when it comes
being con'ed.

@_date: 2003-12-20 14:39:47
@_author: Anne & Lynn Wheeler 
@_subject: Difference between TCPA-Hardware and a smart card (was: 
one can claim that the SIM module isn't a smartcard as per the original design point .... it is a mobile phone that happens
to leverage the smartcard manufactoring process.
my assertion is that the original smartcard design point was
as a portable computing infrastructure that didn't have portable input/output technology. a huge investment went into
standards (so that these cards could be carried around and
still interoperate with various input/output stations) and
volume manufactoring faclities.  Just because they are the
same physical components doesn't mean that they are the same
my observation has been that the stored-value smartcards were an economic trade-off .... supposedly because of either
1) extremely high telco fees and/or 2) availability problems
with telco connectivity .... giving everybody smartcards and all merchants "offline" (aka smartcard) point-of-sale terminals  ... was less expensive than an online paradigm.
in the US .... with ubiquitous and inexpensive telco availability ... it was less expensive to go with the
standard online POS terminals and stored-value using
the traditional magstripe interface (aka it was difficult
to justify the increased chip expense based on any possible savings in telco &/or online transaction costs).
my contention in the AADS chip strawman scenario ... that with aggresive focus on compelling business use of hardware
token (regardless of form factor) as an authentication device,
it should be possible to justify the hardware token just
based on fraud mitigation. with reasonable assumption about online
connectivity becoming universal and inexpensive .... it
is difficult to see any business justification for anything
other than fraud mitigation. If the only business justification
is authentication (for fraud mitigation), it isn't necessary
to have multi-function features supported in the hardware token.
If there is no function/feature needed in a hardware token
(other than authentication for an online environment), the
the provisioning for hardware tokens (regardless of form
factor) is significantly simplified ... aka KISS.
The current provisioning convention for magstripe cards
is there because the magstripe carries effectively shared-secrets
for authentication ... which by simple security 101 rules
says that there has to be a unique shared secret per security domain (and every financial institution is their
own security domain).
To some extent the provisioning of financial smartcards just continues to utilize the magstripe model. In addition,
given offline transaction scenario and possible use of the
card for non-authentication purposes, additional provisioning
of the chip is required to load business rules so that
its use is aligned with the financial institution issuing
the card.
The assertion then is that in the scenario where the hardware token is purely an authentication device, most
of the additional provisioning is eliminated (and becomes
There is typically one additional argument used for
institutional delivered hardware tokens (smartcards), even
if there is no provisioning required ... which is that they
tightly control the process so that the chip eventually
delivered to the end-user can be assumed to meet some specified
trust level.
So a person shows up at the doorstep with their own hardware
token and wants to use it as their authentication device
(whether it is a financial institution for electronic financial
transactions, an employer for door badge access, or a gov.
agency) .... the institution will frequently respond something
about "how can they trust the token?"
So what might convince institutions to accept a consumer
presented hardware token for authentication ... as opposed
to mandating that the only hardware token that they will
trust are the ones provided by the institution.

@_date: 2003-12-21 07:41:35
@_author: Anne & Lynn Wheeler 
@_subject: The PAIN mnemonic 
but non-replay would be pretty specific to transactions in flight .... there are probably gobs of additional threats .... if i was looking at data in flight and data at rest ... non-replay wouldn't even apply to all data in flight. non-repudiation could apply to data in flight (whether or not there was a replay attack) as well as data at rest.  one possible issue is that you don't necessarily have to apply non-repudiation ... but it can be a significant security issue. One of the issues of asking that every entity have a unique password and nobody shares passwords could be considered a non-repudiation issue. In the case of insider fraud .... being able to tie every action to specific entity helps in post-even analysis of fraud events.
one could look at one aspect of non-repudiation as the requirement for everybody having a unique pin/password with guidelines never to share pin/passwords ... which could be considered across a broad range of security activities. replay might be considered a more specific kind of  threat to just transactions. Some number of non-repudiation definitions allow for a lot more feature/function than simply don't share your password  .... but a simple conjecture is that whoever originated "pain" might have been thinking of something as that simple.
in any case as mentioned in the previous reply .... doing search engine on
   +security +pain +privacy +authentication +integrity +non-repudiation
on at least google and alta vista turns up several hundred references .... even discounting the medical entries where pain isn't an acronym/mnemonic
i just tried the same on google for
   +security +pain +privacy +authentication +integrity +non-replay
and got zero hits
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-12-21 09:45:54
@_author: Anne & Lynn Wheeler 
@_subject: Non-repudiation (was RE: The PAIN mnemonic) 
I mentioned PAIN as a (in-use) security taxonomy ... not a cryptosystem taxonomy  or network protocol taxonomy ... and there is nothing precluding human factors in a security paradigm (like human factors issues of requiring unique shared-secret for every security domain leading to humans having to fumble around with scores of shared-secrets).
i agreee that non-repudiation has been seriously mis-used especially with regard to crypto systems.  I've even made the assertion that possibly some of it can be contributed to having the word signature occur in both the term "digital signature" and "legal signature" .... even tho the two may have nothing at all to do with each other.
note, however, when I did reference PAIN as (one possible) security taxonomy .... i tended to skip over the term non-repudiation and primarily made references to privacy, authentication, and integrity.
sample of some past posts in various venues on the subject.
 non-repudiation, was Re: crypto flaw in secure mail standards
 non-repudiation, was Re: crypto flaw in secure mail standards
 non-repudiation, was Re: crypto flaw in secure mail standards
 non-repudiation, was Re: crypto flaw in secure mail standards
 non-repudiation, was Re: crypto flaw in secure mail standards
 non-repudiation, was Re: crypto flaw in secure mail standards
 non-repudiation, was Re: crypto flaw in secure mail standards
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Words, Books, and Key Usage
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Legal entities who sign
 Legal entities who sign
 UK: PKI "not working"
 VS: On-line signature standards
 VS: On-line signature standards
 VS: On-line signature standards (slight addenda)
 VS: On-line signature standards
 VS: On-line signature standards
 PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-12-22 21:24:53
@_author: Anne & Lynn Wheeler 
@_subject: Difference between TCPA-Hardware and a smart card (was: 
my analogy ... at least in online scenario has been to wild, wild west before there were traffic conventions, traffic signs, lane markers, traffic lights, standards for vehicles ... misc. traffic rules about operating an unsafe vehicle and driving recklessly, various minimums about traffic regulations, and things like insurance requirements to cover the cost of accidents. infected machines that do distributed DOS  attacks ... might be considered analogous to large overloaded trucks w/o operational breaks (given rise to truck inspection and weighing stations).  many ISPs are already monitoring, accounting and controlling various kinds of activity with respect to amount of traffic, simultaneous log-ins, etc.  If there are sufficient online incidents ... then there could be very easy to declare machines that become infected and are used as part of various unacceptable behavior to have then declared unsafe vehicles and some sort of insurace be required to cover the costs of associated with unsafe and reckless driving on the internet. Direct costs to individuals may go up ... but the unsafe and reckless activities currently going on represent enormous infrastructure costs.  Somewhat analogy to higher insurance premiums for less safe vehicles, government minimums for crash tests, bumper conventions, seat belts, air bags, etc.
part of the issue is that some number of the platforms never had original design point of significant interaction on a totally open and free internet (long ago and far away, vehicles that didn't have bumpers, crash tests, seat belts, air bags, safety glass, etc). Earlier in the original version of this thread ... I made reference to some number of systems from 30 or more years ago ... that were designed to handle such environments .... and had basic security designed in from the start ... were found to be not subject to majority of the things that are happening to lots of the current internet connected platforms.
 example: secure computing kernel misc. past analogies to unsafe and reckless driving on the internet:
 blackhole spam => mail unreliability (Re: A Trial Balloon to Ban Email?)
 blackhole spam => mail unreliability (Re: A Trial Balloon to Ban Email?)
 Internet like city w/o traffic rules, traffic signs, traffic lights and traffic enforcement
 Internet like city w/o traffic rules, traffic signs, traffic lights  and traffic enforcement
 Internet like city w/o traffic rules, traffic signs, traffic lights and traffic enforcement
 Internet like city w/o traffic rules, traffic signs, traffic lights and traffic enforcement
 Internet like city w/o traffic rules, traffic signs, traffic lights   and traffic enforcement
 Secure you PC or get kicked off the net?
 Spam Bomb
 Drivers License required for surfing?
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-12-23 08:03:00
@_author: Anne & Lynn Wheeler 
@_subject: Ousourced Trust (was Re: Difference between TCPA-Hardware 
I don't think that trust checking was so much of the question .... a not uncommon scenario was
1) institution set up an account possibly that included checking with 3rd party trust agencies
2) did various kinds of online transactions where the actual transaction included account-only information
3) got an offer from a certification authority to move into the "modern world"
     a) send the CA a copy of the institutions account database
     b) the ca would convert the information in each account record into a      c) each certificate would be digitally signed by the CA
     d) the CA would returned each digitally signed transformed account record back to the
         institution and only charge a $100/certificate
4) the institution was to convert from modern online transactions to archaic offline transactions based on information in the certificate
5) the certificate would be a x.509 identity certificate that contain all of the account entity's identification information which would flow around attached to every transaction
1) x.509 certificates broadcast all over the world attacked to every transaction were in serious violation of all sorts of privacy issues
2) certificates were fundamentally designed to address a trust issue in offline environments where a modicum of static, stale data was better than 3) offline, certificate oriented static stale processing was a major step backward compared to online, timely, dynamic processing.
4) the traditional outsourced trust has the relying-party contracted with the trust agency so that there is some form of legal obligation, the traditional CA model has no such legal obligation existing between the relying-party and the trust/certifying agency (the contract is frequently between the trust agency and the key owner, not the relying-party).
In the mid to late 90s ... some financial institutions attempted to salvage some of the paradigm (because of the severe privacy and liability issues) by going to relying-party-only, certificates for online transactions. However, it is trivial to show that the static, stale information in the relying-party-only certificate was a trivial subset of the information that would be accessed in the real account record for the online transactions ... and therefor it was trivial to show that static, stale certificates were redundant and superfulous. misc. past posts regarding relying-party-only scenario:
I think that the current federal gov.PKI tries to address the legal obligation issue ... by creating a legal situation where essentially all the authorized CA operators are effectively agents of the federal PKI ... and all the relying parties have contracts with the federal PKI ... which simulates a legal obligation between the issuer of the certificate and the In something like the D&B scenario ... the relying party contracts for some information with D&B about the entity that the relying party is interested in. In many of the traditional 3rd party CA-PKIs, there may be absolutely no legal relationship between the CA issuing the certificate (trust information) and any of the relying parties that are relying on the trust information i.e. the contract is between the CA issuing the certificate ... and the entity that the certificate is about. Since the entity (that the trust information is about) may be the party paying for the trust information ... they may have some motivation to shop around and get the most favorable report. Lets say I was applying for a loan and the loan institution needed a credit report. Rather than the loan institution contracting for the credit report, they rely on one supplied by the loan applicate. The loan applicant is free to choose from all the credit reporting agencies which credit report that they will buy for supplying to the loan institution.
random past threads on trust propagation:
 An attack on paypal
 Keyservers and Spam
 An attack on paypal
 SSL, client certs, and MITM (was  VS: On-line signature standards
 VS: On-line signature standards
 VS: On-line signature standards
 PKI/KRB
 Self-Signed Certificate
 public key vs passwd authentication?
 Is this right?  Question about SSL and PKI
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-12-23 10:48:16
@_author: Anne & Lynn Wheeler 
@_subject: Non-repudiation (was RE: The PAIN mnemonic) 
total aside ... i just did jury duty in criminal case last week
a mammal taxonomy can have
* humans
* horses
* mice
which doesn't mean that all mammal's have hooves, and correspondingly, all security doesn't have to have non-repudiation.
if the authorizations and/or permissions require for somebody to be an employee ... it is possible to authenticate somebody as being an employee w/o having to authenticate who they are ... just sufficient to authenticate them as whether or not they are allowed to do what they are allowed to do.
now, if you have 10,000 people that are authorized to do something ... and you have no tracking about what any specific person does .... then if some fraud takes place .... you may have no grounds whether to suspect any of the 10,000 over any of the others.  However, if you have a policy that employees are strictly not suppose to share passwords and can get fired if they do .... and some fraud process takes placed ... done by an entity entering a specific password .... there would possibly be at least sufficient grounds to at least get a search warrant. The password by itself might not be sufficient to convict beyond a reasonable doubt ... but the audit trail might at least help point the investigation in the correct direction and also be admitted as circumstantial evidence. The defense attorneys in their opening statements said something about the prosecution showing means, motive, opportunity and misc. other things.
in any case, I would claim that both human and non-repudiation issues are part of security.
I wouldn't go so far as to say that just because a certification authority turned on a "non-repudiation" bit in a certificate .... and had no means at all of influencing human behavior, that just because the bit was turned on ... it, in anyway had anything to do with non-repducation.
there is recent thread in pkx mailing list about the name of the non-repudiation bit in a certificate being depreciated. There seems to be two separate issues ... 1) calling the bit "non-repudiation" isn't consistent with the meaning of the bit and 2) the semantics of what the bit supposedly controls.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-12-23 14:43:08
@_author: Anne & Lynn Wheeler 
@_subject: Non-repudiation (was RE: The PAIN mnemonic) 
there is some reference in old posting in pkix thread:
 Meaning of Non-repudation
possibly more than you want to know ... but merged security taxonomy and glossary ... sources at:
has definitions for:
non-repudiation exchange
non-repudiation information
non-repudiation of creation
non-repudiation of delivery
non-repudiation of knowledge
non-repudiation of origin
non-repudiation of receipt
non-repudiation of sending
non-repudiation of submission
non-repudiation of transport
non-repudiation policy
non-repudiation service
non-repudiation token
NRD token
NRO token
NRS token
NRT token
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-12-23 14:52:14
@_author: Anne & Lynn Wheeler 
@_subject: Ousourced Trust (was Re: Difference between TCPA-Hardware  
the one detailed presentation that I've so far seen of a SAML based product .... looked like it had exactly the same message flows description that I sat thru in a Kerberos project audit in the '80s. I asked the guy making the presentation about the similarity to Kerberos message flows and he said something to the effect of ah yes, kerberos.
random kerberos refs:
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-12-23 20:23:07
@_author: Anne & Lynn Wheeler 
@_subject: Ousourced Trust (was Re: Difference between TCPA-Hardware  
in days before the internet .... it was there was a lot more lo-tech attacks on financial transactions ... and when things like the credit card master file got harvested .... it was uaually pretty obviously an insider job. with the advent of the internet ... not only was it a open, insecure, commodity network .... but a lot of the attached systems were never designed to operate in effectively a hostile environment  because of a lot of contributing factors .... there was significant ambiguity when a merchant master file got harvested ... where the attack originated (insider or outsider). minor side thread regarding security proportional to risk with regard to attacks on the merchant master file:
during the past ten years there have been some number of technologies for attempting to compensate for just the transport of the "shared-secret" account number in a transaction on an open, hostile network .... aka primarily ssl, minor reference with regard to emerging ssl and the original payment gateway:
there has been a lot of threads about how much fraud SSL actually prevented .... since the major consumer retail financial related fraud ... both non-internet, pre-internet, and internet has been bulk harvesting of repositories like a merchant master transaction file (for possibly the same effort to evesdrop packets in flight and extract a single account number .... it might be possible to harvest a merchant transaction file with tens of thousands of account numbers.
so the x9a10 working group was given the requirement for preserving the integrity of the financial infrastructure for all electronic retail transactions. To meet that, the x9.59 standard was defined which basically requires end-to-end authenticated transactions between the consumer and the consumer's financial infrastructure and that account numbers used in authenticated transactions can't be used in non-authenticated transactions. With strong, end-to-end authentication, it is possible to evesdrop a x9.59 transaction, extract the account number and still not be able to execute a fraudulent financial transaction. It is also possible to harvest x9.59 account numbers from merchant transaction files and still not be able to execute fraudulent financial transaction.
Hiding account numbers has been associated with identity theft, since in environment where the transactions aren't authenticated .... the account numbers have to be effectively treated as shared-secrets. The downside is that numerous business processes all along the processing chain require access and use of the account number. Just hiding the account number with SSL did little to address the major vulnerabilities and threats.  In effect, the analysis shows that it is effectively impossible to provide necessarily protection for a shared-secret account number, nobody of how deep the earth was blanketed with cryptographic technology. The solution was to change the business process, require end-to-end strong authentication and eliminate the account number as a shared-secret (i.e. knowing the account number is not sufficient for performing a fraudulent transaction). misc. x9.59 standard refs:
There was actually a couple other issues differentiating internet-based transactions and the VPN environment. The VPN environment was circuit based, it is possible to get service level agreements and utilized technology like modem loop-back diagnostics as part of a bootstrap problem determination procedure.  Such an environment has a trouble desk and expects to finish first level problem determination in something like 5 One of the last projects my wife and I had done before taking the early out (and doing some consulting for the payment gateway and ec-commerce stuff) was the HA/CMP product .... i.e. high availability/cluster multi-processing.
There is a slight reference in one of the above aadsm5.htm archive posting to
because some of the people in the above meeting had left and joined a client/server startup and were responsible for this thing called a commerce server .... who we then working with on this thing called a payment server for this thing that would be called e-commerce.
In any case, packet-based internet not only is commodity oriented from standpoint of security but also from the standpoint of availability, diagnostics, etc. It was possible to take an ISO8583 financial messages standards  manual and repackage the same exact messages into internet packet protocol. However, it is extremely difficult to translate the standard VPN RAS (reliability, availability, serviceability) features into an internet environement. At some point in testing the payment gateway, there was a outage and a call to the trouble/call center. Three hours of manual investigation later, the trouble ticket was closed NTF (no trouble found).  Trying to translate VPN-like RAS  to an internet environment was much harder task than just about everything else combined (even just inventing problem diagnostic process for the call center).
In any case, there was an extremely large number of issues translating from a VPN environment to an internet environment .... way beyond simple issues like transaction evesdropping.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-12-25 08:43:41
@_author: Anne & Lynn Wheeler 
@_subject: Ousourced Trust (was Re: Difference between TCPA-Hardware 
disclaimer: I never actually worked on either X.500 or X.509 standards ...  however, I do remember an acm sigmod meeting circa  '90 where somebody did characterize x.500 as a bunch of networking engineers trying to re-invent 1960s database technology. minor past refs:
 Why did OSI fail compared with  Why did OSI fail compared with  Invisible Ink, E-signatures slow to broadly catch on (addenda)
 OCSP and LDAP
also, (not knowing about original intent of x.509) ... the PKI infrastructures I saw in the early to mid 90s ... had x.509 identity certificates that appeared to be populated with stale, static (and possibly subset) of information from a database entry .... targeted for use by relying parties in lieu of the relying parties actually being able to contact the real database (contained some piece of a x.500 directory entry that a relying-party could presumably use if they didn't have direct access to the x.500 directory).
the relying-party-only certificates of mid ot late 90s appeared to be much more of something that would authenticated an entity to a operational service .... having thrown out nearly all of the information that might be found in a database (especially anything that might possibly represent a privacy and/or liability issue) . However,  relying-party-only certificates could still be shown to be redundant and superfluous ... aka if i'm sending a digitally signed transaction containing an account number (or other database indexing value) to a relying party having the database .... then appending any kind of certificate that contains a small subset of the complete information from the database entry (including any public key or authentication material) is redundant and superfluous.
the IETF OCSP standards work seems to be all about a real-time protocol that a relying party can use to check with a (LDAP?) database about whether the information that might be in a specific certificate can still be relied on. It has some of the flavor of a distributed filesystem/database cache entry invalidation protocol  All of the CRL and OCSP stuff isn't about using the certificate for authenticating to an x.500 directory .... but whether the stale, static copy of information in the certificate is still good.
one of the PKI related efforts from the mid-90s specified adding a digital signature and a relying-party-only certificate to a iso8583 oriented financial transaction. It turns out that the typical iso8583 financial transaction eventually gets packaged as something like 60-80 bytes .... while the typically implemented relying-party-only certificate for this effort was between 4k bytes and 12k bytes. In this case, not only was the relying-party-only certificate redundant and superfluous but also represented a two orders of magnitude payload bloat.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-12-27 08:13:23
@_author: Anne & Lynn Wheeler 
@_subject: Ousourced Trust (was Re: Difference between TCPA-Hardware 
in general, distributed cache/filesystem cache consistency algorithms aren't about trust or trust propogation but integrity and consistency.
I had done the initial distributed lock manager for ha/cmp. misc. past posts:
 Disk drive behavior
 KI-10 vs. IBM at Rutgers
 Block oriented I/O over IP
 OT - Internet Explorer V6.0
 OT - Internet Explorer V6.0
 Blade architectures
 Blade architectures
 Avoiding JCL Space Abends
 A few Z990 Gee-Wiz stats
issue with certficates as cache entries ... is that they are purely r/o, static entries ... and the cache consistency protocols (either CRLs or OCSP) is purely with respect to whether the information is still fresh or not. however, I still contend that the primary design point for these deployed certificates is to allow relying-parties to perform offline operations when they wouldn't nominally have access to the real data (from which the certificate is derived).
the issue with the CRLs is that the are an electronic version of the paper booklets of invalid numbers in the credit card industry before online transactions. the issue is that the switch to a real online paradigm in the credit card industry in the '70s pretty much obsoleted the need for offline credentials (they retained the same form factor but added the magstripe for online transactions) and any infrastructure support for offline paradigm (like CRLs). OCSP appears to acquire all the infrastructure costs of doing online transaction while retaining all the disadvantages of CRL paradigm ... i.e. undergo the costs of doing an actual online transaction w/o having any of the advantages of actually having done an online transaction. a trivial example is there is none of the benefits of aggregation (credit limit, fraud use patterns, etc) that comes with having a real online the market niche for certificates are still the offline world (which is rapidly disappearing) or for extremely low value operations that don't justify the expense of online transaction. This issue in the later is two-fold 1) online transaction related costs continue to rapidly decline and 2) for low/no value operations it is difficult to justify the cost and complexity of PKI infrastructure.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-12-28 14:24:55
@_author: Anne & Lynn Wheeler 
@_subject: Non-repudiation (was RE: The PAIN mnemonic) 
so another way of looking at it ... is that somebody repudiates, refutes, and/or disavovs ... typically after the fact.
non-repudiation would be those things that would support countering claims of repudiation, refuting, and/or disavowing.
authentication is typically demonstrating that an entity is allowed to do something. authentication can include having a passphrase that is known by everybody in the organization. knowing the passphrase is sufficient to authenticate that somebody is allowed to do something. however, if somebody refutes that they had done something .... showing that they knew the passphrase (known by everybody in the organization) isn't sufficient to counter the repudiation claim.
an infrastructure that requires a unique passphrase for every person would help counter repudiation claims
public/private asymmetric cryptography systems where the infrastructure requires that a single person only has access to a particular private key would help counter repudiation claims. In that sense .... public/private key system can be seen as addressing both privacy and non-repudiation issues.  the policies governing the determination of private key in a asymmetric cryptography infrastructure can influence whether it just pertains to just privacy and authentication and/or whether it can also be used to counter repudiation claims.
while making sure that one & only one person has knowledge of a specific private key, in no way impacts the asymmetric cryptography operations ...  the process can be used to countering repudiation claims.
while repudiation tends to be a human act .... it is entirely possible to have infrastructure and organizational implementation features that support countering claims of repudiation when they occur.
say dozens of people know (the same) vault combination lock (authentication)  .... which doesn't do anything to counter a particular person's claim that they didn't enter the vault,
however video surveillance and door badge access logs could be considered as part of security taxonomy for countering repudiation claims.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-12-29 12:40:28
@_author: Anne & Lynn Wheeler 
@_subject: Ousourced Trust (was Re: Difference between TCPA-Hardware   
talking to the guy after the presentation, i got the impression that
they probably exactly copied the kerberos flows ... didn't even try to
come up with something that turned out to be similar.
there were 30-40 people in the audience and I expected more people in
the audience to have participated in discussion about kerberos vis-a-vis
kerberos had come out of project athena that had been substantially
jointly funded by two corporations ... project athena had a director
from mit and two assistant directors, one from each of the funding
corporations. one of them i had worked with for a long time when at
science center at 545 tech sq. (random refs):
during the period we were doing hsdt & ha/cmp ... my wife and I also got
to go by and do audits of progress of various project athena activities
(including kerberos). One visit we had a lengthy overview and discussion of the recently
(then) developed cross-domain protocol.

@_date: 2003-01-16 07:55:52
@_author: Anne & Lynn Wheeler 
@_subject: Question regarding group management of documents 
I was at a presentation last week of a company that is doing something like this .... including cross-domain authentication. it looked very much like kerberos architecture but using packets with SAML formated data (as tickets).
they listed several financial institutions as well as some gov. operations
random saml related references ....
 IBM alternative to PKI?
 Proposal: A replacement for 3D  NEWS: 3D-Secure and Passport
 NEWS: 3D-Secure and Passport
 Time to ID Identity-Theft Solutions
 Simple PKI
 SAML Just The Start For Web Services Security
 Invisible Ink, E-signatures slow to broadly catch on (addenda)
 Sun releases Liberty-enabled software
Anne & Lynn Wheeler      lynn at garlic.com,

@_date: 2003-07-08 11:40:29
@_author: Anne & Lynn Wheeler 
@_subject: basic question: semantics of "map", "tie", etc in PKI 
basic authentication taxonomy is something like:
1) something you have (like a hardware token)
2) something you know (like a pin/password)
3) something you are (like biometrics)
frequently PKIs talk about certifying (aka CA's are certification authorities, certificates represent some certification by a certification authority) some binding between something and a public key.
one could claim that the choice of vocabulary was trying to elevate something from straight-forward authentication to something like identification and non-repudiation ... which would represent much more value and therefor the public key owner buying the certificate might pay more. Note, however, identification and non-repudiation is primarily of benefit to the relying-party that receives the certificate .... but the standard TTP business model has the private key owner paying for the certificate (not the relying party .... which is receiving the primary There has been lots of discussion that PKIs don't actually do identification or non-repudiation which requires lots of additional processes.
Certification authorities basically have an entity prove that it can generate a digital signature that can be validated with the supplied public key ..... basically a form of "something you have" authentication ... the entity can prove it has the private key. The certification authority then validates some other piece of information (like the entity's email address); stores the public key and the certified information in a database and then creates a credential/certificate as to the binding between the certified information and the certified public key.
Originally, x.509 specification was thought of as heavily overloading a certificate with lots of identity related information as well as privilege/permission related information ... "bound" to a public key in a certificate. It pretty quickly became apparent that a credential/certificate heavily overloaded with identity and permission information and indiscriminately broadcast all over the world created enormous privacy problems.
  Financial institutions in the mid-90s dropped back to relying-party-only certificates which basically contain only account number and the public key because of the enormous privacy and liability problems. However, a standard business process involving certificate has the key-owner  1) creating a transaction/message,  2) appending a digital signature, 3) appending the certificate ... and transmit the "triple" to the bank.
The bank extracts the account number from the transaction/message, reads the account record and validates the digital signature using the public key stored in the account record. The relying-party-only certificate containing only an account number and public key (because of the enormous liability and privacy issues) is never used. It was subsequently observed that such relying-party-only certificates were redundant and superfluous.
The original purpose of certificates were to provide various certified associations for an offline world (something analogous to letters-of-credit from the days of sailing ships). These certificates were a stand-in/substitute for situations where it was not possible to directly access the real information. Most of them are quickly loosing any reason for existence given the extensive proliferation of internet and wireless technologies around the world. It is becoming more and more unlikely that there wouldn't be some form of connectivity .... especially for transactions or authentication events involving anything of value or The semantics of private key is basically "something you have" .... however given the vagaries of software computing systems, the private key can be stored in a hardware token or in a software encrypted file on a general purpose computer. The software encrypted file is unlocked with a PIN/password ... given some of the characteristics of general purpose computers (like personal computers), any kind of file might be considered publicly copy'able by anybody in the world. As a result, such an encrypted file .... might actually be considered "something you know" authentication (as opposed to something that you "uniquely" have). A hardware token that generates the key in the chip and never allows the private key to leave the chip .... might be considered more representative of "something you have" A hardware token that requires a PIN/password to operate can be considered two-factor authentication ("something you have" and "something you know"). Note that in this situation, the business processes of the token and digital signature technology creates an environment that can be used to establish "something you have" (aka the hardware token). The digital signature technology is not an end in itself ... just a method of proving that you posses a specific hardware token (and possibly have knowledge of a specific PIN/password).
As previously noted .... sometimes there is PKI documentation that attempts to grossly exaggerate the meaning of a digital signature and obfuscate the underlying business processes and procedures ....  possibly as part of a sales technique to convince public key owners to purchase the certificates (obfuscation that attempts to establish certificates as an end in themselves).
misc. past about relying-party-only certificates
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-07-10 07:03:13
@_author: Anne & Lynn Wheeler 
@_subject: replay & integrity  
we did two kinds of replay countermeasures ... one for AADS RADIUS
and a different kinds for x9.59 (for all electronic payments in all in the aads radius there is this (real-time) protocol chatter; client contacts server, server returns message with unique value, client includes unique value in signed message that is returned to server. server validates the signature and makes sure the client's message returns the previously transmitted unique value.
for x9.59 to work in all environments ... it had to operate in single round trip (as per many of existing financial messages). the client creates a complete signed message and sends it to the server (financial institution), the message has some possibly unique values ... but not necessarily guaranteed, including time. the server uses current time and message time to bracket checking of previously processed messages for replay.
the radius implementation requires two round-trips to establish the unique value as part of replay counter measure.
the x9.59 implementation (in order to meet one of the requirements for the protocol; perform completely in single round trip) uses a log and a sort of fuzzy time implementation (at the server).  this is in part because the client end can be considered somewhat unreliable ... not necessarily being able to reliably remember previous value and/or keep synchronized time. highly synchronized time could eliminate the log check. having reliable client that was guaranteed to remember previous transaction could get by with the log elimination by using a take off on the single password scheme .... where both the server and the client reliably remembers just the previously used value, this rmemory doesn't get out of sync ... and the iteration to the next value is non-obvious.
and of course the overall requirement given the x9a10 working group for x9.59 was to preserve the integrity of the financial infrastructure for all electronic payments in all environments.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-03 14:46:27
@_author: Anne & Lynn Wheeler 
@_subject: Maybe It's Snake Oil All the Way Down 
> That's a red herring.  It happens to use X.509 as its preferred bit-bagging
 > format for public keys, but that's about it.  People use self-signed certs,
 > certs from unknown CAs [0], etc etc, and you don't need certs at all if you
 > don't need them, I've just done an RFC draft that uses
 > shared secret keys for mutual authentication of client and server, with no
 > need for certificates of any kind, so the use of
 > certs, and in particular a hierarchical PKI, is merely an optional extra.
 > It's no more required in SSL than it is in SSHv2.
the pk-init draft for kerberos allows public keys .... allowing both
cert & cert-less implementation
the scenario allows for public key registration in lieu of shared secret
registration. the scenario is that r/o access, divulging, sniffing, etc
doesn't result in compromise.
in the token form ....
the key-pair is gen'ed in the chip and never leaves the chip.
as part of 3-factor authentication
* something you have
* something you know
* something you are
the chip in the token purely provides "something you have"
authentication ... and the digital signature done by the token is purely
to prove  that you have that particular token. It doesn't prove who you
are, it just proves that you have a specific (extremely difficult to
counterfeit) token as part of "something you have" authentication.
if the token is augmented with a pin/password for its correct operation,
then there can be 2-factor authentication. It doesn't involved
shared-secrets since the pin/password is purely between the person and
the hardware token.
The business process validates that the token is of the type requiring
PIN and/or biometric for
correct operation.
The ecdsa digital signature authentication protocol for kerberos,
radius, x9.59 for all retail financial transactions, or ssh can be
identical regardless of the integrity level.
The ecdsa digital signature authentication protocol can be ubiquitous
regardless of the authentication integrity level required.
The business process to meet integrity requirements then can require
sofware key-pair or hardware token key-pair, the level of integrity of
the hardware token, and/or the operational characteristics of the
hardware token (no-pin, pin, biometrics, etc) w/o changing the protocol.
If the protocol is independent of the business process integrity issue
then either the business and/or the end-user may be able to having
personal choice about the level of integrity required. Furthermore, the
person might even have personal choice whether they need a unique token
per security environment, a single token for all security environment,
and/or a small number of tokens selectively applied to different
security environments
the digital signature has nothing at all to do directly with the person,
it is purely related to demonstrating the possession of the token (as
part of something you have authentication) and possibly the integrity
level of the token.
The issue of the authentication protocol  is getting the bits and bytes for
transmission correct but doesn't normally say what it means ... i.e. secret,
shared-secret, one factor authentication, two-factor authentication,
something you have authentication, something you know authentication,
etc. ... although frequently the protocol is envisioned to be a specific
implementation of a specific kind of authentication and trust/integrity level.
recent token discussions
 Two-factor authentication with SSH?
 Two-factor authentication with SSH?
 electronic-ID and key-generation
 electronic-ID and key-generation
older token discussions
 biometrics
 Welome to the Internet, here's your private key
 Meaning of Non-repudiation
 Interests of online banks and their users [was Re: Cryptogram:  Palladium Only for DRM]
 when a fraud is a sale, Re: Rubber hose attack
 eBay Customers Targetted by Credit Card Scam
 Cryptogram Newsletter is off the  PKI and Non-repudiation  distributed authentication
 FREE X.509 Certificates
 Are client certificates really  I-net banking security
 Opinion on smartcard security  Opinion  on smartcard security  Crypting with Fingerprints ?
 Biometric authentication for intranet websites?
 privileged IDs and non-privileged IDs
 Help! Good protocol for national ID card?
 Certificate Authority: Industry vs. Government
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-03 17:29:44
@_author: Anne & Lynn Wheeler 
@_subject: Maybe It's Snake Oil All the Way Down 
The issue is where does the authentication material come from.
Basically, certificates were solution targeted for offline email from
the early '80s. you dail-up, connect, exchange email, hang-up. then
you read. some random person that you never, ever dealt with before
sends you something. they claim to be somebody .... the certificate
is signed by somebody you trust .... is offered as proof that they are
who they claimed to be.
the other approach in the online world &/or with previous relations,
is have a table of authentication material. the payment (debit/credit) card
world went from non-electronic, offline to electronic and online (and
skipped the step altogether that certificates represent ... the electornic
and offline).
note that even the certificate-based infrastructure are dependent on
this method .... basically the certificate-enabled infrastructures have
local table of "CA" public keys (i.e. those public keys that they've previously
decided to trust) ... then certificates are validated with "CA" public keys
and the current message/document is validate with public key from
certificate. The primary difference between cert-based infrastructure and
certless-based infrastructure is that the cert-based infrastructure there
CAs have the database of all public keys and create these small R/O
copies of their database records called certificates and spray them all
over for use in offline environments. Then relying parties just have
abbreviated CA-only public key tables and can't access the full tables
maintained at the CAs.
In the certless-based infrastructure the relying parties either maintain
their own full tables of all public keys and/or have direct online access to
the full tables. There is no need for these little R/O, static, stale,
redundant and superfluous copies of somebody else offline database entry certificates) since there can be direct, online access to the original copy.
generalized case can be hooking the web server to either radius or
kerberos for handling the authentication process. both radius and
kerberos support shared-secrets recorded in database as authentication.
the radius example at
shows example of radius recording public key in lieu of shared-secret
and performing ecdsa digital signature authentication. pkinit for
kerberos also allows for public key recorded in lieu of shared-secret
and digital signature authentication.
misc. radius public key authentication posts
misc. kerberos public key authentication pots
futher discussion specifically regarding static, stale, redundant,
superfluous certificates.
slightly related discussions regarding SSL merchant comfort
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-03 20:49:48
@_author: Anne & Lynn Wheeler 
@_subject: Maybe It's Snake Oil All the Way Down 
some generic reasons for hooking radius (or one of the AAA technologies) into your webserver for authentication are:
1) supports a variety of authentication mechanisms on an account by account basis. day one, none of the users actually need to see any difference (single administrative interface supporting all the client authentication options that might be in use). existing userid/password, challenge/response and in the referenced asuretee url, ecdsa digital signature.
2) single administrative interface for both client authentication options as well as all of their authorization and privilege options.
3) client database is accessable in real-time by the webserver, real-time updates can occur to both authentication information as well as  authorization, permission and privilege information using single consistent administrative operation
4) there is no disconnect between client administration and static, stale, redundant and superfluous certificates that are a subset of a r/o administrative database entry. (RADIUS) Updates can take place in real time and immediately reflected. The certificate story (as mentioned previously, created for offline, disconnected environment) basically would do something like a) invalidate the old certificate, b) issue new CRLs, c) possibly update a OCSP LDAP, d) update the master database permissions entry for that client, e) generate a certificate that represents a subset of the master information, f) distribute it to the client and f) then have the client install the new certificate. This of course becomes unnecessary if the certificate doesn't actually contain any information and the webserver accesses the authorization and permissions from an online database. However, as has repeatedly been pointed out before, if the certificate doesn't contain any information and the webserver is accessing an online database for authorizations and permissions ... then the webserver can access the online database for the authentication material also. The certificate then is static, stale, redundant and superfluous and you are back to a single online, real-time comprehensive administrative facility (like radius) that supports client/account specifics for authentication, authorization, permissions, accounting, privileges, etc.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-04 10:12:04
@_author: Anne & Lynn Wheeler 
@_subject: Maybe It's Snake Oil All the Way Down 
the ground rules given the x9a10 working group for the x9.59 standard was to preserve the integrity of the financial infrastructure for all (credit, debit, stored-value, POS, internet, non-internet, aka ALL) electronic retail payments. it was one of the things that led us down the path of certless operation. We had previously done the work on the original payment gateway and had to perform various kinds of due diligence on all the major CA vendors .... which started to dawn on us that stale, static certificates were actually redundant and superfluous in the financial business process.
sort of the clinker was starting to do operational and performance profile on any of the existing payment networks .... and it was evident that there was a huge mismatch between the existing payment transaction payload size and any of the commonly used certificates (even the drastically simplified replying-party-only certificates carrying only an account number and public Two major characteristics of X9.59 was that it would provide 1) end-to-end authentication (aka the consumers financial institution would be the one responsible for performing authentication) and 2) account numbers used in X9.59 transactions could not be used in unauthenticated transactions.
Some of the '90s digitally signature oriented specifications had authentication occurring at the internet boundary and stripping off the certificate (avoiding the extreme certificate payload penalty in the payment network). The downside was that the party performing the authentication didn't necessarily have the consumer's interest in mind and Visa subsequently presented statistics at a ISO standards meeting on the number of transactions flowing through the network 1) with a flag claiming to have been digitally signature authenticated and 2) they could prove that no digital signature technology was ever involved.
Evesdropping, sniffing or harvesting account numbers in the current infrastructure (at any point in the process, by insiders or outsiders, traditionally financial exploits have been 90 percent insiders) can result in fraudulent transactions. As a result, existing account numbers effectively become a form of shared-secret and need to be protected. With the X9.59 business rule requiring the account number to only be used in authenticated transactions, simple harvesting of a X9.59 account number doesn't result in fraud. Issuing financial institutions then can use existing business processes that support mapping of different account numbers to the same account.  A discussion of the security proportional to risk with regard to credit card transactions:
 Net banking, is it safe?
The issue with the use of SSL for protecting credit card transactions isn't addressing all or even the major vulnerability to the infrastructure. Eliminating the account number as a form of shared secret addresses all of the vulnerabilities, not just the transaction-in-flight vulnerability addressed by SSL. As a byproduct of addressing all of the shared-secret related vulnerabilities, it also eliminates the need to use SSL for protecting the shared secret while being transmitted.
Detailed report of its use in the NACHA debit network trials can be found at
scroll down to "July 23, 2001: Digital Signatures Can Secure ATM Card Payments"
More details of X9.59 standard:
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-04 20:58:47
@_author: Anne & Lynn Wheeler 
@_subject: Maybe It's Snake Oil All the Way Down 
one could claim that public-key is a practical alternative but it got significantly sidetracked with independent business model that wanted extract huge amount of money out of existing infrastructures (say totally brand new independent operations wanting $100/annum for every person, extracted from the existing infrastructure for no significant positive benefit ... aka say 200m people at  is $20b/annum ... in return for some abstract bit vapor that doesn't change any core business issue).
it is relatively trivial to demonstrate that public keys can be registered in every business process that currently registers shared-secrets (pins, passwords, radius, kerberos, etc, etc).  the issue then becomes one of cost to change/upgrade those infrastructures to support digital signature authentication with the stored public keys in lieu of string comparison (no new business operations, no new significant transfer of wealth to brand new outside business entities, etc).
however, think about even these simple economics for a minute .... even for relatively modest technology changes that don't change any of the business processes/relationships ... it still costs some money ... and the beneficiary isn't the institution, it is the individual. The individual has the paradigm changed from hundreds of shared-secrets to a single key-pair ... however each institution continues to see just as many individuals and account records. From a very practical standpoint ... entities don't frequently fund things that they don't benefit from ... and typically most success is achieved when the entity that benefits from the change is also driving/funding the change.
the issue is to find out how the individual pays for the change .... or figure out how the institutions are going to benefit.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-06 13:34:41
@_author: Anne & Lynn Wheeler 
@_subject: Maybe It's Snake Oil All the Way Down 
there are actually two scenarios .... one is to pre-cache it (so that its transmission never actually has to happen) and the other is to compress it to zero bytes. detailed discussion of certificate pre-caching and certificate zero byte compression:
the typical use for HTTPS for e-commerce is to hide the account number on its way to the financial institution. for the most part the merchant is primarily interested in the response from the consumer's financial institution on whether or not the merchant gets paid. If it weren't for the associated business processes, the merchant could get by with never knowing anything at all about the consumer (the merchant just passes the account number on ... and gets back what they are really interested in .... the notification from the bank that they will get paid).
So a HTTPS type solution is that the consumer pre-caches their bank's certificate (when they establish a bank account). .... and they transmit the account number "hidden" using the bank's public key. This happens to pass thru the merchants processing .... but for purposes of the authorization, the merchant never really has to see it. The protocol would require minor issues of replay attacks .... and be able to be done in a single round trip .... w/o all the SSL protocol chatter. Actually, is isn't so much pre-caching their bank's certificate .... as loading their bank's public key into a table .... analogous to the way CA public keys are loading into tables (aka using out-of-band processing .... the convention that they may be self-signed and encoded in a certificate format is an anomoly of available software and in no way implies a PKI). The primary purpose of HTTPS hasn't been to have a secure channel with the merchant, the primary purpose of the HTTPS is to try and hide the consumer's account number as it makes its way to the consumer's financial institution.
The other solution is the X9.59 standard (preserve the integrity of the financial infrastructure for all electronic retail payments, not just internet, not just POS, not just credit, ALL; credit, debit, stored value, etc) that creates authenticated transactions and account numbers that can only be used in authenticated transaction. The consumer's public key is registered in their bank account (out of band process, again no PKI). X9.59 transactions are signed and transmitted. Since the account number can only be used in authenticated transactions .... it changes from needing encryption to hide the value as part of a shared-secret paradigm to purely a paradigm that supports integrity and authentication. As in the above, scenario, the merchant passes the value thru on its way to the consumer's financial institution; and is focused on getting the approved/disapproved answer back about whether they will be paid. As in the bank HTTPS scenario where the bank's pubilc key is pre-cached at the consumer, the pre-caching of the consumer's public key is pre-cached at the bank .... involves no PKI business processes (although their may be some similarities that the transport of the public key involves encoding in a certificate defined format).  misc. x9.59 refs:
Both pre-caching solutions are between the business entities that are directly involved; the consumer and the consumer's financial institution based on having an established business relationship.
The invention of PKI was primarily to address the issue of an event between two parties that had no prior business relationship and possibly weren't going to have any future business relationship and that they would conclude their business relying on some mutual trust in the integrity of a 3rd party w/o actually having to resort to an online environment. The e-commerce scenario is that there is real-time, online transaction with the trusted 3rd party (the consumer's financial institution) involving prior business relationship. This negates the basic original assumptions about the environment that PKIs are targeted at addressing.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-06 17:45:35
@_author: Anne & Lynn Wheeler 
@_subject: Maybe It's Snake Oil All the Way Down 
??? public key registered in place of shared-secret?
NACHA debit trials using digitally signed transactions did it with both software keys as well as hardware tokens.
in the above scroll down to July 23, 2001 ... has pointer to detailed report?
X9.59 straight forward establishes it as standard .... with some activity moving on to ISO
pk-init draft for kerberos specifies that public key can be registered in place of shared secret.
following has demo of it with radius with public keys registered in place of shared-secret.
the radius implementation has been done be a number of people.
in all of these cases, there is change in the business process and/or business relationship .... doesn't introduce totally unrelated parties to the business activities. the is digital signing on the senders side (actually a subset of existing PKI technology) and digital signature verification on the receivers side (again a subset of existing PKI technology). To the extent that there is impact on existing business process ... it is like in the case of introducing x9.59 authentication for credit transactions that have relatively little authentication currently .... and as a result would eliminate major portion of the existing credit card transaction related fraud.
The big issue isn't the availability of the technology ... although there is a slight nit in the asuretee case being FIPS186-2, ecdsa .... and having support in CAPI and related infrastructures. It not working (easily) is like when my wife and I were doing the original payment gateway .... with this little client/server startup in menlo park (later moved to mountain view and have since been bought by AOL) and people saying that SSL didn't exist ... misc ref from the past
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-08 18:12:34
@_author: Anne & Lynn Wheeler 
@_subject: An attack on paypal 
in a world where there are repeated human mistakes/failures .... at some point it is recognized that people aren't perfect and the design is changed to accommodate peoples foibles. in some respects that is what helmets, seat belts, and air bags have been about.
in the past systems have designed long, complicated passwords that are hard to remember and must be changed every month. that almost worked when i person had to deal with a single shared-secret. when it became a fact of life that a person might have tens of such different interfaces it became impossible. It wasn't the fault of any specific institution, it was a failure of humans being able to deal with large numbers of extremely complex, frequently changing passwords. Because of known human foibles, it might be a good idea to start shifting from an infrastructure with large numbers of shared-secrets to a non-shared-secret paradigm.
at a recent cybersecurity conference, somebody made the statement that (of the current outsider, internet exploits, approximately 1/3rd are buffer overflows, 1/3rd are network traffic containing virus that infects a machine because of automatic scripting, and 1/3 are social engineering (convince somebody to divulge information). As far as I know, evesdropping on network traffic  doesn't even show as a blip on the radar screen.
In the following thread on a financial  authentication white paper:
 Authentication white paper
 FINREAD was. Authentication white paper
 FINREAD ... and as an aside
 FINREAD was. Authentication white paper
there is point made that X9.59 standard doesn't directly address the Privacy aspect of security (i.e. no encryption or hiding of data). However, the point is made that it changes the paradigm so that the financial account number no longer represents a shared-secret and that it can be supported with two-factor authentication  i.e. "something you have" token and "something you know" PIN. The "something you know" PIN is used to enable the token, but is not a shared secret. Furthermore, strong authentication can be justification for eliminating the need for name or other identification information in the transaction.
However, if X9.59 strong authentication is used with two-factor authentication and no identification information is necessary .... then it would make people more suspicious if privacy information was requested. Also, since privacy information is no longer sufficient for performing a fraudulent transaction, it might mitigate that kind of social engineering The types of social engineering attacks then become convincing people to insert their hardware token and do really questionable things or mailing somebody their existing hardware token along with the valid pin (possibly as part of an exchange for replacement). The cost/benefit ratio does start to change since there is now much more work on the crooks part for the same or less gain. One could also claim that such activities are just part of child-proofing the environment (even for adults). On the other hand, it could be taken as analogous to designing systems to handle observed failure modes (even when the failures are human and not hardware or software). Misc. identify theft and credit card fraud reference:
 Identity Theft Losses Expect to hit $2 trillion
Slightly related in recent thread that brought up buffer overflow exploits
 A Dark Day
and the report that multics hasn't ever had a buffer overflow exploit
 Thirty Years Later: Lessons from the Multics Security Evaluation
 Thirty Years Later: Lessons from the Multics Security Evaluation
somebody (else) commented (in the thread) that anybody that currently (still) writes code resulting in buffer overflow exploit maybe should be thrown in jail.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-08 20:00:40
@_author: Anne & Lynn Wheeler 
@_subject: An attack on paypal 
that is why we coined the term merchant "comfort" certificates some time ago. my wife and I having done early work for payment gateway with small client/server startup in menlo park ... that had this thing called SSL/HTTPS ... and then having to perform due diligence on the major issuers of certificates .... we recognized 1) vulnerabilities in the certificate process and 2) information hiding of transaction in flight only addressed a very small portion of the vulnerabilities and exploits.
lots of past discussions related to our use of merchant comfort certificates from the past:
we concluded that a real issue is that way too much of the infrastructure is based on shared-secrets and there was no realistic way of providing blanket protection to all the exposures and vulnerabilities of such shared-secret infrastructures. somewhat related discussion in the security proportional to risk posting:
so rather than trying to create a very thick blanket of encryption covering the whole planet .... a synergistic approach was attempting to provide alternatives to as much of the shared-secret paradigm as possible. As in the referenced post:
 authentication white paper
strong encryption of identification and privacy (and shared-secret) information is good ... but not having identification, privacy and shared-secret information is even better.
there are all sorts of ways of obtaining shared-secret information (and/or privacy and identification information prelude to identity theft) .... including various kinds of social engineering.
as previously mentioned requirement for X9.59 standard was to preserve the integrity of the financial infrastructure for ALL electronic retail payments. As per previous notes, X9.59 with strong authentication eliminates the account number as a shared-secret as well as eliminating requirements for name, address, zip-code, etc as part of any credit card authentication process (strong encryption of vulnerable information is good, not having the information at all is even better).
ALL in addition to referring to things like credit cards, debit cards, atm transactions, stored-value transaction, over the internet, at point-of-sale, face-to-face, automated machines, etc .... also refers to ACH transactions. ACH information allows for unauthenticated push or pull transactions. Social engineering requesting bank account information so somebody can push tens of millions into your account also allows for them to generate a pull transaction removing all the money from your account. Part of the above posting on the authentication white paper .... makes references to securing ACH transactions:
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-10 09:19:19
@_author: Anne & Lynn Wheeler 
@_subject: virus attack on banks (was attack on paypal) 
virus attempting to harvest ("shared-secret", single-factor) passwords at financial institutions
and somewhat related:
 authentication white paper
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-10 21:33:37
@_author: Anne & Lynn Wheeler 
@_subject: The real problem that https has conspicuously failed to fix 
slight nit .... the solution is non-shared secret in conjunction with something you have authentication implementing, digital signatures, public/private keys where the private key is never divulged .... even to the owner (the private key housing can be hardware token ... or something embedded in the computer).
it seems that certificates sometimes are considered synonymous with public/private key and digital signatures. however, certificates were originated to address a specific issue with key distribution and trust involving parties that 1) had no prior business relation, 2) were unlikely to have any future business relationship, and 3) didn't have online access to trusted 3rd party. however, it is actually much more natural in a standard business process setting that public key is registered in lieu of shared-secret authentication material when parties are involved that have established business relationship (aka for example a person with some sort of an account, especially in any sort of online paradigm). A trivial examples is certificateless operation with public/private keys for radius, kerbers pk-init or x9.59 standard for all retail payment transactions (internet, non-internet, point-of-sale, debit, credit, ach, stored-value, Also note, a certificate tends to only contain the owners public key and some other information about the owner (and nominally is assumed to be freely distributable, somewhat in  the same way the PGP keyserver information is published). The certificate doesn't contain the private key ... which tends to be either in a software encrypted file or an external hardware token.
for the various possible types of social engineering & virus exploits, eliminating shared secrets is only a partial solution (although shared secrets have a number of vulnerabilities and exploits, so eliminating shared secrets is not a bad thing)., if the individual has direct access to the private key in anyway, then it is possible to compromise that access.  That is where some flavor of "something you have" authentication comes in with hardware that houses the private key and there is no way to divulge the private key, even to the owner.  EU finread (financial reader) has an external reader with its own display and pin-pad. This addresses the issue (even with something you have hardware token) where a viirus can 1) display one value on the screen and send another value to the token for signing and 2) spoof keystroke entry with the correct PIN (perform fraudulent transactions w/o the owners knowledge).
If the
1) private key can never be directly physically accessed,
2) the digital signature is taken to represent a form of something you have 3) the display can be trusted to always display what will be signed
4) the keypad can't be spoofed and actually requires the person to hit the keys
5) hardware token never signs anything unless there has been (human) keypad then the remaining types of fraud will tend to be no different than the phone scams, mail scams and the people coming to your door scams .... effectively no different than the types of fraud that has been going on for hundreds/thousands of years.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-11 12:42:50
@_author: Anne & Lynn Wheeler 
@_subject: An attack on paypal 
actually, if you had a properly secured DNS .... then you could trust DNS to distribute public keys bound to a domain name in the same way they distribute ip-addresses bound to a domain name.
the certificates serve two purposes: 1) is the server that we think we are talking to really the server we are talking to and 2) key-exchange for establishing an encrypted channel. a properly secured DNS would allow information distributed by DNS to be trusted .... including a server's public key .... and given the public key .... it would be possible to do the rest of the SSL operation (w/o requiring certificates) which is establishing an agreed upon session secret key.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-11 13:00:31
@_author: Anne & Lynn Wheeler 
@_subject: Keyservers and Spam 
i've been told of the things that form the basis of contract/obligation is providing something in return for consideration. the certificate is sold to key owner, to the extent there is some obligation it is tetween the certificate issuer and the owner of the key.
there tends to not be any relationship between the relying party and the certification authority. i believe the federal gov. got around this by having GSA(?) be the certification authority .... with the certificate manufactures/issuers performing as agents of GSA .... and all the possible relying parties had some sort of contract with GSA.
That of course is a little awkward in the case of domain name server certificates .... having all the consumer relying parties in the world sign contracts with the major certificate vendors .... so it would establish some sort of obligation for relying on a certificate.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-11 15:38:18
@_author: Anne & Lynn Wheeler 
@_subject: An attack on paypal 
we actually included that in suggestion as part of original stuff for setting up electronic commerce and providing comfort to consumers. however it didn't take the form of a certificate .... which is left over from ancient offline world (aka certificates are akin to the little BBB certificates that you get to put in your window ... a comfort issue but doesn't actually address any real cases). even before e-commerce, the real BBB process was that people called up the BBB and got realtime information .... i.e. it was an online, realtime process.
the equiivalent for an online, internet paradigm (as opposed to something left over from the offline email genre of at least 10--15 years earlier) was that the browswer tab;e pf trusted entities were of online authorities (as opposed to certificate manufacturing) and if you cared, you clicked thru to the BBB and got realtime information about the merchant in question (being equivalent to when people call the BBB to actually get some level of real input .... as opposed to just a fuzzy comfort fealing).
lots of past posts about merchant comfort certificates and ancient efforts to suggest requiring a BBB operation for internet merchants:
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-11 17:23:52
@_author: Anne & Lynn Wheeler 
@_subject: An attack on paypal (trivia addenda) 
somewhat related to the early posting in this m.l. about distributed computing systems conference and possible interest from security and cryptography sections.
when my wife and I were doing ha/cmp
we were working with two people in the following meeting in ellison's conference room
who the following year, left and joined a small client/server startup and were responsible for something called the commerce server (the company also had this thing called https/SSL). we then worked with these two people on the implementation for payments for the thing called the commerce server and well as the infrastructure regarding
trusting online merchants (as part of promoting this whole thing that came to be called electronic commerce):
and more recent posting in the same thread that I had also posted about buffer overflows and the multics study:
 A Dark Day
in any case, one of the jokes has been there are actually only 200 people in the industry.
in any case, back to the recent related thread on distributed system operation:
 A few Z990 Gee-Wiz stats
 A few Z990 Gee-Wiz stats
 A few Z990 Gee-Wiz stats
 A few Z990 Gee-Wiz stats
and past posts discussing the BBB aspects for online electronic commerce:
 "SSL & SET Query" ... from usenet group
 U.S. & Ireland use digital  Public Key Infrastructure: An  Public Key Infrastructure: An  SSL certs & baby steps
 TTPs & AADS (part II)
 OCSP and LDAP
 FTC says incidence of ID theft jumped in 2002
 SET; was Re: Why trust root CAs ?
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-11 19:37:32
@_author: Anne & Lynn Wheeler 
@_subject: An attack on paypal  
"real" authentication is actually that hard; it is "identification" that tends to really get sticky. one of the reasons for simplified security taxonomy like PAIN or PAIIN ... aka
3-factor authentication is
something you have (like a token)
something you know (like password)
something you are (like biometrics)
In the past, I've posted regarding proposals for implementing authentication techniques in association with various internet operation registries .... in part because they are currently relying primarily on identification which is easily spoofed.
the previous posts highlight the domain name take-over exploits .... using the same techniques used in the referenced article for ip-address take-over.
the issue for SSL domain name certificates .... and people concerned about the integrity of the domain name infrastructure .... is that the certification authorities aren't the authoritative reference for the information that they are certifying .... it is the domain name infrastructure (and similarly the ip-address registry). The domain name take-overs have been very similar to the described techniques in the article for ip-address take-over. Somewhat the CA industry proposal is for the registries to implement public key registration at the same time the domain name (or ip-address) is registered.  The public key is registered in the registry account record .... and all future interaction is done via authenticated signed transactions (authenticated using the public key in the registry account record).
The claim regarding the operation of the internet operational registries is that they are effectively non-authenticated .... in much the same way that current credit card transactions are not authenticated. The x9.59 standard is for all electronic retail payments and are authenticated using a public key registered in the account record. This is effectively the some proposal (somewhat instigated by the certification authority industry) for transitioning the internet registries from non-authenticated transactions to authenticated transactions (by using digitally signed messages that are authenticated with public key registered in the corresponding registry account record).
as in previous observations .... having a domain name owner register their public key in the internet registry (domain name infrastructure or ip-address registery) starts to lesson the requirement for having SSL domain certificates.
random past posts regarding irony/catch22 for the CAs and SSL domain name  How effective is open source crypto?
 How effective is open source crypto? (bad form)
 Why trust root CAs ?
 Web of Trust
 CA Certificate Built Into Browser Confuse Me
 SSL MITM Attacks
 SSL integrity guarantees in abscense of client certificates
 Root certificate definition
 SSL certificate modification
 SSL certificate modification
 SRP authentication for web app
 Are ssl certificates all equally  Cirtificate Authorities 'CAs', how curruptable are they to
 SSL & Man In the Middle Attack
 SSL & Man In the Middle Attack
 SSL questions
 Authentification vs Encryption in a system to system interface
 New RFC 3514 addresses malicious network traffic
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-12 08:35:03
@_author: Anne & Lynn Wheeler 
@_subject: The real problem that https has conspicuously failed to fix 
or slightly more accurately doing authentication for accounts. the other is frequently confusing  identification with authentication. the internet registries (both domain and ip-address) haven't been doing authentication ... but just some simple identification. there are situations where identification may quite orthogonal to whether or not you are the owner of the account in question. also, identification also tends to open up the whole can of worms around protecting privacy. as periodically stated (in reference to x9.59) thick blanket of encryption protecting privacy information is good, the information not being there at all is even better.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-12 11:14:33
@_author: Anne & Lynn Wheeler 
@_subject: certificates & the alternative view 
the other view ... is using a little information theory .... is that certificates are stale, static, read-only copy of information in the certificate authority's account record .... targeted for offline environments where the relying party has no access to the real authoritative agency responsible for the information.
one of the things from the '90s, in the transition from offline to the start of a pretty much ubiquitous online world was trying to come up with things to put into certificates to justify their price. One of the attempts was extreme overloading of the certificate with large amounts of identity and privacy information, and furthermore you convince the public that they should pay for the privilege of having huge amounts of their privacy information sprayed all over the world.
The fallback is to attempt to reduce as much as possible any information of actual value in a certificate and to not go around confusing identification with authentication. This was sort of the relying-party-only certificates from the financial community in the later part of the 90s .... don't put any information of any value what-so-ever in a certificate; just create these huge,  very large  bit patterns that were one hundred times larger than a typical payment transaction and require that these extremely large bit patterns had to be attached to every  payment transactions sent back to the financial institution (which already had the original copy of all the information). From this is was possible to demonstrate a PKI infrastructure where every certificate was compressed to zero bytes. The horrible payload penalty and information/privacy leakage problem was ultimately addressed with zero byte certificates.  They contained zero byte, stale, static, read-only copy of the information in the certificate authority's account Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-12 11:26:57
@_author: Anne & Lynn Wheeler 
@_subject: An attack on paypal 
we sort of tried that ... however the financial justification sort of fell apart. the big thing about BBB is being able to trust some merchant that you have absolutely no knowledge about. However, the actual buying patterns are extremely skewed ... with well over 80 percent of the transactions either repeat or with some organization that there is other avenues of trust propagation .... and involving a very small number of very large merchants.  The BBB model tends to work with higher value, infrequent transaction. The remaining online, merchant market segment not covered via other trust processes, tended to represent a small percentage of total transactions, spread over a very large population of very small merchants, and frequently low value.
eBay is an attempt to provide an alternative delivery for such market segment .... and the issue is how does eBay operations break even financially on a BBB like offering. The first filter is to quickly catch major scamming  operations ... and differentiate between the one-off Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-12 13:10:55
@_author: Anne & Lynn Wheeler 
@_subject: PKI not working 
picked up from a ietf pkix mailing list posting:
 Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-13 16:50:20
@_author: Anne & Lynn Wheeler 
@_subject: Keyservers and Spam 
PGP .... or other similar account-based mechanisms provide trust between parties that have established relationship .... on a purely pair-wise, bilaterial basis.  It does allow some direct trust operations to diffuse out to other parties. It isn't so much a close-knit community .... it is how far every specific entities's trust operation diffuse out across other If the entity is called a certification authority .... and it provides an online service ... then the diffusing of specific trust operation might propogate out to a wide community. The issue of course is what trust attributes are propagating/diffusing and the diligence that the entity used in establishing the information to be trusted.
If the entity is called a certification authority, and it manufactures certificates (basically stale, static copies of some CA internal account record) then those certificates will presumably contains some information that is bound to the public key ... where there is some degree of confidence (aka trust) with regard to the binding between the information and the public key.
One issue is what meaning is there between having absolute certainty between something like an email address and a public key. Let's say it is an email address. Typically, email addresses at random are meaningless to me unless they are part of some specific context .... like somebody I have an established relationship with. However, if I have an established relationship with the entity, then it is back to the PGP scenario.  In a broad context, businesses run on established relationships; aka financial institutions.  The whole existing payment infrastructure effectively has the PGP scenario without needing certificates, and not exactly being considered a very close-knit community.
The primary difference between a financial institution actiing as an entity in a PGP web-of-trust paradigm (say payment cards, credit, debit, etc) and individual .... is the typical scope of the reputation of the financial institution is larger than an individual, and therefor the propagation/diffusing of trust is likely to have a much further reach. To a larger degree ... the trust radius of an entity is somewhat independent of whether it is operating in the PGP manner w/o certificates or in certificate paradigm.
The primary difference in the certificate paradigm is not the scope of the entity's trust .... it is the design point of delivering the trust. The certificate paradigm of trust delivery was targeted at an offline environment for relying parties that had no previous relationship (and had no online and/or direct recourse to the trust entity.
The payment card industry established a certificateless nearly world-wide scope of trust, in part by providing an extensive online network.
The certificate-based design point was to be able to provide an infrastructure for propogating trust between relying parties that had no previous relationship, were unlikely to need future relationship, and had no online or direct recourse to the trust enttity.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-19 08:56:50
@_author: Anne & Lynn Wheeler 
@_subject: An attack on paypal 
typically certificates have had two characteristics .... 1) asn.1 encoding for network interoperability distribution and 2) trusted third party binding of some information to the public key
self-signed certificate caching is really loading public key into a locally maintained table.
in principal there is no need to maintain asn.1 encoding format in a locally maintained table since it eliminates having to decode it on every use .... and the asn.1 encoding is only useful if you 1) are planning on redistributing somebody else's public key and 2) need the original bit format for validating the self-signed signature. The validating of the self-signed signature can be done on initially acquiring the certificate .... and then it can be decoded, and the decoded values loaded into the table. the table/database just becomes entries of public keys and the associated attributes (which might be a combination of the original plus any additional that you might want to add along the way).
in that sense it becomes more of authentication management .... along the lines of kerberos, radius, and/or the AAA RFCs, aka authentication,  authorization, and accounting.
in previous posts about BBB, it is possible that it would be used in combination with online trusted references .... i.e. analogous to real-time call to BBB and obtaining referrels and any complaint information ... and then possibly remembering it by recording it in the table (aka online trust propogation as opposed to the offline trust propogation represented by TTP Part of the issue with the offline TTP stale, static certificate model was that it periodically tried to overload the contents of the certificate .... trying to justify the expense of the ceritifcate to the public key owner .... but having little or no idea what might be the future requirements  of a broad range of relying parties. A locally maintained relying-party table/database would allow the relying party to dynamically adapt the trust characteristics that they were interested in.
Decoding the self-signed certificate before loading into the local table .... helps highlight that the recorded trust characteristics don't have to be restricted to just those that happen to exist in the stale, static certificate (created at some time in the past by entities that had no anticipation regarding your specific trust requirements).
past discussions of online & offline trust propogation:
 TTPs & AADS (part II)
 OCSP and LDAP
 An attack on paypal (trivia addenda)
 An attack on paypal
 U.S. & Ireland use digital  Public Key Infrastructure: An  Public Key Infrastructure: An  Public Key Infrastructure: An  Public Key Infrastructure: An  Public Key Infrastructure: An  revised Shocking Truth about Digital Signatures
 Public Key Infrastructure: An Artifact...
 SSL certs & baby steps
 FTC says incidence of ID theft jumped in 2002
 "SSL & SET Query" ... from usenet group
 SET; was Re: Why trust root CAs ?
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-03-12 11:50:06
@_author: Anne & Lynn Wheeler 
@_subject: Encryption of data in smart cards 
a lot of cards use derived (symmetric) keys ... similar to the derived key per transaction X9 standards. they are used to protect data from outside examination and in multi-function cards to provide protection domains between the different applications on a card.
typically there is a system wide key that you would find in a secure terminal (like transit systems) that read data, decrypt it, update it, re-encrypt it and write it back to the card. this handles situations involving attacks with fraudulent readers that load fraudulent value on the card.  given the possibility of a brute force attack on the infrastructure (aka getting the data out of one card, and finding the master system key) ... many systems go to some form of derived keys. They typically amount to one-way function that combines the system-wide key with something like an account number from the card that results in the derived key. A brute force attack on the card data .... will only result in obtaining the card-specific, derived key .... and not the system-wide master key. All secured readers, knowing the system wide key and some card identification can always calculate the  derived key for a card.
misc. derived key stuff ...
 cardtech/securetech & CA PKI
 pk-init draft (not yet a RFC)
 Opinion  on smartcard security  Biometric Encryption: the solution for network intruders?
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-03-13 08:22:47
@_author: Anne & Lynn Wheeler 
@_subject: Encryption of data in smart cards 
there are a large number of different kinds of cards .... however the most prevalent smartcards (in terms of numbers deployed) are the institutional smartcards that tend to include stored-value  of various kinds that are supported at various kinds of merchant &/or transient terminals (i.e. subway turnstyles). the transient tend to be proximity/contactless (aka  iso14443) rather than contact (aka iso7816).
these infrastructures use secret keys .... especially derived secret keys ... that are designed to protect the infrastructure from various kinds of attacks by others (including the people that posses the card) ... typically fraudulent value substitution on the card.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-03-13 14:08:04
@_author: Anne & Lynn Wheeler 
@_subject: Encryption of data in smart cards 
note however, that PIN could be possibly in infrastructure with real secret key and encryption done with derived key. the derived key one-way function is attempting to protect the infrastructure-wide secret key from brute force key search on specific piece of data. The issue is how many bits in a PIN is required to protect the secret key in a one-way function (involving the secret key and the PIN). A simple derived key is sufficient using the secret key and public account number. Adding a (privately known, card specific) PIN to such a derived key function:
1) doesn't increase the ease of attack on the secret key
2) doesn't affect brute force attack on the derived key
3) makes it harder to use a lost/stolen card
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-03-15 16:15:22
@_author: Anne & Lynn Wheeler 
@_subject: How effective is open source crypto? 
having worked on some of the early e-commerce/certificate stuff ... recent ref:
 Certificate Policies (addenda)
the assertion is that basic ssl domain name certificate is so that the browser can check the domain name from the url typed in against the domain name from the presented (trusted) certificate ... and have some confidence that the browser is really talking to the server that it thinks it is talking to (based on some trust in the issuing certification authority). in that context ... self-certification is somewhat superfluous ... if you trust the site to be who they claim to be ... then you shouldn't even have to bother to check. that eliminates having to have a certificate at all ... just transmit a public key
so slight step up from MITM-attacks with self-signed certificates would be to register your public key at the same time you register the domain. browsers get the server's public key from dns at the same time it gets the ip-address (dns already supports binding of generalized information to domain ... more than simple ip-address). this is my long, repetitive argument about ssl domain name certification ....
i believe a lot of the non-commercial sites have forgone SSL certificates .... because of the cost and bother.
some number of the commercial sites that utilize SSL certificates .... only do it as part of financial transaction (and lots of them .... when it is time to "check-out" .... actually transfer to a 3rd party service site that specializes in SSL encruyption and payments). The claim by many for some time .... is that given the same exact hardware .... they can do 5-6 times as many non-SSL (non-encrypted) HTTP transactions as they can do SSL (encrypted) HTTPS transactions .... aka they claim 80 to 90 percent hit to the number of transactions that can be done switching from HTTP to HTTPS.
a short version of the SSL server domain name certificate is worry about attacks on the domain name infrastructure that can route somebody to a different server. so SSL certificate is checked against to see if the browser is likely talking to the server they think they are talking to. the problem is that if somebody applies for a SSL server domain name certificate .... the CA (certification authority) has to check with the authoritative agency for domain names .... to validate the applicants domain name ownership. The authoritative agency for domain names is the domain name infrastructure that has all the integrity concerns giving rise for the need for SSL domain name certificates. So there is a proposal for improving the integrity of the domain name infrastructure (in part backed by the CA industry ... since the CA industry is dependent on the integrity of the domain name infrastructure for the integrity of the certificate of the certificates) which includes somebody registering a public key at the same time at a domain name. So we are in catch-22 ....
1) improving the overall integrity of the domain name infrastructure mitigates a lot of the justification for having SSL domain name certificates (sort of a catch-22 for the CA industry).
2) registering a public key at the same time as domain name infrastructure ... implies that the public key can be served up from the domain name infrastructure (at the same time as the ip-address .... eliminating all need for certificates).
There is a description of doing an SSL transaction in single round trip. The browser contacts the domain name system and gets back in single transmission the 1) public key, 2) preferred server SSL parameters, 3) ip-address. The browser selects the SSL parameters, generates a random secret key, encrypts the HTTP request with the random secret key, encrypts the random secret key with the public key ... and sends off the whole thing in a single transmission .... eliminating all of the SSL protocol back&forth setup chatter. The browser had to contact the domain name system in any case to get the ip-address .... the change allows the browser to get back the rest of the information in the same transmission.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-03-16 10:17:39
@_author: Anne & Lynn Wheeler 
@_subject: How effective is open source crypto? 
Sorry, there were two pieces being discussed.
The part about SSL being a burden/load on servers ....
and the shorten SSL description taken from another discussion. The shorten SSL description was (in fact) from a discussion of the round-trips and latency ... not particularly burden on the server. In the original discussion there was mention about HTTP requires TCP setup/teardown which is minimum seven packet exchange .... and any HTTPS chatter is in addition to that. VMTP, from rfc1045 is minimum five packet exchange, and XTP is minimum three packet exchange. A cached/dns SSL is still minimum seven packet exchange done over TCP (although XTP would reduce that to three packet exchange).
So what kind of replay attack is there. Looking at purely e-commerce ... there is no client authentication. Also, since the client always chooses a new, random key .... there is no replay attack on the client ... since the client always sends something new (random key) every time. That just leaves replay attacks on the server (repeatedly sending the same encrypted data).
As follow-up to doing the original e-commerce stuff ... we then went on to look at existing vulnerabilities and solutions .... and (at least) the payment system has other methods already in place with regard to getting duplicate transaction .... aka standards body for all payments (credit, debit, stored-value, etc) in all (electronic) environments (internet, point-of-sale, self-serve, face-to-face, etc), X9.59
 (standard)
 (debit/atm network pilot)
Replay for simple information retrieval isn't particularly serious except as DOS .... but serious DOS can be done whether flooding is done with encrypted packets or non-encrypted packets. Another replay attack is transaction based ... where each transaction represents something like performing real world transaction (send a shirt and debit account). If it actually involves payment ... the payment infrastructure has provisions in place to handle repeat/replay and will reject. So primarily what is left .... are simple transaction oriented infrastructures that don't have their own mechanism for detecting replay/repeats and are relying on SSL.
I would also contend that this is significantly smaller exposure than self-signed certificates.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-03-16 10:40:52
@_author: Anne & Lynn Wheeler 
@_subject: How effective is open source crypto? (addenda) 
... small side-note .... part of the x9.59 work for all payments in all environments .... was that the transaction system needed to be resilient to repeats and be done in a single round-trip (as opposed to the transport).
there needed to be transaction resiliency with respect to single round trip with something like email that might not happen in strictly real-time (extremely long round-trip delays).
Real-world systems have been known to have glitches ... order/transaction generation that accidentally repeats (regardless of whether or not transport is catching replay attacks).
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-03-16 11:26:59
@_author: Anne & Lynn Wheeler 
@_subject: How effective is open source crypto? (bad form) 
so, lets look at the alternatives for servers that are worried about server replay attacks:
client has public key & crypto-preferred info (dns or cached), generates random secret key, encrypts request, encrypts random secret key, single server gets request ... application has opened the connection with or w/o server replay attack. if the application, higher level protocol has its own repeat checking .... it has opened the connection w/o server replay attack. and the server sends the request up the stack to the application. If the application has opened the connection with server replay attack, the protocol sends back some random data (aka its own secret)... that happens to be encrypted with the random key.
The client is expecting either the actual response or the replay attack check. If the client gets the actual response, everything is done. If the clients gets back the replay attack check .... it combines it with something .... and returns to the server.
The difference is basic two packet exchange (within setup/teardown packet exchange overhead) plus an additional replay prevention two packet exchange (if the higher level protocol doesn't have its own repeat handling protocol). The decision as to whether it is two packet exchange or four packet exchange is not made by client ... nor the server ... but by the server application.
Simple example for e-commerce is sending a P.O. along with payment authorization ... the transmitted P.O. form is guaranteed to have a unique identifier. The P.O. processing system has logic for handling repeat POs ... for numerous reasons (not limited to replay attacks).
Single round-trip transaction:
                         <- ServerResponse/Finish
Transaction w/replay challenge:
                         <-Server replay challenge
                         <-ServerResponse/Finish
Now, ClientHello/Trans can indicate whether the client is expecting a single round-trip or additional data.
Also, the ServerResponse can indicate whether it is a piggy-backed finish or not.
So, the vulnerability analysis is what is the object of the replay attack and what needs to be protected. I would contend that the object of the replay attack isn't directly the protocol, server, or the system .... but the specific server application. Problem of course, is that with generic webserver (making the connection) there might be a couple levels of indirection between the webserver specifying the connection parameters and the actual server application (leading to webservers always specifying replay challenge option).
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-03-16 13:48:02
@_author: Anne & Lynn Wheeler 
@_subject: How effective is open source crypto? (aads addenda) 
we did something similar for AADS PPP Radius
AADS radius example
... with FIPS186-2, x9.62, ecdsa digital signature authentication on sourceforce ....
radius digital signature protocol has replay challenge.
so adding radius option to webserver client authentication stub (infrastructure can share common administration client authentication across all of its environments). then client clicks on https client authentication, generates secret random key, encrypts request for client authentication with random key, encrypts random key with server public key, sends off single transmission. Server responds with radius connect request .... which includes replay challenge value as part of message (encrypted with random key). Client responds with digital signature on the server radius message (and some of its own data, encrypted with random key).
Basically use the same packet sequence as in transaction w/o replay challenge ... since higher level protocol contains replay challenge.  Then can use same packet sequence for webserver TLS and encrypted PPP (and works as VPN; possibly can define also as encrypted TCP) .... along with the same client authentication infrastructure
Infrastructure can use the same administration (RADIUS) infrastructure for all client authentication .... say enterprise with both extranet connections as well as webserver .... or ISP that also supplies webhosting. The same administrative operation can be used to support client authentication at the PPP level as well as at the webserver level.
The same packet exchange sequence is used for both PPP level encryption with client authentication as well as TLS for webserver level encryption with client authentication.
The higher level application can decide whether it already has sufficient replay/repeat resistance or request replay/repeat resistance from lower level protocol.
So regardless of TLS, PPP, or TCP, client authentication (using same packet sequence as transaction, w/o lower level replay challenge):
1) client picks up server public key and encryption options (from cache or DNS)
2) client sends of radius client authentication, encrypted with random secret key, encrypted with server public key ...
3) server lower level protocol handles the decryption of the random secret key and the decryption of the client request (which happens to be radius client authentication .... but could be any other kind of transaction request) and passes up the decrypted client request
4) server higher level protocol (radius client authentication) responds with radius replay challenge
5) client gets the replay challenge, adds some stuff, digitally signs it and responds
6) server higher level radius client authentication protocol appropriately Same server public key initial connect code works at TLS, PPP, and possibly TCP protocol levels. The same server public key initial connect code supports both lower-level replay challenge and no replay challenge.
Same radius client authentication works at TLS, PPP, and possibly TCP protocol levels. Same client administrative processes works across the whole environment.
aka .... the radius client authentication protocol is just another example (like the purchasse order example) of the higher level protocol having its own replay/repeat handling infrastructure (whether it is something like log checking or its own replay challenge).
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-03-24 10:10:53
@_author: Anne & Lynn Wheeler 
@_subject: Who's afraid of Mallory Wolf? 
slight observations ... i've heard of no cases of credit card number intercepted on the internet "in flight" (requiring crypto) ... and no known cases of MITM attack (requiring certificates)
However there have been some cases of impersonation ... being directed to a counterfeit web-site. I know of no cases of that being done with DNS cache poisoning ... which is also what certificates are targeted at ... both MITM and other impersonations of various kind. the ones i'm aware of is that the person clicks on some URL and goes to that site .... which is a counterfeit website. This isn't caught by SSL ... since it just compares the domain name in the URL against the domain name in the certificate presented by the server. Since the subterfuge happens well before any DNS cache is involved ... the SSL check of matching domain names doesn't catch anything. There have also been various impersonation involving frames and other screen painting techniques.
There have been cache poisonings (ip-address take over) ... there have been also incidents in the press of domain name hijacking ... sending updates to domain name infrastructure convincing them that somebody else is the new domain name owner. getting a new certificate as the new domain name owner is also a way of subverting the SSL check of matching domain names.
people registering public keys at the same time they register domain names was one of the suggested countermeasures to domain name hijacking.
There was another press thing last week regarding DNS attacks. The issue raised by the DNS attack last fall and the latest warning is that these have the potential to bring the internet to a halt.
 so there is some effort regarding dns integrity because of its critical importance for just having internet function at all.
past dns attack refs:
 from a cost of business standpoint ... i've suggested why not use the existing DNS infrastructure to distribute server public keys in the same way they distribute ip-address (they are pieces of information bound to the domain name, a function of the domain name infrastructure).... and are capable of distributing other things ... like administrative & technical contacts .... although that is getting restricted ... some bleed over from pkix
 The case against directories
 The case against directories
they could be naked public keys ... which would also be subject to DNS cache poisoning ...  or they could be "signed" public keys .... doesn't need all the baggage of x509 certs ... can just be really simple signed public key.
Slightly related to the above posting about long ago and far away .... when looking at allowing people (20 plus years ago) on business trips to use portable terminals/PCs to dial in and access the internal network/email .... a vulnerability assesement found that one of the highest problem areas was hotel PBXs. as a result a special 2400 baud encrypting modem was created.  encrypting modem anecdote from the time:
 Security Proportional to Risk (was: IBM Mainframe at home)
... these weren't in any related to the link encrypters from the previous reference (aka supposedly over half of the link encrypters in the world were installed on the internal network).
in any case, there was a big concern about numerous kinds of evesdropping ... requiring encryption for information hiding. however, the current internet credit card scenario seems to be that it is so much easier to harvest a whole merchant file with tens or hundreds of thousands of numbers ... than trying to get them one or two at a time off some internet connection.
note that the x9.59 approach has always been to remove the credit card numbers as a point of attack (form of shared-secret) by requiring all transactions to be authenticated. as a result, just knowing the number isn't sufficient for fraud (countermeasure against all account number harvesting .... regardless of the technique and whether insider or outsider the low-hanging fruit theory is that if merchant sites were armored then there could be more interest in evesdropping-based harvesting ... (leading to more demand for internet encryption). However. armoring merchant sites is difficult since 1) there are potentially millions, 2) human mistake is frequent/common vulnerability, 3) still leaves insiders as threat.
other parts of security proportional to risk thread:
 Security Proportional to Risk (was: IBM Mainframe at home)
 Security Proportional to Risk (was: IBM Mainframe at home)
 Security Proportional to Risk (was: IBM Mainframe at home)
 Security Proportional to Risk (was: IBM Mainframe at home)
 Security Proportional to Risk (was: IBM Mainframe at home)
 Security Proportional to Risk (was: IBM Mainframe at home)
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-03-24 10:21:47
@_author: Anne & Lynn Wheeler 
@_subject: Who's afraid of Mallory Wolf? (addenda) 
.... and while I don't know of any internet-based evesdropping for account number harvesting .... there are numerous reports of skimming in the physical world .... harvesting of account numbers by all sorts of techniques. These include things like video cameras by crooks trained on  various kinds of POS and other terminals.
misc. skimming references:
 In Brief: Anti-'Skimming' Guidelines Coming
 eBay Customers Targetted by Credit Card Scam
 The end of P-Cards?
 The end of P-Cards? (addenda)
 The end of P-Cards? (addenda)
 High-tech Thieves Snatch Data  From ATMs (including PINs)
 ATM Scams - Whose Liability Is It, Anyway?
 Credit Card Skimming Rising In The US
 "out of control credit card  High-tech Thieves Snatch Data  From ATMs (including PINs)
 Remove the name from credit cards!
 A Lesson In Security
 How to map a user account to a digital cert?
 SSL integrity guarantees in abscense of client certificates
 Backdoor in AES ?
 (OT) acceptance of technology, was: Convenient and secure
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-03-24 12:29:17
@_author: Anne & Lynn Wheeler 
@_subject: Armoring websites 
Who's afraid of Mallory Wolf?
 Who's afraid of Mallory Wolf? here is discussion of armoring websites with respect to security proportional to what is at risk
 net banking, is it safe???
 net banking, is it safe?? ... security proportional to risk
random refs to hardened sites:
 another characteristic of online validation.
 Where do the filesystem and RAID system belong?
 Calculating a Gigalapse
 Dumb Question - Hardend Site ?
 Dumb Question - Hardend Site ?
 Home mainframes
 diffence between itanium and alpha
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-03-24 17:50:41
@_author: Anne & Lynn Wheeler 
@_subject: Who's afraid of Mallory Wolf? 
I assert that there may be more sites that transmit credit card numbers w/o crypto, as sites that use SSL (although transaction rates are highly skewed so they even if it were ten times the number of sites, it might represent fewer actual transmissions). I don't have actual numbers, but I am aware of significant number of sites. However, I would contend that harvesting numbers from end-point merchant files has significantly higher return (ROI, expected results for the effort) than any sort of network evesdropping ... and that it is practically impossible to provide the necessary armoring as countermeasure for this vulnerability; end point attacks by either insider and outsider (historically, insider attacks on financial infrastructure have represented vast majority of incidents. While it may be possible to do a single armored site .... it isn't practical to do a million such sites (for one thing, people make too many mistakes) ... as per previous ref to security proportional to risk (and the merchant file risk is proportional to the credit limits of the accounts, not the specific merchant transaction).
I would expect that network evesdropping  would be employed where vulnerability was something other than kind of fraud do'able by attacking the end-point merchant file. Note however, skimming (various kinds of electronic & non-electronic recording) does go on in the physical world. Part of the issue may be that the target object (account number) has much lower occurance in general internet traffic (physical world skimming involves traffic that is almost solely account numbers). If you just have to skim, there are some number of points that are much more target rich environments (better fraud ROI) than internet traffic.
There is some phrase that if the only thing you know how to use is a hammer, then every solution may involve a nail.
The fundamental problem with account numbers is that they are effectively a kind of shared-secret .... acquiring/harvesting the numbers enables fraud. There are significant number of business processes that require the availability of the account numbers. This is one of the reasons for the end-point merchant files and also why "SET" (with significantly more complex crypto infrastructure and essentially only, also addressing data in-flight) offered very little additional over what my wife and I were involved with setting up the original SSL for e-commerce.
The point of x9.59 wasn't to add even more layers of crypto and information hiding to protect these shared-secrets .... but to change the business model so that the account numbers were no longer shared-secrets. X9.59 uses simple digital signature for authenticated payment transactions and a business rule that account numbers used in x9.59 transactions can't be used in non-authenticated payment transactions.
aka just by evesdropping an x9.59 transactions or harvesting account numbers used in x9.59 transactions doesn't enable a crook to initiate a fraudulent payment transaction.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-03-25 10:15:00
@_author: Anne & Lynn Wheeler 
@_subject: Who's afraid of Mallory Wolf? 
except the certification authorities ... when doing the certification of who owns a domain name .... still asks the domain name infrastructure as to who really owns the domain name .... when they get a request for a SSL domain name certificate. SSL domain name certificate request  after a domain name hijack still is possible (aka a chubb vault lock with a possible backdoor).
the other scenario that has been raised before is that the browsers treat all certification authorities the same .... aka if the signature on the certificate can be verified with any of the public keys in a browser's public key table ... it is trusted. in effect, possibly 20-40 different manufactures of chubb vault locks .... with a wide range of business process controls ... and all having the same possible backdoor. Furthermore, the consumer doesn't get to choose which chubb lock is being Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-03-25 15:32:00
@_author: Anne & Lynn Wheeler 
@_subject: Who's afraid of Mallory Wolf? 
circa '95 .... there were comments that ISP's didn't want to verify from/spoofed packet addresses on DHCP modem connections because it increased their router cpu costs (actually one of the most common routers didn't have enuf processor power to implement even trivial packet filtering on modem lines).
 Internet like city w/o traffic rules, traffic signs, traffic lights and traffic enforcement
 Internet like city w/o traffic rules, traffic signs, traffic lights  and traffic enforcement
 Internet like city w/o traffic rules, traffic signs, traffic lights and traffic enforcement
 Internet like city w/o traffic rules, traffic signs, traffic lights and traffic enforcement
 Internet like city w/o traffic rules, traffic signs, traffic lights and traffic enforcement
now there is the observation in this thread (or the previous thread) that many websites use SSL very sparingly because it cuts their web traffic capacity by 80-90 percent (http vis-a-vis https given the same hardware).
Typical sequence is that person clicks-on/types something and goes to a site with straight HTTP, they shop for a while ... until they are ready to check-out, they then click on the "check-out" button. That button supplies a URL that sends them off to a HTTPS site (aka the user didn't actually originated the HTTPS url) ... where all the payment information is provided. Now since the client/consumer never provided the actual HTTPS sequence  .... but it was provided for them by a webpage at the HTTP site they were shopping at .... it is presumably trivial for the HTTP site that they are shopping at to make sure that the HTTPS URL domain that clients are sent to .... matches the certificate domain at that site (and a lot of shopping URLs have a lot of  appended history so that it is relatively easily contrived that the consumer doesn't notice the domain name of the "check-out/payment" page).
A lot of the requirement for encryption is end-to-end ... or at least VPN-like .... so encrypted packets should mostly be transparent to operations in their ISP roles. This isn't as true on the web-hosting side of the house ... where SSL or similar encryption activity can represent significant additional CPU processing load.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-05-13 11:12:53
@_author: Anne & Lynn Wheeler 
@_subject: economics of spam (Re: A Trial Balloon to Ban Email?) 
... but i would contend that the infrastructure costs associated with a billion or two spams per day are significantly higher than the costs that are currently being incurred by the spammers .... in effect the industry as a whole is underwriting a significant percentage of the actual costs, which makes spamming such an attractive economic activity. one of the issues is to reflect the fully loaded costs of a billion or two spams per day back to the spammers.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-05-17 08:07:35
@_author: Anne & Lynn Wheeler 
@_subject: Payments as an answer to spam 
x9.59 standard for all elecronic payments can use digital signatures w/o PKI or certificates ... just public key registered with account and connectivity to senders financial institution. It isn't "centralized" any more than the existing payment card operation is centralized .... aka huge number of different consumer financial institutions all with their individual operation and account records. however, much of it is based on a private network interconnecting all of these financial operations that predates the existing internet ... but effectively functionally equivalent.
The existing payment card infrastructures are open in the sense thay they do have an international standard, iso8583 .... in much the same way that certificates have iso international standard. and there are numerous interconnects between the internet and these infrastructure ... witness the existing electronic commerce. It is less open than the "internet" in the sense that there are contractual, institutional, and financial obligations that are necessary to directly participate (but i believe that will tend to be always true except in the cases of toy demos). However, that isn't precluding the migration of more electronic commerce related traffic to internet-based technology in various ways. The issue isn't directly whether it is internet-related technology or non-internet related technology .... but much more of an issue whether there are explicit legal and other obligations required to participate.
x9.59 standard reference
account record public key infrastructures
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-05-17 09:21:21
@_author: Anne & Lynn Wheeler 
@_subject: Payments as an answer to spam (addenda) 
The existing payment card infrastructure (credit, debit, online stored-value, 3rd party, etc) had used a PKI-type infrastructure prior to about 1970, aka credential (in this case in the guise of a plastic physical card with varioius embossing and printing) that could be used in offline transactions, unconnected transactions.
The transition to online transactions started in the early '70s ... used an electronic end-point in the guise of magstripe added to the existing physical credential ... while they were emboddied in the same physical package, they represented totally different paradigms.
The existing PKI certificates are a return to the offline, pre-70s paradigm that the existing payment card infrastructure left long ago. The existing payment card paradigm is not only online in the sense that it checks whether the account is still valid ... but also checks real-time, aggregated information regarding whether there is sufficient funds.
OCSP for PKIs is a limiting baby step into an online world with real-time checking of whether the offline credential is still valid .... but it doesn't actually make it into the 1970s where a stale, static certificate is redundant and superfluous and there is direct access to much higher quality real-time and possibly aggregated information used for financial operations. OCSP is actually a more timely version of the paper booklets that were distributed in the 50s & 60s .... not an actual switch from a basically offline paradigm to an online paradigm.
Frequently there were were comments equating statements about redundant and superfluous certificates as being a transition to a centralized paradigm. However the issue isn't with regard to centralized/non-centralized ... which is effectively orthogonal to the issue regarding static, stale certificates .... it is an issue of offline/online (not centralized/non-centralized). There is the issue that if it is online paradigm ... it is possible to have either a centralized or a non-centralized paradigm .... which is somewhat more difficult to have such option in a purely offline paradigm.
random past posts on redundant and superfluous offline credentials for an online paradigm
 CFP: PKI research workshop
 CFP: PKI research workshop
 CFP: PKI research workshop
 CFP: PKI research worksho
 Q: Where should do I put a max amount in a X.509v3 certificat e?
 Q: Where should do I put a max amount in a X.509v3 certificate?
 ALARMED ... Only Mostly Dead ... RIP PKI ... part II
 draft-ietf-pkix-warranty-ext-01
 Employee Certificates - Security  Identification = Payment  I-D Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-05-17 17:56:52
@_author: Anne & Lynn Wheeler 
@_subject: Payments as an answer to spam (addenda) 
the description was that CRLs were an exact analogy of the paper booklet,
while OCSP is a more timely version of the paper booklet; aka it is a more
timely solution for an offline paradigm ... using a little bit of online but not with the actual transition from an offline paradigm to an online theoretically, the payment system could have preserved the offline paradigm
and just used the online terminal to check whether the offline credential
is still valid .... however, they actually used the online capability to
actually change from an offline paradigm to an online paradigm ... rather
than using the online capability as sort of a kludgey crutch for continuing
to prop up an offline paradigm.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-05-18 06:47:13
@_author: Anne & Lynn Wheeler 
@_subject: Payments as an answer to spam (addenda) 
But the actual transformation from offline paradigm to online paradigm had nothing to do with the credential. In the credential world, there is something emboddied in the credntial that convinces the relying party to accept or reject the operation modula a currently valid/active credential (aka as previously outline, these credentials are static, stale subset copy of some master information someplace, typically kept in an account record). The transition to the online paradigm involved asking is the payment approved, nothing to do (directly) with the validity of any credential. The certification authority and up-to-date information about authentication ... but also up-to-date and aggregated information about patterns leading up to this event. The certifying authority ... instead of commenting about any credential ... providing yes/no regarding the transaction in the context of real-time and aggregated information.
In fact, to the extent that any financial institution using a certificate .... it did go thru a period of being used because of requirement by various off-the-shelf software on the internet. However, because of privacy and liability reasons they aborted the contents to just an account number for a relying-party-only certificate. However, (other than requirement to satisfy certain off-the-shelf software), it is trivial to show that such relying-party-only certificates are redundant and superfluous from a business process & flow perspective.
In general, there is almost nothing that you really want to put into some document that is going to be sprayed all over the infrastructure for everybody to examine. The original premise for X.509 was that there would be some information in the contents of the certificate, that a relying-party could take a look at for the basis of making a decision w/o requiring anything more .. like online access or previously obtained information. Given online access and/or previously obtained information (prior/previous business relationship) .... it is possible to show that stale, static information embodied in a certificate is redundant and random past comments on relying-party-only certificates:
 Attacks on a PKI
 "Trusted" CA - Oxymoron?
 "Trusted" CA - Oxymoron?
 "Trusted" CA - Oxymoron?
 general questions on SSL certificates
 Why trust root CAs ?
 Why trust root CAs ?
 PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  Q: ANSI X9.68 certificate format  Invalid certificate on 'security'  Can I create my own SSL key?
 FREE X.509 Certificates
 PKI/Digital signature doesn't work
 PKI/Digital signature doesn't work
 PKI/Digital signature doesn't work
 PKI/Digital signature doesn't work
 Net banking, is it safe???
 PKI Implementation
 PKI and Relying Parties
 Digital certificate varification
 A new e-commerce security proposal
 A new e-commerce security proposal
 Beware, Intel to embed digital certificates in Banias
 Help! Good protocol for national ID card?
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-10-01 16:18:10
@_author: Anne & Lynn Wheeler 
@_subject: how simple is SSL? (Re: Monoculture) 
some related recent thread from comp.ssecurity.ssh n.g. (somewhat my standard harping about confusing the technology of digital signatures and the business issues of PKI and certificates):
 public key vs passwd authentication?
 public key vs passwd authentication?
 public key vs passwd authentication?
 public key vs passwd authentication?
 public key vs passwd authentication?
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-10-07 12:53:59
@_author: Anne & Lynn Wheeler 
@_subject: Simple SSL/TLS - Some Questions 
really KISS/simple SSL/TLS .... given the business requirements for existing use (as opposed to existing technical specifications for existing implementations) is to register server's public key and crypto preferences in DNS .... when client calls DNS to get ip-address ... they can also request public key & crytpo preferences be returned in the same transmission. for transition purposes, the public key, crypto preferences, etc .... can exist in a authoritative signed message by some generally recognized trusted party .... a mini-certificate (if you will).
the client generates a random session key according to the crypto preferences, encrypts a credit card number and misc. ancillary transaction info with the session key, encrypts the session key with the public key (if you really want to simplify to the business requirements, directly encrypt with the public key and eliminate the session key step) .... and use a XTP-like (or some of the emerging real-time protocol) .... aka existing SSL is carried on top of TCP .... TCP requires a minimum of 7 packet exchange .... and SSL on top of that then requires all the negotiation chatter.
Having the public key (& possibly crypto preferences .... unless you want to directly encrypt with the public key) piggy-back with the DNS request .... then the actual transaction can be done in three-packet exchange (i.e. XTP defines a minimum three-packet exchange for reliable transaction).
This is about as simplified SSL/TLS as you can get based on business requirements for the major existing applications using SSL/TLS
some past related comments
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-10-07 13:15:18
@_author: Anne & Lynn Wheeler 
@_subject: Simple SSL/TLS - Some Questions 
KISS ... for the primary business requirement .... the application already has anti-replay .... TLS ant-replay is then redundant and superfluous.
yes, it isn't existing TLS .... it is KISS TLS based on primary business requirement ... as mentioned in original,  not on existing specification for existing implementation
when doing the original deployment stuff
there was the idea in would be used for the whole online experience. The subsequent comments was that it got cut back to the current primary use .... because it imposed a five-fold overhead increase (or reduced a server service capacity by 80 percent).
Making it significantly more simple and lightweight might encourage it to be used more extensively.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-10-07 21:53:32
@_author: Anne & Lynn Wheeler 
@_subject: Simple SSL/TLS - Some Questions 
what i said was that it was specifying a simplified SSL/TLS based on the business requirements for the primary use of SSL/TLS .... as opposed to a simplified SSL/TLS based on the existing technical specifications and existing implementations.
I don't say it was technical TLS .... I claimed it met the business requirements of the primary use of SSL/TLS.
I didn't preclude that there could simplified SSL/TLS based on existing technical specifications as opposed to implementation based on business requirements for the primary use.
I thot I was very fair to distinguish between the business requirements use of SSL/TLS as opposed to technical specifications for SSL/TLS.
There are lots of really great implementations in this world .... many of which have absolutely no relationship at all with a good business reason to The real observation was that in the early deployments of SSL .... it was thot it would be used for something entirely different ... and therefor had a bunch of stuff that would meet those business requirements. However, we come to find out that it was actually being used for something quite a bit different with different business requirements.
So a possible conjecture is that if there had been better foreknowledge as to how SSL was going to be actually be used .... one might conjecture that it would have looked more like something I suggest (since that is a better match to the business requirements) ... as opposed to matching some business requirements for which it turned out not to be used.
As to usefulness .... I wasn't really trying to claim it would be useful .... just that it would meet the business requirements of its primary use.
I've repeatedly claimed that the credit card number in flight has never been the major threat/vulnerability .... the major threat (even before the internet) has always been the harvesting of the merchant files with hundreds, thousands, tens of thousands, even millions of numbers .... all neatly arranged.
The issue that we were asked to do in the X9A10 working group was to preserve the integrity of the financial infrastructure for all electronic retail payments.  A major problem is that in the existing infrastructure, the account number is effectively a shared-secret and therefor has to be hidden. Given that there is a dozen of business processes that require it to be in the clear and potentially millions of locations .... there is no practical way of addressing integrity of such a shared-secret ((you could burry the earth to the depth of a couple miles with cryptography .... and it still wouldn't alleviate the threat).
It turns out that once the account number is no longer a shared-secret .... then it is no longer necessary to hide it in order to preserve the integrity of the financial infrastructure. At that point, a primary existing use of SSL/TLS goes away completely.
I wasn't really to hijack the protocol .... however, if you wanted to simplify something based on the business requirements of its use ... then one might consider simplifying based on the business requirements of its use (even if it became somewhat different). My strong preference (by several orders of magnitude) is to not do anything to contribute to delays of eliminating account numbers as shared-secrets (that would include not contributing to an extreme KISS TLS other than a hypothetical mental exercise related to business justification as a reason for doing something)..
I would prefer the primary justification for SSL/TLS to totally disappear  There then might remain some other uses that could benefit from SSL/TLS .... and they might not have a need for simplification at all.
Frequently when simplification is done to something .... you throw away stuff that isn't needed (at least for the targeted business purpose). The issue in extreme KISS TLS .... at what point has it become so simple that it can no longer be TLS  ... aka what is the minimal simple set of things needed for something to still be TLS?
simple result of the x9a10 working group to preserve the integrity of the financial infrastructure for all electronic retail payments .... and eliminate account numbers as shared-secrets
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-10-12 08:25:21
@_author: Anne & Lynn Wheeler 
@_subject: Trusting the Tools - was Re: Open Source ... 
1) that it is more straight-forward to check assembler generated
code since there is nearly a one to one correspondance between the
assembler statement and the generated machine code
2) default assembly program generated listings shows assembler
statement and the corresponding generate machine instruction
3) the assembler was widely used thru-out the world
4) the source of the assembler was available
5) there were things like the SLAC assembler enhancements (just down/up
the road)
6) people available (like people that did SLAC mods) that had dealt with
the source of the assembler
7) some organizations that extensively used such systems that did
study some of these issues in more detail
8) people dealing with development and debugging assembler-based
systems normally are operating between the assembler listings
(showing one-to-one between assembler statement and generated
machine instruction) and what appears in memory.
9) assembler program listing also summarizes code size .... and is also and commonly used in manual mapping to memory image.
It wouldn't have been impossible ... but quite unlikely. It is somewhat
easier in C-based programs since there are additional levels of indirection
and obfuscations between the statements in a C program and the
generated machine code.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-10-12 17:13:06
@_author: Anne & Lynn Wheeler 
@_subject: Trusting the Tools - was Re: Open Source ... 
well ... you can take and compare the listing file against the "txt" deck of the assembler listing for each module . Each "txt": deck is input to the which builds the actual executable (almost) memory image. past discussion
of the TXT file format:
 IBM Model Numbers (was: First video terminal?)
 "Bootstrap"
 Is anybody out there still writting BAL 370.
 Blade architectures
 Relocation, was Re: Early computer games
then the issue isn't if the assembler has been compromised ... it is whether the
loader has been compromised. then you compare the memory image file
against the aggregate of the txt decks ... if you've done the assembler
listing comparison against the txt deck correctly .... then the memory
image comparison is looking for a loader compromise ... not an
assembler compromise.
some past discussion of memory/debugger analyser from approx. period that
gnosis started (precursor to keykos):
which also had some capability to work from memory image of the program
in conjunction with assembler listing files.
of course it primarily relied on the REXX interpreter for its functionality so
if there was a compromise in the REXX interpreter .... or any of the utilities
written for analyses and comparison were compromised from the standpoint
of masking compromise in other components related to insertion of malicious
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-10-13 16:24:51
@_author: Anne & Lynn Wheeler 
@_subject: NCipher Takes Hardware Security To Network Level 
I would contend that the penetrate-and-patch model is because the original base was not designed for 7x24, fully interconnected environment. some slightly related comments on the subject:
 Poor People's OS
The air force found none of the problems in the studied infrastructure:
 Thirty Years Later: Lessons from the Multics Security Evaluation
 another 30 year thing
 Thirty Years Later: Lessons from the Multics Security Evaluation
 grey-haired assembler programmers (Ritchie's C)
 A Dark Day
the contention is that the system was designed to handle the circumstances. The currently common distributed software was not originally designed to handle this kind of situation .... and repeatedly it has been demonstrated for assurance to work well .... it has to be designed in from the start .... not added on afterward.
At various times, we had polite competition since the worked referenced in the air force study was done on the 5th floor of 545 tech. sq ... and I was on the 4th floor ... also working on what was considered a secure (but totally different) system.
There were issues about unfair comparison since at the time of the following .... the totally number of systems ever existing for the 5th floor system was something over one hundred. The total number of just internal corporate machines running the 4th floor system was in the thousands and the number of customer machines were low tens of thousands. So we just had light hearted competition with regard to just code I wrote .... and the number of (internal) machines that I directly provided systems for (something over a hundred ... comparable to the total number of 5th floor systems).
The following reference was the system that the air force data center in the pentagon was running was getting old ... and they were looking at newer hardware, in this case initially twenty newer machines, each with about the same MIP rate of the aging machine running the 5th floor system. As referenced, this then turned into 210 such machines:
 departmental servers
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-10-17 10:05:47
@_author: Anne & Lynn Wheeler 
@_subject: WYTM? 
One can claim this is what a credit card does for the consumer .... the
name on the card is somewhat tangential to it being a credential; it is
there so that the merchant can authenticate the credential by cross
checking the name on the card with names on other credentials that you
might be carrying. If you have enuf credentials with the same name ...
then it eventually satisfies the merchant that it is your credential.
Some number of places are taking the name off the card .... as part of
improving consumer privacy at point-of-sale. They can do this with debit
.... where the PIN is a substitution for otherwise proving it is your
credential. however, as previously posted there is a lot of skimming
going an with the information for making a counterfeit card as well as
skarfing up the corresponding PIN is being done.
This is also being done with some kinds of chip cards .... where a PIN
is involved .... but since the infrastructure "trusts" the cards ....
the counterfeit cards are programmed to accept any PIN .... see the "yes
card" at the bottom of the following URL.
The issue is that technique used to skim static data for making
counterfeit magstripe cards also applies to skimming static data for
making counterfeit "yes cards".
The claim in X9.59 is that the signature from something like an asuretee
card ... can both demonstrate two (or three) factor authentication as
well as proving that the transaction hasn't been tampered with since it
was signed.
In this case, while the card may still look like an (offline) credential
from pre-1970s (with printed credential revokation lists mailled out
every month to all merchants) .... it, in fact does an online
transaction. The digital signature proving 2/3 factor authenticaiton
(and no transaction tampering during transit) is then accepted (or not)
by the financial institution which reports back real-time result to the
relying party (merchant).
This is a move from the ancient offline paradigm that has been going on
for hundreds of years (with credentials as substitute for real-time
interaction) to an online paradigm. While the form-factor may still
appear the same as the rapidly becoming obsolete offline credential; it
is actually operating as a long-distance 2/3 factor authentication
mechanism between the consumer and their financial institution .... with
the merchant/relying-party getting back a real-time response as to
whether the institution stands behind the request. The difference between the x9.59/asuretee implementation and the "yes
card" implementation is that there is no static data to skim (and use
for creating counterfeit cards/transactions).
misc. x9.59 refs:
misc. aads chip strawman & asuretee refs:
The integrity of the chipcard and the integrity of the digital signature
substitutes for requiring the merchants to cross-check the name on the
card with the names on an arbitrary number of other "credentials" until
they are comfortable performing the transaction. The current (non-PIN card) infrastructure is sort of half way between
the old style "everything is a credential" and the new "everything is
onlin"e .... to a fully trusted online infrastructure. The magstripe
does an online transaction and the institution will approve the
transactions with some number of caveats regarding it not being a
counterfeit/fraudulent transaction. For the non-PIN transactions, the
merchant (can) uses the name on the card to cross check with as many
other credential names until the merchant becomes comfortable.
This is similar to the scenario with the existing SSL domain name
certificate issuing process (using names mapping to common/real-world
identities in order to achieve authentication). The domain name system
registers the owner's name. The CA SSL certificate issuer obtains a name
of the certificate requester .... and then the CA attempts to map the
two names into the same real world identities as a means of achieving
authentication. The drastically simpler solution is the domain name
system registers a public key at the same time as registering the domain
name. THen the SSL certificate issuer, instead of having to map real
world identities in order to achieve authentication .... can just use
the registered public key to achieve authentication. The catch22 is that
if the SSL certificate issuer can use the registered public key for
authentication (instead of the much harder problem of trying to map
names into the same real word identities) ... then lots of other
entities can also use the registered public key for authentication ....
significantly decreasing the need for such a SSL certificate.  The integrity of the chipcard and the integrity of the digital signature
substitutes for requiring the merchants to cross-check the name on the
card with the names on an arbritrary number of other "credentials" until
they are confortable performing the transaction.  recent threads discussing identification when all that is needed is
 Is cryptography where security
took the wrong branch?
 Resolving an identifier into
a meaning

@_date: 2003-10-22 14:27:30
@_author: Anne & Lynn Wheeler 
@_subject: SSL, client certs, and MITM (was WYTM?) 
in general SSL domain name certs address
1) is the server I think I'm talking to really the server that I'm
talking to (is the URL I entered match the URL in the certificate)
2) key exchange, for an encrypted session
So what purpose would client certificates address? Almost all of the use
of SSL domain name certs is to hide a credit card number when a consumer
is buying something. There is no requirement for the merchant to
identify and/or authenticate the client .... the payment infrastructure
authenticates the financial transaction and the server is concerned
primarily with getting paid (which comes from the financial institution)
not who the client is.
So, there are some infrastructures that have web servers that want to
authenticate clients (for instance online banking). They currently
establish the SSL session and then authenticate the user with
userid/password against an online database.
In fact is .... one contention is that possibly 99.9999 percent of the
client-based authentication that happens in the world today is done
against some database.
There was an instance of a bank issuing client certificates for use in
online banking. At one time they claimed to have the largest issued PKI
client certificates (aka real PKI as opposed to manufactured
However, they discovered
1) the certificates had to be reduced back to relying-party-only
certificates with nothing but an account number (because of numerous
privacy and liability concerns)
2) the certificates quickly became stale
3) they had to look up the account and went ahead and did a separate
password authentication .... in part because the certificates were
They somewhat concluded that the majority of client certificate
authentication aren't being done because they want the certificates ....
it is because the available COTS software implements it that way (if you
want to use public key) ... but not because certificates are in anyway
useful to them (in fact, it turns out that the certificates are
redundant and superfluous ... and because of the staleness issue
resulted in them also requiring passwords).
So a reasonable suggestion was to ship webservers ....  with a radius
stub for the client authentication interface. The client registers
authentication material (in much the same way that nearly all of the ISP
authentication infrastructures operation).
If the desire is to have something better than passwords or
"shared-secrets" (aka trying to help the world address the huge
propogation of number of shared-secrets per person that is occuring in
the online world), then it would be possible to register a public key in
the radius database ... and authenticate with a digital signature as
opposed to a shared-secret.
A certificate is to address the propagation of trust between two
entities that have had no prior relationship (and possibly may never in
the future have any sort of relationship) and there is not any other
kind of recourse ....  it is purely possible to have digital signature
strong authentication when certificates aren't involved in anyway
If you eliminate all the scenarios where the entities have no prior
relationship and/or have no recourse to an online service then you are
pretty much done to a zero set. The scenario with a random customer at a
random merchant website ... never before visited ... the merchant is
interested in getting paid .... the customer contacts their bank (prior
business relationship), the customer bank contacts the merchant bank
(prior business relationship), and the merchant bank contacts the
merchant (prior business relationship) .... to tell the merchant that
they will get paid (aka the real-time response from the financial
infrastructure means a lot more to the merchant than anything that a
random, unknown consumer might claim ... regardless of any possible
redundant and superfluous certificate that might be involved).

@_date: 2003-10-22 15:58:33
@_author: Anne & Lynn Wheeler 
@_subject: SSL, client certs, and MITM (was WYTM?) 
the statement was SSL domain name certificate is
1) am i really talking to who I think I'm talking to
2) encrypted channel
obviously  addresses MITM (am i really talking to who I think I'm talking The issue for CC is that it really is a "shjared secret" and is extremely vulnerable ... as I've commented before
1) CC needs to be in the clear in a dozen or so business processes
2) much simpler to harvest a whole merchant file with possibly millions of CC numbers in about the same effort to evesdrop one off the net (even if there was no SSL) return on investment .... for approx. same amount of effort get one CC number or get millions
3) all the instances in the press are in fact involved with harvesting large files of numbers ... not one or two at a time off the wire
4) burying the earth in miles of crypto still wouldn't eliminate the current shared-secret CC problem
slightly related .... security proportional to risk:
so the requirement given the X9 financial standards working group X9A10
was to preserve the integrity of the financial infrastructure for all electronic retail payment (regardless of kind, origin, method, etc). The result was X9.59 standard
which effectively defines a digitally signed, authenticated transaction .... no certificate required ... and the CC number used in X9.59 authenticated transactions shouldn't be used in non-authenticated transactions. Since the transaction is now digitally signed transactions and the CC# can't be used in non-authenticated transactions .... you can listen in on X9.59 transactions and harvest all the CC# that you want to and it doesn't help with doing fraudulent transactions. In effect, X9.59 changes the business rules so that CC# no longer need to be treated as shared secrets.
misc. past stuff about ssl domain name certificates
misc. past stuff about relying-party-only certificates
misc. past stuff about using certificateless digital signatures in radius misc. past stuff about using certificateless digital signatures in kerberos misc. fraud & exploits (including some number of cc related press some discussion of early SSL deployment for what is now referred to as electronic commerce
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-10-22 18:36:35
@_author: Anne & Lynn Wheeler 
@_subject: SSL, client certs, and MITM (was WYTM?) 
ok, the original SSL domain name certificate for what became electronic commerce was
1) am I really talking to the server that I think I'm talking to
2) encrypted session.
so the attack in  was plausably some impersonation ... either MITM or straight impersonation. The issue was that there was a perceived vulnerability in the domain name infrastructure that somebody could contaminate the domain name look up and get the ip-address for the client redirected to the impersonater.
The SSL domain name certificates carry the original domain name .... the client validates the domain name certificate with one of the public keys in the browser CA table ... and then validates that the server that it is communicating with can sign/encrypt something with the private key that corresponds to the public key carried in the certificate ... and then the client compares the domain name in the certificate with the URL that the browser used.  In theory, if all of that works .... then it is highly unlikely that the client is talking to the wrong ip-address (since it should be the ip-address of the server that corresponds to the server).
So what are the subsequent problems:
1) the original idea was that the whole shopping experience was protected by the SSL domain name certificate .... preventing MITM & impersonation attacks. However, it was found that SSL overhead was way to expensive and so the servers dropped back to just using it for encryption of the shopping experience. This means that the client ... does all their shopping ... with the real server or the imposter ... and then clicks on a button to check out that drops the client into SSL for the credit card number. The problem is that if it is an imposter ... the button likely carries a URL for which the imposter has a valid certificate for.
2) the original concern was possible ip-address hijacking in the domain name infrastructure .... so the correct domain name maps to the wrong ip address .... and the client goes to an imposter (whether or not the imposter needs to do an actual MITM or not). The problem is that when somebody approaches a CA for a certificate .... the CA has to contact the domain name system as to the true owner of the domain name. It turns out that integrity issues in the domain name infrastructure not only can result in ip-address take-over .... but also domain name take-over. The imposter exploits integrity flaws in the domain name infrastructure and does a domain name take-over .... approaches a CA for a SSL domain name certificate ... and the CA issues it ... because the domain name infrastructure claims it is the true owner.
So somewhat from the CA industry ... there is a proposal that people register a public key in the domain name database when they obtain a domain name. After that ... all communication is digitally signed and validated with the database entry public key (notice this is certificate-less). This has the attribute of improving the integrity of the domain name infrastructure ... so the CA industry can trust the domain name infrastructure integrity so the rest of the world can trust the SSL comain name certificates?
This has the opportunity for simplifying the  SSL domain name certificate requesting process. The entity requesting the SSL domain name certificate .... digitally signs the request (certificate-less of course). The CA validates the SSL domain name certificate request by retrieving the valid owner's public key from the domain name infrastructure database to authenticate the request. This is a lot more efficient and has less vulnerabilities than the current infrastructure.
The current infrastructure has some identification of the domain name owner recorded in the domain name infrastructure database. When an entity requests a SSL domain name certificate ... they provide additional identification to the CA. The CA now has to retrieve the information from the domain name infrastructure database and map it to some real world identification. They then have to take the requester's information and also map it to some real world identification. They then have to try and see if the two real word identifications match. The recording of the public key for certificate-less authentication ... not only improves the integrity of the domain name infrastructure (so that it can be better trusted by the CA industry) .... but it can also convert a very error prone identification process for certificates into a simple authentication process.
So now we have the catch-22 clinker for the CA industry (since they are somewhat sponsoring this whole idea)
1) if the certificate-less public key process improves the integrity of the domain name infrastructure, then one can claim that the integrity concerns about the domain name infrastructure are lessoned and therefor the perceived requirement for SSL domain name certificates is lessoned
2) if the CA industry can use the registered public key for certificate-less authentication regarding domain name related operations ... then presumably the rest of the world can also ... which would further eliminate justifications for SSL domain name certificates (i don't need to get the server's public key from a certificate .... I could get it from a dynamic, trusted, information distribution utility ... the domain name as before ... misc SSL domain name certificate related posts:
the following also have some references to domain name hijacking events (as opposed to ip-address hijacking):
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-10-23 09:43:04
@_author: Anne & Lynn Wheeler 
@_subject: SSL, client certs, and MITM (was WYTM?) 
Internet groups starts anit-hacker initiative
 one of the threats discussed in the above is the domain name ip-address take-over mentioned previously
which was one of the primary justifications supposedly for SSL deployment (am i really talking to the server that I think i'm talking to).
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-10-24 08:39:10
@_author: Anne & Lynn Wheeler 
@_subject: Digital certificate clearinghouse needs work 
Digital certificate clearinghouse needs work
The mechanism that allows a digital certificate to be used across
government agencies must be upgraded before it will be available for the
entire government, a federal information technology official said today.
The Federal Bridge Certification Authority (FBCA) is the central
mechanism that handles digital certificates for transactions secured by
any participating agency's public-key infrastructure (PKI). Clients of
FBCA participants do not need certificates from every agency with which
they do business.
... snip ..

@_date: 2003-09-02 15:02:50
@_author: Anne & Lynn Wheeler 
@_subject: invoicing with PKI 
somewhat related thread in sci.crypt ... summary
 RSA vs AES
 RSA vs AES
 RSA vs AES
 RSA vs AES
 RSA vs AES
when we were working with small client/server startup for payments
we coined the term "certificate manufacturing" as part of doing due diligence on various commercial CAs ... to distinguish from PKI.
we've also since claimed that proposal, effectively by SSL server certification business ... to have public keys registered as part of the domain name process goes a long way to both 1) improving the integrity of the domain name infrastructure and 2) provides basis for trusted, real-time public key distribution making SSL server certificates redundant and One of the big issues with identity x.509 certificates from the early 90s was the quandary  with 1) overloading a certificate with huge amounts of privacy information (hoping that its use by unknown relying parties at some point in the future would find something in the certificate useful  and 2) the extremely onerous privacy issues with the spraying of such privacy information all over the world. Somewhat as a result, financial infrastructures dropped back to relying-party-only certificates .... something that effectively contained only the public key and the account Somebody from Deutsche bank made a presentation in 1998 regarding having moved to relying-party-only certificates because of the enormous privacy and liability issues. However, since Duetsche bank had issued the certificate for the public key (and account), Duetsche bank already had the public key on file. There was actually nothing in the appended relying-party-only certificate that carried any information that Duetsche bank didn't already had on file (and the elimination of the requirement to append a certificate tended to remove a large payload penalty).
It was relatively trivial to show for financial transactions that relying-party-only certificates were redundant and superfluous (i.e. the financial institution already has all the information so there is no reason to tack a certificate on to the end of every transaction or communication with the bank).
The other issue ... somewhat highlighted by SET was that the payload penalty for certificates in the payment infrastructure was enormous ... a basic SET certificate possibly being two orders of magnitude larger than the basic payment message. As a result, SET typically was deployed for internet only operations with a gateway between the internet and the payment network performing the signature verification, stripping off the certificate and flagging the real payment transaction indicating that the signature had verified. First of all that violates one of the basic principles of end-to-end security. In fact, somebody from VISA presented some numbers in an ISO standards meetings about the transactions flowing through interchange with the "signature verified" flag set and they could prove that no digital signature technology was ever involved.
The financial standards x9a10 working group was given the requirement to preserve the integrity of the financial infrastructure for all electronic retail payments (aka ALL as in internet, non-internet, point-of-sale, face-to-face, non-face-to-face, debit, credit, ach, stored-value, etc ... i.e. ALL). The result was a digital signed transaction that was lightweight enough that it would operate in all environments and didn't require the enourmous payload penalty of an appended certificate:
NACHA tested a certificate-less digitally signed debit transaction in their Internet trials:
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-09-03 08:21:57
@_author: Anne & Lynn Wheeler 
@_subject: Is cryptography where security took the wrong branch? 
My view was that ipsec had been in progress for some time and not making a whole lot of headway. At the San Jose IETF meeting (fall '94?), VPN was introduced in a router/gateway working group. This caused quite a bit of consternation among the router vendors that didn't have processing to implement the required cryptography operations (and you saw some vaporware product announcements following the meeting). It also caused some consternation among the ipsec group. Eventually most of the router vendors upgraded to processors that could handle the VPN requirements and it started to make some deployment progress. The ipsec group somewhat came to terms by referring to VPN as lightweight ipsec (and the vpn group referring to ipsec as heavyweight security).
HTTPS came out about the same period. It basically is a transport layer protocol implemented in the application layer .... again ipsec implementation and distribution at the operating system level was not making a lot of progress ... and so a vendor could build HTTPS into their product and distribute it w/o having to worry about dependencies on other vendor components.
There is some postings in sci.crypt that while you see pervasive distribution of HTTPS support ... supposedly the percentage of web sites that actually offer up HTTPS (and SSL domain name server certificates) is around the one percent range.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-09-03 08:36:55
@_author: Anne & Lynn Wheeler 
@_subject: invoicing with PKI 
x.509 identity certificates are business processes ... not a cryptography process. as I've mentioned elsewhere many of the institutions that looked at x.509 identity certificates in the early 90s had retrenched to relying-party-only certificates with just some sort of account number and public key. The problem of overloading a x.509 identity certificate with lots of privacy information turned out to be an enormous identity and liability problem. Part of the issue was creating a certificate at some time in the past and attempting to guess at what might be needed by various random relying-parties in the future ... led to overloading certificates with ever increasing privacy detail loaded. One of the content models was driver's license, name, address, date-of-birth. date-of-birth is an obvious identity theft vulnerability. The idea of randomly spraying your privacy detail all over the earth (attached to every electronic operation) turned out to be significant issues. Even just having your name attached to every electronic operation and sprayed all over the world represented a significant issue.
recent post in sci.crypt:
 RSA vs AES
and slightly related post (also from sci.crypt):
 Proposal for a new PKI model
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-09-07 10:16:02
@_author: Anne & Lynn Wheeler 
@_subject: Is cryptography where security took the wrong branch? 
a webhosting company presented some numbers at some standards meeting that they handled ten websites (all with monthly hits higher than the number one in the published monthly "hit" rankings) ... five were adult-type downloads and five were various kinds of (non-adult) software downloads. The adult-type charge backs were comparable to mainstream brick&mortar upscale retail outlets .... while the mainstream software downloads was on the order of fifty percent. It seemed that the people that download software are much more "fringe" than the types that download adult material (i believe they threw in some snide comments about the character f people that download software).
as I've mentioned before .... ipsec had been progressing very slowly in ietf for some time. in '94 ... you saw VPN being introduced at router working group (fall san jose meeting?) and introduction of SSL. both could be considered the domain of ipsec. Several of the router vendors didn't have processors capable of doing the crypto for VPN ... so you somewhat saw vaporware product announcements following the san jose meeting and VPN didn't make much progress until more router vendors had processors capable of handling the crypto load. the ipsec people seemed to evnetually come to terms with vpn by referring to it as lightweight ipsec (so the vpn people got to refer to ipsec as heavyweight ipsec). also in 94 you started to see SSL deployment .... basically a transport level ipsec feature implemented by applications (could be considered because ipsec was having such a hard time progressing).
minor past refs:
 Digital Signatures Spark Debate
 Proxy PKI. Was: IBM alternative to PKI?
 Microsoft worm affecting Automatic Teller Machines
 Use of SSL as a VPN
 Use of SSL as a VPN
 Why more than 1 hole in FW for IPSec
what i remember from the time was that SSL was thought as handling all of the shopping experience .... not just the credit card part but the feedback was that doing everything thru SSL cut the thruput capacity by about a factor of five (or you could handle five times as much traffic on the same hardware not using SSL).. The result was rather than using SSL for all commercial activity ... it was cut back to just handling the credit card part.
Basically, SSL was being used for hiding the credit card number while in transit (over the internet). However, almost all the exploits have been from harvesting credit card files .... even when it would be possible to "sniff" non-encrypted credit card transmission. That issue is somewhat that you can be very targeted and quickly get possibly hundred thousand credit card numbers .... or you could put up a listening post and hope that you run across several a day (or maybe even an hour).
SET came out after SSL ... and made extensive use of public key operations. I reported a public key operation performance profile for SET within a couple weeks after the original specification ... which several people working on SET claimed to be one hundred times too slow. It was probably just wishful thinking on their part since when they had some running prototype ... the profile was within a couple percent of measured. An issue was that SET was at least an order of magnitude more resource intensive than SSL ... and the only thing it did was protect credit card information in transit; basically it was only addressing the same (credit card) threat model as SSL .... but with significantly more overhead (having possibly hundred times more PKI didn't actually make things more secure).
lots of past comments about what SSL does for credit card transactions:
lots of recent comments in sci.crypt about eliminating certificates from SSL by collapsing the public key stuff into DNS:
 Proposal for a new PKI model (At least I hope it's new)
 Proposal for a new PKI model (At least I hope it's new)
 Proposal for a new PKI model (At least I hope it's new)
 Proposal for a new PKI model (At least I hope it's new)
 Proposal for a new PKI model (At least I hope it's new)
 Proposal for a new PKI model (At least I hope it's new)
 Proposal for a new PKI model (At least I hope it's new)
 Proposal for a new PKI model (At least I hope it's new)
 Proposal for a new PKI model (At least I hope it's new)
 Proposal for a new PKI model (At least I hope it's new)
 Proposal for a new PKI model (At least I hope it's new)
 Proposal for a new PKI model (At least I hope it's new)
 Proposal for a new PKI model (At least I hope it's new)
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-09-07 17:06:47
@_author: Anne & Lynn Wheeler 
@_subject: Is cryptography where security took the wrong branch? 
actually was supposedly no worse than the face-to-face world .... aka make the transit part secure ... so that the rest became the same as the physical world .... transactions go into big merchant file ... because there are several merchant related business processes that subsequently reference the transaction and number.
the problem was that their appear to be little or not fraud associated with threats against CC numbers in flight (with or w/o SSL), however the threat model was against the merchant credit card file and the numbers in the clear; it wasn't that the process was any different than the physical world, but the web merchants allowed the file to be access able from the network (which didn't exist in the physical world).
the requirement given the x9a10 working group was to preserve the integrity of the financial infrastructure for all electronic retail payments (debit, credit, stored-value, ach, internet, non-internet, point-of-sale, etc).  Turns out the internet threat profile wasn't so much data-in-flight .... but having the operation connected to the internet at all.  X9.59 addressed most of that ... which neither ssl or set did .... and did it with just a single digital signaturee. misc. x9.59
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-09-07 17:19:24
@_author: Anne & Lynn Wheeler 
@_subject: Is cryptography where security took the wrong branch? 
in the case of SSL domain name certificate .... for both domain name infrastructure and CA/PKI .... it is is a case of authenticating that the the web site you think you are talking to is really the web site you are talking to. The business issue is that the domain name registration and the CA/PKI are disjoint business operations and the domain name registration didn't provide for a really good authentication mechanism. As a result when getting a certificate request, the CA/PKI has to check with the domain name infrastructure .... map their information out to an external world identification, and then map the entity making the certificate request out to the same external world identification.
Out of all this, there is somewhat a request from the CA/PKI industry that a public key be registered as part of domain name registration (no certificate, just a public key registration). Then SSL domain name certificate requests coming into a CA/PKI can be digitally signed, the CA/PKI can retrieve the authoritative authentication public key (for the domain name ownership) from the domain name infrastructure and authenticate the request .... eliminating all the identification gorp (and also done w/o the use of certificates).
misc. additional recent musings:
  Proposal for a new PKI model (At least I hope it's new)
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-09-09 09:50:47
@_author: Anne & Lynn Wheeler 
@_subject: Is cryptography where security took the wrong branch? 
actually, physical credit card ... is a number of pair-wise communications .... card-holder to merchant terminal ... merchant terminal to merchant acquirer, merchant acquirer to interchange, interchange to issuer (credit card model is sometimes referred to as the 4-corner box .... with interchange trying to be transparent in the acquirer to issuer communication).
original electronic commerce with the netscape commerce server ... had SSL for the shopping experience ... with the credit card done at the end. Depending on the mall version of the commerce server had dedicated leased line directly to merchant acquirer. The wider userd commerce server had a SSL connection from the commerce server to the payment gateway (which then interfaced to the merchant acquirer) ... effectively emulating the real world (two pair-wise communcations).
In the real-world .... SSL use got cut-back to only handling the credit card part of the transaction ... and not being used for the rest of the shopping experience.
In any case, the SSL flows exactly emulate the physical world (effectively the front side of the virtual POS running at the merchant website ... and the backside of the virtual POS  to the acquirer) . ... modulo previous comment that the merchant transaction file in the physical world wasn't accessable via the internet (even tho it directly doesn't show up in the flows). The major exploits haven't been in the transaction flow part of the operation .... but in the business mechanics .... the major exploits have been harvesting the merchant transaction file. Neither SSL, nor SET have counter-measure against the major exploit (harvesting the merchant transaction file). Both SSL and SET hid the credit card number while in SET had all this other certificates and PKI gorp ... that significantly increased the crypto-related burden ( much more so than SSL).  In theory, SET had an opportunity for end-to-end authentication .... but even a single certificate represented on the order of two-orders of magnitude bloat increase for the payload in the standard payment network (aka a single PKI certificate tends to be one hundred times larger than the typical, base payment transaction). The SET burden was orders of magnitude worse than the SSL burden. This, in part is what gave way to the SET payment gateway .... all the PKI gorp would occur at the SET payment gateway ....then all SET related information would be thown away, a standard 8583/x9.15 transaction created .... with an additional flag indicating that digital signature authentication had been correctly performed ...and off it goes.
One of the VISA business people later gave a presentation at an ISO meeting about the number of 8583 transactions flowing thru the payment network with the SET-authenticated flag set ....but they could prove that no PKI technology was even remotely possible for the transaction .... aka a slight issue of end-to-end security was violated.  The important issue here was that the vision for SET ... was that if SET-authenticated transaction were involved ... the merchant eventually would be eligible for card-holder present discount rates ... rather than MOTO discount rates (aka having SET authentication was proposed as being as safe as a) card-holder present, b) card-preset, and c) track 1&2 readable). It was therefor in the interest of the merchant side of the business to tell the issuing side of the business that transactions were SET authenticated and the mrechant could get a much better discount rate).
The claim was that SET enormously increased the complexity, overhead, and payload processing ... while having little practical impact on the major Out of all this ... the X9A10 standards working group was giving the requirement to preserve the integrity of the financial infrastructure for all retail payments. The result is X9.59 which addresses all the major exploits at both POS as well as internet (and not just credit, but debit, stored-value, ACH, etc ... as well).
One of the things addressed by X9.59 was not the elimination of the ability to harvest the merchant transaction file ... but to make the account numbers in the merchant transaction file useless for fraud. slightly related discussion of the "security proportional to risk" and the vulnerability represented by the merchant transaction file
 merchant web server security
 net banking, is it safe?? ... security proportional to risk
 Net banking, is it safe???
misc. recent SET refs:
 invoicing with PKI
 Is cryptography where security took the wrong branch?
 Is cryptography where security took the wrong branch?
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-09-09 12:32:51
@_author: Anne & Lynn Wheeler 
@_subject: x9.59 
look at:
and it has a pointer to the standards document at ANSI. I think there may be some discussion at the oct. x9 meeting about progressing x9.59 to ISO.
but slightly simpler description is the mapping of x9.59 to iso8583 (basically the credit/debit network standards protocol) at:
the above lists the x9.59 elements and the iso 8583 elements .... and some mapping equivalence ... and how to carry the additional x9.59 values in an iso 8583 addenda field .... so you can achieve end-to-end authentication .... rather than truncated high integrity authentication at something like a boundary interface between the internet and the real payment infrastructure .... show how x9.59 can operate in all payment card processing environments (not just internet) and be able to provide x9.59 authentication on an end-to-end basis.
In this particular mapping between x9.59 and iso 8583 ... the original signed x9.59 object isn't carried end-to-end ... but there is a methodology defined for being able to reconstitute and verify the x9.59 object and the issuing financial institution.
The X9.59 standards document actual lists the ASN.1 encoding for the signing object (and therefor any reconstituted object)  ... although there has been investigation into a x9.59 "version number" for XML specification. One of the original issues for XML encoding specification was that there was no deterministic encoding rules for XML .... allowing for an object to be mangled in transmission and then reconstituted for authentication.  This is something that FSTC
did for FSML .... the deterministic encoding rules to cover the scenario where a signed electronic check object was mangled for transmission thru the ACH network ... and then had to be reconstituted for signature authentication. Since then W3C has incorporated FSML into the xml signature specification work. some overview:.
The problem wasn't whether XML or ASN.1 was better encoding method ... the issue was that given that the signed string of bits were mangled during transmission and how to be reconstituted, there had to be identical, deterministic encoding rules at both the signing end and the authentication end. This was very close to what was used in the NACHA AADS trials ... reference at:
Although not in available document ... there was work mapping x9.59 directly to ACH network (the message formats in ACH are different than the message formats in the payment card networks .... actually many of the payment card networks ... both interchange and various acquiring networks ... have frequently proprietary differences from the ISO 8583 .... although there is lots of recent work to achieve convergence). These are primary electronic electronic networks for payment transactions. There has also been some work mapping of x9.59 to wholesale networks, aka FEDWIRE, SWIFT, etc. The original X9.59 work was done in X9A which deals with retail standards. In the past there has been some differentiation between the retail and wholesale financial networks under the assumption that the values in the wholesale transactions were a lot larger and therefor required much higher level of security which, in turn, should cost significantly more. However, I think we managed to demonstrate in X9.59 a level of integrity that is as high as anything required for wholesale transactions at the same time being able to achieve a cost that was acceptable for retail transactions.
To be effective ... the standard deployment just about needs a hardware token that can be trusted to house the private key and perform the signature operation. My joke from 5-6 years ago was that I was going to take a $500 mil-spec part and cost reduce by it two orders of magnitude while at the same time increasing the security ... and cut the time & power requirements so that it could meet the transit gate elapsed time requirements in a ISO 14443 contactless configuration (the transit constraint model was basically the octopus sony/mitsubishi card used in HK transit system)..
I needled the chip module guys on this subject at a talk I gave two years ago at the intel developer's conference trusted platform track ... that it took them several years to iterate to nearly the same design point. The guy that headed it up ... claimed it was because I didn't have a committee of 200 people helping me .... a zip'ed copy of the presentation is listed a little lower in the AADS section of the web page (in front of the taxonomy/glossary section of the web page):
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-09-09 14:24:00
@_author: Anne & Lynn Wheeler 
@_subject: Is cryptography where security took the wrong branch? 
The "Database gaps make ID fraud easier, GAO says"
is somewhat analogous to the SSL domain name certificate problem ... a primary purpose for existing is to authenticate that the website you think you are talking to is the website you are talking to.
The problem is that the domain name infrastructure has a database of domain name owners .... but no real good infrastructure ... and the CA/PKI operations doing SSL domain name certifications are disjoint from the domain name infrastructure operations. As a result .... effectively the CA/PKI industry has to treat requests for SSL domain name certificates effectively as if it was a random person walking in from the street ... and then they have to try and match up such seemingly random requests ... with what little bit of information that they can extract from the domain name infrastructure (seeing if they can establish an identity in the real world based on the DNS database information ... and see if that identity then can be matched against the identity of the entity requesting the certificate).
Adding a public key to the domain name infrastructure database as part of the domain name registration process .... then eliminates the requirement of trying to establishing corresponding identities in the real world ... and it just reduces to a question of authentication.
Of course, the bottom line is if the domain name infrastructure has a real-time database of public keys for authentication purposes .... in part for use by the CA/PKI industry for authenticating SSL domain name certificate requests .... for use in authentication operations .... the use of the domain name infrastructure's authentication public keys don't have to just be restricted to authentication use by the CA/PKI industry. In fact, domain name infrastructure authentication public keys could be used to effectively for authentication operations that actually subsume the SSL domain name certificates authentication operations.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-09-09 14:47:10
@_author: Anne & Lynn Wheeler 
@_subject: Police smash UK's biggest credit card fraud ring 
here is example of downloading the database ... but not (necessarily) over the internet ... and not involving internet transactions.
not in general there is some amount of counterfeit cards going on from skimming. There are even reports in the UK press ... of counterfeit EMV  (chip) "yes cards" being produced.
the initial "847" in the following seems a little inconsistent 2m to 20m in fraud ... maybe it was 8 thousand or 80 thousand ... not 847
Police smash UK's biggest credit card fraud ring
By Drew Cullen
Posted: 08/09/2003 at 13:14 GMT
Three men are facing long jail sentences after pleading guilty, Friday (Sept. 5) to running the UK's biggest ever credit card fraud at Middlesex Guildhall Crown Court.
The trio stole details of 847 cards of Heathrow Express rail passengers who had paid for their journey by credit cards. They passed on the infor a gang of forgers who cloned 8,790 credit cards for use in the UK and on the Continent. The cloners were able to use only 10 per cent of the numbers, pocketing ?2m for the gang. Police estimate that the gang could have gained ?20m if all the credit card numbers had been used.
... snip ...
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-09-09 19:24:46
@_author: Anne & Lynn Wheeler 
@_subject: Is cryptography where security took the wrong branch? 
... while SET, 3d-secure, etc may have been designed for all sorts of reasons .... I guess my point was that w/o a adequately specified threat model .... for the primary vulnerabilities ... there turned out to be little effective difference between the use of SET and the use of SSL (regardless of what the designers may have original thot). Also technology adoption/uptake typically requires the transition to be less painful than the problem it is fixing. SSL was already in the market space ... so SET had to demonstrate that it was incrementally better (not effectively the "same as" for the major vulnerabilities) in order to justify its significantly more difficult and costly deployment.
The other issue that has been the bane of major PKI/certificate deployments (and I've repeatedly raised the issue) ... is that certificate-based operations typically have the key owner paying for the certificate .... while the major benefit accrues to the relying-party ... the the key/certificate owner. In the case of SET ... there was the consumer payng for their certificate ....  and the merchant not only receiving a better than MOTO-discount (making interchange transactions with the "SET" flag turned on ... somewhat suspecious) ... but also the possibility that the transaction would be treated as "authenticated" and potentially shifting the burden of proof in a dispute from the merchant to the consumer. There was the possibility that not only would the consumer be footing the bill (buying their own certificate) for the sole benefit of reducing what the merchant paid on the transaction .... but there was also speculation that it might also be used to make it more difficult for the consumer (there was sporadic mention of shifting the burden of proof from the merchant to the consumer in a dispute).
At least in the SSL domain name certificate, the merchant pays because of some belief that it will help attracted (internet) consumers/business.
In the SET/PKI scenario ... it was nearly impossible to figure out a value proposition for the consumer .... where the consumer is footing the (certificate) bill ... that turns out to be totally for the benefit of the merchant.  It wasn't so much that "cryptography took a wrong branch" ... but many of the PKI business models don't conform to any sane business operation .... with the entity (key-owner) footing the bill not getting any benefit ... and all the benefit going to the relying-party.
The other generalized PKI issue (again not just SET) ... is "any" contract tends to be between the CA?PKI and the consumer .... aka the entity in a contract that purchases something. Frequently is no contractual relationship between the relying-parties .... who effectively the sole reason that the certificates exist ... and the CA/PKI. As mentioned elsewhere, the GSA PKI has attempted to somewhat address this by having all relying-parties sign contracts with the GSA .... and all the CA/PKI certificate issuing entities have a contract with the GSA where they are effectively issuing certificates on behalf of the GSA. Those set of contracts then preovide the legal foundation for some generic reason for relying-parties to do anything with certificates (since the relying-parties and the CA/PKI agency, aka GSA ... have contractual relationship and therefor a legal reason to deal with certificates). The slightly different SET scenario ... the associations just told the merchants that they would be charged less per transaction ... aka instead of MOTO (mail order, telephone order) discount, they could get something closer to card present Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-09-10 08:14:14
@_author: Anne & Lynn Wheeler 
@_subject: Is cryptography where security took the wrong branch? 
Since DNS is a online positive list .... you change the database ... and voila it is updated.
This is the scenario for credit cards going from pre-70s technology with plastic cards and the monthly revokation booklet mailed out to all merchants. The credit card industry transitioned to online infrastructure where it transactions are denied by updating the online database. It eliminates the revokation process, since there aren't an unknown number of copies of static, stale credentials/certificates floating around the world potentially being presented to an unknown variety of relying parties.
DNS caching is the closest equivalent of the certificate paradigm of static, stale copies floating around the world. The two slight differences are that cached stale, static entries tend to have very short lifetimes ... they come into creation by activities by the relying-party (not the entity being authenticated) and tend to have very short lifetimes .... of a few hours to at most a day. However, relying-parties have the choice of going directly to the root and obtaining the current copy .... a function somewhat filled in the PKI world by OCSP .... although OCSP is just a check about whether the current, static, stale copy in a relying-party's possession is current ... not what the current entry is..
 From information theory standpoint, stale, static certificates are logically a form of long-lived, distributed, replicated, r/o, cache entries.  Cache entry semantics have been studied in some detail in areas like distributed file systems and multiprocessor consistent shared memory caches, etc.  With short-lived r/o, distributed cache entires (like DNS) ... there is a trade-off involving 1) entry life-time, 2) frequency of change, 3) impact of dealing with stale entry. We ran into a problem with doing consistent database updates over NFS (network filesystem) because while NFS advertises itself as item potent, most client implementations have this 8k cache that can be stale.
Given high value &/or low trust ... relying parties still have option of directly contacting root authority. And as outline, the root authority is also the root authority for the CA/PKIs. If you attack the root trust authority with false information .... then all subsequent trust operations flowing from that false information is suspect. Domain name system still has some exploits against the root database resulting in false information .... but since that is the root for both DNS as well as CA/PKIs generating SSL domain name certificates .... it is a common failure point for both infrastructures. It needs to be fixed, in order to improve trust on either the DNS side or the CA/PKI side (doesn't matter how thick you make the vault door .... if somebody forgot to complete the back wall on the vault).
random, unrelated refs to past life working on processor cache design, distributed filesystems, and distributed databases
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-09-10 08:38:02
@_author: Anne & Lynn Wheeler 
@_subject: Is cryptography where security took the wrong branch? 
fingers typing w/o brain syncronized ... it should have been idempotent not item potent.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-09-10 12:56:05
@_author: Anne & Lynn Wheeler 
@_subject: Is cryptography where security took the wrong branch? 
a normal cache-based system attempts to make everything appear as if it is online and dynamic .... with the characteristics of information caching as close as possibly transparent to the relying-parties.
one might claim that PKIs have tried to turn long-lived certificate-based "cache-entries" into a cult (aka from a information theory standpoint, certificates are a form of free-standing, somewhat self-describing, stale, static, long-lived cache entries) .... in part to create an independent revenue flow based on these cult objects. standard cache infrastructures usually attempt to go out of their way to try and make caching operation transparent to relying-parties (and can dynamically change/eliminate caching details to meet specific business requirement).
domain name infrastructure needs to support 1) trusted information distribution and may implement 2) cached entries. DNS has never been restricted to just trusted information distribution of IP-addresses.
CA/PKI SSL domain name certificates were deployed, in part because of integrity concerns about the domain name infrastructure. However, the "trust root" for CA/PKI SSL domain name certificates is still the domain name infrastructure (as to the authoritative owner of a domain name).
Turning DNS into a PKI-like thing happens only in the sense that CA/PKIs have only been a trusted distribution of public keys ... while DNS has always been a (somewhat) trusted distribution of any information (that happens to be registered with them). Adding public keys to DNS distribution is only turning it into a PKI-like thing from the standpoint that DNS hasn't in the past ben used as a trusted distribution for public key specific information (and the issue about the level of trust you can actually have in DNS).
My assertion is 1) DNS integrity issues have to be addressed as part of generalized DNS trust issues .... regardless of any use for trusted distribution of information that may include public keys. 2) because domain name infrastructure is the root authority for CA/PKI SSL domain name certificates, there is a suggestion that public keys be registered as part of domain name registration (to fix trust issues in domain infrastructure on behalf of the CA/PKI industry). Being able to trust DNS ... and having registered public keys .... means that existing DNS information distribution operation can turn itno trusted distribution of public keys (aka existing DNS infrastructure supports distribution of any information that happens to be registered).
some past threads about transition steps for DNS trust .... which could include having cache entries that instead of being naked public keys could be digitally signed cache entries (sharing some characteristics in common to stale, static, long-lived, free-standing digitally signed certificate  Time to ID Identity-Theft Solutions
 How effective is open source crypto? (bad form)
 How effective is open source crypto? (bad form)
 Payments as an answer to spam  SSL certs & baby steps
 SSL certs & baby steps (addenda)
 SSL certs & baby steps
 Invisible Ink, E-signatures slow to broadly catch on (addenda)
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-09-23 13:45:42
@_author: Anne & Lynn Wheeler 
@_subject: End of the line for Ireland's dotcom star 
so ignore for the moment the little indiscretion
 Proposal for a new PKI model (At least I hope it's new)
 Proposal for a new PKI model (At least I hope it's new)
and the part of turning a simple authentication problem into a significantly harder and error prone (along with exploits and vulnerabilities ... not to say expensive) problem:
 Is cryptography where security took the wrong branch?
 Is cryptography where security took the wrong branch?
 Resolving an identifier into a there has been the some past discussions of what happens to long term CA private key management over an extended period of time, possibly involving several corporate identities. Checking latest release browsers ... I find two CA certificates for GTE cybertrust ... one issued in 1996 and good for 10 years and another issued in 1998 and good for 20 years.
so lets say as part of some audit ... is it still possible to show that there has been long term, continuous, non-stop, highest security custodial care of the GTE cybertrust CA private keys. If there hasn't ... would anybody even know? ... and is there any institutional memory as to who might be responsible for issuing a revokation for the keys? or responsible for notifying anybody that the certificates no longer need be included in future browsers?
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-09-29 08:45:38
@_author: Anne & Lynn Wheeler 
@_subject: New authentication protocol, was Re: Tinc's response to 
... snip ...
1) TLS both authenticates the server and establishes an encrypted
session in the server part of the transaction. 2) The original SSL somewhat assumed that the business requirements are
different for server authentication (and encrypted session) vis-a-vis
client authentication. The original SSL requirement a) was to give some
level of confidence to the client that "the server that the client thot
it was talking to" was actually "the server it was talking to" and b)
provide an encrypted session. There wasn't actually a threat model
requiring proving who you are ... just a threat model that the server
prove that it was who the client supposedly thot it was. 3) SSL was being deployed with a requirement for encrypted session in an
environment where client authentication:
  a) might not be required
  b) was not required as part of the transport protocol
  c) was used to webize/tunnel an existing legacy application
      where the client might use userid/password or other       authentication previously established
  d) wouldn't be public key based because the clients were not
     expected to have public/private key pairs and certificates
Some web'ized legacy applications were adopted from a private network
environment ... where the client as part of making the connection "knew"
that it was talking to the correct server. The minimum required to move
that to the wide-open web ... was to provide server authentication and
encrypted session ...  and then tunnel the legacy app thru the encrypted
session. The business requirement and threat model wasn't to invent a
brand new environment from scratch ... but to adapt existing business
operations to the wide-open web.
"Mutual" authentication was somewhat an add-on of client authentication
to the base infrastructure. In fact, I think that we were the first to
specify and required the first implementation as part of the back-end of
this thing that has come to be called electronic commerce.
random electronic commerce refs:
The trivial e-commerce is that the merchant server didn't really care
who the client was ... just that the client bought something and the
merchant was going to get paid. The merchant needed to provide some
assurance that the credit card transaction being passed thru to the
financial infrastructure was protected. The merchant relied on the
financial infrastructure authenticating the credit card transaction ...
and, in fact, any mutual authentication that might be done as part of
the SSL transaction had no impact on the credit card transaction. To some extent, both VPN and SSL come into existence about the same time
to satisfy specific business requirement(s) (and in part because it was
taking so long to see any progress with ipsec).

@_date: 2004-04-08 23:24:40
@_author: Anne & Lynn Wheeler 
@_subject: eCompute ECC2-109 Project has PROBABLE solution 
There has been a PROBABLE solution generated as of 1425 hrs GMT, April
8, 2004.
Until Certicom has confirmed this, it will be treated as a PROBABLE
solution and the DP collection will continue.
The two people who have submitted the DP values have been emailed. Until Certicom formally accepts this, please do not stop your clients.
Remember, this is only a PROBABLE solution and we do not done yet!
The ECC2-109 Team

@_date: 2004-04-14 09:34:58
@_author: Anne & Lynn Wheeler 
@_subject: Definitions of "Security"? 
there was a discussion on PAIN taxonomy for security earlier in the year ... misc. references
 Non-repudiation (was RE: The PAIN  Non-repudiation (was RE: The PAIN

@_date: 2004-04-16 10:15:20
@_author: Anne & Lynn Wheeler 
@_subject: eCompute ECC2-109 Project has PROBABLE solution (now 
it is now official
eCompute ECC2-109 Project
We have received unofficial  OFFICIAL word that the solution is valid!
As a result, the DP server has been closed and we?re working on finalizing the final stats. No further DP values will be accepted and the DP server will remain closed.
A little later today we?ll be posting complete information regarding the solution, some project stats, and other final information. Until then
We wish to thank everyone who has contributed to this project. With your help, it was a success. Without your help, it never could have happened!
The solution was achieved through a collision of points provided by:
           glenon from Ars Technica Team Vodka Martini
         Maximum_Confusion from TechIMO
The following was written by Chris Monico to describe the solution achieved.
... snip ..
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2004-04-29 15:18:18
@_author: Anne & Lynn Wheeler 
@_subject: RFC 3766  Determining Strengths For Public Keys Used For 
also summary entry at
clicking on ".txt=nnn" field in the summary retrieves the actual RFC
         BCP 86
         RFC 3766
         Title:      Determining Strengths For Public Keys Used
                     For Exchanging Symmetric Keys
         Author(s):  H. Orman, P. Hoffman
         Status:     Best Current Practice
         Date:       April 2004
         Mailbox:    hilarie at purplestreak.com, paul.hoffman at vpnc.org
         Pages:      23
         Characters: 55939
         Updates/Obsoletes/SeeAlso:    None
         I-D Tag:    draft-orman-public-key-lengths-08.txt
         URL:        ftp://ftp.rfc-editor.org/in-notes/rfc3766.txt
Implementors of systems that use public key cryptography to exchange
symmetric keys need to make the public keys resistant to some
predetermined level of attack.  That level of attack resistance is the
strength of the system, and the symmetric keys that are exchanged must
be at least as strong as the system strength requirements.  The three
quantities, system strength, symmetric key strength, and public key
strength, must be consistently matched for any network protocol usage.
While it is fairly easy to express the system strength requirements in
terms of a symmetric key length and to choose a cipher that has a key
length equal to or exceeding that requirement, it is harder to choose
a public key that has a cryptographic strength meeting a symmetric key
strength requirement.  This document explains how to determine the
length of an asymmetric key as a function of a symmetric key strength
requirement.  Some rules of thumb for estimating equivalent resistance
to large-scale attacks on various algorithms are given.  The document
also addresses how changing the sizes of the underlying large integers
(moduli, group sizes, exponents, and so on) changes the time to use
the algorithms for key exchange.
Anne & Lynn Wheeler

@_date: 2004-08-16 13:54:45
@_author: Anne & Lynn Wheeler 
@_subject: Any TLS server key compromises? 
One of the issues is some prior implication that at least some of the SSL/TLS port knocking was helping identify sites that might be indicative of something to protect. Lets say somebody finds some really juicy financial targets using the technique.
So the server is penetrated and the attacker is presented with two files .... one with the private key .... and one with a million financial transactions ... which are would they be more likely to take?
I would assert that the million financial transactions file .... yield possibly couple hundred thousand accounts numbers that could then be used directly in fraudulent transactions. The SSL/TLS private key just says that you have to put in some evesdropper in on the server's SSL/TLS sessions, decrypt the traffic and decide what it means. While it may be of some academic interest ... it would seem that letting the server keep on doing all that work for you ... and just harvesting the results ..... represents a lot bigger return for effort.
Part of the issue is that the threat model for server file exploit is frequently the same for the real data "at rest" and the private key file (which is just protecting the real data while in transit) ... the actual, real data can represent a lot higher immediate fraud potential. So lets say the attacker does take
both files for the fun of it .... but likely won't get around to any SSL/TLS evesdropping attacks until exhausting all the other financial fraud possibilities (from already having a huge number of account numbers). Even if they eventually exhaust any current crop of fraudulently harvested account numbers ...  they will likely try the same attack on another server ... before they possibly decide that SSL/TSL evesdropping attacks are worth the effort.
It is possible, the SSL/TSL private key file might be more attractive target in non-financial sector circles (evesdropping for the sake of evesdropping .... possibly for other than direct financial incentive).
You would probably start hearing about the client keylogger exploits including any client private key file .... if client keys started being used for any significant purposes .... aka current client keylogger exploits are able to authenticate directly just from the pin/password key capture. any change to private key operations would mean that the client keylogger attacks would also need the private key file (with the pin/password capture then being used to decrypt the private key file in order to use the private key for authentication).
Anne & Lynn Wheeler

@_date: 2004-08-16 16:31:58
@_author: Anne & Lynn Wheeler 
@_subject: RPOW - Reusable Proofs of Work 
I got hit with exploits on 4758 cards ... in thread in sci.crypt
Anne & Lynn Wheeler

@_date: 2004-08-16 16:50:13
@_author: Anne & Lynn Wheeler 
@_subject: RPOW - Reusable Proofs of Work 
the issue in the "yes card" exploit is that you migrate the financial business rules out into hardware tokens (of any kind) and then do peer-to-peer operations between tokens.
the threat model is you attack the belief in a valid hardware token ... once you have that you have the mechanism for creating counterfeit tokens that can convince other tokens that they are valid. These counterfeit tokens don't tell the truth ... they are programmed to say whatever will convince other tokens that can be trusted.
and as per previous post ... i got hit in a sci.crypt thread with the claim that even 4758 can be succesfully attacked.
misc. posts discussing token attacks that 1) result in being able to fabricate counterfeits 2) which are acceptable in offline, peer-to-peer  WYTM?
 A combined EMV and ID card
 Single Identity. Was: PKI International Consortium
 Article on passwords in Wired News
 Security of Oyster Cards
 command line switches [Re: [REALLY OT!] Overuse of symbolic constants]
 US fiscal policy (Was: Bob Bemer, Computer Pioneer,Father of ASCII,Invento
 US fiscal policy (Was: Bob Bemer, Computer Pioneer,Father of ASCII,Invento
 US fiscal policy (Was: Bob Bemer, Computer Pioneer,Father of ASCII,Invento
Anne & Lynn Wheeler

@_date: 2004-08-20 21:46:13
@_author: Anne & Lynn Wheeler 
@_subject: RFCs that reference MD5 
I've made a number of modifications to my rfc index.
if you go to the main url
you'll see a new note about list of RFCs that have some MD5 references in
thier text (i.e. grep on "md5" with some number of eliminations)
the display is my standard summary format; if you click on the ".txt=nnnn"
field it retrieves the actual RFC
removed from the list are Obsoleted and/or Historic RFCs.
I've also scanned (actually some gawk) all the RFCs attempting to recognize
any References section and pull out list of referenced RFC numbers.
That information is now added to the RFC summary listings ... in manner
similar to the obsoletes/obsoletedby and updated/updatedby fields ... i.e.
RFCs that are referenced by other RFCs now show the list of "Ref'ed By").
the summary listing for 1321 now looks like:
1321 I
     The MD5 Message-Digest Algorithm, Rivest R., 1992/04/16 (21pp)
     (.txt=35222) (Ref'ed By 1352, 1446, 1479, 1544, 1751, 1828, 1910,
     1994, 2264, 2274, 2409, 2938, 3012, 3110, 3174, 3208, 3224, 3230,
     3275, 3414, 3631, 3652, 3797)
note that the RFCs mentioned md5 are more than the ones that include
RFC 1321 in their references section (and/or I wasn't able to
correctly recognize some references sections).
Anne & Lynn Wheeler

@_date: 2004-08-25 16:13:08
@_author: Anne & Lynn Wheeler 
@_subject: RFC 3833 Threat analysis of the domain name system (DNS) 
as always ... can go to
and either scroll down the summary page to the 3833 summary and then retrieve the actual RFC by clicking on the ".txt=nnnn" field.
In this case it is also possible to click on "Term (term->RFC in the "RFC's listed by" section ... and then click on "DNSSEC" in the acronym fastpath section at the top. That brings up the DNSSEC RFCs. ... where DNSSEC (and/or domain name security) appeared somewhere in the title or as a side note, I've just done about everything possible that I can do with scanning actual RFCs for references. I did a pass ... where I created a list of all RFCs ... where the scan didn't produce RFC numbers from a reference section ... and then scanned those RFCs for anything that looked like there might be a RFC number anywhere in the body. Then I manually examined that list of RFCs for how they formated/called the references section. somewhat more detailed discussion of the references & md5 stuff:
         RFC 3833
         Title:      Threat Analysis of the Domain Name System (DNS)
         Author(s):  D. Atkins, R. Austein
         Status:     Informational
         Date:       August 2004
         Mailbox:    derek at ihtfp.com, sra at isc.org
         Pages:      16
         Characters: 39303
         Updates/Obsoletes/SeeAlso:    None
         I-D Tag:    draft-ietf-dnsext-dns-threats-07.txt
         URL:        ftp://ftp.rfc-editor.org/in-notes/rfc3833.txt
Although the DNS Security Extensions (DNSSEC) have been under
development for most of the last decade, the IETF has never written
down the specific set of threats against which DNSSEC is designed to
protect.  Among other drawbacks, this cart-before-the-horse situation
has made it difficult to determine whether DNSSEC meets its design
goals, since its design goals are not well specified.  This note
attempts to document some of the known threats to the DNS, and, in
doing so, attempts to measure to what extent (if any) DNSSEC is a
useful tool in defending against these threats.
Anne & Lynn Wheeler

@_date: 2004-12-01 11:47:37
@_author: Anne & Lynn Wheeler 
@_subject: SSL/TLS passive sniffing 
the other attack is on the certification authorities business process ... crook gets the issuing authority to give them a certificate with all the same information ... but their public key; the key-owner may have little control over the long term business process standards of the issuing certification authority
This is one of the attacks on SSL domain name server certificates.  Supposedly the purpose for SSL domain name server certificates was some perceived vulnerabilities in the domain name infrastructure. Note, however, the authoritative agency(s) for domain name ownership is the domain name infrastructure. The current process has a SSL domain name server certificate applicant supplying some amount of identification information. The certification authority then has the error-prone and expensive job of contacting the domain name infrastructure (authoritative agency for domain name ownership) and comparing the supplied identification information (provided with the certificate application) with what is on file at the domain name infrastructure.
The attack isn't on the process that was used for the valid applicant ... the issue is that at any time in the future, can an attacker compromise that process .... using any recognized, valid, certification The side note is that the certification authority industry has somewhat pushed a business process where the domain name supplies their public key to the domain name infrastructure at the time they register the domain name. Then when somebody applies for a SSL domain name server certificate, they digitally sign the request. The certification authority then just has to retrieve the on-file public key from the domain name infrastructure and validate the digital signature. This turns an expensive and error-prone identification process into a much more reliable and less expensive authentication process.
The catch22 of course, is that if the certification authorities can retrieve public keys from the domain name infrastructure for authentication ... then just about anybody in the world could do the same thing .... significantly reducing the need for any SSL domain name server certificates.
misc past postings:
Anne & Lynn Wheeler

@_date: 2004-12-05 16:07:50
@_author: Anne & Lynn Wheeler 
@_subject: SSL/TLS passive sniffing 
i just had went off on possibly similar rant in comp.security.ssh where a question was posed about "password
or certficate"

@_date: 2004-01-05 08:34:12
@_author: Anne & Lynn Wheeler 
@_subject: Difference between TCPA-Hardware and a smart card (was: 
The original issue involves three factor authentication
* something you have
* something you know
* something you are
A public key can be representative of  hardware token ... say a token where the private key is generated on the token and is designed to never leave the token. A digital signature that can be verified by the corresponding public key can be used to infer possession of the hardware token (something you have). Furthermore, a hardware token can be designed to only work in a specific way when the appropriate pin/password (something you know) or biometric (something you are) have been entered into the token. The entity receiving the digital signature doesn't need a copy of the pin/password or biometric (making it a shared-secret) but infers by the operation of the hardware token that there has been something you know &/or something you are authentication to have happened.
An institution can enroll the person in possession of the token using whatever processes they feel necessary (say anonymous for ISPs up to "know your customer" identity as required by various legislation for financial The issue is that can the validating of the entity in possession of the token be a separate business process issue from validating the integrity of the hardware token. The idea is that the integrity of the hardware token can be treated as a totally separate business process from the process of validating the entity being enrolled (an entity that happens to possess the hardware token).
Treating them as totally separate business process doesn't preclude collapsing the enrolling of the entity and enrolling the hardware token into a single process. However, not treating them as separate business process will pretty much preclude ever being able to treat them as separate So the question is as part of the enrolling process, can the integrity of the hardware token be treated as a totally separate business issue from the characteristics of the entity in possession of the hardware token, say like the advertisements for the service that allows being able to research the history of a used car. Most institutions already have all sorts of business processes involved with enrolling the characteristics of an entity. What would be the incremental requirement for adding being able to enroll (& trust) the integrity of a consumer presented hardware token.
So, i'm a little bit biased, I claimed that I ruthlessly discarded all feature and function from AADS chip strawman that wasn't needed for trusted complexity can contribute to insecurity ... KISS and focus can contribute to security.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2004-01-05 11:19:06
@_author: lynn@garlic.com 
@_subject: Difference between TCPA-Hardware and a smart card (was: 
aka ... in some sense the reply
is also attempting to keep separate the business processes of identification and authentication. Will it continue to be allowed to have authentication events (i can prove that i'm authorized to do something) w/o also always mandating that whenever there is an authentication operation will proof of identity always also be required?
today, I supposedly can open an ISP account, provide proof of payment and supply a password for that account (w/o also having to provide a gene pattern for identification). Would it ever be possible to simply substitute a digital signature and public key in lieu of a password when opening an account (where that digital signature may have been performed by a hardware will it continue to be possible in the future to have separation between authentication and identification business processes ... or will at some time, things change and all authentication events also always require Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2004-01-06 07:45:58
@_author: Anne & Lynn Wheeler 
@_subject: Difference between TCPA-Hardware and a smart card (was: 
a lot of current identity theft is evesdropping &/or otherwise harvesting shared secrets and then doing replay attacks. part of this is that the prevalence of shared secrets paradigm creates significant human factors problems with being able to memorize all the possibly scores of shared secrets that are used as "something you know" authentication. the obvious is various kinds of skimming of real transactions and the harvesting of merchant payment transactions file to extract the shared secrets sufficient to perform fraudulent financial transactions. two aspects of this: 1) the transactions are based on static shared-secrets that are subject ... effectively to replaying the shared secret and 2) a security guideline about requiring unique shared-secret for every security domain ... so that an authorized entity in one security domain can't extract your shared secret and perform fraudulent transactions in another security domain (as simple as one employee at one merchant getting your shared secret and performing fraudulent transaction at another merchant). slightly related is discussion regarding posting about security proportional to risk:
somewhat related issue is because of the human factor memory issue, a common authentication shared secret (something you know) is "mothers maiden name". The upside is that most people will tend to remember it. The downside is 1) it really isn't all that secret and 2) using the same shared-secret in multiple different security domains violates the security principle requiring a unique (and preferably unpredictable) shared secret in every security domain.
So, my assertion is that a significant amount of fraudulent activity that is currently labeled identity theft is really poorly implemented shared-secret, something you know authentication. Furthermore, various aspects of existing shared-secret implementations lends itself to electronic collection and/or harvesting of large batches of shared-secrets that, then in turn can be used in fraudulent transactions (significant fraud return-on-investment).
So one solution is significantly changing all such existing authentication transactions and turning them into identification transactions .... where the cost of faking the identification is significantly higher than the value of the fraudulent transactions.
Another solution is significantly changing the existing shared-secret authentication transactions and turning them into non-shared-secret authentication transactions ... where the cost of faking the authentication is significantly higher than the value of the fraudulent transactions.
The previous paradigm description has the use of asymmetric cryptography and digital signature technology to infer "something you have" authentication because enrollment establishes 1) private key is contained in a specific hardware token and 2) characteristics can be established about the hardware token where it has generated a random key pair in the token and the token never voluntarily gives up the private key.
Enrollment may also establish that such a hardware token also works in a specific way when a unique pin/password and/or biometric has been passed to the token.  Later when transactions arrive that are believe to have been digitally signed by such a hardware token, it may also be valid to infer that "something you know" and/or "something you are" authentication has also occurred (w/o the pin/password and/or the biometric needing to be passed to the authenticating institution and becoming a shared-secret).
It will probably always be possible to subvert various kinds of identification and/or authentication technologies. Two issues are:
1) can such subversion be made more costly than any resulting risk/fraud
2) can solution be authentication oriented as opposed to identification The second is possibly a bias towards not wanting to proliferate identity oriented events into each and every transaction that occurs in the world (when authentication may be sufficient).
With regard to the first point, the claim has been that X9.59 changes the existing retail electronic transactions from shared-secret based to non-shared-secret based ... and therefor eliminates the existing vulnerability of harvesting merchant transaction files as a threat (discussed in the security proportional to risk reference).
Furthermore, as implied in the security proportional to risk reference, it may never be possible to eliminate the transaction file harvesting, what  x9.59 did was eliminate the threat of fraud that results when such harvesting takes place.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2004-01-07 10:28:34
@_author: Anne & Lynn Wheeler 
@_subject: [Fwd: Re: Non-repudiation (was RE: The PAIN mnemonic)] 
lets say they are somewhat different threat models (but may have some partial overlap).
it would be possible to give a dozen people the same passprhase and have some degree of confidence that only the permitted entities entitled to do something were authenticated. however, if one of them claimed that they didn't do some specific thing ... there would be difficult to differentiate between the different entities as to which entity had been authenticated at any specific time. some of the best practices security guidelines for authentication (like not sharing passwords) have more to do with non-repudiation ... than straight authentication.
key-escrow can be considered mandatory for encryption keys under the non-single-point-of-failure and availability best practices. At the same time there may be mandatory requirements for NOT having key-escrow for authentication keys under non-repudiation best practices (even when the cryptographic technology is identical ... the issue of key-escrow policy is exactly opposite depending on whether the business use is encryption of a straight-forward authentication issue might be whether a particular message originated from a specific entity. That would not necessarily include the sense that the entity agreed with the terms and conditions described in the body of the message (say a financial transaction). This is somewhat akin to various EULA agreements that have people clicking on various buttons .... which is not an issue of authentication but of agreement; aka *repudiation* can include things that are outside the scope of authentication (not whether the message originated from me ... but do i fully agree with what is included in the body of the message).  neither identification nor authentication by itself can necessarily include the concept of agreement. repudiation can include a number of items outside the sense of identification and authentication (like aggreement).
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2004-01-16 11:41:00
@_author: Anne & Lynn Wheeler 
@_subject: (federal) PKI spending hits $1b 
(federal) PKI spending hits $1b
GAO Faults 'inconsistent' online security programs ($1b on PKIs)
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2004-07-01 20:40:39
@_author: Anne & Lynn Wheeler 
@_subject: authentication and authorization (was: Question on the 
there are two sides of this .... some amount of crime statistics call it ID-theft .... which plausibly could be either identity or identification ... but in general involves situation where criminal is impersonating you to one degree or another to perform some fraudulent action.
there has been some attempt to distinguish impersonation events between fraudulently extracting money from existing accounts and fraudulently creating new accounts in your name.
practically, objecting to the label id-theft may be like objecting to the label suicide bomber.
in general, the problem is using any kind of static data for authentication. it applies to name, birthdate, mother's maiden name, pins, passwords, account numbers .... any kind of static data. it worked for a long time ... but it was based on assumption that it had characteristics of 1) shared-secret and 2) used uniquely, different static data in different security domains.
the growth of electronic environments has drastically affected this in lots of ways (invalidating the core assumptions that was behind the use of such static data for authentication, it wasn't that static data didn't work ... but it worked well only as long as the underlying assumptions were valid):
1) drastic increase in number of different electronic environments requiring unique shared secrets ..... basic human factors making it impossible to process unique shared secret for every possible (scores of unique) environment
2) drastic increase in number of different electronic environments ... drastically increasing the number of places that shared secrets are being used ... which increasing the places that shared secrets can be harvested (for criminal purposes)
3) drastic increase in electronic environments that contain information about individuals ... drastically increasing the number of places that personal information can be harvested (of the type that is likely to be used in shared-secret, static authentication information) for criminal minor reference to the account based scenario .... security proportional to and then there is the whole thing about frequent confusion of identification and authentication:
 (my) misc. additional comments on X9.59 issues.
 3D Secure Vulnerabilities? Photo ID's and Payment Infrastructure
 A PKI Question: PKCS11-> PKCS12
 The real problem that https has conspicuously failed to fix
 certificates & the alternative view
 A combined EMV and ID card
 PKI International Consortium
 Confusing Authentication and  Account Numbers. Was: Confusing Authentication and Identiification? (addenda)
 Account Numbers. Was: Confusing Authentication and Identiification? (addenda)
 The Tao Of Backup: End of postings
Anne & Lynn Wheeler

@_date: 2004-07-02 07:57:02
@_author: Anne & Lynn Wheeler 
@_subject: authentication and authorization ... addenda 
one of the industry groups brought my wife and me in to help work on the cal. and then the federal e-sign legislation. there is this intersection between privacy, e-sign, and fraud. in any case, one of the things that they had done was a study of the driving factors for legislative and regulatory privacy activity ... the two primary driving factors were
(institutional) denial of service (to individuals)
the claim could be made that the id-theft issue is almost totally related to the use of various kinds of static data for authentication and that given the current pervasive electronic online world .... that it is effectively impossible to continue operating with static data paradigm w/o having to accept large amount of exploits and fraud.
the privacy legislative and regulatory mandates can try and establish rules for "protecting" information ... but keeping static data authentication information "private" is a loosing battle. in part, because traditionally 90% of the exploits have involved insiders .... although recent study now only claims that at least 77% of the incidents involve insiders. All the internet histeria about outsiders ... in part just obfuscates and identifying the real sources of the problem.
one assertion is that the whole environment collapses because large scale, wide-spread static data based authentication paradigm has too many vulnerabilities ... somewhat as per the previous reference to security proportional to risk
if nothing else ... there isn't sufficient finances to fund the security necessary to protect all the authentication static data. also, this isn't taking into account the wide-spread education necessary for countermeasure to the social engineering and phishing exploits.
some sort of hardware token with non-static data (as "something you have" authentication) starts to address the situation. the issue isn't that the hardware token can't be stolen .... but it is difficult to steal electronically a million at a time (large scale harvesting with little investment and risk is one of the things that makes phshing so attractive ... the potential fraud ROI is enormous).
If the hardware token implements a non-static data authentication paradigm and never exposes its internal secrets (say like a private key of public/private key pair) ... then no amount of phishing can convince somebody to divulge something that they don't know. social engineering might still be able to convince people to mail their authentication token to some far off country (that requires quite a bit more gullable populace .... comparable to convincing everybody that they have to mail off their driver's license to some far off location).
changing the paradigm from static data authentication to non-static data authentication would do more for reducing id-theft vulnerabilities than all the privacy and security regulations. one of the side issues .... is sometimes if all you have is a data security classification & protection hammer ... then the solution to all problems is protecting the data. The "security proportional to risk" scenario is it is impossible to protect the pervasive use of authentication static data ... the paradigm has to be changed.
legislative and regulatory privacy mandates would still be necessary for the other privacy driving factor .... (institutional) denial of service (to there will still be various kinds of impersonation fraud .... if you can't perform fraudulent financial transactions by stealing account numbers .... criminals might still open accounts in victims names. However, an assertion is if the points of attack are reduced by several orders of magnitude ... aka from all transactions (because of stolen account numbers) to stolen hardware tokens and opening accounts ... then it is possible to better concentrate the security budget on the drastically reduced attack points and threat models.
i mentioned before that i've been one of the x9.99 (privacy impact assessment) standard co-authors for the last year or so .... and it is now out for public comment (can be bought from the ansi e-store) ... and there is work item proposal to move it forward to ISO.  For part of the background work, i started a merged privacy taxonomy and glossary .... similar to the merged taxonomy & glossary work that i've done in other areas:
FTC has some resources in this area:
I gave a talk earlier this week at treasury conference in DC on privacy and id-theft ... and there were some number of questions about resources for individuals that are victims of id-theft

@_date: 2004-07-04 14:25:23
@_author: Anne & Lynn Wheeler 
@_subject: Use cash machines as little as possible 
ONE of Britain's biggest banks is asking customers to use cash
machines as little as possible to help combat soaring card fraud.
... snip ..
Anne & Lynn Wheeler

@_date: 2004-07-07 10:25:02
@_author: Anne & Lynn Wheeler 
@_subject: authentication and authorization 
there is actually a whole series of issues.
the identity x.509 certificates from early 90s were targeted at stuff that
appeared to be totally unrelated to existing business processes and given the scenario that existing business relationships and permissions have
been established .... there is requirement to asserting access to those (some means of asserting some identification associated with the permissions
and some means of authentication or substantiating the rights to the identity x.509 certificates have been totally unrelated to such a business
environment ... although attempts have been made to contort them into
that use. the original premise was that the identity x.509 certificates
could be used by parties that previously had no direct knowledge of each
other and could make use of the x.509 certificates w/o needing any recourse
to any additional information. one problem was a random name from
some place in the world had no context or meaning to some other random
entity some place in the world.
putting a person's instantly  changing available balance in the certificate
might do. however this had (at least) two problems 1) it could be considered
privileged information that deemed not advisable in public certificates
with copies all over the planet and 2) with possibly thousands of each
such certificate cached all around the world .... there was some issue
with instantaneously and dynamically updating all copies.
so in the mid-90s there was some retrenchment to relying-party-only
certificates ... which basically only contained an account number and
the public key. the transaction always went to where the permissions
and other important information was available. However it was trivially
possible to show that in such situations, the certificates are redundant
and superfluous.
The majority of the business infrastructures in the world don't need
free floating and complete personal information contained in a certificate
about random and totally unknown entities. The need a non-static-data
authentication paradigm to replace the static data authentication paradigm,
i.e. simply replace pin/password with public key and digital signatures.
Anne & Lynn Wheeler

@_date: 2004-07-07 10:07:29
@_author: Anne & Lynn Wheeler 
@_subject: authentication and authorization (was: Question on the 
another way of looking at it in an authentication/authorization infrastructure
is that some set of privileges are asserted ... this is typically done by having some
sort of identification associated with those privileges (like an account number
or userid). There can be some confusion whether what is being asserted is a
tag, identity or identification. if the tag being asserted, is something like a
person's name, the institution is likely just using it for a tag to look up set of privileges associated with that name (they may not actually care who
you are ... they want to know what privileges are associated with the then there is some sort of authentication as to the binding to those set of
privileges .... aka 3-factor authentication taxonomy
* something you know
* something you have
* something you are
note, in some scenarios .... it is possible that knowing the account
number provides both the privilege assertion as well as the "something you
know" authentication (aka knowing the account number is sufficient
to make withdrawals).
in any case there are frequently used institutional processes that can be
characterized by assertion of privileges and authentication. The taxonomy
of those processes can be considered independent of the terms used to
label the processes (is a guard really interested in who you are or just
finding out what privileges and permissions you have).
so we have an environment with institutions and CSOs and an attitude
that the institution and the institution integrity must be protected from
outsiders (and criminal insiders)
however, with the prevalent use of "static data" and "something you know"
authentication paradigms ... there is huge amounts of static data laying
around, ripe for the harvesting ... where the criminal impersonates an
individual. so one view is that the vulnerability is the extensive use
by institutions of "static data" and "something you know" authentication,
where the individual may have little or no ability to protect the majority
of the information. The crime appears to be against the individual and
the source of the information may be totally unrelated to where the
crime actually occurs. Assuming that the source of the vulnerability
are the institutional infrastructures, some laws have been passed to
try and hold the institutions responsible for the protection of
individual information. in some scenarios, institutions are
charged with protecting individual information from the institution
itself (which sort of inverts a security officers job of protecting
institution from others).
However, in some scenarios
the common use of static data is so pervasive that an individual's information
is found at thousands of institutions. The value of the information to the
criminal is that the same information can be used to perpetrate fraud
across all institutions and so the criminal value is enormous. However
the value to each individual institution may be minimal. As a result
there can be situations where an individual institution hasn't the
infrastructure or the funding to provide the countermeasures necessary
to keep the criminals away from the information (they simply don't
have the resources to provide security proportional to the risk).
The value of the static data authentication information to a criminal
is far greater than the value of the information to the institution ...
or the cost to the criminal to acquire the information is possibly
orders of magnitude less than the value of the information (for
criminal purposes).
Given such a situation .... the infrastructures simply don't have
the resources to provide the countermeasures adequate to meet
the attacks they are going to experience (there is such a huge
mismatch between the value of the information to the individual
institutions and the value of the information to the criminal).
Which results in my assertion that there has to be a drastic
move away from the existing "static data" authentication paradigm
.... because there is such a mismatch between the value
to secure the information verses the value of attacks to
obtain the information.
It isn't that theory can't provide  mechanisms to protect
the information .... it that the information is spread far and
wide and is in constant use by thousands of business processes,
and that protection problem is analogous to the problem of
having people  memorize a hundred different 8+character
passwords that  change every month (which is also a shortcoming
of the static data authenticaton paradigm).
Anne & Lynn Wheeler

@_date: 2004-07-08 08:33:42
@_author: Anne & Lynn Wheeler 
@_subject: FUJITSU DEVELOPS ENCRYPTION TECH THAT TAKES 20 MILLION YEARS 
Tokyo, July 8 (ANTARA/AFP) - Japanese IT giant Fujitsu Ltd. said Wednesday it has developed credit card encryption technology which is impossible to break with existing means
... snip ...

@_date: 2004-07-08 09:44:52
@_author: Anne & Lynn Wheeler 
@_subject: Using crypto against Phishing, Spoofing and Spamming... 
both SET & SSL encrypted data in transit. an issue is that SET is significantly more complex and provided no additional countermeasure (vis-a-vis SSL) against major remaining exploits .... like harvesting the merchant transaction file while at rest.
there was some issue that SSL was the incumbent ... so SET had to demonstrate significant better ROI to displace it ... rather than significantly higher "I" with little or no additional "R".
some SSL:
the security proportional to risk reference (using merchant transaction file as example)
couple minor past refs related to SET business operations
 non-repudiation, was Re: crypto flaw in secure mail standards
 non-repudiation, was Re: crypto flaw in secure mail standards
another SET issue was that it took a typical ISO 8583 transaction of 60-80 bytes and added a RSA 128 digital signature and issuing certificate of 4k-12k bytes .... effectively increasing the payload size by a factor of two orders of magnitude. it stripped all the SET overhead off at the internet boundary and transmitted a traditional 8583 message (in part because it was difficult to justify a 100-fold increase in payload size for no obvious benefit) with a flag indicating whether the signature had verified. There was some presentation at an ISO meeting by one of the association business people about the number of 8583 messages with the signature-verified flag turned on and they absolutely knew that there was no SET technology involved (some justification was association was proposing rules that transactions with the flag on would have lower merchant fees). missing is that typical authorization includes a lot of dynamic and aggregation factors (like credit limit) that are totally missing in a simple certificate-based (offline) authentication model. In fact, most infrastructures that involve transactions of any value have migrated and/or are migrating to online infrastructures that involve timely and/or aggregated information .... something that is missing from a purely offline, certificate-based, static, stale data infrastructure.
misc. implications
1) given an online transaction environment, it is then trivial to show that certificates are redundant and superfluous ... because it is possible to access the timely updated copy of the information rather than having to rely on the stale, static copy of the certificate information (designed to satisfy an offline environment requirement)
2) certificate market then becomes relegated to both offline and no/low value (as infrastructures of value migrate to online paradigms) ... there is little/no justification for paying money for certificates if only no/low value infrastructures are involved.
3) w/o significant funding for certificate-based infrastructure, there is little money to underwrite high-integrity certificate-based operations
4) with no high-integrity certificate-based operations, it is difficult to justify using certificates for high-value operations
5) go to as has past frequently noted, the requirement given the x9a10 retail payments working group for the x9.59 standard was to preserve the integrity of the financial infrastructure for all retail payment environments. one of the considerations was being able to accommodate end-to-end integrity ... aka the financial responsible entity for authorizing the transaction also performs the authentication. another issue x9a10 had to address was to address other kinds of risks .... like the merchant transaction file where the information traditionally has to occur in the clear to support normal business operations (offer something more than the encryption of data lots of posts about certificate infrastructures
misc. stuff on x9.59, identity, authentication, and privacy
Anne & Lynn Wheeler

@_date: 2004-07-09 04:14:01
@_author: Anne & Lynn Wheeler 
@_subject: Using crypto against Phishing, Spoofing and Spamming... 
the other issue was rsa public key op overhead (besides extreme payload
bloat, extreme additional complexity, and no significant countermeasures for
prime exploits compared to e-commerce incumbent SSL).
when the initial set specification was published, i did a business profile and
a performance profile (including public key operations profile). somebody
i knew was playing with bsafe library and tweaked it to run four times
faster. I got him to run the set public key op profile on a number of i mentioned the numbers at some set get together and the response from
the set people was that it was 100 times too slow (if they had ever run
any bsafe they should have realized that it was four times too fast).
anyway ... sometime later when they actual set implementations running ...
the earlier profile numbers were within a couple percent of measured on
actual implementations.
i also observed that given nominal extended peak avgs. of 1000/transactions
per sec .... that if SET ever actually became mainstream operational (rather than
just toy pilots) ... processing would need something like 100,000 to 250,000
extra processors to handle the RSA op processing load. the counter argument
was that SET would take so long to became mainstream ... that by
then CPUs might be ten to 100 times faster and it might only
require 10,000 to 25,000 (or 1,000 to 2,500) extra processors.
Anne & Lynn Wheeler

@_date: 2004-07-13 13:33:29
@_author: Anne & Lynn Wheeler 
@_subject: FasTrak information 
i was in toronto 18 months ago for business meeting ... and their toll
road is license plate based. at night a couple people offered to drive
to dinner reservations and unfortunately i was in a car that got stopped
for 20 minutes by the police because the rear license plate wasn't
readable. it had a "clear" plastic cover that had gotten coated & pitted
w/grime. simply wiping it off didn't work .... and nobody had a
screwdriver to undo the plate so the cover could be removed. finally a
call went out to any police car with a screwdriver. finally one showed
there was apparently a scam with pickup trucks stopping and lowering the
tailgate just before passing a camera .... which was sufficient to foil
the camera but not enuf to alert the police.

@_date: 2004-07-15 09:06:42
@_author: Anne & Lynn Wheeler 
@_subject: Using crypto against Phishing, Spoofing and Spamming... 
my earlier responses
i also included some discussion on it at a talk i gave on
naked keys at global grid forum conference last month,
focusing on business issues of authentication;
... minor ref (with pointer to the GGF pages &
with some comparison to x9.59
.... one of the business issues of public key infrastructures
is the dual-issue vulnerability of using digital signatures
for both authentication and signatures.
many of the authentication infrastructures have the
server sending the user some random data to be signed
as part of authentication (issues like replay attacks, etc);
which the user never looks at.
ignoring all the non-repudiation issues .... real signatures
are suppose to imply things like agreement, approval,
and/or authorization  (of the contents of what is being
the dual-use vulnerability is ever having signed random
data ... w/o reading it .... and using the same technology
to sign documents where reading is implied (as well as
agreement, approval, authorization).
the scenario is somewhat out of MASH where Radar
is periodically having the col. sign documents w/o
having read them.
Anne & Lynn Wheeler

@_date: 2004-07-15 17:18:21
@_author: Anne & Lynn Wheeler 
@_subject: Question on the state of the security industry 
A couple recent news stories
Intuit warns of credit card risk
Cyberattacks are soaring, countermeasures are sucking up tons of cash, and hardware and software vendors for the most part are sitting it out, *Bob Evans* says. But big customers are starting to say enough is enough, so the business-technology world is about to get whirled.
i've been saying for some time that after market security is broken by design ... it is somewhat like after market seat belts of the 60s. for security to work, it has to be designed & built in from the start .... some relatively recent comments about after market security:
 Oh, here's an interesting paper
 Secure you PC or get kicked off the net?
 Poor people's OS?
Anne & Lynn Wheeler

@_date: 2004-07-16 08:31:27
@_author: Anne & Lynn Wheeler 
@_subject: dual-use digital signature vulnerability 
ok, this is a long posting about what i might be able to reasonable assume
if a digital signature verifies (posting to c.p.k newsgroup):
basically the relying-party has certified the environment that houses the private key and the environment that the digital signature was done in ... then the verification of the digital signature might be assumed to imply one-factor or possibly two-factor authentication (i.e. if the relying-party has certified that a private key is housed in a secure hardware token and can never leave that hardware token, then the verification of the digital signature might imply one-factor, "something you have" authentication).
that establishes the basis for using digital signature for authentication purposes ... being able to assume that verification of the digital signature possibly implies "something you have" authentication (or something similar).
just the verification of the digital signature, however doesn't do anything to establish any implication about a legal signature where the "signer" is assumed to have read and agrees to the contents of the thing being signed (intention to sign the content of the document as agreement, approval, and/or authorization).
lets assume for argument sake that some sort of environment can be certified that provides a relying party some reasonable assurance that the signer has, in fact, read and is indicating agreement, approval, and/or authorization ... then there might possible be the issue of the dual-use the dual-use comes up when the person is 'signing" random challenges as purely a means of authentication w/o any requirement to read the contents. Given such an environment, an attack might be sending some valid text in lieu of random data for signature. Then the signer may have a repudiation defense that he hadn't signed the document (as in the legal sense of signing), but it must have been a dual-use attack on his signature (he had signed it believing it to be random data as part of an authentication Anne & Lynn Wheeler

@_date: 2004-07-17 09:25:41
@_author: Anne & Lynn Wheeler 
@_subject: Using crypto against Phishing, Spoofing and Spamming... 
misc. recent selections
Online Phishing Scams Exploding
Business faces growing loss from identity theft
Firms hit hard by identity theft
ID theft costing UK billions in taxes
ATM skimmers go hi-tech down under
Phishing will cost financial firms $400m in 2004
Worried firms consider email boycott
social engineering has frequently been talking somebody into giving up some information that then can be used for impersonation in later fraudulent transactions. A "something you have" token of some sort is a lot harder to give-up than shared-secrets for use in "something you know" authentication. A private key that never leaves the hardware token can't be given up because even the owner doesn't know it. also, conjecture is that it is a lot harder to convince general public to mail off some physical object compared to getting them to divulge some information.
hardware tokens don't eliminate social engineering attacks where the victim is talked into performing some transaction on behalf of the attacker ... but they would tend to address the whole vulnerability landscape related to "something you know" shared-secret authentication paradigms.
one of the cost issues with technology for server reputation is that it typically applies to servers that the consumer is visiting for the first time (or visits extremely rarely). the consumer pretty much ignores repetitive information for sites that they visit frequently. it has been that something like ninety percent (or better) of internet transactions are done by the frequently visited sites. so the cost issue is that the reputation technologies basically tend to apply to the millions of low-volume and/or low-revenue sites (in aggregate accounting for 10 percent or less of all transactions) ... which aren't looking to spend a lot of money on such technologies.
it is somewhat like the better business bureau use .... people will tend to contact the better business bureau before they deal with some vendor for the first time .... but they aren't likely to contact the better business bureau each time they deal with a vendor that they have extensive repeat business with. it at least some scenarios ....
an alternative to the business logo .... is a  better business bureau or gov. licensing logo on a website .... that provides click-thru to the official site .... where the consumer can review complaints and/or history about the business in question. i believe that this is somewhat the ebay model ... where past transaction history reputation of individuals can be Anne & Lynn Wheeler

@_date: 2004-07-18 08:54:56
@_author: Anne & Lynn Wheeler 
@_subject: dual-use digital signature vulnerability 
I don't see here any problem or attack. Indeed, there is difference
between signature in the crypto sense and legally-binding
signatures. The later are defined in one of two ways. One is by the
`digital signature` laws in different countries/states; that approach
if often problematic, since it is quite tricky to define in a general
law a binding between a person or organization and a digital
signature. The other way however is fine, imho: define the digital
signature in a (`regular`) contract between the parties. The contract
defines what the parties agree to be considered as equivalent to their
(physical) signature, with well defined interpretation and
the digital signature laws, for the most part, defined how a
certification authority went about binding the owner of a public key
(or at least the entity presenting a public key and a digital
signature that could be verified by that public key) and some other
information ... and presenting that in a certificate. However, I don't
remember seeing any of the e-sign laws a) defining a non-repudiation
environment that is mandated for signature digital signing environments
(indicating that the key owner has read, understood, and approves,
agrees, and/or authorizes the contents of the message and b) as
part of the integrity of the message, there is proof that such a
non-repudiation environment was used.
the relying party being able to certify the integrity level of
something like a hardware token .... for use in "something you have"
authentication .... aka the relying party verifies a digital signature
and that verification may used to imply "something you have"
authentication (at this point there is absolutely nothing involving a
certificate). However, in order for the relying party to be able to
assume or imply what the verification of the digital signature
actually means .... and therefor how much it can trust the
verification ... it needs to know how the private key is maintained
and operated. If the act of "verifying a digital signature" actually
means or implies that it is "something you have" authentication
... then it needs to have some certification along the lines that the
private key is used and maintained in a hardware token with specific
characteristics. It has nothing at all to do with any certificate
traditionally mentioned in various kinds of e-sign laws.
during the early '90s, the identity certificates tended to be
overloaded with all sorts of identity and privacy information. this
was fairly quickly realized to represent serious privacy and liability
issues. this was retrenched to things like relying-only-party
certificates that basically only had a public key and some sort of
account identifier (which could be used by the relying-party to pull
up the real information .... w/o having it publicly broadcast all over
the world). However, there were also things like "non-repudiation"
bits defined in certificates ... that have since been severely
depreciated. During the mid-90s there were some infrastructures being
proposed that if you had some data which had an appended digital
signature and an appended certificate containing a non-repudiation bit
.... then the burden of proof (in disputes) could be shifted from the
relying party to the signing party.
This was vulnerable to possibly two exploits
a) the digital signer had believed that they had signed random data as
part of an authentication protocol ... as opposed to having signed
some document contents indicating agreement, approval, and/or
authorization (as in real live signature .... aka the dual-use
scenario) and/or
b) since the appended certificate isn't part of the signed transaction
.... the relying-party might be able to find a digital certificate
(belonging to that key-owner for the same public key) that had the
non-repudiation bit set and substitute a non-repudiation certificate
for the certificate that the key-owner had actually appended (aka the
certificate is not part of the integrity of the message covered under
the digital signature).
at the NIST PKI workshop a couple months ago .... there were a number
of infrastructure presentations where various entities in the
infrastructure were
a) signing random data as part of authentication protocol (where the
entity performing the digital signature was given no opportunity to
view the contents being signed) they were using hardware token
implementation .... and they were assuming that the verification of
the digital signature implied some sort of "something you have"
authentication. however there was nothing in the infrastructure that
provided certification and/or proof that the private key was kept and
maintained in a hardware token .... so there was no proof as to the
level of integrity and/or level of trust that the relying party could
place in the verification of that digital signature
b) signing authorization documents (using the same tokens that were
used in the authentication protocols)
However, there was no distinguishing and/or provable characteristics
that were provided which a relying-party could use to distinguish
between (random) contents that were signed as part of an
authentication protocol and (authorization) contents that the
relying-party could assume to indicate that the signer was agreeing,
approving, and/or authorization what was indicated by the contents of
the document.
Since there was no proof provided to the relying-party as to the
environment and conditions under which the signing actually occurred
.... then a dual-use attack is for non-random contents (aka some sort
of authorization document) to be injected into an authentication
protocol .... under the assumption that the entity performing the
digital signature will never look at the contents. Then such digitally
signed contents can be used in an approval, agreement, and/or
authorization scenario to imply that the entity performing the digital
signature was actually approving the contents of the document.
this now verges into various of the non-repudiation definitions and
threads that have occurred in the past. in effect, for any kind of
infrastructure where the digital signature is being used to imply that
the entity responsible for the digital signature agrees, approves,
and/or authorizes what is in the content of the message being signed
(as opposed to some random data being signed as part of authentication
protocol and is never viewed) ... there has to be some additional
signing environment (demonstrating that the signer has actually read,
understood, and agrees with the contents) ... and the proof of the use
of such a signing environment infrastructure has to be carried as part
of the integrity of the message .... in order for the relying party to
rely on it being a real "signature signing" event ... as opposed to
have really originated from a authentication protocol where the person
believed that random data was being signed (and never actually viewed
the contents being signed). Note that not only does such an
non-repudiation signing environment has to have been used .... but the
proof of its use has to be carried as part of the integrity of the
message (in order for the relying party to distinguish between random
data being digital signed and the person having signed after viewing
the contents, understanding the contents and approving, agreeing,
and/or authorization what was indicated by the contents). So it isn't
just that a non-repudiation environment has to be used for signing
operations (as in human signature) ...but the proof of such
non-repudiation environments have to be carried as part of the
integrity of the message .... to differentiate from a dual-use attack
where the signing is believed to be random data and the person never
views the contents.
other kinds of infrastructure implementations may be to have two
completely different hardware tokens with two completely different
public/private key pairs.
the hardware token used for authentication protocols doesn't concern
itself with the contents of the data ... in fact it always appends a
disclaimer to all random data (that it signs) stating that the digital
signature cannot be used to imply any agreement, approval,
authorization and/or any obligation on the part of the
token-owning entity.
the hardware token used for authorization, agreement, and/or approval
signing events will never perform a digital signature operation unless
it first senses that the token owner has read, understood and
approved of the contents.
all protocols indicate as part of the hardware token interaction, which
type of digital signature will be performed ... and the owner of the
hardware tokens is then instructed appropriately when hardware token
swapping needs to occur.
random past posts about non-repudiation:
 CFP: PKI research workshop
 CFP: PKI research workshop
 PAIIN security glossary &  Meaning of Non-repudiation
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Words, Books, and Key Usage
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 NEWS: 3D-Secure and Passport
 TOC for world bank e-security paper
 Employee Certificates - Security  Legal entities who sign
 Legal entities who sign
 e-Government uses  An attack on paypal
 UK: PKI "not working"
 basic question: semantics of "map", "tie", etc in PKI
 VS: On-line signature standards
 VS: On-line signature standards
 VS: On-line signature standards (slight addenda)
 VS: On-line signature standards
 VS: On-line signature standards
 Difference between TCPA-Hardware and a smart card (was: example: secure computing kernel needed)
 The PAIN mnemonic
 Non-repudiation (was RE: The PAIN mnemonic)
 Non-repudiation (was RE: The PAIN mnemonic)
 Non-repudiation (was RE: The PAIN mnemonic)
 Non-repudiation (was RE: The PAIN mnemonic)
 Non-repudiation (was RE: The PAIN  Non-repudiation (was RE: The PAIN  Using crypto against Phishing, Spoofing and Spamming
 RealNames hacked. Firewall issues.
 PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  FREE X.509 Certificates
 distributed authentication
 Security and e-commerce
 Security Issues of using Internet  Digital signature
 Are you really who you say you are?
 Does Diffie-Hellman  schema belong to Public Key schema family?
 Does Diffie-Hellman  schema belong to Public Key schema family?
 Definition of Non-Repudiation ?
 Beginner question on Security
 Convenient and secure eCommerce using POWF
 Help! Good protocol for national ID card?
 Help! Good protocol for national ID card?
 Message (authentication/integrity); was: Re: CRC-32 collision
 Message (authentication/integrity); was: Re: CRC-32 collision
 unix
 application of unique signature
 entity authentication with  electronic-ID and key-generation
 electronic-ID and key-generation
 The Tao Of Backup: End of postings
 Security models
 Questioning risks of using the same key for authentication and
 securID weakness
 Biometric cards will not stop identity fraud
 Does OTP need authentication?
 Order of Encryption and  Does OTP need authentication?
 Soft signatures
Anne & Lynn Wheeler

@_date: 2004-07-18 09:51:46
@_author: Anne & Lynn Wheeler 
@_subject: Using crypto against Phishing, Spoofing and Spamming... 
there sort of two parts of SSL .... I believe the original justification was based on perceived integrity issues with the domain name infrastructure and various kinds of hijacking attacks. the client got back a certificate, verified the integrity of the certificate (from a table of certificate authority public keys), verified that it appeared to originate from the certificate owner and then compared the certificate domain name string with the domain name used in the URL. once that was done, there was key-exchange to protect the contents of the transmission.
the catch22 was that the domain name infrastructure is also the authoritative agency as to the owner of the domain name. the SSL domain name certification authorities have this horrendously, error prone and expensive problem of getting sufficient identification information from the certificate applicant and attempting to match it with the identification information carried by the domain name infrastructure as to the owner of the domain name.
so the first issue is that the integrity of the domain name infrastructure could be attacked with a domain name hijack ... then the attacker applies for a certificate .... and the identification provided the certification authority and the identification on file with the domain name infrastructure compare ... and the attacker gets a valid certificate.
so the certification authorities came up with a proposal to have domain name registers .... also supply a public key at the time of registration. then future communication with the domain name owner is digital signed ... which the domain name infrastructure can verify with the public key on file. this is a countermeasure against domain name hijacking (improving the integrity of the domain name infrastructure and rising the trust that certification authorities can place in the authoritative agency). the other issue is that the certification authorities can use the public key on file with the domain name infrastructure to turn an expensive, and error-prone identification process into a much simpler and KISS authentication process .... aka domain name certificate applicants digitally sign their requests ... which are then verified with the public key on file at the domain name the two issues then are that with increased domain name infrastructure trust ... 1) it should reduce the demand for domain name SSL certificates (motivated by integrity concerns about the domain name infrastructure) and 2) it could eliminate the need for domain name SSL certificates .... since all clients could possibly also use the public keys on file with the domain name infrastructure (in lieu of needing to get public keys from certificates).
So now to the key-exchange issue protecting credit-card numbers from evesdropping and harvesting. The issue is that the crooks tend to go after the best fraud ROI (return on investment). The claim is that it is so much more profitable to harvest the merchant transaction file .... that until that barn door is closed .... the crooks have little incentive to go after credit card numbers by evesdropping packets in flight. There have been some assertions that there has been no known cases of picking up account numbers from packet evesdropping .... even where SSL or any other encryption is being used to protect data in-flight. Part of the issue is that evesdropping packets takes a lot more work ... and provides much less return than going after the merchant transaction file. Other scenarios have also been end-point attacks ... where password files are harvested and/or viruses are installed at end-points to harvest information .... as opposed to doing anything with data in-flight.
So, it could be claimed that there is some question about what is cause and what is effect i.e. are the end-point attacks because everything is encrypted .... or are the end-point attacks occurring because they are so much more profitable and easier. Given that there are significant amounts of non-encrypted traffic ... then the claim could be made that the crooks are getting so much more from end-point attacks ... and until that is addressed ... that attacks on data in flight is somewhat academic (since there is so little evidence about fraud happening from data in flight attacks). The other argument has traditional been that 90 percent of fraud has been insiders, typically also associated with various kinds of end-point attacks (rather than any kind of outsider attack on data in flight). There was some recent study that at least 77 percent of the identity theft has involved insiders. This would also indicate that the end-points are the primary points of attack .... and that data-in-flight attacks are of primarily of academic interests ... not particularly contributing to fraud, even when no encryption or protection is involved.
One might even assert that the attention paid to data-in-flight attacks is actually counterproductive ... distracting attention from the much more serious and significant end-point attack fraud .... which has always been the major problem.
Anne & Lynn Wheeler

@_date: 2004-07-18 10:32:44
@_author: Anne & Lynn Wheeler 
@_subject: dual-use digital signature vulnerability 
the fundamental issue is that there are infrastructures using the same public/private key pair to digital sign
1) random authentication data that signer never looks at and believe is of low value ... if they connect to anybody at all ... and are asked to digitally sign some random data for authentication purposes ... they do it.
2) contents that they supposedly have read, understood, and are indicating that they agree, approve and/or authorize.
i haven't seen any definition of data arriving at the relying party where the relying party has proof of whether it was case  or case  The closest was the non-repudiation bit in a certificate. however, the non-repudiation bit in a certificate was put in there at the time the certificate was manufactured and in no way applies to the environment and conditions under which the signature in question actually occurred.
there are definitions like non-repudiation services and/or the EU FINREAD definition ... which purports to specify the environment under which the "signatures" take place. Note however, while the EU FINREAD defines an environment where there is some indication that the signing party might have read and agreed to the contents of what is being signed .... there is nothing in the EU FINREAD specification that would provide proof to the relying party that a FINREAD terminal was actually used for any specific signing. Anything, like a flag ... not part of a signed message ... that might be appended to the transmission ... that makes claims about whether a FINREAD terminal was used or not ... could have originated from anywhere .... analogous to the example where a relying party might be able to substitute a certificate with the non-repudiation bit set .... in order to change the burden of proof from the relying party to the signing party (in a legal dispute ... more the mid-90s ... where non-repudiation flag in a certificate might have been thought to have some valid meaning (since the certificate wasn't covered by the signature .... anybody could claim any valid certificate was the certificate used for the transaction)
In any case, if a signing party has ever used their private key to sign random data that they haven't read ..... and they are ever expected to use the same private key in legal signing operations where they are presumed to have read, understood, and approve, agree, and/or authorize the contents .... and there is no proof provided (or included) as part of the signed message that the signing occurred in a specified (non-repudiation) environment ... then there is no way that a relying party can prove or disprove under what conditions a digital signing actually occurred.
misc. past post reference EU FINREAD:
 Shades of FV's Nathaniel Borenstein: Carnivore's "Magic Lantern"
 Welome to the Internet, here's your private key
 AW: Digital signatures as proof
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Proxy PKI. Was: IBM alternative to PKI?
 Interests of online banks and their users [was Re: Cryptogram:  Palladium Only for DRM]
 The real problem that https has conspicuously failed to fix
 FAQ: e-Signatures and Payments
 example: secure computing kernel  3D Secure Vulnerabilities? Photo ID's and Payment Infrastructure
 Authentication white paper
 FINREAD was. Authentication white paper
 FINREAD ... and as an aside
 FINREAD was. Authentication white paper
 Q: Internet banking
 PKI/Digital signature doesn't work
 PKI/Digital signature doesn't work
 PKI/Digital signature doesn't work
 PKI/Digital signature doesn't work
 Net banking, is it safe???
 No Trusted Viewer possible?
 Are client certificates really secure?
 Smart Card vs. Magnetic Strip Market
 Smart Card vs. Magnetic Strip Market
 Opinion on smartcard security  Opinion on smartcard security  Security Issues of using Internet  Security Issues of using Internet  Digital signature
 Convenient and secure eCommerce using POWF
 Help! Good protocol for national ID card?
 Help! Good protocol for national ID card?
 smartcard+fingerprint
 HELP, Vulnerability in Debit PIN Encryption security, possibly
 application of unique signature

@_date: 2004-07-18 11:25:17
@_author: Anne & Lynn Wheeler 
@_subject: dual-use digital signature vulnerability 
the issue in the EU FINREAD scenario was that they needed a way to distinguish between (random) data that got signed ... that the key owner never read .... and the case were the key owner was actually signing to indicate agreement, approval, and/or authorization. They specified a FINREAD terminal which supposed met the requirements that the key owner had to have read and to some extent understood .... and approved as to the meaning of the contents of what was being signed.
However, the FINREAD specification didn't define any mechanism that provided proof to the relying party that a FINREAD terminal was actually used as part of the signature process.
Some of the non-repudiation service definitions also talk about processes that would provide high likelyhood that the person performing the signing has read, understood, and agrees with the contents of what is being signed. However, many of them fail to specify a mechanism that proves to a relying party that such a non-repudiation service was actually used.
so the dual-use attack .... is if a key-owner ever, at any time, signs something w/o reading it ... then there is the possibility that the data being signed actually contains something of significant.
if there is never any proof, included as part of the integrity of the message ... that proves to the relying party that some sort of non-repudiation environment was used as part of the digital signing .... then it falls back on requiring an exhaustive proof that never in the history of the private key was it ever used to sign contents that were unread and could possibly be random.
it isn't sufficient that you show there is some specific authentication protocol with unread, random data ... that has countermeasures against a dual-use attack ... but you have to exhaustively show that the private key has never, ever signed any unread random data that failed to contain dual-use countermeasure attack.
the alternative to the exhaustive proof about every use of the private key .... is strong proof (that is built into the integrity of the signed contents) that non-repudiation environment was used for the digital signing (strong implication that the key owner, read, understood, approves, agrees, and/or authorizes the contents of the message).
the NIST scenario for a exhaustive proof ... rather than exhaustive proof about every use of a specific private key .... would be able to show that it is impossible to use the private key in any protocol not written by the people making the presentation
this came up in a SET discussion long ago and far away. it was about whether there was every any SET gateway protocol that could set the "signature verified" bit in the ISO 8583 message. One of the SET vendors claimed that the software they shipped was certified that it would never set the "signature verified" bit in the ISO 8583 message, if the signature hadn't actually been verified (and therefor there wasn't an infrastructure vulnerability). The problem was that they had created an infrastructure that didn't require end-to-end proof of the signature verification ... and they were unable to control that every ISO 8583 generated message .... was certified as only being able to be generated by their code.  They had created an infrastructure vulnerability .... that allowed a wide variety of software to be used .... and was only safe if they could prove that every copy of code generating every ISO 8583 messages was their code and it was impossible to modify and/or substitute something else in the generation of an ISO 8583 message.
The countermeasure to the seriously flawed SET design requiring exhaustive proof that every ISO 8583 message that was ever created that carried the "signature verified" bit .... could have only been created by unmodified, certified software .... was to support end-to-end authentication. .And for a slight drift ... that wasn't practical in the SET design because the inclusion of a certificate would have represented horrendous payload bloat of two orders of magnitude (discussed in some detail in recent posts to another thread in this mailing list)
Anne & Lynn Wheeler

@_date: 2004-07-18 13:28:17
@_author: Anne & Lynn Wheeler 
@_subject: dual-use digital signature vulnerability 
there is a variation on the EU FINREAD terminal that sort of provides a chain of trust/evidence (that has almost nothing at all to do with the traditional trusted third party certification authorities and their 1) there ae a certain class of certified terminals with security modules, tamper evident, and are known to always present an accurate text of what is about to be signed ... and then asked the person if they agree with what was presented .... which they have to indicate by pressing some button (or set of buttons)
2) these are a certain class of certified hardware tokens which contain unique private keys.
3) the specific certified hardware terminals are able to verify what kind of hardware token they are dealing with and only work with the appropriate hardware token
4) the specific certified hardware tokens are able to verify what kind of terminal they are dealing with and only work with the appropriate hardware 5) relying party gets a signed message
6) the relying party can verify the digital signature with a specific public key known to be associated with a known hardware token
7) the known hardware token is known to be in the possession of a specific person .... which implies "something you have" authentication
8) the known hardware token is known to satisfy requirements  and 9) the corresponding terminals that the hardware token works with are known to satisfy requirements  and 10) given conditions 1-9, the relying party has some assurance that the token owner has actually read, understood, and agrees with the contents of the message.
In this scenario the relying party wouldn't need direct evidence included as part of the integrity of each message that the signing took place in an non-repudiation environment .... the infrastructure assurance as to the kind of terminals, tokens, and procedures provide such indirect evidence as part of the infrastructure operation (aka the chain of evidence/trust scenario .... having nothing at all to do with traditional third party certification authorities and their certificates).
This kind of scenario falls apart .... if the hardware token ever digitallly signs some contents that is not provided by a trusted terminal. In which case the chain of evidence/trust is lost as to whether the token owner has read, understood, and agrees, approves, and/or authorizes the contents of what is being signed.
Either you
1) have some proof that every use of the specific hardware token (and its corresponding unique private key) digital signing always meets the requirements laid out as to human reading, understanding and agreeing, approving and/or authorizes the contents of what is being signed ... and it can never be used in any other way
2) or that every use of the specific hardware token (and its corresponding unique private key) digital signing that is purported to meet the requirement for human reading, understanding and agreeing, approving and/or authorizes the contents of what is being signed .... carries in the integrity part of the message some indication/proof of the human reading, understanding and agreeing, approving and/or authorizes (and that indication can't be fraudulently fabricated if the hardware token was to ever be used in signing some message that doesn't involve reading/understanding/approval by the token owner).
Anne & Lynn Wheeler

@_date: 2004-07-18 23:51:28
@_author: Anne & Lynn Wheeler 
@_subject: dual-use digital signature vulnerability 
so if digital signing is used for nothing else than authentication ... with signing of challenge data (with or with/out client-side modification) ... then there is no concern that something signed might be a document or authorization form. it is a non-problem.
EMV chipcards are supposed to be doing dynamic data RSA signing of authorized transactions  ... at some point, real soon now ... and the financial industry is writting some number of apps to be able to use the EMV cards for other applications.
this is from yesterday
which talks about additional applications (in addition to expected RSA signing at EMV point-of-sale terminals)
* OneSMART MasterCard Authentication ? ensures a higher level of security for online shopping and remote banking
* OneSMART MasterCard Web ? allows cardholders to securely store and manage a wide range of personal data (such as names, addresses, URLs, log-on passwords) on the smart card chip
* OneSMART MasterCard Pre-Authorised ? a new chip-based payment solution suitable for new markets and off-line payment environments
it doesn't give any details but possibly if the expected RSA signing at EMV point-of-sale terminals is an example of aggreement/approval ... then the authentication application may be RSA signing of some sort of challenge data .... and i would guess that few, if any people make it a habit to examine presented challenge data.
part of the issue is creating an environment where all authentication protocols and all authentication implements are required to have countermeasures against dual-use attack on signing of documents or transactions ... means that loads of stuff have to be perfect in the future.
the other is requiring more proof regarding the signing environment to be carried when the signing is associated with approval, agreement, and/or authorization (more than simple authentication) .... for instance that for some of the non-repudiation features (that supposedly address such issues) .... that they have to also sign in some manner to indicate non-repudiation features in in place.
Anne & Lynn Wheeler

@_date: 2004-07-19 09:26:18
@_author: Anne & Lynn Wheeler 
@_subject: dual-use digital signature vulnerability 
note that some of the online click-thru "contracts" have been making attempt to address this area; rather than simple "i agree"/"disagree" buttons ... they put little checkmarks at places in scrolled form .... you have to at least scroll thru the document and click on one or more checkmarks .... before doing the "i agree" button. a digital signature has somewhat higher integrity than simple clicking on the "i agree" button ... but wouldn't subsume the efforts to demonstrate that a person was required to make some effort to view document. Of course in various attack scenarios ... simple checkmark clicks could be forged. However, the issue being addressed isn't a forging attack ... it is person repudiating that they read the T&Cs before hitting the "I agree" button.
With the depreciating of the "non-repudiation" bits in a long ago, and far away manufactured certificates (which has possibly absolutely no relevance to the conditions under which digital signatures are actually performed) .... there has been some evolution of "non-repudiation" processes. An issue for the "non-repudiation" processes is whether or not the person actually paid attention to what they were "signing" (regardless of the reason).
An issue for relying parties is not only was whether or not there was some non-repudiation process in effect, but also does the relying party have any proof regarding a non-repudiation process. If there is some risk and/or expense associated with repudiation might occur (regardless of whether or not it is a fraud issue), then a relying party might adjust the factors they use for performing some operation (i.e. they might not care as much if it is a low-value withdrawal transaction for $20 than if it was a withdrawal transaction for $1m).
some physical contracts are now adding requirement that addition to signing (the last page), that people are also required to initial significant paragraphs at various places in the contract.
Anne & Lynn Wheeler

@_date: 2004-07-21 10:10:24
@_author: Anne & Lynn Wheeler 
@_subject: Using crypto against Phishing, Spoofing and Spamming...  
SET couldn't replace online transaction ... the encryption was
effectively there for hiding credit card while in-flight ...
which SSL was already doing ... but SET was doing at an
order to two-orders increase in complexity and overhead.
SET didn't provide any additional countermeasure against
the major exploits/vulnerabilities (vis-a-vis SSL) ... even
with all that complexity.
the transaction was still online ... since there are a bunch
of other factors involved in authorization ... like credit limit
... not just whether there is impersonation with lost/stoleln
there was still the enormous payload bloat (certificates and
signatures increase the size of typical 8583 transaction by
two-orders of magnitude) which prevent true end-to-end
security operation. As a result the signature was verified
at some internet boundary, then the signature and certificate(s)
were stripped off and traditional 8583 packet forwarded
to the consumer/issuing financial institution. Later at some
ISO standards meeting, one of the association business
people presented numbers on number of 8583 packets
with the signature bit turned on and they positively knew
no digital signature was involved.
It wasn't even a real PKI ...
1) i.e. the x.509 identity certificates from the early 90s had
been depreciated because of the privacy and liability issues
... and the certificates effectively were issuing
relying-party-only certificates with the account number
and public key.
2) there was no revocation and/or other types of process
(which could be considered minimum requirement for
a PKI operation) ... they were simply manufactored
certificates (a term we coined to describe the SET and
SSL infrastructure; contrasting it to PKI). SET
specifically stated that the transaction would be
online and rely on the existing online infrastructure
for determining lost, stolen, revoked, canceled, etc
... as well as all the other stuff an online infrastructure
can do with  timely and aggregated information
(like credit limit)
3) it is trivial to show that for relying-party-only certificates
requiring online infrastructure ... that the certificates
themselves are redundant and superfluous ... aka the
key is registered with the issuing party ... and the transaction
is performed by the issuing party. The transaction can
be digitally signed (w/o the enormous payload bloat of
carrying a certificate) and the issuing party verify the
digital signature with an onfile public key .... w/o having
to resort to dealing with a certificate (that the issuing
party would have originally generated from the onfile
 From an incentive standpoint the PKI model is effectively
orthogonal to standard business processes.
The key owner pays something to the issuing party (or
at best, the issuing party absorbs the costs). The standard
business process has any sort of contract between the
key owner and the issuing party.
This totally leaves out the relying-party ... which is the
primary beneficiary of the PKI model from being a part
of the contractual business process ... which would imply
little or no legal recourse if something went wrong. GAO
has created a facade to address this issue by making the
TTP certification authorities sort of agents of the GAO ... and
having all relying-parties signed contracts with the GAO.,
The PKI frequently creates a total disconnect between
the parties of the certification "contract" ... and the
relying parties ... which should have recourse in case
something went wrong aren't even a part of it.
In the specifics of the SET deployment ... the primary
potential beneficiaries theoritically were the merchants
(from the thoery that SET signed transactions would be
considered card-present & card-owner present ... and
lower the merchants cost for doing the transactions).
However the parties "paying" for the certificates and
most of the infrastructure were the issuers and the
consumers. Not only may a traditional TTP PKI create
legal disconnect for relying parties .... but in the SET
case there was major disconnect between who paid for
most of the infrastructure and who benefited (i.e.
need some sort of mechanism to get the merchants
to pay for the consumer's certificate .... even tho
the certificates were functionally redundant and
Anne & Lynn Wheeler

@_date: 2004-07-22 08:34:25
@_author: Anne & Lynn Wheeler 
@_subject: dual-use digital signature vulnerability 
there has been some claim that large random nonces as part of message ... before hashing and signing is characteristic of RSA signatures. one of the issues with DSA and hardware tokens in the 90s was that none of the hardware tokens had reliable random generators. If you were doing DSA (or ECDSA) infrastructure ... then integrity was dependent on quality random generator as part of the signature process (to preserve the integrity of the private key). In some sense, large random nonces (as part of the content to be signed) was shifted to the party(s) generating the message as part of the RSA process. In theory, DSA/ECDSA eliminates that requirement ... especially as you move in to the late 90s where hardware tokens started to appear that had quality random generators.
protocols have had severs contributing unique values in signed messages .... in things like authentication protocol .... as countermeasure to replay attacks (on the server).
protocols have had clients contributing some values in signed messages ... in an authentication protocol ... as countermeasure of server attacks on clients. It isn't necessary that the client contributed part has to bracket both the start and end of the message .... in a digital signature environment ... since the digital signature protects the whole message integrity. The client contributed part could be simple readable text disclaimer ... comparable to some disclaimers you see at the bottom of emails (especially from lawyers, doctors, and/or people that work for such firms .... you even see it in various mailing lists by people that work for the big accounting firms).
sometimes the recommendations are that both server and client contribute something unique to the signed message ... as generic countermeasures ... regardless of whether the situation is actually vulnerable to the associated attacks. In general, where the server incurs some expense and/or liability associated with every message ... the server (or relying-party) is probably interested in countermeasures against replay attacks.
one of the requirements given x9a10 working group (for the x9.59 protocol) ... was to be able to perform the operation in a single round-trip .... w/o any sort of protocol chatter. this is comparable to existing electronic payment business process. the countermeasure that the infrastructure uses for replay attacks is to have the transactions time-stamped and log is kept. transactions with time-stamps that predate the log cut-off are deemed invalid. In the x9.59 transaction scenario ... the signing entity (in theory) specifically approved every transactions and used ecdsa signature. the ecdsa signature would preserve the integrity of the transaction. the time-stamp in the transaction would indicate whether it was within the current active log window of the payment processor, and the randomness of the ecdsa signature would provide uniqueness (two transactions that were otherwise identical (in amount, time, etc) would be unique if they had different ecdsa signatures (effectively provided by the definition of dsa & the addition of ecdsa signature to existing payment transaction .... exactly preserved all the existing business processes and flows ... including the requirement that the client can originate the transaction and the message flow could complete in a single round-trip.
the addition of the ecdsa signature added
a) integrity of the transaction message,
b) authenticated the origin, and
c) provided transaction uniqueness.
no (public key) certificate was required since the transaction was being processed by the relying-party (which in the SET model was also the relying-party, had the public key on file, had the original of all the information that went into a SET relying-party-only certificate, and the only function that the SET relying-party-only certificate was to repeatedly travel from the client to the relying party increasing the payload and the bandwidth requirements by a factor of one hundred times, carrying static, trivial subset of information to the relying party ... which the relying party already had ... making it redundant and superfluous ... other than contributing enormous payload bloat).
there was one additional thing that was specified in x9.59 standard .... that account numbers used in x9.59 transactions could not be used in non-authenticated transactions (not that all the payment processors already supported feature/function of mapping multiple account numbers to the same account). the issue was that it was recognized that regardless of the crypto facilities used to protect the account number in flight, there were scores of business processes that required the account number to appear in the clear.
In the existing infrastructure that are huge numbers of unauthenticated transactions that can be performed with the account number ... which effectively turns the account number into an enormous shared-secret .... requiring enormous amounts of protection for the shared-secret. however, with all the enormous numbers of places that the clear-text account number is used ... it is not possible to also preserve the account number as a shared-secret. minor past note about security proportional to risk
 so the x9.59 approach was to eliminate "shared-secret" as a business characteristic of the account numbers used in x9.59 transactions. if an account number used in an (digitally signed) x9.59 transaction ... can only be used in x9.59 (digitally signed) transactions .... it no longer carries with it the "shared-secret" characteristic (since simple knowledge of the account number is insufficient to impersonate and/or perform fraudulent transactions).  So if the insiders at a merchant processing end-point (or an external outsider that is harvesting merchant processing transaction files) is unable to "steal" the account number and use it fraudulently ... it no longer has to be protected as a shared-secret.
The end-point static harvesting of transaction files has been the major vulnerability for a long time. They have tended to be in the clear because of the large number of business processes that require access to the transactions. Neither SET nor SSL provided any countermeasures for this (the major) vulnerability/exploit.
X9.59 did eliminate this as a vulnerability ... since stealing the transaction file and harvesting the account numbers .... would not provide the crook any mechanism to impersonate and/or perform a fraudulent transaction. It turns out the secondary effect was that it was no longer necessary to hide the account number while in flight either (in order to preserve an account number as a shared-secret). digitally signing the transaction both preserved the integrity of the transaction as well as authenticating the origin of the transaction. This then eliminated the requirement to hide the account number as a countermeasure against the account number being exposed (and comprimising its shared-secret The issue with SET was that it was horribly more complex and expensive and provided no fundamental additional protection/countermeasure than existing SSL (with respect to reducing existing vulnerabilities and fraud).  This was somewhat orthogonal to the problem with the horribly additional expense not being born by the primary benefiting parties.
X9.59 is an enormously simpler and less expensive protocol than either SET or SSL ... and turns out to address (in a business way) the major exploits and vulnerabilities in the existing infrastructure ... the basic characteristic that the account number is effectively a shared-secret (which neither SET nor SSL addresses). Furthermore, with the elimination of the shared-secret attribute for account numbers .... then it is no longer necessary to encrypt the transmissions (for purposes of preserving the account number secrecy).
Anne & Lynn Wheeler

@_date: 2004-07-22 13:07:30
@_author: Anne & Lynn Wheeler 
@_subject: RP -- Re: Using crypto against Phishing, Spoofing and 
the TTP (trusted third party) PKI business model typically described in the early 90s ... had a business exchange between a key owner and a certification authority ... where the key owner paid the certification authority for the issuing of a certificate that bound some information to the public key. The payment of money by the key owner to the certification authority created some sort of legal relationship between the key owner and the certification authority .... with regard to the certificate.
in that environment .... the key owner then digitally signed something, and sent the something with a digital signature and the certificate to a relying-party. The relying-party was frequently assumed to be making some sort of legal reliance and recourse on the performance of the certification authority. However, w/o payment of funds and/or other legal arrangement between the relying-party and the certification authority .... there was no legal bases for reliance (unless mandated outside of traditional business context by some gov. mandate)
it appears that the GAO .... working within that semantic & structural business context ... has taken some effort to create a legal basis for reliance and recourse between the relying parties and the certification authorities for the federal PKI . It basically has something along the lines of the certification authorities signing a contractual relationship with the GAO. Then all the relying parties also sign a contractual relationship with the GAO ....  then there is recourse for the relying parties on certification authority performance based on the relying parties contract with GAO (for certification authority performance) and the GAOs contract with the certification authorities (for certification authority performance). This is sort of trying to get around the lack of any implied performance and/or contractual relationship (and therefor recourse) because the relying parties haven't actually paid any money to the certification In the simple case, having any sort of legal obligation between the certification authority and the key-owner ... and any sort of totally different legal obligation between the key-owner and a relying party ... normally would fail to create any sort of legal obligation between (the traditional TTP PKI) certification authorities (described in the early 90s) and the set of relying parties.
some of this became mute by the mid-90s with the observation that the traditionally considered identity x.509 certificates represented a significant privacy and liability exposure ... and the retrenching by infrastructures to relying-party-only certificates (effectively account number and public key ... although even a relying-party-only SET certificates could represent a factor of 100-times payload bloat). the other issue that quickly became observed if the relying-party and the certification authority were the same .... then the relying party would typically have a large superset of the information that they included in any relying-party-only certificate ... and that having the key-owner to return this small subset of information repeatedly to the relying-party (/certification authority) was redundant and superfluous .... other than possibly contributing huge computational and transmission overheads for no useful purpose.
IETF standards tend to be descriptions of protocol and parties role in the protocol. Such syntactical and semantical description of the protocols has rarely included description of any possible syntactical and semantic business relationships .... especially of the typical kind being proposed in the early 90s for TTP certification authorities.
for pkix references .... see
and click on "Term (term->RFC in the "RFC's listed by" section
then click on "PKI" in the "Acronym fastpath" section.
the current results:
public key infrastructure (PKI)
see also authentication , encryption , public key
3820 3779 3778 3770 3741 3739 3709 3653 3647 3562 3447 3379 3354 3335 3281 3280 3279 3278 3275 3174 3163 3161 3156 3126 3125 3110 3076 3075 3039 3029 2986 2985 2943 2931 2898 2847 2807 2803 2802 2797 2726 2693 2692 2587 2585 2560 2559 2537 2536 2535 2528 2527 2511 2510 2459 2440 2437 2404 2403 2385 2315 2314 2313 2311 2202 2154 2137 2085 2082 2065 2025 2015 1991 1864 1852 1828 1810 1751 1544 1424 1423 1422 1421 1321 1320 1319 1186 1115 1114 1113 1040 clicking on any RFC number will bring up the RFC summary in the lower frame. Clicking on the ".txt" field in the RFC summary will fetch the actual RFC.
Anne & Lynn Wheeler

@_date: 2004-07-23 09:04:33
@_author: Anne & Lynn Wheeler 
@_subject: E-commerce attack imminent; Sudden increase in port scanning for 
E-commerce attack imminent; Sudden increase in port scanning for SSL
doesn't look good.
... aka not necessarily an attack on SSL itself ... but identifying
end-points with open SSL ports as attack targets i.e. end-points with
open SSL ports are likely to be somewhat higher value targets than
machines w/o SSL ports .... since the operators possibly feel they have
something to protect.

@_date: 2004-07-23 12:08:29
@_author: Anne & Lynn Wheeler 
@_subject: E-commerce attack imminent; Sudden increase in port 
i just mentioned that it could possible be (another kind of)
attack/threat model (other than the obvious referenced
in the article).
i wasn't aware that this mailing list would preclude mention
of other possible attack/thread models ....  other than the
obvious ones mentioned.
Anne & Lynn Wheeler

@_date: 2004-07-23 13:34:22
@_author: Anne & Lynn Wheeler 
@_subject: E-commerce attack imminent; Sudden increase in port 
slightly more topic drift w/respect to potential/possible threat models ...
i have put quite a bit of work into security taxonomy as part of the merged securitity glossary and taxonomy
i've relatively recently taken a pass at the cve database ...
but what I found was very little structure. i have done word frequency analysis on the descriptions ... but even that isn't really conclusive (since effectvely random people are generating quite random word descriptions). I was hoping to find more structure for expanding taxonomy for threat models, vulnerabilities, and exploits.
Anne & Lynn Wheeler

@_date: 2004-07-25 13:41:56
@_author: Anne & Lynn Wheeler 
@_subject: dual-use digital signature vulnerabilityastiglic@okiok.com 
one could claim that there might be two possible useage scenarios, involving two different thread models: encryption and authentication.
from a business standpoint the encryption of corporate data (especially data at rest .... which might include some of the corporate jewels) can represent single point of failures ... if private key is required for the recovery of corporate jewels and the private key isn't reliably replicated (to avoid single points of failure); then there is a serious, corporate, overriding availability threat.
the claim can be made that the trade-off for authentication and digital signature would result in no escrow or replication of private key .... since the overriding threat model is a) impersonation and/or b) not being able to reliably attribute certain actions to specific people.
the assertion here is possible threat model confusion when the same exact technology is used for two significantly different business purposes.
.... in general, no key escrow or no key replication is frequently bad in the encryption business process scenario
... while no key escrow or no key replication is good in the authentication/digital signature business process scenario.
a problem arises when the business purpose uses of the public/private key pair isn't sufficiently described ... leading to confusion (and/or the same public/private key pair are used for different business processes with possibly conflicting threat models).
Anne & Lynn Wheeler

@_date: 2004-07-26 14:26:01
@_author: Anne & Lynn Wheeler 
@_subject: dual-use digital signature vulnerabilityastiglic@okiok.com 
I believe there was at least one large institutional effort where
keys were generated, escrowed and loaded into hardware tokens
and distributed. the persons were expected to use the hardware
tokens for both authentication and encryption. if the hardware token
failed (like if the battery died), they could get a new hardware token
issued with the same keys.
the obviously needed the original keys if they had used the hardware
token for encryption (of data that turned out to be laying around
however, it wasn't necessary to have escrowed keys for authentication,
simply issuing a new hardware tokens with new (authentication) keys
would have been sufficient (and reregistering the new public key).
here is an issue where, if they're using hardware tokens for key protection ...
they really need to distinguish between encryption keys and authentication
keys .... either a single hardware token with two different sets of keys ...
and the token knows how to consistently differentiate their use between
encryption and authentication ... or two different hardware tokens ...
consistently used for the different (business) purposes.
there is a side issue with institutional delivered hardware tokens ...
and if they were to replace existing shared-secret pins/passwords ...
where a person might have a hundred unique shared-secrets for
their various electronic relationships .... and potentially be issued
at least one hardware token to be used in lieu of every pin/password
... and potentially a second hardware token for encryption only
purposes (say in dongle form ... a key chain with 100-120 or dongles
... in need of medium sized ruck sack just to lug them around).
Anne & Lynn Wheeler

@_date: 2004-07-28 14:35:42
@_author: Anne & Lynn Wheeler 
@_subject: should you trust CAs? (Re: dual-use digital signature 
in the case of SSL domain name certificates ... it may just mean that somebody has been able to hijack the domain name ... and produce enuf material that convinces the CA to issue a certificate for that domain name. recent thread in sci.crypt
  Convince me that SSL certificates are not a big scam
the common verification used for email address certificates (by certification authorities) ... is to send something to that email address with some sort of "secret" instructions. so the threat model is some sort of attack on email from the CA ... snarf the user's ISP/webmail password and intercept the CA verification email.  (it simply falls within all the various forms of identity theft ... and probably significantly simpler than getting a fraudulent driver's license). with the defense that it is possibly another form of identity theft .... say you ever actually stumbled across such a fraudulently issued certificate .... it would probably be difficult to prove whether or not the certification authority was actually involved in any collusion. even discounting that there is no inter-CA certificate duplicate issuing verification .... there are enuf failure scenarios for public/private keys .... that somebody could even convince the same CA to issue a new certificate for the same email address (even assuming that they bothered to check)
Anne & Lynn Wheeler

@_date: 2004-06-01 12:06:00
@_author: Anne & Lynn Wheeler 
@_subject: Yahoo releases internet standard draft for using DNS as 
this may or may not be my KISS authentication thread.
mid-90s, some number of financial institutions retrenched from x.509 identity certificates to simple relying-party-only certificates ... because of enormous privacy issues regarding blanketing the world with privacy information contained in identity certificates.
however, they were still looking at taking a 60-80 bytes payment message, attaching a 128byte digital signature, and then attaching a 4k byte to 12k byte relying-party-only certificate ... and sending it back to the financial institution that issued the certificate. this is not counting any ASN.1 encoding that might have been done which then possiby includes a bunch more bytes. note that standard payment message message has been around some 30 years carefully crafted as simple 7bit ascii w/o any addition encoding requirements. the purpose of the certificate was to carry the account number ... which was also included in the signed payment message ... and the public key ... which was stored in the account record back at the financial institution that was receiving the transmission and had originally issued the relying-party-only certificate.
so the financial institution receives this new payment object, retrieves the account number from the (signed) payment message and uses the public key in the account record to verify the signature ... w/o ever resorting to the certificate. So we have a payload bloat of one hundred times ... in order to carry a certificate that is redundant and superfluous and never used.
so x9.59 was fairly carefully crafted to add a 42byte ECC signature to a standard 60-80byte payment message. any special encoding to carry 42byte ecc 8bit in 7bit transmission at worst doubled the signature payload size.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2004-06-03 20:44:32
@_author: Anne & Lynn Wheeler 
@_subject: The future of security 
minor ref:
Hospital Adopts PGP Universal For HIPAA Compliance

@_date: 2004-06-06 13:54:01
@_author: Anne & Lynn Wheeler 
@_subject: Article on passwords in Wired News 
there is two factor authentication:
* something you have
* something you know
in this scenario we could conclude there are are a least
3-4  types of "something you know" authentication.
* re-usable "shared-secret", things like run-of-the-mill
account numbers .. where knowing the account number is
sufficient to perform a fraudulent transaction. these are
extremely attractive to criminals ... because merchants
tend to aggregate them in transaction files ... so a single
theft of the transaction file could represent an extremely
huge return-on-investment (benefit/risk trade-off). some past
discussion of this with regard to security proportional
to risk:
* shared-secret, one-time account numbers. this is
a fairly adequate counter-measure for the major fraud
scenario ... harvesting merchant account files. there
can still thefts/copying of individual account sheets,
just like there can be thefts of individual cards. note
however that the benefit/risk of individual thefts is
orders of magnitude less than the merchant transaction
file harvesting. as per the above url discussion of
security vis-a-vis risk ... harvesting a merchant account
file of re-usable account numbers may represent a $50m
exposure ... and hundreds of thousands of dollars
expense to a bank to block the affected accounts and
re-issue new cards. one time numbers may represent
little or no countermeasure to the individual vulnerability
.... but it represents a countermeasure for the aggregate
vulnerability that is several orders of magnitude larger
and more expensive
* something you have cards ... that are supposedly
hard to counterfeit ... but changing technology over
the years have made them more and more vulnerable,
PINs with most of these existing cards have been
somewhat "something you know" shared secret ...
i.e. some flavor of it is transmitted to the financial
institution. skimming technology captures the
magstripe value as well as the entered PIN;
counterfeit cards are then manufactored ... along
with notation regarding the correct pin. this
skimming also relies on re-useable values ... and
skimming operations can be setup and automated
to capture tends of thousands
* newer generation of something you have cards
with embedded chips and non-shared secret
PINs ... i.e. the correct PIN has to be sent
to the chip ... before the chip performs the
correct operation. Some of these have acquired
the "yes card" label in some parts of euro-press.
transaction information is skimmed  ... sufficient
to create a counterfeit chip-card. these counterfeit
chip-cards answer "yes" to everything ... i.e.
whether the pin entered was correct, whether the
transaction value is less than limit, etc. again
the skimming process has been automated,
allowing the capture of information for potentially
thousands of counterfeit cards (the skimming
can be identical to that used with magstripe cards).
Anne & Lynn Wheeler

@_date: 2004-05-08 15:36:16
@_author: Anne & Lynn Wheeler 
@_subject: The future of security 
at the nist pki r&d workship (mentioned elsewhere in some other post
in this mailing list) there was discussion of 1) using private key signing for things like signature (like in human
signature) agreement/authorization as opposed to straight
authentication. one of the issues is that if you ever use a private key
to digitally some random challenge/response data in a authentication
paradigm ... you might be at risk ever using the same private key for
signature purposes ... since it might be possible that some of the
random data you may have signed might not have been truely random after
2) naked public keys ... aka w/o certificates at all
3) and in some of the breaks the certificate use in payment
transactions. sort of two issues in payment transactions were/are a)
privacy and b) size bloat. in the mid-90s, the traditional x.509
identity certificate from the early 90s was drastically cut back to
relying-party-only, "account number" certificate because of privacy
issues with identity information. The work on certificate-based
financial transaction started with taking a 60-80 byte payment
transaction, instead of ISO8583, using ASN.1 encoding to blow it up to
200-300 bytes; added a 128-byte RSA signature (then adding in the ASN.1
encoding) and a relying-party-only certificate that typically ran 4k-12k
bytes; having starting from a 60byte normal transaction, the
certificate-based stuff would blow it up by factor of one hundred times
to 6k to 12k bytes. The certificate was totally redundant and
superfluous since the financial institution was the relying party and
already had all the information. In the X9.59 work it was observed that
it was possible to encode an ECDSA signature in an ISO8583 transaction
in 42 bytes ... so absolute minimum for authenticated payment
transaction would go from 60 bytes to a little over 100 bytes ... w/o
throwing in a bunch of extraneous, duplicated and/or superfluous data
that provided absolutely no added value (the payment transaction still
contained the same data, digital signature authentication was added ...
and all the payload carried in a certificate was totally redundant and
superfluous since the relying-party had a superset). It isn't exactly
that payment security requirements have to be proportional to the cost
of certificate security ... it was that certificate security increased
the payload costs by a factor of one hundred times and provided NO added
some of my further observations about mixing authentication signing and
signature signing ... as well as nature of naked public keys ...
recently posted to thread in sci.crypt:
 Soft signatures
and "the future of security" ... somewhat orthogonal to cryptography ...
there was recently a letter from NSF to some former multician that was
posted to the alt.os.multics n.g. that started a thread on (not
necessarily crypto) system security (and multics never having been
broken). a couple posts in the thread
 NSF itnerest in Multics
 NSF itnerest in Multics

@_date: 2004-05-26 09:51:01
@_author: Anne & Lynn Wheeler 
@_subject: The future of security  
one of the issues has been that many crypto security solutions have been oriented towards hiding information. that may work with outsiders ... but traditionally, 90percent of fraud has been insiders ... and recent news last friday about study to be published was that interviewing something like 1000 people involved in identity theft cases ... it was determined that at least 70percent had some sort of employee involvement.
in that sense ... the internet and introduction of the possibility of outsider related fraud ... has distracted/obfuscating focus from the real, long standing issues.
my repeated observation that current generation of desktop systems were originally introduced to operate in a standalone environment where applications could be introduced that freely took over the whole machine. attempting to continue to satisfy the standalone ... total take-over requirements at the same time using the same platform for generalized interconnect to an increasingly hostile environment creates some diametrically opposing objectives.
there have been some number of time-sharing systems from the 60s & 70s that were designed from the ground up to handle multiple, concurrent users that potentially had conflicting, competitive, and/or opposing objectives (say multiple users from competing corporations and industrial secrets might be involved). these systems with designed in security from the ground-up have shown to be immune to many of the current day vulnerabilities and exploits. to some extent, there could be valid claims about attempts to use cryptography as bandaids to address fundamentally flawed infrastructures (or at least infrastructures that were specifically designed to not handle many of the existing situations that they have been used for) ... aka lets use bandaids to treat strep infections.
Anne & Lynn Wheeler

@_date: 2004-05-28 10:44:17
@_author: Anne & Lynn Wheeler 
@_subject: The future of security 
the caveat to that is many of the infected machines were originally infected by spam with spoofed origin ... somehow convincing users to click on something. authentication would help somewhat with that ... and, in fact, some of the spam being sent out by the infected machines, in turn uses spoofed origin. authentication might also help address the identity-theft oriented spam ... claiming to be your bank and needing personal information.
it doesn't help with ... click on this to get the latest, greatest game ... where there isn't any attention at all paid to the origin ... just looking for instant gratification.
the 60s/70s time-sharing systems nominally had some assurance applied to the introduction of executables into the environment. this is my comment about the desktop systems having diametrically opposing requirements ... the original design point of totally unconnected, stand alone environment where an introduced executable could take over the whole machine ... and at the same time fully wired to an increasingly hostile environment needing signficant safeguards and processes associated with assurance of introduced executables. the intermediate step was that some of these stand-alone machines acquired interconnect capability for a local, safe, isolated departmental/office network. This had hardly any restricted execution and access capability ... again not worrying about protection against a hostile and unsafe operation.
the shared environment analogy is highway traffic and rules about operating an unsafe vehicle could result in both having your license revoked and the vehicle confiscated (it doesn't require the driver to be a highly trained car mechanic ... it just holds the driver responsible).
connecting systems that were designed for fundamentally safe and isolated environment to wide-open anarchy hostile operation exposes all sorts of problems. somewhat analogous to not actually needing a helmet for riding a motorcycle ... or seat belts and airbags to drive a car.
Anne & Lynn Wheeler

@_date: 2004-10-19 15:10:50
@_author: Anne & Lynn Wheeler 
@_subject: New IBM Thinkpad includes biometrics 
one of the market targets of biometrics has been those that write their
password on their machine (or don't even bother with a password).
in the past, it seems that biometrics have tried to make a big thing of
how much more secure that it might be than passwords ... in part because
it was so much more expensive. however, "significantly more secure than passwords" ... doesn't
necessarily have to be the market target.

@_date: 2004-10-28 12:21:32
@_author: Anne & Lynn Wheeler 
@_subject: Financial identity is *dangerous*? (was re: Fake 
my claim about the paradigm is that during the 80s, there was start of lot of investment by all sorts of parties into smartcards ... targeted for the portable computing market niche ... where the state of the art would allow relatively powerful computing and memory in such chips ... but the technology didn't exist for portable input/output technology .... as a result there also had to be ISO international standards for the input/output stations that would interoperate with the smartcards. that market niche started to disappear in the early 90s with the appearance of portable input/output technology associated with cellphones and PDAs. by this time, at least several billion dollars had been invested in the somewhat to recoup (at least some portion of) the investment, there has been some searching for alternative market niches for the
technology. In the early 90s, my wife and I consulted to some agencies on aspects of this. one such target was emergency medical information .... a person could carry their complete medical records in such a form factor .... and in a life&death emergency .... the emergency crews could pull out the victims card and insert it into their locak, offline, portable display technology and have access to the victims complete medical records. The problem in this scenario was that an emergency first responder isn't likely to be able to make use of the victims medical records in offline manner. First off, if it is a real emergency ... how does a first responder do other than triage. Typically for anything that involves anything more complicated ... the first responder has to go online to "real" doctors at some remote location. If you have a real online environment ... to real (remote) doctors ... then a much better solution is to have something that authenticates the victim ... and the consulting doctor then has some mechanism for locating and retrieving the online medical records (as opposed to first responder being able to make sense out of a victim's complete medical records).
Another niche for the technology was offline financial transactions ... for parts of the world where online connectivity was difficult, non-existent and/or extremely expensive. the smartcard would contain the business rules and logic for performing (offline) financial transaction interacting with random merchant terminals. Two issues arise here .... there is a significant mutual suspicion (lack of trust) problem between random merchant terminals anywhere in the world and random consumer smartcards anywhere in the world; and the technology started to be deployed at a time when online connectivity was starting to become ubiquitous and easily available in most places in the world. An example is the european deployed stored-value (offline) smartcards in the 90s compared to the rapid market penetration of stored-value (online) magstripe (gift, affinity, merchant, etc) cards in the US .... making use of the ubiquitous nature of online connectivity available in the US. Again, which the availability of online .... the problem changes from requiring a very expensive and trusted distributed offline infrastructure and offline distributed business rules  .... to the much more simple problem of requiring (increasingly strong) authentication.
So the financial oriented infrastructure has seen some amount of "skimming" threats and exploits with the terminals and/or networks. Even if the smartcard paradigm is just reduced to a (dumb) chipcard that only provides strong authentication .... the issue is does the consumer completely provide their own environment ... or do they have to depend on (and trust) randomly located terminals at random locations around the world.
Part of the authentication issue ... is the 3-factor authentication model
* something you have
* something you know
* something you are
the "card" (or chip) provides the "something you have" piece.
in order to add "something you know" ... requires the consumer entering a pin or password; the issue then becomes does the consumer trust some randomly located pin-pad. there is a similar issue with whether the consumer trust their own biometric sensor or would they trust somebody else's biometric sensor.
a consumer owned cell phone .... could presumably provide both a consumer trusted pin-pad ... and w/o a whole lot of magic ... a consumer camera cell phone could be used for sensor for various kinds of biometric info.
some part of the issue is that the original target market niche for smartcards (portable computing with fixed interoperable input/output stations) started to evaporate after a lot of the investment had been done but before there was a lot of deployment and investment recovery.
Anne & Lynn Wheeler

@_date: 2004-10-29 07:55:07
@_author: Anne & Lynn Wheeler 
@_subject: Financial identity is *dangerous*? (was re: Fake 
there are a couple different trust relationships ... the issue of the user trusting the keyboard/terminal ... and the issue of the relying party trusting the keyboard/terminal.
The FINREAD terminal ... misc. (EU) finread references:
supposedly is certified as an stand-alone external keypad and display that can't (very difficult) in being hacked. the financial scenario is that the display can be trusted to display the amount being approved .... the user puts in his card and enters their pin/password. The pin-pad is certified as not being subject to virus keyloggers (that you might find if a PC keyboard was being used).
For the relying party (say an online financial institution) ... the user putting their card into the reader ... and the card generating some unique value ... would indicate to the relying party "something you have" authentication. The user entering a PIN can both indicate "something you know" authentication as well as implying that the user aggrees/approves with the value in the display.
Note that the implied agreement/approval ... in not just dependent on the user entering the PIN ... but also on the certification of the terminal ... that the terminal doesn't accept the PIN until after the certified terminal displays the correct value (i.e. there is a certified business process The entering of the PIN can also involving transmitting some form of the PIN to the relying party ... and/or the PIN is passed to the smartcard/chip ... and the chip is known to only operate in the appropriate manner when the correct PIN is entered. In this later case, the relying party doesn't actually have knowledge of the "something you know" authentication .... but the relying party can infer it based on knowing the certified business process operation of all of the components.
Lets say the unique value provided by the smartcard is some form of digital signature ... and the relying party infers from the correct digitial signature "something you have" authentication. There is still the trust issue between the relying party and the terminal used by the user .... which may also require that the (certified eu finread) terminal also performs a digital signature .... in order for the relying party to be able to trust that it really was a terminal of specific characteristics ... as opposed to some counterfeit or lower-trusted terminal.
There is still the issue of the user trusting such a terminal. If the terminal belongs to the user .... in the user physical home space .... then there isn't as much of a trust issue regarding the user trusting the terminal.
The problem arises for the user if they are faced with using a terminal in some random, unsecured location some place in the world. Even in the situation where a relying party receives a valid transaction with a valid digital signature from a certified, known finread terminal ... there are still a number of MITM attacks on finread terminals that might be located in unsecured locations (various kinds of overlays and/or intermediate boxes capable of performing keylogging and/or modified display presentation).
The personal cellphone and/or PDA ... with user "owned" display and key entry .... is a countermeasure to various kinds of MITM attacks on terminals in public &/or unsecured locations
(user has no way of easily proofing that they aren't faced with some form of compromised terminal environment).
Anne & Lynn Wheeler

@_date: 2004-10-30 10:36:49
@_author: Anne & Lynn Wheeler 
@_subject: Adding reliability and trust to smartcards 
IST Results -   Adding reliability and trust to smartcards
of course ... reliability and trust is more than just the smartcards ... it assurance and trust related to the smartcard infrastructre ... not just the cards themselves.
recent posting on eal5 evaluation, somewhat related
 EAL5
other parts of the thread
 EAL5
 EAL5
semi-related posts about infrastructure
 Financial identity is *dangerous*? (was re: Fake companies, real money)
 Financial identity is *dangerous*? (was re: Fake companies, real money)
Anne & Lynn Wheeler

@_date: 2004-09-13 13:16:17
@_author: Anne & Lynn Wheeler 
@_subject: [anonsec] Re: potential new IETF WG on anonymous IPSec 
i've referred to it as identity agnostic ... as opposed to anonymous ... even with public key use. the scenario is that the original identity x.509  certificates created huge privacy issues.
the the current credit card scenario, it carries a name ... in theory so  that the merchant or point-of-sale can cross-check the name against additional forms of identification .... as a means of authentication (where the merchant is sort of a stand-in agent for the consumer's financial institution .... even tho the merchant and the consumer's financial institution may have significantly different and possibly opposing interests). in effect it is transforming something that should be purely an authentication operation (is the entity entitled to perform a transaction for the account) into a much more difficult (and privacy invasive) identification operation.
the x9.59 scenario .... is that the transaction is simply authenticated with a digital signature that the merchant passes thru to the consumer's financial institution. the consumer financial institution verifies the digital signature with public key on file for that account.  the verification of the digital signature implies some form of "something you have" authentication (implies that you uniquely have the corresponding private key).
it becomes a straight-forward authentication operation and identity agnostic ... w/o the horrible identity and privacy invasive that can accompany a x.509 identity certificate.
while it may be possible for various agents to associated the authentication operation .... the operations themselves, at least don't carry the possibly mandatory identity information & privacy invasive information that can be found in identity x.509 certificates.
Anne & Lynn Wheeler

@_date: 2004-09-15 18:54:11
@_author: Anne & Lynn Wheeler 
@_subject: public-key: the wrong model for email? 
there are (at least) 2-3 characteristics of various public key systems
1) the public key doesn't have to be kept confidential as part of the 2) you don't need a unique key for every unique security &/or business domain
3) other parties can attest to any bindings between the public key and other characteristics
however, while the fact that public key secrecy isn't required (vis-a-vis secret keys) ... and possibly enables one or more of the mentioned characteristics, public key operation doesn't mandate all such characteristics be mandatory for the use of public keys.
PGP allows that a relying party vet a public key with the key owner and/or vet the key with one or more others (web-of-trust)
note that while public key alleviates the requirement that a key be distributed with secrecy ... it doesn't eliminate the requirement that the public key have some trust characteristic associated (i.e. secrecy will tend to include some trust, but elimination of secrecy doesn't eliminate the requirement for trust).
so an infrastructure analogy to physical mail for public key .... is that public key becomes the trusted address for the recipient. in the physical world ... to send some mail ... you need a trusted mailing address for the recipient ... you need to have acquired that address in some manner and furthermore have some trust that it is the correct address. so lets assume that some number of equivalent mechanisms exist for public keys. it so happens that the encryption of the contents with the public key and the addressing of the contents with that same public key .... has some associated trusted infrastructure that delivers the package to the correct lets say that instead of having personal zip-codes and personal cell-phone numbers (that you take with you regardless of the service and/or physical location)... that can reach you regardless of where you happen to be in the world ....  the "number" that can be guaranteed to reach you, also happens to have the characteristics of a public key.
so public key mapping to entity infrastructures take on similar characteristics as personal (physical) mailing addresses and/or personal cell-phone numbers ... and then you have trusted infrastructures (usps, telephone companies, gov. posts) that can be relied on to make the connection to the appropriate recipient .... which then approximates a
public key paradigm mapping to existing physical world paradigms.
in the current physical world infrastructure, the publication &/or distribution of addresses are relatively low-cost (&/or free) operations with the infrastructures making their real money off the delivery ... as opposed to the publication.
translated to the internet paradigm .... everybody has a public key (in much the same way that everybody can have a personal cellphone number that may reach them regardless of where they are in the world). the public key is registered in something like the domain name infrastructure which then is able to figure out how to find you in the world (in manner similar to how personal cellphone number can find you anywhere in the world).
it isn't necessary that public key paradigms have to be the wrong model for email .... it is that the various existing economic models for making money off of public key infrastructures may be inconsistent with normal expected business operations. however, there is nothing intrinsic to public keys that mandate they are tied to existing public key infrastructure economic Anne & Lynn Wheeler

@_date: 2004-09-16 10:42:37
@_author: Anne & Lynn Wheeler 
@_subject: public-key: the wrong model for email? 
the issue then is what level do you trust the recipient, what is the threat model, and what are the countermeasures.
if there is a general trust issue with the recipient (not just their key generating capability) ... then a classified document compromise could happen after it has been transmitted. you may have to do a complete audit & background check of the recipient before any distribution of classified if the threat model is purely the document transmission, and you worry only about the recipient's key generating capability being up to the task of protecting the document transmission ... but you otherwise aren't worried about other trust issues with the recipient ... then go for 3rd party secure transmission service ... say where the encrypted package is delivered to the recipient and the recipient has to do some sort of real-time retrieval from the 3rd party of the package encryption key.
in the physical world ... there still could be the issue that the delivery address for the recipient (to be used by the 3rd party delivery service) might not be trusted.
part of the problem with introducing trust issues involving any specific recipient issue starts a real slippery slope  .... since the security of the system is all of the infrastructure .... and just addressing a single recipient trust issue (like key generation strength) .... still leaves open all sorts of other recipient trust issues.
say you have 3rd party encryption and secure delivery ...  with the possibility that the electronic package might be evesdropped (copied but not decoded). the issue then is how does the 3rd party know that the correct recipient is the only one that obtains the correct decryption key. there has to be some trust at some point that the correct recipient and only the correct recipient can decode any encrypted electronic package. at some point there has to be some flavor of trusting some sort of recipient authentication mechanism.
either the sender has it before hand (like the recipient's public key) or there is some sort of post-transmission authentication of the recipient. eliminating the requirement for strong authentication of the recipient before the transmission doesn't really eliminate the problem, it just moves it to some point.
Anne & Lynn Wheeler

@_date: 2004-09-17 09:11:05
@_author: Anne & Lynn Wheeler 
@_subject: public-key: the wrong model for email? 
note there is still the issue of knowing it is bob ... whether before the "transmission" or after the "transmission" .... and, in fact, the "transmission" itself is somewhat arbitrary.
in the physical world ... the base point is that the sender pays to physically transmit something. there is threat model of taking physical possession of whatever is being transmitted. they then pay extra for countermeasures wrong person taking physical possession. they also pay extra for extra care in delivery to the correct person.
the current electronic world ... the base point is that the sender doesn't actually pay per transmission. with encryption, the threat model is changed to possession of the unencrypted information. encryption (shared-secret or digital signatures) is also used to help with the issue of "delivery" to the correct person (although the convention is converted to the correct person decrypts the data).
so what is the difference between the sender setting up facility so that "when bob shows up" .... bob gets a decrypted version .... and say sending a version to some trusted 3rd party that is encrypted with the 3rd party's key ... and direction to only let bob have it when bob shows up. how does the 3rd party know its bob ... any better than the originating sender? note also in standard ssl ... the recipient generates a random symmetric key and sends it to the server, encrypted with the server's public key. there is nothing about how the server knows that the bob making the contact ... and the bob that is suppose to receive the information .... is the same entity.
so the 3rd party keeps the pre-transmitted encrypted stuff with directions to only give it to any entity that shows the magic something (the movie stuff about tearing a bill in half and the person needs to have the appropriate torn half).  the 3rd party holds it until bob contacts the sender and gets the magic something ... which they they can give to the 3rd party. given the nature of electronic transmission ... is that really substantially different than the sender waiting until bob contacts them before doing the original transmission.
if it is purely electronic world ... how does the sender get the necessary information to the correct bob ... so that the correct bob can give the stuff to the 3rd party ... to proove that they are the correct bob.
so possibly the only distinction ... is that the email communication between bob and the sender is non-real-time ... and the SSL communication is considered possibly real-time .... so the scenario isn't actually the information being transmitted between the sender and bob that is the issue ... it is possibly the mechanics of real-time vis-a-vis non-realtime?
so the sender at some point has to trust bob's authentication information (whether directly and/or outsourced to 3rd party) ... say digital signature public key and may or may not trust that same key for encryption.
common pgp flow ... which effectively is the same as ssl ....  same process steps ... but possibly not in real time. sender looks up in some directory the contact information for bob,
this directory is trusted to map the contact process for bob to bob .... the directory may or may not also provide some authentication information for bob.  if the sender doesn't have authentication information for bob ... they send message to bob requesting authentication information. when they get that back, they vet the authentication information before using it to make sure it is actually for bob. so now they have a process which has some assurance of contacting bob and some assurance that bob can be authenticated.
this is pretty much true whether the actual sender is responsible for the steps or has been outsourced to some 3rd party.
now the issue is wether or not the authentication information is also trusted to securely protect the classified information during transmission (aka public key).  possible scenario if sender  requires different encryption keys from authentication information:
1) sender sends message to bob saying classifed document is waiting. bob generates secret key, digitally signs it, encrypts it with the senders public key and returns it to the sender. this could be all email exchange ... or possibly combination of email and ssl .... it could also be directly with the sender or a 3rd party agent on the sender's behalf.
2) the sender decrypts bob's message, validates the digital signature, encrypts the classified information with bob's secret key and sends the information to bob. the sender's process can be email or ssl ... and can either directly be the sender ... or a 3rd party acting on the sender's behalf.
for efficiency purposes .... the acquisition of bob's authentication information and possible encryption key might be collapsed into single round trip. sender (or 3rd party on sender's behalf) send bob a message that they need both bob's authentication information .... as well as a digitally signed, randomly generated secret key ... which is encrypted with the supplied public key. the sender/3rd party then has to vet bob's authentication information .... before using the randomly generated secret key. again, the exchange could be purely non-real-time email .... or combination of email and real-time ssl.
sort of practical issues:
given that the electronic paradigm have enuf differences from the physical world sending model (i.e. sender doesn't pay in the base case) .... can sender's be induced to pay 3rd party to outsource some of the operations?
given that the there are some number of other vulnerabilities and exploits in the overall infrastructure .... is the treat model specifically to trusting bob's public key for both authentication and confidential transmission .... sufficient to impose the extra processes (and/or convince sender's that they need to pay extra money for outsourcing to 3rd parties).
since the paradigm issue of securely transmitted has changed from secure physical movement to safe encryption .... a 3rd party may only have to provide a business of assuring recipients'  public keys for "safe" transmission (as opposed to actually doing the transmission). everybody gets to generate their own public/private key pair for authentication. the same key pair is not used for both authentication and encryption. people may also generate their own encryption key pair.
senders either trust a recipient's encryption key pair ... or they don't. if the sender doesn't trust a recipient's encryption key pair .... they ask for a encryption public key that has been issued by a trusted 3rd party ... and for which the 3rd party is willing to attest to. there is an issue of how the issued private key has gotten to the recipient ... but that isn't a whole lot of difference than the process of a recipient exchanging a real secret key for transmission. there is an issue of whether or not the recipient has continued to protect the encryption private key .... but that isn't a whole lot difference than whether or not the recipient has the facility to protect the unencrypted classified document (once they receive it).
the physical world has the sender outsourcing and paying for the actual secure physical movement .... and some assurance that it only goes to the intended recipient. translated to the electronic world ... the paradigm has been changed to the use of encryption to make sure wrong people don't have the unencrypted version ... and various kinds of authentication processes. so the critical processes has changed not from the actual movement of the data ... but the encryption process "gatekeepers" .... aka the integrity and management of keys used for authentication and decryption. so rather than focus on the actual electronic transmission processes .... focus on the issues related to the keys.
Anne & Lynn Wheeler

@_date: 2004-09-17 09:11:05
@_author: Anne & Lynn Wheeler 
@_subject: public-key: the wrong model for email? 
note there is still the issue of knowing it is bob ... whether before the "transmission" or after the "transmission" .... and, in fact, the "transmission" itself is somewhat arbitrary.
in the physical world ... the base point is that the sender pays to physically transmit something. there is threat model of taking physical possession of whatever is being transmitted. they then pay extra for countermeasures wrong person taking physical possession. they also pay extra for extra care in delivery to the correct person.
the current electronic world ... the base point is that the sender doesn't actually pay per transmission. with encryption, the threat model is changed to possession of the unencrypted information. encryption (shared-secret or digital signatures) is also used to help with the issue of "delivery" to the correct person (although the convention is converted to the correct person decrypts the data).
so what is the difference between the sender setting up facility so that "when bob shows up" .... bob gets a decrypted version .... and say sending a version to some trusted 3rd party that is encrypted with the 3rd party's key ... and direction to only let bob have it when bob shows up. how does the 3rd party know its bob ... any better than the originating sender? note also in standard ssl ... the recipient generates a random symmetric key and sends it to the server, encrypted with the server's public key. there is nothing about how the server knows that the bob making the contact ... and the bob that is suppose to receive the information .... is the same entity.
so the 3rd party keeps the pre-transmitted encrypted stuff with directions to only give it to any entity that shows the magic something (the movie stuff about tearing a bill in half and the person needs to have the appropriate torn half).  the 3rd party holds it until bob contacts the sender and gets the magic something ... which they they can give to the 3rd party. given the nature of electronic transmission ... is that really substantially different than the sender waiting until bob contacts them before doing the original transmission.
if it is purely electronic world ... how does the sender get the necessary information to the correct bob ... so that the correct bob can give the stuff to the 3rd party ... to proove that they are the correct bob.
so possibly the only distinction ... is that the email communication between bob and the sender is non-real-time ... and the SSL communication is considered possibly real-time .... so the scenario isn't actually the information being transmitted between the sender and bob that is the issue ... it is possibly the mechanics of real-time vis-a-vis non-realtime?
so the sender at some point has to trust bob's authentication information (whether directly and/or outsourced to 3rd party) ... say digital signature public key and may or may not trust that same key for encryption.
common pgp flow ... which effectively is the same as ssl ....  same process steps ... but possibly not in real time. sender looks up in some directory the contact information for bob,
this directory is trusted to map the contact process for bob to bob .... the directory may or may not also provide some authentication information for bob.  if the sender doesn't have authentication information for bob ... they send message to bob requesting authentication information. when they get that back, they vet the authentication information before using it to make sure it is actually for bob. so now they have a process which has some assurance of contacting bob and some assurance that bob can be authenticated.
this is pretty much true whether the actual sender is responsible for the steps or has been outsourced to some 3rd party.
now the issue is wether or not the authentication information is also trusted to securely protect the classified information during transmission (aka public key).  possible scenario if sender  requires different encryption keys from authentication information:
1) sender sends message to bob saying classifed document is waiting. bob generates secret key, digitally signs it, encrypts it with the senders public key and returns it to the sender. this could be all email exchange ... or possibly combination of email and ssl .... it could also be directly with the sender or a 3rd party agent on the sender's behalf.
2) the sender decrypts bob's message, validates the digital signature, encrypts the classified information with bob's secret key and sends the information to bob. the sender's process can be email or ssl ... and can either directly be the sender ... or a 3rd party acting on the sender's behalf.
for efficiency purposes .... the acquisition of bob's authentication information and possible encryption key might be collapsed into single round trip. sender (or 3rd party on sender's behalf) send bob a message that they need both bob's authentication information .... as well as a digitally signed, randomly generated secret key ... which is encrypted with the supplied public key. the sender/3rd party then has to vet bob's authentication information .... before using the randomly generated secret key. again, the exchange could be purely non-real-time email .... or combination of email and real-time ssl.
sort of practical issues:
given that the electronic paradigm have enuf differences from the physical world sending model (i.e. sender doesn't pay in the base case) .... can sender's be induced to pay 3rd party to outsource some of the operations?
given that the there are some number of other vulnerabilities and exploits in the overall infrastructure .... is the treat model specifically to trusting bob's public key for both authentication and confidential transmission .... sufficient to impose the extra processes (and/or convince sender's that they need to pay extra money for outsourcing to 3rd parties).
since the paradigm issue of securely transmitted has changed from secure physical movement to safe encryption .... a 3rd party may only have to provide a business of assuring recipients'  public keys for "safe" transmission (as opposed to actually doing the transmission). everybody gets to generate their own public/private key pair for authentication. the same key pair is not used for both authentication and encryption. people may also generate their own encryption key pair.
senders either trust a recipient's encryption key pair ... or they don't. if the sender doesn't trust a recipient's encryption key pair .... they ask for a encryption public key that has been issued by a trusted 3rd party ... and for which the 3rd party is willing to attest to. there is an issue of how the issued private key has gotten to the recipient ... but that isn't a whole lot of difference than the process of a recipient exchanging a real secret key for transmission. there is an issue of whether or not the recipient has continued to protect the encryption private key .... but that isn't a whole lot difference than whether or not the recipient has the facility to protect the unencrypted classified document (once they receive it).
the physical world has the sender outsourcing and paying for the actual secure physical movement .... and some assurance that it only goes to the intended recipient. translated to the electronic world ... the paradigm has been changed to the use of encryption to make sure wrong people don't have the unencrypted version ... and various kinds of authentication processes. so the critical processes has changed not from the actual movement of the data ... but the encryption process "gatekeepers" .... aka the integrity and management of keys used for authentication and decryption. so rather than focus on the actual electronic transmission processes .... focus on the issues related to the keys.
Anne & Lynn Wheeler

@_date: 2004-09-18 10:19:20
@_author: Anne & Lynn Wheeler 
@_subject: public-key: the wrong model for email? 
a "complete audit and background check" ... would include an audit of the recipient ... not just the recipient person .... but the recipient ... as in the recipient operation.
so given sufficient sender concern, checking might be similar to something that the federal reserve has specified for a fedwire terminal .... although the announcement about allowing fedwire access via the internet has raised some eyebrows. i'm sure that such things don't happen .... but could all the stuff about swift providing internet-oriented services been some the issue for the sender is that they could be concerned about a number of different possible vulnerabilities ... and complete audit and background check would be to try and cover all the bases ... aka the leakage of a classified document wouldn't solely be restricted to technical subversion.
Anne & Lynn Wheeler

@_date: 2004-09-20 16:07:55
@_author: Anne & Lynn Wheeler 
@_subject: Academics locked out by tight visa controls 
in '94 there was report (possibly sjmn?) that said at least half of all cal. univ. tech. PHDs were awarded to foreign born. during some of the tech green card discussions in the late '90s ... it was pointed out that the internet boom (bubble) was heavily dependent on all these foreign born .... since there was hardly enuf born in the usa to meet the demand.
in the late 90s there were some reports that many of these graduates had their education paid by their gov. with directions to enter an us company in strategic high tech areas for 4-8 years .... and then return home as tech transfer effort. i was told in the late 90s about one optical computing group in a high tech operation .... where all members of the group fell into this category (foreign born with obligation to return home after some period).
another complicating factor competing for resources during the late 90s high-tech, internet boom (bubble?) period was the significant resource requirement for y2k remediation efforts.
nsf had recent study on part of this
graduate enrollment in science and engineering fields reaches new peak; 1st time enrollment of foreign students drops
Anne & Lynn Wheeler

@_date: 2004-09-27 12:58:31
@_author: Anne & Lynn Wheeler 
@_subject: An interesting "new" computer security problem 
note that was being done with virtual machines in the 60s .... well before the orange book
there were also a number of commercial time-sharing companies offering services based on virtual machine technology where possibly mutually antagonistic clients were using the services.
we had a service that had some of the most sensitive corporate secrets there were .... on the same machine with all sorts of BU, MIT, and harvard random past references to some of the in-house as well as commerical (virtual machine based) time-sharing services from the 60s & 70s:
Anne & Lynn Wheeler

@_date: 2005-08-03 10:25:27
@_author: Anne & Lynn Wheeler 
@_subject: [Clips] Online ID Thieves Exploit Lax ATM Security 
two-factor authentication nominal objective is to have different
vulnerabilities, i.e. PINs ("something you know") is nominally
countermeasure to lost/stolen cards ("something you have").
However, skimming exploits can copy both magstripe and pin for
producing a counterfeit magstripe card that can be used with stolen
PIN (common vulnerability) ... minor reference found with search
The phishing vulnerability can steal both account number and PIN for
producing counterfeit magstripe card for use with the stolen pin; again,
common vulnerability defeating objective of using two-factor authentication.
back in the dark ages there were attacks on magstripe credit cards that
used the algorithms for valid account numbers to generate counterfeit
magstripe credit cards. magstripes then acquired effectively a kind of
hash code as countermeasure to counterfeit mastripes with algorithm
generated account numbers. this turns out to also be a countermeasure
for counterfeit magstripe credit cards that have been created from
phished account number (however this isn't a countermeasure to skimmed
magstripe exploit that produces counterfeit magstripe with all the exact
information). description of magstripe (and descretionary data field)
PINs have also been used as countermeasure to counterfeit magstripe
debit cards ... possibly based on assumption that counterfeit debit
magstripe from phishing exploits were similar threat to lost/stolen
card. However, this isn't a effective countermeasure when both the PIN
and the account number (magstripe) have a common vulnerability (phishing)
As an aside, a countermeasure for lost/stolen cards is also early
reporting (owner is aware of the missing card). However this is not
applicable to skimmed/phished information since the card owner might not
even be aware that it has happened (until after discovering fraudulent
spate of recent articles on phishing and ATM/debit
Analysts Say ATM Systems Highly Vulnerable To Fraud
Something Phishy's Going On
Analysts Say ATM Systems Highly Vulnerable To Fraud
E-Fraud | Cybercrooks Target ATM And Debit Cards, Steal Billions
Analysts Say ATM Systems Highly Vulnerable To Fraud
Phishers exploiting lax ATM security - Gartner
Banks let phishers get away with $2.75bn
Banks let phishers get away with $2.75bn
Phishing attacks highlight banks' weaknesses
Phishers cash in on ATM cards
ATM Systems Highly Vulnerable

@_date: 2005-08-05 14:24:59
@_author: Anne & Lynn Wheeler 
@_subject: [Clips] Escaping Password Purgatory 
> Hmm.  I came up with the same idea a while back - though with a
note that rfc2289 is one time password
... takes passphrase, a site supplied salt, and iterative hashing.
supposedly this was to allow transmission in the clear and resistance to
man-in-the-middle attacks. the idea was also that the person only had to
remember a single passphrase
however, the following discusses a man-in-the-middle exploit ...
 public key vs passwd
 public key vs passwd
 public key vs passwd
 public key vs passwd
 public key vs passwd
 What 'NSA'?
 Secure web logins w random

@_date: 2005-08-05 14:37:29
@_author: Anne & Lynn Wheeler 
@_subject: Cross logins 
project athena was being funded to the tune of $50m split between dec
and ibm. my wife and I got to go by periodically and review their
projects. on one of the visits we were on the leading edge of working
out the details of kerberos cross-domain operation.
in the following years ... it turns out that the protocol wasn't the big
issue ... it was establishing the business trust between two independent
organizations (not the protocol issues) ... random past kerberos posts
however, maybe two years ago, i saw a presentation on a saml
cross-domain deployment ... that went into some details on the message
flows. I happened to observe that the basic message flows looked exactly
like the kerberos cross-domain message flows (dating back to start of
kerberos cross-domain). first, the person doing the presentation was
surprised that anybody in the audience had ever heard of kerberos ...
and then they finally allowed that their might just be a limited number
of ways of doing cross-domain operation.
saml reference:

@_date: 2005-08-06 09:18:14
@_author: Anne & Lynn Wheeler 
@_subject: [Clips] Does Phil Zimmermann need a clue on VoIP? 
when we were doing this stuff related to e-commerce ... we also had to
go out and audit some number of these certificate issuing institutions.
we frequently explained to them what a service operation was. at the
time, we coined the term *certificate manufactoring* to help
differentiate from a PKI. one of the  largest organization commented
that they thot it was somehow involved computers and technology and
other fancy stuff ... and they were finding out that even simple
*certificate manufactoring* was 95 percent or more bookkeeping,
accounting and paper work. there was frequently questions about how they
might outsource even that little part of service oriented operation.
random past posts on ssl domain name certificates ... some number dating
back to the period of the original payment gateway.
one of the big issues for real businesses with extensive and well
established relationship management infrastructure ... it readily became
apparent that even trivial *certificate manufactoring* operation
represented a significant redundant and superfluous activity ...
unnecessarily duplicating existing business operations.

@_date: 2005-08-06 15:18:19
@_author: Anne & Lynn Wheeler 
@_subject: [Clips] Does Phil Zimmermann need a clue on VoIP? 
oops, finger slip, that should be
... oh, and there are some slightly related postings regarding the
period from another thread:
 Data communications over
telegraph circuits
 Data communications over
telegraph circuits
 Data communications over
telegraph circuits
 Data communications over
telegraph circuits
 Data communications over
telegraph circuits

@_date: 2005-08-06 16:43:41
@_author: Anne & Lynn Wheeler 
@_subject: solving the wrong problem 
some of the work 5-6 years ago on self-serve boarding pass machines were
along the same lines ... it would have to be the same card as used to
purchase the ticket. now it is any card that can be related to you and
your name ... since there is still somebody at the head of the line that
checks that the name on the boarding pass (that was just printed) is the
same name on some gov. issued picture card.

@_date: 2005-08-09 13:08:42
@_author: Anne & Lynn Wheeler 
@_subject: solving the wrong problem 
i've frequently used a metaphor about a bank vault door installed in the
middle of an open field.
 Is cryptography where security
took the wrong branch?
 IEEE article on intelligence
and security
 HELP, Vulnerability in Debit
PIN Encryption security, possibly
 Cracking SSL
the other metaphor is the one about if all you have is a hammer, then
all problems become nails.
and for some of the PKI related ... frequently they start out claiming
the answer is PKI ... before asking what the problem is.
one of the current issues is that some financial operations are using a
value for a userid-like capability and at the same time using the same
value as a password-like capability. userid requires fairly high
security integrity ... aka from PAIN
* privacy
* authentication
* integrity
* non-repudiation
and the userid capability also requires fairly general availability in
order to establish permissions and as the basis for other business
however, the password capability requires very high privacy and
confidentiality. the result is relatively high diametrically opposing
use critiaria ... high integrity and generally available ... vis-a-vis
high confidentiality.
pure encryption might claim that they could meet the high
confidentialilty requirements ... but that then tends to break all the
"generally available" requirements for its userid function (and/or
esposing it in the clear for all its business use operations creates
enormous number of points for the value to leak out)
the fundamental threat model then turns out not to be there isn't enuf
encryption ... the fundamental threat model is a dual-use compromise ...
where the same information is being used to select permissions (aka
userid) and needs to be generally available ... while at the same time
serving as a password (for authentication).

@_date: 2005-08-10 18:33:56
@_author: Anne & Lynn Wheeler 
@_subject: The summer of PKI love 
The annual PKI Deployment Summit at Dartmouth College is becoming a
summer tradition. Universities differ from other large enterprises in
ways that make them bellwethers for IT's future.
... snip ..

@_date: 2005-08-11 12:55:48
@_author: Anne & Lynn Wheeler 
@_subject: How much for a DoD X.509 certificate? 
one might claim that part of this is the lingering affinity to offline
credentials ... when most really secure operations have gone to online
and realtime operations ... leaving any physical object primarily a
feature of "something you have" authentication that might be used in
conjunction with other authentication factors.
the issue of many offline credentials are that they are left over from a
bygone era that is rapidly disappearing, but some of the legacy mindsets
still linger on.
the issue was raised in the mid-90s in financial infrastructures ...
that such offline credentials ... even tho superfluous and redundant (in
a modern online world) wouldn't actually be hurting anything (other than
possibly the out-of-pocket expense to support such operations).
the danger did show up when operations were tempted to use the redundant
and superfluous credential in lieu of doing an actual online operation.

@_date: 2005-08-12 10:43:20
@_author: Anne & Lynn Wheeler 
@_subject: How much for a DoD X.509 certificate? 
> as i understand it, the problem here was that credentials were issued by
the justification for having offline credentials typically has been
because 1) the technology isn't available for doing an online
infrastructure for accessing the real data or 2) the value of the
operation doesn't justify the cost & expense of having a real online
the statement was that most modern day infrastructures have gone to real
online operations where the real information is accessed rather than
substitute offline credential .... this transition has been
1) the online technology to access the real information is becoming more
2) the cost of doing online access to the real information has been
3) many of the security sensitive infrastructures realize that they now
can easily justify any incremental expense of full online operation
(including the additional benefits of being able to analyze activity
across multiple sequences of security related events ... rather than
each individual security event occuring in offline isolation purely
based on the contents of the offline credential).
I've frequently explained the analogy that offline credentials are
basically a read-only cache of the real information stored in a
repository some place. they are a direct analogy (modulo possibly the
read-only characteristics) of distributed cpu cache/memory, distributed
databases, ... any kind of distributed operation where specific
activities go on referencing in isolation the local read-only copy.
so if you physically compare direct access operation to the real
information (including the ability to have a global view of operations
across individual events and be able to re-act and correct in real time)
... vis-a-vis offline, isolated, distributed operation involving the
copies  .... there are a significantly larger number of places that
directly touch the distributed read-only copies which can possibly
result undetected corruption (compared to direct accesses to the real
it isn't that there aren't touch points that can corrupt the real
information ... it is just that there possibly are several orders of
magnitude fewer touch points that can corrupt the real information.
in a PKI, certification authority operations ...
1) the "real information" is the authoritative agency responsible for
the actual information.
2) typically a certification authority then will create its own
repository operation duplicating the real information
3) it creates a certificate containing some subset of the real
information which is relatively freely released to the world.
the issue is that in the real respository  and possibly any
certification authority's shadow  the possible value of criminal
corruption of the real information is a lot higher ... but there tends
to be significantly larger number of security countermeasures against
there being any sort of corruption.
the individual certificate copies released into the wild tends to have
much fewer countermeasures and a much large number of infrastructure
attack points. in the case of the original ... the information is either
correct or it is not correct. in the offline credential copy ... the
offline credential copy can 1) be a copy of incorrect information (from
the original)  or 2) possibly be one of many counterfeit copies
containing fraudulent information.
so the online infrastructure is not concerned about there being
counterfeit copies of the information or ficticious counterfeits (of
information that doesn't even exist at the original) ... because copies
don't exist.
online infrastructure, however is concerned about valid authentication
and the counterfeiting of valid authentication information. i contend
that this is a much narrower exposure than the exposure of having
generalized counterfeit information floating around random locations in
the infrastructure. furthermore, the online infrastructure has much
greater capability for tracking and potentially recognizing counterfeit
authentication operation and furthermore, being able to react to it in
real time.
So somewhat after I was making statements about online infrastructure
having much fewer and narrower corruption points, having more capability
for recognizing compromises (being able to analyze patterns across
multiple security related events) and doing real-time re-acting ...
there started appearing things like OCSP.
However, i claim that if you can do an a real-time, online operation ...
you are incurring the majority of the expense of doing a real-time,
online operation ... and therefor you would have much higher integrity
simply transitioning to a real-time, online operation ... and eliminate
the offline information that is floating around out in the wild.
slightly related recent posting regarding sanity check about whether you
have a fundamental online system or a fundamental offline system ... and
if you have a fundamental online system ... then it is trivial to show
that digital certificates are redundant and superfluous in a fundamental
online system, and if you can show digital certificates are redundant
and superfluous in a fundamental online system ... then you can also
show that certification authorities and PKI  are also redundant and
 X509 digital certificate for
offline situation
 X509 digital certificate for
offline situation
aka ... fundamentally digital certificates were designed to specifically
address the offline situation. frequently the use of digital
certificates in online situations are contrived and results in being
able to trivially show that they are redundant and superfluous.

@_date: 2005-08-12 15:09:51
@_author: Anne & Lynn Wheeler 
@_subject: The summer of PKI love 
PKI deployment to authenticate SSL servers almost doesn't exist.
we were called in to work with this small client/server startup that
wanted to do payments on their server ... and had this technology called
SSL. we had to do a lot of laying out the business ground work for the
payment stuff ... and because they wanted to use SSL for pieces of it
and certification authorities issuing digital certificates were involved
... we also had to go audit the major digital certificate issuing
in the course of doing this ... we coined the term "certificate
manufactoring" to describe what we were finding ... as one way of
differentiating it from the industry accepted definition for PKI.
another place that it came up ... was that we had a SSL encrypted
session defined between webservers (doing payment transactions) and the
payment gateway. special digital certificates were issued for both the
webservers and the payment gateway as part of initializing the encrypted
tunnel (and we forced the implementation of mutual authentication ...
rather than the simple one-way that was available at the time). At this
point it became readily apparent that the digital certificates part of
all this were redundant and superfluous. All the webservers had the
public key of the payment gateway pre-installed in the webserver ... and
the payment gateway had a separate mechanism (once the encrypted tunnel
was set up) for authenticating the webserver (based on established
payment processing conventions). while there was movement of digital
certificates during the setup of this encrypted tunnel ... it was purely
an artificial artifact of the existing code implementation and didn't
actually serve any other useful purpose.
this then resulted in re-examing the design-point and requirements for
digital certificates, certification authorities, and PKI ... which was
to address an introduction issue where a relying party was facing first
time communication with a total stranger and had no access to any other
means for obtaining information (aka the letters of credit model from
the sailing ship days). In situations where there was an established
relationship between the two parties ... it was fairly trivial to
demonstrate that the digital certificates were redundant and superfluous.
so the original justification for server domain name digital
certificates in SSL was
1) key exchange ... which can be done via other mechanism
2) address perceived integrity issues with the domain name
infrastructure so that the user has some level of confidence that the
server they think they are talking to actually is the server they are
talking to.
basically, the browser checks the typed-in URL against the domain name
in the server's certificate. this originally was specified as happening
at the time the user typed in the URL that initially contacted the
server and the SSL session existed for the complete period that the user
interacted with the server.
however, most servers very quickly discovered that SSL operation cut
their thruput by 80-90 percent and so you found e-commerce servers
moving to straight HTTP w/o SSL for the browsing and shopping experience
and providing a "checkout/pay" button that moved into SSL for actual
payment. As been repeated described before this creates a large
vulnerability in the SSL use for real live environments ... since if a
user was initially interacting with a fraudulent site (because SSL
wasn't used for the original typed in URL) ... when the user got to
clicking on the "checkout/pay" button ... a fraudulent site was more
than likely to specify a URL for which they had a valid server domain
name SSL certificate.
the other issue ... is most of the certification authorities in the
world aren't actually the authoritative agency for the information they
are certifying. the actual trust root for many digital certificates ...
are the authoritative agency that the certification authority has to
check with regarding the validaty of the digital certificate application.
Now, it happens that the authoritative agency for domain name ownership,
is the domain name infrastructure ... the very same domain name
infrastructure that has the integrity concerns giving rise to the
requirement for ssl domain name certificates.
so there has been some proposals for improving the integrity of the
domain name infrastructure ... in part from the certification authority
industry so that the certification authority process can better trust
the information that they are certifying.
Part of this proposal is to have domain name owners register their
public key with the domain name infrastructure. Future communication
between the domain name owner and the domain name infrastructure would
be digitally signed and the domain name infrastructure can verify the
digital signature using the on-file public key (note no digital
certificates required)
The other benefit is to the ssl domian name certificatin authority
industry ... they can change an expensive, error-prone, and
time-consuming identification process (matching the identity of the
certificate applicant with the identity of the domain name owner on file
with the domain name infrastructure) into a simpler, less expensive, and
more reliable authentication process (by requiring that certificant
applicants digitally sign their applications and the certification
authority then verify the digital signature by doing a realtime, online
retrieval of the onfile public key).
Of course, this represents a signficant catch22 for the ssl domain name
certification authority industry;
1) if you improve the integrity of the domain name infrastructure it
reduces the requirement for having ssl domain name certificates
2) if the certification authority can base their trust infrastructure on
realtime retrieval of online public keys for authenticating digital
signatures ... it is possible that the rest of the world could also
start doing realtime retrieval of online public keys for authenticating
digital signatures (eliminting the requirement that a webserver needs to
transmit a digital certificate to a relying party in order for them to
verify a digital signature).
One could even imagine an enhanced, optimized hostname->ipaddress
transaction with the domain name infrastructure ... where the ipaddress,
any public key, and other optional information all piggybacked in a
single response. Then the client could do a real, transaction oriented
operation ... they piggyback the encrypted random transaction symmetric
key and the encrypted transaction data in a single transmission (to the
webserver) ... with the webserver being able to do a single transmission
reply. None of the certificate related protocol chatter needs to even
occur ... you have a single round-trip with the domain name
infrastructure (if the information isn't already cached locally) and it
is possible to also have a single tround-trip transmission with the
slightly related post in another thread
 X509 digital certificate for
offline solution
 X509 digital certificate for
offline solution

@_date: 2005-08-17 09:52:14
@_author: Anne & Lynn Wheeler 
@_subject: How many wrongs do you need to make a right? 
basically you can have offline & non-electronic, offline & electronic,
online & non-electronic (maybe null), and online & electronic.
the credit card model of the 60s was a manual credential in an offline
environment (aka offline & non-electronic). they started by mailing
monthly booklets (push model) to all registered merchants, as system
grew, the size of the booklets grew, the number of registered merchants
grew, and the aggregate risk grew ... so they started reducing the risk
window by pushing out booklets more frequently. this was growing
enormously cumbersumb and obviously couldn't continue scalling.
in the 70s, they started deploying an online system and added a
magstripe to the plastic ... the plastic could continue to operate in
the old-fashion offline credential mode ... but the magstripe would act
as "something you have" authentication for the online paradigm (aka
online & electronic). the online infrastructure could scale much easier
as well as significantly reducing the risk and adding function
1) any cancelation was effective immediate for all relying-parties
2) was able to add credit limit function which involved real-time
aggregated information ... which is possible in an online environment
put enormously difficult with offline, stale, static certificates.
3) real-time patterns of use that could indicate other kinds of fraud
or possibly lost/stolen
so long ago and far away ... the payment gateway and e-commerce
added ssl domain name certificates as a countermeasure for various
MITM-attacks (but almost totally "certificate manufactoring" w/o
bothering with revokation)
there were some efforts in the following time-frame that was advocating
consumer PKI digital certificate deployment as a mechanism for moving
electronic payments into the modern world (aka offline & electronic).
I repeatedly observed that the stale, static PKI digital certificate
paradigm actually would regress the electronic payments environment to
the ancient 60s (a fundamental issue was giving up the scallable online
If you went purely with the offline stale, static PKI digital
certificate paradigm you lost 1) scallable immediate concelation for all
relying-parties and 2) credit limit real-time aggregated information,
3) real-time patterns of use.
If you kept the scallable online transaction infrastructure ... it would
be possible to upgrade the magstripe "something you have" authentication
by registering the public key for the account and doing digital
signatures verification (using the onfile public key in the account
record). This kept the online & electronic paradigm with upgrading
the magstripe technology to something that was more counterfeit
but not requiring a certification authority to produce a stale, static,
redundant and superfluous certification for use by other parties..
as I recently posted in another thread
 X509 digital certificate for
offline solution
 X509 digital certificate for
offline solution
that a fundamental characteristic of a PKI certification authority
infrastructure is that the certification authority is certifying the
validity of some information for use by other parties ... where the
other parties lack any means of otherwise determining the validity of
the information aka don't have their own copy and/or don't have online
access to the authoritative agency responsible for the information
and/or don't have online access to a related certification authority.
There was some effort in the mid-90s for relying-party-only certifcates
... where the relying-party registered the public key, stored it in an
account record, generated a digital certificate, stored that in the
account record ... and finally provided the key owner with a copy of the
digital certificate
however, it is trivially shown that such relying-party-only certificates
are redundant and superfluous since the relying-party has both the
original ceritifcate as well as real-time copy of all the related
the other way of looking at it is that this violates the fundamental
requirements justifying the use of PKI digital certificates.
some old posts mentioning PKI digital certificates would be throwing the
payment card industry back into the 60s.
 Who or what to authenticate?
 CFP: PKI research workshop
 CFP: PKI research workshop
 CFP: PKI research workshop
 ALARMED ... Only Mostly Dead
... RIP PKI .. addenda
 Identification = Payment
 The Worth of Verisign's Brand
 The Worth of Verisign's Brand
 The Worth of Verisign's Brand
 More Phishing scams, still no
SSL being used
 More Phishing scams, still no
SSL being used

@_date: 2005-08-17 11:42:21
@_author: Anne & Lynn Wheeler 
@_subject: How many wrongs do you need to make a right? 
as an aside, PKIs have attempted to moved into the no-value market segment.
as internet and online have become more and more ubiquitous the original
offline market segment for PKI has drastically dwindled ... i.e. a
certification authority certifying information and freely distributing
that certified information for the benefit of parties that don't have
access to the information themselves ... i.e. turning them into relying
parties, parties that rely on the digital certificates (certification of
information by certification authorities).
In the past, these relying parties were operations that didn't have
their own information and no capability for contacting any authoritative
agency directly responsible for the information and/or directly
contacting certification authorities. This is my analogy to the the
"letters of credit" from the sailing ship days.
As internet and online have become more and more ubiquitous (as well as
the general decline in dataprocessing costs), situations where parties
don't have their own copy of the information and/or aren't directly able
to contact somebody with the information ... is rapidly disappearing.
What is remaining are operations that still can't justify the cost of
thier own copy of the information (rapidly disappearing with the drastic
decline in the general cost of dataprocessing) and/or can't justify the
cost of directly contacting somebody with the information ... becoming
more and more difficult to find such a market niche as the cost of
online operation is rapdily declining and becoming ubiquitously available.

@_date: 2005-08-25 15:16:01
@_author: Anne & Lynn Wheeler 
@_subject: Another entry in the internet security hall of shame.... 
basically somebody may eventually load the public key from the
self-signed digital certificate into their local trusted public key
repository ... possibly based on some out-of-band trust process.
that isn't any different than almost every certification authority
public key that is in use today. almost every certification authority
public key is represented by some sort of self-signed certificate and is
loaded into the trusted public key repositories of relying parties.
in that sense, it is frequently possible to show (from an information
theory standpoint) that such digital certificates are redundant and
superfluous  ... they however may not be not useful (double negative?)
or may not be unsueful.
given that there exists deployed software that thinks that it requires
some sort of digital certificate in order to perform some processing ...
then even if the digital certificates are redundant and superfluous
(from an information theory standpoint) they can still serve some useful
when attempting to have compatibility with existing deployed software.
recent posting in sci.crypt on slightly related subject

@_date: 2005-08-26 10:24:12
@_author: Anne & Lynn Wheeler 
@_subject: Federal Information Assurance Conference 2005, Oct 25-26 
Federal Information Assurance Conference 2005, Oct 25-26, Univ. of Maryland
and one of the sessions from above:
Session Highlight: A5 - NIST and IBM Discuss Draft Publication SP 800-53A

@_date: 2005-08-26 13:11:16
@_author: Anne & Lynn Wheeler 
@_subject: Another entry in the internet security hall of shame.... 
periodically, some of the PKI related comments remind me of some stories
about power production from the 70s.
some of the '70s energy stories focused on the different quality of
support for power generation technologies based on whether they were
institutional centric (and would be able to charge for delivery)
vis-a-vis individual oriented generation technologies (even when they
involved identical/same/similar solar, wind, etc energy sources). one of
the issues from the energy stories of the 70s was that institutional
centric solutions frequently collected a lot more backing because
proponents were willing to put the effort into the activity in
anticipation of revenue flows.
however, there are sometimes significant differences between the PKI
institutional centric operations and institutional power generation
operations. The power being generated (and delivered) tends to be
relatively standard and individuals may view it a reasonable trade-off
to have it supported by large institution rather than being responsible
for their own power generation installations.
There tends to be a much larger variation in the types of things which
PKI relying-parties are interested in haved certified by some PKI
certification authority (somewhat different from bland uniform power
production operation).
Furthermore, PKI relying-parties frequently may still operate a
significant relationship management infrastructure of their own ...
where the information being certified by a trusted 3rd-party
certification authority represents a tiny fraction of the information
that a production relying party will be keeping. In these situations,
once a relying-party has to operate their own relationahip management
infrastructure of any significance, then the benefit of any
certification added value by a trusted 3rd-party certification authority
becomes marginal at best.
Once a relying-party is operating any significant relationship
management infrastructure of their own, any certification done by some
3rd party certification authority frequently becomes redundant and
superfluous. It then follows, if the certification by some 3rd party
certification authority becomes redundant and superfluous, the associaed
digital certificate (representing that certification operation) then
also becomes redundant and superfluous.
A trivial example in p2p ... is an individual doesn't necessarily know
that the presentation of a "John Smith" x.509 identity certificate in
any way corresponds to a specific "John Smith" that the relying-party
individual is familiar with. They are frequently going to still rely on
some locally maintained repository as well as additional out-of-band
and/or other communication processes. Once they have done that ... then
the incrmeental effort to also include the other individual's public key
becomes trivial (at least from a high-level business process and
information theory standpoint). This, in turn, renders any added value
from a trusted 3rd party certificate authority (and their digital
certificaes) marginal at best.

@_date: 2005-08-29 10:50:49
@_author: Anne & Lynn Wheeler 
@_subject: Another entry in the internet security hall of shame.... 
the major ISPs are already starting to provide a lot of security
software to their customers.
a very straight forward one would be if they provided public key
software ... to (generate if necessary) and register a public key in
lieu of password ... and also support the PPP & radius option of having
digital signature authentication in lieu of password checking
at that point your public key is now registered with your ISP ... and
possibly could be used for other things as well ... and scaffolding for
a certificateless trust infrastructure.
in much the same way i've commented about some of the implications of
the SSL certificae industry backing for having onfile public keys in the
domain name infrastructure (and anybody being able to do real time
retrieval of public key) ... something similar could happen with onfile
public keys for general public with their ISP (and possibly allowing
real time retrieval of public keys).
so it would be convenient if such public keys were then integrated with
various client email programs as part of the address book (automatic
process for adding email addresses to address book, then possibly also
automatically add public key as part of the same address book entry).
you could then, at least have a button that would cross-check that the
public key that came with the email was the same public key onfile with
the sender's ISP. it would still be up to the recipient to provide a
mapping/binding between an email address and an entity in the real world
(if they so desired).
the automatic add to the address book ... can work the same way
automatic add to address book works today.
part of the issue might be considered separating the trust
infrastructure from the standard addressing infrastructure.
one of the downsides (compared to some of the downsides in the domain
name infrastructure onfile public keys) for the certification authority
industry ... is that public keys no longer require independent
certification ... they just become part of the general addressing landscape.
lots & lots of past postings on SSL landscape

@_date: 2005-12-01 08:40:36
@_author: Anne & Lynn Wheeler 
@_subject: Broken SSL domain name trust model 
this can basically be considered a form of extended DNS providing
additinal authentication ... secure DNS is one such proposal for
repository of public keys ... but the DNS model of online information
repository can be used for a variety of information.
this is also my oft repeated scenario of the ssl domain name
certification authorities needing secure DNS ... because when processing
an SSL domain name certificate request ... they have to check with the
domain name infrastructure as to the true owner of the domain name. this
currently is an expensive, time-consuming and error-prone process of
matching identification supplied with the request against identification
information on file with the domain name infrastructure. on the other
hand, if public keys of domain name owners were on file with the domain
name infrastructure ... the domain name infrastructure uses digitally
signed communication (validating with the onfile public keys) to
eliminate some of their existing integrity problems (which, then in
turn, improves the integrity of any ssl domain name certificate based on
information at the domain name infrastructure registry). the registered
public keys also allow the certification authorities to turn the
expensive, time-consuming and error-prone identification process into a
much less expensive, simpler, and more reliable authentication process
... by requiring ssl domain name name certificate requests to be
digitally signed by the domain name owner (and validated with the onfile
public keys).

@_date: 2005-12-01 23:01:31
@_author: Anne & Lynn Wheeler 
@_subject: Broken SSL domain name trust model 
note that the other possible semantic confusion is referring to them as
certificate authorities ... rather than certification authorities.
they happen to distribute certificates which are a representation of the
certication. however, there are some number of the certification
authorities that
1) aren't the actual authoritative agency for the information being
certified i.e. the certification authority is just checking with the
real authoritative agency as to the validity of the information
2) many appear to actually prefer to just do "certificate manufactoring"
... a term we coined when we were doing audits of these new
organizations called certification authorities ... back when we were
consulting with the new client/server startup on something that has come
to be called electronic commerce.
of course the issue has always been that if you can do real-time, online
certification it has no lower value than a stale, static,
offline-oriented certificate. the business model tends to be further
aggrevated by the fact that most of the certification authorities aren't
actually the authoritative agency for the information being certified.
it is highly likely that as online connectivity becomes more and more
pervasive ... that people will start to realize the much higher value of
having real-time, online certification. Since the majority of the
certification authorities aren't actually the authoritative agency for
the actual information, then any transition to high-value, real-time,
online certification will tend to be done directly with the
authoritative agency responsible for the actual informmation. at that
point, most of the certification authorities become obsolete.
an obfuscation is to concentrate on the certificates as having magical
properties, distinct from their representation of an information
certifying business process. referring to them as certificate
authorities helps create semantic confusing as to where the business
process value actual exists. similarly there have articles in the
popular press referring to attached digital crrtificates as what
provides the value to any digitally signed message/document ... further
obfuscating the the value of authentication can be done with digital
signatures with online registered public keys (where any digital
certificates become totally redundant and superfluous).
the other problem/issue with requiring x.509 identity certificates on
every digitally signed message/document .... is that it turns what
should be straight-forward, simple authentication operation into a heavy
duty identification operation.
this has also tended to cause semantic confusion as well as something of
a schizo personality in some societies; especially those professing
extremely stringent privacy principles and at the same time trying to
mandate x.509 identity certificates attached to every electronic
communication (making every electronic message an identification operation).
misc. past posts referring to semantic confusion:
 Common misconceptions, was
Re: KISS for PKIX. (Was: RE: ASN.1 vs XML (used to be RE: I-D ACTION
:draft-ietf-pkix-scvp- 00.txt))
 Authentication white paper
 Employee Certificates -
Security Issues
 A challenge
 VS: On-line signature standards
 JIE - Contracts in Cyberspace
 Citibank discloses private
information to improve security
 Digital signatures have a big
problem with meaning
 UK EU presidency aims for
Europe-wide biometric ID card
 Another entry in the internet
security hall of shame
 Contactless payments and the
security challenges
 Security models
 New Method for Authenticated
Public Key Exchange without Digital Certificates
 Some questions on smart cards
(Software licensing using smart cards)
 Question about authentication
 IPSEC and user vs machine
 Catch22. If you cannot legally
be forced to sign a document etc - Tax Declaration etc etc etc
 winscape?
 NEW USA FFIES Guidance

@_date: 2005-12-07 13:34:58
@_author: Anne & Lynn Wheeler 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
unfortunately there are more than a few counter-examples that are made
enormously complex (and extremely expensive) and it turns out that the
complexity itself introduces additional failure and threat
vulnerabilities which aren't found in KISS-solutions.
nearly ten years ago, i joked that i was going to take a $500 milspec
part, cost reduce it by two orders of magnitude and at the same time
improve its security (in part by eliminating unnecessary features that
contributed to security vulnerabilities).

@_date: 2005-12-07 14:45:14
@_author: Anne & Lynn Wheeler 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
> Depends on your use. An X.509 identity cert or a PGP cert
i've periodically written on security proportional to risk ... small sample
then the issue is what security are you interested in and what are the
threat models and corresponding countermeasures.
in the security pain model
P .. privacy
A .. authentication
I .. integrity
N .. non-repudiation
you may need authentication and integrity (say from digital signature)
but not necessarily privacy/confidentiality.
in normal ongoing email, there is a lot of repeated stuff and/or
out-of-band stuff ... that makes certificates redundant and superfluous
... they are targeted at the letters of credit/introduction paradigm
from the sailing ship days. certificates basically are representations
of some certifying process performed by a certification authority. the
integrity and security of the certificate itself may have absolutely
nothing to do with the integrity and security of the certification
business process ... minor drift in sci.crypt
 PGP Lame question
furthermore, the whole complexity and series of processes involved in a
PKI-based infrastructure may have the certificates themselves totally
redundant and superfluous because the recipient has numerous other
indicators that they know who it is that they are dealing with. the
introductioin of PKI and certificates in such an environment may
actually create greater vulnerabilities ... since it may convince the
recipient to trust the PKI operation more than they trust their own,
direct knowledge ... and the PKI operation opens up more avenues of
compromise for the attackers.
... there is even a slightly related article that i ran across yesterday:
An Invitation to Steal; The more you automate your critical business
processes, the more vigilant you need to be about protecting against
the other issue in digital signature based operation is that it is a
part of 3-factor authentication
* something you have
* something you know
* something you are
where the fundamental linchpin for the whole operation is the protection
and confidentiality of the private key. unfortuantely almost all digital
signature operations tend to talk about the integrity and security of
the PKI operation and its certificates ... when they should be talking
about the integrity and security of the private keys and the
integrity and security of the digital signing environment.
i've sporadically gone so far as to assert that the focus on the
integrity and security of PKI and certificates results in obfuscating
the fundamental integrity and security issues with private keys and
digital signing environments (aka long before anybody is talking about
the integrity of the certificates ... they should have resolved that the
private keys are only available in hardware tokens of known and specific
integrity characteristics).
The whole PKI and certificate operation having a design point of
resolving first time interaction between complete strangers (as in the
letters of credit/introduction paradigm from sailing ship days) and
should come after the basic underlying infrastructure isssues involving
trusted communication between two entities has first been resolved
(whether it is first time communication between complete strangers or
not ... which then can be layered on top of a sound infrastructure that
has its fundamental operations already resolved).

@_date: 2005-12-08 14:41:26
@_author: Anne & Lynn Wheeler 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
but that is one of the points of the article that as you automate more things you have to be extra careful about introducing new vulnerabilities (of course a business operation will make claims that while they may have introduced enormous additional complexity and number of business processes ... that they are all perfect and have no the issue of public key email w/o PKI ... is you have all the identical, same basic components that PKI also needs.
there is a local trusted public key repository and a method of getting keys into/out of that trusted public key repository. in the non-PKI case, the trusted public key repository contains public keys that are used to directly authenticate messages from other entities. in the PKI case, the trusted public key repository also contains public keys that are used to authenticate messages from a certification authority; these messages are called digital certificates. the digital certificates, in turn contain other public keys that can be used in authenticating messages from directly communicating entities.
the original PKI and digital ceritificate design point is the letters of credit/introduction (from the sailing ship days) ... addressing first time communication between two strangers.
that a large volume of email doesn't involved first time communication between two strangers that have no prior relationship ... and so one possible question is does a PKI operation ... does the little or no added value for such communication possibly offset the drastically increased amount of complexity and increased number of business processes (that also contribute to possible enormous increase in potential for vulnerabilities).
PKI is trying to offer some added value in first time communication between two strangers (say the bulk mailing advertising industry) ... and it is possibly acceptable the significant increase in business processes and complexity is justified in improving reliance in the bulk mailing advertising market segment. The question does the vast increase in business processes and complexity (with the possibility that the increased business processes and complexity also introduce significant new types of vulnerabilities) justify its use in the scenarios where first time communication between two strangers is not involved.
This is business process analysis of what goes on in a basic public key email operation ... aka all the public key operations and the entity's trusted public key repository ... and then showing where PKI incrementally adds business processes and complexity to that basic infrastructure .... certification authority public keys added to the trusted public key repository, these new kind of messages called digital certificates and the indirection between the certification authority's public key (in the entity's trusted public key repository) and the public key of the other entities communicated with.
The additional digital certificate verification technical steps that a PKI operation adds to a core fundamental public key email process (that directly has access to public keys of entities directly communicated with) ... also drags in the enormous amount of complexity and additional business processes that the certification authorities have to perform.
It is some of this other complexity and business processes that may be attacked ... as in my oft repeated description of a crook attacking the authoritative agency that a certification authority uses for the basis of its certification, and then getting a perfectly valid certificate.
The user (relying-party) then may have a perfectly valid public key for an entity that they've communicated with for years .... but this perfectly valid certificate (from a crook) now claims that the user must now automatically accept the crook's public key also as representing the same entity.
so a traditional risk/threat analysis ... would frequently analyze the basic components ... establish a baseline threat/vulnerability profile ... and then consider what happens when additional complexity does to the baseline. I assert that a simple public key email operation can establish a baseline w/o any digital certificates ... and then you consider what happens when the baseline has digital certificates added
(which then also drags in all the business process vulnerabilities that may exist at the certification authority ... and all dependencies that tthe certification authority has). we had to sort of look at this sort of stuff when we were asked to work with this small client/server startup that wanted to do payment transactions on their server
and we had to go around and audit some number of these relatively new business operations called certification authorities.

@_date: 2005-12-09 14:53:02
@_author: Anne & Lynn Wheeler 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
i like the explanation that some attempted to give at the acm sigmod
conference in san jose (circa 1992) .... of what was going on in the
x.5xx standards activities; ... a bunch of network engineers trying to
re-invent 1960s database technology ...
the x.509 digital certificates being a stale, static cachable entry of
something in x.500 ldap database ... that was armored for survival in
potentially hostile environment and for relying parties that didn't have
ability to access the real database entry.
cps was something that was needed for trusted third party certification
authority operation ... not for x.509 identity certificate itself. the
issue is when you effectively have these stale, static cacheable,
armored database entries that aren't part of an organization and
business processes that relying parties belong to. traditional access to
database entries (whether you are directly accessing the entry or a
stale, static cached copy of the database entry) ... the business
processes accessing the data and the businesses responsible for the data
are part of the same operation and/or belong to organizations that have
binding contractual relationships.
it is only when you have parties responsible for the information
(trusted third party certification authorities) that are 1) totally
different from the parties relying on the information  and/or 2) the
different parties have no contractual relationships.
one could hypothesize that the creation of CPS were to provide some sort
of substitute for contractual relationship between different
organizations/parties where the relying party has no means of directly
accessing the information and must rely on a stale, static digital
certificate representation (of that information), provided by an
organization that the relying party has no contractual relationship
(just claiming to be a trusted third party certification authority
possibly wasn't enough of a sense of security for some relying parties
and so CPS were invented to provide relying parties a higher sense of
comfort in lieu of having something like an actual contractual
that makes CPSs a substitute for contractual relationships when x.509
digital certificates are used for trusted third party certification
authorities where the relying parties and the TTP/CAs are different

@_date: 2005-12-09 14:59:56
@_author: Anne & Lynn Wheeler 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
> PGP is public-key email without PKI. So is IBE. And yet neither of
them has
usually when you are doing baseline ... you start with the simplest,
evaluate that and then incrementally add complexity. in that sense
PGP is much closer to the simplest baseline ... and PKI becomes added
complexity ... inverting you classification; email PKI is PGP with
digital certificates added.
you then could add various layers of public key operation where the
relying parties have direct access to the information in one way or
another and therefor don't require stale, static, armored cached copies
(digital certificate) of the real information.
then you can go thru numerous layers of PKI ... are the relying parties
and the digital certificate creators part of the same business
organizations ... and therefor require neither contractual relationship
and/or CPS as a substitute for contractual relationship.
then add trusted third party certification authority PKI ... where the
relying parties and the certification authorities have direction
contractual relationship and thefore don't require CPS as a substitute
for contractual relationship.
it is when you get to trusted third party certification authority PKI
... where the relying parties and the ttp/ca are part of totally
different business operations and have no contractual relationship that
you then get into the issue of how does a relying party actually know
than it should be trusting a ttp/ca.

@_date: 2005-12-09 15:06:34
@_author: Anne & Lynn Wheeler 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
in the public key model ... whether it involves pgp, pki, digital
certificates, what-ever; the local user (relying party) has to have a
local trusted repository for public keys. in the pki model, this tends
to be restricted to public keys of certification authorities ... so that
the relying party can verify the digital signature on these
message/document constructs called digital certificates.
in the traditional, ongoing relationship scenario, relying parties
directly record authentication information of the parties they are
dealing with. if a relying party were to directly record the public key
of the people they are communicating with ... it is the trusting of that
public key and the validating of associated public key operations that
provide for the countermeasure for man-in-the-middle attacks and
phishing attacks.
the issue that has been repeatedly discussed is that supposedly the
existing SSL domain name digital certificates was to prevent
impresonation and mitm-attacks. however, because of various
infrastructure shortcomings ... an attacker can still operate with
perfectly valid SSL domain name digital certificates ... and it doesn't
stop the MITM-attack and/or phishing.

@_date: 2005-12-10 14:34:36
@_author: Anne & Lynn Wheeler 
@_subject: NSA posts notice about faster, lighter crypto 
NSA posts notice about faster, lighter crypto
The National Security Agency wants federal agencies to consider using a
group of algorithms it refers to as Suite B to satisfy future
cryptographic requirements. Suite B contains NSA-approved cryptographic
algorithms of various key sizes to protect classified and unclassified
but sensitive information. NSA has posted a notice about Suite B on its
Web site.
... snip ..

@_date: 2005-12-10 15:04:43
@_author: Anne & Lynn Wheeler 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
the baseline analysis, threat/vulnerability models, etc ... start with
the simplest and then build the incremental pieces .... frequently
looking at justification for the additional complexity.
when doing the original design and architecture you frequently start
with the overall objective and do a comprehensive design (to try and
avoid having things fall thru the cracks).
i would contend that the issue with PKI isn't as much that they started
with simple and then did incremental piece-meal design (rather than
complete, comprehensive design) ... but they actually did design
something for a specific purpose ... and subsequently it was frequently
tried to force-fit it for purposes for which it wasn't originally
designed for.
for example the traditional business model tends to have relying parties
contracting directly with the parties they rely on (and there is
contractual obligation between the two parties). the evolution of the
trusted third party certification authority model violates most standard
business practices that have grown up over hundreds of years.
the trusted third party certification authority is selling digital
certificates to key owners for the benefit of relying parties. there is
a large disconnect where the parties that are supposedly going to rely
on and benefit from the digital certificates aren't the ones contracting
for the digital certificates. this disconnect from standard business
practices can be considered the motivating factor for the invention of
CPS ... even tho there may not be a direct business and contractual
relationship between the relying parties and the certification
authorities ... a CPS tries to fabricate a sense of comfort for the
relying parties. A contractual relationship would otherwise provide for
this sense of trust... the relying party pays the certification
authority for something, and the certification authority then has some
obligation to provide something in return to the relying party.
In most trusted third party certification authority operations there is
no legal, business or otherwise binding relationship between the
relying party and the TTP/CA ... it is between the key owner and the TTP/CA.
This could be further aggravated by RFC authors who possibly have no
familiarity with standard business practices and attempt to write
something just because they want it to be that way.
Another example could be considered OCSP. Basically digital certificates
are stale, static, r/o, armored copies of some information located
someplace. A business process model has relying parties, relying on the
information in stale, static, r/o copies of the information because they
have no means for directly accessing the real, original information
(basically the letters of credit/introduction from sailing ship days ...
aka offline with no local resources). OCSP provides for a online
transaction which asks whether the stale, staic information is still
usuable, attempting to preserve the facade that digital certificates
serve some useful purpose when there is online, direct access
capability. The alternative is to eliminate the digital certificates all
together and rather than doing an OCSP transaction, do a direct, online

@_date: 2005-12-11 10:28:31
@_author: Anne & Lynn Wheeler 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
i've seen some discussions that were either/or regarding pki & pgp;
aka pki advocates attempting to position pki as a OR to pgp. the issue
is that both pki and pgp require a local trusted public key repository
as the basis for establishing trust.
pki then layers on it, these certification authority business processes,
specialized digitally signed messages called digital certificates, etc
to address first time communication between strangers where the relying
parties have no other resources for determining information about the
sender in an offline environment. they then advocate that all
(personally) digitally signed operations are required to have attached
x.509 identity digital certificates that has been digitally signed by a
certification authority.
we saw some of that when we did work on the cal. state & fed. electronic
signature legislation
one possible interpretation might be that it would have increased the
revenue stream for the certification authority industry.
drastically improving the useability of the interface to the trusted
public key repositories could be viewed as having two downsides 1)
certification authorities that haven't payed to have their public keys
preloaded can more easily join the club, 2) the pgp-like scenario
becames much easier, potentially drastically reducing existing reliance
on the digital-certificate-only (and certification authority only
business process) digital-signed-operation model.
part of the problem with the trusted third party certification authority
 model is that its primary benefit in the case of first time
communication betweeen two strangers ... where the relying party has no
other recourse to information about the other party. this is actually an
extremely small percentage of communications. we saw some of this
working on the original e-commerce activity
where we layed out hypothetical certification issues for merchants ...
including things like having FBI background checks for all merchant
employees. the problem is that e-commerce transactions have been quite
bi-model whith the largest percentage of transaction occuring as repeat
business with well-known merchants. in these cases, consumers have
established trust via a large number of other mechanisms ... so there is
little added value that a certification authority can provide ...
especially if they aren't willing to stand-behind and guarantee all
merchant transactions (ssl then is primarily countermeasure to
mitm-attack and evesdropping on transaction as opposed to a
certification/trust issue).
the rest of the remaining transaction are spread around to a large
number of different merchants having a few transactions each. the issue
here is that the incremental revenue flow for a few transactions a month
couldn't possibly cover the cost of a certification process that
involved things like fbi background checks on all merchant employees.
the large majority of transactions are either repeat business and/or
with extremely well-known merchants ... this doesn't satisfy the PKI
target profile of first time communication between complete strangers.
simple countermeasure to mitm-attack and countermeasure is achieved by
having stored the merchant's public key (from the consumer's standpoint).
from the merchant standpoint they already have transaction guarantees on
credit card processing from their contract with financial institution.
the threat/vulnerability model here is client-originated fraudulent
transactions that aren't strongly authenticated. here, x9.59 standard
allows for digitally signed transaction where the public key is
registered with the consumer's financial institution and the digital
signature is verified by the consumer's financial institution as part of
verifying the transaction.
the other part of x9.59 standard is that it specifies that account
numbers used in x9.59 transactions can't be used in non-authenticated
transactions. this eliminates both data breaches and evesdropping as a
threat/vulnerability for fraudulent financial transactions ... aka the
requirement given the x9a10 working group for x9.59 standard was to
preserve the integrity of the financial infrastructure for all retail
payments. if data breaches and evedsdropping no longer can result in
fraudulent transactions, then there is much less reason for
sophisticated countermeasures for those threat/vulnerabilities (ssl is
no longer needed to prevent evesdropping on the account number, since
evesdropping on the account number no longer provides any practical
fraudulent benefit).
simple public key registration as part of financial account operation
(in an onging relationship that a consumer has with their financial
institution) not only is a certificateless digital signature model
but also eliminates much of the requirement for existing major use of
digital certificates; that of providing ssl encrypted communication
as countermeasure for evesdropping for the purpose of account number
furthermore, not only does simple x9.59 digital signature authenticated
transactions eliminate the threat/vulnerability of evesdropping for
account number harvesting, but it also eliminates the
threat/vulnerability of data breaches for account number harvesting
aka the harvesting could still go on, but the threat/vulnerability of
fraudulent transactions as a consequence of harvesting is eliminated ...
note that phishing attacks for the purpose of account number harvesting
is also eliminated as a threat/vulnerability ... phishing can still go
on, account numbers cna still be harvested, the account numbers are
useable for fraudulent transactions w/o the digital signature.
misc. past posts mentioned bi-model transaction distribution and/or
having suggested employee fbi background checks as part of merchant
certification process.
 [FYI] Did Encryption
Empower These Terrorists?
 SSL certs & baby steps
 E-commerce security????
 Does "Strong Security" Mean

@_date: 2005-12-13 10:54:57
@_author: Anne & Lynn Wheeler 
@_subject: [Clips] Banks Seek Better Online-Security Tools 
some number of organizations have come up with the term "account fraud"
... where fraudulent transactions are done against existing accounts ...
to differentiate from other forms of "identity theft" which involves
things like using a stolen identity to establish new accounts.
account fraud just requires strong authentication applied consistently
... doesn't require identification ... although there are cases where
identification is confused and is used as a supstitute for
authentication. part of the issue of confusing identification for
authentication ... is that it is typically quite a bit more privacy
evasive than pure authentication.

@_date: 2005-12-18 10:27:34
@_author: Anne & Lynn Wheeler 
@_subject: browser vendors and CAs agreeing on high-assurance certificates 
but this is consistent with my comments that as the offline market
segment ... which was the original design point for certification
authority ... starts to disappear ... as the internet becomes more and
more ubquitous; then certification authorities have moved into the
no-value market segment; aka that market segment that still couldn't
justify either
1) cost of having thier own local repository of communicating entities
(even as cost of local computing and storage was rapidlty dropping)
2) even the drastically dropping cost of internet online operations
couldn't be cost justified for whatever it was that they were doing.
this gets into rapidly downward spiral ... since was they moved more and
more into the no-value market segment ... what the certification
authorities were able to charge customers dropped ... as they lost price
elasticity in what they could charge ... the revenue flow for supporting
internal infrastructure and operation would start to dry up.
the other long standing comment with regard to original ssl domain name
certificates was that this supposedly stacked out the e-commerce trust
model. when we initially tried to set more stringent requirements for
what could be checked as the basis for providing e-commerce trust ... we
ran into strong bi-model environment
1) the majority of e-commerce transactions were done with a few widely
known sites and/or sites that the client had repeatedly transacted with
before. as a result, there were a large number of other trust vehicles
and the these merchants felt it was not necessary to pay a large amount
for significant certificate-based trust operation ... since their trust
was being established by a wide-range of other mechanisms.
2) the vast majority of e-commerce sites did very few number of
transactions each. this was the market segment involving e-commerce
sites that aren't widely known and/or represents first time business. it
is this market segment that is in the most need of trust establishment;
however, it is this market segment that has the lowest revenue flow to
cover the cost of creating a trust value.
there is actually a third issue for the vast numbers of low traffic
e-commerce merchants ... the lack of trust can be offset by risk
mitigation. it turns out that this market segment where there is
poissble litte reason for the customer to trust the merchant has had a
trust issues predating the internet ... at least going back to the
introduction of credit financial transactions. as opposed to trust, risk
mitigation was addressed in this period with things like reg-e and the
customer having a high level of confidence that disputes tended to
heavily favor the customer. this characteristics of risk mitigation, in
lieu of trust, then carried over into the internet e-commerce relm.
somewhat as a result, the certification authorities weren't willing to
insure and/or provide any guarantees ... and the e-commerce merchants
weren't willing to pay certification authorities for such risk
mitigation ... since they were already paying the financial institutions
for such risk mitigation ... and there was no point in having redundant,
superfluous, duplicated and/or replicated overhead costs.
so that effectively left the certification authorities (of the period)
providing sense of confidence and trust ... not in the entity that
clients were dealing with ... but purely some incremental sense of
confidence that the URL that clients had typed in, was really getting
them to the website that they thot they thot they were getting to. part
of the problem here, was that there were extremely few fraud incidents
involving people typing in a URL and getting redirected to a site other
than the site indicated by the URL (the incremental trust value
represented by having certificate-based certified information from a
certification authority).
Even this exploit/countermeasure scenario was subverted when merchants
decided that SSL was too expensive for the general shopping experience
... and was only needed for checkout/paying. In that emerging model
(that is now widely prevalent), the merchant site provided a
click-button that automatically generated the URL ... along with a
certificate matching the URL. There was no longer checking of the URL
provided by the customer ... there was only a certificate provided by
the merchant that validated a URL provided by the merchant.
most of the sense of trust ... and/or at least a sense of well-bounded
risk in e-commerce was provided by mechanisms that had predated internet
e-commerce. the websites that had the lowest amount of trust (not widely
known and/or repeat business; aka unknown, first time business) were the
ones that could the least afford expensive certification process.
certification authorities were trying to 1) use a mechanism originally
designed to provide trust in a offline environment which was a repidly
disappearing market segment, 2) primarily provide incremental trust in a
market segment that already had several well-established trust
mechanisms ... which left them a very bounded market niche which didn't
actually justify large revenue. The possible incremental trust and/or
sense of safety provided by certification authorities was pretty well
bounded in the environment ... and the market segment that had the
highest need for incremental trust and sense of safety was the market
segment with the lowest revenue flow per website.
a secondary factor was the certification authority price structure was
effectively flat rate to all merchants. the trust and safety model from
the financial infrastructure was much better business structured model.
the financial infrastructure effectively provided insurance on every
transaction ... the customer had a much, much higher sense of safety ...
and the cost to the merchant was strictly proportional to their revenue.
with the financial infrastructure already in the sense of safety market
segment ... with effectively a product that had a significantly better
business structure for both customers and merchant ... that
significantly narrowed the trust&safety market segment opened to
certification authorities.
some misc past posts about certification authorities migration into the
low/no value market segment
 I-D
 Employee Certificates -
Security Issues
 First Data Unit Says It's
Untangling Authentication
 TTPs & AADS (part II)
 A challenge (addenda)
 Ousourced Trust (was Re:
Difference between TCPA-Hardware and a smart card and something else before
 Using crypto against
Phishing, Spoofing and Spamming
 Broken SSL domain name trust
 Cirtificate Authorities 'CAs',
how curruptable are they to
 The SOB that helped IT jobs
move to India is dead!
 Soft signatures
 New Method for Authenticated
Public Key Exchange without Digital Certificates
 More Phishing scams, still no
SSL being used
 The Worth of Verisign's Brand
 The Worth of Verisign's Brand
 The Worth of Verisign's Brand
 Certificate Authority of a
secured P2P network

@_date: 2005-12-18 12:59:34
@_author: Anne & Lynn Wheeler 
@_subject: browser vendors and CAs agreeing on high-assurance certificates 
part of the issue is that certification authority trust model is
attempting to equate internet routing names with business entity names
.... something that they were never designed to do. it isn't so much
that there are too many names ... but that business name operation and
internet routing names were never designed to be used as the same thing
(even for business operation names ... in the same jurisdiction, you may
have a business organization with three different names ... where what
is on the store front ... is different than what is registered at state
business agency).
another part of the issue might be considered that effectively digital
certificate paradigm (designed for offline operation in lieu of the
replaying party having any other resources) comes down to the individual
having to repeat the whole trust sequence on every cycle ... each
operation resends the same certificate requiring that all the operations
have to be repeated. this is in-turn predicated on the assumption that
the user has no resources for online, real-time information and no local
trusted memory (other than the local trusted public key repository where
there are attempts to reserve for certification authority use only). the
problem here is that it is long known that you run into trouble if you
force the end-user to repeat the same operations over, and over, and
over again ... until they become meaningless. in conjunction ... digital
certificate operations (at least exposed to the end-user) have been
forced to be more & more hidden and more & more trivial. more consistent
with long recognized human factors is to have the end-user perform some
sequence of recognizable trust operations once per site ... and then
save the results of those operations for future use (like validating a
public key and saving it in their local trusted public key repository)
... rather than forcing that ALL the trust operations have to be
repeated on every interaction (which in-turn, forces what trust
operations are performed to be more and more trivial as the repitition
becomes more & more meaningless to the end-user).

@_date: 2005-12-24 09:20:56
@_author: Anne & Lynn Wheeler 
@_subject: browser vendors and CAs agreeing on high-assurance certificat 
this is a semantic nit ... certs are typically distributed openly and
freely ... so potentially everybody in the world has free access to the
same cert.
what operations need is the same access to a high-assurance private key.
given that there is access to a high-assurance private key ... then it
is possible to scaffold various other operations. some of the issues
surrounding private key high-assurance may preclude having replicated
private keys, restricting use to a single physical entity.
over ten years ago ... i helped a small isp set up a single server to
host a larger number of different email domains ... which required doing
several hacks/enhancements to sendmail.
the early onset of some of the leading search engines started out with
multiple-A records for load balancing and availability (i.e. dns having
single host/domain name with a list of different ip-addresses) ... where
they rotated the ip-addresses in the list. as their traffic ramped up,
this wasn't sufficient ... in part because the ip-address lists got
cached in a large number of different places ... as static lists. this
resulted in the evolution of boundary routers that responded to the set
of published ip-addresses and internally kept track of activity to
backend servers ... and dynamically spread the load across an
increasing/growing number of backends.

@_date: 2005-12-26 05:58:12
@_author: Anne & Lynn Wheeler 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
it stops the MITM attacks where the client supplies a URL and the server
supplies a certificate that corresponds to the URL.
the original issue is that a MITM might have redirected the connection
from the client to a bogus site ... or an intermediate site that then
impersonated the real site.
the infrastructure issue was that the merchants decided that SSL was too
high an overhead and stopped using SSL for the main connection where the
client supplied the URL. they allowed the client supplied URL connection
to be done w/o a URL. then later ... the website provided a click button
for checkout/pay ... which supplied a URL and then they also supplied a
certificate that matches the URL that they provided.
this situation could either be a completely bogus site ... or even a
mitm-attack ... which just did a pure passthru of all traffic going in
each way .... except for the pay/checkout button. for the pay/checkout
button, the mitm substituted their own URL & certificate. everything
else passes thru as usual ... except the mitm is having two ssl session
... the mitm to "real" server session and the mitm to the client
session. the mitm to "real" server uses the "real" server's certificate
... the mitm to client server users the mitm certificate. since the mitm
supplied the URL to the client as part of the click operation ... the
mitm can control that the actual URL invoked by the client matches the
certitificate used by the mitm. the e-commerce use for pay/checkout
scenario is one of the major uses for SSL on the internet today ... and
the way that the infastructure has come to use SSL no longer prevents
the mitm-attack with the attacker can supply both the URL and the
the issue for preventing mitm-attacks ... you need the client to supply
the URL and have the SSL process validate the other end of that
connection (with a server provided ssl domain name certificate ... or at
least a trusted, supplied public key associated with the URL). when the
attacker provides both the URL and a trusted public key ... what is
being prevented.
there is another problem, somewhat the week binding between domain name
and domain name owner. the issue is that many of the certification
authorities aren't the authoritative agency for the information they are
certifying. much of the original justification for SSL related to mitm
attacks was various integrity issues in the domain name infrastructure.
the process tends to be that a domain name owner registers some amount
of identification information for their domain name ownership with the
domain name infrastructure. the certification authorities then require
that SSL domain name certificate applicants also provide some amount of
identification information. then the certification authorities attempt
to do the expensive, time-consuming, and error-prone process of matching
the supplied identification information for the SSL domain name
certificate with the identificaiton information on file with the domain
name infrastructure for the domain name.
as part of various integrity issues related to that process, there has
been a proposal, somewhat backed by the ssl domain name certification
authority industry that domain name owners also register a public key
with the domain name infrastructure (in addition to identificaiton
information). then future communcation can be digitally signed and
verified with the onfile public key. also the ssl domain name
certification authority industry can require that ssl domain name
certificate applications be digitally signed. then the certification
authority can replace the expensive, time-consuming, and error-prone
identification matching process with a much less-expensive and efficient
authentication process by doing a real-time retrieval of the on-file
publickey from the domain name infrastructure for verifying the digital
signature (in lieu of doing a real-time retrieval of the on-file
identificaiton information for the expensive, time-consuming and
error-prone identification matching).
the two catch22 issues here are
1) improving the overall integrity issues of the domain name
infrastructure lessons the original justification for ssl domain name
2) if the certification authority industry can rely on real-time
retrieval of publickeys from the domain name infrastructure as the base,
TRUST ROOT for all of their operations ... it is possible that other
people in the world might also be able to do real-time retrieval of
publickeys as a substitute to relying on SSL domain name certificates
misc, numerous past postings mentioning SSL and ssl domain name certificates

@_date: 2005-12-26 12:27:40
@_author: Anne & Lynn Wheeler 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
part II;
i've repeatedly asserted that the fundamental, underlying certificate
business practices is to address the first time communication between
complete strangers ... analogous to the letters of credit/introduction
from the sailing ship days.
so the original SSL design point was to cross-check the domain name from
the URL typed in by the client to the certificate supplied by the
server. that basic premise is underminned when the server supplies the
URL and the certificate.
so you are left with placing the burdon on the user to cross-check the
URL displayed with the URL they think they are going to. it is simple
human dynamics ... after the first several thousand displayed URLs ...
they are going to ignore the process.
this is somewhat akin to the share-secret passwords ... that the
security experts define that the user has to have hard-to-guess,
impossible-to-remember passwords that change every 30 days, can never be
written down and every new password has to be unique ... as well as
unique across all security domains. the problem is that the number of
unique security domains that a person deals with has grown from 1-2 (I
had my first logon password in the 60s followed with the addition of an
ATM pin in the late 70s) to scores ... there is no practical possibility
that all such requirements can be satisified. misc. past collected posts
on shared-secret
the underlying infrastructure further complicated the whole process when
a large percentage of the merchants outsourced the payment process to
3rd party ... where the click button supplied a URL of the 3rd party
payment processor that had absolutely no relationship to the merchant
site the client had been shopping at. this not only creates the
situation where
1) any initial connection to a merchant site where the user might
possibly have typed in the URL (or controls the URL generation via other
mechanisms) is not checked ... and any actual checking for things like
MITM-attacks doesn't occur until there is a URL provided by a
potentially suspect site.
but also
2) conditions the user as normal process that the pay/checkout button
may have a complete different domain name URL than the domain name of
the shopping site.
so, pretty well documented human factors ... especially related to the
design of security systems ... is that you don't tie humans making
determination about soem security issue to something that repeatedly
happens thousands and thousands of times. there are some guards that
have to check badges against faces ... but they tend to have intensive
training AND organizations that have high volume have gone to guards
doing it only short periods and rotating ... and/or the guards are
looking for a very simple repeating pattern and are trained to look for
missing pattern). having the human have to repeatedly check a (URL)
field that changes several thousand times a day against something they
are suppose to expect ... is pretty quickly a useless security design.
a more sensible human factors design ... is to remember whether a person
has checked out first time communication with a stranger ... the real
first time, have the person do something additional ... and from then on
remember that checking. in that respect ... creating a dependency on the
user to repeatedly check a field that changes possibly thousands of
times per day is extremely poor human factors security design.
now, the other part of my constant theme about certificates having
design point of first time communication between complete strangers ...
involves the additional constraing that the relying party has no other
recourse to obtain information about the other party. if you go to
paradigm where the relying party has facilities to remember first time
checking ... then the appended certificate on the communication is
actually only useful for the real first-time-communication (since by
definition the relying party has facilities to remember previous
checking ... like saving away the other parties publickey in a trusted
public key repository).
another part is that if you have the relying party do some additional
checking on the real first time interaction (rather than expecting the
user to do increasingly trivial checking on each new URL) ... and the
user is really online ... then that first time checking can involve
real-time check of online resources .... again invalidating more of the
underlying design point of appending a certificates on every
communciation for benefit of relying parties who have no other recourse
for determining information about complete stranger in first time
there is something of a dichotomy here ... where there is a somewhat
justification for certificates, based on the explanation that it could
be too onerous for end-users having to do anything unusual for
first-time communication with complete stranger (and therefor there is
no dependency on local repository for remembering such additional
checking and/or infrastructure that might be able to allow for the user
to do real-time, online checking) ... but at the same time there is
sometimes stated that there is a dependency on the user checking
thousands and thousands of changing URLs every day to make sure they are
what the user expected them to be (which is pretty much been a long
recognized poor security design point).
again, collected past posts on ssl certificates
as to the other point about their being a week binding between URL
domain name and owner; there are recognized integrity weaknesses in the
domain name infrastructure (including the binding between the domain
name and the domain name owner), however as previously stated, the SSL
domain name certification authority certification process is dependent
on the integrity of that information (as the TRUST ROOT basis for
performing the certication, that in turn, is represented by a stale,
staic certiciate). i would claim, in the minds of end-users, there is an
icnreasingly growing weak binding between the parties that consumers
have to deal with on the internet and any domain name. furthermore
creating a security foundation based on end-users having to mentally
correlate URL domain names in a field (something that is constantly
changing thousands of times per day) with external entities is a long
recognized poor security design point.

@_date: 2005-12-27 10:06:36
@_author: Anne & Lynn Wheeler 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
the original SSL paradigm was predicated on end-to-end security that
"the server the user thot they were taling to" was "the server that they
were actually talking to". certificates addressed the part from "the URL
inside the browser" to "the server".
the paradigm was dependent on the user having a tight binding between
"the server the user thot they were talking to" and "the URL inside the
browser" ... which in turn was dependent on the user actually inputing
the URL (as demonstration of the binding between the server the user
thot they were talking to and the inputed URL).
the problem was that as the infrastructure matured ... the actual URL
came to have less & less meaning to the user. so the MITM-attacks moved
to the weak points in the chain ... rather than attacking a valid
certificate and/or the process after the URL was inside the browser,
attack the process before the URL got inside the browser.
petnames would seem to suffer somewhat the same problem as
shared-secrets and passwords ... requiring a unique petname for every
URL. it works as long as their a few ... when they reach scores ... the
user no longer can manage.
so part of the problem is that the URL has become almost some internal
infrastructure representation... almost on par with the ip-address ...
the user pays nearly as much attention to the URL for a website as they
pay to the lower-level ip-address for the site (legacy requirements
still have ways for people to deal with both the URL and the ip-address
... but they don't have a lot of meaning for a lot of people).
however the URL Is one way of internally doing bookkeeping about a site.
so security issues might be
1) is the user talking to the server they think they are talking
2) does the user believe that the site is safe
3) is the site safe for providing certain kinds of sensitive information
4) is the site safe for providing specific sensitive information
 is the original SSL design point ... but the infrastructure has
resulted in creating a disconnect for establishing this information.
possibly another approach is that the local environment remembers things
... akin to PGP key repository. rather than the SSL locked ... have a
large green/yellow/red indicator. red is neither SSL locked and/or
checked. yellow is both SSL locked and checked.  green is SSL loaked,
initial checked, and further checked for entry of sensitive information.
a human factors issue is how easy can you make preliminary checking ...
and then not have to do it again ... where the current infrastructure
requires users to match something meaningful to URL to SSL certificate
on every interaction. preliminary checking is more effort than the
current stuff done on every SSL URL ... but could be made to be done
relatively rarely and part of an overall infrastructure that directly
relates to something the end-user might find meaningful.
bits and pieces of the infrastructure is already there. for instance
there is already support for automatically entering userid/password on
specific web forms. using bits and pieces of that repository could
provide ability to flag a specific web form as approved/not-approved for
specific sensitive information (like specific userid/password).
the issue isn't that a simple indicator with 2-4 states isn't useful ...
but the states presented need to realistic need to mean something to the
user. the locked/unlocked just says that the link is encrypted. it
doesn't indicate that the remote site is the server that that the user
thinks it is ... in part because of the way that the infrastructure has
creating disconnect between the URL and what users actually deal in.
if the browser kept track of whether the user actually hit the keys for
the entering of the URL ... then it might be useful for the browser to
provide a higher level of confidence to the SSL certificate checking
(aka it is only if the user actually typed in the URL ... can their be a
high-level of confidence related to the SSL certificate checking).
one might be tempted to make some grandiose philosophical security
statement ... that unless the user is involved in actually doing some
physical operation (at least at some point in time) to correlate between
what is meaningful to the user and the internal infrastructure. the
original SSL scheme was dependent on the user actually typing in the URL.
this is somewhat analogous to the confusion that seems to have cropped
up in the past with respect to the difference between digital signature
and human signature.
could actually have digital signature applied to a retail transaction at
point-of-sale as means of authentication. however, that digital
signature wouldn't be the representation of human intent, aka read,
understood, agress, approves, and/or authorizes. pin-debit POS currently
has two-factor authentication, you swipe the magnetic card and you enter
a PIN. however, both are purely authentication. to get human intent, the
(certified) POS terminal asks the person to push the yes button if they
agree with the transaction. in the case of an x9.59 transaction at a
point-of-sale, the digital signature is authentication, but NOT human
intent. pushing the green/yes button on the POS terminal is what
indicates human intent (and therefor is the equivalent of human
signature indicating read, understood, approves, agrees, and/or authorizes).

@_date: 2005-12-30 10:12:18
@_author: Anne & Lynn Wheeler 
@_subject: Techworld.com - Phishers now targetting SSL 
The spoofing has taken a number of forms, which appear to be becoming highly sophisticated. The vary from exploiting browser flaws, to hacking legitimate sites or even just frames on these sites, as a way of presenting what appears to be a legitimate banking site to visitors.
... snip ...

@_date: 2005-02-04 11:07:32
@_author: Anne & Lynn Wheeler 
@_subject: Dell to Add Security Chip to PCs 
and chips that typically have had eal4+ or eal5+ evaluations. hot topic in 2000, 2001 ... at the intel developer's forums and rsa conferences

@_date: 2005-02-04 11:12:59
@_author: Anne & Lynn Wheeler 
@_subject: Dell to Add Security Chip to PCs 
> I've read your objections. Maybe I wasn't clear. What's wrong in
the cost of EAL evaluation typically has already been amortized across large number of chips in the smartcard market. the manufactoring costs of such a chip is pretty proportional to the chip size ... and the thing that drives chip size tends to be the amount of eeprom memory.
in tcpa track at intel developer's forum a couple years ago ... i gave a talk and claimed that i had designed and significantly cost reduced such a chip by throwing out all features that weren't absolutely necessary for security. I also mentioned that two years after i had finished such a design ... that tcpa was starting to converge to something similar. the head of tcpa in the audience quiped that i didn't have a committee of 200 helping me with the design.

@_date: 2005-02-09 09:27:26
@_author: Anne & Lynn Wheeler 
@_subject: link-layer encryptors for Ethernet? 
the internal network was larger than the arpanet/internet just about the whole time up until about mid-85. all the links leaving physical premise had to be encrypted ... there was the claim that over half of all encrypters in the world were on the internal network (and put at least one of the major products/companies into business). lots of random comments about about the internal network
small sample posting about the internal net passing 1000 nodes not long after internet passed 255 nodes.
one of the big issues in part of this period was getting encrypters on links that cross national boundaries.

@_date: 2005-02-09 10:26:57
@_author: Anne & Lynn Wheeler 
@_subject: link-layer encryptors for Ethernet? 
how 'bout microwave terrestrial ... remember all the press about the consulate in san fran that supposedly had clear shot at the mci microwave antenna complex?
san jose south valley complex had T3 collins digital radio between the main plant site (roof of bldg. 12) and stl/bldg.90. i've heard comments from people driving the stretch of 87 having their radar detectors go off when they are in the straight line between bldg. 12 and the repeating tower on top of the hill going to bldg.90.
a similar setup went to the lsg/bldg.29 (los gatos lab) ... with a repeating tower on the hill above san jose dump.
my hsdt project had some of the circuits
and also put in a tdma system that ran off a transponder on sbs4. had 4.5meter dish in the back parking lot of bldg.29 with tail circuits to the main plant site, a 4.5meter dish out behind yorktown research, and a 7meter dish on the austin plant site.
i got tired of paying all the money for the link encrypters ... and got involved in designing a board that was a lot more powerful and orders of magnitude cheaper ... which caused some churn.

@_date: 2005-02-10 19:03:37
@_author: Anne & Lynn Wheeler 
@_subject: A cool demo of how to spoof sites (also shows how TrustBar preventsthis...) 
cylink had the contract ... bea had subcontract. usps was going to do some sort of in-person verification before issuing the certificate ... along the lines of US passports.
this dates back to the days when the CA industry was floating business cases that there was going to be $100/annum x.509 identity certificate for every person in the country (the $20b/annum gift to the CA industry there was some rumor that if the gov. wouldn't cough up the $20b/annum, then the financial industry was just chopping at the bit to turn over $20b/annum to certification authorities. there is a story from the period about an offer to a financial institution that if they would transmit a copy of the master account database of tens of millions of customers to the certification authority ... the certification authority would re-arrange the bits in each database entry into this magic format called a certificate and return the re-arranged magic bits to the financial institution at a mere $100/database entry (nominally overnight ... but possibly actually several days, maybe only earning the CA a measely $1b/day of work).
this overlapped with the realization that identity certificates were composed at some point in the past w/o any knowledge of just what identity information any future relying parties might require .... as a result there was one strategy that it would be necessary to overload all identity certificate with every possibly piece of identity information so as to cover all possible requirements possibly needed by future unknown relying parties.
at the same time, the financial industry was realizing that identity certificates represented huge privacy and liability exposures ... and so you started to see retrenching by various parties (particularly the financial industry) to relying-party-only certificates. misc. past posts about relying-party-only certificates:
The problem lurking in the background is that fundamentally, the certificate design-point is an offline paradigm in a situation where the relying-party has absolutely no recourse for obtaining information about the origin of the digital signature (so is reduced to operating with a letter-of-credit paradigm from the sailing ship era).
This fact was well highlighted in digitally signed payment scenario. A bank customer was issued a relying-party-only certificate by their financial institution (after registering their public key in the financial institution's account record). The customer would then create a payment authorization message, digitally sign the message and then transmit the message, the digital signature and the bank's relying-party-only certificate back to the bank. Since the bank already has the customer's public key on file, the first thing it does is discard the transmitted certificate and verifies the digital signature with the on-file public key.
Another minor annoyance was that typical digital certificate was nominally two orders of magnitude (one hundred times) larger than the typical 8583 payment message. So not only were the relying-party-only certificates redundant and superfluous ... its only apparent purpose was to increase transmission payload bloat by a factor of 100 times.
some past posts about browser trusted public key lists:
 Merchant Comfort  Merchant Comfort  RSA vs AES

@_date: 2005-02-22 10:00:35
@_author: Anne & Lynn Wheeler 
@_subject: ATM machine security 
messages/networks tend to be some flavor of iso8583 (used for both credit and debit). most associations have requirement for DUKPT (derived unique key per transaction) DES and transition to 3DES.
do search engine some flavor of 8583, dukpt, and/or x9 (x9 is the us/ansi financial standards organization ... they have some recognition at places like NIST where they've gotten around to saying that they no longer have to rewrite X9 crypto standards for FIPS ... but can directly reference the X9 documents).
lots of the attacks aren't directly on the ATM machines ... but on the cards used at ATM machines ... aka skimming attacks. there is the stuff about overlays on the front of ATM machines to capture information as the card passes thru for valid transations. the captured information is then used to manufactor counterfeit cards (i think there was even a scene on this on one of last seasons CSI tv shows).

@_date: 2005-01-05 23:46:32
@_author: Anne & Lynn Wheeler 
@_subject: Banks Test ID Device for Online Security 
in general, it is "something you have" authentication as opposed to the common shared-secret "something you know" authentication.
while a window of vulnerability does exist (supposedly something that prooves you are in possession of "something you have"), it is orders of magnitude smaller than the shared-secret "something you know" there are two scenarios for shared-secret "something you know" 1) a single shared-secret used across all security domains ... a compromise of the shared-secret has a very wide window of vulnerability plus a potentially very large scope of vulnerability
2) a unique shaerd-secret for each security domain ... which helps limit the scope of a shared-secret compromise. this potentially worked with one or two security domains ... but with the proliferation of the electronic world ... it is possible to have scores of security domains, resulting in scores of unique shared-secrets. scores of unique shared-secrets typically results exceeded human memory capacity with the result that all shared-secrets are recorded someplace; which in turn becomes a new exploit/vulnerability point.
various financial shared-secret exploits are attactive because with modest effort it may be possible to harvest tens of thousands of In one-at-a-time, real-time social engineering, may take compareable effort ... but only yields a single piece of authentication material with a very narrow time-window and the fraud ROI might be several orders of magnitude less. It may appear to still be large risk to individuals ... but for a financial institution, it may be relatively small risk to cover the situation ... compared to criminal being able to compromise 50,000 accounts with compareable effort.
In some presentation there was the comment made that the only thing that they really needed to do is make it more attactive for the criminals to attack somebody else.
It would be preferabale to have a "something you have" authentication resulting in a unique value ... every time the device was used. Then no amount of social engineering could result in getting the victim to give up information that results in compromise. However, even with relatively narrow window of vulnerability ... it still could reduce risk/fraud to financial institutions by several orders of magnitude (compared to existing prevalent shared-secret "something you know" authentication old standby posting about security proportional to risk

@_date: 2005-01-06 06:52:30
@_author: Anne & Lynn Wheeler 
@_subject: Banks Test ID Device for Online Security 
oh, and this is old discussion of a unit that has been in use in europe ... it basically is very inexpensive calculator with 7816 contacts that you can slip a smartcard into. it is used in a challenge/response scenario, a numeric keypad is used to enter the challenge, which is
passed to the smartcard, which does something and the response is displayed. the person enters the displayed response.
 Q: Internet banking
works with anything that can present a challenge and has a numeric keypad for the response (even works over telephone with VRU).
note that in any online scenario ... the server-side can do security proportional to risk by making a decision to ask or not ask for additional inputs. possible scenario is bill pay in home banking, use
authentication for initial access and then if total transactions exceed some value ... ask for additional authentication input (trading off convenience and risk, in online scenario it doesn't need to be all just one way or another way, there is some amount of latitude for adaptive Note that the additional authentication input can also be used for interpreting the (human specific) input as evidence of approval for the transaction(s) as opposed to simply authentication.
other pieces of the previous mentioned thread on security proportional to risk:
 net banking, is it safe?? ... power to the consumer
 net banking, is it safe?? ... security proportional to risk
 Q: Internet banking
 Net banking, is it safe???
 Net banking, is it safe???
 Net banking, is it safe???
 Net banking, is it safe???
 Net banking, is it safe???
 Net banking, is it safe???
 Net banking, is it safe???
 Net banking, is it safe???
 Net banking, is it safe???
 Net banking, is it safe???
 Net banking, is it safe???
 Net banking, is it safe???
 Net banking, is it safe???
 Net banking, is it safe???

@_date: 2005-07-09 10:30:06
@_author: Anne & Lynn Wheeler 
@_subject: payment system fraud, etc. 
a lot the big news articles about data breaches are related to being
able to do account fraud against the payment system .... just from
electronic records. this is basically static data that can leveraged to
directly performing electronic account fraud and/or being able to create
counterfeit cards and performing fraudulent transactions. similar to the
database harvesting exploits are the skimming exploits where electronic
recording of transactions are performed .... there have even been crime
tv shows about ATM overlays and pin-hole cameras as part of skimming
activities. again the electronic recording is sufficient for creating
counterfeit cards and performing fraudulent transactions. lots of past
posts related to harvesting and skimming
the above includes some number of past posts about the target databases
provide much bigger fraud return-on-investment than evesdropping for
e-commerce transactions. slightly related is old security proportional
to risk posting
the other way of viewing this is that the knowledge of the account
number and/or the static data magstripe card are taken as authentication
which enables the performing of an unauthenticated transactions. This
can be interpreted as both a form of replay-attack (replaying the
authentication to enable to the execution of an unauthenticated
transactions) and a MITM-attack (i.e. the crooks slipping into the
cracks between the simple authentication and the unauthenticated
as mentioned in past posts on x9.59,
the x9a10 working group was tasked with preserving the integrity of the
financial infrastructure for all retail payments. this resulted in two
business rules
1) strongly authenticated transactions .... example mapping to iso 8583
payment transactions used ecdsa with public keys registered at the
issuing bank ... there were pki-based payment specifications in the same
period as the original x9.59 standards work. even when they retrenched
to relying-party-only certificates to mitigate severe privacy and
liability issues with x.509 identity certificates
the certificate overhead was still on the order of 4k-12k bytes. for
typical iso 8583 message sizes of 60-80 bytes, this represented a factor
of one hundred times payment bloat for redundant and superfluous PKI
2) account numbers used in x9.59 transactions, if used in non-x9.59
transactions would not be authorized.
the first business rule made it difficult to counterfeit x9.59
transactions (and made them business process friendly, especially
compared to some of the PKI-oriented specifications).
the second business rule eliminated harvesting/skimming of x9.59 account
numbers as a threat/vulnerability. the issue here is that account
numbers are used in dozens of business processes .... and even if the
earth was buried miles deep in cryptography attempting to maintain
privacy/confidentiality of the account numbers ... there would still be
account number leakage. x9.59 recognizing that such leakage would be
essentially impossible to stop ... attempted to eliminated such account
number leakage as a threat and vulnerability.
so, as in earlier statements ... this would still leave merchant
misrepresentation as a threat and vulnerability. the problem is that
that is fairly quickly identified and shutdown. a big
threat/vulnerability in the harvest/skimming scenario is that the crooks
attempt to perform the fraud as far away as possible from the source of
compromise (maximizing the benefit of the compromised source). Fraud
being performed at the point of compromise tends to have a much shorter
lifetime. recent post
 massive data theft at
MasterCard processor
that leaves the old-fashion waving guns and social engineering. waving
guns tends to have much lower fraud return on investment (especially
when transactions tend to be limited to hundreds of dollars and
lost/stolen reports can shut off the account).
if simple harvesting/skimming has been eliminated .... like data
breaches ... then similar harvesting thru social engineering isn't going
to work much better. you are back to something similar to the merchant
misrepresented transactions .... except this is a social engineering
misrepresented transaction (rather than social engineering
chips by themselves are not necessarily a panecea. there have been past
chip-based systems that have simple static data authentication ...
making their threat/vulnerabilities little different than magstripe
threat/vulnerabilities. there have also been MITM attacks on chips where
the chip does dynamic data authentication  ... and then proceed to do
unauthenticated transactions. this can also be represented as separating
authentication and authorization ... and the crooks slip into the cracks
between the authentication and the authorization.
lots of past fraud, threats, and vulnerability posts

@_date: 2005-07-09 12:17:43
@_author: Anne & Lynn Wheeler 
@_subject: the limits of crypto and authentication 
the x9a10 financial standard working group was charged with preserving
the integrity of the financial infrastructure for all retail payments
... and came up with x9.59
besides the two business rules mentioned before, there were guidelines
about being able to fit within the existing financial transaction
*straight-through processing* transaction model ... aka the consumer
originates the transaction and it can be processed in a single round trip.
there were provisions that the consumer should originate the transaction
... and/or at least have certified terminal when presented with the
option to sign; misc. past posts about the EU finread terminal standard
worst case is that the foreign terminals are still susceptable to
various compromises ... like misrepresnting the transaction. Not that
this is slightly lower threat model since the point of compromise and
the point of fraud are the same place ... and therefor are subject to
quick shutdown. recent post mentioning paranoid consumers needing
pda/cellphone portable devices at point-of-sale as countermeasure to
various transaction misrepresentation vulnerabilities
 massive data theft at
MasterCard processor
x9.59 does provide for interaction outside the *straight-through
processing* of the financial transaction. for instance, x9.59 has
provision for including the hash of the *order details* in the body of
the signed x9.59 transaction. the consumer returns such a signed message
to the merchant. at this point the merchant can verify that the hash of
*order details* in the body of the x9.59 digitally signed transaction is
the same as their computed hash of *order details*. This is
countermeasure against consumer attack on the merchant. While the body
of the *order details* isn't part of the actual financial transaction,
in the case of any dispute ... the two parties can produce their
purported versions of *order details* and see which one hashes to the
same value contained in the x9.59 digitally signed transaction.
from 3-factor authentication
* something you have
* something you know
* something you are
the digital signing represents "something you have" authentication (i.e.
the originator has access to and use of the private key).
for lost/stolen countermeasure ... the private key may be protected in a
hardware token and/or software file can require a PIN to operate.
the next level of detail for the relying party (financial responsible
institution performing authentication, authorization and transaction
execution) could be labeled parameterized risk management .... i.e. much
lower level details regarding the integrity of the private key
protection (i.e. evaluation level of any hardware token), environment
and location that the transaction happened, other details of components
involved in the transaction, etc.
part of the conventional, single round trip, *straight-through
processing* financial transaction paradigm is a log as countermeasure
for replay attacks. In many conventional, internet *chatty* protocols,
one side includes a unique random number that the other party includes
in subsequent transactions (as countermeasure to replay attacks). In the
conventional, single round trip, *straight-through processing" model ...
the originator makes the transaction reasonably unique (like including
date/time, etc) and the relying party checks the current transaction
against a log of previous transaction (as countermeasure to replay attack).
turns out that logs/audit trails as useful in general ... and frequently
required anyway when performing financial transactions.

@_date: 2005-07-10 10:22:27
@_author: Anne & Lynn Wheeler 
@_subject: Why Blockbuster looks at your ID. 
the issue is lost/stolen credit cards ... your name is embossed on the
plastic and recorded on the mastripe. this provides for the
point-of-sale to check for lost/stolen card by attempting the
identification process of matching the name on the card with the name on
something else.
this moves the card out of the relm of authentication into the relm of
identification. there was a number of threads (mostly prior to 9/11)
about EU privacy directives for making retail electronic transactions as
anonymous as cash. basically this involved removing your name from the
plastic embossing and magstripe ... so that the card was purely an
authentication "something you have" .... and didn't wander across the
line into identification. lost/stolen card risks then could be contained
by deactivating accounts when the owner reported the card lost/stolen
part of the issue has been the appearance of skimming/harvesting compromises
where the crooks didn't actually have to physically steal the card, they
could electronically record the necessary information (w/o the owner's
knowledge) and then perform fraudulent transactions. The
skimming/harvesting compromises can involve tens of thousands of cards
... not just a single card at a time. Also, the fraud period instead of
being limited to possibly a few hrs (when the owner reports the missing
card), now could extend to a few weeks (since the owner doesn't notice
unitl they get around to examining the next statement). The
skimming/harvesting threat and vulnerability can magnify the fraud risk
by several orders of magnitude (compared to simple lost/stolen).

@_date: 2005-07-10 10:33:01
@_author: Anne & Lynn Wheeler 
@_subject: Why Blockbuster looks at your ID. 
this is the EU privacy directive threads that went on (mostly prior to
9/11) and why couldn't they apply in the US also ... aka that electronic
retail transactions could be as anonymous as cash. names would be
removed from the plastic embossing and magstripe ... and the merchant
would not longer have to wander across the line from authentication into
identification (attempting to match the name on the card with other
when we started x9.59 in the mid-90s,
we frequently commented that it was privacy agnostic. it provided strong
authentication that didn't have skimming and harvesting threats and
vulnerabilities. there was a strong correlation with some account number
... and the degree that there was some trail from that account number to
an individual was dependent on a lot of things outside of the financial
transaction itself. however, the basic financial transaction didn't
require wandering across the line from authentication into identification.
this was also the period where it started to show up the shortcomings of
the x.509 identity certification paradigm that had somewhat tried to get
 some toe hold in the early 90s .... including grossly overeloading the
certificates with personal information. basically that every digitally
signed transaction in the world would carry a huge x.509 identity
certificate grossly overloaded with personal information. Not only would
all such transactions carry such humongous personal information
repositories, while in flight .... but all the transaction logs would be
heavily burdened with the same information. You might have tens of
thousands of transactions logs all over the world ... and every one
would include a humongous x.509 identity certificate grossly overloaded
with personal information.

@_date: 2005-07-10 11:43:25
@_author: Anne & Lynn Wheeler 
@_subject: the limits of crypto and authentication 
this is also the EU finread standard
which has a certified display and certified pin-pad. it was for token
reader external to the PC ... so that what is displayed is what gets
signed ... and the PIN entry isn't easily compromised. This still
somewhat assumed standard 7816 card w/o its own display and pin-entry.
the issue in x9.59 design
was that it was possible for the relying party to get certified
integrity information about the hardware token at the time the public
key was registered .... and recheck that certified integrity information
(binding to the public key) on every digitally signed transaction ...
the EU finread standard didn't provide for the similar level of assurance.
x9.59 allowed (but didn't mandate) that the environment, in which the
signing took place, could also digitally sign the transaction. this
could provide the relying party a binding not only between the integrity
of the token doing the digital signing .... but also a binding between
the environment that the digital signing took place and the integrity of
that binding.
The base EU finread terminal scenario provides for a standard for high
integrity digital signing environment. However, it doesn't provide for
any proof to the relying party that such a terminal was actually used
for any specific transaction. Having the public key of the EU finread
terminal registered along with the associated certified integrity level
of that environment .... then if such a terminal was also to digitally
sign the transaction, the relying party could do some risk assesement
both on the integrity of the token performing the digital signing (for
authentication purposes) and the integrity of the signing environment
If the display, pin-entry, and authentication token were tightly bound
in the same device .... then when the relying party registered the
public key for authentication purposes .... they would also register the
associated integrity characteristics of the hardware token (for
authentication purposes) as well as the display and pin-entry (for
integrity related to the signing environment).
The issue here is that the relying party is fundamentally interested in
the overall risk of the transaction ... which is composed of a lot of
individual integrity characteristics.
Relating this to the old style x.509 identity certificate .... grossly
overloaded with personal information .... a relying party ... can have
done an authentication binding regarding the public key (i.e. don't
necessarily need to have the identity of the person .... such know that
the authentication indicates the entity is the one that is authorized to
performed the related operations .... w/o having across the line from
auhentication into identification and grossly confusing the difference
between the two).
One the relying party has done the straigth-forward authentication
binding for a hardware token and a public key .... the really
interesting charactistics for the relying party is all the integrity
characteristics surrounding a transactions.
To some estent, the PKI identity-centric focus have tended to distract
relying parties from the more fundamental risk issues regarding
integrity characteristics of performing the transaction. One an entity
is registered as enabled for performing valid transactions (which can be
a purely authentication operation w/o getting grossly confused about the
difference between authentication and identification), then issues of
certification interest to a relying party are the integrity
characteristics of the authentication events (and the enormous
concentration by PKI bodies on confusing identification with
authentication tends to be a pure distraction to the risk assesement of
the operations).

@_date: 2005-07-10 10:03:03
@_author: Anne & Lynn Wheeler 
@_subject: the limits of crypto and authentication 
two-factor authentication per se, isn't necessarily the panecea.
pin-debit ... has a magstripe card as "something you have" and a pin "as
something you know". as recently mentioned, compromised ATM &/or POS
machines have been able to skim the magstripe and the pin .... enabling
creation of counterfeit cards and fraudulent transaction.
in x9.59,
a hardware token can digitally sign the actual financial transaction.
this would be single factor, "something you have" authentication.
skimming and/or harvesting the transaction and/or transaction log files
doesn't enable either counterfeit cards and/or fraudulent transactions.
the issue of a PIN, in conjunction with the magstripe card for
two-factor authentication, was a countermeasure against lost/stolen
card. However, skimming as a threat, is able to capture both the PIN and
the card magstripe information, enabling fraudulent transactions.
a single-factor authentication hardware token ("something you have")
that digitally signs the transaction is sufficient countermeasure
against skimming and harvesting.
Enforced PIN-debit ... i.e. where the magstripe can't be used w/o the
PIN ... turns out to be a countermeasure against some of the transaction
log harvesting (the type of data breach stories recently in the press)
... since the PIN information isn't normally carried in the transaction
log. The issue with the transaction log is that there are several other
merchant business processes that require access to transaction information.
The issue with magstripe and PINs ... is the threat and vulnerability
model effectively is a replay attack ... static data that can be
relatively easily recorded and repeated in fraudulent transactions
(and/or used to create counterfeit magstripe).
A "single factor" authentication hardware token that digitally signs
that transactions, is countermeasure against attacks recording static
data for replay-type attacks.
Adding a PIN or biometric authentication to a hardware token for "two
factor authentication" .... doesn't improve the countermeasure to
skimming and harvesting attacks. The PIN or biometric authentication in
conjunction with a hardware token is primarily countermeasure for
lost/stolen token ... not countermeasure for skimming/harvesting
replayable information.
There is has been a separate issue with the use of pin/passwords
for "something you know" authentication, is people having large number
of different accounts .... each, supposedly requiring unique "something
you know" shared secrets. The estimate is that possibly 30percent of the
debit cards have PINs written on them. The issue is basic human factors
and blindly adding "something you know" shared secret as a second
authentication factor doesn't necessarily significantly improve the
situation. so you are possibly faced with having to fundamentally rework
some of the authentication landscape to compensate for well documented
human short comings.
So two possible pieces for reworking this portion of the authentication
landscape (for human factor shortcomings with proliferation of large
number of shared-secrets)
1) certified tokens that accept PINs for operation. the PINs are
shared-secrets since they don't travel past the token. The token is in
the person's possession and the PIN is just for activating certified
token operation. this can contribute to the person being able to
initialize all tokens to the same PIN
2) transition from institution-centric tokens to person-centric tokens
... aka rather than every institution in the world issuing a token ...
and each token possibly requiring a single PIN, people can acquire some
small number of personal tokens and register their personal tokens for
valid "something you have" authentication at different institutions.
A big issue in the recent data breach stories with respect to security
PAIN acronym
P ... privacy
A ... authentication
I ... integirty
N ... non-repudiation
is that many of the infrastructures tend to have relatively strong
integrity requirements for their business records. this protects the
infrastructure business operations. however, they tend to have much
lower privacy requirements ... in part because the large number of
business processes that require access to those records. furthermore,
the privacy threats and vulnerabilities isn't directly against the
infrastructures .... the privacy threats and vulnerabilities are against
their customers. This, then becomes, you offering to pay for all
automobile repairs and maintenance for the rest of the people in your
town ... because it improves the overall safety of the roads.
There is a large privacy threat and vulnerability for the customers of
these institutions .... because of the pervasive use of static data for
authentication and the readily available technology to record and
replay/counterfeit that static data for fraudulent transactions.
So the privacy play is hard
* pervasive use of static data for authentication
* pervasive use of the same static data for multitude of standard
business processes
* readily available technology to record and replay/counterfeit static
data for fraudulent transactions
* the privacy threat and vulnerability risk isn't directly for the
majority of the institutions that need to provide the countermeasures
* entities directly at risk aren't in position to provide most of the
* the value of the static data to the institutions is typically
relatively low
* the value of the fraudulent use the static data to the entities at
risk can be extremely high
... aka, this is related to the security proportional to risk posting
where business operations have a frequent requirement to access the
static data as part of normal business operations ... and the value of
that data is proportional to the profit off an individual transactions.
the business operations aren't directly at risk to the privacy threat
and vulnerability. the entities having the privacy threat and
vulnerability can be at risk equal to their credit limit (or their bank

@_date: 2005-07-10 13:36:04
@_author: Anne & Lynn Wheeler 
@_subject: the limits of crypto and authentication 
another characteristic of the PKI x.509 identity certificate activity
(besides attempting to create mass world-wide confusion regarding the
difference between identification and authentication ... and trying to
get govs. to mandate that x.509 identity certificates, grossly
overloaded with personal information had to be appended to even the most
simple of authentication transactions) .... was trying to cause a great
deal of confusion about the difference between *digital signatures* and
*human signatures*. some of this possibly was semantic confusion because
both of the terms; *digital signature* and *human signature* contain the
word *signature*.
nominally a digital signature is the use of a private key to encode a
message/document hash. the relying party then recalculates the
message/document hash, uses the corresponding public key to decode the
digital signature, and compares the two hash. if they are equal, the
relying party assumes:
1) the message/document hasn't been altered (since the digital signature)
2) "something you have" authentication, aka the originator has access
and use of the private key.
the base technology is asymmetric key cryptography (what one key
encodes, the other key decodes). the business process of public key,
identifies one key as publicly available. the other key is kept
confidential and never divulged. the integrity of "something you have"
authentication can be improved by deploying secure hardware tokens where
the key pair are generated in the token and the private key never leaves
the token (improving the probability that the private key is never
now, normal *human signature* implies read, understood, agrees,
approves, and/or authorizes. The normal *digital signature* is purely a
"something you have" authentication process implying none of the
characteristics of a *human signature*. In fact, a series of my pasts
posts on *dual-use attacks* was specifically with using the same private
key to apply digital signatures to random data (as part of
authentication operations) and digital signatures to non-random data
(assuming human signature characteristics).
Somewhat in support of helping create world wide confusion about the
differences between *digital signatures* and *human signatures* (in
addition to creating world wide confusion about the difference between
authentication and identification), the PKI x.509 digital certificate
standard also defined a non-repudiation bit. For some number of
PKI-oriented payment protocols in the mid-90s, there was the
specification of digital certificates with the non-repudiation bit
turned on. Supposedly, if a merchant could demonstrated any valid
digital certificate with the "non-repudiation" bit turned on (for the
customer's public key), then the burden of proof in any dispute would
have shifted from the merchant to the consumer. The threat/vulnerability
1) the PKI-oriented protocols provided no mechanism for proving which
certificate had been originally attached to the transaction
2) supposedly the "non-repudiation" bit was capable of turning any
digital signature operation (regardless of the environemnt in which the
signature had been performed) magically into a *human signature*
carrying the attributes of read, understood, agree, approve, and/or
So the PKI x.509 identity digital certificates were targeted at
1) turning every transaction in the world (even the most trivial
authentication operation) into a heavy duty identification operation
(with attached x.509 identity digital certificates carrying enormous
amounts of personal information)
2) allowing anybody that could produce a valid digital certificate (for
the associated public key) with the non-repudation bit on, to magically
turn all associated *digital signatures* into *human signatures* (even
digital signatures that had been presumably been performed on random
data for purely authentication operations).
since that time, the use of the certificate-based "non-repudiation" bit
has been severely depreciated (many people coming to realize that it
takes more than magical PKI bits to turn *digital signatures* into
*human signatures*).
there were some that started to realize that the PKI x.509 identity
certificate model represented severe privacy and liability issues. The
initial quick&dirty fix were the relying-party-only certificates
containing just public key and some sort of database lookup index.
The issue here is that it is trivial to demonstrate that such
relying-party-only certificates are redundant and superfluous .... if
the relying party already has all the information, then the relying
party can directly look up the necessary information (including
registered public key as well as all integrity characteristics that
might be associated with that public key ... and the last thing they
need are redundant and superfluous relying-party-only digital certificates).

@_date: 2005-07-10 15:50:17
@_author: Anne & Lynn Wheeler 
@_subject: Keeping an eye on ATM fraud 
Keeping an eye on ATM fraud
What happened to the good ole days when the magnetic stripe was king?
Remember ? those were the days when you didn?t have to worry about ATM
devices that skim or trap. In today?s techie world, those days are long
gone, and the mag-stripe?s life is nearing its end.
... snip ...
note, as in previous posts ... it isn't just the skimming of static data
from the magstripe (as well as pin-hole cameras that capture any pin)
.... but it is being able to capture the static data at any point in the
and use that static data in any kind of subsequent fraudulent transactions.
For the *enforced* PIN-debit and *enforced* x9.59 operations, it also
means that normal static data is *never* sufficient to perform a
transaction .... that authentication is always required.
The specific issue for PIN-debit is that technology advances are making
it easier to skim both the magstripe as well as the PIN ... and then
reproduce them for fraudulent transactions. *Enforced* PIN-debit does
improve situation (compared to regular credit magstripe) that harvesting
static data from transaction logs is normally not sufficient to perform
fraudulent transactions. *enforced* PIN-debit has somewhat higher
resistance to the data breaches that have been in the press ... since
the necessary PIN won't be found in the standard log and accounting
files for standard business process (but PIN-debit is still vulnerable
to the skimming exploits at transaction origin).
ecdsa on x9.59 transactions
won't expose any of the information to originate a fraudulent
transaction (the specific account number and digital signature may be
exposed ... but not the private key).
A PIN on digital signature transactions can act as a countermeasure for
lost/stolen token exploits. The issue is that the PIN doesn't make a lot
of difference on point-of-origin skimming exploits ... since the PIN
will nominally be captured (but not the private key). Digital signature
with private key (that is never divulged) for *enforced* x9.59
transactions (i.e. the related static information can never be used
succesfully for a non-x9.59 transaction) is sufficient countermeasure
against both skimming and harvesting vulnerabilities.
A lot has been made of two-factor authentication as being necessary as
countermeasure for majority of the current threats and vulnerabilities.
A majority of the current threats and vulnerabilities are authentication
infrastructures that use static data for authentication (and the static
data can be skimmed and used for fraudulent transactions). Simple
(static data) two-factor authentication isn't a countermeasure for the
skimming exploits, while (dynamic data, like digital signature) single
factor authentication is a countermeasure for the skimming and
harvesting exploits.

@_date: 2005-07-10 16:26:59
@_author: Anne & Lynn Wheeler 
@_subject: US consumers want companies fined for security breaches 
US consumers want companies fined for security breaches
The majority of US consumers want to see criminal charges levied against
companies that fail to protect their personal data, as one in five
individuals admit falling victim to identity theft.
... snip ...
part of this is the risk proportional to security post that i frequently
part of the issue is that these tend to not be security *integrity*
breaches that threaten the companies involved. these tend to security
*privacy* breaches that threaten the customers, where (static) personal
data can be used in account and/or identity fraud. In some cases, as
little information as a valid account number is sufficient to generate a
succesful fraudulent transactions.
I had provided a motherhood statement for the x9.99 financial standards
privacy standard .... something to the effect that most *privacy*
security tends to require a rethinking of the security landscape ....
since these security threats aren't directly against the institution,
they are against customers of the institution (unless the gov. can
translate such *privacy* breaches into direct threats against the
institution in the form of fines or other regulatory/legislative action).
somewhat related post
 the limits of crypto and

@_date: 2005-07-11 09:07:45
@_author: Anne & Lynn Wheeler 
@_subject: City National Bank is the latest major US company to admit it has 
City National Bank is the latest major US company to admit it has lost
customer data.
The bank says it lost data back-up tapes in April, while they were being
transported to a secure facility by third-party data storage company
Iron Mountain.
The sensitive data contained account numbers, social security numbers...
... snip ...

@_date: 2005-07-11 12:54:27
@_author: Anne & Lynn Wheeler 
@_subject: the limits of crypto and authentication 
there is two issues for digital signatures ...
1) "something you have" authentication and
2) proof to the relying party as to the integrity level of the operations
it is possible to establish the integrity level of the hardware token at
the time the public key is registered ... and then possibly track the
token integrity level as it degrades over time (because of technology
in the EU finread standard case
it assumed that the display/pinpad and the token were separate. the the
case of relying party being able to evaluate the risk of the transaction
... then it would actually need the separate display/pinpad to also
digitally sign the transaction (and also having previously registered
the finread terminal public key and integrity level).
the co-signing by the separate display/pinpad was allowed for in x9.59
financial transaction standard
but not mandated.
when the display, pinpad, and token are all a single device ... then
there would only be a requirement for a single digital signature ...
representing both the "something you have" authentication as well as the
integrity level of the signing environment.
in the *human signature* realm there is the aspect of many financial
point-of-sale termainals where there is requirement for some sort of
manual, human interaction that demonstrates some sort of agreement,
approval, and/or authorization of the transaction (in addition to the
authentication operation). frequently this is a display of the
transaction requiring the person to hit the agree/yes button ... as a
separate operation from any authentication operations.

@_date: 2005-07-12 12:28:20
@_author: Anne & Lynn Wheeler 
@_subject: the limits of crypto and authentication 
my impression of the 3party x.509 identity certificate model of the
early 90s ... was that every person would pay $100/annum for their
identity certificate grossly overloaded with personal information.
the certificate model has a design point from the early 80s, offline
email, where the receiver dials their local (electronic) postoffice,
exchanges email and hangs up. they then are faced with dealing with
first time email from total strangers. the x.509 identity certificates,
grossly overloaded with personal information ... were targeted at
(hopefully) including at least one piece of personal information (about
the sender), that the receiver might find useful when dealing with total
moving into the early 90s, with a model where everybody would have
$100/annum identity certificates ... the apparent business model would
be that all established business relationships would be done away with
... and people would only be performing spontaneous business
transactions with total strangers ... supported by the x.509 identity
certificates. For instance, rather than depositing money in an
established bank account .... you would spontaneously contact a total
stranger to accept your large sums of money. The exchange of x.509
identity certificates with total strangers would provide sufficient
trust and integrity to safegard your large sums of money.
Moving into the mid-90s, some institutions started to realize that such
x.509 identity certificates represented huge privacy and liability
issues and there was some implementations by financial institutions of
relying-party-only certificates
which only contained a public key and some sort of database lookup index
 (as unique information) along with a lot of CPS and other types of
certification accounting gorp. In this situation, it was trivial to show
that such relying-party-only certificates were redundant and
superfluous: the relying party already has all the necessary information
on file, which invalidates the certificate design point of providing
"letters of credit" type of information between two strangers in first
time communicate (where there is no other recourse for information about
the party you are dealing with).
of course, there was a side issue in these payment protocols from the
period. the typical iso8583 payment message is on the order of 60-80
bytes. the typical overhead for even the relying-party-only certificates
(attached to every payment message) was on the order of 4k-12k bytes ...
leading to an enormous payload bloat of one hundred times for something
that was totally redundant and superfluous.
In general, the design point of x.509 identity certificates were to turn
all transactions (regardless of kind, even the most lightweight
authentication transactions) into heavyweight identification operations.
You would even find some govs. passing legislation that was oriented
towards mandating x.509 identity certificate be appended to every
digital signed transaction ... even when you might be looking at purely
a lightweight "something you have" authentication operation.
misc. recent posts on the subject:
 EMV cards as identity cards
 Digital signatures have a big
problem with meaning
 The Worth of Verisign's Brand
 The Worth of Verisign's Brand

@_date: 2005-07-12 12:42:29
@_author: Anne & Lynn Wheeler 
@_subject: the limits of crypto and authentication 
there are a couple of issues. in some ways .... if institutional-centric
physical tokens were to be succesful ... you would start to see one in
lieu of ever pin, password, &/or shared secret ... for every possible
type of relationship requiring authentication.
there was an issue in the early e-commerce days
a lot of the funding for the early commerce server work was targeted at
a "mall" type environment/experience ... where a large outsourcer would
provide electronic "mall" space for retail stores. The apparent
assumption was that the physical distance metaphor addressed by shopping
malls, would be carried over into the internet. however, the basic
characteristic of the internet & the world-wide-web already was
obliterated physical distance concepts. the issue then was why would a
metaphor designed to address physical distance limitations, carry over
into an environment where physical distance was a meaningless concept.
the issue with many of the existing issued cards and tokens are that
they are institutional-centric, one per institution. this could approach
the DRM/copy-protect approach of the mid-80s ... where applications were
being shipped with unique floppy disks that were required to be mounted
anytime the application was executed. an operation with one or two such
applications wouldn't be so bad ... but can you imagine that being
succesful today? .... where you might have hundreds of such floppy disks
and requirement to have a dozen such floppy disks concurrently mounted
in a single floppy drive ... and possibly having to select and exchange
floopy disks (from a pile of hundreds) several times a minute.
i contend that the physical store checkout and payment model ... where
you are physically performing checkout and can likely do only one such
at a time .... has analogies to the shopping mall physical metaphor
model ... and it starts to hit limitations when you translate that into
internet electronic metaphor with the possibility of multiple things
going on concurrently

@_date: 2005-07-12 18:55:26
@_author: Anne & Lynn Wheeler 
@_subject: EMV 
... the original introduction of HK octopus transit card used the
"sony" flavor of iso 14443 with 10cm and transit requirements of
transaction in 100ms. having it in the bottom of a bag and bringing the
bag within 10cm of the reader does the trick.
there was a transit meeting where the mondex people attended ... they
claimed that they could also be used for transit ... just get a wireless
sleave for the mondex card ... and build 14' long tunnels leading up to
the transit gates ... and have the people walk slowly thru the tunnels.

@_date: 2005-07-13 10:49:30
@_author: Anne & Lynn Wheeler 
@_subject: UK EU presidency aims for Europe-wide biometric ID card 
UK EU presidency aims for Europe-wide biometric ID card
The UK is using its Presidency of the Council of the European Union to
push for the adoption of biometric ID cards and associated standards
across the whole of the EU. In a proposal issued on Monday (11th July),
the UK calls for the drafting of "common standards for national identity
cards taking into account the achievements in relation to the EU
passport and in the ICAO framework."
,,, snip ...
note that some EU govs. are trying to have legislation that has an x.509
identity certificate appended to every digital signature. this
effectively turns even the most lightweight digital signature
authentication even into a heavyweight identification event.
when we were called into help word-smith the cal. state and later the
fed. electronic signature law ... a lot of effort went into making the
wording technology agnostic as well as trying to avoid confusing
authentication and identification. the other force that was somewhat at
work was moving things in the direction that a digital signature could
take on the attributes of a human signature (possibly because of
semantic confusion over both terms; *digital signature* and *human
signature* containing the word *signature*) ... including that if a
digital signature was discovered ... that human intent, read,
understanding, agrees, approves, and/or authorizes was somehow implicit
in the existance of a digital signature.

@_date: 2005-07-13 11:25:43
@_author: Anne & Lynn Wheeler 
@_subject: ID "theft" -- so what? 
there are a couple issues
1) using any widely known information for authentication.
2) standard security kindergarten 101 requires that every unique
security domain requires a unique shared secret (if shared secret is
used for authentication)
3) any information that is used for authentication should be dedicated
for authentication and not widely used in large number of other business
processes (like account numbers)
4) static data authentication (whether unique or not) is subject to
skimming for various kinds of replay and impersonation attacks.
the issue with digital signatures and private keys ... is that the
digital signature can be unique per transaction ... and that the
mechanism which is used to originate the transaction (private key) is
never divulged ... countermeasure against the skimming attacks on
transaction origin.
note that there have been some poorly designed digital signature schemes
that separate the authentication from the transaction ... such that they
are subject to MITM-attacks

@_date: 2005-07-14 08:25:42
@_author: Anne & Lynn Wheeler 
@_subject: the limits of crypto and authentication 
there was an observation that SET possibly wouldn't divulge your account
number until the merchant had been determined to be some entity
registered as a merchant (akin to the SSL domain name infrastructure
certificates ... if a spoofed site didn't use SSL until you hit the
pay/checkout button, what is the probability that the spoofed site
provide a URL that matched some valid certificate that they did have).
note, however, some of the participants even got confused about this issue.
note that there are a lot of merchant business processes that require
the account number ... and therefor you can't prevent the merchant from
possessing the account number. some might be tempted to observe that
there is a kind of conflict of interest ... using the same value for
authentication purposes as well as widely needed for a large number of
other purposes (akin to designing a system that widely uses your userid
a basis for normal functioning ... as well as making your userid also
your password).
some past posts where the SET issue of divulging account number was
 Credit Card # encryption
 Credit Card # encryption
 Credit Card # encryption
 non-repudiation, was Re:
crypto flaw in secure mail standards
 non-repudiation, was Re:
crypto flaw in secure mail standards
I thot the goal of SET was to maximize the number of RSA-ops being
executed in the world.
When I first obtained a copy of the initial SET specification, I did a
RSA-ops profile and a business operation profile. An acquatance had done
some work on the BSAFE library and improved the performance by a factor
of four times. I got him to run timing tests on the SET RSA-ops profile
across a number of different machines. I then communicated the results
to a number of people that were part of the SET group. The reply from
various members of the SET group was that the numbers were obviously one
hundred times too slow (the correct answer should have been that the
numbers were four times too fast). Six months later when the first
prototype SET code was running ... their measured numbers were within a
couple percent of my earlier profile numbers (aka the BSAFE enhancements
had been given back to RSA).
One possible observation was that SSL work
was already providing account number confidentiality for
*data-in-flight*.  The significantly much more complex, and heavyweight
SET would have needed to provide countermeasures for significantly more
threats and vulnerabilities ... like security for *data-at-rest* (aka
data breaches) in order to make any headway against the (SSL) incumbant.
I also made a couple comments to the SET group about the heavy-weight
nature of SET (apparently the RSA-ops being one hundred times more
onerous than they had anticipated). Effectively, the SET RSA-op profile
was symmetrical .... but the standard processing is quite asymmetrical.
In effect, the massive datacenters that are currently processing credit
card transactions would have needed their computational facilities
increased by at least one hundred times (SET RSA-op profile was looking
at tens of seconds per transaction while many of these datacenters
measure their thruput in thousands of transactions per second ... a four
orders of magnitude gap).

@_date: 2005-07-14 11:09:21
@_author: Anne & Lynn Wheeler 
@_subject: the limits of crypto and authentication 
can you say that that processing overhead was on the order of 20-30
seconds (on completely unloaded infrastrucutre ... demos at shows and
conferences ... can you imagine what a little bit of queuing load would
do to it?) ... if merchants thot SSL was onerous ... just imagine what
SET did to the infrastructure .... and it provided effectively no
additional improvement over fraud vis-a-vis effectively only addressing
the confidentiality of account numbers as data-in-flight.
SSL was the encumbant, was significantly less complex and significantly
lighter weight (even tho most merchants decided that it was too heavy
except for the credit card portion) and provided effectively the same
amount of anti-fraud as SET.
If you had two products ... both effectively performing the same
function, one you already had deployed, which was significantly cheaper,
significantly simpler, and significantly faster, which one would you choose?

@_date: 2005-07-14 11:41:52
@_author: Anne & Lynn Wheeler 
@_subject: the limits of crypto and authentication 
this was some of the confusion between identification and
authentication. The SET effort was smart enuf to not do x.509 identity
certificates and instead do relying-party-only certificates
and they even made comments about the enormous privacy and liability
issues raised with x.509 identity certificates.
They also avoided doing any sort of PKI infrastructure ... aka the
management and administration of the certificates. The effectively were
doing the same stuff as the original SSL domain name certificates ...
for which we coined the term "certificate manufactoring" (to
differentiate from a certificate administrative and management
operation). They basically said that the certificate only contained the
account number ... and the account number could be turned-off at the
issuing financial institution ... making it redundant and superfluous to
also have to have a separate infrastructure for invaliding the certifcate.
So they have an online infrastructure with real-time transactions and
real-time operation of the real information. It is an extremely trivial
additional step to show that then the certificates themselves are
redundant and superfluous.
The cost of the certificates only become an issue if you are talking
about having to pay a trusted third party, $100/annum for every certificate.
So we can take this in incremental steps.
1) you have the consumer's financial infrastructure register the public
key. they then can generate and issue a relying-party-only certificate
to the consumer (containing the consumer's public key and account number).
2) there was work started in X9 financial standards body on compressed
certificates. Even the SET relying-party-only certificate overhead ran
4k-12k bytes. The typical iso8583 financial message is on the order of
60-80 bytes. Even the trivial SET relying-party-only certificates
represented a payload bloat of one hundred times (besides the RSA-ops
inflating processing overhead by 3-4 orders of magnitude).
3) Because of the enormous payload bloat contributed by the
certificates, the digital signature processing was being truncated at
the internet boundary and a standard iso 8583 message was then generated
with a flag turned on indicating that the internet had validated the
digital signature. The merchants had an incentive to see that flag
turned on since that was the basis on which a lower discount was
calculated. At an ISO meeting in europe ... one of the association
network people presented statistics on the number of iso 8583 messages
that they found with the flag turned on and they could prove that no
digital signature technology could have been involved
4) I presented an argument that a valid compressing technology is to
eliminate all fields from the (certificate) contents that were known to
already be in possession of the relying party. Since it could be proved
that all fields in the SET relying-party-only certificate were already
on file with at the consumer's financial institutions ... it would be
possible to eliminate all fields from the relying-party-only
certificates. If they preferred, i would start describing the process of
appending zero byte digital certificates as an alternative to describing
certificateless digital signature operation
5) The consumer's financial institution could effectively use the
existing business processes for registering PINs as a mechanism for
registering public keys. That is not known to be an expensive business
process. A consumer's financial institution then could set up a website
where the consumer could later retrieve their (redundant and superfluous
relying-party-only) digital certifcate. There is some integrity
constraints here ... but since the purpose of a digital certificate is
to spray it all over the world ... there isn't a lot of confidentiality
constraints (i.e. it doesn't hurt a lot if other people pick up your
digital certificate). However, since both the public key and the digital
certificate would already be on file ... you could require people to
perform digital signature authentication before picking up their
redundant and superfluous digital certificate. This does have an
unfortunate downside since it highlights that consumer digital
signatures can be validated by onfile public keys w/o needing digital
6) there were lots of comments that leaving all the PKI gorp in the
hands of trusted third parties was a trade-off of the
$100/annum/certificate against the upfront costs of modifying mainline
production systems. The two problems was that only worked as long as the
PKI stuff was being limited to toy demos. For any sort of producting
a) the $100/annum/certificate would exceed the costs of upgrading
mainline production system,
b) toy demos didn't have to worry about customer calls, if you wanted to
provide a service, you have to take trouble/customer calls. To have
integrated financial institution trouble/customer sevice ... you have to
integrate the public key stuff into the production systems.
aka ... the only scenario where you could use trusted third party
trade-off of $100/annum/certificate against modifying production systems
was in the toy demo stage.
7) concurrent with SET ... we were also working in the X9A10 financial
standards working group ... which had been charged with preserving the
integrity of the financial infrastructure for all retail payments. we
had done many of the detailed business and technology issue examination
coming up with x9.59 standard ...
which then made it much easier to spot them in the SET specification.

@_date: 2005-07-14 23:15:13
@_author: Anne & Lynn Wheeler 
@_subject: the limits of crypto and authentication 
I only know of MOTO ... the original netscape e-store and merchants processed thru the original payment gateway.
SSL originally just provided for webserver authentication. while we mandated mutual authentication for SSL between webservers and the payment gateway (before there was even a specification for mutual authentication). Information about the respective other end-point were preloaded in the respective servers ... so the use of digital certificates was purely an artificial artifact of the existing code base.
However, normal merchant webserver operation for SSL was purely one-sided authentication ... there was no form of client authentication that would provide any kind of basis for either cardholder-present or There is something for being there first, starting late 94 ...
remember what Verisign was called before it was renamed Verisign?
SET prototype shows up early fall 96 with dedicated demo systems appearing at conferences late '96 (dedicated demo systems taking 30 seconds elapsed time to perform transaction).
Two of the major risks and vulnerabilities that have been discussed are evesdropping on data-in-flight ... and data breaches at merchant databases ... old post on security proportional to risk
both SSL and SET addressed confidentiality of data-in-flight. Neither SSL nor SET addressed data breaches at merchant databases.
Going on in parallel with webservers doing MOTO transactions thru the payment gateway .... you also found some number of webservers doing emulated POS terminal dialup operations (also MOTO transactions). Some number of vendors were peddling software that was originally developed to run on PCs and autodial merchant processor (effectively emulated POS terminal dial) ... software originally targeted for hotels, casinos, etc.
... from long ago and far away:
The new SET (Secure Electronic Transaction) draft standard/
specs are now online at VISA and Mastercard for downloading.
The draft docs were just released yesterday (Feb 23).
The docs are available in Word and Postscript file formats
for Windows, Unix and the Mac.
Check out:
The Web pages also have information on how to subscribe to
the set-discuss mailing list.
- Morrow

@_date: 2005-07-15 12:13:35
@_author: Anne & Lynn Wheeler 
@_subject: the limits of crypto and authentication 
a harder problem for early stage web merchants was getting a merchant
financial institution .... the merchant financial institution that
sponsors a merchant for payment transactions ... takes financial
responsibility for that merchant.
the standard procedure was to send somebody out to the retail
brick&morter and do an asset inventory ... to see if the merchant went
under ... that there would be enuf assets left to help cover the
merchant financial institutions losses.
retail web merchants might have nearly zero assets ... they leased time
with a webhosting and fulfillment was outsourced ... so there was no
onhand inventory and effectively no assets. if they were totally
unsuccesful ... then the merchant financial institution would have
little outstanding transaction financial liability.
there were cases where merchant financial institution would try and
cancel a merchant as it became succesful ... since the outstanding
transaction liability for the merchant financial institution could be
going way up ... with no increase in assets to cover the finanical
institution's outstanding liability.
for such "high risk" merchants ... the merchant financial institution
discount might actually be bigger than the MOTO discount ... or any
difference between MOTO and card-present.
early web merchants tended to be existing brick&morter operations where
web MOTO ("mail-order/telephone-order") transactions were not separated
out from non-web MOTO transactions.
there were all sorts of strategy meetings in the '95 time-frame, brain
storming about how to get a bank's financial risk department to even
approve purely web merchant signup (and MOTO vis-a-vis card-present
wasn't a primary issue).

@_date: 2005-07-15 12:35:29
@_author: Anne & Lynn Wheeler 
@_subject: the limits of crypto and authentication 
there was a later "set-lite" w/o certs for clients ... but the original
specification had client certs as part of the core process.
note that the SET consumer certificate was *NOT* a x.509 identity
certificate ... because of stated reasons regarding privacy and
liability. It was a relying-party-only certificate that basically
contained the account number and the public key
It was also, not a true PKI ... since it didn't have any certificate
administration and management infrastructure. It was purely a
*certificate manufactoring* process (a term we had coined to
differentiate the early SSL certificate operations from what had been
defined for a PKI operation). Further, the statement was that they could
get by w/o a PKI operation ... since it was purely a "certificate
manufactoring" process using relying-party-only certificates (containing
just the public key and account number), the business process could be
managed by deactivating the account number in the *real*, real-time,
online operation.
quicky search engine for set-lite:
from above:
When MasterCard and Visa unveiled technology for secure Internet
electronic commerce transactions two years ago, they thought it would
take over the world.
But while Secure Electronic Transaction (SET) has made inroads in Europe
and Asia, it has faltered badly in the U.S. Faced with technical and
business obstacles to SET, MasterCard and Visa are now coming up with
alternatives to SET - SET Lite and Merchant-originated SET (MOSET).
But SET Lite and MOSET critically alter the SET 1.0 architecture and
soften SET's rock-hard security - all for the sake of convenience. For
example, the technologies abandon the idea that each online consumer is
going to have a bank-issued SET digital certificate for credit-card
encryption. This certificate was to be the main means of verifying the
consumer's real identity on the Internet.

@_date: 2005-07-15 13:05:11
@_author: Anne & Lynn Wheeler 
@_subject: the limits of crypto and authentication 
some reference:
little later, we got to review chaum and brand stuff. brand had done a
take-off on chaum's stuff so that if somebody double-spent (aka fraud)
... the financial institution could determine who did it (basically a
form of solving two equations in two unknowns).

@_date: 2005-07-16 10:48:14
@_author: Anne & Lynn Wheeler 
@_subject: the limits of crypto and authentication 
note that the bank-issued consumer SET digital certificate ... wasn't
used for credit-card encryption. the original set had this terribly
convoluted process where the consumer encrypted some of the stuff with
the *merchants* public key and other stuff with the *processors* public
the consumers relying-party-only digital certificate
was used for the client to perform "something you have" authentication
... aka digitally signing with the corresponding private key (aka the
verification of the digital signature implies that the signer has access
and use of the private key)
since it wasn't an x.509 identity certificate, didn't contain any
personal information, and was purely a relying-party-only certificate
... there was no real identity on the internet (avoiding raising
horrible privacy and liability issues).
futhermore, since it was a simple relying-party-only certificate, it is
trivial to demonstrate that it is redundant and superfluos ... aka just
flow the transaction thru to the consumer's bank ... and they can
validate the digital signature using the onfile public key. it isn't
necessary for the consumer to repeatedly append a relying-party-only
certificate to possibly thousands of transactions ... for transmission
back to the issuing institution ... which has the original *onfile*;
especially when the redundant and superfluous relying-party-only
certificate can represent a payload bloat of one hundred times.
note that the referenced article is dated 1999/3/22 and references the
original SET 1.0 deployment (full blown redundant and superfluous
relying-party-only customer certificates) two years earlier (spring
1997). The draft 1.0 specification had appeared spring 1996, initial
prototype appeared early fall 1996, and dedicaed demo systems showed up
at floor shows by the end of 1996.
the other reference indicates that browsers with ssl support appeared
late 1994 with big announcement the spring of 1995.
 the limits of crypto and
a trivial side-note ... since the SET specification wasn't issued by a
sanction standards body ... it wasn't a Standard in the official sense.
one of the operational differences between SET and x9.59 financial
industry standard ...
is that x9.59 has an operational rule that account numbers used in x9.59
transactions can't be valid in non-x9.59 transactions .... which
eliminates the requirement for horrendous amounts of cryptography as
countermeasure for evesdropping of transactions during transmission
(since evesdropping of the transactions doesn't provide an attacker with
sufficient information to perform fraudulent transactions). As a
by-product, it also eliminates the threats and vulnerabilities from
data-breaches ... where there is sufficient information in logged
transactions for a crook to perform fraudulent transactions.
In the SET scenario ... even when the transaction is authenticated using
digital signature ... there was still a requirement for horribly complex
cryptographic implementation as countermeasure to attacker evesdropping
the transaction and using the gained information to perform fraudulent
There is an issue where both account fraud and identity fraud have been
lumped under global identity theft label. In the strict account fraud
case, the attacker just needs to obtain sufficient information to
perform fraudulent transactions (against existing accounts) w/o
necessarily obtaining any real personal information.
While SET avoided the horrible privacy and liability issues with real
x.509 identity certificates by using relying-party-only certificates ...
it was still subject to account fraud where crooks obtaining access to
information from transaction (either *data-in-flight* or *data-at-rest*
.... aka data breaches) have access to sufficient information for
performing fraudulent transactions.
In contrast, x9.59 is signifcantly simpler and represents significantly
lighter payload ... and even eliminates the need to provide security
confidentiality for transactions as countermeasure against attackers
(both in the *data-in-flight* as well as the *data-at-rest* cases)
looking at performing account fraud transactions.
past posts mentioning x9.59 & business rules:
 Thin PKI won - You lost
 Simple PKI
 Erst-Freedom: Sic
Semper Political Cryptography
 DNSSEC (RE: Software
for PKI)
 CFP: PKI research workshop
 Who's afraid of Mallory Wolf?
 Maybe It's Snake Oil All the
Way Down
 SSL, client certs, and MITM
(was WYTM?)
 What happened with the
session fixation bug?
 payment system fraud, etc
 the limits of crypto and
 Net banking, is it safe???
 E-commerce security????
 Symmetric-Key Credit Card
Protocol on Web Site
 So how does it work...
(public/private key)
 Cirtificate Authorities 'CAs',
how curruptable are they to
 New Method for Authenticated
Public Key Exchange without Digital Certificates
 REVIEW: "Biometrics for Network
Security", Paul Reid
 More on garbage
 The Worth of Verisign's Brand

@_date: 2005-07-18 10:07:47
@_author: Anne & Lynn Wheeler 
@_subject: the limits of crypto and authentication 
the limits of crypto and
 the limits of crypto and
 the limits of crypto and
one of the issues raised in the x9.59 business rule case was whether
there are sufficient PANs (account numbers) to be able to temporarily be
able to issue two PANs for every account; one PAN useable against
account in X9.59 transactions and one PAN useable against account in
non-X9.59 (legacy, non-authenticated) transactions.
there was some issues raised about having multiple PANs pointing at the
same account ... but that is in wide-spread use already as normal
business practice.
Note that during any transition to secure x9.59 transaction ... the
worst case scenario is that there would be two PANs in existance for
every account. The issue raised whether the account number space is
large enuf to have two PANs for every account (note that if this turns
out to be a real issue ... it would also be a much larger problem for
one-time-PAN implementations ... where you might have hundreds of PANs
mapped to the same account number).
The problem for an X9.59 transition is actually somewhat less severe.
Part of the current PAN strategy is stacked against re-use of a PAN.
However, in the x9.59 transition case, I would claim that PAN re-use is
much less of a problem
1) re-use of any PAN for x9.59 use .... automatically disables the PAN
for all non-x9.59 use (if the PAN had some lingering legacy attachment
... that woulc be disabled as soon as it was assigned for x9.59 use)
2) re-use of a previously assigned x9.59 PAN for x9.59 use ... could
happen on somewhat accelerated schedule ... since the previous x9.59 PAN
use would have been associated with a public key that was no longer active.
the lingering issue as dangling business process associated with old
transactions that are bound to a specific PAN. re-use of PANs need to
after any such dangling business processes have been assured to have
the upside is that any transition to x9.59 would then give the consumer
some choice and/or control ... strict use of x9.59 transactions would
give the consumer some protection against most skimming, havesting and
data breach threats and vulnerabilities. such a consumer might then want
any non-x9.59 PANs to have very strict use limits (akin to some of the
customer specified limits available on pin-debit accounts ... or what is
available on dependent cards).

@_date: 2005-07-19 13:20:47
@_author: Anne & Lynn Wheeler 
@_subject: the limits of crypto and authentication 
there is also the EU bank challenge/response scenario (requires two-way
communication protocol chatter). the customer initiates a transaction
... on the internet or even over (voice) phone. the bank responds with a
challenge which is entered into a calculator sized device and the
display comes back with the response. the response then is either typed
or the keyboard (or the phone keypad).
basically it is a relatively dumb pin-pad sleave that a chipcard slips
into ... some old post visiting the company that makes the devices:
 Q: Internet banking

@_date: 2005-07-21 10:28:33
@_author: Anne & Lynn Wheeler 
@_subject: ID "theft" -- so what? 
an analogy i've used recently with respect to userid/password paradigm,
is that account numbers are being concurrently used for both the userid
function (requiring security *integrity* but not security
*confidentiality*) as well as the password function (requiring strong
security *confidentiality*). as a result there are frequently
diametrically opposing requirements where the muiltitude of userid-type
business functions require access to the account number ... at the same
time, the password-type functions require that the account number be
kept strictly *confidential* and not be available at all.
the x9a10 working group was given the requirement to preserve the
integrity of the financail infrastructure for all retail payments. the
resulting x9.59 protocol
* allowed for single round-trip, straight-through processing found at
many point-of-sale ... w/o requiring extraneous protocol chatter
* created a strictly enformed separation of the account number as a
userid-type function from digital signature as a password-type function
this eliminated the strongly conflicting goals of very weak
*confidentiality* requirement for use of the account number in the
multitude of userid-type business processes at the same time having a
very strong *confidentiality* erquirement for the same account number in
 its role as passoword/authentication.
this had the downside that there was potentially a maximum of two PANs
allocated for the same account during some transition period (where both
legacy, conflicting use of an account number was required and the new
x9.59 use of an account number requiring separate authentication).
it was startling that some of the strongest foes of x9.59 claiming that
there wasn't large enuf PAN space available to have a maximum of two
PANs per account (during some transition periods) ... subsequently were
strong backers of one-time-use PANs ... which might result in
potentially hundreds of PANs being mapped to the same account.

@_date: 2005-07-21 12:20:51
@_author: Anne & Lynn Wheeler 
@_subject: Qualified Certificate Request 
aads chip strawman
took a different approach ... the key pair is generated during the
power-on chip test process ... before the wafer is even sliced and diced
and the public key becomes an attribute of the chip (along with some
number of other individual chip specific integrity characteristics).
the resulting digital signature from the token isn't intended to
represent who you are ... it is intended to provide "something you have"
authentication ... aka the verification of the digital signature then
implies that the individual has access to and use of the corresponding
private key (and the specific hardware token that contains it). the
private key is never divulged and the public key and the digital
signature represent characteristics of the "something you have"
the public key can be registered ... and there is a service that allows
a relying party to retrieve the integrity characteristics of the
hardware token associated with the public key.
the issue is that the majority of the existing business processes go to
a great deal of trouble binding an identity to some set of business
process characteristics. the incremental issue for the majority of the
business processes in the world ... isn't with respect to who an
individual is ... but what are all the integrity and assurance
characteristics associated with the actual authentication business
the overall integrity and assurance characteristics associated with
hardware token public key digital signatures ... includes (at least) the
current time-varient characteristics of the specific chip (apparently
identical hardware tokens might have different chip generations with
different assurance characteristics depending on the date/time of the
manufactor of the specific chip), the key length, the particular digital
signature algorithm, the environment in which the digital signature
occured, whether the hardware otken performed a digital signature with
or w/o an associated PIN entry or with or w/o an associated biometric entry.
I've frequently asserted in the past that some number of PKI-oriented
interests have muddled and obfuscated the fundamental assurance issues
that most business processes have a real need-to-know ... and attempted
to substituted things that certification authorities might be doing when
 certification of information for inclusion in a digital certificate.
However, for the majority of things that have been talked about for
stuff that goess into certificates (like information for x.509 identity
certificates) ... is stuff that duplicates operations by long existing
and well established business process relationship management
One might conjecture that since most such PKI-oriented deployments
didn't provide the components of the end-to-end actual authentication
environment (hardware tokens, singing environments, validation
environments) ... that it was in their interest to maximize the
perceived value of the (mostly redundant and superfluous digital
certificates duplicating existing business process of long existing and
well established relationship management infrastructures) digital
certificates and minimizing the perceived value of the really important
assurance components of interest to relying parties.

@_date: 2005-07-21 16:48:49
@_author: Anne & Lynn Wheeler 
@_subject: ID "theft" -- so what? 
there was a vulnerability where attackers took the published algorithm
for valid account numbers and attacked using account numbers that
satisfied the published algorithm. somewhat as a result, guite some time
agao, the CVV field was added to the magstripe ... which could be
considered a kind of one-way hash of the contents of the magstripe ...
with some other stuff that is not predictable from the algorithm (as a
countermeasure to attacks from automatically generated account numbers).
one of the "business processes" is that somebody calls their issuing
bank and disputes a charge by a specific merchant on such & such a date.
the issuing bank eventually provides notice to the merchant (giving the
account number, date, and purchase details). the merchant then looks for
a transaction (in their transaction log) for that account number on that
date. In some cases, the merchant bank processor may provide an online
service for merchants ... where the merchant processor keeps the online
merchant transaction log on behalf of merchants for things like dispute
resolution (this may include things like online library of digital
images of the original reciepts).
There was a least one processing specification (possibly even mandatory)
during the 90s ... where each transaction was giving a unique
transaction identifier ... and transaction logs were only to be
referenced by the transaction identifier. However, consumers only
identified their account number by their account number ... and so
processes, like dispute resolution, continued to use the account number
as the identifier (and you need something else to be used for
authentication ... since the use of the account number as the identifier
is so ingrained into so many processes ... including the minds of the
however, with regard to the magstripe, there are lots of widely
published reports about magstripe being skimmed at point-of-sale
devices, at ATM machines (and/or the value of the magstripe being
skimmed in transit) ... and counterfeit magstripe/cards being produced
for fraudulent transactions.
here is a news article from yesterday about magstripe from credit/debit
cards being skimmed (including the CVV field) and used to rewrite the
magstripe on (magstripe) gift cards:
Gift Cards Carrying Cloned Data Used To Steal Gas

@_date: 2005-07-22 10:22:18
@_author: Anne & Lynn Wheeler 
@_subject: ID "theft" -- so what? 
a company can operate under possibly 3(?) different names ... a dba
name, a legal name, and some sort of general use name. the legal name
that a merchant signs a contract with a merchant financial institution
... can be totally different from the dba name.
i once found a legal name on a statement that was something like
"minority women owned title ?-something, no. ??? company" ... which was
totally different from the name on their store-front. I assumed that
their legal name was to help highlight their classification when bidding
on gov. contracts. the "no. ???" apparently was to differentiate them
from other companies that had also included the same reference to their
minority women owned status. I don't remember what the "title
?-something" was ... but it struct me as something where a minority
female owned small company was given special treatment in gov. bids.
i don't think it is so much a short coming of the merchant/financial
institution relationship ... it is just the general nature of the way
the society operates.

@_date: 2005-07-22 12:00:47
@_author: Anne & Lynn Wheeler 
@_subject: Qualified Certificate Request 
i ran into an interesting problem with EAL5-high. basically there
weren't any readily available crypto specification for getting higher
than an EAL4 certification.
most vendors that get higher than an EAL4 certification ... seem to get
it on a bare-bones chip before any applications are added ... and then
subsequently add applications (the fact that applications can be added
might be a security issue in itself). i've found it quite difficult to
figure out how to get a certification for higher than EAL4 when there
are any significant application already existing on the chip ...
especially for crypto; basically as the certification goes higher you
need a much more formal specification for the components to certify
against .... and i've found it difficult to find such formal
specification for crypto operation.
things like fips140-2 level 4 tends to be on the operation of the crypto
box against certifiable hardware operational characteristcs.
i've periodically posted requests in the past about anybody knowing of a
source for EAL5 or higher standards for crypto that can be certified

@_date: 2005-06-01 12:52:10
@_author: Anne & Lynn Wheeler 
@_subject: Trojan horse attack involving many major Israeli companies,  
there is the story of the (state side) financial institution that was outsourcing some of its y2k remediation and failed to perform due diligence on the (state side) lowest bidder ... until it was too late and they were faced with having to deploy the software anyway.
one of the spoofs of SSL ... was originally it was supposed to be used for the whole shopping experience from the URL the enduser entered, thru shopping, checkout and payment. webservers found that with SSL they took a 80-90% performance hit on their thruput ... so they saved the use of SSL until checkout and payment. the SSL countermeasure to MITM-attack is that the URL the user entered is checked against the URL in the webserver certificate. However, the URL the users were entering weren't SSL/HTTPS ... they were just standard stuff ... and so there wasn't any countermeasure to MITM-attack.
If the user had gotten to a spoofed MITM site ... they could have done all their shopping and then clicked the checkout button ... which might provide HTTPS/SSL. however, if it was a spoofed site, it is highly probable that the HTTPS URL provided by the (spoofed site) checkout button was going to match the URL in any transmitted digital certificate. So for all, intents and purposes .. most sites make very little use of https/ssl as countermeasure for MITM-attacks ... simply encryption as countermeasure for skimming/harvesting (evesdropping).
in general, if the naive user is clicking on something that obfuscates the real URL (in some case they don't even have to obfuscate the real URL) ... then the crooks can still utilize https/ssl ... making sure that they have a valid digital certificate that matches the URL that they are providing.
the low-hanging fruit of fraud ROI ... says that the crooks are going to go after the easiest target, with the lowest risk, and the biggest bang-for-the buck. that has mostly been the data-at-rest transaction files. then it is other attacks on either of the end-points. attacking generalized internet channels for harvesting/skimming appears to be one of the lowest paybacks for the effort. in other domains, there have been harvesting/skimming attacks ... but again mostly on end-points ... and these are dedicated/concentrated environments where the only traffic ... is traffic of interest (any extraneous/uninteresting stuff has already been filtered out).

@_date: 2005-06-01 10:37:51
@_author: Anne & Lynn Wheeler 
@_subject: Digital signatures have a big problem with meaning 
the bigger the transaction that the digital signature verifies .... the more the relying party is going to be interested in fundamental integrity issues surrounding the digital signature generation
from 3-factor authentication paradigm
* something you have
* something you know
* something you are
simple digital signature verification is basically "something you have" authentication ... implying that the originator has access to and use of the corresponding private key (in addition to the transaction not having been modified in transit).
fundamental issues surrounding digital signature can be the integrity level of the infrastructure preventing compromise of the private key aka is the private key protected in a software file, is the private key in a hardware token, was the private key generated in a hardware token and can never leave the hardare token. also if it is a hardware token, is a pin/password also required to make the token operate correctly i.e. knowing characteristics of the hardware token, the relying party might be able to infer two-factor authentication and assess the risk/threats also what is the integrity level of the infrastructure in which the digital signature was generated ... for instance some of the EU finread
which try and specify the minimum constraints for generation of a digital signature on a financial transaction.
this isn't so much proving anything ... this is risk management ... what is the likelyhood/exposure of a compromise for the relying party ... or security proportional to risk
standard types of things that you would find at financial institutions and/or insurance institutions.
part of the confusion possibly is because of the extensive deployment of PKI literature ... which tends to focus the attention on the certification process ... as opposed to the integrity of the authentication process. the issue is that for the majority of business operations ... the PKI certificate process tends to be duplication of extensive relationship management business process that they already have in use (and therefor is redundant and superfluous) ... and there is much less focus on the basic risk, threat and vulnerability issues related directly to the authentcation.
and as i've frequently postulated ... that same may have an interest in creating semantic confusion ... implying that because the term "digital signature" includes the word "signature" ... that it somehow bears some relationship to human signatures.

@_date: 2005-06-01 16:38:18
@_author: Anne & Lynn Wheeler 
@_subject: Citibank discloses private information to improve security 
i would claim that SSL-like protocol with both countermeasure for MITM-attack and eavesdropping attacks should be adequate.
many of the current problems is that browsers and email clients have tended to added multiple layers of obfuscation around the URL process ... so it may be difficult for even experience users to realize what is a semi-counter argument for defense-in-depth is KISS ... lots of complex   layers tend to create all sorts of cracks for the attackers to get thru.
in theory, the KISS part of SSL's countermeasure for MITM-attack ... is does the URL you entered match the URL in the provided certificate. An attack is inducing a fraudulent URL to be entered for which the attackers have a valid certificates.
so some of the recent internet phishing countermeasures are trying to rely on clear, un-obfuscated indications recognizable by even naive users. however, the tend to be add-ons, non-integrated with existing countermeasures (like SSL MITM-attack countermeasures) and leave existing systemic vulnerabilities in place. When purely static data un-obfuscated recognizable indications are used independently of MITM countermeasures .... a MITM can create active channels between themselves and the end-user and themselves and the website and transparently pass information between the two end-points.
Rather than complex defense in depth ... all with cracks and vulnerabilities that attackers can wiggle around ... a better approach would be KISS solution that had integrated approach to existing systemic vulnerabilities. For instance, some sort of clear, un-obfuscated indications integrated with URL selection that can leverage the existing SSL MITM-attack countermeasures.
The downside of a KISS integrated solution that eliminates existing systemic problems (and avoids creating complex layers, each with their individual cracks that the attackers can wiggle thru) ... is that the only current special interest for such a solution seems to be the victims. Some sort of fix that allows naive users to relate and enter specific trusted URLs associated with specific tasks could fix many of the existing infrastructure vulnerabilities. The issue is what institutions have financial interest in designing, implementing, and marketing such a likely "free" add-on to existing mostly "free" based infrastructure. It appears to be much easier justify the design, implementation and marketing of a totally new feature that can be separately charge for.
some some topic drift ... one person's history of priced software:

@_date: 2005-06-02 12:23:13
@_author: Anne & Lynn Wheeler 
@_subject: "SSL stops credit card sniffing" is a correlation/causality myth 
we got brought in to work on some word smithing for both the cal. state and the fed. digital signature legislation (we somewhat concentrated on the distinction between digital signature authentication and that human signature implies read, understands, agrees, approves, authorizes, etc .... which isn't present in simple authentication).
one of the industry groups that was active in the effort had done some extensive surveys on driving factors behind various kinds of regulatory and legislative actions. with regard to privacy regulatory/legislative actions ... the two main driving factors were 1) identity theft and 2) effectively institutional (gov, commercial, etc) denial of service.

@_date: 2005-06-03 07:40:14
@_author: Anne & Lynn Wheeler 
@_subject: [Clips] Paying Extra for Faster Airport Security 
there were several news URLs a month or so ago about the issue of "faster" in conjunction with the orlanda effort and some of the predictions on possibly 40mil (most frequently travelling) people sign up if such programs were rolled out around the country.
the issue raised was that they were effectively paying to have a priority queue for the existing screening stations (effectively could take the place of the first class queue at some airports) ... and what is the characteristic of a priority queue if nearly everybody is standing in the priority queue rather than the regular queue.
having done some work on queuing ... i turned out the mainframe resource manager in the 70s
if the service stations are the same ... and you just are re-arranging the order of service ... priority queues have the appearance of meeting their objectives when only a small percentage of the total population is in the priority queue.

@_date: 2005-06-03 07:51:02
@_author: Anne & Lynn Wheeler 
@_subject: Digital signatures have a big problem with meaning 
this was one of the big issues in the asn.1 encoding vis-a-vis xml encoding wars.
asn.1 encoding provided deterministic encoding for signed material, although some of the more common applications of digital signature have what is transmitted is the original encoded material along with the signature of that encoded material.
fstc/e-check project wanted to digital sign stuff that was xml encoded ... but not transmit the xml encoded fields. they wanted to take standard financial transaction fields ... momentarily xml encode the standard fields, digitally sign the encoded material ... and then append the resulting digital signature to the (original) standard transaction for transmission.
the problem was that xml didn't have a deterministic definition for encoding fields. when the recipient/relying party received the transmission ... they had to take the standard transaction fields and re-encode in xml in order to verifiy the digital signature. fstc/e-check came up with fsml for deterministic encoding of fields ... so that the encoding done by the originator (of the digital signature) and the encoding done by the relying party (for verifying the digital signature) would have identical bit patterns.
fsml was subsequently contributed to the xml digital signature project.
xml is descendent of gml invented by "G", "M", and "L" in 1969 at the science center
and then standardized at ISO in the 70s

@_date: 2005-06-04 08:10:10
@_author: Anne & Lynn Wheeler 
@_subject: [Clips] Paying Extra for Faster Airport Security 
one of the articles from a couple months ago about what happens if too many people shift into a priority queue. note that it is somewhat cheaper to let a few people to pay to go to the head of the screening line ... so that their queueing wait is reduced. It is a lot more expensive to install significantly more screening stations if you are planning on moving a large precentage of the people to the priority queue.
Frequent fliers' priority perks may lose value
an article about making the screening process (itself) significantly, rather than just re-arraigning the order that people go thru the screening process.
Design Build Contractor Emmanuel Cabrera Unveils Model for a New Airport Security and Screening Facility
some older stories about going to the head of the screening line
Orlando airport will allow frequent fliers to bypass screening
OIA, TSA to launch first 'Private Sector Known Traveler Program'
lots of recent stories about going to the head of the screening line.
Voluntary Security ID to Debut in Florida
Voluntary Security ID to Debut in Florida
Voluntary Security ID to Debut in Florida
Voluntary security ID to debut in Florida
Voluntary security ID to debut in Florida
Orlando airport first tester of quick-pass voluntary biometric ID
Orlando airport to allow use of $80 security ID
Voluntary Security ID to Debut in Florida
Firm's system lets frequent fliers speed through airport's security
Passes put fliers in the fast lane
Skipping security checks
Bio ID may make airport security easy
Transport Deptt. Wants the Airline Passenger Information
Airport fast lanes to get test

@_date: 2005-06-06 11:41:28
@_author: Anne & Lynn Wheeler 
@_subject: Using Corporate Logos to Beat ID Theft 
former chair of x9a10 working group did quite a bit of work on this approach ... although it was more oriented towards being able to validate websites as opposed to email ... and none of it shows up in the x9.59 standard
for some topic drift ... recently i had opportunity to repeat the story about ISO/OSI directive prohibiting work on standards that violated OSI and happen to remember during the 90s work on x9.59, somebody trying to claim that (some?) ISO organization couldn't do work on standards involving digital signatures unless they were certificate-based infrastructures; collection of certificate-less based postings
Using Corporate Logos to Beat ID Theft
The Mountain View, Calif., company's technology uses corporate logos to distinguish legitimate e-mail messages from those that fake, or spoof, their origin. Iconix is preparing to announce its first product next quarter, said company officials.
... snip ...

@_date: 2005-06-06 15:48:14
@_author: Anne & Lynn Wheeler 
@_subject: Digital signatures have a big problem with meaning 
there was another issue with digital signatures supposedly acquiring attributes of human signatures .... aka implication that human had actually read, understood, approves, agrees, and/or authorizes the content ... as well as intent.
so at least some financial institutions in the mid-90s were realizing that x.509 identity certificate ... potentially overloaded with enormous amounts of personal information, represented significant liability and privacy concerns ... were looked at switching to relying party only certificates ... basically containing some sort of database record locator (where all the real information was located) and a public key. however, it was trivial to demonstrate that such certificates were redundant and superfluous.
there was another issue involving the typical 4k-12k byte size of such certificates ... when appended to a typical payment transaction of 60-80 bytes ... besides being redundant and superfluous ... also would represent horrendous payload bloat.
now the certificate crazed periods of the 90s also had something called the certificate non-repudiation bit ... which large segments of the market was interpreting as meaning that digital signatures with appended certificates containing the non-repudiation bit ... couldn't be repudiated by the person making the digital signature.
in the retail payments scenario ... the task was to convince consumers to pay $100/annum for redundant and superfluous, payload bloating relying party only certificates with the non-repudiation bit set. supposedly the scenario being sold retail merchant industry was that while the current retail payment environment had the burden of proof (in any consumer dispute) placed on the merchant ... if the consumer would be so kind to append an redundant and superfluous, enormous payload bloating certificate with the non-repudiation bit set ... the burden of proof in a dispute would be shifted from the merchant to the consumer.
there was some hypothetical investigation that even if the consumer did digitally sign a retail payment transaction and appended a redundant and supefluous, payload bloating relying party only certificate ... w/o the non-repudiation bit set .... that merchants could possibly substitute a similar certificate which did have the non-repudiation bit turned on ... possibly harvested from some convenient, cooperating LDAP trusted certificate repository.
besides all the other practical and legal issues about digital signatures being interpreted as simply "something you have" authentication ... from 3-factor authentication model
* something you have
* something you know
* something you are
and NOT as human signature implying intent, read, understood, agree, approve, and/or authorize ....
... there was the issue that the "non-repudiation" bit within a certificate was supposedly creating liability on behalf of the digital signer ... however the PKI protocols contained no provision for proving what specific certificate the person applying a digital signature had actually appended to any specific transaction ... aka the digital signature was only on the transaction itself ... and there was no digital signature armoring/binding which digital certificate might actually have been originally appended to any specific digitally signed transaction (possibly allowing merchants to substitute non-repudiation certificates when none had been intended).

@_date: 2005-06-07 19:59:44
@_author: Anne & Lynn Wheeler 
@_subject: encrypted tapes (was Re: Papers about "Algorithm hiding" ?) 
a couple past posts (from jan. 1999) on the thread between information security and risk management (in financial institutions, with stuff about encryption, effects of exploits on corporate valuation ... even includes some discussion of citi)

@_date: 2005-06-13 13:21:55
@_author: Anne & Lynn Wheeler 
@_subject: de-identification 
from privacy glossary and taxonomy
that i put together when working on x9.99 PIA standard for financial
industry ... from HIPAA
    Previously identifiable data that have been deidentified and for
which a code or other link no longer exists. An investigator would not
be able to link anonymized information back to a specific individual.
[HIPAA] (see also anonymous, coded, directly identifiable, indirectly

@_date: 2005-06-13 18:16:47
@_author: Anne & Lynn Wheeler 
@_subject: expanding a password into many keys 
there is financial standard for derived key per transaction
from x9f taxonomy and glossary
derived unique key per transaction (DUKPT)
    A key management method which uses a unique key for each
transaction, and prevents the disclosure of any past key used by the
transaction originating TRSM. The unique Transaction Keys are derived
from a base derivation key using only non-secret data transmitted as
part of each transaction. [X924] (see also cryptographic key, transaction)
basically you may be able to brute force an individual key w/o
comprimising the "master key" (or any other keys derived from the master
derived keys are used in other infrastructures beside financial
transactions. some token based systems may simply use derived key per
token (as opposed to per transaction) ... brute force of a particular
token's key doesn't compromise either the overall infrastructure and/or
other tokens in the infrastructure.

@_date: 2005-06-14 10:59:26
@_author: Anne & Lynn Wheeler 
@_subject: expanding a password into many keys 
as previously noted ... financial industry has had a standard for
derived key for some time.
a variation on this is the interative hash for one-time password (except
the keyname became the server specific "salt" and there was added value
for the number of hash iterations) ... the claim was that it was
targeted for an end-user could walk up to an open environment w/o
anything other than their passphrase ... and be able to logon. various
MITM attacks against the server were examined ... however there wasn't
equal examination of MITM attacks against the end-user (i.e. providing a
count of one to the end-user ... so that attacker then can reproduce
all subsequent hash iteration values) ... misc. past postings
 public key vs passwd
 public key vs passwd
 public key vs passwd
 XOR passphrase with a constant

@_date: 2005-06-20 20:26:25
@_author: Anne & Lynn Wheeler 
@_subject: massive data theft at MasterCard processor 
reference to posting in a usenet n.g. in a thread that talked about
putting encryption everywhere as a solution
 Encryption Everywhere?
 Encryption Everywhere?
as referenced in the above ... x9.59
has countermeasure against the harvesting vulnerability (w/o
requiring any encryption) which is so attractive to attackers because
the return is so enormous for the amount of effort
it is a countermeasure to fraudulent terminals. there was some effort in
x9a10 working group (which was tasked with preserving the integrity of
the financial infrastructure for *ALL* retail payments, regardless of
kind, debit, credit, stored-value, etc ... and/or environment) with
regard to trusted terminal modules .... somewhat akin to EU finread
standard and existing POS security modules ... but with the addition
that the terminal also digitally signed the same transaction. the
consumer would digitally signed for authentication ... and the trusted
terminal would also digitally co-sign authenticating the terminal used.
the issue is there is still some vulnerability involving terminal
overlays (analogous to what has been read about regarding ATM cash
machine overlays ... although not for harvesting ... since x9.59 closed
that hole ... but for transaction misrepresntation ... the payback isn't
nearly as attractive as compared to harvesting tho).
so one of the AADS chip strawman suggestions for x9.59 from the 90s
was the same protocol and transaction whether it was with the merchant
terminals ... or with a consumer owned pda/cellphone device (any kind of
wireless to the merchant device) ... where a paranoid consumer would
always maintain physical control of their private display and keypad.

@_date: 2005-06-21 06:27:59
@_author: Anne & Lynn Wheeler 
@_subject: massive data theft at MasterCard processor 
the payment infrastructure requires a financial institution taking
responsibility for a merchant to connect into the network ... and the
settlement into the merchant account nominally flows thru the sponsoring
merchant financial institution. for a merchant not to actually exist
would require some lapse on the sponsoring financial institution ...
i.e. some of the anonomous stored-value specifications tried to simulate
direct cash-like transfer between two tokens .... but the existing
payment networks are far from that, requiring a bit more deception
on the part of any fraudulent merchant.
note that some of the transaction authentication specifications don't
necessarily match x9.59 financial standard in also specifying that a PAN
in an authenticated transaction can't be used in a non-authenticated
transaction. recent post reference
i.e. which still leaves open the various harvesting vulnerabilities. the
x9.59 financial standard specified that both
1) transactions have to be individually authenticated (account-level
authentication with the issuing institution) and
2) the same PAN used in authenticated transactions can't be used in
non-authenticated transactions (countermeasure to harvesting
vulnerability where crook could utilize information for later fraudulent
misc. x9.59

@_date: 2005-06-21 09:03:14
@_author: Anne & Lynn Wheeler 
@_subject: massive data theft at MasterCard processor 
note that while x9.59 allows for digital signature (as method of
strong-authentication) ... and even co-signing by both the consumer and
the terminal ... it doesn't mandate certificate-based operation and
allows for certificate-less digital signature authentication.
we had worked on the original payment gateway for what was becoming
before starting in the x9a10 financial standards working group on x9.59
in that time frame there were some number of specifications for
financial transactions that involved digital signatures and mandated a
fairly large collection of digital certificates and pki.
the financial industry in the mid-90s was one of the industries that was
starting to realize that the x.509 certificates, somewhat from the early
90s, representing significant privacy and liability issues ...
especially when grossly overloaded with personal information.
they had retrenched to relying-party-only certificates
which effectively bound a public key to an account number or some other
form of database lookup value (where the real and relavant information
was actually stored). note that it was relatively trivial to show that
such digital certificates were redundant and superfluous (repeatedly
sending back database lookup value to the institution that had issued
the certificate and had direct access to all the real information).
the other issue we saw with some of the financial transactions mandating
digital certificates (especially redundant and superfluous
relying-party-only certificates) was the enormous payload bloat in
typical payment network transaction. A typical payment network
transaction has been on the order of 60-80 bytes ... the typical
relying-party-only digital certificate for these programs ran 4k to 12k
bytes ... which represented an enormous payload bloat of a factor of one
hundred times.
Some of the programs realizing that it really wasn't practical to
transmit such a redundant and superfluous digital certificate over the
typical payment network ... were having an internet boundary gateway
validate any digital signature (with the public key in the digital
certificate) ... and then transmitting a normal payment network
transaction with simply a bit turned on indicating if the digital
signature had verified.
Besides violating kindergarten security 101 regarding end-to-end
security (or because of it) ... there was an ISO standards meeting where
a business person from one of the payment networks gave statistics on
there being quite a few payment transactions flowing thru the network
with the digital signature verified flag turned on ... and they could
prove that there hadn't been any digital signature technology involved
(one possibly motivation given was that they were talking about lowering
the discount rate for digital signature verified transactions based on
presumption of lower fraud rate). The scenario is that the consumer's
issuing bank is the financial responsible party ... and fundamental
end-to-end security principles would dictate that the responsible party
for authorizing the transaction should also be the responsible party for
authenticating the transaction (rather than possible organizations that
might have interests quite different from that of the consumer's issuing
financial institution).
A side issue with some of the payment digital signature specifications
from the period was that they provided no countermeasure for the growing
harvesting/skimming problem ... aka the sam PAN in a digital signed
transaction could be harvested and used in a non-authenticated transaction

@_date: 2005-06-21 14:07:38
@_author: Anne & Lynn Wheeler 
@_subject: crypto rfcs 4055, 4056, 4101 announce today 
4055 Additional Algorithms and Identifiers for RSA Cryptography for use
in the Internet X.509 Public Key Infrastructure Certificate and
Certificate Revocation List (CRL) Profile. J. Schaad, B. Kaliski, R.
Housley. June 2005. (Format: TXT=57479 bytes) (Updates RFC3279) (Status:
PROPOSED STANDARD)
4056 Use of the RSASSA-PSS Signature Algorithm in Cryptographic Message
Syntax (CMS). J. Schaad. June 2005. (Format: TXT=11514 bytes) (Status:
PROPOSED STANDARD)
4107 Guidelines for Cryptographic Key Management. S. Bellovin, R.
Housley. June 2005. (Format: TXT=14752 bytes) (Also BCP0107) (Status:
BEST CURRENT PRACTICE)

@_date: 2005-06-22 08:39:02
@_author: Anne & Lynn Wheeler 
@_subject: massive data theft at MasterCard processor 
note that "dual-use" attack is another variation on "what you see is not
necessarily what you get".
the dual-use attack ... is possibly a person-centric digitally signing
token (in contrast to institutional-centric token where each institution
might issue a unique token for every use) ... that can be registered for
use in multiple places and applications.
one of the digial signing scenarios is pure authentication where the
server sends out some random data which the end-user signs (effectively
a variation on challenge/response as countermeasure against replay attacks).
the issue in the "dual-use" attack ... is can somebody substitute a
perfectly valid financial transaction in lieu of random challenge data?
this attack is similar but different to point-of-sale attack where the
terminal displays a transaction different than what is provided for
signing ("what you sign is not necessarily what you think you are signing").
"dual-use attack" is against a possibly person-centric digital signing
where the same token/key is used for both authentication events as well
as "signature" type events .... where the signature implies read,
understood, approve, authorize, and/or agree.
misc. past refs:
 dual-use digital signature
 dual-use digital signature
 dual-use digital signature
 dual-use digital signature
 dual-use digital signature
 two-factor authentication
 New Method for Authenticated
Public Key Exchange without Digital Certificates
 New Method for Authenticated
Public Key Exchange without Digital Certificates
 Using smart cards for signing
and authorization in applets
 [Lit.] Buffer overruns
 Public/Private key pair
protection on Windows
 Maximum RAM and ROM for smartcards

@_date: 2005-06-24 06:52:42
@_author: Anne & Lynn Wheeler 
@_subject: massive data theft at MasterCard processor 
so the random data is sent encrypted with the person's public key ...
they can decrypt it with their private key. so the random data could
contain someting like a session key. they send back the random data
encrypted with the random session key. this demonstrates possesion of
the private (aka "something you have" authentication). this avoids
having to perform digital signatures on perported random data for pure
authentication operations (never digital sign random data ... only
digital sign what, you, yourself have personally created).
For pure authentication operations ... this model eliminates the whole
digtital certificate paradigm ... since the model assumes that the
originator of the authentication request already has the recipients
public key recorded someplace.
this has also been the suggestion for optimized SSL modification to use
public keys registered with the domain name infrastructure. public key
and SSL options are registered with the domain name infrastructure. An
optimized DNS call returns the ip-address and any public key and SSL
options as optional piggyback on the same transaction. the client
generates the random session key ... and on the initial packet,
transmits the random session key encoded with the server's registered
public key ... along with the initial packet of data encrypted with the
generated random session key. the server returns the response encrypted
with the generated random session key. For real transaction oriented
operations, you could even do this with UDP and a single send followed
by single response (plus the DNS send/reponse).
the SSL domain name certificate infrastructure was targeted as
countermeasure for perceived integrity issues with the domain name
infrastructure. somebody would apply to CA for SSL domain name
infrastructure, they would check with the domain name infrastructure if
the applicant was the valid owner of the domain name ... and then issue
the SSL domain name infrastructure. the problem of course, is that the
domain name infrastructure then is still the trust root as to who gets
issued SSL domain name infrastructure ... the very same domain name
infrastructure that was perceived to have integrity problems generating
the requirement for SSL domain name infrastructure.
So somewhat from the CA industry to help close various vulnerabilities
in the domain name infrastructure, there has been suggestion that domain
name owners register their public key. this helps with using the domain
name infrastructure as the "trust root" for the CA industry related to
domain name ownership and valid applicants for SSL domain name
infrastructure. this also helps the CA industry, where they can change
an expensive, time-consuming and error prone identification matching
operation (checking the applicant's identification against the
identification on file for the domain name owner with the domain name
infrastructure) to a much simpler and reliably authentication operation
(have the applicant digitally sign the SSL domain name application,
retrieve the on-file public key and validate the digital signature).
this, then creates the catch-22 for the CA industry for SSL domain name
certificates (aka if the CA industry can use certificateless, onfile
public keys for their purposes ... why can't the rest of the world).

@_date: 2005-06-24 07:34:29
@_author: Anne & Lynn Wheeler 
@_subject: massive data theft at MasterCard processor 
so the simplified SSL using the domain name on-file public key ... still
has possible replay attack potential against the server (the attacker
doesn't necessarily know what the replay is doing ... but getting the
server do it multiple times might result in something bad).
so in another kind of authenticated connection scenario ... say Kerberos
or RADIUS ... the client has registered their public key in lieu of some
sort of password (for certificateless operation)
they contact the server asserting some userid. the server generates a
random key, encrypts a time-stamp plus asserted userid plus more random
data, encrypts the random key with the public key on file for that
userid and responds. the user decrypts the random key with their private
key, and decrypts the response. at this point their is a choice of
possibly having encrypted sessions (with possibly perceived overhead
issues) ... or having the client permute the unencrypted data in some
way, re-encrypt just the permuted data and return it with unencrypted
data. the re-encrypted data demonstrates "something you have"
authentication (i.e. the client has possession and use of the
appropriate private key).
there are MITM vulnerabilities for the client ... since the server
hasn't been authentication.
to eliminate the MITM attacks against the client and replay attacks
against the server ... they would have to authenticate each other ....
w/o resorting to digital signatures (and opening themselves up to
dual-use attack) ... each sending some random data encrypted with the
other's public key .. which then can be decrypted with the appropriate
private key.

@_date: 2005-06-24 14:01:47
@_author: Anne & Lynn Wheeler 
@_subject: massive data theft at MasterCard processor 
absolutely ... see comment at end of early post in this thread about
paranoid consumers ...
as part of the charge to x9a10 financial standards working group to
preserve the integrity of the financial infrastructure for all retail
payments (aka debit, credit, ach, stored-value, etc as well as internet,
pos, face-to-face, moto, etc) ... there were some other provisions in
x9.59 payment standard
for use with private PC-based internet transactions and/or enhanced
personal point-of-sale device (cellphone, pda, etc). there is a data
field defined in the x9.59 that was specifically put in place for use as
personal transaction number (or a virtual check number if you are so
it was specifically designed for supporting electronic reconciliation
between transactions and various possible electronic statements.
in the mapping from x9.59 to iso 8583 payment transaction description
it is referred to as a LUID (costomer/locally unique number) ...
although there is not actual requirement for it to be unique and/or even
anything other than NULL. the standard suggests that if the LUID field
is present as part of an x9.59 transaction, that the institution should
include it any statements provided the customer (analogous to the way
that check numbers are provided on statements).
X9.59 also provides for an optional field for hash of order detail.
basically what the user signs, can include the hash of the
invoice/order. the merchant then is to validate that any (non-null)
invoice/order hash included in the signed x9.59 message corresponds to
hash of their invoice/order ... if the two hashes don't match ... don't
submit the transaction for payment. If the merchant disputes the
invoice/order later ... and the user happens to have included the hash
of invoice/order in the payment transaction ... then the disputed
invoice/order submitted by the merchant better have a hash that matches
what is in the signed payment transaction. this avoids requiring that
the invoice/order has to be part of the payment transaction ... but
leaves around some amount of detail that can be used as supporting
evidence in the event of any dispuate.
there is a EU FINREAD standard for a personal financial termainal that
talks about countermeasures for things like keylogging and making sure
the value of the transaction is correctly displayed
from the x9.59 perspective, there was a lot of work on allowing that
such a terminal could co-sign the transaction ... providing the
financial institution some risk indication about the person
authenticating the transaction as well as risk indication about the
environment in which the transaction occured (aka EU FINREAD specified
requirements for the personal financial termainal ... but didn't
actually require proof that such a terminal was actually used).
some of the characteristics of the EU FINREAD terminal are similar to
the security module requirements for POS terminals. The issue is that
both the users as well as the financial institutions may have no
indication that a POS terminal with specific integrity level was in use
for any specific transaction (making it difficult to fully do
parameterized risk management ... i.e. calculate all the possible fraud
and risk factors on a transaction by transaction basis).
the identified issue leading up to the privatly owned display and keypad
at POS ... is that even if there was a tamper resitent security module
in a tamper resistent post-of-sale terminal ... that also co-signed the
transaction ... there is still POS vulerability with things like
overlays (i.e. a compromised MITM display/keypad sitting between the
user and the real POS secure terminal).

@_date: 2005-03-05 09:23:11
@_author: Anne & Lynn Wheeler 
@_subject: MD5 collision in X509 certificates 
the purpose of a certificate is analogous to the old letters of credit in the sailing ship days .... it supposedly establishes the bonifides of the individual in an offline, non-connected world where the relying party has no other recourse regarding trust/integrity of the individual that they are dealing with.
in the PKI/certificate world ... the relying party receives some sort of digitally encrypted/signed information and validates it using the public key presented in the attached certificate. a correctly validation then implies some kind of 3-factor authentication (although the PKI/certificate paradigm tends to totally gloss over this characteristic, instead attempting to focus the communities attention on the value of the certification as opposed to focusing the attention on any possibility/value/trust that some part of 3-factor authentication might have occured).
In any case, if the public key (from some source, possibly a certificate) is able to validate the transmission, then the relying party assumes that some portion of 3-factor authentication occured in the access and use of the corresponding private key ... possibly
* something you have (private key exclusively in a hardware token)
* something you know (hardware token won't work appropriately w/o PIN)
* something you are (hardware token requires some biometric)
in any case, given that the relying party accepts the validation by the public key as representing some implied 3-factor authentication involved in access and use of the corresponding private key ... then the relying party may be faced with just who the implied authentication corresponds to. In the typical, long time accepted business process ... the relying party will have prior relationship with the entity being authenticated and it will be explicit and/or implicit in the communication itself. In the more modern world, in the situations where the relying party has no prior relationship with the authenticated entity ... they will have access to online and/or real-time information to establish that fact.
However, certificates were targeted at the offline email world ... where the email was created, digitally signed (presumably after some form of 3-factor authentication occuring to establish access/use of the private key), and the email, digital signature, and certificate packaged up and sent off to some party that there had been no previous communciation (might be considered spam in this day and age). After some number of intermediary store-and-forwards stops, the package arrives at the post office of the relying party. the relying party eventually calls their post office, exchanges emails and hangs up.
At this point the relying party is presented with a digital signed message with whom that they had no prior communciation. The attached certificate provides the public key for validating the digital signature and the rest of the certificate contents is supposedly to attest to some characteristic of the email sending party (that the relying party has no other way of validating).
The implication is that if i can substitute a public key in some certificate that attests to represent some other party .... then it may be some form of identity theft (fraudulent messages can be created that otherwise appear to have originated from you ... and validate with the substituted public key). The other might be elevation of privileges .... adding characteristics to a certificate that were otherwise not provided.

@_date: 2005-03-05 11:13:40
@_author: Anne & Lynn Wheeler 
@_subject: MD5 collision in X509 certificates 
so three kinds of attacks on certificate contents ... the previously two * identity theft
* privilege escalation
the other is possibly by the relying party against the key owner.
in the early '90s identity certificates were all the rage. some problems were at the time the certification took place ... it might not be possible for the certification authority to determine all possible kinds of identity information that a relying party (at any point in the future) might require ... so there was a trend to overloading an identity certificate with all possible types of identity information on the off chance that something might be useful to some relying party in the future. this led to increasing realization that such collection of identity information might represent various kinds of privacy violation and you saw some retrenching to relying-party-only certificates in the mid-90s ... misc. relying-party-only certificates only containing an account number to be used in online/real-time transaction (note however, in online/real-time relying-party-only scenario it is also trivial to show that certificates are redundant and superfluous)
the other thing in the 90s was trying to project a value proposition for certificates. there was a lot of FUD and confusion generated about the value of certificates to the point that it was frequently obscured that it was even necessary to have security and safety around the protection and use of the private key ... and/or that any form of 3-factor authentication was even involved in the access and use of the private key. To this day, you have people writing about using a digital certificate to create a digital signature.
So another value representation for digital certificates was that of non-repudiation. basically if the non-repudiation flag in a digital certificate was checked/marked ... then the relying party could assume non-repudiation on the part of the originating party. Again this is a scenario trying to represent the value of a digital certificate in place of the safety and security around the access and use of the private key.
So the story given to merchants in the merchant/consumer market place .... was that the existed circumstances were that in any dispute the burden of proof is on the merchant .... but the proposal was that if a merchant could produce any certificate (for the originator's public key) that had the non-repudiation flag marked/checked, then the burden of proof (in a dispute) whould shift from the merchant to the consumer.
So if that effort had been succesful ... then it would be in the interest of merchants to be able to produce a consumer digital certificate that included the non-repudiation flag (regardless of whether that certificate had been used in the original transaction or not .... since by definition all burden of proof then is shifted to the some of this is discussed in various postings regarding finread ... where the EU attempted to dictate some minimum hardware environment that   would provide some level of assurance around the access and use of the private key (which helps diffuse the confusion around whether the digital signature value proposition relies solely in the existance of a digital certificate .... or whether there is some value in controlling the access and use of private keys .... and it possibly isn't the case that digital signatures are generated by digital certificates):
other past postings on 3-factor authentication

@_date: 2005-03-06 15:29:09
@_author: Anne & Lynn Wheeler 
@_subject: SSL Cert prices ($10 to $1500, you choose!) 
and with a little bit of intelligent compression, zero bytes!

@_date: 2005-03-07 15:36:23
@_author: Anne & Lynn Wheeler 
@_subject: two-factor authentication problems 
in general, non-repudiation is a legal term and is associated with a legal signature ... which implies a person has read, understands, agreed, approves, and/or authorizes what is being signed.
a digital signature is somewhat of a semantic misnomer since by itself, it carries none of the characteristics commonly associated with a legal a digital signature, by itself, implies that some entity has accessed and used a specific private key. there is nothing in the standard, basic PKI infrastructure that either
1) implies that anything associated with any form of 3-factor authentication was necessary in the access and use of a private key (in the generation of a digital signature)
2) that there was any demonstration that there was any reading, understanding, agreement, approval, and/or authorization associated with the access and/or use of a private key (in the generation of a digital part of this i pointed out in a number of postings on dual-use digital signature attack ... where the scenario is that digital signature is being used to imply simple authentication aka possibly some flavor of a
challenge was transmitted, the receiving entity then used a private key to digitally sign the challenge and return the digital signature (there is a extremely vague implicit assumption that any component of 3factor authentication was used in access and use of the private key ... with the existance of a digital signature hopefully implying that some component of 3factor authentication actually occured in the access and use of the private key).
issues are
a) frequently challenge type protocols don't bother to present (the possibly totally random) bits (being signed) to the entity (that is assumed to be associated with the digital signature).
b) frequently infrastructures that attempt to equate legal signature and   digital signature ... will accept the existance of a digital signature applied to some number of bits as representing that the associated entity actually read, understood, approved, agrees, and/or authorizes the semantic meaning associated with the bits that were signed ... w/o requiring either 1) some demonstration/proof that 3factor authentication was used in the access and use of the private key for the digital signature and/or 2) that the meaning of what was digital signed had actually been read, understood, approved, agreed and/or authorized
in the dual-use attack, bits that might have semantic meaning are presented as random and/or meaningless as part of an authentication challenge/response protoocol. The attacker then takes and represents that the challenge bits that were signed ... were actually signed in the sense of a legal signature.
as a totally extraneous observation ... the discussion up to this point has been totally agnostic with regard to whether an infrastructure attempting to show some relationship between a digital signature and a legal signature involves PKI in anyway what so ever and/or is totally certificateless with regard to establishing a relationship between an entity and what might be assumed from the existance of a digital signature.
past posts regarding 3-factor authentication
EU finread standard attempting to address some of the issues regarding providing some level of assurance about 1) any characteristic of 3factor authentication actually occuring when the private key was accessed and used for a digital signature and 2) the entity might have actually read and approves the transaction
past posts on dual-use vulnerability
 Using crypto against Phishing, Spoofing and Spamming
 dual-use digital signature  dual-use digital signature  dual-use digital signature  dual-use digital signature  dual-use digital signature  dual-use digital signature  dual-use digital signature  dual-use digital signature  dual-use digital signature  dual-use digital signature  should you trust CAs? (Re: dual-use digital signature vulnerability)
 EMV cards as identity cards
 Credit card leaks continue at a furious pace
 New Method for Authenticated Public Key Exchange without Digital Certificates
 New Method for Authenticated Public Key Exchange without Digital Certificates
 New Method for Authenticated Public Key Exchange without Digital Certificates
 REVIEW: "Biometrics for Network Security", Paul Reid
 Using smart cards for signing and authorization in applets
 [Lit.] Buffer overruns
 [Lit.] Buffer overruns
past posts on non-repudiation ... and possibly some characteristics that might be required to demonstrate a person has read, understood, approved, agrees, and/or authorized what was digitally signed:
 non-repudiation, was Re: crypto flaw in secure mail standards
 non-repudiation, was Re: crypto flaw in secure mail standards
 non-repudiation, was Re: crypto flaw in secure mail standards
 non-repudiation, was Re: crypto flaw in secure mail standards
 non-repudiation, was Re: crypto flaw in secure mail standards
 non-repudiation, was Re: crypto flaw in secure mail standards
 non-repudiation, was Re: crypto flaw in secure mail standards
 3D Secure Vulnerabilities? Photo ID's and Payment Infrastructure
 Invisible Ink, E-signatures slow to broadly catch on
 Invisible Ink, E-signatures slow to broadly catch on (addenda)
 FBI Probing Theft of 8 Million Credit Card Numbers
 Authentication white paper
 FINREAD ... and as an aside
 FINREAD was. Authentication white paper
 Confusing Authentication and  cardtech/securetech & CA PKI
 revised Shocking Truth about Digital Signatures
 revised Shocking Truth about Digital Signatures
 Online Certificate Revocation Protocol
 Simple PKI
 Sender and receiver  Sender and receiver  [FYI] Did Encryption Empower These Terrorists?
 [FYI] Did Encryption Empower These Terrorists?
 FW: The end of P-Cards?
 Erst-Freedom: Sic Semper Political Cryptography
 Rubber hose attack
 Software for PKI
 Software for PKI
 Software for PKI
 Shades of FV's Nathaniel Borenstein: Carnivore's "Magic Lantern"
 A PKI Question: PKCS11->  CFP: PKI research workshop
 CFP: PKI research workshop
 CFP: PKI research workshop
 PAIIN security glossary &  Limitations of limitations on RE/tampering (was: Re: biometrics)
 biometrics (addenda)
 biometrics
 Welome to the Internet, here's your private key
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 Words, Books, and Key Usage
 Meaning of Non-repudiation
 Meaning of Non-repudiation
 NEWS: 3D-Secure and Passport
 TOC for world bank e-security  Interests of online banks and their users [was Re: Cryptogram:  Palladium Only for DRM]
 Employee Certificates - Security Issues
 Legal entities who sign
 Legal entities who sign
 TTPs & AADS Was: First Data Unit Says It's Untangling Authentication
 e-Government uses  Invisible Ink, E-signatures slow to broadly catch on (addenda)
 surrogate/agent addenda (long)
 Payments as an answer to spam  Maybe It's Snake Oil All the Way Down
 An attack on paypal
 UK: PKI "not working"
 basic question: semantics of "map", "tie", etc in PKI
 VS: On-line signature standards
 VS: On-line signature standards
 VS: On-line signature standards (slight addenda)
 VS: On-line signature standards
 VS: On-line signature standards
 VS: On-line signature standards
 FAQ: e-Signatures and Payments
 example: secure computing kernel needed
 Difference between TCPA-Hardware and a smart card (was: example: secure computing kernel  The PAIN mnemonic
 Non-repudiation (was RE: The PAIN mnemonic)
 Non-repudiation (was RE: The PAIN mnemonic)
 Non-repudiation (was RE: The PAIN mnemonic)
 Non-repudiation (was RE: The PAIN mnemonic)
 Non-repudiation (was RE: The PAIN mnemonic)
 Non-repudiation (was RE: The PAIN mnemonic)
 Definitions of "Security"?
 Using crypto against Phishing, Spoofing and Spamming
 Using crypto against Phishing, Spoofing and Spamming
 dual-use digital signature  dual-use digital signature  dual-use digital signature  dual-use digital signature  dual-use digital signature  dual-use digital signature  dual-use digital signature  MD5 collision in X509  X9.59/AADS announcement at BAI this week
 RealNames hacked. Firewall issues.
 PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  PKI and Non-repudiation  solicit advice on purchase of digital certificate
 Block oriented I/O over IP
 Remove the name from credit cards!
 distributed authentication
 FREE X.509 Certificates
 distributed authentication
 PKI/Digital signature doesn't work
 PKI/Digital signature doesn't work
 PKI/Digital signature doesn't work
 Net banking, is it safe???
 Net banking, is it safe???
 E-commerce security????
 OT - Internet Explorer V6.0
 Are client certificates really  Are client certificates really  Are client certificates really  A thought on passwords
 Internet like city w/o traffic rules, traffic signs, traffic lights and traffic enforcement
 FA: Early IBM Software and Reference Manuals
 Q: Buffer overflow
 Opinion on smartcard security  Opinion on smartcard security  Beginning of the end for SNA?
 Mainframers: Take back the light (spotlight, that is)
 Why?
 Opinion  on smartcard security  Crazy idea: has it been done?
 Crypting with Fingerprints ?
 O'Reilly C Book
 Least folklorish period in computing (was Re: IBM Mainframe at home)
 Computers in Science Fiction
 Security and e-commerce
 Biometric Encryption: the solution for network intruders?
 Security Issues of using Internet Banking
 Digital signature
 Biometric authentication for intranet websites?
 Are you really who you say you  Does Diffie-Hellman  schema belong to Public Key schema family?
 Does Diffie-Hellman  schema belong to Public Key schema family?
 Definition of Non-Repudiation ?
 Beginner question on Security
 MVS 3.8J and NJE via CTC
 What good is RSA when using passwords ?
 Two questions on HMACs and hashing
 A new e-commerce security proposal
 A new e-commerce security proposal
 (OT) acceptance of technology, was: Convenient and secure
 Convenient and secure eCommerce using POWF
 Help! Good protocol for national ID card?
 Help! Good protocol for national ID card?
 Help! Good protocol for national ID card?
 Help! Good protocol for national ID card?
 Help! Good protocol for national ID card?
 smartcard+fingerprint
 Cost of computing in 1958?
 Public key and the authority  Public Encryption Key
 unix
 IBM says AMD dead in 5yrs ...

@_date: 2005-03-08 07:08:16
@_author: Anne & Lynn Wheeler 
@_subject: two-factor authentication problems 
note that there is typically some close relationship between a secureid and the relying party .... that if everything is working correctly ... the relying party is pretty sure that (most of the times) the response originated from a valid token .... although there are various kinds of attacks and vulnerabilities associated with originating that information and/or transmitting it to the relying party.
most PKIs tend to focus on the integrity of the indiciation arriving at the relying party. the digital signature is an indication that something occured at the remote end ... namely some entity accessed and used a private key. however, almost all PKI descriptions fail to focus on the primary event (that a digital signature is suppose to indicate) is that some form of 3factor authentication actually occured in the access and use of a private key. A lot of PKI has shifted the focus from the fundamental authentication business process (the integrity of the access and use of a private key) to the integrity of the communication that some (any arbitrary) access and use of a private key (while failing to establish the there was any fundamental integrity actually associated with the actual access and use of the private key).
aka ... digital signatures are a secondary factor associated with the primary integrity event of concern. the primary integrity business process is the actual access and use of the private key. a digital signature is a secondary integrity factor ... the indication or communication that some access and use of a private key has occured (w/o having any indication about the actual integrity of that access and use).
the actual access and use of the private key would be the primary integrity event of concern. the (high integrity) communication that such an access and use has concerned is secondary to the actual access and use (although both can be considered as attack targets or vulnerabilities).
note that integrity of the actual access and use of the private key, establishing some form of 3factor authentication
and the communication that some actual access and use of the private key has occured with a digital signature
is orthogonal whether the relying party is relying on a (offline, unconnected) PKI model or a certificate-less
The PKI model was original met to target the scenario where the relying party has had no prior relationship with the originating party and/or
has no access and/or recourse to any other source of information (especially online access) about the originating party.
However, PKI descriptions have frequently obfuscated that there is other business processes requiring integrity issues (aka anything other than those related to certificate generation and use).
The actual core process that everything depends on is the integrity surronding the access and use of the private key .... and all other processes are scaffolding intended to provide a remote relying party some indication that the access and use of a private key has occured.
PKI models frequently fail to even bother to describe that the primary integrity issue is the access and use of the private key (and everything else is secondary). PKI models also frequently fail to describe that they are intended for the offline, unconnected business environment ... which has become the small minority of actual business processes in the world today.

@_date: 2005-03-09 11:52:51
@_author: Anne & Lynn Wheeler 
@_subject: DC metro smartcard failure/exploit? 
anybody hear of a DC metro (smartrip) smartcard failure/exploit?
you have a smartcard that supposedly has $10-something left ... and the next time you go to the station ... the turnstyle says "not acceptable, see stationmaster". the stationmaster puts the card in a reader and the display comes up and says the card has negative $5 balance. in theory, the transactions with the smartcard are encrypted (and possibly the values stored in the chip are also encrypted). somehow the card has had a failure/exploit that made it look like the card has a negative $5 balance?

@_date: 2005-03-15 12:40:59
@_author: Anne & Lynn Wheeler 
@_subject: Do You Need a Digital ID? 
i've been asked to flush out my merged security taxonomy and glossary
to  highlight the distinction between identity theft and account theft.   typically identity theft is that enuf information is obtained to fraudulently be able to open new accounts in the victim's name (among other things) while account theft is that the thief has enuf information to perform fraudulent transactions against an existing account of the account theft tends to be attacks on poor authentication procedures by account institutions and/or use of social engineering or phishing to obtain the victim's account authentication information (which shares a lot in common with straight identity theft).
a common exploit is the use of skimming/sniffing of static authentication verification data that enables creating counterfeit tokens/cards that enables fraudulent transactions.
given 3-factor authentication:
* something you have
* something you know
* something you are
there can be a great deal of confusion whether a token/card represents "something you have" or not. If a token/card contains valid authentication information and if that token/card is lost/stolen and a new account has to be created .... then it is likely the token/card represents "something you have" authentication.
however, some infrastructure just utilize a token/card to provide the equilvalent of userid (say an account number which isn't required to be secret) and the actual authentication is in the form of a password/PIN ... i.e. "something you know" authentication. just because a token/card is involved along with a PIN/password doesn't automatically imply that two-factor authentication is involved.
if a re-issued a new token/card (to replace a lost/stolen token/card) is identical to the lost/stolen token/card ... then it is likely that there is no "something you have" authentication involved (even tho a token/card is involved in the process) ... and therefor the infrastructure is just single factor authentication.
at the basics, a digital signature is an indirect indication of "something you have" authentication .... aka the existance of a digital signature implies that the originator accessed and utilized a private key in the generation of the digital signature. a digital signature by itself says nothing about the integrity of that "something you have" authentication ... since the digital signature doesn't carry any indication of the integrity measures used to secure and access the associated private key.
there is some temptation to claim that the a lot of the problems with establishment of digital signature technology is that the basic trust building blocks haven't been established. numerous institutions have spent a lot of time focusing on the trust infrastructures associated with certification authority operation and digital certificates .... which have nothing directly to do with any form of 3 factor authentication.
the basic building block is that a financial (or other) institutions have ongoing relationships represented by established accounts and that the entities associated with those accounts have established authentication material. In the case of digital signatures, that would be public keys. To the degree that a relying party institution (financial or other) can trust what is represented by a digital signature is the integrity level of the environment that protects the access and use of the associated private key .... w/o additional knowledge, the relying party only knows that some entity accessed and utilized a specific private key ... as in a simple, single factor, "something you have" authentication.
A digital signature by itself has no indication of the security and integrity level associated with the private key protection, access and use ... and/or if there is anything more than simple, single factor, "something you have" authentication.
Furthermore, in the great majority of the transactions involving established relationships, there is no need for digital certificates to establish identication information .... straight-forward authentication tends to be sufficient.
misc. past 3-factor authentication posts

@_date: 2005-03-21 09:13:57
@_author: Anne & Lynn Wheeler 
@_subject: Do You Need a Digital ID? 
minor addenda ... ref:
 Do You Need a Digital ID?
 Do You Need a Digital ID?
there are 2nd order implementations of public/private key authentication business process where keeping the private key private might involve
* keeping the private key in an encrypted file and a pin/password is required to decrypt a file. this could be considered a possibly weak form of two-factor authentication: 1) possession of the encrypted file and 2) possession of the key to decrypt the file (it may in fact be considered so weak that many might considerd it only one-factor authentication, the knowledge of the key to decrypt the file).
* keeping the private key in a token ... where the characteristics of the private key and the token holding the private key are taken as equivalent. the simple token/private-key equivalence is then one-factor "something you have" authentication ... aka a) digital signature is an expression of access and use of the private key and b) access and use of the private key is an expression of the possession of the token.
* a private key token that requires PIN and/or biometrics to operate in specific manner ... a relying party with business process certification of the private key only existing in a specific token and that the specific token is also certified as to requiring specific PIN and/or biometrics then possibly the relying party can assume some form of two factor authentication (or even three factor authentication); the digital signature is an expression of the access and use of the private key, the access and use of the private is an expression of a combination of a) possession of a specific hardware token, b) corresponding PIN for that specific hardware token to operate in a specific manner and/or c) biometric for that specific hardware token to operate in a specific manner.
note in the old fashion identity digital certificates from the early 90s ... there was frequently little or no discussion as to the integrity requirements regarding the ability to access and use a specific private key (which is what the whole private/public key business process is fundamentally built on). there was frequently lots of documentation on what a certification authority might do in the integrity around the generation of an identity digital certificate .... but very little or nothing about what the key owner was required to do in order to enable the whole fundamental public/private key business process to operate

@_date: 2005-03-21 08:27:53
@_author: Anne & Lynn Wheeler 
@_subject: Do You Need a Digital ID? 
now, i've said that all of these comments are within the 3 factor authentication paradigm ... if you back up a couple paragraphs in the original postings ... you will find the comments:
 > given 3-factor authentication:
 >
 > * something you have
 > * something you know
 > * something you are
aka the comments/postings are within the framework/paradigm of 3-factor authentication. so is the issue with the 3-factor authentication framework ... or is the issue that the comments are inconsistent given a 3-factor authentication framework?
I assert (as stated in the original posting) that the comments/posting is within the context of 3-factor authentication framework and the definition of the public/private key business process. you are free to define something other than 3-factor authentication framework .... or a totally different business process for the treatment of asymmetric cryptography keys.
a digital signature is something that is supposedly hard to counterfeit .... and just represents the application of a private key to some data
(the digital signature is an indication/expression that a private key has been accessed and used). for most entities, a private key is not something that is memorized, but rather it is contained by something that the human has. the integrity of the process is based on the integrity of the infrastructure that controls the access and use of that private key ... therefor a digital signature infrastructure typically represents a "something you have" technology.
the whole asymmetric cryptography technology (of which a digital signature is just a part) has been taken and a business process wrapped afound it which is frequently referred to as public/private key cryptography (an abbreviation frequently to simple public key technology). the foundation of the public/private key (or public key technology for short) business process is based on keeping the "private key" actually "private". If everybody is allowed to have as free access to the "private keys" as there is access to the "public key" ... the whole infrastructure (including digital signatures) falls apart.
So if you are looking at a threat assessement ... the public/private key business process allows for both digital signatures and public keys to be readily known ... the whole foundation that holds the whole "public key" business process together is based on keeping the private key actually unknown and unaccessable to others than the authorized entities.
so i've haven't seen any private key deployments which are based on a human actually memorizing the private key ... so it can't be a (at least directly) a "something you know" operation. of the private key deployments i've seen, there has been the requirement that an entity possesses a "private key" and is able to access and make use of that "private key" ... since it isn't "something you know" (and since a "private key" is also not typically "something you are" biometrics) then that leaves a "private key" representing "something you have".
so if you look at typical "something you have" infrastructures, their integrity is based on the protection of the operations that access and utilize the "something you have".
as i pointed out in one of the earlier postings, much of the literature in the mid-90s grossly confused the the terms digital signature and digital certificates and private key ... to the point that it sometimes represented that a digital ceritifcate was responsible for generating a digital signature (or by implication the public key included in a digital certificate). Since the public/private key business process allows for both digital signatures and public keys to be readily known, it is fairly obvious that they can't be the integrity/security foundation for the business process.
so when a digital signature is validated with a public key ... what is it doing ... it is validating that the private key (of a public/private key pair from asymmetric cryptography) generated that digital signature.
"private key" isn't a characteristic of asymmetric cryptography ... it is a characteristic of public/private key business process requiring that the "private key" be kept private. a digital signature is just an expression of the business process use of that private key.
so from 3-factor authentication paradign there are three things:
* something you know authentication
* something you have authentication
* something you are authentciation
now, i know of no public/private key business process deployments that
require humans to memorize the private key ... that eliminates (at least
direct use of) "something you know" authentication.
the most common deployments of public/private key business process deployment aren't based on biometrics ... which then eliminates "something you are" authentication.
that just leaves "private keys" as a type of "something you have" technology ... (since it isn't memorized or biometrics). therefor the foundation of public/private key business process deployments (frequently abbreviated to simply public key ... with the existance of a corresponding pviate key assumed) is based on the possession of a private key and the business processes of keeping that private key actually private (and the business processes of uniquely being able to use the private key and not having it widely available to large numbers of unauthorized people).
now, usually once past the description of public key business processes for public consumption (where it might actually be stated that the digital signature was generated by the digital certificate) .... you
quickly get into the foundations which are based on
1) asymmetric key cryptography
2) business process of allowing one of the asymmetric key pair to be made public
3) business process of allowing one of the asymmetric key pair to be kept private
4) business process of consistently maintaining the privacy of the designated private key.
repeating 3-factor authentication paradign
* something you know authentication
* something you have authentication
* soemthing you are authentication
digital signature is an expression of the private key business process that consistently and reliably maintains the privacy of the private key.
private key isn't a technology (like asymmetric key cryptography is a technology). private key is a business process application to asymmetric key cryptography. the access and use of a private key is supposedly for the purpose of reliably authenticating the entity associated with that private key. so by process of elimination:
* how many public key deployments require the associated entity memorize the "private key"
* how many public key deployments require that the private key be an expression of some biometric for that entity
by process of elimination, if the "public key" deployments aren't typically "something you know" or "something you are" ... then that just leaves "public key" deployments to be "something you have" authentication.
now it is obvious that a specific physical object can be in unique possession of a specific entity (modulo physical object counterfeiting). however, the business process for public/private key defines that a private key is in the unique possesion of a specific entity. not by law of physics ... but by law of the business process. if you violate the law of the business process and allow multiple entities to possess the private key (say you include
both the private key and the public key in a widely published digital certificate) then the whole public/private key business process would come apart.
lots of past postings on 3-factor authentication
I do agree that (possibly because of the syntactic similarity) lots of people confuse digital signature and real human signatures. A human signature carries with it the connotation of understanding, aggreement, approval, authorization, etc. A digital signature is simply the expression of the access and use of a private key ... and the definition/law of the public/private key business process is that the private key be consistently protected and kept private so that relying parties ... when verifying a particular digital signature ... can associate it with the authentication of a specific entity.
There are several deployed infrastructures of the application of the public/private key business process, where the digital signature generation is simply for authentication purposes ... there is a human that is responsible for activating the access and operation of the private key for the generation of the digital signature ... w/o a requirement that the human ever observes the contents of what the digital signature is being applied to.
As previously mentioned numerous times before ... there is a dual-use attack on public/private key infrastructures where there are procedures in place that require a human to observe, read, and understand any bits that are being digital signed. However, if the same private key that is used in real "signature" applications, is also ever used in authentication applications where the human doesn't observe and read the contents, then the attacker just supplies a valid document masguerading as authentication bits (which the human won't be reading and/or note that non-repudiation is sometimes referenced with regard to some aspects of digital signatures being similar to human signatures (aka read, observe, understand, approve, authorize, agree). the eu finread definition tried to include some aspects of read, observe, understand, approx, authorize, agree ... misc. past finread postings:

@_date: 2005-03-21 20:11:51
@_author: Anne & Lynn Wheeler 
@_subject: Do You Need a Digital ID? 
but business rules for public(/private) key infrastructure can describe that only the associated authenticating entity is the only one in possession of the private key ("something you have") .... as a way of relating the objective of having a specific entity's exclusive ability to access and utilize a private key to three factor authentication.
almost all of the existing "something you have" authentication objects are capable of being counterfeited to a greater or lesser degree. possibly the widest deployed "something you have" authentication objects are magstripe plastic cards ... and it turns out they have been proven to be remarkably easy to counterfeit/copied. the distinction between the ease or difficulty of counterfeiting/copying a magstripe plastic card vis-a-vis a private key ... depends on the level of security used to prevent it from being copied. obviously a private key can be copied with relative ease (possibly much easier than a magstripe plastic card).
in general, you will find that almost all "something you have" authentication objects are subject to being copied ... the issue is the degree to which security processes are in place to prevent them from being copied. just because a private key ... represented by some sequence of bits can be easily copied ... when no protections are in force ... doesn't mean that there can't be security procedures put into place that would make it extremely difficult to achieve copying of a private key.
most models serve a useful purpose until somebody comes up with a better or more applicable model.
many of the 3-factor authentication implementations actually use some representation that allows the actual occurence to be implied by something else.
for instance "something you know" authentication can be done as a "shared-secret" where both the originator and the relying party are both in possession of the shared-secret. an example are keys in symmetric key however, it is possible to have "something you know" authentication where the secret is not shared. For instance if there is a hardware token that is certified to only operate when the correct PIN has been entered .... the PIN represents "something you know" authentication w/o having to share the secret with any other party (the relying party assumes that the correct PIN has been entered by a) being confident of the operation of the particular hardware token and b) the hardware
token having done something known & expected).
similarly, biometrics systems are frequently implemented as a form of shared-secret. an entity's biometric template is registered with some relying party .... and subsequent transactions are authenticated by
checking a new biometric template with the biometric template on file.
the x9.84 biometric standard devotes a great deal to the security for centrally stored biometric templates .... treating them as a greater security risk than traditional "something you know" shared-secrets. the threat is that somebody can obtain files of registered biometric templates and be able to subsequently retransmit them electronicly attempting to impersonate the associated person. The issue in the traditional 'something you know" shared-secret is that a PIN compromise can be reported and a new, replacement PIN/password created.
However, it is somewhat more difficult to replace a thumb or iris when there has been a reported compromise of "something you are" shared secret.
in any case, for all of the deployed existing authentication systems involving any one of the three factor authentication paradigms, all of the methods are vulnerable to copying to one degree or another. as a result, I would assert that criteria of being able to copy or not is not useful .... in all of the different three factors, it isn't whether they are copyable .... it is the difficulty with which they can be copied.
The difficulty that any of them can be copied or counterfeited can be a combination of their native characteristics and the level of security that they are wrapped in.
i would further assert that the meaningful aspects represented by the three=factor authentication model is not the native characteristic of the components but how the individual being authenticated interacts with the components .... i.e.
1) something you know .... implies that the person has to know the value
2) something you have ... implies that the person is in possession of the thing or value ... but doesn't actually know or have it memorized
3) something you are .... implies that it represents some physical characteristic of the person ... w/o the person needing to either know or otherwise possess the object or value.
all three methods can be implemented as static value or shared-secret implementations ... where the characteristic of the particular authentication mode is expressed as some static value and is vulnerable to shared-secret eavesdropping or skimming. "Something you know" shared-secrets can be eavesdropped and fraudulently used. A magstripe plastic card "something you have" is expressed as transmission of the contents of the magstripe, which can be skimmed and used to create counterfeit/copied cards. A "something you are" feature is expressed as biometric template which can be eavesdropped and used in fraudulent transmissions (or counterfeited in things like the gummy bear attack).
rather than interpreter 3-factor authentication as physical characteristics which are classified as being copyable or not-copyable ... 3-factor authentication is frequently interpreted as how the entity being authentication relates to the authentication process.

@_date: 2005-03-23 09:41:21
@_author: Anne & Lynn Wheeler 
@_subject: Do You Need a Digital ID? 
3-factor authentication paradigm obviously doesn't take into account whether the authentication material is treated as a secret or a shared-secret i.e. both biometrics and "something you know" can be implemented as either secret or "shared-secret" .... "shared-secret" tends to have copies of the authentication material in the possession of the relying party ... while "secret" tends to be an infrastructure where the relying-party can infer the existance of the "secret" by other characteristics. it is one of the reasons that the x9.84 biometric standard goes to great deal of description when biometrics are implemented as "shared-secrets" ... with the biometric templates stored at a central site.
3-factor authentication paradigm obviously also doesn't cover whether the authentication is direct fact-to-face or that the relying party is infering authentication taking place by the existance of other kinds of evidence. for instance, a relying party validating a digital signature with a public key will infer that the other party is in possession of the corresponding private key. the relying party may not have direct knowledge of the other party being in possession of the corresponding private key ... the relying party just infers it from the validation of a digital signature with the public key.
which then takes us back to your original response:
 > This is a rather bizarre way of defining things.  "Something you have"
 > is a physical object.  On the one hand, any physical object can
 > be copied to an arbitrary degree of precision; on the other hand,
 > no two physical objects are *identical*.  So a distinction based
 > on whether a replacement is "identical" to the original gets
 > you nowhere.
 Do you Need a Digital ID?
3-factor authentication paradigm obviously also doesn't cover all the sort of business rules that allow a relying party to infer something to be true ... even when they don't have direct evidence that it is true
aka for a public/private key infrastructure where the relying party
normally is inferring that the private key owner has in fact attempted to consistantly and reliably maintained the confidentiality and privacy of the private key and therefor its usefullness as part of any 3-factor authentication paradigm.
3-factor authentication paradigm might also help people designing and/or analysing authentication infrastructures. "something you know" operations may be some what more vulnerable to electronic sniffing, phishing, and/or  information harvesting attacks. "something you have" hopefully are more resistant to electronic sniffing, phishing, and/or information harvesting attacks ... although the transmission of static data in non-face-to-face operations that allow the relying party to infer the possession of the "something you have" has been shown to be extremely vulnerable to skimming attacks (that enable the manufactor of counterfeit magstripe plastic cards). Obviously sniffing and skimming exploits involve very similar threat model.
One application would be to choose a multi-factor authentication implementation where the different factors represent countermeasure to different threats. A multi-factor authentication implementation, where the different factors are vulnerable to the same threats, doesn't provide a great deal of additional security. However, there are obviously a lot of variouscharactistics like
* face-to-face or non-face-to-face
* direct evidence or inferring based on other evidence
* static or non-static data
* central store or remote inferrance
* treat models
* represents what kind of countermeasures
* resistance to counterfeiting/impersonation
* human factors
a difficult human factors has been the issue of "something you know" shared-secrets. shared-secret pin/passwords have had two kinds of guidelines 1) make it hard to guess (which tends to make it difficult to memorize) 2) different shared-secret for every security domain (where most institutions viewed that they were the only security domain, but in reality many people now are faced with scores of different security domains with scores of extremely difficult to remember shared-secrets).
lots of past posts on threats, vulnerabilities, exploits
and lots of 3-factor authentication posts:
and various past posts on general subject of designing high-assurance
we have somewhat viewed assurance and high-availability as similar ... where a system needs to be resistant to all kinds of failures ... regardless of whether they were failures due to attacks/exploits or just plain simple failures. it is part of building real, industrial strength infrastructures .... misc. posts on our high-availability project/product
i have some ancient archived thread abouts (remote) 2-factor authentication where plastic card is used with biometrics in place of pin/password ... and the counter-argument was that they could show biometrics was easier to counterfeit than pin/password .... ignoring the fact that 30 percent of the audience that biometrics were being offered to, routinely wrote their pin on their plastic card. it wasn't part of the institutional design. Futhermore, the issue of having a 2nd factor
(pin/password or biometric) was supposedly a countermeasure for the lost/stolen card threat. It was fairly trivial to show (regardless of the theoritical strength of the particular biometrics versus an ideal pin/password) that it would be more difficult to counterfeit the biometrics than it would be for an criminal to utilize a pin/password written on a lost/stolen card. ... refs:
 checks (was S/390 on PowerPC?)
 checks (was S/390 on PowerPC?)
 biometrics
 biometrics (addenda)
 biometrics
 VS: On-line signature standards
 Opinion  on smartcard security  Biometrics not yet good enough?
 Biometric authentication for intranet websites?
 Biometric authentication for intranet websites?
 Biometric authentication for intranet websites?
 Certificate Authority: Industry vs. Government
 Certificate Authority: Industry vs. Government
 smartcard+fingerprint
 smartcard+fingerprint
 Biometrics

@_date: 2005-03-23 13:57:13
@_author: Anne & Lynn Wheeler 
@_subject: Do You Need a Digital ID? 
Do You Need a Digital ID?
one of the possible side-effects of applying 3-factor authentication paradigm ... and observing that
1) the verification of a digital signature is just a method
of inferring the possession of a specific private key
2) the possession of a private key obviously (theoritically possible, but i know of not instances of people memorizing private keys) isn't "something you know" authentication and a private key isn't "something you are" authentication ... leaving it to be "something you have" authentication (aka in your possession)
3) private keys in their simplest form are just electronic bits that are relatively easy to copy
then in order for a private key to be useful in a "something you have" authentication, it follows fairly staight-forwardly that significant security procedures and countermeasures are required to prevent such copying (in order to provide some level of assurance that the assumed entity is consistantly and uniquely in possession of the specific private key).

@_date: 2005-05-20 22:07:40
@_author: Anne & Lynn Wheeler 
@_subject: What happened with the session fixation bug? 
all of them may have been less than expected ... the comoningly recognized SSL certificate issuers (that have their public key preloaded into common browsers) sell their certificates and have processes that look at whether you have a validly registered corporation. For most practical purposes this has been for e-commerce sites and the objective for the majority is protecting credit card numbers.
however, the reported exploits .... and what seem to represent a significantly larger ROI (fraud for effort invested) is to harvest the merchant transaction file (containing all the accumulated transaction information that would have taken months of listening to gather) ... aka it is much easier to let the merchant gather and organize all the information on behalf of the crook. slightly related posting ...
 Security proportional to risk
the original ssl e-commerce work
had the user typing in the merchant webserver URL as a HTTPS session from the start and then it would check the domain name in the returned certificate (after all the digital signature gorp) with the domain name typed in. this is rarely if ever happening ... the common justification is running SSL during the shopping experience cuts the thruput by 80-90 percent. as a result, SSL is typically saved for the "check-out" button.
so lets say you have been redirected to a fraudulent site and don't know it because the SSL domain name stuff hasn't been done yet. then comes time to do the check-out button. if it is a fraudulent site ... and since the crooks would then be supplying the URL with the check-out button ... the crooks are likely to have obtained a valid SSL certificate for some domain and that domain will match whatever the check-out button supplies.
random past ssl certificate posts
crooks are capable of setting up valid dummy front companies ... it isn't a very large effort.
most of what the CA TTPs do when they are verifying stuff ... is that the person applying for a certificate is in some way associated with a valid company that they claim to be associated with.
then the CA TTPs check with the domain name infrastructure to see if the corporation that they just checked on ... is the same one listed as the owner of the subject domain name (modulo the issue that there can be a common company name, a DBA company name, and a legal company
name ... all for the same corporation and all completely different names ... you sometimes will see this in credit card statements where the store-front name and the company name on the statement are different).
As observed, one of the things SSL was for a countermeasure for integrity problems in the domain name infrastructure involving domain name hijacking (where the mapping of the domain name to an ip-address was altered to be a different ip-address, potentially fraudulent website).
However, there have been more sophisticated domain name hijackings that have occured where both the domain name infrastructure records had both the name of the corporate owner as well as the ip-address altered. In this more sophisticated form, a crook with a perfectly valid dummy front corporation ... that has done the more sophisticated form of domain name hijacking ... could apply for a perfectly valid SSL domain name certificate ... and pass all the tests.
in any case, that was my perception of what we were doing with SSL ten years ago.
PKI is slightly different. One of the reasons that we coined the term "certificate manufactoring" was to try and differentiate what was comingly being referred to as PKI ... and what SSL domain name certificate stuff was actually doing.
Note that there has been a proposal to somewhat address the more complex form of domain name hijacking (both the company name take-over as well as the ip-address take-over) ... which involves having domain name owners register a public key when they get a domain name. Then all future correspondance with the domain name infrastructure is digitally signed ... which then can be veriefied with the onfile public key. as a side note ... this is a non-PKI, certificateless implementation of public key. In any case, with authenticated correspondance ... there supposedly is less chance of domain name hijacking occuring.
This has somewhat been supported by the CA SSL domain name certification industry. The have a complex, expensive, and error-prone identification process to try to establish a valid corporation. And even then they are at the mercy of whether the company name listed in the domain name infrastructure is actually the correct company (i.e. their whole infrastructure otherwise is useless).
The other advantage ... is that the Certification Authority can require that SSL domain name certificate applications also be digitally signed. Then the CA can turn an expensive, time-consuming, and error-prone identification process into a much simpler, cheaper, and reliable authentication process ... by retrieving the onfile public key from the domain name infrastructure for verifying the applicants digital signature (again note that this is a non-PKI, certificateless implementation that they would use as the trust basis for the whole SSL domain name certificate operation).
There is some slight catch22 to this for the SSL domain name certificate business. First off, improving the integrity of the domain name infrastructure for the Certification Authority industry ... would also improve the integrity for everybody ... somewhat mitigating one of the original supposed requirements for having SSL domain name certificates in the first place. The other is that if the SSL certification industry found it viable to base their trust infrastructure on the certificateless, onfile public keys at the domain name infrastructure... it might be possible that the rest of the world might find them acceptable also. One could imagine a slightly modified SSL process where the public key didn't come from a certificate ... but was an onfile certificateless public key retrieved directly from the domain name infrastructure (in much the same way the CA industry has proposed doing).

@_date: 2005-05-31 11:55:37
@_author: Anne & Lynn Wheeler 
@_subject: What happened with the session fixation bug? 
asymmetric cryptography has a pair of keys ... the other of the key-pair decodes what has been encoding by one of them. a business process was defined using this technology where one of the key-pair is designated as public ... and freely distributed and the other of the key-pair is designated as confidential and never divulaged. an authentication business process was defined using public/private business process called digital signature .... where a hash of a message is taken and encoded with the private key. the recipient can recompute the hash of the received message and compare it to the digital signature that has been decoded with the corresponding public key. this catches whether the message has been altered and from 3-factor authentication
* something you have
* something you know
* something you are
implies "something you have" authentication ... i.e. the originator has access and use of the corresponding private key.
PKI was somewhat targeted at the offline email model of the early 80s; the relying party dials up their (electronic) post office, exchanges email, and hangs up. They then may be dealing with first time correspondance from a total stranger with no (offline or online) recourse for determining information about the sender. Relying parties could be seeded with trusted public key repository of trusted third party certification authorities. Stangers could be issued "certificates" (digitally signed by one of these certification authorities) containing informoation about themselves bound to their public key. Email recipients in the offline email days of the early 80s ... could now of source of information regarding first time communication from total strangers (sort of the "letters of credit" model from the sailing ship we were asked to work this small client/server startup in menlo park
that wanted to do payments on something they called a commerce server. In the year we worked with them ... they moved from menlo park to mountain view and changed their name (trivia question ... who previously had the rights to their new name? also what large corporate entity was providing most of the funding for the commerce sever?). some topic drift ... recent postings referencing this original e-commerce work as an example of service oriented architecture (SOA):
they had this technology called SSL which was configured at addressing two issues: a) is the webserver that the user had indicated to the browser ... the actual webserver the browser was talking to and b) encryption of the transmitted information.
SSL digital certificates would be issued
which would contain the domain name of the webserver bound to their public key. the browsers would have trusted public key repository seeded with the public keys of some number of trusted third party certification authorities. the browser SSL process would compare the domain name indicated by the user to the domain name in the digital certificate (after validating the certificate).
(at least) two (other) kinds of vulnerabilities/exploits have shown up.
1) in the name of convenience, the browsers have significantly obfuscated the certificate operation from the end-user. attackers have devised ways for the end-users to indicate incorrect webservers ... which the browser SSL process (if it is even invoked) will then gladly validate as the webserver the user indicated.
2) a perceived issue (with knowing that the webserver that a browser is talking to is the webserver the user indicated) were integrity issues in the domain name infrastructure. however, as part of doing this consulting with this small client/server startup ... we also had to do detailed end-to-end business process due dilligence on some number of these certification authorities. it turns out that a certification authority typically has to check with the authoritative agency for the information they are certifying. the authoritative agency for domain name ownership is the domain name infrastructure ... the very institution that there are integrity questions giving rise to the requirement for SSL domain name server certificates.
In the second vulnerability, the certification authority industry is somewhat backing a proposal that when somebody registers a domain name with the domain name infrastructure ... they also register their public key. then in future communication with the domain name infrastructure, they digitally sign the communication. the domain name infrastructure then can validate the digital signature using the (certificateless) public key onfile for that domain. This supposedly improves the integrity of the communication between the domain name owner and the domain name infrastructure .... mitigating some possible domain name hijacking exploits (where some other organization becomes recorded as the domain name owner).
It turns out that the certification authority industry also has an issue. When somebody makes an application for an SSL domain name certificate, they need to supply a bunch of identification information. This is so the certification authority can perform the expensive, time-consuming and error-prone identification process ... and then do the same with the information on file at the domain name infrastructure as to the owner of the domain name ... and then see if the two domain name owner identifications appear to match. Having an on-file public key for the domain name owner ... the certification authority industry can also require that an SSL domain name applicant, digitally sign their application. Then the certification authority can retrieve the onfile (certificateless) public key and change an expensive, error-prone, and time-consuming identification process into a simple and more reliable authentication process (by retrieving the onfile public key and validating the digital signature).
 From an e-commerce perspective ... the SSL process was to protect against credit card information havesting for use in fraudulent transactions. However, the major vulnerability/exploit before SSL and after the introduction of SSL ... wasn't against credit card information in flight ... but against huge repositories of credit card information
(information at rest). It was much easier for the crooks to steal the information already collected in huge repositories than go to the effort of evesdropping the information inflight and creating their own repositories (fraud return-on-investment, much bigger benefit in stealing large repositories of already collected and organized information). related reference regarding security proportional to risk
the financial standards working group, x9a10 was given the task of preserving the integrity of the financial infrastructure for all retail payments (as well as some number of other requirements) for x9.59 standard
so some earlier work on PKI-oriented protection for retail payments involved digitally signed transaction oriented protocol with attached digital certificates.
in the early 90s, there was some work on x.509 identity certificates. however, there was some issues with ceritifcation authorities predicting exactly what information might be needed by unknown future relying parties ... and so there was some direction to grossly overload these certificates with excessive amounts of personal information. In the mid-90s, some number of institutions were starting to realize that such overloaded repositories of excessive personal information representing significant liability and privacy issues. As a result you saw some retrenchment to relying-party-only certificates
these were digital certificates that basically contained some kind of database record locator (like an account number) bound to a public key (the database record contained all the real information). however, it became trivial to demonstrate that such relying-party-only certificates were redundant and superfluous. This was, in part because they violated the original design point for certificates ... the relying party not having any other recourse to the necessary information. By definition if all the information was in a relying-party's database ... then by definition the certificate was redundant and superfluous.
in this later part of the mid-90s payment scene, these relying-party-only certificates were on the order of 4k-12k bytes. It turns out that a typical retail payment message is 60-80 bytes. Not only were the stale, static, relying-party-only certificates redundant and superfluous ... but they also would contribute to enormous payload bloat (on the order of one hundred times).
the other problem with the relying-party-only, redundant and superfluous, stale, staic, enormous payload-bloat digital certificate based infrastructure ... were that they effectively were targeted only at protecting credit card information "in-flight" ... something that SSL was already doing. They were providing no countermeasure for the major vulnerability to the data "at rest". the information at rest was still vulnerable (and was the major exploit already with or w/o SSL)
So one of the things in the x9a10 financial standards working group was to do a treat and vulnerability analysis ... and design something that could preserve the integrity of the financial infrastructure for all retail payments (credit, debit, stored-value, online, offline, pos, etc).
X9A10 defined a light-weight digitally signed transaction that wouldn't contribute to the enormous payload bloat of the stale, static, redundant and superfluous certificate-based infrastructures.
Another issue was the analysis demonstrated that the major treat and vulnerability was to the data at rest. So for X9.59, a business rule was defined ... for account numbers used for X9.59 transactions ... only correctly verified digitally signed transactions (authenticated) could be authorized.
An x9.59 transaction was digitally signed, and the relying party could use an on-file public key to validate the digital signature .... showing the transaction wasn't modified in transit and providing "something you have" authentication as to the originator (they had access and use of the corresponding private key). furthermore, evesdropping of the transaction in flight ... and/or harvesting the large transaction databases (information at rest) wouldn't yield information for the crook to perform a fraudulent transaction. the current exploits where knowledge from an existing transaction is sufficient to generate fraudulent transaction has gone away ... for vulnerabilities involving both "data in flight" as well as "data at rest".
The issue wasn't that SSL being designed to protect data-in-flight ... the issue was that the major threat/vulnerability has been to "data-at-rest" ... so to some extent, SSL (and the various other countermeasures to "data-in-flight" vulnerabilities) wasn't responding to the major threats. To some extent, e-commerce/internet was opening a theoritical, new vulnerabilities ("data-in-flight") compared to the non-internet world ... and so SSL was somewhat theoritically demonstrating that e-commerce/internet use wouldn't make the situation any worse.
Recent studies have indicated that at least 77% of the id theft exploits have involved insiders (supporting the long standing premise that the majority of fraud is by insiders). The introduction of e-commerce and internet have introduced new avenues for attacking data-at-rest by outsiders. As a result, e-commerce/internet potential threats to data-at-rest has contributed to obfuscating responsible insiders in cases of exploits against data-at-rest.

@_date: 2005-05-31 13:23:34
@_author: Anne & Lynn Wheeler 
@_subject: Citibank discloses private information to improve security 
one might claim then that a solution is to go to a PGP-like repository of trusted public keys (in addition to and/or in conjunction of typical browser repostiory of trusted certification authority public keys). the URL & public key are loaded into the repository and some out-of-band process is used to establish the "trust" level of the information ... and you are involving the end-user in the trust establishment process.
For convenience ... enable this from bookmark and end-user clicks on trusted URLs. then rather than browser using webserver supplied certificate as part of SSL process, the browser uses the onfile trusted public key for that URL.
a threat is social-engineering can convince some number of naive users to do just about anything ... including things like updating a trusted public key repository ... and clicking on email obfuscated URLs (what the email claims to be the URL ... in unrelated to what the URL actually is). a major problem is that a large percentage of the population seems to be extremely naive about trust.
some large amount of the skimming and harvesting related fraud is because of existing authentication paradigms that make extensive use of static data and shared-secrets
a countermeasure could be public key and digital signature verification based authentication. extensive use of file-based private keys make them vulnerable to harvesting by viruses ... but also vulnerable to social engineering attacks getting naive users to divulge contents of private key files.
a countermeasure might be hardware tokens where the private key can't be divulged ... even by the token owner. however, social engineering attacks can still get naive users to perform fraudulent transactions on behalf of crooks (even in hardware token based infrastructures). however, the percentage of the population vulnerabile to such attacks might go down as complexity of the social engineering and/or the awareness of the user population goes up.

@_date: 2005-05-31 14:05:51
@_author: Anne & Lynn Wheeler 
@_subject: "SSL stops credit card sniffing" is a correlation/causality myth 
the major exploits have involved data-at-rest ... not data-in-flight. internet credit card sniffing can be easier than password sniffing .... but that doesn't mean that the fraud cost/benefit ratio is better than harvesting large transaction database files. you could possibly conjecture password sniffing enabling compromise/exploits of data-at-rest ... quick in&out and may have months worth of transaction information all nicely organized.
to large extent SSL was used to show that internet/e-commerce wouldn't result in the theoritical sniffing making things worse (as opposed to addressing the major fraud vulnerability & treat).
internet/e-commerce did increase the threats & vulnerabilities to the transaction database files (data-at-rest) ... which is were the major threat has been. There has been a proliferation of internet merchants with electronic transaction database files ... where there may be various kinds of internet access to the databases. Even when the prevalent risk to these files has been from insiders ... the possibility of outsider compromise can still obfuscate tracking down who is actually

@_date: 2005-05-31 14:31:13
@_author: Anne & Lynn Wheeler 
@_subject: Citibank discloses private information to improve security 
but they appear to be vulnerable to MITM-attacks
a recent thread

@_date: 2005-05-31 14:33:44
@_author: Anne & Lynn Wheeler 
@_subject: Citibank discloses private information to improve security 
a couple more
BofA rolls out authentication tools after data breach incident
Bank of America looks to protect Online users with SiteKey
Payments News: Bank of America Launches SiteKey
Bank of America | Sign up for the SiteKey Service
Bank of America takes on cyberscams
Bank Of America Fights Phishing With New Authentication
Bank of America Announces Industry-Leading Security Feature ...
Bank of America's SiteKey scrutinized

@_date: 2005-05-31 14:59:43
@_author: Anne & Lynn Wheeler 
@_subject: Citibank discloses private information to improve security 
just for the heck of it ... something today more from the physical world
ATM scams added to GASA?s fraud library
CAPE TOWN, South Africa and BROOKINGS, S.D. ? The ATM Industry Association's Global ATM Security Alliance launched its online library of ATM fraud, according to a news release. The library is part of Cognito, GASA?s global ATM crime data management system.
... snip ...
... and

@_date: 2005-05-31 15:19:38
@_author: Anne & Lynn Wheeler 
@_subject: Citibank discloses private information to improve security 
oops, sorry, forgot to include this one
Hong Kong banks to introduce two-factor authentication for online Banks in Hong Kong are set to introduce two-factor authentication services to the country's 2.7 million Internet banking customers next month.
... snip ...
and lots of collected posts on 3-factor authentication paradigm
* something you have
* something you know
* something you are

@_date: 2005-05-31 16:43:09
@_author: Anne & Lynn Wheeler 
@_subject: Citibank discloses private information to improve security 
as discussed in numerous non-repudiation posts, dual-use threat posts, and posts about human signatures .... where the human signature implies that the person has read, understood, authorizes, approves, and/or agrees with what is read and understood .,...
the validation of a digital signature with a public key implies that the message hasn't been altered since transmission and there is "something you have" authentication (the originator has access and use of the corresponding private key). the simple validation of a digital signature doesn't carry with it any of the sense of a human signature and/or in most business scenarios ... the relying party has previous knowledge and contact with the entity that they are dealing with (making the introduction of PKI digital certificates redundant and superfluous). Furthermore, x.509 identity certificates possibly horribly overloaded with personal information would reprensent significant privacy issues.
i've claimed that in the aads effort
not having to be pre-occupied with trying to interest relying parties in digital certificates containing information they already had .... we were more free to concentrate on general threat, risk and vulnerability analysis. for instance, one of the things that a relying party might be really interested in is the integrity of the environment housing a subject's private key (is it in a software file or a hardware token, if a hardware token, what are the characteristics of the hardware token, etc) and the integrity of the environment in which a digital signature was generated.
one possible scenario is that CAs wanted to convince relying parties in the value of the certificates and not distract them with fundamental business integrity issues ... which might have resulted in businesses diverting money to fundamental business integrity items ... rather than spending on redundant and superfluous digital certificates likely containing information that they already had (i.e. having digital certificates would result in magical fu-fu dust being sprinkled over the rest of the infrastructure automagically precluding any such integrity problems?). furthermore they could spread semantic confusion ... somehow implying that because the term "digital signature" contained the word "signature" ... it was somehow related to a human signature.
lots of collected past postings related to fraud, exploits. vulernabilities, etc
some number of posts on account number harvesting

@_date: 2005-11-01 15:07:54
@_author: Anne & Lynn Wheeler 
@_subject: Some thoughts on high-assurance certificates 
as part of some work on cal. & fed. e-signature legislation ... one of
the industry groups involved was the insurance industry. rather than PKI
certificates, there was some look at real-time, online transactions ...
where the liability was calculated on the basis of each individual
The PKI certification model ... somewhat is paradigm for the letters of
credit offline scenario from the sailing ship days. in the modern world
... that somewhat states that the certificate is issued for a period of
time ... possibly one year ... and theoritically covers all operations
that might occur during the period of that year ... ragardless of the
number of operations that might be involved during that period ... where
each operation carried liability. in the online scenario ... rather than
having a stale, static certificate that carried with it implied
liability for the period of time, independent of the number of
operations ... each individual operation was a separatee liability
one could imagine insurance on a large tanker for a period of a year
with regard to sinking. that translation to an electronic world ...
would be that the tanker would have an arbitrary number of sailings ...
and could sink on each sailing ... and having sunk on a previous sailing
... wouldn't prevent it from its next assignment and sinking again.
the "insurance" in the credit card industry is that there is an online
operation for each transaction ... and each transaction involves the
merchant being charged a value proportional the transaction value. the
liability is taken on each online transaction ... rather than for a
period of time ... regardless of the number or magnitude of the
this is somewhat with respect to my previous reply that the
certification and assurance of the certificaqtion can be independent of
the way that certification is represented. in the past for the offline
world ... having a stale, static certificate representing that
certification was useful ... because there was no way of obtaining
real-time, online certification information. with ubuquitous online
availability, there has been more and more transition to real-time
online certification represwentation especially as the values involved
increases (frequently the real-time, online certification representation
can involve higher quality and/or more complex information ... like
real-time aggregated information ... which is rather difficult with a
stale, static represnetation creaed at some point in the past)

@_date: 2005-11-28 04:39:10
@_author: Anne & Lynn Wheeler 
@_subject: Broken SSL domain name trust model 
so this is (another in long series of) post about SSL domain name trust
basically, there was suppose to be a binding between the URL the user
typed in, the domain name in the URL, the domain name in the digital
certificate, the public key in the digital certificate and something
that certification authorities do. this has gotten terribly obfuscated
and looses much of its security value because users rarely deal directly
in actual URLs anymore (so the whole rest of the trust chain becomes
significantly depreciated).
the contrast is the PGP model where there is still a direct relationship
between the certification the user does to load a public key in their
trusted public key repository, the displayed FROM email address and the
looking up a public key using the displayed FROM email address.
the issue isn't so much the PGP trust model vis-a-vis the PKI trust
model ... it is the obfuscation of the PKI trust model for URL domain
names because of the obfuscation of URLs.
so one way to restore some meaning in a digital signature trust model is
to marry some form of browser bookmarks and PGP trusted public key
repository. these trusted bookmarks contain both some identifier, a url
and a public key. the use has had to do something specific regarding the
initial binding between the identifier, the url and the public key. so
such trusted bookmarks might be
1) user clicks on the bookmark, and a psuedo SSL/TLS is initiated
immediately by transmitting the random session key encrypted with the
registered public key. this process might possible be able to take
advantage of any registered public keys that might be available from
security enhancements to the domain name infrastructure
2) user clicks on something in the web page (icon, thumbnail, text,
etc). this is used to select a bookmark entry ... and then proceeds as
in  above (rather than used directly in conjunction with a URL and
certificate that may be supplied by an attacker).
there are other proposals that try and collapse the obfuscation between
what users see on webpages and the actual security processes (trying to
provide a more meaningful direct binding between what the user sees/does
and any authentication mechanism) ... but most of them try and invent
brand new authentication technologies for the process.
digital signatures and public keys are perfectly valid authentication
technologies .... but unfortunately have gotten terribly bound up in the
certification authority business processes. the issue here is to take
perfectly valid digital signature authentication process ... and create
a much more meaningful trust binding for the end-user (not limited to
solely the existing certification authority and digital certificate
business models).
the issue in  is that the original electronic commerce trust process
was that the URL initially provided by the user (typed or other means)
started the trust process and avoided spoofed e-commerce websites. one
of the problems has been that the SSL security has so much overhead,
that e-commerce sites starting reserving it just for payment operation.
As a result, users didn't actually encounter SSL until they hit the
checkout/pay button. Unfortunately if you were already at a spoofed
site, the checkout/pay button would have the attacker providing the
actual URL, the domain name in that URL, and the SSL domain name
so the challenge is to drastically reduce the obfuscation in the
existing process ... either by providing a direct mechanism under the
user control for getting to secure websites or by doing something that
revalidates things once a user is at a supposedly secure webstie.
the issue is that if users start doing any pre-validation step and
storing the results ... possibly something like secure bookmarks ...
then it becomes farily straight-forward to store any related digital
certificates along with the bookmark entry. if that happens, then it
becomes obvious that the only thing really needed is the binding the
user has done between the public key in the digital certificate and the
bookmark entry. at that point, it starts to also become clear that such
digital certificates aren't providing a lot of value (being made
redundant and superfluous by the trust verification that the user has
done regarding the various pieces of data in the entry).
in effect, the PKI model is based on premise that it is a substitute
where the relying party isn't able to perform any trust
validation/operations themselves (i.e. the letters of
credit/introduction model from the sailing ship days). when the relying
parties have to go to any of their own trust operations, then there is
less reliance and less value in the trust operations performed by
certification authorities.

@_date: 2005-10-01 09:29:06
@_author: Anne & Lynn Wheeler 
@_subject: 'Virtual Card' Offers Online Security Blanket 
Offered to holders of Citi, Discover and MBNA cards, these "virtual
credit cards," or single-use card numbers, are designed to give some
peace of mind to consumers concerned about credit card fraud.
... snip ...
when we were doing x9.59 ... some observed that during any transition
period, groups of people would require two account numbers and claimed
there weren't enough available numbers in the account number space to
support that. the issue is that x9.59 has business requirement that
account numbers used in x9.59 transactions can only be used in strongly
authentication transactions ... and can't be used in other kinds of
transactions. x9.59 account numbers obtained through skimming, phishing,
data breaches, etc ... then can't be turned around and used in ordinary
transactions that aren't strongly authenticated
in any case, single-use account numbers also address the issue of re-use
of account numbers from skimming and data breaches (i.e. places that
they might normally be obtained because of wide-spread requirement for
access to account numbers by normal business practices). they are less
effective in phishing attacks, possibly involving, as yet, unused
account numbers. in any case, single-use account numbers could be
considered a much more profligate use of account number space ... than
recent post somewhat related to security proportional to risk
 DDJ Article on "Secure" Dongle
and long standing example
aka there are various scenarios that effectively only need knowledge of
the account number to perform fraudulent transactions ... and the
account number has to be widely and readily available because of its use
in a broad range of standard business processes. because of the broad
range of business processes requiring availability of the account number
... it is difficult to secure it using "privacy" or "confidentiality"
... aka from security PAIN acronym
P ... privacy
A ... authentication
I ... integrity
N ... non-repudiation
application of cryptography technology for privacy/confidentiality
security isn't a very effective solution because of the wide-spread
requirement for account number availability in numerous business
processes. X9.59 approach was to apply *authentication security* (in
lieu of *privacy security*) as a solution to fraudulent mis-use of
account numbers obtained from skimming, phishing, data breaches, etc.

@_date: 2005-10-13 23:32:01
@_author: Anne & Lynn Wheeler 
@_subject: mixing authentication and identification? 
FFIEC Guidance; Authentication in an Internet Banking Environment
The Federal Financial Institutions Examination Council (FFIEC) has
issued the attached guidance, ?Authentication in an Internet Banking
Environment.? For banks offering Internet-based financial services, the
guidance describes enhanced authentication methods that regulators
expect banks to use when authenticating the identity of customers using
the on-line products and services. Examiners will review this area to
determine a financial institution?s progress in complying with this
guidance during upcoming examinations. Financial Institutions will be
expected to achieve compliance with the guidance no later than year-end
... snip ..
and some comments from some other thread:
 NEW USA FFIES Guidance
and ...
Uncle Sam Comes Knocking
The U.S. government's interest in having banks help it form networks of
federated identity, thus allowing vetted, shared user-credentials
between government and private industry, is obvious. So far, only four
banks-Wells Fargo, Wachovia, National City and an unidentified bank-have
signed on, though more are expected to join Uncle Sam's E-Authentication
Federation. The looming question: What's in it for banks?
... snip ...

@_date: 2005-10-31 10:13:26
@_author: Anne & Lynn Wheeler 
@_subject: Some thoughts on high-assurance certificates 
when we were doing this stuff for the original payment gateway ...
we had to also go around and audit some number of these relatively (at
the time) brand new organizations called certification authorities ...
issuing these things called digital certificates.
we listed a large number of things that a high assurance business
service needed to achieve (aka explaining that the ceritification
authority business was mostly a business service operation). at the
time, several commented that they were started to realize that ... it
wasn't a technically oriented local garage type operation ... but almost
totally administrative, bookkeeping, filing, service calls ... etc (and
from an operational standpoint nearly zero technical content). most of
them even rasied the subject about being able to outsource their actual
the other point ... was that the actual design point for digital
certificates ... were the providing of certified information for offline
relying parties ... i.e. relying parties that had no means of directly
accessing their own copy of the certified information ... and/or it was
an offline environment and could not perform timely access to the
authoritative agency responsible for the certified information.
as the online infrastructure became more and more pervasive ... the
stale, static, digital certificates were becoming more & more redundant,
 superfulous and useless. in that transiition, there was some refocus by
certification authority from the offline market segment of relying
parties (which was rapidly disappearing as the online internet became
more and more pervasive)) to the no-value relying party market segment
... aka those operations where the operation could justify the cost of
having their own copy of the certified information AND couldn't cost
justify performing timely, online operations (directly contacting
authoritative agency responsible for certified information). even this
no-value market segment began to rapidly shrink as the IT cost rapidly
declined of maintaining their own information and the telecom cost of
doing online transactions also rapidly declined.
while the attribute of "high-assurance" can be viewed as a good thing
... the issue of applying it to a paradigm that was designed for
supplying a solution for an offline environment becames questionable in
a world that is rapidly becoming online, all-the-time.
it makes even less sense for those that have migrated to the no-value
market segment ... where the parties involved that can't cost justify
online solutions ... aren't likely to find that they can justify costs
associated with supporting a high-assurance business operation.
part of the issue here is the possible confusion of the business process
of certifying information and the digital certificate business operation
targeted at representing that certified information for relying parties
operating in an offline environment .... and unable to perform timely
operations to directly access the information.
this can possibly be seen in some of the mid-90s operations that
attempted to draw a correlation between x.509 identification digital
certificates and drivers licenses ... where both were targeted as
needing sufficient information for relying parties to perform operations
... solely relying on information totally obtained from the document
(physical driver's license or x.509 identification digital certificate).
there was some migration away from using the driver's license as a
correlary for x.509 identification digital certificates ... as you found
the majority of the important driver's license relying operations
migrating to real-time, online transactions. a public official might use
the number on the driver's license purely as part of a real-time online
transaction ... retrieving all the actual information ... and not
needing to actually rely on the information contained in the driver's
license at all. it was only for the relatively no-value operations that
the information in the physical drivers license continued to have
meaning. any events involving real value were all quickly migrating to
online, real-time transactions.

@_date: 2005-09-01 10:47:56
@_author: Anne & Lynn Wheeler 
@_subject: Another entry in the internet security hall of shame.... 
an alternative view of the server side is to recognize that the two most
widest used authentication infrastructures are radius and kerberos
furthermore both radius and kerberos not only have facilities for
abstracting authentication function ... but also abstracting
authorization functions.
one of the short-comings of PKIs, CAs, and digital certificates was the
issue of encorporating authorization information along with the
authentication information into a single paradigm ... for one thing
digital certificates tended to be publicly available .. and
authorization information frequently tends to be sensitive.
frequently then the issue is that attempting to replace existing
authentication infrastructures with PKIs, CAs, and digital certificates
still leaves the rest of the infrastructure for authorization in place.
It is then frequently trivial to demonstrate that the stale, static
digital certificates are redundant and superfluous ... and it is more
efficient and less expensive to have an integrated authentication and
authorization environment by simply registering public keys in lieu of
passwords in an existing integrated authentication/authorizatin environment.
for example ... the original pk-init draft for kerberos specified
registering public keys in lieu of passwords ... giving a integrated
authentication/authorizatin environment using digital signature
verification in place of passwords for authentication. later PKI, CAs,
and digital certificate operation was added to the pk-init draft.
Another aspect was that in the early 90s ... certification authorities
were started to wonder just what set of information would really be
useful for unknown and undefined relying parties ... as a result there
was some direction to start grossly overloading x.509 identity
certificates with huge amounts of personal information.
It was in the mid-90s that some institutions were starting to realize
that x.509 identity certificates, grossly overloading with huge amounts
of personal information represented significant privacy and liability
issues. As a result you started to see the apperance of
relying-party-only certificates (in fact, it may have been a german bank
that started producing the first relying-party-only certificates)
A relying-party-only certificate basically contains some sort of
database lookup value (like userid, account number, etc) where the real
information is kept and a public key. However it is trivial to
demonstrate that a relying-party-only certificate is redundant and
superfluous when the real information has to be directly accessed ... by
demonstrating that the body of the signed message/transaction can also
include the same database index value ... and the real information will
be where the registered public key is recorded. That makes the public
key in the digital certificate redundant and superfluous. Simple
scenarios like transactions have to include the identifier ... and in
certificate-based scenarios ... the identifier in the transaction needs
to match the identifier in the certificate (or otherwise you could have
somebody with a valid account doing transactions against any account at
the same bank). With the identifier in the body of the
message/transaction and the registered public key in the account record,
the relying-party-only digital certificate becomes redundant and

@_date: 2005-09-01 11:04:36
@_author: Anne & Lynn Wheeler 
@_subject: Another entry in the internet security hall of shame.... 
in fact, the first time i heard the term relying-party-only certificates
was in a presentation by somebody from a german bank at a nissc
conference ... describing all the horrible privacy and liability
problems represented by x.509 identity certificates.

@_date: 2005-09-01 14:28:21
@_author: Anne & Lynn Wheeler 
@_subject: Another entry in the internet security hall of shame.... 
on the business/server side ... where x.509 identity certificates
represent horrible privacy and liability issues ... and they've migrated
to relying-party-only certificates
by definition, the institution needs to have already registered the
clients public key ... in order to even issue a relying-party-only
certificate ... they client/customers "public key" has been preshared
(otherwise it would have been impossible for the institution to have
issued the certifivate).
at this point it is trivial to demonstrate that the issuing of the
relying-party-only certificate is redundant and superfluous ... since by
definition the institution has the PSK.
so if you look at existing business process where "pre-shared" passwords
are part of an authentication administration infrastructure that is
integrated with the permissions and authorization administrative
infrastructure ... say like either radius or kerberos
it is possible to register public keys in place of password, retaining
the existing business process and integrated administration of
authentication and authorization.
one of the issues when we started dealing with this small client/server
startup that wanted to do payments on their server platform
had this new thing called SSL which were dependent on PKI, certification
authorities, and digital certificates. As part of that effort, we had to
 do various kinds of business process and end-to-end audits of these
things called certification authorities. There was a lot of discussion
in these audits about certification authorities having very little to do
with security and technology ... and primarily involved in a traditional
service operation with loads of administrative work.
One of the characteristics of businesses that have existing relationship
management administrative relationship management operations ... like
financial institutions with accounts or business with accounts payable
and accounts billable or ISPs ... is that they have tried to provide
some amount of administrative scaleup and integrity to the operation.
Frequently it is possible to show a trivial toy PKI demo as an add-on
w/o impacting the core authentication and authorization business
processes. The big expenses quickly dawns on them when it starts to
appear that PKI operation might have some impact on real business
operations. At that point of time, it becomes quickly apparent that any
full-scale PKI authentication infrastructure deployment will have an
enormous cost duplication (especially after there has been possibly
scores of years developing scaleable and integrated authentication and
authorization infrastructures).
At that point, the ongoing duplicate PKI operational costs totally
dominate ... any trivial software technology deployment issue. Part of
the issue is that the promise of having x.509 identity certificates
groslly overloaded with enormous amounts of privacy information along
with authorization and permissions ... has been shown to be false. That
the organization isn't able to use the deployment of a X.509 PKI
operation (with the digital certificates containing enormous amounts or
privacy and senstive information) to eliminate their existing integrated
relationship management and administrative infrastructure costs ... it
possible turns out to be possibly doubling the actual business costs (in
any sort of full-scale production deployment used for actual business
purposes.). It may actually be worse than doubling ... the basic PKI
administrative infrastructure may be replicated ... doubling the costs
... however the actual costs may be tripled if the existing production
business operation and the replicated PKI administrative operation then
has to be kept in sync.
authentication/authorization/permission infrastructure to use digital
signature authentication with public key registration ... conforms to
existing business practices and doesn't introduce duplicate and
unnecessary administrative operation.

@_date: 2005-09-07 10:49:08
@_author: Anne & Lynn Wheeler 
@_subject: Another entry in the internet security hall of shame.... 
> ATMs would be infeasible if they were not a 2 factor authentication
ATMs use "something you have" authentication ... a card with a magstripe
that is sent out. There is a 2nd factor, PIN, that is also distributed
... as a countermeasure to lost/stolen cards.
note that both credit cards and many debit cards can be used in non-PIN,
signature mode (i.e. if the card is lost/stolen, crook may still be able
to use it w/o PIN).
multi-factor authentication presumes that the different factors are
subject to different kinds of vulnerabilities and exploits.
PINs are a form of shared-secrets ... security requirements typically
mean that there is a unique shared-secret for every environment. the
result is vast proliferation of PINs and passwords leading to people
writting down their pins & passwords (there was some study that claimed
30percent of atm cards have pins written on them). As a result,
multi-factor infrastructure is undermined because of shared-secret based
environments has led to scores of shared-secrets that people are
required to keep track of.
the short-coming of shared-secret environment, is that a shared-secret
can be used for both origination as well as verification (the same value
 used for authentication can also be used for impersonation), which has
led to requirement that there are large number of unique shared-secrets,
 which has led to the huge proliferation in the number of shared-secrets
... which has also led to underminning principle of multi-factor
authentication ... having unique failure modes .... sorry for that ... I
spent some large amount of time producing  high availability systems ...
where security exploit/vulnerabilities were just another kind of system
it isn't so much that the key distribution/sharing mechanism is flawed
... it is that there are flaws in shared-secret based infrastructures
(including swamping nominal human factors with an impossible number of
different things to memorize).
The other short-coming in current ATM environment is skimming that can
go on at the POS or ATM terminal ... where the attackers can record the
card and pin information. This results in both 1) common vulnerability
for two factor authentication ... defeating purpose of having
multi-factor authentication and 2) that existing technology is quite
vulnerable to replay attacks (aka creating copy of magstripe in
counterfeit card and being able to reproduce the pin).
So fundamental public key operation can address a number of these
short-comings w/o resorting to PKI infrastructure and/or changing the
key and card distribution operation.
1) upgrade magstripe to hardware token that does digital signature
authentication. the digital signature is unique each time and is
therefor resistant to existing replay vulnerability, threats and attacks
2) since public key is not a shared-secret based infrastructure ... it
is practical to record the same public key in multiple different
environments, in theory transitioning to a person-centric environment
(from the existing institutional-centric environment). this also is more
resistant to data breaches ... since any exposure of the recorded public
key can't be used for impersonation.
3) there is still the issue of using a PIN as countermeasure to
lost/stolen token ... which is a significantly lower threat compared to
crooks being able to harvest tens of thousands or millions of pieces of
information for purposes of account fraud (skimming recording devices at
ATM & POS terminals or data breaches).
4) with hardware token, the PIN can be used directly with the token for
token operation ... as opposed to be transmitted and recorded in the
infrastructure. That eliminates the PIN as a shared-secret. In theory a
person-centric environment can use the same PIN/token with multitude of
different infrastructures and/or use the same PIN with multitude of
different tokens. This last becomes a trade-off between remembering lots
of PINs (and threat of having them written down) vis-a-vis compromise of
single PIN can expose several tokens. However, in person-centric
environment, it is possible to leave such a threat trade-off decision to
the individual.
The issue of PKI, certificatin authorities, and digital certificates
were that the original digital certificate design point was for first
time communication between strangers where the relying party also had
not timely, direct (possibly online) access to a trusted party. The
digital certificates filled this trust void in a manner siumilar to
letters of credit from the sailing ship days.
In an environment where relying parties have long-standing and extensive
relationship management operations keeping track of large number of bits
of information ... it is trivial to show that digital certificates are
redundant and superfluous.
Furthermore, even in the first time communication between strangers ...
where the relying party has no prior interaction with the subject ...
digital certificates may still be redundant and superfluous standin for
the real information if the relying party is able to directly contact
some authoritative agency responsible for the information (aka real-time
communication obtaining the real current information in lieu of a
redundant and superfluous, stale, staic digital certificate).
misc. past person-centric related postings:
 maximize best case, worst
case, or average case? (TCPA)
 MP cost effectiveness
 MP cost effectiveness
 were dumb terminals actually so
 To live in interesting times
- open Identity systems
 massive data theft at
MasterCard processor
 the limits of crypto and
 Maximum RAM and ROM for smartcards
 Security via hardware?
 public key authentication
 Innovative password security

@_date: 2005-09-09 00:21:48
@_author: Anne & Lynn Wheeler 
@_subject: ID theft ring proves difficult to stop 
some older refs:
ID theft ring escapes shutdown
MacDailyNews - Apple and Mac News - Welcome Home
Massive ID theft ring still operating
Grand Theft Identity
Servers keep churning in ID theft case
Servers keep churning in ID theft case
Servers keep churning in ID theft case
most recent:
ID theft ring proves difficult to stop
Almost a month after Sunbelt Software of Clearwater discovered what it
called an international identity theft ring, one Web site collecting the
data has been shut down. But the operation is active.
... snip ...

@_date: 2005-09-10 16:11:26
@_author: Anne & Lynn Wheeler 
@_subject: Is there any future for smartcards? 
my characterizations of smartcards from the 80s ... was that they were
targeted at the portable computing market segment. however, the
technology was only sufficient for the chip ... and there wasn't
corresponding portable technology for input and output. as a result you
saw things like the work in ISO for standardizing interface to the chip
... so the chipcard could be carried around and interop with fixed
input/output stations.
in the early 80s, you saw the advent of PDAs and cellphones with
portable input/output technology that sort of took over that market.
which would you prefer a portable computing device with lots of
application and data where you had to go find a fixed input/output
station to utilize the device .... or a similar portable computing
device where the input/output was integrated?
in the 90s, anne & I were asked to spec, design, & cost the
infrastructure for a mondex roll-out in the US ... aka it wasn't the
mondex card per-se ... it was all the rest of the infrastructure and
dataprocessing required to support a mondex infrastructure (from the
mondex international superbrick on down to loading/unloading value on
the chip). one of the financial issues with mondex was that most of the
float & value was at mondex international with the superbrick; in fact
later on you saw mondex international making inducements to various
countries where they offered to split the float. this was about the time
several of the EU central banks made the statement that the current
genre of stored-value smartcards would be given a couple year grace
period allowing them to establish an infrastructure ... but after that
they would be required to pay interest on unspent value in the card
(would have pretty much eliminated the float value at higher levels in
the operational stream). that was coupled with the fact that it had a
fundamental offline design point ... i.e. the value was held in the chip
... and could be moved between chips w/o having to go online ... becomes
something of an anachronism if you have ubiquitous online access (as
you've observed).
mondex also sponsored a ietf working group looking at possibly
application of mondex transactions in the internet environment. that
really represented a difficult undertaking being a shared-secret based
infrastructure. the working group somewhat morphed and eventually turned
out ECML and some other stuff ... some recent RFCs ..
XML Voucher: Generic Voucher Language
Voucher Trading System Application Programming Interface (VTS-API)
which evolved out of the work on ECML (electronic commerce markup
language), which in turned started out with working group somewhat
looking at adapting Mondex to Internet transactions.  Electronic
Commerce Modeling Language (ECML) Version 2 Specification
some of that chipcard technology can be applied to an electronic
"something you have" authentication technology ... where it is difficult
to compromise and/or counterfeit a valid chip.
this raises something of a perception issue ... if you stick with the
protable computing device model ... then the chipcard has a bunch of
capability that is redundant and/or superfluous for somebody with a
If you go with purely the (hard to compromise and counterfeit)
"something you have" authentication model in an online world ... then
KISS (or Occam's Razor) would imply that most of the features associated
with the earlier smartcard model are redundant and superfluous (and
might actually pose unnecessary complexity and points of
attack/compromise for something that is purely targeted as "something
you have" authentication).
a couple recent postings somewhat related to threat models and
authentication vulnerabilities.
 Hi-tech no panacea for ID
theft whoes
 Hi-tech no panacea for ID
theft woes

@_date: 2005-09-11 16:49:16
@_author: Anne & Lynn Wheeler 
@_subject: Another entry in the internet security hall of shame.... 
> For PKI to have all these wonderful benefits, everyone
the real issue in the early 90s ... was that the real authoritative
agencies weren't certifying one true identity ... and issuing
certificates representing such one true identity ... in part because
there was some liability issues if somebody depended on the information
... and it turned out to be wrong.
there was talk in the early 90s of independent 3rd party trust
organizations scene and claimed that they would check with the official
bodies as to the validity of the information ... and then certify that
they had done that checking ... and issue a public key certificate
indicating that they had done such checking (they weren't actually
certifying the validaty of the information ... they were certifying that
they had checked with somebody else regarding the validaty of the
the issue of these independent 3rd party trust organizations was that
they wan'ted to make money off of certifying that they had checked with
the real organizations as to the validaty of the information ... and
they way they were going to make this money was by selling public key
digital certificates indicating that they had done such checking. the
issue then came up was what sort of information would be of value to
relying parties ... that should be checked on and included in a digital
certificate as having been checked.  It started to appear that the more
personal information that was included ... the more value it would be to
relying parties ... not just your name ... but name, ancestry, address,
and loads of other characteristics (the time of stuff that relying
parties might get if they did a real-time check with credit agency).
one of the characteristics of the public key side of these digital
certificates ... was that they could be freely distributed and published
all over the world.
by the mid-90s, institutions were starting to realize that such public
key digital certificates ... freely published and distributed all over
the world with enormous amounts of personal information represented
significant privacy and liability issues. you can also consider that if
there was such enormous amounts of personal information ... the
certificate was no longer being used for just authenticating the person
... but was, in fact, identifying the person (another way of viewing the
significant privacy and liability issues).
as a result, you started seeing institutions issuing relying-party-only
certificates in this time frame
which contained just a public key and some sort of database or account
lookup value ... where all the real information of interest to the
institution was kept.
the public key technology ... in the form of digital signature
verification, would be used to authenticate the entity ... and the
account lookup would establish association with all the necessary
real-time information of interest to the institution.
this had the beneficial side-effect of reverting public key operations
to purely authentication operations ... as opposed to straying into the
horrible privacy and liability issues related to constantly identifying
the entity.
however, it became trivial to prove that relying-party-only certificates
are redundant and superfluos ... with all the real-time information of
interest for the instittution on file (including the public key) ... and
the entity digitally signing some sort of transaction which already
included the database/account lookup value ... there was no useful
additional information represented by the relying-party-only certificate
... that the relying party didn't already have (by definition, the
public key was registered with the relying party as prelude to issuing
any digital certificate ... but if the public key had to already be
registered, then the issuing of the digital certificate became redundant
and superfluous).
this was also in the era where the EU data privacy directive was pushing
that names be removed from various payment card instruments doing online
electronic fund transactions. If the payment card is purely a "something
you have" piece of authentication ... then it should be possible to
perform a transactions w/o also requiring identification.
as to the 2nd part ... passwords are a shared-secret, based,  intrenched
institutional-centric technology. it requires lot less technology
infrastructure to support a shared-secret password based operation. this
was ok back in the mar, 1970 ... when i got my first permanent home
terminal with userid/password login to the office computer ... and i
only had a single pin/password. however, as the decades passed ... the
number of shared-secret password/pin based environments proliferated to
the point where i now have to deal with scores of different values ...
all of which i'm suppose to theoritically have memorized, each one of
them being unique from the others ... and potentially have to be changed

@_date: 2005-09-12 08:07:33
@_author: Anne & Lynn Wheeler 
@_subject: Is there any future for smartcards? 
a couple years ago ... i was on an assurance panel in the tcp/tpm track
at idf. during my 5 minutes ...
i happened to comment that over the previous couple years that tpm had
gotten simpler and started to look more and more like aads
one of the tpm people was in the front row ... and replied that i didn't
have a couple hundred people on a committee helping me design a chip.
I even claimed that the original aads chip design could meet the then
tpm requirements with no changes.
some side drift into finread
a minor anecdote
htt:// Q: Internet banking
one of the things considered in the x9.59 financial standard
was the provisions of have two digital signatures on a transaction ...
one authenticating the originator and one from the signing environment.
two issues with respect to the finread standard has been 1) secure
pin-pad and secure entry of pin entry and 2) is what you are signing
what you see. finread provides for a hardened external device that
attempts to address both of these issues. the issue from a financial
institution authenticating and authorizing the transaction for risk
management ... is how does the financial institution (or other relying
party) really know that a finread terminal was used for a particular
transaction (as opposed to any other kind of terminal).
the finread standard specifies the operational
characteristics/objectives of the terminal/reader ... but doesn't
actually provide assurance to the financial institution (or other
relying party) that a certified finread terminal was used for the actual
signing environment.
this is sort of out of risk adjusted capital from basel
.... all the possible risks are evaulated for an institution ... and
capital assets are put aside proportional to the evaluated risks.
approved transactions that have been signed by both the account owner
and a certified finread terminal should have lower possible risk than
transactions simply signed by the account holder (more unknowns and
possible vulnerabilities)
in financial transactions there typically are (at least) two interested
parties ... the individual as the account owner ... and the financial
institution as the relying party & potentially having significant
liability with respect to fraudulent transactions.
software may surfice when things are under your own phsyical control AND
nobody else has exposed risk related to operations performed in that
environment under. however, when there are other parties at risk, they
may ask for a higher level of assurance than simply a statement from the
individual that there have been no compromises. some collected postings
on assurance
and fraud

@_date: 2005-09-13 10:55:52
@_author: Anne & Lynn Wheeler 
@_subject: Another entry in the internet security hall of shame.... 
this is relatively straight-forward on the server side ... most
webservers have stub-code for client authentication. frequently you see
places writing roll-your-own code for accessing a password flat file
(and comparing passwords for authentication).
 another approach is to have the webserver client authentication
stub-code call kerberos or radius interface
where the clients credentials are managed and administrated ...
including authentication, authorizations and also potentially accounting
the original pk-init draft for kerberos had public keys registered in
lieu of passwords ... and kerberos doing digital signature verification
with the on-file public key. similar implementations have existed for
basically use the extensive real-time administrative and operational
support for integrated authentication, authorization and even accounting
across the whole infrastructure. ISPs and/or corporations that currently
use something like radius for their boundary authentication in places
like dial-in routers ... could use the same exact administrative and
operational facilities for providing client authentication,
authorization and accounting for any webhosted services they might
provide (aka ... the integrated administrative and operational support
could include very dynamic and fine-grain authorization information ...
like which set of servers during what portions of the day).
the other advantage of the integrated real-time business,
administrative, and operational of a radius type approach is that it can
select the authentication technology used on a client-by-client basis
... it doesn't have to be a total system-wide conversion. the
radius/kerberos solution could be rolled out on all the servers ... and
then technology selectively rolled on a client-by-client basis ...
continueing to use the same exact integrated business, admnistrative,
and management real-time characteristics with large co-existance of
different client technologies (for instance ... when clients setup their
dial-in PPP connection to their server ... they may be offered a number
of different authentication options ... a server-side radius operation
can concurrently support all possible authentication technologies ...
appropriantly specified technology on a client by client basis.
kerbersos and radius are extensively used for doing real-time integrated
administrative and management of authentication, authorization and even
accounting information. registering public keys in lieu of passwords is
a straight-forward technology operation upgraded ... preserving the
existing business, management, and administrative real-time integrated
it wouldn't introduce new business, management, and/or administrative
operations ... like frequently occurs with pki-based operations.
with the use of the appropriate business, management, and administrative
real-time infrastructure ... straight-forward new technology roll-outs
addressing various authentication, authorization, and/or accounting
requirements doesn't have to be a syncronized, serialized, system-wide
change-out ... all the servers could be upgraded to a real-time
business, management, and administrative infrastructure that is
relatively technology agnostic as to the specific technology used by any
specific client.
then the specific technology used by any client then becomes an
individual client decision coupled with possible infrastructure overall
risk management requirements for that specific client when doing
specific operations.
one could imagine a wide-variety of clients ... all accessing the same
identical infrastructure ... possibly concurrently using password,
challenge/response, digital signature with and w/o hardware token
protected private keys.
specific authorization features might only be made available when the
digital signature is believe to have originated from a private key that
has been certified to exist in a hardware token with certified integrity
charactistics (keys generated on the token, private key never leaves the
token, token evaluated at EAL5, etc). Certain fine-grain entitlement
permissions might conceivably even require options like authentication
operation is digitally co-signed by a known terminal ... somewhat the
finread side-subject which also has known, certified integrity
characteristics ... possibly even including fixed physical location.
recent finread related posting:
 Is there any future for smartcards
not such an integrated real-time operation can leverage the same
business, administrative and management infrastructure for not only
deploying fine-grain session-based operations ... but also fine-grain
transaction operations (supporting real-time distribution of client
credential authentication, authorization, and accounting information
across the operational  environment).
in the past, i've periodically commented that when you have been freed
from having to worry about all the extraneous and distracting vagueries
of PKI-related issues ... you can start concentrating on the fundemental
requirements that a large, complex institution might have for
authentication, authorization, and accounting .... including being able
to support multiple different concurrent technologies meeting a broad
range of risk management and integrity requirements.
Given a suffiently robust real-time administrative and management
infrasturcutre ... then specific technology roll-outs should be much
less tramatic since they should be do'able piece meal on a server by
server and client by client basis ... w/o resorting to a whole scale
infrastructure syncronized conversion (while still retaining integrated,
real-time overall administration of the operation).

@_date: 2005-09-13 12:07:59
@_author: Anne & Lynn Wheeler 
@_subject: Is there any future for smartcards? 
part of the issue may involve semantic confusing digital signature and
human signature (possibly because they both contain the word signature)
from 3-factor authentication paradigm
* something you have
* something you know
* something you are
... fundamentally a digital signature verification by public key is
basically a form of "something you have" authentication (aka the private
key contained uniquely in a hardware token).
so, from a parameterized risk management and threat model standpoint ...
the issue is how many ways ... and how probable is the compromise of the
physical object ... such that the digital signature doesn't originate
from a specific hardware token in the possesion of a specific person.
the other stuff ... say related to issues attempting to be address by
some of the finread characteristics
where a digital signature may be used in conjunction with other efforts
and technology to imply a human signature ... which in turn implies that
the person had read, understood, approves, authorizes, and/or agrees
with what is being signed. this goes far beyond the straight-forward
"something you have" authentication that is implied by the verification
of a digital signature with a public key.
it also potentially opens up the dual-use attack ... where the same
technology is used for the original straight-forward authentication
purpose ... and as part of some sort of infrastructure implying read,
understood, approves, authorizes, and/or agrees.
the pki digital certificate work somewhat originally strayed into this
confusing the term *digital signature* and *human signature* (possibly
because they both contain the word *signature*) ... with the original
definition of the *non-repudiation* bit in a digital signature. The
scenario went that if the relying party could find and produce a digital
certificate w/o the "non-repudiation" bit set, then the relying party
could claim that a digital signature applied to some bits were purely
for authentication purposes. However, if the relying party could find
and produce a digital certificate (for the public key) with the
"non-repudiation" bit set, then the relying party claimed that was
sufficient proof that the person had read, understood, agrees,
authorizes, and/or approves the bits that had the digital signature
(in part, because there is nothing in normal PKI standards that provides
proof as to what, if any, digital certificate happened to be attached to
any particular digital signature).
Then came the realization that it was quite absurd that because a
certification authority had included the non-repudiation bit in some
digital certificate at some point way in the past ... that the setting
of that bit had absolute and total control of whether a person had read,
understood, agrees, authorizes, and/or approves some pattern of bits for
every digital signature that might be created in the future. The
absurdity of such an assertion was since lead to the non-repudiation bit
being depreciated.
in any case, the morphing of any digital signature for "something you
have" authentication into anything that could imply human signature goes
well beyond the secure boundary issues.
some past posts on dual-use attack
 dual-use digital signature
 dual-use digital signature
 dual-use digital signature
 dual-use digital signature
 dual-use digital signature
 two-factor authentication
 massive data theft at
MasterCard processor
 massive data theft at
MasterCard processor
 the limits of crypto and
 New Method for Authenticated
Public Key Exchange without Digital Certificates
 New Method for Authenticated
Public Key Exchange without Digital Certificates
 Using smart cards for signing
and authorization in applets
 [Lit.] Buffer overruns
 Public/Private key pair
protection on Windows
 Maximum RAM and ROM for smartcards
 Creating certs for others
(without their private keys)
 Question about authentication
 The Chinese MD5 attack

@_date: 2005-09-13 14:18:00
@_author: Anne & Lynn Wheeler 
@_subject: Clearing sensitive in-memory data in perl 
note that compared to some other languages .... a lot of C-language
buffer overflows can be attributed to C requiring the programmer to keep
track and manage various lengths (where in some number of other
languages, buffer length characteristics are built into basic object
characteristics and operations). i know of at least one production
implemented tcp/ip stack done in pascal ... which had no known buffer
related problems compared to the possibly hundreds of thousands that
have appeared in c-language based implementations.
large collection of past posts on buffer overflow related vulneabilities
part of the issue is that there are hundreds of thousands of
applicantations being written ... with possibly only a couple hundred
mistake-free, careful programmers available world-wide. a possible
solution is to create a time-machine that allows for the limited number
of mistake-free, careful programmers to have several thousand hour work
days (along with the medical support to allow them to never sleep).
there are separate class of vulnerabilities related to dangling buffer
pointers and syncronization problems ... which are common to languages
that place the burden of allocation/deallocation burden on the
programmer (however, that is a distinct vulneability from c-language
placing burden of length management on the programmer ... and the
resulting mistakces).
some languages like apl ... large collection of past apl posts
have abstracted both object length characteristics as well as storage
allocation/deallocation operations.

@_date: 2005-09-14 11:00:29
@_author: Anne & Lynn Wheeler 
@_subject: simple (&secure??) PW-based web login (was Re: Another entry 
by the time all the authentication options are being created ... you
might as well move to radius or kerberos as core authentication
technology ... if nothing else to manage and administer the myriad of
co-existing authentication possibilities.
once you have an effective administrtative infrastructure for managing
different and co-existing authentication technologies ... there is an
opportunity to examine the level of technology required for some of the
password-based technologies vis-a-vis a straight forward certificateless
public key (where public key is registered in lieu of password) and
digital signature verification
so the requirements are somewhat ... resistant to evesdropping on the
interchange and related replay-based attacks; possibility of using the
same password with multiple servers ... w/o cross security domain
compromises; availability of the software to perform the operations.
so if the assuption is that SSL is part of the basic infrastructure ...
that should satisfy whether there is availability of public key software
available at both the client and the server (even tho it may tend to be
entangled with digital certificate processing).
from the client prospect, i would contend that having the client keep
track of server-specific details as to things like login iterations or
other details ... creates client operational management complexity ...
but at least requires some form of container. such a container
technology could possibly be as easily applied to keeping track of
private key.
the meta tag scenario applies equally well to returning a digital
signature as one-time-password ... possibly as well as any of the other
schemes (especially if you have something like radius on the server side
for the administrative management of the variety of co-existing
authentication technologies). Note that some flavor of this is used for
ISP PPP dial-up authentication (and raidus infrastructures) ... where
client may have option of multiple different authentication technologies.
In many ways the administrative management of multiple concurrent,
co-existing authentication technologies ... is at least as complex issue
as the implementation details of any specific technology (especially if
you are considering a large complex infrastructure that is facing
operational environment spanning large number of years and dealing with
a wide variety of different client and server requirements). One of the
advantages of dumping the PKI concept (which is really targeted at first
time interaction with strangers) ... and going with single management
and administrative infrastructure (using a radius-like model) is that a
wide variety of co-existing authentication technologies can be managed
in a single administrtive environment (w/o requiring the cost and effort
duplication of having two or more deployed authentication operations ...
aka the real-time production environment and any redundant and
superfluous duplicate PKI environment).

@_date: 2005-09-14 14:14:13
@_author: Anne & Lynn Wheeler 
@_subject: simple (&secure??) PW-based web login (was Re: Another entry 
there is somewhat an anciallary philosphical issue. most of the current
password-based systems have been oriented towards a static environment
... contributing to a mindset that addresses authentication technology
as a static issue.
The PKI paradigm even goes further with contributing to a somewhat
rigid, stale, static view of authenticaiton technology ... spending an
enormous amount of effort in focusing on the rigid, stale, static nature
of the issued digital certificates.
this can be contrasted with real-time authentication environment
provided by RADIUS like technologies ... not only providing for
integrated overall management and administration ... but also real-time
integrated operation of authentication, authorization, and accounting.
minor confession ... in past life i actually assisted with radius
configuration on real, live livingston boxes for a small startup ...
when radius was still a purely livingston technology.
radius-like technologies provide extremely agile, real-time environment
integrating the management, administration, and operation of multiple,
co-existing authentication technologies ... along with integrated
real-time authorization and accounting.
given that you are freed from the static oriented authentication
technologies (like PKI) and related stale, static mindset ... one could
even imagine radius-like implementations extended to parameterized risk
management; where the infrastructures apply integrity classifications to
different authentication technologies and processes ... and
authorization infrastructures specifying minimal acceptable
authentication integrity levels.
some of this is born out of the credit-card industry where real-time
authorization can be associated with unique credit limit values on an
account-by-account basis ... as well as account specific "open-to-buy"
... aka the difference between the account's outstanding charges and the
account's credit limit (aka allows dynamic co-existance of wide-range of
different credit limits and dynamic risk management authorization
for instance, a parameterized risk management operation in an agile,
real-time, integrated environment might allow for an integrity level
with simple "something you are" digital signature for some permissions
... but other permissions may require that the public key having been
registered with a certified hardware token of minimal specified
integrity charactiristics and furthermore, the authentication operation
has to be co-signed by a finread-like technology certified station.
there is a very loose analogy between using the structuring of
role-based access control for fine grain permissions ... and the
structuring of authentication integrity levels ....  for dynamic
application for permission purposes.
Part of the problem that stale, static PKI oriented infrastructures have
foisted is the focus on the characteristics of the stale, static digital
certificate .... as opposed to being free to concentrate on the
real-time, dynamic operational characteristics of each, individual
authentication event (and not having to by bound by stale, static
infrastructure characteristics).
of course, anytime i mention agile, dynamic operation ... i frequently
digress to also throwing in boyd and ooda-loop references:
and for even further topic drift ... numerous references to having
created dynamic, adaptive resource management as an undergraduate in the

@_date: 2005-09-16 16:05:26
@_author: Anne & Lynn Wheeler 
@_subject: Clearing sensitive in-memory data in perl 
I've frequently observed in the past that some assembler language
environments have also had very pervasive use of explicit lengths
associated with most operations, system functions, and
library routines resulted in very low frequency of buffer overflows ...
some amount of collected past posts on the subject ... including the
30 years later article (when it first came out)
minor connection .... the 30 years later article is about multics
which was done on the 5th floor of 545 tech sq ... and some of
the assembler stuff that i'm familiar with was done on the 4th
floor (slight disclaimer i was on the 4th flr for some amount
of the period)
some of the early stuff done on the 4th floor ... also was adapted to
some number of commercial time-sharing services which had some fairly
stringent integrity requirements

@_date: 2005-09-17 14:24:09
@_author: Anne & Lynn Wheeler 
@_subject: Clearing sensitive in-memory data in perl 
note that various infrastructures ... have made the length field an
integral characteristic of nearly every piece of storage and that
automatic use the length values an integral piece of every operation;
extended from the lowest level interrupt handlers and device drivers ...
up thru the most complex application code. it isn't just a
characteristic of the high level application libraries ... but nearly
every aspect of the operation environment.
these length-based paradigms aren't only limited to programming
languages (other than C) ... but can also be found in infrastructures
that are pure assembler code.
the other way of viewing the string issue is that the length isn't
explicit ... the default c-based length paradigm is implicit based on
the pattern of data in a buffer ... which tends to create length related
vulnerabilities from simple data manipulation operations (you might
generalize this as a dual-use vulnerability). this is further compounded
when there is a field/buffer that is empty and doesn't yet have any data
to establish an implicit data-pattern defined length.
explicitly separating the length attribute from any data pattern
characteristic would make the infrastructure less vulnerable to length
mistakes resulting from simple data manipulation operations. it would
also enable a single, consistant length paradigm for both field/buffers
that contain data patterns and field/buffers that are empty and don't
contain data patterns.

@_date: 2005-09-18 19:14:57
@_author: Anne & Lynn Wheeler 
@_subject: [Clips] Contactless payments and the security challenges 
related ref:
 Payment Tokens
 Payment Tokens
there is an interesting side light involving x.509 identity
certificate and the non-repudiation bit ... in the context of point of
sale terminals for financial transactions.
fundamentally, PKIs, CAs, and digital certificates have a design point
of addressing the opportunity for first time communication between
strangers ... when the relying party has no prior information about the
communicating stranger and/or has no ability to obtain such
information by either online or other mechanisms (the "letters of
credit" model from the sailing ship days).
the fundamental characteristic of digital signatures is "something you
have" authentication ... i.e. the validation of the digital signature
(with a public key) implies that the originator has access and use of
the corresponding private key (the effect can be further enhanced by
binding the private key to a unique hardware token).
the appending of x.509 identity digital certificate to digitally
signed transactions, tends to turns possibly straight-forward, simple
authentication operation unnecessarily into a heavy weight
identification operations,
the other characteristic was the confusing digital signatures with
human signagures (possibly semantic confusion because both terms
confain the word *signature*). in addition to x.509 identify
certificates turning simple authentication operations into
identification operations, supposedly if a certification authority had
included the non-repudiation bit in the issued x.509 identity
certificate ... not only did the operation unncessarily become an
identity operation ... the digital signature then became proof that
the person had read, understand, agrees, approves, and/or authorizes
what had been digitally signed. Eventually there was some realization
that just because some certification authority had turned on the
non-repudiation bit, it could hardly provide proof and some possibly
much later time (after the certification authority had issued the
digital certificate), the person was reading, understanding, agreeing,
authorizing, and/or approving what had been digitally signed.
now an interesting situation comes about with point-of-sale terminals.
the current equivalent to human signature at POS terminals is when the
terminal displays the amount of the transaction and asks the person to
select the yes button ... aka the swiping of the card is an
"authentication" operating ... the equivalent of the human signature
or approval operation is the pressing of the "yes" button in response
to the message (i.e. a specific human operation indicating agreement).
so applying an aads chip card doing x9.59 digital signature at
the digital signature becomes "somthing you have" authentication
... not the agreement indication. the aads chip strawman had
postulated form factor agnostic as well as interface agnostic
from 3-factor authentication
* something you have
* something you know
* something you are
the additional requirement for pin/password (at POS) would make the
operation two-factor authentication ... where the pin/password entry
("something you know") is nominally a countermeasure to a lost/stolen
so it is possible to imagine a POS terminal that delays requesting the
entry of pin/password until the amount of the transaction is displayed
...  and the terminal requests entry of the pin/password as confirming
the transaction.
in this scenario, the result has the interesting aspect of the
"digital signature" representing "something you have" authentication
but the entry of the pin/password not only represents part of
two-factor authentication, but in addition, the entry of the
pin/password also represents a human operation implying agreement (aka
implication of human signature is understanding a message and some
human response to the message)
it is rather difficult to turn "digital signatures" into "human
signatures" ... because "human signatures" will require implication of
human interaction. "digital signatures" is something generated by some
computer process that frequently is totally missing any human effort
(also some of the dual-use attacks). however, the entry of a
pin/password involving a human hitting specific sequence of keys in
response to a message requesting agreement ... can meet standard
implying agreement/response ... especially with terminals that have
certified operational characteristics are involved.
confusing authentication and identification
 the limits of crypto and  Another entry in the internet security hall of shame
recent post referencing dual-use attack
 Is there any future for smartcards

@_date: 2005-09-20 00:11:56
@_author: Anne & Lynn Wheeler 
@_subject: Online fraud 'ahead' of credit-card companies-experts 
Online fraud 'ahead' of credit-card companies-experts
Speaking at an conference here, John Shaughnessy, senior vice president
for fraud prevention at Visa USA and Suzanne Lynch, vice president for
security and risk services at MasterCard International, said that
organized crime rings ....
.. snip ...
The picture they presented of an escalating struggle between commerce
and criminality offered little hope of quick relief for consumers
worried about identity theft or for investors in card-issuing banks
concerned about security's escalating costs.
... snip ...

@_date: 2005-09-20 15:54:41
@_author: Anne & Lynn Wheeler 
@_subject: [Clips] Contactless payments and the security challenges 
couple articles to put switch on RFID/contactless payment cards
that has to be depressed for the card to be active (somewhat cutting
down on some of the covert skimming attacks)
Switching Off Credit Card Fraud
Switching Off May Reduce Contactless Card Fraud

@_date: 2005-09-22 19:18:12
@_author: Anne & Lynn Wheeler 
@_subject: Defending users of unprotected login pages with TrustBar 0.4.9.93 
and the latest phishing
New Phish Deceives With Phony Certificates
A new, advanced form a phishing dubbed "secured phishing" because it
relies on self-signed digital certificates, can easily fool all but the
most cautious consumers, a security firm warned Thursday.
... snip ...

@_date: 2005-09-28 09:01:37
@_author: Anne & Lynn Wheeler 
@_subject: continuity of identity 
note this verges on my theme of confusing authentication and
identificaton. one of my examples is the opening of an off-shore
anonymous bank account and providing some material for use in
authentication ... say tearing a dollar bill in half and leaving
one-half on file ... to be matched with the other half in the future.
registration of public key can provide continuity of authentication ...
that the current entity is the same as the original entity ... and any
issue of identity is orthogonal ... aka the registration of public key
for authentication of continuity is orthogonal to the issue of whether
there is any associated identification information.
this is somewhat one of the holes that x.509 identity digital
certificates dug for themselves ... effectively starting out with the
premise that the most trivial of authentication operations were mandated
to be turned into heavy weight identification operation.
of course it is possibly one of those established nomenclature
convention things ... that the popular convention now has references to
identity and identification so terribly confused with even trivial
authentication operations ... that it may be impossible to unwind the
damage done.

@_date: 2006-04-05 10:37:44
@_author: Anne & Lynn Wheeler 
@_subject: Unforgeable Blinded Credentials 
this is sort of the track of the x9a10 working group activity on x9.59 ... which had been given the requirement to preserve the integrity of the financial infrastructure for ALL retail payments.
the analysis was that the account number had become grossly overloaded. one hand it was mainstay of normal business process required to be widely available and divulged for large number of different business processes.  on the other hand, it was also effectively being used for authentication; aka knowing the account number was frequently sufficient for authenticating the transaction.
the severely conflicting requirement for account number use ... on one hand being widely available and divulged for large number of different business processes ... and on the other hand needing to be kept private and confidential for authentications purposes ... created opportunity for numerous compromises. this also somewhat has led to my periodic observation that the planet could be buried under miles of cryptography (for hiding account numbers) and it still wouldn't be sufficient to prevent account numbers from leaking.
this is further aggravated by the long term findings that the majority of fraud have involved insiders who have legitimate access to the information. it is even further aggravated by account number being static data and therefor vulnerable (as an authentication mechanism) to skimming and replay attacks.
x9.59 called for dynamic data on the actual transaction for authentication (as countermeasure to both replay attacks and mitm attacks). x9.59 also called for account numbers used in x9.59 transactions would not be honored when used in "non-authenticated" transactions (countermeasure to skimming, security breaches, and data the combination of specifications in the x9.59 standard drastically reduced the sensitive nature of account numbers. the crooks could have all the skimming, security breaches and data breaches involving account number sources and it would be insufficient to execute fraudulent a few recent posts mentioning x9.59 drastically reducing sensitive nature of account numbers.
 X.509 and ssh
 Caller ID "spoofing"
 trusted repositories and trusted transactions
 GP4.3 - Growth and Fraud - Case  - Phishing
 Meccano Trojans coming to a desktop near you
and my old long time standby of security proportional to risk ... with regard to the possible large discrepancy involving the value of skimmed account number data to the crooks (in the current infrastructure) vis-a-vis the worth of account number data to retail merchants
(the crooks can possibly afford to mount a massive attack that merchants can't reasonably be expected to afford to defend against)

@_date: 2006-04-08 08:31:45
@_author: Anne & Lynn Wheeler 
@_subject: Creativity and security 
supposedly new?
iPod used to store data in identity theft
from above ..
April 7, 2006 4:55 PM PDT
A 35-year-old identity theft suspect may have taken Apple Computer's mandate, "Think Different," a little too far.
... snip ... above article references:
Beware the 'pod slurping' employee
... from above
Published: February 15, 2006, 10:29 AM PST
A U.S. security expert who devised an application that can fill an iPod with business-critical data in a matter of minutes is urging companies to address the very real threat of data theft.
... snip
and some conjecture about a possible MITM-attack ... using counterfeit card in conjunction with PDA wireless internet connection to a lost/stolen valid card at some remote location.
 FraudWatch - Chip&Pin
 Mecccano Trojans coming to a desktop near you
This is scenario where a card may be authenticated separately from its actual operation. The hypothetical MITM-attack is against a terminal's willingness to agree with the business rules in a valid card used for offline transactions. Since the attack is against the offline transaction business rules in a valid card, it may not even be necessary to obtain a lost/stolen valid card ... it may just be just necessary to obtain any valid card (say thru valid application using false information) ... the MITM counterfeit card uses any valid card for the authentication exchange ... and then proceeds with the rest of the transaction using its own business rules.

@_date: 2006-04-12 10:28:33
@_author: Anne & Lynn Wheeler 
@_subject: Creativity and security 
Creativity and security
Trial starts on swipe-and-go card; A new smartcard could result in shorter queues in the shops
the above has the quote:
"The card never leaves your hand," ... "In fact, it need not even be taken out of the wallet, and there is no chance information from the card can be skimmed, the most common form of card fraud."
... snip ...
while the earlier reference is to a situation where the crook is using their own device for extra swipes, a significant portion of skimming
involve compromised devices that harvest information
as part of a normal transaction. The real issue is whether "static data" is used for authentication and therefor the infrastructure is vulnerable to any kind of skimming/harvesting/evesdropping and replay attacks.
a few recent comments about static data exploits for replay attacks
 FraudWatch - Chip&Pin, a new tenner (USD10)
 FraudWatch - Chip&Pin, a new tenner (USD10)
 Caller ID "spoofing"
 Debit Cards HACKED now
 X.509 and ssh

@_date: 2006-04-26 14:31:23
@_author: Anne & Lynn Wheeler 
@_subject: History and definition of the term 'principal'? 
part of this has been that x.509 has layered certification authorities,
digital certificates and other business processes on top of any direct
interaction between parties. as a result, the focus of x.509 related
descriptions tends to focus on the certification processes and the
acceptance of those certification processes by relying parties.
(along with any digital certificate representation of those
certification processes)
credentials, certificates, licenses, diplomas, letters of
credit/introduction and other mechanisms have served the world for
centuries ... providing information to relying parties, where the
relying parties didn't have the information themselves and/or have
direct mechanisms for obtaining the information.
digital certificates has been electronic analog of those centuries old
constructs for representation of information for use by relying parties
(where the relying parties have no direct access to the information
and/or other mechanisms for obtaining the information).
in my merged security taxonomy and glossary collected from a variety of
    Terms merged from: AFSEC, AJP, CC1, CC2, CC21 (CC site), CIAO, FCv1,
FFIEC, FJC, FTC, IATF V3 (IATF site), IEEE610, ITSEC, Intel, JTC1/SC27
(SC27 site), KeyAll, MSC, NIST 800-30, 800-33, 800-37, 800-53, 800-61,
800-77, 800-83 FIPS140, NASA, NCSC/TG004, NIAP, NSA Intrusion, CNSSI
4009, online security study, RFC1983, RFC2504, RFC2647, RFC2828, TCSEC,
TDI, TNI, vulnerability testing and misc. Updated 20060202 with terms
from 800-77, 800-83
the only definition for principal comes from sc27:
    An entity whose identity can be authenticated. [SC27]
the merged taxonomy and glossaries from X9F (including some x.509
sources), i.e.
    Terms merged from X9F document glossaries: WD15782, X509, X9.8,
X9.24, X9.31, X9.42, X9.45, X9.49, X9.52, X9.62, X9.65, X9.69.  Terms
from ABA/ASC X9 TR1-1999 replace terms from X9F TG-16 glossary
(identified by lower case x9 instead of upper-case X9). Original source
documents include: X3.92, X3.106, x9.1, x9.5, x9.6, x9.8, x9.9, x9.17,
x9.19, x9.23, x9.24, x9.26, x9.28, x9.30, x9.31, x9.41, x9.42, x9.44,
x9.45, x9.49, x9.52, x9.55, x9.57, x9.62, x9.69 x9.74, x9.76, x9.78,
x9.80, x9.82, and TG-17. (990710)
doesn't include a definition for principal.

@_date: 2006-04-28 08:17:46
@_author: Anne & Lynn Wheeler 
@_subject: PGP "master keys" 
the key escrow meetings attempted to differentiate between keys used for authentication and keys used for securing corporate data (I only went to a couple of the meetings). the case of key escrow as part of
securing corporate data was similar to business processes for backing up corporate data, disaster recovery, and no single point of failure. in fact, escrow of authentication keys was equally a violation of business standards as not having escrow of encryption keys.
there was cross-over from backup infrastructure and the transition from all corporate data residing in hardened datacenters to individual desktops ... where the they were finding critical corporate data being managed and maintained w/o adequate backup and recovery capabilities.
the point of key escrow as part of infrastructure securing corporate data ... was that the data belonged to the corporation ... and loss of keys could be equivalent to losing the data ... and as such, was as negligent as not backing up critical corporate data and not having a disaster/recovery plan.
there was some backup related study that claimed half of the corporations that had a disk failure (where the disk was not being backed up) containing critical corporate data ... filed for bankruptcy withing 30 days of the failure. i assumed that "critical" was stuff like account-billable files ... loosing a month worth of customer account billing information could create a real dent on the corporation's cash flow. one incident involved a corporation that lost something like $50m in monthly billings.
it wasn't suppose to be a back door to anything ... anymore than having copies of all corporate files on corporate backup tapes (however, the corporate backup tapes wouldn't be worth a lot if all the data has been secured with encryption ... and the encryption keys are lost).

@_date: 2006-04-28 09:42:51
@_author: Anne & Lynn Wheeler 
@_subject: PGP "master keys" 
note from the corporate side ... is was specifically the escrow of encryption keys for data at rest ... as part of prudent corporate asset protection; it was not escrow of authentication keys nor escrow of encryption keys used for communication.
the internal network was larger than the arpanet/internet from just about the beginning until possibly around summer of 85. at the time of the great change-over to internetworking protocol on 1/1/83, the number of arpanet/internet nodes was approx. 250 (a number that the internal network had passed in the mid-70s, the internal network passed 1000 nodes a little later in 83).
corporate inter-site links had to be encrypted ... which at the time met link encryptors .. there was claims that the internal network had over half of all the link encryptors in the world. there wasn't any corporate escrow issues with link encryptor keys. there were various problems with gov. agencies ... significant problems especially in europe getting gov/ptt authorization for corporate link encryptors (on corporate links, between corporate sites, purely carrying corporate data) especially when the links crossed country boundaries.
issues did start showing up in the mid-90s in the corporate world ... there were a large number of former gov. employees starting to show up in different corporate security-related positions (apparently after being turfed from the gov). their interests appeared to possibly reflect what they may have been doing prior to leaving the gov.

@_date: 2006-04-28 09:54:51
@_author: Anne & Lynn Wheeler 
@_subject: PGP "master keys" 
and real-time reference from today ... on backup tapes ... at off-site location that weren't encrypted (and should have been):
Data storage firm apologizes for loss of railroad data tapes
Information on as many as 17,000 workers at risk

@_date: 2006-04-29 07:23:01
@_author: Anne & Lynn Wheeler 
@_subject: PGP "master keys" 
one of the issues is that corporate/commercial world has had much more orientation towards prevention of wrong doing. govs. have tended to be much more preoccupied with evidence and prosecution of wrong doing. the influx of former gov. employees into the corporate world in the 2nd half of the 90s, tended to shift some of the attention from activities related to prevention to activities related to evidence and prosecution (including evesdropping).
for lots of drift ... one of the features of the work on x9.59 from the was its recognition that insiders had always been a major factor in the majority of financial fraud and security breaches. furthermore that with various financial functions overloaded for both authentication and normal day-to-day operations ... that there was no way to practical way of eliminating all such security breaches with that type of information. ... part of this is my repeated comment on security proportional to risk
the x9.59 approach was to eliminate the function overload so that the same information that was needed for normal day-to-day operation didn't also carry with it any authentication feature/attribute. the result was that data breaches could still occur, but no longer enabled the financial fraud that it once did ... and therefor it didn't really represent a serious security breach ... aka the countermeasure to financial fraud associated with the data breaches was to recognize that it was impossible to totally eliminate them, since the information was required extensively in day-to-day business processes, so to prevent the wrong doing, the authentication feature/attribute was removed from the associated information.

@_date: 2006-08-05 06:04:08
@_author: Anne & Lynn Wheeler 
@_subject: Crypto to defend chip IP: snake oil or good idea? 
so one could claim that the difference is along the lines of
trade secrets vis-a-vis patents &/or copyrights .... at least
for the 20,000 circuit scenario i was talking about
i.e. using authentication to help differentiate "originals"
from "copy chips" (as opposed to hiding, privacy, confidentiality)
and other parts of the thread
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
as an aside, i noticed that a lot of recent spam about copy this and
copy that ... actually claims it to be "replicas" (watches, etc).
it could be difficult to tell the difference from a work-a-like
copy chip ... and an original ... especially if it happens
to be embedded in something.
authentication raises the bar on telling an original vis-a-vis a
counterfeit/copy ... something like the holograms and other brand
stuff they put on various physical products ... or the stuff they put
into money. it doesn't actually try and hide the details of the
original (just making it harder for a counterfeit to pass as an original)
for a little drift, recent post on long ago and far away court case
involving theft of trade secrets
 More Brittle Security
the above also drifted into the subject of security proportional
to risk ... unrelated post
for even more drift ... collected past posts about being involved
in project as an undergraduate that built a clone mainframe control
unit ... and article that was written blaiming us for the resulting
several billion dollar/annum market.
the other analogy is electronic commerce that has attempted
to use privacy/confidentiality to hide transaction details as
countermeasure to fraudulent transactions
compared to x9.59 financial standard using transaction strong
to preserve the integrity of the finanical infrastructure for all
retail transactions (requirement given the x9a10 financial standard
working group for the standard)... w/o needing privacy/confidentiality
(hiding) as countermeasure to fraudulent transactions
and further drift ... about possibility of various kinds of
attacks (replay attacks, mitm-attacks) w/o strong authentication
or where authentication is used for a device w/o having
strong authentication on an actual transaction
 New ISO standard aims to
ensure the security of financial transactions on the Internet
 Naked Payments IV - let's all
go naked
 Naked Payments IV - let's all
go naked
 Naked Payments IV - let's all
go naked
 Naked Payments IV - let's all
go naked
 Naked Payments IV - let's all
go naked
 Naked Payments IV - let's all
go naked
 Naked Payments IV - let's all
go naked
 Naked Payments IV - let's all
go naked
 Naked Payments II

@_date: 2006-08-08 07:22:12
@_author: Anne & Lynn Wheeler 
@_subject: And another cloning tale 
and if you happened to miss this thread on chip&pin cloning
 DDA cards may address the UK
chip&pin woes
there is always the current e-passport news (aka form of static data
skimming and replay attack which at least traces back to magstripe copying)
Researcher warns of security problem in electronic passports
Researchers: E-passports pose security risk
Researchers: E-passports pose security risk
Researchers: E-passports pose security risk
Researcher: E-passports easy to clone
Researchers: E-passports pose security risk
Researcher warns of security problem in electronic passports
Expert Warns on E-Passport Security
Expert Issues Warning About E-Passports
German hackers clone RFID e-passports
Expert: E-passports vulnerable
Expert Issues Warning About E-Passports
Hackers crack new biometric passports
Expert warns on e-passport security
RFID e-passports hacking and terrorism risk says experts
Electronic passports vulnerable, expert says
RFID passports vulnerable to hackers, security expert says
German Security Consultant Clones E-Passports
E Passports Susceptible To Cloning
Leader: Of course passport security is too weak
Researcher warns of security problem in electronic passports
Expert warns on e-passport security
German hackers clone RFID e-passports
German Expert: RFID Chips In E-Passports Can Be Cloned
E-passports.. a neverending story!
Expert issues warning about e-passports

@_date: 2006-08-16 13:45:46
@_author: Anne & Lynn Wheeler 
@_subject: Hamiltonian path as protection against DOS. 
it can be considered from the standpoint of a lot of SSL is transaction you start with reliable TCP session support ... which has a minimum of 7-packet exchange. then you encapsulate all the HTTPS hand-shaking ... which eventually possibly reduces to doing a transaction packet exchange (as opposed to really requiring full session semantics).
in the late 80s, there was work on reliable XTP, a transaction oriented protocol that supported reliable internet with a minimum of 3-packet exchange (disclaimer, my wife and I were on the XTP technical advisory so a lot of the SSL stuff around ssl server certificates is validating that the server you think you are talking to is actually the server you are talking to .... by checking the domain name from the URL that you supposedly typed in against the domain name in the ssl server certificate. a big vulnerability was created when a lot of the merchant servers ... that were the original prime target for ssl server certificates ... backed way from using SSL for the whole web experience and reduced it to just the payment transaction. the problem then was that the supposedly typed in URL came from a button provided by the server ... and not actually typed in by the client. the ssl server process then became checking the domain name in the URL provided by the server against the domain name in the certificate provided by the server (totally subverting original security assumptions). lots of past collected posts mentioning ssl server certificate infrastructure
So the next part was that somebody applies for a SSL server certificate .... which basically involves the certification authority checking the applicant provided information against what is on file with the domain name infrastructure. there was some integrity issues with this information being hijacked/changed ... so the certification authority industry was backing a proposal that domain name owners register a public key (with the domain name infrastructure) along with the other information. Then all future communication would be digitally signed
(as countermeasure to various hijacking vulnerabilities).
the issue then is that certification authorities can also request that ssl server certificate applications also be digitally signed. the certification authorities, then can validate the digital signature with the onfile domain name infrastructure (turning a time-consuming, error-prone, and expensive identification process into a much simpler, less-expensive and efficient authentication process)
note that the existing infrastructure has the trust root with the information on file with the domain name infrastructure (that has to be cross-checked for identification purposes). the change to registering a public key retains the domain name infrastructure as the trust root (but changing from an expensive identification operation to a much simpler
authentication operation).
so a real SSL simplification, when the client contacts the domain name infrastructure to do the domain name to ip-address translation, the domain name infrastructure can piggy-back the public key and any necessary ssl options on the ip-address reply.
the client then composes a XTP transaction (has minimum 3-packet exchange for reliable operation) that has an "SSL" packet structure. the client generates a random transaction key, encrypts the communication with the random generated key and encrypts the random key with the server's public key ... and sends it off the encrypted random key and the encrypted communication.
for purely transaction operation, there is minimum (XTP) 3-packet exchange between client and server. however, if more data is involved, then as many packets as necessary are transmitted. I've suggested this design numerous times in the past.
as an aside, i've pointed out before that in the mid-90s that as webserver activity was increasing ... a lot of platforms experienced severe throughput degradation with HTTP transaction protocol use of TCP. Most platforms had a highly inefficient session close implementation around checking of the FINWAIT list ... the assumption as that most session activity had relatively infrequent session open/close activity. The HTTP transaction activity violated those TCP activity assumptions ... and for a period of time you found platforms spending over 95percent of their processor utilization dealing with the FINWAIT list.

@_date: 2006-08-17 16:28:33
@_author: Anne & Lynn Wheeler 
@_subject: Hamiltonian path as protection against DOS. 
Hamiltonian path as protection against DOS
so much of postings at
talks about attempting to standardize xtp as HSP (high-speed protocol) in ansi x3s3.3 (and iso chartered organization) ... which was under mandate that no standardization work could be done on networking protocol that was in violation of the OSI model. turns out xtp/hsp violated OSI model in at least three different ways.
xtp implementation was an adjunct to the tcp/ip (typically kernel) protocol stack.
I've often commented that both SSL and VPN were successful because they added security layer w/o requiring changes to the (kernel) tcp/ip protocol stack.
A person that we had worked with quite a bit introduced something (that since become to be called VPN) in gateway working group at the '94 san jose IETF meeting. my view was that it caused quite a bit of consternation in the ipsec crowd ... which were working on implementation that had hits to the underlying tcp/ip stack. VPN got a lot a lot of immediate uptake because it added security w/o requiring hits to the protocol stack in the end-nodes. The ipsec crowd somewhat reconciled VPN by starting to call it lightweight ipsec ... and some number of others then started called (regular) ipsec, heavyweight ipsec.
original (lightweight ipsec) vpn resulted in some peculiarities .... being a countermeasure to internet anarchy by being a boundary router between corporate intranets tunneled thru the internet ... w/o requiring changes to the end-points. part of the issue was that some of the router vendors had sufficient extra processing capacity to do the necessary vpn crypto and some didn't. so two months after the san jose ietf meeting ... you saw some router vendors announcing VPN "products" that were actually just add-on of traditional hardware link encryptor boxes.
so i've frequently claimed that ssl got market traction in much the same way that vpn got market traction ... by providing a solution that avoided hits to the (kernel) tcp/ip protocol stacks (modulo some really emergency server fixes at some high-end websites to handle the finwait list handling problem).
requiring coordinated (most frequently kernel) tcp/ip protocol stack upgrades for all (or majority of the) machines in the world, is a uptake inhibitor. ssl wasn't necessarily the optimal networking solution ... but it did have the minimum impact on existing deployed infrastructure.
in any case, some of the xtp features are starting to appear in some of the real-time streaming extensions ... like one of my favorites ... rate-based pacing (which i was forced to implement in high-speed backbones in the mid-80s)
many of the online xtp resources have since gone 404 ... however there still are a few around
HTTP1.1 attempted to amortize multiple HTTP interactions across a single tcp session (attempting to mitigate the overhead of reliable session protocol for something that was frequently very transaction oriented). again w/o requiring hits to the underlying protocol stack.

@_date: 2006-12-23 13:37:30
@_author: Anne & Lynn Wheeler 
@_subject: Security Implications of Using the Data Encryption Standard (DES) 
from rfc-editor announcement today
4772 I
    Security Implications of Using the Data Encryption Standard (DES), Kelly S., 2006/12/22 (28pp) (.txt=68524) (was draft-kelly-saag-des-implications-06.txt)
The Data Encryption Standard (DES) is susceptible to brute-force attacks, which are well within the reach of a modestly financed adversary.  As a result, DES has been deprecated, and replaced by the
Advanced Encryption Standard (AES).  Nonetheless, many applications continue to rely on DES for security, and designers and implementers continue to support it in new applications.  While this is not always inappropriate, it frequently is.  This note discusses DES security implications in detail, so that designers and implementers have all the information they need to make judicious decisions regarding its use.
... snip ...
rfc 4772 summary
from and in the rfc summery, clicking on the ".txt=" field retrieves the actual RFC.
note that there have been (at least) two countermeasures to DES brute-force attacks ...  one is 3DES ... and the other ... mandated for some ATM networks, has been DUKPT. while DUKPT doesn't change the difficulty of brute-force attack on single key ... it creates a derived unique key per transaction and bounds the life-time use of that key to relatively small window (typically significantly less than what even existing brute-force attacks would take). The attractiveness of doing such a brute-force attack is further limited because the typical transaction value is much less than the cost of typical brute-force attack.
... and a little extra in the same announcement:
4732 I
    Internet Denial-of-Service Considerations, Handley M., IAB, Rescorla E., 2006/12/22 (38pp) (.txt=91844) (Refs 1058, 1075, 1112, 2349, 2385, 2439, 2827, 2918, 3261, 3411, 3550, 3618, 3682, 3768, 4251, 4271, 4346, 4566, 4601) (was draft-iab-dos-05.txt)
This document provides an overview of possible avenues for denial-of-service (DoS) attack on Internet systems.  The aim is to encourage protocol designers and network engineers towards designs
that are more robust.  We discuss partial solutions that reduce the effectiveness of attacks, and how some solutions might inadvertently open up alternative vulnerabilities.
... snip ...
rfc 4732 summary

@_date: 2006-02-04 11:42:06
@_author: Anne & Lynn Wheeler 
@_subject: serious threat models 
> All phone switches, thanks to the US government's CALEA rules, are
the off-site terminal program for accessing systems online, reading
email, etc, while on the road ... early 80s ... a vulnerability analysis
was done and one of the biggest identified threats was hotel PBXs
(frequently the room was unlocked and anybody could walk in). as a
result there was work done on custom encrypting (2400) modem. basically
did session key exchange on connection, so that all transmission was
i was amazed in the 90s with the growing use of laptops and online
access (traveling road warriors)  and the number of people that seemed
oblivious to the security issues. insecure practices that was forboten
from 1980 (although i had online access at home for ten years
prior to the encrypting modems, starting march 1970).

@_date: 2006-01-11 13:09:38
@_author: Anne & Lynn Wheeler 
@_subject: long-term GPG signing key 
there is a somewhat separate issue having to do with security
proportional to risk. minor old posting:
the security acronym  PAIN
P ... privacy (or sometimes CAIN and conficentiality)
A ... authentication
I ... integrity
N ... non-repudiation
part of the problem is that sometimes confusion between digital
signatures and human signatures (implying read, understood, agrees,
approves, and/or authorizes).
the technology is asymmetric keys .... involving a pair of keys, what
one key encodes, the other key decodes (differentiates from symmetric
key encryption where the same key is used for encryption and decryption).
there is a business process commonly referred to as public key where one
key of a asymmetric key pair is identified as public and made available.
the other key is identified as private, kept confidential and never
there is a business process called digital signatures where a hash of
some message or document is computed and then encoded. the
message/document is sent off with the appended digital signature. the
recipient recomputes the hash of the message/document and decodes the
digital signature with the corresponding public key. if the two hashes
compare, then the recipient (or relying party) can assume:
1) the message/document hasn't changed since transmission
2) the message/document has been authenticated as originating from the
entity associated with the public key.
the amount of risk is associated with the risk of attack on the
corresponding message/document.
say the digital signature operation is used for authenticating x9.59
that happen to be credit card transactions where the account owner has a
credit limit of $1000, all transactions are online against the account,
the account public key can be deactivated when there appears to be fraud
and to the consumer the frauulent transactions can be reversed (leaving
the consumer with a maximum $50 exposure).
the existing infrastructure has no real authentication operation except
for attempting to maintain the account number as a shared secret (which
implies that the account number ... rather than any public key  ... has
to be deactivated & replaced when there has been compromise):
some postings on account number skimming/havesting
some postings on fraud & vulnerabilities
compared to some of the other payment card operations that specified
public key authentication ... x9.59 allowed for
1) digital signature authenticated transactions
2) account number used in authenticated transactions could not be
skimmed and used in non-authenticated transactions (which some of the
other specifications allowed) ... basically countermeasure to form of
replay attacks and countermeasure for having to treat account number as
the basic issue in both (digital signature) signing keys and encryption
keys is what is the risk from a compromise and based on that risk you
can determine the level security required.
another consideration is the overall infrastructures. for many of the
online e-commerce operations ... an ECC 163-bit signing key probably has
a lot higher security strength than the rest of the infrastructure used
to protect the signing key and/or the environment where the digital
signature is applied. from an attackers standpoint that means that it is
probably cheaper/easier to attack the infrastructure to capture the
signing key ... than to try a brute-force attack on the signing key (and
all of these other attacks are applicable regardless of the strength of
the signing key). there may also be attacks on other parts of the
infrastructure ... getting the financial institution to register a new
public key (belonging to the attacker) or getting a certification
authority to issue a new certificate with the attacker's public key in
the name of the victim. some of these other operations may be currently
weak because the claim is that they aren't currently the weakest link in
overall infrastructure.
there may be other trade-offs. it is possible to get reasonably priced
14443 contactless tokens that can do ecc 163-bit digital signing in
subsecond time that may be desirable in various POS or transit turnstyle
operations. going to larger key sizes may exceed both the power
requirement and the elapsed time requirement (in contact token operatin
you can someimes trade-off peak power draw against onger elapsed time).
The case can be made in some scenarios ... that the longest possible
keylength be chosen if the power and elapsed time requirements aren't a
major factor. However, there can be environments where power and elapsed
time requirements may justify choosing a shorter keylength (within the
context of the overall environment)
one of the things that payment card infrastructures have the ability to
do is a real time risk evaluation on a per transaction basis and pass
judgement on a wide variety of factors which might include ... key
length, whether there is a certifified token protecting the signing key
and what is the evaluated integrity of that token, what kind of terminal
and merchant is used for the digital signing environment, the physical
location of the signing, past consumer transaction history, past
terminal transaction history, etc. one might imagine financial
institution having different minimum token and key length requirements
for different kinds of accounts and/or different kinds of transactions
(based on factors like overall risk and the relative security strength
in which such tokens and signing keys operate).
you might some authorities setting the requirements don't understand the
overall risk and infrastructure issues ... they can always go for the
maximum available for everything ... even if some of the specified
requirements don't make any sense in a particular overall
infrastructurt. the other may be that the infrastructure has no means of
differentiating and authorizing at different levels of risk ... so that
the requirements have to mandate the maximum strength for all
components, always assuming the worst case risk.
there may be a lot higher risk with a (digital signature) singing public
key gets confused with human signatures ... which then may carry with it
the implicattion of a human read, understood, agrees, approves, and/or
autherirzes the contents of what is signed, the risk exposure might also
be greater is if the overall infrastructure is an offline environment
that is totally dependent on digital certificates and PKI operation as
opposed to a real-time, online environment that can take into account a
lot larger numgber of factors (including aggregation of past transactions).

@_date: 2006-01-14 12:30:25
@_author: Anne & Lynn Wheeler 
@_subject: long-term GPG signing key 
as in previous post ... i assert that fundamental digital signature
verification is an authentication operation
 long-term GPG signing keys
and doesn't (by itself) carry with it characteristics of human
signature, read, understood, approves, agrees, and/or authorizes.
the PKI & CA hiearchical infrastructures does tend to add those
attributes to digital signature operations ... creating an equiivalence
between certification digital signatures (and the private keys that
produce such digital signatures) and the validity of the information
being certified.
if you are starting to create a class of private keys that start to
carry the attribute of whether something is true or not (i.e. the
information being certified) ... then there can start to become some
confusion between the difference between the private key as an
authentication mechanism and the use of the private key as whether
something is true or not.
I would assert that authentication private keys can be treated like a
much better password technology ... not having various of the
shared-secret vulnerabilities and other shortcomings.
it is when you start equating private keys with certification and truth
characteristics that you move into a completely different risk and
threat domain.
the other foray into embellishing private keys and digital signatures
with human signature type characteristics was the non-repudiation
activity. however, it is now commoningly accepted that to embellish
digital signatures with non-repudiation attributes requires a whole lot
of additional business processes ... not the simple operation of
generating an authentication digital signature.
the whole scenario of digital signing of public keys ... is a matter of
the entity performing the digital signing doing an authentication
operation ... but that the entity is certifying the truth of some value
... typically related to the public key. that is a whole business
process infrastructure that has to be layered on top of digital
signatures (in much the same way to actually achieve non-repudiation a
whole business process infrastructure has to be created that is built
above any authentication digital signature).
the other characteristics is that stale, static certification ... paper
or digitally signed electronic bits ... are characteristic of the
offline age ... where an entity could present the certificate
representing the truth of some information; as opposed to the relying
party having their own access to the truth of the same information. in
the transition to an online world, it is becoming less & less coming
that relying parties won't have access to the truth of some piece of
information (making certificates and credentials less and less
meaningful). the corollary is that digitally signed certificates and
private keys embellished with certification and truth characteristics
become less and less meaningful.

@_date: 2006-01-14 15:17:05
@_author: Anne & Lynn Wheeler 
@_subject: long-term GPG signing key 
but as in some of the PKI forays into non-repudiation and human
signatures ... there was no way for a relying party to determine the
difference ... and in the previous thread of digital signature dual-use
vulnerability, this can open up fraud.
at one point, some were assuming if there was a digital certificate with
the non-repudiation flag set, then the digital signature indicated human
signature (read, understood, agrees, approves, and/or authorizes).
however, nothing in various PKI protocols providing for proving which
digital certificate was actually appended to a particular digital
signature (appending a non-repudiation digital certificate might imply
the creation of some obligation associated with a digital signature used
as a human signature; however there was no protocol provisions for
establishing which form of digital signature was actually intended
and/or which digital certificate was actually appended to any particular
the dual-use vulnerability has an environment where servers nominally
transmit random data for signing (one of the possible countermeasures
for replay attack) and the person generates a digital signature on the
random data w/o having looked at the data (assuming purely
authentication operation). the other party has actually substituted some
sort of valid text in place of the valid data and then asserts that the
person has performed the digital signature implying a human signature
(read, understood, agrees, approves, and/or authorizes) as opposed to
implying pure authentication operation.
the crook may attempt to further substantiate the fraudulent claim by
producing a digital certificate (for the corresponding public key) with
the non-repudiation bit set (and PKI protocols lack provisions for
differentiating which, of possible several, digital certificates might
actually have been attached).
the possible dual-use for digital signatures then may lead to enormous
ambiguity since the basic technology only provides for authentication
... and that w/o significant additional business processes it is
difficult to differentiate digital signatures used for purely
authentication purposes and the grossly embellished purposes associated
with human signatures.
any embellishing of digital signatures for human signature purposes, in
turn creates significant additional risk than straight-forward
a basic issue isn't what you intended when you caused a digital
signature to be created ... but what can any relying-party reasonably
expect that you intended ... and what can the relying-party reasonably
rely on.
then if there is any possible ambiguity as to what you may have intended
when a digital signature was created, can an attacker use the existence
of such ambiguity to perpetrate fraud (aka dual-use vulnerability).

@_date: 2006-01-24 21:53:09
@_author: Anne & Lynn Wheeler 
@_subject: Kama Sutra Spoofs Digital Certificates 
Kama Sutra Spoofs Digital Certificates
The Kama Sutra worm can fool WIndows into accepting a malicious ActiveX
control by spoofing a digital signature, a security company said Tuesday.
.. snip ..

@_date: 2006-01-26 13:56:40
@_author: Anne & Lynn Wheeler 
@_subject: A glimpse of SIGINT 20 years ago... 
recent posting and glimpse of public key crypto 20 years ago

@_date: 2006-01-27 14:11:27
@_author: Anne & Lynn Wheeler 
@_subject: thoughts on one time pads 
is there any more reason to destroy a daily key after it as been used
than before it has been used?
one of the attacks on the stored-value gift cards has been to skim the
cards in the racks (before they've been activated) ... and check back
later to see which cards are gone.
i was standing at grocery store checkout last week ... apparently it was
the store manager ... one of the other employees came up with a gift
card that somebody had bought before xmas and gave as a present. they
had come back complaining that there was no money credited to the
account. it could have simply been an computer foul-up ... and then
again, it could have been somebody had skimmed the card, waited and then
drained the account.

@_date: 2006-01-28 15:29:22
@_author: Anne & Lynn Wheeler 
@_subject: thoughts on one time pads 
if you have seen many of the gift cards in racks at grocery stores ...
they can be skimmed w/o any tampering needed (many with no packaging at
all). it might be better that they were shipped in some sort of
packaging that would require tampering in order to skim.
i think that the conventional wisdom was that the cards were (nearly)
worthless until activated (and so why would anybody bother with a
worthless card).

@_date: 2006-01-28 15:50:16
@_author: Anne & Lynn Wheeler 
@_subject: thoughts on one time pads 
periodically there was some discussion about institutional-centric
tokens vis-a-vis person-centric tokens ... in one case specifically with
respect to being able to replace magstripe payment cards with tokens.
in the person-centric token scenario, the person can choose to have a
single token that they could use for all authentication purposes,
including all accounts (or choose how many tokens they want and which
purposes each token is used for).
at one point, there were counter arguments that a single card per
account (the current mechanism) was much preferred because of the
lost/stolen card problem. the problem is that the prevailing threat
model for lost/stolen cards is the purse or wallet containing all cards
(as opposed to individual cards).
the person-centric model at least would allow a person to replace all
cards subject to common threat model with a single token.
a major issue with cdrom one-time pads would be somebody skimming the
whole cdrom.
destroying keys as they are being used would appear to only be a
countermeasure to theft of the cdrom (in which case it is apparent that
unused pads are compromised and should be eliminated). however, skimming
the cdrom might not leave any trace that unused pads have been
compromised ... which turned out to be the issue in the gift card
skimming compromise.

@_date: 2006-01-30 08:53:29
@_author: Anne & Lynn Wheeler 
@_subject: Face and fingerprints swiped in Dutch biometric passport crack (another 
Face and fingerprints swiped in Dutch biometric passport crack
The crack is attributed to Delft smartcard security specialist Riscure,
which explains that an attack can be executed from around 10 metres and
the security broken, revealing date of birth, facial image and
fingerprint, in around two hours.
.. snip ..

@_date: 2006-01-31 09:46:02
@_author: Anne & Lynn Wheeler 
@_subject: thoughts on one time pads 
if you have a scores or hundreds of one-time pads (or any other static
secrets) on a cd .... and the vulnerability is skimming ... then if the
already used pads are destroyed as countermeasure to skimming ... the
unused pads that are also on the same cd are also vulnerable to the same
skimming. say the cd was skimmed before any pads were used ... then
there hasn't yet been any destroyed pads. supposedly if you provide
protection sufficient for the unused pads ... then that should be
protection for the used pads also (although there always is the school
of thot that more security is always better).
destroying just the one time pads on a cd is countermeasure to theft ...
since the theft of the cd hopefully prevents the unused pads from being
used (at least by you), there potentially is vulnerability that the
thief might be able to use the unused pads in some sort of attack.
the issue is that having both used and unused pads on the same CD
creates a potential common vulnerability of everything on the same CD
(which are in different states). once all pads have been used ... then
the whole CD represents a common vulnerability state ... and the whole
CD can either be destroyed.

@_date: 2006-01-31 10:20:41
@_author: Anne & Lynn Wheeler 
@_subject: thoughts on one time pads 
============================== START ==============================
an open question is whether preventing anybody from accessing the cd
for skimming is also sufficient for preventing anybody from accessing
the cd for theft. this has some analogy to tamper-evident vis-a-vis
tamper-proof. obviously theft leaves more tell tail trails (aka
tamper-evident). then does any countermeasures for skimming
(tamper-proof) have to be more stringent than countermeausures for
theft (tamper-evident). destroying the used keys is countermeausre for
all kinds of access of the used keys. however destroying used keys still
leaves vulnerability of skimming the unused keys (on the same cd). if
the countermeasures for skimming the unused keys (tamper-proof) is
sufficiently high ... then that may also be adequate for all kinds of
access to the used keys on the same cd.
but as mentioned ... there are also the people of the school of thot
that more security is always better.

@_date: 2006-07-03 10:41:05
@_author: Anne & Lynn Wheeler 
@_subject: Use of TPM chip for RNG? 
One of the issues for a long time for that class of chips is whether on-chip key-gen and/or supported DSA (and/or ECDSA) were in use ... processes where reasonable good RNG are integral to the operation.
at one point there was tests for a collection of chips in that class that perform 65k power-cycle/RNG operations and found that something like 30 percent of the numbers were repeated.
however, at least some of the TPM chips have RNGs that have some level of certification (although you might have to do some investigation to find out what specific chip is being used for TPM).

@_date: 2006-07-04 10:53:11
@_author: Anne & Lynn Wheeler 
@_subject: Use of TPM chip for RNG? 
and even this ... having to resort to the wayback machine
includes mention of "yes card" attack (end of last paragraph). however, the "yes card" attack is really an attack on the terminals (and the infrastructure implementation) ... not on cards. a few posts discussing "yes card"
 UK Detects Chip-AND-Pin Security Flaw
 Naked Payments IV

@_date: 2006-07-05 12:26:20
@_author: Anne & Lynn Wheeler 
@_subject: Use of TPM chip for RNG? 
i.e. you have to actually understand what is being tested; fips, common criteria, etc. there was a presentation a couple years ago on common criteria certification for the same EAL4 level ... supposedly something like 64 certifications had been done to the same protection profile ... but in the fine print, something like sixty (of the 64) evaluations had some sort of (unspecified) deviations ... so you didn't even know that two "things" evaluated to the same level with supposedly the same protection profile ... were in any way comparable (assuming you actually have access to protection profiles that being used for the evaluations).
i believe some of the earlier mention chips
 Use of TPM chip for RNG?
had been FIPS140 evaluated ... even tho that the 64k power on/off tests followed by RNG were found to have something like 30percent of the values repeat of some previous generated value.
we started seriously looking at aads chip strawman
around '98 ... in part, support x9.59 transactions ... and mandated both on-chip keygen as well as EC/DSA ... both operations requiring fairly high integrity RNG. However, at the time, I somewhat facetiously claimed that we were going to take a $500 milspec part, cost reduce it by better than two orders of magnitude and at the same time improving its security/integrity. In any case, significantly higher RNG assurance was requiren that what was normally found in most chips.
I made somewhat the same claim in an assurance panel at spring 2001 IDF in the TPM track ... somewhat chiding the TPM people in the audience.
Another aspect of evaluation certification was that a lot of chips were evaluated straight out of the fab ... based on the characteristic of the chip at that moment. after that the appications and crypto were loaded onto the chip (so even for chips that might have some RNG capability, since the applications that might expose any RNG characteristics weren't yet loaded ... RNG wasn't part of the chip evaluation).
What we ran into with aads chip strawman ... was that key-gen and ec/dsa was built into the manufactored chip as it came from the fab. As a result key-gen and ec/dsa became part of the chip evaluation ... and formal definition of same, limited the evaluation level. this was even tho that other uses of very similar chips were able to claim much higher certification levels (since they were able to certify prior to loading various crypto and RNG related applications ... aka there were significant differences in the protection profiles that the certifications were based on).

@_date: 2006-07-11 11:38:34
@_author: Anne & Lynn Wheeler 
@_subject: Phishers Defeat 2-Factor Auth 
happen to mention more than a year ago ... that it would be subject to mitm-attacks ... recent comment on the subject
 Threatwatch - 2-factor tokens attacked by phishers.
in thread in this mailing list more than year ago
 Citibank discloses private information to improve security
 Citibank discloses private information to improve security
 Citibank discloses private information to improve security
 Citibank discloses private information to improve security
 Citibank discloses private information to improve security
... and so on

@_date: 2006-07-11 16:45:27
@_author: Anne & Lynn Wheeler 
@_subject: Interesting bit of a quote 
my slightly different perspective is that audits in the past have somewhat been looking for inconsistencies from independent sources. this worked in the days of paper books from multiple different corporate sources. my claim with the current reliance on IT technology ... that the audited information can be all generated from a single IT source ... invalidating any assumptions about audits being able to look for inconsistencies from independent sources. A reasonable intelligent hacker could make sure that all the information was consistent.
a counter example is the IRS where individual reported income is correlated with other sources of reported financial information. however, i don't know how that could possibly work in the current environment where the corporation being audited is responsible for paying the auditors (cross checking information across multiple independent sources)
some past posts on the subject

@_date: 2006-07-11 20:18:39
@_author: Anne & Lynn Wheeler 
@_subject: Interesting bit of a quote 
but this is the security issue dating back to before the 80s ... when they decided they could no longer guarantee single point of security ... in part because of insider threats ... they added multiple independent sources as a countermeasure. the crooks responded with collusion ... so you started to see countermeasures to collusion appearing in the early 80s.
the advent of the internet, sort of refocused attention to outsider attacks ... even tho the statistics continue to hold that the major source of fraud is still insiders ... including thru the whole internet era. the possibility of outsiders may have helped insiders obfuscate true source of many insider vulnerabilities.
the issue with auditing to prove no possible vulnerability for a single point ... leading to the extremes of having to prove a negative ... can possibly be interpreted within the context of attempting to preserve the current audit paradigm.
independent operation/sources/entities have been used for a variety of different purposes. however, my claim has been then auditing has been used to look for inconsistencies. this has worked better in situations where there was independent physical books from independent sources (even in the same corporation).
As IT technology has evolved ... my assertion is a complete set of (consistent) corporate books can be generated from a single IT source/operation. The IRS example is having multiple independent sources of the same information (so that you can have independent sources to check for inconsistencies).
The fusion scenarios tend to be having multiple independent sources of at least some different data ... so the aggregation is more than the individual parts (as opposed to the same data to corroborate).
 Interesting bit of a quote
 Sarbanes-Oxley
 Sarbanes-Oxley

@_date: 2006-07-12 13:08:11
@_author: Anne & Lynn Wheeler 
@_subject: Interesting bit of a quote 
note that a lot of the data breaches and financial fraud have involved things with payment card transactions ... where details of previous transactions is sufficient for crook to perform fraudulent transactions (and as a result one of the reasons that there is various concern of data breaches involving files containing payment card data).
also a lot of the identity theft incidents involve "account fraud", i.e. being able to perform a fraudulent transaction against an existing account with the use of minimal amount of harvested information
there has been some attempt by the FTC and other organizations to differentiate account fraud from other forms of identity theft.
however, the information in the transactions is also required in dozens of business processes. this somewhat led to my old post on security proportional to risk
and my frequent observation that the planet could be buried under miles of crypto and still not be able to stop the information leakage .... i.e. transaction details having diametrically opposed requirements ... openly available for all sorts of business processes and never divulged because it can lead to fraudulent transactions.
in the mid-90s, the x9a10 working group had been given the requirement to preserve the integrity of the financial infrastructure for all retail payments. the result was x9.59 financial industry retail payment standard
one of the features of x9.59 standard was that it eliminated the leakage of transaction information as a financial fraud vulnerability (i.e. a crook could not perform a fraudulent transaction just from information from previous transaction or skimming).
as a result the integrity of the financial infrastructure and x9.59 transactions are preseved for both transactions "in-flight" (say over the internet) as well as transactions "at-rest" (in databases and transaction logs), w/o having to resort to "hiding" the transactions with technology like cryptography.
a thread/discussions about "naked transactions" and their vulnerabilities (i.e. unarmored, non-x9.59 transactions):
 Naked Payments IV - let's all go naked
 Microsoft - will they bungle the security game?
 Naked Payments IV - let's all go naked
 Naked Payments IV - let's all go naked
 DDA cards may address the UK Chip&Pin woes
 DDA cards may address the UK Chip&Pin woes
series of blogs on "naked" payment (transaction) issue:
misc. past posts mentioning "at rest" and "in flight" transaction  does CA need the proof of acceptance of key binding ?
 Unix hard links
 PKI Implementation
 PKI / CA -- Public Key & Private Key
 Security and e-commerce
 Symmetric-Key Credit Card Protocol on Web Site
 So how does it work... (public/private key)
 Cirtificate Authorities 'CAs', how curruptable are they to
 Public key encryption
 SSL questions
 public key confusion
 Questioning risks of using the same key for authentication and encryption
 Computer-oriented license plates
 vm
 The future of the Mainframe
 Security via hardware?
 Brit banks introduce delays on interbank xfers due to phishing boom
 IBM's mini computers--lack thereof
 RSA SecurID product
 Hey! Keep Your Hands Out Of My Abstraction Layer!

@_date: 2006-07-13 11:23:52
@_author: Anne & Lynn Wheeler 
@_subject: Interesting bit of a quote 
being slightly perverse ... there is the analogy with the new england net. at one point somebody went to the trouble to get nine(?) 56kbit circuits routed out of the new england area on nine distinct physical trunks (diverse routing, telco provisioning). however, over a period of years, nobody appeared to pay attention as the unique circuits were consolidated to fewer and fewer physical trunks. one day, someplace in conn., the new england net fell victim a backhoe denial of service attack (and the new england net was partitioned from the rest of the world for a couple of days).
so one might conjecture that the sox approach to the opportunity is to retrofit the complete length of the single physical trunk with a bunker, built to bank vault specifications ... as a countermeasure to the backhoe denial of service attack.
possibly the only "new" real countermeasure in sox is the part about informants ...
recently i was told that the typical sox bill for a small to medium size $25m corporation runs $800k.
misc. past sox references:
 Sarbanes-Oxley
 Sarbanes-Oxley
 Interesting bit of a quote
 Interesting bit of a quote

@_date: 2006-07-15 09:15:21
@_author: Anne & Lynn Wheeler 
@_subject: Interesting bit of a quote 
a lot of that has to do with whether you have an original and/or whether an original has been modified.
my view of audits for sox type stuff is whether the original is correct. that is where multiple independent sources of original information came in for purposes of cross checking   (and possibility of any inconsistency is indication of something amiss) ... and where subsequently you have to start worrying about countermeasure to collusion.
however, if you have collapsed the originals to single source, you loose the ability to cross-check multiple independent originals for validity of the information. so you ask for a lot more detailed information in the originals ... hoping the level of detail is harder to make consistent (since you may have some sense that you have lost the capability of cross checking multiple independent sources for inconsistency). the counterargument is that with IT technology ... that any level of detail can be programmed to be consistent (if you are going to create incorrect information in an original ... you could make it incorrectly consistent to any level of detail).
So now you create significant threats and penalties for anybody (in charge) allowing incorrect information to appear in an audit (since you somehow realize that that with only a single source, it isn't likely that an audit is going to turn up inconsistent information as an indication that something is incorrect).
So now you are potentially in a situation that audits are no longer an effective countermeasure to serious inconsistent or incorrect information ... its the threats and the penalties that are the countermeasure to serious inconsistent or incorrect information.
At the same time there is some sense if audits previously had turned up inconsistency (from multiple independent sources) ... then possibly just increasing the level of audit detail might still provide some benefit.

@_date: 2006-07-25 15:49:11
@_author: Anne & Lynn Wheeler 
@_subject: Crypto to defend chip IP: snake oil or good idea? 
disclaimer ... although our names are on the patents ... they are assigned and we currently have no association with the patents or the company that owns the patents (the most recent allowed happens to be out in todays regular tuesday update):
which basically puts keygen and minimal number of other circuits in the chip. keygen is executed as part of standard initial power-on/test ... before the chips are sliced and diced from the wafer. the public key is exported along with the other power-on/test data and is retained along with the other standard chip inventory information. no increase in chip processing and/or handling.
basically it adds dynamic information to static (data) serial number (which can be easily skimmed and replayed) w/o adding any additional handling or processing steps (other than incorporating the additional circuits into the base chip design). not necessarily definding chip IP ... just slight addition to existing chip serial number convention processing ... somewhat dating back to part of the original aads chip strawman concepts
somewhat related among them:
6,892,302: Incorporating security certificate during manufacture of device generating digital signatures
6,915,430: Reliably identifying information of device generating digital 6,978,369: Person-centric account-based digital signature system
6,983,368: Linnking public key of device to information during manufacture
7,047,414: Managing database for reliably identifying information of device generating digital signatures

@_date: 2006-07-25 18:50:22
@_author: Anne & Lynn Wheeler 
@_subject: Crypto to defend chip IP: snake oil or good idea? 
EE Times is carrying the following story:
from above ...
San Jose, Calif. -- Security specialist Certicom Corp. this week will roll out a hardware-based approach to protecting silicon intellectual property using its elliptic-curve cryptography (ECC) technology and a 20,000-gate embedded core.
... snip ...
in 2000, the initial estimate was 40,000-gate embedded core ... but that included the key-gen and public key export as part of initial power-on/test.
 Crypto to defend chip IP: snake oil or good idea?
 DDA cards may address the UK Chip&Pin woes

@_date: 2006-07-26 08:07:22
@_author: Anne & Lynn Wheeler 
@_subject: Crypto to defend chip IP: snake oil or good idea? 
Crypto to defend chip IP: snake oil or good idea?
 DDA cards may address the UK Chip&Pin woes
 Crypto to defend chip IP: snake oil or good idea?
 The very first text editor
 The very first text editor
a little more backgroun ....
the x9a10 financial standard working group had been given the
requirement to preserve the integrity of the financial infrastructure
for all retail payments .... that included ALL ... aka, internet,
non-internet, point-of-sale, credit, debit, stored-value, ... ALL.
the result was x9.59 financial standard
which reguired strong authentication of every transaction. part of
this was business rule that account numbers used in x9.59 transactions
couldn't be used in non (strongly) authenticated transactions.  this
went a long way to closing the security breaches and data breaches
associated with account fraud (i.e. it was no longer necessary to
encrypt and hide account numbers and transactions since any "skimmed"
information couldn't be used in replay attacks). a recent post
 more on FBI plans new Net- tapping push
however, it did mean that some sort of chip technology was going to be
needed for at least point-of-sale operation. there was some grappling
at the time (mid-90s) with the cost of high integrity chips. we
approached it from the standpoint of KISS ... making a semi-facetious
statement that we were going to take $500 mil-spec technology,
cost-reduce it by better than two orders of magnitude while improving
the integrity at the same time. The other comparison was that it was
going to be significantly more secure than any "DDA" technology while
costing much less than any "SDA" technology.
so the AADS chip strawman was looking at such aggresive KISS and
cost reduction
so part of it was that institutions were also claiming that each had
to issue their own chip token ... since it was only by taking
possesion of the chip at the fab and maintaining strong security
thru-out all its personalization and delivery to the individual, that
they could guarantee they weren't dealing with copy chips. this
possibly implied that if hardware token paradigm ever took off,
individuals will have been issued scores of hardware tokens (i.e.
somewhat analogous to the current password management nightmare).
so the opportunity was could a person choose to present their own
hardware token for institutional use ... rather than have to be issued
a unique token by each institution. this got back to how could the
institution know that it wasn't a copy chip.
so the process was to do key-gen and export as part of power-on/test.
this met that no additional business processes were needed. the
exported public key went into the standard fab
inventory/manifest. when a person presented a hardware token, the
institution could take the public key and validate a digital signature
from the token and then request that the public key and hardware
integrity characteristics be corroborated by the original fab
manifest for the chip.
the idea was to enable transition from institution-centric token
paradigm to a person-centric token paradigm. instead of a person
needed a hundred or more tokens, they could get by with one or
possibly a very small number. this could reduced the overall
token-based infrasstructure costs by a hundred by reducing the number
of required tokens by a hundred. since it was no longer necessary to
have huge amounts of personalization and security between the fab and
delivery to the individual ... up to another factor in one hundred in
processing costs could be eliminated (per token).
a combination of possibly a factor of one hundred times reduction in
the number of required tokens plus a possible reduction of one hundred
times in per token processing costs ... could represent an overall
factor of ten thousand times reduction in overall infrastructure costs
for a hardware token deployment (i.e. one hundred times one hundred).
sometime late 1999 or early 2000 time-frame ... that if the AADS chip
strawman scenario could address the hardware token copy chip
opportunity, then it concievably could also be used to address the
general copy chip opportunity.
this is were the initial estimate came from for being able to do a
general chip core for around 40,000 gates ... and possibly a complete
secure hardware token using total custom chip design for around
100,000 gates.
I had raised the subject during a talk at the assurance session in the
TPM track at the spring 2001 Intel Developers Forum
misc. past posts mentioning person-centric
 maximize best case, worst case, or average case? (TCPA)
 To live in interesting times - open Identity systems
 massive data theft at MasterCard processor
 the limits of crypto and  Another entry in the internet security hall of shame
 thoughts on one time pads
 MP cost effectiveness
 MP cost effectiveness
 were dumb terminals actually so  Maximum RAM and ROM for smartcards
 Security via hardware?
 public key authentication
 Innovative password security
 Hi-tech no panacea for ID theft woes
 RSA SecurID product
 RSA SecurID product
 Caller ID "spoofing"

@_date: 2006-07-27 15:10:27
@_author: Anne & Lynn Wheeler 
@_subject: Crypto to defend chip IP: snake oil or good idea? 
a related article (that also mentions certicom crypto):
How Secure Is That Device?  As device software joins the larger world,
security becomes ever more vital
and some general comments in another thread
 the more things change, the more things stay the same

@_date: 2006-07-27 20:53:26
@_author: Anne & Lynn Wheeler 
@_subject: Crypto to defend chip IP: snake oil or good idea? 
... long post warning :) ...
that is basically a certificate-based process .... i.e. a recognized certification authority is signing the exported public key and injecting it back into the chip ... as a form of digital certificate.
this allows that some relying party ... that has a copy of the appropriate certification authority's public key to validate the device's digital certificate in an offline manner.
the approach i described was not the offline pki-based offline scenario but the certificateless flavor ... the "relying party" accepts the public key and contacts the authoritative agency managing/hosting the fab's manifest. the authoritative agency then returns whether it is an original chip (rather than possibly a counterfeit / copy chip) and possibly also the integrity characteristics of the particular chip.
in any case, can you say "parameterized risk management" :)
with respect to the "kind of enclosure IBM users to protect the private keys inside the cryptographic modules" is that the integrity characteristics of any specific kind of chip is likely to be proportional to the vulnerabilities, threats, risks and purposes that the chip is used for. the high level of integrity for the ibm crypto unit's private key isn't directly related to the cost of the unit and/or whether it is a counterfeit unit ... it is much more related to various anticipated uses that the ibm crypto unit will be applied.
say a 10-50 cent security chip that has been evaluated to EAL5-high
.... possibly even less ... see discussion here
 DDA cards may address the UK chip&Pin woes
... the integrity and protection of the private key is likely going to proportional to the purposes for which the chip will be used.
Part of the least expensive process ... is that other than the 20k-40k additional circuits ... the actual processing, processing steps, and processing time is done in such a way that there is absolutely no different from what they are doing today ... the initial power-on/test to validate a working chip (before it has been sliced and diced from the wafer) is the same exact step taking the same exact amount of time. the exporting of the test fields indicating a valid working chip as part of power-on/test ... is not changed ... other than there are a few more bits that represent the exported public key. the storage and maintenance in the fab chip manifest is exactly the same.
There is no incremental cost and no incremental processing ... other than the chip real estate for additional 20k-40k circuits.
If you treat it as a real security chip (the kind that goes into smartcards and hardware token) ... it eliminates the significant post-fab security handling (prior to finished delivery), in part to assure that counterfeit / copy chips haven't been introduced into the stream .... with no increase in vulnerability and threat.
So finally it comes down to later wanting to check whether you have a counterfeit / copy chip. The current scenario would be to read out the static data serial number and have that looked up in the fab's chip manifest. however serial number static data is vulnerable to things like skimming and replay attacks. So in the basic operation ... for effectively zero incremental cost ... you effectively get a dynamic data serial number authentication for looking up in the fab's chip manifest (as opposed to a simple static data serial number).
For nearly all uses of such a basic chip configuration, the cost of attacking the private key (in such a eal5-high evaluated chip) is much more than any likely benefit ... and is bracketed by being able to flag the chip serial and public key in the fab's chip manifest.
As an attack purely for the purposes of selling 50 cent copy chips ... each chip attack is going to cost enormously more than expected fraud So you have to be expecting something other than a revenue from selling copy chips .... to mount such an attack, you would have to be expecting to be able to make use of the private key for some significantly larger benefit than selling a copy chip.
If you are talking about an attack on the private key ... for purpose other than selling a copy chip ... then you are into security proportional to risk ... i.e. having a variety of chips with integrity proportional to risks of their expected use ... some expected uses far above an EAL5-high evaluation ... may an EAL10 :) or EAL25 :) evaluation?
So for extremely close to zero cost ... you can add straight private key and digital signature to any chip as countermeasure to counterfeit and copy chips. As a side-effect ... it may possible to also use the digital signing capability of the embedded circuits to represent "something you have" authentication. However, the utilization of any such side-effect should be evaluated from the standpoint of the integrity of the chips private key environment and whether it is proportional to the risks associated with the expected application uses.
now when i was talking about this with some government types ... within the context of parameterized risk management ... i.e. the integrity of the chip and the associated private key integrity could be dynamically evaluated to see whether that it satisfied the requirements for the purposes it would be applied ... they commented that this area was totally missed in the work on x.509v3 digital certificates. the commented that if i were to develop an integrity level grading system (for a real-time, online parameterized risk management operation being able to dynamically take into account chip integrity ... including that the chip integrity may have degraded since it had been originally manufactured ... i.e. advances/changes in attack technology/knowledge may increased the chip vulnerability and lowered its integrity) ... then they would see that x.509v3 digital certificates were extended to allow specify a static flavor of chip integrity level.
the basic process was that private key, digital signatures and public key could be added to existing chips at absolutely ZERO additional cost (other than the 20k-40k additional circuits) as a countermeasure to copy chips (where the existing mechanism involves lookup using static serial number) ... aka countermeasure to copy chips. additional uses of such a private key and digital signature capability has to be evaluated against the basic integrity level of the chip (& private key) against the risks associated with the target uses.
Some simple armoring of the private key comes with the design of the basic 20k-40k additional core (i.e. in many respects, the additional circuits operate as a separate computer core and nothing is directly available to the primary processor). That level of integrity may, in fact, be sufficient for a large number of applications.
so ... instead of having a lookup parameterized risk management system
(as originally described) ... the integrity level stuff might indeed be retrofitted to stale, static x.509v3 certificates. in the ibm scenario ... the crypto unit would have an evaluated integrity level ... the public key is exported ... some sort of digital certificate is created with the crypto unit's public key and the crypto unit's integrity level ... and the result is digitally signed ... by some sort of certification authority .... and the certificate is injected back into the crypto unit. future users of the crypto unit can not only extract the digital certificate to validate it is an "original" crypto unit (as opposed to possibly a counterfeit or copy unit) ... and also have the integrity of the crypto unit at the time it was manufactured (for a moment ignoring that the integrity level of the crypto unit may degrade over time as technology advances) ... and evaluate whether the certified integrity level is sufficient for the uses for which it will be applied.
in the lookup parameterized risk management ... there is absolutely
no change in current day standard fab chip processing ... the whole thing is submerged into processes that already occur. I think i was quoted something like a couple pennies per chip per second of additional processing. For the fundamental process, I had incentive ... to incorporate the key-gen and public key export into the existing fab chip processing so there was absolutely no increase in elapsed time of initial chip power-on/test.
NOTE, there is a basic premise here that parameterized risk management doesn't require that there can be one and only one integrity level that has to be met by all devices for all purposes .... it can assume that the required integrity level need only be sufficient to the purposes for which it will be applied. If it is only going to be used to raise the barrier for copy chip vulnerabilities for chips that are priced at tens of cents to tens of dollars ... you might choose one level of private key armoring. The level of private key armoring might be increased if you start talking about copy chip countermeasures for chips that cost hundreds or thousands of dollars.
The risk/threat landscape can also be considerably different if you are doing dynamic, online, real-time lookup or if you depending on a stale, static, offline digital certificate environment.
Another dynamic might be if such a design was incorporated into a variation of RFID chips where the RFID chip is then incorporated into a pill bottle worth hundreds of dollars and targeted as countermeasure to counterfeit/copy drug vulnerability (i.e. one of the issues in the original 40k circuit design from the late 90s was extremely low power requires to work in contactless, radio frequency deployments)
as aside, the patents referenced in the original post (and which we
no longer have any relationship)
 Crypto to defend chip IP: snake oil or good idea?
allowed for both digital certificate modes of operation and certificateless operation.
some recent posts mentioning contactless/proximity and/or power/rf
design considerations in the original aads chip strawman:
 UK Detects Chip-And-PIN Security Flaw
 UK Detects Chip-And-PIN Security Flaw
 UK Banks Expected To Move To DDA EMV Cards
 New ISO standard aims to ensure the security of financial transactions on the Internet
 Naked Payments IV - let's all go naked
 Microsoft - will they bungle the security game?
 DDA cards may address the UK Chip&Pin woes
 DDA cards may address the UK Chip&Pin woes
 DDA cards may address the UK Chip&Pin woes
misc. past posts mentioning parameterized risk management
 QC Bio-info leak?
 QC Bio-info leak?
 biometrics and electronic signatures
 AADS Strawman
 Risk Management in AA / draft X9.59
 X9.59 Electronic Payment standard issue
 cardtech/securetech & CA PKI
 cardtech/securetech & CA PKI
 cardtech/securetech & CA PKI
 cardtech/securetech & CA PKI
 cardtech/securetech & CA PKI
 Common misconceptions, was Re: KISS for PKIX. (Was: RE: ASN.1 vs XML (used to be RE: I-D ACTION  Overcoming the potential downside of TCPA
 Loss Expectancy in NPV  massive data theft at MasterCard processor
 the limits of crypto and  EU digital signature initiative stalled
 Is there any future for  simple (&secure??) PW-based web login (was Re: Another entry in the internet security hall of shame....)
 RSA Adaptive Authentication
 Chip-and-Pin terminals were replaced by "repairworkers"?
 Attacks on a PKI
 Attacks on a PKI
 question about PKI...
 RealNames hacked. Firewall issues.
 how old are you guys
 A Dark Day
 Sun researchers: Computers do bad math ;)
 build-robots-which-can-automate-testing dept
 More on garbage
 Why are smart cards so dumb?

@_date: 2006-07-28 12:16:59
@_author: Anne & Lynn Wheeler 
@_subject: Crypto to defend chip IP: snake oil or good idea? 
there is no increased vulnerability and threat to existing situation where attacker can copy the serial number as it is being read out by normal functions. its static data ... along the lines of symmetric password ... where the same information that is used to establish the authentication is also used to validate the authentication.
the private key scenario doesn't export the private key as part of any normal function ... it is generated within the added circuit core, not available to processing outside of the added circuit core, and the only thing that is normally exposed/exported outside the normal added circuit core is the public key and digital signatures.
so the added circuit core is incremental cost for the chip real estate for the incremental 20k-40k circuit core. the rest of the associated fab and post-fab processing can be reduced to effectively zero ... changing the paradigm from a serial number, pin, password symmetrical based authentication to an asymmetrical based authentication (for essentially no incremental cost).
so an attacker to retrieve the private key ... can't do it by trivial evesdropping or readily available processor functions ... instead the attacker has to resort to physical invasive techniques on the chip to obtain the private key. right away that eliminates all the distance, electronic attacks ... reducing the attacks that require physical possession of the object.
so now the issue is countermeasure to physical invasive attacks requiring physical possession of each chip. so in some of the scenarios ... one sufficient is to have sufficient physical invasive countermeasures that the physical attack will take longer than the nominal interval to report physical lost/stolen (invalidating the use of the physical object).
another scenario from parameterized risk management ... is to make the physical attack more expensive than the associated expected fraudulent benefit to the attacker.
the issue is since the serial number is static (and requires symmetrical authentication ... same value is used for both establishing authentication and verifying authentication) ... and
symmetric authentication mechanisms are vulnerable to a large number of attacks other than physical invasive attack on the physical chip
(the argument is nearly identical to the justification of using digital signature authentication in lieu of static data pin/password authentication which is subject to all sorts of evesdropping and replay attacks) ... like peeling physical layers of the chip and using scanning electron microscope .... i actually spent some time working at the los gatos vlsi lab (bldg. 29) which claims to have pioneered use of scanning electron microscope for chip analysis ... not for chip attacks ... but as part of debugging initial chips.
so a physical vulnerability issue for something fips140-2 is whether there is constant power and countermeasure to physical invasive attack can trigger zeroization. there is cost and vulnerability trade-off regarding not having constant power and can have a physical attack w/o zeroization countermeasure. that is something that shows up as part of parameterized risk management.
this is also somewhat related to the security proportional to risk topic
... one such discussion:
past posts involving this thread:
 Crypto to defend chip IP: snake oil or good idea?
 Crypto to defend chip IP: snake oil or good idea?
 Crypto to defend chip IP: snake oil or good idea?
 Case Study: Thunderbird's brittle security as proof of Iang's 3rd Hypothesis in secure design: there is only one mode, and it's secure
 Crypto to defend chip IP: snake oil or good idea?
 Crypto to defend chip IP: snake oil or good idea?
 The very first text editor
past posts discussing parameterized risk management issues:
 QC Bio-info leak?
 biometrics and electronic signatures
 Risk Management in AA / draft X9.59
 cardtech/securetech & CA PKI
 cardtech/securetech & CA PKI
 cardtech/securetech & CA PKI
 Common misconceptions, was Re: KISS for PKIX. (Was: RE: ASN.1 vs XML (used to be RE: I-D ACTION  X9.59 Electronic Payment standard issue
 Overcoming the potential downside of TCPA
 Loss Expectancy in NPV  massive data theft at MasterCard processor
 the limits of crypto and  Is there any future for  simple (&secure??) PW-based web login (was Re: Another entry in the internet security hall of shame....)
 RSA Adaptive Authentication
 Chip-and-Pin terminals were replaced by "repairworkers"?
 Crypto to defend chip IP: snake oil or good idea?
 Attacks on a PKI
 Attacks on a PKI
 question about PKI...
 RealNames hacked. Firewall issues.
 More on garbage
 Why are smart cards so dumb?

@_date: 2006-07-28 12:22:23
@_author: Anne & Lynn Wheeler 
@_subject: Crypto to defend chip IP: snake oil or good idea? 
so one analogy to explore is somebody claims pin/passwords authentication infrastructures have the exact same vulnerabilities (no more and no less) as private key digital signature authentication. that evesdropping attacks on digital signatures represents the exact same vulnerability as evesdropping on pin/passwords.
to further explore this analogy ... the registration of a public key as part of digital signature infrastructure represents the same exact vulnerability as pin/password registration .... i.e. that anybody having access to the public key registration file can take the public key and perform a fraudulent authentication ... because just like in pin/password authentication paradigm ... the public key is used for both originating the authentication as well as verifying the authentication.
for some additional assertions in this analogy ... that would imply that an attacker only needs to learn the public key in order to perform a successful attack and doesn't actually require access to the private key at all (assuming an assertion that a serialno/pin/password authentication paradigm has the same exact vulnerabilities and threats
as public/private key digital signature authentication paradigm).

@_date: 2006-07-28 15:52:55
@_author: Anne & Lynn Wheeler 
@_subject: Crypto to defend chip IP: snake oil or good idea? 
so maybe we can look at another kind of static serial number vulnerability ... besides it will be nominally directly accessable by general programming and/or transmitted (neither of which would require capturing with physical intrusive methods).
so for more drift ... given another example of issues with static
data authentication operations is that static serial numbers are normally considered particularly secret ... and partially as a result ... they tend to have a fairly regular pattern ... frequently even sequential. there is high probability that having captured a single static serial number ... you could possibly correctly guess another million or so static serial numbers w/o a lot of additional effort. This enables the possibly trivial initial effort to capture the first serial number to be further amortized over an additional million static serial numbers ... in effect, in the same effort it has taken to steal a single static serial number ... a million static serial numbers have effectively been stolen.
So even if you have a scenario where the effort to steal a single static serial number is exactly the same as the effort to steal a private key (because the chips containing them will never divulge and/or export either ... which is actually a false assumption, but just for argument sake assume it to be true) ... then we can still claim that when the effort has been made to steal a single static serial number ... that effort could then be amortized over a million static serial numbers ... while you are still stuck with only a single private key. the equation then is whether "identical effort" divided by one is the same as "identical effort" divided by a million.
so we could look at it from an additional analogy
 Crypto to defend chip IP: snake oil or good idea?
and yet again another anlogy/example similar to static serial numbers tends to be account numbers. one of the static account number vulnerabilities in the 60s were their regular structure. attackers would use the regular structure nature of account numbers to conjure up bogus account numbers from which counterfeit magstripe payment cards were created. this would frequently be succesful for performing fraudulent eventually the payment card industry came up with a sort of secure hash that was written to magstripe along with the account number. basically it was a bank/bin "secret" mashed with the account number. the association network collected a table of all the bank/bin "secrets" and could check the secure hash on an account transaction against the computed value for the account (for instance, if they were going to be doing standin authorization).
you then started to see bogus reading of the magstripe (static data) by attackers ... who then would use the recorded information to create a counterfeit replica.
in the mid-90s, there was chip&pin effort as countermeasure to the bogus reading of magstripes. there was nothing that could be swiped and read ... so it prevented attackers from creating counterfeit cards from bogus the only problem was that sometime in the 80s, you started to also see attackers recording valid transactions ... they didn't actually need physical access to the card ... they just needed to be able to record valid transactions ... and since it was static data ... it could be readily used for replay attacks using counterfeit magstripe cards.
the chip&pin deployments in the late 90s thru recently would have the chip present a digital certificate as its authentication. It didn't do any actual public key operations ... it just presented the certificate. This was called static data authentication. The problem was that the technology used for skimming/recording valid (magstripe) transactions frequently worked equally well recording static data chip&pin transactions (the attackers didn't require any physical access ... they just skimmed/recorded valid transactions, in fact they could record tens of thousands of transactions enabling them to build tens of thousands of counterfeit cards).
Now since it was purely static data authentication, the attackers found that they could take a counterfeit chip and install the skimmed/recorded certificate ... and the chip would now pass as valid. In the late 90s, this got the label "yes cards" ... old "yes card" reference:
the reason for the "yes card" label was that the "chip&pin" effort, in addition to convert from less secure magstripe to a more secure chip ... also added requirement that the person enter their pin. the terminal would pass the pin to (an authenticated) chip and what for the chip to answer yes or no as to whether the pin was correct. Of course, the counterfeit chips were programmed to always answer "yes" regardless of what was passed.
The other was since the chip was so much more secure than the magstripe ... and also more expensive ... infrastructure costs could be saved by offering to do offline (rather than online) transactions. after the chip had been authenticated and indicated the correct pin was entered ... the terminal could then asked the chip if it should do an offline transaction (rather than online) ... and then because it wasn't checking with the account ... it also had to ask the chip if the transaction was within the account credit limit. Of course a counterfeit "yes card" was also programmed to always answer "yes" to these questions.
as an aside, it should be noted that none of this was an actual attack on the chip ... it was an attack on the terminal and the static data authentication paradigm.
as an aside this same time-frame the x9a10 financial standard working group had been given the requirement to presenve the integrity of the financial infrastructure for all retail payments. the result was the x9.59 financial standard for all retail payments
previous posts on this subject:
 Crypto to defend chip IP: snake oil or good idea?
 Crypto to defend chip IP: snake oil or good idea?
 Crypto to defend chip IP: snake oil or good idea?
 Case Study: Thunderbird's brittle security as proof of Iang's 3rd Hypothesis in secure design: there is only one mode, and it's secure
 Crypto to defend chip IP: snake oil or good idea?
 Crypto to defend chip IP: snake oil or good idea?
 Crypto to defend chip IP: snake oil or good idea?
 Crypto to defend chip IP: snake oil or good idea?
and just for the fun of it, past posts discussin the "yes card"  WYTM?
 A combined EMV and ID card
 Single Identity. Was: PKI International Consortium
 Article on passwords in Wired  RPOW - Reusable Proofs of Work
 FraudWatch - Chip&Pin, a new tenner (USD10)
 FraudWatch - Chip&Pin, a new tenner (USD10)
 Meccano Trojans coming to a desktop near you
 Meccano Trojans coming to a desktop near you
 FraudWatch - Chip&Pin, a new tenner (USD10)
 FraudWatch - Chip&Pin, a new tenner (USD10)
 FraudWatch - Chip&Pin, a new tenner (USD10)
 Court rules email addresses are not signatures, and signs death warrant for Digital Signatures
 News and Views - Mozo, Elliptics, eBay + fraud, na??ve use of TLS and/or tokens
 Security Soap Opera - (Central) banks don't (want to) know, MS prefers Brand X, airlines selling your identity, first transaction trojan
 Petrol firm suspends chip-and-pin
 Petrol firm suspends chip-and-pin
 Chip-and-Pin terminals were replaced by "repairworkers"?
 Petrol firm suspends chip-and-pin
 Spring is here - that means Pressed Flowers
 UK Detects Chip-And-PIN Security Flaw
 FraudWatch - Chip&Pin, a new tenner (USD10)
 UK Detects Chip-And-PIN Security Flaw
 UK Banks Expected To Move To DDA EMV Cards
 Naked Payments IV - let's all go naked
 Microsoft - will they bungle the security game?
 Naked Payments IV - let's all go naked
 Naked Payments IV - let's all go naked
 Naked Payments IV - let's all go naked
 Use of TPM chip for RNG?
 Naked Payments IV - let's all go naked
 FraudWatch - Chip&Pin, a new tenner (USD10)
 DDA cards may address the UK Chip&Pin woes
 DDA cards may address the UK Chip&Pin woes
 DDA cards may address the UK Chip&Pin woes
 DDA cards may address the UK Chip&Pin woes
 DDA cards may address the UK Chip&Pin woes
 DDA cards may address the UK Chip&Pin woes
 Security of Oyster Cards
 command line switches [Re: [REALLY OT!] Overuse of symbolic constants]
 US fiscal policy (Was: Bob Bemer, Computer Pioneer,Father of ASCII,Invento
 US fiscal policy (Was: Bob Bemer, Computer Pioneer,Father of ASCII,Invento
 US fiscal policy (Was: Bob Bemer, Computer Pioneer,Father of ASCII,Invento
 A quote from Crypto-Gram
 Methods of payment
 Methods of payment
 AMD to leave x86 behind?
 Caller ID "spoofing"
 When *not* to sign an e-mail  Passwords for bank sites - change or not?
 Google Architecture
 Google Architecture
 Google Architecture

@_date: 2006-07-28 18:46:54
@_author: Anne & Lynn Wheeler 
@_subject: Crypto to defend chip IP: snake oil or good idea? 
which effectively gets you the same as the secure hash scenario for the static account number scenario ... example immediately following the million static serial numbers in the same post:
which is countermeasure to attackers taking advantage of regular pattern.
however, if the static serial number is ever used for any purpose ... it then has to be exposed ... since it is static ... it then is subject to skimming, evesdropping, etc ... and then used in replay attacks,
i.e. previous post
the only equivalent of static serial number to private key is if it is never exposed ... which effectively implies that it is never used,
i.e. previous post
for years the standard security response has been that the best security is to lock it away and never use it and/or provide access.
if it is ever used for any purpose ... then it can be exposed all over the place ... in manner similar to static account numbers (even with the static secure hash) described in the same posting as the million account number scenario, i.e. previous post
so is the issue really with asymmetric key cryptography technology done in custom circuit design ... or is the issue with certicom??
btw, the 40k circuit core design that i referred to done in late 99 and early 2000 had no certicom content ... even the ecc was done w/o any certicom content.

@_date: 2006-07-28 22:36:58
@_author: Anne & Lynn Wheeler 
@_subject: Crypto to defend chip IP: snake oil or good idea? 
fab has plenty of equipment ... at some point there needs to be a little
trust ... the fab could also create copy chips with back doors that
would enable attackers with the appropriate knowledge to extract all
private keys from all manufactured chips .... w/o even requiring
diagnostic equipment. there are audit processes that are designed to
preclude both the backdoor design scenario as well as the private key
extraction scenario.
my claim is that whether it is 20-40 gates or 20k-40k gates would both
be equivalently trivial ... or at least unable to differentiate the
difference if you are talking about 100 million circuit chip.
my assertion is that there is incremental benefit of asymmetric key
operation over straight static serial number. in the scenario where the
asymmetric key operation is being used as countermeasure to copy chips
... there may even be incentive for the fab to not compromise their own
there are also some interesting processes in fabs around the
poweron/test situation to narrow the vulnerability of possible private
key extraction (after the key may be generated) ... unless you are
talking about physical invasive techniques that damage the chip
(negating the purpose have using the digital signature from the private
key for proof of a valid, undamaged, working chip).
my assertion is that the cost of the additional gates can be more than
offset by improving/eliminating other chip processing related processes
... resulting in a net economic benefit .... this is improved by
aggresive cost reduction of the additional gates .... so it might need
to save more than dollar or two in other chip processes for a net
economic benefit (i.e. it may be able to accomplish asymmetric key
circuits for pennies)
you seem to be asserting that the complexity of asymmetric key circuits
would require savings on the order of possibly hundreds of dollars (per
chip) to show any net economic benefit.
somewhat related is that there are lots of current chip activity where
they ahve an excess of circuits that they are somewhat desperately
looking for applications for. if they can front load some incremental
purpose that uses the excess circuits ... the design costs are front
loaded and then amortized across hundreds of millions of chips ...
effectively driving the actual circuit related cost (for the incremental
feature) to zero. if it doesn't actually increase any post fab per chip
processing cost ... and can decrease any post fab per chip processing
cost ... then it actually takes extremely little savings to show a net
economic infrastructure benefit.
in my scenario ... it takes relatively trivial copy chip countermeasure
incremental benefit to justify fabs adding the feature to their chips.

@_date: 2006-07-30 09:33:20
@_author: Anne & Lynn Wheeler 
@_subject: Crypto to defend chip IP: snake oil or good idea? 
from long ago and far away ....
The USB chip is starting to come up higher on peoples' radar ... bunch
of discussion was kicked off by this posting.
the NACHA announcement talks about not absolutely requiring chip for
the signing ... however that means that they can't tell whether it was
chipped signed or not.
Within the AADS infrastructure, it can be a stand-alone AADS chip
(possibly in as few as 20,000 circuits compared to several hundred
thousand to tens of million circuits for the smartbrick chips).
Not only can the AADS chip definition be used for ubiquitous
authentication purposes ... but it is trivial to include such a small
chip in almost any kind of package ... either as a seperate chip (say
in a card, USB housing or corner of a PDA or cellphone) ... or in the
corner of a more complex chip (pentium, k7, strongarm, etc).
In principle, it is technical possible for the same AADS function/chip
to be used for digital signing (and authenticating) multiple X9.59
debit&credit accounts, ISP internet login, corporate intranet login,
webserver access, and business process access.

@_date: 2006-06-02 19:09:41
@_author: Anne & Lynn Wheeler 
@_subject: Status of SRP 
EU finread terminal was countermeasure to (widely held impression that) PCs are extremely vulnerable to compromise.
card authentication required pin entry to work ... and finread terminal had its own PIN-pad distinct the vulnerable PC keyboard. orientation was towards transaction authentication ... with the finread terminal also having its own display of what was being authentication. the transaction authentication orientation was countermeasure to session authentication orientation where PC compromises could operate within the boundaries of any authenticated session.
part of thread in sci.crypt mentioning finread terminal as countermeasure to (widely held view of) the ease of PC compromises
 Keylogger resistance
 Keylogger resistance

@_date: 2006-06-02 19:16:05
@_author: Anne & Lynn Wheeler 
@_subject: Status of opportunistic encryption 
this could be analogous or the same as the trusted certification authority authentication keys that are incorporated into browsers when they are distributed (to the extent that distributed certification authority authentication keys, that are authenticated out of band from the standard PKI process, appear to work, it could be possible that something similar might also work for DNS).
the specification of the root DNS servers could include specifying the associated authentication keys ... in much the same way that the distribution of the root CAs information include the distribution of the associated CA authentication keys.
my rfc index
select "Term (term->RFC under "RFCs listed by" ... and then select "DNSSEC" in the acronym fastpath.
domain name system security  (DNSSEC )
     see also domain name system, domain name system extensions,
     security
  4509 4470 4431 4398 4322 4310 4035 4034 4033 3845 3833 3755
  3658 3226 3225 3130 3110 3090 3008 3007 2931 2930 2845 2541
  2540 2539 2538 2537 2536 2535 2137 2065
in frames mode, clicking on the RFC number brings up the RFC summary in the lower frame. clicking on the ".txt=nnnn" field in the RFC summary retrieves the actual RFC.

@_date: 2006-06-02 19:41:55
@_author: Anne & Lynn Wheeler 
@_subject: Status of opportunistic encryption 
oh, and some number of certification authorities actually backed some parts of DNSSEC ... including the idea that people register a public key when they registered a domain name. this was countermeasure to various kinds of domain name hijacking vulnerabilities ... i.e. the domain name owner would digitally sign communication ... and the domain name infrastructure would validate the digital signature with the onfile public key.
this became attractive to certification authorities. currently they require a ssl domain name certificate application to supply a lot of identification information. the certification authority then performs the time-consuming, error prone, and expensive process of matching the supplied identification information with the information on file with the domain name infrastructure. with communication authenticated with the onfile public keys, there is a reduction in the chance of domain name hijacking ... and therefor the certification authority has higher level of assurance that they aren't dealing with a ssl domain name certificate applicant that has just hijacked the domain name.
also, if the public keys were on file with the domain name infrastructure, then certification authorities could require that application for ssl domain name certificates be digitally signed.
then the certification authorities could change from a time-consuming, error prone, and expensive process of matching identification information to the less-expensive and more reliable process of simply authenticating the digital signature. they would execute dnssec protocol with the domain name infrastructure requesting real-time retrieval of the onfile public key for the domain name. they would validate the response with DNSSEC trusted root public key on file in their local repository of trusted dnssec public keys (in much the same way that the existing PKI infrastructure validate digital signatures on digital certificates using CA public key from their local repository of trusted (CA) public keys).
This whole thing then goes to the root of improving the integrity of the SSL domain name certificate infrastructure.
The catch22 for the certification authority infrastructure is that if they can start retrieving real-time public keys for authenticating digital signatures on ssl domain name certificate applications ... then possibly the rest of the world could also start using DNSSEC to also do real-time retrieval of onfile public keys from the domain name one might even imagine a highly optimized SSL type session protocol where instead of the existing protocol chatter exchange ... the servers on-file public key could piggyback on the standard DNS response for hostname->ipaddress. the client in the initial transmission send a random session key encrypted with the server's public key.
a few recent posts mentioning this catch22 dilemma for the SSL
domain name certificate industry:
 X.509 and ssh
 Caller ID "spoofing"
 X.509 and ssh
 The Pankian Metaphor

@_date: 2006-06-02 20:09:55
@_author: Anne & Lynn Wheeler 
@_subject: Status of opportunistic encryption 
the original pk-init draft for kerberos just had public keys being registered in lieu of passwords ... in much the same way that people register public keys as part of the "registration authority" part of a pki certification authority process.
machines then could have public keys to authenticate communicating with the trusted public key store (imagine it like real-time access to a certification authority ... in lieu of the stale, static digital certificates). to the extent that such machines can trust a repository of trusted certification authority public keys ... then they could also have a trusted repository of public keys for real-time communication with key store (where a key store might also be replicated for availability and scaling ... in manner analogous to the way DNS had replicated trusted servers).
it was only later that the draft succumbed to the pressure to also allow
PKI digital certificate mode of operation ... i.e. the machines rather than doing real-time authenticated communication with the trusted key store ... they might also use a local trusted public key repository to authentication certification authority digital signatures on stale, static digital certificates.
basically the key registration process is identical in the PKI digital certificate mode of operation and the certificateless public key mode of operation. the management of the trusted public key repository (of trusted "root keys ... in one case for certification authorities, in the other case for the key store) on each machine is effectively also identical. however, the certificateless public key mode uses real-time communication with the key store ... while the PKI digital certificate mode substitutes the whole digital certificate issuing, management, administrative, etc infrastructure overhead (in lieu of the much simpler real time communication).

@_date: 2006-06-03 07:01:57
@_author: Anne & Lynn Wheeler 
@_subject: Status of SRP 
if they can build a $100 PC ... you think that they could build a finread terminal for a couple bucks. sometimes there are issues with volume pricing ... you price high because there isn't a volume and there isn't a volume because you price high.
there is one issue missing from the actual FINREAD specification.
when we were doing X9.59 financial standard ... we allowed for a digital signature for authentication as well as for a digital signature from the environment that the transaction was performed in. the issue from a relying party standpoint ... is what assurances do they have as to the actual environment that a transaction was executed in. consumers could claim they were using a FINREAD terminal when they weren't. counterfeit FINREAD terminals could be out in the wild.
part of the x9.59 financial standard looked at the assurance/integrity that a relying party might have with regard to the actual authentication ... one factor, two factor, three factor ... and the actual assurance/integrity of the associated factors (or conversely, how vulnerable were the factors to compromise). this somewhat led into also having to consider the assurance/integrity environment that the authentication took place in (and what assurances would a relying party have with regard to the environment).
part of it has been some past inclination to just specify some standard ... w/o regard to how a relying party might actual have assurances as to whether some standard or another was being followed in an open environment (and considering threat scenarios that might involve compromise/impersonation of various components).
for instance, there was a recent scenario in the UK where crooks were impersonating maint. people and were updating secure POS terminals with compromised components.

@_date: 2006-06-03 07:44:38
@_author: Anne & Lynn Wheeler 
@_subject: Status of SRP 
Status of SRP
another aspect was that there was a program in the past to give away smartcards and card readers to consumers as part of doing smartcard financial transactions. the issue at the time was that deployed support for pc/sc standard only supported pc serial port interfaces ... and therefor the free card reader was a serial port device. there was an ensuing disaster as consumers tried to get the serial port device operational ... lots of stories of BSOD, having to re-install everything from scratch, etc. as the dust was settling, there was a quickly spreading opinion that smartcards (or at least smartcard readers) were not viable in the consumer market segment. it was during this period that m'soft even canceled its smartcard operating system project.
recent post discussing the subject:
 Spring is here - that means Pressed Flowers

@_date: 2006-06-06 09:48:52
@_author: Anne & Lynn Wheeler 
@_subject: Status of SRP 
Status of SRP
 Status of SRP
i got involved in tracking down a virus/trojan like problem in the 70s on the internal network
basically if you are going to allow loading of stuff that can do its own execution w/o many safeguards ... you are going to be extremely vulnerable to numerous kinds of attacks.
either you have to very tightly control what applications are loaded .... or possibly do a fixed function deployment that can support multiple different applications ... possibly based on some form of data driven architecture (i.e. the data specification possibly adapts the functional operation to different applications w/o requiring loading of executable code).
we had done the AADS chip strawman was done this way ... basically single function operation w/o any ability to load executable code ... that was adaptable to a large number of different applications
another possible solution is very strong partitioning of any loadable executable content that is allowed extremely limited/controlled capability.
in the 60s as an undergraduate, i had done a lot with extremely controlled partitioning ... which i learned much later got used in various environments that had extremely high integrity requirements ... random drift
i had this discussion with the general manager of the business unit that included java and java virtual machine (when it was in its very early infancy) ... turns out that I had done some work with the person (general manager) nearly 20 years earlier in a different life.
many of the modern generation of POS terminals are trying to cope with this problem ... getting all sorts of frequent application downloads of various kinds ... and still attempting to operate within constraints of their trusted security module implementation.
basically if finread
is countermeasure to widely acceptable PC vulnerabilities (many that arise because of the ease and common practice of loading executable content) ... then if you deploy such a finread terminal that is operated using similar conventions ... then it will acquire similar vulnerability characteristics (as the environment that it is suppose to be a countermeasure for).

@_date: 2006-06-07 05:39:35
@_author: Anne & Lynn Wheeler 
@_subject: Status of SRP 
so they aren't exactly unrelated.
 Status of SRP
 Status of SRP
 Status of SRP
 Status of SRP
the financial standards x9a10 working group had been given the requirement to preserve the integrity for all retail payments. the result was the x9.59 payment standards for all retail payments.
part of x9.59 retail payment standard requires the transaction to be authenticated. another part of the x9.59 retail payment standard requires that the account number in x9.59 retail payments can't be used in non-authenticated transactions. it as been recognized for a long time that a major source of account financial fraud  has been the data breaches
and resulting fraudulent use of account numbers ... this is somewhat my old posting on security proportional to risk
in effect, account numbers have been overloaded. on one hand, knowledge of account numbers have been sufficient for doing fraudulent transactions. as a result they have to be treated as shared secrets, kept confidential and never divulged. on the other hand, account numbers are required in a large number of business process as the fundamental cornerstone for transaction execution ... and are required to be widely available. as a result of these totally opposing requirements, i've periodically observed that the planet could be buried under miles of cryptography used in hiding account number, and it would still be unable to prevent leakage of account numbers. the x9.59 business rule recognizes this and changes the paradigm, eliminating the severe financial fraud vulnerability associated with divulging account numbers
(and/or data breaches involving account numbers).
another part of x9.59, in addition to providing for transaction digital signature as part of transaction authentication (and trying to close some of the barn door with the overloaded requirements placed on account numbers) was allowing for a second digital signature by the environment that the transaction originated in. this would provide the relying party additional information for performing risk assessment related to authorizing the transaction.
so later when this software company wanted to come up with something for content providers, they hired the chair of the x9a10 financial standards working group to move to redmond to be director of development.
for other drift on trusted computing ... there are capability based operating systems ... current example is capros ... which was spawned from eros, which was sort of spawned from keykos, which was spawned from gnosis ... recent post mentioning some capros, eros, keykos, gnosis, et all (and other related lore regarding secure and/or capability-based operating systems ... going back to deployments by commercial time-sharing service bureaus in the late 60s and their connections to some of the current efforts ... as well as connections to what i was
doing as an undergraduate in the 60s)

@_date: 2006-06-07 07:21:44
@_author: Anne & Lynn Wheeler 
@_subject: UK Detects Chip-And-PIN Security Flaw 
UK Detects Chip-And-PIN SecurityFlaw
APACS says the security lapse came to light in a recent study of the authentication technology used in the UK's new "chip-and-PIN" card system.
... snip ...
this was documented as the "yes card" in 2002 regarding chip&pin rollouts that had been done in the 99-2002 time-frame
since the "yes card" vulnerability is an attack against the pos terminal (not the card) ... and since the vulnerability is part of the standard ... even if all new cards were rolled w/o the "fix" ... the infrastructure might still be vulnerable if POS terminals could be convinced to communicate using the vulnerable standard (this is somewhat analogous to attacker attacking protocols and convincing parties to downgrade to lower encryption).
misc. posts discussing the "yes card" vulnerability as well as mentioning possible man-in-the-middle attack against the fix for "yes card" vulnerability.
 WYTM?
 A combined EMV and ID card
 Single Identity. Was: PKI International Consortium
 Article on passwords in Wired  RPOW - Reusable Proofs of Work
 FraudWatch - Chip&Pin, a new tenner (USD10)
 FraudWatch - Chip&Pin, a new tenner (USD10)
 Meccano Trojans coming to a desktop near you
 Meccano Trojans coming to a desktop near you
 FraudWatch - Chip&Pin, a new tenner (USD10)
 FraudWatch - Chip&Pin, a new tenner (USD10)
 FraudWatch - Chip&Pin, a new tenner (USD10)
 Court rules email addresses are not signatures, and signs death warrant for Digital Signatures
 News and Views - Mozo, Elliptics, eBay + fraud, na??ve use of TLS and/or tokens
 Security Soap Opera - (Central) banks don't (want to) know, MS prefers Brand X, airlines selling your identity, first transaction trojan
 Petrol firm suspends chip-and-pin
 Petrol firm suspends chip-and-pin
 Chip-and-Pin terminals were replaced by "repairworkers"?
 Petrol firm suspends chip-and-pin
 Spring is here - that means Pressed Flowers
 Security of Oyster Cards
 command line switches [Re: [REALLY OT!] Overuse of symbolic constants]
 US fiscal policy (Was: Bob Bemer, Computer Pioneer,Father of ASCII,Invento
 US fiscal policy (Was: Bob Bemer, Computer Pioneer,Father of ASCII,Invento
 US fiscal policy (Was: Bob Bemer, Computer Pioneer,Father of ASCII,Invento
 A quote from Crypto-Gram
 Methods of payment
 Methods of payment
 AMD to leave x86 behind?
 Caller ID "spoofing"
 When *not* to sign an e-mail  Passwords for bank sites - change or not?
 Google Architecture

@_date: 2006-06-07 09:43:06
@_author: Anne & Lynn Wheeler 
@_subject: UK Detects Chip-And-PIN Security Flaw 
Status of SRP
 UK Detects Chip-And-PIN Security Flaw
 Google Architecture
as i mentioned, the x9a10 financial standards working group had been given the requirement to preserve the integrity of the financial infrastructure for all retail payments .... this included at least all kinds of internet, all kinds of POS, and all kinds of payments (debit, credit, stored-value, etc).
part of the resulting x9.59 financial standard was transaction authentication. session authentication had been looked at, and it was felt (compared to transaction authentication) it was much more vulnerable to end-point threats, mitm threats, as well as insider threats.
from some retailers comments that chip&pin wasn't appropriate for internet transactions ... it might be implied that chip&pin does session-like (as opposed to transaction) authentication ... regardless of whether it is SDA or DDA (possibly making it vulnerable to some of the end-point threats, mitm threats, and/or insider threats considered by the x9a10 financial standard effort).
UK Detects Chip-And-PIN Security Flaw
using the x9.59 transaction authentication paradigm, i had started on the aads chips strawman.
at the NISSC conference in 98, i had quiped that I was going to take a mil-spec security token, cost reduce it by two orders of magnitude while increasing its security. in a chip&pin reference this met having a chip doing "DDA" at higher integrity than the chip&pin DDA chip ... but at lower cost than the chip&pin SDA chip. The aads chip strawman also needed to be able to do x9.59 transaction authentication within iso14443 contactless power profile and within the transit industry turnstyle timing requirements. a number of aads strawman chips were demonstrated in dec. 1999 at the world-wide retail banking show in miami, authenticating a variety of different kinds of financial and non-financial transactions.
i gave a presentation on assurance at the 2001 intel developer's forum (in the tpm track). I happened to quip during the presentation that it was nice to see that the TPM chip design had started to look more and more like the aads chip strawman over the previous year or so. the guy leading the TPM chip effort was in the front row and quiped back that it was because i didn't have a committee of 200 people helping me with my

@_date: 2006-06-08 12:13:42
@_author: Anne & Lynn Wheeler 
@_subject: UK Detects Chip-And-PIN Security Flaw 
> for even more drift ... a news item from later yesterday
 >
 > UK Detects Chip-And-PIN Security Flaw
 >  >
 > APACS says the security lapse came to light in a recent study of the
 > authentication technology used in the UK's new "chip-and-PIN" card
 > system.
 >
 > ... snip ...
 >
 > and some comment
 >  UK Detects Chip-And-PIN
 > Security Flaw
 >
 > not too long after the exploit (from earlier deployments) being
 > documented in 2002 ... it was explained to a group from the ATM
 > industry ... leading somebody in the audience to quip "do you mean
 > that they managed to spend a couple billion dollars to prove that
 > chips are less secure than magstripes".
the above from discussion on the subject in a different context
the above reference goes into a little more detail of where the label "yes card" came for the counterfeit cards used in the "SDA" exploit.
as mentioned in earlier posting in this thread:
 UK Detects Chip-And-PIN Security Flaw
part of the aads chip strawman
requirements in the 90s was to be able to do dynamic data authentication
with higher security than the "DDA" chips (using the chip&pin terminology) with chip that cost less than the "SDA" chips (and also could meet the contactless transit power and timing profile requirements).
the x9a10 working group had already examined replay attack threat models (based on static data authentication) especially in light of the common skimming attacks that being used to harvest magstripes and PINs
that were starting to become common at the time.
for little more drift, there are assumptions about multi-factor authentication being more secure ... i.e. magstripes and PINs represent different factors. However, skimming attacks appearing by at least the
mid-90s where capturing magstripes and PINs as part of the same operation (invalidating a basic multi-factor security assumption).
also previously mentioned, x9a10 was specifying transaction authentication as opposed to session-like authentication ... because transaction authentication reduced several kinds of vulnerabilities that were frequently related to session operation (end-point threats, mitm threats, insider threats).
there were a number of chip&pin "SDA" deployments in the 90s ... a partial reference here:
... which had provided opportunities for the "yes card" type attacks to evolve. by the time of the 2002 article about "yes cards" ... the article also mentioned that information about building counterfeit "yes cards" was widely available on the internet.
however, the information about "yes card" kind of attacks (skimming "SDA" data for replay attacks against terminals) was relatively readily available by 2000. In late fall of 2000, there was a small conference in London with principles of the lloyd's of london syndicates involved in insuring (brick & mortar) point-of-sale retail payment fraud discussing numerous threat models and countermeasures.
however, a lot of chip&pin deployments have been by people that are extremely chip centric ... interpreting everything from the context of the produced chips. there were some chip&pin deployments in 2001 that interpreted the "yes card" vulnerability from the standpoint that valid cards could do offline transactions. their "yes card" countermeasure was to produce valid cards that always did online transactions.
Some of the chip&pin aficionados, when various of the "yes card" details were explained in more details ... tended to have trouble coming to grips with it being an attack on terminals and the rest of the infrastructure ... not attacks on valid chips ... and also thought that the crooks were not playing fair in how they programmed the counterfeit one of the references in the 2002 article was to "yes cards" never going away. this also was somewhat behind the cited comment from ATM industry in conference not too long after the 2002 article about proving chips are less secure than magstripe.
a cornerstone countermeasure to attacks on valid chips (like lost/stolen vulnerabilities) was infrastructure feature that when a card did an online transaction (as opposed to offline), the online infrastructure could instruct the card to self-destruct. the infrastructure allowed valid cards to instruct chip&pin terminals that they were doing offline transactions ... but valid cards were programmed to sporadically do online transactions. if a valid chip was reported as compromised, the account could be flagged (as happens with all magstripe transactions) and the chip also be scheduled for self-destruct command, the next time it went online.
since a counterfeit "yes card" could be programmed to never go online, flagging an account (as works with magstripe transactions) has no effect (which was part of what prompted the comment about proving that chips are less secure than magstripes, another part was in many cases, the same technology being used for skimming magstripes & pins would also skim "SDA" information). however, periodically some of the "yes cards" might be forced to go online ... but several of the chip-centric individuals were totally dismayed and felt it very unfair that crooks would go so far as to program the counterfeit "yes cards" to ignore the self-destruct commands.
in the 2001 chip&pin deployments with countermeasures to counterfeit "yes cards", involving programming valid cards to always do online transactions, had no effect on "yes card" fraud. the "yes card" attack was (replay attack) on terminals (not an attack on valid cards). the countermeasure for counterfeit "yes cards" would have required the terminals to be programmed to always ignore instructions to do offline transaction ... forcing everything to online transactions ... so the operation would be subject to the same online "account number flagging" that has been used as countermeasure to magstripe fraud.

@_date: 2006-06-08 13:21:00
@_author: Anne & Lynn Wheeler 
@_subject: UK Banks Expected To Move To DDA EMV Cards 
UK Banks Expected To Move To DDA EMV Cards
... from above ...
Of the 6.2 billion card transactions in the UK each year, one in five occurs offline, which increases the risk of cloned cards being used at a retailer?s POS terminal. In short, a cloned credit or debit card may go unidentified if a transaction is not sent to a bank for approval.
... snip ...
 UK Detects Chip-And-PIN Security Flaw
note that the counterfeit "yes card" attack (from the late 90s) isn't on valid cards programmed to do offline (or online) transactions; the counterfeit "yes card" attack (built from skimmed "SDA" data) is on chip&pin terminals programmed to do what any authenticated card tells it to do (part of the chip&pin terminal standard):
the countermeasure to counterfeit "yes card" attacks on chip&pin terminals is to program the terminal to ignore what the card tells it to do, and always do an online transcation. this makes chip&pin deployments subject to the same "account flagging" countermeasure that has been long used for magstripe cards. The counterfeit "yes card" exploit always doing offline transactions (making it immune to account flagging countermeasures) was somewhat prompted somebody several years ago to make the comment about spending several billion dollars to prove that chips were less secure than magstripe.
part of what had prompted the aads chip strawman effort
in the 90s was the frequent comment about deployments being forced into doing "SDA" chip deployments because technology cost for "DDA" chip deployments was too uneconomical. Part of the aads chip strawman was to demonstrate technology doing dynamic data authentication (as countermeasure to skimming, harvesting and replay attacks) at the highest possible integrity ... for less cost than any "SDA" technology
(as well as being able to meet transit contactless power and timing profile requirements).
 UK Detects Chip-And-PIN Security Flaw

@_date: 2006-06-09 09:29:44
@_author: Anne & Lynn Wheeler 
@_subject: whole load of new RFCs announced yesterday on LDAP and SASL 
possibly fastest way of getting sense of all the new rfcs is to go to
and click on "Date" in the "RFCs listed by" section. Clicking on each individual RFC number (in the june section) will bring up that RFC summary in the lower frame. Clicking on the ".txt=nnnn" field will retrieve the actual RFC.
another approach is to click on "Term (term->RFC in the "RFCs listed by" section and then clikc on either "LDAP" (or "SASL") in the Acronym

@_date: 2006-06-09 21:17:07
@_author: Anne & Lynn Wheeler 
@_subject: New ISO standard aims to ensure the security of financial transactions 
New ISO standard aims to ensure the security of financial transactions on the Internet
from above:
ISO 21188:2006, ?Public Key Infrastructure for financial services ? practices and policy framework?, offers a set of guidelines to assist risk managers, business managers and analysts, technical designers and implementers and operational management and auditors in the financial services industry.
... snip ...
my two bits ... in part, in light of recent pin&chip vulnerability thread
another metaphor for viewing the session authentication paradigm is that they tend to leave the actual transaction naked and vulnerable.
we had worked on the original payment gateway for what become to be called e-commerce
which we also assert can be considered the first SOA implementation
 Token-ring vs Ethernet - 10 years later
to some extent part of the transaction vulnerability analysis for x9.59 transactions in the mid-90s was based on analysis and experience with the original payment gateway implemented with session oriented paradigm.
work on x9.59 in the mid-90s, did what very few other protocols did, defined end-to-end transaction strong authentication. many of the other protocols would leave the transaction naked and vulnerable at various steps in the processing.
session oriented protocols leaving the actual transaction naked and vulnerable (or the actual transaction not having complete end-to-end transaction strong authentication and therefor naked and vulnerable for at least some part of the processing) ... implies that the complete, whole end-to-end business process has to be heavily armored and secured. Minor chinks in the business armoring will expose the naked transaction to potentional attack and fraud.
if outsider attacks aren't enuf, naked transactions are also extremely vulnerable to insider attacks. nominally, transactions will be involved in a large number of different business processes ... exposing them to insider attacks at every step. end-to-end transaction strong authentication armors the actual transaction (avoiding leaving the transaction naked and vulnerable at vast array of processing steps). the naked transaction paradigm also contributes to the observation that something like seventy percent of fraud in such environments involve end-to-end transaction strong authentication (armoring the actual transaction) then also alleviates the need for enormous amounts of total business process armoring (where absolutely no chinks in the armor can be allowed ... which is necessary for protecting naked and vulnerable transactions ... which don't have end-to-end transaction strong the x9a10 working group (for what become the x9.59 financial standard) had been given the requirement to preserve the integrity of the financial infrastructure for all retail payments. this met not only having countermeasures to things like replay attacks (static data that could be easily skimmed), but also having end-to-end transaction strong authentication (eliminating the vulnerabilities associated with having naked and vulnerable transactions at various points in the infrastructure).
part of the x9.59 financial standard for all retail payments in armoring and protecting transactions included the business rule that account numbers used in x9.59 transactions could not be used in transactions that didn't have end-to-end transaction strong authentication. this
eliminated the problem with knowledge leakage of the account number representing a vulnerability (i.e. a naked account number was no longer vulnerable for use in fraudulent transactions).
part of the theme of the post on security proportional to risk is that if the individual transactions aren't armored then it can be extraordinarily expensive to provide absolutely perfect infrastructure armoring to protect naked and vulnerable transactions
part of the issue with some of the payment oriented protocols in the mid-90s looking at providing end-to-end strong authentication based on digital signature paradigm was the mistaken belief regarding appending digital certificates as part of the implementation. typical payment transaction is on the order of 60-80 bytes. the various payment protocols from the period with appended digital certificates had a payload bloat of 4k to 12k bytes (or a payload bloat of one hundred times). it was difficult to justify an enormous end-to-end payload bloat of one hundred times for a redundant and superfluous digital certificate, so the protocols tended to strip the digital certificate off, leaving the transaction naked and vulnerable during subsequent processing. of course this was before I had demonstrated that it was possible to compress appended digital certificates to zero bytes (opening the way for x9.59 transactions with end-to-end strong authentication based on digital signatures).
rather than viewing x9.59 as using certificateless digital signatures for end-to-end transaction strong authentication
just consider that x9.59 has appended compressed zero byte digital certificates to address the severe payload bloat problem
the issue of SDA (static data authentication vulnerable to replay attacks) or DDA (countermeasure to replay attacks) is somewhat independent of using a session oriented implementation (and having naked and vulnerable transactions at various points in the infrastructure):
 UK Detects Chip-And-PIN Security Flaw
 UK Detects Chip-And-PIN Security Flaw
 FraudWatch - Chip&Pin, a new tenner (USD10)
 UK Detects Chip-And-PIN Security Flaw
 UK Banks Expected To Move To DDA EMV Cards
 FraudWatch - Chip&Pin, a new tenner (USD10)
 Google Architecture
 Google Architecture
 Google Architecture
 Google Architecture

@_date: 2006-06-10 11:36:24
@_author: Anne & Lynn Wheeler 
@_subject: Securely handling credit card transactions earns Blackboard kudos 
Securely handling credit card transactions earns Blackboard kudos
... from above
"These programs utilize the Payment Card Industry (PCI) data security standard as the foundation to assess third-party processors," he added. "This standard ensures that all third-party processes safely and securely store, process, and transmit sensitive credit card data across their network infrastructures. This is the second year that Blackboard has achieved this milestone in the payment card industry."
... snip ...
couple other refs
this can also somewhat be considered from the standpoint of my old security proportional to risk posting
however, it can also be interpreted that "sensitive credit card data" is represented by an infrastructure with naked and vulnerable transactions:
  New ISO standard aims to ensure the security of financial transactions on the Internet
i.e. that when dealing with naked and vulnerable transactions then the overall infrastructure requires extensive armoring (as countermeasure to attacks on naked transactions that otherwise don't have any of their own one might be tempted to draw an analogy with the bubble boy reference
about the countermeasures needed for a boy that was w/o his own immune system to combat attacks.

@_date: 2006-03-27 09:15:30
@_author: Anne & Lynn Wheeler 
@_subject: Creativity and security 
the trivial case from nearly 10 years ago was the waiter in nyc
restaurant (something sticks in my mind it was the Brazilian restaurant
just off times sq) that had pda and small magstripe reader pined to the
inside of their jacket. At some opportunity, they would causally pass
the card down the inside of their lapel (doesn't even really have to
disappear anyplace). This was before wireless and 801.11 ... so the
magstripe images would accumulate in the pda until the waiter took a
break ... and then they would be uploaded to a PC and then to the
internet (hong kong was used as example) ... counterfeit cards would be
on the street (opposite side of the world), still within a few hours at
recent posts mentioning some skimming threats
 Meccano Trojans coming to
desktop near you

@_date: 2006-03-27 09:53:47
@_author: Anne & Lynn Wheeler 
@_subject: Creativity and security 
Creativity and security
and a more recent skimming news item from this month:
Cloned-card scams socking it to bank accounts
the above card mentions pins with debit cards ... which is typically
required for atm machines for withdrawing cash ... but the new class of
debit cards with logos can also be used w/o pins at pos terminals (aka
at pos, it is option selection to decide whether the debit card is used
with or w/o pin).
various recent postings mentioning skimming attacks:
 When *not* to sign an e-mail
 When *not* to sign an e-mail
 When *not* to sign an e-mail
 Caller ID "spoofing"
 Debit Cards HACKED now
 Debit Cards HACKED now
 Debit Cards HACKED now
 Debit Cards HACKED now
 Does the Data Protection Act
of 2005 Make Sense
 GP4.3 - Growth and Fraud -
Case  - Phishing
 long-term GPG signing key
 thoughts on one time pads
 thoughts on one time pads
 thoughts on one time pads
 Face and fingerprints swiped
in Dutch biometric passport crack (another card skim vulnerability)
 thoughts on one time pads
 thoughts on one time pads
 FraudWatch - Chip&Pin, a new
tenner (USD10)
 FraudWatch - Chip&Pin, a new
tenner (USD10)
 FraudWatch - Chip&Pin, a new
tenner (USD10)
 Meccano Trojans coming to a
desktop near you

@_date: 2006-05-01 11:56:18
@_author: Anne & Lynn Wheeler 
@_subject: PGP "master keys" 
multi-party operations were supposedly countermeasure to single person
insider threads. the fraud response was collusion. so by at least the early 80s you started seeing work on collusion countermeasures. 25 years later, things have regressed to a pre-occupation with intrusion threats and intrusion countermeasures; even tho insiders have continued to be the major source of fraud through the whole period. insiders may even leverage the pre-occupation with intrusion to obfuscate the source of the exploit.
somewhat related issue with regard to sarbanes-oxley and auditing assumptions about independent information sources looking for  Sarbanes-Oxley
 Sarbanes-Oxley
and a couple recent articles about current fraud pre-occupation
SSL Trojans: The next Great Bank Heist
Ripped Off: Identity Theft - A View from the Financial Services

@_date: 2006-05-13 17:02:57
@_author: Anne & Lynn Wheeler 
@_subject: NSA knows who you've called. 
for other drift ... the stuff about call record analysis with regard to social networking has been topic in datamining conferences for at least a couple years ... both academia and industry. the cellphone companies appear to be especially interested in it, for various kinds of capacity planning and marketing purposes (I think some academia even have contracts with cell phone companies researching this area).
several months ago my wife had extensive communication with an editor doing some background stuff on datamining. some of it showed up in an article somewhat spun for the current situation
Info Mining & Sharing are Controversial Co-Dependents, part 1:
my wife's quotes liberally lace part 2:
Data Mining "Disrupts & Enables"

@_date: 2006-05-16 17:24:53
@_author: Anne & Lynn Wheeler 
@_subject: Elliptic Curve Cryptography (ECC) Cipher Suites for Transport Layer 
4492 I
     Elliptic Curve Cryptography (ECC) Cipher Suites for Transport Layer Security (TLS), Blake-Wilson S., Bolyard N., Gupta V., Hawk C., Moeller B., 2006/05/16 (35pp) (.txt=72231) (Refs 2246, 3268, 3279, 3280, 4346, 4366) (was draft-ietf-tls-ecc-12.txt)

@_date: 2006-11-09 12:20:31
@_author: Anne & Lynn Wheeler 
@_subject: Flaw in RFID-enabled passports (part 2?) 
Flaw exploited in
RFID-enabled passports
Budapest Declaration on Machine Readable Travel Documents (MRTDs)
from above:
By failing to implement an appropriate security architecture, European
governments have effectively forced citizens to adopt new international
Machine Readable Travel Documents which dramatically decrease their
security and privacy and increases risk of identity theft. Simply put,
the current implementation of the European passport utilises
technologies and standards that are poorly conceived for its purpose. In
this declaration, researchers on Identity and Identity Management
(supported by a unanimous move in the September 2006 Budapest meeting of
the FIDIS ?Future of Identity in the Information Society? Network of
Excellence) summarise findings from an analysis of MRTDs and recommend
corrective measures which need to be adopted by stakeholders in
governments and industry to ameliorate outstanding issues.
... snip ...
RFID Passport Security 'Poorly Conceived'
the above also references
Feds Leapfrog RFID Privacy Study
from above:
The story seems simple enough. An outside privacy and security advisory
committee to the Department of Homeland Security penned a tough report
concluding the government should not use chips that can be read remotely
in identification documents. But the report remains stuck in draft mode,
even as new identification cards with the chips are being announced.
... snip ...
The Use of RFID for Human Identification; A DRAFT REPORT from DHS
Emerging Applications and Technology Subcommittee

@_date: 2006-11-13 12:36:22
@_author: Anne & Lynn Wheeler 
@_subject: Citibank e-mail looks phishy 
... and the situation can in turn be aggravated by ....
NatWest shuns ID fraud victims
from above ...
Other types of fraud are on the rise, too. New figures from Apacs show
a dramatic rise in the number of "phishing" incidents, where scammers
send out an e-mail purporting to be from a consumer's bank and asking
them to type in their account details.
... snip ...

@_date: 2006-11-15 16:51:40
@_author: Anne & Lynn Wheeler 
@_subject: ATMs hacked using MP3 player 
and one more skimming attack
ATMs hacked using MP3 player
from above:
The gang targeted freestanding cash dispensers and would tap the phone line between the ATM and a wall socket by placing a two-way adaptor on it and connecting an MP3 player, according to the newspaper.
... snip ...
just another in long history of skimming/harvesting of static authentication information
somewhat related:
 Citibank e-mail looks phishy
and as referred to here
 New attacks on the financial PIN processing
x9.59 protocol
attempting to address the whole problem of attackers acquiring (sensitive) static authentication information ... regardless of method, harvesting, skimming, data breaches, phishing, whatever
... effectively for use in any form of replay attack.
the design of the x9.59 protocol also attempted to address numerous possible man-in-the-middle attacks ... which still might occur even when switching from static authentication data to dynamic authentication data i.e. the authentication was part of the transaction itself ... as opposed to separately operation (which could possibly open up cracks for man-in-the-middle attacks).

@_date: 2006-11-16 07:45:08
@_author: Anne & Lynn Wheeler 
@_subject: Citibank e-mail looks phishy 
past posts in this thread
 Citibank e-mail looks phishy
 Citibank e-mail looks phishy
 ATMs harcked using MP3 player
couple more in sci.crypt thread:
 New attack on the financial PIN processing
 New attack on the financial PIN processing
elsewhere in the "PIN processing" thread somebody mentions that ATM standards require encryption for the PIN but not the rest of the message. This could be considered sufficient prior to the introduction of signature-debit ... since up until that time all debit transactions required the associated PIN.
However, the introduction of signature-debit makes the rest of the (unencrypted) message attractive targets, since attackers can skim the information and create counterfeit cards and use them in (PINless) signature-debit transactions.
or can you say security proportional to risk
or using the "naked payments" metaphor, consistent requirement for a debit transaction to have a PIN ... and the PIN was given at least some level of protection ... would imply that the payment transaction had some degree of armoring ... which eliminated the rest of the transaction as useful to the attacker (and therefor didn't need encryption since it wasn't sufficient to perform fraudulent transactions). With the introduction of signature-debit, it removes the transaction armoring and creates a vulnerability for the rest of the transaction information (the armoring of the transaction information was removed, leaving it naked and exposed, making the information vulnerable to skimming, harvesting, data breach, etc attacks).
as mentioned in numerous times in the past, the x9a10 financial standard working group was given the requirement to preserve the integrity of the integrity of the financial infrastructure for all retail payments
part of the of the standard was to specify an environment were the transactions were always consistently "armored" and never left naked and vulnerable. misc. past posts mentioning
the naked payment/transaction metaphor
 New ISO standard aims to ensure the security of financial transactions on the Internet
 Naked Payments IV - let's all go naked
 Naked Payments IV - let's all go naked
 Naked Payments IV - let's all go naked
 Naked Payments IV - let's all go naked
 Naked Payments IV - let's all go naked
 Naked Payments IV - let's all go naked
 Naked Payments IV - let's all go naked
 DDA cards may address the UK Chip&Pin woes
 DDA cards may address the UK Chip&Pin woes
 DDA cards may address the UK Chip&Pin woes
 Interesting bit of a quote
 Naked Payments IV - let's all go naked
 Naked Payments II - uncovering alternates, merchants v. issuers, Brits bungle the risk, and just what are MBAs good for?
 More Brittle Security -- Agriculture
 Identity v. anonymity -- that is not the question
 WESII - Programme - Economics of Securing the Information Infrastructure
 OpenSSL Hacks
 OT - J B Hunt
 the personal data theft pandemic continues
 the personal data theft pandemic continues
 the personal data theft pandemic continues
 Encryption and authentication

@_date: 2006-11-15 16:15:12
@_author: Anne & Lynn Wheeler 
@_subject: Citibank e-mail looks phishy 
the straight-forward ones are not too bad ... they just require somebody to understand the infrastructure and to do a detailed  vulnerability analysis. the more complex ones are systemic failures ... which can happen in complex, interconnected infrastructures .... whether it is financial infrastructure or the power grid ... or some of the PKI-based scenarios (things that might be considered relatively minor failures, cascade and pull down the whole infrastructure).
some of the straight-forward ones can also happen because of infrastructure and/or paradigm changes ... and there wasn't any forward thinking.
recent thread today in sci.crypt
 New attack on the financial PIN processing
 New attack on the financial PIN processing
there is reference to chip&pin and the "yes card" exploit
as referenced, the x9a10 financial standard group was formed to work on x9.59 standard (and given the requirement to preserve the integrity of the financial infrastructure for all retail payments) in the same time frame that work started on chip&pin. chip&pin appeared to come out with a solution that addressed lost/stolen (magstripe) card. however, in the decade preceding that work, there was a big increase in skimming/harvesting static authentication data for the production of counterfeit cards.
there was already a partial countermeasure for lost/stolen card ... that was notifying the issuer and getting the account flagged. however, skimming, harvesting, and/or data breaches involving static authentication information was a much more difficult problem ... since it typically wasn't evident to the card owner that it has happened (and most indications would only be there when the fraudulent transactions started showing up)
so not too long after chip&pin deployments in the 90s, "yes card" exploits started appearing. some have even claimed that chip&pin actually made the situation worse vis-a-vis magstripe card ... because a chip was allowed to tell a terminal to do offline transactions (which a counterfeit "yes card" would always do) ... which negated the countermeasure of flagging the account (since a real time transaction wasn't being done, by the time a terminal found out that an account was flagged, it was way too late).

@_date: 2006-11-23 09:23:51
@_author: Anne & Lynn Wheeler 
@_subject: Citibank e-mail looks phishy 
and now for some different threat vector:
Banks face growing threat of identity theft from insiders
from above:
Banks are pouring money into building formidable defenses against computer hackers, but are only just waking up to what may be a bigger threat--the physical theft of client information by people in the office.
.... snip ...
it isn't exactly new news ... insiders have always been considered the major threat ... whether it is physical theft or various kinds of electronic data breaches and/or security breaches. misc. past items ...
Study: ID theft usually an inside job
Leading Cause of Data Security breaches Are Due to Insiders
Bank workers biggest ID theft threat
other insider threat
i've frequently commented in the past that the stuff about external threats that make the popular press has frequently obfuscated the source of the major threats (for all i know, insider attacks may even take advantage of the added confusion and ambiguity introduced by the prospect of internet-based attacks).

@_date: 2006-10-01 18:35:39
@_author: Anne & Lynn Wheeler 
@_subject: signing all outbound email 
so what if an isp only signs email where the origin address is the same
as the claimed email "from" address.
then email that claims to be from such an isp, that isn't
signed, might assumed to be impersonation.
and any "abuse" reports to the isp ...where the email has been signed
... should at least trace back to the correct originating account.
ISPs could do ingress filtering where they only process incoming email
from their customers ... where the origin address matches the email
"from" address ... which would eliminate their customers from
impersonating other addresses ... but doesn't preclude customers at
non-participating ISPs from impersonating their customers.
ISPs could also start to quarentine unsigned email that claims to have
originated from ISPs that are known to sign email.
it might be considered to be small step up from ssl domain
name digital certificates ... where the browser checks that
the domain name in the URL is the same as the URL in the
certificate. the issue in the ssl domain name scenario is
some common use where the user has little or no awareness
of the domain name in the URL  .... so the fact that the
actual domain name matches the domain name in the certificate
may bring little additional benefit.
lots of past collected posts mentioning ssl domain name
certificates ... some of the posts mentioning merchant
comfort digital certificates

@_date: 2006-10-12 08:43:12
@_author: Anne & Lynn Wheeler 
@_subject: TPM & disk crypto 
so i did do fab process and associated infrastructure for tpm-like chips
that recorded public key at manufacturing time. this came up in recent
thread on trusting chips and/or knowing integrity level of chips
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?
 Crypto to defend chip IP:
snake oil or good idea?

@_date: 2006-10-17 22:26:08
@_author: Anne & Lynn Wheeler 
@_subject: hashes on restricted domains: random functions or permutations? 
posts discussing other kinds of attack on 2289 ... assuming the original
circumstances that 2289 is supposed to address; most of the "fixes" for
the attacks ... in turn, negate/invalidate the original
purpose/justification for 2289
 public key vs passwd
 public key vs passwd
 public key vs passwd
 public key vs passwd
 The Chinese MD5 attack
 RSA SecurID product
 Looking for Information on
password systems
 Caller ID "spoofing"

@_date: 2006-10-28 15:21:16
@_author: Anne & Lynn Wheeler 
@_subject: Flaw exploited in RFID-enabled passports 
Flaw exploited in RFID-enabled passports
from above:
Security researchers have released proof-of-contact code that they say enables an attacker to read the passport number, date of birth, and passport expiration date from passports with RFID tags enabled.
... snip ...
something similar could be claimed behind the switch-over from x.509 identity certificates
to relying-party-only digital certificates in the mid-90s (i.e. potentially serious privacy and liability issues)
and as i've pointed out repeatedly, it is trivial to then show that such relying-party-only digital certificates are redundant and superfluous.
then from three factor authentication model
* something you have
* something you know
* something you are
part of the issue with something like "date of birth" is that it not only is a privacy issue but it may also represent a serious identity theft and fraud issue, in part because there is pervasive use of "date of birth" as part of "something you know" authentication.
if the paradigm was sanitized ... then you might at most have "something you have" authentication ... i.e. you assert some passport number which is in turn, digitally signed by some hardware token or other embedded chip.
even simpler, you have anything that asserts some sort of passport number. the challenger than
does real-time online lookup (using the supplied number) for photo along with other identifying and/or pertinent information ... and performs authentication based on the information just looked up. a person could carry their passport number in some sort of cellphone/pda ... which requires some response from the owner for it to be transmitted (in response to a query) ... or alternatively ... as a barcode pasted to the back of their cellphone.
The online, real-time scenario would even eliminate the person needing to carry some gov. issued registered document ... just that they are able to provide the appropriate passport number when challenged (which is used to do real-time retrieval of the necessary registered information).
The returned real-time information reponse can be specific and limited to the task being performed.
One of the paradigm issues with documents/certificates issued for purely offline operation ... is a tendency to try and make them (more) useful for multiple purposes ... which then leads to them being overloaded with lots of different information for the multiple purposes. Many times there is real danger that the available aggregate information is far in excess of what is needed for any specific task/process. However, it is poor human factors to burden an individual with large set of different documents/certificates that would be exactly specific for any single operation.

@_date: 2006-09-09 14:12:51
@_author: Anne & Lynn Wheeler 
@_subject: RSA SecurID SID800 Token vulnerable by design 
as i've mentioned serveral times, in the mid-90s, the x9a10 financial standards working group was given the task of preserving the integrity of the financial infrastructure for all retail payments. the result was x9.59 standard
which specified (end-to-end) authenticated transaction (and a business rule that account numbers used in x9.59 transactions could not be used in non-authenticated transactions) ... recent, related post:
 DDA cards may address the UK Chip&Pin woes
part of the issue was with the actual transactions being signed and running end-to-end ... and account numbers no longer vulnerable to "naked" exploits ... it was no longer necessary to hide the account number (as countermeasure to prevent fraudulent "replay attack" the issue then became end-point attacks; either the originating end-point or the authorizing end-point. most infrastructure have had the authorizing end-points pretty well armored for some time. that primarily leaves vulnerabilities at the originating end-point.
part of the EU finread terminal work was to close off some of the originating end-point vulnerabilities.
basically an independent, secure token terminal with its own display and key-entry. the transactions is forwarded from the end-point to the finread terminal ... the finread terminal displays a summary of the transaction details ... and passes it to the token for digital signing. any pin-entry (for two-factor authentication ... token "something you have" and pin-entry "something you know") is performed at the finread terminal (minimizing any pin evesdropping and associated pin replay attack exploits).
while session encryption is useful for confidentiality and privacy of the operations ... a lot of existing session encryption is primarily because existing transactions don't have end-to-end armored authentication ... leaving various pieces of information involved in the actual transaction naked and vulnerable to various kinds of replay attacks.
the x9.59 standards approach was to provide end-to-end armoring of the actual transactions ... eliminating numerous kinds of replay vulnerabilities and some of the man-in-the-middle attacks
... independent of any possible use of authentication for session purposes
note that while it isn't part of the x9.59 standard ... the standard was carefully crafted such that end-point environments like the EU finread would be allowed to also sign transactions.
the issue is that the responsible authorization end-point frequently will be doing risk assessment  (especially involving financial transactions). it is easy to see that a eu finread terminal provides a much higher integrity digital signing environment that many personal computers (for instance, virus software than log the entered pin and replay it to a connected hardware token w/o the person's knowledge) ... it is useful to have some knowledge about the transaction originating environment when doing risk assessment.

@_date: 2006-09-16 13:57:06
@_author: Anne & Lynn Wheeler 
@_subject: A note on vendor reaction speed to the e=3 problem 
FSTC originally created FSML for digitally signed xml encoded data ... which was then donated to w3c and became part of xml digital signature specification.
the issue for FSTC was "e-checks" ... where originator took fields from ACH transaction ... encoding them in XML, digitally signed the XML encoding, and then appended the signature to the original ACH transaction. the recipient received the ACH transaction ... duplicated the original XML encoding process, computed the hash ... and then compared it to the decoded signature (from the ACH transaction append field).
the original issue for FSML was that XML didn't have a bit-deterministic encoding process ... which could result in the originator and the recipient getting different results doing XML encoding of ACH transaction fields.
X9.59 financial transaction specified something similar
which allowed originator and recipient to perform deterministic encoding of standard financial transaction (in manner similar to FSTC e-check process) ... where the signature was carried in standard electronic transaction append field. the base standard specified ASN.1 encoding ... but the fully constituted x9.59 fields included a version field ... the purpose of which included being able to specify an x9.59 version that used XML encoding (rather than ASN.1 encoding).
the standard just specified all the fields and ordering for the encoding.
there were sample mappings between the fields in the standard and fields in various
existing financial transactions. if x9.59 called for fields that weren't part of
specific financial transaction ... then those fields needed to be carried in the transaction append/addenda, along with the digital signature (i.e. the digital signature was appended
to standard transaction in unencoded format, it wasn't required that the encoded format
being transmitted ... just that the encoded format could be reproduced in a deterministic manner). old write-up giving correspondence between x9.59 fields and some fields from some
common financial transaction formats (includes a proposed xml tagged encoding)
part of the issue for the x9.59 specification was the requirement for a standard that preserved the integrity of the financial infrastructure for all retail payments (ALL, including point-of-sale).
A typical point-of-sale payment card transaction avgs. 60-80 bytes. By comparison, some of the PKI digital signature based specifications from the period had enormous payload bloat resulting in 4k-12k bytes ... aka increasing transaction payload size by two orders of magnitude (100 times).

@_date: 2006-09-25 21:19:02
@_author: Anne & Lynn Wheeler 
@_subject: fyi: On-card displays 
for a decade or so ... i've made comments that the increasingly powerful smartcards are obsolete because they are really pda(/cellphone) wannabes (after some of the gov. technology transfer legislation in the early 90s, we did some consulting for one of the gov. agencies on attempting to move some smartcard chip based technology into the commercial sector ... and we could already see it was rapidly becoming obsolete).
the smartcard target of portable computing device from 70s/80s required various kinds of iso standards because of the lack of appropriate portable input/output capability .... so there would be standardized, fixed input/output stations that could be used with the portable smartcards. that market niche for smartcards became obsolete with the appearance of pda/cellphone portable input/output capability sometime in the early to mid-90s.
possibly part of the problem was that there was significant investment in various kinds of smartcard technology during the 80s and 90s ... and when they became obsolete ... there was some amount of scurrying around attempting to obtain some/any return on the original investments ... even if it was only a few cents on the dollar.
they are now contending with various kinds of cellphone/pda payment delivery operations. there is some paradigm discontinuity tho. there is a tradition grown up where the institutions issue the card (payment, identification, etc) ... to some extent smartcard activities are attempting to capitalize on that legacy momentum. an individual's cellphone/pda tends to break that institutional centric issuing paradigm ... since it can involve an individual taking their cellphone/pda (that they already have) and registering it for various activities/transactions/identification ... aka another form of "something you have" authentication ... but it is possibly a personal device rather than an institution issued device.
so there are already various kinds of pda/cellphones with display, input capability ... and
some of them even have their own biometric sensing capability.
the issue with "electronic signature" is demonstration of intent ... we got into that when we were asked to help word-smith some of the cal state (and later federal) electronic signature act. various past postings mentioning issue of establishing intent

@_date: 2006-09-25 21:48:40
@_author: Anne & Lynn Wheeler 
@_subject: fyi: On-card displays 
we were asked to do the design/sizing/cost for mondex infrastructure in the us. one of the things that turned up was much of the mondex infrastructure was based on float (initially essentially all going to mondex international) ... cards were almost incidental. somewhere along the way, mondex international even started offering to split the float with national organizations as an inducement to sign up.
somewhere along the way a group was also formed to try and map mondex to the internet ... which eventually morphed into IOTP.
misc. past posts that mention mondex
 7th CACR Information Security Workshop
 IP: Re: Why we don't use digital cash
 AGAINST ID CARDS
 Payment Application Programmers Interface (API) for IOTP
 EMV
 Is there any future for smartcards?
 Payment systems - the explosion of 1995 is happening in 2006
 EMV cards
 Opinion  on smartcard security requested
 Are you sure about MONDEX?
 Are you sure about MONDEX?
 US fiscal policy (Was: Bob Bemer, Computer Pioneer,Father of ASCII,Invento
 US fiscal policy (Was: Bob Bemer, Computer Pioneer,Father of ASCII,Invento
 Revoking the Root
 Is Mondex secure?

@_date: 2006-09-26 09:19:37
@_author: Anne & Lynn Wheeler 
@_subject: fyi: On-card displays 
and for a whole lot of drift with respect to smartcards being pda/cellphone wanabees
Storm building over RFID-enabled passports
from above:
The chip, which is embedded inside the cover of the passport, contains only a duplicate copy of the passport photograph and the printed data. The digital data is intended to prevent forgeries by allowing inspectors to compare the printed and digital data.
... snip ...
the article mentions that integrity of the electronic data is protected by a digital signature (preventing tampering and/or forgeries).
At some level, the digitally signed data can be considered a electronic credential that is extremely difficult to counterfeit.
posting with number of references about cloning (electronic) passport data
 And another cloning tale
from three factor authentication model
* something you have
* something you know
* something you are
... frequently hardware tokens (chips) are implemented as "something you have" authentication (i.e. the chip supposedly contains some unique information ... which differentiates it from every other chip). some recent posts mentioning "something you have" authentication.
 On-card displays
 RSA SecurID SID800 Token vulnerable by design
 Fraudwatch - Chip&PIN one-sided story
however, taking the passport chip data as an electronic credential, cloning the information doesn't (directly) represent a vulnerability ...  since it is more analogous to digital certificates ... which are readily assumed to be widely distributable.
the passport chip data as an electronic credential containing a digital photograph ... and matching a person's face to the digital photograph then represents "something you are" authentication (as opposed to assuming the chip ...or even a cloned chip ... represents any sort of "something you have" authentication).
in theory, an electronic credential would be considered valid, regardless of any specific chip container that it might be carried in. one might then make the assertion, that a passport electronic
credential could be carried in any device capable of reliably reproducing the correct bits.
going back to the issue raised in
 On-card displays
that most smartcards/chips are really pda/cellphone wanabees ... one might suggest that you could then even carry your electronic credential/passport in your pda or cellphone ... as opposed to needing a separate physical device.
the issue that then is raised are there any significant privacy considerations similar to privacy issues raised with x.509 identity digital certificates from the early 90s (having large amounts of privacy information in x.509 identity digital certificates widely distributed all over the place).
by the mid-90s, many institutions considered that the privacy and liability problems with x.509 identity digital certificates were so significant that they retrenched to "relaying-party-only" certificates. lots of past posts mentioning rpo-certificates
these were digital certificates that effectively only contained some sort of database index or account number. the relying party then used the account number to retrieve the actual information of interest (w/o having to widely expose it in any way).
the analogy for an electronic passport infrastructure would be just needing to present the passport number. the actual credential data (and any photos or other information necessary for "something you are" authentication) is retrieved from secure online repository.
as repeatedly pointed out in the "RPO" digital certificate scenario ... it isn't even necessary to include the account/passport number in a digitally signed document ... since there is no information that needs integrity protection. the person just makes an assertion as to their correct account/passport number. the appropriate information is then retrieved from the online infrastructure and used for authentication (and whatever other required purposes). asserting the
wrong account/passport number presumably retrieves information that fails to result in valid authentication.
needing (some certification authority) to digitally sign the passport/account number (in the RPO scenario) for any possible integrity purposes, is then redundant and superfluous (one of my oft
repeated comments).

@_date: 2006-09-30 16:29:56
@_author: Anne & Lynn Wheeler 
@_subject: signing all outbound email 
============================== START ==============================
recently published IETF RFC
... from my IETF RFC index
4686 I
  Analysis of Threats Motivating DomainKeys Identified Mail (DKIM), Fenton J., 2006/09/26 (29pp)      (.txt=70382) (Refs 1939, 2821, 2822, 3501, 4033) (was draft-ietf-dkim-threats-03.txt)
from the introduction:
The DomainKeys Identified Mail (DKIM) protocol is being specified by
the IETF DKIM Working Group.  The DKIM protocol defines a mechanism
by which email messages can be cryptographically signed, permitting a
signing domain to claim responsibility for the use of a given email
address.  Message recipients can verify the signature by querying the
signer's domain directly to retrieve the appropriate public key, and
thereby confirm that the message was attested to by a party in
possession of the private key for the signing domain.  This document
addresses threats relative to two works in progress by the DKIM
Working Group, the DKIM signature specification [DKIM-BASE] and DKIM
Sender Signing Practices [DKIM-SSP].
... snip ...

@_date: 2007-04-02 11:35:31
@_author: Anne & Lynn Wheeler 
@_subject: SSL MITM-attacks make the news 
ABN Amro compensates victims of 'man-in-the-middle' attack
from above:
Four ABN Amro customers activated a virus allowing a man-in-the-middle attack that overcame the bank's two-factor authentication. After the attack, ABN Amro removed an 'urgent payment' option from its Web site as a precaution, compensated the customers and launched a campaign to remind users about internet banking safety.
... snip ...
and lots of past posts mentioning MITM-attacks

@_date: 2007-04-03 12:52:21
@_author: Anne & Lynn Wheeler 
@_subject: Governance of anonymous financial services 
Governance of anonymous financial services
so applying x9.59
mapping to iso 8583 (i.e. credit transactions, debit transactions ... and even some
number of stored-value transactions carried by some point-of-sale terminal and
... at least part of the financial network)
you have the standard iso8583 financial transactions with a x9.59 addenda ... that includes
a digital signature, a hash of the receipt and some misc. other stuff.
existing infrastructure advises that both merchant and consumer retain (paper) receipts (in
case of disputes). x9.59 financial standard didn't specify/mandate how that might be
done ... but provided for support for applications for doing.
the financial transaction was already required to be archived/logged for all sorts of
regulations and business processes (as evidence some number of recent breach references). In the mid-90s, the x9a10 financial standard working group had been given the requirement
to preserve the integrity of the financial infrastructure for ALL retail payments. In numerous
other references I've mentioned that doing required taking into account all sorts of
considerations as part of x9.59 standard (including countermeasures to fraudulent transactions
from breaches), it had to be extremely lightweight because of numerous considerations when
you are asked to consider ALL retail transactions (including looking forward to various c
ontactless, wireless, cellphones, transit turnstyles, etc), and maximizing the optimal
use of all the existing processes and flows.
In any case, as a result, the "x9.59" transaction would be logged/archived as part of existing standard financial transaction processes ... which includes the digital signature against the
full transaction ... where the full transaction ... along with the digital signature
is being logged ... including the receipt hash and the additional x9.59 specified fields.
the "receipt", that is hashed, isn't specified as part of the x9.59 protocol standard
... but is assumed to be whatever is necessary to support resolution, in case of any dispute (at least the equivalent of saying that both the merchant and consumer retained
paper receipt copies in the case of dispute).
we actually may have done too good a job. a lot of efforts that have worked on doing similar
or related efforts ... essentially viewed it as profit opportunities. the x9a10 standards
worked view all the "stuff" as added expense ... to be aggressively eliminated as much as
possible. For instance in the AADS chip strawman
in the mid-90s, i would semi-facetiously say that we would take a $500 mil-spec part, aggressively cost reduce it by 2-3 orders of magnitude, increase its security/integrity,
have it form-factor agnostic (as well as being able to meet contactless transit turnstyle to compound the problem ... we also did a bit of work on being able to change the
institutional-centric "something you have" authentication paradigm to a person-centric
paradigm ... i.e. rather than having one "something" per institution ... you could have
one (or a very few) "somethings" per person (could be viewed as creating the "something you are"
biometric authentication analogy for "something you have" authentication). misc. past
posts mentioning 3-factor authentication paradigm
so having something that was aggressively cost reduced by 2-3 orders of magnitude, more
secure ... and instead of having one per institution/environment (that a person was involved with), they would have only one (or a very few). overall this could have represented
possibly four orders of magnitude cost reduction (that many others were viewing as potential
profit opportunity).
in any case, who would be the stack-holders interested in something that eliminates nearly all
fraud and nearly all costs?
a few past posts mentioning working on change-over to a "person-centric" paradigm:
 Crypto to defend chip IP: snake oil or good idea?
 Why security training is really important (and it ain't anything to do with security!)
 Failure of PKI in messaging
 Caller ID "spoofing"
 Gen 2 EPC Protocol Approved as ISO 18000-6C
 OT - hand-held security
 Device Authentication - The answer to attacks lauched using stolen passwords?
 Special characters in passwords was Re: RACF - Password rules
 special characters in passwords
 One Time Identification, a request for comments/testing

@_date: 2007-04-03 15:25:15
@_author: Anne & Lynn Wheeler 
@_subject: Governance of anonymous financial services 
Governance of anonymous financial services
 Governance of anonymous financial services
My wife has been gone five years and I've been gone for over a year (they had
corporate re-org in Dec '05) ... and we have no rights/interest ... but they
continue to trickle out
latest today (3Apr2007) ... hot off the press:
Method and system for using electronic communications for an electronic contract
A method and system for digitally signing an electronic contract document. An electronic
communication contains an identifier, a message, which includes the document, and a digital signature generated with a private key of an asymmetric key pair (247). The identifier may be used to retrieve a corresponding public key (287) and account information pertaining to the sender of the message. The public key may be used to authenticate the sender and the message. A device containing the private key may be used to protect the privacy thereof. The device may also generate a verification status indicator corresponding to verification data input into the device. The indicator may also be used as evidence that the sender of a contract document performed an overt act in causing the electronic communication to be digitally signed. A security profile linked to the public key in a secure database indicates security characteristics of the device. ... snip ...
for a little drift ... slightly related to this recent posting in sci.crypt
 Electronic signature outside Europe

@_date: 2007-04-07 11:03:04
@_author: Anne & Lynn Wheeler 
@_subject: DNSSEC to be strangled at birth. 
one could claim that PKI failed ... especially in its trusted 3rd
party scenario ...  since it was an amazingly complex and expensive
deployment to solve a rapidly vanishing problem.
the basic design point is the electronic analog for physical
credentials, certificates, licenses used in the "offline" world ... or
the electronic analog of letters of credit/introduction from the
sailing ship days (and before) ... the trusted distribution of
information for the benefit of relying parties that had no other
recourse for the information.
in an online world ... a paradigm designed for trusted distribution of
information for an offline world, rapidly becomes redundant,
superfluous and obsolete (besides enormously NOT cost effective).
SSL was intended as countermeasures to two vulnerabilities 1) are you
really talking to the server that you think you are talking to (among
other things ip-address hijacking) and 2) evesdropping of information
in transit.
The SSL solution to  was predicated on the end-user having knowledge
of a trusted binding between the server he thought he was talking to
and the URL for that server.  The SSL protocol then provided the
trusted binding between the URL and the server the user was actually
talking to. That weak-link in all of this was current infrastructure
where end-users frequently have very little knowledge of the binding
between the server they think they are talking to and the URL for that
It isn't so much that SSL has failed to do what it was implemented to
do, it is that SSL failed to take into account that part where
end-users have very little knowledge of the relationship between
servers and the URLs for those servers. It isn't so much a small-scale
population that it works for ... it requires a (disciplined)
population that maintains adequate knowledge of the relationship
between servers and the URL for those servers. Even a well disciplined
population is likely only to maintain knowledge of strong binding
between servers and URLs ... for only a small number of servers and
their corresponding URLs. The same population may be also be
vulnerable when dealing with URLs and servers outside some well
regulated domain.
these series of posts talk about eliminating PKI and digital
certificates for SSL ... and going to real-time public key operations
in the domain name infrastructure ... as countermeasure to ip-address
hijacking (original SSL) as well as domain name hijacking (as well as
providing mechanism for encrypting information while in transit).
Aka the current domain name certification authority PKI-based paradigm
has its root trust in the validity of the information at the domain
name infrastructure. While the existing SSL/PKI related implementation
was targeted at ip-address take-over ... it still remained vulnerable
to domain name hijacking.
however, the real-time domain name public keys, still doesn't address
the vulnerability of end-users typically not having knowledge of
strong binding between the website they think they are talking to and
the corresponding URL (making them vulnerable to website impersonation
and social engineering attacks that get them to click on arbitrary
Solutions for these vulnerabilities ... typically involve some amount
of additional trust operations by the users ... along the lines
of local repository of trusted public keys with the corresponding
trusted binding to trusted URLs (which starts to look somewhat
like the PGP email public key repository). One of the issues for
such solutions is that they lack the economic incentive for
large scale deployment (i.e. there is no 3rd party taking in
money selling digital certificates).

@_date: 2007-04-19 18:23:21
@_author: Anne & Lynn Wheeler 
@_subject: crypto component services - is there a market? 
recent post/thread with some discussion of the business of
digital certificates ... as distinct from either digital
and/or electronic signatures.
 sizeof() was: The Perfect Computer - 36 bits?
one of the exploits for the "changing" the burden of proof scenario
(mentioned in the above post) ... since the incentive is significant ... is where the merchant produces a digital signature plus corresponding
digital certificate purported to be from the other party.
the underlying digital signature stuff was designed for providing
authentication and integrity for the transaction. there was never
any provisions for it to ever provide intent and/or handle the
situation of establishing the inverse ... i.e. in traditional
digital signature & digital certificate paradigm ... there is
no way of proving what, if any, digital signature and digital
certificate were originally appended to the transaction/invoice.
this somewhat gets into the area of non-repudiation services
(where some of the trusted time-stamping have periodically
wandered into) ... i.e. for individuals, digital signature isn't representative of a human signature and intent ... it is
purely does (what digital signatures were originally designed
for) authentication and integrity. other parts of the same thread related to digital signatures
 sizeof() was: The Perfect Computer - 36 bits?
 sizeof() was: The Perfect Computer - 36 bits?
 sizeof() was: The Perfect Computer - 36 bits?
 sizeof() was: The Perfect Computer - 36 bits?
possibly being able to force changing of burden of proof ... is analogous to
some past discussions about "dual-use" attack ... again where there was possibility
of allowing digital signatures to wander into the arena of human signatures and
intent ... a thread that started in this mailing list
 dual-use digital signature vulnerability
 dual-use digital signature vulnerability
 dual-use digital signature vulnerability
 dual-use digital signature vulnerability
 dual-use digital signature vulnerability
 two-factor authentication problems
 Citibank discloses private information to improve security
 massive data theft at MasterCard processor
 massive data theft at MasterCard processor
 the limits of crypto and authentication
 Is there any future for smartcards?
 Contactless payments and the security challenges
 Court rules email addresses are not signatures, and signs death warrant for Digital Signatures

@_date: 2007-04-20 13:46:35
@_author: Anne & Lynn Wheeler 
@_subject: crypto component services - is there a market? 
crypto component services - is there a market
slightly related discussion of x9.59 financial standard protocol
supporting hash of invoice in any dispute resolution ... thread from a couple
weeks ago
 Governance of anonymous financial services
 Governance of anonymous financial services
where the x9.59 transaction is digital signed (and presumably logged/archived as part
of various financial regulations).
In dispute, both parties can produce their version of any invoice (bill of materials, etc)
and differences can be resolved by the hash included in the signed payment transaction.
In the mid-90s, the x9a10 financial standard working group had been given the requirement
to preserve the integrity of the financial infrastructure for ALL retail payments. It
faced a couple issues
1) It was starting to dawn that x.509 identity certificates from the early 90s, frequently overloaded with personal information represented significant privacy and liability issues.
As a result there was move to digital certificates that contained some sort of indirect
(and/or obfuscated) lookup value ... and were frequently referred to as relying-party-only
however, it was trivial to show that in any situation where the indirection had to be
used for some sort of lookup ... that the public key could be obtained in the same
operation ... making the digital certificate redundant and superfluous
2) Some of the other digital signed work for financial transactions in the period ...
the appending of a digital certificate to such a transaction was resulting in
two orders magnitude payload and processing bloat (for something that was redundant
and superfluous)
3) The appending of the digital certificate is basically a paradigm operation that
supports distribution of trusted information for offline operation (the electronic analog of physical credential, certificate, license, and/or letters of credit/introduction from sailing ship days and earlier). time we were working on x9.59 ... there
were several claiming that the appending of digital certificates (to financial transactions)
was needed to bring financial processing into the "modern age". Our reply was that moving
from a fundamentally online infrastructure to an offline paradigm actually represented
a regression of several decades. It was somewhat after that you started to see work
on the rube goldberg OCSP standard.
In some respect ... trusted time-stamping is attempting to take the online financial
transaction model where there are frequently strict regulations about archiving/auditing
and extend it to other types of operations. In the x9.59 financial standard scenario ...
the financial archiving/auditing infrastructure was extended to cover invoice, bill-of-materials,
etc ... but simply adding their hash to the digital signed financial transaction
(and at the same time avoiding the enormous payload and processing bloat seen in various
other strategies).

@_date: 2007-04-25 17:26:28
@_author: Anne & Lynn Wheeler 
@_subject: Public key encrypt-then-sign or sign-then-encrypt? 
the discussion in this thread was about potentially long-lived document contents
carrying digital signature for authentication and integrity. this is a more
of a business issue than a traditional security/confidentiality issue
 asymmetric cryptography + digital signature
 asymmetric cryptography + digital signature
the contents plus digital signature might be encrypted for transmission purposes
(or other confidentiality reasons). one might contend that if the document has to always be kept encrypted
... for confidentiality reasons ... then it might be useful to apply
the digital signature to the encrypted version.
however, if it is a long-term electronic document normally processed in
clear-text ... then clear-text digital signature can be used for check of
integrity and authentication (of the document contents) and it may only rarely or never require encryption for confidentiality
part of this is that in the symmetric key example ... encryption can be viewed
as doing double duty for confidentiality and integrity .... with authentication a separate item. in the asymmetric key scenario, the digital signature is doing double duty for integrity and authentication ... with (encryption) confidentiality a separate operation ... in which, also using encryption for integrity can be viewed as redundant.

@_date: 2007-04-26 07:36:00
@_author: Anne & Lynn Wheeler 
@_subject: Public key encrypt-then-sign or sign-then-encrypt? 
there has been sporadic periods/attempts that effectively attempt
to equate "digital signature" with "human signature" ... possibly because
of semantic confusion since both terms contain the word "signature".
This goes beyond digital signature being able to provide integrity
and authentication (i.e. read, understood, approves, authorizes,
and/or agrees).
we saw one such when we were called into help word smith the
cal. state electronic signature (and later federal) legislation.
misc. past posts
another scenario that can arise is dual-use attack ... where
same private key is used to both digitally sign in authentication
protocol (i.e. presented with random "challenge" from a server
and private key automatically digitally signs the server presented
value; the signing of the server presented random value is countermeasure
to replay attacks against the server) and in the sense of human
signature (read, understood, approves, authorizes, and/or agrees).
The attacker injects a valid document in lieu of random data
in an authentication protocol that automatically performs
digital signatures.
In the 90s, there was some suggestion that possibly a payment
protocol using digital signature ... in a PKI-based paradigm,
the consumer would append a digital certificate indicating
their agreement with the contents of what was being signed
(as opposed to pure integrity and authentication). The choice
of the appended digital certificate would be used to "prove" non-repudiation and subsequently also be the basis for changing the burden of proof in disputes. Since PKI-based
paradigm don't provide for any integrity mechanism as
to what digital certificate was originally appended ... there
was possibly motivation (in such a PKI-based paradigm)
for a relying-party to discover someplace in the world
a copy of a signer's digital certification that would
better suit the relying party's purpose (than the one
that the signer actually appended) ... there would have
been significant financial incentive to the relying
party to change the burden of proof in disputes.
Since that period, the idea of PKI-based paradigms
(and/or digital certificates) being used as basis
for non-repudiation has been severely depreciated.
some of this from security acronym PAIN
P -- privacy (or sometimes CAIN, confidentiality)
A -- authentication
I -- integrity
N -- non-repudiation
encryption provides for privacy/confidentiality ... and
possibly integrity. digital signature provides for authentication and integrity
at various times in the past, some PKI-based paradigms
have attempted to make claims that digital signatures
also imply non-repudiation ... and could equate to
imply intent and equivalence with human signature
(read, understood, approves, authorizes and/or aggrees).
past posts mentioning dual-use attack and/or changing
 Sender and receiver non-repudiation
 [FYI] Did Encryption Empower These Terrorists?
 Invisible Ink, E-signatures slow to broadly catch on
 dual-use digital signature vulnerability
 dual-use digital signature vulnerability
 dual-use digital signature vulnerability
 dual-use digital signature vulnerability
 dual-use digital signature vulnerability
 dual-use digital signature vulnerability
 MD5 collision in X509 certificates
 two-factor authentication problems
 Digital signatures have a big problem with meaning
 massive data theft at MasterCard processor
 massive data theft at MasterCard processor
 the limits of crypto and authentication
 Is there any future for smartcards?
 Contactless payments and the security challenges
 [Clips] Banks Seek Better Online-Security Tools
 Court rules email addresses are not signatures, and signs death warrant for Digital Signatures
 Shifting the Burden - legal tactics from the contracts world
 Chip-and-Pin terminals were replaced by "repairworkers"?
 crypto component services - is there a market?
 RealNames hacked. Firewall issues.
 does CA need the proof of acceptance of key binding ?
 PKI/Digital signature doesn't work
 PKI/Digital signature doesn't work
 Digital signature
 New Method for Authenticated Public Key Exchange without Digital Certificates
 New Method for Authenticated Public Key Exchange without Digital Certificates
 Using smart cards for signing and authorization in applets
 [Lit.] Buffer overruns
 Public/Private key pair protection on Windows
 xml-security vs. native security
 Maximum RAM and ROM for smartcards
 Creating certs for others (without their private keys)
 Creating certs for others (without their private keys)
 Question about authentication protocols
 The Chinese MD5 attack
 How good is TEA, REALLY?
 Catch22. If you cannot legally be forced to sign a document etc - Tax Declaration etc etc etc
 Logon with Digital Siganture (PKI/OCES - or what else they're called)
 TTP and KCM
 ABN Tape - Found
 When *not* to sign an e-mail message?
 Beginner's Pubkey Crypto Question
 Basic Question
 sizeof() was: The Perfect Computer - 36 bits?
 John W. Backus, 82, Fortran developer, dies

@_date: 2007-12-29 15:04:37
@_author: Anne & Lynn Wheeler 
@_subject: 2008: The year of hack the vote? 
> The only reason this 'must' be true is because an anonymous and secure
 > payment system is a terror which thankfully our federal governments
 > and central banks protect us from. While Amazon and others obviously
 > like being able to build customer profiles of everyone, I don't doubt
 > that they would be perfectly willing to accept an anonymous payment as
 > long as the money is good (and, of course, that the transaction costs
 > are no more than a credit card and/or the order flow is sufficient
 > that it is worth building support for it).
in the mid-90s, the x9a10 financial standard working group had
been given the requirement to preserve the integrity of the
financial infrastructure for all retail payments ... which resulted
in the x9.59 standard
in the same timeframe, the EU (in conjunction with eu-dpd)
made statements that electronic payments at point-of-sale
should be as anonymous as cash.
this was interpreted as meaning that names should be
removed from payment cards (plastic and magstripe).
the contention was that (because of poor authentication)
retail outlets could cross-check names on the cards against
some other form of "ID". the implication that removing
names might help promote other integrity measures.
in the x9.59 standard, we claimed that the improved
integrity allowed meeting the EU-DPD objectives.
We also claimed that x9.59 was privacy agnostic
i.e. it allowed for privacy. The "ALL" requirement
given to the x9a10 financial standard working
group met internet, face-to-face, point-of-sale,
electronic commerce. It also met debit, credit,
ACH, as well as stored-value cards ... aka the
same X9.59 was applicable to *ALL*. In the debit/credit
scenario some countries have "know your customer"
mandates associating account numbers with individuals
... which we claimed was outside the x9.59 standard.
Supposedly with appropriate regulated access to
information, govs can obtain information associating
account activity with individuals.
However, the very same x9.59 standard also works
with stored-value/gift cards ... which doesn't have
similar "know your customer" mandates.
And in fact, most stored-value/gift cards share a lot
of the same exact processing with the debit/credit
processing ... the addition of x9.59 could provide for
the exactly same level of integrity thruout debit,
credit, and stored-value/gift processing.
for other drift, in the mid-90s ... there were some
of the other payment efforts specifically for the
internet which had so much payload and processing bloat
that it made it impractical past the toy demo stage
related recent post on infrastructure provisioning and bloat of
toy demos:
 folklore indeed
about the same time, there were completely different
chip card oriented efforts for point-of-sale. one of the
scenarios of some of the chipcard pilot projects in
the late 90s and early part of this century was that
they managed to increase the vulnerabilities
(magstripe vis-a-vis chipcards)
the common excuse from the period, was that chips
cost so much that it wasn't possible to afford integrity
that actually improved over magstripe. The other
possible observation was that some of the chipcard
efforts were so chip myopic ... that they couldn't
realize that they were actually making it worse
for the overall infrastructure.
A big issue for merchants isn't anonymous payments
... it is cost of doing business. This has been in
the news quite a bit recently in the form of
interchange fees ... recent posts
 folklore indeed
the other area is in the liability related to breaches
(and/or the costs of countermeasures to breaches).
i've mentioned before that we had been called in
to consult with small client/server startup that wanted
to do payments on their server. They had this technology
they called SSL and it is frequently now referred to
as electronic commerce
and then we got dragged into involved with the x9a10
financial standard. as part of attempting to meet the
requirement to preserve the integrity of the financial
infrastructure for all retail payments ... we did some detailed
threat and vulnerability analysis. A big item that came out
were infrastructure vulnerabilities ... breaches, skimming,
harvesting, evesdropping, ... a whole slew of things.
we identified that much of the vulnerability could be
attributed to the account number and transaction
information has diametrically opposing requirements
... 1) it has to be readily available for large number of
different business processes and 2) since the crooks
can use the same information for various kinds of
essentially replay attacks ... the information has to
be kept confidential and never divulged.
we've also talked about this as the dual-use nature
of the information ... and that even if the planet
was buried under miles of (information hiding) encryption,
it still wouldn't be able to prevent information leakage.
So another part of the x9.59 financial standard
was to eliminate the dual-use nature of the information,
making it useless for crooks ... aka x9.59 didn't do
anything to prevent information leakage ... it just eliminated
the information leakage as a vulnerability. a related
recent post
 folklore indeed
from this stand-point ... the x9.59 financial standard addresses
both drastically reducing fraud in the infrastructure as well
as drastically reducing the infrastructure costs for fraud

@_date: 2007-12-29 18:37:03
@_author: Anne & Lynn Wheeler 
@_subject: Death of antivirus software imminent 
Storm, Nugache lead dangerous new botnet barrage
from above:
The creators of these Trojans and bots not only have very strong software development and testing skills, but also clearly know how security vendors operate and how to outmaneuver defenses such as antivirus software, IDS and firewalls, experts say. They know that they simply need to alter their code and the messages carrying it in small ways in order to evade signature-based defenses. Dittrich and other researchers say that when they analyze the code these malware authors are putting out, what emerges is a picture of a group of skilled, professional software developers learning from their mistakes, improving their code on a weekly basis and making a lot of money in the process.
... snip ...
... and somewhat related
Virtualization still hot, death of antivirus software imminent, VC says
from above:
Another trend Maeder predicts for 2008 is, at long last, the death of antivirus software and other security products that allow employees to install and download any programs they'd like onto their PCs, and then attempt to weed out the malicious code. Instead, products that protect endpoints by only allowing IT-approved code to be installed will become the norm.
... snip ...
and post about dealing with compromised machines
 folklore indeed
mentioning sophistication in other ways:
Botnet-controlled Trojan robbing online bank customers
from above:
If the attacker succeeds in getting the Trojan malware onto the victim's
computer, he can piggyback on a session of online banking without even
having to use the victim's name and password. The infected computer
communicates back to the Trojan's command-and-controller exactly which
bank the victim has an account with. It then automatically feeds code
that tells the Trojan how to mimic actual online transactions with a
particular bank to do wire transfers or bill payments
... snip ...
there have been some number of online banking countermeasures for
specific kinds of system compromises .... like keyloggers ... but they
apparently didn't bother to get promises from the crooks to only limit
the kinds of attacks to those exploits.
some related comments on such compromised machines
 2007: year in review
 2007: year in review

@_date: 2007-02-03 10:04:18
@_author: Anne & Lynn Wheeler 
@_subject: man in the middle, SSL 
My oft repeated comment about when we were asked to consult with this small
client/server startup that wanted to do payments on servers .... and had this
technology called SSL ... The browser was to check that what the person typed in ... matched the domain name
in the digital certificate that the server provided (that the server that the client
thot they were talking to was the server that they were talking to).
There was some other ancillary things that we were interested in ... that the digital certificate actually represented something more ... i.e. it was issued by the acquiring
financial institution that financially stood behind the merchant .... since the merchant
was already paying a lot of money to cover doing business. however, that never happened
... so the digital certificate just represents that it belongs to the owner of the domain.
this issue is somewhat touched on in this blog posting
 EV - what was the reason, again?
in this blog
However, early on, merchant webservers found that that doing SSL for the whole shopping
experience cut their thruput by something like 80-90 percent ... so the industry fairly
quickly switched to just using SSL for the payment/checkout portion when you click on
their button. Now the URL is being provided by the server (button) ... not by the client,
as a result the effect is no longer "is the client talking to the server that the
client thinks they are talking to" ... since the server is supplying both the URL
and the digital certificate ... the result is "the server is the server that the
server claims to be" (unless it is a really dumb crook/attacker).
It isn't sufficient for their to be "ssl certificates" to be countermeasure to MITM-attack,
the security process has to include that the server is validated against something the client supplies ... not that the server is validated against something the server supplies
(i.e. i can prove that i am whoever i claim to be ... not that i can prove that i am who
you think i am).
This is also behind a lot of the phishing stuff ... that the attacker can claim to be
something ... and provide a field/button for you to click on ... the SSL certificate
then just proves that the server matches the URL provided by the field/button;
since the attacker supplier field/button is producing the URL ... and not the client ... it takes advantage of the difference, for a MITM-attack ... between the opening/crack
opened by what is claimed for the button and what the URL actually is ... since only the URL is being validated by the SSL certificate  ... not what the client thinks is claimed for the field/button. some more comments in these posts:
 "New Universal Man-in-the-Middle Phishing Kit"?
 Securing financial transactions a high priority for 2007
lots of past posts mentioning MITM-attacks
i.e. you have to understand the end-to-end business process (of security) ... where all
the cracks are ... and just which (of possibly large number) MITM vulnerability ...
that you have specifically created a countermeasure for.
so one of the things that we did as part of early deployment (of this stuff that has since come to be called electronic commerce) was go around and do some detailed end-to-end audits
of these emerging operations that were calling themselves certification authorities and
producing these things that were being called SSL domain name digital certificates.
At the time, we coined this term "certificate manufacturing" to try and differentiate
what was happening
and what was in the literature about "public key infrastructure" ... for a little topic
drift ... proposal from 1981 for a (small i) infrastructure:
 more secure communcation over the network
Part of the "audits" was figuring out just what it was they were doing as part of the process that they were calling "certification" ... as the business process supporting the technology
that produced the actual digital certificates (i.e. a credential/certificate that is a
stand-in representation of that certification they were performing). this gave rise to
a lot of comments/observations about if the domain name infrastructure actually provided
a direct, higher integrity operation ... it would obsolete any requirement for having
external certification operations (and therefor also obsolete the certificates as representations of those certification operations) ... lots of past posts mentioning
such catch-22 scenario
For other topic drift ... a recent post/comment about the early x.500 stuff
 IBMLink 2000 Finding ESO levels
and recent posts with comments about early x.509 identity certificate stuff
 SSL info
 SSL info
 SSL info
 The logic of privacy
 Securing financial transactions a high priority for 2007
 The logic of privacy

@_date: 2007-02-03 13:33:52
@_author: Anne & Lynn Wheeler 
@_subject: man in the middle, SSL ... addenda 
man in the middle, SSL
basically digital certificates were designed as the electronic equivalent for offline distribution of information ... paradigm left over from the letters of credit and letters of introduction out of the sailing ship days (and earlier). as things moved into the online age ... certification authorities and digital certificates moved into generic low-value/no-value market segment. this is the difference between a generic employee badge for door entry ... that is identical for all employees ... vis-a-vis doing stuff specific and tailored to each employee.
this is somewhat the x.509 identity certificate example mentioned in the original post ... from the early 90s ... overloaded with personal information and paradigm that promoted repeatedly spaying the identity certificates all over the world. by the mid-90s, it was starting to dawn that such a paradigm wasn't such a good idea ... and there was retrenchment to "relying-party-only" certificates which basically only contained public key and some sort of record location (which contains the "real" information). however, in the payment sector ... even these truncated relying-party-only certificates still represented enormous payload and processing bloat
especially when it was trivial to demonstrate that you could have the public key along with all the other necessary information in the designated record ... and that the digital certificate was redundant and superfluous. This is also somewhat the scenario raised in the domain name infrastructure for on-file public keys .... creating a significant "catch-22" for the ssl domain name certification authority industry
... just upgrade the existing domain name infrastructure with on-file public keys (a requirement also suggested by the ssl domain name certification authority industry) ... but that can quickly result in a certificate-free, public key infrastructure
.... also the reference from 1981
 more secure communication over the network
i.e. for the most part now ... SSL is just be using to prove that you have some valid domain
name ... and the domain name you claim is the domain name you have ... this is somewhat equivalent to the low-value door badge readers to simply check are you some valid employee ... w/o regard to any higher value scenario requiring specific detail about which valid employee.
so one of the points i repeated raise is that while digital certificates (as representation of some certification) is part of an offline paradigm construct ... and in the migration of the world to online environment ... digital certificates have attempted to find place in the no-value/low-value market niches ... that as soon as there is some online component (like record locater) ... it then becomes trivial to show that such digital certificates become redundant and superfluous.
so SSL domain name infrastructure was originally primarily to address what came to be called electronic commerce (and still may be the primary use) .... for:
1) is the browser actually talking to the webserver that the person thinks it is talking to
2) hide (encrypt) the account number during transmission over the internet.
there have been some number of technical implementation vulnerabilities with respect to SSL and things like MITM-attacks ... but the big business process issue was that the deployment fairly early changed from "is the browser actually talking to the webserver the person thinks it is talking to" ... to "the browser is talking to the webserver that the webserver claims to be" (since the same webserver was supplying both the URL and the digital certificate confirming the webserver supplied URL).
The second feature of ssl (encrypting to hide transmitted account numbers) was somewhat to put transactions flying over the anarchy of the world-wide Internet ... on "level play field" with the transactions that flew over dedicated telephone wires. However, the major vulnerability during that period ... and continuing today ... wasn't evesdropping the transaction during public transmission ... but vulnerabilities at the end-points .... which SSL does nothing to address. The end-point webservers somewhat increased vulnerabilities (compared to non-internet implementations) since a lot of the transaction logs became exposed to attacks from the internet. This matter is slightly debatable since the long term studies ... continuing up thru at least recently is that seventy percent of the resulting fraudulent transactions involve some sort of "insider".
So 1) the resulting major deployments of SSL negating much of the original countermeasure against MITM-attacks (related to integrity issues in the domain name infrastructure) and the 2) encryption only slightly put internet transactions on same playing field vis-a-vis the non-internet transactions ... and did nothing to address the major vulnerabilities (at least with regard to the fraud related to the kind of transactions that might happen over the internet ... whether the actually fraudulent transactions occurred over the internet or not).
So after working on the stuff currently called electronic commerce ... we did some stuff in the x9a10 financial standard working group ... which in the mid-90s had been given the requirement to preserve the integrity of the financial infrastructure for all retail payments (ALL as in ALL ... and not just internet). the result was x9.59 financial standard
in the security PAIN acronym
P ... privacy (sometimes CAIN and confidentiality)
A ... authentication
I ... integrity
N .... non-repudiation
SSL was being used for privacy/confidentiality attempting to prevent leakage of the account number.
The x9a10 working group observation was that the account number was needed in large number of different business processes ... and couldn't just be simply kept hidden. This somewhat resulted in my periodically repeated comment that the planet could be buried under miles of encryption and still not prevent account number leakage. This is because the account number is required (unencrypted) in a large number of different places.
So effectively ... x9.59 standard could be described as substituting "authentication" and "integrity" for "privacy/confidentiality" in order to preserve the integrity of the financial infrastructure. X9.59 transactions can be exposed all over the place ... during transmission over the internet, security breaches involving transactions logs ... etc ... and the attackers still wouldn't be able to use the information to perform fraudulent transactions. It was no longer necessary to hide (encrypt) the account number and/or the transactions to prevent fraud ... the information could be widely publicly exposed and the crooks wouldn't be able to use the information for fraudulent transactions. In that sense ... x9.59 eliminates one of the primary uses of SSL for hiding electronic commerce transactions (hiding transactions) and some suggested improvements in the domain name infrastructure integrity eliminates most of the rest ... i.e. MITM-attacks.

@_date: 2007-02-05 10:42:48
@_author: Anne & Lynn Wheeler 
@_subject: man in the middle, SSL 
somewhat related Study Finds Bank of America SiteKey is Flawed
Study Finds Security Flaws on Web Sites of Major Banks
The Emperor's New Security Indicators
from above:
We evaluate website authentication measures that are designed to protect users from man-in-the-middle, "phishing", and other site forgery attacks. We asked 67 bank customers to conduct common online banking tasks. Each time they logged in, we presented increasingly alarming clues that their connection was insecure. First, we removed HTTPS indicators. Next, we removed the participant's site-authentication image---the customer-selected image that many websites now expect their users to verify before entering their passwords. Finally, we replaced the bank's login page with a warning page. After each clue, we measured whether participants entered their passwords or withheld them.
... snip ...
somewhat the issue ... from previous posts in this thread:
 man in the middle, SSL
 man in the middle, SSL
and recent post/thread from early last month on the subject
... originally SSL was going to prevent man-in-the-middle attack because the person
knew the website that they were going to talk to and the corresponding URL. They would
enter that URL into the browser and the browser would validate that the contacted website
was in fact the website for that URL (assuming the entered URL was HTTPS and not HTTP)
early on, SSL was perceived to be too expensive,  and so relegated it to just checkout/payment.
now the user entered URL with HTTP and the website wasn't validated ... so could be man-in-the-middle. at some point the user clicked on https (checkout/payment) button provided by the website. now instead of HTTPS validating that the user was talking to the webserver that they thot they were talking to ... HTTPS was validating that the webserver was whatever webserver that the webserver was claiming to be
(since the webserver was providing both the HTTPS URL and the SSL digital certificate).
so as the user convention of clicking on provided buttons proliferated ... the cracks/gaps widened between what webserver the user thot they were talking to and the webserver they might actually be talking to (since there was less & less a connection between what they thot of as a browser and the URLs that were being validated by SSL).
So one of the possible countermeasures was for a website to provide unique "something you know" authentication ... i.e. something hopefully only you knew (so you had higher degree of confidence that you were actually talking to the website you thot you were talking to. The problem was that if the communication was already talking to man-in-the-middle website impersonation ... there is nothing that would prevent the man-in-the-middle from impersonating the website to the consumer ... and impersonating the consumer to the actual website. Effectively, by definition for man-in-the-middle, the man-in-the-middle transparently passes communication in both directions (except possibly modifying URLs and internet addresses contained in the traffic as needed).
in effect, the mechanism is a countermeasure to simple website impersonation attacks ... but not to website man-in-the-middle attacks.
other refs
 "New Universal Man-in-the-Middle Phishing Kit"?
 Securing financial transactions a high priority for 2007
misc. past posts mentioning man-in-the-middle attacks

@_date: 2007-02-05 11:41:28
@_author: Anne & Lynn Wheeler 
@_subject: News.com: IBM donates new privacy tool to open-source Higgins 
from above:
The encrypted credentials would be for one-time use only. The next purchase or other transaction will require a new credential. The process is similar to the one-time-use credit card numbers that Citigroup card holders can already generate on the bank's Web site.
... snip ...
past post:
 News.com: IBM donates new privacy tool to open-source Higgins
... so if you had to go to the credential issuing website every time you needed a one-time use credential (one-time use is countermeasure to replay attacks involve static data credentials) ... what mechanism are you using to authenticate yourself to the credential issuing website.
if the mechanism for authentication to the credential issuing website is of reasonably strong security ... then why don't you use that mechanism directly in the regular transaction ... rather than having to have an intermediary credential involved.
this is somewhat the argument used about digital certificates being redundant and superfluous in an online environment ... whatever was used to acquire the (x.509 identity) digital certificate ... especially a relying-party-only digital certificate
to avoid repeatedly spraying personal information all over the world ... just use that interaction directly ... and avoid the superfluous and redundant digital certificate.
this is the certificateless public key infrastructure operation
in the x9.59 financial standard transaction
or in the similar FAST transaction (for matters other than financial transaction authorization) done by FSTC in the 90s
one might claim that this new mechanism is another approach to addressing the enormous privacy exposure represented by the x.509 identity digital certificates from the early 90s ... but my oft repeated claim is that the while credentialing and certificate paradigm is left-over from the offline era. in the online era ... if the relying party either 1) has their own online information and/or 2) has online, realtime access to the responsible authoritative agency or institution ... then credentials and certificates purely represent relics predating online infrastructures.

@_date: 2007-02-06 08:40:18
@_author: Anne & Lynn Wheeler 
@_subject: man in the middle, SSL 
i.e. it is a countermeasure to a impersonation attack ... not a man-in-the-middle
(impersonation). all it presumably attempts to address is "are you talking to the website you think you are talking to" ... which is the same thing that SSL countermeasure to man-in-the-middle is supposed to be doing.
man-in-the-middle can defeat simple impersonation countermeasures by impersonating the server to the client and impersonating the client to the server ... and (somewhat) transparently passing traffic in both directions. requiring the server to present unique "something you know" authentication information is then straight forward for man-in-the-middle by having access to the "real" server.
i would contend that the issue for introducing sitekey ... was that SSL wasn't adequately protecting against man in the middle attacks ... i.e. previous posts
 man in the middle, SSL
 man in the middle, SSL ... addenda
 at 28 man in the middle, SSL
... however, i contend that sitekey isn't even designed to be countermeasure against man-in-the-middle attacks ... it only is a countermeasure against simple impersonation attacks ... so it isn't even addressing the short-comings in SSL that (my opinion) gave rise for the need for sitekey in the first place.
the other issue is that "your own image and phrase" is a shared secret (and a flavor of static "something you know" authentication) ... so it presumably requires similar practices required for password shared secrets ... if it had turned out to significantly address SSL short-comings (mitm-attacks) and saw wide deployment .... then presumably you would need a unique flavor for every unique security domain (ala password shared secrets). The implication then is that it would scale as poorly as password shared secret paradigm.
previous post mentioning that the paradigm might scale as poorly as other shared secret based authentication implementations
 Special characters in passwords was Re: RACF - Password rules
misc. posts mentioning man-in-the-middle attacks
misc. posts mentioning shared secret (authentication) paradigm

@_date: 2007-02-07 11:44:28
@_author: Anne & Lynn Wheeler 
@_subject: man in the middle, SSL ... addenda 2 
so the assertion in the previous post
 man in the middle, SSL
was that sitekey as being introduced because of shortcomings in SSL countermeasures to
man-in-the-middle attacks .... however sitekey only deals with simple impersonation
and is easily defeated with a man-in-the-middle attack
in earlier post
 man in the middle, SSL
there was reference to SSL attempting to address man-in-the-middle attacks and "are you really talking to the server that you think you are talking to". however, SSL might be better characterized as verifying that the operator of the webserver is the owner  of the corresponding domain name ... aka a digital certificate & pki operation  demonstrates that the operator of the webserver has use of the private key that corresponds to the "public key" in the digital certificate ... bound to the domain name. The browser than validates that the domain name in the URL is the same as  the domain name in the (validated) digital certificate.
one of my assertions is that problems cropped up when the public started associating
webservers with buttons that they clicked on ... significantly degrading any association in most of the publics' mind between URLs and the webserver. Since
the public weren't effectively associating URLs with webservers ... and the only
function provided by SSL (as countermeasure to man-in-the-middle attacks) was validating the correspondence between the URL and the webserver .... a widening security gap
exists between the "buttons" that the public associate with webservers and the URL,
which is the unit of validation by SSL
one conclusion is if countermeasures are introduced that don't actually
address the actual security vulnerabilities ... then they may not be able
to eliminate those security vulnerabilities.
so one countermeasure that has been introduced (to close some part of the security gap) is by some of the email clients which look for "buttons" in the content ... and if the label of the button appears to be a url/http ... it checks if the actual url/http is the same as the claimed url/http. if they don't match ... the email client will flag the email as potential problem. The simple countermeasure by attackers ... is to not use a http/url label for the button (i.e. just label the button something else, say the name of some financial institution).
Another kind of approach trying to close the gap between what the people associate with webservers and the actual URL used ... is to take a page out of PGP and have a list of "trusted" urls (or at least domain names). Browsers display the assigned trust level recorded for that domain name used in the URL (and then SSL verifies that the webserver contacted is actually the webserver for that URL). This would start to provide a mechanism  for closing the gap between what the public deals with and the part of the infrastructure being checked by SSL.
(at least) two problems with this approach:
1) a repository of URL trust levels is almost identical to a trusted public key repository (directly used by PGP). the repository could directly record both the URL, the public key  for that URL as well as the associated trust level. this would be another demonstration  of digital certificates being redundant and superfluous in an online world and would provide  the basis for a more trusted
environment than the current SSL operation .... misc. past posts mentioning
certificateless public key operation
2) so the new (old) attack is social engineering attempting to get people to click on various  buttons that change the trust level in their local trust repository. however, that also  exists today ... social engineering to get people to load certification authority digital certificates into their local (certificate authority public key) repository.
so number  doesn't eliminate all possible attacks ... however, it actually addresses one of the identified security vulnerabilities/attacks ... as opposed to supplying "fixes" for things other than what is actually broken.  lots of past posts mentioning ssl domain name certificates .... including posts in
long thread about the certificates providing more of a feeling of "comfort", as opposed to actually security, integrity, trust, etc. note that  in attempt to close the gap between what the public associates with websites ... and what is SSL is validated for a website (i.e. some chance that the operator of a webserver reached by the domain name in the URL is the same as the owner of that domain name) ... it can actually close some of the gaps ... but in doing so, it increases the need for endpoints with some level of integrity ... and/or it leaves the end-points as possibly the weaskest link in the trust chain. also as outlined in  the possibly integrity improvement that comes from a local trust repository ... can also result in making digital certificates even more redundant and superfluous (doesn't reduce the need for public key operations ... just further reduces the need for digital certificates as a trust mechanism) ... this is similar to other examples where improving levels of trusts, also reduce the need for digital certificates as a trust mechanism ... misc. related posts on the subject

@_date: 2007-02-13 08:35:17
@_author: Anne & Lynn Wheeler 
@_subject: Failure of PKI in messaging 
looking at the ssl domain name certificate uptake scenario ... there was
a combination of things ... lots of publicity so that consumers perceived it providing
some benefit, merchants perceiving that the consumers would feel better about
it ... and therefor (for merchants) that it was worthwhile to shell out the money ... and
lots of financial interests providing for publicity and support to have
it ubiquitously deployed (to encourage merchants to shell out the money).
lots of past posts mentioning the whole ssl domain name certificate part of the problem was that the PKI financial model is out of kilter with
standard business practices. nominally a relying party has some sort of
relationship with the certification authority (i.e. what they are
relying on) and there is exchange of value between the two parties.
In the standard PKI model, there frequently is absolutely no relationship
between the relying party and the certifying agency. The "owner" of the
digital certificate is paying the certifying agency ... not the relying
party ... so there is typically no exchange of value between the
certifying agency and the relying party ... and therefor the relying party has no foundation for actually relying on the certifying In early 90s ... there was some attempt to sidestep the lack of business
foundation for PKI ... by defining X.509 identity certificates, frequently grossly overloaded with personal information and then getting gov. regulations mandating the certificates. There were also attempts to up the anty
with semantic confusion attempting to equate "digital signatures"
with "human signatures". misc. past posts about helping word
smith various electronic signature legislation and/or the wide
divide between "digital" and "human" signatures.
Remember that the (late 80s and) early 90s (with the attempts at ISO x.509 identity
certificates) was also in the period when you saw various institutions
and govs. mandating the elimination of the internet and its replacement
with ISO (OSI model) networking standards.
one might even contend that in the ssl domain name certificate scenario ...
that once all the hype and publicity is stripped away ... that a fundamental
issue is that the "relying party" has absolutely no recourse with regard
to the certifying agency when things go wrong (which would exist in normal
business relationship between two parties). That the "padlock" symbol
is purely a representation of the hype and publicity ... and not a fundamental
business foundation.
recent thread about one of the major, fundamental justifications for ssl domain name
certificates ... countermeasure to man-in-the-middle attacks ... and not being
very effective
 man in the middle, SSL
 man in the middle, SSL
 man in the middle, SSL
 man in the middle, SSL
 man in the middle, SSL

@_date: 2007-02-13 09:41:27
@_author: Anne & Lynn Wheeler 
@_subject: Failure of PKI in messaging ... addenda 
Failure of PKI in messaging
another way of looking at the issue is somewhat alluded to in this blog post
 Extended Validation - setting the minium liability, the CA trap, the market in browswer governance
somewhat contrasting SSL domain name certificate with association branded payment instruments.
the association logos also promote a feeling of comfort for people doing transactions ... but they have quite a bit of regulatory and policy standing behind those transactions for the benefit of the consumer ... something that you don't find in any of the ssl domain name certificate operations.
at least in some of the PKI publicity and hype ... the concept was conveyed that a relying party could base trust purely on a digital certificate ... that the existence of a digital certificate provided all the trust that anybody would ever need. however, there is a big gap in the level of recourse provided to a consumer using an association branded payment mechanism ... and the recourse provided to a consumer (relying party) by the existence of a digital certificate.
i would contend that basic fundamental asymmetric cryptography defined business process that allowed an individual to somewhat equate digitally signed electronic communication nearly equivalent to having face-to-face communication with an individual; aka it provided for authentication and integrity. there was no sense of "trust" ... the concept of trust was something that was associated with an individual or entity ... digitally signature somewhat put electronic communication on level playing field with face-to-face communication ... allowing it to be associated with a specific individual or entity. The issue of "trust" was separate from being able to depend on that equivalence.
this starts out purely as certificateless operation
or this email from 1981 discussing using public key for secure communication
 more secure communication over the network
various PKI related publicity and hype from the 90s basically attempted to equate digital certificates (added to an underlying public key operation) would actually
provide the basis for "trust" between two parties that had no previous interaction (aka this
is the letters of credit/introduction from the sailing ship days scenario). part of the issue was that there was frequently nothing that actually provided recourse to
the parties in the event that something didn't go quite as expected (which is present
in the association branded payment mechanisms). such publicity/hype may also account
for any confusion that ssl domain name certification ... while only the basis for the owner
of a domain name is likely also the operator of a webserver (addressed by that domain name) ... rather than actually the basis for a webserver that a person
thinks they are talking to is actually the webserver they are talking to.

@_date: 2007-02-14 09:16:27
@_author: Anne & Lynn Wheeler 
@_subject: Failure of PKI in messaging 
Failure of PKI in message
 Failure of PKI in messaging ... addenda
note that merchant interchange fee works this way ... i.e. the merchant
wanting to know whether it gets paid when you present your card
recent posts with some interchange fee references
 Securing financial transactions a high priority for 2007
 Securing financial transactions a high priority for 2007
 Securing financial transactions a high priority for 2007
 Securing financial transactions a high priority for 2007
doing the original deployment of what currently has come to be called electronic commerce,
there was some investigation whether the payment infrastructure would issue certificates
... since they were already certifying merchants for processing of payment transactions
(and the digital certificates then become representation of that certification).
As mentioned before, merchants were already paying fairly hefting interchange fee
to effectively insure consumer transactions ... that would have somewhat boxed-in/capped
fees for ssl domain name certificate operations ... which weren't providing anything
... other than a lot of publicity and hype convincing public that they should feel
good about digital certificates ... previously referenced posting in this blog
 Extended Validation - setting the minimum liability, the CA trap, the market in browser governance
as i've often mentioned before ... this is probabily why the fed gov. PKI has GSA signing contracts with certification authorities ... effectively them making them agents of the
federal gov. ... so there is avenue for recourse and business reliance between the
federal gov as the relying party and the fedreal gov as the certificate issuing operations
(thru their agents via contractual relationship) ... i.e. effectively a relying party PKI operations
the argument then is that in an online environment, the relying-party digital certificates
are redundant and superfluous. The two diminishing market segments are 1) the original design point for digital certificates, situation where the relying party has no repository of their own regarding prior relationship with the certified entity and/or have no timely connectivity to a certifying agency
2) no-value operations where the value of the transaction can't justify relying parties keeping their own records and/or doing a real-time transactions.
both of these remaining PKI market segments are rapidly shrinking as internet online connectivity becomes ubiquitous and as the costs of dataprocessing and networking continues to drop.
as mentioned numerous times, in effect, x9.59 financial standard just augmented existing payment transactions with digital signature for authentication and integrity.  there were no requirement for digital certificates ... for a wide variety of reasons ... in addition to being redundant and superfluous ... the digital certificates represented an enormous payload and processing bloat that providing no fundamental added value
the x9.59 consistent application of digital signature for authentication and integrity ... w/o requiring any certificates
also eliminated simply "knowing" the associated account number as a vulnerability ... that then eliminates a lot of the risk currently associated with phishing and data breaches. x9.59 didn't eliminate phishing and data breaches .... it just eliminated attackers being able to utilize a lot of the acquired information for fraudulent purposes.
With a pervasive use of SSL in the world today as support for electronic commerce ... primarily
to hide account numbers during transit thru the internet ... x9.59 basically eliminates that need .... effectively substituting authentication and integrity for encryption (used to hide the account number).
So a level set ... rather than asking how to fix PKI for messaging ... since there are
a lot of process and practices effectively result in its failure ... start at a simpler
level regarding what are the authentication requirements for messaging. Digital signatures
and public keys might then be looked at for satisfying those authentication requirements
... w/o necessarily requiring the heavy-weight bloat and business process overhead related
to a PKI deployments.
misc. past posts mentioning the GSA PKI scenario where contracts with certifying authorities
effectively make them agents of the federal gov (creating a recourse and basis for relying)  Misc. payment, security, fraud, & authentication GAO reports (long posting)
 Setting X.509 Policy Data in IE, IIS, Outlook
 Using crypto against Phishing, Spoofing and Spamming
 "doing the CA statement shuffle" and other dances
 Shifting the Burden - legal tactics from the contracts world
 Proposal for a new PKI model (At least I hope it's new)
 New Method for Authenticated Public Key Exchange without Digital Certificates
 single-signon with X.509 certificates
 The Worth of Verisign's Brand
 The Worth of Verisign's Brand
 Creating certs for others (without their private keys)

@_date: 2007-02-16 09:28:17
@_author: Anne & Lynn Wheeler 
@_subject: Failure of PKI in messaging 
part of x9.59 financial standard
was to consistently require (digital signature) strong authentication and integrity on all transactions. as a result, phishing, data breaches, security breaches (with regard to account numbers) was eliminated as risk vector (account numbers could be divulged, phished, breached, etc ... but couldn't be used for fraudulent purposes). this also eliminated needing SSL for electronic commerce transactions (as part of hiding account numbers). in the online model ... don't require independent stand-alone/offline paradigm credentials ... just need a reliable authentication mechanism that is reasonably resisted to attacks. sort of as part the x9.59 effort ... in the later half of the 90s, was the aads chip strawman as countermeasure to software private keys being easily compromised ... i.e. digital signature becomes a "something you have" authentication operation ... i.e. it represents having unique hardware token containing the private key that generates the digital signature. the next issue was hardware token costs ... both the costs of individual hardware tokens ... as well as the aggregate infrastructure costs related to institutional centric model with each institution issuing their own hardware token.
the first part was addressed by eliminating everything thing from the chip that wasn't in direct support of (security) of "something you have" authentication ... and the other was moving from a "institution centric" hardware token to a "person centric" hardware token. Moving to a "person centric" hardware token also turns out to eliminate a bunch of institutional hardware token personalization costs.  The objective was aggressive cost reduction gaining possibly two orders of magnitude on per chip .... and instead of requiring a unique hardware token effectively replacing every password a person currently uses ... just have one (or a small few) tokens per person. Institutional specific credentials go away ... since the increase the per chip issuing costs and  tend to eliminate person-centric operation (resulting in unique chips per institution).
This makes the hardware token ("something you have") authentication much more analogous to biometrics ("something you are") authentication. The hardware token for digital signature ... is presented in very much the same way a RFID chip (with static number vulnerable to replay attacks) might be presented ... or a fingerprint is sensed (again w/o being subject to replay attacks) .... but not requiring any other infrastructure, institutional, or application specific processing (it becomes a single function ... authentication, unlimited multi-app ... for whatever apps require authentication ... implementation).
A couple of the remaining vulnerabilities are
1) social engineering attacks getting victim to directly perform operations on behalf of
the attacker.
2) direct chip attacks to give up private key
current phishing tends to be convincing the person that they have to divulge some piece of information to verify and/or in support of other operations. the attacker then uses the information to perform fraudulent transactions w/o the victims knowledge. social engineering to perform operations on behalf of the attacker would tend to raise alarms in more peoples minds and possibly has less fraud ROI ... since it would presumably require more effort on the attacker's behalf for each fraudulent transactions. another possible social engineering operation is to convince the individual to "return" their hardware token (possibly as part of some required exchange operations). This would be easier done with the institutional-centric model ... since the victims would associate the token with the institution ... rather than believing they "owned" the token (in a person-centric model).
the issue in direct chip attacks is attempting to keep the cost of the attack somewhat higher than reasonable expected returns for the attacker ... i.e. part of this is parameterized risk management. the other is try and have the various chip attacks reasonably take longer than the typical lost/stolen reporting interval ... i.e. associated with an online transaction model. If the chip attacks cost more than the reasonable return to the attacker ... or the attack typically takes longer than avg. remaining lifetime before a lost/stolen report deactivates the chip.
In the parameterized risk management scenario ... the risk profile is registered for each kind of chip ... while there is possibility of a single kind of chip serving all possible operations ... there may be a case for multiple kinds of chips that have different costs and risk profiles. Some scenarios might require an individual to have a (person-centric) chip with a significantly better risk profile (being able to perform transactions with values up to the limit of a particular kind of chip risk profile). This may not provide extensive countermeasures to the possible kinds of attacks ... but it may be sufficient to provide countermeasures to 99percent of the current attacks (and make many of the remaining kinds of attacks financially unattractive).
In the past, i've somewhat facetiously stated that the aads chip strawman with person-centric approach and aggressive end-to-end cost reduction could reduce fully loaded hardware token infrastructure deployment costs by four orders of magnitude (reducing both per chip costs as well as total aggregate number of chips for scenario where hardware token authentication becames pervasive, say replacement for all existing password/pin operations).
One of the scenarios is that there is currently a significant amount of operations around hardware token paradigm that approach it from the profit perspective ... as opposed to approaching it from the cost perspective ... suggesting that total, fully loaded hardware token deployment costs are potentially reduced by four orders of magnitude has downside effect on many visions of profit.
disclaimer ... neither of us are associated with the owners of the aads chip strawman
patent portfolio
misc. past posts mentioning person-centric hardware token authentication paradigm
 maximize best case, worst case, or average case? (TCPA)
 To live in interesting times - open Identity systems
 massive data theft at MasterCard processor
 the limits of crypto and authentication
 Another entry in the internet security hall of shame
 thoughts on one time pads
 Crypto to defend chip IP: snake oil or good idea?
 Crypto to defend chip IP: snake oil or good idea?
 Crypto to defend chip IP: snake oil or good idea?
 Why security training is really important (and it ain't anything to do with security!)
 MP cost effectiveness
 MP cost effectiveness
 were dumb terminals actually so dumb???
 Maximum RAM and ROM for smartcards
 Security via hardware?
 public key authentication
 Innovative password security
 Hi-tech no panacea for ID theft woes
 RSA SecurID product
 RSA SecurID product
 Caller ID "spoofing"
 Gen 2 EPC Protocol Approved as ISO 18000-6C
 OT - hand-held security
 Device Authentication - The answer to attacks lauched using stolen passwords?
 Special characters in passwords was Re: RACF - Password rules
 special characters in passwords
 One Time Identification, a request for comments/testing

@_date: 2007-02-16 11:50:50
@_author: Anne & Lynn Wheeler 
@_subject: New Credit Cards May Leak Personal Information 
New Credit Cards May Leak Personal Information
from above:
You may be carrying a new type of credit card that can transmit your personal information to anyone who gets close to you with a scanner.
The new cards--millions of which have been issued over the past year--use RFID, or Radio Frequency Identification, technology. RFID allows scanners to use radio signals at varying distances to read information stored on a computer chip. ... snip ...
this is somewhat discussed in recent post
 Failure of PKI in messaging
i.e. x9.59 eliminating divulged account number as a vulnerability ... effectively substituting
authentication & integrity for privacy/confidentiality (leading to claim that x9.59 was privacy agnostic)
The other item mentioned in the article was leaking names. Part of the x9a10 financial standard working group ... starting in the mid-90s ... was taking into account of an EU-directive (from the period) that electronic point-of-sale transactions should be as anonymous as cash. Somewhat the x9a10 assertion was that name on credit card was required so that point-of-sale clerk could do additional authentication by matching that name with the name on various forms of identification. Given a sufficiently high integrity authentication implementation ... the additional forms of authentication could be eliminated and therefor the name on the card could be eliminated.
This also goes along with similar earlier discussions about RFID-enabled passposts
 Flaw in RFID-enabled passports
 Flaw in RFID-enabled passports (part 2?)
i.e. avoid unnecessarily spraying personal information all over the world
 News.com: IBM donates new privacy tool to open-source Higgins
the parallel was drawn between these mechanisms deploying static data personal identification information infrastructures and the x.509 identity digital certificates from the early 90s ... also raising their own enormous privacy issues. In that period, there was even suggestions that the x.509 identity digital certificates could be overloaded with sufficient personal information that they could also serve as electronic driver licenses and passports.
In the x9.59/aads model ... simple strong authentication and integrity is used with sufficient countermeasures for things like replay attacks and other kinds of exploits ... eliminating requirements for significant amounts of additional personal information for transactions

@_date: 2007-01-04 13:13:51
@_author: Anne & Lynn Wheeler 
@_subject: SSL (https, really) accelerators for Linux/Apache? 
for lots of topic drift about fast transactions and lightweight SSL
(somewhat related to past assertions that majority of SSL use has been
e-commerce related)... recent post in thread on secure financial
 Securing financial transactions a high priority for 2007
having some discussion about this news URL from today:
Faster payments should not result in weaker authentication
... other posts in the same thread:
 Securing financial transactions a high priority for 2007
 Securing financial transactions a high priority for 2007
 Securing financial transactions a high priority for 2007
so having done a lot of optimization on the original payment gateway
and some other SSL uses ... some of it mentioned in this thread
(to help minimize payment transaction elapsed time):
 SSL info
 SSL info
 SSL info
now, in the above thread, I've discussed the possible "catch-22" for
the SSL domain name certification industry however, in the past, I've also discussed leveraging the "catch-22"
to implement a really lightweight SSL ... somewhat similar proposal
mentioned here in old email from 1981
 more secure communication over the network
and a couple past posts discussing really lightweight SSL in the context of the catch-22 scenario:
 Another entry in the internet security hall of shame
 GP4.3 - Growth and Fraud - Case  - Phishing
 X.509 and ssh
So after the initial e-commerce activity ... there were some number of
efforts in the mid-90s to improve the internet payment technologies
...  two such activities were SET and X9A10. The financial standards
X9A10 working group had been given the requirement to preserve the
integrity of the financial infrastructure for all retail payments (not
just internet) ...  resulting X9.59
I had gotten ahold of the SET specification when it was first
available and did a crypto-op profile and calculated some crypto-op
performance for typical SET transactions. Some number of people
associated with SET claimed that my numbers were off by two orders of
magnitude (too large by a factor of one hundred times) ... however
when they eventually had running code ... my profile numbers were
within a couple percent of the measured numbers. On an otherwise idle
dedicated test infrastructure, a simple SET transaction was over 30
seconds elapsed time ... nearly all of that crypto-op processing.  In
a loaded infrastructure, contention and queueing delays could stretch
that out to several minutes (or longer). Besides the enormous processing bloat ... there was also a lot of protocol chatter and
enormous payload bloat. misc. posts:
by comparison, X9.59 had to be a lightweight payload, lightweight
processing, and fast transaction that was applicable to all
environments (not just the internet).
x9.59 went for lightweight payload transaction that could complete in
a single transaction roundtrip, with strong end-to-end security
(applicable whether the transaction was "in-transit" or "at-rest").  It
effectively substituted end-to-end strong authentication and strong
integrity for information hiding encryption. X9.59 also eliminated knowledge of the account number as a fraud exploit
and therefor eliminated the need for the most common use of SSL for
hiding account numbers in e-commerce transactions (i.e. for really
high performance and lightweight SSL is when you don't have to do it
at all).

@_date: 2007-01-06 13:43:33
@_author: Anne & Lynn Wheeler 
@_subject: Tamperproof, yet playing Tetris. 
a couple mentions of the same	
Game over for Chip and PIN?
Hacked Chip and PIN terminal plays Tetris
Chip and Pin fraud alert
misc. past posts on related vulnerabilities and exploits
as an aside ... some of the "overlay" type of exploits that make the news about automatic teller machines have also been used with point-of-sale terminals ... somewhat a man-in-the-middle attack ... even if it is only being used for skimming information (as in most of the automatic teller machine scenarios) .... aka how does the consumer know they are dealing with the real-terminal ... or an MITM/middle-man terminal? various past posts mentioning MITM-attacks
the EU finread standard attempted to address some of the same issues ... providing tamper resistant personal-use terminals (addressing some of the same tamper resistant characteristics as point-of-sale terminals)
two of the issues
1) is the transaction you "see", the same as the transaction you "approve"
2) independent pin-entry ... as countermeasure to the numerous PC-based keylogging vulnerabilities there is somewhat reduced concern that a terminal (that you always have physical possession
of) ... being subverted with some sort of overlay technology (i.e. there isn't an actual
attack the tamper-resistant characteristics of the operating point-of-sale terminal ... but there is a MITM overlay). Cellphone and PDAs use at POS have also been suggested
as countermeasure to the variety of point-of-sale terminal exploits.
In X9a10 financial standards working group .... recent mention in this post
 SSL (https, really) accelerators for Linux/Apache?
one of the things looked at for X9.59 standard
was how can the relying/authorizing party really know the integrity characteristics of the transaction environment. so x9.59 allowed for the transaction environment (point-of-sale terminal, finread terminal, etc) to also digitally (co-)sign the transaction. the authorizing party can
look-up the integrity characteristics of the terminal used in the transaction environment (and also have some assurance that terminal was actually used for the transaction based on verifying its digital signature with onfile public key).

@_date: 2007-01-08 11:41:36
@_author: Anne & Lynn Wheeler 
@_subject: Tamperproof, yet playing Tetris. 
... and has now made slashdot ....
Chip & PIN Terminal Playing Tetris
previous post
 Tamperproof, yet playing Tetris
recent related comments
 FC07 Preliminary Programme - Leaving Room for the Bad Guys
and a whole lot of past comments

@_date: 2007-01-17 19:07:01
@_author: Anne & Lynn Wheeler 
@_subject: It's a Presidential Mandate, Feds use it. How come you are not 
PC/RT had external scsi disk drive housing ... with scsi disk drive "bricks" that could be removed from the housing and locked in safes (when the owner wasn't physical present). This was later part of the '80s ... twenty some years ago.
nearly 35 yrs ago ... there was this enormous corporate project and all the information on the project was kept strictly confidential. a whole bunch of security features were added to prevent leakage of any of the information. they even went so far as to claim that even I couldn't access the information ... even if I was physical present in the room. It was one of the few times that I actually took the bait ... I claimed it would only take me a few minutes ... I found the location in memory of the authentication routine and patched one byte so all returns from the routine indicated valid authentication (most of the time was spent disabling all access to the machine from outside the room since i didn't want a real compromise).
This is similar ... but different to more recent "yes card" vulnerability ... where the card is asked if the correct PIN has been entered ... and a "yes card" always responds "YES". Would appear to work not only for skimming scenario and counterfeit card .... but also as a MITM-attack with valid card. misc. past posts mentioning "yes card"
In any case, my claim way back then (nearly 35yrs ago) was that the only countermeasure to such physical access was encrypting the data. Later, I even did prototype filesystem as example ... but at the time ... the processor load was excessive (would typically only be justified for small subset of extremely sensitive information).
The project back then was called Future System
and was canceled w/o ever being announced. However there were some comments that the amount spent on the failed future system project would have bankrupted any other computer company.
misc. past posts admitted to haven once risen to the bait in my brash youth.
 old manuals
 command line switches
 Some credible documented evidence that a MVS or later op sys has ever been hacked
The scenario was that if I had physical access ... there were a whole variety of compromises that wouldn't have been possible otherwise .... at least for these class of systems ... small footnote about some deployments ... which i didn't find out until sometime later
Note that when it started becoming common for people taking portable terminals and later PCs on the road ... for off-site access (reading email, etc) in the very early 80s ... there was vulnerability study done ... and one conclusion was that one of the most weakest points is a hotel PBX closet ... which resulted in design, build and deployment of custom encrypting 2400baud modems for all off-site dial-in access. I'm periodically quite dismayed by the cavalier way that many corporations have treated off-site access over the past 20 years. For other comparison, the corporate network, which was larger than arpanet/internet from just about the beginning until possibly sometime mid-85. required link encryptors on all lines that left a corporate facility ... and sometime in the mid-80s there were comments that the internal corporate network had over half of all the link encryptors in the world (these are things like leased lines ... separate from the encrypting dial-up modems).

@_date: 2007-01-30 10:14:47
@_author: Anne & Lynn Wheeler 
@_subject: News.com: IBM donates new privacy tool to open-source Higgins 
this was somewhat the issue with x.509 identity certificates from the early 90s,
they were being overloaded with personal information ... and then the proposal
that everybody should then "spray" such digital certificates frequently all
over the world. in this period, they were also being touted for use in
electronic driver's licenses, passports, etc.
In the mid-90s, with the realization of the enormous privacy exposures of
such a paradigm ... there was some parties retrenching to relying-party-only
certificates ... basically a record pointer ... which was then used as
reference to the record with the necessary information ... and only the
absolutely necessary information was then divulged.
however, it was trivially possible to demonstrated that the actual
digital certificate was redundant and superfluous ... all that was
necessary was the record pointer, a digital signature ... and the
responsible agency could verify the digital signature with public
key on file ... at the same time they processed the request using
the record pointer.
This was basically the FSTC organizations
model for "FAST" (financial authenticated secure transaction). The transaction
is mapped into existing ISO 8583 message and uses the existing infrastructure
operations. Rather then divulging age, a FAST (/8583) transaction ... digital
signed by the individual ... could ask whether the person meets some age
criteria, address criteria, etc ... getting YES/NO response ... w/o divulging
any additional information (like actual date of birth). This was modeled
after existing (ISO 8583, debit, credit, etc) financial transaction which effectively asks whether the merchant gets paid or not (simply YES/NO
This is also, effectively the X9.59 financial standard
The X9A10 financial standard working group, in the mid-90s was given the
requirement to preserve the integrity of the financial infrastructure for
all retail payments. The transaction is sent with digital signature,
the responsible agency validates the digital signature, examines the
transaction request and then responds YES/NO regarding whether the
merchant gets paid or not.
The other characteristic of X9.59 was that it included a business rule that
"X9.59" account numbers couldn't be used in non-X9.59 transaction. That
made the associated account numbers (record pointers) unusable w/o the
accompanying digital signature i.e. random people couldn't generate
random (valid) transactions against the account number/record number.
This had the effect of eliminating a lot of the existing skimming/harvesting
It isn't necessary to have an encrypted credential ... since if it was
purely "static data" ... and simply presenting such static data exposes
the infrastructure to various kinds of replay attack. In that sense,
the static data can be any recognizable information specific to the
responsible agency handling the transaction. The "static data" is used
by the responsible party to lookup the actual information (including,
if necessary the public key)  ... and the digital signature on every transaction prevents various kinds of replay attacks ... that might be
possible in an infrastructure relying on only static data. If the agency is going to lookup something (rather than have it carried around
in large encrypted packet ...) then it becomes immaterial whether the
actual (static data) record locator is encrypted or not.
related post in this thread:
  Securing financial transactions a high priority for 2007
  Securing financial transactions a high priority for 2007
  Securing financial transactions a high priority for 2007
with reference to recent news items somewhat touching on the same subject:
Latest Breach May Force a New Approach to Data Security
Analyst: Banks Must Make Credit Card Accounts Useless to Data Theives
this is somewhat related to my periodic references that existing infrastructure could
bury the planet under miles of (information hiding) encryption and still not prevent
account number linkage ... somewhat related old post about security proportional to risk
misc. past posts with reference to FSTC's FAST
 checks (was S/390 on PowerPC?)
 Ask about Certification-less Public Key
 AADS/X9.59 demo & standards at BAI (world-wide retail banking) show
 more on privacy
 CFP: PKI research workshop
 CFP: PKI research workshop
 FSTC to Validate WAP 1.2.1 Specification for Mobile Commerce
 DOD prepares for credentialing pilot
 PKI International Consortium
 Improving Authentication on the Internet
 More Phishing scams, still no SSL being used
 More Phishing scams, still no SSL being used
 More Phishing scams, still no SSL being used
 X.509 and ssh

@_date: 2007-07-01 08:23:00
@_author: Anne & Lynn Wheeler 
@_subject: The bank fraud blame game 
The decade or so old EU FINREAD standard is along this line ... sort
of modeled after point-of-sale terminal ... includes its own display and
pinpad (countermeasure to keyloggers). lots of past posts mentioning
EU FINREAD standard
the actual communications that enter and leave aren't required to
be encrypted ... the communication that enter are revalidated on
the display ... and the communication that exits is on the order
of an x9.59 transaction
that are armored with digital signature (integrity and authentication)
... misc. posts mentioning "naked" transaction metaphor
old aads chip strawman from nearly decade ago postulated form factor
agnostic ... that could even be added to existing pda/cellphone for
a lot less and communicate wirelessly.
in the mid-90s, the x9a10 financial standard working group had been given
the requirement to preserve the integrity of the financial infrastructure
for all retail payments. part of the detailed end-to-end threat and
vulnerability analysis was not only the end-point vulnerabilities
but also the large number of business processes that are giving rise
to security breaches and data breaches that have frequently made
the press. part of x9.59 transaction armoring was that all the
transaction information could be readily exposed and still not
be useful to attackers for performing fraudulent transactions.
This was countermeasure to all the breaches ... regardless of whether insiders or outsiders were involved ... it was recognized that
the transaction information had to be exposed in a large number
of business processes. Recognizing the impossibility of eliminating all such information exposure ... the x9.59 approach
was to eliminate the risk and fraud associated with such exposures
(i.e. impossible to eliminate all the breaches ... so eliminate
the risk and fraud associated with such breaches).
We had previously been called in to consult with small client/server
startup that wanted to do payment transactions on their server
and had this technology called SSL that they wanted to use. The
issue in SSL was that it hid the information was moving across
the internet ... but left it totally exposed at all other
points (and in fact the numerous business processes required
such exposure). the x9.59 approach was then to try and eliminate
all such exposures ... but to eliminate the risks associated with
all exposure of the information (in effect, armoring the transaction
w/o requiring the information to be hidden as countermeasure to
fraudulent transactions).

@_date: 2007-07-01 10:06:45
@_author: Anne & Lynn Wheeler 
@_subject: The bank fraud blame game 
The bank fraud blame game
slight addendas ...
1) EU finread
one of the issues that we looked at early on in x9.59 standard ... somewhat related
to the EU finread ... was what proof did the financial institution have as to the integrity of the originating end-point (for doing risk assessment purposes). With
this motivation, X9.59 standard allowed for multiple digital signatures ... which
could include device authentication for finread-like devices (giving some assurance
as to the integrity of the originating end-point)
2) liability
there appears to be a lot more motivation for improving assurance in the online
banking scenario ... say, as opposed to e-commerce and retail payments. in the
e-commerce and retail payments ... financial institutions can charge off a lot
of fraud to the merchants (buried in things like interchange fees). in the online
banking scenario, merchants aren't part of the scene ... just leaving the consumer
and the financial institutions as the responsible parties.
misc. recent financial news items ...
Police arrest three suspects in credit card investigation (fraud)
ACH Fraud: Clearing House Aims To Clean House
Mobile wallets to replace payment cards - report
Debit Scam used 'parasite' pin pads
Shoppers 'easy prey' for debit card fraud
... in the early aads chip strawman (from the 90s)
form-factor agnostic in user "owned" pda/cellphone were countermeasure
to foreign, unfamiliar POS-terminals that possibly were compromised
(i.e. paranoid consumers could have some responsible control over
their own devices ... as opposed to POS-terminals at random merchants)

@_date: 2007-07-01 13:38:14
@_author: Anne & Lynn Wheeler 
@_subject: The bank fraud blame game 
The bank fraud blame game
 The bank fraud blame game
i.e. to large extent, the existence of the EU finread standard is proof
of attempt at countermeasures to the (known) PC integrity weaknesses.
the original electronic-commerce adopted the MOTO model (mail-order/telephone-order) which placed significant responsibility
on the merchant ... AND there was some presumption that physical
goods were involved, shipping to a known address. SSL was used as
compensating process, in theory, placing internet-order on level playing field with MOTO.
as electronic-commerce deviated more & more from the
MOTO-model and related assumptions ... there were increasing
risks and vulnerabilities.
one of the early problems ... in the electronic-commerce genre ...
was what to do with purely internet merchants. in the standard
MOTO model ... there is consumer financial institution, financially
responsible for the consumer and merchant financial institution,
financially responsible for merchants (with merchant interchange
fees largely underwriting the whole environment). merchant financial institutions tended to sponsor merchants where there were physical assets available for seizure ... equivalent to a month or two of credit card transactions. With every transaction
passing thru the sponsoring organization (or its agent), the merchant
financial institution had real-time knowledge of the outstanding exposure and risk (and was capable of cutting things off at a moments notice).
However, a lot of internet merchants were setting up as purely order fulfillment organizations with little in the way of physical assets.
In the early electronic commerce days there were some intense lobbying
that went on with the risk management departments in merchant financial institutions.
But as mentioned in previous post ... the move to online banking ...
removes the merchant completely from the picture (it is no longer
the electronic commerce MOTO-model) ... leaving just the end-user
and their financial institution as the responsible party.
In the mid-90s, financial institutions looking at the internet for
online, commercial banking and cash management (i.e. business equivalent to consumer online banking) were extremely conflicted ... they frequently were almost insisting on their own appliance at the business (and low-end of SOHO at least overlaps high-end
of consumer online banking).
Various of the PC-based dedicated financial applications go to
quite some lengths to compensate for kind of vulnerabilities
typically associated with browser activity. For instance,
instead of relying on a trusted third party to certify that
some remote location really has a valid digital certificate,
they have a trusted repository of valid financial institutions.
This is somewhat the equivalent of the table of certification
authority trusted third parties built into browsers ... but
instead of table of certifying parties that can certify other
parties ... it is table of the actual financial institutions.
This has the added benefit of eliminating the horribly complex
and vulnerable PKI-type of operation (an don't rely on certification
of something totally unrelated to financial transaction operation,
but instead rely directly on known financial transaction operation).

@_date: 2007-07-01 14:49:40
@_author: Anne & Lynn Wheeler 
@_subject: The bank fraud blame game 
The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game
there was a detailed analysis of the 99/00 smartcard deployments ... looking at the most common causes for problems. this was overlapped with opinion
claimed to be widely held among consumer financial institutions, that it had been proven that smartcards were not practical in the consumer market segment.
for something of a lark, at the annual smartcard conference, i went around to
most of the booths asking people at the booth if they were 1) aware that the financial industry considered smartcard not practical in the
consumer market segment and 2) what was the cause of the majority of the
some of the major deployments selected to be pc/sc compliant ... which at the
time only supported serial port attachment ... and did not support USB plug&play.
It turned out that the vast majority of smartcard deployment problems in that time-frame
had to do with consumers trying to install serial port card readers, consumers
that couldn't find the serial port, serial port connections that conflicted with
something else, serial port conflicts, serial driver conflicts (large number of BSOD and consumers having to re-install their systems from scratch).
there was then a very complex and intricate series of negotiations getting
agreement to upgrade pc/sc to support USB plug&play (for starters, responses like why even bother since it had been proven already that smartcards weren't practical in the consumer marketplace ... ignoring for a moment that major
factor in the failures was the pc/sc serial port limitations) . There were also things like  alternative packaging ... USB keyboard with built-in smartcard reader, display,  and PIN-pad cut-out switch ... where keyboard incremental cost was more like $5  (but again, it required PC/SC to be upgraded to USB plug&play)
however, by that time, nearly every where you went, there were echos that it (some
deployment or another) had proven that smartcards were not practical in consumer environment. Note that it wasn't just consumer limited, there were instances where commercial  operations figured that it would be on the order of $500/PC to be able to handle PC/SC serial port smartcard reader attachments.
it was in the midst of these particular disasters that you also saw some of
the smartcard operating system projects being canceled (again the spreading
belief that smartcards were not practical in the consumer market place).
All of this can be pretty much put at the doors of the institutions failing
to understand some of the fundamental issues attempting to deploy serial-port
PC/SC in the PC market place of the time (and/or understand that large
driver behind doing the whole USB plug&play thing was the significant problem
and issues attempting to deal with the serial port implementation)
some number of past posts mentioning the whole PC/SC serial port problems
encountered with various attempts at smartcard deployments in the
PC/consumer marketplace
 Welome to the Internet, here's your private key
 Spring is here - that means Pressed Flowers
 Status of SRP
 Convenient and secure eCommerce using POWF
 Convenient and secure eCommerce using POWF
 ftp authentication via smartcard

@_date: 2007-07-01 17:33:59
@_author: Anne & Lynn Wheeler 
@_subject: The bank fraud blame game 
The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game
there had been lots of home banking with PCs starting in the 80s. these
were dial-up into private bank modem pools (both consumer and
business cash management). one of the trade-offs looking at
going to internet based operation is the enormous infrastructure
savings to financial institutions. in 1995, a presentation by one financial institutions figured that they were supporting something like 65 different software modem drivers (different modems, different operating systems, different platforms, etc). transitioning to internet met that they could eliminate all of that (lots of help desk, lots of serial port issues, lots of hardware
issues ... a much smaller precursor to the later smartcard PC/SC serial
port disaster).
they talked about what trade-offs were with any conversion to internet, the operating system vendors  and ISPs would  go to a common connectivity operation,  bearing the cost of all  the online connectivity ... amortized over a lot of online use (not just online  banking). This eliminated an
enormous cost for online banking. The downside was that the security issues significantly increased.
the dedicated financial applications have some similarities to
that earlier dial-up phone environment ... except they are using
something akin to a controlled SSL encrypted path (tunneled thru
the internet) where the remote PC application has preloaded information
about the financial institution's server (not needing traditional PKI trusted 3rd party certification authority to provide information about unknown
now with respect to weakness of using PKI for such purposes, i've contended in the past that the image/picture authentication helped increase the possibility that the consumer/client was dealing with valid financial institution (that they had previously registered the image/picture with).
in that sense, it can be viewed as countermeasure to common phishing attacks
... where clients are convinced to click on some field that takes their
browser to some webserver. Given that the attacker can supply both the
actual URL and the corresponding SSL digital certificate ... and majority
of clients have very weak binding between websites and the corresponding
URL (i.e. SSL PKI digital certificate is just checking that the webserver
contacted actually corresponds to the supplied URL) .... then attackers
have found an enormous PKI weak link in the current way SSL is deployed (it relies on the user to provide the binding between the webserver
they think they are talking to and that webserver's URL ... where
SSL PKI is then only providing the binding between a URL and a webserver).
As a result, active MITM attacks have happened ... where consumer is convinced to click on a field purported to connect them to their
financial institution. The attack actually provides a URL to their
own webserver for which they have a valid SSL digital certificate ...
then they can transparently pass communication between the real
financial institution website and the consumer (with two different
SSL sessions connected at the attackers website) ... aka the image/picture
authentication stuff is to imcrease the sense of comfort a customer
would have that they are actually talking to their financial institution
(in view of all the SSL short-comings ... however, it doesn't actually
preclude the security attacks).
lots of past posts mentioning MITM-attacks
some specific past posts about MITM-attacks and bank site authentication
 Citibank discloses private information to improve security
 man in the middle, SSL
 man in the middle, SSL
 man in the middle, SSL ... addenda 2
 Threatwatch: MITB spotted: MITM over SSL from within the browser
 Securing financial transactions a high priority for 2007
part of this harks back to when were originally called into consult
with this small client/server startup that wanted to do payments on
their servers ... they had this technology called SSL they wanted
to use and it has since come to be frequently called electronic commerce
the end-to-end security "assumptions" at the time was that the user
would type into the browser, the URL of the website they wanted to
connect to. This created the trusted binding between the website the
user wanted to talk to and the URL. Then the browser using SSL, digital
certificates, PKI, etc ... would validate the correspondence between
the URL and the webserver that was actually contacted (two part trust
operation, both required).
however, fairly early in the deployment, merchants found that using
SSL for the whole shopping experience cut there thruput by 90-90 percent.
as a result, they cut SSL use back to just the part for payment.
Now the user can enter a URL ... and it isn't validate with SSL ...
so the user can be talking to an attackers website. Then when they
go to pay/checkout ... they click on a button (provided by potential
fraudulent website). The button provides the URL for the checkout
portion ... allowing an attacker to provide both the URL and an
digital certificate that corresponds to that URL.
Now longer is SSL being used to provide the correspondence between
the webserver that the user thinks they are talking to and the webserver
they are actually talking to ... the user is getting both the
URL and the digital certificate off the net ... so all an attacker
has to show that the URL they claim to be is the URL that they
have a valid digital certificate for. lots of past posts about SSL (and effectively SSL digital certificates
turning into a "comfort" item as opposed to a real security feature)
For other topic drift, in the mid-90s at one of the large security
conferences (in the US), one of the large German banks gave a talk on relying
party only digital certificates ... lots of past posts mentioning
RPO certificates
They had realized that the X.509 identity digital certificates from the early
90s and potentially overloaded with enormous amounts of personal information ...
represented significant privacy and liability issues. As a result, they
had retrenched to RPO-certificates containing little more than an account
number (or other kind of record locater) and public key ... if you actually
wanted to do something ... it was necessary to read the information from
the correct account. It wasn't just large German financial institutions that
had come to this realization ... numerous financial institutions were retrenching from the x.509 identity digital certificates of the early 90s.
Note, however, examining all the business processes that would make use of
RPO-certificates ... we were able to demonstrate that it was trivial to
include the public key in the specified account record ... making the associated PKI and digital certificates redundant and superfluous.
This also significantly influenced our work on the X9.59 financial standard
in the X9A10 financial standard working group (which in the mid-90s had been
given the requirement to preserve the integrity of the financial infrastructure
for all retail payments)
It wasn't just that the RPO-certificates were redundant and superfluous. The
typical RPO-certificates being tested in that time-frame were contributed
enormous payload bloat (PKI and digital certificate payload overhead was
on the order of one hundred times larger than the typical financial transaction
size). misc. past posts mentioning the enormous payload bloat of redundant
and superfluous digital certificates
In the same timeframe as x9a10 work on x9.59, the X9F committee was attempting
to take another approach. They had a standard work item for "compressed" digital
certificates (objective to try and get payload bloat of RPO-certificates and PKI
overhead down to possibly only 5-10 times larger than the base financial transaction One of their suggested approaches ... was that all fields that were common to
an issuers RPO-certificate would be eliminated ... i.e. only the fields that
were unique to every RPO-certificate would be included. I had a slightly different
suggestion ... instead eliminate all fields in the RPO-certificate that the
financial institution already had on file for the entity. Since by definition,
it could be shown that the financial institution already had all fields (if nothing else from having issued the RPO-certificate in the first place),
then it would be possible to eliminate all fields, reducing an RPO-certificate
to zero bytes. So as an alternative to deploying a certificateless public key infrastructure
it would be possible to deploy a fully functional PKI operation that depended
on attaching zero byte digital certificates to every transaction (which would
also address the enormous PKI payload bloat). some old posts discussing the
enormous advantages of a PKI with zero byte digital certificates
 cardtech/securetech & CA PKI
 cardtech/securetech & CA PKI
 KISS for PKIX. (Was: RE: ASN.1 vs XML (used to be RE: I-D ACTION :draft-ietf-pkix-scvp- 00.txt))
 KISS for PKIX. (Was: RE: ASN.1 vs XML (used to be RE: I-D ACTION :draft-ietf-pkix-scvp- 00.txt))
 Public Key Infrastructure: An Artifact...
 Thin PKI won - You lost
 X9.59 Electronic Payment Standard
 revised Shocking Truth about Digital Signatures
 Simple PKI

@_date: 2007-07-01 19:53:40
@_author: Anne & Lynn Wheeler 
@_subject: TPM, part 2 
as i've mentioned before ... we looked at somewhat similar hardware solution
(but much simpler) for the original acorn (ibm/pc code name), primarily as software piracy countermeasure  ... but the tamper resistant technology state of the art at the time was way too expensive ... and investigation was dropped. what was seen during
the 80s were things like those specially encoded floppy disks ... that had to be inserted when you started the application ... a couple past posts/references:
 Device Authentication - The answer to attacks lauched using stolen passwords?
 Enterprise Right Management vs. Traditional Encryption Tools
 Patents, Copyrights, Profits, Flex and Hercules
in the late 90s i would periodically chide the TPM folks about what
they were doing ... and at an assurance talk i gave in the trusted computing
track at intel developers forum (spring 2001), i chided the guy running
the effort (was sitting in the front row) that it was nice to see that over the previous couple yrs that TPM had started to look more & more
like the AADS chip strawman. his retort was something about it being
because I didn't have a committee of couple hundred people helping
me with (my) chip design. misc. past posts mentioning aads chip strawman

@_date: 2007-07-02 09:50:15
@_author: Anne & Lynn Wheeler 
@_subject: The bank fraud blame game 
there is an interesting side story to this involving certification, common criteria,
protection profiles, etc.
possibly the majority of the smartcard protection profiles have to do with all the
problems allowing software/application to be loaded. on the other hand, you can
get a common criteria evaluation done on the basic chip ... w/o any application
loading ... and being able to show a much higher security level ... than might be
possible with any application actually loaded.
one of the problems i ran into getting higher than eal4+ for aads chip strawman
... was since everything was built into the silicon at manufacturing time, and nothing could be subsequently loaded ... all the crypto had to also be resident
in the silicon. one of the original objectives given for the aads chip strawman was being able
to do digital signature in contactless form factor within transit gate elapsed
time requirements (very low power and very fast) ... which eventually fell to
doing ec/dsa ... and i couldn't get an protection profile definition for ec/dsa
higher than eal4+.  similar chips ... w/o anything loaded had been able to
get eal5+ evaluation (or better) ... but since ec/dsa was built into the chip silicon,
it was only possible to get eal4+.
the other criteria for aads chip strawman was extremely aggressive cost reduction;
i had joked i was taking a $500 milspec part, cost reducing by 2-3 orders of
magnitude and at the same time increasing the integrity. part of the aggressive
cost reduction was choosing a single function ("something you have" authentication
via chip digital signature) that could be used in a broad range of applications ...
and eliminate everything else.
misc. aads
other posts in this thread:
 The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game

@_date: 2007-07-03 10:29:19
@_author: Anne & Lynn Wheeler 
@_subject: The bank fraud blame game 
given the recognition of the serial port issues from the earlier, dial-in
online banking ... providing a strong motivation to transfer responsibility
for all such problems to ISPs (under the guise of moving to the internet)
 The bank fraud blame game
that even the transfer of a little bit of institutional knowledge would
have enabled the avoidance of later smartcard reader deployment disasters
 The bank fraud blame game
However, following some of the early "yes card" deployments
it appeared to be more of a case where smartcard organizations were
very narrowly focused on purely smartcard issues and ignoring everything else.
that aspect was highlighted in an early presentation about circumstances
surrounding the "yes card" ... and there was a somewhat
uncontrolled comment from somebody in the audience "do you mean to say that they managed to spend a  billion dollars to prove that chips are less secure than magstripes".
misc. old posts/threads mentioning the pc/sc serial port issue & smartcard
reader deployment disasters
 Spring is here - that means Pressed Flowers
 Status of SRP
 Convenient and secure eCommerce using POWF
 Convenient and secure eCommerce using POWF

@_date: 2007-07-03 10:48:48
@_author: Anne & Lynn Wheeler 
@_subject: a fraud is a sale, Re: The bank fraud blame game 
thread from earlier this year ... when over a period of a month or
so there were several releases that essentially had fraud declining
by 10-15 percent simultaneously with fraud increasing by 200-300 percent.
 Securing financial transactions a high priority for 2007
 Securing financial transactions a high priority for 2007
 Securing financial transactions a high priority for 2007
 Securing financial transactions a high priority for 2007
 Securing financial transactions a high priority for 2007
 John W. Backus, 82, Fortran developer, dies
 John W. Backus, 82, Fortran developer, dies
 John W. Backus, 82, Fortran developer, dies
 John W. Backus, 82, Fortran developer, dies
 nouns and adjectives
this followed an article pointing out that EU financial institutions
had something less than 10percent of their bottom line coming from
payment transaction operation ... while it was closer to 40percent
for US financial institutions.
 IBM Unionization
 IBM Unionization
 My Dream PC -- Chip-Based
and articles about interchange fee represents the single large expense for some retail
 3 of the big 4 - all doing payment systems
 Debit Cards HACKED now
 Value of an old IBM PS/2 CL57 SX Laptop
 Securing financial transactions a high priority for 2007
 Securing financial transactions a high priority for 2007
 John W. Backus, 82, Fortran developer, dies
 Free Checking

@_date: 2007-07-04 06:21:47
@_author: Anne & Lynn Wheeler 
@_subject: a fraud is a sale, Re: The bank fraud blame game 
a fraud is a sale, Re: The bank fraud blame game
for a little bit more background ....
signature-debit fraud has been quoted at 15 times that of pin-debit fraud ... some refs:
 FraudWatch - Chip&Pin, a new tenner (USD10)
 Debit Cards HACKED now
 Debit Cards HACKED now
 John W. Backus, 82, Fortran developer, dies
 John W. Backus, 82, Fortran developer, dies
 John W. Backus, 82, Fortran developer, dies
 IBM Unionization
and so the merchant fees for signature-debit are like an order of magnitude more
than pin-debit (i.e. more on par with credit fees)
in the US, there has been some numbers that walmart accounts for 25-30 percent of
all retail store transactions. several yrs ago they won a class action legal action
against the payment transaction infrastructure.
 John W. Backus, 82, Fortran developer, dies
 John W. Backus, 82, Fortran developer, dies
 John W. Backus, 82, Fortran developer, dies
 John W. Backus, 82, Fortran developer, dies
 John W. Backus, 82, Fortran developer, dies
various refs:
other posts in the previous part of this thread:
 The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game

@_date: 2007-07-04 10:43:49
@_author: Anne & Lynn Wheeler 
@_subject: The bank fraud blame game 
we had gotten tasked to do a design and costing of mondex implementation
in the states (all the transaction processing dataprocessing, sizing
capacity and resources, etc) ... and looking at pricing various kinds
of mondex related transactions ("super brick" from mondex international
and how it flowed thru the rest of the infrastructure).
the conclusion we came up with was that nearly all the financial
justification for mondex was in the float. later there were scenarios
where mondex international was encouraging deployment in various
countries by offering to split the float with the chartered
mondex national body (and then it seemed like float offerings were
starting to peculate down to financial institutions lower in
the mondex hierarchy)
then along came an EU statement that mondex (and similar implementations)
would only be given a grace period with regard to retaining the float
(as a mechanism to underwrite start-up costs) ... but after a period
of 2-3 yrs, they were then going to be required to start paying interest on
balances carried in the cards. after that, much of the interest(?) seemed
to evaporate.
separately there were some issues with the chip technology being
used in the mondex cards.
misc. past posts mentioning mondex.
 7th CACR Information Security Workshop
 IP: Re: Why we don't use digital cash
 AGAINST ID CARDS
 Payment Application Programmers Interface (API) for IOTP
 EMV
 Is there any future for smartcards?
 Payment systems - the explosion of 1995 is happening in 2006
 On-card displays
 EMV cards
 Opinion  on smartcard security requested
 Are you sure about MONDEX?
 Are you sure about MONDEX?
 US fiscal policy (Was: Bob Bemer, Computer Pioneer,Father of ASCII,Invento
 US fiscal policy (Was: Bob Bemer, Computer Pioneer,Father of ASCII,Invento
 Revoking the Root
 Is Mondex secure?
 newbie need help (ECC and wireless)
 John W. Backus, 82, Fortran developer, dies

@_date: 2007-07-04 13:39:51
@_author: Anne & Lynn Wheeler 
@_subject: The bank fraud blame game 
The bank fraud blame game
in the mid-90s a number of US financial institutions looked at the economics
of the EU chipcard electronic purses (modulo the float issue ... which could
be made to work) the issue was that the (much more) expensive chips were
being used to offset the significantly higher PTT costs (and/or just plain
PTT availability) in Europe.
The US could deploy a magstripe authentication card for stored-value ... that
did online transactions using much of the existing online point-of-sale
infrastructure ... for significantly lower overall infrastructure costs
than the EU chip-based offline stored value. The magstripe card basically
became a "something you have" authentication mechanism. The primary trade-off
issue was that the US telecom pricing was so much lower than in Europe
(and lots of 80s & 90s design in europe was being driven by the extremely
high PTT costs and/or, in some cases, lack of PTT availability).
Note, however, the internet along with various telcom and technology changes around the world have contributed to significantly changing the online/offline economic trade-off considerations.
Independent of the online/offline economic issues ... there are some fraud
and security issues that could drive towards using chips for a more secure
"something you have" authentication device.
however, there is some lingering effects from the older high PTT costs
related to chip-based architectures ... and whether there are any residual
design features related to (originally) supporting offline operation.
Part of this could be seen in the "yes card" exploits ... where, transaction
"business rules" were left in the chip implementation (as oppsed to the chip
being purely an authentication mechanism) ... contributing to the enormous vulnerability increase
For the float issue with regard to this class of US gift/stored-value cards ... they are sold as "merchant" cards ... i.e. the kind of gift & stored-value cards
you see used by coffee shops, video rental, grocery stores, large department
stores, etc. Possibly, in part, because they are "merchant" cards ... as
opposed to "bank" cards ... the associated accounts and balances are
pretty far removed from any jurisdiction that might impose payment of
interest. misc. past posts about how the large difference in telecom costs drove different
 Solving the problem of micropayments
 Confusing Authentication and Identiification? (addenda)
 Difference between TCPA-Hardware and a smart card (was: example: secure computing kernel needed)
 Financial identity is *dangerous*? (was re: Fake companies, real money)
 Payment Tokens
 IP: Re: Why we don't use digital cash
 Smart Card vs. Magnetic Strip Market
 Opinion on smartcard security requested
 Opinion on smartcard security requested
 Why?
 Opinion  on smartcard security requested
 Smartcards and devices
 Methods of payment
 Methods of payment
 Maximum RAM and ROM for smartcards

@_date: 2007-07-09 16:55:12
@_author: Anne & Lynn Wheeler 
@_subject: a fraud is a sale, Re: The bank fraud blame game 
a fraud is a sale, Re: The bank fraud blame game
 a fraud is a sale, Re: The bank fraud blame game
recent item with the other side of the issue (as opposed to being able
to profit when merchants have fraud)
Data Security Advanced by New Aleratec Multi-purpose DVD/CD Shredder from above:
Identity Theft and Fraud cost business $600 billion a year, according to the
Association of Certified Fraud Examiners. .. snip ... post from earlier this spring about series of articles essentially appearing
 Securing financial transactions a high priority for 2007
ID fraud down, except credit cards
Survey: ID fraud in U.S. falls by $6.4B
Survey Indicates ID Theft May Be Diminishing
Study: ID fraud in decline
US ID theft losses decline
US ID theft losses decline
ID Theft Is Exploding In The U.S.
ID fraud soaring across the pond

@_date: 2007-06-09 13:17:17
@_author: Anne & Lynn Wheeler 
@_subject: Why self describing data formats: 
gml (precursor to sgml, html, xml, etc) was invented at the science center in 1969 ... some recent (science center) topic drift/references in this post
 mainframe = superserver
"G", "M", & "L" were individuals at the science center ... so the
requirement was to come up with an acronym from the inventors initials
so some of the historical justification for the original "markup language" paradigm
can be found originally CMS had the script command for document formating ... using
"dot" format commands ... i.e. science center on 4th flr of 545 tech sq
doing virtual machines, cp67, cms, the internal network, etc ... and multics
on 5th flr of 545 tech sq ... draw from some common heritage to CTSS (and some
of the unix heritage traces back thru multics also to CTSS).
the original GML was sort of a combination of "self-describing" data (somewhat for
legal documents) and document formating ... when GML tag formating was added to CMS script processing command. Later you find a big CMS installation at CERN ... and HTML drawing heritage from the "waterloo" clone of the CMS script command.
first webserver in the states was at slac (a CERN "sister location) ... another big vm/cms installation:
recent historical post/reference
 old tapes
last time i checked, w3c hdqtrs was around the corner from the old
science center location at 545 tech. sq.
before GML, the science center had an activity involving "performance" data
from the time-sharing service (originally using virtual machine cp67 service
and then transitioning to vm370) ... lots of system activity data was captured
every 5-10 minutes and then archived to tape ... starting in the mid-60s ...
by the mid-70s there was a decade of data spanning lots of different configurations,
workloads, etc. The original intention when the system activity data was being
archived was to include enuf self-describing information that the data could
be interpreted many yrs later. lots of past posts about using cp67&vm370
for time-sharing services (both for internal corporate use and customers offering
commercial, online time-sharing services using the platform)
lots of past posts about long term performance monitoring, workload profiling,
benchmarking and stuff leading up to things like capacity planning
much later, you find things like ASN.1 encoding for handling interoperability
of network transmitted data between platforms that might have different
information representation conventions (like the whole little/big endian stuff).
one of the things swirling around digital signature activity in the mid-90s
was almost religious belief that digital certificate encoding mandated ASN.1. other digital signature operations that were less religious about PKI, x.509 identity digital certificates, etc ... were much less strict
about encoding technique for digitally signed operations ... included
certificateless digital signature infrastructures
One of the battles during the period between XML and ASN.1 proponents
during the period was that XML didn't provide for a deterministic encoding.
It really was somewhat a red herring on the digital certificate ... ASN.1
side ... since they were looking at always keeping things ASN.1 encoded
(not just for transmission) ... and only decoding when some specific information needed extraction.
On the other side was places like FSTC which was defining digitally
signed electronic check convention (with tranmission over ACH or ISO8583).
There was already a transmission standard ... which ASN.1 encoding would
severely bloat ... not to mention the horrible payload bloat that was
the result of any certificate-based infrastructure needing to append
redundand and superfluous digital certificates.
FSTC just defined appending a digital signature to existing payload.
The issue then became a deterministic encoding of the information
for when the digital signature was generated and verified. If you
temporarily encoded the payload as XML, generated the digital signature
... and then appended the digital signature to the standard (ACH or
ISO8583) payload ... the problem was that at the other end,
XML didn't provide a deterministic encoding methodology so that
the recipient could re-encode the payload and verify the digital
signature. So FSTC eventually defined some additional rules for
XML called FSML ... which then was turned over to W3C as part of
XML digital signature activity.
There was something of a cultural class between the FSTC orientation and
much of the x.509 standards environment. In the FSTC world ... the information
is only temporarily encoded for digital signature generation and verification;
the rest of the time, the data is in some native useable form. In the X.509
standards environment, the data tends to always remain encoded in ASN.1
format ... and is only (temporarily) decoded when it is actually needed
to be used/accessed.

@_date: 2007-06-09 13:39:33
@_author: Anne & Lynn Wheeler 
@_subject: Why self describing data formats: 
Why self describing data formats:
for other archaeological trivia ... later i transferred from the science center
to SJR and got to do some of the work on the original relational/sql implementation,
a few years later, the "L" in GML also transferred to SJR and worked on relational,
included being involved in the development of of BLOBS (Binary Large OBjectS) for relational.
roll forward a few yrs to the acm (database) sigmod conference in san jose in
the early 90s. In one of the sessions, somebody raised the question about what
was all this X.500 and X.509 stuff going on in ISO ... and there was somebody
from the audience that explained how it was a bunch of networking engineers trying to re-invent 1960s database technology.
today ... you can periodically find heated online discussion about XML "databases"
and whether they compromise the purity of information integrity that you get
from the relational paradigm. lots of past posts mentioning various things about
system/r, relational database technology, etc

@_date: 2007-06-09 14:27:21
@_author: Anne & Lynn Wheeler 
@_subject: A crazy thought? 
A crazy thought?
for some other topic drift regarding certification authorities ... having been certification
authorities for "digital certificates" targeted at the (electronic but) "offline" market
... they encountered a number of issues in the mid-90s as the world was transitioning
to ubiquitous online operation ... the digital certificates were somewhat targeted for
relying parties ... dealing with total strangers (that they had no prior information
about) and had no timely mechanisms for directly contacting any authorities for
references regarding the stranger.
so one of the issues for x.509 identity certificates ... small x-over from this
other thread
 Why self describing data formats
was to try and move out of the no-value market into the identity market ... aka ...
as world transitioned to ubiquitous online operation ... the remaining "offline"
was "no-value" situations where the relying-party couldn't justify the cost of
maintaining information about the parties that they dealt with (aka something
analogous to browser "cookies") and/or couldn't justify the cost of directly
contacting responsible agencies for information about the parties they were deailing
now in this recent thread ... somewhat about some internet historical  nouns and adjectives
 nouns and adjectives
 nouns and adjectives
 nouns and adjectives
the last posts drifts into the subject of some of the recent "churn" around
"identity" activities ... also lengthy post on the subject here:
 Identity resurges as a debate topic
the certification authorities were somewhat looking at increasing the
value of x.509 identity digital certificates (since there wasn't a lot
of future selling into the no-value market segment) by starting to
grossly overload the digital certificates with enormous amounts of
personal information.
now typically "identity" has been a "authentication" characteristic ...
adding potentially enormous amounts of personal information could be considered attempting to move into the "authorization" area ... where a relying-party might
be able to make a authorization, approval, and/or permission decision purely based
on the additional personal information in the digital certificate.
what was seen by the mid-90s was that many of the institutions were
starting to realize that x.509 identity digital certificates, grossly
overloaded with personal information represented significant privacy
and liability issues. what you saw then was a retrenchment to purely
"authentication", relying-party-only digital certificate
with the digital certificate containing little more than a record
locator (where all the necessary information was actually kept, even real-time,
and aggregated information ... which is difficult to achieve in a stale,
static digital certificate paradigm) and a public key ... note, however, we could  trivially show that in such situations the stale, static digital certificate was redundant and superfluous ... aka just add the public key to the
entity's record ... which already had all the personal, private and
other information necessary for "authorization". in the payments
market segment ... this is somewhat separate from the fact that
the appended stale, static, redundant, and superfluous digital
certificates were causing a factor of 100 times payload and processing
one of the other problems faced by certification authorities attempting
to move "identity" digital certificates into the "authorization" market
segment was what (with loads of personal information), if any, liability were certification authorities going to accept with regard to "authorization" problems encountered by the relying-parties (depending on the digital
certificate personal information in their decision making process).

@_date: 2007-06-09 18:02:10
@_author: Anne & Lynn Wheeler 
@_subject: A crazy thought? 
CAs actually tend to certify that they were able to verify a supplied
digital signature with a supplied public key ... with the implication
that the entity supplied the signature & key ... had access to the
corresponding private key in order to generate the signature
(aka "something you have" authentication model).
CAs then may also certify that they were able to verify some amount
of other information related to the entity supplying the signature
and public key.
the existence of a certified digital certificate with a different
public key ... can be on the order of various kinds of identity
theft ... and as equally difficult to deal with.
for instance ... it may not be sufficient that you can prove that there
are two distinct, different digital certificates ... in the identity
theft scenario ... it may also going to require that the disputed
digital certificate couldn't possibly apply to you (which is more than
just that it is not the same as the digital certificate you are
owning up to).
previous posts in thread:
 A crazy thought?
 A crazy thought?

@_date: 2007-06-09 18:34:42
@_author: Anne & Lynn Wheeler 
@_subject: A crazy thought? 
A crazy thought?
 A crazy thought?
 A crazy thought?
actually ... at a very fundamental level both PKI and PGP have nearly identical
business and implementation processes ... the difference is somewhat that the PKI operations tend to try and make out that their structure is more formal ... and therefor should be more trusted.
Both implementations require that the relying-parties have some sort of local
trusted public key repository ... initially populated with some out-of-bad
process. In the SSL PKI scenario ... there tends to be a trusted public key
repository built into each browser distributed ... initially loaded with
possibly 40-50 public keys that you are told that you can trust. In the
"web of trust" scenario ... there tend to be some set of public keys
that are also trusted and have also been acquired in some out-of-band process.
In both scenarios ... the relying-party is expected to "trust" new public keys
that carry digital signatures ... where these digital signatures can be
verified with public keys from their local repository of (already) trusted
public keys (public keys that have typically been distributed/initialized
by some out-of-band process)
It isn't so much that the fundamental processes are different ... it
is more about how tightly controlled and cast in concrete the surrounding
pieces happen to be (aka formalized and not easily changed/adapted).
For totally other drift ... one of the places we came up with requirement
for multiple digital signatures was in the process for x9.59 financial
infrastructure for payment transactions ... i.e. in the mid-90s, the
x9a10 financial standard working group had been given the requirement
to preserve the integrity of the financial infrastructure for all retail
x9.59 actually doesn't specify the details of digital signature process ...
but defines the fields necessary for a payment transactions which require
authentication and integrity protection on end-to-end basis. one of the
scenarios is the authentication of the account holder with digital
signature (which also provides payment transaction integrity). one of
the trust issues was that their could be various kinds of exploits
at the originating environment (where the account holder's digital
signature and the transaction was otherwise valid). to increase the
trust (as indication of possible countermeasures against these additional
exploits/vulnerabilities) allowed for the originating environment to
also digitally sign the transaction (as a flavor of "device" authentication,
possibly a point-of-sale terminal or other kind of device that was
used to originate the transaction).
the FSTC electronic check work also allowed for multiple digital signatures
... representing the equivalent of requiring multiple co-signers on
business checks ... i.e. business checks that allow for single signer
if the amount is below some limit ... but requires additional co-signers
for larger amounts.
note that both in the FSTC electronic check and the X9.59 financial
standard scenario, there was some assumption that the basic transaction went via normal existing electronic payment networks ... with appended digital
signature(s) ... where the transaction might actually only be encoded
during just the digital signature generation and digital signature verification
processes. recent posts in the encoding thread:
 Why self describing data formats:
 Why self describing data formats:
also any additional appending of traditional digital certificates to such
operations could represent a factor of 100 times payload and processing

@_date: 2007-06-22 10:30:27
@_author: Anne & Lynn Wheeler 
@_subject: A secure Internet requires a secure network protocol 
A secure Internet requires a secure network protocol
from above:
Implementing -- and requiring -- stronger authentication and cryptography standards is the next step toward a new Internet
... snip ...
i would contend that majority of exploits are attacks on (vulnerable) end-points ... not directly involving any actual network protocol or cryptography; this includes
(updated) variations on old-time "social engineering" ... which has some relation to authentication (between end-points) ... but on par with crooks using the telephone to call people and convince them of one thing or another (and then suggesting that encrypting the telephone call transmission would eliminate the problem).
one of the things seen in various of the SSL (authentication) vulnerabilities
... are attackers being able to ("authenticate") prove who they claim to be
... however, who they claim to be for SSL authentication ... and who they
claim to be for their "social engineering" attacks ... may not be exactly the As before, one of the largest class of attacks (not restricted to internet) are against information related to payment transactions and which (largely because of weak authentication in unrelated parts of the infrastructure) is then turned around and relatively easily used for fraudulent financial transactions. misc. past posts on the theme of "naked" transactions.

@_date: 2007-06-23 07:37:02
@_author: Anne & Lynn Wheeler 
@_subject: A secure Internet requires a secure network protocol 
A secure Internet requires a secure network protocol
i.e. we were called in to consult with this small client/server startup that wanted
to do payments on their server. they had this technology they called SSL ... and we
had to end-to-end process audits ... including walk-thru of some of these new business
entities that were calling themselves certification authorities.
the fundamental SSL design point was that the user knows the relationship between a website
and a URL, the user entered that URL, and SSL would authenticate that the website that
the user *thot* they were talking to (from entering the URL), was in fact, the website
they were actually talking to.
these days, most users have no cognition about relationship between websites and URLs, they click on something in email and/or webpages. In this scenario, the attacker
is providing the URL and then the only thing that SSL is providing is authenticating
who the attacker is claiming to be (via the URL that the attacker provides).
the original SSL design point had implicit assumptions that users knew the relationship
between the website they thot they were talking to and URLs (and then SSL authenticated
the relationship between those known URLs and the website). For the most part those
assumptions are no longer valid ... which then breaks the security model and all bets
are off. With the potential attacker frequently providing both the URL and the website,
then the only thing SSL is providing is authenticating the website that the attacker claims to be (via the URL) is the website that they are (breaking original basic
assumption about SSL). This totally invalidates the assumption that SSL is proving that the website that the user *thot* they were talking to (via directly entering the URL) was, in fact, the website that they were talking to (aka the user has
no idea what website they are talking to ... because they no longer have the knowledge
about the relationship between websites they think they are talking to and the URLs
for those websites).
The (*URL*) name to key mapping isn't the problem ... that is the mechanics that SSL provided. The problem was that SSL security had implicit assumption that the
user knew the mapping between the website they think they talk to and the URL for
that website. In the current environment, that assumption is no longer valid,
So the basic, most common PKI infrastructures provide a trusted public key repository
(typically manufactured into browsers before they ship). Users are indoctrinated that
they can trust those public keys ... for the purposes of digitally signing digital
certificates. These digital certificates provide the binding between URL (actually
the domain names part of URL) and website public keys. It is imperative that the
user (knowledge) then provide the binding the website they think they are talking
to and the URL. That is the part that is missing in today's environment (and what
large numbers of attackers can leverage to slip thru the "cracks").
The missing piece is trusted binding between who the user's think they are talking
to and the URL (or at least domain name). This could be accomplished by a separate trusted repository ... names that the end-user relates to and trusted binding between those names
and URLs. Attacker provided URLs that are clicked on ... then can be cross-checked
with things in that new trusted table (analogous to the way that the browser table
of certification authority public keys are trusted).
Then the issue is that if there is a trusted table mapping names to URLs (or at least
domain names) ... and a separate table of trusted public keys ... the whole thing
could be collapsed into a single table ... totally eliminating the level of
indirection provided by (redundant and superfluous) PKI and certification authorities ... just add the public key to the trusted table of names & domain names (aka URLs).
The issue isn't so much that SSL is broken ... it is the implicit dependency on
users knowing the relationship between the website they think they were talking
to and the URL for those websites. Creating a user trusted table of website/urls
(analogous to the browser trusted table of certification authority public keys),
can make PKIs and certification authorities redundant and superfluous ... since
in whatever trusted process is used to maintain the trusted table of website/urls
... can also directly include the public key for those website/urls.
this is similar, but different to some of the domain name infrastructure proposals that
would allow real-time retrieval of on-file, domain name public keys (also making
PKIs and certification authorities redundant and superfluous). Some past posts
discussing catch-22 for PKI infrastructures with real-time domain name infrastructure
public keys
other posts about certificate-less public key operation

@_date: 2007-03-14 10:22:35
@_author: Anne & Lynn Wheeler 
@_subject: PKI: The terrorists' secret weapon 
slightly related URL from this morning
Browser Certs Can't Force Adherence in the past, i've repeatedly asserted that the "I" in PKI filled a need related to
letters of credit/introduction left-over from the offline, sailing ship days.
In on online world, such "I" tends to be redundant and superfluous ... typically representing
an (expensive) duplication of other facilities. Another way of looking at it is that typically cryptography has represented some aspect
of security ... and frequently the common wisdom is that security is something
that is best when built into the basic core business processes and infrastructure ... rather than
some independent add-on. This possibly has contributed to failure of most attempts to
create large revenue flow for some independent crypto/security feature (which frequently
is a characteristic of PKI deployments).
An example is some early to mid 90s proposed PKI deployments as an electronic driver's
license. The (driver's license) PKI certificate supposedly would be grossly overloaded with personal information ... creating enormous privacy issues.  Reliance on
information in the (PKI electronic) driver's license would be substituted for the growing
use of (online) real-time checks .... along with eliminating any of the information
that was becoming available from real-time checking (outstanding warrants, revocation,
overdue parking tickets, etc). Any claims as to real-time checks still could be done,
further highlighted the PKI part being a significantly expensive redundant and superfluous

@_date: 2007-03-14 13:03:09
@_author: Anne & Lynn Wheeler 
@_subject: PKI: The terrorists' secret weapon (part II) 
PKI: The terrorists' secret weapon
so the other way of thinking about the "I" in PKI is that basically PK is an Authentication
mechanism, the "I" frequently stands for attempting to move upstream in the value-chain revenue flow to Identification.
several issues:
1) emulation of the credential/certificate/license paradigm from the offline world (like letters of credit/introduction) is net positive when there is no other avenue for providing the necessary information. it can quickly become redundant and superfluous in any move into the online world.
2) PKI perceived value supposedly increased proportional to the number of attributes (i.e. personal information) included for an entity. however (as repeatedly mention) this
has tended to run into serious privacy concerns. in some quarters rather than value
increasing with the amount of personal information included ... the value increases
as the amount of personal information goes to zero
3) in numerous business processes, having online, real-time information ... tailored specific to the business process ... is significantly more valuable than lots of stale, static offline information.
4) in paradigm change to an online world, the stale, static offline information methodologies
tend to migrate into the no-value market niches ... i.e. business processes that can't
justify the cost of higher-value, real-time information. being moved into no-value market
niches tends to create conflicts with objectives for moving upstream in the value-chain
revenue flows.
5) any significant spending on offline, low-value, stale, static information (credential/certificate/license) paradigm may impact funds available for high-value online real-time operations; aka any costs related to "I" (in PKI) should tend to
zero ... at the same time the associated (personal, identification) information tends
to zero.
lots of past posts about purely PK Authentication operation w/o needing any
stale, static, redundant and superfluous "I" (infrastructure and/or Identification)

@_date: 2007-03-30 16:18:05
@_author: Anne & Lynn Wheeler 
@_subject: Governance of anonymous financial services 
we had done something analogous in the x9.59 financial standard. the x9a10
financial standard group had been given the requirement to preserve the
financial infrastructure for all retail payments. digital signature on the transaction itself provided for end-to-end
strong authentication (armoring payment transaction as countermeasure
to various kinds of replay attacks ... as have been in the news recently
related to large data breaches and then being able to subsequently
use the information for fraudulent transactions).
one of the "problems" was that some of the other attempts at PKI-related
payments protocols in that period ... were creating enormous (two orders of magnitude) processing and  payload bloat
one of the implied x9a10 requirements was efficiency, i.e. mechanism that could be
deployed in ALL environments (internet, point-of-sale, cellphone, etc) ...
and needed to be highly concerned about processing and payload efficiency.
the actual transaction is digitally signed ... and it is also the thing that
is authorized, logged, archived, audited, etc.
so part of x9.59 provided for a hash of the  receipt (contract,  bill-of-materials, sku data, "level 3" data, etc) as part of the digitally signed payload
(as opposed to including the whole receipt). Then in any subsequent dispute,
if both parties didn't produce identical receipts ... the hash from the
audited/logged/archived transaction could be used to determine the
valid/correct receipt.
While the receipt wasn't part of the actual audited/archived/logged transaction,
the process provided a mechanism (in cases of disputes) for establishing the
legitimate receipt.
we claimed privacy agnostic for x9.59 ... i.e. there was an account number in
protocol but the degree that any jurisdiction required a binding between an account number and an individual was outside the x9.59 protocol. x9.59 was
designed so that it could be used for credit, debit, stored value, ach, etc.
In many jurisdictions, credit & debit can have some "know you customer"
requirements for financial institutions (binding between individuals
and account numbers) ... however there was 1) no requirement to divulge
such bindings during retail transactions and 2) x9.59 applies equally
well to stored-value retail transactions (where there is much less
frequently a requirement imposed for "know your customer".

@_date: 2007-05-02 09:29:39
@_author: Anne & Lynn Wheeler 
@_subject: Public key encrypt-then-sign or sign-then-encrypt? 
Public key encrypt-then-sign or sign-then-encrypt?
 Public key encrypt-then-sign or sign-then-encrypt?
there is the issue for some kinds of operations of having integral authentication
and integrity .... or integral authentication and privacy ... or integral privacy and integrity.
so there is the whole issue of semantic confusion with the term digital
signature .... because it contains the word "signature" ... leading to
confusion that it might somehow be related to human signature ... aka
things like intent and a human having read, understood, approves, agrees,
and/or authorizes.
on the other hand ... digital signatures can get into various kinds of
dual-use attacks ... when the same private key is being used in a purely
authentication protocol (server sends random data to be digitally
signed ... as countermeasure to replay attack) ... and also in a
authentication+integrity protocol ... where the contents being digitally
signed is presumed to carry some sort of meaning (and that a digital
just happens to be performed ... carries some additional implication
other than authentication+integrity).
there is this slightly x-over thread from sci.crypt
 public key password authentication
 public key password authentication
 public key password authentication
where there is possibly the suggestion that if the only thing being performed
is authentication (and doesn't require either integrity and/or privacy) ...
then possibly a totally different protocol by utilized (rather than
digital signature) ... to help minimize the apparent extensive (human)
confusion where the same technology might be used for both authentication
only operations as well as authentication plus integrity operations
(and where having the word "signature" in the term also appears to
contribute significant additional confusion).
however, in the x-over thread from sci.crypt ... i mention that if both authentication and integrity are both required ... that potentially
if they are done as separate operation ... that there can be (security)
openings provided to attackers for things like man-in-the-middle attacks.
in the "naked" transaction metaphor mentioned in these postings
it is possible that if authentication is performed separately from any
integrity provisions applied to the actual transactions ... that it may
be an opening for a man-in-the-middle attack (or other kinds of attacks)

@_date: 2007-05-09 13:54:16
@_author: Anne & Lynn Wheeler 
@_subject: Public key encrypt-then-sign or sign-then-encrypt? 
Public key encrypt-then-sign or sign-then-encrypt?
some aspects of this was discussed in old dual-use attack thread ... it possibly isn't enuf to encapsulate all scenarios where the person intends to use the digital signature
in manner analogous to human signature (indicating intent, having read, understood,
authorizes, agrees, and/or approves) .... then if there is ever a digital signature
applied for pure authentication purposes ... say random data from a server (as
countermeasure to replay attacks) ... then all such signed data should always also
be bracketed by disclaimer saying that such signatures are in no way met to imply
agreeing, approving, and/or authorization any message content.
the problem is that digital signatures are an authentication and integrity mechanism,
and except for possible semantic confusion resulting from both "digital signature"
and "human signature" containing the same word ("signature") ... there is no
relationship. a danger of any mis-use of digital signatures as representing
human signatures  ... is if they are also used for authentication ... where the
human doesn't actually physically examine and understand every bit that a
signature might be applied to. if the human doesn't actually physical examine
and understand every bit that they might apply a signature too ... then it
becomes a requirement that all such (signed and unexamined) bits are wrapped with strong disclaimer about any existence of a digital signature is not met to imply read, understood, approves, agrees, and/or authorizes.
... aka any random data not examined, but signed ... could in fact contain padding
and comments about aggreement ... to appear as if the signer actually wrapped
it (instead of the attacker).
lots of past posts discussing "signatures" ... included having been called in
to help word-smith the cal. state electronic signature legislation.
related and slightly facetious posting here:
 survey of RFC S/MIME signature handling
as part of this thread
 survey of RFC S/MIME signature handling

@_date: 2007-05-14 11:46:55
@_author: Anne & Lynn Wheeler 
@_subject: Enterprise Right Management vs. Traditional Encryption Tools 
somewhat aside ... there was an effort in the very early days of the PC
to look at (hardware) countermeasures to software (and other) piracy
(I don't remember whether i was involved shortly before or after the actual announcement of the PC).
starting with 370, the mainframes had unique processor identifications
and licensed software was configured for the specific processor. this
may have been relatively easy to defeat ... but the numbers and costs
involved somewhat created a barrier. It was sufficient to show that
some (illegal) action had to have been taken in order to successfully
because the costs and numbers involved with the PC were so significantly different, individual prosecution was harder to justify ... and so the hardware
countermeasures needed to be much more robust. a problem with the investigation
at the time was that tamper-evident technologies were way too expensive
which contributed to the investigation being shelved.
somewhat in the wake of that ... there were various methods like specially encoded floppy disks as countermeasure to piracy (i.e.
the floppy disks were not trivially duplicated by normal means).

@_date: 2007-05-20 09:03:08
@_author: Anne & Lynn Wheeler 
@_subject: 0wned .gov machines (was Re: Russian cyberwar against Estonia?) 
part of this is that many of the basic platforms providing internet connectivity
evolved from disconnected/unconnected desk/table top environment ... with
lots of applications assuming that they had full & free access to all resources.
attempting to leverage the same platforms for connectivity to extremely hostility
and anarchy of the internet creates diametrically opposing requirements.
one countermeasure from the 60s is to use a dynamically created ("padded cell")
virtual machine for internet connectivity ... with limited scope and accesses.
then when the session completes ... the environment is collapsed and everything
is discarded. while the "native" system operation may have little or no defenses against the hostile internet ... the "padded cell" virtual machine environment is used to bound the scope of any penetration ... somewhat analogous to "air gapping".
recent post:
somewhat older reference:

@_date: 2007-05-21 20:48:19
@_author: Anne & Lynn Wheeler 
@_subject: 307 digit number factored 
in theory, certification authorities charge for the certification operations
that they perform ... and the certificate is just a representation of that
certification process.
somewhere over the yrs the term "certification authority" was truncated
to "certificate authority" ... along with some impression that certificates are being sold (as opposed to certification processes).
doing quicky web search of licensing and certification agencies ... it
looks like there is charge for replacing certificates/licenses ... but
nothing compared to the charge for the original certification process.
of course ... the whole licenses/credentials/certificates are an offline
world paradigm .... licensing, credentialing, and certifications can be
validated with online, real-time operations ... obsoleting any requirement for
supporting offline methodologies.
it would be really great to make it an excuse to move away from offline
paradigm to real online operation ... getting totally rid of the need for
domain name certificates ... DNS serving up both ip-addresses and public
keys in single operation.

@_date: 2007-05-22 09:40:29
@_author: Anne & Lynn Wheeler 
@_subject: 307 digit number factored 
A big part of the issue is the domain name certification authority has to trust
the domain name infrastructure as to the true owner of the domain name ... when
they are processing a domain name certificate application for certification (i.e.
only the actual domain name owner on file with the domain name infrastructure should
be able to apply for domain name certifications).
The catch-22 is that the original idea behind domain name certificates were
because of integrity issues with the domain name infrastructure. However, the
domain name certification industry is dependent on the integrity of the domain
name infrastructure in their domain name certification process.
As a result they need to improve the integrity of the domain name infrastructure
because their dependency on the domain name infrastructure in their process of
certification. So one of the proposals (somewhat backed by the domain name certification authority
industry) is that domain name owners place a public key on file when they register
a domain name with the domain name infrastructure. They all future communication
with the domain name infrastructure can be digitally signed ... and the domain
name infrastructure verify the digital signature with the onfile public key.
This is intended to help improve the integrity of the domain name infrastructure.
However, it could also offer benefits to the domain name certification authority
industry. The domain name certification authority industry could also then start
requiring that domain name certification applications also be digitally signed.
The the domain name certification authority industry can do a real-time retrieval
of the on-file public key to verify the domain name certification application digital
signatures. This provides for turning a time-consuming, error-prone, and expensive
identification process into a much simpler, reliable, and less expensive authentication
process (enormous benefits for the domain name certification authority industry).
The issue is that if the domain name certification authority industry are somewhat
two fold:
1) the original justification for domain name certification involved integrity
issues with the domain name infrastructure. improving the integrity of the domain
name infrastructure would reduce the original justification for having domain
name certification
2) if the domain name certification authority industry could start relying
on real-time retrieval of public keys ... then possibly the rest of the world
could also ... eliminating the need for domain name infrastructure.
some collected "catch-22" posts
long ago and far away, we had been called in to consult with this small client/server
startup that wanted to do payment transactions and had this technology called
SSL. In addition to doing stuff about working out the payment transaction operation
we also had to do a lot of stuff with end-to-end business process investigation of
these new business operations called certification authorities. Since then,
this has frequently come to be referred to as electronic commerce. some old posts
and collection of posts mentioning payment processing and payment gateway
Now, the original SSL infrastructure was to verify that the URL that the
user entered (into the browser) corresponded to the website that the
browser was talking to (i.e. the website that the user thought they were talking to was the website they were actually talking to). However,
most electronic commerce sites fairly quickly found that SSL was costing
them something like 90percent of their thruput. The result was that most
websites transitioned to no longer using SSL for the initial user connection
but reserved just for the payment process (to hide the account number information). Now the user clicks on a button (provided by the webserver)
which generates a URL (provided by the webserver). Now instead of checking
the URL provided by the user against the webserver ... most use of SSL
now checks the URL provided by the webserver against the webserver (invalidating
the original SSL security assumptions). lots of past posts about ssl
digital certificate infrastructure
so it could be claimed that the way that the currently deployed SSL for the
electronic commerce infrastructure doesn't really cut it either ... it is somewhat
a case of the emperor's new clothes ... and the integrity of the domain
name infrastructure has to be improved in any case, since it is the trust
root for the whole domain name certification authority industry's certification process (but fixing the integrity of the trust root could also
make additional domain name certification processes redundant and superfluous).
afterwards we did some work with the x9a10 financial standard working group
that in the mid-90s had been given the requirement to preserve the integrity of the financial infrastructure for all retail payments (i.e. all, point-of-sale,
internet, credit, debit, ach, face-to-face, stored-value, aka ALL). The
result was the x9.59 financial standard
In the security acronym "PAIN"
P ... privacy (or sometimes CAIN, confidential)
A ... authentication
I ... identification
N ... non-repudiation
now, we've claimed that possibly the largest use of SSL is in support of
electronic commerce (to hide account number information).
however, in X9A10, a detailed end-to-end vulnerability and threat analysis
was performed ... and divulging account information was identified as
major exploit (requiring SSL to hide transaction information). However
the majority of exploits had never been capturing information in transit
(before SSL, even before the internet) ... it had always been capturing
information at end-points and/or logs of previous transactions. As a result, a primary objective of X9.59 financial standard was to eliminate havesting/skimming
of previous transactions as a (replay attack) vulnerability. The result was
that X9.59 effectively "armors" every transactions ... in effect replaces
"privacy/confidentiality" as a countermeasure with "authentication" and
X9.59 transactions no longer have to be hidden as a fraud countermeasure.
This eliminates the requirement to hide such transactions ... and therefor eliminates the major use of SSL in the world today (related to electronic commerce). X9.59 also eliminates the major threats and vulnerabilities related to the data breaches and security breaches that have been in the news recently. some related recent posts about naked transactions/payments
for some topic drift ... lots of the stuff being "hidden" with SSL
are really transaction oriented operations ... and if domain name
infrastructure could serve up public keys ... there could be significant
thruput improvements in such protocols. some recent posts in a
financial crypto blog
 H6.2 Most Standardized Security Protocols are Too Heavy
 H6.2 Most Standardized Security Protocols are Too Heavy

@_date: 2007-05-22 14:31:06
@_author: Anne & Lynn Wheeler 
@_subject: dnssec? 
307 digit number factored
 307 digit number factored
sometimes i wonder if at least some of the dnssec issue doesn't turn out to be related to not having a revenue flow champion. domain name certification business caught on fairly rapidly (as countermeasure to
perceived integrity issues with domain name infrastructure).
fixing the domain name infrastructure integrity issues 1) doesn't appear to have
any champion (at least motivated with significant incremental revenue flow) ... and 2) could make the existing industry doing domain name certifications obsolete, redundant and superfluous.
for other topic drift ... a recent post with some DNS related trivia ... more
than a decade before DNS (about half-way down the post mentioning former MIT student)
 Even worse than UNIX
and for other topic drift, old email about online, real-time public key distribution
(also predating DNS)
in this post
 more secure communication over the network

@_date: 2007-05-23 13:52:23
@_author: Anne & Lynn Wheeler 
@_subject: dnssec? 
and rfc editor announcement from today .... my rfc index
4871 PS
    DomainKeys Identified Mail (DKIM) Signatures, Allman E., Callas J., Delany M., Fenton J., Libbey
M., Thomas M., 2007/05/22 (71pp) (.txt=166054) (Obsoletes 4870) (See Also 4870) (Refs 1847, 2045,
2047, 2440, 2821, 2822, 3447, 3490, 3766, 3833, 3851, 4033, 4234, 4686) (was
draft-ietf-dkim-base-10.txt) 4870 -H
    Domain-Based Email Authentication Using Public Keys Advertised in the DNS (DomainKeys), Delany M.,
2007/05/22 (41pp) (.txt=87378) (Obsoleted by 4871) (See Also 4871) (Refs 1421, 3833, 3851, 4648) (was

@_date: 2007-05-23 16:30:59
@_author: Anne & Lynn Wheeler 
@_subject: 307 digit number factored 
307 digit number factored
 307 digit number factored
... that could be the short term view ... as well as dealing
with established operation ... having been around since before
the current CA stuff started ... and somewhat involved in
helping get the current infrastructure established
(from the standpoint of its inception for what is now
called electronic commerce ... and having to do detailed
business process & technical walk thru and audit of the early
certification authority players) ... the issue is more how to replace something once it was established (i.e. the current infrastructure somewhat got fast uptake ... because it didn't have
alternative solutions to deal with).
 dnssec?
 dnssec?
somewhat topic drift with DNS related trivia ... more than a decade before
and some old email (predating dns) suggesting online, realtime public key
in this post

@_date: 2007-05-24 14:07:04
@_author: Anne & Lynn Wheeler 
@_subject: 307 digit number factored 
307 digit number factored
 307 digit number factored
 dnssec?
 dnssec?
 307 digit number factored
part of the quick IETF uptake of SSL and VPN in the 94/95 time-frame was that there
really wasn't any serious competition. there was ipsec ... but it was end-to-end implementation
at low level ip-stack ... which were kernel implementations ... and then was faced
with the whole issue of distribution, installation and support of new kernels on
machines all around the world (from a variety of different vendors and different
operating systems).
SSL was almost a no-brainer ... since it just involved loading/installing a new
application (orders of magnitude easier than ipsec). lots of collected posts
mentioning SSL and/or SSL certificates
in the same time-frame VPN was introduced at the gateway committee meeting at '94
San Jose IETF meeting. We had worked with the guy on and off since the late 70s and
he originally developed the technology for his own use ... between home and office;
actually both his wife and he worked for different technology companies ... he got
a leased line from the house to his office ... and her company got a circuit from
his office to their office. The issue was how to encrypt the wife's communication w/o
having it exposed to the husband and/or the husband's company.
sort of the state-of-the art had been link encryptors ... for a little topic drift ...
the internal corporate network had been larger than the arpanet/internet from just
about the beginning until possibly summer of '85. the internal network required
encryption on everything leaving the premise ... and in the mid-80s there were comments that the internal network had over half of all link encryptors in the world.
misc. past posts mentioning the internal network.
the requirement that led to VPN was how to carry separately encrypted streams over the same link. ipsec would have solved the problem ... but again was end-to-end
solution that required upgrading all the low-level ip-stacks ... which required
distribution, installation (and support) of new kernel. the VPN solution was
to handle the stream encryption/decryption in boundary routers (which could be
tunneled over other infrastructure).
my observation was this resulted in some amount of consternation in the ipsec faction ... which they somewhat resolved by starting to refer to VPN as "lightweight
ipsec" (and of course, everybody else could then refer to regular ipsec as
"heavyweight ipsec").
the other problems was with various router vendors in the IETF. it was
sort of divided along the lines of the vendors that had enuf horse power in
their current boxes to implement and deploy VPN support ... and the other vendors
whos' products didn't have enuf processing power available to do the crypto
operations in support of VPN. This difference dragged out some of the VPN standardization
activity within IETF.
misc. past posts mentioning "lightweight ipsec"
 Proxy PKI. Was: IBM alternative to PKI?
 Is cryptography where security took the wrong branch?
 Hamiltonian path as protection against DOS
 Use of SSL as a VPN
 Why more than 1 hole in FW for IPSec
 MAC and SSL
 The Perfect Computer - 36 bits?
 SSL vs. SSL over tcp/ip
for other drift ... some of the people doing VPN implementations were using RSA
bsafe library ported to whatever processor they were using. Some number of these
put in effort to enhance the performance of bsafe library.
some of this was going on when we were in transition from working on the infrastructure
that is currently frequently referred to as electronic commerce and work in the
x9a10 financial standard committee. in that same time frame there were other
efforts looking at "enhancing" how payment transactions could be implemented and
deployed for the internet (as opposed to x9a10 standards work which had a requirement to have a standard that preserved the integrity of financial infrastructure for
ALL retail payments). One of these published some of their specification and from the specification I drew up a business operation profile and a "public key" operation profile. I then got the "public key" operation profile executed on a number of different platforms using the "speeded up" bsafe library (running four times faster) ... and reported the numbers back to the organization responsible for that specification. The people in the organization
"claimed" that the performance numbers were one hundred times too slow (instead of
observing that they were four times too fast). About six months later when
they actually had some prototype code ... the "profile" numbers were within a couple
percent of measured (the speeded up bsafe library having been returned to rsa).

@_date: 2007-05-24 16:25:31
@_author: Anne & Lynn Wheeler 
@_subject: 307 digit number factored 
307 digit number factored
 307 digit number factored
 dnssec?
 dnssec?
 307 digit number factored the credential/licensing/certificate paradigm was certification of strangers
who have never before communicated before ... and there was no timely, available
mechanism for providing information about the other party (aka the analogy
of letters of credit/introduction from sailing ship days and before).
parties with previous relationship can have available information about each
other based on prior relationship ... or strangers in first time communication
may have access to timely sources of information about the other party.
the issue wasn't that the offline stranger paradigm didn't exist ... it just
was a rapidly disappearing scenario ... aka digital certificates were somewhat
modeled after the sailing ship "days" letters of credit/introduction for
the early 80s offline email scenario for first time communication between
complete strangers ... dial-up local electronic post-office, exchange email,
hang-up ... and then potentially faced with first-time email from total stranger.
while digital certificate wasn't as high a quality information paradigm as
real-time, online ... in this particular scenario, it was better than the
alternative ... nothing.
the issue isn't eliminating digital certificates for the situations where they may be appropriate ... it is eliminating digital certificates
for uses where they are obsolete, never intended for, redundant and/or superfluous. For all the situations where digital certificates and PKI aren't applicable (or redundant and superfluous) they tend to represent
and extraneous and unnecessary business cost providing little or no added
in the wake of some of the original stuff (w/SSL that is frequently no referred
to as electronic commerce) there was some investigations that looked at
adding digital certificate kinds of processing to existing real time payment
 307 digit number factored
.... some of the comments was that adding such digital certificate processing would
bring payment transactions into the modern era. Our observation was that
reverting to an offline PKI, digital certificate processing paradigm would
set back real-time payment transactions several decades. That if you
were doing real-time payment transactions that online, timely processing
had significantly higher quality information processing ... real-time status
of public key onfile in the account record as well as aggregated information ...
recent payment transaction patterns, current balance and/or credit limit, etc.
It was in the wake of that series of exchanges that you saw OCSP work start
in IETF.
We observed that not only was the stale, static digital certificate addition
to real-time payment transactions redundant and superfluous ... that the typical
proposals of the period represented a factor of 100 times in payload size bloat
(enormous payload cost addition providing no added benefit) as well as the
redundant and superfluous digital certificate processing increased real-time
payment transaction processing by nearly a factor of 100 times. Misc. past
posts mentioning enormous redundant and superfluous stale static digital certificate added overhead

@_date: 2007-05-27 09:19:37
@_author: Anne & Lynn Wheeler 
@_subject: A crazy thought? 
CAs are certification authorities ... they certify some information they
have checked and issue digital certificates that represent that checking
... somewhat analogous to physical licenses, credentials, certificates.
most certification authorities aren't the authoritative agency for the
information that they certify ... for the most part they are simply
certifying that they have checked the information with whatever authoritative
agency is responsible for that information.
in that sense they are somewhat like notary ... i.e. if somebody has
done some identity theft and managed to obtain a valid driver's license
... the notary isn't held responsible ... they just notarize that
they checked a valid drivers license.
this is somewhat the catch-22 scenario in recent posts for ssl domain
name certification authorities
where they are in something of a situation because big part of the
original justification for ssl domain name certificates involved
integrity issues with the domain name infrastructure ... however,
the domain name infrastructure is also the authoritative agency for
domain name owner information, which the ssl domain name certification
authority is dependent on as part of the integrity for certifying
ssl domain name information. Fixing integrity issues in the domain
name infrastructure ... improves the probability that correct
ssl domain name certification is being performed ... but fixing
integrity issues in the domain name infrastructure can also drastically
reduce justification for having ssl domain name certificates.
recent posts
 307 digit number factored
 307 digit number factored
 dnssec?
 dnssec?
 307 digit number factored
 307 digit number factored
 307 digit number factored
in some cases, there is the possibility that the excessive attention
to the details of the cryptographic operations is pure obfuscation
that the rest of the end-to-end business processes may purely be
built on a house of cards.
for additional drift, some recent posts in related thread on digital certificates in another fora (including some possible infrastructure vulnerabilities
and systemic risks)
 John W. Backus, 82, Fortran developer, dies
 John W. Backus, 82, Fortran developer, dies
 John W. Backus, 82, Fortran developer, dies
 John W. Backus, 82, Fortran developer, dies
 John W. Backus, 82, Fortran developer, dies
 John W. Backus, 82, Fortran developer, dies
 Re: John W. Backus, 82, Fortran developer, dies
 Re: John W. Backus, 82, Fortran developer, dies
 Re: John W. Backus, 82, Fortran developer, dies
 Re: John W. Backus, 82, Fortran developer, dies

@_date: 2007-10-05 18:13:36
@_author: Anne & Lynn Wheeler 
@_subject: Retailers try to push data responsibilities back to banks 
some number of other recent notes on the subject:
Customer Service: Consumer Confidence at Stake in Retail, Credit Card
Industry Clash
Retailer PCI Rebellion: 'No More Storing Credit Card Numbers'
Retailers Fighting To No Longer Store Credit Data
Retail group takes a swipe at PCI
Retailers Challenge the Networks? Card-Data Storage Requirements
NRF to Credit Card Companies: Stop Forcing Retailers to Store Credit Card Data
Retail group takes a swipe at PCI, puts card companies 'on notice'
Rethinking the Assumptions Behind PCI-DSS
PCI Is Here: Keeping the barbarians outside the cyber gates
Retailers, Credit Card Industry Clash
.... we had been called in to consult with this small client/server startup that
wanted to do payment transactions. this required some amount of translating
technology into business critical data processing ... which has somewhat
come to be referred to as "electronic commerce". This including technology
invention that they called SSL ... and among other things we had to do
some detailed audits of these supporting infrastructures that were calling
themselves certification authorities ... various past posts on the subject
in the mid-90s we got involved in the x9a10 financial standard working group
that had been given the requirement to preserve the integrity of the
financial infrastructure for all retail payments. we drew on our experience
having previously done "electronic commerce" as well as some detailed
vulnerability studies and threat models. having been given the requirement
for all retail payments ... we had to look at a standard that was lightweight
enuf that could be easily deployed in both point-of-sale as well as internet
environments ... and provide end-to-end security and integrity with countermeasures
for both "data-in-flight" vulnerabilities (aka transaction transmission)
as well as "data-at-rest" vulnerabilities (aka transaction logs and databases).
part of the issue was some studies that claimed as much as 70 percent
of ("data-in-flight" and "data-at-rest") compromises involved "insiders"
(aka countermeasures had to recognize that majority of compromises
possibly involved individuals with legitimate access to the information).
the resulting financial standard was x9.59
the x9.59 approach was to eliminate fraudulent transactions resulting
evesdropping and data breach compromises ... aka it didn't eliminate
evesdropping and data breach compromises ... but it eliminated the
ability of attackers (insiders or outsiders) to use the information that they had obtained for purposes of doing fraudulent transactions.

@_date: 2007-10-24 14:57:32
@_author: Anne & Lynn Wheeler 
@_subject: Fingerprint Firefox Plugin? 
the design point for certificates was first time communication between total
strangers (aka the letters of credit/introduction from sailing ship days).
certificates have also somewhat tried moving into no-value market segment for relying
parties that had no (and/or couldn't cost justify) mechanism for recording information
about other parties they were dealing with. by comparison pgp had assumed some mechanism for relying parties being able to record information about the parties that they had dealings with. huge number of
infrastructures have had well entrenched infrastructures for recording information
about parties that they dealt with ... it just has been that the authentication
related information (for these infrastructures) have tended to be shared secrets.
many of these infrastructures could have been upgraded from shared secrets
to public key ... w/o having any impact on the business and/or trust models
... and furthermore by the very nature of the existing infrastructures,
the paradigm behind digital certificates wasn't applicable (i.e. digital
certificates being totally redundant and superfluous).
recent thread/posting about it being much more natural for simple upgrade of kerberos infrastructure from shared secrets to public key ... w/o the
exorbitant additional overhead and processing introduced by digital
certificates.  Windows Live vs Kerberos
 Windows Live vs Kerberos
when we were called in to consult with this small client/server startup
that wanted to do payment transactions on their server ... since then
somewhat has come to be called electronic commerce
one of the technologies they had invented was SSL ... and we had
to do some work on applying SSL to real business processes and also
do some end-to-end audits of the whole series of operations ... including
these things that we calling themselves certification authorities
one of the things that undermined original assumptions applying
SSL to business processes was the whole "click" paradigm ... discussed
in more detail in this recent post
 and the assumptions about SSL as countermeasure and the related
threat models.
another aspect of SSL, certification authorities, digital certificates
was the whole issue behind what is met by certification process ... and
what certifications were represented by digital certificates. during the initial decade or so of electronic commerce something over
70 percent of the transactions were done by less than 100 websites
(activity is highly skewed) These websites were both well known and also carried a lot of repeat business ... invalidating one of the original/primary justifications  for having digital certificates. so a very few websites did majority of transactions and didn't need certification. by comparison, the vast majority of websites
were only doing a very, very few electronic transactions
(especially those involving large percentage of first interaction
between complete strangers) ... and couldn't cost justify expensive certification process
the other issue was that (all) merchants were already paying a fairly
hefty "interchange fee" that acted as a form of warranty/insurance
to cover their client/consumers (actually proportional to
the value of the operations). by comparison, the certification
authorities were providing almost no added value ... so except
for pure hype ... there was no real reason for spending
money for additional certification (at least from the standpoint
of electronic commerce) ... which somewhat gave rise to the thread about "merchant comfort certificates" in some of the older ssl domain name certificate postings
  a combination of these factors continued to push
PKIs, certification authorities, and digital certificates
more and more into the no-value market segment.

@_date: 2008-04-26 11:22:06
@_author: Anne & Lynn Wheeler 
@_subject: "Designing and implementing malicious hardware" 
traditional approach is to make the compromise more expensive that any
reasonable expectation of benefit (security proportional to risk).
helping bracket expected fraud ROI is an infrastructure that can (quickly)
invalidate (identified) compromised units. there has been some issues
with these kinds of infrastructures since they have also been identified
with being able to support DRM (& other kinds of anti-piracy) efforts.
disclaimer: we actually have done some number of patents (that are in this area

@_date: 2008-02-01 09:37:59
@_author: Anne & Lynn Wheeler 
@_subject: Dutch Transport Card Broken 
my view of ipsec was that it faced a significant barrier to entry since
it required upgrading lots of installed kernels all over the infrastructure
(aka tcp/ip protocol stack have been integrated kernel implementations)
both SSL and VPN offered implementations that require having to
upgrade existing deployed kernels (something that has gotten
somewhat easier in the last decade plus).
about the same time as SSL, a friend that we had worked on & off with
over a couple decades introduced what was to become called VPN
in gateway committee at fall '94 IETF meeting in san jose.
my view was this resulted in some amount of consternation
with the ipsec forces as well as some of the router vendors.
the ipsec forces were somewhat mollified by being able
to refer to vpn as "lightweight" ipsec (while others then
would refer to ipsec as "heavyweight" ipsec).
the initial proposal involved border routers providing
authentication and (encryption) tunneling through the
internet. some of the router vendors had processors
that could handle the encryption load. however, there
was opposition from the router vendors that didn't
have products with processors that could handle
the encryption load (or at least stalling until they
had such a product).
in any case, uptake of both SSL and VPN ... was
the significantly easier and less complex deployment
... vis-a-vis ipsec.

@_date: 2008-02-01 10:13:32
@_author: Anne & Lynn Wheeler 
@_subject: Fixing SSL (was Re: Dutch Transport Card Broken) 
the problem that digital certificates were suppose to address was first time communication
between strangers ... the electronic analogy of the letters of credit/introduction from
sailing ship days. this harks back to the "offline" email days of the early 80s ... dial-up
electronic post-office, exchange email, hangup, and now authenticate first-time email
from total stranger.
the design point assumptions are invalidated if the relying party has their own
repository of information about the party being dealt with (and therefor included that party's public key) and/or has online, timely electronic access to
such information.
one of my favorite exchanges from the mid-90s was somebody claiming that
adding digital certificates to the electronic payment transaction would bring it into the modern age. my response was that it actually would
regress the infrastructure at least a couple decades to the time when
online, real-time transactions weren't being done. The online, real-time
transaction provides much higher quality and useful information than
a stale, static digital certificate (with an offline paradigm from before
modern communication). Having an available repository about the party
being dealt with ... including things like timely, aggregated information
(recent transactions) is significantly mover valuable than the stale,
static digital certificate environment (the only thing that it has going
for it, is it is better than nothing in the oldtime offline environment).
misc. past posts referencing "certificate-less" public key operation
for some real topic drift ... i've mentioned x9.59 financial
standard protocol that can use digital signatures for
authentication w/o requiring digital certificates
part of the issue included that digital certificates
(even relying party only digital certificates) can
add a factor of one hundred times payload bloat
to a typical payment transaction
however, we were also got involved in co-authoring
the x9.99 privacy standard ... as part of that we had
to look at a number of things, HIPAA, GLBA ... as
well as EU-DPD. as part of that we had also done
a privacy merged taxonomy and glossary ... some
EU had also made a statement in the mid-90s that
electronic retail payments should be as anonymous
as cash. The dominant use of SSL in the world
today is electronic commerce between a consumer
and a merchant. Passing a client certificate (with
PII information) within an encrypted SSL channel
to a merchant ... still exposes the information to
the merchant ... also violating making purchases
as anonymous as cash.

@_date: 2008-02-03 20:01:32
@_author: Anne & Lynn Wheeler 
@_subject: Fixing SSL (was Re: Dutch Transport Card Broken) 
most people who heard the statement, understood that.
i think that possibly 2nd level detail was that they didn't want
PII easily associated by casual merchant. Initial response was to remove
name from payment cards & magstripes. This also precluded
merchants from requesting other forms of identification to
see if the names matched the name on the payment card.
The implication being that the payment infrastructure would
have to come up with other mechanisms to improve
the infrastructure integrity.
The offline payment paradigms ... while touting "true"
anonymity were actually primarily justified based on
other factors.
We had been asked to design and cost the dataprocessing
supporting US deployments of some of the "offline" products
(that were being used in Europe). Along the way, we did
some business process and revenue analysis and realized
that the primary motivation behind these system deployments
was the float.
About the same time that there was the EU about the
privacy of electronic retail payments ... there was also
a statement by the EU (and some of the country central
banks) that the offline products would be allowed to
keep the float for a short grace period .... to help in
the funding of the infrastructure deployment ... but
after the grace period ... the operators would have to
start paying interest on the balance held in the "offline"
instruments (eliminating float from the equation).
After that, much of the interest in the offline
deployments drifted away.
In that time frame we had also done design, implementation
and deployment of a payment transaction infrastructure
supporting target marketing ... recent reference
 Diversity
support was for a small pilot of 60mil accounts and
1.5million transaction/day ... but capable of scaling
up to 20-30 times that amount. There was significant
attention paid to privacy issues and it was subject
to quarterly auditing by some dozen or so privacy
organizations. there had to be a large amount
of sensitive treatment of the information along
the lines of what HIPAA specifies for health information.
  Previously identifiable data that have been deidentified and for
  which a code or other link no longer exists. An investigator would
  not be able to link anonymized information back to a specific
  individual. [HIPAA] (see also anonymous, coded, directly
  identifiable, indirectly identifiable)
as part of co-authoring x9.99 financial privacy standard, one
of the things we created was a privacy merged glossory and
taxonomy ... including GLBA, HIPAA, and EU-DPD references
some notes:
in our work on x9.59 financial transaction standard
we made the statement that it was privacy agnostic ... since
the transactions were tied to accounts ... but then whether or
not the accounts were tied to individuals was outside the x9.59
As a total aside ... as part of the Digicash liquidation,
we were brought in to evaluate the patent portfolio.

@_date: 2008-02-06 13:23:29
@_author: Anne & Lynn Wheeler 
@_subject: Fixing SSL (was Re: Dutch Transport Card Broken) 
a recent reference
Research unmasks anonymity networks
Research unmasks anonymity networks
Research unmasks anonymity networks
Paper Outlines Methods for Beating Anonymity Technology

@_date: 2008-02-09 21:14:23
@_author: Anne & Lynn Wheeler 
@_subject: Fixing SSL (was Re: Dutch Transport Card Broken) 
in AADS
and certificateless public key
we referred to the scenario as person-centric ... as a contrast
to institutional-centric oriented implementations.
past posts in this thread:
 Fixing SSL (was Re: Dutch Transport Card Broken)
 Fixing SSL (was Re: Dutch Transport Card Broken)
 Fixing SSL (was Re: Dutch Transport Card Broken)

@_date: 2008-02-10 05:41:30
@_author: Anne & Lynn Wheeler 
@_subject: Fixing SSL (was Re: Dutch Transport Card Broken) 
Fixing SSL
so lots of the AADS
scenarios are that every place a password might appear, have
a public key instead.
for various of the cookie authentication operations ... also
think kerberos tickets. recent reference
 Kerberized authorization service
part of the scenario for cookie/ticket encryption ... involving
servers, is brute force attack on the server secret key. the cookie
instead of all encrypted data ... has some sort of client registration
value ... analogous to an account number or userid. the cookie caries the
registration value followed by the server encrypted data.  the
encryption part uses a derived key ... formed by combination of the
server's secret key and the client's registration value. these derived
key scenarios are also found in transit system operation (both
magstripe and memory chip) as well as financial transactions.
the issue then is initial registration ... the part where the user
chooses their userid (and/or the client registration value is
otherwise selected) and supplies a password (but in this case a public
key). m'soft and others have been using CAPTCHA to weed-out the
non-humans, but this has come under attacks. reference to recent news
 Spammer' bot cracks Microsoft's the ticket/cookie carries the clients public key (and whatever other
characteristics) ... which then can be used by the server(s) to
perform dynamic authentication (digital signing of some server
supplied, random data, countermeasure to replay attacks). this is in
lieu of server having to maintain the client account record ... ala a
RADIUS scenario where public key has been registered in lieu of a
password (some sort of online access to RADIUS account
records). various RADIUS public key in lieu of password postings:
the ticket/cookie scenario (with derived key encryption) is cross
between dynamic server-side account record data (say RADIUS
repository) and stale, static digital certificate scenario. as in the
transit gate operation, the ticket/cookie could also be retrieved,
decrypted, updated, re-encrypted, and returned as part of the
operation. initial server hand-shakes can include server sending some
random challenge data. The client returns the digital signature
and their previously obtained cookie. in the straight RADIUS public
key handshake scenario, just the digital signature and client
userid/account-number is returned since the rest of the cookie/ticket
equivalent info is online in the RADIUS account repository.
The straight RADIUS scenario would be to combine the server-side
random challenge data and combine it with the client registration
value (account number, userid) and whatever else the client-side
digital signing requires ... and return the userid/account-number
any other data and digital signature (i.e. server-side has to be
able to reconstruct what the client actually digitally signed
as part of verifying the digital signature). In the straight RADIUS
scenario, the public key (and any associated permissions, authorization,
etc) is obtained from the RADIUS repository. In cookie/ticket
scenario, it is obtained from the cookie/ticket appended to the
The business process still has the initial registration phase
... where the original cookie is created (or in the RADIUS
scenario, where the userid definitiion is initially created) and the
public key is supplied (in lieu of a password).
This is also effectively the original certificateless pk-init scenario
for kerberos (aka public key in lieu of password)
The cookie scenario is standard client/server ... attempting
to eliminate the server having to retain the account
record on behalf of every client (as in either the RADIUS
and/or KERBEROS scenario). Encrypting of the cookie data
is standard ... although transit systems and financial transactions
have gone to derived key for the situation ... as countermeasure
to brute force attack on the infrastructure secret key.

@_date: 2008-01-02 12:09:50
@_author: Anne & Lynn Wheeler 
@_subject: Death of antivirus software imminent 
> My favorite virtual machine use is for the virus to install itself
 > as a virtual machine, and run the OS in the virtual machine.  This
 > technique should be really good for hiding from virus scanners.
 Death of antivirus software  Death of antivirus software i commented on that in reference posts mentioning that there have been
uses of virtual machines to study virus/trojans ... but that
some of the new generation virus/trojans are now looking to see if they
are running in virtual machine (studied?).
some of the current trade-off is whether that virtual machine technology
can be used to partition off basically insecure operations (which are widely
recognized as being easy to compromise) and then completely discard
the environment and rebuild from scratch after every session (sort of
the automated equivalent of having to manually wipe an infected machine
and re-install from scratch).
the counter argument is that crooks can possibly also use similar
technology to hide ... once they have infected the machine. the current
issue is that a lot of the antivirus/scanning techniques are becoming w/o the attackers even leveraging virtual machine technology.
The attackers can leverage the technology in an otherwise poorly
defended machine. Some years ago there was a product claiming
that it could operate even at a public access machine because
of their completeness of their antivirus countermeasures ... even
on an infected machine. I raised the issue that it would be trivial
to defeat all such countermeasures using virtual machine technology.
Somewhat of a skirmish resulted since they had never considered
(or heard of) virtual machine technology ... for all i know there
is still ongoing head-in-the-sand situation.
for little topic drift ... this blog entry:
there is some assertion that the crooks overwhelming the
defenders countermeasures because they are operating
significantly faster and more efficiently.
however, another interpretation is that the defenders
have chosen extremely poor position to defend ... and are
therefor at enormous disadvantage. it may be necessary
to change the paradigm (and/or find the high ground)
in order to successfully defend.

@_date: 2008-01-03 11:05:59
@_author: Anne & Lynn Wheeler 
@_subject: Death of antivirus software imminent 
Death of antivirus software  Death of antivirus software  Death of antivirus software the other claim was that it was assumed that basic systems were built to be secure,
so it would have been quite foreign idea it would be necessary to build a secure
specific system.
besides the referenced fairly wide use of gov and commercial institutions requiring
high integrity systems ... the early virtual machine systems (cp67 and were also used by commercial time-sharing service bureaus. most of these
created cms "padded cell" modifications, a lot of it was to prevent users from
damaging themselves (as opposed to the underlying security that prevented
uses from damaging the system and/or each other).
at least some of these services provided online, concurrent services to
(competitive) wall street firms ... who would be using the online services
for highly sensitive financial activities (as example of integrity a little related x-over from posting in this thread
 hacked TOPS-10 monitors

@_date: 2008-01-25 10:28:55
@_author: Anne & Lynn Wheeler 
@_subject: Dutch Transport Card Broken 
my impression has been that with lack of takeup of various kinds of security
solutions that were extensively marketed in the 90s ... that the current
situation has many of those same organizations heavily involved in behind
the scenes lobbying
saw some of that nearly a decade ago when we were brought in to
help wordsmith the cal. state electronic signature legislation which
led to also be brought in on federal electronic signature legislation
... some past posts
some other references ...
Hackers break into transport smart card
Transport smart card hacked again (update)

@_date: 2008-01-25 10:47:39
@_author: Anne & Lynn Wheeler 
@_subject: Dutch Transport Card Broken 
we sort of saw that in the mid-90s when we were doing the x9.59 financial standard
and getting comments that it wasn't possible to have both low cost and high security at
the same time. we looked at it and made the semi-facetious statements that we
would take a $500 milspec part and aggresively cost reduce it by 2-3 orders of magnitude
will improving the security. along the way we got tapped by some in the
transit industry to also be able to meet the (then) transit gate (well under 1 second and do it within iso 14443 power profile).
part of it was having to walk the whole end-to-end process ... all the way back
to chip design and fab manufacturing process ... little drift about walking
fab in a "bunny suit"
we effectively did get it on close to the RFID chip (i.e. the one that they
are targeting for UPC) technology curve ... i.e. chip fabrication cost is roughly
constant per wafer ... wafer size and circuit size have been leading to number of chips per wafer (significantly reducing cost/chip). As circuit shrank with a corresponding shrinkage in the size of chips (that didn't have
corresponding increase in number of circuits) there was a "blip" on the
cost/chip curve as the area of the cuts (to separate chips in the wafer)
exceeded the (decreasing) chip size.  Earlier this decade there was
a new cutting process that significantly reduced the "cut" area ... allowing
yield of (small) chips per wafer to continue to significantly increase
(allowing pushing close to four orders of magnitude reduction ... rather
than 3-4 orders of magnitude reduction).
aads chip strawman references

@_date: 2008-01-26 23:11:25
@_author: Anne & Lynn Wheeler 
@_subject: Lack of fraud reporting paths considered harmful. 
some chance they are doing this to save money on transactions that aren't
likely to be approved ... i.e. rather than be charged for a transaction that
they send thru to the issuer that they are sure to be rejected ... they
reject it upfront.
now the associations have standard procedure to perform "stand-in" when
the network accepts a transaction from an acquirer but isn't able to forward
it to the issuer. stand-in allows the network to decide whether to approve
or reject the transaction using simplified rules. later, when contact is
re-established with the issuer ... the issuer has to be informed of all
the stand-in activity.
a possible simplified mechanism is to be able to generate a simulated report of rejected transactions. the issue then in such a simulated stand-in
role ... for all the reasons that they chose to reject a transaction ... do they map
into the standard iso 8583 codes for reasons that the issuer would reject
the transaction.

@_date: 2008-01-30 12:57:07
@_author: Anne & Lynn Wheeler 
@_subject: Fixing SSL (was Re: Dutch Transport Card Broken) 
Dutch Transport Card Broken
 Dutch Transport Card Broken
aka ... that was part of the relying-party-only certificates from the i.e. the x.509 identity digital certificates from the early 90s, were more and more overloaded with personal information ... and by the
mid-90s, lots of institutions were starting to realize all that personal
information represented significant privacy and liability issues ... and
the RPO digital certificates were born.
However, it was trivial to demonstrate that (for all those business that the digital certificates were redundant and superfluous (however, there
was some amount of industry brain washing that digital certificates were
mandatory ... especially if digital signatures was used ... even if they
served no useful purpose).
this also showed up in work on pk-init for kerberos supporting digital
signature authentication ... and got into the confused mess with redundant
and superfluous digital certificates
and similarly digital signatures for radius
(between kerberos and radius, they represent possibly the majority
of authentication in the world today)
part of the confusion regarding the necessity for digital certificates
could be seen in the X9F financial standards work ... the appending
of even a relying-party-only digital certificate (lacking any personal
information) could represent a factor of 100 times payload bloat
for a nominal electronic payment transactions (and also 100 times
processing bloat). as a result, there was some standardization
effort looking at "compressed" (relying party only) digital certificates
(even tho they were serving no useful purpose), attempting to
get the payload bloat down to possibly only 5-10 times (instead
of 100 times). I took the opportunity to demonstrate that it
would be logically possible to compress such digital certificates
to zero bytes ... totally eliminating the payload bloat. then rather
than advocating the elimination of totally useless, redundant
and superfluous digital certificates
there could be an infrastructure that mandated zero-byte
digital certificates appended to every transaction.

@_date: 2008-01-31 14:28:30
@_author: Anne & Lynn Wheeler 
@_subject: Dutch Transport Card Broken 
Victor Du
 Dutch Transport Card Broken
 Dutch Transport Card Broken
 Fixing SSL (was Re: Dutch Transport Card Broken)
TCP requires minimum of seven message exchange for reliable transport
.... VMTP (rfc 1045) got that down to minimum of five messages, and XTP got it down to three messages minimum for reliable transport (disclaimer
we were on the XTP technical advisory board).
i've frequently pontificated that with reliable registration of public keys
in the dns system and then piggy-backing any registered public key in
standard DNS response .... then it would be possible to encode the
randomly generated secret key (with that public key) and the encrypted
message in the XTP packet for minimum 3 packet exchange.
http already went thru its period of problems of implicit assumptions
with tcp. tcp sessions were assumed to be long lived and session shutdown
was assumed to be relatively infrequently. non-session activity like http
was always assumed to use udp for efficiency. the http ignored all of
that and used tcp for non-session activity. as a result, webserver systems
went thru a period where the processors was spending 95+ percent of
processor in the session shutdown processing. systems then were retrofited
with new kind of tcp session shutdown implementation to handle the
misuse by http.
the original ssl deployment was to 1) encrypt data in transit and
2) authenticate the server. the implicit assumption was that the
user understood the binding between the business and the url.
the browser then provided the second part, verifying the binding
between the url and the server contacted (was the server that
the user thot they were talking to, the server they were actually
talking to).
The dependency for valid ssl operation was violated almost
immediately when merchants found that ssl overhead reduced thru
thruput by 5-10 times. the regression was instead of initial contact
of the webserver (presumably url supplied by user) being ssl,
ssl was moved to checkout/pay phase where the user clicked
on a button (and url) provided by the webserver (not a url
provided by the user). It was no longer possible to provide
any assurances as to the authentity of the webserver contacted
(ssl purely being reduced to encrypting data in transmission).
we had been called in to consult with the small client/server
company on using this technology (they created) called SSL
for payment transactions
and had to go thru detailed walk thrus of the technology as
it applied to actual business processes (and the associated
implicit dependencies) ... as well as detailed walk thrus of the
new business operations that were calling themselves
certification authorities.
the other issue that we came up in applying this SSL technology
was communication between webservers and something called
the payment gateway. for  this communication we mandated mutual
authentication ... this was before mutual authentication had
been implemented in SSL. It turns out that by the time
we had it all implemented and deployed ... it also became
very apparent that the things called digital certificates
were redundant and superfluous.
the basic design point for digital certificates is first time
communication between total strangers. the payment gateway
business processes required that all the merchants had
to be pre-registered with the payment gateway and the payment
gateway pre-registered with all the merchants .... violating the
basic justification for having digital certificates.

@_date: 2008-01-31 17:50:00
@_author: Anne & Lynn Wheeler 
@_subject: Dutch Transport Card Broken 
Dutch Transport Card Broken
sorry, I didn't say that TCP required seven round-trips for reliable the statement was that minimum TCP operation was seven packet
exchange (for reliable operation) .... sort of 3.5 round-trips. That
VMTP (rfc 1045) reduced that to minimum of five packet exchange
(sort of 2.5 round-tips) ... and that XTP got it to a minimum of three
packet exchange (sort of 1.5 round-trips) for reliable operation.
from my RFC index
rfc 1045 summary
1045 E
  VMTP: Versatile Message Transaction Protocol: Protocol specification,
  Cheriton D., 1988/02/01 (123pp) (.txt=264928) (Refs 955, 966, 969)
  (Ref'ed By 1050, 1072, 1105, 1106, 1190, 1263, 1323, 1453, 1458,
  1700, 2018, 2375, 2757) (VMTP)
as always, clicking on the ".txt=nnn" field (in rfc summary) retrieves the actual RFC.
If there is more than minimum amount of data ... TCP might involve more
than seven packet exchange ... but the minimum packet exchange is
seven packets (not round-trips).

@_date: 2008-07-04 12:59:22
@_author: Anne & Lynn Wheeler 
@_subject: WoW security: now better than most banks. 
post in thread here a yr ago (1jul07) about financial institutions attempting some
(disastrous) deployments in the 99/00 time-frame ... and then instead of blame for deployment problems ... there was quickly spreading opinion that hardware
tokens weren't practical in the consumer market place
 The bank fraud blame game
as noted in another post ... the disastrous failures were somewhat a case of
institutional knowledge not permeating different part of the organizations.
banking conferences in the mid-90s were attributing the existing online migration to the internet in large part motivated by significant customer support
problems with serial port modems (mostly with the serial port part).
 The bank fraud blame game
that even if a little bit of the experience form the earlier online banking
programs had carried over into the later hardware token deployments ...
much of the deployment problems could have been averted.
In any case, the claim could be made that the industry is still attempting
to recover from those disasters.
a couple other posts on the same subject in other threads:
 Poll: oldest computer thing you still use
 'Man in the browser' is new threat to online banking
 Public Computers

@_date: 2008-07-23 17:21:37
@_author: Anne & Lynn Wheeler 
@_subject: The PKC-only application security model ... 
original PK-init (public key) draft for Kerberos was (only) certificateless public key operation ...
i.e. kerberos server operators maintaining trusted database of their clients' public keys (in
lieu of passwords) ... PKI/certificate mode of operation was eventually added to the specification.
lots of past posts about  certificateless public key kerberos
similar implementation was done for RADIUS
general posts about certificateless (sometimes "naked") public key
X9.59 is financial transaction standard also using certificateless public key operation
part of the issue was that in the mid-90s, the x9a10 financial standard working group
had been given the requirement to preserve the integrity of the financial infrastructure
for all retail payments. One of the issues for x9.59 was that it had to be lightweight enough
to operate in existing infrastructures. Some of the certificate-oriented payment transaction
standards from the period resulted in factor of 100 times (two orders of magnitude) payload
(i.e. certificate payload overhead could be 100 times larger than basic payment transaction)
and processing (i.e. certificate processing overhead could be 100 times larger than basic
payment transaction) bloat
general discussions of the "account authority public key" model (as contrast to
"certification authority public key" model)

@_date: 2008-07-23 21:42:45
@_author: Anne & Lynn Wheeler 
@_subject: The PKC-only application security model ... 
this post references scenario for replacing the SSL server domain name certificates with a certificate-less public key infrastructure
 The PKC-only application security model
the first reply
 The PKC-only application security model
mentions certificate-less X9.59 (financial transaction), certificate-less KERBEROS (large number of infrastructure and application authentication operation) and certificate-less RADIUS (possibly dominant client authentication infrastructure in the world today used by lots of ISP, corporate intranets, webhosting operations, etc).
RADIUS provides a generalized authentication, authorization, and accounting infrastructure ... where AAA specifics can be specified on an account or client basis (i.e. including being able to easily accomodating both password and public key concurrently).
There are even RADIUS "plug-ins" for webservers for doing webserver client authentication.
A combination of replacing SSL server domain name certificates with certificate-less server operation and
and using certifcate-less RADIUS (client) authentication ... covers mutual (client & server) operation.
RADIUS references from our rfc index:
click on "Term (term->RFC field and then click on "RADIUS" (in the "Acronym fastpath"):
Remote authentication dial in user service (RADIUS)
see also authentication , network access server , network services
5176 5090 5080 5030 4849 4818 4679 4675 4673 4672 4671 4670 4669 4668
4603 4590 4372 4014 3580 3579 3576 3575 3162 2882 2869 2868 2867 2866
2865 2809 2621 2620 2619 2618 2548 2139 2138 2059 2058
clicking on any of the RFC numbers, retrieves the RFC summary in the lower frame. Clicking on the ".txt=nnn" field (in a RFC summary) retrieves the actual RFC.

@_date: 2008-07-24 10:29:34
@_author: Anne & Lynn Wheeler 
@_subject: The PKC-only application security model ... 
The PKC-only application security model
 The PKC-only application security model
 The PKC-only application security model
another approach that X9 financial standard organization took to attempt the enormous
digital certificate bloat was standards effort for "compressed" digital signature ...
possibly reducing  100-times bloat to possibly only 5 to 10 times bloat. was some conjecture that such "lightweight" digital certificates might also find
place in wireless applications.
part of compression effort was to recognize that the server already had much
of the information was exactly the same in every certificate and/or the already possessed.
I raised the issue (rather than harping on the theme that digital being redundant and superfluous ... besides 100 times bloat) .... that (for all the
situations they were looking at) the server already had all the information in a digital
certificate. Therefor, it would be possible to define a new class of zero byte
digital certificates that would be appended to every digitally signed

@_date: 2008-07-30 08:58:08
@_author: Anne & Lynn Wheeler 
@_subject: Secure64 Develops First Automated DNSSEC Signing Application to Help 
Secure64 Develops First Automated DNSSEC Signing Application to Help Secure the Internet Worldwide
from above:
Secure64 Software Corporation has developed a product that
dramatically simplifies the implementation and management of
DNSSEC. Secure64 DNS Signer? is the first and only product that
addresses each of the obstacles that have slowed the widespread
deployment of DNSSEC zone signing, including the need for simplicity,
security, auditability and scalability. While recent patching efforts
have mitigated the impact of the cache poisoning vulnerability
identified by Dan Kaminsky and widely reported by the media,
deployment of DNSSEC is widely regarded as the only viable long-term
solution to securing the Domain Name System (DNS).
... snip ...
One of the people behind Itanium design ... was one of the Secure64
founders ... somewhat as part of demonstrating what could be done with
features that had been included in Itanium chip architecture. I've
noted before that they had been heavily involved in earlier RISC chip
efforts ... including original 801 risc chip. misc. past posts
mentioning 801, risc, romp, rios, somerset, fort knox, power/pc, etc

@_date: 2008-06-02 22:29:50
@_author: Anne & Lynn Wheeler 
@_subject: Can we copy trust? 
that was one of the business case problems early in SSL for
electronic commerce ... namely majority of ecommerce was
with repeat sites ... while design point of digital certificates
is for first time communication between strangers.
the other factor that bounded what merchants would pay
was liability in electronic commerce ... there were already
paying significant interchange fees as part of protecting
the consumer. certification authorities weren't looking
at taking on any of that aspect.
the combination has been pushing digital certificates
into the no-value market segment ... which, in turn,
further limits what would could be charged for.

@_date: 2008-06-09 18:07:12
@_author: Anne & Lynn Wheeler 
@_subject: Ransomware 
At Jim Gray's tribute on the 31st, Bruce Lindsay gave a talk about Jim's
formalization of transaction processing enabled online transactions ... i.e.
needed trust in the integrity of integrity of transaction as prerequisite
to move from manual/paper processes.
In the early 90s, when glasshouse and mainframes seeing significant
downturn in their use ... with lots of stuff moving off to PCs, there
was a study that half of the companies that had a disk failure involving
(business) data that wasn't backed up ... filed for bankruptcy within
30 days. The issue was that glasshouse tended to have all sorts
of business processes to backup business critical data. Disk failures
that lost stuff like billing data had significant impact
on cash flow (there was case of large telco that had
bug in its nightly backup and when the disk crashed with customer
billing data ... they found that there didn't have valid backups).
Something similar also showed up in the Key Escrow meetings in the
mid-90s with regard to business data that was normally kept in encrypted
form ... i.e. would require replicated key backup/storage in order to
retrieve data (countermeasure to single point of failure). part of the
downfall of key escrow was that it seem to want all keys ... not just
infrastructure where business needed to have replicated its own

@_date: 2008-06-17 13:53:59
@_author: Anne & Lynn Wheeler 
@_subject: Own a piece of the crypto wars 
archeological email about proposal for doing pgp-like public key
(from 1981):
the internal network was larger than the arpanet/internet from
just about the beginning until sometime summer of '85. corporate
guidelines had become that all links/transmission leaving corporate
facilities were required to be encrypted. in the '80s this met
lots of link encryptors (in the mid-80s, there was claim that
internal network had over half of all the link encryptors in the world).
a major crypto problem was with just about every link that crossed any
national boundary created problems with both national gov. links
within national boundaries would usually get away with argument
that it was purely internal communication within the same
corporate entity. then there was all sorts of resistance encountered
attempting to apply that argument to links that cross national
boundary (from just about every national entity).
For other archeological lore ... old posting with new networking
activity from 1983
above posting includes listing of locations (around the world)
that had one or more new network links (on the internal
network) added sometime during 1983 (large precentage
involved connections requiring link encryptors).
more recent post
mentioning coming to the realization (in the 80s) that there
were three kinds of crypto.

@_date: 2008-06-30 12:49:11
@_author: Anne & Lynn Wheeler 
@_subject: The wisdom of the ill informed 
the other scenario was that the cryptography part was done from such a myopic standpoint ... that they failed to consider the end-to-end I've repeatedly heard excuses that the cryptographers in the wifi debacle believed that they could only design a solution based on significant hardware restrictions/constraints. part of what i observed ... by the time any of them shipped ... the hardware restrictions/constraints no longer existed . the other thing that i observed was that with relatively trivial knowledge about chips ... it was possible to come up with an integrated solution that incorporated both the necessary hardware and the necessary cryptography  ...  there has got to be some analogy here someplace about the blind trying to describe an elephant; in addition to the "point solution" analogy, failing to take in the overall infrastructure.
i've repeatedly claimed that we did that in the AADS chip strawman solution
that including addressing all the issues that showed up in scenarios like with the "yes cards"

@_date: 2008-05-02 15:34:19
@_author: Anne & Lynn Wheeler 
@_subject: SSL use 
I've periodically posted that certain assumptions were made about "safe" SSL deployment for electronic commerce that were almost immediately The original assumptions assumed that the enduser knew the binding between the webserve that they thot they were talking to and the corresponding URL ... which they would then type into the browser. Then SSL would provide the assurance that the webserver that was actually being talked to corresponding URL. The two pieces together than provided that the enduser thot they were talking to was, in fact, the webserve that they were talking to.
Almost immediately merchants invalidated the assumptions when they found that SSL represeted 4-5 times degradation in webserver thruput ... and dropped back to just using SSL for payment/checkout portion of the electronic commerce. Now a web "button" was clicked, providing an URL. Now the only thing going on was that SSL would verify that whatever webserver, the webserver claimed to be, was the webserver it claimed.
This button clicking operation invalidated the original safety assumptions regarding the use of SSL for electronic commerce. The URL supplied by the button can be anything. Some amount of 3rd party payment processing outsources appeared to have taken advantage of this feature. A lot of phishing email also takes advantage of the paradigm also.
I was recently invited to resister at a website with a non-US country domain. My registration would not even closely work since it appeared to require IE ... and since I don't have any windows machines ... I also don't have any IE browser. However in the process I thot I would poke around a little.
I prefixed the URL with https (instead) of http. This got me a warning that the certificate was not for the indicated domain. When i looked at the certificate, it came from a certification authority that my browser recognized but was for a ".com" domain associated with some NIGERIAN payment processing operation.
I then check the ip-address of the original (non-US country) domain and found it mapped to some US-based webhosting company. I then check the ip-address of the NIGERIAN payment processing operation and found it mapped to some other US-based webhosting company.
I can only speculate that the first webhosting operation has some sort of default configuration for electronic commerce ... where SSL gets mapped to payment processing operation of this NIGERIAN payment processing operation.

@_date: 2008-05-26 10:20:08
@_author: Anne & Lynn Wheeler 
@_subject: not crypto, but fraud detection  
*Irish Bank Debit Card Skimmers Net ?1m*
from above:
Most of the withdrawals took place at the end of April and early May 2008. Many of the victims contacted their banks to notify them of the withdrawals, as the banks? fraud detection systems had failed to spot the suspicious activity.
... snip ...

@_date: 2008-05-27 10:32:24
@_author: Anne & Lynn Wheeler 
@_subject: not crypto, but fraud detection + additional 
in theory "signature" debit (i.e. debit transaction w/o PIN) and credit could both work ...  since they both go thru the same way.
pin-debit goes thru in real time and the merchant has assurance that the transaction has been approved (and pin authenticated).  as a result, the interchange fee is much lower ... because the related risk/fraud is presumed to be much lower.
signature debit and credit basically go thru the network the very same way. the machine (either the actual POS terminal or a store controller) remembers all the transactions and there is periodic batch "settlement" (end of shift, or end of day). Settled transaction may or may not have a separate, associated "real time authorization" transaction.
The merchant pays extra charge for each "real time authorization" transaction (which tend to be credit card specific regarding whether the account is active and the new transaction is within the card's credit limit or "open to buy").
the associated "interchange fee" is lower on transactions with "real time authorizations" (presumably transactions with "real time authorizations" tend to have lower risk/fraud). However, transactions may also be settled w/o an associated "real time authorization" (which will have a higher interchange fee since there is presumption of higher risk/fraud). there are some old merchant "small fraud" stories ... where the merchant claimed in the settlement transaction to have a separate "real time authorization" ... when there wasn't one (they got both the lower interchange fee w/o actually having to pay for a real-time authorization transaction ... this was before some financial institutions had the ability to reconcile the information).
All have associated risk/fraud ... one of the tricks is for the financial institution to appropriately adjust the interchange fee to cover the financial institutions associated risk.
There has been recent congressional hearings, EU anti-trust actions and merchant complaints that the financial institutions have adjusted the interchange fees way over what is needed to cover the associated risk. There were snide articles that financial institutions are making significant profits off of the risk adjusted interchange fees. 2-3 yrs ago supposedly something like 40percent of US financial institution bottom line was coming from these (risk adjusted) interchange fees ... and for many retailers it represented their single largest expense.
this is been highlighted in the significant expense going into TV spots to promote "signature debit" .... since the "interchange fee" and especially the profit is significantly higher (vis-a-vis pin-debit).
some of this was discussed in the "bank fraud blame game" thread that went on in this mailing list
last june, july ... my posts archived here.
 The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game
 a fraud is a sale, Re: The bank fraud blame game
 a fraud is a sale, Re: The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game
 a fraud is a sale, Re: The bank fraud blame game

@_date: 2008-11-27 11:18:18
@_author: Anne & Lynn Wheeler 
@_subject: Certificates turn 30, X.509 turns 20, no-one notices 
in the past capitalization referred to CAs making the rounds of
wallstreet with $20B/annum business case (i.e. approx. $100/annum per
adult in the US).
The lower case "public key" met that an entity could make
their public key available ... as countermeasure to the shortcomings
of shared-secret (password/PIN) paradigm ... where a unique shared-secret
was required for every unique security domain (the current scenario where
scores or hundreds of unique shared-secrets have to be managed).
going from lower-case ... where an entity could share the same
public key with large number of different entities, to upper-case,
was the scenario justifying the $20B/annum business case.
sometimes the issue isn't whether the public key is open/closed ... the
issue is whether the business liability is between the parties
involved ... or should random, unrelated participants also get
involved in the business processes.
there have been some attempts at obfuscation ... attempting
to confuse the boundaries between the authentication technology
and the parties involved in business processes liability
i was at annual acm sigmod (aka database) conference in 91 (92?)
and during one of the sessions, somebody asked a question regarding
what was all this X.5xx stuff going on ... and the reply was that
a bunch of networking engineers were trying to re-invent 1960s
database technology.

@_date: 2008-09-23 16:03:57
@_author: Anne & Lynn Wheeler 
@_subject: Elliptic Curve Crypto (ECC) support for PKINIT 
RFC 5349
September 2008
This document describes the use of Elliptic Curve certificates,
Elliptic Curve signature schemes and Elliptic Curve Diffie-Hellman
(ECDH) key agreement within the framework of PKINIT -- the Kerberos
Version 5 extension that provides for the use of public key

@_date: 2009-08-06 12:35:46
@_author: Anne & Lynn Wheeler 
@_subject: Client Certificate UI for Chrome? 
digital certificate design point supposedly was the dial-up email of the early 80s,
dial-up, exchange email, hang-up ... and then faced with how to deal with first
time email from complete stranger. basically electronic analog for letters of
credit/introduction from sailing ship days.
in the 90s, because of numerous privacy and liability issues ... there
was some number of "relying-party only" certificates; individual registered
their public key with the institution, institution then created a digital
certificate with the public key, archived it, and returned a copy to the
individual. the individual, in communication with the institution would
digitally sign the communication and then append the digital certificate.
However, it was trivial to prove that the institution/relying-party already
had a copy of the information ... and the appended digital certificate
was redundant and superfluous. misc. past posts discussion relying-party only
digital certificates
furthermore, major foreys into this sector were by financial institutions
for the purpose of payment transactions. a complicating factor ... besides
the digital certificates being redundant and superfluous ... they added
a 100 times payload size bloat to the typical payment transactions. misc.
past posts
there was a financial standards effort that looked at possibly doing
"compressed" digital certificates (trying to achieve only ten times bloat)
... eliminating redundant fields and information already in the possession
of the individual's financial institution. we showed that the individual's
financial institution already had superset of the information in the
digital certificate ... so it was possible to compress digital certificates
to zero bytes ... and then mandate that financial transactions would always
have zero-byte certificates appended (as opposed to no appended digital
Something similar was demonstrated for RADIUS and Kerberos ... registering
a public key in lieu of password ... some past references
and also something similar for registering public key with domain
name registration with domain name infrastructure ... for use in
lieu of SSL digital certificates
that left institutions and relying party with no-value business processes
as digital certificate opportunities ... i.e. no-value transactions where
the relying party couldn't justify the cost of their own entity repository
and/or justify the cost of doing an online transactions to obtain such entity
information ... and of course ... the original design point, the "offline
email" scenario with first time communication with complete strangers.
One of the problems with no-value market segment is that it is hard for
institutions and individuals to justify paying for things without
any value ... and therefor it is hard to find entities looking
at selling things for nothing.

@_date: 2009-08-21 17:59:08
@_author: Anne & Lynn Wheeler 
@_subject: Client Certificate UI for Chrome?  -- OT anonymous-transaction 
most of the financial industry digital certificate specifications
were "relying party only" digital  certificates ... effectively only
containing an account number ... because of privacy (both in us and
europe) and liability issues. some of this was also about the time
that EU-DPD made statements that electronic retail transactions
should be w/o names (i.e. remove person names from payment cards
... also a form of "relying party only" instrument).
this somewhat side-stepped whether it was linkable or not ...
since it then was back at the financial institution whether
the account number was linked to a person or anonymous ... but
did meet privacy requirements for retail payments .... depending
on gov. & financial institution with regard to any possible
"know your customer" mandates ... a court order to the
financial institution  had the potential of revealing any linkage
There were a couple issues:
1) even as a relying-party-only digital certificate ... the digital
certificate gorp resulted on the order of 100 times payload bloat for typical
payment transaction payload size. there were two approaches a) strip the
digital certificate off the payment transaction as early as possible
to minimize the onerous payload penalty; b) financial standards looked
at doing compressed relying-party-only digital certificates ... possibly
getting the payload bloat down to only a factor of ten times (instead of
one hundred times).
2) it was trivial to show that the issuing financial institution
already had a superset of information carried in the relying-party-only
digital certificate ... so it was redundant and superfluous to repeatedly
send such a digital certificate back to the issuing financial institution
appended to every payment transactions (completely redundant and superfluous
was separate issue from representing factor of 100 times payload bloat).
so there were two possible solutions to the enormous payload bloat
a) just digital sign the transaction and not bother to append
the redundant and superfluous relying party only certificate
b) the standards work on compression included eliminating fields
that the issuing financial institution already possessed ... since
it was possible to demonstrate that the issuing financial institution
had a superset of all information in a relying-party-only digital
certificate ... it was possible to compress the size of the
digital certificate to zero bytes. then it was possible to mandate
that zero byte digital certificates be appended to every payment
transaction (also addressing the enormous payload bloat problem).
the x9.59 financial transaction standard ... some refs
just specified requirement for every payment transaction
to be authenticated ... and didn't really care whether there was
no digital certificate appended ... or whether it was
mandated that zero-byte digital certificates were appended.

@_date: 2009-02-14 15:01:10
@_author: Anne & Lynn Wheeler 
@_subject: Crypto Craft Knowledge 
Note that one of the things that FSTC did in e-check (and I did in
x9.59) was specify the fields from existing transport infrastructures
that were used for signing.
Part of this was that standard digital signature processes (along with
digital certificates if necessary) could represent a one hundred times
factor payload bloat ... some past comments about various efforts that
tried to apply knee-jerk application of digital signatures to existing
financial infrastructures ... resulting in two orders of magnitude
payload bloat
One of the side-effects of some of the extreme bloated approaches was
that they actually avoided defining end-to-end protocol ... just defined
a digitally signed operation for flow over the internet ... which was
then stripped off and thrown away at the gateway to the "real" infrastructure.
In any case, as a result, the fields from standard existing financial
transaction was specified for encoding ... that was signed ... and then just
the digital signature was appended to existing formatted message.
At the receiving end, the fields were re-encoded and verified with
the transmitted digital signature.
The issue for FSTC that prompted FSML ... was that at the time, the
encoding standards weren't deterministic (i.e the sender and
the recipient had to use the same encoding rules ... so the signed
encoding and the verified encoding were the same). FSML was then
contributed to W3C and incorporated into the XML digital signature
in that sense, neither e-check nor X9.59 required a length field
... they just specified all the encoded transaction fields that were
necessary for characterizing a transaction unambiguously.
As an aside ... we didn't particularly come at it from the stand-point
of crypto craft or even security-critical craft ... we came at it
from standpoint of business-critical craft ... where things might
fail in a multitude of ways (some possibly having nothing to do
with security). slightly related recent post mentioning FAA ATC
 Bletchly Park fires up Big Green-Eyed Monster
Another example was we did "audits" of RAID disk arrays
... looking for design &/or implementation shortcomings
thatmight result in loss of data.
In the "security" context ... we did some audits where
we identified (nearly trivial) exploits in end-to-end operation
... and were told that wasn't part of the security protocol.

@_date: 2009-07-01 17:47:37
@_author: Anne & Lynn Wheeler 
@_subject: password safes for mac 
Nominally, hardware token is "something you have" authentication. In many implementations,
business rules are added to the chip for stuff like business requirements for
multi-factor authentication (like in conjunction with PIN). The resulting
situation is business rule/environment specific.
In the late 90s, there was work on EU FINREAD standard for external trusted
card-acceptor device ... that had trusted pin-entry and trusted display. The
objective was countermeasure to lots of well known compromises of PCs (including
keylogger ... implying that compromised PC could operate an external hardware token,
even if PIN was required per transaction).
A lot of this evaporated in the early part of this decade in the wake  of with
various troubles associated with hardware tokens.
As an aside ... one of the things we did in the AADS patent portfolio was
to remove business rules from the hardware token ... as part of
enabling "person centric" operation (i.e. the same token might be
used for lots of different environments ... as opposed to having
hardware token for every unique business environment).
An AADS hardware token can support both single-factor as well as multi-factor
authentication operation ... but it is up to the business application interacting
with the hardware token to indicate the amount of authentication & integrity
(some assumption about "security proportional to risk" ... for instance,
whether or not PIN might be required for every operation, or at all).

@_date: 2009-05-05 17:06:10
@_author: Anne & Lynn Wheeler 
@_subject: Has any public CA ever had their certificate revoked? 
we had been brought in to help word-smith the cal. state electronic signature law. there was some legal types who very clearly differentiated what was required for something to be considered "human signature" (implication that something has been read, understood, agrees, approves, &/or authorizes) and PKI "digital signatures" used for authentication.
we've periodically commented that there may be some cognitive dissonance because both terms contain the word "signature".
slightly related pontification
regarding this recent article mentioning SSL
Inventor: SSL security woes are really the fault of browser design

@_date: 2009-05-09 14:26:51
@_author: Anne & Lynn Wheeler 
@_subject: Solving password problems one at a time, Re: The password-reset 
at least the initial introduction of one-time-account number displays
had a problem because they couldn't meet the flexing specification
(like cards in mens wallet and getting sat on).
note that there has been big push to "signature debit" (similar interchange
fees and fraud as "signature credit") with 15 times the fraud of PIN-debit
(which has significantly lower interchange fees compared to signature debit)
mentioned in this post from 2006
there has been some articles about "unsafe" cards being a profit item
for financial institutions ... since they charge merchants a significantly
higher interchange fee. there have been references that there can be
as much as a order of magnitude difference in fees between "unsafer" transaction
fees and "safer" transaction... with "unsafe" transaction fees
contributing significantly to reports that payment fees have represented
as much as 40% of bottom line for US consumer financial institutions
(an order of magnitude reduction would be a big hit). part of thread
on this subject in this mailing list from two years ago
In the 90s, one of the proposals for some "safer" (PKI-based) internet transactions,
as part of offsetting cost of PKI deployment, was changing the burden of proof
(instead of bank/merchant proving consumer did it, consumer has to prove that they didn't
do it) ... something  more akin to what was done in the UK. some recent references:
that PKI effort floundered for a number of reasons ... some discussed in this recent
post (besides the digital certificates being redundant and superfluous):
in the early part of this decade/century, related to introduction of some of
"safer" internet payment technologies, there was an attempt to justify even
higher merchant interchange fees ... than the "unsafe" fees. this resulted in
some amount of cognitive dissonance ... since merchants had been accustomed
to their interchange fees being proportional to amount of fraud ... aka as the amount
of fraud goes up ... so does the interchange fees ... but this change would
create two domains ... one where the interchange fees go up proportional
to fraud ... and then a point where interchange fees continue to climb
as fraud is reduced. related post
In the 90s (as part of AADS chip strawman), I semi-facetiously commented about
taking a $500 milspec part, cost reducing by 2-3 orders of magnitude while improving
the integrity.
Another part of the AADS chip strawman was enalbing a shift from an institutional-centric
hardware token paradigm to a person-centric hardware token paradigm ... i.e. the same AADS
chip could be used for contact, contactless, proximity, transit turnstyle, single-factor authentication,
multi-factor authentication, low value transactions, high value transactions, payment transactions,
point-of-sale transactions, internet transactions, login authentication, etc. It wasn't just
that the same kind of chip could be used for all these different purposes ... but provide
the individual the option of being able to register their personnal chip for a broad range of
applications. Part of the challenge was documenting all the issues that were raised justifying
a institutional-centric hardware token paradigm ... and addressing each issue.
Part of it was the x9.59 financial transaction standard
part of it was demonstrating an AADS (certificateless) Kerberos solution
and part of it was demonstrating an AADS (certificateless) RADIUS solution
lots of the stuff shows up in the AADS patent portfolio (all assigned patents)

@_date: 2009-05-11 13:11:17
@_author: Anne & Lynn Wheeler 
@_subject: What happened to X9.59? 
x9 web site
"find & buy standards" URL from above:
x9 series have passed "100" ... but no longer lists x9.59. to some extent x9.59 went the way of some other payment technologies in the late 90s and early part of this decade ... when there was a big retrenching from hardware tokens and other more secure technologies for one reason or another ... some of it touched in this recent post
my x9.59 related information
there was this NACHA RFI from 1998
and report mentioned here
declaring success and then evaporating
in large part because of the rapidly spreading opinion that hardware tokens weren't practical in consumer market. I've discussed this more recently  (although cognitive dissonance with merchants & interchange fees played a role).
hardware token issue also discussed in thread on this mailing list from two yrs ago:
 The bank fraud blame game
 The bank fraud blame game
 The bank fraud blame game
and for slight topic drift ... this thread on "new standard for encrypting card data"

@_date: 2009-05-12 20:32:32
@_author: Anne & Lynn Wheeler 
@_subject: Solving password problems one at a time, Re: The password-reset 
Deloitte staff trial Visa card with built in OTP generator for IT access control

@_date: 2009-11-09 22:01:06
@_author: Anne & Lynn Wheeler 
@_subject: Crypto dongles to secure online transactions 
deja vu 1999 .... this should be covered in enormous detail in the EU finread standards documents from the late 90s.
note that the EU finread standard from late 90s (over decade ago) was countermeasure to most every kind of PC compromise that you can think of. Basically it moved the end point out to independent hardware device with its own display and pin-pad. The transaction was still composed on the PC ... but had to be sent to the hardware finread device for approval/authentication. transaction to be approved/executed would be displayed on finread device for approval. It then required physical PIN entry to execute the approval process ... typically assumed to be a digital signature ... which was returned to the PC.
compromised PC could still do a denial of service ... but the independent finread device effectively moved the end-point from the PC out to the finread. the independent display & pin-pad ... was countermeasures to various kinds of exploits ... including
* keylogging ... trojan horse or other could execute transactions w/o users actual knowledge
* is the transaction that the user sees the actual transaction being executed
bad design might have used the finread for session authentication in lieu of separately authentication/approval for every transaction (which would allow trojans on compromised pcs to execute fraudulent transactions within the boundaries of the session.
infrastructure would still be vulnerable to various kinds of social engineering ... convincing end-user to execute valid transactions for the benefit of the attacker.
There was some conjecture (again more than decade ago) that if finread deployment eliminated all the other kinds of compromises ... that user education programs could purely concentrate on social engineering exploits (sort of like the stuff for little kids to have nothing to do with strangers).
EU finread program got caught up in the disastrous deployment of serial-port card acceptor device at the start of the decade (many versions had the appearance of card acceptor device with its own independent display and pin-pad ... slightly akin to small POS terminals that might appear at point-of-sale). The disastrous serial-port acceptor device deployment resulted in rapidly spreading opinion in the financial industry that smartcards and card readers weren't practical in the consumer market ... resulting in nearly all such programs quickly evaporating w/o hardly a trace.
As i've mentioned before ... it wasn't actually a problem with smartcards and/or card readers .... but with the serial-port interface. In the 1995 time-frame there were a number of presentations about moving the dial-up home banking programs to the internet ... in large part motivated by the significant customer support costs associated with supporting serial-port modems (one such bank program claimed to have a library of over 60 serial port modem software drivers to try and cover some reasonable set of their customers. Problems with the whole serial-port gorp was also big motivator behind development of USB.
In any case, i've commented before about the financial industry institutional knowledge and experience apparently rapidly evaporated between the migration of dial-up home banking (migration to the internet) and 2000. A partial/possible explanation might be that the vendor, knowing that everything was moving to USB, saw a really great chance to unload their stock of obsolete serial-port devices on a client that didn't really know what they were doing.
lots of past EU finread standard posts:
random trivia ... i was at an eu finread standard meeting in brussels not long before the whole thing with serial-port resulted in all such programs imploding (even those not using serial-port ... radiation from the event seemed to catch everything)

@_date: 2009-11-11 11:08:39
@_author: Anne & Lynn Wheeler 
@_subject: Crypto dongles to secure online transactions 
vulnerabilities tend to be proportional to complexity.
we had been asked in to consult with small client/server startup that wanted to do payment transactions on their server ... they had also invented this technology called "SSL" applied to the process. The result is frequently called "electronic commerce". The major use/purpose of that "SSL" in the world today is hiding the account number and other transaction details.
somewhat as a result, in the mid-90s we were invited to to participate in the x9a10 financial standard working group which had been given the requirement to preserve the integrity of the financial infrastructure for all retail payments. Part of that was detailed threat&vulnerability studies of different payment methods and environments. One of the biggest problems was vulnerability of leaking account number ... since it was trivial for crooks to use it for originating fraudulent transactions ... and at the same time required by millions of business processes around the world. So part of the resulting standard was slightly tweaking the paradigm and eliminating the account number (and transaction details) as a vulnerability (which then also eliminates the major use of SSL in the world today).
along the way, i also made semi-facetious comment that i would take a $500 milspec item and aggressively cost reduce it by 2-3 orders of magnitude while making it more secure. Part of the effort effectively worked out getting it close to the EPC RFID technology process (items targeted at replacing UPC barcodes on grocery items at a few cents or less) w/o reducing security.
Basically it is all silicon ... which not only reduces a lot of after-FAB vulnerabilities ... but also eliminates the costs of a lot of the post-FAB processing steps (as silicon cost goes to zero, post-FAB processing costs started to dominate).
Along with it is the concept of security proportional to risk ... at the issuing authorization end of a transaction ... the security characteristics of the originating components can be evaluated ... in the case of the chip ... the security level of the chip can even be updated in real time as vulnerabilities are identified.
This can help decide like a when a few cent item might be needed to be replaced for higher value  transactions

@_date: 2009-11-18 18:16:34
@_author: Anne & Lynn Wheeler 
@_subject: Crypto dongles to secure online transactions 
we ran into that with doing chip that required to post-fab personalization ... eliminating lots of the costs thruout the whole infrastructure (eliminating personalization actually makes the delivered cost to the user less than the current infrastructure).
we then looked at the current "institutional-centric" paradigm ... where each institution wants to deliver token/card to user ... with having eliminating any personalization requirement ... then we claimed we could moved to a "person-centric" paradigm ... where a person could use the same token for potentially all their interactions ... having to wade through all the institutional arguments ... and addressing each one that stood in the way of moving from an institutional-centric paradigm to person-centric paradigm.
the smartcard industry was looking at possibly replacing every pin/password with a unique smartcard/dongle.
we claimed we do something like two orders magnitude reduction in fully-loaded costs by going to no personalization (and other things) ... and then another two orders magnitude reduction in number of tokens by transitioning from institutional-centric paradigm to person-centric paradigm (compared to proposed smartcard/dongle replacing every pin/password).
we then came up against that the bank marketing departments have taken advantage of the requirement for institutional personalization ... to put their brand and other stuff on every token. They started out saying they didn't want to do chip because it increased costs ... and when we showed we can come very close to driving costs to zero ... it turns out the marketing departments like the current infrastructure (despite the costs) ... because they feel it is important to have their brand on the token in each person's wallet.
There were various sorts of distractions/obfuscations ... like what happens if the "only" token fails ...
there is nothing that prevents a person from having two "person-centric" tokens (or personally choosing to have a their own unique token per institution). Then it was ... what happens if the only token is stolen. It turns out that the standard threat is the wallet/purse is stolen with all the cards (eliminating any different between there being single token or multiple tokens).
In any case ... with a paradigm that has been in place for this long ... there are quite a large number of people that don't want to change ... some for no other real reason than its different ... for others they have leveraged current paradigm for things that couldn't have been independently justified on its own.
Early on uptake in various standards organization was good ... until some of the change implications started percolating thru the infrastructure. It was analogous to what we did with secure x9.59 financial transaction standard ... and then the implications of eliminating all the associated fraud started to sink in.

@_date: 2009-11-21 18:00:31
@_author: Anne & Lynn Wheeler 
@_subject: Crypto dongles to secure online transactions 
there is no shared secret ... there is unique chip private/public key generated at power-on/test  and the public key was included/transmitted with the test result data as part of the initial power-on/test
cycle (this is process that occurs while the chips are still in wafer ... before being sliced & diced).
the silicon is designed to never (volunteerly) divulge the private key (modulo some extremely heavy duty physical attacks).
the patent stuff was all done for employer as assigned patents quite awhile ago (we've been gone for several yrs and the patent stuff keeps going on).
initially there was a large number of claims and had gotten to packaged as over 60 patents and looked to be 100 before we were done. about that point, the employer looks at filing costs in the US and international ... and directs that all the claims be packaged as nine patents. Later, the patent office comes back and makes some comment about getting tired of huge patents where the filing fee doesn't even cover the cost of reading all the claims ... and directed that the claims be packaged as larger number of claims.
while there are claims related to unique devices with unique digital signatures in other applications ... there was a patent application (in our name ... years after we are gone) this year
all the initial chips were ec/dsa (each chip with its own unique public/private key) ... all done in fab that had security certified by US, EU & other gov. institutions and also financial institutions (no compromised chips substituted for real ones) ... I even got to walk the fab in bunny suit doing my own certification.
if you want different algorithms (or key lengths) ... you have to cut a new mask and make different wafer runs. if the number of wafers in wafer runs are too small ... you would start to drive the cost/chip above a few cents. There is no single-point-of-compromise. Compromising a single chip is equivalent to skimming a single magstripe ... can do fraudulent transactions against the accounts for that chip/token (and chip compromise significantly more difficult than magstripe skimming).
In theory there might be weakness found in specific chip or specific algorithm ... but design allows for a large number of different chips and algorithms to interoperate in the same environment. For the initial chips ... I got a EAL4+ common criteria certification (by accredited lab in germany). I wanted a higher certification ... but had a problem that EC/DSA verification suite had been withdrawn. There were some higher certifications on similar chips by others ...but their design involved loading the crypto after the certification (they got certification done on chip before any software loaded). My chip had everything in silicon (all feature/functions) ... and so the certification was done on everything that would be in actual use.
in the "person-centric" scenario ... each chip's private key becomes somewhat akin to fingerprint or iris pattern ... a unique "something you have" ... as opposed to unique "something you are" (and much easier to replace/change if there is a specific compromise).
some of the patents cover not only recording public key for each account the corresponding token is authorized for (and multiple different tokens might be authorized for same account) ... but also knowledge about the assurance level of the related chip. Real-time updates are then available about chip assurance level ... and real-time authorizations can not only take into account whether the transaction is within the account balance ... but potentially is the assurance level of the chip is high enough for authorizing the transaction.
X9.59 financial standard transaction protocol also allows for the environment that the transaction is performed in to also sign the transaction (in addition to the person's chip). Real-time authorization then may take into account both the assurance level (potentially updated in real-time) of the user's chips as well as the assurance level of the transaction environment (in determining if there is sufficient assurance for the transaction in question). Some of the people responsible for the V3 extensions for X.509 overlooked the issue of assurance characteristics ... when they were originally defining the V3 extensions (of course the whole x.509 is based on static information ... and disappears in a real-time environment).
there are different issues with other chip implementations. there was rather large pilot deployment of such a chip in the US for point-of-sale early part of this decade ... it had a "yes card" problem ... the last paragraph of this cartes 2002 trip report ... includes mention of presentation on it being trivial to make a counterfeit "yes card" (chip)
... in any case, all evidence of that pilot appeared to subsequently evaporate (we had considered/documented such problem several yrs earlier). Current status in the US is possibly somewhat consequence of that ("yes card") pilot (a presentation at the time ... noted that "yes card" vulnerability actually made fraud worse than exists with magstripe; somebody in the audience asking how billions of dollars could be spent to prove that chips are less secure than magstripe) ... not so much the cost of a single deployment ... but there might turn out to be the cost of several deployments. misc. past posts mentioning the "yes card"

@_date: 2009-11-21 18:06:59
@_author: Anne & Lynn Wheeler 
@_subject: Crypto dongles to secure online transactions 
We went thru all the scenarios with the objections on why they wanted institutional-centric paradigm ... part of the scenario was putting the assurance level of the chip on level with assurance level of your fingerprint or iris pattern ... and asking when institutions were going to start issuing individual, institutional-specific fingers for people to use.
this is various person-centric claims here and there  (assigned and still having activity after we've been gone for yrs)
there is specific granted patent here:

@_date: 2009-11-25 10:16:42
@_author: Anne & Lynn Wheeler 
@_subject: Crypto dongles to secure online transactions 
============================== START ==============================
Simplest card/token is basically (single-factor) "something you  have"  authentication
the "cheapest" RFID proximity card is just some static data ... that can be trivially copied and reproduced ... think of it somewhat akin to a wireless magstripe. that has also the "YES CARD" point-of-sale "contact" card vulnerability. Compromised POS terminal that recorded the "static data" from card transaction and trivially used to produce a counterfeit card (little or no difference from compromised POS terminal that records magstripe data). What made it worse than magstripe was that POS terminals were programmed to ask a validated chip three questions 1) was the entered PIN correct, 2) should the transaction be done offline, and 3) is the transaction within the account credit limit. A counterfeit "YES CARD" would answer "YES" to all three questions (it wasn't necessary to even know the correct pin with counterfeit "YES CARD" ... and deactivating the account ... as in magstripe ... wasn't sufficient to stop the fraud). A counterfeit "YES CARD" was also some other counterme
asures that had been built into the infrastructure:
a little more secure is two-factor token that requires both the token and possibly "something you know". However, two-factor authentication is assumed more secure is based on single factor authentication is based on
the different factors having independent compromises. In the case of the "YES CARD" (supposedly two-factor) ... it was only necessary to compromise the token's static data ... and it wasn't even necessary to know the correct PIN. In the case of pin-debit cards ... skimming compromises of ATMs or point-of-sale terminals can collect both the PIN and the magstripe data at the same time (invalidating assumption about independent compromises).
we had somewhat been asked in the mid-90s to participate in the x9a10 financial standard group (which had been given the requirement to preserve the integrity of the financial infrastructure for all retail payments) because of having worked on this stuff now frequently called "electronic commerce". This was *ALL* as in debit, credit, ACH, internet, point-of-sale, low-value, high-value, face-to-face, unattended, and/or transit. Transit-turnstyle has similar requirements to building access ... although the contactless power limitations and contactless elapsed time requirements can be more stringent than building access.
Somewhat as a result ... the related work on the AADS chip strawman, had all sorts of requirements ... form factor agnostic, very-very fast, very-very low-power, contactless capable ... but for high-value ... had to no have *NO* "static data" and very difficult to counterfeit ... but at the same time ... for low-value ... had to have as close to zero cost as possible.
Most of the alternatives from the period ... tended to only consider a very small subset of those requirements ... and therefor created a solution that had a single, specific operation and were ill-suited for a general purpose use. A simple issue was having the same token that was multi-factor authentication agile ... operate with single-factor (something you have) at a transit turnstyle (no time to enter PIN) ... but works the same way at a high-security building access turnstyle that requires multi-factor authentication ("something you have" token in conjunction with PIN "something-you-know" or palm "finger length" something-you-are). The same token then also works the same way at point-of-sale ... where low-value may just be single-factor authentication ... but increasing value transaction may have increasingly complex authentication.
Many of the above issues were also part of the prerequisite for being able to move from an "institutional-centric" paradigm (that also tended to only meet a small subset of possible authentication requirements) and a generalized "person-centric" paradigm.
The requirements to address *ALL* retail-payments in the mid-90s (in the x9a10 financial standard group) ... then were large factor in driving the AADS chip strawman by the the late-90s ... that had the features necessary for satisfying a *person-centric" paradigm.

@_date: 2010-08-01 09:31:05
@_author: Anne & Lynn Wheeler 
@_subject: Five Theses on Security Protocols 
The publicity campaign for SSL digital certificates and why consumers should feel good about them was major reason that long & ago and far away, I coined the term "merchant comfort" certificates.
Part of what was recognized by the x9a10 financial standard working group (and the resulting x9.59 financial standard) was that relying on the merchant (and/or the transaction processor) to provide major integrity protection for financial transactions ... is placing the responsibility on the entities with the least financial interest ... the "security proportional to risk" scenario
(where largest percentage of exploits occur in the current infrastructure ... including data breaches)
The payment current paradigm has the merchant financial interest in the transaction information is the profit on the transaction ... which can be a couple dollars (and transaction processor profit can be a couple cents on the transaction). By comparison (in the current paradigm), the crooks financial motivation in the transaction information is the account credit limit (or account balance) which can be several hundred to several thousand dollars ... as a result, the crooks attacking the system, can frequently afford to outspend the defenders by two orders of magnitude (or more).
The majority of fraud (in the current infrastructure) also contributed to retailers having significant "fraud" surcharges onto their interchange fees. Past crypto mailing list threads have discussed that financial infrastructures make a significant percent of their profit/bottom-line from these "fraud surcharges" (large US issuing financial institutions having made 40-60% of their bottom line from these fees) ... with interchange fee "fraud surcharges" for highest risk transactions being order-of-magnitude or more larger than for lowest risk transactions.
The work on x9.59 financial standard recognized this dichotomy and slightly tweaked the paradigm ... eliminating knowledge of account number and/or information from previous transactions as a risk. This would significantly decrease the fraud for all x9.59 transactions in the world (i.e. the x9a10 financial standard working group had been given the requirement to preserve the integrity of the financial infrastructure for *ALL* retail payments; point-of-sale, face-to-face, unattended, internet, debit, credit, stored-value, high-value, low-value, transit turnstyle, cardholder-not-present; aka *ALL*). As a result, it also eliminates the major use of SSL in the world today ... hiding financial transaction information. It also eliminates other kinds of risks from things like data breaches (didn't eliminate data breaches, but eliminated the motivation behind the majority of breaches in the world today, being able to use the information for fraudulent financial transaction).
The downside, is with the elimination of all that fraud ... it eliminates the majority of "fraud surcharge" from interchange fees ... and potentially cuts the "interchange fee" bottom line for large issuing institutions from 40-60% to possibly 4-6%. It sort of could be viewed as commoditizing payment transaction.
A decade ago, there were a number of "secure" payment transaction products floated for the internet ... with significant upfront merchant interest ... assuming that the associated transactions would have significant lower interchange fees (because of the elimination of "fraud" surcharge). Then things went thru a period of "cognitive dissonance" when financial institutions tried to explain why these transactions should have a higher interchange fee ... than the highest "fraud surchange" interchange fees. The severity of the "cognitive dissonance" between the merchants and the financial institutions over whether "secure" payment transactions products should result in higher fees or lower fees contributed significantly to the products not being deployed.

@_date: 2010-08-01 12:49:55
@_author: Anne & Lynn Wheeler 
@_subject: A mighty fortress is our PKI 
other public key & science center trivia; former RSA CEO also at science center ... following
recent entry from his blog:
lots of past posts mentioning science center, 4th flr, 545 tech sq
a couple old emails from 1981 ... discussing a certificate-less, PGP-like implementation for the internal network
... aka the internal network was larger than the arpanet/internet from just about the beginning until sometime late '85 or early '86. one big difference from arpanet/internet was corporation required all links to be encrypted ... and in the mid-80s there
was the claim that the internal network had over half of all hardware link encryptors in the world ... only practical solution at the time. I was running multiple T1 links in the period ... and DES-encryption processing for sustained full-duplex traffic from a single T1 link was more than enough to consume multiple mainframe processors. old email on the subject (regarding doing some benchmarking of DES software encrypt/decrypt)
past posts mentioning internal network

@_date: 2010-08-01 16:08:42
@_author: Anne & Lynn Wheeler 
@_subject: Five Theses on Security Protocols 
SET specification predated these (as also internet specific, from the mid-90s, went on currently with x9a10 financial standards work ... which had requirement to preserve the integrity for *ALL* retail payments) ... the decade past efforts were later were much simpler and practical ... and tended to be various kinds of "something you have" authentication. I'm unaware of any publicity and/or knowledge about these payment products (from a decade ago) outside the payment industry and select high volume merchants.
The mid-90s, PKI/certificate-based specifications tended to hide behind a large amount of complexity ... and provide no effective additional benefit over & above SSL (aka with all the additional complexity ... did little more than hide the transaction during transit on the internet).  They also would strip all the PKI gorp off at the Internet boundary (because of the 100 times payload size and processing bloat that the certificate processing represented) and send the transaction thru the payment network with just a flag indicating that certificate processing had occurred (end-to-end security was not feasible). Various past posts mentioning the 100 times payload size and processing bloat that certificates added to typical payment transactions
In the time-frame of some of the pilots, there were then presentation by payment network business people at ISO standards meetings that they were seeing transactions come thru the network with the "certificate processed" flag on ... but could prove that no certificate processing actually occurred (there was financial motivation to lie since turning the flag on lowered the interchange fee).
The certificate processing overhead also further increased the merchant processing overhead ... in large part responsible for the low uptake ... even with some benefit of lowered interchange fee. The associations looked at providing additional incentive (somewhat similar to more recent point-of-sale, hardware token incentives in europe), effectively changing the burden of proof in dispute (rather than the merchant having to prove the consumer was at fault, the consumer would have to prove they weren't at fault; of course this would have met with some difficulty in the US with regard to regulation-E).
Old past thread interchange with members of that specification team regarding the specification was (effectively) never intended to do more than hide the transaction during transnmission:
 non-repudiation, was re: crypto flaw in secure mail standards
aka high-overhead and convoluted, complex processing of the specification provided little practical added benefit over and above what was already being provided by SSL.
oblique reference to that specification in recent post in this thread regarding having done both a PKI-operation benchmark (using BSAFE library) profile as well as business benefit profile of the specification (when it was initially published ... before any operational pilots):
 A mighty fortress is our PKI
with regard specifically to BSAFE processing bloat referenced in the above ... there is folklore that one of the people, working on the specification, admitted to a adding a huge number of additional PKI-operations (and message interchanges) to the specification ... effectively for no other reason than the added complexity and use of PKI-operations.

@_date: 2010-08-01 16:48:37
@_author: Anne & Lynn Wheeler 
@_subject: Five Theses on Security Protocols 
oops, finger-slip ... that should be:
 non-repudiation, was re: crypto flaw in secure mail standards
my archived post (14July2001), references earlier thread in commerce.net hosted, ansi-standard electronic payments list ... archive gone 404 ... but lives on at the wayback machine; aka from 1999 regarding what did SET intend to address

@_date: 2010-08-02 13:43:23
@_author: Anne & Lynn Wheeler 
@_subject: Five Theses on Security Protocols 
One of the other issues in the current payment paradigm ... with or without certificates ... the end-user as relying party, is frequently not in control of the risks & security measures related to their assets (fraudulent transactions against their accounts).
This shows up with what kind of fraud gets publicity (at least before the cal. state breach notification legislation) ... namely the kind that consumer has some control over ... lost/stolen cards ... and/or recognizing "add-on" ATM cash machine skimmers. There was almost no publicity about breaches and/or instances were skimmers were installed in machines at point of manufacture ... since about the only corrective action that consumers would have (in such cases), was to stop using the card altogether.
I was one of the co-authors for the financial industry X9.99 privacy standard ... and one of the most difficult concepts to get across was that the institution wasn't providing security for protecting the institutions' assets ... but providing security to provide assets of other entities (it required rethink by security departments about what was being protecting from whom ... in some cases it even required the institution to protect consumer assets from the institution itself).
We were somewhat tangentially involved in the cal. state data breach notification legislation ... having been brought in to help wordsmith the cal. state electronic signature legislation. Several of the participants were also heavily involved in privacy issues and had done in-depth, detailed consumer/public surveys ... where the number one issue came up as "identity theft" ... primarily the form involving fraudulent financial transactions ("account fraud") from information harvested in breaches. There seemed to be little or no activity in correcting problems related to breaches ... so they appeared to think that the data breach notifications might prompt corrective action (aka ... the crooks would perform fraudulent financial transactions with institutions other than the one that had the data breach ... if nothing else to put minimize LEOs determining the source of the information). As a result ... institutions having breaches experienced very little downside and any correcti
ve action was pure cost w/o any direct benefit to the institution (at least prior to data breach notification).
Part of the paradigm changes around x9.59 financial transaction standard, minimized the institutions (that had little direct interest in protecting your information) from having to protect your information. Besides "security proportional to risk" and "parameterized risk management" ... this also has the concept that the parties at risk, have increased control over the actual protection mechanisms (a security failure mode is trying to mandate for parties, with little or no vested interest/risk, be responsible for the security measures).
There is an analogy scenario in the recent financial mess ... involving environment where institutional parties were motivated to do the wrong thing. Congressional testimony pointed out that it is much more effective to change business process environment where the parties have vested interest to do the right thing ... as opposed to all the regulations in the world ... attempting to manage an environment where the parties have a vested interest to do the wrong thing.

@_date: 2010-08-02 14:14:01
@_author: Anne & Lynn Wheeler 
@_subject: Five Theses on Security Protocols 
minor addenda about speeds & feeds concerning the example of mid-90s payment protocol specification that had enormous PKI/certificate bloat ... and SSL.
The original SSL security was predicated on the user understanding the relationship between the webserver they thought they were talking to, and the corresponding URL. They would enter that URL into the browser ... and the browser would then establish that the URL corresponded to the webserver being talked to (both parts were required in order to create an environment where the webserver you thot you were talking to, was, in fact, the webserver you were actually talking to). This requirement was almost immediately violated when merchant servers found that using SSL for the whole operation cost them 90-95% of their thruput. As a result, the merchants dropped back to just using SSL for the payment part and having a user click on a check-out/payment button. The (potentially unvalidated, counterfeit) webserver now provides the URL ... and SSL has been reduced to just validating that the URL corresponds to the webserver being talked to (or validating that the webserver being talke
d to, is the webserver that it claims to be; i.e. NOT validating that the webserver is the one you think you are talking to).
Now, the backend of the SSL payment process was SSL connection between the webserver and a "payment gateway" (sat on the internet and acted as gateway to the payment networks). Moderate to heavy load, avg. transaction elapsed time (at payment gateway, thru payment network) round-trip was under 1/3rd of second. Avg. roundtrip at merchant servers could be a little over 1/3rd of second (depending on internet connection between the webserver and the payment gateway).
I've referenced before doing BSAFE benchmarks for the PKI/certificate bloated payment specification ... and using a speeded up BSAFE library ... the people involved in the bloated payment specification claimed the benchmark numbers were 100 times too slow (apparently believing that standard BSAFE library at the time ran nearly 1000 times faster than it actually did).
When pilot code (for the enormously bloated PKI/certificate specification) was finally available, using BSAFE library (speedup enhancements had been incorporated into standard distribution) ... dedicated pilot demos for transaction round trip took nearly minute elapsed time ... effectively all of it was BSAFE computations (using dedicated computers doing nothing else).
Merchants that found using SSL for the whole consumer interaction would have required ten to twenty times the number of computers ... to handle equivalent non-SSL load ... were potentially being faced with needing hundreds of additional computers to handle just the BSAFE computational load (for the mentioned extremely PKI/certificate bloated payment specification) ... and still wouldn't be able to perform the transaction anywhere close to the elapsed time of the implementation being used with SSL.

@_date: 2010-08-04 15:29:57
@_author: Anne & Lynn Wheeler 
@_subject: A mighty fortress is our PKI, Part II 
Kaspersky: Sham Certificates Pose Big Problem for Windows Security
from above ..
Windows fails to clearly indicate when digital security certificates have been
tampered with, according to Kaspersky Lab's Roel Schouwenberg, and that
opens a door for malware makers.
... snip ...

@_date: 2010-08-06 09:46:56
@_author: Anne & Lynn Wheeler 
@_subject: A mighty fortress is our PKI, Part II 
Zeus malware used pilfered digital certificate
Zeus Malware Used Pilfered Digital Certificate
Zeus malware used pilfered digital certificate
from above:
The version of Zeus detected by Trend Micro had a digital certificate belonging
to Kaspersky's Zbot product, which is designed to remove Zeus. The certificate --
which is verified during a software installation to ensure a program is what it
purports to be -- was expired, however.
... snip ...
Certificate Snatching?ZeuS Copies Kaspersky?s Digital Signature
there was another scenario of certificate-copying (& dual-use vulnerability)
discussed in this group a while ago. The PKI/certificate bloated payment
specification had floated the idea that that when payment was done with their
protocol, dispute burden-of-proof would be switched & placed on the consumer
(from the current situation where burden-of-proof is on the merchant/institution;
this would be a hit to "REG-E" ... and also apparently what has happened in the
UK with the hardware token point-of-sale deployment).
However, supposedly for this to be active, the payment transaction needed a consumer
appended digital certificate that indicated they were accepting dispute
burden-of-proof. The issue was whether the merchant could reference some
public repository and replace the digital certificate appended by the
consumer ... with some other digital certificate for the same public key
(possibly digital certificate actually obtained by the consumer for that
public key at some time in the past ... or an erroneous digital certificate
produced by a sloppy Certification Authority that didn't adequately perform
check for applicant's possession of the corresponding private key).
Of course, since the heavily bloated PKI/certificate payment specification,
performed all PKI-ops at the internet boundary ... and then passed
a normal payment transaction with just a flag claiming that PKI-checking
had passed ... they might not need to even go that far. There
was already stats on payment transactions coming thru with the flag
on ... and they could prove no corresponding PKI-checking had actually
occurred. With the burden-of-proof on consumer ... the merchant might
not even have to produce evidence that the appended digital certificates
had been switched.

@_date: 2010-08-13 14:44:08
@_author: Anne & Lynn Wheeler 
@_subject: Has there been a change in US banking regulations recently? 
the original requirement for SSL deployment was that it was on from the original URL entered by the user. The drop-back to using SSL for only small subset ... was based on computational load caused by SSL cryptography .... in the online merchant scenario, it cut thruput by 90-95%; alternative to handle the online merchant scenario for total user interaction would have required increasing the number of servers by factor of 10-20.
One possibility is that the institution has increased the server capacity ... and/or added specific hardware to handle the cryptographic load.
A lot of banking websites are not RYO (roll-your-own), internally developed ... but stuff they by from vendor and/or have the website wholly outsourced.
Also some number of large institutions have their websites outsourced to vendors with large replicated sites at multiple places in the world ... and users interaction gets redirected to the closest server farm. I've noticed this periodically when the server farm domain name and/or server farm SSL certificate bleeds thru ... because of some sort of configuration and/or operational problems (rather than seeing the institution SSL certificate that I thot I was talking to).
Another possibility is that the vendor product that they may be using for the website and/or the outsourcer that is being used ... has somehow been upgraded (software &/or hardware).

@_date: 2010-08-13 15:55:11
@_author: Anne & Lynn Wheeler 
@_subject: Has there been a change in US banking regulations recently? 
... original design/implementation. The very first commerce server implementation
by the small client/server startup (that had also invented "SSL") ... was mall
paradigm, development underwritten by large telco (they were looking at being major
outsourcer of electronic commerce servers) ... then the individual store implementation
was developed.
we had previously worked with two people responsible for commerce server
(at small client/server startup) on ha/cmp ... they are mentioned in this
old posting about jan92 meeting in ellison's conference room
they then left to join the small client/server startup ... and we also leave
what we had been doing. we then get brought in as consultants because they
want to do payment transactions on their server ... wanting to use this
technology called "SSL" that had been invented at the startup. We have to
go thru the steps of mapping the technology to payment business
processes ... including backend use involving the interaction between commerce
servers and the payment gateway; the payment gateway sitting on
the internet and interface to acquiring network backends ... misc. past
posts mentioning payment gateway
we also have to do walkthru/audits of several of these new businesses calling
themselves Certification Authorities that were selling SSL domain
name digital certificates ... some past posts
approx. in the same era, but not exactly the same time (when webservers
were seeing the ssl cryptographic load & dropping back to only using it for
payment) ... some of the larger websites were starting to first see a "plain"
tcp/ip scaleup issue ... having  to do with tcp being originally designed
as session protocol ... and was effectively being misused by HTTP. As a
result most vendor implementations hadn't optimized session termination
... which was viewed as infrequent event (up until HTTP). There was six
month period or so ... that the large websites saw their processors
spending 90-95% of the cpu running the FINWAIT list (as part of session
The small client/server startup was also seeing (other) scaleup problems
in their server platforms used for downloading products (especially
browser product download activity) ... and in constant cycle of
adding servers. This was before  rotating front-ends ... so users were
asked to manually specify URL of specific server.
Their problem somewhat cleared up when they installed a large sequent
box ... both because of the raw power of the sequent server ... and
also because sequent claimed to have addressed the session terminal efficiency
sometime previously (related to commercial unix accounts with
20,000 concurrent telnet sessions).
For other topic drift ... I believe the first rotating, load-balancing
front-ends was with custom modified software for routers at google.

@_date: 2010-08-22 11:51:01
@_author: Anne & Lynn Wheeler 
@_subject: towards https everywhere and strict transport security (was: 
There is large vested interested in Certification Authority industry
selling SSL domain name certificates. A secure DNS scenario is having
a public key registered at the time the domain name is registered ...
and then a different kind of TLS ... where the public key is returned
in piggy-back with the domain name to ip-address mapping response.
This doesn't have the revenue infrastructure add-on that happened
with the Certifcation Authority ... just is bundled as part of
the existing DNS infrastructure. I've pontificated for years that
it is catch-22 for the Certification Authority industry ... since
there are aspects of improving the integrity of the DNS infrastructure
i.e. Certification Authority industry is dependent on DNS ... aka
The Certification Authority industry has to match the information
from the SSL digital certificate applicant with the true owner
of the domain name on file with the DNS infrastructure (among
other things, requiring digitally signed communication that is
authenticated with the onfile public key in the domain name
infrastructure is a countermeasure to domain name hijacking ...
which then cascades down the trust chain to hijackers applying
for valid SSL domain name certificates).
At 50k foot level, SSL domain name certificates were countermeasures
to various perceived shortcomings in DNS integrity ... nearly any
kind of improvements in DNS integrity contributes to reducing the
motivation for SSL domain name certificates. Significantly improving
integrity of DNS would eliminate all motivation for SSL domain
name certificates. This would then adversely affect the revenue
flow for the Certification Authority industry.
I've also periodically claimed that OCSP appeared to be a
(very rube-goldberg) response to my position that digital
certificates (appended to every payment transaction) would actually
set the state-of-the-art back 30-40 yrs (as opposed to their
claims that appended digital certificates would bring payments
into the modern era ... that was separate from the issue of
the redundant and superfluous digital certificates representing
a factor of 100 times payment transaction payload and processing
Anything that appears to eliminate competition for paid-for
SSL digital certificates and/or strengthen the position of
Certification Authorities ... might be construed as having
an industry profit motivation.

@_date: 2010-08-25 15:31:10
@_author: Anne & Lynn Wheeler 
@_subject: towards https everywhere and strict transport security (was: 
the work on HSP (high-speed protocol) in the late 80s was to do reliable transmission
in minimum 3-packet exchange; compared to 5-packet minimum for VMTP (rfc1045) and
7-packet minimum for tcp (disclaimer, i was on related technical advisory board
for HSP ... while at IBM ... over strong objections from the communication division;
but that also strong protested that we had come up with 3-tier architecture and were
out pitching it to customer executives ... at a time when they were attempting
to get the client/server genie back into the terminal emulation bottle)
then SSL theoretically being stateless on top of tcp added a whole bunch of
additional chatter. there has frequently between changing trade-offs between
transmission and processing ... but SSL started out being excessive in both
transmission and processing (in addition to having deployment requirement that
the user understand the relationship between the website they believed they
were talking to and the URL they had to supply to the browser .... a requirement
that was almost immediately violated).
my pitch forever has been to leverage key distribution piggy-backed on
domain name to ip-address (dns) response ... and use that to do
encrypted/validated reliable transaction within HSP 3-packet minimum exchange.
as previously mentioned, somewhere back behind everything else ... there
is strong financial motivation in the sale of the SSL domain name digital

@_date: 2010-08-26 12:17:37
@_author: Anne & Lynn Wheeler 
@_subject: towards https everywhere and strict transport security (was: 
the profit from sale of SSL domain name certs had profit motivation pretty much
unrelated to the overall costs to the infrastructure ... and so there was
an extremely strong champion.
simply enhancing DNS and doing real-time trusted public key distribution
thru a trusted domain name infrastructure ... was all cost with no champion
with strong profit motivation.

@_date: 2010-08-26 12:49:51
@_author: Anne & Lynn Wheeler 
@_subject: towards https everywhere and strict transport security 
one of the things ran into the (ISO chartered) ANSI X3S3.3 (responsible for standards
related to OSI level3 & level4) meetings with regard to standardization of HSP (high
speed protocol) ... was that ISO had policy that it wouldn't do standardization on
things that violated OSI model.
HSP violated OSI model by (and was turned down by X3S3.3)
1) went directly from level 4/5 interface to the MAC interface (bypassing
OSI level 3/4 interface)
2) supported internetworking ... which doesn't exist in OSI model ...
would set in non-existing layer between level3 & level4
3) went directly to MAC interface ... which doesn't exist in OSI mdoel ...
something that sits approx. in the middle of layer3 (above link layer
and includes some amount of network layer).
In the IETF meetings at the time of original SSL/TLS ... my view was that
ipsec wasn't gaining tranction because it required replacing parts of
tcp/ip kernel stack (upgrading all the kernels in the world was much more
expensive then than it is now). That year two things side-stepped the
ipsec upfront kernel stack problem
* SSL ... which could be deployed as part of the application w/o
requiring changes to existing infrastructure
* VPN ... introduced in gateway sesssion at fall94 IETF meeting. This
was implemented in gateway routers w/o requiring any changes to existing
endpoints. My perception was that it upset the ipsec until they started
referring to VPN as lightweight ipsec (but that opened things for
ipsec to be called heavyweight ipsec). There was a problem with two
classes of router/gateway vendors ... those with processors that
could handle the crypto load and those that had processors that
could handle the crypto load. One of the vendors that couldn't
handle the crypto load went into standards stalling mode and also
a month after the IETF meeting announced a VPN product that
involved adding hardware link encryptors (which would then
required dedicated links between the two locations as opposed
to tunneling thru the internet.
I would contend that various reasons why we are where we are
... include solutions that have champions with profit motivation
as well as things like ease of introduction ... and issues with
being able to have incremental deployments with minimum disruption
to existing facilities (like browser application based solution
w/o requiring any changes to established DNS operation).
On the other hand ... when we were brought in to consult with
the small client/server startup that wanted to do payment
transactions (and had also invented SSL) ... I could mandate
multiple A-record support (basically alternative path mechanism)
for the webserver to payment gateway TCP/SSL connections. However,
it took another year to get their browser to support multiple-A
record (even when supplying them with example code from TAHOE
4.3 distribution) ... they started out telling me that multiple-A
record technique was "too advanced".
An early example requirement was one of the first large
adopters/deployments for e-commerce server, advertized on national
sunday football and was expecting big e-commerce business during
sunday afternoon halftime. Their e-commerce webserver had
redundant links to two different ISPs ... however one
of the ISPs had habit of taking equipment down during the
day on sunday for maintenance (w/o multiple-A record support,
there was large probability that significant percentage of
browsers wouldn't be able to connect to the server on
some sunday halftime).

@_date: 2010-08-27 09:52:25
@_author: Anne & Lynn Wheeler 
@_subject: towards https everywhere and strict transport security (was: 
It is well studied. I had gotten blamed for online computer conferencing
on the internal network in the late 70s and early 80s (rumor is that when
the executive committee became aware ... 5of6 wanted to immediately
fire me ... supposedly there was only one holdout).
somewhat as a result, there was a researcher paid to sit in the back of
my office for nine months, taking notes on how I communicated, face-to-face,
telephone, computer ... got  copies of all incoming and outgoing email,
logs of all instant messages, etc. Besides being a corporate research report,
it was also the basis for several papers, books and stanford phd (joint
between language and computer AI). One number was that I avg. electronic
communication with 275 different people per week for the 9month period.
lots of past posts mentioning computer mediated communication
in any case, we were brought in to help wordsmith the cal. state
electronic signature legislation. the certification authority industry
was heavily lobbying (effectively) that digital certificates had to
be mandated for every adult.
The certification authority industry, besides doing the SSL domain
name digital certificates were out pitching to wall street money
people a $20B/annum business case (basically all adults with
$100/annum digital certificate). Initially they appeared to
believe that the financial industry would underwrite the certificates.
The financial industry couldn't see the justification for
the $20B/annum transfer of wealth to the certification authentication
industry. There were various attempts then to convince consumers
that they should pay it directly out of their own pocket.
in payment area, they were also pitching to the merchants that
part of deploying digital certificates infrastructure, the burden of
proof in digitally signed payment transactions, would be switched
to consumers (somewhat like UK where approx. that has happened as
part of payment hardware tokens).
That netted out to consumers paying $100/annum (for digital certificates),
out of their own pocket, for the privilege of having the burden
of proof in disputes shifted to them. that didn't sell ... so there was
heavy lobbying all around the world wanting gov mandating digital
certificates for every adult (payed for by the individual). The lawyers
working on the cal. legislation explained why digital signatures
didn't meet the criteria for "human signatures" (demonstration of human
having read, agreed, authorizes, and/or approved) needed by
electronic signature legislation. we got some patents in the
area, the 32nd just granted on tuesday, they are all assigned,
we have no interest and have been long gone for years.
There are a couple issues with new technology uptake ... much
more successful when 1) there is no incumbent technology already
in the niche and 2) there are strong champions with profit
motivation and 3) there is at least some perceived benefit.
In the 90s, I would pontificate how SSL domain name
certificates didn't actually provide any significant
security ... but were "comfort" certificates (for consumers),
aka benefit was significantly a matter of publicity.
Better solutions that come along later don't necessarily win
... having incumbent to deal with and are especially at a
disadvantage if there aren't major champions (typically
with strong profit motivation).

@_date: 2010-07-27 11:04:50
@_author: Anne & Lynn Wheeler 
@_subject: A mighty fortress is our PKI 
long ago and far away, we were called in to consult with a small client/server startup that wanted to do payment transactions on their server ... they had also invented this technology called SSL that they wanted to use. As part of applying the technology to the business payment process ... we also had to go around and investigate how some of these new businesses, calling themselves "Certification Authorities", operated. In any case, the result is now sometimes called "electronic commerce".
There were lots of issues with deficiencies and vulnerabilities, resulting in my coining the term "merchant comfort" certificates ... aka ... as opposed to anything to do with security. Of course, I also suggested that everybody that in anyway touched on the certificates or the merchant servers ... needed to have detail FBI background check.

@_date: 2010-07-27 13:17:12
@_author: Anne & Lynn Wheeler 
@_subject: A mighty fortress is our PKI 
that became apparent in the use of SSL between all the merchant servers and the payment gateway. by the time the registration and setup process was completed at both ends ... the certificate was purely an artificial attribute of the crypto library being used. there were other issues with the payment gateway protocol ... i was able to mandate things like mutual authentication ... which didn't exist in the crypto library up to that point ... however the exchange of certificates was so engrained that it wasn't possible to eliminate (even tho all the necessary information already existed at both end-points).
the merchant server/browser part ... I could only recommend ... I couldn't mandate.
my analogy is that certificates & PKI are electronic analogy of the letters of credit/introduction from the sailing ship days ... when the relying party had no other recourse for information about the stranger that they were dealing with. This was left over from the dail-up email days of the early 80s (dial-up electronic post-office, exchange email, hangup, and possibly have first-time email from complete stranger).
that design point was quickly vanishing in the 90s with the pervasive growth of the online internet.
I as at annual ACM sigmod conference in the early 90s ... and one of the big sessions, somebody asked on of the panelists what was all this x.50x gorp about. Eventually somebody explained that it was a bunch of networking engineers attempting to re-invent 1960s database technologies .... with certificates being armored, stand-alone, stale representation of some information from a database someplace. In the later 90s, certificates attempted to find place in no-value market niches (aka, situations involving no-value operations that couldn't justify online &/or real-time information) ... although this got into some conflicts ... trying to address no-value market-niche ... at the same time claiming high-value, expensive operation.
There were businesses cases floated to venture community claiming $20B certificate market ... i.e. that every person in the country would have $100/annum certificate ... some predicting that the financial community would underwrite the cost. When that didn't happen, there were other approaches. We had been called in to help wordsmith the cal. state electronic signature legislation ... which was being heavily lobbied by the PKI industry to mandate certificates.
I could that rube-goldberg OCSP was response to interaction I had with some of the participants ... somebody bemoaning the fact that the financial industry needed to be brought into 20th century requiring certificates appended to every financial transaction. I responded that stale, static certificates would be retrenching to before the advent of online, real-time point-of-sale payment transactions ... aka a major step backward, not a step forward.
Besides the appending a stale, static certificate to every payment transaction being redundant and superfluous ... it also represents enormous overhead bloat. There were some reduced financial, "relying-party-only" certificates being floated in the mid-90s ... which were still 100 times larger than the typical payment payload size (increase the size of payment transaction payload by a factor of 100 times for no beneficial purpose).
The X9 financial standard group ... had some participants recognizing the enormous overhead bloat certificates represented in payments started a compressed certificate standards activity ... possibly looking to reduce the 100 times overhead bloat to only 5-10 times overhead bloat (although still redundant and superfluous). One of their techniques was that all information that was common in every certificate ... could be eliminated. Then all information that the relying party already had could be eliminated. I was able to trivial show, that a relying party would have access to every piece of information in a certificate ... and therefor digital certificates could be compressed to zero bytes.
Then rather than arguing whether it was mandated that every payment transaction have an appended certificate ... we could mandate that every payment transaction have a zero-byte appended certificate.
disclaimer ... eventually had a couple dozen (assigned, retain no interest) patents in the area of certificate-less public key (some showing up long after we were gone) ... summary here

@_date: 2010-07-27 14:10:18
@_author: Anne & Lynn Wheeler 
@_subject: A mighty fortress is our PKI 
somewhat as result of doing the SSL payment stuff ... in the mid-90s got invited to be part of the x9a10 financial standard working group ... which had been given the requirement to preserve the integrity of the financial infrastructure for all retail payments. the result was x9.59 retail payment financial standard ... which was specific in such a way that it would work with any secure authentication (including allowing both certificate & certificate-less mode). The business process was slightly tweaked so it was no longer necessary to hide the information in a payment transaction to preserve the financial infrastructure integrity. This didn't eliminate skimming, evesdropping, data breaches ... but it eliminated the ability for the attackers to use the information to perform fraudulent transactions (and effectively also eliminates the major use of SSL in the world ... hiding the information in financial transaction).
About the same time the x9a10 standards work was going on ... there were a couple other payment transaction specification work occurring ... which were mandating certificate operation ... somewhat trying to side-step the 100 times payload bloat. they would strip the certificate at internet gateway ... and forward the transaction thru the standard payment network with flag turned on
(they could somewhat wave their hands that 100 times payload bloat on the internet was immaterial ... but not so in the real payment network) that certificate processing had occurred (compared to light-weight, super secure, x9.59 ... which operated end-to-end). There were later some presentations at ISO standards meetings that transactions were showing up with the "certificate" flag on ... but they could prove no certificate had been involved (i.e. there was financial interchange fee benefit motivating turning on the flag).
shortly after they had published their (certificate-based) payment specification (but well before any operational code), I did a public-key op profile for their specification. I then got a friend that had a optimized BSAFE library (ran four times faster) to benchmark the profile on lots of different platforms ... and then reported the results to the groups publishing the profile. The response was my numbers were 100 times too slow (if they had actually run any numbers, their comment should have been it was four times too fast). Some six months later when they did have pilot code ... my profile numbers were within a couple percent of actual (i.e. the BSAFE library changes had been incorporated into standard distribution).

@_date: 2010-07-28 08:55:21
@_author: Anne & Lynn Wheeler 
@_subject: A mighty fortress is our PKI 
Part of SSL was countermeasure to perceived weakness in domain name infrastructure ... is the server that I think I'm talking to really the server I'm talking to (things like ip-address hijacking). Now Certification Authorities typically aren't the authoritative agency for the information they are certifying ... they ask for a whole bunch of information from an SSL certificate applicant and then perform and expensive, time-consuming, and error-prone identification process, x-checking the supplied information with the information on-file at the domain name infrastructure as to the true owner of a domain (the same domain name infrastructure that has the weaknesses that SSL is designed as countermeasure).
So ... something that could be backed by the Certification Authority industry as part of DNSSEC is to ask that all domain name applicants also register a public key as part of obtaining a domain name. domain name infrastructure then can required that all subsequent communication be digitally signed ... and can be verified with the onfile public key (as countermeasure to various kinds of domain name hijacking exploits, hijack domain and then apply for valid SSL certificate using dummy front company which matches the corrupted onfile information). The Certification Authority industry then could take advantage of the same infrastructure and require that all SSL domain name certificate applications, also be digitally signed (and can be verified with the onfile public key at the domain name infrastructure); replacing a time-consuming, expensive, error-prone identification process with an efficient, inexpensive, reliable authentication process.
The catch-22 for the industry is if the Certification Authority industry could start doing real-time, online retrieval of public keys for authentication ... then maybe the rest of the world might also ... changing SSL to a certificateless, real-time, online publickey infrastructure.
One of the possible reasons that it hasn't happened is there no startup, venture capital, IPO ... etc, gorp associated with such an incremental enhancement to the existing domain name infrastructure (it is a pure security/integrity play with no big financial motivation for anybody). W/o startup, venture capital, IPO play ... there is no big marketing budget to blitz the public on how much more comforting things would be (i.e. part of the reason that I coined the term "merchant comfort" certificates back in the early days). In the late 90s, we got visited by somebody that wanted to explain about the downside our comments could have on some pending Certification Authority IPO (much of internet hype from the period was actually part of IPO-mill money generating machine).
I've posted frequently in the past about the catch-22 scenario for the certification authority industry.
disclaimer: the inventor of domain name infrastructure did a stint at the science center a decade earlier ... working on various and sundry projects.

@_date: 2010-07-28 10:42:43
@_author: Anne & Lynn Wheeler 
@_subject: A mighty fortress is our PKI, Part II 
long ago and far away ... one of the tasks we had was to periodically go by project athena to "audit" various activities ... including Kerberos. The original PK-INIT for kerberos was effectively certificateless public key ... aka replace registering a shared-secret password (for authentication) with a public key. There was then some amount of lobbying by the certification authority interests for pk-init to include certificate-based mode of operation (I wrote the draft-words for PK-INIT for inclusion of certificateless ecdsa).
An issue with Kerberos (as well as RADIUS ... another major authentication mechanism) ... is that account-based operation is integral to its operation ... unless one is willing to go to a strictly certificate-only mode ... where all information about an individuals authority and access privileges are also carried in the certificate (and eliminate the account records totally).
As long as the account record has to be accessed as part of the process ... the certificate remains purely redundant and superfluous (in fact, some number of operations running large Kerberos based infrastructure have come to realize that they have large redundant administrative activity maintaining both the account-based information as well as the duplicate PKI certificate-based information).
The account-based operations have sense of revocation by updating the account-based records. This can be done in real-time and at much finer levels of granularity than the primitive, brute-force (PKI) revocation (and replacement). For instance, have you gone over your outstanding balance or credit-limit? ... are you up-to-date with you ISP account? ... or should it just be temporarily suspended bending receipt of funds. Account records can carry other kinds of real-time information ... like whether currently logged on ... and should duplicate, simultaneous logons be prevented (difficult to achieve with redundant and superfluous, stale, static certificates).
The higher-value operations tend to be able to justify the real-time, higher quality, and finer grain information provided by an account-based infrastructure ... and as internet and technology has reduced the costs and pervasiveness of such operations ... it further pushes PKI, certificate-based mode of operation further and further into no-value market niches.

@_date: 2010-07-28 11:37:19
@_author: Anne & Lynn Wheeler 
@_subject: A mighty fortress is our PKI, Part II 
as i've mentioned ... the relying-party-only certificates are almost always redundant and superfluous ... except in cases where the relying party can't justify their own repository of information and/or distributed access to such a repository of information.
I previously mentioned that in the payment transaction case, even a relying-party-only certificate was a factor of 100-times payload size bloat for typical payment transactions ... aka not only was the certificate redundant and superfluous ... but it represented an enormous (redundant and superfluous) processing burden.
I've mentioned a number of times that OCSP appeared after I had repeatedly ridiculed revokation process being archaic backwards step for real-time payment processes. And that even OCSP (with a certificate) is still redundant and superfluous when real-time transaction is being performed using the "real" information.
the other scenario for rpo-certs ... besides for no-value operations ...  is when the real infrastructure is down and/or not accessible. But that usually is matter of cost also, some of the higher-value operations have gone to significant redundancy and claim 100% availability. The certificate analogy is still the letters of credit/introduction from sailing ship days ... when the relying-party had no (other) access to first time interaction with complete stranger (and has to fall back to much cruder and lower quality information).
There is also some scenario if the respository and the service are co-located ... that when the repository is unavailable the service will also be unavailable ... so there is no requirement for independent source of information.
The catch22 for certification authority operation ... is that as they move further & further into the no-value market niches (and/or market niches that can't justify the expense of higher quality operation with real-time repository) ... they are forced to cut their fees and indirectly the quality of their operation.

@_date: 2010-07-28 12:39:12
@_author: Anne & Lynn Wheeler 
@_subject: A mighty fortress is our PKI, Part II 
my OCSP analogy was turning authentication into an end in itself ... basically a new kind of retail store ... instead of retail store that sells some product ... you go in and buy something ... doing a real-time payment transaction; ... there is an authentication store ... convince everybody that they need to walk into their (OCSP) authentication retail store at least once a day to perform an authentication operation (for no other reason that people should get a lot of comfort out of being authenticated at least once a day or more if necessary) ... totally divorced and unrelated to any actual business purpose.

@_date: 2010-07-29 11:51:44
@_author: Anne & Lynn Wheeler 
@_subject: A mighty fortress is our PKI, Part II 
that was one of my points ridiculing PKI in the mid-90s ... that the CRL was a return to offline point-of-sale payment operation ... and seemed to motivate the work on OCSP.
The difference was that in the move to real-time online transactions ... it got much high quality operation ... not only could it establish real-time valid/not-valid ... but also other real-time characteristics like real-time credit limit, recent pattern of transactions, and much more. by comparison, OCSP was an extremely poor man's real-time, online transaction
smartcard payment cards started out being stand-alone stored-value to compensate for the extremely expensive and limited availability of point-of-sale in much of the world ... aka it was stored-value operation where the operation could be performed purely offline (the incremental cost of the smartcard chip was offset by savings not requiring realtime, online transaction).
The telco economics didn't apply to the US ... as seen by the introduction of "stored-value" magstripe based payment cards in the US that did real-time, online transaction ... which served the same market niche that the offline smartcard was performing in other parts of the world. Between the mid-90s and now, telco costs & connectivity has significantly changed around the world ... pervasive uniquitness of the internet, cellphone coverage, wireless, ... lots of things.
The common scenario in the past couple decades ... was looking to add more & more feature/function to smartcards to find the magical economic justification ... unfortunately, the increase in feature/function tended to also drive cost ... keeping the break even point just out of reach.
Part of the certificateless public key work was to look at chips as a cost item (rather than profit item ... since lots of the smartcard work was driven by entities looking to profit by smartcard uptake). The challenge was something that had stronger integrity than highest rated smartcard but at effective fully loaded cost below magstripe (i.e. I had joked about taking a $500 milspec part, cost reducing by 3-4 orders of magnitude while improving the integrity). Another criteria was that it had to work within the time & power constraints of a (ISO14443) contactless transit turnstyle ... while not sacrificing any integrity & security.
By comparison ... one of the popular payment smartcards from the 90s looked at the transit turnstyle issue ... and proposed a "wireless" sleeve for their contact card ... and 15ft electromagnetic "tunnels" on the approach to each transit turnstyle ... where public would walk slowly thru the tunnel ... so that the transaction would have completed by the time the turnstyle was reached.
Part of achieving lower aggregate cost than magstripe ... was that even after extremely aggressive cost reduction, the unit cost was still 2-3 times that of magstripe ... however, if the issuing frequency could be reduced (for chip)... it was more than recouped (i.e. magstripe unit cost is possibly only 1% of fully loaded issuing costs). Changing the paradigm from institutional-centric (i.e. institution issued) to person-centric (i.e. person uses the same unit for multiple purposes and with multiple institutions) ... saves significant amount more (replaces an issuing model with a registration model).
Turns out supposedly a big issue for a transition from an institution-centric (institution issuing) to person-centric paradigm ... was addressing how can the institution "trust" the unit being registered. Turns out that "trust" issue may have been obfuscation ... after providing a solution to institution trust ... there was continued big push back to moving off an institutional issuing (for less obvious reasons) ... some of the patent stuff (previous mentions) covered steps for moving to person-centric paradigm (along with addressing institutional trust issues). Part of it involved tweaking some of the processes ... going all the way back to while the chip was still part of wafer (in chip manufacturing ... and doing the tweaks in such a way that didn't disrupt standard chip manufacturing ... but at the same time reduced steps/costs).

@_date: 2010-07-29 16:23:33
@_author: Anne & Lynn Wheeler 
@_subject: A slight modification of my comments on PKI. 
another design goal for any security system might be "security proportional to risk". the major use of SSL in the world today is hiding financial transaction information ... currently mostly credit card transactions. One of the issues is that the value of the transaction information to the merchants (paying for majority of the infrastructure) is the transaction profit ... which can be a dollar or two. The value of the transaction information to the attackers is the associated account limit/balance, which can be several hundred to several thousand dollars. This results in a situation where the attackers can afford to outspend the defenders by 100 times or more.
somewhat because of the work on the current payment transaction infrastructure (involving SSL, by the small client/server startup that had invented SSL), in the mid-90s, we were invited to participate in the x9a10 financial standard working group (which had been given the requirement to preserve the integrity of the financial infrastructure for all retail payments). the result was the x9.59 financial transaction standard. Part of the x9.59 financial transaction standard was slightly tweaking the paradigm and eliminating the value of the transaction information to the attackers ... which also eliminates the major use of SSL in the world today. It also eliminates the motivation behind the majority of the skimming and data breaches in the world (attempting to obtain financial transaction information for use in performing fraudulent financial transactions). note the x9.59 didn't do anything to prevent attacks on SSL, skimming attacks, data breaches, etc ... it just eliminated the
 major criminal financial motivation for such attacks.

@_date: 2010-07-29 17:11:50
@_author: Anne & Lynn Wheeler 
@_subject: A slight modification of my comments on PKI. 
for the fun of it ... from today ...
Twenty-Four More Reasons Not To Trust Your Browser's "Padlock"
from above:
On stage at the Black Hat security conference Wednesday, Hansen and Sokol revealed 24 new security issues with SSL and TLS, the digital handshakes that browsers use to assure users they're at a trusted site and that their communication is encrypted against snoops.
... snip ...
adding further fuel to long ago motivation that prompted me to coin the term "merchant comfort" certificates.
... as an aside, we were tangentially involved in the cal. data breach notification legislation. we had been brought in to help wordsmith the cal. electronic signature act ... and some of the participants were heavily involved in privacy issues. They had done in-depth consumer privacy studies and the number one issue came up "identity theft", namely the "account fraud" form where criminals use account &/or transaction information (from data breaches) to perform fraudulent financial transactions. It appeared that little or nothing was being done about such data breaches ... and they appeared to believe that the publicity from the data breach notifications would motivate corrective action to be taken (and as mention in previous post ... we took a slightly different approach to the problem in the x9.59 financial transaction standard ... eliminating the ability of crooks to use such information for fraudulent transactions).

@_date: 2010-07-30 12:51:54
@_author: Anne & Lynn Wheeler 
@_subject: A mighty fortress is our PKI, Part II 
some ssl, payment, smartcard trivia ...
those smartcards were used for the offline authorization (not just authentication) ... which, in at least one major product, led to the "YES CARD" ... relatively trivial to skim & replicated a static digital certificate for a counterfeit card ... then the counterfeit card was programmed to answer "YES" to 1) was the correct PIN entered, 2) should the transaction be performed offline, and 3) was the transaction approved. Once the static digital certificate was skimmed, it was no longer even necessary to know the PIN, since the counterfeit card accepted every possible PIN as valid. misc. past posts mentioning "YES CARD"
In a 2003, at an ATM Integrity task force meeting ... there was presentation by some LEO explaining the "yes card" ... and how there was little or no countermeasure once a "YES CARD" was in existence ... somebody in the audience loudly observed that billions were spent on proving smartcards are less secure than magstripe. In the "YES CARD" timeframe there was even a rather large pilot of the cards in the US ... but seemed to disappear after the "YES CARD" scenario was publicized (it was actually explained to the people doing the pilot, before the pilot started ... but apparently they didn't appreciate the significance).
much earlier, we had been working on our ha/cmp product and cluster scaleup. we had meeting on cluster scaleup meeting during jan92 sanfran usenet (in ellison's conference room) ... past posts mentioning the jan92 meeting
this was just a few weeks before cluster scaleup was transferred (announced as supercomputer for numerical intensive only) and we were told we couldn't work on anything with more than four processors. some old email from the period on cluster scaleup
we then leave a couple months later. two of the other people named in the jan92 meeting also leave and show up at small client/server startup responsible for something called "commerce server". we get brought in to consult because they want to do payment transactions on the server ... the small client/server startup has also invented some technology called "SSL" they want to use. The results is now frequently called "electronic commerce".
Then apparently because of the work on electronic commerce ... we also get invited to participate in the x9a10 financial standard working group ... which had been given the requirement to preserve the integrity of the financial infrastructure  for all retail payments.
About the same time there is a pilot program for magstripe-based online stored-value cards  (uses existing POS magstripe terminals but the payment network routes the transactions to different backend processor, original program of its kind in the US). At the time, the US didn't have the telco connectivity availability and cost issues that many places in the rest of the world were dealing with ... and therefor didn't have that requirement to move to offline smartcard payment paradigm. However, it turns out their backend, high-availability, no-single-point-of-failure platform developed a glitch ... and even tho it was from a different vendor (than our ha/cmp product) we were asked to investigate at the various failure modes.
Somewhat as a result of all of the above, when one of the major offline, smartcard, european, stored-value payment operators was looking at making an entry into the US in the 90s ... we were asked to design, size, and cost their backend dataprocessing infrastructure. Along the way, we took an indepth look at the business process and cost structure of such payment products. Turns out that the major financial motivation for that generation of smartcard stored-value payment products ... was that the operators got to keep the float on the value resident in the stored-value cards. Not too long later ... several of the major european central banks announced that the smartcard, stored-value operators would have to start paying interest on value in the smartcards (eliminating the float financial incentive to those operators). It wasn't too long after that most of the programs disappeared.
The major difference between that generation of smartcard payment products and the AADS chip strawman ... was that rather than attempting to be a complex, loadable, multi-function issuer card .... the objective was changed to being a person-centric, highest-possible integrity, lowest-possible cost, hard-to-counterfeit authentication ... which could be registered (publickey) for arbitrary number of different environments ("something you have" authentication registered in manner analogous to how "something you are" biometric might be registered).

@_date: 2010-07-31 13:01:26
@_author: Anne & Lynn Wheeler 
@_subject: Five Theses on Security Protocols 
corollary to "security proportional to risk" is "parameterized risk management" ... where variety of technologies with varying integrity levels can co-exist within the same infrastructure/framework. transactions exceeding particularly technology risk/integrity threshold may still be approved given various compensating processes are invoked (allows for multi-decade infrastructure operation w/o traumatic dislocation moving from technology to technology as well as multi-technology co-existence).
in the past I had brought this up to the people defining V3 extensions ... early in their process ... and they offered to let me do the work defining a V3 integrity level field. My response was why bother with stale, static information when real valued operations would use much more capable dynamic, realtime, online process.

@_date: 2010-07-31 19:36:55
@_author: Anne & Lynn Wheeler 
@_subject: Five Theses on Security Protocols 
Part of what is now referred to as "electronic commerce" is a payment gateway that sits between the internet and the payment networks. this small client/server startup that wanted to do payment transactions and had invented this technology called SSL, wanted to also use SSL for internet communication between the merchant servers and the payment gateway (as well as between browsers and merchant servers). One of the things that I mandated for the merchant servers & payment gateway was mutual authentication (wasn't part of the implementation up until then). By the time all required registration and configuration operations were done for both the merchant servers and the payment gateway ... it was apparent that SSL digital certificates were redundant and superfluous ... and purely an artificial side-effect of the software library being used.
The existing SSL digital certificates has a chicken-and-egg problem as to public key trusted repository for the authorized Certificate Authorities ... aka it requires a trusted repository of Certification Authority public keys in order to validate acceptable SSL digital certificates (as mentioned elsewhere, the infrastructure is vulnerable since all entries in the trusted repository are treated as equivalent; i.e. only as strong as its weakest Certification Authority ... aka the weakest link in the security chain scenario).
If the relying party has its own public key trusted repository and/or has trusted communication to a public key trusted repository then it can use public keys from the trusted repository. In fact, the whole PKI infrastructure collapses w/o relying parties having public key trusted repository (for at least the public keys of trusted Certification Authorities).
In that sense, PKI is just a restricted, special case of relying party public key trusted repository ... where the (special case Certification Authority) trusted public keys, in addition to providing "direct" trust, are then used to establish indirect trust for public keys belonging to complete strangers in first time (no-value) communication.
For the at least the first decade or so, the major world-wide use of SSL for electronic commerce ... was quite skewed ... with top 100 or so merchant servers accounting for the majority of all electronic commerce transactions. Collecting and distributing those (few) public keys (in manner similar to the way that Certification Authority public keys are collected and distributed), would satisfy the majority of all trusted electronic commerce. Then volume starts to drop off quite quickly ... so there are possibly million or more websites that have electronic commerce activity that could possibly justify spending $10 for the highest possible integrity SSL digital signature.
The SSL Certification Authority operations started out having a severe catch-22. A major objective for SSL was countermeasures to various vulnerabilities in the domain name infrastructure and things like ip-address take-over (MITM-attacks, etc; is the webserver that I think I'm talking to, really the webserver that I'm talking to). Certificate Authorities can typically require a lot of information from an applicant and then they do an error-prone, time-consuming, and expensive identification process attempting to match the supplied information against the on-file information and the domain name infrastructure as to the true owner of the domain. There have been "domain name take-over" attacks against the domain name infrastructure ... the attacker then could use a front company to apply for an SSL certificate (certificate authority shopping ... analogous to some of the things in the news associated with the financial mess with regulator shopping). Any issued certificate will b
e taken as equivalent to the highest quality and most expensive certificate from any other Certification Authority).
So part of some Certification Authority backed integrity improvements to the domain name infrastructure ... is to have domain name owners register a public key with the domain name infrastructure ... and then all future communication is digitally signed (and validated with the certificateless, onfile public key) ... as countermeasure to various things like domain name hijacking (eliminating some of the exploits where wrong people can get valid SSL certificates).
Turns out then the Certification Authority business could require that SSL digital certificate applications are also digitally signed. The Certification Authority then could do a real-time retrieval of the onfile public key to validate the digital signature (replacing the time-consuming, error-prone, and expensive identification matching process with an efficient, reliable, inexpensive authentication process). The issue for the SSL Certification Authority industry is if it starts basing its whole SSL digital certificate infrastructure on real-time certificateless public keys ... the rest of the world might think it was good enough, and start doing the same thing.

@_date: 2010-03-16 17:42:53
@_author: Anne & Lynn Wheeler 
@_subject: GOST RFCs 5830, 5831, 5832 
welcome back
announcement of RFC 5830, 5831, & 5832 in today's RFC distribution
abstract for 5830:
This document is intended to be a source of information about the
Russian Federal standard for electronic encryption, decryption, and
message authentication algorithms (GOST 28147-89), which is one of the
Russian cryptographic standard algorithms called GOST algorithms).
Recently, Russian cryptography is being used in Internet applications,
and this document has been created as information for developers and
users of GOST 28147-89 for encryption, decryption, and message
authentication.  This document is not an Internet Standards Track
specification; it is published for informational purposes.

@_date: 2010-09-01 14:00:16
@_author: Anne & Lynn Wheeler 
@_subject: Nearly $1,000,000 stolen electronically from the University of 
In the mid-90s, dialup consumer online banking gave pitches on motivation for moving
to the internet (major justification was the significant cost in supporting proprietary
dialup infrastructure ... including all the issues with supporting serial-port modems;
one such operation claimed library of over 60 different drivers for various combinations
of customer PCs, operating systems, operating system levels, modems, etc).
At the same time, the dialup business/commercial online cash-management operations were
pitching why they would *never* move to the internet ... even with SSL, they had
a long list of possible threats and vulnerabilities.
Some of the current suggested countermeasures are that businesses have a separate,
dedicated PC that is dedicated solely to online banking operations (and *NEVER*
used for anything else).
a few recent posts on the subject:
 U.K. bank hit by massive fraud from ZeuS-based botnet
 Is the ATM still the banking industry's single greatest innovation?
 memes in infosec IV - turn off HTTP, a small step towards "only one mode"
 How Safe Are Online Financial Transactions?

@_date: 2013-10-02 07:34:10
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] encoding formats should not be committee'ized 
early 90s annual ACM SIGMODS (DBMS) conference in San Jose ... general meeting in (full) ballroom ... somebody in the audience asks panel on the stage what is all this x.5xx stuff about ... and one of the panelists replies that it is a bunch of networking engineers trying to re-invent 1960s DBMS technology.
CA industry is pitching $20B/annum business case on wallstreet ... where the financial industry pays CAs $100/annum for every account for a relying-party-only digital certificate ... where the financial industry providing all the information that goes into the certificate (CA industry just reformats all the information and digitally signs it). In one case of institution with 14M accounts, the board asks what is this $1.4B/annum thing about?
I repeatedly point out that it is redundant and superfluous since the institution already has all the information. Purpose of the certificate is to append to every financial transaction. I also point out that digital certificate payload is enormous bloat, 100 times larger than the transaction size its attached to (besides redundant and superfluous)
CA industry then sponsors x9.63 work in X9 financial standards industry for "compressed certificate" format ... possibly getting the payload bloat down to 10 times (instead of hundred times). Part of the compressed certificate work was to eliminate fields that the relying party already had. Since I had already shown that the relying party (institution) already had all fields, it was possible to compress every certificate to zero bytes ... so rather than doing digitally signed transactions w/o certificates ... it was possible to do digitally signed transactions with mandated appended zero-byte certificates.
Trivia: last few years before he passed, Postel would let me do part of STD1. There was a joke that while IETF required at least two interoperable implementations before standards progression, ISO didn't even require that a standard be implementable.

@_date: 2013-09-02 14:05:19
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] NSA and cryptanalysis 
recent post with email discussing PGP-like implementation ... a decade before PGP in financial crypto blog
and then a little later realizing there were 3-kinds of crypto (when I was told I could make as many boxes as I wanted ... but could only sell to a certain gov. agency).
In the late 90s, I worked on crypto chip for financial applications ... I would facetiously talk about taking a $500 mil-spec chip and cost reduce by 2-3 orders of magnitude while making it more secure (final objective was well under a dollar). Part of the objective was also to eliminate all the vulnerabilities that payment chips being done primarily in Europe were prone too. Long winded thread in financial crypto blog
About that time, I was also approached by the transit industry to make the payment chip meet transit turnstyle requirements (while not reducing any security) ... this was a contactless chip being able to do crypto operation in 1/10th sec elapsed time and power profile of contactless transit turnstyle operation.
RSA chips at the time were really large implementing 1024-bit arithmatic requiring enormous power and contact operation to get time in a few seconds. It turns out I could have a AADS chip strawman with ECC that was higher integrity *AND* could meet the transit industry turnstyle contactless power & elapsed time profile. some past references to AADS chip strawman
I was also asked to give presentation at Intel trusted computing ... gone 404 but lives on at wayback machine
one of the problems in the early part of the century was that I wanted to go for higher than EAL4+ evaluation ... but NIST(somebody) pullled the ECC evaluation criteria ... and since ECC was part of the chip silicon ... w/o the ECC evaluation criteria ... I had to settle for EAL4+.
Possibly part of the issue with AADS chip strawman was I approached it as purely a cost issue ... and the objective was to eliminate all possible costs from the whole infrastructure ... the side effect of course, it also eliminated all related profit.

@_date: 2013-09-06 16:48:01
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] People should turn on PFS in TLS (was Re: Fwd: 
we were brought in as consultants to a small client/server startup that wanted to do payment transactions on their server, they had this technology they called "SSL" they wanted to use, the result is now frequently called "electronic commerce". The two people at the startup responsible for the "commerce server" we had worked with in prior life on parallel Oracle cluster scaleup.
As part of mapping "SSL" technology to payment transactions we had to audit operations selling "SSL" digital certificates and also came up with recommendations on how browsers and servers would deploy and use the technology. Almost immediately several of the recommendations were violated, resulting in some number of the exploits that continue to this day.
We were then tangentially involved in the Cal. data breach notification legislation, having been brought in to help wordsmith the Cal. electronic signature legislation. Many of the parties were heavily involved in privacy issues and had done numerous, indepth, public surveys. The number one issue was "identity theft" of the form involving fraudulent financial transactions ... frequently as result of data breach. The issue was nothing was being done about the problems and so it was hoped that the publicity from the notifications might motivate corrective action. Part of the issue is normally institutions take security measures in self-interests ... however, the institutions having breaches weren't at risk, it was the account holders.
PCI DSS shows up some time after Cal. data breach notification and frequently the joke is that if you have a breach ... you loose your PCI DSS certification. It turns out that there was a number of Federal "data breach notification" bills introduced, preempting state legislation and effectively eliminating notification requirements ... citing PCI DSS industry effort as justification for no longer needing notification.
Another problem we've frequently pointed out is current paradigm with "dual use" paradigm and even if the planet was covered in miles of information hiding encryption, it wouldn't stop data leakage. Account information is used for authenticating new transactions and so has a requirement that it be kept totally confidential and never divulged to anybody ... but at the same time, account information is needed in dozens of business processes at millions of locations around the planet.
disclaimer: we were co-authors of the x9.59 financial transaction standard that slightly tweaked the current payment paradigm and eliminated the dual-use characteristic .... which then also eliminated the need to hide account information and as a result it also eliminated the need for SSL to hide account information in electronic commerce transactions .... eliminating the major requirement for SSL in the world today.

@_date: 2013-09-07 15:52:52
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
unfortunately as far as SSL domain name certificate ... the domain name infrastructure is the
authoritative agency for domain name ownership ... the SSL domain name certification agencies
have to rely on the domain name infrastructure to validate true ownership for SSL domain name
applications. As I've repeatedly referenced ... this puts the CAs in catch22 ... they
need improved integrity of domain name infrastructure (attacks on ownership records of domain
name ownership and then being issued valid SSL certificate) ... which comes with lots of
DNSSEC ... but that also eliminates much of the need for SSL domain certificates.
as per prior reference about original working on SSL for electronic commerce ... at least for
the financial industry I've repeatedly shown that digital certificates were redundant
and superfluous. I also shown that at the time, the addition of digital certificates
increased the payload size by two orders of magnitude (besides being redundant and superfluous).
That apparently motivated the "compressed" digital certificate financial standard effort ...
trying to reduce digital certificates so that the payload bloat was only ten times (instead
of hundred times) ... in large part by eliminating all information that the processing
institution already had. I demonstrated that processing institution would have all
information and therefor digital certificates could be reduced to zero bytes ... so
instead of eliminating redundant and superfluous digital certificates ... it was possible
to mandate that zero byte certificates be appended to every transaction (it would be
possible to digitally "sign" a payment transaction for authentication ... and rely on
the individual's financial institution to have registered the person's public key ... w/o
having to increase the size of every payment transaction in the world by 100 times just
to transmit a redundant and superfluous appended digital certificate).
I like the interchange at panel discussion in early 90s ACM SIGMOD ballroom open session,
somebody in the audience asked what was all this x.5xx stuff about and one of the panelists
said it was a bunch of networking engineers trying to reinvent 1960s database technology.
there was some amount of participation by the information assurance directorate in financial
industry standards meetings. at various times there were references to rifts between IA
and SIGINT ... but for all I know that may be kabuki theater. I was fairly vocal about
any backdoors could put financial industry at risk for bad guys discovering the vulnerabilities
... and wanted KISS applied to as much as possible (and backdoors forbidden)
there are other agendas in much of this. at the start of the century there
were several "safe" internet payment products pitched to major merchants (accounting for 70%
of internet transactions) which got high acceptance. Merchants have been indoctrinated for
decades that a large part of interchange fee is proportional to associated fraud rate ...
and the merchants were expecting an order of magnitude reduction in their fees (with
the safe products). Then came the cognitive dissonance when the banks told the merchants that
rather than major reduction in interchange fees with the "safe" payment products ... there would
effectively be a surcharge added to the highest fee that they were already paying (and all the
safe efforts collapse).
Part of the issue was that the bottom line for large issuing banks was 40%-60% from these
fees and an order of magnitude reduction in those fees would be a big hit to
their bottom line (the size of fees in part justified by fraud rates). The "safe" products
going a long way to eliminating most fraud and commoditizing the payment transaction
business ... which would also lower the bar for entry by competition.

@_date: 2013-09-08 15:48:09
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] In the face of "cooperative" end-points, 
note when the router hughes references was 1st introduced in in IETF gateway committee meeting as VPN it caused lots of turmoil in the IPSEC camp as well as with the other router vendors. The other router vendors went into standards stall mode ... their problem was none of them had a product with processors capable of handling the crypto processing. A month after the IETF meeting one of the vendors announced what was supposedly an equivalent product ... but was actually their standard product (w/o crypto) packaged with hardware link encryptors (needed dedicated links instead of being able to tunnel thru the internet).
The IPSEC camp whined a lot but eventually settled for referring to it as "lightweight" IPSEC (possibly trying to imply it didn't have equivalent crypto).
As to DNSSEC ... the simple scenario is requiring domain owners to register a public key and then all future communication is digitally signed and authenticated with the onfile, registered public key (as a countermeasure to domain name take-over which affects the integrity of the domain name infrastructure and propogates to SSL CA vendors if they can't trust who the true owner is). Then the SSL CA vendors can also start requiring that SSL certificate requests also be digitally signed ... which can also be authenticated by retrieving the onfile public key (turning an expensive, error-prone and time-consuming identification process into a reliable and simple authentication process). The catch22 is once public keys can be retrieved in realtime ... others can start doing it also ... going a long way towards eliminating need for SSL certificates. Have an option piggy-back public key in the same response with the ip-address. Then do SSL-lite ... XTP had reliable communication minim
 um 3-pack
et exchange ... compared to TCP requiring minimum 7-packet exchange.
In the key escrow meetings, I lobbied hard that divulging/sharing authentication keys was violation of fundamental security principles. Other parties at the key escrow meetings whined that people could cheat and use authentication keys for encryption. However, there was commercial "no single point of failure" business case for replicating keys used in encrypting data-at-rest corporate assets.
One might hypothesis that some of the current DNSSEC complexity is FUD ... unable to kill it ... make it as unusable as possible.
disclaimer: person responsible for original DNS worked at the science center in the early 70s when he was at MIT.

@_date: 2013-09-25 10:09:40
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] Gilmore response to NSA mathematician's "make 
We had been asked to come in and help wordsmith the cal. state digital signature act. Several of the parties were involved in privacy issues and also working on Cal. data breach notification act and Cal. opt-in personal information sharing act. The parties had done extensive public surveys on privacy and the  issue was identity theft, namely the form of "account fraud" as result of data breaches. There was little or nothing being done about this so there was some hope that the publicity from the breach notifications would motivate corrective action. The issue is that normally an entity takes security and countermeasures in self-protection ... the entities suffering the data breaches weren't at risk ... it is the account holders. Since then several Federal breach notification bills have been introduced about evenly divided between having similar notification requirements and Federal "preemption" legislation eliminating requirement for notifications. The federal bills elimina
 ting noti
fications cite industry specifications call for account encryption (that were formulated after the cal. legislation). We've periodically commented in the current paradigm, even if the planet was buried under miles of information hiding encryption it still wouldn't stop information leakage. One problem, is account information is basically used for authentication and as such needs to be kept completely confidential and never divulged. However, at the same time, account information is also required in dozens of business processes at millions of location around the world.
The cal.personal information "opt-in" sharing legislation would require institution have record from the individual authorizing sharing of information. However, before the cal legislation passed, an "opt-out" (federal preemption) provision was added to GLBA. GLBA is now better known for the repeal of Glass-Steagall. At the time, the rhetoric in congress was the primary purpose of GLBA was if you already had bank charter you got to keep it, however, if you didn't have a charter, you wouldn't be able to get one (i.e. eliminate new parties from coming in and competing with banks). However, GLBA was loaded up with other features like repeal of Glass-Steagall and the "opt-out" personal information sharing (i.e. the financial institution needed record of person declining sharing of personal information ... rather than "opt-in" which required institution to have record authorizing sharing).
A few years ago, I was at a national annual privacy conference in Wash DC. (hotel just up the street from spy museum). There was a panel discussion with the FTC commissioners. Somebody in the audience asked the FTC commissioners if they were going to do anything about GLBA "opt-out" privacy sharing. He said he worked on callcenter technology used by all the major financial institutions ... and that none of the 1-800 "opt-out" desks had provisions for recording information from the call (aka an institution would *NEVER* have a record of a person objecting to sharing their personal information). The FTC commissioners just ignored him.

@_date: 2014-04-19 10:15:05
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] It's all K&R's fault 
I've been pontificating for two decades about C language applications having
epidemic of exploits and vulnerabilities. It isn't that it is impossible to
write correct code in C ... or that it is impossible to write incorrect code
in other languages .... but that C string, pointer, and buffer semantics
results in significantly larger number of mistakes.
the original IBM mainframe product tcp/ip stack (in 80s) was implemented in vs/pascal and
not known to have any of the buffer/pointer problems epidemic in C language
implementations. I didn't do the original implementation ... but i made
the modifications to support RFC1044 and in some tuning tests between Cray
and IBM 4341 got possibly 500 times improvement in number of bytes moved
per instruction executed.
2002 paper "Thirty Years Later: Lessons from the Multics Security Evaluation"
Multics was implemented in PLI and one of the observations was that
Multics was not known to have had any of the buffer/pointer problems
epidemic in C language implementations.
old post from decade ago about attempting to characterize exploits
from the CVE database
there had been reports from the late 90s, that the majority of
internet vulnerability/exploits were buffer/pointer related.
They were no longer the majority ... the frequency hadn't dropped
... it was that other kinds had increased. Note that the 1996 MDC
at Moscone, all the banners said "internet" ... but the subtheme
in all the sessions was "preserve your investment". All the
automatic execution of visual basic code embedded in data files
... from the days of small closed, safe business LANs was
being preserved as low-level support for tcp/ip was being
added (but w/o the necessary added integrity and security measures).
I had some number of discussions with Mitre about CVE entries
were free-form and hard to analyze ... and suggested that they
add some structured keywords. In any case, nearly a year
later NIST releases similar analysis. old post
referencing Linux magazine quoting NIST CVE study.
as an aside, multics sites
I use to see some number of agency people in financial
industry security & crypto meetings ... in the 90s, their email
was  in above list.
other drift ... I was at science center involved in virtual
machines and some number of other things ... which was on
the 4th flr, 545 tech sq. Multics was on the 5th flr in same
bldg ... some there was little feeling of competition between
the two groups.
 was AFDSC ... in late 70s some AFDSC people came by to
talk about what was going to be 210 vm/4341s (more than the
total of all multics installations).

@_date: 2014-12-06 22:45:40
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] cost-watch - the cost of the Target breach 
at the start of the century,there was large pilot deployed in the US based
being told it had fixed all the problems ... but there was myopic focus on
lost/stolen card ... even tho attack on POS terminals for skimming attacks
had been around for at least a decade. It turns out this was during the
"YES CARD" period ... where it was as trivial to create a
counterfeit chip&pin from effectively the same skimming exploits used to
harvest magstripe information. In the wake of the "YES CARD" ... the pilot
appeared to disappear w/o a trace and there was conjecture it wouldn't be
tried again in the US until other places were used to better work out all
the kinks & vulnerabilities.
old trip report of "YES CARD" presentation at CARTES 2002 (gone 404 but
lives on at the wayback machine) ... bottom of the page
federal LEOs gave a more detailed description at a ATM Integrity Task
force meeting ... that prompted somebody in the audience to comment
that they managed to spend billions of dollars to prove chips are
less secure than magstripe.
A particular issue was that they had moved business rules into the
chip ... so that the terminal would ask the chip 1) if the correct
PIN was entered, 2) if the transaction should be done offline, and
3) if the transaction was within the credit limit. The "YES CARD"
designation comes from a counterfeit card answering "YES" to all
three questions. "Worse than magstripe" comes from the fact
that countermeasure to counterfeit magstripe is to disable the account
... and online transaction wouldn't be approved. There was no
countermeasure to to "YES CARD", since the transaction didn't go
online (to discover that the account had been disabled).
Also, skimming didn't even need to harvest the PIN since
a "YES CARD" would always answer "YES" to whether correct
pin had been entered, regardless of what had been actually

@_date: 2014-12-07 09:46:04
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] cost-watch - the cost of the Target breach 
long ago and far away, we were brought in as consultants to small
client/server startup that wanted to do payment transactions on their
server, they had also invented this technology called "SSL" that they
wanted to use, the result is now frequently called "electronic commerce".
Part of the work involved a payment gateway ... sits on the internet
and handles backend transactions between webservers and the payment networks.
We had responsibility for security between webservers and the payment networks
but could only make recommendations for the browser/webserver part. As far as
I know, known of the payment gateways have ever been compromised ... but almost
immediately security recommendations on the browser/webserver were violated, resulting
in many of the exploits that continue to this day.
somewhat having done "electronic commerce", in the mid-90s were were invited
into the x9a10 financial transaction working group that had been given the
requirement to preserve the integrity of the financial infrastructure for
*ALL* retail payments. (this was about the same time the card associations
were doing two different specification efforts, one in europe involving chip that was POS
only and a totally different effort that was internet only).
The resulting working group transaction standard addressed *ALL* retail payments
(not just *POS* or not just *internet*, but *ALL* retail payments).
One of the issues is the current paradigm allows information from previous
transactions to be used in a kind of "replay" attack and/or creating counterfeit
authentication. The transaction standard didn't do anything to address
skimming, evesdropping, and/or data breaches ... however it slightly tweaked
the current paradigm and eliminated being able to use previous transaction
information for doing fraudulent transactions. Now the earlier work we did
for electronic commerce involves using "SSL" to hide transaction information,
the x9a10 transaction doesn't require hiding the transaction information to
preserve the integrity of the financial infrastructure for *ALL* retail
payments ... and so eliminates that use for "SSL".
We've used a couple metaphors to describe the current paradigm:
dual-use ... since information from previous transactions can be used
for fraudulent transactions, that information has to be kept totally
confidential and never divulged. at the same time the same information
is required in dozens of business processes at millions of locations
around the world. we've periodically commented that even if the planet
was buried under miles of information hiding encryption, it still
wouldn't stop leakage
security proportional to risk ... the value of the transaction
information to the merchants is the profit on the transactions, which
can be a couple dollars (and a couple cents for the transaction
processor) ... the value of the information to the crooks is the
account balance and/or credit limit ... as a result the crooks can
afford to outspend the defenders by a factor of 100 times.
In support of the standards effort, I also designed a chip ...
at this conference
I was on stage in standing room only ballroom with panel
of CTOs from various security institutions and semi-facetiously
said that I was taking a $500 mil-spec part and aggressively cost
reducing by 2-3 orders of magnitude while making it more secure.
(cost way less and way more secure than any chip being worked on
by financial infrastructures, then or now).
This chip was demo'ed in a number of booths at the 1999
BAI world-wide retail banking show in Miami.
The downside of the chip & standard was that it drastically
reduced the infrastructure for doing secure payments and also
eliminated the need for having the card associations in the
loop for payment transactions ... which enormously upsets
the status quo.
For the large US pilot deployment early part of the century
... I had advised the people doing it about the exploits
and vulnerabilities ... but for what-ever reason, they went
ahead and did it anyway ... I guess having to actually
experience the problems (not being told about them wasn't
good enough).

@_date: 2014-12-08 11:48:00
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] Toxic Combination 
Older observations. In the mid-to-late 90s, the CA industry was floating
a $20B/annum business case around wallstreet ... supposedly the financial industry
would front $100/customer/annum individual digital certificates. That didn't happen,
but they were heavily lobbying gov. to mandate $100/public/annum digital certificate.
We had gone into large financial institution that had been con'ed into doing
a CA-based online financial infrastructure. They had spent $50M on pilot ... but
when they told the board that the CA was asking that they send them 14M account
records which the CA would convert to 14M digital certificates and only charge
$1.4B ... the board shut the whole operation down.
We were then brought in to help wordsmith the California electronic signature
act which was under heavy lobbying pressure from the CA industry to mandate
digital certificates.

@_date: 2014-12-09 10:16:38
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] Toxic Combination 
The CA-industry had a lot of hype about supposed need for branded
CA institution. Note that the financial organization was also being
required to register all the individuals' public keys in the account
records ... before the the 14M account records were conveyed to the
CA, where the bits would be swizzled into a digital certificate for
the small price of $100/account.
Note when the board was told about the $1.4B price, not only was
the effort shutdown (after spending $50M on pilot), but some number
were liberated from their employment.
At the time we had become quite well known for criticizing CAs.
In this case, we pointed out that every case where the CAs were
justifying a digital certificate for verifying a customer's
digital signature, the operation also involved accessing the
account record ... where the public key had been previously
been pre-registered ... as a result, in every case, the digital
signature could be verified by the previously registered public
key in the account record ... and in every case, the digital
certificate was redundant and superfluous (besides being
useless expensive expenditure).
We had also documented, in the case of digital certificates for
payment transactions ... it involved a similar scenario, in every
case the the account record needed to be accessed at some point
(where the public key had been previously registered). Furthermore
in the payment transaction case besides digital certificates being
redundant/superfluous and useless expensive expenditure, they
were also an enormous payload bloat ... digital certificate being
100 times larger than the standard payment transaction size. Somewhat
as a result, the CA industry got a "compressed certificate" work
item added to financial industry standards body. Part of the
"compression" work eliminated any field that would be available
at the relying institution. We then showed that *ALL* fields
would be at the relying institution ... and digital certificates
could be compressed to zero bytes ... rather than eliminate
all use of digital certificates, mandate that zero-byte digital
certificates be attached to every payment transaction (creating
a whole new infrastructure for the management of zero-byte digital
Possibly more than you ever want to know ... during this (internet
bubble) period we were at a financial standards meeting being hosted
in DC by a well known lobbying organization. During the meeting we were
asked to step out and taken to an office, the door was shut and
we were introduced to somebody from a NJ ethnic organization.
He said he had been asked to talk to us by some investment
bankers, it was nothing personal, purely business (investment
bankers are amoral sociopaths). The investment bankers were
expecting $2B in an upcoming (CA-related) IPO and our criticism
was predicted to have a 10% downside ($200M) ... and we should
stop our vocal criticism.
We then went to some Federal LEOs and were told that investment
bankers were like that.Many of the investment bankers involved
in the internet bubble IPO mill (put in a few tens millions, hype
for couple yrs, IPO for couple billion, and then fail, leaving the field
open for the next round of IPOs), had previous walked away clean from
the S&L mess and were predicted next to get into mortgages.

@_date: 2014-12-10 12:35:23
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] Toxic Combination 
In prior life at we periodically did visits to Project Athena
for reviews/audits of the projects ... including Kerberos ...
one visit sat through sessions defining x-domain operation.
Later doing the previous referenced transaction standard & chip
work ... also extended it so that the process worked in such a way that
it could be any authentication (not just payments) ... and
chip could be "person-centric" ... the same chip/key could be
used for all of a person's institutional authentication
... non-CA digital signature in lieu of passwords, POS payments,
internet payments, door badge entry, etc. One of the interesting
was when transit industry called and requested that it also be able
to work with transit turnstyle ... had to be able to do
transaction within the transit turnstyle contactless power
and elapsed time limitations. Chip had to still be more
secure than any of the heavyweight payment security chips and
cost less than typical transit industry chip.
Effort also included making freely available RADIUS and Kerberos code
that would use public key in lieu of password w/o requiring
digital certificate and/or involve CA. I did part of internet
draft for certificateless public key mode for Kerberos ...
but then the CA forces jumped in and made pk-init all about
CA-based infrastructure.
Later one of the people that helped drive CA-based pk-init ...
called and admitted the mistake and asked me to give
certificateless public key presentations to his organization.
long ago joke, at early 90s ACM SIGMOD (DBMS) meeting in San Jose,
there was panel discussion in large, full ballroom ... somebody
in the audience asked what was all this X.5xx stuff about. Somebody
on the panel said it was a bunch of network engineers attempting
to re-invent 1960s DBMS technology.

@_date: 2014-12-10 19:05:27
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] Toxic Combination 
it can be more than inertia ... there can significant financial interests in existing
status quo ... prospect of any significant disruption can be extremely threatening to
those financial interests.
interchange fees (electronic payment transaction fees paid by merchants to financial
institutions) have been heavily prorated for associated fraud rates.
Circa 2000-2001, there were a number of internet "safe payment" products pitched to the
major ecommerce operations (accounting for something like 70-80% of transactions)
which saw high acceptance ... they were anticipating something like 90% reduction
in the interchange fees they were paying (merchants have been indoctrinated for
decades about interchange fees heavily prorated by associated fraud rates ... with
internet originally falling into CNP/MOTO category).
Then the cognitive dissonance sets in ... the merchants were told that use of "safe
payment" products ... rather than 90% reduction in the interchange fees, there
would effectively be a surcharge on top of the highest rate they were already paying
.... and they all collapse.
2006 there was followup analysis that payment fees account for less than 10% of
EU financial institution bottom line ... while it runs 40-60% of the bottom line
for US financial institutions ... a 90% hit would be enormous financial disincentive.

@_date: 2014-12-23 09:16:26
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] Certificates and PKI 
I've periodically commented that DNSSEC is something of a catch-22 for the CA domain name
certification business. Certification Authorities tend to rely on authoritative agencies
for the validity of the information that they are certifying ... in the case of domain names
... it is the domain name infrastructure.
domain name certificates were partially justified on issues with domain name infrastructure
integrity ... but it is the domain name infrastructure that is they trust root for the
information that they are certifying. They have partially backed DNSSEC to help improve
the integrity of the domain name infrastructure that they rely on ... aka an entity
registers a public key at the same time they register a domain name ... then all communication
is digitally signed and the domain name infrastructure can validate the communication
using the on-file public key (as countermeasure to domain name take-overs).
This also provides an opportunity for domain name CAs to require certificate applications
to be digitally signed ... and CAs can replace a time-consuming, expensive and error
prone identification process ... with a much more efficient and reliable authentication
process by retrieving the same public key for validating the domain name certificate
The catch22 then becomes if the domain name CA industry can rely
on the "on-file" public keys ... then others might also
... eliminating need for the domain name digital certificates.

@_date: 2014-05-18 09:29:53
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] Is it time for a revolution to replace TLS? 
in prior life, we had worked with the guys responsible for commerce
server at a small client/server startup and we were brought in as
consultants because they wanted to do payment transactions on their
server; the startup had also invented this technology called "SSL"
they wanted to use; the result is now periodically called "e-commerce".
Part of work was mapping "SSL" technology to payment business process
and working out recommendations on how it was deployed. Part of this
was that 1) it was necessary that the user needed to know the association
between the webserver they thought they were talking to and the URL
they typed into the browser and 2) "SSL" would provide the association
between the typed in URL and the webserver that they were talking to.
Both "1" and "2" were required to establish that the webserver the
user thought they were talking to was the webserver they were
actually talking to.
Almost immediately this was violated. Webservers found that "SSL"
cut their throughput by 90+% and so they dropped back to use "SSL"
just for check-out/paying. As a result, users were contacting a
non-validated webservers and then they would click on a button
and the non-validated webserver would provide a (SSL) URL ... which
the browser would validate. Now the best that could be said is that
the webserver that the user was talking to was the webserver that
they claimed it was (not necessarily the webserver the user thought
they were talking). This was when I coined the term "merchant comfort
digital certificates" ... referring to it provided a sense of comfort
(in contrast to "security").
Note another part of ecommerce was a "payment gateway" which handled
transactions between commerce servers on the internet and the payment
networks. They wanted to use "SSL" for this ... but I had complete
authority for this (I only could recommend about the browser/server
operation). First I required that it have mutual "SSL" authentication
... code which didn't exist at the time we started ... and then a
process that exchanged "public keys" out of band (the payment
gateway public key was shipped with the ecommerce server software,
somewhat like CA keys are included as part of browser software,
and ecommerce server public keys were part of registering ecommerce
servers with payment gateway). By the time things were done,
"SSL" digital certificates were purely an artificial aspect of
the software library being used ... aka the "digital certificates"
were redundant and superfluous.
I've then done several scenarios for browsers ... having caches
of public keys for online authoritative agencies ... where
real-time public keys can be obtained (similar to real-time
mapping of domain name to "ip-addresses") ... like domain
name servers serving public keys and payment gateways serving
public keys ... which  browsers can cache (so it doesn't have
to be done everytime).

@_date: 2014-05-19 00:02:05
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] [cryptography] Is it time for a revolution to 
while HTTP was supposedly atomic UDP like protocol ... it was built
on TCP ... which would provide retry ... and browsers wouldn't have
This caused a whole lot of problems ... TCP session close has finwait
list of recently closed sessions to catch possibly dangling packets
arriving after session close. This was being processed linearly ...
original implementation assumed very small number of session
close in FINWAIT. The used of TCP by HTTP exploded the number
of session closes on the FINWAIT list. Scaleup of early webservers
were finding they were spending 95-99% of their time running FINWAIT
list. NETSCAPE itself had rapidly expanding number of webservers to
handle the load ... until it got a sequent server ... which had
dealt with the FINWAIT problem when they had customers with 20,000 telnet
sessions and growing FINWAIT problem. It was another six months
or so before the other vendors came out with rewrite of FINWAIT
handling for the (mis-)use of TCP by HTTP (during which time
webservers went through mini-crisis)
TCP has minimum 7-packet exchange for a session (besides the
FINWAIT issue). VMTP had defined a minimum 5-packet exchange
for reliable operation. In prior life I was on the XTP technical
advisory board that defined a minimum 3-package exchange for
reliable operation.
I hypothesized webservers registering their public keys with
domain infrastructure (at same time as domain registration).
DNSSEC would have option to return any optional public key
with ip-address lookup response. Then HTTPS/SSL-light could be
done on XTP by piggybacking symmetric key (encrypted with server's
public key) with initial encrypted data

@_date: 2014-05-19 16:11:12
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] [cryptography] Is it time for a revolution to 
SSL was 94/95 ... and banking industry applied MOTO rates to internet transactions.
96/97 the banking industry was afraid that the telco industry would take over
the payment industry. the payment fees were contributing nearly half banking
bottom line and were heavily prorated based on possibility of fraud in transactions.
micropayment had prospect of enormous increase in transactions ... totally
swamping the existing payment backends. the only platforms that could possibly
handle the transaction rates were backends for telco developed for handling
callrecords (still ACID properties leveraging new "in-core" DBMS technologies).
telcos figured they could combine micropayment and callrecord charges in the
same statement.
banks were afraid that once the telcos had the micropayment market, they would
leverage it to move upstream and take over the rest of the payment industry ...
using technology to be substantially more cost effective than banks.
the micropayment volumes never quite emerged and the telcos stumbled not
being very diligent managing non-payment of statements. when statements
were purely callrecords ... it wasn't actually out-of-pocket expense,
basic use of infrastructure already there. With payments, the telcos
had already transferred the money to the merchant/recipients and needed
to recover that money from their customers. Within a couple years,
all the telcos that had made big move into payments had all backed out.
Even at that, the bank industry was still afraid of new entries into
banking that could be much more efficient and competitive. At about
1:03:30 I'm starting to blather that rhetoric on floor of congress
about the primary purpose of GLBA was to keep new competitors out
of the banking industry (specifically referring to new technology
and corporations like microsoft).
GLBA now better known for repeal of Glass-Steagall (enabling "too big to fail").
cal. state was working on legislation for electronic signature, data
breach notification, and op-in personal data sharing. cal. managed to
get data breach notification before preemption by congress ... but
bank industry managed to get "opt-out" added to GLBA and passed
preempting cal. state "opt-in"
The card associates in that time-frame did define SET specification
with enormous amounts of crypto and digital certificates. When it
was 1st published, I did crypto-opt profile and had friend benchmark
with BSAFE library on several platforms ... and provided the information
back to the SET group (that included several vendors). The response
was the numbers were 100 times too slow. They obviously hadn't
ever done any real live operations since this was an improved BSAFE
library that was four times faster than the regular libray. Six
months later, initial SET prototype was very close to the profile
benchmark numbers.
The other issue was that it required appending digital certificates
to every normal payment transaction (besides encrypting the content
of the transaction). The only problem was that the typical digital
certificate payload sizes were 100 times larger than a normal
payment transaction payload size (and I was already constantly
pointing out that they were superfluous and redundant ... but
they also resulted in payload bloat of factor of 100 times).
Somewhat as a result, the CA industry got a work item in the
financial industry standards body to do compressed digital
certificates ... possibly down to only ten times payload
bloat (rather than 100 times payload bloat) ... still ignoring
that the digital certificates were redundant and superfluous.
However, I demonstrated using some of their proposed techniques,
compression of digital certificates to zero bytes. Rather than
eliminating redundant and superfluous digital certificates,
the industry could managed zero byte digital certificates appended
to every payment transaction.

@_date: 2014-05-19 18:39:58
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] Is it time for a revolution to replace TLS? 
somewhat having done e-commerce, in mid-90s we were invited to participate
in the x9a10 financial standard working group which had been given the requirement
to preserve the integrity of the financial infrastructure for *ALL* retail
payments. we did some number of end-to-end threat & vulnerability studies.
the result was x9.59 financial transaction standard which basically
was simple digital signature on standard payment transaction (smaller
enough to transmit end-to-end and authenticated with public key
onfile with users financial institutions).
the standard allowed for security proportional to risk ... i.e.
registering integrity level of the associated private key (software
key, hardware token key, integrity level of hardware token, etc).
the standard also allowed for co-signing by FINREAD conformant
hardware token interface ... developed in the 90s as countermeasure
to compromised PCs (i.e. had independent display and PIN entry
that token couldn't be operated w/o human action in secure
independent environment ... and transaction detail displayed
... which couldn't be spoofed by compromised PC).
One of the results, was attackers could no longer use information
from data breaches (at least involving x9.59 transactions) as enabler
for performing fraudulent financial transactions. x9.59 no longer
even needed ssl to hide financial transaction information as
countermeasure to fraudulent transactions.
A couple things happened start of the century
1) a large chipcard was deployed in the US with free chipcard
reader give away. However, they apparently wear obsolete serial-port
readers which resulted in significant customer support issues and
resulting rapid spreading opinion in the industry that chipcards
weren't practical in consumer market. Now 95-96 timeframe
there were presentations by dialup online banking operations
about main motivation to move to internet was significant
customer support problems with serial port dialup modems
(effectively support problems offloaded to ISPs). Apparently
institutional knowledge about the serial-port customer support
problems had evaporated in a 5yr period. Serial-port customer
support problems was also major motivation for USB. In the wake
of this effort, there was pullback from all consumer chipcard
related programs (including FINREAD).
2) In the same time frame, there were some number of chipcard-based
and non-chipcard "safe" payment products developed that had high acceptance by
major online ecommerce merchants (accounting for something like 70+%
of ecommerce transactions). Merchants had been indoctrinated for
decades that payment (interchange) fees had a significant fraud prorated
surcharge. The major merchants were expecting that "safe" internet
payment products would result in 90% reduction in the fees charged.
With payment fees accounting for something like 50% of bottom line,
a 90% reduction be a big hit. The banks decided that instead of
90% reduction for safe internet products, they would add a surcharge
to the highest rate the merchants were already paying. There result
was major cognitive dissonance with the merchants and whole thing

@_date: 2014-10-29 14:46:12
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] EMV as a fraud enabler 
There are various quotes about those that don't learn from history are doomed to
repeat the same mistakes.
the current payment infrastructure somewhat grew up during the days of
trusted value added networks (VANs) during the 70s&80s ... which were mostly
obsoleted by the internet over the last 20yrs.
about the time the card associations were first drafting the POS/EMV in Europe,
they also had a totally different group drafting a payment specification for
the Internet. They shared the characteristic that the integrity checking was
being done at the perimeter/boundary ... which is then dependent on internal trusted VAN
(lots of business interest in preserving that status quo) ... however it creates
an enormous attack surface ... both at the boundary/perimeter as well as inside
the infrastructure.
Not long after the early deployment of their internet payment specification, some of
the business people discovered that they were getting transactions that had
flag set that the perimeter had performed the crypto integrity check ... and
they could prove no such crypto was ever involved (not all the different from
the current attacks nearly 20yrs later).
In the internet case, the attempts to preserve the status quo of the existing
payment networks (trusted VAN) were masked by selecting crypto technology the
bloated the payload size of a payment transaction by two orders of magnitude
(100 times) ... resulting in the justification  that the crypto integrity checks
had to be performed at the boundary and only a single bit sent through (indicating
successful integrity check) because the payment networks couldn't stand a factor
of 100 times increase in transaction payload size. Note that there is little or
no evidence of that early standard still in existence.
There were other teething problems with the POS version. There was a large early
deployment in the US during the "YES CARD" period ... it turns out that it was
possible to use the same skimming technology to create a counterfeit magstripe
to create a counterfeit chip. The fraud was actually worse because a countermeasure
to counterfeit magstripe is to deactivate the account number. However for the
"YES CARD", business rules had been moved into the chip ... and a (counterfeit)
chip could tell the POS terminal that correct PIN was entered (regardless of
what was typed), that the transaction was offline (no online checking for deactivated
account) and the transaction was approved. In the wake of the "YES CARD", all
evidence of the US deployment disappears and speculation that it would be quite
some time before it is tried again (the people involved loosing credibility).
Reference to the "YES CARD" at the bottom of this Cartes2002 trip report (gone
404 but lives on at the wayback machine)
disclaimer: we had been brought in as consultants to small client/server startup
that wanted to do payment transactions on their server, they had also invented this
technology called "SSL" they wanted to use; the result is now frequently called "electronic
In part for having done "electronic commerce", we were asked to participate in the
x9a10 financial standard working group (about the same time the card associations
were drafting their POS and internet specifications) which had been given the requirement
to preserve the integrity of the financial infrastructure for *ALL* retail payments.
For this financial transaction standard we slightly tweaked the paradigm and defined
end-to-end integrity ... with fast crypto and minimal payload size so that it could
easily travel through the existing payment networks ... but because of end-to-end
integrity no longer required trusted VANs or hiding the transaction information. As
a result it enormously reduces the attack surface.
Now since the major use of SSL in the world today is this early ecommerce work for hiding
transaction details ... the standard also eliminates the requirement for SSL for that purpose.
It also eliminates the motivation for most of the current financial breaches since
crooks can't use the information from previous transactions for fraudulent transactions.

@_date: 2014-09-29 08:47:34
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] NSA versus DES etc.... 
during first decade of the century, there was big increase in privatization
and outsourcing fed. gov. to for-profit companies. over half the people and
70% of the budget of intelligence community is now by for-profit companies.
beltway bandits and for-profit military-industrial complex have used
gaming to come up with even more techniques to maximize revenue flow,
including a series of failed efforts represents more profit than
an initial success
supposedly in the wake of above, congress put the agency on propation and
not allowed to manage its own projects ... which may just have been ploy
to further privatize the agency (fed. agencies can't use appropriations to
"lobby" congress ... but private companies can ... claims are that congress
now expects something like 5% of such appropriations).
more on privatization
note that IBM was heavily involved in DES. The new CEO that was brought
in the early 90s to resurrect IBM and reverse breakup into the 13 "baby blues",
then leaves to head up one of the largest private equity companies ... which
then takes over the company mentioned in the above article. Private equity
companies have become notorious for wringing every possible dollar out of
an operation.
other background on the "success of failure" scenario
Director shelves working $3M ThinThread for multi-billion dollar Trailblazer that doesn't work
Director shelves working $3M ThinThread for multi-billion dollar Trailblazer that doesn't work
now Turbulence

@_date: 2015-05-02 09:23:43
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] "Trust in digital certificate ecosystem eroding" 
we were brought in as consultants to a small client/server startup that
wanted to do payment transactions on their server, the startup had also
invented this technology called "SSL" they wanted to use; the result is
now frequently called "electronic commerce". Early on we started calling
them "comfort" certificates ... not because they provided security ... but
they provided users with a sense of comfort.
Browsers were being paid by CAs to include their certificate ... so the
CAs could sell certificates (paid for by merchants).
we were tangentially involved in the cal. state breach notification
legislation having been brought in to help word smith the electronic
signature act. lots of the participants were heavily involved in
privacy issues and had done detailed, indepth public surveys. The
 issue was "identify theft", primarily the form of fraudulent
financial transactions as a result of breaches ... about which there
was little or nothing being done; it was hoped that the publicity
from the breach notification would prompt corrective action. The
issue is that normally security efforts are taken in self-protection,
in breach scenario, the institutions aren't at risk, it is there customers.
In the congressional hearings into the pivotal role that the ratings
agencies played in the economic mess ... it was pointed out that their
business model was misaligned (and the rating agencies were motivated
to do the wrong thing ... and regulation where business model is misaligned
is enormously more difficult). The buyers benefit from the ratings ... but
the sellers were the ones paying the rating agencies.
Securitized mortgages had been used during the S&L crisis to obfuscate
fraudulent mortgages ... but had limited market. In the late 90s we were
asked to look at improving the integrity of supporting documents as a
countermeasure. In the early part of the century, the sellers found that
they could pay the rating agencies for triple-A (when both the sellers and
the rating agencies knew they weren't worth triple-A, from Oct2008
congressional testimony). Triple-A trumps documents and they could now do
no-down, no-documentation lair loans, pay for triple-A and sell to customers
... including large institutional funds restricted to dealing in "safe"
investments (like large pension funds, claims caused 30% or more loss in
pension funds contributing to trillions in pension shortfall). As a result
over $27T was done between 2001 & 2008
 From the law of unintended consequences ... the lack of documentation leads
to the TBTF having to form the large robo-signing mills to fabricate the
(missing) documents.
If that wasn't enough, they then started doing securitized mortgages
designed to fail, pay for triple-A, sell to their customers and then
take out CDS gambling bets that they would fail ... creating enormous
demand for dodgy loans.

@_date: 2015-05-04 13:56:59
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] "Trust in digital certificate ecosystem eroding" 
Certification authorities tend to certify the information from authoritative
agencies responsible for the information ... in the case of domain name
ownership ... it is the domain name agencies. Domain Name Certification Authorities
have had a catch-22 ... proposing various public key and digital signature
changes to domain name registration for improving the trust and integrity in the information
they are certifying (and countermeasure to various domain name registration exploits
like domain name take-over). The registration of a public key at the same
time as domain name registration ... then requires that all future communication
arriving at the domain name authority is digitally signed ... and can be
authenticated with the on-file public key (for that domain name).
The issue then for the CAs is they can require that an application for
domain name digital certificate can also be required to be digitally
signed ... and they can replace an error prone, complicated, and costly
identification process with a much simpler, straight-forward and less
expensive authentication process ... by retrieving the onfile public
key for verification of the digital signature.
The result is not only improving the trust and integrity with the domain
name registration ... but also improves the domain name CA process.
The catch22 is that if the CA business can do real time retrievals
of on-file public key for authentication ... then possibly others might also
... reducing the need for domain name digital certificates.

@_date: 2015-05-07 09:56:08
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography]  "Trust in digital certificate ecosystem eroding" 
Note the CA industry was floating a $20B/annum business plan on wallstreet for personal digital certificates ... paid for by the financial industry.
The CA industry had sold the wonders of digital signatures (along with requiring digital certificates) to the financial industry for "safe" financial transactions. Understanding liability, People in the financial industry had slightly modified the process to "relying party only" digital certificates. The result was that the financial industry would register an account owner's public key in their account record. The process then would have the financial industry transmit a copy of the account database to a CA, which would swizzle each account record bit pattern into a digital certificate and only charge $100/account. Some number of institutions spent tens of millions on pilots before it was raised to the board level the CA  charge. One typical case of financial institution with 14M accounts, the board was told that CAs would only charge $1.4B for this great new facility ... resulting in the pilot (have already spent several tens of millions) being shutdown and the peop
 le respon
sible freed from their jobs.
I would also make the point that the relying-party-only certificates were redundant and superfluous ... since the financial institution (relying party) already had the public key on file in the account record. I also made a point that a typical credit card transaction payload size was 60-80 bytes. Appending digital certificates to every transaction would add 6kbyte-12kbytes to every transaction ... a factor of 100 times size bloat (for something that was redundant and superfluous).
Ignore the redundant & supefluous comments, a financial industry standards body took up a work item for "compressed" digital certificates ... looking for a factor of ten times reduction (so size bloat would only be ten times instead of 100 times). Part of their approach was to eliminate all fields that the relying party would already have. I was able to demonstrate that the relying party would already have all fields, so a digital certificate could be compressed to zero bytes. Then rather than working for the elimination of all digital certificates as redundant and superfluous ... work for the mandated appending of zero byte digital certificates on every transaction.

@_date: 2019-08-16 11:30:49
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] The actual history of EV. Was: Well, 
Online transactions were mapped into the existing MOTO transactions and fee structure.
Around the turn of the century (nearly 20years agp) there were a couple different "safe" transaction products pitched to major internet merchants (accounting for 70-80% of online transactions) with very favorable acceptance ... expecting that their MOTO fees (person & card not present) would be reduced to that of an ATM machine pin-debit transaction (like a 90% cut). However, the merchants were then were told by financial institutions that instead of major fee cut, there would be a fee surcharge on top of the highest fee that the were already paying ... and the cognitive dissonance sets in and the whole thing falls apart.
The issue was that for decades merchants were indoctrinated that transaction fees had fraud surcharge proportional to fraud rate ... with MOTO (and then internet) being the highest. They were then being told that the safe internet transaction products would just about double the surcharge they were already paying for fraud ... initial surcharge for existing MOTO/internet fraud rate ... and then large additional surcharge for eliminating that fraud.
After that there were number of discussions about bottom line of major financial institutions is dependent on their being some amount of fraud ... which they can bill the merchants for (with significant profit markup). Worse, eliminating that (low-hanging fruit) fraud, criminals would move to other types of financial fraud ... for which they couldn't bill somebody else for.
