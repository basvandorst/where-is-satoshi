
@_date: 2013-10-02 00:05:25
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] Sha3 
Absolutely agreeing... I mean that is the most important point about
crypto at all - being secure.
And if one is in doubt (and probably even when not), better use a very
big security margin, which in the SHA3 case would mean, rather take high
multiples of bit lengths and capacity than what seems conservatively
secure enough.
The argument, that attackers don't penetrate but rather circumvent
cryptography doesn't count much at all, IMHO.
Sure that's what happens in practise, but if we hook up on that, we
could more or less drop any cryptography for say 98% of mankind which
use insecure (or even backdoored) systems like Windows, MacOS, Flash,
etc. pp..
Obviously, performance is an issue for some systems (especially
embedded) but an algo that is fast enough, but potentially not secure
enough is absolutely worthless[0].
Sure, some people utilise the FUD argument now,... basically pointing
that we have no strong reason to believe that e.g. Keccack with the
newly proposed parameters from NIST isn't secure enough.
But when we should have learned one thing from the whole NSA/friends
scandal is ... we really don't have much of an idea how far these guys
are up to - neither in terms of mathematics, nor in terms of raw
computing power (when the public already knows about facilities like
that Utah data centre - one can probably fairly well expect that dozens
of these exist which are unknown).
[0] And if you want a fast hash algorithm that is not to be used in
cryptography, we have plenty of other solutions already.

@_date: 2013-10-02 00:27:00
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] NIST about to weaken SHA3? 
I think the question is rather, what is the exact benefit NIST expects
from this?
AFAIU, performance wasn't the major priority during the competition, was
it? And even were, then Keccak has won already with the higher values,
hasn't it?
So when c roughly gives the performance/security tradeoff... then from a
pure security POV, we should obviously set a high c, right?
So has NIST experienced some real world scenarios where the "previous"
values of c yielded in a too slow algorithm, that made it unusable for
the job?
Cause if not,... then I'm back to the argument, why moving the
performance/security tradeoff towards performance, if there was no
strong reason,...
Even(!) if one says, that from a crypto POV, 128 bits would be enough
for a 256 bit hash... as long as we aren't forced due to some strong
performance reasons... rather waste the extra security margin than
dropping it.

@_date: 2013-10-06 00:22:39
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] Sha3 
You know why other people than the authors are doing cryptoanalysis on
algorithms? Simply because the authors may also oversee something in the
analysis of their own algorithm.
So while the argument "the original authors said it's fine" sounds quite
convincing, it is absolutely not - at least not per se.
The authors may be wrong or they may even be bought as well by NSA or
some other organisation.
Of course this doesn't mean that I?d have indication that any of this
was the case... I just don't like this narrow-minded "they said it's
okay, thus we must kill of any discussion" argument, which has been
dropped several times now.

@_date: 2013-10-18 22:33:14
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Why? If the system is correctly set up, a good seed should be loaded and
no problem will arise.
If not, it's better to have failing programs or even a completely broken
system, than one that does insecure things.

@_date: 2013-10-19 01:27:37
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Sure... but a) AFAIU nobody's talking that urandom should block ever
once it has been correctly seeded, right? and b) even if that was
necessary for security than that simply wins. If an program cannot live
with a blocking device than it's buggy.
And? A thousand times better than revealing all your secrets by using
bad entroy.

@_date: 2013-10-19 23:43:00
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
No it is not,... actually security is generally more important than
anything else, other wise you wouldn't need to have security added to
the respective functionality in the first place.
Basically, I absolutely agree what James A. Donald has written just
Well I'm sure you can make up man non-real world examples like this
where security is (seemingly) less important than functionality.
But apart from the question: Why does a pacemaker need cryptography?,...
you could also wonder yourself: What happens if the cryptography is so
weak, that any passer could hack the pacemakers of all people around
thereby killing them?
I don't think this would work out, as Ted and others mentioned,...
programmers would easily fall into the habit of leaving their programs
broken and use the less secure option,... and if the flag wouldn't
default to the secure setting, it wouldn't help all the legacy apps
being already out there, unless they're explicitly updated (unlikely).
Some people also mentioned that making things secure by default (e.g. in
this case /dev/urandom blocking if it couldn't give back good numbers)
than people may choose to implement their own (even worse) RNGs...
Sure that's always true,... we never can force people not to shoot into
their own feet.
But just because we can't it doesn't mean that we should make the
systems less secure by design.

@_date: 2013-09-30 05:12:06
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] NIST about to weaken SHA3? 
Not sure whether this has been pointed out / discussed here already (but
I guess Perry will reject my mail in case it has):
This makes NIST seem somehow like liars,... on the one hand they claim
to surprised by the alleged NSA-conspiracy around Dual_EC_DRBG and that
this would be against their intentions... on the other hand it looks as
if they'd be trying the same thing again.

@_date: 2013-09-30 23:37:32
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] NIST about to weaken SHA3? 
Well I think the most important advantage would be more security...
performance can only have far lower priority,... otherwise the whole
thing is rubbish.
Sure, SHA2 is far from being broken, but we've seen some first scratches
in SHA1 already... so it doesn't hurt if we have an algo which is based
on different principles, and has a high security margin.
I guess we've seen that in the most recent developments... better take
twice or three times than what we expect to be the reasonable security
margins, since we don't exactly know what NSA and friends is capable of.
Better try to combine different algos, for the same reason.
NIST has somewhat proven, that they can't be trusted, IMHO, regardless
of whether they just didn't notice what the NSA did, whether they
happily helped the agency, or whether they were forced so by law.
For us this doesn't matter.
To my understanding, performance wasn't the top-priority during the SHA3
competition, otherwise other algos might have been even better than
So this move now is highly disturbing and people should question, what
does NIST/NSA know what we don't.
Can you really exclude for sure, that they haven't found some weaknesses
which only apply at lower capacities?
I a way, that reminds me to ECC and the issues with the curves (not from
a mathematical POV, of course)... we have some (likely) fine
algorithm,... but the bad[0] guys standardise some parameters (like the
At some point we smell the scandal and start wondering, if we wouldn't
be far better off with a different set of curves... but in practise it's
more or less too late then (well at least it's very problematic), since
all world is using that set of standardised curves.
It seems a bit as if we now to the same,... following NIST/NSA like
Keccack seems to be a fine algorithm... perhaps it would be better the
scree SHA3 altogether an let the community decide upon a common set of
concrete algos (i.e. a community-SHA3) which is then to be standardised
by IETF, or whatever else.
An better take two or four times the capacity and/or bit-lenghts than
what we optimistically consider to be very secure.
[0] In contrast to the evil guys, like terrorists and so on.

@_date: 2014-11-19 00:21:52
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] New free TLS CA coming 
Well not really a surprise, is it?
Mozilla never really acts with the security of their users in mind.
Countless of highly untrustworthy CAs in their bundle and lots of
insecure default settings demonstrate this quite well.
It's always all just about their money and popularity.

@_date: 2015-04-13 21:35:25
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] the TOFU lie - or why I want my meat... 
... at least when it comes to crypto.
Two weeks ago, I've posted[6] the thoughts(/rant?) below at gnupg-devel
(when someone proposed adding TOFU features to GnuPG.
Of course it was a bit off topic there, but discussion went a bit on
with some people.
Nevertheless, I think this mail rather belongs to this mailing list,
which is why I repost it (hoping that no one who is also on gnupg-devel
feels annoyed :-) ).
Actually I've started a "2nd part" in the meantime,.. not sure though
when I'll find the time to finish it.
What have we had in the recent years when it came about
cryptographically secured message exchange (and message doesn't mean
"mail", it means "any data") that was actually used on a broader basis?
a) OpenPGP and similar schemes, where peers are typically more or less
   directly authenticated (e.g. by personal meeting and fingerprint
   exchange)[0].
   This btw. also includes things like SSH, at least when one
   directly/securely exchanges SSH keys.
   This PKIs put the whole control under the user. He can decide who he
   signs/trusts, or how many indirections (in the case of WoT) he'll
   trust and so on.
b) X.509, and similar schemes, where trust in another one's identity is
   not directly authenticated, but rather one trusts one (or hundreds)
   of central points (the CAs) to do the right thing.
   This includes basically all SSL/TLS, because this is typically only
   used with X.509, and yes I know there is a RFC for OpenPGP + TLS, but
   is there even a client who implements that?
   Here, the control is effectively fully out the user's hand. The CA
   alone decides, can forge (accidentally or on purpose) identities and
   so on.
   Theoretically the user can decide which CAs he trust, but in practise
   this won't work either, since you have no control which CAs your peer
   use.
   Each CA can typically also assert the whole namespace (i.e. *all*
   domainnames,... or *all* personal names - and not just the ones from
   e.g. Lithuania)
(a) Is typically only used by people who want stronger security (i.e.
those who don't trust that fragile strict hierarchical and CA based
model of X.509). Or in cases where it needs to be sure that a 3rd party
cannot forge anything (e.g. when distributing packages of a Linux
(b) Is - whether intended as such or not - typically used for the
masses. Everything in the web (i.e. https) that is secured.
(btw: (b) is in concepts quite similar to TOFU,... no-one ever actually
verifies the CA's root certs... it's also trust on first use, what your
(e.g. browser) vendor ships)
That the X.509/strict hierarchical system is inherently broken, was
clear to everyone for many years (not only since Snowden or the growing
frequency of cases where CAs did something evil).
The masses didn't really complain, neither did any of the bigger players
(banks, Google, Mozilla, MS). The system worked at least to that extent
that people felt save and not enough damage was made by cybercriminals
to make a change worth.
Thanks to incompetent and/or corrupt CAs (does really anyone believe the
story that Turktrust or CNNIC's sub CA just made that forged CAs by
accident?), thanks to greedy companies like Google/Mozilla/MS/Apple who
only care about money and or market share, the system was kept alive and
thanks to them it was weakened more and more by the introduction of more
and more CAs (IIRC Modzilla ships around 150 these days, not counting
intermediate CAs).
You have the money? You'll be a CA and can do what ever you like!
And even if abuse gets public, Mozilla and friends likely won't ban you
(again see e.g. Turktrust, CNNIC).
Now since the whole NSA/GHCQ scandal and since the CA system showed more
and more to be what it is - broken - people started to actually
recognise that problem.
So the same people/player who knowingly kept the broken system alive,
are now looking for ways to fix it (which however isn't really possible
by nature).
The most prominent "solution" is probably TOFU, or key pinning or
however you call it.
It seems like a bad joke that those player, who are all too often
against open standard and who are well known to happily cooperate with
or even advise government agencies are now the ones trying to push TOFU
as "soluion".
Honi soit qui mal y pense!
So... TOFU.
Trust on first use.
That's basically like what we've had in the good old days with anonymous
SSL/TLS modes, where it was clear to everyone, that this doesn't really
provide security. Or similar to just blindly accepting a SSH server host
key without checking whether it's actually the right one.
Well it's that anonymous authentication + pinning of the respective
credentials (key, cert, or however you call it).
One can use TOFU "alone", e.g. just trusting any credential (like a
self-signed cert) on the first use. Or hybrid with e.g. the strict
hierarchical model from X.509.
The idea how TOFU should "solve" or at least improve things is, that
you'd recognise if subsequent connections go to the same destination
(because you have it's credentials/keys pinned/trusted - on their first
The first bad assumption here is that one would have gained "trust" at
any stage. This is simply not true.
One cannot know, whether the peer on the first connection/communication
was actually the desired one (and has thus deserved "trust") or whether
it was my neighbours son, some cyber criminal or the BND (yes even the
German intelligence service isn't that bad as people often may think).
TOFU doesn't prevent MitM at the first connection at all, and once that
would have happened, an attacker could simply MitM every further
So TOFU makes some further assumptions:
1a) In practise one would have simply good enough chances that the first
    connection (where trust is given) is not attacked.
1b) (see below)
2) And even if it was attacked (and all further communication relayed
   via Mallory), one would sooner or later notice it.
I really wonder how one can just dare to make any of these two
assumptions and sell it to people... o.O
As for (1):
We already know that NSA/etc. sit literally at all the central network
places, the internet exchanges, the transatlantic cables, quite surely
in satellites and so on.
They either cooperate with the big content providers (Facebook, Google,
etc.) and the big Tier-1s (Level, Akamai and that like), they force them
to cooperate by law (national security letters, gag orders) or they
simply hack them.
Quite likely most of the commercial companies (i.e. those who file
lawsuits against the NSA and protest loudly) just happily cooperate in
They (NSA/etc.) also even hack the network hardware before it's
delivered to customers.
We know that they have extremely large powers, even already when
operating under law (cause in the US and others, when it comes to
surveillance or economical espionage law doesn't really matter),... and
if law should be in their way, well then they simply ignore it.
So again, how on earth could one believe that one would be safe from
MitM attacks in the "OFU" stage of TOFU?
Quite contrary, one must very well assume that they actually are listen
and sneak in as soon as a target would be interesting.
And even if you don't look at NSA/Co. - the same principle just applies
to the big players AND to cyber criminals.
They likely don't have access to that large part of the cake as e.g. the
NSA, but how can one just assume that the simple cyber criminal who
attacks you for ransom money isn't capable of getting in the line for a
We see that basically daily with highly sophisticated attacks on two
factor authentication systems like smsTAN in mobile banking and lots
So the argument (which is 1b) that typically comes next:
"Well they may be able to MitM most connections, but it would be too
expensive for them to do this on a broad scale ... and _therefore_ it
prevents or at least helps against mass surveillance.
Again, how can one just make such a blind and naive assumption.
We already know the extreme things they're capable of, like storing vast
amounts of data for lata use. We know the extremely big computing
centres they have (and these are just the ones publicly known - I don't
need to wear my alu hat, to believe that there real capacities are many
times higher; history has proven that.).
IMHO the arguments (1a) "in practice on will be lucky and the 'first
use', i.e. when the key is pinned/trusted, will be the right one" as
well as (1b) "well even if not, it at least prevents mass
surveillance"... are at best completely unproven, but likely simply
plain wrong, naive and - in all doing respect - stupid[1].
Then there's argument (2). The idea behind is:
If one makes an anonymous key exchange, then even when it's anonymous
(but trusted) in the first place, one would/could sooner or later
notice, if one was attacked (in the single case), respectively whether
mass surveillance continues.
Let's look at the single case:
When I notice "sooner or later" that I was MitM attacked, then it's
likely already too late. My precious data is likely already stolen or
e.g. evil code may have been already introduced in my system or e.g. my
bank account is already empty.
A cybercriminal who's on to me, or a intelligence agent who has really
targeted me simply wouldn't care.
The former only wants money and if his attack is noticed, well he didn't
send me his address in advance so he'll just move on to the next victim.
And the later... either they have already what they wanted, or it's at
least better for them to have a bit than nothing.
In both cases, the argument "that one may sooner or later notice it" is
simply moot.
And let's look at the mass surveillance case, the idea is basically:
*If* the masses would use opportunistic encryption with TOFU, then
they'd be secure unless the agencies already MitM most or all of them at
the "OFU" stage of TOFU.
But, since one can find out later (e.g. by really comparing the
credentials when meeting the actual peer) people would notice that mass
surveillance is still in place... and then...
then what?
A big outcry? Governments changing the system and stopping mass
surveillance? People start switching to really secure (i.e. mutually
authenticated communication)?
Forgot it already? We've had these things already! A big scandal. A big
What happend? Nothing (at least on "their" side).
Actually quite the contrary - what paranoid people just assumed to be
the case (i.e. the mass surveillance before) is now publicly confirmed
and justified by NSA/Co.
So, to all the proponents of TOFU/key pinning and that like:
How can you dare to make assumption (2)?
How can you dare to believe that this would prevent NSA/Co. from
attacking (in the form of surveillance) people?
We already know that they do much worse things (like actively breaking
into computer systems, computer sabotage, and so on), they're basically
the same as cyber criminals just that they do it for the "good"[2] and
that they don't need to fear any consequences (in contrast to cyber
criminals; remember that people who illegally copy a video get worse
punishment than rapists or murderers).
IMHO, TOFU won't help you at all against mass surveillance:
- As said above, it won't keep the high level attackers (NSA level,
which are the typical bodies for mass surveillance) from doing their
If everyone would do opportunistic encryption in conjunction with TOFU,
they would simply adapt and MitM every connection they can. It would be
publicly known, just as  their mass surveillance is known now.
- The next lower level of attackers who do mass surveillance are
actually the big companies which now try to sell security to people
(Google, Facebook and that like).
For them it would actually get harder to do surveillance (because they
cannot easily operate outside the law). But their form of surveillance
is anyway completely different.
People voluntarily (actually just happily) give them all their data
(look at Facebook).
So they don't care about encryption as an enemy at all
- Last but not least, cyber criminals.
They typically don't care so much about mass surveillance, and even if
they would: They already operate outside the law, so as soon as they can
MitM people - they would.
Last but not least, some motivational analysis and my personal opinion
about how TOFU-like ideas affects security of single people as well as
the masses.
TOFU is IMHO clearly indented for the masses, i.e. those who don't know
to much about crypto, and simply want to use the web. Why? Well simply
because it doesn't give any real strong additional security. So all the
paranoid people, or experts and that like, they likely simply would want
to continue with their safe mutually performed authentication (be it for
OpenPGP, or accessing an SSH server).
So the argument by proponents is often:
3) "that we (i.e. software developers, standard makers, other experts)
need to secure the masses".
Remember the beginning of my lengthy mail (sorry for that btw.)? Were I
basically wrote that noone (not even the banks who loose money) care
about the flaws of the X.509 model?
That's just it. No one cares. At least not until people would suffer
more severe consequences.
Mass surveillance? Well all people complain, but apart from a few none
of them *really* cares (because if, then they would look for ways to
protect themselves).
A hacked email account or the knowledge that all unencrypted
emails/Whatsupp/etc. can be read either by anyone or at least some
others? Do you really think the masses(!) would care?
A few cases of hacked bank accounts? Well that's perhaps when people
start to get annoyed, but as long as the banks pay for the damage...
this ain't a big deal either.
So when it comes to (3) I really wonder:
Why would "we" need to secure the masses, when they typically don't care
anyway? At least not above the level of says "yeah it's a shame that XYZ
happens.." + secretly thinking .oO(but I don' really care either).
Don't get me wrong, I don't say that we should remove security/crypto
from the masses.
But I don't see why we should be obliged to introduce TOFU (for which
it's IMHO questionable whether it increases security at all) when we
already have a system which works for the masses:
Apart from allowing forgeries and surveillance, and apart from single
cases where this was even done by Cybercriminals (remember when the
reserved the TLD  or something like that and got a
certificate for it).
So much for the question, why would the masses want TOFU.
And I'm not going to analyse now which motivation some bigger (e.g. US)
players may actually have to advertise key pinning and that like now as
a big step forward so that people feel secure again.
Honi soit qui mal y pense!
Long story short, my analysis of the TOFU principle and key pinning
methods is the following:
a) at best, it would give people a short longing improvement in they
security, *if* (and only *if* and as long) attackers don't decide to
already start attacking[4] them at the "OFU" stage.
b) at worst - people could assume - it wouldn't harm either
but I think that's wrong:
more realistically:
c) the massive campaign in favour of TOFU that we see at all different
levels: standards making (yeah, HTML2 has now nearly-mandatory
encryption - so it's secure, isn't it?), development and the communities
has IMHO actually quite a number of dangers:
- The masses will actually believe that they'd be now at least more
  secure than before.
  Thus they will care less about their effective security and even less
  about the political dimension of the whole topic.
  In the light of new crypto wars being probably just started - quite
  bad.[5]
- Developers, standard makers and experts actually start believing the
  illusion of TOFU and care less about implementing stronger rock solid
  mutually authenticated crypto systems.
- Which in turn will (in the long term) also affect those people (like
  most/many OpenPGP users) who really wanted strong security, and who
  put their efforts into it.
  Simply because less software/standards may provide that strong
  security.
In the end, the minority who really wants (and or needs) security, would
likely start to suffer for a majority who even doesn't care about it.
Best wishes,
[0] And just to prevent Werner from the usual comment: yes I know,
OpenPGP doesn't mandate this or the WoT,... but I guess one can easily
say that it's mostly used in that way.
[1] And yes I use such harsh words, because people already believed in
the past the intelligence services, cybercriminals weren't capable of
this and that (or at least not doing it)... and they did as if it was a
complete surprise when Snowden revealed his stuff. And now, where they
should know much better, they do it again.
[2] And no I'm not questioning here whether this is the case or not,
actually I don't believe that NSA/BND/Co. are evil per se.
[3] I assume everyone noticed the first a being actually not an a but a
U+0430 CYRILLIC SMALL LETTER A.
[4] And we must generally assume that an attacker has no reason not to,
since he'll always attack the weakest chain in the target. So if he
finds something weaker, e.g. flash installed ;-) he'll take that, but if
there's no better alternative, why should he not do MitM respectively
mass MitMs?
[5] And probably quite bad for Snowden, cause the first day Putin sees
no PR use in him anymore and the US would have to offer anything, we'll
probably disappear forever in some US supermax.
[6]

@_date: 2015-01-04 05:48:05
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] 
=?utf-8?q?ything=3F?=
 I don't see any reason why SSH should be weaker than anything else. In
fact it is not.
No one forces users to blindly trust a remote host key on first
encountering it, that's why there are fingerprints and people should
validate those - if people are stupid and don't validate them, well then
you can't help such folks.
Believing that a strict hierarchical trust model like that of X.509 is
in any way more secure is just plain wrong. In fact the strict
hierarchical model brings all kinds of problems (i.e. ultimate trust in
the root, which can do basically anything). And do your really believe that users are more secure with the
gazillions of untrustworthy CAs shipped by nowadays browsers, none of
which the user has verified himself, neither do the usual users receive
their browsers via a secure way.
TOFU as well. Plus trusting players like Mozilla and the CAs, which all
have rather money in their mind than anything else.
Well you have the same with X.509 and TLS when you encounter a server
using a cert not signed by one of your trusted CAs.
Key management and/or authentication is nothing hard-wired in the SSH
In fact there is already a host authentication mechanism in OpenSSH
which kinda CA like (but not X.509) and there is an (unmerged) set of
patches which allows really to use X.509 (GSI SSH).
Which typically means badly maintained key files (either by the admin or
the user himself) and stupid used (since ignoring the warning, which
tells that one is possibly attacked doesn't seem that smart).
Well but this per se is probably not the reason not to use SSH as a
general crypto tunnel protocol, since one has/had to do the same with
(Oh and btw: I don't want to say that SSH should be used for everything,
it's simply not made for this.)
At least in SSH you have now EtM modes and AEAD algos which make the MAC
completely obsolete.
And legacy protocols? LOL? I don't think that either of the two will get
away soon.

@_date: 2015-01-04 07:49:47
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] 
=?utf-8?q?ything=3F?=
 ?? Well depends... for nodes which I've installed manually, I extract them
locally,... automatically installed nodes are in a securely switched
VLAN, so as soon as I have a secure path to that (e.g. via a login node)
I securely reach the node in question.
For remote nodes I contact their admins for the fingerprints (that's
e.g. how I access CERN),... for some others one may find the
fingerprints on other "secure" paths (e.g. github gives them on their
https website, so if you trust that, you can also trust the
Chris.

@_date: 2015-01-04 07:51:42
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] 
=?utf-8?q?ything=3F?=
 $ ssh -Q cipher-auth
aes128-gcm at openssh.com
aes256-gcm at openssh.com
chacha20-poly1305 at openssh.com
$ ssh -Q mac | grep etm
hmac-sha1-etm at openssh.com
hmac-sha1-96-etm at openssh.com
hmac-sha2-256-etm at openssh.com
hmac-sha2-512-etm at openssh.com
hmac-md5-etm at openssh.com
hmac-md5-96-etm at openssh.com
hmac-ripemd160-etm at openssh.com
umac-64-etm at openssh.com
umac-128-etm at openssh.com

@_date: 2015-01-04 16:23:04
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] 
=?utf-8?q?ything=3F?=
 Well this is what I've mentioned before, but it is, as I've said, not
How would you know?
Well sure, but that's not a problem, since this is not needed with
SSH... and if it was needed, because someone would want to use SSH for
tunnelling to arbitrary remote servers, you could simply implement a
X.509 based (or anything better) host authentication system (or use the
one that already exists).
Apart from that,... everyone should know by now, that the X.509 / CA
based trust system we have in TLS is inherently broken... alone the fact
that you have several 100 CAs in your browsers, many completely
untrustworthy or proven to be incompetent.
So probably the best possible way to have a strict hierarchical system
would be DANE.
And for DANE in turn, you could just place your SSH keys in DNS. Scales
as good as anything else.
Chris.

@_date: 2015-01-05 06:41:42
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] 
=?utf-8?q?ything=3F?=
  there's the "SSH protocol version 2
vendor extensions" section which contains documents "standardising" all
the OpenSSH extensions.

@_date: 2015-01-09 19:51:15
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] Compression before encryption? 
Compression before encryption may be used as an oracle when plain text
injection is possible...
See CRIME/BREACH attacks and the principle behind them.

@_date: 2018-07-27 14:06:49
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] how to encrypt for the very long term? 
I'm basically looking into encryption of (backup) files for the very
long term (like at least 20 years).
The basic scenario is as follows: arbitrary files in the 20-30 TiB
range are backuped with dar (which splits into much smaller slices) and
put on tape.
Ideally, the whole thing should be resilient against data corruption,
e.g. if some bytes of the tape are lost, the remainder of the encrypted
file can still be decrypted (dar tries to recover from such broken
archives),... however this shouldn't go at the cost of security.
A (number of) passphrase(s) shall be used for encryption (i.e. not a
pubkey scheme) of the symmetric encryption key... simply because
otherwise I'd rely on the private key and would need some other
sophisticated means to backup that as well.
Even though it's most likely overkill, I'd prefer to encrypt the files
multiple times,... like e.g. first with AES, then perhaps SERPENT,
maybe even a 3rd one.
And there should be some very strong passphrase hashing algorithm (e.g.
Argon2*)... it woulnd't matter if it takes minutes on a modern CPU.
The encryption tool should be something well maintained, taking over to
get all the difficult things (padding, salting, etc. pp.) done right.
Also it shouldn't use any of the "weaker" algorithms internally (e.g.
things like SHA1 which already has certain scratches for certain use
One choice if obviously gpg with symmetric encryption, which is well
maintained, but it doesn't have e.g. SERPENT or any of the newer
ciphers around the block.
Worst point for gpg is IMP the passphrase hashing. Even with the
maximum number of iterations it's still pretty fast, so I'm kinda
fearing a brute force attack.
mcrypt seems to be unmaintained...
Anything else that can be suggested?

@_date: 2018-07-30 14:18:12
@_author: Christoph Anton Mitterer 
@_subject: [Cryptography] how to encrypt for the very long term? 
Thanks for your replies so far,... but I think this goes in a
completely wrong direction ;-)
I'm fully aware that only OTP is theoretically fully secure... I was
still talking here about crypto which is practicably usable... also
things like forgetting password goes beyond the scope of the question.
May main point was that e.g. gpg supports only a limited set of
algorithms (e.g. AES, CAMELLIA, TWOFISH) ... and especially it seems
there is no modern key derivation function available, even with the
maximum number of s2k iteration it goes pretty fast.
So what I'd have been looking for was a program which does proper file
encryption,... but supports additionally e.g. SERPENT and Argon2*.
Especially not just some home-brew script using somthing like python-
cryptography,... but something which does everything really properly
(starting from nonce generation, up to padding, etc. pp.)
So far my best solution would be actually to use cryptsetup, which
seems to support all of these (AES, SERPENT, PBKDF2, Argon2*)... yes I
know it's for disk encryption, but since my backup slices would be all
of the same size, I could rather easily just write the file as is
(without any filesystem) into the dmcrypt block device.
