
@_date: 2002-11-05 18:20:38
@_author: Jason Holt 
@_subject: patent free(?) anonymous credential system pre-print 
(Re: my paper at  )
my system which would allow malicious users to obtain issuer signatures on
arbitrary documents.
(bitwise) same document for each element but one in the cut and choose
protocol and making the remaining document malicious.  If the malicious
document isn't selected for inspection, dividing out the signatures on the
(n/2)-1 identical documents is trivial, leaving a signature on the malicious
to thwart this attack, (and the session random values to thwart similar
attacks over multiple issuing sessions), and do appear to succeed with the
additional requirement that each credential ID be different from the others.
This requirement will be added to the next update to the pre-print.
in the Chaum/Fiat/Naor system.  It ensures that each candidate is different,
and therefore that the values of the elements signed will be unpredictable.  megabyte in size and require half a megabyte of network traffic.  Efficiency
is /not/ a major selling point of this system. :)
[pulling up from later on in Adam's post]
like Brands' - rather, it has 2 aims.  1: show how to do simple selective
disclosure in a Chaum/Fiat/Naor-like system using X.509v3 credentials as a
base, and 2: show how to link credentials from multiple issuers to the same
identity without compromising anonymity.
expansion of the related work section, and in terms of features to add in the
public key as a selective disclosure field, allowing her to prove ownership as
you describe.
Brands' implementation of lending deterrence to be a worthwhile feature.  Having embarassing information in a credential could be a deterrence against
lending to an untrusted party, but comes at the cost of an equal liability if
the credential is stolen.  It also doesn't prevent the rightful holder from
providing the response to the challenge on that field when the lendee uses the
credential (in real time).  Lending is a problem which I don't believe can be
solved purely mathematically (which Brands also points out, as I recall).  Thus I prefer to avoid the topic rather than give it unavoidably insufficient
out in section 4.4.1 that credentials should be used only one time for maximum
privacy.  Revocable anonymity would be sufficient to detect and identify a
multiple-show offender offline, although of course it doesn't protect the
rightful user's privacy like normal limited-show systems.  This is another
feature which I believe could be added to my system in the future.
update to my paper.
I'll add you to the acknowledgements (a14s?) in the next revision of the

@_date: 2002-11-06 05:18:40
@_author: Jason Holt 
@_subject: "patent free(?) anonymous credential system pre-print" - a simple 
(Re: my paper at  )
response to Adam).
presenting her student ID along with the senior-citizen ID Bob loaned her (or
for which Bob is answering clandestine-ly), as if they both belonged to her,
in order to get both discounts on her movie tickets.  In my system, you get
your credentials issued in a set associated with a single identity, and it's
hard for Alice to get Bob's credentials included in one of her own sets.  It
works even if the CAs don't trust each other.
help in the case when Bob answers in Alice's behalf when she shows his
credentials.  In any case, section 5.5.2 only adds liability to pooling - it
doesn't prevent it mathematically.  (As to lending in general, I think you're
right that discouragement may be the best we can do).
the credentials which the holder can prove is or isn't the same as in other
credentials.  However, the discussion on page 193 is with respect to building
digital pseudonyms, and the discussion on page 210 seems to be about showing
that values are *not* the same, following a scenario in which a pseudonym
holder has been identified as a misbehaver. I can think of ways in which this
feature might be leveraged to create otherwise-unlinkable sets of credentials
from different (distrusting) CAs, but it's never addressed directly that I can
see, and would need some specifics filled in.  Nonetheless, I'll point out in
my paper that it's a possibility in your system.
selective disclosure.
I'm glad that was clear in my text.  This isn't a do-everything system like
Brands' - rather, it has 2 aims.  1: show how to do simple selective
disclosure in a Chaum/Fiat/Naor-like system using X.509v3 credentials as a
base, and 2: show how to link credentials from multiple issuers to the same
identity without compromising anonymity.
was to create a system not encumbered by your patents or Chaum's.
others have lots of features which my system doesn't attempt to provide.  My
apologies if my terse treatment mischaracterized your work.

@_date: 2004-04-28 19:54:50
@_author: Jason Holt 
@_subject: Brands' private credentials 
Here's what I remember from about a year ago about the current state of
private credentials.  That recollection comes with no warranties express or
Last I heard, Brands started a company called Credentica, which seems to only
have a placeholder page (although it does have an info@ address).
I also heard that his credential system was never implemented, but that might
be wrong now.  Anna Lysyanskaya and Jan Camenisch came up with a credential
system that I hear is based on Brands'. Anna's dissertation is online and
might give you some clues.  They might also have been working on an
I came up with a much simpler system that has many similar properties to
Brands', and even does some things that his doesn't.  It's much less developed
than the other systems, but we did write a Java implementation and published a
paper at WPES last year about it.  I feel a little presumptuous mentioning it
in the context of the other systems, which have a much more esteemed set of
authors and are much more developed, but I'm also pretty confident in its
Note that most anonymous credential systems are encumbered by patents.  The
implementation for my system is based on the Franklin/Boneh IBE which they
recently patented, although there's another IBE system which may not be
encumbered and which should also work as a basis for Hidden Credentials.

@_date: 2004-08-26 19:59:54
@_author: Jason Holt 
@_subject: How thorough are the hash breaks, anyway? 
The Wikipedia article on hashes is pretty good on this topic:
So far, we know that the affected hashes are not collision resistant.  They
may still be at least somewhat one way and second preimage resistant, in which
case systems which only require those properties might still be safe.  But any
system which specifies a secure hash in the general sense would have to come
under very close scrutiny to see if it makes any assumptions at all about
collision resistance.

@_date: 2004-07-05 01:28:50
@_author: Jason Holt 
@_subject: Question on the state of the security industry (second half not 
I had the same question about the NSA when some friends were interviewing
there.  Apparently investigators will just show up at your house and want to
know all sorts of things about your friends, who you may or may not know to be
in the process of looking for work there.
As I understand it, the investigators don't even carry NSA badges; they're DSS
or private investigators.  I eventually found a phone number for the DSS, but
AFAICT there's no standard way of authenticating the agents when they show up.
Richard Bizarro had the same problem:
Someone pointed out that the NSA isn't as concerned about other people
(agencies, etc.) compromising your privacy as they are about making sure
DSS: Sir, I need to ask you some questions about John Doe.
Me: Okay, err, where's that NSA public key... windows registry... you don't have a certificate, I take it?
DSS: Well, I have this badge here.
Me: Hm, sorry, no.  I don't suppose you know anything about zero-knowledge
DSS: ...
Me: Right.  Okay, look.  I'm going to randomly generate a 1024-bit -- no, better make that a 4096-bit integer.  We'll run it in blocks through SHA512, and then you can raise it to your private [mumbling].  Do you have a coin?  On second thought, better use my own.  Lesse,  heads...
DSS: I have this gun, too.
Me: So, what do you want to know?
This was also amusing:

@_date: 2004-06-16 20:28:13
@_author: Jason Holt 
@_subject: Hiawatha's research 
"Hiawatha's Research"
Jason Holt June, 2004, released into the public domain.
Dedicated to Eric Rescorla, with apologies to Longfellow.
("E. Rescorla" may be substituted for "Hiawatha" throughout.)
Hiawatha, academic,
he could start ten research papers,
start them with such mighty study,
that the last had left his printer,
ere the first deadline extended.
Then, to serve the greater purpose,
he would post these master papers,
post them with such speed and swiftness,
to gain feedback from his cohorts,
for their mighty learned comments.
from his printer, Hiawatha
took his publication paper,
sent it to the preprint archive,
sent it out to all the newsgroups
Then he waited, watching, listening,
for the erudite discussion,
for the kudos and the errors,
that the others soon would send him.
But in this my Hiawatha
was most cruelly mistaken,
for not one did read his papers,
not one got past the simple abstract.
Still did they all grab their keyboards,
writing with great flaming fury
of the folly of his venture,
of his paper's great misgiving.
Of his obvious omissions,
of his great misunderstandings,
of his utter lack of vision,
of his blatant plagiarism.
(This last point he found most galling,
found it really quite dumbfounding,
since for prior art, he'd listed
ninety-three related papers.)
Now the mighty Hiawatha,
in his office still is sitting,
contemplating on his research,
thinking on his chosen topic.
Wondering, in idle moments,
if he had not chosen wrongly,
the position he had taken
as a research paper author
And he thinks, my Hiawatha,
if he might not have been better
served by a more lowly station,
as a cashier at McDonalds,
as a washer at the car wash,
as a cleaner of the bathrooms.
Thus departs my Hiawatha.

@_date: 2004-05-10 03:03:56
@_author: Jason Holt 
@_subject: chaum's patent expiry? (Re: Brands' private credentials) 
I think it's June 2005.  Actually, now that you mention Chaum, I'll have to
look into blind signatures with the B&F IBE (issuing is just a scalar*point
multiply on a curve).  That could be a way to get CA anonymity for hidden
credentials - just do vanilla cut and choose on blinded pseudonymous
credential strings, then use a client/server protocol with perfect forward
secrecy so he can't listen in.  Hm, I'll have to think it out.

@_date: 2004-05-10 18:45:56
@_author: Jason Holt 
@_subject: blinding & BF IBE CA assisted credential system (Re: chaum's 
Well, he can always generate private keys for any pseudonym, just as in cash
systems where the bank can always issue bank notes.  Here's what I'm
suggesting, where "b" is a blinding function and n1... are random nyms:
Alice              FBI TTP
<---cut & choose: n1,n3
(Alice unblinds and now has a credential for nym n2)
So it's vanilla Chaum-style blinded credentials.  The FBI signs Alice's agent
cred without learning the nym.  Alice can use the nym, and the server can ask
the FBI the attributes (agent? chief? secretary?) of the person with the nym,
but the FBI won't know.  The FBI could eavesdrop on Alice's connection and
generate whatever creds are necessary to read the resource Bob sends her, but
that's why I was talking about building it in a protocol with PFS.
But now that I think of it, PFS isn't really necessary at all for Alice&Bob to
have a conversation where their policies are respected:
Alice                                         Bob
(Alice generates random nonce na)
HC_E(na, "Bob:agent", FBI)--->
                         (Bob generates random nb)
                 <---HC_E(nb, "Alice:member", NRA)
Both generate session keys from Hash(na,nb).
So, Alice wants to connect iff Bob's FBI, and Bob wants to talk iff Alice is
in the NRA, where "Alice" and "Bob" are random pseudonyms.  Thus they send
their random nonces na and nb encrypted against those creds (HC_E is a hidden
cred encrypt), then use those nonces for the session keys.
The FBI can *always* impersonate an agent, because, well, they're the CA and
they can make up pseudonymous agents all day long. But in this protocol, I
believe they wouldn't be able to be a MITM and/or just eavesdrop on Alice&Bob.  That's because Bob only wants to talk to NRA members, and the FBI can't
impersonate that.
Now, this is for an interactive session, rather than just sending a single
request/response round like I discuss in the paper.  But even then, policies
are always respected.  Just change "na" to "request" and "nb" to "response".  Alice's policy is respected whether she talks to FBI-authorized-Bob or
FBI-authorized-FBI, and the FBI doesn't get to read Bob's NRA-Alice-only

@_date: 2004-05-10 20:02:12
@_author: Jason Holt 
@_subject: Brands' private credentials 
Yep, that'd be a problem in that case.  In the most recent (unpublished)  paper, I addressed that by using R as the key for a ciphertext+MAC on the
actual message.  So the server would have to find two R's that both satisfy
the MAC but produce different ciphertexts in order to learn anything from the
In either case, though, you can't just trust that the server encrypted against
"patient OR doctor" unless you have both creds and can verify that they each
recover the secret.  They might be lying about the "doctor" part, and really
sending against "patient OR nonexistant", in which case your response reveals
that you're a patient.  That's why we recommend that your response (if any)
include the policy for the creds you used in decryption.  So if Alice is
responding to a message she decrypted with her "patient" cred, which she only
(implicitly) discloses to Medicare, and the response itself is only for AIDS
clinics, she should encrypt against "Medicare AND AIDS_clinic".
(And you're right, the AIDS example is not very compelling.  The slides give a
better one about FBI agents, but I'm still looking for other examples of
super-sensitive transactions where HCs would fit)
That's very slick.  I'll check it out.
Hugo Krawczyk gave a great talk at Crypto about the going-first problem in
IPSec, which is where I got the phrase.  He has a nice compromise in letting
the user pick who goes first, but for some situations I think hidden
credentials really would hit the spot.
Yeah, although I think most of them would require an on-line trusted server.  But that just makes all sorts of things way too easy to be interesting. :)

@_date: 2004-05-10 22:37:15
@_author: Jason Holt 
@_subject: more hiddencredentials comments (Re: Brands' private credentials) 
I don't quite get what you're suggesting.  Could you give a more concrete
example?  Well, I wouldn't complain. :)  (Although pairings are quite slow, on the order
of hundreds of milliseconds.)  Hilarie Orman presented it at an IETF meeting
to what was reportedly a lukewarm response, and they also raised the patent
issue.  Dan Boneh is sensitive to the issue of patented crypto, and was quite
considerate when I asked about it, but  still has the same
vague statement in their FAQ about how they're not going to be evil with the
patent, so it's still up in the air whether IBE will be useful in IETF

@_date: 2004-05-11 21:10:35
@_author: Jason Holt 
@_subject: who goes 1st problem 
[Adam and I are taking this discussion off-list to spare your inboxes, but
this message seemed particularly relevant.  Perhaps we'll come back later if
we come up with anything we think will be of general interest.]
Agreed.  Ninghui Li's RSA OSBEs might be the answer; they're not quite as
elegant as the IBE version, but they work with blinded RSA signatures, and so
should be patent-free by next year, assuming Ninghui doesn't seek any patents.  Section 4 of his PODC paper describes the RSA implementation.  He also has a
new paper which does neat things with commitments that I haven't wrapped my
mind around yet.
Actually, we might also consider contacting Dan Boneh at some point; he seems
to be interested in the proliferation of IBE, and might be sympathetic to the
needs of the IETF to have free standards, especially considering the exposure
it'd get for his system.
However, we need to define just what we need to accomplish.  Since my lab
works in trust negotiation, we think in terms of policies a lot, whereas SSL
just assumes you know what certs you want to send to whom.  But let's assume
the SSL model for simplicity.
The second issue, now that I think of it in this context, would be how you
actually get your certs to the other guy.  Hidden credentials, as Ninghui
pointed out, assume you have some means for creating the other guy's cert,
eg., a template "(nym):Senior_Agent:(current year)" producing
The OSBE paper, OTOH, assumes we're going to exchange our certificates, just
without the CA signatures.  Then I can send you messages you can only read if
you really do have a signature on that cert.  But I've always thought that was
problematic, since why would honest people bother to connect then use fake
certs?  The attacker doesn't need to see the signature - he believes you.  So
honest users would need to regularly give out fake certs so they can hide
their legit behavior among the fake connects.  Will Winsborough also suggests
this with the notion of ACK policies - you *always* give people something they
ask for, so they can't tell what you have and what you don't.
So maybe what we really want is some sort of fair exchange or something, where
I can show you my valid certs as you show me the valid certs of your own.  If one side is guessable, we've discussed this sort of thing with hidden
E("Hi Bob, since you're a senior agent, you can see my agent credential:
'Alice:Denver field office agent (apprentice):2004",
E("Hi Bob, since you're a BYU alumnus, you can see my BYU credential:
'Alice:Senior:computer science:3.96 gpa:2004",
So that's an open problem.  But let's assume guessable-certs, since that's the
only way I know how to really keep certs and policies safe for now. The
OSBE-RSA math still works.  So we're good so far, except that the RSA approach
is interactive.  Section 4 says that in the RSA scheme, Alice sends her cert
can send back an encrypted message.  (In HC and IBE-OSBEs, Bob doesn't need
the blinded signature to use as a public key).
But maybe Robert's improved secret sharing scheme from the new HC paper can give us some ideas:
1. Alice sends blinded signatures for each of her relevant certs, not
revealing which signature goes with each cert, and not revealing the cert
2. Bob generates the contents of each of Alice's certs relevant to his policy,
and simply generates each possible combination of hash-of-cert-contents and
blinded-signature.  One from each row will be a match-up between contents and
signature, and Alice will have to figure out which.  Unfortunately, this
requires n^2 multiplies and exponentiations.

@_date: 2004-09-07 23:41:43
@_author: Jason Holt 
@_subject: MD2 is not one way (!?) 
The list of accepted papers for AsiaCrypt:
Includes one titled "The MD2 Hash Function is Not One-Way".  That's the first
I've heard about MD2; the other breaks were for md4 and md5.  Anyone know

@_date: 2005-08-04 20:22:54
@_author: Jason Holt 
@_subject: Query about hash function capability 
I don't have a formal reference for you, but this seems intuitively correct to me: put the strings in a canonical form so that all equivalent strings reduce to the same string, then hash conventionally.  Eg., for rotation, the canonical form of a string is the rotation which gives the smallest value when the string is considered a binary number.  In other words, alphabetize all the rotations and then take the first one.
 					-J

@_date: 2005-12-13 07:41:18
@_author: Jason Holt 
@_subject: crypto wiki -- good idea, bad idea? 
Also check out the Cryptography Reader:
"Matt Crypto" set up an "article (to clean up) of the day" replete with a bar graph of how "done" he thinks it is.
As to accuracy, there are several authors I respect who keep many of the crypto articles on their watchlists, so that we notice when people make I'm quite happy with a number of the pages in the reader, enough that I point my students to them and use the figures in my lecture slides.  I like the intersecting planes in the "secret sharing" article particularly:
An old wikipedia saying is "be bold in updating pages":  						-J

@_date: 2005-12-13 08:01:35
@_author: Jason Holt 
@_subject: another feature RNGs could provide 
Rich Schroeppel tells me his "Hasty Pudding" cipher can be used to create PRPs (pseudorandom permutations) of arbitrary size.  It even has the ability to let you define external functions to help define set membership (for sets which aren't just composed of the natural numbers).
 						-J

@_date: 2005-07-01 21:36:47
@_author: Jason Holt 
@_subject: /dev/random is probably not 
You may be correct, but readers should also know that, at least in Linux:
   * All of these routines try to estimate how many bits of randomness a
   * particular randomness source.  They do this by keeping track of the
   * first and second order deltas of the event timings.
And then the inputs are run through a SHA hash before being released through   							-J

@_date: 2005-07-11 21:37:36
@_author: Jason Holt 
@_subject: New Credit Card Scam (fwd) 
I remember the first time a site asked for the number on the back of my credit card.  It was a Walmart or Amazon purchase, and with no warning they redirected me to some site with a questionable domain. I thought for sure my session was being hijacked, and my bank had given me no idea what the number was for or whether it was something I was supposed to give out.
To me, this is closely related to the discussions we have here about web browser security semantics.  With a very good understanding of the underlying PKI, we can usually sort out "secure" from "suspicious" site behaviors with some discussion, but how is the average user (or even the average engineer) supposed to cope?  Is there a standard or even just a document somewhere that defines best practices for both server and user behavior with respect to SSL web sites and credit card transactions?  Or are we leaving them to forward emails to each other warning them not to give out their 3-digit codes over the phone, and that they had better make sure their Dell doesn't have a DHS keylogger installed...
 							-J
---------- Forwarded message ----------
I got this from a co-worker today:
  Apparently, they don't ask for your number, just the 3 digit code on the
back. They'll tell you they're calling from your Visa or Mastercard company
and that they're trying to verify whether or not you've made a $497.99
purchase from a company in Arizona or something. They'll tell you to call
your credit card company if you have any questions, etc, and they never ask
for your card number, so it sounds pretty legit, but it's not. If it does
happen to you, within a few minutes of the phone call you'll have a charge
for $497.99 on your card. You can always call the credit card company
yourself and make sure they're the ones wanting to check about fradulent
charges, so if you get a call that sounds fishy, just tell them you'll call
them back at the number on your card.

@_date: 2005-07-12 01:01:05
@_author: Jason Holt 
@_subject: New Credit Card Scam (fwd) 
You dismiss too much with your "just".  They already do attack plenty of sites, but they also phish because it has a larger return on investment. Security is the process of iteratively strengthening the weakest links in the  					-J

@_date: 2005-06-09 02:04:39
@_author: Jason Holt 
@_subject: encrypted tapes (was Re: Papers about "Algorithm hiding" ?) 
Well, yes.  TLS guarantees that you're talking to the website listed in the location bar.  Knowing what domain you *wanted* is up to you, and Dan handles that by suggesting that perhaps you have a paper brochure from the bank which lists their domain.
So, it's fine to have  link to  (or whatever.com) for forms requesting anything sensitive as long as amex.com (or whatever.com) is what's printed in the brochure.  As Dan points out, examination of the certificate is generally pointless as long as it's signed by a trusted CA, since the attacker can get a perfectly valid cert for hackers-r-us.com anyway.  The big question is just whether the domain asking for your account info corresponds with the organization you trust with it.
Of course, brochures aren't exactly hard to spoof (cf. Verisign's fraudulent domain renewal postcards).  And then there are the dozens of CAs your browser accepts, the CA staff who issue microsoft.com certs to random passersby, international domain names that look identical to, er, national ones.  All those gotchas apply even in the "correct" implementation outlined by Dan.
 						-J

@_date: 2005-06-09 02:11:45
@_author: Jason Holt 
@_subject: encrypted tapes 
If in-transit attacks are the real problem, just email/fax/phone the key when you ship the tapes, and have them stick it in the box when it arrives.
 						-J

@_date: 2005-06-13 19:01:37
@_author: Jason Holt 
@_subject: Digital signatures have a big problem with meaning 
Now there's an ironic counterargument.  I wrote a pure perl SSL implementation a while back, but ultimately had to shell out to openssl for the X.509 parsing because it was more complicated than SSL itself, and was poorly documented to boot.  Niels Ferguson also trashes it in Practical Cryptography.
I have friends in ecommerce who consider XML such a tar pit that they're reluctant to even hire people who think it's a good idea.  So it's easy for me to believe Peter when he says that they're problematic for crypto.
 					-J

@_date: 2005-03-08 18:11:29
@_author: Jason Holt 
@_subject: comments wanted on gbde 
What would you consider an ideal key management solution for disk encryption,
then?  It seems like any passphrase-based system will be
dictionary-attackable, even with strengthening techniques like iteration,
which provide a linear increase in difficulty to both normal use an attack.  Is that all you were asking for, or are you thinking of token (or network)  based solutions which can handle better keys than the average human?  (Or, are
there other more exotic techniques which make passphrases harder to break?)

@_date: 2005-11-07 20:38:35
@_author: Jason Holt 
@_subject: gonzo cryptography; how would you improve existing cryptosystems? 
Take a look at ecryptfs before rewriting cfs:
 					-J

@_date: 2005-11-23 08:55:11
@_author: Jason Holt 
@_subject: Web Browser Developers Work Together on Security 
Core KDE developer George Staikos recently hosted a meeting of the security developers from the leading web browsers. The aim was to come up with future plans to combat the security risks posed by phishing, ageing encryption ciphers and inconsistent SSL Certificate practise. Read on for George's report of the plans that will become part of KDE 4's Konqueror and future versions of other web browsers.
In the past few years the Internet has seen a rapid growth in phishing attacks. There have been many attempts to mitigate these types of attack, but they rarely get at the root of them problem: fundamental flaws in Internet architecture and browser technology. Throughout this year I had the fortunate opportunity to participate in discussions with members of the Internet Explorer, Mozilla/FireFox, and Opera development teams with the goal of understanding and addressing some of these issues in a co-operative manner.
Our initial and primary focus is, and continues to be, addressing issues in PKI as implemented in our web browsers. This involves finding a way to make the information presented to the user more meaningful, easier to recognise, easier to understand, and perhaps most importantly, finding a way to make a distinction for high-impact sites (banks, payment services, auction sites, etc) while retaining the accessibility of SSL and identity for smaller In Toronto on Thursday November 17, on behalf of KDE and sponsored by my company Staikos Computing Services, I hosted a meeting of some of these developers. We shared the work we had done in recent months and discussed our approaches and strengths and weaknesses. It was a great experience, and the response seems to be that we all left feeling confident in our direction moving forward. There was strong support for the ideas proposed and I think we'll see many of them released in production browsers in the near future. I think we were pleasantly surprised to see elements of our own designs in each other's software, and it goes to show how powerful our co-operation can be.
The first topic and the easiest to agree upon is the weakening state of current crypto standards. With the availability of bot nets and massively distributed computing, current encryption standards are showing their age. Prompted by Opera, we are moving towards the removal of SSLv2 from our browsers. IE will disable SSLv2 in version 7 and it has been completely removed in the KDE 4 source tree already.
KDE will furthermore look to remove 40 and 56 bit ciphers, and we will continually work toward preferring and enforcing stronger ciphers as testing shows that site compatibility is not adversely affected. In addition, we will encourage CAs to move toward 2048-bit or stronger keys for all new roots.
These stronger cryptography rules help to protect users from malicious cracking attempts. From a non-technical perspective, we will aim to promote, encourage, and eventually enforce much stricter procedures for certificate signing authorities. Presently all CAs are considered equal in the user agent interface, irrespective of their credentials and practices. That is to say, they all simply get a padlock display when their issued certificate is validated. We believe that with a definition of a new "strongly verified" certificate with a special OID to distinguish it, we can give users a more prominent indicator of authentic high-profile sites, in contrast to the phishing sites that are becoming so prevalent today. This would be implemented with a significant and prominent user-interface indicator in addition to the present padlock. No existing certificates would see changes in the browser.
To explain what this will look like, I need to take a step back and explain the history of the Konqueror security UI. It was initially modeled after Netscape 4, displaying a closed golden padlock in the toolbar when an SSL session was initiated and the certificate verification project passed. The toolbar is an awful place for this, but consistency is extremely important, and during the original development phase of KDE 2.0, this was the only easy way to implement what we needed. Eventually we added a mechanism to add icons to the status bar and made the status bar a permanent fixture in browser windows, preventing malicious sites from spoofing the browser chrome and making the security icon more obvious to the user. In the past year a padlock and yellow highlight were added to the location bar as an additional indication. This was primarily based on FireFox and Opera.
I was initially resistant to the idea of using colour to indicate security - especially the colour yellow! However the idea we have discussed have been implemented by Microsoft in their IE7 address bar, when I saw it in action I was sold. I think we should implement Konqueror the same way for KDE4. It involves the following steps:
    1. The location toolbar becomes a permanent UI fixture along with the status bar
    2. The padlock goes into the location combo-box permanently, is the only place it appears, and the location bar stays white by default
    3. When verification on a site fails, the location bar is filled in red
    4. When a high-assurance certificate is verified, the location bar is filled in green, the organisation name is displayed beside the padlock, and it rotates displaying the name of the CA
I am afraid that the missing yellow will confuse our users, but at the same time I think it was misguided to add the yellow when it was added, and I think this is the price we must pay. Hopefully users will be able to adjust quickly, and KDE4 is the right time to do it. The existence of the padlock and extended identity information makes it safe even for those who have difficulty distinguishing colours.
One more key item that Microsoft is implementing is their anti-phishing plug-in. I hope that Microsoft will be open with this system and allow us to write our own Konqueror plug-in, allowing our users to contribute to their database and take advantage of it. I think this is in everyone's best interest. Microsoft says that they are not evangelising the anti-phishing service to other clients at this time but they are "working with the community on the issue through many avenues and groups, such as the Anti-Phishing Working Group and Digital PhishNet". They didn't rule out the potential to open up their client technology in the future. They suggested that others interested in offering similar technologies could take their own approaches and work with the same industry data providers that they use.
I'm very optimistic about the future of co-operation among browser developers and I hope this recent work signals a new trend of good relations. Together we can really create some amazing new technology and make it possible to solve some of the major problems we face today.

@_date: 2005-10-02 00:13:02
@_author: Jason Holt 
@_subject: nym-0.2 released (fwd) 
As the great Ulysses said,
   Pete, the personal rancor reflected in that remark I don't intend to dignify
   with comment. However, I would like to address your attitude of hopeless
   negativism.  Consider the lilies of the g*dd*mn field...or h*ll, look at
   Delmar here as your paradigm of hope!
   [Pause] Delmar: Yeah, look at me.
Okay, so maybe there's no personal rancor, but I do detect some hopeless negativism.  Or perhaps it's unwarranted optimism that crypto-utopia will be here any moment now, flowing with milk and honey, ecash, infrastructure and multi show zero knowledge proofs.  Maybe I just need a disclaimer: "Warning: this product favors simplicity over crypto-idealism; not for use in Utopia." Did I mention that my code is Free and (AFAIK) unencumbered?
The reason I have separate token and cert servers is that I want to end up with a client cert that can be used in unmodified browsers and servers.  The certs don't have to have personal information in them, but with indirection we cheaply get the ability to enfore some sort of structure on the certs. Plus, I spent as much time as it took me to write *both releases of nym* just trying to get ahold of the actual digest in an X.509 cert that needs to be signed by the CA (in order to have the token server sign that instead of a random token).  That would have eliminated the separate token/cert steps, but required a really hideous issuing process and produced signatures whose form the CA could have no control over.  (Clients could get signatures on IOUs, delegated CA certs, whatever.)
(Side note to Steve Bellovin: having once again abandoned mortal combat with X.509, I retract my comment about the system not being broken...)
Sure, there's no reason for one entity not to run all three services; we're only talking about 2 CGI scripts and a web proxy anyway.  Or, run a CA which serves multiple token servers, and issues certs with extensions specifying what kinds of tokens were "spent" to obtain the cert.  Then web servers get articulated limiting from a single CA's certs.
It buys not having to strap hacked-up code onto your web browser or server. Run the perl scripts once to get the cert, then use it with any browser and any server that knows about the CA.
Great, you guys work up an RFC, then an IETF draft, then some Idemix code with all the ZK proofs.  In the meantime, I'll be setting up my 349 lines of perl/shell code for whoever wants to use it.  Whoops, I forgot the IP-rationing code; 373 lines.
Actually, if all you want is complaint-free certifications, that's easy to put in the proxy; just make it serve up different identifiers each time and keep a table of which IDs map to which client certs.  Makes it harder for the wikipedia admins to see patterns of abuse, though.  They'd have to report each incident and let the proxy admin decide when the threshold is reached.
There's that hopeless negativism again.  Do you want a real solution or not? Because I can think of at least 2 ways to solve that problem in a practical setting, and that's assuming that your assumption about MediaWiki being limited to 4-byte identifiers is even correct.
Sure.  I always meant for the gateway to exit on a public IP address.  The reason to make it a hidden service is to keep n00bs from forgetting to turn on tor when they talk to the proxy.  Thanks for clarifying, though.
 							-J

@_date: 2005-10-02 02:14:38
@_author: Jason Holt 
@_subject: nym-0.2.1 released (live demo available) 
I now have a live server available for those of you who want to play with a "real" nym tokenserver/CA/webserver.  This process constitutes running three scripts and installing the client cert.  Details in the README:
(Please be nice to erg.no-ip.org).
If enough people email me privately after trying it out, I'll proceed to the next phase, which will be working with the wikipedia guys to create a proxy server which should enable tor users to anonymously contribute but allow admins to block misbehaving IPs.
 					-J

@_date: 2005-10-02 22:23:50
@_author: Jason Holt 
@_subject: nym-0.2 released (fwd) 
Hopeless negativism.  I limit by IP because that's what Wikipedia is already doing.  Sure, hashcash would be easy to add, and I looked into it just last night.  Of course, as several have observed, hashcash also leads to whack-a-mole problems, and the abuser doesn't even have to be savvy enough to change IPs.
Why aren't digital credential systems more widespread? As has been suggested here and elsewhere at great length, it takes too much infrastructure. It's too easy when writing a security paper to call swaths of CAs into existance with the stroke of the pen.  To assume that any moment now, people will start carrying around digital driver's licenses and social security cards (issued in the researcher's pet format), which they'll be happy to show the local library in exchange for a digital library card.
That's why I'm so optimistic about nym. A reasonable number of Tor users, a technically inclined group of people on average, want to access a single major site. That site isn't selling ICBMs; they mostly want people to have access anyway. They have an imperfect rationing system based on IPs. The resource is cheap, the policy is simple, and the user needs to conceal a single attribute about herself. There's a simple mathematical solution that yields certificates which are already supported by existing software. That, my friend, is a problem we can solve.
I like the idea of requiring combinations of scarce resources. It's definitely on the wishlist for future releases.  Captchas could be integrated as well.
Thanks for pointing that out! Shouldn't be hard to fix.
Oh, I think I see. The k-smooth sha1(r) values then become "bonus" tokens, so we use a large enough h() that the result is too hard to factor (or, I suppose we could make the client present properly PKCS padded preimages).  I'll do some more reading, but I think that makes sense.  Thanks!
 						-J

@_date: 2005-10-03 11:02:54
@_author: Jason Holt 
@_subject: Hooking nym to wikipedia 
Thanks to everyone who has contributed feedback, cyphrpunk in particular. Here are my thoughts on connecting nym to wikipedia.  I'll take feedback here first, then approach the WikiMedia folks.
* I believe the best solution would be for wikipedia to do the following:
   - Run an SSL server (optionally using a self-signed cert) which requires
     client certificates.  This is a 4-line addition to the httpd.conf.
   - Apache (already) automatically sets an environment variable identifying
     the client certificate used.  MediaWiki would map this to a random state
     variable equivalent to its IP identifier.
   - When admins wish to block an "IP", they follow the usual procedure, which
     has a special case for the special identifiers which adds the
     corresponding cert to a CRL instead of modifying the IP blacklist.  The
     client will no longer be able to connect to the SSL server.
   - Optionally, wikipedia can also send its list of perma-banned IPs to the
     (externally operated, but wikipedia-specific) token server, which will
     then refuse to serve those IPs.
* Alternatives to this approach involve someone else setting up such an SSL server as a reverse proxy for en.wikipedia.org and communicating a special identifier to wikipedia along with the proxied data in some combination of HTTP headers and cookies. I quite like the simplicity of these approaches, which could also allow avoiding certificates entirely by allowing users to trade a token directly for a cookie.  But now the header/cookie is subject (on the proxy->wikipedia link in particular) to eavesdropping, forgery and all the other things SSL is designed to prevent.  So ideally, wikipedia would allow an SSL connection from the proxy, and might as well just accept the client certs or tokens directly.  Also, if we eliminate certs, tokens would then have to be kept around and treated as secrets in case the user needs to get cookies issued onto other browsers or refreshed when a browser chooses to delete the cookie. Certs, OTOH, have a public cert that can be passed around, and come in a standardized file that has browser-supported passphrase en/decryption * Incidentally, making my apache-ssl (1.3) server reverse-proxy (impersonate, essentially) en.wikipedia.org is ridiculously simple.  In the httpd.conf:
   # Inside the  block:
         ProxyRequests Off
         ProxyPass /          ProxyPassReverse / And in the modules.conf:
   LoadModule proxy_module /usr/lib/apache/1.3/libproxy.so
 							-J
(Side note to Damian Gerow: our mail servers refuse to talk to each other; my admin claims pandora.afflictions.org is reporting its IP as 10.9.22.67 (an unroutable IP), which makes a validity test fail.  We'll have to find a side

@_date: 2005-10-03 11:48:48
@_author: Jason Holt 
@_subject: Hooking nym to wikipedia 
More thoughts regarding the tokens vs. certs decision, and also multi-use:
* Client certs are a pain to turn on and off.  If you select "ask me every time" before sending a client cert, you have to click half a dozen "OK"s per page.  (This could be mitigated by having Wikipedia only use the SSL server for edits, since they're not blocking article viewing anyway, just editing.) If you tell the browser to send the certificate automatically and then forget about it, other SSL sites can silently request it, which is particularly bad if you're not using tor just then.
* Using tokens directly at site login time avoids the client cert hassles. However, evil web servers could then collect tokens (nyms) for use at other sites, suggesting that each server should run its own token server.  But now each server has a (potentially short) list of client IPs, whereas a centralized token server would provide better concealment.  Obviously, if wikipedia is the only site that ever bothers to use nym, this is a moot point.
* Lack of forward secrecy is indeed an issue, since our metaphorical Chinese dissident must keep around her cert to continue using it, which if discovered links her with all her past activities.  This is a problem even if Wikipedia maps each client cert to a particular random value for public display, since the attackers can simply use the stolen cert to make an edit on wikipedia and then check to see if the identifier comes up the same.
If Wikipedia generates a new random ID for each edit, then attackers have to access Wikipedia internals to map the IDs back to the cert, but then, so do Wikipedia admins when they want to assess a user's pattern of (bad) behavior. Note that SSL does not (IIRC) encrypt certificates, so a passive network eavesdropper can associate client certs with the random IDs.  (Do the ephemeral modes hide the certs?)
A related approach that thwarts the network eavesdropper would be to issue a series of certificates which expire one per interval (hour/day/whatever, trading privacy against the hassle of managing lots of certs).  Then our dissident uses each cert in turn, securely deleting it after it expires.  The CA keeps a list recording all the certs issued to the same user, and when Wikipedia wishes to ban a user, the CA revokes all the unexpired certs for that user.  The CA also securely deletes expired certs from its lists, so that if compromised, it has merely the same list of certs found on the client machine, and is likewise devoid of any reference to certs used in prior Of course, there are nifty cryptographic solutions to the problem of revoking repeat offenders without linking activities of good users.  Private Credentials and Idemix are the two best known examples, but both are complicated and patent-ridden.
 							-J

@_date: 2005-10-03 12:58:28
@_author: Jason Holt 
@_subject: Hooking nym to wikipedia (fwd) 
Reply-To: or-talk at freehaven.net
Hi Jason et al,
You might want to have a look at our UST (Unlinkable Serial Transactions)
It was published in ACM TISSEC
(or .ps)
There was also an earlier version published at Financial Crypto.
(It lacks the proofs and some improvements to the protocols)
(or .ps)
1. I think it is much less complicated than the other things you raised,
    but of course has other tradeoffs.
2. The papers are it. There is no current code worth looking at.
3. Thanks for the reminder. It too is patented if not patent-ridden,
    but we should be able to cope with that. Basically you shouldn't put
    huge work in assuming that there are no encumbrances to address, but if
    you are interested given 1 and 2 after you look at it, let me
    know. I can then explain the issues regarding the patent situation.

@_date: 2005-10-21 09:25:51
@_author: Jason Holt 
@_subject: nym-0.4 released (now includes Javascript) (fwd) 
Reply-To: or-talk at freehaven.net
The most notable feature in this release of nym is that you can now use nym entirely from your web browser:
Until someone figures out how to create client certificate requests in Javascript, the CA will have to do so instead (or, you could generate the request on a separate machine and paste it in with a trivial hack).  This means the CA will know your certificate's private key; this is bad if you want to make sure you can never be impersonated.  It's actually good if you want deniability, since you can always claim that the CA chose to impersonate you.
There are other miscellaneous bugfixes which break compatibility with earlier Sources (including the javascript client) are available here, as always:
 					-J

@_date: 2005-09-12 00:08:47
@_author: Jason Holt 
@_subject: Clearing sensitive in-memory data in perl 
Securely deleting secrets is hard enough in C, much less high level languages. I've often considered trying to write a C-based module for secret storage, but it's problematic (although the Taint stuff looks promising) and to my knowledge has never been done.
 							-J

@_date: 2005-09-28 06:19:58
@_author: Jason Holt 
@_subject: PKI too confusing to prevent phishing, part 28  
Once we have a better solution to the problem, I'll agree. But in the meantime, I'd say the problem is mismatched expectations.  OS manufacturers have convinced the public that home computers don't require trained administrators, and in my experience this just isn't true. Likewise, it's easy to drive a car, but training is generally required to drive a car safely, and lots of people still get hurt doing it.
Your statement is a good way to recognize an Elegant solution to a problem, but some problems don't yet have Elegant solutions, and sometimes the Elegant solution to a problem isn't practical.
 						-J

@_date: 2005-09-29 01:51:32
@_author: Jason Holt 
@_subject: Pseudonymity for tor: nym-0.1 (fwd) 
Per the recent discussion regarding tor and wikipedia, I've hacked together an implementation of the basic system from Chaum, Fiat and Naor's 1990 "Untraceable Electronic Cash" paper.  This system allows CAs to blindly issue tokens (or "coins") which can then be "spent" elsewhere.  It runs in perl, and comprises a CA, nym-maker, client application and auth checker (for the The tarball is here:
Of course, it's useless at the moment since it gives out tokens indiscriminately (and probably has massive bugs), but if anyone actually cares about this idea, it will be (more or less) easy to do the following:
* Put up a sample CA and server that people can use (potentially as hidden * Make the CA issue only one token per email address, or one token per IP address, one per computational puzzle, one for every $20 mailed in...
* Automatically expire CA keys and generate new ones on a regular basis (rather than bothering with CRLs)
* Instead of randomly generated tokens, have the CA sign an actual X.509 cert request, which will then become a perfectly valid X.509 cert useful as a client-side cert in unmodified browsers and web servers
* Create some sort of aid for maintaining server-side (or CA) blacklists of improperly behaving users
* Check to see if the protocol is actually still secure and properly Comments welcome.
 						-J

@_date: 2005-09-29 23:32:24
@_author: Jason Holt 
@_subject: Pseudonymity for tor: nym-0.1 (fwd) 
Actually, it was just the closest paper at hand for what I was trying to do, which is "nymous accounts", just as you say.  So I probably shouldn't have referred to "spending" at all.
My thinking is that if all Wikipedia is trying to do is enforce a low barrier of pseudonymity (where we can shut off access to persons, based on a rough assumption of scarce IPs or email addresses), a trivial blind signature system should be easy to implement.  No certs, no roles, no CRLs, just a simple blindly issued token.  And in fact it took me about 4 hours (while the conversation on or-talk has been going on for several days...)
There are two problems with what I wrote. First, the original system is intended for cash instead of pseudonymity, and thus leaves the spender a disincentive to duplicate other serial numbers (since you'd just be accused of double spending); this is a problem since if an attacker sees you use your token, he can get the same token signed for himself and besmirch your nym. And second, it would be a pain to glue my scripts into an existing authentication Both problems are overcome if, instead of a random token, the client blinds the hash of an X.509 client cert.  Then the returned signature gives you a complete client cert you can plug into your web browser (and which web servers can easily demand).  Of course, you can put anything you want in the cert, since the servers know that my CA only certifies 1 bit of data about users (namely, that they only get one cert per scarce resource).  But the public key (and verification mechanisms built in to TLS) keeps abusers from being able to pretend they're other users, since they won't have the users' private keys.
The frustrating part about this is the same reason why I'm getting out of the credential research business.  People have solved this problem before (although I didn't know of any Free solutions; ADDS and SOX are hard to google -- are they Free?).  I even came up with at least a proof of concept in an afternoon.  And yet the argument on the list went on and on, debating the definitions of anonymity and identity, and accusing each other of anarchy and tyranny.  We go round and round when we talk about authentication systems, but never get off the merry-go-round.
Contrast that with Debevec's work at Berkeley; Ph.D in 1996 on "virtual cinematography", then The Matrix comes out in 1999 using his techniques and revolutionizes action movies.  Sure, graphics is easier because it doesn't require everyone to agree on an /infrastructure/, but then, neither does the tor/wikipedia problem.  I'm grateful for guys like Roger Dingledine and Phil Zimmerman who actually make a difference with a privacy system, but they seem to be the exception, rather than the rule.
So thanks for at least taking notice.
 						-J

@_date: 2005-10-01 02:18:55
@_author: Jason Holt 
@_subject: nym-0.2 released (fwd) 
nym-0.2 is now available at:
My tor server is currently down, so I can't set up a public trial of this, but perhaps someone else will.  This release makes the following improvements:
* Tokens are now issued one-per-IP to clients via a "token" CGI script. Tokens are still blindly issued, so nobody (including the token issuer) can associate tokens with IP addresses.  The list of already-served IPs could be periodically removed, allowing users to obtain new pseudonyms on a regular basis.  (Abusers will then need to be re-blocked assuming they re-misbehave).
* A token can be used to obtain a signature on a client certificate from a separate "CA" CGI script (potentially on a different machine).  Tokens can only be "spent" to obtain one cert.  Code to make a CA, client certs and have the certs signed is included.
* The CA public key can be installed on a third web server (or proxy) to require that users have a valid client certificate.  Servers can maintain a blacklist of misbehaving client certs.  Misbehavers will then be unable to access the server until they obtain a new token and client cert (via a new IP).
My proposal for using this to enable tor users to play at Wikipedia is as 1. Install a token server on a public IP.  The token server can optionally be provided Wikipedia's blocked-IP list and refuse to issue tokens to offending IPs.  Tor users use their real IP to obtain a blinded token.
2. Install a CA as a hidden service.  Tor users use their unblinded tokens to obtain a client certificate, which they install in their browser.
3. Install a wikipedia-gateway SSL web proxy (optionally also a hidden service) which checks client certs and communicates a client identifier to MediaWiki, which MediaWiki will use in place of the REMOTE_ADDR (client IP address) for connections from the proxy.  When a user misbehaves, Wikipedia admins block the client identifier just as they would have blocked an offending IP address.
 						-J

@_date: 2006-02-04 21:42:34
@_author: Jason Holt 
@_subject: EDP (entropy distribution protocol), userland PRNG design 
* /dev/random's output is limited by available entropy, not the speed of sha1. You want /dev/urandom instead.
* You're talking about a stream cipher, not a OTP, especially since an attacker could see the "plaintext" over the network and would only need to break the cipher to get at the "pad"
* It's dangerous to offhandedly propose stream ciphers, especially when we have some tried and tested ones, and it doesn't really make sense to use them as if they were OTPs, since then you get the benefits of neither
* Hash functions are comparably fast to ciphers anyway, and are plenty fast for the application you propose:
[jason at erg] ~$ openssl speed sha1
Doing sha1 for 3s on 16 size blocks: 1718543 sha1's in 2.99s
[jason at erg] ~$ dc
1718543 20 *p
So sha1 generates 34Mbyte/sec, which is enough to saturate a gigabit ethernet link in many installations.
 						-J

@_date: 2006-07-15 04:28:31
@_author: Jason Holt 
@_subject: Interesting bit of a quote 
My MS Thesis was on this topic:
If you store a value with a TTP (say, an auditor), and follow the protocol honestly, it's impossible to go back later and falsify records.  The symmetric version uses hash chains, and was invented several times before I came along.
 							-J

@_date: 2006-06-29 21:43:20
@_author: Jason Holt 
@_subject: Voice phishing 
Hi-tech fraudsters have begun using recorded telephone messages in a bid to trick users into handing over confidential account information. The tactic has been adopted as a variant of recently detected phishing attacks targeting customers of the Santa Barbara Bank & Trust.

@_date: 2006-06-30 03:37:36
@_author: Jason Holt 
@_subject: Use of TPM chip for RNG? 
Thanks for the useful summary!  For the sake of completeness, let me also add that RNGs in tamper-proof hardware are potentially rather controversial, since there are several known ways to produce output which looks very random to anyone who doesn't know some secret, but allows those who do to predict what future outputs will be.  I believe one straightforward way to do this would be to simply use a symmetric encryption function outputting "random" data blocks
r_i=Encrypt(key, r_(i-1))
If you don't know the secret key, the output will look at least somewhat random, but if you do, you can use any block to predict all subsequent and prior ones.  (This topic has been discussed in the literature, and my off-the-cuff example may not be particularly strong.)
I believe it's a fair summary to say that hardware RNG is a neat and useful feature, but may be unsuitable for the sufficiently paranoid when it comes in a tamper-proof package.
 						-J

@_date: 2006-03-08 22:26:55
@_author: Jason Holt 
@_subject: Paper summarizing new directions in protecting web users 
Amir will also be appearing next month in a panel I'm moderating on the challenges of practical web security at NIST's PKI conference.  Some of the discussions I've seen on this list led to the creation of that panel -- if we as cryptographers sometimes have to wrangle over what's considered trustworthy website behavior, how are users ever supposed to cope?
The standard flyer for that conference follows:
*** NO ON-SITE REGISTRATION!  Last day to register: March 17 ***
5th Annual PKI R&D Workshop at NIST in Gaithersburg, MD
"Making Cryptography Easy to Use"
April 4-6, 2006
Come join with experts from NIST, NIH, private industry and universities
around the world for our fifth workshop!
Scheduled topics include:
KEYNOTE ADDRESS
HAS JOHNNY LEARNT TO ENCRYPT BY NOW? Examining the troubled relationship
between a security solution and its users
Angela Sasse, University College London
REFEREED PAPERS:
-How Trust Had a Hole Blown In It.  The Case of X.509 Name Constraints
-Navigating Revocation through Eternal Loops and Land Mines
-Simplifying Credential Management through PAM and Online Certificate
-Identity Federation and Attribute-based Authorization through the Globus
Toolkit, Shibboleth, GridShib, and MyProxy
-PKI Interoperability by an Independent, Trusted Validation Authority
-Achieving Email Security Usability
-CAUDIT PKI Federation - A Higher Education Sector Wide Approach
INVITED TALKS:
-NIST Cryptographic Standards Status Report, Bill Burr, NIST
-Trust Infrastructure and DNSSEC Deployment, Allison Mankin, Consultant
-Integrating PKI and Kerberos, Jeffrey Altman, Secure Endpoints Inc.
-Enabling Revocation for Billions of Consumers, Kelvin Yiu, Microsoft
- Digital Signatures (Moderator: David Chadwick, University of Kent)
- Domain Keys Identified Mail (DKIM) (Moderator:  Barry Leiba, IBM)
- Browser Security User Interfaces: Why are web security decisions hard and
what can we do about it?
   (Moderator:  Jason Holt, Brigham Young University)
- Federal PKI Update (Moderator - Peter Alterman, National Institutes of
- Bridge-to-Bridge Interoperations (Moderator - Peter Alterman, National
Institutes of  Health)
WORKS IN PROGRESS (WIP)  (Contact Krishna Sankar (ksankar at cisco.com) if you
have additional WIP topics)
Potential topics:
-  CNRI handle system (brief overview)
-  International Grid Trust Federation
Complete agenda is available at

@_date: 2006-11-06 18:47:57
@_author: Jason Holt 
@_subject: Can you keep a secret? This encrypted drive can... 
Unless you have a disk array in your laptop, that performance is an artifact of buffering.  Here are unbuffered and buffered numbers for my rather new desktop machine:
$ hdparm -t /dev/sda
  Timing buffered disk reads:  174 MB in  3.01 seconds =  57.79 MB/sec
$ hdparm -T /dev/sda
  Timing cached reads:   5188 MB in  2.00 seconds = 2595.82 MB/sec
The 25MB/sec number for your encrypted partition looks like it's probably right, though:
$ openssl speed aes-256-cbc
The 'numbers' are in 1000s of bytes per second processed.
type             16 bytes     64 bytes    256 bytes   1024 bytes   8192 bytes
aes-256 cbc      52071.66k    55008.98k    55609.83k    55984.13k    55776.36k

@_date: 2007-05-14 15:37:48
@_author: Jason Holt 
@_subject: Enterprise Right Management vs. Traditional Encryption Tools 
ERM/DRM/TPM are such poorly defined and implemented products that people have started referring to a "DRM fairy" who people assume will wave her wand and solve whatever problem is at hand.  I used to try to draw out the mentioner's claims into a concrete proposal that everyone could objectively examine, but the conversation rarely progressed that far.  So now I think that, as with other crypto proposals, the onus should now be on the proposer to clearly delineate what they're proposing and convince us that it's complete and correct, rather than us nodding our heads or lashing out at what we assume it So I guess the answer to your question is "We'd better assume that DRM+TPM will be ineffective until we've subjected a specific implementation of it to the same level of scrutiny we apply to other cryptosystems, and since DRM+TPM proposals tend to be much more complicated than other cryptosystems like SSL, that's going to take a very long time."

@_date: 2008-01-02 21:26:47
@_author: Jason 
@_subject: Death of antivirus software imminent 
Yes, I wish that were pointed out more often.  Detecting viruses is a fundamentally losing battle: a sufficiently advanced virus can fully simulate a clean computer for the scanner to run in.
On the other hand, writing an OS that doesn't get infected in the first place is a fundamentally winning battle: OSes are insecure because people make mistakes, not because they're fundamentally insecurable.
Detecting spam by analysis of the text is another losing battle: even humans can't always agree on what's spam.
The maddening part is that security as an industry is almost always forced to fight on the losing battlefields, even though we've had beautiful, efficient, impregnable fortresses available for many years.  Any crypto book from 20 years ago can show you how to send an unforgeable email or sign a binary, yet these notions still haven't widely caught on (and when they have, as in the Xbox, they get hijacked for things like DRM and privacy invasion).

@_date: 2008-01-03 03:14:10
@_author: Jason 
@_subject: Death of antivirus software imminent 
You're painting with too broad a brush.  Creating artificial life failed; security just fails to get adopted.
Authentication is exactly what I need in the case of spam/phishing: did that really come from my bank?  Did it come from someone I've interacted with before?  Some people sign their messages automatically, some people's mail readers automatically check.  It works great for those who put in the effort.
And you gave examples of OS techniques which mitigate risks in buggy apps. Privilege escalation makes bad malware into horrible malware.
So good OS and crypto are important, and we've done good work in learning how to build them correctly.  You're right that they've failed in the marketplace, but economics and psychology were the motivating factors.  We just need to send our grad students over to those departments to figure out how to overcome those hurdles.

@_date: 2008-01-04 22:50:09
@_author: Jason 
@_subject: DRM for batteries 
Thanks to the DMCA anti-circumvention clause, your access control mechanism need not actually work.  This is fortunate (for them) given that in many contexts there doesn't actually exist something that could be expected to work.  So we let them, in effect, put a sticker on the side that magically increases the legal penalties for doing things they don't like.

@_date: 2009-01-20 22:13:56
@_author: Jason 
@_subject: [heise online UK] Secure deletion: a single overwrite will do 
I agree in general, although you still have to watch out for "reserve tracks" (search on this page):
"All hard disks have reserved sectors, which are used automatically by the drive logic if there is a defect in the media.":
Those could perhaps be used to smuggle data out of a wiped disk.  Or, if your disk firmware is (or someday becomes) clever enough to transparently swap out dying sectors with those from its reserved store, you could accidentally end up with data on the disk that dd would miss.
