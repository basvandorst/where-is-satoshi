
@_date: 2007-02-13 15:10:08
@_author: Ben Laurie 
@_subject: Failure of PKI in messaging 
Perfectly safe to use in the UK. But sorry, I forgot that only the US

@_date: 2007-02-15 18:24:11
@_author: Ben Laurie 
@_subject: see also credentica announcement about U-prove (Re: IBM donates 
Not sure about more general. Brands does claim they are more efficient,
though - however, Camenisch/Lysyanskya credentials have been improved
since they were first thought of, and are also a lot faster if you don't
insist on academic rigour. I have not yet put them side-by-side, but I
do have a partial implementation of C/L credentials for OpenSSL and am
planning a Brands implementation, too.

@_date: 2007-03-04 11:05:19
@_author: Ben Laurie 
@_subject: Cracking the code? 
That's a very dubious analysis. If the obfuscated password (I hesitate
to say encrypted in the face of an unknown algorithm) contains salt
(i.e. what you called an IV), then this technique will not work.
Of course, all good password obfuscators should include sufficient salt
that this attack doesn't work.

@_date: 2007-10-02 17:36:37
@_author: Ben Laurie 
@_subject: Linus: Security is "people wanking around with their opinions" 
This will be in sharp contrast to kernel design, where its just one
person wanking around with their opinions. :-)

@_date: 2007-10-12 12:05:48
@_author: Ben Laurie 
@_subject: OpenSSL Security Advisory 
OpenSSL Security Advisory [12-Oct-2007]
OpenSSL Vulnerabilities
Andy Polyakov discovered a flaw in OpenSSL's DTLS implementation which
could lead to the compromise of clients and servers with DTLS enabled.
DTLS is a datagram variant of TLS specified in RFC 4347 first
supported in OpenSSL version 0.9.8. Note that the vulnerabilities do
not affect SSL and TLS so only clients and servers explicitly using
DTLS are affected.
We believe this flaw will permit remote code execution.
This vulnerability is tracked as CVE-2007-4995.
Versions Affected
a) Upgrade to the latest version of OpenSSL (0.9.8f) and rebuild all
packages using OpenSSL for DTLS.
b) Disable DTLS.
Vulnerability B
All releases of 0.9.8 prior to 0.9.8f. All releases of 0.9.7 prior to
(Note that versions prior to 0.9.8d and 0.9.7l actually had a worse
problem in the same function).
a) Don't use SSL_get_shared_ciphers().
b) Upgrade to 0.9.8f.
           "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2007-10-13 12:04:06
@_author: Ben Laurie 
@_subject: Password hashing 
+1 to iterated HMAC-xxx, where xxx is a cryptographic hash of your choosing.
Easy to implement, hard to get wrong, somewhat understood security

@_date: 2007-10-26 23:56:05
@_author: Ben Laurie 
@_subject: Password vs data entropy 
It would assist understanding, I feel, if we thought about 4 kilobits of
entropy, rather than a 4 kilobit value. I want to make this distinction
because I'd like to talk about secret keys, which have to be rather
larger than 4 kbits to have 4kbits of entropy for modular arithmetic stuff.
Given the above, it seems there's an obvious formulation.
Let's say the cost of a brute force attack on the secret itself is 2^xn
for n bits of entropy in the secret (it seems that this is actually the
interesting definition of entropy in this case, somewhat circularly).
Similarly, the cost of a brute force attack on the encryption protecting
the secret is 2^ym, where y is the entropy in the password.
So, when 2^ym < 2^xn, it is worth attacking the password.
So, ym < xn and hence m < xn/y.
In other words, your password needs to be x/y times the size of the
secret (in bits), where x and y are the costs of attacking the secret
and the password respectively.

@_date: 2007-09-20 14:34:51
@_author: Ben Laurie 
@_subject: Scare tactic? 
It seems to me that the requirement cited:
"Entity i cannot be coerced into sharing a key with entity j without i?s
knowledge, ie, when i believes the key is shared with some entity l != j."
is generally impossible to achieve in practice. Which is lucky:
otherwise DRM would work.
To address their particular complaint, one of the two parties must
cooperate with the passive attacker to cause key leakage. If they are
prepared to cooperate then they can leak the key anyway, and no amount
of testing of public keys will prevent this.

@_date: 2007-09-21 20:07:28
@_author: Ben Laurie 
@_subject: Scare tactic? 
I have to say that Nick Mathewson should get all the credit for this, I
was merely a facilitator.

@_date: 2007-09-23 21:38:55
@_author: Ben Laurie 
@_subject: open source digital cash packages 
Lucre. There was also a project, lucrative, to make it into a usable
platform. It fizzled, I think, but may still be a good starting point.
Of course, Chaumian e-cash is now patent free. I think there's another
confusingly-named (my fault, sorry) project that does that. Called Lucre.

@_date: 2008-08-02 22:51:53
@_author: Ben Laurie 
@_subject: On the "randomness" of DNS 
Are you seriously saying that the entropy of FreeBSD /dev/random is 0?

@_date: 2008-08-03 12:44:04
@_author: Ben Laurie 
@_subject: On the unpredictability of DNS 
I don't see any actual rephrasing below, unless you are suggesting I should have said "unpredictable" instead of "random". I think that's a perfectly fine substitution to make.
I agree, but my point is unaltered if you switch "randomness" to I don't see why. A perfectly reasonable threat is that the attacker reverse engineers the PRNG (or just checks out the source). It doesn't need to be common to be predictable.
Again, changing the words does not alter my point in any way, though I do agree that unpredictable is a better word.

@_date: 2008-08-03 13:08:13
@_author: Ben Laurie 
@_subject: Strength in Complexity? 
So, an executive summary of your responses appears to be "EKMI leaves all the hard/impossible problems to be solved by components that are out of scope".
As such, I'm not seeing much value.
PKI out of scope...
...impossibility of solving DRM problem out of scope...
...goals the same as pretty much all cryptographic protocols...
...security out of scope and scope out of scope.
Is there anything other than key escrow that's actually in scope?

@_date: 2008-08-09 09:29:09
@_author: Ben Laurie 
@_subject: OpenID/Debian PRNG/DNS Cache poisoning advisory 
Yeah, I considered this scheme. The problem is that it doesn't really help the relying parties, who can still be fooled into believing an existing user is returning (or a new one is arriving) from the original site. This is particularly a problem for Sun's OpenID Provider, which makes the additional assertion (out of band) that the user is a Sun employee. So, anyone can become a Sun employee, as of a few days ago.
This is why the lack of CRL checking in OpenID libraries is an issue.
In general, DNS is not fixable without deploying DNSSEC.
a) The current "fix" just reduces the probability of an attack. If attacker and victim have sufficient bandwidth, it can still be done in under a day.
b) There are many scenarios, mostly revolving around the use of wireless hotspots, where users are easily fooled into using a malicious DNS provider.
So, DNS patching is not, IMO, the real answer to this problem. Of course, the second scenario has been around forever, but is conveniently ignored when explaining why CRLs are not necessary (and all other things that rely on perfect DNS). All that's happened recently is we've made people who are sitting still just as vulnerable as travellers.
But increasingly we are all travellers some of the time, from a "how we get our 'net" POV. We really can't ignore this use case.

@_date: 2008-08-13 11:31:17
@_author: Ben Laurie 
@_subject: Keyczar 
When I joined Google over two years ago I was asked to find a small project to get used to the way development is done there. The project I chose was one that some colleagues had been thinking about, a key management library. I soon realised that unless the library also handled the crypto it was punting on the hard problem, so I extended it to do crypto and to handle key rotation and algorithm changes transparently to the user of the library.
About nine months later I handed over my "starter project" to Steve Weis, who has worked on it ever since. For a long time we've talked about releasing an open source version, and I'm pleased to say that Steve and intern Arkajit Dey did just that, earlier this week: Keyczar[1].
     "Keyczar is an open source cryptographic toolkit designed to make it easier and safer for developers to use cryptography in their applications. Keyczar supports authentication and encryption with both symmetric and asymmetric keys. Some features of Keyczar include:
         * A simple API
         * Key rotation and versioning
         * Safe default algorithms, modes, and key lengths
         * Automated generation of initialization vectors and ciphertext When we say simple, by the way, the code for loading a keyset and encrypting some plaintext is just two lines. Likewise for decryption. And the user doesn't need to know anything about algorithms or modes.
Great work, guys! I look forward to the "real" version (C++, of course!).
[1]

@_date: 2008-02-23 12:33:15
@_author: Ben Laurie 
@_subject: Fixing SSL (was Re: Dutch Transport Card Broken) 
It's not rocket science. You have a public/private keypair. You can sign emails. For example, import your cardspace key into PGP.

@_date: 2008-07-07 16:22:59
@_author: Ben Laurie 
@_subject: Strength in Complexity? 
I find the question difficult to understand. Before I could even begin to answer, you'd have to define what "proper key management" actually is.
That said, EKMI (from my brief reading) has a view of key management that is only "proper" in quite constrained circumstances. In particular, keys are available to participants other than those who are communicating, which is general considered to be a very bad idea. This is fine if you are a corporation wanting to achieve escrow, of course. Though that can be done without requiring a central server to remember all the keys, of course.
Well. You said "centralized server". Many cryptographic systems don't have one of those.
Also, the idea of a client library enforcing policy is DRM all over again. Which, as we all know, will never work.
So, in short: no, they don't.
Ha ha. Like that's going to work. Even if we assume that libraries are verified (fat chance, IMO), how are you going to stop, for example, cut'n'paste? Employees reading things out over the phone? Bugs? Etc.

@_date: 2008-07-08 10:42:31
@_author: Ben Laurie 
@_subject: The wisdom of the ill informed 
Barclay's Bank in the UK uses little chip&pin machines you put your
debit card into and provide the same functions as Ivan describes above.
I have a spare one I've been meaning to dissect to see what's inside
them. I wonder where I put it?

@_date: 2008-07-08 11:16:51
@_author: Ben Laurie 
@_subject: Strength in Complexity? 
Then I would agree that a protocol alone could not achieve all of this, though obviously it is possible to design a protocol that makes it OK, so you still have a PKI problem, in that you have to issue and manage client certificates. How is this done?
 > So, yes,
I'd be very surprised if it were the _only_ logical way to do it. But that aside, my point stands: these characteristics are not shared by all cryptographic systems. In fact, I'd say that all of them are not shared by most cryptographic systems.
I do not believe this is the case. DRM fails because the attacker has physical possession of the system he is attacking.
The fact that the attackers is highly motivated because of the objectionable nature of DRM does not seem to differ much from your system, though in your case the motivator will presumably be profit.
Are there any even vaguely modern systems that target the network for security, or is this a straw man?
 >  As such, it will merely be a tool in the evolution towards
If it is up to them, then why bother with this verification process? This sounds like yet more security theatre to me.

@_date: 2008-07-09 17:36:02
@_author: Ben Laurie 
@_subject: Kaminsky finds DNS exploit 
Guess you need to tell Dan that - he seems to think he did discover it.

@_date: 2008-07-09 22:26:02
@_author: Ben Laurie 
@_subject: Kaminsky finds DNS exploit 
So this seems to me to only be really true in a theoretical sense. Exploring the whole 32 bit space obviously requires well in excess of 4 GB of traffic, which is clearly a non-trivial amount to dump on your victim.
According to other data, the fix in BIND is to:
a) use random ports
b) use a good PRNG
so I'm beginning to suspect the issue is simply that the theory that it was easy to attack led to no effort being made to make it as hard as possible. And now it has.
The beauty of DNSSEC being, of course, that any answer that verifies can be trusted - so its of no interest who provided that answer.

@_date: 2008-07-10 03:54:37
@_author: Ben Laurie 
@_subject: Explaining DNSSEC 
I was asked off-list for a pointer to an explanation of DNSSEC. I guess there may be other readers who'd like that, so here's a pointer to Matasano Chargen's rather beautiful exposition:
Unfinished, but good enough. In particular, part 2 explains DNSSEC

@_date: 2008-07-30 18:56:03
@_author: Ben Laurie 
@_subject: On the "randomness" of DNS 
I thought this list might be interested in a mini-rant about DNS source port randomness on my blog: Ever since the recent DNS alert people have been testing their DNS servers with various cute things that measure how many source ports you use, and how "random" they are. Not forgetting the command line versions, of course
dig +short porttest.dns-oarc.net TXT
dig +short txidtest.dns-oarc.net TXT
which yield output along the lines of
"aaa.bbb.ccc.ddd is GREAT: 27 queries in 12.7 seconds from 27 ports with std dev 15253"
But just how GREAT is that, really? Well, we don'
t know. Why? Because there isn't actually a way test for randomness. Your DNS resolver could be using some easily predicted random number generator like, say, a linear congruential one, as is common in the rand() library function, but DNS-OARC would still say it was GREAT. Believe them when they say it isn't GREAT, though! Non-randomness we can test for.
So, how do you tell? The only way to know for sure is to review the code (or the silicon, see below). If someone tells you "don't worry, we did statistical checks and it's random" then make sure you're holding on to your wallet - he'll be selling you a bridge next.
But, you may say, we already know all the major caching resolvers have been patched and use decent randomness, so why is this an issue?
It is an issue because of NAT. If your resolver lives behind NAT (which is probably way more common since this alert, as many people's reactions [mine included] was to stop using their ISP's nameservers and stand up their own to resolve directly for them) and the NAT is doing source port translation (quite likely), then you are relying on the NAT gateway to provide your randomness. But random ports are not the best strategy for NAT. They want to avoid re-using ports too soon, so they tend to use an LRU queue instead. Pretty clearly an LRU queue can be probed and manipulated into predictability.
So, if your NAT vendor is telling you not to worry, because the statistics say they are "random", then I would start worrying a lot: your NAT vendor doesn't understand the problem. It's also pretty unhelpful for the various testers out there not to mention this issue, I must say.
Incidentally, I'm curious how much this has impacted the DNS infrastructure in terms of traffic - anyone out there got some statistics?
Oh, and I should say that number of ports and standard deviation are not a GREAT way to test for "randomness". For example, the sequence 1000, 2000, ..., 27000 has 27 ports and a standard deviation of over 7500, which looks pretty GREAT to me. But not very "random".

@_date: 2008-07-30 20:06:23
@_author: Ben Laurie 
@_subject: On the "randomness" of DNS 
I doubt you can get a large enough sample in any reasonable time.
Which is entirely my point.

@_date: 2008-07-30 21:33:28
@_author: Ben Laurie 
@_subject: On the "randomness" of DNS 
SHA-1(1), SHA-1(2), SHA-1(3), ... SHA-1(N) will look random, but clearly is not.
By reviewing the algorithm and thinking hard.

@_date: 2008-07-31 04:06:30
@_author: Ben Laurie 
@_subject: On the "randomness" of DNS 
I think that, in general, you are correct. However, in the case of NAT your adversary is not someone who is trying to guess your randomness, but someone who is trying to sell you their NAT gateway. In this case, code/silicon inspection probably suffices.

@_date: 2008-06-02 10:11:33
@_author: Ben Laurie 
@_subject: Unpatented PAKE! 
Hmmm. I don't see any IPR statements for that draft.

@_date: 2008-06-02 17:19:42
@_author: Ben Laurie 
@_subject: Unpatented PAKE! 
Given the stupidity of the US patent system, at least the authors need
to state that they make no claims, AIUI.

@_date: 2008-06-02 19:57:29
@_author: Ben Laurie 
@_subject: Can we copy trust? 
But doesn't that prove the point? The trust that you consequently place in the web server because of the certificate _cannot_ be copied to another webserver. That other webserver has to go out and buy its own copy, with its own domain name it it.

@_date: 2008-06-03 03:36:55
@_author: Ben Laurie 
@_subject: Can we copy trust? 
Obviously. Clearly I am talking about a server in a different domain.

@_date: 2008-03-16 11:32:54
@_author: Ben Laurie 
@_subject: delegating SSL certificates 
You only think this is bad because you believe CAs add some value.
SSH keys aren't signed and don't expire. Is that bad?

@_date: 2008-03-16 18:52:06
@_author: Ben Laurie 
@_subject: [mm] delegating SSL certificates 
I think there's a large gulf between the use case where the relying party and the CA are the same entity, and where they do not even have a contractual arrangement.
CAs within a corporate environment may well be a good idea in some cases, indeed. As you know, we've been pushing on this idea at the Apache Software Foundation for some time now, hindered only by our laziness :-)

@_date: 2008-03-22 10:33:04
@_author: Ben Laurie 
@_subject: How is DNSSEC 
There are two major issues with DNSSEC right now. Neither of them is that it isn't working.
Firstly, the root is not signed. This means there's no easy way for the relying party to establish the correctness of the key on your domain.
Secondly, although we have DNS servers and resolvers, software that uses DNS is largely unaware of DNSSEC and so has absolutely no idea what to do when one of the many possible cryptographic/proof failures occurs. Very little thought has gone into what should be done, even in software that is aware.
That said, if you want to distribute keys with DNSSEC, then RFC 4398 standardises ways to do a number of them, and can be extended to cover more. RFC 4255 gives you SSH host keys, too.
If you want to do something ad hoc, then there are always TXT records, though I guarantee this will make the DNS people hate you forever.

@_date: 2008-03-22 10:59:18
@_author: Ben Laurie 
@_subject: How is DNSSEC 
So far, so good. This disconnect doesn't seem to have done the CA industry any harm, though.
Non sequiteur, plus I can't see why paranoia would prompt me to want to do this? What does it prove?
Also, PTR records are only supposed to point to "primary domain names". Since it is common for hosts to have many names resolving to the same IP address, by definition most of these will not correspond to the reverse Who is "we" and what exactly are you testing?

@_date: 2008-03-22 14:46:40
@_author: Ben Laurie 
@_subject: [mm] How is DNSSEC 
You can disbelieve my assertion if you wish, but I am only quoting the RFC. RFC 1035, to be precise:
"Address nodes are used to hold pointers to primary host names
in the normal domain space."
(section 3.5. IN-ADDR.ARPA domain). So, the "myth" is in the scripture.

@_date: 2008-03-22 15:52:49
@_author: Ben Laurie 
@_subject: [mm] How is DNSSEC 
RFC 1035 does not say, in the case of hosts, but the intent is quite clear from the text on gateways:
"Gateways will often have two names in separate domains, only one of which can be primary."

@_date: 2008-03-22 20:01:47
@_author: Ben Laurie 
@_subject: how to read information from RFID equipped credit cards 
Yeah, but...
He's talking bollocks when he says that the decryption should be done in some secure datacentre. That wouldn't save you unless there was some kind of handshake with the card - and the trouble is, those cards don't have the power to do any real crypto.
In the absence of something to prevent MitM, you would just intercept the encrypted contents of the card, and then use that. So why bother to encrypt it?
So, the bottom line is you need more horsepower in the gadget that controls your money, so you can do real crypto.
Then we get to the next problem: we don't trust the device with the keypad and display. So, we need to add that to the GTCYM (Gadget That Controls Your Money).
And so we end up at the position that we have ended up at so many times before: the GTCYM has to have a decent processor, a keyboard and a screen, and must be portable and secure.
One day we'll stop concluding this and actually do something about it.

@_date: 2008-03-22 21:44:37
@_author: Ben Laurie 
@_subject: [mm] How is DNSSEC 
If you insist on language lawyering, I can play.
I'd say it is clear from:
a) The lack of a repeated PTR record for a host IP in the example,
b) The use of the word 'primary',
c) The fact that the authors felt it necessary to explain what they saw as an exceptional case, i.e. that a gateway could have two names
that in the case of hosts, the authors expected there to only be a single PTR record for reverse lookup.
Of course, we have the power to change RFCs. But there's a process for that.

@_date: 2008-05-04 11:07:17
@_author: Ben Laurie 
@_subject: New result in predicate encryption: disjunction support 
I don't understand this one, could you say it again with more words?

@_date: 2008-05-04 11:22:51
@_author: Ben Laurie 
@_subject: User interface, security, and "simplicity" 
I don't see why.
The ssh server determines who the packets are for from information sent to it by the ssh client.
The ssh client knows on whose behalf it is acting by virtue of being invoked by that user (I'll admit this is a simplification of the most general case, but I assert my argument is unaffected), and thus is able to include the information when it talks to the server.
Similarly, the client end of an IPSEC connection knows who opened the connection and could, similarly, convey that information. That data may not be available in some OSes by the time it gets to the IPSEC stack, but that's a deficiency of the OS, not a fundamental problem.
It seems to me there's no real difference between the two cases.

@_date: 2008-05-05 12:05:01
@_author: Ben Laurie 
@_subject: OpenSparc -- the open source chip (except for the crypto parts) 
I think that's blatantly untrue. For example, if I look at an AND gate, I can be absolutely sure about its security properties.
Rice's theorem says you can't _always_ solve this problem. It says nothing about figuring out special cases.

@_date: 2008-05-05 13:50:12
@_author: Ben Laurie 
@_subject: [mm] OpenSparc -- the open source chip (except for the crypto 
Nor are most algorithms.
I won't debate that, but its not a consequence of Rice's Theorem.

@_date: 2008-05-13 14:10:45
@_author: Ben Laurie 
@_subject: The perils of security tools 
[Moderator's note: A quick reminder: please use ASCII except if you
need Unicode to spell your name right. Microsoft's proprietary quote
marks are not a standard and don't look right on non-Microsoft
displays. I edited them out of this by hand. --Perry]
Debian have a stunning example of how blindly fixing "problems" pointed out by security tools can be disastrous.
I've blogged about it here: Vendors Are Bad For Security
I've ranted about this at length before, I'm sure - even in print, in O'Reily's Open Sources 2. But now Debian have proved me right (again) beyond my wildest expectations. Two years ago, they "fixed" a "problem" in OpenSSL reported by valgrind[1] by removing any possibility of adding any entropy to OpenSSL's pool of randomness[2].
The result of this is that for the last two years (from Debian's "Edgy" release until now), anyone doing pretty much any crypto on Debian (and hence Ubuntu) has been using easily guessable keys. This includes SSH keys, SSL keys and OpenVPN keys.
What can we learn from this? Firstly, vendors should not be fixing problems (or, really, anything) in open source packages by patching them locally - they should contribute their patches upstream to the package maintainers. Had Debian done this in this case, we (the OpenSSL Team) would have fallen about laughing, and once we had got our breath back, told them what a terrible idea this was. But no, it seems that every vendor wants to "add value" by getting in between the user of the software and its author.
Secondly, if you are going to fix bugs, then you should install this maxim of mine firmly in your head: never fix a bug you don't understand. I'm not sure I've ever put that in writing before, but anyone who's worked with me will have heard me say it multiple times.
Incidentally, while I am talking about vendors who are bad for security, it saddens me to have to report that FreeBSD, my favourite open source operating system, are also guilty. Not only do they have local patches in their ports system that should clearly be sent upstream, but they also install packages without running the self-tests. This has bitten me twice by installing broken crypto, most recently in the py-openssl package.
[1] Valgrind is a wonderful tool, I recommend it highly.
[2] Valgrind tracks the use of uninitialised memory. Usually it is bad to have any kind of dependency on uninitialised memory, but OpenSSL happens to include a rare case when its OK, or even a good idea: its randomness pool. Adding uninitialised memory to it can do no harm and might do some good, which is why we do it. It does cause irritating errors from some kinds of debugging tools, though, including valgrind and Purify. For that reason, we do have a flag (PURIFY) that removes the offending code. However, the Debian maintainers, instead of tracking down the source of the uninitialised memory instead chose to remove any possibility of adding memory to the pool at all. Clearly they had not understood the bug before fixing it.
P.S. I'd link to the offending patch in Debian's source repository. If I could find a source repository. But I can't.

@_date: 2008-05-13 23:27:52
@_author: Ben Laurie 
@_subject: [ROS] The perils of security tools 
"However, the Debian maintainers, instead of tracking down the source of the uninitialised memory instead chose to remove any possibility of adding memory to the pool at all."

@_date: 2008-05-13 23:45:06
@_author: Ben Laurie 
@_subject: [ROS] The perils of security tools 
I must confess that I said that because I did not have the energy to figure out the other routes to adding entropy, such as adding an int (e.g. a PID, which I'm told still makes it in there).

@_date: 2008-05-14 10:34:22
@_author: Ben Laurie 
@_subject: [ROS] The perils of security tools 
Well. Kinda. It didn't really explain why:
There is in theory a second place where it might used an uninitialised buffer, but I think in practice that never happens.
I'd note that ISO/IEC 9899 says the result of doing this is undefined, so I am inclined to remove it from future releases.

@_date: 2008-05-14 16:29:40
@_author: Ben Laurie 
@_subject: [ROS] The perils of security tools 
_I_ didn't get anything. And _I_ didn't deserve anything: I did not write the code.

@_date: 2008-05-15 10:25:11
@_author: Ben Laurie 
@_subject: The perils of security tools 
They removed _all_ entropy addition to the pool, with the exception of the PID, which is mixed in at a lower level.

@_date: 2008-05-15 17:14:17
@_author: Ben Laurie 
@_subject: The perils of security tools 
That doesn't scale very well, though - which is why my position is that they should avoid local mods.

@_date: 2008-05-23 22:55:58
@_author: Ben Laurie 
@_subject: [ROS] The perils of security tools 
I'm fully aware why its there! I just wasn't sure (at the time) that this change didn't also remove it.

@_date: 2008-05-24 20:29:51
@_author: Ben Laurie 
@_subject: The perils of security tools 
I think the core point is that 10+ years ago, when this code was written, randomness was actually quite hard to come by. Daemons like EGD had to be installed and fed and cared for. So, even a little entropy from "uninitialised" memory (I use the quotes because I do appreciate that the memory probably has somewhat predictable content) was worth having.
Of course, we have now persuaded even the most stubborn OS that randomness matters, and most of them make it available, so perhaps this concern is moot.
Though I would be interested to know how well they do it! I did have some input into the design for FreeBSD's, so I know it isn't completely awful, but how do other OSes stack up?

@_date: 2008-10-12 12:39:50
@_author: Ben Laurie 
@_subject: once more, with feeling. 
We've been debating this a lot at Google lately. One argument that I
have increasing sympathy with is that SSO (or if you want to be modern,
federated login) provides an opportunity to change the playing field
sufficiently that we can reprogram users to be less vulnerable to
phishing - or just switch them to protocols that make phishing irrelevant.
To that end, we've released some usability research...
Obviously the end game here is that the user only has to protect his
login to a small number of sites - i.e. those that provide the IdP. Once
we get there, perhaps users can be persuaded to authenticate to those
sites using something stronger than username/password.
A sidenote that provides me with some amusement: although the modern
trend is towards using OpenID, no-one wants to use it in the mode it is
designed for, i.e. where the user can pick any old IdP and the RP will
just trust it. In practice where we seem to be headed is that RPs will
trust some smallish number of trusted IdPs. This is, of course, exactly
what the Liberty guys have been working on all along. I predict that
over time, most of the elements of Liberty will be incorporated into OpenID.
Which makes me think that if Liberty had done what it claimed to be
doing when it started, i.e. be a community-based, open-source-friendly
protocol suite, it would have worked much better.

@_date: 2008-10-26 22:00:48
@_author: Ben Laurie 
@_subject: Who cares about side-channel attacks? 
But they've all been unlocked using easier attacks, surely?

@_date: 2008-09-06 14:44:20
@_author: Ben Laurie 
@_subject: Quiet in the list... 
What does this mean? GPG + Enigmail, whilst not the best architecture I
ever heard of, is a tiny increment to the complexity of Thunderbird.
Are you saying anything other than "big software has bugs"?

@_date: 2009-08-06 09:52:23
@_author: Ben Laurie 
@_subject: cleversafe says: 3 Reasons Why Encryption is Overrated 
Surely this is fundamental to threshold secret sharing - until you reach
the threshold, you have not reduced the cost of an attack?

@_date: 2009-08-25 12:44:57
@_author: Ben Laurie 
@_subject: SHA-1 and Git (was Re: [tahoe-dev] Tahoe-LAFS key management, 
In order to roll out a new crypto algorithm, you have to roll out new
software. So, why is anything needed for "pluggability" beyond versioning?
It seems to me protocol designers get all excited about this because
they want to design the protocol once and be done with it. But software
authors are generally content to worry about the new algorithm when they
need to switch to it - and since they're going to have to update their
software anyway and get everyone to install the new version, why should
they worry any sooner?

@_date: 2009-02-01 19:38:51
@_author: Ben Laurie 
@_subject: full-disk subversion standards released 
Apart from the obvious fact that if the TPM is good for DRM then it is also good for protecting servers and the data on them, Mark Ryan presented a plausible use case that is not DRM: I wrote it up briefly here: As for John's original point, isn't the world full of such tools (guns, TV cameras, telephone networks, jet engines, blah blah)?

@_date: 2009-02-11 16:20:22
@_author: Ben Laurie 
@_subject: full-disk subversion standards released 
If I have data on my server that I would like to stay on my server and
not get leaked to some third party, then this is exactly the same
situation as DRMed content on an end user's machine, is it not?
Note that I am not claiming expertise in the use of TPMs. I am making
the claim that _if_ they are good for DRM, _then_ they are also good for
protecting data on servers.
I agree that it is more cute than practical.

@_date: 2009-02-13 10:37:04
@_author: Ben Laurie 
@_subject: full-disk subversion standards released 
You wish. The threat is an attacker who has root on your machine.

@_date: 2009-02-14 12:18:44
@_author: Ben Laurie 
@_subject: Crypto Craft Knowledge 
[Never been 100% sure about the etiquette of sending my own blog posts
to this list, but in this case I am doing so at Perry's request. For
future reference if anyone else ever feels it's appropriate, do feel free]
cryptography is craft knowledge that is not written down anywhere, so it
was with interest that I read a post by Michael Roe about hidden
assumptions in crypto[1]. Of particular interest is this
"When we specify abstract protocols, it's generally understood that the
concrete encoding that gets signed or MAC'd contains enough information
to unambigously identify the field boundaries: it contains length
fields, a closing XML tag, or whatever. A signed message {Payee, Amount}
K_A should not allow a payment of $3 to Bob12 to be mutated by the
attacker into a payment of $23 to Bob1. But ISO 9798 (and a bunch of
others) don't say that. There's nothing that says a conforming
implementation can't send the length field without authentication.
Now of course, an implementor probably wouldn't do that. But they _might_."
Actually, in my extensive experience of reviewing security-critical
code, this particular error is extremely common. Why does Michael assume
that they probably wouldn't? Because he is steeped in the craft
knowledge around crypto. But most developers aren't. Most developers
don't even have the right mindset for secure coding, let alone correct
cryptographic coding. So, why on Earth do we expect them to follow our
unwritten rules, many of which are far from obvious even if you
understand the crypto?

@_date: 2009-02-17 10:22:22
@_author: Ben Laurie 
@_subject: Crypto Craft Knowledge 
I totally agree, and this is the thinking behind the Keyczar project
"Cryptography is easy to get wrong. Developers can choose improper
cipher modes, use obsolete algorithms, compose primitives in an unsafe
manner, or fail to anticipate the need for key rotation. Keyczar
abstracts some of these details by choosing safe defaults, automatically
tagging outputs with key version information, and providing a simple
programming interface.
Keyczar is designed to be open, extensible, and cross-platform
compatible. It is not intended to replace existing cryptographic
libraries like OpenSSL, PyCrypto, or the Java JCE, and in fact is built
on these libraries."

@_date: 2009-02-25 10:57:50
@_author: Ben Laurie 
@_subject: Crypto Craft Knowledge 
Furthermore, its entirely simplistic to suggest that "money first" ==
"do any fool thing a customer demands". Some businesses do actually care
about their reputation, even if only because they believe that will make
them more money in the long run.
Plus, even the most accommodating company will draw the line somewhere -
not every foolish thing is profitable, even if a customer wants it.

@_date: 2009-01-09 14:51:11
@_author: Ben Laurie 
@_subject: OpenPGP:SDK v0.9 released 
I thought people might be interested in this now somewhat-complete,
BSD-licensed OpenPGP library...

@_date: 2009-06-07 17:10:30
@_author: Ben Laurie 
@_subject: Factoring attack against RSA based on Pollard's Rho 
No, no. You don't multiply by .2, you add log_2(.2), which is around -3.
So, 1021 bits.

@_date: 2009-03-06 11:21:11
@_author: Ben Laurie 
@_subject: Solving password problems one at a time, Re: The password-reset 
============================== START ==============================
That's a pretty annoying paper.
Firstly, I don't care about the average rate of account compromise for
sites that host my stuff, I only care about _my_ account. This means
that I cannot, despite their claim, write down my long, "secret" user ID
because if anyone ever sees it, I'm sunk because of the short password
they are advocating.
Secondly, they claim that user IDs are in practice secret, on the basis
that if they weren't, then sites would be experiencing massive DoS
attacks. To prove this claim, they cite a case where SSNs are used as
user IDs. Now, if there's one thing we know, it's that SSNs aren't even
a little bit secret. Therefore the reason there is no widepsread DoS is
because no-one wants to mount the attack.
Thirdly, they really need to learn when to use apostrophes!
Incidentally, the reason we don't use EKE (and many other useful
schemes) is not because they don't solve our problems, its because the
rights holders won't let us use them.
On this we agree. We do have any number of decent cryptographic schemes
that would complete solve phishing. All we have to do is figure out:
a) How to show the user that he is actually using the scheme and is not
being phished.
b) Get it rolled out everywhere.
I am not holding my breath, though perhaps '09 is the year for action?

@_date: 2009-11-05 16:53:54
@_author: Ben Laurie 
@_subject: OpenSSL 0.9.8l released 
OpenSSL version 0.9.8l released
   ===============================
   OpenSSL - The Open Source toolkit for SSL/TLS
      The OpenSSL project team is pleased to announce the release of
   version 0.9.8l of our open source toolkit for SSL/TLS. This new
   OpenSSL version is a security release which disables renegotiation
   as a workaround for CVE-2009-3555.  For a complete list of changes,
   please see    We consider OpenSSL 0.9.8l to be the best version of OpenSSL
   available and we strongly recommend that users of older versions
   upgrade as soon as possible. OpenSSL 0.9.8l is available for
   download via HTTP and FTP from the following master locations (you
   can find the various FTP mirrors under
        *      * ftp://ftp.openssl.org/source/
   The distribution file names are:
    o openssl-0.9.8l.tar.gz
      Size: 4179422
      MD5 checksum: 05a0ece1372392a2cf310ebb96333025
      SHA1 checksum: d3fb6ec89532ab40646b65af179bb1770f7ca28f
   The checksums were calculated using the following commands:
    openssl md5 openssl-0.9.*.tar.gz
    openssl sha1 openssl-0.9.*.tar.gz
   Yours,
   The OpenSSL Project Team...
    Mark J. Cox             Nils Larsch         Ulf Mller
    Ralf S. Engelschall     Ben Laurie          Andy Polyakov
    Dr. Stephen Henson      Richard Levitte     Geoff Thorpe
    Lutz Jnicke            Bodo Mller

@_date: 2010-08-19 09:09:00
@_author: Ben Laurie 
@_subject: About that "Mighty Fortress"...  What's it look like? 
Selective disclosure allows this kind of thing (e.g. "check that x is
not on a blacklist without revealing x"). Not sure it's particularly
efficient, though...

@_date: 2010-07-27 22:34:26
@_author: Ben Laurie 
@_subject: A mighty fortress is our PKI, Part II 
One way to mitigate this would be to revoke a cert on a date, and only
reject signatures on files you received after that date.

@_date: 2010-07-28 11:32:55
@_author: Ben Laurie 
@_subject: A mighty fortress is our PKI 
Had he succeeded in this mission, then we could never have had John
Major on Spitting Image being "not inconsiderably incandescent".

@_date: 2010-07-28 11:34:14
@_author: Ben Laurie 
@_subject: A mighty fortress is our PKI, Part II 
Note that I avoided this issue by using the date of receipt.

@_date: 2010-07-28 11:38:17
@_author: Ben Laurie 
@_subject: A mighty fortress is our PKI, Part II 
Obviously if you are going to change revocation you can also change when
signatures are checked. This hardly seems like a show-stopper.
Again, citing the failure to use revocation correctly right now does not
tell us anything much about the possibility of using it correctly in the
At which time they release another version? Doesn't sound like the
optimal answer to me.
I find your response strange. You ask how we might fix the problems,
then you respond that since the world doesn't work that way right now,
the fixes won't work. Is this just an exercise in one-upmanship? You
know more ways the world is broken than I do?

@_date: 2010-07-28 13:21:33
@_author: Ben Laurie 
@_subject: A mighty fortress is our PKI, Part II 
The core problem appears to be a lack of will to fix the problems, not a
lack of feasible technical solutions.
I don't know why it should help that we find different solutions for the
world to ignore?

@_date: 2010-07-28 14:38:53
@_author: Ben Laurie 
@_subject: A mighty fortress is our PKI, Part II 
To be clear, I am not a proponent of PKI as we know it, and certainly
the current use of PKI to sign software has never delivered any actual
value, and still wouldn't if revocation worked perfectly.
However, using private keys to prove that you are (probably) dealing
with the same entity as yesterday seems like a useful thing to do. And
still needs revocation.
Is there a good replacement for pk for this purpose?

@_date: 2010-07-28 15:46:58
@_author: Ben Laurie 
@_subject: A mighty fortress is our PKI, Part II 
Now you are talking my language! Have I mentioned that my new project at
Google is all about finding good UI for exposing capabilities to users?
The problem here is that it doesn't directly give me an upgrade path. Of
course, I agree that this is sufficient to give me a link to the "right"
binary, but what about its successors?
Yes, this is of course the YURL scheme.

@_date: 2010-07-28 16:05:57
@_author: Ben Laurie 
@_subject: A mighty fortress is our PKI, Part II 
I am referring to the SSH host key. Fully agree for user keys.

@_date: 2010-03-20 17:29:36
@_author: Ben Laurie 
@_subject: 1024 bit RSA cracked? 
What everyone said...
Plus ... even with their fix, all they have to do is induce two errors
in quick succession and OpenSSL will spit out the key whole.
In any case, this all seems entirely pointless: in order to mount the
attack, you have to have intimate access to the hardware. In other
words, what they have demonstrated is that DRM doesn't work. Groundbreaking.
Of course, the annoying fall-out is that there will be (already is) a
knee-jerk clamour for us to "fix" OpenSSL. Well, I've got news: securing
anything in the face of an unpredictable CPU seems well beyond the scope
of the OpenSSL project - or any other crypto library I am aware of. I'm
not even sure it's possible.

@_date: 2010-03-25 13:24:16
@_author: Ben Laurie 
@_subject: "Against Rekeying" 
Note, however, that one of the reasons the TLS renegotiation attack was
so bad in combination with HTTP was that reauthentication did not result
in use of the new channel to re-send the command that had resulted in a
need for reauthentication. This command could have come from the
attacker, but the reauthentication would still be used to "authenticate" it.
In other words, designing composable secure protocols is hard. And TLS
isn't one. Or maybe it is, now that the channels before and after
rekeying are bound together (which would seem to invalidate your
argument above).

@_date: 2010-09-01 21:55:24
@_author: Ben Laurie 
@_subject: Merkle Signature Scheme is the most secure signature scheme possible 
Way behind the curve here, but this argument seems incorrect. Merkle
signatures rely on the properties of chained hash functions, whereas
RSA, for example, only needs a single iteration of the hash function to
be good.
Or, to put it another way, in order to show that a Merkle signature is
at least as good as any other, then you'll first have to show that an
iterated hash is at least as secure as a non-iterated hash (which seems
like a hard problem, since it isn't).

@_date: 2010-09-03 09:45:20
@_author: Ben Laurie 
@_subject: Merkle Signature Scheme is the most secure signature scheme possible 
That's the whole point - a hash function used on an arbitrary message
produces one of its possible outputs. Feed that hash back in and it
produces one of a subset of its possible outputs. Each time you do this,
you lose a little entropy (I can't remember how much, but I do remember
David Wagner explaining it to me when I discovered this for myself quite
a few years ago).
So, on that basis alone, I reject the "most secure possible" argument.
I think I've failed to understand why you thing collisions are not a
problem for Merkle trees.
Also, regardless, you are now talking probabilities and so a claim of
"most secure possible" still doesn't apply.
Merkle trees, probably the best signature in the world? :-)

@_date: 2010-09-03 19:22:56
@_author: Ben Laurie 
@_subject: Merkle Signature Scheme is the most secure signature scheme possible 
I think when I did this, I fully enumerated the behaviour of a truncated
hash (e.g. the first 20 bits of MD5).

@_date: 2010-09-05 15:11:39
@_author: Ben Laurie 
@_subject: questions about RNGs and FIPS 140 
This is nice.
Given that we seem to have agreed that "unpredictable" is kinda hard,
I'm amused that SP800-90 requires it. If it is a requirement then I
wonder why NIST didn't specify how to generate and validate such a seed?

@_date: 2010-09-14 12:38:29
@_author: Ben Laurie 
@_subject: Intel plans crypto-walled-garden for x86 
They said "known and trusted", right? So that would rule out anything
from MSFT...

@_date: 2010-09-14 15:06:48
@_author: Ben Laurie 
@_subject: Debian encouraging use of 4096 bit RSA keys 
Given their constraints, what they say (i.e. "to be on the safe side")
seems entirely reasonable. Code signing and verification do not occur
with great frequency, so a big key is not a big problem.
In general, we should resist the temptation to pare security protocols
down to the bare minimum - it is this tendency that gave us, for
example, the TLS renegotiation attack. A little bit of belt and braces
and that would have been a non-issue.

@_date: 2010-09-14 15:13:51
@_author: Ben Laurie 
@_subject: Hashing algorithm needed 
FWIW, you can get browsers to generate CSRs and eat the resulting certs.
The actual UIs vary from appalling to terrible.
Of some interest to me is the approach I saw recently (confusingly named
WebID) of a pure Javascript implementation (yes, TLS in JS, apparently),
allowing UI to be completely controlled by the issuer. Ultimately this
approach seems too risky for real use, but it could be used to prototype
UI, perhaps finally leading to something usable in browsers.
Slide deck here: (note, videos use flash, I think, so probably won't work for anyone with
their eye on the ball).
Demo here:

@_date: 2010-09-15 11:10:16
@_author: Ben Laurie 
@_subject: Hashing algorithm needed 
That's one of the reasons I said it was only good for experimenation.

@_date: 2013-08-23 20:34:04
@_author: Ben Laurie 
@_subject: [Cryptography] PRISM PROOF Email 
We have already outline how to make verifiable maps as well as verifiable
logs, which I think is all you need.

@_date: 2013-12-07 21:26:41
@_author: Ben Laurie 
@_subject: [Cryptography] Anonymous messaging [was: Email is securable 
You mean anonymity of using TOR is becoming desirable, surely? Because
everyone is accessing the network.

@_date: 2013-12-15 11:21:20
@_author: Ben Laurie 
@_subject: [Cryptography] DNSNMC deprecates Certificate Authorities and 
As I pointed out elsewhere, Bitcoin (and hence Namecoin) is not
decentralised:

@_date: 2013-12-18 22:50:27
@_author: Ben Laurie 
@_subject: [Cryptography] DNSNMC deprecates Certificate Authorities and 
Let us suppose for a moment that this is correct. What is the
well-known solution to the well-known 51% problem?

@_date: 2013-11-02 17:29:33
@_author: Ben Laurie 
@_subject: [Cryptography] FIPS 140 testing hurting secure random bit 
I recommend just ignoring FIPS 140, it is such a waste of time and money.

@_date: 2013-11-06 15:52:18
@_author: Ben Laurie 
@_subject: [Cryptography] DNSSEC = completely unnecessary? 
How did DNS get this magic un-MITM-able property?
Surely if the GoC wants to cause nohats.ca to be modified, for some
specific target(s), they can do that?

@_date: 2013-11-06 22:35:03
@_author: Ben Laurie 
@_subject: [Cryptography] DNSSEC = completely unnecessary? 
And if you are not the target, you will not see the targetted response.
Likewise, the same thing could be done with HTTPS...
_You_ get the standard answers.
The target gets the custom answers.

@_date: 2013-11-16 10:29:30
@_author: Ben Laurie 
@_subject: [Cryptography] Moving forward on improving HTTP's security 
This is not how CT works, the check is asynchronous: you get a signature
from a log along with the certificate, and you later check that the log was
honest. That is, trust but verify.
Synchronous checks would be nice, but the failure rate is too high. Even if
it weren't, the extra latency is also a problem.
CT is a careful compromise that balanced deployability with effectiveness.
Once it is in place, I'm sure we'll start working on compromises that move
the needle towards even higher security at the cost of slower deployment.
For example, revocation is often cited as a problem. I agree. But to solve
it without introducing other problems, we need to change servers. Changing
_all_ servers takes around a decade.
I think if you want this system, the appropriate vehicle is DNSSEC. A
variant on CT for DNSSEC is clearly possible, and I hope my team can start
working on that soon. We're a little busy right now, though.

@_date: 2013-11-19 09:58:35
@_author: Ben Laurie 
@_subject: [Cryptography] Moving forward on improving HTTP's security 
Software releases
Mapping of email address to public key
Delegation of DNSSEC keys

@_date: 2013-10-01 09:09:25
@_author: Ben Laurie 
@_subject: [Cryptography] RSA equivalent key length/strength 
If you don't quote the message you're replying to, its hard to guess who
should check what code - perhaps you could elaborate?

@_date: 2013-10-05 23:12:46
@_author: Ben Laurie 
@_subject: [Cryptography] Sha3 
I have to take issue with this:
"The security is not reduced by adding these suffixes, as this is only
restricting the input space compared to the original Keccak. If there
is no security problem on Keccak(M), there is no security problem on
Keccak(M|suffix), as the latter is included in the former."
I could equally argue, to take an extreme example:
"The security is not reduced by adding these suffixes, as this is only
restricting the input space compared to the original Keccak. If there
is no security problem on Keccak(M), there is no security problem on
Keccak(preimages of Keccak(42)), as the latter is included in the
In other words, I have to also make an argument about the nature of
the suffix and how it can't have been chosen s.t. it influences the
output in a useful way.
I suspect I should agree with the conclusion, but I can't agree with
the reasoning.

@_date: 2013-10-12 11:51:24
@_author: Ben Laurie 
@_subject: [Cryptography] Crypto Standards v.s. Engineering habits - Was: 
AIUI, you're trying to make it so that only active attacks work on the
combined protocol, whereas passive attacks might work on the outer
protocol. In order to achieve this, you assume that your proposed
inner protocol is not vulnerable to passive attacks (I assume the
outer protocol also thinks this is true). Why should we believe the
inner protocol is any better than the outer one in this respect?
Particularly since you're using tainted algorithms ;-).

@_date: 2013-10-20 14:59:06
@_author: Ben Laurie 
@_subject: [Cryptography] prism-proof email in the degenerate case 
Didn't there used to be a newsgroup for exactly this purpose? I can't
find it now, but I distinctly remember it.
I'd guess NNTP was a better protocol than SMTP for this.

@_date: 2013-10-21 20:03:06
@_author: Ben Laurie 
@_subject: [Cryptography] [cryptography] funding Tor development 
I'm not privy to everything that happened in the federal government this
month. Perhaps you could elaborate?

@_date: 2013-10-22 10:11:38
@_author: Ben Laurie 
@_subject: [Cryptography] Fwd: [capsicum] capsicum-linux codebase 
Not crypto, but very much security: Capsicum is a capability system layered
on top of POSIX. It is enabled by default in FreeBSD from 9.1.
We're working on a Linux port.
---------- Forwarded message ----------
As some of you know, I'm working on getting Capsicum working in the Linux
kernel, based on the FreeBSD implementation and on previous work done by
Meredydd Luff in his stint as a Google intern.
If anyone is interested in the details, the Git repo is now visible at:
  This is still work in progress, but I've merged Meredydd's work up to a
more recent kernel (3.11.1), and I'm slowly converging on functional
equivalence to FreeBSD 9.x -- catching up with Pawel et al's more recent
work will come later.
Along the way, I've also separated out a bunch of user-space tests for the
Capsicum syscall functionality into a separate repo at:
  This combines both the FreeBSD test cases and Meredydd's test code with a
few extras, but I've pulled it into a separate repo to make it easy to run
on both Linux and FreeBSD, to allow cross-comparison.  It may potentially
also be useful for other Capsicum port efforts (although as above, it's
targeted at the level of function in FreeBSD 9.x, not 10.x).
Let me know if you have any questions,

@_date: 2013-09-01 13:55:08
@_author: Ben Laurie 
@_subject: [Cryptography] Thoughts about keys 
Not sure about _extremely_, but I certainly agree it should be relatively
straightforward. And since I have an interest in the "Here's a log,
including various sorts of widely witnessed events and hash chains so that
if we were lying about this we had to be planning to lie about it for a
very long time." (not sure I agree about that last part, btw), I hereby
volunteer to implement that part if there are people willing to implement
the rest...

@_date: 2013-09-04 16:42:24
@_author: Ben Laurie 
@_subject: [Cryptography] Hashes into Ciphers 
His claim is that it is actually faster than DES, not impractically slow.

@_date: 2013-09-06 18:18:05
@_author: Ben Laurie 
@_subject: [Cryptography] People should turn on PFS in TLS 
In favour of what, exactly? We're out of good ciphersuites.

@_date: 2013-09-06 18:56:51
@_author: Ben Laurie 
@_subject: [Cryptography] People should turn on PFS in TLS 
Apart from its fragility, AES-GCM is still OK, yes. The problem is that
there's nothing good left for TLS < 1.2.

@_date: 2013-09-07 05:04:21
@_author: Ben Laurie 
@_subject: [Cryptography] Using Raspberry Pis 
FWIW, we're working on a Linux port of Capsicum. Help is always welcome :-)

@_date: 2013-09-07 21:40:39
@_author: Ben Laurie 
@_subject: [Cryptography] Suite B after today's news 
I agree. But I think the ciphersuites should be backported to all previous

@_date: 2013-09-08 19:01:51
@_author: Ben Laurie 
@_subject: [Cryptography] Suite B after today's news 
BTW, Steve Henson just pushed an implementation to the master branch of
We need to get an extension number allocated, since the one it uses clashes
with ALPN.

@_date: 2013-09-09 17:29:24
@_author: Ben Laurie 
@_subject: [Cryptography] What TLS ciphersuites are still OK? 
Perry asked me to summarise the status of TLS a while back ... luckily I
don't have to because someone else has:
In short, I agree with that draft. And the brief summary is: there's only
one ciphersuite left that's good, and unfortunately its only available in
TLS 1.2:

@_date: 2013-09-10 11:34:21
@_author: Ben Laurie 
@_subject: [Cryptography] Suite B after today's news 
Feel free to argue the toss with IANA:
In the meantime, I suggest getting a new number would be more productive.
Which, apparently, means first getting adopted by the TLS WG.
Alternatively, allocate a random number.

@_date: 2013-09-10 14:01:17
@_author: Ben Laurie 
@_subject: [Cryptography] What TLS ciphersuites are still OK? 
Other than minor variations on the above, all the other ciphersuites have
problems - known attacks, unreviewed ciphers, etc.
If you think there are other ciphersuites that can be recommended -
particularly ones that are available on versions of TLS other than 1.2,
then please do name them.

@_date: 2013-09-10 14:03:32
@_author: Ben Laurie 
@_subject: [Cryptography] What TLS ciphersuites are still OK? 
It is not hard coded to 1024 bit RSA. I have seen claims that some
platforms hard code DHE to 1024 bits, but I have not investigated these
claims. If true, something should probably be done.

@_date: 2013-09-10 22:35:05
@_author: Ben Laurie 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
CT makes this impossible to do undetected, of course.

@_date: 2013-09-16 20:14:54
@_author: Ben Laurie 
@_subject: [Cryptography] End to end 
This is a fair point, and we could certainly add on to CT a capability to
post-check the presence of a pre-CT certificate in a log.
I think the important point is that even infrequently connected devices can
_eventually_ reveal the subterfuge.

@_date: 2013-09-19 21:15:58
@_author: Ben Laurie 
@_subject: [Cryptography] PRISM-Proofing and PRISM-Hardening 
No. They typically work. As usual, Apple are the fly in the ointment.

@_date: 2014-04-03 11:36:49
@_author: Ben Laurie 
@_subject: [Cryptography] Clever physical 2nd-factor authentication 
I'm pretty sure you can do this without revealing mask bits in the
challenges. It was used for party invites at the Toronto PETS back in

@_date: 2014-04-16 11:09:31
@_author: Ben Laurie 
@_subject: [Cryptography] NSA disclosure of vulnerabilities 
So, these are the SELinux guys, right? Certainly they did something
useful-ish for the world.
I still remember the shock when an NSA guy leaned over to me during
lunch and said "perhaps you'd like to review our code?" (yes, it was
one of the SELinux guys, I forget which).

@_date: 2014-04-18 12:35:00
@_author: Ben Laurie 
@_subject: [Cryptography] bounded pointers in C 
Hmm. Any info on how this works (or worked)? All bounded pointers
implementations I've seen have required some kind of code annotation
to make them work properly (e.g. explicit fat pointers). Can it really
be done without source modification?
Our research CPU, CHERI
( makes
bounded (and permissioned) pointers a first-class part of the CPU - we
have a version of LLVM that uses annotations to generate assembler
that takes advantage of these pointers.

@_date: 2014-04-19 05:55:55
@_author: Ben Laurie 
@_subject: [Cryptography] Simpler programs? 
My understanding is that a powerbox is a way for an application to get
at a users stuff (which includes things like network access). Files
are an attractive example, because its clear how you create a seamless
replacement. In a windowed environment. Kinda (e.g. what about
temporary files? shared libraries? dictionaries? users do not want to
be choosing these thing by hand).
But it is less clear how you deal with other resources. Not that we
should give up on the idea, but it isn't a painless as you suggest.
Also, we're working on a powerbox for FreeBSD, Casper. Not much
written about it yet, unfortunately, but here's a slide deck:
I think this is simplistic. Also, Java doesn't really do a good job
because of reflection.
We're also trying to help with that:

@_date: 2014-04-19 05:59:15
@_author: Ben Laurie 
@_subject: [Cryptography] Apple and OpenSSL 
"Building its own security software meant that Apple and its
developers were no longer captive to the external development issues
and eccentricities related to the OpenSSL open source project, which
despite its critical importance and broad use by the industry, was
being funded through donations and was, incredibly, maintained by a
very small team of just four core developers."
"Incredible". How could Apple have possibly helped with that? I can't imagine.

@_date: 2014-04-19 06:03:40
@_author: Ben Laurie 
@_subject: [Cryptography] bounded pointers in C 
Not so, actually. In CHERI+LLVM, malloc+memcpy is safe (yes, kids,
CHERI would've prevented Heartbleed - there would be code
modification, but of a trivial kind [I think, we should find out]).

@_date: 2014-04-19 06:07:03
@_author: Ben Laurie 
@_subject: [Cryptography] bounded pointers in C 
The Mill does this:
I think its a pretty interesting architecture, but not convinced its
the _right_ architecture :-)

@_date: 2014-04-19 10:43:58
@_author: Ben Laurie 
@_subject: [Cryptography] Simpler programs? 
This is what Casper is for in FreeBSD. The parent gets to decide which
Casper the child is using (which could simply be the parent). But this
doesn't really solve the problem of what the parent (or Casper) grants
and why.
The nice thing about the file powerbox is you capture the user's
intent through a familiar and reasonably clear interaction. Network
sockets are trickier.
True, but we can do all of the above with Capsicum (which is a Unix retrofit).

@_date: 2014-04-20 23:23:03
@_author: Ben Laurie 
@_subject: [Cryptography] Apple and OpenSSL 
OpenSSL does have a stable ABI.
If this is the conversation I remember (and it probably has to be,
because I'm pretty sure there was only one), Apple's suggestion was
that OpenSSL should change its API to CDSA, and wrap that with an
OpenSSL compatibility layer. If declining that crazy idea caused
insult, I'm sorry.
See above.

@_date: 2014-04-22 22:15:44
@_author: Ben Laurie 
@_subject: [Cryptography] Apple and OpenSSL 
Ah, so that'll be why when I do:
$ ls /lib/*.so*
they are all .so.0.
Anyway, yes, you are right that the promise we make is that the ABI is
only stable within versions that have the same digits in their version
number (which is not what I would call a micro release - that is
indicated by the letter following the version number).

@_date: 2014-04-27 18:33:20
@_author: Ben Laurie 
@_subject: [Cryptography] Improving the state of end-to-end crypto 
We are hiring to improve the state of end-to-end crypto:

@_date: 2014-04-28 09:50:01
@_author: Ben Laurie 
@_subject: [Cryptography] [cryptography] Improving the state of end-to-end 
Clearly we have not explained ourselves well. Sigh. Usability is core
to our proposal, and yes, we intend to involve users in determining
how to do that (unconventional, I know).

@_date: 2014-04-28 09:54:47
@_author: Ben Laurie 
@_subject: [Cryptography] Because one TLS bug per month is just not enough 
FWIW, this bug was described at IETF in March. The site is dated March
4th. That is, it is nearly 2 months old.
As Matthew says, branding is key.
Also, BTW, it doesn't affect many people: use of client certs is
almost non-existent.

@_date: 2014-08-17 18:16:12
@_author: Ben Laurie 
@_subject: [Cryptography] Open Source Sandboxes to Enforce Security on 
(and work is
under way to port to Linux)
 (not exactly
theoretical, but not really deployable yet either)

@_date: 2014-08-19 12:58:53
@_author: Ben Laurie 
@_subject: [Cryptography] Encryption opinion 
What? Nothing bad will happen because you can't do it. You are making
the untestable claim that if you could do it, nothing bad will happen.
This is not science, this is bloviation.

@_date: 2014-08-25 09:02:18
@_author: Ben Laurie 
@_subject: [Cryptography] Open Source Sandboxes to Enforce Security on 
Surely this is not the inverse problem - it's the same one - the
presence of a hypervisor makes the OS just more code that can be

@_date: 2014-08-29 18:44:45
@_author: Ben Laurie 
@_subject: [Cryptography] Encryption opinion 
I missed this pointing out - where are these groups?

@_date: 2014-12-03 12:18:56
@_author: Ben Laurie 
@_subject: [Cryptography] [cryptography] Underhanded Crypto 
Failing to understand the issue is more idiotic still.
The code that was removed was not the code that "relied" on an unitlialised
variable, and nor did the code rely on it anyway.

@_date: 2014-12-03 12:20:49
@_author: Ben Laurie 
@_subject: [Cryptography] [cryptography] Underhanded Crypto 
So crayzee its not what was going on. In fact, what was going on is what
you just described. Which you would've known if you actually bothered to
understand the issue.
But do carry on bloviating. It is _so_ enlightening.

@_date: 2014-12-03 20:30:50
@_author: Ben Laurie 
@_subject: [Cryptography] Fwd:  [cryptography] Underhanded Crypto 
Somehow dropped the list.
---------- Forwarded message ---------
Indeed, it will not.

@_date: 2014-12-03 20:31:27
@_author: Ben Laurie 
@_subject: [Cryptography] Fwd:  Underhanded Crypto 
And list dropped again.
---------- Forwarded message ---------
That is not the converse, and this is the core point.
We all know that low entropy sucks. Throwing in some extra entropy never
There is the orthogonal question of what to make of this in the face of
Purify, valgrind et al. which (almost always rightly) view this entirely
harmless practice as evil.
As you point out, it may mask other problems. OpenSSL provides the -DPURIFY
option to remove the code that might mask, at the cost of losing any
entropy that might have been available. Your call.
Don't blame OpenSSL for the failure of dynamic analysis perfection.

@_date: 2014-12-16 10:23:12
@_author: Ben Laurie 
@_subject: [Cryptography] [cryptography] OneRNG kickstarter project 
I don't really get the relevance to OpenSSL - Dual EC DRBG was
vulnerable regardless of the entropy source. And, as already
mentioned, not actually vulnerable in OpenSSL anyway.
I am curious if there's any evidence that avalanche diodes and Zigbee
receivers are immune to outside influence (one would've thought not in
the case of the receiver, at least, which is designed to be influenced
by the outside)?

@_date: 2014-12-22 13:32:00
@_author: Ben Laurie 
@_subject: [Cryptography] Certificates and PKI 
Pinning does indeed not care who signed the certificate. However, it
introduces an apparently insurmountable problem: what happens when you
lose your key? And, to be clear, by "lose", I mean, "no longer have
access to". It seems that your website is then unavailable for
whatever the pin expiry time is. We don't think that's acceptable, nor
fixable without introducing some entity with essentially the same role
as a CA.
Dealing with leaked (i.e. usable by someone other than you) keys is
also problematic - how do you ever regain control of your domain if
you've ever had it taken over by a bad guy?
CT does care, but for more subtle reasons:
a) If anyone can sign a cert, how do we avoid spamming logs into
uselessness? Right now, we use CA signatures as a mechanism to
attribute log entries to some entity that can be held to account for
b) If there's nothing in a CA-like role, then what do you do when the
log shows a certificate that is not correct? i.e. how do you revoke
I am a lot less worried about b than I am about a: just because we're
not sure what to do about something doesn't seem like a good reason to
not find out about it. However, I do wonder how people think a
practical system with no CA-like entities is supposed to work?
Propose an actual workable alternative would be a good first step. I
know that at this point IanG and Peter will say that I cannot ask this
because I will just shoot down anything you propose with petty
objections. However, I promise any objections I make will not be

@_date: 2014-12-22 13:33:53
@_author: Ben Laurie 
@_subject: [Cryptography] Certificates and PKI 
Indeed, this does appear to be the biggest blocker for DANE.
But also: DANE puts registries and registrars in the roles of CA and
RA. If we think CAs are not a good solution, how is it the
registries/registrars magically are?

@_date: 2014-12-23 10:56:47
@_author: Ben Laurie 
@_subject: [Cryptography] Certificates and PKI 
I'm not getting the distinction you're making here. This sounds pretty
much exactly like the relationship you have with a CA...

@_date: 2014-12-23 11:09:44
@_author: Ben Laurie 
@_subject: [Cryptography] Certificates and PKI 
We've had backups for a long time, and we still don't have easy, 100%
reliable, secure backup solutions. Not even sure we know how to create
them without involving further keys whose loss is catastrophic.
I don't get this: once the attacker has your key, you and he are
indistinguishable - how do you get to do anything he can't do?
Isn't this like self-signed cert warnings? I.e. usually incorrect, so
justifiably ignored by most users?
But if I compare the whole system, then I am back to the questions
I've raised above.
OK, then.

@_date: 2014-12-23 11:15:05
@_author: Ben Laurie 
@_subject: [Cryptography] Certificates and PKI 
This is unknowable, surely? But I think you mean when the key changes?
I do not dispute that this may be valuable information to you, but I
do claim that for most users it is meaningless information.
I certainly agree that Amazon should be expected to keep track of
their key. But we are not just talking about Amazon, we are talking
about every secure site in the world. Which I think many of us hope
will be every website in the world.
How do I publicise that my blog has a new certificate?
Again, I claim that the vast majority of users have no way to evaluate
such announcements.
Big business does have real money on the line - look at Sony, for example.

@_date: 2014-12-23 11:18:39
@_author: Ben Laurie 
@_subject: [Cryptography] Certificates and PKI 
This is clearly a step in the right direction, though it will not help
against targeted attacks.
OK, so DANE + pinning + CT? I'm not entirely sure about including
pinning (because of the aforementioned difficulties). However, seems
like a step in the right direction, but I still end up back where I
a) (If pinning is in the picture): what is done about failures as I
originally asked?
b) How do we prevent CT from being spammed?
c) What do we do when badness is detected using this system?

@_date: 2014-12-23 11:21:10
@_author: Ben Laurie 
@_subject: [Cryptography] Certificates and PKI 
I fully agree that DANE is a (slightly) better DV. But DV is
unacceptably weak and DANE is not the complete solution it is held out
to be by many.
Yes, it is nice to see the steps being taken where DNSSEC clearly does
improve matters.

@_date: 2014-12-23 11:22:43
@_author: Ben Laurie 
@_subject: [Cryptography] Certificates and PKI 
That is patently untrue - if they were, phishing would be a whole lot
harder than it is.
I'm not sure which horses we are talking about? Or what they might win?

@_date: 2014-12-23 17:47:05
@_author: Ben Laurie 
@_subject: [Cryptography] Certificates and PKI 
Ah, I was failing to parse "fate-sharing between the name you
registered and the contents that the registry advertises" - thanks for
the explanation.
I do agree that this is an important difference. However, I don't see
why we should trust registries/registrars any more than we trust CAs?

@_date: 2014-12-23 17:49:40
@_author: Ben Laurie 
@_subject: [Cryptography] Certificates and PKI 
Sure, but that does not alter the point that most people do not
understand DNS, PKIX naming, or any other naming scheme we use.
Is this like the future being IPv6's? :-)
The last mile problem is sufficiently problematic currently that we
cannot realistically rely on DNSSEC (i.e. we would effectively
disenfranchise a significant fraction of users). Obviously this is not
ideal, but its where we are.

@_date: 2014-12-23 17:55:57
@_author: Ben Laurie 
@_subject: [Cryptography] Certificates and PKI 
Totally agreed! My point is just that DANE does not fix one of the
underlying problems, namely that we cannot trust the entities that
control the systems that validate our keys. CT is intended to help
mitigate that problem for PKIX, and if we can solve the deployment
problems for DANE we will need something like CT to mitigate it for
Why do you think it will not? I suspect it should. Are you thinking
about DANE or CAA or both here?
I have perhaps been unclear what my concerns are. I hope this clears it up.

@_date: 2014-12-29 13:06:53
@_author: Ben Laurie 
@_subject: [Cryptography] Certificates and PKI 
Not entirely sure what the issue is here? DNSSEC already has denial of
existence using no more records than already exist in the zone. Not
clear why CT has a problem here?
We've also outlined a system that can efficiently do denial of
existence for CT
Not sure we (the WG) are actually shooting for completion before
addressing them, but certainly my team is already fully occupied with
CT for now, so we won't be pushing hard on it yet! But there's no
great reason to wait for CT to be done (particularly since that may
take a while!).

@_date: 2014-12-29 15:40:00
@_author: Ben Laurie 
@_subject: [Cryptography] Certificates and PKI 
Actually, the most efficient way is a node whose owner is
the hash of the would be node, next is hash + 1 and no RRtypes set in
the type map.
OK. But why would we care for DT (i.e. DNSSEC transparency) - all we
care about, surely, is records that can influence the beholder's view
of the domain key(s)?

@_date: 2014-12-29 19:25:08
@_author: Ben Laurie 
@_subject: [Cryptography] Certificates and PKI 
I agree with the latter but not the former - denial of a TLSA record
requires a signature (assuming you're using DNSSEC - if you're not, DT
is not for you). All we need to secure is that signature. So, NS/DS
matter but TLSA do not.

@_date: 2014-12-31 12:36:07
@_author: Ben Laurie 
@_subject: [Cryptography] Certificates and PKI 
I am still confused by this, but perhaps we are at cross purposes.
IMO, DT is about protecting delegation of keys to subdomains.
It seems some people are arguing that DT should also protect the
entire content of the zone.
It seems to me the latter is substantially harder, not least because
there certainly exist zones that are entirely dynamic and whose
contents vary rapidly over time.
That said, it does seem possible to me to _allow_ both schemes whilst
solving the obvious problems.
Let's call the first version (i.e. protection of keys) DTK and the
second (zones) DTZ.
1. Choice: make DTK mandatory, but include in the protected material a
flag which says whether the zone also does DTZ.
2. Spam: for both DTK and DTZ there's a spam problem (in DTK it is
that any domain can create subdomains essentially ad inifinitum).
Simple answer: allow logs to delegate to sublogs for subdomains.
Spammy domains get to run their own logs, or don't get protected:
their choice.
Monitoring DTZ, particularly for highly dynamic zones, strikes me as a
nightmare, btw. But it also seems to me that DTK is a more important

@_date: 2014-02-03 22:28:15
@_author: Ben Laurie 
@_subject: [Cryptography] cheap sources of entropy 
HOLY CRAP! Enough of the rhetoric. Has anyone measured anything, or is
this all opinion?

@_date: 2014-02-16 11:08:35
@_author: Ben Laurie 
@_subject: [Cryptography] BitCoin bug reported 
Wat? If I'm buying a bitcoin, why would I ever pay more than it would
cost me to mine one?
This is almost content-free, but what content it has seems wrong. The
upper value of a bitcoin is bounded by the cost to produce it. The
cost of producing a bitcoin is the current difficulty * the cost to
run the latest rig * the number of peope-running-latest-rig
equivalents who are currently mining. Two of these quantities can get
(almost) arbitrarily small. So, the value of a bitcoin can get
arbitrarily small - but not because it is an entirely separate

@_date: 2014-02-16 11:14:47
@_author: Ben Laurie 
@_subject: [Cryptography] Unified resource on Random Number Generation 
What's the point of having consensus on speculation?
I'd welcome something evidence-based, though.

@_date: 2014-01-29 00:37:16
@_author: Ben Laurie 
@_subject: [Cryptography] cheap sources of entropy 
Where N, it should be noted, can be less than one. Which makes
extrapolation hard.

@_date: 2014-01-29 00:40:16
@_author: Ben Laurie 
@_subject: [Cryptography] cheap sources of entropy 
Unfortunately, though, in low entropy systems it takes a _really_ long
time to reach an uncompromised state in the first place.

@_date: 2014-07-07 10:11:03
@_author: Ben Laurie 
@_subject: [Cryptography] Preventing co-op notary defection 
This I agree with, and is what I said in the paper.
Bottom line: don't believe it. How do I, as a relying party, determine
when agreement has been reached? How do members of this "loose
binding" determine it? Once more you are back to establishing
consensus in an unknown group.
This seems like the core problem with Ripple, too, BTW.
By pretending you can do the impossible? Always a hit, in my experience.

@_date: 2014-07-15 10:08:23
@_author: Ben Laurie 
@_subject: [Cryptography] VCAT report on NIST's process review 
And this is how the NSA will be dealt with:
"NIST may seek the advice of the NSA on cryptographic matters but it
must be in a position to
assess it and reject it when warranted. This may be accomplished by
NIST itself or by engaging
the cryptographic community during the development and review of any
particular standard.
The VCAT recommends that NIST senior management reviews the current
requirement for
interaction with the NSA and requests changes where it hinders its
ability to independently
develop the best cryptographic standards to serve not only the United
States Government but
the broader community"
I feel so reassured.

@_date: 2014-07-20 17:30:55
@_author: Ben Laurie 
@_subject: [Cryptography] What has Bitcoin achieved? 
How comforting, So now we know they won't take over the currency until
its sufficiently profitable, right?

@_date: 2014-06-10 22:57:40
@_author: Ben Laurie 
@_subject: [Cryptography] Subject: Re: Swift and cryptography 
If you do C++, it is not rocket science. And if you don't, you
probably shouldn't.
There's always MAX_UINT8.
That's why C++ ends up like it does (and, btw, you could also write
SomeUInt8Thing.max() to get the same result.
Suppose I have a type T in hand, which is my int-of-unknown-size: in
C++ I can write
T n = std::numeric_limits::max();

@_date: 2014-06-12 11:50:50
@_author: Ben Laurie 
@_subject: [Cryptography] End-to-End, One-to-Many, Encryption Question 
All symmetric crypto algorithms need to have keys that are not a
group, or there is a meet-in-the-middle attack available.

@_date: 2014-06-15 16:46:55
@_author: Ben Laurie 
@_subject: [Cryptography] End-to-End, One-to-Many, Encryption Question 
I did not claim that "not a group" was sufficient. It is, however, necessary.

@_date: 2014-06-15 16:49:55
@_author: Ben Laurie 
@_subject: [Cryptography] End-to-End, One-to-Many, Encryption Question 
What? DES is not, AFAIK, vulnerable to meet-in-the-middle. But any
algorithm whose keys form a group under composition would be.
True, the security would be half the bit length (at best). But since
symmetric algorithms exist whose security is thought to be roughly
equal to key length, half the key length is pretty crappy.

@_date: 2014-06-18 19:44:58
@_author: Ben Laurie 
@_subject: [Cryptography] Implementing constant-time string comparison 
Not impossible. The compiler could make the same observation you have,
and optimise for that.
You seem to be saying that other libraries are doing this?
By "the problem", I presume you mean the issue of getting 0 or 1 out
of this. In general, the style is if (CRYPTO_memcmp(...)) (or ! that),
so 0 or 1 is not needed.
But I admit to once being bitten in the ass comparing "booleans" that
weren't (in this case bitfields, though), so I can agree it isn't best

@_date: 2014-06-18 22:25:57
@_author: Ben Laurie 
@_subject: [Cryptography] Implementing constant-time string comparison 
Ah! I had misunderstood your issue - I thought you were complaining
about the lack of constant time implementations, but actually, you are
complaining about uniform return values.
In this case there's a tradeoff between speed and exactness. Choose your poison.
It would be a weird compiler that caused a problem for this case.
Some languages (e.g. Python) promote the idea of truthy and falsy. Not
directly comparable but usable as booleans. C/C++ are open on the
question, of course.
It depends on expectations.

@_date: 2014-06-20 14:11:12
@_author: Ben Laurie 
@_subject: [Cryptography] "Is FIPS 140-2 Actively harmful to software?" 
I think it, too. I did the beginning of the first implementation for
OpenSSL, and I hated it then. For example, they made me remove the
inclusion of the PID in the random pool (which prevents duplicate
randomness after a fork).
It hasn't got any better.

@_date: 2014-03-07 04:20:49
@_author: Ben Laurie 
@_subject: [Cryptography] GnuTLS -- time to look at the diff. 
Of course there is: integration with existing code.
How would that have helped with either the Apple SSL or the GNUtls bugs?

@_date: 2014-05-04 08:11:10
@_author: Ben Laurie 
@_subject: [Cryptography] One third IT managers think homomorphic is 
That is not what he said at all. He said that .25 have their data
encrypted at rest. No mention whatsoever of who controls the keys.

@_date: 2014-05-19 20:59:05
@_author: Ben Laurie 
@_subject: [Cryptography] updating a counter 
Hmm. That's surely not sufficient to ensure it doesn't repeat values.
Which matters.

@_date: 2014-05-19 21:06:02
@_author: Ben Laurie 
@_subject: [Cryptography] Is it time for a revolution to replace TLS? 
This is exactly what Certificate Transparency will do. I guess you
could call them transparency protocols.

@_date: 2014-05-28 22:36:53
@_author: Ben Laurie 
@_subject: [Cryptography] client certificates / client-side proxy 
I despair. The one problem we face is good UI design. Obviously the
crypto works.

@_date: 2014-10-07 06:44:49
@_author: Ben Laurie 
@_subject: [Cryptography] 1023 nails in the coffin of 1024 RSA... 
Oh, come on. Its only the number of atoms in the (observable) universe
... squared.

@_date: 2014-09-28 13:49:11
@_author: Ben Laurie 
@_subject: [Cryptography] Which big-name ciphers have been broken in 
On this narrow point, maths absolutely does go stale - the history of
maths is littered with proofs that turned out to be wrong in some
detail. It's even taught that way - i.e. incorrect but nearly OK
proofs at one level that you then throw away and replace with
something more complex (and more right) at the next level (calculus is
particularly memorable in this respect).
On the whole process of proof and refutation Lakatos' book
( is a really
enjoyable read.

@_date: 2015-04-01 22:57:14
@_author: Ben Laurie 
@_subject: [Cryptography] Cipher death notes 
So, you think declining to control a nuclear power plant because some minor
device had a security issue is fine?

@_date: 2015-04-11 21:21:13
@_author: Ben Laurie 
@_subject: [Cryptography] upgrade mechanisms and policies 
Wat? This is crazy talk.
Clearly the only sane policy is to believe that the latest version of X is
the most secure. And if you know about X you ought to also know about the
problems with X-1, X-2,.... So, sure, each end indicates which versions it
is prepared to use, but of the intersection, _surely_ highest wins?

@_date: 2015-04-14 16:50:21
@_author: Ben Laurie 
@_subject: [Cryptography] Fun and games with international transaction 
currencies)
It really doesn't. 51% (more properly, 34%) attacks show that it doesn't.
If it were done properly, i.e. with verifiable append only logs run by a
known set of entities, then it would. It would also be many orders of
magnitude cheaper. Stupidly cheap, in fact, instead of eye-wateringly
I do wish people would stop perpetuating this canard.

@_date: 2015-04-16 04:15:23
@_author: Ben Laurie 
@_subject: [Cryptography] Fun and games with international transaction 
currencies)
I'm on holiday on an astonishingly crap 'net connection so I can't find it
for you, but the relevant paper is referenced in Bonneau et al's excellent
survey paper on Bitcoin, which I'm sure you can find.
We haven't seen any other kind of attempt (and don't claim
Bitcoin-as-implemented is, because it isn't - and seems likely to fail in
any case). Note, BTW, that 51/34% attacks work on
Bitcoin-as-originally-envisaged, not Bitcoin-as-implemented (because of the
central authority that prevents forks).
Weird that they allow exactly that, then.

@_date: 2015-04-16 04:19:52
@_author: Ben Laurie 
@_subject: [Cryptography] Fun and games with international transaction 
currencies)
You are conflating two mechanisms:
1. The ledger. It is this that I say can be done far more cheaply and
2. Allocation of money. I make no claims about this. Though it seems like
an obvious observation that in Bitcoin the more money you spend, the more
bitcoins you get allocated. Seems to me this could be done more efficiently
than wasting all that energy. Maybe everyone should pay me instead of the
electricity companies? I promise I'll spend it wisely. And I won't waste
quite so much energy in the process.

@_date: 2015-04-25 14:49:06
@_author: Ben Laurie 
@_subject: [Cryptography] [cryptography] Shamir Reveals Sisyphus Algorithm 
The name of the game is to protect the secrets despite bugs. And I
don't mean with cryptography.

@_date: 2015-08-05 01:57:30
@_author: Ben Laurie 
@_subject: [Cryptography] SRP for mutual authentication - as an 
Right, because why bother to think about one of the longest standing
security problems we have on the 'net? Obviously you should be able to fix
that in your sleep.
How about you don't think about this much: how do you prevent phishing in
your scheme?

@_date: 2015-08-05 10:07:31
@_author: Ben Laurie 
@_subject: [Cryptography] SRP for mutual authentication - as an 
This is the core problem - if we could get users to only type their
passwords into the one true password box, then there are many viable
solutions to "the password problem". But all attempts to do this so far
have been dismal failures.

@_date: 2015-08-05 18:51:44
@_author: Ben Laurie 
@_subject: [Cryptography] SRP for mutual authentication - as an 
I use one of those, but it doesn't really help with my other devices.
And I'm screwed if I lose it (well, I'm not, because I'll be given another,
but if I were a member of the public I would be).

@_date: 2015-08-07 11:39:44
@_author: Ben Laurie 
@_subject: [Cryptography] SRP for mutual authentication - as an 
Here's a paper that gives a pretty fair overview of the problem:
Unfortunately I can't find the study they claim they're going to do in that
paper, but I do remember seeing it: it didn't work very well. Which is
probably why I can't find it anymore.

@_date: 2015-08-12 04:56:26
@_author: Ben Laurie 
@_subject: [Cryptography] SRP for mutual authentication - as an 
I don't wear a watch.
I'm not sure potential logins are much use to me. :-)
So, if I'm on holiday, I do without access for the remaining 2 weeks?
True, but that doesn't give you a licence to ignore it.

@_date: 2015-08-12 05:33:29
@_author: Ben Laurie 
@_subject: [Cryptography] Threatwatch: CIN - Corruptor-Injector Network 
Or, actually, it is impossible.
That article appears to be complete nonsense.
For example:
"This certificate identifies itself (via CN field) as *.google.com despite
being served during a putative session with google.fr(again, this kind of
obvious certificate misconfiguration is all but impossible to imagine
google doing in production systems):"
Impossible to imagine, but ... true. The certificate is fine, google.fr is
a SAN.
This supposedly fake certificate, btw, is well known to CT:
Another example:
" 404s when loaded.This is not the sort of
thing one will find in a legitimately Google-issued certificate, created
less than 10 days ago."
Oh yes it is. That is completely correct behaviour for an OCSP responder.
The alleged bad certificate, btw, for future record is:
-----BEGIN CERTIFICATE-----
-----END CERTIFICATE-----
To be clear, it isn't fake.

@_date: 2015-12-07 11:36:50
@_author: Ben Laurie 
@_subject: [Cryptography] Montgomery multiplication bug in OpenSSL? 
Another data point: many years ago I found a bug in BN_div() - the
manifestation of the bug was that a particular proven prime tested as
non-prime. The underlying reason was that there's an edge case where a
"digit" is all 1s which was not correctly handles. All 1 digits do not
occur at all often in random numbers and in any case, discarding the
occasional random prime isn't that much of a problem, but this proven prime
was full of them.

@_date: 2015-12-13 16:42:16
@_author: Ben Laurie 
@_subject: [Cryptography] Satoshi's PGP key. 
In other words: you don't think bitcoins are actually worth money - at
least, not sizeable amounts of it?

@_date: 2015-12-14 21:27:24
@_author: Ben Laurie 
@_subject: [Cryptography] Photon beam splitters for "true" random number 
As soon as you do that, the quantum effects disappear so you're now relying
on the perfection of your beam splitter. You haven't said how that works,

@_date: 2015-12-16 21:05:56
@_author: Ben Laurie 
@_subject: [Cryptography] Satoshi's PGP key. 
The other top-10 richest people have assets that are actually worth money.

@_date: 2015-02-10 04:59:47
@_author: Ben Laurie 
@_subject: [Cryptography] What do we mean by Secure? 
On 9 February 2015 at 16:23, Phillip Hallam-Baker As Bill points out, this is exactly the point of capability systems (he
didn't say it, but it is what he meant). A long time ago we had a choice
between ACLs and capabilities, and we chose the wrong thing.
Capability systems do exist, but we also have a lot of ACL-based
engineering to fix in order to properly use them.

@_date: 2015-02-10 05:09:48
@_author: Ben Laurie 
@_subject: [Cryptography] What do we mean by Secure? 
This is obviously untrue. You can easily prove, for example, that three is
not equal to four.

@_date: 2015-02-15 18:35:19
@_author: Ben Laurie 
@_subject: [Cryptography] Do capabilities work? Do ACLs work? 
Tut tut - no threat model?
When you say "work" my immediate question is: for what?
You talk about access to photos. I suspect you are right (having had
this debate many times) that users (think they) want ACLs. But they
are not without their problems when you start thinking about more
complex artefacts. For example, what about a document that includes
(by reference) a photo. ACLs become annoying/difficult to understand -
now some people can see the photo and some can't. Or when I change the
doc ACL do I mean to change the photo ACL, too? Probably not (consider
removing someone's access from the doc who previously had access to
the photo, for example). Capabilities may not be as easy to understand
for this case, but perhaps they work better.
But how about the other use of ACLs, namely on my own computer. In
this setting ACLs make no sense at all - there is only one user: me.
What I really want from the system, whatever it is, is to protect me
from all the evil s/w I am running. ACLs are a pretty poor fit for
that purpose, and in many cases caps + designation-is-authorisation
make far more sense and are much easier to deal with.
The latter case strikes me as far more clear-cut than the former.
Plus, as someone said earlier, Macaroons, which combine identification
and delegation with traditional cap ideas, may be the best of both
This is one way to implement capabilities for one possible use of
them, but hardly comprehensive.

@_date: 2015-02-16 11:55:51
@_author: Ben Laurie 
@_subject: [Cryptography] Do capabilities work? Do ACLs work? 
Or we could ask what the policy really is? Anyway...
That seems quite a complex way to implement what would normally done
with a powerbox. i.e. a piece of code that holds all the caps and
decides at the time of request whether to grant access or not.
i.e. use a powerbox.
Surprise! Policy that is defined as an ACL looks like ACLs.
The traditional way to implement this in a cap system is via a proxy
that also has access to the accessor's current Area 51status.
I really don't think it is.
Surely that issue is in the definition of the problem (i.e. it is ambiguous)?

@_date: 2015-01-01 21:07:02
@_author: Ben Laurie 
@_subject: [Cryptography] on brute forcing 3DES to attack SIMs 
Wat? None of this makes sense. Presumably this is why you omitted the
next sentence:
"Deploying standard processing power, like the Intel CPU (Core
i7-2600k), would take roughly five years to break DES and more than 20
years to break 3DES."
Right. 3DES has 2 bits more security than DES. Check.
Well, I guess they said more than 2 bits, so its true, right?

@_date: 2015-01-05 22:17:24
@_author: Ben Laurie 
@_subject: [Cryptography] Imitation Game: Can Enigma/Tunney be Fixed? 
Surely not as simple as that - this flaw allowed them to automate a
brute force attack (and perhaps reduce its cost, but my understanding
of the Bombe is that it was fully brute force - reductions came from
intelligence of various kinds).
Increasing the cost of the brute force would still be effective.

@_date: 2015-01-25 14:27:09
@_author: Ben Laurie 
@_subject: [Cryptography] The Crypto Pi 
I'm pretty sure modern FreeBSDs do use it. Can't speak to the pi
particularly, though.
We did some experiments a while back which suggest that you can get
sufficient entropy during startup by measuring device attach times.
Probably worth repeating the experiment on the pi - and enabling this
(I am not sure whether FreeBSD does by default, I got tired of arguing
about it).
I'm not sure what "removing bits from the pool" really means -
extracting n bits from a pool does not, IMO, remove n bits, or even
any large fraction of n, from the pool.

@_date: 2015-01-25 16:41:35
@_author: Ben Laurie 
@_subject: [Cryptography] The Crypto Pi 
My point is I don't believe that entropy_avail really represents a
useful measurement.

@_date: 2015-01-26 18:33:53
@_author: Ben Laurie 
@_subject: [Cryptography] 2008 revision of Bitcoin whitepaper 
Not at all. The conclusion is we do not have a good anonymity
mechanism for HTTP transactions.
Which I entirely agree with.

@_date: 2015-07-23 07:23:06
@_author: Ben Laurie 
@_subject: [Cryptography] Whitening Algorithm 
The repeated XORs make this mildly fishy. For example, if we assume
everything is initialised to 0, then the first byte output is B0, and all
the state bytes are also set to B0.
The second byte out, therefore, is B0 ^ B1, and pmb1 = pmb3 = B0 ^ B1, pmb2
= pmb4 = B1.
Third byte out is B2 ^ B1 and pmb1 = B1 ^ B2, pmb2 = B2 ^ B0, pmb3 = B2 ^
B1 ^ B0, pmb4 = B2.
In other words, I don't think this is doing what you think its doing.
Addition (with carry bit recycled?) might be a better choice.

@_date: 2015-07-28 06:06:14
@_author: Ben Laurie 
@_subject: [Cryptography] =?utf-8?q?Why_Nasdaq_Is_Betting_On_Bitcoin?= 
Which is why they should use something that is _actually_ immutable instead
of Bitcoin.
Surely that's easy - you just add a "mistake correction" transaction.

@_date: 2015-07-31 20:34:11
@_author: Ben Laurie 
@_subject: [Cryptography] How to solve the hen-and-egg problem 
Perhaps you should consider writing those scripts in a language that lends
itself to analysis?

@_date: 2015-06-07 11:08:47
@_author: Ben Laurie 
@_subject: [Cryptography] Simple provably secure stream cipher 
One thing that is already known is that if you rely on the DLP, you're
not provably secure.

@_date: 2015-06-09 09:13:42
@_author: Ben Laurie 
@_subject: [Cryptography] let's kill md5sum! 
OpenSSL command line, of course.
But why BLAKE2? And who cares how fast it is?

@_date: 2015-03-20 09:34:11
@_author: Ben Laurie 
@_subject: [Cryptography] TB2F CAs as (un)official browser policy 
and DigiNotar incidents:
1. Comodo appears to have been hacked via a fake RA login, whereas
DigiNotar actually was owned.
2. Comodo issued eight fake certs, DigiNotar > 500.
3. Comodo knew what certs were issued, DigiNotar did not.
4. Comodo did not sit on the facts for 6 weeks.
I'm not sure what relative size by certs issued (or by validations,
which does seem a better metric) Comodo and DigiNotar were at the time
(anyone got numbers?), but I do know that removing the DigiNotar root
had considerable fallout, particularly if you were Dutch...

@_date: 2015-05-01 10:08:33
@_author: Ben Laurie 
@_subject: [Cryptography] "Trust in digital certificate ecosystem eroding" 
This idea is attractive, but incorrect. All CAs are empowered to issue
certs for all domains. Although its likely that most certs issued by
Turktrust are indeed for Turkish sites, it is by no means guaranteed
to be true for all. What's more, Turks do speak English, amazingly, so
even Turkish sites might be useful to English speakers.

@_date: 2015-05-01 23:47:48
@_author: Ben Laurie 
@_subject: [Cryptography] "Trust in digital certificate ecosystem eroding" 
None of this is news. I fail to see what any of it has to do with
TURKTRUST and your knowledge of Turkish.
I'm pretty sure this problem was obvious 20 years ago.

@_date: 2015-05-04 14:16:52
@_author: Ben Laurie 
@_subject: [Cryptography] "Trust in digital certificate ecosystem eroding" 
Why? DNSSEC has its equivalent of CAs/RAs: registries and registrars.
Why do you think they'll do any better a job of verifying ownership
than CAs do?

@_date: 2015-05-06 22:03:09
@_author: Ben Laurie 
@_subject: [Cryptography] Is there a good algorithm providing both 
On 6 May 2015 at 09:15, Francois BERENGER
Compression is fundamentally problematic.

@_date: 2015-05-09 21:47:33
@_author: Ben Laurie 
@_subject: [Cryptography] Is there a good algorithm providing both 
Surely not. Some plaintexts of the same length compress shorter than
others. That gives me a distinguisher. If I have a distinguisher, it
is not "safe".

@_date: 2015-05-16 22:15:24
@_author: Ben Laurie 
@_subject: [Cryptography] [cryptography] NIST Workshop on Elliptic Curve 
And XP's end of life was when? I'll save you looking it up: April
2014. Apparently "so old" is 1 year! Assuming, of course, as we know
didn't happen, everyone believed the end of life and stopped using XP.

@_date: 2015-11-02 11:01:49
@_author: Ben Laurie 
@_subject: [Cryptography] RIP Tommy Flowers 
The victors write history, don't they?
Z1: 1938
Z2: 1939
Z3: 1941
Colossus: 1943
Eniac: 1946

@_date: 2015-11-21 14:12:26
@_author: Ben Laurie 
@_subject: [Cryptography] WSJ: WH wants to meet Techies in DC re encryption 
There's only one sentence in this whole thing that's in any way relevant to
the crypto debate, and it's this one:
But for some reason this non-use of encryption has led to a difficult
position for those advocating encryption. Wat?
You might as well say that in the wake of the Paris attacks, WH wants to
talk to people about global warming. Or the kitten shortage.

@_date: 2015-10-30 11:12:37
@_author: Ben Laurie 
@_subject: [Cryptography] Hiding parties identities 
What's wrong with that? If the server shares a public key which is used by
everyone to encrypt, that's fine, isn't it?

@_date: 2015-09-01 17:29:06
@_author: Ben Laurie 
@_subject: [Cryptography] SRP for mutual authentication - as an 
And now I have found it, and it works even less well than I remembered:

@_date: 2015-09-06 19:23:30
@_author: Ben Laurie 
@_subject: [Cryptography] Feedback welcome on an idea 
The beatings will continue until you reveal all the keys.

@_date: 2016-08-22 21:13:25
@_author: Ben Laurie 
@_subject: [Cryptography] Electronic currency revived after 20-year hiatus 
There's no reason to believe miners are economically rational within
the context of the Bitcoin protocol. Recent counterexample is Chandler
Guo declaring he would attack Ethereum Classic...

@_date: 2016-08-29 23:01:28
@_author: Ben Laurie 
@_subject: [Cryptography] ORWL - The First Open Source, 
I will agree that they are not _yet_ formally verified. However, that
work is under way.
I think it is already clear that the tide is turning.

@_date: 2016-08-29 23:27:23
@_author: Ben Laurie 
@_subject: [Cryptography] ORWL - The First Open Source, 
RISC-V did not exist when this research was started, however, CHERI
will fit on top of any conventional CPU architecture, so there's no
problem doing that.
Also, MIPS as implemented does not have IP issues - and the whole
thing is open source.

@_date: 2016-12-02 18:22:09
@_author: Ben Laurie 
@_subject: [Cryptography] OpenSSL and random 
I already explained how: measure device startup times (and by "device"
I mean the kind of devices you can do nothing until they're running,
like USB hubs and boot disks).

@_date: 2016-12-19 22:30:50
@_author: Ben Laurie 
@_subject: [Cryptography] Photojournalists & filmmakers want cameras, 
I guess your one comfort in enhanced interrogation will be that
there's no way to make it stop.

@_date: 2016-02-27 22:35:10
@_author: Ben Laurie 
@_subject: [Cryptography] From Nicaragua to Snowden - why no national 
Ah, but AES is from the right nation.
Its a crazy idea, I know, but there might be some nations who are not so
keen on other nations mandating their crypto.
IETF has pretensions of being worldwide, but really, its all about the US,
with grudging support of their close allies.
Is there _any_ non-national crypto?

@_date: 2016-02-27 23:36:13
@_author: Ben Laurie 
@_subject: [Cryptography] From Nicaragua to Snowden - why no national 
Run and judged by the US.
Other contests like Nessie have not produced standards that people want.
Not run and judged by the US.
In what sense is AES not a national cipher? Its original name? Seriously?

@_date: 2016-01-10 09:56:15
@_author: Ben Laurie 
@_subject: [Cryptography] Verisimilitrust 
That's not actually true for most revocations, at least in Chrome (I
don't know what other browsers do). OK, there are some where the
browser vendor knows that the cert needs to be revoked, and so revokes
it, but the majority of revocations are from info provided by CAs.

@_date: 2016-01-11 21:28:47
@_author: Ben Laurie 
@_subject: [Cryptography] Verisimilitrust 
Selective quoting for the win. It also says:
"We maintain an internal list of crawled CRLs. The CRLs from that set
go to make up the published CRLSet. For size reasons, the list doesn't
include all CRLs - EV CRLs and CRLs with good reason codes are taken
in preference. CRLs which cover intermediates are typically small and
valuable so we try to take as many as possible."
Only if you stop reading half way down the page.
It is unsurprising that browser vendors are reluctant to rely on CAs
to revoke their own roots.

@_date: 2016-01-12 02:15:11
@_author: Ben Laurie 
@_subject: [Cryptography] Verisimilitrust 
Revocations that are derived from CRLs are only "provided by the
browser vendor" in the same sense that CRLs are "provided by your home
router", as is the whole of the rest of the Internet.
Or, to put it another way: if CAs didn't do the majority of
revocations, who would do it instead? Not the browser vendors, that's
for sure.
Which is the core issue: how do you bind domain names (or identities
or whatever) to keys and deal with the inevitable errors in doing so
without introducing some kind of third party? What realistic system do
you propose to replace the CA gravy train with?

@_date: 2016-03-06 21:19:26
@_author: Ben Laurie 
@_subject: [Cryptography] Secret key agreement by public discussion from 
The short answer, AIUI, is that you can exploit a noisy broadcast
system such that the two cooperating parties get an advantage over the
eavesdropper. In retrospect, this seems obvious (e.g., A tells B
something, B asks A to repeat certain parts B thinks were badly
received, A resends them. E gets noisy versions of the original
transmission, the request for repeats, and the repeats. It seems
inevitable E ends up knowing a little less than B).
Once you have a disparity of information, you can leverage that up into a key.
The snag is, we have worked hard to eliminate the noise from broadcast. :-)
But its a really interesting idea.

@_date: 2016-03-09 10:35:29
@_author: Ben Laurie 
@_subject: [Cryptography] Secret key agreement by public discussion from 
Bob can, though (IIRC this weakness is discussed in the paper).

@_date: 2016-05-10 10:25:58
@_author: Ben Laurie 
@_subject: [Cryptography] [cryptography] Show Crypto: prototype USB HSM 
Oh no they haven't - that's simply projecting a static image, its not steerable.

@_date: 2016-05-23 22:07:32
@_author: Ben Laurie 
@_subject: [Cryptography] Entropy Needed for SSH Keys? 
Gotta say, I really like this analysis.
Why limit yourself to these two possibilities?

@_date: 2016-11-29 19:04:53
@_author: Ben Laurie 
@_subject: [Cryptography] [FORGED] Re: OpenSSL and random 
But what they do have is instruction counters and loads of devices
that take a random amount of time to initialise. I demonstrated quite
a while back that there's enough entropy at startup just from that to
seed your RNG, even in quite cut-down machines, and in VMs.

@_date: 2016-10-01 23:02:19
@_author: Ben Laurie 
@_subject: [Cryptography] distrusted root CA: WoSign 
I am so sick of this lame rhetoric. What is your proposed solution?
Put up or shut up.
More polite version: yes, it is a hard problem, but how do you solve
it without some kind of central authority? On what basis can the end
user validate a certificate, other than some authority doing it on
their behalf? Of course I think that adding transparency to those
authorities is a major win, but other than that, where do you go?
Alternatives like DANE are just shuffling the deck chairs on the
Titanic. What can you do that is radically better than CAs +

@_date: 2016-10-02 18:33:54
@_author: Ben Laurie 
@_subject: [Cryptography] distrusted root CA: WoSign 
I don't understand why that makes DANE strictly better.
* point in time applies to both protocols, surely? Except in the DANE
case the "point" is every time the DNS lookup is done - i.e. far more
often than in DV.
* cursory "verification" of domain control is common to both protocols.
* DNS registries/registrars have a _far_ worse track record than CAs do.
Chrome did support it for a while. No-one used it. Probably it was
premature, unfortunately.
DNSSEC also needs transparency, for exactly the same reason CAs do.
And there needs to be a way to kick DNS registries/registrars out (for
being crap), which doesn't appear to exist currently.
Transparency is orthogonal to the protocol that is being transparented.

@_date: 2016-10-02 18:43:28
@_author: Ben Laurie 
@_subject: [Cryptography] distrusted root CA: WoSign 
anon-DH is not the same thing. Not saying browsers should not have
allowed it, but clearly it has different properties - in particular,
revocation is impossible.
I am confused by this claim: you can add your own roots to browsers...
The problem PKI demonstrably does solve is that when I connect to
google.com (or a host of other well-know domains) I really am
connecting to them.
I don't know why you'd expect it to solve phishing - that is to do
with linking identity to domain names, something the PKI doesn't
really claim to do (well, maybe EV, but studies show that isn't a
great success). Or malware, which seems like an entirely orthogonal
Of course, it is easy to claim that PKI should be "sort of expected"
to solve these problems - but in the absence of any plausible proposal
to solve them, I call bullshit. I "sort of expect" you to solve these
problems, but you demonstrably have not. Nor even proposed a viable
way to do so.
Don't get me wrong: I would love these problems to be solved, but I
don't know how (well, I think transparency helps :-). Complaining that
various things don't do it is not really progress.

@_date: 2016-10-02 18:50:35
@_author: Ben Laurie 
@_subject: [Cryptography] distrusted root CA: WoSign 
Clearly that is a dumb idea.
But this is key: how would a search engine acquire this public key,
other than by doing exactly what CAs do? All you are doing is rolling
the CA function into the search engine function. No actual difference
has been made. Apart from a massive reduction in competition, that is.
You can have ssh-style continuity, that is what pinning gives you.
Turns out that's a large gun aimed squarely at your foot for most
Not sure what point you're making here. The "really exceptional
situation" was a CA demonstrably failing to do their job.
Once more, all you are doing here is renaming "CA" to "browser vendor".
Isn't that exactly what CT does? Implemented, btw, by one of the top
search engines.
i.e. the search engine returns the URL, CT ensures that the
corresponding cert is actually the one the owner of the URL intended.
The CA does the paperwork.

@_date: 2016-10-03 06:10:26
@_author: Ben Laurie 
@_subject: [Cryptography] distrusted root CA: WoSign 
Users have a voice, as Peter well knows, at least in Mozilla's
selection and vetting of CAs. Microsoft and Apple could do the same
I already responded to Viktor.
Err ... CT?

@_date: 2016-10-03 06:13:59
@_author: Ben Laurie 
@_subject: [Cryptography] distrusted root CA: WoSign 
Because browser vendors don't want to be CAs, it seems.
I agree.
I don't understand this. It sounds like he's talking about client certs?
What new mechanisms?

@_date: 2016-10-03 06:16:34
@_author: Ben Laurie 
@_subject: [Cryptography] distrusted root CA: WoSign 
"If ... back-dating is discovered (by any means), Mozilla will
immediately and permanently revoke trust in all WoSign and StartCom

@_date: 2016-10-03 06:21:27
@_author: Ben Laurie 
@_subject: [Cryptography] distrusted root CA: WoSign 
Change to what?
Dude. You are talking to a guy who has spent four years improving the
system instead of complaining it can't be improved. Don't call me
The problem with _your_ lazy slapdown is it is just more lame rhetoric.
I am not suggesting you write a patch, I am suggesting you propose
something that actually works instead of whining about how the system
is fixed. So far, I have seen no such proposal.
Once more: what is the change that should be made?

@_date: 2016-10-03 06:23:31
@_author: Ben Laurie 
@_subject: [Cryptography] distrusted root CA: WoSign 
Whitelisting is, of course, technically possible, but its _big_. Even
the whitelist for EV certificates was close to what Chrome would
tolerate - I doubt there will actually be a whitelist, just

@_date: 2016-10-03 06:35:53
@_author: Ben Laurie 
@_subject: [Cryptography] distrusted root CA: WoSign 
Seems a bit circular - you claim revocation is only done for a "token
subset" and then explain why it is only needed for a subset (token or
How do you do proper mutual authentication? I don't mean at the
protocol level, I mean how do I authenticate the keys used to secure
the exchange "properly"? This is precisely my point about identity...
Installation of a browser is manageable, but installation of a second
thing alongside is not? Still confused.
I know. But I didn't read a proposal for actually doing that.
I know. And I haven't read a proposal for actually doing that either.
Other than EV, that is.
In the case of Amazon I am fine with knowing I've connected to
 because I know that _is_ Amazon.
Cert pinning doesn't scale - that's why I developed CT.
I did see last time you raised this, and I responded, and you ignored
my response, because it inconveniently pointed out that your solution
has been demonstrated not to work.
My part of this loop is to decline to read 1,000 references. Point me
to a single one that proposes a workable solution, don't hide behind
an unmanageable number of references.
I agree the whole thing sucks. I don't think we'd be better of with
nothing in its place.

@_date: 2016-10-03 11:50:34
@_author: Ben Laurie 
@_subject: [Cryptography] distrusted root CA: WoSign 
I disagree. The question is who has power to influence browser root
programs, surely, not who gets to attend what meeting?
I didn't mention Google because Google doesn't have a root program. :-)
When people think DANE is some kind of magic bullet to solve key
distribution there is definitely need to push back on that notion -
the problem being that DNS is even more unreliable than CAs, has a
root program that is even less democratic than the CA ecosystem,
relies on a protocol that has proved to be essentially undeployable,
so far, and is in need of a CT-like mechanism (which presumably will
be no easier to deploy than CT is, and hasn't even been started yet).
SMTP/TLS is definitely a mess!
Cool, but we know it takes at least a decade to deploy something like
this (which is why CT has alternate mechanisms - I suggest doing
something similar as an interim measure for dnssec).
Yeah, I think that's mostly a good idea, except for the distribution
and synchronisation problems.
BTW, to be totally clear, I really don't like the CA system. When I
started CT I hoped it would ultimately provide a way to replace CAs
with something better, but after 5 years of thinking about it, I still
haven't figured out what the something better is!
The core problem, it seems to me, is what you do when the key in the
database is wrong. I don't have an answer for that that doesn't look
very CA-like.

@_date: 2016-10-13 09:58:20
@_author: Ben Laurie 
@_subject: [Cryptography] Blockchain to Secure Nuclear Weapons? 
Curious what gap you think there is? Or do you mean CT does provide
the "more" that is needed?

@_date: 2016-10-13 15:23:15
@_author: Ben Laurie 
@_subject: [Cryptography] Blockchain to Secure Nuclear Weapons? 
Which requires clients to have a complete copy of the blockchain,
right? Its not efficient, though. That's why we're doing Trillian
Sounds like Trillian.

@_date: 2017-08-27 05:49:09
@_author: Ben Laurie 
@_subject: [Cryptography] 1/1000'th of a wavelength antennae 
Surely not. What they're saying is that 30 MHz - 3 GHz _all_ have
large wavelengths (10m - 10cm).

@_date: 2017-12-23 22:05:16
@_author: Ben Laurie 
@_subject: [Cryptography] paragraph with expected frequencies 
A sample from this thread will do - a snippet for the beginning yields:
 858
 506 e
 442 t
 362 a
 350 o
 312 n
 307 i
 285 r
 241 s
 215 h
 175 l
 174
 159 c
 144 _
 134 y
 131 p
 130 d
 122 u
 112 g
 105 m
  96 w
  94 f
  85 .
  73 b
  72 -
  36 2
  35 :
  34 ,
  33 k
  33 0
  30 q
  29 >
  29 /
  26 v
  23 T
  22 x
  21 I
  20 z
  18 1
  16 D
  15 @
  14 E
  13 '
  13 "
  11 F
  11 A
  11 7
  10 W
  10 =
  10 <
   9 j
   9 O
   8 R
   7 S
   6 M
   6 C
   6 )
   5 K
   5 H
   5 (
   4 U
   4 P
   4 4
   3 L
   3 ?
   3 5
   3 3
   2 G
   2 B
   2 6
   1 ]
   1 [
   1 Y
   1 V
   1 J
   1 ;
   1 9
   1 %
   1 !

@_date: 2017-12-24 10:22:09
@_author: Ben Laurie 
@_subject: [Cryptography] Bitcoin, fork you very much 
Eh? That's _always_ the rule. That's what "length" means.

@_date: 2017-02-11 10:48:09
@_author: Ben Laurie 
@_subject: [Cryptography] Fwd: [Trans] Internet-level Consensus - new list 
Step one, of course, is to recognise that complete consensus is
impossible. Then the argument starts about which set of compromises
are preferable...

@_date: 2017-02-21 21:16:19
@_author: Ben Laurie 
@_subject: [Cryptography] Security proofs prove non-failproof 
My understanding is that Peter is correct, and none of them run seL4.
Its a popular misconception.
OTOH, I think formal methods really are becoming useful.

@_date: 2017-02-24 05:51:23
@_author: Ben Laurie 
@_subject: [Cryptography] Verification Tools 
In relation to the thread about verification of code, I should mention
the collection of tools and other stuff I've been curating in the wake
of the two (so far) HACS (High Assurance Cryptographic Software)
PRs welcome!

@_date: 2017-01-16 04:32:51
@_author: Ben Laurie 
@_subject: [Cryptography] ZK meeting scheduling protocol? 
This is almost the same as a problem I'd like to solve, which is this:
I travel a fair amount. I would quite like to be able to meet up with
friends/acquaintances/interesting strangers, who may also travel
frequently, when they happen to be in the same place as me, but I
don't want to publish a detailed itinerary, and nor do they.
Your phrasing makes me realise that this is a well known problem:
private set intersection, There's plenty of protocols in the
In your case, participants each make a set of available time slots,
and that's what they intersect. In my case, I guess I want a list of
time slots and approximate locations.
Since the protocols (AFAIK) rely on exact matching, these sets are
going to be a bit painful to make, but it seems possible (e.g. if I am
looking for a 1 hour meeting and I have a 2 hour slot available, then
I might list every hour long slot in that window with 1 minute
Most of the protocols I've seen are two party (and sometimes one way)
which may be a problem. But I haven't checked carefully yet.

@_date: 2017-07-01 06:39:35
@_author: Ben Laurie 
@_subject: [Cryptography] OpenSSL CSPRNG work 
You're already broken if someone knows your internal state.
No it isn't.
This is an argument against mixing in _actually_ non-random sources, not
_potentially_ non-random sources. If they are also potentially random, then
they should be considered.
I'm not making the decisions here - and its hard to tell from this thread
what decisions are being made!
A design proposal to comment on would be nice.

@_date: 2017-07-03 09:31:55
@_author: Ben Laurie 
@_subject: [Cryptography] actual journalism, was LRB article, 
Confused by this - Merkle trees inherently don't grow to enormous depth.

@_date: 2017-07-07 21:20:23
@_author: Ben Laurie 
@_subject: [Cryptography] What is "chameleon hash"? 
For Certificate Transparency and Trillian this has been discussed.
You don't need to do anything clever: you replace the offending entry with
an entry that says "I'm a deleted entry, and here's the reason, and here's
the hash of what used to be here". You then add an attestation to the
deletion to the end of the log and you're done.

@_date: 2017-03-04 17:19:58
@_author: Ben Laurie 
@_subject: [Cryptography] TPM and SHA-1 
Certainly the current attacks would require writing code that switched
evil behaviour on based on the settings of some bits. The whole point
of attestation is to prove you're running some particular code,
therefore the evil code would be shown to the victim (though in a form
that made it not active). That seems somewhat hard to pull off, but
not impossible.
BTW, I don't know how SHA-1 is used for attestation, so maybe it
entirely avoids this problem by using, say, an HMAC with a random key.

@_date: 2017-03-12 12:33:35
@_author: Ben Laurie 
@_subject: [Cryptography] Secret Handshake problem. 
This seems impossible - you'd just check each plate in the car park,
making it O(n) at worst.
But the normal meaning of enumeration ("give me a list of abusive
plates") should be hard.

@_date: 2017-03-25 01:35:00
@_author: Ben Laurie 
@_subject: [Cryptography] Google distrusts Symantec for mis-issuing 30, 
In what sense are you trusting Google? CT provides the evidence of
whatever Symantec did. Google say exactly what they're doing about it.
You can verify the code does that and build it yourself if you want.
Where did trust come into this?

@_date: 2017-05-06 22:43:52
@_author: Ben Laurie 
@_subject: [Cryptography] CFB/OFB/CTR mode with HMAC for key stream 
On 6 May 2017 at 14:47, Markus Ottela via cryptography
Say breaking AES is k^n (where k is whatever your time is a polynomial
of :-)). Breaking triple-AES is k^2n (+storage), which is quite a lot
more than three-fold, unless n or k are very small.

@_date: 2017-11-13 10:57:28
@_author: Ben Laurie 
@_subject: [Cryptography] Is ASN.1 still the thing? 
JSON is a terrible interchange format, as I've been discovering to my
cost with objecthash:  - I
should not have used JSON as the example.
Most obvious problems: different capabilities in different languages,
can't represent ints over 2^53, no way to transmit raw bytes natively.
This is precisely why I made objecthash: so you hash the parsed
object, not its serialisation. As a result, objecthash is
serialisation agnostic.
It turns out this raises problems of its own, the most obvious being
"what do you mean by an object?" - but still, it seems useful. I will
be working on a new version starting ... soon.

@_date: 2017-09-14 19:05:14
@_author: Ben Laurie 
@_subject: [Cryptography] letsencrypt.org 
Hmm. I guess I just didn't parse it as you intended. :-)
CT doesn't prevent them getting a cert, btw, it just ensure you know they have.
You are checking CT for your domains, aren't you?

@_date: 2018-11-13 05:04:31
@_author: Ben Laurie 
@_subject: [Cryptography] Brute force circa 1939 
The US declined Turing's assistance. Guess they were pretty naive.

@_date: 2018-10-04 17:46:25
@_author: Ben Laurie 
@_subject: [Cryptography] Elixxir 
He's published a "technical brief" without a threat model?

@_date: 2020-02-20 18:46:05
@_author: Ben Laurie 
@_subject: [Cryptography] UK "HCSEC" UK-cleared engineers try to prove 
This is all very interesting - and it seems to me that the clampdown on
interacting with Huawei is going to have the opposite effect to that
intended - i.e. move them even further away from employing secure practices
and up-to-date packages...

@_date: 2020-01-12 05:44:57
@_author: Ben Laurie 
@_subject: [Cryptography] retro crypto 
Are you assuming the contents of the EPROM is secret? If so, why not use it
as a OTP? If not, then surely this construction is trivially insecure?

@_date: 2020-01-21 18:58:19
@_author: Ben Laurie 
@_subject: [Cryptography] Redundant Array of Cryptographic Services 
Not quite so simple. You need some way to prevent spam/kiddyporn.

@_date: 2020-07-28 21:05:29
@_author: Ben Laurie 
@_subject: [Cryptography] Terakey, 
Principles
On Tue, 28 Jul 2020 at 00:49, Arnold Reinhold via cryptography <
Tens of million times bigger means you can do 3s of thousands times as much
traffic. I suspect we do a lot more than that, relative to WWII.

@_date: 2020-05-05 09:57:56
@_author: Ben Laurie 
@_subject: [Cryptography] The EFF 650 CAs lie 
Which is exactly why constraints had to be critical.
