
@_date: 2003-11-23 00:14:32
@_author: Florian Weimer 
@_subject: US antispam bill is death to anonymity 
Why?  Can't you register a domain using a proxy?  I think this claim is
This is a more severe problem.  However, if anonymizers were actually
used to disseminate commercial email messages to a relevant degree, I
think the providers of such service such be held responsible.  Sending
spoofed IP packets is a similar problem at a lower protocol level,
causing lots of trouble, and I think the network operator who permits
spoofed addresses to originate from his network is partly responsible if
something goes wrong.
However, there are obvious workarounds, such as an opt-in approach for
the receipt of anonymized email.
But I wonder how this anti-spam bill relates to manual message
forwarding (which typically destroys most message headers).

@_date: 2003-10-06 17:52:57
@_author: Florian Weimer 
@_subject: Simple SSL/TLS - Some Questions 
A MIT-stlye license or a BSD-style license without advertizing clause
would be appropriate.
What about "Simple Lightweight TLS" (SLT)? 8-)
This one is already taken.
BTW, I would think that RMS would recommend a BSD-style license for this
kind of project (he did so for Ogg Vorbis).
Have you looked at GNU Pth?  It's a non-preemptive threading package
which should be reasonably portable.
I don't know the TLS/ASN.1 formats by heart, but maybe it's possible to
receive the complete blob (possibly involving I/O multiplexing) without
parsing it?  IOW, the parser starts only after the communication layer
has finished transmitting the message.

@_date: 2003-10-07 16:59:18
@_author: Florian Weimer 
@_subject: Open Source (was Simple SSL/TLS - Some Questions) 
Who's the customer, the one that buys and deploys the ATMs, or the
actual customer who interacts with it?
I can only recommend to demand source code before purchase/deployment,
especially for embedded devices which are supposed to communicate
securely over an untrusted network.  Custom crypto protocols appear to
be quite common in this area.
Even if you lack the necessary time and experience to detect subtle
flaws in the implementation, it's likely that you'll discover a few
surprises.  Did you know that proprietary Blowfish libraries exist which
are extremely easy to use?  They even provide a default key which is
used unless another key is imported explicitly.  This neatly solves all
key management problems.  (The key, by the way, is the third one you
would check if you had to guess it.)
There are few licenses today which require distribution of source code
to end users if they don't receive binaries.  One prominent exception is
the Afferro (sp?) GPL.
If you want to see widespread adoption of your Better TLS Library, you
should avoid such licensing experiments.  Use a BSD or MIT-style
license instead.

@_date: 2003-10-11 16:32:25
@_author: Florian Weimer 
@_subject: Open Source (was Simple SSL/TLS - Some Questions) 
Has anybody tried to revert the political decision not to support
password-based authentication with IPsec?
[Moderator's note: there was no such political decision to my
 knowledge. In fact, there was a requirement for manual keying from
 very early on in the protocol's life. --Perry]

@_date: 2003-10-16 12:45:06
@_author: Florian Weimer 
@_subject: WYTM? 
It's not *that* difficult to obtain a certificate for something
involving a well-known brand.  The certificate generation process
appears to be fully automated, and we know that it has already failed.
Furthermore, the certificate says nothing about the contents of the
site.  You can register something like REFRESH-ACCOUNT.COM and collect
passwords using an Ebay or AOL imitation, and none of the SSL CAs will
refuse to certify your key material for use with REFRESH-ACCOUNT.COM.
So why do we see so little fraud involving HTTPS sites?  I'd guess
that's because the current social engineering tactics are effective
without the " mark.  Most users look for assurances of their
privacy, and if the web site says "128 bit encrypted", they feel safe,
indepedent of the actual transport channel.

@_date: 2004-04-09 23:40:31
@_author: Florian Weimer 
@_subject: voting 
I fully agree, but there is a wide variety of voting schemes out there,
of varying complexity.  In a ballot with only very few options, your
proposal makes sense.  But in some cases, the complete description of a
vote doesn't necessarily fit onto an A4 paper sheet.  Our own municipal
elections are so complicated that you fill in your votes at home and
bring the paperwork to the election office.  In the U.S., some of the
simple votes are linked to dozens of plebiscites, and you'll have a hard
time to print that onto a small piece of paper, too.
But I can't see why computerized voting is so important.  Here in
Germany, the pencil-and-paper method is doing just fine.  Volunteers do
the counting, so there is no monetary incentive to automate this
process.  It means that we have to wait a few hours (or even days, in
case of the municipal elections) before preliminary official results are
available, but this doesn't seem to be a significant problem, IMHO.
However, I'm sure our own paper-based voting system would fall apart if
subjected to the same scrutiny as Diebold's voting machines.  It's just
a different kind of insecurity.

@_date: 2004-08-21 22:00:59
@_author: Florian Weimer 
@_subject: First quantum crypto bank transfer 
* R. A. Hettinga:
Not quite correct, the first bank transfer occurred earlier this year,
in a PR event arranged by the same group:
However, I still don't believe that quantum cryptography can buy you
anything but research funding (and probably easier lawful intercept
because end-to-end encryption is so much harder).

@_date: 2004-08-22 16:16:40
@_author: Florian Weimer 
@_subject: First quantum crypto bank transfer 
* Jerrold Leichter:
I'm the last person to argue against basic research, but I'm really
against presenting it as if had direct practical relevance.  Basic
research such receive government funding, but not based on the false
claim that it can secure bank transfers.
I fully agree.  Experimental quantum physics *is* important, but much
more from a physics point of view than from a cryptography point of
My trouble with quantum key distribution is that at the current stage,
the experiments are stunning, but it's snake oil from a cryptography
Have you actually at some of the quantum key distribution papers?  The
ones I examined even lack such a simple thing as a threat model, and
as a result, the authors completely miss man-in-the-middle attacks
where the attacker splits the fiber into two pieces, runs two
instances of the QKD protocol, and reencrypts the communication after
key distribution.
If we postulate that man-in-the-middle attacks are non-existent,
convential cryptography is suddenly much stronger, too. 8-)

@_date: 2004-08-23 11:02:34
@_author: Florian Weimer 
@_subject: First quantum crypto bank transfer 
* Bill Stewart:
But this doesn't scale.  You'd need dark fiber to all communication
partners.  So if quantum key distribution was mandated for
applications involving more than just a handful communication
partners, you'd need relays (or rather unlikely advances in optical
circuit switching).
By the way, the complete bashing of the recent QKD experiment is
probably not totally deserved.  Apparently, the experimenters used a
QKD variant that relies on quantum teleportation of photons.  This QKD
variant is currently *not* available commercially, and the experiment
itself could well be an important refinement of Zeilinger's earlier
work in this area.

@_date: 2004-12-11 22:24:09
@_author: Florian Weimer 
@_subject: Blinky Rides Again: RCMP suspect al-Qaida messages 
* R. A. Hettinga quotes a news article:
As far as I know, these news stories can be tracked back to a
particular USA Today story.  There's also been a bunch of stories how
a covert channel in TCP could be used by terrorists to hide their
Unfortunately, when such stories are retold for the second time, the
"could be used" part tends to change to "is used". 8-(

@_date: 2004-12-12 23:52:11
@_author: Florian Weimer 
@_subject: Blinky Rides Again: RCMP suspect al-Qaida messages 
* Adam Shostack:
However, they use some form of crypto.  From a recent press release of
our attorney general:
(Very rough translation: "The persons are accused of being members of
"Ansar al Islam" and planning the assassination of the Iraqi prime
minister during his visit to Germany on the 2nd and 3rd December,
2004.  This follows from the contents of a multitude of encrypted
telephone calls the accussed exchanged since November 28, 2004.")
Probably, they just used code words, and no "real" cryptography.  I'm
trying to obtain a confirmation, though.

@_date: 2004-12-19 17:24:59
@_author: Florian Weimer 
@_subject: SSL/TLS passive sniffing 
* Victor Duchovni:
The Debian folks have recently stumbled upon a problem in this area:
Generating the ephemeral DH parameters is expensive, in terms of CPU
cycles, but especailly in PRNG entropy.  The PRNG part means that it's
not possible to use /dev/random on Linux, at least on servers.  The
CPU cycles spent on bignum operations aren't a real problem.
Would you recommend to switch to /dev/urandom (which doesn't block if
the entropy estimate for the in-kernel pool reaches 0), and stick to
generating new DH parameters for each connection, or is it better to
generate them once per day and use it for several connections?
(There's a second set of parameters related to the RSA_EXPORT mode in
TLS, but I suppose it isn't used much, and supporting it is not a top

@_date: 2004-12-22 19:43:13
@_author: Florian Weimer 
@_subject: SSL/TLS passive sniffing 
* Victor Duchovni:
Is this the only criticism of /dev/urandom (on Linux, at least)?  Even
on ancient hardware (P54C at 200 MHz), I can suck about 150 kbps out
of /dev/urandom, which is more than enough for our purposes.  (It's
not a web server, after all.)
I'm slightly troubled by claims such as this one:
I know that Linux' /dev/random implementation has some problems (I
believe that the entropy estimates for mouse movements are a bit
unrealistic, somewhere around 2.4 kbps), but the claim that generating
session keys from /dev/urandom is a complete no-no is rather

@_date: 2004-12-22 22:51:42
@_author: Florian Weimer 
@_subject: SSL/TLS passive sniffing 
* John Denker:
Not even for the public parameters?
We are talking about a stream of several kilobits per second on a busy
server (with suitable mailing lists, of course).  This is impossible
to obtain without special hardware.
How many bits per second can you produce using an off-the-shelf sound
card?  Your paper gives a number in excess of 14 kbps, if I read it
correctly, which is surprisingly high.
It's an interesting approach, but for a mail server which mainly sends
to servers with self-signed certificates, it's overkill.  Debian also
supports a few architectures for which sound cards are hard to obtain.
And we would separate desktop and server implementations because the
sound card is used on desktops.  I'd rather sacrifice forward secrecy
than to add such complexity.

@_date: 2004-07-06 06:39:53
@_author: Florian Weimer 
@_subject: Using crypto against Phishing, Spoofing and Spamming... 
* Amir Herzberg:
The trusted credentials area is an interesting concept.  However,
experience suggests that given the current business models, we cannot
build the required logotype registry.  All registries which are used
on the Internet (for IP address assignments, BGP prefixes, DNS names,
and even X.509 certificates) are known to fail under stress.

@_date: 2004-07-10 18:07:52
@_author: Florian Weimer 
@_subject: Using crypto against Phishing, Spoofing and Spamming... 
* Amir Herzberg:
A body which registers visual elements etc. and assigns them to an
There are simply too many of them, and not all of them implement
checks for conflicts.  I'm pretty sure I could legally register
"Metzdowd" in Germany for say, restaurant service.
These certificates would only have value if there is extensive
verification.  We probably lack the technology to do that cheaply
right now, and the necessary level of international cooperation.
But it is, it all boils down to who does the verification, and who
pays for it.  Identifying someone is not that hard, of course, but how
do you know if he or she is authorized to use a resource (be it a
trademark or an IP subnet)?
You still have to handle revocation.  Mistakes will happen. 8-/
Ah, I missed that part.  This could be rather helpful if users are
able to understand the concept.  Have you run any usability tests?
BTW, you can emulate it by removing all root CAs from your browser,
and just relying on previously stored certificates.  Works rather
well, although some people who have different threat models sneer at

@_date: 2004-07-10 18:46:03
@_author: Florian Weimer 
@_subject: Using crypto against Phishing, Spoofing and Spamming... 
* Hal Finney:
Wouldn't typical phishing attacks just read like:
I talked to a financial services provider recently, and they were
scared when I proposed that.  It brings back horrible memories.  To
them, the avent of Java-less SSL banking was a real breakthrough.  It
seems that end-user support issues have plummeted.
Even some form of pre-registration of banking sites seems infeasible.
In Germany, we have a standard called HBCI which supports smart cards
and signed transactions (providing, in theory, end-to-end
verifiability), but support overhead seems to be much larger.
There still remains the issue that you can provide a good visual
approximation to any peace of software just by using JavaScript and
HTML.  I fear that too many users would fall for that. 8-(
But is it so harmful?  How much money is lost in a typical phishing
attack against a large US bank, or PayPal?  (I mean direct losses due
to partially rolled back transactions, not indirect losses because of
bad press or customer feeling insecure.)

@_date: 2004-10-25 22:44:03
@_author: Florian Weimer 
@_subject: Are new passports [an] identity-theft risk? 
* Dave Emery:
Those that perform actual cryptographic operations can store tens of
thousands of bits.  Even older tags (without proper crypto) easily
reach 2**15 bits.  These tags (for example, MIFARE) are usually not
considered RFID tags by privacy activists, even though they can be
read at some distance (but not with COTS equipment).  Contactless
readers are only used for user comfort (you can leave the card in your
purse) and to counter vandalism, not for tracking purposes.
The tags you are referring to are RFID tags used in logistics which
usually provide only very, very few bits (which sometimes can't even
be changed).

@_date: 2004-09-23 23:50:19
@_author: Florian Weimer 
@_subject: AOL to Sell Secure ID Tags to Fight Hackers 
* R. A. Hettinga:
AOL appears to allow you to disable PassCode for your account, so this
is only of limited usability against phishing scams.  AOL even fails
to stress that you must never enter the PassCode serial number during
the normal login process. 8-(

@_date: 2005-08-04 15:58:13
@_author: Florian Weimer 
@_subject: Cross logins 
* James A. Donald:
SXIP is a relatively open effort in that direction.  The rootsite
seems to be proprietary, though.

@_date: 2005-08-10 16:11:31
@_author: Florian Weimer 
@_subject: spyware targets bank customers. news at 11. 
* Perry E. Metzger:
I should point out that most players in the field don't rush to the
press with their findings, in order not to impact a pending law
enforcement investigation.

@_date: 2005-08-10 19:49:32
@_author: Florian Weimer 
@_subject: spyware targets bank customers. news at 11. 
* Adam Fields:
You mean this part?
AFAIK, the FBI is a bit like a black hole, so it's a bit hard to work
with them.  On the other hand, not disclosing the details of an
ongoing criminal investigation to non-trusted individuals (and these
people are apparently new to the field) is usually a good idea.
Filing a complaint doesn't mean you are trustworthy.
(However, this has little to do with cryptography. 8-)

@_date: 2005-08-17 14:14:28
@_author: Florian Weimer 
@_subject: How many wrongs do you need to make a right? 
* Peter Gutmann:
Can't you strip the certificates which have expired from the CRL?  (I
know that with OpenPGP, you can't, but that's a different story.)
OTOH, I wouldn't be concerned by the file size, although it's
certainly annoying.  I would be really worried that the contents of
that CRL leaks sensitive information.  At least from a privacy point
of view, this is a big, big problem, especially if you include some
indication which allows you to judge the validity of old signatures.

@_date: 2005-08-17 14:15:40
@_author: Florian Weimer 
@_subject: no visas for Chinese cryptologists 
* Udhay Shankar N.:
Didn't something similar happen at the FIRST conference in Hawaii a
couple of years ago?  It's sad that it's going to happen again next
year. 8-(

@_date: 2005-08-17 15:24:17
@_author: Florian Weimer 
@_subject: How many wrongs do you need to make a right? 
* Steven M. Bellovin:
This doesn't completely eliminate the data leak, as a long as the
certificates were used in end-to-end communications.  Analysis for
relative outsiders becomes harder, though.

@_date: 2005-08-17 15:59:49
@_author: Florian Weimer 
@_subject: draft paper: "Deploying a New Hash Algorithm" 
* Steven M. Bellovin:
I think this misses the point.  Hardly anybody attacks protocols.  In
fact, I think that those who design protocols easily outnumber those
who attack them.
What is being attacked aren't protocols, but implementations.  More
precisely, deployed implementations.  (I'm not talking about PR
attacks here, which can be powerful and costly as well; these are
completely different matters.)  I will receive a lot of flak for this
from the "faith is a verb", sorry, "security is a process" crowd, but
I'm convinced that at the moment, with the technology we have,
security is primarily a deployment issue.  This becomes becomes even
more clear when you give up the misguided and completely unrealistic
focus on prevention, which still plagues large parts of the industry,
despite continuous failure of this approach.
That's why I was shocked when one vocal critic of electronic voting
disclosed that he'd never observed an actual electronic procedure.
When he did, he suddenly realized that some of the attacks he'd been
speculating about couldn't actually work in the field.  (Other attacks
still seemed realistic, though.)
Or another example: Can you criticize the designers of the cookie
protocol that the cookies are not sufficient for secure session
management in web applications?  Or that IPsec XAUTH doesn't prevent
gateway impersonation attacks from insiders?  There are limits what
protocol designers can do, especially if the protocol is a universal
building block.  Security doesn't compose well, so getting individual
protocols right simply isn't the whole story.  Usually, it's even
possible to deploy insecure protocols and implementations in a
reasonably secure manner, and often, this isn't as costly as it
I think it's also important to realize that new protocols or
countermeasures which protect valuable assets (at least in the
attackers' eyes) can result in a considerable shift in attack
technology, especially on underlying protocols.
In the DoS context, this effect is quite well-known.  Once the end
system's application and TCP/IP stack can withstand the attack, your
network components or link bandwidth is attacked.  Of course, this
increases collateral damage, so it's common practice in a certain
class of DoS targets not to protect your hosts as well as you could.
I fear that a similar shift could occur at a protocol level.  Take
mail authentication, for example.  We have various proposals to use
DNS as a trusted data source.  If attackers think that subverting mail
authentication is a reasonable goal (which I doubt, but let's assume
it for the sake of argument), then it might be feasible to begin
large-scale attacks on DNS.  Of course, these attacks would have
enormous side effects, not just for mail delivery.  You make one thing
more secure, attacks shift to the underlying protocols which are
historically weak, and everybody loses because an old, widely used
protocol is suddenly put under significant stress.
Maybe this fear is a bit far-fetched, especially in the
SPF/DKIM/Sender-ID context, but I think the effect might indeed exist.
In general, attackers don't follow an economic model.  They don't
necessarily attack the weakest link where their attacks might be the
most effective, they just use what works for them.

@_date: 2005-08-25 18:59:04
@_author: Florian Weimer 
@_subject: [Clips] RSA Security Sees Hope in Online Fraud 
* R. A. Hettinga quotes:
Of course, SecureID tokens do not prevent man-in-the-middle attacks
carried out in real-time.  For example, it's probably not too hard to
write a Browser Helper Object which automatically rewrites financial
transactions submitted using Internet Explorer.

@_date: 2005-12-05 19:29:11
@_author: Florian Weimer 
@_subject: [Clips] Banks Seek Better Online-Security Tools 
Why?  Repudiating transactions is easier than ever.  As a consumer, I
fear technology which is completely secure according to experts, but
which can be broken nevertheless.  The current situation is very
different.  Everybody agrees that online banking is insecure, and in
most markets, it's the banks who swallow the losses, not the consumer
(even those who were very stupid).
For those of you who haven't rolled out a national ID scheme in time,
there's still the general identity theft problem, but this affects you
even if you don't use online banking.

@_date: 2005-12-05 19:42:33
@_author: Florian Weimer 
@_subject: [Clips] Banks Seek Better Online-Security Tools 
* Nicholas Bohm:
But it's just a token measure.  You should be afraid of your own
computer, your own network.  SecureID does not authenticate the server
you're going to send your data to.  It does not detect if your
computer is compromised.
Sure, right now, it might help you personally, but once these simple
tokens gain market share, attackers will adjust.  It's not a general

@_date: 2005-12-05 19:56:05
@_author: Florian Weimer 
@_subject: [Clips] Banks Seek Better Online-Security Tools 
* Eugen Leitl:
Some banks have optimized away the special envelope. 8-(
And we face quite advanced attack technology, mainly compromised end
systems.  We are well beyond the point where simple tokens (like RSA
SecureID) would help.
The way the current attacks are carried out, smartcard-based HBCI is
less secure than the PIN/TAN model because with HBCI, you don't need
to authorize each transaction separately.  At this stage, few people
recognize this problem, and German banks put high hopes on
smartcard-based online banking, despite its high costs in terms of
consumer devices and support calls.

@_date: 2005-12-05 20:29:53
@_author: Florian Weimer 
@_subject: [Clips] Banks Seek Better Online-Security Tools 
* Jonathan Thornburg:
Of course you don't.  In some sense, the next-generation security
technology which U.S. banks plan to roll out (either voluntarily, or
due to regulation) has already been broken in Germany.
If you bring the topic up in discussions, the usual answer is "don't
MITM me!" (meaning: "Don't mention man-in-the-middle attacks,
including compromised customer systems, because you know we can't
defend against them! This is not fair!").  But this is not a valid
response when experience shows that the relevant attacks *are* MITM
I'm always glad to read someone who agrees with me on this matter. 8-)
I don't understand why almost everyone is in a frenzy to deploy them.
If you can somehow weasel through the next 6 months or so, it will be
completely non-repudiatable that transactions covered by two-factor
authentication are fully repudiatable.  You can save a lot of money
(including your customers' money) if you manage to skip this
technology cycle.  The only problem could be that the media and
security experts smack you if you don't deploy the same, broken
countermeasures everyone else does.
By the way, one interesting aspect of the online banking problem is
its implications for threat modelling, attack trees, and similar
approaches.  It would be interesting to compare a few models and why
they fail to adequately describe the situation.  My hunch is that
these models do not take two factors into account: Attacks aren't
targeted by the cost/revenue alone, tradition plays a major role, too,
as does sheer luck.  And you are caught in a feedback loop; the
attacks change as you deploy new countermeasures, and the changes are
mostly unpredictable.

@_date: 2005-12-07 14:44:43
@_author: Florian Weimer 
@_subject: AW: [Clips] Banks Seek Better Online-Security Tools 
* Ulrich Kuehn:
Here's a link: In this particular implementation, yes.
There are other attacks if you control the end user system:
You can display a dialog box requesting that the user enters the PIN
on the host, and not on the PIN pad.  Typical smartcard work in
various card readers (with and without PIN pads), so you can later use
the PIN to create additional transactions.
It turns out that you need not do this, though: once the end user has
entered the PIN, you can create as many signatures as you like.  In
this sense, the PIN/TAN approach is more secure than smartcards.
The display contents is supplied by the end user computer, not the
smartcard, so it's still possible to break this scheme just by
attacking the computer.
Postbank's mTAN is promising because uses a separate channel which is
currently not very easy to attack, but the activation procedure is
fundamentally flawed.  Costs are probably too high to introduce this
as a general countermeasure, though.
In the long term, we need a standardized device which generates TANs
which depend on the transaction contents (target account and amount).
Standardization is important because you don't want to carry around
such a device for each plastic card you own.

@_date: 2005-02-23 23:03:46
@_author: Florian Weimer 
@_subject: SHA-1 results available 
* Jack Lloyd:
Thanks for the pointer.
In addition, there's no trace of the second-preimage attack some
persons recently alluded to.

@_date: 2005-01-04 23:19:30
@_author: Florian Weimer 
@_subject: AOL Help : About =?iso-8859-1?Q?AOL=AE?= PassCode 
* Ian G.:
I think you can forward the PassCode to AOL once the victim has
entered it on a phishing site.  Tokens ? la SecurID can only help if
the phishing schemes *require* delayed exploitation of obtained
credentials, and I don't think we should make this assumption.  Online
MITM attacks are not prevented.
(Traditional IPsec XAUTHis problematic for the very same reason, even
with a SecurID token lookalike.)

@_date: 2005-01-08 00:33:11
@_author: Florian Weimer 
@_subject: OpenVPN and "SSL VPNs" 
* Stefan Mink:
It's not standardized, and it only interoperates with itself (but this
is true for many IPsec implementations as well).  This is more than
compensated by its portability.  OpenVPN has a very interesting
feature set, including hybrid authentication and a HMAC-based
integrity check before TLS processing for the paranoid.  (Static key
mode is also possible and doesn't require TLS at all.)
Unfortunately, the protocol would have to be reverse-engineered from
the source code before it can be reviewed.  You've already mentioned
important aspects of the protocl (TSL on the control plane, ESP for
the payload).
What's still missing, though, is multicast support and PPPoE-style
multihop authentication.  PMUTD doesn't work for me at the moment, but
this could also be a local configuration problem.
What is an "SSL VPN"?  A web application that runs over TLS? 8-)
Uh-oh, it looks as if this joke isn't too far off.  This reminds me of
the good old times when we tried to use TeraTerm and SSH port
forwarding to secure a Baan installation.
No, it certainly isn't.  OpenVPN doesn't work at the application
layer, as SSL VPNs usually do.  It's a real VPN, and you can choose
between layer 2 or layer 3 operation.
At least OpenVPN uses a bit SSL and provides a VPN.  SSL VPNs use a
lot of SSL, but provide no VPN.

@_date: 2005-01-28 21:01:11
@_author: Florian Weimer 
@_subject: Simson Garfinkel analyses Skype - Open Society Institute 
* David Wagner:
Skype is unregulated.  PSTN operators (and other VoIP services by
large telcos) are subject to at least some scrutiny.
There's another not readily observable property of Skype's network:
reliability.  Would anyone claim that Skype's network is more reliable
than PSTN?  I don't think so, even though we know as little about its
reliability as about its security.
And please don't forget that privacy of call records is much more
important than encryption of the actual voice traffic.  Doing
interesting things with call record data is much, much cheaper than
voice recognition, entire call archival and so on.

@_date: 2005-07-02 17:09:11
@_author: Florian Weimer 
@_subject: RSA gets a reprieve? 
* Michael Heyman:
My local source of quantum computing knowledge says that the
conclusions of the paper are somewhat questionable.  The authors
examine a specific kind of measurement model; it's not immediately
obvious if their results apply to all measurements, as they claim.

@_date: 2005-07-02 18:52:03
@_author: Florian Weimer 
@_subject: /dev/random is probably not 
* Jason Holt:
I somewhat doubt that moving the mouse around slowly resulting in
about 800?entropy bits per second is an accurate estimate.  But I have
to admit that I haven't run statistical tests on the unmixed data,
which would be necessary to back up my claim that this figure is
grossly exaggerated.

@_date: 2005-07-05 16:39:31
@_author: Florian Weimer 
@_subject: Feature or Flaw? 
* Lance James:
Couldn't you just copy (or proxy all content) and get the same effect
without using frames at all?
Maybe I'm just missing something.

@_date: 2005-07-05 17:14:44
@_author: Florian Weimer 
@_subject: Feature or Flaw? 
* Lance James:
In both cases, you have the SSL lock on your own certificate.
At least my browser does not provide a user interface to access the
certificates of the servers from which embedded objects (or frames)
were downloaded.

@_date: 2005-07-05 18:48:14
@_author: Florian Weimer 
@_subject: Feature or Flaw? 
* Lance James:
In case of XSS or CSRF, you have lost anyway.  The web was not
designed as a presentation service for transaction processing,
especially if the transactions involve significant value.  If you use
the web for this purpose, it's always a tradeoff.
Maybe it's time to realize that all these web applications together
form a huge monoculture, and to move on and diversify again.

@_date: 2005-07-09 20:38:38
@_author: Florian Weimer 
@_subject: the limits of crypto and authentication 
* Steven M. Bellovin:
You send the pass code in an SMS to the user's mobile phone, together
with some information on the transaction.  (If the SMS delay is a
problem, use a computer-generated phone call.)  The pass code is then
entered by the user to authorize the transaction.
This will eventually break down, once PCs and mobile phones are
integrated tightly, but in the meantime, it's reasonably secure even
if the client PC is compromised.
I'm not sure if users will accept it, though.  What's worse, the costs
for sending the SMS message (or making the phone call) are so
significant that it's unrealistic we'll see widespread use of such
(Manually transferring cryptographic tokens which depend on the
transaction contents seems to be infeasible, given the number of bits
which must be copied.)

@_date: 2005-07-09 21:50:21
@_author: Florian Weimer 
@_subject: [Forwarded] RealID: How to become an unperson. 
* Perry E. Metzger:
I share your general concern, but it's not the ID cards which worry
me.  After all, forgeable passports are only a very, very weak form of
defense in an age of non-invasive biometric applications which operate
in real-time.  (I know, we aren't quite there yet, but we're getting
My concern is that our government is building infrastructure for
monitoring extremist citizens, trying very hard to interdict all
extremist propaganda.  The rationale behind that is the assumption
that most Germans are still latent nazis.  (I'm not sure if this is
really the case, but it seems that anti-democratic feelings are rather
widespread.)  Unfortunately, this monitoring infrastructure covers the
whole population by design, and in case of a coup d'etat, it can be
easily abused by the perpetrators to make sure that they stay in
power.  In other words, this approach is not fail-safe.  I find it
rather unsettling that our politicians seem to be completely unaware
of this risk.

@_date: 2005-07-10 00:46:44
@_author: Florian Weimer 
@_subject: the limits of crypto and authentication 
* Nick Owen:
I doubt this is true.  In Germany, we already use some form of
two-factor authentication for Internet banking transaction (account
number/password and a one-time password for each transaction).  Yet
banks are desperately looking for alternatives because distributing
those one-time password lists is too expensive (!).  To me, this was
quite surprising because it's just one sheet of paper every 200
transactions or so.
Even worse, this scheme has failed, and there are successful attacks
in the wild (involving compromised client PCs).  Right now,
time-dependent tokens do help, but only because you outrun the other
guy.  The real-time requirements imposed by them are not a fundamental
obstacle to the attackers, and even now, the way they route the money
makes it very hard to detect things in real-time (at least on the
money side).
Well, you can imagine my surprise when Howard Schmidt praised
two-factor authentication as a solution to our current problems at the
FIRST 2005 conference. 8-/

@_date: 2005-07-10 17:36:55
@_author: Florian Weimer 
@_subject: EMV 
* David Alexander Molnar:
If you are interested in useful RFID applications, just visit
Singapore. 8-) They use RFID tickets on the subway (MRT) and on
busses, and you don't have to worry about buying the right ticket
because the system charges you the correct amount.  However, there's
one thing that makes me nervous: if you know the card number (which is
printed on the cards), you can go to a web page, enter it, and obtain
the last 20 rides during the last 3 days, without any further
authentication.  It's a system where contactless readers make a lot of
sense, though.
In Germany, we have got something even better: digital cash
(Geldkarte).  The system is rather old, so it doesn't use contactless
smartcards, and it was never accepted by customers and merchants.  I'm
not even sure if it's still usable.  I own one or two of the
smartcards, but I don't think I've ever used them. 8-/

@_date: 2005-07-10 12:15:36
@_author: Florian Weimer 
@_subject: the limits of crypto and authentication 
* Perry E. Metzger:
On the surface, we already have such technology in Germany (it's
optional for bank customers), but there's a drawback: The external
device doesn't know anything about the structure of banking
transactions, so it relies on the (potentially compromised) host
system to send the correct message to display before generating the
signature.  Ouch.

@_date: 2005-07-10 12:12:53
@_author: Florian Weimer 
@_subject: the limits of crypto and authentication 
In the foreseeable future, this approach won't stop fraudulent
transactions because the one-time password does not depend on the
transaction content.  Anything which doesn't display essential parts
of the transaction contents to the end user over a trusted channel is
doomed to failure.

@_date: 2005-07-22 19:42:04
@_author: Florian Weimer 
@_subject: Qualified Certificate Request 
* Nap van Zuuren:
That's by design, all those notaries public don't like being replaced
by smartcards.

@_date: 2005-06-09 15:53:57
@_author: Florian Weimer 
@_subject: encrypted tapes 
I don't think this is a good policy in general.  Often, it's more
cost-effective to fix a potential vulnerability than to investigate it
in detail, construct a proof that it's real, and fix it.  This is
especially true in environments where changes can be deployed at
moderate cost.  (I know that there are others.)
To sum it up, I think it's fine to report potential problems as well,
but they have to be labeled as such (so that they receive the right

@_date: 2005-06-12 12:17:58
@_author: Florian Weimer 
@_subject: de-identification 
We call it pseudonymization ("Pseudonymisierung").  It's a commonly
used technique in Germany to detaint personally identifiable
information, so you can share it freely for statistics purposes.  The
methods used in the field are rather crude (time-seeded LCGs are very
common, unfortunately).
A reference to the book "Translucent Databases" was posted to this
list a couple of months ago, but IIRC it's being revisied, so I didn't
rush to buy and read it.

@_date: 2005-06-20 17:58:07
@_author: Florian Weimer 
@_subject: RSA signatures without padding 
I came across an application which uses RSA signatures on plain MD5
hashes, without padding (the more significant bits are all zero).
Even worse, the application doesn't check if the padding bits are
actually zero during signature verification.  The downside is that the
encryption exponent is fairly large, compared to the modules (27 vs
1024 bits). A few hundred signed messages have been published so far.
What do you think?  Are attacks against this application feasible?
(It should be corrected, of course, but it's not clear if a
high-priority update is needed.)

@_date: 2005-06-21 07:51:17
@_author: Florian Weimer 
@_subject: massive data theft at MasterCard processor 
* Peter Fairbrother:
Apparently, handwritten signatures can be repudiated, at least I've
heard of a few cases where this likely was the case (but naturally,
graphologists didn't agree if the signature was genuine).
You can even use a signature machine to facilitate repudiation at a
later date.
In Germany, there's a widely used system based on PIN and a magnetic
stripe, and you can buy used reader devices on Ebay. 8-( This makes it
rather easy to mount a MITM attack.

@_date: 2005-03-13 10:14:56
@_author: Florian Weimer 
@_subject: comments wanted on gbde 
* Joseph Ashwood:
Even if a more standard approach had been used, you'd need something
quite similar for storing the IVs (or IV equivalents).
It seems as if GBDE doesn't atomically update both the metadata sector
and the data sector in a single transaction.  This means that a power
failure which results in a lost sector has some probability of
destroying much more, including sectors which previously have been
advertised as having reached stable storage.  Of course, such issues
are complex to address and are the main reasons why other schemes (ECB
mode, CBC mode with constant IVs derived from sector numbers) are so

@_date: 2005-03-15 21:36:22
@_author: Florian Weimer 
@_subject: Security is the bits you disable before you ship 
* Peter Gutmann quotes CNET:
Actually, mudflap is not a security feature (and I'd be surprised if
Mark claimed it was).  It's a debugging tool, not a silver bullet.
mudflap simply wasn't designed to stop buffer overflow exploits (or to
make them at least somewhat harder), but to find memory management

@_date: 2005-03-23 17:35:50
@_author: Florian Weimer 
@_subject: Propping up SHA-1 (or MD5) 
* Ben Laurie:
Unfortunately, it does, in a rather fundamental way: streamed
processing is no longer possible.

@_date: 2005-03-25 18:55:50
@_author: Florian Weimer 
@_subject: and constrained subordinate CA costs? 
* Adam Back:
Is there a technical option to enforce such a policy on subordinated

@_date: 2005-11-11 11:20:15
@_author: Florian Weimer 
@_subject: How broad is the SPEKE patent. 
* James A. Donald:
Keep in mind that one party runs the required software on a computed
infected with spyware and other kinds of Trojan horses.  This puts the
effectiveness of zero-knowledge proofs into question.

@_date: 2005-11-12 21:18:37
@_author: Florian Weimer 
@_subject: [Clips] [dave@farber.net: [IP] Apple tries to patent  'tamper-resistant software'] 
* R. A. Hettinga:
The patent application seems to be this one:
Note that it covers some stuff that does in fact work, for example
claim 9 (although there is plenty of prior art for this one).
Unfortunately, the things that can work are in the wrong direction:
Apple can prevent you from running anything but Mac OS X on your Intel
Mac.  What they really want to do (at least according to press
reports) is to stop you from copying Mac OS X to your other Intel box.
Big difference.

@_date: 2005-11-13 18:05:43
@_author: Florian Weimer 
@_subject: FW: Fermat's primality test vs. Miller-Rabin 
* Charlie Kaufman:
How do you chose a random integer, that this, based on which
probability distribution? 8-)
Anyway, one can show that for some fixed number, the probability that
one run of the Miller-Rabin algorithm fails (i.e. reports "potentially
prime" for a composite) does not exceed 1/4.  Knuth gives a proof in
an exercise in Volume 2 of The Art of Computer Programming, including
an example that the 1/4 bound is pretty good.  However, this answers a
slightly different question.

@_date: 2005-11-17 11:20:46
@_author: Florian Weimer 
@_subject: "ISAKMP" flaws? 
* Perry E. Metzger:
These bugs have been uncovered by a PROTOS-style test suite.  Such
test suites can only reveal missing checks for boundary conditions,
leading to out-of-bounds array accesses and things like that.  In
other words, trivial implementation errors which can be easily avoided
using proper programming tools.

@_date: 2005-11-18 10:58:14
@_author: Florian Weimer 
@_subject: "ISAKMP" flaws? 
* Peter Gutmann:
Of course, the relevance of a bug and how easily it could have been
avoided are completely different matters.  I mainly wanted to point
out that there is no new cryptography involved.
They have chosen different trade-offs, focusing on performance,
time-to-market and things like that.  It's hard enough to create an
ISAKMP implementation that works at all.
How many completely independent implementations are there?

@_date: 2005-11-18 11:03:14
@_author: Florian Weimer 
@_subject: "ISAKMP" flaws? 
* William Allen Simpson:
Photuris uses a baroque variable-length integer encoding similar to
that of OpenPGP, a clear warning sign. 8-/ The protocol also contains
nested containers which may specify conflicting lengths.  This is one
common source of parser bugs.

@_date: 2005-11-18 22:43:23
@_author: Florian Weimer 
@_subject: "ISAKMP" flaws? 
* William Allen Simpson:
Even back then, the integer encoding was considered to be a mistake.
(Jon Callas, 1997-08-08)
Variable-length integers within other fields, for example.  You can't
avoid this phenomenon in its entirety, of course, without sacrificing
some of the advantages of a binary encoding.
I like ISAKMP as much as the next guy, but somehow I doubt that
simpler protocols necessarily lead to more robust software.  Sure,
less effort is needed to implement them, but writing robust code still
comes at an extra cost. *sigh*

@_date: 2005-10-20 21:29:01
@_author: Florian Weimer 
@_subject: Cisco VPN password recovery program 
* Perry E. Metzger:
Why?  In essence, this is the PSK that is used to authenticate the VPN
gateway.  It must be available in cleartext on the client.
(Later versions offer asymmetric encryption as well.)

@_date: 2005-10-20 21:34:22
@_author: Florian Weimer 
@_subject: Cisco VPN password recovery program 
I really doubt that this affects group password (PSK).
In some cases, network administrators used the password obfuscation to
force their users to use Cisco's VPN client.  Competing products, such
as vpnc, do not enforce client-side policies.  However, there's been a
website where you can upload the obfuscated password, and it returns
the password in clear text for quite some time now.  It is implemented
by running the Cisco client under a debugging tool, intercepting a
memcpy call that copies the password.
In the end, the publication of the algorithm doesn't change the
security of the system (there wasn't much to start with).  But it's
certainly easier to write interoperable software using this

@_date: 2006-04-29 20:15:55
@_author: Florian Weimer 
@_subject: History and definition of the term 'principal'? 
* Hadmut Danisch:
The OED might also be helpful:
  B. [...] 2. a. A chief actor or doer; the chief person engaged in
  some transaction or function, esp. in relation to one employed by or
  acting for him (deputy, agent, etc.); the person for whom and by
  whose authority another acts.
  [...] 1962 H.O. Beecheno Introd. Business Stud. xiii. 117 Whereas an
  agent is not normally allowed to relend his principal's money at
  interest .. a bank is allowed to do this.  1976 Times 22
  Par. (Baltic Exchange Suppl.) p. i/9 The Baltic is unusual in being
  open both to middle men and principals.
I think this is a strong indication that the term is used in one of
its original meanings.  It also explained why nobody thinks it's
necessary to define it properly.

@_date: 2006-12-20 23:36:17
@_author: Florian Weimer 
@_subject: ATM vulnerability 
In a weired sense, yes.  If I understand the paper correctly, the
authors show that given the current protocol requirements, spending
money on HSMs is a total waste.

@_date: 2006-02-13 19:18:54
@_author: Florian Weimer 
@_subject: GnuTLS (libgrypt really) and Postfix 
* Werner Koch:
_exit in libraries is fine if you don't service multiple clients from
a single process.  However, with the advent of heavy VMs and stuff
like that, there is a trend towards serving multiple clients from a
single process (which is quite a bad idea in almost all cases, but
this view is rather unpopular).  There are also libraries which
require proper cleanup procedures, otherwise the next program start
can be quite costly (think of databases, where you want to avoid log
replay).  Some services have even been implemented following a
single-process model for more than a decade (IRC servers, for
A user-defined "fatal error" function (which must not return) would be
a compromise, I think.  Of course, such a function should never be
called if you just see wrong or unsual input.  But with a bit of
optimism, the process could recover from an error which is not locally
recoverable (throw an exception, terminate the offending thread, and
leak the allocated resources).
Now if the library maintains global, per-process state, this is a real
problem.  You can't know for sure if this state is consistent after a
fatal error, unless you program carefully to avoid this situation.
Yet another reason to move this functionality to a separate process. 8-)

@_date: 2006-02-26 19:15:28
@_author: Florian Weimer 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
* Ben Laurie:
A step which has really profound privacy implications.
I couldn't find a PGP key server operator that committed itself to
keeping logs confidential and deleting them in a timely manner (but I
didn't look very hard, either).  Of course, since PGP hasn't
progressed as faster as our computing resources, I'm nowadays in a
position to run my own key server, but this is hardly a solution to
that kind of problem.

@_date: 2006-07-20 22:53:56
@_author: Florian Weimer 
@_subject: NIST hash function design competition 
* Travis H.:
Is this about Colin Percival's work?  IIRC, it's mainly about shared
associative caches which leak information about what addresses are
being cached across trust boundaries.

@_date: 2006-07-29 22:56:26
@_author: Florian Weimer 
@_subject: Recovering data from encrypted disks, broken CD's 
* Steven M. Bellovin:
A lot of software tends to create temporary files in random places.
If you don't encrypt the whole disk (including swap space and the
suspend-to-disk area), plaintext might be written to the disk and can
be recovered even though the actual cryptography is sound.  This
assumes that transparent decryption is used--the situation is worse if
you need to create a temporary plaintext copy on disk before you can
actually process the data.
(Now I only need to figure out why sequential disk I/O takes such a
significant hit when using dm-crypt. *sigh*)

@_date: 2006-06-01 09:23:01
@_author: Florian Weimer 
@_subject: Status of SRP 
* James A. Donald:
All browsers I've tested permit overriding chrome in the default
configuration as a deliberate design decision. 8-(
If you've deployed two-factor authentication (like German banks did in
the late 80s/early 90s), the relevant attacks do involve compromised
customer PCs. 8-( Just because you can't solve it with your technology
doesn't mean you can pretend the attacks don't happen.

@_date: 2006-06-03 09:59:19
@_author: Florian Weimer 
@_subject: Status of SRP 
* Ka-Ping Yee:
I'm not sure if this can't be defeated by something like a "Choose a
new funny icon for your security button!" offer. 8-( However, this
points to a more general problem: We have no real-world studies how
users make their day-to-day trust decisions when using the Internet.
For example, if I need to judge the trustworthyness of a web page, a
large factor is the way I got there.  If it was a link from an email
message that looks like spam, or something that was returned by a
search engine, I'm rather sceptical.  This is why those "80% can't
tell a phishing page apart from the real one" web-base studies are
quite worthless.  They simply do not present enough context.
I suppose this can be circumvented if you you use email to lure the
victim to the fake web page and have obtained names matching the email
addresses.  Even if you want to present the full address to the
victim, you can buy this data from direct marketing companies, I

@_date: 2006-06-03 10:16:06
@_author: Florian Weimer 
@_subject: Status of SRP 
* Anne & Lynn Wheeler:
You say that as if that assumption were unrealistic.
Transaction-rewriting malware is out in the wild. 8-(
FINREAD is really interesting.  I've finally managed to browse the
specs, and it looks as if this platform can be used to build something
that is secure against compromised hosts.  However, I fear that the
support costs are too high, and that's why it hasn't caught on in
retail online banking.
The interesting part is that it's possible to create an application
that runs exclusively on the trustworthy component and presents the
actual transaction data to the user before it is signed.
Previous card readers/smart card combinations relied on host software
to provide the display contents, without any way to check that it
matches the blob that was to be signed.  Of course, it's still
possible to develop a FINREAD application that behaves that way,
perhaps in order to cut down development costs.  As usual, just
because it's FINREAD, it's not automatically secure (and a
"transparent mode" exists as well).

@_date: 2006-06-06 09:17:14
@_author: Florian Weimer 
@_subject: Status of SRP 
* Anne & Lynn Wheeler:
The problem is not hardware costs, but support costs.  You really
don't want to outsource this to the cheapest call center in the world.
Even relatively simple changes like the indexed TAN rollout are
rather expensive as a result.
You mean something like remote attestation?  I find it hard to believe
that this capability is available today in a relatively open
environment, on a platform supporting multiple applications developed
by different applications.

@_date: 2006-06-24 09:49:02
@_author: Florian Weimer 
@_subject: Greek cellular wiretapping scandal 
* Steven M. Bellovin:
Isn't Ericsson's switching software written in Erlang, is highly
modular and officially supports run-time code replacement (like many
COBOL systems, but unlike, say, traditional IOS)?  This means that at
least no "rootkit" is needed.  You just replace the parts of the
system you are interested in using the standard system interfaces
intended for this purpose.  Of course, the complexity of the attack is
still significant.

@_date: 2006-03-04 16:38:24
@_author: Florian Weimer 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
* Bill Stewart:
What a peculiar advice.  We know for sure that Google logs these
requests and stores them indefinitely. 8-(

@_date: 2006-05-05 21:51:24
@_author: Florian Weimer 
@_subject: Linux RNG paper 
* Travis H.:
AFAIK, they use it to generate the IVs for CBC mode.  Directly using
the sector numbers leads to fingerprinting vulnerabilities.

@_date: 2006-05-13 23:02:14
@_author: Florian Weimer 
@_subject: There are no limits to human stupidity. 
* Perry E. Metzger:
Needless to say, the mass-mailing was not sent from Chase's own
infrastructure, but by a contractor.  I've heard that they even use
fuzzy matching to recover your email address from your postal address.

@_date: 2006-05-15 07:33:25
@_author: Florian Weimer 
@_subject: the meaning of linearity 
* Travis H.:
I wouldn't call that "linear" if b /= 0, "affine" is probably better.
But I'm not familiar with the cryptographic term, maybe it's
It refers to arithmetic over GF(2), the field with two elements.  In
this field, XOR is addition, and AND is multiplication.

@_date: 2006-05-15 07:38:11
@_author: Florian Weimer 
@_subject: picking a hash function to be encrypted 
* Travis H.:
Is this still true if you don't know your actual requirements?

@_date: 2006-05-29 07:21:29
@_author: Florian Weimer 
@_subject: Status of opportunistic encryption 
* Sandy Harris:
It seems to me opportunistic encryption has moved to the application
layer, at least as far as Internet mail is concerned.  Many MTAs use
TLS automatically with whatever certificates they can get.  Of course,
this only guards against active attacks, but it seems to me that this
is a reasonable threat model.  At least it's like to hide your
important GnuPG-encrypted messages from the casual traffic
analyst. 8->
Didn't Openswan announce that opportunistic encryption is deprecated?
My impression was that, according to its creators, Freeswan was mainly
about OE, but people used it as a regular IPsec implementation on
Linux.  Openswan tried to bridge that gap, even while the Freeswan
project itself was still active.

@_date: 2006-05-31 07:32:43
@_author: Florian Weimer 
@_subject: Status of SRP 
* James A. Donald:
There is no way to force an end user to enter a password only over
SRP.  That's why SRP is not effective against phishing (even the
mimicry variant).  In that regard, the password input field was a huge
mistake.  Fortunately, it doesn't matter because today, we must assume
that the client is thoroughly compromised, which means that entering
passwords over SRP isn't safe, either.

@_date: 2006-10-03 18:16:09
@_author: Florian Weimer 
@_subject: Hamiltonian path as protection against DOS. 
* James A. Donald:
How do Hamiltonian paths protect against the H.R.4411 attack?
(Part of the DoS problem online casinos face is that due to their
activity, which was illegal before, they are extremely reluctant to
approach law enforcement about this matter.)

@_date: 2006-09-05 19:00:41
@_author: Florian Weimer 
@_subject: Locating private keys in RAM? 
* Douglas F. Calvert:
(The web page no longer exists, though.)

@_date: 2006-09-30 11:44:58
@_author: Florian Weimer 
@_subject: Circle Bank plays with two-factor authentication 
* Steven M. Bellovin:
I agree that if you consider this scheme in isolation, it's better
than plain user names and passwords.  But I wonder if it significantly
increases customer confusion because banks told their customer that
they won't *ask* for credentials via email, but now a bank is
*sending* them by email.
If this technology enters the attacker's radar screen, the "keystroke
logger" would be changed to scan mail folders for the message sent by
the bank.  Or it would alter the login page to display an empty
matrix, without any further explanations. 8-/

@_date: 2007-04-05 22:56:06
@_author: Florian Weimer 
@_subject: DNSSEC to be strangled at birth. 
* Peter Gutmann:
You can see that the keys change and draw your conclusions.  Right
now, you need to watch the actual data, which is a bit unwieldy (2.5%
daily change rate for .COM/.NET and things like that).
By the way, who else has expressed willingness to hold the key, under
reasonable conditions?  Would it be preferable if some
non-governmental organization held the keys, after receiving an
indemnification guarantee from Congress?

@_date: 2007-04-05 23:06:12
@_author: Florian Weimer 
@_subject: DNSSEC to be strangled at birth. 
* Simon Josefsson:
There are some examples that such static configuration is extremely
bad.  Look at the problems with bogon filters, or how long
decommissioned root server IP addresses continue to receive queries.
It's not a problem if you do this for .SE as a Swedish ISP because you
notice quickly that something is amiss.  But if too many people do
this for most TLDs, it will become practically impossible to change

@_date: 2007-08-23 00:29:59
@_author: Florian Weimer 
@_subject: interesting paper on the economics of security 
* Hal Finney:
I don't, either, but for a different reason.
The tests I've seen are mostly worthless because they do not weigh
their results based on the actual threats a typical user faces.  After
all, these days, the goal is not to avoid the embarrassments caused by
a virus infection or a spam bot operating from your network, but to
avoid actual loss due to fraud (or perceived fraud).  Mere detection
rates do not reflect that.[1] So there is certainly a lack of
But in contrast to the used care market, the seller doesn't really
know how useful their products are to the buyer, either.  Some vendors
(those offering spam filtering as a service, for instance) might have
a better idea than their customer what's happening, but for the
broader market, return on security investment is a completely
imaginary figure for both buyers and sellers.  Only if you look at
things like pro-forma regulatory compliance, it's possible to obtain
hard facts.
[1] This might sound like marketing gibberish from some of the
big-name vendors, but I think it's true.  It does not mean that a
product which looks bad in a synthetic test gives adequate results in
the real world, though.

@_date: 2007-08-31 20:55:52
@_author: Florian Weimer 
@_subject: World's most powerful supercomputer goes online 
* Peter Gutmann:
It's a bit unfair to compare those numbers with single-image systems
or tightly-coupled clusters.  Grids are the more apt comparison.
Doubt it.  If I recall the confirmed Phatbot numbers correctly, they
where pretty substantial, too, especially for that time.  And this was
the first time when I came across that "botnets are grids plus
scalability and security" joke.
Some of the HTTP-based botnets advertised pretty high infection
numbers, too, but such claims are difficult to verify.
On the other hand, LINPACK numbers for a botnet would likely be much
lower than what is suggested by the raw CPU count.

@_date: 2007-12-10 17:50:07
@_author: Florian Weimer 
@_subject: More on in-memory zeroisation 
* Thierry Moreau:
This isn't true; inlining of standard library functions is always
permitted under the as-if rule.

@_date: 2007-12-12 22:17:19
@_author: Florian Weimer 
@_subject: PlayStation 3 predicts next US president 
* William Allen Simpson:
The problem is not the outer MD5 (explicitly mentioned in your
description), but that Dp is typically (well, to the extent such
services have been deployed) some kind of hash.  This has got the
advantage that the timestamping service does not need to know the
contents of the document.  On the other hand, if the timestamping
service archives Dp and can reveal it in a dispute, evil twins can be
identified and analyzed -- which undermine the submitting party's claim
that it submitted the second document instead of the first.
Of course, this is actually cheating by substituting proven protocols
for fragile cryptography.  And the result is still open to
interpretation, but all evidence is.

@_date: 2007-02-14 21:44:07
@_author: Florian Weimer 
@_subject: Failure of PKI in messaging 
* James A. Donald:
Deutsche Postbank uses S/MIME, and they are anything but a niche
player.  It doesn't help against phishing in the sense that deters the
attackers and reduces the PR impact.
Why bother, when it's been shown it doesn't make a difference?

@_date: 2007-01-03 21:06:47
@_author: Florian Weimer 
@_subject: Fwd: [FDE] Largest Ever Single FDE implementation 
* Saqib Ali:
In the process, the following document has been published:
Is it standard practice to publish so many contact details of those
who are involved in the bidding process?

@_date: 2007-01-27 13:27:59
@_author: Florian Weimer 
@_subject: "Free WiFi" man-in-the-middle scam seen in the wild. 
* Perry E. Metzger:
Of course, this only helps if users visit the site using bookmarks
that were created after the switch.  If they enter "fidelity.com" (or
even just "fidelity") into their browsers to access it, switch to
HTTPS won't help at all.  Perhaps this explains why someone might
think that serving the login page over HTTPS is just security theater.
In the same "we use use HTTPS and are still vulnerable to MITM
attacks" department, there's the really old issue of authenticating
cookies which are not restricted to HTTPS, but will be happily sent
over HTTP as well. *sigh*
Apart from that, the article you linked to does not even mention
actual attacks with an identity theft motive.  What's worse, the
suggested countermeasures don't protect you at all.  Ad-hoc networks
are insecure, and those with an access point are secure?  Yeah, right.

@_date: 2007-07-01 12:04:34
@_author: Florian Weimer 
@_subject: The bank fraud blame game 
* Jerry Leichter:
But if you don't do this, customers can repudiate *any* transaction,
even those they have actually issued.  In other words, you run into
tons of secondary fraud, where people claim they are victims, but they
actually aren't.
Customers need to provide some evidence that they are actually
victims.  Just claiming "the virus did it" can't be sufficient.

@_date: 2007-07-01 23:35:03
@_author: Florian Weimer 
@_subject: The bank fraud blame game 
* Ian G.:
But not as far as client-side fraudulent activity is concerned.  After
all, the attacked systems are not under their administrative control.
We have courts that are traditionally bank-friendly, and courts that
aren't.  While we do not heavily rely on case law, it's a bit of luck
which one sets the precedent (which will eventually help to shape
And what's worse, the situation is so unstable that a case that gets
decided in favor of one party might actually end up shifting the risks
to the other party in the long run because the environment keeps
changing rapidly.
And vice versa.
It might even happen that we see competion from foreign, EU-based
banks that offer transactions without the safeguards German banks have
agreed to among each other.  We'll see if this increase in convenience
turns out to be a major selling point.
I think the extent to which end users, hardware and software
manufacturers, and ISPs don't care about compromised machines was a
real surprise.  If there's malware on the PC, it's not just banking
that is affected.  You'd expect people to do something about it, but
no one does without significant external pressure.
And if you look closely at which attacks security experts predict (and
not just self-proclaimed ones!), and which actually materialize, there
are significant differences.  These differences are usually mulled
over by ambiguous terminology, but the gap is there.
They didn't build the Internet, they didn't provide the PC and its
software, they don't even run the most-frequented online commerce
applications.  But in a moment of weakness, they started to take
responsibility.  And the real difficulties began.
For a rare security success story, look at how ISPs manage to sell a
completely insecure product which puts their customers at significant
risk, and take virtually no blame for it.  And technologically, banks
are not that different from mail providers.  They just pass around
messages.  Why should they be responsible for their content, if ISPs
Non-digital crime faces the same problem.  You haven't got a
cryptographically secured audit trail, either.  But clues can still be
The American banking system is mainly protected by its obsolescence.
It's not an end-to-end transaction system, unlike the European ones.
The new APACS standard should be a huge leap forward for the UK.
AFAIK, it includes the limited form of transaction signing that is
possible within the constraints.  Of course, it's still not foolproof,
but the non-fools can actually detect a compromised terminal.

@_date: 2007-07-01 23:49:48
@_author: Florian Weimer 
@_subject: The bank fraud blame game 
* Anne & Lynn Wheeler:
Well, in 1994, German Postbank already had 300,000 online banking
customers.  (To put this into perspective, there are somewhere around
3 million online customers today, and this was well before the
Internet took off in Germany.)
On top of that, there were other forms of digital banking that were
mainly used by business customers, such as transactions submitted on
floppy disks.
Oh really?
In Germany, early digital banking had no cryptographic protection at
all.  Integrity and confidentiality were inherited from the underlying
phone system.  There were no end-to-end digital signatures.  Nothing.
Just a one-time password for each transaction, but the password was
not tied to the transaction in any way.
Except that there aren't any attacks on the browser PKI.  That's part
of the reason why the certificate prices plummeted. 8-/

@_date: 2007-07-05 16:25:27
@_author: Florian Weimer 
@_subject: UK RIPA Pt 3 
* Peter Fairbrother:
Well, if Mr Gates is a witness and not a suspect, such coercive
measures are well within the legal framework of most countries.  As a
witness, you must testify.  It simply does not matter if the
information you are asked to provide is encrypted, or is stored in a
database and needs significant preprocessing to obtain.  It would be
quite surprising if this was any different in the UK.
So it's purely the self-incrimination part that is questionable from a
legal POV.  I think this bears repeating because we face a similar
discussion in Germany regarding covert data seizure using
technological measures, and the discussion focuses almost entirely on
the technological measures.  But the legal obstacle is just the

@_date: 2007-07-09 22:40:44
@_author: Florian Weimer 
@_subject: How the Greek cellphone network was tapped. 
* Ian Farquhar:
It's also an open question whether network operators subject to
interception requirements can legally offer built-in E2E encryption
capabilities without backdoors.

@_date: 2007-07-10 07:59:56
@_author: Florian Weimer 
@_subject: How the Greek cellphone network was tapped. 
* John Ioannidis:
Uh-oh, no.  The protocol characteristics don't change depending on who
is selling you the device.  Many telcos have an aversion to end-to-end
protocols.  Building reliable networks for ill-behaving end systems
has been a pretty recent idea (and we are still far away from a
complete solution).
There aren't any interception requirements for device vendors, either,
at least not any I'm aware of.  They aren't telcos.  Projects like
OpenMoko should not be affected.

@_date: 2007-06-09 17:00:38
@_author: Florian Weimer 
@_subject: IBM Lost Tape(s) 
* John Ioannidis:
I guess it's pretty easy because your personal information is
available to so many organizations, without any safeguards.
Obviously, they had your social security number (it's only the backup
that was lost), so they could work from that.
And more data is being collected: If you participate in their
monitoring program, Kroll can associate an email address with your
SSN, which is probably something that wasn't possible before.

@_date: 2007-05-02 13:44:54
@_author: Florian Weimer 
@_subject: Public key encrypt-then-sign or sign-then-encrypt? 
* Travis H.:
With sign, then encrypt, it's also possible that the receiver decrypts
the message, and then leaks it, potentially giving the impression that
the signer authorized the disclosure.  There has been a fair bit of
buzz about this confusion.  But the lesson from that seems to be that
signature semantics are very hard to agree upon, and most marginally
successful standards sidestep the issue anyway, acting as a mere
transport protocol.

@_date: 2007-05-02 22:34:49
@_author: Florian Weimer 
@_subject: Was a mistake made in the design of AACS? 
* Perry E. Metzger:
Sorry, but where's the security failure?  Where can you buy hardware
devices that can copy HD disks?  Or download software that does, with
a readily usable interface?
In that sense, even CSS hasn't really been broken.
Even the flurry of DMCA takedown notices isn't necessarily a bad move.
It might help to shape the future of how access to content is
regulated in some very particular way.

@_date: 2007-05-12 18:46:38
@_author: Florian Weimer 
@_subject: no surprise - Sun fails to open source the crypto part of Java 
* Ian G.:
The Sun JCE provider appears to be missing, which means that few
cryptographic algorithms are actually implemented in the source drop.
All the symmetric encryption algorithms are missing, for instance.

@_date: 2007-05-14 19:31:22
@_author: Florian Weimer 
@_subject: no surprise - Sun fails to open source the crypto part of Java 
* Ian G.:
The signing provider PKI is a joke, it's sole purpose is to ensure
that Sun has got a fax allegedly from you in which you promise that
you will comply with applicable export regulations.
The root CA list shipped in OpenJDK should be empty at this stage (at
least this is mentioned somewhere on the OpenJDK web page) because it
is not clear what the criteria are to populate it.

@_date: 2007-05-23 18:34:26
@_author: Florian Weimer 
@_subject: 307 digit number factored 
* Victor Duchovni:
But no one is issuing certificates which are suitable for use with
SMTP (in the sense that the CA provides a security benefit).  As far
as I know, there isn't even a way to store mail routing information in
X.509 certificates.

@_date: 2007-05-29 11:30:06
@_author: Florian Weimer 
@_subject: 307 digit number factored 
* Victor Duchovni:
Which runs into the same problem as HTTP because the set of recipient
domain names is not known at the time the TLS handshake occurs.
And if you use fingerprints, there is no need for PKI.  And in my
experience, PKI doesn't buy you that much if you need to configure
per-client privileges and things like that.  Using the DN instead of a
fingerprint doesn't seem to be worth the trouble.

@_date: 2007-11-06 10:54:20
@_author: Florian Weimer 
@_subject: ITU-T recommendations for X.509v3 certificates 
I'm looking for a halfway self-contained set of ITU-T recommendations
which are relevant for implementing X.509v3 certificates.  The
references in RFC 3280 appear to be incomplete; for instance, a
reference for ASN.1 itself is missing.
Or is it unreasonable to expect that the specs match what is actually
needed for interoperability with existing implementations (mostly in the
TLS, S/MIME area)?

@_date: 2007-11-20 09:41:43
@_author: Florian Weimer 
@_subject: fyi: Adi Shamir's microprocessor bug attack 
Perhaps I'm missing something, but real-world RSA implementations are
not vulnerable to this because they implement RSA blinding to prevent
timing attacks (which prevents a magic a * b fault from being exploited
deterministically) or verify the signature after creation (which
protects against random faults, a very good idea anyway).
Something can't be "new" and "big" if it's been addressed in GnuPG,
Crypto++ and others years ago. 8-P

@_date: 2007-10-03 10:39:05
@_author: Florian Weimer 
@_subject: Seagate announces hardware FDE for laptop and desktop machines 
* Simon Josefsson:
Perhaps this section wasn't updated?  A password-based lock method is
present in most laptop drives today.
But this exhibits an issue with disk-based encryption: you can't
really know what they are doing, and if they are doing it right.
(Given countless examples of badly-deployed cryptography, this isn't
just paranoia, but a real concern.)

@_date: 2007-10-04 12:37:12
@_author: Florian Weimer 
@_subject: Seagate announces hardware FDE for laptop and desktop machines 
-0400")
* Ivan Krsti?:
I think the really interesting question is what happens when you lose
a FDE-ed hard drive.  Do you still need to publish the incident and
contact potentially affected individuals?  If the answer is "no", I'm
sure this technology will be quickly adopted, independently of its
actual implementation.

@_date: 2007-09-24 19:49:31
@_author: Florian Weimer 
@_subject: OK, shall we savage another security solution? 
* Steven M. Bellovin:
Some of the models only have got a single USB connector.  I can't see
how they can ensure that they are always on the forwarding path.

@_date: 2007-09-24 21:52:48
@_author: Florian Weimer 
@_subject: OK, shall we savage another security solution? 
* Dave Korn:
The models in the shape of a USB stick haven't got a USB connector, at
least according to the spec sheet.
Some malware queues captured data and transmits it when a network
connection is available again.

@_date: 2008-08-08 23:28:19
@_author: Florian Weimer 
@_subject: OpenID/Debian PRNG/DNS Cache poisoning advisory 
* Eric Rescorla:
There are three sets of keys, for big-endian 32-bit, little-endian
32-bit and little-endian 64-bit.  On top of that, "openssl genrsa"
generates different keys depending on the existence of $HOME/.rnd (and
-3 creates yet another set of keys, but this is more in the league of
"different key length").  If the library is used for key generation
(instead of the command line tool), different keys might result.
On the other hand, the on-disk size would be comparable to the phishing
filter database.
Part of the problem of the CRL approach is that CAs usually have
policies against obtaining private keys and therefore can't prove to the
customer that their keys are compromised.  And adding a CRL entry when
the customer isn't convinced that they've got a problem is probably not
a good idea, either.

@_date: 2008-12-27 21:20:27
@_author: Florian Weimer 
@_subject: Security by asking the drunk whether he's drunk 
* Jerry Leichter:
This is also why I don't want browser vendors to remove CAs for which
they haven't got enough documentation, at least at this stage.  After
a few rounds of competitors attacking each other (and themselves as
well, because who knows who controls some of the older private keys
these days), the only CAs left are those where initiating RA
procedures is sufficiently difficult for law-abiding citizens--and
cost is a very likely discriminator in this area.
And for most sites, those extra $$$ are better spent on hosting with
some sort of security monitoring.

@_date: 2008-01-01 22:34:23
@_author: Florian Weimer 
@_subject: Question on export issues 
-0500")
* Ivan Krsti?:
Debian has been filing notices for crypto export for years (at BXA for
some time; nowadays, it's likely BIS).  So far, nobody there has
complained that what is being done is insufficient.
Here are some details: The actual process may have changed a bit over the years.

@_date: 2008-01-05 11:48:26
@_author: Florian Weimer 
@_subject: DRM for batteries 
* Marcos el Ruptor:
If the law is on your side, you don't need strong cryptography.

@_date: 2008-01-10 10:27:46
@_author: Florian Weimer 
@_subject: "I am ashamed of you. They couldn't hit an elephant at this distance" 
* Peter Gutmann:
Has anybody read the original column/editorial/whatever in the Sunday
Times and can tell whether Mr Clarkson has, in fact, claimed that he
actually lost money?
The secondary reporting is very unclear on this point.

@_date: 2008-01-10 19:14:24
@_author: Florian Weimer 
@_subject: "I am ashamed of you. They couldn't hit an elephant at this distance" 
* Ben Laurie:
The reports I've seen claimed that this was a direct debit transaction.
This means that a (supposedly properly vetted) organization approaches
the bank, claims it's been properly authorized by the account holder,
and requests transfer of money from that account.
A standing order is an instruction to the bank, issued by the account
holder, that a fixed amount of money shall be transferred at fixed
intervals until further notice (for instance, in Germany, it's typically
used to pay your monthly rent).
Direct debit sounds dangerous, but there's a money-back guarantee by the
bank.  This is why I find it unlikely that Mr Clarkson has actually lost
money.  And if you read them carefully, some of the reports do not claim
that he did.
Setting up a standing order typically requires that the attacker
sucessfully impersonates the account holder to the bank.  The attacker
should need more information to mount this kind of attack than what Mr
Clarkson published.
(To our U.S. readers: Your banking system is hopelessly antiquated, so
don't worry if this doesn't make any sense to you.)

@_date: 2008-01-11 22:25:42
@_author: Florian Weimer 
@_subject: Foibles of user "security" questions 
* Jerry Leichter:
It's been claimed that once you reach the retirement age, one person in
ten hasn't got any fingerprints which can be used for biometric

@_date: 2008-07-04 22:43:32
@_author: Florian Weimer 
@_subject: German banks liable for phishing (really: keylogging) attacks 
* Stephan Neuhaus:
"District court" may be a bit misleading, it's the entry-level court for
this particular type of dispute, at the lowest place in the hierarchy.
The "latest" part is not clear.  I'm also puzzled that forensics could
not recover the actual malware.
(A keylogger alone is not quite good enough--you need to disrupt
transmission of the one-time password to the bank's server if you want
to to use the password later on.  OTOH, the disruption component does
not necessarily appear in AV descriptions.)
Well, the open question is not whether the bank has to take the risk
(after all, the transaction has been successfully disputed, even before
the case went to court), but if the customer was negligent and needs to
share some of the damage.
For instance, if a computer takes 15 minutes to boot, constantly
displays pop-up ads, and sporadically shows error messages during
browsing, I would hope that it's reasonable to assume that the machine
is not safe for on-line banking--no matter what the anti-virus says
about the state of the machine.

@_date: 2008-07-05 01:36:10
@_author: Florian Weimer 
@_subject: ITU-T recommendations for X.509v3 certificates 
* Peter Gutmann:
I should have written that my main goal was to extract the public key
material, and perhaps the validity period.  I want to use the
certificates as interoperable public key containers, mainly in order to
be able to rely on proven TLS implementations for encryption and
I guess parsing X.509 certs to derive further semantic content is
comparable to mail header parsing.  That is a futile exercise, too, but
sometimes unavoidable (for finding spam injection points, for instance).
But to be honest, I really don't see the point of extracting further
data from the certificates.  I can't reach OCSP servers and CRL
distribution points anyway because they are firewalled off.  I still
need to map a DN to some application-specific entity, and I need to
grant specific capabilities to it because I don't want to grant blanket
permission to the CAs involved--but this means I can directly bind this
metadata to the certificate, using the DN instead does not really
simplify set-up.  The lack of indirection makes key rollover more
difficult, granted, but you don't have to deal with broken random number
generators every other day, so I'm not sure if this is such a bad
I've got a couple of X.509v1 certs with extensions in production use,
which are a bit difficult to phase out. 8-( Turns out that this is not
so interoperable after all.

@_date: 2008-07-05 01:42:02
@_author: Florian Weimer 
@_subject: Strength in Complexity? 
* Peter Gutmann:
Are you sure that the constraints are not supposed to be applied when
the root certificate is actually processed, after its signature has been
verified by the trust anchor?

@_date: 2008-07-05 01:57:34
@_author: Florian Weimer 
@_subject: Strength in Complexity? 
* Arshad Noor:
First of all, a simple SKSML request for a symmetric key is a whopping
77 lines of SOAPWSS/whatever XML; the server response is 62 lines even
without the container.  If this is not enough to make every complexity
fanboy happy, I don't know what can do the trick.
On a more serious note, I think the criticism probably refers to the
fact that SKSML does not cryptopgrahically enforce proper key
management.  If a participant turns bad (for instance, by storing key
material longer than permitted by the protocol), there's nothing in the
protocol that stops them.

@_date: 2008-07-05 15:03:37
@_author: Florian Weimer 
@_subject: Strength in Complexity? 
* Peter Gutmann:
Let me rephrase my remark: The trust anchor is conceptually separate
from a root CA certificate.  It is only used to validate it the CA
certificate.  Nothing in that section gives you permission to ignore
extensions on the CA certificate (skipping the first entry in the
certification path).  In addition, the trust anchor cannot be used
directly to verify certificates issued by the CA because the subject DN
does not match.  Ergo, the extensions on the CA certificate are still in
I think your interpretation actually leads to a non-compliant
implementation.  Obviously, wording of that section could be less

@_date: 2008-07-05 20:36:23
@_author: Florian Weimer 
@_subject: Strength in Complexity? 
* Arshad Noor:
As far as I understand it, you don't actually change protocols, which
means that there's likely no way around this problem.
No, there are things like digital cash and mental poker which do not
work with a trusted third party.  I think it's even possible to compute
RSA signatures from a split private key in a way that is secure against
byzantine failure (IOW, a certain number of key holders needs to
cooperate to forge a signature or recover the private key).  There's
also quite a bit of research on operations on encrypted databases.
Of course, you cannot actually run an ordinary web shop on top of such
protocols because interfaces to the public and to the processors are
essentially fixed.  Cryptographically securing the middle end seems
rather pointless to me because the public-facing front end is the
component that causes most of the trouble.  (And I'm not fully convinced
that more encryption is the answer to that.)

@_date: 2008-07-07 03:57:10
@_author: Florian Weimer 
@_subject: Secure voice? 
* Allen:
Looks a bit fishy because Nuance Communications hasn't issued a similar
press release about their cooperation.  There's also a total lack of
technical content.
And calling voice recordings "biometrics" is a bit of a stretch--you
could ask your customer about color preferences and label it
"biometrics", too.

@_date: 2008-07-10 14:42:03
@_author: Florian Weimer 
@_subject: Kaminsky finds DNS exploit 
* Paul Hoffman:
I haven't seen credible claims that the underlying issue can actually be
fixed in the classic DNS protocol.  There are workarounds on top of
workarounds.  A real fix requires more or less incompatible protocol
changes, and at that point, it might be easier to deploy DNSSEC instead.

@_date: 2008-07-13 20:50:37
@_author: Florian Weimer 
@_subject: Kaminsky finds DNS exploit 
* Jack Lloyd:
It's not a smokescreen, it's a statistical workaround.
CERT/CC mentions this:
I think the CERT/CC statement is more approriate.

@_date: 2008-07-14 16:27:58
@_author: Florian Weimer 
@_subject: Kaminsky finds DNS exploit 
* John Levine:
It requires code changes on both types of servers, in order to make them
more scalable.
Implementors say that in many cases, their software as it's currently
implemented can't take the load.  It's not much worse than web traffic,
that's why I think it can be made to work (perhaps easier with kernel
support, who knows).  But code changes are apparently required.
And once you need code changes, you can roll out DNSSEC--or some
extended query ID with 64 additional bits of entropy.
On top of that, some operators decided not to offer TCP service at all.

@_date: 2008-07-16 22:06:31
@_author: Florian Weimer 
@_subject: =?utf-8?Q?=E2=80=9CA?= Practical Attack on the MIFARE 
* Karsten Nohl:
Isn't this a bit of wishful thinking?
The dynamics are probably very involved because you usually don't buy
from NXP, but an integrated product from a reseller.  An upgrade isn't a
free patch, either, so it needs some sort of budgeting and planning.
That being said, the chip should have been phased out years ago.  But
within half a year?  No way.

@_date: 2008-07-20 12:50:47
@_author: Florian Weimer 
@_subject: Looking through a modulo operation 
I've got a function f : S -> X x S where S = (Z/2Z)**96 and
X = (Z/2Z)**32.  Suppose that s_0 is fixed and (x_i, s_i) = f(s_{i-1}).
(f implements a PRNG.  The s_i are subsequent internal states and the
x_i are results.)
Now f happens to be linear.  I know the values of x_i, x_{i+1}, ...,
x_{i+k} module N, for a fixed, known N.  N is odd (but divisible by 9).
Is it possible to recover s_i with reasonable effort (better than brute
force, and k should be in the hundreds, not thousands)?  And if yes, how?
Prediction of candidates for x_{i+k+1} with high probability would be
helpful, too.
(Obviously, using f as an unpredictable PRNG is not a good idea.  But if
there's a real attack I can present, convincing the authors to replace
it would be so much easier.)

@_date: 2008-06-16 22:41:31
@_author: Florian Weimer 
@_subject: skype claims they have no technical means to assist wiretapping 
* Perry E. Metzger:
It's sort-of industry practice to wiretap peer-to-peer voice-over-IP
environments by asking the naming service not to signal the availability
of a direct, end-to-end, but to fall back to some media gateway (which
is there for interoperability with the phone network anyway).  I'm
surprised that is compliant with regulatory requirements, but
apparently, it is.
So, at that point, it wouldn't be "Skype-to-Skype" anymore.  It also
solves the problem of getting access to the media stream (which is the
difficult part for traditional VoIP systems, which are encrypted only in
the marketing brochures).

@_date: 2008-03-22 09:48:03
@_author: Florian Weimer 
@_subject: How is DNSSEC 
* James A. Donald:
DNS is hierarchical.  Nobody wants the DoD (who are traditionally quite
good at keeping secret data) or any other institution to keep keys at
important positions in the hierarchy.  And nobody wants to be the keep
irreplaceable keys, either, which makes introduction at levels below the
DNS root difficult.
This is not a problem with the browser PKI because it's possible to
replace root certificates with a software update (which can be automated
in many cases).
And as Bill pointed out, it's not possible to use the DNS keys directly.
However, you can bootstrap another key based on data from DNS.  This
even works without DNSSEC.  DKIM does that, for instance.

@_date: 2008-05-23 23:40:45
@_author: Florian Weimer 
@_subject: [ROS] The perils of security tools 
* Peter Gutmann:
This shouldn't be the case.  There's a clear policy that non-packaging
changes (basically, anything beyond trivial build fixes and pathname
changes for FHS compliance) should be submitted upstream.
If you name names, we can certainly fix that.  I couldn't figure out
what packages are affected on Debian's side.

@_date: 2008-05-23 23:49:01
@_author: Florian Weimer 
@_subject: [ROS] The perils of security tools 
* Ben Laurie:
It's mentioned in the manpage for a function that eventually calls the
function that was (correctly) patched--through a function pointer.  The
incorrectly patched function looks somewhat parallel, but it's not.
There is no local comment in the source code for this particular case of
uninitialized memory access.
AFAIK, this piece of code is not really related and rarely used outside
OpenSSL itself.  And in the OpenSSL case, the fread call always
overwrites the whole buffer, it seems.

@_date: 2008-05-23 23:33:46
@_author: Florian Weimer 
@_subject: [ROS] The perils of security tools 
* Ben Laurie:
The PID dependency is there because of the need for fork
support--obviously, the PRNG must return a different key stream in the
parent and child process, but the two cannot communicate with each

@_date: 2008-05-27 19:48:49
@_author: Florian Weimer 
@_subject: RIM to give in to GAK in India 
* Dave Korn:
                                                   ********************
                                                        **************
                                               ********************
If you look closely, there's no contradiction.  Non-enterprise customers
don't run their own gateway, so RIM just acts as a telco, which
naturally has got access to all the data.  The Indian government doesn't
need "special access", either, because Lawful Intercept services etc.
aren't that special anymore.

@_date: 2008-11-14 23:16:14
@_author: Florian Weimer 
@_subject: voting by m of n digital signature? 
* James A. Donald:
What about this?
  Christian Cachin, Asad Samar
  Secure Distributed DNS
Or do you require that potential signers must not be able to prove
that they signed?

@_date: 2008-11-22 14:29:40
@_author: Florian Weimer 
@_subject: Raw RSA binary string and public key 'detection' 
* Dirk-Willem van Gulik:
If the padding scheme is decent, this should not be possible without
breaking RSA.
However, the proposal limits keys to about 250*6 bits, which seems
rather restrictive for RSA keys.
I'm also concerned about reflective attacks were you ask someone who's
trusted by the data owner to decrypt the data for you, possibly in an
automated fashion.

@_date: 2008-09-09 21:26:46
@_author: Florian Weimer 
@_subject: More US bank silliness 
* Peter Gutmann:
To keep this in perspective, note that you could disable the location
bar altogether in FF2 (and that default changed in FF3), so the FF3
approach is actually an improvement.

@_date: 2009-02-13 22:25:30
@_author: Florian Weimer 
@_subject: Property RIghts in Keys 
[Moderator's note: I've been clamping down on the IP discussion since
not much more really new was being said, but I'm allowing this through
because it brings up an interesting side point -- I will reply to it
to move to that discussion. --Perry]
* Perry E. Metzger:
4) It can't be trademarked because the company named in the DN is long
   gone
(It's quite strange that so many of the browser root certs use DNs
which aren't correct anymore.)

@_date: 2009-01-12 21:52:58
@_author: Florian Weimer 
@_subject: What risk is being defended against here? 
* Jerry Leichter:
I wild guess would be fraudulent testing organizations which claim to
have been subject to fraud themselves, and the testing standards body
answered with some sort of regulation.
(For certain German language test instances at certain sites, there
used to me impossibly high participation numbers.  The alleged
certificates of the results were probably simply forged, but that's
where I got the idea from.)

@_date: 2009-03-04 22:45:06
@_author: Florian Weimer 
@_subject: Judge orders defendant to decrypt PGP-protected laptop 
* Stephan Somogyi:
The difference is that having your residence searched does not require
active cooperation from you.  You don't even have to disclose all your
residences which should be searched.  Forcing a suspect to decrypt
data is rather questionable because it is difficult to draw a line
between decrypting, decompressing, selecting, and producing relevant
FWIW, the case which sparked this thread is rather special because
when the laptop was searched at the border, the files were visible to
a border guard.  I guess this constellation is highly unusual.

@_date: 2009-11-03 21:25:10
@_author: Florian Weimer 
@_subject: First Test for Election Cryptography 
* Saqib Ali:
It needs a trusted printer, right?  (Which is no regression, different
sizes for yes/no circles are a very old trick.)

@_date: 2009-11-08 19:48:23
@_author: Florian Weimer 
@_subject: Crypto dongles to secure online transactions 
* John Levine:
There are some countries which use per-transactions one-time
passwords.  These methods has been broken as well.
There are already some commercial implementations (e.g. those
following ZKA's Secoder standard).  IBM apparently has something in
the works called ZTIC.  There used to be the FINREAD standard.
Attacks which would break these authentication schemes have already
been observed in the wild.  There are various means to trick people
into providing authorization for fraudulent transactions.  Tell them
that they have the opportunity to buy an expensive car at a fraction
of the price, or offer them a very attractive financial investment,
for instance.
$50 per device doesn't seem to be much, but you actually need a huge
amount of fraud that's actually prevented until it's cost-effective to
roll this out.  I don't think banks which offer real electronic
banking (that is, something pretty much like Paypal, but with consumer
rights) can legally tell high-risk from low-risk customers, so you're
basically stuck with general rollout.  While $50 per device may seem a
bit on the high side, I think it's not unrealistic if you consider
costs associated with personalization, branding, etc.
There's also the issue that a large amount of online banking happens
from work during the lunch hour.  USB dongles with software
installation requirements are problematic for those users.

@_date: 2010-04-22 17:58:04
@_author: Florian Weimer 
@_subject: What's the state of the art in factorization? 
* Thierry Moreau:
You might be able to make it to CNN if your spin is really good.

@_date: 2010-04-22 18:59:49
@_author: Florian Weimer 
@_subject: What's the state of the art in factorization? 
* Thierry Moreau:
I was referring to news of a breach (whether through factoring or
otherwise), not the key management procedures as such.

@_date: 2010-07-26 07:35:27
@_author: Florian Weimer 
@_subject: MITM attack against WPA2-Enterprise? 
* Donald Eastlake:
On the other hand, group key vulnerabilities are nothing new.  It's
just that many protocol designers seem to not understand them.  Back
when Cisco proposed XAUTH for IPsec, there was a heated discussion
about password strength and other irrelevancies, but as far as I could
later reconstruct the discussion, no one objected to the group key
concept as such.  It was only much later, when people used XAUTH in
large deployments for providing general Internet access over insecure
media, that the group key was recognized as a vulnerability.
It's amazing that people still fail for this group key thing.  There
is quite a simple rule: If you choose the secret bits without
constraints (except length and formatting), and proceed to share those
bits, there can be no protection from those with whom you share, no
matter what cryptographic algorithms you use.

@_date: 2010-09-28 07:47:08
@_author: Florian Weimer 
@_subject: Obama administration revives Draconian communications intercept plans 
Isn't this just a clarification of existing CALEA practice?
In most jurisdictions, if a communications services provider is served
an order to make available communications, it is required by law to
provide it in the clear.  Anything else doesn't make sense, does it?
Service providers generally acknowledge this (including Research In
Motion, so I don't get why they are singled out in the article).
There are indications that governments have access to Skype these
days  Here's a blog post mentioning it:
(Udo Vetter is sometimes a bit sensationalist, though.)  Another
indicator is that German law enforcement no longer calls for new laws
granting them access to Skype traffic.
In any case, the cleartext requirement for lawful intercept has always
been very public.  Oddly enough, it has not been perceived as some
sort of crypto regulation, although it puts some constraints on key
management.

@_date: 2010-09-28 20:34:00
@_author: Florian Weimer 
@_subject: ciphers with keys modifying control flow? 
* Steven Bellovin:
AES.  See Fran?ois Koeune, Jean-Jacques Quisqater, "A timing attack
aganst Rijndael". Universit? catholique de Louvain, Technicl Report

@_date: 2013-06-30 20:16:09
@_author: Florian Weimer 
@_subject: [Cryptography] Snowden "fabricated digital keys" to get access 
============================== START ==============================
* John Gilmore:
Most likely, as part of his job at the contractor, he had
administrator access to a system which was used for key management,
perhaps to apply security updates, manage backups or fix the
occasional glitch.  This is precisely the kind of low-level grunt work
that I expect is outsourced to contractors.
It's also possible that he was directly charged with key management.
I can image that someone thought that as long as some agency committee
made the actual decisions, it was fine to hire an external data typist
who entered the committee decision in to the key management system.
It's really funny that "NSA-level security" has now turned pejorative.

@_date: 2014-04-20 22:22:50
@_author: Florian Weimer 
@_subject: [Cryptography] Something that's bothering me about the 
* Guido Witmond:
And you can reuse buffers only in a very limited fashion.
With the most obvious solution, your I/O bandwidth will be limited by
your garbage collection throughput.  That might be problematic.

@_date: 2014-08-31 15:42:50
@_author: Florian Weimer 
@_subject: [Cryptography] [cryptography] STARTTLS for HTTP 
* John Levine:
For most web sites, it translates to a measurable loss of audience.
It's certainly significant enough that server operators won't feel
comfortable about locking out such browsers.
This is not necessarily true, you can still buy vendor support for an
SNI-incapable browser.
That's true, but again, you wouldn't necessarily need to update
clients if it's strictly at the transport layer because the TLS could
be terminated on a proxy.
Turning off certificate warnings for everything would disable
authentication for everyone, including those who have obtained proper

@_date: 2014-08-31 22:26:31
@_author: Florian Weimer 
@_subject: [Cryptography] [cryptography] STARTTLS for HTTP 
* Tony Arcieri:
Correct.  Secure (HTTPS-only) cookies wouldn't be sent, either, and
whatever else is enabled by https:// mode right now would remain
disabled, too.

@_date: 2014-01-05 19:51:47
@_author: Florian Weimer 
@_subject: [Cryptography] Dual_EC_DRBG backdoor: a proof of concept 
* Jon Callas:
Conventional wisdom, yes, but the mathematics don't actually add up:
Koblitz and Menezes, "Another look at provable security II",

@_date: 2014-03-13 10:51:18
@_author: Florian Weimer 
@_subject: [Cryptography] GnuTLS -- time to look at the diff. 
* Lodewijk andr? de la porte:
Functional programming replaces loops with GOTOs, disguised as
recursive function in tail positions.  Usually, this does not improve

@_date: 2014-03-13 11:26:01
@_author: Florian Weimer 
@_subject: [Cryptography] GnuTLS -- time to look at the diff. 
* Harald Koch:
OpenSSL has a confusing API, is difficult to enhance (especially
upstream), and used to lack ABI stability.  These issues alone
encouraged development of new libraries.  The fact that the OpenSSL
license requires you to put a typo in your advertising material
("rouines") is comparatively minor.

@_date: 2014-11-01 10:05:15
@_author: Florian Weimer 
@_subject: [Cryptography] Vulnerability of RSA vs. DLP to single-bit faults 
* Peter Gutmann:
What about Dan Boneh, Richard A. DeMillo, Richard J. Lipton, ?On the
Importance of Checking Cryptographic Protocols for Faults? (1997)?  It
shows how to break RSA implementations common at that time with a
random fault occurring during signature computation.

@_date: 2014-11-02 12:27:14
@_author: Florian Weimer 
@_subject: [Cryptography] Vulnerability of RSA vs. DLP to single-bit faults 
* Tom Mitchell:
Well, Sun blamed it on IBM.  We don't know if it was actually IBM's
fault or even an IBM part.

@_date: 2014-11-22 14:12:41
@_author: Florian Weimer 
@_subject: [Cryptography] Walmart fooled by non-authenticated web pages 
* Jerry Leichter:
I expect that Walmart doesn't disclose the margins on individual items
to each store.  The clerk who approved the discount is unlikely to
have all relevant information.  Usually, when it comes to discounts,
companies have policies specifying which discounts can be granted by
which employees.  It would be easy to restrict local approval directly
in the store to, say, 10% or $50 at most, and require approval from
higher up (presumably with access to real information) for everything
On the other hand, maybe Walmart looked at their numbers, figured out
that the price-matching offer wasn't really used all that much, and
estimated that developing a policy (and staffing the approval process)
would cost more than the occasional blunder.
Even in this case, the popularizing its price-matching offer, and the
underlying message that Walmart is a trusting supplier who treats
customers fairly even to a fault, is likely worth far more than the
money they have lost because of the erroneous discounts.

@_date: 2014-09-03 22:36:53
@_author: Florian Weimer 
@_subject: [Cryptography] [cryptography] STARTTLS for HTTP 
* John Levine:
There's currently no way for a sever operator to state that http://
and https:// offer the same content.
This doesn't work because it's not just the UI indicators.  The change
from https:// to http:// alters browser and web application behavior
as well.  That's why it's preferable to make the change at a lower
layer, so tht the http:// scheme can be reduced.

@_date: 2015-04-03 21:09:14
@_author: Florian Weimer 
@_subject: [Cryptography] Fwd:  OPENSSL FREAK 
* Ray Dillinger:
The trouble here is that most primitives are considered broken well
before a death node can be constructed which could be recognized by a
program written a decade ago.  For example, there is wide consensus
not to use HMAC-MD5 or SHA-1, although no concrete proof of their
unsuitability for practical applications has been published.
Something which could be considered a death note for DES arrived much
later than the successful brute-force attacks on it, and a
death-note-checking implementation would still have neeed a lot of
forethought (and a bit of luck).

@_date: 2015-04-19 23:09:34
@_author: Florian Weimer 
@_subject: [Cryptography] Entropy is forever ... 
* R. Hirschfeld:
When just talking about the a single password, the universal
programming language might have (among other things) just a special
instruction to output it.  This may not be as preposterous as it
sounds?password crackers solve a similar problem (they try to probe
passwords of encreasing complexity), and they come with dictionaries
of common words.
More importantly, the relative ordering of password complexity will
depend a *lot* on accidents such as choices of instruction encodings
for the compleixty-measuring machine.  I also find it difficult to
believe that for these three strings,
there is a more efficient encoding than just output the characters one
by one, but the first one is a regular German word, the second one is
insecure (pronounceable) output from pwgen, and the third one is
supposed to be purely random.

@_date: 2015-12-28 22:27:45
@_author: Florian Weimer 
@_subject: [Cryptography] China doesn't pass law requiring tech firms to 
"28 Dec 2015 17:22:14 -0000")
* John Levine:
It's quite similar to the situation in Germany
If the obligated party protects the telecommunication entrusted to it
for transmission against unauthorised cognisance by technical measures
on the network side, it must revoke the protective measures used by it
for this telecommunication for the copy of the intercept to be
provided at the handover point.
In both cases, it is unclear if this means that if the obligated party
happens to own a CA in the browser PKI, they must issue interception
certificates and conduct a man-in-the-middle attack to obtain a
clear-text copy of the traffic.

@_date: 2015-02-22 13:10:18
@_author: Florian Weimer 
@_subject: [Cryptography] [cryptography] Equation Group Multiple Malware 
Baker's message of "Fri, 20 Feb 2015 13:05:03 -0800")
* Henry Baker:
The BRD did it as well (so far documented only for border-crossing mail),
and even engaged in large-scale suppression of incoming mail from the DDR,
as some sort of early spam filter (they wanted to get rid of propaganda
material from the DDR).

@_date: 2015-03-27 18:42:19
@_author: Florian Weimer 
@_subject: [Cryptography] D-Wave, RSA, and DLP 
* Mattias Aabmets:
How so?  Can you show us the math?
I don't think enough is known publicly about the D-Wave architecture
to tell if it is particularly suited to integer factorization.  At an
alleged price of $10 million, you can buy a *lot* of general-purpose
computing power, certainly enough to make factorization of 512 bit IFC
keys practical in a reasonable amount of time.
Most publications argue that the qbit requirements for the EC DLP are
substantially higher (> 1000 qbits for certain 224 bit curves).

@_date: 2015-03-27 18:57:51
@_author: Florian Weimer 
@_subject: [Cryptography] "Most Americans Don't Mind Being on Candid 
Mar 2015 19:34:08 +0000")
Perceptions of reasonable trade-offs change over time.
Germany ceased to track people by marking them with radioactive
isotopes, although the technology has improved considerably since the
practice was abolished.
It's difficult to deal with domestic threats in any other way.  The
people caught in the dragnet have rights; they are often citizens or
at least legal residents.
I think the many of the current problems are caused by the desire to
keep (surveillance) capabilities secret for some reason.  This means
that we suddenly have secret evidence in what should be an ordinary
criminal trial.

@_date: 2015-09-02 22:25:26
@_author: Florian Weimer 
@_subject: [Cryptography] Vulnerability of RSA vs. DLP to single-bit faults 
* Peter Gutmann:
A while back, it occurred to me that deployment of forward secrecy in
TLS gives us a wide range of test cases, and implemented a crawler.
Today, we finally published the results:
The number of leaked private keys may seem fairly low (272), but so
was the crawler bandwidth.  I'm sure you'd find additional affected
vendors if you conducated a lot more TLS handshakes.  (Two of the
affected devices had really low leak rates.)

@_date: 2015-09-03 19:46:52
@_author: Florian Weimer 
@_subject: [Cryptography] Vulnerability of RSA vs. DLP to single-bit faults 
* Phillip Hallam-Baker:
You also need to protect p and g for finite-field DH.  When you change
those, it seems less obvious what might happen.  Klima and Rosa
described a key recovery algorithm for DSA based on deliberate choices
of p and g, but maybe there are results for random changes as well.

@_date: 2015-09-03 19:51:04
@_author: Florian Weimer 
@_subject: [Cryptography] Vulnerability of RSA vs. DLP to single-bit faults 
* Ralf Senderek:
I found the format somewhat difficult to digest.  Is there are more
accessible version?  I wonder if they used specifically hardened
devices, or just the regular CPU versions.
I'm not sure if that's worrying.  I don't think a general-purpose
computing device I own should have private keys I cannot access or
read in the first place.

@_date: 2015-09-03 22:08:07
@_author: Florian Weimer 
@_subject: [Cryptography] Vulnerability of RSA vs. DLP to single-bit faults 
* Ralf Senderek:
Lenstra's side-channel attack on RSA-CRT is extremely powerful because
it does not need any assumption about the nature of the fault.  It
just does not matter, as long as it only affects one of the
components.  As far as I understand it, other side-channel attacks do
not have this property, you have to apply considerable knowledge of
implementation details (which can often be reverse-engineered,

@_date: 2015-09-19 22:32:10
@_author: Florian Weimer 
@_subject: [Cryptography] Comey: targeted ads => plaintext access 
* Henry Baker:
Or access to the ads.
This was written in 2007, I think.

@_date: 2015-09-21 09:00:39
@_author: Florian Weimer 
@_subject: [Cryptography] Comey: targeted ads => plaintext access 
* Bill Frantz:
But in an advertising context, these environments have to be leaky,
otherwise you could not redirect users to other sites when they click
the ads, or bill for showing specific ads or clicking on them.

@_date: 2016-04-03 11:12:11
@_author: Florian Weimer 
@_subject: [Cryptography] On the Impending Crypto Monoculture 
* Peter Gutmann:
Authenticated encryption is always two-pass in the recipient because
you cannot start processing the data before you have authenticated it,
which requires the entire (sub)message.  Not everyone bothers to wait
with data processing until the authentication happens, of course.
(And the problem isn't specific to encrypting modes.)
I don't think it's a huge burden to have buffering on the sending side
as well.
(Regardingo OCB, doesn't need periodic rekeying at intervals that are
practically relevant?)
I think you mean strong crypto or algorithmic crypto.  They use
codewords, which are form of cryptography.
One problem to keep in mind that it is still difficult to build actual
protocols from those primitives.  For example, if you ditch TLS in
favor of one of those minimal cryptographic libraries, it is likely
that your code which attempts to implement an encrypted byte stream on
top of them will be subject to replay attacks.

@_date: 2016-12-06 11:53:14
@_author: Florian Weimer 
@_subject: [Cryptography] OpenSSL and random 
* Theodore Ts'o:
The error checks don't look right.  The errno variable won't be set if
getrandom succeeds.  The system call returns a buffer length, not just
a 0/-1 flag indicating success/failure.

@_date: 2016-12-20 22:41:14
@_author: Florian Weimer 
@_subject: [Cryptography] Photojournalists & filmmakers want cameras to be 
Baker's message of "Thu, 15 Dec 2016 10:37:55 -0800")
* Henry Baker:
Aren't most of these people freelancers, and their relationship with
their buyers is rarely cosy?  In-camera encryption risks shifting even
more power from photographers to media companies.
Encryption rarely benefits device owners because one of its primary
applications is to restrict what people who happen to have physical
access to a piece of technology can do with it.  If you already own
the device, adding encryption means you lose something.

@_date: 2016-03-29 20:43:56
@_author: Florian Weimer 
@_subject: [Cryptography] USG Moves to Vacate Apple Decrypt Order 
* Phillip Hallam-Baker:
Surely consumers will get a refund because the iPhone 5c has a
world-ending, critical security flaw?  And we are expected to believe
that this flaw happened by accident, as the result of their
engineering practices, and not through a deliberate assault of their
best brains on their own technology.
I find the media reporting on the outcome rather puzzling.

@_date: 2016-11-07 22:41:53
@_author: Florian Weimer 
@_subject: [Cryptography] "we need to protect [our dox] by at least 
message of "Sat, 5 Nov 2016 14:29:38 +0100")
I think you're missing the point.  The message at the time was that
online transactions could be made reasonably secure, so that the are
beneficial to the parties involved.  This was and is evidently true.
Back in the 90s, people weren't quite ready to believe that, so some
smart people added some cryptography nobody quite understood.  That
gave everyone the confidence they were desperate for.  That the
cryptography was broken from the start, that the X.509 standard was
completely at odds with Internet domain names (and still is today, to
some degree), that the Internet threat model was wrong even back then,
that the user interface was a mess, all that did not matter.  It
wasn't about the technical details.

@_date: 2016-11-07 22:47:34
@_author: Florian Weimer 
@_subject: [Cryptography] "we need to protect [our dox] by at least 
Baker's message of "Sat, 05 Nov 2016 10:20:37 -0700")
* Henry Baker:
Current public discourse has tremendously raised the perceived cost of
being in the wrong.  Typically, it is possible to negotiate a way
forward for everyone involved, while all parties can somehow save face
in the public eye (at least formally).  In a fully public environment,
this wouldn't be possible, so there wouldn't be much incentive to make
any compromise at all.

@_date: 2016-10-01 11:26:25
@_author: Florian Weimer 
@_subject: [Cryptography] Use Linux for its security 
* Henry Baker:
Actually, it's not.  Common Lisp does not mandate bounds checking for
AREF or SVREF.  One can hope that most implementations perform it by
default, but for those implementation with optimizing compilers, it
can be easily switched off.  The language rules even say that if a
supposedly-safe function is called from a function compiled without
safety checks, the safety checks in the called functions do have to be
performed (so safety is not modular).
The main difference to C is that Common Lisp arrays have an explicit
length, which makes bounds checks easy to implement, either manually
or automatically by the compiler.

@_date: 2016-10-02 09:44:40
@_author: Florian Weimer 
@_subject: [Cryptography] another security vulnerability / travesty 
* Peter Gutmann:
An account breach doesn't mean that email is actually compromised.
I expect that for redirecting faxes, you don't even need to guess a
password.  You just need to obtain a fax machine, and then place a
phone call or visit a store.
Another explanation is that faxes going wrong are routinely blamed on
the victims.  Look at UK phone hackingthe network operators hardly
received any criticism for enabling that.

@_date: 2016-10-02 15:07:04
@_author: Florian Weimer 
@_subject: [Cryptography] Use Linux for its security 
* Ron Garret:
Along with writable literals, I suppose. :-/
GCC got rid of them how many years ago?  20?  And that is with kernel
enforcement on most system.  Ocaml is phasing them out as well.
Again, then why wasn't it standardized, along with a suitable error
It leads to developers switching of safety checks because they know
their code is bug-free (they wrote it, after all), and it's also the
most important part of the system and users cannot afford to have it
drag down the whole system.
It appears that safe code is only safe if it is evaluated as part of a
safe call.
Address Sanitizer almost does it for C.  It is possible there as well.
(The almost part refers to the limited size of the red zone.)

@_date: 2016-10-02 21:41:58
@_author: Florian Weimer 
@_subject: [Cryptography] distrusted root CA: WoSign 
* Georgi Guninski:
The idea is to whitelist certificates which have been logged to the
Certificate Transparency servers prior to a cut-off date.  As long as
you trust the timestamps of those servers (or even just your previous
downloads you have kept), the CAs cannot backdate that.

@_date: 2016-10-03 18:39:18
@_author: Florian Weimer 
@_subject: [Cryptography] phone firmware ... to mod, 
message of "Sun, 2 Oct 2016 13:46:07 -0700")
* John Denker:
I looked at this a few months ago.
If you want timely updates, you need to get a Google-branded device.
(But on the privacy front, Google might be considered slightly worse
than Apple, but that can change at each iOS update, obviously.)
With Priv, Blackberry aimed to be the OEL of Android (even publishing
similar statistics about patch delays).  I didn't find this very
convincing.  Priv is probably history by now anyway.
The update situation with CyanogenMod is a bit unclear.  Patches for
security updates generally look like this:
I suspect that more information is in the CYNGNOS-3257 ticket, but
that's not publicly viewable.  It's already a lot of work to map these
changes back to the Google fixes, and this lack of transparency makes
it even harder to see if they do the right thing.
(I still haven't bought a smartphone.)

@_date: 2016-10-29 21:53:27
@_author: Florian Weimer 
@_subject: [Cryptography] How to prove Wikileaks' emails aren't altered 
* John Levine:
The messages contain signed timestamps, so if they are indeed forged,
then a lot of planning went into this.  And to avoid detection, you'd
have to prevent message delivery to the recipients (or at least
reading).  Sure, all this is possible in theory, but it seems a bit

@_date: 2016-09-02 07:52:42
@_author: Florian Weimer 
@_subject: [Cryptography] "Flip Feng Shui: Hammering a Needle in the 
message of "Thu, 1 Sep 2016 11:33:16 -0400")
* Jerry Leichter:
Why bother with patching public keys, making them amenable to
factorization, if you can patch executable code instead?
If you can target executable code (and I see why not, it's all the
same to KSM), it is very clear that there cannot be a software-only
defense.  (The authors try to frame this as a software problem which
needs fixes in GnuPG etc.)

@_date: 2016-09-03 10:24:22
@_author: Florian Weimer 
@_subject: [Cryptography] "Flip Feng Shui: Hammering a Needle in the 
"Fri, 02 Sep 2016 12:08:56 +0200")
* Jeff Burdges:
Do you mean Lenstra's attack on unverified CRT?  It targets RSA
signing operations, while the paper discusses an attack on RSA
signature verification.

@_date: 2016-09-03 11:25:55
@_author: Florian Weimer 
@_subject: [Cryptography] "Flip Feng Shui: Hammering a Needle in the 
message of "Fri, 2 Sep 2016 10:56:10 -0400")
* Jerry Leichter:
That's not what the paper claims:
(Section 2.)
(Section 2.3.)
Even if the choice of offsets is somewhat limited based on the
underlying hardware defect, there is so much machine code involved in
typical security and policy checks that I expect you'd find
*something* which is usable.  It could be a the condition code in a
branch, the offset of a branch or call, a comparison with a magic
constant, or testing a different register for a zero value.

@_date: 2016-09-03 11:30:54
@_author: Florian Weimer 
@_subject: [Cryptography] "Flip Feng Shui: Hammering a Needle in the 
(Natanael's message of "Sat, 3 Sep 2016 11:05:58 +0200")
* Natanael:
It doesn't work this way.  Deletions are not bit flips.
$ diff -u rquine.rb rquine-flipped.rb
--- rquine.rb	2016-09-03 11:28:14.548923861 +0200
+++ rquine-flipped.rb	2016-09-03 11:28:37.929435698 +0200
 -6,7 +6,7  182845904;          _987654321          0;;eval)+?
             =((            um}-eval.
 _sum)%256             ).chr;             ;eval)+?@
-*12+%(.s             can(//){             a=$`+x+$
+*32+%(.s             can(//){             a=$`+x+$
 ^_a.unpa            ck      (^            H*^)[0].
 hex%999989==        k("H*")[0].hex%999989
 }&&eval(a)}        $ diff -u rquine.rb <(ruby rquine-flipped.rb)
--- rquine.rb	2016-09-03 11:28:14.548923861 +0200
+++ /dev/fd/63	2016-09-03 11:29:59.671225153 +0200
 -6,7 +6,7  182845904;          _987654321          0;;eval)+?
             =((            um}-eval.
 _sum)%256             ).chr;             ;eval)+?@
-*12+%(.s             can(//){             a=$`+x+$
+*32+%(.s             can(//){             a=$`+x+$
 ^_a.unpa            ck      (^            H*^)[0].
 hex%999989==        k("H*")[0].hex%999989
 }&&eval(a)}         -15,7 +15,7  / eval if eval          .size>692}}
             TUVWXY/.i rescue
 3141592653589793+                +271828182845904;
-9876543210;;eval                  "x=((42737-eval.
-sum)%256).chr;;eval            .scan(//){a=$`+x+$'
+9876543210;;eval                  "x=((42739-eval.
+sum)%256).chr;;eval                                .scan(//){a=$`+x+$'
 eval eval (C) Copyright 2014 Yusuke Endoh

@_date: 2016-09-17 17:47:03
@_author: Florian Weimer 
@_subject: [Cryptography] Ada vs Rust vs safer C 
* Arnold Reinhold:
An implementation that just provides safety, so that you can just flip
a compiler switch for code which isn't performance-critical.
Obviously, it would need to provide ABI compatibility to be truly
The specification changes could be fairly minor (e.g., the
implementation would have to detect all type-safety violations).  But
it would be difficult to show that a particular (high-performance)
implementation meets those new requirements.
Funding and competent people willing to work on this.  Funding alone
goes only so far.  Compared to what positions are open to people with
the relevant expertise, it's probably not a very attractive task.
At least on the GNU/Linux side, we don't know how to constrain the
scope, and which performance trade-offs are safe.  Resources are
always limited, and if you want to deliver something, you'll
eventually have to cut corners.  Free software vendors just don't know
how their products are exploited in practice (when it comes to
low-level issues where a memory-safe C implementation could help).
And there is still some probability of failure, in the sense that some
things are just very, very hard to implement (parallelism which
actually uses multiple hardware threads in a meaningful way comes to
my mind).

@_date: 2016-09-17 17:55:05
@_author: Florian Weimer 
@_subject: [Cryptography] Ada vs Rust vs safer C 
* Ron Garret:
Just type-safe array slice type (which has address and length) would
be a big help to many developers.  A natural way to write saturating
arithmetic or conditions evaluated to infinite precision would be
rather convenient for low-level code, too.  (You don't need to care
that much about integer overflow if you have decent memory structures
and APIs to access them, but someone still needs to write *their*
Existing compilers already track pointer provenance information, the
syntactic separation isn't really required.
But those are still language changes, and you need changes in
programmer attitude to see adoption.  For example, both glib and C++
provide arrays-with-bounds, but the implementations do not check them.
The C++ standard has both operator[](size_type) and at(size_type), so
the programmer can choose between having and not having overflow
So I think we just need the magic, ABI-compatible safe C

@_date: 2016-09-17 18:40:07
@_author: Florian Weimer 
@_subject: [Cryptography] Ada vs Rust vs safer C 
* John Denker:
Are there any success stories for C one can actually look at?
(I know there are for SPARK.)
We have some very powerful tools, but my impression is that in order
to use them, I need to manually massage my source code and feed it to
the tool outside of the build process.  This may certainly give
important insights, but by its nature, it's just a snapshot (like a
source code audit, or a typical fuzzing effort).  What I want is
something that runs as part of the regular build process, just like a
test suite, and that narrows the set of available tools quite
significantly (and most have you deal with license management *yuck*).

@_date: 2016-09-17 19:11:59
@_author: Florian Weimer 
@_subject: [Cryptography] Ada vs Rust vs safer C 
* Ron Garret:
Recent GCC generates:
t.c: In function main:
t.c:3:7: warning: x[101] is used uninitialized in this function [-Wuninitialized]
   int y = x[101];
       ^
t.c:4:7: warning: *((void *)&x+404) is used uninitialized in this function [-Wuninitialized]
   int z = *(x+101);
       ^
t.c:5:11: warning: x[101] is used uninitialized in this function [-Wuninitialized]
   return y+z;
          ~^~
Not really pretty, I admit.
But if I change your example to:
int main(int argc, char* argv[]) {
  int x[100] = {0};
  int y = x[101];
  int z = *(x+102);
  return y+z;
GCC still warns:
t.c: In function main:
t.c:3:12: warning: array subscript is above array bounds [-Warray-bounds]
   int y = x[101];
           ~^~~~~
t.c:4:7: warning: *((void *)&x+408) is used uninitialized in this function [-Wuninitialized]
   int z = *(x+102);
       ^
So GCC tracks both expressions and knows that they are problematic
because the subscript is out of bounds (although the GIMPLE
representation is different).  I'm not sure if the warnings are issued
from the same pass yet.

@_date: 2016-09-17 17:56:48
@_author: Florian Weimer 
@_subject: [Cryptography] Ada vs Rust vs safer C 
* Henry Baker:
Feedback from actual data appears to be crucial here.  We don't have
that (for GNU/Linux close to the upstream projects; I can't talk about
other vendors or certain large-scale users).

@_date: 2016-09-18 09:45:37
@_author: Florian Weimer 
@_subject: [Cryptography] Ada vs Rust vs safer C 
* Ron Garret:
Not really, GCC is such a compiler.  It started with loop optimization
(where there is some value in knowing that a loop must execute at
least once), and now extends somewhat beyond that.  It is still not
very aggressive, but it already can optimize away incorrectly written
overflow checks.
Clang is similar in this regard.  The frontend produces LLVM IR with
markup so that signed overflow is deemed undefined to the LLVM

@_date: 2016-09-18 09:53:59
@_author: Florian Weimer 
@_subject: [Cryptography] Ada vs Rust vs safer C 
* Ron Garret:
It is unclear if these timing attacks are really feasible.
In the end, this comes back to knowing which things really matter and
what actual attacks out there look like.

@_date: 2016-09-18 10:33:12
@_author: Florian Weimer 
@_subject: [Cryptography] Ada vs Rust vs safer C 
* Peter Gutmann:
I'm not sure.  PREfast is explicitly targeted at small code bases:
The Clang analyzer works reasonably well only on a single translation
unit.  In both cases, source code massaging is still needed (but maybe
less so PREfast's case if the 10 MB figure refers to actual source
code, and not produced binaries with debugging information).
The PREfast web site says it performs intraprocedural analysis, which
means that source code rewriting (or annotations) might be required as
well (but I don't really now what it does).
Coverity is somewhat different.  It performs interprocedural analysis
across translation units.  But the inter-translationpunit analysis
also assumes a certain way code is built, which may or may not apply
to typical build environments, so annotations or code restructuring is
still needed.
Coverity does find relevant bugs (relevant in the sense that they
had to be fixed after shipping the product).  But the results are just
not good enough to aggressively compel its use.  The other issue is
that Coverity has been designed for an advisory role.  There are
basically three ways to address a report: mark it for suppression in
the future, fix the underlying issue, or change things in such a way
that Coverity no longer addresses the bug.  Even if you rule out the
first option, with a sufficiently nasty code base, you can
accidentally end up in the last cast while aiming for the second.  I
still think Coverity is quite useful (despite the non-technical issues
surrounding its use), but I don't think it will bring us closer to a
safer C.
I haven't used Fortify.
If there are annotations that are really helpful and not utterly
Windows-specific, we can put them into GCC.  We just need
We have a code base which uses C99/C11 features heavily. :-/

@_date: 2016-09-18 22:10:49
@_author: Florian Weimer 
@_subject: [Cryptography] Ada vs Rust vs safer C 
* Peter Gutmann:
Do you know how Prefast ist related to SAL?  Is it just a checker for
SAL annotations?

@_date: 2016-09-20 07:27:11
@_author: Florian Weimer 
@_subject: [Cryptography] Ada vs Rust vs safer C 
* Arnold Reinhold:
It's an option feature in C11 and a bit of a joke because it is
required to call a callback in case of constraint violations.  The
callback is controlled by a global variable (it's not even
thread-local) and does not necessarily terminate the process.

@_date: 2016-09-21 21:56:21
@_author: Florian Weimer 
@_subject: [Cryptography] Ada vs Rust vs safer C 
* Arnold Reinhold:
We need (reasonably) hard evidence which of the many open issues
actually matter, and based on that, determine the direction to move
Currently, no one has that kind of data (and is willing to share).
Vulnerabilities and press releases likely paint a misleading picture.
So does following current trends in publicly documented exploitation
of mobile devices.

@_date: 2016-09-22 22:38:51
@_author: Florian Weimer 
@_subject: [Cryptography] Ada vs Rust vs safer C 
* John Denker:
That's not really true for most language runtimes that see usage at
scale today.  In my experience, there is a concern for the long term.
It's just very difficult for security-related matters to compete with
other concerns: internal infrastructure improvements, better
diagnostics for programmersor extremely mundane matters, like
increasing the number of search domains in the stub resolver so that
people can move off NIS more easily (and if you replace NIS with LDAP
and DNS over TLS, this could well be a practically relevant security

@_date: 2016-09-29 09:31:38
@_author: Florian Weimer 
@_subject: [Cryptography] Privacy-enhanced OpenPGP 
OpenPGP for use in email was (deliberately?) designed in such a way
that key servers obtain a pretty accurate picture of who is talking to
whom: Ideally, before encrypting a message or checking a signature,
you should reach out to a key server to see if a revocation has been
uploaded since the last use of the key.
Even if you do not perform automated key updates, when you have to
reply to an encrypted message from a new sender, you still need to
contact the key servers because OpenPGP-encrypted messages do not
include the public key of the sender.
(This privacy leak even made it into a Dan Brown novel, but I forgot
which one.)
Is there software which can do something about this?  I could run a
key server locally and download some key server dump once a week or
so.  But that's rather complicated, and doesn't really scale, and I'm
not sure if there any other sources besides this one:
Is there a source for key server data which provides incremental
updates without an explicit peering setup?

@_date: 2017-04-02 21:00:20
@_author: Florian Weimer 
@_subject: [Cryptography] Regulations of Tempest protections of buildings 
* Perry E. Metzger:
Such an ad-hoc shielding would not be compliant with the TEMPEST
specifications, which do not seem to be available to the general
public.  So the quote may be phrased awkwardly, but could still be
substantially true.

@_date: 2017-02-22 22:45:40
@_author: Florian Weimer 
@_subject: [Cryptography] Security proofs prove non-failproof 
* Peter Gutmann:
Those commercial tools don't care about soundness, so there isn't much
actual proving going on.  (Not sure about PREfast, it's somewhat
difficult to find accurate information.)  There is some correlation
with customer-encountered bugs, but it's not as strong as one would
want it to be.  I suspect a lot of use of those tools is
compliance-driven and gives good results mainly because any
interesting-looking report prompts real people to look at source code,
finding and fixing the actual problems (which are not always those
reported by the tool).
My main problem with formal methods (apart from odd things like Z3
giving me an invalid solution for pretty much the first problem I
threw at it) is that with the current tools, it's a one-time effort,
just like an audit.  You can't put production code through the proof
tool.  Few people say this explicitly, unfortunately, but it seems
that there is always an expectation that you massage the code (i.e. go
from Ada to SPARK, from C to ACSL, etc.), prove the basic properties
you get for free (such as termination, bounded resource use, and lack
of memory safety violationsall stuff that is relatively easy to
specify in general, but can be quite hard to prove in specific cases,
obviously).  After patching things up, you then go back to the
original code to fix things there as well.
But now someone makes a change to the original code to implement a new
feature, and you have to do all that source code massaging again from
scratch.  That clearly does not work.

@_date: 2017-02-22 22:29:06
@_author: Florian Weimer 
@_subject: [Cryptography] HSMs or Intel SGX? Which is harder to hack? 
* Peter Gutmann:
Some regulators require that all tokens are personalized and
run-of-the-mill smartcards.  If you have business processes that
require mass-signing, then you need such smartcard farms.
But I think there's lately been a general trend away from requiring
signatures with personalized smartcards for mass-market transactions.

@_date: 2017-02-22 23:19:54
@_author: Florian Weimer 
@_subject: [Cryptography] German govt tells parents to destroy 
Baker's message of "Mon, 20 Feb 2017 06:30:08 -0800")
* Henry Baker:
Alexa isn't the problem, isn't that just some voice processing
service?  I think the products are called Echo, and they might
The current media reports fail to mention that this is based on
earlier enforcement activity against a similar device:
But in general, the emerging consensus (not just in the EU) seems to
be that recording someone's spoken word isn't really recording as long
as only a machine processes the recording.  Which aligns quite well
with how government agencies make copies of data generated by citizens
who are clearly not suspected of any wrongdoing and claim that it
doesn't count as long as only machines look at the data.

@_date: 2017-07-02 10:36:57
@_author: Florian Weimer 
@_subject: [Cryptography] OpenSSL CSPRNG work 
For glibc, we are also considering adding an implementation of
arc4random to an upcoming release.  The consensus view is that we
cannot use /dev/urandom because it may not be available in chroots.
We support kernels older than 3.17/3.18, so we cannot assume the
presence of the getrandom system call.  And getrandom cannot obtain
randomness if the kernel pool is not initialized (d'oh).  We cannot
keep open a file descriptor to /dev/urandom, so every call would have
to do open/read/close system calls, whose performance impact would
drive away some users.
My hope is to create something that it is reasonable fast so that
using arc4random is a no-brainer, and you'd something else only if you
need a predictable stream of random bits.  It also has to work in case
the kernel pool hasn't been initialized yet, otherwise applications
will switch back to /dev/urandom because it won't block booting.
I'm leaning towards AES-128 in CTR mode with a per-process key, a
global counter, and per-thread counters and output blocks (so around
20 bytes of TLS storage, instead of >176 bytes if we stored an AES key
schedule for every thread).  We'd probably put the per-process key in
non-dumpable memory.  Fork safety is somewhat easier for us than for
others because we can directly invalidate the per-process key from the
fork implementation.  (Clone safety is more complicated.)  Seeding is
still tricky, of course.  We would use the getrandom system call if
available, otherwise fall back to /dev/urandom and then to AT_RANDOM
(directly to AT_RANDOM if the kernel pool is not seeded; we'd then try
to re-seed from getrandom on every arc4random call in that case).
Proper reseeding after fork will be complicated if getrandom is not
available; we'll probably do something theoretically unsound in that
case (and tell people to use a fixed kernel if they dislike this), or
use a MAP_SHARED mapping to maintain counters shared across processes.
This implementation is unlikely to pass certification.  Some auditors
do not allow the use of /dev/urandom to seed another generator.  I
don't know yet if we can just prentend that our arc4random
implementation is not cryptographically secure, and thereby game the
auditing process.  I expect that anyone who uses actual cryptography
uses a cryptographic library which comes with its own CSPRNG, so this
shouldn't be a problem in practice as along as our arc4random provides
an unpredictable stream of bits, even if it is not certified to do so.

@_date: 2017-07-02 11:42:19
@_author: Florian Weimer 
@_subject: [Cryptography] demonstrating SSLv2 weaknesses 
* Robin Wood:
The SSLv2 truncation vulnerability should be practical to demonstrate,
except it may be tricky to find a HTTPS client which does not
reimplement it on top of later TLS versions.

@_date: 2017-07-05 23:18:26
@_author: Florian Weimer 
@_subject: [Cryptography] OpenSSL CSPRNG work 
* Theodore Ts'o:
I already wrote that we're going to use AT_RANDOM (and reseed using
getrandom once it returns data with GRND_NONBLOCK).  If that AT_RANDOM
value is not random, it's up to you guys to fix that.
So use CPU instructions, firmware-provided randomness, hypervisor
interfaces, or cross-core scheduling jitter, whatever works to scrape
together a few hard-to-predict bits.  You are in a much better
position to do that than userland.  We won't implement something like
egd just for use during early boot in userland, and we couldn't access
protected UEFI variables anyway.
That's a non-starter because it would halt the boot process.  In the
futrue, we will need something like arc4random during process
initialization.  And if we block there, the system will never proceed
to the point where it generates more entropy.
There are many kernels out there which receive security backports.
Many of them will receive getrandom soon, but certainly not all of
them.  I have no problem with *recommending* kernels with getrandom
support.  We just can't require it.
And the availability of getrandom doesn't solve the early boot issue

@_date: 2017-07-07 22:21:39
@_author: Florian Weimer 
@_subject: [Cryptography] OpenSSL CSPRNG work 
* Theodore Ts'o:
It's in 2.6.32, which is good enough for me.  The actual limit is 3.2
these days, even.
We refuse to start on such kernels anyway because they lack other
critical functionality.
I've seen system boot logs where the SSH prints the key generation
message after the kernel message indicating that the pool has been
initialized.  And that was about as non-crappy as gets (x86-64 running
under KVM, where control *everything*, probably even with RDRAND).
Admittedly, it was three years ago:
Has this changed?
Or are the kernel messages just misleading for modern systems?

@_date: 2017-03-25 16:43:55
@_author: Florian Weimer 
@_subject: [Cryptography] Google distrusts Symantec for mis-issuing 30, 
(Ben Laurie's message of "Sat, 25 Mar 2017 01:35:00 +0000")
* Ben Laurie:
It's very difficult to tell what is actually going on because the
Chrome team posting only says:
My interpretation is that the 127 certificates which prompted the
investigation are identifiable using CT logs, but the large majority
of those 30,000 certificates discovered later are not.
It seems that more information what is actually going can be cleaned
from this mozilla.org (!) bug:
Comment 10 includes audits from some CAs which I suspect are
affiliated in some way with the Symantec roots.  Several of these
documents describe organizations which failed audits.  Comment 8
contains fairly substantial comments from Symantec.
Based on reviewing this information, my best guess for what is
actually going is this:
Some functionally misissued certificates where detected (a subset of
the original 127).  With functionally misissued I mean that the
certificate contains domains for which the owner positively confirmed
that they did not request that the certificate.  Such certificates can
indeed be recovered from CT logs, with a bit of guesswork regarding
subscriber intentions.  (Although most large organizations face
challenges enforcing stringent certificate management practices, so it
can be very difficult to rule out that an organization did *not*
request specific certificates.)
On top of the functionally misissued certificates, there are
certificates which contain apparent violations of intended constraints
on certificate contents.  These constraints are not functionally
relevant for the browser PKI.  An example would be a subject DN such
as C=KR, ST=1, L=1, O=12, OU=1.  Many of the original 127
certificates are in this category.
On top of that, Symantec has identified about 30,000 certificates
which are problematic as well.  I'm sure some of them contain
violations of technical constraints, and a few probably are
functionally misissued as well (based on my definition above), but
based on the information in the mozilla.org bug, I think the majority
of those 30,000 certificates are defective because they were issued
based on a broken process.  In that sense, they were formally
misissued, but there are likely no traces in the certificates
themselves that the process was incorrect.  (In other words, had the
intended browser PKI processes been followed, the net effect would
have been the same.)  Those formally misissued certificates are under
Symantec roots also used by completely different processes, but there
is no way to tell which of the certificates used an affect process and
which did not, without relying on confidential Symantec business
information.  This information is not available from the CT logs,
Without a way to tell the actually affected certificates apart, the
Chrome team decided to decommission several Symantec roots.  My
interpretation is that the impact of that change goes far beyond the
set of certificates known to be affected by the process failures
identified in the mozilla.org bug report.  As far as ensuring browser
PKI compliance goes, decommissioning these roots is a conservative
approximation (all known-to-be-problematic certificates will be phased
out), but it appears that many more Symantec certificates and
subscribers will be affected.
Regarding what caused the process failure, my speculation is that
while the browser PKI guidelines where increasingly tightened
regarding CA operations and delegating powers to sub-CAs, similar
controls have not been required explicitly for the delegation of
registration authority functions.  A reasonable interpretation of the
guidelines might have been that key process elements may not be
outsourced to unaudited contractors (such as strong domain name
ownership checks, to prevent functionally misissued certificates, and
enforcement of technical constraints on certificate contents).  But
apparently, this is not entirely explicit in the guidelines.  Symantec
accidentally ran into this loophole, and several of their
contractors/business partners seem to have followed processes which do
not match the browser PKI guidelines.
I do not have an opinion at this time whether the response outlined by
the Chrome team is warranted.  I also don't know if all the
certificate-related and process-related information they reviewed is
captured in the mozilla.org bug.

@_date: 2017-03-30 23:14:26
@_author: Florian Weimer 
@_subject: [Cryptography] stegophone 
* Michael Marking:
I think most smartphones have this capability (with multiple
implementations within the same phone, actually), but the device
makers do not use it in the way you want.  It's usually used to
protect data from access by the legitimate device owner, too.  (On the
other hand, that's probably the only way the user can convincingly
claim that they do not have access and avoid disclosing that data,
which is rather sad.)

@_date: 2017-03-30 23:38:46
@_author: Florian Weimer 
@_subject: [Cryptography] escalating threats to privacy 
* John Denker via cryptography:
You need to negotiate with everyone along the path.  The Internet was
designed with the goal that you don't have to do that, and that's a
major source of its efficiency.
It's also not just traditional ISPs (the companies that push packets
through their networks).  Exchange point operators also share traffic
(samples) for research purposes.  So do other critical Internet
infrastructure operators.
I expect that many Tor exit nodes have pervasive logging.  This might
even be justifiable because the exit node operator could claim the
traffic they see has been anonymized by the Tor network.  Except that
I don't think Tor anonymization is all that strong, and the Tor
infrastructure (both the network and the endpoint software) can only
do limited things to avoid clear-text information leaks.
And it's obviously game over once the exit node operator has access to
an interception certificate.
Anonymous real-time/interactive traffic is probably never going to
happen because there are trade-offs (real-time responses are difficult
to anonymize properly).
The other problem is that on the current web, sites actively collude
to break anonymity for various commercial purposes, and more and more
web sites require some form of authentication.  That happens on the
server side, and technology like Tor isn't going to change that.  The
New York Times will still know which articles you read.
I think the ISPs just want a pie of that already existing market for
user data.  The next step will be that they start rolling out
interception certificates, to improve web site response times due to
better caching, and general browsing experience through well-targeted

@_date: 2017-11-09 21:32:44
@_author: Florian Weimer 
@_subject: [Cryptography] One Bitcoin Transaction Now Uses as Much Energy 
(Tony Arcieri's message of "Mon, 6 Nov 2017 14:13:16 -0800")
* Tony Arcieri:
Or several groups have a shortcut and their models independently show
that they can tune up their rate without revealing the existence of
their shortcut.
(And I'm not talking about a 20% advantage or something like that,
which is well within margin of local prices for electricity.)

@_date: 2017-11-25 12:32:59
@_author: Florian Weimer 
@_subject: [Cryptography] Is ASN.1 still the thing? 
* Peter Gutmann:
What I find very hard, as someone who has never been formally trained
in the ASN.1 arts, is going from a specification like this:
   Certificate  ::=  SEQUENCE  {
        tbsCertificate       TBSCertificate,
        signatureAlgorithm   AlgorithmIdentifier,
        signatureValue       BIT STRING  }
   TBSCertificate  ::=  SEQUENCE  {
        version         [0]  EXPLICIT Version DEFAULT v1,
        serialNumber         CertificateSerialNumber,
        signature            AlgorithmIdentifier,
        issuer               Name,
        validity             Validity,
        subject              Name,
        subjectPublicKeyInfo SubjectPublicKeyInfo,
        issuerUniqueID  [1]  IMPLICIT UniqueIdentifier OPTIONAL,
                             -- If present, version MUST be v2 or v3
        subjectUniqueID [2]  IMPLICIT UniqueIdentifier OPTIONAL,
                             -- If present, version MUST be v2 or v3
        extensions      [3]  EXPLICIT Extensions OPTIONAL
                             -- If present, version MUST be v3
        }
to the BER/DER encoding.  The problem is this:
        version         [0]  EXPLICIT Version DEFAULT v1,
which has a funny impact on the encoding, which turns out rather
irregular at this point.  The reset is pretty boring TLV stuff and
easy to implement, but I never found a specification of what
*actually* happens here.  If it's described in X.690 (07/2002), I
really don't see it.

@_date: 2017-11-27 19:37:06
@_author: Florian Weimer 
@_subject: [Cryptography] Is ASN.1 still the thing? 
* Nico Williams:
And that might be the reason for doing things exactly this way: I
think the version field was added retroactively.  There are definitely
certificates out there which lack it.  This is not what puzzled me.  It is how to get from the ASN.1 syntax,
with the [0], the EXPLICIT, the DEFAULT (or the [3] and the IMPLICIT
further down) to the on-the-wire representation, with the
CONTEXT_SPECIFIC wrapper around the actual version field and all that.
And I wonder if ASN.1 compilers actually ensure that the serialized
data and be deserialized in an unambiguous fashion, and what the rules
are for *that*.

@_date: 2017-11-27 20:02:11
@_author: Florian Weimer 
@_subject: [Cryptography] WIPEONFORK in Linux 4.14 
* Nico Williams:
This is not true on Linux once you have code that calls fork/clone
system calls directly (which is traditional for namespace/container
setup, although it shouldn't strictly be necessary anymore).
pthread_atfork won't be called in these cases because it's strictly a
userspace thing.
What should work as an MADV_WIPEONFORK replacement is a MAP_SHARED
mapping and two counters, one on the mapping and one outside of it (in
regular, MAP_PRIVATE memory), and a lock covering both.  Around each
for-protected operation, you acquire the lock, check both pointers for
quality, increment both (the one on the MAP_SHARED mapping needs
atomic increment), and release the lock.  You need to do this before
and after the operation; the operation itself does not have to be
under the lock.
If the two counters diverge, you need to reinitialize: replace the
mapping and reset the counters (under the same lock), and retry the
operation if the second check failed.  This happens in both the parent
and the child process, eventually, but it it should be rare and not
contribute too much to the overall cost of forking.
At least for PRNGs, where you can retry as often as you want, this
looks promising to me.  I expect this to be much more reliable than
getpid/time/gettimeofday calls, and also much faster as long as the
lock is not contended.
With MADV_WIPEONFORK, you don't need to acquire the lock as long as
the mapping has not been zeroed, which avoids the lock contention and
any writes to globally shared data during regular operation.

@_date: 2017-11-27 20:17:49
@_author: Florian Weimer 
@_subject: [Cryptography] Is ASN.1 still the thing? 
* Nico Williams:
You can only do interop testing with real data and a concrete ASN.1
specification.  I'm more interested in the theory, i.e. how this is
*supposed* to work at the design level.
I have no doubt that you can get almost anything to work with
sufficient interop testing, at least for a brief period of time, but
the point of something like ASN.1 and associated tools is that if both
ends use the same schema of data types, then you can at least
understand each other to the degree that each side sees the same data.
(Whether it reacts to it in the expected way is a different matter.)
My hunch is that the criticism of ASN.1 (as opposed to direct wire
format specification using ASCII diagrams or whatever) is that how you
get from ASN.1 syntax, to the internal data model, via some specific
encoding rules, to the actual bytes, is far from obvious, and the
specifications do not really help unless you have been taught a
particular mental framework for reading those specifications.  The XML
stack (whether XML Schema or RelaxNG doesn't matter) is much clearer
in this regard, for example, so I'm not sure if this issue of apparent
disconnect is inherent to the problem domain.
The fact that fully-featured ASN.1 tools used to be proprietary, with
closely guarded test suites, probably did not help, either, because it
resulted in a proliferation of concrete, manually written parsers and
substantial divergence even between automatically generated parsers.

@_date: 2017-11-27 22:28:57
@_author: Florian Weimer 
@_subject: [Cryptography] WIPEONFORK in Linux 4.14 
* Nico Williams:
Well, historically, we have done a very poor job exposing clone(2)
functionality in a more ready-to-use manner.  What we provide is
geared towards creation of threads, rather than the fork/vfork-like
interface many applications want.
Unfortunately, PIDs get reused too quickly for that:
OpenSSL started to mix in time as well since then, but it's still very
hackish (and I don't blame themthe MAP_SHARED trick is unlikely to
work on all platforms they need to support, and we don't know yet if
it will withstand the test of time).

@_date: 2017-10-23 23:58:03
@_author: Florian Weimer 
@_subject: [Cryptography] Signature Hashing Choices ... So Many Choices ... 
* Andrew Donoho:
If the hash function is broken, it may be possible to generate
collisions for hash(BLOB) (and thus hash(preamble || hash(BLOB)),
independently of the preamble value), but not for hash(preamble ||
BLOB), particularly if you need to commit to a specific value of BLOB
before you can learn (or predict with reasonable probability) the
In many cases, this helped to extend the practical lifetime of MD5 and
SHA-1, beyond the point where collision resistance for the unadorned
hash function has been demonstrated not to exist.

@_date: 2018-04-11 22:24:41
@_author: Florian Weimer 
@_subject: [Cryptography] Georgia prohibits vulnerability research 
* L. Jean Camp:
I don't see the problem as reported.  The bill, unlike many others, is
extremely friendly to unauthorized security testing, to the degree
that I would consider it problematic for that reason.  It excludes
legitimate business activity and Cybersecurity active defense
measures that are designed to prevent or detect unauthorized computer
access.  If your research doesn't fall into those categories,
perhaps it is really prolematic?

@_date: 2018-02-17 22:05:02
@_author: Florian Weimer 
@_subject: [Cryptography] Quantum computers will never overcome noise 
(Allen's message of "Wed, 7 Feb 2018 14:07:54 -0500")
* Allen:
For classical computation, I don't think we have conclusive proof that
it is impossible to build Shamir's constant-time arithmetic machine,
which, among other things, is able to factor any number n in O(log n)
steps.  We have much less experience building quantum computers, so I
doubt it is possible to make definite claims about their strengths and
People used to compute architectural designs using soap bubbles,
instead of using discrete computer simulations.  Maybe that's how
quantum computing will look like when it arrives.

@_date: 2018-06-27 20:29:51
@_author: Florian Weimer 
@_subject: [Cryptography] Fast-key-erasure RNG and fork()ing 
* Yann Ylavic:
You can use two counters, one in a MAP_SHARED page, and one in a
MAP_PRIVATE page.  Increment them before and after each access to
random data, under a process-private lock, and compare if they are
still the same.  You have to reseed if the counters diverge.
An implementation of this approach is part of this patch (still under
review, LGPLv2.1+ license, so be careful if that matters to you):

@_date: 2018-06-27 20:34:41
@_author: Florian Weimer 
@_subject: [Cryptography] Fast-key-erasure RNG and fork()ing 
* Peter Gutmann:
That's not necessary except perhaps on Solaris, where there is a
forkall system call (which I believe does not work in general anyway).
On the majority of systems, only the current thread survives in the
new process.  You cannot return from a signal handler that has called
fork.  This leaves a fairly limited range of synchronization issues to
deal with, and INHERIT_ZERO actually simplifies them a lot.
(Particularly on systems where fork handlers do not generally run on

@_date: 2018-06-28 20:31:25
@_author: Florian Weimer 
@_subject: [Cryptography] Open Storage Controllers 
* R0b0t1:
There's iSCSI and ATA-over-Ethernet, so you can have storage that can
run commodity operating systems.
Theoretically, the same thing should be possible with USB, but I
haven't seen that in practice yet.

@_date: 2018-03-08 21:34:45
@_author: Florian Weimer 
@_subject: [Cryptography] Mutually authenticated TLS 
* Kevin W. Wall:
A real downside is that encoding the access privileges in the
certificate means that you need to reissue the certificate if
privileges change.
Red Hat does this approach for subscription certificates in the
entitlement PKI:
Others can comment how smoothly this works out in practice.
In theory, it allows localized ACLs checks (without looking up the
certificate in a database) and very good partition tolerance,
especially if you do not need perfect certificate revocation checks.

@_date: 2018-03-18 17:00:03
@_author: Florian Weimer 
@_subject: [Cryptography] On those spoofed domain names... 
* Nico Williams:
There are several slightly incompatible standards, without any
signaling mechanism.  Both the IETF, Unicode, and registries
contributed to various efforts, reinterpreting and altering the work
of others.
Browsers try to focus the attention on the registry-controlled part,
but I don't know how effective this is in practice.
In a quick test, I see things like this (all branded sites, likely
Paymentech, LLC (US) | Jack Henry & Associates, Inc. (US) | Fiserv, Inc. (US) | These sites wouldn't have any users if people actually followed the
security advice we give to them.

@_date: 2018-10-03 22:57:00
@_author: Florian Weimer 
@_subject: [Cryptography] IKE/ISAKMP/IPsec complexity by design 
* Paul Wouters:
I have yet to see a large-scale IPsec deployment where users cannot
attack each other by impersonating the gateway.
Of course, that's not the fault of the IPsec protocol as standardized
by the IETF because the IETF refused to cover that use case.  But if
the protocol does not match user requirements and users start looking
for dodgy alternatives, that should tell us something about the
protocol, too.

@_date: 2018-09-29 18:55:24
@_author: Florian Weimer 
@_subject: [Cryptography] Did Spectre help torpedo Qualcomm? 
* Henry Baker:
I find that extremely unlikely.  There is a point (regarding cost or
power efficiency) at which most customers would stop caring.  The
whole zoo of issues is now largely perceived as a software problem

@_date: 2019-01-13 18:48:55
@_author: Florian Weimer 
@_subject: [Cryptography] Government shutdown: TLS certificates not 
(Tom Mitchell's message of "Sat, 12 Jan 2019 17:14:44 -0800")
* Tom Mitchell:
Akamai (the CDN operator) probably handles the key material and any
required certificate renewal.
The certificate subject (with O=The Executive Office of the President)
is affected by the shutdown (according to Wikipedia at least), but
that doesn't matter if the process is fully automated (similar to
Let's Encrypt) or outsourced (which is probably the case here).

@_date: 2019-03-19 20:27:21
@_author: Florian Weimer 
@_subject: [Cryptography] In the event of my death, master password 
* Paul F. Fraser:
It depends on what you need.  For some things, it may be interesting
to gain access before the estate has been settled.  In other cases,
you want to precisely avoid that.
Secret sharing does not work socially in the long term because you
eventually need to handle revocation, and that could become quite
stressful.  It also exposes the sharing parties to government pressure
even before death.
Maybe sharing passwords is not the answer anyway because it allows
perfect impersonation.  Other forms of delegation might be more
appropriate because they can be audited in a more straightforward way.

@_date: 2019-11-01 11:24:16
@_author: Florian Weimer 
@_subject: [Cryptography] 0xFFFFFFFF is the loneliest number that you'll 
message of "Thu, 31 Oct 2019 06:11:24 -0400")
* Jerry Leichter:
This still doesn't say how the bug was fixed.  Does the instruction
now work correctly?  Or is the CPUID bit for RDRAND just masked to
hide the instruction?
Recent Linux versions do the latter:
commit c49a0a80137c7ca7d6ced4c812c9e07a949f6f24
Author: Tom Lendacky     x86/CPU/AMD: Clear RDRAND CPUID bit on AMD family 15h/16h
    There have been reports of RDRAND issues after resuming from suspend on
    some AMD family 15h and family 16h systems. This issue stems from a BIOS
    not performing the proper steps during resume to ensure RDRAND continues
    to function properly.
    RDRAND support is indicated by CPUID Fn00000001_ECX[30]. This bit can be
    reset by clearing MSR C001_1004[62]. Any software that checks for RDRAND
    support using CPUID, including the kernel, will believe that RDRAND is
    not supported.
    Update the CPU initialization to clear the RDRAND CPUID bit for any family
    15h and 16h processor that supports RDRAND. If it is known that the family
    15h or family 16h system does not have an RDRAND resume issue or that the
    system will not be placed in suspend, the "rdrand=force" kernel parameter
    can be used to stop the clearing of the RDRAND CPUID bit.
    Additionally, update the suspend and resume path to save and restore the
    MSR C001_1004 value to ensure that the RDRAND CPUID setting remains in
    place after resuming from suspend.
    Note, that clearing the RDRAND CPUID bit does not prevent a processor
    that normally supports the RDRAND instruction from executing it. So any
    code that determined the support based on family and model won't

@_date: 2019-11-16 22:28:18
@_author: Florian Weimer 
@_subject: [Cryptography] Encryption doesn't seem to have bothered 
(Peter Gutmann's message of "Sat, 16 Nov 2019 10:35:42 +0000")
* Peter Gutmann:
They did not decrypt the phone calls.  The JIT wrote this earler in
their witness appeal:

@_date: 2020-04-29 22:39:13
@_author: Florian Weimer 
@_subject: [Cryptography] The EFF 650 CAs lie 
* Phillip Hallam-Baker:
I think the situation is much more complicated.  On the one end, the
number of distinct organizations having access to private key material
was likely lower than 650.  We don't really know because at the time,
there was a number of unconstrained, unaudited sub-CAs in operation.
This was long before certificate transparency, so a corporate MiTM
proxy with a valid sub-CA certificate and on-the-fly server
certificate generation could easily fly under the radar.
But for purposes of the browser PKI, we have seen that the RA part of
the CA business was equally important.  And the number of trusted RAs
was much larger than 650.  Lack of disclosure requirements for RAs
naturally made estimates difficult.  The public learned about these
trusted RAs (essentially resellers which could instruct the CA to
issue certificates based on fairly arbitrary CSRs) usually only after
some RA did something very wrong.
It's also funny that it's so hard to identify root CAs in the browser
PKI.  For organizations in the business of identifying others, they
put remarkable little effort into properly identifying themselves.  If
I recall correctly, for a long time, there was just Kathleen Wilson's
Google spreadsheet for that.
For some sub-CAs, the published policy said that DFN (or any other
party) must not perform domain validation.  My understanding this is
not how things were implemented after the DFN PKI joined the browser
PKI.  We can debate whether it's preferable if a CA operators
according to its policy and does not perform domain validation, or if
validates and violates its policy.  And if they have different
policies with different validation procedures, wouldn't they qualify
as separate CAs?
In any case, it's a bit disingenuous to criticize someone for not
spending a week or two on unraveling the whole DFN PKI structure.  I
agree that it was probably much simpler than the published policies
suggested.  But then why publish these misleading policies?
PKIX also refused to require that the constraint applied to the
commonName field, making path constraints completely useless for the
browser PKI.
Eh, if your security policy depends on certificate constraints being
applied by implementations, then you absolutely have to set the
critical bit, no?
I think it's valuable because it draws attention to the phenomenon of
vanity CAs.  That is still

@_date: 2020-07-05 16:40:01
@_author: Florian Weimer 
@_subject: [Cryptography] Zoom publishes draft cryptographic design for 
of "Fri, 5 Jun 2020 00:50:38 +0000")
* Peter Gutmann:
Why is choosing a fixed parameter fine in this context, and a no-no
for DH parameters?  That's the part I don't understand.

@_date: 2020-06-04 18:52:18
@_author: Florian Weimer 
@_subject: [Cryptography] Zoom publishes draft cryptographic design for 
of "Wed, 3 Jun 2020 06:29:58 +0000")
* Peter Gutmann:
It's hard to draw the line between parameters and algorithms in some
My understanding this kind of security by obscurity still has a bad
reputation when it comes to algorithms, although I suspect that it
works there as well.
It assumes that choosing suitable parameters is easy.  There must have
been a time when people were unsure about this when it came to DH
parameters.  It also does not help that parameter generation is very,
very slow, at least in common implementations.
I'm pretty sure there used to be a widespread design constraint in
early mass-market cryptography, with an assumption that non-hostile
users would use hostile implementations.  This discouraged any use of
randomness that can be observed publicly.
Beside DH parameters, the other rather astonishing example is the
public RSA exponent.  You cannot even use a random value there anymore
because some implementations do not allow an arbitrary-precision
integer for it:

@_date: 2020-05-03 09:14:11
@_author: Florian Weimer 
@_subject: [Cryptography] The EFF 650 CAs lie 
* jamesd:
If I recall correctly, certificate pinning in Chrome found a bunch of
such cases over time.  In order to discover them, it is necessary to
run something on the network that is subject to interception, it is
usually not possible to find these interception certificates by
scanning the public Internet.

@_date: 2020-05-04 06:52:45
@_author: Florian Weimer 
@_subject: [Cryptography] The EFF 650 CAs lie 
* Natanael:
There is, via Certificate Transparency, but those offer services need
to be bothered to actually check those resources for misissued
certificates.  Determining whether a certificate is in fact misissued
can be quite hard for organizations of just moderate size.
Why would that be a problem?  Surely this is not the failure mode for
the browser PKI.

@_date: 2020-05-04 08:51:00
@_author: Florian Weimer 
@_subject: [Cryptography] NSA security guidelines for videoconferencing 
* Whitfield Diffie:
I would rather say there have to be some key at each end that cannot
be negotiated.
As far as I can see, there is no way to have security in the strong
end-to-end sense with a service that offers any form of password
recovery (and repatriating the identity to another device in case the
original device is lost).  Basically, your identity in the system has
to be tied to the key material you generated, and if you lose access
to that, you'll need a new account.  It's possible to lessen the
impact of this event by keep billing separate, but it still does not
seem compatible with what people expect from such services.
It also does not seem the main problem that video conferencing
currently faces: ensuring that the right people have access to
meetings.  Not so much to protect confidentiality, but to avoid

@_date: 2020-09-29 21:10:29
@_author: Florian Weimer 
@_subject: [Cryptography] Exotic Operations in Primitive Construction 
* Phillip Hallam-Baker:
That's a very x86 and Windows-specific viewpoint.  (Windows switches
the FPU to a 53 bit mantissa.)  long double uses the Intel extended
precision format on x86 Linux.  Anything on that platform that
involves long double uses this format, so there is quite a bit of
library support out there.
However, that's really specific to i386/amd64/x86-64.  On other
architectures in current use, long double is just double (presumably
that's true for Windows as well?), or full IEEE binary128.  The other
outlier is IBM POWER, but we are fixing that, switching from the
double-double hack for long double to IEEE binary128.  Hardware
support for binary128 is still rare, I think.
Curiously, the 80 bit extended precision format with its explicit
leading one bit causes issues because implementations rely on the fact
that values without the leading one bit (and all computations with
them) are undefined.  We fixed to crasher bugs in glibc just this
year, but it's somewhat debatable if those are even glibc bugs: With
this floating point format, you just can't take an arbitrary bit
pattern and start computations with it.
