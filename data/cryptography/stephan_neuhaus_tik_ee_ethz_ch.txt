
@_date: 2013-12-13 09:27:35
@_author: Stephan Neuhaus 
@_subject: [Cryptography] Size of the PGP userbase? 
I'm using Enigmail for Thunderbird and I would challenge the implication that it is "extremely easy to use" for people who care. I recently told the story on this list of how I use two different private keys on one account and would like to use one for some recipients, and the other for everyone else.  Except fiddling with the preferences every fricking time, I found no way of doing this.
That's not "extremely easy to use".  I'm not saying that it is the fault of the Enigmail developers for not foreseeing such a use case (because it probably *is* very rare), but it's not "extremely easy to use".

@_date: 2013-12-17 10:43:18
@_author: Stephan Neuhaus 
@_subject: [Cryptography] The next generation secure email solution 
I think this is the most succinct summary of this particular conundrum
that I have ever seen.  May I steal it for my lectures?

@_date: 2013-11-23 23:58:07
@_author: Stephan Neuhaus 
@_subject: [Cryptography] (no subject) 
Fair enough. I have just put an entry in my calendar for November 30,
2023, to check if email encryption is now widespread.  I'll let you know.

@_date: 2013-11-23 21:11:05
@_author: Stephan Neuhaus 
@_subject: [Cryptography] Dark Mail Alliance specs? 
That is almost exactly the title of a very old paper from 1999's
Usenix Security.  It's called "Why Johnny Can?t Encrypt:
A Usability Evaluation of PGP 5.0" and still a worthwhile read.  Things,
if they have changed at all since then, have changed very little.  For
example, I can't get OpenPGP's Thunderbird plugin to understand that I
have different private keys that I use for different purposes on the
same account. I always need to go through preferences to change it.
(N.B.: there *might* be a way to do it, but I couldn't figure it out.)
One big problem is that most crypto software is written by geeks who
then often simply map every feature of the command-line program to a GUI
and then think that their grandmothers can operate it as well as they
can.  I mean, they ought to try to explain to their grandmothers the
concept of a public key.  And if any geek is reading this, and if you
think that you have this wonderful metaphor that is so simple that
surely any grandmother will understand it, please do actually try it out
on an actual grandmother.  You might be surprised.
In my opinion, massive user-controlled email encryption will not happen.
 Not now, and not in the next ten years.
PS: GPG being installed *on the server* won't make Johnny use encryption
*on his client*.

@_date: 2013-10-03 18:12:33
@_author: Stephan Neuhaus 
@_subject: [Cryptography] encoding formats should not be committee'ized 
Then that puts it in the same category as HBCI version 1.  Sure, it was
rigorous.  Sure, it was unambiguous.  Sure, it was ASCII-encoded.  But
human-readable?  I implemented that protocol once, and can assert that,
after reading more HBCI messages than was probably good for me, I felt
decidedly less than human.

@_date: 2013-10-16 23:05:37
@_author: Stephan Neuhaus 
@_subject: [Cryptography] /dev/random is not robust 
It should also be a step along a path begun in 1998 and continued in
2000 by Peter Gutmann.  /dev/random is among those that are analysed
(obviously as it was in 2000).
[PS: This email will not make it to the list. I have forgotten the email
address under which I am subscribed and can't be arsed to find out right

@_date: 2013-09-04 20:40:13
@_author: Stephan Neuhaus 
@_subject: [Cryptography] Hashes into Ciphers (was Re: FIPS, 
I remember having reviewed a construction by Peter Gutmann, called a Message Digest Cipher, at around that time, which also turned a hash function into a cipher.  I do remember that at that time I thought it was quite secure, but I was just a little puppy then.  Schneier reviews this construction in Applied Cryptography and can't find fault with it, but doesn't like it on principle ("using the hash function for something for which it is not intended").
It works like this. Let h be the "incremental" hash function, i.e., the compression function that you use to hash data piecewise.  In programming terms, this function is usually called XXXUpdate() if XXX is the name of the hash function. Then, if P(1), ..., P(n) are your plaintext blocks and K is your key, compute:
   C(1) = P(1) XOR h(IV, K)
   C(j) = P(j) XOR h(C(j-1), K),   for 1 < j <= n.
Decryption is a very similar operation:
   P(1) = C(1) XOR h(IV, K)
   P(j) = C(j) XOR h(C(j-1), K),   for 1 < j <= n.
It's just running the compression function in CFB mode.

@_date: 2013-09-17 20:22:57
@_author: Stephan Neuhaus 
@_subject: [Cryptography] The paranoid approach to crypto-plumbing 
I like Stannopilosery better, but the first half is a keeper.  Or,
perhaps a bit incongruously, Stannopsaffery.

@_date: 2014-04-18 18:01:05
@_author: Stephan Neuhaus 
@_subject: [Cryptography] I  don't get it. 
Jesus Christ.  I've just read through that thread and while I can't
really say that I like fefe's foot-stomping "I'm not going away until
you fix that bug and I get my sweet" attitude, technically he's spot on.
 The gcc maintainers insist that "undefined" gives them the license to
do literally anything at all instead of trying to find out what the
sensible semantics in such as case might be.
Overflow checks are rare already, so they should be cherished, not
optimised away.

@_date: 2014-04-21 08:06:26
@_author: Stephan Neuhaus 
@_subject: [Cryptography] bounded pointers in C 
And therein lies, I think, a clue as to why, in every case that I know,
software without security problems has been written by one person alone.
I usually find it plain awkward to read code written by others;
therefore I'd rather audit my own code than someone else's, and I
daresay that this probably also holds true for you, Peter.   And then it
does take a special kind of person that would look at his or her own
code not with awe at the wonderful thing one has made, but with an
honest intent to find mistakes.
PS: At the risk of incurring the wrath of list members, the pieces of
software I was thinking of are CryptLib (Peter Gutmann), Postfix (Wietse
Venema), djbdns (Dan Bernstein) and qmail (also Dan Bernstein).  Did I
miss any?

@_date: 2014-04-22 21:42:53
@_author: Stephan Neuhaus 
@_subject: [Cryptography] LibreSSL (was Re:  bounded pointers in C) 
That web page says "At the moment we are too busy deleting and rewriting
code to make a decent web page", which implies, or at east suggests to
me, that this project will be reusing OpenSSL's architecture.
I think that if you want to make something that's substantially better
than OpenSSL, it would be a good idea to stop for a moment and think of
how you want your library to be used. I doubt that if you tried to
design an SSL/TLS API from the API user's point of view, something like
OpenSSL would come out. So why not make a clean-slate design, steal
those parts of OpenSSL that you can (the basic crypto algorithms,
probably) and reinvent and rewrite the rest?
If you want to know how this can be done, may I suggest that you take a
look at Peter Gutmann's CryptLib? If you prefer dead trees over code,
you could do worse than look at

@_date: 2014-04-23 07:18:51
@_author: Stephan Neuhaus 
@_subject: [Cryptography] 
=?iso-8859-1?q?inters_in_C=29?=
I know I'm picking nits here, but *that* goal can be achieved by simply
removing all the meat from the OpenSSL functions and just leaving
"return;".  How is functional correctness or even compatibility tested?
The web site doesn't say.

@_date: 2014-04-23 07:29:14
@_author: Stephan Neuhaus 
@_subject: [Cryptography] Open Source developer employment agreements, 
If I remember correctly, (one of) the main point(s) of literate
programming is the intermingling of code and documenting text.  Javadoc
and its brethren only document whole files, class members, method
signatures and the like, not the code itself.  But I must say, it's been
a while since I've last used JavaDoc, so I might be wrong. (For Doxygen,
however, I'm rather confident that this is indeed the case.)

@_date: 2014-04-25 08:31:42
@_author: Stephan Neuhaus 
@_subject: [Cryptography] GCC bug 30475 (was Re:  bounded pointers  in C) 
And what do you do if al and be are of type ptrdiff_t, for example?  The
only thing I can think of would be something like
  sizeof(ptrdiff_t) == 4
#  define PTRDIFF_T_MAX INT32_MAX
 sizeof(ptrdiff_t) == 8
#  define PTRDIFF_T_MAX INT64_MAX
#  error Your ptrdiff_t has a weird size
I look at this code and am uneasy. It isn't portable, since int32_t and
int64_t are optional, and hence, so are the corresponding _MAX macros.
Is it guaranteed to work? I'm sure I could find out from reading the
standard, but it's not intuitive to me.
If I read correctly, the compiler may even create evil code for stuff
that came textually before the overflowing computation, provided that
these preceding computations don't interfere with the overflow-producing
one and can thus be legitimately reordered.
And while I'm sure that you're technically correct, I still think that
the compiler writers should not read the standard as giving them license
to do literally anything (without a warning, which was the original
point of the bug report), but should instead try to preserve the
intention of the programmer (with a warning).

@_date: 2014-04-25 10:17:21
@_author: Stephan Neuhaus 
@_subject: [Cryptography] GCC bug 30475 (was Re:  bounded pointers  in C) 
See? I knew I was missing something.  I remembered that sizeof evaluates to a constant but missed that the value of that constant wouldn't be available to the preprocessor.

@_date: 2014-04-30 23:01:57
@_author: Stephan Neuhaus 
@_subject: [Cryptography] GCC bug 30475 (was Re: bounded pointers in C) 
While I disagree with most of what you said about what the compiler
ought and ought not to do with security checks and undefined behaviour,
there is precedent of a kind for this.
Some CPU/FPU implementations have 80 bit FPU registers (equivalent to
C's long double type when on an IEEE-conforming implementation), but
64-bit double representations.  Computations are done by loading the
(64-bit) double operands form memory, extending them to (80 bit) long
double, doing the computation in long double, then rounding the result
to double and finally storing the result. This can invalidate many
carefully crafted optimisations or error-curtailing tricks.

@_date: 2014-08-08 09:33:55
@_author: Stephan Neuhaus 
@_subject: [Cryptography] All dice are loaded? 
(I can't find the article or the follow-up.) Oh dear.  Let's assume for
the moment that the test was carried out competently.  Two things need
to be borne in mind:
(1) If you make N large enough, systematic deviations from uniformity
will eventually become "statistically significant" at any level.
(2) The die used in the experiment may indeed be biased so that sixes
appear more than 1/6 of the time, but is the size of the effect
something to worry about?  (If this bias caused a reduction of effective
key strength from 256 to 255 bits then that's interesting, but nothing
to worry about.  This is especially so since that reduction will very
likely not be confined to a certain bit position, but instead be spread
over all the 256 bits in an interesting and nonlinear way.)
(Incidentally, ans slightly OT, people often think "p < 0.05, yay, I've
made a discovery", but that's often not the case.  See
 and for how this works.)
Add to that the fact that even such seemingly simple tests can be
screwed up in so many ways and it becomes an interesting data point
among many others.  Something that, as you say, belongs in the "tin
foil" category.

@_date: 2014-08-08 09:35:10
@_author: Stephan Neuhaus 
@_subject: [Cryptography] All dice are loaded? 
On a philosophical note, indeed all dice are loaded.  They have to be.
If all the sides were the same, we couldn't say which face was up.

@_date: 2014-08-10 19:39:01
@_author: Stephan Neuhaus 
@_subject: [Cryptography] All dice are loaded? 
My point was not a practical one, but a philosophical one.  The only way
to avoid bias (from a philosophical point of view) is to make all faces
exactly equal, aka indistinguishable.

@_date: 2014-08-10 20:28:03
@_author: Stephan Neuhaus 
@_subject: [Cryptography] All dice are loaded? 
... which makes your point a practical one, and one with which I'd
agree, but not a philosophical one :-)

@_date: 2014-08-20 09:04:50
@_author: Stephan Neuhaus 
@_subject: [Cryptography] Encryption opinion 
A small nitpick: IIRC, WEP wasn't broken through cryptanalysis of RC4
(at least not initially), but because the designers of WEP had designed
too small an IV so that IVs and hence keystreams would repeat before long.

@_date: 2014-08-20 09:14:39
@_author: Stephan Neuhaus 
@_subject: [Cryptography] CSPRNG for password salt 
a) The only "attack" I can think of is that rand() (IIRC) is a 32-bit
RNG, which would mean that after 2^16 generated salts, one should start
seeing collisions.  And *if I knew in advance what that collision was*,
I could now hack two passwords as cheaply as one through a prepared
dictionary using that salt.
b) Now a salt is not an IV, so even with a collision, no keystream is
repeated, so I'm doubtful that even doubling the probability of success
counts for very much.  I think it's much more likely that some user's
password is 123456 or something easily crackable, so the answer to that
is "not very".

@_date: 2014-08-20 13:44:53
@_author: Stephan Neuhaus 
@_subject: [Cryptography] CSPRNG for password salt 
I don't think so.  In my opinion, the cost in pre-computing the tables
is in their storage, not their computation.  In that case, it doesn't
matter if I compute the table on the fly or offline.

@_date: 2014-08-25 08:31:52
@_author: Stephan Neuhaus 
@_subject: [Cryptography] Encryption opinion 
I would opine that even if users could tell the difference, they'd still
get phished.  HTTPS doesn't protect against phishing; if your browser is
talking to a phishing site, and if they have a genuine certificate, the
certificate will happily (and correctly) attest to the authenticity of
that phishing site.
Pervasive HTTPS would indeed be a (part of the) solution to the problem,
if only because it would no longer be possible to make the stupid
decision that a site with a self-signed certificate (that fails to
verify because the browser doesn't have the issuer's cert in its cache
of trusted roots) is somehow less secure than a site with no certificate
at all.

@_date: 2014-08-25 13:32:41
@_author: Stephan Neuhaus 
@_subject: [Cryptography] Encryption opinion 
Except that the M isn't ITM in the case of phishing.  Phishing is not so
much a Man In The Middle, it's more a Man On The Sidelines That Looks
Very Much Like Bob, or MOTSTLVMLB, but good luck pronouncing that.
Not sure if sarcastic or serious, but HTTPS isn't useless just because
it doesn't protect against phishing.
We're very much on the same page here.
I'm not sure.  It's very hard (at least NOW it's very hard) to come up
with a way to tell users that a site is probably a phishing site without
confusing them even more than they already are.
Again, I'm on the same page as you, so I'm not going to "explain that"
:-) In my original post I merely pointed out that crypto won't stop Eve
from dressing up as Bob while still showing credentials that say
correctly that she's Eve.

@_date: 2014-01-21 17:01:35
@_author: Stephan Neuhaus 
@_subject: [Cryptography] Does PGP use sign-then-encrypt or encrypt-then-sign? 
Dear list,
I'll be darned if I can find in RFC4880 how to do both encryption and signature in OpenPGP.  Knowing that both naively doing sign-then-encrypt and encrypt-then-sign have their problems, surely it can't be that, right?  So what *is* actually happening in OpenPGP?  And where does it say that in the RFC?

@_date: 2014-01-21 13:32:18
@_author: Stephan Neuhaus 
@_subject: [Cryptography] Timing of cyberattacks -- is this a joke? 
This paper  has been making some waves; I've heard it discussed in several podcasts to which I subscribe.
Mathematically, the paper is not very difficult, and the treatment more than superficial (using tables to find the optimum of a smooth function of two variables), and some assumptions questionable (constant payoff discount rate), but from a practical perspective, it's useless because none of the parameters that go into the equations can be estimated robustly. (As far as I could see, there's also no discussion of how sensitive the equations are to errors in the parameter estimates.)
So my question is: is this paper just an elaborate hoax or is this to be taken seriously? To be honest, it has the feel of the Sokal paper, just without the latter's excellent exploitation of jargon. (Or perhaps I'm just too blind to see it.)

@_date: 2014-01-30 07:46:06
@_author: Stephan Neuhaus 
@_subject: [Cryptography] cheap sources of entropy 
I happen to agree with you. TFM to R for those who don't (and in fact probably anyone on this thread) would be, in my opinion:
 followed by  .
These are publications that avoid opinion in favour of technical analysis.  From my point of view, they're still the last (or at any rate the technically most defensible) word on the subject, even though I am of course willing to learn the error of my ways, if they are accompanied by, as you say, a pointer to another TFM to R.

@_date: 2014-01-30 07:50:41
@_author: Stephan Neuhaus 
@_subject: [Cryptography] cheap sources of entropy 
Taking Dan's original formulation of "N bit streams, at least one of which is truly unpredictable", a simple XOR would be enough.

@_date: 2014-01-30 08:07:26
@_author: Stephan Neuhaus 
@_subject: [Cryptography] cheap sources of entropy 
Sorry, they have to be N *independent* streams.  A weaker precondition can surely be found, but I'm too lazy now to look for it.

@_date: 2014-07-26 10:29:22
@_author: Stephan Neuhaus 
@_subject: [Cryptography] propaganda on "hurdles for law enforcement" 
If you need absolute assurance that your secrets are being kept, don't
have any, because once you have secrets, it always "involves some level
of risk".

@_date: 2014-06-01 10:34:22
@_author: Stephan Neuhaus 
@_subject: [Cryptography] Is it mathematically provably impossible to 
To tackle your questions in turn: the answer to the question of whether
it is "mathematically provably impossible to construct a mechanism to
test for back doors in programs?" is yes, and the proof is simple and
requires only elementary logic.  It is the same proof that was used by
Fred Cohen some thirty years ago to prove that no perfect virus detector
could exist. It is a classic proof by contradiction.
Assume therefore that such a method existed.  In other words, if P is
any program, we assume the existence of a function f such that
  * f(P) is "yes" if P contains a backdoor
  * f(P) is "no" if P contains no backdoor
  * the computation of f always terminates
Now I build an encryption program C that contains the following code:
  void encrypt (buffer b, key k) {
    if (f(C) == "no")
      send_key(k, NSA);
    ... /* encryption code here */
  }
In other words, C exhibits a back door if and only if f(C) says it has
no backdoor.  This is a contradiction to our assumption and we must
therefore conclude that no such function f can exist.
Now for the second question: given the impossibility of f, why do we
favour open source?  The first answer to this is that "we" might *not*
favour open source at all, for a variety of reasons, but that is a
fairly cheap and glib answer.  The real answer is that while no
algorithm with the properties given above can exist, there is
nevertheless the possibility of detecting a great number of backdoors in
a practical way.  Also, the contortions that program C above went
through are rather easy to detect themselves and would lead one to
reject program C.
The same mistake is occasionally made in cryptography.  Ralph Merkle
once invented a cryptosystem where an attacker had to solve a knapsack
problem, but where the legitimate recipient had secret information that
would allow him to turn the knapsack problem into a so-called
"superincreasing" knapsack problem, which is easy to solve by brute
force.  The reasoning was that since the knapsack problem is known to be
NP-complete, then unless P = NP, the attacker has a very difficult job.
The fault in the logic was that, yes, a *random* instance of the
knapsack problem is hard to solve on average, but the knapsack problems
that came out of his cryptosystem were *not* random instances.  In fact,
they were solved on standard desktop hardware just a few years later,
and the cryptosystem thus broken.

@_date: 2014-06-16 09:16:48
@_author: Stephan Neuhaus 
@_subject: [Cryptography] [cryptography] Dual EC backdoor was patented by 
Leaving aside the question what the benefit *to society* is of patenting this, one man's backdoor is another government's key escrow mechanism.

@_date: 2014-06-26 16:35:57
@_author: Stephan Neuhaus 
@_subject: [Cryptography] a question on consensus over algorithmic agility 
I think you're screwed either way.  In the case that you stick with a single cipher, you're screwed if it gets broken; and in the second case, you're screwed because you can't do (or in any case, to my knowledge no one has done) a secure failover from one supported (but broken) cipher to another.
It's opportunistic, right?  That means that data is opportunistically encrypted that would otherwise have been sent in the clear.  In that case, I'd go for the vastly easier-to-implement single-cipher solution.   Because it doesn't matter if the cipher is broken.  There was never any expectation of confidentiality.

@_date: 2014-03-03 09:03:56
@_author: Stephan Neuhaus 
@_subject: [Cryptography] The GOTO Squirrel! [was GOTO Considered Harmful] 
Essentially, what you're describing is fuzzing.  I agree with your assertion that it's dangerous to have it lying around in code, but there's no reason why one couldn't annotate the code (using comments, for example) and then have a fuzzer prepare a special version.  This version could be transient and exist only for testing purposes.
Sounds like an interesting project. Any collaborators?

@_date: 2014-03-03 09:54:32
@_author: Stephan Neuhaus 
@_subject: [Cryptography] The GOTO Squirrel! [was GOTO Considered Harmful] 
My mistake, I should have been more specific. I was thinking not so much about *randomly* changing data, but rather about annotating code so that important corner cases and otherwise-hard-to-test situations can be created, using custom code.
The main idea was not the random fuzzing (though that can also be of interest), but using annotations to create that code.

@_date: 2014-03-04 08:57:06
@_author: Stephan Neuhaus 
@_subject: [Cryptography] The GOTO Squirrel! [was GOTO Considered Harmful] 
There are two problems that I have personally encountered in practice:
1. Languages like C or C++ are de-facto unparseable without
preprocessing. Real-world C and C++ code is full of things like
 A
  while (X) {
  while (Y) {
    ...
  }
So there actually isn't something that you could call *the* program
flow. Strictly speaking, the program flow exists only for a specific
compilation environment.
2. Especially C++ is so full of "decision points" that it's hard to get
even 100% branch coverage on unit tests for even the simplest of
classes. Try it. There's just too much going on behind the scenes. The
assembler output of g++ is eye-watering.
That means that the number of "decision points" is so large that you get
a combinatorial explosion if you want to get every combination.

@_date: 2014-03-09 07:58:18
@_author: Stephan Neuhaus 
@_subject: [Cryptography] RC4 again (actual security, 
"Secure if used correctly" is my main gripe with it.
Despite all the other concerns mentioned by other posters, the RC4 API
gives no indication that you, the programmer, have to manually discard
the first few thousand bits of output. RC4 is to this extent more
difficult to use correctly than, say, ChaCha20 (even though ChaCha20 is
so new that it might well have other flaws that we don't yet know about;
I'm using it merely as an illustrative example).
Given that most crypto code will not be written by crypto specialists,
and also given the wonderful apparent simplicity of its API (also
mentioned by you), RC4 is a natural candidate for an unsafe
implementation in many applications.
So I'd second the argument against RC4 in new systems.

@_date: 2014-03-10 19:21:49
@_author: Stephan Neuhaus 
@_subject: [Cryptography] RC4 again (actual security, 
I'm not so sure. RC4 is really nice in that it doesn't have to have
length expansion. Once you try to substitute, say, AES in the mode du
jour, some length expansion will occur through the IV and perhaps
through padding. That may sound trivial, but it's not for a programmer
that really doesn't have to change anything about his or her program
other than to substitute the block of plaintext with a block of
(random-looking) ciphertext.
But I agree with you, it's real easy to upgrade from properly
implemented single-DES-CBC (say) to AES-CBC because all the machinery
for handling IVs and length expansion etc is already in place. But the
lure of RC4 is precisely that one can get away with not having this
If you do all the voodoo correctly, RC4 may be a fine cipher, but if you
don't, you end up with a program where the substitution of AES-CBC, say,
for RC4 isn't as easy as one might think.

@_date: 2014-05-03 12:06:45
@_author: Stephan Neuhaus 
@_subject: [Cryptography] One third IT managers think homomorphic is 
Do you have evidence for that?  You don't have to name it, just say
"yes" if you know of examples; I'll believe you, even though it does
boggle the mind.
But of course encrypting locally and storing ciphertex remotely does
have an important drawback: without homomorphic encryption you can't do
"SELECT column FROM table WHERE ..." on encrypted database rows.

@_date: 2014-05-19 20:31:27
@_author: Stephan Neuhaus 
@_subject: [Cryptography] updating a counter 
Precisely. If I understand things correctly, there is (or ought to be)
zero correlation between encrypt(x) and encrypt(x + 1) for a good block
But of course, not being a cryptographer, I'd love to learn otherwise.

@_date: 2014-05-27 21:08:35
@_author: Stephan Neuhaus 
@_subject: [Cryptography] Langsec & authentication 
Even worse, the document
might authenticate differently from the document
if any characters used to represent the first line used UTF-8
non-shortest-form encodings and the second one didn't.  (I don't know
how to make this happen in Thunderbird, so this is an example only, OK?)
And this even though both represent the same document!
I think you should treat data to be authenticated as a binary blob.  In
other words, you should authenticate a particular representation of your
data.  If you want to authenticate "what you mean" instead of "what you
say", you will never get anywhere.  Or rather, you will get somewhere,
but it might not be where you want to be.
I'm thinking of XML signatures here, they tried the same thing and
failed horribly.

@_date: 2014-05-27 21:53:46
@_author: Stephan Neuhaus 
@_subject: [Cryptography] Langsec & authentication 
Once you have ambiguous blobs of data, one of which means "re-order
coffee" and the other meaning "nuke North Korea", you've lost the game.
 But surely that's not the fault of the authentication subsystem.

@_date: 2014-05-28 08:45:46
@_author: Stephan Neuhaus 
@_subject: [Cryptography] Langsec & authentication 
My point was rather that if I send you a message which you can legitimately decode as either a request for more caffeine or delivery of apocalyptic weaponry, authenticating the message is the least of your worries and you should redesign your protocol.
One protocol which does it right is IPFIX (see RFC 5101). This is a protocol that's designed for the transport of network measurement data. (It's a descendent of NetFlow V9, if that helps.) (Conflict-of-Interest declaration: I am writing a fast IPFIX/V9 collection/transcoding/export library.) The various data items have types, but these aren't the types that a CS major would come up with (boolean, integer, float), but rather have very specific semantics.  Thus you have, for example, the types "IP V4 source address" and "IP V4 destination address".  There is really no way to mistake one for the other.  (Well of course there's always a way, but the protocol really goes out of the way to make that difficult.)
In this protocol, there's no way to say "bring me more coffee" and have it interpreted as "launch nukes", even though there are many ways to say "there were 100 bytes exchanged between 1.2.3.4 and 5.6.7.8 last Monday between 10.00 am and 10.01 am", through different orderings of the data items.  In this case, even reordering the source and destination IP addresses would not change the meaning of the data, since the types of the data items are not just "IP V4 address" but "IP V4 source address".

@_date: 2014-05-28 08:59:48
@_author: Stephan Neuhaus 
@_subject: [Cryptography] New slogan for the NSA 
After the invention of the smart phone it is perhaps time to invent the Smart shoe.

@_date: 2014-09-04 08:13:41
@_author: Stephan Neuhaus 
@_subject: [Cryptography] List of Proven Secure Ciphers / Hashes 
I'm not sure why this should be so.  Presumably you mean that the security of all cryptography depends on P != NP.  That may be true for all *current* crypto (I don't know), but if you could find an encryption algorithm that would be provably as difficult to break as a random problem in NEXP - NP, then even if P = NP, your algorithm would still be NP just isn't the hardest class of problems out there.

@_date: 2014-09-11 09:01:30
@_author: Stephan Neuhaus 
@_subject: [Cryptography] List of Proven Secure Ciphers / Hashes 
Apart from all the things Peter has already said, the "practical, efficient" bit is the (often left-out) key here.  It may be that P=NP, but if the exponent is something ridiculous, like 10^10^10^10, even the most efficient implementation in the world wouldn't crack RSA-2048 any time soon, and you're faster with the (non-poly-time) general number field sieve.

@_date: 2014-09-22 09:25:07
@_author: Stephan Neuhaus 
@_subject: [Cryptography] Of writing down passwords 
If I had written this document, I'd probably have removed the "easy to remember" part while emphasising the "write it down" part, but that's a

@_date: 2014-09-29 08:43:49
@_author: Stephan Neuhaus 
@_subject: [Cryptography] Which big-name ciphers have been broken in 
It looks like a fun read indeed.  The title could well be a nod to "Conjectures and Refutations: The Growth of Scientific Knowledge" by Karl Popper.
