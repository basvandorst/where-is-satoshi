
@_date: 2001-12-27 17:29:30
@_author: Sidney Markowitz 
@_subject: (A)RC4 state leakage 
Here's something by Ron Rivest about RC4 security that will give you a
simple overview before delving into the articles that Steve Bellovin
cited in his message. Note that Steve Bellovin's link includes the two
papers on RC4 weaknesses that Rivest references.

@_date: 2001-06-12 17:01:55
@_author: Sidney Markowitz 
@_subject: Thermal Imaging Decision Applicable to TEMPEST? 
IANAL, but when I read the decision it seemed to apply to new
technologies that are equivalent to entering someone's house and looking
around without a search warrant. Looking ahead, it may someday be
possible to make the walls of someone's home effectively transparent,
and the ruling says it is illegal to use such technology in situations
where it would be illegal to enter the house.
There's an article by someone who is a lawyer at
where he defines the question in this case as
"Is thermal imaging more like going through your garbage (which courts
have allowed) or more like looking into your window with a high-powered
telescope (for which courts generally require a warrant)?"
The article goes on about the decision process in cases like this.
I think it is clear that a Supreme Court judge might consider technology
to effectively look through walls to see whatever is there as being in a
different class than technology to remotely detect the details of use of
electronic equipment, in the same way that a telescope looking in the
window is different from sifting through garbage.
 -- sidney
    sidney at sidney.com

@_date: 2001-11-28 09:37:28
@_author: Sidney Markowitz 
@_subject: cryptoheaven.com 
I haven't seen mention of this on the mailing list and it is new enough
that it doesn't show up in a google search as of the moment I am typing
Looking at  it appears they provide anonymous
encrypted services including email, instant messaging (chat), and server
based file storage. Their client code is open source Java. They appear
to use standard algorithms. They are based in Canada. The services are
free at small volumes (supposedly suitable for ordinary personal use)
and for fee at higher volumes.
I only know what I see on their website. Has anyone else heard of these
 -- sidney

@_date: 2001-10-13 23:25:28
@_author: Sidney Markowitz 
@_subject: Rijndael in Assembler for x86? 
A little over a month ago Perry Metzger asked about free assembler
language implementations of Rijndael for x86. Helger Lipmaa, whose
commercial assembler language version seems to be the fastest,
mentioned Brian Gladman as having the best free C implementation.
Gladman's web page now says that he has a free assembler language
version. For comparison, Lipmaa says that his runs at 230 cycles per
block, Gladman's C version runs at 360 cycles per block, and Gladman's
assembler language version runs at 300 cycles/block. It is not yet a
complete implementation. Here's a quote from the website:
"Here is a preliminary version of this code in assembler for the
Pentium family with MMX (Pentium II/III/IV). This only implements the
standard block size of 128 bits but is 15-20% faster than the C code.
It achieves a maximum speed with a fully primed processor cache of
about 300 cycles/block, which is around 50 Mbytes/second on a 1GHz
processor.  This version has not been extensively tested so please be
aware that there may be bugs in it. Note also that it uses the
Microsoft VC++ register saving conventions and may hence need changes
if used with other C/C++ compilers."
The URL is
 -- sidney

@_date: 2001-10-15 15:37:44
@_author: Sidney Markowitz 
@_subject: First Steganographic Image in the Wild 
The URL Kevin posted is slashdotted because of this article
Based on the comments on slashdot it appears that Niels Provos, whose program found no steganography in millions of images on the web, was able to detect and decode an example image planted by ABC as part of their documentary on steganography and mentioned b ythem on the air. The example was a picture hidden mixed in to another picture revealed using the password 'ABC'.
I don't think this is an example of steganography in the wild. It does show that the software would have been effective at finding hidden unencrypted pictures protected by simple English words if anyone was posting such things  on the sites that Provos searched. As to why that is more effective than an email from one anonymous hotmail account to another saying "Everything is set. Proceed according to plan" or even "Plans have changed, make contact through the usual channels" I have no idea.
 -- sidney

@_date: 2001-09-24 22:13:51
@_author: Sidney Markowitz 
@_subject: Senators on civil liberties 
Here's a quote from the Washington Post last Sunday, 23 Sept, 2001.
The URL
is good for 2 weeks from then:
 -------------
"I've been getting e-mails from all over the country, from people both
on the left and the right, concerned about what we're doing to civil
liberties," Senate Judiciary Committee Chairman Patrick J. Leahy
(D-Vt.) told Ashcroft in a meeting Wednesday.
"That's okay, Pat, we've been reading your e-mails all week," Ashcroft
Leahy erupted in laughter, disarmed.
 --------------

@_date: 2002-04-16 13:37:07
@_author: Sidney Markowitz 
@_subject: Schneier on Bernstein factoring machine 
"The big news is" does not mean the same as "I'm shocked that". He appears to agree
with Lucky Green's decision to keep 1024 bit keys up until now despite the prediction
some years ago that 1024 bit keys would only be safe until sometime between 2000 and
2002. If you accept the table as being a reasonable prediction at the time it was
made, the "big news" is that someone like Lucky Green has continued to consider 1024
bits safe up to now.
 -- sidney

@_date: 2002-08-13 11:07:35
@_author: Sidney Markowitz 
@_subject: [aleph1@securityfocus.com] Implementation of Chosen-Ciphertext Attacks against PGP and GnuPG 
[Perry message forwarded a notice of a paper on an attack against PGP and
A posting on bugtraq in response said, in part:
The full posting is at  -- sidney

@_date: 2002-02-26 16:06:19
@_author: Sidney Markowitz 
@_subject: Bernstein's fast factorization 
Someone on another mailing list pointed me to this posting by Dan
Bernstein on sci.crypt newsgroup:
[begin quote]
 From: D. J. Bernstein (djb at cr.yp.to)
 Subject: Re: Strength of PGP vs SSL
 Newsgroups: comp.security.pgp.discuss, sci.crypt, alt.security.pgp
 Date: 2002-01-16 01:00:11 PST
Protecting against the  speedup
means switching from n-bit keys to f(n)-bit keys. I'd like to emphasize
that, at this point, very little is known about the function f. It's
clear that f(n) is approximately (3.009...)n for _very large_ sizes n,
but I don't know whether f(n) is larger than n for _useful_ sizes n.
I'd also like to emphasize that special-purpose hardware is useful for
much more than factorization. In fact, it's much easier to reduce cost
this way for secret-key cryptanalysis or elliptic-curve discrete log
than for factorization.
[end quote]
 -- sidney

@_date: 2002-01-23 11:47:57
@_author: Sidney Markowitz 
@_subject: I-P: WHY I LOVE BIOMETRICS BY DOROTHY E. DENNING 
A search for 'hippus eye' (two separate words, not quoted as a phrase)
turns up a bit more. The only references for its use in biometrics were
from Iridian or the scientist who is now who developed and
patented its use for that purpose. But there are plenty of references to
'hippus', the continual motion if the iris that keeps us from
habituating to an unchanging scene and is related to eye fatigue.
Apparently it includes contraction/expansion of the iris, which would be
hard to fake with a contact lens.
 -- sidney

@_date: 2002-01-28 09:47:51
@_author: Sidney Markowitz 
@_subject: biometrics 
Shared "secret"? People don't leave a copy of their PIN on every water
glass they use.
 -- sidney

@_date: 2002-10-17 02:11:29
@_author: Sidney Markowitz 
@_subject: [Bruce Schneier <schneier@counterpane.com>] CRYPTO-GRAM, October 15, 2002 
"Bill Frantz"  asked:
A Google search for 'nmap test' came up with this as the first hit:
It seems to offer that service, but also has links to a whole bunch of other
sites that offer port scanning services, further down the page at:
  -- sidney

@_date: 2002-10-22 11:37:21
@_author: Sidney Markowitz 
@_subject: Why is RMAC resistant to birthday attacks? 
"bear"  asked:
It doesn't. As described in the paper all you can do with it is the following:
Mallory discovers that a message from Alice "Buy a carton of milk" and another
message from Alice "Get a dozen eggs" are sent with the same salt and have the
same MAC, and guesses correctly that Alice and Bob are using RMAC and the two
messages use the same keys. He then notices a message from Alice with the same
salt as the others "Buy a carton of milk and send Mallory a million dollars".
That allows Mallory to forge a message that says "Get a dozen eggs and send
Mallory a million dollars".
The mention of the birthday surprise in the paper is in the section on message
extension forgery attack, which is the arttack described above. Where the
birthday surprise comes in is in computing the work factor for performing that
attack. In the case of RMAC it is two to the power (k+r)/2, and that's how
many messages from Alice that all use the same keys Mallory will, on the
average, have to snoop before an opportunity for such an attack crops up,
i.e., the MAC is the same (k bits) and the salt is the same (r bits). The salt
does add r/2 bits to the work factor compared to just using a k bit hash for
the MAC without a salt.
It is left as an exercise for the reader to come up with an application for
RMAC in which one would have a chance to snoop 2^((k+r)/2) messages that all
use the same keys to find one colliding pair, and then in which Alice would
send another message that is the first one of that pair extended with
something and which happens to have the same salt as the first one (about
1/2^r probability), and in which the second colliding message extended with
the same things as the first would have some meaning that would create a
damaging result.
But whether or not this is a likely problem, the paper does compute the work
factor of the attack so you can make a decision on key and salt sizes to make
it infeasible given the circumstances of your use of RMAC.
 -- sidney

@_date: 2002-10-22 12:33:07
@_author: Sidney Markowitz 
@_subject: Why is RMAC resistant to birthday attacks? 
Ed Gerck" Well, to be really pedantic the paper never says that it is "easy" only that
it has a work factor of the square root of the number of possible MAC strings
without salt, and that adding the salt multiplies that by the square root of
the possible number of salt values. That attack scenario certainly doesn't
look easy to me :-). And as long as I'm being pedantic I'll point out my own
mistake in my last message of using 'k' as the variable for block size (MAC
length) instead of 'b' as in the paper.
 -- sidney

@_date: 2002-10-22 13:52:18
@_author: Sidney Markowitz 
@_subject: Why is RMAC resistant to birthday attacks? 
Victor.Duchovni at morganstanley.com
I just realized something about the salt in the RMAC algorithm, although it
may have been obvious to everyone else:
RMAC is equivalent to a HMAC hash-based MAC algorithm, but using a block
cipher. The paper states that it is for use instead of HMAC iin circumstances
where for some reason it is easier to use a block cipher than a cryptographic
The security of HMAC against attacks based on collisions is measured as a
function of the bit length of the hash. Using a block cipher in CBC mode makes
it in effect a b bit hash, where b is the block length of the cipher. In many
cases the block length of a cipher being 64 or 128 bits will be too small by
itself. Hence the need to add r bits from the salt and the need to write up
explicitly how RMAC handles collision based attacks and how the salt affects
 -- sidney

@_date: 2002-10-22 15:55:39
@_author: Sidney Markowitz 
@_subject: Why is RMAC resistant to birthday attacks? 
Ed Gerck"  said:
Some quotes from the paper:
"This paper defines an authentication mode of operation, called RMAC, for a
symmetric key block cipher algorithm"
The definition of RMAC in the table of defnintions: "The name of the
authentication mode that is specified in this Recommendation"
"In particular, RMAC is an algorithm for generating a message authentication
code (MAC) from the data to be authenticated and from an associated value
called a salt, using a block cipher and two secret keys [...]"
"Fips Pub 198 specified a different MAC algorithm, called HMAC, that is also
appropriate for protection of sensitive data. Because HMAC is constructed from
a hash function rather than a block cipher algorithm, RMAC may be preferable
for application environments in which an approved block cipher is more
convenient to implement than an approved hash function."
RMAC was devised for the reason I stated, as it says in the last quote from
the paper above. The salt is there to make the cost of the extension forgery
attack more expensive because the birthday surprise shows that just the number
of bits in the cipher block may not make it expensive enough without a salt.
The key size is not relevant to the "birthday attack" (actually extension
forgery attack) as shown in the table where the work factor expressed as a
function of the block length and the salt length, not the key size.
 -- sidney

@_date: 2002-10-22 16:07:53
@_author: Sidney Markowitz 
@_subject: comparing RMAC to AES+CBC-MAC or XCBC (Re: Why is RMAC resistant to birthday attacks?) 
No, because it is not a collision for the purpose of this attack on this
algorithm unless the b bit untruncated MAC and the r bit salt both match, even
if the m bit truncated MAC matches. As it says in the paper:
"the unauthorized party would have to collect 2^((b+r)/2) message-tag pairs in
order to expect to detect a collision"
That's because the collision is only of use for the extension forgery attack
if the two colliding messages have the property that RMAC(x) == RMAC(y) and
RMAC(x||z) == RMAC(y||z) which is only true for a collision of the full b bit
untruncated MAC and the r bit salts are the same..
I think that they are chosen to make the work factors for General Forgery and
Extension Forgery attacks about the same in any one parameter set. It would
not make sense to have a parameter set which was a lot weaker to one of the
attacks than to the other. Look at Table 2 to see that is so.
 -- sidney

@_date: 2002-10-22 18:53:37
@_author: Sidney Markowitz 
@_subject: Why is RMAC resistant to birthday attacks? 
Thank you, that was really helpful in seeing the motivation for the work that led to
the NIST draft paper. The way I read it now, he includes a justification for block
cipher based MACs in general, then presents his RMAC, which he devised to deal with
the effect of the birthday surprise on the work factor of the forged extension attack
on other block cipher based MACS.
  -- sidney

@_date: 2002-10-24 02:08:11
@_author: Sidney Markowitz 
@_subject: comparing RMAC to AES+CBC-MAC or XCBC (Re: Why is RMAC resistant to birthday attacks?) 
[... quote snipped ...]
This doesn't contain the paragraph that you quoted, though a Google search found it
which appears to be the complete version of the same presentation.
In any case, I don't see any mention of extension forgery attacks in either the
portion you quoted nor elsewhere in the paper. There isn't reason to mention it since
XCBC should be inherently resistant to extension forgery attacks. The attack requires
that the MAC have the property that MAC(x) == MAC(y) implies that MAC(x||z) ==
MAC(y||z). In the case of XCBC, because of the padding and the use of K2 and K3 that
would only be true when x and y are the same length or both have lengths that are
multiples of the cipher block size.
I agree with your conclusion, but I don't see how anything Rogaway says about XCBC
has anything to do with it.
In the case of RMAC, if the parameter sets were chosen to make the work factors
comparable on the two attacks, I think it is making the mistake of comparing apples
and oranges: In the exhaustive key search attack, the attackers captures one message
and the work factor is multiplied times the time it takes to try a key on their own
computers. In the extension forgery attack the work factor is multiplied by the time
between captured messages. The latter is somewhat under the control of the person who
is using RMAC. There is no reason to require that they have similar work factors if
the scale is much different.
It was just my supposition that equality of the work factors was the motivation
behind selecting those parameter sets. I would like to see another reason or a
pointer to an explanation by the author if there is one.
 -- sidney

@_date: 2002-09-20 12:28:42
@_author: Sidney Markowitz 
@_subject: unforgeable optical tokens? 
The section on replay attacks in Pappu's PhD thesis only addresses what an
adversary could do given some free access to the device, presumably for a
finite time after which the device is returned to the owner. Pappu
demonstrates that it is not feasible to extract and store sufficient
information to either have all possible challenge/response pairs available
or to be able to compute them with a simulation.
That does not address the issue that the challenger also does not have
access to the full range of challenge/respones, and so has to keep a
feasibly small number of them as secrets. This is more secure than a shared
secret, because the token owner does not need to know which challenges the
challenger has stored, so an adversary can only obtain them from the
challenger. If the same challenge/response pair is given to two challengers,
then either one could forge authentication of the identity of the token's
owner. On the other hand there are so many possible challenge/response pairs
that there is no need to give the same ones to two people. In fact Pappu
describes a protocol in which challenge/response pairs are never reused. It
means that challengers can believe the authentication to the degree that
they believe that they have kept their copy of the challenge/response pairs
secure and that the token is in the physical possession of the right person
at the time the challenge/response is exchanged.
Pappu characterizes the device as a "physical one-way hash function". Given
a random challenge that is not known in advance, producing the proper
response proves that one has posession of a particular physical token. It
does not break security to lend the token to someone so that they can store
a bunch of challenge/response pairs for future use in having you
authenticate yourself to them.
Figuring out how to use this for digital signatures or asymmetric encryption
looks like a challenge: Unlike algorithmic one-way hash functions, the only
way to compute the function is to have physical posession of the device: Bob
does not get to confirm Alice's result unless the protocol involves Alice
lending or giving Bob her token. Pappu's example of a bit commitment
protocol (page 128 of his thesis) involves Alice picking a random token from
a pile and handing it to Bob.
The thesis has a section on digital signatures, but all that does is
describe how algorithmic one way hash functions are used to sign messages,
not how the physical one-way hash function could be used for that. Since the
only way to compute the hash is to have physical access to the device,
verification of a signature would require one to be able to submit a
challenge to the device and read back the response. This brings up all sorts
of questions such as how the challenger verifies that the device is the
correct signing token and is functioning properly, as well as how to prevent
the challenger from using their temporary access to the device to generate a
signature for any message they wish. Whether or not this device can be used
for digital signatures, how to do it is never addressed in the thesis.
 -- sidney

@_date: 2003-04-18 14:11:16
@_author: Sidney Markowitz 
@_subject: DMCA Crypto Software 
Profitability is not possible now given the time of protection is zero?
I wonder at what point it makes obvious sense to simply have an economic
model for content that incorporates the ease with which it can be copied.
It would be interesting to see what it is possible to do with a player that
executes its content. That opens a lot more possibilities for hacking it
than one has available in the current dumb players.
 -- sidney markowitz
     sidney at sidney.com

@_date: 2003-05-01 09:19:23
@_author: Sidney Markowitz 
@_subject: eWeek: Cryptography Guru Paul Kocher Speaks Out 
Since the "stalemate" is that one player might become disabled for future movies from at least one studio, perhaps these measures are only aimed at a threat model of individuals making their personal copies available for widespread distribution over P2P networks like Kazaa. Kocher could have said that and it was left out of the quotes, or he could have neglected to mention the threat model he is addressing and those he is not.
Clearly anyone who would go to the trouble of using five or more players to extract the watermark and make an untraceable copy for widespread distribution would also not be stopped by having to buy a player for cash or steal one or borrow one and sacrifice its eventual ability to play movies made after some future date.
 -- sidney

@_date: 2003-12-08 09:10:34
@_author: Sidney Markowitz 
@_subject: yahoo to use public key technology for anti-spam 
No, it implies a service that your outgoing mail server makes available that has you authenticate to it in some way and then signs your mail in some way.
The article doesn't make clear exactly how it would work. The signature might just certify that the mail really was sent through the mail server that the headers claim was used. That would allow you to use any email address that you want, such as your acm.org address, and the signature certifies that you authenticated yourself with the SMTP server.
My ISP recently switched to using TLS SMTP/Auth for access to their SMTP server from outside their network for their customers. It would be easy and useful for them to stamp mail that I send to show that it really was sent through their SMTP server and that they know who I am.
This might not be exactly the same as what Yahoo! is talking about: They might be thinking only about mail with a yahoo.com From address being sent through a yahoo.com server and being signed with a key associated with the yahoo.com domain. But if the signature is taken to authenticate the domain of the SMTP server in the initial Received header, then it is possible to maintain lists of servers of ISPs who are trusted to authenticate users of their SMTP servers and to have anti-spam policies, and blacklists of servers that are spam sources. The From address would be irrelevant.
  -- sidney

@_date: 2003-12-08 09:33:18
@_author: Sidney Markowitz 
@_subject: yahoo to use public key technology for anti-spam 
I agree. Even time period and message content aren't good enough: Let's say that the outgoing SMTP mailer at example.com is trusted. Spammer gets an account at example.com, sends themselves one message, then immediately copies the signature into forged headers for their spam that is sent out through whatever open relays or compromised machines they are using. The only way that the mail can be trusted is if it is being received directly from the example.com SMTP server. If there is any relaying, there is nothing that remains true and constant to sign.
But that is the situation we have today: My ISP's server can choose to refuse to accept connections from servers that are on a blacklist of open relays and spammers, and can, in theory, have a list of known good servers who authenticate their clients. If all the new header does is verify the sending mail server, that is done just as well by verifying the ip address at the time of connection.
  -- sidney

@_date: 2003-12-09 05:56:48
@_author: Sidney Markowitz 
@_subject: yahoo to use public key technology for anti-spam 
A google search for "rmx dns" without quotes brings up as its first hit the Internet Draft at IETF which is dated October 2003. The subsequent hits show lots of discussion about it.
You might also be interested in  which seems to be a similar proposal that extends the MX record rather than define a new rmx To bring it back to the cryptography topic of this list, the draft proposal for rmx brings up a problem with crypto solutions that I did not see mentioned here yet. I'll just quote the relevant paragraph from the Draft rather than summarize it. Note that the draft states that it specifies only non-cryptographic mechanisms but still allows use of [begin quote]
2.4.  Shortcomings of cryptographical approaches
  At a first glance, the problem of sender address forgery might
  appear to be solvable with cryptographic methods such as challenge
  response authentications or digital signatures. A deeper analysis
  shows that only a small, closed user group could be covered with
  cryptographical methods. Any method used to stop spam forgery must
  be suitable to detect forgery not only for a small number of
  particular addresses, but for all addresses on the world. An
  attacker does not need to know the secrets belonging to a
  particular address. It is sufficient to be able to forge any
  address and thus to know any secret key. Since there are several
  hundreds of millions of users, there will always be a large amount
  of compromised keys, thus spoiling any common cryptographic method.
  Furthermore, cryptography has proven to be far too complicated and
  error prone to be commonly administered and reliably implemented.
  Many e-mail and DNS administrators do not have the knowledge
  required to deal with cryptographic mechanisms. Many legislations
  do not allow the general deployment of cryptography and a directory
  service with public keys. For these reasons, cryptography is
  applicable only to a small and closed group of users, but not to
  all participants of the e-mail service.
[end quote]
  -- sidney

@_date: 2003-12-12 13:58:03
@_author: Sidney Markowitz 
@_subject: ANDOS-based secure voting system 
A clear summary of some voting protocols including the use of ANDOS for voting with one central facility can be found at
If you compare the protocol that uses ANDOS with the one that uses two central facilities and avoids the complications of ANDOS, it may become clear just what is the point of the identification number I which is distributed using ANDOS. That number is linked to the identity of the voter. The problem being addressed is how to allow someone to vote while preserving the anonymity of their vote, i.e., without recording their real-world ID with the vote. ANDOS allows a central facility to distribute unique ID numbers without knowing who gets what ID. The second protocol simplifies the problem by allowing one central facility to know who got what ID and the second facility to know the vote cast by each ID, but anonymity depends on trusting the two facilities not to Where this relates to your question is that nothing in the protocols has anything to do with the problem of physically identifying the voter and certifying that individual's right to vote. That is outside the cryptographic protocol. Step 1 of the ANDOS version is publishing a list of eligible voters. That implies that there are individual identities, that some are eligible to vote, and that they can be identified. In Step 2 each voter submits an intention to vote. This step implies some way for each voter to authenticate as being one of the identities on the list. Whether it is through biometrics or fear of legal sanctions or naive trust of all the voters is up to the people setting up the voting procedures. It is only after the identity has been verified and an ID number assigned that the rest of the protocol comes into play to allow exactly one vote per ID and to preserve the privacy of the voter.
  -- sidney

@_date: 2003-02-04 10:12:41
@_author: Sidney Markowitz 
@_subject: question about rsa encryption 
The short answer is that you should use one of the standard padding modes
that are designed for RSA encryption, usually OAEPPadding. There are
subtleties that the paddings are designed to take into to account, and if
you use the padding you don't need to know all of them.
 -- sidney

@_date: 2003-02-05 06:35:55
@_author: Sidney Markowitz 
@_subject: question about rsa encryption 
Ralf Senderek"  asked:
The page titled "Prescriptions for Applications that are Vulnerable to the
Adaptive Chosen Ciphertext Attack on PKCS  v1.5" at URL
 is not a complete explanation, but if you read it and start following the
links from there you should find what you want to know. There are links to
various articles on PKCS and there is some explanation of rationale in
the section on OAEP in the PKCS v2.1 standard.
 -- sidney

@_date: 2003-02-19 15:18:32
@_author: Sidney Markowitz 
@_subject: AES-128 keys unique for fixed plaintext/ciphertext pair? 
> For each AES-128 plaintext/ciphertext (c,p) pair with length
Excuse my naivete in the math for this, but is it relevant that the unicity
distance of ASCII text encrypted with a 128 bit key is about 150 bits
[Schneier, p 236] and the AES block size is only 128 bits? If you use plain
ECB mode is the plaintext/ciphertext length in the above statement 128 bits,
or does the statement imply that you have an arbitrary length (c,p) pair
using whatever mode, possibly chaining, makes sense for your purpose?
 -- sidney

@_date: 2003-06-30 08:49:18
@_author: Sidney Markowitz 
@_subject: Attacking networks using DHCP, DNS (Updated news) 
It turned out that the ISP, Charter, was not compromised. The user had some nasty spyware install itself on his computer. Here are the details:
  -- sidney

@_date: 2003-03-15 17:18:16
@_author: Sidney Markowitz 
@_subject: Face-Recognition Technology Improves 
Wow, 99% accuracy for false positives! That means only a little more than
750000 people a year mistakenly detained for questioning in Atlanta
HartsField Airport (ATL), and even fewer at the less busy airports (source
Airports Council International, 10 Busiest Airports in US by Number of
Passengers, 2001).
 -- sidney markowitz
     sidney at sidney.com

@_date: 2003-03-16 07:55:44
@_author: Sidney Markowitz 
@_subject: Face-Recognition Technology Improves 
No, 75 million. If you look at my message again I did correctly say 750,000
for the 1% false positive figure, although I did not type a comma to make it
easier to read.
True, but to a first approximation most of the 200,000 average passengers
per day in ATL will be unique individuals, so the false positive rate over
the entire population is a good indicator of the effect of deploying the
system in an airport. In any case, unless the individuals who repeatedly are
falsely matched against the database stop travelling, they would increase
the overall false postive rate by the same amount that repeat passengers who
are not falsely matched decrease the overall rate.
The more important number in these trials to ask about is the size of the
database. A 1% false positive rate on a large population matched against a
database of 5 faces is much worse than the same rate against a database of
500000. The article mentioned a watch list size of 3000, which seems like a
reasonable size for comparison, but the article implies that there were
different trials conducted for the study. Without referring to the original
report I can't tell if the 1% FP rate was based on that trial or one with a
different size database.
Taking into account the imprecision inherent in a news article reporting on
a large study, all it is safe to say is that when it says "only one subject
in a 100" the article is saying "only" while presenting a really horrific
scenario for the airport security people if this system is used to screen
all the passengers.
 -- sidney

@_date: 2003-03-29 10:49:59
@_author: Sidney Markowitz 
@_subject: Run a remailer, go to jail? 
The Massachusetts law defines as a crime:
(b) Offense defined.--Any person commits an offense if he knowingly
(1) possesses, uses, manufactures, develops, assembles, distributes,
transfers, imports into this state, licenses, leases, sells or offers,
promotes or advertises for sale, use or distribution any communication
[ ... ] or;
(ii) to conceal or to assist another to conceal from any communication
service provider, or from any lawful authority, the existence or place of
origin or destination of any communication;
(5)  Assist others in committing any of the acts prohibited by this section.
And it also says under civil actions:
(1) Any person aggrieved by a violation of this section may bring a civil
action in any court of competent jurisdiction.  "Any person aggrieved" shall
include any communication service provider
   --------------
This does seem broad enough to be used in situations other than outright
fraud against an ISP or communications company. There is language about
"intent to defraud" in Section 1 but the language in Section 2 (b)(1) about
possession, use, manufacture, etc., would seem to have the same kind of
broadness we have seen misused in the DMCA, covering people who sell NAT and
encryption tools that might be used by someone who sends email while
attempting to defraud a communications service provider.
 -- sidney markowitz
     sidney at sidney.com

@_date: 2003-11-14 15:33:50
@_author: Sidney Markowitz 
@_subject: Are there... 
How is that different from any asymmetric encryption algorithm where you throw away half of the keypair after you generate it?
  -- sidney

@_date: 2003-11-18 20:48:24
@_author: Sidney Markowitz 
@_subject: Are there...one-way encryption algorithms 
If you quantify the "practically negligible" risk, it might be less irksome: SHA-1 is a 160 bit hash. The birthday paradox says that you would need to hash 2^80 different credit card numbers before you had a 50% probability of having even one collision in your database keys. Very roughly that means you would need to have a trillion different credit card numbers in your database in order to get as much as a one in a trillion chance of a collision. You would probably find dealing with a trillion different credit card numbers more irksome than the negligible chance of a collision even that many would give you.
  -- sidney

@_date: 2003-11-27 14:13:18
@_author: Sidney Markowitz 
@_subject: Open Source Embedded SSL - Export Questions 
As a separate issue from whether you want to implement AES, if you do decide to implement it look at Brian Gladman's code at It is the fastest free implementation of AES that I know of, and has a good history and credentials behind it as you can see from the background information linked from that web page.
  -- sidney

@_date: 2004-12-09 07:34:31
@_author: Sidney Markowitz 
@_subject: 3DES performance 
Note that AES is significantly faster than 3DES. The slow speed of 3DES was at least one of the motivations for soliciting a new algorithm to be selected for AES.
try 'openssl speed des-ede3 aes' for a comparison.
  -- sidney

@_date: 2004-12-16 05:58:44
@_author: Sidney Markowitz 
@_subject: The Pointlessness of the MD5 'attacks' 
This isn't worked out enough to be a proof of concept, but I can imagine a piece of code that has a comment "This can't overflow because value X computed from the magic bits table will always be between A and B. Get 0.1% speed boost by leaving out range check here but don't change magic That doesn't even have to be so obscure. It provides a place to introduce a security hole that will not be noticed by substituting a new magic bits table without the protective property. Unless someone takes their copy of the source code that has MD5 equal to the MD5 of the sources that have been reviewed by the experts and verifies for themselves whether their magic bits table does compute a value X between A and B, they are vulnerable. If MD5 is trusted, there is no reason to audit every downloaded copy of the source code like that, as long as you are sure that someone has done the audit.
  -- sidney

@_date: 2004-01-03 12:41:53
@_author: Sidney Markowitz 
@_subject: [OT] Encryption 
Does the US have any import restrictions on crypto? I thought there were only export restrictions?
  -- sidney
[Moderator's note: that's one -- but only one -- of the reasons I
think Bob found the exchange so funny. --Perry]

@_date: 2004-01-03 20:54:49
@_author: Sidney Markowitz 
@_subject: [OT] Encryption 
Ah, I thought he was being honest but naive and couldn't understand how he could apply for "clearance" from the US for an import.
I looked at the rest of the thread in their mailing list archive and see where he has claimed to be able to crack any AES-128 encrypted document in 20 minutes and that he has references to the current scientific literature showing that such times are well known state of the art. He says he will demonstrate decrypting a document one of the list members sent him and post the literature references when he is back in his office during the week.
If I had read that first I would not have wondered about the US import restrictions :-)
  -- sidney

@_date: 2005-08-12 14:22:15
@_author: Sidney Markowitz 
@_subject: Motorist wins case after maths whizzes break speed camera code 
Looking at the article and the links that were posted here,
1. It appears that the defense won only because the prosecution did not come
up with an expert to refute the defense expert. He could have argued based
on Goedel's Theorem or the Heisenberg Uncertainty Principle and the case
would have gone the same way.
2. "The NRMA has called for a full audit of the way the state's 110
enforcement cameras are used ..." Note that NRMA is a motorist association,
like the AAA in the US. This is not a government body nor anyone with
authority calling for an audit.
3. The expert may not have outright lied by saying that the MD5 collision
result "theoretically" means that RTA could change the speed without
changing the hash, but his definition of "theoretically" has to include
"leaving it in the realm of theory by not trying to think the problem
through". This is not a situation where you can throw some random looking
bits in to make the hash come out right. Actually reading the article again
I don't see it made explicit that the person quoted was the expert used by
the defense or if he is just someone the reporter went to for a comment on
the story. For all we know the defense lawyer made the claim that "People
have shown it [MD5] has been hacked and it's open to viruses," and without a
prosecution rebuttal that was enough.
4. The marketing speak that Aram linked to is not all that bad for marketing
people making a hash of technical jargon they have been given. My assumption
is that they sign the time, date, place, numberplate and speed record using
RSA/MD5. Trying to explain that to a non-techie and they will hear the words
public key, encryption, and MD5 hash, so it is not unreasonable for them to
write "public key authenticated using MD5 encryption to ensure information
is authentic and tamper free".
5. Back to point  the attack on MD5 doesn't seem to cast doubt on the
signed data from the speed camera, as long as one can trust that the private
key is safely hidden in the camera. As Aram pointed out it is easy to show
that no possible speed, time and date will hash with the same numberplate to
get the same value.
 -- Sidney Markowitz

@_date: 2005-12-04 03:41:54
@_author: Sidney Markowitz 
@_subject: Fermat's primality test vs. Miller-Rabin 
I haven't thought through why it would produce non-primes, but it
doesn't seem to do what you want. That produces a 512 bit
twos-complement number, which gives you a 511 bit positive integer, not
512 bit. It also is unnecessarily complicated compared to this form of
the BigInteger constructor and the or method (see the javadoc):
curNum = BigInteger.ONE.or(new BigInteger(512, rand));
 -- Sidney Markowitz

@_date: 2005-12-05 15:01:42
@_author: Sidney Markowitz 
@_subject: Fermat's primality test vs. Miller-Rabin 
That doesn't make sense, unless I'm misinterpreting what you are saying. Primes
aren't that common, are they?
I don't have time right now to look for a bug in your code, but you could add a
sanity check that would catch a bug immediately by adding in the appropriate
spot a test like
 if (!curnum.isProbablePrime(128))
   System.out.println("Something wrong, number is not really a prime!");
to check that your primality test gets the same result as the M-R primality
test that comes with BigInteger.
 -- sidney

@_date: 2005-12-06 08:08:06
@_author: Sidney Markowitz 
@_subject: Fermat's primality test vs. Miller-Rabin 
Ok, I did misunderstand you. If that "failed 120-130 times" is talking about
the number of trials between primes, then you are getting within the range of
expected results.
According to the prime number theorem, the probability of selecting a prime
number at random from odd numbers is about 2/ln(n) which for a 512 bit number
is about 1 in 177, which means you have about a 50% chance of 120 tries before
finding a prime.
According to the results that Anton quoted there is a 2^56 chance that a 512
bit odd number that passes one round of Miller-Rabin is actually prime.
So all of your results do make sense.
 -- sidney

@_date: 2005-12-19 12:16:06
@_author: Sidney Markowitz 
@_subject: browser vendors and CAs agreeing on high-assurance certificat 
Do you mean like Amazon Marketplace and Amazon zShops? I think it's been
done already:
 -- Sidney Markowitz

@_date: 2005-12-28 12:57:29
@_author: Sidney Markowitz 
@_subject: crypto for the average programmer 
One set of comparisons of OpenSSL 0.9.7d and GMP RSA speed from last March was
posted on the GMP discussion mailing list by the GMP developer at
The less than surprising result is that if one of the packages has optimized
assembler language Bignum routines for a platform and the other doesn't, then
the package with the assembler routines is faster.
A few years ago I found that it was not worth the overhead of a JNI call to
have a Java program call out to the OpenSSL library instead of using the java
BigNum class which is written in Java. At the time I thought I was testing the
effect of JNI overhead, assuming that the C implementation of BigNum in OpenSSL
was of course much faster than one in Java.
I revisited the question sometime in the last six months and was surprised to
find that the JNI calls to OpenSSL were now much faster. It was not a matter of
JNI overhead being large, but that OpenSSL bignum arithmetic had been slow.
Looking into it I found some discussion of how GMP bignum was much faster than
OpenSSL and subsequent revision of the OpenSSL code on the x86 platform. I'm
pretty sure I did these later tests with a newer version of OpenSSL than 0.9.7d
and the x86 performance was about equal to that of GMP, as opposed to GMP being
2.5 to 3 times faster in the March tests.
Recently OpenSSL added a GMP engine to allow GMP to be used for Bignum
arithmetic on platforms where GMP is faster than the OpenSSL library.
Based on the final sentence of the posting to gmp-discuss linked to above, I
would predict that there will continue to be a version race between the two
packages until they both reach some limit of performance, at least on platforms
 on which the OpenSSL developers want to maintain parity, letting the other
platforms be serviced by the GMP engine.
Another small thread about this in an OpenSSL mailing list:
 -- Sidney Markowitz

@_date: 2005-02-18 05:55:09
@_author: Sidney Markowitz 
@_subject: Digital Water Marks Thieves 
And other people complain about how someone can spray their paint on
someone else's valuable and then call the police.
These arguments remind me of Peter Gutmann's recent post to the list
about "good enough" security... You can make the same arguments about
the DNA signature in blood. A civilian can analyze it. It is conceivable
that someone can get a sample of someone else's blood or other
biological sample and frame them by leaving DNA evidence somewhere. That
does not make DNA analysis useless as a tool in forensics.
So now there is a way of marking items that cannot be engraved and a way
of marking intruders. It sounds more sophisticated than a red dye bomb
in a sack of cash stored in a bank vault -- which also has its uses and
its drawbacks. Now it will be easier to tie the dyed material and the
dyed thieves to the specific crime. It is not a big deal that it does
not solve all problems in one stroke.
 -- sidney markowitz

@_date: 2005-07-02 09:06:46
@_author: Sidney Markowitz 
@_subject: /dev/random is probably not 
This is not a new or unconsidered problem. Disk caching has always been a
factor in disk I/O. /dev/random uses multiple sources of entropy. The idea
is that some of the sources being deterministic does not diminish the
entropy that comes from good sources, so all can be mixed in. And if your
system does not have any good source of entropy, then you need to add one.
See a discussion back in 2001 on linux-kernel mailing list for example:
 -- Sidney Markowitz

@_date: 2005-10-13 09:14:38
@_author: Sidney Markowitz 
@_subject: US Banks: Training the next generation of phishing victims 
I don't understand how big companies can be willing to send their
customers through multilayer telephone menu hell just to be put on hold
for 20 minutes, but think that it is unacceptable to have to click a
"Secure Online Banking" button on the home page before entering their id
and password. As you have pointed out, the latter seems to be the
standard for banks outside the US, and I'm sure it works for them.
It looks like they are all getting their web sites from the same
Hack-In-A-Box. I just checked out my credit union in the US that used to
be an example of doing things right so I could say something nice about
them here, but it appears that their online management have also been
replaced by the same pod people since I last had a reason to do online
transactions with them.
When I entered the  URL that I'm familiar with, the
first thing that happened was an immediate and invisible redirect to
 Ok, maybe they finally bought that domain and
decided to standardize on it. The behavior I remember it having a couple
of years ago was an immediate redirect to There on the home page is a form to enter my member number and password
and a login button. Next to it is a turquoise padlock icon labeled
"security advisory". The word "advisory" led to me to think, "Aha,
they've succumbed to the dark side under management pressure, but at
least they are going to warn me that this is not really secure and if I
want to prevent any phishing attack I should do something like click on
the login button without entering my information, then actually enter on
the secured site".
Nope. Hovering the mouse over the icon tells me that they secure their
transactions using 128-bit SSL and I can get more information by
clicking on the icon. Clicking it brings up a page saying... Yes, the
same pod people wrote their web site:
"Online Security Policy
You may notice when you are on our public web site that some familiar
indicators do not appear in your browser to confirm the entire page is
secure. These indicators include the small "padlock" icon in your
browser's status area and the "https" prefix in the Address bar. To
provide all of our users with the fastest and most responsive possible
access to our web site, we have chosen to make the process of signing in
to Online Banking secure without unnecessarily securing any additional
pages on the public web site. Again, please be assured that your member
number, password and other information are secure, and that Bay Federal
alone has access to them: only public, non-sensitive web pages will
remain unsecured, while any page that collects or reveals your sensitive
personal information will continue to be handled with the strictest
available security measures."
Hmm, one difference from the BoA and Wachovia examples is that this is
under the heading "Security Policy". It can be argued that their
unsecured home page, which collects a member number and password,
violates the portion of the policy that says "only public, non-sensitive
web pages will remain unsecured, while any page that collects or reveals
your sensitive personal information will continue to be handled with the
strictest available security measures".
By the way, it does get worse.  gives me a warning
about a certificate that expired over a year ago, then when I accept it
redirects me to the unsecured  Clicking on the
login button on the home page without entering my ID and password does
not take me to a secured page that gives me a chance to log in securely

@_date: 2005-10-14 16:37:11
@_author: Sidney Markowitz 
@_subject: NSA Suite B Cryptography 
Excerpt from
"NSA has determined that beyond the 1024-bit public key cryptography in
common use today, rather than increase key sizes beyond 1024-bits, a
switch to elliptic curve technology is warranted. In order to facilitate
adoption of Suite B by industry, NSA has licensed the rights to 26
patents held by Certicom Inc. covering a variety of elliptic curve
technology. Under the license, NSA has a right to sublicense vendors
building equipment or components in support of US national security
Does this prevent free software interoperability with Suite B standards?
It potentially could be used to block non-US vendors, certainly anyone
who is in the US Government's disfavor, but it seems to me that even
with no further intentional action by the NSA it would preclude software
under the GPL and maybe FOSS in general in countries in which the
patents are valid.
 -- Sidney Markowitz

@_date: 2005-10-15 09:38:59
@_author: Sidney Markowitz 
@_subject: NSA Suite B Cryptography 
Because the NSA's assurances that their license would cover open source
software is probably good enough to allow you to write and contribute
code to a non-GPL open source project if they do not have specific rules
against accepting patent-encumbered code, but the GPL has these two
sections regarding patents. I interpret them as meaning that the only
patent restriction there may be on GPL'd code is that it may not be
distributed in certain countries, but _any_ other restriction makes the
code not distributable under GPL.
[begin quote]
7.  If, as a consequence of a court judgment or allegation of patent
infringement or for any other reason (not limited to patent issues),
conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License. If you cannot distribute
so as to satisfy simultaneously your obligations under this License and
any other pertinent obligations, then as a consequence you may not
distribute the Program at all. For example, if a patent license would
not permit royalty-free redistribution of the Program by all those who
receive copies directly or indirectly through you, then the only way you
could satisfy both it and this License would be to refrain entirely from
distribution of the Program.
If any portion of this section is held invalid or unenforceable under
any particular circumstance, the balance of the section is intended to
apply and the section as a whole is intended to apply in other
It is not the purpose of this section to induce you to infringe any
patents or other property right claims or to contest validity of any
such claims; this section has the sole purpose of protecting the
integrity of the free software distribution system, which is implemented
by public license practices. Many people have made generous
contributions to the wide range of software distributed through that
system in reliance on consistent application of that system; it is up to
the author/donor to decide if he or she is willing to distribute
software through any other system and a licensee cannot impose that choice.
This section is intended to make thoroughly clear what is believed to be
a consequence of the rest of this License.
8. If the distribution and/or use of the Program is restricted in
certain countries either by patents or by copyrighted interfaces, the
original copyright holder who places the Program under this License may
add an explicit geographical distribution limitation excluding those
countries, so that distribution is permitted only in or among countries
not thus excluded. In such case, this License incorporates the
limitation as if written in the body of this License.
[end quote]
 -- Sidney Markowitz

@_date: 2005-10-15 10:37:01
@_author: Sidney Markowitz 
@_subject: NSA Suite B Cryptography 
If you wrote a Suite B program and distributed it under a BSD license
after getting a sub-license for the patent from the NSA, presumably I
could take that code, modify it, and then in order to use or distribute
 my modified code I would have to obtain my own sublicense from the NSA.
I could do that as long as I met whatever criteria the NSA has for
granting sublicenses. My guess is that at a minimum the program would
have to be available for free or for sale to the US government for some
purpose that allows it to be considered as being "in support of US
national security interests."
It would make no sense for the NSA to grant a sublicense to you that
allowed to you grant me a license to produce possibly proprietary code
that infringes the patent and is not in support of US national security
So, yes, under those assumptions BSD-like licenses would not be
excluded, with the understanding that in addition to the copyright terms
allowing free use of the code there would also be patent restrictions
affecting the use.
As you say, the NSA's solution to their problem has nothing to do with
FOSS, and it doesn't specifically exclude FOSS. But it will preclude GPL
software that will interoperate with Suite B from being distributed in
countries that recognize the patents.
Unless, I suppose the NSA is able to say that any use of the patent in
open source software can be considered "in support of US national
security interests" and therefore the sublicense can be propagated as
long as the source remains available. In other words, if they include a
GPL-like provision that the patent license will stay with the code as
long as it is distributed under GPL. That would be an interesting twist.
 -- Sidney Markowitz

@_date: 2005-10-15 19:52:56
@_author: Sidney Markowitz 
@_subject: NSA Suite B Cryptography 
Poor phrasing on my part. Exactly as you said, the patent sublicense
cannot be passed on even if the code is released under, say a BSD
copyright license. People would have a right to copy the source code but
would have to obtain patent rights either from the NSA if they are
eligible, or as you said under alternative arrangements from Certicom.
Since the GPL excludes distribution of code with patents that limit
their distribution other than by specific country, the patent
encumbrance that would accompany the code would prevent it from being
released under GPL.
The possible twist that I see is if the NSA declares that any freely
available open source software that interoperates with Suite B is by
definition "in support of US national security interests" and therefore
automatically gets one of their sublicenses. That would effectively
remove the patent encumbrance for GPL code. There would still be patent
restrictions on the code, but they would not apply to open source freely
redistributable code, therefore would not get in the way of the GPL.
Oh, no, that would not be strictly true. GPL allows you to do anything
at all with the code if you use it for yourself without distributing it.
Patent restrictions still apply to such uses. They could be uses that
are not "in support of US national security interests". Therefore you
still could not distribute the code under GPL as the people you give it
to would not have the patent rights to modify the code for their own
private modified use if they do not distribute the changes.
So it still comes down to what I think is the important point: BSD
licensed Suite B code may be possible, GPL'd Suite B code is not
possible unless Certicom makes appropriate free license to the patents
available for software licensed under GPL.
 -- Sidney Markowitz

@_date: 2005-09-04 01:00:15
@_author: Sidney Markowitz 
@_subject: AES implementation in C - any recommendations? 
Brian Gladman's code is the fastest free version I know of, is widely used,
and has a BSD-like license.

@_date: 2005-09-12 10:33:59
@_author: Sidney Markowitz 
@_subject: Clearing sensitive in-memory data in perl 
Does anyone know of an open source crypto package written in perl that is careful to try to clear sensitive data structures before they are released to the garbage collector?
Failing that, does anyone know of an example that tries to deal with the particularly bad effect that at least on some perl platforms writing to a tied DB_File results in data from garbage collected strings appearing in the unused space between the logical end of file and the end of the allocated disk block?
And failing that, how about a reference to how one would go about preventing leaking sensitive information in garbage collected strings when writing in perl. Google and reading perl documentation hasn't helped me so far, but I find it hard to believe that this has not been considered when writing crypto software in perl.
  Sidney Markowitz

@_date: 2005-09-18 09:25:54
@_author: Sidney Markowitz 
@_subject: European country forbids its citizens from smiling for passport 
New Zealand did this earlier this year, as part of giving in to pressure from the US to have passports with biometric information.
Here is a press release of last June from the NZ Green Party's Human Rights spokesperson. A quote from it "Most people arriving in our fair land have smiles on their faces and there is nothing wrong with having passport photos to match"
  -- Sidney Markowitz

@_date: 2006-02-05 08:34:25
@_author: Sidney Markowitz 
@_subject: serious threat models 
There is more information in Bruce Scheier's blog entry and his links to blog
and news articles. It hit slashdot yesterday:
According to those reports, the attack involved modifying (configuring?)
software on a Vodafone switch to cause all calls to/from some 100 mobile phone
numbers to be conference calls with some prepaid mobile numbers that recorded
the conversations.
 Sidney Markowitz

@_date: 2006-02-09 13:07:33
@_author: Sidney Markowitz 
@_subject: general defensive crypto coding principles 
Schneier deals with that explicitly when he makes the suggestion, on pp 115-117
in Practical Cryptography, referring to "theoretical results" rather than
referencing Krawczyk's paper directly.
Krawczyk's paper shows that authenticate before encryption is not secure under
assumptions that are not realistic, such as the encryption being subject to a
chosen ciphertext attack, use of ECB mode, separate MAC authentication of each
block along with an encryption oracle so you can use a kind of block level
replay attack in CBC mode. If you use a good cipher with an appropriate mode
and apply the authentication to the entire message with proper use of message
ID or timestamp to prevent replay attacks, you avoid Krawczyk's vulnerabilities
four times over.
Schneier deals with the argument about potential DoS attacks by pointing out
that most real-life DoS attacks saturate the communication channel, not the CPU.
He also presents arguments for authenticating before encrypting which I won't
repeat here -- It's all there in a pretty clear three pages in his book.
 -- Sidney Markowitz

@_date: 2006-01-04 09:37:30
@_author: Sidney Markowitz 
@_subject: RNG quality verification 
Try this:
Generate 256000 bytes from MD5(i), i=1...16000 and run the same tests. That is
clearly not acceptable as a PRNG because it is completely predictable if you
know that the sequence is MD5(1) ... MD5(16000), but it should pass any tests
other than one that checks specifically if it is correlated to MD5(1) ...
Perhaps you would say that example is unfair because MD5 makes a perfectly good
PRNG as long as the software package seeds it properly. In that case, how are
you going to ensure that the package you are testing is seeding the PRNG properly?
In fact, the famous Netscape vulnerability was based on a PRNG that was simply
MD5 of a counter, with the vulnerability being predictability of the seed. See
 for a clear
description of that.
Your tests would not detect that kind of vulnerability.
You asked,
The point is that your tests will not detect the difference between a PRNG
using a properly seeded MD5(counter) and one with a predictable seed. More
generally, a sequence can be predictable while still being statistically random.
Carrying it even further, back in 1996 the only problem with using MD5 of a
counter as a PRNG was making sure that the seed was unpredictable. That may not
be true anymore because of recent results of MD5 collisions, or more
accurately, it may not remain true if stronger attacks continue to be found.
Statistical tests have not all of a sudden changed their results: MD5 will not
appear any less random in those tests just because vulnerabilities are found.
So how do you certify PRNGs used by your customers? You have them use well
known software packages that have been analyzed and vetted by the cryptographic
community, such as OpenSSL. It would be a shock if any of them did not pass the
simple statistical tests that you can perform. Passing those tests does not
ensure that there are none of the more subtle vulnerabilities that are only
discovered by many smart people taking a very hard look over a significant time
 -- Sidney Markowitz

@_date: 2007-04-20 08:56:32
@_author: Sidney Markowitz 
@_subject: AES128-CBC Question 
Here is some discussion about doing this, in the context of PGP doing
just that and why PGP inserts random characters at the begining of the
 It points out that a fixed IV results in information leakage if the
first block or more of plaintext is the same in two messages encrypted
with the same key.
 Sidney Markowitz

@_date: 2007-04-30 08:25:47
@_author: Sidney Markowitz 
@_subject: Cryptome cut off by NTT/Verio 
Cryptome.org has not been shut down yet (the notice from Verio dated 28
April says they were being given two weeks to find another provider).
They seem to have been slashdotted.
The shutdown notice page is not yet archivd at archive.org, but is
mirrored on a responsive site, mirror.org:
Here's a comment by John Young in the slashdot thread:
It links to a page on cryptome.org, which of course is unavailable
during the slashdotting but is in the archive.org archives:

@_date: 2008-01-01 09:32:52
@_author: Sidney Markowitz 
@_subject: Question on export issues 
I find that very strange considering this from a BIS FAQ
"all encryption source code that would be considered publicly available under Section
734.3(b)(3) of the EAR (such as source code posted to the Internet) and the corresponding
object code may be exported and reexported under License Exception TSU -- Technology and
Software Unrestricted (specifically, Section 740.13(e) of the EAR), once notification (or
a copy of the source code) is provided to BIS and the ENC Encryption Request Coordinator."
What hoops did you have to jump through?

@_date: 2007-05-03 05:54:49
@_author: Sidney Markowitz 
@_subject: 128 bit number T-shirt? 
My thoughts too. This one looks much better, but I don't see a link
anywhere to get it. Perhaps the author just photoshopped the picture as
a proof of concept to go with his blog comment?
 -- sidney

@_date: 2007-05-04 09:53:19
@_author: Sidney Markowitz 
@_subject: Yet a deeper crack in the AACS 
Article "AACS cracks cannot be revoked, says hacker"
Excerpt: "The latest attack vector bypasses the encryption performed
by the Device Keys -- the same keys that were revoked by the WinDVD
update -- and the so-called 'Host Private Key,' which as yet has not
been found. This was accomplished by de-soldering the HD DVD drive's
firmware chip, reading its contents, and then patching it. Once that
was done, the firmware was soldered back onto the drive."

@_date: 2007-05-18 13:31:22
@_author: Sidney Markowitz 
@_subject: Latest AACS key cracked a week before release 
Ars Technica reports that a new volume key which has been issued to
replace the one that was cracked earlier this month and which is being
used in DVDs to be released for sale next week has been cracked using a
beta version of SlySoft's AnyDVD HD program and early release previews
of The Matrix trilogy.
Here's the article
This is the same link in preview tinyurl form:
I know that there is nothing technologically new or interesting about
this crack, but it does add a certain emphasis to the arguments for the
futility of DRM, seeing systems cracked before they are released. What
does it do to Ed Felten's model when C drops below 0? (reference Hal
Finney's post to this list about two weeks ago
 -- Sidney Markowitz

@_date: 2007-11-09 08:41:35
@_author: Sidney Markowitz 
@_subject: Hushmail CTO interviewed (Re: Hushmail in U.S. v. Tyler Stumbo) 
There's an informative article in a Wired blog in which Hushmail CTO
Brian Smith provides some information that hints at what happened in
this case, although he would not speak specifically about the case.
See His implication is that the target was using their simplified version of
Hushmail that encrypts on the server, using an SSL connection to send
passphrase from the client to the server then providing an interface
similar to ordinary webmail. The court order may have required Hushmail
to save and hand over the password and/or the decrypted mail. Since
Brian Smith would not say exactly what happened in this case, we can't
tell if they modified the system to save the target's password the next
time they used it and handed that over along with historical stored
encrypted mail, or if the modification was to save unencrypted mail sent
after the court order was received, or something else I haven't thought
of. In any case, Smith said that Hushmail only complies with court
orders that target specific accounts and would not take any action that
would affect users not specifically targeted by a court order.
My reading of Smith's statements in interview is that Hushmail would be
subject to a court order requiring them to supply a hacked Java applet
to someone who is using their Java based client-side encryption. There
is no doubt that would be technically feasible, it is mentioned  and
would fall within the guidelines for court orders that Smith said that
Hushmail would comply with.

@_date: 2007-09-21 08:24:04
@_author: Sidney Markowitz 
@_subject: Scare tactic? 
The "without i's knowledge" part is critical to the argument, as the
author is assuming that entity i is monitoring all of entity j's
channels of communication and either entity j has no communication of
any kind outside of that used for the DH protocol with entity i, or else
entity i would be able to recognize whether any other communication with
anyone is a revelation of the secret session key that entity i is
sharing with entity j.
Note that entity i would even have to be sure that entity j is not using
any side channels such as variations in the timing of response packets
during the subsequent encrypted session to communicate with a colluding
passive attacker who is eavesdropping.
That is an awfully impractical constraint on the threat model, which
makes this issue moot in practice.
 Sidney Markowitz

@_date: 2007-09-21 11:37:10
@_author: Sidney Markowitz 
@_subject: Scare tactic? 
Curse this non-standard notation! I of course meant "entity l"
everywhere I said "entity j" to keep with the original author's
nomenclature. Whatever happened to Alice, Bob, and Eve?
 -- Sidney Markowitz

@_date: 2008-08-24 14:14:25
@_author: Sidney Markowitz 
@_subject: 5x speedup for AES using SSE5? 
A commenter on slashdot hinted at the vector permutation instructions, similar to those on Altivec, being useful:
Altivec is also known as VMX
That led me to this paper with a section on use of VMX vector operations in an AES implementation:
I didn't see performance comparisons or anything specific to SSE5, but it looks like the kind of thing that AMD might have meant.
  -- Sidney Markowitz

@_date: 2008-12-31 10:21:11
@_author: Sidney Markowitz 
@_subject: Security by asking the drunk whether he's drunk 
I should remember -- morning coffee first, then post.
The CA root certs themselves have not been cracked -- It is the digital
signatures created by some CAs who still use MD5 to sign the certs that
they issue that have been hacked: The known weakness in MD5 allows one
to create two certs with the same MD5 hash, one that is legitimate to
get signed by the CA, and another one for rogue use that can be given
the same signature.

@_date: 2008-01-07 08:23:34
@_author: Sidney Markowitz 
@_subject: Question on export issues 
That's the problem with using lawyers, they'll always give you a conservative cautious answer. Unfortunately for people who don't use them, sometimes those really are the correct, prudent answers. When I worked for a company that had to face this we acted according to what looked like the plain language documentation from the BIS, concluding that use of an existing open source package required just sending an email. We were never as high profile as OLPC and in fact never ended up exporting anything, so our interpretation of the laws was not only not made by qualified legal counsel, it also was never tested.
I do look forwrd to seeing what you discover were the considerations that your outide counsel had.
  -- sidney

@_date: 2008-01-23 18:51:08
@_author: Sidney Markowitz 
@_subject: SSL/TLS and port 587 
I would like to see some facts to support the assertion that the "idea that SSL/TLS and port 587 are somehow able to prevent warrantless wiretapping" is "often expressed".
A Google search for
  ssl "port 587" warrantless wiretapping
got exactly one hit, which was your posting to the mailing list where it had been archived on security-basic.blogspot.com and snarfed up by Google within the hour.
(As an aside, see "Google Taking Blog Comments Searching Real-Time?"  for a discussion of this remarkable update to their search engine).
  Sidney Markowitz

@_date: 2008-07-10 13:32:03
@_author: Sidney Markowitz 
@_subject: Kaminsky finds DNS exploit 
He's posted a quite long article on his blog
  that looks like all the details he is likely to provide for the next 30 days. It does seem to address the speculation on this list about how the patch relates to stuff that has been known for years, Dan Bernstein's code, who knew what when, etc.
   -- sidney

@_date: 2008-09-07 02:39:34
@_author: Sidney Markowitz 
@_subject: Quiet in the list... 
As far as I recall, the last time Thunderbird had an upgrade it told me that one was available, I clicked to upgrade, and the addons, including Enigmail, continue to work. When there was an upgrade available to Enigmail, same thing. And the upgrade to GNUgpg also installed cleanly with no reconfiguration necessary. It has all been as transparent as can be.
My only problem with it is that I keep having this nagging feeling in the back of my mind that "set it and forget it" is not the best approach to security.
  -- sidney

@_date: 2014-06-01 16:46:05
@_author: Sidney Markowitz 
@_subject: [Cryptography] What is going on with TrueCrypt? 
ianG wrote, On 1/06/14 3:26 pm:
Here are the links for the previous two versions of license. Aside from any
other problems with the license, the Readme.txt files make no provision for
applying the Version 3.1 license that comes with TrueCrypt 7.2 to TrueCrypt
7.1a, which comes with the Version 3.0 license. The only difference between
them is that the license for 7.1a requires a link to get the original code
from truecrypt.org to appear in any documentation and in the splash-screen,
about box, etc. Does that mean a fork of 7.1a (7.2 removes all encrypt code)
has to contain an obsolete link to truecrypt.org?
The new version 3.1 license that is part of the last TrueCrypt 7.2 is here:
The version 3.0 license:
This might be a better way to phrase what I was trying to say, which has
nothing to do with "GPL-versus-the-world".
Reading the license I get the impression that the author intends to require
similar restrictions to the GPL with the additional restriction that nobody
make money from derived code (so no commercial derivatives or forks); that it
was not written by a lawyer and so may be full of unintended implications;
that the intended restrictions would prevent someone forking it if they want
their project to have a BSD type license; that the attempt to prevent for-fee
use and other perhaps sloppily written clauses would prevent someone who wants
to fork with added code under GPL from doing so. I'm left wondering if there
is a license that someone who wants to fork can reasonably use.
I intended to point out that there might be problems forking the project under
any license, with GPL being only the most obvious one with which there would
be a problem.
  Sidney Markowitz

@_date: 2014-06-02 13:08:10
@_author: Sidney Markowitz 
@_subject: [Cryptography] What is going on with TrueCrypt? 
ianG wrote, On 2/06/14 1:45 am:
Version 2.6 was the first (incomplete) response to the Red Hat criticisms.
This is version 2.5, which is the one that the Red Hat lawyers criticized:
I don't have a direct link to the text of license version 2.6, but all old
versions of TrueCrypt are archived at the following link so you can see any
license if you want by downloading and unpacking the distribution. The license
version history after 2.5 is
TrueCrypt version
* 6.1, 6.1a, 6.2: `TrueCrypt License Version 2.6`
* 6.2a: `TrueCrypt License Version 2.7`
* 6.3, 6.3a: `TrueCrypt License Version 2.8`
* 7.0, 7.0a, 7.1, 7.1a: `TrueCrypt License Version 3.0`
* 7.2: `TrueCrypt License Version 3.1`
Link to historical archives of TrueCrypt:
When I look at the license for some software, I want to know that I can use it
the way I want to without getting into any trouble with the vendor or author.
Whether it says that I would likely win a lawsuit is not nearly as relevant as
reassurance that the vendor is not going to be bothered by what I do enough to
come after me. When the license says "you may do this" that is a promise not
to sue that provides a high degree of reassurance if I want to "do this".
obCrypto: I consider writing your own license similar to writing your own
crypto. The field is too specialized, the twists and turns are too tricky. No
matter how much hobby time I've spent reading up about open source licenses I
would choose from amongst GNU GPL, BSD, Apache 2.0, etc. to select the one
most closely expressing what I want, not try to demonstrate my clever ability
to write exactly what I want. If I'm going to have the responsibility I'm not
going to have someone like me hack something custom together.
 Sidney Markowitz

@_date: 2014-06-03 06:45:26
@_author: Sidney Markowitz 
@_subject: [Cryptography] What is going on with TrueCrypt? 
Nemo wrote, On 3/06/14 6:11 am:
The result would not be able to be included in common Linux distributions
(which is the case with TrueCrypt already because of the deficiencies in the
license) and would likely not be used in business environments to the degree
that I have seen TrueCrypt being used.

@_date: 2014-06-03 16:40:19
@_author: Sidney Markowitz 
@_subject: [Cryptography] What is going on with TrueCrypt? 
The speculation in Bill Cole's comment linked below isn't nearly as
exciting/spooky/twisty as some others, but after reading is the one I find
most convincing:

@_date: 2014-06-08 15:45:23
@_author: Sidney Markowitz 
@_subject: [Cryptography] Help investigate cell phone snooping by police 
Bill Cox wrote, On 8/06/14 11:56 am:
Did Snowden say it was because a fridge is a Faraday cage or was that
explanation only from reporters discussing the meeting?
The test is easy and disproves the idea, as demonstrated in these two links:
A microwave oven is a better choice, as it is designed to function as a
Faraday cage.
However, might not the audio insulation and the hum of the refrigerator motor
when the phone is inside the refrigerator in another room be sufficient to
mask the conversation?
I did some Googling about that. According to Table 1 in
the approximate sound insulation of a modern refrigerator varies by frequency,
with the lowest amount in the voice frequency range being about 13dB. The
sound from the fan is about 30dB.
According to
normal conversational voice levels at a distance of 12 feet (3.7m) would be 48dB.
I'm not sure from the literature I've seen how much dB loss to allow for there
being a wall and closed door between the room the meeting is in and the
kitchen. Maybe 30dB for a typical non-insulated interior wall rated at STC 33?
I think that means that there could be up to 5dB of sound energy at the worst
frequencies making it to the inside of the refrigerator, and 30dB of hum from
the fan. If there are two walls, and/or at least 5m distance between the
meeting and the refrigerator that should be enough.
I don't know what would make me feel safer - putting the phones in a microwave
oven with the chance that the door could easily be left ajar, or getting the
acoustic insulation and masking hum of a refrigerator.
 Sidney Markowitz
 http:/sidney.com

@_date: 2014-05-04 11:12:05
@_author: Sidney Markowitz 
@_subject: [Cryptography] One third IT managers think homomorphic is 
Stephan Neuhaus wrote, On 3/05/14 10:06 pm:
Here is an article in infofworld about the same report. I haven't watched the
video clip linked in the beginning of this thread, but the description of the
report in this article does seem to match what Peter said:
"Only 39 percent of SaaS users and 26 percent of IaaS/PaaS users had data at
rest encrypted, and only 44 percent (SaaS)/40 percent (IaaS/PaaS) of those
users were encrypting data before sending it to the cloud. An unsurprisingly
strong correlation existed between a company's overall security posture (if
they subject to regulations, for example) and its use of encryption."
"Here, the consistency between the numbers for apps and at-rest encryption
hints at how the encryption profile across all types of companies is
consistent. In other words, the use of encryption may be more closely tied to
the type of company than the type of data."

@_date: 2014-06-01 13:08:19
@_author: Sidney Markowitz 
@_subject: [Cryptography] What is going on with TrueCrypt? 
Jerry Leichter wrote, On 1/06/14 8:41 am:
The license itself looks to me, a non-lawyer, like an unprofessional attempt
to write a basically free and open source license. It has clauses saying that
you can freely distribute TC and its source code. You can distribute modified
versions of TC and its source code as a standalone product or as part of your
won software as long as you meet certain conditions of making your own
modifications and combined software freely available in source, and include
certain notices and acknowledgments.
My non-lawyer take is that the license was written by a non-lawyer who did not
know how to make the license say what they meant to say, leaving a number of
ambiguities, loopholes, and clauses which would make it incompatible with GPL.
Here is a link to a summary of Red Hat's legal people's reasons why they could
not make use of TC with the TC license. It doesn't list all of the flaws, only
the main ones that make it so there is no reason to list more minor ones that
would still by themselves be enough to block its use:
"TrueCrypt licensing concern"
As a non-lawyer comparing the way the TC license expresses concepts to the way
they appear in GPL and the way FSF talks about license compatibility in their
FAQ, my immediate reactions were 1) The way they express requirements for
acknowledgment might have the same incompatibility with the GPL as the
advertising clause in the original BSD license; 2) The remaining clauses read
to me as if the author intended to provide restrictions equivalent to those in
the GPL with the addition of preventing anyone from charging money; 3) The
writing of the license by a non-lawyer in this case resulted in something that
can't really be trusted to actually say what the author intended to say.
 Sidney Markowitz

@_date: 2014-06-01 14:28:44
@_author: Sidney Markowitz 
@_subject: [Cryptography] What is going on with TrueCrypt? 
Sidney Markowitz wrote, On 1/06/14 1:08 pm:
That link I provided discussed TrueCrypt License Version 2.5 and is a bit out
if date. Version 2.6 of the license addressed some (but not all?) of Red Hat's
concerns, the latest version before this recent change was Version 3.0, and
with the recent announcement the license was change to Version 3.1
The TLDR; of the license is that you can modify and distribute their code as
long as your changes and your program that includes their code is freely
source distributable. That would make it FLOSS except for the likely devils in
the details.
What I haven't seen is something that says that the new Version 3.1 license
can be used for the TrueCrypt 7.1.a source code, which is the version that a
fork would have to be based on. Has anyone noticed a reference to a statement
that would allow that?
A diff between the two license versions shows that the only change between 3.0
and 3.1 is the removal of the requirement to acknowledge TrueCrypt, which is
the clause that I thought might be similar to the advertising clause in the
original BSD license that is incompatible with GPL.
The new version 3.1 license that is part of the last TrueCrypt 7.2 is here:
The version 3.0 license:
Version 3.0 and 3.1 still contain a clause that requires your code to be
distributed at no fee or for your reasonable copying costs. As I understand it
that is incompatible with GPL which allows you to charge anything you want
while not preventing anyone else from giving away free copies of what you are
selling. Economically that may not be very different, but it could prevent you
from distributing a fork under GPL.
 Sidney Markowitz

@_date: 2016-08-06 18:59:26
@_author: Sidney Markowitz 
@_subject: [Cryptography] Generating random values in a particular range 
That patent link says that it has a priority date of Dec 27, 2000 (with a
disclaimer that Google has not performed a legal analysis to come up with that
The Gnu GMP library version 3.0.1 source code at tarball  date stamped 2000-04-07
in file gmp-3.0.1/mpz/urandomm.c uses that algorithm for function mpz_urandomm
Later versions of GMP have the improvement of iterating a maximum number of
times then return the value mod n if it doesn't get a result less than n by
then, but that improvement does not appear in the patent claims.
 Sidney Markowitz

@_date: 2016-08-07 04:09:01
@_author: Sidney Markowitz 
@_subject: [Cryptography] Generating random values in a particular range 
Oh, right, the patent is actually about taking the output of the RNG which
might be fewer bits than the length of the number you want when generating a
key and hashing it to get the right bit length. Like for example when
generating a RSA key you can take so many random bits and hash them to a
longer bit string of fixed length L that you then test for primality. If
before you do the primality test you first reject the hash result if as an
integer it is greater than some particular L-bit length prime, then you have
done what the claims of the patent say.
The patent is not about generating a uniform random variable in a range.
What that means is that if you do what we are talking about here, generate a
uniform random integer between 0 and N by rejecting any output of the
underlying PRNG that is larger than N, then it has nothing to do with this patent.
Now I'm curious. Do the primality tests that are usually used for generating a
prime of some fixed length L for a key that needs a large prime such as RSA
make use of some specific L-bit prime that the result must be less than? Or
will any L bit random number be run through the same primality test? Because
if all you do is hash some 256 bit random number to get 2048 bits that contain
256 bits of entropy and then test it for primality without as a first step
checking if the 2048 bit number is too large, you have not practiced the
claims of this patent. So is this patent obvious or is it useless?
 Sidney

@_date: 2016-08-07 05:53:50
@_author: Sidney Markowitz 
@_subject: [Cryptography] Generating random values in a particular range 
I read the description part of the patent which provides some context for how
it came about.
This has to do with a vulnerability in the DSA implementation standard that
was discovered by Daniel Bleichenbacher and announced in November 2000. FIPS
186-2 described generating a 160-bit prime less than some specific 160-bit
prime p by taking the SHA-1 hash of a larger random number (I got it backwards
when I was speculating in my last email) mod p. Bleichenbacher showed an
attack based on the non-uniformity of that result. This was fixed in FIPS
186-2 Change Notice 1, which was later superseded by FIPS 186-4. The original
approach to fixing the problem involved two hashes. Someone people apparently
managed to file for a patent on the idea of doing one hash and discarding
results that were too big before NIST published the change notice with that
In FIPS 186-4 NIST presents two methods for fixing the problem, I presume
because the second method they list is encumbered by the patent. Their first
method is to get a random bit string of length L+64 and then take that mod the
L bit prime. The idea is that the extra 64 bits before the mod results in
enough uniformity.
FIPS 186-4, unlike FIPS 186-2, does not specify how the random bits are
generated. One way would be to apply a hash that has the requested bit length
output to the output of a PRNG that has the right number of bits of entropy
for the desired security strength. That would make the second method be
impacted by the patent.
 Sidney

@_date: 2016-08-07 14:09:15
@_author: Sidney Markowitz 
@_subject: [Cryptography] Generating random values in a particular range 
Looking at it more, this looks like a submarine patent originally filed by
Certicom soon after Bleichenbacher announced the vulnerability, aimed at
catching out anyone using their obvious fix that ended up in common
implementations of DSA. FIPS 186 says "The algorithms in the Standard may be
covered by U.S. or foreign patents" but doesn't call out anything specific.
I just did a quick check of source code for DSA parameter generation in
OpenSSL and at least in the version I glanced at they seem to use the second
method that is specified in FIPS 186-4, which is the variation on the first
fix for Bleichenbacher's vulnerability that was specified in FIPS 186-2 Change
Notice 1. This was in
 where the first
step in checking for primality is to check if the random number (which is the
hash of the output of a PRNG) is greater than p. The call to it in
dsa/dsa_gen.c does loop until the primality test returns true, and so does
what the patent claims describe.
This means that it is irrelevant that there are prior examples of rejection
sampling. This is not a patent on rejection sampling. It is a patent on using
rejection sampling to eliminate the bias when generating a series of candidate
random numbers between 0 and L-bit prime p by getting an initial random number
(the seed) from a PRNG, hashing it to get a number of length L, rejecting it
if it is greater than p before checking it for primality, then if it is
rejected doing any transformation of the seed including simply incr4menting
it, hashing that new value, and trying again.
Challenging this patent would probably involve trying to convince the PTO or
the courts and/or a jury that once you know that the problem is that a simple
mod p introduces bias, the solution is obvious to anyone who has any expertise
in random number generation that you can solve the problem by using rejection
sampling in this way. Considering that the original algorithm was "1) take
H(seed) mod p to ensure a value less than p; 2) check if it is prime; 3) if it
isn't prime, increment or otherwise get a new seed to hash and loop back,
otherwise exit" and the new patented algorithm is identical except that
instead of taking the hash mod p in step 1 you instead make step 2 "check if
it smaller than p and is prime", there should be a good case for it being
obvious. However that makes the patent lawsuit something unpredictable. It is
not the slam dunk that it would be if it were an attempt to patent rejection
sampling itself.
This does actually look worse, though, as it means that Blackberry might be
going after anyone who is using OpenSSL and likely some other common libraries
for DSA. To work around the patent you would have to generate a hash at least
L+64 bits long, not too convenient when you are using a standard hash that is
the same length as the prime p.
Again, the patent is not relevant to the uniform random number generator in
the library that started this thread.
 Sidney

@_date: 2016-08-17 14:24:53
@_author: Sidney Markowitz 
@_subject: [Cryptography] Generating random values in a particular range 
RFC 2631 is simply quoting FIPS PUB 186-1 and so in section 2.2.1.1 steps 5-7
(the second 5 and 6, the linked document has typos in its numbering) it has
the vulnerability that was fixed in the FIPS Pub 186-2 Change Notice.
The patent claims the steps in that Change Notice where instead of taking the
mod in step 5, if q is too large they iterate on advancing the seed and
hashing again.
The point of the patent near as I can tell seems to be to claim that fix for
the vulnerability, then submit the fix to FIPS who accepted it into their

@_date: 2016-06-22 14:47:03
@_author: Sidney Markowitz 
@_subject: [Cryptography] Code is Cruel -- The DAO 
A more detailed technical look at the exploit is here:
This is my first look at ethereum and theDAO, so maybe someone more
knowledgeable can weigh in on something that sticks out for me:
It looks like a fundamental flaw that is being exploited is a lack of
mechanism for locking data structures that are being updated. I see people
talking about the hack as an exploit of the use of recursion in theDAO
scripts. A comment in the above linked article mentions that the exploit could
be done without recursion because it really was an exploit of a function that
performed an operation that transfers money, then calls another function that
contained a call to a function controlled by the attacker, and only then
updated the balances that were changed by the transfer.
What that analysis ignores is that it was possible to have a function that
manipulates the balances which in the middle of that manipulation can call
another function that manipulates the balances. Isn't a fundamental
requirement of a system like this that it be possible to grab and release
locks on shared resources?
 Sidney

@_date: 2016-06-25 12:44:18
@_author: Sidney Markowitz 
@_subject: [Cryptography] Proposal of a fair contract signing protocol 
If you say that because of Alice's promise in Step 1 that it is not true that
in Step 3 "the valid contract is completely under Alice's control at this
point, and completely out of Bob's control" then you are asserting that the
promise has the force of taking it out of Alice's control after Step 1. In
which case the validity of the contract is completely under Bob's control in
Step 2. Either the "promise" falls under the definition of "commitment" and
Bob has unfair control in step 2, or it is not, in which case Alice has unfair
control in Step 3.

@_date: 2016-06-26 20:08:44
@_author: Sidney Markowitz 
@_subject: [Cryptography] Proposal of a fair contract signing protocol 
Ok, I went over all the previous messages you have sent in this thread and
extracted everything you have said that regards the definition of what is fair
or not fair and how each step in the protocol makes it fair.
As far as I can tell you define "not fair" as being the situation in which one
person is "fully committed" to contract C when the other person is not "fully
committed" to contract C. You define "fair" as the situation in which both
parties become "fully committed" at a single moment.
The most recent way you summarized the definition "fully committed":
"Fully committed by a partner means he/she has signed both X and Y
or has promised to sign both because a certain condition is satisfied"
Since you say that Alice is not "fully committed" after step 1, you must be
saying that the promise does not make her fully committed until the condition
of the promise is satisfied by Bob signing C in step 2.
You have not specified any protocol for "promise". How is it proven that A
promised to sign Y without having A digitally sign Y or digitally sign a
promise that includes Y?
This leaves no reason for your protocol to require that contract C is split
into separate halves X and Y that are signed separately. You could just as
easily write the contract to say "Alice and Bob agree to this transaction
subject to this contract being signed by both Alice and Bob" and then have
both Alice and Bob "promise" to sign it conditional on the other person
signing it. If you do that, then a single signature provides the simultaneous
commitment that you require for "fairness", according to your definitions.
This protocol puts all the power into the "promise" which binds Alice, but you
never define how a binding promise can be made without the promise itself
being a contract that has to be put into effect in a "fair" fashion. That
leads to an endless recursion.
 -- Sidney

@_date: 2016-06-27 17:38:49
@_author: Sidney Markowitz 
@_subject: [Cryptography] Proposal of a fair contract signing protocol 
You never mentioned that the promise is what is signed in step 1. You said
that Alice only signs X in step 1 and promises to sign C = X | Y if Bob signs
it in step 2. How could Alice sign a promise to sign X and Y if what she signs
only includes X? And if Alice does have to sign "I promise to sign Contract C
= X | Y within time T1 after Bob signs Contract C if he signs within time T2"
and she is bound by that, then that promise is an unfair contract by your
 Sidney

@_date: 2016-06-29 01:08:09
@_author: Sidney Markowitz 
@_subject: [Cryptography] Proposal of a fair contract signing protocol 
If "signcryption" means, as you said, that step 1 sends signed(Alice,
encrypt(Bob, signed(Alice, X)|"I, Alice, promise to sign X|Y when Bob signs
X|Y")) then Alice has never signed her promise, all she has signed is a
message that is encrypted with Bob's public key with no proof that she even
knows what is in it. If you have Alice sign the promise, then the promise
itself is a contract that she fully commits to in Step 1 and so is unfair by
your definition. There is still the recursion.
 Sidney

@_date: 2016-06-30 02:40:29
@_author: Sidney Markowitz 
@_subject: [Cryptography] Proposal of a fair contract signing protocol 
Well, at least you have made it clear that it is different than the Two
Generals problem, so we can't simply say that what you are trying to do has
been proven impossible that way. The Two Generals problem says (roughly) that
it is impossible for two parties to unequivocally come to an agreement over an
unreliable channel. Your protocol is allowed to time out without any contract
coming into effect if it takes too long, so that is not an issue.
No, this is not obvious. Someone always has to be first to sign a contract,
but a contract does not come into effect before both parties agree to it.
If signing is what makes commitment then whoever signs first is committed
first. In your protocol Alice first signs the promise. She is committed to
contract P (the promise) which requires her to do certain things in exchange
for Bob providing his signature on C. Bob has no corresponding commitment.
That is unfair by your definition, but does not seem particularly unfair to
me. When someone proposes a contract C, at some point they need to commit to
something so that the other party has a reason to commit to something else.
All you have done is make the promise that first stage of commitment and then
called it "fair" because it is conditional on Bob's act of commitment.
If signed conditional promises make it fair by your definition then there is
no need for your protocol: Alice writes C to include the clause "This contract
comes into effect as soon as it is signed by both Alice and Bob as long as
both signatures are done and the signed document is published by time T." Then
it can be signed in any order and it is still fair by your definition.
At this point I don't see that you are clarifying any more, only repeating
your initial statement of the protocol. You have not explained why Alice
signing the promise is any different than an "unfair" signing of C, or why
signing a C that says that it is conditional on Bob's signature is not just as
fair as signing a conditional promise to sign C. If you simply repeat a
description of your protocol without answering those questions I don't see any
further purpose in discussion.
 Sidney

@_date: 2016-07-01 13:27:45
@_author: Sidney Markowitz 
@_subject: [Cryptography] Proposal of a fair contract signing protocol 
============================== START ==============================
mok-kong shen wrote on 1/07/16 3:50 AM:
Then in Step 1 Alice commits to Promise P, which makes P an unfair contract.
According to your fairness definition: promise P is a contract that is
proposed by Alice, that comes into being in Step 1, is committed to by Alice
and not by Bob in Step 1 and is therefore unfair.
Using only your own definitions, you have specified a protocol in which a
Contract C can be committed to by Alice and Bob in a fair fashion by having
Alice first commit to unfair contract P.
 Sidney

@_date: 2016-05-23 19:06:29
@_author: Sidney Markowitz 
@_subject: [Cryptography] Entropy Needed for SSH Keys? 
There is a difference between checking every one of the 2^256 4096 bit numbers
that could have been generated from that 256 bits of entropy and going through
all the calculations needed to factor a 4096 bit number. However both will
take you more time and resources than you have.
Both take much longer than factoring a 256 bit RSA key. Which is why 256 bits
is enough entropy to generate the key but the key has to be 4096 bits.

@_date: 2016-09-19 08:50:40
@_author: Sidney Markowitz 
@_subject: [Cryptography] Recommendations for short AES passphrases 
A minor point, but RFC1924 explains why using b85 is better than b94 if you
want to encode 128 bits. Short form of the explanation is that both of them
need 19 and a fraction chars to hold 128 bits, i.e. they both will encode to
20 chars, and b85 lets you choose more characters for other uses such as to
delimit the string.

@_date: 2017-08-15 12:36:30
@_author: Sidney Markowitz 
@_subject: [Cryptography] National Navajo Code Talkers Day 
Tracking this down I actually found a bit of cryptographic relevance :)
The short answer is that they didn't have a word for shark, they did have a
word for "fish" and various adjectives that could be used if they had a
concept regarding fish to express, and their ancestors migrated from British
Columbia by way of other places that had water and fish.
First, the cryptography part:
One reference I found from a Google Books search into "Secret History: The
Story of Cryptology"
It describes the Navajo code talking as not a simple matter of native Navajo
speakers conversing in their language. It was a cipher that used Navajo words
to encode the English alphabet. For example, the letter C was a Navajo word
for "cow" rotated with two other words that translated to English words that
begin with "c". Similarly, A was a word for "ant" rotated with two other
words. To shorten the messages, a number of designated plaintext words were
represented by Navajo words. Three of those words I saw listed charts were
[battleship - lo-tso - whale], [destroyer - ca-lo - shark], [submarine -
besh-lo - iron fish]
However, according to that reference the code words were made up by the code
talkers for use among themselves and were not necessarily the common native
speaker words for anything. I noticed that an online Navajo English dictionary
(which I do not claim be authoritative) has this for "shark"
 containing two different Navajo entries
 hashkh
Elsewhere I saw it mentioned that the first one literally means "angry fish".
Thus, "ca-lo" is [some adjective] - fish, not even properly phonetically
transcribed and not necessarily how a native Navajo speaker would refer to a
Some other discussions I found pointed out that even a native Navajo speaker
who was not trained in the code talking would not understand the messages as
more than a meaningless sequence of nouns. The language contains phonemes that
would be difficult for a non-native speaker to distinguish, especially true
for the Japanese, making it difficult for the messages to be transcribed for
And finally,
An interesting history with quotes from a 19th century anthropologists, which
includes the comment "He notes that Navajo basically has only one word for
'fish': , a generic term referring to all fish".
Sidney Markowitz

@_date: 2017-08-18 09:34:40
@_author: Sidney Markowitz 
@_subject: [Cryptography] 2008 revision of Bitcoin whitepaper - original 
This looks like it. It has the older phrase "without the burdens" in the
abstract that was posted to this mailing list in 2008 rather than the newer
"without going through"
 --
 Sidney Markowitz

@_date: 2017-08-20 08:57:50
@_author: Sidney Markowitz 
@_subject: [Cryptography] 2008 revision of Bitcoin whitepaper - original 
[ ...]
The sha256 hash StealthMoner posted matches that of the older pdf at Gwern's
site, so nothing new there.
Also, in case your search leads you to the discussion at
and from there trying to get the copy of the paper that is stored on the
blockchain at
TX id 54e48e5f5c656b26c3bca14a8c95aa583d07ebe84dde3b7dd4a78f4e4186e713
I already did that and it is just a copy of the newest one that is now on
So far I've seen nobody saying they have a copy of the "Electronic Cash
Without a Trusted Third Party" draft version referenced in the email to Wei Dai.
 --
 Sidney Markowitz

@_date: 2017-12-24 10:42:46
@_author: Sidney Markowitz 
@_subject: [Cryptography] paragraph with expected frequencies 
It would be better to teach the how statistics provide usefully approximate
results rather than faking a perfect match to some commonly quoted frequency.
Here is one interesting contrast of letter frequencies from a few different
sources, quoted from the multi-language examples at
  David Copperfield          etaoinhsrdlmuwycfgpbvkxjqz
  Pride and Prejudice        etaoinhsrdlumcywfgbpvkzjxq
  Wuthering Heights          etaonihsrdlumcyfwgpbvkxjqz
  Vanity Fair                etaonhsirdlumcwfgypbvkjqxz
  Gulliver's Travels         etoainshrdlmucfwygpbvkxjqz
  Alice in Wonderland        etaoihnsrdluwgcymfpbkvqxjz
  Inaugural speeches:
  Reagan                     etonarishdlumwcfgpybvkjxzq
  Obama                      etoarnsihdlucwfmgpybvkjqzx
  British National Corpus    etaoinsrhldcumfpgwybvkxjqz
  (90 million words of UK English)
  Brown corpus               etaoinsrhldcumfpgwybvkxjqz
  (one million words of US English)
 --------------

@_date: 2017-03-20 09:44:02
@_author: Sidney Markowitz 
@_subject: [Cryptography] Crypto best practices 
Are you thinking of Phillip Rogaway, "Evaluation of Some Blockcipher
Modes of Operation"  ?
It's not that old, 2011, and the reference to encrypting the IV with K in CBC
is on page 37 where he refers back to his 2004 paper "Nonce-based symmetric
encryption"  and even in
that earlier paper he discusses the attack on it.
I don't think he can have any "real oldie" papers on the topic as his PhD
thesis is as recent as 1991.
 Sidney

@_date: 2017-10-17 02:41:32
@_author: Sidney Markowitz 
@_subject: [Cryptography] Severe flaw in WPA2 protocol leaves Wi-Fi traffic 
According to this article, a protocol level vulnerability has been found in
WPA2 that allows an attacker to eavesdrop on WPA2 protected WiFi traffic. As a
vulnerability in the protocol it potentially affects all compliant
implementations of WPA2.
It links to an article by one of the researchers who found it at

@_date: 2017-10-18 06:10:55
@_author: Sidney Markowitz 
@_subject: [Cryptography] [FORGED] Re: Severe flaw in WPA2 protocol leaves 
"All official 14.1 builds built after this tweet have been patched for KRACK.
9:26 PM - 16 Oct 2017"

@_date: 2017-09-04 11:18:29
@_author: Sidney Markowitz 
@_subject: [Cryptography] early archives of cypherpunks? 
Three of the top four results of a google search for "cypherpunks archive"
seem to be complete copies of 1992-1998. The venona site has two links. The
one that is indexed by date is a bit misleading because some of the emails
have wrong Date headers. The raw archive link contains plain text files, one
for each year, avoiding that problem.
 at cpunks.org/msg00616.html
Multiple sources combined:

@_date: 2018-08-31 11:33:08
@_author: Sidney Markowitz 
@_subject: [Cryptography] Need a list of Solinas/pseudo Mersene Primes. 
> I am using Shamir secret sharing as a recovery mechanism for private keys and
 > would like to extend this to recover quantum resistant keys. As a result, I
 > need a nice round prime greater than 2^256.
 >
 > Finding a nice round prime smaller than 2^256 is easy, 2^255-2^19-1. But I
 > need 2^256-x. I was looking for lists of Solinas primes but can't find one
 > with what I need.
 >
 > Anyone got a pointer?
Are you asking for exactly 256 or greater than or equal to 256?
There are a number of both listed in the table of curves in

@_date: 2018-08-31 13:12:09
@_author: Sidney Markowitz 
@_subject: [Cryptography] Need a list of Solinas/pseudo Mersene Primes. 
I'm still not sure if you are asking for exactly 2^257-n or any 2^m - n for m>256, but see if the appendix in this paper helps
Tables 1-4 list all Solinas Prime Numbers of the form 2^m - 2^n +/- 1 with small modular reduction weight and m from 64 through 2000

@_date: 2018-12-13 01:31:47
@_author: Sidney Markowitz 
@_subject: [Cryptography] Decrypting the Encryption Debate 
When you get to the login or register page there is a button with a third choice "Download as Guest" which leads to a page that requires you to enter a string formatted like an email address and to tick a checkbox saying that you accept the terms of use.

@_date: 2019-01-02 16:13:52
@_author: Sidney Markowitz 
@_subject: [Cryptography] blake2b 160 
[...]> sufficient I could test it to produce a collision in the last sixty or
If the "technobabble" tried to say  that hashes could be broken in less than brute force times without using some specific cryptanalysis of the hash algorithm, it is probably nonsense. But if you really do intend to only use the last n bits of the hash and you really are trying to protect against collision, then 60 bits may not be good enough.
Brute force lets you find some two blocks with a collision on an n-bit hash by trying on the order of 2^(n/2) hashes on random blocks. The algorithm is to generate blocks, hash each, and save the results in a way that you could quickly find when you have encountered the hash before and what data block made it. The details are left as an exercise. Because of the birthday "paradox" finding a collision makes it n/2 instead of n when you don't care which two blocks have the collision.
If what you are concerned about is second preimage resistance, i.e., given a specific block of data  find a different block that hashes to the same value as the first, that would take on the order of 2^n hashes to brute force, but you would not have to use the memory to save all the hashes you compute until you find it.
Which of the two you are concerned with depends on your threat model. Collision resistance protects against somebody producing two things that have the same hash and using them in some kind of bait and switch scam. But if what you want to use the has for is to prove that an item you supply has not been tampered with, all you need is second preimage resistance.
When you say "the last n bits of the hash", that's the n that you use in those estimates. Finding a collision in just the last 60 bits would only take on the order of a bit more than a billion hashes and a billion numbers in memory. What would that be, a few hours on just one core and tens of GB of RAM? But if you really intended to use the full 160 bits of a 160-bit hash, then you are looking at 2^80, so multiply that by another 2^50 which would be bigger than is feasible.
And if you really meant second preimage, even only using the last 60 bits would require a brute force attack to calculate 2^60 hashes, which my really rough fermi estimate tells me would be more than a thousand years running on a thousand cores.
  Sidney Markowitz
  sidney at sidney.com

@_date: 2019-01-24 09:20:41
@_author: Sidney Markowitz 
@_subject: [Cryptography] Historic Codebreaking. 
A quote from the sidebar of the subreddit /r/voynich
    Every few months there's a new article on how the VM has been deciphered.
    This is not true. Read the following for more information.
  Does anyone here have the expertise (I certainly don't) to say whether this latest discovery is a credible one, or might it be another of those "every few months" articles?

@_date: 2019-01-24 16:22:38
@_author: Sidney Markowitz 
@_subject: [Cryptography] Historic Codebreaking. 
Hmm, possibly so. I'm still no expert, but here someone who claims to be, who doesn't think well of it:

@_date: 2019-05-10 10:51:29
@_author: Sidney Markowitz 
@_subject: [Cryptography] peering through NAT 
And I replied
Naturally as soon as I hit Send I remembered something contradictory.
Bitcoin core can use UPnP which is probably what you are thinking of
See and other results of a Google search for UPnP bitcoin core

@_date: 2019-05-15 16:24:26
@_author: Sidney Markowitz 
@_subject: [Cryptography] Dieharder & /dev/urandom 
Here is an article which goes through a very thorough step by step analysis of an RNG using Dieharder to demonstrate how to interpret WEAK results by using them to refine the testing to get more certain results.
One important point of the article is that a result of PASSED does not mean that the RNG has passed a test, it means that it has with high probability not failed; a result of FAILED means that it has with high probability failed; and a result of WEAK indicates uncertainty in the results, not that the RNG is close to passing or close to failing a test. WEAK is an indication that you need to make the test stronger (e.g. with more p samples) until the uncertainty is resolved one way or another. The article is a demonstration of how to do that.

@_date: 2019-10-23 09:03:18
@_author: Sidney Markowitz 
@_subject: [Cryptography] Very best practice for RSA key generation 
Have you looked at FIPS 186-4 section A.1.1 Generation and Validation of Probable Primes to see if any other differences between your method and that spec make a difference?

@_date: 2020-04-04 18:39:56
@_author: Sidney Markowitz 
@_subject: [Cryptography] "Zoom's end-to-end encryption isn't 
?ngel wrote on 4/04/20 2:30 pm:
Updates for Zoom on Windows and macOS showed up, though not Linux, iOS, or Android
Interesting note: Zoom updates are marked "prompt", or else "manual" which do not prompt or notify the user no matter their preferences settings. This update is the first one set to "prompt" since mid 2017, after 58 non-prompted releases for Windows and 66 for macOS. I had not realized that my Zoom was 9 months out of date on one of my Macs until it started crashing regularly and I manually checked for updates, something I thought was unnecessary after having set preferences to notify me when an update is available.
Release notes:
April 2, 2020 Version 4.6.9 (19253.0401)
* Resolved an issue where a malicious party could use UNC links to leak a user?s hashed password
* Resolved an issue where some users could access chat in a webinar when chat was disabled
April 2, 2020 Version 4.6.9 (19273.0402)
* Resolved an issue where a malicious party with local access could tamper with the Zoom installer to gain additional privileges to the computer
* Resolved an issue where a malicious party with local access could gain access to a user?s webcam and microphone
* Resolved an issue where some users could access chat in a webinar when chat was disabled

@_date: 2020-02-17 09:23:38
@_author: Sidney Markowitz 
@_subject: [Cryptography] Extracting TOTP credentials 
Ron Garret wrote on 16/02/20 2:26 am:
I didn't dig into the code, but this claims to be a complete Authy client with support for TOTP so maybe it has the details you need?

@_date: 2020-01-08 03:23:05
@_author: Sidney Markowitz 
@_subject: [Cryptography] looking for a word 
Peter Fairbrother wrote on 7/01/20 3:08 pm:
"Copy" is the correct word. It is the context of the copying that makes it part of a breach of confidentiality. When someone eavesdrops, wiretaps, breaks in to files, spies, engages in espionage, hacks in to a protected system, breaks in, cons, or whatever is the suitable phrasing to describe what they are doing and copies confidential material, "copy" is the right word and the context provides the right connotations. "Pat copied the files" sounds innocent. "The spy copied the files" does not.

@_date: 2020-01-08 13:54:26
@_author: Sidney Markowitz 
@_subject: [Cryptography] looking for a word 
Peter Fairbrother wrote on 8/01/20 6:32 am:
I don't think that works as a verb substituting for "copy". People aren't familiar with that use of the verb "abstract" will not understand what is being said. The Oxford definition at  defines that sense of the verb as "Extract or remove (something)" and then says "Used euphemistically to indicate that someone has stolen something" with the first example sentence referring to stealing concrete objects and the second using "abstracting electricity". The legal term may be because electricity is not a "thing" that can be subject to "stealing" but the action still uses up electric power without replacement, as opposed to copying data and leaving the original. So "abstract" still does not serve as a replacement for "copy".
There may not be a standalone verb to use. But what is wrong with "illegal copying" or "unauthorised copying" choosing the first for an action that is in violation of some law and the second for an action that may or may not actually be illegal but may have moral weight?

@_date: 2020-11-13 01:19:25
@_author: Sidney Markowitz 
@_subject: [Cryptography] Swiss helped with CIA spying 
Dave Horsfall wrote on 12/11/20 4:12 pm:
The article does acknowledge it as old news, but says
"At the time, the company called reports that it was a secret asset of Western intelligence agencies 'an unbelievable conspiracy theory,' according to a report in German magazine Focus detailing a 1994 book on the subject.
After being told late last year of fresh research about the company, the Swiss government in January appointed a former Swiss Supreme Court judge to scrutinise Crypto's activities "to investigate and clarify the facts of the matter", the defence ministry said in a statement."
Anyway, do these count as major media?
 From Baltimore Sun in 1995
No Such Agency Part Four
Rigging the Game
 From Der Speigel 1996
Geheimdienste unterwandern Verschl?sselungsger?te
Rough English translation of Der Speigel article
secret services undermine cryptographic devices
 From BBC 2015
How NSA and GCHQ spied on the Cold War world

@_date: 2020-11-16 16:31:17
@_author: Sidney Markowitz 
@_subject: [Cryptography] Satoshi Nakamoto Email Timestamps Disambiguation 
Kapilkov, Michael wrote on 16/11/20 3:53 am:
The relevant headers from the email in my inbox:
Received: from green.metzdowd.com (green.metzdowd.com [166.84.7.15])
Received: by green.metzdowd.com (Postfix, from userid 1101)
Delivered-To: cryptography at metzdowd.com
Received: from hacklheber.piermont.com (hacklheber.piermont.com [166.84.7.14])
Received: from snark.piermont.com (localhost [127.0.0.1])
Received: by snark.piermont.com (Postfix, from userid 1000)
Received: from mail.anonymousspeech.com (anonymousspeech.com [124.217.253.42])
Received: from server123 ([124.217.253.42]) by anonymousspeech.com with MailEnable ESMTP; Sat, 01 Nov 2008 02:20:18 +0800
X-Mailer: Chilkat Software Inc (
X-Priority: 3 (Normal)
Reply-To: satoshi at vistomail.com

@_date: 2020-11-16 17:26:43
@_author: Sidney Markowitz 
@_subject: [Cryptography] Satoshi Nakamoto Email Timestamps Disambiguation 
Kapilkov, Michael wrote on 16/11/20 3:53 am:
Some additional clarification based on the headers I already posted:
The first date you listed is the one in the Date header of the email itself, when it was mailed by Satoshi. The bottom Received header shows it arrived at the mailing list's server about ten minutes later.
The second date is an incorrect translation of the time showed at mail-archive, where it the time it received the mail was  Sat, 01 Nov 2008 16:16:33 -0700. Daylight Savings Time in Eastern Time zone did not end in 2008 until Nov 2, so that time was Nov 1, 2008 19:16:33 ET (-0400)
The Received headers I posted have an approximately 29 hour delay between first received by the mailing list server and being sent out to the next step. I assume that is how long it sat in moderation waiting to be manually released. That 10 minutes plus approximately 29 hours sum to the gap between Oct 31 14:10:00 ET and Nov 1 19:16:33 ET
