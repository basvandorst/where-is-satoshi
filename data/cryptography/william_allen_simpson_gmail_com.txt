
@_date: 2006-12-28 10:01:04
@_author: William Allen Simpson 
@_subject: Security Implications of Using the Data Encryption Standard (DES) 
The IETF/IESG refused to publish the "ESP DES-XEX3-CBC Transform" submitted
as draft-ietf-ipsec-ciph-desx-00 (1997) and draft-simpson-desx-01 and
draft-simpson-desx-02 (1998).
Of course, they also refused to publish draft-simpson-des-as-00 (1998) and
draft-simpson-des-as-01 (1999) that deprecated DES -- despite strong
votes of support at SAAG and PPP meetings.
There was an "Appeal of IESG inaction, decisions of 13 Oct 1999 and 16 Feb 1999".
The NSA and Cisco folks that were involved in IKE/ISAKMP advocated DES,
refusing to assign code points for DESX.  Gosh, I wonder why....

@_date: 2006-07-27 15:22:21
@_author: William Allen Simpson 
@_subject: IKE resource exhaustion at 2 to 10 packets per second 
The vulnerability allows an attacker to exhaust the IKE resources on a
remote VPN concentrator by starting new IKE sessions faster than the
concentrator expires them from its queue. By doing this, the attacker
fills up the concentrator's queue, which prevents it from handling valid
IKE requests.
The exploit involves sending IKE Phase-1 packets containing an
acceptable transform. It is not necessary to have valid credentials in
order to exploit this vulnerability, as the problem occurs before the
authentication stage. The vulnerability affects both Main Mode and
Aggressive Mode, and both normal IKE over UDP and Cisco proprietary
TCP-encapsulated IKE.
In order to exploit the vulnerability, the attacker needs to send IKE
packets at a rate which exceeds the Concentrator's IKE session expiry
rate. Tests show that the target concentrator starts to be affected at a
rate of 2 packets per second, and is becomes unusable at 10 packets per
second. As a minimal Main Mode packet with a single transform is 112
bytes long, 10 packets per second corresponds to a data rate of slightly
less than 9,000 bits per second.
The vulnerability was first discovered on 4th July 2005, and was reported
to Cisco's security team (PSIRT) the same day. Cisco responded on 9th
August 2005, but no further progress has been made, over a year after
finding the flaw.
Gosh and golly gee, how could this vulnerability slip past them without
anybody noticing?
... other than the person posting an internet-draft that the IESG refused
to publish as an RFC, that was instead published in ;login: December 1999.
... that attack threat was mentioned in the design principles of Photuris
circa 1995, that the IESG also refused to publish until after the
NSA-originated and approved IKE/ISAKMP protocol.
It's particularly amusing that Photuris was overwhelmingly approved in a
straw poll conducted by John Gilmore at the 36th IETF in Montreal, 1996,
but Cisco issued a press release that they had chosen the NSA-designed
protocol instead.  Protocol adoption by press release, such a good choice.
They just had the 66th IETF in Montreal a week ago.  Full circle.
Anybody ready to order Photuris from your vendors?

@_date: 2007-12-01 11:11:35
@_author: William Allen Simpson 
@_subject: PlayStation 3 predicts next US president 
It always bothers me as these things are announced, but are based on
presumptions that have absolutely no relevance in the real world....
Therefore, nothing to do with cryptography (which is not a parlor trick).
There is no such MD5 vulnerability implied.  As the paper itself states:
   In cryptographic terms: our attack is an attack on collision resistance,
   not on preimage or second preimage resistance. This implies that both
   colliding files have to be specially prepared by the attacker, before
   they are published on a download site or presented for signing by a code
   signing scheme. Existing files with a known hash that have not been
   prepared in this way are not vulnerable.
Since this "attack" requires the certifier be compromised, the attacker
could also modify the program data itself undetectably.  That is, this
theoretical problem actually is more effort than the obvious attack!
In summary, there are exactly zero instances where this use of MD5 would
actually present a vulnerability.
As many discussions in this community have amply demonstrated, trust is
not transitive.  At some point, you have to "know" (usually by reputation)
the chip-vendor, compiler-writer, et alia, are not compromised.  Therefore,
many of us compile our own systems and packages (as much as practical).
Over the many years we have designed protocols using MDx, we were always
aware that a mere hashing function could never perfectly protect against
prefix or suffix data extension.  Therefore, (I for one) always design
with a prefix chosen by the certifier, and a suffix nonce or counter
publicly shared with (preferably chosen by) the verifier.
For example, see PPP CHAP (originally written circa 1991).
The only cryptographic question is how to quantify the strength of the
collision resistance.  CRC, FCS, MD2, MD4, MD5, SHA1, SHA256 -- they all
have some level, and that is useful to determine the practical application
for the function.
The base complexity assumptions are (have always been) 2 to the:
  8 CRC
16 FCS
64 MDx
80 SHA1
None of these have ever been out of the realm of possibility.  Yet we all
have long known that SHA1 is stronger than MD2, which is stronger than MD5,
which is stronger than MD4.  We also have long known that FCS and CRC are
perfectly acceptable for many integrity applications.
How much stronger is an interesting result.  The rest is merely academic.

@_date: 2007-12-01 21:09:07
@_author: William Allen Simpson 
@_subject: PlayStation 3 predicts next US president 
You are referring to a different page (that I did not reference).
Never-the-less, both attacks require the certifier to be compromised!
That's a mighty big "if" -- as in infinite improbability.  Therefore, a
parlor trick, not cryptography.
There are no circumstances in which any reputable certifier will ever
certify any of the "multitude" containing a hidden pdf image, especially
where generated by another party.
The attack requires the certifier to be compromised, either to certify
documents that the certifier did not generate, or to include the chosen
text (hidden image) in its documents in exactly the correct location.
While there are plenty of chosen text attacks in cryptography, this one
is highly impractical.  The image is hidden.  It will not appear, and thus
would not be accidentally copied by somebody (cut-and-paste).
The parlor trick demonstrates a weakness of the pdf format, not MD5.
To be as weak as CRC, the strength would be 2**8.  I've seen no papers
that reduce MD5 complexity to 2**8.
Please present your proofs and actual vulnerabilities, including specific
examples of actual PPP CHAP compromised traffic -- and for extra credit,
actual compromise of netbsd and/or openbsd software distribution.

@_date: 2007-12-01 22:57:58
@_author: William Allen Simpson 
@_subject: PlayStation 3 predicts next US president 
Apparently, you never read the original rationale for MD5.  It
still does what it was intended to do....
If it is a certifier, it damn well better be its own documents!
Look at the original message:
   This implies a vulnerability in software integrity protection
   and code signing schemes that still use MD5.
Anybody that's "certifying" software and code that they didn't
personally generate and vet is selling snake oil.
Trust is *not* transitive!  Neither is reputation.

@_date: 2007-12-02 11:26:20
@_author: William Allen Simpson 
@_subject: PlayStation 3 predicts next US president 
Actually, I deal with notaries regularly.  I've always had to
physically sign while watched by the notary.  They always
read the stuff notarized, and my supporting identification,
because they are notarizing a signature (not a document).
And yes, they always generate the stamp or imprint they sign.
To do otherwise would be irresponsible (and illegal).
I've digitally signed contracts, that I prepared and verified,
on plaintext documents using PGP.  So far, I've seen no such
exploit described nor quantified.
There's this silly idea that's been floating around that a
digital signature is somehow equivalent to a human signature.
Or worse, somehow better?!?!  Heck, current U.S. law counts a
digitized sound as a signature!?!?
(Folks have lost money on this snake oil.  They deserved it.)
Anyway, this is irrelevant to the original topic.  That is:
   This implies a vulnerability in software integrity protection
   and code signing schemes that still use MD5.
Please quantify your spurious allegations (and stay on topic).

@_date: 2007-12-02 11:51:24
@_author: William Allen Simpson 
@_subject: PlayStation 3 predicts next US president 
Parlor trick.
Parlor trick.
More interesting.  Where on your web site?  I've long abhorred the
X.509 format, and was a supporter of a more clean alternative.
Parlor trick.
So far, all the things you mention require the certifier to be suborned.
Certainly it was done before!  We talked about it more than a decade ago.
We knew that what was "computationally infeasible" would become feasible.
Every protocol I've designed or formally reviewed is protected against the
chosen prefix attack.  (To qualify, where I had final say.  I've reviewed
badly designed protocols, such as IKE/ISAKMP.  And I've been overruled by
committee from time to time....)
What *would* be crypto is the quantification of where MDx currently falls
on the computational spectrum.

@_date: 2007-12-02 17:51:39
@_author: William Allen Simpson 
@_subject: PlayStation 3 predicts next US president 
This will be my last posting.  You have refused several requests to stick
to the original topic at hand.
Apparently, you have no actual experience with the legal system, or
are from such a different legal jurisdiction that your scenario is
somehow related to MD5 hashes of software and code distribution.
Because human beings often try to skirt the rules, there's a long
history of detailed notarization requirements.  How it works here:
(1) You prepare the document(s).  They are in the form prescribed by law

@_date: 2007-12-02 18:08:31
@_author: William Allen Simpson 
@_subject: PlayStation 3 predicts next US president 
Much more interesting.  Looks like the death knell of X.509.  Why
didn't you say so earlier?
(It's a long known design flaw in X.509 that it doesn't provide
integrity for all its internal fields.)
Where are MD2, MD4, SHA1, and others on this continuum?
And based on the comments in the page above, the prefix is quite large!
Optimally, shouldn't it be <= the internal chaining variables?  512 bits
for MDx.  So, the attacks need two values for comparison: the complexity
versus the length of the chosen prefix.
Let me know when you get the chosen prefix down to 64-bits, so I can say
"I told you so" to Bellovin again.  I was strongly against adding the
"random" IV field to IPsec....

@_date: 2007-12-03 08:47:09
@_author: William Allen Simpson 
@_subject: PlayStation 3 predicts next US president 
And that makes all the difference.  The digital notary is not certifying the
original document.  You described the notary generating its own tuples
(credentials as presented, the hash, a timestamp, and a notarized declaration
that such was presented).  There is no problem, and the described attack does
not apply.
Note that the notary bears no responsibility for presentation of false
credentials.  Here, in a case with which I'm personally familiar, somebody
with the SAME NAME as his father got a new driver's license, signed it in
the same fashion as his father, then went to banks and presented the
driver's license and signature, causing all his father's deposits to be
transferred to his wife's name, and adding his son to the house deed (and
then mortgaging the house).  It was certainly not the several notaries'
fault that identical names were used.  The "certificate" (same name driver's
license and signature) appeared valid.
All the cryptography in the world will not prevent false certification,
where the underlying information is already compromised.
To reiterate the topic at hand: trust is not transitive!

@_date: 2007-12-06 09:30:21
@_author: William Allen Simpson 
@_subject: PlayStation 3 predicts next US president 
I had intended to stop posting, but with the request for history and a few
misguided postings later, please indulge me.  I'll try not to be too long.
We've been talking about "collision" and "preimage" resistance at least
since 1989.  We didn't use those terms (I'm not fond of "preimage").  We
merely had a clever bit of design by Rivest, and were eager to use the
tools in our network protocols, but had the usual qualms about new things.
If anything, being security minded, we were somewhat paranoid!
Remember, at the time we had 80286s in deployment, and MD2 was considered
too slow!  So, MD4 came along (1990), and its little-endian design was
fast enough to use on a server with 24 incoming connections.  Not only was
it "computationally infeasible" to find a collision, it was barely
feasible to use the functions at (56 Kbps) line speed!
There was some concern that MD4 would not be sufficiently resistant in the
future.  To be "safe", PPP CHAP was originally specified with either MD2
or MD4.  Later, by 1994, we had settled upon MD5 as the compromise.
To answer Benne's question, I was introduced to chosen-prefix collisions
(again, we didn't use that term) by Dave Balenson after the Common
Authentication Technology (CAT) Working Group meeting in Santa Fe circa
mid-1991, and changed the PPP CHAP hash field order to protect against the
possibility.  The original drafts hashed the packet in field order.
Splitting the Identifier from Challenge (with the secret between) protects
against prefix calculations (and provides a modicum of replay protection).
Within a couple of years, I would have included the Length as well, and
additional MD-strengthening after the secret.  The current CHAP design
depends upon the final MD-strengthening to protect against appending
attacks on the secret.  Actually, PPP CHAP is probably not vulnerable, as
the Challenge is short and fixed size for a particular connection.
We added length for IPv6 in 1993, what I retrospectively call the L-MAC
algorithm.  That evolved in 1994 to the "envelope" method (secret before
and after the data), and again in 1995 after the "On the Security of Two
MAC Algorithms" paper presented at the rump session of Crypto '95.  Within
days, we adopted the recommended additional MD-strengthening between the
data and the trailing secret, presented at the next IETF (and later
published) as the "interleaved padding" IP-MAC algorithm.
Sadly, the slower and weaker H-MAC (even though developed after IP-MAC) is
the currently used specification.  Sometimes, folks just assume that
something published later is better.  A reminder that the pressure of
commerce, lobbying, and politics often trumps our best efforts.
To reiterate, when designing security systems, there is a continuum of
possibilities, and we choose those that fit the threat model.  Even today,
with laptop processors that out-perform the supercomputers of that era,
PPP CHAP with MD5 is still resistant to such limited time-frame attacks
over a serial link.
As our understanding improves, it is perfectly reasonable to evolve our
designs.  That's why it is so important to specify flexible protocols from
the very beginning!
Reminding you that this is something like a notary function, *not* a code
distribution or signing function.  And the attack requires (as I've shown
repeatedly) the original document generator to be compromised.
Folks on this list seem to forget that the legal purpose of a notary is
not to protect the bidder/contractor/deed/etc.  It is to protect the
*public* against *fraudulent* bidders/contractors/deeds/etc.  As we all
agree (except for one increasingly phlegmatic person), the only purpose of
a notary is to bind a person to a document at a particular time.
The notary would never sign a hash generated by somebody else.  Instead,
the notary generates its own document (from its own tuples), and signs its
own document, documenting that some other document was submitted by some
person before some particular time.
As in code distribution, every certifier *MUST* *ALWAYS* generate their
own document.  Then, there is no chosen-prefix collision, and the attack
does not apply.
In your hypothetical, the certifier virtually guarantees that Mallory
will be caught!  When Mallory tries to assert the claim, the bids can
easily be compared.  When the verifier compares the original documents
and hashes with the later hashs, it will become readily apparent that two
documents have the same hash.  And then the trial judge will appoint a
special master (such as me) to review the documents.
It would be no problem to show that the documents re-typed by a
certified court reporter do not generate the same hash.  It would also be
no problem to show that the documents with the common hash also have an
"invisible" block of data.  Even a jury will easily understand that
apparently random garbage that serves no purpose other than to obfuscate
the document is proof beyond a reasonable doubt of conspiracy and fraud.
And because the document hash is certifiably bound to a person, there's
no escaping the conviction....

@_date: 2007-12-09 20:33:53
@_author: William Allen Simpson 
@_subject: PlayStation 3 predicts next US president 
Personally, I thought this horse was well drubbed, but the moderator let
this message through, so he must think it important to continue....
Sorry, obviously I incorrectly assumed that we're talking to somebody
skilled in the art....
Reminding you that several of us have told you that a notary has the
document in her possession; and binds the document to a person; and that
we have rather a lot of experience in identifying documents (even for
simple things like email), such as the PGP digital timestamping service.
   Dp := any electronic document submitted by some person, converted to its
         canonical form
   Cp := a electronic certificate irrefutably identifying the other person
         submitting the document
   Cn := certificate of the notary
   Tn := timestamp of the notary
   S() := signature of the notary
   S( MD5(Tn || Dp || Cp || Cn) ).
Of course, I'm sure the formula could be improved, and there are
traditionally fields identifying the algorithms used, etc. -- or something
else I've forgotten off the top of my head -- but please argue about the
actual topic of this thread, instead of incessant strawmen.
Another statement with no proof.  As the original poster admitted, there is
not a practical preimage or second preimage attack on MD5 (yet).
As to "its intended purpose", rather than making one up, I've always relied
upon the statement of the designer:
    ... The MD5
    algorithm is intended for digital signature applications, where a
    large file must be "compressed" in a secure manner before being
    encrypted with a private (secret) key under a public-key cryptosystem
    such as RSA.

@_date: 2007-12-10 12:31:43
@_author: William Allen Simpson 
@_subject: PlayStation 3 predicts next US president 
First of all, the weakness in MD5 (computational feasibility over time)
that "we are talking about" is not (yet) a preimage or second preimage
attack.  Please don't extrapolate your argument.
Second of all, you need to read my messages more carefully.  No good
canonical format allows random hidden fields or images.
Third of all, that's not a weakness of a notary protocol -- it's a trap!
The whole point of a notary is to bind a document to a person.  That the
person submitted two or more different documents at different times is
readily observable.  After all, the notary has the document(s)!
Remember, the notary is not vouching for the validity of the content of
the document.  A notary only certifies that something was submitted by
some person at some time.  And that cannot be broken by making multiple
submissions, or submissions that themselves have the same hash.
That's one reason I'm much more interested in the attack on X.509.
But since it's not, that's a ridiculous strawman.  I was remembering PGP
off the top of my head.  Fairly certain that Kerberos does, too.  Not
everybody is naive!
And since the timestamp is "predictable" (within some range, although
picoseconds really aren't very predictable), the protocols that I've
designed include message identifiers, nonces, and sequence numbers, too.
As you may recall, I mentioned that there were other fields....
He asked for an explanation about how a document is identified, he got
one.  Don't expect me to redesign an entire notary (or even a timestamp)
protocol on a Sunday evening for a mailing list....  Really, there are
fairly secure standards already available.
However, the actual topic of this thread is code distribution.  In that
case, there is no "other" party certifying the documents.  The code
packager is also the certifier.  There is (as yet) no weakness in the
MD4 family (including MD5 and SHA1) that allows this attack by another

@_date: 2007-10-02 17:35:57
@_author: William Allen Simpson 
@_subject: Linus: Security is "people wanking around with their opinions" 
I often say, "Rub a pair of cryptographers together, and you'll
get three opinions.  Ask three, you'll get six opinions."  :-)
However, he's talking about security, which often isn't quantifiable!
And don't get me ranting about "provable" security....  Had a small
disagreement with somebody at Google the other week, as he complained
that variable moduli ruined the security proof (attempts) for SSH.

@_date: 2008-08-09 07:42:19
@_author: William Allen Simpson 
@_subject: On the unpredictability of DNS 
It seems like enough time has passed to post publicly, as some of these
are now common knowledge:
Remember, this is the sum of the range of the 16-bit DNS header identifier
and the 16-bit UDP port number.
The theoretical maximum is less than 2**(16+16), as the ports less than
4096 are reserved.
Many or most implementations use only a pool of ports: 2**[9, 10, 12]
have been reported.
Some implementations (incorrectly) use positive signed integers for the
DNS identifier: 2**15.
And in this week's Hall of Shame, MacOSX Leopard patch for servers seems
to randomize the BIND request port in a small pool.  The next UDP packet
ports are sequential, so the range to guess is very small, simply by
looking at the following UDP packets.  Very strange reports coming out!
MacOSX total: about 2**18.
Worse, Apple didn't fix Leopard clients, didn't patch the stub resolver
library (neither did BIND), didn't patch earlier versions such as Panther.
Many, many MacOS systems are still vulnerable.
And in case you don't think this matters, once upon a time I helped build
an ISP entirely with Macs, resistant to most compromises.  There are far
more Macs used as resolvers than any other flavor of *nix.
I don't understand this comment.
When MD5 is used as a PRNG, in this case the upper 32-bits of its 128-bit
output cycle, what amount of samples will reveal the seed, or the current
internal state of the sequence?
When ARC4 is used as PRNG, what amount of samples will reveal the seed or
the current state?
Are you only referring to reverse engineering trivially poor PRNG?

@_date: 2008-12-08 12:40:24
@_author: William Allen Simpson 
@_subject: AES HDD encryption was XOR 
Oh, say it ain't so! ;-)
In the NBC TV episode of /Chuck/ a couple of weeks ago, the NSA cracked
"a 512-bit AES cipher" on a flash drive "trying every possible key".
"Could be hours, could be days."  (Only minutes in TV land.)
(Chuck Versus The Fat Lady, 4th segment, at 26:19)
It's no wonder that folks are deluded, pop culture reinforces this.

@_date: 2008-12-16 07:19:29
@_author: William Allen Simpson 
@_subject: CPRNGs are still an issue. 
[Snip admirably straightforward threat and requirements analysis]
Given the previous discussion on combining entropy, it shouldn't hurt, as
long as it's testable during manufacture.
Ah, here's the rub.  I like this testing requirement.  The recent FreeBSD
Security Advisory was merely a simple failure of initialization -- yet
wasn't caught for the longest time, because it wasn't readily testable.
As long as the testing procedure validates the key and key+RTC separately.
Recently, I was pleasantly surprised that the AT&T "U-verse" box had this!
Unlike the AT&T "2wire" boxes we were installing just this summer.
If we could only get Linksys, et alia on board....

@_date: 2008-07-31 05:50:48
@_author: William Allen Simpson 
@_subject: On the unpredictability of DNS 
============================== START ==============================
I've changed the subject.  Some of my own rants are about mathematical
cryptographers that are looking for the "perfect" solution, instead of
practical security solution.  Always think about the threat first!
In this threat environment, the attacker is unlikely to have perfect
knowledge of the sequence.  Shared resolvers are the most critical
vulnerability, but the attacker isn't necessarily in the packet path, and
cannot discern more than a few scattered numbers in the sequence.  The
more sharing (and greater impact), the more sparse the information.
In any case, the only "perfect" solution is DNS-security.  Over many
years, I've given *many* lectures to local university, network, and
commercial institutions about the need to upgrade and secure our zones.
But the standards kept changing, and the roots and TLDs were not secured.
Now, the lack of collective attention to known security problems has
bitten us collectively.
Never-the-less, with rephrasing, Ben has some good points....
While randomness is sufficient for "perfect" unpredictability, it isn't
necessary in this threat environment.
Keep in mind that the likely unpredictability is about 2**24.  In many
or most cases, that will be implementation limited to 2**18 or less.
In this threat environment, a better test would be for determination of a
possible seed for any of several common PRNG.  Or lack of PRNG.
How many samples would be needed?  That's the mathematical limitation.
Is it less than 2**9 (birthday attack on 2**18)?
Agreed!  All my tests of locally accessible NATs (D-Link and Linksys) show
that the sequence is fairly predictable.  And no code updates available....
Some are coming in on another private security list where I and some
others here are vetted, but everything is very preliminary.
In addition to the publicized attacks on major ISP infrastructure, there
are verified scans and attacks against end user home NATs.
Again, the question is not randomness, but unpredictability.

@_date: 2008-03-16 08:46:18
@_author: William Allen Simpson 
@_subject: RNG for Padding 
We had many discussions about this 15 years ago....
You usually have predictable plaintext.  A cipher that isn't strong enough
against a chosen/known plaintext attack has too many other protocol
problems to worry about mere padding!
For IPsec, we originally specified random padding with 1 trailing byte of
predictable trailing plaintext (the amount of padding). Together with the
(encapsulated) protocol number, that actually made 2 bytes of predictable
trailing plaintext.
Due to my work in other groups, everything that I've specified afterward
uses "self-describing-padding".  That is, the last byte indicates how much
padding (just as before), but each byte of the padding indicates its
position in the padding sequence.
0 ::= never used.
1 ::= 1 byte of padding (itself)
1 2 ::= 2 bytes of padding
The original impetus was hardware manufacturers of in-line cipher devices,
that don't usually have a good source of randomness.
Also, this provides a modest amount of integrity protection.  After
decryption, the trailing padding must be the correct sequence.  Of course,
this should be in addition to integrity protection over the whole packet!
Additionally, this avoids a possible "covert channel" for compromised data,
whether by accident (revealing a poor RNG or the current state of the RNG),
or trojan process communication.  Note that I've said "avoids", as varying
the amount of padding would give a lower bandwidth channel for the latter.
When designing, it's always best to defend in depth.

@_date: 2008-09-10 13:29:32
@_author: William Allen Simpson 
@_subject: once more, with feeling. 
I agree.   I'm sure this is a world-wide problem, and head-in-the-sand
cyber-libertarianism has long prevented better solutions.  The "market"
doesn't work for this, as there is a competitive *disadvantage* to
providing improved security, and it's hard to quantify safety.
Remember automotive seat-belts?  Air-bags?  Engineers developed them,
but the industry wouldn't deploy because the "market" failed to demand
safety.  That is, long-term safety would cut into short-term profits.
The corporate world actually led the public to believe (through
advertising) that they were sufficiently safe without them.  Only
legislation and regulation resulted in measurably greater safety.
M$ has long advertised (falsely) that safety was their concern, and their
systems were already safe.  We all know how that worked out....
So, what campaigns are you working on currently to improve this?
I've educated dozens of U.S. legislators over the years....  Indeed, the
original funding for my NSFnet work 20 years ago was funded by the Michigan
House Fiscal Agency, and my early IETF work was funded by the Levin (Senate)
and Carr (House) campaigns.
The problem, as always, is enough folks that are competent in both
computer security *and* political action.
Cannot say much about McCain/Palin, but the Obama folks have been fairly
computer literate from the beginning.  Not always as security conscious as
I'd like, but some seem to be receptive.  Unlike McCain (who needs help to
get his email), Obama himself seems from reports to be tech-savvy.
We either have to educate more political folks about computer security,
or more security folks have to become active in politics.  The former is
the never-ending long-term problem, while the latter is an effective
sort-term solution.
At the IETF, we used to have a t-shirt, with 9 layers instead of 7.  The
top was "Political", with "you are here" next to it.

@_date: 2009-10-20 09:20:04
@_author: William Allen Simpson 
@_subject: Possibly questionable security decisions in DNS root management 
I agree.  Let's get something deployed, as that will lead to testing.
One of the things that bother me with the latest presentation is that
only "dummy" keys will be used.  That makes no sense to me!  We'll have
folks that get used to hitting the "Ignore" key on their browsers....
Thus, I'm not sure we have time to get this right.  We need good keys, so
that user processes can be tested.

@_date: 2013-12-23 03:33:42
@_author: William Allen Simpson 
@_subject: [Cryptography] RSA is dead. 
"We made the decision to use Dual EC DRBG as the default in
   BSAFE toolkits in 2004, in the context of an industry-wide
   effort to develop newer, stronger methods of encryption. At
   that time, the NSA had a trusted role in the community-wide
   effort to strengthen, not weaken, encryption."
The NSA has *NEVER* been trusted to strengthen security!
Have we forgotten their multi-year effort in the '90s to suborn
key management?  40-bit keys?  Weakening IPsec?  Trying to
prevent SSH from distribution?
   "The carefully worded post, which avoids discussing whether or
   not the company actually took the NSA's $10m, ...."
That itself is an indictment of RSA.  If they are concealing
taking money, then they knew it was wrong.
It's time to DigiNotar RSA.

@_date: 2013-10-11 23:55:12
@_author: William Allen Simpson 
@_subject: [Cryptography] Key stretching 
Yeah, that's a weaker simplification of the method I've always
advocated, stopping the hash function before the final
MD-strengthing and repeating the input, only doing the
MD-strengthening for the last step for each key.  I used this in
many of my specifications.
In essence, the MD-strengthening counter is the same as the 0xnn
counter they used, although longer and stronger.
This assures there are no releated key attacks, as the internal
chaining variables aren't exposed.

@_date: 2013-09-10 21:35:24
@_author: William Allen Simpson 
@_subject: [Cryptography]  Evaluating draft-agl-tls-chacha20poly1305 
Let's get behind this!  It does things a bit differently than I'd choose,
but fits the discussion we had a few months ago (on the companion list)
about the next algorithm to choose, and seems to fit the TLS paradigm.
I applaud moving the ICV outside the encryption.  Phil Karn and I were
advocates of this (for denial-of-service protection) going back long
before there were known theoretical attacks on inner protection.
    ChaCha20 is run with the given key and nonce and with the two counter
    words set to zero.  The first 32 bytes of the 64 byte output are
    saved to become the one-time key for Poly1305.  The remainder of the
    output is discarded.
Why generate the ICV key this way, instead of using a longer key blob
from TLS and dividing it?  Is there a related-key attack?
    Authenticated decryption is largely the reverse of the encryption
    process: the Poly1305 key is generated and the authentication tag
    calculated.  The calculated tag is compared against the final 16
    bytes of the authenticated ciphertext in constant time.  If they
    match, the remaining ciphertext is decrypted to produce the
    plaintext.
If AEAD, aren't the ICV and cipher text generated in parallel?  So how do
you check the ICV first, then decipher?
Needs a bit more implementation details.  I assume there's an
implementation in the works.  (Always helps define things with
something concrete.)

@_date: 2013-09-10 22:59:05
@_author: William Allen Simpson 
@_subject: [Cryptography] Evaluating draft-agl-tls-chacha20poly1305 
It bugs me that so many of the input words are mostly zero.  Using the
TLS Sequence Number for the nonce is certainly going to be mostly zero
bits.  And the block counter is almost all zero bits, as you note,
    (In the case of the TLS, limits on the plaintext size mean that the
    first counter word will never overflow in practice.)
Heck, since the average IP packet length is 43, the average TLS record
is likely shorter than that!  At least half the connection directions,
it's going to be rare that the counter itself exceeds 1!
In my PPP ChaCha variant of this that I started several months ago, the
nonce input words were replaced with my usual CBCS formulation.  That is,
    invert the lower 32-bits of the sequence number,
    xor with the upper 32-bits,
    add (mod 2**64) both with a 64-bit secret IV,
    count the bits, and
    variably rotate.
This gives more diffusion, at least 2 bits change for every packet,
ensure a bit changes in the first 32-bits (highly predictable and
vulnerable), and varies the bits affected among 64 positions.
Note that I use a secret IV, a cipher key, and an ICV key for CBCS.
However, to adapt your current formulation for making your ICV key,
    ChaCha20 is run with the given key and nonce and with the two counter
    words set to zero.  The first 32 bytes of the 64 byte output are
    saved to become the one-time key for Poly1305.  The remainder of the
    output is discarded.
I suggest:
    ChaCha20 is run with the given key and sequence number nonce and with
    the two counter words set to zero.  The first 32 bytes of the 64 byte
    output are saved to become the one-time key for Poly1305.  The next 8
    bytes of the output are saved to become the per-record input nonce
    for this ChaCha20 TLS record.
Or you could use 16 bytes, and cover all the input fields....  There's no
reason the counter part has to start at 1.
Of course, this depends on not having a related-key attack, as mentioned
in my previous message.

@_date: 2013-09-11 12:11:36
@_author: William Allen Simpson 
@_subject: [Cryptography] Evaluating draft-agl-tls-chacha20poly1305 
You mean IV, the Initialization Vector.  ICV is the Integrity Check Value,
usually 32-64 bits appended to the packet.  Each is separately keyed.
I strongly disagree.  In my network protocol security designs, I always
try to think about weaknesses in the implementation and potential future
attacks on the algorithm -- and try to strengthen the security margin.
For example, IP-MAC fills every available zero space with randomness,
while H-MAC (defined more than a year later) uses constants instead.
IP-MAC was proven stronger than H-MAC.
Sadly, in the usual standards committee-itis, "newer" is often assumed to
be "improved" and "better".  So H-MAC was adopted instead.  Of course, we
know that H-MAC was chosen by an NSA mole in the IETF, so I don't trust it.
Also, there's a certain silliness in formal cryptology that assumes we
shouldn't have longer randomness keying than the formal "strength" of the
algorithm.  That might have been true in the days of silk and cyanide,
where keying was a hard problem, but modern computing can generate lots of
longer nonces without much effort.
In reality, adding longer nonces may not improve the "strength" of the
algorithm itself, but it improves the margin against attack.  A nearly
practical attack of order 2**80 could be converted to an impractical
attack of order 2**96....
I don't understand this part of your message.  My ancient CBCS
formulation that I'll probably use for PPP (Xor'ing a per-session key
with a per-packet unique value) is demonstrably much faster than using
ChaCha itself to do that same thing.
We've been using stream ciphers and pseudo-stream ciphers (made by
chaining MACs or chaining block ciphers) to create per-packet nonces
for as long as I can remember (over 20 years).  You'll see that in CHAP
and Photuris and CBCS.
So I'm not arguing with Adam's use of ChaCha for it.  It just bugs me
that we aren't filling in as much randomness as we could!

@_date: 2013-09-11 12:43:04
@_author: William Allen Simpson 
@_subject: [Cryptography] Evaluating draft-agl-tls-chacha20poly1305 
Thanks, this part I knew, although it would be good explanatory text to
add to the draft.
I meant a related-key attack against the MAC-key generated by TLS?
Thereby causing you to discard it and not key the ICV with it?
Oh sure.  We used hashes long ago.  Using AES is insane, but then
UMAC is -- to be kind -- not very efficient.
My old formulation from CBCS was developed during the old IPsec
discussions.  It's just simpler and faster to xor the per-packet counter
with the MAC-key than using the ChaCha cipher itself to generate
per-packet key expansion.
I was simply wondering about the rationale for doing it yourself.  And
worrying a little about the extra overhead on back-to-back packets.
ICV = Integrity Check Value at the end of the packet.  So ICV-key.
Sometimes MAC-key.
Anyway, good explanation!  Please add it to the draft.
Depends on how swamped the processor.  I'm a big fan of rejecting
forgeries (and replay attacks) before decrypting.  Not everybody is
Google with unlimited processing power. ;)

@_date: 2013-09-11 12:55:08
@_author: William Allen Simpson 
@_subject: [Cryptography] Evaluating draft-agl-tls-chacha20poly1305 
I kinda covered this in a previous message.  No, we should design with
the expectation that there's something wrong with every cipher (and
every implementation), and strengthen it as best we know how.
It's the same principle we learned (often the hard way) in school:
  * Software designers, assume the hardware has intermittent failures.
  * Hardware designers, assume the software has intermittent failures.
Sorry, you're correct there -- my mind is often still thinking of DES
with its unicity distance of 2**32, so you had to re-key anyway.
OK.  I see the pipeline stall.  But does poly1305 pipeline anyway?
Aha, I hadn't found this (XSalsa, there doesn't seem to be an XChaCha).
Good reading, and some of the same points I was trying to make here.

@_date: 2013-09-12 00:47:27
@_author: William Allen Simpson 
@_subject: [Cryptography] Evaluating draft-agl-tls-chacha20poly1305 
Come on folks, here's an actual design that could help solve problems!
Give it a look!!!
Having re-read Poly1305 yesterday, I'm not sure I agree yet.  But in a
parallel thread now Metzger is also talking about eliminating side
channels by generating the secret IV in counter mode, and you're
essentially doing the same for the integrity check value (ICV).
So absent deeper analysis, I'll wait and see.
As to inner-MAC in SSL, I argued against it with ElGamal at the time.
But I've never seen a published rationale.  I don't remember anybody
thinking the MAC was weaker than the cipher.  For both 40-bit DES
(remember the horrors?) and RC4, we thought of MD5 as stronger!
As to CBC, I actually prefer it to counter mode.  I just think folks
kept missing the lessons of early designs.
Yes, counter mode allows some limited parallelism.  And that's a good
thing for such as servers to limit latency.
Yet it doesn't buy any improvement on the client side -- it actually
adds scheduling overhead which potentially increases latency.
And for saturated transmission links, the added overhead is a killer.
The data has to be stored and forwarded serially anyway, so no win.
In the days of yore (a Z80 could barely keep up with 56K links) to now
(current processors having problems keeping up with the lambda at full
rate), a good serialized protocol that can do both the cipher and the
integrity check at the same time in the same registers is what we need!
But the killer argument for me against counter mode is that it allows
the well-funded adversary to attempt decrypt or do oracles in parallel,
making the adversary more efficient without a concomitant security gain
for the defender.
I guess the optimum for me would be the ability to encrypt output in
parallel, but only decrypt input serially.
But we're getting far afield of this design.
A fair reasoning.  I agree this is a pretty good design, although not
exactly as I'd have done it -- but we need more eyeballs.  There are a
couple of thousand on this list.  Hopefully others will take a look,
and we can get some community support....  I'll shut up for a bit.

@_date: 2014-08-10 15:19:41
@_author: William Allen Simpson 
@_subject: [Cryptography] Many curves versus one curve 
I've already opined on this topic a couple of weeks ago, but again:
   Never-the-less, all protocols should be designed so that one
   party (usually the responder/server) lists all supported
   algorithms, and the other party chooses from that list.
Good.  However, I have never been of the opinion that everybody
should generate their own curves/moduli, nor that everybody should
check each others' curves/moduli at run time.
Rather, each manufacturer should generate a new set for each
release.  That gives us some confidence that they were made
with some deliberation from well-known processes.  Yet gives us
public opportunity for verification.
Also, regular releases further broadens the base to be attacked,
hopefully to the extent that it no longer makes sense to attack
the individual curves/moduli!
Agreed, I don't expect my light bulb to verify.
Who are we to decide that the application needs the "utmost"
security instead of speed?
Which one?
That's only when there's some sort of guarantee that
they will never use the same parameters.  Known flaws in
random number generators obviate that assumption.
How long ago did I raise this issue on this list?  1999?
That is the argument we've been making for over 20 years.
Embedded devices are the worst case scenario, and still need
variety in curves/moduli.  Why would picking one that turns out to
be bad ever be a good idea?
How do you "prove" that nothing will ever be learned that makes
one become bad in the future?
Better that 20 not yet bad ones are available to choose.  In that
case, the security updater could reliably ignore the bad one, then
update the device with a better list without the known bad.
If all you have is the bad one, you'll never know whether you've
made a good connection, and whether your update itself hasn't been
Again, we've covered all this logic over 20 years ago.

@_date: 2014-01-21 18:30:39
@_author: William Allen Simpson 
@_subject: [Cryptography] RSA is dead. 
I'm surprised at the sudden interest in my month old December 23 post.
No.  NSA had a good reputation in the '60s.  I even recommended a friend for a
position there in the mid '70s.  (AFAIK, he's still there.)
By the '90s, its reputation was dirt.  Because, other than what was known or
suspected about DES, every action they took was to inhibit public use of
NSA was *very* involved in the crypto wars!
Have we forgotten that the NSA mole in the IETF, Steve Kent, removed the
link encryption option from PPP before RFC 1134 publication in 1989?
Have we forgotten that Steve Kent had the NSA (via the FBI) investigate
me for *treason* for posting the PPP CHAP internet-draft circa 1991?
Because that would prevent the security agencies from intercepting
passwords and pretending to be somebody else....  So by then we knew
they were already wiretapping passwords of US citizens and presumably
everybody else.
Hogwash.  In addition to the well-known Clipper chip, and the well-known
40-bit key export:
(A) Have we forgotten that Steve Kent had my 1994 Cypher Block CheckSum
(CBCS) removed from the IETF publication schedule -- because it wasn't
compatible with his Null Encryption option?
AFAIK, CBCS was the first attempt at integrating encryption with
integrity.  Had it been adopted, there would have been no Lucky13, et
And why the heck did we need a null encryption option anyway!
(B) Have we forgotten that Photuris was adopted by acclamation at the
Montreal IETF -- and then Cisco announced they were supporting
My guess is forensic accounting would show that Cisco was paid, just as
RSA was recently.  Whether it was a cash payment or just a promise that
they'd be favorably considered in future bids....
I remember meeting with NSA twice at the supposedly neutral NRL.  Phil
Karn refused to meet with them, even though he grew up in Maryland and
it would have been cheaper for him to meet them.  But I naively thought
that we could come to an agreement.
Their biggest complaint was that Photuris concealed the parties, which
inhibited traffic analysis.  And sure enough, that's still what they
still want today!
All I could get agreement on was expanding the Group-Index field
(renamed Schemes in draft -03) from 8 to 16 bits for them to define
their own.  That took 2 meetings!
(C) Have we forgotten that H-MAC was adopted over IP-MAC, even though we
had already shown that H-MAC was formally less secure than IP-MAC (and
IP-MAC was older and already had had more analysis)?
Why is it that everything NSA supported at NIST (SHA, SHA1, SHA2, ...)
was demonstrably less secure than other proposals?
> As for the rest, the lesson we should take from this is, moving
 > forward, if any company in the future hears the words, "I'm from the
 > NSA and I'm here to help", they should run away, as fast their legs
 > can carry them.
 >

@_date: 2014-07-06 19:32:53
@_author: William Allen Simpson 
@_subject: [Cryptography] Review: The Codebreaker, by David Kahn 
Likewise, read Kahn long before Schneier.  Have a first edition, signed
(to me).
Learned about it when a sweetheart told me Kahn was one of her most personally
influential books on her father's shelf....  (He was a Rand physicist.)  But
she became a database programmer.  A brother became a computer science prof.
I'd also been reading Cryptologia in the university library (this was back in
the stapled pamphlet days.)  I was already doing network protocols and device
drivers.  Later, Schneier came along and influenced me to write security code.

@_date: 2014-07-28 21:05:14
@_author: William Allen Simpson 
@_subject: [Cryptography] IETF discussion on new ECC curves. 
Never-the-less, all protocols should be designed so that one
party (usually the responder/server) lists all supported
algorithms, and the other party chooses from that list.  This
avoids reliance on particular curves, and allows the parties to
choose appropriate strengths.
Who are we to decide that the application needs the "utmost"
security instead of speed?
Moreover, there are too few curves.  We should also encourage as
many good curves to be published and analyzed as possible.
Certainly there are even better to come!

@_date: 2014-09-15 12:49:03
@_author: William Allen Simpson 
@_subject: [Cryptography] RFC possible changes for Linux random device 
Hear hear! I've long been in favor of improving linux [u]random.
I'd prefer an explicitly designed stream cipher, such as chacha20.
We've been making streams ciphers out of block ciphers for a long
time, but there are pretty good options these days.
Almost anything would be better than the old half-md4 slices.

@_date: 2014-09-15 12:55:24
@_author: William Allen Simpson 
@_subject: [Cryptography] RFC possible changes for Linux random device 
Agreed.  Once upon a time, I submitted a patch for Linux to delay
selection of the secret for TCP syncookies, until an actual TCP
packet arrived!  And to change the secret on a regular basis....
David Miller rejected it.  It would really help for Linux to
have more folks who supported (or even understood) security.

@_date: 2015-02-23 03:01:09
@_author: William Allen Simpson 
@_subject: [Cryptography] forward secrecy 
Hogwash.  We specified forward secrecy as a requirement in the
original IPv6 IPSec of 1993 at IETF Amsterdam.  That was only
later weakened due to the NSA mole(s) in the IETF.
Photuris was designed with forward secrecy, with cell phones in
mind -- Karn was employed by Qualcomm -- on 186 cores.
The specifications and first implementation were written and
ran just fine on my x86 laptop running KA9Q NOS circa 1994-95.
By 1996, there were multiple open source implementations.
Commercially, it also ran on RADGuard in the same time frame.
And others that escape my memory....

@_date: 2016-02-10 04:20:58
@_author: William Allen Simpson 
@_subject: [Cryptography] DH non-prime kills "socat" command security 
Which is why all responsible OS vendors ship /etc/moduli -- and
better OS vendors generate and validate their own for every release,
so that we aren't stuck with stale parameters.

@_date: 2016-02-10 04:48:37
@_author: William Allen Simpson 
@_subject: [Cryptography] Basic auth a bit too basic 
# Someone just pointed out an interesting problem with HTTP basic auth,
# published in 1999 as RFC 2617 and updated 15 years later as RFC 7617:
Or PPP CHAP (circa 1991).  Or swIPe cum IPsec (circa 1992-1993).
Or Photuris (circa 1994-1995).
Sadly, the HTTP folks refused to learn from earlier efforts.  I've
always ascribed it to self-censorship in fear of large government
agencies.  Or actual pressure.  And as we now know, payoffs.

@_date: 2017-04-07 10:49:31
@_author: William Allen Simpson 
@_subject: [Cryptography] Should the IV of an encryption operation be 
I proposed this secret IV circa 1993-1994 for the original IPsec,
but also ensured that the IV changed per message by XOR'ing the
Sequence Number into it.
And for Photuris also ensured that it would not be a related key.

@_date: 2017-08-07 10:29:04
@_author: William Allen Simpson 
@_subject: [Cryptography] Finding undocumented opcodes 
It is also useful for cryptography, for providing a nearly uniform
shift count (instead of the more common shift-by-constant used by such
as SHA-1) to unpredictably mix a one-way hashing/"whitening" function.
For example, in the CDC SCOPE/Hustler authentication back in the '70s.
Therefore I used it in CBCS in '94 (as it couldn't be patented),
arguably the first public "authenticated encryption" algorithm.
Unfortunately, on architectures that don't have a population count,
counting is somewhat more expensive than a table lookup.  Happily,
almost all of them have population count now.

@_date: 2017-03-24 16:40:44
@_author: William Allen Simpson 
@_subject: [Cryptography] Google distrusts Symantec for mis-issuing 30, 
As always, we'll just have to cross that bridge when we come to it.
You shouldn't.  Google is a company (now a collection of companies),
not a person.  Since trust is not transitive, although I trust several
folks at Google, that doesn't mean that I blindly trust Google.
The person who caught this at Google has proven trustworthy, and
Semantic as a company has proven untrustworthy (not the first time).
You don't.  AFAIK, there's no reason that you cannot use another
provider of HTTPS certificate verification.
However, you know the old saying: Trust but Verify.

@_date: 2017-09-11 16:29:41
@_author: William Allen Simpson 
@_subject: [Cryptography] ANIMA protocol to "bootstrap a Secure Key 
And there are more bad assumptions.  Trust is not transitive.
The only reason this appears to exist is for tracking by manufacturers
after sale.
Funny that they require each device to "know" its serial number, but
somehow it isn't capable of "knowing" a secret.  Or an internal
random number seed that can be updated per use.
In the real world, nobody drop ships a device without power-on test,
which means there's no actual reason for this protocol.  During
testing, the device can generate its own public-key certificate, and it
can be printed on the label at the same time as the serial number.
Also, it has some need for a DNS.  But most IoT devices shouldn't be
visible in the DNS.  And we spent a lot of cycles re-doing DNSsec
so that exterior entities couldn't see internal DNS.  This leaks.
Finally, I keep laughing at the supposed need for light bulbs to
authenticate.  Terrible example.  Light bulb sockets might, as that's
what the controller will want to control, but light bulbs are just
commodity replacement items.
[shrug] Maybe trying to finesse that it's not a "public" key.  Or maybe
that's what they call it in patents.  This is doubly patent encumbered.
this list.  I suspect he had a lot to do with the circumscribing the
applicability and security considerations.
There are an awful lot of cases where it isn't useful.  At least that's
kinda sorta admitted up front.

@_date: 2018-08-06 09:54:55
@_author: William Allen Simpson 
@_subject: [Cryptography] threat models, 
"Dont just try to shout down the skeptics with a mixture of
   technobabble and libertarian derp."
How does blockchain currency prevent anybody from being "cut off"?
Obviously, you can be cut off by governments.  Several nations
have already taken this step.
But you can be cut off by payment processors of any kind.
The fewer who will take it, the less it's a valuable asset.  You can
accumulate all the blockchain bits you want, but it's rather worthless
after nobody will take it.
A trust market?  How is that valued?
There's been a bunch of derp about "reputation" floated in this
thread.  Reputation doesn't exist as a market.
Heck, I'll go farther: reputation isn't a barrier of any kind.
Bad actors simply change their names.  Do you trust Academi nee Xi
nee Blackwater?
Worse, even with all the controls in the world, exchanges can go
bankrupt.  At which point they also change their names....
Reputation is entirely based upon non-repudiation (to inject a
little cryptology into the discussion), and liability (provably
having sufficient real assets to cover their outstanding balance).
Blockchain currency doesn't have either of those properties.
And as soon as there is no possible exchange, your asset is valued as
Currently, there's a fellow named Manafort who is discovering how
pertinent mapping of real assets is to liability.
Note there was some other libertarian derp mentioned earlier:
"[...] taxing needs to be driven out of the market for good."
Manafort is also learning that just because you've concealed your
currency and tried to conceal your transactions, that doesn't mean
they are not subject to taxes.

@_date: 2018-08-30 09:49:08
@_author: William Allen Simpson 
@_subject: [Cryptography] Is "perfect forward secrecy" the biggest fraud 
I'm not sure whether you are using the term "perfect" forward secrecy
correctly.  Perhaps the definitions have changed over time?
I've taken a quick look at the article, and it only mentions factoring
large numbers.  That's applicable to public/private key pairs.  But
doesn't seem to be applicable to symmetric keys.
Does Signal really only use asymmetric algorithms?
Not even worrying about quantum, circa 1994-1995 we were worried
about other kinds of attacks.  Photuris distinguished between
"forward secrecy" and "perfect forward secrecy".
Forward secrecy was provided by the establishment mechanism of an
ephemeral session key.  Also, independent keys were used for each
direction of traffic.
Perfect forward secrecy required destruction of the signing key
used in the authentication exchange.
Both the signing and shared secrets were used in generating the
session keys, so you'd have to solve multiple hard problems for
every key.
Photuris also provided a Secret Exchange to generate a short
term signing key prior to the session key.  That could be used
multiple times for repeat exchanges and session key rollover,
then easily destroyed.
So you really needed to solve many hard problems for every key.
We figured at that rate, it would be easier to attack the
symmetric algorithms than try to break any keys.
That doesn't help data at rest, the only time you'd need to
re-encrypt.  Are you using asymmetric algorithms for data at rest?

@_date: 2018-02-07 09:13:07
@_author: William Allen Simpson 
@_subject: [Cryptography] RISC-V branch predicting 
Also in kernel level code and even some userland, we already use the
likely() and unlikely() hint functions.
But no matter what is done, the wrong branch will sometimes be taken.
The basic underlying problem is they didn't check access permissions
during the prediction path in exactly the same way as usual.
That created a timing side-channel opportunity.  And those are rather
difficult to fix.

@_date: 2018-07-31 07:05:28
@_author: William Allen Simpson 
@_subject: [Cryptography] Krugman blockchain currency skepticism 
Apparently, there's a blockchain conference coming up at the same time
as many of our other security conferences.
Krugman has a column today that's saying some things that have already
been posted here.  Hopefully will gain traction.
Still, there were a couple of inaccuracies.  So I sent a short message,
but he's traveling and will not likely be able to make corrections.
Your headline today is inaccurate. Could you correct it?
Also, Bitcoin was announced Oct 31, 2008, on the moderated cryptography
mailing list maintained by my long-time collaborator Perry Metzger:
You wrote "eight years". Could you correct that, too?
You are a "blockchain" currency skeptic. Perry has actually gone so far
as to outlaw posts calling it crypto-currency:

@_date: 2018-03-11 06:57:56
@_author: William Allen Simpson 
@_subject: [Cryptography] On those spoofed domain names... 
IIRC, pushed by some Greeks? (and a lot of East Asians).
Agreed.  Amusingly, I had to rescue this message from my spam folder, as
Gmail tells me:
   Be careful with this message. Someone might be trying to trick you by
   using similar looking characters in their email address or links (for
   example replacing the letter "O" with the number "0").
Even with your examples in the body, not the address....
Anyway, this problem goes even farther.  With "zero-touch" Internet of
Things, they want us to trust our lamp/refrigerator/television to be
trusted to bypass the firewall and talk to somewhere outside, simply
because it has some manufacturer's signed certificate in/on it.
That is, because we can read that it says "LG" on the outside, and the
machine itself can verify its own signature, we should trust it.
Trust is not transitive.

@_date: 2018-05-08 21:28:46
@_author: William Allen Simpson 
@_subject: [Cryptography] Security weakness in iCloud keychain 
Here we are almost 25 years later back at Photuris....

@_date: 2018-05-13 09:31:32
@_author: William Allen Simpson 
@_subject: [Cryptography] Single factor with automated change 
Photuris was fairly carefully designed; there were no patents in
the base document.
The Secret Exchange (potential RSA patent) was deliberately
moved to a second document.  That patent expired even before
IESG permitted RFC publication (after 5+ long years), but
they never published the Secret Exchange as an RFC.
Also, the Secret Exchange wasn't dependent on RSA.  It could
use any existing authentication secret to verify the change of
this newly generated replacement authentication secret.
Moreover, all the secrets everywhere had specified lifetimes.
I've long been a believer in limiting exposure via relatively
short lifetimes, rather than revocations.
Finally, everything about Photuris was designed to lower the
incentives for cracking.  Exchanging pre-computed moduli
instead of relying on "well known" ones, so there were no
incentives to build a rainbow table....
That's always been one of my beefs with Elliptic Curves.  No
families, not easy to generate infinite numbers of them.

@_date: 2018-09-10 08:09:38
@_author: William Allen Simpson 
@_subject: [Cryptography] IKE/ISAKMP/IPsec complexity by design 
Some of us remember that somebody from Boston with a 4-character
surname was known to be communicating with "Other Agency" to
prevent publication of IETF security protocols.  And providing the
FBI with information to investigate those of us promoting IETF
security protocols.
Some of us remember that the person (from Boston with a 4-character
surname) who took over the IPsec editor role didn't actually write
his own drafts, and refused to disclose who was writing them.
Has anybody already written an academic (or otherwise) critique of
the complexity of IKE/ISAKMP/IPsec, resulting in difficulty to
implement and deploy?

@_date: 2018-09-22 10:19:20
@_author: William Allen Simpson 
@_subject: [Cryptography] IKE/ISAKMP/IPsec complexity by design 
My FBI file.  Took me 6 1/2 years to get even a partial copy.  It was
scanned in and posted for all to see in '99.  We discussed it on this
list (and elsewhere) at that time....
Now that Trump is declassifying FISA court files, maybe it's time to
see mine?
Really, you shouldn't joke on a mailing list without lots of emojis.
People might think you are serious.
IPsec was *NOT* originally designed by committee.  It was me, Phil
Karn, Perry Metzger, based upon previous work by John Ioannidis and
Matt Blaze, with a lot of text in the SIPP IPv6 WG by Ran Atkinson.
We had to do the work in the SIPP IPv6 WG, because the IAB forbade us
having an IPsec WG.  I was the original IANA registrant of IPv6.  We
later learned that the person on the IAB preventing us scheduling a WG
(or even a BoF) was named Steve Kent.
Unsurprisingly, that's a 4 character name from Boston.  See below.
ESP was quickly weakened by Kent, changing our original secret IV to
"in the clear".  It took a few years, but John Gilmore eventually
proved that change was exactly what was needed to make a practical DES
decryption device.
We posted 3DES, DESX, CBCS, and other enhancements that would make DES
IPsec harder to break.  The IETF refused to publish any of them.
Don't forget my paper, IKE/ISAKMP Considered Harmful, that showed
several ways to bring a Cisco router to its knees.  The IETF refused to
publish.  Fortunately, Usenix thought it important.
There have been many papers since.  The most recent was at Usenix
Security just last month.
They were still using fixed pitch teletypes.  The 4 characters are
blacked out (redacted), but the attribution is Other Agency.
So all we know is Boston, attended IETF at Santa Fe, near Los Alamos.
Mentioned the seriousness of describing a cryptographic protocol to
foreign nationals attending a conference near Los Alamos.  Somehow
the conference location was important to the *treason* investigation.
That paper was PPP CHAP.  Only an authentication protocol.  But from
context we surmise they wanted to be able to learn your password --
so that they could impersonate you on-line.

@_date: 2019-06-14 09:02:41
@_author: William Allen Simpson 
@_subject: [Cryptography] Call for nomenclature... 
So what can I use as the name for a DARE Message?
As I recently suggested for a project that was overloading
"frame", "message", /et alia/: try an unrelated paradigm.
As a musician, I suggested prelude, intro, verse, stanza,
refrain, coda, outro, etc.
Since this is a mesh, you might try electrical engineering
topology terms, such as bridge (also a good music term),
transform, etc.
(I used transform in the original IPsec.)
Memorable names are always helpful!

@_date: 2020-04-30 12:17:00
@_author: William Allen Simpson 
@_subject: [Cryptography] The EFF 650 CAs lie 
Having taken the time to read through the documents, it seems to me
that EFF is correct.  No lying involved.
A Certificate Authority is an authority from whom you obtain a
certificate.  It makes no legal difference whether you personally
sign the certificate, whether you personally operate a root, or
whether the certificate is issued with an "intermediate" root.
This issue is merely one of agency.  I pay you, a certificate is
issued.  Thus, you've demonstrated _control_ of the authority.
Enough of the world's TLS implementations accept it.  Done.
Do I think that the whole CA infrastructure is good?  Of course not.
Do I think there are better models?  I was a strong supporter of
SPKI....  Also, that the Internet distribute certificates via DNS.
But Very Important People (with money) wanted to monetize the
security infrastructure.  This is what resulted.

@_date: 2020-12-23 07:54:40
@_author: William Allen Simpson 
@_subject: [Cryptography] Schneier on US security failure 
All these years, John Gilmore and others have been warning us about supply chain vulnerabilities.
Nice to see widespread international publication.
"If anything, the US?s prioritization of offense over defense makes us less safe."
"We need to adopt a defense-dominant strategy."

@_date: 2020-07-02 13:27:20
@_author: William Allen Simpson 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
[reading some older list items, branching off]
The original IPsec (Karn, Metzger, and Simpson) did not!
Photuris was designed around negotiating variable DH parameters
and avoiding easy denial of service attacks.  From the beginning!
Karn also insisted the option field be limited to 8 bits, so there
would never be many options.  We'd only assign a few combinations
that were well vetted together.
All of that went by the wayside after NSA (and BBN) got involved.
Also, among other things, requiring the IV sent in the clear was
another Steve Kent innovation.  Even though he'd been on a paper
years earlier that the IV should be secret.
And there was the Null encryption option.  And the ability to
negotiate a downgrade.  And the serious problems we published via
Usenix, because IETF wouldn't....
We knew so many things to be wrong.  The best explanation is that
flaws in the resulting IPsec were deliberate.
Thankfully, after a quarter century, TLS 1.3 has almost all the
features we originally presented in 1995.

@_date: 2020-07-06 09:13:57
@_author: William Allen Simpson 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
Correct.  I'm the person who registered IPv6, then called PIPE (Practical
Internet Protocol Extensions).  It had security required, and even required
authentication for getting a globally routable address.
Why should anybody be able to install an internet-capable toaster (or light
or refrigerator or TV) inside your house without authorization?
Why should a TV be able to evesdrop on other traffic inside the house?
I'd also named the "spy" field: Security Parameters Index (SPI).
Lixia Zhang mentioned that Steve Deering was working on something similar
in overall format, so we joined to make SIP (Simpler Internet Protocol).
Steve's interests in multicast and IP mobility became an important part of
the specification, also requiring security.
Paul Francis had some brilliant ideas, and had called his PIP (Polymorphic
Internet Protocol).  In July 1993, we combined to make SIPP.  We all agreed
that security was required.
Circa 1990-1991, Kent prevented the publication of the Cryptographic Handshake
Authentication Protocol (CHAP) in the PPP WG.
As I've written before, around the same time Steve Kent was preventing us from
having an IPsec working group.  At the 1992 San Diego IETF, Kent prevented us
from scheduling an official IPsec BoF.  So Phil Karn organized a series of
lunches that week.
Instead, all the IPsec design took place in the PIPE/SIP/SIPP WG.  None of the
other IPng efforts required security.  (Needed it, but wouldn't require it.)
When we reformed the IAB, Steve Kent was the first against the wall.
Eventually there was an official IPsec WG.  It didn't actually produce anything,
but the general direction was to use some useless IEEE proposals as a basis.
Perry Metzger called me, and over 1994 Christmas week, we ported IPsec from
IPv6 to IPv4.  We called these the "Troublemakers" drafts.
Also, I ported my SIPP mobility design to IPv4.  It also required security.
The "powers that be" reassigned my drafts to other editors, who gutted them,
over objections of the WG members.  Several WG chairs resigned.
Since then, my internet drafts are only posted with restrictions (that I'd
helped write into the IETF standards process).
Institutionally.  IETF is an international organization, and members made
some noise about requiring security.  But profits came before security.
Plus the US apparently bribed major corporations, and infiltrated moles into
our institutions.
Snowden taught us that the US was spending tens to hundreds of millions of
dollars influencing standards bodies.  Mere researchers with our meager
budgets couldn't compete.
Constitutionally, the US guarantees "The right of the people to be secure in
their persons, houses, papers, and effects...."
Most people think that digital communications are the equivalent of papers.
Otherwise, they certainly could be considered "effects" (that is, our works).
An originalist textual argument can be made that the Founders understood
security encompassed confidentiality, integrity, and privacy.

@_date: 2020-07-11 09:57:08
@_author: William Allen Simpson 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
Having given folks a few days to respond....
Sorry, just didn't push a whole hog history in one post.
Yes, a great deal of credit should go to Naval Research Labs' (NRL) running code.
(Also more famously later work on Onion Routing.)
IIRC, Ran Atkinson joined PIPE/SIP/SIPP circa mid-1993, and wrote an architecture
document that he graciously permitted me to reformat and republish (extracts) for IPv4.
But the header formats and details were finalized long before Ran arrived, and mostly
were originally based upon experimental code written for Karn's KA9Q NOS.  There's a
reason that ESP is port 50, and AH is port 51.
And let us not forget swIPe: Came out of those lunch discussions I'd mentioned that Karn hosted.  First posted as an
internet draft, but the IETF wouldn't allow RFC publication.  Published by Usenix.
Also, let us not forget Usenix.  A lot of security would never have happened without a
fearless board at Usenix, willing to defy US government prior restraint efforts.
Yeah, there was more than enough FUD flung around.  Metzger was in the NetBSD
community.  Karn had his own code base that was used in rather a lot of (late
'80s early '90s) products.  I contributed code in both places.
Most significant IPsec development was in *BSD.  Gnu/Linux GPL came years later,
thanks to promotion and funding by John Gilmore.
In addition, Photuris draft -00 was published December 1994.  By summer of 1995,
both session key management and IP packet security were implemented, and
commercially deployed not very long afterward.
Also, I'd like to call out other significant efforts:
Angelos Keromytis (a Greek undergrad) developed a completely independent
implementation circa October 1995.  He is now a full professor.
Niels Provos (a physics grad student in Hamburg) did an implementation that was
interoperable with both Keromytis and KA9Q.  We coopted him into changing majors
and universities, and drove him across the border into Canada to work on OpenSSH,
so it could be _imported_ into the US.  After years doing good security things at
Google, IIRC he's CSO at Stripe.
I've always been pleased to know that our original IPsec design was easy enough to
understand that (brilliant, talented) undergrads, interns, and non-computer
engineers could write interoperable implementations over a summer. ;)
Contrast with IKE/ISAKMP.  Took paid teams, and at least a half dozen bakeoffs and
workshops over a period of several years before interoperable implementations.
Really not most of the IETF participants themselves.  John Gilmore conducted a
hum at the 1996 Montreal open plenary.  Photuris won overwhelmingly.  We had
rough consensus and running code.  We had at least 3 vendors shipping product.
A day later, Cisco issued a press release announcing they would be supporting
only NSA's ISAKMP.  We've always assumed they were paid off in one form or
another by the US.
As you've mentioned, Sun was pushing SKIP.  I'm fairly sure that in addition
to being rather resource intensive, it was patented?
We've seen this in other areas as well.  In subsequent years, Randy Bush has
often referred to the Internet *Vendor* Task Force.
I've not forgotten you!  Is a copy of the NRL code base posted anywhere?

@_date: 2020-07-11 12:19:21
@_author: William Allen Simpson 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
You've got it backward.  The server proposed several DH parameters.  The
client chose among them, but didn't really have time to verify them.
The server then verified the client choice was valid.
We also provided code (eventually integrated into NetBSD among others) to
generate lists of verified DH parameters.  I also documented a file format
(etc/moduli) to store them, that we later re-used for OpenSSH.
The key here is everybody could independently verify that the list of DH
moduli were safe primes.  And nothing would be dependent upon any fixed DH
prime moduli.  And they could be changed on a regular basis, so that
efforts to break them would be futile.  It was intended that every OS
release or security update have a fresh list.
It's very bad.  In the early '90s, we were merely speculating that a secret IV
could prevent a DES hardware cracker of the era from determining the encryption
secret.  Gilmore later proved it.
Note I'm the originator of one of the first AEAD designs, CBCS, in April 1994.
(We didn't yet have the AEAD terminology at the time.)  It XOR'd a secret into
every block, not just the first, using a checksum technique pioneered in the '70s
SCOPE/Hustler CDC operating system.  No patents.
CBCS is faster than MD5 (and much faster than triple-DES), with a side effect of
theoretically strengthening the encryption at least as much as DESX.  Detects
altering, extending, truncating, or swapping the cipher data blocks; and the
trailing checksum was used to verify the integrity before doing the more
computationally expensive decryption.
Also co-author of the July 1997 DES-XEX3 internet draft, too.  But IETF
wouldn't publish that, either.  Nothing more secure than plain old DES with an IV
transmitted in the clear.
[Heavy sigh] Karn worked for Bell Labs and then Qualcomm.  The IP stack in
Qualcomm (and Sony and others') phones was based upon his KA9Q NOS.  I'd
consulted on it and shrunk the IP stack enough to fit in the tiny memory.
Photuris and IPsec were designed to be lightweight enough to run on the 186
core in those phones.  I repeat: a 186, not a 286, not a 386.  Karn wrote an
assembly version of both MD5 and DES.
Karn and I were well aware of the evesdropping issue.  CHAP was originally
proposed circa 1989-1990 as an authentication solution for AMPRnet radios.
Everything else you mention are later developments.  There should never have
been a Null encryption option!
Not a problem for Photuris.  Absolutely everything, every field, and every
field length, verified by crypto.
The designers of IKE/ISAKMP were either incompetent, or it was deliberate.
"ike isakmp considered harmful"
At the time, I owned an ISP.  I could bring a cisco I owned to its knees in seconds.
[Another heavy sigh]  As I've recounted before on this list, back when Netscape was
located near the Stanford campus (I walked there from the computing center), Paul
Mockapetris got me to visit.  I sat down with Taher Elgamal and others, to critique
their early SSL.
Obviously, it has taken decades, and we still cannot get everybody to stop
running SSL or TLS 1.0.
That's what some of us call broken.
Also, see "ike isakmp considered harmful" mentioned above.
Photuris and SSL were both ~1994, before ISAKMP -> Oakley -> IKEv1.
Never forget, ISAKMP was originally defined in ASN.1 ("asinine one").
That was going to become the meta higher layer above ATM (asynchronous
transfer mode).  There's a couple of ideas whose time never came....
A lot of the truly terrible ideas, such as aggressive mode, came from Oakley.
Admittedly, I've stopped looking at IKEv(whatever) many years ago.  Glad
somebody has the stomach, and things are getting better.

@_date: 2020-07-22 14:20:02
@_author: William Allen Simpson 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
But some of us were very much in favor of firewalls.  The issue with NAT
was altering packets.  Also, distributing security secrets to the NAT.
Yes, I for one thought that SIPP (v6) would be rapidly deployed, as we had
strong consensus and running code.  Who knew that the vendors would take
over the IESG, and insist that IPv6 be done over again?
Some of us were thinking about it.  I remember presenting our Authenticated
Firewall Traversal paper(s) circa 1995-96.  At least the ICMP message
actually made it to RFC 2521, publication delayed until 1999.
In my view, that was really the only valid reason for AH, used in an outer
wrapper (using the protocol 4 IP in IP).  The firewall didn't get to see
the confidential traffic.  We had running code.
But various folks hated the idea that the firewall needed a separate secret.
There was a big push to have secret sharing that allowed the firewall to
read the traffic as it went through, because pornography terrorists....
You were not alone.  I'd posted one of the socket interface drafts.
As if they couldn't have upgraded that legacy software over a period of a
few years.  There wasn't much legacy yet in 1995!
Never-the-less, the existing packet filter designs could have turned on
IPsec per socket, as they already filtered per socket.  Fairly sure
SELinux can do something like that.
But the legacy vendors were a problem.  Also their reasoning for tacking
the next header onto the end of the ESP packet.  Terrible idea, caused
already perfectly aligned packets to need extra block cipher padding,
and even fragmentation.
Our original design had things like the port and the protocol chain
negotiated by the session key management per SPI.
For goodness sake, what security is there in allowing the OS or outside
actor to modify things like the port, redirecting to another process???
At one point, I'd added a disclaimer about mutually hostile users.
Prescient, now we see Specter et alia.
Ha, non-amusing story.  When I was at Red Hat, I discovered that their
internal accounting systems only supported very old SSL.  They didn't want
to pay Oracle for the upgrade.  When the browsers stopped supporting it,
they bought F5 appliances to intercept the traffic, downgrade, re-encipher.
Instead of deploying their own RHEL....
Or at least their corporate overlords.

@_date: 2020-07-22 14:35:17
@_author: William Allen Simpson 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
Forgot to mention, not all of us hated NAT entirely.  Paul Francis was the
originator of NAT, RFC 1631, and was actively involved in SIPP (IPv6).
