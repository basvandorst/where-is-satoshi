
@_date: 2014-04-22 00:51:33
@_author: D. Hugh Redelmeier 
@_subject: [Cryptography] GCC bug 30475 (was Re:  bounded pointers in C) 
I don't like the way the C language handles overflow with signed ints.
I think signed overflow should, by default, cause a trap.
But the problem actually lies with the success of the PDP-11.  That
machine uses a pun: signed and unsigned add of two's complement
numbers produce the exact same bits of result from the same bits of
operands.  The only difference is how to interpret the signedness and
overflow of the result.  So the PDP-11 had a single add instruction.
It set a lot of condition bits:  the program could test the bits that
were relevant to the representation intended.  But the computer could
not trap on overflow because it didn't know if there were an overflow.
Contrast this with the IBM/360.  It too used two's complement.  But it
had distinct signed and unsigned add operations (it called the
unsigned operations "Logical").  It could generate a trap on overflow.
Almost all important machines after the PDP-11 copied it in this respect (and much else).
C is a close-to-the-metal language.  The designers didn't wish to
impose inefficiency on the program.  Furthermore, the C Committee
tried to be as hardware-agnostic as they could afford.  So the
committee decided early-on that the result of signed int overflow was
undefined.  This allowed but didn't require trap-on-overflow.
The assertion
is nonsense: it assumes a definition of arithmetic overflow that does
not apply.  I can see that as a human.  But compilers often see tests
that are redundant, and this just looks redundant.
I like my compilers to warn me when I write nonsense.  But like
everyone else, I get on my high horse when there are false positives.
Redundant code that is intended is hard to separate from redundant
code that is a mistake.
I write a lot of assertions that I hope are redundant.  I love it when the compiler can make them free!
I know enough to not write overflow tests that create overflows.  I
write them to prevent overflows.
The first careful work on this issue that I was aware of was by David
Wortman.  It was published 35 years ago:
D. B. Wortman, ?On Legality Assertions in Euclid?,
IEEE Transactions on Software Engineering, Vol.4, July 1979, pp.359-367. I imagine that numerical analysts dealt with these issues earlier.  I can imagine William Kahn railing about this kind of thing.  The problems in floating point are much more, uh, interesting.
In any case, I think that there is a much more surprising (even to me) example of GCC getting rid of a test.  It can eliminate a null pointer test if it is preceded by a dereference of the pointer.  This is well known now:
I am very happy that systems I run trap null dereferences without help
from the compiler.  I like this so much that I once hacked circuits
and the OS on my computer to get this feature.

@_date: 2014-04-23 18:06:09
@_author: D. Hugh Redelmeier 
@_subject: [Cryptography] GCC bug 30475 (was Re:  bounded pointers  in C) 
No, that's not what I said.  I said, roughly, that the pun of treating
unsigned and signed adds as the same operator precluded
trap-on-overflow being free.  The /360 did it right and the PDP-11 did
it wrong (in this regard) and most architectures followed the PDP-11.
That's not what the standard says.  It says: when you go outside the
specs, we don't specify what the result will be.
I want a compiler that says: when you go outside the specs, we'll
catch it and tell you (the language can help or hinder this).  The
market seems to disagree (John Gilmore has pointed this out).
Yes.  But people don't think that they want to use naive compilers.
I suspect (but am too lazy to check) that gcc without -O would
probably generate the naive code that you think you want (it does not
have to).
Anyone who's used one knows that an optimizing compiler will do things
that surprise you.
The language specification is a carefully crafted contract.  I don't
agree with all in the C standard, but it isn't secret.  You no longer
have to pay an arm and a leg to read it.
You say "just what the author intended".  The author is either too
smart or too stupid.  We infer from the code that he knows enough
about overflow to try to catch it (good), he thinks he knows what it
does in his language (wrong, bad).  The rule in C is: don't generate
overflows because all bets are then off.
What's a false abort?
If you don't overflow, the assertion is true.  If there is an
overflow, any result is legal.
You are not programming in machine language.  Stop thinking that you
are getting machine language semantics.
No, programmers really really don't like compilers calling wolf every
time they compile.  And they almost never run lint and its successors.
When programmers see warnings in C, they often throw casts around,
making things worse.
I don't understand how that's a response.  Perhaps I wasn't clear
I like assertions being free.  That means that the compiler has been a
theorem prover, letting me write clearer code.  Think of assertions as
being enforceable comments, the best kind.  That means that the reader
can believe them.  It also means that comment-rot will be corrected.
This is a special case of what optimizers are really good for.  They
are not for making old programs run more quickly, they are for letting
programmers program at a higher, more productive level, leaving the
detailed book-keeping to the computer. War story about assertions: in about 1982 I bought my first UNIX
machine, an 8086-based NABU 1600.  I ported my file compressor.  An
assertion failed.
- first I blamed me for writing code that wasn't portable.  Wrong.
- then I blamed the C compiler (a variant of Ritchie's original,
  ported by Microsoft to the 8086 and not well tested).  Wrong.
- it was a bug in the 8086!  All 8086 processors.  Already shipping
  for about four years.
It took a while to convince them, but Intel came through with a fix.
The architecture manuals were changed: no chips were recalled.  And I
changed the compiler (for me).
The only code that tripped this bug was the assertion itself.  Simply
deleting the assertion made the code work.
The bug?  The shift instruction was supposed to set the condition
code.  But a shift of 0 bits didn't do that on the 8086 or 8088.  It
did on the '186 or higher models.  The 8086 ALU could only shift by
one bit at a time so a shift of n bits went through the ALU n times,
setting the condition code, but when n was 0, ...
That was when chips were simple enough that the bugs could be
Autoconf is an abomination.  General principal that it violates: avoid
complexity, don't try to master it.
"If your code looks like these examples, it is probably safe even
though it does not strictly conform to the C standard."
Horrible advice.
I agree.
If you use substandard programmers, don't use C.
If you use standard programmers, avoid C.
If you have excellent programmers, you are wasting their effort with C.
So what's my excuse for using C?  I understand it pretty well.  It is
pretty stable (eg. my compressor program from the 1970's still works).
It isn't clear what the winning alternative would be.  And there is a
large body of code that I value and support written in C.
(And NSA has used some of my C code!  FreeS/WAN, initiated by John
I've heard people who advocate Python.  I cannot imagine trying to
write secure code in a language without strong typing.  Typing is
again a kind of theorem proving about your program, one that the
compiler can check.

@_date: 2014-04-29 12:26:04
@_author: D. Hugh Redelmeier 
@_subject: [Cryptography] Intel experimental tool.... 
I'm not sure what you are seeing in that blurb that I'm not.
It's all about code, lifted by one kind of abstraction.  Details are a
bit fuzzy (since it is a short puff piece).
Algebra is a much higher and more powerful abstraction.
Machines (and humans) can do algebra better than program optimization
partly because algebraic transformations are unencumbered by nasty
details like side-effects and bounded representations.
I don't see a new threat here.  At least not to systems with a sound
theoretical basis (i.e. algebraic).
(I'm using the word "algebraic" in a somewhat loose "you know what I
mean" way.)
I think that you are saying that computational difficulty can be
reduced, surprising the designer.  Either it is visible at the
algebraic level or it is a constant-factor implementation detail.
I'm not sure what you are saying here.  Perhaps that "what the
compiler has the machine doing" doesn't match "what the programmer
thinks the machine is doing".  Or even: the programmer knows what he
wants the machine to do but cannot direct the compiler to get this to
happen.  When you have concerns that are not expressable in the programming
languange semantics, you are in trouble.  C's "volatile" is a tool
that many seemed to think would solve their problem.  Unfortunately,
everyone read into the semantics what they wanted.  It actually
doesn't promise enough to meet most folks expectation.
Heck, even at the machine language level you cannot get the memory
destruction that you may want: think of caching and the details like
snooping, cache-line width, etc.  Also speculative execution.  And
flash memory.  Swapping.  SMM. ...

@_date: 2014-02-28 15:32:17
@_author: D. Hugh Redelmeier 
@_subject: [Cryptography] GOTO Considered Harmful 
Sorry for being dense: could you explain how it doesn't work?
I'm too lazy to read the code, but surely you must have found a bug so
you ought to point it out.
That doesn't count because failed is explicitly set to 0 at the
beginning.  If you can pretend that there is any change anywhere, then
all code doesn't work.

@_date: 2015-01-01 17:27:09
@_author: D. Hugh Redelmeier 
@_subject: [Cryptography] on brute forcing 3DES to attack SIMs 
Since 3DES takes 3 DES operations, that suggests that their brute
forcing of 3DES-with-partially-known-keys takes the same number of
trials as brute forcing of DES.
Apparently 3DES can be used with three keying options: use one, two,
or three 56-bit+parity keys.  I've only used it with three 56-bit keys.
When used reasonably, it is a LOT harder to brute force than 3DES.  (I
don't see how using one 56-bit key for 3DES is reasonable.)
So I think that either:
- their partial knowledge of the 3DES key is quite significant (56 or
  112 bits?) OR
- the 3DES is using only one 56-bit key.
PS: I know that there are meet-in-the-middle attacks on 3DES but that
isn't going to apply on the same hardware that was used to attack DES.

@_date: 2015-11-14 20:56:58
@_author: D. Hugh Redelmeier 
@_subject: [Cryptography] Nvidia- one Tflop could change the rules quicker 
TFLOP grates since FLOPS means FLoatingpoint Operations Per Second.
Of course English speakers instinctively think that the S is to make
it plural, but that s isn't in the acronym.  It sure would be clearer
if the industry had chosen / in place of P.
Floating point operations would not seem to be the most useful kind
for crypto.  Of course GPUs can do integer operations too.
There's something funny about how all the PR about this board only
talks about "deep neural networks".  Does that mean it isn't so good
at other things that GPUs have been used for?
Right now desktops with GPUs are cheaper per TFLOPS.
These might be good at floating point operations / joule.
I suspect that the interconnect between the ARM CPU and the GPU is
faster than a PCIe bus.  This might be important.
This card is probably less interesting than the chip.  Not sure
how well a pile of them can be interconnected.
For some reason, bitcoin miners preferred AMD GPUs (before they
switched to ASICs).  I understand that AMD cards were faster than
NVidia cards for the crypto operations.
AMD APUs have been widely available for some time and AMD has been
pushing a shared address space between the CPU and GPU.  NVidia has
only recently gotten a CPU core to fuse with their GPU.  Their first,
the Tegra K1, uses a 32-bit ARM and that's not so great for heavy
crunching.  The Jetson TX1 uses the Tegra X1 chip with a 64-bit ARM core.

@_date: 2015-10-25 17:13:30
@_author: D. Hugh Redelmeier 
@_subject: [Cryptography] letter versus spirit of the law ... UB delenda 
Crashing is generally a better policy than continuing with a wrong
answer.  This forces bugs to be noticed and to be fixed.  (Throwing
an exception instead of crashing would be OK except that programmers
would start to write code that intended to generate exceptions.)
In the work up to the first C standard, I kept an eye on what signed
overflow and "undefined" meant.  I intended to implement a debugging
compiler that would abort the program if signed overflow happened.  As
I understood the standard, this was a legal interpretation.  I am not
sure that it is true of subsequent revisions.
It used to be that it was possible on ordinary hardware to get an
exception on integer overflow for free.  IBM/360, for example.  For
an extreme example, see the IBM 709 Divide and Halt instruction.
To make that work, if unsigned and signed arithmetic were supported,
the architecture needed distinct signed and unsigned instructions.  On
the /360: A for signed add, AL for unsigned.  The PDP-11 designers
decided that since the values (in twos complement) were the same, the
distinction would be left in the condition code, for subsequent
instructions to interpret.  Every machine since the PDP-11 seems to
have copied this.
This made trapping on overflow expensive so nobody did it.  Intel 8086
even had an instruction "INTO" (Interrupt if overflow flag set) that
apparently nobody used (I think it got dropped from follow-on architectures).
If overflow traps, a signed type is no longer closed under those
operations.  But we were only pretending that the type is closed on
non-trapping machines: in place of overflow we get
wrong values.  What we do lose is associativity.
vs	(maxint + 1) - maxint
The second traps but the first does not.  With the normal
implementation these expressions compute the same value.
Associativity is useful for optimization.
If I were redesigning C, I would make it the compiler's job to ensure
that a mathematically correct value were computed from each
expression.  If the programmer then took such a correct value and
assigned it to a too-narrow variable or parameter, that would be an
error.  By the "as-if rule", most wide arithmetic could be optimized
away.  I have not studied how much extra this would cost.  It would
make C a lot simpler.

@_date: 2015-10-27 23:28:56
@_author: D. Hugh Redelmeier 
@_subject: [Cryptography] RIP Tommy Flowers 
Apparently he got his MBE in 1943.  I wonder if the award was secret then.
It's all a matter of definitions and qualifications.  One could argue
that the abacus (and precursors) were digital computers.
Perhaps you feel that a computer needs a program.  I don't really know
the whether the Colossus' tape was what we'd consider a program.
Perhaps you meant to add "electronic".
And why not one of Zuse's machines?  Or Atanasoff's?
I thought he was at Dollis Hill.
I've always wondered how one could come up with a meaningful figure.
In any case, just imagine how much shorter the war would have been if the Allies had widely used systems half as good as Enigma.  Read, for example, Marks' "Between silk and cyanide" to see how bad it was (recommended to me by Hugh Daniel RIP, former member of this list). Another example: if I remember correctly, codes used by Allied shipping were always broken by the time they were deployed.

@_date: 2016-04-15 15:21:03
@_author: D. Hugh Redelmeier 
@_subject: [Cryptography] Canadian Police Had BlackBerrys Global 
I'm not sure of the issue here.  Am I missing something?
My understanding (inferred) has been that anyone owning the BES* can
read the BBM traffic going through it.  Law enforcement (or other
security folks) can go after that owner.
For ordinary mortals, the BES is run by Blackberry (or perhaps the
phone company).  And governments regularly compel them to produce the traffic.
A few years ago, a few countries wanted access to traffic.  In the
end, all it took to appease them was Blackberry placing their BES in
the country so local traffic would be accessible to the government.
That still left the corporate BESes in a different situation.  If the
government wanted access to their traffic, they'd need a production
order for that company and the company would know it was the subject
of an investigation.
As I understand it, it is even practical for a modest sized company to
run a BES.
* BES stands for Blackberry Enterprise Server.  I don't know what it
would be called when run by Blackberry -- probably something different.

@_date: 2016-08-27 00:31:21
@_author: D. Hugh Redelmeier 
@_subject: [Cryptography] tail recursion in C [was Re: "NSA-linked Cisco 
If the last act of a function is to call another function, that call
can be compiled as a goto (plus some conversion of the current
function's activation record into the parameters for the new
function).  Tail recursion optimization is a special case of this.
This is purely an implementation feature.  I cannot think of anything
in C that precludes this optimization.  Just culture?
This optimization confuses programmers trying to debug the result,
but then so do many optimizations.
Slide to crypto relevance:
Optimization can destroy some properties that one might have
intentionally coded into a program.
If you carefully coded all paths through a loop to take the same time (to avoid timing sidechannel attacks) an optimizer might re-introduce them.  If you clear variables to avoid having sensitive values laying around, an optimizer might detect that the clearing is redundant and eliminate it.
GCC optimization has been known to eliminate assert calls that would
have fired.  Technically, these optimizations were correct but the
result was unsafe for human programmers.  Roughly, if your code
dereferences a pointer, that tells the compiler that it may assume
that the pointer is non-Null; a subsequent test of that pointer for
NULL may then be assumed to yield false.

@_date: 2017-12-01 22:56:08
@_author: D. Hugh Redelmeier 
@_subject: [Cryptography] Intel Management Engine pwnd 
I'm not sure if this is what you are talking about.
I have a device (Dell Venue 11 Pro) that implements this.  And it
doesn't implement normal "sleep" mode (the Wikipedia article claims
that the IntstantGo specification forbids support for Sleep and
Hibernate modes).  It is horrible with Linux because Linux doesn't
know how to use the new lowish power mode.  So when I close the V11p,
it stays warm and the battery drains.
I would guess that Linux doesn't support this mechanism because it
isn't publicly documented.  But I don't know.
I don't know how widely this "standard" is adopted, but I think that
it is on the Microsoft Surface Pro devices too.
The V11p does seem to turn off when requested.  I have not checked if
the battery continues draining.  To be honest, I barely use the
machine because sleeplessness is so annoying.
Microsoft, Intel, and PC manufacturers seem to copy bad features of
the phone and tablet world.  Perhaps envy will be the death of them.

@_date: 2018-11-02 13:49:36
@_author: D. Hugh Redelmeier 
@_subject: [Cryptography] Ten years ago today 
This demonstrates how bitcoin is used for buying drugs, not stamps.  Vancouver is famous for even stronger drugs.

@_date: 2019-07-16 17:27:18
@_author: D. Hugh Redelmeier 
@_subject: [Cryptography] Apollo Guidance Computer as Bitcoin mining rig 
Not totally fair.  If you were really trying to mine on the Altair,
you'd microcode it.  The article mentions this.  That would likely
make it at least 10 times faster (pure guess).
- 400000 instructions/second for compiled BCPL vs
  6000000 microcode instructions/second
- "the SHA-256 algorithm makes heavy use of Boolean operations
  including exclusive-OR and OR. These are pretty basic instructions
  that you'd find on even something as primitive as the 6502, but the
  Alto doesn't have them"
  I'm pretty sure that the microcode does have these operations
  because the ALU is a naked sn74181 and that has such functions.
- "SHA-256 heavily uses bit shift and rotate operations.
  Modern processors typically have a "barrel shifter" that lets you
  shift by as many bits as you want in one step. The Alto's shift
  instructions, on the other hand, only shift a single bit. Thus, to
  shift by, say 10 bits, the Alto code calls a subroutine that performs
  10 separate shift instructions."
  The microcode does only have a one-bit shifter but it can also
  rotate by 8 bits (a byte swap, I guess).  To efficiently shift
  by 8 bits, one could exploit this feature.
  Also, since the words are 16 bits, shifting a larger entity by 16
  bits can be probably be accomplished by shuffling the words.  One
  could thus implement a shift by 10 as a shuffle and a shift by 6 (10
  = 16 - 6).
- the microcode seems to have an RSEL (register select field) of 5
  bits so it likely has 32 registers (of 16 bits).  If that is enough
  to calculate a hash, the speedup would be considerable.

@_date: 2020-07-11 12:05:42
@_author: D. Hugh Redelmeier 
@_subject: [Cryptography] "Home router warning: They're riddled with known 
Nice resource!
I was part of the FreeS/WAN project.
In 2006, I read an ad for the Linksys WRV200.  It was marketed as a
Wireless G VPN Router.  I was intrigued and read the manual.  They
mentioned an IPSec feature that only FreeS/WAN had (bare RSA keys for
authentication).  So I knew that it was running our code.
I bought one.
It did not actually support bare RSA keys, even though it was
documented in their manual.  Support said that was a bug in the
manual, not in the router.
I went looking for the GPLed source.  For one thing, I wanted to
re-enable that feature.  The source was not available.
I asked Linksys, several ways, for a copy (as per the GPL).  None was
forthcoming.  I didn't sue them.  They eventually made source
downloadable (6 months later?  I don't remember).  It could not be
built and it didn't correspond to the binaries they shipped.
Meanwhile, the community was up in arms because the router was an
unreliable piece of junk, through multiple firmware releases.  And I
couldn't fix it.  (Mind you, the unreliability was probably not in
FreeS/WAN; it may even have been in the hardware.)
I did hear the excuse that the WRV200 was made by Gemtek and thus out
of control of Linksys.  But Linksys put their name on it.  I don't
remember whether Cisco owned Linksys at the start but they did during
the products lifetime.
Anyway, I have never used that router.  I barely ever turned it on.  Sad.

@_date: 2020-07-11 15:00:24
@_author: D. Hugh Redelmeier 
@_subject: [Cryptography] "Home router warning: They're riddled with known 
I'm not sure what you mean by "for this scenario".
The Raspberry Pi can run OpenWRT, a distro tuned for routers.  Two
wired ethernet interfaces would be useful -- you could use a USB3 to
1G ethernet dongle.
What I use is little PCs with two ethernet interfaces (LAN-facing and
WAN-facing) (more interfaces would sometimes be better). For the last
few years, these have been inexpensive Zotac ZBoxes.  I run stock
Linux distros on them, configured and maintained by me.
I originally used PCs as gateways so that I could run our FreeS/WAN
IPsec implementation on the gateways.  You can get commercial routers
that do IPsec but I don't choose to trust them.
In my area, all the cable modem / router / AP boxes supplied by the
cable company can have all but the modem function turned off.  They
call this "bridge mode", which kind of implies that there is a router
still there but isn't doing anything (the term makes no sense in terms
of modem functionality).
All of the xDSL modem / router / AP boxes that the phone company has
forced on me have supported "bridge mode".
Do the suppliers in your area prevent you using "bridge mode"?  Only
if they do are you forced to double NAT.
I haven't done IPv6 due to laziness.  My cable ISP offers IPv6 subnets
I run a recursive DNS server on my gateway.  But my ISP can see the
traffic since it is in the clear.  I don't run PiHole (to blackhole
ad sites) but many do.
All you ask for can be done with a bog standard Linux distro.
Downside: you have to figure it out.
