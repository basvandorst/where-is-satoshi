
@_date: 2002-02-01 11:09:37
@_author: D. A. Honig 
@_subject: An attack on the 'Trusted Traveler' Pass 
So does an attack.  Befriend someone with such a card, give
her a gift with well hidden, unscented plastique and a barometric
detonator.  After some time she takes her planned flight and gets only a
cursory exam.  She neglects to mention the gift she's carrying (they don't
even ask the 2 security questions reliably, any more, anyway).  It worked over Lockerbie, it'll work again.  The Lockerbie carrier
had the equivalent of a "trusted traveller" card --she was a white

@_date: 2002-01-14 09:36:50
@_author: D. A. Honig 
@_subject: CFP: PKI research workshop 
More demos: You can create your own cert with TinySSL, a lightweight ( <
100Kbyte) server for Wintel, and amuse your friends if they bother to read
the info there.  Using trademarks (RSA, Verisign, etc.) in the fields
would escape most.  Or, as the TinySSL docs advise, you can get a free
cert from Thawte --which *in fact* certifies only that you can receive
email at the address you gave them.
As others have written, great for enabling SSL's confidentiality, nothing

@_date: 2002-01-15 06:16:45
@_author: D. A. Honig 
@_subject: CFP: PKI research workshop 
No, its more.  SSL sans certs is like using envelopes to write to
Dear Abby.  You have no authentication on who Dear Abby "really is" but your communications are private.
Since the entity who claims to be Dear Abby also gives
a communications address, writing to Dear Abby at that address is sufficient. (Modulo MIM attacks)
[Moderator's note: Except that's precisely the point: "Modulo MIM
attacks" is like saying "we're all immortal, modulo death". The
question isn't some sort of mystification of identity -- it is being
able to know that you're talking to the same "Dear Abby" your friends
have talked to and that you talked to last week. Now that MIM attacks
have been automated they don't even need sophistication to conduct. --Perry]
When you call a phone number listed with an advert, and give them your credit card number, you have less
confidentiality (you're speaking plaintext), but its the same model.

@_date: 2002-01-15 10:48:30
@_author: D. A. Honig 
@_subject: CFP: PKI research workshop 
Here you're talking about "reputation of nyms", which doesn't require
third parties or certs, just well-kept secret keys of a PK pair.  If the remote entity keeps using the same PK keys, you can reasonably
update reputation
based on that alone.   (They're essentially signing their behaviors.)
[Moderator's note: I fully agree. I was disputing only the notion that
unauthenticated connections were sufficient. Authentication does not
require certificates or third parties -- see the way SSH handles keys
for example. --Perry]
Since a signed cert is useful for recovering ZERO dollars from the signer,
if you've been defrauded by some entity, the end result is the same if a MIM defrauds you.  A *trusted* signer would solve the confidentiality loss problem but not the
liability problem.  But given that signers will sign *anything* (and why
not, they have no
financial liability and little useful reputation to lose) this is a small

@_date: 2002-01-17 13:34:56
@_author: D. A. Honig 
@_subject: Stego applications for other file types 
mp3stego works fine, though I don't think anyone's published
a StegDetect-like analysis of steg signatures.  Remember to use original material (not a published
CD) for the covertext, if you're using it for real.

@_date: 2002-01-25 17:58:00
@_author: David Honig 
@_subject: biometrics 
The lesson I learned from the excellent reverse engineering of
various smartcards is this: if the device is in someone's possesion,
*they* should be interested in not tampering with it.  (E.g., When a bank's
card is in a cracker's wallet, this is not the case.)  Which party the
sensor should belong to depends on the app.  For some apps the other party
may insist that you use their sensor; for some, you might insist on
keeping your fingerprint (etc) in your smart card.

@_date: 2002-01-27 10:53:55
@_author: David Honig 
@_subject: A risk with using MD5 for software package fingerprinting 
Um, right.  A good company would have *design* reviews, but would it really
spend time having skilled engineers review *all* the actual codelines
(given time to market pressure, tedium limits, etc.)?  An individual with write access to their part of a source-control-system is all
you need.  Remember, you could buy Aldrich Ames (wife included) or Hanssen (just him) for under 1.5 mill $USD each.  Perhaps certain
core operations are studied with >2 eyeballs, but all you need is
one breach to undermine security.
I would like to learn about *code* review practices in whatever
is considered a 'sophisticated' software company.

@_date: 2002-01-28 07:48:46
@_author: David Honig 
@_subject: A risk with using MD5 for software package fingerprinting  
I have done enough years of chip testing AND architectural
Nice piece.  When I was writing Verilog for Blowfish and IDEA, we
got interested in how to verify that the chip did what the code described.
Esp. because you hand over your output to other internal groups who transform
it into other forms (e.g., standard cell netlist, then GDSII masks, etc.)
We were thinking about using reverse-engineering services who could
strip, image, and reconstruct a netlist, to confirm that the logic
did what it was supposed to (and in our case, nothing else).  The equivalent
of reverse-compiling from assembler --or microcode!  We never got that far,
