
@_date: 2001-09-13 02:46:05
@_author: Matt Blaze 
@_subject: The tragedy in NYC  
Here are my thoughts and fears, which I sent to IP earlier this evening.
I find myself overwhelmed by emotion.
I'm a native New Yorker - I was born here and have lived here almost
continuously all my life.  I love this city as much as a person can
possibly love a place; the loss of the World Trade Center and the
literally countless lives taken by this senseless and cruel attack
feels intensely personal.  Yes, I'm angry - part of me is consumed by
a visceral, irrational rage that makes me thirst for terrible
vengeance to be brought upon the murderers responsible for this
outrage.  Mostly though, what I feel can only be described as
revulsion.  When I first saw the video of the Trade Center towers
collapsing I became physically ill.  I what I really want is simply
for this never to have happened - or at least to ensure that it never
be allowed to happen again.  Whatever the cost.
This, far more than the awful prospect of further terrorist attack, is
what scares me.  My fear is that the terrorists will prove to have
already won.  Not by destroying our buildings, but by scarring us into
abandoning the values that give our society its greatness.
Over the weeks and months to come, people of good will, leaders who
truly believe they have our best interests at heart, will be looking
for ways to make it impossible for this to happen again.  The
temptation to trade away our freedoms will be irresistible, the
pressure to take decisive action, whatever its effect on liberty and
privacy, overwhelming.
My own experience with this, in the calmer times before yesterday, was
focused on the debate over cryptography.  I believed then, and
continue to believe now, that the benefits, to our security and
freedom, of widely available cryptography far, far outweigh the
inevitable damage that comes from its use by criminals and terrorists.
I believed, and continue to believe, that the arguments against widely
available cryptography, while certainly advanced by people of good
will, did not hold up against the cold light of reason and were
inconsistent with the most basic American values.  The debate took
years, and was painful at times for all of us on both sides of it, but
was, in retrospect, a sign of our democracy's good health.  We did not
resolve the cryptography debate emotionally or in secret, but rather
through a political and legal process weighted heavily to favor the
protection of individual rights.
Our collective resolve to maintain the freedom, openness and diversity
that so enriches and defines our society will soon be put to its
greatest test in generations.  Compelling reasons will be offered for
curtailments and restrictions on our ability to travel freely and
spontaneously, to keep private matters confidential, and to speak and
conduct business anonymously.  Pressure will be brought on the
designers of computing and communication infrastructure to include
surveillance capability as primary design criteria, alongside
efficiency and performance.
As a technologist involved in networking I have a special respect for
the awesome and subtle power of architecture.  I worry about the
robustness of systems designed with back doors, the potential for
failure in centrally controlled and managed networks, the weakening of
the end-to-end model that made the Internet such a natural success.
My worries take on a special gravity when I consider how pervasively
connected our communication architecture has become to the fabric of
our democracy.  Like it or not computers and networks, as much as our
Constitution, are now endowed with the power to either protect us from
or make us more vulnerable to evils like unreasonable search and
I fear that we will be seduced into accepting what seem at first blush
as nothing more than reasonable inconveniences, small prices to pay
for reducing the risk that terrorism happens on our soil again,
without assessing fully the hidden costs to our values and to the
robustness of our society.  Worse, I fear that we may allow these
things to simply happen, without the debate and exposure that an
informed open society would and must demand.
I'm not suggesting for a moment that we ignore the threat of terrorism
or fail to defend ourselves against an increasingly sophisticated and
obviously determined enemy.  But we will have decisions to make about
the direction we want and expect our society to take, and we must not
make them lightly or passively.  Now would not be a bad time for all
Americans to re-read the Bill of Rights and to reflect on the power
and wisdom of the hard choices that maintaining these rights forces us
to make.  We are not, it is abundantly clear, a society built on
Many commentators, in the media and elsewhere, have observed that
September 11th will be remembered as the day that everything changed
in America.  Yes, everything changed yesterday, but we needn't allow
it to change us.
Matt Blaze
New York, 12 September 2001

@_date: 2003-01-08 20:32:46
@_author: Matt Blaze 
@_subject: DeCSS, crypto, law, and economics  
Huh?  DVD region coding doesn't prevent this at all; ripped decrypted
DVD mpeg files could be played anywhere.
The DVD region code scheme would, however, be mildly effective in reducing
the utility of (encrypted) DVD images by making them playable only on
players from the original market.  But as others have pointed out, there
aren't any consumer DVD writers that can write out an entire image, so
this wouldn't happen anyway with current products.
By the way, import region-free DVD players *are* available, quite
legally, within the US, as are non-region 1 disks.  Kim's video in NYC
is one source.  They are all unfamiliar off brands, however - you won't
find Sony or Matsushita (deliberately) producing one.  The main reason such
players aren't more popular or commonly available here is not the DMCA,
but rather lack of consumer demand.  Most popular movies are available and
cheapest on a region 1 version of the release. It's people outside North
America who buy most of the multi-region players, primarily to take
advantage of the region 1 market.  North American consumers of multi-region
players and other regions' disks are mostly just fanatics like me who
have less mainstream taste and want the few disks that aren't available
for region 1.

@_date: 2003-01-21 11:02:25
@_author: Matt Blaze 
@_subject: Patents as a security mechanism 
Patents were originally intended, and are usually used (for better
or for worse), as a mechanism for protecting inventors and their
licensees from competition.  But I've noticed a couple of areas where
patents are also used as a security mechanism, aiming to prevent the
unauthorized production of products that might threaten some aspect of a
system's security.
One example close to home is the DVD patents, which, in addition to
providing income for the DVD patent holders, also allows them to prevent
the production of players that don't meet certain requirements.  This
effectively reduces the availability of multi-region players; the patents
protect the security of the region coding system.
Another example I've found is in the world of mechanical locks, where
one of the biggest security threats to users comes from the unauthorized
duplication of keys.  High-security lock manufacturers try to create
key designs that are novel enough to be patented, and advertise the
patents (and the fact that keys have tightly controlled distribution)
as a selling point.  Many users actually prefer these patented products
because even though it means they might have to pay monopoly prices for their
keys, it makes it less likely that a thief will be able to get a duplicate
at the corner hardware store.  I'm a bit skeptical about whether this
really is effective (and at least one legal case, Best v. Ilco, casts some
doubt on the validity of many of the key blank patents) but it's standard
practice in the lock industry.
Are there other examples where patents are used as a security mechanism?

@_date: 2003-10-01 23:32:46
@_author: Matt Blaze 
@_subject: Monoculture  
I must admit I'm baffled, and rather appalled, to be seeing supposed
advocates of cryptography suggesting, in effect, that cryptologic
education somehow perpetuates a guild system or that deployed security protocols need not be measured against the current state of
the art.
It might be debatable whether only licensed electricians should
design and install electrical systems.  But hardly anyone would argue
that electrical system designers and installers needn't be competent
at what they do.  (Perhaps most of those who would advance such arguments
were electrocuted or killed in fires before they had a chance to make
their case).
The sad fact is that if one wants to be taken seriously as cryptographer,
one needs to learn cryptology.  The good news is that there are few,
if any, artificial barriers to doing so.  Those of us who seek to
increase the pool of talent and see more widely deployed cryptography
can best do so by making the subject accessible to newcomers and those
in related fields.  We do everyone a disservice by patronizingly
encouraging or tolerating poor designs in deployed systems, however well
intentioned they may be.

@_date: 2003-09-06 13:53:14
@_author: Matt Blaze 
@_subject: USENIX Security '04 Call for Papers 
USENIX SECURITY '04 - AUGUST 9-13, 2004 - SAN DIEGO, CA
CALL FOR PAPERS
The USENIX Security Symposium brings together researchers,
practitioners, system administrators, system programmers, and others
interested in the latest advances in security of computer systems.
The 13th USENIX Security Symposium will be held August 9-13, 2003 in
San Diego, CA.
If you are working on any practical aspects of security or
applications of cryptography, the program committee encourages you to
submit a paper.  Submissions are due at 23h59 (Pacific time) January
25, 2004.  The symposium will span five days: Two days of tutorials
will be followed by a two and one half day technical program, which
will include refereed papers, invited talks, Work-in-Progress reports,
panel discussions, and Birds-of-a-Feather sessions.
IMPORTANT DATES
Submissions Due:         25 January 2004
Notification to Authors: 31 March 2004
Camera-Ready Papers Due: 18 May 2004
Program Chair:
Matt Blaze, AT&T / University of Pennsylvania
Program Committee:
Bill Aiello, AT&T Labs - Research
Tina Bird, Stanford University
Drew Dean, SRI International
Carl Ellison, Microsoft
Eu-Jin Goh, Stanford University
Sotiris Ioannidis, University of Pennsylvania
Angelos Keromytis, Columbia University
Patrick McDaniel, AT&T Labs - Research
Adrian Perrig, Carnegie-Mellon University
Niels Provos, Google
Greg Rose, Qualcomm
Sean Smith, Dartmouth College
Leendert van Doorn, IBM Research
Paul van Oorschot, Carleton University
Dave Wagner, University of California, Berkeley
Rebecca Wright, Stevens Institute of Technology Invited Talks Co-Chairs:
Vern Paxson, ICSI
Avi Rubin, Johns Hopkins University
SYMPOSIUM TOPICS
Refereed paper submissions are solicited in all areas relating
to systems and network security, including: Note that USENIX Security is primarily a systems security conference.
Papers whose contributions are primarily in the area of new
cryptographic algorithms or protocols, cryptanalysis, electronic
commerce primitives, etc, may not be appropriate for this conference.
REFEREED PAPERS & AWARDS Papers that have been formally reviewed and accepted will be presented
during the symposium and published in the symposium proceedings. The
proceedings will be distributed to attendees and, following the
conference, will be available online to USENIX members and for
One author per accepted paper is offered a $200 discount against the
registration fee; USENIX will waive the fee for presenters for whom
the fee would present a hardship.
Awards may be given at the conference for the best overall paper and
for the best paper that is primarily the work of a student.
TUTORIALS, INVITED TALKS, PANELS, WIPS, AND BOFS In addition to the refereed papers and the keynote presentation,
the technical program will include tutorials, invited talks, panel
discussions, a Work-in-Progress session (WiPs), and Birds-of-a-Feather
Sessions. You are invited to make suggestions regarding topics or
speakers in any of these sessions via email to the contacts listed
below or to the program chair at sec04chair at usenix.org.
Tutorials for both technical staff and managers will provide
immediately useful, practical information on topics such as local
and network security precautions, what cryptography can and cannot
do, security mechanisms and policies, firewalls, and monitoring
systems. If you are interested in proposing a tutorial or suggesting
a topic, contact the USENIX Tutorial Coordinator, Dan Klein, by
email to dvk at usenix.org.
Invited Talks
There will be several outstanding invited talks in parallel with the
refereed papers. Please submit topic suggestions and talk proposals
via email to sec04it at usenix.org.
Panel Discussions
The technical sessions may include topical panel discussions.
Please send topic suggestions and proposals to sec04chair at usenix.org.
Work-in-Progress Reports (WiPs)
The last session of the symposium will be a Works-in-Progress
session. This session will consist of short presentations about
work-in-progress, new results, or timely topics. Speakers should
submit a one- or two-paragraph abstract to sec04wips at usenix.org by
18h00 on Wednesday, 11 August, 2004.  Make sure to include your name,
affiliation, and the title of your talk. The accepted abstracts
will be posted on the symposium Web site after the symposium. The
time available will be distributed among the presenters with each
speaker allocated between 5 and 10 minutes. The time limit will be
strictly enforced.  The schedule of presentations will be posted at
the symposium.
Birds-of-a-Feather Sessions (BoFs)
There will be Birds-of-a-Feather sessions (BoFs) Tuesday, Wednesday
and Thursday evenings. Birds-of-a-Feather sessions are informal
gatherings of persons interested in a particular topic. BoFs often
feature a presentation or a demonstration followed by discussion,
announcements, and the sharing of strategies. BoFs can be scheduled
on-site, but if you wish to pre-schedule a BoF, please email the
conference office, conference at usenix.org. They will need the title of
the BoF with a brief description, the name, title, affiliation, and
email address of the facilitator, your preference of date, and whether
an overhead projector and screen is desired.
PAPER SUBMISSION INSTRUCTIONS
Papers should represent novel scientific contributions in computer
security with direct relevance to the engineering of secure systems
and networks. Submissions should be finished, complete papers.  Papers
should be about 8 to a maximum of 16 typeset pages (10 point type on
12 point leading).  Submissions must be received by 23h59 (Pacific
time) on 25 January, 2004.
Submissions will only be accepted electronically via the symposium Web
form, and must be in PDF format (e.g., processed by Adobe's Acrobat
Distiller or equivalent). Note that LaTeX users can use the "dvipdf"
command to convert a DVI file into PDF format. Please make sure your
submission can be opened using Adobe Acrobat 4.0.  For more details on
the submission process, authors are encouraged to consult the detailed
author guidelines at To ensure that we can read your PDF file, authors are urged to follow
the NSF "Fastlane" guidelines for document preparation
( and to pay special
attention to unusual fonts.
A link to the web submission system will be available on the
symposium web site, at  on or about
1 January, 2004.
All submissions will be judged on originality, relevance, and
correctness.  The USENIX Security Symposium, like most conferences and
journals, requires that papers not be submitted simultaneously to
another conference or publication and that submitted papers not be
previously published elsewhere, or subsequently published within 12
months of acceptance at the Symposium. (We may share information about
submissions with the program chairs of other conferences considering
papers during the review period.)  Papers accompanied by
non-disclosure agreement forms will not be considered.  All
submissions are treated as confidential, both as a matter of policy
and in accord with the U.S. Copyright Act of 1976.
Authors will be notified of acceptance by 31 March, 2004.  The
camera-ready final paper due date is 18 May, 2004.  Each accepted
submission may be assigned a member of the program committee to
act as its shepherd through the preparation of the final paper.
The assigned member will act as a conduit for feedback from the
committee to the authors.
Specific questions about submissions may be sent via e-mail to
the program chair at sec04chair at usenix.org.
The current version of this call for papers can be found online at
 .

@_date: 2003-09-29 12:15:43
@_author: Matt Blaze 
@_subject: New authentication protocol, was Re: Tinc's response to "Linux's answer to MS-PPTP"  
It's also worth pointing out that the standards for authentication /
key exchange / key agreement protocols (and the techniques for
attacking them) have improved over the last few years, to the point
that if you want your protocol to have any chance of being taken
seriously, you'd better have both a clear statement of why your
protocol is an improvement over those in the existing literature,
and some kind of proof of security under an appropriate model.
Key agreement turns out to be a surprisingly hard problem, especially
in any context that's to be used in a real protocol.  (For evidence of
this, you need look no further than the fact that research papers on
the subject are still being written and published in competitive
conferences and journals).  Even defining the security model under
which such protocols should be analyzed is a hard problem and the subject
of current research.
It is probably no longer acceptable, as it was just a few years ago,
to throw together an ad-hoc authentication or key agreement protocol
based on informal "obvious" security properties, without a strong
proof of security and a clear statement of the model under which the
security holds.
For some recent relevant papers, see the ACM-CCS '02 paper my colleagues
and I wrote on our JFK protocol (
and Ran Canetti and Hugo Krawczyk's several recent papers on the design
and analysis of various IPSEC key exchange protocols (especially their
CRYPTO'02 paper).

@_date: 2003-09-29 12:58:59
@_author: Matt Blaze 
@_subject: New authentication protocol, was Re: Tinc's response to "Linux's answer to MS-PPTP"  
But of course I meant the url to be
I don't know what I could have been thinking; I don't use the
program that produces files with that extension unless a gun is
pointed to my head.

@_date: 2003-09-30 17:25:34
@_author: Matt Blaze 
@_subject: Monoculture  
Oh come on.  Are you willfully misinterpreting what I wrote, or
did you honestly believe that that was my intent?
No one - at least certainly not I - suggests that people shouldn't
be allowed to invent whatever new protocols they want or that some
"union card" be required in order to do so.  However, we've learned
a lot in recent years about how to design such protocols, and we've
seen intuitively "obviously" secure protocols turn out to be badly
flawed when more advanced analysis techniques and security models
are applied against them.
Yes, the standards against which newly proposed protocols are measured
have increased in recent years: we've reached a point where it is
practical for the potential users of many types of security protocols
to demand solid analysis of their properties against rather stringent
security models.  It is no longer sufficient, if one hopes to have
a new protocol taken seriously, for "designers" to simply throw a proposal
over the wall to users and "analysts" and hope that if the analysts
don't find something wrong with it the users will adopt it.  Now
it is possible - and necessary - to be both a protocol designer and
analyst at the same time.  This is a good thing - it means we've made
progress.  Finally we can now look at practical protocols more
systematically and mathematically instead of just hoping that we
didn't miss certain big classes of attack.  (We're not done, of course,
and we're a long way from discovering a generally useful way to look
at an arbitrary protocol and tell if it's secure).
Fortunately, there's no dark art being protected here.  The literature
is open and freely available, and it's taught in schools.  And unlike
the guilds you allude to, anyone is free to participate.  But if they
expect to be taken seriously, they should learn the field first.
I'd encourage the designer of the protocol who asked the original question
to learn the field.  Unfortunately, he's going about it a sub-optimally.
Instead of hoping to design a just protocol and getting others to throw
darts at it (or bless it), he might have better luck (and learn far
more) by looking at the recent literature of protocol design and analysis
and trying to emulate the analysis and design process of other protocols
when designing his own.  Then when he throws it over the wall to the rest
of the world, the question would be not "is my protocol any good" but
rather "are my arguments convincing and sufficient?"
I suppose some people will always take an anti-intellectual attitude
toward this and congratulate themselves about how those eggheads who
write those papers with the funny math in them don't know everything to
excuse their own ignorance of the subject.  People like that with
an interest in physics and engineering tend to invent a lot of
perpetual motion machines, and spend a lot of effort fending off
the vast establishment conspiracy that seeks to suppress their
brilliant work.  (We've long seen such people in cipher design, but
they seem to have ignored protocols for the most part, I guess
because protocols are less visible and sexy).
Rich, I know you're a smart guy with great familiarity (and
contributions to) the field, and I know you're not a kook, but
your comment sure would have set off my kook alarm if I didn't
know you personally.
Me too.

@_date: 2003-09-30 18:02:40
@_author: Matt Blaze 
@_subject: Monoculture  
Speaking of plumbers and electricians, it occurs to me that while
it would be very difficult to find pipe fittings designed without
taking into account static and dynamic analysis or electric wiring
designed without benefit of resistance or insulation breakdown tests
(basic requirements for pipes and wires that nonetheless require
fairly advanced knowledge to understand properly), equipping a house
with such materials might actually end up being safe.  The inevitable
fire might be extinguished by the equally inevitable flood.

@_date: 2004-07-08 11:42:20
@_author: Matt Blaze 
@_subject: Question on the state of the security industry (second half not necessarily on topic) 
Last month I had a rather good experience with American Express
in this regard.  I recently moved and had ordered something
to be shipped to my new address (this was before I changed my
billing address with AMEX).  Apparently the merchant had Amex
verify the transaction, and so AMEX called me.
Naturally, I asked how I was supposed to know it was really them
calling.  Without missing a beat, the caller invited me to hang
up and call back the number on the back of my card, which I did.
After the usual exchange of information to establish my "identity,"
I was transferred to the right department, and ended up speaking with
the same person who had originally called me(!).
After confirming the validity of the transaction in question, I
asked how many people are as suspicious as I was in asking for
confirmation that it's really AMEX calling.  He said not many,
but a significant enough number that they're ready to handle it
routinely when it happens (he also congratulated me for my
It's nice that they have a procedure for this, but it's still a
mixed success for security against the theft of sensitive personal
information.  People like me (us?) remain the exception rather
than the rule, and while it's comforting that the standard procedures
accommodate us, the vast majority of people appear to happily give any
information requested to whoever calls them.  And when banks and
credit card issuers make calls requesting sensitive information
as part of their routine operations, they're training their customers
to engage in exactly the same behavior that they should be trying to
Perhaps a better procedure would be to always simply ask the customer
to call back the known, trusted contact number (e.g., as printed on
the card), and never ask for any personal or sensitive information
in an unsolicited call.  They could widely advertise that this is
always the procedure and ask customers to be alert for any caller
who deviates from it.

@_date: 2005-08-17 00:09:29
@_author: Matt Blaze 
@_subject: Webcast of crypto rump session this year! 
And for those who didn't catch this bit on the webcast (or in person):
The Bletchley park trust wants to sell off the building that houses the
Colossus rebuild and turn it in to housing.
Another group, the Bletchley Park Heritage (run by, among others,
the amazingly interesting Tony Sale) hopes to buy the land and
preserve and expand the project.
For those not familiar with it, the Colossus rebuild is a remarkable
engineering effort to reconstruct what was arguably the world's first
electronic computer.
They BADLY need cash.

@_date: 2005-01-09 21:39:48
@_author: Matt Blaze 
@_subject: Safecracking for the computer scientist 
I've been thinking for a while about the relationship between the
"human-scale" security systems used to protect the physical world
the cryptologic and software systems that protect the electronic
world.  I'm increasingly convinced that these areas have far more
in common that we might initially think, and that each can be
strengthened by applying lessons from the other.
I've started writing down much of what I've learned about a
particularly interesting area of "high-end" human-scale security --
safes and vaults.  A draft survey of safe security from a CS
viewpoint, "Safecracking for the computer scientist," is at:
     This is a big file -- about 2.5MB -- and is heavily illustrated.
This is the same paper that was slashdotted last weekend, but I
figured some here may not have seen it and may enjoy it.

@_date: 2005-01-29 14:19:24
@_author: Matt Blaze 
@_subject: Weaknesses in RFID-based transponders 
A group of computer scientists at Johns Hopkins and RSA Labs
is reporting practical attacks against the TI "Digital Signature
Transponder" RFID chip, which is used, among other things, to
secure many automotive "transponder" ignition keys and the
"SpeedPass" payment system.  Their paper is available at
    The results are also mentioned in today's New York Times, at
    Aside from the practical significance of this work (a thief
may be able to copy your ignition immobilizer and payment
transponder from a short distance away without your knowledge
or cooperation), it nicely illustrates yet again the increasing
convergence of cryptology, computer security and physical security,
as well as the importance of exposing any security technology to
scrutiny before it is fielded.
 From a cursory scan of the paper, it appears that these attacks
could have been easily avoided had the designers of the system
followed well known, widely accepted computer security practices
such as the use of well-scrutinized algorithms and, most importantly,
not depending on easily discovered "secrets".  Unfortunately, as
this work demonstrates, many designers of both computer and
physical security systems have yet to take these principles

@_date: 2006-02-03 16:09:50
@_author: Matt Blaze 
@_subject: serious threat models 
Yes, it's not at all clear from these stories just what was
going on or how "high tech" the attack would have to be. What does
"diverting" to a prepaid mobile mean?  Here's a possibility:
they "social engineered" or otherwise compromised the target account
to assigned it a new telephone number and forward the old number
to a prepaid account they control.  The "interceptor" box acts
as a "man in the middle" that receives calls at this prepaid account
and forwards them back to the target's "new" number (all the
while recording the content).
Such an arrangement would allow interception of incoming calls (but
not outgoing calls, unless they managed to get those forwarded
as well somehow -- perhaps there's a GSM feature that can do that,
too).  Cumbersome, but has the advantage to the attacker of not
requiring any custom software or features on the switch or
cryptanalysis of the over-the-air interface, just garden-variety
subscriber account compromise and cobbling together a couple of
off-the-shelf GSM handsets.

@_date: 2006-03-28 05:32:45
@_author: Matt Blaze 
@_subject: Creativity and security 
Heh, that's marvelous.
I touched briefly on the awfulness of restaurant payment protocols in my
2004 paper from the Cambridge Protocols Workshop, which you may enjoy:
    M. Blaze. "Toward a broader view of security protocols."
    12th Cambridge International Workshop on Security Protocols.
    Cambridge, UK. April 2004.

@_date: 2007-02-12 17:03:32
@_author: Matt Blaze 
@_subject: Failure of PKI in messaging 
I'm all for email encryption and signatures, but I don't see
how this would help against today's phishing attacks very much,
at least not without a much better trust management interface on
email clients (of a kind much better than currently exists
in web browsers).
Otherwise the phishers could just sign their email messages with
valid, certified email keys (that don't belong to the bank)
the same way their decoy web traffic is sometimes signed with
valid, certified SSL keys (that don't belong to the bank).
And even if this problem were solved, most customers still
wouldn't know not to trust unsigned messages purporting
to be from their bank.

@_date: 2007-01-26 17:58:16
@_author: Matt Blaze 
@_subject: Intuitive cryptography that's also practical and secure. 
I was surprised to discover that one of James Randi's "million dollar
paranormal challenges" is protected by a surprisingly weak (dictionary-
based) commitment scheme that is easily reversed and that suffers from
collisions. For details, see my blog entry about it:
    I had hoped to be able to suggest a better scheme to Randi (e.g., one
based on a published, scrutinized bit commitment protocol).   I don't know of any that meets all his requirements, the most important
(aside from security) being that his audience (non-cryptographers
who believe in magic) be able to understand and have confidence in it.
It occurs to me that the lack of secure, practical crypto primitives and
protocols that are intuitively clear to ordinary people may be why
cryptography has had so little impact on an even more important problem
than psychic debunking, namely electronic voting. I think "intuitive
cryptography" is a very important open problem for our field.

@_date: 2007-01-30 16:53:15
@_author: Matt Blaze 
@_subject: Intuitive cryptography that's also practical and secure. 
Yes, and randomized hashes (which many of these applications require
to make them secure) seem especially likely to invite this sort of
ill-informed -- but intuitively attractive -- speculation.

@_date: 2008-08-13 14:42:25
@_author: Matt Blaze 
@_subject: Security by restraining order 
The EFF yesterday filed a letter from a number of academic security  urging the judge in the MIT "Charlie Card" case to reverse the  order.  It can be found on the EFF's case page, at
    As a security researcher (and one of the signers of the letter to the  judge), I was
particularly struck by the ironic -- and very unfortunate -- message  that the court
order sends to our community:  it's safer to irresponsibly blindside  users and vendors
by publishing about vulnerabilities without warning them first (thus  denying them
the opportunity to seek a pre-publication gag order).
Surely that's not what that the court or the MBTA seek to encourage  I blog a bit more about this at

@_date: 2008-08-26 10:52:58
@_author: Matt Blaze 
@_subject: road toll transponder hacked 
I believe that's correct.  In fact, the plate recognition technology  use seems to be good enough to make the transponder itself redundant.
I know several people with E-Z Pass who disconnected the internal
battery of their transponder (out of concern that there might be
hidden readers around town that track vehicles at places other than
toll gates).   Even with dead transponders, their accounts are still
charged accurately when they pass toll gates.  (The sign displays "EZ  not read" or some such thing, but the account is debited within a day
or two anyway).

@_date: 2008-12-27 14:21:14
@_author: Matt Blaze 
@_subject: Domestic surveillance and warrantless wiretaps 
Like many people, I found last week's Newsweek cover
piece, revealing Thomas M. Tamm as the principal source
for James Risen and Eric Lichtblau's 2005 NY Times story
that broke the warrantless wiretap story, to be a riveting
But I actually found a sidebar to the story even more
interesting. That story talks about the now famous 2004
incident at Ashcroft's hospital bed in which several
top DoJ officials threatened to resign. It turns out
that was not about warrantless content  collection,
but rather about the wholesale collection of call
   This story raises a number of new -- and ultimately
quite disturbing -- questions about the nature of the
wiretap program and the extent of its reach into the
domestic communication of innocent Americans.  In
particular, put together with other reports about the
program, it seems to corroborate claims that telcos
(including my alma matter AT&T) provided the NSA with
wholesale access to domestic call detail records, and
that top DoJ officials worried seriously that this
violated the law.
I discuss the implications of this in more detail on
my blog; perhaps some here will find it interesting:

@_date: 2008-02-29 17:12:24
@_author: Matt Blaze 
@_subject: Rewriting the cryptography debate 
============================== START ==============================
So I recently re-read Lawrence Wright's controversial piece in the
New Yorker profiling Director of National Intelligence Mike McConnell.
While the piece's glimpse into the administration's attitudes toward  and warrantless wiretaps have gotten much attention, I was particularly
struck by this paragraph:
      In the nineties, new encryption software that could protect        conversations, faxes, and e-mails from unwarranted monitoring  was coming
      on the market, but the programs could also block entirely legal        to eavesdrop on criminals or potential terrorists. Under        direction, the N.S.A. developed a sophisticated device, the  Clipper Chip,
      with a superior ability to  encrypt any electronic  transmission; it also
      allowed law-enforcement officials, given the proper authority,  to decipher
      and eavesdrop on the encrypted communications of others.  Privacy advocates
      criticized the device, though, and the Clipper was abandoned by  1996. "They
      convinced the folks on the Hill that they couldn't trust the  government to
      do what it said it was going to do," Richard Wilhelm, who was  in charge of
      information warfare under McConnell, says.
This seems to me a significant re-writing of history, and the Wilhelm  quote a particularly
disingenuous interpretation of recent events.  In fact, Clipper died  on the vine due to
technical problems that rendered it ineffective for its intended  purpose (to say nothing
of the extravagance of being implemented in an expensive tamper- resistant ASIC).  And
key escrow and crypto export controls died (in 2000) not from an act  of Congress (which
never actually voted on any cryptography legislation), but from  unilateral action within
the executive branch.  In 2004, the Bush administration further  liberalized the crypto
export control policies of the previous administration, which I  believe had (and still
have) strong bipartisan support.
While Clipper certainly was a lightning rod for criticism on privacy  grounds, the changes
in policy that eventually occurred can hardly be attributed to some  sort of frightened
capitulation to an out-of-control privacy lobby, as the quote implies.
I blog a bit more about this at

@_date: 2008-07-02 14:23:14
@_author: Matt Blaze 
@_subject: Security and Human Behavior workshop 
There was a terrific interdisciplinary workshop this week at MIT on
"security and human behavior".  Organized by Ross Anderson and
Bruce Schneier, the idea was to bring together security researchers
from diverse fields who don't normally talk with each other: computing,
psychology, economics, criminology, sociology, etc.
There weren't any new earth shattering research results presented;  the idea was to inspire security thinkers who should be learning from  other (but often don't) to reach outside their own disciplines.   There's a
lot to learn.
Bruce's comments, with links to an agenda and position papers, are on  blog at:
    Ross liveblogged the sessions at:
    I recorded most of the sessions, for those who enjoy listening to hours
of noisy, out-of-context audio of events they didn't attend.  MP3s can
be found at:

@_date: 2008-07-25 17:30:46
@_author: Matt Blaze 
@_subject: Surveillance, secrecy, and ebay 
One of the less-discussed risks of widespread surveillance is
not just the abuse or misuse of intercepted content and meta-
data by the government, but its accidental disclosure. As
more and more private data gets collected, and as it sits
around for longer and longer, it becomes inevitable that some
of it will end up in surprising places.  No malice is required;
it's practically impossible to avoid.  And this is not merely
a hypothetical concern.  Case in point:
I recently indulged myself with a used Nagra SNST tape
recorder, a beautifully-engineered miniature reel-to-reel
device that was especially popular with law enforcement and
intelligence agencies from the 70's to the 90's.  (Hey, I'm a
old-school geek -- I like gadgets.)
The recorder came with with a tape reel, which I had assumed
was blank or erased. But a couple of days ago, I decided to
double check just to be sure.  To my surprise, the the tape
wasn't blank at all.  It contained a recording of a "wired"
confidential informant being sent out to buy drugs on behalf
of a state police agency in 1996.
The recording was pretty innocuous and boring, to be honest
(the deal never happened, and most of the tape is the sound
of a car being driven to the buy location).  But there was
a disturbing element: the tape contained the full names of both
the suspect and the supposedly "confidential" informant!
I've got an MP3 of the tape on my blog.  The names of the
hapless informant and suspect have been muted out in the name
of good sense:
   Unfortunately, this is hardly an isolated incident; this sort of
inadvertent disclosure of sensitive information -- stuff that
could cause people real harm -- happens all the time.  And law
enforcement agencies can be among the most carless offenders.  A
couple of years ago, when my grad students and I were studying
telephone wiretaps and were buying up surplus law enforcement
wiretapping gear, we were disturbed to discover that almost none
of the equipment we bought had been sanitized before being sold
off.  Pen registers bought from several different agencies (on
ebay and other places) generally were delivered in the state in
which they were last used, configured complete with suspect's
telephone numbers and call detail records
None of this should be terribly surprising.  It's becoming harder
and harder to destroy data, even when it's as carefully controlled
as confidential legal evidence. Aside from copies and backups made
in the normal course of business, there's the problem of obsolete
media in obsolete equipment; there may be no telling what
information is on that old PC being sent to the dump, where it
might end up, or who might eventually read it.   More secure storage
practices -- particularly transparent encryption -- can help here,
but they won't make the problem go away entirely.   Once sensitive
or personal data is captured, it stays around forever, and the
longer it does, the more likely it is that it will end up somewhere
unexpected.  This is yet another reason why everyone should be
concerned about large-scale surveillance of the kind recently
authorized by Congress; it's simply unrealistic to expect that the
personal information collected will remain confidential for very

@_date: 2008-05-05 20:17:58
@_author: Matt Blaze 
@_subject: OpenSparc -- the open source chip (except for the crypto parts) 
In particular, while it's certainly true than an expert can often  unexpected security-related behavior by careful examination of source
(or object) code, the absence of such a discovery, no matter how
expert the examination, is no guarantee of anything, for general  and hardware designs.
And on a slight tangent, this is why it was only with great  reluctance that
I agreed to participate in the "top-to-bottom" voting system reviews
conducted last year by California and Ohio.  If flaws were found (as  were), that would tell us that there were flaws.  But if no flaws had
been found, that would tell us nothing about whether any such flaws were
present.  It might just have been that we were bad at our job, that the
flaws were subtle, or that something prevented us from noticing  them.  Or
maybe there really are no flaws. There'd be no way to no for sure.
I ultimately decided to participate because I suspected that it was  based on the immaturity of the software and the apparent lack of  engineering in the design process for these systems, that we would find
vulnerabilities.  But what happens when those are fixed?  Should we then
conclude that the system is now secure?  Or should we ask another set
of experts to take another look?
After some number of iterations of this cycle, the experts might stop  vulnerabilities.  What can we conclude at that point?
It's a difficult question, but the word "guarantee" almost certainly
does not belong in the answer (unless preceded by the word "no").

@_date: 2008-05-08 15:04:49
@_author: Matt Blaze 
@_subject: How far is the NSA ahead of the public crypto community? 
During the 1980's and 1990's "crypto wars", an occasional topic of  speculation was
just how much the NSA was ahead of the open/public/academic  cryptography research
community in cryptanalysis and cipher design.  We wondered (and still  whether the NSA was merely a strong center of expertise, a bit ahead  of the rest
of us by virtue of their focused mission and culture, or were they  more of a
crypto-mathematical superpower, possessing amazing techniques that  demolish every cipher in the public domain?
For those of us in the unclassified world, there has relatively  little evidence
to go on beyond the occasional tantalizing technical nugget, and even  have been hardly uniform in their message.  The impressively well- resistance of DES to differential cryptanalysis (apparently called the
"tickle attack" on the inside years before Biham and Shamir's result)  and the
narrow -- but apparently solid -- resistance of Skipjack to various  new attacks
suggests a remarkably sophisticated set of decades-old cipher design  and analysis
tools that the civilian world is only beginning to catch up with.  On  the other
hand, there have been blunders, like the early problems with SHA and  the protocol
weaknesses in Clipper, that suggest that the NSA's crypto toolkit  might not be
all that much sharper than ours after all.
Anyway, there's now a bit more fuel for speculation.  The latest  batch of (still
partly redacted) publicly-released NSA technical and historical  includes several policy papers from the 1990's that touch on NSA's  over crypto in the face of an increasingly sophisticated public research
community (among other factors).  I found one of the most interesting  frustratingly censored) new documents to address this point was  "Third Party
Nations: Partners and Targets" from Winter 1989:
     This paper discusses the pros and cons (from the NSA's perspective)  of sharing
cryptologic technology with other countries.  The specifics  (presumably naming
names of the countries concerned) are all redacted, but what remains  is a
hypothetical dialog between "liberal" (pro-sharing) and  "conservative" (anti-
sharing) internal viewpoints.  Page 8 of the PDF (marked as page 17)  the general spread of cryptographic expertise.    Interestingly, both  liberal and the conservative sides acknowledge the rapid development  of public
cryptographic expertise, and this was back in 1989.  The conservative  relied here not on the NSA's better crypto-mathematics (an advantage  they seemed to believe was shrinking), but rather on the large gap  the theory and actual deployment in the non-NSA world (a problem that we
here have long recognized).
Anyway, this isn't big news, since it's essentially what most of us have
suspected all along, but this is the earliest document I'm aware of from
inside the NSA to explicitly address the question.
Personally, I suspect the NSA does have a large advantage in SIGINT
technologies, but in those areas, like demodulation of unknown signals,
for which there's less of a civilian research interest.  The vibrant
crypto research community, on the other hand, has probably evolved to
the point of being a serious competitor to NSA.
On a side note, I've also been enjoying filling in some of the redacted
gaps in the various technical papers.  I was particularly delighted
to discover a fun little paper on safecracking (an analysis of the
keyspaces of safe locks), which was very similar to part of a survey I
published a few years ago.   I discuss what's likely in some of the
redacted material from that paper in a recent blog post at

@_date: 2008-05-09 15:48:30
@_author: Matt Blaze 
@_subject: How far is the NSA ahead of the public crypto community? 
I've heard similar recollections of mathematicians from improbably
abstract specialties being eagerly taken in by NSA, throughout the
cold war.   I've also heard it said that at one time NSA was the
US's single largest employer of math PhDs.  I don't know if that
was actually true, but it certainly seems plausible.
But it's also important to remember that crypto isn't the only
area of the NSA mission that benefits from mathematical expertise.
I suspect that while many of these NSA math PhDs were indeed doing
cryptomathematics, a large fraction were (and are) working on
other SIGINT problems such as signal processing, databases and
searching, coding theory, machine learning, and so.  Some of the
(non-crypto) problems here seem rather specific to the NSA's domain,
and so don't likely have an advanced civilian research community
competing with them they way academic crypto does today.
A couple of the papers from the 1970's hint (in redacted form,
frustratingly)  that the NSA then had large scale automatic systems
for intercepting and processing morse code signals from large
blocks of radio spectrum, which implies some pretty advanced
(for that era) signal processing and computing, crypto aside.

@_date: 2009-05-02 15:00:36
@_author: Matt Blaze 
@_subject: SHA-1 collisions now at 2^{52}? 
I must admit I don't understand this line of reasoning (not to pick
on Perry, Greg, or Peter, all of whom have a high level of
crypto-clue and who certainly understand protocol design).
The serious concern here seems to me not to be that this particular
weakness is a last straw wedge that enables some practical attack
against some particular protocol -- maybe it is and maybe it isn't.
What worries me is that SHA-1 has been demonstrated to not have a
property -- infeasible to find collisions -- that protocol designers
might have relied on it for.
Security proofs become invalid when an underlying assumption is
shown to be invalid, which is what has happened here to many
fielded protocols that use SHA-1. Some of these protocols may well
still be secure in practice even under degraded assumptions, but to
find out, we'd have to analyze them again.  And that's a non-trivial
task that as far as I know has not been done yet (perhaps I'm wrong
and it has).  "They'll never figure out how to exploit it" is not,
sadly, a security proof.
Any attack that violates basic properties of a crypto primitive
is a serious problem for anyone relying on it, pretty much by

@_date: 2010-09-19 20:23:52
@_author: Matt Blaze 
@_subject: Czech intel agency allegedly offered "tax free cash" to local crypto vendor to incorporate defects 
I don't know anything beyond this this news story, but interesting...

@_date: 2011-08-10 12:06:48
@_author: Matt Blaze 
@_subject: [Cryptography] Vulnerabilities (in theory and in practice) in P25 
Our (Sandy Clark, Travis Goodspeed, Perry Metzger, Zachary Wasserman, Kevin Xu and me) Usenix Security paper on vulnerabilities in the P25 two-way radio system (used by public safety agencies in the US and elsewhere) is out today.
   for the paper (pdf format) and
   for a summary of mitigations.
