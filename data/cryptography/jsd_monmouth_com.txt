
@_date: 2002-04-14 13:33:42
@_author: John S. Denker 
@_subject: Error in Applied Cryptography 2nd Ed 
Finding errors in _Applied Cryptography_ is like finding
sand on the beach.
My favorite example is the discussion of modular arithmetic
and Galois fields, on pages 254 and 255.  These errors are
pretty amazing, considering the pivotal role modular arithmetic
plays in modern crypto.
 1) It says modular arithmetic on integers is a finite field whenever the modulus "is prime or the power of a large prime".
I don't think so.  For integers, the modulus had better be a plain old prime.  (If the modulus were of the form p^n, then p itself would be a zero-divisor ... not good.)  And BTW, if powers of primes were allowed, the "largeness" of the prime would not be part of the definition.
 2) It says "A polynomial that is a generator in a given field is called primitive".  That is not the way the term
"primitive" is defined in any math book I've ever seen.
The mis-definition is obviously inconsistent with the statement a few paragraphs later that "the trinomial must be primitive" when using it as a modulus;  obviously you can't have something
that is both a generator and a modulus!
The standard definition is that if the monomial x is a
generator in the field modulo a polynomial p[x], then p[x] is primitive.  This definition captures the property
that is important to technology, because the monomial x
represents a simple shift of a shift register.  So when
choosing a modulus, it's smart to choose one that is
primitive in the standard sense. Note that "primitive" is also mis-defined in [HAC] chapter 2 (def. 2.214) but the correct definition is given in [HAC] chapter 4 (start of section 4.5).
 3) The table of values of n "for which x^n + x + 1 is
primitive" is out to lunch.  The given n values correspond
roughly (but with errors) to irreducible polynomials, but
only some of these are primitive.  It even lists n=1, for which the given from is not even a trinomial.  The tables chapter 4 of [HAC] appear to be much more trusthworty.
 4) It says that in a generator, "all its coefficients
must be relatively prime".  I don't think so.  It's obvious that you want their GCD to be unity, but that's
a very different statement.
Remark:  I asked Mr. Schneier about this and he blew
me off.
[AC} _Applied Cryptography_ by Bruce Schneier.  There is a page of errata at
  [HAC] _Handbook of Applied Cryptography_ by Alfred J. Menezes, Paul C. van Oorschot and Scott A. Vanstone.
The whole book can be downloaded (subject to restrictions)
from

@_date: 2002-08-01 18:15:35
@_author: John S. Denker 
@_subject: building a true RNG 
1) There were some very interesting questions such as
  -- whether one can construct a hash function that
     generates all possible codes.
  -- ditto, generating them as uniformly as possible.
  -- Whether off-the-shelf hash functions such as SHA-1      have such properties.
The answers are respectively yes, yes, and very probably.
I wrote up a discussion of this, with examples, at
  2) David W. suggested (off-list) that I clarify the relationship
of entropy-based information-theoretic arguments to computational-
feasibility arguments.  I took some steps in this direction; see

@_date: 2002-08-02 07:27:45
@_author: John S. Denker 
@_subject: building a true RNG 
What about the scheme
described at
  There is only the most minor of problems here, namely
that DAW mentioned a symmetric cipher.  The problem goes away if you use asymmetric crypto.  You want a cipher with
no _deciphering_ key, as described in my paper.  (op. cit.)

@_date: 2002-08-03 17:26:30
@_author: John S. Denker 
@_subject: Translucent Databases 
I think the problem is a lot harder than that.
Let me clarify by telling a story:  Once upon a time, Hansel
designed an online-forms system that collected credit-card
info, encrypted it using PGP, and mailed it to Goldylocks
(the secretary) with a backup copy going to Tweedledee.
Despite the fact that Hansel had installed PGP on her
computer and indoctrinated her on how to use it, Goldylocks
was unable to decrypt the info.  So at her request, Tweedledee
decrypted it -- a whole conference's worth of registrations --
and sent it to her in the clear.
In a clear violation of Murphy's law, no harm came of this,
but otherwise it was a worst-case use of cryptology:  just
secure enough to be a nuisance to the authorized users, but
in the long run providing no real protection for the card-
The sad fact is that most people on this planet cannot get
PGP to work in a way that suits them.  The future of security
depends at least as much on user-interface research as it does
on mathematical cryptology research.
Oh, BTW, a preprinted number on the admissions form doesn't
really do the trick.  Forms are printed on printing presses,
in batches of several thousand, all alike.  After they are
mailed out, the guidance counselor at Podunk South High School
will make copies as needed.  A web-based approach won't work
unless you are making computer-savviness an entrance requirement.

@_date: 2002-08-07 16:43:15
@_author: John S. Denker 
@_subject: Challenge to TCPA/Palladium detractors 
That is frightfully underspecified.  Creating such a system
could be very easy or very hard, depending on what range of
policies is to be supported, and depending on what your threat model is.
At one extreme I might trust an off-the-shelf PC if it were
booted from CD by trusted parties in a TEMPEST-shielded room
surrounded by armed guards.  At the other extreme, making
tamper-proof hardware to face unlimited threats is very, very
hard -- most likely outside the "PC" price range for the
foreseeable future.
Well, the "technical terms" are not and should not be the
sole focus of the current discussion.  There are other
questions such as
 -- what range of policies should be supported
 -- who gets to set the policy
 -- who decides who trusts whom
 -- etc. etc. etc.
I agree that there has been too much ad-hominem sewage
and emotional rhetoric mixed in with the valid arguments

@_date: 2002-08-14 13:43:50
@_author: John S. Denker 
@_subject: Overcoming the potential downside of TCPA 
That's an overstatement;  better versions appear below.
Yes!  Now we're talking.
BTW I would have said _supposedly_ the only way to get an approved key
is .....
OK, that's an important part of the idea.
OK, that's part of the story, but not the whole story.
1) The conversation over the last many days seems like the
classic blind men + elephant story.  Different people have
emphasized different parts of a complex issue.
2) The conversation has been greatly impeded by extremism.
People have been talking in black-and-white terms when
shades of gray are needed.
For starters, we must stop talking about "trust" as a binary
quantity.  That's like asking whether a lock is unpickable
or a cipher is unbreakable -- it's usually the wrong question.
We need to talk about _how much_ something is trusted.  We
need to be clear about threat models.  The current TCPA stuff
must be rated somewhere between "amateurish" and "preliminary"
because it doesn't clearly articulate what threat(s) it is
meant to address.  (Not to mention lying about what threats it is meant to address. :-)
Again, let's not get carried away.  A long time ago, in a galaxy
far away, I derived a bunch of income from the sale of software back when most people who tried that lost their shirt.  Part of the story was that the software was sold in cartridges that could not be duplicated without hardware hacking and/or substantial investment in non-standard equipment.  So there was no widespread grass-roots copying.  At the opposite end of the spectrum, any large-scale copying would have been detected and stopped by legal In this case, as the creator of the intellectual property, I didn't much care if you "looked inside" the cartridge.  The main thing
that mattered to me was preventing rampant copyright infringement.
I don't want to start a holy war about copyrights _per se_.  Probably nobody thinks that current copyright laws are ideal from a public-policy point of view.  But I do think that there ought to be _some_ way to make sure authors and performers get paid.
Similar notions apply to patents and inventors.  In revolutionary
France, they did away with patents and copyrights ... but they
quickly discovered that was a really bad idea and reversed course.
Also, the idea that you would have and use something that isn't
100% yours isn't such a radical idea.  I have partial control over my credit-cards and badges, but they technically belong to the issuers, not to me, and the owners can demand that I return them.
Whether you want to use a computer (or anything else) that you don't fully own and don't fully control is a complex shades-of-gray question.  It depends on what it's good for, and what it costs
(including direct charges plus possibly very-indirect downsides).
Again, the question is _how much_ trust, including how much
tamper resistance.  The answer depends on how much you value
the data that is being protected.
Important parts of the elephant include
  -- what threats are to be addressed (type and magnitude of threat)
  -- what degree of hardware tamper resistance
  -- what degree of security of keys, key infrastructure, etc.
  -- what range of policies is to be supported
  -- who gets to set policy
  -- who decides who trusts whom, and how much
  -- etc. etc.
These items are interlinked.  In particular, AFAICT to have a
useful system, somebody will have to jointly certify that such-and-such piece of hardware is tamper resistant _and_ holds a particular key.
(And of course many items are totally dependent on the threat
model.  For example, the required degree of hardware tamper-
resistance might be rather rather modest for a low-grade communications endpoint inside a well-guarded facility, and vastly higher for the Permissive Action Link on a weapon carried on a bomber, which could conceivably be captured and subjected to intense scrutiny.)

@_date: 2002-08-15 18:32:29
@_author: John S. Denker 
@_subject: get a grip on what TCPA is for 
.... Brother Bear belabors one obvious point while missing a
more-important obvious point.  What some people want
is not what other people want.
The TCPA/Pd designers don't much care whether the
person who has custody of the machine trusts it.  They've
been shipping untrustworthy software for years.  The
thing they care about, probably the only thing they deeply care about, is whether _they_ can trust the machine while it is in _somebody else's_ custody.
To a first approximation, TCPA/Pd is for !!their!! direct
benefit, not for yours.  But to a second approximation, they are not entirely wrong when they say consumers will benefit, because there are indirect benefits of having some sort of system whereby authors, performers, and
inventors get paid for their work.  Things that are
simply not available now would become available if there
were a way people could get paid for creating them.
You can wish for some Land of Cockaigne where you get paid but nobody has to do any paying, but that's a long way from reality.
Most of us know how to secure a machine that is disconnected
from the net.  We can probably even combine some limited networked functionality with some degree of security -- !!provided!! we retain physical custody of the machine.
But how to trust a machine when you don't have physical
custody?  Even the most-skilled members of this list would find that a challenge (depending, as I have emphasized before, on what your threat model is).
I guarantee you will not understand TCPA/Pd unless you
walk a while in the proponents' moccasins.  If you can't stand the smell of those moccasins, OK, but prepare yourself for perpetual ignorance and irrelevance.
For example: Imagine you are the owner of a valuable copyright
and you want to protect it.  You want consumers to be able to use your work in some ways, but you want to prevent rampant
infringement.  What will you do???  It's not an easy problem.
If your powers of imagination are not up to the task in the
previous paragraph, here's an alternative:  Suppose you want
to spend a few weeks visiting Outer Zambonia, but you want to communicate securely with your colleagues back home during this
time.  Alas, the Zambonian Ministry of Friendship has been
looking forward to this as an opportunity to trojanize your
laptop.  You simply don't have the resources to guard your
laptop 24 hours a day.  You can't travel with a GSA-approved
safe in your carry-on.  You can't take your laptop with you
when you go swimming.  The idea of hardware with !!some!!
degree of tamper-resistance might eventually start to appeal
to you.
Of course, our task of understanding what TCPA/Pd is trying
to do is made more difficult when proponents lie about what
they are trying to do.
The most interesting technical point AFAICT is figuring out
how to _vet_ a piece of tamper-resistant hardware.  Presumably
you want it to detect the early stages of tampering and
react by expunging all its private keys.  Alas essentially
identical behavior could be used to cover the tracks of
built-in trojan beasties.
Here are some partially-baked thoughts:
  1) You have to allow it to expunge things.  That's the
only way it can really protect your secrets.
  2) So allow that.  It should be possible to verify that
the box is in a tabula-rasa state -- if the trojan is gone,
it's gone, and if it's not gone, it should be detectable
if you probe hard enough.  We require the hardware to allow
certain types of probing.    3) After you're satisfied that the hardware is not infested, load the software, and the keys, from a trusted source.  Replace
the tamper-evident seals and latches.
This isn't a complete design, but you can where it's going:
It should be possible to design hardware with some degree of tamper-resistance !!without!! creating a monopoly as to
who decides who trusts whom.
Alas it is also possible to design the hardware so that it
becomes a monopoly-enhancer of Orwellian proportions.  We
need to be vigilant to prevent this.  This will require
nuanced, non-extremist thinking.  Those who exhibit the
knee-jerk response that "all tamper-resistant hardware is
bad" will be ignored.  Such hardware, like most things,
can be used for good or ill, depending on details.

@_date: 2002-08-15 21:54:58
@_author: John S. Denker 
@_subject: get a grip on what TCPA is for 
If the hardware isn't tamper-resistant, the adversary can just put in a slightly-less simple BIOS that captures your passphrase the next time you use it.  At this point the game is pretty much over.  You've lost.
As a general rule:  If you don't have physical security,
you don't have security.

@_date: 2002-07-05 12:52:45
@_author: John S. Denker 
@_subject: New Chips Can Keep a Tight Rein on Consumers 
I don't know the whole story, and I don't know anything for sure, but here's a hypothesis and a starting point:
Expand the acronym DMCA to discover the word "copyright".
IANAL but:  As a rule, copyrights aren't supposed to be used to protect functionality;  that's what patents are for.  Reverse
engineering in general remains legal ... not just laissez-faire legal, but actually protected by the fair-trade laws.  DMCA carves out an exception in the case of reverse engineering that
promotes violation of copyrights.  A micron-by-micron copy of
the smartchip would be a violation of somebody's plain-old non-DMCA copyright in the mask, but a clone that reproduces
the functionality is fair game.
You might wonder about a hypothetical next step:  printer vendors could put some crypto in the system (so that every smartchip would _need_ to have a copy of the key) and then invoke copyright on the IANAL but that might be asking for trouble.
 0) Copyrights are not supposed to be used to protect functionality,
    as discussed above.
 1) Printer vendors aren't analogous to DVD vendors, because
    the latter have "intellectual property" rights in the content,
    long recognized by law, which they are allowed to protect.      Preventing piracy is a _perfectly legal_ limitation on
    trade.  In contrast, printer makers have far fewer recognized     rights in the ink.  Trying too hard to mess up the aftermarket
    in ink might be considered an _illegal_ restraint of trade.
 2) Related point:  The printer vendors claim that the chips
    are there "merely" to provide necessary functionality, which
    is legal.  Court action against somebody who didn't copy
    anything but the key would put the lie to this claim.  And     then you would have questions about the legality of the chips;
    see item (1).

@_date: 2002-07-11 09:59:49
@_author: John S. Denker 
@_subject: vulnerability in Outlook PGP plugin 
This vulnerability can be exploited by the Outlook user simply
selecting a "malicious" email, the opening of an attachment is not required. [NAI] have released a patch for the latest versions of the PGP
Outlook plug-in to protect systems from this flaw. Users can download the patch from:
By TED BRIDIS, Associated Press Writer
 WASHINGTON (AP) - The world's most popular software for scrambling
 sensitive e-mails suffers from a programming flaw that could allow
 hackers to attack a user's computer and, in some circumstances,
 unscramble messages.
 The software, called Pretty Good Privacy, or PGP, is the de facto
 standard for encrypting e-mails and is widely used by corporate and
 government offices, including some FBI ( news - web sites) agents and
 U.S. intelligence agencies. The scrambling technology is so powerful
 that until 1999 the federal government sought to restrict its sale
 out of fears that criminals, terrorists and foreign nations might use
 it.
 The new vulnerability, discovered weeks ago by researchers at eEye
 Digital Security Inc., does not exploit any weakness in the complex
 encrypting formulas used to scramble messages into
 gibberish. Instead, hackers are able to attack a programming flaw in
 an important piece of companion software, called a plug-in, that
 helps users of Microsoft Corp.'s Outlook e-mail program encrypt
 messages with a few mouse clicks.
 Outlook itself has emerged as the world's standard for e-mail
 software, with tens of millions of users inside many of the world's
 largest corporations and government offices. Smaller numbers use the
 Outlook plug-in to scramble their most sensitive messages so that
 only the recipient can read them.
 "It's not the number of people using PGP but the fact that they're
 using it because they're trying to safeguard their data," said Marc
 Maiffret, the eEye executive and researcher who discovered the
 problem. "Whatever the percentage is, it's very important data."
 Maiffret said there was no evidence anyone had successfully attacked
 users of the encryption software with this technique. He said the
 programming flaw was "not totally obvious," even to trained
 researchers examining the software blueprints.
 Network Associates Inc. of Santa Clara, Calif., which until February
 distributed both commercial and free versions of PGP, made available
 on its Web site a free download to fix the software. The company
 announced earlier it was suspending new sales of the software, which
 hasn't been profitable, but moved within weeks to repair the problem
 in existing versions. The company's shares fell 50 cents to $17.70 in
 Tuesday trading on the New York Stock Exchange ( news - web sites).
 Free versions of PGP are widely available on the World Wide Web.
 The flaw allows a hacker to send a specially coded e-mail - which
would appear as a blank message followed by an error warning - and
effectively seize control of the victim's computer. The hacker could
then install spy software to record keystrokes, steal financial
records or copy a person's secret unlocking keys to unscramble their
sensitive e-mails. Other protective technology, such as corporate
firewalls, could make this more difficult.
 "You can do whatever you want - execute code, read e-mails, install a
 backdoor, steal their keys. You could intercept all that stuff,"
 Maiffret said.
 Experts said the convenience of the plug-ins for popular e-mail
 programs broadened the risk from this latest threat, since encryption
 software is famously cumbersome to use without them. Even the creator
 of PGP, Philip Zimmermann, relies on such a plug-in, although
 Zimmermann uses one that works with Eudora e-mail software and does
 not suffer the same vulnerability as Outlook's.
 A plug-in for Microsoft's Outlook Express - a scaled-down version of
 Outlook - is not affected by the flaw.
 Maiffret said his company immediately deactivated the vulnerable
 software on all its computers, which can be done with nine
 mouse-clicks using Outlook, until it could apply the repairs from
 Network Associates. The decision improved security but "makes it kind
 of a pain" to send encrypted e-mails, he said.
 Zimmermann, in an interview, said PGP software is used "quite
 extensively" by U.S. agencies, based on sales when he formerly worked
 at Network Associates. He also said use of the vulnerable companion
 plug-in was widespread. Zimmermann declined to specify which
 U.S. agencies might be at risk, but other experts have described
 trading scrambled e-mails using PGP and Outlook with employees at the
 FBI, the Energy Department and even the super-secret National
 Security Agency.
 In theory, only nonclassified U.S. information would be at risk from
 this flaw. Agencies impose strict rules against transmitting any
 classified messages - encrypted or not - over the Internet, using the
 government's own secret networks instead.
 "The only time the government would use PGP is when it's dealing with
 sensitive but unclassified information and has a reasonable degree of
 assurance that both parties have PGP," said Mark Rasch, a former
 U.S. prosecutor and expert on computer security.  "It's hardly used
 on a routine basis."
 __
 On the Net:
 eEye Digital Security:  Network Associates:  MIT's PGP site:

@_date: 2002-07-19 14:40:41
@_author: John S. Denker 
@_subject: Quantum Computing Puts Encrypted Messages at Risk 
I don't even need quantum mechanics to generate
industrial-strength random symbols.  By that
I mean the correctness of the generator is not
dependent on the usual-but-unproven cryptologic
assumptions such as the existence of a one-way
function.  (It is somewhat dependent on much
milder assumptions about the mixing properties
of hash functions.)
Specifically:  The "executive summary" of the principles of operation of my generator is:
 -- use SHA-1, which is believed to be resistant
    to collisions, even under chosen-input attack.
 -- use it under conditions where the adversary
    cannot choose the input.
 -- the rest is just physics and statistics.
I consider the traditional "cryptologic" design
and validation of SHA-1 to be the _weakest_ part
of the argument!!!!
There is no reason to believe quantum noise is
"more random" than thermal noise, provided you
can control the temperature of your computer to
any reasonable degree.  And if you don't have
reasonable physical control of your computer,
all bets are off anyway.
  cost = practically free
  size = small, if not already built-in to your computer
  Where is that coming from?  I consider the uncertainty
principle incomparably more well-established than the
usual "crypto principles".
It depends on what you mean by "could".

@_date: 2002-07-19 18:21:53
@_author: John S. Denker 
@_subject: Maybe no stego on eBay afterall 
Regarding the farcical wetstone results, Says who?  See below.
It's not "cool" to detect only whatever stego was inserted
by idiots.
a) Consider the following:  Suppose I take a picture with
my CCD camera of a scene containing a more-or-less white
area.  I choose the f/stop and exposure-time so that N
photons are expected to hit each pixel of the CCD array
in this area.  Elementary physics and statistics tell us that there will be an uncertainty of sqrt(N) in the actual photon count.
b) I repeat the operation using a brighter light, bigger
aperture, and/or longer exposure, so that the expectation
value is now 10N.  Then I divide by 10 to get an image
rather comparable to the first, but with sqrt(10) less
noise.  I then add noise back in, using either
  b1) an industrial-strength random symbol generator, or
  b2) a well-encrypted message
I claim it is impossible for any empirical test to distinguish case (a) from (b1) or (b2).  Maybe they'll just pass a law making it illegal to
take pictures except in mid-day sunlight.
Our tax dollars at work.  Whoopee.

@_date: 2002-07-20 08:56:07
@_author: John S. Denker 
@_subject: Maybe no stego on eBay afterall 
Regarding my remarks about the ubiquity of Poisson
I can't imagine what those reasons are, so I won't respond.
Huh?  A camera has a limited exposure time, limiting
the opportunity to perform signal-averaging.  My
original note pointed this out.  Similarly I pointed
out that it is possible in principle to reduce the noise to arbitrarily low levels by using very strong
illumination, very wide aperture, and very long
exposure -- but there is no 11th commandment requiring
everyone to do so.  Therefore it is a fact, whether
you like it or not, that pictures have noise in them.
Audio signals have noise in them, too.
Real life does not have the sort of mathemetical purity
that software sometimes has.  Get used to it.
Receivers have been successfully decoding noisy signals
for some time now.  I think some guy named Shannon had
something to say about this:  how much signal we need
in order to achieve reliable throughput, et cetera.
No, it would not.
For starters, a simple method for separating the signal
from the "carrier" image would be to use a high-pass filter.
The pixel noise has all frequencies, including very high
frequencies, while many natural scenes have areas devoid of high-frequency content.
I don't know what that is saying.  The LSB is not strongly
random before or after encoding.  (It isn't entirely
non-random, either, but it would be a colossal blunder to
assume that everything is either entirely random or entirely
BTW, I didn't say substitute.  I said add.  Vulgar language does not make the argument more clear.
What's the point?  Use a lossless encoder, go to jail?
I say again, it is a colossal fallacy to assume that the
LSB is either completely random or completely non-random.
An application of this idea is called "guard digits" in the language of numerical methods.  This idea is also
discussed in the reference I cited previously, specifically
at   and elsewhere.
No, they're not eye-catching in the sense of blowing
the cover off the stego.
I never suggested it was necessary or appropriate to
photograph _just_ a white wall.    1) My mention of a white area was just to simplify
     the discussion.  My stego method is readily      adaptable to non-white areas by anyone with
     ordinary skill in the art.
  2) It is a fact, whether you like it or not, that
     many perfectly ordinary images on eBay contain
     white areas.  I just looked.  The very first
     image I came across was
     which contains many, many pixels worth of areas close
     enough to solid colors to make the aforementioned
     high-pass filtering easy to carry out.
This is diametrically wrong.  Correlated bits are the
ones that do not contain information, and can be cut
away without loss.
Saying "of course" does not make the argument more clear.
There is no law requiring images to be filed using only
8 bits.

@_date: 2002-07-22 11:59:00
@_author: John S. Denker 
@_subject: It's Time to Abandon Insecure Languages 
Really?  What's the evidence for that?
What definition of "most" are we using?
One out of 20 doesn't count as "most" in my book.
When I look at the reports for 2002 year-to-date, at  there are 20 advisories.  Depending on how you count multi-bug reports, it appears that 19 out of 20 involve buffer overflows and related issues -- things that could easily be prevented by using a language that has a built-in string type and automatic object management.
Exotic languages are not required;  C++ would make a huge
impact.  And of course in any language a modicum of skill and
care is required;  it's hard to make a language foolproof because fools are so ingenious.
My evidence:   20- multiple, including writing out-of-bounds
19  buffer overflow
18  multiple, including buffer overflow
17  stack overflow
16  multiple, including stack overflow
15= DoS: internal consistency check
14  buffer overflow
13  buffer overflow
12- format string
11  heap overflow
10- format string
 9  multiple, including buffer overflow
 8  multiple, including buffer overflow
 7- double free
 6  multiple, including buffer overflow
 5  multiple, including heap overflow
 4  buffer overflow
 3  multiple, including buffer overflow
 2  buffer overflow
 1  buffer overflow

@_date: 2002-07-22 12:42:38
@_author: John S. Denker 
@_subject: It's Time to Abandon Insecure Languages 
Earlier he wrote
                     ^^^^^^^^
We are talking about _reported_ bugs.  If CERT is not the right place to look for reports, please tell us where we
_can_ find appropriate reports.
I was trained as a scientist.  I like to look at data.
Listening to other people's summaries and conclusions is
nice, too, but sometimes it pays off to take a look at the real data.

@_date: 2002-07-22 16:24:43
@_author: John S. Denker 
@_subject: building a true RNG (was: Quantum Computing ...) 
For the humor-impaired, let me point out that the lava lamp is a joke.  What it conspicuously lacks is a proof of correctness -- that is, a nonzero lower bound on the entropy rate of the raw data.  The "lava" could turn out to have a not-very-complicated periodic pattern.  Secondarily, the pattern changes so slowly that there must be rather strict upper bounds on the entropy rate, small out of all proportion to the cost of the contraption.
A detuned FM card is a bad idea, because it is just
begging the opponent to sit next door with an FM
A microphone causes users to worry about privacy, and
in any case doesn't add much beyond what you'd get with
the same input circuitry open-circuited, i.e. everything
except the microphone itself.
Radioactive decay has a poor price/performance ratio, and
isn't nearly as random as neophytes might think, when the
data-acquisition hardware is taken into account.
We agree.
Depending on what "whitening" means;  see below.
That's the point where I would like some more detail.
If "measuring" means applying statistical tests, then
I've never seen such measurements done in a way that is
really convincing.  Constructive examples would be welcome.
Just saying "Joe Schmoe applied all the tests he could think of and couldn't compress it more than XY%" isn't
going to convince me.
I recommend _calculating_ the entropy from physics principles,
rather than trying to "measure" the entropy using statistical
tests.  The calculation is based on a handful of macroscopic
physical parameters, such as temperature, gain, and bandwidth.
Commonly but not necessarily < 1 bit/symbol.
Depending on what you mean by "symbol", a 24-bit audio card provides a low-cost counterexample.
We need to be more specific about what the symbol
alphabet is.  If the symbols are ASCII characters,
1 bit per symbol is not nearly good enough.
More importantly, I don't know what whitening means in this case.
The output of a good distiller has virtually 100% entropy density, i.e. 8 bits per byte.  I say "virtually" because
perfection is impossible, but 159.98 bits in a 160 bit
word ought to be good enough for most applications :-).
I see no point in "whitening" the output of such a
If whitening means encrypting the output of the distiller,
I consider that just a more-complicated hash function ...
just another few rounds.
I assume that means "know [that I'm using a distiller]"
Well, in principle nobody outside the box knows _anything_
about the mechanism (unless they read the documentation).
One random symbol stream looks a lot like another :-).  Attackers can always check to see whether the generator is broken or not.  But if it's not broken, all they can do (from outside) is measure the output-rate.
Certainly there's no harm.  It's like kicking the tires
on the used car.  It gives some people a warm fuzzy, but it's far from sufficient for establishing any reasonable level of confidence.
I recommend monitoring the aforementioned macroscopic
(non-statistical) physical parameters, both to detect
gross hardware failure and to detect attempted jamming.
But that's very different from the traditional (and
hereby deprecated) procedure of "measuring" the entropy
using statistical tests.
For lots more detail, see

@_date: 2002-07-22 20:21:05
@_author: John S. Denker 
@_subject: building a true RNG (was: Quantum Computing ...) 
David Honig wrote yet another nice note:
Tee, hee.  Have you ever worked in a Faraday cage?
Very expensive.  Very inconvenient.
I'm not trying to be dense, but I'm totally not understanding the distinction here.  The following
block diagram is excellent for focussing the discussion,
OK, we have DES as an example of a whitener.

@_date: 2002-07-23 10:03:40
@_author: John S. Denker 
@_subject: building a true RNG (was: Quantum Computing ...) 
Sorry, no, that doesn't answer the question.   -- I already use SHA-1.
 -- It is considered a strong cryptologic hash that doesn't
    need whitening.
 -- I am told (but don't understand) that there might exist
    a weaker hash that somehow does require whitening.  This
    is the point of the conversation.  Please address this
    point if you can.

@_date: 2002-07-23 10:14:24
@_author: John S. Denker 
@_subject: building a true RNG 
OK.  Evidently it's dominated by thermal noise, not to
be confused with the Poisson noise recently featured
in another thread.  Not a problem.
There might be a minor point, namely computational efficiency.
A well-chosen compressor might eliminate low-entropy bytes
rather quickly.  Make sure it's a lossless compressor, perhaps
GIF or PNG ... as opposed to a perceptual coder (e.g. JPEG) that would persumably throw away some of the entropy.  Calling SHA-1 on low-entropy bytes doesn't waste entropy, but wastes CPU
1) In any good hash function, any input bit should have
about as much effect on the output as any other input bit.
SHA-1 has been analyzed by experts (of which I am not one :-)
and I would imagine they checked this.
2) There are 5 one-bit shifts in the fivefold expansion, and
lots of 5-bit shifts in the main loop, so it shouldn't matter
that the sparse input bits are clustered in the bottom of the
32-bit words.
3) I performed an amateur kick-the-tires test, namely cobbling
up some sparse input vectors, calling SHA-1, and applying
"standard" statistical tests including Diehard and Maurer's
"universal" statistical test.  No nobody's surprise, the tests didn't detect anything.
Thermal noise is good.  Antennas are bad -- just an invitation
to be attacked that way.  Get rid of the antenna.  Keep the high
gain preamp.
Better yet, do as Eugen has done:  Use a framegrabber !!without!! the "portable TV set".  No RF section at all.  Plenty of entropy,
lower cost, greater simplicity, and less vulnerability to attack.
For that matter, an audio card (without microphone) produces more
than enough entropy for most applications.

@_date: 2002-07-24 12:06:07
@_author: John S. Denker 
@_subject: understanding entropy  (was: building a true RNG) 
I join in the agreement.
I don't think jamesd's point was wrong.  One could quibble
about some of the wording, especially if it were taken out
of context, but the passage as a whole makes an important,
valid point.
Yes, it is a physical quantity.  Yes, it enters into chemistry.
But it also contains an element of subjectivity.
For a careful discussion of what entropy is, including
the element of subjectivity, see
  Charles H. Bennett and Rolf Landauer.
Not to mention Leo Szilard, Ed Fredkin, Wojciech Zurek,
and others.
Chaitin's work is profound and well-regarded.  Referring
to it as "mindgames" is, well, nothing but name-calling
and won't advance the scientific discussion.  If anybody
has a thoughtful objection to Chaitin's work I would be
extremely interested to hear it.
A lack of understanding of what entropy is has gotten more
than one cryptographer into trouble.

@_date: 2002-07-25 11:24:28
@_author: John S. Denker 
@_subject: building a true RNG 
David Honig wrote in part:
I suspect those were intended as rhetorical questions, but
we are better off taking them as real questions.  They are
in fact excellent questions.  Incisive questions.
It is important to the correctness of my Random Symbol Generator
that I deal with those questions.  I accept the challenge of dealing with them, although that won't involve answering them
The point is that I do not need a frictionless table.  I
do not need an ideal gas.  And most particularly I do not
care if the analog threshold of my soundcard shifts slightly (as a function of recent history, temperature, phase of the
moon, or whatever).
This is the central conceptual point of my paper.  It is
more important than any particular implementation.  The point
is that a Random Symbol Generator can be proved correct using
fairly mild assumptions and premises.
The turning point of the argument is statistical: if I have
enough entropy at the input of the hash function, and if the
hash function doesn't waste entropy (by having unnecessarily
many hash collisions) then the statistics takes over and covers a multitude of sins.  For example, if I have 165 bits
of entropy at the input of the hash function, the output will
have 159.98 bits of entropy in a 160 bit word.  You can shift
the threshold all you want.  You can add something to the input.
You can subtract something.  It just doesn't matter.     Roughly speaking, think of the input as an ensemble of values,   a set containing 2^165 elements.  I don't care what the values   of the elements are, so long as they're all different.  Of   course this is not the only way to make 165 bits of entropy;   it's just roughly speaking to paint a pedagogical picture.
What matters is the _variability_.  As long as there is 165
bits worth of variability, and the hash function doesn't waste
any of it, the details don't matter.  If the alleged threshold
shift is so large as to decrease the variability of the raw
data, then all bets are off... but that wasn't the question
that David asked.  The rhetorical question suggested that if
the threshold shifted "at all" I would have a big problem, and I loudly assert that I don't.  Specifically:  If you give me
any halfway-reasonable upper bound on the magnitude of the shift, I can design the generator to accomodate that, producing industrial-strength randomness despite such a shift.
And by the way, there's nothing sacred about the 159.98
number.  It's just easy to remember.  As another data point:
If you have 170 bits at the input, the output will have 159.9993 bits of entropy in a 160-bit word.  Note that the excess entropy
needed to provide good saturation is only a few percent:
170/160 = 1.0625
In the same note David continued to advocate the block
which I will discuss in a separate posting.

@_date: 2002-07-25 11:45:20
@_author: John S. Denker 
@_subject: building a true RNG 
David Honig helped focus the discussion by advocating the block diagram:
Let me slightly generalize this to:
! Source --> Digitizer --> hash --> Whitener (e.g., DES)
i.e. we defer the question of whether the hash is "simple" or not.
I continue to claim that
 a) if the hash function happens to have a property I call "no wasted entropy" then the whitening stage is superfluous (and
you may decide to classify the hash as "non-simple");  otherwise
 b) if the hash function does not have that property, this
is a defective Random Symbol Generator and   b1) the whitener will _at best_ conceal, not remove the       defects, and
  b2) this is not the best way to conceal defects.  Very
      definitely not.
To illustrate my point, I will accept David's example of a
Well, then, suppose that the raw data coming off my digitizer
consists of an endless sequences of even-parity words.  The
words have lots of variability, lots of entropy, but the parity
is always even.  Then the output of the simple-hash is an endless sequence of zeros.  I encrypt this with DES.  Maybe triple-DES.  It's not going to help.  The generator is defective and doesn't even have satisfactory error-concealment.
I like my design a lot better:
+ Source --> Digitizer --> good hash
where I have chosen SHA-1 as my hash function.  Finally, since SHA-1 is remarkably computationally efficient,
I don't understand the motivation to look for "simpler" hash
functions, especially if they are believed to require whitening
or other post-processing.
Thanks again for the questions.  This is a good discussion.

@_date: 2002-07-27 13:52:34
@_author: John S. Denker 
@_subject: building a true RNG 
David Honig responded:
That's a red-herring tangent.  I'm not talking about any old
function that doesn't waste entropy;  I'm talking about a !!hash!! function that doesn't waste entropy.  The hash function
has a hard constraint on the word-size of its output.  If it
starts doubling bits, or otherwise putting out redundancies,
then it is wasting entropy.  See the discussion of the BADHASH-2
function in the paper.
  And remember:  in addition to having a non-entropy-wasting hash function, we are also required to saturate its input.  Then we can conclude that the output is white to a very high degree, as quantitatively discussed in the paper.
Total entropy is preserved in the non-saturated regime.  This is
documented in upper rows of the table:
  In the saturated regime, some entropy is necessarily lost.  This is
documented in the lower rows of the table.  This is only a small percentage, but it is mandatory.  I don't consider this to be "wasted" entropy;  I consider it entropy well spent.  That is, these are necessary hash collisions, as opposed to unnecessary ones.
See the discussion of BADHASH-1 in the paper.
Well, I tend to agree that systems that separate the bit-reduction
from the mixing are easier to analyze, in the sense that it is
easier to find flaws in them.  But that's because they're so flawed!

@_date: 2002-07-27 14:39:06
@_author: John S. Denker 
@_subject: building a true RNG 
That's the right question.
The answer I give in the paper is      A cryptologic hash function advertises that it is
     computationally infeasible for an adversary to unmix
     the hash-codes.
     A chosen-plaintext (chosen-input) attack will not
     discover inputs that produce hash collisions with
     any great probability.
     In contrast:
     What we are asking is not really very special. We
     merely ask that the hash-codes in the second
     column be well mixed.      We ask that the data acquisition system will not
     accidentally produce an input pattern that unmixes
     the hash-codes.     We believe that anything that makes a good pretense of being     a cryptologic hash function is good enough for our purposes,
    with a wide margin of safety.   If it resists attack when the     adversary can choose the inputs, it presumably resists attack     when the adversary can't choose the inputs.

@_date: 2002-07-29 13:37:49
@_author: John S. Denker 
@_subject: building a true RNG 
Barney Wolff  asked:
David Wagner replied:
I was temporarily astonished, but he clarified as follows:
1) Consider the following function H0:  Divide the input into
chunks N bits long.  Calculate the XOR of all the chunks, and
use that as the output.
This meets the definition of hash function, although it would
not be a one-way hash function.  And it would most certainly
be capable of generating all 2^N possible outputs.
2) I can't prove that a standard hash function such as SHA1
generates all possible codes, but I consider it likely.  It would be quite shocking if a strong hash function such as SHA1 generated
fewer codes than a weak function such as H0.
3) For a one-way hash function should not expect a _constructive_ proof that it generates all possible codes;  such a construction
would violate the one-way property.
4) Here is a rough plausibility argument.  Consider two hash
functions H_1 and H_2 that are independent.  We define
which implies
Now let's look at the truth table for equation (2), where
the row-index is the H' code, the column-index is the H_2
code, and each entry represents the H_1 code required
to uphold the equation:
Now let's suppose H_2 is missing one code (say the 10 code) and
H' is missing one code (say the 11 code).  Then H_1 must be missing
at least three codes!  Otherwise there would be a way of combining
a non-missing H_1 code with a non-missing H_2 code to create the
missing H' code.
We can extend this argument by combining lots and lots of independent hash functions H_i.   The combination has far fewer missing codes than any of the ingredients.  So either
you conclude that   a) there is a conspiracy that prevents us from constructing
     "independent" hash functions to use as ingredients, or
  b) we can produce hash functions with very few missing codes.

@_date: 2002-06-01 20:13:17
@_author: John S. Denker 
@_subject: diehard versus SHA-1 
David Honig responded, starting with a quote from that URL:
The quoted passage comes from an appendix which is a "parking lot" for half-baked ideas that have NOT been incorporated into the draft paper, because they do not meet my standards of clarity and precision.  So it is about as out-of-context as anything could possibly be.
The passage that actually describes what I believe can be
found in the main part of the paper,
  (I have just now revised it a bit, so please hit the "reload" button on your browser.)
Well,  1) I did run Diehard.  Also Mauer's Universal Statistical Test.
They didn't turn up anything.  I would have been very, very
astonished if they had turned up any "nuances".  Gross bugs,
maybe, but not nuances.  Turbid was designed to be "industrial strength" -- not sensitive to nuances.
 2) Questions:  What sort of nuances would you expect to see?  -- If you suspect a weakness in SHA-1, wouldn't it be better
to attack SHA-1 directly, using standard cryptanalytic techniques,
including chosen inputs, rather than haphazardly probing it with
whatever comes off the data-acquisition system?
 -- If you suspect a problem upstream of SHA-1, why not look
there, where the alleged problem is?  Why not look with a test that's appropriate to the problem, rather then obscuring
the problem with SHA-1 and then applying a non-specific test?
3) There are lots of hardware random number generators out there
that seem to be built on the criteria of "Gee, it looks kinda
random to me" or "I can't find any pattern in it using the following standard tests".  We strongly deprecate all such
criteria.  Observation and testing can provide an upper bound
to the entropy density, not a lower bound.
Turbid, in contrast, is designed around a lower bound.  The
lower bound is calculated from physics principles, not estimated using some statistical test(s).

@_date: 2002-06-25 22:21:36
@_author: John S. Denker 
@_subject: privacy <> digital rights management 
Uhhh, my mileage varies rather considerably.  Perhaps we are using
wildly divergent notions of "privacy" -- or wildly divergent
notions of "identical".
DRM has to do mainly with protecting certain rights to _published_
material.  Private material is not "identical" with published
material -- it is more opposite than identical.
Private material is, according to the usual definitions, in the hands of persons who have a common interest in keeping the information
private and restricted.  Published material, in contrast, is in the hands of persons who have no interest in keeping it private, and indeed commonly have an interest in defeating whatever restrictions
are in place.
We have thousands of years of experience with military crypto, where the parties at both ends of the conversation are highly motivated to
restrict the flow of private information.  The current state of this
technology is very robust.
Ending about 20 years ago we had a 500-year era where it was not
practical for anyone except an established publisher to infringe
copyrights in a big way.  During this era, Rights Management had
essentially nothing to do with crypto;  it mainly had to do with the economics of printing presses and radio transmitters, supplemented by copyright laws that were more-or-less enforceable.  This era was killed by analog means (widespread photocopy machines) and the corpse was pulverized by digital means (widespread computers
and networking).
I repeat:  The main features of our experience with Privacy Management
are disjoint from the main features of our experience with Publishers'
Rights Management.  They are about as different as different can be.
The record is replete with spectacular failures attributable to non-understanding of the difference.

@_date: 2002-06-26 15:13:37
@_author: John S. Denker 
@_subject: privacy <> digital rights management 
That's not a helpful remark.  My first contribution to
this thread called attention to the possibility of
wildly divergent notions of "privacy".
Also please note that according to the US Office of
Technology Assessment, such terms do not posess "a single
clear definition, and theorists argue variously ... the
same, completely distinct, or in some cases overlapping".
Please let's avoid adversarial wrangling over terminology.
If there is an important conceptual distinction, please
explain the concepts using unambiguous multi-word descriptions
so that we may have a collegial discussion.
That is quite true, but quite irrelevant to the point I was making.
Pick an intermediate number, say 100 people.  Distributing
knowledge to a group of 100 people who share a vested interest in not divulging it outside the group is starkly different from distributing it to 100 people who have nothing to lose and something to gain by
divulging it.
Rights Management isn't even directly connected to knowledge.  Suppose
I know by heart the lyrics and music to _The Producers_ --- that doesn't mean I'm free to rent a hall and put on a performance.
That's partly true (although overstated).  In any case it supports
my point that fixating on the *technical* issues misses some
crucial aspects of the problem.
Colorful language is no substitute for a logical argument.
Exaggerated remarks ("... ALWAYS have ...") tend to drive the
discussion away from reasonable paths.  In the real world,
there is a great deal of information held by N people where
(N>>1) and (N<<infinity).

@_date: 2002-05-31 17:55:28
@_author: John S. Denker 
@_subject: Commercial quantum crypto product - news article 
"Kossmann, Bill" asked:
Actually a couple of products, I will comment only on one
of them, the quantum random number generator.
It reminds me of using a sport-utility vehicle to drive
to the neighbor's house, ten feet away.  There are easier ways to get to there.  There is no reason to
believe that quantum noise has any practical advantage
over thermal noise.  This point is not discussed in Quantique's principles-of-operation paper
  and indeed they say there "goal is to avoid" thermal
You can harvest industrial-strength randomness from
the thermodynamics of electrical circuits, costing
next to nothing.  A draft writeup can be found at:

@_date: 2002-11-08 08:58:53
@_author: John S. Denker 
@_subject: did you really expunge that key? 
1) This topic must be taken seriously.  A standard technique
for attacking a system is to request a bunch of memory or
disk space, leave it uninitialized, and see what you've got.
2) As regards the "volatile" keyword, I agree with Perry.
The two punchlines are:
 > if, for example, gcc did not honor [the "volatile" keyword],
 > the machine I am typing at right now would not work because
 > the device drivers would not work.
 > If they haven't implemented "volatile" right, why should
 > they implement the pragma correctly?
3) However, a discussion of compilers and keywords does not
complete the analysis.  A compiler is only part of a larger
system.  At the very least, we must pay attention to:
  -- compiler
  -- operating system
  -- hardware architecture
  -- hardware physics
At the OS and hardware-architecture levels, note that a
device driver accesses a "volatile" device register only
after beseeching the OS to map the register to a certain
address in the driver's logical address space. In contrast,
for some address that points to ordinary storage, the OS and
the hardware could (and probably do) make multiple copies:
Swap space, main memory, L2 cache, L1 cache, et cetera.
When you write to some address, you have no reason to assume
that it will "write through" all the layers.
Swap space is the extreme case: if you were swapped out
previously, there will be images of your process on the
swap device.  If you clear the copy in main memory somehow,
it is unlikely to have any effect on the images on the swap
device.  Even if you get swapped out again later (and there's
no guarantee of that), you may well get swapped out to a
different location on the swap device, so that the previous
images remain.
The analogy to device drivers is invalid unless you have
arranged to obtain a chunk of memory that is uncacheable and
To say the same thing in other words: a compiler can only do
so much.  It can generate instructions to be executed by the
hardware.  Whether that instruction affects the real
physical world in the way you desire is another question
4) In the effort to prevent the just-mentioned attack, a
moderately-good operating system will expunge memory right
before giving it to a new owner.  It would be more secure
(but vastly less efficient) to expunge it right after the
previous owner is finished with it.
To see this in more detail, consider swap space again: a
piece of "used" swap space need not be expunged, unless you
are fastidious about security, because the operating system
knows that it will write there before it reads there.  Clearing
it immediately would be a waste of resources.  Leaving it
uncleared is potentially a security hole, because of the risk
that some agent unknown to the operating system will (sooner or
later) open the swap-space as a file and read everything.
5) We turn now to the hardware-physics layer.  Suppose
you really do manage to overwrite a disk file with zeros.
That does not really guarantee that the data will be
unrecoverable.  As Richard Nixon found out the hard way,
the recording head never follows exactly the same path, so
there could be little patches of magnetism just to the left
and/or just to the right of the track.  An adversary with
specialized equipment and specialized skills may be able
to recover your data.
6) To reduce the just-mentioned threat, a good strategy is
to overwrite the file with random numbers, not zeros.  Then
the adversary has a much harder time figuring out what is old
data and what is new gibberish.  (To do a really good job
requires writing your valuable data always in the middle,
and overwriting gibberish twice, once offset left and once
offset right.)
This is one of the reasons why you might need an industrial-
strength "stretched random symbol generator":
   Note that the random-number trick can be used for main
memory (not just disks) to ensure that the compiler + OS +
hardware system doesn't optimize away a block of zeros.
This actually happened to me once: I was doing some timing
studies, and I wanted to force something out of cache by
making it too big, so I allocated a large chunk of memory
and set it to zero.  But no matter how big I made it, it fit
in cache.  The system was using the memory map to give me
unlimited copies of one small page of zeros (with the
copy-on-write bit set).
7) Terminology:  I use the word "expunge" to denote doing
whatever is necessary to utterly destroy all copies of
something.  Clearing a memory location is sometimes far
from sufficient.

@_date: 2002-10-02 01:30:24
@_author: John S. Denker 
@_subject: Optical analog computing? 
Gimme a break.  This is remarkable for its lack of 1) Bletchley Park used optical sensors, which were (and
still are) the best way to read paper tape at high speed.
You can read about it in the standard accounts, e.g.
  2) For decades before that, codebreakers were using optical
computing in the form of superposed masks to find patterns.
You can read about it in Kahn.
3) People have been doing opto-electronic computing for decades.  There's a lot more to it than just holography.  I get 14,000 hits from
  It isn't right to make it sound like three numbers (frequency, amplitude, and phase);  actually there are innumerable frequencies, each of which has its own amplitude and phase.
Some things that are hard with wires are easy with
light-waves.  But most things that are easy with wires
are hard with light-waves.
People were doing smaller versions of that in
the 1980s.
Not "FFTs".  FTs.  Fourier Transforms.  All you need for
taking a D=2 Fourier Transform is a lens.  It's undergrad
physics-lab stuff.  I get 6,000 hits from:
  All optical???  No optoelectronics anywhere???
That's medicinal-grade pure snake oil, USP.
Photons are well known for not interacting with
each other.  It's hard to do computing without

@_date: 2002-09-02 17:59:12
@_author: John S. Denker 
@_subject: Quantum computers inch closer? 
Sorry, that's a severe mis-characterization.
That's good advice.
Random is not the right word.
C'mon folks, let's cut down on extreme statements like the-whole-point-is-this or the-whole-point-is-that
and using words like "magic" to describe finding the
right answer.
1) Computer design has many points that must be
taken into consideration.  Quantum computer design
is in some ways more powerful but in other ways more
constrained than classical computer design.
2) One of the points is that yes, the computer should
compute what you want it to compute.  OTOH it takes
more than wishing to bring such a computer into 3) A sufficiently well designed quantum computer can, in principle, find some needles in some haystacks, precisely because the structure of the machine, acting according to the laws of quantum mechanics, does in fact "collapse" the wave-function into a representation of the wished-for answer.  (PS most of what has been written about "collapse" of wave-functions is baloney, but we need not pursue that tangent just now.)
A general remark about parallel computing:  For every
parallel algorithm (running on P processors) there exists a corresponding uniprocessor algorithm:  just set P=1 and turn the crank.
The converse does not hold.  The existence of a uni-
processor algorithm may or may not be a guide to the creation of a parallel algorithm.  As Brooks famously said, creating a baby requires nine months, no matter how many mothers are assigned to the task.
The same applies even more strongly to quantum computing:
It would be nice if you could take a classical circuit,
automatically convert it to "the" corresponding quantum
circuit, with the property that when presented with a
superposition of questions it would produce "the" corresponding superposition of answers.  But that cannot be.  For starters, there will be some phase relationships between the various components of the superposition of answers, and the classical circuit provides no guidance as to what the phase relationships should be.
So let's not guess about what quantum algorithms exist.
It is possible to construct such algorithms, but it requires highly specialized skills.

@_date: 2002-09-20 14:22:16
@_author: John S. Denker 
@_subject: unforgeable optical tokens? 
Those observations are true, but they don't nullify
the main feature of the system.
Forget about optics for a moment.  Model the token as a
gigantic ROM with 10^12 cells of one bit each.  The ROM
will need 40-bit addresses just to address all those cells.
Before the token is issued, the issuer will choose a few million addresses at random and probe the ROM at the corresponding locations, and store the results in a table.
After the token is issued, it can be challenged.  A
challenge consists of 60 or so addresses, taken at random
from the aforementioned table.  An impostor would have
one chance in 2^60 of guessing the correct responses.
To clone the token would require the bad guys to do a
million times more work than the legitimate issuer, because
the cloner would need to copy all cells of the ROM,
whereas the issuer needs only to probe (and remember)
only enough for a lifetime's worth of challenges (or
even less than a lifetime, if you want to return the
token to the issuer every so often to 'freshen' the
table).  The point being that the cloner doesn't know
which addresses will be probed by challenges.
Finally, all you need is a way to cheaply create a ROM
with many, many bits of quenched randomness.  Microbeads
in epoxy is one way of doing that.

@_date: 2003-04-11 08:24:03
@_author: John S. Denker 
@_subject: Via puts RNGs on new processors 
>>>  * detection of run-time TRNG failures:...
 >
 >> No guaruntee, then no problem.  This seems
 >> to be a userland problem, solved by some
 >> user program that tests the output, run on
 >> an application basis.
I disagree, for multiple reasons, including:
  -- The slow tests are not sufficient, not in
  principle nor in practice, to prove the goodness
  of a randomness generator.
  -- The tests for detecting plausible run-time
  failures are not slow.
For details, see
   which says in part:
It would be a huge mistake to use statistical techniques to
``measure'' the entropy density of the raw signal coming
from the hardware. To paraphrase Dijkstra: Measurement
can prove the absence of entropy, but it cannot prove the
presence of entropy. More specifically, there are various
methods that will give an upper bound on the entropy
density, but what we need is a lower bound, which is
something else entirely.
 > check out this hardware RNG threr is even an inexpensive circuit  >
 >  >
 > another HW RNG here:
 > Hmmmm.  What about this:  IMHO a much better RNG, utilizing
hardware that is even more inexpensive:

@_date: 2003-04-21 15:15:41
@_author: John S. Denker 
@_subject: DRM technology and policy 
There appear to be two extremes:
  -- the pro-copyright extremists and
  -- the anti-copyright extremists.
Sanity lies in the gray area in the middle.
Usually what I hear from each side is something
  a) The other side is scared and acting like a
     hypocritical selfish spoiled child, making
     totally illogical arguments, and
  b) therefore everything my side says is true
     and righteous.
I completely agree with both sides when they say
part (a) and disagree with both sides when they
get to part (b).
Recent anti-DRM arguments on the cryptography list have
cited examples suggesting that there are _some_ DRM
problems that cannot be well solved by _certain_
technologies....  And then they claim to have "proved"
thereby that all DRM is futile.  This is the height of
Techniques that don't protect a song might work just
fine to protect computer programs including games.
Also:  The cash register was invented a little over
a hundred years ago.  From a "security protocol" point
of view, it is open to criticism.  It is not 100%
effective at preventing "inventory shrinkage".  But
it is a lot better than nothing.  If certain DRM
schemes are imperfect, that doesn't prove we should
do nothing.  Maybe we live with the imperfections.
Maybe we fix them later.  Just because something
isn't 100% white doesn't prove it is 100% black.
Recent economics/policy arguments are comparably
I don't think it is good economics/policy to set the
price of everything at or below the point where it
becomes "convenient" to steal it.
When I encounter a toll booth, it would be much more
"convenient" to drive right through without stopping
and paying.  It would be technically possible for them
to install barriers to prevent this, but instead they
rely on _a posteriori_ detection and penalization of
Give me a break.  A big reason copyright holders are
scared of digital media is the potential to copy them
_without_ loss of fidelity.
In that scenario, the copyright holder spends a lot
of money creating demand, while somebody else steps
in to fill the demand.
Five-year-olds "think" lollipops should be given
away free to everyone.
Anybody who really thinks that is a good idea is
encouraged to start his own publishing house and/or
candy store.
Really?  What about Rhapsody, Pressplay, MusicNet...???
Don't get me wrong.  I am quite aware that certain
big publishing houses are paralyzed by fear, blinded
by their own stupidity, and heading for a spectacular

@_date: 2003-04-22 12:23:25
@_author: John S. Denker 
@_subject: DRM technology and policy 
On 04/22/2003 09:06 AM, Peter Clay wrote in part:
 >
 >  I'm sure that if candy
 > could be produced with zero _marginal_ cost, there would be free candy
 > stores.
Please get a clue.  Copyright isn't about the
scarcity of copying or the marginal cost thereof.
Never has been.
Copyright is about recouping the _fixed_ costs.  This
is necessary in general, and particularly important
when the market is of limited size, so that the fixed
cost per unit is significant in absolute terms.

@_date: 2003-04-22 22:41:05
@_author: John S. Denker 
@_subject: DRM technology and policy 
Says who?
That's not the law.
I see no reason to make that the law.
My unpublished notes are protected by copyright.
They are also private.  The copyright will eventually
expire.  It is not guaranteed or even likely that the
material will become public at that time.
(Note that patents are different from copyrights.)
 >> Copyright is about recouping the _fixed_ costs.  This
 >> is necessary in general, and particularly important
 >> when the market is of limited size, so that the fixed
 >> cost per unit is significant in absolute terms.
To which Derek Atkins responded:
If we're going to go down that road, we need
to be much more specific about what assumedly-
scarce resource we're talking about.
Suppose I've written a book.  I'll give you a
license to publish it if you pay me $1.00 per
copy.  You can have a thousand-copy license for
$1000.00.  You could get a six-billion-copy
license for even less than $6e9, since I would
give you a quantity discount.  So there is no
shortage of licenses.  Far from it.  AFAIK there
is no shortage of paper or ink for making books.
So I see no reason for believing that real
shortages or 'assumed' shortages play any
significant part in the business model.
So much for books.  It turns out that CDs almost
but not quite fit the same pattern.
As I have mentioned before, the thing that makes
present-day intellectual-property issues tricky
is that they collide with fundamental notions of
More than a few people believe that what they
do in the privacy of their homes should be, with
rare exceptions, unregulated by the law.
Until recently, privacy did not conflict with
patent and copyright, because it was uneconomical
to infringe things on a small scale.  Economically
significant infringement required mass production,
which had no pretense of privacy.
The thing that has changed is that now people
can engage in rampant copyright infringement
using the same technology that they use for
private activities.
Business has never assumed a scarcity of printing
presses -- but it has tacitly assumed the absence
of reproduction systems that are (collectively)
economically significant yet (individually) small
enough to hide behind a claim of personal privacy.
There is a profound dilemma here.  I don't claim
to have all the answers.  I'm just trying to point
out that we won't find the answers until we have
a better understanding of what the question is.
Incest is forbidden by law and custom, even
when it involves the same physical activities
that are ordinarily considered strictly private.
The problem is that acts that seem private at
the time can have serious impact on the larger
The analogy is not perfect, but you can see
the point:  Copyright infringement is a bad
thing, and it doesn't become unbad just because
it is technically possible to do it in a sparsely
distributed way so that the individual acts seem
private at the time.
We sometimes disallow seemingly-private acts if
they harm society, even if the harm is distant
in time and space.
We have here a bundle of hard problems.  Some
of them are manifestly intractible, but others
are only moderately hard.  Comparable problems
have been solved in the past.  For example:
The invention of radio overturned previously-
valid assumptions about copyright.  After much
to-ing and fro-ing, the laws were changed to
provide for "mechanical licenses" and for
something that we might recognize as a primitive
micropayments system:  BMI and ASCAP pay artists
based on statistical estimates of how much
airtime each work is getting.
If we solve the new problems right, there is
tremendous upside potential.   Right now
typical web content is produced by amateurs
and hobbyists.  That's fine for some things,
but not for everything.  Imagine how much
niftier the web would be if people who created
good stuff actually got paid to put it on
the web.
Maybe cyberspace is intrinsically barbarous,
such that everything that can be stolen will
be stolen, and everything that remains will
be subject to onerous and intrusive controls.
The real world doesn't work that way, but
maybe cyberspace is intrinsically worse.
OTOH, maybe cyberspace will turn out OK.
We might even be fairly close to a solution.
As an example:
You know how booze bottles and cigarettes
packs come with tax stamps on them.  One
could imagine a simple certificate, possibly
something quite light-weight, certifying that
so-and-so paid the royalty on such-and-such
song.  Then you need a way to buy certificates
at a reasonable price.  Then you need a grace
period for people to get into compliance.
Then you make examples of a few people who
didn't bother to comply.
It's more than an honor system, because it
can be audited.  It's sort of like the
driver's license system.  There is no fancy
DRM that prevents you from driving without
a license, but if you get caught you might
suddenly realize it would have been better
to get the license.
That's just a sketch of an example.  Probably
better schemes exist.  Wild extremes to the
left and right are also possible, but if we
keep our wits about us we should be able to
prevent the wild extremists from taking over.

@_date: 2003-04-22 23:13:11
@_author: John S. Denker 
@_subject: DRM technology and policy 
>>
 > Thus, the marginal cost of
No, the marginal cost of the product started out
zero and remains zero.  It does not shrink.
The presence or absence of competing product
does not change this.
 > Both of these are also zero.
This is getting sloppy.  It blurs "cost" with
"marginal cost".
The total cost includes fixed costs.  It
does not shrink to zero.  The cost per unit
shrinks toward zero, but does not shrink "to"
zero unless the market is infinite.  I've
sold into some small markets and some fairly
large markets, but I've never sold into an
infinite market.
Fixing the price at a point appropriate for
the infinite market is absurd in a finite
market.  It results in not recovering costs.
This violates one of the most elementary
notions of economics.
There also seems to be here the assumption
that all units must sell for a price equal
to the marginal cost.  Economics does not
require this.  One can show that the marginal
unit should sell for the marginal price=cost,
but the proof does not generalize to any
other unit.
It's not directly a physical foundation.
Copyright is a legal fiction, and always
has been.  It eventually becomes physical
if you violate it, because guys with guns
will physically haul you into court.

@_date: 2003-04-24 13:29:01
@_author: John S. Denker 
@_subject: US Secret Service capabilities 
Hi --
I just returned from the Post Office.  And
I don't mean SMTP, I mean ink on paper, with
little self-adhesive micropayment certificates
on the corner.
The reason is that the US Secret Service
asked me to mail them some info about an
identity-theft scam.
I offered to email the info, but the Special
Agent said he didn't have email at work, and
it was "not convenient" for him to check his
email account at Yahoo.  At that point I broke
off the conversation, figuring that if they
couldn't invest the effort of checking their
email they wouldn't invest the effort of
actually investigating the incident in
question, so I wouldn't waste any more of
their time or mine.
To my surprise, the Special Agent called back
and pleaded with me.  He changed his story and
said they had means of sending and receiving
email, but they _weren't allowed_ to give out
their email addresses.
I know this is supposed to be the Secret
Service, but keeping their email addresses
secret is going a bit far IMHO.  I would
think most computer-security professionals
would know how to set up a temporary and/or
anonymous email address.
I hope he enjoys transcribing the scammers'
350-character-long URLs from the paper I sent.
I put the info on a secure web site and
suggested he pull it down from there, but
he declined that, too.
The Special Agent was surprised to hear that
I controlled multiple web sites.  He didn't
understand how that was possible.
The Special Agent was surprised to hear that
given an IP address, I could figure out what
country it's in.  He argued with me about this.
The term "whois" meant nothing to him.
Heretofore I didn't understand how identity-
theft rings could operate so openly.  One
might have thought they would be afraid of
stings, but evidently they're not.
There's a lot of darkness here.  I've set
out a few candles, but I'm not sure it's
going to be enough.

@_date: 2003-02-08 00:41:08
@_author: John S. Denker 
@_subject: Columbia crypto box 
As reported by AP:
Apparently some folks skipped class the day Kerchhoffs'
Principle was covered.
One wonders what other shuttle systems were designed
with comparable disregard of basic principles.

@_date: 2003-01-07 09:18:45
@_author: John S. Denker 
@_subject: Jon Johansen acquitted 
OSLO, Norway (CNN) -- A Norwegian teenager has been
cleared of DVD piracy charges in a landmark trial brought
by major Hollywood studios.
"Johansen is found not guilty," Judge Irene Sogn told the
court. She said prosecutors could appeal against the
unanimous verdict.
The teenager has become a symbol for hackers worldwide who
say making software such as Johansen's -- called DeCSS -- is
an act of intellectual freedom rather than theft.
The studios argued unauthorised copying was copyright theft
and undermined a market for DVDs and videos worth $20
billion a year in North America alone.
But Johansen argued his code was necessary to watch movies
he already owned, on his Linux-based computer, for which DVD
software had not yet been written.
The court ruled there was "no evidence" that Johansen or
others used the decryption code called DeCSS for illegal
purposes. Nor was there any evidence that Johansen intended
to contribute to illegal copying.
The court also ruled that it is not illegal to use the DeCSS
code to watch DVD films obtained by legal means.
In the United States, Johansen's case raised concerns among
Internet users of what they see as a constitutional right to
freedom of expression. A battle is raging in the U.S. over a
1998 copyright law that bans software like DeCSS.
Even though Johansen's software is now outdated, it was the
first to give the so-called source codes, or instructions,
for how to decipher DVD codes.

@_date: 2003-01-07 15:00:41
@_author: John S. Denker 
@_subject: DeCSS, crypto, law, and economics 
Regarding the acquittal of Jon Johansen, I quoted CNN
as saying:
Some elements of the industry did indeed claim that,
but such claims are grossly irrelevant, and to bring
them up is foolish or dishonest.  This case was never
about unauthorized _copying_ of DVDs.  You can make a
bit-for-bit perfect copy of a DVD without decrypting
it.  Indeed it's easier to copy if you don't decrypt
The main thing the industry really had at stake in
this case is the "zone locking" aka "region code"
system.  The studios like to release videos in
different parts of the world at different times,
and to charge different royalty fees in different
places.  This is called market segmentation. The
idea of an open-source player was abhorrent to them,
because it makes it easy to buy a DVD in one region
and play it in other regions.  This is an example of
For "normal" products, market segmentation is neither
forbidden by law nor protected by law.  Mushrooms that
cost $4.00 per ounce at the supermarket can be purchased
for $4.00 per pound at the Asian grocery down the street.
The stores are free to charge whatever they like, and I
am free to shop wherever I like.  The law is silent on
the issue.
People who engage in market segmentation are always
looking for ways to prevent arbitrage.  For instance,
airlines make sure tickets are non-transferable, to
prevent some ticket agent from stocking up on tickets
at "excursion" prices and reselling them to business
Movie studios never had a really good market segmentation
system, because
  -- I can legally own region-1 or region-4 DVDs or some
of both, no matter whether I live in the US or Australia.
  -- I can legally own a region-1 or region-4 DVD player,
or both, no matter whether I live in the US or Australia.
To be clear: the industry was never able to erect a legal
barrier to arbitrage of disks _or_ arbitrage of players.
The closest they could come was to make it slightly hard
to get a _multi-region_ player.  The manufacturers of
player hardware had to do the studios' bidding because of
the the controversial (to say the least) "anti-circumvention"
provisions of the 1998 "DMCA" law.
If we somewhat charitably assume the studios knew what
they were doing, their whole market segmentation scheme
was predicated on the lack of multi-region players _and_
on the assumption that players would remain sufficiently
expensive that users couldn't just buy a stack of players,
one per region.  Less charitably the scheme was predicated
on the foolish assumption that nobody would ever discover
the possibility of inter-region arbitrage of player
I repeat, the practical issue in this case was never about
cheating the studios out of their per-disk royalties on
At this point you might be wondering about per-player
   First, let's dispose of an irrelevant side-issue.  The
   rights to patents on raw DVD hardware are held by a
   consortium of hardware companies, not movie studios.
   These people presumably collected their cut when Mr.
   Johansen purchased his raw DVD drive hardware.  So
   this case was never about patent infringement.
The studios arguably hold intellectual property rights
in the CSS decoding keys, and they can collect per-player
royalties from hw mfgrs who incorporate such keys in
their products.  AFAIK Mr. Johansen never copied any
such key (or even had one he could have copied), so
this case was never about illegal copying even on a
per-player basis.
The truly amazing thing about this case is that the
"crime" would not have occured if the studios had used
decently-strong crypto.  It's ironic that in an age when
for cryptographers enjoy a historically-unprecedented
lopsided advantage over cryptanalysts, the industry
adopted a system that could be cracked by amateurs.
This probably wasn't simply due to stupidity in the
industry; it is more plausibly attributed to stupidity
in the US export regulations which induced the industry
to use 40-bit keys.
So what we have here are remarkably intrusive laws:
under US regulations the crypto must be easy to break,
while under US law it is illegal to break it.  The
latter is dressed up as a "copyright" law even if no
illegal copying is involved.
This strikes me as analogous to requiring everyone
to use pin/tumbler locks with only a single pin, so
that all locks can be picked using a popsicle stick,
and then arresting people for burglary whenever they
are caught carrying a popsicle stick.
US law is not the same as Norwegian law.  You should
not imagine that this case sets a precedent for US
Additional remarks:
We should try to avoid overwrought arguments about the
"morality" of market segmentation and/or arbitrage.
Producers and retailers will always try to benefit
themselves by segmenting the market;  consumers and
arbitrageurs will always try to benefit themselves
by defeating market segmentation.
In fact it is easy to demonstrate that _some_ market
segmentation is good for society as a whole.  Please
refer to the graphs in
   In both graphs, the abscissa is the total number of units
(N), for some product.  There are three different ordinates,
all denominated in dollars, namely
  -- the total cost of producing N units (shown in blue),
  -- the total consumer value of consuming N units,
     (shown in red), and
  -- the total market dollar-volume (shown in green).
In both graphs, the blue production-cost curve has a
large Y-intercept at N=0 and a rather small slope
everywhere else.  This is characteristic of a wide
range of products including DVD movies, which have
enormous fixed costs and remarkably small incremental
costs.  Meanwhile, the slope of the red customer-value
curve is steep for small N and less steep for larger N,
conveying the idea that the product is more valuable
to some consumers and less valuable to others.
In the top graph we arbitrarily assume that everybody
pays the same price -- no market segmentation.  Then
the maximum N that can be sold is shown by the tick-mark
on the axis:  this is the point where the market price
(the slope of the green curve) equals the incremental
customer value (the slope of the red curve).  You
can't sell any more units because the product isn't
worth it to additional customers at that price.
The "created wealth" is given by the length of the
magenta line, the difference between the customer-value
curve and the producer-cost curve.
Now we turn to the lower graph, in which there is
some market segmentation.  The customers who value
the product less highly are allowed to buy the product
at a lower price.  This process absolutely necessarily
ends at the point shown by the tickmark on the lower
axis, because this is the point where the incremental
producer cost (the slope of the blue curve) equals the
incremental customer value (the slope of the red curve).
This is the point of maximal created wealth;  there is
no way to sell a larger number of units N without
somebody taking a loss, so that's not going to happen.
Note that in the absence of market segmentation,
the society as a whole is worse off.  Given the
producer and consumer curves shown in the figure,
or anything qualitatively similar, there is no
unsegmented solution that maximizes the created
wealth.  If the sellers insist on selling every unit
at the highest possible price, society loses.  If the
buyers insist on buying every unit at the lowest
possible price, society loses.
It would be the height of foolishness and the height
of hypocrisy to pretend that whatever favors my selfish
interests is "moral" while whatever favors somebody else's
selfish interests is "immoral".  Much of the debate about
intellectual property issues, on both sides, stinks of
foolish hypocrisy.
There are two not-quite-separate sensible questions:
  -- Find a way to maximize the created wealth.
  -- Decide how to divvy up the created wealth among
the various stakeholders:  inventors, authors, performers,
publishers, manufacturers, wholesalers, retailers,
consumers, et cetera.
It would be nice to have an enlightened discussion of
such topics.

@_date: 2003-01-10 13:09:04
@_author: John S. Denker 
@_subject: DeCSS, crypto, law, and economics 
John Gilmore wrote in part:
 > firmware refuses to write in the key area of the disk, and the blank
 > disks are shipped with the key area obliterated.  (And, DVD readers
 > will only let you read out the keys from a disk after you've reverse
 > engineered some simple bits that the industry wouldn't reveal.)  So
 > you can't do any bit-for-bit copying of DVDs unless you have a very
 > expensive (and restrictively licensed) DVD mastering press.
That's an interesting bit of technology, but it
cannot be considered a cryptographically-strong
anti-piracy scheme.  Any (unPalladiated) software
player could be patched to remap the "key area" to
another part of the disk (with an insignificant
loss of total disk capacity).
As a general principle, it's hard to talk about
security unless you are clear about what the security
boundary is.  As applied to DVDs, this means they
didn't have a chance of being secure unless all the
security-related processing steps were performed
inside tamper-resistant hardware.
Also note that if your goal is to make pirate disks
that play on living-room-grade players, it is not
even sufficient to have DeCSS||remapping, because of
low-level hardware incompatibilities.  You cannot
play a home-made unencrypted disk in many living-room
grade players.
To summarize, the necessary condition for piracy is
something like
    (DeCES||remapping) && low_level_compatibility
The compatibility matrix for unencrypted disks is
something like:
                              living-room   computer
                                player      RW drive
                              -----------------------
   commercially-pressed disks    yes         yes
   home-made DVD+R or DVD+RW   often no      yes
 > bit-copying ability ....  No other major computer
 > storage technology has lacked it
It depends on what you mean by "major" and "computer".
The video-game industry is huge.  Since its earliest
days it has distributed many games on cartridges for
which most consumers lack bit-for-bit copy capability.
Not-easily-copyable media do not actually cause the
earth to fall out of its orbit.  Some people may
object to them on political or philosophical grounds,
but that's another matter.
I wrote in part:
 >> We should try to avoid overwrought arguments about the
 >> "morality" of market segmentation and/or arbitrage.
What's wrong with my "tone"?  I was trying to
set a tone of moderation.  That will seem "wrong"
to extremists on both sides, but complaining
about the tone won't change the facts.
I'm not even sure what "it" refers to (segmentation
and/or arbitrage) but since I'm not an apologist
for either I can reject this accusation without
needing to fully parse it.
Sometimes I'm a buyer.  Sometimes I'm a seller.  I
see no reason to be an apologist for either extreme.
IMHO extremists do everyone a disservice.
How does this make me an "apologist"?  It looks
to me like an inalterable objective fact.
Yes.  And by other means as well, such as (gasp!)
genuine product differentiation.
And I agree with all who have noted that it is
highly ironic that while one part of the US
government is busily negotiating free-trade zones,
to remove geography-based barriers to trade, other
parts of the government are enacting and enforcing
new laws (!criminal! laws) that the studios exploit
to erect novel geography-based barriers.
The concepts are correct.
Various labels are used by various authors; there is
no standardization.
The purpose of terminology is to facilitate communication.
Given no terminology of any kind (standard or otherwise)
that was a_priori well-known to the readership, I have
tried to be clear about what I mean by the terms I use.
I believe anybody who wants to understand will be able
to understand.  (Those who want to not understand will
always find a way to not understand;  there's nothing
I can do about that.)
 >>  Whether the goods can be produced forever is irrelevant,
because the _demand_ is saturated at the point in question
(left of the point of max created wealth, in the absence
of segmentation).  There is no benefit to anyone in producing
goods for which there is no demand.
Please do not misread my curves.  My ordinates represent
cumulative value and cumulative cost.  Most "econ 101"
textbooks present something else, namely per-unit price
curves, which are the derivative of my cumulative curves.
I greatly prefer the cumulative curves, because they can
readily represent such things as
  -- sunk costs (e.g. the Y-intercept of the blue line), and
  -- the created wealth (the length of the magenta line).
.. whereas the per-unit curves cannot reasonably represent
such things.
 > where society maximizes gains.  That is
 > the optimum profits, not the optimum wealth.
I cannot imagine how my presentation could be so
grossly misinterpreted.
The market I described (the green line in the figures)
can be clearly seen splitting the created wealth (CW)
more-or-less evenly between the producers and the
consumers.  Maximum producer profit would be described
by a much higher green line, hugging the red line.
There is no rational basis for such an assertion.
First of all, when market segmentation is being
discussed, there is no such thing as "the" price.
There is an ensemble of prices, one per segment.
Rational economic principles require the "incremental"
unit -- the very last unit -- to go for the lowest
possible price.  This is a statement about the slope
of the green line at the endpoint of the green line.
  -- This condition on the slope does not seriously
     constrain the height of the green line, i.e.
     the way in which the CW is divvied up between
     producers and consumers.
  -- This condition on the incremental unit does
     not require other units to sell for the same
     price.
I remind everyone that I said
When I said _some_ segementation I meant _some_
segmentation [emphasis in the original].
I did not say we should put the fox in charge of
the henhouse.
  -- When I'm selling, I might hope for a seller's
   market (green line near the top of the feasible
   region).
  -- When I'm buying, I might hope for a buyer's
   market (green line near the bottom of the feasible
   region).
But I'm not so hypocritical as to think I'm entitled
to whatever most benefits me.  In the real world,
commerce revolves around _mutually beneficial_ bargains.
The seller benefits and the buyer benefits.
I'm not interested in bogus economic "principles"
that buyers invent in order to "prove" that all
markets must be buyers' markets ... or sellers
invent in order to "prove" that all markets must
be sellers' markets.
 > dominance, economists get a headache.
Really?  Maybe some of them do, but I suspect most of
them wouldn't formulate it as a conflict at all;  they
would just ask "how much do you want to pay for your
Example:  Suppose you have the choice of either carpooling
to work or taking your own car, solo.  The latter gives
you more liberty as to when you drive home.  But it comes
at a cost.
I stand by what I wrote before.  We should maximize
the created wealth, but that is not the whole story;
we also need to arrange that the created wealth is
divvied up in a reasonable way.
Competition is not an end unto itself.  It is
_sometimes_ a means toward an acceptable divvying.
  -- Examples abound where it works amazingly well.
  -- Examples abound where it doesn't work and
   other means must be employed.
To be explicit about what I'm claiming and what I'm
not claiming:  A low-level supply versus demand
analysis (what-does-it-cost versus what-is-it-worth)
produces the curves shown in the figure and predicts
how much created wealth there will be.
But that's not the whole story.  We need to figure
out how the created wealth will be divvied up, and
the low-level analysis does not address that.
If you want to predict the market price (the slope
of the green line) the low-level analysis makes a
definite prediction about the incremental unit, but
for every other unit it predicts a _range_ of feasible
prices, i.e. a _solution set_ rather than a unique
solution to the price question.
There are ways to take the analysis to the next level,
in hopes of more fully describing/predicting the green
line, but then things become much more dependent on
details.  We can go there if people are interested, but
for now I don't need to go there;  my original statement
was crafted in terms of "society as a whole" precisely
so that it could be fully appreciated using only a
low-level analysis:
 >> In fact it is easy to demonstrate that _some_ market
 >> segmentation is good for society as a whole.

@_date: 2003-01-21 13:50:35
@_author: John S. Denker 
@_subject: Patents as a security mechanism 
That's an oversimplification.  Patents "were originally
intended" as a bargain between the inventors and the
society at large.  Under the terms of this bargain, the
inventors make public (which is the root meaning of
"patent") the details of the invention, rather than
thereby advancing general knowledge and permitting
follow-on inventions.  In exchange the inventor was
granted limited protection from competition.  In the
absence of a patent system, inventors will try to
keep everything a trade secret, which is another way of
fending off competition for a while.  From society's
point of view, patents are generally better than trade
secrets.  From the inventors' point of view, patents
are generally better than trade secrets.  So we have a mutually-beneficial bargain.  Patents "were originally
intended" to be a win/win proposition.
Of course it is axiomatic that whatever you're doing,
you can always do it wrong.  We can debate whether the
current system fulfills the original intention, but
let's not go there right now.
An interesting observation.
 > I'm a bit skeptical about whether this really is effective
So am I.
 > (and at least one legal case, Best v. Ilco, casts some
It's amusing that Best had a utility patent and a
design patent, both of which were held invalid (on
different grounds).  It is the design patent which
I think speaks most clearly to the point Matt is
   The following sounds like a nit, but I think it is
more than that:  I think it is the _CSS licenses_
rather than the "DVD patents" that play the role
of protecting the region coding system and reducing
the availability of multi-region players.
This gets back to the "bargain" discussed above,
because the CSS license is based, as far as I can
tell, on trade secrets.  No particular patents are
mentioned in the CSS license forms I've seen;
instead there is much mention of "Highly Confidential
Perhaps a more important point is the economic angle.
Let's re-examing the statement:
 > Many users actually prefer these patented products
We need sharper terminology.  We need to unbundle
the "products";  that is, we have a _lock_ product
and a _key_ product.  It is unsafe to assume that
whoever buys the lock product is the same person
who buys the key product.
Whoever pays for the locks has a vested interest
in high-security locks that open to as few keys
as possible.  Whoever pays for the keys, on the
contrary, has a vested interest in keys that are
extra-powerful and/or cheap and extra-widely
Suppose some party "Alice" controls a restriction,
such as a patent or trade secret.  Alice will try
to sell the restriction to the lock-buyer, "Larry",
who benefits directly from the security.  Larry
won't buy it unless he is convinced that Alice is
willing and able enforce the restriction against
key-makers and key-buyers such as "Kathy".
 > a security mechanism?
Not that I know of.
So we have a grand total of less than one valid
  -- CSS depends on secrecy, which is by definition
the opposite of patentcy.
  -- Best v. ILCO held that patenting key-blanks is
an abuse of the design-patent law.
I think this is as it should be.  That's not the
proper purpose of patent law.
Of course if you ask about non-patent laws, there
are many examples:
  -- in some jurisdictions it is illegal in general
     to carry lock picks.
  -- in some jurisdictions it is illegal in general
     to copy a key marked "do not duplicate".
  -- copyright law is sort of a "do not duplicate"
     stamp protecting original creative works against
     certain types of duplication.
  -- DMCA makes it a federal criminal offence to
     circumvent triple-rot-13.

@_date: 2003-06-07 12:44:05
@_author: John S. Denker 
@_subject: Quantum crypto, from BBC 
It's been discussed here some, and discussed elsewhere
plenty.  I get 19,000 hits from
 > Is there something to this?
It depends on your definition of "something".
Quantum cryptography is perfectly real and is
fascinating in an academic sort of way.
The available products are somewhere between "not
very practical" and "ridiculous" if you ask me.
Most companies can't be bothered to do classical
crypto properly.  The idea that they would pay the
incremental cost to step up to quantum crypto seems
far-fetched to me.
On the scale of physics hype, quantum crypto in
particular and quantum computation in general are
nowhere near as bad as cold fusion, but perhaps
comparable to high-Tc superconductors, which had
a definite basis in fact, but their practicality
was wildly overclaimed.
This is not new news.
Tee hee.  Very funny.  I don't think "trade and industry"
considerations are the driving force here.  I think the
military and the cryptologic agencies have rather larger
budgets than the Department of Trade and Industry, and
they are really who's paying for the flurry of R&D.
If you want to improve the fact-to-hype ratio, go to
   and type "cryptography" in the 'abstract' box.  I get
82 hits in the range 2001-to-date.  And those lead to
yet other references.

@_date: 2003-06-08 18:16:27
@_author: John S. Denker 
@_subject: An attack on paypal 
>
 >>Attached is a spam mail that constitutes an attack on paypal similar
 >>in effect and method to man in the middle.
Yeah, I've been seeing that one for a month or
two now.  I've seen several versions.  Some of
them are quite well done.  I imagine they get
more than a few victims.
I would have thought that the perpetrators would
have been too afraid of stings to try something
so bold.  The existence of such schemes is a sad
commentary on the state of law enforcement.
 >>The bottom line is that https just is not working.  Its broken.
You guys are talking past each other.
All statements of the form.
  -- foo is working (or not)
  -- foo solves the problem (or not)
are so imprecise as to be useless.
It is better to talk about a definite specification.
Then we can ask whether foo meets the spec or not.
If you ask whether a given https implementation meets
the https specifications, then quite possibly it does.
So in this sense the technology is not "broken".
But if you ask whether https makes the world safe
for naifs to conduct e-commerce, by protecting them
from all possible spoofs and MITM attacks, then no,
it certainly does not do that.  There are some who
rashly claimed it was supposed to do that, so in
this sense it is quite broken.  It fails to meet
the broader spec.

@_date: 2003-06-11 12:53:25
@_author: John S. Denker 
@_subject: https for virtual hosts (was: attack on paypal) 
A reasonable workaround might be something like:
       ... to allow isolated IPv6 domains or
    hosts, attached to an IPv4 network which has no native IPv6 support,
    to communicate with other such IPv6 domains or hosts with minimal
    manual configuration, before they can obtain natuve IPv6
    connectivity.  It incidentally provides an interim globally unique
    IPv6 address prefix to any site with at least one globally unique
    IPv4 address, even if combined with an IPv4 Network Address
    Translator (NAT).

@_date: 2003-06-22 17:15:47
@_author: John S. Denker 
@_subject: authentication and ESP 
> As far as I can tell, IPsec's ESP has the functionality of
 > authentication and integrity built in:
It depends on what you mean by "built in".
  1) The RFC provides for ESP+authentication but
does not require ESP to use authentication.
  2) Although the RFC allows ESP without
authentication, typical implementations are
less flexible.  In FreeS/WAN for instance, if
you ask for ESP will get ESP+AH.
ESP without authentication may be vulnerable to
replay attacks and/or active attacks that tamper
with the bits in transit.  The degree of vulnerability
depends on details (type of chaining, higher-level
properties of payload, ...).
Remember that encryption and authentication perform
complimentary roles:  Suppose Alice is sending to
Bob.  They are being attacked by Eve.  Encryption
limits the amount of information _Eve_ receives.
Authentication prevents tampering, so _Bob_ can
trust what he receives.
It is possible to construct situations where you
could omit the AH from ESP+AH without losing
anything, but you would need to analyze the
situation pretty carefully.  If you have a good
reason for using something other than ESP+AH,
please clarify what you want to do and why.
Otherwise just go with the normal ESP+AH.

@_date: 2003-03-05 16:57:17
@_author: John S. Denker 
@_subject: Wiretap Act Does Not Cover Message 'in Storage' For Short  Period 
> In order to avoid overreaction to a nth-hand story, I've attempted to
 > locate some primary sources.
 >
 > Konop v. Hawaiian Airlines:
 >   [US v Councilman:]
 >  Well done.  Thanks.
 > I'd be interested in any opinions on how this affects the government's
 > need to get specific wiretap warrants; I don't know if the law which
 > makes illicit civilian wiretapping illegal is the same code which
 > governs the government's ability (or lack thereof) to intercept
 > communications.
0) IANAL.  But as to the question of "same code", the
answer is clearly "no".
1) As to government-authorized intercepts, see
which gives a plain-language discussion of at least
eight different standards under which some sort of
authorization could be obtained.
Also note that neither Konop nor Councilman involved
government intercepts, so you can't learn anything about
authorized intercepts by studying them.  Also note that
post-9/11 laws have superseded everything you might
previously have known on the subject.
2) As to intercepts by civilians, it's wrong, and it
may be punishable under many different theories and
standards, including invasion of privacy, copyright
infringement, computer trespass, computer vandalism,
simple theft of things of value, and who-knows-what
3) As to unauthorized intercepts by government agents,
in "theory" it is exactly the same as item (2), but
in practice your chance of seeing anybody punished
for it is comparable to your chance of seeing a State
Trooper ticketed for speeding, tailgating, weaving,
and failing to signal turns enroute to the donut shop.
They're doing God's work, you know;  why should mere
laws and bills of rights apply to them?  About the
best you can realistically hope for is the exclusionary
rule (illegally siezed evidence can't be used against
you) but I wouldn't necessarily count on that.
4) Crypto-related sidelight: I wonder what would
have happened if Konop had encrypted his sensitive
data. (eBook format or the like. :-)  Then could he
have used the draconian provisions of the DMCA
against his opponent (Hawaiian Airlines)?????

@_date: 2003-03-05 20:03:40
@_author: John S. Denker 
@_subject: Wiretap Act Does Not Cover Message 'in Storage' For Short Period 
Well, there could have been one other slight source
of doubt, namely the theory that communications "with
no expectation of privacy" are not private and intercepting
them is free-for-all.  Talking out loud in a public
place, for instance.  US laws going back to 1934 if not
earlier made it clear that most wired transmissions
were to be considered private.
Wireless is a horse of a different color.  IANAL but
the last time I looked, there was no federal law
against intercepting most wireless signals, but you
were (generally) not allowed to disclose the contents
to anyone else.  I don't know what that means in
practice.  Perhaps I can act on the information, so
long as I don't "disclose" it?  Plus there is a welter
of state laws.  And cellphone transmissions are a more-
protected special case.
In the communication industry (e.g. for tariff purposes)
the usual test for whether something is a "stored"
message is whether the storage adds value to the service.
The delay that occurs in a store-and-forward network does
not make it a "storage" service.  This criterion has been
very closely examined in connection with fly-by-night
voice-over-IP telephony schemes, most of which are competitive
only if they don't have to pay the tariffs that phone
companies have to pay.  The tariffs distinguish IP from
telephony on the theory that IP is used to access "stored"
data -- but if IP is used for telephony that theory goes
out the window.  Big mess.
The reason why wiretap warrants are (were?) harder
to get is because they are insidious:  If somebody
comes to my house to sieze my papers I generally
know about it.  But if somebody siezes my bits
while they are entrusted to some third party's
wire, how am I supposed to know?
For this reason and others, I very much doubt that
Congress intended different treatment for
  -- data in transit on a wire versus
  -- data in transit in a store-and-forward switch.
The intention, I assume, was a distinction between
data in transit and data truly stored at the
endpoint, under control of the end user.
We should want the standards for siezing data in
transit to be just as high as the standards for
a "sneak and peek" search warrant, considerably higher
than for an ordinary above-board search warrant.
Since the Konop case didn't involve warrants or
government searches, I doubt anything that judge says
will have much effect on this issue.  I think we
should be much more worried about the USA PATRIOT
act and the son-of-PATRIOT act that Ashcroft's
aides say isn't being drafted.

@_date: 2003-03-06 10:44:00
@_author: John S. Denker 
@_subject: Wiretap Act Does Not Cover Message 'in Storage' For Short  Period 
Next time, before disagreeing with someone:
   a) Please read what he actually wrote, and
   b) Don't quote snippets out of context.
Three sentences later, at the end of the paragraph that
began as quoted above, I explicitly pointed out that

@_date: 2003-05-23 08:37:47
@_author: John S. Denker 
@_subject: baseline privacy ... not 
Hi --
1) In a cable-modem system, the layer-1 signal to/from
your cable is physically present in your neighbors' homes.
2) To defend against the obvious privacy problems this
implies, the standards provide for Baseline Privacy (BPI)
which encrypts the signals.
So you're safe, right?
3) Evidence suggests that most cable-modem customers in
the US are not protected.  Many service providers have
Baseline Privacy turned off.  Defeated.  Disabled.
Skipped.  No privacy.
The evidence for this comes from
  -- directly examining the configuration of a few modems
  -- talking to The Cable Guy
  -- noting that when certain small providers do implement
     BPI, they brag about it and claim this gives them an
     advantage over the "established" providers.
        4) From this it appears that in most cases, all that
protects your privacy is security-by-obscurity.
And if you want an upper bound on how much obscurity
there is, note that there is a vibrant community of
cable-modem firmware hackers:
   5) It's interesting to think what customers ought to
do about this, short-term and/or long-term.
  -- Obviously end-to-end security is needed.  But it is
not always feasible at present.  I would connect to google
via SSL if I could, but google doesn't implement https.
And that would still leave me open to traffic analysis.
  -- Link-by-link security is never a substitute for
overall security, but you need some link-by-link security
just to cut down on traffic analysis and DoS attacks,
including ARP poisoning and the like.
One idea that comes to mind is to use IPsec to secure the
connections to an onion routing system.  Or mist / crowd /
Comments?  Suggestions?
