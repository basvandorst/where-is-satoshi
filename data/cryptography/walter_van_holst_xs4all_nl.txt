
@_date: 2013-09-10 18:07:25
@_author: Walter van Holst 
@_subject: [Cryptography] Usage models (was Re: In the face of 
Which is pretty spot-on and one of my biggest gripes about OTR. It just
doesn't mesh at all with user's expectations.
Sounds like another Freedom Box...
Anyway, if we consider each device an end-point to a group-chat that has
to be verified at least once by another end-point (and that is a
somewhat doable thing, e.g. the socialist millionaire's problem), what
about having end-points being able to vouch for other end-points?
For example if I introduce my smartphone to an already existing instant
messaging chat, I can vouch for it through my PC and if other end-points
already trust my PC, there is no reason not to trust my smartphone either.
If this is a dumb idea, feel free to point it out.
 Walter

@_date: 2013-09-18 19:31:34
@_author: Walter van Holst 
@_subject: [Cryptography] Gilmore response to NSA mathematician's "make 
What makes me a tad bitter is that we apparantly live in a world with
two classes: US citizens and the subhuman rest of it. NSA-style blanket
surveillance violates the fundamental right to privacy and ultimately
also the fundamental right to freedom of expression.
These are not rights that are solely vested in the exceptional
Americans. The Bill of Tights already alludes to their universality,
although it took the UN Declaration of Human Rights to explicitly
acknowledge their universal nature.
The way the debate is being framed in the USA does not endear the rest
of the world to the USA any more than the USA's track-record in foreign
policy already has.
Other than that I wholeheartedly agree with what you wrote.
 Walter

@_date: 2014-04-27 22:58:07
@_author: Walter van Holst 
@_subject: [Cryptography] GCC bug 30475 (was Re:  bounded pointers 	in C) 
I do practice law and the GNU GPL disclaimer is unlikely to hold water
in any civil law jurisdiction in case of a clear security issue brought
to the developer's attention. It quite likely works for civil liability
in common law jurisdictions (such as most of the USA). That said,
product liability for software is practically terra incognita in law,
but quite likely to heat up in the near future.
 Walter

@_date: 2014-04-28 07:47:49
@_author: Walter van Holst 
@_subject: [Cryptography] GCC bug 30475 (was Re: bounded pointers in C) 
I never stated that it was for the simple reason that it still is unclear to me whether GCC bug  is such a beast. I was triggered by the blanket statement that the GPL's exoneration clause would make any discussion on liability moot. Which it doesn't in several important jurisdictions. Please note that at no point I said that it was a clear security issue. I simply am not knowledgeable enough for saying such a thing (or the opposite), despite having coded in assembler in some previous life.
No, although a case can be made that if the C language standard leaves so much undefined behaviour that gives rise to so many security issues despite decades of experience with it, it might be software engineering malpractice to write anything critical in C. The opposite case can be made that there are industry best practices that allow for security critical code written in C (see the OpenBSD project), but then the lack of adhering to such industry practices could be an indicator, etc.
That would not shield you from liability (in most civil law jurisdictions, mind you) if there is a security issue that is introduced willfully or through willfull neglect. Even the fact that you can always audit free software may not shield you from such a case. So yes, if there is a *real* security issue, not fixing it or not at the very least publishing the issue may make you liable. Liability is not necessarily about an error, but about your lack of enabling others to mitigate any damages that arise from your error.
Actually, the commonly held analysis of the GPL is that it *is* a contract in civil law jurisdictions. No matter what the FSF may be saying, it just is.
Which is a very Anglo-American perspective. While I love the well-argued court opinions (and the dissenting opinions) it produces, it doesn't allow for much common sense. Again, in civil law jurisdictions it doesn't work that way. You're most likely to be laughed out of court if you were to sue for malpractice if you heeded the legal advice of some random person on some random mailing list.
  Walter

@_date: 2016-04-05 07:12:35
@_author: Walter van Holst 
@_subject: [Cryptography] Hayden on encryption v. metadata 
"reasonable expectation of privacy" may still be a thing in the US context. It is not a terribly relevant criterium in most of the rest of the industrialised world which has moved on to more sensible legal doctrines, such as informational privacy. Reasonable expectation of privacy is a fallacy because it is extremely vulnerable to technological developments. See the following statement:
"Anyone who voluntarily lives in a house that is inherently permeable by UWB radar has no, repeat no, reasonable expectation of not being Or apply your own statement to good old wired telephony. Or analog broadcast media. You'll notice that what you are saying is that because of the underlying technology changes, all of a sudden our privacy expectations should change.
  Walter

@_date: 2016-04-05 19:23:31
@_author: Walter van Holst 
@_subject: [Cryptography] Hayden on encryption v. metadata 
As a legal doctrine. I do law, I don't do reality ;-)
The fundamental difference between the US and the EU hypocrisy that you are rightfully pointing out is that the EU and the CoE have legal mechanisms for redressing that hypocrisy. Those mechanisms are being actively used and are highly likely to have the reining in of GCHQ and others as a result.
Since the Amnesty International USA SCOTUS case we know that even as an American citizen you don't have standing unless you can prove harm. Something the European Court of Human Rights (ECtHR) specifically has addressed in the Sakharov case in which it ruled against Russia's blanket surveillance. Which makes me willing to bet that it will rule against the UK and NL in the GCHQ case later this year. There is not even a glimmer of hope for such a viable case in the US context.
And that was the fundamental issue in the Schrems-case, the Court of Justice of the European Union (CJEU) had a reasoning that was pivoting on a lack of redress, no less than on the blanket surveillance.
No it is not. It is unreasonable to track someone everywhere that someone goes because you *can*. Because it ultimately destroys fundamental values we hold dear in a democratic society with the rule of law. Values like freedom of expression, freedom of association, religion and of conscience. Because all that "harmless" meta-data provides insights in your attendance of your place of worship, the books you read, the people you talk to etc. People will and do change their behaviour in the face of such pervasive monitoring.
It is not unlike saying "It's unreasonable to expect not to get raped if you walk around naked, even if you do so without realising".
The growth of our data shadows is a reason to have proper frameworks safeguarding the values I mentioned, not an excuse to strip us from our fundamental rights.
  Walter

@_date: 2016-08-27 08:05:14
@_author: Walter van Holst 
@_subject: [Cryptography] programming languages and the people who (don't) 
was "NSA-linked Cisco exploit poses bigger threat than previously thought"
And now there's a C-to-Rust translator:   Walter

@_date: 2016-02-23 23:32:10
@_author: Walter van Holst 
@_subject: [Cryptography] RIP Claude Shannon 
It was an era in which managers, politicians and generals did not suffer from less hubris than today. It was also an era in which the boffins were dealt with a modicum of respect. If they said it couldn't be done it might be possible to do it, but everyone except Stalin knew that trying to bend the laws of nature through sheer coercion was a road in which way madness lies.
  Walter

@_date: 2016-02-24 21:36:40
@_author: Walter van Holst 
@_subject: [Cryptography] RIP Claude Shannon 
Because voice gives an immediate interaction and allows for more of a personal relationship, not to mention the little things like intonation and the little bits of non-verbal communication that voice still does. No need for smileys, because you can hear the laughter, anger, grief, disbelief, passion, anxiety etc. in one's voice. Necessary for fast decision-making processes. Telegraphs were used for purposes for which we now use mail. But little beats just sitting face to face to hash something quickly out. And voice telephony comes closest to that.
  Walter

@_date: 2017-12-12 08:14:41
@_author: Walter van Holst 
@_subject: [Cryptography] Rubber-hose resistance? 
Or that they play by the rules, or any rules that matter, to begin with. And that the user will be capable of lying through the teeth. Whereas the reality is that even in democracies a lot of law enforcement/border control officers will try to intimidate anyone they suspect of being a "bad person" (for whatever value of "bad person"). Try being olive skinned, having a few too many Middle Eastern passport stamps while having an Arabic name and getting through US border control with a truecrypt volume.
Other part of reality is that most normal people are incapable of lying all that convincingly under duress to an adversary that isn't willing to let them get away with it. Even your average politician, who is more or less vetted for being capable of bending the truth since not overpromising won't get you elected, typically cannot do it very well.
So yes, most of the "plausible deniability" schemes are just a load of bollocks. I am looking at you, OTR, you hateful, user-unfriendly pile of bovine excrement.
  Walter

@_date: 2017-12-12 21:16:42
@_author: Walter van Holst 
@_subject: [Cryptography] Rubber-hose resistance? 
I have yet to see an implementation that doesn't force the user to force a renegotiation of keys when someone that is part of the conversation has had his/her device suspended. Which happens all the time with laptops and mobile devices.
It also does not allow for a pretty common use case in which at least one side of the conversation switches devices frequently while continuing the conversation.
Less of a design issue, probably more of an implementation issue is that when both sides enforce OTR but the negotiation somehow fails, there's no way to fix this without both sides dropping OTR.
Couple the above issues with the use of UX-wise problematic protocls like XMPP and you end up in a situation in which people just drop OTR to make the conversation happen in the first place.
OTR appears to be designed by people who were thinking in continuous network sessions, not even devices talking to each other, let alone *human beings* having a *human conversation*. Every explanation I have heard so far centered around "plausible deniability". Which is useless. So we have a protocol that's useless from a UX perspective, all for the sake of having "plausible deniability", ergo, being useless.
  Walter

@_date: 2017-02-23 11:39:06
@_author: Walter van Holst 
@_subject: [Cryptography] German govt tells parents to destroy 
While this is a line that has been trotted out by intelligence services to the point of it getting tiresome, I would not consider it an "emerging consensus".
So far both the highest courts in Europe (CJEU for the EU and ECtHR for the Council of Europe) seem to interpret the treaties underpinning fundamental rights in Europe in a way that cannot be reconciled with such a limited notion of "recording".
For examples, look at DRI vs Ireland (CJEU) and Zakharov vs Russia (ECtHR) in which both courts reaffirmed that collection in itself can constitute an illegal intrusion in the right to a private life.
Pointers to evidence of such an emerging consensus, despite the aforementioned jurisprudence of the highest European courts, would be most welcome, obviously.
  Walter

@_date: 2018-03-19 08:56:16
@_author: Walter van Holst 
@_subject: [Cryptography] Avoiding PGP 
OTR + XMPP is from a usability perspective a raging dumpster fire. XMPP has a piss poor support for people changing from device during a conversation, OTR even less so.
And even under "perfect" circumstances I have experienced repeatedly that OTR refused to initiate or stubbornly stuck to an older session. Generating useless errors "you received a message for a different session" in the process.
Whoever designed and/or implemented bloody mess that deserves the same circle of hell as the Microsoft developers who designed their numbered paragraphs bits in Word.
And don´t get me started about the state of play with GPG. A long time ago in a Galaxy far away (well, ok, in 1993) I wrote a quasi-GUI for PGP to make it bearable (it was called PGP-Front). Fast forward to 2018 and the most of the tooling around GPG has only gotten marginally better. Enigmail manages to give you the impression that you have sent encrypted mail when it is actually cleartext. Key management is still an incredible pain in the behind.
Also, in the real world people want to look at their mail from multiple devices. Which is not a terribly good fit with GPG right now. To put it very, very mildly. I have to ask people to resend their encrypted mails in cleartext on an almost weekly basis if it is urgent.
Encryption that causes people to resort to plaintext just isn´t teaching good security habits. Both GPG and OTR fall in that category.
  Walter

@_date: 2018-03-22 09:13:05
@_author: Walter van Holst 
@_subject: [Cryptography] Avoiding PGP 
Using a key to unlock them is nothing out of the ordinary.
No sane person would use that application. If anything people want more integration between their modes of communication, not less. You can scream that is a wish that is bad for security till you see blue in the Usability first. Without usability there is no security.
Also, please stay away from any design decisions that involves artefacts that are going to be used by actual humans.
  Walter
