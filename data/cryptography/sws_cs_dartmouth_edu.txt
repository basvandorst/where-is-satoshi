
@_date: 2002-04-08 17:54:36
@_author: Sean Smith 
@_subject: Call for Participation: 1st Annual PKI Research Workshop 
1st Annual PKI Research Workshop
April 24-25, NIST, Gaithersburg
Registration deadline: April 10
For info and program:
 For registration:
To a large extent, the hoped-for public key infrastructure has not "happened
yet." PKI for large, eclectic populations has not materialized; PKI for
smaller, less diverse "enterprise" populations is beginning to emerge, but at a
slower rate than many would like or had expected. Why is this? This workshop among leading security researchers---from academia, industry,
and government, from US and international---will explore the issues
relevant to this question, and will seek to foster a long-term research agenda
for authentication and authorization in large populations via public key
cryptography. The workshop is intended to promote a vigorous and structured
discussion---a discussion well-informed by the problems and issues in
deployment today.

@_date: 2002-08-11 12:35:12
@_author: Sean Smith 
@_subject: Thanks, Lucky, for helping to kill gnutella  
Actually, our group at Dartmouth has an NSF "Trusted Computing"
grant to do this, using the IBM 4758 (probably with a different
OS) as the hardware.   We've been calling the project "Marianas", since it involves a chain of

@_date: 2002-08-11 16:17:34
@_author: Sean Smith 
@_subject: Thanks, Lucky, for helping to kill gnutella  
i guess it's appropriate that the world's deepest
hole is next to something labelled a "trust territory" :)

@_date: 2002-12-10 16:35:44
@_author: Sean Smith 
@_subject: Research signals safer smart cards  
I haven't been following this as closely as I should.
But what about Chari et al's techniques (and bounds proofs, if I'm
not mistaken) in Crypto 99?

@_date: 2002-01-27 14:16:03
@_author: Sean Smith 
@_subject: Limitations of limitations on RE/tampering (was: Re: biometrics)  
It would be interesting to see how this impossibility theorem reconciles with the last few years of work in encrypted functions...
Sean W. Smith     sws at cs.dartmouth.edu     Department of Computer Science, Dartmouth College, Hanover NH USA

@_date: 2002-07-11 13:16:19
@_author: Sean Smith 
@_subject: IP: SSL Certificate "Monopoly" Bears Financial Fruit  
A colleague of mine just loaded a new root into IE, and pointed
out that when one does this, the new root is apparently BY DEFAULT
enabled for all purposes, including some interesting ones
like "Digital Rights" and "Windows System Component Verification."
I just tried this, and it appears to be the case.  (But I haven't yet tried to see whether Windows will happily use my root for these OS-specific purposes....)

@_date: 2002-03-20 22:23:11
@_author: Sean Smith 
@_subject: Secure peripheral cards  
Well, there's always the IBM 4758, which we built as a general-purpose
secure computer environment for hostile environments, with the ability
for on-device applications to prove to the outside world what they are
and where they're running.
IBM's been marketing it primarily as a crypto accelerator, unfortunately.
The official product pages make it hard to distinguish the box from the
CCA application sw.
For basic architecture stuff:
S.W. Smith, S.H. Weingart.
`Building a High-Performance, Programmable Secure Coprocessor.''
Computer Networks (Special Issue on Computer Network Security.) 31: 831-860. April 1999. For some recent creative applications:
S. Jiang, S.W. Smith, K. Minami.
``Securing Web Servers against Insider Attack.''
ACSA/ACM Annual Computer Security Applications Conference. December 2001
A. Iliev, S.W. Smith.
Prototyping an Armored Data Vault: Rights Management on Big Brother's Computer.
Privacy-Enhancing Technology 2002, Springer-Verlag, to appear.
These and more live at:
Prof. Sean W. Smith                          sws at cs.dartmouth.edu          (has ssl link to pgp key)
Department of Computer Science, Dartmouth College, Hanover NH USA

@_date: 2002-11-27 12:01:44
@_author: Sean Smith 
@_subject: 'E-postmark' gives stamp of approval  
Back when I first heard about this idea (a long time ago),
I wondered two things:
1. What about  Haber and Stornetta's work (and patents)?
2. What's to stop me from setting up "Sean's Discount Postmark Service,"
where, each time unit, I collect document hashes from customers,
build a hash tree, and buy a USPS postmark for the root of the tree?

@_date: 2003-08-27 11:03:40
@_author: Sean Smith 
@_subject: blackmail / real world stego use  
Check out:
Using caching for browsing anonymity Anna M. Shubina, Sean W. Smith Dartmouth TR2003-470 The code's available for download, too.

@_date: 2003-07-14 20:51:11
@_author: Sean Smith 
@_subject: [Fwd: BugTraq - how to coverup the security]  
Does this really surprise anyone?  When I had some students try this out (providing content
that browsers render in a way that makes it look like security info from the browser) a few years ago, there was just no end
to the tricks one could play...
If you don't design a trusted path into the system, why should
you expect there to be one?
Sean W. Smith, Ph.D.                         sws at cs.dartmouth.edu          (has ssl link to pgp key)
Department of Computer Science, Dartmouth College, Hanover NH USA

@_date: 2003-07-15 09:34:35
@_author: Sean Smith 
@_subject: [Fwd: BugTraq - how to coverup the security]  
My point was just that the browser paradigm was not really designed with the
idea of making the security status information always clearly distinguishable
from the content provided by malicious servers.
In our project, we'd looked at popular browser/OS combinations (two years ago),
and found that (with some cleverness) you could produce fairly convincing
impersonations in many scenarios. The barriers were repeatedly permeable. E.g.,
does the browser mark your popup window with a label that spoils the spoof? No
problem: just send an image of the window instead.
As has been mentioned on this list before, we also designed and implemented a
trusted path solution in Mozilla. (But this was complicated by the fact that
each new release of Mozilla seemed to break our code :)
That was the whole point of our Usenix paper last year
E. Ye, S.W. Smith.
``Trusted Paths for Browsers.''
11th Usenix Security Symposium. August 2002

@_date: 2003-07-16 11:17:09
@_author: Sean Smith 
@_subject: [Fwd: BugTraq - how to coverup the security]  
no problem!
No, unfortunately.
According to Eileen (who was the lead on this),
it didn't easily fit into things:
- it was not clearly a "bug fix"
- it touched many modules (so it wasn't clear who would own it)
- it changed the UI in a way that some folks weren't happy with

@_date: 2003-06-09 12:29:42
@_author: Sean Smith 
@_subject: An attack on paypal --> secure UI for browsers  
Minor nit: just Ye and Smith. (Yuan had helped with some of the spoofing)
Advertisement: we also built this into Mozilla, for Linux and Windows.

@_date: 2003-10-22 10:24:17
@_author: Sean Smith 
@_subject: PKI Research Workshop '04, CFP  
Hey, but at least the password was protected by an SSL channel,
which was authenticated by a real certificate signed by one of
the 10^4 trust roots built into your browser :)

@_date: 2003-09-08 17:55:35
@_author: Sean Smith 
@_subject: fyi: bear/enforcer open-source TCPA project 
The Bear/Enforcer Project
Dartmouth College
How can you verify that a remote computer is the "real thing, doing
the right thing?"  High-end secure coprocessors are expensive and
computationally limited; lower-end desktop enhancements like TCPA and
the former Palladium have been mainly limited to Windows and
proprietary development.
In contrast, this code is part of our ongoing effort to use open
source and TCPA to turn ordinary computers into "virtual" secure
coprocessors---more powerful but less secure than their high-assurance
Our current alpha release includes the Linux Enforcer Module, a TCPA
enabled LILO, and a user-level TCPA library.  All source is available
from the SourceForge site.
The Linux Enforcer Module is a Linux Security Module designed to help
improve integrity of a computer running Linux.  The Enforcer provides a
subset of Tripwire-like functionality.  It runs continuously and as
each protected file is opened its SHA1 is calculated and compared to a
previously stored value.
The Enforcer is designed to integrate with TCPA hardware to provide a
secure boot when booted with a TCPA enabled boot loader.  TCPA
hardware can protect secrets and other sensitive data (for example,
the secrets for an encrypted loopback file system) and bind those
secrets to specific software.
When the Enforcer detects a modified file it can, on a per-file basis,
do any combination of the following: deny access to that file, write an
entry in the system log, panic the system, or lock the TCPA hardware.
If the TCPA hardware is locked then a reboot with a un-hacked system is
required to obtain access to the protected secret.
We developed our own TCPA support library concurrently with, but
independently from, IBM's recently announced TCPA library.  Our library
was an initial component of the Enforcer project.  However, our
in-kernel TCPA support and the enforcer-seal tool are derived from
IBM's TCPA code because of its ease of adaptation for in-kernel use.
We plan to use our more complete library for user-level applications.
(IBM's TCPA code and documentation is available from
For more information on our project, see Dartmouth College Technical
Report TR2003-471 available from
Or contact Omen Wild at the Dartmouth PKI Lab: Omen Wild

@_date: 2003-09-09 10:13:06
@_author: Sean Smith 
@_subject: fyi: bear/enforcer open-source TCPA project  
Using a high-end secure coprocessor (such as the 4758, but not
with a flawed application) will raise the threshold for the adversary
No, there are no absolutes.  But there are things you can do.
So you never buy anything online, or use a medical facility
that uses computers?

@_date: 2003-09-10 13:57:41
@_author: Sean Smith 
@_subject: fyi: bear/enforcer open-source TCPA project  
Go read about the 4758.  CPU speed won't help unless
you can crack 2048-bit RSA, or figure out a way around
the physical security, or find a flaw in the application.
But (at a high-level) there are things that are awkward
or extremely impractical to do with, say, multi-party computation.
That's where the "secure hardware" work---from Abyss, to TCPA, to
plastic-speckles, to the CPU+ work at MIT and Princeton---comes in.

@_date: 2003-09-11 08:32:47
@_author: Sean Smith 
@_subject: fyi: bear/enforcer open-source TCPA project  
It's been on the market for six years now; so far, the foundation
has held up.    (We also were darn careful about the design
and evaluation; we ended up earning the first FIPS 140-1 Level 4
cert, but went beyond it in several respects.)
But there are numerous war stories and drawbacks---which is
why I find the new generation of initiatives interesting.
(Particularly since I don't have to build products anymore! :)
As does the alternative proposition that one should NEVER, under any circumstances, have sensitive data or computation on a remote machine.

@_date: 2003-09-11 10:34:53
@_author: Sean Smith 
@_subject: is "secure" hardware worth it?  (Was:  Re: fyi: bear/enforcer  
Just to clarify... I'm NOT saying that any particular piece of "secure" hardware can never be
broken.   Steve Weingart (the hw security guy for the 4758) used to insist that
there was no such thing as "tamper-proof." On the HW level, all you can do is
talk about what defenses you tried, what attacks you anticipated, and what
tests you tried.
What I am saying is that using "secure coprocessors"---defined loosely, to
encompass this entire family of tokens---can be a useful tool.  Whether one
should use this tool in any given context depends on the context. Are there
better alternatives that don't require the assumption of physical security?
How much flexibility and efficiency do you sacrifice if you go with one of
these alternatives? How dedicated is the adversary?  What happens if a few
boxes get opened?  How much money do you want pay for a device?
Some cases in point: it's not too hard to find folks who've chosen
a fairly weak point on the physical security/cost tradeoff, but still
somehow manage to make a profit.  Of course his all still leaves unaddressed the fun research questions of how to
build effective coprocessors, and how to design and build applications that
successfully exploit this security foundation.  (Which is some of what I've
been looking into the last few years.)

@_date: 2004-08-13 18:33:02
@_author: Sean Smith 
@_subject: Any TLS server key compromises? 
Hi, Marc!
I don't know about in-the-wild attacks.
However, proof-of-concept attacks:
Server-side: Brumley and Boneh did timing attacks on Apache SSL servers---see their Usenix Security paper from 2003.
Client-side: we've done a number of host-based attacks and http-based attacks, to steal or borrow use of a user's client-side SSL/TLS key.    J. Marchesini, S.W. Smith, M.Zhao.
"Keyjacking: The Surprising Insecurity of Client-side SSL"
Computers and Security.  To appear, 2004.
Sean W. Smith sws at cs.dartmouth.edu    Asst Prof, Department of Computer Science, Dartmouth College.
  Director, Cybersecurity and Trust Research Center, Institute for Security Technology Studies.

@_date: 2004-07-18 12:36:21
@_author: Sean Smith 
@_subject: dual-use digital signature vulnerability 
I believe our paper may have been one of those that Lynn objected to.  We used the same key for client-side TLS as well as for signing a delegation certificate.  However (as we made sure to clarify in the revised paper for the final proceedings):
In SSL and TLS, the client isn't signing random data provided by the adversary.  Rather, the client is signing a value derived from data both the client and server provide as part of the handshake.  I do not believe it is feasible for a malicious server to choose its nonces so that the resulting signature be coincide with a valid signature on a delegation cert the client might have constructed.
(On the other hand, if we're wrong, I'm sure that will be pointed out repeatedly here in the next day or two :)

@_date: 2004-07-18 22:08:25
@_author: Sean Smith 
@_subject: dual-use digital signature vulnerability 
Why isn't it sufficient?   (Quick: when was the last time anyone on this list authenticated by signing unread random data?)
The way the industry is going, user keypairs live in a desktop keystore, and are used for very few applications.  I'd bet the vast majority of usages are client-side SSL, signing, and encryption.
If this de facto universal usage suite contains exactly one authentication protocol that has a built-in countermeasure, then when this becomes solid, we're done.
Our energy would be better spent on the real weaknesses: such as the ease of getting desktops to just cough up the private key, or to use it for client-side SSL without ever informing the user.
And on the real problems: such as using the standard suite to get the trust assertions to match the way that trust really flows in the real

@_date: 2004-07-21 11:52:37
@_author: Sean W. Smith 
@_subject: dual-use digital signature vulnerabilityastiglic@okiok.com 
I would have thought that de facto standard approach is: the client constructs the certificate request message, which contains things like the public key and identifying info, and signs it.  The CA then checks the signature against the public key in the message.
Quickly checking with our deployment folks...this is how it works the standard browser/OS suites, with the iPlanet Certificate Management System at the CA.    (We combine CA and RA here.)
It would be interesting to see if there's support software out there that does something as naive as sign a random challenge.  I really suspect this is a strawman...
(Darn it, this is creating the need for some real data: how many X.509 certs are in use today, how many of these are on standard user platforms, what are the keys used for, and how was PoP handled?)

@_date: 2004-07-26 20:07:22
@_author: Sean Smith 
@_subject: dual-use digital signature vulnerability  
For what it's worth, last week, I had the chance to eat dinner with Carlisle Adams (author of the PoP RFC), and he commented that he didn't know of any CA that did PoP any other way than have the client sign part of a CRM.
Clearly, this seems to contradict Peter's experience.
I'd REALLY love to see some real numbers here---how many CAs (over how many users) do PoP a sane way; how many do it a silly way;  what applications people use their keys for, etc.

@_date: 2005-02-04 10:04:50
@_author: Sean Smith 
@_subject: Using TCPA 
check out
We also had a paper at ACSAC 2004 with some of the apps we've built on Two things we've built that haven't made it yet to the sourceforge site:
- an SELinux version
- an OpenSSL engine
Sean W. Smith  sws at cs.dartmouth.edu  Hanover, NH USA  (Where the Appalachian Trail crosses the VT-NH border)

@_date: 2006-04-03 06:36:30
@_author: Sean W. Smith 
@_subject: is breaking RSA at least as hard as factoring or vice-versa? 
Dan Boneh had an interesting paper on this topic a few years back  giving some evidence that that "breaking RSA" might in fact be easier  than factoring.    However, it defines "breaking RSA" as being able  to DO the private-key operation, not as knowing the private key  (because the latter lets you factor).
Boneh and Venkatesan. "Breaking RSA may not be equivalent to  factoring." Eurocrypt '98. Springer-Verlag LNCS 1233. 1998.
Sean W. Smith, Ph.D.  sws at cs.dartmouth.edu  Department of Computer Science, Dartmouth College, Hanover NH USA

@_date: 2006-04-26 15:18:40
@_author: Sean W. Smith 
@_subject: History and definition of the term 'principal'? 
I like the definition in Kaufman-Perlman-Speciner:
"A completely generic term used by the security community to include  both people and computer systems.  Coined because it is more  dignified than 'thingy' and because 'object' and 'entity' (which also  means thingy) were already overused."
Sean W. Smith, Ph.D.  sws at cs.dartmouth.edu  Department of Computer Science, Dartmouth College, Hanover NH USA

@_date: 2006-04-26 22:00:08
@_author: Sean W. Smith 
@_subject: History and definition of the term 'principal'? 
I got that definition from the glossary in the 2nd edition.   I'm  pretty sure it was in the glossary in the first edition as well, but  I can't seem to find my copy anymore!

@_date: 2006-09-09 09:06:36
@_author: Sean W. Smith 
@_subject: RSA SecurID SID800 Token vulnerable by design 
One can have a lot of fun with key-wielding tokens, especially on  Windows.  See:
J. Marchesini, S.W. Smith, M. Zhao.
"Keyjacking: the Surprising Insecurity of Client-side SSL."
Computers and Security.
4 (2): 109-123. March 2005.
Sean W. Smith   sws at cs.dartmouth.edu  Department of Computer Science, Dartmouth College, Hanover NH USA

@_date: 2007-07-02 07:19:26
@_author: Sean W. Smith 
@_subject: TPM hacking 
Seeing as how there are are some rumors about other attacks coming  from BlackHat, I thought we should publicize ours a bit:
A 3" piece of wire does the job.  More info (and a link to a YouTube  demo) at:
Sean W. Smith   sws at cs.dartmouth.edu  Associate Professor, Department of Computer Science, Dartmouth  College, Hanover NH USA

@_date: 2007-07-03 07:13:34
@_author: Sean W. Smith 
@_subject: TPM hacking 
Yes, and that's why we cited Kauer on the page, in Evan's paper, and  in the video!

@_date: 2008-01-03 09:00:12
@_author: Sean W. Smith 
@_subject: virtualizaton and security cfp (was Re: Death of antivirus software imminent) 
With this discussion of virtualization and security, it might be a  good time to note:
