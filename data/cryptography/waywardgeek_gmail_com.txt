
@_date: 2013-12-05 21:24:57
@_author: Bill Cox 
@_subject: [Cryptography] Fun with hardware RNGS: the Infinite Noise Multiplier 
I'm naming this circuit after my daughter.  We're a whole family of severely ADHD people!
I've been trying to crack a simple problem for a few years, thinking about it now and then: how do you generate "true" random numbers on an analog CMOS process designed to be "quiet"?  In 1998, I built a 4-megabit/second hardware RNG that destroyed the DieHard tests back then (I found bugs in the prof's code, rather than his code finding bugs in my hardware).  It relied on zener noise from a breakdown of a Vbe on a N2222 transistor.  Every process is different, so I had potentiometers for tweaking gains and such.  It was a sweet little board, but not mass-production ready.
So, here's my dumb infinite noise multipier.  It's a switched cap circuit doing the following steps:
- Start with a voltage V > 0, but < Vref.
- Multiply V by 2X.
- If V > Vref, subtract Vref
- Repeat forever
The RNG output is 1 whenever we have to subtract Vref, and 0 otherwise.  If there is a tiny bit of noise way down in say the 35th bit position of resolution, then about 35 cycles later, that noise will impact the output signal.  It really doesn't matter how quite the circuit is.  Enough cycles later, you're output will be banging around quite randomly, kind of like some people I know.
Just some fun for the day... true RNGs in ANY process is now very simple...

@_date: 2013-12-07 15:50:17
@_author: Bill Cox 
@_subject: [Cryptography] Fun with hardware RNGS: the Infinite Noise 
Someone asked for some more detail about the design.  I've created a simple
web page describing the Infinite Noise Multiplier here:
Surely someone else has already invented this.  Anyone know where I could
such a circuit described on the Internet?

@_date: 2013-12-07 17:37:03
@_author: Bill Cox 
@_subject: [Cryptography] Fun with hardware RNGS: the Infinite Noise 
Actually, the circuit is highly insensitive to noise from non-random
sources.  Simply imagine the digital version, where we shift out one bit
every cycle.  We can add any signal you like at any amplitude, and all it
does is flip bits that are already randomized, making them no less random.
 Coupling with adjacent circuits, RF, and NSA or China inspired signal
injection attacks are all OK.  The only assumption here is the max
amplitude of the injected signal does not move the signal out of the valid
bounds, and I've got about .2V on both ends.  A an attacker capable of
injecting more than .2V may be able to compromise randomness, but that's a
large signal.
The signal from any one channel will be available in raw form for any
software that wants it that way.  On my 1.5 mm^2 die, I fit 16 channels,
along with pads, and a custom microcontroller I designed.  I don't have
enough digial I/Os available to provide all 16 channels at 8MHz at the same
time, but you'll be able to switch between them.

@_date: 2013-12-09 17:21:05
@_author: Bill Cox 
@_subject: [Cryptography] Fun with hardware RNGS: the Infinite Noise 
Like any clocked digital chip, it will put out some RF, though I expect it
to be low.  This is a slow low power .35u CMOS process, with about 0.4
milliwatt of power per Infinite Noise Multiplier, and there will be 16 of
those.  The clocked comparator in each INM is differential, and should
generate nearly the same power spike for a 1 or a 0.  All other power drawn
by each INM is in the form of constant current sources in the voltage
buffers, so they should be very hard to read from noise on external power
pins.  Shorting the .1pF caps to each other on clock edges doesn't impact
AVDD or AVSS currents, and also should not be detectable from external
power pins.  I do not know if this would be detectable from outside the
package with an RF detector.  Does anyone have a cool application for
microcontroller with a true RNG that needs super-secret random data that
remains secret even when the attacker has a logic analyzer attached to the
chip and some sort of RF detector?  I would need advice on what sorts of
on-chip events are detectable.  I don't have any equipment capable of
detecting such low level RF spikes.
I had some fun yesterday and wrote code to predict the output bits based on
the previous 8.  It achieved a 74.5% success rate predicting the SPICE
output, which is about what I expected.  Today wrote code to eliminate most
of the bias and correlations as a post-process, and it defeats my
prediction code.  The algorithm is pretty cool.  I think I can get the data
to be around 99% free of correlation and bias, while compressing this data
by about 2X.  This would make the bias drop by a factor of 0.02 for each
compressed bit XORed together, rather than the 0.5 I get now, meaning I get
about a 2.8X improvement in output rate at the same quality.  That would
provide bits with no more than about 1e-24 of non-randomness leading to a
rate of about 5 M-bits/sec.
The bias/correlation removal algorithm has two parts.  First, read about a
megabyte (8 seconds worth) from a given channel, and use it to gather
prediction statistics.  For each place a given 8-bit sequence occurs,
record how many times the next bit is a 1 and how many times it's a 0 in
arrays called 'zeros' and 'ones'.  Then, as bits come in, I run the
following C code to remove the detected bias and correlation:
void removeBias(int *data, int length) {
    double prob, lower = 0.0, upper = 1.0;
    int i;
    unsigned char value = 0;
    for(i = 0; i < length; i++) {
        if(data[i]) {
            prob = ((double)zeros[value])/(ones[value] + zeros[value]);
            lower += prob*(upper - lower);
        } else {
            prob = ((double)ones[value])/(ones[value] + zeros[value]);
            upper -= prob*(upper - lower);
        }
        while(lower >= 0.5 || upper <= 0.5) {
            if(upper <= 0.5) {
                upper *= 2.0;
                lower *= 2.0;
                printf("0");
            } else {
                printf("1");
                upper = 2.0*upper - 1.0;
                lower = 2.0*lower - 1.0;
            }
        }
        value <<= 1;
        if(data[i]) {
            value |= 1;
        }
    }
    printf("\n");
For use in one-time-pad encryption or generating keys, I'd still want to
XOR 14 of these 2-to-1 compressed bits together, and then run a
cryptographic randomizer on the results.  I don't think I use any hash
function like SHA-256 which is not reversible, unless someone convinces me
that it does not introduce correlations.  Any permutation should be fine,
such as encrypting the random data with block-chained AES-256 and a random
key.  Does that sound reasonable?

@_date: 2013-12-10 16:26:42
@_author: Bill Cox 
@_subject: [Cryptography] Fwd: [IP] 'We cannot trust' Intel and Via's 
I think there may be weaknesses in Intel's hardware RNG.  I took a good look at Intel's hardware random number generator source. There's a paper analyzing it here:
The basic idea is that back-to-back inverters, when powered on, flip one way or the other randomly, sort of like DRAM memory when our computer's power on.  By powering on a single pair of back-to-back inverters over and over, they can generate a random bit per cycle, at about 3 Giga-bits/second, which is amazing!  Here's my concerns about the the paper:
- I saw no mathematical analysis of how much noise exists in the system and how strongly it will influence the result each cycle. There were generalities about how the noise could cause the output to be random, but no numbers at all.
- There is an assumption that the capacitors are charged/discharged by 10% of the standard deviation of the noise.  I saw no justification for this.  It seems they simply assumed best case.
- The paper is about as objective as a mother talking about her children.  For example: "Overall, the Ivy Bridge RNG is a robust design with a large margin of safety that ensures good random data is generated even if the ES is not operating as well as predicted." Based on what?
- I am not convinced they have the right model for the entropy source.  They add noise to the bias on the capacitors, and compare that to 0 to determine the next output bit in their model.  I think the main source of noise may be the randomness in number of electrons added/subtracted each cycle, and that the back-to-back inverters in the absence of other noise may be acting almost as an ideal comparator.  However, if this were the case, even if there were 10% noise in the number of electrons, there would be considerable correlation between bits.
I also have questions about the design itself.  My main concern is that noise on the VDD rail could easily determine the output.  For example, if the transistors are mismatched, which of course they will be, and the bias is set exactly right on the caps so there's a 50-50 chance of a 0 or 1, and suddenly VDD drops 10% due to a rising edge of the the main system clock, then the inverter with higher gate thresholds will become weak faster than the other one, thus determining which one wins.  Since this circuit runs asynchronously from the main system clock, I could easily see the 3MHz system clock phase relative to the entropy generator clock determining most of the results from the entropy source, while looking fairly random. Any weakness in the raw random data stream is hidden from us by the AES encryption done as a post-process.
I simulated back-to-back inverters in my .35u low power CMOS process in SPICE to see if I could figure out how to make a practical circuit using Intel's topology.  If it works, it would be fantastic.  I think I can get rid of most of the supply noise issues.  I had a similar problem in my "Infinite Noise Multiplier", so I switched to powering the circuit with nothing but large W and L constant current sources, and using the range from 0V to Vref, rather than 0V to VDD, because Vref is stable relative to AVSS. However, I wasn't able to get enough noise to make Intel's ciruit work, though that may be due to limitations in the SPICE Has anyone else had success using Intel's RNG topology?

@_date: 2013-12-10 18:57:31
@_author: Bill Cox 
@_subject: [Cryptography] Fwd: [IP] 'We cannot trust' Intel and Via's 
I have to take back my criticism of Intel's RNG.  I got my sims working for a version of their architecture in .35u CMOS, and it's simply better than my "Infinite Noise Multiplier".  It's probably the best true random noise generator ever.  I still don't like how their schematic is seems highly sensitive to supply noise, but we don't know what the actual circuit looks like.  Intel hasn't told us.
So, I'm going to modify it a bit to use the resistors available on my chip and reduce the caps, fix the supply sensitivity, and I think I can run 16 of these things in parallel at 100-200MHz on the tiny .35u CMOS chip I'm designing.  I'll spit out the raw waveforms from the inverters, buffered once, through 16 "analog" pins, so there wont be any fear (hopefully) that I'm cooking the data on-chip, before you can see it, and I'll open-source the schematics.  If there's a circuit that can consume all 1.6Gbit/sec of this raw data, have fun with it!  On the digital side, I'll XOR bits together to get the bandwidth down to something reasonable, which I can send over USB, and provide a simple Linux driver.
This thing will definitely put out RF, but since I'm making the raw data available at the pins, should I care?  By the way, this is just a for-fun project at work.  I get to do a free chip design :-)

@_date: 2013-12-10 21:35:39
@_author: Bill Cox 
@_subject: [Cryptography] Fwd: [IP] 'We cannot trust' Intel and Via's 
I just had an email asking about possible patent issues with using Intel's entropy circuit.  Well, IANAL, but I skimmed the 86 patents Intel has so far that mention RNG, and they don't cover the entropy source.  They did patent all the crud they do to the data once it leaves the entropy source, but I think no one will mind if I don't do any of that.  I've read a ton of patents, and am listed as an inventor on 25.  I could be wrong, but I doubt it.
So, feel free to copy Intel's back-to-back inverter entropy source, at least until they publish a patent that does cover it.
I think my main concerns using Intel's back-to-back inverters as an RNG is how to fix it... connecting the inverters supply through a clocked PMOS directly to VDD is stupid.  I'd be very surprised if they actually did that.  Hopefully I wont violate any patents while figuring out how to fix that.

@_date: 2013-12-14 08:04:15
@_author: Bill Cox 
@_subject: [Cryptography] An alternative electro-mechanical entropy source 
I like the idea of a completely auditable source of entropy, and the accelerometer is clever.  However, why not use zener noise like many have done before?  I've used the reverse breakdown of a base-emitter in a common N2222 NPN transistor with excellent results - commercial zeners are specially designed to be quiet, but no one bothers with a reverse Vbe.  Just amplify that with discreet transistors, resistors, and capacitors until it's large enough to digitize through an A/D converter, and feed that into a cheap PLD for whitening.  Every part of the flow along the way is auditable.
I've always wanted to design the entropy source directly into an IC, and I'll still do that with my little project, but this conversation has convinced me that what we really need for entropy is low tech discrete solutions.  Your accelerometer idea is fine, but I'd prefer the bit rates I can get from zener noise.

@_date: 2013-12-18 06:58:45
@_author: Bill Cox 
@_subject: [Cryptography] 
=?windows-1252?q?ased_Key_Derivation_for_Elliptic_curve_Diffie=96Hellman_?=
 =?windows-1252?q?key_agreement?=
Very cool!
PBKDF2, just like TrueCrypt?  I hope you decide to have better password security than those guys.  The PBKDF2 key stretching in TrueCrypt is a joke.  You have to find an obscure option to even enable the 2000-round SHA256 key stretching, which provides close to no security at all.  The kinds of passwords your users on Facebook will actually use have very few bits of entropy, and can be guessed by hardware based brute force attacks very quickly.
To have much better password protection, take a look at the key stretching used in FreeCoin: scrypt.  While it is less effective at reducing hardware based password guessing attacks than it should be, it's still many thousands of times more effective than SHA-256 based key stretching.  I wrote some code that is like scrypt but it understands that we should thrash the on-chip cache while keeping the DRAM interface at 100% data transfer rates to more effectively beat hardware based password guessing.  Scrypt causes a cache miss every cycle, enabling hardware that does faster random access to accelerate it's key stretching by a factor of maybe 100.  Scrypt also has some undesirable properties such as needing to put scrypt parameters along side the salt, making it clear that the file is an script based encrypted password rather than random junk, reducing deniability.  My code gets around the weaknesses in scrypt that I perceived, but please just use scrypt rather than untested code. Freecoin proved scrypt works, and that's worth a lot.  Also, you guys will naturally do what everyone should be doing: perform the key stretching in the browser, not on the server.  For example, default Microsoft key stretching is only 1000 rounds of SHA-256 because it's done in ASP.net on the server rather than in the browser.
Now for my tin hat conspiracy theories: Why is Microsoft so stupid about where to perform key stretching?  Why wont the TrueCrypt team adopt decent password security?  Why does PGP have 0 key stretching by default, and why is my SSH private key encrypted with no key stretching and no option to use it?  You want to encrypt Facebook traffic with real security?  I just have to wonder if some tall suits with dark sunglasses are going to convince you to do otherwise.  My other theory is people are really that stupid, whether they write SSH encryption code, PGP, or

@_date: 2013-12-20 23:00:29
@_author: Bill Cox 
@_subject: [Cryptography] Why  don't we protect passwords properly? 
I only dabble in crypto because it's way cool, but I keep seeing signs of either serious ignorance, or amazingly clever social engineering.  Which is it?
For example, last month I pointed out on the TrueCrypt list that their key stretching is a joke, at least if you want to protect data from any organization with many millions of dollars to spend on brute-force password guessing hardware.  TrueCrypt's strongest option of 2000 rounds of AES-512 key stretching is simply not enough to protect passwords real Facebook users can remember.  SHA-XXX (all of them) seem to have been designed specifically to be cheap and fast to compute in custom hardware, while taking forever to compute on modern CPUs.  I especially like the bit position swaps which don't take any computation at all in hardware.  I thought that was a mistake on the web page when I read it the first time.
Scrypt, used by FreeCoin, shows how to do truly effective key stretching, which can protect typical Facebook passwords from even the most well funded government spy agencies.  Nevertheless, the most common tools in use don't include effective key stretching. TrueCrypt is an open source project hosted out of Spain, yet the devs are silent when asked about their ineffective key stretching choice.  GPG and ssh don't key stretch at all by default, AFAIK. How is it possible that the open-source devs who invented and wrote these amazing tools fail to understand basic password security?
I want a straight answer, and I truly don't know what it is.  Is it scary tall dudes in dark suits, or seriously ignorant devs?

@_date: 2013-12-21 09:50:22
@_author: Bill Cox 
@_subject: [Cryptography] Decentralized, global, irreversible, 
This is a fantastic idea.  I've been noodling this a bit, as I'm sure many
people are doing.  For example, we could use such a system to fix a problem
with authenticating public keys.  We typically use "trustworthy"
authorities, like the MIT GPG key server, but if the authority has been
compromised, users might wind up using bogus public keys, or keys that have
been revoked.
With nothing but the ability to publish Merkel hash roots and URLs, we
could replace the central authority with a BitCoin-like somewhat
decentralized authority.  I would simply publish a 256 bit hash root and a
URL to the on-line archive of my valid public keys (or whatever other data
I want to publish).  Any key not listed there would have been revoked.  It
may not be perfectly secure, but I think it would be a big improvement.
Another application I am interested in is publishing stuff in on-line
games.  For example, if my server grants your character an awesome item,
and you would like your character to be able to use that on other servers,
then the other servers could check if that item is currently valid in the
public database.  Security for things like virtual game items is a lot
harder than you might think.  Nothing gets kids hacking servers like good
game stuff.  A system strong enough for real money should be strong enough
for virtual game items.

@_date: 2013-12-21 23:46:59
@_author: Bill Cox 
@_subject: [Cryptography] Why don't we protect passwords properly? 
I don't understand why servers do the KDF rather than the client.  The
current system requires that the password be transmitted to the server, and
users have to trust the service provider to be honest.  This provides a
couple ways for attackers to compromise the password.  Just pay off the
guys running the server ($10M anyone?), issue them a court order of some
sort, or override the CA and do the man-in-the-middle thing.  As soon as
you transmit your password to the server, security is already broken.
With client-side KDF, the DDoS issue goes away, the servers have a far
lighter load, and users get real password security.  Why is the current
flawed system used?  I just don't understand it.
The guys in charge of mainstream crypto algorithms don't seem to be doing
KDFs very well.  It's not just the lame server-side KDFs.  The one that
really bothers me is TrueCrypt, which in user-land is more popular than all
the rest combined by a factor of several.  About 90% of all file encryption
in user-land (not corporate or server side) is done in TrueCrypt.
I've scanned through the code, and the strongest KDF you can select is 2000
rounds of AES-512.  By default it uses something far weaker.  From BitCoin,
we learned that custom hardware can deliver SHA-256 hashing at a rate of 1
giga-hash/second for $10.  If you have on the order of $1B to spend, you
can do 10^17 SHA-256 hashes per second or 10^16 SHA-512 hashes.  A $1B
machine could do close to 10^13 KDFs/second of TrueCrypt's strongest KDF.
 Given that the NSA only claims to be able to do something like 1T password
guesses/second, TrueCrypt's max KDF seems to provide little additional
security, at least against custom hardware guessing machines.
In addition to a weak KDF, users are encouraged to use weak passwords.  For
example,  says that "dogs breakfast"
would take a desktop PC a million years to crack.  My Huffman Code password
compressor represents this pass phrase as 011011101110010 1110111101011110
- 31 bits.  My password cracker on a PC would guess this password in about
2 billion attempts, or about 70 years if each guess required a full second
of KDF  With the weak TrueCrypt KDF (about 50 milliseconds on a PC), that
drops to 3.5 years.  With a graphics card, that drops to days, not years.
 At 1T password guesses per second, this password would be cracked in 2
A $1,000 PC might do 50,000 SHA-512 hashes/second, while for $20, I can do
1e9 AES-512 hashes/second with an ASIC.  Why give attackers a free factor
of a million advantage for using custom hardware?  Why do we even quote
password strength in terms of how long a PC would tack to crack it?  Simply
switching to scrypt reduces the cost advantage of custom hardware from a
million to maybe 100.  Done right, we could reduce it to 10 or less.  I
just don't understand how these guys can live with weak key stretching.  At
a minimum, they should let users select the number of iterations for the
SHA-512 KDF.  GPG at least does that.  I'm suspicious there may be some
cash being paid to the right people to make sure TrueCrypt key stretching
stays weak.  If RSA got $10M, what did the TrueCrypt guys get?  Simply
adding an option for user-selectable rounds of key stretching would take
about 10 minutes of coding.

@_date: 2013-12-22 16:42:33
@_author: Bill Cox 
@_subject: [Cryptography] Why don't we protect passwords properly? 
There were some very informative statements in the replies.  Thanks for all
the history and background, and pointers to some cool technologies.  Some
 "That makes no sense.  If you transmit the derived key, *it*
becomes the "real" key. "
There are several advantages over just sending the user's password to the
server.  It offloads the server enabling more compute intensive KDFs.  The
client side software is auditable by users, so we can verify the KDF is
done well, unlike the situation with servers like LinkedIn.  Also, anyone
seeing a user's passwords in plain text is going to gain a great advantage
when trying to crack those passwords for other sites.  They are often the
same, or only slightly different.  This is how so many LinkedIn users had
their Google accounts hacked.
Still, those were some great links you and the others pointed out.  Your
link to Secure Remote Password Protocol is very cool.  It does KDF in the
client also.  This is better than sending any password every time to the
I'm just noodling, but could we enhance SRP to not rely only on the
discrete logarithm problem?  I'm looking at SRP on wikipedia.  They
describe the secret stored on the server is "v", which is computed by Carol
as g^x, where x is Carols derived key.  V is essentially Carol's public
key, and x is her private key, enabling Steve to securely send a session
key to Carol even if a MITM attacker has Steve's hashed password file.
 That's very cool, but if a MITM attacker doesn't have the hashed password
file, but does have a silly amount of compute power for computing discrete
logs, couldn't we thwart them simply by using v as a shared private key
during the session key exchange?  When Steve sends his info to Carol, why
not AES encrypt it with v?  That's all it would take.

@_date: 2013-12-22 16:59:43
@_author: Bill Cox 
@_subject: [Cryptography] RSA is dead. 
Nonsense.  Most other equally capable developers should be able to discover
a backdoor with far less effort to hide it.  Reading other people's code is
a skill that some people never acquire, but it's generally easier to
understand someone else's code entirely than to have created it from
If the code is so obscure that this is not the case, that code should not
be used in crypto.  I'll just point out that gtksu falls exactly into this
category, yet we continue to use it... it really deserves to be retired.
 Open source is *very* helpful, but if the people with the decision power
over what to include are far more ignorant than the coders... well then
just forget security.

@_date: 2013-12-23 00:08:02
@_author: Bill Cox 
@_subject: [Cryptography] Fwd: [IP] RSA Response to Media Claims Regarding 
Does this mean RSA denies accepting $10M for making the NSA RNG the default
in BSAFE?  You did not say so in your post.  So now RSA "categorically
denies" entering into a secret contract with the NSA.  If it wasn't secret,
why didn't I hear about it?  I'm pretty sure it would have made the geek
news, and I may not be a crypto expert, but I follow geek news (slashdot
would have burned RSA alive).
I think I get that RSA employees have been duped by the NSA.  It's the
NSA's job after all, and they have smart people, apparently smarter than
many RSA employees.  I don't get any sense that RSA might have made any
mistakes from your post.  Your post seems like something a corporate lawyer
wrote.  I hate that, and I have good personal reasons for it.

@_date: 2013-12-23 00:21:08
@_author: Bill Cox 
@_subject: [Cryptography] RSA is dead. 
Ouch!  I have a fantastic job, and I doubt the NSA would want a 50-year-old geek like me, but half of what really upsets me about all the recent news is I've always wanted to do crypto (as well as what I actually do - it's an ADHD thing).  The recent revelations just show that the NSA is good at their job.  Why would that discourage geeks like me?  Now comparing to Fox News... that's below the belt.  BTW, is there anywhere else that even matters in the industry?  Aren't they the elephant in the room?

@_date: 2013-12-23 00:33:15
@_author: Bill Cox 
@_subject: [Cryptography] [IP] 'We cannot trust' Intel and Via's 
I audited David Patterson's class (the prof who coined the term RISC) in the 80's.  I was even hired as an undergrad to write test vectors for the SPUR CPU, and later did some diagnostics for the SPARC HP CPU.  I designed a super-tiny RISC microconroller for a .35u process last month.  I wont bill myself as a RISC expert, but I'm far from ignorant.
AFAIK, every successful high-end CPU today has incorporated the RISC architecture as it's core processing unit.  Intel wraps huge amounts of circuitry around it, but at the heart, it's RISC.  At the same time, every successful RISC architecture today is now way more complex than the CISC CPUs they used to compete with.  There's really no such thing as a RISC vs CISC CPU anymore.  RISC won in the core, and CISC won in dealing with complexity, and now they're all hybrids of both.
Anyway, it's a nice thought that RISC CPUs might provide more trust due to their simplicity, but given the complexity of modern RISC architectures like ARM, forget it.  There's no modern CPU of any reasonable performance that isn't too complicated to easily audit. There's a lot of room for back doors that no one would ever find, RISC or CISC, IMO.

@_date: 2013-12-23 00:50:22
@_author: Bill Cox 
@_subject: [Cryptography] BitCoin Question - This may not be the best 
Are you concerned about a government willing to spend $1B on hardware to
create bogus BitCoin addresses?  If $1B could buy you 1T new BitCoin
addresses per second, we'd see the first collision in about 38 thousand
years.  I'm pretty paranoid about security, but I'm OK with this.

@_date: 2013-12-23 01:06:59
@_author: Bill Cox 
@_subject: [Cryptography] how reliably do audits spot backdoors? (was: Re: 
Well, first, It's David Wagner.  Had we set up this test with me inserting
the bugs and David Wagner finding them, I think the results would have been
However, IMO, David Wagner's bugs would not have survived a year of open
source review, given that it was confined to 100 lines of code.  That code
might be a serious mess, but people can usually grok that kind of
With that said, God only knows what back doors exist in gksu.  Crypto code
should be as simple as possible.  Why does gksu need multiple threads that
all violate the GTK rule that only the main thread can muck with UI
widgets?  It's only a simple dialog with two buttons!  Why does it even
need multiple threads?  If I do say so myself, I am awesome at reading and
groking code, and gksu is one of the only Linux projects I've had to read
that I could not understand.  Code like that in the crypto system makes me
want to set my hair on fire.

@_date: 2013-12-23 01:53:58
@_author: Bill Cox 
@_subject: [Cryptography] Passwords are dying - get over it 
Sounds good, but what's the alternative?  It scares me to have a key ring
decrypt all my passwords at once, and just hang around in memory.  The
closed-source password safes are a non-starter, IMO.  I agree the password
situation sucks.  I'm not very familiar with alternatives.  What do you

@_date: 2013-12-23 09:14:50
@_author: Bill Cox 
@_subject: [Cryptography] Fwd: [IP] RSA Response to Media Claims Regarding 
It's good news that there was a press release about the $10M.  So, RSA had
no secret contract.  However, here's a morning headline that bothers me:
So now this press release is being morphed by some press as a denial that
the $10M deal ever happened.  ZDNet is not exactly a no-name news source
for techies.  It kills me how badly even tech savvy news sources butcher
the details.  You get a nice clean story like what we can infer from the
above statements: RSA did take $10M, they did put flawed RNG into BSAFE,
but there was no secrecy or intent to back-door anything.  Instead of
running that, we're hearing conflicting headlines of conspiracy and denial.
Surely this will damage RSA, and perhaps RSA does not deserve it, though I
think taking $10M to include code promoted by the NSA was somewhere between
risky and stupid.  However, like most of the other Snowden revelations,
this will cause consumers to be more informed, and security companies like
RSA will have to do an even better job proving their trustworthiness.  In
the end, I think this is good.

@_date: 2013-12-23 10:10:07
@_author: Bill Cox 
@_subject: [Cryptography] Passwords are dying - get over it 
I also take that approach.  As Jefferson once said, when you do a thing,
imagine the whole world is watching and act accordingly.
It bothers me that I get more security from carrying a metal key to a
physical lock than I can get online.  Maybe I'll put a key file on my phone
and try to be a bit more secure with my TrueCrypt password safe.  I
certainly can't count on just their key stretching.
How would you recommend protecting your ssh private key?  Here's a great
tutorial on adding key stretching to your ssh private key, which by default
has none:
The bad news: even the 0.1% of us who bother to add key stretching to our
ssh private key's only get 2048 rounds of AES-256, which wont even slow
down an ASIC based cracker.  All this does is provide security against
hackers with graphics cards, and not much security at that.  Frankly, this
protection is so dismal, I give up.  Whoever is influencing TrueCrypt and
OpenSSL into hard-coding 2048 worthless rounds of key stretching designed
to be efficient on ASICs wins.

@_date: 2013-12-23 12:07:25
@_author: Bill Cox 
@_subject: [Cryptography] Passwords are dying - get over it 
I agree with all these points.  However, github and other sites I visit
often require a public ssh key.  A lot of git managment tools require
public ssh keys to work, and I one linux server I manage that has many
users who log in with ssh keys as a result.  A decent high entropy pass
phrase is just too hard to type every time I want to log onto these
servers, so my security is weak.  Grr...
That's one heck of a password.  A randomly generated password can gaurentee
security, but I'm to lazy to type that sort of monster every time!
If the word table has the most common 2^13 (8K) words, then such a pass
phrase has 39 bits of entropy.  That's not bad if the KDF were scrypt
running in 1G of memory for a second.  A $1B scrypt stretcher running on a
password guesser that knows you have 3 words chosen from the list of 10,000
would likely take an hour and a half to crack this.  In reality, such a
machine probably does not yet exist, so you'd be safe for now.  However, if
it's just AES-256 for 2048 rounds, a cheap 1T-hash/second machine (for only
$10,000 using BitCoin ASICs) enables guessing at a rate of 500M
guesses/second, and would crack this in 19 minutes.  That's not much
security!  That's why I'm promoting a switch to better KDFs, like scrypt.
 I look forward to seeing the result of the upcoming competition.

@_date: 2013-12-23 23:15:47
@_author: Bill Cox 
@_subject: [Cryptography] Serious paranoia... 
Do any of you guys find that web sites go down after you post a new crypto
related idea to an email list?  When I posted to the TrueCrypt list it went
down for over a day.  I just posted to the password-hashing.net list, and
it's down right now.  This happened before when I posted to the old
BitTorrent list.  The sites just go away for a while.  Also, my wife is mad
at me.  She thinks my crypto posts are causing delays in her emails.  My
emails seem to get delayed after I post dumb crypto ideas.  This whole site
is down:
I posted my dumb ideas for key stretching there earlier today.  I'm sure
it's junk, but when I make these kinds of posts with mostly junk and
potentially a new idea or two, sites seem to just go away for a while.  The
posts usually make it through eventually, though one whole thread on the
TrueCrypt list seems to be no longer findable, unless you have a saved link
to it.
Anyone else see anything like this?  Is it total paranoia?  It's kind of
freaking me out.

@_date: 2013-12-24 20:35:59
@_author: Bill Cox 
@_subject: [Cryptography] Serious paranoia... 
So, consensus seems to be that this is just paranoia.  I prefer that to the
thought that some poor guy actually has to spend time dealing with my dumb
posts to earn a living.
My next question is shills.  I often think I'm seeing potential shills, but
it's hard to tell a shill paid to subvert Internet security from the common
dork.  For example, on one of my other posts on this forum, "Why don't we
protect our passwords", I agree wholeheartedly with Arnold when today he
"So why the lack of attention to KDFs? If one tenth the effort to replace
SHA-2 had been devoted to improving password storage, the benefits to
industry and the public would be far greater than anything we can expect
from SHA-3.  While I'm glad the hear that there is a
password-hashing competition (password-hashing.net), scrypt is available
now. As long as an algorithm identifier is included in a password database,
it's easy to substitute a better algorithm when it comes along. And is
there any cryptographer out there who knows the algorithm and believes that
scrypt could be weaker than PBKDF2? Seriously?"
"> to substitute a better algorithm when it comes along. And is there
yep, plenty. for example all that knows the principle of not using
branching/indexing on secret. pbkdf2 does not do that, and therefore
safe against cache timing attacks. the same can not be said about
either bcrypt, which uses secret based s-boxes, but especially not
scrypt, which uses secret based memory access wildly.
one could also ask how safe it is to sprinkle the secret all over the
RAM, increasing the risk of getting swapped to disc, or being
recoverable by cold boot attack.
there is a lot to fear about scrypt. don't forget, we live in the era
of side channel attacks. the safety of scrypt against direct attacks
does not grant much in the real world."
I don't mean to call people names.  I'm only using Kriszti?n's post as a
recent example, of which there are many.  Kriszti?n Pint?r clearly doesn't
want to switch to scrypt, which AFAIK any non-dork can tell improves
security against common real attacks, which far outweighs Kriszti?n's
concerns about side-channel attacks, and OMG, what was that crazy rant
about sprinkling secret data all over RAM?  It's just the output of a
respected stream cipher!  From where I'm sitting, Kriszti?n's position is
so lame, it makes me think he may be getting paid to spread FUD.
So, is Kriszti?n a dork or a shill?  Do we live in a world where we can't
chat intelligently about security because of NSA shills, or is the world
really full of that many dorks?

@_date: 2013-12-24 21:00:06
@_author: Bill Cox 
@_subject: [Cryptography] [IP] 'We cannot trust' Intel and Via's 
It's not publically documented, but I hear TSMC added extra transistors to
some Xilinx FPGAs, and the last I heard, no one had figured out what they
were for.

@_date: 2013-12-25 09:18:42
@_author: Bill Cox 
@_subject: [Cryptography] [IP] 'We cannot trust' Intel and Via's 
I heard this second hand, but the guy at the time was pretty freaked out.  I never heard what became of this story.  Characterization transistors are normally added in small gaps between die, not on the die itself.  Xilinx does a good job of using all the available area for circuitry, even putting transistors in the corners where almost every other die you'll see has nothing but wasted space, and some 45-degree turns for IO power busing.  The extra transistors were added in some of the few remaining spaces that Xilinx didn't fill. The fact that I never heard about this again probably means it either was not malicious or our guys decided not to make it public for some reason.

@_date: 2013-12-26 08:48:11
@_author: Bill Cox 
@_subject: [Cryptography] Serious paranoia... 
I regret using "lame" and "crazy rant".  I apologize for that.  I'll try to
be less inflammatory going forward.  I am glad some people responded
seriously about the "shill" question.  I didn't know if there would be
several others who felt there seem to be shills now and then or not.  The
answer seems to be not many, and I appreciate that answer.
You said, "there is a lot to fear about scrypt" and that kind of statement
sets of my spidey senses.  You also said, "one could also ask how safe it
is to sprinkle the secret all over the RAM."  I assume you made that
statement knowing that scrypt calls PBKDF2_SHA256 on the password as it's
first step, and "the secret" will be interpreted by most readers as the
password rather than it's hash.  Now many of the new poorly informed
readers like me that have joined this list after the Snowden leaks may be
misinformed about scrypt, fearing that it spreads the plaintext password
all over RAM.  You probably did that unintentionally, but that's exactly
the sort of thing I suspect the NSA would want.
What scares me is the nearly useless (against custom hardware attacks)
hard-coded key stretching in the tools that protect most of us.  When you
turned my question about why we don't properly protect our passwords to a
discussion of why should fear scrypt, I suspected a shill.  Sorry about
that.  The title of this thread is "serious paranoia" after all.  After the
Snowden leaks, just how paranoid should we be?
I suspect the moderators have allowed non-technical discussions like this
in light of the Snowden revelations.  There are some serious expert crypto
guys on this list, and I appreciate that some of them are taking the time
to answer these sorts of questions.
By the way, I like the word "dork" because of this Dilbert series:
I'll try and find some other way to describe people who are likely not
aware that they are misleading the public.

@_date: 2013-12-26 09:52:31
@_author: Bill Cox 
@_subject: [Cryptography] On Security Architecture, The Panopticon, 
I agree.  We need a distributed global commit-only database, and some sort
of revenue model.  The BitCoin solution is extremely cool, but in the end
it's basically a Ponzi scheme.  The value of the coins keeps going up, but
no one is using them to buy anything.
I have some dumb ideas in this area.  I think we could build a P2P system
that allows Ripple-style microtransactions.  It could allow us to plug in
our Raspberry Pi's and sell services such as storage of encrypted data or
email, speeding up downloads in torrents, or hosting games, files or web
The financial incentives would be that we essentially get free Rasberry
Pi's and other server hardware while users get cheap services.  The P2P
aspects are hard, but IMO, the crypto part is even harder.  As soon as
there is anything of value online that we can trade, it becomes a target.
Even something as simple and cheap as a Raspberry Pi is so complex that it
could have multiple back-doors and unintended security weaknesses in both
hardware and software.  iPhones keep getting rooted, demonstrating that
even the most valuable company in the world can't secure a phone.
I agree a possible solution is multiple layers, preferably multiple layers
of hardware.  For example, a simple USB stick microprocessor could have a
small single-chip RAM buffer that can electrically connect to either the
host PC/Rasberry Pi, or the USB microprocessor, but only one at a time.
 The USB microprocessor could be FPGA based, making it also more easily
auditable, and we could have a discrete zener-noise based RNG that can be
fully probed providing random data.  All signing of things could be done in
the FPGA.  If that could be done for $20 and plugged into a $35 Rasberry
Pi, just maybe we'd be able to build a P2P system we could trust enough to
enable microtransactions.  After that, all kinds of services might follow.

@_date: 2013-12-26 20:09:12
@_author: Bill Cox 
@_subject: [Cryptography] A modification to scrypt to reduce side channel 
I may be misinterpreting what you're saying, but I believe steps 1 and 3
take very little time, and being able to do them in parallel or not makes
little difference in the strength of scrypt.  Personally, instead of 1
round of SHA-256 in steps 1 and 3, I would use 2048, just to be able to
claim scrypt starts as strong as the strongest KDF you can select in
OpenSLL for your ssh private key, and just claim scrypt adds security from
there.  In hardware an attacker can likely compute 2048 SHA-256 rounds in 2
microseconds in about a cent worth of silicon.  In the slowest modern
Javascript implementations, it's still only 2 or 3 milliseconds.  Steps 1
and 3 in scrypt are 2000 times faster than this.  It's step 2 that we have
to get right...
However, you are correct that writing salt-based hashing data to RAM that
does not depend on the key lowers security in some ways, but maybe that's
OK.  Instead of having to fill memory and then read it for each password
guess, depending on the salt only for the written data allows the attacker
to make a guess twice as fast, since he only has to read memory once per
guess.  Personally, I'd rather just use 2048 rounds of SHA-256/PBKDF2 to
initialize the RNG and use that all over memory, but the FUD-mongers seem
to have latched onto some sacred rule about leaking info derived from the
password to DRAM, even though we seem to be fine with weak password
security in general stored to disk on insecure corporate servers.
The more I try to make improvements to scrypt, the more respect I gain for
scrypt's current implementation.  As I said, he should just add 2048 rounds
of SHA-256 at the start and end to quiet critics, but other than that, it's
pretty good now.  The main improvement I see possible is to increase the
amount of memory we use vs script, to increase the cost to an attacker.
 Scrypt runtime is dominated by it's hashing function for filling memory
and cache misses.  We could improve on both of those if the fear mongers
let us.
The key is taking into account real hardware.  The best DRAM for cracking
memory-hard KDFs right now is probably GDDR5.  The PlayStation4 has 16
512MB GDDR modules with 176GB of bandwidth, and that monster will beat just
about every server around in memory bandwidth.  If we use a memory hard KDF
that hashes 4 GB with RNG data on our PCs in 1 second (sorry... not blake2,
not chacha...), an attacker will have to spend 88 milliseconds simply to
read that data from the world's fastest memory (4X slower than the
PlayStation4 because it has 1/4 of the memory modules).  We could easily
double that read time with cache misses on the assumption that high tCAS
latency will dominate cheap memory for many years to come.  Those chips
will cost the attacker, according to the best data I could find today,
somewhere from $20 to $30, and I'll just throw out a WAG that the rest of
the system in high volume will cost another $20 to $30.  It's that cost and
runtime that will defeat hardware based password crackers.
There are other funky issues I've run into.  For example, to use more
memory with the same number of cache misses as scrypt, just increase the
read/write data size from 64 bytes to something larger.  If you increase it
too much, an attacker will just cache the state of your RNG at fixed
intervals while generating the RAM data, and instead of having external
RAM, they'll just regernerate RAM data from the cached state as needed.
 Scrypt is secure against this only because 64 bytes is comparable to the
RNG state.  If scrypt were to write out 16K bytes instead with each
read/write, it would not be very secure.  The author is a smart guy.

@_date: 2013-12-27 07:02:30
@_author: Bill Cox 
@_subject: [Cryptography] A modification to scrypt to reduce side channel 
I saw code in script to automatically generate good parameters.  Basically
it fills and hashes memory for about a second.  If you use it that way, it
works on a mobile phone or a high end gaming machine perfectly well.  I
think to make it friendly to most users, this is how implementations need
to work.
Actually, I'm proposing splitting the load between the client and server,
allowing any ratio at all.  Basically both the client and server should run
the KDF.  If the client is just running non-Javascript-enabled HTML, then
he's entirely dependent on the server for KDF.  If he's running Javascript,
the server would likely prefer that the client to take some, but not all,
of the load.  Long KDF times like a second of hashing and using half of all
available memory is something you really want to offload to the client.
 However, the server should not assume the client did KDF properly, and
should do at least a little, like hashing memory for 10 to 100
milliseconds.  The only thing required here is that the server save KDF
parameters for both the client and server, rather than just the server, so
it's not a huge step in complexity.  However, I think it adds a great deal
of security and flexibility.  And my favorite reason for this proposal:
maybe it will end the endless server-side/client-side KDF debate.
No, 4GB was just an example, based on my 8GB linux desktop.  Parameters
should most likely be determined automatically in most cases, so old cell
phones would be fine.  However, you wouldn't want to enter a password with
major client side processing on a high end desktop and still expect to be
able to login to that site on your phone.  Assuming this is generally up to
the server, since users wont generally know what KDF is anyway, it would be
up to the server admins to decide what kind of client-side hashing is
reasonable.  Facebook probably would want to assume very little, but an
online bank might prefer to assume you've at least got a 1GB netbook worth
of power.
Also, remember this client/server thing remains a side issue.  My poor ssh
private key is sitting on disk with at most 256 rounds of SHA-256, which is
basically worthless vs hardware based guessing.
Or my son's gaming machine, which I is a converted BitCoin miner.  He loves
that graphics card.  Actually the linux box I'm using as my reference is
also his.  He wanted a Minecraft server capable of hosting 4 simultaneous
games.  I discovered yesterday what happens when I use all the memory and
lock it down with mlock...  all the Minecraft servers crash!  Getting this
KDF right is tricky...

@_date: 2013-12-27 09:59:04
@_author: Bill Cox 
@_subject: [Cryptography] A modification to scrypt to reduce side channel 
D'oh!  The data written to memory MUST rely on the password!  This was a
good idea (the topic of this thread), but we require both the salt and
password to initialize memory.
The reason is simple, and now I feel dumb (happens a lot I'm afraid).
 After initializing memory just based on salt, we take a random walk
through memory just based on salt to pick data to hash.  An attacker just
feeds the resulting hash stream to a million super-cheap password guessers,
none of which need significant memory.
Maybe this is what you guys meant when you said step 3 can be done in
In any case, we must initialize memory with the intermediate derived key,
but we don't have to rely on the password to generate the random walk.  We
can do that with just the salt, and I think that results in better security
against timing attacks.

@_date: 2013-12-27 19:23:30
@_author: Bill Cox 
@_subject: [Cryptography] A modification to scrypt to reduce side channel 
I've come to the conclusion that bad things happen when we don't hash
memory based on the password.  From what I can tell, any system that uses
only the salt to determine the order of blocks to hash into the derived key
will not be memory-hard.
Here's well understood "attack" on scrypt (not really an attack), implied
in the original paper:  Instead of having external RAM, an attacker could
build a chip with just enough internal memory for the state of the RNG.  In
the case of scrypt, that's 2KB.  Whenever they need a block at a particular
position, the chip resets the RNG state to the beginning, and computes all
the way up through memory to the needed block.  Thus, they can perform the
KDF with almost no memory, but it would take a very long time, which is
obviously bad for the attacker.  Now consider a chip with say 100 such
units.  It takes 100X more chip area and memory, and runs 100X faster, but
it's still probably slower than just having the full external RAM.  Part of
the reason is that the attacker cannot predict what address will be read
next from RAM, and so his 100 units sit idle waiting for the hashing of the
current block to complete.  This is expected from a memory-hard KDF.  The
attacker can increase memory to reduce runtime, reduce memory to save on
cost, but it will increases his runtime.  I'm sure there is a sweet spot
when attacking script where instead of storing hashed memory off chip, an
attacker would store 2KB RNG states, but this is expected behavior that in
no way violates the proof of scrypt's memory-hardness.
Now consider the case where the attacker can predict the order memory will
be read before the blocks are read and hashed into the derived key.  This
is the case in any system that relies only on the salt to determine the
hashing order.  Instead of having 100 generators sitting idle until the
next address is known, all 100 can be working in parallel trying to get to
the address in memory where they need to be at some point in the future.
 This reduces the time of the attack considerably, violating the definition
of a memory hard KDF.
There still may be ways to mitigate timing attacks, such as figuring out
what blocks might still be partially cached and avoiding those.  However, I
see no way around having the user's password involved in computing memory
addresses.  I think the password simply needs some decent hashing before
it's used to compute addresses.
As for scrypt, the only weakness I can point to is doing only one round of
SHA256 on the user's password before using this intermediate value to
compute data stored to memory.  I would prefer 2048, so we could start with
what is normally considered decent security and improve from there,
hopefully reducing some of the fear of this new algorithm.  As for
improvements, I think we could have a much faster RNG than salsa20/8, which
would still be secure for this application, but I can't fault the scrypt
author for choosing instead a proven known algorithm.  His design rocks.  I
only really want to change to replace "1" with "2048" on one line, and
that's mostly just to squelch nay-sayers.  That's pretty amazing, IMO.  I'm
still playing with speed improvements, and I'm making some, but I'm having
to drop Salsa20/8 and am using a simpler algorithm that people will likely
not want to risk using.  I can't blame people for paranoia in cryptography.

@_date: 2013-12-30 15:05:14
@_author: Bill Cox 
@_subject: [Cryptography] I posted a memory-hard key stretching algorithm on 
It's at:
If this algorithm isn't too lame, I'll enter it in the password hashing
competition in January.  There isn't much time for feedback or code
development, so if you're interested in these algorithms, please let me
know your thoughts on this one.  Essentially, I've upped the pre-hashing of
the password to 4096 SHA-256 rounds, and replaced the memory hashing
function of scrypt, Salsa20/8, with a simple hack that seems to run 8X
faster while being unpredictable enough.
The only other entry I've read about so far is based on Blake2, which is a
nice improvement over Salsa20, I think, but like scrypt, it spends most of
it's time hashing rather than filling the memory bandwidth.  I'm not sure a
cryptographically strong hash is called for, so I'm suggesting using a
simpler hash that seems to work well enough.  Any thoughts welcome.

@_date: 2014-04-10 14:30:22
@_author: Bill Cox 
@_subject: [Cryptography] Heartbleed and fundamental crypto programming 
Sounds cool.  Any code I security wrote over a decade ago like that
should probably be carefully reviewed and patched.  For example, now
days it is difficult to force the compiler not to optimize away
clearing of memory on object destruction.  Here's the zeroing function
from Blake2 I'm using for this purpose:
static inline void secureZeroMemory(void *v, uint32_t n) {
    volatile uint8_t *p = (volatile uint8_t *)v;
    while(n--) {
        *p++ = 0;
    }
Casting to a volatile pointer is a trick that might not work on all
compilers, so it should be checked with each.  Even so, you'll still
leak data.  For example, a password length might have been passed as a
parameter (as above, when I clear it), and it might be on the stack,
or in a register.  When interrupts happen, those registers get written
to different places, and a leak can happen.  If your program gets
written to swap, core-dumped to a file, or if it's a laptop in
hibernation, chances are you're red-data can get written to disk.
With SSDs, you can't erase that data because of the algorithms to
uniformly distribute writes so that some locations don't wear out too
Still, I very strongly agree that we should at least *attempt* to
clear sensitive data ASAP.  One of the silliest things I see in crypto
APIs is:
    const unsigned char *password
It's even in the PHC (password hashing competition) required "PHS"
API.  I certainly hope no one actually uses this PHS interface in real
systems.  It's very tempting, because every one of the 24 entries has
one, and you can use it to quickly plug any of them into your system.
I personally would much prefer a generic API to the password hashing
system than hard-coding a specific one.  It makes the code more
True, but it doesn't mean you replace the allocator, or defeat various
memory checks for the sake of speed.  Doing it with a destructor hook,
like you did, sounds right to me.
This, unfortunately, does depend on the application somewhat.  Linux
already zeros memory for you when you return pages back to the kernel:
    I'm working on memory-hard password hashing for an entry in the PHC,
and I hash about 3GiB/s on my 3.4GHz Ivy Bridge machine.  Of that,
maybe 25% is kernel allocation overhead, which probably includes the
zeroing.  Zeroing before freeing would double that.  At the same time,
if compiling on a non-Linux box, the safe thing is to zero it as you
Unfortunately, zeroing seems highly system/compiler specific.  We need
to verify it on every combination.
The current state of affairs is terrible.  For example, how should a
programmer read a password?  Here's an interesting thread on
For years, the getpass manpage said getpass was obsolete and not to
use it.  At the same time, it did not recommend any other solution,
and AKAIK, there was none.  The current manpage does say in the BUGs
section that it is critical for the user to clear the password ASAP,
but there is no hint about how to actually do that in a way that the
optimizer will honor.
Password security should be simple, and workable.  One critical
GNU/Linux utility, gksu, is an absolutely evil pile of grotesque code
that should be erased from existence (it has major bugs that even I
can't figure out how to fix, which have been there for many years,
most likely related to it's illegal calling of GTK+ GUI functions on
non-main thread).  If users feel the way to learn how to write secure
code is to read what Linux relies on... ugh...
Seriously, a "Writing Secure Code for Dummies" guide would be great.
I could certainly use it myself.

@_date: 2014-04-20 11:45:18
@_author: Bill Cox 
@_subject: [Cryptography] Are dynamic libs compatible with security? was: 
This is almost the right way to ship and update applications.  Every
application is tested with a fixed set of shared libraries, and that is the
set that likely will be most stable over time.  Updating shared-libraries
underneath an application is not just insecure, it's a great way to
introduce bugs.
The right way to do applications is much like this, where we also run each
application in it's own security jail (as Android does - I don't personally
bother reading anything from an organization as evil as Apple, so I don't
know what they do).
In addition, to save on space, identical binaries should only exist on disk
once.  This can be done trivially with hard links.  Finally, there should
be a way to do "critical" updates of libraries.  For example, all the apps
linking to OpenSSL, should be updated after the Heartbleed discovery.  The
application authors should mostly lock down the libraries they link to, but
the distro maintainer should be able to override those choices in critical
I can't even begin to explain here how many benefits such a system would
have for GNU/Linux.  GNU/Linux is losing the OS war for the desktop.  The
way GNU/Linux is built and distributed requires insane testing and
maintenance, which is why you can't just publish an app today, and access
it in Debian Stable tomorrow.  GNU/Linux is basically designed to break,
and the way we work around that stifles innovation.  GNU/Linux needs an
Android-inspired App delivery system.

@_date: 2014-04-24 19:03:43
@_author: Bill Cox 
@_subject: [Cryptography] Two round secure hashing 
I'd appreciate feedback on the following dumb idea.  If it works as I hope,
it will dramatically speed up secure file hashing.  My benchmarks from
yesterday are out of date, but I was seeing file hashing 5X-ish faster than
md5sum, and 12X-ish faster than sha256sum.  Here's a simple page I wrote on
the idea:
Any feedback welcome

@_date: 2014-04-24 20:46:48
@_author: Bill Cox 
@_subject: [Cryptography] Two round secure hashing 
I'm finding problems in my proof.  In particular, if a message value on the
other track is changed, it is possible to undo the impact it that change
has by changing another message value.  I just realized that this
correction can occur anywhere in the message, even quite far in the hashing
chain, giving the attacker a lot of flexibility in finding collisions.
 I'll have to work on this some more... it may not work out.

@_date: 2014-04-24 23:42:00
@_author: Bill Cox 
@_subject: [Cryptography] Two round secure hashing 
And now I've found a way to create input collisions... oh, well!  In case
anyone spent time reading it, for a 1024 sized super-block, pick a random
bit location, and flip it in m0, m1, m512, and m513.  If the probability of
R(R(S1^m0)^m1) == R(R(S1^m0^(1<

@_date: 2014-04-25 10:14:54
@_author: Bill Cox 
@_subject: [Cryptography] Two round secure hashing 
Thanks for the encouragement.  It's nice to hear in crypto land.  It's a
tough place for hobbyists and dabblers, which I think is a shame.  Internet
security is in shambles, and it's not so much the expert's fault as the
next level down, guys like me who don't get paid to do this, but who now
and then get told to go implement some security widget (happens all the
time).  I wish we were better about getting people in-the-loop, but instead
we have a "just don't do it" approach that works about as well as our "just
say no" commercials.  I think we should all be encouraged to write our own
public-key cryptosystem, so long as no one uses them.  Here's mine:
    Two things next:  First, someone pointed me to Dmitry's Ph.D. thesis:
    I'll have some fun reading that.  Second, there seems to be significant
security gain in hashing large super-blocks at once, rather than blocks no
bigger than the hash state.  I want to explore this more.  Maybe I should
read the thesis first, but what's the fun in that?  Reinventing the wheel
is most of what everyone does now days, and they wind up wiser for it.
 That provides people the gut-feel for a field that the original pioneers
had.  I'll have to read it eventually, though...
I figured out yesterday that 3 states and 3 chains are required for obscure
(to me) reasons.
Assume you want to create a collision with only 2 chains.  Assume you have
a simple 1-bit flip that is preserved by R some percentage of the time,
like 50%.  You can flip this bit, and also in the next message block, and
the changes cancel with 50% probability in one chain.  The other chain,
however, separates those bit flips by a long distance, so you have to do 2
more message bit-flips on the other chain to cancel them, and now our
probability of succeeding is down to 1/8th (still very high).
Samuel was kind enough to email me an explanation of the more general tool
called a "differential characteristic".  The idea is to find some input
bit-flip pattern "a" that results in an output bit flip pattern "b" with
high probability:
ROUND(state ^ a) = ROUND(state) ^ b
My simple 1-bit flip -> same bit flip is just a sub-set of this, but it
works well enough for my purposes for now.
This is where my analysis before went wrong:  I assumed that if a single
bit flip turned into two, and then six (it's up to 6 flips by the time we
make our two corrections on the second chain), then it must explode
exponentially.  Nope!  When 2 became 4, that was the only doubling that
occurs.  After that, an attacker has two adjacent choices to make his
correction, and the two correction paths bounce back and forth between
chains until there are either too many for any chance of success relative
to random guessing (meaning < 1/2^512 - so very many are needed!), or the
chains converge with a useful probability of cancelling each other.  With
the bit-reversal pattern, many of these two tracks meet up (become
adjacent) after 2 bounces, and have a reasonable chance of canceling each
other out, so two-chains using bit-reversal permutation is a dead end.
I worked a bit on message block permutations that guarantee that the tracks
don't meet for as long as possible.  This turns out not to work out well.
 Every node has to be highly unrelated to every other at the same time.  It
can't be done with enough distance to be effective.
So, I have to add a 3rd state and message hashing chain.  With 3, every
message bit-flip creates two changes in the other two chains, both of which
have to be fixed locally.  This does explode exponentially, and has some
potential, I think.
A reasonable way to think of this hashing approach is instead of multiple
chains, it's just a bigger state (three times bigger).  The difference
between this and normal block hash is that it hashes many input blocks at
the same time, allowing each operation to cause an attacker more pain, by
spreading the changes farther apart.  I think this can lead to much faster
secure file hashing, though the algorithm would not be efficient for small
block hashes, so it would not be general-purpose.  It's still very cool :-)

@_date: 2014-04-28 03:45:11
@_author: Bill Cox 
@_subject: [Cryptography] Two round secure hashing 
I'm not sure if anyone is interested in this sort of in-progress noodling
on fast file hashing by someone who doesn't really know what he's doing
(yet).  I'm having fun with this, and I don't want to ruin it just yet by
reading up on what really goes into modern hash function design.  I'll do
that later.  Just in case anyone else finds this stuff cool, here's some
fun I had.
I'm trying to determine how secure can we make 2-round hashing using large
numbers of message blocks in two chains, hashed in different orders.
 Apparently, given a file long enough, we can make it as secure as we like,
but "long enough" is exponential in terms of the number of rounds of
desired security against differential attacks.  However, substantial round
reductions for files a few KiB long appears doable, and least if we are
primarily concerned about collision attacks based on differential
characteristics (I'm not sure I used that term right).
Basically, the fun I've had lately has been building graphs corresponding
to two-chain hashing of message blocks in a way that guarantees there are
no loops smaller than some small constant K, insuring any differential
characteristic has to span K rounds to result in a collision.
Consider two hash chains of message blocks stored in an NxN matrix.  The
first chain hashes row by row, and the second hashes column by column.  Any
two adjacent message blocks in the first chain will be separated by N in
the second chain, meaning a simple two sequential message change that
cancel each other out on the first chain will explode into a mess on the
second.  The messages are in a matrix like this:
m11 m12 m13 ... m1N
m21 m22 m23 ... m2N
mN1 mN2 mN3 ... mNN
The row chain hashes messages in row order:
    m11 m12 m13 ... m1N m21 m22 m23 ... m2N ... mNN
The column chain hashes messages in column order:
    m11 m21 m31 ... mN1 m12 m22 m32 ... mN2 ... mNN
If an attacker finds a good "differential characteristic" for the round
function R, which has a reasonable chance of occurring for random message
blocks, then he can easily find collisions.  For example, if R(m^a) ==
R(m)^a  (where ^ means xor) with high probability (like > 1/sqrt(2^N) for
N-bit hashes) then an attacker can compute hashes for a random message M,
and a slightly modified version of M:
m11^a, m12^a, m13, m14 ...
m21^a, m22^a, m23, m24 ...
m31, m32, m33, m34 ...
The row-based sequence well see m11^a followed by m12^a, and will have a
chance of these two changes cancelling each other.  The same thing happens
in the next row with m21^a followed by m22^a.  Similarly, the column based
chain may see m11^a and m21^a cancel out, and m21^a cancel m22^a.  I call
this a "4-loop", since it is a message hashing loop involving 4 message
blocks.  With only a single chain, the differential characteristic would
only need to work out once, but here it has to work out in 4 places at the
same time, with probability being raised to the 4th power.  If the chance
of R(m^a) == R(m)^a is 1/4, then this 4-loop works out about 1 in 256 tries.
The more messages that have to be modified, and the further apart they are,
the lower the chance that the changes will cancel out.
The two chains can be represented by message indexes, and we can
draw bipartite graphs between the two message chains showing the relative
positions of the message blocks.  These graphs are hard to represent in
text, so I just write the message block numbers, where the first chain is
always 1 to N, and the second chain shows the position where each message
block has moved.  For example, a 6-block chain could look like:
chain a: 1 2 3 4 5 6
chain b: 1 3 5 2 4 6
A loop is written like: a1 => a2 => a3 -> b3 => b1 -> a1
This says we start in chain a at message m1, compute a round R(m1^a), and
hope we can still cancel out the change in m1 with a modification to m3.
 That fixes chain a, but chain b still needs work.  Moving from a3 -> b3
moves from the 3rd position in chain a to the second position in chain b.
 It doesn't call the round function R, it's just a free switch from chain a
to b.  In chain b, this loop shows an attacker is hoping that the changes
that cancel between a1 and a3 also cancel between b1 and b3.  To succeed in
cancelling changes in both chains, an attacker must complete the loop, or
else he will have a change with nothing to cancel it, exploding into a mess.
The round cost of this loop is only 3, because changes between chains are
free.  The round function is used to go from a1=>a2, a2=>a3, and b3=>b1.
 To be secure against differential collision attacks, I want to find
permutations of the message blocks for chain b that make it impossible for
an attacker to find short chains.  This is actually doable.
To make a chain that has a minimum loop size of 4, I can do this:
chain a: 1 2 | 3 4 | 5 6 | 7 8
chain b: 1 X | 3 X | 5 X | 7 X
Here, I've chosen the odd message numbers to remain in their original
positions, and I'm trying to find an assignment for all the even positions
that insure a loop size of no less than 4.  Regardless of this assignment,
4-loops for this pattern will exist, such as a1 => a2 => a3 -> b3 => bX =>
b1 -> a1.
A simple assignment that works for the X's is to just use x+4 mod N, where
x is the position, and there are N message blocks:
chain a: 1 2 | 3 4 | 5 6 | 7 8 ...
chain b: 1 6 | 3 8 | 5 10 | 7 12 ...
A simple proof that all loops will be 4 or more is to consider the 3
possible loop types, where they are differentiated by crossing vertically,
or diagonally.  Any loop with 2 vertical crossings between chains a and b
is clearly a 4-loop.  For example, if we cross vertically at position 3,
and again at position 5, we'll need to do 2 rounds in each chain to
complete the loop.  Similarly, and loop with two diagonal crossings is at
least a 4-loop.  The case of a vertical and diagonal is tricker.  if
instead of x+4, we use x+2 in the pattern, then we would have a 2 loop,
such as a3 => a4 -> b4 => b3 -> a3.  However, with x+4, all loops are
clearly >= 4, because each case where the vertical crosses the diagonal is
a 4-loop, and all loops where they do not cross are larger than 4.
To increase the minimum loop size from 4 to 6, we start with this pattern
and insert one more edge in every group (shown separated by | above):
chain a: 1 2 3 | 4  5 6 | 7  8 9 | 10 11 12 | 13 14 15 | 16 17 18 | 19 20
21 ...
chain b: 1 8 X | 4 11 X | 7 14 X | 10 17 X | 13 20 X | 16 23 X | 19 26 X ...
I just choose X to be x + c, where c is longer than the longest possible
span using 4 rounds.  In this case, the longest span of 4 rounds looks like:
    b8 -> a8 => a7 -> b7 => b14 -> a14 => a13 -> b13 => b20 -> a20
So, choose c == 18, so we span from the position after b8 all the way to
chain a: 1 2  3 | 4  5  6 | 7  8 9 | 10 11 12 | 13 14 15 | 16 17 18 | 19 20
21 ...
chain b: 1 8 21 | 4 11 24 | 7 14 27 | 10 17 30 | 13 20 33 | 16 23 36 | 19
26 39 ...
As before we can characterize minimum loops by crossing types.  Any loop
with 2 vertical edges between chains will be a 6-loop, such as a4 => a5 =>
a6 => a7 -> b7 => b24 => b11 => b4 -> a4.  Any loop with two of the same
type of diagonals (long or short), will similarly be at least a 6-loop, as
will the case as before of a vertical and a short diagonal.  The different
case is when we include one long diagonal.  The shortest loop we can make
will include the longest chain of 4 as above, plus 1 to get on the long
diagonal, + 1 to get off it, making it another 6-loop.
To make chains that have no loops smaller than 8, we just add another very
long edge type.  Again, we find the longest span possible with 6 calls to
R, and choose an edge length that makes an 8-loop out of it.  The longest
span looks like:
    b21 -> a21 => a22 -> b22 => b39 -> a39 => a40 -> b40 => b57 -> a57
=>a58 -> b58 => b75 -> a75
This uses 4 of the 18 long edges, and the other edges go forward or
backward 1, cancelling out progress, so the total span is 4*18 = 72, or 24
groups of 3.  We need to add another node to each group, so they'll be 4
long rather than 3, and add edges that span 24 groups of 4, or 96 long:
chain a: 1 2 3 4 | 5 6 7 8 | 9 10 11 12 ...
chain b: 1 10 99 28 | 5 14 103 32 | 9 18 107 36 ...
Note that the new long edge was inserted between two of the prior
diagonals.  This increase the cost to move forward on the new long edges

@_date: 2014-08-03 08:47:54
@_author: Bill Cox 
@_subject: [Cryptography] The original "public" public key algorithm 
Does anyone on this list know anything about this story?  I heard it while
I was a student at Berkeley in about 1983.  It was a story making it's way
around the CS department.  Does anyone know the original source for this
The cool part is how this algorithm is so simple and easy to explain to
just about anyone:
A CS professor at Berkeley taught one of the first crypto courses.  In a
yes/no homework problem, he asked, "Alice wants to have a private
conversation with Bob, and keep Eve out of it, but Eve is listening to
everything Alice and Bob send to each other.  Without any shared secrets
between Alice and Bob, but not Eve, is it possible for Alice to exclude
The "correct" answer was "no".  One kid thought really hard about it.  This
is the solution that he supposedly gave, and it's the best proof for
believing public-key crypto isn't total BS ever:
Alice chooses 1,000,000 random strong passwords of 256 bits each.  Then she
encrypts each of them with random 32-bit passwords.  She uses the strong
passwords to encrypt the following message 1,000,000 times: "You guessed
the right password!  Now send me a message starting with 'I love you more
than anything', encrypted with it!"  Alice sends all 1,000,000 weakly
encrypted passwords along with their strongly encrypted verification
messages to Bob, tells him how to know when he has guessed the correct weak
password, and to follow the decrypted instructions.
Bob then picks one of the 1,000,000 weakly encrypted strong passwords at
random, and on average in 2^31 (2 billion) guesses, he has brute-force
decrypted it.  He then sends Alice the message "I love you more than
anything, except when Eve is in town, in which case I love her more"
encrypted with the strong password.  Alice tries all 1,000,000 strong
passwords and decrypts it in no time.  Then she starts her secret
conversation with Bob while Eve is stuck decrypting the 1,000,000 passwords
until she finds the one that decrypts Bob's message.  On average, that's
500,000 passwords she will have to crack brute force, giving Bob and Eve a
security work factor of 500,000, or about 2^19.  If it takes both Bob and
Eve 1 hour to crack one password, Bob has on average 500,000 hours to act
on whatever  secret plans he forms with Alice before Eve finds out.
The funny part of this story is that supposedly the professor simply marked
the student's answer wrong.  Does anyone know the origin of this story from

@_date: 2014-08-03 17:36:37
@_author: Bill Cox 
@_subject: [Cryptography] The original "public" public key algorithm 
Thanks for the link!  This mostly confirms the old legend.  Here's Merkel's
own page on it:
The details became fuzzy over time.  It was not a homework question, but a
proposal for a class project where Merkel basically invented public key
crypto.  He was an undergrad at Berkeley at the time.  His prof in fact
rejected the proposal.  Haha, that's just too funny.  I wonder if Merkel
knew that this legend continued to make it's rounds at Berkeley for many
years, losing his name, but keeping the algorithm basically intact.

@_date: 2014-12-05 07:00:25
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day (week?): ATSHA204A has low 
If I made no mistake (and I do make a lot), the "random" data from the
Atmel ATSHA204A is highly predictable when you disable the seed update to
EEPROM.  Until we understand the this predictability in their output data,
I believe any "random" data from this part should not be used for crypto.
I generated 32 bytes of "random" data repeatedly with the Hashlet, after
disabling update_seed (I set the default to false in cli_commands.c).  I
ran 1MiB of this generated data through a little bit predictor I wrote, and
verified that each output bit has less than 0.5 bits of entropy.

@_date: 2014-12-05 08:09:33
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day (week?): ATSHA204A has low 
To check my results, feel free do download two data files I generated using
the Hashlet, containing the Atmel part:
The "one_go" file is what I get when asking for 100,000 bytes in one call
to random.  It has no simple correlations I see.  The randdata file was
generated by generating 32 bytes from the hashlet over and over, without
updating the EEPROM seed.  Bits in these 32 bytes are highly predictible,
based on the previous several bits.
To measure this predictability, I ran it through the usual program "ent",
and also a program I wrote specifically to predict the next bit based on
the previous N bits.  Ent only detects a 0.1% level of non-randomness.
However, the predictor program I wrote can compress this file by more than
The predictor program is in infnoise/software/entcheck.c.  You can convert
the hex output from the hashlet program to binary using hex2bin.
I am still tuning the predictor, but if I haven't goofed up, I seem to be
able to compress the "random" data from the Atmel part by over 10X.

@_date: 2014-12-05 10:31:23
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day (week?): ATSHA204A has low 
The first time I turned off update_seed, only 164 unique 32-byte values
were ever returned by "hashlet random".  Then I called "hashlet random"
exactly once with update_seed on.  After that, with update_seed off, only
124 unique 32-byte values were ever returned by "hashlet random".
It looks likely that no more than 8 bits of true randomness is mixed into
the seed each time the random function is called.
I suspect this chip's crypto is fully breakable due to it's poor entropy
source, if you know the starting seed and know the update algorithm.  IMO,
the use of the EEPROM seed seems most likely to be nothing but a way to
mask that the crypto on this chip is back-doored.
Can anyone else verify this?  If what I think I am seeing is real, I
certainly hope this part is not being used in new systems for any security

@_date: 2014-12-09 04:32:29
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day (week?): ATSHA204A has low 
A more secure way to use this part is:
1) Call the "random" function 512 times, with EEPROM updates turned OFF
2) Combine the LSBs of the results to create a single 512 bit value
3) Call SHA256 on the 512 bit value, resulting in a whitened true random
256-bit value
This procedure is more secure than relying on the EEPROM seed as a "random"
source.  Not only does this get around some simple back-doors that may be
in the device, but this procedure eliminate the limit on how many random
values can be generated.  Normally the device refuses to generate "random"
data after about 1,000,000 calls.
While there is some evidence, there is still no convincing proof that there
is an entropy source in this device at all.  There is some evidence that
Atmel has inserted a back-door.  My advice is to avoid this line of parts
from Atmel for cryptographic use.
I think any Linux system that already has this part should go ahead and add
the "random" values it generates using the procedure above to the
the entropy pool recover if it's state is compromised for any reason.
However, do not update the entropy estimate in the pool, because we cannot
be sure we've added any actual entropy!  This is how we use random values
from the Intel RDRAND instruction, or any other source of randomness that
is suspect.
The great thing about FOSS software is we are free to improve it.  Landon,
who uses an Atmel email address, wants you to use the EEPROM seed, which
could hide a back-door.  If people want a more secure version that does not
rely on the EEPROM seed, I would be happy to fork the Hashlet code and make
this fix.

@_date: 2014-12-09 05:42:11
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day (week?): ATSHA204A has low 
I just did another simple test.  After cold-booting my Raspberry Pi, I
called "./haslet random" and recorded the 32-byte result.  I had the
update-seed parameter turned off.  I did this 4 times.  Then I generated
about 800 values in a loop, which resulted in only 161 unique 32-byte
values.  All 4 cold boot values were in the list of 161 unique values.
I then generated 5326 64-byte values, of which 1171 were unique.  Looking
at just the first 32 bytes, there were 171 unique values.  Looking at just
the second 32-byte values, there were 1171 unique values.
I then generated 5348 96 byte values, of which 3217 were unique.  The first
group had the same 171 unique values, and the second had 1179.  The 3rd
group of 32 had 3217 unique values.
My best guess as to what's going on here is that the device has a
ring-oscillator based entropy source, but that it generates only a few bits
of entropy for each use.  It seems to be called before generating each
32-byte "random" value, which is why the second set of 32-bit values have
more possible values, and the 3rd has even more.  However, the number of
unique values in the final column of 32*N byte values is always equal to
the number of unique values of the entire string of bytes.
In the most common use case, where a Linkys router or some other embedded
device calls the random function only a few times ever, then Atmel will be
able to easily guess the values generated, since they are the ones who
created the initial seeds.  For devices that always publish a public key
somewhere after using this random function to generate the secret, Atmel
would always be able to determine the private key.  The only way I see to
generate a secure key would be to disable the EEPROM and combine enough
entropy from the random function results, then whiten it, as I described in
my prior post.
Since this device does not seem to get any signals such as a clock from the
Raspberry Pi, yet it returns different values after a cold boot on the
first call to random, I think there is strong evidence that some sort of
entropy generator does exist on the part.  However, with that EEPROM, it
could still just be a PRNG.  There is no way to be sure, and Atmel does not
seem very forthcoming about what they actually put inside the part.
This remains the scariest TRNG I have reviewed!

@_date: 2014-12-10 06:08:07
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day (week?): ATSHA204A has low 
This part uses the same language to describe the random number generator.
It is "high quality".  I think that's pretty funny.
I would be interested in seeing if the new part can generate random numbers
continuously, or if it fails after it's EEPROM wears out like their other
parts.  The use of an EEPROM seed is for PWN-ing your RNG, not making it
more secure.

@_date: 2014-12-11 14:30:22
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day (week?): ATSHA204A has low 
Hi, Russ.  Especially if all you're using this device for is DRM of some
sort, feel free to use it exactly as Atmel recommends.  However, the EEPROM
seed is most likely a back-door.  I have to laugh at the phrased "unseeded
RNG" when talking about a hardware true random number generator.  There's
no such thing.

@_date: 2014-12-14 21:47:00
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day: OneRNG KickStarter 
If you've followed these discussions, you know I distrust undocumented and
unverifiable hardware RNGs, like Atmel's.  Intel does better - at least
they tell us enough about their hardware RNG for me to fear a power-droop
attack to control it's output.  Some would-be really nice TRNGs such as
TrueRNG almost got there, and then for unexplained reasons failed to
publish schematics.
I started reviewing with OneRNG, and of those I've reviewed, it remains by
far the strongest in terms of real security, IMO.  They are one of only a
handful that understand that hardware RNG security needs to be open, from
schematics and board layout to source code.  They just launched a
KickStarter today.  I've signed up for a OneRNG at the $50 NZD level.
I now sell a hardware RNG USB key on Tindie.  I have various reasons for
doing this, but creating the world's most secure entropy source was not one
of them.  I feel OneRNG did a better job at real security, through solid
engineering.  For real security, I feel like I can trust OneRNG above
everything else I've seen.  I hope future versions of the OneRNG may
include a modular noise multiplier entropy source, but frankly, these guys
built a heck of a trustworthy RNG using what is proven and accepted.
If $50 is not a lot of money to you, I hope you'll join me in supporting
OneRNG.  We need secret generators that we can trust.  Otherwise, how can
we trust crypto at all?  Passwords only?
Non-disclaimer: Not only am I not associated in any way with OneRNG, but I
directly compete with OneRNG with my Infinite Noise RNG.  I have no reason
to promote OneRNG other than my belief that they have built the world's
most trustworthy TRNG.

@_date: 2014-12-14 21:51:48
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day: OneRNG KickStarter 
Grr... if you needed any proof that OneRNG is more solid than my own quite
cool Infinite Noise RNG, well... I forgot to post the link to OneRNG's
KickStarter!  I am a wonderful source of entropy!

@_date: 2014-12-15 19:25:11
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day: Skipping EntropyKey 
I have been asked a few times now why I have not reviewed the EntropyKey.
The truth is, I have too much respect for it's authors to tear them down
with a critical review.  They deserve praise for their excellent work, and
little else.  However, I have seen no schematics, and though I didn't look
very hard, I did not find source code for the firmware either.
That said, I believe firmly that the EntropyKey authors are simply trying
to help the world be more secure.  Their motives are sound, as is the TRNG
they produce.  It is the key I would have bought if OneRNG had not come on
the scene.
So, if you like EntopyKey, you're not alone.  I have some differences of
opinion about the right technical direction, but I'll keep the rest of that
to myself.  Kudos to the EntropyKey team.  If they are interested in my
dumb opinions, I can always be contacted off-list

@_date: 2014-12-17 02:52:01
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day: Skipping EntropyKey 
I see your point.  In that case, here's my thoughts on Entropy Key.  First,
it is a solid effort, with a lot of feedback from the Linux community that
went into it's design.  The fact that Entopy Key was out there dealing with
so many security concerns before the Snowden revelations shows a lot of
good insight by the Entropy Key developers.  However, we can do better.
Here's one decent FAQ about Entropy Key:
Here's the issue that bothers me most:
Q. How open is this device anyways?
A. The source to the firmware is not currently available from Simtec.  The
keys are epoxied and one-time programmable, which would make it impossible
to verify the source with the firmware if we did have it.
I don't understand how an effort like Entropy Key could get so far and then
fail on this point.  However, before Snowden, only seriously paranoid
tin-foil hat nerds worried about things like having the firmware
compromised.  Also, this effort pre-dates recent work showing how USB keys
can be used to PWN your system.  Epoxy may have seemed like a good solution
before hearing about how devices are sometimes intercepted in the mail and
modified.  With this knowledge, I have to agree with the OneRNG team that
the best solution is to be completely open and verifiable.  The lack of an
open schematic is also a problem.  Similar to the TrueRNG, Entropy Key
devices have two zener noise sources, which is a good thing.  However,
having two zener noise sources is not as strong as two completely different
kinds of entropy sources, as we have in OneRNG.  My preference here remains
using a single entropy source of higher quality than either zener or radio
noise, but zeners are the current standard.  Hopefully that will change.
Another issue I have with the Entropy Key is it's complexity, which is
quite harmful to cryptographic security.  The firmware takes on too much,
IMO, in terms of health monitoring, whitening, and then encrypting
communication with the host application.  The KISS rule applies far more in
crypto than elsewhere, since writing secure crypto code can be very
difficult.  I would prefer that these functions run on the host, and be
open-source, so many eyes could help verify it, and where a security patch
could be issued quickly if any problem is found.  Also, to support these
functions, a high-end microcontroller is required, making it a bit more
While encrypting the Entropy Key output is cool, I think this added
complexity is not worth the risk.  Having a master key bothers me a bit, as
it is known by the user, the manufacturer, and possibly the MiB, since they
can easily force the manufacturer to hand over the master keys.  I see that
Entropy Keys are not currently in production, with no new production date
offered.  This is a bit mysterious, and with my tin-foil hat, I wonder if
perhaps they've been NSL-ed (national security letter), and forced to hand
over the master keys.  From what I can tell, the Entropy Key authors are
the kind of guys who would rather end production of a device than hand over
it's keys to the MiB.  If this were the case, they likely would be
restricted from even saying that they have ended production.  This could
explain the current bazaar status of Entropy Key production.  Have they
been NSL-ed?  How's that for paranoia :-)
Encrypting random data seems redundant to me, because such encryption
requires that the client already have a crypto-strength secret, from which
it could simply crank out as much key material as it needs with a CPRNG.
If an attacker learns this secret, he could predict the CPRNG output, but
he could also then decrypt the RNG data stream from the Entropy Key.
Exactly, what security is gained through this encryption?  I haven't
figured it out, yet.  IMO, all this complexity creates too many new avenues
of attack, and the code is closed-source.  Not good for security.
All this said, I think Entropy Key did an outstanding job overall, and they
blazed the trail followed by the likes of OneRNG.  I heard of it long
before OneRNG, and I wanted to buy one.  I'd own one now if it were still
in production.  However, it is time to move to a more open solution.

@_date: 2014-01-03 02:29:18
@_author: Bill Cox 
@_subject: [Cryptography] The problem is not just merely a secure KDF (was 
I agree it is beneficial to talk about specific cases, as Kevin suggests.
 If the OpenSSL authors are aware of the benefits of the newer KDFs, why
don't they use them?  My private ssh key by default, which by far is the
most important case, is protected by a decent salt and ONE round of MD5.
 Off line, and attacker can throw hardware acceleration at for days on end
to crack my password.  Through an obscure option, you can switch to 2048
rounds of SHA-1, and that's the best they offer.  There's a great article
No options for bcrypt or scrypt exist, and you can't even increase to 4096
rounds, which on my machine is about 2.5ms of computation.  Whatever
happened to 1 second of computation?  Didn't we figure out that was a good
idea in the 70's?
Maybe the article above is wrong, and with even more obscure options I can
do better than one round of MD5, but I have to wonder who could feel good
about maintaining that code with such an antiquated default.  There are
plenty of C programmers still around to fix this.  I volunteer if anyone
would like me to provide a patch.

@_date: 2014-01-10 17:53:08
@_author: Bill Cox 
@_subject: [Cryptography] Dumb idea: open-source hardware USB key for crypto 
I've been noodling the idea of a USB stick designed in a way that we
can trust the crypto that goes on there.  It's a hard problem, but
there seems to be some guidelines that could help:
- Open source hardware - schematics and everything including board
layout need to be free
- No ICs that could be compromised.  Any CPU would have to be a
soft-core in an FPGA, with an open-source design
- FPGA configuration memory both readable and writable over a JTAG port
- External flash program memory also read/writeable through JTAG
- Reasonable hardware RNG where every node in the circuit can be probed
- Signal isolation from the PC: solid state relays would swap a simple
memory back and forth between the PC side and USB stick side.  Maybe
power draw should be randomized to obscure any processing going on.
RF shielding should cover the USB stick.  No other communication
should be possible.  This is similar to an air gap.
- A community supported audit trail verifying produced USB keys are secure
The idea still has issues.  Where would I be able to store secret keys
securely such that an attacker who stole my USB stick could not
recover it?  Anyway, it's just a fun idea.  I'd love to have such a
device in my pocket.  There's a lot of applications I can think of
that could benefit from it, from electronic voting to
microtransactions.  As one security expert once said in an
electronic-voting discussion I followed, no machine ever connected to
the Internet has proven secure.  Could we make such a beast?  I
probably don't really have time to work on it, but if a group were
building it, I'd participate.

@_date: 2014-01-11 19:01:02
@_author: Bill Cox 
@_subject: [Cryptography] Dumb idea: open-source hardware USB key for 
A keypad and display would be great, but for users who just want to
carry it in their pockets, a USB stick form-factor would be
preferable.  I personally was thinking that I would have a Raspberry
Pi based system with keyboard and display that was isolated from the
Internet to help me generate keys, but of course average users would
plug them into their Windows machines, and who knows who's watching
them type passwords in that case.
Your preference for epoxy encased circuits, and read-protected
microcontrollers is interesting.  That's one way to go, but I'm more
worried that our USB sticks will be subverted somewhere along the
build chain, so my preference is to make it easy to read out the
programming information and to be able to probe the internal signals.
You probably are right that in reality users would never bother with
such authentication, which is why I would like to see a volunteer
group of people who do bother to prove that most of these USB keys are
But you are right that my version makes it easy for an attacker to
steal my USB key and read out the keys...
It's a tough problem...

@_date: 2014-01-20 17:14:34
@_author: Bill Cox 
@_subject: [Cryptography] one-time pads 
I built a OTP system fun in the late 1990's.  My Dad and I both had
CDs that I filled with identical copies 600MB of true random data.  My
father's data started at 0 and increased as he sent mail, and I
started at 600MB and went down.  Each email said what range was needed
to decrypt it, so we just kept track of how much we had used (it was
of course automated).  I wrote a cute little Windows email program
that worked like a regular email program, except it used the
one-time-pad.  It even supported attachments.  It complained if the CD
was not inserted in the drive.  However, it was attached to a Windows
machine on the Internet, so I'm sure glad I didn't have anything
valuable in those messages.  The provable security of one-time-pads is
really no comfort.
People dump on OTPs, but compare that flow to using the latest and
greatest public key system.  Instead of handing my Dad a thumb drive
full of OTP data next time I see him, we would more likely email our
public keys to each other, and maybe even follow it up with a phone
call to convince each other we've got the right ones.  In the process,
we may tip off Eve that we're up to something (I hear she's really hot
by the way - hope she's not reading this post...).  If I really wanted
to communicate secretly, I would hand my Dad a thumb drive with a true
random 256-bit shared AES-256 key, and never let it touch any device
attached to the Internet.  We might play with stenography, embedding
our secret messages in pictures.
I protect my car (worth maybe $15,000) with a physical key I keep in
my pocket.  If an attacker wanted my car, he might be able to get it,
but it's tricky.  He has to be physically present, know what he's
doing, and not get caught while doing it.  In reality, I've never had
a car stolen.  Physical keys work pretty well.
If I protect $1 worth of e-money with the best open-source crypto
system available, I sure wouldn't want to depend on that $1 being
there tomorrow.  That's why I sold all my BitCoins (all 20-something
of them last spring for $23 each).  When they were worth < $50 total,
I didn't care if they were stolen.  Once they hit $500, I got them the
heck off my computer.
Electronic keys don't work very well when used on anything connected
to the Internet.  If they did, we'd all love voting over the Internet.
 My point is that fancy crypto is fun and all, but for real security,
you have to have some physical device that never touches the Internet.
 Once you already carry around a physical key, how different is the
experience than using OTPs?
I think the main reason for the death of OTPs is that we've convinced
ourselves that shared private key crypto works, and it's simply a
better solution.  It's frightening how often we've been wrong, though!

@_date: 2014-07-03 11:47:26
@_author: Bill Cox 
@_subject: [Cryptography] Security clearances and FOSS encryption? 
I am working on the CipherShed open-source fork of TrueCrypt.  I believe
one of our contributors has a US security clearance of some sort.  I have
no problem with this, but:
Do US security clearances in any way restrict a person's involvement in
FOSS encryption projects like CipherShed?  In the US, we only recently
gained the right to contribute to FOSS encryption projects with only a
reporting requirement.  The government surely could restrict those rights
with a security clearance, but having never had one, I have no idea.  Is
there anything I should know about people with security clearances who
contribute to CipherShed?
I would be quite the hypocrite to say people with US security clearances
are not welcome to contribute.  A company I founded did US military
sub-contracting after all.  I would just feel better knowing that a
security clearance in no way impacts how or if a person can participate.

@_date: 2014-07-08 13:38:58
@_author: Bill Cox 
@_subject: [Cryptography] Security clearances and FOSS encryption? 
I agree with you.  Our CipherShed project is currently too small to worry
about this issue, so I am going to assume it's OK.  I'll post that to the
CipherShed PMC list.  Thanks for the well thought out replies!

@_date: 2014-07-16 23:46:20
@_author: Bill Cox 
@_subject: [Cryptography] Steganography and bringing encryption to a piece 
This is cool but I do not think this algorithm is very secure. For example
I encrypted "this is a test" followed by "this is a test" and the
ciphertext included for ciphertext words repeated. I have not read the
paper but it sounds like the algorithm needs a bit of work. Sorry about not
the reading the paper but I am on vacation and I do not have a reader
On Jul 16, 2014 7:30 PM, "Gr?gory Alvarez"

@_date: 2014-06-01 10:35:37
@_author: Bill Cox 
@_subject: [Cryptography] What is going on with TrueCrypt? 
that there might be problems forking the project under
I agree with your analysis so far.  TrueCrypt 7.1a looks forkable, but will
have to contain dead links, and can't have a name similar to TrueCrypt.  I
think it is OK to point out that the link is dead on the page containing
the link (probably the About page).  This license does look like no IP
lawyer ever looked it over, but I don't think it's a problem other than for
inclusion in Linux distros that are very careful about their licenses, such
as Debian.
We don't have the right to change the license, so we can't re-release this
code under any GPL license for example.  It will have to continue to be
released under the license that shipped with 7.1a, though more restrictions
can be added for new code if anyone wishes.
Perhaps the code can be replaced over time, and the new code licensed under
some other form, but I think that's low priority for the near term.  There
are already FOSS alternatives with decent FOSS licenses that would make a
better starting point if having a Debian compatible license is the goal.
Perhaps the new TrueCrypt maintainers could work with one of those FOSS
alternatives, and over time converge on a common properly FOSS licensed
crypto core.

@_date: 2014-06-02 21:09:53
@_author: Bill Cox 
@_subject: [Cryptography] Fork of TrueCrypt 
There is a discussion list for the TrueCrypt fork over at:
    Does anyone here know the guys behind this fork?  In their Vision
statement, they said they wanted to add an auto-update feature, and have
the dev team working on continual feature enhancements.  If they integrate
code that talks to the network on purpose, I'm going to do my own fork
instead.  If they get a team adding new code constantly, I'll also have to
pass on this fork.  Do they know anything about crypto?

@_date: 2014-06-03 07:05:37
@_author: Bill Cox 
@_subject: [Cryptography] Fork of TrueCrypt 
An auto-update feature pinging the server would alert any network snooper
of exactly who was using the TrueCrypt fork.  From a security point of
view, auto-update is DOA.
I read some more posts over on truecrypt.ch.  The more technical of the two
guys behind it wonders if he can buy out the zulucrypt guys.  He's
definitely thinking of this as his new startup rather than a FOSS effort.
in this team.  It seems they're just interested in cashing in on TrueCrypt.

@_date: 2014-06-03 10:54:39
@_author: Bill Cox 
@_subject: [Cryptography] GeekCrypt: A Secure Fork of TrueCrypt 
TrueCrypt must not die.  Therefore, crypto geeks must run the TrueCrypt
fork.  Announcing GeekCrypt:
    Unfortunately, the truecrypt.ch guys aren't real crypto geeks.  Apparently,
they are out to make quick buck.  The TrueCrypt code needs severe KISS
defense to maintain it's security, which will be destroyed by the current
truecrypt.ch vision.
I truly do not wish to run a TrueCrypt fork, but I also can't stand by and
let the effort fail due to greed and incompetence.  I can defend the
TrueCrypt code base from insecure feature creep, but there are better
crypto coders out there, and certainly coders more able to find security
holes.  I've CC-ed two such coders.  If you are a good crypto coder, please
consider working with me on GeekCrypt (or whatever we eventually call it).
There wont be any financial rewards in this project.  We wont be anonymous,
and we will make every edit public.  The best reason for joining is to do
some public good.  Initial discussion can happen here, and an initial page
can be found at:
    If you would like to be part of the team, please contact me:
waywardgeek at gmail.com.

@_date: 2014-06-03 17:28:19
@_author: Bill Cox 
@_subject: [Cryptography] GeekCrypt: A Secure Fork of TrueCrypt 
Already done :-)  I'm just lucky that the first dev to contact me (the guy
who did the first Linux compile on truecrypt.ch) happens to live in Germany
(I think).  Also, it's not clear yet if he wants to "join my team", but at
least we can start collaborating on code on github.
I think it may wind up being US-heavy, but the coding team needs to be

@_date: 2014-06-03 17:32:23
@_author: Bill Cox 
@_subject: [Cryptography] Fork of TrueCrypt 
Absolutely true!  If the truecrypt.ch guys issued a goal list that had
taking all the code in a FOSS direction, working with (but not buying)
ZuluCrypt and others, defending the code with stringent application of
KISS, and fixing TrueCrypt's poor password security, I'd be onboard even if
they were raising money.  I just find that the money as often as not pushes
a FOSS project in a direction it really shouldn't go, and I think this is
especially true for crypto.  Stated goals like "continual feature
enhancements" is what a marketing guy things of when there's a continual
money stream.  Injuring marketing guys is probably what a lot of crypto
guys think of when they hear "continual feature enhancements".

@_date: 2014-06-04 06:33:25
@_author: Bill Cox 
@_subject: [Cryptography] FalseCrypt (was GeekCrypt) 
While the name may change again, for now, the GeekCrypt project is going by
the name FalseCrypt.  How's this for a logo?
Decent crypto coders are welcome to join.  Visit FalseCrypt.net for more
info if you want to be part of a TrueCrypt fork with a chance to succeed.

@_date: 2014-06-04 19:10:21
@_author: Bill Cox 
@_subject: [Cryptography] Fork of TrueCrypt 
All true.  It's funny, but I can argue that BitLocker is safer in some ways
because your computer is *expected* to contact Microsoft once a day.
So, what if people just go with BitLocker?  It probably is secure against
most government snooping, just not ours.  At what point do we trust our
government not to illegally snoop and do horrific Star-Chamber sorts of

@_date: 2014-06-06 08:46:21
@_author: Bill Cox 
@_subject: [Cryptography] Back door competition for TrueCrypt fork? 
I need your guys opinion on the following idea.  I think it would enhance
security to have a back-door competition to keep our core developers
security auditing skills sharp.  However, there is some strong opposition
to the idea.  What do you guys think?
This is my slightly spelling corrected email sent to the list yesterday:
---------- Forwarded message ----------
I really am paranoid.  As another poster said, "My paranoia goes to 11."
We may already have an NSA plant on this list.  How can we succeed while
working with an NSA plant?  If he's good, he may create really difficult to
detect back doors, and even if we find them, they will look like innocent
mistakes.  Is there any defense?  The only way I can think of is diligent
code review.  How can we tell if we're doing a good job?
I think it might be a lot of fun to see which of us can succeed in
inserting a back door without the others noticing.  Every week each
developer (core developer?) would publish a warrant canary containing an
encrypted code snippet, as well as the key to the prior week's code
snippet.  The code snippets would either say "No back doors were inserted
this week", or show exactly where the back door is with an explanation.
Any time one of us finds a back door, we should raise the alarm.  The
person responsible for the back door should then reveal the decryption key,
proving to us that he had planned to reveal it next week anyway.
Whenever one of us gets away with an undetected back door, the next week
everyone would know about it (and obviously remove it).  We could call that
"winning", and having our back door detected "losing", and even keep
tallies of wins and losses.
Anyway, it's just a though.  It's a sort of a QA for cryto.

@_date: 2014-06-07 04:14:18
@_author: Bill Cox 
@_subject: [Cryptography] Vote of no confidence. 
I was thinking of posting a photo of my 100% secure computer: totally
I built it myself out of SN74LS* parts!  All wirewrap, running 10MHz (very
fast!).  There's no networking of any kind, no disk storage - when you turn
it off, everything you did is gone!  Totally secure! :-P
I haven't felt any other computer I've used since is quite as safe...

@_date: 2014-06-07 05:15:35
@_author: Bill Cox 
@_subject: [Cryptography] TrueCrypt forum on CipherShed.org 
The truecrypt.ch forum has been the main discussion board for building a
fork of TrueCrypt.  It has been down for some time now, and in case it does
not come back, please feel free to continue discussions at:
Developers there want one fork, not two, and hope to merge with the
truecrypt.ch effort when they catch up.

@_date: 2014-06-07 19:56:18
@_author: Bill Cox 
@_subject: [Cryptography] Help investigate cell phone snooping by police 
It's called a Faraday cage.  I'd test it right now, but I think someone hid
my mobile phone in a fridge.

@_date: 2014-06-09 09:41:08
@_author: Bill Cox 
@_subject: [Cryptography] Back door competition for TrueCrypt fork? 
Hash: SHA1
Grr... the link to describing the risk is still there, but the link to
how they defend is gone.  This link offered no help at all.
Good point.  Maybe just one per release cycle would be better.
I'll take your word for what US spies are trained to do.  I have no
idea!  However, with so little transparency, it is hard to know just
what public laws have been overturned by secret laws.  Is it legal to
force someone to break a contract or lie in the US for national
security purposes?  It's a good theory...

@_date: 2014-06-24 09:41:29
@_author: Bill Cox 
@_subject: [Cryptography] Good GPG email solution for Windows (NOT Thunderbird) 
Thunderbird has failed me for many years across multiple machines and
operating systems.  My poor experience may have to do with using their
crappy accessibility interface with screen readers, so that may explain why
my experience is different from most.  Let's just say that Thunderbird
totally and permanently sucks for my needs and move on to the next solution.
I needed integrated GPG support in Windows 8.  I prefer FOSS tools, but at
this point, I'll even pay for a lame insecure closed-source unauditable
hacked up PoS email tool, if it automates signing and signature
What would be the tool of choice?

@_date: 2014-03-08 22:12:29
@_author: Bill Cox 
@_subject: [Cryptography] RC4 again (actual security, 
I have been an ARC4-DROP fan for years.  I wrote the "TinyCrypt"
project (on SourceForge) to encrypt files with it years ago when it
was hard to even find a simple file encryption program.  I felt it was
secure enough up until last year when the Royal Holloway attack was
    As they say on Wikipedia, it's not a practical attack yet, but it
looks scary.  That combined with rumors that the NSA has broken ARC4
are enough for me to no longer use my own TinyCrypt ARC4 based code.
The Snowden leaks, if I'm not mistaken, seem to imply that AES is
secure, even against the NSA.  It's even simpler to use AES from the
openssl library than to code ARC4.  I've got some not ready for
prime-time code in tigerkdf-enc.c and tigerkdf-dec.c, which show how
to (improperly) use the openssl library:
    Another recent use for ARC4 I proposed was using it in a memory-hard
password hashing system to rapidly fill memory.  It's plenty secure
enough for that application, but even with it's amazing simplicity,
it's too slow for my purposes there.  It's great for an 8-bit
microcontroller, but with an Intel Core i7-4770, I can use the 8x32
SIMD unit (AVX2) to hash memory amazingly fast (thanks to guidance
from Solar Designer).  ARC4 was amazing for it's time and got a bad
rap due to poor implementations, but I think it's time has passed.
Hope this helps.

@_date: 2014-03-08 22:30:06
@_author: Bill Cox 
@_subject: [Cryptography] RC4 again (actual security, 
You're opinion matches that of many academic security people, but for
the more practical coders among us who just want real-world security,
ARC4 has been just fine for most of these years since 2000.  Just
being able to tell that 1GiB of data was most likely generated by ARC4
is interesting, but in applications where it is already known that the
encryption is ARC4 by everyone, this is a non-issue  (for example
encrypting a file with a .arc4 suffix is pretty obvious).  That number
has come down a lot from 1GiB since 2000, but it's still a non-issue.
The recent attacks on RC4 scare me a lot more than these efforts to
detect what algorithm generated the data stream.  It' not a complete
attack yet, and ARC4 remains secure currently for many applications,
but now I am concerned that ARC4 may be actually broken in the not too
distant future, and that it may already be broken in government crypto
agencies.  Of course, academics will cringe at my use of the the
phrase broken, since many feel an encryption algorithm is broken once
it's output can be detected as non-random.  That's just nonsense.  An
algorithm is only broken when an attacker can decrypt stuff.
So, I agree with you that ARC4 should no longer be used, just for
different reasons.

@_date: 2014-03-22 21:52:33
@_author: Bill Cox 
@_subject: [Cryptography] BLAKE2: "Harder, Better, Faster, 
"We hypothesized that offering engineers a hash function that was both
faster and more secure than their beloved MD5 or SHA-1 might be more
effective than haranguing them to upgrade to an alternative that is
more secure but slower."
I guess that makes me just like all the other geeks who care about
speed!  Actually, if anything, there aren't enough of us anymore.
Blake2 rocks.  It pains me to switch to slower, more secure systems
when the old one has not yet been broken (I hung onto ARC4-DROP(N)
longer than most).  I think people forget that in many cases,
increased speed results in increased security.

@_date: 2014-03-24 00:02:50
@_author: Bill Cox 
@_subject: [Cryptography] BLAKE2: "Harder, Better, Faster, 
The SHA-3 competition also seems to have led to an unfortunate case of
foot-in-mouth over changing the security requirements after picking
the winner, to a weaker standard, scaring the heck out of those of us
who know about the competition, but have no clue what they're actually
doing.  Especially after all the Snowden leaks... I bet this really
frustrates the SHA-3 judges.
Also, while Keccak does sound cool, the reasons for choosing over
Blake2 are reasons I would have avoided it.  As discussed above, being
like SHA2 should likely be considered a good thing now, and being more
efficient in hardware, IMO, should generally be considered a bad
thing, and certainly not a reason for choosing the SHA3 winner.
However, I only know about a small subset of the security field, and
in protecting passwords, it's critical to find algorithms that are
inefficient in hardware.  Someone suggested Keccat on the PHC list,
and I think it went over like a lead balloon.

@_date: 2014-05-07 15:59:11
@_author: Bill Cox 
@_subject: [Cryptography] cryptography Digest, Vol 13, Issue 6 
Nice topic.  I'm not very knowledgable about this, but Dwave may have the
best quantum factoring capability, with a 512 cubit machine now, and a
machine with at least twice that in the works.  There was a teaser about a
future blog post from their CTO titled, "Better than Shor", and then
everything about using Dwave for factoring integers somehow seems to have
been scrubbed from the Internet.  However, there is ongoing research into
the problem, such as:
If I understand correctly, with a small constant factor of qubits larger
than the number of bits of N, a Dwave machine should be able to factor N,
given low enough noise and accurate enough control (big if).  So, there is
a reasonable possibility that quantum annealers may be built in the next
decade or so that could crack most current public key cryptosystems.
 There's a lot on post-quantum cryptography out there.

@_date: 2014-05-27 16:09:45
@_author: Bill Cox 
@_subject: [Cryptography] [PHC] Re: The proper way to hash password files 
If I understand this thread correctly (which is often not the case), the
basic idea here is to use a special non-disclosed master key to scramble
password hashes even more, making it impossible for an offline attacker
without the master key to brute force guess any passwords.  This is a great
idea, and should be encouraged, IMO.
This was discussed on the PHC forum (I first learned about it from the
Blakerypt paper posted there), and several of the entries, including
Catena, Yescrypt, Lyra2, TwoCats and others, support site-specific data
fields that get hashed into the password, which can be used to support
master keys.  I mention that as my favorite use for the extra parameter in
my TwoCats submission.  Even with Yescrypt (the entry with the most defense
features), use of such a key is probably a good idea.  A password
authentication server with a 1TiB ROM still loads that ROM from disk, and
if an attacker gains physical access to it (during maintenance for
example), having a master key that never hits disk could be a good thing.
I think for large web sites like eBay, I'd prefer an authentication server
with a mongo ROM and lot's of defensive features, rather than a cheap
USB/FPGA key.  However, for all the guys out there (like me) who couldn't
realistically justify an authentication server costing many thousands of
dollars, a cheap USB-dongle sounds good.
I like the idea of using an FPGA and a microcontroller, and making it all
open source and easily verifiable.  I'd say just use a Raspberry Pi or work
with the FreedomBox guys, if they were more easily verifiable.  Such a
dongle could also potentially be used for micro-transactions and other
applications, in addition to hashing passwords, or SRP.  They could be used
as secondary authentication factors, too.  If we had a second access port
on the "secure" side, maybe it could be used for secure end-to-end
encryption (or even VPN) between parties who each have one.  I can think of
lots of uses for such a device.  I want one :-)

@_date: 2014-05-27 16:44:17
@_author: Bill Cox 
@_subject: [Cryptography] New slogan for the NSA 
Maybe if we came up with a cute crypto-dongle as has been mentioned several
times on this forum, we could call it the "Cone of Silence" :-)

@_date: 2014-05-29 06:26:50
@_author: Bill Cox 
@_subject: [Cryptography] Truecrypt removed by authors 
I already suspected TrueCrypt was being pressured to weaken their security.
 Bcrypt was presented in 1999, and is still not offered in TrueCrypt, nor
is Scrypt an option.  Only very weak password hashing options are offered
(max is 2000 rounds of SHA256), and the default is the weakest of them all.
The even dumber defense from geeks on their forum of their weak password
hashing is one of those things that make me suspect NSA shills.  However,
it's hard to distinguish intentional manipulation away from decent security
from good old fashion stupidity.

@_date: 2014-05-29 06:55:24
@_author: Bill Cox 
@_subject: [Cryptography] Truecrypt removed by authors 
I particularly enjoyed the repeated claim that the 512-bit password hash
stored in a TrueCrypt header provides unbreakable security against all
brute-force password guessing attacks, regardless of password strength.
 The large salt value was also repeatedly pointed out as being particularly
secure :-)

@_date: 2014-05-29 17:09:21
@_author: Bill Cox 
@_subject: [Cryptography] What is going on with TrueCrypt? 
I tend to agree.
It's probably just me being paranoid, but I have been suspicious for some
time that something is up over at the TC site.  First, some commenters were
either really really dumb, or purposely supporting keeping TC password
hashing (key derivation) weak for unknown reasons.  Second, when I was
active on the user forum, twice, both times on Sunday afternoons, the forum
shut down after I posted until Monday morning. It gave me the feeling that
someone was monitoring the site, and had a way to shut it down if a post
was made that needed to be reviewed for some reason.  Likely this is just
paranoia, but it's possible there has been something strange going on for
over six months (roughly how long ago this happened).

@_date: 2014-05-30 10:18:53
@_author: Bill Cox 
@_subject: [Cryptography] Fork of TrueCrypt 
I see that Matthew Green, the guy behind the TrueCrypt audit, is
considering doing a fork of TrueCrypt.
I encourage this!  I also would like to contribute, as the current version
of TrueCrypt has poor password security IMO, and needs an upgrade anyway.
Is there someplace where interested geeks can discuss this fork?  Is here
the right place?

@_date: 2014-05-30 17:09:55
@_author: Bill Cox 
@_subject: [Cryptography] What is going on with TrueCrypt? 
On Thu, May 29, 2014 at 9:01 PM, Peter Fairbrother
I like this theory best of the ones I've read so far.  Microsoft is know
for shady business practices, and I would not put it past them to buy out
the TrueCrypt devs.

@_date: 2014-05-30 18:13:20
@_author: Bill Cox 
@_subject: [Cryptography] Fork of TrueCrypt 
Looks like one of the devs may have replied to a couple emails.  Check the
end of this blog:
It sounds like the devs are tired of developing it for free, and want to
kill it off rather than see others fork and degrade it.  I've looked at
some of the TrueCrypt code, and what I've seen is very good.  I've read a
ton of FOSS code, and good code in FOSS land is rare.  I can see why they
would not want others to muck with it.
I feel confident I can work with this code and keep the quality high :-)  I
hope the truecrypt.ch guys pick me to be on their team.

@_date: 2014-11-05 08:04:52
@_author: Bill Cox 
@_subject: [Cryptography] Infinite Noise or Firebug? 
It turns out that Peter Allan invented what I have been calling an Infinite
Noise Multiplier, way back in the summer of 1999.
    It sounds like he is interested in working together to popularize this
architecture.  That's a good thing, because I feel this is the _right_
architecture for TRNGs.  Which name would be better for a USB key sold on
Tindie?  Is there a better name?

@_date: 2014-11-08 21:59:20
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day (week?): ATSH204A 
Atmel has a chip for crypto that we can buy for under $0.50.  That's cool!
However, it has a "high quality HW RNG", with absolutely no description of
how they do it.
However, I've personally reverse-engineered the part.  Here's how they do
1) They program their flash with a 256 bit "random" seed, which they could
easily record, just in case they need it (or some government demands it).
2) Whenever you call their "random" function, it actually runs a plain old
PRNG, with this "random" value as the seed.  It then overwrites the seed
with the new "random" value.
3) If you try to call their "random" function more than 2 billion times, it
locks up, to avoid giving you enough data to see that is is just a PRNG.
OK, so I didn't actually do the reverse-engineering... However, I wouldn't
allow this part in any system that requires any sort of actual security.
Am I wrong?  Atmel?  Anyone?  Buller?  Anyone?  Buller?
How could they release a part with behaviour that is so obviously likely to
not be random at all, for use in cryptography?
Anyway, for now, I give it a "Danger Will Robinson" rating.

@_date: 2014-11-09 07:26:05
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day (week?): ATSH204A 
There are many comments about Atmel's part like this:
And here's the standard snake-oil from the manufacturer:
Atmel claims, "In the ATSHA204, the random seed comes from variations at a
quantum scale within the ATSHA204."
If this were true, then why do they have to have a "random" seed?  A high
quality TRNG is used to _genereate_ random seeds, and has zero need for one
to be provided!  Also, exactly what "quantum scale" entropy are they
As for which PRNG they are using... well, I see they have HW SHA-256.  If I
had to guess, it's SHA-256(seed + counter), where counter is incremented
for each 256 bits they spit out.  At the end, they likely write the counter
value back to flash, which enables them to cut off output at a specific
value.  I doubt they ever change the seed, so it's shipped pre-programmed
into your part.
By the way, I can only find a ATSHA204A , not an ATSH204A. Is it this one?
Yes... thanks for pointing that out :-)
I saw that.  I guess it is useful for testing...

@_date: 2014-11-09 08:16:40
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day (week?): ATSH204A 
I didn't explain why I find post like this so scary.  A bunch of our
Linksys/Cisco routers apparently use the ATSHA204A for seeding /dev/random
at boot, to cover a security hole caused by lack of entropy in the device.
This thread is about a guy adding this "random" seed to OpenWRT!  There are
statements like:
"Certain randomness extractors need a random seed."
Huh?  Which randomness extractors require a random seed?  This is a scary
level of ignorance for guys implementing such critical security code.  If
the MiB have a copy of every ATSHA204A's seed, they might be able to PWN a
huge number of routers.
Here's a great quote on this thread from the data sheet:
"Random numbers are generated from a combination of the output of a
hardware random number generator and an internal seed value, which| is not
externally accessible. The internal seed is stored in the EEPROM, and is
normally updated once after every power-up or sleep|wake cycle."
If the TRNG is capable of producing even 200 bits of entropy, then why do
they need the seed at all?  Why bother to "update" it?  Here's what I
think: they only implemented a short counter to save a few gates.  When it
overflows, the device will start spitting out repeated "random" values.
There is a simple way to test this.  They have the ability to turn off the
seed update.  If the device generates correlated keys after multiple cold
boots with update turned off, then the TRNG is weak.  If it always
generates identical keys, then the TRNG doesn't exist at all.
Apparently Atmel expects to fail this test:
"In certain circumstances, the system may choose to suppress the EEPROM
seed update using the mode parameter to the Nonce and Random commands.
Because this may affect the security of the system, it should be used with
Does anyone have one of these devices that they can test in this mode?  I
would love to have access to a few thousand "random" outputs after cold
boot of the device without the seed update.
I find it very difficult to believe this device has a "high quality TRNG"
as Atmel claims.  If it did, there would be no impact on the security of
the system when the "seed update" is disabled.  There would be no need for
the seed at all.
This device fails the smell test worse than any TRNG I've read about.
And... it's in our routers...

@_date: 2014-11-09 09:39:24
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day (week?): ATSH204A 
I believe them, and a unique serial number is a good thing.  In fact, it
might be the "seed" they talk about.  There is no way to insure that these
serial numbers are not recorded by Atmel.
That's how it should work, but why does their TRNG need the seed?  Doesn't
that violate this statement that each random number does not depend on past
No, I've just read the docs and some discussion.
No, I'm not qualified to have a useful opinion about your breeze PRNG.  I
read your README.md, and it sounds cool.  My un-useful opinion is that it
looks like it would be hard for me to determine the state of several of
your state variables just from the low bytes, at least if they are mixed
together somewhat before outputting them.  I haven't read the code.

@_date: 2014-11-11 08:15:17
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG Review Per Day: TrueRNG 
TrueRNG is soooo close...  Maybe I can shame the author across the finish
TrueRNG was published on Tindie for $50 as "Open Hardware".  That is
fantastic!  His product is sold here:
The problem is once the author started selling a few, he forgot to make the
hardware open.  I see that he continues to claim to be open hardware in his
marketing on Tindie.  IMO, keeping the details of TRNG hardware secret is a
terrible mistake.  Keeping the details of a reverse-biased NPN zener noise
based TRNG secret is even worse.
I suspect the author just wants to make some money for a while.  I
certainly have no problem with that.  He likely feels he can further that
goal by claiming to be open hardware while actually keeping the design a
complete secret.  I have a big problem with that.
Partly in response to this insult to open-hardware, I built an an actual
open-hardware USB TRNG, and made it available on Tindie:
    My schematics, board layout, source code, and even a complete BOM are here:
    Feel free to make them yourself, or even mass produce them and sell them
for whatever price you like.  My preference is for the original inventor of
this entropy source, Peter Allan, to start producing them in volume (or
some improved version).  Hopefully, with my little Infinite Noise TRNG, I
can help suck the greed motivation out of this market, and manufacturers
will begin to be more open.
My advice to anyone interested in a USB key TRNG is to wait for OneRNG.
Don't buy TrueRNG until the author stops pretending to sell open-hardware,
and don't buy mine, either.  I literally bake these boards outside on my
grill to solder the parts onto the boards!  You deserve something built
with machine precision, like the OneRNG devices will be.  You certainly
deserve a device that is verifiable, which seems to be the main point of
So... on to reviewing the scant details about TrueRNG that have been
revealed so far...
TrueRNG claims to use zener noise as the entropy source, just as other more
reputable TRNGs like OneRNG and Entropy Key.  Like OneRNG, TrueRNG claims
to have added a second entropy source, because these zener noise sources
can be unreliable.  Having two of them adds an important level of
redundancy, reducing my worst fear about the device - that it will start
producing predictable output.
However, to reduce the chance that both zener noise sources fail together,
the NPN transistors being used should come from different manufacturers.
These things all use the reverse Vbe breakdown of a cheap NPN transistor as
the zener noise source, since this zener is not tuned to be low-noise like
real zener diodes.  Used this way, the noise from the NPN transistors tends
to drift over time, and they can eventually fail.  Since the NPN transistor
manufacturer does not test this mode of operation, there is no way to be
sure that they will continue to work reliably, other than to buy a ton of
them and do the QA yourself.  Buying two transistors from the same lot of
parts from the same manufactures would maximize the chance that they fail
together.  Does TrueRNG use identical parts in both sources?  I hope not,
but we have no way to tell until someone does a tear-down of this "open
hardware" device.
Zener noise sources can be reliable.  They don't produce provable levels of
entropy, but we can test them statistically and become confident that they
produce enough entropy to be secure.  We can shake-and-bake them in burn-in
boards to verify that they will last.  However, for a small volume product
like TrueRNG, we can't realistically expect this level of QA.  Using two
different NPN devices from two different manufacturers should reduce the
chance of both failing to about the square root of the chance that one
fails.  That's good enough for me.
Because zener noise based sources use massive amplification to detect the
noise, they are naturally *very* sensitive to outside signals, such as
power supply noise.  If not designed by an expert analog designer (like
Paul, who works on OneRNG), they can easily have flaws that cause their
output to only appear random.  Because of this, having open schematics and
board layout is critical for zener noise based TRNGs.
IMO, TrueRNG remains in limbo, not quite a security failure, not quite a
trustworthy entropy source.  Until the author does what he claimed he would
do a long time ago, and make the design truly open, TrueRNG can not be
I have to give TrueRNG a rating of "untrustworthy" until I can see both
schematics and board layout, complete with sources for the NPN transistors
and other parts.  At that point, a real review could be done.

@_date: 2014-11-12 12:45:48
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG Review Per Day: TrueRNG 
Of the Infinite Noise keys?  I just did, since you mentioned the idea.  It
was slightly tricky getting both going at once on my laptop.  If there is
correlation in the raw output, I have not yet been able to find it.  There
should be a small correlation.  For one thing, they both output slightly
more 1's than 0's, which should be reported as a correlation.  The 'ent'
program rates both outputs at 0.92 bits of entropy per bit, which happens
to be an over-estimate.  I compute 0.876 bits of entropy per output bit
from both USB keys.  Because of this, I do not put much stock in ent
entropy estimates.
When I compress each output with bzip2, and then compress the combined
files, the combined file size is 0.07% larger, so bzip2 found no useful
repeating patterns between the two outputs to enable it to compress any
better.  Ent also reported 0.92 bits of entropy for the combined file, just
like each individually.
As for TrueRNG, I think it would be awesome to have access to both entropy
streams individually, before any whitening.  I would expect some
correlation.  Power supply noise, for example, is likely impact both
outputs in a similar manner, and while careful analog design can reduce
this effect, it cannot be completely eliminated.
However, a small correlation is OK.  We can just subtract any measurable
correlation from the estimated entropy per source.  The only thing that
would be bad, I suspect, is very long sequences of bits from both sources
that are equal, or very high correlation.  That might indicate that some
external signal is overriding the zener noise in both entropy sources at
the same time, often enough to make the output predictable.

@_date: 2014-11-12 18:11:34
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG Review Per Day: TrueRNG 
This certainly is true for CPRNGs, where finding any correlation is deadly
to the algorithm.  However, SFAIK, there is no such thing as a hardware RNG
that generates data that is undetectably non-random.  There are always
correlations.  They all require "whitening" before the data can be used for
crypto.  Some of the less impressive TRNGs whiten before you can see the
data, without giving you access to the raw data from the entropy source.
This destroys any chance of verifiability.
There are many ways to do whitening.  For example, I used to use the parity
of 80 sequential bits from a zener noise based RNG as the output, and that
passed the old diehard tests.  However, I wasted most of the entropy in
whitening.  A better solution would is to try and get a good estimate of
the entropy, and compress it just enough through a cryptographic sponge to
get it where it needs to be.
Some TRNGs, like Turbid, have provable levels of average entropy output.
That's helpful in whitening.  The Turbid paper showed that you don't need
to compress entropy much through the sponge to have undetectable levels of
non-randomness.  It's pretty cool.

@_date: 2014-11-17 11:18:04
@_author: Bill Cox 
@_subject: [Cryptography] Infinite Noise or Firebug? 
Peter and I have bounced a couple names back and forth.  What do you think
of Modular Multiplication Loop?  It is more descriptive of the function
than Infinite Noise Multiplier, or Firebug.  Other variations might be Mod2
Multiplication/Multiplier Loop, Analog Modular Multiplier, etc.

@_date: 2014-11-17 18:45:00
@_author: Bill Cox 
@_subject: [Cryptography] Infinite Noise or Firebug? 
I'll just call my specific USB TRNG on Tindie an "Infinite Noise TRNG".
The name for the circuit topology can be different.  It does not have to be
catchy, but I think it should be descriptive.  "Noise multiplier" is fairly
descriptive.  Should we have "loop" at the end?  For example, "noise
multiplier loop".  Maybe some indication that it is a non-saturating
multiplier, like "modular noise multiplier"?

@_date: 2014-11-17 21:31:13
@_author: Bill Cox 
@_subject: [Cryptography] Infinite Noise or Firebug? 
Good point.  The circuit actually happens to do modular multiplication, mod
K, where K is from 1 to 2.  However, it's not like the world has been
screaming for an analog modular multiplication solution!
I guess "noise multiplier" may be good enough for now.

@_date: 2014-11-24 20:53:55
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per week - XR232USB 
This is one of my favorite TRNGs.  It's open source hardware and software!
Frankly, if you conceal stuff in crypto related projects, it's DOA.  This
project is one of the few that get this right.  You can read about it here:
It is simple and cheap.  It relies on "comparator noise", which the
designer has trouble mathematically analyzing.  However, to me, it is
clearly similar to oscillator based noise sources, with similarly provable
entropy generation.  It is unfortunately sensitive to RF interference,
which the author tested himself.  That puts him in a whole new class of
geeks who actually test their hardware and admit to it's weaknesses.  This
guy wants you to understand the risks, unlike the vast majority of TRNG
designers out there.
On the downside, it does have a microcontroller, which means it could
potentially PWN your system, but it is only programmable through a
programming header.  It probably should have signed software, bloated with
random data to fill the ROM, like the OneRNG, but this is still very good
compared to most.  I have to give this guy kudos for ripping TRNGs like my
own "Infinite Noise" TRNG for having "creepy bit-bang" control.  It is
creepy!  I have a timer I check to insure the bit-bang is fast enough, but
I'd feel better if this were not required in my TRNG.
The author did not offer direct access to the entropy source, which is a
big problem!  However, I think most likely, he just needs to hear from us
geeks that we want it.  He stirs the entropy in an XOR pool, which makes it
nearly impossible to do proper health monitoring of the noise source.
Internally, there is a health monitor, but it only looks for long sequences
of 0's or 1's.  An attacker can simply inject a seemingly random pattern
rather than constant 0's or 1's, and defeat this health monitor.
In summary, I have to give this TRNG my second highest rating.  I would say
it is "conditionally safe for cryptography", where the condition is that
the user believes he is not being attacked with RF or (far more likely) a
power supply drain attack.  The power supply drain attack is also the one I
worry about with the Intel DRNG.
This is a good TRNG.

@_date: 2014-11-30 21:28:48
@_author: Bill Cox 
@_subject: [Cryptography] Underhanded Crypto 
I think this is a fantastic idea!  I guess lots of details need to be
worked out, such as whether a 1-line edit to a 1-million line program is
acceptable, vs the other extreme of requiring all-new code for each entry.
Will there be an opportunity for the public to try and find the underhanded
security holes?  That sounds really fun!

@_date: 2014-10-01 16:54:37
@_author: Bill Cox 
@_subject: [Cryptography] Internet of Things and small cheap ASICs? 
Personally, the Internet of Things seems to have a major security problem.
I personally do not plan to hook my thermostat to the Internet any time
soon, for example.  Can anyone point me to the best papers describing how
to actually secure the IoT?
Since you guys were so helpful with feedback on my Infinite Noise Generator
concept, I thought I'd go back to the well and bug you about something a
bit less crypto related...
I am trying to find out if there is any need for board-level designers out
there to be able to create small mixed-signal ASICs. I'm not talking about
an iPod-Nano on a chip, but simple arrays of capacitors, resistors,
transistors, a few logic gates, and maybe some amplifiers. The die would be
tiny, and each would have the same components. Designs would be configured
with custom routing. The minimum order might be 1,000.
So, for example, a chip you could design using say 100 0.1pF caps, 300 6K
Ohm resistors, maybe 50 analog N and P mosfets configured for analog (wide
gates), maybe 20-ish T-gates, and 20-ish logic gates (NAND/NOR/INV), a
couple of op-amps, and maybe 16 pads, and come in some tiny 16-pin surface
mount package. It might even have 1K-ish gates of real logic, and 128
FLOPs, and even a small block of SRAM, if people think it should. The
resistors would not be very accurate, but they would match well. Same thing
for the other components. It would come with free design tools, likely
based on existing open-source tools. Something like this I think can be
done for under $1/chip, in quantities of 1,000.
I am trying to figure out if this is a good fit for helping enable the
Internet of Things. It might be useful for simple sensor interfaces, for
example, or reducing part-counts and size. Would anything like that be
Thanks Bill

@_date: 2014-10-06 18:23:42
@_author: Bill Cox 
@_subject: [Cryptography] Creating a Parallelizeable Cryptographic Hash 
I disagree with this point.  This thread is an excellent way for people to
*avoid* mistakes like this hash function.  People should be *encouraged* to
post their latest dumb idea about hashing here, so it can be reviewed
before harming anyone.
Furthermore, this thread introduces a valuable concept I was not aware of
before, and it's fun :-)  The uses for such a hash function are I think
quite broad.  For example, we could incrementally update a
cryptographically strong hash of a huge database in constant time.  So...
here's *my* dumb hashing solution for this problem:
Simply compute:
Digest = H(N || H(H(1 || B1) * H(2 || B2) * ... * H(n || Bn) mod p))
While I am often wrong, I have managed in my head to prove to myself that
finding collisions in the generalized birthday problem over a
multiplicative group modulo a prime is equivalent to solving the discrete
log problem.  If this proof holds up, then this should be a secure hash, so
long as p is large enough, such as 2048 bits.  Also, I assume that H is
effectively a random oracle with no possible analysis of it's function that
could help us find collisions.  Some hash functions, such as H(x) = g^x mod
p clearly fail here.  However, any respected ARX based hash should work
out, as should Wolfram's Rule-30-like hashes such as Keccak.
My proposed proof is simple.  Instead of picking true random numbers ri < p
to multiply together, looking for a collision in the usual way, compute si
= g^ri mod p for i in 1 .. n.  If g is a group generator, then si is just
as random as ri, but we know something about si (it's discrete log).  Using
a supposed algorithm faster than solving the discrete log, we now find the
discrete log of y = g^x.  Just find r1 ... rn such that g^r1 * g^r2 * ... *
g^rn = x, using our fast algorithm, and then the discrete log of x is
trivially found as r1 + r2 + ... + rn mod p-1.
Surely, any algorithm that can find such solutions multiplying r1 * r2 *
... * rn will work just as well using ri = g^H(i) mod p as it would using
the H(i) values as random numbers instead, so this step of replacing ri
with si is sound.
Therefore, this hash function is secure, based on the security of the
discrete log problem.
Does this work out?  If it is secure, as I currently believe, then it
should have a number of good uses in cryptography.

@_date: 2014-10-06 18:46:16
@_author: Bill Cox 
@_subject: [Cryptography] Creating a Parallelizeable Cryptographic Hash 
In case it's not obvious to Tom or anyone not familiar with modulo
arithmetic, this hash function can be updated in constant time by keeping
track of the Digest, as well as the mod p result.  Just multiply the old
mod p result by the multiplicative inverse of the H value that changed, and
then multiply by the new H value mod p, and recompute the digest.

@_date: 2014-10-07 06:52:26
@_author: Bill Cox 
@_subject: [Cryptography] Creating a Parallelizeable Cryptographic Hash 
Tom's idea being discussed here is a constant time updateable hash function
of very many records/messages/blocks, which Blake2 does not do.  A good
solution to this problem has many real-world use cases.  Rsync, for
example, uses a rolling hash function
 which is insecure.  Maybe we
could use:
y = H(1 || B1) * H(2 || B2) * ... * H(n | Bn) mod p
This looks secure to me, based on the difficulty of the discrete log
If you can give me an algorithm that takes random numbers and finds
combinations of them that multiply out to a specific digest y mod p, then I
can use your algorithm to find the discrete log base g of y.  I simply give
your algorithm g^rand() rather than rand(), and the algorithm finds y =
g^r1 * g^r2 * ... * g^rn mod p.  I am somewhat surprised Wagner did not see
this in his paper on the generalized birthday problem,
 since significant effort
was put into framing attacks using multiplicative groups.  I just didn't
find that part very convincing :-)

@_date: 2014-10-07 07:02:56
@_author: Bill Cox 
@_subject: [Cryptography] Creating a Parallelizeable Cryptographic Hash 
Actually, this is one of my favorite processes for producing good ideas.
Continuing with this process, what's wrong with:
Digest = H(1 || B1) * H(2 || B2) * ... * H(n | Bn) mod p
I think I've shown this is secure based on the difficulty of the discrete
log problem.  If true, isn't this exactly what you say is unlikely to

@_date: 2014-10-07 17:34:01
@_author: Bill Cox 
@_subject: [Cryptography] Creating a Parallelizeable Cryptographic Hash 
Hi, Jerr.  Thanks for taking a look at this.  However, I am confused.  Why
do I care that an attacker can in constant time compute the correct hash of
a different set of data?  By multiplying in H(n+1 || Bn+1), the data is
different, and so is the hash.  That seems to be the way we want this
function to work.  In constant time any new block can be added or
subtracted from the hash.  That is the goal, I believe.
It seems to me that the security model is that if we have D = H(B1, B2, ...
, Bn), then an attacker should not be able to find find D = H(C1, C2, ... ,
Cm), unless n == m and Bi == Ci for all i in 1 .. n.  By appending H(n+1 ||
Bn+1), you've changed the message, and derived the correct hash of it, in
constant time.  Isn't that useful?  You can also prepend, or even replaced
any Bi you want in constant time.
I agree that this should certainly not be used for anything for now, but I
would like to talk about it more.  Do you agree with my assertion that it
is secure for the purpose of verifying data integrity of a large data set,
while allowing constant time update, including appending new data blocks or
replacing old ones?

@_date: 2014-10-07 21:31:58
@_author: Bill Cox 
@_subject: [Cryptography] Creating a Parallelizeable Cryptographic Hash 
Constant time update is asymptotically infinitely faster than log-time hash
trees for updates, and I think also provably secure.  Besides that, there
are plenty of real-world applications where constant time updates are
acceptable, but log(n) are not.
Is anyone here going to address my defence against Wagner's generalized
birthday attack?  By the way, Wagner is one of my heroes.  Defending
against even one of his attacks would be quite validating.

@_date: 2014-10-07 21:59:28
@_author: Bill Cox 
@_subject: [Cryptography] The world's most secure TRNG 
I've reduced the BOM for the parts (not board/assembly/test yet) from about
$7.00 to $2.60.  Unfortunately, my bandwidth dropped from 1MiB/s to maybe
25KiB/s.  Also, I was convinced by the argument above that I had to write a
driver anyway, so why not put the whitener there?  I call it a whitener
because that's the accepted term... frankly I think that term sucks, but I
have gripes about a lot of common terms like this.
I removed the FPGA from the design and now only have a USB-to-FIFO chip
acting in bit-bang mode to control the infinite noise multiplier, which is
much slower.  I think you guys were right to have me focus on cost.  More
people will copy my $1.10 in parts (without the USB controller) even if it
generates only 25KiB/s, than ever would copy my $5.50 1MiB/s TRNG.
I've got my $1.60 USB interface chip to configure Lattice ICE40 FPGAs,
which only cost about $1.50 (both in quantities 1,000).  It seems like that
would be a fun proto-board by itself.  A $5 FPGA USB hacker board might be
fun... The Lattice tools to configure it runs a free copy of Synplify Pro,
which looks almost exactly like it did when I stopped working on this tool
in 1998.  The schematic generator seems to be about the same as I left it,
though there was a really good guy making amazing improvements for a while
after I left.  Time seems to have degraded it back to my version.

@_date: 2014-10-08 20:59:02
@_author: Bill Cox 
@_subject: [Cryptography] The world's most secure TRNG 
No command/control.  In fact, I feel a lot better not having a
microcontroller on there that could transmit nasty malware when being
plugged into a new system, or which could be reprogrammed to emit
non-random data.
It's just a simple USB -> 8-bit fifo chip controlling the TRNG.  The USB
controller is a FT240X, which has some reconfigurability, but not even
enough to create a 2-bit state machine.
The host just sets Ph1 high and Ph2 low and vice versa through the bit-bang
mode on the FT240X, and receives the resulting bytes one per clock.  Only
one bit of each byte is output from the TRNG, so you clock it 8 times and
then send a byte to the whitener.
I'm working on the Eagle schematic and board layout now.  It's a lot of
fun.  I know I should put an EMI shield on the device to keep it from
leaking data to attackers, but I am leaning towards shipping naked cheap
little USB boards, similar to a  DigiSpark.
How important is the proper USB connector vs a raw connector with no
housing like the DigiSpark?  Do we really feel we need to wrap this thing
in metal to keep it from radiating secret bits?  I figure if we feed it
into a whitener, an attacker would have to know *every* bit to know the
state of the whitener.  That seems like a tall order for an attacker trying
to read bits from EMI.

@_date: 2014-10-08 21:24:36
@_author: Bill Cox 
@_subject: [Cryptography] Secure parallel hash, with constant time update 
This was Creating a Parallelizeable Cryptographic Hash Function, started by
Jason Resch.  His XORing hashes together is not secure, but doing the same
thing with multiplication modulo a prime appears to be.
The hash function is:
    Digest y = H(1 || B1) * H(2 || B2) * ... * H(n || Bn) mod p
The prime p should be large, such as 2048 bits, because if an attacker can
compute the discrete log of the H values mod p, he can easily find
My security proof is simple.  Assume an attacker has found an algorithm
that takes essentially random numbers ri as inputs (the H values for each
i), and finds a way to multiply some of them together to equal the previous
digest.  All we do is change his algorithm so that instead of picking
various ri = H(i) to multiply together, compute instead si = g^ri mod p for
each i used by the algorithm.  If g is a group generator, then si is just
as random as ri, but we know something about si (it's discrete log).  Using
the attacker's algorithm, we now find the discrete log of y = g^x.  Just
find s1 ... sn such that s1 * s2 * ... * sm = x, and then the discrete log
of x is trivially found as r1 + r2 + ... + rn mod p-1.
I've had a few days to noodle on this proof, and I now believe it is
sound.  If the world needs a constant-time updateable parallel hash
function, this should do the job.  When we add new messages to the end, we
can compute the new digest in constant time.  We can also replace any
existing message Bi with Bi', and compute the new hash in constant time.
We can also use this for a rolling-window hash, similar to what rsync uses,
but more secure.
Jason, is this what you were looking for?  I would love to know what use
case you have in mind.

@_date: 2014-10-09 09:43:34
@_author: Bill Cox 
@_subject: [Cryptography] Creating a Parallelizeable Cryptographic Hash 
hash primitive, you can't.  So, this is not really a problem.  However, we
can't use just any hash function.  H has to be secure.
Not true for block sizes of B where B is large.  Anything over 1MiB should
be  fine.  However, if the block size is just a KiB or so, then the modular
multiplications will dominate.  There needs to be a significant need for
constant time update in this case.
That is much cheaper, but David Wagner broke such systems in his paper on
Generalized Birthday attacks:
He explores security using various operators and goes into some depth about
possible attacks on multiplication modulo primes.  However, his explored
directions also directly apply to attacks on discrete logs.
I'm afraid I know of no secure shortcut that avoids 2048-bit arithmetic.
That this can be done securely at all is new information, SFAIK.
Thanks for taking a crack at it.

@_date: 2014-10-13 16:53:42
@_author: Bill Cox 
@_subject: [Cryptography] Secure parallel hash, with constant time update 
Can I take it as a good sign than no one offered any attacks or found any
weaknesses so far? :-)
While I am often wrong, I claim it is secure based on the difficulty of the
discrete log problem.  What would be the next natural step for this
algorithm?  It seems the usual way is to write a paper...

@_date: 2014-10-13 17:49:51
@_author: Bill Cox 
@_subject: [Cryptography] Secure parallel hash, with constant time update 
Hi, Jerry.  Thanks for making the attempt, but your attack fails.  To mount
it, an attacker must have an algorithm for finding x such that H(x) = 0.
If he has such an algorithm, he has broken H completely, which contradicts
the assumption that H is a secure cryptographic hash.
A more interesting point is does the algorithm have a practical use?  Is
there need for a hashing algorithm that defends well against the
generalized birthday attack?
It probably is worth noting that there is such an algorithm in any case,
and we cannot assume that this attack breaks all hashes of this form.

@_date: 2014-10-13 19:34:47
@_author: Bill Cox 
@_subject: [Cryptography] Secure parallel hash, with constant time update 
Very cool...
Thanks for point out the paper!
I take it as good news.  It means I'm  less of a dork than I thought,
although I wish I had better google-fu.  I was going for "parallel" when
"incremental" would have gotten me these results quickly.
It's fun to read these papers knowing about the generalized birthday
attack.  My construction is identical to MuHASH, which he proved secure in
the same way.  However, he then argues that we can securely use AdHASH,
can't prove it, and instead states similarities between finding collisions
in hashes added together modulo a big number to the modular knapsack
problem, known to be hard.  It's a good example of how hand-waving in
crypto can be a bad idea.
Wagner and friends clearly broke AdHASH with his generalized birthday
attack, but I think MuHASH still stands.  For example, the 4-element
generalized birthday problem works so long as we throw out any hash values
Wagner's paper spends so much time trying to find weaknesses with
multiplication, but I guess it makes sense if we're talking about weaker
multiplicative groups than integers modulo large primes.  I assume he knew
about AdHASH and MuHASH.
In general, the important property of the combining operator seems to be
that it mixes bits cryptographically well.  Addition didn't quite get there.
With multiplication, even 2-way, picking two random numbers between 0 and
p-1 that multiply to anything other than astronomically larger than p is on
the easily less likely than 1/sqrt(p) - how's that for had waving :-)
Therefore, we can't throw out all those too-large random numbers and expect
to run faster than sqrt(p) calls to H.
Thanks again for the pointer.  Very cool

@_date: 2014-10-21 01:05:21
@_author: Bill Cox 
@_subject: [Cryptography] The world's most secure TRNG 
Top posting just the new news, with responses to your comments below.
The breadboard works!  The estimated entropy coming out of the Infinite
Noise Multiplier is very close to the predicted amount.  I measure it by
recording outcomes given the previous 16 bits many times until I have a
reasonable guess for the probability of the next bit being a 1 or 0.  I use
that to estimate the probability of a long string of bits occurring.  The
entropy is estimated as log2(1/P(S)), where P(S) is the probability
estimate of the string of bits S occurring.  This estimated entropy closely
matches the expected log2(K), where K is the gain in the op-amp circuit.  I
tested this for 3 different gains, and they all matched within 5% of the
theoretical value.  I added a picture of the breadboard here:
I also wrote some code to find how soon we see a repeated string N bits
long.  The data from the INM has repeated strings of size N consistent with
the estimated entropy.  This proves that there is no scary cycling of the
same outputs over and over, at least with a period less than the expected
length before seeing an N-bit repeated string (20,000+ in my tests for 34
For now, I've got an application that reads from the USB using the existing
serial interface driver that comes with the FT240X USB interface chip I'm
It normally whitens by reading 2X the amount of entropy requested and
filtering it through the 1600 bit version of the Keccak (SHA3) sponge.  It
just writes the binary data to stdout for now, but it's simple to make that
a file socket or whatever.  There's a --raw flag which dumps raw data from
the noise source without whitening.  I have been doing some fun health
checking stuff with that.  A --debug flag causes it to print estimated
entropy, gain in the op-amp, and a couple of other stats.
Some sort of automated Internet traffic cop might be a hit.  If it needs a
source of random data, it's about $1 in extra components to an embedded
I added a real USB connector, and have nickle EMI paint I can use on the
inside of the USB key housing. Hopefully that will keep it quiet.
True enough.  I'm shielding it with conductive paint on the inside of the
plastic housing.  I am tempted to leave the housing un-glued so that users
can take it apart if they like and poke at the internals.   I saw at least
one TRNG company that encases their electronics in potting material.
That's no better than Intel asking us to just trust that their TRNG circuit
is secure.  If we can't open it up and see for ourselves, why should we
trust the manufacturer?

@_date: 2014-10-21 22:17:25
@_author: Bill Cox 
@_subject: [Cryptography] The worlds easiest TRNG not to F-up 
IanG has some awesome things to say about the difficulty of TRNGs and
random number generation in general:
    I also discovered the excellent work of OneRNG, and Paul has been awesome
with advice:
    After learning about these efforts, I no longer feel "the world's most
secure TRNG" is appropriate for my Infinite Noise Multiplier.  Instead, I'm
backing off to "least likely to F-up".  The whole noise immunity makes it
comparatively simple to get right.

@_date: 2014-10-22 10:01:59
@_author: Bill Cox 
@_subject: [Cryptography] A review per day of TRNGs: OneRNG 
I had a ton of fun reviewing PHC candidates, and I learned a lot in the
process.  If people think it would be fun to review TRNGs in a similar
manner on this thread, then I'll do a review once per day-ish, until I
can't find any more TRNGs to review.
I'll start with my favorite, to begin on a positive note: OneRNG.
    OneRNG is free-hardware and free-software, as in freedom.  It's typically
called open-hardware and open-source.  This is *very* important for a
TRNG.  *Any* TRNG that has either unavailable software source, or
unavailable hardware design is going to get a poor rating by me, since
security-through-obscurity has been shown over and over again to fail,
particularly with TRNGs. AFAIK, OneRNG is the *only* open-hardware/software
device that has been built which is suitable for cryptography (mine has
only been breadboarded so far).  TrueRNG claims to be, but I have yet to
see a schematic, let along a board layout or software source.  However,
maybe I'll find it when I do that review :-)  Rob Seward gets an honorable
    This is free hardware and software in the best form.  However, as he
states, there are some security issues with this design that make it more
suitable for white noise generation than cryptography.
To support secure crypto, OneRNG takes unpredictability of their resulting
data *very* seriously.  Rather than rely on either radio noise or zener
noise, they put *both* on their board, and mix the streams together.  They
continuously monitor the health of both, and shut down if either is not
functioning properly.
They also disabled programming over USB, so nasty malware cannot subvert
the device.  This is a limitation of Rob Seward's design that he wisely
states in his documentation.  However, it is possible to intercept a OneRNG
in the mail, and reprogram it in nasty ways.  Users who are particularly
concerned about this possibility are encouraged to re-flash the device
This brings up threat models.  No hardware can be considered secure if sent
through the mail, unless we assume the mail service is trustworthy.  This
is true for laptops as well as TRNGs.  More than any other TRNG, OneRNG has
considered this a real threat and done something about it.  To verify you
have a genuine OneRNG, the metal shielding is removable.  You are
encouraged to inspect the board yourself and compare it to the picture
online.  The microcontroller label can be inspected, though it's hard to
prove it is not an impostor.  However, it is *very* difficult to make an
impostor of a microcontroller that functions properly with a programmer and
debugging interface.  It most likely has to be built by the original
manufacturer, in this case TI.  So, there is an assumption that a complex
$4 chip has no back-door, but I find that far more palatable than the
assumption that Intel's RDRAND instruction has no back door.
The radio entropy source can be influenced remotely by a radio transmitter,
so the OneRNG randomly skips around in the frequency being sampled, and
makes that decision I assume using output at includes the zener noise.
While I am not sure I would want to rely on radio alone, when combined with
the zener, it seems secure enough to me.
The zener noise is, I believe, generated a typical reverse base-emitter
breakdown, because the fabs don't bother to make this mode of using a
transistor low-noise.  Real zeners are far less noisy.  This circuit is
cheap, but has some problems.  It drifts over time, and the noise level can
very a great deal from part to part, making it hard to build a reliable,
dependable entropy source.  However, they do monitor it's health, and shut
down if it fails.
Because of the saturating amplification of the zener noise, an attacker can
influence the output with a very small injected signal.  To counter this
threat, OneRNG encases all of the analog circuits in a solid metal box.
The back side of the board under this box is a solid ground plane, with
several vias connecting the box to this ground plane.  Paul seems to know
what he's doing here, and I think he has likely succeeded in an excellent
shield against external interference.
As for downsides, OneRNG is not as simple as some TRNGs.  This makes it
tougher to insure it is secure.  Also, the possibility of having it
reprogrammed by an attacker who intercepts it in the mail remains an issue,
since most users will not likely re-flash their device.  I am not sure if
the flash can be dumped securely over USB, or if an attacker can mod the
program to deliver the original firmware, hiding the malware.
The biggest current downside to OneRNG is that you cannot buy one yet.
They are in Beta stage.  Paul has his own pick-and-place machine, and
hopefully will ramp production soon.  I plan to buy one when he does.
In summary, I give this TRNG my highest rating: secure for all
cryptographic purpose, IMO.  All threat models I can conceive have been
considered.  I would encourage users concerned about mail interception to
compare their firmware to that on the website, and then re-flash it anyway.
Also, Paul has been very helpful to me on my own TRNG project, which is
going beyond the call of duty.  He really does seem to want the world to be
more secure, and is willing to help other TRNG developers towards that
goal.  I do hope that in a future version, Paul might consider dropping the
zener and use a more noise injection resistant and more consistently
manufacturable Infinite Noise Multiplier, but he should ship what he has
for now.  Upgrading to an INM might be splitting hairs for the security of
this device.

@_date: 2014-10-22 19:20:59
@_author: Bill Cox 
@_subject: [Cryptography] A review per day of TRNGs: some snake oil 
Going alphabetically (I did reverse alphabetically on PHC entries), using
this awesome site:
and selecting hardware RNGs, I this at the top:
- Araneus Alea II
The Araneus Alea II USB key can be bought for 199 Euros here:
It passes dieharder tests, but the entropy source is zener noise, which is
not that white at these speeds, so there must be some whitening going on.
There is no description of the circuit, and the software is closed source.
I like that they use an A/D rather than just comparing to Vref like most
zener noise TRNGs.  There is a microcontroller on board, and we have no
idea if it can be used to PWN your system.
There's really nothing else to review, so until these guys open up and let
us see what's inside, I have to rate it: Snake Oil... until proven

@_date: 2014-10-23 06:51:02
@_author: Bill Cox 
@_subject: [Cryptography] A review per day of TRNGs: OneRNG 
So long as we're considering threats such as interception in the mail, I
think we should look at a more detailed threat model.  The most obvious use
for a TRNG is as an additional entropy source for a Linux server's entropy
pool.  I would like to assume:
- An attacker, Mallory, is logged in as a regular user, but for some
unexplainable reason is unable to obtain root access.
- The attacker know the *exact* state of the Linux entropy pool at time == 0
- There are 0 bits of entropy in the pool, and the pool is blocking on a
read by gnupg which is trying to create a strong cryptographic key.
- The user of gnupg is being careful to not allow his new key hit disk in
any non-encrypted form
- Fortunately, this system has a OneRNG key attached.
What attacks can Mallory mount?  One problem with my review of OneRNG so
far is I have not looked at any source code, even though it's open source!
Such a review eventually should be done in depth by multiple people, but
for now, here's two attacks this code needs to defend against:
- attacks that try to guess the random bits being added to the entropy pool
- attacks against the OneRNG's functioning properly
Do we care about cache-timing attacks?
To guess the random bits, Mallory might do a cache-timing attack.  To
defend against it, first you need to do never branch based on the data from
the OneRNG.  I need to go back and fix this in my infnoise driver.  It's
easy to get this wrong.  This is particularly easy to get wrong if you do
any health monitoring, like I do, in the driver.  OneRNG does health
monitoring on the USB key, which is secure against cache timing attacks.
Even harder is doing no data based memory addressing.  A statistical
analysis such as what rngd does will read and/or write data to a lot of
places that depend on the TRNG data.  My infnoise driver also does this,
reading from a memory location addressed by the last 14 bits of TRNG
output, to find the expectation that the next bit will be a 1 or 0.  Does
the OneRNG driver look for a string of only 0's or 1's coming from the
device, and stop the driver if only 1's or 0's are output?  If you do, you
help defend against faulty OneRNG devices, or devices that Mallory has
compromised.  However, by incrementing the 0's memory location for every 0,
and the 1's memory location for every 1, you give Mallory the possibility
of a cache-timing attack.
So, it is unclear to me whether it makes sense to worry about this
cache-timing attack.  The more extensive the health server-side health
monitoring, the more cache-timing susceptible we are.  For now, I'll just
point out these cache-timing attacks, but wont worry about whether the
improved health monitoring justifies the security hole.  If you use rngd,
there's no point in worrying anyway, since it will violate cache-timing
defence rules far worse than your driver.
Can an attacker directly attack the OneRNG?  For example, it would be bad
for the OneRNG to be accessible to Mallory in user space.  I would prefer
that it only be accessible by the daemon feeding the entropy pool (rngd?).
Adding udev rules for users to use the OneRNG could be dangerous.
Can Mallory can load the system down and cause the OneRNG daemon to be
swapped to disk?  If so, Mallory wins if he can gain physical access to the
disk later.  Therefore, *all* buffers containing TRNG output should be
considered as sensitive as passwords, and should be allocated in
non-swappable memory using mmap, and a secure zeroing function (such as
secure_zero from the Bake2 source) should be used to clear all TRNG bits
after they are fed to /dev/random (using ioctl).
Can Mallory cause any kind of time-out in the USB communication, by causing
high system load?  My infnoise driver does the bitbang hack to control the
clocking of the circuit on the board from the infnoise driver.  If left
unclocked for too long, the voltage in the INM drifts to 0, allowing
Mallory to guess the next several bits when clocking starts again.  To
defend against this, I will have to measure the time between packets read
from the INM and when it is too long, I'll have to drop the packets.
I think the hardware design of OneRNG is excellent for security.  A solid
code review of the driver probably is in order at some point, however.
This stuff is *very* easy to get wrong - my infnoise driver needs a lot of
work, and I'll bet most TRNG drivers out there don't even consider the
security of the TRNG bits against things like swapping to disk.

@_date: 2014-10-24 05:31:51
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day: RDRAND and the right TRNG 
The "right TRNG architecture" looks like this:
    auditable cheap low speed TRNG -> auditable high speed CPRNG -> happy
Respectable TRNGs like the new Cryptech Tech TRNG are switching to this
architecture.  If you use *any* secure TRNG to feed /dev/random, regardless
of it's speed, and then read your cryptographic key data from /dev/urandom,
then you are already using this model.
However, I happen to be something of a speed freak.  Intel's RDRAND
instruction is appealing to me.  The architecture is the fastest TRNG I
have seen.  So, why not use it?  Here's why:
- It is probably back doored
- It is not auditable
- Critical portions of its design remain secret (such as whitening and how
to disable it)
- We don't need a fast TRNG, even though it's cool
I have no knowledge of any intentional back door in this architecture, but
if I were to design a TRNG for a processor, and wanted to insert a hard to
detect back door, this is the architecture I would use.  I simulated this
architecture myself in SPICE in a .35 micron CMOS process.  It seems to
work, and man it's fast!  It basically powers up a latch and let's it
randomly initialize to either a 0 or 1, and uses that as it's random
output.  If you wait 20ns, the latch will have flipped one way or the
other, and you can read out the result.  If you don't mind reading the
latch before it's sure to have settled to a 0 or 1, you can read it as fast
as your clock runs, and still get a high average entropy per bit.  There is
simply no reason not to run this at 3GHz.
That said, this TRNG has so many drawbacks that I predict no one other than
Intel will ever use it.  First, it requires a couple of large-ish on-chip
capacitors to hold the control voltages that compensate for factors that
cause the latch to prefer to power up one way or the other.  Without
measuring the 0/1 bias and dynamically compensating for it, this circuit
simply does not work.  This by itself makes Intel's TRNG both large and
complex.  Worse, it is *massively* sensitive to nearby signals.  It is more
sensitive to external signals than any other architecture I know of.  No
other TRNG relies on amplifying such a small noise signal, and no other
architecture can be PWNed with as little injected energy.  This is
literally the most attacker signal sensitive TRNG ever designed.
It's power supply sensitivity is so bad, Intel actually *patented*
regulating the supply of a TRNG in order to reduce the impact of a power
drain attack on their device, thus making it *illegal* for any of us to
build this architecture securely.  Simply executing a power hungry loop
surely would otherwise cause this TRNG to output a long sequence of either
1's or 0's, until the bias circuit manages to charge the capacitors to
different levels to compensate.  There is *zero* published evidence that
Intel's power supply regulation actually works well enough to defending
against this attack.  We can't even test for ourselves, because Intel
purposely hides the raw TRNG output!
The power drain attack is so obvious that I suspect Intel's engineers who
aren't owned by a TLA would not allow this on their chip without a separate
power regulator.  This circuit is also is effected by substrate currents,
which is my preferred method for back-dooring it in a way that most Intel
engineers would not notice.  An attacker with special knowledge of
surrounding components could easily influence the device through this path,
which will not show up in any schematic.  It also will not be flagged as a
potential problem by any DRC or signal integrity tool.  No SPICE simulation
will reflect this attack unless the netlist is manually modified to take
this into account.  Intel's hordes of EDA tool pushers would give this
attack a green light, because it would pass every step in their
tried-and-true IC verification process.
If they did look for substrate current attacks, maybe I could PWN it using
light.  Certainly this device would change it's power-up behaviour by
simply shining a flashlight on it.  If I could get some circuit on the chip
to emit some low levels of infrared, I could probably PWN it that way.
Another potential attack is rapidly changing the thermal gradient.  If a
nearby portion of the die could be made hot very quickly, it might change
the power-up preference of the latch faster than the bias correction
circuit can compensate.
These are just some of the ways this device could be back-doored or PWNed.
I bet we could have an entertaining competition to come up with the most
create way.
Despite the NSA's likely back door in RDRAND, adding it to your entropy
pool will still defeat anyone who lacks knowledge about the back door.
Most of the bad guys we worry about lack this knowledge.  However, one day
the back door may be reverse-engineered and published on the Internet.
Relying on RDRAND for security is a bad idea, even if you don't worry about
the NSA's snooping.  However, adding it to the entropy pool is a good idea,
so long as we don't increase the entropy estimate.  Linus was right to bash
that guy who wanted RDRAND banned from the Linux entropy pool.
So, why do we need true random data at high speed so badly that Intel
decided to build in a device requiring large capacitors and it's own power
regulator?  The truth is, we don't need high speed.  As many people have
argued here, all any single system requires is 256 bits of true random
data.  That's all they *ever* need, so long as it remains secret (which is
hard), and so long as a cryptographically secure PRNG (CPRNG) is used to
generate all future cryptographically pseudo-random data (which is
comparatively easy).
A TRNG simply does not need to be fast.  A Lava Lamp generates entropy fast
enough for almost any application, so long as we use it to seed add a high
speed CPRNG firehose.  Anyone selling you a high speed TRNG for a lot of
money, based on quantum voodoo or whatever, is ripping you off.
Due to Intel's inexplicable reluctance to make their device auditable,
while relying on what is probably the hardest TRNG architecture to get
right, I have to rate RDRAND as snake-oil for use in cryptography.

@_date: 2014-10-24 17:01:28
@_author: Bill Cox 
@_subject: [Cryptography] Uncorrelated sequence length, 
I agree with you about on point.  Turning off the TRNG leaves the CPRNG
vulnerable.  In that case, if the CPRNG algorithm is broken, a lot of
generated keys could be compromised.  Using a CPRNG with the TRNG turned
off means your security drops to the level of the stream cipher or sponge
chosen, which in theory is lower than a well designed TRNG.  In reality,
I'm not so sure a CPRNG built using Keccak or ChaCha will be the weak
To help defend against this, the TRNG should be left on, and applications
needing the highest security should still read from /dev/random, while
applications that can live with the assumption that the CPRNG is secure can
read from /dev/urandom.  When I write data to the Linux entropy pool, I
only claim to write half as much as I measure.  This should enable it's
CPRNG to generate any sequence, even if I am slightly off in my entropy
estimate, though I would need to look under the hood at the Linux CPRNG to
be sure.
I suppose there are some use cases for high speed TRNGs that are auditable
and trustworthy.  Electronic one-time-pads for large organizations like the
US military come to mind, though that seems a bit far-fetched.

@_date: 2014-10-25 05:51:03
@_author: Bill Cox 
@_subject: [Cryptography] Uncorrelated sequence length, 
Interesting paper.  Here's how I would recover much faster.
I write 512 bits containing over 400 bits of entropy in one call, as the
minimum, with ioctl.  I have to look at the kernel code to see how it
works, but assuming:
1) The kernel sucks in all 512 bits at once, blocking all other users of
one-way hash on it's entire entropy pool.
2) The cryptographic hash is ideal in the sense that it's output cannot be
distinguished from true random, and cannot be reversed short of brute force
guessing all 2^n input possibilities.
3) No attacker can guess a state of the pool when no state has higher than
a 1/2^256 probability
Under these assumptions, the pool recovers from a state compromise in one
call.  The pool is not full, but no state has a probability higher than
about 1/2^400 so it does not matter.
However, I just went and looked a bit at random.c.  I would have to look a
*lot* harder to feel confident I am reading it right, but at first glance,
it's mixing function, _mix_pool_bytes does not satisfy my assumptions
above.  It does not appear to be a cryptographically secure hash function.
It simply stirs data in the pool weakly, counting on lots of entropy data
to make that OK.
This seems insecure to me, but I suppose there are probably reasons for the
Linux kernel to weakly mix the input entropy rather than performing a
secure hash.  If I were writing that code, I'd turn Blake2b into a sponge
(similar to Lyra2), and would only mix in entropy once I'd collected at
least 256 bits worth.  That way, the state becomes secure again on every
Can I use a simple hack to insure the Linux entropy is secure after every
write to /dev/random?  I am thinking of force-feeding it 4096 bits from the
Keccac sponge, rather than just 512 bits like I do now.  Is my reading of
random.c's mixing accurate?  Will this hack insure that the entropy pool is
securely refreshed?
Given that they write the entropy pool to disk on shutdown, instant
recovery from state compromise seems like an important goal.

@_date: 2014-10-27 13:09:54
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day: Turbid 
Turbid is a FOSS TRNG that generates high quality random data from a
system's sound card. It is free, and when calibrated correctly by an expert
with a sound card capable of reliably amplifying thermal noise, it
generates provable amounts of entropy. Being totally FOSS, it's 100%
auditable, making it one of the few decent choices out there for a good
TRNG, IMO.
 The Turbid paper is here:
  It discusses many important concepts in TRNGs, and is a excellent
contribution on it's own. It is easier to be a critic than an author of
good ideas, but my role here is pointing out the bad along with the good. I
applaud the authors for excellent work in general, but I do not consider
Turbid's approach of using a sound card as an entropy source to be a
particularly good idea for these reasons:
 - A sound card used by Turbid cannot be used for input, meaning most users
need a second sound card.
- Once a user is buying extra hardware for use as a TRNG, there is no
reason to use a sound card, when a TRNG designed for the purpose can do a
better job.
- Turbid needs to be calibrated for each type of sound card by an expert at
Turbid configuration. Given how few people there are who can do this
properly, availability of properly tuned Turbid installations will likely
remain low.
- ALSA has to be patched to ensure exclusive access to the mic input, so a
good sys-admin is also required.
 Given the difficulty of analyzing a system's sound card for potential for
producing entropy, it makes more sense, IMO, to use a dedicated hardware
TRNG, where the entropy can be proven once. In this case, using a sound
card is just one possible solution among many, and not my preferred
solution. A dedicated amplification of thermal noise in a carefully
designed and shielded circuit for this purpose would be better, for
example, than a random sound card which was not designed for generating
cryptographically secure random data. There are cheap A/D based TRNGs out
there that do exactly this, though I would go with a OneRNG or possibly an
Entropy Key before one of those. There is a *huge* number of threats to
consider, like whether a USB key can PWN your system, and sound card USB
keys simply aren't designed for security.
However, there is one good thing about Turbid vs custom TRNG harware.  As
IanG states, using a dedicated hardware TRNG is like having a "Kick me"
sign on your back.  That device is a prime target for attackers, while
buying a sound card at Best Buy would go unnoticed.  However, I would
prefer to rely on the security measures proposed by the OneRNG team than
trying to get a Turbid install right.
 Turbid is not the only system with an entropy lower bound proven by
physics. For example, my Infinite Noise Multiplier gives log2(K) bits of
entropy per output bit, even if the only noise is the resistors around the
op-amp. In contrast, Turbid requires a skilled analyst to determine the
lower bound of entropy for any given system.  TRNGs using zener noise have
trouble, but those amplifying thermal noise, which are also common,
generate easily provable entropy.  Those based on "A/D converter noise" are
common thermal entropy sources.
 The paper states:
 "It harvests entropy from physical processes, and uses that entropy
efficiently. The hash saturation principle is used to distill the data, so
that the output has virtually 100% entropy density. This is calculated from
the laws of physics, not just statistically estimated, and is provably
correct under mild assumptions."
 I particularly like their coverage of the hash saturation principle. This
is used by most TRNGs. This paper quantifies how many extra bits of entropy
are needed to saturate the entropy pool, and it is surprisingly few!  I use
2X the input entropy as hashed output data, which may be over-kill.
 Getting a system to work well with Turbid first requires a "good-quality"
sound card:
 "We start with a raw input, typically from a good-quality sound card."
 I would dispute ?good-quality? here. What they need is an A/D converter
with enough bits to digitize the thermal noise on the mic input. A 24-bit
A/D converter is simply a marketing tool, since the low 8-ish bits will be
random. That's not a ?good? sound card, IMO, probably just a waste of
money, but it is wonderful for use as a TRNG. A sensible 12-bit A/D mic
input probably is unusable with Turbid.
 Here's what they say in Apendix B about their assumptions:
 "Let C be a machine that endlessly emits symbols from some alphabet Z. We
assume the symbols are IID, that is, independent and identically
distributed. That means we can calculate things on a symbol-by-symbol
basis, without worrying about strings, the length of strings, or any of
that. Let PC(i) denote the probability of the ith symbol in the alphabet.
 Note: Nothing is ever exactly IID, but real soundcards are expected to be
very nearly IID. At the least, we can say that they are expected to have
very little memory. What we require for good random generation is a very
mild subset of what is required for good audio performance."
 I had difficulty reading their proofs with this invalid assumption that
samples are independent. They are not independent, or even close to
independent.  However, I read through the paper, and can see how the
arguments can be enhanced to deal with correlation between samples easily
enough.  Their conclusions seem sound to me, but the short-cut of this
assumption was cutting corners when they didn't have to.  It also set off
alarms in my head when I read it.  I read this assumption a while back, and
stopped reading the paper right there.  I didn't return to Turbid until
today, and if you had asked me about Turbid yesterday, I would have had
some uncomplimentary things to say about the author's making unrealistic
assumptions and "proving" things with them, just like a lot of snake-oil
TRNG manufacturers do.
 They also say:
 "We use no secret internal state and therefore require no seed, no
 This is touted as a strength when in fact it is a weakness. Turbid uses
SHA-1 to concentrate entropy and whiten it's output. If they were to use
the init/update/finalize interface, and make a copy of the state before
finalize, and use that copy for the next sample, they could carry entropy
from one SHA-1 application to the next, which would make their output to be
less predictable. Some inputs they pass to SHA-1 will be far more likely
than others, and because of this, the corresponding outputs will also be
more likely.
 They go on to say:
 "Best performance and maximally-trustworthy results depend on proper
calibration of the hardware. This needs to be done only once for each make
and model of hardware, but it really ought to be done. Turbid provides
extensive calibration features."
 I feel this is the single most important point about Turbid. So long as
someone skilled at the task calibrates Turbid for each revision of each
make and model of hardware, assuming it has a suitable sound input that
know one wants to use for inputting sound, it can be made as secure. How
often do systems have redundant sound inputs? How many skilled technicians
do we have seeking out these useless mic inputs for use with Turbid?
 In section 4, "surprisal" is discussed, but with the assumption that each
output symbol from the sound card is independent of the others, apparently
regardless of how fast the mic input is sampled, which is far from being
true. However, sampling fast will capture more of the available entropy, so
there's no harm in doing so. I would feel better about Turbid if they were
to estimate the entropy in the input, and compare this estimate to the
theoretical result, and show that there is a close match. I do this for my
INM, for example, and others do this for their TRNGs.  I build three of
them yesterday, and all three output measured entropy within 0.5% of the
model's prediction.  Turbin's theory is solid, but when a Turbid technician
goofs, it would be nice to catch the error.
 Sound outputs will be correlated when sampled at high speed. To help
correct for this short-term correlation, Turbid could keep the history of
the next sample given several previous samples. This would give a good
estimation of surprisal, allowing more accurate entropy estimation.  This
could then be compared to the predicted entropy.
 The paper states:
 "If there is some 60-cycle hum or other interference, even something
injected by an adversary, that cannot reduce the variability (except in
ultra-extreme cases)."
 This is the basic concept behind an Infinite Noise Multiplier, where
signals added by an attacker cannot reduce the entropy of the output. Many
other TRNGs also rely on this principle, and like Turbid, an attacker who
can inject a large enough signal can saturate the output, controlling the
bits produced.  This problem is worse in cheap zener-noise TRNGs, which
saturate easily, but with a 24-bit A/D, not much amplification is required
to sample thermal noise.
 They state:
 "We also need a few specialists who know how to tune a piano. Similarly,
we need a few specialists who understand in detail how turbid works.
Security requires attention to detail. It requires double-checking and
 "Understanding turbid requires some interdisciplinary skills. It requires
physics, analog electronics, and cryptography. If you are weak in one of
those areas, it could take you a year to catch up."
 This is the weakest point to Turbid, IMO.  Security needs to be easy to be
 As the paper states with the line-in example on a ThinkPad, if the
upstream gain times the expected thermal noise level given the presence of
capacitance to GND is less than 1 bit worth of input voltage on the A/D
converter, then most entropy will be lost. Other TRNG architectures do not
have such problems. Turbid is difficult to get right.
 Section 8.3 is titled, "Whitener Considered Unhelpful". This is just a
matter of semantics, IMO. I would call Turbid's output hash function a
whitener, so hearing them claim whiteners are not helpful seems strange to
me. Most people working on TRNGs would call Turbid's output hash a
whitener, I think.
 I would prefer a Blake2b rather than SHA-1 in Turbid, since it is faster
and more secure, and they should keep the internal state for the next
snippet of data to randomize the chances of any given output occurring,
rather than what they have now where some outputs are more likely than
 The health checks for Turbid sound weak, such as checking for bits stuck
at 1 or 0. In my INM driver, as well as drivers for OneRNG, Entropy Key,
and others,, entropy is statistically estimated, and if any sample fails,
it is disguarded, and if this continues for long enough, it stops all
 Here's a part in the paper I found very helpful:
 "A subtle type of improper reseeding or improper stretching (failure 3) is
pointed out in reference 22. If you have a source of entropy with a small
but nonzero rate, you may be tempted to stir the entropy into the internal
state of the PRNG as often as you can, whenever a small amount of entropy
(?S) becomes available. This alas leaves you open to a track-and-hold
attack. The problem is that if the adversaries had captured the previous
state, they can capture the new state with only 2?S work by brute-force
search, which is infinitesimal compared to brute-force capture of a new
state from scratch. So you ought to accumulate quite a few bits, and then
stir them in all at once (?quantized reseeding?). If the source of entropy
is very weak, this may lead to an unacceptable interval between reseedings,
which means, once again, that you may be in the market for a HRNG with
plenty of throughput, as described in this paper."
 This is why TRNGs should mix only a cryptographically strong entropy
sample at a time into /dev/random. 256 bits at a time should do the trick.
They also said:
 "Therefore in some sense /dev/urandom can be considered a stretched random
generator, but it has the nasty property of using up all the available
entropy from /dev/random before it starts doing any stretching. Therefore
pool entropy goes to zero, every byte read from either /dev/random or
to read modest amounts of high-grade randomness from /dev/random cannot
coexist with programs reading large amounts of lesser-grade randomness from
paper is much better behaved, in that it doesn?t gobble up more entropy
than it needs."
 Linux (at least Ubuntu 14.04) let's users read from /dev/random if only 64
bits of entropy exist in the pool, meaning if an attacker knows the state
when the pool is at 0, he can guess your keys read from /dev/random in 2^64
guesses. I guess in real life that's a lot, but I think this makes it
harder than need be to reseed the Linux pool when compromised.
Force-feeding the entropy pool >= 4096 bits *might* be good enough... not
100% sure. Why isn't the lower limit something stronger, like 160 bits or
 The paper states:
 "The least-fundamental threats are probably the most important in
practice. As an example in this category, consider the possibility that the
generator is running on a multiuser machine, and some user might
(inadvertently or otherwise) change the mixer gain. To prevent this, we
went to a lot of trouble to patch the ALSA system so that we can open the
mixer device in ?exclusive? mode, so that nobody else can write to it."
 Instructions are provided for patching ALSA. However, until those patches
are main-stream, users of Turbid will also need to be good at system
 Turbid violates my KISS rule. Security this complex isn't secure.
 All that said, I think their paper is outstanding, and I benefited
substantially from reading it. I just don't expect to set up a Turbid
installation any time soon.  It *is* excellent work, however, and it
advanced the state of the art so far as I know it (which is limited) a ton.
 Bill

@_date: 2014-10-27 19:55:57
@_author: Bill Cox 
@_subject: [Cryptography] In search of random numbers 
I'm not sure we can't just have all our IoT devices have their own TRNG.
It's hard to trust an unauditable TRNG in someone else's IC, but if it's my
custom ASIC I design or even just an FPGA, it's easy to trust the TRNG
design you drop in, so long is it isn't rocket science to get right.  Ring
oscillator noise sounds like a decent candidate, though for even smaller
size and higher speed with predictable entropy output, I prefer an infinite
noise multiplier.  For board level designs, there should be a $0.25 highly
auditable TRNG chip you can buy that just spits out 0's and 1's when
clocked.  If they go into many designs, we can tear down enough of them
chosen at random to show that at at most only a small percentage of them
are back-doored.

@_date: 2014-10-27 21:46:19
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day: Turbid 
Some TRNGs also require no additional driver (like the one I'm working
on).  If you use a well accepted USB interface chip, you don't need one.
Turbid ideally uses a 24-bit sound card, though a 16-bit might work.  I see
a Creative Labs Sound Blaster 24-bit audio card at New Egg.  Is this the
sort of card recommended?
This is inaccurate.  White noise with energy in every frequency would have
infinite energy and destroy the universe.  Thank goodness for quantum
mechanics!  All white noise rolls off somewhere.  In this application, I
believe the frequency of interest is the cutoff frequency of the
anti-aliasing filter, which is somewhat lower than 1/2 the sample rate
(Niquist frequency).  That gives you a decent thermal noise estimate.
If you sample at the maximum supported sample frequency, you will do a
better job capturing the entropy that is there, but sampling at a rate
beyond the anti-aliasing filter cut-off frequency insures successive
samples are highly correlated, violating the Turbid paper's assumptions.
However, the results are still valid, if they correct for short-term
correlations, which can be done easily.
Let's use Turbid's definition of entropy (which happens to agree with mine
- what are the odds?).  Entropy is the expected "surprise" (a good word by
the way...) in a snippet of samples.  Surprise is log2(1/probability of
snippet occurring).  I wrote this exact equation a few days ago in my
entropy estimator code before reading the Turbid paper.
The correlation I am concerned about here is correlation that normally
exists between successive samples from the sound card, which can be quite
high if you are sampling faster than the anti-aliasing cut-off frequency.
However, drop a decade in frequency and the correlation is likely
negligible.  This can be done easily by sampling 10X less frequently, at
the cost of losing most of the entropy available in the sound stream.
Alternatively, we can estimate the surprise in each sample based on prior
history, and adaptively tune our entropy estimator.  A linear predictive
code based surprise estimator would work OK, though it would be optimistic
about the level of surprise in each sample.
In my TRNG, I have a 1-bit output, which lets me have a table of
probabilities of the next bit being a 1 or 0 based on the prior 14
outputs.  This enables me to eliminate all but a small fraction of the
nearby sample correlations from my entropy estimate.  The entropy estimator
matches the expected entropy of log2(K) to within 0.5% on the first three
boards I built (which I built yesterday - see
github/waywardgeek/infnoise).  The health monitor kills the process if
estimated entropy drops below predicted entropy by more than 5%.
Turbid, from what I read in the paper, does not adaptively estimate
entropy, which makes it's health monitor fairly weak, IMO.  Instead it
requires hand testing of the sound system to come up with a good entropy
estimate, which is then set for all time.  Is this right?  Is there any
adaptation at all?
Even if someone put my TRNG in a cryogenic freezer, it's entropy estimator
would adapt, and it would kill the process when it dropped more than 5%
below expected entropy.  However, because I effectively compress so many
bits of thermal noise together while it's still an analog voltage (about 15
bits in the first design), the temperature required to get a 2X drop in
entropy would be on the order of 293K/2^28.  This would drop the noise
voltage by 2^14, leaving only about 1 bit of noise in for every bit of
entropy out,
system.  I'm basically still a noob at ALSA, but whatever I've tried seemed
to require shot-gunning many different possible API call sequences to see
what combination does what I need.
This is another reason I am reluctant to use the ALSA sound system as an
entropy source that I count on.  How many of us can dabble in ALSA, and
understand thermal noise well enough to estimate accurately the noise that
must be there?  Now, adding it to the pool is a good thing, just like
adding entropy from RDRAND, but I think both should be set to add nothing
to the pool's entropy level.  That way, I don't have to worry about all the
mistakes I make all the time (like the ones I'm sure I made above).

@_date: 2014-10-29 07:13:48
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day: Turbid 
Duh... I was thinking of SAR ADCs, which would never go to 24 bits.  Of
course they're sigma-deltas.  The external filter is what I normally hear
called the anti-aliasing filter, even for SD-ADCs, but it's cut-off can be
much higher than the decimation filter's cut-off, so it is irrelevant for
calculation of thermal noise.  In that case it's the decimation filter
cut-off that counts.  That's typically 2X the highest audio frequency of
interest, isn't it?
There will still be significant correlation between samples.  There is
thermal noise in a band from 9X to 10X below the sample rate which will
turn into a significant short-term correlation between samples 10 away from
each other.  It's not a big deal, since the math works anyway, but it's
It should at least do some basic tests...

@_date: 2014-10-29 09:22:26
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day: Turbid 
Not in my experience, but that is somewhat limited.  A simple test would be
seeing if the zero crossings are correlated between adjacent samples.  My
guess is they are highly correlated, as in I have a 70% chance of guessing
if your next sample is greater or less than zero if you tell me the full
value of the previous sample.  If you send me some typical Turbid maximum
sample rate sound samples, I'd be happy to do that test.
However, this does not invalidate Turbid's entropy estimate in any way.
Feeding every sample, even if there is some correlation, into the hash
function is the right thing to do to collect all that entropy.

@_date: 2014-10-29 09:34:08
@_author: Bill Cox 
@_subject: [Cryptography] In search of random numbers 
I completely agree.  Make it so cheap and easy that every IoT device just
does it.
By the time IoT devices are in every home, we'd see these selling for $0.05
in decent volume.  However, any company building them early on is going to
want a decent ROI, and they'll sink maybe $500K into such a project ($200K
in NRE, an engineer for a year at $200K (design, test, packaging,
reliability - several engineers, but for only a part of a year), marketing,
stocking distributors, G&A...
It is hard to get lower than that $0.05 number because the fab wants $0.05
for the silicon, the packaging house wants $0.05 for the package, and the
test house wants $0.05 for test.  Getting them all to be reasonable and
make a small profit at the same time is hard!

@_date: 2014-10-29 17:24:31
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day: Turbid 
Good points.  I suppose Linux distros should look at borrowing the mic
input for a fraction of a second on boot to refresh the entropy pool.

@_date: 2014-10-29 19:42:19
@_author: Bill Cox 
@_subject: [Cryptography] A TRNG review per day: Turbid 
In this case, it sounds like we're in complete agreement.  This is what
*should* happen.  Turbid is doing the right thing.
I'll dive into this in the morning, though I expect to find what you
found.  Again, I am a fan of the the models the Turbid authors put
forward.  I don't know if they coined the term "surprise", but I don't know
how to measure entropy in a sample without it.

@_date: 2014-09-20 22:46:29
@_author: Bill Cox 
@_subject: [Cryptography] The world's most secure TRNG 
This is a shameless promotion of a dumb I idea I had a while back, the
Infinite Noise Multiplier.  I thought it was cool because it's fast
and simple and easy to integrate on an ASIC, but now that I've become
more of a tin-foil-hat geek, I see that it is in fact the architecture
I prefer for all my true random data.  However... it's only for those
of us who are silly paranoid.
I am building a board-level proof-of-concept, and it uses only a dual
op-amp chip and an dual SPDT switch chip, plus a few caps and
resistors.  It is very simple on a board, and runs way faster than
typical zener noise solutions.
What makes it more secure than other reasonable-speed reasonable-cost
architectures is that it is immune to signal injection.  If you use
zener avalanche noise, for example, or Intel's very cool random
power-up latch state, you are hugely sensitive to signal injection.
These schemes amplify a signal from almost 0V to measurable input
signals.  Any signal-injection attack will dominate over the true
random noise and send the user the attacker's desired data instead.
With an Infinite Noise Multiplier, injected signals simply flip
otherwise random bits of state, which makes them no less random.
So, in case anyone wants to use this, the original idea is at
waywardgee.net.  I hereby renounce any claim to copyrights and patents
related to this project.  I'm giving it away emphatically freely.
I'm working on a board level version over on Upverter.  If there's
interest, I'll post that when it's ready.

@_date: 2014-09-28 07:27:57
@_author: Bill Cox 
@_subject: [Cryptography] The world's most secure TRNG 
I have a quick question for you guys.  For a USB stick TRNG, would you
rather pay ~$15 for a 100K-byte/second source of true entropy, or ~$30 for
a 1M-byte/second source?
I am currently designing a USB stick version of an INM to promote the
architecture.  I plan to offer them for sale for what it costs me to build
them, which in low volume I expect to be around $15 to $30 depending on the
speed target.  Schematics, board layout, and BOM will be made
public-domain.  Current my target spec is 1MiB/second (mega-byte, not bit),
over USB 2.0, but some of the high-performance parts are expensive
(high-speed buffer, comparator, op-amp, and analog switch).  Just using a
jelly-bean quad op-amp is super-cheap, but 20X slower.
The jelly-bean op-amp based versions are available on github, with LTspice
schematics and sims:
It's cheap, comparatively fast, and unlike other TRNGs, it's easy to get
right.  It is 10X more fool-proof than any other TRNG I know of, simply
because of it's near immunity to signal injection, power supply noise,
cross-talk, etc.  No shielding is required, and the power supply can be
noisy.  No care needs to be taken with cross-talk between traces.
Attackers are welcome to inject strong signals into this TRNG, which simply
results in enhancing entropy, rather than subverting it.  It turns out that
attackers make a nice source of entropy, and INMs add all sources, without
letting any saturate the signal.
Basically, TRNGs today generally amplify a noise source until it saturates
to a 0 or 1.  Such systems are *very* hard to get right because they are so
sensitive to external noise.  The right way to amplify the noise source is
with modular multiplication rather than saturating multiplication. It is as
simple as that.
There is some analysis on that page, and test-code to verify that the level
of entropy shifted out per bit, when the loop amplification is A, is:
    E = log(A)/log(2)
For example, when using a gain of sqrt(2), rather than 2, each bit shifted
out contributes 1/2 bit to the entropy pool.  I've written code to test the
entropy of INM output, and measurements on simulation data closely match
this equation.
At least for the most sensitive cryptography, I think we should stop using
zener noise, oscillator jitter, latch power-up state, and other TRNG
architectures that are highly sensitive to noise that could be controlled
by an attacker, and which are too hard for regular guys to get right on a

@_date: 2014-09-29 07:32:53
@_author: Bill Cox 
@_subject: [Cryptography] The world's most secure TRNG 
Thanks for all the feedback.  I get the main point: cheaper is better.  On
that note, I'm tempted to start with a DigiSpark, and add the cheapest
possible infinite noise multiplier.
As for theory, it's simple: use *modular* multiplication when amplifying
noise, rather than saturating multiplication.  It really is as simple as
Any TRNG that amplifies noise to saturation, like all zener-noise devices,
are highly sensitive to external noise, RF, etc.  This is because the
amplifiers saturate when they hit the rails.  If an attacker can inject
even a few microvolts, he can likely control the output.
By using modular analog multiplication, the outputs wrap around and never
saturate.  The zener or thermal noise can still be amplified enough to be
detected, but an attacker loses the ability to control the output.

@_date: 2014-09-29 08:15:17
@_author: Bill Cox 
@_subject: [Cryptography] The world's most secure TRNG 
One more question, though I think I know the answer, based on "cheap" is
the  goal:
I'm using the cheapest FPGA available: a $2 Lattice ICE part with 384
LUT/Flops.  This is more than enough for interfacing to the USB fifo, but
not enough to whiten the signal with cryptographic secrity.  I know I need
to provide the raw signal without whitening - that can be done in
software.  However, is there any value in also incorporating a Keccak
sponge so that whitening can be done on the USB stick?  This would probably
require a $4 or $5 FPGA.

@_date: 2014-09-30 15:58:46
@_author: Bill Cox 
@_subject: [Cryptography] The world's most secure TRNG 
Thanks for that suggestion.  I'll whiten with some of the leftover gates.
How to do a decent job sounds like a fun problem.
Will do!  I'll have the default power-on state be to whiten, while there
will be a simple value you write to the USB port to toggle whitening.
Allow the user to verify that the whitener follows the specification by
What's worse, IMO, is that they claim an audit mode exists, and is used in
debug and also during device testing, but they wont let us know how to
activate it.

@_date: 2015-04-24 15:59:51
@_author: Bill Cox 
@_subject: [Cryptography] Entropy is forever ... 
I use surprise as described in this document:
    It says:
"Following Solomonoff (reference 33 and reference 34) and Chaitin
(reference 35) we quantify the surprisal of a string of symbols as follows:
    Let z be a string of symbols. The elements of z are denoted zk and are
drawn from some alphabet Z. The number of symbols in the alphabet is
denoted     Let PC(z) be the probability that computer programs, when run on a
given computer C, will print z and then halt. The surprisal is defined to
be the negative logarithm of this probability, denoted $C(z) := ? logPC(z).
In this paper we choose to use base-2 logarithms, so that surprisal is
measured in bits. Surprisal is also known as the surprise value or
equivalently the unexpectedness. It is intimately related to entropy, as
discussed below."
It's the best paper I've found on making practical use of thermal noise to
build a TRNG.  The specific case of using a 24-bit A/D converter, where we
know the low bits are actually random, seems a bit hackish to me, but the
concepts presented about random number generation generally are excellent.
Sounds good to me :-)
I think Turbid is the main source of this term as it's used to describe
true random number generators.  When I say entropy in statements like how
many "bits of entropy" are output by my "Infinite Noise Multiplier" device,
I mean how many bits of surprisal, as defined in the Turbid paper.  It
directly represents an attacker's probability of guessing the state, which
is perfect for security proofs.

@_date: 2015-04-24 16:12:38
@_author: Bill Cox 
@_subject: [Cryptography] Entropy is forever ... 
Here's a good Turbid quote:
"Let?s be clear: The surprisal is a property of the symbol, while the
entropy is a property of the source. In particular, the entropy is the
appropriately-weighted average surprisal.
For a long string, we expect the surprisal of the string to converge to the
entropy of the source times the length of the string.
Beware: In the literature it is common to see the word ?entropy? used in
places where surprisal would make more sense. In particular, the code and
documentation for the Linux /dev/random talks about depleting the ?entropy?
in its buffer."
We can't fix how everyone else uses the word entropy.  Linux has an entropy
pool... end of story.  However, we can be more clear in our discussions of
TRNGs, randomness, and entropy.  In common usage, it is simpler to say
entropy, because no one knows what you're talking about if you say
surprisal :-)

@_date: 2015-08-02 06:17:44
@_author: Bill Cox 
@_subject: [Cryptography] asymmetric attacks on crypto-protocols - the 
I think it is possible to defend against this attack, but it is difficult.
An attacker will likely assume multiple fake identities, join the group
multiple times, and amplify his attack.  To defend against this, you want
to use real identities, preferably backed up by getting to know people by
voice in group voice meetings.  The better you get to know the people you
deal with, the harder it becomes for a shill to do real damage.
Another defense is to call a guy out as a potential shill when you suspect
it.  If the attacker is keen on not being discovered, they'll stop being
disruptive.  On the other hand, this can backfire - calling a natural born
a-hole a shill does not discourage his bad behavior in my experience :)
Maybe I'm too paranoid, but I have felt in multiple situations that a
security-related discussion might be under a rough-consensus attack by a
shill. For example, when discussing the possibility of switching from SHA1
to SHA256 for BitTorrent, some guy got so obnoxious and irrational that it
killed the discussion.  An attacker who can break SHA1 at will can do nasty
things to torrents.
The sorry state of a lot of our FOSS security might be due to this attack.
We probably should make effort to defend against it.  In short, don't let
anonymous a-holes disrupt security discussions.  Security requires real
people working together.

@_date: 2015-08-02 06:41:54
@_author: Bill Cox 
@_subject: [Cryptography] asymmetric attacks on crypto-protocols - the 
Re-reading your post, I see you're talking about a dedicated attacker who
is a real person everyone already knows.  This isn't some small change,
like switching from SHA1 in BitTorrent to SHA256 that you might discuss
anonymously.  You're talking about securing data important enough for a
government to plant a real person on a committee to disrupt it.
In this case, I think you are right to drop rough consensus.  Just go build
it, and don't let anyone get in your way.  Strong leadership is a good
defense in this case.

@_date: 2015-08-12 18:12:13
@_author: Bill Cox 
@_subject: [Cryptography] Why is ECC secure? 
I took my geometry based attack further today and found some things I think
are very cool.  In particular, in an Edwards curve with negative d
(squished circle, not fat one), I set z = -sqrt(d)xy, so that the Edwards
curve points map onto the unit sphere.  I found that when I add a small
delta (like the point (0.0001, ~0), then measure the distance traversed on
the sphere, it is always equal no matter what point I start from, once I
divide by 1/sqrt(x^2 + y^2).
I computed the line integral on the sphere from the Edwards curve origin
(0, 1, 0) to an arbitrary point using Wolfram's awesome integration
toolkit.  It resulted in a closed form solution, but unfortunately involves
an Elliptic integral.  This was the only part that I can't compute using
modular arithmetic.  Had it resulted in an equation that was modular
arithmetic friendly, I think that might result in a significant break of
elliptic curve crypto that can be mapped to Edwards curves.
The idea would have been to find the modular distance from the origin of
the generator point, and also of the user's publiic key point.  At that
point, I think we've mapped the problem to regular modular arithmetic in
one variable.  But... it didn't work.  Was fun, though :)
I used Wolfram to evaluate the path integral for several multiples of the
generator point, and indeed, they are clearly multiples of a constant.

@_date: 2015-08-13 08:29:13
@_author: Bill Cox 
@_subject: [Cryptography] Why is ECC secure? 
Just for completeness, here's my notes on the math:
x^2 + y^2 = 1 + dx^2y^2
Define a curve C as follows:
let z' = -sqrt(d)xy
x^2 + y^2 + z^2 = 1
So, it is the unit sphere.
Let (0, 1, 0) be the origin point on the curve
C is a path inscribed on a unit sphere with a cool property.  Any point on
the Edwards curve corresponds to a point on C and can be trivially computed
using modular arithmetic.  Edwards curve addition is equivalent adding the
lengths from the origin to the two points on the sphere, weighted by a
simple weighting factor.  The weight is 1/|(x, y)|.  If the length,
computed in modular arithmetic, of both the generator and public key point
are known, then computing the discrete log can be done using regular
techniques such as index calculus.
If this where to happen, the strength of Edwards curve compatible EC crypto
would plummet, as we typically only use 256 bits in EC, while we need more
like 2048 bit to defend against index calculus.
So, can we find the line integral from the origin to (x, y, z) given x and
y using modular arithmetic?
y = sqrt((1 - x^2)/(1 + x^2))
         = sqrt((x^4 + 1)/(x^2 + 1))
z = xy = x*sqrt((1 - x^2)/(1 + x^2))
x' = 1
y' = -(2 x)/(Sqrt[(1 - x^2)/(1 + x^2)] (1 + x^2)^2)
z' = (-x^4-2 x^2+1)/(sqrt((1-x^2)/(x^2+1)) (x^2+1)^2)
integrate sqrt(x'^2 + y'^2 + z'^2)/sqrt(x^2 + y^2)
 = sqrt(1 + ((2 x)/(Sqrt[(1 - x^2)/(1 + x^2)] (1 + x^2)^2))^2 + ((-x^4-2
x^2+1)/(sqrt((1-x^2)/(x^2+1)) (x^2+1)^2))^2)/sqrt((x^4 + 1)/(x^2 + 1))
Plugging the above into Wolfram's integral calculator results in:
= (Sqrt[2 - 2 x^4] Sqrt[-((1 + x^4)/((-1 + x^2) (1 + x^2)^2))]
EllipticF[ArcSin[x], -1])/Sqrt[(1 + x^4)/(1 + x^2)]
The ArcSin and especially the EllipticF are functions that I don't know how
to compute using modular arithmetic.  There are various modular-arithmetic
friendly infinite series expansions.  Are there any where we can reduce to
a reasonable finite equation using modular arithmetic?

@_date: 2015-08-13 10:34:59
@_author: Bill Cox 
@_subject: [Cryptography] Why is ECC secure? 
I simplified some of the math above.  For d == -1 (it's only slightly more
complex for d != 1), the equation to integrate in the path from the origin
to the elliptic curve point simplifies to:
    sqrt(2)/sqrt(1 - x^4)
The line integral simplifies to:
    Sqrt[2] EllipticF[ArcSin[x], -1]
Evaluating this equation at the first four points where the generator has x
= 0.4:
path integral over 0 .. 1 = 1.85407, which is Sqrt[2] EllipticK[-1]
x               y               path integral ratio
0.4             0.8509629434    0.567149
0.7699820705 0.5252257314 1.1343       2.0000035264
0.9884198756 0.1079220526 1.70145       3.0000052896
0.9175950827 -0.2928953491 2.26859       3.9999894208
Now, if I could just figure out how to evaluate
sqrt(2)*EllipticF(arcsin(x), -1) mod p :)

@_date: 2015-08-14 06:46:12
@_author: Bill Cox 
@_subject: [Cryptography] Why is ECC secure? 
The power of visualization seems to be under-rated in group theory :)
Not only does all this work, it gives me a way to create new additive
groups easily, which is something I've wanted to know how to do for a while
now.  For example, here's a group I just came up with using this line
integral stuff:
a @ b  = sqrt(((4a^2 + 1)^(3/2) + (4b^2 + 1)^(3/2))^(2/3) - 1)/2
Plug it into a spread sheet, and you'll see it works.  I created it by
doing the line integral of 12x over the curve y = x^2.  If the line
integral is called L(x), then the addition rule is simply Linv(L(a) +
L(b)).  I'm not sure if the cube-root is friendly modulo a prime, but if it
is, we could probably use this to do crypto :)
We can create groups on path or function using this technique.  The unit
circle group is the simplest case, where point multiplication is simply
angle addition.

@_date: 2015-08-14 09:35:09
@_author: Bill Cox 
@_subject: [Cryptography] Why is ECC secure? 
Duh... any operator of the form Finv(F(a) + F(b)) forms a group.  It is
associative and commutative.  The identity element is Finv(0).  The inverse
of x is Finv(-F(x)).  I really would have enjoyed the class where they
teach this :)

@_date: 2015-08-14 12:15:00
@_author: Bill Cox 
@_subject: [Cryptography] Why is ECC secure? 
Actually, there's a sad story here.  I love group theory.  However, in the
class I took at Berkeley on intro group theory, they allowed a prof who had
recently had a stroke teach it, but the guy had lost all of his
mathematical ability.  So... we all failed the final, and the math
department gave us all A's anyway.  I was unable to continue with the
second course since I had learned nothing from the first.  So, all I have
now is a Wikipedia level of knowledge of group theory.
Anyway, I had fun this morning coming up with all sorts of group addition
laws of the form Finv(F(a) + F(b)).  Here's one of the simplest:
  let F(x) = 1/x for x != 0, and 0 for x = 0
  Finv(x)  = 1/x for x != 0, and 0 for x = 0
  Addition rule: 1/(1/a + 1/b), or 0 if a == 0, b == 0, or 1/a + 1/b == 0
We need a "0" element, which is why we need F(0) = 0.  Now check for
  inv(a) = Finv(-F(a)) = 1/(-1/a) = -a
We can define this on the open interval (-1, 1), which excludes 1, and -1,
which map to themselves, which would cause problems.  This seems to satisfy
the definition of a group.
To make it faster for modular arithmetic, we only have to do the modular
inverse at end of computation if we track numerator/denominator separately:
an/ad @ bn/bd = 1/(ad/an + bd/bn) = 1/((ad*bn + an*bd)/(an*bn) =
an*bn/(ad*bn + an*bd)
This is only 3 multiplications and one addition per group operation, which
I think is quite a bit faster than Edwards curve performance with
protective coords.  Have simpler groups like this one been broken?  I'm
trying to get my head around why we need the full complexity of elliptic
curve crypto to get the security we need, and understanding weaknesses in
this system and why such weaknesses are not in regular elliptic crypto
would give me some more confidence in elliptic crypto.
I wrote some simple Python code to implement it, which is attached.  An
interesting property in this group is that anything multiplied (not added)
by itself is 1.  One way to think of it is that the group operation is
putting n resistors in parallel, and the result is the resistance of the
parallel structure.  Are there standard attacks I can try against it?

@_date: 2015-08-16 17:56:19
@_author: Bill Cox 
@_subject: [Cryptography] Why is ECC secure? 
I just realized what is either an obvious attack against the circle group -
probably the usual attack, or maybe I'm making a mistake.  In short,
represent the group generator g as a 2x2 rotation matrix.  In computing
m*g, we just raise the matrix to the power of m and multiply it by (1, 0).
This is simple linear matrix based crypto.  This has been shown to be
equivalent to regular DLP.  You take the characteristic equation of the
matrix, and using this compute an equivalent regular DLP problem with some
polynomial manipulation magic.
This is good news to me for the security of elliptic curve crypto.  My fear
was that we simply have not yet figured out how to do invsin(x) mod p.  If
we did, we'd reduce the circle group to a regular additive group with zero
bits of security.  Showing it is equivalent to regular DLP means that we
can never invert arcsin mod p, at least not in less effort than it would
take to solve DLP.  This inverse is well defined once you scale the circle.
The reason I care about the security of elliptic curves is that I'm now in
a group at Google that is working on Token Binding, and we have to pick a
default prefered encryption mode.  It is not the end of the world if Token
Binding gets broken, and we have the flexibility to switch, but pretty much
any crypto decision made at Google impacts a billion people.
In particular, we're leaning towards P256 as the default.  What do we know
about this curve?  Should there be any concern that there may be a back
door of any kind?  For example, what happens if the prime modulus minus 1
has factors that are only known to the NSA?  What if they are purposely
small?  Do we know enough about P256 to know this sort of thing is not the

@_date: 2015-08-18 08:36:58
@_author: Bill Cox 
@_subject: [Cryptography] Why is ECC secure? 
I think I'm finally getting the basics of why we like elliptic curve
crypto.  Here's my attempt to explain it in regular English.
These are curves such that they fit into this form:
    a @ b = Finv(F(a) + F(b))
The @ is the group "addition" operator and the + is some group operation,
likely addition or multiplication.  In the case of Edwards elliptic curves,
F(a) is a line integral along a path on the unit sphere.
These would all be trivially broken except:
1) F(a) is a transcendental function, with no modular arithmetic equivalent
2) Finv(F(a) + F(b)) is algebraic
This means we can easily compute the result, but not the magic in the
middle, where we're doing addition or multiplication on the transcendental
In elliptic curve crypto, during DH key agreement, Alice publishes
Finv(am*F(g)) mod p, where am is Alice's secret and g is the group
generator.  If we could compute Finv(x) mod p, Alice's secret would be
It's a rare function that fits in this form and is algebraic when built
with a transcendental function F.  The circle group is in this form, when F
= arcsin(x).  It turns out that:
    sin(arcsin(x1) + arcsin(x2)) = x1x2 - y1y2
    where y1 = sqrt(1 - x1^2), and y2 = sqrt(1 - x2*2)
If this weren't the same as simple matrix multiplication, we might have
trouble analyzing it, but it is, and we can convert this easily to regular
DLP.  So, naturally, we want to know what functions are in this form but
are not equivalent to some well understood linear system.  Elliptic curves
seem to fit the bill.
In unrelated noodling...
I was trying to figure out what the NSA could possibly hide in a random
looking group seed.  It might be the case that they know the original
arithmetic representation of the group seed on the curve, and no one else
If I were attacking either the circle group or any Edwards curve, and I
knew the generator's original arithmetic (x, y) position on the curve, and
if I could find an arithmetic point on the curve which is in the group and
maps to Alice's public key point, then it becomes trivial to reveal Alice's
secret.  Could it be helful to know the arithmetic representation of g on
the curve to map Alice's pubic key to such a point?
I think we've shown that finding such a point in the circle group is
equivalent to DLP, since I can convert the circle group problem into
regular DLP, and find the multiple of g that generates Alice's pubic key
point.  So, using DLP, I can find the arithmetic point on the curve.  If
instead, I were given an arithmetic representation (it would be a big
operator tree corresponding to the multiplication of g by am), I can easily
find am just by doing line integrals to am and dividing by the line
integral to g.
Therefore, on the circle group mapping a public key point to an arithmetic
point in the group on the circle is equivalent to DLP.  We can pose the
same problem for Edwards curves.  If we can map Alice's public key point to
an arithmetic representation of the point on the curve that is in the
group, then we can trivially reveal Alice's secret.  This problem is
equivalent to finding Alice's secret on Edwards curves.
Would knowing the arithmetic representation for g help?  I it might...
That's the only potential use for obscuring the original point that I can
think of...

@_date: 2015-08-28 10:00:14
@_author: Bill Cox 
@_subject: [Cryptography] AES Broken? 
I liked this part.  They estimate the "security" of AES at:
with 2^127 precomputation.
Is there any reason for stating a shot-in-the-dark security guess to 42
significant digits?
Anyway, the method used in AES to generate the S-boxes are a bit scary in
the first place.

@_date: 2015-12-01 12:57:34
@_author: Bill Cox 
@_subject: [Cryptography] Large companies sued for using Elliptic Curve 
These claims all rely on generating a "random" secret using "system
parameters".  The term only appears in the claims, not the text, which is a
problem for the claims, since they must be clearly understandable from the
patent body.  The patent body talks about specific methods for generating
"random" secrets only in the context of key escrow, which no one does (or
at least they don't admit it).
However, patent trolls like this are in it not to win, but to get a small
payment from a zillion companies that would rather pay the small amount
than go to trial, potentially costing ~$1M or more.  They seem to have not
bothered suing companies known for fighting patent trolls.  This is a basic
shakedown, IMO.
Man, our patent system bites.

@_date: 2015-12-07 21:57:44
@_author: Bill Cox 
@_subject: [Cryptography] Opinions on signatures algorithms for 
OK, since you're asking the high-noise crypto list for opinions, I'll offer
my high-noise $0.02.
I read the pseudo-code for NTRU.  I have not attacked this problem enough
to get a feel for it, but my dumb arm-chair crypto knee-jerk reaction is
that it is a bit scary.  There are plenty of NP-complete problems where it
is difficult to state an instance that is hard to solve, such as graph
isomorphism.  This particular NP-complete problem looks harder, but I am
Multi-variate quadratics worry me even more.  Also, the mqqsig256 algorithm
needs 789552 bytes for it's public key, which seems like a non-starter.
So, I'm back to hoping that NTRU or a similar algorithm will pan out.  At
some point I need to waste a few weeks attacking it to convince myself that
it's core problem is likely difficult enough.  I'm not nearly as good at
this as a bunch of skilled cryptographers, but a person flaw I have is that
I don't trust anyone else to do the analysis.  I see security flaws
everywhere I look.

@_date: 2015-12-13 11:48:23
@_author: Bill Cox 
@_subject: [Cryptography] Photon beam splitters for "true" random number 
If I understand their technology correctly, this company has been selling
them for years

@_date: 2015-12-16 00:53:04
@_author: Bill Cox 
@_subject: [Cryptography] Photon beam splitters for "true" random number 
I'm the dork making them by hand in SF :)  It's just a fun hobby.  I'll
make 10 more soon...
As you found, OneRNG is open-source and open-hardware.  I strongly
recommend it for nearly all applications.  Coupled with a solid CPRNG, it
generates all the cryptographically secure key data you will ever need.
Being fully open-source is extremely important for a TRNG.  NeuG
 should get an
honorable mention here.  However, the engineering and theory behind OneRNG
is stronger, and OneRNG includes the schematics and board layout, and even
a bill-of-materials if I remember correctly.
A more popular alternative is TrueRNG
but even though the creator promised to make his code and schematics open
source, he never delivered.  We simply don't know if it is any good.
Back to this thread: The beam splitter is cool :)  An open-hardware version
would be a welcome development, IMO.

@_date: 2015-12-16 11:55:31
@_author: Bill Cox 
@_subject: [Cryptography] What should I put in notifications to NSA? 
I don't think requiring registration of open-source crypto violates our
constitutional rights, but I know this is debatable.  I'd just comply with
the law and send a simple email.
That said, I think I wrote a whole editorial piece in my last email like
this :)

@_date: 2015-12-17 09:30:22
@_author: Bill Cox 
@_subject: [Cryptography] Photon beam splitters for "true" random number 
It is possible no one replied because I am WaywardGeek, and I'm on this
thread.  That's too bad, because I would love to hear opinions on my TRNG,
especially negative ones.  I'd love to hear about the flashing red lights
:)  Don't worry, I have thick skin and take negative feedback well.
There are some negatives that I know about.  In particular, no EMI
shielding means a nearby radio might determine the 0's and 1's from the
device.  One user concerned about this wrapped it with aluminum foil, and
used the extra shrink-wrap over the tin-foil, but I like to see the board
and choose to live with the EMI risk.  Another issue is the architecture is
new, and not time-proven.  For stronger protection, consider the OneRNG.
It is my current favorite for production needs.  I actually carry this one
in my pocket, so I prefer its smaller form factor.  However, only a
ridiculous geek would carry one of these in their pockets :)

@_date: 2015-12-28 08:24:12
@_author: Bill Cox 
@_subject: [Cryptography] Photon beam splitters for "true" random number 
Very cool!
In the game above, if one attacker could see all the random numbers from
the other people before committing to their own random number, the attacker
could simply submit the XOR of the other random values, then XORed with the
value the attacker desires to be the seed to the hash function.
Your scheme of concatenation, then feeding into a cryptographically strong
hash algorithm, seems to defeat this attack.  What if the attacker hacks
the hash algorithm on the air-gapped computer?  The nice part about the
simple 1-page C program concept is the result could theoretically be
manually verified.  On the other hand, do we really want all the
participants looking at the resulting seed, or should it be kept secret?
Fun stuff.  I guess at some point we just have to accept some level of risk
and move on.

@_date: 2015-12-31 10:01:17
@_author: Bill Cox 
@_subject: [Cryptography] Nu supr unbrakable cripto 
We see these posted on this list often, to the annoyance of some, but to
some of us they are fun to analyze and crack.  If you are one of the
readers who find this annoying, please skip this thread.
On this post, I just want to demonstrate to those of us who are not crypto
experts what real crypto people already know: that making unbreakable
symetric key crypto is trivial.  Any decent crypto hacker should be able to
do it.  While making an unbreakable symmetric key algorithm is trivial, it
is very difficult to design one that is _useful_.  It also turns out to be
very hard to get all the details right, such as counter-mode
encrypt-then-mac, and implementing side-channel resistance.  Further, it is
extremely difficult to design a new useful public key crypto system, which
I wont even touch here.
Feel free to try an crack this new algorithm.  More likely than not, I made
at least one mistake for you to catch :)
The basic strategy is to create a crypto grade hash function, and then turn
that into a crypto-grade symmetric-key encryption algorithm.  Let's call
this new hash function H, and the new encryption algorithm E.  E will be a
block-based cipher.  The key will be 256 bits and the data will be 512
bits.  H will take a "key" and "data", both 256 bits, and in theory return
a "compressed" 256 bit cryptographic-grade hash of them.  Given H, we
create E like this:
def E(key, data):
    if key >= (1 << 256) or data >= (1 << 512):
        raise Exception("E input data too large")
    dlow = data & ((1<<256)-1)
    dhigh = data >> 256
    for i in range(4):
        dlow ^= H(key, dhigh)
        dhigh ^= H(key, dlow)
    dlow ^= H(key, dhigh)
    return (dhigh << 256) | dlow
Assuming H acts as an ideal cryptographic hash function, then after the
first iteration of the for loop, the output is scrambled beyond
recognition.  However, at that point, the output is "malleable", meaning
that an attacker can flip bits of the dhigh output, and the same bits of
the dhigh input will be flipped when decrypted.  This gives an attacker too
much control, so we need at least one more iteration, and just to be
paranoid, I did 4, though I think technically only 2 are required.  The
last XOR is just to make this function the inverse of itself so that I do
not need a separate encrypt and decrypt function.
Next, we need a super-duper hash function H.  All that is required is
mixing bits back and forth like above, but this time instead of a key, we
need to use three primitives which when mixed are difficult to
mathematically analyze:  ADD, ROTATE, and XOR, sometimes called ARX.  I
used multiplication rather than ADD, but it doesn't really matter since
multiplication is just a bunch of additions.  Designing this well is an art
because it has to map very well to the SIMD units on modern processors, and
mix bits quickly.  In my case, I simply do a large number of rounds.  Is it
enough?  Probably, but a proof of this is beyond my skill currently.
 "Proving" this is enough is basically a matter of asking the world's best
crypto experts to analyze it for days.  Here's my super-duper hash
function, which I simply conjecture is secure enough, based on my using
many rounds of ARX:
def H(key, data):
    state = key << 256 | data
    for i in range(64):
        state = doRound(state)
    return state & ((1 << 256)-1)
def doRound(state):
    vlow = state & ((1 << 256)-1)
    vhigh = state >> 256
    vlow = (vlow*(vhigh | 1)) & ((1 << 256)-1)
    vhigh ^= vlow
    vlow = rotateBits(vlow, 39)
    vhigh = rotateBits(vhigh, 209)
    return (vhigh << 256) | vlow
def rotateBits(data, dist):
    return (data >> dist) | ((data & ((1<<256-dist)-1)) << (256-dist))
The "round" function has a multiplication, XOR, and rotation, so it's
probably good enough if iterated enough.  Doing it only 64 times might be
too few, but with the multiplication instead of an addition, I suspect this
mixing is enough.  There are two things to note about this hash function.
First, the doRound function is reversible.  This means that given the
output of doRound, we can always compute what the input must have been.
This property insures that all 64 calls to doRound result in a 1-to-1
permutation of possible inputs to outputs.  No "entropy" is lost.  The only
non-reversible step is the last step, where we return the low 256 bits of
Now we have a block cipher!  Let's try it in Python.  I added these lines
for the test:
data =
key = 0xaaaabbbbccccddddeeee
encData = E(key, data)
print "Encrypted data %x" % encData
decData = E(key, encData)
print "Decrypted data %x" % decData
When run, it prints:
Encrypted data
Decrypted data
How cool is that?
So, are we done?  Not really.  A block cipher can only encrypt a block at a
time, and it doesn't even do that properly yet.  For example, any 0 data
will always encrypt to the same output for any given key.  If we know that
a file is mostly 512-bit blocks of 0's, we can figure out where the 512-bit
0 blocks are in the the file by looking at the encrypted data.  To avoid
this, we need to encrypt the file in "counter mode", meaning we add 1 to
the key each time we encrypt a block.  Also, we don't want the same file to
be encrypted the same way twice, because that let's an attacker compare
your encrypted file to a database of encrypted files he has, and unless
your file is unique, he will figure out your data.  We need a "nonce" to
fix this, which is a long random value that we mix in somehow to make each
encrypted version of the same file unique.  Here's an example counter-mode
encryption function:
def encryptFile(filename, key):
    if filename.endswith(".enc"):
        outFilename = filename[:-4]
        encrypting = False
    else:
        outFilename = filename + ".enc"
        encrypting = True
    with open(filename, "rb") as infile:
        with open(outFilename, "wb") as outfile:
            if encrypting:
                rndfile = Random.new()
                nonce = bytes2int(rndfile.read(32))
                outfile.write(int2bytes(nonce, 32))
            else:
                nonce = bytes2int(infile.read(32))
            key ^= nonce
            for data in blocksFromFile(infile):
                encData = E(key, data)
                outfile.write(int2bytes(encData, 64))
                key = (key + 1) & ((1 << 256)-1)
This has one significant error still: I did not deal with padding the last
block, and the last block will be decrypted incorrectly.  I'm too lazy at
the moment to fix it :)  Also, even with the nonce and counter mode, we
have no data integrity check.  We should MAC the encrypted data so that we
can verify the file has not been modified.  Otherwise, counter mode is just
not good enough.  But... this is enough for a fun quick hack for today :)
Python code, with goobered padding and no MAC, attached.

@_date: 2015-07-06 11:18:28
@_author: Bill Cox 
@_subject: [Cryptography] Are Momentum and Cuckoo Cycle PoW algorithms broken? 
Is it known whether Momentum and/or Cuckoo are memory-hard?  I don't think
either are.
Both claim to be "memory-hard".  I would consider any algorithm that
defeats the memory*time defense of a memory-hard algorithm like Scrypt to
be a complete break, in the sense that we can no longer claim they are
memory-hard.  Such algorithms are prone to effective custom-hardware
attacks, and should probably be avoided as a PoW system which is trying to
avoid ASIC implementations.
Momentum  is a cool
algorithm.  I particularly like it's simplicity.  Unfortunately, we can
arbitrarily speed up the computation with parallel processing, without
increasing memory, violating Momentum's memory*time hardness.  To speed up
Momentum with custom hardware, simply run any effective parallel sorting
algorithm .
Detecting repeated entries is then simply comparing adjacent values in
For a concrete example (though not the most efficient) of a parallel
machine that breaks Momentum's memory-hardness, consider a hyper-cube of
nodes.  Each node generates birthday hashes in it's assigned range of input
nounces.  Each node is also assigned the task of storing a specific range
of birthday hashes in a hash table.  This is done in parallel by having
each node generate birthday hashes and transmit them through the network to
the nodes that will store them.  Each node puts incoming hashes in a hash
table in constant time, looking for collisions.
The runtime of this algorithm is proportional to the time to generate the
hashes, which is O(n/p), plus the time to transmit them through the
network, which is O(log(p)).  The total is O(n/p + log(p)).  both terms can
be made arbitrarily small compared to n as n and p both increase.  At the
same time, we only used n total memory.  Therefore, we've reduced the
memory*time cost by an arbitrary factor, as n increases, with parallel
computation, breaking Momentum's memory-hardness.
Cuckoo Cycle also claims to be memory-hard, but I don't buy it.  They're
looking for cycles of length L by building a forest of trees, and detecting
when loops form, and measuring the length.  If we do a parallel sort as
above, we can store entries in a Cuckoo hash table
 rapidly in parallel.
Collisions force use to move entries from one node's table to another, but
only on average a small constant number of times.  The total network
traffic per hash store is still O(log(n)) on a hyper-cube, just like
Momentum.  On each failed store, we detect a cycle, along with its length.
The time to do this is already factored into the store time.
Cuckoo is rather complex, and I am likely missing something, but I do not
see how it can be considered memory-hard.  Did I get this wrong?

@_date: 2015-07-07 18:03:54
@_author: Bill Cox 
@_subject: [Cryptography] Is this parallel DPL solver for elliptic curves 
Sorry if this is just a matter of my relative ignorance of crypto...
The algorithms I've found with my poor google-fu solve DLP over elliptic
curves in time much worse than sqrt(q)/p, for a group of order q, running
on p processes.  The obvious parallel algorithm is to cut the search space
into p linear sections, and have p processors run the algorithm on it's
sub-interval.  The computations and memory for each process is then
sqrt(q/p), for a total of sqrt(p)*sqrt(q), far worse than the serial case.
If instead, we could do this:
1) first, compute sqrt(q) baby step values in parallel, with total memory
sqrt(q) and time sqrt(q)/p.  Store these to cheap disk storage
2) next, assign each node a range of the result space, so the first node is
assigned hash values from 1 to q/p, etc
3) In a linear pass over the disk data, sort it into p lists according to
it's assigned node
4) In p steps, using a barrel-shifter shaped router, route hashes to their
destination nodes.  First, transmit the node0 data, then node1, etc.  This
takes time proportional to q/p, and a barrel-shifter shaped router of depth
log(p) and width p.  It is efficiently implemented using FPGAs, such as
those from Achronix.
5) Now repeat steps 1-4 using the giant steps, rather than baby steps.  At
the end, each node must search for identical hashes in the data it has
6) Sort the data using a fast radix sort to find the discrete log
Latency of the routing network is low enough to be ignored.  The bandwidth
of the hard disks involved is the limiting factor.  The algorithm can be
sped up so that instead of writing to local disk and partially sorting the
data, we simply write to local RAM and transmit buffers at nearly
disk-write speed to their destination, by having the barrel-shifter router
cycle rapidly.  So, the first 2 passes have runtime O(sqrt(q)/p) each.
Radix sort of the resulting data is fast, but there will still be several
passes over the disk.  This is the dominant step of the algorithm.  For
example, if sorting 16-byte values using radix 256, it will take 16 passes.
If I did the math correctly, the overall runtime is a small factor,
O((sqrt(b/r) + 2)*sqrt(q)/p), where b is the bits in the hash, and r is the
radix of the sorting step.  The speedup and total memory reduction is a
factor of O(p^(3/2)/(sqrt(b/r) + 2)).
This can be used for DLP, meet-in-the-middle parallel attacks, and other

@_date: 2015-07-07 23:31:00
@_author: Bill Cox 
@_subject: [Cryptography] Are Momentum and Cuckoo Cycle PoW algorithms 
One thing I've noticed when I post attacks... the good ones are met with
silence.  The bad ones get debunked instantly :-)

@_date: 2015-07-07 23:53:38
@_author: Bill Cox 
@_subject: [Cryptography] Is there a better way to discuss/publish new attacks? 
If I am correct (and I am often mistaken), I've broken 3 would-be
memory-hard PoW systems this week.  Momentum and I believe Cuckoo Cycle can
be sped up with parallel processing to arbitrarily reduce memory*time cost
with practical hardware.  Ramhog is so flawed that I did not bother posting
attacks to this list, and just left a warning on a bitcoin related forum
instead.  Momentum and Ramhog were even used in their own crypto-currencies
(BitShare and ShinyCoin).
I do not know anyone who I can discuss these algorithms with, so I have no
choice but to post attacks without any review by anyone else before hand,
or not post my security concerns at all.  That, plus my lack of experience
in this field lead to most of my posts being half-baked and ignorant of
prior work.  If you say "go research the prior work first", go suck an
egg.  I do that all the time.  You can't absorb this whole field in a few
Is there a better way to discuss new attacks?  I really enjoy them.  My son
told me, "Dad, I didn't know you liked being evil."  I responded, "But only
evil for good."  :-)

@_date: 2015-07-08 11:33:18
@_author: Bill Cox 
@_subject: [Cryptography] Are Momentum and Cuckoo Cycle PoW algorithms 
This bounty is for a memory-time trade-off.  I have not analyzed Cuckoo
Cycle for TMTO resistance, and only lightly analyzed it for memory*time
memory-hardness.  I've focused so far mainly on Momentum's memory-hardness.
Both of these bounties require N ranging over {2^28,2^30,2^32} and
Memory hardness is different than TMTO-resistance.  I use the definitions
used by the Catena authors:
"Percival introduced the notion of sequential memory-hardness (SMH), which
is satisfied by his introduced password scrambler scrypt. Bases on this
notion, an algorithm is sequential memory-hard, if an adversary has no
computational advantage in using multiple CPUs, i.e., using b cores
requires b times the effort used for one core."
Your bounty requires that I use less total memory, which will make it hard
to find cycles fast.  A proper bounty for sequential-memory-hardness would
allow me to use N memory, and any number of CPUs to achieve a target
speedup, preferably an unbounded speed-up as the number of CPUs grows.
This is achieved against Momentum with a parallel sorting machine.
I read it, but I am focusing primarily on Momentum first, which is far
simpler to analyze.  I see you have a mistake in your analysis of
Momentum's memory-hardness:
"Since the extreme case of L = 2 is so special, there is likely to be a
greater variety of algorithms that are more efficient than for the general
case. While we havent found (and dont know of) a improved main algorithm,
we did find an improved BFS(L/2) TMTO algorithm (implemented in
momentomatum.cpp) that cuts the memory usage in half, resulting in a
slowdown of only 1.75a lack of memory-hardness."
There is a trivial TMTO against Scrypt where for a large memory reduction
factor N, the runtime is increased by only slightly more than N/4.
Attackers often make use of this.  However, since the memory*time cost is
only reduced by at most a constant factor, Scrypt is still considered
memory hard.  I am confident this is not the case for Momentum, but not
because of your TMTO attack.
I also doubt Cuckoo Cycle is memory hard, though this needs further
Can we focus on Momentum first, and see if there is something special about
Cuckoo Cycle that avoids Momentum's flaws?
My parallel sort algorithm uses the same amount of memory, and I already
took into account the latency bottleneck when the number of parallel
processing nodes runs into the thousands.
Cuckoo Cycle is a very cool agorithm, as is Momentum, but let's focus on
security against parallel attacks using custom ASICs, since this is what
we're trying to prevent as a crypto-coin PoW.
A major flaw I have not yet found any good solution for is the slowness of
cryptographic hashing algorithms.  I checked the runtime of SHA256 using
Intel's latest hardware instructions, and they just aren't fast enough
(multiple cycles per byte rather than the other way around).  I think an
ASIC attacker will gain a substantial advantage with far faster,
lower-power implementations.  I have not seen a PoW system with fast
verification yet that avoids this problem.  Until then, for ASIC
resistance, I think it is safer to stick with algorithms like Scrypt, or
even better, Yescrypt, and possibly Lyra2 or Argon2d.

@_date: 2015-07-08 11:51:17
@_author: Bill Cox 
@_subject: [Cryptography] Are Momentum and Cuckoo Cycle PoW algorithms 
You wrote in the paper:
"David Andersen also suggested an alternative method of trimming that
avoids storing a bit per edge. Expanding on that idea led to the algorithm
implemented in tomato miner.h, which, unlike the main algorithm, can
trade-off memory directly for runtime. On the downside, to even achieve
memory parity with the main algorithm, it already incurs a big slowdown. To
the extent that this slowdown is unavoidable, it can be called the memory
hardness of the proof-of-work."
This is an incorrect notion of memory-hardness.  Specifically, the goal is
to defeat attackers who have a huge number of cheap parallel cores, whether
they are using a GPU, FPGA, or ASIC attack.  Scrypt's notiion of
memory-hardness where multiple computing cores provides no more than a
constant advantage in memory-use * runtime is the proper definition.
Momentum certainly runs faster when using N memory locations when trying to
find a collision over N nounces.  That makes it memory intensive, but not
sequential memory-hard.  Parallel sorting algorithms will be devastatingly
more efficient at mining any crypto-currency based on Momentum.
If I just implement an actual Cuckoo hash table using a parallel sorting
machine, and do the on-average constant time insertions mostly in parallel,
wont I detect all the Cuckoo cycles?  How much faster is your
implementation than this basic algorithm?

@_date: 2015-07-08 13:37:20
@_author: Bill Cox 
@_subject: [Cryptography] Are Momentum and Cuckoo Cycle PoW algorithms 
For consistency with existing terminology as used to describe Scrypt and
other "sequential-memory-hard" password hashing schemes, why don't we call
this a "memory-intensive TMTO-resistant PoW with fast verification"?
I was trying to show that an ASIC based miner doing Momentum computations
would have essentially an unfair advantage vs CPUs, leading to an
inevitable switch to ASIC based mining if Momentum were used as the PoW for
a PoW mining based crypto-currency.  Parallel sorting is enough to work out
well enough for the proof, I think.
Now that I've been pointed to faster the parallel Pollard rho-algorithm
 for
finding hash collisions (thanks for the link, Jonathan!), I think Momentum
can be sped up linearly with the number of processors.  Momentum does not
seem parallelization-hardened
I am more interested in massively parallel attacks.  If I'm not mistaken,
using lots of memory had providing good defense against parallel attacks is
what we need to defend against ASIC based mining.

@_date: 2015-07-09 19:53:24
@_author: Bill Cox 
@_subject: [Cryptography] Are Momentum and Cuckoo Cycle PoW algorithms 
I analyzed Momentum in more detail.  It is a very cool algorithm, and it is
not broken, but it is also not sequential-memory-hard.  However, it does
seem reasonably ASIC-resistant, more than I thought it would be.  Momentu's
ASIC defense seems to lie somewhere between BitCoin's SHA-256 based PoW,
and a large-memory Scrypt based PoW.  It's simplicity and rapid constant
time verification are a big plus.
I believe there will be an advantage for ASICs in that the external DRAM
can be eliminated because all the data can be split among many different
ASIC on-chip memories and that data can be shared while the ASICs do their
computations in parallel.  This is why Momentum is not
sequential-memory-hard.  The cost to do this is a special router between
the ASICs (one that operates as a barrel-shifter would work well).  One
that can only do barrel-shifter style routing would work well, and should
not significantly slow down computation.  However, this router could easily
cost more than the external DRAMs, so the savings may not work out in the
end.  However, it does prove that Momentum is not sequential-memory-hard,
which requires that at most no more than a constant speedup in runtime
occur when using no extra memory but more processing.
There are two other advantages that could be used in an ASIC
implementation, even without communication between the ASICs.  First,
Intel's SHA256 instructions are very slow compared to hardware.  An ASIC
will easily fill it's DRAM memory bandwidth, while even with 8 threads, we
can't even fill one bank worth of DRAM memory bandwidth using Intel/AMD
CPUs.  Second, some high-end ASICs have memory bandwidths exceeding 300
GiB/s, while my Intel CPU in my desktop is limited to about 25 GiB/s.
Since memory bandwidth is the liming factor in this case for the ASIC,
there seems to be a difference of up to 10X for improved hashing speed, and
another 10X for improved memory bandwidth, for a combined potential
advantage of 100X faster.  If a memory-hard algorithm like
Yscrypt/Lyra2/Argon2d/Scrypt were used, it would reduce this gain to maybe
10X, just the difference in memory bandwidth, and possibly less with
multiplication-chain compute-time hardening.
So, Momentum is better than I thought, but I think we should stop calling
it "memory-hard", and use an alternate term.  It is memory-intensive,
As for Cuckoo Cycle, it inherits the memory-intensity of Momentum, adds
some TMTO resistance, and _might_ have some additional ASIC defense because
it finds cycles of length >2.  It is still important to keep the hash
function fast, and Cuckoo Cycle uses Siphash, so I'm please with that
choice.  The current dependence on DRAM cache-miss latency concerns me,
though.  I suspect I could design around it, as I do for Momentum below.
More analysis is needed, IMO.
Overall, the Momentum and Cuckoo Cycle authors seem to have done their
homework, and I found no glaring algorithm flaws.  The simplicity of
Momentum gives me some confidence in the algorithm.
Here I talk about the Momentum implementation in the BitShare miner code I
read.  It's flaws do not directly reflect on the Momentum algorithm, and if
this was meant purely as reference code, then it does it's job well.
However, it is slow, which seems odd for a miner.
If implementing Momentum, you must be very careful about relative sizes of
the input and output to the birthday hash function.  You may be vulnerable
to a parallel Pollard rho attack otherwise.  In particular, if the input
and output widths are equal (say 50 bits), then the memory requirement
almost completely goes away, and you can mount a massively parallel attack
with standard parallel Pollard Rho.  If the input bit width is about half
the output width, this seems to defeat Pollard Rho.  I am comfortable
saying that there seems to be no known way (at least that I can find after
some effort) to reduce the memory without increasing computations
proportionally in this case.  I am not ready to say it is impossible.
Clearly we cannot detect the collisions with reduced computations, but
there may still be decent memory reduction algorithms.
There are some issues with the implementation I read, though it was well
implemented, clear, and concise.  First, the SHA-512 hash fails to take
advantage of the new SHA-256 acceleration instructions.  It should be
replaced with SHA256, or possibly Siphash or maybe Blake2b.  As-is, an ASIC
attacker is getting a very significant bonus due to the slow hashing speed
of SHA-512.
Second, this implementation is needlessly slow, likely being cache-miss
penalty bound.  Perhaps it was only meant to be a reference minter.  A
faster implementation would have maybe 1024 buckets for storing hashes that
would be indexed by the high 10 bits of the birthday hash.  Worker threads
would generate hashes based on a fast hash rather than SHA512, and one
thread would gather the resulting hashes and append them to the buckets.
This would mostly eliminate L3 cache miss penalties during hash
generation.  A second pass would read the buckets one at a time (maybe with
parallel threads if the bandwidths allow), storing the hashes into a hash
table in L2 cache.  Again, this pass should incur very few L3 cache-miss
penalties, making me feel a lot better about ASIC defense, since we can at
least hope to limit the ASIC attack speed by I/O bandwidth.
I've read a few miner implementations now.  This one was nice.  They just
need a bit of a speed-monger to help out :-)

@_date: 2015-07-11 10:45:46
@_author: Bill Cox 
@_subject: [Cryptography] Are Momentum and Cuckoo Cycle PoW algorithms 
Possibly.  However, I found a way to generate vastly more hash data, to
fill up the memory bandwidth of the CPU:
What I do now is generate a chain of cryptographic hashes (Blake2s), but
fill only 1 in 32 356-bit memory locations.  For the rest, I run a
non-cryptographic hash function to fill the spaces in between, seeded by
the prior Blake2s hash.  The filling function can be anything, it doesn't
even need to mix well.  A good choice would be the PWX-transform from the
Yescrypt PHC entry, with 2 rounds, as it's very fast and also provides
decent GPU defense, similar to Bcrypt.
With this scheme, I can easily fill the memory bandwidth while generating
hashes.  My own system at home will require 2 threads to fill the 25 GiB/s
pipe, and there is efficiency loss.  Anything over 20 GiB/s total would be
very good.  However, it is not clear that I will succeed at the collision
detection portion at this speed, though I am already doing it much faster
than the Momentum BitShare miner code that I downloaded.
Verification of hash collisions wont take much longer, but it will take
more memory.  Since only 1 in 32 hashes are cryptographically derived
directly from the block digest, you have to verify the entire path to the
hash from the cryptographically strong hash that was bound to the digest.
This means computing 1KiB of hash data for each of the two hashes
involved.  However, this step is faster than generating a single SHA512, so
it's not really a problem.
The reason filling bandwidth is important is that data transfer speed seems
to be the only real limiting factor an ASIC will face in computing Momentum
hashes.  It is not technically memory-hard because I can generate all the
hashes in parallel, and find collisions with a partial-sorting parallel
router.  True memory-hard algorithms all generate values sequentially in a
chain defeating parallel generation of the data.  However, the routing
required to find Momentum collisions seems to be expensive, and this is
what will keep an ASIC miner from completely pulling away in efficiency vs
Any Momentum implementation that uses a small fraction of the CPU memory
bandwidth will find an ASIC implementation gets that additional multiplier
pretty much for free.  ASICs also sometimes achieve memory bandwidths that
are very high, some even over 300GiB/s, more than 10X the bandwidth of my
CPU.  However, these are expensive power-hungry beasts which are very
difficult and expensive to design.  For comparison, a Sony Playstation,
IIRC, has 120GiB/s, with 8 GDDR 5 banks.  A system like that wont be cheap
or low-power.
So, in summary: It is critical to hash Momentum data fast!

@_date: 2015-07-13 11:29:25
@_author: Bill Cox 
@_subject: [Cryptography] Are Momentum and Cuckoo Cycle PoW algorithms 
A possible solution to this speed problem is to generate a small number of
full secure hashes, and then rapidly generate a large number of fast hashes
from them.  It complicates verification a bit, but not much.  If two
non-cryptographic hashes collide, you just need to verify how they were
generated from the secure hashes.
For example, a hash value can be indexed by an (x, y) pair, where x is the
value used in counter-mode to generate the secure hash h = H(block-digest,
x), and y is the counter-mode value used to generate the fast hash from it
f = FH(h, y).  Verification requires computing FH(H(x1), y1) == FH(H(x2),
y2) where x1 != x2 and H(x1) != H(x2).
The security analysis is tricky.  If there is a mathematical solution to
finding y1 and y2 to generate a collision given h1 and h2, then an attacker
can use this and avoid the full brute-force collisions search.  For
example, if FH(h, y) = h + y, then it becomes trivial to verify if there
are any values of y1 and y2 in the legal range that lead to collisions for
any given h1 and h2.  In this case, there are collisions iff abs(h1 - h2)
<= maxY.  I've been using maxY == 32, and FH does xors, additions, and
rotations to make it hard to find simple mathematical techniques to find FH
collisions faster than computing all 64 FH values.  A single Blake2b hash
round seems like a good candidate for FH, for example.
Assuming FH is reversible (which is true in the functions I've tried), one
possible attack is to guess a colliding value C for FH given x1 and x2, and
see if there are valid y1 and y2 to generate C.  If maxY is large, then
this attack might be faster than computing all the FH values looking for
collisions.  Since maxY is small (like 32), in a space of very many
possible FH values (2^50 of them), a scheme where we have to guess C first
wont work out.
I think this is secure for small values of maxY, and an HF that resists
algebraic analysis, such as ARX hashes.
On the down-side, even though I can now generate hash data at the full
bandwidth to my external DRAM, the hash-table lookups still heavily
dominate runtime, even when the tables fit into L2 cache.  An FPGA with
similar memory bandwidth should be able to eliminate this extra latency,
and certainly we can do it with a custom ASIC.  It seems that setting
random bits in L2 is a slow operation.  I think the fastest algorithm I've
come up with so far is to do 2 rounds of radix-sort on the generated
hashes, which has very good cache performance.  After that, the buckets of
hashes to be checked should fit into L1 cache.  On my laptop, this agorithm
can generate 1 GiB of hash data in 0.2 seconds, but one radix-sort rouund
takes 0.6 seconds.  The two radix-sorts and the final L1 hash table lookups
run around 1.5 seconds.  However, the simple algorithm of just storing
hashes into a large external hash table takes only 2.7 seconds, so the
speed-up is less than 2X.  This is not very impressive.  A custom circuit
will beat this runtime by the difference in my bandwidth vs theirs.  I
write 1 GiB twice, and read it twice, in 1.5 seconds.  With a better
on-chip memory designed for this partial sorting, I would only have to read
and write memory once.  An FPGA version with 25 GiB/s to memory should run
10X faster than me.  I can improve with 2 processes in parallel, possibly
reducing the FPGA advantage to 5X-ish.
I don't know why radix sort is so slow.  When using 1 bucket, I generate
1GiB of hashes in 0.21 seconds.  With 2, it increases to 0.4 seconds, which
makes some sense.  With 256 buckets, it takes 0.6 seconds, and that
required using Intel's non-temporal streaming intrinsics.  I do not
understand why there is a decrease in speed when going from 2 buckets to
256, since I cache the data in each bucket in a 4 KiB cache, and only write
then to main memory when full.  If I could get this to run at the full
memory bandwidth, I'd be in good shape.

@_date: 2015-07-23 14:04:57
@_author: Bill Cox 
@_subject: [Cryptography] Whitening Algorithm 
Bear's advice on this topic is sound, as usual.  Here's my $0.02:
What are you doing with the output data?  If you use it with the Linux
entropy pool, then don't bother whitening it.  Instead, go get an accurate
estimate of the entropy -- ent is fairly weak at this.  Then, write all
your data to /dev/random, and update the entropy pool level by the number
of bits written times the entropy per bit.
If you are using the output directly for cryptographic keys, then It is not
secure enough.  Here's your code:
void loop(){
  currentByte = readByteFromSource()
    mixedByte1 = currentByte ^ previousByte;
  mixedByte2 = mixedByte1 ^ previousMixedByte1;
  mixedByte3 = mixedByte2 ^ previousMixedByte2;
  mixedByte4 = mixedByte3 ^ previousMixedByte3;
  outByte = mixedByte4 ^ previousMixedByte4;
  Serial.write(outByte);
  previousByte = currentByte;
  previousMixedByte1 = mixedByte1;
  previousMixedByte2 = mixedByte2;
  previousMixedByte3 = mixedByte3;
  previousMixedByte4 = mixedByte4;
Let f = outByte, mN = mixedByteN, and pN = previousMixedByteN.  Also, let
iN = inputN, where i0 = currentByte, i1 = previousByte, etc.  Let delta(g)
be the equation g with iN replaced with i(N+1) everywhere.  This moves it
back in time one sample.
m1 = i0 ^ i1
m2 = m1 ^ p1 = (i0 ^ i1) ^ p1
    p1 = delta(m1) = i1 ^ i2
m2 = (i0 ^ i1) ^ (i1 ^ i2) = i0 ^ i2
m3 = m2 ^ p2 = (i0 ^ i2) ^ p2
    p2 = delta(m2) = i1 ^ i3
m3 = (i0 ^ i2) ^ (i1 ^ i3) = i0 ^ i1 ^ i2 ^ i3
m4 = m3 ^ p3 = (i0 ^ i1 ^ i2 ^ i3) ^ p3
    p3 = delta(m3) = i1 ^ i2 ^ i3 ^ i4
m4 = (i0 ^ i1 ^ i2 ^ i3) ^ (i1 ^ i2 ^ i3 ^ i4) = i0 ^ i4
f = m4 & p4 = (i0 ^ i4) ^ p4
    p4 = delta(m4) = i1 ^ i5
f = (i0 ^ i4) ^ (i1 ^ i5) = i0 ^ i1 ^ i4 ^ i5
The output of your code is just the XOR of the two most recent samples, and
the samples 4 and 5 samples ago.  This can be inverted with some effort,
revealing the original pre-whitened stream by an attacker.  Imagine I know
i1 through i5, and see an output f.  The new input, i0, is easily computed:
    i0 = f ^ i1 ^ i4 ^ i5
The simplest attack is to make all 2^40 guesses for i1 through i5 and see
which one was right.  This can be easily determined because we expect
correlation between adjacent samples.  The correct guess will generate the
highest correlation.  After guessing the state, we can un-whiten the stream
trivially from then on.  The lower bits of entropy per byte, the quicker I
can guess your state.  If your input is already perfectly random, then
there is no way to guess the state -- and also no reason for whitening.
Unfortunately, properly whitening is a bit harder than what you're doing.
The simplest effective solution is to do a long chain of XORs, rotates, and
unsigned char pool = 0;
while(true) {
    int i;
    for(i = 0; i < NUM_SAMPLES/2; i++) {
        pool ^= readSample();
        pool += readSample();
        pool = (pool << 1) | (pool >> 7);
    }
    output(pool);
With these add, xor, and rotate instructions, your simple 8-bit entropy
pool will slowly lead to uniformly random states as you feed in entropy.  I
did this once with a 40-MHz A/D converter that sampled avalanche noise.  It
worked great, but I used NUM_SAMPLES = 80, so it slowed it down
In your case, I'd use NUM_SAMPLES to be something like 32, based on what
you said about your ent results.  The output would be much slower, but far
more likely to be cryptographically secure.
However, if you want to maintain high output rates, you can do so safely
with a cryptographic hash function like Bear suggests.  For example, let's
say you can compute SHA256 on your microcontroller.  In that case, use
something like:
unsigned char state[32] = {0,};
while(true) {
    state[0] ^= readSample();
    SHA256(state, state, 32); // Replace state with SHA256(state)
    outputBits(state[0], 5); // Assuming you are confident in 5 bits of
entropy per input sample
Unfortunately, you wont be able to accurately guess the entropy per bit,
because there is no good model for correlations between bits in avalanche
noise.  Also, if there is a large spike from your noise source, your A/D
converter inputs will saturate to 0 or 255, possibly for several sequential
samples.  Temperature will effect correlations in your source, and it will
change over time as it ages.  If you make more than one, the
characteristics of the noise sources will vary.  These are some reasons I
recommend using a modular entropy multiplier
 as your entropy source instead.
A MEM generates a highly predictable randomness per bit which is easily
verifiable according to the model.  All these problems go away.  However,
you still need proper whitening.  I try to use the cryptographic hash
function trick when possible.  Blake2s is fast in software.  Keccak is fast
and small in hardware.  ChaCha is a popular.  SHA256 is good but slow.
Spritz sounds good to me, but I'd want a large state, like 256 8-bit

@_date: 2015-07-23 18:20:36
@_author: Bill Cox 
@_subject: [Cryptography] Whitening Algorithm 
Not a bad solution.  I use 1600-bit Keccak to whiten the output of my
Infinite Noise TRNG.  Works great :-)

@_date: 2015-07-24 11:15:04
@_author: Bill Cox 
@_subject: [Cryptography] Whitening Algorithm 
I use the full 24 rounds of KeccakF-1600.  I absorb 512 bits at once, with
0.86 bits of average entropy per bit.  This is computed from the gain
around an op-amp.  If K is the gain, then the entropy/bit is log2(K).  In
this case, I use K = 1.82.  This results in cryptographically scrambling
the state all at once.  I squeeze 512*min(measuredEntropy,
theoreticalEntropy/1.03) bits.  It is fast compared to th 300K bits/second
coming from my TRNG.
I also have an "outputMultiplier" parameter.  If a user needs unpredictable
pseudo-random data faster than my TRNG produces (around 240K bits/s of
whitened data), then I simply squeeze 256*outputMultiplier bits for each
512 bits absorbed.  This does not produce true random data, as there is far
less than 1 bit of entropy per bit of output, but it is useful in some

@_date: 2015-07-24 11:23:24
@_author: Bill Cox 
@_subject: [Cryptography] Whitening Algorithm 
I consider this paper some of the best work in TRNGs ever.  This paper has
had a more important impact than tthe Turbid code, IMO.  However, this
particular section just quibbles about semantics of the words "hash
function" and "whitener".   Turbid uses a "hash function" on the output,
and stubbornly refuses to call this a whitener.
In reality, that hash function is what the rest of the world calls a
whitener.  However, I agree that two hash functions in a row - what the
paper calls a hash function and a whitener - is a poor idea.  There is also
very loose use of the word "entropy", here and elsewhere.  Personally, I
gave up on trying to correct the rest of the world, and just use the term
as others do, unless we're in a conversation where the specifics matter.
For example, in the discussion above, "entropy" is meant as an average
expected level of surprise in some cases, and the actual measured surprise
for a given string in others.  One use is a property of the TRNG, and the
other is a property of a specific output string.  In general, unless it
makes a difference in the results, I gloss over distinctions like
"whitener" vs "hash function".

@_date: 2015-07-27 07:21:04
@_author: Bill Cox 
@_subject: [Cryptography] Whitening Algorithm 
My Infinite Noise TRNG is primarily meant as a means for educating the
world about this architecture of TRNG.  If it is a good fit for your
project, feel free to copy the Eagle files and simply delete the USB
interface portion.  It's all open hardware/software.  This should make a
nice tiny shield if you can deal with 6 pins:
- VCC - 3.3V, though the components should handle 3V to 5V.
- GND - 0V
- CLK1 - a 300 KHz square wave
- CLK2 - the inverse of the 150 KHz square wave
- OUT1 - output channel 1: sample this on rising edge of CLK1
- OUT2 - output channel 2: sample this on rising edge of CLK2
I prefer to do whitening on the host side, with a pre-whitening health
check.  Whitening in the shield is an iffy thing to do, for the reason you
mention - you can't trust the data once it's whitened, if you have no way
to verify the source.

@_date: 2015-07-27 11:29:09
@_author: Bill Cox 
@_subject: [Cryptography] [OT] Improvement to Momentum PoW 
A problem with Momentum as currently implemented is that it can be run with
reduced memory, enabling efficient GPU attacks
I think we can get around this problem simply by changing the parameters it
uses.  Here's what Momentum computes:
for i, j in [0 .. 2^n-1]:
    if Hb(i) == Hb[j] and H(i || j) < threshold:
        report i, j
In this case, Hb is specific to a block-chain digest and nonce, as is H.
In the current implementations, n is 2^26 and the size of Hb's output is 50
bits.  H's output is far larger, either 256 or 512 bits.  This leads to on
average something like 3-ish collisions per nonce tried.
If instead, we run with n == 26, and Hb's output also being 26 bits, then
we get around 2^26 collisions.  Each needs to be tested to see if H(i || j)
< threshold.  The obvious algorithm is to do this rapidly is:
Initialize array M to 2^26 empty lists.
for i in [0 .. 2^n-1]:
    list = M[Hb(i)]
    for j in list:
        # i collides with j
        if H(i || j) < threshold:
            report i, j
        if H(j || i) < threshold:
            report j, i
    list.append(i)
This seems to defeat Bloom filters and similar memory reduction
techniques.  While a parallel Pollard Rho algorithm would work, it's slow
and reduces memory no more than the simple TMTO attack where we only store
some small range of Hb(i) in the hash table to reduce it's size.
I am not sure why this approach is not used in current implementations.  Is
there some attack I'm not seeing?
While this slight modification might enable Momentum to resist GPU attacks,
it's runtime is still dominated by Hb and H calculations, which an ASIC
will speed up dramatically.  I get around that by generating 32
non-cryptographic hash values for each cryptographic hash generated,
getting a speed-up of over 16X.  However, modern Intel CPUs seem to be very
weak at running buffered radix-sort.  An ASIC will run at full memory
bandwidth, which might be far higher than a typical CPU's bandwidth.  For
example, I can fill 1 GiB with unsorted birthday hashes in 0.2 seconds on
my machine.  When I create 256 buffers of 4KiB each, and do a byte-based
radix-sort pass, this delay jumps up to about 0.65 seconds.  This is with
temporal streaming writes, so I'm not polluting L2 or L3 cache with my
buffer writes.  An ASIC would see no such additional delay, and would
likely have significantly higher bandwidth to memory as well.
I'm think that ASICs will still win significantly vs CPUs on every
implementation I've seen of Momentum.  The enhancements above should, if
I'm not mistaken, at least stop GPUs.

@_date: 2015-07-27 14:02:20
@_author: Bill Cox 
@_subject: [Cryptography] [OT] Improvement to Momentum PoW 
Well, it certainly seems different, at least in terms of optimizations and
attacks.  With input/output of Hb set to the same width, I _think_ it is
more GPU resistant.  I could be wrong.  I think we can not compute the
collisions efficiently in less than around 2^27 bytes, though there's the
obvious TMTO option, as usual in Momentum.
If this works as I think it does, without any attacks I'm missing, then I
would prefer this version, since it forces an ASIC to use more memory.  I
think the main ASIC defense for Momentum is total memory bandwidth.  The
latency defense is overcome with buffered radix-sort, but the data still
has to be written and read once.

@_date: 2015-07-28 06:13:58
@_author: Bill Cox 
@_subject: [Cryptography] [PHC] [OT] Improvement to Momentum PoW 
This is incorrect.  This is covered in the paper in the section "Run-Time
Analysis for Finding a Large Number of Collisions" under finding golden
collisions on page 9.
The hash table algorithm uses O(sqrt(n)) memory, for n points, and runs in
time O(n) to generate all collisions.  Decreasing it by a factor of T,
causes it to run T times longer to generate all collisions, so memory*time
= O(n^1.5), regardless of T.  The paper's algorithm runs with w
distinguished points, using O(w) memory, and runs in time O(sqrt(n^3/w)).
Memory*time is O(n^1.5*sqrt(w)).  This is far worse than the hash table,
for all values of w >> 1.
For constant memory, both algorithms converge to O(n^2) runtime, no better
than comparing random points.  This isn't in the paper, but it's clear from
the algorithm if you imagine storing 1 distinguished point.  You have to
take O(n) steps to hit it once, and the paper's algorithm requires hitting
it twice.  Since random points collide with probability 1/n, you only need
O(n) random comparisons to find a collision.  The same goes for the hash
table algorithm.
So, distinguished point algorithms fail at every memory size compared to
using a hash table.
Parallel Pollard Rho is where we share the distinguished points among a
large number of workers.  This algorithm fails vs a shared hash table for
the same reasons as above.
Anyway, thanks for taking some time to examine it.  For now, I still think
this algorithm works better than regular Momentum.

@_date: 2015-06-01 22:35:43
@_author: Bill Cox 
@_subject: [Cryptography] Why is ECC secure? 
It's certainly harder, at least for me.  I have an annoying trait (one of
several):  I don't like to believe anything other people tell me.  They're
wrong too often.  I had to prove Pythagorean's theorem before I could feel
comfortable using it.  I still cringe whenever anyone throws around "real
numbers" and "infinity" without any mathematical definition, which is why
Cantor's diagonal proof is wrong.
This is why I'm asking about the security of ECC.  I'm not trying to stir
FUD.  I just want to understand why you guys who have played with ECC for
years feel comfortable with the security.
Here's my latest dumb attack on Edwards curves, still working the
circle-angle.  I know it's a dumb attack...
Points used in cryptography on a curve like Ed25519 correspond to real
points on a real-numbered 2D curve.  We start with a point where X == 9,
and use this as the group generator.  Just clockwise of the identity
element (0, 1), is going to be the minimal generator, which I'll call G.
The group will include 2G, 3G, 4G, etc, and these points all line up
increasing in the clockwise direction.  I do not see why there would be
points in the group between multiples of G.  I also don't see why I can't
do a simple binary search to determine m, when given m*G.  If that works,
then given the real group generator H, I should be able to find n such that
H = n*G.  After that, I think it's basic arithmetic to find o, when given
o*H.  I'm making a lot of assumptions, like being able to find G easily.  I
know I have an error or invalid assumption.  Where is it?  This is simple
enough to code, and that's where I always find the flaw...

@_date: 2015-06-02 17:54:50
@_author: Bill Cox 
@_subject: [Cryptography] Why is ECC secure? 
My dumb attack fails (as expected).  I missed the fact that we cannot
easily convert from (x, y) form to an actual location on the curve that I
can plot.  Modular addition hides the actual point position well.  I do not
even see how to attack this even when using points on a circle.

@_date: 2015-06-06 00:04:29
@_author: Bill Cox 
@_subject: [Cryptography] Simple provably secure stream cipher 
For any prime p suitable for Diffie-Hellman key agreement with group
generator g = 2, simply generate the binary digits of fraction(2^n/p),
where n is a shared secret.  XOR these digits over the message stream for
both encryption and decryption.
I'm ignoring issues such as the need for a unique nonce, and maliability
defense.  The standard fixes apply.  The ability to determine n is
trivially equivalent to solving the discrete log problem.
Is this well known?  I'm pretty much finding that everything seems to be
already known in crypto...

@_date: 2015-06-06 07:56:57
@_author: Bill Cox 
@_subject: [Cryptography] Simple provably secure stream cipher 
Sorry!  While true that we cannot recover n, as that is DLP equivalent,
this is not a secure stream cipher at all, as only log(p) bits is enough to
determine the rest of the pattern forever.  Specifically, this is _not_
suitable as a stream cipher.  It does seem to make a pretty nice PRNG,
though too slow for practical use.

@_date: 2015-06-10 21:13:17
@_author: Bill Cox 
@_subject: [Cryptography] Why is ECC secure? 
Is the following problem hard?  I'm still trying to grok the basics of what
make ECC hard to attack.  The simplified system I'm trying to attack is
just the unit circle, which is basically an Edwards Curve with d = 0.  I
think I might be able to find the discrete log on the circle if I could
just map the (x, y) mod p point back to a rational point on the circle.
For a given prime p, the given integer x, y point mod p satisfies
    (x, y) = s*G mod p
where G is a generator point, and s is a secret value.  I'm trying to find
s, which looks doable if I can map (x, y) back to a rational point on the
circle, (l/n, m/n).  The (x, y) point satisfies:
    x^2 + y^2 = 1 mod p
This point corresponds to a rational point on the unit circle, (l/n, m/n),
    (l/n)^2 + (m/n)^2 = 1   (not modular arithmetic)
or equivalently:
    l^2 + m^2 = n^2
At the same time:
    l/n = x mod p
    m/n = y mod p
or equivalently:
    l = n*x mod p
    m = n*y mod p
There are three unknowns (l, m, and n) and three equations restricting
their values.  I would expect to be able to find a solution in most similar
cases.  I have not figured out any better way to compute l, m, and n given
x and y than the giant-step/baby-step algorithm.  Is this problem known to
be hard?  Have I simply failed to find the known solution?

@_date: 2015-06-15 14:05:51
@_author: Bill Cox 
@_subject: [Cryptography] Why is ECC secure? 
Yes, this is correct.
The homomorphism is simply taking each rational point in the rational group
mod p.  If we have P = s*G in the rational group, then we will also have P
= s*G mod p.  If we find an s that works in the rational group, it also
works mod p.  Further, we don't even have to represent P in the rational
group very accurately.  If we have a 2*n digit approximation of m/n, we can
trivially solve for s in the circle group (just divide by G), and I believe
we can also easily solve for s on an Edwards curve.
Since there are only finitely mod p points, each point has a finite
That's the shortest proof I've seen for why all but a few rational points
generate infinite groups on the unit circle.  I Googled that the other day,
and maybe this is a standard proof, but I failed to find such a succinct
proof.  Nice!
In reality, we typically do not do elliptic curve crypto on groups
homomorphic to rationals over an elliptic curve.  We always extend the
rationals by certain irrationals and sometimes i, but the math basically
seems to work out the same.  Given a rational coordinate x, I haven't seen
a curve where y is rational, though I've only looked at some NIST curves
and curve25519, and a few toy curves I made up.
However, I'm not trying to map a finite group mod p to another finite
group.  I was just wondering if we already knew what the difficult problem
is in doing the reverse-mapping of the homomorphism from rationals on the
unit circle to points mod p.  I was guessing this is already well known.  I
was just wondering if anyone had a useful link where I could learn more
about the problem.

@_date: 2015-06-30 08:57:33
@_author: Bill Cox 
@_subject: [Cryptography] Why is ECC secure? 
Thanks for this info.  That's very cool.
Given that the circle group seems roughy equivalent to regular DLP in
difficulty, is it safe to say that finding a compactly representable point
on the unit circle that maps to (x, y) mod p is equivalent in difficult to
DLP?  This would explain why I am finding it difficult to do :-)

@_date: 2015-03-11 15:30:30
@_author: Bill Cox 
@_subject: [Cryptography] Securing cryptocurrencies 
BitCoin has also shown that the typical PBKDF2-SHA256(1000) is essentially
broken.  About 1/2-ish of all user passwords are likely to be in an
attacker's 5-million-ish entry dictionary.  See 10-million-combos.zip -
over 2.5 million of the first 5 million users' passwords occur in the
second 5 million.  These passwords can be brute-force guessed by ASICs in
about 2.5 million guesses, where the guessing hardware costs $1 per 1
billion SHA256 per second.  An average password in the dictionary is broken
in 5 seconds (two SHA-256 calls per guess) on $1 worth of hardware,
assuming the attacker has bought enough of them to get to the economy of
scale that the BitCoin miners have achieved.
We didn't know this before BitCoin.  I did some back-of-the-envelop
calculations, but never guessed ASIC attacks could be this brutal.

@_date: 2015-03-12 15:15:40
@_author: Bill Cox 
@_subject: [Cryptography] Securing cryptocurrencies 
full of ASICs that might also double as room heaters, clothes dryers,
electric stoves, and such.  Low powered cell-phones could securely delegate
the computationally intensive task of proper password hashing to these
boxes, and the box operator could keep any coins he might mine as a
result.  We could dramatically improve password hashing security this way.
I don't think it even requires a mod to Makwa.  Simply define the PoW as
finding _any_ y^(2^w) where N leading bits exactly match the SHA256 of the
block 100 back in the chain (since this cannot be easily changed), and then
publish a document containing this PoW, and the hash summary of the new
database transactions you are signing, all signed by the private key of the
wallet where the mining bounty will go.
Password hashing this way is naturally very ASIC attack resistant, because
it hashed with a box full of ASICs.  The only down-side is the boxes need
to be accessible online.  You couldn't use this for protecting disk
encryption passwords, for example.

@_date: 2015-05-06 15:50:20
@_author: Bill Cox 
@_subject: [Cryptography] Is there a good algorithm providing both 
This simple use case, where compressed_text is generated with something
like bzip2 is clever, and might be useful for cases where performance is
more important than having uncrackable encryption.  However, for cases
needing strong encryption, this wont be good enough.  For example, if my
cleartext is a compressed and bzip2-ed tar archive, then the compressor
most likely wont be able to compress it further, and most if not all of the
cleartext will be passed along without any change.
I assume what you're interested in special compression techniques where the
compressed data is indistinguishable from random without the dictionary.
This would have to be a compressor that randomizes the input
cryptographically well.  The dictionary would effectively become the key in
this combined encryption/compression algorithm.  In some sense, the
compression already begins the process of randomizing the data, at least
for most compressible data, and therefore there should be less work
required to achieve cryptograhic levels of apparent randomness.  Sounds
good to me, but hard :-)  The two problems independently are already some
of the most challenging that we face.

@_date: 2015-05-07 08:03:36
@_author: Bill Cox 
@_subject: [Cryptography] Is there a good algorithm providing both 
We need a way to tell the lower-level transport to not encrypt the most
sensitive data, by inserting a marker into the stream that disables/enables
compression.  This would not stop all data leakage, but at least it could
help protect security tokens and other keys.

@_date: 2015-05-29 12:26:25
@_author: Bill Cox 
@_subject: [Cryptography] Why is ECC secure? 
no mathematical proof of security has been published for ECC as of 2009."
Why do we believe this is secure, other than the fact that in EEC's short
life, no one has cracked it?  Compared to DLP and integer factorization, I
doubt many people have tried.  BitCoin began to make me a believer, but
consider this attack:
As you may know Edwards curves have formulas of the form:
    x^2 + y^2 = 1 + d*x^2*y^2
and that as d ==> 0, this morphs into a unit circle.  With d == 0, addition
becomes addition of angles, and we can compute the modular inverse of a
point, and easily reveal the secret multiplicand.  The security relies on
the warping done by the d parameter.  However, what if we say:
    z^2 = -d*x^2*y^2
then we have:
    x^2 + y^2 + z^2 = 1
which is just the unit sphere.  Looking at the drawing for this EC curve,
where d == -30, you can see the angles don't add up like they do on the
circle.  However, z increases rapidly when leaving the for corners.  The
path climbs the sphere.  Visually, it looks like the path lengths may add
up just like angles do for circles, once you realize the point moves in the
positive z direction (towards us) when moving away from corners.
If the path lengths in fact add up on the sphere, then we trivially can
break EEC, simply by transforming the problem into regular integer modular
arithmetic and computing the modular inverse.
Has this been investigated?
Actually... I investigated it, and no, the path lengths do not add up.
There are other avenues to explore.  If any transformation from EEC to
regular modular arithmetic is found, it looks like it will transform into
finding m when given m*g mod P, which is trivial.  When other systems, such
as PKC based on matrix powers, were converted to regular integer
equivalents, they at least had DLP to fall back on.  ECC, even if it also
translated to regular DLP, uses keys that are far too short to be secure.
Should we be concerned?

@_date: 2015-11-02 13:13:31
@_author: Bill Cox 
@_subject: [Cryptography] YubiKeys / FIDO / U2F ?? 
If I'm not mistaken, Microsoft is publicly saying they will support FIDO in
JavaScript in IE by the end of this year.  I am not aware of the details,
but in theory this could enable web sites other than Microsoft to provide
device-based security somewhere between a Yubikey and what we have today.
Yubikey based FIDO should be awesome for enterprise situations, but I doubt
we'll see widespread end-user adoption.  What do you think of the Microsoft

@_date: 2015-11-03 16:11:49
@_author: Bill Cox 
@_subject: [Cryptography] YubiKeys / FIDO / U2F ?? 
Dumb question: what's SOP stand for?
In a better world, IMO, we would register our devices semi-anonymously with
web sites, and passwords/pins/fingerprints would only be used to
authenticate you to your devices.  In such a world, there would be less
need for a third party to provide authentication services.  I resisted
using "Login with Facebook" and such in the past, but it seems hackers are
gaining ground, and I am close to giving in.  By moving to device based
authentication, which FIDO and some other techniques support, we can keep
the web safe enough for smaller sites to continue managing their own user
So, in a way, I think FIDO may help promote the level playing field that
made the Internet awesome.

@_date: 2015-11-16 01:24:37
@_author: Bill Cox 
@_subject: [Cryptography] [FORGED] Re: ratcheting DH strengths over time 
Yes, longer key sizes will resist quantum attacks longer.  My understanding
(which could easily be wrong) is that the difficulty of increasing the
number of qubits in a machine grows exponentially with the number of
qubits, which is why I think we'd see ECC keys attacked well before longer
EC and RDA keys.
I like the idea of auto-increasing the key sizes.  If this were somehow
block-chain based, difficulty could be a function of solving discrete log
problems of increasing size.  The otherwise wasted CPU cycles in mining
could be used to work on factoring or solving discrete logs.
It might be simpler to have everyone use a minimum of 2048 bit keys for now
for DH and RSA.

@_date: 2015-10-01 08:02:21
@_author: Bill Cox 
@_subject: [Cryptography] Why is ECC secure? 
Do you know if this particular map is already known?  As per my experience
in crypto so far, I assume the answer is "yes".  At least this time, I'm
not _also_ wrong :)
Yeah, I figured that out.
I'm not ignoring it, I'm just using the geometric correspondence to help me
understand these curves.  There's no point wasting all thatd GPU hardware
in my brain :)

@_date: 2015-10-01 09:23:35
@_author: Bill Cox 
@_subject: [Cryptography] Why is ECC secure? 
By the way, using the elliptic function addition laws
 on Wikipedia, I
get equations of equal speed to the Edwards curve addition laws.  It
computes the _same_ X coordinate.  The only difference is that this is done
on an ellipse.  I have not tested them in Python, yet.  I could have a
typo, or Wikipedia could, but it should work out.
I prefer this ellipse method of visualizing the Edwards addition law,
though I don't know how to add the twist:
x3 = (x1*y2*d2 + x2*y1*d1) / (1 - d*x1^2*x2^2)
y3 = (y1*y2 - x1*x2*d1*d2) / (1 - d*x1^2*x2^2)
d3 = (d1*d2 - d*x1*y1*x2*y2) / (1 - d*x1^2*x2^2)
A = x1*x2
B = A*A
N = 1 - d*C
C = y1*y2
D = d1*d2
E = A*C
F = x1*d2
G = x2*d1
X3 = y2*F + y1*G
Y3 = C - A*D
D3 = D - d*A*C
13 multiplies... identical to Edwards curve algorithm from Wikipedia.

@_date: 2015-10-02 16:15:43
@_author: Bill Cox 
@_subject: [Cryptography] Edwards curves are just ellipses - and why ECC works 
I assume this is all well known, but it's new to me and may help people on
this list understand modern ECC.  One of the best recent curves is
curve25519, with an excellent signing algorithm, Ed25519.  I wanted to know
"why this works".  Here's why.
[image: Inline image 1]
It turns out that anyone can trivially create "addition laws" to create new
ways to add "group elements" together, forming an "Abelian group ".
Here's how:
1) Pick _any_ one-to-one function, so that an inverse exists, even if it is
hard to compute, Call this function F, and it's inverse Finv.
2) Write out the function G(a, b) = Finv(F(a) + F(b)).  This is the "group
addition law" that shows how to add elements of the group.
Give it a try.  I'm sure you can easily convince yourself that this
generally works.  For example, if F(a) = 1/a, then G(a, b) = 1/(1/a + 1/b)
.  This can be though of as the "parallel resistor group", where elements
are resistors and the addition operator puts them in parallel.
So, what is the "addition law" for one of the most awesome recent curves,
the "Edwards curve"?  For Edwards curves without the "twist", the addition
law is simply:
    G(a, b, d) = sn(F(a; d) + F(b; d))
I've proven this.  The function F(a; d) is the Incomplete Elliptic Integral
of the First Kind .  The
'd' is the same constant d used in Edwards curves
.  It is one-to-one and
invertable.  It's inverse function is sn(u, m), the Jacobi Elliptic Sine
 function.  The
proof basically projects an Edwards curve onto a unit hemisphere, by adding
a variable z^2 = d*x^2*b^2.  If you integrate 1/sqrt(xy) along this path on
the unit hemisphere, you get the exact same integral that defines the sn(u,
d) function.  This integral defines the "formal group law" for the Edwards
curve, I think.  By the way, "d" in the Edwards curve formula is equal to
"m" on the ellipse, which is the "eccentricity" squared.
Now that's all scary, but these are just functions like sine and cosine.
The important thing is we _don't_ know how to do modular arithmetic with
them, but we _do_ know how to compute the addition law G(a, b, d)
algebraically, in a modular arithmetic friendly way.  It was proven maybe
200-ish years ago that the "group addition law" for a regular ellipse (the
actual squished circle we all know and love) can be written.  Here's a link
to the well know addition theorem
So, that's it.  That's what ECC is, and why it works.  Here's something
cool I found that may or may not be known:
The Edwards addition law is the _same_ law as the ellipse addition law.
Anyone who tries to tell you that Elliptic Curve Crypto has nothing to do
with ellipses is wrong.  The above G group law is in fact the "exponential
map" for _both_ Edwards curves and regular point addition on an actual
The mapping from an Edwards curve to an ellipse is funny.  The "x"
coordinate on an Edwards curve is _identical_ to the "y" coordinate on the
ellipse!  AFAIK, there is no good reason to hurt our brains with overly
complex mathematics, when we can do the exact same crypto on the same ellipse
we all studied in high-school
I've attached python code demonstrating the equivalence of crypto on
Edwards curves and ellipses.  Enjoy!

@_date: 2015-10-02 18:00:22
@_author: Bill Cox 
@_subject: [Cryptography] Edwards curves are just ellipses - and why ECC 
Here's another Python file showing how Edwards curves and the Edwards
addition law is the same as the old ellipse and it's addition law.  This
one does the full modulo arithmetic.

@_date: 2015-10-03 08:10:46
@_author: Bill Cox 
@_subject: [Cryptography] Edwards curves are just ellipses - and why ECC 
Just to clarify how these programs show the equivalence, compare th "x"
values on each line to the "sn" values.  They are the same.  The "x" values
are computed using the Edwards addition law, while the "sn" values are
computed using the ancient ellipse addition law.
In describing the mapping to the ellipse, I forgot a minor point:  The
Edwards X coordinate is equal to the sn value from the ellipse.  To get the
(x, y) point on the  ellipse, the "cn" value is the X coordinate, but you
have to divide the "sn" value by the "b" coefficient from the ellipse
equation, which is:
    x^2 + y^2/b^2 = 1
It looks like there never was a good consensus for whether this form should
be the "official" unit ellipse, or whether we should use this alternate
    x^2/a^2 + y^2 = 1
The choice makes some minor differences in the resulting unit ellipse
equations.  In particular, the excellent paper above describing elliptic
functions as trigonometry use this second form, while Wikipedia and Wolfram
both use the first.  My code is based on the first, to be more easily
verified using Wikipedia.
If you compare my code carefully to Wikipedia, you'll see one difference.
Wikipedia defines the r "radius" as 1/sqrt(x^2 + y^2).  It's wrong.  To get
the code to work, you have to use the sensible, correct equation for the
radius, which is sqrt(x^2 + y^2).  Their statement that dn = 1/r is also

@_date: 2015-10-04 08:29:11
@_author: Bill Cox 
@_subject: [Cryptography] Edwards curves are just ellipses - and why ECC 
I left out some details, trying not to overwhelm the reader.  Yes, you need
F(a) + F(b) to be in the range of F.  The identity element is simply
Finv(0), so 0 has to be in the domain as well.  Given that, it's a group
addition law.
By the way, I also just showed that the Y coordinate in the Edward's
addition law is simply cn/dn from the ancient addition law.  This means I
can simplify the ancient law as follows:
s3 = (s1(c2/d2) + s2)/(1 + ds1(c1/s1)s2(c2/d2)
c3/d3 = ((c1/d1)(c2/d2) - s1s2)/(1 - ds1(c1/d1)s2(c2/d2))

@_date: 2015-10-04 09:18:34
@_author: Bill Cox 
@_subject: [Cryptography] Edwards curves are just ellipses - and why ECC 
Here's a simplified way to see the equivalence between ellipses and Edwards
curves.  First, here's two forms of the group law, which are equivalent,
though the Edwards form is faster:
Edwards form:
    sn3 = (sn1(cn2/dn2) + sn2)/(1 + d*sn1(cn1/sn1)sn2(cn2/dn2)
    cn3/dn3 = ((cn1/dn1)(cn2/dn2) - sn1*sn2)/(1 -
Old form:
    cn3 = (cn1*cn2 - sn1*sn2*dn1*dn2) / (1 - d*sn1^2*sn2^2)
    sn3 = (sn1*cn2*dn2 + sn2*cn1*dn1) / (1 - d*sn1^2*sn2^2)
    dn3 = (dn1*dn2 - d*sn1*sn2*cn1*cn2) / (1 - d*sn1^2*sn2^2)
Given either of these equivalent addition laws, we can compute a point on
the Edwards curve as:
    x = cn/dn
    y = sn
and we can compute teh point on the ellipse as:
    x = cn
    y = sn/b
The Edwards equation is:
    x^2 + y^2 = 1 + d*x^2*y^2
and the ellipse equation is:
    x^2 + y^2/b = 1
    b^2 = 1/(1-d)

@_date: 2015-10-04 09:46:12
@_author: Bill Cox 
@_subject: [Cryptography] Edwards curves are just ellipses - and why ECC 
I left out one factor.  The Edwards form of the ellipse point addition law
    sn3 = (sn1(cn2/dn2) + sn2(cn1/dn1))/(1 + d*sn1(cn1/sn1)sn2(cn2/dn2)
    cn3/dn3 = ((cn1/dn1)(cn2/dn2) - sn1*sn2)/(1 - d*sn1(cn1/sn1)sn2(cn2/dn2)

@_date: 2015-10-04 19:51:14
@_author: Bill Cox 
@_subject: [Cryptography] Edwards curves are just ellipses - and why ECC 
I found slides from a talk by DjB that shows that this is already known:
"Edwards x is sn;
Edwards y is cn/dn."
I'm sure the other formula must also be well known, that G(a, b, d) =
sn(F(a;d) + F(b;d), d) being equivalent to the addition laws.  Of course
this is only valid when F(a), F(b), and F(a) + F(b) are all positive (or
all negative).  The other variable for cn is required to traverse the whole

@_date: 2015-10-22 17:40:54
@_author: Bill Cox 
@_subject: [Cryptography] Attacking Elliptic Curve Crypto on the infinity 
Short version: cracking modern ECC, at least in this special case, is
equivalent to adding up arc-lengths on the infinity symbol.  However, the
math is hard, and no one has figured it out.  Do you want to have a try?
[image: Inline image 1]
Fear mongering disclaimer: Please _do_ continue to use ECC with confidence
(224 bits or more).  I see no reason to believe ECC DH is weaker than
regular DH (2048 bits or more), or the other way around.  I personally
consider the security of the ECDLP assumption to be on-par with the
security of the DLP assumption.  I doubt either will be cracked in my
lifetime.  I also doubt we'll see quantum computers capable of cracking
ECC-224.  Any "crypto expert" who thinks one is obviously easier to crack
than the other is not really a crypto expert, IMO.  Preferences for one or
the other are fine, but no one has a crystal ball that tells them which
problem will fall first.  If you are really paranoid, consider using _both_
so that your security relies on both problems being cracked at the same
time.  This suggestion is from DjB, where I read his recommendation for
using regular DH for long-term keys, and ECDH for ephemeral keys, bound to
the long-term keys.  Also, there is no pending "cryptopocalypse", and
quantum computing at this scale remains comfortably in the far distant
future.  Use either DH or ECC DH depending on the specific needs of your
application.  Don't fall victim to the fear mongering.
Now, back to attacking ECC, just for fun...
For the case of d == -1 on Edwards Curves
, the "thing being added" when
we add points together in Elliptic Curve Crypto is arc-lengths on the
infinity symbol, called a Lemniscate
.  If we can compute the
following integral, mod p, we can break ECC in this case (-1 is not a
square mod p, or a different p would have been used), and likely gain
insight into how to crack the general ECC case:
    arcLength(x) = integrate 1/sqrt(1  - t^4) dt from 0 to x
Here, x is the x-coordinate of Alice's public key (x, y) which she computed
as m*g, where g is the "generator point" on the infinity symbol.  What we
mean by m*g is the point on the infinity symbol we reach when moving m
times the arc length from the center to g.  By choosing units for the arc
length of g to be 1, rather than using radians or degrees, the arc length
to Alice's point m*g is just m.
There is a problem: the point m*g on the infinity symbol wraps around many
times. There is a solution.  Simply find the point "h" in the group closest
to the origin (0, 0), and convert Alice's point m*g into m*h.  This is done
by multiplying Alice's point m*g by n, where h = n*g.  We find n at the
same time as finding h.  This turns out to be easy, so long as we know the
rational point on the curve used to generate g.  This is the case for my
prefered signature scheme Ed25519.  It is not the case for the curve we
actually use most of the time: ECDSA-P256.  The NSA decided not to tell us
the original rational X-coordinate that they used to compute their
generator point, which means we can't find h, and we can't solve the
wrapping-around problem.  I'm not saying this is strong evidence of a
back-door in ECDSA-P256, but it does make me go "hmmm..."
Other than for NSA designed ECC curves, it is common practice to publish
how the generator point was selected, which is usually to start with a
simple rational X-coordinate on the curve, which enables us to find h.
Using 'h' rather than 'g'.  m*h never wraps all the way around the
lemniscate, so arcLength(m*h) = m in units of arcLength(h).
All we have to do is compute that simple arc-length integral.  If we can do
that, we can reveal m.  However, no one knows how to do this, SFAIK.  We
don't even seem to have promising leads.  We do have strong evidence that
solving this integral is at least as hard as finding x given 2^x mod p.
However, if p is only 256 bits, we can trivially crack that in Python.  The
rest of ECC's security, at least for d == -1, relies on the assumption that
no one will figure out a solution to this very difficult problem, and the
somewhat more difficult ones where d != -1.  However, we have no proof that
it cannot be done, just as we have no proof that we can't solve regular DPL
in polynomial time.  Crypto is based on assumptions that problems are
hard.  We can't "prove" they are hard.  Instead, we get there by having
lot's of people try to solve it and fail.  Want to help out by taking a
crack at it?
Have fun,

@_date: 2015-10-25 06:22:38
@_author: Bill Cox 
@_subject: [Cryptography] Attacking Elliptic Curve Crypto on the infinity 
Actually, it all works out mathematically.  I'm just trying to show people
a cool geometric interpretation of ECC.  I'm not claiming to have any new
insight for cracking ECC.
You surely know this, but for others reading, generally algebraic
expressions make sense mod p.  For example sqrt(2) is irrational, but since
3*3 == 2 mod 7, we can say sqrt(2) = 3 mod 7.  Similarly, i is imaginary,
so how can it make sense mod 5?  Well, -1 == 2*2 mod 5, so clearly i == 2
mod 5.  Most people think we pick rational points on the curve for
generators, when in fact, only X is  typically rational.  The point used in
Ed25519 has an X coordinate of 4/5, but the Y coordinate, when mapped back
to a regular Edwards curve, is both imaginary and irrational, but mod p,
it's an integer.
Consider arc-lengths on the unit circle.  The equation is:
    arc-length(x) = integrate 1/sqrt(1 - t^2) dt from 0 to x.
This is the arcsin function, mapping rational x values to non-algebraic
arc-lengths.  Did you know that arcsin(x) is an algebraic expression of
integers, x and pi?  In fact, simply using uints such as degrees, which are
fractions of pi makes arcsin(x) a regular algebraic expression of x, which
makes sense mod p.
The same is true here.  In fact, you can do point addition on the
Lemniscate using a ruler and compass, which is modulo arithmetic friendly.
I think I have defined everything correctly, or close to it.
I hope this geometric insight will be interesting to some people.  What I
have not offered is any insight on how to speed up computing ECDLP, which
is why I started with "Please _do_ continue to use ECC with confidence".
We know there is an algebraic expression for Alice's public key point (X,
Y).  We know it corresponds to an algebraic expression for the arc-length
on then Lemniscate, and that mod p, that expression is simply m when using
units of the arc length of h.  Finding that expression is obviously
equivalent to solving ECDLP in this case (d == -1).
I've simply transformed ECC for this case into another form.  I think it is
a very interesting form, one where people can go, "So... we're really just
adding arc-lengths mod p."

@_date: 2015-10-25 17:24:38
@_author: Bill Cox 
@_subject: [Cryptography] composing EC & RSA encryption? 
We need to move to more efficient protocols anyway, and this provides an
ideal opportunity to implement two-cipher-suite protection, IMO.
To enable zero-round-trip encrypted handshakes, the clients must retain
information about the server from prior connections.  This should include a
"long term key", such as regular DH-2048.  The first packet could be
encrypted using a secret derived from the long-term DH-2048 server key and
the local long-term DH-2048 key for that particular server.  This
computation only needs to be done once, or until we begin to feel that our
"long-term" keys are a little long in the tooth and need to be refreshed.
The first packet would not be forward-secure, meaning that if the long-term
key were stolen/broken, these packets could be revealed.  The first packet
should be a public "GET" request, and not passwords.
The first response from the server can be encrypted using an ephemeral ECDH
256-bit key.
The important step here is to insure that the ephemeral secret cannot be
guessed unless _both_ the DH derived secret and the ECDH derived secret are
cracked/stolen.  Simply computing SHA256(DH_secret || ECDH_secret) should
be good enough.  All packets after the first one can be doubly-secured, and
SFAIK, this does not present any new major burden on the protocols.  TLS
1.3 should probably do something like this to enable zero-round-trip
handshakes.  The improved security would be a side-benefit :)

@_date: 2015-10-26 08:18:20
@_author: Bill Cox 
@_subject: [Cryptography] composing EC & RSA encryption? 
We expect 256-bit ECC to fall to QCs before RSA-2048 or DH-2048.  If we use
one for long-term keys and the other for short-term keys, we'll see one
broken long before the other, hopefully with enough notice to upgrade away
from the broken system.
I know the Australian guys seem to think QCs with "1 million" cubits are
possibly as close as "five years" away, but I've seen these kinds of
predictions come and go so often that I am fairly comfortable ignoring
them.  What they accomplished was a 2-transistor QC.  That's really not
very impressive.  Wake me up again when they have a few hundred doing a
useful computation.
However, I think it would be prudent to start combining algorithms,
preferably very different ones.  The size of the keys is so vastly
different, I think it would be reasonable to start by simply combining ECC
and regular crypto (DH or RSA).  This might also fit the usage model of TLS
1.3 0-RTT.
However, the general idea of combining multiple algorithms isn't inherently
I agree.  I'm not following what's going on in the TLS 1.3 effort.  Is
there an opportunity there?  I think there are already two keys, one for
long-term and one for short-term, but I think they use the same
cryptosystem for both, which would be a mistake, IMO.

@_date: 2015-09-22 08:59:47
@_author: Bill Cox 
@_subject: [Cryptography] Follow up on my password replacement idea 
I agree that a replacement, or at least a significant upgrade, is needed to
Your scheme was fun to read.  It is yet another scheme to split secrets.
The "canonical" method is probably Shamir's Secret Sharing
.  For arm-chair
crypto enthusiasts like you and me, I suspect you'll find that scheme a bit
heavy-weight for a low number of devices.  A simpler scheme for sharing
sharing a secret between 3 parties is to take the secret S and generate 3
pieces that must be XORed together.  Do this by computing 2 random values
R1 and R2:
A = R1
B = R1
C = S ^ R1 ^ R1
Recreating S requires A, B and C, like your scheme.  Distribute (A, B) to
Alice, (B, C) to Bob, and (A, C) to Charlie.  Each has a copy of what the
other two are missing to recreate the secret.  This scheme does not even
require a cryptographic hash function, though I think it does improve
security, in case we have biased random generators.  However, this scheme
scales poorly, requiring O(N^2) keys for N parties.  Shamir's Secret
Sharing scales linearly.  Your scheme is interesting in that it scales
better than the simple deterministic XOR scheme, but it is probabilistic.
For example, if we split the secret into 128 keys, and gave 1024 people
each one copy of one key, there would be 8 copies of each key.  The
likelihood that any random 512 of them could recover the secret would be
about 1 - (255/256)^128 ~= 60%.  However, if only 256 of them got together,
the chance would be about 1 in a million.  Using 2 keys per user, we can
tighten up the probability distribution considerably.  So, this scheme has
nice scaling properties.  It still is probably better just to use the
canonical method.
A good example of an attempt to use a secret sharing scheme in
authentication is the PolyPassHash
algorithm, though they only covered password security on the server.
I think the problem you are trying to solve is authentication, which is
tougher than password security.  Having even 2 devices participate in
authentication dramatically improves security.  Google does this with 2-Step
Verification .  However, the number
of people who have bothered to use this is an insignificant fraction of all
users, so the problem of authentication remains very tricky.
So, the problem we need to solve is making 2-devices (or more) for
authentication almost invisible to the user.  If even touching a screen is
required, 99% of all users will not bother to protect their bank accounts
with the required extra effort.  Imagine if you had to touch your phone to
log into your work account on your laptop.  That's no biggie, but let's say
you forgot to charge your phone and when you got to work it was dead?
This authentication problem is a lot tougher than it sounds.  It goes way
beyond what cryptographers worry about all day.  It will take solid
engineering to improve the situation, in addition to solid crypto.

@_date: 2015-09-22 17:40:32
@_author: Bill Cox 
@_subject: [Cryptography] Follow up on my password replacement idea 
This effort sounds like a ton of work requiring a lot of good engineering.
If it did work out, it could be pretty huge.  Is it possible to sign up for
an account, yet?  I would be interested in kicking some tires.
Protecting those private keys is difficult.  Malware might sniff them when
the user unlocks them.  A co-worker and I would like to build an
open-source a hardware-backed signing library with a common API on the
major platforms.  For example, the new SGX Intel extensions can enable more
secure rapid key signing.  Some operations have to be super-fast, like
Token Binding signature operations, while others, such as unlocking a key
when a user enters a password, can be slower, and may rely on signing in
secure hardware, such as a TPM.
I read some of your IETF document on the Mesh
, and also
your email announcement
.  Your
project sounds ambitious.  However, secure authentication is a complex
problem.  One criticism I'm sure you hear is that the Mesh publishes
private keys to the world that can be used to "track" users.  There is a
trade-off here between privacy and security.  Algorithms can be used to
enhance privacy, but at some reduction in security.  It kills me that we
work so hard on anonymity, when most users are willing to click "Yes, let
this web site use my location data" when asked (including me).  I suspect
most users would be willing to use a potentially anonymous public profile
with a list of public keys to gain security, at least if it took zero
effort on their part.
Yep, these are tough problems.  To take this to the next level, the Mesh
may want to consider more than just signatures.  For example, if suddenly a
device is correctly authenticating to the Mess from Russia when all the
other user's devices remain in Idaho, that's a signal that maybe more
authentication factors are needed.  This can be more devices, answering
security questions, or sending an email to the user's default account
asking for confirmation.
However, anything that works is likely to be better than the mess we have
now :)

@_date: 2015-09-23 06:29:39
@_author: Bill Cox 
@_subject: [Cryptography] Follow up on my password replacement idea 
Why is multiple keys on multiple devices more secure than a single key on
those same devices?  An attacker needs only steal one of them to PWN user
accounts.  The attack surface is about the same.
At a minimum, you want signing to be done a separate process running as a
user in it's own group, without giving read permission to any of it's
files.  However, that leaves the entire OS as an attack surface, and as
time has shown, we can't fully secure an entire OS, at least not while
making that OS general purpose.  Reducing the attack surface even further
makes sense, especially if it's as easy as linking to a shared library.
We're hoping to make it that simple.
In any case, simply storing the private keys in the clear for malware to
attack is nuts, IMO.  Don't be lazy.  Link to a key manager that gets key
security right on each platform.
I am particularly interested in Matt Blaze's proxy re-encryption work that
It's cool.  How can it be used to increase security of keys stored on
Actually, I meant privacy issues similar to what we see today with
third-party cookies that enable advertisers to track your web browsing
behavior.  The initial "killer app" for the Mesh seems to be a password
manager, which should do a reasonable job of privacy protection, but as you
said above, eventually the goal would be stronger authentication using
PKI.  If a user exposes the same public key to multiple sites, those sites
can collude to track the user's behavior on the web.  The FIDO initiative
uses semi-anonymous assertions, as does DAA, to help solve this issue.
However, I agree that you don't have to solve every problem in the first
pass.  Simply giving the user the choice of opting into the Mess, with it's
potential key-based tracking limitation, is probably good enough to start.
Most people wont care, I think.  Longer term, I think you can take a play
out of the FIDO or DAA book and upgrade both privacy and authentication
A major challenge in authentication is doing it in the presence of
malware.  In a magical world filled with unicorns and fairies, we could
imagine that users have zero malware infected devices, and build our
security model based on that.  Alternatively, we could try and solve the
actual problem the world has given us, instead of whimping out and letting
users get PWNed.
I see way too many security people give up on delivering real security by
starting with, "Assuming there's no malware..."  That's a good point to
stop listening to those security experts, at least when it comes to
So, how can we authenticate users in the presence of malware?  It's
complicated, ugly, dirty, and painful.  You can't simply "solve" it with
PKI.  We have to take every advantage we can get, and even then expect to
lose way too often.  Some steps we can take in no particular order are:
* Secure secret keys and passwords in a far less complex and hopefully
malware-free location, such as a TPM or SGX "enclave".
* Track as much data as users are willing to let you track to help
distinguish them from malware-bots.
* Don't allow any critical state changes (such as financial transactions)
without verifying that the user is physically present at the device and
intends to allow a significant state change.
* Use multiple devices for authentication, at least when important state
changes need to be approved.
* Have multiple levels of authentication, each requiring a higher bar of
confidence that the user is genuine.
* Enable recovery of PWNed profiles using every bit of data at your
Solid authentication is the one place where we really need to leak a ton of
information, preferably only to a semi-trusted third-party.  In a world
with an exploding number of malware infested devices per user, we are in a
constant arms race to do a better job of discriminating bots from real
people than the attackers do at making user-like bots.  You also need to
keep the battle in those terms, and secure the secret keys against malware
with hardware backing, or you enable attacks with low-wage labor where
attackers authenticate remotely to PWN user accounts.  This is the
preferred method today - live attacks against your accounts through your
device are rare.
This is where a semi-trusted third party can be valuable.  The entire
history of a user's MAC addresses, IP addresses, geolocations, operating
system, web browser, and every other aspect of the user's behavior can all
be taken into account along with passwords and device-based PKI assertions
in making an authentication decision.  We could even consider typing
cadence as they type a password, which is highly identifying, if we could
get the device to send that data.  If we knew you used your credit card 3
miles away to buy lunch 1 hour ago, and that your cell phone says it's
moved from the restaurant back to your office where you are authenticating
with your computer, that would be a solid authentication signal.
Doing authentication and account recovery well is _very_ hard.  I'm still
just learning the basics.  This is one reason it might make sense to simply
let a monster corporation do most of the authentication for the world, in
the manner we see today when web sites offer "Log in with Facebook or
Google".  I've personally given up on authenticating users on my own web
sites.  For all future sites I build, I plan to throw the authentication
over the wall to the monster corps.
Unless you succeed with the Mesh :)

@_date: 2015-09-23 07:45:24
@_author: Bill Cox 
@_subject: [Cryptography] Non-Authenticated Key Agreement 
I know others on this list might dump on arm-chair crypto attempts, but so
as long as non-proven crypt is not put into practice, it's all fun.
Besides, it's nice to be able to break a crypto system before breakfast :)
d' XOR d'', and the result is kb, revealing Bob's secret key.
Your basic intuition is right, though.  If we can find an encryption
function E(d, k) such that E(E(d, k1), k2) == E(E(d, k2), k1) where E is a
secure symmetric key encryption, then you can use it to create a public key
crypto system.
If you look at regular DH, it almost fits into this model.  Instead of user
data d, use a constant g.  Then you need E(E(g, k1), k2) == E(E(g, k2),
k1).  If E(g, k) = g^k mod p, then E(E(g, k1), k2) = (g^k1)^k2 = g^(k1*k2)
= E(E(g, k2), k1).
One hard part in public key crypto is finding candidate functions E with
this property.  It leads naturally to investigating Abelian groups.

@_date: 2015-09-23 14:09:52
@_author: Bill Cox 
@_subject: [Cryptography] Yet another dumb crypto system 
Enjoy breaking this probably very old crypto system that was probably
broken decades ago :)
Here's my dumb idea for the day: public key crypto system based on a set of
"reduction rules" applied to polynomials.  It's pretty simple.  I'm using
just 2 variables in the polynomials: x, and y, though the technique extends
to more.  The polynomials have this form:
axy + bx + cy + d
where a, b, c, and d might be 128 bit numbers modulo a 128 bit prime p.  I
want to do DH key agreement, so I want to compute
(axy + bx + cy + d)^x
for some secret x.  Multiplying this out gives larger and larger
polynomials.  One technique to keep them small is to take them modulo some
fixed polynomial.  Instead, I'm using a couple of simple "reduction
rules".  The two rules are:
    x^2 => x + 3
    y^2 => 2y
These rules result in a unique reduction of any polynomial of x and y with
integer coefficients to the form axy + bx + cy +d.  The "addition
operator", which is really multiplication, is computed this way:
    (a x y + b x + c y + d) (e x y + f x + g y + h)
    = dexy + bex^2y + cexy^2 + aex^2y^2 + dfx + bfx^2 + cfxy + afx^2y + dgy
+ bgxy + cgy^2 + agy^2x + dh + bhx + chy + ahxy
Now apply reductions
    = dexy + be(x+3)y + 2cexy + 2ae(x+3)y + dfx + bf(x+3) + cfxy + af(x+3)y
+ dgy + bgxy + 2cgy + 2agyx + dh + bhx + chy + ahxy
    = dexy + bexy + be3y + 2cexy + 2aexy + 2ae3y + dfx + bfx + bf3 + cfxy +
afxy + af3y + dgy + bgxy + 2cgy + 2agyx + dh + bhx + chy + ahxy
    = dexy + bexy + 3bey + 2cexy + 2aexy + 6aey + dfx + bfx + 3bf + cfxy +
afxy + 3afy + dgy + bgxy + 2cgy + 2agyx + dh + bhx + chy + ahxy
    = xy(de + be + 2ce + 2ae + cf + af + bg + 2ag + ah) + x(df + bf + bh) +
y(3be + 6ae + 3af + dg + 2cg + ch) + (3bf + dh)
This gives the formulas for new coefficients A, B, C, and D, in terms of a,
b, c, d, e, f, g, and h:
    A = (d*e + b*e + 2*c*e + 2*a*e + c*f + a*f + b*g + 2*a*g + a*h) % p
    B = (d*f + b*f + b*h) % p
    C = (3*b*e + 6*a*e + 3*a*f + d*g + 2*c*g + c*h) % p
    D = (3*b*f + d*h) % p
With this addition rule, I can define multiplication in the usual way, and
use it for DH key agreement.  The identity element is (0, 0, 0, 1) meaning
a = 0, b = 0, c = 0, and d = 1.
The resulting groups have cycle lengths up to p^2 - 1.  Are prime power
sized groups as secure as groups with prime size?  If so, and with the
wildly optimistic assumption that this dumb scheme has bit security equal
to sqrt(group size), then just maybe using 128 bit values for A, B, C, and
p result in 128-ish bits of security.  Probably not, though :)
Partially, the motivation here is to include elements of add-xor-rotate
hash functions.  The x^2 => (x + 3) reduction rule creates terms that
combine with the constant term, sort of simulating right shift  Without it,
the constant term is just d^x mod p, which is too easy to break.  The
multiplications give an addition-like mixing from lower to higher order
terms, while truncating the exponents seems to give me non-linearity like I
get with XOR.  If these function as I hope, the output bits (the
coefficients a, b, c, and d) should be uniformly pseudo-random and resist
I've attached some hacked up Python code.

@_date: 2015-09-23 23:02:32
@_author: Bill Cox 
@_subject: [Cryptography] Cycles overhead for TLS 
Not a bad WAG.  It's probably a fairly minor point, but you did not include
the extra round-trips for the TLS handshake, which likely dwarfs the
overhead for key agreement.  QUIC, a new protocol with 0 round trips for
most handshakes, improves the network efficiency overall something like 3%,
just for the improved handshake.  The extra round-trip is the overhead we
need to kill in TLS.  They're working on it for TLS 1.3, I think.

@_date: 2015-09-23 23:26:45
@_author: Bill Cox 
@_subject: [Cryptography] Non-Authenticated Key Agreement 
It turns out that no public-key protocol can ever be designed that delivers
security in the face of a bad RNG on just one end.  This is another reason
that a good RNG is critical to security.
This is something I proved to myself a while back.  In general, if Eve can
predict any action Bob will take, because Bob has no actual source of
random behavior, then Even will know anything Bob knows as soon as he knows
it.  If Bob is a Turing machine with no random oracle, and Eve can see
initial state and all the input and output to Bob, she can simulate the
state machine on the inputs herself and know every bit of state Bob
contains.  Not good for Bob's privacy.
For Bob's internal state to diverge from what Eve can trivially predict,
Bob needs a random oracle.  I carry one in my pocket
, just for fun.

@_date: 2015-09-29 21:47:01
@_author: Bill Cox 
@_subject: [Cryptography] Why is ECC secure? 
A few weeks ago, I managed to prove what I'm sure is already well known:
that for Edwards curves, Finv(a) is just sn(a, k), where sn is the Jacobi
Elliptic sine function.  The whole Edwards curve addition rule, at least in
one quadrant, can be restated (in Wolfram Alpha language) as:
    x3 = JacobiSN[EllipticF[ArcSin[x1], d] + EllipticF[ArcSin[x2], d], d]
or more simply in regular notation:
    x3 = sn(F(arcsin(x1), d) + F(arcsin(x2), d), d)
The 'd' is the same 'd' as the Edwards curve definition on Wikipedia.  It
turns out that sn(a, d) is the inverse of F(arcsin(x), d), so this is just
Finv(F(a) + F(b)).  The x coordinates map to an actual ellipse.  I probably
had multiple mistakes (I often do), but I had a plausible mapping to the
circle group figured out, so I coded it in Python to see if it worked, and
naturally it failed.  The error was a little funny.  I relied on what
is surely the very well known Farooque equation for arc length of an
    L = pi/(2*sqrt(2))*sqrt((x2-x1)^2 + (y2 - y1)^2).
Other than the constant pi, that's all modular arithmetic friendly, and we
can eliminate the pi by working in degrees rather than radians.  As you
probably know, the arcsin of any algebraic number results in an algebraic
fraction of pi, and I suspect there is a similar thing going on here.
After a bit of geometric hand-waving, I had a potential mapping.  Of
course, the Farooque formula turned out to be wrong.  There's no known
closed form solution for the arc-length of an ellipse.  Well, duh, I guess
I know that now :-p
By the way, the u parameter in elliptic integrals can be thought of as the
average radius over the sector, times the angle, which I think of as an
"effective arc length".  It would be the arc length along a circle of the
average radius.  Not sure how that helps, but it's a nice geometric image.
Also, we can easily map Edwards curve points onto the ellipse and work
there.  Oddly, it seems like we just need to leave out the y coordinate,
unless I've made a mistake, which is likely, though I did check several
points, and the Edwards addition law matched the one above to many decimal
places.  The X coordinate appears to follow this equation exactly, at least
in the upper right quadrant.
I'm beginning to feel better about the security of ECC (though I was
worried when writing that Python code yesterday.  The linear techniques
used against the circle group seem to fail here, and I don't know what to
try next.  I worry there's some magical "Complex Elliptic Analysis"
mathematics we haven't discovered yet which will succeed in mapping this to
regular DLP, but I also worry we haven't found the most awesome factoring
and regular DLP solving algorithms yet.  Even I was able to come up with
several ad-hoc speed-ups for factoring, though none as good as the best
algorithms known.  Like everyone else, I have not found any heuristic to
speed up attacks on ECC.
I admit it is difficult.

@_date: 2016-04-07 09:16:00
@_author: Bill Cox 
@_subject: [Cryptography] At what point should people not use TLS? 
Noise Pipes looks very cool, but I cannot find any source code used by
WhatsApp that implements Noise Pipes.  Can any of you folks find it?  I am
interested in trying to understand the security of their implementation,
but can't find the source code.

@_date: 2016-04-08 05:52:38
@_author: Bill Cox 
@_subject: [Cryptography] At what point should people not use TLS? 
I agree it is likely their implementation is closed source, at least for
now.  If true, that's a shame, especially since they have made at least one
rookie mistake already, by not using ZRTP-style hash commitments.  It makes
me worry their crypto is vulnerable.

@_date: 2016-04-08 06:18:07
@_author: Bill Cox 
@_subject: [Cryptography] Silly idea for WhatsApp MitM protection for the 
WhatsApp's first rookie crypto mistake that I see is not using ZRTP-style
hash commitments.  This means:
- Users have to verify a 60 digit code rather than a 4 digit code to prove
there is no MitM
- Users can be fooled by a MitM that forces the first and last several
digits of the 60-digit codes to be the same
They also do not warn users when the other party changes their public key,
making a MitM attack very likely to succeed against the large majority of
users.  So, here's to trivial suggestions, and one silly idea to fix their
MitM problem
- Use hash commitments and reduce their code to 4 digits
- Warn users to verify the code when the other party's public key changes
And since 99.9% of users will ignore all that anyway, consider the
following additional silly idea:
They could display an animated game of some sort in the title bar which
proceeds pseudo-randomly, based on the shared secret.  The game could be
hands doing rock-paper-scissors or kittens chasing each other, and when one
side scores there could be an animated victory dance.  The idea is to make
it just intrusive enough that casual users mention the progress of the
game, which will only make sense to the other person if there is no MitM,
because the MitM would cause the game seeds to be different.  If the users
discover that the scores don't match, they should kill the connection,
which should be the advice shown to the user when they click on the game.
If the QR code is scanned to prove there is no MitM, the game would go away.

@_date: 2016-04-08 09:18:53
@_author: Bill Cox 
@_subject: [Cryptography] At what point should people not use TLS? 
I read through this code briefly, and it clearly does not implement the
Noise Protocol as currently specified.  For example, it sends signatures
rather than authenticating by using static DH key shares.  I saw no mention
of the Noise Pipe tokens, and the words noise and pipe do not appear in the

@_date: 2016-04-08 11:44:20
@_author: Bill Cox 
@_subject: [Cryptography] Text of Burr-Feinstein encryption backdoor bill 
IANAL, but it seems clear from the rest of the text that this bill would
specifically outlaw all strong encryption, not just end-to-end encryption.
It has no exceptions for open-source, so all full disk encryption products
would become illegal, as would programs such as WhatsApp, iMessage,
TrueCrypt and gnupg.  My personal laptop has an Intel SDD with full-disk
encryption, which would no longer be available for sale.  My work laptop
uses LUKS disk encryption, which looks like it also would become illegal,
since LUKS has no known back door.  The recent proposal to allow a
combination of several governments to decrypt data when they cooperate to
do so would also be illegal, since this law requires that the US government
can do it alone.
I have never understood Dianne Feinstiein's opposition to encryption, which
she has fought since the 1990s.  Why we continue to vote for such a
non-technical dork to represent California is beyond me.

@_date: 2016-04-08 13:02:58
@_author: Bill Cox 
@_subject: [Cryptography] Silly idea for WhatsApp MitM protection for the 
Hi, Trevor.  Not that I'm an expert, but what I've seen so far of your
Noise Protocol looks good to me.  I recommended it as a potential solution
to a problem yesterday.  Do you know if the Noise Pipes implementation in
WhatsApp is open-source?  I think several of us on this list would like to
take a look and help WhatsApp find any implementation flaws.  Also, kudos
to the WhatsApp team for enabling end-to-end encryption by default.
The QR code feature is cool.  I doubt many users will use it.  I tried it
out yesterday with my dad, and it is simple enough to use, if you are in
the same location.
What if you only display the SAS (or something more interesting randomly
selected based on the SAS) after sending the second message?  I assume the
second message is better protected than the first message in any case,
since that's when ephemeral secrets are in place.

@_date: 2016-04-08 20:35:30
@_author: Bill Cox 
@_subject: [Cryptography] At what point should people not use TLS? 
While I empathise with the motivation for a clean slate TLS, I doubt Google
is moving away from TLS.

@_date: 2016-04-13 16:12:48
@_author: Bill Cox 
@_subject: [Cryptography] TLS 1.3 PSK 0-RTT with replay protection seems 
misconception that 0-RTT is unsafe in many ways regardless of how it is
used in TLS 1.3.  Almost all discussion seems to focus on 0-RTT when used
with stateless servers.  However, severs with "replay protection" can
provide solid perfect forward secrecy, in addition to replay protection.
An initial 1-RTT handshake can do full client auth.  Master secrets are not
reused between connections, and instead a resumption master secret is used
that ratchets secrets forward to resume.  Replay protection based PSK 0-RTT
which essentially emulates TLS 1.2 session resumption from cache, provides
similar security with some differences, some better, some worse.
I think we should discuss PSK 0-RTT enabled servers with replay protection
more.  I think this should become the default 0-RTT mode supported by TLS
server libraries.  The stateless version is needed for improved scalability
by some expert users, but the safer stateful mode with replay protection
should be used by most organisations.  It deserves more attention than it
is getting IMO.

@_date: 2016-04-23 03:30:41
@_author: Bill Cox 
@_subject: [Cryptography] Fun crypto puzzles, one easy, two impossible 
Puzzle 1:
Can you find the backdoor in this ECC addition law?
    x3 = x1y1y2x2/(y1y2 - x1x2)
    y3 = x1y1y2x2/(x1y2 + y1x2)
I attached a simple Python program that does Diffie-Hellman key agreement
using this.  If you publish a public key using this, I can reveal your
secret for short keys, say < 300 bits, because this group is equivalent to
regular DLP.
Puzzle 2:
You are given a prime p and as many digits of 1/p as you want, starting at
digit n.  Find n.  If you can do this, you have solved the discrete log
problem, and the MiB (Men in Black) have a ton of data in Utah they would
like you to help decrypt.
Puzzle 3:
Find functions X(x, y) and Y(x, y) such that:
  X(x, y)^2 - Y(x, y)^2 = X((x^2 - y^2)/(2 - x^2 - y^2), 2xy/(x^2 + y^2))
  2X(x, y)Y(x, y) = Y(x^2 - y^2)/(2 - x^2 - y^2), 2xy/(x^2 + y^2))
You can use addition, multiplication, subtraction, division, n-th roots,
raising to n-th power, and any other modular arithmetic friendly buttons on
your HP-41c calculator.  Avoid sin, cos, factorial, and other functions
that we do not know how to efficiently compute mod p, where p is 256-bit
prime number.
If you succeed, then you have implemented a crucial step in breaking
elliptic curve crypto.  The MiB will almost certainly want to chat.
Have fun!

@_date: 2016-04-23 03:45:05
@_author: Bill Cox 
@_subject: [Cryptography] Fun crypto puzzles, one easy, two impossible 
In problem 2, note that p is a large prime number, probably around 2048
bits.  Solving problem 2 for p = 31 does not count.
Are there any other goobers in my problem statements?

@_date: 2016-04-23 14:54:26
@_author: Bill Cox 
@_subject: [Cryptography] Fun crypto puzzles, one easy, two impossible 
Note that if you restrain this to the circle, it works out:
    x^2 + y^2  = 1, X(x, y) = x, Y(x, y)  = y
This is a sub-case of an Edwards curve, with d = 0.  For d != 0, an
alternate form of the equations is:
  X(x, y)^2 - Y(x, y)^2 = X((x^2 - y^2)/(1 - dx^2y^2), 2xy/(1 + dx^2y^2))
  2X(x, y)Y(x, y) = Y((x^2 - y^2)/(1 - dx^2y^2), 2xy/(1 + dx^2y^2))

@_date: 2016-04-30 03:45:26
@_author: Bill Cox 
@_subject: [Cryptography] Fun crypto puzzles, one easy, two impossible 
Answer to 1st one and explanation of other 2 below.
Puzzle 1:
Can you find the backdoor in this ECC addition law?
   x3 = x1y1y2x2/(y1y2 - x1x2)
   y3 = x1y1y2x2/(x1y2 + y1x2)
I attached a simple Python program that does Diffie-Hellman key agreement
using this.  If you publish a public key using this, I can reveal your
secret for short keys, say < 300 bits, because this group is equivalent to
regular DLP.
Let's attack this cryptosystem and break it.  This formula should look
familiar.  Here's the Edwards curve equation used in curve25519 (modified
to go counter-clockwise from (1, 0), like all the rest of our mathematics):
   x3 = (x1x2 - y1y2)/(1 - d*x1y1x2y2)
   y3 = (x1y2 + x2y1)/(1 + d*x1y1x2y2)
Breaking the Edwards curve equation appears very hard, but the same attacks
can be used against both sets of equations.  Let's attack the first set.
Both of these equations look similar to the circle group addition law:
   x3 = x1x2 - y1y2
   y3 = x1y2 + x2y1
The circle group is well known to be equivalent to regular DLP.  In
particular, the position of m*G, where m is a scalar and G is the generator
point, is simply:
   P = G^m mod p
where G is represented as a complex number x + i*y rather than as a point
(x, y).  This is simply DLP when using complex variables, which has been
shown to be equivalent to regular DLP in complexity.
Here's the attack: Let's see if there is any variable substitution that can
convert the circle-group-like addition laws into the regular circle-group
addition laws.  To simplify our attack, let's focus on the point doubling
equations.  If we find a substitution that turns one point doubling
equation into another, it will likely also work for the addition
equations.  The point doubling equations are:
Circle doubling:
   x2 = x^2 - y^2
   y2 = 2xy
Puzzle doubling:
   x2 = x^2y^2/(y^2 - x^2)
   y2 = x^2y^2/(2xy) = xy/2
Edwards doubling:
   x2 = (x^2 - y^2)/(1 - d*x^2y^2)
   y2 = 2xy/(1 + d*x^2y^2)
To convert one set of doubling equations into another, we can try a
variable substitution.  Thats where we find a function F(x, y) = (X(x, y),
Y(x, y)) which is invertible at least a significant fraction of the time.
We use F to modify the doubling equation for the circle group like this:
   x2 = Xinv(X(x, y)^2 - Y(x, y)^2, 2*X(x, y)*Y(x, y))
   y2 = Yinv(X(x, y)^2 - Y(x, y)^2, 2*X(x, y)*Y(x, y))
If we assume that X is a function of only x, and Y is a function of only y,
then this simplifies to:
   x2 = Xinv(X(x)^2 - Y(y)^2))
   Y2 = Yinv(2*X(x)^Y(y))
For example, we can let X(x) = x^2, and Y(y) = y^2.  This leads to:
   x2 = sqrt((x^2)^2 - (y^2)^2) = sqrt(x^4 - y^4)
   y2 = sqrt(2*(x^2)*(y^2)) = xy*sqrt(2)
These are perfectly valid addition equations, which create a group that is
trivially isomorphic to the circle group, which is why we dont bother to
do this to in real cryptosystems.
To convert the puzzle doubling to regular circle doubling, we need the
equations to satisfy:
   x^2 - y^2 = Xinv(X(x, y)^2*Y(x, y)^2/(Y(x, y)^2 - X(x, y)^2), X(x,
y)*Y(x, y)/2)
   2xy = Yinv(X(x, y)^2*Y(x, y)^2/(Y(x, y)^2 - X(x, y)^2), X(x, y)*Y(x,
Assuming X depends only on x, and Y depends only on y (a poor assumption
generally), then we need:
   x^2 - y^2 = Xinv(X(x)^2*Y(y)^2/(Y(y)^2 - X(x)^2))
   2xy = Yinv(X(x)*Y(y)/2)
For example, letting X(x) = x and Y(x) = y is close.  The second equation
becomes xy/2, only off by a factor of 4, which can be fixed by letting X(x)
= 4x, but then the first equation is not satisfied.
What else can we try?  From the 2xy equation, it looks like equations where
Y x*y) = Y(x)*Y(y) are promising.  What variable substitutions have this
property?  It turns out that F(x*y) = F(x)*F(y) when F(x) = x^n:
   F(x*y) =(x*y)^n = x^n*y^n = F(x)*F(y)
To solve this puzzle, it is enough to try a few values of n.  In
particular, if we use X(x) = 1/x and Y(y) = 1/y, we get:
   Yinv(X(x)*Y(y)/2) = 1/((1/x)*(1/y)/2) = 2xy
which is what we want, so its worth checking the other equation:
   Xinv(X(x)^2*Y(y)^2/(Y(y)^2 - X(x)^2)) = 1/((1/x)^2*(1/y)^2/((1/y)^2 -
       = ((1/y)^2 - (1/x)^2))/((1/x)^2*(1/y)^2)
       = x^2 - y^2
which is also what we want.
So, the puzzle is simply the circle group morphed with the variable
substitution X = 1/x and Y = 1/y.  Applying this technique to attack
Edwards curves is actually Puzzle 3.  Good luck :)
Puzzle 2:
You are given a prime p and as many digits of 1/p as you want, starting at
digit n.  Find n.  If you can do this, you have solved the discrete log
problem, and the MiB (Men in Black) have a ton of data in Utah they would
like you to help decrypt.
I should have made it clear that someone else gives you digits starting at
digit n without telling you what the value of n is.  Anyway, this is simply
a restatement of the discrete log problem.  If you solve it, it would be
The conversion is simple.  The DLP problem is typically stated as finding
n, given 2^n mod p, where p is a large prime.  Other generators than 2 can
be used, but it does not matter, so lets use 2.  Imaging we compute this
sequence, all mod p:
   2^1, 2^2, 2^3, 2^4, , 2^(p-1)
Let's print a binary number between 0 and 1. Start by printing ..  To
compute the list, we multiply the prior value by 2, and if it is larger
than p, we subtract p. If we subtracted p, then print 1.  Otherwise,
print 0.  The resulting string is the binary representation of 1/p.  If
we were able to find a matching subsequence in the digits of 1/p, given at
least log2(p) digits, then we would find n, solving the DLP problem.
Again, good luck :)
Puzzle 3:
Find functions X(x, y) and Y(x, y) such that:
 X(x, y)^2 - Y(x, y)^2 = X((x^2 - y^2)/(2 - x^2 - y^2), 2xy/(x^2 + y^2))
 2X(x, y)Y(x, y) = Y(x^2 - y^2)/(2 - x^2 - y^2), 2xy/(x^2 + y^2))
See the description of puzzle 1.  Note that I did not assume X and Y depend
on only x and y as I did in puzzle 1.  This form covers all possible
variable substitutions.  Does a solution exist?  Yes! Mathematically, we
know we can map Edwards curve ECC groups onto the circle group with a
continuous differentiable function in such a way that every point in the
Edwards curve group land directly on top of corresponding points in the
circle group.  However, no one knows what that function could possibly be,
and it is conjectured that we cannot compute it in any realistic time on
realistic classical computers when the group has on the order of 2^200
elements or more.
Trying to find a solution to this puzzle is leading me in some cool
directions.  Im sure it is all well understood mathematics.  Ill ask if
anyone can point me to the relevant field of mathematics in another post.
So far I have only found out about the study of equivalence classes of
functions given birational variable substitutions. It has to do with
"algebraic varieties" and a lot of Jacobi's work, which I have not yet
read.  However, it looks like Jacobi's results are enough to solve puzzle 1
without having to guess X(x) = 1/x and Y(y) = 1/y like I did above.
Instead, we simply guess that the substitution has the form P(x, y)/Q(x,
y), where P and Q are polynomials.  However, birational mappings do not
cover all possible variable substitutions. For example, I can create a
simple group equivalent to the circle group using X(x) = sqrt(x + y), and
Y(x) = y, which is not birational.
Have we proven that no birational substitution can convert an Edwards group
into the circle group? I have not seen how to solve this problem for more
general substitutions.

@_date: 2016-04-30 04:17:29
@_author: Bill Cox 
@_subject: [Cryptography] Mathematics of variable substitutions? 
I was hoping someone could point me in the direction of relevant
mathematics where we examine what equations can be converted to other
equations using variable substitutions, in ways that are efficiently
computable modulo a prime.  For example, we can easily convert an Edwards
curve into a circle with the substitution z^2 = x^2(1 + y^2).  However,
this substitution does not cause the Edwards addition law to become the
circle group addition law.  It becomes something cool, but the equations
are no more efficient than computing the regular Edwards addition law.
Has it been proven that no birational substitution can convert the Edwards
addition law into the circle group addition law?  The circle group addition
law is:
    x3 = x1x2 - y1y2
    y3 = x1y2 + x2y1
The Edwards addition law (with the origin properly set to (1, 0) rather
than (0, 1)) is:
    x3 = (x1x2 - y1y2)/(1 - d*x1y1x2y2)
    y3 = (x1y2 + x2y1)/(1 + d*x1y1x2y2)
These seem similar, so it is natural to ask if there is any efficiently
computable variable substitution that maps one to the other.  Clearly there
is such a substitution, since we know we can continuously morph the points
on the Edwards curve that are in the group to the points of the circle
group at least when the points do not wrap around the curve more than once,
which turns out not to be a significant limitation.
It looks like it is enough to do is map the doubling equation onto the
circle doubling equation, which is a simpler problem.  The Edwards point
doubling equation for points in the upper right quadrant can be expressed
in terms of the X coordinate like this:
    x2 = -(x^4 + 2x^2 - 1)/(x^4 - 2x^2 - 1)
Similarly, the circle group doubling equation is:
    x2 = 2x^2 -1
To be able to use the circle doubling equation to compute the Edwards
doubling equation, we have to find a function F(x) such that:
    2*F(x)^2 - 1 = F(-(x^4 + 2x^2 - 1)/(x^4 - 2x^2 - 1))
To work on this, I seem to need modular-arithmetic friendly identities such
    F(a*b) = F(a)*F(b) when F(x) = x^q for any rational q
    F(a*b) = F(a) + F(b) when F(x) = log(x) (I assume I can solve DLP
efficiently, since I'm attacking ECC which uses small keys)
    F(a + b) = F(a)*F(b) when F(x) = g^x
This feels a bit like solving integrals, but I don't know the rules.  Where
can I read about this?

@_date: 2016-04-30 04:22:05
@_author: Bill Cox 
@_subject: [Cryptography] Mathematics of variable substitutions? 
I meant to say that clearly a mapping exists, but not that an efficient
mapping exists.

@_date: 2016-04-30 04:56:06
@_author: Bill Cox 
@_subject: [Cryptography] Mathematics of variable substitutions? 
This is only for d == -1, which is a simplification I've been using.  For d
!= 1, the equation is:
(-d x^4 + 2x^2 - 1)/(d x^4 - 2d x^2 + 1)

@_date: 2016-04-30 14:20:09
@_author: Bill Cox 
@_subject: [Cryptography] sha1sum speed 
SHA256 has some Intel HW instructions.  However, from my latest benchmarks,
it is still a lot slower than BLAKE2b on CPUs with SSE or AVS enabled.
I don't think so.  IIRC, the BLAKE2b implementations are side-channel
They are to me!  People still use MD5 for the speed, when they should
upgrade to more secure hashes.  That's why I am particularly excited about
BLAKE2b (and BLAKE2's other flavors).
I'm working a bit with the HighwayHash authors, playing with what we can do
using AVX2's parallel multiplication and byte shuffling.  It's very fast.
However, the BLAKE2 functions are very well analyzed and are ready for
secure deployment now.  Any new function will take years to get there.
 b2sum runs faster than md5sum on all my machines.  The parallel versions
(BLAKE2bp and BLAKE2sp) are even faster.

@_date: 2016-08-30 16:47:29
@_author: Bill Cox 
@_subject: [Cryptography] N. Korean radio broadcasts string of random 
If by amateur radio, you mean ham radio, then I strongly recommend you do
not do that.  The FCC will be there in short order, though some hams I know
say they don't show up soon enough.

@_date: 2016-12-05 09:36:19
@_author: Bill Cox 
@_subject: [Cryptography] Final words on RNG design 
I agree 100%.  This is the main ingredient that is missing on almost all
systems.  A typical user-system running Linux will eventually collect
enough entropy from IRQ timing to seed the CPRNG.  This is highly
auditable, but the speed varies greatly between systems, and is too slow to
ensure availability at boot time everywhere.
Unauditable TRNGs seem to be available on most systems that run Linux,
including the Raspberry Pi. We give Intel a hard time about their
non-auditable TRNG, but they simply did the same thing as nearly every
other manufacturer, and keeps the details of their TRNG secret.  Somehow,
this needs to change.

@_date: 2016-12-05 17:26:12
@_author: Bill Cox 
@_subject: [Cryptography] Is Ron right on randomness 
There is still something wrong.  I've tried a more recent 4.4.0-51-generic
kernel in Ubuntu 14.04, with no luck.  There is no SYS_getrandom syscall
available through the syscall function, nor getrandom in libc.  I'm running
x64.  I see this:
sys_getrandom, sys_getrandom)
So, it looks like it is in the kernel.  Here's the latest code I tried to
compile with gcc -Wall foo.c:
 _GNU_SOURCE
    int main() {
    unsigned char buffer[32];
    int numBytes = syscall(SYS_getrandom, buffer, 32, 0);
    printf("bytes read = %u\n", numBytes);
    return 0;
This gives:
foo.c: In function main:
foo.c:10:28: error: SYS_getrandom undeclared (first use in this function)
     int numBytes = syscall(SYS_getrandom, buffer, 32, 0);
                            ^
foo.c:10:28: note: each undeclared identifier is reported only once for
each function it appears in
Various combinations of includes also fail.  There is no instance of
getrandom under /usr/include.
How can I access getrandom?  Is this a Debian/Ubuntu bug?

@_date: 2016-12-15 22:29:36
@_author: Bill Cox 
@_subject: [Cryptography] Is glibc right on randomness 
Awesome!  Before this thread started, I had not heard that DjB worked with
the Linux folks to provide ChaCha-20 (in 2016) for urandom, or that
getrandom had even been written (in 2014).  I guess now I can stop griping
about the Linux entropy pool.  Kudos to those who made it happen!

@_date: 2016-02-08 08:35:26
@_author: Bill Cox 
@_subject: [Cryptography] New block cipher competition 
Is this because we can do faster hashing/encryption per byte on very large
blocks?  This turns out to be true, but AFAIK, it is not a well known or
understood issue.
If we have a 512 bit block hash and apply it to 64KiB mega-blocks, we can
get the same security using fewer hashing rounds in the 512-bit hash.  For
example, we can use 1/6 the rounds, and hash the 64KiB twice in such a way
that any message change in the first pass is at least 6 hashes away from
any resulting change in the second pass, giving an equivalent hashing
strength as a single pass with full rounds.  That would give us ~3X speedup
assuming we are computation bound.  The memory access pattern is more
complex than one would think because we have to ensure that the resulting
data dependency graph has no loops of < 6 nodes in this case, and the nodes
can be on either pass.  For example a bit-reversal access pattern (like we
used in Catena-1) in the second pass does not work (there are loops of size
4).  A pattern more like Gambit's does seem to work (using a step size of 6
in this case), IIRC.
Is something like that what you had in mind?

@_date: 2016-02-12 10:16:47
@_author: Bill Cox 
@_subject: [Cryptography] [Crypto-practicum] Justify the sequence of 
I'll second this, assuming that this works for this disk encryption
application we enough.  If using CXR mode on a UNIX system where users are
allowed somehow to read the encrypted disk contents, I can modify my
plaintext sector to be encrypted the same way as any other sector, and if I
just need to know if your data is A or B, I can figure that out in two
That said, I strongly prefer CTR to XTS mode.  XTS is malleable, and should
not be used.  Also, it has the same chosen plaintext attack, so CXR mode is
no worse in this case.  If we cannot have more bytes per sector for AEAD,
then I think I prefer CXR mode, simply because it is not malleable, even
with the chosen plaintext weaknesses.
It is not possible to avoid this chosen plaintext attack without an IV.
Without an IV, the attacker can always create cleartext that will encrypt
the same as your disk sector, if the attacker can guess what the cleartext
is.  So, if we can have extra bytes, use Chacha20-Poly1305.  Otherwise, I
recommend a slight change to CXR mode:
The case of storing incrementing binary numbers at the end of each sector
might actually occur now and then accidentally.  So, just use a simply
non-cryptographic function of the counter instead:
    Ciphertext = E(H(counter) XOR Plaintext, key)
Where H is something super-fast and simple, like:
   H(x) = (RAND_CONST ^ x) * ODD_RAND_CONST
This is a permutation for any RAND_COST, and odd ODD_RAND_CONST.  I would
not expect any unintentional collisions for large bit-lengths, but 64 bits
seems good enough.  A different H should be chosen for hardware-based

@_date: 2016-02-12 15:16:49
@_author: Bill Cox 
@_subject: [Cryptography] [Crypto-practicum] Justify the sequence of 
You can use an ultra-fast randomized hash function because the key is
unknown to the attacker.

@_date: 2016-01-01 12:50:34
@_author: Bill Cox 
@_subject: [Cryptography] Nu supr unbrakable cripto 
Works for me :)  If a proper MAC were added, it could be faster and simpler
to just use the hash function in counter mode to generate data for a stream
cipher, with the only real downside being a stronger dependence on the
unpredictable nature of the nonce.  Two files with the same nonce and key
XORed together are just the plain texts of the files XORed together.  The
extra work in the block cipher has some use.

@_date: 2016-01-05 08:35:00
@_author: Bill Cox 
@_subject: [Cryptography] How can you enter a 256-bit key in 12 decimal 
It actually _can_ be done reasonably well, but I have never seen it in a
FDE product before.  A 12-digit decimal pin is nearly 2^40, well above the
number of combinations we typically need to try to guess a typical
password.  If the hardware were specifically designed to strengthen this
pin well, it could be secure.
For example, it could reserve a 100MiB for a ROM and use maybe 1MiB of RAM
and do a 1-second memory-hard hash, and use some operation the hardware
does fast for compute-time hardening.  If done well, an attacker might have
to spend 100ms per guess, and 3000 years worth of compute time on a machine
with 100MiB of ROM and 1MiB of RAM to crack the pin.  Not great, but not
terrible either.
OTOH, even our software FDEs, which I expect to be better than most
embedded closed-source solutions, does not get it quite right, at least not
yet.  LUKS for example has a long-term plan to switch to Argon2, which
should be an excellent solution for this use case, but for now, all they do
is PBKDF2-SHA1 for a fraction of a second.  They're switching to
PBKDF2-SHA256, but not for security reasons, but because SHA1 is going
away.  BitCoin mining ASICs prove we can do 1 GH/s for about $2 in
hardware.  The electricity actually costs more than the hardware.  If we
crank the numbers on the security level LUKS can achieve for sub-second
hashing using PBKDF2, it's not pretty when there is an ASIC attack.  An
ASIC attacker has something like a 1,000,000 to 1 cost advantage over the
defender, and at the same time may be willing to spend 1,000X more than the
defender.  Given most users choose passwords with < 30 bits of difficulty
to guess, an attacker may be able to crack most stretched passwords in < 1
second.  Even a GPU attack looks reasonable against PBKDF2-protected FDE
Here's a lame FDE story about me.  I had a paranoid password on my Intel
FDE-SSD in my laptop, which I've since given to my son for use in school.
Every time the battery goes dead, which is about once a week, he has to
re-entry my crazy long high entropy password.  The Intel FDE disk cannot
change the password without wiping the drive (LUKS gets this part right),
and I don't have time to do a full OS re-install.
So, guess where my stupid supler-long painful password lives now?  It's
taped to the laptop.  The complaint I get now is that I taped it on the
bottom, and it is hard to flip the laptop over, type a few characters, flip
it again, and so on.  He wants it taped to the screen.

@_date: 2016-01-05 14:30:42
@_author: Bill Cox 
@_subject: [Cryptography] How can you enter a 256-bit key in 12 decimal 
D'oh!  My mistake!  I read on the Lenovo help page that I cannot reset the
SSD key without losing all the data.  If I had read a bit more carefully, I
would have seen that this refers to the disk encryption key only, and not
the password used to decrypt the drive.  The same FAQ mentions that all I
have to do is go into the BIOS settings to change the disk encryption
Thanks, Darren Lasko, for pointing out my error!  I'll go change the
password later today.  My son would thank you!
Now, apparently Darren knows a thing or two about disk encryption :)
 Darren, is there any chance you want to chime in?

@_date: 2016-01-10 06:38:39
@_author: Bill Cox 
@_subject: [Cryptography] A possible alternative to TOR and PrivaTegrity 
This is an old idea, but perhaps now there might be more reason to consider
it.  I currently call this idea Alias.  Here's my dumb data-dump on it.
Alias is a concept for a TOR-like Internet protocol supporting free speech
and user privacy, but without encouraging the worst evil behaviors.  Exit
Nodes are replaced with Public Gateways, which sponsor users.  The
definition of evil behavior is defined by the Public Gateways and operators
of routing nodes.  Users would be encouraged to use good behavior, as their
public alias would develop a reputation over time.  Anonymity would be
protected, but a user's Public Gateway and any routing node could refuse to
route data for aliases with poor reputations.
TOR was created with a lofty goal: to support free speech.  Unfortunately,
TOR has drawn attention from governments and law enforcement, as it could
be used to protect some of the worst activities, such as contract killing,
and the slave trade.  TOR Exit Node operators generally follow a strict
policy of never looking at traffic, because simply observing this traffic
would require Exit Node operators in most countries to regularly contact
law enforcement to report crimes.  PrivaTegrity is an alternative protocol
to TOR, which aims to find a balance between protecting free speech and
protecting the world from the worst behavior.  Unfortunately, the
PrivaTegrity inserts encryption backdoors.
Alias Design:
This is very much a dumb idea in the half-baked stage.  Feedback and ideas
are welcome.
Alias would be a fork of TOR, and route Internet traffic from a user's
machine through a couple of Routing Nodes, to a Public Gateway, which
replaces the Exit Node.  The Public Gateway would have an account for the
user, under a pseudonym used on Alias network by the user, called his
alias.  The Public Gateway should keep an email contact address for the
user, similar to regular accounts on various web sites.
In Alias, user aliases would have trackable reputations, and the
reputations of user aliases would be combined into a reputation for a
Public Gateway.  At a minimum, incident reports would be used to compute
user reputations.  Exactly how this works is TBD, but the goal is to cause
gateways with very poor reputations to be effectively blacklisted by
routing nodes, and for users with poor reputations to be dropped by
reputable gateways.  Users could move their alias from one gateway to
another when needed, but they could not erase what their previous gateway
knows about there identity.  The Gateway would not know a user's location,
and in many cases will know nothing other than the user's reputation and
email address.  When requested by a government authority, at a minimum, a
gateway can drop support for a user alias, causing that alias to try to
find a new gateway that will agree to sponsor it.
Participants who act as routing nodes in Alias would be able to select what
sort of reputations they require from aliases and Gateways to allow traffic
to be routed through them to those gateways.  They could, for example,
choose to not route data for any gateway with a high reputation for routing
to pornography sites.
I compare the TOR, PrivaTegrity, and Alias concepts in several "threat
cases" below:
Threat Case: Governments Overreact to Terrorism
In this case, we assume all the governments involved have decided to share
all user network traffic in a mass surveillance program.  The user Alice
has something to say, such as wanting to tell the world that the mass
surveillance program exists.
TOR:  Alice succeeds in using TOR to log into various blogging sites and
publishes her knowledge about the surveillance program.  Unfortunately, TOR
provides limited defense against the Men in Black (MiB), and Alice may be
arrested.  The MiB is assumed to compromise TOR in various ways, such as
operating many Exit Nodes and monitoring meta-data such as packet timing
and size between nodes.
PrivaTegrity:  With the assumption that all governments involved are
colluding, Alice is revealed directly, without having to subvert the
Alias:  Alice needs a Public Gateway to sponsor her.  She can choose a
gateway with a reputation of sponsoring free speech, such various
newspapers, in a country that is not participating in the mass surveillance
program.  When Alice posts what she knows to various blogs, the Public
Gateway (newspaper in this case) will be the the one defending her
anonymity.  In any case, even if the newspaper is forced to reveal what
they know about Alice, they never knew her location.
Conclusion: Alias seems to provide better protection of free speech in this
Threat Case: A Single Government Blackmails the Rest
Suppose one of the governments involved decides to use its influence in
the protocol to blackmail one or more of the other governments involved
into agreeing to some political agenda.
TOR: If the government were the USA, it might have unique powers to track
users through the TOR network.  If true, the USA could refuse to reveal a
French suspected terrorist unless the French government share mass
surveillance data collected on its citizens.  Is this sort of thinking too
PrivaTegrity:  With nine separate governments who must collude to expose a
user, it is possible for any one of the nine to blackmail the rest.  For
example, if tracking down a particular user is of critical importance to
one government, another could demand certain trade policies be agreed to
before allowing that user to be revealed.
Alias:  A country containing the Public Gateway sponsoring a user might
make political demands from another country before agreeing to force the
Public Gateway to reveal a users email address.  However, this coercion is
weaker than weaker than the TOR case because there is no country with
majority control, and weaker than the PrivaTegrity case because a
government can coerce cooperation only from Public Gateways in its country.
Conclusion: While none are immune to this threat, Alias seems to perform
better in this case.
Threat Case: Hackers Compromise the Network
In this case, a group of hackers wants to reveal the identity of a
particular user.
TOR: There is little chance that the attacker can hack all the nodes from
the user to the Exit Node, and since the Exit Node has no information about
the user, there seems to be little chance that the hacker can reveal the
users identity, short of bugs in the protocol.
PrivaTegrity:  While hackers might hack one or more of the nine
governments, it would be a considerable task for the hacker to hack them
all.  However, it is possible, and this is a weakness vs TOR.
Alias:  The hacker need only hack the users chosen Public Gateway, which
is a considerably simpler task than with PrivaTegrity.
Conclusion:  Hackability of Public Gateways is a significant weakness for
Alias compared to the other two.
Threat Case:  Evil Users Secretly Collude
In this case, suppose there is strong evidence that several evil users
wants to collude to do something terrible, and they want to communicate
anonymously.  For example, they could be running a contract-killing
business or enslaving people and selling them on the Dark Web.
TOR:  Unfortunately, evil behaviors have been enabled in some cases over
PrivaTegrity:  The users involved in such evil activities can have their
communication secretly wiretapped.  This is a strong capability for law
enforcement in this case.
Alias: Assuming reputable Public Gateways are used, most of the users
emails would be revealed to law enforcement.  This is weaker than a wiretap.
Conclusion: In the case of severe evil, PrivaTegrity performs the best,
Alias next best, and TOR the worst.
Threat Case:  Somewhat Evil Users Secretly Collude
What is evil vs good is highly subjective, and getting people to agree can
be difficult.  In this case, the users are engaged in what most reasonable
people consider evil.  For example, consider illegal trade in ivory, which
could lead to the extinction of wild elephants.
TOR:  Users trading in ivory likely would benefit from using TOR.
PrivaTegrity:  Having to get cooperation from nine governments may be too
painful when tracking down a single ivory trader, and the ivory trader
likely could use PrivaTegrity to their advantage.  If, on the other hand,
the nine governments put in place a rapid rubber-stamp process to enable
going after small-time criminals, then this capability can be highly abused.
Alias:  Ivory traders would avoid using Alias through reputable Public
Gateways, since their identities could easily be revealed and the sites
the traders visit to buy/sell ivory would not likely be very reputable,
lowering their alias' reputation.
Conclusion: Alias seems to perform better at determine somewhat evil

@_date: 2016-01-10 13:52:15
@_author: Bill Cox 
@_subject: [Cryptography] A possible alternative to TOR and PrivaTegrity 
I take back the validating an email part.  I do not see how that would work
out.  It creates too simple of a path to reveal identities, and would
create data on public gateways that would become the target of both hackers
and governments.  The most the public gateways could do is track what users
do with their aliases, and condense web behavior down to a public
This is definitely still in the dumb idea stage :)

@_date: 2016-01-11 17:10:37
@_author: Bill Cox 
@_subject: [Cryptography] TRNG review: Arduino based TRNGs 
Summary: We're not quite ready for generating random numbers for crypto on
Arduinos, at least not without a TRNG shield.  Two libraries for generating
true random numbers are TrueRandom
, and probably_random
.  If you _have_ to generate key
material on an Arduino, it looks like you can do an OK job of it in about 1
The most popular technique for generating true random data is to do what
TrueRandom does, and drive a voltage onto pin 0, and measure it with the
8-bit ADC.  While sometimes this generates unpredictable data, the scatter
plots show scary correlations, and the one thing we know it is not
measuring is thermal noise.  Here is a scatter plot built by the author of
[image: Inline image 1]
The 8-bit ADC in this application does not have enough resolution to
reliably detect any thermal noise.  It is more likely measuring power
supply noise, which could be under the control of the machine powering the
Arduino.  This scatter plot has issues even though some whitening was
applied, so reality is probably much worse.
I like the probably_random page.  The author says, "Disclaimer: I have no
idea what I'm doing."  Honestly, he did a fairly decent job, and only went
wrong when it came time to guess the level of entropy per sample.  This is
fairly good work overall.  On the down side, he is generating only 64 bits
per second, and as we'll see, that is a bit too fast, since there isn't
quite enough entropy there to reliably extract 64 bits/s.
Probably_random 8 reads from the timer to produce one byte, rotating and
XORing each 8-bit sample.  The README states that we assumes there is at
least one bit of entropy per byte, and the scatter plots look
unpredictable.  However, at least on my Arduino Uno, extracting 64 bits per
second is most likely pushing faster than the timer can integrate jitter
noise.  Here's a plot from his web site:
[image: Inline image 2]
That looks pretty good!  However, I prefer to see pre-whitened data to get
a feel for how much real entropy is there from the start.  You can make the
data look random, but you can't make it actually random.  The rotating and
XORing simply hides too much.  Here's a plot using his tester.py code when
I output every sample from the timer without mixing 8 together:
[image: Inline image 3]
This was generated from 65536 8-bit samples from the timer, which normally
would be condensed to 65536 output bits.  Is it true that there is a least
1 bit of entropy per sample?  I could use ent, but ent is absolutely
terrible for finding patterns like we see here.  Ent thinks this plot is
very random.  So, I examined the data manually, and found that most of the
time, given two sequential bytes, I could predict the next byte, by
examining previous cases in the stream.  Clearly most bytes have less than
one bit of entropy.  However, _some_ bytes buck the trend and have a value
that rarely follows the prior two.  The entropy in those bytes is far
higher, so the average can still be over 1.  Here is a program I hacked
together  to determine an upper
bound for entropy per byte in probably_random.  Here's its output when run
on about 120K samples:
./predict16 foo
There seems to be at most 1.029738 bits per byte in this sample
Based on 122368 total samples
num bins: 4795, average hits per bin: 25.52
There is a more non-randomness that my program is not finding, which I
suspect I could find if I put in a few days of effort.  For example,
different 3-sample sequences appear more frequently near each other than
far apart in the sample stream, likely due to whatever global parameters
are drifting to cause the trends we see in the plot above.  So, to be safe,
we need at least 2X margin, so we should back off to 32 bits/s when using
probably_random.  However, this does not take into account variation in
jitter from device to device, or over temperature, or what happens when
running of a nice quiet battery, rather than a noisy laptop USB port.  To
account for these variables, I would prefer to back off another factor of
4X: 2X for process variation, and 2X for the differing environments the
Arduino runs in.
So, I recommend extracting only 8 bits of entropy per second, base on the
limited data I saw today.  I prefer no whitener on the Arduino, and instead
would feed the timer samples into a cryptographic sponge, like Keccak-1600,
but you can use the current probably_random output as-is if you change one
void loop()
  if (sample_waiting) {
    sample_waiting = false;
    result = rotl(result, 1); // Spread randomness around
    result ^= sample; // XOR preserves randomness
    current_bit++;
    if (current_bit == 64)  // Was 8, but I want 8X more samples per output
    {
      current_bit = 0;
      Serial.write(result); // raw binary
    }
  }
If you just need numbers as a seed for a game or something, where there is
no money on the line, feel free to use the original version.  As the author
says, it is _probably_ random :)

@_date: 2016-01-12 09:38:15
@_author: Bill Cox 
@_subject: [Cryptography] TRNG review: Arduino based TRNGs 
I think that would be similar to doing more reads from pin 0.  It might be
possible with 2 or 3 passive external components to make this work with
thermal noise.  The trick would be to have the DC voltage on pin 0 right on
a boundary between two counts of the 8-bit ADC.  A resistor and capacitor
could generate this voltage with the PWM.  Another resistor from the cap to
pin 0 should provide the isolation needed to get reasonable levels of
thermal noise on pin 0.  Then, you'd need some feedback loop in the sketch
where you change the PWM output a bit every time you read a 1 or a 0, and
try to keep the average 1's and 0's the same.
This would still have issues when an attacker might control noise on the
power rails, but running off a battery with clean code, it should work OK.
This design would be similar to Intel's DRNG.
Without any external components, I think the thermal drift of the timers is
the only reliable source of entropy, but it is very low speed.

@_date: 2016-01-13 14:09:03
@_author: Bill Cox 
@_subject: [Cryptography] TRNG review: Arduino based TRNGs 
Yep.  If you are happy with 128-bit AES, I see no reason to be unhappy with
128-bit seeds for CSPRNGs.  I would feel better with 256-bit for both
encryption and random number seeds, but clearly the world seems to run OK
currently on 128 bits.
Well, it wont be in stock for long now that you've plugged it!  Actually, I
prefer to keep it fairly quite, since these things take 29 placements
(including USB pins) to make.  I'm more interested in having a device using
modular entropy multiplication simply being available than actually selling
them.  That's one reason I moved to a hacker-style board without a normal
USB key enclosure and proper connector.
Adding a TRNG to an IC design requires < $0.001 worth of silicon.  For some
reason, almost all the devices I've seen that have TRNGs do not make it
possible to read the raw data from the entropy source.  I think this is a
significant mistake made almost universally in the semiconductor industry,
which generally is very secretive.  Worse, when I do get access to raw data
(such as from probably_random), I more often than not find that the
engineering was not quite done properly (it is apparently somewhat hard to
do), and the result is that the output bits are less random than
advertised.  The marketing claims that devices include "high quality" TRNGs
makes me cringe.  Just give us access to the entropy source, and let us
determine that for ourselves!
The OneRNG designers put in the effort to get the engineering right, and
remains my recommended solution for anyone in need of a USB key TRNG.
As for the minimum required hardware for an Arduino, I have not built it,
but I suspect we could do it with 1 cap and 2 resistors, using the 10-bit
ADC, assuming we could use the PWM to force A0 to a value that keeps
randomly flipping between 0x200 and 0x1FF, by using an RC filter on the PWM
connected through a resistor to A0.  Should cost about $0.03 in components,
though placing a $0.01 resistor often costs $0.25, at least here in the USA.

@_date: 2016-01-13 14:13:32
@_author: Bill Cox 
@_subject: [Cryptography] TRNG review: Arduino based TRNGs 
I should have mentioned that such a solution would still be highly
sensitive to power supply noise.  Good engineering is still required to
ensure it is secure!

@_date: 2016-01-13 15:11:27
@_author: Bill Cox 
@_subject: [Cryptography] TRNG review: Arduino based TRNGs 
AFAIK, there is no such thing as an entropy source that does not require
whitening.  They all produce biased/correlated bits.
You can whiten with simple software schemes, such as was done in
probably_random.  Rotating and XORing bits in from the entropy source
eventually will make your value indistinguishable from perfectly random.
My change above to probably_random left the rotate-XOR in place, and just
does 8X more of them per output byte.
However, CPRNGs do not care.  As long as you feed enough biased/correlated
bits into the CPRNG to seed it, you are in good shape.  My "infinite noise
multiplier" TRNG produces something like 0.85 bits of randomness per output
bit.  I feed 512 of them into /dev/random all at once, so you get > 400
bits of "entropy" all at once, where "entropy" is defined as
1/log2(surprise), where surprise is the probability of seeing the 512 bits
we saw, given a model for how likely it is.  The properties I like about
modular entropy multipliers are:
1) There is a simple model for estimating the entropy in a string of bits,
which is good for health monitoring.  Note that a string of bits
technically does not have entropy - only the channel does, but you can
_estimate_ the entropy.
2) It is fairly robust against power supply noise and other sources of
3) The thermal noise is ensured to be there, based on simple thermodynamics.
Ring oscillator based entropy sources are the most common kind to find in
an IC.  Just put 5 or maybe 7 inverters in a loop to create a ring
oscillator, and sample the output of one of them every once in a while to
see if it is a 0 or 1.  Jitter is caused by various factors, but thermal
noise is always there.  If you don't know the current state of the ring
oscillator (which inverter is in the process of switching), you don't know
whether to speed it up or slow it down to make the next output a 1 or 0.
However, one attack showed that common security ICs using ring oscillator
TRNGs can be controlled through power supply noise, since there is
inductance in the wiring in the ring oscillator, and this is enough to sync
the oscillator to an injected power supply oscillation.  Still, all that is
required to use them securely is good engineering.  Don't let an attacker
inject a large power supply oscillation :)

@_date: 2016-01-13 21:28:30
@_author: Bill Cox 
@_subject: [Cryptography] TRNG review: Arduino based TRNGs 
We have the same concerns here.  That's why I followed this statement with,
"I should have mentioned that such a solution would still be highly
sensitive to power supply noise.  Good engineering is still required to
ensure it is secure!".
There is always thermal noise, which can be quantified.  It is hard to
ensure that thermal noise will dominate over non-random sources.  This is
why zener noise is popular.  It starts with a larger random signal.  Even
better is ring oscillators, which in certain ideal models (lacking
inductance), are nearly immune to external influences.  I _think_ infinite
entropy multipliers are even more resistant, though time will tell.

@_date: 2016-01-14 09:29:22
@_author: Bill Cox 
@_subject: [Cryptography] TRNG review: Arduino based TRNGs 
I did another test on the output from probably_random, which confirms my
suspicion that slightly less than one bit of entropy per byte is generated
by the timer.
One of my main concerns was that sequences of timer samples closer together
in time would be repeated more often, as the drift we see in the timer
could be due to lots of things other than thermal noise.  When looking for
16 byte long repeated sequences, I found one repeated 49 times in a 256KiB
file of sequential 8-bit timer samples.  I compared that to a 256KiB random
file of ASIC '0' and '1' (one bit of randomness per byte).  It had a 16
byte sequence repeated 15 times, but none more than that.
To be safe using timer noise, we must use more than 8 sequential samples
per output byte.  I think 64 might be OK, but more testing is required.  If
someone ran a number of parts in various conditions, like running off a
battery in a Faraday cage, and running with strong injected periodic power
supply noise very close to the frequencey of the on-chip timer oscillator,
I might begin to feel better about using this 8-bit per second modified
version of probably_random for crypto.
As it is for now, all I can say is what the probably_random author said.
The modified version that generates only 8 bits per second is probably
random :)  I do not recommend this hack for crypto without a lot more

@_date: 2016-01-14 21:41:07
@_author: Bill Cox 
@_subject: [Cryptography] TRNG review: Arduino based TRNGs 
I think you would usually be right.  An exception might be the guy who is
running in something close to a Faraday cage off a battery and good bypass
caps, with little non-thermal noise feeding the ADC.  Does anyone know what
the anti-alias filter is like on these parts?  There surely is one, and it
will limit the thermal noise.
As an example, the negative input to the op-amp on my TRNG has 24uV RMS of
thermal noise, based on the 8 MHz bandwidth and resistance.  A 10-bit
Arduino ADC probably has less than 8MHz of input bandwidth due to the
anti-aliasing filter, but I could be wrong.  If it also has 24uV RMS of
thermal noise, a 2V range, and a 10-bit resolution, it will be measuring a
24uV noise source with an ADC with 2mV resolution.  That can be a problem...

@_date: 2016-01-15 16:24:37
@_author: Bill Cox 
@_subject: [Cryptography] TRNG review: Arduino based TRNGs 
It's not the rate of entropy collection, but whether there is _any_ entropy
coming from the source.  A 256 bit key is going to be pretty weak if is a
single 8-bit constant repeated 32 times.  If the input on A0 is
consistently in the center of a 2mV range that is output as the same
constant on each read, that's what you'll get.
Even with a simple circuit and PWM feedback to ensure that the noise
voltage will cause the input voltage to cross boundaries between 2mV
ranges, and be recorded as one of the values randomly, this circuit remains
highly sensitive, in that any injected signal on the order of the noise
amplitude (24uV in my example) can control the output, overriding any real
randomness.  We can design around this constraint, with reasonable
shielding, supply regulation, bypass caps, and such, as appropriate for the
application.  It just takes good engineering.
Too bad this $0.001 worth of hardware isn't pre-engineered for us ;)

@_date: 2016-01-15 17:49:25
@_author: Bill Cox 
@_subject: [Cryptography] TRNG review: Arduino based TRNGs 
That's probably fine for seeding PRNGs for games.  It may have worked well
in that you saw no pattern, but 1) there could have been one you did not
see, and 2) any actual randomness from pin A0 might go away under different
conditions, such as running on a battery inside a metal box.
I was going to recommend what I'd do to figure out the thermal noise you
can count on, but this guy already did all of the work for me
The R-C stages on the input to the ADC act as an anti-aliasing filter.  The
8K Ohm feeding the 10pF gives a 12MHz roll-off, which is not quite right,
since I'm not taking the 12K into 4pF stage into account.  From this site
we can easily compute the expected thermal noise as 40uV.  This 10-bit A/D
has what, 2mV resolution on the input?  In a _very_ quite external
environment, where is the noise coming from that will reliably cause A0 to
wander all over the place?  I would be surprised if it were there.  The
data from the probably_random project seems to show that even with the
post-whitening, there isn't much randomness there.
My first guess is that you're measuring power supply noise.  Can you try
generating a bunch of floating A0 samples when running on a battery, with
good bypass caps, in a nice shielded environment like a metal box?

@_date: 2016-01-18 06:02:58
@_author: Bill Cox 
@_subject: [Cryptography] TRNG review: Arduino based TRNGs 
Very cool!  I had a similar idea related to using the ADC on A0.  Everyone
seems to just let it float, but most pins on most boards float to a
specific voltage, often 0V, but it depends on the chip and sometimes the
board.  We could run a simple test to see what happens when we drive A0
high, and then let it float.  Assuming it decays to 0V, it will have to
cross all 1024 thresholds between count values, and while crossing them, we
can record thermal noise as the ADC jumps randomly between two adjacent
values.  If we just run the ADC rapidly for the whole voltage decay time,
we might be able to ensure there is enough entropy for use in crypto.
One nice thing about this approach is it should be somewhat resistant to
external influence, such as power-supply noise.  A "health monitor" routine
could check that the voltage decay happens at roughly the expected rate,
and without more variation than expected.  Toggling between adjacent ADC
input counts is expected from a 10-bit A/D.  Jumping from one value to a
far away value would be unexpected.  We could also compute the minimum
expected entropy contribution from thermal noise.  I suspect it will be

@_date: 2016-01-19 17:37:28
@_author: Bill Cox 
@_subject: [Cryptography] TRNG related review: rngd and /dev/random 
I've talked a bit about different TRNGs, but there is more to the story.
Once "random" data leaves the TRNG, there needs to be software to make use
of this data securely to generate cryptographic IVs and keys.  I _think_ I
know enough now days about /dev/random and rngd to have a useful opinion,
so here goes...
The problem seems simple.  We want to take all the sources of "entropy" we
have access to and mix them together in a big "entropy pool" which when
completely randomized, can be used in crypto.  However, it must be harder
than it sounds, because we seem to have trouble building opensource entropy
pools that work exactly right, and there is contention about what "exactly
right" would mean in this case.
First, here is my almost certainly inaccurate list of dirt on /dev/random:
- Denial of randomness attacks are as simple as "cat /dev/urandom >
- If entropy is trickled in, and an attacker who knows the initial state of
the entropy pool (which is a file on disk) and all the public keys of all
pairs generated from /dev/random, she can easily guess all the private keys
- If the hard-coded models in the kernel of entropy in its various sources
(network, hard disk, interrupts) are highly inaccurate (common in VMs for
example), then the entropy in the pool can be highly over-estimated
- Embedded systems such as DD-WRT have had insecure keys due to such issues
(though I think the DD-WRT folks bear much of the blame in this case)
All that said, if you feed and care for this beast properly, you can
generate secure keys from it.  When I generate keys, I check the entropy in
the pool, which you can do with
    $ /proc/sys/kernel/random/entropy_avail
Without a hardware TRNG, the pool on my loptop grows at a very slow rate.
This is likely due to conservative entropy guestimates in the kernel, so I
don't think this is a problem by itself.  If all you want to do is generate
keys with ssh-keygen right away, consider some advice I read here on this
list, and take a photo of your cat (because cats are scientifically proven
to be excellent sources of randomness).  Upload it to your laptop, and
simply do:
    $ sudo cat cat.jpg > /dev/random
    $ shred cat.jpg
If you have an SSD, shred will run, but it wont work...
Assuming you feel good about having randomized /dev/random, just go
generate keys with ssh-keygen, and all should be fine.  However, you may
notice if you are  on an air-gapped machine (which you should be, to
protect the world from all that cat randomness), that it takes a heck of a
long time to generate an RSA-4096 key.  It takes ~30 minutes on my
machine.  This is because the Linux kernel wisely allows you to write
randomness, but it does not assume that your data actually added randomness
to the entropy pool.  Doing that requires using a low-level APIs (ioctrl).
So, if you, like me, got frustrated repeatedly creating keys on air-gapped
Linux machines, the answer may be a hardware TRNG, such as OneRMG
.  If you do use OneRNG, and follow their directions
(from a few months ago), you'll use rngd to talk to the OneRNG, and rngd
will feed /dev/random.  You will be able to generate cryptographic keys
very fast, because rngd assumes every bit it writes is 100% random.  I hope
that gives everyone a nice warm feeling...
So, here's my almost certainly inaccurate dirt-list on rngd:
- It assumes every bit written is 100% random, and updates the Linux
entropy pool estimate to say so.
- It uses FIPS testing to ensure that the bits are random (there is a
barf-bucket around the corner for you statistical wizards)
- It stops writing to /dev/random after one batch of bits is written (a
nice large batch)
- It will ignore all other entropy sources if hardware TRNGS are enabled
and Intel RDRAND instructions work on your CPU
The _right_ way, IMO, to mix entropy is with a more sophisticated tool that
has a physical model for understanding how each source of entropy works.
That way, we can write a health monitor for each source, and at least
somewhat justify using the claimed entropy rate from these sources.  AFAIK,
rngd has no way for the entropy source to say, "Here's my raw data, I think
it has 0.8 bits of entropy per bit".
The problem is that _every_ entropy source has measurable bias.  There are
no exceptions I am aware of.  To pass the FIPS test required by rngd, every
TRNG manufacturer is therefore forced to pre-whiten the data before rngd
sees it.  This code is usually closed-source, and embedded permanently in
hardware that is difficult to audit.  I suspect most of it is done poorly,
such as feeding an 8-bit hardware ring-oscillator output into a 80-bit LFSR.
The worst problem I found, the one that caused me to stop using rngd, is
that it refused to write data from my OneRNG device to /dev/random.  This
was because in Ubuntu 14.04, with hardware TRNGs enabled in rngd, the
RDRAND instruction _always_ generates all the bits rngd wants before any
other source can generate 1 bit.  The result is that _all_ entropy from
rngd was RDRAND data, and zero was from the OneRNG!
These problems are fixable.  Health monitors with good entropy estimators
should be required for each entropy source.  The rngd-internal pool should
wait until it has enough randomness from N sources before writing any data
to /dev/random,  where N is user-selectable, or even better, allow the user
to specify exactly which sources are required to provide a secure number of
bits (> 200-ish) before the pool is considered secure.  Then, write the
whole thing to /dev/random, and repeat.  Do some decent mixing in rngd
first, with a cryptographic sponge (I use Keccak-1600).
For now, I just use the TRNG I carry in my pocket, an air-gapped machine,
and an my own software for randomizing /dev/random.  Now, I just wish I had
a good reason for all this secrecy :)

@_date: 2016-01-20 08:09:03
@_author: Bill Cox 
@_subject: [Cryptography] TRNG related review: rngd and /dev/random 
I may be wrong about this, but the threat-case where I think this matters
is when an attacker gets access to the machine, learns the state of the
entropy pool, and then loses access.  Can the machine recover?
If only 1 random bit per second is fed into /dev/random, but keys and IVs
are extracted from /dev/urandom at a bit-rate far higher than this, and if
the attacker remains as an eavesdropper on the network and can see the
results of every read to /dev/urandom, then the attacker needs only to make
a few guesses per second to keep the attacker's copy of the entropy pool
synced to the server's.  Is this right?

@_date: 2016-01-20 11:49:54
@_author: Bill Cox 
@_subject: [Cryptography] TRNG related review: rngd and /dev/random 
I was unclear.  I meant to say that rngd, or some daemon like it, should
require health monitors and good entropy estimators.  I agree this is
out-of-scope for the kernel, but a good hardware RNGD utility daemon like
rngd should provide this, IMO.  Developers of TRNGs should be encouraged to
provide raw bits, and a decent model, and leave the rest to the rngd devs.
Getting this stuff right is hard.  Hiding the raw bits makes it even harder.
The kernel cannot make a perfect RNG, there are system issues that are
Agreed.  Every source of entropy, even one with a back-door, is welcome in
the entropy pool.  The trick is maintaining a good guestimate of secure
entropy.  Physical models and health monitors can help with entropy
estimates, though back-doors are still possible.  Multiple sources can help
with security.  The problem I saw in my version of rngd (which may be old -
I did not check upstream) is that it did not have a way to require multiple
entropy sources to contribute significant entropy.
I agree.  All (potential) sources of entropy are welcome.
Hmm... How about when I use a single very well characterized TRNG, for
which I can prove that the entropy contributed on each update to
I guess it depends on what you mean by cracking.  If you mean hacking in
user space to defeat all sources of entropy feeding /dev/random, I agree.
It is simpler to hack one source than several.  However, if you mean an
attack that attempts to guess the output from /dev/urandom, I would prefer
to defend against this with one known-good source over multiple
questionable ones.
Yep.  It is simple enough to just throw more somewhat imperfect bits of
entropy at the problem than polishing each one to be sure we understand it
100%, so long as we can be confident that the bits contain _some_ entropy.

@_date: 2016-01-20 13:52:22
@_author: Bill Cox 
@_subject: [Cryptography] TRNG related review: rngd and /dev/random 
I guess if this were a significant attack vector, someone would patch it.
It is simply a well known minor flaw  that makes my list, and for which I
code around by writing a bunch of random bits all at once rather than
trickling them in.  Rngd gets this detail right, and other entropy
gatherers should be aware of it.

@_date: 2016-01-21 08:03:46
@_author: Bill Cox 
@_subject: [Cryptography] TRNG related review: rngd and /dev/random 
This is a well known simple attack.  I'll explain in more detail.
Initially, somehow, the attacker knows the state of the CPRNG.  From that
point on, she only sees IVs and public keys, and may miss some of them now
and then.  However, if zero new entropy is inserted into the CPRNG, it is
trivial for the attacker to play the state forward and re-sync her version
of the state.  This lets her figure out all the private keys.  Would you
Now, suppose there is a very slow trickle of randomness into the CPRNG
state, say one byte at most between the times that the attacker sees new
IVs and public keys.  To re-sync, the attacker only needs to consider the
256 possible values that may have been added to the state, times the number
of places where it might have been added between keys and IVs, and again
play the CPRNG forward to re-sync.
In general, this attack works so long as the attacker continues to see the
output, likely as a network eavesdropper, and so long as only small
guessable amounts of randomness are added to the CPRNG state betwen
outputs.  This is why you need to add an unguessable amount all at once,
rather than trickling it in.
There seem to be popular TRNG ICs that only add at most one byte of true
randomness to the CPRNG between reboots, so this is a real issue,
especially since the initial state is pre-programmed secretly at the

@_date: 2016-07-21 03:36:03
@_author: Bill Cox 
@_subject: [Cryptography] Entropy of a diode 
I have not seen any papers on this, but I can tell you that if you buy a
regular zener diode, it will generate a disappointingly low amount of
noise, many times less than the reverse breakdown Vbe of a cheap
transistor.  Apparently, zener avalanche noise is highly dependent on the
process used, and if you tune the process to lessen avalanche noise, you
can eliminate most it.

@_date: 2016-07-23 06:55:10
@_author: Bill Cox 
@_subject: [Cryptography] Entropy of a diode 
Please stop using reverse-breakdown of emitter-base diodes as noise sources
for crypto.
These circuits have several limitations, such as sensitivity to power
supply noise, changing noise patterns as they age, and have no reliable
model for predicting the rate or quality of random bits, making it
difficult to monitor the health of the noise source.  A better circuit
is a modular
entropy multiplier , which costs
around $1 in parts, is simple to breadboard
, and has
open-source implementations including what parts to buy, and where to get
them.  Alternatively, if you happen to have an FPGA on your board, you can
build a reliable TRNG using phase noise from multiple ring oscillators.  If
you happen to have access to a 24-bit A/D, the lowest bits will be reliably
random if you sample audio from a mic, or even an unconnected mic jack.  If
all you want is to collect 256 true random bits for crypto to seed a CPRNG,
you can easily use the mouse and keyboard to accumulate your bits from a
highly random source: humans.

@_date: 2016-07-24 05:44:47
@_author: Bill Cox 
@_subject: [Cryptography] Entropy of a diode 
I agree.  Good TRNGs can be built using diode noise, and my favorite of
these is the OneRNG.  They build these devices with lots of shielding and
redundancy (mixing with an RF source).  They characterize the reverse
breakdown of emitter-base junctions they use as noise sources themselves,
rather than relying on any data sheet or physics model.  You can overcome
the problems of a diode noise source, but for future designs, I hope
designers will use better circuits.
A new diode-based TRNG on the way is ChaosKey:
  I am glad to see more open-source TRNGs,
so kudos to the developer for that.  The source code and schematics are
both available.  However, I wish we were moving away from such noise

@_date: 2016-07-26 13:36:34
@_author: Bill Cox 
@_subject: [Cryptography] Entropy of a diode 
Nice paper!  This is the first time I've seen a publicly reviewable
implementation of something similar to Intel's DRNG.  The Intel folks mean
well, but they are not allowed to answer technical questions about their
DRNG.  Can you answer some questions for me?
First, it looks like both your circuit and Intel's will have a strong bias,
possibly even output just 0's or just 1's, if the voltage is caused to
increase more rapidly than your feedback circuit can compensate for.  If I
write software meant to cause significant voltage shifts on the power rails
in a saw-tooth pattern, will I be able to control the output of your ES?
To simulate this, just add small voltages in series with the gates in your
inverters so there is a small mismatch.  At 14u, the mismatch will be worse
than ever unless specific steps are taken to remedy the problem.
Second, why bother with more than one ES?  AFAIK, there is no way to
combine independent sources to produce 100% perfect randomness, though we
can easily get whatever level of true randomness desired for any practical
purpose such as crypto.  Is this for improved speed?
Are you able to make devices available for testing?  Can we access the raw
ES output (unlike Intel's DRNG)?
I've simulated DRNG-like circuits, and I do believe they work, but while
they do consume less power per bit and deliver bits at a higher speed, and
with less die area than anything else I've seen, the flip side of that is
they seem to be more sensitive to external influences, mostly power supply
changes, than any other circuit I've simulated.  Intel has a patent they
don't use on adding voltage regulation to a TRNG to prevent power-rail
attacks, so the rest of us are not allowed to do that.  Without it, can you
make a single ES robust against attack?
BTW, I really do hope to be convinced that this circuit is solid and
trustworthy.  It has the best performance specs around.

@_date: 2016-06-09 22:04:28
@_author: Bill Cox 
@_subject: [Cryptography] Edwards roller coaster (a physical model) 
This is a fun physical model for Edwards curves I came up with, which can
represent most of the elliptic curves we use for crypto that are related to
the Jacobi addition laws
  I do not know of any relevance this has for crypto, but I like to have a
physical model in my head when thinking about problems...
When d < 0, we get a 4-pointed star inscribed in the unit circle.  This
picture from Wikipedia is accurate, except that it flipped the sign of d,
so negate the signs of d and you will be less confused, because then it
will match the article:
[image: Inline image 1]
These squished circles where d < 0 are entirely within the unit circle.
Place a unit hemisphere on top of it, and project the squished circle
directly up onto the hemisphere.  Imagine that the resulting path is the
track of a roller coaster.  At time t = 0, the roller coaster is moving at
angular velocity w0, crossing the point (x, y, z) = (1, 0, 0).  w0 Is
really just the speed at that point, but we need it to have units of
1/seconds for the units to work out.
Now assume that the track is frictionless, and that there is a bizarre
force acting on the roller coaster.  For d == -1, the force pushes away
from the Z-axis with strength equal to e^(w0*r), where r is the distance
from the Z-axis, in other words, sqrt(x^2 + y^2).  Got it?  What happens
when you set off the roller coaster at t = 0, with a speed of w0?
The roller coaster speeds around the track, moving faster near the corners
of the star, and slower as it gets close to the Z-axis.  The speed is
always w0/r, and the potential plus kinetic energy is constant.  In this
model, the thing being added by the Edwards addition law is time.  Given
the position at t1 and t2, we can use the addition law to compute the
position at t1 + t2.
I kind of want to build an animated gif :>

@_date: 2016-06-09 22:28:27
@_author: Bill Cox 
@_subject: [Cryptography] Edwards roller coaster (a physical model) 
Grr... I knew I'd make at least one mistake: the speed is always r*w0, not
w0/r.  Some emails should be peer reviewed :>

@_date: 2016-06-13 16:03:41
@_author: Bill Cox 
@_subject: [Cryptography] Proposal of a fair contract signing protocol 
I did not read the above article, but...
In general, if two parties are communicating just with each other and wish
to both sign a contract, the last person to act has an advantage.  For
example, if I buy a domain name from you, and send you $100, you can keep
the $100, and not give me the domain name.  We can add rounds to help.  I
could send you half the money, you could give me the domain name, and then
I could send the other half, but then I can cheat and not send the
remaining $50.  The size of possible cheating is reduced proportionally to
the number of rounds, but we can't get it to 0.  We don't have this problem
at the grocery store because we simultaneously pay for goods and receive
them.  Participants at a distance taking turns do not have this ability.
With block chains, we can effectively get the possible cheating to 0.  For
example, we can sign a contract and enter it's hash into the block chain,
and in the contract state that it is valid only if recorded in the block
chain with both party's signatures.  It is like having a free escrow
agent.  I assume the article is about some improvement on this concept.

@_date: 2016-03-17 01:11:40
@_author: Bill Cox 
@_subject: [Cryptography] USG v. Lavabit-Snowden Files Unsealed 
Wow, this is scary.  It sounds like Lavabit was fined $5,000 per day until
it handed over the encryption keys for its email service, and that Lavabit
further had a gag order and could say nothing about it.  Here's the text of
this order:
This matter comes before the Court on the motion of the government for
sanctions for failure to comply with this Court's order entered August 2,
2013. For the reasons stated in the government's motion, and pursuantto
Title 18, United States Code. Section 401, it is hereby ORDERED that the
motion for sanctions is granted; It isfurther ORDERED that, if the
encryption keys necessary to implement the pen register and trap and trace
device are not provided to the FBI in PEM or equivalent electronic formal
by noon (CDT) on August 5, 2013, a fine of five thousand dollars
($5,000.00) shall be imposed on Lavabit LLC and Mr. Levison; It is further
ORDERED that, if the encryption keys necessary to implement the pen
register and trap and trace device are not provided to the FBI in PEM or
equivalent electronic format by noon (CDT) each day thereafter beginning
August 6, 2013, a fine of five thousand dollars ($5,000.00) shall be
imposed on Lavabit LLC and Mr. Levison for each day of noncompliance; and
It is further ORDERED that the government's motion for sanctions and this
Order shall remain under seal until further order of this Court
As an ethical matter, I believe our government should tell its citizens
what form of spying on our private communications it is doing, and under
what conditions.  Seeing our government do this sort of thing in secret
scares the heck out of me.  It is certainly not what I thought would happen
in the USA.

@_date: 2016-03-29 11:02:08
@_author: Bill Cox 
@_subject: [Cryptography] USG Moves to Vacate Apple Decrypt Order 
This is also a lost opportunity to set a strong precedent to protect
American privacy.  There was never any doubt that the FBI could get the
data off this phone.  This was simply a power grab by the FBI to use the
terror attack in San Bernardino as an excuse to increased their power
beyond what is safe or reasonable, IMO.  I am glad Apple did the right
thing.  I am sad that the FBI decided to kick the can down the road and
avoid risking setting a precedent that would most likely limit their their
power to invade our privacy.  I expect them to be back, attacking less
principled and/or less wealthy companies, where there is little chance of
strong resistance.  I suspect there are lots of Lavabits out there.  The
unique part about Lavabit is the founder chose doing the right thing over
keeping his successful company alive.  I am sure this is quite rare.

@_date: 2016-05-01 13:01:40
@_author: Bill Cox 
@_subject: [Cryptography] sha1sum speed 
This shows a major problem we face in Linux distros: we like everyone to
run the same binary, so everyone is forced to use the oldest supported CPU
instruction set.
The program sha1sum is from the coreutils package, which AFAICT contains
zero vector-optimization of any kind.  Here's what I get with my version of
b2sum, compiled with AVX2 support, vs sha1sum shipping with Ubuntu.
 randfile is a 300MiB file, already cached:
$ time sha1sum randfile
30b42c8894b108d65db90090c98c0a9c8cd63cb9  randfile
real 0m0.845s
user 0m0.784s
sys 0m0.056s
$ time b2sum randfile
 randfile
real 0m0.432s
user 0m0.396s
sys 0m0.036s
BLAKE2 is almost twice as fast, and the parallel version is faster (for
large hashing, not < 1KiB):
$ time b2sum -a blake2bp randfile
 randfile
real 0m0.324s
user 0m0.996s
sys 0m0.068s
Not only that, but Samuel Neves (who wrote the optimized BLAKE2 code) has
an optimized version of BLAKE2bp using more of the available parallelism
per core to get around 1 byte/cycle throughput.
Now, any sane person who needs a whole lot of speed and has a processor
supporting SSE4 or newer instruction set should just use BLAKE2.  That
said, the future looks bright for even more speed using HighwahHash-like
parallel multiplications and byte shuffles.  We're seeing some pretty sick
speed in prototype code.

@_date: 2016-11-20 07:55:14
@_author: Bill Cox 
@_subject: [Cryptography] Use of RDRAND in Haskell's TLS RNG? 
Intel's "DRNG" should not to be trusted if your threat model includes the
NSA.  It remains secretive, and simple potential attacks like a "power
droop" attack have not been properly addressed by Intel, IMO.  However, if
you just need random-looking numbers for simulations, RDRAND is good.
Clearly, Haskell should include all attackers in its threat model.  If what
you say is true, I think the authors of that code should provide an
explanation of how this happened.
I find it disturbing that this same bug keeps showing up.  I found the
exact same bug in rngd, the standard Linux deamon for gathering entropy
from true random number generators: rngd.  The authors and maintainers of
rngd I think owe us an explanation as well.  Has it been fixed yet?
As for Intel's DRNG, there are no published attacks against it AFAIK, and I
doubt there will be any - it is just too difficult to reverse-engineer.
However, it is negligent to build a random number source that could be used
for cryptography that relies only on Intel's secretive RNG for entropy.
My best guess is the Intel designers did an honest job of Intel's DRNG, but
I never did get a competent answer to how they would defend against a
trivial power-droop attack, where the CPU just does a ton of
multiplications in a loop for a while.  The incompetent answer provided was
that back-to-back inverters naturally provide high power supply rejection.
Now days, this is simply not true, because side-by-side transistors usually
have significantly different thresholds.  They could easily counter this
problem with large slow transistors, but given the speed they run, clearly
they did not.

@_date: 2016-11-23 23:25:28
@_author: Bill Cox 
@_subject: [Cryptography] Use of RDRAND in Haskell's TLS RNG? 
Note: I do believe David is honest in his stated opinions here, and I
suspect if we were allowed to dig into Intel's DRNG design, we would find
nothing sinister.  That said, I feel his opinions stated above are
AFAIK, there are zero cases of PWNing because servers mixed multiple
sources instead of relying on just one.
I am one of a handful of people who know for sure that RdRand is secure
It worries me that you "know for sure" that RdRand is secure.  Do you have
the analog background to warrant that confidence?  How do you defend
against a simple power droop attack?
Other people have to trust it and their basis of trust should be the
inspire trust.
Just write your random data to /dev/random, and let it do the mixing.  How
does that add to the attack surface?  Mixing multiple sources is good.
Anybody can write the code to feed potentially random data to /dev/random.
It's easy, and even if you mess up, you have not made things worse.
I'd point you to a good book on extractor theory, but I haven't finished
The trick is avoiding buggy software like Haskel and rngd that somehow have
bugs that cause them to rely exclusively on RdRand.

@_date: 2016-11-23 23:50:41
@_author: Bill Cox 
@_subject: [Cryptography] Is Ron right on randomness 
+1.  However, you now incorporate any security flaws in your CPRNG into
your random number source, thus spreading the flaws to all crypto on your
system.  You also integrate the probability over time that an attacker has
taken a snapshot of your CPRNG state.  I like to reseed the CPRNG now and
then with a few hundred unpredictable bits.
Absolutely right.  Only TRNGs that make raw data available should be
trusted.  Further, the source should have a simple physical model which is
proven out by measurements, preferably continuously.

@_date: 2016-11-24 00:28:41
@_author: Bill Cox 
@_subject: [Cryptography] Is Ron right on randomness 
I prefer randomness from a source that has a solid physical model and a way
to measure that it is performing according to that model.  There are
several TRNGs that accomplish this, and many that don't (such as zener
For your example, I agree it would work fine.  However, it would be hard to
characterize the entropy in a recording of "Shhh".  I look at a lot of
recordings of sound (I wrote libsonic to speed up speech).  Even in
recordings of "shhh", generally the next point can be predicted with more
accuracy than I would have thought if I had not looked at the waveforms.
There is a surprising amount of non-randomness.  There's nothing wrong with
going for thermal noise instead.

@_date: 2016-11-27 13:40:41
@_author: Bill Cox 
@_subject: [Cryptography] Is Ron right on randomness 
I think there is no need to modify OpenSSL.  Hardware TRNGs can write their
entropy directly to /dev/random, and if they are confident enough, they can
also update the estimate of entropy in the pool (I do this with my TRNG).
OpenSSL should simply continue waiting for enough bits to be available.
If the OpenSSL devs have any sway in Linux development, maybe you could
suggest to upstream that /dev/random could be improved.  It was good work
for when it was written, but it is showing its age.  The same goes for
password hashing in /etc/passwd.

@_date: 2016-11-28 03:19:14
@_author: Bill Cox 
@_subject: [Cryptography] Use of RDRAND in Haskell's TLS RNG? 
Yes I looked at the simplified circuit diagram they published, made guesses
as to the missing details (W/L, etc), and simulated it in various
conditions.  The raw DRNG is _very_ power supply sensitive, counter to
Intel claims.
The output impedance of the power supply generally is not an issue in this
sort of attack.  The power droop on the internal rails happens on the order
of nanoseconds.  The package impedance is generally far to high for the
off-chip caps to have any impact on the attack.  More than likely, all that
matters is local capacitance on the power mesh, and the coupling between
the devices drawing power and the target device.

@_date: 2016-11-28 07:22:21
@_author: Bill Cox 
@_subject: [Cryptography] Use of RDRAND in Haskell's TLS RNG? 
I just realized that I have not described a "power droop" attack in enough
detail.  I make the following assumption:
- The Intel DRNG shares a power rail with some on-chip power hungry device
Assuming this is the case, you have to cause the power rails to drop
rapidly.  For example, if a multiplier is nearby the TRNG, doing
multiplications should work.  If it is near a cache block, repeated
read/writes to that block should work.
The timing has to be such that the attack is faster than DRNG's feedback
response time.  The resistance in the power mesh is likely enough to make
the attack independent of the time constant from the outside supply pins to
the internal power mesh.
All you need is a few millivolts of power droop to control this device in
my simulations, based on guessed W/Ls and Vth mismatch.  For the time it
takes for the feedback to compensate for slightly lower power rails, the
DRNG will output a string of either 1's or 0's, depending on the Vth
At some point, it begins to correct for the change in power supply
voltage.  At this point, you have to turn off the source of power drain
(for example, multiplier or cache access loop).  The power rails then
recover faster than the feedback loop in the DRNG, and the output will be
the opposite of what it was before: either a string of 0's or 1's.
Attacks like this can be defended against with careful design.  I have no
way to know if this happened or not.

@_date: 2016-11-28 08:30:12
@_author: Bill Cox 
@_subject: [Cryptography] OpenSSL and random 
I hate to suggest using /dev/random because it blocks when it does not need
to, and is susceptible to simple denial-of-service attacks (cat /dev/random
should.  Here is a quote from the urandom man page on my 14.04 Ubuntu
"A read from the /dev/urandom device will not block waiting for more
entropy.  As a result,  if  there is  not sufficient entropy in the entropy
pool, the returned values are theoretically vulnerable to a cryptographic
attack on the algorithms used by the driver."
So, my simple answer is, "Don't change OpenSSL".  If the OpenSSL folks are
willing to do a bit more Linux-specific work, then I would instead suggest:
Read N bits (like 1024) bits from /dev/random when OpenSSL first needs
random data, and throw them away.  Thereafter, read only from /dev/urandom.
Regardless, bugs like the one in rngd that cause RdRand to provide 100% of
the entropy is currently causing /dev/random on many Linux systems to
initially return random numbers that depend on only one unauditable
source.  That's not OpenSSL's fault, but it needs to be addressed, IMO.  I
believe that no unauditable random source should be incrementing the
internal entropy estimate of /dev/random.  Those that do should be
carefully audited, and preferably their health should be monitored over

@_date: 2016-11-28 08:46:54
@_author: Bill Cox 
@_subject: [Cryptography] Is Ron right on randomness 
Ian, would you agree that something on the platform needs to first ensure
that /dev/random is well seeded before OpenSSL reads from /dev/urandom?  I
suggested perhaps OpenSSL should read 1024 bits from /dev/random, and all
later bits from /dev/urandom, but then every app that needs
cryptographically unpredictable numbers would each independently reseed the
entropy pool.
Maybe Linux could provide a way to read total entropy generated since
boot?  That could be used to compute how much data to read from

@_date: 2016-11-28 22:35:15
@_author: Bill Cox 
@_subject: [Cryptography] OpenSSL and random 
I think I see some potential for consensus here: Read from /dev/urandom,
but only once it is properly seeded.  It is the OS's job to properly seed
Since Linux does not do this today, I'll stick with my "Don't change
OpenSSL" advice for now, but if we can, we should lobby for /dev/urandom to
stop feeding us predictable bits before proper seeding.  Predictable bits
suck for crypto.

@_date: 2016-11-29 09:53:09
@_author: Bill Cox 
@_subject: [Cryptography] [FORGED] Re:  OpenSSL and random 
Unless the Linux entropy pool has not yet had time to seed properly.  If
Linux switched to this model, we would have:
- Buggy systems that do not obtain entropy fast enough appear to hang
- Functional systems that do obtain entropy fast enough work as expected
I prefer for systems with security bugs to hang rather than adopt a
work-around to continue functioning in an insecure mode.  I think most
software developers would prefer to discover the security flaw this way
rather than shipping insecure software.
This is not some abstract threat.  The OpenWRT wireless router OS shipped
with just such a bug that caused them all to be insecure.  If /dev/urandom
had blocked on boot on those devices, the problem would have become obvious
to the developers.
Real developers are not generally crypto geeks.  They need an alarm bell
like this to go off to let them know when something is wrong.

@_date: 2016-11-29 14:00:27
@_author: Bill Cox 
@_subject: [Cryptography] [FORGED] Re: OpenSSL and random 
I'll stick with my current advice: Nothing needs to change in OpenSSL when
running on Linux until something first changes in Linux.
Here's a pretty good article on /dev/urandom
, which strongly advocates for
moving to using /dev/urandom for crypto.  However, it includes this
"FreeBSD does the right thing: they don't have the distinction between
Then it won't block ever again."
This is the correct behavior.  If you switch to using /dev/urandom on Linux
now, we'll likely see more OpenWRT-like PWNing.  I can't recommend that.
This is a Linux flaw, and reading from /dev/random remains the simplest
work-around.  A less simple work-around would be to read from /dev/random
for some number of bits (>= 256?) and then switch to /dev/urandom.  This is
not perfect, but better than just reading from /dev/random, while remaining
secure on Linux while being a noop on FreeBSD.

@_date: 2016-11-29 20:38:45
@_author: Bill Cox 
@_subject: [Cryptography] [FORGED] Re: OpenSSL and random 
Ugh...  You do realize that getrandom simply reads from /dev/random, right?
The noise on these threads is not just aggravating, but suspicious...

@_date: 2016-11-30 05:27:23
@_author: Bill Cox 
@_subject: [Cryptography] [FORGED] Re: OpenSSL and random 
Whoa... I was entirely wrong!  The right answer on Linux is now:
Just call getrandom
Now I have to change a lot of code that reads /dev/random.

@_date: 2016-11-30 05:59:24
@_author: Bill Cox 
@_subject: [Cryptography] Is Ron right on randomness 
I just learned on another thread that Linux provided a fixed API.  The new
right answer on Linux is to call getrandom:
It's in linux 3.17.  My Ubuntu 14.04 laptop upgraded to 3.19, so I had
it... Then it upgraded to 4.2.0, and now I no longer have it.  Grrr...

@_date: 2016-09-16 09:01:29
@_author: Bill Cox 
@_subject: [Cryptography] True RNG: elementary particle noise sensed with 
The noise you are describing is called "thermal noise", and is ensured to
be there by basic physics.  You have discovered the method used by
"Turbid".  I reviewed their system a while back:
Looking at my review, I don't think I gave them enough credit early enough
for doing the basic research on this TRNG method.  It really is excellent
work.  That said, I agree with a lot of Bear's comments, such as using
simple devices, and even the glitter nail polish.
On Thu, Sep 15, 2016 at 12:34 PM, Thierry Moreau <

@_date: 2016-09-16 20:57:17
@_author: Bill Cox 
@_subject: [Cryptography] True RNG: elementary particle noise sensed with 
Oh... there are _so_ many points to debate here... However, please consider
the following argument: All a typical device needs is 256 bits of
randomness, ever.
Bear is entirely correct in pointing out that any device that has only 256
random bits can never generate 257 "random" bits.  We can only use more
than 256 bits from such a device if we take a leap of faith in some CPRNG.
So... let's' assume we can trust that SHA256(randSeedl + counter) is just
such a function, just as secure as a real TRNG, up to the 256 bit level of
In this case, we don't actually need a high quality TRNG in every device.
We simply need a trustworthy secure source of random numbers to load into
each device we need to trust, probably only up to 256 bits, unless we're
paranoid about quantum attacks, and then only to 512 bits.  However, we do
require a very _secure_ method of providing each new device with it's own
256 (or 512) bit seed.
Now, to generate a trusted 256 (or 512) bit secure root seed for a set of
personal devices, all we need is a _really_ good TRNG for just this number
of bits.  My preferred TRNG is the one I build personally and carry in my
pocket (because I am a _huge_ geek), the "Infinite Noise Generator".
However, a simpler free program is just as good: simply record random key
events and/or mouse movements for a while until the SHA256 (or SHA512) of
these events is so unpredictable that the "surprise" is > 256 bits (or
512).  Just to be sure, use 10X more random inputs than the math says is
Then, use this secure seed to seed all your devices.
Anyway, the best commercial TRNG, IMO, is the OneRNG.  The best concept for
a TRNG is based on termal noise, and invented by Peter Allen: the Infinite
Entropy Multiplier (basically an analog modular rather than saturating
multiplier of thermal noise).  These devices provide convenience when you
are not sure if prior seeds are secure, but that is the primary reason we
need them.  We don't need them for every unpredictable value we need to

@_date: 2016-09-18 22:15:53
@_author: Bill Cox 
@_subject: [Cryptography] True RNG: elementary particle noise sensed with 
As I said... there are _many_ points to debate on this thread...  For the
original poster, I'll simply repeat that good quality thermal noise
extractors can make excellent TRNGs.  Overcoming the problem of amplifying
the real noise rather than an attacker's signal is problematic, but
solvable.  Now, on to some of those other points...
It is an excellent concept.  I simulated a similar circuit, and am
convinced that this _can_ be what you say, but I also found that I could
trivially PWN entropy sources like this with what I call a "power rail
attack", where I simply run CPU intensive algorithms in parallel with the
TRNG attempting to generate random bits.  Entropy sources like this are the
most power-rail sensitive TRNGs I have ever simulated (and very similar to
what Intel's CPUs use for the RAND instruction).  Can you show me the
details of your design and real-life data showing resistance to this simple
attack?  I remain skeptical.
As I said, thermal noise can be an excellent TRNG entropy source, but only
if you overcome an attacker's influence over the thermal noise signal.
This can and is done in well designed circuits all the time, including in
ring-oscillator circuits (and even better in Peter Allan's circuit).  Your
entropy source is also a thermal-noise source.  How do you overcome an
attacker's influence?
Please don't repeat what I heard from Intel: the design is inherently
resistant to power supply noise because of symmetry in the feedback
circuit: any noise impacting one side equally impacts the other.  This was
mostly true in 0.35u silicon and larger, but this is _very_ wrong in
fin-fet land.

@_date: 2017-02-07 22:33:05
@_author: Bill Cox 
@_subject: [Cryptography] So please tell me. Why is my solution wrong? 
I just read it, and I think the main idea is clever.  Show the user a
secret picture whenever they authenticate.  This could help defend against
phishing attacks.
I like this idea for corporate logins.  It has to be something people use a
lot, or they will forget the picture.  Also, corporations can make sure
every machine has a browser with this feature by default.  That let's you
skip having to convince the big browser dev teams that your feature needs
to be integrated.

@_date: 2017-02-07 23:58:48
@_author: Bill Cox 
@_subject: [Cryptography] So please tell me. Why is my solution wrong? 
FIDO is great solution for corporate settings where people can put up with
2FA.  I think the secret picture idea is only for 1FA settings, which
unfortunately are the majority of corporate settings.
With a FIDO Yubikey, my password can be simpler, maybe just a PIN, but a
PIN is just a simple password.  My phone uses a fingerprint, but still
makes me type in the password every few days.  In other cases, I get
perma-cookies that authenticate me forever, but then I forget the password
and the next time I use a different browser or device, I have to go through
the password reset process.  It's a mess.
Here's a dumb idea for improving the situation slightly until that day when
passwords are finally retired.  Web sites should state the password
requirements on the login form.  I wind up resetting passwords about twice
a week, and more often than not, when I see the change password form, I
remember the old one.

@_date: 2017-02-08 00:39:38
@_author: Bill Cox 
@_subject: [Cryptography] [FORGED] Re: So please tell me. Why is my 
Can you elaborate a bit on the research?  Did it cover the case where the
picture is stored on the client machine and the same picture is shown when
logging into for all web sites?
I think a tool like that could be built as a browser plugin, and it could
use some simple heuristics like Chrome does when it saves your passwords to
figure out when a user is on a login page.
That said, I find most crypto and authentication related ideas are almost
always 1) not new 2) already broken, and a frustratingly high portion of
the time they are both :-\

@_date: 2017-02-08 00:55:06
@_author: Bill Cox 
@_subject: [Cryptography] [FORGED] Re: So please tell me. Why is my 
Well... I think I figured out why that wont work well.  If the browser
displays the same thing for every site, as some sort of side-bar or
something, then phishers can convince the browser to show it on their
phishing site, and only a slight difference in the URL will alert the user
about the attack.
So, I guess you can't let the phisher convince the browser to show it,
which means it can only be shown for specifically trusted sites, such as
your work related login pages.

@_date: 2017-02-08 09:46:49
@_author: Bill Cox 
@_subject: [Cryptography] [FORGED] Re: So please tell me. Why is my 
Good solutions are almost universally dismissed.  The trick is to ignore
the negative feedback and keep inventing new ideas, both good and bad.
Here's a story that highlights this in crypto.  An undergrad student at UC
Berkeley in the 1970's took a crypto class which required that each student
pick a class project to implement during the course.  This student came up
with the following idea for a class project:
- Alice and Bob want to communicate, but Eve sees every message that Alice
and Bob send each other.
- Alice encrypts 1,024 strong keys (back then a strong key was 64 bits
long), using random weak keys that are only 20 bits.  The encrypted strong
keys are MACed so that you can figure out when you've found the right
20-bit weak key.
- Alice sends the encrypted strong keys to Bob
- Bob picks one at random and guesses the weak 20-bit key to get the strong
64-bit key.  This takes about 500,000 attempts to guess the weak key on
- Bob sends a message back to Alice, saying "I am using this key",
encrypted with the strong key that Bob decrypted.
- Alice tries all 1024 strong keys that she generated, finds the correct
one, and starts communicating with Bob using that strong key.
Eve sees all 1024 encrypted keys, but does not know which one Bob picked,
so Eve has to crack on average 500 of them before she finds the one Bob
picked.  Assuming Eve has only similar compute power to Bob and Alice, Eve
will most likely be kept out of the conversation for the time it takes to
do 500,000,000 decryption attempts, probably hours or days.
This scheme is the first publicly known public key cryptography, though the
NSA claims they invented it first.  The student invented public key crypto
for an undergrad class project.  It eventually revolutionized the entire
The professor rejected the student's proposal, saying, "That's not how
crypto is done."  The student was so upset that he dropped the class and
forgot about crypto entirely until he was in grad school at Stanford.  That
student was Ralph Merkle, and his invention is called Merkle Puzzles
.  He's credited as the
inventor of public key cryptography, among several other incredible

@_date: 2017-02-16 05:57:32
@_author: Bill Cox 
@_subject: [Cryptography] HSMs or Intel SGX? Which is harder to hack? 
If you wanted to store secrets so securely that you could never get them
out, how would you do it?  The secrets need to be usable for things like
signing, but they should be unrecoverable.  In particular, is it better to
buy an HSM, or use Intel's SGX mode on some of its newer processors?  If
the answer is HSM, which one(s)?
What if both the hardware cost and ongoing power cost are taken into
Assume that the secrets are initially stored in an SGX enclave, or HSM
before an attacker has access to the system.  After that, the attacker has
full access, including physical access, to the HSM or CPU.  The attacker is
capable of dissolving the CPU packaging, reading fuses, and is skilled at
hacking HSMs.  Assume that all design secrets of both the Intel SGX
implementation and the HSM have been published, so there is zero security
through obscurity.
How would you make your secrets usable, but unrecoverable?  I realize that
there is no perfect security for secrets.  They can always be extracted.
However, which is a better solution?  Which is a more practical solution,
given that cost matters?

@_date: 2017-02-16 08:15:03
@_author: Bill Cox 
@_subject: [Cryptography] So please tell me. Why is my solution wrong? 
Full disclosure: other people in my group at work develop and maintain
software for this key, so I can't say I am entirely disinterested in
whether or not it becomes a commercial success.  However, I have no
financial incentive to promote this:
I think having the key so small that it fits entirely inside your
computer's USB port is revolutionary.   It becomes part of your computer
rather than something you have to carry around.  It nearly eliminates the
PITA factor of all the other keys I've used.
Using FIDO, the web site makes your key blink, and then your touch it.
That's it.  It defeats most phishing and even provides an addition layer of
defense for your online data in the case that malware compromises your
computer.  People will argue that this extra layer is useless, but I think
every layer is welcome.

@_date: 2017-02-16 18:43:39
@_author: Bill Cox 
@_subject: [Cryptography] HSMs or Intel SGX? Which is harder to hack? 
The cost per signature is the main metric for being "practical" in this
case.  A 100K/second signature capable HSM that costs $1M would be worse
than a 10/second signature capable device that costs $1.  I don't care
about FIPS compliance, as it no longer seems well correlated with good
For being practical, Intel SGX has the advantage here, assuming I have the
SGX capable CPUs I need anyway.  However, security comes first.  In this
case, I only care about attacks that occur after securely booting the SGX
enclave or HSM.
For an example attack on SGX, IIUC based on what I've read in Intel's
public docs, an SGX enclave can have it's cached data evicted to DRAM, and
that data will be encrypted with a symmetric key derived from the CPU's
fuse settings.  If I save that encrypted data, and then extract the keys
from the CPU chip debugging/reverse-engineering lab, then I can
decrypt the cache lines, because I assume the attacker knows everything
about how the CPU works.
I imagine that a good HSM should be harder to hack, but I don't know.
First of all, the secrets remain in SRAM inside the device, and never
leave, so the attacker has to extract the secrets while power is on, or
somehow chill the SRAM rapidly so the state remains for a while.  A good
HSM might have counter-measures and erase SRAM base secrets when it detects
a potential attack such as power loss (or over-voltage) or a rapid change
in temperature, or vibrations from drilling holes.  Maybe there's a shield
layer around the whole thing that would prevent most physical attacks... I
have no idea.
I could keep reading manufacturer's claims of their HSM security, but I
just can't read any more unsubstantiated claims of "military grade"
security.  I was hoping some of you folks might know the real story, and
save me the effort of discerning reality from fiction based on HSM
marketing material.

@_date: 2017-02-16 19:08:07
@_author: Bill Cox 
@_subject: [Cryptography] HSMs or Intel SGX? Which is harder to hack? 
Here's an example of what makes it hard for me to read about HSMs.  I'm
picking on Thales here only by chance.  I know for a fact that they are a
well respected HSM vendor, but OMG, reading their web page is very hard for
even an arm-chair crypto-geek like me.  Some quotes from this page
"While devices from Thales have been proven in a range of settings
including some of the worlds most stringent environments, you do not need
to take our word for the fact that they are more secure. Thales products
have been independently certified to meet FIPS 140-2 and Common Criteria
What is the actual state of real-world security from respectable HSMs?  How
hard is it to extract secrets from a "level 4" tamper-resistant HSM that
attempts to erase secrets when a potential attack is detecte?

@_date: 2017-02-19 18:07:51
@_author: Bill Cox 
@_subject: [Cryptography] HSMs or Intel SGX? Which is harder to hack? 
That seems pretty weak: extracting the publicly visible metadata from a
binary isn't a break.  That information was published.
 I actually am dropping SGX from the running because it cannot support what
I call "dynamic defense".  A software-only attacker can force all the SGX
secrets to be dumped to SRAM, though they are encrypted with the CPU's
symmetric key.  An attacker can do this, and come back later and take her
time extracting the secrets from the CPU.
This defeats any attempt to make secrets time-sensitive, meaning we want to
force hackers to complete their work in a short period of time, or fail.
An HSM does not seem to have this problem.

@_date: 2017-02-27 04:47:12
@_author: Bill Cox 
@_subject: [Cryptography] Just in case it isn't obvious... 
I found another simple fix for git.  I thought it would be really hard,
because "SHA1" is a hard-coded call in ~1,000 places.  Instead, just define
a new function called sha1.  I've added a BLAKE2b wrapper locally.  It was
a tiny change, makes it more secure, and is faster than SHA1.

@_date: 2017-07-18 14:45:13
@_author: Bill Cox 
@_subject: [Cryptography] Raspberry Pi-like FPGA ?? 
It depends on your definition of cheap and easy.  AFAIK, this is the
cheapest FPGA
and you can get one for $1.50.  It has only 640 LUTs, though, so it is too
small for crypto.   This FPGA
seems large enough for some real crypto (12K LUTs), for $6.26.  I don't see
any nice USB dev-board for it, though.
A more mainstream FPGA might be this Xilinx Zynq FPGA
for about $50.  I don't like the high price tag, but the dev board looks
awesome at $89, and the 25K logic cells should be enough for some real

@_date: 2017-07-25 19:47:43
@_author: Bill Cox 
@_subject: [Cryptography] Anyone interested in a cheap security module for 
I am a fan of the Cryptech project
, but
the alpha boards are pricey.  I also am a fan of the low cost open SC4-HSM
, but I am interested in devices with better physical
I think I could build a fairly cheap daughter board for the Raspberry Pi
using the NXP Kinetis K81
.  I am interested in
algorithms for enhanced security using cooperating networks of security
modules, and this chip looks like a winner.  The Raspberry Pi would be used
for encrypted data storage and to run network protocols, while the Kinetis
K81 would physically secure the data's privacy, do the crypto, and
The K8 microcontroller is about $11.  The rest of the parts might add up to
another $3, and another $2 for the board.  If Macrofab
 continues the success they showed with my build of
three TRNG boards, then I would expect the total price from them to be
maybe 60% over the part cost, which in this case might be around $25.
People could justify selling them for probably the $50 range.
Would something like that be of interest to anyone else?

@_date: 2017-07-26 11:10:17
@_author: Bill Cox 
@_subject: [Cryptography] Anyone interested in a cheap security module for 
could be:
- Malware on the host computer
- The owner of the device, so pass phrases do not help
- A botnet of HSM emulators, so I'll need hardware attestation
- A group of hackers motivated enough to buy a large number of HSMs and PWN
them to control the network
I think it would be useful to have:
- Basic tamper resistance
Having an accessible debug port would be bad.  This would allow an attacker
to see secret keys.  There is a debug port on the  STM32F405R.  Do you
somehow disable it?
Neither a safe nor passphrase would help, because the owner is in the
threat model.  I do not want to lock it down like a Tivo, but instead have
the hardware erase all secrets, including the attestation key, before
allowing the owner to reprogram the entire device.
Tamper detection would be useful.  Random physical auditing of nodes could
help determine when the fraction of PWNed nodes is getting too high, but
only if we can tell when a device has been PWNed.  We could use glitter
nail polish and a photo of the original device to detect physical
intrusion.  It is also important to thwart side-channel attacks, such as
extracting secrets using timing, power analysis, or RF emissions.  We do
not need to defend against experts since they are rare, but a you-tube
video should not be enough to enable most HSM owners to easily PWN their
device through side-channels.
- Verifiable boot and firmware updates.
I'll need to be able to run a boot loader that verifies firmware signatures
before upgrading, and in some cases, it will need to erase secrets before
upgrading.  Can the STM32F405R do that?
- ECC (P256 is fine), AES, and SHA256 acceleration to enable reasonable
transactions per second (as in more than 1).
The main metric here is hardware cost per transaction per second.  The K81
is pretty fast at 150 MHz, but it is slower than the  STM32F405R, and the
K81 costs about 30% more.  I'm assuming the crypto engines are equivalent...
- Several KiB of SRAM, say a minimum of 4KiB
SRAM is divided up between applications, and one applications cannot read
another's SRAM.  More SRAM is better.  The K81's 256KiB of SRAM is more
than I need as is the 192KiB on the  STM32F405R.
- A lot of flash, say at least 100KiB
Flash would be divided between the virtual machine emulator and the
application it runs, so each app only gets a fraction of flash memory.  The
K81's 256KiB of flash seems low, but probably good enough.  The 1MiB of
the  STM32F405R is a nice upgrade.
Do you think a SC4-HSM might be close to supporting this application's
needs?  If not, would you have any interest in having my help developing a
new HSM that would?

@_date: 2017-07-26 14:18:10
@_author: Bill Cox 
@_subject: [Cryptography] Anyone interested in a cheap security module for 
What I would do is run some software on the user's computer to form a
network of HSMs.  Only firmware and keys in the HSM need to be trusted, not
the host software.  The HSMs would secure not just the owner's secrets, but
would participate in securing secrets of other users.  This creates a
potential incentive for the owner to hack their own HSM, since the secrets
of others might be valuable.  The idea sounds a bit nutty, but there seem
to be ways to improve security, reliability, and availability considerably
with this approach.
Some concerns I would have putting my secrets into a SC4-HSM: What if I
lose it?  What if it breaks?  Do I need to backup all my secrets?  What if
I want to buy a hamburger with my bitcoins bug my HSM is plugged in at
home?  What if an attacker steals it and brute-forces my HSM pin/password?
Do I need to use a super-hard password, and enter it every time I buy a
hamburger?  I really just want to buy a Hamburger with bitcoins on my
phone.  Can I do that with the HSM, without carrying it around?  There seem
to be opportunities to improve on all this with networked HSMs working
together.  That's the area I am currently interested in.
Attackers who want to PWN the network of collaborating HSMs would like to
run emulators.
I checked it out.  RDP mode 2 looks like what I want.
HSM network.  There are ways to mitigate the risk, but the HSM owner is
considered a potential attacker.
Thanks for the tip.  This looks good.
I might want a semi-clear glitter paint or nail polish over the MCU, maybe
just the leads.  This should not make it hard to verify that the MCU is
what it is supposed to be, but make it hard to replace the MCU with a PWNed
one, which could happen while I mail a pre-programmed HSM in DRP mode 2 to
a customer.  There would be no way for the customer to verify the firmware
isn't hacked once mode 2 is enabled, but they could compare the glitter
paint to the picture on a web site.
In DPR mode 2, I'd need a boot loader to enable firmware upgrades.  I need
a bit more flexibility than the built-in mode 1.  For example, I might have
a bitcoin app loaded, and want to also load a U2F app.  I do not want to
lose my bitcoins when adding the U2F app.  However, if someone wants
program upload a new virtual machine, some apps might want their data
erased, even if the binary is signed by the author.
Being open is my favorite feature of the SC4-HSM.
True, but I'd want to be able to install apps, somewhat like javacard apps
(but 10X less complexity in the VM).  At that point, I want to trust the
app author.
This was a nice surprise to me.  Looks like they got this part right.
Half a second is painful.  I suspect that can be sped up with custom
assembly code, but I would prefer ECC acceleration here: preferably a nice
wide multiplier.  I can't find the NXP K81 ECC acceleration speeds.  I
can't find a reference manual or user guide either, which is a potential
huge problem.  Does NXP require an NDA to have access to their K81 user
manual?  That would make it very hard to use in an open system.  However,
at least they claim to have ECC hardware acceleration, and that likely
gives it a 10X speed boost.
In some similar applications, ECC took about 1/3 the time with hardware
acceleration, since I do multiple ECC operations per transaction.
It looks very good to me for its intended purpose, and I still want one.
a very long time.  I am interested in open security modules partly so I can
make progress on algorithms without waiting for hardware to appear in data
Your device is close to what I am looking for.  There is also a $50 dev
board for the K81, which might make a good dev platform, if I can ever find
the user manual for the K81.

@_date: 2017-07-27 09:10:39
@_author: Bill Cox 
@_subject: [Cryptography] Anyone interested in a cheap security module for 
Well, crud!  The Kinetis K81 reference manual is only available under NDA.
That is no problem for me, and probably not for most users, but some
open-source developers may balk at working with a chip who's documentation
is not open.
What are the alternatives for a secure microcontroller with elliptic-curve
crypto acceleration?

@_date: 2017-03-29 08:48:55
@_author: Bill Cox 
@_subject: [Cryptography] "Perpetual Encryption" 
The following scheme scores highly, except that it has no web site:
I invented an amazing truly unhackable super-encryption algorithm:
1) Generate n bits of true random data that have no bias or any detectable
2) Manually deliver this OTP random bits to the recipient, then go home.
3) XOR OTP data with an n-bit secret message to generate ciphertext.
4) Use HMAC-SHA512(ciphertext) to generate tag
6) Transmit ciphertext | tag over any unsecured channel to the recipient.
I claim this OTP scheme has "perfect security", is authenticated, has
information theoretic security, is trivially provable as CCA2 secure, is
simpler than all popular AEAD schemes, and yet is completely useless :)

@_date: 2017-03-29 09:12:52
@_author: Bill Cox 
@_subject: [Cryptography] "Perpetual Encryption" 
Duh.  This scheme needs a MAC for auth.  So, generate replace
HMAC-SHA512(ciphertext) with HMAC-SHA512(OTP data | ciphertext).
Anyway, to pick on Patrick's scheme a bit more, it looks like this:
\T1=(xor K1 M1)
\T2=(xor K1 K2)
Those two bits T1 and T2 are transmitted in the clear.
For the next transmission, we have:
\T3=(xor K2 M2)
\T4=(xor K2 K3)
Suppose M1 is known to the attacker.  Then M2 = T1 XOR T2 XOR T3 XOR M1.
Obviously, no scheme that transmits m bits of secret message protected by
only k bits of secret key can have "perfect security".
This brings me to a practice I see used commonly which drives me nuts.  In
the cloud, vendors like to share TRNG data from one hardware TRNG with many
virtual machines that need entropy.  Worried that an eavesdropper might be
listening to the channel between the TRNG and virtual machines, they
encrypt the TRNG data stream.
It is not possible to increase the entropy of a remote machine when an
eavesdropper is listening.  The remote machine requires its own TRNG, or
some ability to collect unpredictable events not seen by the eavesdropper.

@_date: 2017-11-03 23:17:36
@_author: Bill Cox 
@_subject: [Cryptography] Here's how to evaluate tan(x) mod p... math to hurt 
The cool thing is that we can transform an addition law for a
transcendental function, the tangent function, into a*b with an algebraic
variable substitution.  That kind of freaks me out.  These functions work
with identities I've tried so far in Python, when solutions exist.  The
angles are complex numbers with integer values, mod p:
def arctan(a, q):
    return Complex(2*modinv(a**2 + 1, q) - 1, -2*a*modinv(a**2 + 1, q), q)
def tan(a):
    q = a.q
    x, y = a.real, a.imag
    return (-2*y*modinv((x + 1)**2 + y**2, q)) % q
This leads to definitions for sin and cos, though the sqrt only exists half
the time, and it needs to use tan2 to get the signs right, which I haven't
def sin(A):
    q = A.q
    return sqrt(tan(A)**2*modinv(tan(A)**2 + 1, q), q)
def cos(A):
    q = A.q
    return sqrt(modinv(1 + tan(A)**2, q), q)
I defined these functions based on a variable substitution that converts
the tangent angle addition formula into regular multiplication.  The
tangent addition law is:
    tan(A + B) = (tan(A) + tan(B))/(1 - tan(A)*tan(B))
Substituting A = arctan(a), B = arctan(b):
    tan(arctan(a) + arctan(b)) = (a + b)/(1 - a*b)
This forms a valid addition operator.  All addition functions I've seen,
and I conjecture this is generally true, can be converted into this form:
    a :+: b = F(Finv(a) + Finv(b))
This is true with elliptic curves as well as the simpler circle group.  For
elliptic curves equivalent to Edwards curves we have:
    a :+: b = sn(F(a;m) + F(b;m), m)
where sn is the Jacobi elliptic sine funciton, and F is the elliptic
integral of the first kind.  We can apply a variable substitution to
convert this into regular multiplication of complex numbers:
    a = -i(2/(A + 1) - 1)
When plugged into the tangent addition rule (a + b)/(1 -a*b) we get a*b.
The whole thing can be naturally computed mod p.  How cool is that?

@_date: 2017-10-25 22:53:32
@_author: Bill Cox 
@_subject: [Cryptography] Has there been any good cryptanalysis of FourQ yet? 
It was announced back in 2015
Back then, AFAIK, it was still lacking constant-time implementations, so it
was not really possible to benchmark.  Now they've got constant-time code
for several variants of ARM, as well as x86
.  There is also an IETF draft for
standardization , though
I understand that does not mean much on its own.
My Haswell laptop says it takes only 50664 CPU cycles for compressed point
multiplication, which should only be around 17us.  In contrast, my laptop
takes about 100us to perform a NIST P256 point multiplication.
Do we think this algorithm is secure?  Is it growing up?

@_date: 2018-08-12 12:41:37
@_author: Bill Cox 
@_subject: [Cryptography] Crowd Supply announces Infinite Noise TRNG 
This guy has my full support.  He did a great job on this hardware.  He
even had it UL tested.  He sent me one for free, which is more that enough
compensation for me :)  Anyone is welcome to freely clone any of my
open-source projects (including open hardware), for fun and profit.  I also
support OneRNG, but 1) this is better, and 2) more open-source TRNGs is a
good thing.  Hopefully there will be enough folks out there buying both of
these to encourage new versions in the future, as well as robust software
That said, here's a ridiculously simple TRNG architecture that you cant
use, IIUC (highly unlikely: IANAL), due to a-holes patenting security:
Use a flawed ring-oscillator with an _even_ number of inverters (actually
you want 4*n + 2 inverters).  Useless, right?  Now take two inverters at
opposite sides of the ring, and turn them into 2-input NAND gates, which
creates 2 enable inputs, which you tie together.  When enable is low, the
ring is stable, with the other NAND-gate inputs being high.  When enable
goes high, two edges chase each other around the ring until they collide
and annihilate each other.  Count how many times an edge goes around the
ring and wait for the counter to be stable.  The low bits of the counter
are generally reasonably random.  The counter values form a Poisson
distribution when noise in the ring is consistent, which your
health-checker should verify before using the TRNG output.
The criteria I look for in a good TRNG architecture include:
- Freely available design (open-source), without IP ownership issues.
- Clean physical model, enabling good health-checking
- Continues working well over changes in process, temperature, voltage,
age, etc
- Resistant to radio and supply voltage attacks
- Difficult to screw up
- Cheap, even if that makes it run slowly: we only need 256 bits of entropy
to seed a CPRNG
This simple almost-ring-oscillator checks all the boxes, except the first
and most important one.  One day, this architecture will be free for all to
use, and at that time, I'll start recommending it.  Until then, at least
for a USB form-factor, I recommend this guy's new Infinite Noise TRNG.  It
checks all the boxes.

@_date: 2018-12-06 19:48:28
@_author: Bill Cox 
@_subject: [Cryptography] What if Responsible Encryption Back-Doors Were 
Re-posting, minus the bottom post cruft that isn't allowed by moderators,
yet is completely hidden by Gmail...  This is a BOTTOM post, because
nothing follows it.
As for responsible encryption policies, I believe:
1) It is possible, but _hard_ and _expensive_ to build it securely.
2) No one wants to be in a position where a mass murderer has encrypted
data that cannot be revealed to law enforcement.
3) Governments will always over-reach and go for mass-surveylence that
violates everyone's privacy.
I wont go into tech details, but if Bitcoin can protect billions in online
value, there are systems that can unlock back-doors without too many
failures to make the system a bad idea.  Check out what Oasis Labs is up
to, for some good ideas (that remain to be proven).  The problem is that
while the public wants tech companies to help law enforcement in extreme
cases, no one wants to simply let governments around the world spy on
absolutely everything we do.
IMO, the only acceptable solutions to this problem will require distributed
trust (like Bitcoin), such that users' devices can participate in decisions
on how their data is used, distributed widely enough that no single entity
can unilaterally decrypt a user's data  Data policies will need to be
automated, like smart-contracts on something better than the total-crap
Ethereum VM.  When a backdoor is used (or used too often), it should make
the news, because a bunch of different interested folks would notice the
transaction(s) on the blockchain.  Secret mass surveylence should be
impossible, as a key requirement for the system design.  Publicly visible
mass surveylence should be prohibited by the smart contracts, and the
public should hold governments accountable for overreach.
If the public can monitor the access policy and frequencey of use of these
backdoors, then the tech companies will have a way out of the ethical
delema law enforcement always tries to put them in: secretly snooping on
users for the government (like we saw with Yahoo).
Anyway, I feel very strongly that folks out there should start thinking
along these lines.  We'll have to cooperate to make it happen.

@_date: 2018-02-16 05:57:12
@_author: Bill Cox 
@_subject: [Cryptography] Quantum computers will never overcome noise 
Surely you have access to an electron beam device capable of 10nm
The cost per device created will be 1000x higher than for bulk CMOS and
standard UV lithography, but why would you care?

@_date: 2018-02-19 08:45:04
@_author: Bill Cox 
@_subject: [Cryptography] Hashgraph is cool, but over-hyped 
The concept is cool.  However, this is not a replacement for proof-of-work
or proof-of-stake in blockchain algorithms, both of which are intended to
scale to millions of nodes with a constant rate of work per node.  Some
downsides of Hashgraph in comparison to proof-of-work:
- O(n^2) data transfer and work per node per transaction block for graphs
of n nodes.
- O(n^3) total network traffic per transaction block.
- The network does not naturally expand after a media story.  It works best
on fixed-size networks of reliable nodes.
- There is no mining or related crypt-currency.  Nodes need to be paid to
- If the algorithm were changed to allow nodes to join quickly, it would be
subject to shill attacks.
- Poor DDoS defense, due to small graph size.
This is all fine assuming Hashgraph is not intended as a replacement for
proof-of-work or proof-of-stake.  However, it is
that way.  In particular, the claim of being more efficient is true only
for small networks of nodes, so I give this claim a "Pants-on-fire"
rating.  With O(n^3) network traffic, I don't expect to see Hashgraph
networks large enough to have decent DDoS defense compared to Bitcoin or
Hashgraph probably has good use cases, but don't expect it to change the
world of crypto-currency algorithms that it is being compared to.  I put
Hashgraph in the same boat as technologies like cold fusion, and the
Cuk "Optimum
Topology Switching DC-to-DC Converter"
.  If it takes an
expert to explain why inflated claims are false, then get ready for the
wild spread of over-inflated expectations, fueled by blogger click-bait.

@_date: 2018-05-03 17:37:52
@_author: Bill Cox 
@_subject: [Cryptography] Security weakness in iCloud keychain 
Ron, I'd recommend seeing if you can replicate this bug, preferably with a
new test account and a couple of devices you don't mind wiping afterwards.
This might be a bug they've fixed already.

@_date: 2018-05-08 14:16:38
@_author: Bill Cox 
@_subject: [Cryptography] secure authentication ... as opposed to passwords 
We should be heading in that direction.  However, Zero Knowledge proofs
don't work for passwords.  The problem is that passwords are guessable.
Zero knowledge proofs work only for proving knowledge of secrets so
difficult to guess, that we can ignore that case.  For example, a
zero-knowledge proof of the discrete log of a number in a field where the
discrete log is hard to compute wont work for passwords, because the proof
relies on g^s, where g is the base and s is the secret.  If s is derived
from a low-entropy password, anyone can mount a brute-force attack on s.
We do have Zero Knowledge Password Proofs
, which is a
misleading term: the verifier must be in possession of data derived from
the password, meaning that the verifier can mount a brute-force attack.
We should be able to eliminate sending passwords to servers in most cases,
and instead let our devices authenticate for us.  We authenticate to the
device, possibly with a password, pin, fingerprint, etc.  Then the device
proves possession of a private key to the server, which is enough for the
server to allow access to that user's data (unless we have 2-factor on,
which is superior).
However, even then, we still have the "new device" problem."  How do we
give access to a user's account when the user is on a new device that she
has never used before, and when they have no access to previously
registered devices?
So, we still require companies to secure their password-derived data.  One
angle to work here is to secure that data better.  For example, encrypt the
password-derived secret to the public key of trusted hardware, rather than
writing a password hash and salt to a database.
If there is another angle, where companies no longer require
password-derived data to help authenticate users on new devices (and
previously registered devices are not available), I'd love to hear about it.

@_date: 2018-11-03 11:16:53
@_author: Bill Cox 
@_subject: [Cryptography] hash size 
communication overhead.  A recent paper about this algorithm that was
invented in 1994:
128-bit is simply not collision resistant for any modern efficiently
computed hash.  If you don't care about collisions, sha1 still is secure.
There are already collisions for SHA1
Generating the collision took ~2^63 SHA1 computations.  Google did it for
fun (well... really to make the point that SHA1 is insecure).

@_date: 2019-08-25 04:07:20
@_author: Bill Cox 
@_subject: [Cryptography] "Entropy as a Service: A New Resource for Secure 
It's just a bad paper
, and a
confusing article based on it.  Here's the heart of their protocol:
The client makes a HTTP GET request to the EaaS server, with the number of
Pretty funny.  Encryption requires a secret that potential attackers do not
know.  To get such entropy, use this protocol.  To use this protocol, you
require a secret (the private key) that potential attackers do not know...
I run into this silly concept now and then.  IIRC, the "Entropy Key" even
has an Entropy-as-a-Service feature for encrypting random numbers to
multiple servers in a data center.  It cracks me up that folks who know
enough to make a decent TRNG don't understand why you can't just do a DH
key exchange, and send the remote server the entropy it needs to do a
secure DH key exchange.

@_date: 2019-08-25 06:14:11
@_author: Bill Cox 
@_subject: [Cryptography] The best TRNG architecture, comming soon? 
Ring oscillator based TRNGs suck, hugely.  They are the reason we have so
many RSA keys out there with one common factor.  They are hard to get right
because no one knows exactly how much entropy is coming from them, and
everyone wants to boot fast, so we read them too soon.
The best, but patented IIRC, architecture for a TRNG is super simple.
Since I'm not supposed to look at patents anymore, can someone take a look
and see when this circuit will be available for the world to use
unencumbered?  Here's a picture of the circuit:
[image: image.png]
In real life, you probably want to add more inverters than this.  This is
like a traditional ring oscillator, but with an *even* number of
inverters.  You take two inverters at opposite ends of the ring and turn
them into NAND gates.  The other inputs of both NAND gates are tied
together to make the ENABLE input.  When ENABLE is low, OUT is low.  When
ENABLE goes high, two edges in the ring oscillator chase each other.
Eventually, due to thermal or other noise, one edge catches the other, and
they annihilate each other.  The oscillator stops oscillating at this point.
To extract entropy, in a tight counter loop, poll the output.  When it is
stable for enough samples, say 32, the random output is the last loop
counter value where OUT changed.  Write  this value into the entropy pool,
and permute the pool (in Linux, just write it to /dev/random).  Repeat
until you have enough entropy in your pool.  The counter values form a
Poisson distribution.  The entropy per sample
 is roughly:
    entropy ~= 1/2 * log(2?e?) - 1/(12*?) - 1/(24*?^2)
However, a simpler rule is for counter values up to 100 million, you get
over  40% of log2(count) entropy per sample.  So, if you have a 12 bit
counter value, add 0.4*12 = 4.8 bits to your entropy estimate when you mix
in the counter value.
Advantages of this scheme vs the traditional lame ring oscillator that
causes IoT devices to get PWNed:
- Easy to estmate entropy per sample, due to a good physical model for
- An attacker might lock the oscillator to their oscillator source, but
they cannot reduce the entropy in the output sample.
- If for whatever reason the noise in the this source becomes weaker over
time, it self-compensates by running longer.
- The layout matters little.  Just let the place and route tools place it
however it likes.
This circuit retains the nice properties of traditional ring oscillator
TRNGs, which make them so popular:
- Simle and tiny.
- Easy to implement on CPLDs, FPGAs, and ASICs.
- Purely digital: no analog design skills required.
I've forgotten how long the patent on this circuit will run.  It *might*
have expired by now, I have no idea.

@_date: 2019-08-26 11:19:02
@_author: Bill Cox 
@_subject: [Cryptography] The best TRNG architecture, comming soon? 
Good point.   It is OK for rise/fall to be different, but the lower chain
needs to match the upper chain well.  This requires some manual constraints
in an FPGA/CPLD.  It is possible in some systems (the P&R tools I worked on
for Triad Semiconductor) to copy the place and rout result from instance A
to instance B, translated by some distance in the fabric.  That generally
causes the routing to match well.  I'm not sure if the major FPGA/CPLD
providers offer this functionality.

@_date: 2019-01-24 17:40:51
@_author: Bill Cox 
@_subject: [Cryptography] Stupid question on S-boxes 
S-boxes leak secret key info through cache timing attacks.  IMO, they
should be avoided.

@_date: 2019-06-03 11:06:56
@_author: Bill Cox 
@_subject: [Cryptography] About Secret Sharing Schemes and a Question 
Sure, you can use partially-homomorphic ElGamal threshold encryption based
on Shamir secret sharing.  You want to add a way for each member to prove
they did their end of the computation honestly, so you'll need some custom
zero-knowledge proofs.  There are frameworks for generating them for code
like this.  You can encrypt, decrypt, re-encrypt to a new public key, or
sign which such a scheme.  No member learns anything about the shared
secret, and every so often the group can re-key, so if an attacker has some
shares < t, those shares become useless.

@_date: 2019-09-30 12:44:53
@_author: Bill Cox 
@_subject: [Cryptography] "Strong" passwords too clever by half... 
I did something even worse: On Android, I added a space at the end of my
password, which was accepted.  However, in browsers, the JavaScript for the
login page trims trailing spaces...
