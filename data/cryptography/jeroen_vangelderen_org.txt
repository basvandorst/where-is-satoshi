
@_date: 2001-04-02 17:27:26
@_author: Jeroen C. van Gelderen 
@_subject: secure hash modes for rijndael 
Could you give a URL for the benchmarks you looked at?
According to [1], a C implementation of SHA-256 is not much slower than SHA-1 on either Alpha or Itanium:
BeeCrypt 2.0.0, egcs-2.91.66, RedHat Linux 6.2, Alpha EV6.7 667, 2048 RAM
SHA-1   : 24.80  MB/sec
SHA-256 : 19.27  MB/sec
BeeCrypt 2.0.0, gcc-2.9-ia64, Linux64, Itanium 666, 2048 RAM
SHA-1   : 9.60   MB/sec
SHA-256 : 7.12   MB/sec
On the ia32 architecture however the difference is quite immense [1]:
BeeCrypt 2.0.0, gcc-2.95.3, Mandrake Linux 7.[0|1], PIII 800, 4096 RAM
SHA-1   : 39.00  MB/sec
SHA-256 : 18.60  MB/sec
This suggests that the difference is caused by some kind of
platform deficiency. My guess is that a lack of registers is
the root cause of the problem; Looking at the SHA-256 algorithm
internals we see that it uses 8 32-bit state variables. The ia32 platform has 7 32-bit registers available in the best case
and 5 or 6 on average. This means an awful lot of register spills and hence slow memory accesses in the performance critical inner loop of the SHA-256 algorithm. Using a better compiler (one that generates more efficient spills), unrolling the loops and implementing SHA-256 in ia32 assembly should increase the speed of SHA-256 on ia32 quite a [1]

@_date: 2002-08-10 17:42:31
@_author: Jeroen C.van Gelderen 
@_subject: Thanks, Lucky, for helping to kill gnutella 
This argument is a straw man but to be fair: I am looking forward to your detailed proof that the only way to protect a Gnutella-like network from rogue clients is a Palladium-like system. You are so adamant that I have to assume you have such proof sitting right on your desk. Please share it with us.

@_date: 2002-02-04 11:43:12
@_author: Jeroen C.van Gelderen 
@_subject: Welome to the Internet, here's your private key 
You sound surprised? I recently asked my bank[1] for a solvency statement on a personal account and they responded that they were not allowed to provide such statements. When pressed for an explanation I was told that handing out those statements caused them too much litigation. Apparently when the bank states that
   "Alice has been a customer since 23-01-1980 and as of
    12-12-1999 her account is in good standing."
they can (and have indeed been) be sued when Alice goes bankrupt in 2002. This despite the fact that the statement obviously does not make any claim about Alice in 2002. Now, the bank may very well win the court case, or they may not. Whatever the outcome, it will cost them.
The moral of the story is: when the legal system allows for silly cases like this, alternative protective measures[2] will be put in place, such as not handing out solvency statements[3], or forcing a user to accept a CA-generated private key. The problem here is not with the technical competence of the CA but rather with the CA being held liable and being forced to mitigate the risk of losing lots of money.
Technically speaking, having the CA generate the private keys allows the user to repudiate signatures made with the key. After all, the CA (or one of its employees) could have leaked the key or have signed stuff with it.
Practically speaking this would probably be solved by passing an additional law that declares CAs trustworthy by definition. After all, if you don't pass such a law, the PKI cannot work in the current legal framework. And CAs are run by the good people, right? What is wrong with effective key escrow for signature keys!? ;-p
We do not even want to think about the conflicts of interest: what incentive is there for a CA to report that it lost a user's private key?
[1]  ABN-AMRO.
[2]  Alternative because the legal system is supposed to protect the       party here but obviously fails.
[3]  The bank does have provisions for providing solvency statements on
      business accounts. They have insurance and make you pay Jeroen C. van Gelderen - jeroen at vangelderen.org
"Economics is a theoretical science and as such abstains from any
judgement of value. It is not its task to tell people what ends
they should aim at. It is a science of the means to be applied for
attainment of ends chosen, not, to be sure, a science of the choosing
of ends. Ultimate decisions, the valuations and the choosing of ends,
are beyond the scope of any science. Science never tells a man how
he should act; it merely shows how a man must act if he wants to
attain definite ends." -- Ludwig von Mises

@_date: 2003-12-06 14:36:35
@_author: Jeroen C.van Gelderen 
@_subject: origin of SHA 224 initial hash values 
I'd like to second this request for clarification.
I noted that 224 yields a security level identical to 2-key Triple DES.
A quick Google search reveals that SHA-224 is mentioned a few times, in
   draft-ietf-pkix-rsa-pkalgs-01.txt
   draft-ietf-smime-cms-rsa-kem-01.txt
among others.
A draft-ietf-pkix-sha224-00.txt is referenced but not yet available from the IETF website.
       *  80-bit security. The RSA key size SHOULD be at least 1024 bits,
          the hash function underlying KDF2 SHOULD be SHA-1 or above, and
          the symmetric key-wrapping scheme SHOULD be AES Key Wrap or
          Triple-DES Key Wrap.
       *  112-bit security. The RSA key size SHOULD be at least 2048
          bits, the hash function underlying KDF2 SHOULD be SHA-224 or
          above, and the symmetric key-wrapping scheme SHOULD be AES Key
          Wrap or Triple-DES Key Wrap.
       *  128-bit security. The RSA key size SHOULD be at least 3072
          bits, the hash function underlying KDF2 SHOULD be SHA-256 or
          above, and the symmetric key-wrapping scheme SHOULD be AES Key
          Wrap.
       -- draft-ietf-smime-cms-rsa-kem-01.txt, pg4

@_date: 2003-12-08 11:43:23
@_author: Jeroen C.van Gelderen 
@_subject: RSA-576? 
I didn't see anything on this list, but apparently RSA-576 has been

@_date: 2003-01-01 21:43:14
@_author: Jeroen C. van Gelderen 
@_subject: Implementation guides for DH? 
This may be of use:
"Over the last year or two, a large number of attacks have been found by the authors and others on protocols based on the discrete logarithm problem, such as ElGamal signature and Diffie Hellman key exchange. These attacks depend on causing variables to assume values whose discrete logarithms can be calculated, whether by forcing a protocol exchange into a smooth subgroup or by choosing degenerate values directly. We survey these attacks and discuss how to build systems that are robust against..."
 anderson96minding,
     author = "Anderson and Vaudenay",
     title = "Minding Your p's and q's",
     booktitle = "{ASIACRYPT}: Advances in Cryptology -- {ASIACRYPT}: International Conference on the Theory and Application of Cryptology",
     publisher = "LNCS, Springer-Verlag",
     year = "1996",
     url = "citeseer.nj.nec.com/anderson96minding.html" }

@_date: 2003-01-20 16:53:18
@_author: Jeroen C. van Gelderen 
@_subject: Key Pair Agreement? 
Here is a scenario: Scott wants Alice to generate a key pair after which he will receive Alice's public key. At the same time, Scott wants to make sure that this key pair is newly generated (has not been used I do not know what the proper terminology is to discuss this. Assuming there is none, I will call the solution Key Pair Agreement.
 From HAC we know that "Key Agreement is a key establishment technique in which a shared secret is derived by two (or more) parties ... such that no party can pre-determine the resulting value".
Let's see if we can come up with a informal definition of Key Pair Key Pair Agreement is a protocol in which two parties A and S interact such that
  - A generates a private key Kpriv and the corresponding public
    key Kpub
  - S can randomize the key generation process by providing a
    SEED1 such that A cannot pre-determine either Kpriv or Kpub
  - S cannot not learn anything about Kpriv
    (S cannot pre-determine either Kpriv or Kpub)
  - Given SEED1 and Kpub one can determine if the Key Pair
    generation process was randomized by SEED1.
It would seem that the DSA key structure facilitates this:
1. Scott sends SEED1 to Alice.
2. Alice picks a random number SEED2.
3. Alice sets SEED=SHA1(SEED1 || SEED2).
4. Alice generates a set of DSA parameters P, Q, G using the
    algorithm in Appendix 2, FIP-186-2.
5. Alice generates a key pair (x,y) using the parameters from (4).
6. Alice sends SEED2, counter, P, Q, G, y to Scott.
7. Scott generates P', Q', G' based on SEED=SHA1(SEED1 || SEED2),
    counter, and compares them to P, Q, G.
This is a very expensive key generation operation but it would
seem to work.
My questions are:
0) who has invented this before?
1) does it achieve what I think it achieves?
2) does anybody know of more efficient algorithms?

@_date: 2003-07-10 14:52:17
@_author: Jeroen C. van Gelderen 
@_subject: replay & integrity  
From what I can see, both IanG and Zooko are making an end-to-end argument: if one requires end-to-end replay (integrity/confidentiality) protection, one does not necessarily benefit from the corresponding point-to-point mechanisms that SSL provides.
IIRC SSL provides secure, point-to-point, ordered byte streams. Systemics' SOX tries to provide secure, end-to-end, (partially) offline, non-repudiable, unordered, at-most-once transactions.  There is no benefit in using SSL underneath SOX: if SOX is insecure, using SSL won't help (except perhaps of obfuscate the problems) and if SOX is indeed secure, it provides all the security functionality that is required.
There are plenty other situations in which use of SSL is counterproductive or impossible. Various group communication and replication algorithms (BFT) come to mind, as well as various UDP-based Reinventing SSL is not such a good idea (although -having studied the SSL spec a few years ago- I can see why the SSH designers went that route). Blindly assuming everyone can or should use SSL is an equally bad idea.
That is fine, my understanding isn't perfect either. You should not need a book to be able to use or discuss an open protocol like SSL/TLS. As Eric Rescorla said: "What makes developer's lives simple is simple [good stuff elided]
It might get you from per-session protection to across-all-session protection. But it can never protect against injecting two messages with identical meaning (replay) into the SSL layer twice.

@_date: 2003-07-10 14:43:41
@_author: Jeroen C. van Gelderen 
@_subject: replay & integrity 
This would be a side-channel problem in the protocol which needs to be fixed, not obfuscated by an integrity mechanism. Worse, the integrity protection didn't even work in TLS 1.0: "TLS v1.0 also provides an optional MAC which failed to thwart the attack..." [Vau02a].
[Vau02a]

@_date: 2003-06-03 17:21:49
@_author: Jeroen C. van Gelderen 
@_subject: Maybe It's Snake Oil All the Way Down 
(I noticed that SSL and HTTPS are sometimes used interchangeably in this thread and sometimes not (i.e. STARTTLS). I'll concentrate on HTTPS in this mail. Note that HTTPS is slightly broader than just SSL: it also includes the browser interface.)
Absolute numbers are one measure. Another would be to consider the ratio of HTTPS/HTTP and SSH/telnet. You could define a successful protocol by ability to displace its unprotected equivalent. I for one would consider that a more useful measure. I bet you find that HTTPS is non-existent according to this definition, completely disappearing in the noise. Interestingly (and IMHO correctly) enough OpenPGP fails this test too. Miserably.
Perhaps that measure is too coarse grained. For instance, in the domain of "security advisories" most emails are digitally signed with OpenPGP. And in the domain of online credit card payments HTTPS has displaced But HTTPS covers only those transactions for which users demand protection. Actually, that isn't quite correct. It is those transactions for which the users want to *feel* [2] protected. It is mindbogglingly easy to spoof an HTTPS site. Either with or without the impostor using a certificate. (Today, I can register  and obtain a matching certificate for $100. All the user will see is a lock icon and he thinks he is safely on A large part of the problem obviously is the browser's user interface. The other part mainly concerns the use of CA certificates. Self-signed certificates only compound the problem by teaching the user bad habits. ("Oh, if the browser asks a question, just click yes." Guess what: people will now always click "YES" on certificate related questions, whatever the question or warning is.)
Penetration? Even privacy-sensitive sites like, say,  do not utilize HTTPS by default. The possibility of HTTPS access isn't even mentioned on the homepage. No support for RFC 2817 and no transparent redirect either. You have to manually change http: to https: for it to work.
Same for  When you manually go to the HTTPS version you will note that they use a self-signed certificate   a) requires user interaction and a user
     knowing what she is doing;
  b) erodes the value of security questions
     (through teaching bad habits)
  c) doesn't cache the key so subsequent
     MITM attacks are not defended against.
Another sensitive site? How about HTTPS access to Google ... ?
SSH on the other hand succeeded in protecting network infrastructure nearly transparently. It virtually replaced telnet in places where it matters (and a whole lot where it doesn't). I don't have to change addresses or port numbers. Open-source UNIXes have it enabled by default. It completely redefined how X screens are remoted for the (small?) set of users that are interested in that. Of course its protocol isn't perfect and it certainly is vulnerable to the MITM on the first connection. But I bet it offers more real protection than HTTPS, as *presently* implemented, ever will. SSH is the closest thing to opportunistic encryption I know of.
I guess this is qualified agreement with Ian's statement that SSH is the "only really successful net crypto system". I can only hope that people will adopt the displacement ratio as a measure of success and design their protocols (all the way up to the user interface) Lifting and modifying a quote from Peter Gutmann's homepage:
"I think a lot of purists would rather have cryptographic protocols be useless to anyone in any practical terms than to have it made simple enough to use, but potentially "flawed"."?-- with apologies to Chris [1] One exception would be the subset of mail roughly corresponding to security advisories. There OpenPGP signatures are the norm.
[2] Airport "security" anyone?

@_date: 2003-06-03 19:47:27
@_author: Jeroen van Gelderen 
@_subject: Maybe It's Snake Oil All the Way Down 
I noticed this the other day whilst buying something at Amazon: allegedly, Amazon doesn't store your CC number in a network readable "To provide you with an additional layer of security, all credit card numbers provided to Amazon.com are stored on a computer that is not connected to the Internet. After you type or call it in, your complete credit card number is transferred to this secure machine across a proprietary one-way interface. This computer is not accessible by network or modem, and the number is not stored anywhere else."
Now I'm not sure how they get to use the number during the billing process but hey... :)
I don't know if I'd feel much better if Amazon didn't have my CC on file. The danger of a disgruntled sysadmin snarfing the numbers while they pass trough the system for one time use during a single billing cycle seems to real for me.

@_date: 2003-03-14 00:38:14
@_author: Jeroen C. van Gelderen 
@_subject: Microsoft: Palladium will not limit what you can run 
and sold by Microsoft below cost (aka subsidized). With the expectation that you will be buying Microsoft games to offset the initial loss. (You don't have a right to this subsidy, it is up to Microsoft to set the terms here.)
and sold by numerous vendors. With no expectations like the ones above.
So, a fortiori you are comparing apples with oranges. Or you may have left out the part of your argument that bridges this gap.
Obviously a vendor can restrict what kind of software runs on the hardware he sells, either by contract or trough technical means. In the latter case the consumer is of course free to circumvent the barriers, provided that he lives in a free country. If he doesn't like the vendor's policy, he is of course free to vote with his wallet.
Your conclusion may or may not be warranted but it can definitely not be drawn from this 3-sentence argument.

@_date: 2003-03-24 19:24:55
@_author: Jeroen C. van Gelderen 
@_subject: Keysigning @ CFP2003 
It's rather efficient if you want to sign a large number of keys of people you mostly do not know personally.

@_date: 2003-03-24 19:50:39
@_author: Jeroen C. van Gelderen 
@_subject: Who's afraid of Mallory Wolf? 
Correct. On the other hand, in a lot of cases people cannot be expected to do the verification. This shows in the number of people that can be tricked into being spoofed out of their passwords, even when certificates are deployed. That is not an argument against certificates though, it is (partially) an argument against broken user interfaces.
What makes you say it is gratuitous? Or: how can you state my privacy is gratuitous?
This is illogical. Even if a server operator would prefer to allow unauthenticated encryption, he cannot do so without annoying 90% of his customers because they too will be getting these alarming messages. In general, if my browsing privacy is important to me and the server operator is willing to accomodate me, he cannot do so.
This however still does not constitute an argument against certificates. It can be morphed as an argument against browsers not supporting Anonymous-DH. (Note that I'm favoring treating sites offering ADH the same as sites offering a certificate. Each offers different functionality which should be distinguishable in the GUI.)

@_date: 2003-03-25 00:22:04
@_author: Jeroen van Gelderen 
@_subject: Keysigning @ CFP2003 
Not that I heard of. I always understood that I should be 'convinced' of the identity and willing to state that to others.
Knowing someone personally is very nice and gives you rather a lot of assurance that their identity is being used consistently and that others know the person by the same identity. (It is for precisely that reason that I have signed a few keys for people who use an alias.)
Sometimes however you have the choice between a 'weaker' form of certification and no certification at all. I prefer the former because it increases the chances of the WoT being useful. Key signing parties' reliance on passports are a case in point. In general passports are a reasonable indication of identity.
Yes. But PGP doesn't mandate either interpretation. That is what you use your trust knobs for: you decide on a per-user basis how trustworthy an identity certification from that user is. The redundancy of a well-connected WoT then helps you a bit in eliminating simple

@_date: 2003-03-25 01:42:53
@_author: Jeroen C. van Gelderen 
@_subject: Who's afraid of Mallory Wolf? 
This is good info!
True. Based on his first post however I think that IanG is saying something like:
1. Presently 1% of Internet traffic is protected by SSL against
    MITM and eavesdropping.
2. 99% of Internet traffic is not protected at all.
3. A significant portion of the 99% could benefit from
    protection against eavesdropping but has no need for
    MITM protection. (This is a priori a truth, or the
    traffic would be secured with SSL today or not exist.)
4. The SSL infrastructure (the combination of browsers,
    servers and the protocol) does not allow the use of
    SSL for privacy protection only. AnonDH is not supported
    by browsers and self-signed certificates as a workaround
    don't work well either.
5. The reason for (4) is that the MITM attack is overrated.
    People refuse to provide the privacy protection because
    it doesn't protect against MITM. Even though MITM is not
    a realistic attack (2), (3).
    (That is not to say that (1) can do without MITM
     protection. I suspect that IanG agrees with this
     even though his post seemed to indicate the contrary.)
6. What is needed is a system that allows hassle-free,
    incremental deployment of privacy-protecting crypto
    without people whining about MITM protection.
Now, this is could be achieved by enabling AnonDH in the SSL infrastructure and making sure that the 'lock icon' is *not* displayed when AnonDH is in effect. Also, servers should enable and support AnonDH by default, unless disabled for performance reasons.
Phew, that is a lot of pages to read (40?). Its also rather though material for me to digest. Do you have something like an example approach written up? I couldn't find anything on the site that did not require study.

@_date: 2003-03-25 02:07:49
@_author: Jeroen van Gelderen 
@_subject: Keysigning @ CFP2003 
I don't think that is a contradiction. This is just your personal requirements for being 'convinced'.
Nah. I think the photo-id case just makes large key-signing parties easier (or possible).
I suspect that for a large group of people (excluding you(?)) the following statement holds:
"When I see a new person for 30 seconds she cannot 'convince' me of her identity. If a passport is flashed in my face in those 30 seconds I actually am quite certain of it."
So there you have it: the difference between being able to sign in 30 seconds, or not. A practical -if not optimal- way to grow the WoT. This does *not* mean photo-id is a pre-condition for signing someone's key. It does *not* mean you should sign a key if you are shown a photo-id. It just *might* make it possible to sign a key where otherwise no certification would be possible.
Why not? It is *your* definition of 'convinced'. Other people will use their trust knobs to translate your judgement to their reliance on said

@_date: 2003-03-25 03:36:14
@_author: Jeroen van Gelderen 
@_subject: Who's afraid of Mallory Wolf? 
Heu? I am talking about HTTPS (1) vs HTTP (2). I don't see how the MSIE bug has any effect on this.

@_date: 2003-03-25 13:29:43
@_author: Jeroen C. van Gelderen 
@_subject: Who's afraid of Mallory Wolf? 
Go tell that to Joe Average. Or your mom. Or my sister. Or the average MSN user. You know, the insignificant group of people that make up the majority of the Internet population these days.
"If the lock icon is displayed it is safe."
Of course the consumer doesn't get to choose. Just like the consumer never, ever gets to use all of the features on his VCR[*]. This is an software agent deficiency. A UI issue: presently the UI doesn't facilitate the consumer in making that choice.
[*] I'm *not* talking about TiVo here, just about old-fashioned VCRs.

@_date: 2003-03-25 14:19:03
@_author: Jeroen van Gelderen 
@_subject: Who's afraid of Mallory Wolf? 
I am NOT talking about MSIE bugs at all. I didn't mention them and I don't know where you pull the reference from. I am talking about HTTPS traffic (1%) vs. HTTP traffic (99%) on the Internet:
1. Presently 1% of Internet traffic is protected *by SSL* against
    MITM and eavesdropping.
2. 99% of Internet traffic is not protected at all (because it
    travels over plain HTTP).
Well, that is *exactly* the point I made:
3. A significant portion of the 99% could benefit from
    protection against eavesdropping but has no need for
    MITM protection. (This is a priori a truth, or the
    traffic would be secured with SSL today or not exist.)
Hence the a priori truth.
4. The SSL infrastructure (the combination of browsers,
    servers and the protocol) does not allow the use of
    SSL for privacy protection only. AnonDH is not supported
    by browsers and self-signed certificates as a workaround
    don't work well either.
That is, we cannot add just privacy protection to HTTP by enabling SSL. That sucks because HTTP with just privacy protection is preferable over plain HTTP. But the present SSL infrastructure insists that I pay to defend against MITM even if I have no need for that. That is the problem I (and I suspect IanG) is talking about.
5. The reason for (4) is that the MITM attack is overrated.
    People refuse to provide the privacy protection because
    it doesn't protect against MITM. Even though MITM is not
    a realistic attack for (2), (3).
    (That is not to say that (1) can do without MITM
     protection. I suspect that IanG agrees with this
     even though his post seemed to indicate the contrary.)
6. What is needed is a system that allows hassle-free,
    incremental deployment of privacy-protecting crypto
    without people whining about MITM protection.
Now, this is could be achieved by enabling AnonDH in the SSL infrastructure and making sure that the 'lock icon' is *not* displayed when AnonDH is in effect. Also, servers should enable and support AnonDH by default, unless disabled for performance reasons.

@_date: 2003-03-25 15:28:28
@_author: Jeroen van Gelderen 
@_subject: Who's afraid of Mallory Wolf? 
You are saying that active attacks have the same cost as passive attacks. That is ostensibly not correct.
Not at all. That assertion is nowhere to be found in my original post I am talking about a website like -say- Cryptix (or Dilbert, or The Onion, or whichever). Websites where we do not have any requirement of offering the user any privacy whatsoever. Where we do not collect CC numbers. Where we do in fact not collect much of anything. And where we definitely don't have money for an SSL certificate. Where in fact any effort spent on this stuff is an incredible waste of resources.
What we would like to do however is offer a little privacy protection trough enabling AnonDH by flipping a switch. I do have CPU cycles to burn. And so do the client browsers. I am not pretending to offer the same level of security as SSL certs (see note [*]).
Enabling AnonDH will eliminate passive attacks at near zero cost and thus *raise* *the* *cost* of eavesdropping. For one it will render mere recording of HTTP traffic useless, which, in my book is a plus. We obviously don't care to *eliminate* eavesdropping because we are happily putting up with that today.
You seem to be asserting that increasing the cost of eavesdropping by a small amount is worthless. I'm sorry but I don't see how that makes sense. It is the difference between simply mirroring Google's OC48 to and NSA-owned port on the switch and redirecting the OC48 trough a real-time, low-latency NSA-owned MITM device. Without being detected.
I'm proposing a slight, near-zero-cost improvement[*] in the status quo. You are complaining that it doesn't achieve perfection. I do not understand that.
"Now, this is could be achieved by enabling AnonDH in the SSL infrastructure and making sure that the 'lock icon' is *not* *displayed* when AnonDH is in effect. Also, servers should enable and support AnonDH by default, unless disabled for performance reasons."

@_date: 2003-10-06 10:29:46
@_author: Jeroen C.van Gelderen 
@_subject: [e-lang] Re: Protocol implementation errors 
I take it you a saying that ASN.1 syntax is hard to parse? Having written two parsers (C & Java) I can say that ASN.1's DER encoding is in fact straightforward to parse correctly, provided that you don't underestimate the task *and* you create and use an 'exhaustive' test The problems with ASN.1 seem to stem more from its ISO heritage and dense specifications. That and the fact that a low-level bit-packing library isn't as glamorous as writing crypto and thus doesn't get as much scrutiny as other parts of protocol libraries.

@_date: 2003-10-06 13:02:00
@_author: Jeroen C.van Gelderen 
@_subject: [e-lang] Protocol implementation errors 
This is a little too anecdotal for my taste. When it comes to security I think we can safely ignore anything SNMP. The OpenSSL crew didn't (doesn't?) even have an exhaustive test-suite for their DER parsers which I believe to be a requirement when a security requirement is on the table.
While I like the SSH2 protocol because of its simplicity, it forces one to use ad-hoc approaches for anything more complex than single-level product types. Sum types are not supported at all, apart from those offered as primitives, and have to be (are) handcrafted in some ad-hoc The implementation language seems to be more of a problem than the actual data representation formats. I have found that typed high-level (declarative) languages supporting sum/product types with pattern matching provide near bullet-proof framework for safely marshalling data of arbitrary complexity. The compiler will statically check that all corner cases are handled. If it compiles, it tends to be correct. And creating the corresponding proof is straightforward.
If one is really lucky, one's language supports polytypic programming, in which case a single algorithm can marshall arbitrary data structures   The bottom line is that these problems occur because presently programmers are required to perform a compiler's job. Just like persistence bugs occurs because programmers are forced to do what should be the platform's responsibility (c.f. KeyKOS/EROS persistence). When language support is not feasible, parser generators can go a long way towards eliminating parser bugs.

@_date: 2003-09-27 13:51:52
@_author: Jeroen C.van Gelderen 
@_subject: Reliance on Microsoft called risk to U.S. security 
Could it not ask the user? My Apple regularly asks for decisions of this sort, and remembers the results. So do (popular firewall) products on the PC. Now, most of these questions are too technical in nature but point remains that asking question and remembering the answer is I continue to believe that few users would grant an email message access to both the Internet and the Address Book when they are asked those two questions, provided that the user had not been conditioned to clicking "YES" in order to get any work done at all.
There is no way around asking the user because he is the ultimate authority when it comes to making trust decisions. (Side-stepping the issues in a (corporate) environment where the owner of the machine is entitled to restrict its users in any way he sees fit. The point is that the software agent cannot make trust decisions.)
Are you familiar with the KeyKOS and EROS operating systems and/or Stiegler's CapDesk, a secure desktop in Java? They are all based on the Principle Of Least Privilege (trough capabilities) and they manage to preserve security in the face of composition. Do you consider those systems to be trivial, or broken? What is the reason these systems cannot exist in theory or practice?

@_date: 2003-09-27 16:46:32
@_author: Jeroen C.van Gelderen 
@_subject: Reliance on Microsoft called risk to U.S. security 
Indeed, but I'm here to learn :)
True. But don't you think that this may be in part because the popup dialogues are shown way too often in the course of normal use? And because they ask questions that cannot be understood by Real Users? Is it naive to assume that Real Users are intelligent but that an ill-designed security architecture has *conditioned* them to always click YES, as you say because that is the only way for them to get any work done at all?
I have to imagine starting with a clean slate, with unconditioned users.
Now imagine that the Alice, a Real User, can usually do a full day's worth of work (Excel, Word, Browsing, Email) without seeing a security popup asking some weird question. Imagine this is the status quo. In this scenario, a security popup is cause for concern. After all, normal use doesn't result in popups so this is a clear indication that something is wrong. Why would she click "YES"?
Now additionally imagine that security popups ask Alice an intelligible question. Not "FooBar is trying TCP to port 1223, that okay with you?" but rather something like "This website wants access to ALL YOUR PERSONAL FILES, that okay with you?" Or: "This email wants to access the Internet and your Address Book, that okay with you?"
Because I'm an optimist I believe that Alice will read the dialog and err on the side of caution. Maybe that isn't realistic. So we teach Alice to always click "NO". We can do so because unlike today, Alice's "NO" will not interfere with her ability to get work done.
I agree that such composition must be intuitive or we cannot expect it to work. I think that CapDesk is a nice publicly available prototype of a workable capability desktop. It would be very interesting to see your assessment on whether a CapDesk approach would be workable for your users. And if it isn't, why not. I hope you can lend your experience.

@_date: 2003-09-27 22:36:46
@_author: Jeroen C.van Gelderen 
@_subject: Reliance on Microsoft called risk to U.S. security  
Oops, I didn't mean to imply that you'd have to ask as much as happens at present! Automatically inferring is pretty much required if Alice is to be able to do a whole day's worth of work without seeing any popups in the steady case. You only ask Alice when you cannot otherwise reliably infer her intentions; That will be necessary at some point. The remaining questions that do get asked then are meaningful and do not condition towards a knee-jerk Click-Yes reaction.
And you can even download and try it for yourself as all of CapDesk is freely available. If that is too much, just download Marc's video demonstration [1]:
  I truly don't know how much more helpful one can get in order to dispel the perpetuation of these security myths?
[1] I don't know why the video is available in M$ proprietary format only though :(
