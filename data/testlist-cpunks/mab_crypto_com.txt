
@_date: 1993-08-13 11:52:56
@_author: Matt Blaze 
@_subject: Beepers can also be used to track you down! 
No, that won't work - the pager won't be able to receive the signals for
paging you.  You need a one-way faraday cage (OWFC).  You can get
these from a good electronic supply house, but they're rather expensive and
specialized so they don't usually list them in their catalogs.  You have to
call and ask.  Law enforcement and the military are the main users of OWFC's,
so they may refuse to sell you one without proper authorization, or they may
deny knowing about them at all.  Expect to pay at least $500 bucks for a pager-
sized one, much more for a room size model.  Use a fake name when buying, or
expect extra attention from the authorities.
If you have no luck finding someone willing to sell you one, you can make your
own, but it's a bit of a tedious process.  A brillo pad is a good starting
point, but you have to insert diodes at least every 1/64th wavelength to allow
the RF energy to flow into the cage but not out.  For a 450mhz pager, every
centimeter or so will do.  Surface-mount diodes are a good choice because of
their small size.  Basically, expand out the brillo pad as described in the
previous post, then mark 1cm size squares  around its entire outer surface.
At each intersection point, cut throw the mesh and solder in a diode, making
sure that the emitter side is pointing either in or out for all the diodes.
(I don't remember which side the diodes are supposed to point, but you
can easily turn the mesh inside out when you're done.  Whichever way lets
you receive pages is the right way.).    Be warned that buying a large number
of surface mount diodes is considered somewhat suspicious, so to play it safe
and order them with a fake name and in small quantities from several suppliers.
It's been over a year since I made an OWFC for my pager and the results have
been astounding - I am certain that the authorities are no longer using my
pager to track my location.
Be warned, though, that those so-called holographic images on Visa and
MasterCards can easily be used for much the same purpose, although I've been
unable to prove that they are actually using this technology to track people
on any kind of large scale.  Safest bet is to carry your credit cards along
with your pager in your OWFC.

@_date: 1993-08-18 09:55:42
@_author: Matt Blaze 
@_subject: The Zen of Anonymity 
Be careful here - this does not allow third parties a blanket escape
from liability simply by disclaiming authorship.
As I understand the law of defamation, who *wrote* the words is not all
important; the issue is who is publishing or otherwise causing them
to be published (which would ordinarily include, but not be limited to,
their author).  For example, in NY Times v. Sullivan (the case that
established a different standard of defamation for public figures),
the NY Times didn't write a story, they simply carried an ad that claimed
abuse of power by some officials (in Georgia, I think).  Although it is
often easier to show that the author of defamatory words knew or should
have known them to be false (part of what you need to prove to win a
libel case), liability does not end there.
Knowingly repeating words you should know to be defamatory is still

@_date: 1993-08-19 03:25:59
@_author: Matt Blaze 
@_subject: network parallel decryption amateur style 
Using the fastest software DES implementation I know of, optimized for
fast single-bit key change, it would take about a million SparcStation-years
(at 100% utilization) to do an exhaustive DES search.
Even assuming a order of magnitude faster than that (from a better
implementation or faster common workstation hardware), that's still
an awful lot of Sparc-years you'd have to get "the net" to donate.

@_date: 1993-12-04 09:53:02
@_author: Matt Blaze 
@_subject: CFS (was Re: Will Mike Ingle's name be a household word like "Buttafuoco"?) 
In cypherpunks Perry Metzger write:
With any luck, and barring unforseen lawyerly problems, CFS should be
released (at least within the US) by around Xmas.  The upside is that it's
been made considerably stronger (cryptographically speaking) than the version
in the paper, and I now believe it's roughly as strong as three runs
of the underlying cipher (DES in this case) but with greatly reduced latency.
Stay tuned...

@_date: 1993-12-16 14:21:32
@_author: Matt Blaze 
@_subject: Distribution of Secure Drive 
Please, please don't do this without checking with the author of
the package first.  He went out of his way to say that he doesn't
want to a make it available for ftp because he doesn't want to deal with
potential export problems.  So respect his wishes; it's his work, after
I'm the process of arranging the release of my own Unix crypto file system,
and am myself concerned about the export issues (as is my employer).
Messages like this one don't exactly give me a warm fuzzy feeling about
people violating their agreements to not export the code or
otherwise creating future headaches on my behalf.
If you think that an author of cryptographic software is immune from
export hassles just because it was someone else who exported it, ask
Phil Zimmermann...

@_date: 1993-06-08 14:42:10
@_author: Matt Blaze 
@_subject: CERT: the letter from CERT to berkeley.edu admin 
I think CERT is off base with these notes.  The problem, to my eyes, is not
that they're notifying administrators of potential problems before they occur;
that's all well and good, and probably easily within their charter.  What I
take issue with is the underhanded manner in which they seem to be doing it.
According to the reports from soda and penet, the notes were not sent in response to any specific request from the sites in question, but rather
on the inititate of someone at CERT itself or in response to some vague
complaint from a third party.  Furthermore, the notes were sent
"above the heads" of the individual site adminstrators (perhaps to whoever
is listed in the domain contact at the NIC), apparently causing bad feelings
and misunderstanding in at least the two cases reported here.
If they had sent mail to the postmasters at the individual sites saying
"hey, did you know your machine has a writeable anonymous ftp directory?"
that's one thing.  I'd interpret that as a friendly and helpful gesture.
Instead, the impression is one of, at best, unwelcome meddling, or, at worst,
some kind of bizarre network-vigilantism.  If they find something they don't
like about one of my computers, who else are they going to send mail to?
My boss?  My mother?
I should point out that I've delt with CERT myself a couple of years ago
regarding an intruder on a machine I administered, and found them to be
nothing but helpful and professional.  Their assistance was, however, limited
to reacting to specific problems that I asked them to help with.  They never
initiated any kind of audit of my site or did anything that would make me feel
as if they were some kind of "net cop wannabes" who were "checking up" on
my computers.  I'd hate to see that image changing, because they have the
potential to provide an increasingly valuable service as the internet grows.

@_date: 1993-06-11 19:28:11
@_author: Matt Blaze 
@_subject: Privacy panel at USENIX Conference 
Anyone who's going to be attending USENIX the week after next will want
to make sure not to miss the privacy panel, to be held Friday afternoon
(First session after lunch, I think).   The topic to be
discussed is anonymity on the net...
Here's the official announcement:
Privacy Panel: Anonymity Servers - Finding The Bounds of Rights
This USENIX Panel session will address anonymity servers,
systems serving to sanitize e-mail and NetNews postings in
order to conceal the source.   We will explore the legal and
ethical issues involved, and try to shed some light on the
subtle complexities involving "the bounds of rights"
such systems pose.  Some of the issues are considerably
more complex than they might first appear.
Our panel will consist of Dan Appelman, John Gilmore,
Johan ("Julf") Helsingius, and will be convened by Mike O'Dell.
Biographies of the participants follow.
Dan Appelman, Panelist
Dan Appelman is a lawyer who practices computer and
telecommunications law from his office in Palo Alto, California. He also teaches a course in telecommunications policy, law and
regulation and has written and lectured about the legal issues in
both the telecommunications and data processing industries.  Dan
is the lawyer the USENIX Association and several other amusing
high-tech enterprises. He is a partner in the law firm of Heller,
Ehrman, White & McAuliffe.  John Gilmore, Panelist
Among his other interests and accomplishments,
John Gilmore is a dedicated champion of civil liberties in
cyberspace.  John was a cofounder of the Electronic Frontier Foundation
and has campaigned aggressively for public availability of
high-quality encryption systems.  He was employee number five at
Sun Microsystems, may well have written more APL interpreters
than any other single human, and his most recent business
venture is the founding of Cygnus Support, a software
support company dedicated to the commercial viability of
free software.  He notes that he has never had time to
attend college or buy a suit.
Johan Helsingius, Panelist
The last time anyone really referred to Johan Helsingius using his
family name was while he was doing his military service long ago. As the
memories are not too fond, he prefers to be called "Julf", a name based
on a play on words involving 3 languages.  He has been heavily
involved in all manner of European Unix-related activities
for longer than he cares to remember.  He founded and still runs two
successful consultancy and training companies, Penetron
and Penetic, which manage to fund his well-developed tastes
for global travel and exploring the native arcania.  Most recently Julf established an anonymity server, anon.penet.fi,
that quickly became the most popular anonymous posting service
on the Internet with more than 20,000 users.  Although he
is based in downtown Helsinki, Julf tends to spend most of his time in airport departure lounges.
Mike O'Dell, Provocateur
Mike O'Dell is Vice-president of the USENIX
Association and he is also Editor-in-Chief of
the USENIX journal, Computing Systems.
When he is not busy doing either of those two things,
he is Vice-president of Engineering at UUNET Technologies, Inc.,
a commercial IP and UUCP connectivity provider.
Mike's role in this panel, however, is to reprise his occasional
role as Resident Crank and thereby provoke a lively analysis
of the issues.

@_date: 1993-05-12 13:26:22
@_author: Matt Blaze 
@_subject: The Halting Problem 
I don't see how determining that a particular string is an encrypted
message reduces to the halting problem.  For an arbitrary cipher, you can't
prove anything about any given potential ciphertext, since the cipher
could be a one-time pad.  (for one time pads, where keylength=message length,
any string can encrypt to any other string by selecting the right key).
So it's true that you can't prove anything about arbitrary ciphertext, but
that doesn't involve the halting problem.  If the cipher is known, on the
other hand, there are perfectly deterministic methods to determine whether
a particular ciphertext may coresponds to some given plaintext, simply
by exhaustive search of the keyspace.
However, I do agree with your basic conclusion - there is no way to determine,
by the bitstream alone, whether something has been encrypted with an arbitrary

@_date: 1993-05-12 15:46:01
@_author: Matt Blaze 
@_subject: The Halting Problem 
Well, that formulation is a bit fuzzy, but I think you've got your reduction
technique backwards.  To reduce something to the halting problem, you
need to show that you could use a machne that solves your problem to solve
halting, not the other way around.

@_date: 1993-05-25 15:44:59
@_author: Matt Blaze 
@_subject: Say again? 
Actually, the most alarming revelation here could be that someone at uunet
is going around casually disclosing information about their customers.
Most communications companies, especially those that seek to be regarded
as "common carriers", make quite clear to their employees that customer data
are among their most proprietary and that revealing any of it is grounds for
lightning-speed dismissal.  (Obviously, they reveal data that they SELL about
their customers, and will disclose anything on a court order, but that's not
what we're talking about here).
-matt (who has signed his share of non-disclosure agreements with big, bad
communications companies)

@_date: 1993-11-22 21:48:05
@_author: Matt Blaze 
@_subject: Can NSA crack PGP? 
Minor nit: I agree that keystroke timing is good in principle for getting
"true" random bits, but we should be careful not to extrapolate too much from
the STU-III for general purpose computer systems.  The STU may have a
specially designed keypad timer, while god knows how often some random OS/
hardware combination delivers keyboard interupt times back to user processes.
Compounding the issue is knowing which bits in the interarrival time are
the "hotest" ones to measure on a particular system, which may be surprisingly
far from the lowest order bits depending on the clock granularity and skew.
Obviously the technique works well in some configurations, but there may
be others where it fails badly.  PGP seems to use it too good advantage, but
I'd still be suspicious before trusting it on an untested platform.

@_date: 1993-10-23 11:43:06
@_author: Matt Blaze 
@_subject: Warning about exposing anon id 
It seems that an anonymous remailer can operate in one of three ways -
it can reveal your psuedonym, it can reveal your identity, or it can
reveal nothing and simply give you a generaic "anonymous" identity.
Unfortunately each mode of operation is inapproprate as a default behavior:
- If it reveals your psuedonym, you could inadvertently expose map your
name to your psuedonym if you reply to a remailed message and include your
real identity.
- If it reveals your real identity, this could lead all sorts of obvious
problems with people who don't expect this behavior.
- If it simply strips out all identifying information and calls you some
generic anonymous name, this could lead to problems for people who expect
a reply to their messages.
I think the best solution is to require any message sent through a remailer
to include explicit instructions as to how it should be handled.  For example,
require something like an "X-Identify:" field that would be used to select the
return address behavior, with options like "real-id", "psuedonym", or
"anonymous".  Messages that don't include the field should bounce, probably
with some instructions as to how to fix the message to make it go through

@_date: 1993-10-23 11:43:26
@_author: Matt Blaze 
@_subject: ADMIN: proposed new policy on the mailing list 
Oops, forgot to cc this to the list:
While I'm all for encouraging the use of digital signatures, I think this
is a bad idea.  The fact is there is not yet a truely generally available
method for digitally signing messages, and there are two competing standards
from which to choose as it is.  Just how should messages be signed?  PEM?
PGP?  What consititues a valid certificate?  (Actually, this question when
applied to your proposal underscores the inadequacy of both systems in
processing heterogeneous signatures - pgp imposes too little structure
and pem imposes too much.  But that's another story).
Then there's the practical problem that some people simply can't use a
particular signature technique with exisiting software and systems.
These people include:
- People outside the US and Canada, who can't legally use any PEM
implementation of which I'm aware because of restrictions on RSAREF.
- People in the US who can't use PGP because they're afraid to.
- People in the US who want to use PGP but can't because the people who
own/operate the computers they use won't let them.  Some people on public
access and university systems and many people in lawsuit-conscious large
companies with deep pockets are included here.
- People who would love to use PGP or PEM but don't see the point because
they don't fully trust the system on which they would sign their messages.
Anyone who uses anything but a private, single-user workstation SHOULD
be in this category.
- People who would love to use PGP or PEM but can't because they don't have
a working implementation of their secure mailer of choice for their particular
Do we really want to exclude these people from full participation?  If so,
I suspect this would eliminate a few of the most valuable contributors to the
Again, I don't thing this CONCEPT is a bad one, only that this particular
IMPLEMENTATION is premature in the absence of better and more ubiquitous
signature tools.
-matt (also unsigned, also known as mab at research.att.com)

@_date: 1993-10-23 12:28:26
@_author: Matt Blaze 
@_subject: Warning about exposing anon id 
How will this work?  Will you have a separate name space of "heavyweight"
anonymous IDs for messages that explicitly ask for a psuedonym (like with
a password) and those that don't?  If so, that sounds like a nice solution.

@_date: 1993-10-23 15:13:08
@_author: Matt Blaze 
@_subject: ADMIN: proposed new policy on the mailing list 
Perhaps I wasn't clear.  The concept I support is encouraging signatures,
not some "sign or delay" scheme.  I think such schemes don't really help
encourage the use of signatures as much as they exclude people who
live in the wrong place or who don't have the right computers.  And a
"make it look signed or delay" scheme is even worse.  It just encourages
people to either give up on the list and go back to some place where the rules
make more sense or, even worse, waste their valuable time writing code that
produces funny "psuedosignatures" that serve no valuable purpose.
A much better way to spread cryptography is to work on developing new
and transparent mechanisms that help regular people securely integrate
signatures and encryption into their routine work without having to do
anything special or different. Trying to make life more inconvinient for people who already identify
themselves as "cypherpunks" but who for whatever reason don't have easy
access to the right tools seems not the way to do it.

@_date: 1993-09-20 06:06:05
@_author: Matt Blaze 
@_subject: meaningless rumor 
Assuming that whoevever implemented PGP did not himself import the cipher, but
based the implementation on the EUROCRYPT '90 paper that was 'imported'
by Springer-Verlag, I don't understand what the basis would be for such a
charge.  Now an indictment against Springer for shipping the proceedings
(which contained C source code for IDEA) into the US - that would be

@_date: 1993-09-28 06:21:28
@_author: Matt Blaze 
@_subject: my clipper letter 
Matthew Blaze
55 River Drive South
Jersey City, NJ 07310
September 25, 1993
National Institute for Standards and Technology (NIST)
ATTN:  Proposed FIPS for Escrowed Encryption Standard
Technology Building, Room B-154
National Institute of Standards and Technology
Gaithersburg, MD  20899
Dear Director:
I am writing to express my opposition to the Proposed Federal
Information Processing Standard (FIPS) for an Escrowed Encryption
Standard, docket First, let me state my qualifications in this area.  I hold a Ph.D. in
computer science in the area of large-scale systems from Princeton
University.  I am presently employed as a Principal Investigator /
Member of Technical Staff in the Computing Systems Research Laboratory
of AT&T Bell Laboratories.  My research focuses on the design of
cryptographically secure networked computing and communications
systems and I have published several research papers in this field.  I
must emphasize, however, that I am making these comments as a private
citizen; nothing in this letter should be construed as representing
the opinion or position of my employer or any other organization.  I
state my affiliation only for the purpose of identification.
I believe that adoption of the proposed Escrowed Encryption Standard
would be harmful to the national interest in at least two ways.
First, it will harm us economically, putting our computing and
communications technology at a significant disadvantage against
foreign competition.  Second, it will hinder, rather than promote, the
increasingly vital efforts to improve the security of our information
Several aspects of the proposed standard render the system inadequate
for our competitive and information security needs.  First, because
the proposed system relies on the use of a special, tamper-resistant
computer chip, it is impossible to manufacture equipment or design
systems that have their cryptographic security functions based
entirely in software.  The implementation of cryptographic systems in
software has only recently been made feasible by advances in computer
speed and has significant advantages over hardware (chip)-based
encryption.  Software encryption can be included in digital voice and
computer communications equipment, such as cellular telephones, at
virtually no increase in marginal cost.  Hardware-based encryption
(based on technologies such as the proposed standard), on the other
hand, can add over a hundred dollars to the end price of each unit.
This could represent an increase of several times the original price
for typical low-end consumer communications products.  Clearly,
devices that include the proposed standard will be at a significant
disadvantage compared with equivalent products (possibly from foreign
competitors) that employ software-based encrypFrom owner-cypherpunks  Tue Sep 28 06:46:18 1993
Received: by toad.com id AA03637; Tue, 28 Sep 93 06:41:30 PDT
Received: by toad.com id AA03607; Tue, 28 Sep 93 06:38:21 PDT
Return-Path: Received: from transfer.stratus.com ([134.111.1.10]) by toad.com id AA03603; Tue, 28 Sep 93 06:38:18 PDT
Received: from lectroid.sw.stratus.com by transfer.stratus.com (4.1/3.14-jjm)
Received: from ellisun.sw.stratus.com by lectroid.sw.stratus.com (4.1/3.10-jjm)
Received: by ellisun.sw.stratus.com (4.1/SMI-4.1)
Message-Id: <9309281338.AA25476 at ellisun.sw.stratus.com>
I'd much rather not do it.  There won't be enough people out there to
really swamp the system.  Meanwhile, it lends credence to the stupid notion
that S/W crypto is arms.  I much prefer the statements in the READMEs at
soda.berkeley.edu ....
The official Stratus line on this issue, BTW, is that we don't want to deal
in munitions.  We have no intention of selling arms to anyone.  We sell
much of our product overseas and we sell only freely available crypto --
the stuff which is so widely documented and available that no terrorist or
unfriendly government could possible not already have it.  In particular,
we sell software DES and a few simpler systems for our customers to use as
they will.
Of course, ye olde US Gov't still forces not to export this except to
financial institutions (which is a reasonable fraction of our business) but
there are other customers pissed at us because we obey the stupid US export
laws.  Needless to say, Stratus as a company wants to see the export laws
 - Carl
Disclaimer: I don't speak for Stratus.  For the official company policy,
see the company's letter to NIST re: Skipjack.  [I certainly hope these
will be available to the public.]

@_date: 1993-09-28 09:46:19
@_author: Matt Blaze 
@_subject: FAX # for Clipper Comments 
I just checked with NIST; they are accepting FAX comments
on the Escrowed Encryption Standard until close-of-business
The number is 301-948-1784

@_date: 1993-09-29 09:06:27
@_author: Matt Blaze 
@_subject: Disturbing statistics on wiretaps 
Out of curiousity, what's "wire communication" for the purpose of this
statute?  How does that differ from electronic communication (other than,
perhaps, non-voice data traffic sent via cellular telephone)?

@_date: 1994-08-17 10:22:44
@_author: Matt Blaze 
@_subject: cfs & remailers 
e
I'm working (with very low priority, unfortunately) on a sendmail hack
that spools mail (instead of bouncing) if the mailbox write fails.
This will be intended for a secure mail system that I'm working on
that uses CFS for its storage.  Stay tuned...
Another potential problem with sendmail->cfs interaction is that
CFS doesn't implement NFS file locking.  This isn't much of an issue with
a single host and a single instance of CFS, but could be a problem if the
mailboxes are read and written by other machines or are remotely mounted
by the machine running sendmail.
By the way, another mode of operation you might consider is to use a
"permanent" key (that you supply at boot time) for the spool directories
and a temporary key (assigned randomly by the machine at boot time)
for temp files that have only local significance but that may have sensitive data.  /usr/tmp points to /crypt/tmp on my machine for this
service (do a cmkdir and cattach at boot time. You also have to hack
cfs to make /crypt/tmp be mode 777).

@_date: 1994-12-06 19:12:24
@_author: Matt Blaze 
@_subject: swIPe 
Well, if by swIPe you mean the standards-track IP security protocol,
quite a bit.  I'm not going to the next IETF meeting (perry?, phil?)
but I understand that swIPe and friends have mutated into something
that is very close to becoming an RFC.  Key management is another
story, with no general agreement as to what the requirements even are.
My own feeling is that more experience is needed with network-layer
security in general before the problems and tradeoffs of key managment
in heterogeneous networks will emerge with any clarity.
If you mean swIPe, the protocol described in Ioannidis and Blaze's
draft RFC of last December, not much.  There's an implementation
floating around (I think on the ucb ftp server), but I don't know
of anyone who's actively deploying it outside of closed systems.
Now would is a very good time to play with this stuff, particularly with
an eye toward understanding what the key management requirements are.
Right now the future internet cryptographic security architecture is wide
open, but that window is starting to close.

@_date: 1994-12-27 16:45:01
@_author: Matt Blaze 
@_subject: Making sure a program gets to the receiver intact 
... Another, practical, problem with integrity checks (both signatures
and timestamps) for files on public archive servers is that the
receiver has to expect them and know how to verify them.  Current
ftp and www clients certainly don't have facilities to do this
automatically, and neither do users have reason to suspect foul
play if a timestamp or signature is missing for some file.  It's
somewhat analogous to the situation ten years ago when some nut
was lacing over-the-counter drugs with poison and putting the
packages back on the shelf.  The major drug companies responded by
including tamper-evident seals on their packages, but until consumers
learned to expect the seals, all the bad guys had to do was remove
the seal entirely before replacing the tainted packages.  In the short
term, given today's infrastructure, there's not a lot you can do.
Of course, in the medium- and long- term, the best solution is to
design good schemes and deploy them widely enough that people learn
to expect them.

@_date: 1994-12-28 12:20:29
@_author: Matt Blaze 
@_subject: Why I have a 512 bit PGP key 
If I were going to implement a compiler-based attack against a
piece of security software, I'd probably do it entirely by altering
the linker.  That is, I'd have the linker recognize that it was
emiting a program called "pgp" or "pem" or "cfs" or whatever and
have it put a wrapper around the final executable module that simply
records any I/O and sends it to me.  With shared libraries, building
such a wrapper would be especially easy; just have all I/O go to your
library instead of the standard one.
It's also not hard to imagine ways in which such an attack could
be extended to fool even customized versions of systems like tripwire
into always reporting fixed results when run on particular files.

@_date: 1994-01-01 10:38:53
@_author: Matt Blaze 
@_subject: Anonymous Video on Demand 
In cypherpunks you write:
It just occured to me that when this protocol is implemented with RSA, it is subject to a minor (and unlikely) failure that can allow Alice
to determine which video Bob has selected (or at least eliminate some
of them).  If each video keypair has a different modulus and the one
Bob selects has a larger modulus than some of the "dummy" videos, then
if the encryption of Bob's session key with his selected video public key results in a message that is close to the modulus itself, the keypairs
with moduli that are smaller than Bob's message can be trivially eliminated
as candidates.
Of course, Bob can easily test for this condition and simply select a new
key (or diddle a random confounder in the message) until the encrypted
message is smaller than the modulus of any dummy keypairs.

@_date: 1994-07-14 05:08:20
@_author: Matt Blaze 
@_subject: Idle question... 
Assuming you're asking about the masks for the chips that implement
Skipjack (Clipper and Capstone), probably lots of people.  The
masks themeselves aren't classified (but are covered by standard
trade secret law).  But the masks alone won't help much.  According
to NSA, "part of the algorithm", probably including the configuration
tables for the S-boxes, is burned in to the chips in the secure
vault during the classified escrow programming session.  See my
February comp.risks post, "Notes on Key Escrow Meeting with NSA",
for more details.  (I think it's available somewhere in the
ftp.eff.org archive.)
If you're asking about A5 then I have no idea.

@_date: 1994-07-29 13:42:51
@_author: Matt Blaze 
@_subject: No SKE in Daytona and other goodies 
I just looked over the viewgraphs from the Karlshrue meeting; short of
breaking the signature scheme used to certify the "package instance"
public escrow key, there doesn;t appear to be any unilaterial action that
one party can take to interoperate with a "legal" recipient without
Others have pointed out, however, that you can re-use other people's
public escrow keys (that you learned, for example, by communicating with
them) to thwart traffic analysis.  Of course, traffic analysis is not
one of the stated requirements of the system anyway.
Also, the TIS proposal involves "software" tamper resistance in the form
of code checksums that the verified at run time.  This is intended to
discourage bi-laterial escrow circumvention.  Of course, any software-
only scheme can be thwarted, but patches to disable it may be a bit
involved, depending on how well obfuscated the code is.

@_date: 1994-05-07 07:36:03
@_author: Matt Blaze 
@_subject: iPower card info from NatSemi 
My understanding is that NSC plans to release a Tessera version for
the federal market and a DES version for the rest of us.  This is probably
reasonable - the federal (defense message system) Tessera market is pretty
big.  I don't know if they actually got the federal contract; I seem
to recal hearing last week that the DoD contract for Tessera cards went to
someone else, but I don't remember who.
BTW, I've been playing with a prototype Tessera card for the last couple
of weeks; cute little thing.  Comments to follow shortly...

@_date: 1994-05-26 08:11:22
@_author: Matt Blaze 
@_subject: dispersed DES 
In local.cypherpunks you write:
You have to be really careful when you invent new cipher modes, almost
as much as when you invent an entire new cipher.
It sounds like you have weakend 3-DES.  Where do you get these 4 bytes?
If they are fixed or deterministically generated, you will have made it
possible for an attacker who can brute-force 1-DES (e.g., with a Weiner
machine) to "peel off" each single DES key.  Instead of a 112 (or 168) bit
work factor (as with 3-DES), you'd end up with a 57 or 58 bit work factor.
If you randomly generate the 4 bytes, you have to carefully evaluate your
random number method.  In any case it sounds like your mode is the weaker
of 3-des and 1-des*(the complexity of your random bit generator).
Perhaps I don't understand how your scheme works.  Also, what intuition
makes you think that it's stronger than plain old 3-DES?

@_date: 1994-05-26 09:19:11
@_author: Matt Blaze 
@_subject: dispersed DES 
my
Let me see if I understand your scheme: you prepend 4 unpredictable
bytes to the data before running through each single des cycle.  What do
you do with the 4 bytes from each cycle that are shifted into the end of
the datastream?  Is the datastram vulnerable to independent search there,
Assuming the 4 bytes really are unpredictable, and assuming you deal with
both "ends" of the stream, there doesn't seem to be an *obvious* attack
that allows independent search for each of the 2 or 3 des keys.  There
was a paper in Eurocrypt this year (that I haven't seen yet) that
discusses some not-so-obvious properties of multi-cipher modes that may
reveal another attack, however.
If you don't think you've weakened 3-des, now the question is whether you've
strengthened it (or otherwise improved it).  Your method doesn't seem to
increase the complexity of a brute force attack on the 112 (or 168) bits of
3-des key material.  In fact, you may have actually increased the number of
bits of key material (if the decryptor has to know extra secret bytes in order
to recover the ends of messages) that the good guy has to manage without
increasing the work factor for the bad guy.
3 des is plenty strong, and if you don't trust or otherwise don't want
to use 3-des, it's not clear that this offers an improvement.

@_date: 1994-11-27 15:42:13
@_author: Matt Blaze 
@_subject: School Admins 
One of the most surprising things that I discovered after dropping
out of high school (in my senior year) is just how little my "permanent
record" in school affected me after I was out.  In particular, colleges
are remarkably flexible about admiting people with interesting backgrounds
who have demonstrated interests and skills in "non-standard" ways
and who seem to know why they want an education.  (In other words, schools
look for reasons to admit people who may not have good grades but who've
done interesting things and who show unusual interests.  Sometimes
all you have to do to show this is write a good essay or get a
convincing letter of recommendation from someone who knows you well
and has seen a side of you not reflected in your formal "record").
I'm mentioning this not to encourage you to drop out or to think that
nothing you do matters, but rather because your posts remind me of
me, 15 years ago.   I believed, as you seem to, the message that my high
school was sending: do things exactly the "right way" or you'll never
get anywhere.  In fact, I've discovered almost exactly the opposite to be
true.  The fact that you're doing unusual stuff like exploring computers
and cryptography and the like suggests that you will have an
easier time than you might think being successful in the much less structured life that you will be living after you finish high school.
Don't let anyone tell you that success in high school is the only
route to success in real life.  The best kinds of success in life come
from finding ways to expand and exploit your own interests and intellect.
High schools rarely teach you anything about how to do this.
-matt (who dropped out of HS, and now has all the credentials that he
needs to do what he likes with his life)

@_date: 1994-11-27 16:53:28
@_author: Matt Blaze 
@_subject: Zimmermann interrogated without counsel 
I'm going to be taking a business trip to Europe next month, and just to
find out what the procedure is I decided to get a "temporary export
authorization" for a so-called "exportable" AT&T telephone security
device (model 3600-F).  This is the "bump in a cord" voice encryptor.
The "F" model is supposed to be approved for "fast track" export; it
doesn't use Clipper or DES, but rather some exportable algorithm.
About two months ago I called our (AT&T's) export lawyer division.  They
said "ok, this will be easy".  Well, sure enough the other day I got back
my "license for the temporary export of unclassified defense articles".
The form on which this is printed is apparently used for everything in the
ITAR; it took me a while to realize that the part of the form where they
want the "serial number of aircraft or vessel" is to be filled in only if
I'm actually exporting a plane or ship and does not refer to the plane
on which I'm flying out of the country.  (Where is the serial number on a
767, anyway?)
Anyway, the "fast track" procedure seems to be as follows.  I have to leave
from an international airport with a customs agent present.  Before I leave
I have to make up an invoice for the devices (even though I'm not selling
them to anyone) that states that "These commodities are authorized by the US
government for export only to Belgium and the United Kingdom [the
countries I'm visiting].  They may not be resold, transshipped, or
otherwised disposed of in any country, either in their original form
or incorporated into other end-items without the prior written approval of
the US Department of State."  At the airport, I have to fill out something
called a "shippers export declaration" (SED) and copy the same wording onto
it.   Then I present my invoice, SED, and export license to a customs
official at the airport before I leave (this will be fun - I leave from
JFK, where Customs is in a different building from departing flights).  The
Customs officer then endorces my license to show what I'm taking out of the
On the way back in, I'm supposed to "declare" my item (even though it
was manufatured in the US) and show them my license, SED, and invoice,
and they're supposed to endorse the license to show that I have, in fact,
returned the "defense article".
I'd hate to know what the "slow track" is like....
I'll post a report of what actually happens when I try to follow these

@_date: 1994-11-27 22:09:25
@_author: Matt Blaze 
@_subject: Zimmermann interrogated without counsel 
According to our export guy (and also someone I spoke with at NIST)
that exemption is not yet in effect.

@_date: 1995-08-09 16:51:42
@_author: Matt Blaze 
@_subject: "S1" encryption system (was: this looked like it might be interesting) 
Someone sent me (to my bell labs address) a copy of this this afternoon via
an anon server in the netherlands.  It looks like others got it as well, and
it appears to have been posted to the cypherpunks list, though it hasn't
yet shown up here from the list (my mail seems to be slow today).  Did
anyone else have a copy mailed directly to them?
I don't quite know what to make of it.  A couple of random quick first-order
I don't know what to believe.  If this is a real, classified cryptosystem,
it would be a very unusual first.  On the other hand, if this is a hoax,
whoever did it appears to have gone to some trouble, and has included some
interesting design features.  A third possibility, if we are to believe
the spook markings, is that it is a re-implementation of someone else's
cryptosystem, created for the purpose of cryptanlysis.
All in all, I remain very skeptical.  It smells like a hoax to me, but
I'm willing to look at it with an open mind.

@_date: 1995-08-09 18:08:53
@_author: Matt Blaze 
@_subject: "S1" encryption system (was: this looked like it might be interesting) 
Well, I don't hold (and have never held) a clearance, but I've seen
declasified/sanitized documents that have crossed out "TOP SECRET"
markings all over them.

@_date: 1995-08-10 01:45:04
@_author: Matt Blaze 
@_subject: "S-1" key schedule 
Well, I have to admit I've been staying up late playing with the "S-1"
cipher that was posted here earlier.  Hal Finney already noted what is
clearly a bug in the code; only half the key schedule is ever used,
and only in the first 16 of the 32 rounds.  Even assuming that that
is a typo rather than intentional, "S-1" still appears to suffer from
key-related weaknesses.
The key expansion function in "S-1" produces a skewed key schedule
given uniformly distributed 80 bit input keys.  Here's a histogram
of the distribution of key schedule bytes produced by all 2^32 ways
of generating each byte (each key schedule byte is a function of the
F functions applied to four selected input keys bytes).  The expected
value for each line is 16777216.  For just about any conventional block
cipher, (e.g., DES) we'd expect this graph to be absolutely flat.  Yet
here some values are more than 5% away from expected.  This behavior
appears to be a consequence of the non-uniform distributon of "S-1"'s
F output values, which are used to create the expanded key.
This does not bode well for "S-1"; it means that some key bytes are
applied against the ciphertext slightly more often than others, even when
the input key itself is uniformly chosen.  (Ditto for the outputs of the F
functions themselves, even when their inputs are uniformly distributed,
but that's still another story).
Still, this may not be fatal; the key schedule is still much larger than
the keyspace, so there might not be any easy way for the cryptanalyst to
exploit this property to any great advantage.  It is possible that the
cipher's structure somehow cancels this out in some non-obvious way
that manages to provide a flat 2^80 keyspace, but it's hard to see
exactly how.
My money still says the "TOP SECRET" markings and other clues that
suggest that "S-1" has something to do with Skipjack are a hoax.
key   number
val  produced

@_date: 1995-08-10 13:35:24
@_author: Matt Blaze 
@_subject: More "S-1" foolishness 
Yesterday I mentioned that I'd noticed that "S-1" has a non-uniform
distribution of F (Sbox?) outputs - some values appear far more often
than others.  This means that some values are more likely to be XORed
against the cleartext than others.  Needless to say, this is a very
unusual (and presumably very bad) property - in DES, for example, the
Sbox outputs are completely flat.
I've been avoiding real work today, so here's a breakdown of the
distribution of output values for F0-F3 by value and by bit
position, as well as the total for all four.  (The expected numbers are
16 for the outputs by value and 128 for the outputs by bit).
If I get more time, I'll try to figure out how to do a structure a
differential attack (which will be a little bit tricky given the
G function).  I'm not sure this is worth putting much effort
into, however, given that the closer I look the more hoax-like this
seems.  Much as I'd like to think this is a version of Skipjack, it's
getting pretty hard to suspend disbelief.  I might be willing to
believe, however, that this is some kind of proprietary industrial
cipher; perhaps the poster added the "TOP SECRET" stuff to attract
additional attention to it.
All in all, this is a most unusual cipher.  On the surface at least,
it has many elements of a really bad design.  On the other hand, some
of the other ideas are novel enough that I wonder why its inventors
wouldn't want to be associated with them.
---F0 output distribution---
F0:0 = 18 (1.12) ******************
F0:1 = 10 (0.62) **********
F0:2 = 17 (1.06) *****************
F0:3 = 15 (0.94) ***************
F0:4 = 13 (0.81) *************
F0:5 = 12 (0.75) ************
F0:6 = 18 (1.12) ******************
F0:7 = 14 (0.88) **************
F0:8 = 17 (1.06) *****************
F0:9 = 18 (1.12) ******************
F0:a = 14 (0.88) **************
F0:b = 17 (1.06) *****************
F0:c = 18 (1.12) ******************
F0:d = 12 (0.75) ************
F0:e = 19 (1.19) *******************
F0:f = 24 (1.50) ************************
---by bit---
F0:1 = 122 (0.95) ***************
F0:2 = 138 (1.08) *****************
F0:4 = 130 (1.02) ****************
F0:8 = 139 (1.09) *****************
---F1 output distribution---
F1:0 = 21 (1.31) *********************
F1:1 = 13 (0.81) *************
F1:2 = 15 (0.94) ***************
F1:3 = 20 (1.25) ********************
F1:4 = 22 (1.38) **********************
F1:5 = 15 (0.94) ***************
F1:6 =  8 (0.50) ********
F1:7 = 22 (1.38) **********************
F1:8 = 19 (1.19) *******************
F1:9 = 18 (1.12) ******************
F1:a = 15 (0.94) ***************
F1:b = 13 (0.81) *************
F1:c = 10 (0.62) **********
F1:d = 12 (0.75) ************
F1:e =  9 (0.56) *********
F1:f = 24 (1.50) ************************
---by bit---
F1:1 = 137 (1.07) *****************
F1:2 = 126 (0.98) ***************
F1:4 = 122 (0.95) ***************
F1:8 = 120 (0.94) ***************
---F2 output distribution---
F2:0 = 16 (1.00) ****************
F2:1 = 13 (0.81) *************
F2:2 = 16 (1.00) ****************
F2:3 = 13 (0.81) *************
F2:4 = 12 (0.75) ************
F2:5 = 17 (1.06) *****************
F2:6 = 16 (1.00) ****************
F2:7 = 16 (1.00) ****************
F2:8 = 14 (0.88) **************
F2:9 = 22 (1.38) **********************
F2:a = 27 (1.69) ***************************
F2:b = 19 (1.19) *******************
F2:c = 14 (0.88) **************
F2:d = 16 (1.00) ****************
F2:e = 11 (0.69) ***********
F2:f = 14 (0.88) **************
---by bit---
F2:1 = 130 (1.02) ****************
F2:2 = 132 (1.03) ****************
F2:4 = 116 (0.91) **************
F2:8 = 137 (1.07) *****************
---F3 output distribution---
F3:0 = 23 (1.44) ***********************
F3:1 = 20 (1.25) ********************
F3:2 = 11 (0.69) ***********
F3:3 = 23 (1.44) ***********************
F3:4 = 17 (1.06) *****************
F3:5 = 15 (0.94) ***************
F3:6 = 13 (0.81) *************
F3:7 = 17 (1.06) *****************
F3:8 = 15 (0.94) ***************
F3:9 = 11 (0.69) ***********
F3:a =  9 (0.56) *********
F3:b = 19 (1.19) *******************
F3:c = 14 (0.88) **************
F3:d = 16 (1.00) ****************
F3:e = 14 (0.88) **************
F3:f = 19 (1.19) *******************
---by bit---
F3:1 = 140 (1.09) *****************
F3:2 = 125 (0.98) ***************
F3:4 = 125 (0.98) ***************
F3:8 = 117 (0.91) **************
===overall sum===
---F* output distribution---
F:0 =  78 (1.22) *******************
F:1 =  56 (0.88) **************
F:2 =  59 (0.92) **************
F:3 =  71 (1.11) *****************
F:4 =  64 (1.00) ****************
F:5 =  59 (0.92) **************
F:6 =  55 (0.86) *************
F:7 =  69 (1.08) *****************
F:8 =  65 (1.02) ****************
F:9 =  69 (1.08) *****************
F:a =  65 (1.02) ****************
F:b =  68 (1.06) *****************
F:c =  56 (0.88) **************
F:d =  56 (0.88) **************
F:e =  53 (0.83) *************
F:f =  81 (1.27) ********************
---by bit---
F:1 =  529 (1.03) ****************
F:2 =  521 (1.02) ****************
F:4 =  493 (0.96) ***************
F:8 =  513 (1.00) ****************

@_date: 1995-08-11 04:35:03
@_author: Matt Blaze 
@_subject: More "S-1" foolishness 
While I'm loath to make any statement that could be interpreted as
defending this cipher, these are, as you say, only "apparent"
weaknesses.  Other than the "r vs. i" bug, which a very forgiving
observer might attribute to some kind of error (maybe the code was
typed in from a printout; maybe the program was taken from a "working
copy" in the middle of being modified), so far, no one has demonstrated
conclusively that these unorthodox and seemingly unsound design
characteristics actually help the cryptanalyst in this particular
cipher.  I'm talking out of my hat here, but for all we know
carefully selected non-uniformly distributed s-boxes and key
schedules that throw out the odd bit here and there in just the
right way might thwart some killer cryptanalytic technique that
isn't yet known in the civilian world.  Hardly likely, but still
remotely possible.
We can't completely rule this out unless we've seen that the cipher
falls to the various known meta-attacks, like differential and
linear cryptanalysis.  I don't really think this is worth the
trouble, however, given that these techniques can require considerable
effort and skill to apply to an arbitrary cipher and that everything
else about this thing points to a hoax designed to provoke just
such a waste of time.
(Someone will no doubt make me eat my words by doing a rump session
talk at CRYPTO on how interesting the linear and differential
analysis of this cipher turned out to be.)
PS to whoever posted this thing, if you're reading this: If this
cipher isn't what its comments assert, and you've just added spooky
labels to get people interested in evaluating some design technique
that you've invented because you think no one will take you seriously
if you just come clean, you're wrong.  An intellegently-written
description of your ideas, coupled with an easily-evaluated example,
can get a lot of attention from the crypto community no matter what
the source.  I've personally looked at several such schemes, and
had at one of my own (MacGuffin, which you're obviously familar
with) widely examined by doing just that.  You could have produced
such a description with about as much effort as you've obviously
already gone to in creating the "S-1" code, with far greater
potential rewards.  And if this is just a random hoax, well, I
guess it looks like you've suceeded.

@_date: 1995-08-11 14:58:24
@_author: Matt Blaze 
@_subject: Still more "S-1" foolishness 
Here's a table of where the expanded key schedule bits come from
(I think - this could be wrong, I had to tweek some of the output
by hand).  Note that some key bytes are used much more often, and
in more positions, than others, but every key byte does at least
end up being used as input to each F eventually (but not always to
each "target" byte).
Sorry for the opaque notation; this reads best when used in conjunction
with Colin's cool graph that he posted to sci.crypt last night.
    | G0   G1  F+0  F+1  F+2  F+3   (function input)
   bytes| 4    5    2    3    0    1    (mixed with byte rou|enc-| all  all R+6L R+6H R+7L R+7H  (output affects)
nd |rypt| 0    1    2    3    4    5    (key schedule byte  # |ed  |LLHH LLHH LLHH LLHH LLHH LLHH  (posn of orig key byte in sched byte)
 0  76   5954 9538 5495 4851 8515 5151
 1  54   1510 5194 1051 0415 4171 1717
 2  32   7176 1750 7617 5071 0737 7373
 3  10   3732 7316 3273 1637 6393 3939
 4  67   9398 3972 9739 7293 2959 9595
 5  54   5954 9538 5495 4851 8515 5151
 6  32   1510 5194 1051 0415 4171 1717
 7  10   7176 1750 7617 5071 0737 7373
 8  76   3732 7316 3273 1637 6393 3939
 9  54   9398 3972 9739 7293 2959 9595
10  32   5954 9538 5495 4851 8515 5151  (original key bytes used)
11  10   1510 5194 1051 0415 4171 1717
12  76   7176 1750 7617 5071 0737 7373
13  54   3732 7316 3273 1637 6393 3939
14  32   9398 3972 9739 7293 2959 9595
15  10   5954 9538 5495 4851 8515 5151
16  76   1510 5194 1051 0415 4171 1717
17  54   7176 1750 7617 5071 0737 7373
18  32   3732 7316 3273 1637 6393 3939
19  10   9398 3972 9739 7293 2959 9595
20  76   5954 9538 5495 4851 8515 5151
21  54   1510 5194 1051 0415 4171 1717
22  32   7176 1750 7617 5071 0737 7373
23  10   3732 7316 3273 1637 6393 3939
24  76   9398 3972 9739 7293 2959 9595
25  54   5954 9538 5495 4851 8515 5151
26  32   1510 5194 1051 0415 4171 1717
27  10   7176 1750 7617 5071 0737 7373
28  76   3732 7316 3273 1637 6393 3939
29  54   9398 3972 9739 7293 2959 9595
30  32   5954 9538 5495 4851 8515 5151
31  10   1510 5194 1051 0415 4171 1717

@_date: 1995-08-11 15:13:20
@_author: Matt Blaze 
@_subject: More "S-1" foolishness 
Interestingly, though, such keys are not weak in the sense that the
all-zero/all-one key is weak in DES.  There doesn't seem to be any
obvious way to key it such that encryption == decryption.

@_date: 1995-08-12 10:30:21
@_author: Matt Blaze 
@_subject: Still more "S-1" foolishness 
Whoops - there was a bug in my understanding of what was going on
that conspired with a bug in my table generation program to make everything
wrong.  Here's the correct table, for those interested.  Sorry for the noise.
 R |    | G0   G1  F+0  F+1  F+2  F+3   (this key byte is input to this fn)
 O bytes| R+4  R+5 R+2  R+3  R+0  R+1   (key byte is mixed with this block byte)
 U |enc-| all  all R+6L R+6H R+7L R+7H  (output affects this byte)
 N |rypt| 0    1    2    3    4    5    (key schedule byte  D |ed  |LLHH LLHH LLHH LLHH LLHH LLHH  (posn of orig key byte in sched byte)
 0  76   5831 9425 5362 4738 8492 5038  1  10   1497 5081 1928 0394 4058 1694  2  32   7053 1647 7584 6950 0614 7250  3  54   3619 7203 3140 2516 6270 3816  4  76   9275 3869 9706 8172 2836 9472  5  10   5831 9425 5362 4738 8492 5038  6  32   1497 5081 1928 0394 4058 1694  7  54   7053 1647 7584 6950 0614 7250  8  76   3619 7203 3140 2516 6270 3816  9  10   9275 3869 9706 8172 2836 9472 10  32   5831 9425 5362 4738 8492 5038 	(number indicates position in schedule
11  54   1497 5081 1928 0394 4058 1694   of original key bytes; an entry
12  76   7053 1647 7584 6950 0614 7250   "5678" means key bytes 5 and 6 are
13  10   3619 7203 3140 2516 6270 3816   in the low order position of this
14  32   9275 3869 9706 8172 2836 9472   schedule entry and bytes 7 and 8
15  54   5831 9425 5362 4738 8492 5038   are in the high order position.  Bytes
16  76   1497 5081 1928 0394 4058 1694 	 are first run through an F functuon
17  10   7053 1647 7584 6950 0614 7250   and XORd with each other to create
18  32   3619 7203 3140 2516 6270 3816   the schedule nibble.)
19  54   9275 3869 9706 8172 2836 9472 20  76   5831 9425 5362 4738 8492 5038 21  10   1497 5081 1928 0394 4058 1694 22  32   7053 1647 7584 6950 0614 7250 23  54   3619 7203 3140 2516 6270 3816 24  76   9275 3869 9706 8172 2836 9472 25  10   5831 9425 5362 4738 8492 5038 26  32   1497 5081 1928 0394 4058 1694 27  54   7053 1647 7584 6950 0614 7250 28  76   3619 7203 3140 2516 6270 3816 29  10   9275 3869 9706 8172 2836 9472 30  32   5831 9425 5362 4738 8492 5038 31  54   1497 5081 1928 0394 4058 1694

@_date: 1995-12-03 10:40:05
@_author: Matt Blaze 
@_subject: Remind me why we're so mad at Netscape 
Could someone please remind me what it is we're mad at Netscape about?
As far as I can tell it's some combination of the following offenses:
(a) - Jim Clark made a speech in which he revealed that he thought the
government would be a player in determining the way cryptography ends
up being deployed on the Internet.  He was quoted in the trade press,
but it was unclear exactly which words were actually his.  Asked to
clarify, he said that Netscape would implement mandatory government
access across its product line only if required to by law, but he
observed that things seem to be moving in that direction.  I share his
pessimism, unfortunately, unless we find a way to shift the winds.
(b) Netscape contracted with the government to produce a ``Fortezza''
version of their browser for government use.  They negotiated to get a
lot of money for this (maybe something like $5 million).  Good for
them.  Personally, I *like* the Fortezza interface; the API seems to
provide a good abstraction for hardware and software crypto, it's easy
to replace the module with something else (like software 3DES with no
key escrow), and it's easy to defeat the key escrow features.  Of
course, maybe I'm just defending them out of guilty self-interest
here, since I've played around with the Fortezza interface quite a bit
myself, although they never sent me my $5 million.
(c) No one from Netscape attended Bernstein hearing.  I wish someone
had let me know beforehand that that was to be the litmus test for the
right to claim cryptographic correctness, or I would have flown right
out.  I guess I blew it, too.
(d) Their stock price is very high, many times greater than their
profits and physical assets would seem to justify.  I'm not sure I
understand the implication here.  Maybe that this is proof that in
exchange for selling out (by committing sins (a), (b) and (c), above),
the secret NSA stock-price-manipulation cabal rigged the market to
overvalue their stock?  Wow.
Don't get me wrong here; it may be useful to make clear that the market
(to the extent that any of us can claim to represent any market they
would be interested in) won't tolerate vendors who put the government's
desires ahead of their customer's security needs.   But I have yet to
see any actual evidence that that's what's happened here, and I'd hate to
see Netscape loose a lot of good people who could go a long way toward
deploying real security on the net over something that turns out to have
been a false alarm.
Disclaimer: I'm employed full time by a soon-to-be-tri-vested major
player in the military industrial complex, and us sellouts like to
stick together.

@_date: 1995-12-12 07:02:56
@_author: Matt Blaze 
@_subject: Timing Cryptanalysis Attack 
Of course, this works against a remote adversary, but not against one
on the same machine who can look at actual CPU consumption (which doesn't
increase when the target is blocked).

@_date: 1995-12-13 05:54:04
@_author: Matt Blaze 
@_subject: Timing Attacks 
The more timing noise between the attacker and the target, the
harder it is to exploit the measurements.  Based on some (very
rough) experiments I've set up here, I suspect the attack is easy
if you're on the same computer (and measure CPU load), probably
feasible if you're on the same network and the host and net are
unloaded, and unlikely otherwise.  The attack is especially
interesting against crypto tokens that are supposed to hold a secret
key secret, where you can get very close and take very good timing
Keep in mind also that Kocher's results are only the first cut,
based on a very simple statistical model.  I suspect we'll be seeing
many improvements and variations over the coming months.
Bottom line is that implementing good cryptosystems is a lot harder
than one might think...

@_date: 1995-12-14 14:23:12
@_author: Matt Blaze 
@_subject: Attacking Clipper with timing info? 
Clipper chips require fixed time to do a codebook cipher operation (exactly
64 clock ticks).  It's in the chip spec.
Capstone chips, on the other hand (as embodied in Tessera/Fortezza) have
public-key operations (DSA and a classified key exchange algorithm called
KEA that appears based on its interface to be El Gamal-like).  The cards
aren't supposed to reveal the secrets stored on them, ever.  There does
appear to be some variability in those functions, however.  I've not yet
reached any firm conclusions, however.

@_date: 1995-12-19 16:03:46
@_author: Matt Blaze 
@_subject: revised time quantization package (Unix & WIN32) available 
I don't normally like to respond to anonymous kooks, but...
Since I don't understand what you're talking about, I can't really
respond to it.  The only restrictions on the use of this code are that
you have to acknowledge where it came from and that it comes with no
waranty.  You also have to keep the notice in place on any copies you give
to anyone else.  Just like the GPL, only without the nutty requirement
that you also give away your own source code.
I think you're confused.  AT&T Bell Labs Research (which is soon to be
split into two parts, Bell Labs and AT&T Labs, owned by two different
companies starting next year) is a research laboratory.  A lot of very
good cryptology and security people work here.  While AT&T (the
parent company) is in the products and services business, AT&T Bell Labs
doesn't sell any products or services itself.  Like most of the
computer science researchers in Bell labs (and like those in universities
and elsewhere), I publish the results of most the work that I do (modulo
some consulting I do for the moneymaking part of the company in order
to "pay the rent").  I (like many other researchers) also sometimes create
software in the course of my work.  When this might be of use to others,
I prefer to give it away rather than let it sit idle on my disk.  The
quantization code (like CFS, swIPe and others) is an example.  CryptoLib
is another example; it was created by my colleague Jack Lacy.  We give that
away, too.  Bell Labs doesn't advertise anything.  We don't have retail customers.  Our research software is unconnected with AT&T's commercial
activities.  We make it available because that's what members of the research community do.  Its distribution is neither purely altruistic nor especially
mercenary.  If you really like our research software, I guess you can switch
your long distance service to AT&T or buy an AT&T answering machine or
something.  But that part of the company is very remote from my food chain.
I'm from the part of the company that _spends_ money.  Other parts _make_
the money.
Again, I think you're confused.  Jeff Weinstein works for Netscape, not
AT&T.  I think there's a connection between AT&T and Netscape somewhere
(like we bundle netscape with worldnet service), but I don't really
know the details.
I can't speak for Jeff Weinstein, but in my case, not nearly enough.
"I'm from The Phone Company and I'm here to help you."

@_date: 1995-12-19 16:45:46
@_author: Matt Blaze 
@_subject: revised time quantization package (Unix & WIN32) available 
Perry wonders:
I must admit I don't quite get it, although I think there are people
who really can't distinguish between a person and a person's employer, and
who believe that the entire world is a black-and-white battle between
good and evil.
Jeff Weinstein got treated rudely back during the feeding frenzy
where everyone hated Netscape because he works for Netscape.
Brian Davis got treated rudely when he first joined the list because
he works for the government as a federal (?) prosecutor.
I get treated rudely from time to time because I work for AT&T.
It doesn't bother me, especially when it comes from an anonymous source who
for all we know might earn his or her keep by advertising the joys of
smoking cigarettes to small children or by testing the toxic effects of
new cosmetics on cute, furry animals.  I figure it all just comes with
the turf.  At least I don't get blood thrown on my by protestors the way
people who work in animal testing labs do...

@_date: 1995-12-20 20:34:57
@_author: Matt Blaze 
@_subject: CFS and Linux 
I don't run Linux, and every time I open my mouth it seems to provoke
a flame-fest, but I'll risk responding anyway.
I'm told that all version of CFS since 1.0.4 (the latest is 1.3.1)
do work out-of-the-box under *some* releases of Linux and with some
coaxing on the others.
I'm not sure exactly what problem you're having, but the most common
CFS-Linux problem that people complain about has to do with the rpcgen
output not being in the format expected by the rest of CFS.  There
seem to be two things you can do about this:  get a version of rpcgen
that generates the "standard" (original Sun) names for the functions it
generates, or just grab the rpcgen output from the cfs-users mailing list
archive ("echo help | mail cfs-users-request at research att.com" for details).
Or are you able to compile it but not get it installed?  I've not heard
of any problems here.  If so, you might try the cfs-users at research.att.com
mailing list and see if someone there can help out.
NB to "Bill Gates" and friends:  To save you the trouble of pointing it out,
I hereby admit that I'm a commie-fascist brainwashed sold out member of the
military-industrial complex who has been programmed by his masters to
infiltrate the cypherpunks in order to sap and impurify their precious
bodily fluids.

@_date: 1995-12-23 06:21:47
@_author: Matt Blaze 
@_subject: CFS and Linux 
I'd love to.  It isn't that simple.  No one has ever told me exactly what
"the Linux problem" is or even convinced me that a problem actually exists.
I don't run Linux.  People who do run Linux are divided between telling
me it that does run out-of-the-box and that it doesn't.  ALL I can do is
pass on patches that the people who run CFS under Linux give me.  My
understanding is that CFS does run out-of-the-box under some of the
all-too-many varieties of Linux, but that it depends very much on your
particular configuration (particularly your rpcgen version).  Some
configurations require some tweeking.  If you want to see CFS supported
out-of-the-box on a particular platform, someone has to tell me about it
and supply me with the fixes, which I will galdly wrap into the distribution.
Requests that I make something work on a platform that I don't have and
don't control are very frustrating.
Anyway, this is the wrong list for this.  Linux issues come up every now and
then on the cfs-users mailing list (cfs-users-request at research.att.com;
subscription info included in the distribution).

@_date: 1995-12-24 04:45:49
@_author: Matt Blaze 
@_subject: CFS and Linux (fwd) 
What, exactly, is your complaint?  I'm honestly confused.
Please see my previous message on this subject for an explanation of
the situation regarding CFS with respect to Linux.
I'm not "refusing to support" anything.  I want to do whatever it takes
to get CFS (and other applications of strong cryptography) as widely
deployed as possible.  I am unwilling to allow supporting CFS to become
a full-time job, however, and I'm not going to apologize for that.
I have a Linux machine, in fact.  But I've tried to run CFS on it and it
seems to work fine.  I've not investigated further because that seems like
a poor use of my time given the large number of Linux experts (who know far
more than I ever will about the vagaries of the various Linux releases) who
have not come up with a satisfactory, general patch that runs on all the
various Linux platforms.  The problem seems to be that some versions of Linux
include an rpcgen that produces non-standard output.  I don't have one
of those versions, however, so I've not encountered this "problem" myself.
Again, if you want to see CFS, or any other software that I distribute, run
on some platform that I don't have, you are welcome to send me patches that
I will happily wrap into the distribution (as long as it doesnt break the
other supported platforms).  Until you do that, you have nothing to whine

@_date: 1995-02-01 07:27:03
@_author: Matt Blaze 
@_subject: The security characteristics of crypto modules with secrets 
The advantage of a secure crypto module on an insecure server (or
router or whatever) is in limiting the scope of successful attack. As Eric pointed out, if you can subvert a general purpose machine that
does all its crypto through a secure module that you can't subvert,
you can still add a covert "service" to the machine that lets
a future spoofer use the module remotely.  The main important
difference between this attack and just learning the server's secret
is that it only remains useful as long as the attack is undiscovered.
In the case of software keys, it is sufficient for the attacker to subvert
the machine that knows the secret ONCE.  He or she can put things back
to normal on the original machine and still know the secret forever, with
little chance of future detection.  With a secure module, the attacker has
to either steal (physically) the hardware (which will be discovered when
the real server stops working) or set up the kind of future access that
Eric mentioned (which, once discovered, will likely be turned off or
If you have secure crypto hardware, you only have to worry about and
detect whether the server is being compromised continuously.  Otherwise,
without special hardware, you have to worry about and detect whether the
server was ever compromised since it was last rekeyed.  Personally,
the former seems like a realistic thing to try to do while the latter
doesn't, at least in the environments in which I live.
If the server hardware or software is insecure, cryptographic techniques
can't provide any absolute guarantees, period.   In the real world, though,
you're not interested in absolute guarantees, you just want to
reduce risks.   How effective the mechanisms to do this are depends on
how accurately they reflect the real world threats.

@_date: 1995-02-01 13:37:44
@_author: Matt Blaze 
@_subject: ESP Unix encrypted session protocol software 
The reason there's no "computer" analog to the "anti-spoofing vector"
for human-human voice communication lies in the definition of
authentication.  In a formal sense authentication here means binding a
secret that only you know to the encrypted channel.  In the case of voice
communication over an encrypted link, that "secret" consists of the ability
to hold a convincing exchange that sounds like your voice.  You bind the
secret to the channel by speaking a hash of the key.  Computers, not
pre-equipped with biological mechanisms for establishing who they are,
need to use another secret (like knowledge of the secret part of a public
key signature pair) to which only the computer you want to authenticate has
The encrypted human voice authentication scheme is only as strong as it
is hard to spoof voices.  Digital signature authentication is only as
strong as it is hard to break the signature scheme or compromise the
signing key.

@_date: 1995-02-05 16:45:30
@_author: Matt Blaze 
@_subject: The SKRONK protocols (version 0.6) 
Actually, tunneling through a telnet connection on an application-level
firewall does have its place, especially when the firewall's
granularity of authentication is designed only to bind authorized
people to telnet connections.   This way, the firewall need only
enforce a very simple access control model (which is easier to
verify is working correctly) and need make very few authentication
decisions on a per-packet basis.
The down side (which is why I don't do this myself) is that you
have to be careful that the external end of the tunnel does not
forward IP packets from the rest of the net and is otherwise
reasonably secure, or one such connection is enough to eliminate
any security benefits the firewall might otherwise have offered.
It's not clear there's much a telnet firewall can do to prevent
tunnels, however, so we might as well at least make them secure as
we can.

@_date: 1995-02-10 10:36:41
@_author: Matt Blaze 
@_subject: Global Filesystem Guild 
You've brought up three separate issues - fault-tolerance,  secrecy and
secret sharing.  They are probably best dealt with separately, for the
purposes of understanding them as well as implementing them.
There are replicating file systems that provide the kind of fault
tolerance that you seem to be looking for, although I'm not aware
of any "production grade" systems that can replicate read-write
files in any reasonable way.  Done right, such a system would
probably involve guarantees, implemented partially at the server
side, that a file has been replicated in some number of places
prior to any write operation returning.  You could kludge this at
the client side alone by just modifying your file system interface
to make an approprate number of replicas each time something is
written.  There are a whole bunch of issues surrounding failure
semantics - how do you handle writes when one of the replica servers
is unavailable, and so on.
Secrecy, on the other hand, is best thought of as a client-side
issue, and can be handled with existing client file system encryption
tools that run at the client file system interface level.  For
example, on Unix clients, CFS can store its underlying data on most
any remote file system, and requires no changes or special attention
from the server side.  I have no idea whether the various PC
encrypting file systems (SFS, etc) that have since come along
separate their functions from the low-level storage in a way that
makes it possible to use them with remote file servers, but there's
probably no reason you couldn't build such a system if one didn't
already exist.  The main issue in practice is key management.
Depending on the application, you might want to back up keys under
some secret sharing scheme that allows keys to be recovered by some
subset of key holders.  This is especially important for commercial

@_date: 1995-02-10 11:48:38
@_author: Matt Blaze 
@_subject: why pgp sucks 
PGP suffers from its failure to separate cleanly its primary
mechanism (encrypting and signing messages) from policy (what to
do with those signed and encrypted mechansims).  Without a clean
separation, the mechanism is limited to use in those applications
narrowly envisioned by the system's authors.  Of course, PGP is
hardly unique here; designing clean interfaces and separation-of-
functions isn't easy, and its even harder in the face of meeting
the needs of an existing installed base of first-generation users.
Personally, I'd much rather see a suite of tools: an encryption/signature
tool (or maybe tools - let me apply them in whatever order is
approprate), a decryption verification tool, a certificate management
system that operates on messages signed with the signature tool and a
top level that glues all this together and implements local policy
(like what consitutes a valid signature, key revocation, etc).  If
we had a system that worked like this,, we could more easily create
richer key certificates that specify restrictions on what is being
signed, revocation conditions, etc.  (As it is, there isn't even
any way for a key signer to revoke a signature, let alone describe
what purpose the signature exists for.)
Of course, you could probably build all this ON TOP of the existing
pgp and pem, but you'd still be left with bloated underlying tools
that implement more policy than they need to.
Oh well.

@_date: 1995-02-10 14:31:27
@_author: Matt Blaze 
@_subject: why pgp sucks 
The only "principle" of which I'm aware (and particularly interested
in supporting) is that of having widely fielded, useful and strong
privacy and authentication tools that work properly and transparently.
That means, among a great many other things, flexible protocols
and tools that support remote key distribution services.
As much as people want to believe that privacy can be reduced to
some kind of romantic struggle between the evil forces of Centralization
(PEM?) and the civilizing forces of Anarchy (PGP?), the world most
of us live in is a lot more complex than that.
More seriously, the problem that Perry brought up is that it's hard
to deploy any kind of scaleable key distribution infrastructure
that works with PGP (as it currently exists - and yes, I realize
there are work-arounds for some specific situations).  That, as well
as other shortcomings (like its fixed trust/certification model)
that work against its serious use, make it doubtful that PGP 2.x
has much long-term future as anything other than a plaything for
nerds like us.  Hopefully, PGP and other good tools will evolve to
work well on a larger scale before Microsoft has a chance to give
everyone what _it_ thinks the world needs.
(I'm not trying to attack anyone here, by the way - part of the
problem is that we're just now learning what the privacy problems
of the real world even _are_.  Experimental tools like PGP are
important as much for providing experience and exposing problems
and limitations as they are for their immediate function.  Indeed,
the fact that PGP and PEM are as useful as they are may actually
work _against_ the spread of really large-scale crypto tools; the
people who they are aimed at stay happy while the rest of the world
never finds out what it's missing.)

@_date: 1995-02-10 17:11:41
@_author: Matt Blaze 
@_subject: why pgp sucks 
Well, you could do that, but it has the disadvantage that you can't
or control what server a particular key would end up on.  One of the
nice things about DNS-like systems is that a domain is responsible for
providing the resources to provide lookups within it.  If I add a machine
to crypto.com, I add it to the crypto.com name server (plus the secondary
servers, but that's a detail that gets handled automatically).
Everyone knows to come here if they want to resolve a crypto.com name.
In the case of PGP key IDs, you could create an artificial hierarchy
of numbers for the purpose of offloading work among several servers,
but that doesn't solve the hard problem, which is letting _me_ (or my
designee) control (and be responsible for) the distribution of keys in
_my_ domain.  (When someone generates a new key it could end up anywhere
in the kind of hierarchy you described).
I don't think it's clear yet, by the way, that domain names are
the right model for personal key distribution (in particular, it
assumes that keys are being distributed on-line and deals only
awkwardly with semi- off-line clients, as anyone who travels with
a sometimes-networked laptop knows.  It also assumes that the
distribution hierarchy can be mapped atop the lookup keys namespace,
which makes it hard to use for anything that isn't hierarchically
formed).  It's probably one of the important options, though, since
it scales so well and has a successfully fielded history in DNS.

@_date: 1995-02-12 09:25:57
@_author: Matt Blaze 
@_subject: the problem that destroyed PGP 
I don't think anyone has suggested there's any one problem that
"destroys" PGP.  Several people have pointed out a number of problems
that limit PGP's scalability in various ways.  Its flat key ID
namespace is one.  Lack of functional modularity is another.  Its
fixed certification model is still another.  There are more, and
no doubt still others waiting to be discovered as the user base
grows.  Any secure communications system that aspires to large-scale
penetration, whether called "PGP" or something else, will have to
tackle these kinds of issues before it will be successful.  Some
of the issues are obvious, while others only become apparent after
some experience.  Scale, after all, has a way of turning easy
problems into surprisingly hard ones.
For whatever reason, PGP has attracted an almost cult-like following,
and this has so far helped the spread of secure email.  But this
cuts both ways; cult status or not, PGP has to continue to evolve
and adapt to large-scale, mainstream demands by applying the lessons
of other big systems.  If it doesn't, rest assured that companies
like Microsoft and AT&T will do just fine with whatever they decide
the market wants.

@_date: 1995-02-12 17:17:01
@_author: Matt Blaze 
@_subject: Factoring - State of the Art and Predictions 
No it hasn't.  Factoring is believed to be hard, but no one has ever
shown it to be NP-hard (let alone NP complete).
Ditto for discrete log.

@_date: 1995-01-01 20:21:50
@_author: Matt Blaze 
@_subject: Book review: Codebreakers, the Inside Story of Bletchley Park 
Let me wholeheartedly echo John's recommendation; this is a terrific
book, one from which I learned a great deal.  You'll get more out
of it, however, the more you already know about the Bletchley Park
efforts and the principles on which the Enigma and Lorenz machines
operated.  In particular, Welchman's "The Hut Six Story" (McGraw
Hill, 1982) makes good preparatory reading.  Unfortunately, that
book has been out of print for some time, but is fairly widely
available at used book shops.
I had the opportunity to visit Bletchley Park a couple of weeks
ago.  Most of the original huts are still standing, albiet in
various states of disrepair.  Walking around the site, knowing
something of what went on there in complete secrecy 50 years ago,
I could only imagine the sense of urgency and bustle that must have
been in the air with 12000 people working (day and night, over
three shifts) in a relatively small space.  The more I learn about
the effort the more impressed I am with the accomplishments that
took place there.  In particular, the path from basic research to
operational functionality was far shorter than one would think
After the war, the site was used by GCHQ and by British Telecom as
a training center.  It was recently saved from redevlopment and is
now being converted into museum.  Among the projects taking place
there is a construction of a working model of the original "Colossus"
machine, arguably the first electronic computer ever built (it was
used in breaking the Lorenz teleprinter cipher).  I believe the site
is currently open for visitors on alternate weekends.

@_date: 1995-01-29 15:58:54
@_author: Matt Blaze 
@_subject: Telnet Acrobatics 
This is really funny - these programs are almost *exactly* the first
assignment in the computer networks class that I taught at Columbia last
Spring.  I think these may actually be modified versions of one of the
submissions from one of the students in the course.  (The actual assignment
called for something slightly different from these two programs, but close
enough to make it easy enough to modify.  Assignment sheet attached below
for reference...)
By the way, speaking of encrypted sessions, I'm currently shaking the
bugs out of "esp", an application-level encrypted session manager for Unix
terminal sessions across untrusted networks.  It's based on RSAREF
and 3-DES, and I expect to release it next week or so.  Stay tuned.
========== assignment1.ms (troff -ms format) attached below ===============
.nr FM 1i
.nr HM .75i
.nr LL 6.9i
.nr PO .85i
.OH ""
.EH ""
Homework  TCP Laundry Service
CS 4119 - Computer Networks
Assigned: Thursday, January 27, 1994
Due: Sunday, February 13, 1994, Midnight
The Problem
One of the features of the TCP/IP protocol suite is that two communicating
entities each need to know the network address of the other.  In general,
this is a useful property; it makes it possible, for example, for a server
to use the network address of clients who connects to it as part of an
authentication protocol.  An example of this is the
.I rlogin
protocol, in which the server machine uses the network address from which
a request originates to determine whether to ask for a password before letting
the user log in.  (It is worth understanding how this works, by the way,
and the inherent risks of relying on the network for authentication).
Sometimes, however, it is desirable to offer completely
.I anonymous
services in which the server has no way to determine where a connection to
it originates.  For example, it may be useful to provide the ability for
informants to send anonymous electronic mail to news reporters or law
enforcement agencies.
Unfortunately, the Internet Protocol (IP) suite does not provide for
anonymous communication.  One way to simulate anonymous communication is
to make use of intermediate "data laundry" servers, whose sole purpose is
to relay traffic between its sources and destinations.  Data laundries derive
their name from the criminal practice of "money laundering", where a
criminal moves his or her loot between several businesses and banks in an
effort to obscure the connection between stealing the money and spending it.
A data laundry accepts connections from clients (or other
laundries) and connects them to whatever remote service (or laundry) they
wish to communicate with.  Since the final destination thinks it is
communicating with the laundry, the only way to determine the real origin
of a connection would be to compromise the security of each of the laundries
along the way.
The Assignment
Your job is to build a laundry service for TCP connections.  This should
consist of two parts: a
.I "laundry daemon"
which connects clients to services and a
.I "laundry client"
which provides a convenient front end to users of the service.
Also write a short manual describing how to use your programs.
.NH 2
Laundry Daemon
The laundry daemon should accept TCP connections on a pre-selected port
number (pick one that isn't already used by some existing service).  When
a connection comes in, it should \fCfork\fP a subprocess for the duration
of the connection and print a message announcing that it is ready:
\fC100 cs.columbia.edu laundry service ready\fP
All messages from the daemon should consist of single lines of ASCII text
starting with a three digit number and followed by an informational message.
Messages numbers starting with 1 indicate success, message numbers starting
with 2 indicate failure.
Once the initial ready message is transmitted to the client, the server should
accept a single line of text containing a destination hostname followed by
at least one space followed by a port identifier.  Both the hostname and
port ID should be able to be specified by either their official names
or by their decimal values; you may assume that any identifier starting with a
digit is a numeric, otherwise it is a name.  Examples of valid input:
\fCcunix.cc.columbia.edu finger
128.59.40.11    79
128.59.40.11   telnet\fP
The server should then attempt to open a TCP connection to the given
host/port.  If the connection fails for any reason (host unreachable,
name lookup failure, etc.), the server should send an appropriate error
message to the client, e.g,:
\fC201 cunix.cc.columbia.edu connection refused on port finger\fP
Otherwise, the server should send a message indicating success:
\fC101 connected to cunix.cc.columbia.edu port finger\fP
Once the connection is established, the daemon should simply relay the all traffic between the source and destination.  If an error occurs
or the connection to either side of the connection closes, the daemon
should close both sides of the connection and terminate the subprocess.
Your laundry daemon should be able to handle arbitrarily many connections
simultaneously.  In particular, it should be possible to launder connections
through itself.
.NH 2
Laundry Client
The laundry client provides a convenient front end to users of the laundry
service.  Its job is to read, from a configuration file, a list of
laundry servers (and the TCP port numbers they run on) followed by
a final destination and port number.  For example:
\fCa.columbia.edu 10000
b.columbia.edu.edu 10000
cunix.cc.columbia.edu telnet\fP
would launder a TCP connection to the telnet port of cunix.cc.columbia.edu
through laundry servers running on port 10000 of a.columbia.edu and
Once the connection is established, the laundry client should simply connect
its standard input and standard output to the laundered connection.  Upon
EOF at either the remote connection or the standard input, the client
should close the connection and terminate.
If the connection fails any any point along the laundered path,
the client should print an appropriate error message and terminate.
You'll need to be familiar with the system calls for establishing TCP
connections (socket, connect, bind, etc.), the routines for looking up
host and service names (gethostbyname, etc.), the system calls for
manipulating terminal IO (ioctl), and the system call for multiplexing
input streams (select).
A common source of errors is to try to bind your service to a port already
in use by another process.  Make sure the port number you're using is
not already in use.  Also, make sure you kill any laundry daemons you've
started when you're done testing your program.
Extra Credit Ideas
Make the laundry service fully compatible with the telnet protocol.
Extend your service to provide encrypted connections. (You'll want to
learn about key exchange protocols.  You'll find the RSAREF library,
available at the rsa.com ftp site, helpful.)
Extend the laundry service to allow laundered servers as well as clients;
that is, allow a service to set up and accept connections through a chain
of proxy servers.
For lots of extra credit, make your code available and convince lots of
people to adopt it as a standard.  (This is more work than it's worth!).
Your program will be graded based on whether it works according to the
assignment, how well it handles errors, and the quality of your
documentation and code.
Turn your programs in with the submit program; your TAs will have information
on how to use this.
Late programs will be accepted, but with a reduced grade.  Late programs
cannot get extra credit.

@_date: 1995-07-16 01:18:30
@_author: Matt Blaze 
@_subject: Unix not the Only Place for "Vanguard" Applications 
Cypherpunks, as they say, write code.
It doesn't really matter very much what platform cypherpunks write
code for, as long as we actually write code.  Progress comes from
getting stuff done and making results available so that others can
expand on it and use it, not from sitting around optimizing what
should be done (by others, of course) in the future.  (Ever notice
how, every time this comes up, the question is always something
like "why aren't people writing more software for platform X?" and
never "I want to write some software - does anyone have any
suggestions on which platform would have the most impact?")
Every minute spent arguing about whether Unix, DOS, Macs or VIC-20s
constitute the optimal platform for writing and deploying crypto
software is a minute during which no crypto code is being written
or deployed for Unix, DOS, Macs, or VIC-20s.
Just write code.  For whatever platform you like writing code for.

@_date: 1995-07-31 18:05:10
@_author: Matt Blaze 
@_subject: a hole in PGP 
It's true that, in general, the "burden" of demonstrating whether a
system is secure should fall primarily on those who claim it is rather
than on those who claim it isn't.  It's also true that PGP, for
whatever reason, is treated with a degree of reverence that is,
perhaps, unwarranted.  I, for one, would be much happier to see
greater vetting of widely-used programs like PGP.  But that does not
mean that one can expect to be taken seriously by simply throwing
darts and seeing where they land.  That would mean that essentially no
hardware, software, algorithm or protocol could ever be considered
trustworthy by anyone for any purpose.  There is a difference between
raising specific concerns and making vague, wild, unsupported claims,
which is how what you wrote below reads to me.
No one knows how "prove" anything substantial, much less the absence
of backdoors, for anything but the most trivial software and
Your attempt to cast a near-defamatory shadow of suspicion over the
individuals and institutions who wrote the software, without raising
even a single specific concern about something you've observed about
the code, invites more questions about your own motives than those of
MIT or its staff.  It seems reasonable to ask you to put up or shut
Disclaimer: I also give away cryptographic source code, in connection
with my job as a research scientist for a company that has even closer
ties to the spook community than you seem to think MIT has...

@_date: 1995-07-31 19:31:45
@_author: Matt Blaze 
@_subject: a hole in PGP 
I never said that I thought that PGP (or anything else) is "secure."
But to the extent that I do trust it for any given purpose, it is for
approximately the same reasons that I trust lots of other things that
I rely on.  I've spot checked some of the code - far from an
exhaustive analysis - and I've yet to discover anything myself that
points to any specific weakness.  I assume that others have done the
same, and I also assume that someone like me who did discover a
weakness would be likely, as I would be, to publish it and that
therefore I'd hear about it.  This is, for better or for worse, about
as much as can be said for almost anything in the cryptographic world.
Far from perfect, to be sure, but hardly unusual or unique to PGP.
Because you seem to be pointing a finger at specific people.  Your
recent messages imply (to me, at least) that you think one or more
members of the MIT PGP project may have deliberately tampered with
some of the PGP code.  You think the risk of this sort of thing having
occurred is especially great - greater than with other products, in
fact - with MIT PGP because of some (unspecified) connection you
believe MIT has with NSA.  (If I am mistaken here and you don't think
MIT PGP is at special risk, please clarify this - I suspect others got
the same impression).  PGP did not come from "MIT".  It came from
specific individuals who work there and who are named in the code and
documentation.  They have professional and personal reputations and
feelings just like we all do.  Some of these individuals are on or
close to this list.  To imply, without offering evidence, that these
people are somehow tainted and that their work should be especially
mistrusted is harmful and hurtful to them.  To use such implications
as the entire basis for claims about the security of or risks
associated with specific software does not move our understanding of
things forward.  Pointing out something specific, on the other hand,
would move things forward.  I think your "arguments" about this
subject so far have been vague, unscholarly, unprofessional,
needlessly personal, and just plain insulting.

@_date: 1995-07-31 19:43:51
@_author: Matt Blaze 
@_subject: Attacks on PGP 
[good comments deleted]
My impression (based on reviewing papers for the last few CRYPTOs and
EUROCRYPTs) is that the reason for the lack of "practical" papers is
primarily that not very many of them get submitted.  In fact, I think
there actually are a fair number of cryptanalysis papers at CRYPTO,
at least compared with the even smaller number of papers there that
describe new ciphers.  Anyway, cryptanalysis IS part of the mainstream
of the academic crypto world these days (consider differential
cryptanalysis, linear cryptanalysis, etc.)

@_date: 1995-07-31 20:33:43
@_author: Matt Blaze 
@_subject: a hole in PGP 
This speaks for itself.  "They or those like them," indeed!
I never made any claim that PGP is "secure".  Quite the contrary -
I've been complaining about the security implications of PGP's
monolithic structure and complexity since I first saw the code, though
I did state the basis on which I trust it little less than I trust
other software of equal complexity.  Primarily, however, I jumped in
to this discussion to take issue with your unfair implication that
there is reason to suspect deliberate wrongdoing on the part of the
MIT people.  If your remarks are based on some specific information
you know about some person or group, please tell us.  Otherwise, it
would be a shame allow your credibility to taint these people in the
backs of people's minds just for the sake of a casual, throwaway
rhetorical device.  There is no need to raise the specter of an evil
conspiracy to make your point.  It's irrelevant and beneath you, based
on what I've read of your earlier work on viruses.
Feel free to have the last word if you'd like, since we seem to AGREE
that PGP needs more analysis and scrutiny.

@_date: 1995-10-02 13:18:02
@_author: Matt Blaze 
@_subject: Crypto APIs 
A couple of weeks ago I attended a meeting at the NATO SHAPE Technical
Center in the Hague to discuss international cryptographic APIs.  Several
high-ranking NSA types were there, as well as their counterparts from
various NATO countries plus a handful of industry crypto people (like
me).  The idea of the meeting was to find a way to separate
cryptographic function from cryptographic interfaces, in a way that
allows the applications that call the cryptographic functions to be
more freely exported.  That is, I can write and export an application
that calls the crypto API but that doesn't actually implement the
cryptography, and then, when it reaches its destination, the
locally-preferred cryptosystem can be plugged right in.  Crypto might
be implemented in hardware (e.g., Fortezza) or software (e.g., with a
shared library or pseudo-device driver).
Obviously, this idea is somewhat (completely?) at odds with the
criteria presented at last month's NIST workshops for exportable
software key escrow systems.  One of the requirements given for such
systems is that it be difficult to replace the crypto with something
that doesn't implement key escrow.  But who ever said the government
was consistent?  Interestingly, it was clear that many people in NSA
believe that applications that call an API are controlled under ITAR,
but there is some recognition that this may be wishful thinking or may
change soon.  So while some (maybe most) of NSA wants to prevent
development of standard APIs and prevent the export of applications
that use them, others recognize that these will evolve by themselves
anyway and will be very hard to control once they do.  Anyway, the
situation is far from clear.  It seems best to encourage the realistic
side of NSA as much as possible...
I learned a few interesting things at the meeting.  First of all,
overwhelmingly, there is recognition, especially on the part of the
non-US government security agencies, that there is enormous value in
being able to buy off-the-shelf applications like Microsoft Word or
Netscape Navigator and just plugging in the local military cryptosystem
and using it for classified traffic.  Everyone seemed to agree that
there is a growing need for this and that it's too expensive to rely
on custom software.  There is also movement away from the traditional
military ``link encryption'' approach that involves centrally-
controlled secure networks in favor of a ``risk management'' approach
that favors end-to-end security with off-the-shelf products.  In other
words, the parts of the military that are concerned with actually
securing communications want exactly what we want, and are just
starting to realize it.  While lots of us have always known this, I
had never heard it articulated as quite clearly (or as loudly) by
actual comsec/infosec people before.
Second, the senior NSA guy mentioned a few things I hadn't heard
before.  Fortezza is now approved for classified traffic through the
SECRET level.  Also, the ``type 1'' (classified) through ``type 4''
(unevaluated) cryptography standard is being scrapped in favor of a
three ``tier'' system, as follows (these are approximate quotes, from
my rough notes):
Tier 1 traffic is stuff related to ``national command authority''.
(Seems to be secret and top secret and up).  It will require NSA
cryptosystems, hardware implementation, and will NOT employ key escrow
(because of the ``obvious risks''!).
Tier 2 traffic is information that, if disclosed, would have
``national implications'' if revealed.  Examples given include things
like the national power grid, the banking system, etc.  It was
unclear whether any classified traffic would be included in tier 2.
Clearly, some of what is now called ``sensitive but unclassified''
(SBU) will be in tier 2.  Anyway, tier 2 systems will be approved by
NIST (not NSA, although there will obviously be NSA input into the
standards) and will require hardware implementation.  Tier 2 traffic
will be escrowed, and the government will escrow its own keys.
Fortezza is an example tier 2 device (but read on...)
Tier 3 traffic will be that which would have ``private implications''
if disclosed.  Examples given included personal financial and medical
records, etc.  Current SBU traffic not in tier 2.  Tier 3 would also
be handled by NIST, employ commercial or government key escrow (like
tier 2) and would be permitted to be implemented in software.
Here's the surprise: Tiers 2 and 3 will be interoperable.  So there
will be published algorithms for tier 3.  It is possible that tiers 2
and 3 will have the same algorithms, and that the government will
suggest them.  It was unclear with interoperability will require that
all tier 2 algorithms will be published and implementable in tier 3
software or whether this means that tier 2 devices will also have to
implement the tier 3 algorithms.  There is an obvious choice of a tier
2/3 algorithm: Skipjack (although there were concerns that this is
``too slow'').  So we may eventually find out whether ``S1'' was
really Skipjack after all....

@_date: 1995-10-02 13:59:33
@_author: Matt Blaze 
@_subject: Crypto APIs 
Yes.  (ICE, by the way, is funded by ARPA and run by TIS.  Strange notion
of "experiment", given that the result of the "experiment" will be to see
whether the government will allow it.  So one part of DoD is funding TIS
to find out how another part of DoD behaves...)

@_date: 1995-10-24 12:02:35
@_author: Matt Blaze 
@_subject: Hash collisions [was Re: MD5 weakness ? ...] 
le  nd I hesitate to jump in to this exchange given the defensive and
vague nature of the discussion, but...
While I agree that SHA seems preferable, for a number of reasons,
to MD5, it is worth noting that Hans Dobbertin of the German Information
Security Agency recently found a collision in MD4. His attack
allows you to generate a pair of plainexts that generate the same hash.
A fast technique for finding a second plaintext that hashes to some given
value remains an open problem with MD4 (and SHA and MD5, for that matter).
As far as I can tell the attack does not readily generalize to MD5
or SHA.

@_date: 1995-10-27 13:34:56
@_author: Matt Blaze 
@_subject: New release of CFS Unix encrypting file system available 
This isn't how it works.  You "attach" an encrypted directory to a
virtual namespace into which you write (and read) the cleartext.  It's
similar to mounting a file system.
Hard links don't work across different "attached" directories (just as
they don't work across different file systems).

@_date: 1995-10-28 07:38:28
@_author: Matt Blaze 
@_subject: DigiCrime web page 
Arjen Lenstra's startup, DigiCrime, full service criminal computer
hacking organization now has a web presence, thanks to to the efforts
of its theif scientist, Kevin McCurley.
-matt blaze, president of vice

@_date: 1995-10-29 08:07:10
@_author: Matt Blaze 
@_subject: New release of CFS Unix encrypting file system available 
I'm not sure why I'm bothering to respond to this, but I'd hate to
think someone might take the above message seriously and think that
there's some kind of "serious flaw" in CFS demonstrated by this sequence
of (hypothetical, incorrect) commands.  So here goes:
What on earth are you talking about?
As I pointed out in a previous message, that's not how CFS works - you
can't link across encrypted directories.
There may be (and probably are) bugs in or attacks against CFS, but this
isn't one of them.

@_date: 1995-09-24 17:05:32
@_author: Matt Blaze 
@_subject: `Random' seed. 
Here's my current favorite quick-and-dirty true-random-in-software generator.
Use at own risk and read the comments carefully...
===================cut here===========================
 *	Physically random numbers (very nearly uniform)
 *	D. P. Mitchell  *	Modified by Matt Blaze 2/95
 */
 * The authors of this software are Don Mitchell and Matt Blaze.
 *              Copyright (c) 1995 by AT&T.
 * Permission to use, copy, and modify this software without fee
 * is hereby granted, provided that this entire notice is included in
 * all copies of any software which is or includes a copy or
 * modification of this software and in all copies of the supporting
 * documentation for such software.
 *
 * This software may be subject to United States export controls.
 *
 * THIS SOFTWARE IS BEING PROVIDED "AS IS", WITHOUT ANY EXPRESS OR IMPLIED
 * WARRANTY.  IN PARTICULAR, NEITHER THE AUTHORS NOR AT&T MAKE ANY
 * REPRESENTATION OR WARRANTY OF ANY KIND CONCERNING THE MERCHANTABILITY
 * OF THIS SOFTWARE OR ITS FITNESS FOR ANY PARTICULAR PURPOSE.
 */
 * WARNING: depending on the particular platform, truerand() output may
 * be biased or correlated.  In general, you can expect about 16 bits of
 * "pseudo-entropy" out of each 32 bit word returned by truerand(),
 * but it may not be uniformly diffused.  You should therefore run
 * the output through some post-whitening function (like MD5 or DES or
 * whatever) before using it to generate key material.  (RSAREF's
 * random package does this for you when you feed truerand() bits to the
 * seed input function.)
 *
 * Test these assumptions on your own platform before fielding a system
 * based on this software or these techniques.
 *
 * This software seems to work well (at 16 bits per truerand() call) on
 * a Sun Sparc-20 under SunOS 4.1.3 and on a P100 under BSDI 2.0.  You're
 * on your own elsewhere.
 */
     static jmp_buf env;
static unsigned count;
static unsigned ocount;
static unsigned buffer;
static int
static void
static unsigned long
unsigned long
int n;

@_date: 1995-09-28 13:44:09
@_author: Matt Blaze 
@_subject: Netscpae & Fortezza (Or, say it Ain't so, Jeff?) 
Oh, come on.  One does not have to "support key escrow" to be interested
in Fortezza.  The Fortezza interface does not have any "escrow-specific"
features; it's actually a pretty good crypto API (for which several vendors
plan to produce compliant, non-escrowed PCMCIA cards).  The Fortezza market
(in the government) is also pretty big, by the way, so one can hardly
blame any vendor for being interested in in.
Disclaimer: I'm also an evil "Fortezza sympathizer".  I built a (Tessera,
actually) version of CFS last year.  I think it's a good interface,
and I'd encourage people to  build strong, non-escrowed crypto modules
(in hardware and in software) that conform to it...

@_date: 1995-09-30 12:35:48
@_author: Matt Blaze 
@_subject: my favorite random-numbers-in-software package (unix) 
About a week ago I posted my (Don Mitchell's really) truerand() routine
for Unix.  truerand() needs some post-processing before use; it cannot
be used directly.  Here's a more complete version; the main interface is
randbyte(), which returns (in about a third of a second) one really
random byte (based on 64 truerand() bits) that can be used directly.
As an added bonus, the library also throws in a shs-2 function and the
basic truerand() code.
The basic idea is that you exploit randomness in the drift between
the processor clock and the rate at which interval timer interrupts
occur.  Such drift occurs even on idle processors.  randbyte() assumes
that there's at least about .4 bits of "entropy" per interrupt, which is (probably) a safe assumption on modern processors.  Randomness introduced
by the OS (scheduler, etc.) can add to the overall entropy, but shouldn't
be relied upon by itself.
An advantage to this approach (using clock skew) is that the randomness
doesn't depend on external events like user input, network traffic or
processor load.  That makes it especially attractive for generating keys
on unattended servers, e.g., for generating Diffie-Hellman exponents.
Note, however, that very (very) slow and heavily-loaded processors may
not provide enough cycles to the truerand process between interrupts for
these assumptions to hold.  Also, all bets are off on processors that use
a single clock source for both interval timing and CPU clocking.
This code is very BSD/SunOS-centric and is completely untested elsewhere.
Read the comments for scary warnings about testing on your own platform
before using it for anything serious like generating keys.
=======================cut here==============
# This is a shell archive (produced by GNU sharutils 4.1).
# To extract the files from this archive, save it to some FILE, remove
# everything before the `!/bin/sh' line above, then type `sh FILE'.
# Existing files will *not* be overwritten unless `-c' is specified.
# This shar contains:
# length mode       name
# ------ ---------- ------------------------------------------
#   1270 -rw-r--r-- makefile
#   1246 -rw-r--r-- randbyte.c
#   2886 -rw-r--r-- truerand.c
#   7142 -rw-r--r-- shs.c
#    149 -rw-r--r-- randtest.c
touch -am 1231235999 $$.touch >/dev/null 2>&1
if test ! -f 1231235999 && test -f $$.touch; then
  shar_touch=touch
  shar_touch=:
  echo
  echo 'WARNING: not restoring timestamps.  Consider getting and'
  echo "installing GNU \`touch', distributed in GNU File Utilities..."
  echo
rm -f 1231235999 $$.touch
# ============= makefile ==============
if test -f 'makefile' && test X"$1" != X"-c"; then
  echo 'x - skipping makefile (file already exists)'
  echo 'x - extracting makefile (text)'
  sed 's/^X//' << 'SHAR_EOF' > 'makefile' &&
# makefile for librand
# tested on Sparc-20 (SunOS 4.x) and P100 (BSDI) only.
# You're on your own elsewhere.  Read the comments for scary warnings.
# Usage: int randbyte();
 The authors of this software are Don Mitchell, Matt Blaze & Jack Lacy.
              Copyright (c) 1995 by AT&T.
 Permission to use, copy, and modify this software without fee
 is hereby granted, provided that this entire notice is included in
 all copies of any software which is or includes a copy or
 modification of this software and in all copies of the supporting
 documentation for such software.
 This software may be subject to United States export controls.
 THIS SOFTWARE IS BEING PROVIDED "AS IS", WITHOUT ANY EXPRESS OR IMPLIED
 WARRANTY.  IN PARTICULAR, NEITHER THE AUTHORS NOR AT&T MAKE ANY
 REPRESENTATION OR WARRANTY OF ANY KIND CONCERNING THE MERCHANTABILITY
SRCS=randbyte.c truerand.c shs.c
OBJS=randbyte.o truerand.o shs.o
# No -O in CFLAGS! On some compilers, this optimizes out the counter...
librand.a: $(OBJS)
X	ar rcv librand.a $(OBJS)
X	ranlib librand.a
randtest: randtest.c $(SRCS)
X	cc -DDEBUGRND randtest.c $(SRCS) -o randtest
librand.shar: makefile $(SRCS) randtest.c
X	shar makefile $(SRCS) randtest.c > librand.shar
  $shar_touch -am 0930150995 'makefile' &&
  chmod 0644 'makefile' ||
  echo 'restore of makefile failed'
  shar_count="`wc -c < 'makefile'`"
  test 1270 -eq "$shar_count" ||
    echo "makefile: original size 1270, current size $shar_count"
# ============= randbyte.c ==============
if test -f 'randbyte.c' && test X"$1" != X"-c"; then
  echo 'x - skipping randbyte.c (file already exists)'
  echo 'x - extracting randbyte.c (text)'
  sed 's/^X//' << 'SHAR_EOF' > 'randbyte.c' &&
X *	Random byte interface to truerand()
X *	Matt Blaze 5/95
X *	eight really random bits
X *	usage: X *		unsigned char r; int randbyte();
X *		r=randbyte();
X *	randbyte() takes about .3 seconds on most machines.
X */
X * The author of this software is Matt Blaze.
X *              Copyright (c) 1995 by AT&T.
X * Permission to use, copy, and modify this software without fee
X * is hereby granted, provided that this entire notice is included in
X * all copies of any software which is or includes a copy or
X * modification of this software and in all copies of the supporting
X * documentation for such software.
X *
X * This software may be subject to United States export controls.
X *
X * THIS SOFTWARE IS BEING PROVIDED "AS IS", WITHOUT ANY EXPRESS OR IMPLIED
X * WARRANTY.  IN PARTICULAR, NEITHER THE AUTHORS NOR AT&T MAKE ANY
X * REPRESENTATION OR WARRANTY OF ANY KIND CONCERNING THE MERCHANTABILITY
X * OF THIS SOFTWARE OR ITS FITNESS FOR ANY PARTICULAR PURPOSE.
X */
int randbyte()
X	unsigned long truerand();
X	unsigned char *shs();
X	unsigned long r[2];
X	unsigned char *hash;
X	r[0]=truerand(); r[1]=truerand();
X	hash = shs(r,sizeof(r));
 DEBUGRND
X	printf("%011o %011o %02x\n",r[0],r[1],*hash & 0xff);
X	return ((int) (*hash)) & 0xff;
  $shar_touch -am 0930145795 'randbyte.c' &&
  chmod 0644 'randbyte.c' ||
  echo 'restore of randbyte.c failed'
  shar_count="`wc -c < 'randbyte.c'`"
  test 1246 -eq "$shar_count" ||
    echo "randbyte.c: original size 1246, current size $shar_count"
# ============= truerand.c ==============
if test -f 'truerand.c' && test X"$1" != X"-c"; then
  echo 'x - skipping truerand.c (file already exists)'
  echo 'x - extracting truerand.c (text)'
  sed 's/^X//' << 'SHAR_EOF' > 'truerand.c' &&
X *	Physically random numbers (very nearly uniform)
X *	D. P. Mitchell X *	Modified by Matt Blaze 2/95
X */
X * The authors of this software are Don Mitchell and Matt Blaze.
X *              Copyright (c) 1995 by AT&T.
X * Permission to use, copy, and modify this software without fee
X * is hereby granted, provided that this entire notice is included in
X * all copies of any software which is or includes a copy or
X * modification of this software and in all copies of the supporting
X * documentation for such software.
X *
X * This software may be subject to United States export controls.
X *
X * THIS SOFTWARE IS BEING PROVIDED "AS IS", WITHOUT ANY EXPRESS OR IMPLIED
X * WARRANTY.  IN PARTICULAR, NEITHER THE AUTHORS NOR AT&T MAKE ANY
X * REPRESENTATION OR WARRANTY OF ANY KIND CONCERNING THE MERCHANTABILITY
X * OF THIS SOFTWARE OR ITS FITNESS FOR ANY PARTICULAR PURPOSE.
X */
X * WARNING: depending on the particular platform, truerand() output may
X * be biased or correlated.  In general, you can expect about 16 bits of
X * "pseudo-entropy" out of each 32 bit word returned by truerand(),
X * but it may not be uniformly diffused.  You should therefore run
X * the output through some post-whitening function (like MD5 or DES or
X * whatever) before using it to generate key material.  (RSAREF's
X * random package does this for you when you feed truerand() bits to the
X * seed input function.)
X *
X * Test these assumptions on your own platform before fielding a system
X * based on this software or these techniques.
X *
X * This software seems to work well (at 16 bits per truerand() call) on
X * a Sun Sparc-20 under SunOS 4.1.3 and on a P100 under BSDI 2.0.  You're
X * on your own elsewhere.
X */
     static jmp_buf env;
static unsigned count;
static unsigned ocount;
static unsigned buffer;
static int
X	struct itimerval it, oit;
X	timerclear(&it.it_interval);
X	it.it_value.tv_sec = 0;
X	it.it_value.tv_usec = 16665;
X	if (setitimer(ITIMER_REAL, , &oit) < 0)
X		perror("tick");
static void
X	if (count)
X		longjmp(env, 1);
X	(void) signal(SIGALRM, interrupt);
X	tick();
static unsigned long
X	if (setjmp(env)) {
X		count ^= (count>>3) ^ (count>>6) ^ ocount;
X		count &= 0x7;
X		ocount=count;
X		buffer = (buffer<<3) ^ count;
X		return buffer;
X	}
X	(void) signal(SIGALRM, interrupt);
X	count = 0;
X	tick();
X	for (;;)
X		count++;	/* about 1 MHz on VAX 11/780 */
unsigned long
X	count=0;
X	(void) roulette();
X	(void) roulette();
X	(void) roulette();
X	(void) roulette();
X	(void) roulette();
X	(void) roulette();
X	(void) roulette();
X	(void) roulette();
X	(void) roulette();
X	(void) roulette();
X	return roulette();
int n;
X	int slop, v;
X	slop = 0x7FFFFFFF % n;
X	do {
X		v = truerand() >> 1;
X	} while (v <= slop);
X	return v % n;
  $shar_touch -am 0930143395 'truerand.c' &&
  chmod 0644 'truerand.c' ||
  echo 'restore of truerand.c failed'
  shar_count="`wc -c < 'truerand.c'`"
  test 2886 -eq "$shar_count" ||
    echo "truerand.c: original size 2886, current size $shar_count"
# ============= shs.c ==============
if test -f 'shs.c' && test X"$1" != X"-c"; then
  echo 'x - skipping shs.c (file already exists)'
  echo 'x - extracting shs.c (text)'
  sed 's/^X//' << 'SHAR_EOF' > 'shs.c' &&
X * The authors of this software are Jim Reeds and Jack Lacy
X *              Copyright (c) 1992, 1994 by AT&T.
X * Permission to use, copy, and modify this software without fee
X * is hereby granted, provided that this entire notice is included in
X * all copies of any software which is or includes a copy or
X * modification of this software and in all copies of the supporting
X * documentation for such software.
X *
X * This software may be subject to United States export controls.
X *
X * THIS SOFTWARE IS BEING PROVIDED "AS IS", WITHOUT ANY EXPRESS OR IMPLIED
X * WARRANTY.  IN PARTICULAR, NEITHER THE AUTHORS NOR AT&T MAKE ANY
X * REPRESENTATION OR WARRANTY OF ANY KIND CONCERNING THE MERCHANTABILITY
X * OF THIS SOFTWARE OR ITS FITNESS FOR ANY PARTICULAR PURPOSE.
X */
X * Secure Hash Standard
X * proposed NIST SHS
X * coded for byte strings: number of bits is a multiple of 8
X *
X * Copyright (c) 1992, 1994 AT&T Bell Laboratories
X * Coded by Jim Reeds 5 Feb 1992
X * Enhanced by Jack Lacy 1993, 1994
X */
X * unsigned char * shs(char *s, int n);
X *
X * input:  X *                s character array to be hashed
X *                n length of s in BYTES
X * output:
X *                return value: address of 5 unsigned longs holding hash
X *
X * machine dependencies:
X *                assumes a char is 8 bits
X */
X * passes test on:
X *                gauss (vax)
X *                3k (cray)
X *                slepian (MIPS)
X *                bird (sparcstation II)
X */
  typedef struct {
X    long totalLength;
X    unsigned long h[5];
X    unsigned long w[80];
} SHS_CTX;
unsigned char *shs();
 SOLARIS2X
 bzero(b, l)             memset(b, 0, l)
 bcopy(s, d, l)          memcpy(d, s, l)
 bcmp(s, d, l)           (memcmp(s, d, l)? 1 : 0)
static long nbits;
static unsigned long *h;
static unsigned long *w;
static void shs1();
static void packl (unsigned long);
static void pack (unsigned char, unsigned char, unsigned char, unsigned char);
static void shs1(void);
static void opack(unsigned char);
 MASK        (unsigned long)0xffffffffL        /* in case more than 32 bits per long */
X * stick one byte into the current block; process the block when full
X */
static void opack(c)
X  unsigned char c;
X	int n32, nd32, shiftbits;
X	register unsigned long x, mask, y;
X	
X	nd32 = (int)(nbits >> 5);  /* nbits/32 */
X	n32 = (int)(nbits & 0x1f); /* nbits%32 */
X	shiftbits = 24-n32;
X	
X	x = (unsigned long)(c<> 5);
X	w[nd32] = (u_long)(((u_long)c0<<24) | ((u_long)c1<<16) | ((u_long)c2<<8) | X	
X	nbits += 32;
X	if(nbits==512){
X		nbits = 0;
X		shs1();
X	}
X * stick a 4 byte number into the current block
X */
static void
X  unsigned long x;
X	pack((unsigned char)(x>>24), (unsigned char)(x>>16),
X	     (unsigned char)(x>>8), (unsigned char)(x>>0));
X * process one block
X */
static void
X	unsigned long *wp;
X	unsigned long temp;
X	unsigned long A, B, C, D, E;
X	int t;
X	
 S(n,x) (u_long)(((x)<<(n))|((MASK&(x))>>(32-(n))))
X	
X	wp = w;
X	t = 8;
X	do {
X		wp[16] = S(1, (u_long)(wp[13]^wp[8]^wp[2]^wp[0]));
X		wp[17] = S(1, (u_long)(wp[14]^wp[9]^wp[3]^wp[1]));
X		wp[18] = S(1, (u_long)(wp[15]^wp[10]^wp[4]^wp[2]));
X		wp[19] = S(1, (u_long)(wp[16]^wp[11]^wp[5]^wp[3]));
X		wp[20] = S(1, (u_long)(wp[17]^wp[12]^wp[6]^wp[4]));
X		wp[21] = S(1, (u_long)(wp[18]^wp[13]^wp[7]^wp[5]));
X		wp[22] = S(1, (u_long)(wp[19]^wp[14]^wp[8]^wp[6]));
X		wp[23] = S(1, (u_long)(wp[20]^wp[15]^wp[9]^wp[7]));
X		wp += 8;
X		t--;
X	} while (t > 0);
X	
X	A = h[0];
X	B = h[1];
X	C = h[2];
X	D = h[3];
X	E = h[4];
X	
X	t = 0;
X	while (t<20) {
X		temp = S(5,A) + E + w[t++];
X		temp += (unsigned long)0x5a827999L + ((B&C)|(D&~B));
X		E = D; D = C; C = S(30,B); B = A; A = temp;
X	}
X	while (t<40) {
X		temp = S(5,A) + E + w[t++];
X		temp += (unsigned long)0x6ed9eba1L + (B^C^D);
X		E = D; D = C; C = S(30,B); B = A; A = temp;
X	}
X	while (t<60) {
X		temp = S(5,A) + E + w[t++];
X		temp += (unsigned long)0x8f1bbcdcL + ((B&C)|(B&D)|(C&D));
X		E = D; D = C; C = S(30,B); B = A; A = temp;
X	}
X	while (t<80) {
X		temp = S(5,A) + E + w[t++];
X		temp += (unsigned long)0xca62c1d6L + (B^C^D);
X		E = D; D = C; C = S(30,B); B = A; A = temp;
X	}
X	h[0] = MASK&(h[0] + A);
X	h[1] = MASK&(h[1] + B);
X	h[2] = MASK&(h[2] + C);
X	h[3] = MASK&(h[3] + D);
X	h[4] = MASK&(h[4] + E);
 CHARSTOLONG(wp,s,i) {*wp++ = (u_long)((((u_long)(s[i])&0xff)<<24)|(((u_
X  SHS_CTX *mdContext;
X	nbits = 0;
X	mdContext->h[0] = (unsigned long)0x67452301L;
X	mdContext->h[1] = (unsigned long)0xefcdab89L;
X	mdContext->h[2] = (unsigned long)0x98badcfeL;
X	mdContext->h[3] = (unsigned long)0x10325476L;
X	mdContext->h[4] = (unsigned long)0xc3d2e1f0L;
X	mdContext->totalLength = 0;
shsUpdate(mdContext, s, n)
X  SHS_CTX *mdContext;
X  unsigned char *s;
X  unsigned int n;
X	register unsigned long *wp;
X	long nn = n;
X	long i;
X	
X	w = mdContext->w;
X	h = mdContext->h;
X	mdContext->totalLength += n;
X	
X	nbits = 0;
X	n = n/(u_long)64;
X	wp = w;
X	
X	while(n>0){
X		CHARSTOLONG(wp,s,0);
X		CHARSTOLONG(wp,s,4);
X		CHARSTOLONG(wp,s,8);
X		CHARSTOLONG(wp,s,12);
X		CHARSTOLONG(wp,s,16);
X		CHARSTOLONG(wp,s,20);
X		CHARSTOLONG(wp,s,24);
X		CHARSTOLONG(wp,s,28);
X		CHARSTOLONG(wp,s,32);
X		CHARSTOLONG(wp,s,36);
X		CHARSTOLONG(wp,s,40);
X		CHARSTOLONG(wp,s,44);
X		CHARSTOLONG(wp,s,48);
X		CHARSTOLONG(wp,s,52);
X		CHARSTOLONG(wp,s,56);
X		CHARSTOLONG(wp,s,60);
X		n--;
X		wp = w;
X		s = (s + 64);
X		shs1();
X	}
X	i=nn%64;
X	while(i>3) {
X		CHARSTOLONG(wp,s,0);
X		s = (s + 4);
X		nbits += (u_long)32;
X		i -= 4;
X	}
X	while (i) {
X		opack((unsigned char)*s++);
X		i--;
X	}
X  SHS_CTX *mdContext;
X	long nn = mdContext->totalLength;
X	w = mdContext->w;
X	h = mdContext->h;
X	
X	opack(128);
X	while(nbits != 448)opack(0);
X	packl((unsigned long)(nn>>29));
X	packl((unsigned long)(nn<<3));
X	
X	/* if(nbits != 0)
X	   handle_exception(CRITICAL,"shsFinal(): nbits != 0\n");*/
unsigned char *
shs(s, n)
X  unsigned char *s;
X  long n;
X        SHS_CTX *mdContext;
X	static SHS_CTX mdC;
X	static unsigned char ret[20];
X	int i;
X	
X	mdContext = &mdC
X	shsInit(mdContext);
X	shsUpdate(mdContext, s, n);
X	shsFinal(mdContext);
X	for (i=0; i<5; i++) {
X		ret[i*4] = (mdContext->h[i]>>24)&0xff;
X		ret[i*4+1] = (mdContext->h[i]>>16)&0xff;
X		ret[i*4+2] = (mdContext->h[i]>>8)&0xff;
X		ret[i*4+3] = (mdContext->h[i])&0xff;
X	}
X        X	return ret;
unsigned long *
X  FILE *in;
X	SHS_CTX *mdContext;
X	SHS_CTX mdC;
X	unsigned char buffer[1024];
X	long length, total;
X	mdContext = &mdC
X	
X	bzero(buffer, 1024);
X	total = 0;
X	shsInit(mdContext);
X	while ((length = fread(buffer, 1, 1024, in)) != 0) {
X		total += length;
X		shsUpdate(mdContext, buffer, length);
X	}
X	shsFinal(mdContext);
X	return mdContext->h;
  $shar_touch -am 0930142495 'shs.c' &&
  chmod 0644 'shs.c' ||
  echo 'restore of shs.c failed'
  shar_count="`wc -c < 'shs.c'`"
  test 7142 -eq "$shar_count" ||
    echo "shs.c: original size 7142, current size $shar_count"
# ============= randtest.c ==============
if test -f 'randtest.c' && test X"$1" != X"-c"; then
  echo 'x - skipping randtest.c (file already exists)'
  echo 'x - extracting randtest.c (text)'
  sed 's/^X//' << 'SHAR_EOF' > 'randtest.c' &&
int argc; char **argv;
X	int count;
X	if (argc==1)
X		count = 0;
X	else
X		count = atoi(argv[1]) + 1;
X	while (--count)
X		randbyte();
  $shar_touch -am 0930150095 'randtest.c' &&
  chmod 0644 'randtest.c' ||
  echo 'restore of randtest.c failed'
  shar_count="`wc -c < 'randtest.c'`"
  test 149 -eq "$shar_count" ||
    echo "randtest.c: original size 149, current size $shar_count"
exit 0

@_date: 1995-09-30 15:50:27
@_author: Matt Blaze 
@_subject: my favorite random-numbers-in-software package (unix) 
I'm the first to agree that, in the absence of some good analysis of
the exact platform on which it is run, the clock-skew approach is built
on a very weak foundation.  But informal (and completely ad hoc)
analysis suggests that it might be more promising than you'd first
expect.  While the drift between the two clocks is likely only very small,
we're also not asking for very much; we need less than one bit
worth of uncertainty in an accumulator that burns processor cycles until
some (smaller) number of clock intervals have occurred.  (The OS might
also not give you all those cycles, adding to the uncertainty, although
you can't really count on this in the case of high-priority processes or
unloaded machines).
I (and a few others) have run some tests on this on a couple of (bare)
processors in an effort to find artificats of the clock periods in the
low-order bits of the counter, with no success.  This, of course, hardly
constitutes a "proof".
I'd love to see some good analysis of this technique, particularly with
an eye toward quantifying the quality and bandwidth of the output and
finding better parameters for the minimum interval rate, etc.
PS there are other "magic" techniques for getting randomness without special
hardware that are proposed from time to time but that never really undergo
enough analysis for my taste.  For example, at CRYPTO '94 (or maybe '93)
there was an interesting proposal to use software to measure the air flow
inside the disk drive.

@_date: 1996-08-08 08:40:34
@_author: Matt Blaze 
@_subject: appropriate algorithm for application 
If you need this "master key" feature embedded in the cryptosystem
itself, you're probably out of luck - such a cipher would be at least
as slow as a public key cryptosystem.  See Blaze, Feigenbaum, Leighton,
"Master-Key Cryptosystems", CRYPTO '96 rump session, available at
ftp://research.att.com/dist/mab/mkcs.ps .
However, you could simulate the function of such a system by
selecting a different key for each file and then encypting each unique
file key with the master encryption key (which could be a public
key or a symmetric key, depending on whether the application that
encrypts the files is trusted to know the master decryption key).
This has the disadvantage, however, of requiring that you store
the encrypted file key with each file, which may or may not be
an issue for you.

@_date: 1996-02-04 21:24:18
@_author: Matt Blaze 
@_subject: RC2 technical questions 
[long list of other good and interesting questions deleted]
I'm confused by these two messages, as a non-lawyer (but I realize you're
also a non-lawyer).  How can RSADSI, on the one hand, expect to be able
to assert trade secret status over RC2 (with a warning to "...any person
who acquires, discloses or uses this information...") while at the same time
encouraging the world to examine and better understand the (illegally-
published) RC2 code?  To my lay mind, I cannot see how one can reconcile
your two messages.
I'm not trying to be cute or play lawyer.  I'm honestly confused as
to just what RSADSI's position here is.

@_date: 1996-02-18 03:00:44
@_author: Matt Blaze 
@_subject: DES_ono 
Actually, that article concludes that they *haven't* figured it out yet.
The report that the bankers haven't figured out yet, by the way,
is available online at:
  ftp://ftp.research.att.com/dist/mab/keylength.txt  [ASCII text]
  ftp://ftp.research.att.com/dist/mab/keylength.ps   [PostScript]

@_date: 1996-01-07 00:34:31
@_author: Matt Blaze 
@_subject: Revoking Old Lost Keys 
Escrow is orthogonal to the underlying problem here, which is that the
PGP revocation model is completely wrong.  Since the trust properties
and other semantics of a key originate with the certificates attached to
the key, and not from the key owner per se, it makes little sense to make
the key owner responsible for revoking that trust.  Far more sensible would
be a scheme in which the certificate issuers themselves could revoke their
certificates when they believe a key is no longer trustworthy.  (A practical
decentralized system like PGP could provide a facility for certifiers to
"pre-revoke" their certificates at the time they are issued so that the key
owner could distribute the revocation certificates himself if he discovers
his own key to have been compromised or lost.)
Note that the problem here is in the basic trust model, not just the
certificate distribution model (which is a separate problem).  The lack of
ability for a certifier to revoke his own certification, plus the lack of a
facility to put limits on the duration and meaning of the certification,
make PGP certificates of very limited practical value.

@_date: 1996-01-07 02:34:23
@_author: Matt Blaze 
@_subject: Revoking Old Lost Keys 
Indeed, I agree that's the right approach.  In fact, I agree so much
that I've spent the last few months (with Joan Feigenbaum and Jack
Lacy) developing the principles and structure for just such a "trust
management" system.  Watch this space for details of our system, called
"PolicyMaker", which I expect to release a paper about shortly and a
reference implementation around April or May.

@_date: 1996-01-12 08:59:13
@_author: Matt Blaze 
@_subject: Zimmermann case is dropped. 
You must be very relieved, as are the rest of us in the cryptographic
community in the US.
One question, though.  In your comments, you write
      I'd also like to thank Joe Burton, counsel for the co-defendant.
This raises the obvious question - do you know if the entire case has
been dropped, or have you just been eliminated as a target with the
possibility still open that others may yet be indicted?
Again, my congratulations.

@_date: 1996-07-20 13:31:15
@_author: Matt Blaze 
@_subject: NSA response to key length report 
Particularly impressive is that our key length report was hardly
above criticism from several angles, but their rebuttal managed somehow to avoid them.
What I find most disturbing about this is that their report was
provided secretly to policymakers in the administration and in
Congress, without independent technical review that would have
quickly exposed the fallacy of the arguments.  I never would have
seen it had several of the recipients not faxed it to me.  This is
the first hard evidence I've seen of NSA providing anything less
than the highest quality technical analysis to other parts of the
government.  A non-specialist reader would be easily misled by the
technically dense, but completely irrelevant, "rebuttal".  It smacks of either ill-informed sloppiness, or, perhaps worse, self-serving  disingenuous cynicism.  Either conclusion is scary, and, to me in
fact, quite surprising.

@_date: 1996-07-23 20:31:20
@_author: Matt Blaze 
@_subject: Distributed DES crack 
I don't want to throw water over what I think would be a very useful
thing to have done, but I'm really skeptical that current "net"
computing power with general purpose processors is up to this.
My back of the envelope calculation, making some generous assumptions
about the implementation, suggests that such an effort would require
somewhere in the range of 10,000 and 50,000 CPU years on general (100MHz
or so Pentium) processors.  This is well beyond any distributed computation
I'm aware of ever having been done, even adjusting for "Moore inflation".
While feasible in a "complexity theory" sense, it's really not realistic
Even if it were feasible, what would we use as a challenge key?
Personally, I'd rather someone finish up the Wiener ASIC to the point where
it could go out to fab, get some prototype chips made, design a board around
it, and publish the design, from board layout on down.  This would be a
great Master's project, and some of us (maybe me, but I'll have to check)
might even be able to scrape up enough funds to buy enough chips/boards/etc
to build a modest size machine (say, that could exhaust a DES key in 1-6
months).  Initial engineering costs aside, the marginal cost of each
such machine could be well within the budgets of, say, a medium size crypto
research lab, and would make a scary enough demo to convince even the
most trusting management types of the risks of 56 bit keys.
(Please cc me on replies, as I'm not reading the list except when someone
alerts me to an interesting topic.  Thanks.)

@_date: 1996-07-24 08:06:06
@_author: Matt Blaze 
@_subject: Distributed DES crack 
Here are my back-of-the-calculator numbers:
2^55 = 3.6 * 10^16 trial ecb operations (+key setup).
Best P-100 DES software implementation I can find can do 110000 ECBs/sec.
Key setup takes about twice as long as a single ECB.
Assuming amazingly fast key setup and careful ECB optimization
(precompute IP and FP, gray coded key enumeration with cached round results,
etc), MAYBE, somehow, you could do 100000 ECB/sec on "average" workstation
(average = 100mhz Pentium).
That's 11000 Pentium-100 years for half the DES keyspace.  Well, I'm working on getting the funds to build (or support someone
to build) some kind of parallel DES engine.  I can probably scrape
together an FPGA-based machine that can do a key in less than 6 months.
I'm very serious about this project, but I can't say for sure when or if
I'll be ready to start.

@_date: 1996-07-24 09:41:05
@_author: Matt Blaze 
@_subject: Distributed DES crack 
My estimate is that an FPGA-based machine that can do a single DES key
every four months (eight months to exhaust the whole keyspace) could
be built with off-the-shelf stuff for comfortably under $50k (plus
labor, plus software development costs).  A prototype board should cost
under $1000 and will help prove the concept and get a more accurate cost
estimate.  I expect to build such a prototype machine myself, and, if it
works as I expect, maybe the whole thing.

@_date: 1996-06-27 19:02:21
@_author: Matt Blaze 
@_subject: My testimony at Wednesday's Senate hearing on encryption policy 
WRITTEN TESTIMONY OF DR. MATTHEW BLAZE
BEFORE THE SENATE COMMITTEE ON COMMERCE, SCIENCE, AND TRANSPORTATION,
SUBCOMMITTEE ON SCIENCE, TECHNOLOGY, AND SPACE
JUNE 26, 1996
Thank you for the opportunity to speak with you about the technical
impact of encryption policy.  It is a privilege to be here, and I
hope my perspective will be useful to you.
Let me begin by describing my own background and biases.  I am a
Principal Research Scientist in the area of computer security and
cryptology at AT&T Research in Murray Hill, New Jersey.  I also
hold a number of ancillary appointments related to computer security;
among others, I teach an occasional graduate course in the subject
at Columbia University, and I serve as co-chair of the Federal
Networking Council Advisory Committee subcommittee on security and
privacy (which advises Federal agencies on computer networking
issues).  However, the views I am presenting here today are my own,
and should not be taken to represent those of any organization with
which I happen to be affiliated.
I am a computer scientist by training; my Ph.D. is from the Princeton
University Computer Science department, and my primary research
areas are cryptology, computer security, and large-scale distributed
systems.  Much of my research focuses on the management of encryption
keys in networked computing systems and understanding the risks of
using cryptographic techniques to accomplish security objectives.
Recent government initiatives in encryption, such as the "Clipper
Chip," have naturally been of great interest to me, in no small
part because of the policy impact they have on the field in which
I work, but also because they present a number of very interesting
technical and scientific challenges in their own right.
My testimony today focuses on three areas.  First, I will discuss
the role and risks of cryptographic techniques for securing the
current and future electronic world.  Next, I will examine in more
detail the security implications of the limitations imposed on
US-based cryptographic systems through the government's export
policies.  Finally, I will discuss the technical aspects of the
Administration's current approach to cryptography policy, which
promotes "key escrow" systems.
I  THE INCREASING IMPORTANCE OF ENCRYPTION
The importance of cryptographic techniques for securing modern
computer and communications systems is widely recognized today.
Evidence of the scope of  this recognition can be found in the
increasing number of hardware, software, and system vendors that
offer encryption in their products, the increasing demand for
high-quality encryption by users in a widening array of applications,
and the growing, thriving community of cryptologic researchers of
which I am a part.  It is vital that those who formulate our nation's
policies and official attitude toward encryption understand the
nature of the underlying technology and the reasons for its growing
importance to our society.
The basic function of cryptography is to separate the security of
a message's content from the security of the medium over which it
is carried.  For example, we might encrypt a cellular telephone
conversation to guard against eavesdroppers (allowing the call to
be transmitted safely over easily-intercepted radio frequencies),
or we might use encryption to verify that documents, such as
contracts, have not been tampered with (removing the need to
safeguard a copy of the original).  The idea that this might be
possible is not a new one; history suggests that the desire to
protect information is almost as old as the written word itself.
Perhaps as a consequence of the invention of the digital computer,
our understanding of the theory and practice of cryptography has
accelerated in recent years, with a number of new techniques
developed and many new applications emerging.  Among the most
important of the recent techniques is "public key cryptography."
It allows secure messages to be exchanged without the need
Modern cryptographic techniques are based on the application of
simple, if repetitive,  mathematical functions, and as such lend
themselves nicely to implementation by computer programs.  Any
information that can be represented digitally can be protected by
encryption, including computer files, electronic mail messages,
and even audio and video signals such as telephone calls, radio,
and television.  Encryption can be performed by means of software
on general-purpose computers, through special-purpose hardware, or
by special programming of microprocessor-based electronic products
such as the next generation of cellular telephones.  The basic cost
of encryption in terms of computational power required is quite
low, and the marginal cost of including encryption in a software-based
computer program or a programmable electronic product is essentially
Why, then, has encryption recently enjoyed so much attention?  The
reasons can be found from two perspectives: the technology of modern
communication systems, and the new purposes for which we are relying
on digital information.
First, the technology and economics of modern communications and
computing systems strongly favors media that have little inherent
security.  For example, wireless telephones have great advantages
in convenience and functionality compared with their familiar wired
counterparts and are comprising an increasing proportion of the
telephone network.  This also makes eavesdropping much easier for
curious neighbors, burglars identifying potential targets, and
industrial spies seeking to misappropriate trade secrets.  Similarly,
decentralized computer networks such as the Internet have lower
barriers to entry, are much less expensive, are more robust and
can be used to accomplish a far greater variety of tasks than the
proprietary networks of the past, but, again, at the expense of
intrinsic security.  The Internet makes it virtually impossible to
restrict, or even predict, the path that a particular message will
traverse, and there is no way to be certain where a message really
originated or whether its content ha
Second, electronic communication is becoming increasingly critical
to the smooth functioning of our society and our economy and even
to protect the safety of human life.  Communication networks and
computer media are rapidly replacing less efficient, traditional
modes of interaction whose security properties are far better
understood.  As teleconferencing replaces face-to-face meetings,
electronic mail replaces letters, electronic payment systems replace
cash transactions, and on-line information services replace written
reference materials, we gain a great deal in efficiency, but our
assumptions about the reliability of very ordinary transactions
are often dangerously out-of-date.
Put another way, the trend in communication and computing networks
has been away from closed systems in favor of more open ones and
the trend in our society is to rely on these new systems for
increasingly serious purposes.  There is every reason to believe
that these trends will continue, and even accelerate, for the
foreseeable future.  Cryptography plays an important and clear role
in helping to provide security assurances that at least mirror what
we have come to expect from the older, more familiar communications
methods of the not-so-distant past.
II  KEY LENGTH AND SECURITY
The "strength" of an encryption system depends on a number of
variables, including the mathematical properties of the underlying
encryption function, the quality of the implementation, and the
number of different "keys" from which the user is able to choose.
It is very important that a cryptosystem and its implementation be
of high quality, since an error or bug in either can expose the
data it protects to unexpected vulnerabilities.  Although the
mathematics of cryptography is not completely understood and cipher
design is an exceptionally difficult discipline (there is as yet
no general "theory" for designing cipher functions), there are a
number of common cipher systems that have been extensively studied
and that are widely trusted as building blocks for secure systems.
The implementation of practical systems out of these building
blocks, too, is a subtle and difficult art, but commercial experience
in this area is beginning to lead to good practices for adding
high-quality encryption systems to software
The most easily quantified variable that contributes to the strength
of an encryption system is the size of the pool of potential values
from which the cryptographic keys are chosen.  Modern ciphers depend
on the secrecy of the users' keys, and a system is considered
well-designed only if the easiest "attack" involves trying every
possible key, one after the other, until the correct one is found.
The system is secure only if the number of keys is large enough to
make such an attack infeasible.  Keys are usually specified as a
string of "bits," and adding one bit to the key length doubles the
number of possible keys.  An important question, then, is the
minimum key length sufficient to resist a key search attack in
Last November, I participated in a study, organized by the Business
Software Alliance, aimed at examining the computer technology that
might be used by an "attacker" in order to determine the minimum
length keys that should be used in commercial applications.  We
followed an unusually conservative methodology in that we assumed
that the attacker would have only available standard "off-the-shelf"
technology and is constrained to purchase in single-unit quantities
with no economies of scale.  That is, our methodology would tend
to produce a recommendation for shorter keys than would an analysis
using the more conventional approach of giving the potential attacker
every benefit of the doubt in terms of technological advantages he
might enjoy.  Nonetheless, we concluded that the key lengths
recommended in existing U.S. government standards (e.g., the Data
Encryption Standard, with a 56-bit key) for domestic use are far
too short and will soon render data protected under them vulnerable
to attack with only modest
Attempting to design systems "at the margins" by using the minimum
key length needed is a dubious enterprise at best.  Because even
a slight miscalculation as to the technology and resources available
to the potential attacker can make the difference between a secure
system and an insecure one, prudent designers specify keys that
are longer than the minimum they estimate is needed to resist
attack, to provide a margin for error.
Current U.S. policy encourages the designers of encryption systems
to take exactly the opposite approach.  Encryption systems designed
for export from the United States at present generally must use
keys no more than 40 bits long.  Such systems provide essentially
no cryptographic security, except against the most casual "hacker."
Examples of 40 bit systems being "broken" through the use of spare
computer time on university computer networks are commonplace.
Unfortunately, it is not only users outside the U.S. who must make
do with the inferior security provided by such short keys.  Because
of the difficulty of maintaining  multiple versions of software,
one for domestic sale and one for export, and the need for common
interoperability standards, many US-based products are available
only with export-length keys.
There is no technical, performance, or economic benefit to employing
keys shorter than needed.  Unlike, for example, the locks used to
protect our homes, very secure cryptographic systems with long keys
are no more expensive to produce or any harder to design or use
than weaker systems with shorter keys.  The only reason vendors
design systems with short keys is to comply with export requirements.
The key length figures and analysis in this section are based on
so-called "secret key" cryptosystems.  For technical reasons,
current public key cryptosystems employ much longer keys than secret
key systems to achieve equivalent security (public keys are measured
in hundreds or thousands of bits).  However, virtually all systems
that use public key cryptography also rely on secret key cryptography,
and so the overall strength of any system is limited by the weakest
encryption function and key length in it.
III  THE RISKS OF KEY ESCROW
A number of recent Administration initiatives have proposed that
future cryptosystems include special "key escrow" provisions to
facilitate access to encrypted data by law enforcement and intelligence
agencies.  In a such systems, copies of keys are automatically
deposited, in advance, with third parties who can use them to
arrange for law enforcement access if required in the future.
Several key escrow systems have been proposed by the Administration,
differing in the details of how keys are escrowed, and who the
third party key holders are.  In the first proposal, called the
"Clipper chip," the system is embedded in a special tamper-resistant
hardware-based cryptosystem and copies of keys are held by federal
agencies.  In the more recent "public key infrastructure" proposal,
keys are escrowed at the time a new public key is generated and
are held by the organization (public or private) responsible for
certification of the public key.
Although the various key escrow proposals differ in the details of
how they accomplish their objective, there are a number of very
serious fundamental problems and risks associated with all of them.
There are some appropriate commercial applications of key escrow
techniques.  A properly designed cryptosystem makes it essentially
impossible to recover encrypted data without the correct key.  This
can be a double-edge sword; the cost of keeping unauthorized parties
out is that if keys are lost or unavailable at the time they are
needed, the owner of encrypted data will be unable to make use of
his own information.  This problem, of balancing  secrecy with
assurances of continued availability, remains an area of active
research, and commercial solutions are starting to emerge.  The
Administration's initiatives do not address this problem especially
well, however.
The first problem with key escrow is the great increase in engineering
complexity that such systems entail.  The design and implementation
of even the simplest encryption systems is an extraordinarily
difficult and delicate process.  Very small changes can introduce
fatal security flaws that often can be exploited by an attacker.
Ordinary (non-escrowed) encryption systems have conceptually rather
simple requirements (for example, the secure transmission of data
between two parties) and yet, because there is no general theory
for designing them, we still often discover exploitable flaws in
fielded systems.  Key escrow renders even the specification of the
problem itself far more complex, making it virtually impossible to
assure that such systems work as they are intended to.  It is
possible, even likely, that lurking in any key escrow system are
one or more design weaknesses that allow recovery of data by
unauthorized parties. The commercial and academic world simply does
not have the tools to analyze or des
Key escrow is so difficult that even systems designed by the
classified world can have subtle problems that are only discovered
later.  In 1994 I discovered a new type of "protocol failure" in
the Escrowed Encryption Standard, the system on which the Clipper
chip is based.  The failure allows, contrary to the design objectives
of the system, a rogue user to circumvent the escrow system in a
way that makes the data unrecoverable by the government.  Others
weaknesses have been discovered since then that make it possible,
for example, to create incriminating messages that appear to have
originated from a particular user.
It should be noted that these weaknesses have been discovered in
spite of the fact that most of the details of the standard are
classified and were not included in the analysis that led to the
discovery of the flaws.  But these problems did not come about
because of incompetence on the part of the system's designers.
Indeed, the U.S. National Security Agency is likely the most advanced
cryptographic enterprise in the world, and is justifiably entrusted
with developing the cryptographic systems that safeguard the
government's most important military and state secrets.  The reason
the Escrowed Encryption Standard has flaws that are still being
discovered is that key escrow is an extremely difficult technical
problem, with requirements unlike anything previously encountered.
A second problem with key escrow arises from the difficulty of
operating a key escrow center in a secure manner.   According to
the Administration (for example, see the May 20, 1996 White House
draft report "Enabling Privacy, Commerce, Security and Public Safety
in the Global Information Infrastructure"), key escrow centers must
be prepared to respond to law enforcement requests for escrowed
data 24 hours a day, completing transactions within two hours of
receiving each request.  There are thousands of law enforcement
agencies in the United States authorized to perform electronic
surveillance, and the escrow center must be prepared to identify
and respond to any of them within this time frame.  If the escrow
center is also a commercial operation providing data recovery
services, it may also have tens of thousands of additional private
sector customers that it must be prepared to serve and respond to.
There are few, if any, secure systems that operate effectively on
such a scale and under such tightly-constr
A third problem with the Administration's key escrow proposals is
that they fail to distinguish between cryptographic keys for which
recovery might be required and those for which recoverability is
never needed.  There are many different kinds of encryption keys,
but for the purposes of discussing key escrow it is sufficient to
divide keys into three categories.  The first includes keys used
to encrypt stored information, which must be available throughout
the lifetime of the data.  The owner of the data has an obvious
interest in ensuring the continued availability of such keys, and
might choose to rely on a commercial service to store "backup"
copies of such keys.  A second category of key includes those used
to encrypt real-time communications such as telephone calls.  Here,
the key has no value to its owner once the transaction for which
it was used has completed.  If a key is lost or destroyed in the
middle of a conversation, a new one can be established in its place
without permanent loss of informatio
Unfortunately, however, the current Administration proposal exposes
all three types of keys equally to the risks introduced by the
escrow system, even though recoverability is not required for all
of them.  Partly this is because there is no intrinsic difference
in the structure of the different types of keys; they are usually
indistinguishable from one another outside of the application in
which they are used.
Finally, there is the problem that criminals can circumvent almost
any escrow system to avoid exposure to law enforcement monitoring.
All key escrow systems are vulnerable to so-called "superencryption,"
in which a user first encrypts data with an unescrowed key prior
to processing it with the escrowed system.  Most escrow systems
are also vulnerable to still other techniques that make it especially
easy to render escrowed keys useless to law enforcement.  The ease
of avoiding law enforcement when convenient raises an obvious
question as to whether the reduced security and high cost of setting
up an escrow system will yield any appreciable public safety benefit
in practice.
IV  CONCLUSIONS AND RECOMMENDATIONS
The wide availability of encryption is vitally important to the
future growth of our global information infrastructure.  In many
cases, encryption offers the only viable option for securing the
rapidly increasing range of human, economic and social activities
taking place over emerging communication networks.  It is no
exaggeration to say that the availability of encryption in the
commercial marketplace is and will continue to be necessary to
protect national security.  Unfortunately, current policy, through
export controls and ambiguous standards, discourages, rather than
promotes, the use of encryption.
Current encryption policy is enormously frustrating to almost
everyone working in the field.  Export controls make it difficult
to deploy effective cryptography even domestically, and we can do
little more than watch as our foreign colleagues and competitors,
not constrained by these rules, are matching our expertise and
obtaining an ever-increasing share of the market.  A large part of
the problem is that the current regulations were written as if to
cover hardware but are applied to software, including software in
the public domain or aimed at the mass market.  The PRO-CODE bill
goes a long way toward moving the regulations in line with the
realities of the technology.

@_date: 1996-06-27 20:14:07
@_author: Matt Blaze 
@_subject: My testimony at Wednesday's Senate hearing on encryption policy 
[Previous message was garbled with several lines truncated; here's
the real one.  Sorry.  -matt]
[This file is (will soon be) at ftp://research.att.com/dist/mab/testimony.txt]
WRITTEN TESTIMONY OF DR. MATTHEW BLAZE
BEFORE THE SENATE COMMITTEE ON COMMERCE, SCIENCE, AND TRANSPORTATION,
SUBCOMMITTEE ON SCIENCE, TECHNOLOGY, AND SPACE
JUNE 26, 1996
Thank you for the opportunity to speak with you about the technical
impact of encryption policy.  It is a privilege to be here, and I hope
my perspective will be useful to you.
Let me begin by describing my own background and biases.  I am a
Principal Research Scientist in the area of computer security and
cryptology at AT&T Research in Murray Hill, New Jersey.  I also hold a
number of ancillary appointments related to computer security; among
others, I teach an occasional graduate course in the subject at
Columbia University, and I serve as co-chair of the Federal Networking
Council Advisory Committee subcommittee on security and privacy (which
advises Federal agencies on computer networking issues).  However, the
views I am presenting here today are my own, and should not be taken
to represent those of any organization with which I happen to be
I am a computer scientist by training; my Ph.D. is from the Princeton
University Computer Science department, and my primary research areas
are cryptology, computer security, and large-scale distributed
systems.  Much of my research focuses on the management of encryption
keys in networked computing systems and understanding the risks of
using cryptographic techniques to accomplish security objectives.
Recent government initiatives in encryption, such as the "Clipper
Chip," have naturally been of great interest to me, in no small part
because of the policy impact they have on the field in which I work,
but also because they present a number of very interesting technical
and scientific challenges in their own right.
My testimony today focuses on three areas.  First, I will discuss the
role and risks of cryptographic techniques for securing the current
and future electronic world.  Next, I will examine in more detail the
security implications of the limitations imposed on US-based
cryptographic systems through the government's export policies.
Finally, I will discuss the technical aspects of the Administration's
current approach to cryptography policy, which promotes "key escrow"
I THE INCREASING IMPORTANCE OF ENCRYPTION
The importance of cryptographic techniques for securing modern
computer and communications systems is widely recognized today.
Evidence of the scope of this recognition can be found in the
increasing number of hardware, software, and system vendors that offer
encryption in their products, the increasing demand for high-quality
encryption by users in a widening array of applications, and the
growing, thriving community of cryptologic researchers of which I am a
part.  It is vital that those who formulate our nation's policies and
official attitude toward encryption understand the nature of the
underlying technology and the reasons for its growing importance to
our society.
The basic function of cryptography is to separate the security of a
message's content from the security of the medium over which it is
carried.  For example, we might encrypt a cellular telephone
conversation to guard against eavesdroppers (allowing the call to be
transmitted safely over easily-intercepted radio frequencies), or we
might use encryption to verify that documents, such as contracts, have
not been tampered with (removing the need to safeguard a copy of the
original).  The idea that this might be possible is not a new one;
history suggests that the desire to protect information is almost as
old as the written word itself.  Perhaps as a consequence of the
invention of the digital computer, our understanding of the theory and
practice of cryptography has accelerated in recent years, with a
number of new techniques developed and many new applications emerging.
Among the most important of the recent techniques is "public key
cryptography."  It allows secure messages to be exchanged without the
need for specific advance arrangements between parties.  A related
notion is the "digital signature," which allows messages to be
"signed" in a way that verifiably associates the signer of a message
with its content.
Modern cryptographic techniques are based on the application of
simple, if repetitive, mathematical functions, and as such lend
themselves nicely to implementation by computer programs.  Any
information that can be represented digitally can be protected by
encryption, including computer files, electronic mail messages, and
even audio and video signals such as telephone calls, radio, and
television.  Encryption can be performed by means of software on
general-purpose computers, through special-purpose hardware, or by
special programming of microprocessor-based electronic products such
as the next generation of cellular telephones.  The basic cost of
encryption in terms of computational power required is quite low, and
the marginal cost of including encryption in a software-based computer
program or a programmable electronic product is essentially zero.
Why, then, has encryption recently enjoyed so much attention?  The
reasons can be found from two perspectives: the technology of modern
communication systems, and the new purposes for which we are relying
on digital information.
First, the technology and economics of modern communications and
computing systems strongly favors media that have little inherent
security.  For example, wireless telephones have great advantages in
convenience and functionality compared with their familiar wired
counterparts and are comprising an increasing proportion of the
telephone network.  This also makes eavesdropping much easier for
curious neighbors, burglars identifying potential targets, and
industrial spies seeking to misappropriate trade secrets.  Similarly,
decentralized computer networks such as the Internet have lower
barriers to entry, are much less expensive, are more robust and can be
used to accomplish a far greater variety of tasks than the proprietary
networks of the past, but, again, at the expense of intrinsic
security.  The Internet makes it virtually impossible to restrict, or
even predict, the path that a particular message will traverse, and
there is no way to be certain where a message really originated or
whether its content has been altered along the way.  It is possible,
even common, for electronic mail messages to route through the
computers of competitors.  This is not a result of sloppy design or
poor planning on the part of the Internet's architects; on the
contrary, these properties are a direct consequence of the
technological advances that make the Internet efficient and useful in
the first place.
Second, electronic communication is becoming increasingly critical to
the smooth functioning of our society and our economy and even to
protect the safety of human life.  Communication networks and computer
media are rapidly replacing less efficient, traditional modes of
interaction whose security properties are far better understood.  As
teleconferencing replaces face-to-face meetings, electronic mail
replaces letters, electronic payment systems replace cash
transactions, and on-line information services replace written
reference materials, we gain a great deal in efficiency, but our
assumptions about the reliability of very ordinary transactions are
often dangerously out-of-date.
Put another way, the trend in communication and computing networks has
been away from closed systems in favor of more open ones and the trend
in our society is to rely on these new systems for increasingly
serious purposes.  There is every reason to believe that these trends
will continue, and even accelerate, for the foreseeable future.
Cryptography plays an important and clear role in helping to provide
security assurances that at least mirror what we have come to expect
from the older, more familiar communications methods of the
not-so-distant past.
II KEY LENGTH AND SECURITY
The "strength" of an encryption system depends on a number of
variables, including the mathematical properties of the underlying
encryption function, the quality of the implementation, and the number
of different "keys" from which the user is able to choose. It is very
important that a cryptosystem and its implementation be of high
quality, since an error or bug in either can expose the data it
protects to unexpected vulnerabilities.  Although the mathematics of
cryptography is not completely understood and cipher design is an
exceptionally difficult discipline (there is as yet no general
"theory" for designing cipher functions), there are a number of common
cipher systems that have been extensively studied and that are widely
trusted as building blocks for secure systems.  The implementation of
practical systems out of these building blocks, too, is a subtle and
difficult art, but commercial experience in this area is beginning to
lead to good practices for adding high-quality encryption systems to
software and hardware.  Users and developers of secure systems can
protect against weaknesses in these areas by choosing only cipher
functions that have been carefully studied and by ensuring that their
implementation follows good engineering practices.
The most easily quantified variable that contributes to the strength
of an encryption system is the size of the pool of potential values
from which the cryptographic keys are chosen.  Modern ciphers depend
on the secrecy of the users' keys, and a system is considered
well-designed only if the easiest "attack" involves trying every
possible key, one after the other, until the correct one is found.
The system is secure only if the number of keys is large enough to
make such an attack infeasible.  Keys are usually specified as a
string of "bits," and adding one bit to the key length doubles the
number of possible keys.  An important question, then, is the minimum
key length sufficient to resist a key search attack in practice.
Last November, I participated in a study, organized by the Business
Software Alliance, aimed at examining the computer technology that
might be used by an "attacker" in order to determine the minimum
length keys that should be used in commercial applications.  We
followed an unusually conservative methodology in that we assumed that
the attacker would have only available standard "off-the-shelf"
technology and is constrained to purchase in single-unit quantities
with no economies of scale.  That is, our methodology would tend to
produce a recommendation for shorter keys than would an analysis using
the more conventional approach of giving the potential attacker every
benefit of the doubt in terms of technological advantages he might
enjoy.  Nonetheless, we concluded that the key lengths recommended in
existing U.S. government standards (e.g., the Data Encryption
Standard, with a 56-bit key) for domestic use are far too short and
will soon render data protected under them vulnerable to attack with
only modest resources.  We concluded that keys today should be a bare
minimum of 75 bits long, and that systems being fielded today to
secure data over the next twenty years must employ keys of at least 90
bits. I have included a copy of our report as an appendix to my
Attempting to design systems "at the margins" by using the minimum key
length needed is a dubious enterprise at best.  Because even a slight
miscalculation as to the technology and resources available to the
potential attacker can make the difference between a secure system and
an insecure one, prudent designers specify keys that are longer than
the minimum they estimate is needed to resist attack, to provide a
margin for error.
Current U.S. policy encourages the designers of encryption systems to
take exactly the opposite approach.  Encryption systems designed for
export from the United States at present generally must use keys no
more than 40 bits long.  Such systems provide essentially no
cryptographic security, except against the most casual "hacker."
Examples of 40 bit systems being "broken" through the use of spare
computer time on university computer networks are
commonplace. Unfortunately, it is not only users outside the U.S. who
must make do with the inferior security provided by such short keys.
Because of the difficulty of maintaining multiple versions of
software, one for domestic sale and one for export, and the need for
common interoperability standards, many US-based products are
available only with export-length keys.
There is no technical, performance, or economic benefit to employing
keys shorter than needed.  Unlike, for example, the locks used to
protect our homes, very secure cryptographic systems with long keys
are no more expensive to produce or any harder to design or use than
weaker systems with shorter keys.  The only reason vendors design
systems with short keys is to comply with export requirements.
The key length figures and analysis in this section are based on
so-called "secret key" cryptosystems.  For technical reasons, current
public key cryptosystems employ much longer keys than secret key
systems to achieve equivalent security (public keys are measured in
hundreds or thousands of bits).  However, virtually all systems that
use public key cryptography also rely on secret key cryptography, and
so the overall strength of any system is limited by the weakest
encryption function and key length in it.
III THE RISKS OF KEY ESCROW
A number of recent Administration initiatives have proposed that
future cryptosystems include special "key escrow" provisions to
facilitate access to encrypted data by law enforcement and
intelligence agencies.  In a such systems, copies of keys are
automatically deposited, in advance, with third parties who can use
them to arrange for law enforcement access if required in the future.
Several key escrow systems have been proposed by the Administration,
differing in the details of how keys are escrowed, and who the third
party key holders are.  In the first proposal, called the "Clipper
chip," the system is embedded in a special tamper-resistant
hardware-based cryptosystem and copies of keys are held by federal
agencies.  In the more recent "public key infrastructure" proposal,
keys are escrowed at the time a new public key is generated and are
held by the organization (public or private) responsible for
certification of the public key.
Although the various key escrow proposals differ in the details of how
they accomplish their objective, there are a number of very serious
fundamental problems and risks associated with all of them.
There are some appropriate commercial applications of key escrow
techniques.  A properly designed cryptosystem makes it essentially
impossible to recover encrypted data without the correct key.  This
can be a double-edge sword; the cost of keeping unauthorized parties
out is that if keys are lost or unavailable at the time they are
needed, the owner of encrypted data will be unable to make use of his
own information.  This problem, of balancing secrecy with assurances
of continued availability, remains an area of active research, and
commercial solutions are starting to emerge.  The Administration's
initiatives do not address this problem especially well, however.
The first problem with key escrow is the great increase in engineering
complexity that such systems entail.  The design and implementation of
even the simplest encryption systems is an extraordinarily difficult
and delicate process.  Very small changes can introduce fatal security
flaws that often can be exploited by an attacker.  Ordinary
(non-escrowed) encryption systems have conceptually rather simple
requirements (for example, the secure transmission of data between two
parties) and yet, because there is no general theory for designing
them, we still often discover exploitable flaws in fielded systems.
Key escrow renders even the specification of the problem itself far
more complex, making it virtually impossible to assure that such
systems work as they are intended to.  It is possible, even likely,
that lurking in any key escrow system are one or more design
weaknesses that allow recovery of data by unauthorized parties. The
commercial and academic world simply does not have the tools to
analyze or design the complex systems that arise from escrow.
Key escrow is so difficult that even systems designed by the
classified world can have subtle problems that are only discovered
later.  In 1994 I discovered a new type of "protocol failure" in the
Escrowed Encryption Standard, the system on which the Clipper chip is
based.  The failure allows, contrary to the design objectives of the
system, a rogue user to circumvent the escrow system in a way that
makes the data unrecoverable by the government.  Others weaknesses
have been discovered since then that make it possible, for example, to
create incriminating messages that appear to have originated from a
particular user.
It should be noted that these weaknesses have been discovered in spite
of the fact that most of the details of the standard are classified
and were not included in the analysis that led to the discovery of the
flaws.  But these problems did not come about because of incompetence
on the part of the system's designers.  Indeed, the U.S. National
Security Agency is likely the most advanced cryptographic enterprise
in the world, and is justifiably entrusted with developing the
cryptographic systems that safeguard the government's most important
military and state secrets.  The reason the Escrowed Encryption
Standard has flaws that are still being discovered is that key escrow
is an extremely difficult technical problem, with requirements unlike
anything previously encountered.
A second problem with key escrow arises from the difficulty of
operating a key escrow center in a secure manner.  According to the
Administration (for example, see the May 20, 1996 White House draft
report "Enabling Privacy, Commerce, Security and Public Safety in the
Global Information Infrastructure"), key escrow centers must be
prepared to respond to law enforcement requests for escrowed data 24
hours a day, completing transactions within two hours of receiving
each request.  There are thousands of law enforcement agencies in the
United States authorized to perform electronic surveillance, and the
escrow center must be prepared to identify and respond to any of them
within this time frame.  If the escrow center is also a commercial
operation providing data recovery services, it may also have tens of
thousands of additional private sector customers that it must be
prepared to serve and respond to.  There are few, if any, secure
systems that operate effectively on such a scale and under such
tightly-constrained response time.  The argument, advanced by the
Administration, that escrow centers can use the same procedures that
protect classified data is a curious one, since classified information
is by its nature available to a far smaller and more
carefully-controlled potential audience than are escrowed keys.  It is
simply inevitable that escrow centers that meet the government's
requirements will make mistakes in giving out the wrong keys from time
to time or will be vulnerable to fraudulent key requests.  Key escrow,
by its nature, makes encrypted data less secure because the escrow
center introduces a new target for attack.
A third problem with the Administration's key escrow proposals is that
they fail to distinguish between cryptographic keys for which recovery
might be required and those for which recoverability is never needed.
There are many different kinds of encryption keys, but for the
purposes of discussing key escrow it is sufficient to divide keys into
three categories.  The first includes keys used to encrypt stored
information, which must be available throughout the lifetime of the
data.  The owner of the data has an obvious interest in ensuring the
continued availability of such keys, and might choose to rely on a
commercial service to store "backup" copies of such keys.  A second
category of key includes those used to encrypt real-time
communications such as telephone calls.  Here, the key has no value to
its owner once the transaction for which it was used has completed.
If a key is lost or destroyed in the middle of a conversation, a new
one can be established in its place without permanent loss of
information.  For these keys, the owner has no use for recoverability;
it is of value only to law enforcement and others who wish to obtain
access to a conversation without the knowledge or cooperation of the
parties.  Finally, there are the keys used not for secrecy but for
signature and authentication, to insure that messages indeed
originated from a particular party.  There is never a need for anyone,
law enforcement or the key owner, to recover such keys, since their
purpose is not to obscure content but rather to establish authorship.
If the owner looses a signature key, a new one can be generated easily
at any time.
Unfortunately, however, the current Administration proposal exposes
all three types of keys equally to the risks introduced by the escrow
system, even though recoverability is not required for all of them.
Partly this is because there is no intrinsic difference in the
structure of the different types of keys; they are usually
indistinguishable from one another outside of the application in which
they are used.
Finally, there is the problem that criminals can circumvent almost any
escrow system to avoid exposure to law enforcement monitoring.  All
key escrow systems are vulnerable to so-called "superencryption," in
which a user first encrypts data with an unescrowed key prior to
processing it with the escrowed system.  Most escrow systems are also
vulnerable to still other techniques that make it especially easy to
render escrowed keys useless to law enforcement.  The ease of avoiding
law enforcement when convenient raises an obvious question as to
whether the reduced security and high cost of setting up an escrow
system will yield any appreciable public safety benefit in practice.
IV CONCLUSIONS AND RECOMMENDATIONS
The wide availability of encryption is vitally important to the future
growth of our global information infrastructure.  In many cases,
encryption offers the only viable option for securing the rapidly
increasing range of human, economic and social activities taking place
over emerging communication networks.  It is no exaggeration to say
that the availability of encryption in the commercial marketplace is
and will continue to be necessary to protect national security.
Unfortunately, current policy, through export controls and ambiguous
standards, discourages, rather than promotes, the use of encryption.
Current encryption policy is enormously frustrating to almost everyone
working in the field.  Export controls make it difficult to deploy
effective cryptography even domestically, and we can do little more
than watch as our foreign colleagues and competitors, not constrained
by these rules, are matching our expertise and obtaining an
ever-increasing share of the market.  A large part of the problem is
that the current regulations were written as if to cover hardware but
are applied to software, including software in the public domain or
aimed at the mass market.  The PRO-CODE bill goes a long way toward
moving the regulations in line with the realities of the technology.

@_date: 1996-03-05 23:42:39
@_author: Matt Blaze 
@_subject: My letter to Leahy supporting the crypto bill 
Here is the text of a letter I sent to Leahy supporting the "Encrypted
Communications Privacy Act of 1996" being introduced today.  I urge everyone
to check out the bill (should be online on thomas.loc.gov sometime soon);
on balance, I think the bill is a huge step forward and deserves support.
Hon. Patrick Leahy
United States Senate
Dear Senator Leahy:
Thank you for introducing the Encrypted Communications Privacy Act of
1996.  As a member of the computer security and cryptology research
community, I have observed firsthand the deleterious effect that the
current regulations governing the use and export of cryptography are
having on our country's ability to develop a reliable and trustworthy
information infrastructure.  Your bill takes an important first step
toward creating regulations that reflect the modern realities of this
increasingly critical technology.
Unlike previous government encryption initiatives such as the
technically-flawed and unworkable ``Clipper'' chip, your bill
re-affirms the role of the marketplace in providing ordinary citizens
and businesses with a full range of choices for securing their private
information.  In particular, by freeing mass-market cryptographic
software and hardware from the burdensome export controls that govern
the international arms trade, the bill will help the American software
industry compete, for the first time, in the international market for
high-quality security products.
Law enforcement need not fear the widespread availability of
encryption; indeed, they should welcome and promote it.  Encryption
thwarts electronic predators by preventing unauthorized access to
private data and computer systems, and the use of strong cryptography
to protect computer networks is becoming as natural and necessary as
the use of locks and burglar alarms to protect our homes and
businesses.  While criminals, too, might occasionally derive some
advantage from the use of cryptography, the benefits of
widely-available encryption technology overwhelmingly favor the honest
user.  By recognizing that those who hold decryption keys on behalf of
others are in a special position of trust, your bill is respectful of
the privacy of law-abiding citizens without introducing impediments to
the government's ability to investigate and prevent crime.
I have also examined the new provision designed to discourage the use
of cryptography by criminals in the furtherance of a felony, and hope
to see your carefully-worded language reinforced by a narrow
interpretation in the courts, consistent with your intent.
Again, thank you for your continued leadership in this area, and I
look forward to doing whatever I can to help you bring encryption
regulations in line with the fast-changing reality of this emerging

@_date: 1996-03-11 06:21:29
@_author: Matt Blaze 
@_subject: Lawz to be. 
I suppose you could parse it that way if you really wanted to, but it seems
to me that the obvious meaning of this rather tortured language:
  "Whoever willfully endeavors by means of encryption to obstruct, impede, or
   prevent the communication of information in furtherance to a felony which
   may be prosecuted in a court of the United States, to an investigative or
   law enforcement officer shall..."
is "...willfully endeavoring to obstruct by means of encryption the
communication to an investigative or law enforcement officer information that
is in furtherance of a felony..."
I think no reasonable person (judge, jury or prosecutor) would interpret
it any other way.  Fortunately, the law is not a program that gets run on a
computer.  People have to interpret it.  In the case of this section, the
awkward wording is an artificat of several iterations of narrowing it from
what was originally a rather broad crime (as it still is in the House bill).
I would rather have the awkward (but still clear) wording than a broader crime.
As it stands, several lawyers whose judgement I trust have told me that this
provision is worded narrowly enough to apply only to people who can already
be conviceted of the underlying crime and who can be proven to have used encryption for the SOLE purpose of thwarting law enforcement.  I don't like
this new crime (since it still stigmatizes encryption as being something
criminals use), but I can probably live with it.
No.  Right now crypto exports fall under the State Department (which is
in the business of saying "no") unless they decide otherwise, in which case
it goes to the Commerce department (which is in the business of saying "yes").
Under the bill, for non-mass-market software and hardware, the Commerce
department must issue a license if equal strength crypto is already available
outside the country.  But the biggest win is that, under the bill, you don't
need a license from anyone in the case of mass-market (or public domain)
software (or hardware bundled with mass-market crypto software).  You
can just export it.
See the analysis of the bill in Personally, on balance, I think the bill, as written, is a big
enough step forward to be worth supporting.

@_date: 1996-03-11 08:40:22
@_author: Matt Blaze 
@_subject: Lawz to be. 
While I don't agree with some of the conclusions you reached in your note,
I certainly agree that the Leahy bill would be better for cryptography
without this crime.  I hope that section gets further narrowed (or removed
altogether), but based on discussions I've had with various Senate staffers,
I'm not optimistic that it will be.
If you feel strongly about this, I urge you to lobby your Senators
(and representatives, since there's also a House version of the bill) and
tell them exactly what you like and don't like about this legislation, as
I am doing with mine.

@_date: 1996-05-24 13:05:19
@_author: Matt Blaze 
@_subject: [SCARE]: "If you only knew what we know..." 
I don't think I actually got "the breifing", if any such standard briefing actually exists.  What Sameer is probably thinking of is that the seven
authors of the "key length report" were invited down to DC to talk with a
bunch of high-level policy types, but they never showed us the bodies (or
the files on us, or whatever it is they show the people who they really want
to impress).
[NB, please send any reply directly to me; I don't read the list with any
regularity these days, and saw this message only because someone mentioned
it.  thanks.  -matt]

@_date: 1996-09-20 02:46:35
@_author: Matt Blaze 
@_subject: 1997 USENIX Technical Conference info 
USENIX 1997 ANNUAL TECHNICAL CONFERENCE
January 6-10, 1997, Anaheim, California
Co-Located with:
USELINUX:  Linux Applications Development & Deployment Conference
Co-Sponsored by Linux International and the USENIX Association
PROGRAM AT A GLANCE AND IMPORTANT DATES TO REMEMBER
Early Registration Savings Deadline: November 22, 1996
Hotel Discount Deadline: December 20, 1996
Registration		4:00pm - 9:00pm
Kickoff Reception	6:00pm - 9:00pm
Registration	7:30am - 5:00pm
Tutorials	9:00am - 5:00pm
Registration	7:30am - 5:00pm
Tutorials	9:00am - 5:00pm
Birds-of-a-Feather Sessions	6:00pm - 10:00pm
Registration		7:30am - 6:00pm
Keynote Address		9:00am - 10:30am
Technical Sessions	11:00am - 5:00pm
USELINUX Developers 	9:00am - 5:30pm
Vendor Display		12:00am - 7:00pm
USELINUX Case Studies	7:30pm - 11:00pm
Birds-of-a-Feather Sessions	7:30pm - 11:00pm
Registration		7:30am - 6:00pm
Technical Sessions	9:00am - 6:00pm
USELINUX Developers	9:00am - 5:30pm
Vendor Display		10:00am - 4:00pm
Birds-of-a-Feather Sessions	6:00pm - 10:00pm
USELINUX Case Studies	6:00pm - 10:00pm
Technical Sessions	9:00am - 5:45pm
USELINUX Business	9:00am - 4:00pm
NEW AT ANAHEIM:
USELINUX, the Linux Applications Development and Deployment
Conference, co-sponsored by Linux International and USENIX.
If you are:
An application developer porting or developing Linux applications,
a system admininistrator having to maintain Linux systems,
a business person who wishes to develop a Linux business,
plan to attend USELINUX.  One fee covers the registration for both
conference programs, and you can go freely back and forth between
them. (Tutorials carry a separate fee for both USENIX and USELINUX).
TUTORIAL PROGRAM 	
Monday-Tuesday, January 6-7, 1997
Register now to guarantee your first choice - seating is limited.
Tutorial fees include printed and bound tutorial materials from your sessions, lunch, CD-ROM with Tutorials, Referreed Papers, and Invited Talks, Admission to the Vendor Exhibits
TUTORIAL OVERVIEW
Monday, January 6
M1:  Beginning Perl Programming for UNIX Programmers (Updated for      Perl 5)
M2:  The Kerberos Approach to Network Security (Updated). M3:  An Introduction to Java
M4:  Secure Java Programming
M5:  Windows NT and Windows 95 - The Win32 API
M6:  UNIX Network Programming
M7:  Selected Topics in System Administration (New)
M8:  How Networks Work - The Limits of Modern Internetworking (Updated)
M9:  System and Network Performance Tuning (New)
M10:  Inside the Linux 2.0 Kernel (New)
Tuesday, January 7
T1:  UNIX Security Tools: Use and Comparison.
T2:  CGI and WWW Programming in Perl (New)
T3:  Security on the World Wide Web (New)
T4:  Creating Effective User Interfaces (New)
T5:  Java Applets and the AWT (New)
T6:  Setting Up And Administering A Web Server (New)
T7:  Security for Software Developers: How to Write Code that
     Withstands Hostile Environments (New)
T8:  Solaris System Administration (New)
T9:  IP version 6: An Introduction
T10:  Writing Device Drivers Under Linux (New)
COMPLETE TUTORIAL DISCRIPTIONS
Are available on our Website, TECHNICAL PROGRAM	
Wednesday-Friday, January 8-10, 1997
TECHNICAL SESSIONS
WEDNESDAY, JANUARY 8
Opening Remarks: John Kohl, Pure Atria Corporation
Keynote Address: Developing on "Internet Time"
James Gosling, Sun Microsystems
REFEREED PAPERS
11:00-12:30:  PERFORMANCE I
Embedded Inodes and Explicit Grouping: Exploiting Disk Bandwidth for
Small Files
  Gregory R. Ganger and M. Frans Kaashoek, Massachusetts Institute of
  Technology
Observing the Effects of Multi-Zone Disks
  Rodney Van Meter, Information Sciences Institute, University of
  Southern California
A Revisitation of Kernel Synchronization Schemes
  Christopher Small and Stephen Manley, Harvard University
2:00-3:30:  INTERFACE TRICKS
Porting UNIX to Windows NT
  David G. Korn, AT&T Research
Protected Shared Libraries - A New Approach to Modularity and
  Arindam Banerji, John M. Tracey, and David L. Cohn, University of
  Notre Dame
A Novel Way of Extending the Operating System at the User-Level: the
Ufo Global File System
  Albert D. Alexandrov, Maximilian Ibel, Klaus E. Schauser, and Chris
  J. Scheiman, University of California, Santa Barbara
4:00-5:00:  CLIENT TRICKS
Network-aware Mobile Programs
  Mudumbai Ranganathan, Anurag Acharya, Shamik Sharma, and Joel Saltz,
  University of Maryland
Using Smart Clients to Build Scalable Services
  Chad Yoshikawa, Brent Chun, Paul Eastham, Amin Vahdat, Thomas
  Anderson, and David Culler, University of California, Berkeley
THURSDAY, JANUARY 9
9:00-10:30:  CLUSTERING
Building Distributed Process Management on an Object-Oriented
  Ken Shirriff, Sun Microsystems Laboratories
Adaptive and Reliable Parallel Computing on Networks of Workstations
  Robert D. Blumofe, University of Texas, Austin and Philip A.
  Lisiecki, Massachusetts Institute of Technology
A Distributed Shared Memory Facility for FreeBSD
  Pedro A. Souto and Eugene W. Stark, State University of New York,
  Stony Brook
11:00-12:30:  TOOLS
Libcdt: A General and Efficient Container Data Type Library
  Kiem-Phong Vo, AT&T Research
A Simple and Extensible Graphical Debugger
  David R. Hanson and Jeffrey L. Korn, Princeton University
Cget, Cput, and Stage  Safe File Transport Tools for the Internet
  Bill Cheswick, Bell Laboratories
2:00-3:30:  WORKS IN PROGRESS
FRIDAY, JANUARY 10
9:00-10:30:  USER SOMETHING
WebGlimpse - Combining browsing and searching
  Udi Manber, Michael Smith, and Burra Gopal, University of Arizona
Mailing List Archive Tools
  Sam Leffler and Melange Tortuba, Silicon Graphics
Experience with GroupLens: Making Usenet Useful Again
  Bradley N. Miller, John T. Riedl, and Joseph A. Konstan, University
  of Minnesota
11:00-12:30:  PERFORMANCE II
Overcoming Workstation Scheduling Problems in a Real-Time Audio Tool
  Isidor Kouvelas and Vicky Hardman, University College London
On Designing Lightweight Threads for Substrate Software
  Matthew Haines, University of Wyoming
High-Performance Local-Area Communication With Fast Sockets
  Steven H. Rodrigues, Thomas E. Anderson, and David E. Culler,
  University of California, Berkeley
2:00-3:30:  CACHING and STASHING
An Analytical Approach to File Prefetching
  Hui Lei and Dan Duchamp, Columbia University
Optimistic Deltas for WWW Latency Reduction
  Gaurav Banga, Fred Douglis, and Michael Rabinovich, AT&T Research
A Toolkit Approach to Partially Connected Operation
  Dan Duchamp, Columbia University
4:15-5:45:  JOINT CLOSING SESSION
Severe Tire Damage's Stupid Mbone Tricks - A Lecture/Demonstration
INVITED TALKS
WEDNESDAY, JANUARY 8
11:00-12:30:  Nomadicity and the IETF
  Charles E. Perkins, IBM T.J. Watson Research Center
2:00-3:30:  If Cryptography Is So Great, Why Isnt It Used More?
  Matt Blaze, AT&T Research
4:00-5:00:  The Inktomi Web Search Engine
  Eric Brewer, University of California, Berkeley
THURSDAY, JANUARY 9
9:00-10:30:  The AltaVista Web Search Engine
  Louis Monier, Digital Equipment Corporation
11:00-12:30:  IPv6: The New Version of the Internet Protocol
  Steve Deering, Xerox Palo Alto Research Center
2:00-3:30:  Highlights from 1996 USENIX Conferences and Workshops
4:00-5:30:  Inferno
   Rob Pike, Bell Labs
FRIDAY, JANUARY 10
9:00-10:30:  Measuring Computer Systems: How to Tell the Truth with              Numbers
  Margo Seltzer and Aaron Brown, Harvard University
11:00-12:30:  Stupid Net Tricks
  Bill Cheswick, Bell Laboratories
2:00-3:30:  Finding Bugs in Concurrent Programs
  Gerard J. Holzmann, Bell Laboratories
USELINUX PROGRAM
USELINUX DEVELOPERS
WEDNESDAY, JANUARY 8
9:00-10:30:   Linux: What It Is and Why It Is Significant
  Mark Bolzern, Work Group Solutions
  Tom Miller, X Engineering Software Systems
11:00-12:30:   The Sparc Port of Linux
  David S. Miller, Rutgers CAIP
  Miguel de Icaza, Instituto de Ciencias Nucleares, Ciudad
  Universitaria, Universidad Nacional Autonoma de Mexico
2:00-3:30:  Advanced Device Drivers
  Alessandro Rubini, Universita di Pavia
4:00-5:00:  Future of the Linux Kernel
  Linus Torvalds, Helsinki University
THURSDAY, JANUARY 9
9:00-10:30:  Real Time
  Victor Yodaiken and Michael Barabanov, New Mexico Institute of
  Technology
11:00-12:30:  /proc
  Stephen Tweedie, Digital Equipment Corporation
11:00-12:30:  The Pluggable Authentication Modules (PAM) Framework
  Ted Tso, Massachusetts Institute of Technology
2:00-3:30:  Standards
  Heiko Eissfeldt, Unifix Software
4:00-5:30:  Connecting Legacy and Open Systems
  Michael Callahan, Stelias Computing, Inc.
USELINUX BUSINESS
FRIDAY, JANUARY 10
9:00-9:30:  Linux: What It Is and Why It Is Significant
  Mark Bolzern, Work Group Solutions
  Tom Miller, X Engineering Software Systems
9:30-10:30:  Linux and Distribution Channels: Ways to Enter the              Commercial Market
  Dan Rosenberg, Stromian Technologies
11:00-12:30:  Using Linux in Your Business: A Business Justification
  Presented by Linux International
2:00-4:00:  The Linux Market: Who, What, Where, When and Why?
  Presented by Linux International
USELINUX PRESENTATIONS AND CASE STUDIES DESCRIPTIONS
WEDNESDAY, JANUARY 8, 7:30pm - 11:00pm
The Use of Linux for Dedicated Systems
  Chel van Gennip, HISCOM BV
Perceptions: A Strategic Deployment of Linux in the Health Care
  Greg Wettstein, Velocity LLC
The Future of the Linux Desktop
  Ken Apa, Governors State University; Jim Fetters, Chicago   Mercantile Exchange; Joe Sloan, Toyota Motor Sales USA
The Classroom of the Future
  Karl Jeacle, Broadcom Eireann Research Ltd.
THURSDAY, JANUARY 9,	6:00pm - 10:30pm
Using GNUstep to Deploy User Applications
  Scott Christley, NET-Community
Embedded, Turnkey and Real Time
  Phil Hughes, Linux Journal
Developing Linux-based Electronic Markets for Internet Trading
  Paul J. Brewer, Georgia State University
VENDOR EXHIBITION
Wednesday, January 8,   Noon - 7:00pm
Thursday, January 9   10:00am - 4:00pm
If you cannot make it to the conference but would like to visit the
exhibition, please contact Cynthia Deno, Exhibit Coordinator, at
408-335-9445 or cynthia at usenix.org.
The USENIX 97 Exhibition offers:
"Two days of exposure to the cream of the UNIX User Community."
-Neil Groundwater, Enterprise Management Group, SunSoft, Inc.
Please contact:
Cynthia Deno, Exhibit Co-ordinator
Tel: 408-335-9445
Fax: 408-335-5327
cynthia at usenix.org
GENERAL CONFERENCE INFORMATION
Birds-of-a-Feather Sessions (BoFs)
Tuesday, Wednesday, and Thursday evenings
Do you have a topic that youd like to discuss with others?
Birds-of-a-Feather sessions may be perfect for you. BoFs are
interactive, informal gatherings for attendees interested in a
particular topic. Schedule your BoF in advance. Call the Conference
Office at 714.588.8649 or send email to conference at usenix.org.
Topics are announced at the conference. BoFs may also be scheduled
The Guru is IN
Have a question thats been bothering you? Try asking a USENIX guru!
Noted experts from the USENIX community will be available to spark
controversy and answer questions. Please contact the Invited Talks
Coordinators via email to ITusenix at usenix.org if you would like to
volunteer your expertise.
Works-in-Progress Reports
Short, pithy, and fun, Works-in-Progress Reports (WIPs) introduce
interesting new or ongoing work. If you have work to share or a cool
idea not quite ready to be published, a WIP Report is for you! You
will receive insightful feedback. We are particularly interested in
presenting student work. WIPs are scheduled within the technical
sessions program. To reserve a slot, send email to wips at usenix.org.
Topics are announced on-site.
CONFERENCE SERVICES
Terminal Room
Internet and dial-out access are provided in the Terminal Room.
The Terminal Room will be open throughout the conference week. Look for details posted to comp.org.usenix.
Attendee Message Service
Electronic message service will be available Monday, January 6
through Friday, January 10. Electronic messages to conference
attendees should be addressed: first_lastname at conference.usenix.org.
HOTEL AND TRAVEL INFORMATION:
Hotel Discount Reservation Deadline:
Friday, December 20, 1996
USENIX has negotiated special rates for conference attendees at the Anaheim Marriott. Contact the hotel directly to make your
reservation. You must mention USENIX to get the special rate. A
one-night room deposit must be guaranteed to a major credit card. To
cancel your reservation, you must notify the hotel at least 24 hours
before your planned arrival date.
Anaheim Marriott
700 West Convention Way
Anaheim, CA 92802
Toll Free: 800.228.9290
Phone: 714.750.8000
Reservation Fax: 714.750.9100
Room Rates:	$107/Single, $117/Double
(plus local taxes, currently at 15%)
Need a Roommate?
Usenet facilitates room sharing. If you wish to share a room, post
to and check comp.org.usenix.roomshare.
Discount Airfares and Car Rentals
Special discounted air fares and car rentals are available only
through JNR, Inc., a full service travel agency. All restrictions
apply. Please call JNR for details. Call toll free 800.343.4546 in
the USA and Canada or telephone 714.476.2788.
STUDENT STIPENDS AND DISCOUNTS
TUTORIALS: A limited number of seats in each tutorial are reserved
for full-time students at the very special rate of $70.00 per
tutorial. To take advantage of this, you must telephone the
conference office to confirm availability and make a reservation.
You will receive a reservation code number which must appear on your
registration form. Your registration form with full payment and a
photocopy of your current student ID card must arrive within 14 days
from the date of your reservation. If they do not arrive by that
date, your reservation will be canceled. This special fee is
TECHNICAL SESSIONS: USENIX offers a discount rate of $75 for
technical sessions for full-time students. You must include a copy
of your current student I.D. card with your registration. This fee
is not transferable.
STIPENDS: Student stipends are available to pay for travel, living
expenses and registration fees to enable full-time students to
attend this conference. To apply for a stipend, read comp.org.usenix
six to eight weeks before the conference, visit our Web site,
 or contact Diane DeMartini (diane at usenix.org)
for more information.
To obtain descriptions concerning the tutorials and technical
sessions, and full conference information, please contact USENIX via any one of the following methods:
* Visit our Website, URL:  * Send email to our mailserver at: info at usenix.org
  Your message should contain the line:  send usenix97 conferences
* Contact:	USENIX Conference Office, USENIX ASSOCIATION The USENIX Association brings together the community of engineers,
system administrators,  scientists, and technicians working on the
cutting edge of computing. Its technical conferences are the essential
meeting grounds for the presentation and discussion of the most
advanced information on new developments in all aspects of advanced
computing systems.
==========================CUT HERE================================
REGISTRATION FORM - USENIX 1997 TECHNICAL CONFERENCE
                    January  6-10, 1997, Anaheim, California
Please complete the form below and return with full payment to:
USENIX CONFERENCE OFFICE
22672 Lambert St., Suite 613, Lake Forest, CA 92630
Telephone: (714) 588-8649 / FAX Number (714) 588-9706
Electronic Mail Address:  conference at usenix.org
Office Hours: 8:30am - 5:00pm Pacific Time
         (first)                                 (last)
FIRST NAME FOR BADGE____________________________
USENIX Member ID____________________
COMPANY OR INSTITUTION______________________________________________
MAILING ADDRESS_____________________________________________________
TELEPHONE NO:_________________________FAX NO._________________________
NETWORK ADDRESS______________________________________________________
                          (one only please)
The address you provide will be used for all future USENIX
mailings unless you notify us in writing.
ATTENDEE PROFILE
Please help us serve you better.  By answering the following
questions, you help us plan our activities to meet members'
needs.  All information is confidential.
[ ] I do not want to be on the attendee list
[ ] I do not want my address made available for other than USENIX
    mailings
[ ] I do not want USENIX to email me notices of Association activities.
What is your affiliation? [ ]academic  [ ]commercial  [ ]gov't  [ ]R&D
What is your role in purchase decision?
1.[] final  2.[] specify  3.[] recommend 4.[] influence 5.[] no role
What is your job function? (check one)
1.[] system/network administrator    2.[] consultant 3.[] academic/research   4.[] developer/programmer/architect 5.[] system engineer    6.[] technical manager  7.[] student
8.[] security  9.[] webmaster
How did you hear about this meeting:
1.[] USENIX brochure 2.[] newsgroup/bulletin board 3.[] ;login:  4.[] World Wide Web  6.[] from a colleague  7.[] magazine
What publications or newgroups do you read releated to advanced computing systems?_____________________________________________
TUTORIAL PROGRAM Select only one full-day tutorial per day - 9:00am-5:00pm
Monday, January 6, 1997
[ ] M1:  Beginning Perl Programming [ ] M2:  Kerberos Approach to Network Security
[ ] M3:  Introduction to Java
[ ] M4:  Secure Java Programming
[ ] M5:  Windows NT and Windows 95
[ ] M6:  UNIX Network Programming
[ ] M7:  Topics in System Administration
[ ] M8:  How Networks Work
[ ] M9:  System and Network Performance Tuning
[ ] M10: Inside the Linux 2.0 Kernel
    Second Choice of first is filled:____________________________
Tuesday, January 7, 1997
[ ] T1:  UNIX Security Tools
[ ] T2:  CGI and WWW Programming in Perl
[ ] T3:  Security on the Web
[ ] T4:  Creating Effective User Interfaces
[ ] T5:  Java Applets and the AWT
[ ] T6:  Setting Up and Administering a Web Server
[ ] T7:  Security for Software Developers
[ ] T8:  Solaris System Administration
[ ] T9:  IP version 6
[ ] T10: Writing Device Drivers Under Linux
    Second Choice of first is filled:____________________________
TUTORIAL PROGRAM FEES (January 6-7)
TECHNICAL SESSION FEES
        (Applies to current USENIX, EurOpen national
                                         -Check here [ ]
   	student I.D.
                       TOTAL ENCLOSED...................$_________
PAYMENT MUST ACCOMPANY THIS FORM.  Payment in US Dollars must accompany this form.  Purchase orders,
vouchers, telephone or email registrations cannot be accepted.  [ ] Payment Enclosed (Make check payable to USENIX Conference)
CHARGE TO MY:  ___VISA ___MASTERCARD ___AMERICAN EXPRESS ___DINERS CLUB
ACCOUNT NO.______________________________________ EXP. DATE___________
 Print Cardholder's Name                 Cardholder's Signature
You may fax your registration form if paying by credit card to USENIX Conference Office, fax:  714-588-9706.  (To avoid duplicate billing, please DO NOT mail an additional copy.)
REFUND CANCELLATION POLICY:  If you must cancel, all refund requests must be in writing and postmarked no later than December 27, 1996.  Telephone cancellations cannot be accepted.  You may telephone to substitute another in your place.

@_date: 1997-06-27 15:02:01
@_author: Matt Blaze 
@_subject: Better DES challenge update 
The prize for solving the ``better DES challenge'' has grown to almost
$500 and continues to rise daily.  Here's the list of prize pledges I have
as of June 27; the current pot stands at 3984 bits (US $498.00).  I hope
to have a web page up sometime next week (on  with the
latest challenge status.  (This will be the last update via email, unless
someone solves the challenge or pledges some huge prize or some such).
DATE	Name			Email				Bits Pledged
6/22/97	Matt Blaze		mab at crypto.com			56 bits
6/23	AT&T Labs (via mab)	mab at research.att.com		56
6/24	Steve Gibbons		steve at wyrm.AZTech.Net		56
6/24	Bill Stewart		stewarts at ix.netcom.com		112
6/24	Peter Trei		trei at process.com		288
6/24	Jim Thompson		jim at hosaka.SmallWorks.COM	512
6/25	Adam Shostack		adam at homeport.org		512
6/25	Eric Blossom		eb at comsec.com			1024
6/26	Jamie Lawrence		jal at acm.org			56
6/26	Bill Frantz 		frantz at netcom.com		512
6/27	Jon Leonard		jleonard at divcom.umop-ap.com	800
GRAND TOTAL (Bits)						3984
GRAND TOTAL (USD)						$498.00
Tell your friends!  Note that the pot seems to be growing roughly
exponentially.  If this keeps up, I may join the search myself...
[Unfortunately, due to singularly inexcusable incompetence on the part
of my soon-to-be-former ISP (PSINet), mail to me was bouncing last week
so I may have missed some of the ``Better DES Challenge'' pledge mail.
If you pledged a prize and aren't on the list above, please resend.]
Official rules attached below for reference.
- -matt
N.B.  The ``bit'' is an archaic unit of currency equal to 1/8 of a US
dollar (hence, ``pieces of eight,'' ``two bits,'', etc.).  It seems an
appropriate measure for prizes in key-cracking contests.
I'm not a big fan of these ``challenges'' in which a prize is awarded
to the first person who discovers the key that produces some
plaintext/ciphertext pair.  The effort required to produce a solution
tends to grossly overstate the actual difficulty of searching the
keyspace, since invariably the winner uses the idle time on
general-purpose computers, which are poorly-optimized for use as
keysearch engines.
Another problem with challenges is that even when they are broken
they don't really provide convincing proof that the keyspace was
actually searched.  For example, in the recent 56-bit RSA DES
challenge, RSA has no way to prove that it didn't ``leak'' some hint
about the solution to the winner. (I hasten to point out that I'm not
suggesting that anything like this actually happened, only that a
skeptic might raise the possibility, against which RSA has no real way
to defend itself).  A better challenge, then, would be one in which
even the challenger doesn't know the solution in advance (or would
have had to itself search the keyspace or otherwise cryptanalyze the
cipher in order to find it).  For example, a challenge for a one-way
collision-intractable hash function could simply ask for an example of
a collision, or could ask for the inversion of some well-structured
output (such as all zeros).
We can do the same thing for encryption functions.  I propose an
alternative DES challenge that can be solved only by searching a large
fraction of the keyspace or by cryptanalyzing the cipher.  The
structure of the challenge is such that most people would agree that
either I don't know the solution myself or that I've already searched
the keyspace or otherwise cryptanalyzed DES in some way.  In other
words, the only way I could covertly ``help'' the challenge winner is
if I've already done what the challenge is supposed to establish is
possible in the first place.
Recall that there are 2^56 DES keys that each select a different
permutation of the 2^64 codebook entries.  We expect that there's
about a 1/2^8 chance that there exists a DES key that converts any
given plaintext block to any given ciphertext block.
My challenge is to find a key such that a ciphertext block of the form
 decrypts to a plaintext block of the form , where
X and Y represent any fixed eight-bit byte value repeated across each
of the eight bytes of the block.
Observe that I'm actually posing 2^16 different challenge
plaintext/ciphertext pairs, each with about 1/2^8 probability of
having a solution, where groups of 2^8 challenges can be searched for
simultaneously.  Each challenge may have no solution key, exactly one
solution key, or more than one solution key, but it is very likely
that there is at least one solution key to at least one of them (in
fact, one could expect to find about 2^8 solutions overall, assuming
DES produces good pseudorandom permutations).
The most obvious way to find a solution is try, for each
properly-formed ciphertext block, every key in the DES keyspace until
a plaintext block of the proper form is found.  Special-purpose
hardware, based on FPGAs or ASICs, would obviously be helpful for this
purpose.  (One might first consider the eight weak / semi-weak DES
keys that have 2^32 fixed points, on the chance that one of the blocks
of this form is a fixed point for one of them.  Unfortunately however,
none are.)
I will award a grand prize of fifty six bits ($7 US dollars) to the first
person to provide a solution key.  (The challenge ends when first key
is found).  While the prize money is admittedly trivial (this is out
of my own pocket, after all), I hope it will serve as ``seed money''
that encourages others to add their own prizes to a growing pot.
Of course, I cannot be completely sure whether there exist any
solutions at all.  In the (unlikely) event that there is no winner by
August 1, 1999, I will award the 56 bit prize to the person who submits
the key that produces the most ``interesting'' plaintext block from
the all-zero ciphertext block.  I will be the final judge of what
constitutes interesting.  This prize will be announced at the rump
session of CRYPTO'99.
Void where prohibited by law, etc.  Comments, questions and solutions
should be submitted by email, to .  If others wish
to pledge additional prizes, please also let me know at that address
and I'll keep track of who is offering what, etc..
- -matt
------- End of Blind-Carbon-Copy

@_date: 2007-07-07 02:17:30
@_author: Matt Blaze 
@_subject: Debugging the Greek wiretapping scandal 
Vassilis Prevelakis and Diomidis Spinellis just published (in IEEE  Spectrum) a
terrific technical analysis of the recent Greek cellular  eavesdropping scandal.
It's available online at
     In 2005, it was reported that over a hundred Athens cellphones,  mostly belonging
to politicians (ranging from the mayor to the prime minister), were  illegally wiretapped. The culprit hasn't been found, but there's  plenty of
fodder for speculation, including mysteriously missing records,  suspicious suicide,
and, as Prevelakis and Spinellis point out, an intriguing  technological mystery.
The case dramatically illustrates the real-world risks of incorporating
"lawful intercept" interfaces into network infrastructure; they  become inviting
targets for abuse.
I comments further on my blog, at
    Archives: RSS Feed: Powered by Listbox:

@_date: 2008-12-27 14:21:14
@_author: Matt Blaze 
@_subject: Domestic surveillance and warrantless wiretaps 
Like many people, I found last week's Newsweek cover
piece, revealing Thomas M. Tamm as the principal source
for James Risen and Eric Lichtblau's 2005 NY Times story
that broke the warrantless wiretap story, to be a riveting
But I actually found a sidebar to the story even more
interesting. That story talks about the now famous 2004
incident at Ashcroft's hospital bed in which several
top DoJ officials threatened to resign. It turns out
that was not about warrantless content  collection,
but rather about the wholesale collection of call
  This story raises a number of new -- and ultimately
quite disturbing -- questions about the nature of the
wiretap program and the extent of its reach into the
domestic communication of innocent Americans.  In
particular, put together with other reports about the
program, it seems to corroborate claims that telcos
(including my alma matter AT&T) provided the NSA with
wholesale access to domestic call detail records, and
that top DoJ officials worried seriously that this
violated the law.
I discuss the implications of this in more detail on
my blog; perhaps some here will find it interesting:
