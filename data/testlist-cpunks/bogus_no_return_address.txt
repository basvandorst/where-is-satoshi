
@_date: 1994-10-02 16:13:04
@_author: Underdog 
@_subject: Technical Remailer Analysis. 
Hal Writes:
This raises a fundamental problem with current remailers. It is clear that
next generation remailers will have to encrypt all messages sent between
them, on top of any nested encryption of the message done by the
Timothy C. May Writes:
If the remailers also batched messages to a given destination, or padded
outgoing messages before encrypting them, they would be far less
susceptible to this kind of attack. Re-encrypting the message with padding
(to some standard size) would prevent attackers from recognizing their own
messages in a flood attack, except by noting destination (which could be a
giveaway). Batching would do the same, but would also hide the number of
messages trashed or locally delivered. Neither of these does much against
the concerted "spam attack". I think in the end, remailers will need to run
something like encrypted links, sending a constant volume of data between
them, which would be random garbage when not a real message. This leaves
open the denial of service attack of sending more data per hour then the
link supports, therefore causing long queues at the remailers. Sigh, I
really need to get down to a library and dig up the Chaum articles I hate
to always reinvent the wheel.
While waiting for good digital postage, a substitute could be used. If one
added a "Msg-ID:" header similar to the Ghio remailer's "Cutmarks", which
contained a large random number, this number could be stored at the
remailer, and messages with the same ID simply send to /dev/null. This
would be simple to do with remailer chaining scripts like "premail".
Since I assumed that a typical user sends one message per day, Alice may
draw attention to herself through this mechanism. 10 messages is not
enough, it would leave some correlation. Alice needs to send at least one
message per tick (e.g. 48 in my example), in which case she shown 100%
correlation with all recipients always. There is no way to know that she is
sending to Bob, but I suspect she will be on a short list at the FBI unless
everyone else is doing the same (which violates my assumptions). If
everyone sent a message every tick, traffic analysis would be impossible.
I do not think that the "everyone is a remailer" idea works. At the assumed
one message per day, and an average message chain of 5 remailers, then only
5% of users can maintain remailers with a real traffic flow of 100 messages
per day. Other than that, this idea is functionally similar to Hal's.
Sending messages on to bit buckets is a nice idea. Assuming cutmarks, or
standard message sizes, and reordering are used, this is indistinguishable
from a remailer which just delivers the local mail, and also sends out
periodic junk messages to various bit buckets. As I mentioned in my
original message, this should be done anyway to ensure  complete mixing of
all messages within the web during any given tick.
                -Louis Cypher

@_date: 1994-10-02 20:32:58
@_author: Underdog 
@_subject: Nom de guerre public key 
With a pseudonym, all a signature really says is that this is the key that
always goes with the posts signed by this nym.  Assuming there has not been
more than one key claiming to be the "real" nym, then after a while there
can be no doubt that the key and nym go together (which is all that was to
be proved). Personally, I sign nyms that have existed consistently for some
time. I have never distributed any of these signed keys, but see no harm in
doing so as long as the key's user-id field clearly indicates that the key
is a nym and not a person. A sig on a key by a notable like Tim May would
help keep new users from getting taken in my some interloper claiming to be
Pr0duct Cypher.
If I am trying to maintain a truly anonymous pseudonym, I am hardly likely
to allow to connect my key with an email address. All a sig on a
pseudonym's key means, is that is the key which signs posts from that nym,
not such a hard thing to demonstrate with enough empirical evidence.
                -Louis Cypher
P.S. I can be reached privately by leaving a message in
alt.anonymous.messages with my name in the subject line.

@_date: 1994-10-04 13:57:52
@_author: Underdog 
@_subject: A practical use of c'punk brain power. 
Greetings c'punks!
  I have an Excel 4.0 spreadsheet to which I do not have the password.
Do any of you know a clever way to break the Excel protection either
by divining the password or removing the layer of encryption in the
  Any help is appreciated!

@_date: 1994-09-30 21:35:32
@_author: Underdog 
@_subject: Technical Remailer Analysis. 
Yow, I have been trying to send this for a week!
BTW, yes I am using the bug to add this note.
In this message I will analyze message reordering in remailers, and
traffic analysis in remailer webs.
Remailers which immediately resend incoming messages provide no security against an attacker who is able to watch all traffic to and from the remailer.  Two proposals have been suggested to solve this problem, latency and reordering.  In recent discussions, the consensus was that message reordering was superior to (and the actual intent of) latency.  Reordering is not sufficient, a form of latency is required to make it effective.
In this analysis, I assume that the reordering is accomplished by keeping a group of n messages at the remailer, and sending a random one whenever a new message comes. This is superior to simply waiting for n messages to arrive, then sending them all at once (I will show this later).
The attack on the reordering remailer is simple. The attacker sends a stream of marked messages through the remailer.  After the waiting messages have been flushed out, any incoming real message will be flushed out of the remailer before more arrive, allowing it to be uniquely identified coming and going.  The defense against this is to only check the group and send excess messages after a time delay. This delay should be the typical time for n real messages to arrive. A mixing of approximately n messages is ensured by this process. If there is no attack, then the mixing is not quite as good as keeping a group of 2n messages.
Here is the math on the reordering schemes:
1) Wait for n messages, then mix and send them all.
2) Keep a group of n messages. Send one of the n+1 when a new one prob that the message has not been sent after x messages is (n/n+1)^x
Prob that it has been sent = 1 - (n/n+1)^x
Messages till 90% prob:  x=ln(.1)/ln(n/n+1)
For n=10, x=24, which is much better then 10 for scheme 1.
3) Accumulate b messages, then send a of them (Scheme 2 is a=1, b=n)
  x = ln(.1)/(ln(a) - ln(b))
  This gives the largest x  for a=1.
  In my example of how to defend against the flood attack, a=n, b=2n
  x = 33
  This is misleading, because it will introduce twice the delay as   scheme 2.
  Given the same delay, a=n/2, b=n, one finds that x=16.6
  That is better than batching, but not as good as scheme 2. The   smaller x is
  worth it, because a reordering of at least some minimum number of
  messages is ensured.
Some writer proposed changing n randomly to protect against this attack. Obviously that would not work. The attack will consist of many many more than n messages.
The second issue for consideration is:
Given a web of perfect remailers, how easy is it to identify corespondents? Tim has been asking this one for a while.
I assume that there is sufficient traffic through all remailers that any message entering the web could be any message leaving the web. This can be achieved, even with light traffic, by sending fake messages through the web to bit buckets. While they do not improve the security of the web as a whole, they help ensure that no tracking of messages within the web is possible, forcing it to be treated as a black box.
I assume that no correspondents are remailers themselves, and that all communications are random (random times with random people). This assumtion that all communications are uniformly distributed is terrible but....
This analysis only applies to indistinguishable messages. Each standard packet size can be thought of as having its own black box (a good argument for message splitting and having only one packet size).
To simplify the problem, I am going to treat the web as though it were clock driven. Some number of messages enter and leave the web each "tick" with no messages staying in the web between ticks.  This is a reasonable approximation, with the "tick" being the mean time of passage through the web.
Define "f" as the fraction of remailer using population sending a message in a given tick. This is also the probability that any individual will send a message in a given tick. The probability of a given pair of corespondents in a given tick is
The probability of a pair of corespondents occurring m times in n ticks is
        m
p= 1 - Sum [(f^2)^i (1 - f^2)^(n-i) n! / (i! (n-i)!)]
       i=0
Lets put some numbers in there. If people send 1 message per day on average, and one tick is 30 min., then f=1/48. If you watch the web for a month you will see 1440 ticks. If the chance probability of your sending m messages to your co-conspirator  is too small then you have been nabbed.
The condition for that is: p << (1/population)
The results for m=0 to 12 (using the above numbers) are:
m = 0   	p = 4.64811E-1
m = 1   	p = 1.30173E-1
m = 2   	p = 2.56257E-2
m = 3   	p = 3.86587E-3
m = 4   	p = 4.71498E-4
m = 5   	p = 4.81967E-5
m = 6   	p = 4.23687E-6
m = 7   	p = 3.26538E-7
m = 8   	p = 2.23961E-8
m = 9   	p = 1.38336E-9
m = 10  	p = 7.77044E-11
m = 11  	p = 4.00273E-12
m = 12  	p = 1.91774E-13
So, for a remailer using population of 10,000 you had better send less than 5 messages per month to your accomplice.  This only gets worse the longer you keep it up. You can not send 4 per month, month after So, that is enough typing for one night. I hope this will staunch the RC4 legality debate for a few seconds.
Summoned from Elsewhere:
Here is my key:
