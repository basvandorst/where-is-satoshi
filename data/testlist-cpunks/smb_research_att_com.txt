
@_date: 1993-08-11 09:52:20
@_author: smb at research.att.com 
@_subject: Numeric IP address for ftp.eff.org? 
The dig output explains what's going on.
In other words, ftp.eff.org is an alias for the official name of
the host.  Quite properly, the inverse map lists the official name
for the host:
But by advertising the name ``ftp.eff.org'', instead of ``kragar.eff.org'',
the administrator gains the flexibility to move the archive to some
other machine if necessary/desirable.  That's exactly the right way
to run such a service.

@_date: 1993-08-11 12:52:22
@_author: smb at research.att.com 
@_subject: How long would it take? 
Indeed.  The key length is a worst-case analysis for the cryptanalyst;
they can do no worse than that.  We can be confident that NSA has cracked
DES because an exhaustive search engine is within their means, but we
don't know how much better they can do.
A while back, Shamir gave a talk on differential cryptanalysis here at
Murray Hill.  He mentioned Coppersmith's letter, which said that IBM
knew about differential cryptanalysis back when they built DES, and they
designed it to resist the attack.  That's obviously the case -- so Shamir
said that he asked Coppersmith to state that in the intervening 18 years,
IBM had not come up with a stronger attack on DES.  Coppersmith was
silent, from which you can draw any conclusions you wish.

@_date: 1993-08-11 17:12:05
@_author: smb at research.att.com 
@_subject: Clipper trapdoor? 
You raise a valid point.  I think there are several possible answers.
First, of course, since the key escrow mechanism has not yet been
established, an exception could be written into the procedures.  (And
whether they would be established by law or executive order remains to
be seen.)  There might be some clause saying, ``NSA may have access to
escrowed keys, provided that they certify that the targets of their
surveillance are foreign powers, as defined in the FISA.  If, upon
decryption, it is determined that a U.S.  citizen's conversations have
been intercepted, the procedures of the FISA for such eventualities
will apply.''  Yes, they could abuse such a clause -- but by that
logic, they could be listening in to cleartext domestic phone calls
today.  (And of course, there have been such abuses.)
A second possible answer is for export phones to come from a separate
production run, using a different family key.  These would be
export-only, and you'd never get a license to export a ``secure''
model.  For U.S. residents to make an encrypted phone call to such a
site, either they, too, would need such a phone, or they need some way
to interoperate with a phone with a different family key.  The obstacle
there is the verification procedures such phones have, to guard against
bogus narc headers being inserted.  I'm not certain whether or not such
a solution can be found.

@_date: 1993-08-12 13:58:13
@_author: smb at research.att.com 
@_subject: Secure voice software issues 
Real timing measurements would help, but it's not just the V.42bis
algorithms.  A year or two ago, I did some measurements on a number
of different modems.  I saw large -- and sometimes unacceptable -- delays
even without V.42 or MNP in use.  My methodology was to enable loopback
at various points -- hardware loopback plugs, local loopback on my
modem, remote loopback or a plug at the far end, etc.  I sent single
characters, and timed how long they took to show up.  The modems
seem to either buffer up several characters, or have to wait a while
before sending the first one, but the delays appeared to be for the
first character in a ``bunch'' (``packet'' is too strong a word).

@_date: 1993-08-12 19:08:16
@_author: smb at research.att.com 
@_subject: CA online legislative database access 
Agreed.  Let me put the issue in technical terms:  you want a government
with hysteresis.  Call hysteresis the antidote to hysteria.
The concept, if not the word, was well known to Jefferson et al.
In fact, that was the reason that Senators serve six-year terms, and
are elected at staggered intervals.  Why?  Well, there was an Op-Ed column in the NY Times recently that
explained it quite well -- the instantaneous reaction of the public
to certain kinds of events (like shooting up Iraqi missle batteries,
or starting a war) is quite noticeable.  Was George Bush really doing
a much better job the day after Desert Storm started than the day before?
A substantial portion of the American people seemed to think so.
No, I'll pass.  Our current system of government is far from perfect.
But a switch to direct democracy (the technical term for what you Lance
Dettweiler proposes) is not the answer.  (Want more evidence -- look
at the effects of the referendum and initiative process, especially
in California.  While it can -- and has -- acted as a check on government,
a vast number of propositions have been passed that reflect either
well-financed advertising campaigns or a desire to decree magic.)

@_date: 1993-08-13 07:12:58
@_author: smb at research.att.com 
@_subject: Spooking of neural nets and image recognition... 
Well -- the cameras may have been prompted by the fact that the
toll booths at the GWB have been the targets of armed robberies
several times of late...
Most?  Hardly.  Don't forget the bridges and tunnels from Brooklyn and
Queens, and the two tunnels from New Jersey, and...

@_date: 1993-08-18 08:35:42
@_author: smb at research.att.com 
@_subject: The Zen of Anonymity 
However, under certain circumstances the owner of a facility can be
held liable for not removing libelous graffiti.  I picked up a paper
from the net some time back (/telecom-archives/sysops.libel.liability
on ftp.lcs.mit.edu, ``Defamation Liability of Computerized BBS
Operators & Problems of Proof'', by John R. Kahn) which discusses that
point.  The judgement is context-dependent -- one court noted that
different standards apply to a New York subway car [sic] than to the
interior of a manufacturing plant -- but the general rule is that if
you know of some defamatory graffiti on your property, you're obligated
to remove it.

@_date: 1993-08-18 16:55:50
@_author: smb at research.att.com 
@_subject: World record in password checking 
But DES-cracking and password-cracking are almost completely decomposable;
no co-ordination is necessary after you've sent the ciphertext string and
the starting point for the search. Sure -- if you want a machine that does nothing but.
Well, there's been an interesting thread on rec.woodworking about hurling
strange things with medieval siege engines...

@_date: 1993-08-26 13:05:48
@_author: smb at research.att.com 
@_subject: Source Code NOT available for ViaCrypt PGP 
That rule applies to RSAREF, and not necessarily to anything else.

@_date: 1993-08-29 05:43:57
@_author: smb at research.att.com 
@_subject: Examination of ViaCrypt's PGP by members of this group 
No, there is an important difference:  you'd be starting from known-
good source.  That might make the task feasible.
That doesn't mean it's easy, of course.  A fair number of years ago, I
participated in a review of some code which had been developed, in
part, by someone who was later convicted of assorted {h,cr,chr}acking-
related offenses.  There was far too much source code to check it all;
however, we knew when this person had first had access, so we could use
diff on many modules.  That tremendously reduced the scope of the
effort.  We did find one curious construct -- a combination of two bugs
that together constituted a security hole.  Either alone was harmless.
And to this day, I don't know if they were inserted deliberately.

@_date: 1993-12-07 12:25:26
@_author: smb at research.att.com 
@_subject: W.Diffie on RSA patent 
It sounds like you're talking about the Davida patent, or maybe the
zero-knowledge proof patent.
Here's the basic story.  U.S. patent law contains a provision for
``secrecy orders''.  That is, when you apply for a patent in certain
sensitive areas -- and cryptography is one of them -- the application
is routed to the appropriate government agencies, including NSA.  If
they think the invention is too good, you'll receive a notice saying
that you not only can't get a patent, you're not even allowed to discuss
it anymore.
George Davida -- a professor -- was hit with just such an order.
Eventually, it was lifted, after a lot of public protest.  NSA tried
claiming that the patent application proved that the issue was
commercial, rather than pure free speech, but they didn't try to fight
More recently, Shamir received a secrecy order on his zero-knowledge
proof patent.  This was even more insane than usual, since (a) Shamir
is not a U.S. citizen, and (b) he'd already been discussing the idea
at conferences world-wide.  According to rumor, this order was imposed
by the Army, and was lifted through NSA's intervention.
I know that the Shamir story was in the NY Times, though I don't have
the citation.  A pointer in my files is:
but I don't have the article handy.  The Davida story was probably
in the Times as well; my summary of it is taken from ``Cryptology
Goes Public'', by David Kahn, in ``Kahn on Codes'', 1983.  The article
originally appeared in the Fall 1979 issue of ``Foreign Affairs''.

@_date: 1993-12-14 03:53:52
@_author: smb at research.att.com 
@_subject: Sun secure RPC 
Yup.  The modulus is too small, and the key exchange was cryptanalyze
by LaMacchia and Odlyzko.  See
   author = {Brian A. LaMacchia and Andrew M. Odlyzko},
   journal = {Designs, Codes, and Cryptography},
   pages = {46--62},
   title = {Computation of Discrete Logarithms in Prime Fields},
   volume = {1},
   year = {1991},

@_date: 1993-12-16 17:45:44
@_author: smb at research.att.com 
@_subject: Inman vs. crypto 
Bobby Inman has just been nominated as the new secretary of defense.
When he was director of NSA, he was not, as I recall, particularly
sympathetic to private-sector cryptography.  In fact, he tried to
institute a review process for civilian cryptographic papers.
His nomination is subject to confirmation by the Senate, after review
by the Armed Services committee.  While in my opinion it's unlikely
that his nomination will be blocked, the hearings would be an excellent
time to question him on this subject.  Contact your senator (this is
for U.S. residents only, of course...), especially if he or she is
a member of that committee.

@_date: 1993-12-18 05:46:40
@_author: smb at research.att.com 
@_subject: Writable CD-ROMS as one-t 
Or your enemy has to penetrate your site or your correspondent's site,
and copy five CD-ROMs instead of one.
CD-ROMs have one advantage:  there's a lot of data.  But that's not
all good, because you *really* want to destroy any keying material
you've ever used.
I've heard People Who Know say that in the spook and government world,
one-time pads are falling out of favor --- because their practical
security isn't as good as a really high quality conventional cipher with
a dynamically-negotiated session key.  I repeat:  *practical* security;
your enemy isn't going to hit you or bribe you with a copy of Shannon's

@_date: 1993-12-21 07:49:32
@_author: smb at research.att.com 
@_subject: Writable CD-ROMS as o 
In a reasonably secure setup, any of these things are *HARD* (to use your
word).  But there's no such thing as absolute security; at best, you
can balance relative risks.
Have you overwritten it beyond recovery by sophisticated agents?  What if
the CD-ROM is compromised before you us it?
Again -- there's no such thing as ``right''.  There is only relative risk.
Bob Morris Sr. once observed that the real lesson of ABSCAM was not that
politicians are bribable -- we all knew that -- but that he could afford
one.  And if a U.S. Senator costs $50K, what does the janitor cost?
Look at the Walker family spy ring -- not that they sold out for money,
but just how little money they cost!  You're talking about your home
machine?  Sure -- how resistant is your house to a black-bag job pulled
off by professionals?  With one-time pads on CD-ROM, they only have to
win once to capture your future traffic for a very long time to come.
With something like a STU-III, there's *nothing* that can be captured
that will give that sort of information.  The risk there is cryptanalysis
of the underlying system -- but maybe NSA knows enough about cryptosystems
that they think that that risk is very low -- lower, at any rate, than
the risks of one-time pads.
Remember that the goal is not fancy cryptography.  The goal is information
security; crypto is just one tool to help achieve that.  Your enemy
isn't going to be sporting and attack where your defenses are.  The
proper response to a strong security barrier is not to go through it,
but to go around it.
Let me suggest that folks read
It's an extremely important paper.  I'll quote the beginning of
Section 4:

@_date: 1993-07-13 08:13:10
@_author: smb at research.att.com 
@_subject: new crypto standard to be announced 
Today's NY Times says that Novell and a bunch of other companies (including
AT&T, but I haven't been able to track down any details yet) *and*
the British Ministry of Defense are going to announce a new crypto
standard.  The article indicated that RSA and DES were going to be
used, and portrayed the announcement as a rebuff to Clipper.

@_date: 1993-07-14 11:36:49
@_author: smb at research.att.com 
@_subject: Secure comm program, Sockets + LINK 
RAM, actually.  The phones are keyed for some set of individuals;
these keys are tied to ``crypto ignition keys'' possessed by these
individuals.  When you insert your key, the phone knows who you are,
and transmits a certificate containing your public key to the far
end.  Other information in the certificate includes your security
clearance, and (I think) your name.  On some models at least, the
key storage can be erased instantly by pressing a single button.
The uses for that feature are obvious...
I highly commend this paper to the cypherpunks readership:
   author = {Whitfield Diffie},
   journal = {Proceedings of the IEEE},
   month = {May},
   number = {5},
   pages = {560--577},
   title = {The First Ten Years of Public Key Cryptography},
   volume = {76},
   year = {1988}

@_date: 1993-07-15 17:30:10
@_author: smb at research.att.com 
@_subject: The right to be secure (fwd Computerworld article) 
There are safeguards in the law; whether they're adequate or not is
open to discussion.  But it's not nearly as easy as you portray.
Warrantless wiretaps are governed by the provisions of 50 USC 1801, the
Foreign Intelligence Surveillance Act.  Under that act, the Feds can
engage in electronic surveillance without a warrant if and only if all
parties are non-Americans.  If an American is picked up, they have to
destroy the tape.  Furthermore, under many circumstances (and I don't
remember the details, and I don't seem to have a copy of that law in my
folder for such things), the consent of a special court is needed.
As I said -- they (or should that be ``They'') *can* do anything.  But
that doesn't make it legal, which was your question, and if they do it
and are caught, the case will undoubtedly be thrown out of court.
Furthermore, if the tap didn't fall under the exceptions of the FISA,
it's barred by the ECPA, so you could sue for damages.

@_date: 1993-07-17 15:39:49
@_author: smb at research.att.com 
@_subject: Diffie Hellman 
Any decent book on cryptography should explain it.  The idea was
originally proposed in
   author = {Whitfield Diffie and Martin E. Hellman},
   journal = {IEEE Transactions on Information Theory},
   month = {November},
   pages = {644--654},
   title = {New Directions in Cryptography},
   volume = {IT-11},
   year = {1976}
The basic idea is simple.  Pick a large number p (probably a prime),
and a base b that is a generator of the group of integers modulo p.
Now, it turns out that given a known p, b, and (b^x) mod p, it's
extremely hard to find out x.  That's known as the discrete log problem.
Here's how to use it.  Let two parties, X and Y, pick random numbers
x and y, 1 < x,y < p.  They each calculate
and transmit them to each other.  Now, X knows x and (b^y) mod p, so
s/he can calculate (b^y)^x mod p = (b^(xy)) mod p.  Y can do the
same calculation.  Now they both know (b^(xy)) mod p.  But eavesdroppers
know only (b^x) mod p and (b^y) mod p, and can't use those quantities
to recover the shared secret.  Typically, of course, X and Y will
use that shared secret as a key to a conventional cryptosystem.
The biggest problem with the algorithm, as outlined above, is that
there is no authentication.  An attacker can sit in the middle and
speak that protocol to each legitimate party.
One last point -- you can treat x as a secret key, and publish
(b^X) mod p as a public key.  Proof is left as an exercise for
the reader.

@_date: 1993-07-18 17:43:51
@_author: smb at research.att.com 
@_subject: recomendations for intro books 
The best thing would be to look at the sci.crypt FAQ.

@_date: 1993-07-18 21:23:53
@_author: smb at research.att.com 
@_subject: Diffie-Hellman Weakness Weakness 
The AT&T Telephone Security Device (you know, the beast with the Clipper
chip...) has a display that shows a few digits of a hash of the key.
Each party reads off some of it to the other; the idea is that an
intruder won't be able to spoof a voice in real-time.
For data connections, have a look at
   author = {Ronald L. Rivest and Adi Shamir},
   journal = {Communications of the ACM},
   number = {4},
   pages = {393--395},
   title = {How to Expose an Eavesdropper},
   volume = {27},
   year = {1984}
The idea is to send half of an encrypted block.  You then await a
half-block from the far side, at which point you send your other
half, and listen for the far side's other half.  The idea is that
since one can't decrypt a half-block, the intruder in the middle
can't send a fraudulent one.
Depending on how this scheme (known as the ``Interlock Protocol'')
is used, it may be vulnerable to attack.  Davies and Price, in their
(excellent) book ``Security for Computer Networks'', suggest sending
passwords that way.  But Mike Merritt and I showed how to attack
that scheme under certain circumstances.  (Details to appear in
IEEE Transactions on Information Theory.)

@_date: 1993-07-19 18:19:08
@_author: smb at research.att.com 
@_subject: ANON: AP story 
I'd like someone to provide some statute citations or some case law to
back this up.  As I read the ECPA, nothing in it prevents an employer
from looking at employee files.  (Admittedly, the government may be
different.)  The following quote is from
        title =         {{ECPA} and Online Computer Privacy},
        author =        {Ruel Torres Hernandez},
        journal =       {Federal Communications Law Journal},
        volume =        41,
        number =        1,
        month =         {November},
        year =          1988,
        pages =         {17--41}
I should note that the ECPA also explicitly permits monitoring ``as may
be necessarily incident to ...  the protection of the rights or
property of the provider of that service''.
Again, if anyone has hard citations to the contrary, I'd really like to
know.  In the case that has drawn the most attention, the Epson email
case, the claim was based on a state law that protects employee telephone
calls.  From what I've read, the judge rule against the plaintiff on
the grounds that only voice calls were protected.  That ruling was
apparently not appealed, probably because there was little chance that
that holding would be overturned.

@_date: 1993-07-20 17:54:25
@_author: smb at research.att.com 
@_subject: subliminal messages 
Or your Capstone keys, during certificate exchange.

@_date: 1993-07-21 12:25:55
@_author: smb at research.att.com 
@_subject: Remailers/PayPhones and Today's NYT 
Well, the article said that some of the phone store operators raised
the issue, often defensively.  Even if the reporter didn't know about
the issue beforehand, they sure knew after that.  Also note that part
of the market for such stores is that NY Telephone has cut off some
payphone service in certain areas, thereby sensitizing the reporter
to such questions.

@_date: 1993-07-21 18:14:52
@_author: smb at research.att.com 
@_subject: more on FBI credit search access 
I already looked at the article.  It didn't say much.  But I tend
to agree with Shari Steele's explanation, and in fact posted a
similar analysis to comp.org.eff.talk.  Here's what I said:

@_date: 1993-07-24 17:22:44
@_author: smb at research.att.com 
@_subject: Remailers/PayPhones and Today's NYT 
A lot of the issue isn't drug dealers using payphones, it's credit card
fraud.  Ask yourself what hurts phone companies in their bottom lines.

@_date: 1993-07-26 04:16:19
@_author: smb at research.att.com 
@_subject: Secured E-mail standard? 
This won't fly for several reasons. First, X- implies a non-standard header.  Second, in the Internet world
PEM is on the standards track, and it uses a PGP-like encapsulation.
(More precisely, many facets of the PGP appearance were taken from PEM.)
PEM does provide for various security mechanisms, I should note, not
just the current RSA+DES.  Finally, the scheme which you label ``distracting''
(and I agree) was adopted because there's simply too much information
to put into headers in any comprehensible fashion, and to really
do the job properly requires an encoded (and hence unreadable) plaintext
of the message, independent of the encryption or signature algorithms.
(These folks worried, and rightly so, about character sets, gateways
that would add or drop trailing blanks or tabs, etc.)

@_date: 1993-06-01 00:41:32
@_author: smb at research.att.com 
@_subject: Electronic Contracts 
Digital signatures on contracts are probably legal.  I did some checking
on the subject a while back; someone forwarded me the following official
opinion from the U.S. Controller General.  The specific reasoning applies
only to the U.S. government, but most of the principles generalize.
I'll add one note of my own -- from what I've read lately of the
Federal rules of evidence, printouts of data recorded on disk, tape,
etc., are considered to be equally original, as it were.
A reference I haven't checked is Benjamin Wright, ``The Law of Electronic
Commerce- EDI, Fax, and Email: Technology, Proof, and Liability''.  It is a
1991 book published by Little Brown and Co., 1991.
United States General Accounting Office  [Comptroller General]
DATE:     June 19, 1991
TO:       Assistant Director, AFMD/ASA - John C. Martin
FROM:     Assistant General Counsel, OCG/AFMD -
            Thomas H. Armstrong
This responds to your request for our opinion regarding
whether agencies can use Electronic Data Interchange (EDI)
technologies to create valid contractual obligations that can
be recorded consistent with 31 U.S.C. (s) 1501 (section 1501).
For the reasons stated below, we conclude that they can.
EDI is the electronic exchange of business information between
parties, usually via a computer, using an agreed upon format.
EDI is being used to transmit shipping notices, invoices, bid
requests, bid quotes and other messages.  Electronic
contracting is the use of EDI technologies to create
contractual obligations.  EDI allows the parties to examine
the contract, usually on video monitors, but sometimes on
paper facsimiles, store it electronically (for example on
magnetic tapes, on discs or in special memory chips), and
recall it from storage to review it on video monitors,
reproduce it on paper or even mail it via electronic means.
Using EDI technologies, it is possible for an agency to
contract in a fraction of the time that it now takes.  The
"paperless" nature of the technology, however, has raised the
question of whether electronic contracts constitute
obligations which may be recorded against the government.
Section 1501 establishes the criteria for recording
obligations against the government.  The statute provides, in
pertinent part, as follows:
     "(a) An amount shall be recorded as an obligation of
     the United States Government only when supported by
     documentary evidence of--
          (1) a binding agreement between an agency
          and another person (including an agency)
          that is--
               (A) in writing, in a way and
               form, and for a purpose
               authorized by law. . . ."
31 U.S.C. (s) 1501(a)(1)(A).
Under this provision, two requirements must be satisfied:
first, the agreement must bind both the agency and the party
with whom the agency contracts; second, the agreement must be
in writing.
Binding Agreement
The primary purpose of section 1501(a)(1) is "to require that
there be an _offer_ and an _acceptance_ imposing liability on both
parties."  39 Comp. Gen. 829,831 (1960) (emphasis in
original).  Hence the government may record an obligation
under section 1501 only upon evidence that both parties to the
contract willfully express the intent to be bound.
A signature traditionally has provided such evidence.
_See_ _generally_ 65 Comp. Gen. 806, 810 (1986).  Because of its
uniqueness, the handwritten signature is probably the most
universally accepted evidence of an agreement to be bound by
the terms of a contract. _See_ 65 Comp. Gen. at 810.  Courts,
however, have demonstrated a willingness to accept other
notations, not necessarily written by hand.  _See_, _e.g._,
_Ohl_&_Co._v._Smith_Iron_Works_, 288 U.S. 170, 176 (1932)
(initials); _Zacharie_v._Franklin_, 37 U.S. (12 Pet.) 151,
161-62 (1838) (a mark); _Benedict_v._Lebowitz_, 346 F.2d 120
(2nd Cir. 1965) (typed name); _Tabas_v._Emergency_Fleet_
_Corporation_, 9 F.2d 648, 649 (E.D. Penn. 1926) (typed, printed
or stamped signatures); _Berryman_v._Childs_, 98 Neb. 450,
153 N.W. 486, 488 (1915) (a real estate brokerage used
personalized listing contracts which had the names of its
brokers printed on the bottom of the contract in the space
where a handwritten signature usually appears).
As early as 1951, we recognized that a signature does not have
to be handwritten and that "any symbol adopted as one's
signature when affixed with his knowledge and consent is a
binding and legal signature."  B-104590, Sept. 12, 1951.
Under this theory, we approved the use of various signature
machines ranging from rubber stamps to electronics encryption
2                                                      B-238449
devices.  _See_ 33 Comp. Gen. 297 (1954); B-216035,
Sept. 20, 1984.  For example, we held that a certifying
officer may adopt and use an electronic symbol generated by an
electronic encryption device to sign vouchers certifying
payments.  B-216035, _supra_.  The electronic symbol proposed
for use by certifying officers, we concluded, embodied all of
the attributes of a valid, acceptable signature:  it was
unique to the certifying official, capable of verification, and
under his sole control such that one might presume from its
use that the certifying officer, just as if had written his
name in his own hand, intended to be bound.
EDI technology offers other evidence of intent to be bound
with the same attributes as a signature--for example, a
"message authentication code," like that required by the
National Institute of Standards and Technology (NIST) for the
electronic transmission of data._1_/  In our opinion, this form
of evidence is acceptable under section 1501.
A message authentication code is a method designed to ensure
the authenticity of the data transmitted; it is a series of
characters that identifies the particular message being
transmitted and accompanies no other message.  As envisioned
by NIST's Federal Information Processing Standard (FIPS)
113,_2_/ a message authentication code could be generated when
the sender inserts something known as a "smart card"_3_/ into a
system and inputs the data he wants to transmit.  Encoded on a
circuit chip located on the smart card is the sender's key.
_1_/  The Congress has mandated that NIST (formerly the National
Bureau of Standards) establish minimum acceptable practices
for the security and privacy of sensitive information in
federal computer systems.  Computer Security Act of 1987,
Pub. L. No. 100-235, (s) 2, 101 Stat. 1724 (1988).
_2_/  FIPS 113 adopts American National Standards Institute
(ANSI) standard X9.9 for message authentication.  It outlines
the criteria for the cryptographic authentication of
electronically transmitted data and for the detection of
inadvertent and/or intentional modifications of the data.
By adopting the ANSI standard, FIPS 113 encourages private
sector applications of cryptographic authentication; the same
standard is being adopted by many financial institutions for
authenticating financial transactions.
_3_/  A smart card is the size of a credit card.  It contains
one or more integrated circuit chips which function as a
3                                                      B-238449
The key is a secret sequence of numbers or characters which
identifies the sender, and is constant regardless of the
transmission.  The message authentication code is a function
of the sender's key and the data just loaded into the system.
After loading his data into the system, the sender notifies
the system that he wants to "sign" his transmission.
The system sends the data first to the chip on the smart card;
the chip then generates the message authentication code by
applying a mathematical procedure known as a cryptographic
algorithm.  The card returns the data along with the just-
generated message authentication code to the system, which
will transmit the data and code to the recipient.
When a contracting officer notifies the system that he wants
to sign a contract being transmitted to a contractor, he is
initiating the procedure for generating a message
authentication code with the intention of binding his agency
to the terms of the contract.  The message authentication code
evidences that intention, as would a handwritten or other form
of signature.  The code, incorporating the sender's key, is
unique to the sender; and, the sender controls access to and
use of his "smart card," where his key is stored.  It is also
verifiable.  When the recipient receives the contract, either a
notation identifying the message authentication code and the
sender, usually by name.  The recipient can verify its
authenticity by putting the data that he just received into
his system and asking his system to generate a message
authentication code.  That code should match the one
annotating the message received._4_/
To constitute a valid obligation under section 1501(a)(1)(A),
a contract must be supported by documentary evidence
"in writing."  Some have questioned whether EDI, because of
the paperless nature of the technology, fulfills this
requirement.  We conclude that it does.
Prior to the enactment of section 1501, in the Supplemental
Appropriations Act of 1955,_5_/ the was no "clean cut
definition of obligations."  H.R. Rep. No. 2266, 83rd Cong.,
2d Sess. 50 (1954).  Some agencies had recorded questionable
obligations, including obligations based on oral contracts, in
_4_/  For the sake of simplicity, this example does not describe
the complicated system of controls used to ensure that no
human knows the keys that are used to generate message
authentication codes.
_5_/  Pub. L. No. 663, 68 Stat. 800, 830 (1954)
4                                                      B-238449
order to avoid withdrawal and reversion of appropriate funds.
_See_ 51 Comp. Gen. 631, 633 (1972).  Section 1501 was enacted
not to restrict agencies to paper and ink in the formation of
contracts, but because, as one court noted, "Congress was
by asserting oral contracts."  _United_States_v._American_
_Renaissance_Lines_, 494 F.2d 1059, 1062 (D.C. Cir.), _cert_.
_denied_, 419 U.S. 1020 (1974).  The purpose of section 1501 was
to require that agencies submit evidence that affords a high
degree of certainty and lessens the possibility of abuse.
_See_ H.R. Rep. No. 2266 at 50.
While "paper and ink" offers a substantial degree of
integrity, it is not the only such evidence.  Some courts,
applying commercial law (and the Uniform Commercial Code in
particular), have recognized audio tape recordings, for
example, as sufficient to create contracts.  _See_, _e.g._,
_Ellis_Canning_Company_v._Bernstein_, 348 F. Supp. 1212
(D. Colo. 1972).  The court, citing a Colorado statute, stated
that the tape recording of the terms of a contract is
acceptable because it is a "reduc[tion] to tangible form."_6_/
_Id_. at 1228.  In a subsequent case, the United States Court of
Appeals held that an audio tape recording of an agreement
between the Gainesville City Commission and a real estate
developer was sufficient to bind the Commission.
_Londono_v._City_of_Gainesville_, 768 F.2d 1223 (11th Cir.
1985).  The court held that the tape recording constituted a
"signed writing."  _Id_. at 1228.
In our opinion, EDI technology, which allows the contract
terms to be examined in human readable form, as on a monitor,
stored on electronic media, recalled from storage and reviewed
in human readable form, has an integrity that is greater than
an audio tape recording and equal to that of a paper and ink
contract.  Just as with paper and ink, EDI technology provides
a recitation of the precise terms of the contract and avoids
the risk of error inherent in oral testimony which is based on
_6_/  Some courts, interpreting the laws of other states, have
held that a tape recording is not acceptable.  _See_Roos_v._
_Aloi_, 487 N.Y.S. 2d 637 (N.Y. Sup. Ct. 1985), _aff'd_,
489 N.Y.S. 2d 551 (N.Y. App. Div.); _Sonders_v._Roosevelt_,
476 N.Y.S. 2d 331 (N.Y. App. Div. 1984).
5                                                      B-238449
human memory._7_/  Indeed, courts, under an implied-in-fact
contract theory, have enforced contracts on far less
documentation than would be available for electronic
contracts.  _See_ _Clark_v._United_States_, 95 U.S. 539 (1877).
_See_ _also_ _Narva_Harris_Construction_Corp._v._United_States_,
For the purpose of interpreting federal statutes, "writing" is
defined to include "printing and typewriting and _reproductions_
_of_visual_symbols_ by photographing, multigraphing,
mimeographing, manifolding, or _otherwise_."  1 U.S.C. (s) 1
(emphasis added).  Although the terms of contracts formed
using EDI are stored in a different manner than those of paper
and ink contracts, they ultimately take the form of
visual symbols.  We believe that it is sensible to interpret
federal law in a manner to accommodate technological
advancements unless the law by its own terms expressly
precludes such an interpretation, or sound policy reasons
exist to do otherwise.  It is evident that EDI technology had
not been conceived nor, probably, was even anticipated at the
times section 1501 and the statutory definition of "writing"
were enacted.  Nevertheless, we believe that, given the
legislative history of section 1501 and the expansive
definition of writing, section 1501 and 1 U.S.C. (s) 1 encompass
EDI technology.
cc:  Mr. F. Jackson
_7_/  Of course, just as with any contact or other official
document, an agency must take appropriate steps to ensure the
security of the document, for example, to prevent fraudulent
modification of the terms.  Agencies should refer to NIST
standards in this regard.  _See_, _e.g._, FIPS 113 _supra_
(regarding message authentication codes).  In addition,
agencies should refer to the GSA regulations regarding the
maintenance of electronic records.  _See_ 41 C.F.R. (s) 201-45.2.
6                                                      B-238449

@_date: 1993-06-01 18:32:28
@_author: smb at research.att.com 
@_subject: [daemon@ATHENA.MIT.EDU : FYI: White House EMail] 
Glad to hear the White House in on the net, but where's the PEM
certificate for those addressses?

@_date: 1993-06-01 22:39:22
@_author: smb at research.att.com 
@_subject: WH email petition. 
In general, petitions are a notoriously ineffective way to lobby.
That's doubly so for email versions, for obvious reasons.  Even
without that problem, an electronic petition will (rightly) be ignored
on the grounds that it represents the opinions of a small elite
minority.  With signatures collected in the streets and shopping malls
of America, you have at least some chance of reaching a cross-section
of people.  But on the net?  (And even if I'm wrong about the net's
population, would they know it?)
As for a trouble-maker list -- not likely.  Apart from the political
hell there'd be to pay if word ever leaked (the right to complain to
the government is quite explicit in the Constitution, and is legally
far stronger than the still-controversial right to privacy (remember
Bork?)), I haven't seen any evidence that broad-scale ``enemies lists''
have been collected since Nixon's day.  That may, of course, mean
they've just gotten smarter about how they do it...  Based on my past
experience, your name will be collected -- but just as a person
interested in certain issues, so that you can be solicited for funds
on certain issues.

@_date: 1993-06-03 08:58:02
@_author: smb at research.att.com 
@_subject: WH email petition. 
Does it happen?  Sure did circa 20 years ago, when individual members
of Congress had much less computing capacity.  I wrote to members of
the House Judiciary committee demanding the impeachment of a certain
unindicted co-conspirator.  Over the next few years, I received a
variety of funds solicitation letters, as some of those folks tried
to move on to bigger and better offices.  The letters invariably
spoke of the members' ``bravery and courage of conviction'' during
the Watergate investigation, and noted my interest in that subject...

@_date: 1993-06-05 14:35:14
@_author: smb at research.att.com 
@_subject: Dig. Cash Question. 
You might want to fix your mailer; according to the strict letter of
RFC822, human-readable names shouldn't contain periods unless quoted....
Anyway -- suppose that in some group, you know that a^n=b, where a
and b are members of the group, and n is an integer.  a^n indicates
the group operation iterated n times.  The discrete log problem is
recovering n, given ``a'' and a^n=b.
In some groups, this is a very hard problem.  The group most commonly
used in cryptography is the field GF(p), i.e., the field of integers
modulo p, where p is some large number, preferably a prime, and ``a''
is a ``primitive root'' of the field.  The problem is thus to find
n, given ``a'' and a^n modulo p.  Other instances of discrete log
are useful as well; NeXT, for example, uses the same basic equation
in a field over some family of elliptic curves.  Their much-ballyhooed
invention was to find a set of such curves for which the exponentiation
operation can be performed very efficiently.
Oddly enough, solving discrete log in GF(p) seems to be vaguely akin
to factoring.  p doesn't have to be a prime, but you can use smaller
numbers if it is.  Early attempts used 2^n, since that makes the
modulus operation trivial, but if you do that, you need such a large
n that it doesn't pay.  For p a prime, 512 bits is probably secure now,
though possibly not against NSA.  1024 bits is likely to be secure
forever, barring major theoretical breakthroughs.

@_date: 1993-06-05 16:06:05
@_author: smb at research.att.com 
@_subject: Dig. Cash Question. 
Well, n isn't unique even if p is prime.  Consider a=10,p=11.
10^2=10^4=10^6=10^8=10^10=1 mod 11.  You only get a maximum-length
cycle if ``a'' is a primitive root, hence the restriction I stated
in the part I deleted...
It doesn't matter that n isn't unique, though you do want a good
distribution.  Primitive roots have a maximal distribution, which is
why they're good.  But a reduction by, say, a factor of 2 doesn't
matter in practice.  (For p=11, try a=3.)  The implementation of
secure RPC in SunOS uses Diffie-Hellman (which relies on the
difficulty of the discrete log problem) with base that's not a
primitive root.  To be sure, their key exchange was cryptanalyzed,
but that's because they picked a 192-bit modulus, not because of
the exponentiation base.
If I recall correctly, if p=kq+1, for q a prime and k a small integer,
there are (q-1)/k primitive roots in GF(p).  That suggests generating
p=2q+1, p and q prime, which gives a very good density.  And checking
if a number is a primitive root is easy (again, to my recollection;
I'm not a number theorist) if you know the factorization of p-1, which
of course we do in this case.

@_date: 1993-06-08 08:45:21
@_author: smb at research.att.com 
@_subject: a great revelation from the bowels of NSA 
Well, it could be innocent; it just takes longer to get legislation
passed.  Yeah, that's it...
Of course, NSA does have another option -- they can disclose how
cheaply they can crack DES.  (That they can crack it I don't doubt; my
only question is what it costs them per solution, including
amortization of capital costs.)

@_date: 1993-06-08 11:14:44
@_author: smb at research.att.com 
@_subject: CERT: the letter from CERT to berkeley.edu admin 
Based on what you sent out, I confess that I see nothing wrong with
CERT's note.  They're right -- anonymous ftp is abused that way.  I've
seen it happen on a fair number of sites -- folks upload packages for
others to snarf.  The pattern of some of the transactions I've seen
suggests that folks are chatting anonymously via IRC or some such, and
are using third-party machines as anonymous relay points.  Other
transaction patterns suggest the creation of sub rosa archives by folks
who have no legitimate right to use the machine.  Files distributed
that way (and I'm speaking here of what I've seen personally, not just
rumors from CERT or the net) include copyrighted PC software packages.
Now -- there's a lot of room for disagreement about whether or not it's
proper to charge for software, or whether or not algorithm patents are
or should be valid.  But I suspect that most people on the list would
agree that if someone has written something that they don't want
distributed that way -- as evidenced, for example, by a copyright
notice -- their wishes should be respected.  That's common courtesy, if
nothing else.  Similarly, if you want to distribute files, use your own
machine.  Don't abuse someone else's, when you know perfectly well that
that's not a proper use of anonymous ftp.
Again -- neither CERT nor I am talking about things like RSA software.
That's a can of worms I'm not going to open in this forum.  And they're
probably not even talking about files that legitimate users are making
available.  They're talking about abuse of other folks' machines,
almost always with neither the knowledge nor the consent of the system
owner.  And the outcome is predictable; I've seen a number of cases
where anonymous ftp has been shut down, to the detriment of the entire

@_date: 1993-06-08 13:22:05
@_author: smb at research.att.com 
@_subject: CERT: the letter from CERT to berkeley.edu admin 
Law enforcement?  It's law enforcement if they do more than notify the
owner of the site.  Most such sites welcome the notifications *if* (and
it's a big ``if'') their machines are being abused by outsiders.
If CERT is going out and looking for pirated software, or if they try
to take any action to enforce their notes -- then, I do agree with both
of you; such actions are beyond their charter.  (Though one can argue
that clandestine distribution of malware would fall be an exception.  I
specify ``clandestine'' because one could entertain a reasonable
suspicion that the motives of such distributors was not purely
If you asked CERT to justify such notes, they'd probably quote the
following text from their press release on ftp.cert.org:
``User security awareness'' sounds about right.
Look -- CERT did not demand that the ftp area be shut down, they did
not threaten to cut the machine off from the Internet, they didn't (as
far as I know) turn the note over to the FBI or the Secret Service, and
they didn't mention PGP or ``dirty GIFs''.  They simply *informed* the
administrator, in a polite way, of information that that administrator
probably wants to hear.  (I've had occasion to notify various system
administrators of the same sort of thing.  They were all grateful
for the report.)  The overly-hasty  response came from Eric's end.
What the administrator's response should be if RSADSI sent a note
about PGP is another matter.  This is CERT, and they're talking about
pirated software.
Disclaimer:  I'm on friendly terms with CERT, and with a lot of the
folks who work there.  And -- as anyone who has read my papers knows --
I've sent in my share of incident and vulnerability reports.

@_date: 1993-06-08 13:53:48
@_author: smb at research.att.com 
@_subject: CERT: the letter from CERT to berkeley.edu admin 
I don't know.  The most charitable interpretation is that CERT is being
extremely careful about their own behavior, and they're not going
around probing for anonymous ftp on various sites without more than an
informant's tip that such a service is offered.  Again, though, I'm
guessing.  I do know that they're short on staff.  They certainly can't
scan the archives, and a report of a non-existent anonymous ftp area
may be sufficiently rare they they never thought to check it.
Of course you're not a raving lunatic.  Certainly, you rave at times,
but I don't think I've ever called you a lunatic...
You're right -- the coincidence, if coincidence it is, is quite odd.
I'm more disturbed by the question of how CERT got the information; a
more common report would be from an administrator who found such
unwanted deposits, and who reported to CERT what sites sent them or
retrieved them.  CERT will certainly hurt itself if it allows itself to
be used.  But if most such reports are accurate, welcomed by the
administrators, and obtained from legitimate sources, they won't have a
I'm going to stop speculating, though.  I'll send a note to various
folks at CERT (though without mentioning either cypherpunks, soda, or
anon.penet by name), and ask them what their policy is on such reports,
and in general where they come from.

@_date: 1993-06-08 13:59:09
@_author: smb at research.att.com 
@_subject: CERT: the letter from CERT to berkeley.edu admin 
It doesn't have to be.  Anyone could create ``incoming/.. '', stick
some files in it, and tell his/her friends.  The new directory would
be readable.
Again, I'm not speaking hypothetically here.  In our case, it was ..^T,
and contained pirated PC software.  (We decided not to infect those files
with viruses...  We didn't even replace them with programs that just
printed nasty messages.)

@_date: 1993-06-08 17:49:11
@_author: smb at research.att.com 
@_subject: CERT 
The paranoia is getting out of hand.  Let's take this one point by
point.  I've deleted the poster's name, because this note is just an
example; it's not the only such posting.
``You''?  Who is ``you''?  The CERT note didn't mention any
individual.  They might not have the information.  If they did, it
might be because the account was compromised.  (That was the case the
last time I helped a friend investigate ftp droppings.  In that case,
though, it was only the ftp account, not the login account, so
notifying the owner would not have been damaging.  Btw -- remember the
recent CERT advisory on bugs in the WUSTL ftpd?)
As I said before, they might not know who was involved.  Even if they
did, and even if the account wasn't compromised, it's the SA's
responsibility to investigate.  What if a local user is doing un-
authorized things?  Take this particular case -- they could easily end
up being sued for contributing to copyright infringement.  They might
win -- but defending against a lawsuit is expensive.
Check it out?  How?  Apart from the question of whether or not you want
CERT looking through your directories (and I can just hear the
complaints now -- ``On no evidence but an anonymous tip, CERT logged
in, listed everything, looked for *my* hidden areas that I used to
distribute restricted software, and tied up my link to the Internet for
hours while the downloaded everything in sight'') -- it isn't
feasible.  I just ftp'd to soda for a quick look-see.  A ls-lRa
generated 160K bytes.  Simply screening that takes time.  Many of the
files showed only numeric uid's; the ftpd passwd file was obviously not
up to date.  Even if I knew the suspect files, I might not know who the
responsible user was.  Many of the files had informative names like
``packet123.Z''.  They mirrored the full X11R5 distribution.
How much time and effort should CERT put in?!?!!  A competent SA will
at least know the putative ownership and reliability of the owner of
most of that stuff; CERT sure doesn't (except, of course, for the list
of hackers they may or may not have, and which has been (rightly)
objected to).
Confiscate?  Confiscate?  They asked for a copy, if available.
``Confiscate'' generally means ``take away''.  They're not taking
anything from you.  If the logs do show anything, it's precisely their
business -- evidence of someone abusing your system (I'm assuming here
that there really was 3rd-party deposits and retrieval of files).
Quick -- how many of those file transfers are coming from stolen
accounts?  In my experience, a goodly number.
Look, I have my own concerns about CERT in this matter, notably the
questions of what evidence they're acting on, and whether or not
they're being used (consciously or not) to silence unpopular sites.
I've sent them a note asking those questions.  But let's try to keep
things in perspective.
Oh yeah -- as an added bonus, I've enclosed a transcript of the kinds
of things I do when trying to find an administrative contact for some
machine.  I don't see any avenues of contact more likely than ``root''
or ``postmaster''.  And it's clearly a large-scale timesharing machine,
where there's no one individual clearly responsible for it.
$ whois -h rs.internic.net soda.berkeley.edu
No match for "SODA.BERKELEY.EDU".
The InterNIC Registration Services Host ONLY contains Internet Information
(Networks, ASN's, Domains, and POC's).
Please use the whois server at nic.ddn.mil for MILNET Information.
$ finger root at soda.berkeley.edu
Login: root                             Name: The Allmighty
Directory: /                            Shell: /bin/csh
Office: E238, x2-7453
Last login Mon May 31 22:17 (PST) on console
No Plan.
$ finger postmaster at soda.berkeley.edu
finger: postmaster: no such user.
$ dig mx soda.berkeley.edu
; <<>> DiG 2.0 <<>> mx soda.berkeley.edu ;; ->>HEADER<<- opcode: QUERY , status: NOERROR, id: 6
;; flags: qr rd ra ; Ques: 1, Ans: 2, Auth: 3, Addit: 8
;; QUESTIONS: ;;      soda.berkeley.edu, type = MX, class = IN
;; ANSWERS:
soda.berkeley.edu.      55780   MX      4 soda.Berkeley.EDU.
soda.berkeley.edu.      55780   MX      6 scotch.Berkeley.EDU.
;; AUTHORITY RECORDS:
Berkeley.EDU.   161050  NS      VANGOGH.CS.BERKELEY.EDU.
Berkeley.EDU.   161050  NS      VIOLET.Berkeley.EDU.
Berkeley.EDU.   161050  NS      UCBVAX.BERKELEY.EDU.
;; ADDITIONAL RECORDS:
soda.Berkeley.EDU.      55780   A       128.32.149.19
scotch.Berkeley.EDU.    55780   A       128.32.131.179
VANGOGH.CS.BERKELEY.EDU.        161050  A       128.32.130.2
VIOLET.Berkeley.EDU.    161050  A       128.32.136.22
UCBVAX.BERKELEY.EDU.    39151   A       128.32.137.3
UCBVAX.BERKELEY.EDU.    161050  A       128.32.130.12
UCBVAX.BERKELEY.EDU.    161050  A       128.32.149.36
UCBVAX.BERKELEY.EDU.    51896   A       128.32.133.1
;; Sent 1 pkts, answer found in time: 0 msec ;; FROM: inet to SERVER: default -- 0.0.0.0
;; WHEN: Tue Jun  8 20:16:07 1993
;; MSG SIZE  sent: 35  rcvd: 295
$ telnet soda.berkeley.edu 25
Connected to soda.berkeley.edu.
Escape character is '^]'.
220 soda.berkeley.edu Sendmail 5.65/KAOS-1 ready at Tue, 8 Jun 93 17:10:50 -0700
helo research.att.com
250 soda.berkeley.edu Hello research.att.com, pleased to meet you
vrfy root
250-Eric Hollander <"|/accounts/hh/remail/slocal.pl">
250-Keir Morgan 250-ERic MeHlHaFf 250-ERic MeHlHaFf <\mehlhaff>
250-Tom Holub 250-John S. Jacob 250-Matthew L. Seidl 250-Shannon D. Appel <"| /usr/local/lib/mh/slocal -user appel -verbose">
250-Sean N. Welch 250-Dan Wallach 250-Donald J. Kubasak 250-David G. Paschich 250-Adam Glass <\glass>
250 Adam Glass vrfy postmaster
250-Eric Hollander <"|/accounts/hh/remail/slocal.pl">
250-Keir Morgan 250-ERic MeHlHaFf 250-ERic MeHlHaFf <\mehlhaff>
250-Tom Holub 250-John S. Jacob 250-Matthew L. Seidl 250-Shannon D. Appel <"| /usr/local/lib/mh/slocal -user appel -verbose">
250-Sean N. Welch 250-Dan Wallach 250-Donald J. Kubasak 250-David G. Paschich 250-Adam Glass <\glass>
250 Adam Glass 221 soda.berkeley.edu closing connection
Connection closed by foreign host.
$ finger Login    Name                 Tty  Idle  Login Time   Office     Office Phone
aaron    Aaron C. Smith        qR        Jun  8 08:58 Limbo      643-7217
aaron    Aaron C. Smith       *qT        Jun  8 08:58 Limbo      643-7217
achoi    Andrew Choi           pB     3  Jun  7 18:19
appel    Shannon D. Appel      pK        Jun  8 09:57 CEA        643-5657
aswan    Andrew Swan           pW        Jun  8 17:06
calvin   Wa Pak                qe 22:11  Jun  7 18:57
cgd      Chris G. Demetriou    qf        Jun  7 22:15 278 Cory   510-642-7520
cliffwd  Cliff Draper          pe    36  Jun  8 16:30 9-204a     643-3426
cynthia  cynthia leigh haynes *pr     3  Jun  8 16:43
cynthia  cynthia leigh haynes  ps        Jun  8 16:43
deb      Debra Waldorf        *p7        Jun  8 16:20
deb      Debra Waldorf        *qg    51  Jun  8 15:27
eganloo  Egan Loo              pJ        Jun  8 16:57
eric     Eric van Bezooijen    qz  1:01  Jun  8 15:50 238E      gwh      George William Herbe  pc     1  Jun  8 14:13 238E      gwh      George William Herbe  pm        Jun  8 14:26 238E      henchiu  Henry Chiu            pR        Jun  8 17:02
ho       Kinson Ho            *q3  1:13  Jun  8 15:08 608-1 Evan 642-8290
hughes   Eric Hughes          *qm    36  Jun  8 10:34 238E      isaac    Isaac Cheng          *pE    12  Jun  8 09:51
isaac    Isaac Cheng          *qw    12  Jun  8 10:59
jenn     Jennifer Hom         *pF        Jun  8 16:52 238E       415-688-8034
jlb      Jordana Brown         pQ        Jun  8 14:45
karlht   Karl Thiessen        *pb    13  Jun  8 16:28 238 Evans  642-7453
kenji    Kenji Hubbard        *pX        Jun  8 17:08 238E      kube     Donald J. Kubasak     pU     2  Jun  8 17:05 CEA ESOC   643-7367
marco    Marco Nicosia         qI        Jun  8 15:58 238E       510-283-9587
maroo    Maroo Lieuw          *qx        Jun  8 13:33            849-9872
michelle Michelle Tisi        *qZ  5:30  Jun  8 11:34
ming     Tje Ming             *qj     9  Jun  8 15:28
ming     Tje Ming             *qO  2:17  Jun  8 13:50
mlee     Michael Lee          *pD        Jun  8 16:49
mlee     Michael Lee          *qC        Jun  8 15:52
nancy    Nancy Cheng          *pf  1:18  Jun  8 14:17
nancy    Nancy Cheng          *qV  1:53  Jun  8 13:52
payam    Payam Mirrashidi      po 19:13  Jun  7 20:54 199MD Cory 642-1297
psb      partha s. banerjee   *py  2:25  Jun  8 14:32 IBM Almade 510-649-7505
psb      partha s. banerjee   *pz  2:38  Jun  8 14:32 IBM Almade 510-649-7505
ralbers  Rick Albers          *pV        Jun  8 17:06
rmgee    Randall Gee          *pn        Jun  8 14:28
robert   Roberto Boyd         *pA        Jun  8 16:47
rsr      Roy S Rapoport       *pY        Jun  8 17:09            510-540-5535
seidl    Matthew L. Seidl      qk     1  Jun  8 10:31 238E       x2-7453
seidl    Matthew L. Seidl     *qB        Jun  8 08:32 238E       x2-7453
sfd      Scott Drellishak      pl        Jun  8 16:40 Kerr 3-202
tom      Tom Holub            *pH        Jun  8 16:53
tom      Tom Holub             pI        Jun  8 16:53
welch    Sean N. Welch        *p0        Jun  8 09:04 MTV21-122  415-336-4289

@_date: 1993-06-11 17:28:06
@_author: smb at research.att.com 
@_subject: MAIL: logging that happens on soda 
To subscribe, send mail to majordomo at greatcircle.com, with the body
of the message saying

@_date: 1993-06-12 05:02:23
@_author: smb at research.att.com 
@_subject: PKP sellout? 
It's worth remembering that for the most part, corporations don't have
ethics, they have bottom lines.  Most of PKP's objections to the DSA
were not really solid; rather, they were in defense of RSA as a profit
center.  There only two really big ones -- that DSA as originally
proposed had too small a key size, and that it doesn't provide secrecy,
only authentication.  The former has been fixed by NIST, and the latter
was a design goal.
In this case, NIST really had no choice but to deal with PKP.  Apart
from the question of the Diffie-Hellman patent -- and in my opinion,
DSA definitely did infringe on it -- the proposed algorithm was very
close to Schnorr's algorithm, which was patented, and to which PKP had
purchased the rights.  If NIST had gone ahead without making a deal
with PKP, the standard would have been tied up in lawsuits for years,
with the outcome quite uncertain.  And while that may or may not have
suited this community, it would not meet NIST's objectives.
I don't see the hand of conspiracy here; rather, I see an encouraging
trend, that the private sector is able to compete in cryptographic
competence with NSA.
I am encouraged by the pledges to allow non-commercial use -- note the
lack of any RSAREF-like interface -- and to engage in non-discriminatory

@_date: 1993-06-13 01:34:11
@_author: smb at research.att.com 
@_subject: PKP sellout = betrayal 
I'm not sure what your point is here.  It requires no conspiracy to opt
for Diffie-Hellman as a key exchange mechanism; it's simply the obvious
way to do things.  (I'm speaking professionally here; cryptographic
protocols are one of my research areas.)  The STU-III's already use
Diffie-Hellman; it's possible that the government's license for that
patent grants it broad rights for such things.  (The government does
have free use of RSA; is there any such clause with respect to Diffie-
No, PKP had no such ability.  Clipper was always a potential source of
profit to them, precisely because either RSA or Diffie-Hellman was
needed for it.  Given that they were going to make money from Clipper,
the only question was how much.  As Deep Throat said ~20 years ago,
``Follow the money''.  (Those a bit older still should recall Dow
Chemical's position on co-operating with the government.)
``Betrayal'' is a moral term.  As I said before, corporations don't
care about such things, only about bottom lines.
That some settlement about DSA would be reached was inevitable.  NIST
needed PKP's assent to go ahead with DSA.  PKP wanted to make money
from the DSA, because it extends their profitable lifetime -- the RSA
patent expires in 2001, whereas the Schnorr patent doesn't expire till
2008.  PKP only opposed DSA while they didn't own the Schnorr patent;
their other handle on DSA, the Diffie-Hellman patent, expires even
earlier (1997).
The interesting thing is the incentive to use Clipper.  That's not
something PKP cares about one way or another, compared with any sort of
widespread use of cryptography (though perhaps RSADSI does; if private
cryptography is restricted, RC2 and RC4 have much less of a market).
Obviously, NIST wanted some clause like that.  In exchange, they had to
give PKP something more.  My guess is that the hook was to grant them
exclusive world-wide licensing rights to DSA, rather than simply a cut
of the royalties.
I was unclear; I wasn't referring to the agreement at all.  Rather, I
meant that Schnorr had invented the algorithm that NIST had to have --
a signature scheme that is very efficient for smart cards, but could
not be used for secrecy.  NSA apparently didn't have anything better; I
can't believe they and NIST were unaware of Schnorr's work (though
perhaps they were unaware of the patent).  (I suppose, of course, that
NSA might have had something totally different, which they couldn't
discuss because it would open up new areas for civilian research...)
Especially given the part about reserving the right not to license to

@_date: 1993-06-13 17:08:10
@_author: smb at research.att.com 
@_subject: corporations and morality 
I stumbled on a quote that succinctly expresses what I was saying about
the lack of corporate morality.  This is the head quote from Chapter
XIX of Niven and Pournelle's ``Oath of Fealty'':

@_date: 1993-06-16 08:15:48
@_author: smb at research.att.com 
@_subject: fast des 
I don't know of any 2.4 gbps DES chips, but DEC has built a 1 gbps
chip.  They've even published a technical report on it, though I don't
have the number handy.  But there's more to know than simply the raw
First of all, most real DES chips -- i.e., those designed for
encryption, rather than brute-force cryptanalysis -- are optimized for
encrypting large blocks of data.  Key-loading is a different operation,
and that might not go nearly as fast.  Any hardware assists (i.e., DMA)
would be for the data, not for the next key to use on the same block of
Second, what does this chip cost?  If it costs, say, 10x what the DEC
chip costs, it's not cost-effective; you can build your DES-cracker
more cheaply with the slower chips.  (The DEC TR gave cost figures for

@_date: 1993-06-17 14:28:09
@_author: smb at research.att.com 
@_subject: fast des 
The DEC gigabit/second DES chip was based on the FURY VSC15K gate array
from Vitesse.  It's a gallium arsenide device.
The full paper is ``A High-speed DES Implementation for Network
Applications'', by Hans Eberle, SRC Research Report 90, DEC Systems
Research Center.  Abstracts are (apparently) online in
pub/DEC/srcabstracts.list, on gatekeeper.pa.dec.com.  You can get
hard-copy by sending email to src-report at src.dec.com.
Oh yeah -- he gives the search time as 16 days, for about $1M in DES
chips alone, without any support circuitry.  The chips are estimated
to cost $300 apiece.  His chip is well-suited for DES-cracking because
it has a separate key-loading port, so you can change the key each
cycle without slowing down the pipeline.

@_date: 1993-06-18 06:26:06
@_author: smb at research.att.com 
@_subject: RRe:  Blasting Bidzos Blather 
I repeat -- NIST had no choice, because PKP held all the patent cards.
Even if you don't believe PKP's claim to all of public-key cryptography,
both the Diffie-Hellman and Schnorr patents would most likely be infringed
by DSA.  You can argue with the specifics of the deal -- and with what
NIST gave away in order to get the Clipper exemption through -- but
they had to reach some settlement.
Btw -- the deal is *not* final; the announcement is just the start of
a 60-day comment period.

@_date: 1993-06-18 10:04:10
@_author: smb at research.att.com 
@_subject: fast des 
Probably not.  The DES-crackers are already going to be looking at a
couple of blocks, because in general, the cryptanalyst won't know the IV.
But not knowing it only affects your ability to decrypt the very next block;
you can still get the one after it.
The decrypt equation for CBC mode is
That is, without knowing the IV -- C[0] -- you can't recover P[1].
But P[2] depends only on C[2] and C[1].  If P[1] is random garbage,
you've actually made life a bit easier -- the block they can't recover
isn't important.

@_date: 1993-06-29 12:33:09
@_author: smb at research.att.com 
@_subject: Clipper vs. Russia 
According to an AP wire story, Article 23 of the draft Russian
constitution says that ``Each person has the right to secret
correspondence, telephone conversations, mail, telegraph and other
Shucks -- there goes another export market for Clipper...
Oh yeah -- the AP explains the clause by referring to the ways that
Soviet authorities used to spy on people.

@_date: 1993-06-29 20:20:52
@_author: smb at research.att.com 
@_subject: REMAIL: problems 
There are a fair number of such schemes.  The best overview is in Gus
Simmons' own chapter in ``Contemporary Cryptology:  The Science of
Information Integrity'', edited by Simmons and published last year by
IEEE Press.

@_date: 1993-05-03 04:18:11
@_author: smb at research.att.com 
@_subject: government free reign on RSA -- from whence? 
My understanding -- and I've never seen the original document, so I can
be wrong -- is that the statutes providing for grants to professors
have such provisions.  That is, barring all patents developed under
such grants could be seen as stifling private initiative.  But
permitting the inventor to retain all rights is unfair, since the
government funded the work.  Hence the compromise:  patents are
permitted in such cases, but the government gets free use.
As for the ``personal use'' question -- I've never heard of such a
thing.  The law gives gives the patent holder the right to bar others
from selling, making, or *using* the protected invention.  There is a
court ruling permitting use of patented materials for experimental
purposes; some people may be extending that.
One more word on patents.  The claim that 50% of patents are thrown out
when challenged may or may not be accurate; however, it is very
time-dependent.  Such things go in cycles, depending on the makeup of
the Supreme Court.  During, say, the 1970's, there was a substantial
component on the court that opposed the concept of patents, so many
more challenges were upheld.  I need not point out that the makeup of
the court has changed substantially in recent years; during the 1980's,
many more patents were upheld.  I've seen one or two articles
indicating that the pendulum is starting to swing back, but it's harder
to say now; most patent cases these days only go as high as the Court
of Appeals for the Federal Circuit.

@_date: 1993-05-04 15:42:26
@_author: smb at research.att.com 
@_subject: tripple des 
First, it's usually done as
The middle step is a decryption for two reasons, one of which is no
longer important for DES.  The reason that is still valid is that by
setting k1==k2, you have compatibility with other implementations that
only do single encryption.  (See the Garon and Outerbridge paper in
the July '91 Cryptologia for why you want to triple-encrypt keys...)
The second reason, no longer a concern for DES, is that it was feared
that DES might be a group.  That is, given
it was feared that there might be a third key kx equivalent to encryption
with k1 and k2.  It's recently been proved that DES is not a group.  That
is, in general there is no such kx.  Conceivably, the problem could arise
with other cryptosystems, such as Skipjack.  I haven't yet seen the proof
about DES, and I don't know how much might transfer to other DES-like
algorithms.  In any event, doing a decryption as the second operation
was thought to dodge the whole question.
Finally, even though triple encryption as I've defined it only has a key
length of 112, it's still necessary to do three operations, rather than
a simple double encryption; for the latter, there's a birthday attack
in O(2^56) time, though it does require O(2^56) space as well, making its
feasibility a bit dubious.

@_date: 1993-05-14 12:07:30
@_author: smb at research.att.com 
@_subject: Navigation Prblems and Laptops... 
According to one report (in the NY Times, I believe), SwissAir reports
one incident where the apparent interference not only stopped when
electronic devices were turned off, it resumed when the pilot gave
permission for people to start using them again.
``Documented'' is the wrong word.  There have been plenty of cases of
trouble attributed to electromagnetic interference; what's lacking is
controlled studies that demonstrate an effect, as opposed to anecdotal
evidence from the pilots of various aircraft.

@_date: 1993-05-19 12:34:02
@_author: smb at research.att.com 
@_subject: BBSs under fire! (or on fire, if BATF gets into the act!) 
It's happening again, even as we speak.  The UNC public access system
is being criticized by the local Fox TV station for providing access to
``pornography'' to kids.

@_date: 1993-05-20 12:07:01
@_author: smb at research.att.com 
@_subject: TEMPEST and other "neat stuff" 
I'd like to see the whole thing, but I don't guarantee I'll read it.
In fact, I don't believe it.
I can't speak for England or Canada, but neither statement is true about
the U.S.  Note the text of footnote [3]:
   3.	This  Note  will not  discuses  how  TEMPEST relates  to  the
The ``warrant'' requirement is precisely the point.  Spying on
individuals who have a reasonable expectation of privacy is
prohibited.  In the case of wiretaps, that was in a Supreme Court
ruling in, as I recall, 1967.  In fact, the original wiretap statute
(18 USC 2510 et seq), later amended by the ECPA, was passed (as part of
the Ombnibus Safe Streets and Crime Control Act of 1968) in direct
response to that ruling, to set forth procedures, grounds, etc., for
legal wiretaps and surveillance.  I don't have the citation handy, but
the concept was discussed clearly and at some length in Kemp v Block
(1985) 607 F Supp 1262.  A TEMPEST pickup would appear to run afoul of
the wiretap laws.  Consider the following language in 18 USC 2511(2)(f):
I'll return to the FISA later; note, though, that it and 18 USC 2510
are the *only* means by which anything resembling TEMPEST surveillance
can be performed.
The only grounds on which such intercepts can be justified, given the
language of this section, is from 18 USC 2511(3)(g):
Is TEMPTEST ``readily accessible to the general public''?  At least
since the adoption of the FCC requirements on spurious RFI, I'd tend to
doubt it.  And as I noted earlier, eavesdropping of any sort is legal
if and only if the targets have no reasonable expectation of privacy;
given that 99+% of the American public has never heard of TEMPEST, I'd
call it a fair bet that someone using a computer in a private room
does, in fact, assume that he or she has such an expectation.
The Foreign Intelligence Surveillance Act (50 USC 1801 et seq.)
specifies the conditions under which foreign agents may be subject to
surveillance.  Unless there is ``no substantial likelihood'' that an
American's conversations will be observed, an order from a special
court is needed.  Again -- for the most part, there is a requirement
for due process.
Now -- I'm certainly not going to claim that these niceties are always
observed.  But that they're ignored doesn't make them legal.
Finally, the claim that taking counter-measures against TEMPEST is
illegal strikes me as balloon juice, plain and simple.  Last I heard,
the FCC wanted you to do anything you could to reduce spurious
emissions.  True, they're not telling how sensitive their detectors are

@_date: 1993-05-21 14:26:25
@_author: smb at research.att.com 
@_subject: cypto + compression 
Actually, you've got it backwards.  A decent encryption algorithm,
including DES, generates something with very little redundancy,
and hence which cannot be compress further.
$ compress vmunix.Z
$ des -e -k foo vmunix.Z.des
des: WARNING: using software DES algorithm
$ compress vmunix.Z.des.Z
-rwxr-xr-x  1 root      1875490 Jan  7 16:59 /vmunix
$ des -e -k foo vmunix.des.Z
des: WARNING: using software DES algorithm
$ ls -l /vmunix vmunix*
-rwxr-xr-x  1 root      1875490 Jan  7 16:59 /vmunix
-rw-rw-r--  1 smb        794374 May 21 17:17 vmunix.Z
-rw-rw-r--  1 smb        794376 May 21 17:18 vmunix.Z.des
-rw-rw-r--  1 smb       1066555 May 21 17:18 vmunix.Z.des.Z
-rw-rw-r--  1 smb       2538235 May 21 17:21 vmunix.des.Z
As you can see, compressing after encrypting *increases* the size of
the file.

@_date: 1993-05-23 14:56:18
@_author: smb at research.att.com 
@_subject: Police protection 
I think because he's thinking of places like Beirut, Somalia, Bosnia,
and so on.  You know -- places without any effective central government.

@_date: 1993-05-26 12:28:43
@_author: smb at research.att.com 
@_subject: Selling Tapes ? 
This incident goes back quite a while, to the days when uucp was the
normal (and almost the only) way of getting netnews.

@_date: 1993-05-26 17:37:15
@_author: smb at research.att.com 
@_subject: VinCrypt 
Indeed.  There were a pair of papers in Cryptologia a few years ago
on ``Data Insecurity'' packages.  The author cryptanalyzed a number
of different PC-based crypto packages, and contrasted that with
the glowing advertising copy...

@_date: 1993-11-10 08:53:57
@_author: smb at research.att.com 
@_subject: Ever buy encryption software? YOU WILL! 
Disclaimer:  I'm speaking for myself, not AT&T.
I've said this before, but it's worth repeating.  For the most part,
corporations exist to make money.  They don't take moral stances.
(Aside:  I'm not saying that this is good or bad; rather, I'm saying
that it just is.)  If you offer a company a way to make money, it
will probably do it.  Unified visions, of the sort you're implying
AT&T had on encryption, are generally seen as long-term ways to make
money, i.e., if the company picks some standard, it will be easier or
cheaper to make or sell some future set of products.
In the case of Clipper, there was a clear market:  the government wanted
to buy Clipperphones.  AT&T already sells secure phones (STU-III's) to
the government; the question here (and I wasn't privy to any of the
discussions) was whether or not it would cost more to develop the phone
than the potential profits.
But Clipper isn't, and can't be, the be-all for encryption, even apart
from the moral questions.  See if you can dig up AT&T's response to the
proposed key escrow FIPS.  I suspect you'd be surprised.  I don't think
I have it handy, but it points out things like the unsuitability of
key escrow for software implementations -- and the products you describe
are exactly that.  Yes, AT&T as a company thinks that there is a market
for privacy devices.  (And it's no secret that the defense market is
drying up, due to budget cuts.)  Clipper can't fill certain market niches.
DES -- or triple DES, or IDEA, or RC2, or whatever -- can.

@_date: 1993-11-11 13:03:32
@_author: smb at research.att.com 
@_subject: Should we oppose the 
Ah -- you specify the ``northern'' U.S.  The situation in the south
was very different.  And even in the north, the Pennsylvania Railroad
was so large (they're the ones who billed themselves as ``the standard
railroad of the world) that other folks had to follow if they came near
the PRR.  It was near-monopoly that created that situation, not any
desire for co-operation.
In Europe, there are still a variety of different gauges, electrical
standards, loading gauges, etc.  (Actually, the latter two are problems
in the U.S. as well.)

@_date: 1993-11-18 04:06:24
@_author: smb at research.att.com 
@_subject: Quotable Quotes 
For whatever it's worth, I use ``this'' quoting style as well.  When you
do enough writing in troff and LaTeX (they both use it), you train your
fingers accordingly.

@_date: 1993-11-18 09:34:31
@_author: smb at research.att.com 
@_subject: hohocon 
We use challenge/response devices from the Internet:
$ telnet guard.research.att.com
Connected to guard.research.att.com.
Escape character is '^]'.
This is the new inet. Authorized use only.
Authentication Server.
Id? ches
challenge: 348201
response: d2c3f97d
TCP host name? cetus
rlogin cetus -l ches
IRIX Release 4.0.5C System V cetus.research.att.com
Copyright 1987-1992 Silicon Graphics, Inc.
All Rights Reserved.
cetus=; exit
Connection closed.Connection closed by foreign host.
$ \caption{\label{fig:hha-connect} The full text of an actual terminal

@_date: 1993-11-18 09:41:31
@_author: smb at research.att.com 
@_subject: hohocon 
The Bellcore S-Key system implements this scheme, and is, I think,
freely available.  I know that it's included in TIS's firewall toolkit:

@_date: 1993-11-19 17:11:59
@_author: smb at research.att.com 
@_subject: Privacy/Money Orders 
You can get some information on bills via telnet to locis.loc.gov,
the Library of Congress Information Service.  Here's what I found
on those two bills -- it may be possible to get more, if you know
how to work the search engine, which I don't.
ITEM 1 OF 1                    SET 1: BRIEF DISPLAY                FILE: C103
                                (ASCENDING ORDER)
1. H.R.1448: SPON=Rep Fields, C., (Cosp=34); OFFICIAL TITLE: A bill to
        establish a limit on the fee which certain persons may charge for
        cashing checks and other instruments, to require despository
        institutions to cash checks issued by the United States or a State,
        and to provide that checks drawn by the Federal Government may be
        mailed only to the personal residence or primary place of business of
        the payee, to a Federal post office box, or to a federally insured
        depository institution at which the payee holds an account.
ITEM 1 OF 1                    SET 2: BRIEF DISPLAY                FILE: C103
                                (ASCENDING ORDER)
1. H.R.3235: SPON=Rep Gonzalez, (Cosp=6); OFFICIAL TITLE: A bill to amend
        subchapter II of chapter 53 of title 31, United States Code, to
        improve enforcement of antimoney laundering laws, and for other
        purposes.

@_date: 1993-11-23 11:57:59
@_author: smb at research.att.com 
@_subject: Comments on NSA (was: "Pyrrhus Cracks RSA?") 
There was an interesting discussion on this point at the ACM Conference
on Computer and Communications Security a few weeks ago.  At the
``Festcolloquium'' in honor of Gus Simmons, someone who used to work for
NSA (his name escapes me, but I have it at home) stated that in 1963,
President Kennedy signed a memorandum calling for -- in today's
language -- the use of digital signatures for nuclear weapons command
and control.
The memo -- National Action Security Memorandum (NASM) 160 -- is
still classified.  Someone else on this list (I'll let him speak for
himself) has contacted the JFK library about it.  It may already be
going through clearance release; if not, forms have been submitted
to initiate the release process.  And there's always FOIA if that
It will be very interesting to see the memorandum when it comes out.
(Btw, it was written by Jerome Weisner, Kennedy's science advisor.)
A lot of wisdom consists of asking the right questions; if the phrasing
was right, I would tend to believe that NSA did indeed have public
key technology in the mid-60's, once they were asked to create something
with those properties.  But if that was true, why didn't Simmons himself
know of it?  He said that he learned of public key from the Martin
Gardener column in Scientific American, as I recall.  Simmons was
familiar with NASM-160, though; in fact, he was the one who supplied
the number.

@_date: 1993-11-24 11:23:17
@_author: smb at research.att.com 
@_subject: <8c> C-source for diffie-hellman? 
One more thing -- you want the base for the exponentiations to be
a generator of the subgroup.  Also, ideally the modulus should be
a prime of the form kp+1, where p is also a prime and k is a small
integer.  Your DH toolkit should include routines to generate the
base and modulus according to those criteria.
Indeed, though I've only seen some drafts; my copy of the book itself
hasn't arrived yet.

@_date: 1993-11-29 17:42:15
@_author: smb at research.att.com 
@_subject: really hiding encrypted data 
Well, the output of an additive knapsack encryption has a normal
distribution.  More precisely, if you encrypt many input values
with the same public key, the resulting output values will follow
a normal distribution.  This is because you're adding up a set
of large numbers with an apparent uniform-random distribution.
Not quite you what you asked, I realize.

@_date: 1993-10-04 03:54:38
@_author: smb at research.att.com 
@_subject: FBI on BBS operator liability (fwd) 
It's worth mentioning that that's true of Federal law, but isn't
necessarily true of state law.  For example, California Penal Code
section 502 provides for the conviction of anyone who ``knowingly and
without permission accesses or causes to be accessed any computer,
computer system, or computer network''.  Some other states have similar

@_date: 1993-10-08 04:59:24
@_author: smb at research.att.com 
@_subject: that internet security scanner 
CERT isn't that stupid.  What they said was that ISS has been posted,
and that it was likely that some folks would try to use it to break
into various systems.  Do you disagree with that statement? They also
said that you should consider running it yourself, so that you can
close the holes first.  They even gave the pointer to the directory on
UUNET where it's stored.  What good would it possibly do to delete it
on your own machine, when many thousands of other machines around the
world have copies?  Again -- CERT isn't stupid.

@_date: 1993-10-10 17:26:08
@_author: smb at research.att.com 
@_subject: Was: POISON PILL 
The reference is to the following paper:
   author = {Adi Shamir},
   journal = {Communications of the ACM},
   number = {11},
   pages = {612--613},
   title = {How to Share a Secret},
   volume = {22},
   year = {1979}
More generally, see the article on shared control systems:
        author = {Gustavus J. Simmons},
        title = {An Introduction to Shared Secret and/or Shared Control Schemes
and Their Application},
        booktitle = {Contemporary Cryptology:  The Science of Information Integr
        year = 1992,
        pages = {441--497},
        editor = {Gustavus J. Simmons},
        publisher = {{IEEE} Press}
I'm especially fond of this article:
   author = {David K. Gifford},
   journal = {Communications of the ACM},
   number = {4},
   pages = {274--286},
   title = {Cryptographic Sealing for Information Secrecy and Authentication},
   volume = {25},
   year = {1982}
since it shows how to implement a variety of access mechanisms,
including key-AND, key-OR, m-of-n, etc.
Folks who contemplate such schemes should investigate the false alarm
rate.  Most automated systems experience a much higher rate of false
triggers than true.  Of course, as described here, you'd only get one,
since your data would be gone after that...

@_date: 1993-10-11 14:16:21
@_author: smb at research.att.com 
@_subject: Breaking DES 
There are two reasons for that, one of which no longer applies.
The one that still matters is that if you set k1==k2, then the operation
is equivalent to single encryption with k1, thus providing backwards
The other reason is that it was initially feared that DES was a group.
That is, encryption with k1 and k2 might be equivalent to single encryption
with some unknown (to you and me) key k3.  But a cryptanalyst or a brute-
force cracker would neither know nor care that you double-encrypted.
It has now been proved that DES is not a group.  What isn't clear to me
is whether it's ``mostly closed'', though I suspect not.

@_date: 1993-10-11 17:16:42
@_author: smb at research.att.com 
@_subject: Breaking DES 
The decryption equation for CBC mode is
In other words, decrypt the current ciphertext block, and XOR with the
previous ciphertext block.  Note carefully: the previous ciphertext
block.  That implies that you can start at any point in the string
and do your decryption.  You don't have to know the plaintext of the
previous block to proceed, which is what you're implying.
The property of CBC mode is related to its error propagation character-
istics, which are important in some environment.  Suppose that ciphertext
block C[n] is garbled, either by a bird sitting on a phone line or by
hostile action.  That will garble two blocks of output:  P[n] and P[n+1].
(Derivation is left as an exercise for the reader.)  But P[n+2] will
be decrypted properly, since it depends on P[n+1] and P[n+2].  (N.B.
I'm deliberately ignoring insertion/deletion errors.  If those are a
concern, use CFB mode.)
In accordance with my usual habits, I'll cite an excellent reference
on how to use cipher systems, and what the properties of the different
encryption modes are:
Bruce Schneier's excellent book ``APPLIED CRYPTOGRAPHY: PROTOCOLS, ALGORITHMS,
AND SOURCE CODE IN C'' is due out next month; it covers this, too.  (I'll
forbear to cite my own book till it's nearer completion...)

@_date: 1993-10-18 11:07:15
@_author: smb at research.att.com 
@_subject: jrk@sys.uea.ac.uk (Richard Kennaway) 
I have a fairly strong bias these days towards staying out of meta-
discussions on mailing lists and newsgroups, and primarily contributing
when I have some particular expertise I can bring to bear.  I'll break
that rule now...
There's a persistent tendency on this list to confuse technical
feasibility, political feasibility, and ultimate desirability.  The
whole business about pseudonyms is a good example.
Guess what -- the ability to use pseudonyms is not new.  Yes, the Net
makes it easier, but they're far from rare in the ``real world''.  The
potential for abuse is obvious -- and that's why the government has
tried to make it harder and harder to create truly-functional aliases,
to the point of criminalizing many aspects of it.
Nor is the concept of an anoymous spending mechanism new.  We speak of
``digital cash'' for a reason -- its essential properties are modeled
on those of real cash.  Of course, when real cash became problematic
for the government, they did the obvious -- they promulgated laws and
regulations regarding what you can do with it (i.e., the rules on forms
to be filled out when leaving the country, the bank rules on large cash
transactions, etc.).
Are any of these laws 100% effective?  Or even substantially
effective?  Of course not -- but they've accomplished two things.  One,
they've raised the ante for playing certain games that the government
doesn't want played.  Two -- and probably more important -- they've
provided the government with a new weapon to use against you.  Can't
convict Al Capone of racketeering?  No problem; just charge him with
tax evasion.
So it is with the net.  When email and digital cash become social
forces in the larger community, as opposed to our electronic
subcommunity, you'll start to see more regulation.  It might not even
be purely governmental; the large companies that want to run ``the''
net have their own agendas, which concern things like large profits and
keeping the government away, and have little to do with privacy.
Remember Prodigy?  I haven't noticed that it's lacking for customers
because of their policies.  Or -- envision, if you will, an ukase that
the FCC will regulate the Internet, and that anyone who wants to
connect will have to agree to an acceptable use policy that includes
the requirement that all mail be digitally signed, both by the
individual and by the site, and that mailers enforce this requirement.
Can't happen?
Nor do I think that ``offshore data havens'' will help.  Apart from the
fact that most major governments are basically in accord on the
question of who makes the rules (them, not the people -- or did you see
any governments denouncing Clipper?  I saw lots of endorsements), there
is a potent weapon that can be used:  mandatory disconnection from the
net for any country that doesn't co-operate enough.  (Even the famed
Swiss banking system is under a lot of pressure these days on such
issues, and they and the Swiss government are co-operating a lot more
with other countries.  Wanna place any bets on creating a whole new
anonymity structure?) For that matter, international bandwidth is a
matter for diplomats as well as technicians; permission to create new
circuits will simply be withheld.  If you doubt me, try placing a call
to Cuba, or to the former USSR.  After your Nth ``circuits busy''
message, don't bother asking why the long distance carriers haven't
installed more trunks, when there's obviously a demand for them.
Certainly, there are ways around some restrictions.  The inability to
call directly between Israel and the Arab countries has bred call-
forwarders.  But to the extent that these have come to official notice
of governments that care to suppress the traffic, they've been shut
down.  This is force majeure, friends, not bits on a wire.
Cryptographic technology is an enabling mechanism for various social
changes.  It by no means makes them inevitable.  Don't delude yourself
on that; the political will to do something is more important when
various alternatives exist.  To allude to fiction again, I've heard
people cite Margaret Atwater's ``The Handmaid's Tale'' as an argument
against electronic banking and the like.  In the book, at the stroke of
a pen all women's bank accounts were cancelled.  But that's the wrong
lesson; the real issue was the governmental decision to take the
action.  And throughout the centuries, governments have had no trouble
stripping hated minority groups of their assets, without any need for
If you want a Brave New Digital World, it isn't sufficient to build the
tools.  You also have to convince people that it's a good idea.  Oh,
the online world is coming; no doubt about that.  But people have to
be convinced that privacy and the like is in their interests, that
it will solve problems that *they* will have.  Equally important, they
have to be convinced that it will not create new problems, to their
perception (and the perception may have little to do with reality.
500 -- nay, 500,000 -- channels of digital information to the home
will do nothing to educate those who prefer to learn about the world
from McData Services, or from CBS/NBC/ABC/Fox/AP/UPI.  There are
myriad sources of information right now that most folks never see,
because they don't know of them, don't trust them, or just don't want
to bother.  Face it, it's easier to let someone else do the editing

@_date: 1993-10-19 01:37:23
@_author: smb at research.att.com 
@_subject: Other forms of strong cryptography 
The approach hasn't been abandoned; it's just a lot harder than it
looks, for a number of reasons.
First is that complexity theory says nothing about the average difficulty
of solving a problem, as opposed to the worst case.  A cryptosystem that
only hides 1% of the messages isn't very useful.  Second, finding
a suitable problem -- one that has a keyed back door isn't that easy.
Third -- and this is what sunk the knapsack problem -- you need a
cryptosystem that exploits the full NP-complete problem, as opposed
to just a simple case.  (The knapsack problem was solvable by someone
who knew the key because it wasn't a general knapsack, but a super-
increasing sequence -- each number in it was greater than the sum
of all of its predecessors.  (This was the simplest version; there
were, I believe, some others.))

@_date: 1993-10-26 04:40:57
@_author: smb at research.att.com 
@_subject: No subject 
I'll be there -- I'm presenting a paper.  But I don't know about BOFs
with a bunch of folks wearing masks...

@_date: 1993-10-28 11:28:08
@_author: smb at research.att.com 
@_subject: Signing our keys 
It is, of course, worth noting that the PEM specs make explicit
provisions for aliases; it's just up to some issuing agency to
decide to issue them.  And if no one wants to -- well, no one has
to sign an anXXXX address's key, either.

@_date: 1993-09-08 19:42:10
@_author: smb at research.att.com 
@_subject: Viacrypt export? 
It's not a matter of a safety blanket, it's where you choose to spend
your time and effort.  A well-supported application can easily pay
for itself in decreased staff time.

@_date: 1993-09-10 06:42:43
@_author: smb at research.att.com 
@_subject: Crack DES in 3.5 hours for only $1,500,000! 
I'll let Rivest speak for himself about NSA's influence -- but I've
spoken to cryptographers who've seen the algorithm (under
non-disclosure agreements), and they say that RC2 and RC4 are quite
strong *if* you use a long enough key.  They're algorithms with
variable-length keys, and their strength -- and not just their
resistance to exhaustive search -- is related to the key size used.
The gotcha is that only the 40-bit version is exportable.  But we don't
need stories about weakened algorithms to know that NSA can crack
40-bit RC2/4; they'd never have granted a license otherwise.  (And what
does that tell us about 512-bit RSA?)
One more point -- it's been claimed that RC2 and RC4 have an
inherently- slow key setup mechanism.  That can slow down brute-force
attacks tremendously, since it then takes a long time to try each
case.  But it's fine for point-to-point encryptions, where you can
amortize that overhead over many messages.

@_date: 1993-09-10 08:27:45
@_author: smb at research.att.com 
@_subject: ... long live DES (sic) 
It's not that simple; Wiener's design is indeed a major breakthrough
(for the open literature, of course).
First of all, one can often guess probable plaintext for some of the
message.  Here's the first line of your note as it (apparently) left
your machine:
If I've ever received mail from you, and hence know that format, I know
at least the first 6 bytes, and the format of the next two.  If I know
the date of the intercept, I have even more.  Poof -- a crib.
I can do even better.  Look at the $10,000,000 machine -- the one with
a 21-minute solution.  I can afford to try several guesses for where
the string `Date: ' occurs.  It doesn't take that much more complex a
chip to look for obvious variants, such as that string occuring shifted
over one or two bytes in either direction.  You may get some false
positives, but a second-order search machine can then apply more complex
heuristics to possible keys returned by Wiener's design.
And historically, enemies have been able to get probable plaintext --
or even some chosen plaintext -- for at least a few messages.  Read
``The Codebreakers'' or ``Seizing the Enigma'' for many such examples.
There's one more step here, described in detail in Garon and Outerbridge's
``DES Watch'' paper.  If the DES session key is transmitted encrypted
by DES using a 56-bit master key, you're dead meat.  I can crunch for
weeks to recover one session key, using many possibilities for the plaintext
and its location in the ciphertext.  But once I recover that long-gone
session key, I can use it as the known plaintext to recover your master
key.  And after that, the jig is up.
No, there should be no mistake about it.  Single DES is *dead*, for any
application where recovery of a single session key is bad.  If you want
to stick with single DES, you need to change session keys very often
(every few seconds against an enemy who can build a $10M machine), and
you need to distribute session keys by some other mechanism (i.e., RSA,
Diffie-Hellman, triple DES).

@_date: 1993-09-10 21:27:58
@_author: smb at research.att.com 
@_subject: misc.legal.computing #4107 - Korea now accepts secret US patent applications 
This was posted to misc.legal.computing and misc.int-property.  It's
forwarded to this list with permission.

@_date: 1993-09-20 04:29:54
@_author: smb at research.att.com 
@_subject: meaningless rumor 
Ward posted a note that (in essence) asked for help in evading the ITARs.
(Well, I suppose it could have been someone forging a posting...).  He
went so far as to offer to provide mailing labels to someone abroad who
would redistribute Moby Crypto, though from a country where that would
be legal -- but never said how the first copy would get to the trans-
shipment point.  Some reasons were given why this sequence was going to
be technically legal -- but if you were a U.S. attorney investigating
the export of cryptographic software, it's the sort of thing that almost
has to be investigated.  Face it -- if Ward *wanted* to generate a test
case, he couldn't have done a much better job; a private note to the
authorities could have been ``misfiled'', but an announcement to tens
of thousands of readers around the world?  C'mon -- they may or may not
be stupid, and they may or may not be paranoid, but their entire raison
d'etre is to wield power, and Grady just slapped that authority in the
face.  Spitting at your local traffic cop would have been a lot safer.
As for PKP -- *somehow*, it wandered out of the U.S.  Probably, someone
in power decided that that finally needed investigating in detail, to see
if a law was broken.  And Sternlight is right -- if they decide to indict,
they may throw in charges of importing IDEA, though I doubt that they'd
indict just on those grounds; in an era of key escrow, they'd certainly
like a court to rule they had the power to exclude subversive foreign

@_date: 1993-09-20 06:16:06
@_author: smb at research.att.com 
@_subject: meaningless rumor 
As you say, ``assuming''.  The Feds can afford to lose that count
because of the facts of this case; they can't afford to lose on a point
of law.  I don't know what the facts are, or what they can prove about
them.  They may not, either, at this point, pending the results of the
grand jury probe.

@_date: 1993-09-20 13:19:58
@_author: smb at research.att.com 
@_subject: MISC: thought for the dat 
Hardly a new sentiment.  From Kahn:
In 1940, Stimson was Secretary of War, and a recipient of MAGIC....

@_date: 1993-09-21 13:27:40
@_author: smb at research.att.com 
@_subject: crypto import 
Perhaps not now, but the statutory and regulatory provisions exist:
120.1 -- General authorities and eligibility.
   (a) Section 38 of the Arms Export Control Act (22 U.S.C. 2778) authorizes the
   President to control the export and import of defense articles and defense
   services.
120.5 -- Relation to regulations of other agencies.
   If an article or service is covered by the U.S. Munitions List, its export is
   regulated by the Department of State, except as indicated otherwise in this
   subchapter. For the relationship of this subchapter to regulations of the
   Department of Commerce, the Department of Energy and the Nuclear Regulatory
   Commission, see ^U 123.20 of this subchapter. The Treasury Department controls
   permanent imports of articles and services covered by the U.S. Munitions Import
   List from foreign countries by persons subject to U.S. jurisdiction (31 CFR part
   505).
123.2 -- Import jurisdiction.
   The Department of State regulates the temporary import of defense articles.
   Permanent imports of defense articles into the United States are regulated by
   the Department of the Treasury (see 27 CFR parts 47, 178 and 179).
I confess that I don't happen to have a copy of the Munitions Import List.
Are you certain that crypto gear isn't on it?  Are you certain it wasn't
added last week?  Or next?  But the same authority -- dubious though it
may be -- that lets them ban export of crypto would let them ban import
if they chose to try.
Only if there's a coded message in the timing.

@_date: 1993-09-24 08:27:38
@_author: smb at research.att.com 
@_subject: the public key minefield 
No, because of the language in the patent which requires that it be
infeasible to find the deciphering key from the enciphering key.  Here's
the claim, from patent 4218582, that covers all of public key cryptography:
1. In a method of communicating securely over an insecure communication
channel of the type which communicates a message from a transmitter to
a receiver, the improvement characterized by:
  providing random numbers at the receiver;
  generating from said random numbers a public enciphering key at the
    receiver;
  generating from said random numbers a secret deciphering key at the
    receiver such that the secret deciphering key is directly related to
    and computationally infeasible to generate from the public enciphering
    key;
  communicating the public enciphering key from the receiver to the
    transmitter;
  processing the message and the public enciphering key at the
    transmitter and generating an enciphered message by an enciphering
    transformation, such that the enciphering transformation is easy to
    effect but computationally infeasible to invert without the secret
    deciphering key;
  transmitting the enciphered message from the transmitter to the
    receiver; and
  processing the enciphered message and the secret deciphering key at
    the receiver to transform the enciphered message with the secret
    deciphering key to generate the message.

@_date: 1993-09-24 08:28:37
@_author: smb at research.att.com 
@_subject: Why RSA? 
Let me try to answer some of these questions by giving a broad overview
of patent law.  I'm not a lawyer, but I've spent a lot of time talking
to lawyers about patents during the last several years, and about what
they are and aren't.
First of all, a patent is (theoretically) a contract between an inventor
and society.  In return for the inventor teaching everyone about the
new idea, he or she gets a monopoly on use of that idea for a limited
period (normally 17 years in the U.S.).
Patents cover the right to build, make, import, or even *use* the
protected idea.
A patent is *not* a license to do something.  Rather, it is the right
to prevent others from doing it.  Thus, if I invented the pencil, and
you invented the eraser, neither of us could make a pencil+eraser without
permission from the other.
Patent infringement is not a crime; you cannot go to jail for it.  It is
a civil offense, and the patent holder has to sue you for infringing.
You can get a patent for things that are new, useful, and non-obvious.
All three criteria must be satisfied.  Note specifically that a new
use for an old idea is patentable.  R, S, and A did not patent particular
equations; rather, they patented certain specific uses for those
equations.  If you can find a new use for them, you're home free.
(I and a colleague almost did that.  We came up with a new application
for them, and we felt that the security of our scheme would be
strengthened tremendously by the work that's gone into RSA.  However,
our application was just different enough that I managed to crack
it.  Sigh.  But better that I cracked it before publishing...)
For our purposes, a patent consists of two major parts.  The first is
more or less a technical paper; this is what you're supposed to learn
from.  Some of the language is rather stylized, but for the most part
it will be comprehensible to someone who understands the field.
The second part is the ``claims''; these are written in very dense
legalese, and are supposed to delimit exactly what's new.  You infringe
a patent if your activity includes all of the elements of any one
claim.  Writing good claims is at the heart of a patent attorney's
skills.  You want to claim as much as you possibly can, even if you
think some of it is worthless -- but you have to make sure that what
you claim doesn't include prior art.  In the RSA patent, for example,
almost every claim speaks of both encryption and decryption.  The
idea of mine that I alluded to involved encryption only; thus, it
did not fall within the scope of all but one of the RSA claims.  For
various other reasons, it didn't fall within the scope of the other
Well, Rabin's scheme has other problems as well, including the lack of
an unambiguous decryption algorithm.  You get a few answers, one of which
will be correct.
Under patent law, though, the ``superior'' technology hasn't been suppressed.
Rather, Rabin would need a license from RSA (and Diffie-Hellman) to
practice his invention.  And he couldn't have come up with his idea
unless RSA had been published.
As I explained above, a patent does not infringe per se.  However,
practicing RSA would indeed require a license from Stanford.  But
both Stanford and MIT assigned exclusive licensing rights to those
patents to Public Key Partners, a deal which arguably violates the
antitrust laws.  (Down, libertarians, down.  I know you don't believe
in such things...)
Anyway, patent 4200770 claims virtually all mechanisms for public key
distribution or exchange systems.  Exponential key exchange is the
particular example given; it's claimed, too.  Patent 4218582 claims
all of public-key cryptography.  The knapsack system was the particular
system given; it was claimed, as well.
I should note here -- to patent something, while you don't (as a rule)
have to build it, you do have to show that it's buildable.  If there's
any doubt, the patent examiner can order you to produce one.  This is
used to deal with perpetual motion machines and the like.  The concept
of public key cryptography couldn't have been patented without a
working example.  And, while knapsack systems were subsequently cracked,
at the time the patent was issued there were no (publicly) known attacks.
Have a look at "The first ten years of public key cryptography", Diffie, W.,
Proceedings of the IEEE 76:5, 1988, pp 560-577.
There was some question of prior art published more than one year before
the patent was filed.  See "Multi-user cryptographic techniques",
Diffie and Hellman, AFIPS Proceedings 45, pp109-112, June 8, 1976.
The patent apparently contains some language explaing why that doesn't
count, and in particular because there was no demonstration that it was
even possible to build such a thing as a public key cryptosystem.

@_date: 1993-09-24 08:40:38
@_author: smb at research.att.com 
@_subject: on the `R' in `RSA' 
NSA claims to have developed public-key cryptography about ten years before
the public discovery.  See
   author = {Whitfield Diffie},
   journal = {Proceedings of the IEEE},
   month = {May},
   number = {5},
   pages = {560--577},
   title = {The First Ten Years of Public Key Cryptography},
   volume = {76},
   year = {1988}
a paper I hightly recommend to this entire list.

@_date: 1993-09-25 18:35:52
@_author: smb at research.att.com 
@_subject: the public key minefield 
You seem to have missed my earlier summary of how patents are structured.
A separate part of the patent from the claims describes how to build the
claimed device.  The claims aren't supposed to.

@_date: 1993-09-27 07:51:13
@_author: smb at research.att.com 
@_subject: An amusing coincidence 
The name of the official Russian news agency is -- Itar-TASS.  What
a lovely pair of names....

@_date: 1993-09-27 18:41:21
@_author: smb at research.att.com 
@_subject: the public key minefield 
The question is phrased improperly.  Apart from the fact that the
concept (though not the reality) of anti-gravity is prior art, they
didn't patent the concept of public-key cryptography.  Rather, they
patented a class of devices fitting a certain description, with one
public key cryptosystem as an example and as a separate set of claims.
To use your analogy, I could patent anti-gravity achieved by interposing
a screen of some substance opaque to gravity, and patent Cavorite as
an instance of that class.  If you had another use for Cavorite, you'd
be home free.  Or if you found a way to neutralize gravity by beaming
anti-gravitons downward, you'd probably be clear, too.  But if you
found another substance besides Cavorite that was opaque to gravity --
yes, that would be covered by my patent.  (Fortunately, H.G. Wells didn't
patent his literary device.  But I can't think of another science
fiction author who used that technique....)
It's certainly possible that all possible cryptosystems that achieve the
same effect would be covered by their description.  That, of course, is
the mark of a good patent attorney's work -- that he or she managed to
fashion so broad a claim.  But maybe you can find a better way to do what
you really want to do, which is trade keys and authenticate messages.
And if you do -- well, then, the patent system has succeeded in its goals,
in that the monopoly assigned to someone else has stimulated you to find
another way to do things, and thus furthered the useful arts and sciences.

@_date: 1993-09-28 17:16:35
@_author: smb at research.att.com 
@_subject: Disturbing statistics on wiretaps 
Do you really think that?  One could argue, fairly strongly, that the
rules set forth in the ECPA have created an expectation of privacy,
and that a violation of that expectation would be exactly the violation
of the 4th Amendment that the Supreme Court addressed in the 1967
decision that led to the original wiretap provisions in the Omnibus
Crime Control and Safe Streets Act.

@_date: 1993-09-29 00:51:38
@_author: smb at research.att.com 
@_subject: Disturbing statistics on wiretaps 
I realize that you know more about the relevant case law than I do.  It
would be pretty sad if you didn't.  But I'm not completely ignorant of
either this subject in particular, or constitutional law in gneral, and
I like to learn more.  I'm asking to be educated, and I don't like to
rely on assertions by authority.  I advanced what I thought was a
fairly strong argument against your point.  Further, the wording of the
statute seems pretty clear to me.  18 USC 2515:
As I read it, if the government doesn't follow the wiretap rules,
the evidence thereby obtained can't be used.  What have I missed?

@_date: 1993-09-29 11:36:30
@_author: smb at research.att.com 
@_subject: Easy cracking 
??  As far as I know, Sun's secure RPC uses Diffie-Hellman with a
192-bit modulus.  LaMacchia and Odlyzko solved the discrete log problem
for that size, but there's no single private key to disclose.
For those who are interested, the reference is
   author = {Brian A. LaMacchia and Andrew M. Odlyzko},
   journal = {Designs, Codes, and Cryptography},
   pages = {46--62},
   title = {Computation of Discrete Logarithms in Prime Fields},
   volume = {1},
   year = {1991},
  xnote = "11211-900629-12TM"

@_date: 1994-04-01 08:24:56
@_author: smb at research.att.com 
@_subject: Patent expiration 
No.  The basic patent on public key cryptography and the patent on
Diffie-Hellman key exchange expire in 1997 (the former on April 28;
the latter on August 18).  PGP uses RSA, which is protected until
September 19, 2000.

@_date: 1994-04-02 11:00:24
@_author: smb at research.att.com 
@_subject: Cryptography banned in the Netherlands.... 
``When *I* use a word,'' Humpty Dumpy said, in rather a scornful tone,
``it means just what I choose it to mean---neither more nor less.''
Reagan, McCarthy, Nixon and Hoover wouldn't call themselves liberals.
We liberals certainly don't number them in our ranks.  To call them
``liberals'' is to deny all meaning to the word.  (Not that it's definition
is clear -- but they sure aren't included.)

@_date: 1994-04-14 19:48:01
@_author: smb at research.att.com 
@_subject: Little known facts about the infohigh....  
You deleted the header of that posting.  Was the date, perchance,
April 1?  Or was it from Steve Carleton -- it's about on a par with

@_date: 1994-04-18 08:19:55
@_author: smb at research.att.com 
@_subject: Autentication gadgets 
We use either an AT&T smart card or the Digital Pathways Securenet
Key.  We started using the latter because they don't sell (expensive)
host software, so they'll disclose the information you need to roll
your own host end software.  A list of some other authenticator vendors
can be found in
Btw -- the comment in there about the Securenet Key not being exportable
from the U.S. is wrong, even though it does use DES.  It's an authentication
device not readily usable for secrecy, so our beloved government
has deigned to permit its sale to furriners.

@_date: 1994-04-19 12:49:53
@_author: smb at research.att.com 
@_subject: Money Laundering thru Roulette 
There was a more interesting case in, I believe, Australia.  Someone
who wanted to bribe a politician instead libeled him.  The politician
sued, and they ``settled'' out of court.

@_date: 1994-04-28 07:59:07
@_author: smb at research.att.com 
@_subject: AT&T, Clipper, & Saudi Arabia 
Can we please confine paranoia to reasonable areas -- like AT&T's sales
of secure phones to the government?  The U.S. government has a very long
record of pushing American products against foreign competitors, such as
Boeing versus Airbus.
Of course, there is a quid pro quo here -- but it's Clinton reminding the
Saudis about Desert Storm.
P.S.  It goes without saying that I'm speaking for myself, not AT&T.

@_date: 1994-04-29 07:15:30
@_author: smb at research.att.com 
@_subject: PGP ban rumor - any truth? 
I find this very hard to believe.  Do you have a source for this
rumor?  The rationale?  The legal grounds for this alleged bill?
First of all, the book already exists and has sold tens of thousands of
copies.  Even assuming that there was somehow some classified
information in it, it's already out -- and the courts won't let them
try to put the genie back in the bottle.  They rarely even permit
prepublication suppression; see, for example, the Pentagon Papers case
or the H-bomb design in Progressive.  (Btw -- read the opinions; don't
just look at the outcome.)
Second -- the book has far too little about PGP to be worth the
effort.  Apart from the source code to IDEA -- which is readily
available in the published version of Lai's dissertation (and which is
printed by a non-U.S.  publisher) -- the discussion of PGP is purely
descriptive, and occupies less than a page.  Contrast that with, say,
the book's discussion of PEM.
Third -- Bruce knows nothing of this.  At least, he said nothing about
it when he was here at Murray Hill last week, and I'm sure he would
have, given the other topics we talked about.
Fourth -- the Commerce Department has already granted Phil Karn a
blanket export license.  They're going to permit the current edition to
be exported freely, but suppress it domestically -- with all that
implies in terms of court fights, newspaper stories, etc.?
Fifth -- it's a book, it's got no nuclear secrets, and it's not
obscene.  He can say anything he want.  If Bruce obtained some
information improperly, he might be in trouble personally -- but the
book itself is more or less untouchable.  (C.f. the Phillip Agee case.)
I've spent far too much time on this already.  Do you have any real
evidence for this rumor?

@_date: 1994-04-30 05:05:17
@_author: smb at research.att.com 
@_subject: Random #'s via serial port dongle? 
Absolutely.  Given a choice between a hardware encryptor -- even a
public key hardware encryptor -- and a true random number generator,
I'd unhesitatingly choose the latter.

@_date: 1994-08-01 08:48:02
@_author: smb at research.att.com 
@_subject: Lawsuits Against PKP 
This one is really fascinating -- Cylink is one of the owners of PKP, along
with RSADSI...

@_date: 1994-08-19 07:33:22
@_author: smb at research.att.com 
@_subject: cypherpunks-digest V1 #18 
I'm not defending a 15 year sentence; it's far too harsh.  But I
strongly disagree with ``why outlawing it in the first place? What is
crypto for?''  By analogy, why outlaw burglary?  After all, what are
safes and alarms for?
The purpose of a civilized society is precisely to avoid this sort of
``arms race'' between bandits and those who pay for services.  Even
libertarians generally agree that theft is wrong, and theft of service
is just as wrong as theft of tangible objects; otherwise, there is
no way to recover the cost of the capital investment necessary to
provide the service.  That is, the marginal cost -- the electricity,
wear and tear on the ICs, etc., to make a cellular phone call -- is
obviously very low.  But someone had to pay for all the cellular switches
out there, to say nothing of the R&D that went into them, and a large
part of the charges for a call go towards repaying that investment.
Now, a prudent service provider may wish to invest in crypto as a way
to prevent fraud, just as many homeowners invest in alarm systems.
But failure to do so doesn't make either sort of theft correct.

@_date: 1994-08-19 12:18:27
@_author: smb at research.att.com 
@_subject: Outlawing the overhearing of conversations 
With the possible exception of this point, I suspect that we agree
more than we disagree.  My note included the following excerpt from
the original:
My reply was keyed to the phrase ``unauthorized access to telecommunications
services''.  As I read it -- and you may differ -- the action that's
being prohibited here is picking up things like ESNs, credit card
numbers, etc., and using those to obtain fraudulent access to the
phone network.  I'm hard put to justify such behavior as ethical, and I
have no problem with declaring it illegal.  (Again, though, prudent
folks and/or their insurance companies and/or the government may choose
to use/mandate crypto.  Banks started using DES authentication for
EFT transfers because the Fed insisted -- they didn't see the problem.)
As for decrypting numbers picked up over the air -- although I'm going
to be vague, I suspect that there is a real issue here.  Suppose that
you run a pay TV service that you genuinely attempt to protect -- that
is, you use DES or stronger.  Am I *entitled* to watch for free
because I happen to be smart enough and/or rich enough to crack DES?
Can I legally or ethically give away or sell recovered keys?
The point I'm making here is that you're making a reasonable effort
to protect something, and thus implicitly declare it private and worthy
of protection.  This is in distiction to unencrypted transmissions
(i.e., today's cellular stuff), security through obscurity (today's
digital cellular), or marginally encrypted (frequency inversion).
To be sure, I don't know where to draw the line here, and I don't
think I want a judge (state-appointed or freely agreed upon) drawing
it for me.  Maybe we should take a leaf from NSA's book and say that
40 bits or less of key amounts to a welcome mat...

@_date: 1994-02-02 12:06:10
@_author: smb at research.att.com 
@_subject: digital signatures/copyright 
It's worth noting that U.S. copyright law makes explicit provision
for copyrighting anonymous works.

@_date: 1994-02-04 17:39:57
@_author: smb at research.att.com 
@_subject: CERT advisory 
But you still have to type a password to a command that itself could
have been compromised.  (Not that D-H wouldn't be a tremendous help,
of course.)
All of the hand-held authenticators I'm familiar with require that
the host -- or a dedicated, trusted, security server -- keep a secret
key per user.  That's not a great idea.  Bellcore's S/Key doesn't,
but I don't know of any hardware devices that implement it.  Another
possibility would be hand-held digital signature boxes that could sign
a random challenge from the host.

@_date: 1994-02-04 17:49:56
@_author: smb at research.att.com 
@_subject: No Subject 
The law already says that.  The government's right to spy on non-Americans
is spelled out in the Foreign Intelligence Surveillance Act, 50 USC 1801.
Enforcing it is another matter, of course.
I saw an AP wire story today that's illuminating.  It seems that for
years, members of the Tennessee Highway Patrol have been subpoenaing
phone company records without proper authority.  They've been using
a rubber stamp with the commissioner's signature, apparently without
his knowledge or consent -- which he probably wouldn't have given, since
under Tennessee law the Highway Patrol can deal with crimes committed
on a highway, car theft, odometer tampering, or (of course) drug
dealing.  The only state police agency that has such subpoena authority
is the Tennessee Bureau of Investigation -- and even they're limited;
the D.A. is supposed to do such things after authorization by the grand
And the phone company -- they complied, of course; they had no idea
(they said) that the subpoenas were illegal.

@_date: 1994-02-05 14:35:45
@_author: smb at research.att.com 
@_subject: Some stuff about Diffie-Hellman (and more :-) 
Close, but not quite.  The modulus m should be primed for best results.
Some folks have used a power of 2 for m, since that makes the modulus
operation easier, but it also makes cracking it easier, for comparable
sizes.  Next, the base w should be a primitive root of the group GF(m).
More seriously, your equations are subtly wrong -- Bob and Carol can't
do the calculations you've given.  Bob should calculate (C**b)%m -- he
knows b and C, but doesn't know c.  Similarly, Carol calculates (B**c)%m.
Two problems...  First, many attacks on the discrete log problem are
based on massive precomputation for a known modulus.  That probably
isn't an issue when you get to ~1K bits (*not* digits!).  Second, you
need to specify things far more concretely, and in particular define
the random number generation process.  You can't pick w till you know m.
Well, I'd certainly be interested in hearing about it...  There have
been a number of mechanisms for preventing eavesdropping with DH;
a lot depends on what assumptions you want to make.  My attempts --
which involve the two parties sharing a weak (i.e., PIN- or password-grade
secret) can be found in /dist/smb/{neke,aeke}.ps on research.att.com.
There's also Rivest and Shamir's Interlock Protocol (April '84 CACM).
Davies and Price suggest using it for authentication, but Mike Merritt
and I showed that that doesn't work under certain circumstances.

@_date: 1994-02-15 08:18:28
@_author: smb at research.att.com 
@_subject: Clipper and Traffic Analysis 
Also, it probably goes via a different physical path.  And at least some
SS7 trunks are encrypted with DES.

@_date: 1994-02-15 10:16:01
@_author: smb at research.att.com 
@_subject: LEAF, SS7 
The LEAF has many very interesting attributes.  As I mentioned earlier,
in response to Mike's original question -- yes, there are tremendous
advantages to the LEAF for a traffic analyst.
But the LEAF itself is encrypted, including the session key, so
enemies can't do traffic analysis based on the LEAF.
The structure of the LEAF is also a dead giveaway that Clipper is
being used -- it's easy to envision a box that has the family key,
and tries every LEAF-sized field to see if it decrypts to something
that looks right, and in particular has the right checksum.  It
detects Clipper -- and coupled with a random sequence detector, it
detects encrypted, non-Clipper traffic...

@_date: 1994-02-15 10:36:50
@_author: smb at research.att.com 
@_subject: LEAF, SS7 
I suspect that you'd have too much data -- you'd have to be able to
scan every part of every conversation.  If you're going to go to those
lengths, you'd do just as well to tap the signaling channels instead --
a lot less data, and most of it organized the way you want it.

@_date: 1994-02-16 08:10:14
@_author: smb at research.att.com 
@_subject: Clipper and Traffic Analysis 
I phrased it that way because I'm not certain of the extent, and I'm
not certain how much of what I know is AT&T-proprietary.  But the
obvious risks that encryption avoids are traffic analysis by enemies
(pick your own definition of enemy), information on what channels to
wiretap (remember the furor a few years ago about the location of the
then-Soviet embassy on a hilltop in Washington, D.C.?), and the threat
of phone-phreaking by introducing bogus call setup messages.  On the
latter point, recall that out-of-band signaling was introduced in part
in response to ``blue boxes'' and other device that exploited in-band
signaling technologies.

@_date: 1994-02-16 09:40:16
@_author: smb at research.att.com 
@_subject: AT&T stopped talking to me 
I know of no such policy.  To be sure, I wouldn't necessarily know
of it if it existed, being enmeshed in the wilds of Research -- but
I know of none.

@_date: 1994-02-16 11:45:21
@_author: smb at research.att.com 
@_subject: Clipper and Traffic Analysis 
That's a fairly strange conclusion to draw.  In fact, I was originally
going to use a much stronger word than ``strange'', but I forbore to
change my standing policy against flames.  Why, pray tell, do you
think that because AT&T uses its own information, that it gives it
to the government?  For one thing, that would be illegal, as I read the law.  18 USC 2703(c)(1)(A)
specifically prohibits giving out records of subscriber information to
government agencies, except in reponse to a subpoena, warrant, or court
order.  (Oddly enough, it is permissible to give out the information
to non-government agencies; if I recall correctly what I've read of the legislative
history of the act, that was specifically intended to permit compilation
and sale of mailing lists and marketing data.)
For another, it isn't at all clear to me that it's in any way unethical
for a company to understand which of its products its customers buy.
*Selling* such data is another matter -- I don't like that at all -- but
that isn't what you're claiming.
You also say that AT&T is not using racial data or certain names to
pick out markets.  All you're saying is that you once called Hong Kong,
and that AT&T is now offering you a cheaper way to do so.  What's wrong
with that?  (Btw -- half a year is not at all a long time.  That's only
very slightly longer than they'd need to keep the data just to resolve
billing questions.)
Disclaimer:  Obviously, I work for AT&T.  That doesn't mean I like
everything the company does -- but in this case, I fail to see the offense.

@_date: 1994-02-18 10:55:38
@_author: smb at research.att.com 
@_subject: CERT/Whitehouse/Clipper link - smoking gun... 
It's stuff that's been happening *since* last November.  I'm quite
certain that the attacks were continuing until (at the very least)
shortly before the announcement.
No, you're wrong.  A challenge/response login architecture based on
digital signatures would have eliminated the attack.  And digital
signatures -- unlike most other technologies for one-time passwords --
do not require that any secret information be kept on the host.
There are practical difficulties, such as entering in 160 bits of
information, but for host-to-host logins, that isn't much of a problem.

@_date: 1994-02-23 04:09:12
@_author: smb at research.att.com 
@_subject: Disinformation 
I'll leave out the buzzwords -- but Clipper will definitely hamper the
deployment of good networks.  Encryption is a vital tool for network
management and authentication, even apart from privacy considerations.
But Clipper is of necessity hardware-only, which means that most
current platforms will never support it, and few future ones will
actually have it, whether they're capable of it or not.  And on many
important boxes -- routers, for example -- just leaving room for
Clipper on the boards will be expensive.
We have the following dilemma:  DES isn't exportable, Clipper isn't
suitable, and lots of foreign governments won't allow it in anyway, I
suspect.  How is one supposed to do authentication on a global

@_date: 1994-02-24 04:21:26
@_author: smb at research.att.com 
@_subject: CERT funding 
Thanks, Mark, for an interesting posting about CERT.  Let me add just
one or two comments about the place.
That CERT should be interested in software engineering is a very
good sign.  What do you think causes most security holes?  It *isn't*
lack of cryptography, for the most part, though this last big incident
is an obvious exception.  The answer, of course, is bugs in the
code -- and to that, software engineering is the only answer from
computer science as a whole.  (Bob Morris Sr's keynote address
at the last UNIX Security Conference was entitled ``if your software
is full of bugs, what does that say about its security?'')
As for the database stuff -- from what the folks at CERT have told me
(and yes, I know some of them quite well), they're having a problem
managing the tremendous volume of bug reports, incident reports, etc.
They need to do their own tool-building.
Finally, there are some folks at CERT who are *extremely* sharp.  I don't
know who you talked to, but there are people there I'd hire in an instant
if they were available.

@_date: 1994-02-24 17:35:47
@_author: smb at research.att.com 
@_subject: No Subject 
And there's also the question of whether or not I'm going to
execute a random program that you've sent me, allegedly to do
a decryption....

@_date: 1994-02-25 13:35:43
@_author: smb at research.att.com 
@_subject: I have FOIA'd the Clipper Key Escrow databases 
I confess -- I expect one of two outcomes.  First, they may say that
the database is classified, if only at the level of ``For Official
Use Only''.  Second, maybe they will release it -- but remember that
the keys are stored encrypted.  Can you file an FOIA request for the
key, too?

@_date: 1994-02-27 17:24:16
@_author: smb at research.att.com 
@_subject: I have FOIA'd the Clipper Key Escrow databases 
Good strategy.  I still wonder if the decrypted keys are (all) classified,
while the encrypted ones aren't.  After all, the local cops' magic decoder
boxes can strip off that layer of encryption (as, of course, anyone
who steals one of those boxes or bribes a local cop).
Anyway, I hope the idea works, or at least drives them a bit crazy...

@_date: 1994-02-28 13:13:55
@_author: smb at research.att.com 
@_subject: Dorothy Denning 
Dr. Denning is the head of the computer science department at Georgetown.
She's the author of ``Cryptography and Data Security'', a classic (though
now somewhat-dated) work in the field.  In sort -- though she may be
politically naive, and she obviously puts a different weight on personal
liberty than do most of the people on this list -- she can't be accused
of technical incompetence.  There is no doubt that she knows more -- and
perhaps far more -- about cryptography per se than do most of the people
on this list.
And of course, you don't want to put cryptographic details in an Op-Ed
column in a tabloid newspaper; most of the audience won't understand them.

@_date: 1994-01-01 14:04:13
@_author: smb at research.att.com 
@_subject: _The Hacker Crackdown_ on-line 
It's also out in paperback now -- I picked up a copy yesterday.

@_date: 1994-01-10 11:06:34
@_author: smb at research.att.com 
@_subject: Crypto not being used where needed 
Yes, it's really easy to monitor cellular calls.  They only hop
frequencies when you move between cells -- and most cop calls will be
within a single cell, simply because most of the queries happen *after*
they've pulled someone over.
Things will change somewhat with the so-called personal communicators,
since they'll use much smaller cells -- but the basic problem is still
the same.

@_date: 1994-01-10 15:46:37
@_author: smb at research.att.com 
@_subject: Internet billing scam? 
You raise an interesting point; however, it's far from clear that
digital cash is a solution.  In fact, it may even be a negative
factor in some contexts.
Let's look at why some vendors -- whether of network services, hotel
rooms, or rental cars -- much prefer credit cards, even though the
card issuer will charge them a few percent off the top.  The answer
is that in these cases, customers have the potential to run up a
large bill -- that is, a debt -- between interactions with the
provider.  Furthermore, this debt is often legitimate, i.e., the customer
really did consume that amount of service.  A vendor possessing a
credit card number *will* be paid, with minimum hassle.  If the
customer skips town, the card issuer eats the charge.  But that's
part of their cost of doing business, which they try to minimize
via things like credit checks.
If credit cards didn't exist, the vendor would have to assume the
risk.  Most are not nearly as large as the card issuers, and they
don't have the lead time to do a credit check in many cases.  Their
usual answer is to demand a deposit.  That's fine with either regular
cash or digital cash -- but if and only if you can afford that kind
of capital outlay.  And those deposits are often very large compared
to the final actual bill, because the vendor wants to cover the larger
potential bill (i.e., a wrecked car).  I suppose one could invent a
deposit broker, who took a few percent to cover the short-term loan
of (perhaps) large sums, and who issued digital cash tokens.
But there's one more important point to consider:  U.S. law on
disputed credit card purchases.  Suppose that this organization
really is fraudulent (though the evidence for that varies between
slim and none, and the person who sent the original note may be
headed for a libel suit).  The customer isn't liable for the bill,
subject to assorted restrictions and caveats.  The card issuer has
to eat that, too -- and it's up to them to try to collect from the
offending merchant.  Why send cash -- digital or otherwise -- to
a potentially-disreputable organization, when you can protect yourself
quite easily?
Digital cash solves some problems very nicely -- but I don't think
this is one of them.

@_date: 1994-01-16 05:33:13
@_author: smb at research.att.com 
@_subject: PGP's e exponent too small? 
There was some discussion on this on sci.crypt.  Briefly, the folks
from RSA don't agree that it's a problem in practice.  If you always
include some random padding in the message, you're safe, if I remember
what Kaliski posted.

@_date: 1994-01-24 07:56:38
@_author: smb at research.att.com 
@_subject: subpoenas of personal papers 
I just saw a news story that bears on one of the perpetual questions on
this newsgroup:  can you be compelled to turn over your encryption
key?  In Doe vs. U.S. (93-523), the Supreme Court declined to rule on
whether or not someone can be forced to turn over his personal
appointment calendar.  By doing so, they let stand an Appeals Court
(2nd Circuit) that he could *not* invoke the Fifth Amendment.  That
court ruled that ``testimony'' was protected, but not personal papers.
There was a Supreme Court ruling in 1886 protecting such papers, but
that's been eroded over the years, and the Supreme Court has ruled
several times that business records are not protected.  And in a
concurring opinion in 1986, O'Connor wrote ``The Fifth Amendment
provides absolutely no protection for the contents of private papers of
any kind''.

@_date: 1994-01-26 19:37:25
@_author: smb at research.att.com 
@_subject: Multikey crypto 
There are a number of ways to do that.  The best overview can be
found in
        author = {Gustavus J. Simmons},
        title = {An Introduction to Shared Secret and/or Shared Control Schemes and Their Application},
        booktitle = {Contemporary Cryptology:  The Science of Information Integrity},
        year = 1992,
        pages = {441--497},
The best-known scheme is described in
   author = {Adi Shamir},
   journal = {Communications of the ACM},
   number = {11},
   pages = {612--613},
   title = {How to Share a Secret},
   volume = {22},
   year = {1979}
but also see
   author = {David K. Gifford},
   journal = {Communications of the ACM},
   number = {4},
   pages = {274--286},
   title = {Cryptographic Sealing for Information Secrecy and Authentication},
   volume = {25},
   year = {1982}

@_date: 1994-01-27 10:12:13
@_author: smb at research.att.com 
@_subject: subpoenas of personal 
One caveat -- I believe that the shield laws are state laws; the
U.S. Supreme Court has *not* upheld the principle.  Check with your
local lawyers first.

@_date: 1994-01-31 10:59:31
@_author: smb at research.att.com 
@_subject: Index for ftp site csn.org:/mpj/ 
I can't speak for RIPEM, but that's not accurate for PEM.  You can have
as long a chain of signatures as you want up to the certifying authority.
That may not be as general as you'd like, but it's better than just a
single authority.
A bigger problem is that PEM uses DES rather than IDEA.  I just learned
of a new attack by Mitsuru Matsui of Mitsubishi that requires 2^43
*known* plaintexts, not chosen ones.  The note I received says that it
``breaks the scheme in 50 days on 12 HP9735 workstations''.  This was
presented last week at the Japanese Conference on Cryptography and
Information Security.

@_date: 1994-07-01 10:20:10
@_author: smb at research.att.com 
@_subject: What motivates crypto-folk? 
Being a self-proclaimed left-winger, I do feel compelled to add one
or two random notes.  Much (though of course not all) of the Left
is strongly civil libertarian.  Such folks (including, of course, me)
tend to be strongly opposed to things like Clipper.

@_date: 1994-07-02 17:06:05
@_author: smb at research.att.com 
@_subject: Password Difficulties 
Don't forget the difficulty of typing such a long phrase, with
echoing turned off.

@_date: 1994-07-03 16:49:16
@_author: smb at research.att.com 
@_subject: Password Difficulties 
My tests were informal.  The target was mostly taken from the sci.crypt
readership -- I don't deal much with management...
The initial tests were on passphrases of lengths from 12 to 20, as I
recall.  The phrases were created by chosing random words from
weird, which may have contributed to folks difficulty in typing them.
Not that the scores were bad, but they weren't great.
Access was by telnetting to a special port (or was it a special login?
I forget).  All and sundry are welcome to participate.
Anyway, I never had a chance to follow up, since I was distracted by
the book I was writing.  That's done, and I'm getting back to research
(though I'm thinking of starting another book this fall...).  Rerunning
the experiment, using longer passphrases, is high on my list; there's
some chance I'll be getting to it this summer, along with a student
who's working for me.  (We're currently working on another project of
interest to this audience; the paper will be available for ftp when
it's ready, though that's still a couple of months off.)
P.S.  For the record -- I've been a touch typist for >30 years, as
appalling as that number sounds.  And secretaries are likely to be
*better* typists, not worse.  My concern for folks typing ability
was just that:  concern.  We don't *know*.  We do know that lots of
folks aggressively pick bad passwords; it isn't at all clear to me
if the problem is typing, memory, or both.  Passphrases will tend
to exacerbate both problems.

@_date: 1994-07-03 17:42:14
@_author: smb at research.att.com 
@_subject: Password Difficulties 
Yes, that is an issue.  I attempted to compensate for that by not
turning off echoing.  This way, if you pause in the middle, you'll
be able to see where you are.

@_date: 1994-07-03 18:48:18
@_author: smb at research.att.com 
@_subject: Password Difficulties 
There's an interesting issue here:  is it feasible to construct an
enumeration based on the 50-60 bits of information?  If not, the
protection is rather stronger in a practical sense.  But if one can
generate a reasonably comprehensive enumeration, then an enemy who
can brute-force (say) a 56-bit key could attack a PGP keyring as well.
It should be more or less obvious to this group, but it bears repeating
anyway.  The number of possible keys sets an upper bound on the
difficulty of attacking a system; it says nothing about the lower bound.
(Proof:  a monoalphabetic substitution on English has 26! possible keys,
which is about 88 or 89 bits.  But solutions are extremely trivial.)
Passphrases aren't 128 bits -- but they may be quite strong nevertheless.

@_date: 1994-07-06 04:16:16
@_author: smb at research.att.com 
@_subject: Most People don't Think about Security 
Have a look at Ross Anderson's paper ``Why Cryptosystems Fail'' from
the Fairfax conference.  He points out that one reason U.S. banks use
better security for their ATM cards than do U.K. banks is a difference
in the law:  in the U.S., the banks are (generally) liable for disputed
charges.  Again -- if you pay for failures, you worry about the security.
We have to find ways to make strong security usable.  As you pointed out in
the part of your note that I deleted, banks couldn't deploy 10-digit
PINs even if they wanted to.  And if a bank can't deploy a strong security
system, then we -- who care about it -- can't use it.

@_date: 1994-07-15 13:57:53
@_author: smb at research.att.com 
@_subject: Leaving the Country 
Magic?  TANSTAAFL.  Alaska has oil money (or has had it), and New
Hampshire provides (relatively speaking) fewer services to its citizens,
according to folks I know who have lived there.  Knowing the politics
of much of this list, that's probably considered a Good Thing by many;
I disagree, but I won't clutter the list with (even more) politics.
But if you're thinking of moving anywhere, find out what you *aren't*
getting for your money, and see if it's worth it.

@_date: 1994-07-18 15:17:51
@_author: smb at research.att.com 
@_subject: article: DES strength against attacks 
Let me strongly recommed this paper.  It shows, quite graphically,
just how tightly coupled some parts of DES are.  You don't make up
a good cipher by random bit-twiddling!  (By contrast, I heard a
presentation last week on the cryptanalysis of another cipher.  It
wasn't that strong a cipher -- 2^18 ciphertexts, 2^27 operations
to crack it -- but it would have been far weaker had it not been for
chance.  The cipher had a right shift operation; originally, it was
left unspecified if an arithmetic or logical right shift should be
used.  When different C compilers started producing different results,
the inventor arbitrarily decided to standardize on arithmetic right
shifts.  It turns out that the other choice was far weaker -- but he
didn't know that.)

@_date: 1994-07-19 04:13:34
@_author: smb at research.att.com 
@_subject: Anti-Clipper Article in "THe Computer Applications Journal" 
Might I suggest that this is not the right newsgroup for anti-Clipper
articles?  I've never seen *any* Cypherpunk defend it; what's the
point?  Preaching to the choir?  Repeat doses of brainwashing?
Citations are fine; they show what the outside world thinks.  Technical
aspects are fine; there's a lot to be learned about Skipjack and key
escrow.  But there's little point -- on this list -- to hearing yet
again that Clipper is bad (unless, of course, someone starts defending
it here).

@_date: 1994-07-23 17:12:24
@_author: smb at research.att.com 
@_subject: "Key Escrow" --- the very idea 
In point of fact, U.S. law has required after-the-fact notification of
wiretaps since 1968.  There's a statutory period within which
notification must take place, unless extended by a judge on the
This is 18 USC 2518(8)(d):
This is for domestic surveillance, not for intercepts pursuant to the
Foreign Intelligence Surveillance Act.

@_date: 1994-06-01 07:54:25
@_author: smb at research.att.com 
@_subject: Clipper in patent trouble? 
I think Micali has a good case.  In patent law, the claims are vital.
Exactly what it is that you're claiming is new is described in the claims;
something infringes if it includes all of the elements of any one claim.
Here's claim 15 of that patent:
Sure sounds like Clipper to me...  (Claims 1-14 deal with Micali's
major stuff, the ``fair'' public-key based systems.)
If Micali's claim holds up, it provides Cypherpunks with a whole new
weapon against obnoxious cryptographic protocols -- build 'em first,
patent 'em, and *don't* license them to the government...  (Of course,
since the U.S. uses a ``first to invent'' standard, they could defeat
that by opening up secret NSA archives to show that they really had
it first...)
Btw -- I found the patent online via WWW; see and do the obvious.  If you want just that single patent, go to
ftp://ftp.town.hall.org/patent/data1/05276/05276737, or do the obvious

@_date: 1994-06-02 09:23:42
@_author: smb at research.att.com 
@_subject: News Flash: Clipper Bug? 
Perry's right.  Several of us have seen Matt's paper, and the attacks
really do work.  (Even NSA admits that.)  But out of courtesy to Matt,
we'd rather leave it to him to discuss the details.

@_date: 1994-06-02 12:01:45
@_author: smb at research.att.com 
@_subject: Matt Blaze's Clipper attack -- details 
I spoke with Matt Blaze; he gave me permission to post a summary of his
attacks.  But the paper is not yet available for ftp.
Matt's work was done using a prototype Tessera card, with a SCSI-PCMCIA
interface on a Sun 4.  That may (or may not) have implications for some
of the performance numbers.
There are two classes of ways to foil key escrow.  The less interesting
class of attacks are non-interoperable.  That is, two rogue
implementations can talk security, but can't talk to a conforming key
escrow device.  But there's another attack possible, wherein a rogue
application talks to a conforming device, but without presenting a
valid LEAF.
The LEAF contains a 32 bit unit id, an 80-bit session key encrypted
with the per-device secret key, and a 16 bit checksum.  The whole thing
is encrypted with the family key.  The checksum field is based on both
the session key and the IV.  A receiving device will not decrypt unless
it's handed a valid LEAF.  But it can only base its judgment on the
checksum and on its external knowledge of the key and IV; the actual
key in the LEAF is encrypted in a way that it cannot read.  LEAFs are
sent out of band by the application; they're not concealed in the
encrypted data stream.
Non-interopable applications work by generating a LEAF/IV pair and not
transmitting it.  (Users cannot control the IV; the Tessera interface
(and maybe the Capstone chip) generates it.)  The receiving end does
the same thing.  You don't need an IV for ECB mode, so you have at
least some access to Skipjack that way.  But that's too slow; at least
in the configuration tested, it took ~50 ms to do an ECB encryption.
In CBC mode, if you have the wrong IV, the first block of plaintext
will be garbled.  But the error recovery properties of CBC guarantee
that all subsequent blocks will be decrypted correctly.  (Derivation is
left as an exercise for the reader.)  The solution, then, is simple:
just pad your messages with an 8-byte garbage header.
OFB and CFB modes can be implemented as well.  The obvious way is via
ECB mode, but that's too slow.  It turns out that with a bit of work,
you can use CBC mode as a primitive to build OFB and CFB.  I'll
describe that if anyone's really interested.
The more interesting attack on key escrow is a rogue implementation
that can interoperate with a conforming one.  The checksum is only 16
bits; it's possible to brute-force it.  That is, generate random
128-bit strings, and see if your own Tessera card will accept it as a
valid LEAF.  Again, recall that it knows only the unencrypted key and
the IV.  On average, you'll find a hit in 2^15 tries; at 50 ms per try,
that's 28 minutes.  You can speed this up by running in parallel with
multiple Tessera cards.

@_date: 1994-06-03 08:06:26
@_author: smb at research.att.com 
@_subject: more info from talk at MIT yesterday. 
The government can patent things, but not copyright them.
Why can't they refuse to license a patent?

@_date: 1994-06-03 09:22:07
@_author: smb at research.att.com 
@_subject: more info from talk at MIT yesterday. 
Not only that, there have been too many spies found in the various
intelligence agencies for them to risk such a thing.

@_date: 1994-06-03 10:22:03
@_author: smb at research.att.com 
@_subject: Ultra and Coventy 
Perry wrote that the British let Coventry be destroyed lest Ultra
be revealed.  Kahn doesn't believe that.  From ``Kahn on Codes'', p. 110:
The footnote cites F.H. Hinsley with E.E. Thomas, C.F.G Ransom, and
R.C. Knight, ``British Intelligence in the Second World War:  Its
Influence on Strategy and Operations'' (London, 1979- ), I:528-48;
N.E. Evans, ``Air Intelligence and the Coventry Raid'', Royal United
Services Institution Journal (September 1976), 66-73.  I don't have
access to either of those publications, so I can't assess that further.

@_date: 1994-06-04 18:56:09
@_author: smb at research.att.com 
@_subject: Wiretapping, NYT article 
More or less.  There was a Supreme Court ruling in 1967 (I don't have
the citation handy) that held that wiretaps constituted an illegal
search and seizure.  The Federal wiretap statute (18 U.S.C.  2510 et
seq., later amended by the ECPA) was a direct response to this ruling.
Until then, wiretaps were barred from Federal use by the Federal
Communications Act, and not by 4th Amendment considerations (Nardone v.
United States, 320 US 379 (1937)).  But that was a question of
admissibility of evidence, and in 1953 (Schwartz v. Texas, 344 US 199)
the Court ruled that that was not binding on state courts.
As a sidenote, the first act regulating police wiretaps was in New York
in 1942; in 1895, the state had passed a law prohibiting wiretaps

@_date: 1994-06-11 07:46:41
@_author: smb at research.att.com 
@_subject: crypto in the NY Times 
The magazine section of tomorrow's N.Y. Times has a good story on
cypherpunks, Clipper, crypto, etc.  Whit Diffie adorns the cover.

@_date: 1994-06-13 19:08:33
@_author: smb at research.att.com 
@_subject: DNA 
No.  The purpose of check digits like that is to detect innocent errors in
data entry.

@_date: 1994-06-17 14:35:46
@_author: smb at research.att.com 
@_subject: a bit more information on key escrow 
I and a few others sent a short list of questions to Dorothy Denning
and Steve Kent, with a request that they forward them to the other review
panel members.  Here are Denning's answers.  I do not know if they
represent the view of the other committee members, or if more details
will be forthcoming.  In particular, I do not know if anyone on the
committee will ask NSA to declassify any information relative to these
questions.  I did ask that if the answer to anything was ``it's
classified'', that a persuasive rationale for the classification
status be given.
Reposted with permission....
------- Forwarded Message
Here are answers to the questions you asked.  The answers generally
apply to the current system.  In some cases, I noted changes that will
be made in the target system that is under development.
1.	How are the halves of the unit key generated?  What is
2.      How are the seeds generated for the unit key generation
3.	How is the serial number generated?  Randomly?  With only
4.	How are the seeds destroyed after generation?
        destroyed.
5.	How is the session key encrypted within the LEAF?
6.	How is the entire LEAF encrypted?  The LEAF/IV package use
        The IV is passed in the clear.  See 5 about how the LEAF is
        encrypted.
7.	How is the checksum in the LEAF calculated?
9.	What is the nature of the key exchange and key negotiation
10.	How does the Tessera card generate its random keys and IVs?
11.	How are escrowed keys protected during transport and storage?
12.	What mechanisms will protect the key halves during transmission
13.	How will an audit trail be maintained of unit key requests
14.	How will wiretap keys expire?
------- End of Forwarded Message

@_date: 1994-06-19 06:35:46
@_author: smb at research.att.com 
@_subject: No Subject 
There are a few things to watch out for.  First, it's really easy
for subtle (or not so subtle) biases to be present in a noise source.
These can be due to component drift, external noise (i.e., power
supply coupling), etc.  You want a design that isn't sensitive to
such things, if possible.  Second -- and it's partly a corollary to
the first -- the designs I've seen for real RNGs have always included
a scrambler step, to mix up the bits, account for biases, etc.
The first such scrambler was, I think, described by von Neuman himself.
I have the citation in my office; I'll try to post it tomorrow.

@_date: 1994-06-19 06:39:26
@_author: smb at research.att.com 
@_subject: Having your own computer means never having.... 
Have a look at Matt Blaze's paper from Usenix last week.  He describes
a smart-card based key escrow system for file encryption -- the risk
to the company is that an employee will quit, forget a password, walk in
front of a truck, etc. -- at which point they're unable to get at the
files that this person created -- files that the company owns in
accordance with the provision of the free-market contract willingly
agreed to by this employee.

@_date: 1994-06-19 10:39:25
@_author: smb at research.att.com 
@_subject: Hardware generators was: your mail 
``Cross-platform'' is great, but ``fast'' is probably a bad idea.
Few random number generators are particularly fast, and if you sample
the input too rapidly, you're likely to get too high a correlation
between successive bits.

@_date: 1994-06-20 13:01:07
@_author: smb at research.att.com 
@_subject: rec.radio.scanner #7670 - Re: OJ's Cellular 
This article, reposted with permission from rec.radio.scanner, sheds
a bit of light on the topic.
The original poster mentioned that he's not an expert on cellular; the
person he cited is from an ``''umbrella organization'' for the cellular
industry in D.C.

@_date: 1994-03-01 06:27:44
@_author: smb at research.att.com 
@_subject: DES Question 
Are you sure?  I got the distinct impression it was related to
serial/parallel conversions on the chips of the time.

@_date: 1994-03-01 08:40:05
@_author: smb at research.att.com 
@_subject: ditz in office 
Sorry, that's a statement of fact.  The interesting question is where
one draws the line.  Assume, for example, that you are a fervent believer
in some religion that requires the sacrifice of unwilling outsiders.
Should you be permitted to practice that religion?  (Note:  I said
``practice'', not ``believe in''.)  Would the anarchist liberatarian
next door to you be abridging your rights if he or she shoots back
when you come to collect some victims?
Even your own note acknowledged that rights aren't necessary absolute; you
noted, in an exculpatory context, that
As I said -- the interesting question is how and where one draws the line.

@_date: 1994-03-01 16:57:19
@_author: smb at research.att.com 
@_subject: PGP on the HP 100 
Has anyone tried putting ViaCrypt PGP on the HP-100?  Is anyone but
me crazy enough to contemplate it?  How abysmal is the performance?

@_date: 1994-03-02 08:46:23
@_author: smb at research.att.com 
@_subject: low-overhead encrypted telnet 
Assuming, of course, that you're running a system that has modload.
(Ironically, CERT has recommended that you delete loadable device drivers
from systems that don't need them, as a way to guard against password-
What standards?  There are no RFCs, nor any current drafts, that define
a telnet encryption option.  The last draft I saw was from 1991, and
Internet drafts expire after 6 months.  As I recall, the idea that was
being pushed then was to integrate encryption more closely with

@_date: 1994-03-03 17:00:14
@_author: smb at research.att.com 
@_subject: Standard for Stenography? 
Obscurity is certainly a help.  Attacking an unknown system is very
much harder than attacking a known one.  And everyone in the business
knows that.
However -- in the real world, as opposed to an academic exercise,
you cannot keep an algorithm secret forever.  Partners will betray
you, spies will steal copies, enemies will capture them.  Do you
trust everyone on cypherpunks?  Should you?  If your algorithm is not
strong enough to withstand an attack by an enemy who has captured
it, you're in trouble.  And although you can replace the algorithm,
it's a lot harder than changing keys -- good cryptoalgorithms take
a *lot* of work, and the details often matter a lot.  Besides, your
old traffic will then be readable.
Security through obscurity is more than a buzzword.  It's a necessity
in this business.

@_date: 1994-03-11 08:27:45
@_author: smb at research.att.com 
@_subject: The Coming Police State 
Personally, I give the credit to David Gerrold, in ``When Harlie Was One''.
Here's a netnews posting of mine that explains my reasoning.

@_date: 1994-03-11 10:30:00
@_author: smb at research.att.com 
@_subject: 2nd CJ update 
It's not that ``NSA'' doesn't have the book; it's that that office may
not.  Or at least, making that claim isn't totally beyond the realm of
possibility.  As for the original request -- they *don't* want to rule
that a book needs a license, of any sort; it opens them up to judges
who understand books but not floppies.  (Let me commend to this audience
Kenneth Pierce's paper ``Public Cryptography, Arms Export Controls, and the
First Amendment:  A Need for Legislation'', Cornell International Law Journal
vol. 17, 1984, pp. 197--236 -- it's a very good summary of the legal
issues.  Though the details of the ITAR have changed, the underlying
legal theories have not.)
My impression is that they've realized that that game is a bit stupid
at this point, and that they're giving up on unnecessary secrecy.

@_date: 1994-03-14 07:37:07
@_author: smb at research.att.com 
@_subject: Clipper and Traffic Analysis 
The LEAF can be decrypted with just the family key; from what's been
disclosed so far, local law enforcement agents will be able to do that
without contacting the escrow sites.  The LEAF contains the unit id of
the chip, independent of what phone number it's being used from, or
(in the case of cellular phones) where in the country it is.  The ordinary
signaling channels are (often) encrypted, and in general use a different
path than the call itself.

@_date: 1994-03-14 12:55:20
@_author: smb at research.att.com 
@_subject: Clipper Cracks Appear 
If you're referring to the meeting at AT&T Bell Laboratories, that is
*not* what we were told.  Rather, we were told that a unique mode of
operation was used.  The motivation for using a unique mode for the
LEAF itself isn't completely clear; it may be related to the lack
of space to send a random IV.  The traffic key has to be encrypted
a bit oddly, though; 80 bits doesn't mesh well with standard modes
of operation of a 64-bit cipher if you want to minimize the number
of encryption operations.
Obviously, games can be played with the modes of oepration to weaken
the cryptosystem.  But that's the sort of thing that would stick out
like a sore thumb to the review panel -- much more so than any flaws
in Skipjack itself.  But the question is worth asking of the review
panel members.  I'll pass it on to Steve Kent.

@_date: 1994-03-14 14:53:27
@_author: smb at research.att.com 
@_subject: LEAF field encryption 
As promised, I asked Steve Kent -- a member of the review panel -- about
how the LEAF is encrypted.  Here's his answer, reposted with permission.
------- Forwarded Message
You are right....  SKIPJACK is used to encipher the LEAF, but employing
a complex mode.  The FBI can decode the "outer layer" of the LEAF to
get the chip ID, by using the "family key" but it cannot get at the
traffic key which is encrpted using the device unique key, the splits
for which are held by the escrow agents.
------- End of Forwarded Message

@_date: 1994-03-15 07:24:34
@_author: smb at research.att.com 
@_subject: NY UNIX Clipper Article 
Umm -- wasn't that story datelined February 11?
Think back 20 years -- it would have happened then, to history's most
famous unindicted co-conspirator, had not Ford pardoned him for anything
he might or might not (hah!) have done.  (Fortunately, Agnew had already

@_date: 1994-03-26 04:21:05
@_author: smb at research.att.com 
@_subject: a citation sought.. 
More precisely, it's special-purpose hardware, not NSA-scale computers.
See ftp.eff.org:/pub/EFF/Policy/Crypto/Misc/Technical/des_break.ps.gz.
There are other papers in that directory that you may find of interest.

@_date: 1994-03-26 05:40:27
@_author: smb at research.att.com 
@_subject: Digital Cash 
As someone else noted, ``crypto is all economics''.  In the New York
City subway system, the new fare card readers are all linked to a central
computer, specifically to prevent double spending.  They could have
used smart cards and fancy crypto -- but this is cheaper, especially
because they have an excellent handle on the maximum load -- the number
of subway riders at rush hour.  Fancy technology could get them into
an ``arms race'' with rip-off artists, who reverse-engineer cards,
crack algorithms, etc.
Digital cash -- which provide anonymity, as contrasted against
cryptographically-signed debit card transactions -- will become a
reality if and only if someone finds it more profitable than the
alternative, after deducting the costs for observer chips, licenses
for Chaum's patents, etc.  Some people are willing to pay for privacy --
but are there enough of them to make it pay?

@_date: 1994-03-28 06:48:18
@_author: smb at research.att.com 
@_subject: Ames/clipper compromised? 
Thanks much for posting.  I have a lot of trouble with much of the
article, though, on purely technical grounds.  Consider the following
What does it mean to ``compromise'' Clipper?  The algorithm is known?
No big deal, in my opinion -- Skipjack was almost certainly designed to
be strong even if the algorithm was known.  (As I've said before, I tend
to believe NSA on that point.  I suspect they're telling us the truth
about Clipper -- just not the whole truth -- and what they've said is
damning enough even if 100% accurate.)  It's also quite unlikely that
Ames would ever have seen the algorithm; it's just not something he'd
have any reason to know.
Might he have stolen the family key?  More plausible, though again it's
not something that would be left lying around, as opposed to being
embedded in equipment.  Could he have turned over a magic decoder box,
which would have to know that key?  Not at all unreasonable -- and the
decoder boxes are at a sufficiently early stage of design that they
may not yet be armored against tampering.  But from everything that's
been published, very few Clipper chips have been deployed so far.  It
would not be a major project to recall and rekey the devices.
Copies of the key escrow databases?  Same argument applies -- though if
that's what was stolen, we have to ask how he had access to ``both'' of
them.  I don't believe there have ever been any categorical statements
about how FISA access to Clipper conversations would be obtained.  See
above under ``whole truth''...
It may be, of course, that the episode has made the powers that be wonder
about the wisdom of keeping any such keys around.  There's been a very strong trend in recent years to avoid *any* sort of cryptography where
session keys live anywhere but inside sealed boxes, precisely to avoid
key theft.  (See Diffie's retrospective on public key technology for
more detailed discussion and some examples.)  And it's also why the
government doesn't want to use Clipper -- as opposed to Skipjack -- for
classified information.  So -- if the story is true, just what did Ames steal that would require
them to ``start over from scratch''?  Is there another back door?  That's
the only thing I can think of that would require such an action -- which
means that if they do hold off, there's a new topic to explore via FOIA
requests and the like.

@_date: 1994-03-28 15:37:52
@_author: smb at research.att.com 
@_subject: Ames/clipper compromised? 
Of course, we now know that changing the DES S-boxes isn't necessarily
easy.  Without knowing the details of Skipjack, we can't even start
to evaluate it.
The review committee will be looking at the key generation mechanism,
according to Steve Kent.  Not as good as publishing it, of course, and

@_date: 1994-03-30 19:17:19
@_author: smb at research.att.com 
@_subject: The dumbest question... 
They revealed the values of the S-box.  Unless the patent included
claimes relating to its design criteria, they didn't have to disclose
them.  Of course, then they wouldn't be protected if someone else were
to reinvent and use those criteria in a cipher that isn't covered by
other parts of the DES patent.
As several people have pointed out today, the two halves are 80 bits
apiece, and they're XORed together to make the full key.  You can't
do a brute-force search on 80 bits.

@_date: 1994-05-02 09:07:49
@_author: smb at research.att.com 
@_subject: So, what are we going to do? 
I sent the same reply privately.  But disks were used in a WWII voice
security system -- phonograph disks...
I just learned about this system a few weeks ago.  As anyone who has
read Kahn knows, the early secure voice systems weren't secure; trained
listeners could even understand the scrambled system.  Some folks at
Bell Labs were asked to design one that would work.
The eventual system -- known as SIGSALY, or as Project X (and the
end units were called X terminals, which is probably the only time
that phrase was ever used for something that is secure...) -- utilized
a vocoder and a one-time pad.  The one-time pad was recorded on two
high-quality phonograph records, each of which held 15 minutes of
keying information.
SIGSALY terminals were quite large -- they took up 30 seven-foot bays.
And they needed a *lot* of air conditioning.  But the system did work,
even over transoceanic radio links.  Churchill had one in his underground
office in London, in fact.
References are ``Secret Telephony as a Historical Example of Spread-
Spectrum Communication'', William R. Bennett, IEEE Trans. on Communications,
Vol 31, No. 1, Jan '83, and ``A History of Engineering and Science in
the Bell System:  National Service in War and Peace (1925-1975)''.

@_date: 1994-05-02 10:34:51
@_author: smb at research.att.com 
@_subject: Random #'s via serial port dongle? 
That isn't a matter of ``abstract hacker satisfaction''.  That's a very
strong security requirement:  how do you *know* that your keys are
Tim May suggested using Blum-Blum-Shub.  Fine -- but how are you going
to seed it?  That's why I want real random numbers -- as a seed to
Blum-Blum-Shub or quintuple IDEA or MD5 composed with SHS' or whatever.
I probably wouldn't use the random numbers in raw form, though -- and
no one else does, either; the real random number generators I've seen
all incorporate some sort of scrambling function.

@_date: 1994-05-03 06:39:15
@_author: smb at research.att.com 
@_subject: Digital Cash 
Well, maybe, though traffic analysis may be a problem.
I did hear of an interesting case of people paying for privacy in the real
world.  In Hong Kong, the Aberdeen tunnel has drive-through smart card
readers for tolls.  The problem is, these cards don't use a privacy-
protecting protocol.  And many folks there are worried about what will
happen come 1997.  So there's now a resale market -- stores buy toll
cards in quantity, and resell them over the counter, for cash.
This underscores what I've said in the past about anonymous digital
cash:  it's not going to go anywhere unless folks are willing to pay
a premium for privacy.  There are too many sound reasons for keeping
audit trails (debugging, fraud detection, marketing analysis, etc. --
and note that the first is an issue even for folks with the best intentions
in the word; note how many remailer operators have kept logs, at least
for a while); unless there's a profit motive in doing otherwise, most
folks won't.  In Hong Kong, the threat is not just real and imminent,
it's *perceived* as such.  Whether or not there is a real threat in, say,
the U.S. (let's please not debate that!), there's much less perception
of one.

@_date: 1994-05-06 04:48:40
@_author: smb at research.att.com 
@_subject: Clipper Key Escrow Details 
Anyone who has the right to do a wiretap under both Federal and state law.
That would include local police departments in very many states.
Nothing that I know of, though that's not certain.  Decryptions will
be done by a magic decode box; in theory, at least, the downloaded
key -- which will be Skipjack-encrypted -- could be accompanied by
a time-to-live field.  Last I heard, the decoder boxes hadn't been
completely designed yet.

@_date: 1994-05-06 06:58:41
@_author: smb at research.att.com 
@_subject: Linear Congruential Random Number Crackers.. 
``Cracking a Random Number Generator'', Jim Reeds, Cryptologia 1,1,
Jan '77.  It's also in ``Cryptology:  Yesterday, Today, and Tomorrow'',
edited by Deavours, Kahn, Kruh, Mellen, and Winkel.

@_date: 1994-05-06 16:49:42
@_author: smb at research.att.com 
@_subject: Putting new PGP on company machines. 
Two things come to mind.  First, some company lawyers may not like
the provisions of the RSAREF license.  At the very least, most companies
with on-staff lawyers would want them to glance at it.  Second, I've
never seen a comparable piece of electronic ``paper'' about IDEA.  Have
you seen something from the patent owners themselves?  Not that I have
any doubts -- but I've seen cases where lawyers demanded a paper trail
of agreements from the patent assignee of record as listed in the
Official Gazette.
The answers may be obvious to some folks on this list -- but most of
us aren't lawyers.

@_date: 1994-05-25 09:33:14
@_author: smb at research.att.com 
@_subject: Graph isomorphism based PK cryptosystems? 
Nothing.  Under current U.S. practice -- and I think non-U.S. as well --
his system is quite patentable.  Furthermore, patent applications in
the U.S. are confidential.  If jpp wants to patent it, he can.  If he
publishes first, he can only patent it in the U.S.  If someone else
has invented it first, they can file for a patent, or try to have jpp's
thrown out if he should file.  (The U.S., unlike the rest of the world,
has a first-to-invent rule for patents.)
But the one thing that's unconditionally barred is someone else filing
a patent on something jpp invents and publishes.

@_date: 1994-05-25 12:50:50
@_author: smb at research.att.com 
@_subject: Graph isomorphism based PK cryptosystems? 
Actually, no.  IBM has a separate publication for just that purpose.
The Technicnal Journal (and others like it) are intended as PR vehicles
and as gold stars for researchers -- that's an important part of our
salary, as it were.

@_date: 1994-05-25 13:33:37
@_author: smb at research.att.com 
@_subject: Graph isomorphism based PK cryptosystems? 
Etc.  Note that the patent office itself has a publication for
stuff that you don't want to patent.  I know of no better way
to get something into their files.

@_date: 1994-05-30 10:09:10
@_author: smb at research.att.com 
@_subject: Does Estonian RSA chip violate patents? 
There's a lot of confusion about what the RSA patent covers, and what's
prohibited by it.
Rivest, Shamir, and Adleman did not patent an algorithm.  Rather, they
patented a cryptographic communication system based on certain equations.
That means that it doesn't matter if you build it using software or
hardware -- if it's still a system using the mechanisms described by
their patent, it would infringe the patent in the U.S.
Both within and outside the U.S., RSA hardware is patentable to the
extent that the circuitry used is new, useful, and non-obvious.  But
what you're patenting is a circuit to do RSA, not RSA itself, of course.
(The circuit might actually be more general, i.e., a modular exponentiation
chip or some such -- in which case you'd be well advised to patent the
more general concept rather just its utility for RSA.)  That doesn't
mean you could use the circuit to do RSA in the U.S. without a license
from PKP.  A patent is *not* the right to do something; rather, it is
the right to prevent others from doing it.  But if the circuit did not
do only RSA, there's no reason why you couldn't sell it within the U.S.
without worrying about the RSA patent.
Finally, many folks have claimed that non-U.S. law does not permit
``algorithm'' patents.  That may very well be.  However -- there have
been a lot of patents like that that have been issued within Europe;
IDEA and Schnorr's signature algorithm come to mind.  Whether these
have been issued due to some quirks of the Patent Co-operation Treaty,
or whether they could be issued without that, or whether they'll stand
up in a European court, I couldn't say -- but the patents *are* being

@_date: 1997-02-01 15:55:53
@_author: Steven Bellovin 
@_subject: PCS Encryption? 
And an illegal wiretap besides, most likely -- with a warrant, they could
simply put the tap at the base station.  The story may be true, but it
doesn't sound quite right to me.
I recently got a TDMA phone (a Nokia 2160), which is capable of doing
some sort of encryption, though I'm not sure what algorithm.  It doesn't
always encrypt even when in digital mode (it can handle AMPS, too), but
there's a configuration option to tell the user whether or not encryption
is in use.

@_date: 1997-01-29 06:15:12
@_author: Steven Bellovin 
@_subject: Last nail for US crypto export policy? 
It is dangerously naive to label this success the ``last nail for US
crypto export policy''.  Everyone concerned with this issue, from the
NSA to the FBI to anyone who wants to use crypto, understands this
and accepts it.  40-bit keys are good for protection against casual
snooping, and nothing more -- and no one is going to claim that you
need supercomputers to crack them.  In fact, I assert that the U.S.
government is *happy* about these results -- because it's going to
push folks towards wanting stronger crypto for export.  The only problem,
of course, is the terms under which such code can be exported...
I'll go further -- in my opinion, the only reason the government doesn't
want DES to fall just yet is that alternatives aren't ready.  That is,
the banks and financial institutions, and for that matter the government
agencies, have not converted to 3DES or Clipper or what have you, and
can't do so on short notice; the commercial products they need just aren't
ready yet.  No one wants to risk a loss of confidence in the financial
system.  Two years from now, though, when some key escrow products are
ready, it may be a different story.

@_date: 1997-01-29 07:11:31
@_author: Steven Bellovin 
@_subject: Last nail for US crypto export policy? 
It is dangerously naive to label this success the ``last nail for US
crypto export policy''.  Everyone concerned with this issue, from the
NSA to the FBI to anyone who wants to use crypto, understands this
and accepts it.  40-bit keys are good for protection against casual
snooping, and nothing more -- and no one is going to claim that you
need supercomputers to crack them.  In fact, I assert that the U.S.
government is *happy* about these results -- because it's going to
push folks towards wanting stronger crypto for export.  The only problem,
of course, is the terms under which such code can be exported...
I'll go further -- in my opinion, the only reason the government doesn't
want DES to fall just yet is that alternatives aren't ready.  That is,
the banks and financial institutions, and for that matter the government
agencies, have not converted to 3DES or Clipper or what have you, and
can't do so on short notice; the commercial products they need just aren't
ready yet.  No one wants to risk a loss of confidence in the financial
system.  Two years from now, though, when some key escrow products are
ready, it may be a different story.

@_date: 1997-01-29 08:31:52
@_author: Steven Bellovin 
@_subject: Last nail for US crypto export policy? 
It is dangerously naive to label this success the ``last nail for US
crypto export policy''.  Everyone concerned with this issue, from the
NSA to the FBI to anyone who wants to use crypto, understands this
and accepts it.  40-bit keys are good for protection against casual
snooping, and nothing more -- and no one is going to claim that you
need supercomputers to crack them.  In fact, I assert that the U.S.
government is *happy* about these results -- because it's going to
push folks towards wanting stronger crypto for export.  The only problem,
of course, is the terms under which such code can be exported...
I'll go further -- in my opinion, the only reason the government doesn't
want DES to fall just yet is that alternatives aren't ready.  That is,
the banks and financial institutions, and for that matter the government
agencies, have not converted to 3DES or Clipper or what have you, and
can't do so on short notice; the commercial products they need just aren't
ready yet.  No one wants to risk a loss of confidence in the financial
system.  Two years from now, though, when some key escrow products are
ready, it may be a different story.

@_date: 1997-09-18 06:20:36
@_author: Steven Bellovin 
@_subject: National Security Committee amendments to SAFE 
I'm sure one of the real lawyers will add a lot more detail.  However...
The way something can be beyond judicial review is if it's purely an
executive branch function.  You can sue, of course, but in order to
overcome that argument you'd have to show that either the function
wasn't executive branch-specific, *or* some other constitutional right
is being violated.
To see how a judge can rule on such an issue, have a look at the trial
court's opinion in the Karn case.  You can find that opinion at
 according to Karn's page (I was
unable to confirm that link just now).

@_date: 1998-10-27 07:04:33
@_author: Steve Bellovin 
@_subject: log files (was: Re: dbts: Cryptographic Dog Stocks, The Dirigible Biplane, and Sending the Wizards Back to Menlo Park ) 
Leaving aside the rest of this discussion, Vin touches on a point that
I think has been ignored by some:  operations demand log files.  That
is -- and I'm doffing my security hat here and donning the hat of someone
who has been running computer systems and networks for 30+ years --
when I'm trying to manage a system and/or troubleshoot a problem,
I *want* log files, as many as I can get and cross-referenced 17 different
ways.  This isn't a security issue -- most system administrator headaches are
due to the "benign indifference of the universe", or maybe to Murphy's Law

@_date: 1998-10-29 02:10:58
@_author: Steve Bellovin 
@_subject: log files (was: Re: dbts: Cryptographic Dog Stocks, The Dirigible Biplane, and Sending the Wizards Back to Menlo Park ) 
In message <3.0.1.32.19981028093825.00a3f2d0 at pop.bos.platinum.com>, Hal Lockhar
Why do you assume that the flaw that lets the bad guy in is cryptographic?
I recently analyzed every CERT advisory ever issued.  85% of them
described problems that crypto couldn't fix.  Buffer overflow is the
culprit du jour, but it's hardly the only one.  (This year, the prize
for second place -- admittedly a distant second -- went to crypto modules.)
That's only a flaw if you assume that there are other weak points on
the Web server that a firewall can protect.  If you lock down the host
so that only port 80 is exposed (and maybe a cryptographically protected
administrative port), what good does the firewall do?  The weakest point
is probably the CGI scripts, and those have to be exposed in any event.
There are no panaceas, there is no single technology (and that emphatically
includes crypto) that will solve this problem.  Defense in depth is our
best hope, which means firewalls plus crypto plus IDS plus better operating
systems and programming languages.  Most of all, it means engineering a
solution -- making the right set of tradeoffs, even if unobvious.
Let me give an analogy.  On most electrical equipment, the ground pin
is useless -- *unless* there has been another insulation or air gap
failure within the device, a failure that would render the frame "hot".
But because of the ground pin, such a failure will instead short the
hot lead to ground, tripping the breaker.  It thus takes two failures
to electrocute someone.  *But* -- toasters and other devices with
exposed heating elements don't use this technique.  Why not?  Well,
with an exposed electrode, the probability of direct contact with a live
wire is much greater.  And if you ground the frame of the toaster,
there's now a direct, high-quality path to ground that in turn is
in contact with the other hand of the poor fool who is poking at a
piece of bread with a fork.  In other words, what's a safety mechanism
in your refrigerator is a danger in your toaster -- and sometimes,
that can be true of crypto as well.
For another analogy, think of insecurity as entropy.  You can't destroy
it, but you can move it around.  Using crypto moves the problem from
the (in)security of the links to the (in)security of the keys.  If
you can't protect your keys -- and that generally takes much more than
crypto -- using cryptography hasn't bought you anything.

@_date: 1998-09-18 13:52:37
@_author: Steve Bellovin 
@_subject: Questions for Magaziner? 
It is, of course, worth remembering that Magaziner is pretty much on
our side on this issue.  He just hasn't been able to win over Freeh,
Reno, Clinton, etc.

@_date: 2000-12-05 14:37:44
@_author: Steven M. Bellovin 
@_subject: IBM Uses Keystroke-monitoring in NJ Mob Case (was Re: BNA's Internet Law News (ILN) - 12/5/00)  
Very interesting, but what does IBM have to do with the case?  Did you mean to type "FBI"?

@_date: 2000-12-24 16:10:25
@_author: Steven M. Bellovin 
@_subject: About Gilmore's letter on IBM&Intel push copy protection into ordinary disk drives  
"Standard"?  It was more than that; it was the *right* thing to do.  On a diskless workstation, there was no other identity to the machine; if you didn't swap the ID prom -- which was used for the low-order 24 bits of the Ethernet address -- your machine wouldn't receive the proper boot image, etc.  Add to that the number of machines in the mid-to-late 80's that didn't have ARP, and it was utterly necessary.

@_date: 2000-10-11 10:25:21
@_author: Steven M. Bellovin 
@_subject: Rijndael & Hitachi  
In message <5.0.0.25.2.20001010154833.03a01b80 at ebible.org>, Michael Paul Johnso
Precisely.  What is the *real* threat model?
History does indeed show that believed-secure ciphers may not be, and that we do indeed need a safety margin.  But history shows even more strongly that there are many better ways to the plaintext, and that's the real goal.

@_date: 2001-01-15 12:55:01
@_author: Steven M. Bellovin 
@_subject: Voice over OTP during WW2.  
In message There's an exhibit on this system in the War Room museum in London.

@_date: 2001-07-27 14:13:40
@_author: Steven M. Bellovin 
@_subject: Criminalizing crypto criticism  
It's certainly not broad enough -- it protects "encryption" research, and the definition of "encryption" in the law is meant to cover just that, not "cryptography".  And the good-faith effort to get permission is really an invitation to harrassment, since you don't have to actually get permission, merely seek it.

@_date: 2002-06-20 15:19:08
@_author: Steven M. Bellovin 
@_subject: DOJ proposes US data-rentention law.  
This isn't clear.  The proposals I've seen call for recording "transaction data" -- i.e., the SMTP "envelope" information, plus maybe the From: line.  It does not call for retention of content.
Apart from practicality, there are constitutional issues.  Envelope data is "given" to the ISP in typical client/server email scenarios, while content is end-to-end, in that it's not processed by the ISP.  A different type of warrant is therefore needed to retrieve the latter.  The former falls under the "pen register" law (as amended by the Patriot Act), and requires a really cheap warrant.  Email content is considered a full-fledged wiretap, and requires a hard-to-get court order, with lots of notice requirements, etc.  Mandating that a third party record email in this situation, in the absence of a pre-existing
warrant citing probable cause, would be very chancy.  I don't think even the current Supreme Court would buy it.

@_date: 2002-11-07 15:55:26
@_author: Steven M. Bellovin 
@_subject: Did you *really* zeroize that key?  
In message <200211070207.PAA88426 at ruru.cs.auckland.ac.nz>, Peter Gutmann writes
Regardless of whether one uses "volatile" or a pragma, the basic point remains:  cryptographic application writers have to be aware of what a clever compiler can do, so that they know to take countermeasures.

@_date: 2003-06-01 12:59:53
@_author: Steven M. Bellovin 
@_subject: [spam] Re: Nullsoft's WASTE communication system  
In message , "John Brothers"
It doesn't matter if the GPL statement wasn't inserted by the real owner of the work.  Note that the employees almost certainly do not own the "work for hire" -- it would be Nullsoft/AOL Time Warner that does.

@_date: 2003-06-08 21:39:12
@_author: Steven M. Bellovin 
@_subject: An attack on paypal  
In message <4.2.2.20030608173129.00a99bb0 at mail.earthlink.net>, Anne & Lynn Whee
One could argue that that's because of https...
More seriously, eavesdropping on passwords was a *very* big problem starting in late 1993.  Part of the problem was that ISPs then didn't know better than to put NOC workstations on their backbone LANs; when those were compromised, the attackers had wonderfully-placed eavesdropping stations.

@_date: 2003-06-11 16:06:55
@_author: Steven M. Bellovin 
@_subject: An attack on paypal  
In message <200306111913.h5BJDPV1004648 at gungnir.fnal.gov>, "Matt Crawford" writ
You can also use *.fnal.gov

@_date: 2003-06-28 23:15:45
@_author: Steven M. Bellovin 
@_subject: Attacking networks using DHCP, DNS - probably kills DNSSEC  
No, that's just not true of DNSsec.  DNSsec doesn't depend on the integrity of the connection to your DNS server; rather, the RRsets are digitally signed.  In other words, it works a lot like certificates, with a trust chain going back to a magic root key.  I'm not saying that there can't be problems with that model, but compromised DNS servers (and poisoned DNS caches) are among the major threat models it was designed to deal with.  If nothing else, the existence of caching DNS servers, which are not authoritative for the information they hand out, makes a transmission-based solution pretty useless.

@_date: 2003-06-29 21:46:49
@_author: Steven M. Bellovin 
@_subject: Attacking networks using DHCP, DNS - probably kills DNSSEC  
I can pretty much guarantee that the IETF will never standardize that, except possibly in conjunction with authenticated dhcp.

@_date: 2003-03-05 14:30:54
@_author: Steven M. Bellovin 
@_subject: Wiretap Act Does Not Cover Message 'in Storage' For Short Period (was Re: BNA's Internet Law News (ILN) - 2/27/03)  
In message , "R. A. Hettinga" wr
No, that's not waht the decision means.  Access to stored messages also requires court permission.  The (U.S.) ban on wiretapping without judicial
permission is rooted in a Supreme Court decision, Katz v. United States,
389 U.S. 347 (1967) which held that a wiretap is a search which thus required a warrant.  I don't think there's ever been any doubt that seizing a stored message required a warrant.  But in an old case (OLMSTEAD v. U.S., 277 U.S. 438 (1928))
the Court had held that the Fourth Amendment only protected material things, and therefore *not* conversations monitored via a wiretap.  That decision was overturned in Katz.
The crucial difference, from a law enforcement perspective, is how hard it is to get the requisite court order.  A stored message order is relatively easy; a wiretap order is very hard.  Note that this distinction is primarily statutory, not (as far as I know) constitutional.

@_date: 2003-05-13 11:30:31
@_author: Steven M. Bellovin 
@_subject: economics of spam (Re: A Trial Balloon to Ban Email?)  
In message <200305130152.h4D1qC1F007097 at syn.hamachi.org>, Bill Sommerfeld write
The spammers are doing that and more.  For example, recent traffic on the NANOG list suggests that they are using false BGP advertisements on stolen address blocks to shoot and run.  (There is a proposal to stop that via cryptographic authentication of BGP advertisements, but SBGP hasn't gotten any traction with most of the operator community yet.  Just why is a subject for a separate thread.)

@_date: unknown_date
@_author: smb at research.att.com 
@_subject: technical information on Clipper 
Return-Path: ISL.Stanford.EDU!hellman
Received: by research.att.com; Sun Apr 18 02:06 EDT 1993
Received: by inet.att.com; Sun Apr 18 02:06 EDT 1993
Received:  by ISL.Stanford.EDU (4.1/25-eef) id AA22827; Sat, 17 Apr 93 23:05:23 PDT
Message-Id: <9304180605.AA22827 at ISL.Stanford.EDU>
        adw at research.att.com, amo at research.att.com, bach at cs.wisc.edu,
        berson at sri.com, biham at cs.technion.ac.il, branstad at st1.ncsl.nist.gov,
        brassard at iro.umontreal.ca, burt at rsa.com, carl at joe.math.uga.edu,
        caronni at nessie.cs.id.ethz.ch, clipper at csrc.ncsl.nist.gov,
        denning at cs.cosc.georgetown.edu, diffie at eng.sun.com,
        eor at ISL.Stanford.EDU, erdmann at leland, fahn at cs,
        gfung%ccm.UManitoba.CA at cornellc.cit.cornell.edu, gill at ISL.Stanford.EDU,
        gormish at ISL.Stanford.EDU, infort%czheth5a.BITNET at forsythe.stanford.edu,
        jeffr at sco.com, jhwang at ISL.Stanford.EDU, jim at rsa.com,
        jwarren at well.sf.ca.us, jwolf at ucsd.edu, kurlberg at leland,
        langford at ISL.Stanford.EDU, lenstra at flash.bellcore.com, markoff at nyt.com,
        matt at rsa.com, merkle at xerox.com, minnieho at ISL.Stanford.EDU,
        mitran at asic.sc.ti.com, ovseev at ippi.msk.su, rivest at theory.lcs.mit.edu,
        roche at ISL.Stanford.EDU, rotenberg at washofc.cpsr.org,
        scholtz at jimmie.usc.edu, shamir%wisdom.bitnet at forsythe,
        smb at research.att.com, taher at rsa.com, voois at ISL.Stanford.EDU,
        welch at irving.usc.edu, wesel at ISL.Stanford.EDU
Most of you have seen the announcement in Friday's NY Times,
etc. about NIST (National Institute of Standards & Technology)
announcing the "Clipper Chip" crypto device. Several messges
on the net have asked for more technical details, and some have
been laboring under understandable misunderstandings given
the lack of details in the news  articles. So here to help out
is your friendly NSA link: me. I was somewhat surprised Friday
to get a call from the Agency which supplied many of the missing
details. I was told the info was public, so here it is (the cc of this
to Dennis Branstad at NIST is mostly as a double check on my
facts since I assume he is aware of all this; please let me know
if I have anything wrong):
The Clipper Chip will have a secret crypto algorithm embedded in Silicon. Each chip will have two secret, 80-bit keys. One will be the same for all chips (ie a system-wide key) and the other will be unit specific. I don't know what NIST and NSA will call them, but I will call them the system key SK and unit key UK in this message. The IC will be designed to be extremely difficult to reverse so that the system key can be kept secret. (Aside: It is clear that they also want to keep the algorithm secret and, in my opinion, it may be as much for that as this stated purpose.) The unit key will be generated as the XOR of two 80-bit random numbers K1 and K2 (UK=K1+K2) which will be kept by the two escrow authorities. Who these escrow authorities will be is still to be decided by the Attorney General, but it was stressed to me that they will NOT be NSA or law enforcement agencies, that they must be parties acceptable to the users of the system as unbiased. When a law enforcement agency gets a court order, they will present it to these two escrow authorities and receive K1 and K2, thereby allowing access to the unit key UK.
In addition to the system key, each user will get to choose his or her own key and change it as often as desired. Call this key plain old K. When a message is to be sent it will first be encrypted under K, then K will be encrypted under the unit key UK, and the serial number of the unit added to produce a three part message which will then be encrypted under the system key SK      E{ E[M; K], E[K; UK], serial number;  SK}
When a court order obtains K1 and K2, and thence K, the law enforcement agency will use SK to decrypt all information flowing on the suspected link [Aside: It is my guess that they may do this constantly on all links, with or without a court order, since it is almost impossible to tell which links over which a message will flow.] This gives the agency access to      E[M; K], E[K; UK], serial number
in the above message. They then check the serial number of the unit and see if it is on the "watch list" for which they have a court order. If so, they will decrypt E[K; UK] to obtain K, and then decrypt E[M; K] to obtain M.
I am still in the process of assessing this scheme, so please do not take the above as any kind of endorsement of the proposed scheme. All I am trying to do is help all of us assess the scheme more knowledgably. But I will say that the need for just one court order worries me. I would feel more comfortable (though not necessarily comfortable!) if two separate court orders were needed, one per escrow authority. While no explanation is
needed, the following story adds some color: In researching
some ideas that Silvio Micali and I have been kicking around,
I spoke with Gerald Gunther, the constitutional law expert
here at Stanford and he related the following story: When
Edward Levi became Pres. Ford's attorney general (right
after Watergate), he was visited by an FBI agent asking
for "the wiretap authorizations." When Levy asked for
the details so he could review the cases as required by
law, the agent told him that his predecessors just turned
over 40-50 blank, signed forms every time. Levi did not
comply and changed the system, but the lesson is clear: No single person or authority should have the power to
authorize wiretaps (or worse yet, divulging of personal
keys). Sometimes he or she will be an Edward Levi
and sometimes a John Mitchell.
Martin Hellman
------- End of Forwarded Message

@_date: unknown_date
@_author: smb at research.att.com 
@_subject: correction from Hellman 
Here's a follow-up note from Hellman, in response to a question I sent
(and also in response to my request to post his original note to
------- Forwarded Message
It is fine to post my previous message to sci.crypt if you also post this message with it in which:
1. I ask recipients to be sparse in their requesting further info from me or asking for comments on specific questions. By
this posting I apologize for any messages I am unable to
respond to. (I already spend too much time answering too much
e-mail and am particularly overloaded this week with other
responsibilities.) 2. I note a probably correction sent to me by Dorothy Denning.
She met with the person from NSA that
I talked with by phone, so her understanding is likely to
better than mine on this point: Where I said the transmitted
info is  E{ E[M; K], E[K; UK], serial number;  SK}
she says the message is not double encrypted. The system
key (or family key as she was told it is called) only encrypts
the serial number or the serial number and the encrypted
unit key. This is not a major difference, but I thought it
should be mentioned and thank her for bringing it to
my attention. It makes more sense since it cuts down
on encryption computation overhead.
------- End of Forwarded Message
