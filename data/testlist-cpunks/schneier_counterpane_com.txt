
@_date: 1996-08-16 08:24:43
@_author: Bruce Schneier 
@_subject: Can someone validate this code? 
This looks like something that was anonymously posted to the Internet
about a year ago.  It is widely believed to be a hoax; if nothing else,
the key schedule is horrible.  David Wagner broke the algorithm based
on the key schedule alone.
This is what I wrote about S-1 last time around....
I was in Europe while S-1 was posted, so I missed most of the
discussion.  Better late than never....
Over the last year, I have spent considerable effort collecting
SKIPJACK information.  I have gone through the published
literature, the rumors, and a large stack of documents received
by EPIC through Freedom of Information Act (FOIA) lawsuits.
At Crypto last week I gave a Rump Session talk entitled "Reverse
Engineering SKIPJACK from Open Sources."  I prepared the slides
before I left for Europe.  Here is what I said:
     What the government told us:
          Single-key block cipher.
          Can be used in ECB, CBC, CFB, or OFB.
          64-bit block size.
          80-bit key size.
     What the review committee told us:
          32 rounds.
          No weak keys (like DES has).
          No key complementation property (like DES has).
     What the hardware specifications tell us:
          The latency of the Mykotronx chip has 64 clock cycles.
               This means two clock cycles per round.
     Assorted rumors (excuse me if I don't reveal sources):
          SKIPJACK does not have rounds in the same sense that
               DES does: i.e., half of the text block is not
               encrypted in each round.
          SKIPJACK has half the total S-box data as DES.
          SKIPJACK has a 48-bit internal structure analogous to a
               32-bit internal structure in DES.
          The masks for the Clipper/Capstone chip are
               unclassified and the chips can be produced in an
               unclassified foundry.  Part of the programming in
               the secure vault includes installing part of the
               SKIPJACK algorithm.  The part of the algorithm
               installed in the secure vault are the "S-tables",
               suggesting that perhaps unprogrammed Clipper chips
               can be programmed to implement other 80-bit key,
               32 round ciphers.
Trying to puzzle out the meaning of the third rumor, Matt Blaze
and I invented something called an Unbalanced Feistel Network.
These are Feistel networks where the source and target blocks are
of different size.  For example, in each round 48 bits might be
used as an input into the F function, and produce 16 output bits
to be XORed with the remainder of the bits.  We called this a
48:16 UFN, and we proposed a design at last year's Algorithms
Workshop in Leuven.  Our design was broken, but I am still
examining the structure.  A 48:16 UFN satisfies the first and
third rumor above, and I think it as good a guess as any
regarding SKIPJACK.
A few months ago, I found some additional information in the form
of documents released under FOIA.  One document was a Mykotronx
design review for "Project Capstone" dated 10 December 1991.  The
design review was unclassified.  Among the details about the
modular multipliers and the SHA code was the following page about
     ECB Processing Rate
          2 clocks per G-Box operation
          x 1 G-box per shift
          x 32 shifts per ECB encryption
          ______________________________
          64 clocks per ECB
     64 clocks per ECB / 64 bits out per ECB = 1 clock per bit
     Yields 40 Mbit encryption using a 40 MHz clock.
The only other thing I found was a SECRET memo.  The organization
name (either from or to) is blacked out.  The date is 25 August
1992.  The subject is "SKIPJACK Revision."  Paragraph 2 is
blacked out, but paragraph 1 reads:
     1.  (U) The enclosed Informal Technical Report revises the
     F-table in SKIPJACK 3.  No other aspect of the algorithm is
     changed.
That's it.  Rounds are called "shifts," which seems to indicate
that they are not "rounds" in the DES sense.  A shift consists of
a "G-box" operation, which includes not only what we call the F-
F-function but the XOR as well.  And there is something called an
F-table, which could be a table of constants or perhaps a table
of functions.  In any case, it is something that can be revised
without changing the rest of the algorithm.
Now let's look at S-1.  The most probable explanation is that it
is a hoax.  But it is a very good hoax:
     The hoaxer knew enough about algorithm design to make a
          cipher that was not obviously lousy, while at the same
          time not unduly complicated.  The hoaxer knew enough to
          make a design that included three novel ideas not seen
          anywhere else: S-boxes that are created according to no
          known criteria, a G-table that chooses a rotation of
          S-boxes to use in a given round, and a bizarre key
          schedule.
     The hoaxer knew enough about how algorithms are used in the
          military to make a spookish interface.  I am
          particularly interested in the "zeroize" function, the
          separation of the key creation and key loading
          functions, and the key masking.  Blaze said that the
          interface was similar to the Fortezza interface, but
          not the same.
     The hoaxer knew about Blaze's and my MacGuffin paper and
          that we thought SKIPJACK was a 48:16 UFN.  We made no
          secret about this, and our paper is on Blaze's web
          page.  The hoaxer knew to use the term F-table.  I
          haven't shown many people what I found in EPIC's
          documents, so the hoaxer either had to look through
          them himself or get them by some other means (maybe an
          independent FOIA request).
It's not a perfect hoax, though.  The classification markings
look odd: NSA algorithms are SECRET, not TOP SECRET, and the
codeword restriction sentence is strange.  The key schedule is
hopelessly flawed (David Wagner posted an attack to sci.crypt).
The coding style is amateurish, like it was translated from one
language to another.  (Maybe this is clever on the hoaxer's
part.)  And there's even a typo in the code.
And maybe the hardware latency is wrong.  Clearly the design
facilitates parallelization.  You can precompute all possible F-
table outputs in previous shifts, and then use the G-table result
to select between them; I am not sure you can get a shift down to
two clock cycles.  I don't have the hardware background, and
would appreciate comments from others.
And why are there not bitwise permutations?  If SKIPJACK is
designed for hardware, it makes sense to put them in.  They're
free, after all.
Anyway, it's a real good hoax.  Blaze estimated that he could
have done it, but it would have taken him a month of effort.  I
agree with his assessment: one man-month.  It's a lot of time to
spend on a hoax, especially one where the hoaxer doesn't get any
So, maybe it's SKIPJACK.  It has a 64-bit block size and an 80-
bit key size.  It's a 48:16 UFN with 32 rounds (or shifts, or
whatever).  And it has an F-table.  This is really interesting,
because the structure really is an S-box.  Everyone knows it's an
S-box, and it makes no sense for a hoaxer to call it something
else.  But in S-1 it's called an F-table.  (I think this is very
significant, but others find it less convincing.)
And the F-table has been revised at least once.  In the code it
says that the F-table entries "differ in the S-2 version."  The
code is dated 1 February 1989 and 31 July 1991, and I have a memo
dated 25 August 1992 that says the F-table has been revised in
"SKIPJACK 3."  Pretty convincing, I think.  (Of course this means
that we can't confirm anything by testing the hardware, since the
F-table entries are different.)
Maybe there are no bit permutations because they make analysis
harder, and perhaps they don't add all that much.  Maybe the
algorithm was designed for both hardware and software, or maybe
it was designed for specialized cryptographic hardware with
several parallel microprocessors and some cryptographic
If it is real, we have a lot to learn about S-box design.  The S-
boxes are not even balanced.  Maybe they are created just so to
avoid some bizarre attack we can only dream about, but I kind of
doubt it.
But the key schedule is just plain wrong.
So, here's a theory.  Let's assume the code is real.  (Not that
it's SKIPJACK, but that it's a real algorithm from some military
or some corporation.)  Clearly the code is not designed to test
the cryptographic algorithm, but to simulate some kind of
hardware interface: it's called a "software chip simulator."  If
I were the NSA and I designed an algorithm whose security rested
on some tables of constants, I might replace them with phony
constants before giving them to another organization to test.  I
might call the phony version S-1 and the real version S-2.
Maybe the code was originally written in FORTRAN, and then
translated into C.  (NSA doesn't use ADA.)
NSA algorithms are classified SECRET, put perhaps algorithms in
development are classified TOP SECRET.  (We know cryptanalytic
techniques can be TOP SECRET, so perhaps commented code falls
under that category as well.)
And maybe the code originally didn't have an 80-bit key schedule.
Maybe it had a longer key schedule.  The poster then modified
this key schedule to make it look more like SKIPJACK.  (This
might also explain the bug in the code, which might not be a bug
if it still had the original key schedule.)
Which leaves us precisely nowhere.  The most likely explanation
is that it is a hoax, but I am hard-pressed to imagine a hoaxer
with the requisite combination of skills, resources, and
attitude.  I also don't believe that it is SKIPJACK.  It might be
a preliminary design for SKIPJACK, but if both the key schedule
and F-table entries are wrong, we really haven't learned
anything.  If we suddenly discovered that unbalanced S-boxes are
far superior to balanced ones, then all best are off.
* Bruce Schneier              APPLIED CRYPTOGRAPHY, 2nd EDITION is
* Counterpane Systems         available.  For info on a 15%
* schneier at counterpane.com    discount offer, send me e-mail.
* For Blowfish C code, see ftp.ox.ac.uk:/pub/crypto/misc/blowfish.c.gz

@_date: 1996-12-06 06:23:21
@_author: Bruce Schneier 
@_subject: DES in IBM 730 Assembler and/or COBOL 
I need a DES (preferrably public domain, but I will pay for it) in IBM 730
assembler and COBOL.  Anybody know of one?
* Bruce Schneier            2,000,000,000,000,000,000,000,000,002,000,
* Counterpane Systems       000,000,000,000,000,000,002,000,000,002,293
* schneier at counterpane.com  The last prime number...alphabetically!
* (612) 823-1098            Two vigintillion, two undecillion, two
* 101 E Minnehaha Pkwy      trillion, two thousand, two hundred and
* Minneapolis, MN  55419    ninety three.
*

@_date: 1996-06-26 03:25:29
@_author: Bruce Schneier 
@_subject: I am looking to hire a crypto person.... 
I am looking to hire someone part-time (with potential to upgrade to
full-time) to work for Counterpane Systems, doing cryptography consulting
for a variety of clients.
The work is in analysis and design, mostly of cryptographic and security
systems.  Think of SSL, SPKI, PGP... that sort of thing.  There isn't a
whole lot of math, just critical thinking, complete analysis, and good
If anyone is interested, please send me mail.  (Depending on the number of
responses received, I may have some kind of application test.)
* Bruce Schneier            2,000,000,000,000,000,000,000,000,002,000,
* Counterpane Systems       000,000,000,000,000,000,002,000,000,002,293
* schneier at counterpane.com  The last prime number...alphabetically!
* (612) 823-1098            Two vigintillion, two undecillion, two
* 101 E Minnehaha Pkwy      trillion, two thousand, two hundred and
* Minneapolis, MN  55419    ninety three.

@_date: 1996-11-11 13:53:17
@_author: Bruce Schneier 
@_subject: Why Cryptography is Harder than it Looks (LONG) 
WHY CRYPTOGRAPHY IS HARDER THAN IT LOOKS
Bruce Schneier, Counterpane Systems
Copyright Nov 1996 by Bruce Schneier.  All rights reserved.  Permission is
given to distribute this essay, providing that it is distributed in its
entirety (including this copyright notice).  For more information on
Counterpane Systems's cryptography and security consulting, see
cash, cryptography is an essential part of today's information systems.
Cryptography helps provide accountability, fairness, accuracy, and
confidentiality.  It can prevent fraud in electronic commerce and assure
the validity of financial transactions.  It can prove your identity or
protect your anonymity.  It can keep vandals from altering your Web page
and prevent industrial competitors from reading your confidential
documents.  And in the future, as commerce and communications continue to
move to computer networks, cryptography will become more and more vital.
But the cryptography now on the market doesn't provide the level of
security it advertises.  Most systems are not designed and implemented in
concert with cryptographers, but by engineers who thought of cryptography
as just another component.  It's not.  You can't make systems secure by
tacking on cryptography as an afterthought.  You have to know what you are
doing every step of the way, from conception through installation.
Billions of dollars are spent on computer security, and most of it is
wasted on insecure products.  After all, weak cryptography looks the same
on the shelf as strong cryptography.  Two e-mail encryption products may
have almost the same user interface, yet one is secure while the other
permits eavesdropping.  A comparison chart may suggest that two programs
have similar features, although one has gaping security holes that the
other doesn't.  An experienced cryptographer can tell the difference.  So
can a thief.
Present-day computer security is a house of cards; it may stand for now,
but it can't last.  Many insecure products have not yet been broken because
they are still in their infancy.  But when these products are widely used,
they will become tempting targets for criminals.  The press will publicize
the attacks, undermining public confidence in these systems.  Ultimately,
products will win or lose in the marketplace depending on the strength of
their security.
THREATS TO COMPUTER SYSTEMS
Every form of commerce ever invented has been subject to fraud, from rigged
scales in a farmers' market to counterfeit currency to phony invoices.
Electronic commerce schemes will also face fraud, through forgery,
misrepresentation, denial of service, and cheating.  In fact,
computerization makes the risks even greater, by allowing attacks that are
impossible against non-automated systems.  A thief can make a living
skimming a penny from every Visa cardholder.  You can't walk the streets
wearing a mask of someone else's face, but in the digital world it is easy
to impersonate others.  Only strong cryptography can protect against these
Privacy violations are another threat.  Some attacks on privacy are
targeted:  a member of the press tries to read a public figure's e-mail, or
a company tries to intercept a competitor's communications.  Others are
broad data-harvesting attacks, searching a sea of data for interesting
information: a list of rich widows, AZT users, or people who view a
particular Web page.
Electronic vandalism is an increasingly serious problem. Computer vandals
have already graffitied the CIA's web page, mail-bombed Internet providers,
and canceled thousands of newsgroup messages.  And of course, vandals and
thieves routinely break into networked computer systems.  When security
safeguards aren't adequate, trespassers run little risk of getting caught.
Attackers don't follow rules; they cheat.  They can attack a system using
techniques the designers never thought of.  Art thieves have burgled homes
by cutting through the walls with a chain saw.  Home security systems, no
matter how expensive and sophisticated, won't  stand a chance against this
attack.  Computer thieves come through the walls too.  They steal technical
data, bribe insiders, modify software, and collude.  They take advantage of
technologies newer than the system, and even invent new mathematics to
attack the system with.
The odds favor the attacker.  Bad guys have more to gain by examining a
system than good guys.  Defenders have to protect against every possible
vulnerability, but an attacker only has to find one security flaw to
compromise the whole system.
WHAT CRYPTOGRAPHY CAN AND CAN'T DO
No one can guarantee 100% security.  But we can work toward 100% risk
acceptance.  Fraud exists in current commerce systems:  cash can be
counterfeited, checks altered, credit card numbers stolen.  Yet these
systems are still successful because the benefits and conveniences outweigh
the losses.  Privacy systems -- wall safes, door locks, curtains -- are not
perfect, but they're often good enough.  A good cryptographic system
strikes a balance between what is possible and what is acceptable.
Strong cryptography can withstand targeted attacks up to a point -- the
point at which it becomes easier to get the information some other way.  A
computer encryption program, no matter how good, will not prevent an
attacker from going through someone's garbage.  But it can prevent
data-harvesting attacks absolutely; no attacker can go through enough trash
to find every AZT user in the country.  And it can protect communications
against non-invasive attacks: it's one thing to tap a phone line from the
safety of the telephone central office, but quite another to break into
someone's house to install a bug.
The good news about cryptography is that we already have the algorithms and
protocols we need to secure our systems.  The bad news is that that was the
easy part; implementing the protocols successfully requires considerable
expertise.  The areas of security that interact with people -- key
management, human/computer interface security, access control -- often defy
analysis.  And the disciplines of public-key infrastructure, software
security, computer security, network security, and tamper-resistant
hardware design are very poorly understood.
Companies often get the easy part wrong, and implement insecure algorithms
and protocols.  But even so, practical cryptography is rarely broken
through the mathematics; other parts of systems are much easier to break.
The best protocol ever invented can fall to an easy attack if no one pays
attention to the more complex and subtle implementation issues.  Netscape's
security fell to a bug in the random-number generator.  Flaws can be
anywhere: the threat model, the system design, the software or hardware
implementation, the system management.  Security is a chain, and a single
weak link can break the entire system.  Fatal bugs may be far removed from
the security portion of the software; a design decision that has nothing to
do with security can nonetheless create a security flaw.
Once you find a security flaw, you can fix it.  But finding the flaws in a
product can be incredibly difficult.  Security is different from any other
design requirement, because functionality does not equal quality.  If a
word processor prints successfully, you know that the print function works.
Security is different; just because a safe recognizes the correct
combination does not mean that its contents are secure from a safecracker.
No amount of general beta testing will reveal a security flaw, and there's
no test possible that can prove the absence of flaws.
THREAT MODELS
A good design starts with a threat model: what the system is designed to
protect, from whom, and for how long. The threat model must take the entire
system into account -- not just the data to be protected, but the people
who will use the system and how they will use it.  What motivates the
attackers?  Must attacks be prevented, or can they just be detected?  If
the worst happens and one of the fundamental security assumptions of a
system is broken, what kind of disaster recovery is possible?  The answers
to these questions can't be standardized; they're different for every
system.  Too often, designers don't take the time to build accurate threat
models or analyze the real risks.
Threat models allow both product designers and consumers to determine what
security measures they need.  Does it makes sense to encrypt your hard
drive if you don't put your files in a safe?  How can someone inside the
company defraud the commerce system?  How much would it cost to defeat the
tamper-resistance on the smart card?  You can't design a secure system
unless you understand what it has to be secure against.
SYSTEM DESIGN
Design work is the mainstay of the science of cryptography, and it is very
specialized.  Cryptography blends several areas of mathematics: number
theory, complexity theory, information theory, probability theory, abstract
algebra, and formal analysis, among others.  Few can do the science
properly, and a little knowledge is a dangerous thing: inexperienced
cryptographers almost always design flawed systems.  Good cryptographers
know that nothing substitutes for extensive peer review and years of
analysis.  Quality systems use published and well-understood algorithms and
protocols; using unpublished or unproven elements in a design is risky at
Cryptographic system design is also an art.  A designer must strike a
balance between security and accessibility, anonymity and accountability,
privacy and availability.  Science alone cannot prove security; only
experience, and the intuition born of experience, can help the
cryptographer design secure systems and find flaws in existing designs.
There is an enormous difference between a mathematical algorithm and its
concrete implementation in hardware or software.  Cryptographic system
designs are fragile.  Just because a protocol is logically secure doesn't
mean it will stay secure when a designer starts defining message structures
and passing bits around.  Close isn't close enough; these systems must be
implemented exactly, perfectly, or they will fail.  A poorly-designed user
interface can make a hard-drive encryption program completely insecure.  A
false reliance on tamper-resistant hardware can render an electronic
commerce system all but useless.  Since these mistakes aren't apparent in
testing, they end up in finished products.  Many flaws in implementation
cannot be studied in the scientific literature because they are not
technically interesting.  That's why they crop up in product after product.
Under pressure from budgets and deadlines, implementers use bad
random-number generators, don't check properly for error conditions, and
leave secret information in swap files. The only way to learn how to
prevent these flaws is to make and break systems, again and again.
CRYPTOGRAPHY FOR PEOPLE
In the end, many security systems are broken by the people who use them.
Most fraud against commerce systems is perpetrated by insiders.  Honest
users cause problems because they usually don't care about security.  They
want simplicity, convenience, and compatibility with existing (insecure)
systems.  They choose bad passwords, write them down, give friends and
relatives their private keys, leave computers logged in, and so on.  It's
hard to sell door locks to people who don't want to be bothered with keys.
A well-designed system must take people into account.
Often the hardest part of cryptography is getting people to use it.  It's
hard to convince consumers that their financial privacy is important when
they are willing to leave a detailed purchase record in exchange for one
thousandth of a free trip to Hawaii.  It's hard to build a system that
provides strong authentication on top of systems that can be penetrated by
knowing someone's mother's maiden name.  Security is routinely bypassed by
store clerks, senior executives, and anyone else who just needs to get the
job done.  Only when cryptography is designed with careful consideration of
users' needs and then smoothly integrated, can it protect their systems,
resources, and data.
THE STATE OF SECURITY
Right now, users have no good way of comparing secure systems.  Computer
magazines compare security products by listing their features, not by
evaluating their security.  Marketing literature makes claims that are just
not true; a competing product that is more secure and more expensive will
only fare worse in the market.  People rely on the government to look out
for their safety and security in areas where they lack the knowledge to
make evaluations -- food packaging, aviation, medicine.  But for
cryptography, the U.S. government is doing just the opposite.
When an airplane crashes, there are inquiries, analyses, and reports.
Information is widely disseminated, and everyone learns from the failure.
You can read a complete record of airline accidents from the beginning of
commercial aviation.  When a bank's electronic commerce system is breached
and defrauded, it's usually covered up.  If it does make the newspapers,
details are omitted.  No one analyzes the attack; no one learns from the
mistake.  The bank tries to patch things in secret, hoping that the public
won't lose confidence in a system that deserves no confidence.  In the long
run, secrecy paves the way for more serious breaches.
Laws are no substitute for engineering.  The U.S. cellular phone industry
has lobbied for protective laws, instead of spending the money to fix what
should have been designed corectly the first time.  It's no longer good
enough to install security patches in response to attacks.  Computer
systems move too quickly; a security flaw can be described on the Internet
and exploited by thousands.  Today's systems must anticipate future
attacks.  Any comprehensive system -- whether for authenticated
communications, secure data storage, or electronic commerce -- is likely to
remain in use for five years or more.  It must be able to withstand the
future:  smarter attackers, more computational power, and greater
incentives to subvert a widespread system.  There won't be time to upgrade
them in the field.
History has taught us:  never underestimate the amount of money, time, and
effort someone will expend to thwart a security system.  It's always better
to assume the worst.  Assume your adversaries are better than they are.
Assume science and technology will soon be able to do things they cannot
yet.  Give yourself a margin for error.  Give yourself more security than
you need today.  When the unexpected happens, you'll be glad you did.
Bruce Schneier       schneier at counterpane.com

@_date: 1996-11-14 12:51:11
@_author: Bruce Schneier 
@_subject: New Website: Bruce Schneier, Applied Cryptography, Blowfish,Counterpane 
I finally have a Website:
    On the site I have information on Applied Cryptography, Blowfish,
Counterpane Systems consulting, and more.  The site has the latest errata,
information on ordering the book and source code disks, and the final copy
of "Why Cryptography is Harder Than it Looks."
If you have a website that mentions Bruce Schneier, Applied Cryptography,
Blowfish, or Counterpane Systems, please point to my website.  If you sell
or give away a product that uses Blowfish, please let me know so that I can
point to it.  If you are running an ftp server that has the Blowfish code
available, please tell me so that I can send people to you.
* Bruce Schneier                 For information on APPLIED CRYPTOGRAPHY
* Counterpane Systems            2nd EDITION (15% discount and errata),
* schneier at counterpane.com       Counterpane Systems's consulting services,
*     or the Blowfish algorithm, see my website.

@_date: 1996-09-03 19:17:31
@_author: Bruce Schneier 
@_subject: What the NSA is patenting 
I just spent a pleasant hour or so searching a patent database for all
patents assigned to the NSA.  There's some interesting stuff:
Fifty-Four patents total.  (Used to be they just kept stuff secret; now
they patent some of it.)  Attached is the most interesting thing I found: a
patent on techniques for reading data off overwritten magnetic media.
United States Patent                   Patent Number:  5264794
                                       Date of Patent: 23 Nov 1993
Method of measuring magnetic fields on magnetically recorded media using
a scanning tunneling microscope and magnetic probe
Inventor(s):  Burke, Edward R., Silver Spring, MD, United States
              Mayergoyz, Isaak D., Rockville, MD, United States
              Adly, Amr A., Hyattsville, MD, United States
              Gomez, Romel D., Beltsville, MD, United States
Assignee:     The United States of America as represented by the Director,
              National Security Agency, Washington, DC, United
              States (U.S. government)
Appl. No.:    92-947693
Filed:        21 Sep 1992
Int. Cl. ............. G01R033-00; G01R033-12
Issue U.S. Cl. ....... 324/260.000; 324/212.000
Current U.S. Cl. ..... 324/260.000; 324/212.000
Field of Search ...... 324/212; 324/244; 324/260; 324/262
                            Reference Cited
                            PATENT DOCUMENTS
  Patent
  Number     Date        Class        Inventor
---------- --------- -------------- ------------
US 4232265  Apr 1980  324/260.000    Smirnov
US 4567439  Jan 1986  324/304.000    McGregor
US 4625166  Nov 1986  324/223.000    Steingroever et al.
US 4710715  Dec 1987  324/307.000    Mee et al.
US 4791368  Dec 1988  324/301.000    Tsuzuki
                            OTHER PUBLICATIONS
Magnetic Tip Sees Fine Detail, Lost Data, E. Pennisi, Feb. 29, 1992,
Science News, p. 135.
Magnetic Field Imaging by Using Magnetic Force Scanning Tunneling
Microscopy, Gomez, Burke, Adly, Mayergoyz, Feb. 17, 1992 pp. 906-908
Appl. Phy. Lett.
Tunneling-Stabilized Magnetic Force Microscopy of Bit Tracks . . . ,
Rice, Moreland, IEEE Trans. on Magnetics vol. 27 No. 3 May 1998, pp.
Magnetic Force Scanning Tunneling Microscope Imaging of Overwritten
Data, Gomez, Adly, Mayergoyz, Burke, IEEE Journal of Magnetics, Sep.
Analysis of Tunneling Magnetic Force Microscopy Using a Flexible
Triangular Probe, Burke, Gomez, Adly, Mayergoyz, IEEE Journal of
Magnetics, Sep. 1992.
Magnetic Force Microscopy: General Principles and Application to . . . ,
Rugar, Mamin, et al. Journal of Appl. Phys., Aug. 1, 1990 pp. 1169-1183.
Analysis of In-Plane Bit Structure by Magentic Force Microscopy, Wadas,
Grutter, Guntherodt, J. Appl Phys. Apr. 1, 1990 pp. 3462-3467.
Theoretical Approach to Magnetic Force Microscopy, Wadas, Grutter,
American Physical Society, Jun. 1, 1989, 12,013-17.
Theory of Magnetic Imaging by Force Microscopy, Saenz, Garcia,
Slonczewski, Appl. Phys. Letters, Oct. 10, 1988 pp. 1449-1451.
Description of Magnetic Imaging in Atomic Force Microscopy, Wadas,
Journal of Magnetism and Magnetic Materials, Aug. 1989 pp. 263-268.
Art Unit - 267
Primary Examiner - Snow, Walter E.
Attorney, Agent or Firm -  Morelli, Robert D.; Maser, Thomas O.
                        ---------------------
8 Claim(s), 4 Drawing Figure(s), 4 Drawing Page(s)
                               ABSTRACT
The present invention discloses a method of measuring magnetic fields on
magnetically recorded media. The method entails replacing the metal tip
typically used with a scanning tunneling microscope with a flexible
thin-film nickel of iron magnetic probe. The present invention describes
a mathematical equation that relates probe position to magnetic field
strength. In order to establish a tunneling current between the magnetic
probe and the magnetically recorded media, any protective layer on the
magnetically recorded media is removed. The magnetic probe and the
magnetically recorded media may be coated with at least three-hundred
angstroms of gold in order to reduce spurious probe deflections due to
oxide growths on either the magnetic probe or the magnetically recorded
media. The scanning tunneling microscope is designed to maintain a
constant tunneling current between the probe and the item being scanned.
The present invention uses the scanning tunneling microscope to scan the
recording tracks of magnetically recorded media. Any change in the
magnetic field of the magnetically recorded media will cause a change in
the tunneling current. The microscope will change the position of the
probe in order to maintain a constant tunneling current. These changes
in position are recorded as an image. A mathematical equation that
relates probe position to magnetic field strength is then used to
extract the magnetic fields of the magnetically recorded media from the
recorded image of probe positions.
BACKGROUND OF THE INVENTION
1. Field of Invention
This invention relates to a method of measuring the magnetic fields of a
recorded surface and more particularly to a method of measuring the
magnetic fields of magnetically recorded information using a scanning
tunneling microscope.
2. Description of Related Art
One of the most active areas in magnetic recording technology is the
study of processes occurring at the microscopic level. In recent years,
several techniques based on scanning tunneling microscopy have been
developed to study magnetization patterns in recording media with
sub-micron resolution. These include magnetic force microscopy (MFM),
and tunneling stabilized (TS) or magnetic force scanning tunneling
microscopy (MFSTM).
In "Tunneling-stabilized Magnetic Force Microscopy of Bit Tracks on a
Hard Disk," a published article by P. Rice and J. Moreland in IEEE
Trans. Magn., vol. Mag-27, 1991, pp. 3452-3454 it was shown that
magnetic data on a hard disk can be imaged with a tunneling microscope
by using a flexible triangular probe cut from a thin film of magnetic
In U.S. Pat. No. 4,791,368, entitled "Automatic Magnetic Field Measuring
Apparatus Using NMR Principles," a method of more accurately measuring
magnetic fields is described which entails surrounding the item being
measured with a coil, initially measuring the magnetic field, estimating
the magnetic resonance frequency of the item being measured, applying a
high-frequency voltage of the estimated magnetic resonance frequency,
iteratively refining the estimate of the magnetic resonance frequency
until the variation in coil inductance is a maximum, and finally, from
the resulting magnetic resonance frequency, calculating the magnetic
field of the item being measured.
In U.S. Pat. No. 4,710,715, entitled "Method Of Mapping Magnetic Field
Strength And Tipping Pulse Accuracy Of An NMR Imager," a method of
checking the homogeneity of a magnetic field by producing contour lines
of equal field strength is disclosed that utilizes a different
preparation phase for NMR imaging. The new preparation phase consists of
tipping the spins of the volume elements with a 90 degree wait 90 degree
RF pulse sequence.
In U.S. Pat. No. 4,625,166, entitled "Method For Measuring Magnetic
Potentials Using Hall Probes," a method of measuring the hysteresis
curve of a magnetic material is disclosed. The steps of the method
include subjecting the material to a magnetic field, summing the
voltages from a plurality of Hall probes that are spaced in an arc,
obtaining the magnetic flux density in the material, and deriving a
hysteresis curve of the material from the magnetic flux density and the
magnetic field intensity.
In U.S. Pat. No. 4,567,439, entitled "Apparatus For Measuring The
Magnitude Of A Magnetic Field," a method of measuring the magnitude of a
magnetic field is disclosed. The steps of the method include magnetizing
the item, inducing an oscillating magnetic field, permitting free
precession, inducing signals during free precession, and producing an
output that is proportional to the frequency deviation of the induced
In U.S. Pat. No. 4,232,265, entitled "Device For Measuring Intensity Of
Magnetic Or Electromagnetic Fields Using Strain Gauges Mounted On
Ferromagnetic Plates," a device is disclosed that measures magnetic
fields by monitoring the electrical signal produced by strain gauges
which are connected to overlapping ferromagnetic plates. The magnetic
field to be measured causes the gap between the plates to change which
in turn causes the electrical output signal from the strain gauges to
change. The magnitude of the electrical signal indicates the magnitude
of the magnetic field.
SUMMARY OF THE INVENTION
It is an object of this invention to provide a method of measuring
magnetic fields.
It is another object of this invention to provide a method of measuring
magnetic fields of magnetically recorded information.
It is another object of this invention to provide a method of measuring
magnetic fields of magnetically recorded information using a scanning
tunneling microscope.
It is another object of this invention to provide a method of measuring
magnetic fields of magnetically recorded information using a scanning
tunneling microscope that incorporates a thin-film magnetic probe that
is used to relate probe position to magnetic field strength.
These objects are achieved by using a magnetic force scanning tunneling
microscope to measure magnetic fields. This microscope, which is
typically used for recording surface topology of an item, is modified by
replacing the fine metallic tip with a flexible magnetic probe.
In the typical operation of a scanning tunneling microscope, the fine
metallic tip, which is held at a bias potential, is placed in close
proximity to the sample surface so that a tunneling current is
established between the tip and the sample surface. As the tip scans
across the surface, changes in surface topology cause the tunneling
current to change. In order to maintain a constant tunneling current,
the microscope changes the position of the tip. These changes in tip
position are recorded in a two dimensional image that reflects the
surface topology of the item scanned.
The present invention shows that by replacing the tip with a magnetic
probe and by scanning recorded media along the recording tracks, which
have no significant topological variations, the scanning tunneling
microscope can be used to record the magnetic fields of the recorded
Just as surface variations caused changes in the tunneling current,
changes in magnetic field cause changes in the tunneling current. The
microscope will change the position of the probe, as it did with the
metallic tip, in order to maintain a constant tunneling current. These
position changes are recorded and, with the use of a mathematical
equation that relates probe position to magnetic field strength, are
used to measure the magnetic fields of the recorded media.
BRIEF DESCRIPTION OF THE DRAWINGS
FIG. 1 is a perspective view of a typical image created by a scanning
tunneling microscope;
FIG. 2 is a perspective view of the magnetic probe superimposed upon a
graph that indicates the critical dimensions, coordinates, and angles;
FIG. 3 is a chart showing the relationship between magnetic probe
amplitude and the angle theta; and
FIG. 4 is a chart that compares theoretically expected results of probe
amplitude versus the angle phi against experimentally obtained data of
probe amplitude versus the angle phi.
DESCRIPTION OF PREFERRED EMBODIMENTS
There is a growing interest in measuring magnetic fields created by
magnetization patterns recorded on magnetic media. Since these fields
vary over microscopic distances, various microscopic techniques have
been developed. The present invention describes a method for measuring
magnetic fields on magnetically recorded media by using a modified
scanning tunneling microscope. These magnetic fields are measured by
determining the relationship between the microscope probe movement and
magnetic field strength.
The scanning tunneling microscope operates by scanning the surface of an
object with a metal tip. The tip is biased with a dc voltage and placed
close enough to the surface of the object to establish a tunneling
current. Changes in the surface topology of the object cause a change in
the tunneling current. A feedback system in the microscope adjusts the
vertical position of the tip in order to maintain a constant tunneling
current. As the tip is scanned across the object, the changes in tip
position are recorded. These recordings reflect the surface topology of
the item scanned. An example of such an image is indicated in FIG. 1.
The present invention discloses a method for using a modified magnetic
force scanning tunneling microscope to measure magnetic fields. The
metal tip of the microscope is replaced with a thin-film magnetic probe
20 of FIG. 2. Instead of scanning the surface topology of an item, the
modified microscope is used to scan individual recording tracks of a
magnetically recorded media which do not have any significant
topological variations.
Just as was done with the metal tip, the probe 20 is placed in close
proximity with the recorded media in order to establish a tunneling
current. The probe 20 is then scanned along the recording tracks of the
magnetically recorded media. Changes in magnetic field cause a change in
the tunneling current. The microscope then changes the position of the
probe 20 in order to maintain a constant tunneling current. These
position changes are recorded and, with the use of a mathematical
equation that relates probe position to magnetic field strength, used to
measure the magnetic fields of the recorded media.
The energy of interaction between the probe 20 and the magnetic field
emanating from the sample surface was evaluated using the geometry as
shown in FIG. 2. It was assumed that the field interacts only with the
last magnetic domain (i.e., a region that is magnetized in one direction
only) at the tip of the probe 20 and that this domain is magnetized
uniformly along its length. The magnetization pattern is typically a
recorded signal with repetition in the x-direction and infinite extent
in the y-direction.
Measurements were taken with a scanning tunneling microscope operating
in a constant current mode with a maximum scan range in excess of 100
micrometers in each lateral dimension. The tunneling current is
typically 0.11 nanoamperes, at a dc bias of 2.7 volts. The scan rate is
about 1.5 lines per second. Any protective coatings on the recorded
media must be removed. Adverse effects due to surface oxides on the
probe 20 or recorded media are reduced by coating the recorded media and
the tip of the probe 20 with approximately 300 angstroms of gold. Such a
coating is typically deposited by conventional sputtering techniques.
The tunneling current changes as the probe 20 interacts with the surface
and its magnetic fields. Feedback compensates for this change and the
vertical displacement of the probe 20, .DELTA.z, is recorded as a
function of its horizontal position. Therefore, a two dimensional image,
similar to the image shown in FIG. 1, is formed that maps variations in
z as a function of lateral position, i.e., .DELTA.z(x,y). Such an image
reflects both the topological and magnetic features of the magnetically
recorded media. With the appropriate choice of probe 20 properties, it
is possible to extract the magnetic fields from this image.
The magnetic contribution to the displacement, .DELTA.z, is determined
by the forces acting on the probe 20. Several theoretical calculations
that relate recorded images using such a probe 20 with the forces on the
probe 20 have appeared in "Analysis of in-plane bit structure by
magnetic force microscopy", a published article by A. Wadas, P. Grutter,
and H. Guntherodt in J. Appl. Phys., vol. 67, 1990, p. 3462 and "Theory
of magnetic imaging by force microscopy," a published article by J.
Saenz, N. Garcia, and J. Slonczewski in Appl. Phys. Lett. 53, 1988, p.
1449. However, these calculations have not directly addressed the issue
of the dependence of image contrast and resolution on the orientation of
the probe 20 as the present invention does.
By assuming that the probe 20 is uniformly magnetized along the
direction of its length, the vertical displacement can be modeled by
considering the interaction of the surface magnetic fields with a
magnetic charge distribution at the tip of the probe 20. Flexible
magnetic probes 20 made of nickel (Ni) can be used. The probes 20 used
in the present invention were fabricated by evaporating approximately
500 nanometers of Ni onto pre-patterned substrates. These films retain
the shape of the substrate pattern when peeled away from the pattern. A
typical probe would have a thickness (t) of less than or equal to one
micrometer, a length (l) of two millimeters, and a width (w) of one
micrometer. The angle delta is typically 15 degrees. The angle theta can
vary over a range of zero degrees to pi/2 degrees. The angle phi can
vary over a range of -pi/2 to pi/2. It has been observed that these
probes 20 produce consistent images of magnetization patterns.
FIG. 1 also shows the parameters for the equations used in the present
invention. It was assumed that the recorded signal is a repetitive
pattern of wavelength lambda (.lambda.) in the x direction, with
infinite extent in the y direction.
In "Theoretical approach to magnetic force microscopy," a published
article by A. Wadas and P. Grutter in Phys. Rev. B, vol. 39, no. 16,
June 1989, pp. 12013-12017 it was shown that the energy (E) of
interaction between the field from the pattern and the last domain on
the probe tip can be expressed as
E=-.intg.H.multidot.M dV,
where H is the magnetic field from the pattern, M is the magnetization
of the domain, and V is the volume of the domain. The magnetic field can
be expressed as the gradient of a scalar potential capital phi (.PHI.),
and, if the magnetization is uniform (.gradient..multidot.M=0 is
sufficient), then the above equation for E can be rewritten as
E=.intg..gradient..multidot.(.PHI.M) dV.
This new equation for E can then be converted to a surface integral
using Gauss's theorem to obtain
This latest equation simplifies the calculation of E and the
identification of the source of the different terms. The scalar
potential will then be of the form  where k=2.pi.n/.lambda. and
the coefficients .PHI.n match the series solution to the particular
field pattern. Specific values of .PHI.n for various field patterns can
be found in "Theoretical approach to magnetic force microscopy," a
published article by A. Wadas and P. Grutter in Phys. Rev. B, vol. 39,
no. 16, pp 12013-12017, June 1989 and in "Analysis of in-plane bit
structure by magnetic force microscopy," a published article by A.
Wadas, P. Grutter, ad H. Gutherolt in J. Appl. Phys. 67 (7), pp.
3462-3467, 1990.
In the present invention, it was assumed that 1) the domain is
magnetized along the probe axis by shape anisotropy, 2) the domain is
much longer than .lambda. so that the limit of integration in the z
direction can be extended to infinity, and 3) the thickness of the
probe, t, is much less than the wavelength .lambda..
In "Magnetic force microscopy: General principles and application to
longitudinal recording media," a published article by D. Rugar, H.
Mamim, P. Guethner, S. Lambert, J. Stern, I. McFadyen, and T. Yogi in J.
Appl. Phys. 68 (3), 1990, pp. 1169-1183, it was shown that the last
domain on the probe was 20 micrometers in length. A domain length of
this size is typically much longer than the wavelength of patterns on
modern recording surfaces.
In calculating the energy of interaction (E), the last two equations are
used to obtain  The integrals were preformed so that the point
(x,z) is the coordinate of the probe tip. The first term in the
calculation of the energy of interaction is due to a magnetic charge,
Mtw, at the tip of the probe. The magnetic potential is weighted by a
sampling factor caused by the variation in the field across the width,
w, of the probe tip. The next two terms can be thought of as the
contributions from the magnetic charges on the sides of the probe,
separated from the tip by the distances x.+-..
The quantity that is measured by the tunneling microscope is the
displacement, .DELTA.z, of the probe tip. The displacement is caused by
both the surface topology and magnetic field of the recorded media. If
the probe tip is properly designed, the magnetic interaction will
predominate and the effects due to surface topology will b minimized.
If the probe is constrained to rotate in the theta (.theta.) direction,
the displacement will be given by lsin.theta..DELTA..theta., where l is
the length of the probe's 20 moment-arm. A force, F.sub.N, normal to the
probe 20 will cause a rotation in the theta (.theta.) direction such
that lF.sub.N =-K.DELTA..theta. where K is the tip torque constant. The
displacement .DELTA.z is then given by The force acting on the tip is the gradient of the energy,
F=-.gradient.E, so that .DELTA.z further becomes Using the last equation and the equation for the energy (E) of
interaction, .DELTA.z becomes These last three equations give a complete description of the
interaction between the probe and the recorded pattern. In general, the
equations are quite complicated and their usefulness is not readily
apparent. In the case where the probe lines up with the pattern (i.e.,
phi=0), so that the probe scans along the recorded information, the
equation for .DELTA.z reduces to a simple form, The first two terms give the interaction between the magnetic field and
the magnetic charge at the tip. The third term gives the effect of the
charges on the sides of the probe. The third term was written in the
integral form so that it could be expressed in terms of the magnetic
field Hz. This last equation can be used to obtain relative values of
the magnetic field components Hx and Hz. To obtain absolute values, the
probe would have to be calibrated in a known field to obtain the factor
An alternative way to obtain the fields from the last equation is by
obtaining three images at three different values of the angle theta
(.theta.). The fields Hx and Hz can then be obtained at every point from
a linear combination of the three images. As an example, if the images
were taken at theta equal to 30, 45, and 60 degrees then Hx and Hz would
be given by the following two equations:
H.sub.x =-18.01z(30.degree.)-13.55z(60.degree.)+29.35z(45.degree.),
H.sub.z =-23.48z(30.degree.)-10.40z(60.degree.)+29.35z(45.degree.)
where If phi=0 is chosen as the angle of rotation of the probe, the angle
theta must be determined to give the best image sensitivity. For
 the relative amplitude of the harmonics, for phi=0, will vary
with theta as  The amplitude will have a maximum near theta=pi/2
for both large and small values of a. Raising the elevation of the probe
to this value would cause interactions with all the domains in the probe
so a smaller value would have to be chosen. The smallest value of theta
for which the amplitude is a maximum occurs when a=1, cos(theta)=1/3,
and theta=70.5 degrees. This is still a relatively large elevation, but
as can be seen from FIG. 3, the maximum occurs over a broad range.
Adequate sensitivity can be achieved when theta is as small as 45
Numerous experiments were performed to verify the equations given above
for .DELTA.z, C**2, and beta. Agreement between experimental data and
theory, as shown in FIG. 4, is quite good. The theoretical curve was
obtained using delta (.delta.)=15 degrees, theta=12 degrees and w=1
micrometer. Error is introduced into the experimental data if, during
rotation of the sample, a different recorded track is followed.
The method of the present invention shows how the constituent magnetic
fields from recorded magnetic patterns can be obtained using a magnetic
force scanning tunneling microscope. The sensitivity of the microscope
will vary with the orientation of the probe. Changes and modifications
in the specifically described embodiments can be carried out without
departing from the scope of the invention which is intended to be
limited only by the scope of the appended claims.
1. A method of measuring magnetic fields on magnetically recorded media
comprising the steps of: (a) replacing the fine metallic tip of a
scanning tunneling microscope with a flexible thin-film magnetic probe
in order to relate probe position to magnetic field strength; (b)
removing any protective layer from said magnetically recorded media so
that said protective layer does not impede the establishment of a
tunneling current between said magnetic probe and said magnetically
recorded media; (c) aligning said magnetic probe with a recorded track
of said magnetically recorded media at an angle of zero degrees; (d)
positioning the tip of said magnetic probe to said magnetically recorded
media at an angle in the range of zero degrees to pi/2 degrees in order
to establish said tunneling current; (e) scanning said recorded track of
said magnetically recorded media with said magnetic probe; (f) recording
changes in position of said magnetic probe during said scanning of step
(e) due to changes in the magnetic field of said magnetically recorded
media; and (g) computing the magnetic fields associated with said
recordings of step (f) by using a mathematical equation that relates the
position of said magnetic probe to the strength of the magnetic field.
2. The method of claim 1 further comprising the step of plating said
magnetic probe and said magnetically recorded media with at least
three-hundred angstroms of gold in order to reduce spurious probe
deflection due to surface oxides on either said magnetic probe or said
magnetically recorded media.
3. The method of claim 1 wherein said step of replacing the fine
metallic tip of a scanning tunneling microscope with a flexible
thin-film magnetic probe is accomplished by replacing the fine metallic
tip of said scanning tunneling microscope with a thin-film nickel probe.
4. The method of claim 1 wherein said step of replacing the fine
metallic tip of a scanning tunneling microscope with a flexible
thin-film magnetic probe is accomplished by replacing the fine metallic
tip of said scanning tunneling microscope with a thin-film iron probe.
5. A method of measuring magnetic fields on magnetically recorded media
comprising the steps of: (a) replacing the fine metallic tip of a
scanning tunneling microscope with a flexible thin-film magnetic probe
in order to relate probe position to magnetic field strength; (b)
removing any protective layer from said magnetically recorded media so
that said protective layer does not impede the establishment of a
tunneling current between said magnetic probe and said magnetically
recorded media; (c) aligning said magnetic probe with a recorded track
of said magnetically recorded media at an angle of zero degrees; (d)
positioning the tip of said magnetic probe to said magnetically recorded
media at an angle in the range of zero degrees to pi/2 degrees in order
to establish said tunneling current; (e) scanning said recorded track of
said magnetically recorded media with said magnetic probe a first time;
(f) recording changes in position of said magnetic probe during said
scanning of step (e) due to changes in the magnetic field of said
magnetically recorded media; (g) positioning the tip of said magnetic
probe to said magnetically recorded media at an angle in the range of
zero degrees to pi/2 degrees but at an angle that is different then the
angle used in step (d) in order to establish said tunneling current; (h)
scanning said recorded track of said magnetically recorded media with
said magnetic probe a second time; (i) recording changes in position of
said magnetic probe during said scanning of step (h) due to changes in
the magnetic field of said magnetically recorded media; (j) positioning
the tip of said magnetic probe to said magnetically recorded media at an
angle in the range of zero degrees to pi/2 degrees but at an angle that
is different than the angles used in step (d) and step (g) in order to
establish said tunneling current; (k) scanning said recorded track of
said magnetically recorded media with said magnetic probe a third time;
(l) recording changes in position of said magnetic probe during said
scanning of step (k) due to changes in the magnetic field of said
magnetically recorded media; (m) combining the resulting three
recordings of step (f), step (i), and step (l) linearly in order to
obtain a single record of the position changes of said magnetic probe
due to changes in the magnetic field of said magnetically recorded
media; and (n) computing the magnetic fields associated with said
combination of step (m) by using a mathematical equation that relates
the position of said magnetic probe to the strength of the magnetic
6. The method of claim 5 further comprising the step of plating said
magnetic probe and said magnetically recorded media with at least
three-hundred angstroms of gold in order to reduce spurious probe
deflection due to surface oxides on either said magnetic probe or said
magnetically recorded media.
7. The method of claim 5 wherein said step of replacing the fine
metallic tip of a scanning tunneling microscope with a flexible
thin-film magnetic probe is accomplished by replacing the fine metallic
tip of said scanning tunneling microscope with a thin-film nickel probe.
8. The method of claim 5 wherein said step of replacing the fine
metallic tip of a scanning tunneling microscope with a flexible
thin-film magnetic probe is accomplished by replacing the fine metallic
tip of said scanning tunneling microscope with a thin-film iron probe.
* Bruce Schneier            2,000,000,000,000,000,000,000,000,002,000,
* Counterpane Systems       000,000,000,000,000,000,002,000,000,002,293
* schneier at counterpane.com  The last prime number...alphabetically!
* (612) 823-1098            Two vigintillion, two undecillion, two
* 101 E Minnehaha Pkwy      trillion, two thousand, two hundred and
* Minneapolis, MN  55419    ninety three.

@_date: 1997-04-14 15:54:04
@_author: Bruce Schneier 
@_subject: Cryptographers made fun of on late-night network television 
The show is Politically Incorrect, on ABC at 1:00am.  This show aired on
March 21st (which is the night of the 20th):
Here's what Bill Mahar said (it doesn't parse well):
"Are there any users of cellular phones here? Because people are concerned
(2-3 people finally clap) I knew it was a sophisticated group. Um, no.
People are concerned about the privacy you know. Newt Gingrich, what
happened to him. So a couple of months ago they set out to make these
things a lot better so that you couldn't break in. Well. Put in a new code.
Yesterday, a team of computer experts announced that they had already
cracked the electronic code. And sadly, none of them knew how, still, to
unhook a bra."
All right, so it's not a GOOD joke.  But still....
* Bruce Schneier                 For information on APPLIED CRYPTOGRAPHY
* Counterpane Systems            2nd EDITION (15% discount and errata),
* schneier at counterpane.com       Counterpane Systems's consulting services,
*     or the Blowfish algorithm, see my website.

@_date: 1997-04-15 19:12:18
@_author: Bruce Schneier 
@_subject: Meeting Report: "Developing the Advanced Encryption Standard" 
Meeting Report:
        "Developing the Advanced Encryption Standard" Workshop
                           15 April 1997
                         by Bruce Schneier
NIST held a workshop to discuss the proposed Advanced Encryption Standard
(AES) today.  About 70 people, from government and industry, attended.
Specifically, the workshop was convened to discuss the minimum
acceptability requirements, evaluation criteria, and submission
requirements for the AES.  First my report, and then some opinion.
Miles Smid presented NIST's goals for AES.  They wanted a strong encryption
block encryption algorithm for government and commercial use, one that
would support "standard codebook modes" of encryption, "significantly more
efficient than triple DES," and with a variable key size.
Smid then summarized the comments and their proposed responses.
Thirty-three comments (via paper and e-mail) were received in response to
the 2 January 1997 Federal Register.  These comments were all distributed
at the workshop.
Responses to comments on the "Minimum Acceptability Requirements and
Evaluation Criteria."  (Please note that these responses are only "proposed
responses," and are not the official responses of NIST.)
and encourages that the mathematical rationale behind algorithms be
presented along with the algorithms.
be compatible with DES, and because existing standards specify block modes.
Still, they are open to a discussion on stream ciphers.  (They got a lot of
discussion, but seemed to ignore it.)  They are also open to block sizes
larger than 64 bits.  (The general consensus was 128 bits.)  They would
prefer to have a single algorithm in AES, as opposed to a family of
algorithms (this prompted discussion as well).
be a single large keylength or a variable keylength.  NIST also "intends to
recognize triple-DES when it becomes an ANSI standard."  NIST wants the AES
to offer significant advantages over triple-DES.  (They said this over and
over.  Their opinion was that if the process just recognized triple-DES,
then it wasn't really worth bothering.)
implementations precluded the submission of algorithms that could be
implemented only in hardware.  (Remember the security restrictions imposed
on Skipjack.)
royalty-free world-wide implementation.  They will accept patented
algorithms, but will heavily favor royalty-free algorithms.
strongly encourages a public explanation of the rationale behind any
constants or tables, and a statement of the work factor required to attack
the algorithm; they will judge all attacks below the work factor for
practicality.  Regarding computational efficiency, NIST will favor
efficiency on 32-bit processors and short key-setup time, will test
efficiency on a little endian processor, and will publish the specs of the
test system.  They also encourage two submissions: reference (possibly in
Java) and optimized (in C).  Regarding memory requirements, NIST will
measure memory requirements for C implementation on a single reference
platform (presumably a Pentium Pro), although submitters are welcome to
provide results for other platforms.  Regarding hardware and software
suitability, NIST believes that the primary applications for the AES are
for large processors (although they would "value" flexibility to run on
8-bit processors), and do not believe that they can require hardware
gate-count values from submission.   Regarding simplicity, NIST intends to
evaluate algorithms on their simplicity of design (is there a rationale, or
is the algorithm just a hodge-podge?) and implementation.  Regarding
flexibility, NIST received many conflicting comments on the value of
flexibility versus the value of fixing parameters.  NIST intends to
evaluate algorithms on their ability to implement on differing platforms
for various applications.  They will consider defining a standard interface
for testing.  Regarding variant algorithms, they worry about the difficulty
of analysis and the loss of compatibility; they assume the number of rounds
would be fixed for any given key size.
security is more important than efficiency or flexibility, and that
efficiency is of equal importance to flexibility.  They have no control
over export control laws, and will comply with any export control laws.
The design should be for a strong algorithm, regardless of the legal
climate.  NIST reiterated that the AES should be at least as secure as
Jim Foti provided proposed responses to comments on the "Proposed Draft
Submission Requirements."  NIST will specify block and key sizes, and will
encourage submitters to include design rationale.  They will ask for a
reference implementation as well as an optimized implementation (suitable
for a IBM-compatible Pentium PC running Windows 95 with 16MB of RAM). They
will ask for efficiency estimates for various platforms, including
bytes/sec for encryption, decryption, and key setup, as well as gate counts
and memory requirements for hardware implementations.  They would like a
graph with a plot of speed versus memory.  They will require a suite of
test vectors to ensure all implementations of the algorithm are correct,
and a statement regarding possible patent issues (legal issues may be
appropriate).  They will require a list of any known weak or equivalent
keys, complementation properties, etc., a mathematical rationale for any
items that could hide a trap door, and a reference list of any publications
that discuss cryptanalysis of the algorithm.  NIST will not accept
proprietary submissions (with the possible exception of the optimized
implementation).  The submitter must agree to waive copyright on submitted
materials (again, with the possible exception of the optimized
implementation).  And the submitter must provide a statement of expected
strength of the algorithm, with supporting rationale.  Of course
submissions from outside the U.S. would be welcome.
Ed Roback discussed the selection process.  We've had the draft criteria
and submission requirements (1/2/97), the public comment process (closed on
4/2/97), and the workshop on criteria and submission requirements (today).
NIST estimates that it will take three months to prepare a public call for
submissions, which they will publish in the Federal Register.  The call for
submissions would be closed after four to six months.  Then, they would
take about two months to review submissions for completeness and
correctness (not security), and then they would publish everything and
invite the public to review and analyze the algorithms.  There would be
some workshop early on in the process where the submitters could campaign
for their particular algorithm.  After about 6 months, though would be an
interim workshop where people could comment on the algorithms.  (NIST
doesn't plan on funding cryptanalysis, or offering prizes our bounties for
successful cryptanalysis.)  NIST would think about this for a while (three
months), and would then publish a list of narrowed candidates (exactly how
narrowed is unknown).  After another six to nine months of public comments,
there would be a final workshop.  Then, NIST would review everything (about
two months) and publish a draft FIPS.  Another three months for comments on
the draft FIPS, a month to revise the draft, and then the Secretary of
Commerce approves the FIPS.  Times are approximate (of course), but NIST
expects the process to take "well over two years."  It was pretty much
universally thought that this schedule is wildly optimistic.
NIST doesn't know if this algorithm will be a replacement for DES, or an
alternative to DES with higher security.  With DES and triple-DES so
entrenched, it will be impossible to migrate to AES quickly.  (Remember
that the NIST standard only applies to U.S. Government systems, although
they are often used in broader contexts.)
Discussion followed.  All the pre-lunch arguments were about block and key
size.  Block sizes of 64 bits and 80 bits were quickly eliminated, as was a
64-bit keysize.  People wanted variable keysizes of some subset of 128,
192, 256, or even 512 bits, and block sizes of either 128 bits or 128 and
256 bits.  There was no discussion of stream ciphers, or using block
ciphers as hash functions.
NIST has a hard time figuring out how to measure hardware efficiency.
They'd like to have definitive metrics (like there will be for software)
but are unwilling to force submitters to provide VHDL code, or gate counts,
or whatever.
NIST talked about what to do about "tweaking" algorithms after submission.
What if a break is found, but a simple fix prevents the attack?  What if
someone submits an algorithm and someone else proposes a tweak?  These
questions were not answered.
They also debated whether or not the optimized implementation of the
algorithm could be proprietary.  Pros are that it encourages clever
implementations, and implementations from people other than the inventor.
Cons are that it withholds information from the public, and that it doesn't
allow independent verification of proprietary implementations.  One halfway
proposal was to make optimized implementations public, but allow owners to
retain copyright.  The audience seemed to prefer that optimized
implementations be kept secret by NIST.
There were further discussions on the legal issues.  When do the inventors
give up their rights to the algorithm?  What rights, exactly, do they give
up?  What about patents that an inventor might unknowingly infringe upon?
What is an inventor submits an algorithm and then, a year and a half later,
tries to pull it out of the process?  It was almost universally agreed that
these are hard questions.
And in a final show of hands, ten people admitted that they were "thinking
of submitting an algorithm."
Editorialization time....
Before I showed up, the major question in my mind was whether this was a
serious attempt to develop a secure encryption algorithm to replace DES, or
just another red herring by the government to keep us busy while they go on
eavesdropping.  Now I believe that the NIST representatives at the meeting
are sincere, but I still don't know how they fit in a larger context
This is serious business.  Any algorithm proposed in 1997 won't be approved
until at least 2000.  It will be a standard for 20-30 years, in legacy
systems for at least another ten, securing data that might need to be
secured for another 20.  This means we are trying to estimate security in
the year 2060.  I can't estimate security ten years from now, let alone 60.
The only wise option is to be very conservative.
I'm not sure that NIST knows what it wants.  Technically, a FIPS is only
for government use, but NIST would like everyone to use it.  Communities
like banking are likely to adopt a FIPS right out of the box; other
organizations will view a U.S. Government standard with suspicion.  Still,
NIST needs to decide if they want this AES to be all things to all people,
or a specific encryption algorithm to satisfy a specific set of
requirements.  Everyone in the audience had different ideas about this.
The audience was a mix of government agents, corporate representatives,
academics, and random yahoos.  Of course, the random yahoos talked for more
than their share.  My worry is that NIST will get many more submissions
than they bargained for; I think that every random yahoo is going to submit
his pet algorithm.  NIST hopes the community will be able to quickly
separate the random stupid algorithms from the serious submissions, but I
am less sure that politics will allow NIST to.  Assuming a 128-bit block
requirement doesn't preclude everything already done, I  urge companies
with patented or patent-pending algorithms to give up royalties and submit
their algorithms.  I assume CAST (royalty-free from Northern Telcom), SAFER
(royalty free from Cylink), Blowfish (unpatented), and Square (unpatented)
will be submitted; I would also like to see RC5 from RSADSI, IDEA from
Ascom-Systec, and Khufu from Xerox.  Failing that, I would like to see new
submissions out of the various cryptographic research institutions.  The
yahoos are going to submit regardless; we need at least a small pile of
quality algorithms.
But is there enough time for people to invent strong 128-bit block ciphers?
Probably not.  One alternative is to take existing 64-bit block ciphers,
and then use a 4-round Luby-Rackoff construction to create a 128-bit block
variant.  Another is to give people more time.  Both were talked about.  I
would like them to approve triple-DES as an interim standard, and then take
all the time they need for a secure 128-bit block cipher.
So now we wait for the call for submissions.
* Bruce Schneier            2,000,000,000,000,000,000,000,000,002,000,
* Counterpane Systems       000,000,000,000,000,000,002,000,000,002,293
* schneier at counterpane.com  The last prime number...alphabetically!
* (612) 823-1098            Two vigintillion, two undecillion, two
* 101 E Minnehaha Pkwy      trillion, two thousand, two hundred and
* Minneapolis, MN  55419    ninety three.
*

@_date: 1997-04-18 19:14:25
@_author: Bruce Schneier 
@_subject: Meeting Report: "Developing the Advanced Encryption Standard" 
I agree that testing on a 32-bit machine is kind of dumb.  I also think
that testing it on a 64-bit machine is just as dumb.  We're talking about
a standard that will be with us for 20-30 years; whatever the current
archetecture is, it will be outdated before the standard is.
The lessons of computer are:  the high end always gets faster, and the
low end never goes away.  Anything will run fast on the high end, if not
now then in a generation or two.  We need something optimized for 8-bit
smart card processors.
Again, all that matters is the low end.
We discussed that.  If a group thinks they have six months to develop
something new, they might decide not to even both.  Then, if there is
a six-month extension, we haven't gained anything.  I argued that a full
year should be given.
That's why I want triple-DES approved now, and then to let everyone take
their time with AES.
* Bruce Schneier            2,000,000,000,000,000,000,000,000,002,000,
* Counterpane Systems       000,000,000,000,000,000,002,000,000,002,293
* schneier at counterpane.com  The last prime number...alphabetically!
* (612) 823-1098            Two vigintillion, two undecillion, two
* 101 E Minnehaha Pkwy      trillion, two thousand, two hundred and
* Minneapolis, MN  55419    ninety three.
*

@_date: 1997-04-25 07:26:09
@_author: Bruce Schneier 
@_subject: Crypto '97: Information and Registration Form 
CRYPTO '97
General Information
17-21 August 1997
Santa Barbara, California, USA
Crypto '97 is the 17th international conference on cryptology held at
the University of California Santa Barbara. The academic program
covers all aspects of cryptology; specific papers will be announced on
1 May. Formal proceedings, published by Springer-Verlag, will be
provided to all attendees at the conference.
Crypto '97 is sponsored by the International Association for
Cryptologic Research (IACR), in cooperation with the IEEE Computer
Society Technical Committee on Security and Privacy, and the Computer
Science Department of the University of California, Santa Barbara
(UCSB). Program Chair is Burt Kaliski, Jr., and General Chair is Bruce
In addition to selected and invited papers, there will be a rump
session on Tuesday evening for selected informal presentations.
Facilities are available for attendees to demonstrate hardware,
software, and other items of cryptologic interest. If you are
interested, contact the General Chair by 12 June 1997.
The social program will include hosted dinner receptions on Monday and
Tuesday nights, and a beach barbecue on Wednesday evening. Breakfasts
and lunches will be served at the university dining hall.
Conference Facilities: The workshop will be held on the campus of the
University of California, Santa Barbara.  The campus is located
adjacent to the Santa Barbara airport and the Pacific Ocean; free
shuttle bus service from the airport is available. Reasonably priced
accommodations are available in the university dormitories for
participants and their registered guests. Children under the age of 13
are not allowed to stay in the dormitories, so those bringing younger
children will need to make separate arrangements in one of the nearby
hotels (see Hotels, below). Parking on campus is available at no cost
to participants, but a permit must be requested on arrival. Smoking
inside campus buildings is prohibited. The food is good.
Registration: The conference is open to all interested parties, but
the number of attendees at the workshop is limited to 500;
pre-registration is strongly advised. To register, fill out the
accompanying registration form and return it to the address on the
form along with payment in full before 12 July 1997. Those bringing a
guest are also required to submit the guest registration form. Campus
accommodations will be available on a first come, first served basis
for attendees who register by 12 July 12 1997. Registrations received
after 12 July 1997 may be accepted if space is available but cannot be
guaranteed. The conference fee includes participation in the program
and all social functions, as well as membership in the IACR and a
subscription to the Journal of Cryptology. The room and board charges
include dormitory lodging Sunday night through Wednesday night, and
breakfast and lunch on Monday through Thursday. Technical sessions
will run from Monday morning to Thursday noon, with a free half day on
Tuesday afternoon.
A limited number of stipends are available to students unable to
obtain funding. Students are invited to apply if such assistance is
needed. Requests for stipends should be received by the General Chair
before 14 June 1997. Students registering for the conference need to
provide verification of their student status with a letter from their
Supervisor or Department Chair and a photocopy of their student ID
card. Preference will be given to students whose papers are accepted
and who will present the papers themselves
Cancellations received, in writing, by the General Chair by 15 July
1997 will be considered for a refund in full minus $75 for a copy of
the Proceedings and handling costs. No refunds will be made for
cancellations received after 15 July 1997, but a copy of the
conference Proceedings will be mailed to those registered but unable
to attend.
Travel Information: The campus is located approximately two miles from
the Santa Barbara airport, which is served by several airlines
including American, American West, Delta, United, and US Air.
Complimentary shuttle bus service will be provided between the Santa
Barbara airport and the campus on Sunday and Thursday afternoons. All
major rental car agencies are represented in Santa Barbara. AMTRAK
also has rail connections from both San Francisco and Los Angeles.
Santa Barbara is approximately 100 miles (160 km) north of the Los
Angeles airport and 350 miles (560 km) south of San Francisco.
Hotels: For those who choose not to stay in the dormitories, the
following is a partial list of hotels in the area. Those who choose to
stay off campus are responsible for making their own reservations, and
early reservations are advised since August is a popular season in
Santa Barbara. Note that Goleta is closer to UCSB than Santa Barbara
is to UCSB, but a car will probably be required to travel between any
hotel and the campus. All prices are subject to change: prices should
be confirmed by calling the hotels directly. However, mention Crypto
'97 at UCSB when you are making your reservations, since at several of
the hotels you will be eligible for the university rate, which can be
a significant savings. We are not able to book block rooms in these
hotels, so please make reservations as early as possible. The quality
of the hotels ranges from rather expensive beach-front resorts to
basic inexpensive accommodations. For further information, try
contacting the Santa Barbara Convention and Visitors Center, +1 805
966 9222, or see South Coast Inn: 5620 Calle Real, Goleta, CA 93117. Single rate $89;
double rate $94. Contact Ms. Murrill Forrester at +1 805 967 3200.
Cathedral Oaks Lodge (formerly Turnpike Lodge): 4770 Calle Real, Santa
Barbara, CA, 93110. Single rates $75 and up; double rates $85 and up.
No university rates available. Prices include breakfast. Telephone +1
805 964 3511; fax +1 805 964 0075.
Motel 6: 5897 Calle Real, Goleta, CA 93117. Single rate $36.99; double
rate $42.99. Telephone +1 805 891 6161 or the national reservations
The Sandman Inn: 3714 State Street, Santa Barbara, CA 93105. Rates
start at $79. Telephone: +1 805 687 2468; fax +1 805 687 6581.
Miramar Hotel (Beachfront): Three miles south of Santa Barbara on U.S.
101 at San Ysidro turnoff. No specific single or double rates. Rooms
begin at $75. Telephone +1 805 969 2203; fax +1 805 969 3163.
Pepper Tree Inn: 3850 State Street, Santa Barbara, CA 93105. Single
rate $114; double rate $124. Telephone +1 805 687 5511; fax +1 805 682
Encina Lodge: 2220 Bath Street, Santa Barbara, CA 93105. Single rate
$120; double rate $124. Telephone +1 805 682 7277; fax +1 805 563
Pacifica Suites: Located close to the campus (just down Ward Memorial
Blvd./Highway 217), 5500 Hollister Avenue, Santa Barbara, CA 93111.
Normal rates begin at $135 for a suite. Includes full cooked
breakfast. Telephone +1 805 683 6722; fax +1 805 683 4121.
Upham Hotel: This is a bed-and-breakfast in downtown Santa Barbara.
1404 De La Vina Road, Santa Barbara, CA 93101. Rates begin at $110.
(You must mention that you are attending the Crypto conference.)
Telephone +1 805 962 0058; fax +1 805 963 2825.
The El Encanto Hotel: This renovated hotel is located in the foothills
near downtown Santa Barbara. 1900 Lasuen Road, Santa Barbara, CA
93105. Rates begin at $140. Telephone +1 805 687 5000; fax +1 805 687
To register, print and mail the following form:

@_date: 1997-04-26 10:28:12
@_author: Bruce Schneier 
@_subject: AES Comments 
26 April 1997
Director, Computer Systems Laboratory
Attn: FIPS for AES Comments
Technology Building, Room A231
National Institute of Standards and Technology
Gaithersburg, MD 20899
Dear Mr. Director:
This letter is to offer additional advice subsequent to the 15 April 1997
meeting at NIST, "Developing the Advanced Encryption Workshop." I
appreciate your institute's efforts to develop an AES, and am pleased that
you recognize the importance of this task.
Much of the discussion at the 15 April meeting centered around the "Minimum
Acceptability Requirements" and the "Evaluation Criteria" for the AES.
These are important metrics: good Evaluation Criteria will ensure that the
best algorithm is selected as the AES, while good Minimum Acceptability
Requirements will limit the submissions to high-quality ones.
At the meeting you repeatedly stated that you intend that AES will be a
standard for 20-30 years.   To me, this means that the algorithm will be
used in legacy applications for at least another ten, securing information
that may be required to be confidential for yet another ten.  Assuming we
have a standard approved by the year 2000, the AES must be secure through
the year 2050.
We need to look at AES requirements with this in mind.
Clearly, any algorithm approved for the AES must be secure.  The difficulty
will be choosing among several secure algorithms.  In this letter, I would
like to ignore the important problem of deciding if an algorithm is secure
(and if it will remain secure through the year 2050), and concentrate on
the non-cryptographic requirements.
At the meeting we discussed both flexibility and efficiency: what they
mean, how important they are, and how to compare.
Evaluating encryption algorithms on 32-bit processors such as the Pentium
seems short-sighted for such a long-lasting standard.  Just as the DES,
designed for dedicated hardware in the mid 1970s, is inefficient on any
modern processor, any AES designed for today's computer architectures will
be inefficient on whatever is used 20 years from now.
That isn't much of a problem, though.  Programmers have spent long hours
optimizing DES for different architectures.  And computing power still
doubles every eighteen months: any algorithm becomes ten times faster just
by waiting five years.  Everything is fast on the 64-bit DEC Alpha.
The difficulty is in the low end: embedded systems, smart cards.  The
lesson of the past 20 years of computing seems to be that while the high
end always gets better, the low end never goes away.  We're still
programming tiny 8-bit microprocessors; instead of being used in desktop
computers, they're in cellular phones, automobiles, electrical meters, and
smart cards.  These processors will be around for a long time to come, in
Dick-Tracy-like wristwatch communicators, small affixable processors
(Micron is building the technology), and who knows what else
The AES should be efficient on the low-end processors that are around
today, and be scalable to 16-, 32-, and 64-bit processors.  And think fast;
almost anything written today is faster than triple-DES (see table below).
Encryption at 16 clock cycles per byte; that takes real work.
With this in mind, I propose a set of Minimum Acceptability Criteria that
pushes the envelope of current encryption algorithms:
five times faster than the block modes.
Alpha with a 128-bit key.
128-bit key, and no more than 10 times encryption speed for a 256-bit key.
enough gates), with a maximum latency of 16 clock cycles.
than 64 bytes on an 8-bit smart-card processor.
These requirements are not easy to meet.  As far as I know, no published
block cipher meets them all (although some come close in many areas).  But
requirements such as these will challenge the world's cryptographic
research organizations to create something useful.
I know you realize that the selection process will take several years to
complete.  Therefor, I urge you to approve triple-DES as an interim
standard.  This will satisfy users who need a 64-bit block cipher for
compatibility reasons, while allowing you the time required to choose and
approve the best AES you can.
I applaud your efforts in this matter, and I look forward seeing your call
for submissions in the Federal Register
Bruce Schneier
* Bruce Schneier            2,000,000,000,000,000,000,000,000,002,000,
* Counterpane Systems       000,000,000,000,000,000,002,000,000,002,293
* schneier at counterpane.com  The last prime number...alphabetically!
* (612) 823-1098            Two vigintillion, two undecillion, two
* 101 E Minnehaha Pkwy      trillion, two thousand, two hundred and
* Minneapolis, MN  55419    ninety three.
*

@_date: 1997-04-28 19:14:51
@_author: Bruce Schneier 
@_subject: Corrected Printing of Applied Cryptography Now Available 
Wiley has finally published a corrected printing of Applied Cryptography,
2nd ed!!!
They didn't correct everything, only changes that didn't affect page breaks.
Still, I counted over 250 individual corrections.  And under a dozen errors
remaining.  I'm thrilled that they finally did this.
The fifth printing (or greater) is the corrected printing.  To find what
printing you own, turn to page iv (it's opposite the "Contents in Brief"
page).  The last line (under "Printed in the United States of America")
is a series of numbers, counting down from 10.  The lowest number is the
printing.  You have a fifth printing if your last line looks like:
If you want to buy a fifth printing, you have two options.  One, you can go
to a bookstore and find one.  You can't ask the bookstore to buy a fifth
printing; all he can do is order a copy of the book and hope for the best.
I believe that the fourth printing is sold out (in softcover, at least),
but I cannot be sure.
The other option is to buy it from me.  I have a large supply of fifth
printings that I will sell at the usual 15% discount:
Postage is as follows:
Contact me if you want airmail overseas.  It's expensive.
* Bruce Schneier            2,000,000,000,000,000,000,000,000,002,000,
* Counterpane Systems       000,000,000,000,000,000,002,000,000,002,293
* schneier at counterpane.com  The last prime number...alphabetically!
* (612) 823-1098            Two vigintillion, two undecillion, two
* 101 E Minnehaha Pkwy      trillion, two thousand, two hundred and
* Minneapolis, MN  55419    ninety three.
*

@_date: 1997-12-22 01:41:28
@_author: Bruce Schneier 
@_subject: ECB, CBC, CFB, OFB 
There is a pretty good explanation of the various block cipher modes in
Applied Cryptography.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis,MN  55419       Fax: 612-823-1590

@_date: 1997-12-23 05:03:43
@_author: Bruce Schneier 
@_subject: Question on CFB variant with c[i-N] 
It's kind of obvious.  The encryption of a single plaintext stream
interleaved ten times is the same as the encryption of ten multiplexed
plaintexts.  If one is insecure, the other is insecure.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis,MN  55419       Fax: 612-823-1590

@_date: 1997-01-07 07:03:14
@_author: Bruce Schneier 
@_subject: RSA and Cylink settle 
Subj:  Cylink and RSA Data Security Reach Legal Settlement; Public Key
Encryption Compa
      REDWOOD CITY, Calif.--(BUSINESS WIRE)--Jan. 7, 1997--RSA Data
Security, Inc., a wholly-owned subsidiary of Security Dynamics
Technologies, Inc. (NASDAQ:SDTI), and Cylink Corporation
(NASDAQ:CYLK), today announced a comprehensive global settlement of
their long-standing legal disputes.
          The settlement ends all outstanding litigation between Cylink and
          The two companies reached an amicable resolution of their
disputes.  As part of the settlement, Cylink granted to RSA all
necessary rights to Cylink's Stanford patents, and RSA granted to
Cylink a license to RSA's cryptographic software toolkits.
          For both parties, the settlement ends further prolongation of a
legal dispute that has been costly and distracting.  RSA is
fulfilling the promise made to its customers to resolve the disputes
with Cylink.  Cylink, under its new president and chief executive, is
refocusing all of its energies on providing end-to-end data security
products and solutions, and has the ability to incorporate RSA or
other technologies to meet customer requirements.
          "We are very pleased that what had so long seemed to be an
intractable problem has, within the space of 10 days, now been
resolved by the new management at Cylink," said James Bidzos,
president of RSA.  "I worked well with Fernand Sarrat while he was at
IBM, and that working relationship helped us reach this agreement so
swiftly.  This agreement turns long-time antagonists into companies
that are already exploring ways of working together constructively,
to the benefit of the industry as a whole."
          Fernand Sarrat, president and chief executive officer of Cylink,
said, "We are setting out on an aggressive new course at Cylink in
which old disputes are an unnecessary distraction.  RSA will be one
of our strategic suppliers and we anticipate focusing totally on the
needs of our customers and the enormous market opportunity before
RSA Data Security, Inc.
          RSA Data Security, Inc., a wholly-owned subsidiary of Security
Dynamics Technologies, Inc. (NASDAQ: SDTI), is the world's brand
name for cryptography, with more than 75 million copies of RSA
encryption and authentication technologies installed and in use
          RSA technologies are part of existing and proposed standards for
the Internet and World Wide Web, IT4, ISO, ANSI, IEEE, business,
financial and electronic commerce networks around the globe.  The
company develops and markets platform-independent developer's kits
and end-user products and provides comprehensive cryptographic
consulting services.
          Founded in 1982 by the inventors of the RSA Public Key
Cryptosystem, the company is headquartered in Redwood City, Calif.
Cylink Corporation
          Cylink Corporation (NASDAQ: CYLK) is a leading worldwide supplier
of information security solutions, providing the most comprehensive
portfolio of public key cryptographic hardware and software products
available today.  Cylink's products enable secure transmissions over
local area networks (LANs), wide area networks (WANs), public packet
switched networks such as the Internet, asynchronous transfer mode
(ATM) and frame relay networks.
          Cylink, headquartered in Sunnyvale, Calif., is also the
leader in outdoor spread spectrum microwave radio communications.
Cylink's customers include national and multinational corporations,
financial institutions and government organizations.  For more
information about Cylink and its products, call the fax-on-demand
number 800/735-6614, or visit the company's Web site at
          --30--mg/sf* eh
      CONTACT:
      Cylink
      Paula Contos Dunne, 408/523-5993
      pdunne at cylink.com
      or
      Edelman Worldwide
      Ina McGuinness, 415/433-5381 x 213
      imcguinn at edelman.com
      or
      Patrick Corman
      Patrick Corman, 415/326-9648
      Corman at cerfnet.com
* Bruce Schneier            2,000,000,000,000,000,000,000,000,002,000,
* Counterpane Systems       000,000,000,000,000,000,002,000,000,002,293
* schneier at counterpane.com  The last prime number...alphabetically!
* (612) 823-1098            Two vigintillion, two undecillion, two
* 101 E Minnehaha Pkwy      trillion, two thousand, two hundred and
* Minneapolis, MN  55419    ninety three.
*

@_date: 1997-06-30 10:33:43
@_author: Bruce Schneier 
@_subject: Dr. Dobbs Cryptography and Security CD-ROM 
I've been working on this one.  It looks like a really great deal.
The cost should be reasonable.  And I hope nobody posts the text, or the
publishers won't ever do it again.
* Bruce Schneier            2,000,000,000,000,000,000,000,000,002,000,
* Counterpane Systems       000,000,000,000,000,000,002,000,000,002,293
* schneier at counterpane.com  The last prime number...alphabetically!
* (612) 823-1098            Two vigintillion, two undecillion, two
* 101 E Minnehaha Pkwy      trillion, two thousand, two hundred and
* Minneapolis, MN  55419    ninety three.
*

@_date: 1997-10-08 10:20:17
@_author: Bruce Schneier 
@_subject: What's really in PGP 5.5? 
If this is true (and I have no reason to believe it isn't), then why is the
key escrow code written (although not turned on) in the source code for 5.0
that was posted internationally from PGP?
Makes no sense.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis,MN  55419       Fax: 612-823-1590

@_date: 1997-10-08 13:10:35
@_author: Bruce Schneier 
@_subject: What's really in PGP 5.5? 
In the New York Times Cyber Edition I was quoted as saying that PGP 5.5's
key escrow "sounds like everything the FBI ever dreamed of."  Of course,
that's an overstatement.  The FBI certainly has bigger dreams, like making
non-escrowed encryption illegal.
But PGP's system certainly is key escrow.  PGP, Inc. is splitting hairs,
claiming that their system isn't key escrow because they don't keep copies
of any keys.  This may be true, but it's a difference that makes no
What the PGP system does is automatically encrypt a copy of the message key
in the public key of the organization.  This is more like the original
Clipper Chip.  If you remember, the Clipper Chip included a Law Enforcement
Access Field in the ciphertext field; this field included the session key,
encrypted in a secret law-enforcement key.  PGP 5.5 essentially does this.
You can think of the message key, encrypted in the public key of the
organization, as the CAF (Corporate Access Field).  And just as the Clipper
Chip checked the validity of the LEAF before going into decrypt mode at the
remote end, there is software at the SMTP server that check the validity of
the CAF before allowing the encrypted e-mail to be sent.  This isn't just
key escrow; it's key escrow done well.
Yes, this is only available in the Business Edition and not in the Personal
Edition.  Yes, the company has to decide to turn it on.  Yes, the user is
notified that this feature is turned on.  But once it is turned on, the
user cannot turn it off.  This is not manditory key escrow (unless you are
an employee of a company that decided it is manditory), but the FBI is not
after manditory key escrow right now.  They're willing to settle for
voluntary.  Then, in a few years, making it manditory can be spun as
"closing a loophole."
I agree with the 1996 Phil Zimmermann:
Key escrow = someone other than the author or the intended recipient of the
message being able to decrypt it.
There are valid reasons for data backup, but they have nothing to do with
crypto key recovery.  And there are absolutely no business reasons for
manditory recovery of communications.  We talked about all of this in our
report on key recovery (  Designing a
system that is slightly different doesn't negate everything we said.
I'm sorry, PGP, if I offended you.  But that does not change the facts.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis,MN  55419       Fax: 612-823-1590

@_date: 1997-10-09 22:26:34
@_author: Bruce Schneier 
@_subject: What's really in PGP 5.5? 
Sure.  Please call.  Your CEO called me on Monday, and he tried to tell me
that it wasn't key escrow because you weren't saving copies of any keys.
If you're just going to call to split those sorts of hairs, don't bother.
I'm interested in hearing how your key escrow system works; I've already
been told why you put it in.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis,MN  55419       Fax: 612-823-1590

@_date: 1997-10-14 23:51:33
@_author: Bruce Schneier 
@_subject: Why CMR is bad civic hygene;the short version 
The FBI has publically stated that they want to ban unescrowed encryption.
A couple of years ago, people like Brock Meeks and EPIC predicted this;
they were universially regarded as alarmists.
The problem with corporate key escrow is that it puts an infrastructure in
place that can very easily, with a simple switch of public policy, turn
into GAK.
Diffie has said that the FBS's position is a strawman, and that some kind
of voluntary system will be put in place as a compromise.  Then, in a few
years, eliminating the voluntary nature will be seen as "closing a
Technological infrastructure moves very slowly.  Political moods can move
very quickly.  If companies (like PGP) install a key escrow infrastructure,
it will take one well-timed disaster to convince Congress to pass a law
putting the whole thing under government control.
As Phil Zimmermann said many years ago (I have no idea where he stole it
from): "It's poor civic hygene to install technologies that may someday
facilitate a police state."
Data recovery is essential for stored corporate data.  This is a seperate
problem than corporate key escrow.  Communications keys (used for email)
are fundamentally different than storage keys (used for files).  Someone
sent me email recently and told me that those keys are treated the same in
PGP; I have trouble believing that this is true.
And if everyone is bashing PGP Inc badly over this, it's because people
expected more out of them.  A company like TIS, who gets significant (I
originally wrote "most of its," but I don't know if that's true anymore)
funding from the NSA anyway, is expected to roll over for the Feds.  PGP
Inc was not.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis,MN  55419       Fax: 612-823-1590

@_date: 1997-10-14 23:54:47
@_author: Bruce Schneier 
@_subject: PGP Key Escrow and Congress 
The attached is from Barbara Simons of the U.S. ACM.  Note item 4, where
Congressional staffers point to PGP as an example of key escrow software
being possible.  To those of us fighing the government control of
cryptography, this is not helpful.

@_date: 1997-10-15 07:28:56
@_author: Bruce Schneier 
@_subject: Encyrption Program 
Good luck, but be aware that you won't get much free analysis.  In
general, algorithms that aren't published don't get looked at very
carefully (mostly because there's no real upside in doing so--at least
if the algorithm is published you can get a paper out of a break).
You might have more luck if you posted the algorthm (not in source
code, but in a mathematical description) along with a comprehensive
analysis of its security against existing attacks.  (There is a lot
of published research on the analysis of stream ciphers, although the
field is much less well-studied than block cipher analysis.)  Good
security arguments, proofs even, will make more people interested.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis,MN  55419       Fax: 612-823-1590

@_date: 1997-09-27 01:27:36
@_author: Bruce Schneier 
@_subject: S/MIME Crack?  Beware press bearing incomplete stories 
What I did:  write a Windows 95 screen saver that automatically brute
forces 40-bit RC2 keys.  The screen saver is has an easy interface, and
parallizes nicely.
What I didn't do:  break S/MIME.  I did not find any flaw in the S/MIME
security specification.  I did not find any flaw in any of the cryptographic
algorithms used.  I did not find any flaw in any software implementation
of S/MIME.  There is nothing wrong with the S/MIME standard.
What I find, though, is that many S/MIME implementations don't interporate
at anything stronger than 40-bit RC2.  I find that the default encryption
is 40-bit RC2, and the user isn't given any indication that the encryption
level should be changed.
40-bit RC2 is weak.  This is nothing new to anyone who reads the S/MIME
specifications. In fact, the S/MIME specification is very forthcoming in
discussing security of 40-bit RC2.
Later in the spec, the following appears:
And even later:
I wrote this screen saver not to trash S/MIME (even though the announcement
was used by another company), but to 1) illustrate that 40-bit RC2 really
is insecure, and 2) try to force companies who implement S/MIME to get
DES and triple-DES to interoperate.  I heard recently that RSADSI has said
there is a triple-DES message on their website that can be understood by
both Microsoft Internet Explorer and Netscape Communicator.  I don't know
about the message, but when I tried to get DES and triple-DES to interoperate
a few months ago I couldn't.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis,MN  55419       Fax: 612-823-1590

@_date: 1998-04-01 06:23:56
@_author: Bruce Schneier 
@_subject: 3DES Weakness 
The NYT article is way overblown; the attack is only
against the particular mode in the standard and requires
something like 2^64 texts.  It's great work, but not a
very practical attack.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis,MN  55419       Fax: 612-823-1590

@_date: 1998-04-01 12:23:16
@_author: Bruce Schneier 
@_subject: 2nd announcement of ASIACRYPT'98 
The Hotel was built as a residence for Russian "observers"
in Beijing.  It's quite nice, actually.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis,MN  55419       Fax: 612-823-1590

@_date: 1998-04-22 18:34:24
@_author: Bruce Schneier 
@_subject: Network Security Solutions Conference Announcement 
Network Security Solutions Conference Announcement
                July 29th and 30th, Las Vegas Nevada
******************  Call For Papers Announcement ***************************
Network Security Solutions is now accepting papers for its 1998
event. Papers and requests to speak will be received and reviewed from
March 24th until June 1st.  Please submit an outline on a self selected
topic covering either the problems or solutions surrounding network
security.  Topics of interest include Intrusion Detection Systems (IDS),
distributed languages, network design, authentication systems, perimeter
protection, and more.  Talks will be an hour with a half hour for Q&A.
There will be LCD projectors, overhead, and slide projectors.
Updated announcements will be posted to newsgroups, security mailing lists,
email, or visit the website at Current speakers include:
Marcus Ranum, Network Flight Recorder CEO.
Bruce Schneier, Counterpane Systems CEO.
Ira Winkler, president of the Information Security Advisory Group.
Theo DeRaadt, OpenBSD Lead Developer.
Tom Ptacek, Secure Networks Inc.
Scott Waddell, Cisco-Wheelgroup corporation.
Dominique Brezinski, Network Security Professional at Secure Computing Corp.
Peter Shipley, Independent Security consultant.
Richard Thieme, Thiemeworks, Inc.
Winn Schwartau, Interpact Inc.
Dr. Mudge, L0pht Heavy Industries administrator.
Ray Kaplan, Meet the Enemy panel discussion, Q&A.
Jennifer Granick, Attorney at law.
It's late. You're in the office alone, catching up on database
administration.  Behind you, your network servers hum along quietly,
reliably.  Life is good.  No one can get to your data or disrupt your WAN.
The network is secure.  Or is it?
The Network Security Solutions conference has been organized to put an end
to concerns like these.  While many conferences focus on information and
network security, only Network Security Solutions will put your engineers
and software programmers face-to-face with today's cutting edge computer
security experts and "underground" security specialists.
Only the Network Security Solutions conference will provide your people
with the tools and understanding they need to thwart those lurking in the
shadows of your firewall.
The reality is, they are out there.  The choice is yours.  You can live in
fear of them.  Or, you can learn from them.
                          Conference Overview
The Network Security Solutions Summer '98 conference (Formerly known as The
Black Hat Briefings) was created to fill the need of computer professionals
to better understand the security risks to their computer and information
infrastructures by potential threats.  To do this we assemble a group of
vendor-neutral security professionals in the same room and let them talk
candidly about the problems businesses face, and the solutions they see to
those problems.  No gimmicks, just straight talk by people who make it
their business to explore the ever changing security space.
Spanning two days with two separate tracks, Network Security Solutions will
focus on the vital security issues facing organizations with large
Enterprise networks and mixed network operating systems.  Topics will
include Intrusion Detection Systems (IDS), denial of service attacks and
responses, secure programming techniques and tool selection for creating
and effectively monitoring secure networks.
NSS's intense sessions will bring to light the security and
misconfiguration problems confronting organizations and network
administrators, most of which go unnoticed by today's preoccupied system
admins where security gets put off in lieu of constant network growth and
upgrades.  Our experts will discuss the strategies involved in correcting
existing problems and any problems on the horizon.
Current Intrusion Detection Systems and strategies will be covered so that
attendees may learn how to stop these problems before they occur.  CIO's
are welcome, but they should bring the people implementing their network
strategies and building their applications, because this conference is
for them.
                                Speakers There will be 18-20 speakers covering two tracks speaking over two days.
Speeches will be more technically oriented and last 1 1/2 hours each.  The
goal of the talks are to inform the audience with quality current state
system vulnerabilities and fixes.  Because of our unique speakers NSS will
offer the audience a deep insight into the real security issues facing your
network with no vendor pitches.
                            Wednesday, July 29th
08:30 - 09:00   Breakfast
09:00 - 09:45   Keynote Address: Marcus Ranum - How to REALLY secure the
                                 Internet.
10:00 - 11:30   Track A  Richard Thieme - Convergence -- Every Man (and
                         Woman) a Spy.                 Track B  Dominique Brezinski - Penetrating NT Networks
                         Through Information Leaks and Policy Weaknesses.
11:40 - 13:10   Track A  Ira Winkler - Information Security: Beyond the
                         Hype.
                Track B  Theo DeRaadt - A discussion of secure coding
                         issues, problems with maintaining OS source trees,
                         and secure program design philosophies.
13:20 - 14:20   Lunch
14:25 - 15:20   Ray Kaplan: Meet the Enemy Session.
15:30 - 17:00   Track A  [Empty]
                Track B  Scott Waddell -                             Thursday, July 10th
09:00 - 09:45   Keynote Address: Bruce Schneier - Mistakes and Blunders:
                                 A Hacker Looks at Cryptography.
10:00 - 11:30   Track A	[Empty]
                Track B  Dr. Mudge - Real world VPN implementation
                         problems.
11:40 - 13:10   Track A  Jennifer Granick -                 Track B  Peter Shipley - An overview of a 2 year effort
                         in massive multi-modem wardialing.
13:20 - 14:20   Lunch 14:25 - 15:20   Panel 1  The benefits and problems of commercial security
                         software.  This panel of 5 people and moderator
                         will explore what products work, and what doesn't
                         in specific applications. Q&A.
                Panel 2  The Merits of Intrusion Testing - What is the
                         benefit of having people break into your network.
                         A panel 5 people.
15:30 - 17:00   Track A  Winn Schwartau -                 Track B  Tom Ptacek - Problems with Intrusion Detection
                         Systems.
                     Speaker Topics and Biographies
- - MARCUS RANUM, President and CEO of Network Flight Recorder, Inc.
How to REALLY secure the Internet. Is it possible to really secure the
Internet? With current technology and methods, the answer would appear
to be a resounding "no." We've tried security through stepwise refinement
and security through consensus - the best remaining solutions are
totalitarian and draconian.  Marcus will present an outline for how the
Internet could be secured through some simple, cost effective methods.
He'll also explain why it won't happen.
Marcus Ranum is CEO of Network Flight Recorder, Inc., and has been
specializing in Internet security since he built the first commercial
firewall product in 1989. He has acted as chief architect and implementor
of several other notable security systems including the TIS firewall
toolkit, TIS Gauntlet firewall, whitehouse.gov, and the Network Flight
Recorder. Marcus frequently lectures on Internet security issues, and
is co-author of the "Web Site Security Sourcebook" with Avi Rubin and
Dan Geer, published by John Wiley and Sons. - - BRUCE SCHNEIER, President of Counterpane Systems and author of Applied
Cryptography.  Mistakes and Blunders: A Hacker Looks at Cryptography.
- From encryption to digital signatures to electronic commerce to secure
voting--cryptography has become the enabling technology that allows us
to take existing business and social constructs and move them to computer
networks.  But a lot of cryptography is bad, and the problem with bad
cryptography is that it looks just like good cryptography; most people
cannot tell the difference.  Security is a chain: only as strong as the
weakest link.  In this talk I'll examine some of the common mistakes
companies make implementing cryptography, and give tips on how to avoid
them.  Bruce Schneier is President of Counterpane Systems, the author of
Applied Cryptography, and the inventor the Blowfish algorithm.  He
serves on the board of the International Association for Cryptologic
Research and the Electronic Privacy Information Center.  He is a
contributing editor to Dr. Dobb's Journal, and a frequent writer and
lecturer on cryptography.
- - THEO DERAADT, Lead developer of OpenBSD. A discussion of secure coding issues, problems with maintaining OS
source trees, and secure program design philosophies.  Regular systems
software has many security problems.  A number of approaches at auditing
and repairing these problems have been developed as a result of the
OpenBSD project.
Theo de Raadt heads the OpenBSD project.  This 4.4BSD derived operating
system project has increasingly placed its focus on discovery and
repair of security issues.  Due to a 2 year auditing process by a
10-member team, OpenBSD is probably the most secure operating system
in common use today.  For more information, see
- - IRA WINKLER, President of the Information Security Advisory Group. Information Security: Beyond the Hype If you read the headlines today,
you would think that no matter what people are doing to secure themselves,
they will never be secure.  The reason this idea comes across is
that the media focuses on the threats and stories about unstoppable
geniuses that can compromise even the Pentagon. The truth is that you
can protect yourself from even the most diabolical genius.  This
presentation discusses Information Security from a Risk based perspective.
The threats to your systems are discussed, but more important the
vulnerabilities that actually allow the threats to compromise your
systems are discussed.  Using that information, you can then choose the
countermeasures you need to protect yourself and your organization.  This
presentation will show you that while there is no such thing as perfect
security, you can protect yourself from almost all of the most serious
threats.  Probably what is most valuable to attendees is guidance on how
to spend limited funding in the most efficient manner. Ira Winkler, CISSP is considered one of the worlds leading experts on
Information Security, Information Warfare, investigating information
related crimes, and Industrial Espionage.  He is author of the book,
Corporate Espionage, and President of the Information Security Advisors
Group.  His clients include some of the largest companies and banks in
the world.  He is also a columnist for ZDTV with his column titled
SpyFiles.  He also functions as the network's security expert.  Previously,
Mr. Winkler was with the National Security Agency and was the Director of
Technology with the National Computer Security Association.  He has also
performed studies on Information Warfare for the Joint Chiefs of Staff. - - DOMINIQUE BREZINSKI, Network Security Professional at Secure Computing
Corporation. Penetrating NT Networks Through Information Leaks and Policy
Weaknesses.  The focus of this presentation will be a demonstration of how
Windows NT hosts can be queried for information and how the information
can be correlated to provide an attacker with a path of least resistance.
Even though many Windows NT networks have few remotely exploitable
technical vulnerabilities (buffer over-runs, flawed CGI scripts, address
based authentication etc.), most NT networks give away too much
information.  By analyzing the information it is easy to find policy
weaknesses that can be exploited to gain access to the NT hosts.  Custom
tools will be demonstrated on a small network. Dominique Brezinski is a Network Security Professional at Secure
Computing Corporation and has been concentrating on Windows NT and
TCP/IP network security issues for four years. Prior to working for
Secure Computing, Mr. Brezinski worked as a Research Engineer at
Internet Security Systems where he was responsible for finding new
vulnerabilities and security assessment techniques for Windows NT.  In
1996 Mr. Brezinski published a white paper entitled "A Weakness in
CIFS Authentication" which revealed a serious flaw in the
authentication protocol used in Windows NT (NT LM Security). It was
shown for the first time that an attacker could completely subvert
the network authentication in Windows NT to gain unauthorized access
to Windows NT servers. Mr. Brezinski has continued to demonstrate
advanced techniques for assessing the risks present in Windows NT
networks.   - - RICHARD THIEME, Thiemeworks, Inc.  Convergence -- Every Man (and Woman)
a Spy.  Arbitrary digital interfaces - television, PCs, PDAs - are
converging, but that's only part of the story. The roles people play
in work and life are converging too. Intelligence agents, knowledge
managers for global corporations, competitive business intelligence
agents, sysadmins, hackers,  journalists, and CIOs are becoming
indistinguishable. Why does that matter? Because the ability to
synthesize and integrate information, manage complexity and ambiguity,
morph continually into roles appropriate to a shifting work context, and
somehow remember who you are - that's what matters most. Our
presentations of ourselves are the powerful levers that move mountains
in the digital world. Richard Thieme discusses why and how to do it.
Richard Thieme is a business consultant, writer, and professional speaker
focused on the human dimension of technology and the workplace. His
creative use of the Internet to reach global markets has earned accolades
around the world.  "Thieme knows whereof he speaks," wrote the Honolulu
Advertiser. He is "a prominent American techno-philosopher" according to
LAN Magazine (Australia), "a keen observer of hacker attitudes and behaviors" according to Le Monde (Paris), "one of the most creative minds
of the digital generation" according to the editors of Digital Delirium,
and "an online pundit of hacker culture" according to the L A Times.
Thieme's articles are published around the world and translated into
German, Chinese, Japanese and Indonesian. His weekly column, "Islands
in the Clickstream," is published by the Business Times of Singapore,
Convergence (Toronto), and South Africa Computer Magazine as well as
distributed to subscribers in 52 countries.
Recent clients include:  Arthur Andersen; Strong Capital Management;
System Planning Corporation; UOP; Wisconsin Power and Light; Firstar
Bank; Northwestern Mutual Life Insurance Co.; W. H. Brady Company;
Allstate Insurance; Intelligent Marketing; and the FBI.
- - RAY KAPLAN. Generally, "hackers" are regarded as criminals by the
"legitimate community."  Who are these "hackers" that seem to keep
whacking on our systems and networks? Are they merely scumbag reprobates
that should be purged from the society?  Is there anything to learn from
them?  This session is intended to introduce the two sides of the security
equation to one another in a forum which fosters open, detailed, honest
communication.  Bring your questions.
Who are the enemies of computer and network security?  What techniques do
they employ against us?  Are those that attack our  systems all just a
bunch of slime balls that are devoid of morals,  ethics, and common sense?
While in the minority of reported  computer crime statistics, the skilled
outsider still represents a  significant threat.  This session explores who they are, their attitudes, their techniques, their
successes and their failures from the perspective of what we have to learn
from them to better protect your systems and networks.  This classic session
allows you to interact directly with members of the computer underground.
Join us for some stimulating conversation with those who computer security
professionals consider to be their enemies.  Mr. Kaplan has been actively involved with system and network security as
a consultant for over half of his more than 20 years in the industry.
There is no question that he hacks.  However, he is not a criminal.  His
clients have included the world's largest financial institution, smallest
commodities broker and a wide variety of organizations, including
multinational and Fortune 100 companies from all segments of the economy,
and public institutions all over the world.  Mr. Kaplan is a very prolific lecturer, instructor and writer.  He
consults, lectures and teaches technical system and network-related topics
all over the world.  His articles are frequently published in major computer
journals and magazines.  In over ten years of public speaking and
audio/video conference production, he has given over 2,000 technical,
tutorial-style presentations and lectures in forums such as professional
societies, seminars and his consulting.  As a frustrated inventor, he is
forever trying to rid the  world of inefficiency, frustration and waste by
pursuing new paradigms in the delivery of training, education and technical
information. - - PETER SHIPLEY - An overview of a 2 year effort in massive multi-modem
wardialing.  Security problems occur when obvious security problems are
overlooked.  One commonly overlooked problem is alternative access methods
to a corporate Intranet from an external machine. Many if not most
companies are overlooking their secondary vulnerabilities surrounding
alternate methods of  network access.
Mr. Shipley will present research covering an overview of a 2 year effort
in massive multi-modem wardialing.  His findings will include some personal
observations and the results obtained from scanning the San Francisco Bay
area.  When Mr. Shipley started this project he noted that there were no
published research references to wardialing or documented statistical
results of the types of equipment and computer networks commonly found
on the POTS (Plain old telephone system) network.  Mr. Shipley decided to
change that through his research.
Mr. Shipley Is an independent consultant in the San Francisco Bay Area with
nearly thirteen years experience in the Computer Security field.
Mr. Shipley is one of the few individuals who is well known and respected
in the professional world as well as the underground and hacker community.
He has extensive experience in system and network security as well as
programming and project design. Past and current clients include TRW, DHL,
Claris, USPS, Wells Fargo, and KPMG.  In the past Mr. Shipley has designed
Intranet banking applications for Wells Fargo, Firewall design and testing
for and, WWW server configuration and design for DHL.  Mr. Shipley's
specialties are third party penetration testing and firewall review,
computer risk assessment, and security training.  Mr. Shipley also performs
post intrusion analysis as well as expert witness testimony.   Mr. Shipley
is currently concentrating his efforts on completing several research
- - Thomas Ptacek, Network Security Professional at Secure Networks, Inc.
Defeating Network Intrusion Detection.
Network intrusion detection (ID), a technology that attempts to identify
attackers by monitoring network traffic, is fast becoming one of the hottest
products in the security market. Beneath the hype, however, lie some serious
concerns about the reliability of currently available ID systems, as well as
the fundamental techniques they use to collect information.  This talk will
explain why the most popular ID systems on the market can't be trusted,
demonstrate how to avoid detection by them, and, in the process, eliminate
some very widespread misunderstandings about the capabilities of sniffers
and intrusion detection systems. Thomas Ptacek is a developer at Secure Networks, Inc. His work focuses on
vulnerability assessment, which involves researching and testing network
systems for exploitable design and implementation flaws. In the course of
this work, his team has discovered some of the Internet's most serious
security problems, including vulnerabilities in Windows NT, Checkpoint
Firewall-1, and Solaris, as well as core Internet software such as the
BIND, INN, and Apache.
- - DR. MUDGE, Administrator of the Boston L0pht Heavy Industries.
Real world VPN implementation security issues.
As one of the prominent members of the hacker group 'The L0pht', mudge has
been responsible for numerous advisories and tools in use in both the black
hat and white hat communities. L0phtcrack, the Windows NT password
decryptor - monkey, the S/Key password cracker, Solaris getopt() root
vulnerability, sendmail 8.7.5 root vulnerability, Kerberos 4 cracker,
and SecurID vulnerabilities are some of the recent offerings that mudge
has contributed to the security community. Mudge recently finished
cryptanalysis work with some of the top US cryptographers - papers
will be published within the next several months. The BBC, Wired
Magazine, Byte Magazine, and the Washington Post have all recently covered
mudge and the L0pht's ongoing projects.
- - SCOTT WADDELL, Cisco-Wheelgroup corporation.
                           Fees and Registration
Registration fees before July 10th are $995, after the 10th are $1195 US.
To register please use the online registration page at
Current payment methods include American Express, Master Card, Visa, and
company checks and money orders.  You will receive a confirmation letter
in the mail informing you of a successful registration.
****************************************************************************                                                Hotel Information
Network Security Solutions '98 will take place July 29th and 30th at the
Plaza Hotel & Casino in Las Vegas, Nevada. To take advantage of conference
rates, reservations must be made prior to June 9. When making arrangements,
please reference Network Security Solutions.
The Plaza Hotel and Casino, Number One Main Street
Las Vegas, NV
Phone: 1-800-634-6575               Network Security Solutions Summer '98 Sponsors
Aventail Corporation
Aventail (tm) Corporation is the pioneer of policy-based Virtual Private
Network (VPN) software solutions.  Its award winning product, Aventail VPN
(tm) , enables corporations to privately communicate, share applications,
and securely exchange business-critical information over the Internet with
their business partners, customers, suppliers, and remote/mobile employees.
Aventails adherence to open security standards simplifies VPN deployment,
enables interoperability, and leverages corporations existing network
Network Flight Recorder
Network Flight Recorder builds traffic analysis and monitoring tools that
help you see how your network is being used.  Nobody's network is
shrinking or getting less complicated - and networking is becoming the
lifeblood of many modern businesses.  In other words, your job is getting
harder and more important.  Network Flight Recorder's monitoring package
gives you a flexible, user-programmable system that lets you: Recover or
monitor online transaction records, keep historical statistics about how
your network grows, generate detailed breakdowns of how your network
services are being used and by whom, watch for patterns of abuse of
network resources and identify the culprit in real-time, set burglar
alarms that alert you to security violations or unexpected changes in
your network, log and monitor who went where on your network, and
replay attackers' sessions and learn what they did.
Knowledge is power, and knowing what's going on within your network is
the key to keeping it operating smoothly. Like our namesake, the aircraft
flight recorder, our system records the information you want about what
happened when, where, and how. If you need to go back and look at a
reliable record of events, your Network Flight Recorder is the first
place to check. We are dedicated to providing the best possible tools for understanding
your network traffic, so you can maintain it and secure it. Counterpane Systems
Counterpane Systems is a cryptography and computer security consulting
firm. We are a virtual company based in Minneapolis, with three full-time
employees and six part-time contractors.  Counterpane provides expert
consulting on Design and Analysis.  This is the majority of
Counterpane's work: making and breaking commercial cryptographic systems
and system designs.  We can analyze all aspects of a security system,
from the threat model to the cryptographic algorithms, and from the
protocols to the implementation and procedures.  Our detailed reports
provide clients with information on security problems as well as
suggested fixes.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis,MN  55419       Fax: 612-823-1590

@_date: 1998-04-23 06:53:36
@_author: Bruce Schneier 
@_subject: NSA GAK Report Up 
I believe it was made public by the NSA.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis,MN  55419       Fax: 612-823-1590

@_date: 1998-08-10 16:18:53
@_author: Bruce Schneier 
@_subject: Internet is rickety 
See my editorial:
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-08-16 06:57:41
@_author: Bruce Schneier 
@_subject: Announcement: Cryptanalysis of Frog (an AES Candidate) 
Results Announcement:
D. Wagner, N. Ferguson, and B. Schneier, "Cryptanalysis of Frog," Counterpane Systems Report, Aug 1998.
                                                     Abstract:
We examine some attacks on the FROG cipher.  First we give a differential attack which uses about $2^{58}$ chosen plaintexts and very little time for the analysis; it works for about $2^{-33.0}$ of the keyspace.  Then we describe a linear attack which uses $2^{56}$ known texts and works for $2^{-31.8}$ of the keyspace.  The linear attack can also be converted to a ciphertext-only attack using $2^{64}$ known ciphertexts.  Also, the decryption function of FROG is a lot weaker than the encryption function.  We show a differential attack on the decryption function that requires $2^{36}$ chosen ciphertexts and works on $2^{-29.3}$ of the keyspace.  Using our best attack an attacker with a sufficient number of cryptanalytical targets can expect to recover his first key after $2^{56.7}$ work.   Taken together, these observations suggest that FROG is not a very strong candidate for the AES. This paper is available at  and will be made available at the AES Workshop next week.
Bruce Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-08-16 08:09:47
@_author: Bruce Schneier 
@_subject: Microsoft Electronic Commerce patent: Prior Art? 
I just received this in email.
------------begin forwarded message--------
Dear Bruce,
the Microsoft Patent 5,768,385 filed Aug. 29, 1995, issued Jun. 16, 1998
on "Untraceable Electronic Cash" is nothing more than a well written remake
of the "Anonymously Transferable Standard Values" presented at IFIP Sec
1986 under the name "Anonymous Standard Value Accounts", published both in
the Pre- and Post-Proceedings there, more detailed in a research report of
1987 and even published in a refereed journal, Computers & Security in
1989, see below.
I do not know the legal system of the US well enough to know whether
challenging the patent is worthwhile and I do neither have the time nor
money to do it for myself, but I think it is at least worthwhile for the
security community to know.
So please feel free to distribute this information, e.g. within CRYPTO-GRAM.
Yours Andreas

@_date: 1998-08-17 21:55:34
@_author: Bruce Schneier 
@_subject: Announcement: New Twofish Results 
Results Announcement:
N. Ferguson, , "Upper Bounds on Differential Characteristics in Twofish," Twofish Technical Report  Counterpane Systems, Aug 1998.
                                                     Abstract:
In our initial paper the Twofish block cipher was introduced, and initial estimates of an upper bounds on the probability of a 12-round differential were given. These results used an imperfect model of Twofish. We present an improved model, and show that any 12-round differential characteristic has a probability of at most $2^{-102.8}$.
This paper is available at  and will be made available at the AES Workshop next week.
Bruce Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-08-21 22:26:34
@_author: Bruce Schneier 
@_subject: Announcing:  WWW Cryptography Article Database 
Announcing:  WWW CRYPTOGRAPHY ARTICLE DATABASE
Counterpane Systems
Counterpane Systems has created an extensive bibliography of links to cryptography papers available on the World Wide Web.  We hope to build a comprehensive database of published papers available on the net, organized both by author and by year.
Users can view the bibliography by author (every author is indexed, not just the first author) or by publication year.  There will also be a single page containing all the citations, to facilitate searching the full bibliography (by keyword, for example) with your browser's search function.
Counterpane wants this database to be a research tool for the community, and for it to be continuously updated.  We will frequently monitor the WWW for new articles for our database.  Researchers can also submit articles for inclusion in the database using an on-line form; see the webpage for details.
Please help.  If you have papers on the Web, please submit them into our database.  If you know of any archives of papers that I missed, please let me know.  If there are any features youd like to see, please suggest them.
Future enhancements include grouping of papers by subject, the inclusion of searchable paper summaries, and the ability to comment on research papers.  We hope to also broaden the scope of the database to computer security in general.
Please take a moment to try out the Counterpane Cryptography Article Database, and let us know what you think.
Thank you,
Bruce Schneier Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-08-25 18:29:26
@_author: Bruce Schneier 
@_subject: Announcement: $10,000 Twofish Cryptanalysis Contest 
To stimulate research into Twofish, the designers are putting their money
where their mathematics is. They are offering $10,000 in prize money for
the best attack on Twofish during the first round of the AES evaluation.
This contest is very different from most other cryptanalysis contests.
There is no ciphertext to decrypt, and no key to find. Instead, the $8,000
first prize will be awarded to the person or group (other than the Twofish
design team) that publishes the best cryptanalysis of Twofish. The runner
up will get a $2,000 second prize.  To qualify the cryptanalysis has to
contain a significant new result not published earlier by the Twofish team.
If no new results are published, the prizes will not be awarded. The
deadline of the contest is NIST's deadline for first-round AES comments;
the result should be presented in a format compatible with the NIST
requirements for first-round comments.  Decisions of the judges (the
Twofish design team) are final.
Good luck,
Bruce Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-12-03 08:40:05
@_author: Bruce Schneier 
@_subject: L5 algorithm patent, and free eval version 
It could mean that a set of claims were allowed.  I have been involved in
several patents.  Generally, you submit the patent and then a year and a half later the patent office responds.  This is the "first office action."
the claims are rejeted, sometimes some of them are allowed.  Then you send
a letter back to the patent office, and maybe draft new claims.  Eventually
may be a second office action) a series of claims are allowed, meaning that
they will be included in the patent.  It can be another six months before the
patent issues.
I expect that's what the L5 people were talking about.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-12-04 06:18:41
@_author: Bruce Schneier 
@_subject: Twofish/AES News 
There are some new papers on the Twofish webpage.
We have improved our performance numbers.  On Pentium-class machines, key
setup is faster.  We also have large-RAM implementations, that speed key
setup at the expense of 256K of RAM.  We aso have a variety of performance
options on smart cards, trading RAM off for speed.  And finally, we have a
new hardware implementation that reduces the total gate count.  Details are
in Twofish Technical Report Dave Barton has implemented Twofish in Delphi:
And finally, we have compared the performance of all AES submissions on
32-bit processors, smart cards, and hardware.  Our results are in.
As always, thanks for your support.
Bruce Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-12-16 12:41:48
@_author: Bruce Schneier 
@_subject: The Fallacy of Cracking Contests 
Bruce Schneier
You see them all the time: "Company X offers $1,000,000 to anyone who can
break through their firewall/crack their algorithm/make a fraudulent
transaction using their protocol/do whatever."  These are cracking
contests, and they're supposed to show how strong and secure the target of
the contests are.  The logic goes something like this:  We offered a prize
to break the target, and no one did.  This means that the target is secure.
It doesn't.
Contests are a terrible way to demonstrate security.  A
product/system/protocol/algorithm that has survived a contest unbroken is
not obviously more trustworthy than one that has not been the subject of a
contest.  The best products/systems/protocols/algorithms available today
have not been the subjects of any contests, and probably never will be.
Contests generally don't produce useful data.  There are three basic
reasons why this is so.
1.  The contests are generally unfair.  Cryptanalysis assumes that the attacker knows everything except the secret.
 He has access to the algorithms and protocols, the source code,
everything.  He knows the ciphertext and the plaintext.  He may even know
something about the key.
And a cryptanalytic result can be anything.  It can be a complete break: a
result that breaks the security in a reasonable amount of time.  It can be
a theoretical break: a result that doesn't work "operationally," but still
shows that the security isn't as good as advertised.  It can be anything in
Most cryptanalysis contests have arbitrary rules.  They define what the
attacker has to work with, and how a successful break looks.  Jaws
Technologies provided a ciphertext file and, without explaining how their
algorithm worked, offered a prize to anyone who could recover the
plaintext.  This isn't how real cryptanalysis works; if no one wins the
contest, it means nothing.
Most contests don't disclose the algorithm.  And since most cryptanalysts
don't have the skills for reverse-engineering (I find it tedious and
boring), they never bother analyzing the systems.  This is why COMP128,
CMEA, ORYX, the Firewire cipher, the DVD cipher, and the Netscape PRNG were
all broken within months of their disclosure (despite the fact that some of
them have been widely deployed for many years); once the algorithm is
revealed, it's easy to see the flaw, but it might take years before someone
bothers to reverse-engineer the algorithm and publish it.  Contests don't
(Of course, the above paragraph does not hold true for the military.  There
are countless examples successful reverse-engineering--VENONA, PURPLE--in
the "real" world.  But the academic world doesn't work that way,
fortunately or unfortunately.)
Unfair contests aren't new.  Back in the mid-1980s, the authors of an
encryption algorithm called FEAL issued a contest.  They provided a
ciphertext file, and offered a prize to the first person to recover the
plaintext.  The algorithm has been repeatedly broken by cryptographers,
through differential and then linear cryptanalysis and by other statistical
attacks.  Everyone agrees that the algorithm was badly flawed.  Still, no
one won the contest.
2.  The analysis is not controlled.
Contests are random tests.  Do ten people, each working 100 hours to win
the contest, count as 1000 hours of analysis?  Or did they all try the same
things?  Are they even competent analysts, or are they just random people
who heard about the contest and wanted to try their luck?  Just because no
one wins a contest doesn't mean the target is secure...it just means that
no one won.
3.  Contest prizes are rarely good incentives.  Cryptanalysis of an algorithm, protocol, or system can be a lot of work.
People who are good at it are going to do the work for a variety of
reasons--money, prestige, boredom--but trying to win a contest is rarely
one of them.  Contests are viewed in the community with skepticism: most
companies that sponsor contests are not known, and people don't believe
that they will judge the results fairly.  And trying to win a contest is no
sure thing: someone could beat you, leaving you nothing to show for your
efforts.  Cryptanalysts are much better off analyzing systems where they
are being paid for their analysis work, or systems for which they can
publish a paper explaining their results.
Just look at the economics.  Taken at a conservative $125 an hour for a
competent cryptanalyst, a $10K prize pays for two weeks of work, not enough
time to even dig through the code.  A $100K prize might be worth a look,
but reverse-engineering the product is boring and that's still not enough
time to do a thorough job.  A prize of $1M starts to become interesting,
but most companies can't afford to offer that.  And the cryptanalyst has no
guarantee of getting paid: he may not find anything, he may get beaten to
the attack and lose out to someone else, or the company might not even pay.
 Why should a cryptanalyst donate his time (and good name) to the company's
publicity campaign?
Cryptanalysis contests are generally nothing more than a publicity tool.
Sponsoring a contest, even a fair one, is no guarantee that people will
analyze the target.  Surviving a contest is no guarantee that there are no
flaws in the target.
The true measure of trustworthiness is how much analysis has been done, not
whether there was a contest.  And analysis is a slow and painful process.
People trust cryptographic algorithms (DES, RSA), protocols (Kerberos), and
systems (PGP, IPSec) not because of contests, but because all have been
subjected to years (decades, even) of peer review and analysis.  And they
have been analyzed not because of some elusive prize, but because they were
either interesting or widely deployed.  The analysis of the fifteen AES
candidates is going to take several years.  There isn't a prize in the
world that's going to make the best cryptanalysts drop what they're doing
and examine the offerings of Meganet Corporation or RPK Security Inc., two
companies that recently offered cracking prizes.  It's much more
interesting to find flaws in Java, or Windows NT, or cellular telephone
The above three reasons are generalizations.  There are exceptions, but
they are few and far between.  The RSA challenges, both their factoring
challenges and their symmetric brute-force challenges, are fair and good
contests.  These contests are successful not because the prize money is an
incentive to factor numbers or build brute-force cracking machines, but
because researchers are already interested in factoring and brute-force
cracking.  The contests simply provide a spotlight for what was already an
interesting endeavor.  The AES contest, although more a competition than a
cryptanalysis contest, is also fair Our Twofish cryptanalysis contest offers a $10K prize for the best negative
comments on Twofish that aren't written by the authors.  There are no
arbitrary definitions of what a winning analysis is.  There is no
ciphertext to break or keys to recover.  We are simply rewarding the most
successful cryptanalysis research result, whatever it may be and however
successful it is (or is not).  Again, the contest is fair because 1) the
algorithm is completely specified, 2) there are no arbitrary definition of
what winning means, and 3) the algorithm is public domain.
Contests, if implemented correctly, can provide useful information and
reward particular areas of research.  But they are not useful metrics to
judge security.  I can offer $10K to the first person who successfully
breaks into my home and steals a book off my shelf.  If no one does so
before the contest ends, that doesn't mean my home is secure.  Maybe no one
with any burgling ability heard about my contest.  Maybe they were too busy
doing other things.  Maybe they weren't able to break into my home, but
they figured out how to forge the real-estate title to put the property in
their name.  Maybe they did break into my home, but took a look around and
decided to come back when there was something more valuable than a $10,000
prize at stake.  The contest proved nothing.
Gene Spafford wrote against hacking contests.
Matt Blaze has too, but I can't find a good URL.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-01-06 10:53:42
@_author: Bruce Schneier 
@_subject: Comparing PGP to Symantec's Secret Stuff 
I second this.  The pitiful state of "secure code" is shocking.  (Actually,
I just wrote an essay on the topic.  Get a copy for yourself at:
* Bruce Schneier                 For information on APPLIED CRYPTOGRAPHY
* Counterpane Systems            2nd EDITION (15% discount and errata), * schneier at counterpane.com       Counterpane Systems's consulting services, *     or the Blowfish algorithm, see my website.

@_date: 1998-01-06 11:04:29
@_author: Bruce Schneier 
@_subject: Comparing PGP to Symantec's Secret Stuff 
Blowfish with a 32-bit key has been approved for export before.  The argument is that the long key setup time makes 32-bit Blowfish as weak
as 40-bit anything else.  I don't particularly agree, but there you have it.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis,MN  55419       Fax: 612-823-1590

@_date: 1998-01-20 05:47:07
@_author: Bruce Schneier 
@_subject: British Ministers Adopt Unbreakable Crypto 
This is INSANE.  How could someone be so stupid as to announce
such a feature in a newspaper.  I guess this means that if a
terrorist sees a Cabinet minister with such a computer, he had
better shoot to kill.
The whole point of a feature like this is that its existence is secret.
Someone is NOT paying attention.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis,MN  55419       Fax: 612-823-1590

@_date: 1998-01-29 12:32:10
@_author: Bruce Schneier 
@_subject: Announcement: RPK InvisiMail released on 12 Jan, 1998 
A bunch of us cryptographers would really like to attack RPK, but the
documents on the website are slippery enough to make it difficult.  There
is enough unspecified for them to sneak away from any analysis.
If someone were to reverse engineer the RPK cryptosystem from this product,
I would really appreciate it.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis,MN  55419       Fax: 612-823-1590

@_date: 1998-07-01 15:49:58
@_author: Bruce Schneier 
@_subject: Security Newsletter from Bruce Schneier 
I've just started a crypto newsletter: CRYPTO-GRAM is a free monthly email  newsletter on cryptography from Bruce Schneier (author of Applied Cryptography, inventor of Blowfish, general crypto pundit and occasional crypto curmudgeon).
You can subscribe to CRYPTO-GRAM:
In the May issue:
In the June issue:
Other regular features include:
We understand and respect your right to privacy.  You are receiving this email only because you have demonstrated an interest in the areas of privacy, security and encryption. You should also know that we would not sell, rent or share our mailing list should you decide to subscribe. Our goal is to maintain and develop a relationship of integrity and trust with our subscribers.  The members of this list are not for sale.  Period.
If you have any questions, don't hesitate to contact me.  Otherwise, I hope you'll take a moment to subscribe to CRYPTO-GRAM at:             or mailto:crypto-gram-subscribe at chaparraltree.com
Bruce Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590

@_date: 1998-06-14 06:01:20
@_author: Bruce Schneier 
@_subject: Twofish (our AES Submission) is Available 
Twofish, the block cipher we have submitted to NIST's AES competition, is on the web.  Please see
for details, including description, analysis, source code, and test vectors.
Other AES submissions will presumably be made public as the weeks progress, although NIST will not publish the submissions until the August meeting.  See the NIST website at
for more details.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590

@_date: 1998-06-14 16:06:56
@_author: Bruce Schneier 
@_subject: Twofish soruce code outside the U.S. 
It's time to play the dumb export control game.
I have to take steps to prevent non-US and non-Canadian persons from downloading the Twofish source.
However, if someone outside the US manages to get their hands on the Twofish source from my website and puts it up on their website, please let me know.
I would like very much to link to it, so others can get the Twofish code.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590

@_date: 1998-06-14 17:00:43
@_author: Bruce Schneier 
@_subject: Converting my Twofish PostScript file to pdf 
We have been unable to do this.  We've tried, a few times, and failed miserably.
If anyone has the correct tools to do a clean conversation from Postscript into pdf, please do so and send me the pdf file.  I will post it.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590

@_date: 1998-06-15 06:15:21
@_author: Bruce Schneier 
@_subject: I have the Twofish paper in pdf; thanks 
You can stop sending me new versions.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590

@_date: 1998-06-24 10:33:31
@_author: Bruce Schneier 
@_subject: Comments on "Encryption is Key to Securing Data" 22 Jun 98 
This note is to comment on your article,  "Encryption is Key to Securing Data," that appeared in the 22 Jun 98 issue of InternetWeek.  I'm not sure where to start.  Almost every statement made in the copy is erroneous.  (There was an error when I tried to download the article from your website, so I will retype.  Apologies for minor typos.)
Encryption is Key to Securing Data
by Dayna DelMonico
"Although encryption terminology can make even the most technically astute user cringe, encryption is fairly simple."  I agree, although the rest of this article seems to prove me wrong.  "It's the process of scambling and unscrambling information."
Partly.  It's confidentially (what you said above--making sure secret things stay secret), integrity (making sure data doesn't get modified in transit), authentication (the digital analogue of a signature), and non-repudiation (making sure someone can't say something and then later deny saying it).  Cryptography is a lot more than simple encryption.
"Encryption products showed up when MIS managers adopted two basic encryption technologies from the federal government: private and public-key encryption."
Nothing correct here.  The Federal government has no public-key cryptography standards; MIS managers have nothing to adopt from the Federal government.  You might be thinking of DES, a symmetric encryption algorithm.  (More on this confusion below.)  In any case, commercial use of cryptography products has developed completely independently from government interference.  In fact, things like export control and key escrow are making it harder to buy secure commercial products, not easier.
"With private key encryption, the sends and recieve are the holders and use the same key (algorithm) to secure information."
No.  First off, private-key encryption is a bad term; use "symmetric encryption."  Second, I'm not sure what they are the holders of.  With symmetric encryption, both the sender and the receiver must have the same key; that may be what you mean.  In any case, the key and the algorithm are completely seperate.  This is one of the cornerstones of post-Medieval cryptography.
"With public key encryption, senders and receivers hold a commonly used public key, with an additional private key held only by specific institutions."
Not even close.  With public-key encryption, each receiver has a public key and a private key.  The public key is published.  The private key is held, in secret, by the receiver.  To send a message to someone, the sender gets the public key form some public database and uses it to encrypt the message.  The receiver uses his private key to decrypt it.  There are no specific institutions that have additional private keys, unless you are thinking about key escrow systems (which are related, but not the same).
"To protect systems from the loss of the key, many vendors offer assymetric encypion, which uses two keys."
Sort of.  Assymetric encryption is the same as public-key encryption (just another word), and there are two keys.  But the reason for using public-key encryption is not to prevent the loss of a key, but to facilitate key management.  (With symmetric encryption, both the sender and receiver have to share a key.  How this sharing takes place can be very complicated.)
"Users can choose from products based on various schemes.  Beware, however, that even stronger encryption methods are on the horizon and destined for the next generation of encryption products.  The National Institute of Standards and Technology (NIST) is expected to complete and Advanced Encryption Standard (AES) by the end of the year."
Even NIST has said that AES will not be finalized before 2000.  And AES is just a new symmetric algorithm; it has nothing to do with public-key cryptography.
"The new standard wil luse a 128-bit block size, with key lengths of 128-, 192-, and 256-bits, as opposed to the current 64-bit blocks with 56-bit key standard."
True.  The current standard is DES.
"RSA Data Security also has proposed its own algorithm to content for the new AES standard."
Sort of.  NIST has solicited proposals for algorithms.  Fifteen groups submitted, including RSA Data Security.  RSADSI is competing with other groups--Cylink, IBM, Entrust, Counterpane Systems, NTT, etc--not with NIST.  NIST does not hav an algorithm.
"RSA's extensions to DES, RC4 and RC5 implement multiple keys as well as digital signatures."
Many mistakes here.  RSADSI submitted RC6 to the AES process, which uses many ideas from RC5.  It has nothing to do with DES or RC4.  I'm not sure why multiple keys is something to talk about; as I said above, every algorithm post the Middle Ages uses multiple keys.  And digital signatures have nothing to do with the AES process.  AES is a  new symmetric encryption algorithm; digital signatures are done with public key cryptography.  They are different.
"Another contender is Blowfish II."
I submitted this algorithm.  We called it Twofish, but some early press reports called it Blowfish II.
"The Blowfish scheme, often referred to as PGP (Pretty Good Privacy), lets the sending and receiving computers negotiate a complex number."
First, Blowfish is never referred to as PGP.  Blowfish is a symmetric encryption algorithm.  PGP is an email security product.  PGP could have decided to use Blowfish, but it used IDEA and CAST instead.  Those are two different encrytpion algorithms.  And neither PGP, nor Blowfish, nor anything else discussed to or alluded to in this article, involve sending and receiving computers negotiating complex numbers.
"That number is used to scamble the transmission and unscramble the data that is received."
What you mean to say, I think, is that PGP uses public-key cryptography for key exchange.  The sender uses the reciver's public key to encrypt a session key, and that session key is used to encrypt the email message.
"For more on encryption and encryption products, a buyer's first stop should be the International Computer Security Association.  This ICSA is an independent organization that tests and certifies security products."
ICSA is a private for-profit company, despite what the name implies.  And while they do do some testing and certifying of security products, they do not test or certify encryption products.
Honestly, I can't believe this article made it into print.  Don't you have editors?
Bruce Schneier
President, Counterpane Systems
Author, Applied Cryptography

@_date: 1998-11-15 22:31:05
@_author: Bruce Schneier 
@_subject: Electronic Commerce: The Future of Fraud 
This appeared in my November newsletter, CRYPTO-GRAM, but I thought it
general enough interest to send it here.
Electronic Commerce: The Future of Fraud
Fraud has been perpetrated against every commerce system man has ever
invented, from gold coin to stock certificates to paper checks to credit
cards.  Electronic commerce systems will be no different; if that's where
the money is, that's where the crime will be.  The threats are exactly the
Most fraud against existing electronic commerce systems -- ATM machines,
electronic check systems, stored value tokens -- has been low tech.  No
matter how bad the cryptographic and computer security safeguards, most
criminals bypass them entirely and focus on procedural problems, human
oversight, and old-fashioned physical theft.  Why attack subtle information
security systems when you can just haul an ATM machine away in a truck?
This implies that new commerce systems don't have to be secure, but just
better than what exists.  Don't outrun the bear, just outrun the people
you're with.  Unfortunately, there are three features of electronic
commerce that are likely to make fraud more devastating.
One, the ease of automation.  The same automation that makes electronic
commerce systems more efficient than paper systems also makes fraud more
efficient.  A particular fraud that might have taken a criminal ten minutes
to execute on paper can be completed with a single keystroke, or
automatically while he sleeps.  Low-value frauds, that fell below the radar
in paper systems, become dangerous in the electronic world.  No one cares
if it is possible to counterfeit nickels.  However, if a criminal can mint
electronic nickels, he might make a million dollars in a week.  A
pickpocketing technique that works once in ten thousand tries would starve
a criminal on the streets, but he might get thirty successes a day on the net.
Two, the difficulty of isolating jurisdiction.  The electronic world is a
world without geography.  A criminal doesn't have to be physically near a
system he is defrauding; he can attack Citibank in New York from St.
Petersburg. He can jurisdiction shop, and launch his attacks from countries
with poor criminal laws, inadequate police forces, and lax extradition
And three, the speed of propagation.  News travels fast on the Internet.
Counterfeiting paper money takes skill, equipment, and organization.  If
one or two or even a hundred people can do it, so what?  It's a crime, but
it won't affect the money supply.  But if someone figures out how to
defraud an electronic commerce system and posts a program on the Internet,
a thousand people could have it in an hour, a hundred thousand in a week.
This could easily bring down a currency.  And only the first attacker needs
skill; everyone else can just use software.  "Click here to drop the
deutsche mark."
Cryptography has the potential to make electronic commerce systems safer
than paper systems, but not in the ways most people think.  Encryption and
digital signatures are important, but secure audit trails are even more
important.  Systems based on long-term relationships, like credit cards and
checking accounts, are safer than anonymous systems like cash.  But
identity theft is so easy that systems based solely on identity are doomed.
Preventing crime in electronic commerce is important, but more important is
to be able to detect it.  We don't prevent crime in our society.  We detect
crime after the fact, gather enough evidence to convince a neutral third
party of the criminal's guilt, and hope that the punishment provides a
back-channel of prevention.  Electronic commerce systems should have the
same goals.  They should be able to detect that fraud has taken place and
finger the guilty.  And more important, they should be able to provide
irrefutable evidence that can convict the guilty in court.
Perfect solutions are not required -- there are hundred of millions of
dollars lost to credit card fraud every year -- but systems that can be
broken completely are unacceptable.  It's vital that attacks cannot be
automated and reproduced without skill. Traditionally, fraud-prevention has
been a game of catch-up.  A commerce system is introduced, a particular
type of fraud is discovered, and the system is patched.  Money is made
harder to counterfeit.  Online credit card verification makes fraud harder.
 Checks are printed on special paper that makes them harder to alter.
These patches reduce fraud for a while, until another attack is discovered.
 And the cycle continues.
The electronic world moves too fast for this cycle.  A serious flaw in an
electronic commerce system could bankrupt a company in days.  Today's
systems must anticipate future attacks.  Any successful electronic commerce
system is likely to remain in use for ten years or more.  It must be able
to withstand the future:  smarter attackers, more computational power, and
greater incentives to subvert a widespread system.  There won't be time to
upgrade them in the field.
Why Cryptography is Harder Than it Looks:
Security Pitfalls in Cryptography:
Subscribe to CRYPTO-GRAM:
 Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-10-05 09:40:04
@_author: Bruce Schneier 
@_subject: Review of TriStrata Public Information 
Review of TriStrata Public Information
1  Introduction
Over the past several months, a new company called TriStrata has been
getting substantial press for a new "one-time pad" cryptography system.
Most of these press reports took at face value the company's claims about
their technology and product, and did not try to analyze whether or not
they were true.  Counterpane Systems believes  it is important to dig under
the hype and figure out what the real story is behind their technology.
We reviewed the publicly available documentation on TriStrata, and found a
system whose architecture is that of an early-1970s pre-public-key
cryptography security system.  Central servers, upon which the security of
every message rests, must be kept absolutely secure; yet they run on
Windows NT.  These servers are all powerful, in that they can forge
messages, rewrite audit logs, fake authentication, and lie about anything
else in the system.  Users cannot access their files unless they are
connected to this server.  TriStrata does not use a one-time pad at all,
and none of the security proofs about a one-time pad apply to their system.
Their reliance on this encryption technology forces them to use security
protocols long abandoned by the rest of the security industry.  Even their
performance enhancements bely the fact that encryption is rarely the
bottleneck in any communications system.
Note: For a less-technical summary of this review, please see sections 4.0,
4.1, and 5.0.
2.0  The TriStrata System
2.1  Structure
The TriStrata system uses a centralized server, called the TESS (TriStrata
Enterprise Security Server).  The documentation is not very clear, but
document reference 3 suggests that each company would have its own TESS.
Every encryption or decryption operation requires a "permit" from the TESS.
To encrypt a file or message:
1. The user contacts the TESS over the network.  This can be any type of
network, such as the Internet or a local area network.
2. The user and the TESS authenticate each other using a proprietary
protocol called Private Access Line (PAL). 3. The TESS sends a permit to the user machine, which is used to encrypt
the file or message. The TESS also sends a "seal" to the user.  This seal
is only readable by the TESS. 4. The user simply stores the seal with the file (if it is encrypted
locally), or sends the seal along with the encrypted message (if it is to
be transmitted to another user).
To decrypt a file or message:
1. The user retrieves the seal and sends the seal to the TESS (along with
the authentication data from the PAL protocol).
2. The TESS opens the seal, and determines whether the user is allowed to
decrypt the data.
3. If the user is allowed to decrypt the data, the TESS sends a
decryption permit to the user. 4. The user's local machine uses this permit to decrypt the file or message.
The TESS keeps full audit logs of all operations, and includes procedures
that allow designated recovery agents within the company to recover the
keys to any file.
The system is claimed to provide identification (who is using the system),
authentication (who sent a message), access control (restriction of access
to authorized users), integrity (assurance message is unaltered), and
non-repudiation (sender cannot deny having sent it).  They have received an
export license for their system.
2.2 Authentication
The authentication method used to authenticate the user to the TESS and
vice versa is a crucial part of the security architecture.  The TriStrata
documentation contains no further information than that this is handled by
the Private Access Line protocol.
2.3  Encryption Algorithm
The Random KeyStream (RKS) encryption algorithm used by TriStrata is hailed
as "a new fundamental technology."  It is claimed to be very fast, but the
documentation only contains raw speeds, without documenting which platform
these speeds were achieved on.  The encryption technology is also claimed
to be unconditionally secure. To quote the web site: "No matter how much
mathematical analysis or computing power is applied to the cryptanalysis of
RKS, there is simply no algorithm and no underlying pattern to break.  As
Herbert Yardley foresaw in 1931, cryptography as a profession is dead."
3.0  Our Comments
3.1  The Central Server Structure
Cryptographic systems that use a central access control server are nothing
new. The Kerberos protocol uses a central server for similar tasks.  Using
such a central server as the TESS has several advantages and disadvantages.
The main advantages are:
- There is a central place that administrates all the access rights.  This
makes various administrative tasks easier.
- Revocation of access is automatically supported by the system.  No
separate revocation mechanism is necessary.
- The central server can keep comprehensive auditing logs of
security-related operations.
The main disadvantages are:
- The central server contains confidential information, namely the master
keys that can decrypt any file. It is thus a very tempting target for
attack.  The central server must be very well protected.  At the same time,
the server must be reachable from across the network, and must be reliable,
as nothing can work without a functioning server.  The end result is a
server that is expensive (due to all the requirements) and that still is an
obvious point of attack.
- The central server is a single point of failure. TriStrata uses a
redundant server structure with fail-over, so that a second server takes
over when the first fails.  A fail-over structure protects against
technical errors, but does not necessarily protect against
denial-of-service attacks.  The TESS is based on a "security hardened"
version of Windows NT, an operating system that is not known for its
resistance to malicious attacks.
- The system is effectively a closed system.  Only users who are registered
at the server can partake in the system.  It is not clear how two users
that belong to different servers would communicate.  The TriStrata
documentation mentions electronic commerce extensively, but it does not
discuss how two users at two different companies can use the TriStrata
system to communicate with each other.
- Since the server contains crucial confidential information, every company
must run its own server.  A failure of the server, such as a leak of the
master keys from the server, can reveal all of the company's information.
This is the kind of task that should not be outsourced.  In contrast, the
key server of a public-key-based system is much easier to outsource as it
can be designed so as not to be critical for security.
- The TriStrata solution does not allow a user that is off-line to access
any encrypted files.  A salesman that keeps his data encrypted on his
portable computer cannot access the data without contacting the TESS.  If
he cannot get network access for some reason (e.g., on an airplane,
mismatched phone plug, etc.), he cannot access his own files.
The TriStrata solution is a return to a very old style of centralized key
management.  For some applications this is a good solution, but there are
many situations in which a centralized server is not appropriate.  For
example, one function that a central server cannot do well is
non-repudiation between adversarial parties (one of the critical functions
in electronic commerce).  The TESS system seems to provide non-repudiation
through inspection of the logs of the TESS.  But if a message is sent
between two companies, which TESS do they use? The company that owns the
TESS that is used can manipulate the logs in their own favor.  The end
result is that there is no watertight proof that the message was sent or
In effect, this solution takes us back to the days before public-key
cryptography.  Since its invention in the late 1970s, the ideas of
certificates, public key infrastructure, decentralized key management,
separation of encryption and digital signature functions, etc., have all
been implemented in response to insecurities in centralized systems.  For
example, public-key infrastructures use trusted third parties like the
TESS, but in a public-key system, compromise of the trusted third party
only allows an attacker to issue false certificates, not to decrypt and
read messages.
3.2  Authentication
We have no further information on the PAL protocol.  The documentation does
state that the communication with the TESS consists of a single message
from the user to the TESS, and a single reply back.  Elsewhere it says that
the TESS is stateless, which makes it easy to do a fail-over should one
TESS fail.
It is not clear to the reviewers how the PAL protocol works, if we assume
it consists of two messages and is stateless for the TESS.  These two
properties together would suggest that an attacker can replay requests to
the TESS.  If nothing else, this introduces fake entries in the audit log.
Some of these attacks can be hindered by the use of local clocks, but every
solution along these lines we have ever seen is always troubled by clock
synchronization problems.
We note that the PAL protocol is critical for the security of the overall
system.  If an attacker can impersonate another user, then he can request
the proper permit from the TESS to decrypt a file, and will get access
regardless of the security of the actual encryption algorithm.  The PAL
protocol deserves careful scrutiny before the TriStrata system is put to use.
The most straightforward attack against the TriStrata system is to
introduce some hostile code into the client's PC (for example, a virus or
Trojan horse). This hostile code can then steal the necessary
authentication information and send it back to the attacker.  This type of
attack is a generic attack against any security system, not just the
TriStrata system, but it shows that the "provable security" is at best
limited to a small part of the system and does not extend to the whole system.
3.3  Encryption
To put it bluntly: the TriStrata system does not use the one-time pad
system (Vernam cipher) for encryption.  A true one-time pad uses a random
key that is distributed through a separate secure channel.  While a
one-time pad is, in fact, theoretically unbreakable when used properly, the
details of using it properly make it entirely unusable in any modern
commercial or military setting.
A true one-time pad gains its unbreakable security from the fact that the
key is as long as the message.  Since all keys are equally likely, and a
particular ciphertext could represent any message, given a particular key,
the ciphertext reveals nothing about the plaintext message without the
correct key.  These random keys must be entirely random; this usually
requires generating them from some external random source (such as thermal
noise or radioactive decay).  And both the sender and the receiver must
have this secret key, which must be exchanged in some fashion which the
attacker cannot penetrate.
The requirement that the keys be as long as the data to be exchanged and
that the key needs to be transported via some secure mechanism makes the
one-time pad system entirely impractical.  In order to send a 1 MB message,
the sender and receiver must exchange a 1 MB-long key.  Then the sender
could send the message and the receiver could use the key to decrypt it.
The key would then have to be thrown away and never used again.  If the
sender wanted to exchange messages with a hundred people, he would have to
pre-agree on different keys between each recipient.  For a company with a
thousand employees, this means that there are 499,500 different key sets,
which need to be replenished any time they are exhausted by message exchange.
Because the key has to be as long as the message, there is no way to use an
established system to exchange more keys, since in order to securely send
as 1 MB key a user needs 1 MB of additional pre-agreed key.  (And if users
can exchange these keys, why can't they just exchange the messages?)  This
means that all keys have to be exchanged via some other mechanism (such as
a courier).  This kind of system was used for the U.S.-Soviet teletype "hot
line" and it is occasionally used for paper ciphers and spies, but that's it.
There is no way in which a true one-time pad can be implemented over a
computer network.  From the information provided by TriStrata, we believe
that the encryption method used is a keystream method where an algorithm
generates a key stream which is then XORed with the plaintext to generate
the ciphertext.  This is known as a pseudo one-time pad, and is also called
an OFB stream cipher.  One of the modes of DES works in this manner, as
does the RC4 encryption algorithm.  This is not new technology. A pseudo one-time pad encryption algorithm can be secure, but claiming that
it is secure because it is based on the one-time pad is ridiculous.  The
strength of the cipher algorithm depends on the method used to generate the
key stream. The speed given for the encryption method is fairly fast, but without
knowing what platform was used to achieve these speeds, no sensible
comparison can be made.  To give some comparison material: the leading
candidates for the AES block cipher encryption standard can encrypt data in
about 18 clock-cycles per byte on a Pentium II.  A standard 350 MHz desktop
machine thus achieves nearly 20 Mbytes per second.  This compares to the
TriStrata claimed speed of 36 Mbytes per second for a standard desktop
machine.  The TriStrata figures are faster, but only by a factor of two.
This would be a nice speedup, but it does not present a fundamental
breakthrough in speed.
Reference 4 is a magazine article report that contains more information
about the encryption algorithm.  As with any magazine article, the accuracy
of the information is hard to judge.  Nevertheless, the information it
provides fits well with the information we have from TriStrata.
The TESS generates a single 1 Mbyte block of random data using a hardware
random number generator.  This block is distributed to all clients.  (A
second block is used for authentication, but we have no further information
on the algorithm.)  The encryption algorithm keeps several pointers into
this random block and derives the random key stream from the data the
pointers point to. This is a known technique, first used by Maurer in his
randomized cipher [Reference 5].  The TriStrata documentation talks about a
virtual keystream of over 10^30 bytes, which would correspond to 5 pointers
into a 1 Mbyte block.  This suggests an effective key size of at most 100
bits.  On the other hand, the website also claims that it would take 3.5 x
10^33 years to defeat one TriStrata-encrypted message, which would suggest
either a larger key space or a fundamental misunderstanding of the
mathematical properties of Maurer's system.
The random block is the same for all the clients.  It has to be, as the
client that does the decryption needs the same random block as the client
that does the encryption (and sending 1 Mbyte blocks around in the permit
is too slow).  Therefore, we cannot view this random block as a secret.
After all, a secret shared amongst thousands of users is not a secret any
more.  If we want a more conventional representation of the encryption
algorithm, we can represent the random block as a randomly generated 20 by
8-bit S-box. We have no knowledge about the details of this encryption algorithm, but
the most straightforward variants of this type are susceptible to a
meet-in-the-middle attack on the pointer space.  This could reduce the
effective key size to as little as 60 bits.
The journalist did a speed test of TriStrata's file encryption utility.  On
a 200 MHz Pentium Pro, 128 MB RAM and PCI Ultra-SCSI disk subsystem it
encrypted a 58 MB file in 18 seconds.  This corresponds to a speed of 3.2
Mbytes per second. Presumably this speed is limited by the speed of the
disk I/O.  On this platform a traditional encryption algorithm such as
Blowfish can encrypt at 10 Mbytes per second; the super-fast RKS encryption
is presumably faster than this.  Although this test does not give us any
real speed data, it does show that encryption speed is not the bottleneck
in most situations.  In this situation, the disk I/O is much slower than
the cryptography, making the encryption speed irrelevant.
3.5  Proprietary Encryption Algorithms
The nature of cryptography is such that there is no way to prove that a
cipher is secure, since this amounts to proving a negative assertion: that
there is no way to break it easily.  Anyone, from the most unsophisticated
amateur to the best cryptographer, can create an algorithm that he himself
can't break.  What is hard is creating an algorithm that no one else can
break, even after years of analysis.  And the only way to prove that is to
subject an algorithm to years of analysis by the best cryptographers around.
Because of this situation, the only recognized criterion for secure
cryptographic systems is peer review: having other cryptographers examine a
cipher and attack it. Even cryptographic organizations which operate in
secret, such as the NSA, have an extensive internal peer review system.
presented as "provably secure," "unbreakable," "a new fundamental technology," or "one-time pad" are usually not very good at all.  Those who say these things generally do not understand the current state-of-the-art of mathematical cryptography, and make fundamental mistakes in their system design.
Encryption algorithms that are unpublished have a dismal record. The
literature is littered with the corpses of encryption algorithms that were
broken once they were published. Until TriStrata publishes its algorithm
and it is open to peer review there is no professional reason to presume it
is secure.
4.0  The Real Problem in Security Systems
It is interesting to note that TriStrata gives a lot of attention to the
encryption algorithm.  From all the problems that security systems face at
the moment, the encryption algorithm is probably the least important one.
There are many good encryption algorithms available in the published
literature that can be used for free.  TriStrata chose to develop their own
algorithm.  Although this can be a lot of fun, it is a decision that is
hard to justify, as new algorithms can only be considered secure after an
ample time of peer review.
Cryptographic systems are broken constantly, but the attacks are almost
never against the algorithms.  The really difficult problems in security
systems are key distribution, management, reliability, robustness, etc.
TriStrata uses the solution of having a central server, as necessitated by
its choice of encryption technology.  This solution is suitable in some
situations, but there are many problems that cannot be handled by this
approach.  In fact, the problems associated with central servers and
centralized key distribution have been driving the development of
public-key--based systems for the last two decades.
TriStrata, by implementing a Maurer-style randomized stream cipher and the
centralized key management it requires, has taken the one piece of the
cryptographic puzzle that we can solve--symmetric encryption--and made what
they perceive to be security improvements.  However, they did this at the
expense of the really hard problems in cryptography...ones that their
system does not seem to adequately solve.
4.1  Trust and Security Systems
Whenever someone buys a commercial product, he is trusting that the
manufacturer did a good job designing and building the product.  This is
especially important with security products.  If someone buys a word
processor and it does not perform as advertised (e.g., the print function
does not work), he will eventually notice (he won't be able to print his
documents).  If someone buys an encryption product, it can function
normally (encrypting and decrypting documents successfully), but that is no
indication that it is secure.  Security is completely separate from
functionality, and no amount of beta testing can ever uncover a security flaw.
In the commercial world, we rely on the public review process to evalute
the security of systems.  Internet security infrastructures, such as IPSec,
PKIX, and SSL, have been discussed and debated for years.  Versions have
been proposed, security flaws have been found, fixes have been implemented,
and so on.  Cryptographic algorithms in these protocols are ones that have
been around for years, and have had extensive cryptographic review by the
best in the field.  Even this is no guarantee of security--implementation
flaws are found (and fixed) in the code that implements these protocols,
but it establishes a certain degree of confidence.
TriStrata has chosen to ignore all public standards in favor of their own
proprietary technology, while at the same time refusing to make technical
details of their technology public.  In order to use their system, the
purchaser must trust that their cryptographers are better than the
collective wisdom of the world's academic cryptographers, that their
protocol designers are better than everyone who has worked on the open
Internet protocols over the last few years, that their implementers are
better than everyone who has made and evaluated the public implementations
of those protocols.  The purchaser must trust that TriStrata's misuse of
the academic terminology does not reflect a misunderstanding of that
technology, and that their technology is so much better than what everyone
else has agreed upon that it makes sense to make that leap of faith.
In the end, a star-studded board of directors and upper management does not
obviate the need for good science, open systems, and peer review.  It's
simply foolish to trust a system that has not been evaluated.
5.0  Conclusions
A system like TriStrata's can be made to work within its limitations.  It
is certainly not the universal solution to the world's security problems.
However, there is a huge amount of hype and very little substance to the
documentation.  Many of the statements made are incomplete, vague, or
suggest facts which cannot be true.  The cryptographic claims are wild and
unsubstantiated.  Parts are clearly written by someone who does not
understand modern cryptography, and who is not well versed in the
cryptographic literature.  Certain areas of the documentation give the
impression that they were written with the intent to deceive the reader,
but ignorance is probably a better explanation.  Based on past experience
with systems that made similar unsupported security claims, we are very
skeptical about the security of the TriStrata system.   We reviewed the system as we have reconstructed it from various hints in
the text, as well as conversations with people who have been involved with
the system.  Until TriStrata releases technical information about its
product, it is not possible to give a complete evaluation of their technology.
References: [1]  TriStrata web site,  on Sept. 22nd, 1998.
[2]  Walter Hamscher, Alastair MacWillson, and Paul Turner, "Electronic
Business Without Fear: The TriStrata Security Architecture," Price Waterhouse.
[3]  "Building a Secure Future with CTR Business Systems and TriStrata
Security," leaflet.
[4]  Dan Backman, "TriStrata: A Giant Step In Enterprise Security,"
Network Computing Magazine, 15 September 1998.  Online,
[5]  Ueli M. Maurer, "A Provably-Secure Strongly-Randomized Cipher,"
Advances in Cryptology -- Eurocrypt '90 Proceedings, Springer-Verlag, 1990,
pp. 361--373. Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-10-05 11:38:07
@_author: Bruce Schneier 
@_subject: propose: `cypherpunks license' (Re: Wanted: Twofish source code) 
Clear and coherent summary, and accurate.  Thanks.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-21 05:28:19
@_author: Bruce Schneier 
@_subject: ArcotSign (was Re: Does security depend on hardware?) 
They're not looking to do tamperproof software.  Their business model can
be best described as: "better than passwords, cheaper than SecurID."
Here's the basic idea:  Strew a million passwords on your hard drive, and
make it impossible to verify which is the correct one offline.  So, someone
who steals the password file off the client cannot run a cracking tool
against the file.
It isn't bad.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-21 11:55:38
@_author: Bruce Schneier 
@_subject: ArcotSign (was Re: Does security depend on hardware?) 
It's not that much disk space.  The million entries was a methphor.  They use
mathematics instead of raw disk storage.
Of course.  It's less secure than hardware solutions.
Agreed.  Think of AOL as the ideal user for this idea.  They want something
a little more secure than passwords, but don't want to spend the money on
hardware.  Passwords can be guessed, or sniffed.  This system doesn't
allow passwords to be guessed, and there are some more additions to prevent sniffing (all pretty standard).  Sure, if the client machine is
compromised (installing a sniffer, etc), there is no security, but that's not
the real threat.
Sure.  But it's good enough for some things.
That's not the best way to operate in the real world.  I'd much rather have
friends, get married, and have a fun life than to trust no one.  I'd much
take the occassional hit rather than sit alone in the dark holding a gun.
is the real world of ninny net users in chat rooms, this isn't online real
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-21 16:30:36
@_author: Bruce Schneier 
@_subject: ArcotSign (was Re: Does security depend on hardware?) 
I am not an attorney, so I cannot advise on patentability.  But note that
I simplified the explanation A LOT in the above paragraph.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-22 04:47:56
@_author: Bruce Schneier 
@_subject: ArcotSign (was Re: Does security depend on hardware?) 
Hey, I don't ally myself with the clueless.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-22 04:47:56
@_author: Bruce Schneier 
@_subject: ArcotSign (was Re: Does security depend on hardware?) 
He uses a remembered secret and some mathematical magic.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-22 06:26:50
@_author: Bruce Schneier 
@_subject: ArcotSign (was Re: Does security depend on hardware?) 
One of the significant improvements is that the scheme is immune to
offline password guessing attacks.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-22 06:27:13
@_author: Bruce Schneier 
@_subject: ArcotSign (was Re: Does security depend on hardware?) 
Well, _I_ think they can explain everything (and we hope to do an academic
paper on the idea), but it's not my decision.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-22 07:21:19
@_author: Bruce Schneier 
@_subject: ArcotSign (was Re: Does security depend on hardware?) 
Yes, but only through an on-line protocol.   And if the server has some
kind of "turn the user off after ten bad password guesses," then the
atack doesn't work.
The advantages are that offline password guessing is impossible.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-22 07:42:36
@_author: Bruce Schneier 
@_subject: ArcotSign (was Re: Does security depend on hardware?) 
No.  The online protocol can be public.  Nothing has to be kept secret
in order for this to work.  That would be stupid; we all know that.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-22 07:48:11
@_author: Bruce Schneier 
@_subject: ArcotSign (was Re: Does security depend on hardware?) 
No.  You misunderstood me.  There is NOTHING secret except the key.
The online protocol, mathematical magic, source code, algorithm details,
and everything else can be made public.  There are no secrets in the
system except for the keys.
Yes, it's not obvious how you do this.  That's why Arcot is turning this
into a product--it's a good idea.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-22 07:50:27
@_author: Bruce Schneier 
@_subject: ArcotSign (was Re: Does security depend on hardware?) 
I hope you manage to persaude them then, because, as we all know, if it
I'm working on it.  I think I will be successful.  They know that they have to
make their sytem public if people are going to use it.  At this point, keeping
things under wraps give them a competitive edge.  There will be a point where
they have to make all the details public.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-22 12:01:33
@_author: Bruce Schneier 
@_subject: ArcotSign (was Re: Does security depend on hardware?) 
Yes.  There is something wrong with you logic.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-22 12:02:21
@_author: Bruce Schneier 
@_subject: ArcotSign (was Re: Does security depend on hardware?) 
Intractable, actually.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-22 16:43:28
@_author: Bruce Schneier 
@_subject: ArcotSign (was Re: Does security depend on hardware?) 
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-23 07:08:47
@_author: Bruce Schneier 
@_subject: ArcotSign (was Re: Does security depend on hardware?) 
Sorry.  I am under NDA.  Hopefully Arcot will explain sooner rather than
I suggest not using the product until you are satisfied.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-28 09:45:02
@_author: Bruce Schneier 
@_subject: Wanted: Twofish source code 
I am looking for Twofish ports in other assembly languages and other
high-level languages.  If anyone has, or is willing to write, source code
that they will put in the public domain, I would like to talk with them.
Bruce Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-28 15:22:50
@_author: Bruce Schneier 
@_subject: Twofish News: New Twofish Analaysis and the Cryptanalysis of Magenta 
There are two new papers on the Twofish website:
Both of these papers are on the Twofish website:
Also, the Twofish Pentium assembly code had a small bug in it; revised code
is available on the website.
We are interested in other implementations of Twofish.  If anyone has
ported the algorithm to Visual Basic, Perl, Motorola assembly, or any other
smart card processor, and is willing to make their code public, we'd be
happy to hear from them.
For other AES news, visit the NIST website at:
And for a free subscription to my free email monthly newsletter, CRYPTO-GRAM,
visit the subscription page at:
Bruce Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 1998-09-30 14:24:58
@_author: Bruce Schneier 
@_subject: Announcement: A Self-Study Course in Block Cipher Cryptanalysis 
Ever since writing Applied Cryptography, I have been asked to recommend a
book on cryptanalysis.  My unfortunate answer is that while there are
several good books on cryptography, there are no books, good or bad, on
The only way to learn cryptanalysis is through practice.  A student simply
has to break algorithm after algorithm, inventing new techniques and
modifying existing ones.  Reading others' cryptanalysis results helps, but
there is no substitute for experience.
To help in getting this experience, I designed a self-study course in
block-cipher cryptanalysis.  With it, a student can follow an ordered path
through the academic literature and emerge out the other side fully capable
of breaking new algorithms and publishing new cryptanalytic results.
What I have done is to list published algorithms and published
cryptanalyses in a coherent order: by type of cryptanalysis and difficulty.
 A student's task is to read papers describing algorithms, and then attempt
to reproduce published cryptanalytic results.  (It is definitely more
difficult to learn cryptanalysis from academic papers than from a distilled
textbook, but the sooner a student gets used to reading academic papers the
better off he will be.)  The results, in other published papers, serve as
an "answer key."
The paper is available in both postscript and pdf formats at:
Comments are always appreciated.
Bruce Schneier, President, Counterpane Systems     Phone: 612-823-1098
101 E Minnehaha Parkway, Minneapolis, MN  55419      Fax: 612-823-1590
           Free crypto newsletter.  See:

@_date: 2005-12-19 11:56:55
@_author: Bruce Schneier 
@_subject: [EPIC_IDOF] I Have An Essay on Salon 
Uncle Sam is listening
Bush may have bypassed federal wiretap law to deploy more high-tech
methods of surveillance.
By Bruce Schneier
Dec. 20, 2005 | When President Bush directed the National Security
Agency to secretly eavesdrop on American citizens, he transferred an
authority previously under the purview of the Justice Department to
the Defense Department and bypassed the very laws put in place to
protect Americans against widespread government eavesdropping. The
reason may have been to tap the NSA's capability for data-mining and
widespread surveillance.
Illegal wiretapping of Americans is nothing new. In the 1950s and
'60s, the NSA intercepted every single telegram coming in or going
out of the United States. It conducted eavesdropping without a
warrant on behalf of the CIA and other agencies. Much of this became
public during the 1975 Church Committee hearings and resulted in the
now famous Foreign Intelligence Surveillance Act (FISA) of 1978.
The purpose of this law was to protect the American people by
regulating government eavesdropping. Like many laws limiting the
power of government, it relies on checks and balances: one branch of
the government watching the other. The law established a secret
court, the Foreign Intelligence Surveillance Court (FISC), and
empowered it to approve national-security-related eavesdropping
warrants. The Justice Department can request FISA warrants to monitor
foreign communications as well as communications by American
citizens, provided that they meet certain minimal criteria.
The FISC issued about 500 FISA warrants per year from 1979 through
1995, and has slowly increased subsequently -- 1,758 were issued in
2004. The process is designed for speed and even has provisions where
the Justice Department can wiretap first and ask for permission
later. In all that time, only four warrant requests were ever
rejected: all in 2003. (We don't know any details, of course, as the
court proceedings are secret.)
FISA warrants are carried out by the FBI, but in the days immediately
after the terrorist attacks, there was a widespread perception in
Washington that the FBI wasn't up to dealing with these new threats

@_date: 2005-07-20 11:04:17
@_author: Bruce Schneier 
@_subject: [EPIC_IDOF] Police use cameras to track vehicles of suspects 
I've written about this in New Haven, CT:
     This new story is from Scotland.
Police use cameras to track vehicles of suspects
LUCY ADAMS, Home Affairs Correspondent    July 20 2005
POLICE have created a database of more than 6000 vehicles of suspects
which they can track on special cameras as they move around the country.
On major roads across Scotland, the cameras, which look similar to
the speed ones, record thousands of licence plates every hour and
scan them against the database.
Those on the list are flagged up with the local force control room
with details of the direction in which they are travelling. Depending
on the intelligence held on the motorist, the vehicle could be
stopped immediately by officers or monitored during its journey.
Senior police say there are a "substantial number" of cameras across
the country aimed at detecting drugs traffickers, sex offenders,
suspected terrorists and banned or unlicensed drivers. Owners on the
list are not told, and civil rights campaigners have raised concerns
about whether the scheme is compatible with human rights legislation.
However, officers say Automatic Number Plate Recognition (ANPR),
originally created for counter-terrorism, is a vital tool in
collecting intelligence on criminals and suspected terrorists.
Alan Burnett, spokesman on the system for the Association of Chief
Police Officers in Scotland, and assistant chief constable of Fife,
said: "It is directed against detecting travelling housebreakers,
potential terrorists, bogus callers and drug traffickers. This
technology is very much geared towards disrupting criminals such as
drug traffickers and it is not about prosecuting the motorist."
He said it was nothing to do with speeding or Big Brother, adding
that there were various lengths of time over which they could hold
the information: "A stolen vehicle may be on the list for two days,
but more serious intelligence may be kept on the list for up to 90
The Scottish Executive has spent ?1.5m on ANPR machines which can
check up to 3000 licence plates an hour on vehicles travelling at
speeds of up to 100mph. Forces are planning to connect this database
to the Scottish Intelligence Database (SID) to allow every officer to
be able to request that a vehicle of interest should be checked.
It is managed by the Scottish Criminal Records Office where a
sergeant is responsible for checking the information is held only for
a certain time and that it is compliant with human rights legislation.
John Scott, head of the Scottish Human Rights Centre, said he was
concerned about the lack of judicial scrutiny.
EPIC_IDOF mailing list
EPIC_IDOF at mailman.epic.org
You are subscribed as eugen at leitl.org
To manage your subscription, go to
 Archives at: Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-07-20 11:04:17
@_author: Bruce Schneier 
@_subject: [EPIC_IDOF] Police use cameras to track vehicles of suspects 
I've written about this in New Haven, CT:
    This new story is from Scotland.
Police use cameras to track vehicles of suspects
LUCY ADAMS, Home Affairs Correspondent    July 20 2005
POLICE have created a database of more than 6000 vehicles of suspects
which they can track on special cameras as they move around the country.
On major roads across Scotland, the cameras, which look similar to
the speed ones, record thousands of licence plates every hour and
scan them against the database.
Those on the list are flagged up with the local force control room
with details of the direction in which they are travelling. Depending
on the intelligence held on the motorist, the vehicle could be
stopped immediately by officers or monitored during its journey.
Senior police say there are a "substantial number" of cameras across
the country aimed at detecting drugs traffickers, sex offenders,
suspected terrorists and banned or unlicensed drivers. Owners on the
list are not told, and civil rights campaigners have raised concerns
about whether the scheme is compatible with human rights legislation.
However, officers say Automatic Number Plate Recognition (ANPR),
originally created for counter-terrorism, is a vital tool in
collecting intelligence on criminals and suspected terrorists.
Alan Burnett, spokesman on the system for the Association of Chief
Police Officers in Scotland, and assistant chief constable of Fife,
said: "It is directed against detecting travelling housebreakers,
potential terrorists, bogus callers and drug traffickers. This
technology is very much geared towards disrupting criminals such as
drug traffickers and it is not about prosecuting the motorist."
He said it was nothing to do with speeding or Big Brother, adding
that there were various lengths of time over which they could hold
the information: "A stolen vehicle may be on the list for two days,
but more serious intelligence may be kept on the list for up to 90
The Scottish Executive has spent ?1.5m on ANPR machines which can
check up to 3000 licence plates an hour on vehicles travelling at
speeds of up to 100mph. Forces are planning to connect this database
to the Scottish Intelligence Database (SID) to allow every officer to
be able to request that a vehicle of interest should be checked.
It is managed by the Scottish Criminal Records Office where a
sergeant is responsible for checking the information is held only for
a certain time and that it is compliant with human rights legislation.
John Scott, head of the Scottish Human Rights Centre, said he was
concerned about the lack of judicial scrutiny.
EPIC_IDOF mailing list
EPIC_IDOF at mailman.epic.org
You are subscribed as eugen at leitl.org
To manage your subscription, go to
 Archives at: Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-11-08 11:10:40
@_author: Bruce Schneier 
@_subject: [EPIC_IDOF] National Security Letters 
An Enemy of The State
By DOUG THOMPSON
Nov 7, 2005, 08:14
According to a printout from a computer controlled by the Federal
Bureau of
Investigation and the U.S. Department of Justice, I am an enemy of the
The printout, shown to me recently by a friend who works for Justice,
identifies me by a long, multi-digit number, lists my date of birth,
of birth, social security number and contains more than 100 pages
documenting what the Bureau and the Bush Administration consider to
be my
threats to the security of the United States of America.
It lists where I sent to school, the name and address of the first
wife that
I had been told was dead but who is alive and well and living in
background information on my current wife and details on my service
to my
country that I haven?t even revealed to my wife or my family.
Although the file finds no criminal activity by me or members of my
immediate family, it remains open because I am a ?person of interest?
has ?written and promoted opinions that are contrary to the
government of
the United States of America.?
And it will remain active because the government of the United
States, under
the far-reaching provisions of the USA Patriot Act, can compile and
such information on any American citizen. That act gives the FBI the
authority to collect intimate details about anyone, even those not
of any wrongdoing.
My file begins on September 11, 2001, the day of the terrorist
attacks on
New York and Washington. A Marine guard standing post at the Navy
Yard in
Washington jotted down the license number of my Jeep Wrangler after I
spotted taking pictures of armed guards at the locked-down military
That night, I found a card stuffed under my door from Agent John Ryan
of the
Naval Criminal Investigative Service. I chuckled at the time because the
lead character in Tom Clancy?s novels is named John P. Ryan.
I called Agent Ryan the next day. He wanted to know what the hell I was
doing taking photos of a military facility. I explained that I was a
journalist and taking pictures was what I did for a living. I
directed him
to a web site where he could find some of the photos I shot of the Navy
Yard?s side gate on that day. He asked for additional information,
date of birth and social security number, which I provided, and then
I thought the matter was dead until a few weeks ago when an old
friend from
Washington called, said he was in the area, and suggested lunch. At
he showed me the 100-plus pages of the file on me that grew out of that
first encounter with Agent Ryan of NCIS.
?Much of this information was gathered through what we call Rnational
security letters,?? he said. ?It allows us to gather information from a
variety of sources.?
A ?national security letter? it turns out, can be issued by any FBI
supervisor, without court order or judicial review, to compel libraries,
banks, employers and other sources to turn over any and all
information they
have on American citizens.
The FBI issues more than 30,000 national security letters a year.
When one
is delivered to a bank, library, employer or other entity, the same
law that authorizes such letters also prohibits your bank, employer or
anyone else from telling you that they received such a letter and were
forced to turn over all information on you.
According to my file, the banks where I have both business and checking
accounts have been forced to turn over all records of my
transactions, as
have every company where I have a charge account or credit card. They?ve
perused my book borrowing habits from libraries in Arlington and Floyd
Counties as well as studied what television shows I watch on the
Tivos in my
house. They know I belong to the National Rifle Association, the
Press Photographers Association and other professional groups. They
know I
attend meetings of Alcoholic Anonymous on a regular basis and the
file notes
that my ?pattern of spending? shows no purchase of ?alcohol-related
products? since the file was opened in 2001.
In the past, when information collected on an American citizen failed to
turn up any criminal activity, FBI policy called for such information
to be
But President George W. Bush in 2003 reversed that long-standing
policy and
ordered the bureau and other federal agencies to not only keep that
information but place it in government databases that can be accessed by
local, state and federal law enforcement agencies.
In October, Bush also signed Executive Order 13388 which expands
access to
those databases to ?appropriate private sector entities? although the
does not explain what those entities might be. In addition, the Bush
Administration has successfully blocked legislation and legal actions
have tried to stop the expansion of spying and gathering of
information on
FBI spokesmen defend the national security letters as a ?necessary
tool? on
the so-called ?war on terror.?
"Congress has given us this tool to obtain basic telephone data, basic
banking data, basic credit reports," Valarie E. Caproni, the FBI general
counsel, told The Washington Post. "The fact that a national security
is a routine tool used, that doesn't bother me."
Obviously it doesn?t. Carponi signed at least one of the letters used to
gather information for my file.
When I asked to keep the copy of the file, my friend said ?no.?  I
to keep it and the source confidential.
?You can?t,? he said. ?You can?t keep anything hidden. Your life is
an open
book with us and it will be to the day you die.?
After we left lunch and went our separate ways, I wondered how, if my
was under such scrutiny from Uncle Sam, he could meet me for lunch in a
public restaurant and not be discovered? So the next day I went to a
phone in an out-of-the-way location and dialed his direct number.
It was disconnected. So I called the central number and asked to
speak to
him. The woman who answered the phone wanted my name and phone number
so he
could return the call.  I hung up.
Then I drove home with one eye glued to the rearview mirror. Didn?t see
anything suspicious but if I turn up missing one day, just forward my
to General Delivery, Guantanamo Bay, Cuba.
? Copyright 2005 by Capitol Hill Blue
EPIC_IDOF mailing list
EPIC_IDOF at mailman.epic.org
You are subscribed as eugen at leitl.org
To manage your subscription, go to
 Archives at: Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-10-22 02:40:49
@_author: Bruce Schneier 
@_subject: [EPIC_IDOF] CALEA and Colleges 
New York Times
October 23, 2005
Colleges Protest Call to Upgrade Online Systems
By SAM DILLON
and STEPHEN LABATON
The federal government, vastly extending the reach of an 11-year-old
law, is requiring hundreds of universities, online communications
companies and cities to overhaul their Internet computer networks to
make it easier for law enforcement authorities to monitor e-mail and
other online communications.
The action, which the government says is intended to help catch
terrorists and other criminals, has unleashed protests and the threat
of lawsuits from universities, which argue that it will cost them at
least $7 billion while doing little to apprehend lawbreakers. Because
the government would have to win court orders before undertaking
surveillance, the universities are not raising civil liberties issues.
The order, issued by the Federal Communications Commission in August
and first published in the Federal Register last week, extends the
provisions of a 1994 wiretap law not only to universities, but also
to libraries, airports providing wireless service and commercial
Internet access providers.
It also applies to municipalities that provide Internet access to
residents, be they rural towns or cities like Philadelphia and San
Francisco, which have plans to build their own Net access networks.
So far, however, universities have been most vocal in their opposition.
The 1994 law, the Communications Assistance for Law Enforcement Act,
requires telephone carriers to engineer their switching systems at
their own cost so that federal agents can obtain easy surveillance
Recognizing the growth of Internet-based telephone and other
communications, the order requires that organizations like
universities providing Internet access also comply with the law by
spring 2007.
The Justice Department requested the order last year, saying that new
technologies like telephone service over the Internet were
endangering law enforcement's ability to conduct wiretaps "in their
fight against criminals, terrorists and spies."
Justice Department officials, who declined to comment for this
article, said in their written comments filed with the Federal
Communications Commission that the new requirements were necessary to
keep the 1994 law "viable in the face of the monumental shift of the
telecommunications industry" and to enable law enforcement to
"accomplish its mission in the face of rapidly advancing technology."
The F.C.C. says it is considering whether to exempt educational
institutions from some of the law's provisions, but it has not
granted an extension for compliance.
Lawyers for the American Council on Education, the nation's largest
association of universities and colleges, are preparing to appeal the
order before the United States Court of Appeals for the District of
Columbia Circuit, Terry W. Hartle, a senior vice president of the
council, said Friday.
The Center for Democracy and Technology, a nonprofit civil liberties
group, has enlisted plaintiffs for a separate legal challenge,
focusing on objections to government control over how organizations,
including hundreds of private technology companies, design Internet
systems, James X. Dempsey, the center's executive director, said Friday.
The universities do not question the government's right to use
wiretaps to monitor terrorism or criminal suspects on college
campuses, Mr. Hartle said, only the order's rapid timetable for
compliance and extraordinary cost.
Technology experts retained by the schools estimated that it could
cost universities at least $7 billion just to buy the Internet
switches and routers necessary for compliance. That figure does not
include installation or the costs of hiring and training staff to
oversee the sophisticated circuitry around the clock, as the law
requires, the experts said.
"This is the mother of all unfunded mandates," Mr. Hartle said.
Even the lowest estimates of compliance costs would, on average,
increase annual tuition at most American universities by some $450,
at a time when rising education costs are already a sore point with
parents and members of Congress, Mr. Hartle said.
At New York University, for instance, the order would require the
installation of thousands of new devices in more than 100 buildings
around Manhattan, be they small switches in a wiring closet or large
aggregation routers that pull data together from many sites and send
it over the Internet, said Doug Carlson, the university's executive
director of communications and computing services.
"Back of the envelope, this would cost us many millions of dollars,"
Mr. Carlson said.
F.C.C. officials declined to comment publicly, citing their
continuing review of possible exemptions to the order.
Some government officials said they did not view compliance as overly
costly for colleges because the order did not require surveillance of
networks that permit students and faculty to communicate only among
themselves, like intranet services. They also said the schools would
be required to make their networks accessible to law enforcement only
at the point where those networks connect to the outside world.
Educause, a nonprofit association of universities and other groups
that has hired lawyers to prepare its own legal challenge, informed
its members of the order in a Sept. 29 letter signed by Mark A.
Luker, an Educause vice president.
Mr. Luker advised universities to begin planning how to comply with
the order, which university officials described as an extraordinary
technological challenge.
Unlike telephone service, which sends a steady electronic voice
stream over a wire, the transmission of e-mail and other information
on the Internet sends out data packets that are disassembled on one
end of a conversation and reassembled on the other.
Universities provide hundreds of potential Internet access sites,
including lounges and other areas that offer wireless service and
Internet jacks in libraries, dorms, classrooms and laboratories,
often dispersed through scores of buildings.
If law enforcement officials obtain a court order to monitor the
Internet communications of someone at a university, the current
approach is to work quietly with campus officials to single out
specific sites and install the equipment needed to carry out the
surveillance. This low-tech approach has worked well in the past,
officials at several campuses said.
But the federal law would apply a high-tech approach, enabling law
enforcement to monitor communications at campuses from remote
locations at the turn of a switch.
It would require universities to re-engineer their networks so that
every Net access point would send all communications not directly
onto the Internet, but first to a network operations center where the
data packets could be stitched together into a single package for
delivery to law enforcement, university officials said.
Albert Gidari Jr., a Seattle lawyer at the firm Perkins Coie who is
representing Educause, said he and other representatives of
universities had been negotiating with lawyers and technology
officials from the Federal Bureau of Investigation, the Department of
Homeland Security and other agencies since the spring about issues
including what technical requirements universities would need to meet
to comply with the law.
"This is a fight over whether a Buick is good enough, or do you need
a Lexus?" Mr. Gidari said. "The F.B.I. is the lead agency, and they
are insisting on the Lexus."
Law enforcement has only infrequently requested to monitor Internet
communications anywhere, much less on university campuses or
libraries, according to the Center for Democracy and Technology. In
2003, only 12 of the 1,442 state and federal wiretap orders were
issued for computer communications, and the F.B.I. never argued that
it had difficulty executing any of those 12 wiretaps, the center said.
"We keep asking the F.B.I., What is the problem you're trying to
solve?" Mr. Dempsey said. "And they have never showed any problem
with any university or any for-profit Internet access provider. The
F.B.I. must demonstrate precisely why it wants to impose such an
enormously disruptive and expensive burden."
Larry D. Conrad, the chief information officer at Florida State
University, where more than 140 buildings are equipped for Internet
access, said there were easy ways to set up Internet wiretaps.
"But the wild-eyed fear I have," Mr. Conrad said, "is that the
government will rule that this all has to be automatic, anytime,
which would mean I'd have to re-architect our entire campus network."
He continued, "It seems like overkill to make all these institutions
spend this huge amount of money for a just-in-case kind of scenario."
The University of Illinois says it is worried about the order because
it is in the second year of a $20 million upgrade of its campus
network. Peter Siegel, the university's chief information officer,
estimated that the new rules would require the university to buy
2,100 new devices, at a cost of an additional $13 million, to replace
equipment that is brand new.
"It's like you buy a new car, and then the E.P.A. says you have to
buy a new car again," Mr. Siegel said. "You'd say, 'Gee, could I just
buy a new muffler?' "
EPIC_IDOF mailing list
EPIC_IDOF at mailman.epic.org
You are subscribed as eugen at leitl.org
To manage your subscription, go to
 Archives at: Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2006-04-15 01:14:09
@_author: Bruce Schneier 
@_subject: CRYPTO-GRAM, April 15, 2006 
CRYPTO-GRAM
               April 15, 2006
              by Bruce Schneier
               Founder and CTO
      Counterpane Internet Security, Inc.
           schneier at counterpane.com
                       A free monthly newsletter providing summaries, analyses, insights, and
commentaries on security: computer and otherwise.
For back issues, or to subscribe, visit
You can read this issue on the web at
.  These same essays
appear in the "Schneier on Security" blog:
.  An RSS feed is available.
** *** ***** ******* *********** *************
In this issue:
     Movie-Plot Threat Contest
     Airport Passenger Screening
     80 Cameras for 2,400 People
     Crypto-Gram Reprints
     VOIP Encryption
     Security through Begging
     DHS Privacy and Integrity Report
     News
     KittenAuth
     Terrorism Risks of Google Earth
     New Kind of Door Lock
     Counterpane News
     Evading Copyright Through XOR
     iJacking
     Security Screening for New York Helicopters
     Comments from Readers
** *** ***** ******* *********** *************
     Movie-Plot Threat Contest
NOTE: If you have a blog, please spread the word.
For a while now, I have been writing about our penchant for "movie-plot
threats": terrorist fears based on very specific attack
scenarios.  Terrorists with crop dusters, terrorists exploding baby
carriages in subways, terrorists filling school buses with explosives

@_date: 2006-03-09 03:09:05
@_author: Bruce Schneier 
@_subject: [EPIC_IDOF] My Essay on Data Mining 
Why Data Mining Won't Stop Terror
Commentary by Bruce Schneier
02:00 AM Mar, 09, 2006 EST
In the post-9/11 world, there's much focus on connecting the dots.
Many believe data mining is the crystal ball that will enable us to
uncover future terrorist plots. But even in the most wildly
optimistic projections, data mining isn't tenable for that purpose.
We're not trading privacy for security; we're giving up privacy and
getting no security in return.
Most people first learned about data mining in November 2002, when
news broke about a massive government data mining program called
Total Information Awareness. The basic idea was as audacious as it
was repellent: suck up as much data as possible about everyone, sift
through it with massive computers, and investigate patterns that
might indicate terrorist plots.
Americans across the political spectrum denounced the program, and in
September 2003, Congress eliminated its funding and closed its offices.
But TIA didn't die. According to The National Journal, it just
changed its name and moved inside the Defense Department.
This shouldn't be a surprise. In May 2004, the General Accounting
Office published a report (.pdf) listing 122 different federal
government data-mining programs that used people's personal
information. This list didn't include classified programs, like the
NSA's eavesdropping effort or state-run programs like MATRIX.
The promise of data mining is compelling, and convinces many. But
it's wrong. We're not going to find terrorist plots through systems
like this, and we're going to waste valuable resources chasing down
false alarms. To understand why, we have to look at the economics of
the system.
Security is always a trade-off, and for a system to be worthwhile,
the advantages have to be greater than the disadvantages. A national
security data-mining program is going to find some percentage of real
attacks and some percentage of false alarms. If the benefits of
finding and stopping those attacks outweigh the cost -- in money,
liberties, etc. -- then the system is a good one. If not, you'd be
better off spending that capital elsewhere.
Data mining works best when you're searching for a well-defined
profile, a reasonable number of attacks per year and a low cost of
false alarms. Credit-card fraud is one of data mining's success
stories: all credit-card companies mine their transaction databases
for data for spending patterns that indicate a stolen card.
Many credit-card thieves share a pattern -- purchase expensive luxury
goods, purchase things that can be easily fenced, etc. -- and data
mining systems can minimize the losses in many cases by shutting down
the card. In addition, the cost of false alarms is only a phone call
to the cardholder asking him to verify a couple of purchases. The
cardholders don't even resent these phone calls -- as long as they're
infrequent -- so the cost is just a few minutes of operator time.
Terrorist plots are different. There is no well-defined profile and
attacks are very rare. Taken together, these facts mean that data-
mining systems won't uncover any terrorist plots until they are very
accurate, and that even very accurate systems will be so flooded with
false alarms that they will be useless.
All data-mining systems fail in two different ways: false positives
and false negatives. A false positive is when the system identifies a
terrorist plot that really isn't one. A false negative is when the
system misses an actual terrorist plot. Depending on how you "tune"
your detection algorithms, you can err on one side or the other: you
can increase the number of false positives to ensure you are less
likely to miss an actual terrorist plot, or you can reduce the number
of false positives at the expense of missing terrorist plots.
To reduce both those numbers, you need a well-defined profile. And
that's a problem when it comes to terrorism. In hindsight, it was
really easy to connect the 9/11 dots and point to the warning signs,
but it's much harder before the fact. Certainly, many terrorist plots
share common warning signs, but each is unique, as well. The better
you can define what you're looking for, the better your results will
be. Data mining for terrorist plots will be sloppy, and it'll be hard
to find anything useful.
Data mining is like searching for a needle in a haystack. There are
900 million credit cards in circulation in the United States.
According to the FTC September 2003 Identity Theft Survey Report,
about 1 percent (10 million) cards are stolen and fraudulently used
each year.
When it comes to terrorism, however, trillions of connections exist
between people and events -- things that the data-mining system will
have to "look at" -- and very few plots. This rarity makes even
accurate identification systems useless.
Let's look at some numbers. We'll be optimistic -- we'll assume the
system has a one in 100 false-positive rate (99 percent accurate),
and a one in 1,000 false-negative rate (99.9 percent accurate).
Assume 1 trillion possible indicators to sift through: that's about
10 events -- e-mails, phone calls, purchases, web destinations,
whatever -- per person in the United States per day. Also assume that
10 of them are actually terrorists plotting.
This unrealistically accurate system will generate 1 billion false
alarms for every real terrorist plot it uncovers. Every day of every
year, the police will have to investigate 27 million potential plots
in order to find the one real terrorist plot per month. Raise that
false-positive accuracy to an absurd 99.9999 percent and you're still
chasing 2,750 false alarms per day -- but that will inevitably raise
your false negatives, and you're going to miss some of those 10 real
This isn't anything new. In statistics, it's called the "base rate
fallacy," and it applies in other domains as well. For example, even
highly accurate medical tests are useless as diagnostic tools if the
incidence of the disease is rare in the general population. Terrorist
attacks are also rare, any "test" is going to result in an endless
stream of false alarms.
This is exactly the sort of thing we saw with the NSA's eavesdropping
program: the New York Times reported that the computers spat out
thousands of tips per month. Every one of them turned out to be a
false alarm.
And the cost was enormous -- not just for the FBI agents running
around chasing dead-end leads instead of doing things that might
actually make us safer, but also the cost in civil liberties. The
fundamental freedoms that make our country the envy of the world are
valuable, and not something that we should throw away lightly.
Data mining can work. It helps Visa keep the costs of fraud down,
just as it helps Amazon alert me to books I might want to buy and
Google show me advertising I'm more likely to be interested in. But
these are all instances where the cost of false positives is low (a
phone call from a Visa operator or an uninteresting ad) in systems
that have value even if there is a high number of false negatives.
Finding terrorism plots is not a problem that lends itself to data
mining. It's a needle-in-a-haystack problem, and throwing more hay on
the pile doesn't make that problem any easier. We'd be far better off
putting people in charge of investigating potential plots and letting
them direct the computers, instead of putting the computers in charge
and letting them decide who should be investigated.
EPIC_IDOF mailing list
EPIC_IDOF at mailman.epic.org
You are subscribed as eugen at leitl.org
To manage your subscription, go to
 Archives at: Eugen* Leitl leitl ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2006-05-15 02:57:31
@_author: Bruce Schneier 
@_subject: CRYPTO-GRAM, May 15, 2006 
CRYPTO-GRAM
                May 15, 2006
              by Bruce Schneier
               Founder and CTO
      Counterpane Internet Security, Inc.
           schneier at counterpane.com
                       A free monthly newsletter providing summaries, analyses, insights, and
commentaries on security: computer and otherwise.
For back issues, or to subscribe, visit
You can read this issue on the web at
.  These same essays
appear in the "Schneier on Security" blog:
.  An RSS feed is available.
** *** ***** ******* *********** *************
In this issue:
     Movie Plot Threat Contest: Status Report
     Who Owns Your Computer?
     Crypto-Gram Reprints
     Identity-Theft Disclosure Laws
     When "Off" Doesn't Mean Off
     News
     RFID Cards and Man-in-the-Middle Attacks
     Software Failure Causes Airport Evacuation
     Counterpane News
     Microsoft's BitLocker
     The Security Risk of Special Cases
     Comments from Readers
** *** ***** ******* *********** *************
     Movie Plot Threat Contest: Status Report
On the first of last month, I announced my (possibly First) Movie-Plot
Threat Contest.
"Entrants are invited to submit the most unlikely, yet still plausible,
terrorist attack scenarios they can come up with.
"Your goal: cause terror. Make the American people notice. Inflict
lasting damage on the U.S. economy. Change the political landscape, or
the culture. The more grandiose the goal, the better.
"Assume an attacker profile on the order of 9/11: 20 to 30 unskilled
people, and about $500,000 with which to buy skills, equipment, etc."
As of the end of the month, the blog post has 782 comments.  I expected
a lot of submissions, but the response has blown me away.
Looking over the different terrorist plots, they seem to fall into
several broad categories.  The first category consists of attacks
against our infrastructure: the food supply, the water supply, the
power infrastructure, the telephone system, etc.  The idea is to
cripple the country by targeting one of the basic systems that make it
The second category consists of big-ticket plots.  Either they have
very public targets -- blowing up the Super Bowl, the Oscars, etc. --
or they have high-tech components: nuclear waste, anthrax, chlorine
gas, a full oil tanker, etc.  And they are often complex and hard to
pull off.  This is the 9/11 idea: a single huge event that affects the
entire nation.
The third category consists of low-tech attacks that go on and
on.  Several people imagined a version of the DC sniper scenario, but
with multiple teams.  The teams would slowly move around the country,
perhaps each team starting up after the previous one was captured or
killed.  Other people suggested a variant of this with small bombs in
random public locations around the country.
(There's a fourth category: actual movie plots.  Some entries are
comical, unrealistic, have science fiction premises, etc.  I'm not even
considering those.)
The better ideas tap directly into public fears.  In my book, Beyond
Fear, I discussed five different tendencies people have to exaggerate
risks: to believe that something is more risky than it actually is.
1. People exaggerate spectacular but rare risks and downplay common risks.
2. People have trouble estimating risks for anything not exactly like
their normal situation.
3. Personified risks are perceived to be greater than anonymous risks.
4. People underestimate risks they willingly take and overestimate
risks in situations they can't control.
5. People overestimate risks that are being talked about and remain an
object of public scrutiny.
The best plot ideas leverage one or more of those
tendencies.  Big-ticket attacks leverage the first.  Infrastructure and
low-tech attacks leverage the fourth.  And every attack tries to
leverage the fifth, especially those attacks that go on and on.  I'm
willing to bet that when I find a winner, it will be the plot that
leverages the greatest number of those tendencies to the best possible
I also got a bunch of e-mails from people with ideas they thought too
terrifying to post publicly.  Some of them wouldn't even tell them to
me.  I also received e-mails from people accusing me of helping the
terrorists by giving them ideas.
But if there's one thing this contest demonstrates, it's that good
terrorist ideas are a dime a dozen.  Anyone can figure out how to cause
terror.  The hard part is execution.
Some of the submitted plots require minimal skill and
equipment.  Twenty guys with cars and guns -- that sort of
thing.  Reading through them, you have to wonder why there have been no
terrorist attacks in the U.S. since 9/11.  I don't believe the
"flypaper theory" that the terrorists are all in Iraq instead of in the
U.S.  And despite all the ineffectual security we've put in place since
9/11, I'm sure we have had some successes in intelligence and
investigation -- and have made it harder for terrorists to operate both
in the U.S. and abroad.
But mostly, I think terrorist attacks are much harder than most of us
think.  It's harder to find willing recruits than we think.  It's
harder to coordinate plans.  It's harder to execute those
plans.  Terrorism is rare, and for all we've heard about 9/11 changing
the world, it's still rare.
The submission deadline was the end of April month, but please keep
posting plots if you think of them.  And please read through some of
the others and comment on them; I'm curious as to what other people
think are the most interesting, compelling, realistic, or effective
I'm reading through them, and will have a winner by the next Crypto-Gram.
Flypaper theory:
The contest made The New York Times:
n=c7ccc8d756fc98e7&ei=5090&partner=rssuserland&emc=rss or
** *** ***** ******* *********** *************
     Who Owns Your Computer?
When technology serves its owners, it is liberating. When it is
designed to serve others, over the owner's objection, it is oppressive.
There's a battle raging on your computer right now -- one that pits you
against worms and viruses, Trojans, spyware, automatic update features
and digital rights management technologies. It's the battle to
determine who owns your computer.
You own your computer, of course. You bought it. You paid for it. But
how much control do you really have over what happens on your machine?
Technically you might have bought the hardware and software, but you
have less control over what it's doing behind the scenes.
Using the hacker sense of the term, your computer is "owned" by other
It used to be that only malicious hackers were trying to own your
computers. Whether through worms, viruses, Trojans or other means, they
would try to install some kind of remote-control program onto your
system. Then they'd use your computers to sniff passwords, make
fraudulent bank transactions, send spam, initiate phishing attacks and
so on. Estimates are that somewhere between hundreds of thousands and
millions of computers are members of remotely controlled "bot"
networks. Owned.
Now, things are not so simple. There are all sorts of interests vying
for control of your computer. There are media companies that want to
control what you can do with the music and videos they sell you. There
are companies that use software as a conduit to collect marketing
information, deliver advertising or do whatever it is their real owners
require. And there are software companies that are trying to make money
by pleasing not only their customers, but other companies they ally
themselves with. All these companies want to own your computer.
Some examples:
1. Entertainment software: In October 2005, it emerged that Sony had
distributed a rootkit with several music CDs -- the same kind of
software that crackers use to own people's computers. This rootkit
secretly installed itself when the music CD was played on a computer.
Its purpose was to prevent people from doing things with the music that
Sony didn't approve of: It was a DRM system. If the exact same piece of
software had been installed secretly by a hacker, this would have been
an illegal act. But Sony believed that it had legitimate reasons for
wanting to own its customers' machines.
2. Antivirus: You might have expected your antivirus software to detect
Sony's rootkit. After all, that's why you bought it. But initially, the
security programs sold by Symantec and others did not detect it,
because Sony had asked them not to. You might have thought that the
software you bought was working for you, but you would have been wrong.
3. Internet services: Hotmail allows you to blacklist certain e-mail
addresses, so that mail from them automatically goes into your spam
trap. Have you ever tried blocking all that incessant marketing e-mail
from Microsoft? You can't.
4. Application software: Internet Explorer users might have expected
the program to incorporate easy-to-use cookie handling and pop-up
blockers. After all, other browsers do, and users have found them
useful in defending against Internet annoyances. But Microsoft isn't
just selling software to you; it sells Internet advertising as well. It
isn't in the company's best interest to offer users features that would
adversely affect its business partners.
5. Spyware: Spyware is nothing but someone else trying to own your
computer. These programs eavesdrop on your behavior and report back to
their real owners -- sometimes without your knowledge or consent --
about your behavior.
6. Update: Automatic update features are another way software companies
try to own your computer. While they can be useful for improving
security, they also require you to trust your software vendor not to
disable your computer for nonpayment, breach of contract or other
presumed infractions.
Adware, software-as-a-service and Google Desktop search are all
examples of some other company trying to own your computer. And Trusted
Computing will only make the problem worse.
There is an inherent insecurity to technologies that try to own
people's computers: They allow individuals other than the computers'
legitimate owners to enforce policy on those machines. These systems
invite attackers to assume the role of the third party and turn a
user's device against him.
Remember the Sony story: The most insecure feature in that DRM system
was a cloaking mechanism that gave the rootkit control over whether you
could see it executing or spot its files on your hard disk. By taking
ownership away from you, it reduced your security.
If left to grow, these external control systems will fundamentally
change your relationship with your computer. They will make your
computer much less useful by letting corporations limit what you can do
with it. They will make your computer much less reliable because you
will no longer have control of what is running on your machine, what it
does, and how the various software components interact. At the extreme,
they will transform your computer into a glorified boob tube.
You can fight back against this trend by only using software that
respects your boundaries. Boycott companies that don't honestly serve
their customers, that don't disclose their alliances, that treat users
like marketing assets. Use open-source software -- software created and
owned by users, with no hidden agendas, no secret alliances and no
back-room marketing deals.
Just because computers were a liberating force in the past doesn't mean
they will be in the future. There is enormous political and economic
power behind the idea that you shouldn't truly own your computer or
your software, despite having paid for it.
This essay originally appeared on Wired.com.
Trusted computing:
** *** ***** ******* *********** *************
     Crypto-Gram Reprints
Crypto-Gram is currently in its ninth year of publication.  Back issues
cover a variety of security-related topics, and can all be found on
.  These are a selection
of articles that appeared in this calendar month in other years.
Should Terrorism be Reported in the News?
Combating Spam
Warrants as a Security Countermeasure
National Security Consumers
Encryption and Wiretapping
Unique E-Mail Addresses and Spam
Secrecy, Security, and Obscurity
Fun with Fingerprint Readers
What Military History Can Teach Network Security, Part 2
The Futility of Digital Copy Protection
Security Standards
Safe Personal Computing
Computer Security: Will we Ever Learn?
Trusted Client Software
The IL*VEYOU Virus (Title bowdlerized to foil automatic e-mail filters.)
The Internationalization of Cryptography
The British discovery of public-key cryptography
** *** ***** ******* *********** *************
     Identity-Theft Disclosure Laws
California was the first state to pass a law requiring companies that
keep personal data to disclose when that data is lost or stolen. Since
then, many states have followed suit. Now Congress is debating federal
legislation that would do the same thing nationwide.
Except that it won't do the same thing: The federal bill has become so
watered down that it won't be very effective. I would still be in favor
of it -- a poor federal law is better than none -- if it didn't also
pre-empt more-effective state laws, which makes it a net loss.
Identity theft is the fastest-growing area of crime. It's badly named
