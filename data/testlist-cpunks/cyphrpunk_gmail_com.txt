
@_date: 2005-04-01 11:26:46
@_author: cypherpunk 
@_subject: [silk] Google Targeted ads - gmail (fwd from 
References: <20050401130620.GJ24702 	
  <20050401181746.50026.qmail 	
  <20050401185731.GT24702
Let's get this straight. It's not evil if people are voluntarily
agreeing to it! Maybe you're being facetious but you undermine the
significance of true evil by applying the word to voluntary
relationships. Cypherpunks should support noncoercive information
relationships because they give users the option to protect their own
privacy. Nobody is forced to use Google, and technology exists to
allow it to be used in a privacy protecting way.
True evil would be a system which takes away your options and forces
you to interact in a way that prevents you from protecting yourself.
Google is 180 degrees removed from such an approach.

@_date: 2005-04-04 11:49:17
@_author: cypherpunk 
@_subject: Cryptanalysis of ePassports 
An article is up on the eprint archive,
 "Security and Privacy Issues in
E-passports" by Ari Juels and David Molnar and David Wagner. It
analyzes the new contactless chips which will be in U.S. passports in
a few months.
Among the risks it identifies are that terrorists could eavesdrop on
chip transactions and recover digital photographs of what people look
like - when they are not smiling. The mind boggles at what a creative
terrorist could do with such sensitive information.

@_date: 2005-04-11 10:23:46
@_author: cypherpunk 
@_subject: Rebalanced-RSA-CRT 
References: <20050406010757.GZ701 	
  <20050407171331.13786.qmail
It has to be the second one. If it were only 3 times faster than
vanilla RSA, while RSA-CRT was 4 times faster than vanilla, then
rebalanced would not be a speedup over the usual way of doing things. Rebalanced RSA is 3 times faster than RSA-CRT.
What "rebalanced RSA" means is that you choose the private exponent d
so that exponentiation with it is fast. This speeds up decryption at
the expense of encryption. You can't just choose a small d; this is
known to be insecure. Instead they propose to choose a d such that the
two exponents in the CRT, d mod p-1 and d mod q-1, are relatively
small, about 160 bits. This gives a factor of 3 speedup vs the usual
512 bit exponent in 1024 bit RSA-CRT.
Is this safe? Who knows? I wouldn't recommend using it until Don
Coppersmith chewed on it for a while. He's the guy who pushes the
state of the art on small-d attacks. I'd wait for his opinion on
whether this variant on small-d escapes his attacks.

@_date: 2005-04-13 22:56:53
@_author: cypherpunk 
@_subject: CFP: What the Hack '05 and Blind Signature Expiration Party 
References: <20050408111253.DACA117093
That's very exciting. Perhaps we could aim for the release of some new
software packages that use the blind signature patent technology. Are
there any applications which have been waiting for this patent to

@_date: 2005-04-15 13:24:25
@_author: cypherpunk 
@_subject: Modifed IRS 1040 form 
References: AKA, a get INTO jail free card.  Thanks a bunch.

@_date: 2005-04-27 11:14:50
@_author: cypherpunk 
@_subject: Email Certification? 
References: By whom? Someone at hotmail, or someone who got your password and
logged in as you?
Hotmail shows mail that has already been viewed in a different color
than mail you haven't looked at yet. So it would be obvious if someone
else logged in as you and read your email. But of course there is no
way to know what insiders are doing. Maybe you could explain your
attack concept more clearly.
What would this accomplish? That is, what attack would it make more
difficult? Are you worried that someone is intercepting your email en
route to hotmail, reading and delaying it, then passing it on? And you
hope to detect the unwarranted delay?

@_date: 2005-04-28 15:37:19
@_author: cypherpunk 
@_subject: [Politech] Thumbprinting visitors at the Statue of Liberty 
References: <20050428220450.GQ25963
If this were really as much of a conspiracy as people are making it
out to be, wouldn't it make sense to ask for THUMB prints? that's what
the subject line says, and that's what the titles of the two jpeg
files are. But if you look at the pictures, they plainly ask for the
right index finger. Thumbprints are widely used, drivers' licenses and
banks often require them. If they wanted to be able to track average
users, they would ask for thumb prints. But they're not.
The really funny thing is how people see what they expect to see.
Isn't it strange to have these documents titled Thumbsx.jpg, when they
ask for index finger prints? People are so ruled by their
preconceptions that they actually blind themselves to what is directly
in front of them. I hope no one on this list is so foolish as to put
ideology ahead of reality.

@_date: 2005-04-28 15:44:15
@_author: cypherpunk 
@_subject: EncFS 
References:  	
  <20050427204405.GH720 	
  <20050428154233.GE69135
A remailer posted about EncFS. Gerow quoted the first paragraph and
added the criticism that it doesn't do locking. Dixon saw the quoted
first paragraph, which said that the link to the program was "below".
And indeed, it was below, in the first message from the remailer. It
included this link,  But Dixon
apparently didn't understand the notion of quoting partial messages in
a mailing list conversation. He just saw the part about the link being
"below", and in Gerow's message there was no such link. So he
complained: there was nothing "below". But Gerow misunderstood, he
though Dixon was commenting about EncFS's locking mechanisms. So Gerow
responded as below, adding to the confusion.
Honestly, I don't know how you people generate enough brain power to
keep yourselves alive.

@_date: 2005-04-28 15:55:02
@_author: cypherpunk 
@_subject: [IP] more on Privacy tip: be wary of Google's "personal 
References: <20050428144123.GN25963
The question is, with regard to Google, does turning "personal
history" on or off make a difference in what records they keep about
your searches? Obviously if it's on they do keep records, but if you
disable it or never turn it on, does that mean that they don't keep
 says:
"You can delete information from My Search History, and it will be
removed from the service and no longer available to you. However, as
is common practice in the industry, and as outlined in the Google
Privacy Policy, Google maintains a separate logs system for auditing
purposes and to help us improve the quality of our services for
 says:
"Google collects limited non-personally identifying information your
browser makes available whenever you visit a website. This log
information includes your Internet Protocol address, browser type,
browser language, the date and time of your query and one or more
cookies that may uniquely identify your browser. We use this
information to operate, develop and improve our services."
The bottom line seems to be that even with MSH turned off, Google will
still record your IP address and cookie, presumably along with the
search query you made. You can block Google cookies to help with this,
and if you use a shared IP address then this will give you some
privacy protection.
Chances are that other search engines do the same thing. For real
privacy, do as I do: use TOR or some other anonymizer, and either
block cookies or use a separate browser altogether for anonymous

@_date: 2005-04-28 15:55:02
@_author: cypherpunk 
@_subject: [IP] more on Privacy tip: be wary of Google's "personal history" 
feature [priv] (fwd from dave at farber.net)
Reply-To: cypherpunk The question is, with regard to Google, does turning "personal
history" on or off make a difference in what records they keep about
your searches? Obviously if it's on they do keep records, but if you
disable it or never turn it on, does that mean that they don't keep
 says:
"You can delete information from My Search History, and it will be
removed from the service and no longer available to you. However, as
is common practice in the industry, and as outlined in the Google
Privacy Policy, Google maintains a separate logs system for auditing
purposes and to help us improve the quality of our services for
 says:
"Google collects limited non-personally identifying information your
browser makes available whenever you visit a website. This log
information includes your Internet Protocol address, browser type,
browser language, the date and time of your query and one or more
cookies that may uniquely identify your browser. We use this
information to operate, develop and improve our services."
The bottom line seems to be that even with MSH turned off, Google will
still record your IP address and cookie, presumably along with the
search query you made. You can block Google cookies to help with this,
and if you use a shared IP address then this will give you some
privacy protection.
Chances are that other search engines do the same thing. For real
privacy, do as I do: use TOR or some other anonymizer, and either
block cookies or use a separate browser altogether for anonymous
Eugen* Leitl leitl
ICBM: 48.07078, 11.61144            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
         [demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-07-11 16:06:13
@_author: cypherpunk 
@_subject: Attack on Brands blind signature 
eprint.iacr.org/2005/186 is an attack by Xuesheng Zhong on several
blind signature schemes, including one widely discussed on the
Cypherpunks mailing list back in the 1990s by Stefan Brands. The paper
seems to show that it is possible for the bank/mint to recognize blind
signatures (i.e. untraceable electronic cash tokens) when they are
re-submitted for deposit, which is exactly what the blind signature is
supposed to prevent. The math looks right although I haven't tried to
look back at Brands' old work to see if it is correctly described in
the new paper.

@_date: 2005-07-13 00:15:21
@_author: cypherpunk 
@_subject: Reverse Palladium? 
References: Although you asked about "Reverse Palladium" what you really want is
Palladium itself. This is precisely the security model which has so
many people upset: the system owner (the network admin) is giving up
control over his machine, running software which he cannot control,
molest or modify. You, a third party, are protected against the
computer's owner. The ability for owners to voluntarily and verifiably
give up a degree of control over their computers is anathema to
Trusted Computing opponents, the height of evil and a threat to be
fought at all costs. The fact that it is voluntary for all concerned
means nothing to them. They don't want people even to have the chance
to be tempted to utilize this technology, and they will stop at
nothing to keep it from coming into existence. So far they have been
extremely successful.
See for discussion about how to use Palladium to add security to Internet
voting applications, even for cases where people are voting on
machines owned by others. This is very similar to the threat model in
your situation.

@_date: 2005-05-04 10:31:20
@_author: cypherpunk 
@_subject: Pi: Less Random Than We Thought 
References: <20050501223917.GQ28569
This doesn't really make sense. Either the digits are random or they
are not. You can't be a little bit random. Well, you can be, but the
point is that you either pass the test or you don't.
If pi's digits fail a test of randomness in a statistically
significant way, that is big news. If they pass it, then there is no
meaningful way to compare them with another RNG that also passes. It's
just a statistical quirk due to random variation as to which will do
better than another on any given test.
The bottom line is still that either an RNG passes the tests
acceptably or it does not. From what they say (or don't say), pi does
pass. It doesn't make sense to say that other RNGs do better.

@_date: 2005-05-09 12:13:18
@_author: cypherpunk 
@_subject: [Politech] Passport RFID tracking: a between-the-lines read 
References: <20050504085745.GK6782
A Politech article forwarded email from a liar named :
is the actual EE times article. The true article reads, as you can see
for yourself:
"PARIS  Global electronic passports suppliers hailed a decision by
the U.S. State Department to add a requirement for additional security
measures in next-generation U.S. passports. The specifications have
yet to be finalized."
Can you see the difference? What's wrong with this picture?
The true article says that the U.S. will ADD a requirement for
additional security measures. The article as quoted by liar Parks had
been changed to say that the U.S. will DROP the requirement. Of course
that made the article read as confused and inconsistent, which is what
led me to track down the original.
I'm pissed at Parks for lying and editing a supposedly forwarded
article to make some kind of rhetorical point. He had his own comments
interspersed among the article's supposed text so he had plenty of
opportunity to make his own arguments. Altering the text of material
you are quoting is the lowest of despicable argumentation techniques.
I'm also pissed at McCullagh for forwarding this on without the
slightest fact checking. Of course anyone familiar with his work will
know better than to expect a correction or even acknowledgement of his
error. He is a hack reporter who cares nothing about accuracy or
truth, only on stirring things up and pushing the predictable buttons
of his readers.
And of course there is Eugen* Leitl, who mindlessly forwards far and
wide everything that enters his mailbox. I don't know whether we
should be annoyed or relieved that he fails to exercise the slightest
editorial effort by adding his own thoughts, if he has any, to the
material he passes around.

@_date: 2005-05-09 12:22:22
@_author: cypherpunk 
@_subject: [IP] Real ID = National ID (fwd from dave@farber.net) 
References: <20050504172158.GA6782
We already have de facto national ID in the form of our state driver's
licenses. They are accepted at face value at all 50 states as well as
by the federal government. Real ID would rationalize the issuing
procedures and require a certain minimum of verification. Without it
we have security that is only as strong as the weakest state's

@_date: 2005-05-09 12:35:25
@_author: cypherpunk 
@_subject: Zero knowledge( a>b ) 
References: <427EADEB.5BC2E95 	
  <20050509130058.41661.qmail
You've got two different things mixed up here.  A zero knowledge proof
is normally used by one person to show that he knows a value
satisfying certain conditions, without revealing what the value is.
What you are asking for involves two people who want to compute a
function of their inputs, without revealing those inputs. That is
known as a multi party computation or MPC. As was pointed out,
Schneier has some good pointers on MPC calculations.
There is a program you can download called Fairplay which will perform
MPC calculations like this. One of them does exactly what you are
asking for. See

@_date: 2005-05-17 14:45:28
@_author: cypherpunk 
@_subject: Len Adleman (of R,S, and A): Universities need a little 
References: Any speculations on which half?  My guess is that he agrees on
affirmative action and gun control (opposing both) and probably the
Iraq war (a conservative is a liberal who's been mugged, and many
people took 9/11 personally).  He certainly disagrees on prayer in
school, probably on capital punishment (opposing both, while Limbaugh
supports them), and probably supports abortion rights, which Limbaugh

@_date: 2005-05-17 15:03:52
@_author: cypherpunk 
@_subject: /. [Dissidents Seeking Anonymous Web Solutions?] 
References: <20050515175945.GQ23917
There were some good ideas presented, the best of which were probably
to first compose an email at home, then PGP encrypt it, then stego-ize
it, then put it on a USB token and bring it to the internet cafe, and
send it there.  For receiving, download a bunch of junk from a mailing
list used for this purpose onto the token, go home and de-stego and
de-PGP it.
This doesn't work though for web browsing. For that you need a real
time channel. You can go to various proxies, and some people run them
specifically to help the Chinese, the slashdot replies talked about
this. But first, the Chinese block them when they find out, and
second, it makes you look suspicious if you're visiting one.
Be nice if there were a high bandwidth stego channel that was widely
available. For example, imagine an open source P2P multi player game
which intentionally included a reasonably high bandwidth channel of
random data. It would be a service to the public to play this game and
thereby provide people who need it the ability to communicate
undetectably. Dissidents could use a hacked version which would
replace some of the random noise bits with their messages. Only the
recipients could distinguish the results from noise.

@_date: 2005-11-03 14:54:59
@_author: cyphrpunk 
@_subject: [smb@cs.columbia.edu: Skype security evaluation] 
References: <9D78CC84C35AEF43A69CA95639D376DABB19B1
Thanks for this pointer. In the case of Skype it would be consistent
with the security report if they are encrypting random 128 bit values
under each other's RSA keys, unpadded, and exchanging them, then
hashing the pair of 128 bit values together to generate their session
The paper above shows an easy birthday attack on such encryptions.
Approximately 18% of 128 bit numbers can be expressed as a product of
two 64-bit numbers. For such keys, if the ciphertext is C, consider
all 2^64 values m1 and m2, and compare m1^e with C/m2^e. This can be
done in about 2^64 time and memory, and if the plaintext is in that
18%, it will be found as m1*m2.
Based on these comments and others that have been made in this thread,
the Skype security analysis seems to have major flaws. We have a
reluctance in our community to criticize the work of our older
members, especially those like Berson who have warm personalities and
friendly smiles. But in this case the report leaves so much
unanswered, and focuses inappropriately on trivial details like
performance and test vectors, that overall it can only be called an
entirely unsatisfactory piece of work.

@_date: 2005-11-07 11:51:32
@_author: cyphrpunk 
@_subject: [smb@cs.columbia.edu: Skype security evaluation] 
References: <792ce4370511031454j67372483h4a6d54e23da6c8f2
  	 <20051104194507.35627.qmail
It's not too much to ask that Skype provide real security. It's no
harder to do that than to offer fake security.
And more to the point, this so-called security review should have been
able to pinpoint these security weaknesses rather than running test
vectors against its algorithms. (Granted, the review did in fact
identify several weaknesses, but it appears to have glossed over

@_date: 2005-11-07 12:12:30
@_author: cyphrpunk 
@_subject: On the orthogonality of anonymity to current market demand 
References: <26873835.1130307198603.JavaMail.root
  	 <435F49A1.14621.A33B337 	
I suggest that you're fooling yourself, or at least giving yourself a
false sense of security. Software today is so complex and large that
there is no way that you can be familiar with the vast bulk of what
you are running (and it's only going to get worse in the future). It
is an illusion that you have transparency into it. Water is
transparent but an ocean of it is opaque and holds many secrets.

@_date: 2005-11-07 12:47:15
@_author: cyphrpunk 
@_subject: On Digital Cash-like Payment Systems 
References: <19275506.1130592050616.JavaMail.root
Your point would be to make the encryption key very large?
Unfortunately, making it large enough to present any kind of challenge
to an attacker who is plucking files off a trojaned computer would
make it far too large to be used, with this system.
This doesn't make sense. The discrete log operation is the inverse of
exponentiation. Doing exponentiation is a prerequisite for even
considering discrete log operations. Hence it cannot make them "more
That's a new word to me. What is your goal here, to make something
that is "even stronger" than RSA? Or is it, as in the context of this
thread, to inflate keys, making them bigger so that an attacker can't
download them easily?
That's not feasible in most cases. If you really have a OTP handy, why
are you bothering with RSA? Or are you planning to use it as a
two-time-pad? That generally doesn't work well. (The fact that you are
worried about "giving away" OTP material is not a good sign!)
So where do you store this 256 bit seed? You want to distract the
attacker with the smoke and mirrors of the big file for him to
download, hoping he will ignore this little file which is all he
really needs? I think we are assuming the attacker is smarter than
this, otherwise you could just use regular key files but give them
obscure names.
What is forgery resistance in this context? A public key encryption
system, by definition, allows anyone to create new encrypted messages.
Your technique is complicated but it is not clear how much security it
adds. Fundamentally it is not too different from RSA + counter mode,
where CTR can be thought of as a PRNG expanding a seed. This doesn't
seem to have anything to do with the thread topic. Are you just
tossing off random ideas because you don't think ordinary hybrid RSA
encryption is good enough?
I'm not sure conventional covert-channel analysis is going to be that
useful here, because the bandwidths we are looking at in this attack
model are so much greater (kilobytes to megabytes per second). But
broadly speaking, yes, this was Daniel Nagy's idea which started this
thread, that making the key files big enough would make it more likely
to catch someone stealing them because it would take so long.

@_date: 2005-11-07 13:19:31
@_author: cyphrpunk 
@_subject: [dave@farber.net: [IP] govt surveillance - it's not just 
References: <20051107202302.GT2249
These kinds of claims always strike me as bullshit. Remember the one
the other day about how they wanted his elementary school records and
all that crap? There's always something weird in there. Like this:
What the hell? He had been told that his first wife was dead but now
finds out that she's alive and well and living in Montana? What kind
of a life does someone lead, to have stuff like this happen to them?
It's not credible to me, it's something out of a Hunter Thompson
And what a coincidence, national security letters are in the news
today, the ACLU and others are putting out all kinds of press
releases. Funny timing, huh?
They watch his Tivo recordings? They know he's not buying beer? It's
just a fabrication, red meat for conspiracy nuts, throwing together
every wet dream they ever had into one massive, steaming pile.
And people around here just eat it up!  Yum, yum.

@_date: 2005-11-10 11:45:45
@_author: cyphrpunk 
@_subject: Hacker strikes through student's router 
What if we had a Tor network where exit node operators made Tor-money,
and Tor-money was necessary to use the network? Or perhaps, Tor-money
at least gave you priority in using the network, so all those P2P
traders wouldn't slow you down so much? Maybe exit node operators
could even sell their Tor-money for real cash, to potential Tor users.
People tend to have two contradictory views about proposals like this.
One is that such a Tor network would never work, because people would
prefer to use the free one. The other is that free Tor networks will
never work, because no one will take the heat to run an exit node.
The point is that this proposal cuts the knot and creates a
self-sustaining Tor-style network, one which rewards people who take
the risk of running exit nodes, just as in Anthony's example about
WiFi hotspots.
One technical problem is verifying that a particular exit node is
legit, so that its operator can get his Tor-bucks. It might be enough
to put Tor-money in the packet so that the last node receives it, but
then he could skim the cash without performing the service of letting
the packets go out. Still, this would be easily detected and users
could blacklist exit nodes which didn't perform, so it might be
Obviously an ecash-integrated Tor network is an ambitious project, but
it is something to think about if Tor starts running into problems
with people not wanting to run exit nodes.
Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-11-12 19:18:09
@_author: cyphrpunk 
@_subject: [Clips] Feds mull regulation of quantum computers 
References: Suppose that quantum computers work and the NSA has them. What steps
can or should they take to try to stop the propagation of this
technology? If they come out too openly with restrictions, it sends a
signal that there's something there, which could drive more research
into the technology by the NSA's adversaries, the opposite of the
desired outcome. If they leave things alone then progress may continue
towards this technology that the NSA wants to suppress.
Something like the present action isn't a bad compromise. Work towards
restrictions on technology exports, but in a studiously casual
fashion. There's nothing to see here, folks. We're just covering our
bases, in the outside chance that something comes out of this way down
the road. Meanwhile we'll just go ahead and stop exports of related
technologies. But we certainly don't think that quantum computers are
practical today, heavens no!

@_date: 2005-11-28 00:14:07
@_author: cyphrpunk 
@_subject: [fc-discuss] Financial Cryptography Update: On Digital 
References:  	
  <792ce4370510281418l74b01072kb43ea37584fd50f1 	
  <20051028234456.GA12429 	
  <792ce4370510292117kd379aden794034252ce45fe 	
  <20051124005424.GA8893
These are good ideas to reduce the impact of a stolen key, and
possibly to detect if one has been stolen.
As a potential user of such a system, if anonymity were important to
me I would refuse to honor a request to reveal this linkage
information. I would accept that the coin was lost and pay with a
different one. Depending on the frequency of such spot checks, this
would constitute an effective transaction cost for the use of the
One example is the Sander and Ta-Shma paper I mentioned earlier:
It will be interesting to see more details of how this works. Sander
and Ta-Shma also had the server publish information for every issued
coin, and then used zero knowledge techniques for the depositor to
show that the coin was on the list. This added great complexity to the

@_date: 2005-10-01 15:27:32
@_author: cyphrpunk 
@_subject: nym-0.2 released (fwd) 
All these degrees of indirection look good on paper but are
problematic in practice. Each link in this chain has to trust all the
others. Whether the token server issues tokens freely, or the CA
issues certificates freely, or the gateway proxy creates client
identifiers freely, any of these can destroy the security properties
of the system. Hence it makes sense for all of them to be run by a
single entity. There can of course be multiple independent such
pseudonym services, each with its own policies.
In particular it is not clear that the use of a CA and a client
certificate buys you anything. Why not skip that step and allow the
gateway proxy simply to use tokens as user identifiers? Misbehaving
users get their tokens blacklisted.
There are two problems with providing client identifiers to Wikipedia.
The first is as discussed elsewhere, that making persistent pseudonyms
such as client identifiers (rather than pure certifications of
complaint-freeness) available to end services like Wikipedia hurts
privacy and is vulnerable to future exposure due to the lack of
forward secrecy. The second is that the necessary changes to the
Wikipedia software are probably more extensive than they might sound.
Wikipedia tags each ("anonymous") edit with the IP address from which
it came. This information is displayed on the history page and is used
widely throughout the site. Changing Wikipedia to use some other kind
of identifier is likely to have far-reaching ramifications. Unless you
can provide this "client idenfier" as a sort of virtual IP (fits in 32
bits) which you don't mind being displayed everywhere on the site (see
objection 1), it is going to be expensive to implement on the wiki
The simpler solution is to have the gateway proxy not be a hidden
service but to be a public service on the net which has its own exit
IP addresses. It would be a sort of "virtual ISP" which helps
anonymous users to gain the rights and privileges of the identified,
including putting their reputations at risk if they misbehave. This
solution works out of the box for Wikipedia and other wikis, for blog
comments, and for any other HTTP service which is subject to abuse by
anonymous users. I suggest that you adapt your software to this usage
model, which is more general and probably easier to implement.
Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-10-02 09:12:18
@_author: cyphrpunk 
@_subject: nym-0.2 released (fwd) 
A few comments on the implementation details of
1. Limting token requests by IP doesn't work in today's internet. Most
customers have dynamic IPs. Either they won't be able to get tokens,
because someone else has already gotten one using their temporary IP,
or they will be able to get multiple ones by rotating among available
IPs. It may seem that IP filtering is expedient for demo purposes, but
actually that is not true, as it prevents interested parties from
trying out your server more than once, such as to do experimental
hacking on the token-requesting code.
I suggest a proof of work system a la hashcash. You don't have to use
that directly, just require the token request to be accompanied by a
value whose sha1 hash starts with say 32 bits of zeros (and record
those to avoid reuse).
2. The token reuse detection in signcert.cgi is flawed. Leading zeros
can be added to r which will cause it to miss the saved value in the
database, while still producing the same rbinary value and so allowing
a token to be reused arbitrarily many times.
3. signer.cgi attempts to test that the value being signed is > 2^512.
This test is ineffective because the client is blinding his values. He
can get a signature on, say, the value 2, and you can't stop him.
4. Your token construction, sign(sha1(r)), is weak. sha1(r) is only
160 bits which could allow a smooth-value attack. This involves
getting signatures on all the small primes up to some limit k, then
looking for an r such that sha1(r) factors over those small primes
(i.e. is k-smooth). For k = 2^14 this requires getting less than 2000
signatures on small primes, and then approximately one in 2^40 160-bit
values will be smooth. With a few thousand more signatures the work
value drops even lower.
A simple solution is to do slightly more complex padding. For example,
concatenate sha1(0||r) || sha1(1||r) || sha1(2||r) || ... until it is
the size of the modulus. Such values will have essentially zero
probability of being smooth and so the attack does not work.
Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-10-04 11:35:43
@_author: cyphrpunk 
@_subject: Hooking nym to wikipedia 
This is a good summary of the issues. With regard to turning client
certs on and off: from many years of experience with anonymous and
pseudonymous communication, the big usability problem is remembering
which mode you are in - whether you are identified or anonymous. This
relates to the technical problem of preventing data from one mode from
leaking over into the other.
The best solution is to use separate logins for the two modes. This
prevents any technical leakage such as cookies or certificates.
Separate desktop pictures and browser skins can be selected to provide
constant cues about the mode. Using this method it would not be
necessary to be asked on every certificate usage, so that problem with
certs would not arise.
(As far as the Chinese dissident using net cafes, if they are using
Tor at all it might be via a USB token like the one (formerly?)
available from virtualprivacymachine.com. The browser on the token can
be configured to hold the cert, making it portable.)
Network eavesdropping should not be a major issue for a pseudonym
server. Attackers would have little to gain for all their work. The
user is accessing the server via Tor so their anonymity is still
Any solution which waits for Wikimedia to make changes to their
software will probably be long in coming. When Jimmy Wales was asked
whether their software could allow logins for "trusted" users from
otherwise blocked IPs, he didn't have any idea. The technical people
are apparently in a separate part of the organization. Even if Jimmy
endorsed an idea for changing Wikipedia, he would have to sell it to
the technical guys, who would then have to implement and test it in
their Wiki code base, then it would have to be deployed in Wikipedia
(which is after all their flagship product and one which they would
want to be sure not to break).
Even once this happened, the problem is only solved for that one case
(possibly also for other users of the Wiki code base). What about
blogs or other web services that may decide to block Tor? It would be
better to have a solution which does not require customization of the
web service software. That approach tries to make the Tor tail wag the
Internet dog.
The alternative of running a pseudonym based web proxy that only lets
"good" users pass through will avoid the need to customize web
services on an individual basis, at the expense of requiring a
pseudonym quality administrator who cancels nyms that misbehave. For
forward secrecy, this service would expunge its records of which nyms
had been active, after a day or two (long enough to make sure no
complaints are going to come back).
As far as the Unlinkable Serial Transactions proposal, the gist of it
is to issue a new blinded token whenever one is used. That's a clever
idea but it is not adequate for this situtation, because abuse
information is not available until after the fact. By the time a
complaint arises the miscreant will have long ago received his new
blinded token and the service will have no way to stop him from
continuing to use it.
I could envision a complicated system whereby someone could use a
token on Monday to access the net, then on Wednesday they would become
eligible to exchange that token for a new one, provided that it had
not been black-listed due to complaints in the interim. This adds
considerable complexity, including the need to supply people with
multiple initial tokens so that they could do multiple net accesses
while waiting for their tokens to be eligible for exchange; the risk
that exchange would often be followed immediately by use of the new
token, harming unlinkability; the difficulty in fully black-listing a
user who has multiple independent tokens, when each act of abuse
essentially just takes one of his tokens away from him. Overall this
would be too cumbersome and problematic to use for this purpose.
Providing forward secrecy by having the nym-based web proxy erase its
records every two days is certainly less secure than doing it by
cryptographic means, but at the same time it is more secure than
trusting every web service out there to take similar actions to
protect its clients. Until a clean and unemcumbered technological
approach is available, this looks like a reasonable compromise.

@_date: 2005-10-04 11:38:51
@_author: cyphrpunk 
@_subject: Surreptitious Tor Messages? 
References: <20051003135742.GV2249 	
The Tor protocol is complicated and most of the data is encrypted.
You're not going to be able to see what's happening there.
Tor is open source. Build from source and it is highly unlikely that
someone would have embedded any surreptitious code in there without it
being caught.

@_date: 2005-10-18 23:27:53
@_author: cyphrpunk 
@_subject: [fc-discuss] Financial Cryptography Update: On Digital 
References: This is a thorough and careful paper but the system has no blinding
and so payments are traceable and linkable. The standard technique of
inserting dummy transfers is proposed, but it is not clear that this
adds real privacy. Worse, it appears that the database showing which
coins were exchanged for which is supposed to be public, making this
linkage information available to everyone, not just banking insiders.
Some aspects are similar to Dan Simon's proposed ecash system from
Crypto 96, in particular using knowledge of a secret such as a hash
pre-image to represent possession of the cash. Simon's system is
covered by patent number 5768385 and the ePoint system may need to
step carefully around that patent.  See
 at einstein.ssz.com/msg04483.html for
further critique of Simon's approach.

@_date: 2005-10-19 16:34:26
@_author: cyphrpunk 
@_subject: [fc-discuss] Financial Cryptography Update: On Digital 
References:  	
  <792ce4370510182327n233bb7a8la907f4926398a103 	
  <20051019114455.GA8007
Suppose we consider your concept of a "transaction chain", which is
formed when a token is created based on some payment from outside the
system, is maintained through exchanges of one token for another (we
will ignore split and combine operations for now), and terminates when
the token is redeemed for some outside-the-system value. Isn't it
likely in practice that such transaction chains will be paid for and
redeemed via existing financial systems, which are fully identified? A
user will buy a token using an online check or credit card or some
other non-anonymous mechanism. He passes it to someone else as a
cash-like payment. Optionally it passes through more hands. Ultimately
it is redeemed by someone who exchanges it for a check or deposit into
a bank or credit card account.
If you don't see this as the typical usage model, I'd like to hear your ideas.
If this is the model, my concern is that in practice it will often be
the case that there will be few intermediate exchanges. Particularly
in the early stages of the system, there won't be that much to buy.
Someone may accept epoints for payment but the first thing he will do
is convert them to "real money". A typical transaction will start with
someone buying epoints from the issuer using some identified payment
system, spending them online, and then the recipient redeems them
using an identified payment system. The issuer sees exactly who spent,
how much they spent and where they spent it. The result is that in
practice the system has no anonymity whatsoever. It is just another
way of transferring value online.
The hard part is getting into the middle of those transaction chains.
Until we reach the point where people receive their salaries in
epoints, they will have little choice but to buy epoints for real
money. That puts them at the beginning of a transaction chain and not
in the middle. Sellers will tend to be at the end. The only people who
could be in the middle would be those who sell substantially online
for epoints and who also find things online that they can buy for
epoints. But that will be a small fraction of users. For the rest of
them, anonymity is not a sellling point of this system.
If you take away the anonymity, is this technology still valuable?
Does it have advantages over other online payment systems, like egold,
credit cards or paypal?

@_date: 2005-10-20 11:09:08
@_author: cyphrpunk 
@_subject: Judy Miller needing killing 
References: <43555C1E.683E66D5
We put up with this "needs killing" crap from Tim May because he was
imaginative and interesting, at least when he could shake free from
his racism and nihilism. You on the other hand offer nothing but
bilious ignorance. If you don't have anything to say, how about if you
just don't say it?
The notion that someone who is willing to spend months in jail just to
keep a promise of silence "needs killing" is beyond bizarre and is
downright evil. This list supports the rights of individuals to tell
the government to go to hell, and that is exactly what Judy Miller
did. She should be a hero around here. It's disgusting to see these
kinds of comments from a no-nothing like "Major Variola".

@_date: 2005-10-20 11:31:39
@_author: cyphrpunk 
@_subject: [fc-discuss] Financial Cryptography Update: On Digital 
References: Let's take a look at Daniel Nagy's list of desirable features for an
ecash system and see how simple, on-line Chaum ecash fares.
This is of course the main selling point of Chaum's system, where it
excels. I will point out that defining cash as merely "potentially"
anonymous leaves a loophole whereby fully non-anonymous systems get to
call themselves cash. This underplays the strength of Chaum's system.
It is not just "potentially" anonymous, it has a strong degree of
Certainly Chaum ecash has this property. Because deposits are
unlinkable to withdrawals, there is no way even in principle to
reverse a transaction.
Again this is precisely how Chaum ecash works. Everyone can receive
ecash and everyone can spend it. There is no distinction between
buyers and vendors. Of course, transactions do need the aid of the
issuer, but that is true of all online payment systems including
I have to admit, I don't understand this point, so I can't say to what
extent Chaum ecash meets it. In most cases users will simply use their
software to perform transactions and no familiarity is necessary with
any antiforgery or other technical measures in the payment system. In
this sense all users are "naive" and no one is expected to be a
technical expert. Chaum ecash works just fine in this model.
This is the one aspect where Chaum ecash fails. It is a significant
strength of Daniel Nagy's system that it allows public audits of the
amount of cash outstanding.
However note that if the ecash issuer stands ready to buy and sell
ecash for "real money" then he has an incentive not to excessively
inflate his currency as it would create liabilities which exceed his
assets. Similarly, in a state of competition between multiple such
ecash issuers, any currency which over-inflates will be at a
disadvantage relative to others, as discussed in Dan Selgin's works on
"free banking".
Daniel Nagy also raised a related point about insider malfeasance,
which is also a potential problem with Chaum ecash, but there do exist
technologies such as hardware security modules which can protect keys
in a highly secure manner and make sure they are used only via
authorized protocols. Again, the operators of the ecash system have
strong incentives to protect their keys against insider attacks.
In summary, I don't think this is true at all. At least the first
three characteristics are met perfectly by Chaumian ecash, and
possibly the fourth is met in practice as naive users can access the
system without excessive complications. Only the fifth point, the
ability for outsiders to monitor the amount of cash in circulation, is
not satisfied. But even then, the ecash mint software, and procedures
and controls followed by the issuer, could be designed to allow third
party audits similarly to how paper money cash issuers might be
audited today.
There do exist technical proposals for ecash systems such as that from
Sander and Ta-Shma which allow monitoring the amount of cash which has
been issued and redeemed while retaining anonymity and unlinkability,
but those are of questionable efficiency with current technology.
Perhaps improved versions of such protocols could provide a payment
system which would satisfy all of Daniel Nagy's desiderata while
retaining the important feature of strong anonymity.

@_date: 2005-10-20 15:36:54
@_author: cyphrpunk 
@_subject: [fc-discuss] Financial Cryptography Update: On Digital 
References:  	
  <792ce4370510201131o6e1a2fa0x543a60a566a56a00 	
  <20051020202354.GA8695 	
As far as the issue of receipts in Chaumian ecash, there have been a
couple of approaches discussed.
The simplest goes like this. If Alice will pay Bob, Bob supplies Alice
with a blinded proto-coin, along with a signed statement, "I will
perform service X if Alice supplies me with a mint signature on this
value Y". Alice pays to get the blinded proto-coin Y signed by the
mint. Now she can give it to Bob and show the signature on Y in the
future to prove that she upheld her end.
A slightly more complicated one starts again with Bob supplying Alice
with a blinded proto-coin, which Alice signs. Now she and Bob do a
simultaneous exchange of secrets protocol to exchange their two
signatures. This can be done for example using the commitment scheme
of Damgard from Eurocrypt 93. Bob gets the signature necessary to
create his coin, and Alice gets the signed receipt (or even better,
perhaps Bob's signature could even constitute the service Alice is
I would be very interested to hear about a practical application which
combines the need for non-reversibility (which requires a degree of
anonymity) with the need to be able to prove that payment was made
(which seems to imply access to a legal system to force performance,
an institution which generally will require identification).

@_date: 2005-10-21 11:17:06
@_author: cyphrpunk 
@_subject: [fc-discuss] Financial Cryptography Update: On Digital 
References:  	
  <792ce4370510201131o6e1a2fa0x543a60a566a56a00 	
  <20051020202354.GA8695 	
  <20051020223202.GB15395 	
You're such an asshole. Daniel's actual statement was simply:
This is what you characterized as a "unitary global claim". Aside from
the fact that "unitary" is meaningless in this context, his claim was
far from "global". Instead it was a very modest statement about what
aspects of the technology he was familiar with, and explicitly
admitted the possibility that he might be mistaken. I don't think you
could ask for anything more in a world where no one has perfect
knowledge about any topic.
While Daniel Nagy has been a model of politeness and modesty in his
claims here, you have reverted to your usual role as an arrogant
bully. If Daniel's project should be successful then you will
undoubtedly switch over to your other mode of communication,
obsequious ass-kissing. I have experienced both from you, in my many
names and roles, and I have no taste for either one.
I would encourage Daniel not to waste any more time interacting with Hettinga.

@_date: 2005-10-21 11:35:15
@_author: cyphrpunk 
@_subject: [fc-discuss] Financial Cryptography Update: On Digital 
References:  	
  <792ce4370510201131o6e1a2fa0x543a60a566a56a00 	
  <20051020202354.GA8695 	
  <792ce4370510201536h10f8c17bnb8de923fca27a842 	
  <20051020234839.GD15395
Good idea! Even without this, if there is a problem then everything
will come out in the dispute resolution phase, where Alice will be
forced to reveal the mint's signature. Bob may claim at that time
never to have seen it before, while Alice may claim that she had sent
it earlier, but once they get this far both sides will be forced to
agree that Bob has now been paid so the contract can be completed. So
this method would be OK for contracts where timeliness is not an
important issue. But your idea of having the mint publish its
signatures could help even more.
I'm not sure what costs you see here. There are two main technologies
I am familiar with for signature (or general secret) exchange. One is
purely local and involves bit by bit release of the signatures. Both
parties first commit to their signatures and use ZK proofs to show
that the committed values are in fact signatures over the required
data. They then release their sigs a bit at a time, taking turns. If
one party aborts prematurely he has at most a factor of 2 advantage
over the other in a brute force search to find the missing bits of the
signature. While this takes many rounds, it is still pretty fast. Of
course the users don't manually initiate each round, it all happens
automatically under control of the software. I saw some code to
implement this a couple of years ago somewhere on Sourceforge. It
actually exchanged PGP signatures, of all things. It does not take any
new infrastructure.
The other technology is so-called "optimistic" exchange, where the
signatures are provably encrypted to the public key of a trusted third
party. The two parties each exchange such encryptions and prove they
are valid. Then they exchange the actual signatures in the
straighforward manner. If one party does not send his sig, the other
can go to the TTP and get it. Since this option exists, there is no
incentive for the parties not to complete the transaction and hence
the TTP will in practice almost never be used. This one does require
the TTP to exist and his public key to be available, but that should
be no more new infrastructure than is required for the cash issuer and
his key to be distributed. In fact the issuer could be the TTP for
dispute resolution if desired.
Yes, that's a good example. A reputation system could be enhanced by
provability of payment, although unless there is also provability of
performance (i.e. providing whatever was paid for) there is still a
he-said-she-said issue. Presently, reputation systems like eBay rely
on the idea that if someone cheats, they probably cheat a lot, so
there will be many complaints against them. Your technology would
eliminate some forms of false complaints, namely those where someone
did not pay but claimed that they did pay and demanded the goods. That
is such an audacious fraud that I question how often it happens, but
eliminating it would indeed have some value.

@_date: 2005-10-21 22:18:08
@_author: cyphrpunk 
@_subject: cypherpunks@minder.net closing on 11/1 
References: <20051013204900.GA26449
Gmail would facilitate automating a new cypherpunks-moderated list.
Gmail's spam filtering is great and even a regular cypherpunks
subscription has almost no spam.
Sign up a gmail account and subscribe it only to cypherpunks. Use the
POP interface to fetch message from gmail, and redistribute those to
the new cypherpunks-moderated list. Subscribers gain the anti spam
features of cp-moderated without any manual filtering or moderating

@_date: 2005-10-24 10:50:50
@_author: cyphrpunk 
@_subject: [smb@cs.columbia.edu: Skype security evaluation] 
References: <20051023153121.GW2249 	
But what you have shown here has no encryption, hence no secrecy.
Surely RSA encryption must be used somewhere along the line. The
report doesn't say anything about the details of how that is done. In
particular, although it mentions RSA signature padding it says nothing
about RSA encryption padding.
Is it possible that Skype doesn't use RSA encryption? Or if they do,
do they do it without using any padding, and is that safe?

@_date: 2005-10-24 11:14:08
@_author: cyphrpunk 
@_subject: [fc-discuss] Financial Cryptography Update: On Digital 
References:  	
  <792ce4370510201131o6e1a2fa0x543a60a566a56a00 	
  <200510210743.j9L7htFT002090 	
  <435A3406.7070304
Right, that is one of the kinds of modifications that Ray referred to.
If the mint allows (de-facto) anonymous exchanges then a blackmailer
can simply do an exchange of his ecash before spending it and he will
be home free. Another mod is for the blackmailer to supply the
proto-coin to be signed, in blinded form.
One property of Daniel Nagy's epoint system is that it creates chains
where each token that gets created is linked to the one it came from.
This could be sold as an anti-abuse feature, that blackmailers and
extortionists would have a harder time avoiding being caught. In
general it is an anti-laundering feature since you can't wash your
money clean, it always links back to when it was dirty.
U.S. law generally requires that stolen goods be returned to the
original owner without compensation to the current holder, even if
they had been purchased legitimately (from the thief or his agent) by
an innocent third party. Likewise a payment system with traceable
money might find itself subject to legal orders to reverse subsequent
transactions, confiscate value held by third parties and return the
ill-gotten gains to the victim of theft or fraud. Depending on the
full operational details of the system, Daniel Nagy's epoints might be
vulnerable to such legal actions.
Note that e-gold, which originally sold non-reversibility as a key
benefit of the system, found that this feature attracted Ponzi schemes
and fraudsters of all stripes, and eventually it was forced to reverse
transactions and freeze accounts. It's not clear that any payment
system which keeps information around to allow for potential
reversibility can avoid eventually succumbing to pressure to reverse
transactions. Only a Chaumian type system, whose technology makes
reversibility fundamentally impossible, is guaranteed to allow for
final clearing. And even then, it might just be that the operators
themselves will be targeted for liability since they have engineered a
system that makes it impossible to go after the fruits of criminal

@_date: 2005-10-24 14:46:04
@_author: cyphrpunk 
@_subject: [fc-discuss] Financial Cryptography Update: On Digital 
References:  	
  <792ce4370510201131o6e1a2fa0x543a60a566a56a00 	
  <200510210743.j9L7htFT002090 	
  <435A3406.7070304 	
  <792ce4370510241114y6e2161c9r1ebde458190b4b6a 	
  <6.0.1.1.0.20051024120442.052d4480
Back in the days of such companies as emutualfun.com and
stockgeneration.com there were cases where e-gold froze accounts
without waiting for court orders. I was involved with the discussion
on the e-gold mailing lists back then and it caused considerable hard
feeling among the users. E-gold was struggling to deal with the
onslaught of criminal activity (Ian Grigg described the prevailing
mood as one of 'angst') and they were thrown into a reactive mode.
Eventually I think they got their house in order and established
policies that were more reasonable.
Yes, but unfortunately it is not clear at all that courts would find
the opposite, either. If a lawsuit names the currency issuer as a
defendant, which it almost certainly would, a judge might order the
issuer's finances frozen or impose other measures which would impair
its business survival while trying to sort out who is at fault. It
would take someone with real cojones to go forward with a business
venture of this type in such uncharted waters.

@_date: 2005-10-24 14:58:32
@_author: cyphrpunk 
@_subject: [fc-discuss] Financial Cryptography Update: On Digital 
References: <19746800.1130183853393.JavaMail.root
To clarify one point, it is not necessary to have "accounts" in an
ecash system. Probably the simpler approach is for a mint that has
three basic functions: selling ecash for real money; exchanging ecash
for new ecash of equal value; and buying ecash for real money. All
ecash exchanges with the mint can be anonymous, and only when ecash is
exchanged for real money does that side of the transaction require a
bank account number or similar identifying information.
In such a system, the ecash resides not in accounts, but in digital
wallets which are held in files on end users' computers. The basic
attack scenario then is some kind of virus which hunts for such files
and sends the ecash to the perpetrator. If the ecash wallet is
protected, by a password or perhaps a token which must be inserted,
the virus can lie in wait and grab the ecash once the user opens the
wallet manually. There are several kinds of malicious activities that
are possible, from simply deleting the cash to broadcasting it in
encrypted form such as by IRC. Perhaps it could even engage in the
quixotic action of redistributing some of the cash among the users,
but my guess is that pecuniary motivations would dominate and most
viruses will simply do their best to steal ecash. Without accounts per
se, and using a broadcast channel, there is little danger in receiving
or spending the stolen money.
Digital wallets will require real security in user PCs. Still I don't
see why we don't already have this problem with online banking and
similar financial services. Couldn't a virus today steal people's
passwords and command their banks to transfer funds, just as easily as
the fraud described above? To the extent that this is not happening,
the threat against ecash may not happen either.
They might be sued but they won't necessarily go broke. It depends on
how deep the pockets are suing them compared to their own, and most
especially it depends on whether they win or lose the lawsuit. As
Steve Schear noted, there is a reasonable argument that a payment
system issuer should not be held liable for the misdeeds of its
customers. Jurisdictional issues may be important as well. Clearly
anyone proposing to enter this business will have to accept the risk
and cost of defending against such lawsuits as part of the business

@_date: 2005-10-24 22:18:12
@_author: cyphrpunk 
@_subject: [PracticalSecurity] Anonymity - great technology but hardly 
References: The truth is exactly the opposite of what is suggested in this
article. The desire for anonymous communication is greater today than
ever, but the necessary technology does not exist.
For the first time there are tens or hundreds of millions of users who
have a strong need and desire for high volume anonymous
communications. These are file traders, exchanging images, music,
movies, TV shows and other forms of communication. The main threat to
this illegal but widely practiced activity is legal action by
copyright holders against individual traders. The only effective
protection against these threats is the barrier that could be provided
by anonymity. An effective, anonymous file sharing network would see
rapid adoption and would be the number one driver for widespread use
of anonymity.
But the technology isn't there. Providing real-time, high-volume,
anonymous communications is not possible at the present time. Anyone
who has experienced the pitiful performance of a Tor web browsing
session will be familiar with the iron self-control and patience
necessary to keep from throwing the computer out the window in
frustration. Yes, you can share files via Tor, at the expense of
reducing transfer rates by multiple orders of magnitude.
Not only are there efficiency problems, detailed analysis of the
security properties of real time anonymous networks have repeatedly
shown that the degree of anonymity possible is very limited against a
determined attacker. Careful insertion of packet delays and monitoring
of corresponding network reactions allow an attacker to easily trace
an encrypted communication through the nodes of the network. Effective
real-time anonymity is almost a contradiction in terms.
Despite these difficulties, file trading is still the usage area with
the greatest potential for widespread adoption of anonymity. File
traders are fickle and will gravitate rapidly to a new system if it
offers significant benefits. If performance can be improved to at
least approximate the transfer rates of non-anonymous networks, while
allowing enough security to make the job of the content lawyers
harder, that could be enough to give this technology the edge it needs
to achieve widespread acceptance.

@_date: 2005-10-27 20:18:12
@_author: cyphrpunk 
@_subject: [PracticalSecurity] Anonymity - great technology but hardly 
References:  	
  <792ce4370510242218h12985e18ua62efb15f9e25590 	
  <1130377309.24905.21.camel
This is off-topic. Let's not degenerate into random Microsoft bashing.
Keep the focus on anonymity. That's what the cypherpunks list is

@_date: 2005-10-27 20:41:22
@_author: cyphrpunk 
@_subject: [PracticalSecurity] Anonymity - great technology but hardly 
References:  	
  <792ce4370510242218h12985e18ua62efb15f9e25590 	
  <1130377309.24905.21.camel 	
  <792ce4370510272018o542bed14rc68d17f07189cfc 	
Fine, I want it to be about crypto and anonymity. You can bash
Microsoft anywhere on the net. Where else are you going to talk about
this shit?

@_date: 2005-10-27 20:55:29
@_author: cyphrpunk 
@_subject: [fc-discuss] Financial Cryptography Update: On Digital 
References: <8671013.1130250005432.JavaMail.root
This is why you can't buy ecash with your credit card. Too easy to
reverse the transaction, and by then the ecash has been blinded away.
If paypal can be reversed just as easily that won't work either.
This illustrates a general problem with these irreversible payment
schemes, it is very hard to simply acquire the currency. Any time you
go from a reversible payment system (as all the popular ones are) to
an irreversible one you have an impedence mismatch and the transfer
reflects rather than going through (so to speak).

@_date: 2005-10-27 21:07:21
@_author: cyphrpunk 
@_subject: [smb@cs.columbia.edu: Skype security evaluation] 
References: <20051023153121.GW2249 	
  <792ce4370510241050m6e0cd60atc155ffac3054ca40 	
  <20051026074451.L35119
Wasn't there a rumor last year that Skype didn't do any encryption
padding, it just did a straight exponentiation of the plaintext?
Would that be safe, if as the report suggests, the data being
encrypted is 128 random bits (and assuming the encryption exponent is
considerably bigger than 3)? Seems like it's probably OK. A bit risky
perhaps to ride bareback like that but I don't see anything inherently

@_date: 2005-10-27 21:15:15
@_author: cyphrpunk 
@_subject: On Digital Cash-like Payment Systems 
References: <792ce4370510241458p2c6788e2rc75842dc6a1e30d9
  	 <20051024223836.GI4102 	
  <435F43EE.21250.A1D6EE9
Just make it bigger by adding redundancy and padding, before you
encrypt it and store it on your disk. That way the attacker who wants
to steal your keyring sees a 4 GB encrypted file which actually holds
about a kilobyte of meaningful data. Current trojans can steal files
and log passwords, but they're not smart enough to decrypt and
decompress before uploading. They'll take hours to snatch the keyfile
through the net, and maybe they'll get caught in the act.

@_date: 2005-10-27 21:27:00
@_author: cyphrpunk 
@_subject: [kerry@vscape.com: Re: [p2p-hackers] P2P Authentication] 
References: <20051027140924.GG2249
It's great to see this guy showing up yet another of the false dogmas
of the crypto hacker community: "PKI can't work". According to this
view, only old fogies and tight ass bureaucrats believe in certifying
keys. All the cool kids know that the best key is a bare key. After
all, MITM attacks never really happen, this was just an invented
threat designed to force poor college kids into paying hundreds of
dollars a year for a verisign certificate.
But when we come into the P2P world things look very different. Where
MITM would require special positioning in the old net, in a
distributed P2P network, everyone's a MITM! Every key has passed
through dozens of hands before you get to see it. What are the odds
that nobody's fucked with it in all that time? You're going to put
that thing in your mouth? I don't think so.
Using certificates in a P2P network is like using a condom. It's just
common sense. Practice safe cex!

@_date: 2005-10-28 14:18:43
@_author: cyphrpunk 
@_subject: [fc-discuss] Financial Cryptography Update: On Digital 
References: One other point with regard to Daniel Nagy's paper at
A good way to organize papers like this is to first present the
desired properties of systems like yours (and optionally show that
other systems fail to meet one or more of these properties); then to
present your system; and finally to go back through and show how your
system meets each of the properties, perhaps better than any others.
This paper is lacking that last step. It would be helpful to see the
epoint system evaluated with regard to each of the listed properties.
In particular I have concerns about the finality and irreversibility
of payments, given that the issuer keeps track of each token as it
progresses through the system. Whenever one token is exchanged for a
new one, the issuer records and publishes the linkage between the new
token and the old one. This public record is what lets people know
that the issuer is not forging tokens at will, but it does let the
issuer, and possibly others, track payments as they flow through the
system. This could be grounds for reversibility in some cases,
although the details depend on how the system is implemented. It would
be good to see a critical analysis of how epoints would maintain
irreversibility, as part of the paper.

@_date: 2005-10-28 14:53:30
@_author: cyphrpunk 
@_subject: 0wn3d 
I have hacked the account cyphrpunk at gmail.com. If cyphrpunk want to know the
new password of his account, he can check the box "cyphrpunk at hotmail.com"

@_date: 2005-10-29 21:17:25
@_author: cyphrpunk 
@_subject: [fc-discuss] Financial Cryptography Update: On Digital 
References:  	
  <792ce4370510281418l74b01072kb43ea37584fd50f1 	
  <20051028234456.GA12429
The issuer can still invalidate it even though you have not explicitly
defined such an operation. If Alice paid Bob and then convinces the
issuer that Bob cheated her, the issuer could refuse to honor the Db
deposit or exchange operation. From the recipient's perspective, his
cash is at risk at least until he has spent it or exchanged it out of
the system.
The fact that you don't have an "issuer invalidates cash" operation in
your system doesn't mean it couldn't happen. Alice could get a court
order forcing the issuer to do this. The point is that reversal is
technically possible, and you can't define it away just by saying that
the issuer won't do that. If the issuer has the power to reverse
transactions, the system does not have full ireversibility, even
though the issuer hopes never to exercise his power.
That is an interesting possibility, but I can think of a way around
it. Alice could embed a secret within her secret. She could base part
of her secret on a hash of an even-more-secret value which she would
not reveal when spending/exchanging. Then if it came to where she had
to prove that she was the proper beneficiary of a reversed
transaction, she could reveal the inner secret to justify her claim.
That's true, the public visibility of the system makes secret
reversals impossible. That's very good - one of the problems with
e-gold was that it was never clear when they were reversing and
freezing accounts. Visibility is a great feature. But it doesn't keep
reversals from happening, and it still leaves doubt about how final
transactions will be in this system.

@_date: 2005-09-27 17:25:07
@_author: cypherpunk 
@_subject: Hello directly from Jimbo at Wikipedia 
As an occasional Tor and Wikipedia user, let me add a couple of points.
First, in case it is not obvious, the problem with the present system
is that Tor users can no longer edit on Wikipedia. I have done so in
the past, in what I like to think is a constructive manner, but cannot
do so since this summer. I have valid although perhaps unpopular
contributions to make, and not only is my freedom to express myself
limited, the quality of the material on Wikipedia suffers due to the
absence of my perspective. The status quo is not acceptable and we
should work to find a solution.
Looking at the proposals for authentication servers and such, I see a
major issue which is not being addressed. That is, how does the web
server distinguish "authenticated" Tor users from unathenticated ones?
If this is via a complicated protocol, there is no point as the
servers won't use it.
The hard truth is this: the distinction must be done on the basis of
IP address. That is, there must be a separate set of Tor exit nodes
which are only for authenticated users.
This does not necessarily mean building complex authentication
protocols into the Tor network, and having two classes of traffic
flowing around. It could be that this authenticated Tor is a separate
network. It only lets users in who are authenticated, and owns a
specific set of IP addresses which servers can whitelist. The regular
Tor exit nodes can be blacklisted as they are now.
The technical problem is then, how to achieve as much anonymity as
possible in the authenticated network, while still providing the abuse
prevention services which Wikipedia and other servers will require in
order to whitelist the nodes.
What does Wikipedia need? What is the minimum level of service they
require? Presumably, it is similar to what they can get via ISPs, who
also map many users to a fixed set of IP addresses. Wikipedia can
complain to the ISP, and it will get back in some form to that user.
Of course, Wikipedia does not know the details of how their complaint
is handled. Is the user kicked off, banned temporarily, or merely
given a stern warning? What matters to them is that, generally, users
that they complain about don't keep coming back. Their complaints are
effective, at least much or most of the time. This is the level of
response which an authenticated Tor network would have to provide.
The problem with this functionality from Tor's perspective is that
unlike an ISP, Tor does not have knowledge of the mapping from users
to IP addresses. Given a complaint that a certain IP was misused at a
certain time, Tor has no information about which user to penalize.
To solve the problem we would need to use some cryptographic
mechanism. Let authenticated users gain credentials via some
expensive, slow process. Let them embed the credentials in their
messages such that they are revealed in some blinded form to the exit
node. Let the exit nodes remember the credentials which were used at
different times. When valid complaints arrive, let the exit nodes
blacklist the credential which was in use at that time. This stops the
There could be many such authenticated-Tor subnetworks. Each could
have its own credential servers, its own abuse policies, and its own
set of exit IP addresses. They would be like anonymous ISPs, from the
POV of web server operators like Wikipedia. Those which are
effectively able to suppress abuse will avoid blacklists and their
users will be able to successfully use web based services.
Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-09-29 16:44:37
@_author: cyphrpunk 
@_subject: [roy@rant-central.com: Re: [arma@mit.edu: Re: Wikipedia & Tor]] 
One of the problems with the idea of a pseudonym service
distinguishing between "good" and 'bad" users is that it has no way on
its own of telling the difference. The service manages pseudonyms,
which are intended to be used out on the web in some way. But the
service can't tell if people are playing nicely or not.
The only way this could happen is if the service receives
*complaints*. This is the only feedback mechanism possible. I gather
that Tor does in fact send out complaints about people who misbehave.
Perhaps blog services do so as well.
One problem is that these complaints generally don't arrive in real
time. It takes time for a human being to notice that some vandalism
has occured and register a complaint. If the pseudonym service is
going to be able to respond, it has to know which pseudonym was active
at the time the bad actions occured.
Jimmy Wales very accurately describes the problem with pseudonyms at
the web-server level. If Wikipedia or blog comments require the use of
pseudonyms, these can be linked after the fact. I am very sensitive to
this problem myself.
The implied solution is that the pseudonym service would maintain the
pseudonyms, but would not reveal them to the web service. Rather, it
would only provide a certificate that the pseudonym is currently in
good standing, i.e. it has not received (too many) complaints.
This implies that the pseudonym service must maintain a record of
recently used pseudonyms, and have some way of mapping them to what
the web services (which issue the complaints, services like Wikipedia)
would have seen. This mapping might be by IP address, or if Wikipedia
and other services are willing to do more, it could perhaps be an
opaque identifier which the pseudonym service provided at the time the
web service (Wikipedia) asked whether this pseudonym was a "good guy"
or not.
As a specific example, the pseudonym service might have replied, to a
query from Wikipedia, "Yes, this user is a good guy, and the sequence
number of this reply is  Then later if abuse occured,
Wikipedia (or the blog service, or other victim of vandalism) comes
back and said "we had a problem with the user who was certified with
sequence number  The pseudonym server would map this back to
the pseudonym in use at that time, and invalidate the pseudonym (or at
least give it a bad mark, with enough such marks killing the nym).
The main problems with this solution are first, it requires
considerable manual work on the part of the pseudonym server, similar
to the work necessary at an ISP to resolve complaints about users. It
could be a full time job. And second, it requires custom software at
Wikipedia and other web services that might be willing to work to
implement such a solution.
The second problem could be alleviated by the use of a related
service, a web proxy that is only for "good" pseudonyms. The web proxy
would provide transparent pass-through similar to anonymizer.com, but
only for users who were able to provide the kind of certification
described above, from the pseudonym server. In this way, the outgoing
IP addresses belonging to the web proxy would be "good" from the POV
of Wikipedia and other web services. Those services could continue to
use IP blocking as one of their main tools for handling misuse,
treating the web proxy service as being like an ISP. The web proxy
service could be bundled with the pseudonym service, or they could
exist independently.
Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2006-01-04 21:37:57
@_author: cyphrpunk 
@_subject: [declan.mccullagh@gmail.com: [Politech] Feds begin 
References: <20060104090023.GQ2235
On 1/4/06, Eugen Leitl  forwarded:
I am so friggin' sick of the response of the so-called security
community to these kinds of measures. Everything is greeted with
derision and ridicule. I'm coming to believe that the real goal of the
critics is to make it as easy and safe as possible for terrorists to
Years ago when the new security precautions were put in place,
security experts had nothing but criticism. The model they said should
be followed (obviously in the expectation that it was completely
impractical for America), that they pointed to as successful, was the
Israeli airline El Al. Despite Israel's place as the principle target
for terrorist action, El Al has had an astonishingly good record at
flying safely. What was their secret? Exactly the kind of intensive,
personalized attention which is now being criticized. El Al
investigators are trained to observe passengers closely, to ask them
questions and watch for just the signs of nervousness and evasion
which this Ivan Eland treats with such mockery.
Security people can't win. Non-invasive surveillance is called
"security theater". Intensive surveillance is now described as a way
to force people to smile at TSA agents. Doing nothing will produce
even worse results.
And BTW while I'm on the topic of airline security, a comment on John
Gilmore's doomed attempt to sue to be allowed to travel without
identity or security screening of any kind. Gilmore was offered the
chance to fly if he was searched! And he turned it down! He claims
that this violates his rights, that a physical search to make sure he
isn't carrying any dangerous materials is forbidden by the
Constitution. It's unfortunate that this conflates two very different
issues. On the one hand it makes sense to be able to travel without
showing ID. But on the other it makes no sense to claim immunity from
being searched! By trying to treat these two issues equally Gilmore
ends up weakening his own case.

@_date: 2006-10-17 16:06:13
@_author: cyphrpunk 
@_subject: Brands signature revisited :-) 
References: <20061016193255.I26160 	
What a moronic comment.
First of all, the SL currency is not Lindars, it's Lindens.
Second, Lindens have not traded as high as 207 to the dollar in a long
time if ever. The current rate is 274 to the dollar which is down from
over 300 to the dollar a few months ago.
How exactly is the botnet going to make money playing SL? In general
there is no reliable and automatic way to make money in the game,
nothing that could be automated to the degree that it could be run by
a botnet. You can make a few Lindens an hour by sitting your avatar in
"camping chairs" which some in-game businesses run to attract traffic,
but first of all that is an infinitisimal rate of pay in dollars, and
secondly it requires considerable sophistication to maneuver an avatar
to an appropriate location, identify occupied and unoccupied camping
chairs, and sit in one. It is at or beyond the state of the art in AI
research and would require extensive hacking even to get the game into
a situation where it could be controlled by software rather than a
Forgery is not an issue. Lindens are not bearer certificates, they are
merely accounting entries. The real financial threats are the same one
as for other online services, namely breakins that steal real-world
names and credit card numbers. The SL servers suffered such an attack
a few weeks ago.
Again you and other commentators have missed the real issue. Taxing
money moving out of the game, if that ever happens, is going to drive
commerce to stay within the game. There is no reason you can't buy and
consume information goods like books, magazines, music and video
in-game, supporting your habit by selling in-game goods and services
of your own.
Where this must lead is taxation of in-game transactions. The
government is ultimately going to have to force SL to tax internal
exchanges and send those receipts to the IRS. Or perhaps they will
record the country of origin of each player and send taxes to the
approrpriate national government. Imagine having to implement software
to model every taxation system in the world. Not a pretty task.

@_date: 2006-10-19 16:02:13
@_author: cyphrpunk 
@_subject: Regarding Windows Vista Disk Encryption Algorithm. 
References: <20061019125559.67751.qmail
If you want to know more about Vista's use of the TPM, Sarad, I
suggest that you subscribe to the "cypherpunks" mailing list. An
anoymous message was sent to the list on September 7 which outlined
Vista's TPM use and discussed some security implications. Although the
list has not been too active, it has the advantage of accepting
anonymous postings, which the moderated cryptography mailing list does
not. If you would pay attention to the contents of that list, you
would have found many of your questions answered even before you asked
Here is an excerpt from that posting which describes typical attack
scenarios and how Vista Bitlocker stops them:
"Vista's new disk encryption software, called BitLocker, optionally uses
this feature of the TPM to strengthen its encryption.  For example,
consider various attack models for disk encryption.  A laptop is stolen
and the attacker now seeks to decrypt the disk and recover the data."
"The first step often applied in this situation is to take an image of
the disk and run the attacks on that image, from a computer controlled by
the attacker.  This prevents the laptop OS from performing self-destruct
operations or otherwise keeping the attacker from being able to reset
the disk to a pristine state.  But with BitLocker, the disk decryption
key is sealed to a TPM key (a 2048 bit RSA key).  No amount of brute
force password guessing will work to recover a key from a disk image;
the TPM chip itself has to be involved."
"An alternative for an attacker, then, might be to use the laptop itself
but to boot into another OS, such as via a Linux "Live CD" or external
device.  It can then mount the partitions with the encrypted data and
apply similar attacks.  This will give access to the TPM hardware while
still preventing the BitLocker software from having control."
"Again, the BitLocker design will thwart this attack, because the
sealed storage locks the encrypted disk key to the boot configuration.
Changing that configuration by booting into another OS will change PCR
values and prevent the TPM from unlocking the key, even if the correct
password is used."
In exchange for providing you with this useful information, Sarad,
your assigment is to find a public archive of cypherpunks mailing list
postings, so that links to these messages can be provided instead of
having to type long segments in verbatim.
