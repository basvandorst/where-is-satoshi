
@_date: 2002-07-04 22:54:11
@_author: Hadmut Danisch 
@_subject: Ross's TCPA paper 
References:  <5.1.1.6.2.20020703225147.0b94ecd0
I don't think so. As far as I understood, the bus system (PCI,...) will be encrypted as well. You'll have
to use a NIC which is certified and can decrypt the information
on the bus. Obviously, you won't get a certification for such
an network card.
But this implies other problems:
You won't be able to enter a simple shell script through the
keyboard. If so, you could simple print protected files as
a hexdump or use the screen (or maybe the sound device or any
LED) as a serial interface.
Since you could use the keyboard to enter a non-certified
program, the keyboard is to be considered as a nontrusted
device. This means that you either
* have to use a certified keyboard which doesn't let   you enter bad programs
* don't have a keyboard at all
* or are not able to use shell scripts (at least not in
  trusted context). This means a   strict separation between certified software and data.
  If Microsoft was able to do so, we wouldn't have   worms.

@_date: 2002-07-05 13:31:48
@_author: Hadmut Danisch 
@_subject: Ross's TCPA paper 
References:  <5.1.1.6.2.20020703225147.0b94ecd0 <20020704205410.GA8220 <20020705105252.GC5551
That *might* be a contradiction in terms.
If I understand this correctly, the TCPA or Palladium hardware will include some kind of memory management device, very similar
to the ones we have in hardware of the last years, but which stores
some kind of de-/encryption information for each page segment and
which de-/encrypts every memory access. Doesn't seem to be much of
a problem, except for speed.
But how does this device know which segments belong to the software
and which don't? Or how does it know whether an allowed or foreign task
is accessing the protected areas (which is the same question again,
= is the PC in a program segment which also belongs to the protected
area). If this is done the simple way, like a normal OS configures the
memory management when loading some executable software, the OS
might at any time give wrong information to the device. In this case, the security depends on the integrity and bug-freeness of the OS, because the OS _could_ do it, but it is not supposed to do it.
A more advanced way would be to have the program loaded by the operating system as before, but to have the Palladium device check
some kind of signature to verify the correctness of the OS loading operation. This might lead to an uncontrollable problems, if programs start to load DLLs. Is the TCPA/Palladium
trust transitive? If library A is trusted, and so is B, is then
(A+B) trusted?
A third way would be to keep the OS completely out of the job
of loading software/programs into memory, and to have it done
by the Palladium device. This isn't actually a third way, but
a redefinition of terms and a migration. The OS isn't the OS
anymore, because basic tasks of the OS have been migrated to
the Palladium device, which is now to be considered as a
piece of OS in silicon.
I didn't find the time yet to read the TCPA description in detail. But from my current point of view I doubt that this
will really work, provide the claimed security, and will still
be a useful computer at the same time.
I especially doubt that the same company, which completely fails to
make Outlook or Internet Explorer resistent against content attacks (viruses, worms, ...) will be able to provide
software which such a strict separation between trusted and untrusted
data, as it is required for such a project to work.

@_date: 2002-07-05 16:20:02
@_author: Hadmut Danisch 
@_subject: Ross's TCPA paper 
References: <20020704205410.GA8220 <006001c223e8$733e4200$6401a8c0
That's why I was talking about a shell script (or take any
other program to be interpreted).
What does need to be certified: The shell or the shell script?
The CPU doesn't recognize the shell script as a program, this
is just some plain data entered through the keyboard like
writing a letter. A shell script is not a program, it is
data entered at a program's runtime.
This moves one step forward:
The hardware (palladium chip, memory management, etc.) can
check the binary program to be loaded. So you won'te be able
to run a compiled program and to access protected information.
But once a certified software is running, it takes input
(reading mouse, keyboard, files, asking DNS, connecting servers,...). This input might cause (by interpretation, by
bug or however) the certified software to do certain things
which do not comply with DRM requirements.
At this stage, the running binary software itself is the
instance to provide the DRM security, not the palladium memory management anymore. I agree that this is not yet an "open sesame", but it shows
that the game does not play on the binary/memory management
layer only.
But who controls runtime input?
History shows, that M$ software is anything but able
to deal with malicious input. That's why the world is
using virus filters. That's nothing else than an external
filter to keep malicious input from an attacker away
from the running software.
By analogy, Palladium might require the same: an input
filter between attacker and running software. Since the
"attacker" is sitting in front of the computer this time,
this filter has to be applied to the user interface,
keyboard and mouse.
Maybe they'll install a filter between the keyboard and
the software, thus building a certified keyboard, which
filters out any malicious key sequences. And maybe you
can use your keyboard only, if you have downloaded the
latest patterns (like your daily virus filter update).
I agree that this depends on the assumption that the certified software is not perfect and can't
deal with arbitrary input. But that's reality.

@_date: 2002-07-20 23:29:45
@_author: Hadmut Danisch 
@_subject: Maybe no stego on eBay afterall 
References: <15670.65478.136672.341983 <00af01c2300b$e0388850$6501a8c0
I fully agree.
Go one step further: Every civilian who sells at ebay, puts a picture on the auction
web page, and doesn't take care that this picture can't be
reported falsely positive by some arbitrary software by any
company wishing to be in the headlines, can be considered being a terrorist as well.
So, simply, everyone selling on ebay with a picture (oops, I did
as well), is in danger of being considered as a terrorist. You never know what next month's stego detection software will
pretend to detect in one's picture.
And as we know, the US convicts terrorists at those lawless military courts.
Gee, I was never aware how dangerous it is to sell on Ebay.
(Any idea how to make a picture reliably stego free against
*any* stego detection software?)

@_date: 2003-05-13 15:18:21
@_author: Hadmut Danisch 
@_subject: A Trial Balloon to Ban Email? 
References: <0ac3a2f2dc678e1551bcf8fc1c76fac1
I doubt that any kind of anti-spam mechanism which requires such a certification will be widely accepted. And I do not believe that
any cryptographical method can be deployed widely enough to provide
security against spam. Cryptography is simply too complicated and too
error/theft-of-secret prone to be used in common. (If anyone is interested, I've made an alternative proposal based on
non-cryptographic DNS-based lightweight authentication/authorization,
available at  )

@_date: 2004-04-04 16:53:36
@_author: Hadmut Danisch 
@_subject: Do Cryptographers burn? 
Thanks for the opinions.
Maybe I'll explain a little bit more about the background:
As some already may have heard I'm in a legal dispute with a
german University. I wrote a dissertation in 1998, and the supervisor
announced to give a good rate. I then signed off from the job as an
assistant effectively to the date of the examination. I didn't know
that the supervisor and another professor had made a plan to implement
a security infrastrukture for the faculty and to found a company, and
that this plan included that I would do the work in the year after the
examination. When I signed off, they couldn't fulfill the promises
they gave to the faculty, and thus canceled the examination to extort
me to stay at the university and do the implementation. I refused
to pay that kind of "protection money" and thus they rejected my
dissertation with false expertises.
The advisor's expertise (who claims to be one of the world's top
cryptographers) is just a concatenation of arbitrary nonsense, and
wrong even in the basics of computer science. E.g. he claims that LZ
and MTF would effectively compress just anything. As an example for
the need to distinguish between payload and control information I said
that when phoning, not only speech is to be transmitted, but also
phone numbers and signals about termination of the connection.  He
rated this as completely wrong and giving wrong information, because
phone numbers would be used with today's ISDN Telephones only. As the
reason he gave an obituary in the London Times saying that Donald
Davies had died. Or he blames me for not citing literature that hadn't
been published when I submitted the dissertation. He claims that
rate-distortion theory and shannon encoding allow to pack n+1
independant bits into a single message of n bits (even with small n or
n=1. Just try to do it.).
The second examiner said the dissertation would be completely wrong
but denied to give any explanation. I filed a lawsuit.
During the law suit, the university had informed me, that they would
never accept me to succeed in the examination. They would abuse a gap
in german examination law: courts are restricted to cancel bad or
wrong examinations, but they cannot give a positive examination
result. All they can do is to sentence the University to repeat the
examination. The University informed me that they had decided that
they do not wish me to work in science and thus I had to accept to
fail in the examination. I would have to modify my dissertation and to
include those mistakes the examiners had falsely claimed in order to
confirm that their rejection was correct. If I do that I would be
allowed to have a second try with a new dissertation and would receive
a bad grade which would keep me out of science. If I do not agree,
they announced to keep me in an endless loop of false
expertises. Every single one will take me years to sue against. I
refused that "deal".
I won both at the administration court and the appelate administration
court. The latter one found that the second examiner could never have
read the largest chapter and didn't even open the pages of the
dissertation. This was already sufficient to cancel the examination
action. The University then retracted the action to avoid being
Obviously, this was an extreme disgrace for the University. The
University had to give a new second expertise. If this expertise could
not confirm what the first expertise said, that the dissertation was
completely wrong, the advisor would face beeing fired, severe
compensation claims, and the ultimate disgrace.
Within less then two weeks the University managed to get a third rejecting
expertise, this time from a professor outside Germany, who is indeed
known as one of the top cryptographers and a member of the board of
directors of the IACR. I filed a new lawsuit and could easily prove
that this professor had intentionally given a wrong expertise
(obviously to protect the supervisor from legal trouble):
- He wrote the expertise in less than two days.
- The expertise is less than a page. He does not give any
  reasons and claims that he cannot be expected to reason his
  expertise. Reasoning is a strong requirement under german law.
- There is no "link" between the expertise and the dissertation.
  He obviously didn't read it.
- He didn't find any single mistake. He just says that everything is
  already known and taken from literature.
- He didn't bother to inform himself about the given problem, the
  legal requirements, and the available grades. That's a strong
  requirement in Germany. Obviously, if someone accepts to write an
  expertise and in advance knows that he won't need grades, then he
  knows that he will reject the dissertation before he has seen it.
- And he erroneously assumed that the expertise would be kept secret.
  In Germany, the examinee has the right to get a copy of the
  expertise and raise objections. He was not aware of this and
  based his expertise on the assumption that nobody would see it.
I then raised several technical and legal objections, and cited
literature which explicetly stated that such subjects have not yet
been published.
- He then had to admit that he couldn't prove his statement that all
  this was known in literature, and that he raised this claim to
  reject the dissertation because he didn't like it.
- He couldn't defend against any of my technical objections and
  citations. He is not even claiming that his expertise is correct,
  and obviously was completely surprised by the fact that I have
  access to his expertise (unlike the university where he is working,
  where they keep the expertises secret).
- When I demanded to receive reasons, he denied that and stated that
  he would not agree with the requirent to reason an
  expertise. Instead, he had based his examination on an "international
  consensus" that would free him from the need to give reasons.
  He also stated that it would be illogical to require an examiner to
  give reasons for his expertise, because candidates could succeed
  with empty dissertations then. (???)
So this expertise is just ridiculous and won't have any chance at a
court, except that it will take me again years for the lawsuit.
I then informed the IACR's board of directors and asked them whether
an organization, where such a person can become a director can be
trusted any longer in context of security and cryptography.
Surprisingly, they were not even surprised. The fully tolerate this
and even consider this as normal. It looks as if they consider this
kind of expertise as kind of self-evident. To help a colleague and
protect him from legal trouble seems to be much more important than
giving correct and reasonable expertises.
I discussed that with several friend and colleagues, all working in
security and cryptography, and they were all shocked. Everyone would
have bed that they would kick everyone out known to have given a false
expertise. But they don't.
Very similar with the supervisor and the former second examinor:
It is more than obvious that both had given intentionally wrong
expertises and were claiming technical nonsense. But everyone seems to
silently accept this and to consider this as normal.
When preparing for the lawsuit, I read several other dissertations in
order to compare them. I found several of them to be really wrong or
to contain nothing but citations from literature. One of these
dissertations would never have been published if I hadn't asked for a
copy. It was then published around two years after the examination and
contained just citations from literature.
So what I found is fraud, extortion, false expertises.
But not a single one of those cryptographers burns.
Maybe it's a minority writing false expertises. But it's a majority
accepting that.
So my doubt is not so much about that someone found the magic way to
factorize. It's about someone intenionally selling snake-oil or
backdoors and other's keeping their mouth shut and tolerate this as
they do it here.
I have three expertises proven to be intentionally wrong. One from
someone who is known to have no clue about security. One from someone
who is known as a cryptographer and once claimed to be one of the "top
four". And one from someone who is a director of IACR. And no one
cares about. Nobody told me I'd be wrong. Nobody doubted my claims,
objections, and technical arguments. I could easily show that all of
them have intentionally given wrong expertises. Some people even
explicetely confirmed that my dissertation is correct and the
expertises are wrong. This just doesn't matter in any way.
Isn't that spooky? What kind of business is cryptography?

@_date: 2004-11-21 21:36:01
@_author: Hadmut Danisch 
@_subject: E-Mail Authentication Will Not End Spam, Panelists Say 
References: which is, btw, not really correct.
I was one of those panelists, and I explicitely stated that
authentication is only the first step, but an important step, which requires a second step (literally in my slides). So the
first statement seems to be a quote of my talk.
But my statement about the second step was that "reputation" does not
work on an international scale, this works in the U.S. only. It might
even be unlawful in Europe. My proposal was to do the second step
individually for each country.

@_date: 2004-09-07 00:15:33
@_author: Hadmut Danisch 
@_subject: Spam Spotlight on Reputation 
References: I have mentioned this problem more than a year ago in context of my RMX draft (SPF, CallerID and SenderID are based on RMX).
Interestingly, nobody really cared about this major security problem.
All RMX-derivatives block forged messages (more or less).  But what
happens if the attacker doesn't forge? That's a hard problem.  And a
problem known from the very beginning of the sender verifikation
The last 17 month of work in ASRG (Anti Spam Research
Group, IRTF) and MARID (Mail authorization records in DNS, IETF) are
an excellent example of how to not design security protocols. This was all about marketing, commercial interests, patent claims,
giving interviews, spreading wrong informations, underminding
development, propaganda. It completely lacked proper protocol design,
a precise specification of the attack to defend against, engineering
of security mechanisms. It was a kind of religious war. And while people were busy with religious wars, spammers silently realized that this is not a real threat to spam. Actually, it sometimes was quite
the opposite: I was told of some cases where MTAs were configured to run every mail through spam assassin. Spam assassin assigns a message
a higher score if the sender had a valid SPF record. Since most
senders with valid recors were the spammers, spam received a higher
score than plain mail, which is obviously the opposite of security. People spent more time in marketing and public relations than in problem analysis and verifikation of the solution. That's the What can we learn from this?
Designing security protocols requires a certain level of security skills and discipline in what you want to achieve. Although RMX/SPF/CallerID/SenderID does not make use of cryptography,
similar problems can be sometimes found in context of cryptography.
Knowing security primitives is not enough, you need to know how to
assemble them to a security mechanism.  Good lectures are given about
the mathematical aspects of cryptography. But are there lectures about
designing security protocols?  I don't know of any yet.
And there is a new kind of attack: Security protocols themselves can be hijacked and raped by patent claims.
