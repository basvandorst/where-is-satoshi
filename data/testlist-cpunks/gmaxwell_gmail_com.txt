
@_date: 2008-12-06 19:49:58
@_author: Gregory Maxwell 
@_subject: UK internet filtering 
I've confirmed the reports of UK ISPs censoring Wikipedia using some
UK tor exists.

@_date: 2009-09-16 17:26:31
@_author: Gregory Maxwell 
@_subject: "I Write Mass Surveillance Software" 
The hostility on reddit is odd and unfortunate.
The obvious sidestepping is MITM-ing connections for users then shove
manipulated binaries at them which disable encryption, leak key
material, or intercept keystrokes  ... or simply perform degradation
attacks, either forcing protocols to less secure modes, or simply
blocking or massively slowing secure connections to make the user
switch to something insecure.
These have the enormous downside of being detectable active attacks.
Not something you could afford to apply frequently against general
public unless you were willing to tip off your primary target that you
were watching.  Then againb with ISPs like comcast injecting RST
packets, would a degradation attack be distinguishable?
Less obvious sidestepping would include things like simply monitoring
the remote side with the expectation that they won't be as prudent
with security as your primary target.
Black-helicopter mode sidestepping would be having pre-arranged back
doors in popular operating systems or client software.

@_date: 2010-12-08 10:50:18
@_author: Gregory Maxwell 
@_subject: leaker-optimized versions of Tor 
It is strictly necessary that the bad guy not control 100% of the
forwarding nodes.
On a realtime onion network anonymity is bounded by timing attacksb
even if you could tolerate the delay of having a zillion middle nodes
the attacker could just watch the entrances an exits and correlate
timing. So adding a great many hops would not significantly increase
A mix network can tolerate higher delays and, hopefully, eliminates
the timing attacks. So additional hops can be beneficial.
The down side is increased vulnerability to DOS attacks if flooders
can generate cheap round-the-world messages.
The creating a hidden service based overlay network, as was suggested
here by Karsten N., was what I thought when I read the threadb but I
was concerned that if the network identity of all/most of the nodes is
hidden that an attacker could spin up thousands of fake mix nodes
without even needing a lot of network resources. They could make it
far more likely that all your hops were controlled by one party.
Although the risk exists for non hidden service based designs, it's
probably much easier with an anonymity layer in between. Any design
using hidden services would specifically need to address this risk.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2012-08-06 19:28:53
@_author: Gregory Maxwell 
@_subject: [liberationtech] What I've learned from Cryptocat 
This makes me a little sad.  Previously, I understood what cryptocat was for:
It was an insecure system, which was still probably significantly more
secure than the common default unencrypted system, for use where
deployment/usability issues meant it the choice was
insecure-hosted-software or totally-insecure-plaintext.
Non-server-replaceable systems like OTR were strictly preferable, of
course, but in reality aren't ubiquitously used like they ought to be.
With it becoming a browser extensionb it seems like it would gain
much, although not all, of the usability challenges that precluded
using OTR in the first place and in those places where the extension
can't be pre-installed we still have short term SSL CA trust
challenges (for the on-demand distribution of the extension). It also
still retains many of the JS crypto specific technical challenges (no
mlock, so no way to prevent long term keying material from hitting
disk; generational GC so overwriting can't be trusted to reduce cold
boot attack exposure).
No doubt you'll find this an unwanted barb when you're already working
hard trying to make good software to protect people, and that isn't my
intention... but I don't know how to illustrate my confusion
liberationtech mailing list
liberationtech at lists.stanford.edu
Should you need to change your subscription options, please go to:
If you would like to receive a daily digest, click "yes" (once you click above) next to "would you like to receive list mail batched in a daily digest?"
You will need the user name and password you receive from the list moderator in monthly reminders. You may ask for a reminder here: Should you need immediate assistance, please contact the list moderator.
Please don't forget to follow us on

@_date: 2012-07-01 15:38:53
@_author: Gregory Maxwell 
@_subject: [tor-talk] Anonymous Publishing Is Dead. 
I had a similar experience.
When I decided to publish a large collection (30gb) of previously
paywalled (but public domain) JSTOR documents[1] I initially planned
to do so anonymouslyb simply to mitigate the risk of harassment via
the courts. Ultimately, after more consideration I decided to publish
with my name attached and I think it made more of an impact because I
did so (even though quite a few journalists reported it as though it
were a pseudonym)b though if I didn't have even the prospect that I
could publish anonymously I can't say for sure that I would have
started down that road at all.
I perused anonymous publication for some days prior to deciding to not
publish anonymously and I encountered many of the same issues that
Anonymous Person above named at every juncture I hit roadblocksb
though in my case I already had bitcoins, but I couldn't find anyone
to take them in exchange for actually anonymous hosting especially
without access to freenode.   If I'd wanted to emit a few bytes of
text fineb but large amount of data, no.
It's also the case that non-text documents can trivially break your
anonymityb overtly in the case of things like pdf or exif metadata, or
more subtly through noise/defect fingerprints in images. I think I can
fairly count myself among the most technically sophisticated parties,
and yet even I'm not confident that I could successfully publish
anything but simple text anonymously.
The related problems span even further than just the anonymity part of
it.  Even once I'd decided to be non-anonymous I needed hosting that
wouldn't just take the material down (for weeks, if not forever) at
the first bogus DMCA claim (or even in advance of a claim because the
publication was 'edgy').  I ended up using the pirate bayb which
turned out pretty well, though there were some issues where discussion
of my release was silently suppressed on sites such as facebook
because they were hiding messages with links to the pirate bay, and it
was blocked on some corporate networks that utilized commercial
So I think that the problems for anonymous publication on the Internet
are actually a subset of a greater problem that there is little
independence and autonomy in access to publishing online. You can't
_effectively_ publish online without the help of other people, and
they're not very interested in helping anonymous people, presumably
because the ratio of trouble to profit isn't good enough.
About the only solutions I can see are:
(1) Provide stronger abuse resistant nymservices so that things like
freenode don't have to block anonymous parties, thus facilitating
person to person interactions.
(2) Improve the security and useability of things like freenet and
hidden services, so that they are usable for publication directly and
provide strong anonymity.
I'm disappointed to see some of the naysaying in this thread. It
really is hard to publish anything more than short text messages
anonymously, at least if you care about the anonymity not being broken
and you want to reach a fairly large audience.
[1] tor-talk mailing list
tor-talk at lists.torproject.org

@_date: 2012-07-01 16:46:38
@_author: Gregory Maxwell 
@_subject: [tor-talk] blocked exit node IP because of spam 
There are things the tor project and surrounding community could do to
help here.
For example, If I could anonymously donate $10 to a charity and in
return receive a persistent nym which I could use to get around those
kinds of blocks... I'd be hesitant to misbehave and get my nym
blocked.  (And forums should feel good about whatever small residual
amount of spammers who do buy donation nyms, because even though they
spam their need to keep buying nyms support the charities).
But no practical software infrastructure exists for this sort of thing today.
And until it does any education/advocacy will not go too far because
it doesn't offer much in terms of real alternatives.  "It's not really
so bad." "Yes it is, or we wouldn't have bothered putting in the
blocking in the first place" "er.."
tor-talk mailing list
tor-talk at lists.torproject.org

@_date: 2012-07-02 00:27:35
@_author: Gregory Maxwell 
@_subject: [tor-talk] blocked exit node IP because of spam 
It's this kind of thinking that will result in the web continuing to be largely
read-only for Tor users.
People running services that block Tor aren't blocking Tor because they
Hate Freedomb", or because they can't help but staying up at night
trying to come up with ways of screwing people over.
Blocking tor isn't trivial, especially to do it well... and many of
the people who have been involved with blocking tor at major
sites are themselves Tor supporters and bridge/relay operators and
only block tor when it is clear that they must.
They block write access from Tor because when an abusive user
is blocked their inevitable recourse to evade the block is Tor (if
not their first choice).  After the umpteenth occurrence of
whatever antisocial jerkwad assaulting the site via tor it simply
has to go.
Arguing that a problem doesn't exist is unconvincing to people
who are dealing with it, arguing that blocking tor is ineffective
or involves unacceptable tradeoffs is unpersuasive to people
who have made the changes and measured the results.
One of the great forces which makes online communities
viable and not all trivially destroyed by a few byzantine
troublemakers is that the cost of excluding people is low,
but when tor makes the cost of evading the exclusion
nearly zerob the balance is upset.
Even captchas are a pretty weak tool: Commercial services
will solve them for pennies each, and targeted trouble
makers aren't deterred by them at all.
Perhaps most importantly, b this has been the ongoing
approach used by the Tor community and it is demonstratively
ineffective: Write access via tor is frequently inhibited.
And yes, sure, there are cases where nym use doesn't
solve things. But there are a great many where it does.
The Tor project absolutely has done this in the past.
Though as far as I can tell it has not hat  much success except in
areas where the Tor prohibitions are sloppy (blocking read access,
blocking relays instead of just the relevant exits).
You're making a grave error to characterize the people who've
made different calls than you have as foolish or insensitive.
I'm sure it's true in some cases, but even the well informed
frequently make the dispassionate, considered, and
rational decision to block write access from Tor.
tor-talk mailing list
tor-talk at lists.torproject.org

@_date: 2012-06-22 00:13:06
@_author: Gregory Maxwell 
@_subject: [tor-talk] Forbes article: Tor and Bitcoin 
A word to the wise: Perhaps this is an earnest effort, but it's
impossible to tell.  From appearances it is indistinguishable from a
scam which will accrue a large amount of third party owned bitcoin and
either vanish or get "hacked".
Promotion on the Forbes.com site shouldn't be taken to signify any
evidence of reputability. I've seen first hand that they do not do
much research for this sort of thing, and articles there have
previously plugged services operated by people known to have stolen
from others.
Anonymity can an important tool for social good, but it can also be
misused people should take great caution in handing over control of
valuable information to parties that operate under the veil of
anonymity. Many people have been robbed under similar circumstances.
The open source Bitcoin client software runs excellently over Tor. If
you want to use Bitcoin anonymously its a good combination and you
don't need services like this website.  The next major release of the
Bitcoin software will feature much better support for inbound
connections in hidden services and automatic hidden service peer
discovery, making it work even better.
tor-talk mailing list
tor-talk at lists.torproject.org

@_date: 2012-11-08 14:01:49
@_author: Gregory Maxwell 
@_subject: [tor-talk] Reduced latency transport for TOR 
This work could be _very_ productive for future transport for TOR:
As opposed to a raw datagram transport it still gets through the
firewalls and nats that TCP/TLS does and still looks like HTTPS to
tor-talk mailing list
tor-talk at lists.torproject.org

@_date: 2013-08-06 15:39:29
@_author: Gregory Maxwell 
@_subject: [liberationtech] Tormail in trouble. Experts at Black Hat recommend Elliptic Curves: this is what PassLok 1.3 is based on. 
Wait. You are using vague popular press FUD about RSA to promote a
website hosted JS encryption tool? Really?
Your code generates random values like this:
a.clientY || a.offsetY || 0], 2, "mouse")
try {
    var s = new Uint32Array(32);
    crypto.getRandomValues(s);
    sjcl.random.addEntropy(s, 1024, "crypto['getRandomValues']")
} catch (t) {}
Meaning that if it's used someplace where crypto.getRandomValues()
doesn't exist, it has only pure snake-oil-extract randomness.
If the randomness is poor, the nonce used in ECDSA will be predictable
and the private key will be recoverable.
This isn't to say I've audited any of it, I just grepped for a couple
likely mistakes. Part of the JS code has been whitespace compressed, I
consider it unauditable.
So, not implemented in slow-as-dirt JS 200,000 iterations should take
a random desktop cpu about 100ms or so. This is hardly wopping. It's
not far from the minimum I'd start with, for all keys not just weak
ones.  Generally user provided keys are a security disaster and should
be avoided wherever it's possible, strengthening or no. Humans are
horrific entropy sources and really can't self assess how bad they
Liberationtech list is public and archives are searchable on Google. Too many emails? Unsubscribe, change to digest, or change password by emailing moderator at companys at stanford.edu or changing your settings at

@_date: 2013-07-19 09:33:45
@_author: Gregory Maxwell 
@_subject: [tor-talk] Network diversity [was: Should I warn against Tor?] 
It's _very_ hard to reason about this subject and act safely.
It is common for ISPs to use segments in their network which are
provided by third party providers, even providers who are almost
entirely facilities based will have some holes or redundancy gaps.
Because these are L1 (wave) and L2 (e.g. ethernet transport) they are
utterly invisible from the L3 topology.
You can make some guesses which are probably harmless: a guard that is
across the ocean is much more likely to take you across a compromised
path than one closer—    but going much further than that may well
decrease your security.
These concerns should be reminding us of the importance of high
latency mix networks... they're the only way to start getting any real
confidence against a global passive observer, and the are mostly a
missing item in our privacy tool toolbelt.
tor-talk mailing list
tor-talk at lists.torproject.org

@_date: 2013-07-19 13:42:03
@_author: Gregory Maxwell 
@_subject: [tor-talk] Network diversity [was: Should I warn against Tor?] 
So have low latency ones, some things fail.  Today you'd answer that
concern by running your high latency mix network over tor (or
integrated into tor) and so it cannot be worse. Answering the "you
need users first, and low latency networks are easier to get users
for" concern.
The point there remains that if you're assuming a (near) global
adversary doing timing attacks you cannot resist them effectively
using a low latency network.  Once you've taken that as your threat
model you can wax all you want about how low latency mix networks get
more users and so on.. it's irrelevant because they're really not
secure against that threat model. (Not that high latency ones are
automatically secure either— but they have a fighting chance)
On Fri, Jul 19, 2013 at 10:03 AM, Jens Lechtenboerger
Because you're lowering the entropy of the nodes you are selecting
maybe all the hosts themselves are simply NSA operated, or if not now,
they be a smaller target to compromise.  Maybe it actually turns out
that they all use a metro fiber provider in munich which is owned by
an NSA shell company.
In Germany this may not be much of a risk. But if your logic is
applied to someplace that is less of a hotbed of Tor usage it wouldn't
be too shocking if all the nodes there were run by some foreign
intelligence agency.
tor-talk mailing list
tor-talk at lists.torproject.org

@_date: 2013-09-08 06:44:57
@_author: Gregory Maxwell 
@_subject: [tor-talk] NIST approved crypto in Tor? 
Okay, I need to eat my words here.
I went to review the deterministic procedure because I wanted to see
if I could repoduce the SECP256k1 curve we use in Bitcoin. They don't
give a procedure for the Koblitz curves, but they have far less design
freedom than the non-koblitz so I thought perhaps I'd stumble into it
with the "most obvious" procedure.
The deterministic procedure basically computes SHA1 on some seed and
uses it to assign the parameters then checks the curve order, etc..
wash rinse repeat.
Then I looked at the random seed values for the P-xxxr curves. For
example, P-256r's seed is c49d360886e704936a6678e1139d26b7819f7e90.
_No_ justification is given for that value. The stated purpose of the
"veritably random" procedure "ensures that the parameters cannot be
predetermined. The parameters are therefore extremely unlikely to be
susceptible to future special-purpose attacks, and no trapdoors can
have been placed in the parameters during their generation".
Considering the stated purpose I would have expected the seed to be
some small value like ... "6F" and for all smaller values to fail the
test. Anything else would have suggested that they tested a large
number of values, and thus the parameters could embody any undisclosed
mathematical characteristic whos rareness is only bounded by how many
times they could run sha1 and test.
I now personally consider this to be smoking evidence that the
parameters are cooked. Maybe they were only cooked in ways that make
them stronger? Maybe????
SECG also makes a somewhat curious remark:
"The elliptic curve domain parameters over (primes) supplied at each
security level typically consist of examples of two different types of
parameters — one type being parameters associated with a Koblitz curve
and the other type being parameters chosen verifiably at random —
although only verifiably random parameters are supplied at export
strength and at extremely high strength."
The fact that only "verifiably random" are given for export strength
would seem to make more sense if you cynically read "verifiably
random" as backdoored to all heck. (though it could be more innocently
explained that the performance improvements of Koblitz wasn't so
important there, and/or they considered those curves weak enough to
not bother with the extra effort required to produce the Koblitz
