
@_date: 2004-04-25 15:28:49
@_author: Premise Checker 
@_subject: [>Htech] WT: FBI up for private screens 
WT: FBI up for private screens
   By Guy Taylor
   THE WASHINGTON TIMES
   Published March 26, 2004
     _________________________________________________________________
   The FBI and the Department of Homeland Security are developing a
   database that will allow private companies to submit lists of
   individuals to be screened for a connection to terrorism, the FBI
   Terrorist Screening Center Director Donna A. Bucella told legislators
   yesterday.
       The database "will eventually allow private-sector entities, such
   as operators of critical infrastructure facilities or organizers of
   large events, to submit a list of persons associated with those events
   to the U.S. government to be screened for any nexus to terrorism,"
   Miss Bucella said at a joint hearing of the House Judiciary and
   Homeland Security subcommittees.
       The screening center oversees the master database of known and
   suspected terrorists, which became operational in December. That
   database, created by the FBI and the Department of Homeland Security,
   was developed to ensure investigators, screeners and agents work off a
   unified set of antiterrorist information.
       In his opening statement for the hearing, Rep. Christopher Cox,
   California Republican and chairman of the House Select Committee on
   Homeland Security, said the screening center's support is
   "particularly important to our nation's first responders, our border
   protection officials, and the consular officers who adjudicate
   hundreds of visa applications every day."
       However, Mr. Cox also raised concerns about the need for the watch
   list not to violate the privacy of Americans. "To be the right
   solution, the TSC must not come at the price of the civil rights or
   First Amendment freedoms of American citizens," he said.
       Civil liberties groups say federal law-enforcement and
   intelligence officials are keeping the terror watch lists so secret by
   that mistakes are inevitable.
       Mrs. Bucella said a process to address "misidentification issues"
   is in place.
       "We recognize that with all of these capabilities also comes the
   responsibility to ensure that we continue to protect our civil
   liberties," she said. "Procedures are in place to review and promptly
   adjust or delete erroneous or outdated domestic terrorism
   information."
       After the deadly hijackings of September 11, 2001, the Bush
   administration attempted to stem confusion caused by the existence of
   multiple terrorist watch lists by establishing a joint FBI-CIA
   Terrorist Threat Integration Center (TTIC), consolidating more than a
   dozen previous lists, including the State Department's TIPOFF database
   of more than 110,000 known and suspected terrorists.
       In September, a few days after the two-year anniversary of the
   hijackings that killed about 3,000 people, officials announced the
   creation of the TSC to consolidate watch lists and provide
   round-the-clock operation support for federal screeners across the
   country and around the world.
       Mrs. Bucella outlined several successes since the TSC became
   operational in September, including the establishment of a
   consolidated 24-hour call center that law-enforcement authorities can
   call to determine whether an individual in question is a suspected
   terrorist.
       After a positive or negative match, "we help coordinate operation
   support as to how the person should be handled," Mrs. Bucella said.
   The system has fielded 2,000 calls since its inception.
------------------------ Yahoo! Groups Sponsor ---------------------~-->
Buy Ink Cartridges or Refill Kits for your HP, Epson, Canon or Lexmark
Printer at MyInks.com.  Free s/h on orders $50 or more to the US & Canada.

@_date: 2004-04-25 15:33:19
@_author: Premise Checker 
@_subject: [>Htech] The Courier-Mail: China launches web 'big brother' 
China launches web 'big brother'
   From correspondents in Shanghai
   CHINA has stepped control of the Internet in its largest city Shanghai
   with the installation of video surveillance equipment and software in
   public places, state press reported today.
   The directive from the Shanghai Culture, Radio, Film and TV
   Administration was designed to prevent the surfing of banned websites
   and to stop people under 16 from entering Internet bars, the Shanghai
   Daily said.
   Authorities have already installed video cameras in every Internet
   cafe in the city so officials can keep track of youngsters' movements,
   the newspaper said.
   The yet-to-be installed software will force users to input personal
   identification data to log on, while a supervisory centre will monitor
   surfing and check whether a cafe was illegally operating at night, it
   said.
   Foreigners will have to input their passport number.
   "The software, which cost seven million yuan (850,000 dollars) to
   develop, can help supervise more than 110,000 computers at the city's
   1,325 Internet bars and spot illegal activities immediately," the
   paper quoted project director Yu Wenchang as saying.
   The measures are part of a six-month campaign by municipal
   authorities, which began this month, to crackdown on Internet bars.
   Fifty-seven net bars have been punished or shut down in the city so
   far.
   There are roughly 70 million Internet users in China, putting the
   world's most populous nation second behind the United States in terms
   of people online.
   The Internet explosion is both a blessing and a curse for the Chinese
   authorities, who want people to be more tech-savvy without absorbing
   too many foreign ideas or spreading anti-government messages.
   Internet users are frequently jailed for posting articles critical of
   the government.
------------------------ Yahoo! Groups Sponsor ---------------------~-->
Buy Ink Cartridges or Refill Kits for your HP, Epson, Canon or Lexmark
Printer at MyInks.com.  Free s/h on orders $50 or more to the US & Canada.

@_date: 2004-06-24 14:37:46
@_author: Premise Checker 
@_subject: [>Htech] Infoshop News: Surveillance and Domestication 
Surveillance and Domestication
posted by [1]Anon on Monday June 21 2004 @ 03:25AM PDT
   [2]Spying and Spooks SURVEILLANCE AND DOMESTICATION
   John Connor on the rise of surveillance and our acquiescence in it
   Surveillance is sold to us on the grounds that 'the innocent have
   nothing to hide', but the reluctance of the watchers to also become
   the watched--the police will plead 'operational security' to excuse
   themselves from disclosing even the most trivial points of detail
   about themselves, such as canteen menus, etc--shows this as both a
   transparent excuse to extend surveillance way beyond the point where
   it should be socially acceptable and a disguising of what is in the
   interests of the powerful with reference to what is supposedly 'in the
   interest of all'.
   THE WORM IN ADAM'S APPLE
   By way of excusing current levels of surveillance, where there is now
   one camera / four people in UK alone, it is possible to present the
   first band societies 'where everyone knew everyone else's business' as
   the most surveilled societies of all. This totally misses the point,
   however, as people then felt they were 'everyone else's business'.
   Although individual's 'right' to 'do their own thing' in negotiation
   with the band regardless of traditional custom was highly respected,1
   there were not the firm boundaries of selfhood that characterise
   capitalism's atomised individualism, not least because personal and
   societal survival were so intimately interrelated. Part of your
   identity was your relationship to the rest of the band and you would
   not be complete without this, nor think of withholding something from
   them as you would from yourself. These were free, equal societies
   where an unevenness of knowledge, where it was hoarded to advantage
   one over another, was an entirely alien, civilised concept except
   possibly between genders and then not always. In fact, continuous
   sharing of news and skills were as much part of the fabric of daily
   life in hunter-gatherer societies as the sharing of tools (usufruct)
   and resources.
   With the rise of class society, where it became in the interests of
   the labouring majority to conceal resources and information about
   them, work rates etc ,from the non-labouring minority overseeing them,
   it equally became in the interests of the latter to try to find out
   what was being concealed from them. This, in truth, was the birth of
   the surveillance society, it's limited effectiveness still pretty much
   restricted to what could be seen directly by overseers and residual
   'group think' that led people to disclosure information they really
   wouldn't in modern, individualistic societies.
   Alvarez's Centuries of Childhood is very good in pointing this up in
   the Medieval era, when any idea of an 'internal dialogue' was the
   privilege of a literate monastic minority. Others would say what they
   thought, their expression being limited to the presence of others with
   whom it could be shared - possibly getting back to the ears of feudal
   law enforcers and tax collectors. The most radical significance of the
   book in terms of shaping the human psyche was that it allowed private
   thoughts and expression in 'dialogue' (for surely the relationship is
   not mutual in the way conversation is) with the page. The first
   diaries--typically records of spiritual exercises by cloistered
   divines--are thus Medieval.
   The self-enclosure facilitated by writing led, of ruling class
   necessity, to the elaboration of more sophisticated techniques of
   surveillance - the spy networks engendered by Elizabeth I's courtier
   Sir Francis Walsingham, for example, still celebrated as original in
   Establishment spook circles today. They would solicit disloyal comment
   through infiltration techniques, pretending to be who they were not to
   suspects, as well as incidentally engaging pretty comprehensively in
   mail interception and attempting to crack counter-measures such as
   concealment and cipher. They were still largely dependant on the word,
   however, often words procured by duress (torture) and
   misrepresentation (forgery or 'over-reading' of intercepted
   correspondence). Of course, this was also the era of the witch hunts
   with their 'spectral evidence' (the testimony of 'victims of
   witchcraft'), but this dependence reached its apex in the reign of
   Charles II and the baseless conspiricising of the Protestant fanatic
   Titus Oates and his 'Popish Plot'. Simply on the basis of tortured
   'confession' and guilt by association, an anti-Catholic pogrom was
   whipped up, though its only true substance was Oate's own paranoid
   fantasy.
   THE ALL-SEEING EYE
   This sort of thing may have been adequate as an instrument of terror
   befitting the majesty of absolute kings, but increased rationalism and
   individualism associated with the ascendance of Protestantism, with
   its claims of the believer's unmediated relationship with the Divine,
   meant consequent increased demands for physical evidence as a break on
   the arbitrary power of courts (both kingly and judicial), especially
   in matters concerning the 'sanctity' of private property.
   Paradoxically, as well as demanding more explicit legislative
   regulation, the bourgeoisie's pet religion also demanded greater
   self-regulation, the self now being bounded by contract- and financial
   relationships rather than intimate, social relationships. Thus we have
   the commonplace appearence2 of the divine 'all-seeing eye', as seen
   miserably decorating Protestant homes and chapels to this day, as well
   as topping the Masonic pyramid Washington and Jefferson incorporated
   into the design of every dollar bill. This idea of 'the Lord sees all'
   meant that even the individualistic Protestant clung on to the vestige
   of community, of public being,, in the sense of being in a community
   of two, s/he and the ever-watchful God, even if real
   community--typically more reciprocal, less judgmental of 'sin' and
   'slackness'--was sacrificed to such an unremitting moralistic code in
   consequence.. As well as insisting that the worshipper be hard-working
   and thrifty, the Protestant faith self-imposed harsh standards of
   personal behaviour when it came to the body and bodily interaction
   with others. As Norbert Elias classic study of the rise of 'good
   manners', The Civilising Process, graphically documents, food became
   problematic, no longer to be indulged in gluttonously or passed from
   mouth to mouth but rather, like sexual or excretory functions, to be
   seen as a shameful concession to physicality to be controlled and
   bounded by taboos, best a private thing the better to avoid public
   shame. Such etiquette was literally domesticating, confined to the
   home, and homes too became more elaborate, with particular concessions
   to the body confined to particular rooms - a dining room for eating, a
   toilet for excretion (the corners of rooms having previously been
   preferred, even at Louis XIV's Versailles!), and the bedroom for sex
   behind curtained, canopied beds. The point of all this specialised
   architecture--of privacy--was that as few people saw it as possible.
   And so lose respect for someone shamefully indulging their body, as if
   we all don't It was mainly something between a wo/man and the
   all-seeing Lord.
   SEEING BY NUMBERS
   A combination of capital accumulation secured by resultant fixed,
   abstract laws and 18th century innovations in food production and
   transportation made the mega-cities that characterised the Industrial
   Revolution possible. This, then, was when surveillance came of age. On
   one level, faced with cities inhabited by millions, many born and
   raised undocumented or newly immigrated from the countryside and
   forming tight village / ghetto communities closed to casual
   investigation by outsiders, it was impossible to surveil them using
   the old techniques of gossip gathering On the other hand, this
   redoubled the need for self-surveillance as a curb on the spontaneous,
   riotous street mob behaviour of previous centuries as the only
   practical guarantor of social order.
   On a general level, the inculcation of a self-denying moral code into
   the poor was the responsibility of charismatic Methodism--as in the
   ruling class dilemma of the early-1800s, 'Wesleyism or
   revolution?'--and later 'do-gooders' dispensing unwanted advice about
   thrift, temperance and other supposedly good domestic practice. For
   those who wouldn't accept social inequality as a problem to be
   resolved by behaviour adjustment on their part, there was the hero of
   bourgeois rational social calculation, Jeremy Bentham, and his
   panoptican, a prisonhouse designed to do this architecurally.3 It's
   two key features were (1) individual cells, a rule of silence and the
   hooding of inmates outside their cells to enforce complete isolation
   from their community and force them to fall back on the Protestant
   'God and I' 'community' instead and (2) a central tower from which
   guards could watch each cell unobserved, much like the Protestant God.
   Whether actually watched or not, the prisoner had to assume the worst
   for fear of harsher punishment, also inculcating a feeling of
   permanent surveillance and thus self-regulation. Needless to say, in
   practice this brutal, unnatural treatment amounted to sensory
   deprivation and whilst it made some suggestible enough to be
   effectively brainwashed, it broke others entirely, yielding horrifying
   hallucinations and self-harm. As recidivists could expect many more
   years in such a system than first offenders, there was naturally an
   attempt to evade such treatment by increased anonymity and
   impersonation of identities amongst the urban poor.
   Of course, Michel Foucalt dealt with this extensively in his
   Discipline and Punish, but it is often forgotten that the first
   concern of the new generation of surveillants was not to control crime
   but rather to contain disease, a much more widespread and deadly
   threat to the rich living in close geographic proximity to the poor.
   High walls, sturdy footmen in livery and a mastiff would no way keep
   cholera from their doors, so we find as early as the 1830s the first
   epidemiologists descending into the unplumbed depths of 'darkest
   London' o identify sources of disease and its carriers. This was
   rightly seen as social control being imposed on areas that typically
   rioted before admitting even one of Robert Peel's newly-minted 'blue
   devils' (police). The proletariat typically refused to acknowledge the
   reality of epidemic crowd diseases such as cholera (uniquely deadly in
   the early megalopolises and once a key check on their development) and
   to destroy cholera carts intruding into their space as a conspiracy to
   confine the poor to 'houses of death' (as they reckoned hospitals, not
   without justification) for the sadistic amusement of surgeons, during
   and after life.4 And, of course, the poor only had to look to the
   panoptican to see with what degree of humanity they would be treated
   by the new impersonal total institutions we seem so disturbingly
   accepting of today.
   A combination of a bureaucracy not sophisticated enough for individual
   documentation of entire populations before that developed out of
   regimented military practice during the American Civil War, and
   widespread illiteracy and resistance by its intended target population
   meant that the issuing of identification documents to the poor for
   voluntary presentation was not practical. In fact, it was so
   impractical that the threat of epidemic disease wasn't resolved by way
   of identifying and confining individual carriers (typically bourgeois
   moralistic 'blaming the victim') but rather by anonymous sanitation
   measures such as the building of London's sewers in reaction to the
   'Great Stink' of the 1850s, even though the idea of the state assuming
   responsibility for such massive, tax-eating public works would have
   previously been anathema to bourgeois sensibilities.
   The breakthrough came in Paris as late as 1870 when a Surete clerk
   Alphonse Bertillon developed biometrics from a 14th century Chinese
   model. Bertillonage considered of individually identifying anonymous
   individuals by a 20 minute examination when many key features of their
   body--their height, the length of their limbs, the spacing of their
   facial features--were systematically measured and then recorded to
   card indexes. Potential recidivists were typically uncooperative
   during these examinations, later (1903) augmented by 'mug shots', so
   called by the subject 'mugging' (pulling faces) at the camera in an
   (often amusingly successful) effort to make themselves less
   identifiable in future. It should be noted that Bertillon was heavily
   influenced by the imperial anthropology of its day, with its emphasis
   on the physical classification of 'types'. Like the absurd Italian
   criminologist Lombroso, he attributed mental and moral characteristics
   to these physical signs, typically in a classist and racist manner
   than only served to reinforce such ideologies in future.
   Bertillonage finally failed and fell out of police use not because it
   was racist or unwieldy or even because it was felt to be an excessive
   intrusion on individual privacy ('sir, my statistics are my own') but
   rather because it couldn't do it's job. In 1903, a man called Will
   West was confined to Leavenworth jail for murder on the basis of
   biometric measurements actually appropriate to another man,
   coincidentally also called William West, despite a supposed
   243m-to-one chance against this happening (not counting any slips of
   the police tape measure!). Besides, by then they had something quicker
   to collect and easier to file, which didn't require the perp's
   physical presence to identify him. It is probably no surprise that
   fingerprinting arose from a colonial context, that other great
   'submerged mass' that caused the Victorian elite such worry. A chief
   magistrate in Jigupoot, Sir William Herschel first noticed in 1856
   that Indians either illiterate or otherwise unfamiliar with English
   script signed themselves with thumb prints instead of writing, an
   administrative procedure for unique identification he adopted himself.
   From there, it was a short step to Darwin's pal Sir Francis Galton
   writing this up in the scientific journal Nature and a former supremo
   of Bombay's colonial police, Richard Henry introducing fingerprinting
   to Scotland Yard's repertoire of crime detection procedures in 1896.
   LEARNING TO LOVE BIG BROTHER
   Although the state had a technique for distinguishing one anonymous
   individual from another with unerring accuracy,5 this was fairly
   useless if that individual could disappear into the anonymous urban
   mass. As former Resistance fighter Jacques Ellul noted in his
   Technological Society, an immediate consequence of seeking to surveil
   particular individuals is that the whole society in which they might
   conceal themselves has to be surveilled also, the 'innocent' majority
   as intensively as the 'guilty' few.
   Perhaps more surprisingly, by the time fingerprinting was initiated,
   the resolute resistance to classification of the early-19th century
   was crumbling. There were a number for factors accounting for this,
   but key was the inducements offered the majority not to remain
   anonymous. Mass education on a monitor system--much like that adopted
   by Napoleon's Grand Armee, the basis of Bentham's panoptican--not only
   provided a more literate, technically sophisticated workshop with a
   greater chance of individual socio-economic betterment, it also meant
   the young came to accept such treatment as normal--both classification
   by name and number and harsh restrictions on personal behaviour in
   class ('no talking, no fidgeting')--and could be systematically
   documented, generation by generation. This was augmented by the
   centralisation of registers of births, deaths and marriages in places
   like Somerset House instead of scattered through disparate parishes,
   the taking of censuses to facilitate national planning,, and the
   creation of employment-based taxation which meant both bosses and
   workers (unless inclined to fraud) had to declare their identities
   along with their earnings if they were to make a living at all. Even
   systematic mapping, such as carried out initially for military reasons
   by the Ordnance Survey, meant that space in which people could exist
   anonymously evaporated ('everyone in their place'). This process was
   only accelerated by the Liberal welfare reforms of the early-1910s and
   the post-World War 2 creation of the welfare state, both of which had
   disclosure of identity as prerequisite requirements of receiving their
   services. It was a citizen's 'right' (the 'carrot') and 'duty (the
   legislatively-enforced 'stick') to enter into all this, without
   realising that my surrendering their anonymity to the state, they were
   also surrounding a key check on its otherwise unlimited power.
   I could rehearse at great length the elaboration of technological
   means that now exist to strip us of any possibility of anonymity, but
   this is done elsewhere this issue and besides, there is always Privacy
   International to consult. I will note that when a text like The
   Technology of Political Control was written in the supposedly paranoid
   1970s, the suggestion that a comprehensive database could be linked
   with face recognition programmes and cameras blanketing every public
   space in the country was regarded as pure science fiction, something
   out of George Orwell's dystopian 1984. But today this is, of course, a
   reality and augmented by overgrown police and internal security
   agencies, parallel services like social workers and market researchers
   that want to know everything from the value of your home through to
   your children's eating and TV watching habits the better to predict
   and manipulate you, easily surveilled e-communications (ECHELON) and
   card transactions, 'predictive' databases and profiling,, and any
   other amount of technical intelligence. No - the point of this section
   is to explore why people have come to accept that quarter of a century
   ago would've been thought totalitarian ('like Russia') and
   nightmarish.
   We've already had the homo Economicus version above - that people
   gained in terms of access to education, employment and healthcare by
   bringing themselves to the attention of the state and lost in terms of
   prosecution if they failed to do so. However, I think there is more to
   it than this. A phenomenon like mass observation in the inter-War
   years was popularly and eagerly supported in its detailed
   documentation of everyday life - and what do you make of the dating
   rituals in Chile where, after years of state-orchestrated surveillance
   to the nastiest of ends, courting couples now trail each other round
   with video cameras, 'romantically' building files on each other?
   The point is that with all the mass institutions that came out of
   Bentham's panoptican, the traditional role of the community in
   providing education, employment and neighbourly care has been replaced
   by these. Community has been replaced by institutionalised
   specialisation and so people feel it only natural that such
   specialists look out for them now there is no meaningful community to.
   They have been given no reason to get to know other people and so have
   no reason to trust them. Far from it - as society atomised, anyone can
   be a criminal under the rubric of surveillance and lacking any social
   feeling except fear of punishment under the eye of the camera only
   encourages selfish behaviour. Of course, the cameras are sold on the
   grounds not that we are the criminals, but that they are there to
   protect us from everyone else who potentially is. The old Wesleyans
   were right that give someone a penny in their pocket and the slightest
   whiff of a chance of advancement and they'll see everyone else around
   them as a threat to that, either as potential thieves or as
   temptations to be repudiated with the zeal of the tempted.
   'Terrorists' are currently flavour of the month threat. Before that it
   was 'paedophiles', meaning kids had to be microchipped and cameras
   installed in every family home while a generation of kids turned into
   scared, whiny couch potatoes alongside their parents. Not many years
   ago it was witches, for fucksakes, absurd social workers seeing
   cracking the local coven of 'satanic abusers' as their next step up
   the career ladder. If this doesn't convince you what nonsense it all
   is, it's agreed that now surveillance is so ubiquitous it can't
   displace crime anywhere else (itself surely an exercise in imposed
   policing), it's not actually reducing crime rates. Offences of
   violence people fear most--irrationally, as they're still rare--are
   committed spontaneously by people too drunk or angry to be deterred by
   a camera or too cunning to get filmed by one.
   Why do people still welcome surveillance despite this? Well, the
   reliance on experts and definition of ourselves that comes through
   identification with their institutions and their representations of
   us--qualifications, income, birth and marriage certificates,
   conformity to consumer trends, and all the rest of that inane kit and
   caboodle--continually serves to emphasise our insignificance, an eight
   digit number in their overwhelming megamachine. It is this that leads
   people to love Big Brother, essentially a show where we pass
   tabloid-like judgement on intensively surveilled wannabe nonentities
   undergoing months of sexual frustration in the hope of getting to be
   childrens' TV presenters at the end, Endemol's even more sinister
   Shattered where people were subjected to voluntary sleep deprivation
   in the manner of victims of Stalin's Cheka, and even lower on the
   totem pole, searching for themselves in crowd shots (be it big
   sporting events, pseudo-archaic spectacles typically orchestrated by
   the royals, or futile 'crawl round London' marches) or 5 second slots
   on clip shows using RL footage the police or whoever have cobbled
   together as an extra earner.
   ONE IN THE ELECTRONIC EYE!
   How do we put an end to the reign of surveillance - assuming you don't
   want to lead over-controlled lives like shadows until you die of
   boredom and insignificance, that is?
   Well, firstly don't take advice from me and start thinking for
   yourself, but a few suggestions include:
   * First realising that there is not a quip pro quo between you and
   those surveilling you, that they are not accountable to you, that they
   have no right to do to you what they would not tolerate done to
   themselves, and potentially these voyeuristic parasites have the power
   to make quite a mess of your life from as little motivation as
   boredom-induced whim. They are the enemies of a free society, not its
   guarantors, a further concentration of state power that prevents any
   injustice being righted.
   * Unplugging yourself from all the BS images surrounding you--the
   clowns in the Big Brother house, the endlessly banal biogs of the
   lives of the rich and famous, the five day fashions, all that
   irrelevant crap--and learning to laugh at them and (with consequent
   increased self-confidence) yourself and your past folly
   * Unplugging others through irreverent satire and sheer indifference
   to the manufactured dreams they undoubtedly hold so dear. You'll
   probably start with the people you know best (typically a tiny number
   now people have careers, not friends) but best try to broaden it out a
   bit more than that, as a key factor for sustaining a surveillance
   society is intolerance and fear of anyone at all different. The new /
   old you will have better things to do and talk about, maybe even the
   recreation of authentic, trusting human connections without constant
   manufactured electronic babble and distraction, of baseless paranoia.
   * Disconnection and direct action of a more 'hands on' kind, a refusal
   to fill in tax returns and other official or quasi-official requests
   for information--the census, market research, card applications--.or
   responding to them in absurd, misleading ways to gradually fill their
   databases with (even more) useless shit. Believe me - when up against
   it, you'll find it's really possible to live without that credit card
   and all the form-filling bureaucratic BS, especially with a few mates
   on board with you too. Reformists please note: denying paperwotk and
   opportunities to surveil the public cuts the lifeblood of the dozens
   of agencies that exist principly for that purpose, so they can start
   being laid off as irrelevant too. And the campaign against speed
   cameras is way to go for all intrusive surveillance and related
   records, the creation of genuine unmonitored space (at risk of
   sounding bogus: 'liberated zones') and the return of the lawless,
   deprogrammed 18th century King Mob!
   In conclusion, I'd like to say that I am not arguing for 'privacy', a
   thoroughly bourgeois concept based on self-disgust and shame. No, let
   yourself go and do what comes naturally - fuck in the streets, I say!
   I am arguing for the revolutionary re-creation of original, genuine
   community where there are no secrets, no shame and no surveillance of
   the powerful as a tool to rule over the powerless.
   NOTES
   1 In his Human Cycle (Touchstone, 1983), Colin Turnbull cites a Mbutu
   (Pygmy) lad taking a nanny goat as his 'wife', something his band
   members discourage not with the horror of taboos against inter-species
   sex being violated you might expect in this society (they have none,
   though the situation was unusual) but because, as a domesticated
   village animal, the she-goat could not be expected to cope adequately
   in their beloved forest. The Mbutu typically extend refusal of the
   distinction between self and other to that between human and other. 2
   It had its origins in the early individualism of monasticism, of
   course. We have not missed the irony that though denouncing 'monkery',
   Protestants bought monastic practice outside its traditional confines,
   universalising its body-loathing codes of behaviour. 3 The first such
   panoptican was HMP Pentonville, London, where I was myself confined in
   1988. 3 Ruth Richardson's Death, Dissection and the Destitute
   (Routledge & Kegan Paul, 1987) is excellent on this. See also my
   forthcoming essay, 'When Doctors Were Hated'. 5 In fact they did not.
   As with Bertillonage, there is an outside statistical chance of
   accidental correlation of fingerprints from otherwise dissimilar
   individuals--and there have been documented miscarriages of 'justice'
   arising from this--and twins always have identical fingerprints. As de
   facto clones, even DNA doesn't distinguish twins, only retinal scans
   as the pattern of blood vessels at the back of the eye develops
   post-natum.
   The latest issue of Green Anarchist (UK)  is out now. Availble
   for  from BCM 1715, London, WC1N 3XX. Or in the US from Black and
   Green distribution, P.O. Box 835, Greensburg, PA 15601, USA.
   This issues core focusses on Surveillance and the Big Brother society.
   1.
 at terra
   2. -----BEGIN TRANSHUMANTECH SIGNATURE-----
Post message: transhumantech at yahoogroups.com
Subscribe:    transhumantech-subscribe at yahoogroups.com
Unsubscribe:  transhumantech-unsubscribe at yahoogroups.com
List owner:   transhumantech-owner at yahoogroups.com
List home:    -----END TRANSHUMANTECH SIGNATURE-----
Yahoo! Groups Links
<*> To visit your group on the web, go to:
     <*> To unsubscribe from this group, send an email to:
     transhumantech-unsubscribe at yahoogroups.com
<*> Your use of Yahoo! Groups is subject to:
     Eugen* Leitl leitl
ICBM: 48.07078, 11.61144            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
         [demime 1.01d removed an attachment of type application/pgp-signature]

@_date: 2005-12-04 20:43:36
@_author: Premise Checker 
@_subject: [>Htech] CHE: Show Your Hand, Not Your ID 
Show Your Hand, Not Your ID
The Chronicle of Higher Education, 5.12.2
[Colloquy transcript appended.]
[Yes, I can see the advantages of using these scanners, and I think the
concerns over theft and privacy issues are reasonably countered. But the
real problem is that, in making such identifications mandatory, the
informal and generally harmless violations of rules are no longer
possible. Suppose a researcher wants to sneak a friend into his lab after
hours. This, and many, many other technical violations will no longer be
allowed. We must be ever vigilant about this kind of "unreasonableness of
reason," to almost coin a meme. There is a single hit on Google! I lack a
better term.]
    Colleges use biometric scanners to screen for access to dining halls,
    labs, dorms, gyms, and computer networks
    By VINCENT KIERNAN
    At many colleges, students flash a photo ID at a food-service worker
    to get into a dining hall. Things work differently at the University
    of Georgia, where Gavin Beck, a senior, places his hand on a sensor
    that determines if the person waiting to eat really is Gavin Beck.
    The process, which measures the size and shape of the hand, takes only
    a few seconds. "No system is foolproof, but this is far more efficient
    for us than a photo-based system," says J. Michael Floyd, director of
    food services at Georgia. The university is among the first to use the
    biometric technology widely, having relied on it in one form or
    another in its dining halls since 1974.
    Hand scanners, electronic fingerprint readers, even retina scanners
    are not just for super-spies in Hollywood movies anymore. The
    technology is increasingly being used by colleges to allow students,
    professors, and staff members to gain access to dining halls,
    laboratories, gyms, and other facilities on their campuses.
    Improvements in the technology are spurring greater interest among
    some college administrators.
    Faculty and staff members who seek weekend access to the Biodesign
    Institute at Arizona State University, for example, must be approved
    by a device that checks 240 points in the iris of the eye.
    Locks on dormitory doors at Johnson & Wales University at Denver are
    controlled by a hand-geometry reader similar to Georgia's.
    Food-service workers at Georgia punch in and out of their shifts with
    a time clock that scans their fingerprints so that a worker cannot
    clock in for an absent friend.
    Proponents say biometric technology offers increased security and
    efficiency, making lines move faster while keeping unauthorized
    visitors out. And at a time when colleges are trying to safeguard
    campus data, the technology offers colleges a new tool to control
    access to computers and networks.
    But cost and various technical obstacles are likely to slow the
    technology's adoption by colleges. And some observers worry that the
    systems could leave an electronic paper trail -- open to abuse or
    theft -- of the activities of students and faculty and staff members.
    "It's an extremely disturbing trend," says Lee Tien, a senior staff
    lawyer at the Electronic Frontier Foundation, a group that promotes
    online civil liberties. "Biometrics is a technology that is dangerous
    for privacy."
    How It Works
    Administrators who support the use of biometric technology say
    scanning body parts is far more secure than asking users for
    passwords, which can be forgotten or stolen. The scanning devices look
    for some unique characteristic of the user, such as the arrangement of
    ridges on the finger, the pattern of blood vessels in the eye, or the
    size and shape of the hand. The characteristic -- called a biometric
    measurement -- must be unique for each individual, must not change,
    and must be easily measured.
    Typically a person's hand, fingerprint, or eyeball is measured once
    when he or she is enrolled in the system, and that measurement is
    stored in a computer database or on a smart ID card. At the entrance
    to a controlled area, such as a dining hall, the individual's
    characteristic is measured again and compared with the original
    recording. If the two measurements match, the person is admitted.
    Georgia's early system recorded two-dimensional measurements of users'
    hands. But in 1995, as part of a campuswide move toward biometric
    identification, the system was upgraded to one that takes
    three-dimensional measurements. Now the 32,500 students use their
    hands as passports to all-you-can-eat meal plans, the recreation
    center, and dormitories. They either swipe an ID card through a card
    reader or enter an ID number on a keypad before presenting their hand
    for scanning.
    Mr. Floyd, the food-service director, says the system rarely
    misidentifies anyone. Mr. Beck, the Georgia senior, recalls only one
    glitch, when the system wouldn't recognize him at the start of fall
    semester, probably because of a subtle change in his hand's shape over
    the summer. At a nearby office, he showed his ID, had his hand
    rescanned, and was cleared to eat his meal. "It set me back a couple
    of minutes," he says, "but it was no big deal."
    The University of New Hampshire installed a hand-reading system in its
    dining halls when campus officials wanted to halt the sharing of
    all-you-can-eat meal plans by several people, says David J. May,
    executive director of hospitality services.
    "It really has worked wonderfully for us," he says. Although he cannot
    estimate the amount of fraud that the system has stopped, he is
    convinced that "students would beat the system if we were using ID
    cards."
    The cost of putting biometric security in place is not exorbitant,
    says Mr. May. Each hand reader costs about $2,500, and the turnstile
    to which it is connected costs $8,500 to $9,000. The 12,000-student
    university has seven biometric stations at its dining halls, he says.
    Recently, New Hampshire expanded the system to control employees'
    access to one of its dining halls. That way the university will not
    have to issue keys to employees -- or replace locks if keys are
    stolen. "If an employee leaves, we just take them out of the
    database," so the hand-reading system will no longer recognize that
    person, says Mr. May.
    Smaller-Scale Projects
    Biometric systems are also being used on a smaller scale on some
    campuses. At Rutgers University at New Brunswick, fingerprint-scanning
    devices are being installed on computers attached to laboratory
    equipment in the materials-science department.
    The department, with some 80 potential users of the technology, has a
    password system to track usage of the equipment, so that the
    appropriate research grant is charged. But some students complained
    that they were being charged for others' use, says W. Roger Cannon, a
    professor of materials science and engineering.
    That prompted him to investigate a biometric alternative. "If we had a
    fingerprint system, there would be no argument," he says.
    The new system has functioned well in tests, Mr. Cannon says. "It
    seems to go pretty smoothly if you get the fingerprint centered
    right." Those with concerns about personal privacy can elect to
    continue using passwords, he adds.
    The University of California at Santa Barbara recently installed an
    iris-scanning system for controlling access by about 500 people to a
    10,000-square-foot "clean room" in a semiconductor-research center.
    In the past, having those people swipe their ID cards at the door
    would result in more work for staff members, who would have to replace
    lost or broken cards, says Jack Whaley, manager of the Nanofabrication
    Facility. Moreover, the card readers were sometimes balky, he says,
    and nothing prevented people from lending their cards to others.
    In the new system, an individual's eyes are photographed, and the
    images are digitized, encrypted, and stored on a computer server with
    information about what doors the individual is authorized to use and
    at what times. Researchers who want to get in simply step up to an
    iris reader, which transmits an image of the iris to the server. If
    the images match, the computer opens the door.
    Some challenges remain, like reminding people who have "droopy
    eyelids" to open their eyes wide, says Mr. Whaley. But the system,
    which cost between $20,000 and $30,000, has made a negligible number
    of errors. "It's pretty good," he says.
    More-exotic technology is on the horizon. Fujitsu Ltd. announced in
    June that the Chiba Institute of Technology, in Japan, has adopted a
    company device that uses infrared light to read the unique pattern of
    veins in a student's hand. The patterns are recorded on each
    individual's ID card. At kiosks on the campus, students can get access
    to their academic transcripts and other personal records by inserting
    the cards and holding their hand over a palm reader.
    Next year the institute, which has about 11,000 students, plans to
    issue similar cards to faculty and staff members. It is considering
    expanding the system for such purposes as tracking library checkouts
    and class attendance.
    Joel Hagberg, vice president for marketing and business development at
    Fujitsu Computer Products of America, says the company is discussing
    use of the technology with American colleges, which he does not
    identify. The system could start surfacing on American campuses early
    next year, he says. The vein scanner costs more than a fingerprint
    reader, which can run as much as $100, but less than an iris reader,
    he says, although he declines to provide specific figures.
    The technology will probably materialize first at a large research
    institution, most likely as part of a centralized service such as
    controlling college officials' access to student records, Mr. Hagberg
    predicts, noting that such an application would require only a few
    palm readers.
    "This is something that you will see coming to a university near you
    in the near future," he says.
    Privacy Concerns
    For all the efficiency and gee-whiz value of biometric technology,
    civil libertarians say it raises serious concerns about privacy. The
    theft or abuse of biometric measurements could be even more
    threatening than misuse of Social Security numbers, warns Mr. Tien, of
    the Electronic Frontier Foundation.
    Campus officials using fingerprint readers stress that their systems
    do not record individuals' fingerprints in images like those used by
    law-enforcement agencies. Rather, the systems produce a mathematical
    representation of fingerprints that would be useless to anyone outside
    the colleges.
    Hand-geometry systems seem to cause the least apprehension because
    such measurements are not commonly used off campus and so would have
    little or no application if the biometric data were to leak out. "The
    only person it does any good is me," says Mr. Beck, the Georgia
    student.
    Keene State College, in New Hampshire, moved to a hand-reader system
    this semester. Paul A. Striffolino, director of campus life, says the
    system does not intrude on the privacy of the college's 5,000
    students. "An eye-scanning system would seem over the top to me," he
    says.
    But some observers say even hand-geometry data could be misused. If
    hand readers become commonplace, authorities could use records from
    the systems to reconstruct a student's movements and activities on the
    campus or across a broader area, says Mr. Tien.
    "It facilitates an atmosphere or a climate of checkpoints," he says.
    "All it is, is maybe a faster way to get through a door. We have to
    wonder whether these are the right trade-offs to be making."
    Indeed, records of a student's biometric measurements, as well as
    records of where and when that student used a biometric device,
    probably would be protected from public disclosure under the Family
    Educational Rights and Privacy Act, says Steven McDonald, general
    counsel at the Rhode Island School of Design, who tracks the effect of
    the federal law on the use of technology on campuses.
    In most cases, he says, Ferpa would not allow a college to disclose,
    without a student's permission, where and when that student had
    entered a dining hall, for example. But the records could still be
    used by the college's own staff and might be vulnerable to subpoena by
    law-enforcement officials, he says.
    Nancy Tribbensee, deputy general counsel at Arizona State, says a
    college should acknowledge privacy concerns before settling on
    biometric technology. She suggests that college officials consider
    whether the benefits, like tighter security, would be outweighed by
    ways in which the data could be abused.
    Recordings from the iris scanner at the university's Biodesign
    Institute are not covered by Ferpa, Ms. Tribbensee notes, because the
    system is used by faculty and staff members. But the university treats
    the data as personnel records and therefore as confidential, and it
    would fight any effort to obtain copies through the state's
    public-records law, she says.
    High Price Tag
    Privacy is not the only concern about biometric security systems. Some
    users also worry about safety -- for example, whether touching a hand
    reader could expose someone to colds and the flu from previous users.
    Mr. May, of New Hampshire, says the device is "no different than a
    doorknob." Still, liquid hand sanitizer is available at each hand
    reader, in a dispenser attached to the wall, and a staff member wipes
    the readers with a sanitizing solution every 15 minutes.
    Another hurdle facing biometric systems is cost. Last year Creighton
    University considered using fingerprint readers to control access to
    the 1,500 to 2,000 computers in its laboratories and offices. At $90
    to $100 a pop, Creighton would have had to spend as much as $200,000
    on the devices -- and that wouldn't have included the cost of
    upgrading the machines as technology advanced. "That would have been a
    huge expense," says Michael M. Allington, assistant director of
    student-technology support in the information-technology department.
    Creighton took a pass.
    Still, industry officials argue that biometric systems make financial
    sense for colleges, at least in some situations. The staff and systems
    needed to maintain a list of passwords for security systems might cost
    a college $50 per student annually, says Tom Doggett, director of
    marketing for Saflink Corporation, which makes a variety of biometric
    systems. By contrast, he says, a large college might spend $30 to $40
    per student to deploy a biometric system.
    "You could make the case that the system would pay for itself in a
    year," Mr. Doggett says.
    But James L. Wayman, director of the National Biometric Test Center at
    San Jose State University, which explores technical issues related to
    the technology, is less optimistic.
    It is unclear, he says, whether dining halls are losing enough money
    from fraud to warrant the expense of a biometric system. "Will it
    pay?" he asks. "That's where it all falls apart."
    "Tell me again," he says, "why you need them on college campuses."
    Biometric systems can also have technical problems, which have prodded
    a few colleges to back away from the technology.
    Recently the New York State Center for Engineering Design and
    Industrial Innovation, at the State University of New York at Buffalo,
    encountered problems with a fingerprint-scanning system used to
    control access to its facilities. The readers worked well in 2000,
    when they were installed inside the building, says Kenneth W. English,
    deputy director. But the design center is planning an expansion that
    would require placing the access controls on the building's exterior,
    and the fingerprint readers worked poorly there because of snow and
    ice. So the center is reverting to having users swipe ID cards through
    a card reader.
    Mr. English hopes that improvements in biometric technology will allow
    the center to move back to fingerprint readers in the next two or
    three years.
    'Weak Fingerprints'
    When Creighton considered fingerprint readers, it tested several
    models. But the machines had a hard time recognizing faculty members
    in the dental school, recalls Mr. Allington. They seemed to have
    less-visible fingerprints, probably because of the frequency with
    which they washed their hands, he says.
    A similar problem surfaced in Georgia's food-service department, where
    600 employees use a fingerprint system to sign in and out of work.
    About 10 of them, whose work often keeps their hands submerged in
    water, have "weak fingerprints" and so cannot use the biometric
    system, says Christopher H. Wilkins, an information-technology manager
    in the university's food-service division. They still clock in and out
    by swiping an ID card or entering an ID number.
      _________________________________________________________________
Colloquy Transcript
Throwing Away the Keys
    Thursday, December 1, at 2 p.m., U.S. Eastern time
    The topic
    Forget keys and photo ID's. Students trying to get into dormitories at
    Johnson & Wales University in Denver must have their hands measured by
    an electronic scanner. Food-service workers at the University of
    Georgia punch in and out of their shifts with a time clock that scans
    their fingerprints. And faculty and staff members seeking weekend
    access to the Biodesign Institute at Arizona State University must be
    approved by a device that checks 240 points in the iris of the eye.
    More and more colleges are using such biometric technology, which its
    fans say is more secure and efficient than traditional tools. The
    technology also offers a new way to control access to campus computers
    and networks. But biometric systems can have technical problems, and
    they are expensive to install. And some observers worry that the
    systems could leave an electronic trail -- open to abuse or theft --
    of employees' and students' activities.
    Are the advantages of biometric technology worth its high cost? Do
    they outweigh its potential misuses? Are biometric records protected
    from public disclosure under the Family Educational Rights and Privacy
    Act, or do colleges need to take extra steps to protect such data?
    The guest
    J. Michael Floyd is director of food services at the University of
    Georgia, which has used biometric technology in one form or another in
    its dining halls since 1974.
      _________________________________________________________________
                      A transcript of the chat follows.
      _________________________________________________________________
    Vincent Kiernan (Moderator):
        Good afternoon, and welcome to Colloquy. I'm Vincent Kiernan, a
    senior writer at The Chronicle, and I will be moderating today's
    discussion about the use of biometrics in higher education.
    Our guest is J. Michael Floyd, director of food services at the
    University of Georgia. His institution is a pioneer in the use of
    biometrics -- Georgia has used hand readers in its dining halls since
    the 1970s.
    Just a quick reminder to everyone out there in cyberspace: Send in
    your questions and comments!
    Now, welcome, Mike. Could you start by giving us a thumbnail sketch of
    what your institution does in this area?
      _________________________________________________________________
    J. Michael Floyd:
        The University of Georgia Food Services has utilized biometric
    technology since 1972 for access control for its voluntary meal plan
    program that allows unlimited access for its customers from 7 am to
    midnight daily. The department is presently on its third generation of
    hand image readers and has recently implemented a biometric
    timekeeping system for its 700 employees. The department has chosen
    biometric technology for its access control to prevent sharing of meal
    plans by customers, reduce labor cost for access control, and to
    increase speed of entry for its customers. The average customer gains
    access into our dining commons within a 3-5 second time period with
    the use of biometric technology. Presently 33,000 students here at the
    University utilize this technology for access for dining commmons,
    residence halls and campus recreation facilities.
      _________________________________________________________________
    Vincent Kiernan (Moderator):
        Now onto our questions...
      _________________________________________________________________
    Question from Terri Moreman, U.S. Olympic Training Center:
        Terri Moreman
    U.S. Olympic Training Center
    Colorado Springs, Colorado
    Advantages to Biometrics
    Easy to maintain and archive guest access (various reports available
    with the ability to customize)
    Quicker smother entry - especially when most students dont want to
    carry I.D. card.
    Cheaper and easier then re-keying access doors
    Less chance of misuse
    Card access is even higher however; here again the student would need
    to carry the card at all times. Without the card they have no access.
    Disadvantage
    Dont go with new technology out the start gate. Seek out a proven
    product in the marketplace.
    Initial equipment set-up is high however in the long run it pays for
    itself
    Hand geometry readers cost an average of $3,000 per location
    Certified technicians trained in this specialty are required to
    maintain, trouble shoot and make repairs. Generally speaking an
    electrician or layman may understand the electrical components;
    however he would lack the necessary knowledge to function in this
    capacity.
    The challenge is that technology changes and if you maintain a system
    too long its hard to find parts it. Routine upgrades in software and
    hardware need to be considered to maintain your system.
    Electronic access is great until you have a power outage.
    Systems normally reset themselves however; surges and losses in power
    can cause damage to your system. If your facility is in a high risk
    lightning area it would advantageous to secure a back up generator.
    J. Michael Floyd:
        Terri Moreman makes some excellent comments on her use of
    biometric handreaders at the US Olympic Training Center. One of the
    big advantages that we find in our application of biometrics here at
    the University of Georgia is the financial savings that we realize
    with this system. Let me explain this statement. In our application
    customers activate the system themselves by either swiping their id
    card or punching in their id number then placing their hand in the
    reader. Once the reader recognizes the hand image as a customer it
    then sends a signal to the turnstyle that allows the customer to enter
    the dining commons. By using this self activation system we do not
    need a cashier at every entry device, only a cashier to monitor all
    the entry devices for each dining commons. This reduces our labor cost
    by eight fulltime cashiers. This cost savings greatly outweighs the
    additional cost of the biometric readers. A disadvantage of the system
    is that it does require trained technicians to maintain the system,
    which a photo base only system normally does not require. The main
    service issue that we have is the routine replacement that we have to
    do on the keypad due to the large amount of usage our systems receive
    by our customers choosing to enter their student id number in lieu of
    swiping their id card. The numbers are actually worn off the keypad.
      _________________________________________________________________
    Question from G. Buhl, Rutgers U.:
        WIth the loss and theft of personal data by Universities reported
    recently in the media, what are the risks to students and faculty of
    entrusting biometric data to Universities?
    J. Michael Floyd:
        With any systems the appropriate safeguards must be in place to
    protect data. However, the biometric data that we use is hand & finger
    images and not prints. This data is of no value to an outsider to
    identify a customer by a hand or finger image. The key to our system
    is that we do not store finger or hand prints. In addition we do not
    identify our customers or employees by their social security number in
    our systems, but we utilize University identification numbers instead.
      _________________________________________________________________
    Question from Vincent Kiernan:
        Mike, a big issue with any new IT system is cost. Can you give us
    an idea of how much this system costs Georgia -- and how much it saves
    you in operational costs?
    J. Michael Floyd:
        The cost of any system is reflective of the size of the
    application, number of hand readers and the number of locations. In
    our case the initial cost was approximately $100,000. But this cost
    was immediately offset by reduction of staffing. With the use of
    biometric readers where the customer activates the system you do not
    need a cashier for every entry device. In our case we are able to
    staff our cashier station with one cashier who monitors two hand
    readers. This alone reduced labor by 8 fulltime positions. In today's
    dollars this is a savings of approximately $186,000 in salary and
    benefits cost every year. But the true savings is the speed of access
    for our customers. Thereby allowing greater thru put of customers in
    dining centers, which allows us to maximize our operations and reduces
    the need to build operations for peak customer periods. In our case we
    provide meal plan service for our customers in four dining centers. On
    some other campuses this same number of customers may need five to six
    dining centers.
      _________________________________________________________________
    Question from Vincent Kiernan:
        Mike, biometrics make some people nervous from a privacy
    perspective. Have you encountered any concern on your campus? How do
    you reassure people that their privacy is being protected?
    J. Michael Floyd:
        We have not experienced the privacy concern from our customers
    because we take an aggressive approach of educating our customers that
    our system is a hand image and not a hand print. One of the ways we
    educate our customers on the system is including this information in
    our Food Service presentation during the summer Freshman Orientation
    program. In addition we have previous articles from the Wall Street
    Journal and New York Times framed and in our lobbies to educate our
    customers on our biometric application. Our biometric system was also
    featured in "Beyond 2000" on the Discovery Channel several years ago
    and when the film crew was on campus we attempted to get as many of
    our students involved with the filming. In addition, during my 20 year
    tenure here at the University I have never had a customer express
    concern on this issue. What I do encounter from our customers is a
    sense of pride that they are using state of the art technology and I
    find they are normally our best PR agents as they love to explain our
    system to visitors.
      _________________________________________________________________
    Question from Vincent Kiernan:
        Do you have any plans to further expand your use of biometrics in
    the dining hall system?
    J. Michael Floyd:
        Yes. We have recently expanded the use of biometrics for
    timekeeping for employees. Utilizing a different biometric system, our
    employees clock in & out daily using a finger image. The next
    expansion is to utilize these devices for backdoor employee access
    into our operations. This will increase the overall security of our
    operations, especially since we have operations open till midnight and
    our plans include a 24-hour dining center in the near future. In my
    opinion, the real future of biometrics in the workplace is in
    timekeeping. This application for employers with large work forces
    will greatly increase the accuracy of paying for actual hours worked
    and prevent "buddy punching."
      _________________________________________________________________
    Question from Edward Marshall, University of Pennsylvania:
        Are you aware of any health related issues resulting from the use
    of biometric technologies? In particular, retinal scans.
    J. Michael Floyd:
        No, there is no greater risk with the hand image readers than the
    doorknob on the front of the building. However, we do have a procedure
    in place to sanitize the hand reader surface on a routine schedule
    thru out the day. In addition we have hand sanitizer stations located
    inside our dining operations for customers who would like to use this
    product. We do not utilize retinal scans here. However, the most
    common form of eye scanning is iris scanning and with these devices
    the eye is typically 10 to 14 inches away from the scanner.
      _________________________________________________________________
    Vincent Kiernan (Moderator):
        We're about half way through our scheduled time for this
    conversation. If you have any questions for Mr. Floyd, now would be a
    great time to send them in.
      _________________________________________________________________
    Question from Dick Sigelko, Michigan State University:
        If the system is not storing fingerprints or hand geography, how
    does it identify the individual as having the privilege?
    J. Michael Floyd:
        The system is storing hand and finger image templates. The
    templates are a mathematical representation of the hand or finger
    ridges. These stored templates are then compared to the image
    presented by the customer/employee when they place their hand or
    finger in the reader. All verifications are done on a one to one
    comparison, not a one to many comparison. For example the customer
    will input their ID number by scanning their card or typing their card
    number on a keypad and then they place their hand in the reader. The
    customer / employee must be active in the system prior to utilizing
    the system.
      _________________________________________________________________
    Question from Matt Miller, Gettysburg College:
        How long on average does it take to add a new hand image to the
    system?
    J. Michael Floyd:
        For both systems the initial image is captured at an orientation.
    Each image takes approximately 30 seconds to capture and verify the
    first time. However, with our meal plan system this one time
    enrollment is the only time we must physically see the student to
    begin participation in the meal plan for their entire academic stay at
    UGA. The enrollment for students is done when they have their ID card
    produced.
      _________________________________________________________________
    Question from Vincent Kiernan:
        What advice do you have for colleges that might consider hand
    scanning in the future? Are there any particular land mines to avoid?
    J. Michael Floyd:
        The key is to promote this as state of art technology and to
    excite the customers that they are involved in a unique application of
    technology. One installation issue to avoid is to make sure that all
    hand image readers are installed at the same height. Readers installed
    at different height can result in a higher error ratio.
      _________________________________________________________________
    Question from Dick Sigelko, Michigan State University:
        Have students expressed a concern about contamination, germs or
    the "ick" factor?
    J. Michael Floyd:
        Over the years we have heard this question from a few customers,
    which allows us to explain our system and how we sanitize the reader
    surface. But normally when we share the comparison about the front
    doorknob on the building the student then realizes the enormous number
    of common surfaces they touch with their hands each day.
      _________________________________________________________________
    Question from Dick Sigelko, Michigan State University:
        How many mis-reads per 100 do you get?
    J. Michael Floyd:
        We are at less than 1% of false-negatives. This allows our Cashier
    to then look up the customer in our data base and then permit the
    customer to dine.
      _________________________________________________________________
    Question from Francine Reynolds, University of Richmond:
        Mike, what systems are your biometric readers interfacing with
    (i.e. CBORD's CSGold, etc.)
    J. Michael Floyd:
        Our system is a proprietary system that our campus IT department
    developed and maintains for the campus.
      _________________________________________________________________
    Question from Terri Moreman, U.S. Olympic Training Center:
        Mike, is your system tied to dorm room or buliding access?
    J. Michael Floyd:
        Yes, our system is tied to residence hall building access. But not
    individual rooms.
      _________________________________________________________________
    Question from Rich Bredahl, University of Texas at Austin:
        How about issues of cleaniness? With potentially several hundred
    people using a reader per hour, how do you:
    1) Keep the reader clean
    2) Ensure the reader does not become a means of passing
    germs/bacteria/viruses
    J. Michael Floyd:
        No, there is no greater risk with the hand image readers than the
    doorknob on the front of the building. However, we do have a procedure
    in place to sanitize the hand reader surface on a routine schedule
    throughout the day. In addition we have hand sanitizer stations
    located inside our dining operations for customers who would like to
    use this product.
      _________________________________________________________________
    Question from Vincent Kiernan:
        That will be our last question. Mike, any final thoughts?
    J. Michael Floyd:
        In conclusion, the key benefit of a biometric system is that it
    can be a user activated system that creates a great deal of ownership
    by the customer. With this ownership, there is a buy in from the
    customer to assist the organization in making the system work.
    Additionally, biometric systems have the potential of reducing
    personnel cost and improving overall levels of security and customer
    thru put. There is also a greater awareness of security by the
    customer than the traditional photo base system. Biometrics is the
    technology that our children will see in their future workplace.
      _________________________________________________________________
    Vincent Kiernan (Moderator):
        That about does it for today. On behalf of The Chronicle, thanks
    to Mike Floyd and his staff for their illuminating answers to the
    questions, and thanks to all of you for participating. Have a good
    afternoon.
      _________________________________________________________________
    J. Michael Floyd:
        A special thank you to Donald Smith, Department Manager of UGAcard
    Support Services and Chris Wilkins, IT Manager, UGA Food Services for
    joining me today on the Colloquy and assisting with the
    responses.Additionally Biometric systems have the potential of
    reducing personnel cost and improving overall levels of security and
    customer thru put.
Post message: transhumantech at yahoogroups.com
Subscribe:    transhumantech-subscribe at yahoogroups.com
Unsubscribe:  transhumantech-unsubscribe at yahoogroups.com
List owner:   transhumantech-owner at yahoogroups.com
List home:    Yahoo! Groups Links
<*> To visit your group on the web, go to:
    <*> To unsubscribe from this group, send an email to:
    transhumantech-unsubscribe at yahoogroups.com
<*> Your use of Yahoo! Groups is subject to:
    Eugen* Leitl leitl ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-12-21 22:26:58
@_author: Premise Checker 
@_subject: [>Htech] Independent: Britain will be first country to monitor every 
journey
Reply-To: transhumantech at yahoogroups.com
Britain will be first country to monitor every car journey
By Steve Connor, Science Editor
Published: 22 December 2005
    Britain is to become the first country in the world where the movements of
    vehicles on the roads are recorded. A new national surveillance system
will hold
    the records for at least two years.
    Using a network of cameras that can automatically read every passing
    plate, the plan is to build a huge database of vehicle movements so that
    police and security services can analyse any journey a driver has made
    several years.
    The network will incorporate thousands of existing CCTV cameras which are
    converted to read number plates automatically night and day to provide
    coverage of all motorways and main roads, as well as towns, cities, ports
    petrol-station forecourts.
    By next March a central database installed alongside the Police National
    in Hendon, north London, will store the details of 35 million
    "reads" per day. These will include time, date and precise location, with
    sites monitored by global positioning satellites.
    Already there are plans to extend the database by increasing the storage
    to five years and by linking thousands of additional cameras so that
details of
    up to 100 million number plates can be fed each day into the central
    Senior police officers have described the surveillance network as possibly
    biggest advance in the technology of crime detection and prevention since
    introduction of DNA fingerprinting.
    But others concerned about civil liberties will be worried that the
movements of
    millions of law-abiding people will soon be routinely recorded and kept on
    central computer database for years.
    The new national data centre of vehicle movements will form the basis of
    sophisticated surveillance tool that lies at the heart of an operation
    to drive criminals off the road.
    In the process, the data centre will provide unrivalled opportunities to
    intelligence data on the movements and associations of organised gangs
    terrorist suspects whenever they use cars, vans or motorcycles.
    The scheme is being orchestrated by the Association of Chief Police
    (Acpo) and has the full backing of ministers who have sanctioned the
spending of
    ?24m this year on equipment.
    More than 50 local authorities have signed agreements to allow the police
    convert thousands of existing traffic cameras so they can read number
    automatically. The data will then be transmitted to Hendon via a secure
    communications network.
    Chief constables are also on the verge of brokering agreements with the
    Agency, supermarkets and petrol station owners to incorporate their own
    cameras into the network. In addition to cross-checking each number plate
    stolen and suspect vehicles held on the Police National Computer, the
    data centre will also check whether each vehicle is lawfully licensed,
    and has a valid MoT test certificate.
    "Every time you make a car journey already, you'll be on CCTV somewhere.
    difference is that, in future, the car's index plates will be read as
well," said
    Frank Whiteley, Chief Constable of Hertfordshire and chairman of the Acpo
    steering committee on automatic number plate recognition (ANPR).
    "What the data centre should be able to tell you is where a vehicle was in
    past and where it is now, whether it was or wasn't at a particular
location, and
    the routes taken to and from those crime scenes. Particularly important
    associated vehicles," Mr Whiteley said.
    The term "associated vehicles" means analysing convoys of cars, vans or
trucks to
    see who is driving alongside a vehicle that is already known to be of
interest to
    the police. Criminals, for instance, will drive somewhere in a lawful
    steal a car and then drive back in convoy to commit further crimes "You're
    necessarily interested in the stolen vehicle. You're interested in what's
    with the stolen vehicle," Mr Whiteley explained.
    According to a strategy document drawn up by Acpo, the national data
centre in
    Hendon will be at the heart of a surveillance operation that should deny
    criminals the use of the roads.
    "The intention is to create a comprehensive ANPR camera and reader
    across the country to stop displacement of crime from area to area and to
allow a
    comprehensive picture of vehicle movements to be captured," the Acpo
    says.
    "This development forms the basis of a 24/7 vehicle movement database that
    revolutionise arrest, intelligence and crime investigation opportunities
on a
    national basis," it says.
    Mr Whiteley said MI5 will also use the database. "Clearly there are values
    this in counter-terrorism," he said.
    "The security services will use it for purposes that I frankly don't have
    to. It's part of public protection. If the security services did not have
    to this, we'd be negligent."
Post message: transhumantech at yahoogroups.com
Subscribe:    transhumantech-subscribe at yahoogroups.com
Unsubscribe:  transhumantech-unsubscribe at yahoogroups.com
List owner:   transhumantech-owner at yahoogroups.com
List home:    Yahoo! Groups Links
<*> To visit your group on the web, go to:
    <*> To unsubscribe from this group, send an email to:
    transhumantech-unsubscribe at yahoogroups.com
<*> Your use of Yahoo! Groups is subject to:
    Eugen* Leitl leitl ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2006-02-05 16:00:09
@_author: Premise Checker 
@_subject: [>Htech] Supply Chain Review: Device To Disable RFID Tags In The 
Reply-To: transhumantech at yahoogroups.com
Device To Disable RFID Tags In The Works
RFID Kryptonite
Supply Chain Review  - Australia
Monday 23 January 2006
Two students have turned a disposable camera into a gadget that literally
shocks the power out of RFID tags.
The pair behind the "RFID-Zapper", Tim and Chris (who don't reveal their
last names online), say the gadget is designed to deactivate (destroy)
passive RFID-Tags permanently.
Goals are a proof-of-concept and the construction of at least one
functioning and appealing prototype, as well as a documentation of the
project. The pair plan to publish the instructions for build online, "so
that everyone can build an own RFID-Zapper".
"We have to expect to be surrounded by RFID-Tags almost everywhere within
the near future, and they will serve many different purposes," write Tim
and Chris online.
"The benefits and risks of this technology and its use are already being
"However, there will be atempts to use RFID-Tags to establish constant
surveiliance and to further threaten and compromise the privacy of
customers (and citizens and even non-citizens, when [governments] start to
use RFID-Tags like the German [government] already did).
"To defend yourself against such measures, you might want a small, simple
and relatively appealing gadget to permanently deactivate RFID-Tags around
you, e.g., to deactivate RFID-Tags in recently bought clothes or books
without damaging those [items]."
How does it work?
There are several ways to deactivate RFID-Tags, including
RFID-deactivators, which send the RFID-Tag to sleep.
"A problem with this method is, that it is not permanent, the RFID-Tag can
be reactivated," write Tim and Chris.
"Several ways of permanently deactivating RFID-Tags are known, e.g.,
cutting off the antenna from the actual microchip or overloading and
literally frying the RFID-Tag in a common microwave-oven, which needs to
be turned on only for a short period of time.
"Unfortunately both methods aren't suitable for the destruction of
RFID-Tags in clothes: cutting off the antenna would require to damage the
piece of cloth, while frying the chips is likely to cause a small but
potent flame, which would damage most textiles or even set them on fire."
The RFID-Zapper copies the microwave-oven-method, but on a much smaller
The duo modified the electric component of a singe-use-camera with flash,
readily available in most retail outlets, to "keep the costs of the
RFID-Zapper as low as possible".
The coil is made from coated copper wire and placed inside the camera
where the film normally lies.
"Then one end of the coil is soldered to the camera's capacitor, from
which we earlier disconnected the flash," Tim and Chris write.
"The other end of the coil is soldered to a switch, which itself is
connected to the capacitor's other terminal. Once everything is tested,
the camera can be closed again and henceforth will serve as a RFID-Zapper,
destroying RFID-Tags with the power of ordinary batteries."
The zapper generates a strong electromagnetic field with a coil, which,
claim the inventors, should be placed as near to the target RFID-Tag as
The RFID-Tag then will receive a strong shock of energy comparable with an
EMP and some part of it will blow, thus deactivating the chip forever.
Until now the pair have only had access to 13.56 MHz RFID tags, but hope
to be able to test the RFID-Zapper on other tags soon.
A German privacy advocacy group -- FoeBuD -- plans to manufacture and sell
a device that consumers could used to disable RFID tags permanently.
FoeBuD says it wants to manufacture the RFID-Zapper and sell it at its
online store. The group met with a hardware developer last week, but says
it has no timescale for production or product price yet.
Post message: transhumantech at yahoogroups.com
Subscribe:    transhumantech-subscribe at yahoogroups.com
Unsubscribe:  transhumantech-unsubscribe at yahoogroups.com
List owner:   transhumantech-owner at yahoogroups.com
List home:    Yahoo! Groups Links
<*> To visit your group on the web, go to:
    <*> To unsubscribe from this group, send an email to:
    transhumantech-unsubscribe at yahoogroups.com
<*> Your use of Yahoo! Groups is subject to:
    Eugen* Leitl leitl ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2007-12-30 05:29:38
@_author: Premise Checker 
@_subject: [tt] NS: Virtual entrepreneurs and 'griefers' spoil the fantasy of 
Virtual entrepreneurs and 'griefers' spoil the fantasy of online worlds
   * 01 September 2007
   * Jim Giles
IT SHOULD have been a coming-of-age moment. In December 2006, Anshe
Chung, the most prominent of Second Life's entrepreneurs, was
interviewed about her burgeoning [12]property portfolio, which she
says is worth more than $1 million. It was a milestone to mark the
emergence of a mature and corporate side to virtual worlds. But
then, for a full 15 minutes, the virtual room in which she was
being interviewed was invaded by [13]flying penises.
Two months later, something similar happened. The Second Life
headquarters of US presidential candidate John Edwards was attacked
by a gang known as the Patriotic Nigras, who [14]plastered the
building with objects including faeces (see Picture). Other
residents say they have received racist materials from the Nigras.
To anyone familiar with Second Life, airborne genitalia and
offensive comments come as no surprise. Griefers - the disruptive
residents who create such disturbances - have been active since the
virtual world's earliest days. Since many residents are attracted
to Second Life precisely because of its anything-goes ethos, such
behaviour is generally tolerated.
Now that Wild West spirit is under threat. With tens of thousands
of denizens logged in at any one time and [15]millions of dollars'
worth of transactions taking place in a single year (see Chart), a
class of entrepreneurs is emerging who see griefers not just as an
annoyance but as a potential source of lost revenue. That can
simply encourage the griefers, some of whom are irritated by
residents who seem to take life in Second Life too seriously, but
it also prompts entrepreneurs to turn to [16]real-world courts to
settle disputes. That in turn is cause for concern for residents
who believe virtual worlds' value lies in their freedom from
real-world laws and norms.
"As the worlds industrialise we're going to see more appeals to the
law," says Ren Reynolds, an expert on virtual worlds based in
London who is establishing [17]a think tank to explore their policy
implications. "The worry is that legislators will say that virtual
worlds should be like the real world." That might wreck the main
reason for using virtual worlds, which, despite rampant
commercialisation, many still view as fantasy spaces.
Last week New Scientist reported how virtual worlds can enhance
social interactions, by facilitating meetings between people who
wouldn't have that opportunity in real life or allowing them to
step into the shoes of others (25 August, p 26). But it is also
clear that virtual worlds are ripe for abusive behaviour, and that
the naively enthusiastic attitude of some residents may even
provoke it.
Studies of griefer psychology are limited, but the Nigras' former
leader, "Mudkips Acronym", who declined to give his real-life name,
is happy to talk about his gang's motivations. He says that the
group, which boasts between 35 and 60 members, is motivated by
"laughs" and a desire to annoy the Second Lifers "who take their
'metaverse' enormously seriously". Despite the fact that the Nigras
hurl racist abuse at some residents (see "Second Life - under
attack"), Acronym says that he is not aware of anyone who is "truly
racist". Rather, "we do anything we can to shock people".
In the past, online communities have either endured residents like
Acronym or acted together to punish them. In World of Warcraft
(WoW), an online game full of elves and dragons where players
compete for gold and weapons, users often group themselves into
[18]guilds that police themselves, so that certain tasks, such as
dividing the spoils of a raid, can be carried out fairly.
Linden Lab, the San Francisco firm that runs Second Life, is also
happy to let its residents settle their own disputes. The company
says its goal is "neither to be a 'government' nor to foist one
upon the residents". Rather, it hopes to "foster a self-governing
community where residents are empowered to act on things they feel
strongly about, and adjudicate such disputes".
Self-policing is sometimes so effective that it can be used not
just to punish residents, but also to wrest control of a virtual
world from its owner. Last year, that's exactly what residents of
WoW did when Blizzard Entertainment, of Irvine, California, which
runs the world, [19]tried to block an attempt to form a guild for
gay, lesbian, bisexual and transgender (GLBT) people. Once word
spread, players organised protest marches in WoW, says Reynolds.
Some wore pink armour as a symbol of support for the proposed
guild. Bloggers also criticised the decision. Eventually Blizzard
backed down, and now several GLBT guilds exist.
The approach appears to be breaking down, however, as
entrepreneurial residents call upon real-world justice systems to
settle disputes. "Most people consider virtual worlds to be like
the Wild West, places where the law doesn't apply," says Sean Kane,
an attorney with Drakeford & Kane in New York City who specialises
in internet law. "But the law will catch up."
Financial disputes are the most common trigger for legal action.
Last month, Second Lifer Kevin Alderman filed suit against a
resident known as Volkov Catteneo over Alderman's SexGen bed, which
animates Second Life avatars so that they are able to perform more
than 150 sexual acts. Alderman's suit alleges that Catteneo, whose
real-life name is not known, is selling a pirated version of the
bed, which normally sells for $45.
Another virtual entrepreneur who has contemplated - but not yet
initiated - legal action is Catherine Fitzpatrick, a Second Life
real estate dealer who goes by the Second Life name of [20]Prokofy
Neva. She says she regularly receives obscene and racist messages
from the Nigras, some of which have led to tenants leaving her
properties. "I don't view Second Life as a fantasy world," says
Fitzpatrick. "I'm looking at it as a business."
That attitude makes some residents anxious. "The worry is that
legislators will say virtual worlds should be the same as the real
world and make very naive laws," Reynolds says.
It is not only business activities that might bring a legal
clampdown to virtual worlds. Second Life has a long tradition of
adult users adopting childlike avatars, and sometimes getting their
characters to engage in sexual acts with adult avatars. Users have
debated whether this amounts to virtual child pornography, but
since Second Life is viewed as a fantasy world, and all
participants are adults, such behaviour has generally been
tolerated. In May, however, a German TV show covered the practice
and reported details to the police. Linden Lab subsequently banned
two of the residents involved.
Meanwhile gambling, which is illegal in most US states but
widespread in Second Life, has also taken a hit. In July, Linden
Lab decided to shut down its virtual casinos after receiving a
visit from the FBI. Angry users on the firm's blog accused the
company of eroding the freedom associated with an experience that
was, after all, designed to be different from normal life. "Welcome
to Real Life 2," wrote one user. "Enjoy your stay!"
Will big online worlds like Second Life and WoW survive these legal
attacks, perhaps by adopting the protected status that sports enjoy
(see "Sporting solution")? Or will the pressure from commercially
minded users eradicate the anything-goes spirit, perhaps allowing
smaller and freer worlds to take their place? Read about a host of
planned virtual experiences in next week's instalment of this New
Scientist report.
Sporting solution
The fantasy inherent to virtual worlds is under attack from
commercially minded residents and real-world laws. Is it possible
to keep everyone happy?
One solution is to look to sport for guidance, says New York
attorney Sean Kane. When players take to the rugby field, they
experience tackles that would be classed as assaults if they took
place anywhere else.
Courts understand this and create what Kane calls a "magic circle"
around on-field behaviour. When disputes arise, the courts tend to
respect the arbitration systems established by sport authorities,
even though such committees have no formal legal standing. Virtual
worlds might earn the same respect from courts if they ensure that
the arbitration systems established by residents are fair and
Another option is to have different types of virtual spaces, says
[21]Ren Reynolds, who studies virtual worlds, with some regulated
to keep entrepreneurs happy, and others free, for people who just
want to have fun.
Second Life, however, is one space that could face more legal
problems. The site currently [22]reserves the right to terminate a
user's account "for any or no reason", destroying their virtual
assets. If the company does not start to provide residents with
genuine ownership, some will feel compelled to go to the courts,
Kane says.
Related Articles
FBI investigates virtual casinos in Second Life
4 April 2007
Online games, real-life crimes
20 May 2006
"Grey goo" engulfs virtual world
20 November 2006
Game company sued over virtual land squabble
18 May 2006
Web letter: What Life?
22 September 2007
Anshe Chung's Second Life property portfolio
Ren Reynolds
Videos and podcasts about the Patriotic Nigras
Second Life
World of Warcraft guilds
Drakeford & Kane
Virtual Policy Network
Prokofy Neva, Second Life
Second Life's policy on wagering
Linden Lab Terms of Service
Survey of developers in the Second Life directory
   11.    12.    13.    14.    15.    16.    17.    18.    19.    20.    21.    22. E-mail me if you have problems getting the referenced articles.
tt mailing list
tt at postbiota.org

@_date: 2007-02-20 14:05:47
@_author: Premise Checker 
@_subject: [>Htech] NYT: Europe's Plan to Track Phone and Net Use 
Europe's Plan to Track Phone and Net Use
By VICTORIA SHANNON
PARIS, Feb. 19 -- European governments are preparing legislation to
require companies to keep detailed data about people's Internet and
phone use that goes beyond what the countries will be required to
do under a European Union directive.
In Germany, a proposal from the Ministry of Justice would
essentially prohibit using false information to create an e-mail
account, making the standard Internet practice of creating accounts
with pseudonyms illegal.
A draft law in the Netherlands would likewise go further than the
European Union requires, in this case by requiring phone companies
to save records of a caller's precise location during an entire
mobile phone conversation.
Even now, Internet service providers in Europe divulge customer
information -- which they normally keep on hand for about three
months, for billing purposes -- to police officials with legally
valid orders on a routine basis, said Peter Fleischer, the
Paris-based European privacy counsel for Google. The data concerns
how the communication was sent and by whom but not its content.
But law enforcement officials argued after the terrorist bombings
in Spain and Britain that they needed better and longer data
storage from companies handling Europe's communications networks.
European Union countries have until 2009 to put the Data Retention
Directive into law, so the proposals seen now are early
interpretations. But some people involved in the issue are
concerned about a shift in policy in Europe, which has long been a
defender of individuals' privacy rights.
Under the proposals in Germany, consumers theoretically could not
create fictitious e-mail accounts, to disguise themselves in online
auctions, for example. Nor could they use a made-up account to use
for receiving commercial junk mail. While e-mail aliases would not
be banned, they would have to be traceable to the actual account
"This is an incredibly bad thing in terms of privacy, since people
have grown up with the idea that you ought to be able to have an
anonymous e-mail account," Mr. Fleischer said. "Moreover, it's
totally unenforceable and would never work."
Mr. Fleischer said the law would have to require some kind of
identity verification, "like you may have to register for an e-mail
address with your national ID card."
Jvrg Hladjk, a privacy lawyer at Hunton & Williams, a Brussels law
firm, said that might also mean that it could become illegal to pay
cash for prepaid cellphone accounts. The billing information for
regular cellphone subscriptions is already verified.
Mr. Fleischer said: "It's ironic, because Germany is one of the
countries in Europe where people talk the most about privacy. In
terms of consciousness of privacy in general, I would put Germany
at the extreme end."
He said it was not clear that any European law would apply to
e-mail providers based in the United States, like Google, so anyone
who needed an unverified e-mail address -- for political,
commercial or philosophical reasons -- could still use Gmail, Yahoo
or Hotmail addresses.
Mr. Hladjk said, "It's going to be difficult to know which law
applies." Google requires only two pieces of information to open a
Gmail account -- a name and a password -- and the company does not
try to determine whether the name is authentic.
In the Netherlands, the proposed extension of the law on phone
company records to all mobile location data "implies surveillance
of the movement of large amounts of innocent citizens," the Dutch
Data Protection Agency has said. The agency concluded in January
that the draft disregarded privacy protections in the European
Convention on Human Rights. Similarly, the German technology trade
association Bitkom said the draft there violated the German
Internet and telecommunications industry associations raised
objections when the directive was being debated, but at that time
their concerns were for the length of time the data would have to
be stored and how the companies would be compensated for the cost
of gathering and keeping the information. The directive ended up
leaving both decisions in the hands of national governments,
setting a range of six months to two years. The German draft
settled on six months, while in Spain the proposal is for a year,
and in the Netherlands it is 18 months.
"There are not a lot of people in Germany who support this draft
entirely," said Christian Spahr, a spokesman for Bitkom. "But there
are others who are more critical of it than we are."
Post message: transhumantech at yahoogroups.com
Subscribe:    transhumantech-subscribe at yahoogroups.com
Unsubscribe:  transhumantech-unsubscribe at yahoogroups.com
List owner:   transhumantech-owner at yahoogroups.com
List home:    Yahoo! Groups Links
<*> To visit your group on the web, go to:
    <*> Your email settings:
    Individual Email | Traditional
<*> To change settings online go to:
        (Yahoo! ID required)
<*> To change settings via email:
    mailto:transhumantech-digest at yahoogroups.com
    mailto:transhumantech-fullfeatured at yahoogroups.com
<*> To unsubscribe from this group, send an email to:
    transhumantech-unsubscribe at yahoogroups.com
<*> Your use of Yahoo! Groups is subject to:
    Eugen* Leitl leitl ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2008-08-08 15:55:27
@_author: Premise Checker 
@_subject: [tt] NYT: Fingerprint Test Tells What a Person Has Touched 
Fingerprint Test Tells What a Person Has Touched
New York Times, 8.8.8
By KENNETH CHANG
With a new analytical technique, a fingerprint can now reveal much
more than the identity of a person. It can now also identify what
the person has been touching: drugs, explosives or poisons, for
Writing in Friday's issue of the journal Science, R. Graham Cooks, a
professor of chemistry at Purdue University, and his colleagues
describe how a laboratory technique, mass spectrometry, could find a
wider application in crime investigations.
The equipment to perform such tests is already commercially
available, although prohibitively expensive for all but the largest
crime laboratories. Smaller, cheaper, portable versions of such
analyzers are probably only a couple of years away.
In Dr. Cooks's method, a tiny spray of liquid that has been
electrically charged, either water or water and alcohol, is sprayed
on a tiny bit of the fingerprint. The droplets dissolve compounds in
the fingerprints and splash them off the surface into the analyzer.
The liquid is heated and evaporates, and the electrical charge is
transferred to the fingerprint molecules, which are then identified
by a device called a mass spectrometer. The process is repeated over
the entire fingerprint, producing a two-dimensional image.
The researchers call the technique desorption electrospray
ionization, or Desi, for short.
In the experiments described in the Science paper, solutions
containing tiny amounts of various chemicals including cocaine and
the explosive RDX were applied to the fingertips of volunteers. The
volunteers touched surfaces like glass, paper and plastic. The
researchers then analyzed the fingerprints.
Because the spatial resolution is on the order of the width of a
human hair, the Desi technique did not just detect the presence of,
for instance, cocaine, but literally showed a pattern of cocaine in
the shape of the fingerprint, leaving no doubt who had left the
cocaine behind.
"That's an advantage that this technique would have," said Bruce
Goldberger, professor and director of toxicology at the University
of Florida who runs a forensics laboratory that helps medical
examiners and law enforcement. Dr. Goldberger was not involved in
the research.
The chemical signature could also help crime investigators tease out
one fingerprint out of the smudges of many overlapping prints if the
person had been exposed to a specific chemical, said Demian R. Ifa,
a postdoctoral researcher and the lead author of the Science paper.
Prosolia Inc., a small company in Indianapolis, has licensed the
Desi technology from Purdue and is already selling such analyzers as
add-ons to large laboratory mass spectrometers, which cost several
hundred thousand dollars each.
Prosolia has so far sold about 70 analyzers, said Peter T.
Kissinger, the company's chairman and chief executive. The most
sophisticated $60,000 version that would be needed for fingerprint
analysis went on sale this year.
However, fingerprints are not the main focus for Prosolia or Dr.
Cooks. "This is really just an offshoot of a project that is really
aimed at trying to develop a methodology ultimately to be used in
surgery," Dr. Cooks said.
If a Desi analyzer can be miniaturized and automated into a surgical
tool, a surgeon could, for example, quickly test body tissues for
the presence of molecules associated with cancer. "That's the
long-term aim of this work," Dr. Cooks said.
In unpublished research, the researchers have successfully tested
the method on bladder tumors in dogs.
Prosolia is collaborating with Griffin Analytical Technologies, a
subsidiary of ICx Technologies, on a Desi analyzer that works with a
portable mass spectrometer. That product is probably a year or two
away from the market, Dr. Kissinger said.
As it becomes cheaper and more widely available, the Desi technology
has potential ethical implications, Dr. Cooks said. Instead of drug
tests, a company could surreptitiously check for illegal drug use by
its employees by analyzing computer keyboards after the workers have
gone home, for instance.
tt mailing list
tt at postbiota.org

@_date: 2008-06-13 18:50:59
@_author: Premise Checker 
@_subject: [tt] NS: Laptops could betray users in the developing world 
Laptops could betray users in the developing world
Colin Barras
IN JANUARY, a court in Mazar-e-Sharif, Afghanistan, sentenced a
young journalism student to death. Sayed Pervez Kambaksh's crime was
to download and distribute a document about Islam and women's rights
to his fellow students at Balkh University in Mazar, an action that
the court considered blasphemous. Despite widespread international
condemnation, the Afghan Senate later passed a motion confirming the
death sentence.
Kambaksh was caught because some of his fellow students reported him
to the authorities. But oppressive governments could soon have a
simple way to track the internet activity of their citizens
directly, potentially paving the way for many more such cases.
For security reasons, sensitive data sent over the internet, such as
that used for online banking transactions, is digitally signed at
source with a signature that can be traced to the user's computer.
This helps validate their identity and guard against fraud. The
system is known as non-repudiation, because the person creating the
digital signature can reasonably be assumed to be the source of the
sensitive data and, in a fraud case, for example, cannot repudiate
If this system were to become the default setting for all traffic on
a network, there would be nothing to stop authorities from tracing
the source of any online activity, says Len Sassaman, a computer
security researcher at the Catholic University of Leuven (KUL) in
Belgium. Users would be stripped of their anonymity and authorities
could identify anyone that criticised them. "If countries like
Afghanistan were to switch to a system where the user cannot refute
any action they took on the internet, I suspect we'll see more cases
like Kambaksh's," says Sassaman.
Now Sassaman and his colleague Meredith Patterson at the University
of Iowa in Iowa City claim a prominent philanthropic organisation is
inadvertently in the process of introducing just such a system
across the developing world.
The One Laptop per Child foundation (OLPC), the brainchild of
Nicholas Negroponte, hopes to provide children around the world with
a cheap laptop, called the XO, and access to the internet. But
rolling out internet-ready laptops to inexperienced users across the
developing world poses a huge security problem, not least because
the devices could easily get stolen.
To minimise this risk, the OLPC security team, formerly led by Ivan
Krsti at Harvard University, developed the Bitfrost security model.
Bitfrost has garnered praise from security experts around the world
for its innovations, such as its anti-theft system, P_THEFT. Each
laptop automatically phones an anti-theft server each day, sending
its serial number. The server responds with an activation lease,
valid for the next 24 hours. Any laptop that has been reported
stolen is denied activation and becomes a useless lump of plastic
and metal. While this will discourage theft, Sassaman and Patterson
think there is a crucial element missing from the Bitfrost security
model - personal privacy.
Because the XO laptops will often be used in areas with limited
internet connectivity, the OLPC team chose to use a mesh network, in
which all XO computers in the region act as nodes. This means a
message might pass through many XOs before it reaches its target, so
each one is digitally signed to authenticate its source. While it is
possible to use a digital signature that simply confirms the device
is legitimate without identifying it, Bitfrost uses non-repudiable
digital signatures. These can be traced to a specific laptop and -
since children must register their details with a central database
on taking possession of their XO - an individual child.
"If a government happens to be monitoring, perhaps by inserting
itself into the network between two XOs, it can prove to the world
that the communicating parties said what they said," says Sassaman.
Then, taking advantage of the P_THEFT system, the government could
silence the user by simply denying their laptop a new activation
Steven Murdoch, a privacy and security researcher at the University
of Cambridge, says that Sassaman and Patterson have made a useful
contribution to the Bitfrost model. "What I found most surprising
about the Bitfrost specification is that it doesn't appear to
consider governments as a risk to security," he says.
Simson Garfinkel, a former security consultant for OLPC, dismisses
the claims. He says Bitfrost does not use the signature to track
user activity, adding that the model was intensely scrutinised by
security experts after it was developed.
"It's an issue of intent versus possibility," counters Sassaman.
"They may not intend for the signatures to be used for
non-repudiation, but it's possible to use them for this purpose."
That won't be an issue, says Ricky Greenwald, a clinical
psychologist and founder of the Child Trauma Institute in
Greenfield, Massachusetts. Governments won't need to monitor the
internet activity of 5 to 10-year-olds. "Children that age are more
likely to use their computer for games and schoolwork," he says.
It's very unlikely that a child's laptop would be deactivated by an
oppressive regime, he says.
Sassaman disagrees. "Remember where these computers are being
deployed," he says. "We have 11-year-olds in some of these countries
being drafted as child soldiers. Why would we not want to give them
the ability to whistleblow?"
Furthermore, Sassaman points out that it is unlikely that XO laptops
will be used by children alone. "The OLPC project is laying the
groundwork for a major network across the Third World," he says.
"It's rather short-sighted to think that this would be limited to
children, or to education." With rumours that an adult XO programme
is in development, it is important to tackle security issues now, he
To this end, Sassaman and Patterson are working on a modified
version of Bitfrost that will allow XO laptops to identify each
other without eroding the privacy of their users. Their work is at a
preliminary stage, but will be based on existing cryptographic
techniques that cannot be used for non-repudiation.
With recent changes at the OLPC project it remains to be seen how
widely Bitfrost will be installed in the XO laptops (see "Education,
or just the laptop?"). The security system was designed to run
alongside the Linux operating system and the experimental Sugar
graphical user interface developed for the project. Last month,
however, OLPC announced that the latest XO laptops will run Windows
XP, although the foundation said the machines will eventually be
able to run both operating systems. So far, there are 1000 XOs in
Mongolia and 8000 in Uruguay using Bitfrost, with thousands more due
to be delivered this year. Other countries that have agreed to buy
XOs include Peru, Libya, Nigeria and Rwanda.
Meanwhile Walter Bender, the former president of software and
content at the OLPC, has begun talks with a number of ultra-low-cost
laptop manufacturers that might see Sugar deployed on non-XO laptops
in the near future. "Bitfrost is a far-reaching design," Bender
says. "Much of it is of general use, and aspects of Bitfrost will be
folded into the Sugar efforts."
Sassaman welcomes this development. "Don't get me wrong, Bitfrost is
a highly ambitious project. It's an application of lessons learned
in software security and in that respect it has done a great job,"
he says. "They just happened to overlook a significant issue - user
privacy. But those problems can be fixed without changing the goals
of Bitfrost."
At the time New Scientist went to press, after four months of
international pressure, the Afghan authorities appear to be on the
verge of freeing Kambaksh. With modifications to Bitfrost, Sassaman
and Patterson hope that, in similar cases, at least people's
computers won't betray them.
Computer Viruses - Learn more about the threats to your PC in our
comprehensive special report.
Education, or just the laptop?
Earlier this year, Nicholas Negroponte claimed that One Laptop per
Child, the organisation he founded, had been acting "like a
terrorist group" and needed to be managed "more like Microsoft".
Since then, OLPC has lost some of its key members and all but
abandoned a Linux operating system in favour of the ubiquitous
Microsoft Windows XP.
Reports suggest Negroponte took the decision to adopt Windows after
requests from developing countries, which were stalling on placing
orders for the XO. Critics argue, though, that the switch, coupled
with the recent resignations of Walter Bender, president of software
and content, and Ivan Krsti, director of security architecture, are
signs that OLPC has abandoned its original mission to educate, and
is now simply a laptop manufacturer. "Teaching children to use a
proprietary system such as Windows does not make the world a better
place, because it puts them under the power of the system's
developer," wrote Richard Stallman, founder of the Free Software
Foundation, on the foundation's blog.
Krsti argues that a Windows computer is as useful an educational
tool as one running free software, but he agrees that OLPC's
priorities have changed. "I quit when Nicholas told me that learning
was never part of the mission. The mission was, in his mind, always
getting as many laptops as possible out there," he wrote on his
personal blog.
Related Articles
Hackers have poor nations' PCs in their sights
15 December 2007
$100-laptop created for world's poorest countries
17 November 2005
Developing nations to test new $150 laptops
13 February 2007
One Laptop Per Child
tt mailing list
tt at postbiota.org

@_date: 2009-01-15 13:42:45
@_author: Premise Checker 
@_subject: [tt] Power Blogging Tips: The Grip Of Internet Censorship Is 
The Grip Of Internet Censorship Is Tightening Worldwide
Governments around the world have gotten a taste for internet
censorship and they like it. Through the use of mandatory filters
and new "cybercrime laws", internet freedom is being crushed around
the world like never before.
*In February, New Zealand will implement Section 92 of their
Copyright Amendment Act which allows the government [26]to
immediately disconnect someone from the internet if they are even
accused of illegal file sharing.
*The new mandatory internet filter being imposed on the people of
Australia is so restrictive that it is being called [27]"The Great
Firewall of Australia".
*In China, the new year [28]has brought a severe crackdown on
websites and search engines that offer material that the Chinese
government decides is "too vulgar" or "too subversive" for the
Chinese people to see.
*Internet activists in Thailand are getting increasingly upset by
efforts of that government [29]to censor the internet in that
*A new set of laws in India [30]is so brutal that it will allow a
government official to break in to someone's home to check if they
were surfing porn, and it will allow the government of India to
block any website they want for any reason.
The internet has truly been one of the greatest advances in
communication in the history of the world. For the past few years,
we all have experienced an era of unlimited, high speed internet
with the freedom to say almost anything we have wanted to. It has
been a golden age for the internet, but every golden age ends, and
the golden age of the internet is now being crushed by repressive
governments all over the globe.
So will we see such restrictive measures in the United States soon?
While such repressive measures as a mandatory filter have not been
imposed yet, we have been seeing more limits and restrictions on
internet usage.
Many of these subtle restrictions are very quietly being put into
On November 1st, AT&T, the largest U.S. Internet provider, [31]began
testing limits that would curb internet usage for customers whose
video and music downloads are flooding their network.
Are fundamental changes to our beloved internet on the horizon? Are
we about to face increased restrictions regarding what we can say on
the internet even in the U.S.? Unfortunately, the answer to all of
these questions is very clearly yes, and the following are ten
reasons why the golden age of the internet is ending:
 Once one or two large internet providers get away with putting a
cap on internet use all of the other providers will follow very
quickly. [32]Now that Comcast has announced a hard cap on internet
use, it is only a matter of time until more internet providers
follow suit.
 Bandwidth is very expensive. With the explosion of online gaming
and the massive increase of internet users downloading video and
music files, there has been a huge increase in the average bandwidth
utilized by the average consumer. Bandwidth costs money, and those
costs have to be passed on to the consumer somehow.
 There has never been a greater information tool than the
internet in the history of the world. The free flow of information
that has resulted has given a lot of power to the people of the
world. Many governments around the world, including the Western
establishment, do not like this one bit. Increased censorship and
other types of "internet reform" are being introduced in order to
curtail our freedom of speech to a more acceptable level.
 Greed. Every single day health insurance companies deny
healthcare to sick people in the United States and they make
billions of dollars doing it. Why? Because they can. Now that we
have all become addicted to the internet do you think internet
providers will not get greedy? The reality is that they already are
getting greedy.
 This is all part of the plan to transition us over to Internet
2, which will be much more heavily restricted and controlled:
 Canada's new internet subscription model appeals to a lot of
powerful interests. What some internet providers in Canada are
getting ready to do is to provide internet service on a subscription
model similar to how cable television service is provided. In other
words, your "package" will include 400 or 500 of the top websites,
and if you want more than that you will have to pay for it:
 Up until now, the internet has largely avoided taxation.
However, with governments increasingly looking at significant
shortfalls, it is only a matter of time before some politicians look
at the internet as a great source of tax revenue.
 The world is heading for incredibly difficult economic times,
and when the economy crashes you won't get anything "for free". If
you doubt that the economy is headed for a crash then you really
need to read this article:
 Giant media companies are sick and tired of giving away their
media for free. Huge newspapers are going broke, movie companies are
losing revenue, news organizations have lost control over the flow
of information and the "small guy" is finding a way to carve out a
bigger piece of the pie. Giant media organizations desperately want
their power and control back.
 Most people in modern society are sheep, and they will pay
whatever someone tells them to pay, and they will passively accept
whatever controls and restrictions are put on them without even a
whimper. Hopefully this last point is wrong and more people will
stand up and will have the backbone to fight for the future of the
26. 27. 28. 29. 30. 31. 32. tt mailing list
tt at postbiota.org

@_date: 2009-05-02 15:00:36
@_author: Premise Checker 
@_subject: [tt] Cyberwar--Iranians and Others Outwit Net Censors--Series 
Cyberwar--Iranians and Others Outwit Net Censors--Series
By JOHN MARKOFF
The Iranian government, more than almost any other, censors what
citizens can read online, using elaborate technology to block
millions of Web sites offering news, commentary, videos, music and,
until recently, Facebook and YouTube. Search for "women" in Persian
and you're told, "Dear Subscriber, access to this site is not
Last July, on popular sites that offer free downloads of various
software, an escape hatch appeared. The computer program allowed
Iranian Internet users to evade government censorship.
College students discovered the key first, then spread it through
e-mail messages and file-sharing. By late autumn more than 400,000
Iranians were surfing the uncensored Web.
The software was created not by Iranians, but by Chinese computer
experts volunteering for the Falun Gong, a spiritual movement that
has beem suppressed by the Chinese government since 1999. They
maintain a series of computers in data centers around the world to
route Web users' requests around censors' firewalls.
The Internet is no longer just an essential channel for commerce,
entertainment and information. It has also become a stage for state
control--and rebellion against it. Computers are becoming more
crucial in global conflicts, not only in spying and military action,
but also in determining what information reaches people around the
More than 20 countries now use increasingly sophisticated blocking
and filtering systems for Internet content, according to Reporters
Without Borders, a Paris-based group that encourages freedom of the
Although the most aggressive filtering systems have been erected by
authoritarian governments like those in Iran, China, Pakistan, Saudi
Arabia and Syria, some Western democracies are also beginning to
filter some content, including child pornography and other sexually
oriented material.
In response, a disparate alliance of political and religious
activists, civil libertarians, Internet entrepreneurs, diplomats and
even military officers and intelligence agents are now challenging
growing Internet censorship.
The creators of the software seized upon by Iranians are members of
the Global Internet Freedom Consortium, based largely in the United
States and closely affiliated with Falun Gong. The consortium is one
of many small groups developing systems to make it possible for
anyone to reach the open Internet. It is the modern equivalent of
efforts by organizations like the Voice of America to reach the
citizens of closed countries.
Separately, the Tor Project, a nonprofit group of anticensorship
activists, freely offers software that can be used to send messages
secretly or to reach blocked Web sites. Its software, first
developed at the United States Naval Research Laboratories, is now
used by more than 300,000 people globally, from the police to
criminals, as well as diplomats and spies.
Political scientists at the University of Toronto have built yet
another system, called Psiphon, that allows anyone to evade national
Internet firewalls using only a Web browser. Sensing a business
opportunity, they have created a company to profit by making it
possible for media companies to deliver digital content to Web users
behind national firewalls.
The danger in this quiet electronic war is driven home by a stark
warning on the group's Web site: "Bypassing censorship may violate
law. Serious thought should be given to the risks involved and
potential consequences."
In this cat-and-mouse game, the cat is fighting back. The Chinese
system, which opponents call the Great Firewall of China, is built
in part with Western technologies. A study published in February by
Rebecca MacKinnon, who teaches journalism at the University of Hong
Kong, determined that much blog censorship is performed not by the
government but by private Internet service providers, including
companies like Yahoo China, Microsoft and MySpace. One-third to more
than half of all postings made to three Chinese Internet service
providers were not published or were censored, she reported.
When the Falun Gong tried to support its service with advertising
several years ago, American companies backed out under pressure from
the Chinese government, members said.
In addition, the Chinese government now employs more than 40,000
people as censors at dozens of regional centers, and hundreds of
thousands of students are paid to flood the Internet with government
messages and crowd out dissenters.
This is not to say that China blocks access to most Internet sites;
most of the material on the global Internet is available to Chinese
without censorship. The government's censors mostly censor groups
deemed to be state enemies, like the Falun Gong, making it harder
for them to reach potential members.
Blocking such groups has become more insidious as Internet filtering
technology has grown more sophisticated. As with George Orwell's
"Newspeak," the language in "1984" that got smaller each year,
governments can block particular words or phrases without users
realizing their Internet searches are being censored.
Those who back the ragtag opponents of censorship criticize the
government-run systems as the digital equivalent of the Berlin Wall.
They also see the anticensorship efforts as a powerful political
lever. "What is our leverage toward a country like Iran? Very
little," said Michael Horowitz, a fellow at the Hudson Institute who
advises the Global Internet Freedom Consortium. "Suppose we have the
capacity to make it possible for the president of the United States
at will to communicate with hundreds of thousands of Iranians at no
risk or limited risk? It just changes the world."
The United States government and the Voice of America have financed
some circumvention technology efforts. But until now the Falun Gong
has devoted the most resources, experts said, erecting a system that
allows the largest number of Internet users open, uncensored access.
Each week, Chinese Internet users receive 10 million e-mail messages
and 70 million instant messages from the consortium. But unlike spam
that takes you to Nigerian banking scams or offers deals on drugs
like Viagra, these messages offer software to bypass the elaborate
government system that blocks access to the Web sites of opposition
groups like the Falun Gong.
Shiyu Zhou, a computer scientist, is a founder of the Falun Gong's
consortium. His cyber-war with China began in Tiananmen Square in
1989. A college student and the son of a former general in the
intelligence section of the People's Liberation Army, he said he
first understood the power of government-controlled media when
overnight the nation's student protesters were transformed from
heroes to killers.
"I was so disappointed," he said. "People believed the government,
they didn't believe us."
He decided to leave China and study computer science in graduate
school in the United States. In the late 1990s he turned to the
study of Falun Gong and then joined with a small group of
technically sophisticated members of the spiritual group intent on
transmitting millions of e-mail messages to Chinese.
Both he and Peter Yuan Li, another early consortium volunteer, had
attended Tsinghua University--China's Massachusetts Institute of
Technology. Mr. Li, the son of farmers, also came to the United
States to study computer science, then joined Bell Laboratories
before becoming a full-time volunteer.
The risks of building circumvention tools became clear in April 2006
when, Mr. Li later told law enforcement officials, four men invaded
his home in suburban Atlanta, covered his head, beat him, searched
his files and stole two laptop computers. The F.B.I. has made no
arrests in the case and declined to comment. But Mr. Li thinks China
sent the invaders.
Early on, the group of dissidents here had some financial backing
from the International Broadcasting Bureau of the Voice of America
for sending e-mail messages, but the group insists that most of its
effort has been based on volunteer labor and contributions.
The consortium's circumvention system works this way: Government
censorship systems like the Great Firewall can block access to
certain Internet Protocol addresses. The equivalent of phone
numbers, these addresses are quartets of numbers like 209.85.171.100
that identify a Web site, in this case, google.com. By clicking on a
link provided in the consortium's e-mail message, someone in China
or Iran trying to reach a forbidden Web site can download software
that connects to a computer abroad that then redirects the request
to the site's forbidden address.
The technique works like a basketball bank shot--with the remote
computer as the backboard and the desired Web site as the basket.
But government systems hunt for and then shut off such alternative
routes using a variety of increasingly sophisticated techniques. So
the software keeps changing the Internet address of the remote
computer--more than once a second. By the time the censors
identify an address, the system has already changed it.
China acknowledges that it monitors content on the Internet, but
claims to have an agenda much like that of any other country:
policing for harmful material, pornography, treasonous propaganda,
criminal activity, fraud. The government says Falun Gong is a
dangerous cult that has ruined the lives of thousands of people.
Hoping to step up its circumvention efforts, the Falun Gong last
year organized extensive lobbying in Congress, which approved $15
million for circumvention services.
But the money was awarded not to the Falun Gong consortium but to
Internews, an international organization that supports local media
This year, a broader coalition is organizing to push for more
Congressional financing of anti-filtering efforts. Negotiations are
under way to bring together dissidents of Vietnam, Iran, the Uighur
minority of China, Tibet, Myanmar, Cuba, Cambodia, Laos, as well as
the Falun Gong, to lobby Congress for the financing.
Mr. Horowitz argues that $25 million could expand peak usage to as
many as 45 million daily Internet users, allowing the systems to
reach as many as 10 percent of the Web users in both China and Iran.
Mr. Zhou says his group's financing is money well spent. "The entire
battle over the Internet has boiled down to a battle over
resources," he said. "For every dollar we spend, China has to spend
a hundred, maybe hundreds of dollars."
As for the Falun Gong software, it proved a little too popular among
Iranians. By the end of last year the consortium's computers were
overwhelmed. On Jan. 1, the consortium had to do some blocking of
its own: It shut down the service for all countries except China.
tt mailing list
tt at postbiota.org

@_date: 2010-12-02 04:40:13
@_author: Premise Checker 
@_subject: [tt] Tech Republic: You are probably breaking at least one law with 
You are probably breaking at least one law with your computer right now
* Date: November 24th, 2010
* Author: Deb Shinder
For many years, the Internet was the "final frontier," operating
largely unregulated--in part because of the jurisdictional
nightmare involved in trying to enforce laws when communications
crossed not just state lines but also national boundaries. That was
then; this is now. Legislation that affects the use of
Internet-connected computers is springing up everywhere at the
local, state and federal levels. You might be violating one of them
without even knowing.
In this article, we'll take a look at some of the existing laws and
some of the pending legislation that can influence how we use our
computers and the Internet. Nothing in this article should be
construed as legal advice; this is merely an overview of some of the
legislation that's out there, how it has been interpreted by the
courts (if applicable), and possible implications for computer
Note: This article is also available as a [49]PDF download and was
originally published in the [50]10 Things Blog in March 2010.
1: Digital Millennium Copyright (DMCA) Act
Most computer users have heard of this law, signed in 1998 by
President Clinton, implementing two World Intellectual Property
Organization (WIPO) treaties. The DMCA makes it a criminal offense
to circumvent any kind of technological copy protection--even if
you don't violate anyone's copyright in doing so. In other words,
simply disabling the copy protection is a federal crime.
There are some exemptions, such as circumventing copy protection of
programs that are in an obsolete format for the purpose of archiving
or preservation. But in most cases, using any sort of anti-DRM
program is illegal. This applies to all sorts of copy-protected
files, including music, movies, and software. You can read a summary
of the DMCA [51]here.
If you're a techie who likes the challenge of trying to "crack" DRM,
be aware that doing so--even if you don't make or distribute
illegal copies of the copyrighted material--is against the law.
2: No Electronic Theft (NET) Act
This is another U.S. federal law that was passed during the Clinton
administration. Prior to this act, copyright violations were
generally treated as civil matters and could not be prosecuted
criminally unless it was done for commercial purposes. The NET Act
made copyright infringement itself a federal criminal offense,
regardless of whether you circumvent copy-protection technology and
whether you derive any commercial benefit or monetary gain. Thus,
just making a copy of a copyrighted work for a friend now makes you
subject to up to five years in prison and/or up to $250,000 in
fines. This is the law referred to in the familiar "FBI Warning"
that appears at the beginning of most DVD movies. You can read more
about the NET Act [52]here.
Many people who consider themselves upstanding citizens and who
would never post music and movies to a P2P site think nothing of
burning a copy of a song or TV show for a friend. Unfortunately, by
the letter of the law, the latter is just as illegal as the former.
3: Anti-Counterfeiting Trade Agreement (ACTA)
This treaty is still in negotiation between the United States,
European Commission, Switzerland, Japan, Australia, Canada, Jordan,
Mexico, Morocco, New Zealand, the Republic of Korea, Singapore, and
the United Arab Emirates. The most recent round of negotiations took
place in Mexico in January 2010, and the next is scheduled for April
2010 in New Zealand.
As with the DMCA, many regard the ACTA as a workaround for
governments to impose regulations and penalties through
international treaties that they would not be able to pass into law
through their regular legislative processes. ACTA covers a number of
areas, including counterfeit products and generic medicines, but the
part that affects computer users is the chapter titled "Enforcement
of Intellectual Property Rights."
Although the treaty negotiations are conducted in secret, a leaked
document indicated that one provision in the treaty would force ISPs
to give information about customers suspected of copyright
infringement without requiring a warrant. According to reports,
another provision would allow customs agents to conduct random
searches of laptops, MP3 players, and cell phones for illegally
downloaded or ripped music and movies. Not surprisingly, the
Recording Industry Association of America (RIAA) is a supporter of
the treaty. The Electronic Frontier Foundation (EFF) opposes it, as
does the Free Software Foundation. You can read the EFF's stance on
ACTA [53]here.
4: Court rulings regarding border searches
Most Americans are aware of the protections afforded by the U.S.
Constitution's fourth amendment against unreasonable searches and
seizures. In general, this means that the government cannot search
your person, home, vehicle, or computer without probable cause to
believe that you've engaged in some criminal act.
What many don't know is that there are quite a few circumstances
that the Courts, over the years, have deemed to be exempt from this
requirement. One of those occurs when you enter the United States at
the border. In April 2008, the Ninth Circuit Court of Appeals upheld
the right of Customs officers to search laptops and other digital
devices at the border (the definition of which extends to any
international airport when you are coming into the country) without
probable cause or even the lesser standard of reasonable suspicion.
The Electronic Frontier Foundation (EFF) and other groups strongly
disagree with the ruling. You can [54]read more on the EFF Web site.
Meanwhile, be aware that even though you've done nothing illegal and
are not even suspected of such, the entire contents of your portable
computer, PDA, or smart phone can be accessed by government agents
when you enter the Unites States. So if you have anything on your
hard drive that could be embarrassing, you might want to delete it
before crossing the border.
Stay on top of the latest Microsoft Windows tips and tricks with
TechRepublic's Windows Desktop newsletter, delivered every Monday
and Thursday. [55]Automatically sign up today!
5: State and federal laws regarding access to networks
Many states have criminal laws that prohibit accessing any computer
or network without the owner's permission. For example, in Texas,
the statute is Penal Code section 33.02, Breach of Computer
Security. It says, "A person commits an offense if the person
knowingly accesses a computer, computer network or computer system
without the effective consent of the owner." The penalty grade
ranges from misdemeanor to first degree felony (which is the same
grade as murder), depending on whether the person obtains benefit,
harms or defrauds someone, or alters, damages, or deletes files.
The wording of most such laws encompass connecting to a wireless
network without explicit permission, even if the Wi-Fi network is
unsecured. The inclusion of the culpable mental state of "knowing"
as an element of the offense means that if your computer
automatically connects to your neighbor's wireless network instead
of your own and you aren't aware of it, you haven't committed a
crime. But if you decide to hop onto the nearest unencrypted Wi-Fi
network to surf the Internet, knowing full well that it doesn't
belong to you and no one has given you permission, you could be
prosecuted under these laws.
[56]A Michigan man was arrested for using a cafi's Wi-Fi network
(which was reserved for customers) from his car in 2007. Similar
arrests have been made in Florida, Illinois, Washington, and Alaska.
The federal law that covers unauthorized access is Title 18 U.S.C.
Section 1030, which prohibits intentionally accessing a computer
without authorization or exceeding authorized access. But it applies
to "protected computers," which are defined as those used by the
U.S. government, by a financial institution, or used in or affecting
interstate or foreign commerce. In addition to fines and
imprisonment, penalties include forfeiture of any personal property
used to commit the crime or derived from proceeds traceable to any
violation. You can read the text of that section [57]here.
In [58]a recent case regarding unauthorized access, a high profile
lawsuit was filed against a school district in Pennsylvania by
students who alleged that district personnel activated their
school-issued laptops in their homes and spied on them with the
laptops' webcams. The FBI is investigating to determine whether any
criminal laws were broken. Because the school district owned the
computers, there is controversy over whether they had the right to
remotely access them without the permission of the users.
6: "Tools of a crime" laws
Some states have laws that make it a crime to possess a "criminal
instrument" or the "tool of a crime." Depending on the wording of
the law, this can be construed to mean any device that is designed
or adapted for use in the commission of an offense. This means you
could be arrested and prosecuted, for example, for constructing a
high gain wireless antenna for the purpose of tapping into someone
else's Wi-Fi network, even if you never did in fact access a
network. Several years ago, a California sheriff's deputy made the
news when he declared [59]Pringles can antennas illegal under such a
7: Cyberstalking and Cyberbullying laws
Stalking is a serious crime and certainly all of us are in favor of
laws that punish stalkers. As Internet connectivity has become
ubiquitous, legislatures have recognized that it's possible to stalk
someone from afar using modern technology. Some of the
"cyberstalking" laws enacted by the states, however, contain some
pretty broad language.
For example, the Arkansas law contains a section titled "Unlawful
computerized communications" that makes it a crime to send a message
via email or other computerized communication system (Instant
Messenger, Web chat, IRC, etc.) that uses obscene, lewd, or profane
language, with the intent to frighten, intimidate, threaten, abuse,
or harass another person. Some of the lively discussions on mailing
lists and Web boards that deteriorate into flame wars could easily
fall under that definition. Or how about the furious email letter
you sent to the company that refused to refund your money for the
shoddy product you bought?
Closely related are the [60]laws against cyberbullying. Such laws
have been passed by some states and local governments. In April
2009, the [61]Megan Meier Cyberbullying Prevention Act (H.R. 1966)
was introduced in the U.S. Congress. The act would make it a federal
crime to "intimidate, harass, or cause substantial emotional
distress to another person, using electronic means to support
severe, repeated and hostile behavior." Subcommittee hearings have
been held and the bill is continuing through the legislative
Opponents of the proposed law point out that the language is open to
interpretation, and could be construed to apply to someone who
merely gets into heated discussions on a web board or email list.
The best policy is to watch your language when sending any type of
electronic communications. Not only can a loss of temper when you're
online come back to embarrass you, it could even get you thrown in
8: Internet gambling laws
Like to play poker online or bet on the horse races from the comfort
of your home? The federal [62]Unlawful Internet Gambling Enforcement
Act of 2006 criminalizes acceptance of funds from bettors--but
what about the bettors themselves? Are they committing a crime?
Under this federal law, the answer is no, but some state laws do
apply to the person placing the bet. For example, a Washington law
passed in 2006 makes gambling on the Internet a felony. The King
County Superior Court just [63]recently upheld that law, although
challengers have vowed to take it to the Supreme Court. Be sure to
check out the state and local laws before you make that friendly
online bet.
9: Child pornography laws
We all want to protect children and keep pedophiles away from them,
but could you be arrested for possession of child pornography or for
exposing children to pornography even though you would never
voluntarily indulge in such a thing? Unfortunately, as the laws are
written and enforced, the answer is "yes." In January 2007, a
substitute teacher in Norwich, CT, was convicted of four felony
pornography charges, although she claimed the offending pictures
were the result of pop-ups and that she did not knowingly access the
Web sites in question. The [64]conviction was set aside after
forensics and security experts examined her hard drive and found the
school's antivirus software was out of date and the computer had no
anti-spyware, firewall, or pop-up blocking technology. The teacher
ended up pleading guilty to a misdemeanor charge.
Pornographic images of children are illegal to possess. This
includes not just photographs of actual children, but also
computer-generated pictures and drawings in which no real people are
involved and photos of models who are of adult age but look like
children. There are many ways such images can get on a computer.
Viruses can infect your system and allow another person to remotely
access your hard drive. Your computer can be taken over to become a
bot, controlled by someone else without your knowledge. Someone can
email you an illegal image. You can click a link on a
non-pornographic Web site that takes you to a site where the illegal
images are displayed, and they're then downloaded into your Web
cache on your hard drive.
In another 2007 case, [65]a 16-year-old was charged with possession
of child pornography and got 18 months probation and over a quarter
of a million dollars in legal fees, even though he passed polygraph
tests in which he denied knowledge of the images and an examination
of the hard drive found more than 200 infected files and no
10: Pro IP Act
Returning to the copyright front, the Prioritizing Resources and
Organization for Intellectual Property Act (Pro IP Act), which was
signed into law in 2008, imposes stricter penalties for copyright
infringement. It created a new position of "copyright enforcement
czar" (formally called the Intellectual Property Enforcement
Coordinator) in the federal bureaucracy and gives law enforcement
agents the right to seize property from copyright infringers.
This may all sound fine in theory, but when you look at the way
other seizure and forfeiture laws have been applied (for instance,
the ability of drug enforcement officers to seize houses, computers,
cars, cash, and just about everything else that belongs to someone
tagged as a suspected drug dealer--and in some cases, not
returning the property even when the person is acquitted or not
prosecuted), it makes many people wary. Read more about the bill
Some local jurisdictions have also established [67]seizure authority
for piracy. In September 2009, Victoria Espinel was appointed as the
[68]first copyright czar. She has asked for public input by March
24, 2010.
49. 50. 51. 52. 53. 54.  55. 56.  57. 58. 59. 60.  61. 62. 63.  64. 65. 66.  67.  68.  tt mailing list
tt at postbiota.org

@_date: 2010-12-17 18:14:26
@_author: Premise Checker 
@_subject: [tt] NYT: New Advice for Nuclear Strike: Don't Flee, Get Inside 
New Advice for Nuclear Strike: Don't Flee, Get Inside
U.S. Rethinks Strategy for the Unthinkable
By WILLIAM J. BROAD
Suppose the unthinkable happened, and terrorists struck New York or
another big city with an atom bomb. What should people there do? The
government has a surprising new message: Do not flee. Get inside any
stable building and don't come out till officials say it's safe.
The advice is based on recent scientific analyses showing that a
nuclear attack is much more survivable if you immediately shield
yourself from the lethal radiation that follows a blast, a simple
tactic seen as saving hundreds of thousands of lives. Even staying
in a car, the studies show, would reduce casualties by more than 50
percent; hunkering down in a basement would be better by far.
But a problem for the Obama administration is how to spread the word
without seeming alarmist about a subject that few politicians care
to consider, let alone discuss. So officials are proceeding gingerly
in a campaign to educate the public.
"We have to get past the mental block that says it's too terrible to
think about," W. Craig Fugate, administrator of the Federal
Emergency Management Agency, said in an interview. "We have to be
ready to deal with it" and help people learn how to "best protect
Officials say they are moving aggressively to conduct drills,
prepare communication guides and raise awareness among emergency
planners of how to educate the public.
Over the years, Washington has sought to prevent nuclear terrorism
and limit its harm, mainly by governmental means. It has spent tens
of billions of dollars on everything from intelligence and securing
nuclear materials to equipping local authorities with radiation
The new wave is citizen preparedness. For people who survive the
initial blast, the main advice is to fight the impulse to run and
instead seek shelter from lethal radioactivity. Even a few hours of
protection, officials say, can greatly increase survival rates.
Administration officials argue that the cold war created an
unrealistic sense of fatalism about a terrorist nuclear attack.
"It's more survivable than most people think," said an official
deeply involved in the planning, who spoke on the condition of
anonymity. "The key is avoiding nuclear fallout."
The administration is making that argument with state and local
authorities and has started to do so with the general public as
well. Its Citizen Corps Web site says a nuclear detonation is
"potentially survivable for thousands, especially with adequate
shelter and education." A color illustration shows which kinds of
buildings and rooms offer the best protection from radiation.
In June, the administration released to emergency officials around
the nation an unclassified planning guide 130 pages long on how to
respond to a nuclear attack. It stressed citizen education, before
any attack.
Without that knowledge, the guide added, "people will be more likely
to follow the natural instinct to run from danger, potentially
exposing themselves to fatal doses of radiation."
Specialists outside of Washington are divided on the initiative. One
group says the administration is overreacting to an atomic threat
that is all but nonexistent.
Peter Bergen, a fellow at the New America Foundation and New York
University's Center on Law and Security, recently argued that the
odds of any terrorist group obtaining a nuclear weapon are "near
zero for the foreseeable future."
But another school says that the potential consequences are so high
that the administration is, if anything, being too timid.
"There's no penetration of the message coming out of the federal
government," said Irwin Redlener, a doctor and director of the
National Center for Disaster Preparedness at Columbia University.
"It's deeply frustrating that we seem unable to bridge the gap
between the new insights and using them to inform public policy."
White House officials say they are aware of the issue's political
delicacy but are nonetheless moving ahead briskly.
The administration has sought "to enhance national resilience--to
withstand disruption, adapt to change and rapidly recover," said
Brian Kamoie, senior director for preparedness policy at the
National Security Council. He added, "We're working hard to involve
individuals in the effort so they become part of the team in terms
of emergency management."
A nuclear blast produces a blinding flash, burning heat and crushing
wind. The fireball and mushroom cloud carry radioactive particles
upward, and the wind sends them near and far.
The government initially knew little about radioactive fallout. But
in the 1950s, as the cold war intensified, scientists monitoring
test explosions learned that the tiny particles throbbed with
fission products--fragments of split atoms, many highly
radioactive and potentially lethal.
But after a burst of interest in fallout shelters, the public and
even the government grew increasingly skeptical about civil defense
as nuclear arsenals grew to hold thousands of warheads.
In late 2001, a month after the Sept. 11 attacks, the director of
central intelligence told President George W. Bush of a secret
warning that Al Qaeda had hidden an atom bomb in New York City. The
report turned out to be false. But atomic jitters soared.
"History will judge harshly those who saw this coming danger but
failed to act," Mr. Bush said in late 2002.
In dozens of programs, his administration focused on prevention but
also dealt with disaster response and the acquisition of items like
radiation detectors.
"Public education is key," Daniel J. Kaniewski, a security expert at
George Washington University, said in an interview. "But it's easier
for communities to buy equipment--and look for tech solutions--
because there's Homeland Security money and no shortage of
contractors to supply the silver bullet."
After Hurricane Katrina in 2005 revealed the poor state of disaster
planning, public and private officials began to question national
preparedness for atomic strikes. Some noted conflicting federal
advice on whether survivors should seek shelter or try to evacuate.
In 2007, Congress appropriated $5.5 million for studies on atomic
disaster planning, noting that "cities have little guidance
available to them."
The Department of Homeland Security financed a multiagency modeling
effort led by the Lawrence Livermore National Laboratory in
California. The scientists looked at Washington, New York, Chicago,
Los Angeles and other big cities, using computers to simulate
details of the urban landscape and terrorist bombs.
The results were revealing. For instance, the scientists found that
a bomb's flash would blind many drivers, causing accidents and
complicating evacuation.
The big surprise was how taking shelter for as little as several
hours made a huge difference in survival rates.
"This has been a game changer," Brooke Buddemeier, a Livermore
health physicist, told a Los Angeles conference. He showed a slide
labeled "How Many Lives Can Sheltering Save?"
If people in Los Angeles a mile or more from ground zero of an
attack took no shelter, Mr. Buddemeier said, there would be 285,000
casualties from fallout in that region.
Taking shelter in a place with minimal protection, like a car, would
cut that figure to 125,000 deaths or injuries, he said. A shallow
basement would further reduce it to 45,000 casualties. And the core
of a big office building or an underground garage would provide the
best shelter of all.
"We'd have no significant exposures," Mr. Buddemeier told the
conference, and thus virtually no casualties from fallout.
On Jan. 16, 2009--four days before Mr. Bush left office--the
White House issued a 92-page handbook lauding "pre-event
preparedness." But it was silent on the delicate issue of how to
inform the public.
Soon after Mr. Obama arrived at the White House, he embarked a
global campaign to fight atomic terrorism and sped up domestic
planning for disaster response. A senior official, who spoke on the
condition of anonymity, said the new administration began a revision
of the Bush administration's handbook to address the issue of public
"We started working on it immediately," the official said. "It was
recognized as a key part of our response."
The agenda hit a speed bump. Las Vegas was to star in the nation's
first live exercise meant to simulate a terrorist attack with an
atom bomb, the test involving about 10,000 emergency responders. But
casinos and businesses protested, as did Senator Harry Reid of
Nevada. He told the federal authorities that it would scare away
Late last year, the administration backed down.
"Politics overtook preparedness," said Mr. Kaniewski of George
Washington University.
When the administration came out with its revised planning guide in
June, it noted that "no significant federal response" after an
attack would be likely for one to three days.
The document said that planners had an obligation to help the public
"make effective decisions" and that messages for predisaster
campaigns might be tailored for schools, businesses and even water
"The most lives," the handbook said, "will be saved in the first 60
minutes through sheltering in place."
tt mailing list
tt at postbiota.org

@_date: 2011-06-20 16:46:50
@_author: Premise Checker 
@_subject: [tt] NYT: Microdrones, Some as Small as Bugs, 
Microdrones, Some as Small as Bugs, Are Poised to Alter War
By ELISABETH BUMILLER and THOM SHANKER
WRIGHT-PATTERSON AIR FORCE BASE, Ohio--Two miles from the cow
pasture where the Wright Brothers learned to fly the first
airplanes, military researchers are at work on another revolution in
the air: shrinking unmanned drones, the kind that fire missiles into
Pakistan and spy on insurgents in Afghanistan, to the size of
insects and birds.
The base's indoor flight lab is called the "microaviary," and for
good reason. The drones in development here are designed to
replicate the flight mechanics of moths, hawks and other inhabitants
of the natural world. "We're looking at how you hide in plain
sight," said Greg Parker, an aerospace engineer, as he held up a
prototype of a mechanical hawk that in the future might carry out
espionage or kill.
Half a world away in Afghanistan, Marines marvel at one of the new
blimplike spy balloons that float from a tether 15,000 feet above
one of the bloodiest outposts of the war, Sangin in Helmand
Province. The balloon, called an aerostat, can transmit live video
--from as far as 20 miles away--of insurgents planting homemade
bombs. "It's been a game-changer for me," Capt. Nickoli Johnson said
in Sangin this spring. "I want a bunch more put in."
the way America fights and thinks about its wars. Predator drones,
the Cessna-sized workhorses that have dominated unmanned flight
since the Sept. 11, 2001, attacks, are by now a brand name, known
and feared around the world. But far less widely known are the sheer
size, variety and audaciousness of a rapidly expanding drone
universe, along with the dilemmas that come with it.
The Pentagon now has some 7,000 aerial drones, compared with fewer
than 50 a decade ago. Within the next decade the Air Force
anticipates a decrease in manned aircraft but expects its number of
"multirole" aerial drones like the Reaper--the ones that spy as
well as strike--to nearly quadruple, to 536. Already the Air Force
is training more remote pilots, 350 this year alone, than fighter
and bomber pilots combined.
"It's a growth market," said Ashton B. Carter, the Pentagon's chief
weapons buyer.
The Pentagon has asked Congress for nearly $5 billion for drones
next year, and by 2030 envisions ever more stuff of science fiction:
"spy flies" equipped with sensors and microcameras to detect
enemies, nuclear weapons or victims in rubble. Peter W. Singer, a
scholar at the Brookings Institution and the author of "Wired for
War," a book about military robotics, calls them "bugs with bugs."
In recent months drones have been more crucial than ever in fighting
wars and terrorism. The Central Intelligence Agency spied on Osama
bin Laden's compound in Pakistan by video transmitted from a new
bat-winged stealth drone, the RQ-170 Sentinel, otherwise known as
the "Beast of Kandahar," named after it was first spotted on a
runway in Afghanistan. One of Pakistan's most wanted militants,
Ilyas Kashmiri, was reported dead this month in a C.I.A. drone
strike, part of an aggressive drone campaign that administration
officials say has helped paralyze Al Qaeda in the region--and has
become a possible rationale for an accelerated withdrawal of
American forces from Afghanistan. More than 1,900 insurgents in
Pakistan's tribal areas have been killed by American drones since
2006, according to the Web site In April the United States began using armed Predator drones against
Col. Muammar el-Qaddafi's forces in Libya. Last month a C.I.A.-armed
Predator aimed a missile at Anwar al-Awlaki, the radical
American-born cleric believed to be hiding in Yemen. The Predator
missed, but American drones continue to patrol Yemen's skies.
Large or small, drones raise questions about the growing disconnect
between the American public and its wars. Military ethicists concede
that drones can turn war into a video game, inflict civilian
casualties and, with no Americans directly at risk, more easily draw
the United States into conflicts. Drones have also created a crisis
of information for analysts on the end of a daily video deluge. Not
least, the Federal Aviation Administration has qualms about
expanding their test flights at home, as the Pentagon would like.
Last summer, fighter jets were almost scrambled after a rogue Fire
Scout drone, the size of a small helicopter, wandered into
Washington's restricted airspace.
Within the military, no one disputes that drones save American
lives. Many see them as advanced versions of "stand-off weapons
systems," like tanks or bombs dropped from aircraft, that the United
States has used for decades. "There's a kind of nostalgia for the
way wars used to be," said Deane-Peter Baker, an ethics professor at
the United States Naval Academy, referring to noble notions of
knight-on-knight conflict. Drones are part of a post-heroic age, he
said, and in his view it is not always a problem if they lower the
threshold for war. "It is a bad thing if we didn't have a just cause
in the first place," Mr. Baker said. "But if we did have a just
cause, we should celebrate anything that allows us to pursue that
just cause."
To Mr. Singer of Brookings, the debate over drones is like debating
the merits of computers in 1979: They are here to stay, and the boom
has barely begun. "We are at the Wright Brothers Flier stage of
this," he said.
Mimicking Insect Flight
A tiny helicopter is buzzing menacingly as it prepares to lift off
in the Wright-Patterson aviary, a warehouse-like room lined with 60
motion-capture cameras to track the little drone's every move. The
helicopter, a footlong hobbyists' model, has been programmed by a
computer to fly itself. Soon it is up in the air making purposeful
figure eights.
"What it's doing out here is nothing special," said Dr. Parker, the
aerospace engineer. The researchers are using the helicopter to test
technology that would make it possible for a computer to fly, say, a
drone that looks like a dragonfly. "To have a computer do it 100
percent of the time, and to do it with winds, and to do it when it
doesn't really know where the vehicle is, those are the kinds of
technologies that we're trying to develop," Dr. Parker said.
The push right now is developing "flapping wing" technology, or
recreating the physics of natural flight, but with a focus on
insects rather than birds. Birds have complex muscles that move
their wings, making it difficult to copy their aerodynamics.
Designing insects is hard, too, but their wing motions are simpler.
"It's a lot easier problem," Dr. Parker said.
In February, researchers unveiled a hummingbird drone, built by the
firm AeroVironment for the secretive Defense Advanced Research
Projects Agency, which can fly at 11 miles per hour and perch on a
windowsill. But it is still a prototype. One of the smallest drones
in use on the battlefield is the three-foot-long Raven, which troops
in Afghanistan toss by hand like a model airplane to peer over the
next hill.
There are some 4,800 Ravens in operation in the Army, although
plenty get lost. One American service member in Germany recalled how
five soldiers and officers spent six hours tramping through a dark
Bavarian forest--and then sent a helicopter--on a fruitless
search for a Raven that failed to return home from a training
exercise. The next month a Raven went AWOL again, this time because
of a programming error that sent it south. "The initial call I got
was that the Raven was going to Africa," said the service member,
who asked for anonymity because he was not authorized to discuss
drone glitches.
In the midsize range: The Predator, the larger Reaper and the
smaller Shadow, all flown by remote pilots using joysticks and
computer screens, many from military bases in the United States. A
Navy entry is the X-47B, a prototype designed to take off and land
from aircraft carriers automatically and, when commanded, drop
bombs. The X-47B had a maiden 29-minute flight over land in
February. A larger drone is the Global Hawk, which is used for
keeping an eye on North Korea's nuclear weapons activities. In
March, the Pentagon sent a Global Hawk over the stricken Fukushima
Daiichi nuclear plant in Japan to assess the damage.
A Tsunami of Data
The future world of drones is here inside the Air Force headquarters
at Joint Base Langley-Eustis, Va., where hundreds of flat-screen TVs
hang from industrial metal skeletons in a cavernous room, a scene
vaguely reminiscent of a rave club. In fact, this is one of the most
sensitive installations for processing, exploiting and disseminating
a tsunami of information from a global network of flying sensors.
The numbers are overwhelming: Since the Sept. 11 attacks, the hours
the Air Force devotes to flying missions for intelligence,
surveillance and reconnaissance have gone up 3,100 percent, most of
that from increased operations of drones. Every day, the Air Force
must process almost 1,500 hours of full-motion video and another
1,500 still images, much of it from Predators and Reapers on
around-the-clock combat air patrols.
The pressures on humans will only increase as the military moves
from the limited "soda straw" views of today's sensors to new
"Gorgon Stare" technology that can capture live video of an entire
city--but that requires 2,000 analysts to process the data feeds
from a single drone, compared with 19 analysts per drone today.
At Wright-Patterson, Maj. Michael L. Anderson, a doctoral student at
the base's advanced navigation technology center, is focused on
another part of the future: building wings for a drone that might
replicate the flight of the hawk moth, known for its hovering
skills. "It's impressive what they can do," Major Anderson said,
"compared to what our clumsy aircraft can do."
tt mailing list
tt at postbiota.org

@_date: 2011-10-30 00:48:20
@_author: Premise Checker 
@_subject: [tt] NS 2836: Inside Facebook's massive cyber-security system 
NS 2836: Inside Facebook's massive cyber-security system
* 17:20 26 October 2011 by Jim Giles
FACEBOOK has released details of the extraordinary security
infrastructure it uses to fight off spam and other cyber-scams.
Known as the Facebook Immune System (FIS), the massive defence
network appears to be successful: numbers released by the company
this week show that less than 1 per cent of users experience spam.
Yet it's not perfect. Researchers have built a novel attack that
evaded the cyber-defences and extracted private material from real
users' Facebook accounts.
It took just three years for FIS to evolve from basic beginnings
into an all-seeing set of algorithms that monitors every photo
posted to the network, every status update- indeed, every click made
by every one of the 800 million users. There are more than 25
billion of these "read and write actions" every day. At peak
activity the system checks 650,000 actions a second.
"It's a big challenge," says Jim Larus, a Microsoft researcher in
Redmond, Washington, who studies large networks. The only network
bigger, Larus suspects, is the web itself. That makes Facebook's
defence system one of the largest in existence.
It protects against scams by harnessing artificially intelligent
software to detect suspicious patterns of behaviour. The system is
overseen by a team of 30 people, but it can learn in real time and
is able to take action without checking with a human supervisor.
One notable attack took place in April, says [10]Tao Stein, a
Facebook engineer who works on the system. It began when several
users were duped into copying computer code into their browser's
address bar. The code commandeered the person's Facebook account,
and started sending chat messages to their friends saying things
like "I just got a free iPad", along with a link where the friends
could go to get their own. Friends who clicked on the link went to a
site that encouraged them to paste the same code into their
browsers, further spreading the plague. "Attacks like these can
generate millions of messages per minute," says Stein.
[10] Users are less likely to fall for a similar tactic when using email,
because the message would probably be sent by a stranger.
But inside Facebook's network it's much more persuasive. "It's
easier to exploit trust relationships in online social networks,"
says Justin Ma, a computer scientist at the University of
California, Berkeley, who develops methods to combat email spam.
To tackle the attack, FIS generated a signature that it used to
differentiate between spam and legitimate messages. This was based
on the links in the spam messages, keywords like "free" and "iPad",
and the IP addresses of the computers sending the messages.
But spammers can use multiple machines to switch IP addresses, and
link redirection services like [11]bit.ly can change links on the
fly. So FIS checked to see which messages were being flagged as spam
by users and blocked messages with similar keywords in the text.
Together with other features of the message, which Facebook declined
to discuss for fear of aiding spammers, the system was able to begin
developing a signature to identify the spam within seconds of the
attack emerging.
[11] Facebook said this week that, thanks to FIS, less than 4 per cent of
the network's messages are spam and that fewer than 1 in 200 users
experience spam on any given day. "It's pretty good," says Ma, who
has a Facebook account. "I'm pretty happy with the level of
Yet like any defence based on patterns of known behaviour, FIS is
vulnerable to strategies it has not seen before. Yazan Boshmaf and
colleagues at the University of British Columbia in Vancouver,
Canada, [12]have exploited this and eluded the system by creating
"socialbots"- software that can pose as a human and control a
Facebook account.
[12] The bots began by sending friend requests to random users, around 1
in 5 of whom accepted. They then sent requests to the friends of the
people they had connected with, and the acceptance rate jumped to
almost 60 per cent. After seven weeks the team's 102 bots had made a
combined 3000 friends.
Facebook's privacy settings allow users to shield personal
information from public view. But because the socialbots posed as
friends, they were able to extract some 46,500 email addresses and
14,500 physical addresses from users' profiles- information that
could be used to launch phishing attacks or aid in identity theft.
"An attacker could do many things with this data," says Boshmaf, who
will present the team's work at the Annual Computer Security
Applications Conference in Orlando, Florida, next month.
A socialbot attack is yet to happen, but it's only a matter of time.
Socialbots behave differently to humans that enter Facebook for the
first time, in part because they have no real-world friends to
connect with, and their random requests lead to an unusually high
number of rejections. FIS would be able to use this pattern to
recognise and block an attack of socialbots, says Stein. That would
put Facebook back on top- if only until hackers release their next
tt mailing list
tt at postbiota.org

@_date: 2013-08-11 22:02:47
@_author: Frank Forman 
@_subject: [tt] NS 2929: Meshnet activists rebuilding the internet from scratch 
NS 2929: Meshnet activists rebuilding the internet from scratch
* 08 August 2013 by Hal Hodson
Worried about the NSA snooping on your email? Maybe you need to start
creating your own personal internet
THE internet is neither neutral nor private, in case you were in any
doubt. The US National Security Agency can reportedly collect nearly
everything a user does on the net, while internet service providers
(ISPs) move traffic according to business agreements, rather than
what is best for its customers. So some people have decided to take
matters into their own hands, and are building their own net from
Across the US, from Maryland to Seattle, work is underway to
construct user-owned wireless networks that will permit secure
communication without surveillance or any centralised organisation.
They are known as meshnets and ultimately, if their designers get
their way, they will span the country.
Dan Ryan is one of the leaders of the Seattle Meshnet project, where
sparse coverage already exists thanks to radio links set up by fellow
hackers. Those links mean that instead of communicating through
commercial internet connections, meshnetters can talk to each other
through a channel that they themselves control.
Each node in the mesh, consisting of a radio transceiver and a
computer, relays messages from other parts of the network. If the
data can't be passed by one route, the meshnet finds an alternative
way through to its destination. Ryan says the plan is for the Seattle
meshnet to extend its coverage by linking up two wireless nodes
across Lake Union in downtown Seattle. And over the country at the
University of Maryland, Baltimore County, student Alexander Bauer is
hoping to build a campus meshnet later this year. That will give his
fellow students an alternative communications infrastructure to the
While these projects are just getting off the ground, a mesh network
in Catalonia, Spain, is going from strength to strength. Guifi was
started in the early 2000s by Ramon Roca, an Oracle employee who
wanted broadband at his rural home. The local network now has more
than 21,000 wireless nodes, spanning much of Catalonia. As well as
allowing users to communicate with each other, Guifi also hosts web
servers, videoconferencing services and internet radio broadcasts,
all of which would work if the internet went down for the rest of the
So successful is the community model that Guifi is now building
physical fibre-optic links to places like hospitals and town halls
where it can help carry the heaviest traffic.
Earlier this month, the General Hospital in the Catalan town of Gurb
was wired up to Guifi with a fibre-optic link, and cable is being
rolled out into the nearby town of Calldetenes too.
In the US, people can generally already get online with relative
ease, so meshnets there are less about facilitating access and more
about security, privacy and net neutrality - the idea that ISPs
should treat all traffic equally, and not charge more for certain
After the extent of the NSA's clandestine PRISM program was revealed,
privacy advocates like the Electronic Frontier Foundation urged users
to start using relatively simple email encryption programs like
Pretty Good Privacy and GNU Privacy Guard. But even those can be
daunting to set up. A better idea would be a decentralised network
that relies on encryption by default.
This is the case with Hyperboria, the virtual layer that underpins
meshnet efforts in the US. Hyperboria is a virtual meshnet because it
runs through the existing internet, but is purely peer-to-peer. This
means people who use it exchange information with others directly
over a completely encrypted connection, with nothing readable by any
centralised servers.
When physical meshnet nodes like those in Maryland and Seattle are
set up, existing Hyperboria connections can simply be routed through
them. At the moment, Hyperboria offers a blogging platform, email
services, and even forums similar to reddit.
Encryption is the starting point. Computer researcher Caleb James
DeLisle wrote software called cjdns which allows the Seattle Meshnet
nodes to use Hyperboria and keep all communications between them
encrypted. Instead of letting other computers connect to you through
a shared IP address which anyone can use, cjdns only lets computers
talk to one other after they have verified each other
cryptographically. That means there is no way anyone can be
intercepting your traffic.
The Seattle Meshnet has just completed a successful crowdfunding
campaign for meshboxes - routers that come preloaded with the cjdns
software needed to join Hyperboria. Users will just plug the routers
into their existing internet connection and be ready to go on the
virtual meshnet - or a local physical meshnet when one becomes
Some form of encryption is already in use across much of the
internet, but to be useful it has to be ubiquitous. Web services like
Gmail, for example, let you log in using an encrypted connection. But
when you send an email it leaves Google's encrypted garden and hits
the open web in clear text for anyone to read. With Hyperboria's
peer-to-peer connections, every single link in the chain of
communication is fully encrypted. Intermediaries that handle traffic
cannot even see what kind of traffic it is, let alone read any email.
Use the purpose-built hyperboria.name email service, and your
communication becomes untraceable.
Instead of a few established players building network infrastructure,
DeLisle wants anyone to be able to do it. For him, decentralised
internet access in the hands of the people is just a start. The
services they use must be decentralised, too. "If people continue to
use Facebook, they will continue to be spied on, that's just the
reality of the world."
Into the darknet
Visions of a decentralised internet come with a seedier side - the
darknet. One way to access it is through the anonymising routing
service Tor, which lets a user find hidden web pages that have .onion
addresses, rather than IP addresses. But anonymisation like this can
facilitate otherwise unacceptable activities. Illegal drug market,
Silk Road can only be accessed using its .onion address. But
Alexander Bauer, who works on a meshnet in Maryland thinks meshnets
are less likely to carry this content. Any website that can
successfully run on a meshnet must be socially acceptable to every
peer they connect with, making it less attractive for child
pornographers or websites like Silk Road.
"That's why we don't think the network will be taken over by child
porn. You have to have someone accept what's on your node in order
for them to pass your traffic around," he says.
tt mailing list
tt at postbiota.org

@_date: 2013-08-13 21:19:39
@_author: Frank Forman 
@_subject: [tt] NYT: Microsatellites: What Big Eyes They Have 
Microsatellites: What Big Eyes They Have
By ANNE EISENBERG
PEOPLE already worried about the candid cameras on Google Glass and
low-flying drones can add a new potential snooper to the list:
cameras on inexpensive, low-orbiting microsatellites that will soon
be sending back frequent, low-cost snapshots of most of Earth's
populated regions from space.
They won't be the first cameras out there, of course. Earth-imaging
satellites the size of vans have long circled the globe, but those
cost millions of dollars each to build and launch, in part because
of their weight and specialized hardware. The new satellites, with
some of the same off-the-shelf miniaturized technology that has made
smartphones and laptops so powerful, will be far less expensive.
The view from high up is rich in untapped data, said Paul Saffo, a
forecaster and essayist. He expects the new satellite services to
find many customers.
Insurance companies, for example, could use the satellites' "before"
and "after" views to monitor insured property and validate claims
after a disaster. Businesses that update online maps for geologists,
city planners or disaster relief officials could be customers, too.
The images could also be used to monitor problems like
deforestation, melting icecaps and overfishing.
And food companies and commodities traders could use the images to
keep track of crops and agricultural yields all over the planet, Mr.
Saffo predicted.
But the images are also likely to be viewed as the latest mixed
blessing by people already apprehensive of Big Brother-like
surveillance in their lives.
First into space in the microsatellite business will be the San
Francisco company Planet Labs, which plans to launch a fleet of 28
small satellites at the end of the year that will photograph the
planet around the clock, with frequent updates. The company has
already sent up two trial satellites for test runs, and will
dispatch the entire set, called Flock-1, in December, said Will
Marshall, a co-founder of the company and a former NASA scientist.
The Planet Labs' satellites won't be able to distinguish your face
or read your license plate--the cameras don't have that level of
resolution. But the frequency with which images can be updated could
raise privacy questions, said Timothy Edgar, a visiting fellow at
the Watson Institute for International Studies at Brown University
and a former director of privacy and civil liberties in the Obama
Mr. Edgar contrasted the satellite images with those provided by
Google Earth--the ones that people zoom in on to see, for example,
an aerial view of their homes."That's just an image of your house
that was probably taken a few years ago," he said. "It may feel like
you are being watched, but you aren't. It's just a static picture
that's most likely several years old."
But a satellite that regularly passes over your cabin deep in the
woods and photographs a car that is sometimes parked there--and
sometimes not--has different ramifications. "It can show a
pattern, for example, when you appear to be at home and when you're
away," he said.
Planet Labs' technology, like that at other microsatellite companies
such as Skybox Imaging, are benefiting from the progressive
miniaturization of consumer electronic components, along with a
federal effort to commercialize space. "What we are seeing are
smaller satellites that have similar capabilities to much larger,
traditional satellites," said Glenn Lightsey, a professor at the
University of Texas who founded and directs the Texas Spacecraft Lab
there. "Since putting a satellite in orbit is a function of its
size, these new satellites are able to get into orbit at a much
lower cost," he said.
The lightweight satellites have another advantage: the companies
don't have to spend millions of dollars for a rocket to get them
into space. Instead, they can hitch a ride as a secondary payload on
a rocket already making the trip. Planet Labs will send its
satellites on an Antares rocket when it heads out on a cargo
transportation flight to the International Space Station.
Investors have flocked to the new satellite companies, though
neither Planet Labs nor Skybox Imaging has disclosed what it will
charge customers. Planet Labs has obtained $13.1 million in funding,
led by Steve Jurvetson, managing director of Draper Fisher
Jurvetson. Other backers include O'Reilly AlphaTech Ventures, Data
Collective and First Round Capital.
Five ground stations will receive the Planet Labs imagery as the
satellites pass overhead. Dr. Marshall would not disclose how often
the satellites would pass the same spot. "The point is that by
putting up lots of satellites, we can image the whole Earth on a
much more frequent basis," he said.
Skybox Imaging, in Mountain View, Calif., aims to provide sharply
detailed images as well as high-definition video with its
satellites. The company, which has raised about $91 million, expects
to put its SkySat-1 and SkySat-2 satellites into orbit later this
year, said Dan Berkenstock, a co-founder, and then follow with a
group totaling 24 satellites. Customers will be able to buy images
or an appliance to download information directly from the satellite.
"They can log onto our satellite and ask it to take pictures," he
Japan Space Imaging, a subsidiary of the Mitsubishi Corporation,
recently signed a contract with Skybox allowing it to directly
downlink imagery for agricultural and maritime monitoring as well as
for disaster response.
Microsatellite services promise a new, accessible way to monitor
global changes such as crop growth, said Anthony Janetos, director
of Boston University's Pardee Center for the Study of the
Longer-Range Future. "You can't understand these forces if you can't
measure them," he said. "These services will be useful in gathering
those measurements."
The new satellites are yet another stage in the expansion of the
human view aided by powerful cameras and digital communication, said
Mitchell Stephens, a journalism professor at New York University and
author of "The Rise of the Image, the Fall of the Word."
This change has pluses and minuses, he observed. People who try to
build a private hideaway in the woods might come to realize that it
isn't so private. But such images could also spot illegal logging in
remote spots.
"Now we can have a Godlike view, looking down from the heavens," he
said. "I can understand why people would be nervous. But the cameras
can make the world more transparent and open. I'm for that."
E-mail: novelties at nytimes.com.
tt mailing list
tt at postbiota.org

@_date: 2013-08-23 00:10:17
@_author: Frank Forman 
@_subject: [tt] Crypto-Gram: August 15, 2013 
Lots of alarming stuff.
Crypto-Gram: August 15, 2013
by Bruce Schneier
BT Security Futurologist
schneier at schneier.com
A free monthly newsletter providing summaries, analyses, insights,
and commentaries on security: computer and otherwise.
In this issue:
* The Public/Private Surveillance Partnership
* The NSA is Commandeering the Internet
* Restoring Trust in Government and the Internet
* News
* Book Review: "Rise of the Warrior Cop"
* Schneier News
* Michael Hayden on the Effects of Snowden's Whistleblowing
* Counterterrorism Mission Creep
The Public/Private Surveillance Partnership
Imagine the government passed a law requiring all citizens to carry
a tracking device. Such a law would immediately be found
unconstitutional. Yet we all carry mobile phones.
If the National Security Agency required us to notify it whenever we
made a new friend, the nation would rebel. Yet we notify Facebook.
If the Federal Bureau of Investigation demanded copies of all our
conversations and correspondence, it would be laughed at. Yet we
provide copies of our e-mail to Google, Microsoft or whoever our
mail host is; we provide copies of our text messages to Verizon,
AT&T and Sprint; and we provide copies of other conversations to
Twitter, Facebook, LinkedIn, or whatever other site is hosting them.
The primary business model of the Internet is built on mass
surveillance, and our government's intelligence-gathering agencies
have become addicted to that data. Understanding how we got here is
critical to understanding how we undo the damage.
Computers and networks inherently produce data, and our constant
interactions with them allow corporations to collect an enormous
amount of intensely personal data about us as we go about our daily
lives. Sometimes we produce this data inadvertently simply by using
our phones, credit cards, computers and other devices. Sometimes we
give corporations this data directly on Google, Facebook, Apple
Inc.'s iCloud and so on in exchange for whatever free or cheap
service we receive from the Internet in return.
The NSA is also in the business of spying on everyone, and it has
realized it's far easier to collect all the data from these
corporations rather than from us directly. In some cases, the NSA
asks for this data nicely. In other cases, it makes use of subtle
threats or overt pressure. If that doesn't work, it uses tools like
national security letters.
The result is a corporate-government surveillance partnership, one
that allows both the government and corporations to get away with
things they couldn't otherwise.
There are two types of laws in the U.S., each designed to constrain
a different type of power: constitutional law, which places
limitations on government, and regulatory law, which constrains
corporations. Historically, these two areas have largely remained
separate, but today each group has learned how to use the other's
laws to bypass their own restrictions. The government uses
corporations to get around its limits, and corporations use the
government to get around their limits.
This partnership manifests itself in various ways. The government
uses corporations to circumvent its prohibitions against
eavesdropping domestically on its citizens. Corporations rely on the
government to ensure that they have unfettered use of the data they
Here's an example: It would be reasonable for our government to
debate the circumstances under which corporations can collect and
use our data, and to provide for protections against misuse. But if
the government is using that very data for its own surveillance
purposes, it has an incentive to oppose any laws to limit data
collection. And because corporations see no need to give consumers
any choice in this matter--because it would only reduce their
profits--the market isn't going to protect consumers, either.
Our elected officials are often supported, endorsed and funded by
these corporations as well, setting up an incestuous relationship
between corporations, lawmakers and the intelligence community.
The losers are us, the people, who are left with no one to stand up
for our interests. Our elected government, which is supposed to be
responsible to us, is not. And corporations, which in a market
economy are supposed to be responsive to our needs, are not. What we
have now is death to privacy--and that's very dangerous to
democracy and liberty.
The simple answer is to blame consumers, who shouldn't use mobile
phones, credit cards, banks or the Internet if they don't want to be
tracked. But that argument deliberately ignores the reality of
today's world. Everything we do involves computers, even if we're
not using them directly. And by their nature, computers produce
tracking data. We can't go back to a world where we don't use
computers, the Internet or social networking. We have no choice but
to share our personal information with these corporations, because
that's how our world works today.
Curbing the power of the corporate-private surveillance partnership
requires limitations on both what corporations can do with the data
we choose to give them and restrictions on how and when the
government can demand access to that data. Because both of these
changes go against the interests of corporations and the government,
we have to demand them as citizens and voters. We can lobby our
government to operate more transparently--disclosing the opinions
of the Foreign Intelligence Surveillance Court would be a good start
--and hold our lawmakers accountable when it doesn't. But it's not
going to be easy. There are strong interests doing their best to
ensure that the steady stream of data keeps flowing.
This essay originally appeared on Bloomberg.com.
Corporations collecting data:
Corporations cooperating with the NSA:
How the partnership manifests itself:
Congress attempt to rein in NSA:
The death of privacy:
Disclosing FISA opinions:
The NSA is Commandeering the Internet
It turns out that the NSA's domestic and world-wide surveillance
apparatus is even more extensive than we thought. Bluntly: The
government has commandeered the Internet. Most of the largest
Internet companies provide information to the NSA, betraying their
users. Some, as we've learned, fight and lose. Others cooperate,
either out of patriotism or because they believe it's easier that
I have one message to the executives of those companies: fight.
Do you remember those old spy movies, when the higher ups in
government decide that the mission is more important than the spy's
life? It's going to be the same way with you. You might think that
your friendly relationship with the government means that they're
going to protect you, but they won't. The NSA doesn't care about you
or your customers, and will burn you the moment it's convenient to
do so.
We're already starting to see that. Google, Yahoo, Microsoft and
others are pleading with the government to allow them to explain
details of what information they provided in response to National
Security Letters and other government demands. They've lost the
trust of their customers, and explaining what they do--and don't
do--is how to get it back. The government has refused; they don't
It will be the same with you. There are lots more high-tech
companies who have cooperated with the government. Most of those
company names are somewhere in the thousands of documents that
Edward Snowden took with him, and sooner or later they'll be
released to the public. The NSA probably told you that your
cooperation would forever remain secret, but they're sloppy. They'll
put your company name on presentations delivered to thousands of
people: government employees, contractors, probably even foreign
nationals. If Snowden doesn't have a copy, the next whistleblower
This is why you have to fight. When it becomes public that the NSA
has been hoovering up all of your users' communications and personal
files, what's going to save you in the eyes of those users is
whether or not you fought. Fighting will cost you money in the short
term, but capitulating will cost you more in the long term.
Already companies are taking their data and communications out of
the US.
The extreme case of fighting is shutting down entirely. The secure
e-mail service Lavabit did that last week, abruptly. Ladar Levison,
that site's owner, wrote on his homepage: "I have been forced to
make a difficult decision: to become complicit in crimes against the
American people or walk away from nearly ten years of hard work by
shutting down Lavabit. After significant soul searching, I have
decided to suspend operations. I wish that I could legally share
with you the events that led to my decision."
The same day, Silent Circle followed suit, shutting down their
e-mail service in advance of any government strong-arm tactics: "We
see the writing the wall, and we have decided that it is best for us
to shut down Silent Mail now. We have not received subpoenas,
warrants, security letters, or anything else by any government, and
this is why we are acting now." I realize that this is extreme. Both
of those companies can do it because they're small. Google or
Facebook couldn't possibly shut themselves off rather than cooperate
with the government. They're too large; they're public. They have to
do what's economically rational, not what's moral.
But they can fight. You, an executive in one of those companies, can
fight. You'll probably lose, but you need to take the stand. And you
might win. It's time we called the government's actions what they
really are: commandeering. Commandeering is a practice we're used to
in wartime, where commercial ships are taken for military use, or
production lines are converted to military production. But now it's
happening in peacetime. Vast swaths of the Internet are being
commandeered to support this surveillance state.
If this is happening to your company, do what you can to isolate the
actions. Do you have employees with security clearances who can't
tell you what they're doing? Cut off all automatic lines of
communication with them, and make sure that only specific, required,
authorized acts are being taken on behalf of government. Only then
can you look your customers and the public in the face and say that
you don't know what is going on--that your company has been
Journalism professor Jeff Jarvis recently wrote in the "Guardian":
"Technology companies: now is the moment when you must answer for
us, your users, whether you are collaborators in the US government's
efforts to 'collect it all'--our every move on the internet--or
whether you, too, are victims of its overreach."
So while I'm sure it's cool to have a secret White House meeting
with President Obama--I'm talking to you, Google, Apple, AT&T, and
whoever else was in the room--resist. Attend the meeting, but
fight the secrecy. Whose side are you on?
The NSA isn't going to remain above the law forever. Already public
opinion is changing, against the government and their corporate
collaborators. If you want to keep your users' trust, demonstrate
that you were on their side.
This essay originally appeared on TheAtlantic.com.
Corporations and the NSA surveillance apparatus:
Companies wanting more disclosure:
Whistleblowing as civil disobedience:
Cooperating with NSA surveillance costs companies money:
Silent Circle:
Jarvis essay:
Tech companies meet with Obama:
NSA is a criminal organization:
Regaining trust:
Slashdot thread:
Restoring Trust in Government and the Internet
In July 2012, responding to allegations that the video-chat service
Skype--owned by Microsoft--was changing its protocols to make it
possible for the government to eavesdrop on users, Corporate Vice
President Mark Gillett took to the company's blog to deny it.
Turns out that wasn't quite true.
Or at least he--or the company's lawyers--carefully crafted a
statement that could be defended as true while completely deceiving
the reader. You see, Skype wasn't changing its protocols to make it
possible for the government to eavesdrop on users, because the
government was already able to eavesdrop on users.
At a Senate hearing in March, Director of National Intelligence
James Clapper assured the committee that his agency didn't collect
data on hundreds of millions of Americans. He was lying, too. He
later defended his lie by inventing a new definition of the word
"collect," an excuse that didn't even pass the laugh test.
As Edward Snowden's documents reveal more about the NSA's
activities, it's becoming clear that we can't trust anything anyone
official says about these programs.
Google and Facebook insist that the NSA has no "direct access" to
their servers. Of course not; the smart way for the NSA to get all
the data is through sniffers.
Apple says it's never heard of PRISM. Of course not; that's the
internal name of the NSA database. Companies are publishing reports
purporting to show how few requests for customer-data access they've
received, a meaningless number when a single Verizon request can
cover all of their customers. The Guardian reported that Microsoft
secretly worked with the NSA to subvert the security of Outlook,
something it carefully denies. Even President Obama's justifications
and denials are phrased with the intent that the listener will take
his words very literally and not wonder what they really mean.
NSA Director Gen. Keith Alexander has claimed that the NSA's massive
surveillance and data mining programs have helped stop more than 50
terrorist plots, 10 inside the U.S. Do you believe him? I think it
depends on your definition of "helped." We're not told whether these
programs were instrumental in foiling the plots or whether they just
happened to be of minor help because the data was there. It also
depends on your definition of "terrorist plots." An examination of
plots that that FBI claims to have foiled since 9/11 reveals that
would-be terrorists have commonly been delusional, and most have
been egged on by FBI undercover agents or informants.
Left alone, few were likely to have accomplished much of anything.
Both government agencies and corporations have cloaked themselves in
so much secrecy that it's impossible to verify anything they say;
revelation after revelation demonstrates that they've been lying to
us regularly and tell the truth only when there's no alternative.
There's much more to come. Right now, the press has published only a
tiny percentage of the documents Snowden took with him. And
Snowden's files are only a tiny percentage of the number of secrets
our government is keeping, awaiting the next whistle-blower.
Ronald Reagan once said "trust but verify." That works only if we
can verify. In a world where everyone lies to us all the time, we
have no choice but to trust blindly, and we have no reason to
believe that anyone is worthy of blind trust. It's no wonder that
most people are ignoring the story; it's just too much cognitive
dissonance to try to cope with it.
This sort of thing can destroy our country. Trust is essential in
our society. And if we can't trust either our government or the
corporations that have intimate access into so much of our lives,
society suffers. Study after study demonstrates the value of living
in a high-trust society and the costs of living in a low-trust one.
Rebuilding trust is not easy, as anyone who has betrayed or been
betrayed by a friend or lover knows, but the path involves
transparency, oversight and accountability. Transparency first
involves coming clean. Not a little bit at a time, not only when you
have to, but complete disclosure about everything. Then it involves
continuing disclosure. No more secret rulings by secret courts about
secret laws. No more secret programs whose costs and benefits remain
Oversight involves meaningful constraints on the NSA, the FBI and
others. This will be a combination of things: a court system that
acts as a third-party advocate for the rule of law rather than a
rubber-stamp organization, a legislature that understands what these
organizations are doing and regularly debates requests for increased
power, and vibrant public-sector watchdog groups that analyze and
debate the government's actions.
Accountability means that those who break the law, lie to Congress
or deceive the American people are held accountable. The NSA has
gone rogue, and while it's probably not possible to prosecute people
for what they did under the enormous veil of secrecy it currently
enjoys, we need to make it clear that this behavior will not be
tolerated in the future. Accountability also means voting, which
means voters need to know what our leaders are doing in our name.
This is the only way we can restore trust. A market economy doesn't
work unless consumers can make intelligent buying decisions based on
accurate product information. That's why we have agencies like the
FDA, truth-in-packaging laws and prohibitions against false
In the same way, democracy can't work unless voters know what the
government is doing in their name. That's why we have
open-government laws. Secret courts making secret rulings on secret
laws, and companies flagrantly lying to consumers about the
insecurity of their products and services, undermine the very
foundations of our society.
Since the Snowden documents became public, I have been receiving
e-mails from people seeking advice on whom to trust. As a security
and privacy expert, I'm expected to know which companies protect
their users' privacy and which encryption programs the NSA can't
break. The truth is, I have no idea. No one outside the classified
government world does. I tell people that they have no choice but to
decide whom they trust and to then trust them as a matter of faith.
It's a lousy answer, but until our government starts down the path
of regaining our trust, it's the only thing we can do.
This essay originally appeared on CNN.com.
Skype story:
Clapper story:
Government lies:
How NSA sniffers actually work:
Published reports of NSA surveillance requests:
Microsoft Outlook story:
General Alexander's justification:
Examining terrorist plots:
The value of trust:
Two more links describing how the US government lies about NSA
A problem with the US Privacy and Civil Liberties Oversight Board:
Interesting essay on the impossibility of being entirely lawful all
the time, the balance that results from the difficulty of law
enforcement, and the societal value of being able to break the law.
It is very much like my notion of "outliers" in my book "Liars and
Good article on the longstanding practice of secretly tapping
undersea cables.
This is news right now because of a new Snowden document.
An amazing e-mail from the DHS, instructing its employees not to
read Snowden's documents when they appear in the press.
Edward Snowden has set up a dead man's switch. He's distributed
encrypted copies of his document trove to various people, and has
set up some sort of automatic system to distribute the key, should
something happen to him. Dead man's switches have a long history,
both for safety (the machinery automatically stops if the operator's
hand goes slack) and security reasons. WikiLeaks did the same thing
with the State Department cables. I'm not sure he's thought this
through, though. I would be more worried that someone would kill me
in order to get the documents released than I would be that someone
would kill me to prevent the documents from being released. Any
real-world situation involves multiple adversaries, and it's
important to keep all of them in mind when designing a security
For a change, here's a good idea by the TSA:
Violence as a source of trust in criminal societies:
I generally don't like stories about Snowden as a person, because
they distract from the real story of the NSA surveillance programs,
but this article on the costs and benefits of the US government
prosecuting Edward Snowden is worth reading.
Related is this article on whether Snowden can manage to avoid
arrest. Here's the ending:
Marc Rotenberg of EPIC explains why he is suing the NSA in the
Supreme Court.
And "USA Today" has a back and forth on the topic.
This is a succinct explanation of how the secrecy of the FISA court
undermines trust.
In an effort to lock the barn door after the horse has escaped, the
NSA is implementing two-man control for sysadmins.
This kind of thing has happened before. After USN Chief Warrant
Officer John Walker sold encryption keys to the Soviets, the Navy
implemented two-man control for key material. It's an effective, if
expensive, security measure--and an easy one for the NSA to
implement while it figures out what it really has to do to secure
information from IT insiders.
The story of people who poach and collect rare eggs, and the people
who hunt them down.
Securing wildlife against poachers is a difficult problem,
especially when the defenders are poor countries with not a lot of
We're starting to see Internet companies talk about the mechanics of
how the US government spies on their users. Here, a Utah ISP owner
describes his experiences with NSA eavesdropping:
Declan McCullagh explains how the NSA coerces companies to cooperate
with its surveillance efforts. Basically, they want to avoid what
happened with the Utah ISP.
And Brewster Kahle of the Internet Archive explains how he
successfully fought a National Security Letter.
Secret information is more trusted:
Original paper abstract:
NSA cracked the Kryptos Sculpture (parts one, two, and three) years
before the CIA did.
The fourth part is still uncracked.
The Obama Administration has a comprehensive "insider threat"
program to detect leakers from within government. This is
pre-Snowden. Not surprisingly, the combination of profiling and "see
something, say something" is unlikely to work.
This is a really clever social engineering attack against a
bank-card holder.
Research on why some neighborhoods feel safer.
I've written about the feeling and reality of security, and how
they're different.
That's also the subject of this TEDx talk.
Yes, it's security theater: things that make a neighborhood *feel*
safer rather than actually safer. But when the neighborhood is
actually safer than people think it is, this sort of security
theater has value.
Two related links:
This is what happens when you're a security writer and you piss off
the wrong people: they conspire to have heroin mailed to you, and
then to tip off the police. And that's after they've called in a
fake hostage situation.
The UK has banned researchers from revealing details of security
vulnerabilities in car locks. In 2008, Phillips brought a similar
suit against researchers who broke the Mifare chip. That time, they
lost. This time, Volkswagen sued and won.
This is bad news for security researchers. (Remember back in 2001
when security researcher Ed Felten sued the RIAA in the US to be
able to publish his research results?) We're not going to improve
security unless we're allowed to publish our results. And we can't
start suppressing scientific results, just because a big corporation
doesn't like what it does to their reputation.
Richard Bejtlich and Thomas Rid (author of the excellent book "Cyber
War Will Not Take Place") debate the cyberwar threat on "The
Economist" website.
There was a story about how searching for a pressure cooker and
backpacks got one family investigated by the police. It was
initially reported as NSA eavesdropping, but it wasn't. And as more
of the facts came out, it seemed pretty reasonable overall.
The "Guardian" discusses a new secret NSA program: XKeyscore. It's
the desktop system that allows NSA agents to spy on anyone over the
Internet in real time. It searches existing NSA databases--
presumably including PRISM--and can create fingerprints to search
for all future data collections from systems like TRAFFIC THIEF.
This seems to be what Edward Snowden meant when he said that he had
the ability to spy on any American, in real time, from his deck.
There's speculation that the FBI is responsible for an exploit that
compromised the Tor anonymity service. Note that Tor Browser Bundles
installed or updated after June 26 are secure.
The further Kip Hawley has gotten from running the TSA, the more
sense he has started to make. This is pretty good.
Twitter just rolled out a pretty nice two-factor authentication
system using your smart phone as the second factor.
Latest movie-plot threat: explosive-dipped clothing. It's being
reported, although there's no indication of where this rumor is
coming from or what it's based on. I can see the trailer now. "In a
world where your very clothes might explode at any moment, Bruce
Willis is, Bruce Willis in a Michael Bay film: BLOW UP! Co-starring
Lindsay Lohan..." I guess there's nothing to be done but to force
everyone to fly naked.
Lots of sports stadiums have instituted draconian new rules. Here
are the rules for St. Louis Rams games.
Of course, you're supposed to think this is about terrorism. My
guess is that this is to help protect the security of the profits at
the concession stands.
General Keith Alexander thinks he can improve security by automating
sysadmin duties such that 90% of them can be fired. Does anyone know
a sysadmin anywhere who believes it's possible to automate 90% of
his job? Or who thinks any such automation will actually improve
security? He's stuck. Computerized systems require trusted people to
administer them. And any agency with all that computing power is
going to need thousands of sysadmins. Some of them are going to be
Leaking secret information is the civil disobedience of our age.
Alexander has to get used to it.
The 2013 Cryptologic History Symposium, sponsored by the NSA, will
be held at Johns Hopkins University this October.
Rangzen looks like a really interesting ad hoc mesh networking
system to circumvent government-imposed communications blackouts. I
am particularly interested in how it uses reputation to determine
who can be trusted, while maintaining some level of anonymity.
This is exactly the sort of thing I was thinking about in this
This essay is filled with historical MI5 stories--often bizarre,
sometimes amusing.
Book Review: "Rise of the Warrior Cop"
"Rise of the Warrior Cop: The Militarization of America's Police
Forces," by Radley Balko, PublicAffairs, 2013, 400 pages.
War as a rhetorical concept is firmly embedded in American culture.
Over the past several decades, federal and local law enforcement has
been enlisted in a war on crime, a war on drugs and a war on terror.
These wars are more than just metaphors designed to rally public
support and secure budget appropriations. They change the way we
think about what the police do. Wars mean shooting first and asking
questions later. Wars require military tactics and weaponry. Wars
mean civilian casualties.
Over the decades, the war metaphor has resulted in drastic changes
in the way the police operate. At both federal and state levels, the
formerly hard line between police and military has blurred. Police
are increasingly using military weaponry, employing military tactics
and framing their mission using military terminology. Right now,
there is a Third Amendment case--that's the one about quartering
soldiers in private homes without consent--making its way through
the courts. It involves someone who refused to allow the police to
occupy his home in order to gain a "tactical advantage" against the
house next-door. The police returned later, broke down his door,
forced him to the floor and then arrested him for obstructing an
officer. They also shot his dog with pepperball rounds. It's hard to
argue with the premise of this case; police officers are acting so
much like soldiers that it can be hard to tell the difference.
In "Rise of the Warrior Cop," Radley Balko chronicles the steady
militarization of the police in the U.S. A detailed history of a
dangerous trend, Mr. Balko's book tracks police militarization over
the past 50 years, a period that not coincidentally corresponds with
the rise of SWAT teams. First established in response to the armed
riots of the late 1960s, they were originally exclusive to big
cities and deployed only against heavily armed and dangerous
criminals. Today SWAT teams are nothing special. They've multiplied
like mushrooms. Every city has a SWAT team; 80% of towns between
25,000 and 50,000 people do as well. These teams are busy; in 2005
there were between 50,000 and 60,000 SWAT raids in the U.S. The
tactics are pretty much what you would expect--breaking down
doors, rushing in with military weaponry, tear gas--but the
targets aren't. SWAT teams are routinely deployed against illegal
poker games, businesses suspected of employing illegal immigrants
and barbershops with unlicensed hair stylists.
In Prince George's County, MD, alone, SWAT teams were deployed about
once a day in 2009, overwhelmingly to serve search or arrest
warrants, and half of those warrants were for "misdemeanors and
nonserious felonies." Much of Mr. Balko's data is approximate,
because police departments don't publish data, and they uniformly
oppose any attempts at transparency or oversight. But he has good
Maryland data from 2009 on, because after the mayor of Berwyn
Heights was mistakenly attacked and terrorized in his home by a SWAT
team in 2008, the state passed a law requiring police to report
quarterly on their use of SWAT teams: how many times, for what
purposes and whether any shots were fired during the raids.
Besides documenting policy decisions at the federal and state
levels, the author examines the influence of military contractors
who have looked to expand into new markets. And he tells some pretty
horrific stories of SWAT raids gone wrong. A lot of dogs get shot in
the book. Most interesting are the changing attitudes of police. As
the stories progress from the 1960s to the 2000s, we see police
shift from being uncomfortable with military weapons and tactics--
and deploying them only as the very last resort in the most extreme
circumstances--to accepting and even embracing their routine use.
This development coincides with the rhetorical use of the word
"war." To the police, civilians are citizens to protect. To the
military, we are a population to be subdued. Wars can temporarily
override the Constitution. When the Justice Department walks into
Congress with requests for money and new laws to fight a war, it is
going to get a different response than if it came in with a story
about fighting crime. Maybe the most chilling quotation in the book
is from William French Smith, President Reagan's first attorney
general: "The Justice Department is not a domestic agency. It is the
internal arm of national defense." Today we see that attitude in the
war on terror. Because it's a war, we can arrest and imprison
Americans indefinitely without charges. We can eavesdrop on the
communications of all Americans without probable cause. We can
assassinate American citizens without due process. We can have
secret courts issuing secret rulings about secret laws. The
militarization of the police is just one aspect of an increasing
militarization of government.
Mr. Balko saves his prescriptions for reform until the last chapter.
Two of his fixes, transparency and accountability, are good remedies
for all governmental overreach. Specific to police departments, he
also recommends halting mission creep, changing police culture and
embracing community policing. These are far easier said than done.
His final fix is ending the war on drugs, the source of much police
violence. To this I would add ending the war on terror, another
rhetorical war that costs us hundreds of billions of dollars, gives
law enforcement powers directly prohibited by the Constitution and
leaves us no safer.
This essay originally appeared in the "Wall Street Journal."
Related essay.
Schneier News
My blog has made the "Time" magazine "25 Best Bloggers 2013 Edition"
Good review of the strengths and weaknesses of "Cryptography
Engineering" and "Applied Cryptography." Best--at least to me--
is the list of things missing, which we'll have to address if we do
another edition.
Mikko Hypponen and I answered questions about PRISM on the TED
Michael Hayden on the Effects of Snowden's Whistleblowing
Former NSA director Michael Hayden lists three effects of the
Snowden documents:
* "...the undeniable operational effect of informing adversaries of
American intelligence's tactics, techniques and procedures."
* "...the undeniable economic punishment that will be inflicted on
American businesses for simply complying with American law."
* "...the erosion of confidence in the ability of the United States
to do *anything* discreetly or keep *anything* secret."
It's an interesting list, and one that you'd expect from a NSA
person. Actually, the whole essay is about what you'd expect from a
former NSA person.
My reactions:
* This, I agree, is actual damage. From what I can tell, Snowden has
done his best to minimize it. And both the Guardian and the
Washington Post refused to publish materials he provided, out of
concern for US national security. Hayden believes that both the
Chinese and the Russians have Snowden's entire trove of documents,
but I'm less convinced. Everyone is acting under the assumption that
the NSA has compromised everything, which is probably a good
* Hayden has it backwards--this is good. I hope that companies
that have cooperated with the NSA are penalized in the market. If we
are to expect the market to solve any of this, we need the cost of
cooperating to be greater than the cost of fighting. If we as
consumers punish companies that have complied with the NSA, they'll
be less likely to roll over next time.
* In the long run, this might turn out to be a good thing, too. In
the Internet age, secrecy is a lot harder to maintain. The countries
that figure this out first will be the countries that do well in the
coming decades.
And, of course, Hayden lists his "costs" without discussing the
benefits. Exposing secret government overreach, a secret agency gone
rogue, and a secret court that's failing in its duties are
enormously beneficial. Snowden has blown a whistle that long needed
blowing--it's the only way can ever hope to fix this. And Hayden
completely ignores the very real question as to whether these
enormous NSA data-collection programs provide any real benefits.
I'm also tired of this argument: "But it takes a special kind of
arrogance for this young man to believe that his moral judgment on
the dilemma suddenly trumps that of two (incredibly different)
presidents, both houses of the U.S. Congress, both political
parties, the U.S. court system and more than 30,000 of his
It's like President Obama claiming that the NSA programs are
"transparent" because they were cleared by a secret court that only
ever sees one side of the argument, or that Congress has provided
oversight because a few legislators were allowed to know some of
what was going on but forbidden from talking to *anyone* about it.
The NSA has gone rogue:
NSA surveillance cost/benefits:
Obama's comments on NSA transparency:
Counterterrorism Mission Creep
One of the assurances I keep hearing about the U.S. government's
spying on American citizens is that it's only used in cases of
terrorism. Terrorism is, of course, an extraordinary crime, and its
horrific nature is supposed to justify permitting all sorts of
excesses to prevent it. But there's a problem with this line of
reasoning: mission creep. The definitions of "terrorism" and "weapon
of mass destruction" are broadening, and these extraordinary powers
are being used, and will continue to be used, for crimes other than
Back in 2002, the Patriot Act greatly broadened the definition of
terrorism to include all sorts of "normal" violent acts as well as
non-violent protests. The term "terrorist" is surprisingly broad;
since the terrorist attacks of 9/11, it has been applied to people
you wouldn't normally consider terrorists.
The most egregious example of this are the three anti-nuclear
pacifists, including an 82-year-old nun, who cut through a
chain-link fence at the Oak Ridge nuclear-weapons-production
facility in 2012. While they were originally arrested on a
misdemeanor trespassing charge, the government kept increasing their
charges as the facility's security lapses became more embarrassing.
Now the protestors have been convicted of violent crimes of
terrorism--and remain in jail.
Meanwhile, a Tennessee government official claimed that complaining
about water quality could be considered an act of terrorism. To the
government's credit, he was subsequently demoted for those remarks.
The notion of making a terrorist threat is older than the current
spate of anti-terrorism craziness. It basically means threatening
people in order to terrorize them, and can include things like
pointing a fake gun at someone, threatening to set off a bomb, and
so on. A Texas high-school student recently spent five months in
jail for writing the following on Facebook: "I think I'ma shoot up a
kindergarten. And watch the blood of the innocent rain down. And eat
the beating heart of one of them." Last year, two Irish tourists
were denied entry at the Los Angeles Airport because of some
misunderstood tweets.
Another term that's expanded in meaning is "weapon of mass
destruction." The law is surprisingly broad, and includes anything
that explodes, leading political scientist and terrorism-fear
skeptic John Mueller to comment:
As I understand it, not only is a grenade a weapon of mass
destruction, but so is a maliciously-designed child's rocket even
if it doesn't have a warhead. On the other hand, although a
missile-propelled firecracker would be considered a weapon of
mass destruction if its designers had wanted to think of it as a
weapon, it would not be so considered if it had previously been
designed for use as a weapon and then redesigned for pyrotechnic
use or if it was surplus and had been sold, loaned, or given to
you (under certain circumstances) by the secretary of the army
All artillery, and virtually every muzzle-loading military long
arm for that matter, legally qualifies as a WMD. It does make the
bombardment of Ft. Sumter all the more sinister. To say nothing
of the revelation that The Star Spangled Banner is in fact an
account of a WMD attack on American shores.
After the Boston Marathon bombings, one commentator described our
use of the term this way: "What the United States means by terrorist
violence is, in large part, 'public violence some weirdo had the
gall to carry out using a weapon other than a gun.' ... Mass
murderers who strike with guns (and who don't happen to be Muslim)
are typically read as psychopaths disconnected from the larger
political sphere." Sadly, there's a lot of truth to that.
Even as the definition of terrorism broadens, we have to ask how far
we will extend that arbitrary line. Already, we're using these
surveillance systems in other areas. A raft of secret court rulings
has recently expanded the NSA's eavesdropping powers to include
"people possibly involved in nuclear proliferation, espionage and
cyberattacks." A "little-noticed provision" in a 2008 law expanded
the definition of "foreign intelligence" to include "weapons of mass
destruction," which, as we've just seen, is surprisingly broad.
A recent "Atlantic" essay asks, somewhat facetiously, "If PRISM is
so good, why stop with terrorism?" The author's point was to discuss
the value of the Fourth Amendment, even if it makes the police less
efficient. But it's actually a very good question. Once the NSA's
ubiquitous surveillance of all Americans is complete--once it has
the ability to collect and process all of our emails, phone calls,
text messages, Facebook posts, location data, physical mail,
financial transactions, and who knows what else--why limit its use
to cases of terrorism? I can easily imagine a public groundswell of
support to use to help solve some other heinous crime, like a
kidnapping. Or maybe a child-pornography case. From there, it's an
easy step to enlist NSA surveillance in the continuing war on drugs;
that's certainly important enough to warrant regular access to the
NSA's databases. Or maybe to identify illegal immigrants. After all,
we've already invested in this system, we might as well get as much
out of it as we possibly can. Then it's a short jump to the trivial
examples suggested in the "Atlantic" essay: speeding and illegal
downloading. This "slippery slope" argument is largely speculative,
but we've already started down that incline.
Criminal defendants are starting to demand access to the NSA data
that they believe will exonerate themselves. How can a moral
government refuse this request?
More humorously, the NSA might have created the best backup system
Technology changes slowly, but political intentions can change very
quickly. In 2000, I wrote in my book "Secrets and Lies" about police
surveillance technologies: "Once the technology is in place, there
will always be the temptation to use it. And it is poor civic
hygiene to install technologies that could someday facilitate a
police state." Today we're installing technologies of ubiquitous
surveillance, and the temptation to use them will be overwhelming.
This essay originally appeared in TheAtlantic.com.
The definition of terrorism has broadened:
The anti-nuclear pacifists:
Tennessee official story:
Texas high-school student story:
Irish tourist story:
"Weapon of mass destruction" story:
Mueller comment:
Quote about what a terrorist is:
Secret court rulings on NSA power:
Atlantic article:
Other agencies are already asking to use the NSA data: "Agencies
working to curb drug trafficking, cyberattacks, money laundering,
counterfeiting and even copyright infringement complain that their
attempts to exploit the security agencys vast resources have often
been turned down because their own investigations are not considered
a high enough priority, current and former government officials
The Drug Enforcement Agency is already using this data, and lying
about it:
Defendants demanding NSA data:
NSA as a backup system:
Ubiquitous surveillance:
Since 1998, CRYPTO-GRAM has been a free monthly newsletter providing
summaries, analyses, insights, and commentaries on security:
computer and otherwise. You can subscribe, unsubscribe, or change
your address on the Web at
. Back issues are also
available at that URL.
Please feel free to forward CRYPTO-GRAM, in whole or in part, to
colleagues and friends who will find it valuable. Permission is also
granted to reprint CRYPTO-GRAM, as long as it is reprinted in its
CRYPTO-GRAM is written by Bruce Schneier. Bruce Schneier is an
internationally renowned security technologist, called a "security
guru" by The Economist. He is the author of 12 books--including
"Liars and Outliers: Enabling the Trust Society Needs to Survive"--
as well as hundreds of articles, essays, and academic papers. His
influential newsletter "Crypto-Gram" and his blog "Schneier on
Security" are read by over 250,000 people. He has testified before
Congress, is a frequent guest on television and radio, has served on
several government committees, and is regularly quoted in the press.
Schneier is a fellow at the Berkman Center for Internet and Society
at Harvard Law School, a program fellow at the New America
Foundation's Open Technology Institute, a board member of the
Electronic Frontier Foundation, an Advisory Board Member of the
Electronic Privacy Information Center, and the Security Futurologist
for BT--formerly British Telecom. See .
Crypto-Gram is a personal newsletter. Opinions expressed are not
necessarily those of BT.
tt mailing list
tt at postbiota.org

@_date: 2014-09-01 00:35:43
@_author: Frank Forman 
@_subject: [tt] NYT: Hal Finney, Cryptographer and Bitcoin Pioneer, Dies at 58 
Hal Finney, Cryptographer and Bitcoin Pioneer, Dies at 58
By NATHANIEL POPPER
Hal Finney, a cryptographer and one of the earliest users and
developers of the virtual currency Bitcoin, died on Thursday in
Phoenix. He was 58.
Mr. Finney had been paralyzed by amyotrophic lateral sclerosis, or
A.L.S., and was taken off life support at Paradise Valley Hospital,
his wife, Fran Finney, said. She said his body was immediately
prepared for cryonic preservation by the Alcor Life Extension
Foundation in Scottsdale, Ariz., according to his wishes.
A graduate of the California Institute of Technology, Mr. Finney was
a longtime futurist who put his programming skills to work in the
service of his ideals, particularly his desire to see the privacy of
individuals protected.
In 1991, he began doing volunteer work for a new software project
known as Pretty Good Privacy, or P.G.P., and immediately became one
of the central players in developing the program. P.G.P. aimed to
make it possible for people everywhere to encrypt electronic
communication in a way that could not be read by anyone other than
the intended recipient. The program used relatively new innovations
in encryption that are still thought to be invulnerable to code
Mr. Finney wrote in 1992 that cryptographic technology appealed to
him because he worried about the ability of corporations and
governments to snoop on citizens.
"The work we are doing here, broadly speaking, is dedicated to this
goal of making Big Brother obsolete," he wrote to an online group of
fellow privacy activists.
The original author of P.G.P., Philip R. Zimmermann, quickly became
the target of federal prosecutors, who believed that the software
broke United States laws against exporting military-grade encryption
While the investigation went on and became a major cause for civil
libertarians, Mr. Finney played a more quiet role in P.G.P. to avoid
becoming a target himself. Mr. Zimmermann said in an interview that
this decision meant Mr. Finney did not get proper credit for some of
the important innovations he had made in the development of P.G.P.
When the investigation concluded in 1996 without any charges being
filed, P.G.P. became a company, and Mr. Zimmermann set out to hire
Mr. Finney as his first employee.
Mr. Zimmermann, in an interview before Mr. Finney died, said Mr.
Finney was unusual in the field because he had none of the asocial
tendencies and physical awkwardness that are commonly associated
with people in the programming world. Rather, he said, Mr. Finney
was a gregarious man who loved skiing and long-distance running.
"Sometimes people pay some price for being extremely smart--they
are deficient in some emotional quality," Mr. Zimmermann said. "Hal
was not like that."
While working on P.G.P., Mr. Finney was a regular participant in a
number of futurist mailing lists, the most famous of which gave
birth to the Cypherpunk movement, dedicated to privacy-enhancing
Following these lists, Mr. Finney became fascinated by the concept
of digital currencies that could not be tracked by governments and
He was involved in many experiments aimed at creating an anonymous
form of digital money, including his own invention, in 2004, of
reusable proofs of work. Though that system never took off, he
quickly saw the promise of the Bitcoin project when it was announced
on an obscure email list in 2008 by a creator with the pseudonym
Satoshi Nakamoto.
Bitcoin used some of the same cryptographic tools harnessed by
P.G.P. and held out the promise that participants could choose to be
anonymous when spending money online.
When the project drew criticism from other cryptographers, Mr.
Finney was among the first people to defend it. He downloaded the
Bitcoin software the day it was released. The day after that, he
took part in the first transaction on the network when Satoshi
Nakamoto sent him 10 Bitcoins.
His early work on Bitcoin and his programming background led to
frequent speculation in the Bitcoin community that Mr. Finney was
Satoshi Nakamoto, a claim he always denied.
Soon after getting started with Bitcoin, Mr. Finney learned in 2009
that he had A.L.S., and he withdrew, for a time, from active
participation in the project.
Harold Thomas Finney II was born on May 4, 1956, in Coalinga,
Calif., to Virginia and Harold Thomas Finney. His father was a
petroleum engineer.
After graduating from Caltech in 1979 with a degree in engineering,
he worked for a company that developed video games like Astroblast
and Space Attack.
As a young man, Mr. Finney developed an interest in preserving life
through cryonic freezing until better, life-enhancing technologies
were invented, said a college roommate, Yin Shih. In 1992, Mr.
Finney visited the Alcor facility with his wife to determine whether
he wanted to sign up his family to be preserved in Alcor's
"containment vessels."
"In my personal opinion, anyone born today has a better than 50-50
chance of living effectively forever," he wrote at the time.
Mr. Finney remained an employee of the P.G.P. Corporation until his
retirement in 2011, working from his home in Santa Barbara, Calif.
In the last few years, Mr. Finney was able to move only his facial
muscles, but he communicated and wrote Bitcoin-related software
using a computer that tracked his eye movement.
"I'm pretty lucky overall," Mr. Finney wrote on a Bitcoin website in
2013. "Even with the A.L.S., my life is very satisfying."
As the price of Bitcoins rose, his family, to pay for his medical
care, was able to sell some of the coins he secured in the early
Besides his son, Jason, and his wife, he is survived by a daughter,
Erin Finney; two sisters, Kathleen Finney and Patricia Wolf; and a
brother, Michael. His wife, a physical therapist whom he met at
Caltech, spent most of her days caring for him in his final years.
After Mr. Finney's death, the freezing of his remains was announced
by another futurist, Max More. "Hal," he wrote in a statement
online. "I know I speak for many when I say that I look forward to
speaking to you again sometime in the future and to throwing a party
in honor of your revival."
tt mailing list
tt at postbiota.org
