
@_date: 2012-08-03 20:08:57
@_author: Mike Perry 
@_subject: [liberationtech] The Tor Project has funding for a Firefox developer 
The Tor Project is looking for a Firefox developer as a contractor
position likely starting in October and going through Q1 2013, with the
possibility of later in 2013 and beyond. There may also be a possibility
for part-time work prior to October. This would be a telecommuting
position, with collaboration happening primarily over IRC and email.
The purpose of our browser is to build a private-by-design reference
implementation of "Do Not Track", but through the alteration of
browser behavior and without the need for regulation or begging:
Your job would be to work on that Firefox-based browser as a developer.
This includes triaging, diagnosing, and fixing bugs; looking for and
resolving web privacy issues; responding on short notice to security
issues; and working collaboratively with coworkers and volunteers on
implementing new features and web behavior changes. You'd also be
reviewing other people's code, designs, and academic research papers,
and looking for ways to improve upon them.
For information on how to apply and what to send in with your
application, please see the job posting:

@_date: 2012-08-24 15:12:42
@_author: Mike Perry 
@_subject: [tor-talk] End-to-end correlation for fun and profit 
Thus spake Ted Smith (tedks at riseup.net):
The Raccoon has made a believer out of me, but there are some limits to
both of his/her proofs.. The full proofs can still be found here:
The actual numbers from the examples of the first proof are affected by
the resolution of the data retention. The core concept of the proof
seems to hold no matter what (that full dragnet n^2 correlation is hard,
and the amount of similar co-incident traffic - aka the base rate - is
what makes it hard), but if the adversary has full observation of *all*
traffic data, they *might* be able to do better than 99.9% true positive
rate. It's not clear that low-resolution connection-level data retention
or even sampled netflow data can provide anywhere near that true
positive rate, though.
A full adversary may also get to combine repeat observations (assuming
it is possible to identify them as from the same user), but the post
mentions that.
Incidentally, my guess is that's probably one of the reasons for the
huge boondoggle^W datacenter in Utah. They probably realized that to
reliably track large botnet activity, they really needed to log all data
forever. Well, keep sitting on the unpublished 0day software
vulnerabilities, guys. That should totally help you solve both those
problems, once and for all. Oh wait. ;)
Anyways, the key thing I think the first proof tells us is that even
sloppy defenses against correlation attacks are likely to work against
dragnet surveillance/data retention, especially if you have a lot of
co-incident traffic to blend in with and if the data retention
resolution is low.
I think this alone can justify experimentation with traffic padding
to/from Guard nodes, where bandwidth is relatively cheap and plentiful.
It especially justifies minimal amounts of Guard node padding to defend
against the single-ended version of the end-to-end correlation attack,
which is also known as the "website traffic fingerprinting attack". The
single ended version is even *more* vulnerable to the properties of
background traffic than the double-ended version, and has far fewer
reliably recognizable traffic features to extract from data streams as
well. See this blog post and its links for more details:
 It's my personal opinion that we should also experiment with Guard
padding against the website traffic fingerprinting attack, and see
how far that gets us against e2e correlation while we're at it.
Unfortunately, current academic religious dogma tends to hold that
correlation is unbeatable no matter what. This publication and research
bias already has hindered and will likely continue to hinder research
into viable defenses :(.
The second proof wrt tagging attacks scared the crap out of me. However,
the "c/n" compromise result at the end hinges crucially on nodes that
fail circuits being able to attract additional traffic to make up for
it. The bandwidth authorities might do this to a certain extent
currently, and will certainly do it if operated in "PID feedback mode".
However it's still not clear that the 3 guard node round-robin circuit
selection properties of Tor wouldn't end up also hampering the attack
against specific clients (unless the Guard nodes' keys were stolen and
the attack is locally targeted).
Either way, it's caused me to drive Nick nuts by pushing hard to include
at least *some* kind of simple defense for circuit failure attacks on
the client-side. How much of that actually survives in 0.2.3.x in a
functional form remains to be seen :/.
P.S. Incidentally, you used to be able to get the full copy of the first
proof in the old seul archives at
 but since seul
is currently down with unknown hardware and disk issues,
might be the last full public copy other than your repost. I've added
the Raccoon on Cc so s/he can hopefully do a full repost if the seul
archives end up being destroyed forever.

@_date: 2012-08-25 18:11:46
@_author: Mike Perry 
@_subject: [tor-talk] End-to-end correlation for fun and profit 
Thus spake Maxim Kammerer (mk at dee.su):
Well, the argument over correlation accuracy comes down to observation
resolution, feature extraction ability, and academic lab conditions
versus reality. For an example, let's assume that the adversary cannot
see inside of Guard TLS connections. With this assumption: if at any
point there's concurrent Guard TLS activity from a single client (either
other circuit activity, directory fetch activity, or circuit
pre-building activity), then some or all of your fine-grained timing and
size information features go out the window.
To see the effects of this currently, consider: Is it *really* the case
that only one connection in *a billion* experiences incidental
concurrent activity that interferes with or obliterates high-resolution
feature extraction? I think the actual rate of random (or deliberate)
concurrent activity is much higher than that, especially for heavily
used tor clients, and even more so if they are serving as bridges or
relays. But, against high-resolution adversaries, the really interesting
question is: How little real cover traffic is actually needed to obscure
timing and size information to the point where the remaining features
are insufficient for high rates of correlation success? And over how
many observations can such activity be expected to survive for a given
base rate of similar activity?
I suspect that for relatively short-lived bursts of traffic like web
site views and random webapp AJAX activity, we can actually do pretty
well with very little effort and overhead. Especially against the
one-ended version of the correlation attack: the website fingerprinting
attack, but probably against both.
But for long-lived or otherwise atypical connections, you're absolutely
right. There's just a whole lot of information encoded there.. Almost
any level of observation will likely be able to correlate such flows
eventually, and it's also hard to imagine generalized padding techniques
that could blend these flows with web traffic.
Unfortunately, because academia has mostly concluded that this work is
uninteresting and that all forms of this problem are generally
"impossible", we have no solid answers to these types of questions wrt
what can be done in practice. Perhaps it is merely because defense
work is less sexy than attack work when it comes to getting
publications. I don't know for sure. I haven't yet figured out exactly
why CS academia is broken. There's a whole lot of symptoms, though...
But anyway, failing real research, there's always the botnets, the drug
war, and the aliens to guide us... Can I get three cheers for Big Data?
After all, I'm sure we can trust Them to tell us how the science shakes
out in the end, amirite? ;).

@_date: 2012-03-07 12:27:53
@_author: Mike Perry 
@_subject: [tor-talk] Tor and HTTPS graphic 
Thus spake Paul Syverson (syverson at itd.nrl.navy.mil):
Thanks to Mark Klein, we know that the NSA wiretaps in the US are
passive in nature, not active. But who knows what they do to overseas
links and specific high-value targets...
I have to agree with the Raccoon here. I actually don't think Murdoch's
work demonstrated that sampling adversaries can adequately correlate
web-sized traffic.
It seems pretty clear to me that the typical sampling rate of 1/2048 did
not become effective until you were around O(100MB) in transfer. He
wrote that 1/500 became effective at around O(1MB) in transfer, but that
is still a bit above most web page sizes.
There is also the question of an extremely low concurrent flow count
compared to reality today. He used only 500 flows/hour to correlate,
where as at any given *second* O(10k) TCP connections are opened through
every gbit Tor node in operation today. He also used an artificial prior
distribution on connection sizes. Both of these properties alter the
event rate and thus the overall accuracy in the experimental results as
compared to reality.
I think we can agree that large video uploaders stick out like sore
thumbs (due to relative lack of upload traffic frequency), but I don't
think The Man can correlate millions of simultaneous web page views and
expect to have certainty over who is viewing what at all times. At some
point, you simply run out of differentiating bits to extract from size
and timing information to properly segment the userbase.
And as far as I know, no one has really considered the full impact of
userbase size on correlation in the research community (aside from the

@_date: 2012-10-11 02:20:57
@_author: Mike Perry 
@_subject: [tor-dev] Proposal: Tuning the Parameters for the Path Bias Defense 
Also exists at
Title: Tuning the Parameters for the Path Bias Defense
Author: Mike Perry
Created: 01-10-2012
Status: Open
Target: 0.2.4.x+
 This proposal describes how we can use the results of simulations in
 combination with network scans to set reasonable limits for the Path
 Bias defense, which causes clients to be informed about and ideally
 rotate away from Guards that provide extremely low circuit success
 rates.
 The Path Bias defense is designed to defend against a type of route capture
 where malicious Guard nodes deliberately fail circuits that extend to
 non-colluding Exit nodes to maximize their network utilization in favor of
 carrying only compromised traffic.
 This attack was explored in the academic literature in [1], and a
 variant involving cryptographic tagging was posted to tor-dev[2] in
 March.
 In the extreme, the attack allows an adversary that carries c/n
 of the network capacity to deanonymize c/n of the network
 connections, breaking the O((c/n)^2) property of Tor's original
 threat model.
Design Description
 The Path Bias defense is a client-side accounting mechanism in Tor that
 tracks the circuit failure rate for each of the client's guards.
 Clients maintain two integers for each of their guards: a count of the
 number of times a circuit was extended at least one hop through that
 guard, and a count of the number of circuits that successfully complete
 through that guard. The ratio of these two numbers is used to determine
 a circuit success rate for that Guard.
 The system should issue a notice log message when Guard success rate
 falls below 70%, a warn when Guard success rate falls below 50%, and
 should drop the Guard when the success rate falls below 30%.
 To ensure correctness, checks are performed to ensure that
 we do not count successes without also counting the first hop.
 Similarly, to provide a moving average of recent Guard activity while
 still preserving the ability to ensure correctness, we "scale" the
 success counts by an integer divisor (currently 2) when the counts
 exceed the moving average window (300) and when the division
 does not produce integer truncation.
 No log messages should be displayed, nor should any Guard be
 dropped until it has completed at least 150 first hops (inclusive).
Analysis: Simulation
 To test the defense in the face of various types of malicious and
 non-malicious Guard behavior, I wrote a simulation program in
 Python[3].
 The simulation confirmed that without any defense, an adversary
 that provides c/n of the network capacity is able to observe c/n
 of the network flows using circuit failure attacks.
 It also showed that with the defense, an adversary that wishes to
 evade detection has compromise rates bounded by:
   P(compromise) <= (c/n)^2 * (100/CUTOFF_PERCENT)
   circs_per_client <= circuit_attempts*(c/n)
 In this way, the defense restores the O((c/n)^2) compromise property,
 but unfortunately only over long periods of time (see Security
 Considerations below).
 The spread between the cutoff values and the normal rate of circuit
 success has a substantial effect on false positives. From the
 simulation's results, the sweet spot for the size of this spread appears
 to be 10%. In other words, we want to set the cutoffs such that they are
 10% below the success rate we expect to see in normal usage.
 The simulation also demonstrates that larger "scaling window" sizes
 reduce false positives for instances where non-malicious guards
 experience some ambient rate of circuit failure.
Analysis: Live Scan
 Preliminary Guard node scanning using the txtorcon circuit scanner[4]
 shows normal circuit completion rates between 80-90% for most Guard
 nodes.
 However, it also showed that CPU overload conditions can easily push
 success rates as low as 45%. Even more concerning is that for a brief
 period during the live scan, success rates dropped to 50-60%
 network-wide (regardless of Guard node choice).
 Based on these results, the notice condition should be 70%, the warn  condition should be 50%, and the drop condition should be 30%.
Future Analysis: Deployed Clients
 It's my belief that further analysis should be done by deploying  loglines for all three thresholds in clients in the live network
 to utilize user reports on how often high rates of circuit failure
 are seen before we deploy changes to rotate away from failing Guards.
 I believe these log lines should be deployed in 0.2.3.x clients,
 to maximize the exposure of the code to varying network conditions,
 so that we have enough data to consider deploying the Guard-dropping
 cutoff in 0.2.4.x.
Security Considerations
 While the scaling window does provide freshness and can help mitigate
 "bait-and-switch" attacks, it also creates the possibility of conditions
 where clients can be forced off their Guards due to temporary
 network-wide CPU DoS. This provides another reason beyond false positive
 concerns to set the scaling window as large as is reasonable.
 A DoS directed at specific Guard nodes is unlikely to allow an
 adversary to cause clients to rotate away from that Guard, because it
 is unlikely that the DoS can be precise enough to allow first hops to
 that Guard to succeed, but also cause extends to fail. This leaves
 network-wide DoS as the primary vector for influencing clients.
 Simulation results show that in order to cause clients to rotate away
 from a Guard node that previously succeeded 80% of its circuits, an
 adversary would need to induce a 25% success rate for around 350 circuit
 attempts before the client would reject it, or a 5% success rate
 for around 215 attempts, both using a scaling window of 300 circuits.
 Assuming one circuit per Guard per 10 minutes of active client
 activity, this is a sustained network-wide DoS attack of 60 hours
 for the 25% case, or 38 hours for the 5% case.
 Presumably this is enough time for the directory authorities to respond by
 altering the pb_disablepct consensus parameter before clients rotate,
 especially given that most clients are not active for even 38 hours on end,
 and will tend to stop building circuits while idle.
 If we raised the scaling window to 500 circuits, it would require 1050
 circuits if the DoS brought circuit success down to 25% (175 hours), and
 415 circuits if the DoS brought the circuit success down to 5% (69 hours).
 The tradeoff, though, is that larger scaling window values allow Guard nodes
 to compromise clients for duty cycles of around the size of this window (up to
 the (c/n)^2 * 100/CUTOFF_PERCENT limit in aggregate), so we do have to find
 balance between these concerns.
Implementation Notes: Log Messages
 Log messages need to be chosen with care to avoid alarming users.
 I suggest:
 Notice: "Your Guard %s is failing more circuits than usual. Most likely
 this means the Tor network is overloaded. Success counts are %d/%d."
 Warn: "Your Guard %s is failing a very large amount of circuits. Most likely
 this means the Tor network is overloaded, but it could also mean an attack
 against you or potentially the Guard itself. Success counts are %d/%d."
 Drop: "Your Guard %s is failing an extremely large amount of circuits. [Tor
 has disabled use of this Guard.] Success counts are %d/%d."
 The second piece of the Drop message would not be present in 0.2.3.x,
 since the Guard won't actually be dropped.
Implementation Notes: Consensus Parameters
 The following consensus parameters reflect the constants listed
 in the proposal. These parameters should also be available  for override in torrc.
 pb_mincircs=150
   The minimum number of first hops before we log or drop Guards.
 pb_noticepct=70
   The threshold of circuit success below which we display a notice.
 pb_warnpct=50
   The threshold of circuit success below which we display a warn.
 pb_disablepct=30
   The threshold of circuit success below which we disable the guard.
 pb_scalecircs=300
   The number of first hops at which we scale the counts down.
 pb_scalefactor=2
   The integer divisor by which we scale.
1. 2. 3. 4.

@_date: 2012-10-11 02:38:44
@_author: Mike Perry 
@_subject: [tor-dev] Proposal: Internal Mapaddress for Tor Configuration 
Also at:
Title: Internal Mapaddress for Tor Configuration Testing
Author: Mike Perry
Created: 08-10-2012
Status: Open
Target: 0.2.4.x+
 This proposal describes a method by which we can replace the
  testing service with an internal XML
 document provided by the Tor client.
 The Tor Check service is a central point of failure in terms of Tor
 usability. If it is ever out of sync with the set of exit nodes on the
 Tor network or down, user experience is degraded considerably. Moreover,
 the check itself is very time-consuming. Users must wait seconds or more
 for the result to come back. Worse still, if the user's software *was*
 in fact misconfigured, the check.torproject.org DNS resolution and
 request leaks out on to the network.
Design Overview
 The system will have three parts: an internal hard-coded IP address
 mapping (127.84.111.114:80), a hard-coded mapaddress to a DNS name
 (selftest.torproject.org:80), and a DirPortFrontPage-style simple
 HTTP server that serves an XML document for both addresses.
 Upon receipt of a request to the IP address mapping, the system will  create a new 128 bit randomly generated nonce and provide it
 in the XML document.
 Requests to  must include a valid,
 recent nonce as the GET url path. Upon receipt of a valid nonce,
 it is removed from the list of valid nonces. Nonces are only valid
 for 60 seconds or until SIGNAL NEWNYM, which ever comes first.
 The list of pending nonces should not be allowed to grow beyond 10
 entries.  The timeout period and nonce limit should be configurable in torrc.
Design: XML document format for  To avoid the need to localize the message in Tor, Tor will only provide
 a XML object with connectivity information. Here is an example form:
 The tor-bootstrap-percent field represents the results of the Tor client
 bootstrap status as integer percentages from bootstrap_status_t.
 The tor-version-current field represents the results of the Tor client
 consensus version check. If the bootstrap process has not yet
 downloaded a consensus document, this field will have the value
 null.
 The dns-nonce field contains a 128-bit secret, encoded in base16. This
 field is only present for requests that list the Host: header as
 127.84.111.114.
Design: XML document format for  The first two fields are the same as for the IP address version.
 The dns-nonce-valid field is only true if the Host header matches
 selftest.torproject.org and the nonce is current and valid. Upon
 receipt of a valid nonce, that nonce is removed from the list of
 valid nonces.
Design: Request Servicing
 Care must be taken with the dns-nonce generation and usage, to prevent
 users from being tracked through leakage of nonce value to application
 content. While the usage of XML appears to make this impossible
 due to stricter same-origin policy enforcement than JSON, same-origin
 enforcement is still fraught with exceptions and loopholes.
 In particular:  Any requests that contain the Origin: header MUST be ignored,
 as the Origin: header is only included for third party web content
 (CORS).
 dns-nonce fields MUST be omitted if the HTTP Host: header does not
 match the IP address 127.84.111.114.
 Requests to selftest.torproject.org MUST return false for the
 dns-nonce-valid field if the HTTP Host: header does not match
 selftest.torproject.org, regardless of nonce value.
 Further, requests to selftest.torproject.org MUST validate that
 'selftest.torproject.org' was the actual hostname provided to
 SOCKS4A, and not some alternate address mapping (due to DNS rebinding
 attacks, for example).
Design: Application Usage
 Applications will use the system in two steps. First, they will make an
 HTTP request to  over Tor's SOCKS port and
 parse the resulting XML, if any.
 If the request at this stage fails, the application should inform the
 user that either their Tor client is too old, or that it is
 misconfigured, depending upon the nature of the failure.
 If the request succeeds and valid XML is returned, the application
 will record the value of the dns-nonce field, and then perform a second
 request to  If the second
 request succeeds, and the dns-nonce-valid field is true, the application
 may inform the user that their Tor settings are valid.
 If the second request fails, or does not provide the correct dns-nonce,
 the application will inform the user that their Tor DNS proxy settings
 are incorrect.
 If either tor-bootstrap-percent is not 100, or tor-version-current is
 false, applications may choose to inform the user of these facts using
 properly localized strings and appropriate UI.
Security Considerations
 XML was chosen over JSON due to the risks of the identifier leaking
 in a way that could enable websites to track the user[1].
 Because there are many exceptions and circumvention techniques
 to the same-origin policy, we have also opted for strict controls
 on dns-nonce lifetimes and usage, as well as validation of the Host
 header and SOCKS4A request hostnames.
1.

@_date: 2012-09-26 11:48:14
@_author: Mike Perry 
@_subject: [tor-talk] Tor and P2P 
Thus spake Nathan Freitas (nathan at freitas.net):
This is a great point, and I wish I could reply to it and Robert's
comments about DoSing the hsdirs in the same mail.
It would seem that "simple" solutions might end up destroying the Tor
network. Based on Robert's comments, it sounds like the properties we
need are:
1. Persistent hidserv connections. Reconnecting for each message via an
HTTP POST is right out. Way too many circuits+onionskins to scale.
2. Avoid the situation where a single user is creating multiple hidden
services for all their crazy P2P apps.
For 1: It would seem to me that a system that ships a local torified
XMPP server would satisfy this. XMPP is fully decentralized, and
maintains persistent connections between servers. Each user would run
their own server over .onion.
For 2: The resource identifiers of XMPP mean we can connect multiple
XMPP clients to a single local XMPP server, and have them provide
multiple (admittedly linkable) P2P services over XMPP 'streams' without
spinning up additional hidden services for each client app.
XMPP has some obvious downsides... We'd need to audit the whole beast to
make sure the federation+decentralization properties can't be
manipulated to connect to things over non-tor.
It also appears to have the property that social networks where
everybody wants presence notifications for everybody else end up
requiring O(n^2) persistent hidserv connections between the n XMPP
servers... Not sure how serious this is, or if there are any workable
decentralized alternatives.
However, unlike torchat, the XMPP protocol itself is well documented,
widely used, and seems to be designed for a superset of the things we
want. I was able to spend just 10 minutes reviewing the XMPP specs to
fact-check before composing this email:
I was unable to determine if torchat even has property 1 in that time...

@_date: 2012-09-26 17:52:41
@_author: Mike Perry 
@_subject: [tor-talk] Tor and P2P 
Thus spake adrelanos (adrelanos at riseup.net):
Yeah. Due to my distributed systems background, I read "P2P" in this
thread as "peer to peer", not "filesharing". I assume that was the case
for most of the other Tor people commenting in this thread.
I would love it for Tor to support ways for people to communicate
without revealing either their social network or message content to the
network or infrastructure. I literally cannot stand the fact that there
are no ways to communicate right now without handing your social graph
to someone who wants to datamine it or sell it, or both.
I do think it is important to devote thought even to something as simple
as P2P chat, or we could end up destroying the network as soon as it
becomes popular, as Nathan and Robert said. Hidden services in Tor are
quite expensive: ~3-4X more expensive than exit circuits in terms of CPU
usage during connection setup, and 2X as expensive in terms of bandwidth
consumption during usage.
Because of this, I would be annoyed if people wrote bittorrent clients
that used hidden services the way I2P does. I would prefer it if people
focused such efforts on networks other than Tor, because I like Tor to
remain useful for things other than simply filesharing.
I recognize we don't have a whole lot of options to prevent such abuse,
but I am not opposed to stopgaps such as throttling loud clients and QoS
mechanisms to impact the popularity of resource-intensive filesharing
I suspect most of the other Tor folks in favor of "Tor and P2P" are in
the same boat.
