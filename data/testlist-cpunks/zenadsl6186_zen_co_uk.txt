
@_date: 2002-08-11 19:09:22
@_author: Peter Fairbrother 
@_subject: TCPA/Palladium -- likely future implications (Re: dangers of 
That was a software keylogger (actually two software keyloggers), not
hardware. (IMO Scarfo's lawyers should never have dealt, assuming the evidence was
necessary for a conviction, but the FBI statement about the techniques used
was probably too obfuscated for them - it took me a good week to understand
it. I emailed them, but got no reply.
Incidently, Nicky Scarfo used his father's prison number for the password,
so a well researched directed dictionary attack would have worked anyway.)
The FBI reputedly can (usually, on Windows boxen) now install similar
software keyloggers remotely, without needing to break in.

@_date: 2002-08-14 04:36:44
@_author: Peter Fairbrother 
@_subject: Spam blocklists? 
One of the ISP's I use (only until the contract ends!!) now forces me to
employ spam blocking, I have no choice.
Quote "It is necessary for Freezone Internet to put such measures in place
in order to ensure that other mail servers on the Internet do not block
traffic originating from Freezone Internet's mail servers. If Freezone
Internet were to be blocked, eventually over 90% of your email potentially
may not be received or delivered to its recipients."
IMO this is just plain wrong.
Spam is a problem, no doubt, but it's not evil or anything, and I object to
people stopping my email, for whatever reason (DoS attacks are another
There used to be an offence of interfering with the Royal Mail (in the UK,
with horrendous penalties). While the per-message cost of email is so low
that that concept is no longer viable for email, there must be better ways
to limit spam.
For instance, limiting the number of recipients of an email (the cryptogeek
system I'm working on [m-o-o-t] just allows one), or limiting the number of
emails one IP can send per day (adjusted for number of users).
There was an EU proposal to force spammers (who are not always unwanted) to
put [ADV] in the Subject: line, with appropriate penalties if they failed
to, but it didn't happen (and we got long-term traffic data retention
I don't know offhand how to do it, but having unelected and unaccountable
people (making the conditions for) stopping my email is unacceptable. If
somehow there was a limit to the number of people an email could be sent to
without a willing "passing on" by a human, that could limit the damage spam
could do, and be a better way to do it than involving stopping real (false
positive) emails.
A slightly drunk (you don't see me here very drunk that often, lucky
someone.... ,

@_date: 2002-12-02 14:57:19
@_author: Peter Fairbrother 
@_subject: CNN.com - WiFi activists on free Web crusade - Nov. 29,     
What I don't understand is how a node knows the location of a person who
moves about in the first place.
Also, I don't like the idea that my location is known by the location of my
equipment. But I know very little about geographical routing.

@_date: 2002-12-05 02:17:30
@_author: Peter Fairbrother 
@_subject: DBCs now issued by DMT 
OK, suppose we've got a bank that issues bearer "money".
Who owns the bank? It should be owned by bearer shares, of course.
Can any clever person here devise such a protocol?
I'd guess that all the Bank's finances should be available to anyone who
asks. That should include an accounting of all the "money" issued. And not
be reliant on one computer to keep the records.
Or the propounders wanting to: make a profit/control the bank?

@_date: 2002-12-13 06:43:53
@_author: Peter Fairbrother 
@_subject: Extradition, Snatching, and the Danger of Traveling to 
Dear America,
Yes, It's hard, but here's how. First, you can make comms unreadable. There
are well-known ways to do this. Second, you can make comms untraceable. Ways
to do this exist, and better ones are being developed*. Third, you can make
comms available to everyone - the 'net might help here.
If you don't choose to use these methods, the consequences are up to you.
But secure comms alone will only provide you with useful information, by
themselves they aren't enough; you need to vote. Lots of you.
Nothing else really matters. To "them", and you.

@_date: 2002-07-15 15:27:11
@_author: Peter Fairbrother 
@_subject: Which universe are we in? (tossing tennis balls into 
Yes it does. Heisenberg Uncertainty Principle. Ring a Bell?

@_date: 2002-07-16 18:39:34
@_author: Peter Fairbrother 
@_subject: Which universe are we in? (tossing tennis balls into  
Oh dear. QM does rule out internal states.
I didn't think I would have to explain why I capitalised "Bell", but perhaps
it was a bit too subtle. Google "Bell" and "inequalities", and go from
there. The uncertainty principle was generally considered to rule out internal
states long before Bell, though. Since around 1930, I think. Whether QM/the
uncertainty principle is wrong is a different question.

@_date: 2002-07-31 20:07:16
@_author: Peter Fairbrother 
@_subject: Challenge to David Wagner on TCPA 
The wise general will plan his defences according to his opponent's
capabilities, not according to his opponent's avowed intentions.
However, in this case the intention to attack with all available weapons has
not been well hidden. There may be some dupes who honestly profess that no
attack is planned, and some naif's who cannot or will not see the wood, but
they will reap the whirlwind.
My humble opinion,

@_date: 2002-06-26 04:05:30
@_author: Peter Fairbrother 
@_subject: Ross's TCPA paper  
Neither do I. If one-way functions exist there is no such symmetry. While in theory such
functions cannot be proved to exist, in practice they are used a lot in
crypto etc.

@_date: 2002-06-28 17:02:43
@_author: Peter Fairbrother 
@_subject: Stick this up... 
On the subject of trusted hardware: m-o-o-t does this, by booting and
running from a verified CD on an ordinary PC/Mac box. No expensive chips.
BTW, there was a M$ patent for Tsomewhere, can I claim prior?
We're getting close to anonymity (PA). Too. :)  Nah, that's not big enough.
Add that to the mix,
remembering that TYABBAYABBA won't work 100%, and some geeky people will be
able to redistribute *m*o*v*i*e*s* without being caught. Then their friends
will do so too (their friends),
and if it's anonymous.... (and I mean _really_ anonymous...)
I'm going to buy some more of this fine beer now. I'll probably wish I
hadn't posted this, at some time in the future.
Peter

@_date: 2002-11-12 21:06:52
@_author: Peter Fairbrother 
@_subject: Yodels, new anonymous e-currency 
Nomen Nescio quoted:
Why? What for? It's the customers who need anonymity, not the Bank.
It is now legal in the UK and the EU to issue "private money". You need a
lot to start (euro100k or so) and you need to follow some regulations, but
AFAIK customer anonymity isn't prohibited.
I'm not clear on the details though. Started around the beginning of summer,
sorry no ref's, but an inventive Googler should find something. I think Ben
(Laurie) was interested in doing something along these lines.

@_date: 2002-11-20 23:22:30
@_author: Peter Fairbrother 
@_subject: OPPOSE THE WAR! We are going to ruin Iraq to get the oil.   
There isn't that much difference in reload times - say 30 seconds for a
Kentucky rifle, as opposed to 20 seconds for a Brown Bess musket, for
well-trained troops. However, if you are in a volley line and waiting for
the last man to reload before firing a volley, that's a lifetime. Remember,
you are standing up to reload! Putting a few men armed with rifles in a line
of musketmen, they would seem useless, or worse, a liability.
Before I get flamed about those figures, may I point out that modern black
powder flintlock rifle shooters can and do shoot about one round a minute,
without trying to fire fast - a hotspot on the barrel can cause the powder
to cookoff unexpectedly, so they service the bore and touch hole between
shots, which slows them; but this isn't so important on the battlefield when
risks can be taken. It is said that Simon Kenton could reload his Kentucky
rifle in 12 seconds. The world record Springfield reload is about 6.5
seconds, a Brown Bess will take a bit longer than a Springfield.
At first glance the rifle was a better infantry weapon, but pitched battles
at 300 yards just didn't happen - and smoke obscuring the battlefield made
aimed shots difficult after a few volleys. Muskets weren't usually aimed,
just pointed in the right direction - musketmen were sometimes told to close
their eyes when firing to prevent injury from pan flash.
In volley fire it isn't really possible to aim - for aimed fire you need to
fire when the rifleman is ready, not on command. The superior accuracy of a
rifle is no use if you can't or don't aim it. The time taken to aim also
slows the rate of fire over an unaimed weapon.
Another problem was that early rifles weren't optimised for battle or use in
an army. It was often difficult starting the ball down the barrel, which can
slow reload time - there's a tool to do it, and you then use the ramrod, but
if the rifle/ball/patch combination is right you can start the ball by
hitting it with the ball of your hand, and the ramming can be quite quick.
Rifles were seldom fitted with bayonets, important to the tactics used at
the time - fire a volley or two, then a bayonet charge while your opponents
are reloading. They were also too fragile to use as a close quarter club.
Rifles weren't standardised either, so ammunition and parts couldn't be
shared and the riflemen had to cast/roll their own balls. Rifle balls need
to be more accurate than musket balls. Rifles take more training to use as
But I think the main reason that rifles didn't play a bigger part, apart
from the usual military inertia (google Ferguson rifle for a British example
of this), was the simple lack of rifles, and their cost. Many men fighting
in the Revolutionary War didn't have any firearms at all.

@_date: 2002-11-20 23:22:30
@_author: Peter Fairbrother 
@_subject: Psuedo-Private Key (eJazeera) 
Yes it exists. It's called deniable encryption. Two-level deniable
encryption is not hard, but it usually involves increases in data size.
There is some stuff about this in Crypto and Eurocrypt reports.
Steganography and steganogaphic filing systems can do something similar, but
the increase in message size tends to be larger.
I am developing a form of deniable encryption (as part of m-o-o-t) that
works slightly differently and does not involve message-size increases - in
fact it it decreases message size.
It's grammer-based and works a bit like this: A sentence is parsed, and eg
a noun is encoded as a number relating to one of a publicly shared
dictionary of nouns. This number is then encrypted. Decrypting with a random
key will give a noun in that position in the sentence in all possible
decryptions, and a good proportion of all randomly keyed decryptions will
apparently make sense.
There is a lot more involved, so eg both parties can give out the same false
key, and so eg the same nouns used more than once in a message will decrypt
to identical nouns in decryptions, as well as notions of closeness in the
words used in a typical message, but I have done both the theoretical
unicity calculations and some practical tests, and it works for email-length
messages. The main implementation problems I have are coding time and that the only
parser that works well enough is proprietary. If anyone else is working on
something similar I would like to know. I'm probably not a cypherpunk, more
a privacy avocate, but I do write code.

@_date: 2002-09-10 03:16:29
@_author: Peter Fairbrother 
@_subject: A message from Alan I. Leshner, AAAS CEO 
I think it's actually quite reasonable: below is the proposed new list of
agents with some notes from me in [>  <] (much the same as the old list,
which is presently used to regulate transport, and you already need to be
registered to send/receive these agents), and except for malicious reasons I
can't think why anyone would want to use them outside a fully-equipped lab.
Anyone who does is showing negligent disregard for human/ the public's
safety. And his own.
While there may be an anti-terrorist element to the Public Health Security
and Bioterrorism Preparedness and Response Act (I haven't read it), there's
a safety element too. I don't know if any labs who do things right will be
refused registration/permission, we'll have to see. They may need armed
guards or something. At first sight it doesn't affect researchers much (they
already need approval/licences to work on most of this stuff, it's mostly
changes to regulations about storage).
A curiosity - a 1oz packet (the smallest size available to gardeners) of
castor beans probably contains more than the exempted 100 mg of ricin.
However, it's not a "Toxin preparation", so they won't have to register.
Could kill quite a few people if it was.

@_date: 2002-09-17 17:39:03
@_author: Peter Fairbrother 
@_subject: Bush admin cybersecurity report weighs anonymity 
I wonder whether the authors know that it is impossible to stop anonymous
communications for the intelligent criminal or terrorist who is willing to
jump through a few hoops.
If they don't, they shouldn't be writing such reports, as they are not
qualified. If they do, then I wonder at their motives. The use of the term
"wide-scale" is worrying in it's implication that they do know of the
impossibility, and merely want to prevent anonymity for the masses.
If the motive is to provide general surveillance capability, it is
reprehensible and oppressive. Didn't you 'merkins once fight against
oppressive government?
If it's intended to help catch the dumb criminals and terrorists, they are
mistaken about it's likely effectiveness - tracing is only useful when there
is something worth tracing, and this only happens when people are unaware
that their communications can be traced.
Even dumb criminals and terrorists (who can usually be caught by less
intrusive methods anyway) will quickly learn not to use traceable
communications. Disposable mobile- and pay- phones are already favourites. I
suppose they might be comparing the slight, short-term benefit to be gained
in the ease of catching the dumb against the long-term loss of liberty for
all, and weighing the loss of liberty at naught.
If the motive is to give citizens the feeling that something is being done,
it's just more political bullshit, but with unfortunate consequences. I
can't think of any other possible motives.

@_date: 2003-04-13 05:04:10
@_author: Peter Fairbrother 
@_subject: Kill MS, again, but sideways 
I got a request from a (US) psychiatrist that m-o-o-t (m-o-o-t is a CD that
boots on your computer, and does secure things) should include an
implementation of VOIP, to allow his patients to securely connect to his
server. I think they are mostly servicemen or spies, but so what.
It's actually easy to do a version that will do that, and if you're
listening, I'll do it soon, and for free to you only  :)  - but m-o-o-t is
based on OpenBSD, and isn't that good at modems. Linux isn't that good
The problem is that the usual, everyday, modem is _only_ supported by
Windows... which thereby gains a competitive advantage, based on it's
monopoly position.
While I have no beef (and being a UK person I eat no beef anyway) with the
idea that there should be a single computing platform/ interface, and I
don't expect manufacturers to do the work, I do think that interfaces used
en masse should, in general, be communal property. That includes modem
interfaces, especially. Apple is no better either here.
I'd like to suggest that those who don't provide details of their modems'
functionality (which is the main problem) should be boycotted. Or killed.
Similar applies to all hardware.
It's not a very libertarian perspective, and I like to think I am a
libertarian - but so be it. The alternative is...

@_date: 2003-04-19 06:50:02
@_author: Peter Fairbrother 
@_subject: Military Drops OpenBSD Funding Because of de Raadt's 
OpenSSH, sshurely.
Is that UK-based? OpenSSL might well be, at least sort-of, but OpenSSH? I
dunno, but I doubt it.
There are potential problems ahead for OpenSSL in the UK. The EU dual-use/
(including crypto) export control regulations might be about to be
implemented here, under the Export Control Act 2002,.. but it won't affect
the actual releases, just talking about them beforehand...

@_date: 2003-04-25 12:45:08
@_author: Peter Fairbrother 
@_subject: Military Drops OpenBSD Funding Because of de Raadt's  
It looks like you'll need a licence (or registration) to run a mirror of the
BSD's, Linuxes, etc..
Will probably apply in all EU countries soon.

@_date: 2003-04-28 15:42:41
@_author: Peter Fairbrother 
@_subject: Anonglish (was: Re: Authenticating Meat) 
I'm starting to do something slightly similar, for different reasons. It's
part of a deniable encryption project.
If you have perfect compression, and you encrypt a message which has been
compressed, any decryption will look sensible.
This means that you don't need long keys, that brute force attacks won't
work, and that any supposed decryption is deniable. Unfortunately it's
theoretically impossible to achieve, and difficult to usefully approach,
perfect compression.
What _is_ possible, at least in theory, is super-perfect compression,
wherein the set of possible messages is reduced. The way I am attempting to
do it is quite similar to your proposal, but there's a long way to go yet!
There's an August 2001 thread in the sci.crypt.research archives called
"Grammar/dictionary-based compression for deniability:" in which I explain a
bit more about it (or rather, about an earlier version). The "super" bit
solves, at least in theory, the unicity problems.

@_date: 2003-04-30 17:36:01
@_author: Peter Fairbrother 
@_subject: Anonglish (was: Re: Authenticating Meat) 
I do realise that. More, it has to be able to fake the sender, not just a
random human.
I'm not trying to build that sort of compressor tho' - but see my ps.
The compressor I'm beginning to build now does not have to pass a Turing
test directly. It can only compress a limited subset of possible messages,
and if that subset is small it's easy to see that it can be done.
Say your possible messages are:
Attack at dawn
Attack at dusk
Retreat at dawn
Retreat at dusk
Assign a number to the verb, and a number to the "time" (not being a
grammarian I don't know offhand what that part of speech is called). In this
limited case that's just two bits, so eg "Attack at dawn" compresses as
Now encrypt that 0x00, using eg an XOR with a key of 10, to give ciphertext
0x10. Decrypting that with key 00 gives message 0x10 - which decompresses to
"Attack at dusk", a plausible decryption*.
There are further considerations when variable sentence structures,
multi-sentence messages (and lots more things) are considered, of course.
For instance, longer messages have to be self-consistent, which can be done
using closeness arrays and best-fit techniques. And doing it on a wider
scale is harder, and a whole lot of work...
* However, if "Attack at dusk" is an unlikely message because of real-world
events, eg you have already won the battle, then the decryption loses some
There are several ways around that. First is to have a "godlike" compressor
which knows everything in the real world, or at least everything any sender
is likely to send, so that _all_ possible decryptions are real-world
plausible, but that's not within my ability to write. It's impossible anyway
(unless you're God).
Second is to just accept that only a portion of possible decryptions will be
real world plausible (most, if not all, should be language-plausible and
self-consistent-plausible). It shouldn't be hard to get a small proportion
to be rwp.
This is still very useful, as an attacker can't distinguish between a
brute-forced set of real-world plausible decryptions (a subset of all
possible decryptions, which should be large enough to contain many examples
of contradictory decryptions), and a purportedly real decryption can be
challenged by producing a different real-world plausible decryption, or
preferably ten thousand of them.
Having a fake key that decrypts to a rwp decryption can be done, if the fake
key is prearranged before the message is sent. Useful when lots of messages
are encrypted with the same key. If you can check the decryption first, you
can also afterwards select a key that will give a rwpd.
Third is to try and get almost all decryptions to be rwp, using complex
techniques (!) and the fact that the set of messages that can be sent is
limited. For instance, if it was limited as in my example above and you
wanted to tell someone that you couldn't go on a promised date this evening,
you would send "retreat at dusk". This is a very contrived example, of
Unfortunately you still can't give a randomly-chosen-afterwards key which
will _always_ give a rwpd, which would be _very_ nice to do.
I'm investigating a few possible ways to do that, perhaps just to do it
effectively without 100% of possible decryptions being rwp, but I haven't
gotten any results worth repeating yet.
And yes, I do know the theory that says it's impossible. Change the
conditions a little and the theory might not be applicable any more.

@_date: 2003-05-01 00:03:38
@_author: Peter Fairbrother 
@_subject: Anonglish (was: Re: Authenticating Meat) 
The property of encryption in a particular cipher not being a group
operation is insufficient in itself to make multiple encryptions in that
cipher stronger than single encryptions in it. It may be the case that
multiple encryption is less secure than single encryption. Not likely, but
it is possible.
If the encryption is a group operation then at best multiple encryptions
using that cipher are as strong as single encryptions - but if the keys are
related then it is possible that multiple encryptions may be weaker, and
it's a difficult (maybe even hard) problem to decide whether the keys are
Then there's the meet-in-the-middle attack, qua google.
Using multiple encryption in different ciphers is a fraught subject, full of
potential pitfalls. It hasn't been well researched, probably partly because
it's so complex. It is possible that it can be less secure than single
encryption in a single cipher.
Personally, for the two ciphers case, I'd choose Blowfish and AES, ensuring
the keys are randomly and seperately generated, because Blowfish is a
Feistel cipher and AES isn't (and because both are well-peer-reviewed, and
available), but that's just a feeling which I can't really justify
(All this is a bit nit-picking-ish, except the [multiple encryption with a
ciher that is a group operation can't be stronger than a single encryption
with that cipher] bit, and anything else is not _likely_ to be relevant, but
it still should be considered when designing multiple encryption systems)

@_date: 2003-08-07 14:00:52
@_author: Peter Fairbrother 
@_subject: [eff-austin] Antispam Bills: Worse Than Spam? 
Troll or not, if AOL censored email in the UK* it would be illegal
interception. 2 years for every interception.
IMO, that's the only good thing to come from the RIP Act (the one with
not-(yet)-implemented GAK).
Freedom to do your own thing is great, but what if the baby bells refused to
connect you to another baby bell? The benefits of a unified 'phone service
are such that legislation prevents baby bells doing that, and most of us
would agree with that legislation. IMO, email should be similar.
But it don't solve the spam problem :-(

@_date: 2003-02-05 08:31:29
@_author: Peter Fairbrother 
@_subject: Transport, the near future 
It's a nice idea, but it needs a tensile-strength-to-mass ratio equivalent
to holding a girl and her mother up by a single thread of her 10 denier
stockings. Not easy to achieve. You'd need carbon nanotubes or the like, and
at the moment we can't build it. You also need 45,000 km or so of tether.
Expensive. Huge investment, fragile. Unrealistic, imo.
Rotating tethers on the other hand can use hi-test fishing line. Really, no
kidding.  You only need a few hundred km, or at most a few thousand km, of
tether. Cheap.
There are two types, landing takeup and hypersonic takeup. They work a bit
like this (here goes a try at some ascii art...)
               [] orbiting mass-->
                \
                 \ rotating tether
                  \
                   \
                  <-\      space
            --------------------
                           atmosphere
           ________________________
                           earth
(on this scale a space elevator cable would be roughly six feet long)
The tether, whose centre of gravity is in a fairly low orbit, dips it's end
into the earth's atmosphere every so often. Hypersonic takeup tethers catch
a 'plane flying at hypersonic speeds in the upper atmosphere, and landing
takeup tethers reach the surface. The energy/momentum is replaced by sending
current through the tether as it passes through the Earth's magnetic field.
Hypersonic takeup tethers are better studied, even the rendezvous techniques
apparently work, and can use fishing line except for the short length that
enters the upper atmosphere (it would melt). They use a mesh-like tether
structure to avoid catastrophic damage from meteorites etc (a patented, but
IMO obvious, idea).
Landing tethers sort of cast the line a bit ahead, like a fisherman; it hits
the ground, is tied on to the spaceship (good knots!) and then the line and
the spaceship are dragged up. No-one really has studied them much (except
me, and I'm not telling yet), but the strength (and length) of line needed
is _much_ (order of mag+) less than a space elevator. And you don't need a
hypersonic 'plane.
You can also fling things away from the tether when they're going away from
the Earth. Can get any (reasonable) speed you like.

@_date: 2003-01-04 02:01:30
@_author: Peter Fairbrother 
@_subject: constant encryped stream 
Get the "pull" from a "party popper" and wrap it in a dollar bill. Record
the serial number of the bill (some crypto here maybe). Make it impossible
to open the closet without setting the "pull" off, ie no trapdoor.
Fairly good tamper-evidence, and the token is hard (and very illegal!) to
forge. Also the dollar bill is still spendable, so the only cost of your
accesses are the "pull"s.
Depends on your threat model, of course.

@_date: 2003-01-07 20:36:59
@_author: Peter Fairbrother 
@_subject: The Microsoft Xbox Key/dvd issues 
The entertainment lobby has failed to persuade a Norwegian court to convict
a teenager for creating a utility for playing back DVDs on his own computer.
Jon Lech Johansen has been acquitted of all charges in a trial that tested
the legality of the DeCSS DVD decryption utility he produced, Norwegian
paper Aftenposten reports.
Norwegian prosecutors, acting largely on the behest of the Motion Picture
Association of America (MPAA), argued in court that Johansen acted illegally
in sharing his DeCSS tool with others and distributing it via the Internet.
They claimed the DeCSS utility made it easier to pirate DVDs.
The court rejected these arguments, ruling that Johansen did nothing wrong
in bypassing DVD scrambling codes that stopped him using his Linux PC to
play back DVDs he'd bought.
(They go on to say that it's not illegal to use DeCSS to play dvd's. So if
you haven't already got a copy, you can get one now, in Sweden at least.)
There is a product called DVD region x for the xbox that allows you to play
dvd's from any region coming out soon. As it probably has to be signed by
Microsoft (as all xbox programs must be), can we assume that the
regionalisation of DVD's silliness is effectively over?
And apart from that, what was the point of CSS? You can do a "dd" on a DVD
and play the image from a hard drive. I don't have a DVD burner, but I'd
imagine you could burn a DVD from such an image, so direct copying is
probably easy enough. Maybe I'm wrong, I haven't tried it, but the pirates
don't seem to have any technical trouble.
The regionalisation issue was another monopoly grab. The DVD format is as
much a monopoly as Microsoft or Intel (probably more...)

@_date: 2003-01-15 14:53:50
@_author: Peter Fairbrother 
@_subject: Strange spam 
I just got this spam, and I was wondering if it was a honey-pot. Anyone? The
site exists, and advertises games and movies for download.

@_date: 2003-07-08 18:40:08
@_author: Peter Fairbrother 
@_subject: Idea: The ultimate CD/DVD auditing tool 
Eh? It's a spiral.
The constant linear velocity applies to the scan velocity (1.3 m/s at 1x),
not the head velocity, which might cause problems.
Also the spiral track/ holes in the centre aren't accurate enough to follow
the track without real-time correction, done by some complex optical tricks
and feedback loops.
However, it should be quite easy to get a signal from somewhere in the CD
player (especially from early ones which split the functions between lots of
chips), probably best would be from the EFM (eight to fourteen modulation)
or frame output. This will include all the interesting subcodes etc., plus
sync and C1/C2 parity bytes.
That's a fairly clean (it's digital, but with errors) signal at about 2.1
Mb/s at 1x speed, so it shouldn't be hard to capture and analyse in real
time  :). However, you will still have to do the CIRC decoding.
If you are feeling adventurous you could just take a signal from the laser
head, and do the timing, EFM, circ etc yourself. That will give you the
pits, plus the errors, plus a lot (!) of work. Not recommended really,
unlees you need it for some (anti?) copy-protection purpose.
As for getting the player to actually follow the track on a protected disc,
again the solution is probably to go for an older player and hack about. I
used to repair them (a long time ago, when it was worth doing), it should be
quite easy (though I'm no expert on CD copy protection). There was a mod
involving just putting a few volts on one chip lead on an early Sony model,
but I can't remember enough details to find a ref.
A curiosity, only tenuously related - I just came across a Feb 1994 copy of
Elector magazine, with plans for a S/PDIF copybit eliminator (for SCMS).
Seems people have been defeating copy protection for a while..

@_date: 2003-07-09 01:24:42
@_author: Peter Fairbrother 
@_subject: Idea: The ultimate CD/DVD auditing tool 
okay I'm a bit pissed now. actually i'm raging pissed! Wheeee!!!
the nyquist/lindquist/someone-else-who-was-pissed sampling theorems are
based on the possibility of mathematically extracting frequencies from
digital information in a STEADY_STATE situation.
That doesn't mean that a speaker will properly reproduce those frequencies.
Consider the dynamics of energy transfer. A digital signal at
near-1/2-sampling frequency will have two datum points. The transitiion
between them will be dramatic! the possibilities of energy transfer will not
be comparable to an analogue sinusoidal waveform.
And that's why good analogue is better then good digital.
Doug Self etc. did some work on ultra-fast analogue systems in the mid 90's,
and designed some amps that were and are regarded as pretty good - but afaik
he didn't get the theory right.
YAAAAHHH!-- Peter Fairbrother

@_date: 2003-07-09 02:47:40
@_author: Peter Fairbrother 
@_subject: Idea: The ultimate CD/DVD auditing tool 
the nyquist/lindquist/someone-else-who-was-pissed sampling theorems are
based on the possibility of mathematically extracting frequencies from
digital information in a STEADY_STATE situation.
That doesn't mean that a speaker will properly reproduce those frequencies.
Consider the dynamics of energy transfer. A digital signal at
near-1/2-sampling frequency will have two datum points. The transitiion
between them will be dramatic! the possibilities of energy transfer will not
be comparable to an analogue sinusoidal waveform.
and i missed a bit or two. Consider the entropic uncertainty of a signal
that has two-and-a-bit datums, against a sine wave. Start from zero, and go
to such a waveform. Is it a constant-amplitude sine wave at frequency z? or
a decaying sine at a frequency (z-at)?
There's more, and it's to do with the limits of fourier and sampling theory.
Say you have a wave at a frequency of z that's sampled according to nyquist
theory. can you distinguish it from a wave of a frequency z - delta z? It
can be done, but it takes a while, and a good few samples to do it. And a
good analogue system will do it quicker.
someone (hopefully not me, i haven't the time just now) can probably apply
wavelet theory and get all this from steady-state theory, and tie it up in a
nice package.

@_date: 2003-07-17 12:12:12
@_author: Peter Fairbrother 
@_subject: Security for Mafiosos and Freedom Fighters 
A long time ago I used to teach an "intro to computing" class. many students
were older people who were afraid to physically touch a keyboard - partly
just because it was unfamiliar, because it meant they were actually, now,
starting on the road to learning, because they feared to "break something",
or because they thought they might get a shock (I kid you not). I digress.
One way of making them feel more comfortable was to "accidently" spill a
drink on a keyboard, than immerse it in a sink, rinse, and hang out to dry.
Sometimes I used a hairdrier to reuse the keyboard during the lesson, but
mostly I just left it overnight to dry. That gave some at least of them some
confidence that it was ok to touch the keyboard.
I've also washed an iMac (which had fallen in the sea) by immersion in tap
water and careful drying, the CD needed more care (drying with IPA), I took
out the hard drive first and was careful with that, also cleaned all
connectors with solvent cleaner, but it worked ok afterwards.
BTW, do NOT do this with crappy Apple keyboards! They are membrane-based and
will be destroyed. They are also hard to open for repair, and when I asked
an Apple chap about them he said "You should never drink near a keyboard".
What crap!
I give no guarantee that it won't destroy your keyboard, but it won't hurt
most keyboards.

@_date: 2003-07-18 00:25:14
@_author: Peter Fairbrother 
@_subject: Sealing wax & eKeyboard 
Peter Fairbrother (me) wrote (in a different thread):
(senhorita contains the 9 most-commonly-used-in-English letters, tho' not in
There is another problem - assuming the TEMPEST gear or camera can't see the
randomised resistant letters, if it can follow the cursor then it's just a
simple substitution cypher to get plaintext (assuming the gear can get
I thought of having a large cursor grid, with resistant symbols on each grid
place, and changing the position of the operative symbol every so often -
how often? -  but I don't know how to get such a large cursor - any ideas? X
on OpenBSD preferred.
Any better ideas?

@_date: 2003-07-21 19:49:03
@_author: Peter Fairbrother 
@_subject: Defeating Optical Tempest will be easy... 
a_b_sorbed. Absorb is a widely used word meaning 3to drink in, to soak up,2
both literally and figuratively. Adsorb is a specialized technical term,
meaning only 3to collect a condensed gas or liquid on a surface.2
The glass of CRT's absorbs so much of the X-rays that it might be hard to
detect a signal at all at any distance, but then the signal is not swamped
by noise from the not-immediately-illuminated areas, unlike the optical
"0.5 milliroentgens per hour at a distance of five (5) centimeters from any
point on the external surface of the receiver" is the US legal limit[*], and
low voltage (and thus very low x-ray emission) crt monitors are common now,
if not a de-facto standard.
However, I expect shot noise to be a limiting factor here. Unfortunately,
the Roentgen is such a wierd unit it's not that easy to convert it to
photons and do the math!
A light background on a CRT screen image will give out enough delayed light
to give problems in the s/n ratio of an optical TEMPEST attack. It's much
easier to "see" white text on a black background than black text on a white
I use 180:210:210[**] (r:g:b) text on a 255:255:255 window background at
present, with very light wallpaper, though I speckle both slightly. It's a
little hard to read, but much better than some other suggested combinations.
[*]< Probably far too high for safety! Originally for TV's, where the
viewing distance is much higher. But most modern monitors will emit much
less than that. I hope! >
[**]< I replaced the black in Marcus's anti-em-tempest fonts with
180:210:210, and varied the other colours in proportion. >

@_date: 2003-07-26 14:15:36
@_author: Peter Fairbrother 
@_subject: A 'Funky A.T.M.' Lets You Pay for Purchases Made Online 
'Twas meant for the list, I just hit "reply" instead of "reply all" without
looking.  and  don't set a Reply-To: header, but does. I don't get any mail from other nodes, if there are any.
So some list mail needs a "reply" to get to the list, and some needs a
"reply to". Personally I prefer to hit "reply", ie with a Reply-To: header set to the
list (confusing, eg!). That way, if I want to reply to the list (which is my
default preference) then the sender of the mail I'm replying to doesn't get
two copies. But then I use OE...
Perhaps  and  could do this? Or, if people prefer,
 could stop setting the Reply-To: header?
Or would having all the nodes do it the same way be too conventional for

@_date: 2003-11-12 01:17:09
@_author: Peter Fairbrother 
@_subject: Deniable data storage 
Information-theoretic deniability is impossible (or impractical). You can
have computationally-bounded secure deniability though.
StegFS (if that's the one Markus Kuhn wrote, there is another program with a
similar name which isn't as secure), and the other construction in Ross
Anderson, Roger Needham and Adi Shamir's paper [1] are pretty good, at least
as good as your outline construction.
All hide ciphertext in random data, rather than in eg images, where there is
no underlying pattern to the covertext which an adversary can use a better
understanding of than the filing system has to extract and identify
The moral? - hide ciphertext in random data, not "partly-random" data such
as images.
You might also want to look at Mnemosyne [2], but I haven't analysed it and
have no idea whether it's any good.
It also depends on whether your adversary is going to torture you, or take
you to Court. There's not a great deal of difference in effect, but a
torturer can harm you on suspicion only, whereby a Court can't jail you on
suspicion alone but needs, at least in theory, proof beyond reasonable
Getting a bit theoretical now, but still important:
Two problems with all these systems are observability and secure deletion.
If the database can be continuously observed (eg a NFS-based FS) then an
adversary can ask why the SFS was modified. This can be overcome - I'm
writing a paper on how to do that right now, but it's not finished yet.
Secure deletion is harder - if someone can prove that some data is in the
SFS (or, combining this with observability, that some data was at some time
in the SFS) then they can demand a key - are you going to remember a zillion
different keys/passwords, and what they refer to? If you store them
somewhere then they can demand the key to the keys, so to speak.
I think secure deletion in observable SFS's is impossible, it seems obvious
on information grounds - but there also seems to be just a teeny hint of a
crack in that proof. I'm working on it.
James, you might want to move this to eg the cryptography list if you want
more technical answers. Or subject yourself to sci.crypt's abuse, which will
at least stop some elementary mistakes.
[1] [2]

@_date: 2004-03-09 22:38:24
@_author: Peter Fairbrother 
@_subject: Evidence is clear: Videos convict 
With The-Man-With-No-Name in it. I remember. She wasn't killed in a white
house though, but in a rich man's apartment. It could have been white.
There was a reflection in Blade Runner too, with Indiana Jones.
(dons Conspiracy-Finder uniform and  ...

@_date: 2004-05-19 00:22:14
@_author: Peter Fairbrother 
@_subject: Diffie-Hellman question 
No need. The best known discreet logarithm attacks are such that if they succeed in
the attack then they can easily apply their solution to anything encrypted
with the same prime. A shared prime attracts attacks. Widely used primes can
become a big target.
These attacks are generally supposed to be beyond capability for the next X
zillion years though. Or perhaps for ten years.
This might seem garubonsendese in the naive ""it's safe' or 'it's not safe""
crypto paradigm. However, that isn't how crypto works.
Cryptanalysis (the revealing of plaintext against the wishes of the
encryptor) is an economic activity. No-one will bother putting in enough
resources to break your 2k-bit modexp-based crypto unless they think it
But if your prime is shared with several other people who are sending
nuclear secrets, then your prime might become subject to attack.
The prime is public - anyone can know it  - so it's retrieval won't affect
anything. The question I think you are asking is "if the secret key is retrieved, will
I lose forward security", to which the answer is "yes".
For long-term forward secrecy you need to change the public key every every
day or so. Use a long-term key to sign the daily keys. PGP does this.
Once you have deleted the day's public key, you are OK (but see belaw!).
The ephemeral keys cannot (or should not) be retrive(able)d.
(below!) Or perhaps the question you were asking was "if finding DL's mod
_this prime_ becomes possible, will I lose forward security?", in which case
the answer is "yer fukked" - as are we all - if one prime gets broken, they
all will, sooner or later.

@_date: 2007-07-04 20:22:56
@_author: Peter Fairbrother 
@_subject: UK RIPA Pt 3 
The UK Home Office have just announced that they intend to bring the provisions of Pt 3 of the Regulation of Investigatory Powers Act 2000 into force on 1st October. This is the law that enables Policemen to demand keys to encrypted material, on pain of imprisonment, and without judicial approval of these demands.
There is one last Parliamentary process to go through, the approval of a code of practice, but as far as I know there has never been a case of one of these failing to pass - though a related one was withdrawn a few years ago. We will try to prevent it happening, the chances of success are against us but it is not impossible.
You are not required to keep keys indefinitely, or give up a key you don't have, but the rules regarding the assumption that you know a key at least partially reverse the normal burden of proof.
m-o-o-t will be there on the day. m-o-o-t is a freeware live CD containing OS and applications, including an ephemerally keyed messaging service, and a steganographic file system.
If anyone knows of any other technologies to defeat this coercive attack I would be glad to hear of them, and perhaps include them in m-o-o-t.

@_date: 2013-09-08 16:20:40
@_author: Peter Fairbrother 
@_subject: [Cryptography] A Likely Story! 
This is just a wild story, It isn't true. If we cryptographers found
it was true we would all be totally gobsmacked.
The Beginning:
Sometime in 2008 the NSA - the United States National Security Agency,
who employ many times more mathematicians than anyone else does -
discovered a new mathematical way to factorise big numbers better.
It wasn't a huge advance, but it would be good enough for them to
factorise several hundred 1024-bit-long numbers per month using some
big computers they wanted to build.
In the form of RSA public keys, these 1024-bit numbers were (and
sometimes still are) used to generate the session keys which encrypt
and protect internet traffic.
A session key is the key which is used to encrypt the traffic between
you and a website, using a normal cipher - it is a shared secret
between you and the website.
Setting up a shared secret session key, when the communications used
to set it up may also be intercepted, is quite difficult and involves
considerable tricky math. That's where RSA and factorising comes in.
In 2008, when you saw a little padlock in your browser, the connection
was almost always encrypted using a session key whose secrecy depends
on the inability of anybody to factorise those 1024-bit RSA numbers.
They change every few years, but usually each big website only uses
one RSA key per country  - so when the NSA factorised just one of
those RSA keys it could easily find the session keys for all the
internet sessions that website had made in that country for a couple
of years.
Now the NSA had been collecting internet traffic for years, and when
the big computers were built they would be able to see your past and
present online banking, your secret medical history, the furlined
handcuffs you bought online ..
The Dilemma:
So, did the NSA then go "Hooray, full steam ahead?" Not quite. The NSA
has two somewhat conflicting missions: to be able to spy on people's
communications, and to keep government communications secure.
On the one hand, if they continued to recommend that government people
use 1024-bit RSA they could be accused of failing their mission to
protect government communications.
On the other hand, if they told ordinary people not to use 1024-bit
RSA, they could be accused of failing their mission to spy on people.
What to do?
Some Background:
Instead of using 1024-bit RSA to set up session keys, people could use
a different way, called ECDHE. That stands for elliptic curve Diffie
Hellman (ephemeral), the relevant bit here being "elliptic curve".
You can use any one of trillions of different elliptic curves,which
should be chosen partly at random and partly so they are the right
size and so on; but you can also start with some randomly-chosen
numbers then work out a curve from those numbers. and you can use
those random numbers to break the session key setup.
The other parts are: starting from the curve, you can't in practice
find the numbers, it's beyond the capabilities of the computers we
have. So those if you keep those random numbers you started with
secret, only you can break the ECDHE mechanism. Nobody else can.
And the last part - it is convenient for everybody to use the same
elliptic curve, or perhaps one or two curves for different purposes.
So if you know the secret numbers for the curve, you can break
everybody's key setup and get the secret session keys for all the
traffic which uses those curves.
The Solution:
Make government people use ECDHE instead of RSA, but with the NSA's
special backdoored elliptic curves. Ordinary people will follow suit.
This solves both problems - when people change to the new system the
NSA can still break their internet sessions, and government
communications are safe from other people (although the NSA can break
US government communications easily - but hey, that's the price of
doing business, and we're the NSA, right?).
Someone else might find the factoring improvement, but it is thought
infeasible that someone else would be able to find the secret
"Hooray, full steam ahead!"
That's the story.
The rest is just details - maybe the NSA somehow got NIST to put their
special backdoored curves into NIST FIPS 186-3 recommendations in
2009, so people would use them rather than make up curves of their own
- it is usual and convenient, but not strictly necessary, for ECDHE
software to only be able too use a small selection of curves.
Maybe they asked the US Congress for several billion in extra funding
in the 2010 budget to run the RSA-breakers.
Maybe they are building a new "data center" in Utah to use the session
keys to decrypt the communications they have intercepted over the
Maybe they put those special backdoored curves into Suite B, their
official requirements for US Government secret and top secret
Or maybe they didn't. It's just a story, after all. The cryptography,
while incomplete, is correct, and it may all seem plausible - but of
course it isn't true.
