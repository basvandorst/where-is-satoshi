
@_date: 2003-06-03 14:46:27
@_author: Anne & Lynn Wheeler 
@_subject: Maybe It's Snake Oil All the Way Down 
> That's a red herring.  It happens to use X.509 as its preferred bit-bagging
 > format for public keys, but that's about it.  People use self-signed certs,
 > certs from unknown CAs [0], etc etc, and you don't need certs at all if you
 > don't need them, I've just done an RFC draft that uses
 > shared secret keys for mutual authentication of client and server, with no
 > need for certificates of any kind, so the use of
 > certs, and in particular a hierarchical PKI, is merely an optional extra.
 > It's no more required in SSL than it is in SSHv2.
the pk-init draft for kerberos allows public keys .... allowing both
cert & cert-less implementation
the scenario allows for public key registration in lieu of shared secret
registration. the scenario is that r/o access, divulging, sniffing, etc
doesn't result in compromise.
in the token form ....
the key-pair is gen'ed in the chip and never leaves the chip.
as part of 3-factor authentication
* something you have
* something you know
* something you are
the chip in the token purely provides "something you have"
authentication ... and the digital signature done by the token is purely
to prove  that you have that particular token. It doesn't prove who you
are, it just proves that you have a specific (extremely difficult to
counterfeit) token as part of "something you have" authentication.
if the token is augmented with a pin/password for its correct operation,
then there can be 2-factor authentication. It doesn't involved
shared-secrets since the pin/password is purely between the person and
the hardware token.
The business process validates that the token is of the type requiring
PIN and/or biometric for
correct operation.
The ecdsa digital signature authentication protocol for kerberos,
radius, x9.59 for all retail financial transactions, or ssh can be
identical regardless of the integrity level.
The ecdsa digital signature authentication protocol can be ubiquitous
regardless of the authentication integrity level required.
The business process to meet integrity requirements then can require
sofware key-pair or hardware token key-pair, the level of integrity of
the hardware token, and/or the operational characteristics of the
hardware token (no-pin, pin, biometrics, etc) w/o changing the protocol.
If the protocol is independent of the business process integrity issue
then either the business and/or the end-user may be able to having
personal choice about the level of integrity required. Furthermore, the
person might even have personal choice whether they need a unique token
per security environment, a single token for all security environment,
and/or a small number of tokens selectively applied to different
security environments
the digital signature has nothing at all to do directly with the person,
it is purely related to demonstrating the possession of the token (as
part of something you have authentication) and possibly the integrity
level of the token.
The issue of the authentication protocol  is getting the bits and bytes for
transmission correct but doesn't normally say what it means ... i.e. secret,
shared-secret, one factor authentication, two-factor authentication,
something you have authentication, something you know authentication,
etc. ... although frequently the protocol is envisioned to be a specific
implementation of a specific kind of authentication and trust/integrity level.
recent token discussions
 Two-factor authentication with SSH?
 Two-factor authentication with SSH?
 electronic-ID and key-generation
 electronic-ID and key-generation
older token discussions
 biometrics
 Welome to the Internet, here's your private key
 Meaning of Non-repudiation
 Interests of online banks and their users [was Re: Cryptogram:  Palladium Only for DRM]
 when a fraud is a sale, Re: Rubber hose attack
 eBay Customers Targetted by Credit Card Scam
 Cryptogram Newsletter is off the  PKI and Non-repudiation  distributed authentication
 FREE X.509 Certificates
 Are client certificates really  I-net banking security
 Opinion on smartcard security  Opinion  on smartcard security  Crypting with Fingerprints ?
 Biometric authentication for intranet websites?
 privileged IDs and non-privileged IDs
 Help! Good protocol for national ID card?
 Certificate Authority: Industry vs. Government
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-03 17:29:44
@_author: Anne & Lynn Wheeler 
@_subject: Maybe It's Snake Oil All the Way Down 
References: <200306031304.h53D4dl25250
The issue is where does the authentication material come from.
Basically, certificates were solution targeted for offline email from
the early '80s. you dail-up, connect, exchange email, hang-up. then
you read. some random person that you never, ever dealt with before
sends you something. they claim to be somebody .... the certificate
is signed by somebody you trust .... is offered as proof that they are
who they claimed to be.
the other approach in the online world &/or with previous relations,
is have a table of authentication material. the payment (debit/credit) card
world went from non-electronic, offline to electronic and online (and
skipped the step altogether that certificates represent ... the electornic
and offline).
note that even the certificate-based infrastructure are dependent on
this method .... basically the certificate-enabled infrastructures have
local table of "CA" public keys (i.e. those public keys that they've previously
decided to trust) ... then certificates are validated with "CA" public keys
and the current message/document is validate with public key from
certificate. The primary difference between cert-based infrastructure and
certless-based infrastructure is that the cert-based infrastructure there
CAs have the database of all public keys and create these small R/O
copies of their database records called certificates and spray them all
over for use in offline environments. Then relying parties just have
abbreviated CA-only public key tables and can't access the full tables
maintained at the CAs.
In the certless-based infrastructure the relying parties either maintain
their own full tables of all public keys and/or have direct online access to
the full tables. There is no need for these little R/O, static, stale,
redundant and superfluous copies of somebody else offline database entry certificates) since there can be direct, online access to the original copy.
generalized case can be hooking the web server to either radius or
kerberos for handling the authentication process. both radius and
kerberos support shared-secrets recorded in database as authentication.
the radius example at
shows example of radius recording public key in lieu of shared-secret
and performing ecdsa digital signature authentication. pkinit for
kerberos also allows for public key recorded in lieu of shared-secret
and digital signature authentication.
misc. radius public key authentication posts
misc. kerberos public key authentication pots
futher discussion specifically regarding static, stale, redundant,
superfluous certificates.
slightly related discussions regarding SSL merchant comfort
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-03 20:49:48
@_author: Anne & Lynn Wheeler 
@_subject: Maybe It's Snake Oil All the Way Down 
References: <200306031304.h53D4dl25250
some generic reasons for hooking radius (or one of the AAA technologies) into your webserver for authentication are:
1) supports a variety of authentication mechanisms on an account by account basis. day one, none of the users actually need to see any difference (single administrative interface supporting all the client authentication options that might be in use). existing userid/password, challenge/response and in the referenced asuretee url, ecdsa digital signature.
2) single administrative interface for both client authentication options as well as all of their authorization and privilege options.
3) client database is accessable in real-time by the webserver, real-time updates can occur to both authentication information as well as  authorization, permission and privilege information using single consistent administrative operation
4) there is no disconnect between client administration and static, stale, redundant and superfluous certificates that are a subset of a r/o administrative database entry. (RADIUS) Updates can take place in real time and immediately reflected. The certificate story (as mentioned previously, created for offline, disconnected environment) basically would do something like a) invalidate the old certificate, b) issue new CRLs, c) possibly update a OCSP LDAP, d) update the master database permissions entry for that client, e) generate a certificate that represents a subset of the master information, f) distribute it to the client and f) then have the client install the new certificate. This of course becomes unnecessary if the certificate doesn't actually contain any information and the webserver accesses the authorization and permissions from an online database. However, as has repeatedly been pointed out before, if the certificate doesn't contain any information and the webserver is accessing an online database for authorizations and permissions ... then the webserver can access the online database for the authentication material also. The certificate then is static, stale, redundant and superfluous and you are back to a single online, real-time comprehensive administrative facility (like radius) that supports client/account specifics for authentication, authorization, permissions, accounting, privileges, etc.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-04 10:12:04
@_author: Anne & Lynn Wheeler 
@_subject: Maybe It's Snake Oil All the Way Down 
References: <000101c3298e$cf6edd30$6401a8c0
the ground rules given the x9a10 working group for the x9.59 standard was to preserve the integrity of the financial infrastructure for all (credit, debit, stored-value, POS, internet, non-internet, aka ALL) electronic retail payments. it was one of the things that led us down the path of certless operation. We had previously done the work on the original payment gateway and had to perform various kinds of due diligence on all the major CA vendors .... which started to dawn on us that stale, static certificates were actually redundant and superfluous in the financial business process.
sort of the clinker was starting to do operational and performance profile on any of the existing payment networks .... and it was evident that there was a huge mismatch between the existing payment transaction payload size and any of the commonly used certificates (even the drastically simplified replying-party-only certificates carrying only an account number and public Two major characteristics of X9.59 was that it would provide 1) end-to-end authentication (aka the consumers financial institution would be the one responsible for performing authentication) and 2) account numbers used in X9.59 transactions could not be used in unauthenticated transactions.
Some of the '90s digitally signature oriented specifications had authentication occurring at the internet boundary and stripping off the certificate (avoiding the extreme certificate payload penalty in the payment network). The downside was that the party performing the authentication didn't necessarily have the consumer's interest in mind and Visa subsequently presented statistics at a ISO standards meeting on the number of transactions flowing through the network 1) with a flag claiming to have been digitally signature authenticated and 2) they could prove that no digital signature technology was ever involved.
Evesdropping, sniffing or harvesting account numbers in the current infrastructure (at any point in the process, by insiders or outsiders, traditionally financial exploits have been 90 percent insiders) can result in fraudulent transactions. As a result, existing account numbers effectively become a form of shared-secret and need to be protected. With the X9.59 business rule requiring the account number to only be used in authenticated transactions, simple harvesting of a X9.59 account number doesn't result in fraud. Issuing financial institutions then can use existing business processes that support mapping of different account numbers to the same account.  A discussion of the security proportional to risk with regard to credit card transactions:
 Net banking, is it safe?
The issue with the use of SSL for protecting credit card transactions isn't addressing all or even the major vulnerability to the infrastructure. Eliminating the account number as a form of shared secret addresses all of the vulnerabilities, not just the transaction-in-flight vulnerability addressed by SSL. As a byproduct of addressing all of the shared-secret related vulnerabilities, it also eliminates the need to use SSL for protecting the shared secret while being transmitted.
Detailed report of its use in the NACHA debit network trials can be found at
scroll down to "July 23, 2001: Digital Signatures Can Secure ATM Card Payments"
More details of X9.59 standard:
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-04 20:58:47
@_author: Anne & Lynn Wheeler 
@_subject: Maybe It's Snake Oil All the Way Down 
References: <4.2.2.20030604094322.00d5ed90
  <008701c32a88$cde93f00$c71121c2
one could claim that public-key is a practical alternative but it got significantly sidetracked with independent business model that wanted extract huge amount of money out of existing infrastructures (say totally brand new independent operations wanting $100/annum for every person, extracted from the existing infrastructure for no significant positive benefit ... aka say 200m people at  is $20b/annum ... in return for some abstract bit vapor that doesn't change any core business issue).
it is relatively trivial to demonstrate that public keys can be registered in every business process that currently registers shared-secrets (pins, passwords, radius, kerberos, etc, etc).  the issue then becomes one of cost to change/upgrade those infrastructures to support digital signature authentication with the stored public keys in lieu of string comparison (no new business operations, no new significant transfer of wealth to brand new outside business entities, etc).
however, think about even these simple economics for a minute .... even for relatively modest technology changes that don't change any of the business processes/relationships ... it still costs some money ... and the beneficiary isn't the institution, it is the individual. The individual has the paradigm changed from hundreds of shared-secrets to a single key-pair ... however each institution continues to see just as many individuals and account records. From a very practical standpoint ... entities don't frequently fund things that they don't benefit from ... and typically most success is achieved when the entity that benefits from the change is also driving/funding the change.
the issue is to find out how the individual pays for the change .... or figure out how the institutions are going to benefit.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-06 13:34:41
@_author: Anne & Lynn Wheeler 
@_subject: Maybe It's Snake Oil All the Way Down 
References: <3EDE1D79.8791.1B477836
 <3EDD06EF.2850.17076FA5
 <3EDE1D79.8791.1B477836
there are actually two scenarios .... one is to pre-cache it (so that its transmission never actually has to happen) and the other is to compress it to zero bytes. detailed discussion of certificate pre-caching and certificate zero byte compression:
the typical use for HTTPS for e-commerce is to hide the account number on its way to the financial institution. for the most part the merchant is primarily interested in the response from the consumer's financial institution on whether or not the merchant gets paid. If it weren't for the associated business processes, the merchant could get by with never knowing anything at all about the consumer (the merchant just passes the account number on ... and gets back what they are really interested in .... the notification from the bank that they will get paid).
So a HTTPS type solution is that the consumer pre-caches their bank's certificate (when they establish a bank account). .... and they transmit the account number "hidden" using the bank's public key. This happens to pass thru the merchants processing .... but for purposes of the authorization, the merchant never really has to see it. The protocol would require minor issues of replay attacks .... and be able to be done in a single round trip .... w/o all the SSL protocol chatter. Actually, is isn't so much pre-caching their bank's certificate .... as loading their bank's public key into a table .... analogous to the way CA public keys are loading into tables (aka using out-of-band processing .... the convention that they may be self-signed and encoded in a certificate format is an anomoly of available software and in no way implies a PKI). The primary purpose of HTTPS hasn't been to have a secure channel with the merchant, the primary purpose of the HTTPS is to try and hide the consumer's account number as it makes its way to the consumer's financial institution.
The other solution is the X9.59 standard (preserve the integrity of the financial infrastructure for all electronic retail payments, not just internet, not just POS, not just credit, ALL; credit, debit, stored value, etc) that creates authenticated transactions and account numbers that can only be used in authenticated transaction. The consumer's public key is registered in their bank account (out of band process, again no PKI). X9.59 transactions are signed and transmitted. Since the account number can only be used in authenticated transactions .... it changes from needing encryption to hide the value as part of a shared-secret paradigm to purely a paradigm that supports integrity and authentication. As in the above, scenario, the merchant passes the value thru on its way to the consumer's financial institution; and is focused on getting the approved/disapproved answer back about whether they will be paid. As in the bank HTTPS scenario where the bank's pubilc key is pre-cached at the consumer, the pre-caching of the consumer's public key is pre-cached at the bank .... involves no PKI business processes (although their may be some similarities that the transport of the public key involves encoding in a certificate defined format).  misc. x9.59 refs:
Both pre-caching solutions are between the business entities that are directly involved; the consumer and the consumer's financial institution based on having an established business relationship.
The invention of PKI was primarily to address the issue of an event between two parties that had no prior business relationship and possibly weren't going to have any future business relationship and that they would conclude their business relying on some mutual trust in the integrity of a 3rd party w/o actually having to resort to an online environment. The e-commerce scenario is that there is real-time, online transaction with the trusted 3rd party (the consumer's financial institution) involving prior business relationship. This negates the basic original assumptions about the environment that PKIs are targeted at addressing.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-06 17:45:35
@_author: Anne & Lynn Wheeler 
@_subject: Maybe It's Snake Oil All the Way Down 
References: <4.2.2.20030604174233.00cace00
 <3EDE1D78.2422.1B4777E6
??? public key registered in place of shared-secret?
NACHA debit trials using digitally signed transactions did it with both software keys as well as hardware tokens.
in the above scroll down to July 23, 2001 ... has pointer to detailed report?
X9.59 straight forward establishes it as standard .... with some activity moving on to ISO
pk-init draft for kerberos specifies that public key can be registered in place of shared secret.
following has demo of it with radius with public keys registered in place of shared-secret.
the radius implementation has been done be a number of people.
in all of these cases, there is change in the business process and/or business relationship .... doesn't introduce totally unrelated parties to the business activities. the is digital signing on the senders side (actually a subset of existing PKI technology) and digital signature verification on the receivers side (again a subset of existing PKI technology). To the extent that there is impact on existing business process ... it is like in the case of introducing x9.59 authentication for credit transactions that have relatively little authentication currently .... and as a result would eliminate major portion of the existing credit card transaction related fraud.
The big issue isn't the availability of the technology ... although there is a slight nit in the asuretee case being FIPS186-2, ecdsa .... and having support in CAPI and related infrastructures. It not working (easily) is like when my wife and I were doing the original payment gateway .... with this little client/server startup in menlo park (later moved to mountain view and have since been bought by AOL) and people saying that SSL didn't exist ... misc ref from the past
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-08 18:12:34
@_author: Anne & Lynn Wheeler 
@_subject: An attack on paypal 
References: <3EE32428.1173.13AC2C1
in a world where there are repeated human mistakes/failures .... at some point it is recognized that people aren't perfect and the design is changed to accommodate peoples foibles. in some respects that is what helmets, seat belts, and air bags have been about.
in the past systems have designed long, complicated passwords that are hard to remember and must be changed every month. that almost worked when i person had to deal with a single shared-secret. when it became a fact of life that a person might have tens of such different interfaces it became impossible. It wasn't the fault of any specific institution, it was a failure of humans being able to deal with large numbers of extremely complex, frequently changing passwords. Because of known human foibles, it might be a good idea to start shifting from an infrastructure with large numbers of shared-secrets to a non-shared-secret paradigm.
at a recent cybersecurity conference, somebody made the statement that (of the current outsider, internet exploits, approximately 1/3rd are buffer overflows, 1/3rd are network traffic containing virus that infects a machine because of automatic scripting, and 1/3 are social engineering (convince somebody to divulge information). As far as I know, evesdropping on network traffic  doesn't even show as a blip on the radar screen.
In the following thread on a financial  authentication white paper:
 Authentication white paper
 FINREAD was. Authentication white paper
 FINREAD ... and as an aside
 FINREAD was. Authentication white paper
there is point made that X9.59 standard doesn't directly address the Privacy aspect of security (i.e. no encryption or hiding of data). However, the point is made that it changes the paradigm so that the financial account number no longer represents a shared-secret and that it can be supported with two-factor authentication  i.e. "something you have" token and "something you know" PIN. The "something you know" PIN is used to enable the token, but is not a shared secret. Furthermore, strong authentication can be justification for eliminating the need for name or other identification information in the transaction.
However, if X9.59 strong authentication is used with two-factor authentication and no identification information is necessary .... then it would make people more suspicious if privacy information was requested. Also, since privacy information is no longer sufficient for performing a fraudulent transaction, it might mitigate that kind of social engineering The types of social engineering attacks then become convincing people to insert their hardware token and do really questionable things or mailing somebody their existing hardware token along with the valid pin (possibly as part of an exchange for replacement). The cost/benefit ratio does start to change since there is now much more work on the crooks part for the same or less gain. One could also claim that such activities are just part of child-proofing the environment (even for adults). On the other hand, it could be taken as analogous to designing systems to handle observed failure modes (even when the failures are human and not hardware or software). Misc. identify theft and credit card fraud reference:
 Identity Theft Losses Expect to hit $2 trillion
Slightly related in recent thread that brought up buffer overflow exploits
 A Dark Day
and the report that multics hasn't ever had a buffer overflow exploit
 Thirty Years Later: Lessons from the Multics Security Evaluation
 Thirty Years Later: Lessons from the Multics Security Evaluation
somebody (else) commented (in the thread) that anybody that currently (still) writes code resulting in buffer overflow exploit maybe should be thrown in jail.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-08 20:00:40
@_author: Anne & Lynn Wheeler 
@_subject: An attack on paypal 
References: <3EE32428.1173.13AC2C1
  <4.2.2.20030608173129.00a99bb0
that is why we coined the term merchant "comfort" certificates some time ago. my wife and I having done early work for payment gateway with small client/server startup in menlo park ... that had this thing called SSL/HTTPS ... and then having to perform due diligence on the major issuers of certificates .... we recognized 1) vulnerabilities in the certificate process and 2) information hiding of transaction in flight only addressed a very small portion of the vulnerabilities and exploits.
lots of past discussions related to our use of merchant comfort certificates from the past:
we concluded that a real issue is that way too much of the infrastructure is based on shared-secrets and there was no realistic way of providing blanket protection to all the exposures and vulnerabilities of such shared-secret infrastructures. somewhat related discussion in the security proportional to risk posting:
so rather than trying to create a very thick blanket of encryption covering the whole planet .... a synergistic approach was attempting to provide alternatives to as much of the shared-secret paradigm as possible. As in the referenced post:
 authentication white paper
strong encryption of identification and privacy (and shared-secret) information is good ... but not having identification, privacy and shared-secret information is even better.
there are all sorts of ways of obtaining shared-secret information (and/or privacy and identification information prelude to identity theft) .... including various kinds of social engineering.
as previously mentioned requirement for X9.59 standard was to preserve the integrity of the financial infrastructure for ALL electronic retail payments. As per previous notes, X9.59 with strong authentication eliminates the account number as a shared-secret as well as eliminating requirements for name, address, zip-code, etc as part of any credit card authentication process (strong encryption of vulnerable information is good, not having the information at all is even better).
ALL in addition to referring to things like credit cards, debit cards, atm transactions, stored-value transaction, over the internet, at point-of-sale, face-to-face, automated machines, etc .... also refers to ACH transactions. ACH information allows for unauthenticated push or pull transactions. Social engineering requesting bank account information so somebody can push tens of millions into your account also allows for them to generate a pull transaction removing all the money from your account. Part of the above posting on the authentication white paper .... makes references to securing ACH transactions:
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-10 09:19:19
@_author: Anne & Lynn Wheeler 
@_subject: virus attack on banks (was attack on paypal) 
References: <009201c32e0f$66d925c0$01c8a8c0
 <3EE32428.1173.13AC2C1
virus attempting to harvest ("shared-secret", single-factor) passwords at financial institutions
and somewhat related:
 authentication white paper
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-06-11 12:42:50
@_author: Anne & Lynn Wheeler 
@_subject: An attack on paypal 
References: <3EE5F9DD.10939.696EC1A
actually, if you had a properly secured DNS .... then you could trust DNS to distribute public keys bound to a domain name in the same way they distribute ip-addresses bound to a domain name.
the certificates serve two purposes: 1) is the server that we think we are talking to really the server we are talking to and 2) key-exchange for establishing an encrypted channel. a properly secured DNS would allow information distributed by DNS to be trusted .... including a server's public key .... and given the public key .... it would be possible to do the rest of the SSL operation (w/o requiring certificates) which is establishing an agreed upon session secret key.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-05-09 10:11:52
@_author: Anne & Lynn Wheeler 
@_subject: A Trial Balloon to Ban Email? 
References: <0ac3a2f2dc678e1551bcf8fc1c76fac1
  <0ac3a2f2dc678e1551bcf8fc1c76fac1
the proposal in the past has been that ISPs filter spam at ingress from their customers. the counter-argument has been that there are lots of ISPs that can't be trusted to do it.
So it is much easier for ISPs to have lists of other trusted &/or untrusted ISPs that they will accept email from.
It is orders of magnitude easier (and more efficient) for ISPs to do ingress filtering for SPAM and effectively ISP blacklists than it is to populate the whole consumer infrastructure.
There are still some ways to slip thru the cracks with small amounts .... but it isn't the 40-80% volume of all email that is seen today.
It does have an analogous downside to the individual privacy issues ... which are that the big ISPs could use blacklisting for other purposes than addressing SPAM issues.
Some of the ingress filtering pushback may be similar to the early counter-arguments for packet ingress filtering related to ip-address spoofing. however, that seemed to be more a case of disparity among the router vendors in which could & could not implement ingress filtering. as majority of the router vendors achieved such capability ... the push-back significantly reduced.
2267 -
Network Ingress Filtering: Defeating Denial of Service Attacks which employ IP Source Address Spoofing, Ferguson P., Senie D., 1998/01/23 (10pp) (.txt=21032) (Obsoleted by 2827)
there already are logs relating ingress email to originating ISP customer id. that could be made available via some sort of legal action. the only issue then is the strength of authentication that is performed on customer connection to the ISP ... rather than some sort of origin authentication for every email.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-05-09 23:35:36
@_author: Anne & Lynn Wheeler 
@_subject: blackhole spam => mail unreliability (Re: A Trial Balloon 
References: <4.2.2.20030509095631.00c9dd20
  <0ac3a2f2dc678e1551bcf8fc1c76fac1
  <0ac3a2f2dc678e1551bcf8fc1c76fac1
  <20030509034024.A8886127
  <4.2.2.20030509095631.00c9dd20
Currently ISPs typically "notice" when they get complaints. ISPs could do a much better job of actively noticing and limiting mail at ingress ... as opposed to waiting for somebody to complain and canceling the account. Many of the recent statements about ISPs can't limit email at ingress dynamically are similar to the comments about not being able to filter ingress packets if their origin address didn't match the ip address of the sender (as stated in the original posting) ... per the ingress packet filtering RFC referenced in the original post.
My original post mentioned that the ISPs could then do their own effort of blacklisting (of other ISPs). Currently spam blacklists can be somewhat like vigilantes .... with the argument analogy that since vigilantly justice can make mistakes then there shouldn't be any highway patrol, FBI, and/or secret service. ISPs would be expected to filter on ingress of email from their own customers .... and even if the 10 top ISPs blacklisted other ISPs that didn't do a reasonable job of ingress filtering ... it could start to put a big dent in the spamming business, possibly cutting it from 40-80% of existing email down under 5-10%. It is sort of like stop signs and stop lights .... there are typically hundreds of more intersections than there are traffic enforcers .... however with sufficient leverage ... it can significantly improve the situation ... even if it can be proved that it can't, absolutely, 100% guarantee one hundred percent compliance.
I didn't make any statement about ISPs attempting to identify spammers when they register the account .... the original post was only with regard to ISPs doing active email ingress filtering. My ISP recognizes and bills me extra if I'm simultaneously connected multiple times ... there is a little latitude for modem hanging, my dropping the line ... but the modem not reporting it ... and my connecting on a different modem. It also does traffic load-leveling if I really try and hit it hard. If it can bill extra for simultaneous connects and traffic load leveling, it can do both packet ingress filtering and email ingress filtering.
past thread drawing the analogy that the information superhighway is something like the wild west .... w/o traffic rules, traffic signs, traffic lights, speed limits, and enforcement. start with a couple hundred people in town .... and went to millions ... and there still isn't even any rule about which side of the road people should be driving on.
 Internet like city w/o traffic rules, traffic signs, traffic lights and traffic enforcement
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-05-10 09:36:43
@_author: Anne & Lynn Wheeler 
@_subject: blackhole spam => mail unreliability (Re: A Trial Balloon 
References: <4.2.2.20030509231022.00d53e90
  <4.2.2.20030509095631.00c9dd20
  <0ac3a2f2dc678e1551bcf8fc1c76fac1
  <0ac3a2f2dc678e1551bcf8fc1c76fac1
  <20030509034024.A8886127
  <4.2.2.20030509095631.00c9dd20
  <20030510060245.A9116582
  <4.2.2.20030509231022.00d53e90
do you think that earthlink would automatically blacklist aol if it found incoming spam from aol? I think that earthlink would contact aol and say ... your ingress filtering doesn't seem to be working. It would only be after all attempts to understand aol's ingress filtering that earthlink might take action.
again ... it is analogous to somebody hearing about traffic lights for the first time and coming up with all the reasons why people would ignore traffic lights.
I would claim that the current issue isn't that spam exists (aka traffic violations), it is that there are billions of spams each day. and that this easily cuts the majority of it if the top ten start doing ingress mail filtering and that ingress mail filtering is orders of magnitude more efficient than other kinds of solutions.
the blacklisting isn't for the mistakes ... it is for the ISPs that obviously aren't going to follow the traffic rules.
so there are lots of kinds of tunneling. the major ISPs are already doing ingress filtering for email not coming from a recognizable customer. so tunneling actually reduces to a common vulnerability with ISPs not doing ingress email filtering (aka the tunneling issue to a ISP that isn't doing ingress email filtering is common vulnerability with a customer directly getting an email account with ISP that isn't doing ingress email filtering). So the issue comes back to ISPs that are recognized as not doing ingress email filtering.
So lets say this gets something like 80 percent of the traffic violations.
So the majority of the random traffic violations are now starting to be taken care of. There are 1) the corporations effectively operating as private ISPs, 2) compromised machines, 3) random anarchy.
So both  and  are vulnerabilities treated just the same as a real spammer getting a real account and directly doing spam. These two vulnerabilities should be caught be ingress email filtering. Real spammers caught by ISP ingress filtering, compromised machines caught by ISP ingress filtering, and hit&run anarchist caught by ingress filtering .... all appear to be a common vulnerability caught by ingress email filtering.
The issues actual reduce to a very few simple, non-complex vulnerabilities from a business process standpoint (ignoring all the technology twists and turns): 1) ISPs that do ingress email filtering and 2) ISPs that do not do ingress email filtering.
If ISPs are doing ingress email filtering .... then all the situations of known spammers, spammers masquerading enormously getting accounts, spammers compromising other machines and masquerading enormously, tunneling, etc ... all get taken care of. There are still the periodic traffic accidents where somebody might be able to do a couple hundred before getting cut .... but it probably reduces over 90 percent of the traffic.
So the remain issue is whether an ISP is following the traffic laws and doing ingress email filtering or flagrantly flaunting the law and letting millions of spam thru. This is regardless of whether it is a real public ISP ... or effectively a corporate/private ISP. The other ISPs then use blacklisting. The first line of defense is that all ISPs are to do ingress email filtering and the 2nd line of defense is that the major ISPs do blacklisting  on the ISPs that obviously are flaunting the law.
The primary business issue is that majority of spam is being done for some profit .... that the cost of sending the spam is less than the expected financial return. This should address the 99 percentile.
Again, it is very simple, first line of defense is ingress email filtering. This is only a moderate extension of what the major ISPs are currently doing with regard to not accepting email from entities that are obviously not their customers, current traffic limiting business rules, etc. The second line of defense is blacklisting ISPs that aren't following the traffic rules. I claim, it actually is rather much simpler and much more So back to the obvious traffic violations. One is the compromised machines. Large proportion of the compromised machines are their because they all got hit by spamming virus. I claim, that over time if over 90 percent of spamming gets cut ... then 90 percent of the machines that get compromised by virus in spam can also get cut.
Situation is now down to large number of compromised machines each sending couple hundred emails each ... staying under the ingress filtering radar.  That is orders of magnitude better than the current situation but it is starting to reduce the case to manageable traffic violations.
So this scenario gets down to providing significantly more focus on compromised machines ... and back to a recent comment about lots of vendors saying that consumers won't pay for better security ... because they have no motivation. This is somewhat the insurance industry theory of improving on severity of traffic accidents (what motivated automobile manufactory to build safer cars). My ISP currently charges me extra over the flat rate for certain behavioral activities. Violating ingress email filtering rules would be such a valid inducement. I get ingress email filtering accident insurance the premiums are based on the integrity of the machine i'm operating.
So, two simple rules .... 1) ISPs do ingress email filtering, and 2) ISPs blacklist other ISPs that flagrantly violate the ingress email filtering rules.
With a sizeable reduction in spam, there is corresponding sizeable reduction in compromised machines. However, compromised machines that do spam and hit the ISPs ingress email filtering rules, get fined. It is treated as accident and operating an unsafe vehicle. You can get accident and fine insurance .... but the premium is related to kind of machine you operate. Some inducement for consuming public to purchase safer machines. The two simple rules ... with the fines for violations then provides some inducement for consumer buying habit regarding purchasing safer machines. And it is all quite similar to policies and practices currently in place.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2003-05-13 11:12:53
@_author: Anne & Lynn Wheeler 
@_subject: economics of spam (Re: A Trial Balloon to Ban Email?) 
References: <20030512214557.A9261480
  <200305121353.h4CDrP2Y022329
  <200305121353.h4CDrP2Y022329
... but i would contend that the infrastructure costs associated with a billion or two spams per day are significantly higher than the costs that are currently being incurred by the spammers .... in effect the industry as a whole is underwriting a significant percentage of the actual costs, which makes spamming such an attractive economic activity. one of the issues is to reflect the fully loaded costs of a billion or two spams per day back to the spammers.
Anne & Lynn Wheeler    Internet trivia 20th anv

@_date: 2004-09-20 16:07:55
@_author: Anne & Lynn Wheeler 
@_subject: Academics locked out by tight visa controls 
ink.net>
References: <17894379.1095689037533.JavaMail.root
in '94 there was report (possibly sjmn?) that said at least half of all cal. univ. tech. PHDs were awarded to foreign born. during some of the tech green card discussions in the late '90s ... it was pointed out that the internet boom (bubble) was heavily dependent on all these foreign born .... since there was hardly enuf born in the usa to meet the demand.
in the late 90s there were some reports that many of these graduates had their education paid by their gov. with directions to enter an us company in strategic high tech areas for 4-8 years .... and then return home as tech transfer effort. i was told in the late 90s about one optical computing group in a high tech operation .... where all members of the group fell into this category (foreign born with obligation to return home after some period).
another complicating factor competing for resources during the late 90s high-tech, internet boom (bubble?) period was the significant resource requirement for y2k remediation efforts.
nsf had recent study on part of this
graduate enrollment in science and engineering fields reaches new peak; 1st time enrollment of foreign students drops
Anne & Lynn Wheeler

@_date: 2005-02-04 11:07:32
@_author: Anne & Lynn Wheeler 
@_subject: Dell to Add Security Chip to PCs 
References: and chips that typically have had eal4+ or eal5+ evaluations. hot topic in 2000, 2001 ... at the intel developer's forums and rsa conferences

@_date: 2005-02-04 11:12:59
@_author: Anne & Lynn Wheeler 
@_subject: Dell to Add Security Chip to PCs 
References: <017630AA6DF2DF4EBC1DD4454F8EE29704776C51
  > I've read your objections. Maybe I wasn't clear. What's wrong in
the cost of EAL evaluation typically has already been amortized across large number of chips in the smartcard market. the manufactoring costs of such a chip is pretty proportional to the chip size ... and the thing that drives chip size tends to be the amount of eeprom memory.
in tcpa track at intel developer's forum a couple years ago ... i gave a talk and claimed that i had designed and significantly cost reduced such a chip by throwing out all features that weren't absolutely necessary for security. I also mentioned that two years after i had finished such a design ... that tcpa was starting to converge to something similar. the head of tcpa in the audience quiped that i didn't have a committee of 200 helping me with the design.

@_date: 2005-01-05 23:46:32
@_author: Anne & Lynn Wheeler 
@_subject: Banks Test ID Device for Online Security 
References: <017630AA6DF2DF4EBC1DD4454F8EE29704776BE6
  <20050105032142.7E8D4F2CB
in general, it is "something you have" authentication as opposed to the common shared-secret "something you know" authentication.
while a window of vulnerability does exist (supposedly something that prooves you are in possession of "something you have"), it is orders of magnitude smaller than the shared-secret "something you know" there are two scenarios for shared-secret "something you know" 1) a single shared-secret used across all security domains ... a compromise of the shared-secret has a very wide window of vulnerability plus a potentially very large scope of vulnerability
2) a unique shaerd-secret for each security domain ... which helps limit the scope of a shared-secret compromise. this potentially worked with one or two security domains ... but with the proliferation of the electronic world ... it is possible to have scores of security domains, resulting in scores of unique shared-secrets. scores of unique shared-secrets typically results exceeded human memory capacity with the result that all shared-secrets are recorded someplace; which in turn becomes a new exploit/vulnerability point.
various financial shared-secret exploits are attactive because with modest effort it may be possible to harvest tens of thousands of In one-at-a-time, real-time social engineering, may take compareable effort ... but only yields a single piece of authentication material with a very narrow time-window and the fraud ROI might be several orders of magnitude less. It may appear to still be large risk to individuals ... but for a financial institution, it may be relatively small risk to cover the situation ... compared to criminal being able to compromise 50,000 accounts with compareable effort.
In some presentation there was the comment made that the only thing that they really needed to do is make it more attactive for the criminals to attack somebody else.
It would be preferabale to have a "something you have" authentication resulting in a unique value ... every time the device was used. Then no amount of social engineering could result in getting the victim to give up information that results in compromise. However, even with relatively narrow window of vulnerability ... it still could reduce risk/fraud to financial institutions by several orders of magnitude (compared to existing prevalent shared-secret "something you know" authentication old standby posting about security proportional to risk

@_date: 2005-06-01 12:52:10
@_author: Anne & Lynn Wheeler 
@_subject: Trojan horse attack involving many major Israeli companies, 
References: <429B1666.90701    <20050531130352.GA6447   <429C791D.1070108 <20050531140358.R37356
  <429DB28D.2030200
there is the story of the (state side) financial institution that was outsourcing some of its y2k remediation and failed to perform due diligence on the (state side) lowest bidder ... until it was too late and they were faced with having to deploy the software anyway.
one of the spoofs of SSL ... was originally it was supposed to be used for the whole shopping experience from the URL the enduser entered, thru shopping, checkout and payment. webservers found that with SSL they took a 80-90% performance hit on their thruput ... so they saved the use of SSL until checkout and payment. the SSL countermeasure to MITM-attack is that the URL the user entered is checked against the URL in the webserver certificate. However, the URL the users were entering weren't SSL/HTTPS ... they were just standard stuff ... and so there wasn't any countermeasure to MITM-attack.
If the user had gotten to a spoofed MITM site ... they could have done all their shopping and then clicked the checkout button ... which might provide HTTPS/SSL. however, if it was a spoofed site, it is highly probable that the HTTPS URL provided by the (spoofed site) checkout button was going to match the URL in any transmitted digital certificate. So for all, intents and purposes .. most sites make very little use of https/ssl as countermeasure for MITM-attacks ... simply encryption as countermeasure for skimming/harvesting (evesdropping).
in general, if the naive user is clicking on something that obfuscates the real URL (in some case they don't even have to obfuscate the real URL) ... then the crooks can still utilize https/ssl ... making sure that they have a valid digital certificate that matches the URL that they are providing.
the low-hanging fruit of fraud ROI ... says that the crooks are going to go after the easiest target, with the lowest risk, and the biggest bang-for-the buck. that has mostly been the data-at-rest transaction files. then it is other attacks on either of the end-points. attacking generalized internet channels for harvesting/skimming appears to be one of the lowest paybacks for the effort. in other domains, there have been harvesting/skimming attacks ... but again mostly on end-points ... and these are dedicated/concentrated environments where the only traffic ... is traffic of interest (any extraneous/uninteresting stuff has already been filtered out).

@_date: 2005-05-20 22:07:40
@_author: Anne & Lynn Wheeler 
@_subject: What happened with the session fixation bug? 
References: <427CCA9B.29132.760A1FC
all of them may have been less than expected ... the comoningly recognized SSL certificate issuers (that have their public key preloaded into common browsers) sell their certificates and have processes that look at whether you have a validly registered corporation. For most practical purposes this has been for e-commerce sites and the objective for the majority is protecting credit card numbers.
however, the reported exploits .... and what seem to represent a significantly larger ROI (fraud for effort invested) is to harvest the merchant transaction file (containing all the accumulated transaction information that would have taken months of listening to gather) ... aka it is much easier to let the merchant gather and organize all the information on behalf of the crook. slightly related posting ...
 Security proportional to risk
the original ssl e-commerce work
had the user typing in the merchant webserver URL as a HTTPS session from the start and then it would check the domain name in the returned certificate (after all the digital signature gorp) with the domain name typed in. this is rarely if ever happening ... the common justification is running SSL during the shopping experience cuts the thruput by 80-90 percent. as a result, SSL is typically saved for the "check-out" button.
so lets say you have been redirected to a fraudulent site and don't know it because the SSL domain name stuff hasn't been done yet. then comes time to do the check-out button. if it is a fraudulent site ... and since the crooks would then be supplying the URL with the check-out button ... the crooks are likely to have obtained a valid SSL certificate for some domain and that domain will match whatever the check-out button supplies.
random past ssl certificate posts
crooks are capable of setting up valid dummy front companies ... it isn't a very large effort.
most of what the CA TTPs do when they are verifying stuff ... is that the person applying for a certificate is in some way associated with a valid company that they claim to be associated with.
then the CA TTPs check with the domain name infrastructure to see if the corporation that they just checked on ... is the same one listed as the owner of the subject domain name (modulo the issue that there can be a common company name, a DBA company name, and a legal company
name ... all for the same corporation and all completely different names ... you sometimes will see this in credit card statements where the store-front name and the company name on the statement are different).
As observed, one of the things SSL was for a countermeasure for integrity problems in the domain name infrastructure involving domain name hijacking (where the mapping of the domain name to an ip-address was altered to be a different ip-address, potentially fraudulent website).
However, there have been more sophisticated domain name hijackings that have occured where both the domain name infrastructure records had both the name of the corporate owner as well as the ip-address altered. In this more sophisticated form, a crook with a perfectly valid dummy front corporation ... that has done the more sophisticated form of domain name hijacking ... could apply for a perfectly valid SSL domain name certificate ... and pass all the tests.
in any case, that was my perception of what we were doing with SSL ten years ago.
PKI is slightly different. One of the reasons that we coined the term "certificate manufactoring" was to try and differentiate what was comingly being referred to as PKI ... and what SSL domain name certificate stuff was actually doing.
Note that there has been a proposal to somewhat address the more complex form of domain name hijacking (both the company name take-over as well as the ip-address take-over) ... which involves having domain name owners register a public key when they get a domain name. Then all future correspondance with the domain name infrastructure is digitally signed ... which then can be veriefied with the onfile public key. as a side note ... this is a non-PKI, certificateless implementation of public key. In any case, with authenticated correspondance ... there supposedly is less chance of domain name hijacking occuring.
This has somewhat been supported by the CA SSL domain name certification industry. The have a complex, expensive, and error-prone identification process to try to establish a valid corporation. And even then they are at the mercy of whether the company name listed in the domain name infrastructure is actually the correct company (i.e. their whole infrastructure otherwise is useless).
The other advantage ... is that the Certification Authority can require that SSL domain name certificate applications also be digitally signed. Then the CA can turn an expensive, time-consuming, and error-prone identification process into a much simpler, cheaper, and reliable authentication process ... by retrieving the onfile public key from the domain name infrastructure for verifying the applicants digital signature (again note that this is a non-PKI, certificateless implementation that they would use as the trust basis for the whole SSL domain name certificate operation).
There is some slight catch22 to this for the SSL domain name certificate business. First off, improving the integrity of the domain name infrastructure for the Certification Authority industry ... would also improve the integrity for everybody ... somewhat mitigating one of the original supposed requirements for having SSL domain name certificates in the first place. The other is that if the SSL certification industry found it viable to base their trust infrastructure on the certificateless, onfile public keys at the domain name infrastructure... it might be possible that the rest of the world might find them acceptable also. One could imagine a slightly modified SSL process where the public key didn't come from a certificate ... but was an onfile certificateless public key retrieved directly from the domain name infrastructure (in much the same way the CA industry has proposed doing).

@_date: 2005-05-31 11:55:37
@_author: Anne & Lynn Wheeler 
@_subject: What happened with the session fixation bug? 
References: <427CCA9B.29132.760A1FC
asymmetric cryptography has a pair of keys ... the other of the key-pair decodes what has been encoding by one of them. a business process was defined using this technology where one of the key-pair is designated as public ... and freely distributed and the other of the key-pair is designated as confidential and never divulaged. an authentication business process was defined using public/private business process called digital signature .... where a hash of a message is taken and encoded with the private key. the recipient can recompute the hash of the received message and compare it to the digital signature that has been decoded with the corresponding public key. this catches whether the message has been altered and from 3-factor authentication
* something you have
* something you know
* something you are
implies "something you have" authentication ... i.e. the originator has access and use of the corresponding private key.
PKI was somewhat targeted at the offline email model of the early 80s; the relying party dials up their (electronic) post office, exchanges email, and hangs up. They then may be dealing with first time correspondance from a total stranger with no (offline or online) recourse for determining information about the sender. Relying parties could be seeded with trusted public key repository of trusted third party certification authorities. Stangers could be issued "certificates" (digitally signed by one of these certification authorities) containing informoation about themselves bound to their public key. Email recipients in the offline email days of the early 80s ... could now of source of information regarding first time communication from total strangers (sort of the "letters of credit" model from the sailing ship we were asked to work this small client/server startup in menlo park
that wanted to do payments on something they called a commerce server. In the year we worked with them ... they moved from menlo park to mountain view and changed their name (trivia question ... who previously had the rights to their new name? also what large corporate entity was providing most of the funding for the commerce sever?). some topic drift ... recent postings referencing this original e-commerce work as an example of service oriented architecture (SOA):
they had this technology called SSL which was configured at addressing two issues: a) is the webserver that the user had indicated to the browser ... the actual webserver the browser was talking to and b) encryption of the transmitted information.
SSL digital certificates would be issued
which would contain the domain name of the webserver bound to their public key. the browsers would have trusted public key repository seeded with the public keys of some number of trusted third party certification authorities. the browser SSL process would compare the domain name indicated by the user to the domain name in the digital certificate (after validating the certificate).
(at least) two (other) kinds of vulnerabilities/exploits have shown up.
1) in the name of convenience, the browsers have significantly obfuscated the certificate operation from the end-user. attackers have devised ways for the end-users to indicate incorrect webservers ... which the browser SSL process (if it is even invoked) will then gladly validate as the webserver the user indicated.
2) a perceived issue (with knowing that the webserver that a browser is talking to is the webserver the user indicated) were integrity issues in the domain name infrastructure. however, as part of doing this consulting with this small client/server startup ... we also had to do detailed end-to-end business process due dilligence on some number of these certification authorities. it turns out that a certification authority typically has to check with the authoritative agency for the information they are certifying. the authoritative agency for domain name ownership is the domain name infrastructure ... the very institution that there are integrity questions giving rise to the requirement for SSL domain name server certificates.
In the second vulnerability, the certification authority industry is somewhat backing a proposal that when somebody registers a domain name with the domain name infrastructure ... they also register their public key. then in future communication with the domain name infrastructure, they digitally sign the communication. the domain name infrastructure then can validate the digital signature using the (certificateless) public key onfile for that domain. This supposedly improves the integrity of the communication between the domain name owner and the domain name infrastructure .... mitigating some possible domain name hijacking exploits (where some other organization becomes recorded as the domain name owner).
It turns out that the certification authority industry also has an issue. When somebody makes an application for an SSL domain name certificate, they need to supply a bunch of identification information. This is so the certification authority can perform the expensive, time-consuming and error-prone identification process ... and then do the same with the information on file at the domain name infrastructure as to the owner of the domain name ... and then see if the two domain name owner identifications appear to match. Having an on-file public key for the domain name owner ... the certification authority industry can also require that an SSL domain name applicant, digitally sign their application. Then the certification authority can retrieve the onfile (certificateless) public key and change an expensive, error-prone, and time-consuming identification process into a simple and more reliable authentication process (by retrieving the onfile public key and validating the digital signature).
 From an e-commerce perspective ... the SSL process was to protect against credit card information havesting for use in fraudulent transactions. However, the major vulnerability/exploit before SSL and after the introduction of SSL ... wasn't against credit card information in flight ... but against huge repositories of credit card information
(information at rest). It was much easier for the crooks to steal the information already collected in huge repositories than go to the effort of evesdropping the information inflight and creating their own repositories (fraud return-on-investment, much bigger benefit in stealing large repositories of already collected and organized information). related reference regarding security proportional to risk
the financial standards working group, x9a10 was given the task of preserving the integrity of the financial infrastructure for all retail payments (as well as some number of other requirements) for x9.59 standard
so some earlier work on PKI-oriented protection for retail payments involved digitally signed transaction oriented protocol with attached digital certificates.
in the early 90s, there was some work on x.509 identity certificates. however, there was some issues with ceritifcation authorities predicting exactly what information might be needed by unknown future relying parties ... and so there was some direction to grossly overload these certificates with excessive amounts of personal information. In the mid-90s, some number of institutions were starting to realize that such overloaded repositories of excessive personal information representing significant liability and privacy issues. As a result you saw some retrenchment to relying-party-only certificates
these were digital certificates that basically contained some kind of database record locator (like an account number) bound to a public key (the database record contained all the real information). however, it became trivial to demonstrate that such relying-party-only certificates were redundant and superfluous. This was, in part because they violated the original design point for certificates ... the relying party not having any other recourse to the necessary information. By definition if all the information was in a relying-party's database ... then by definition the certificate was redundant and superfluous.
in this later part of the mid-90s payment scene, these relying-party-only certificates were on the order of 4k-12k bytes. It turns out that a typical retail payment message is 60-80 bytes. Not only were the stale, static, relying-party-only certificates redundant and superfluous ... but they also would contribute to enormous payload bloat (on the order of one hundred times).
the other problem with the relying-party-only, redundant and superfluous, stale, staic, enormous payload-bloat digital certificate based infrastructure ... were that they effectively were targeted only at protecting credit card information "in-flight" ... something that SSL was already doing. They were providing no countermeasure for the major vulnerability to the data "at rest". the information at rest was still vulnerable (and was the major exploit already with or w/o SSL)
So one of the things in the x9a10 financial standards working group was to do a treat and vulnerability analysis ... and design something that could preserve the integrity of the financial infrastructure for all retail payments (credit, debit, stored-value, online, offline, pos, etc).
X9A10 defined a light-weight digitally signed transaction that wouldn't contribute to the enormous payload bloat of the stale, static, redundant and superfluous certificate-based infrastructures.
Another issue was the analysis demonstrated that the major treat and vulnerability was to the data at rest. So for X9.59, a business rule was defined ... for account numbers used for X9.59 transactions ... only correctly verified digitally signed transactions (authenticated) could be authorized.
An x9.59 transaction was digitally signed, and the relying party could use an on-file public key to validate the digital signature .... showing the transaction wasn't modified in transit and providing "something you have" authentication as to the originator (they had access and use of the corresponding private key). furthermore, evesdropping of the transaction in flight ... and/or harvesting the large transaction databases (information at rest) wouldn't yield information for the crook to perform a fraudulent transaction. the current exploits where knowledge from an existing transaction is sufficient to generate fraudulent transaction has gone away ... for vulnerabilities involving both "data in flight" as well as "data at rest".
The issue wasn't that SSL being designed to protect data-in-flight ... the issue was that the major threat/vulnerability has been to "data-at-rest" ... so to some extent, SSL (and the various other countermeasures to "data-in-flight" vulnerabilities) wasn't responding to the major threats. To some extent, e-commerce/internet was opening a theoritical, new vulnerabilities ("data-in-flight") compared to the non-internet world ... and so SSL was somewhat theoritically demonstrating that e-commerce/internet use wouldn't make the situation any worse.
Recent studies have indicated that at least 77% of the id theft exploits have involved insiders (supporting the long standing premise that the majority of fraud is by insiders). The introduction of e-commerce and internet have introduced new avenues for attacking data-at-rest by outsiders. As a result, e-commerce/internet potential threats to data-at-rest has contributed to obfuscating responsible insiders in cases of exploits against data-at-rest.

@_date: 2005-05-31 14:05:51
@_author: Anne & Lynn Wheeler 
@_subject: "SSL stops credit card sniffing" is a correlation/causality myth 
References: <20050531183839.89CBA3BFFF9
the major exploits have involved data-at-rest ... not data-in-flight. internet credit card sniffing can be easier than password sniffing .... but that doesn't mean that the fraud cost/benefit ratio is better than harvesting large transaction database files. you could possibly conjecture password sniffing enabling compromise/exploits of data-at-rest ... quick in&out and may have months worth of transaction information all nicely organized.
to large extent SSL was used to show that internet/e-commerce wouldn't result in the theoritical sniffing making things worse (as opposed to addressing the major fraud vulnerability & treat).
internet/e-commerce did increase the threats & vulnerabilities to the transaction database files (data-at-rest) ... which is were the major threat has been. There has been a proliferation of internet merchants with electronic transaction database files ... where there may be various kinds of internet access to the databases. Even when the prevalent risk to these files has been from insiders ... the possibility of outsider compromise can still obfuscate tracking down who is actually

@_date: 2008-01-02 12:09:50
@_author: Anne & Lynn Wheeler 
@_subject: Death of antivirus software imminent 
Death of antivirus software  Death of antivirus software i commented on that in reference posts mentioning that there have been
uses of virtual machines to study virus/trojans ... but that
some of the new generation virus/trojans are now looking to see if they
are running in virtual machine (studied?).
some of the current trade-off is whether that virtual machine technology
can be used to partition off basically insecure operations (which are widely
recognized as being easy to compromise) and then completely discard
the environment and rebuild from scratch after every session (sort of
the automated equivalent of having to manually wipe an infected machine
and re-install from scratch).
the counter argument is that crooks can possibly also use similar
technology to hide ... once they have infected the machine. the current
issue is that a lot of the antivirus/scanning techniques are becoming w/o the attackers even leveraging virtual machine technology.
The attackers can leverage the technology in an otherwise poorly
defended machine. Some years ago there was a product claiming
that it could operate even at a public access machine because
of their completeness of their antivirus countermeasures ... even
on an infected machine. I raised the issue that it would be trivial
to defeat all such countermeasures using virtual machine technology.
Somewhat of a skirmish resulted since they had never considered
(or heard of) virtual machine technology ... for all i know there
is still ongoing head-in-the-sand situation.
for little topic drift ... this blog entry:
there is some assertion that the crooks overwhelming the
defenders countermeasures because they are operating
significantly faster and more efficiently.
however, another interpretation is that the defenders
have chosen extremely poor position to defend ... and are
therefor at enormous disadvantage. it may be necessary
to change the paradigm (and/or find the high ground)
in order to successfully defend.

@_date: 2008-06-17 13:53:59
@_author: Anne & Lynn Wheeler 
@_subject: Own a piece of the crypto wars 
References: <78730D6C-AB1A-420B-B0C0-C7A802F552FC
archeological email about proposal for doing pgp-like public key
(from 1981):
the internal network was larger than the arpanet/internet from
just about the beginning until sometime summer of '85. corporate
guidelines had become that all links/transmission leaving corporate
facilities were required to be encrypted. in the '80s this met
lots of link encryptors (in the mid-80s, there was claim that
internal network had over half of all the link encryptors in the world).
a major crypto problem was with just about every link that crossed any
national boundary created problems with both national gov. links
within national boundaries would usually get away with argument
that it was purely internal communication within the same
corporate entity. then there was all sorts of resistance encountered
attempting to apply that argument to links that cross national
boundary (from just about every national entity).
For other archeological lore ... old posting with new networking
activity from 1983
above posting includes listing of locations (around the world)
that had one or more new network links (on the internal
network) added sometime during 1983 (large precentage
involved connections requiring link encryptors).
more recent post
mentioning coming to the realization (in the 80s) that there
were three kinds of crypto.

@_date: 2013-09-06 16:48:01
@_author: Anne & Lynn Wheeler 
@_subject: [Cryptography] People should turn on PFS in TLS (was Re: Fwd: NYTimes.com: N.S.A. Foils Much Internet Encryption) 
we were brought in as consultants to a small client/server startup that wanted to do payment transactions on their server, they had this technology they called "SSL" they wanted to use, the result is now frequently called "electronic commerce". The two people at the startup responsible for the "commerce server" we had worked with in prior life on parallel Oracle cluster scaleup.
As part of mapping "SSL" technology to payment transactions we had to audit operations selling "SSL" digital certificates and also came up with recommendations on how browsers and servers would deploy and use the technology. Almost immediately several of the recommendations were violated, resulting in some number of the exploits that continue to this day.
We were then tangentially involved in the Cal. data breach notification legislation, having been brought in to help wordsmith the Cal. electronic signature legislation. Many of the parties were heavily involved in privacy issues and had done numerous, indepth, public surveys. The number one issue was "identity theft" of the form involving fraudulent financial transactions ... frequently as result of data breach. The issue was nothing was being done about the problems and so it was hoped that the publicity from the notifications might motivate corrective action. Part of the issue is normally institutions take security measures in self-interests ... however, the institutions having breaches weren't at risk, it was the account holders.
PCI DSS shows up some time after Cal. data breach notification and frequently the joke is that if you have a breach ... you loose your PCI DSS certification. It turns out that there was a number of Federal "data breach notification" bills introduced, preempting state legislation and effectively eliminating notification requirements ... citing PCI DSS industry effort as justification for no longer needing notification.
Another problem we've frequently pointed out is current paradigm with "dual use" paradigm and even if the planet was covered in miles of information hiding encryption, it wouldn't stop data leakage. Account information is used for authenticating new transactions and so has a requirement that it be kept totally confidential and never divulged to anybody ... but at the same time, account information is needed in dozens of business processes at millions of locations around the planet.
disclaimer: we were co-authors of the x9.59 financial transaction standard that slightly tweaked the current payment paradigm and eliminated the dual-use characteristic .... which then also eliminated the need to hide account information and as a result it also eliminated the need for SSL to hide account information in electronic commerce transactions .... eliminating the major requirement for SSL in the world today.
