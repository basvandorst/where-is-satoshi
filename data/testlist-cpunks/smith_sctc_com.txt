
@_date: 1996-04-12 21:59:04
@_author: Rick Smith 
@_subject: Add me (Net.Enemies List) 
Please add my name to your list of Net Enemies. I'd rather start out
branded as subversive and retain the freedom to be myself. Otherwise I
might be tempted to keep silent and feign political correctness.
smith at sctc.com        secure computing corporation

@_date: 1996-04-24 06:14:51
@_author: Rick Smith 
@_subject: DES as a stream cipher 
karl at geoplex.com ("Karl A. Siil") asks:
The right answer depends on the types of attacks you're interested in
countering. The classic reference is probably Voydock and Kent's
"Security Mechanisms in High Level Network Protocols," from Computing
Surveys in 1983. I think Stallings recently put together collection of
paper reprints for IEEE Press that included this one.
This paper is particularly nice since they present various streaming
modes and then talk about the vulnerabilities associated with them.
So it's not crypto algorithms so much as how to use them.
smith at sctc.com        secure computing corporation

@_date: 1996-04-27 10:35:15
@_author: Rick Smith 
@_subject: trusting the processor chip 
Yes, and this is where the real risks are. The original question was
entirely about explicit subversion. The larger risk is accidental
flaws. Same with software in most cases.
smith at sctc.com           secure computing corporation

@_date: 1996-04-27 12:31:41
@_author: Rick Smith 
@_subject: trusting the processor chip 
Having penned the response to Jeffrey Flinn on the unlikelihood of
processor back doors, I'll comment on jim bell's response:
Actually, I perceived two models: either all processors are subverted
or a subset of them are. Both require a reasonably complete design
team to reliably achieve the objective of a well hidden and reliable
back door. The cost effective thing to do is use the original design
team since they have the knowledge you need to pull it off. A
different and/or much smaller team has a lower likelihood of success.
Simple, no. Hard to detect, somewhat. Gets what they want, unclear.
My experience with processor design and development is rather ancient
and my knowledge of IC work is third hand, so I'll gladly defer to
someone with closer knowledge of the process (Tim?).  However, I've
never heard anything to imply that a processor architecture can be
cleverly and reliably dinked with in this manner without lots of
expensive engineering. Where does the chip real estate come from?  Is
there room in the microcode for this? Will it destabilize other
behaviors? Will the victim detect it through RFI testing?
No, it's not impossible. The risk vs reward tradeoff is shaky.
smith at sctc.com        secure computing corporation

@_date: 1996-04-27 13:19:21
@_author: Rick Smith 
@_subject: trusting the processor chip 
Yep. Regardless of whether the fabs are government property or not,
it's a sure thing that some contractors have appropriately SCIFfed
fabs and appropriately cleared staffs.
Agree. Keyboard controllers (and other peripheral components
of a system) are a much more tractable target than the CPU and
may be within the capbailities of such organizations. I'm more
inclined towards disk controller subversion myself. Of course,
there's also the apocryphal story of the so called "Iraqi
printer virus" that disabled the Iraqi air defense system.
Subverting the CPU is not simple even by NSA standards.
smith at sctc.com        secure computing corporation

@_date: 1996-05-01 14:30:39
@_author: Rick Smith 
@_subject: The Joy of Java 
Scott Brickner  quoted the Princeton
paper's concerns about Java's lack of a formal semantic basis,
and mpd at netcom.com (Mike Duvos) replied:
Having some familiarity with application of formal methods to computer
security, I'd like to point out a few things.
The experience in the multilevel security world was that a weak or
nonexistent specification pretty much guaranteed that there would be
holes in the design -- limitations that kept you from being able to
block covert channels or other flaws in the kernel.
Language design is as tough a problem, if not more so. Brinch Hansen
told a story over a decade ago about how he tried to specify a
language with good semantics, and had Tony Hoare review his attempts.
There always seemed to be a flaw somewhere and they weren't trying to
capture object semantics back then, just types. So, in the absense of
rigor there's probably not much sense in assuming correctness.
When doing formal specification of a high assurance MLS system, a
large proportion of flaws were found simply through the process of
producing the formal specifications, both of the device design and of
the security requirements. A large proportion of the design flaws are
found while doing the formal proofs.
Note that Java operating in the Internet environment acquires two sets
of security requirements: the original ones for the language plus
another set that applies to the platform (workstation) it runs on. The
former set of requirements were pretty thoroughly worked out, though
it doesn't appear that they were ever formalized. This seems to be
the primary topic of discussion here, but not the only one.
As of last winter, when I last checked into it, the latter set of
requirements hadn't been specified in any reasonable detail. Such a
spec would reflect the security requirements for running on a
workstation that requires some measure of confidentiality. For
example, consider the CEO's workstation: the SEC has rules about
keeping certain things secret, and that stuff tends to live in files
on a CEO's workstation. Of course, the problem also applies to anyone
who has unwrapped PGP keys lying about when some applet turns
The only reason MLS systems were formally specified and analyzed was
because the DOD wanted to avoid a computer based train wreck involving
intelligence data or other stuff of comparable sensitivity. They had
money and market clout, at least when they started.
smith at sctc.com          secure computing corporation

@_date: 1996-08-03 08:53:52
@_author: Rick Smith 
@_subject: Corporate e-mail policy 
:   The company I work for has set up a committee to draft a security : policy involving, among other things, e-mail. Since I'm responsible : for our networking and e-mail, I'm part of this group. Unfortunately, : I'm outnumbered by legal, auditing and HR types who, basically, want : to have access to everything.
First, figure out what *your* objective is. You can't achieve e-mail
privacy by implementing some idealized policy that says "Our company
won't snoop into e-mail."  It is the obligation of corporate
functionaries to act in the corporation's best interest, and if that
includes violating the privacy policy (as opposed to civil or criminal
statutes) then it's going to happen. If you write it into one policy,
they'll just find a different one that they can apply to override it.
As you pointed out, the courts agree with this interpretation.  Let us
focus on what we *can* fix.
You can make things better if you write the policy to reduce the risk
of abuse. Nip this nonsense about "access to everything" in the bud.
For example, the policy could provide oversight by requiring approvals
from affected people (the victim's manager if not the actual victim).
Then, access is granted to the victim's files and not to all the
files. Even if auditors want to do "random audit" of e-mail, they
don't really need "access to everything" to achieve it.  They can
randomly select messages somehow and only get readable copies after
the messages are selected.
You'd probably find lots of support for a more measured policy like
this. For example, mail from the CEO or the head of the Audit
department shouldn't be an open book just because Joe Blow from Audit
is "auditing e-mail today."
Also, your policymakers might think about the issues raised by the
recent skit, "FBI Files on Republicans Stored in the Democratic White
House." If they demand unlimited access to e-mail files, they might be
held responsible for making use of information contained therein
simply because they *could* have read them.
smith at sctc.com         secure computing corporation

@_date: 1996-08-27 08:49:32
@_author: Rick Smith 
@_subject: NSA's Venona Intercepts 
The bulk of the material available from NSA's web site is associated with a
long time project called Venona to decrypt Soviet message traffic from the
1940s. It's an interesting exhibition of the practical output of
cryptanalysis that, incidentally, contains alleged reference to famous
Commie spies of that era (Hiss, the Rosenbergs, etc).
One question that I haven't found answered in my perusals of the site is a
definitive statement of the cryptographic technology used by the Soviets. I
was re-reading Kahn's 1967 chapter on Soviet crypto and he claimed that
they relied primarily on one time pads. In fact, he was pretty specific
about them using OTPs for exactly the type of traffic appearing in the
Venona archive. But when I look at the partial decrypts in the Venona
archive I don't understand how you'd get such partial decrypts from OTPs.
The intercepts seem to indicate the use of ciphers with some codewords
weakly layerd on top. Some intercepts show translations based on the
phonetic properties of the extracted Russian plaintext. So I don't think
the "unrecovered codegroups" are caused by a classic code that substitutes
tokens for word meanings. But you're not going to crack only part of a OTP
ciphertext -- presumably you'd need a compromised key tape, and that would
either decrypt everything or nothing.
So they were either really using rotor machines or they were using
something else. Any other ideas? Other references?
smith at sctc.com          secure computing corporation

@_date: 1996-08-28 02:03:09
@_author: Rick Smith 
@_subject: NSA's Venona Intercepts 
Kahn's "Codebreakers" also has photos of OTPs captured from undercover
Soviet spies. The fact that illegals were using OTPs to talk to their
controllers didn't necessarily imply that messages from Soviet embassies
and other offices needed to be using OTPs themselves. The could have used a
good rotor machine (well, good for the era). But now I'm convinced they
The whole thing makes sense if we're looking at cryptanalysis based on
reused OTPs. I can see why the NSA doesn't mind letting the world know that
they could crack reused OTPs as opposed to some other identifiable cipher
technique. The degree of NSA's success doesn't help an adversary optimize
their crypto technology. The decryption success is in direct proportion to
how sloppy the Soviets were in using their OTPs. I'll bet some official got
shot when this was all figured out.
Partial decrypts occur when parts of the keystream are recovered and other
parts are not. I wonder if one could compare the "holes" in the various
messages and thereby infer which OTPs were used for which messages based on
patterns of keystream recovery.
Venona also presents an object lesson on why not to use OTPs: the security
does not degrade gracefully if they are misused. Reusing one even once
could easily compromise both messages sent with it. I doubt security
degrades nearly as quickly if you overuse or reuse keys in more modern
techniques. Thus, OTP keying requires a reliably pessimistic prediction of
traffic flow, and your security is toast if you underestimate your
transmission needs.
Besides, given that nobody can crack a truly randomized OTP, I can see why
NSA would want to publicize a failed use of OTPs. Might as well focus
interest on more theoretically tractable techniques.

@_date: 1996-01-22 09:06:32
@_author: Rick Smith 
@_subject: NSA vacuuming down Internet traffic 
alanh at infi.net (Alan Horowitz) asks:
There are two parts to this question. First, how do you choose targets?  It's been a few years since I read
Bamford's book (when *is* the next edition coming out, anyway?) but I
seem to remember that there is some sort of "committee" that agrees on
what to aim at. It probably contains the usual collection of
bureaucrats from military and civilian agencies. Despite the lofty
budgets, even the NSA's vacuum cleaner has a hose of limited size. The
committee allocates the available resources to prioritized objectives.
You can probably predict targets by estimating political priorities
and clout of the various agencies, and, of course, by watching CNN.
Second, how do you ensure that you capture relevant traffic? I'm sure
you start with the obvious -- look at traffic that's definitely
relevant and set up filters to find more of it. While it's attractive
to want to treat this as a state detection problem (message is/isn't
relevant) you really want more of a signal analysis solution (measure
likelihood of relevance). Also, a high priority target would probably
have its hit behavior evaluated by real humans to ensure that the
expected amount of relevant traffic is continuously sucked up.
My first job, twenty years ago, involved a prototype speech
recognition system under contract for Rome Air Development Center (a
traditional cover for TLA research). The machine was supposed to go
beep whenever a specified word or phrase was heard over the input
voice stream. We joked about testing for the term "Russian Spy" but
settled on looking for "Kissinger" instead. That let us run tests by
listening to news broadcasts of the time. We built custom boards with
Schottky TTL and a blazing fast 120ns cycle time. Times change, eh?
smith at sctc.com            secure computing corporation

@_date: 1996-01-24 05:27:58
@_author: Rick Smith 
@_subject: NSA vacuuming down Internet traffic 
Not. It wasn't a classified project. It was upstairs from Woolworth's
in Central Square, ferheavens sake. SCIFs would have annoyed the
landlord, and presented interesting "challenges" given the pasteboard
construction. We didn't even have any of those clunky file cabinets
for Keeping Secrets Safe.  We just amused ourselves with such
speculation, since this was clearly a technology that excited interest
in certain quarters.

@_date: 1996-01-25 05:02:14
@_author: Rick Smith 
@_subject: IPSEC == end of firewalls 
What firewalls do is they allow an independent group of people to
track external network access and enforce rules over a large
population of hosts. Given that just about any security installed on a
workstation can be overcome (inadvertently or consciously) by someone
with physical access to it, I doubt firewalls will ever go away
entirely. Today's techniques will no doubt evolve and change in varous
ways over time. But I'd be surprised if the function went away
Until Netscape came out I suspected that desktop crypto wouldn't make
the bigtime soon, simply because there are too many ways to do it
wrong. Netscape has demonstrated that doing it wrong is no impediment
to deployment.
Organizations that want to do crypto well are probably going to
concentrate crypto services in a few closely managed hosts to reduce
the risk of messing things up.
smith at sctc.com         secure computing corporation

@_date: 1996-07-09 11:44:15
@_author: Rick Smith 
@_subject: [RANT] Giving Mind Control Drugs to Children 
Tim writes about Ritalin:
It sounds to me like the mom is abusing the drug -- Ritalin is tricky
stuff and you can really mess up a kid by overdosing.  That's child
abuse, IMHO, not some benigh paddling.
Alex, our 8 year old son, uses Ritalin. He doesn't need Ritalin to
concentrate. He can get caught up in a building project for hours and
create a masterpiece. He can focus so thoroughly you can't pry him
What Alex *can't* do is get comfortably through a day of grammar
school. I sympathise -- I was the same way when I was that age. I had
a tough time and I saw Alex having problems similar to mine.  So I
sic'ed the educational establishment on the problem. Alex ended up
with a Ritalin prescription. At least for now. And it's been pretty
effective. With Ritalin he finds it much easier to concentrate on
drivel, an important skill to make it through school, or sports.
The problem is that Ritalin isn't some useful, generically wholesome
substance like milk or peanut butter -- you risk more than "acting
out" if you're not incredibly careful. Sleep disorders at least.  But
I don't like the downside of doing nothing, so we're trying it out.
I've *never* seen Alex zoned out on Ritalin.

@_date: 1996-07-10 02:15:19
@_author: Rick Smith 
@_subject: [RANT] Giving Mind Control Drugs to Children 
Home schooling has its own set of disadvantages. I've done enough teaching
to respect it as a profession, especially when dealing with a small,
evolving set of students. I also respect my own limitations.
I tend to agree, but it doesn't make the problem any easier to solve.
Another alternative to Ritalin would simply be to let him struggle with
school. It worked for me, I guess.
I definitely see that as a risk. Without knowing how his parents and
associated medical gurus (if any) were managing the drug, it's hard to tell
if the situations are parallel.
Life without Ritalin prepared me for a life as a coffee addict, I guess.

@_date: 1996-07-10 03:44:20
@_author: Rick Smith 
@_subject: [RANT] Giving Mind Control Drugs to Children 
Tim writes more about Ritalin:
That's very interesting, especially the part about video games. It
sounds like overdosing to me. My wife says that a Ritalin overdose can
also affect your heart rate and ability to sleep.
Regarding video games, we went through some elaborate assessment
process before Alex ended up on Ritalin. The school people did an
assessment declaring he wasn't "learning disabled" but may have ADHD.
Then he saw a behavioral psychologist for a few hours of observation,
yielding the diagnosis. Lastly a different psychologist measured his
behavior using some computer based game/test. The actual dosage was
calibrated according to his effectiveness on the game/test, which
involved memory, coordination, and ability to concentrate on something
fundamentally boring. The test was performed 3 times to compare his
performance before and after dosage.
The point of all this is that there are other ways of using Ritalin.
I don't think I'd tolerate its use on Alex if I didn't trust my wife.
She has a much better background in such things than I, as well as a
family doctor's experience with seeing the results of drug abuse.
This matches my own experiences with ADHD.  That's the thing about the
raw phenomenon and its overall lifestyle effect: you either find your
niche and do OK, or you get sidelined.

@_date: 1996-07-10 04:39:01
@_author: Rick Smith 
@_subject: [RANT] Giving Mind Control Drugs to Children 
I use coffee, or else I just managed to grow out of the worst effects.
In any case, I drink more coffee than just about anyone I know, and it
doesn't "wire" me at all.

@_date: 1996-06-28 10:22:36
@_author: Rick Smith 
@_subject: CIA Fears UmpTeen InfoNukes 
m5 at vail.tivoli.com (Mike McNally) asks:
The number comes from the recent GAO report, which provides it as an
estimated upper bound of the number of attacks. Notice how rapidly the
press loses the distinction between an estimated upper bound and a
hard number. The GAO report claims that 559 attacks were reported on
DOD machines last year, and that "only 1 in about 150 incidents" are
reported. That comes out to less than 84,000, and I'm not sure where
the extra factor of 3 comes from. The GAO report is vage about the
distinction between "reported" and "successful" attacks in statistics
from different sources, and this may account for some of it.
The GAO report also gives statistics from recent penetration work
done by DISA. What they did was mount a bunch of attacks on DOD
systems and see what happened. They claimed a 65% success rate.  Only
4% of the successful attacks were detected, and only 27% of those
detected were reported back up the line to the Pentagon.
It's an interesting report. It's gao/aimd-96-84, and you can get it
via their website at (no kidding) smith at sctc.com        secure computing corporation

@_date: 1996-06-29 09:56:56
@_author: Rick Smith 
@_subject: CIA Fears UmpTeen InfoNukes 
frantz at netcom.com (Bill Frantz) writes about the miserable state of
computer security, and I'll comment on some statements, hopefully
taken not too far out of order and context:
The phrase "backward compatibility" is, in my experience, a code
phrase for peoples' annoying habit of wanting to stay with things
they've finally made useful as opposed to having them replaced by
something "better" that is more expensive, less convenient, and in
general less familiar. The components of the latest release of MS
Office come to mind as a good example, and they didn't even include
public key crypto to atone for it.
I agree that it's seductive for us security weenies to think the tail
wags the dog, but let's remember what's really supposed to be happening.
The requirement isn't "backwards compatibility," the requirement is
that people get their work done. If the security threat keeps them
from getting their work done, then backwards compatibility is no
longer a major requirement.
The problem (or at least the difference) is in the priorities
established by an organization's culture. Some would rather take the
risks and do things in a fairly open, if unpredictable, environment.
Some prefer and even thrive on predictability. Either approach can and
does produce valuable results. However, few people want to use a bank
that takes the "open, if unpredicable" approach. Banks have auditors.
Nonsense. The mere fact that it's not currently deployed guarantees
that it won't be user transparent. Vendors will include it on some
rewrite of whatever software it's embedded in. Memory requirements go
up and delays are introduced when the crypto computations are
performed. Security will be added only if it gives customers more
things they can do, so there'll be other functional changes as well.
In any case, working crypto *can't* be entirely user transparent.
People need to handle keys, choose the one to use, and update them
occasionally. There is a lot of training and cultural awareness
involved here that just doesn't exist yet.
And there will be *billions* in fraud before people finally learn,
then maybe it'll attenuate to mere millions (and I'm probably still
optimistic by orders of magnitude).  Look at credit and ATM cards. A
dozen years ago a bank issued us some ATM cards, and the clerk
insisted on writing the PIN code ON the cards. Very few banks do that
any more.
smith at sctc.com            secure computing corporation

@_date: 1996-03-08 23:18:36
@_author: Rick Smith 
@_subject: art-stego 
In a related vein, consider the work of a Minnesota folk hero from the
last century named Ignatius Donneley.  Aside from trying to start a
Utopian community just north or our town, he wrote a book "proving"
that Shakespeare was really Francis Bacon. His proof was based on
"decrypting" hints in messages hidden in Shakespeare's writings.
Donneley also wrote a book on Atlantis (available from Dover) and
another postulating that a huge comet caused the extinction of the
dinosaurs. A crackpot, eh?
smith at sctc.com           secure computing corporation

@_date: 1996-03-23 19:13:11
@_author: Rick Smith 
@_subject: NT's C2 rating 
Regarding the comment:
C2 is no big deal. It means you have the typical security measures
that can be disabled or bypassed by a trojan horse. You're not doing
serious protection till you put in mandatory protections like what
appears in B or A level systems.
The big deal is that few vendors have tried to get NCSC evaluations.
smith at sctc.com    secure computing corporation

@_date: 1996-05-08 13:07:33
@_author: Rick Smith 
@_subject: Security Scruffies vs Neats, revisited 
This is an attempt to restart the discussion in a slightly different direction.
I've been giving the topic some thought since Tim's truncated essay
appeared. But when I re-read it just now, I realized that I read in my own
interpretation of "scruffy" and "neat" to this.
IMHO, the critical property of AI scruffies is that they believe in the
value of some notion of emergent behavior -- if you build it right, it'll
surprise you and do something clever and unexpected to fulfill its
objectives. The "neats" have to know exactly why the behavior emerged, but
the scruffy methodology almost never allows such a detailed analysis to
Intuitively, I tend to think of scruffies as trying to build biological
processes or concepts into computers. The goal seeking built into IP
packets, for instance. The Internet is an impossible artifact, if you view
distributed computing with '70s blinders. Nobody would want to cede control
so much to largely autonomous routers. Once you drop an IP packet into the
"system" it generally gets to its destination or dies of old age trying.
When I try to apply this style of thinking to security, I find myself going
towards layered defenses. These goal seeking, semi biological processes are
somewhat failure prone, so you probably need a set of them to make things
"safe." Falling back to biology, we see "security" in the various defensive
mechanisms developed in plants and animals.
But now things start to break down. "Security" these days means more than
defense -- it means access control. "Let me in" as well as "Keep them out."
How do you "tune" or "train" a semi-biological mechanism to exert such fine
control? It's not clear to me that you can. When I read Kevin Kelley's book
"Out Of Control" I kept wondering who wanted to live with his semi-biological
toasters and heating plants, tolerating burned toast and frozen bathrooms
until the devices finally "learned" how to behave. (but I shouldn't get
started on that book -- I once wrote 20 pages of notes about how bogus I
thought it was).
In other words, the problem may be with the concept of security itself.
Defense seems to be a biological concept, but security is not. It's too
artificial, involving the reflection of some abstract and arbitrary human
intent. Constructing a subsumption device to collect pop cans is one thing,
but building one to construct a cuckoo clock (or play doorman) is something

@_date: 1996-11-12 13:54:06
@_author: Rick Smith 
@_subject: Secrecy: My life as a nym. (Was: nym blown?) 
: Are there other measures which parents could take while their children are
: young to get them off to a good start, privacy-wise?
I doubt it's ever too late to start. Sure, it seems as if old, crufty
bits sit on the 'Net just waiting to embarass us ("oh, yeah, maybe I
*did* post to alt.naughty.stuff 'way back then...") but there *is*
such a thing as bit rot and perhaps it really is our friend after all.
The first question, always, when evaluating security measures is to
ask "What are you trying to protect?"
This gets really weird when you don't know what the threats really
are, which is true of this situation. I don't really see "privacy"
itself as something you can pursue as an absolute objective. I think
Black Unicorn's tale illustrates this well -- he doesn't try for
non-existence, instead he describes a series of well reasoned and
consistent steps. Basically, though, it has to be a personal choice.
So it's hard to judge perfectly for another, even your own kids.
IMHO you have to find a reasonable balance for your kids. The problem
is that you don't want your kids to disappear -- there are times they
will WANT their records found. The problem is to make verification
easy when they're directly involved and difficult otherwise.
The basic and obvious rule to most of us is to control the SSN and
don't give out a correct one except when absolutely necessary.  One of
the banks in Minneapolis refuses to pay interest at all if you don't
have your SSN on file.
I toyed with the idea of manipulating birthdates, but it wasn't clear
what the benefit was. Also, it required my wife's help, and I'll defer
to Tim May's recent discussion of his'n'her anarchy if you wonder why
this might be an impediment. If the kids know their "real" birthdate
they'll *always* report it to their teachers. And if it's consistently
incorrect in school records, then what does it mean for it to be
When faced with peculiar situations I try to choose a disclosure that
meets whatever the immediate requirements are but doesn't make it easy
to automatically match up records. Often the best you can do is reduce
certainty and increase the likelihood of multiple matches with other
records. It doesn't hurt if you last name is Smith here in the U.S.A.
smith at sctc.com

@_date: 1996-11-13 10:33:27
@_author: Rick Smith 
@_subject: Dossier on Tim May is Easily Obtainable 
The thorough investigator respects the value of physical records and
interviews with those actually present. Bit rot is a tricky thing, and so
are simple string matches.
Perhaps that was the Rick Smith in the class behind or before me who is or
is not shown in yearbook photos with that blonde cheerleader. Or perhaps it
was another Rick Smith who does or does not appear in yearbook photographs
in the company of various brunette females. Could it have been the Rick
Smith whose house got struck by lightning in our town a few weeks back? Or
the Rick Smith who just got a building permit? Are these all the same
person? Nope.
On the other hand, a review of physical records from that important era of
the mid 1960s *does* indicate the existence of one and only one young
Timothy Christopher May in the vicinity of Langley, Va.
Interviews with [SOURCE DELETED] indicate that this young Timothy
Christopher May was known for a clever and abrasive style of discourse.
Investigators note that the exact same style of discourse appears in the
postings of one "Tim May" who is associated with that subversive cabal
known as "cypherpunks." The interviews also indicate that young Timothy
Christopher May was observed on numerous occasions to be reading Scientific
American in the school library and didn't always "share." E-mail messages
authored by "Tim May" and intercepted by [SOURCE DELETED] state that he has
read Scientific American on numerous occasions. At this time there is no
evidence as to whether or not "Tim May" willingly shares his magazines with
others, though some investigators argue that it is unlikely.
Records retrieved from [SOURCE DELETED] also show that the young Timothy
Christopher May exploited his interest in physics for destructive purposes,
like elaborate pranks involving fictious weaponry and national security
information. [INFORMATION DELETED FOR NATIONAL SECURITY REASONS -- ORCON
U31 -- OADR FOR RECLASSIFICATION]
However, more careful investigators have uncovered evidence to suggest that
this was not entirely a prank. Records from [SOURCE DELETED] indicate that
the young Timothy Christopher May purchased a huge gap magnet from Edmund
Scientific Company and also produced science fair project titled "Ball
Lightning: A Stable Plasma?" Investigators suspect the timing of these
events is not a coincidence.
Unfortunately, the photographs of young Timothy Christopher May being
escorted out of Earth Science class by agents of the Office of Naval
Intelligence have somehow been tampered with and are difficult to
reconstruct. Perhaps with modern technology...
Hmmm, similarities in name, interests, style of discourse, and a history of
technological subversion. Is this the same individual, thirty years later?
Gentle readers, you decide.
smith at sctc.com

@_date: 1996-11-13 14:31:40
@_author: Rick Smith 
@_subject: Validating SSNs 
OK, I'll bite.
My guess is that the bank sticks the SSN in a report to the IRS and the
bank is happy with the SSN as long as the IRS doesn't complain about it.
Now, does the IRS check? I suspect that they don't, either. Their objective
is to look for "matches" with SSNs that show up on filed tax forms, since
they want to verify the data on the tax form. Given the behavior of every
other large database I've ever seen, I'd guess that there would be a huge
number of SSNs that don't in fact associate with tax forms. If someone High
Up hasn't decreed that they should chase such things down (and allocated
heaps of money to do it), they'll ignore the mismatches.
This seems consistent with the reports of people who use bogus SSNs for
decades at a time.
smith at sctc.com

@_date: 1996-10-02 10:31:21
@_author: Rick Smith 
@_subject: How might new GAK be enforced? 
Tim May asks:
: Any other ideas on how the government plans to enforce GAK, to make GAK the
: overwhelmingly-preferred solution?
The problem seems somewhat analogous to the software copy protection
problem and maybe the enfocement will be similar: make "examples" of a
few high profile offenders who are exchanging blatantly un-GAKed
traffic with foreigners. This assumes they fine tune the law to make
such behavior illegal without having to prove you yourself exported
the stuff to them. Wonder what the Supremes will say to that.
But that's not the end of the story. If there is lots of GAK encrypted
traffic flowing about, then encrypted traffic in general is no longer
noteworthy. So as long as your traffic looks like GAK, you won't be
hassled until they try to read your traffic.
So it's possible that products will appear that use pseudo-GAK
protocols -- they look just like their GAKed cousins but the GAK
fields contain plausiable garbage instead of keys. It could even
turn out to be a vendor "quality control" thing -- oops, the GAK
was supposed to work but...
You couldn't do that with Clipper (except via Matt Blaze's brute
forcing of the LEAF checksum) because the crypto wouldn't decrypt a
packet with an invalid LEAF checksum. Since it was a sealed hardware
module, implementers had no choice but to play by those rules. There's
no such enforcable limitation on commercial software implementations.

@_date: 1996-09-04 03:52:17
@_author: Rick Smith 
@_subject: Moscowchannel.com hack 
: > Just a matter of time before some builds a dedicated Satan type tool that
: > scans for  HTTP server holes or messed up file permissions to make locating
: > potential victims easy.
Snow replied:
: Write your web site to a CD-ROM and hard-code the base directory into the
: webserver.
Or host it on something with mandatory access control protections.
There are still a handful of us building such things, and they can
give really good protection to web page contents.
smith at sctc.com         secure computing corporation

@_date: 1996-09-05 06:36:01
@_author: Rick Smith 
@_subject: Protecting Web servers (was: Moscowchannel.com hack) 
Years ago, the government published some criteria for highly secure
systems, notably the TCSEC or "Orange Book," which described requirements
for protecting classified information on a timesharing system with
uncleared users. Several vendors managed to build such systems, though very
few were judged secure enough to really protect classified data from
uncleared users.
However, the underlying mechanisms of "mandatory access control" do manage
to block a range of sophisticated attacks against the host computer. These
are the systems given the various B and A ratings: B1, B2, B3, A1 (in
ascending order of security). Also-ran systems that can keep honest people
from tripping over one another were given "C" ratings, though "C2" is all
you see any more.
A few vendors are putting Web servers and such on systems with mandatory
protection. I've heard talk of it from SecureWare, HP, Harris, and AT&T
using B1 or B1-like systems. Pardon the plug, but our Sidewinder also hosts
a protected Web server and uses mandatory protection to prevent Internet
attacks from damaging it.
In practice, I've found that most customers just want to demonstrate "due
diligence" regarding security. They pick up whatever's popular in the
marketplace that has some pretention of strong security ("We're C2 rated by
the government!!"). It's a rare customer that actually takes the time to
look at the security issues and consider whether they might need what
mandatory protection provides.
smith at sctc.com             secure computing corporation

@_date: 1996-09-10 13:32:26
@_author: Rick Smith 
@_subject: Conservation Laws, Money, Engines, and Ontology 
Wouldn't the model fit reality better if it were based on biological
analogies instead of the raw physics of energy?
I recognize there's a desire here to put some controls on one's own
equipment ("I don't want to receive spam if I don't want to") and that
physics provides the conceptual lever to argue in favor of the desired
controls. Biological systems are a poor choice for grained control by
people who like to change their minds.
But the Internet really is more like an ecology with its own complex
notion of "emergent order" than a simple physical process that must
obey conservation laws in some narrow fashion. Trees obey physical
conservation laws, but they don't exchange micropayments with soil,
air, and Sun to ensure the balance is preserved. As things get out of
balance, trees die. Other entities flourish.
I can't imagine the mechanism by which very precise access charging
and cost recovery mechanisms would replace the current "free" model.
As we all know, it's not really "free."  Information is published and
made available because the vendor needs to distribute it and finds the
Internet to be a cheap way to make it available.  Many vendors
exchange information and entertainment for your attention to a
commercial message. As long as there are unmetered 'Net resources (and
they're unmetered for a plethora of reasons) you'll never get rid of
free riders.
I think you have to choose between the relatively lawless open world
or an enclave where you bar the door with your favorite security
measures. You allow spam as long as you allow uninvited guests.  And
what is cypherpunks but a continuous party of uninvited guests?
Regarding these micropayment machines, I think it would be interesting
to identify some existing, widely used, real world analogues to them:
how big/small are individual transactions, how much money can you
securely collect, how much does the mechanism cost to deploy and
maintain, how hard is it to attack, etc. Gumball machines? Pop
machines?  Pay phones?  I'm not sure there *is* a real world analogue.
smith at sctc.com          secure computing corporation

@_date: 1996-09-12 09:31:24
@_author: Rick Smith 
@_subject: Child Porn as Thoughtcrime 
: Declan answers in the affirmative that, yes, nearly all of the examples I
: cited are indeed crimes. ....
: As I well knew, which is why I presented them. (The Jock Sturges case was
: in SF,  ...
I've read in several places that the Jock Sturges case was thrown out
of court by the judge. Nobody has dragged me away in shackles for
owning "Radiant Images."  Stores selling photo books often carry his
work, and it is rarely covered with opaque plastic.
So it may be nudity that set the gendarmes (sp?) in motion, but that's
evidently not what's really illegal. I wonder what would happen if an
"adult magazine" were to reproduce Sturges' work. The court case might
be interesting...
Now apply that to the Web. Imagine there's a Sturges site, and a porn
site links to it. Does that make the Sturges material "child porn?"
If so, is the porn site illegal or the Sturges site? I suspect the
prosecutors will come down on both and let the courts sort it out.
Prior restraint, eh?
: ...the "little girls in leotards" case was only a few years ago, etc.)
Don't know about that one. Is it illegal for little girls to be
photographed in leotards now? "Nutcracker" is X rated? Move over,
Personally, I think the political posturing theory captures the
essence of the legislative climate.

@_date: 1996-09-13 05:36:12
@_author: Rick Smith 
@_subject: (Correction) Child Porn as Thoughtcrime 
: I've read in several places that the Jock Sturges case was thrown out
:   Nobody has dragged me away in shackles for
: owning "Radiant Images."
Correction -- That's "Radiant Identities."

@_date: 1996-09-17 09:41:27
@_author: Rick Smith 
@_subject: Workers Paradise. /Political rant. 
: .... But suppose the population problem could
: be fixed. Then, with technology escalating towards singularity,
: machines doing almost all labor, there could certainly exist a
: system where the 'dumb' and 'lazy' could be fed and housed properly
: without anybody complaining.
I'm always fascinated when people trot out this notion of technology
giving us a maintenance free world that provides all our needs.  Like
Rifkin's "End of Work." I'm sorry but I just don't see how the
problems of food and shelter are solved simply because we've automated
the production of bank statements.  All the really effective
automation has involved symbolic activities, not the basic stuff of
life, like food and shelter.
: P.S.  Mac Donalds could easily be replaced by a bot.
Very unlikely. Despite the incredible degree of mechanization that
happens in food production, *most* of it requires people in the loop.
Part of it is health concerns -- you're far more likely to poison a
significant portion of the population if you don't keep active human
involvement in food production. But there's also a lot having to do
with the structure of the work. You *can't* send a robot tractor into
the fields and expect it to treat your corn right. And milking
machines, well ....
I did a lot with fault tolerance and industrial robotics in a previous
life. Robots work fine in highly structured environments. Their value
decreases dramatically as you remove structure.  In unstructured
environments they're either useless or just plain dangerous. Even the
so called "industrialized" farms are wildly unstructured compared to a
factory floor. And there's little reason to assume that 'biological
units' (plants and animals produced for food) in a fully structured
factory-like setting will yield all the products necessary for an
adequate food supply.  It seems that whenever we develop a "complete"
model of what people need to survive and subject a few people to it,
we discover that something fatal has been left out.
: But to force people into menial service jobs just to literally
: survive is not to my taste. No, give them minimal shelter for
: nothing and from there on let the market anarcho-capitalistic
: struggle begin, for obtaining a higher than minimum material
: standard or reputational standing.
I suspect that the Real World will always require a large portion of
the available labor pool to do work that supports the production of
food and shelter. The support has gotten pretty indirect in modern
industrialized countries, I admit.
smith at sctc.com

@_date: 1997-01-07 14:46:56
@_author: Rick Smith 
@_subject: Relative Strength of 40-bit Crypto Implementations 
: 	A client asked me today about where he could find evidence of the
: relative strength of different encryption algorithms, when all are
: restricted to 40-bit keys.  He assumed dot-Gov was going to restrict his
: export product to the 40-bit limit, but he wanted to provide the strongest
: security he could within that limitation.
There is a tiny technical wrinkle here -- the simpleminded approach is
to use a 40 bit secret key appended to a constant, the smarter
approach is to use some disclosed random data that, combined with 40
secret bits, produces a much longer key. It's like the salt in Unix
passwords.  The simple approach can allow an attacker to use a
dictionary attack. The smarter approach means that the algorithm's
full key length gets used.
So, for example, you have 128 bit RC4 in which 88 bits are random but
disclosed while the remaining 40 bits are still secret.
The only practical problem is disclosure of the extra random bits,
which the government expects the software to do. This is one of the
uses of the big chunks of random data that host exchange in SSL V3.
In earler SSLs they built the disclosed bits right into the protocol,
an explicit field for disclosing part of the key.
smith at sctc.com          secure computing corporation

@_date: 1997-01-21 15:33:48
@_author: Rick Smith 
@_subject: Keyword scanning/speech recognition 
: I was talking to someone recently about the feasibilty of keyword-scanning
: phone conversations....
My first "real" job in the computer industry was for a garage shop
doing speech recognition. We did a demo system in 1977 for Rome Labs
that did exactly what you're asking about: scanning a stream of
continuous speech over a telephone line looking for key words. It was
tolerably effective: I forget the success rate but it was above 90%.
But we were never asked to go past the research prototype.
We did it the "hard way" in that we were trying to solve the "talk to
the computer" problem which is harder than the "look for something
suspicious worth looking closer at" problem. I expect they were looking
for something to cut down on their false positives and perhaps we weren't
significantly better than what they were already doing.
: "Discrete Utterance Speech Recognition without Time Alignment", John Shore
: and David Burton, IEEE Trans.Information Theory, Vol.29, No.4 (July 1983),
:  p.473.
:  :This generates a feature vector every 10-30ms from input speech which is
:compared to pre-generated reference sequences.  It also has references to many
:other papers covering the same area.
When I worked in the field "discrete utterance" was the buzz phrase
for talking with - pauses - between - each - word. Ecch. Our
commercial systems at the time (late '70s) used discrete speech
without time alignment since we could process 8 input channels
simultaneously.  Ahhh. The joys of microcoding for a 74S181 ALU.
smith at sctc.com            secure computing corporation

@_date: 1997-01-21 15:59:49
@_author: Rick Smith 
@_subject: Keyword scanning/speech recognition 
: I was talking to someone recently about the feasibilty of keyword-scanning
: phone conversations....
My first "real" job in the computer industry was for a garage shop
doing speech recognition. We did a demo system in 1977 for Rome Labs
that did exactly what you're asking about: scanning a stream of
continuous speech over a telephone line looking for key words. It was
tolerably effective: I forget the success rate but it was above 90%.
But we were never asked to go past the research prototype.
We did it the "hard way" in that we were trying to solve the "talk to
the computer" problem which is harder than the "look for something
suspicious worth looking closer at" problem. I expect they were looking
for something to cut down on their false positives and perhaps we weren't
significantly better than what they were already doing.
: "Discrete Utterance Speech Recognition without Time Alignment", John Shore
: and David Burton, IEEE Trans.Information Theory, Vol.29, No.4 (July 1983),
:  p.473.
:  :This generates a feature vector every 10-30ms from input speech which is
:compared to pre-generated reference sequences.  It also has references to many
:other papers covering the same area.
When I worked in the field "discrete utterance" was the buzz phrase
for talking with - pauses - between - each - word. Ecch. Our
commercial systems at the time (late '70s) used discrete speech
without time alignment since we could process 8 input channels
simultaneously.  Ahhh. The joys of microcoding for a 74S181 ALU.
smith at sctc.com            secure computing corporation
