
@_date: 2002-08-20 01:58:50
@_author: Jason Holt 
@_subject: Data Security class programming project 
I'm working on designing the programming projects for a data security class.  What do you think of this one?
I love its intrinsic irony, but can we actually get away with requiring it for
a university class?  I mean, Elcomsoft really is in court for this.  My
University is unfortunately not the type of organization to stand at the
forefront and protect our civil rights.
DRM Lab
* Make the lab open-ended - they get to pick what to break and how, as long as
they don't use a pre-packaged tool.  DVDs, CDs, .WMA, etc.
To demonstrate the fundamental futility of current attempts to prevent
unauthorized copying of published works.
_Here_ you can find a copy of Dmitry Sklyarov's Defcon slides in Adobe's eBook
format.  They were created with the eBookPro compiler, advertised as "the only
software in the universe that makes your information virtually 100%
Extract all text from the slides using the method of your choice and turn in
the resulting text file.  It needs no special formatting.

@_date: 2002-08-27 02:39:15
@_author: Jason Holt 
@_subject: Chaum's unpatented ecash scheme 
credentials.  It'll be nice to have it at least referenced in the literature,
since Ben's paper is the only place I know of where it's really explained.  I
give a URL for it as well as credit to Anonymous, but it would be helpful to
know who really should be credited with what.
I haven't been able to tell how much David Wagner had to do with the idea.  Ben?  David? The URLs to the Anon messages are handy; I'll see about including
them too.

@_date: 2002-07-23 18:11:04
@_author: Jason Holt 
@_subject: Tunneling through hostile proxy 
back and forth, allowing you to connect all the way to the other server.  However, it is possible for the proxy to have its own CA which has been added
to your browser.  Then it acts as a man in the middle and pretends to be the
remote host to you, and vice versa.  In that case, it works as you describe,
watching the data during its interim decryption.
"*.com"), but it could conceivably generate a certificate for each site you
visit ("secure.yahoo.com", etc.).  The way to tell would be to look at the
issuing authority according to your browser - if it's one of the public ones,
like Thawte, you've got a connection to the far end.  If it's "Th4wt3", or
your company's, the proxy is probably watching.
 (along with other nifty anonymizing stuff).

@_date: 2002-07-23 19:58:00
@_author: Jason Holt 
@_subject: Tunneling through hostile proxy 
I don't know of any other real-world examples.  Rescorla mentions the
technique on pp. 316-319 of "SSL and TLS".  Certainly Thawte isn't going to
issue such wildcard certs, for exactly the reasons you mention.  That's why
you (or your government, or company, or whoever keeps an eye on you) create
your *own* CA and tell your browser to trust it.  Then it'll accept the
wildcard certs without complaint.

@_date: 2002-06-05 19:37:34
@_author: Jason Holt 
@_subject: Laurie's blinding w/cut and choose? 
where h is the message, and g is the public generator:
r = blind(h) = h^y * g^b (mod p)
s = sign(r) = m^h
(s/g^k^b)^(1/y) (mod p)
signer can verify the signature).  Unfortunately, this doesn't work with cut
and choose where the signer signs the product of unrevealed documents, since the 1/y exponent above would distribute to all the internal terms:
    ((r  * r  * r   ...)^k)^(1/y )
       1    2    3              1
    ------------------------------     !=  (h  * r  * r   ...)^k   (mod p)
             (g^k)^b                         1    2    3
                    1
money system since he doesn't need cut and choose, but I'm working on a
patent-free credential system where the issuer needs to cut and choose to keep
the user from cheating.
(that foils the issuer from adding subliminal information that would
compromise the blinding) without stepping on Chaum's patent?  I hear Chaum
mentioned one himself at PET 2002, but I can't find anything about it online.

@_date: 2002-06-07 20:07:50
@_author: Jason Holt 
@_subject: More of Ben's blinding 
undeniable signatures, they're actually much closer to (h^y)(g^b), so your
suggestion should work great.  Thanks!
about Chaum's blind signature and undeniable signature patents, and want to
present as patent-free a system as possible.
(h1*g^b1 *h2*g^b2 *h3*g^b3...)^k
being hard.  If I replace h1 with (g^b0) and get the issuer to sign:
((g^b0)*g^b1 *h2*g^b2 *h3*g^b3...)^k
the cut-and-choose protocol will be to require that the n/2 checked documents
are all valid and different from any previous instances of the protocol.  So
it should be extremely hard for the user to sneak lots of previously used
values and fake h's (which are really blinding factors) into the unrevealed
documents.  But are there other ways to separate out signatures on individual

@_date: 2002-06-11 01:56:34
@_author: Jason Holt 
@_subject: Ben's blinding, plus pre-publishing 
maybe on sci.crypt.research) before sending it off to the journals.  What are
the issues surrounding that, though?
I'd be leaking something secret.  AFAICT, nobody else would be able to apply
for a patent on the idea without telling a lot of lies in the process.  So
that leaves the possibility that somebody whips out another paper on the topic
before mine's all the way done.  Are the journals going to be snippy about
copyright issues?  Why haven't I seen other papers published on usenet and
such before going to press?
each issuing session which gets hashed several times along with some other
data before going into the blinded messages.  You have to prove that the value
properly descends from the issuer's random value, which makes it tough to
reuse values from a previous session.

@_date: 2002-06-14 01:35:41
@_author: Jason Holt 
@_subject: Safe RSA variant? 
Well, I got such a good response from my last technical question that I'll try
again :)
If it's actually secure, it'll go really well with my credential system.
Trent generates primes p,q.  He publishes n=pq and some random value g.
Trent calculates a and a' such that aa' = 1 % (p-1)(q-1) and a' is prime.  He
sends Alice a' and g^a%n.  a' is her secret exponent and g^a%n her public
Bob can establish a shared secret with Alice if Alice got a' from Trent.  He
picks a random r and sends her g^ar%n.  She raises it to a' to compute the
shared secret g^r%n.
So the important questions are:
* Given g^a%n and a', can Alice derive (p-1)(q-1)?  If so, she'd be able to
take over Trent's job.
* Given g^k%n and k' for lots of different k, can we derive (p-1)(q-1) or
otherwise imitate Trent's ability to give out (g^k%n, k') pairs?
So IOW the goal is for Bob to be able to send Alice a message iff she knows a
secret from Trent.  And if Alice's secret is compromised, only messages sent
to (or possibly from)  Alice become vulnerable.
A friend of mine pointed out that Alice can trivially compute another working
pair of keys from her own: g^-a and -a'. And if the a' keys weren't prime,
Alice and Bob could factor them and generate other keypairs. Both of those
seem manageable, though.
The common modulus attack in which you use g^k and g^k' to get information on
g (which is public in this case) by calculating rk+sk'=1 caused me problems in
earlier equations I tried, but doesn't seem to help the attacker here.

@_date: 2002-05-30 16:22:35
@_author: Jason Holt 
@_subject: When encryption is also authentication... 
Self signed certs defeat the purpose of the certificate chain mechanism, which
is not just there to make Veri$ign rich.  Mallory can self-sign a cert for
bob.com, and hack Alice's DNS to point bob.com at her own site.  But it's
(theoretically, anyway) much more difficult for her to convince Verisign that
she owns bob.com.  If we trust Verisign to do that, then we know we're really
talking to Bob when we visit bob.com.
Now, the ability to add other CAs which we trust would be a nice feature, and
if there were more trustworthy CAs which were added to the browsers by
default, we could get the costs down closer to the actual overhead of
verifying that the supplicant (er, applicant) actually owns the domain he's
trying to get a cert for.  But anyone can certify themselves as owning
amazon.com, and it's critical that my browser tell me when some stranger makes
such an assertion on their own.

@_date: 2002-05-30 20:23:06
@_author: Jason Holt 
@_subject: Making Veri$ign rich(er) 
bother with SSL at all?  SSL provides two things:
talking to
one is still nice, but if you're worried about me *watching* your traffic,
shouldn't you also be worried about me intercepting your DNS lookup and
replacing the response with my own IP?  If we all use self-signed certs,
you'll never be the wiser.
redirect *all* amazon.com traffic to me is hard.  And it can be pretty tough
to watch and modify an individual user's traffic.  But it's not nearly as
tough as breaking the crypto behind SSL.  If we use it right, that security
extends to the domain I type into my browser.  If we don't, we reduce it to
the hardness of manipulating the wire.
server end.  But that's orthogonal to the SSL issue.

@_date: 2002-11-06 05:18:40
@_author: Jason Holt 
@_subject: "patent free(?) anonymous credential system pre-print" - a simple 
(Re: my paper at  )
response to Adam).
presenting her student ID along with the senior-citizen ID Bob loaned her (or
for which Bob is answering clandestine-ly), as if they both belonged to her,
in order to get both discounts on her movie tickets.  In my system, you get
your credentials issued in a set associated with a single identity, and it's
hard for Alice to get Bob's credentials included in one of her own sets.  It
works even if the CAs don't trust each other.
help in the case when Bob answers in Alice's behalf when she shows his
credentials.  In any case, section 5.5.2 only adds liability to pooling - it
doesn't prevent it mathematically.  (As to lending in general, I think you're
right that discouragement may be the best we can do).
the credentials which the holder can prove is or isn't the same as in other
credentials.  However, the discussion on page 193 is with respect to building
digital pseudonyms, and the discussion on page 210 seems to be about showing
that values are *not* the same, following a scenario in which a pseudonym
holder has been identified as a misbehaver. I can think of ways in which this
feature might be leveraged to create otherwise-unlinkable sets of credentials
from different (distrusting) CAs, but it's never addressed directly that I can
see, and would need some specifics filled in.  Nonetheless, I'll point out in
my paper that it's a possibility in your system.
selective disclosure.
I'm glad that was clear in my text.  This isn't a do-everything system like
Brands' - rather, it has 2 aims.  1: show how to do simple selective
disclosure in a Chaum/Fiat/Naor-like system using X.509v3 credentials as a
base, and 2: show how to link credentials from multiple issuers to the same
identity without compromising anonymity.
was to create a system not encumbered by your patents or Chaum's.
others have lots of features which my system doesn't attempt to provide.  My
apologies if my terse treatment mischaracterized your work.

@_date: 2002-10-29 23:49:21
@_author: Jason Holt 
@_subject: patent free(?) anonymous credential system pre-print 
I've submitted a pre-print of my anonymous credential system to the IACR
ePrint server.  Thanks to all of you who responded to the questions I posted
here while working on it.  I'd love to hear feedback from any and all before I
sumbit it for publication; particularly, I want to make sure I haven't
forgotten to give proper attribution for any previous work.
It mentions how to use the blinding technique Ben Laurie describes in his
Lucre paper, which I don't think has been mentioned in the formal literature,
and also describes what I call a non-interactive cut and choose protocol which
is new AFAICT.  Thanks again!
                                        -J

@_date: 2004-06-16 20:28:13
@_author: Jason Holt 
@_subject: Hiawatha's research 
Hash: SHA1
"Hiawatha's Research"
Jason Holt June, 2004, released into the public domain.
Dedicated to Eric Rescorla, with apologies to Longfellow.
("E. Rescorla" may be substituted for "Hiawatha" throughout.)
Hiawatha, academic,
he could start ten research papers,
start them with such mighty study,
that the last had left his printer,
ere the first deadline extended.
Then, to serve the greater purpose,
he would post these master papers,
post them with such speed and swiftness,
to gain feedback from his cohorts,
for their mighty learned comments.
from his printer, Hiawatha
took his publication paper,
sent it to the preprint archive,
sent it out to all the newsgroups
Then he waited, watching, listening,
for the erudite discussion,
for the kudos and the errors,
that the others soon would send him.
But in this my Hiawatha
was most cruelly mistaken,
for not one did read his papers,
not one got past the simple abstract.
Still did they all grab their keyboards,
writing with great flaming fury
of the folly of his venture,
of his paper's great misgiving.
Of his obvious omissions,
of his great misunderstandings,
of his utter lack of vision,
of his blatant plagiarism.
(This last point he found most galling,
found it really quite dumbfounding,
since for prior art, he'd listed
ninety-three related papers.)
Now the mighty Hiawatha,
in his office still is sitting,
contemplating on his research,
thinking on his chosen topic.
Wondering, in idle moments,
if he had not chosen wrongly,
the position he had taken
as a research paper author
And he thinks, my Hiawatha,
if he might not have been better
served by a more lowly station,
as a cashier at McDonalds,
as a washer at the car wash,
as a cleaner of the bathrooms.
Thus departs my Hiawatha.

@_date: 2004-05-10 02:42:04
@_author: Jason Holt 
@_subject: Brands' private credentials 
Hash: SHA1
Right, good summary.
How would you use SSL to prove fulfillment without revealing how?  You could
get the CA to issue you a "patient or doctor" SSL cert, likewise for every
possible combination of things somebody might ask you for, but that's not very
practical.  Presumably this is why the other systems also allow proof of
expressions without revealing all the attributes you used to do so.
If you can trust the server to do so.  Firstly, hidden credentials limit what
the server learns, so you don't *have* to trust the server as much.  But
secondly, they also solve the problem which shifts to the server when it goes
first: now the server has to reveal attributes to a complete stranger.  For
sensitive systems, it's easy to get circular dependencies where neither side
wants to go first.  Hidden credentials let you enforce the policy in the
ciphertext: "if you can read this, let's talk.  if not, I didn't want to talk
to you anyway (and you won't learn why)".  (Incidentally, two other similar
systems came out at about the same time as mine, both geared less toward
extreme policy/credential paranoia and more toward resolving such circular
dependencies: OSBE (Li, Du, Boneh) and Secret Handshakes (Balfanz et al)).
Right, that is a big consideration with my system; CAs can be nosy.  Of
course, any CA will want you to show paper credentials or some other
real-world proof that they should give you a credential.  But you're right
that the Chaum/Brands/L&C family do have a big advantage in limiting the risks
of big-brother CAs once they've issued it to you.
If your definition requires anonymity wrt the CA, then you're right.  My
system lets folks:
* authenticate based on attributes rather than identity
* access resources without the server even knowing whether they fulfill the
* hide policies from people who don't fulfill them
So it's definitely in the realm of other privacy systems.  We could define a
new term just to exclude my system from the others, but at this point I don't
think naming confusion is any worse for my system; they all have lots of
different nonorthogonal features.  I have to write a survey paper for my Ph.D.
requirements, and I've been thinking I should write a big feature table as
part of it.
I've never really considered it as a payment system.  It's geared more toward
systems which use extremely sensitive resources, and their corresponding
sensitive policies and credentials.

@_date: 2004-05-10 18:45:56
@_author: Jason Holt 
@_subject: blinding & BF IBE CA assisted credential system (Re: 
Well, he can always generate private keys for any pseudonym, just as in cash
systems where the bank can always issue bank notes.  Here's what I'm
suggesting, where "b" is a blinding function and n1... are random nyms:
Alice              FBI TTP
<---cut & choose: n1,n3
(Alice unblinds and now has a credential for nym n2)
So it's vanilla Chaum-style blinded credentials.  The FBI signs Alice's agent
cred without learning the nym.  Alice can use the nym, and the server can ask
the FBI the attributes (agent? chief? secretary?) of the person with the nym,
but the FBI won't know.  The FBI could eavesdrop on Alice's connection and
generate whatever creds are necessary to read the resource Bob sends her, but
that's why I was talking about building it in a protocol with PFS.
But now that I think of it, PFS isn't really necessary at all for Alice&Bob to
have a conversation where their policies are respected:
Alice                                         Bob
(Alice generates random nonce na)
HC_E(na, "Bob:agent", FBI)--->
                         (Bob generates random nb)
                 <---HC_E(nb, "Alice:member", NRA)
Both generate session keys from Hash(na,nb).
So, Alice wants to connect iff Bob's FBI, and Bob wants to talk iff Alice is
in the NRA, where "Alice" and "Bob" are random pseudonyms.  Thus they send
their random nonces na and nb encrypted against those creds (HC_E is a hidden
cred encrypt), then use those nonces for the session keys.
The FBI can *always* impersonate an agent, because, well, they're the CA and
they can make up pseudonymous agents all day long. But in this protocol, I
believe they wouldn't be able to be a MITM and/or just eavesdrop on Alice&Bob.  That's because Bob only wants to talk to NRA members, and the FBI can't
impersonate that.
Now, this is for an interactive session, rather than just sending a single
request/response round like I discuss in the paper.  But even then, policies
are always respected.  Just change "na" to "request" and "nb" to "response".  Alice's policy is respected whether she talks to FBI-authorized-Bob or
FBI-authorized-FBI, and the FBI doesn't get to read Bob's NRA-Alice-only

@_date: 2004-05-10 20:02:12
@_author: Jason Holt 
@_subject: Brands' private credentials 
Hash: SHA1
Yep, that'd be a problem in that case.  In the most recent (unpublished)  paper, I addressed that by using R as the key for a ciphertext+MAC on the
actual message.  So the server would have to find two R's that both satisfy
the MAC but produce different ciphertexts in order to learn anything from the
In either case, though, you can't just trust that the server encrypted against
"patient OR doctor" unless you have both creds and can verify that they each
recover the secret.  They might be lying about the "doctor" part, and really
sending against "patient OR nonexistant", in which case your response reveals
that you're a patient.  That's why we recommend that your response (if any)
include the policy for the creds you used in decryption.  So if Alice is
responding to a message she decrypted with her "patient" cred, which she only
(implicitly) discloses to Medicare, and the response itself is only for AIDS
clinics, she should encrypt against "Medicare AND AIDS_clinic".
(And you're right, the AIDS example is not very compelling.  The slides give a
better one about FBI agents, but I'm still looking for other examples of
super-sensitive transactions where HCs would fit)
That's very slick.  I'll check it out.
Hugo Krawczyk gave a great talk at Crypto about the going-first problem in
IPSec, which is where I got the phrase.  He has a nice compromise in letting
the user pick who goes first, but for some situations I think hidden
credentials really would hit the spot.
Yeah, although I think most of them would require an on-line trusted server.  But that just makes all sorts of things way too easy to be interesting. :)

@_date: 2004-05-10 22:37:15
@_author: Jason Holt 
@_subject: more hiddencredentials comments (Re: Brands' private 
Hash: SHA1
I don't quite get what you're suggesting.  Could you give a more concrete
example?  Well, I wouldn't complain. :)  (Although pairings are quite slow, on the order
of hundreds of milliseconds.)  Hilarie Orman presented it at an IETF meeting
to what was reportedly a lukewarm response, and they also raised the patent
issue.  Dan Boneh is sensitive to the issue of patented crypto, and was quite
considerate when I asked about it, but  still has the same
vague statement in their FAQ about how they're not going to be evil with the
patent, so it's still up in the air whether IBE will be useful in IETF

@_date: 2004-05-11 21:10:35
@_author: Jason Holt 
@_subject: who goes 1st problem 
[Adam and I are taking this discussion off-list to spare your inboxes, but
this message seemed particularly relevant.  Perhaps we'll come back later if
we come up with anything we think will be of general interest.]
Agreed.  Ninghui Li's RSA OSBEs might be the answer; they're not quite as
elegant as the IBE version, but they work with blinded RSA signatures, and so
should be patent-free by next year, assuming Ninghui doesn't seek any patents.  Section 4 of his PODC paper describes the RSA implementation.  He also has a
new paper which does neat things with commitments that I haven't wrapped my
mind around yet.
Actually, we might also consider contacting Dan Boneh at some point; he seems
to be interested in the proliferation of IBE, and might be sympathetic to the
needs of the IETF to have free standards, especially considering the exposure
it'd get for his system.
However, we need to define just what we need to accomplish.  Since my lab
works in trust negotiation, we think in terms of policies a lot, whereas SSL
just assumes you know what certs you want to send to whom.  But let's assume
the SSL model for simplicity.
The second issue, now that I think of it in this context, would be how you
actually get your certs to the other guy.  Hidden credentials, as Ninghui
pointed out, assume you have some means for creating the other guy's cert,
eg., a template "(nym):Senior_Agent:(current year)" producing
The OSBE paper, OTOH, assumes we're going to exchange our certificates, just
without the CA signatures.  Then I can send you messages you can only read if
you really do have a signature on that cert.  But I've always thought that was
problematic, since why would honest people bother to connect then use fake
certs?  The attacker doesn't need to see the signature - he believes you.  So
honest users would need to regularly give out fake certs so they can hide
their legit behavior among the fake connects.  Will Winsborough also suggests
this with the notion of ACK policies - you *always* give people something they
ask for, so they can't tell what you have and what you don't.
So maybe what we really want is some sort of fair exchange or something, where
I can show you my valid certs as you show me the valid certs of your own.  If one side is guessable, we've discussed this sort of thing with hidden
E("Hi Bob, since you're a senior agent, you can see my agent credential:
'Alice:Denver field office agent (apprentice):2004",
E("Hi Bob, since you're a BYU alumnus, you can see my BYU credential:
'Alice:Senior:computer science:3.96 gpa:2004",
So that's an open problem.  But let's assume guessable-certs, since that's the
only way I know how to really keep certs and policies safe for now. The
OSBE-RSA math still works.  So we're good so far, except that the RSA approach
is interactive.  Section 4 says that in the RSA scheme, Alice sends her cert
can send back an encrypted message.  (In HC and IBE-OSBEs, Bob doesn't need
the blinded signature to use as a public key).
But maybe Robert's improved secret sharing scheme from the new HC paper can give us some ideas:
1. Alice sends blinded signatures for each of her relevant certs, not
revealing which signature goes with each cert, and not revealing the cert
2. Bob generates the contents of each of Alice's certs relevant to his policy,
and simply generates each possible combination of hash-of-cert-contents and
blinded-signature.  One from each row will be a match-up between contents and
signature, and Alice will have to figure out which.  Unfortunately, this
requires n^2 multiplies and exponentiations.

@_date: 2004-09-20 20:14:14
@_author: Jason Holt 
@_subject: The internment taboo 
A related book on MAGIC and the Japanese internment is "MAGIC: The untold
story of U.S. Intelligence and the evacuation of Japanese residents from the
West Coast during WW II".  Website here:
Some of the folks involved in that project also set up this site, which has
scans of a lot of relevant primary sources:

@_date: 2005-02-04 19:35:59
@_author: Jason Holt 
@_subject: Dell to Add Security Chip to PCs 
Yes, Senator McCarthy, I do in fact feel safer knowing that mathematics
protects my data.  Welcome to cypherpunks.

@_date: 2005-05-02 21:19:02
@_author: Jason Holt 
@_subject: Secure erasing Info (fwd from richard@SCL.UTAH.EDU) 
There are lots of pitfalls in secure erasure, even without considering
physical media attacks.  Your filesystem may not overwrite data on the same
blocks used to write the data originally, for instance.  Plaintext may be left
in the journal and elsewhere.  Even filling up the disk may not do it, as some
filesystems keep blocks in reserve.  I did a demo a few years ago where I
wrote plaintext, overwrote, then dumped the filesystem blocks out and found
parts of the plaintext.
For anybody who hasn't read it, the Gutmann paper is "Secure Deletion of Data
from Magnetic and Solid-State Memory", and is highly recommended.  He shows
that even RAM isn't safe against physical media attacks.

@_date: 2005-11-07 00:12:50
@_author: Jason Holt 
@_subject: nym-0.5 released 
nym-0.5 is now available from:
Most notably, this release fixes a bug whereby the client code didn't check
that returned signatures are valid.  Thus, a token server could "tag"
clients by returning invalid signatures which the CA would then detect.
A preprint of an academic paper on nym is also now included in the
distribution as well.
Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-11-07 20:38:35
@_author: Jason Holt 
@_subject: gonzo cryptography; how would you improve existing 
References: Take a look at ecryptfs before rewriting cfs:
 					-J

@_date: 2005-11-19 10:13:41
@_author: Jason Holt 
@_subject: nym-0.5.1 released 
I just discovered that the javascript client was completely broken.
nym-0.5.1 fixes this:
Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-10-02 00:13:02
@_author: Jason Holt 
@_subject: nym-0.2 released (fwd) 
As the great Ulysses said,
  Pete, the personal rancor reflected in that remark I don't intend to
  dignify
  with comment. However, I would like to address your attitude of hopeless
  negativism.  Consider the lilies of the g*dd*mn field...or h*ll, look at
  Delmar here as your paradigm of hope!
  [Pause] Delmar: Yeah, look at me.
Okay, so maybe there's no personal rancor, but I do detect some hopeless
negativism.  Or perhaps it's unwarranted optimism that crypto-utopia will be
here any moment now, flowing with milk and honey, ecash, infrastructure and
multi show zero knowledge proofs.  Maybe I just need a disclaimer: "Warning:
this product favors simplicity over crypto-idealism; not for use in Utopia."
Did I mention that my code is Free and (AFAIK) unencumbered?
The reason I have separate token and cert servers is that I want to end up
with a client cert that can be used in unmodified browsers and servers.  The
certs don't have to have personal information in them, but with indirection
we cheaply get the ability to enfore some sort of structure on the certs.
Plus, I spent as much time as it took me to write *both releases of nym*
just trying to get ahold of the actual digest in an X.509 cert that needs to
be signed by the CA (in order to have the token server sign that instead of
a random token).  That would have eliminated the separate token/cert steps,
but required a really hideous issuing process and produced signatures whose
form the CA could have no control over.  (Clients could get signatures on
IOUs, delegated CA certs, whatever.)
(Side note to Steve Bellovin: having once again abandoned mortal combat with
X.509, I retract my comment about the system not being broken...)
Sure, there's no reason for one entity not to run all three services; we're
only talking about 2 CGI scripts and a web proxy anyway.  Or, run a CA which
serves multiple token servers, and issues certs with extensions specifying
what kinds of tokens were "spent" to obtain the cert.  Then web servers get
articulated limiting from a single CA's certs.
It buys not having to strap hacked-up code onto your web browser or server.
Run the perl scripts once to get the cert, then use it with any browser and
any server that knows about the CA.
Great, you guys work up an RFC, then an IETF draft, then some Idemix code
with all the ZK proofs.  In the meantime, I'll be setting up my 349 lines of
perl/shell code for whoever wants to use it.  Whoops, I forgot the
IP-rationing code; 373 lines.
Actually, if all you want is complaint-free certifications, that's easy to
put in the proxy; just make it serve up different identifiers each time and
keep a table of which IDs map to which client certs.  Makes it harder for
the wikipedia admins to see patterns of abuse, though.  They'd have to
report each incident and let the proxy admin decide when the threshold is
There's that hopeless negativism again.  Do you want a real solution or not?
Because I can think of at least 2 ways to solve that problem in a practical
setting, and that's assuming that your assumption about MediaWiki being
limited to 4-byte identifiers is even correct.
Sure.  I always meant for the gateway to exit on a public IP address.  The
reason to make it a hidden service is to keep n00bs from forgetting to turn
on tor when they talk to the proxy.  Thanks for clarifying, though.
Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-10-02 22:23:50
@_author: Jason Holt 
@_subject: nym-0.2 released (fwd) 
Hopeless negativism.  I limit by IP because that's what Wikipedia is already
doing.  Sure, hashcash would be easy to add, and I looked into it just last
night.  Of course, as several have observed, hashcash also leads to
whack-a-mole problems, and the abuser doesn't even have to be savvy enough
to change IPs.
Why aren't digital credential systems more widespread? As has been suggested
here and elsewhere at great length, it takes too much infrastructure. It's
too easy when writing a security paper to call swaths of CAs into existance
with the stroke of the pen.  To assume that any moment now, people will
start carrying around digital driver's licenses and social security cards
(issued in the researcher's pet format), which they'll be happy to show the
local library in exchange for a digital library card.
That's why I'm so optimistic about nym. A reasonable number of Tor users, a
technically inclined group of people on average, want to access a single
major site. That site isn't selling ICBMs; they mostly want people to have
access anyway. They have an imperfect rationing system based on IPs. The
resource is cheap, the policy is simple, and the user needs to conceal a
single attribute about herself. There's a simple mathematical solution that
yields certificates which are already supported by existing software. That,
my friend, is a problem we can solve.
I like the idea of requiring combinations of scarce resources. It's
definitely on the wishlist for future releases.  Captchas could be
integrated as well.
Thanks for pointing that out! Shouldn't be hard to fix.
Oh, I think I see. The k-smooth sha1(r) values then become "bonus" tokens,
so we use a large enough h() that the result is too hard to factor (or, I
suppose we could make the client present properly PKCS padded preimages).
I'll do some more reading, but I think that makes sense.  Thanks!
Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-10-07 07:57:11
@_author: Jason Holt 
@_subject: Wikipedia proposal 
I just posted this to wikitech-l:
There has been a lot of discussion lately on the or-talk list about
how to let tor and other anonymizing proxy users edit wikipedia without
allowing vandals free rein. Several straightforward approaches have been
proposed, such as holding edits in escrow pending approval by a trusted
user, and requiring anonymizing network users to login before posting.
The latter idea in particular could easily be abused, since abusers can
create a new account for each edit.
Roger Dingledine, tor's author, suggested creating a pseudonym service
using a cryptographic construction called blind signatures:
Basically, Alice can generate a token, mathematically blind it
(obscuring its value), have it signed, then unblind the signature.
Anyone can verify that the signature on the token is valid, but nobody,
including the signer, can link the blinded value Alice had signed with
her unblinded token.
I implemented such a scheme which works as follows:
* Alice creates and blinds a token, then submits it to a token server
for signing.  Optionally, the token server may have a list of IPs banned
from wikipedia, and refuse to sign Alice's token if her IP is on the list.
* The token server signs the blinded token, then records what IP address
Alice used so that she can't obtain multiple tokens per IP address.
Later, this will allow us to block Alice's IP address if she misbehaves,
just as Wikipedia admins currently do, except that now it'll work even
when she connects via tor.  Token rationing could also be done based
on other (more or less) scarce resources, including email addresses,
captchas, CPU-intensive tasks or even money, just as I'm sure has been
proposed for the vanilla wikipedia.  The advantage of blind signatures is
that tokens can be recorded and blocked without revealing the potentially
sensitive underlying resource (such as a personal email address or
IP address).
* Alice can now turn on tor and present her token to wp, without revealing
her actual IP address.  This token takes the place of the IP address
record currently stored along with article edits, and can be blacklisted
just the same way that IPs are banned.
* However, I implemented an intermediary step which has several
advantages.  Instead of presenting her token to wp, Alice generates an
essentially empty client certificate and presents it via the tor network
to a certificate authority (CA) for signing, along with the signed token.
The CA records that the token has been "spent" (preventing her from
receiving multiple certs per token), then signs her cert just as Verisign
would sign a server SSL certificate. Since she connects via tor, the CA
doesn't learn her real IP address.
* Alice installs the client certificate in her browser, then connects
to a special wp server running an SSL server that demands valid client
certificates from our CA.  That configuration takes only 4 lines in my
apache-ssl server's httpd.conf.  Apache automatically sets environment
variables which identify the client certificate, and which can be used
in place of the REMOTE_ADDR variable currently used to record users'
incoming IP addresses when marking page edits.  Blocking a client cert
would then be just as easy as blocking an IP address.
All of Alice's edits will be marked with that identifier unless she
obtains a new IP address (or other scarce resource) and repeats the
process to obtain another certificate.  Later, features can optionally
be added which will allow her to have separate identifiers for each edit
(protecting her in case, say, her repressive government confiscates her
computer in order to find out if she wrote a particular article they
disagree with).
I have already released code to implement this system, with the exception
of the wp-specific code. I sent the proposal to both the or-talk lists
and the cryptography list at metzdowd.com on Monday. Next I'd like your
comments, before I dive into the mediawiki code (or find someone willing
to help with this part).  Once the feature is complete, we can set up a
live test wiki for people to bang on, before we consider implementation
on the live wp servers.
                                              -J
Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-10-13 01:17:09
@_author: Jason Holt 
@_subject: nym-0.3 released 
Hacking MediaWiki to map client certificates to IP addresses turns out to be
quite trivial.  nym-0.3 includes the 17 line patch, as well as the security
fix proposed by cyphrpunk.  The live demo at erg.no-ip.org now includes a
live, patched MediaWiki called NymWiki.
If you want to be able to edit wikipedia through tor, I suggest you try out
the code and email me, so that we can make a case that there's actual demand
for inclusion of the patches.
Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-10-21 09:22:34
@_author: Jason Holt 
@_subject: nym-0.4 released (now includes Javascript) 
The most notable feature in this release of nym is that you can now use nym
entirely from your web browser:
Until someone figures out how to create client certificate requests in
Javascript, the CA will have to do so instead (or, you could generate the
request on a separate machine and paste it in with a trivial hack).  This
means the CA will know your certificate's private key; this is bad if you
want to make sure you can never be impersonated.  It's actually good if you
want deniability, since you can always claim that the CA chose to
impersonate you.
There are other miscellaneous bugfixes which break compatibility with
earlier versions.
Sources (including the javascript client) are available here, as always:
Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-10-22 10:20:40
@_author: Jason Holt 
@_subject: nym paper preprint 
I've finished a first draft of an academic paper on nym:
nym is a straightforward application of blind signatures to create a
pseudonymity system with extremely low barriers to adoption.  Clients use
an entirely browser-based application to pseudonymously obtain a blinded
token which can be anonymously exchanged for an ordinary TLS client
certificate.  In the appendix, we give the complete Javascript application
and the necessary patch to use client certificates in place of IP addresses
in the popular web application MediaWiki.
Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-09-29 01:49:26
@_author: Jason Holt 
@_subject: Pseudonymity for tor: nym-0.1 
Per the recent discussion regarding tor and wikipedia, I've hacked together
an implementation of the basic system from Chaum, Fiat and Naor's 1990
"Untraceable Electronic Cash" paper.  This system allows CAs to blindly
issue tokens (or "coins") which can then be "spent" elsewhere.  It runs in
perl, and comprises a CA, nym-maker, client application and auth checker
(for the server).
The tarball is here:
Of course, it's useless at the moment since it gives out tokens
indiscriminately (and probably has massive bugs), but if anyone actually
cares about this idea, it will be (more or less) easy to do the following:
* Put up a sample CA and server that people can use (potentially as hidden
* Make the CA issue only one token per email address, or one token per IP
address, one per computational puzzle, one for every $20 mailed in...
* Automatically expire CA keys and generate new ones on a regular basis
(rather than bothering with CRLs)
* Instead of randomly generated tokens, have the CA sign an actual X.509
cert request, which will then become a perfectly valid X.509 cert useful as
a client-side cert in unmodified browsers and web servers
* Create some sort of aid for maintaining server-side (or CA) blacklists of
improperly behaving users
* Check to see if the protocol is actually still secure and properly
Comments welcome.
Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-09-29 01:51:32
@_author: Jason Holt 
@_subject: Pseudonymity for tor: nym-0.1 (fwd) 
Per the recent discussion regarding tor and wikipedia, I've hacked together
an implementation of the basic system from Chaum, Fiat and Naor's 1990
"Untraceable Electronic Cash" paper.  This system allows CAs to blindly
issue tokens (or "coins") which can then be "spent" elsewhere.  It runs in
perl, and comprises a CA, nym-maker, client application and auth checker
(for the server).
The tarball is here:
Of course, it's useless at the moment since it gives out tokens
indiscriminately (and probably has massive bugs), but if anyone actually
cares about this idea, it will be (more or less) easy to do the following:
* Put up a sample CA and server that people can use (potentially as hidden
* Make the CA issue only one token per email address, or one token per IP
address, one per computational puzzle, one for every $20 mailed in...
* Automatically expire CA keys and generate new ones on a regular basis
(rather than bothering with CRLs)
* Instead of randomly generated tokens, have the CA sign an actual X.509
cert request, which will then become a perfectly valid X.509 cert useful as
a client-side cert in unmodified browsers and web servers
* Create some sort of aid for maintaining server-side (or CA) blacklists of
improperly behaving users
* Check to see if the protocol is actually still secure and properly
Comments welcome.

@_date: 2005-09-29 23:32:48
@_author: Jason Holt 
@_subject: Pseudonymity for tor: nym-0.1 (fwd) 
Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-10-01 02:18:43
@_author: Jason Holt 
@_subject: nym-0.2 released 
nym-0.2 is now available at:
My tor server is currently down, so I can't set up a public trial of this,
but perhaps someone else will.  This release makes the following
* Tokens are now issued one-per-IP to clients via a "token" CGI script.
Tokens are still blindly issued, so nobody (including the token issuer) can
associate tokens with IP addresses.  The list of already-served IPs could be
periodically removed, allowing users to obtain new pseudonyms on a regular
basis.  (Abusers will then need to be re-blocked assuming they re-misbehave).
* A token can be used to obtain a signature on a client certificate from a
separate "CA" CGI script (potentially on a different machine).  Tokens can
only be "spent" to obtain one cert.  Code to make a CA, client certs and
have the certs signed is included.
* The CA public key can be installed on a third web server (or proxy) to
require that users have a valid client certificate.  Servers can maintain a
blacklist of misbehaving client certs.  Misbehavers will then be unable to
access the server until they obtain a new token and client cert (via a new
My proposal for using this to enable tor users to play at Wikipedia is as
1. Install a token server on a public IP.  The token server can optionally
be provided Wikipedia's blocked-IP list and refuse to issue tokens to
offending IPs.  Tor users use their real IP to obtain a blinded token.
2. Install a CA as a hidden service.  Tor users use their unblinded tokens
to obtain a client certificate, which they install in their browser.
3. Install a wikipedia-gateway SSL web proxy (optionally also a hidden
service) which checks client certs and communicates a client identifier to
MediaWiki, which MediaWiki will use in place of the REMOTE_ADDR (client IP
address) for connections from the proxy.  When a user misbehaves, Wikipedia
admins block the client identifier just as they would have blocked an
offending IP address.
Eugen* Leitl leitl
ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]
