
@_date: 2011-11-30 11:51:17
@_author: Rich Kulawiec 
@_subject: Used your smartphone to log into your network? 
If so, this might be a good time to change passwords, and to review
what other information has transited your phone.
(Note: androidsecuritytest.com appears to be slashdotted at the moment.)
November 16: initial reports of Carrier IQ spyware surface:
all of which reference the research presented here:
November 22: Carrier IQ threatens security researcher Trevor Eckhart:
November 24:  Carrier IQ backs off its threats, says that it doesn't track Android users
November 29: Further research by Trevor Eckhart shows Carrier IQ spyware logs ALL keystrokes
all of which reference this research:

@_date: 2013-02-07 13:08:43
@_author: Rich Kulawiec 
@_subject: [liberationtech] Cryptography super-group creates unbreakable 
Alchemy is to chemistry, astrology is to astronomy, as closed-source
is to open source.
Closed-source is intellectual fraud.  It is the equivalent of an academic
paper which has a synopsis and conclusions -- but nothing else.  No honest
reviewer would ever approve such tripe for publication in a refereed
journal of mechanical engineering or physics or medicine...yet we, in
computer science, are expected to do the equivalent.  We're actually
expected to take someone's word that their code does what they say it
does -- even though we have a mountain of evidence stretching back to the
beginning of our field that says it's NEVER been true, even when the
code's written by people who are smart/experienced/honest/diligent/etc.
Not even Stephen Hawking gets his papers published without showing
his data/reasoning/work/etc.  As it should be.
So yes, my response to this is "source or GTFO".  Extraordinary claims
require extraordinary proof and in this case, there is none.
Unsubscribe, change to digest, or change password at:

@_date: 2013-02-07 13:18:23
@_author: Rich Kulawiec 
@_subject: [liberationtech] Chromebooks for Risky Situations? 
Strongly agreed.
As the size of the organization grows, the probability that zero employees
are (a) taking payoffs/bribes (b) succumbing to extortion/blackmail
and/or (c) otherwise political/socially/economically/personal motivated
to do Bad Things decreases.
We could debate the shape of the curve, but I think it's darn near certain
that there is -- somewhere -- a Google employee doing (a) and a Google
employee doing (b) and a Google employee doing (c).  Of course there are.
There are simply too many of them for this not to be true.  The same
can be said of every large company and organization.
The question is thus not "do they exist?" because I think we already
know that they do.  The question, or questions rather, become things
like "What is their goal?", "What do they have access to?", "What
measures exist to prevent them from accessing things they shouldn't?",
"What measures exist to detect them trying to access things they
shouldn't?", "Will I find out if it happens to be my data?", and so on.
My own experience suggests that the answers to those last questions
are nearly always "nothing", "not much" and "no" even in places where we
would all hope otherwise.
So if you (rhetorical and plural you) are becoming an annoyance to whatever
government you're antagonizing because you're smart and effective,
then why wouldn't they consider dropping $100K in cash on a cloud engineer
in return for a USB drive full of everything you've all stored there?
Seems like a good investment.  Much less tedious than infiltrating
your group.  Probably cheaper and less risky.
Or why wouldn't they plan ahead and start getting their own people in the
pipeline for jobs there?  They could play the long game and gamble that
spending years training some of their own, putting them through school
at RIT or Michigan or GaTech and getting them into Rackspace and Google
and Twitter will one day pay off, when someone very very loyal to their
ideology and politics feeds them timely information.
Yes, you can encrypt everything -- if you're all diligent about that.
But the logs will still show when and where you were, and possibly who
is talking to who, how much information they're exchanging, and when.
(And there's the possibility that, in extremis, your communications can
be "accidentally" cut off just when you need them most.)
My point is that I don't think trusting *any* large organization is a
good move.  If you're going to store this kind of data anywhere but on
systems that you personally control, then pick the smallest, most obscure
ones you can find.  Better yet: don't build an architecture that relies
on centralized communications and thus is vulnerable to centralized
compromises; we've discussed Usenet here before and I think that sort
of decentralized architecture is a much better model for this application.
Unsubscribe, change to digest, or change password at:

@_date: 2013-02-21 11:00:24
@_author: Rich Kulawiec 
@_subject: NYT covers China cyberthreat 
Would it hurt their business?  Really?
Well, if they're eBay, probably.  If they're Joe's Fill Dirt and
Croissants in Omaha, then probably not, because nobody, NOBODY in China
is ever actually going to purchase a truckload of dirt or a tasty
croissant from Joe.  So would it actually matter if they couldn't
get to Joe's web site or Joe's mail server or especially Joe's VPN server?
Probably not.
Nobody in Peru, Egypt, or Romania is likely to be buying from Joe
any time soon either.
This is why I've been using geoblocking at the network and host levels
for over a decade, and it works. But it does require that you make an
effort to study and understand your own traffic patterns as well as your
organizational requirements. [1]
I use it on a country-by-country basis (thank you ipdeny.com) and
on a service-by-service basis: a particular host might allow http
from anywhere, but ssh only from the country it's in.  I also
deny selected networks access to selected services, e.g., Amazon's
cloud doesn't get access to port 25 because of the non-stop spam
and Amazon's refusal to do anything about it.  Anything on the
Spamhaus DROP or EDROP lists (thank you Spamhaus) is not part
of my view of the Internet.  And so on.  Combined, all this
achieves lossless compression of abusive traffic.
This is not a security fix, per se; any services that are vulnerable
are still vulnerable.  But it does cut down on the attack surface as
measured along one axis, which in turn reduces the scope of some
problems and renders them more tractable to other approaches.
An even better approach, when appropriate, is to block everything
and then only enable access selectively.  This is a particularly
good idea when defending things like ssh.  Do you *really* need to
allow incoming ssh from the entire planet?  Or could "the US, Canada,
the UK and Germany" suffice?  If so, then why aren't you enforcing that?
Do you really think it's a good idea to give someone with a 15-million
member global botnet 3 or 5 or 10 brute-force attempts *per bot*
before fail2ban or similar kicks in?  I don't.  I think 0 attempts per
most bots is a much better idea.  Let 'em eat packet drops while they
try to figure out which subset of bots can even *reach* your ssh server.
Which brings me to the NYTimes, and the alleged hacking by the Chinese.
Why, given that the NYTimes apparently handed wads of cash over to
various consulting firms, did none of those firms get the NYTimes to
make a first-order attempt at solving this problem?  Why in the world
was anything in their corporate infrastructure accessible from the 2410
networks and 143,067,136 IP addresses in China?  Who signed off on THAT?
(Yes, yes, I *know* that the NYTimes has staff there, some permanently
and some transiently.  A one-off solution crafted for this use case
would suffice.  I've done it.  It's not hard.  And I doubt that
it would need to work for more than, what, a few dozen of the NYTimes'
7500 employees?  Clone and customize for Rio, Paris, Moscow, and
other locations.  This isn't hard either.  Oh, and lock it out of
everything that a field reporter/editor/photographer doesn't need,
e.g., there is absolutely no way someone coming in through one of
those should be able to reach the subscriber database.)
Two more notes: first, blocking inbound traffic is usually not enough.
Blocks should almost always be bidirectional. [2]  This is especially
important for things like the DROP/EDROP lists, because then spam
payloads, phishes, malware, etc. won't be able to phone home quite
so readily, and while your users will still be able to click on
links that lead to bad things...they won't get there.
Second, this may sound complex.  It's not.  I handle my needs with
make, rsync, a little shell, a little perl, and other similar tools,
but clearly you could do the same thing with any system configuration
management setup.  And with proper logging, it's not hard to discover
the mistakes and edge cases, to apply suitable fixes and temporary
point exceptions, and so on.
[1] 'Now, your typical IT executive, when I discuss this concept with
him or her, will stand up and say something like, "That sounds great,
but our enterprise network is really complicated. Knowing about all the
different apps that we rely on would be impossible! What you're saying
sounds reasonable until you think about it and realize how absurd it
is!" To which I respond, "How can you call yourself a 'Chief Technology
Officer' if you have no idea what your technology is doing?" A CTO isn't
going to know detail about every application on the network, but if you
haven't got a vague idea what's going on it's impossible to do capacity
planning, disaster planning, security planning, or virtually any of the
things in a CTO's charter.'  --- Marcus Ranum
[2] "We were so concerned with getting out that we never stopped to
consider what we might be letting in, until it was too late."
Let's see who recognizes that one. ;-)

@_date: 2013-02-22 05:29:40
@_author: Rich Kulawiec 
@_subject: [liberationtech] Fwd: [greg@pryzby.org: Ubuntu, Dash, 
I've thought about this for a couple of days and about 20 miles, and
although my initial reaction was "yes, they should", I'm now going to
reverse myself and say "well...maybe not".  Here's why.
I think the problem here is not susceptible to patching, because the
root cause isn't software: it's mindset.  The people who think that this
is actually a good idea -- and persist in thinking so despite cogent
(and in my opinion, highly persuasive) arguments to the contrary -- are
unlikely to shift course.  The course they've embarked on inevitably leads
to more of the same -- oh, with different technical details and levels of
impact, of course, but still: more of the same.  I am reminded of one
of my favorite quotes:
I don't think the situation is salvageable; I think the effort that could
be put into trying to do so is better spent elsewhere.
I think it's time to go.
Unsubscribe, change to digest, or change password at:

@_date: 2013-02-26 07:35:22
@_author: Rich Kulawiec 
@_subject: [liberationtech] Looking for collaborators for free-range 
It won't work.  Until the bot/zombie is solved, online voting is
a non-starter, since any election worthy of being stolen can be.
It doesn't matter what you do on the server side: you can construct as
elaborate and clever and secure an infrastructure as you wish...because
on the client side, there is no way to ensure that what the user sees
is what's actually happening.  (After all: it's not *their* computer
any more.  Its new owners can, if they wish, cause a vote for candidate
A to be sent as a vote for candidate B, and they can prevent the user
from knowing that's happened.)
And given that (a) we're now about a decade into the zombie problem
(b) no significant effort against them has ever been attempted,
let alone completed [1] and (c) the problem is already epidemic and
continues to get worse [2] [3], there is no reason whatsoever to think
it will be mitigated, let alone solved, in the forseeable future.
This doesn't just apply to your proposal: it applies to *all* of
them.  Unless you can propose and execute a viable plan for solving
the zombie problem, then whatever you design/build can be undercut
whenever someone chooses to make the effort.  (And provided they're
not foolishly heavy-handed about it, it's unlikely you would be able
to detect this. [4])
[1] Botnet "takedowns" are unimportant and irrelevant; their only
purpose is to provide a forum for the spokesliars at Microsoft et.al.
to trumpet their prowess while a gullible press and public overlook
that they *created* this problem.  Merely removing C&C networks does
nothing to remediate the individual members of the botnets, which are
still compromised, still vulnerable, and likely to be conscripted into
other botnets before the day is out.
[2] We're now seeing portable devices zombie'd: phones, tablets, etc.
[3] Estimates of zombie population vary, of course, but clearly, any
estimate under 100M should be laughed out of the room.  Vint Cerf gave
an estimate of 150M just about six years ago, and based on my own work
as well as that of others in the anti-spam/abuse area, I thought that
was on the high side at the time...but it's most certainly not now.
I think the number's probably in the 200-300M range at this point.
See:  for
Cerf's comments.
[4] See Schneier's insightful and chilling piece on this here:
That piece should be absolutely mandatory reading for anyone even
considering voting systems.  It not only provides a method for
estimating attacker budgets, but it correctly points out that attackers
quite often could tip the balance of an election by manipulating a
rather small number of votes -- with a corresponding reduction in the
probability that the manipulation will be detected.
Note that Schneier wrote that in 2004.  If you repeat his analysis
with numbers from the 2012 election cycle you'll end up with *much*
large attacker budgets.  For example, Schneier says that in 2002,
Congressional candidates raised over 500M.  But
says that in 2012, they spent about $1.82B.
Too many emails? Unsubscribe, change to digest, or change password by emailing moderator at companys at stanford.edu or changing your settings at

@_date: 2013-03-01 13:14:55
@_author: Rich Kulawiec 
@_subject: [liberationtech] Designing the best network infrastructure for 
I'm not sure what else you expected.  (Really, I'm not.)
You didn't explain what you're trying to do.  You showed up with
a list of middling-to-hideously-poor technology choices looking not
for design review or critiques, but vetting of your choices even
though you didn't provide any rationale for them. And yet you got some very sound advice, like "Don't use Windows".
You just don't happen to like it.  Okay, fine.  Then don't take it.
Do whatever you want: you don't need our individual or collective
approval.  (Although y'know...if I said "I'm gonna do X" here and
several people told me that was a bad idea, that would give
me serious reason to back off and reconsider at length.)
If you actually want serious advice, then take a serious approach:
explain *in detail* what you're trying to build.  Infrastructure?
Desktops?  Laptops?  Portables?  What are the functions you're
trying to provide?  What's your budget?  What are your personnel
resources?  What is the scale of deployment?  What's the scope?
What's the threat model look like?   And so on.
Too many emails? Unsubscribe, change to digest, or change password by emailing moderator at companys at stanford.edu or changing your settings at

@_date: 2013-03-15 12:22:49
@_author: Rich Kulawiec 
@_subject: [liberationtech] Here Come the Encryption Apps 
I'll give him a pass on rigor, as this is an informal article and not
intended to be a journal paper.  (Besides, I write in the same style
most of the time.)  But when he asks:
I think he completely misses the point.  I think a much more fundamental
question is: My answer to that is no.  In fact: HELL NO.  "Using a smartphone"
strikes me as one of the most dangerous things you could possibly
do in that situation.
Yes...I know that's not a happy statement and is likely to be unpopular
here, but let me see if I can manage to back it up.
First, if you have a government that is so awful that the only alternative
left is overthrowing it, then they control the telco.  Therefore everyone
walking around with a smartphone is providing them with a 24x7 feed of
geolocation data, to the resolution available. (And that can be selectively
improved in locations of interest.)
Second, everyone using a smartphone is providing them data for traffic
analysis.  Oh, sure, it might be encrypted, but if X sends a 27313 byte
message and shortly thereafter Y and Z get a 27313 byte message...
Third, everyone using a smartphone and transmitting/receiving IP traffic
is also providing them information about their intentions, Tor and VPNs
and HTTPS notwithstanding. ("Oh, look: every night, right after the
protests die down for the evening, X sends 300-400M of traffic out.
Gosh...I wonder what that is.")
Fourth, malware on phones is epidemic.  One might have a fighting
chance of stopping it if the phones are centrally managed and strictly
controlled (no downloading of apps, no "updates", only a few web sites
accessible, etc.) but few have the knowledge, resources and discpline
to do that.  Plus "centrally managed" is not exactly the best idea
in this context.  And of course any government faced with this threat
will probably write and release more malware.  Any government that
*thinks* they might be faced with this threat in the future could
plan ahead and embed the malware in the phones somewhere in the supply
chain prior to retail sales.
(I would.  If I were the dictator of Elbonia, I'd be embedding
malware in *every* shiny gadget because of course their closed-source
nature makes it easy for me to do so.  This would constitute an
inexpensive insurance policy -- actually, now that I think about it,
I could probably just pass the costs along to purchasers and thus get
them to fund my malware.  I'd label it as "a feature" or as some sort
of network performance/diagnostic tool.  *cough* CarrierIQ *cough*)
Fifth, it's pretty easy to shut down the cellular network.  Yes, this
might have political and economic consequences.  So?  It's still not a
good idea to use a communications medium that your adversary can turn
off at will.  (Let me note that it's not even necessary to shut it
down entirely: local/temporary disruptions suffice and are easier to
explain away.  As we've seen.)
Sixth, and let me encapsulate it as a principle:
That's harsh, condescending, snarky...but I think it's probably true.
Sorry: revolution is hard.  And if you're faced with an oppressive,
vicious, murderous government that's fighting for its existence,
I assure you that they will have people at *their* disposal who don't
need a GUI to do whatever horrible things they have in mind.
Too many emails? Unsubscribe, change to digest, or change password by emailing moderator at companys at stanford.edu or changing your settings at

@_date: 2013-03-22 18:50:37
@_author: Rich Kulawiec 
@_subject: [liberationtech] Privacy, data protection questions 
Ok.  Here's some advice.  You're not going to like it. ;-)  Sorry.
But better now than later, when lives are on the line.
I'd like to ask you to open a web browser and use your favorite
search engine to search for:
and similar.
Then I'd like you to explain how you propose to keep all those mobile
phones secure in the face of routine malware, let alone targeted and
custom malware crafted by hostile governments who would very much like
all those journalists and researchers and NGOs you mentioned to STFU
because they're saying and reporting and doing things those
governments find...disturbing.
Forget all the other security and privacy issues for a moment (some of
which I touched on in a previous list message [1]): how, EXACTLY, do you
propose to keep those phones from being infested just like a gazillion
other phones already are or will be real soon now?
Because once those endpoints are compromised, all the crafty routing and
anonymization and encryption layers you could possibly put in place aren't
going to matter very much.  And those endpoints WILL be compromised
(probably much sooner than you think) because they're going to be in the
hands of journalists and researchers and NGOs, *not* in the hands of
paranoid clueful paranoid diligent (did I mention paranoid?) geeks.
Oh, sure, someone sufficiently knowledgeable, cautious, etc.
can probably keep *one* phone secure.  Just like someone with those
qualities might be able to keep a single Windows system secure.  There are
people on this list who are capable of both of those things.  But dozens?
Hundreds?  Thousands?  Being carried around all over the place by
their owners?
There's not a chance in hell.  None.  This is not a solved problem in
computing.  Nor is there even a hint of a twitch of a notion of a
suggestion of a whisper that it will be solved anytime soon.
It's not even solved for people who've stacked the deck in their favor
(e.g., those who have the luxury of centralized control) let alone for
those who are allowing end users to connect their own.  And most of them
aren't painting big targets on their chests, they're just caught up in
the general crossfire...unlike *your* users, who are self-nominating to be
on the business end of some very serious attention from some very determined,
clueful and nasty people -- people who probably *already* have been
working on building or buying custom malware for phones because of course
that's what any prudent adversary with sufficient resources would be
doing just about now.
Yeah, okay, so I'm making the point at your expense, and I don't really
mean to do that, so I'll make it in the more general case: look, people,
unless you can produce a plan -- and more than that, a plan that's been
proven in the field to work -- for keeping, let's say, a population of, oh,
a thousand independent scattered phones free of malware, then you CAN'T
deploy your whizbang singing dancing smartphone app because it's going to
be promptly undermined.  Any government worthy of the term "oppressive"
is going to 0wn each and every phone of interest and is going to install
trackers, spyware, keystroke loggers, and whatever else occurs to them,
and you're not going to stop them.  At best, you might figure out that
this is happening after-the-fact and remediate some of them...until they
go back out in the field and get infested again.  Lather, rinse, repeat.
Not to put too fine a point on it (but I suppose I will anyway):
The phone may be in a journalist's hand or it may be in a researcher's
pocket, but it's not theirs.  *Not any more*.
Which means that your liberation app, the one that you designed and
developed and sweated over, the one that your user is trusting to
send and receive sensitive information, the one that's connecting
to a backend through umpteen layers of encryption and obfuscation
and misdirection and whatever...is now running on the government's phone.
[1] [2] I'm probably quoting somebody.  But I don't know who.
Too many emails? Unsubscribe, change to digest, or change password by emailing moderator at companys at stanford.edu or changing your settings at

@_date: 2013-03-26 19:12:41
@_author: Rich Kulawiec 
@_subject: [liberationtech] Privacy, data protection questions 
Clearly you have no idea how I write when I'm being "nonconstructive". ;-)
Think equal proportions Kingsfield[1], Vader, Snape.  Season to taste with
HST and Mencken, serve at full boil.
(a) There aren't enough hours in the day to provide extensive (security
or other) critiques of everything that comes across here.   And there
are other people whose expertise in certain areas dwarfs mine, so
until/unless I close the gap, I'll defer to them.  Also I think I should
occasionally STFU and listen.
So I respond on-list when I feel that I have something useful to say,
*usually* (but not always) when I think that has applicability beyond the
particular topic-of-the-moment.  Hence my comments in re Silent Circle,
which are far more about the inherent insecurity of closed source
software than about the specifics of Silent Circle itself -- most of
which I didn't pay any attention to because I think they're irrelevant.
And speaking of applicability beyond the topic-of-the-moment:
(b) If you read my message carefully you'll notice that I did in fact
explicitly point out that while I was using this particular project as
an example, it's by no means the only one facing the exact same issue.
"Building a secure smartphone app" is presently equivalent to "trying
to put the roof on a house whose foundation is sinking into quicksand
and whose main floor is on fire".
So what "constructive" thing could I possibly say?  The entire smartphone
ecosystem is rotten to the core: the OS vendors care far more about
advertising than privacy and security [2].  Well, and they care a lot
about paying attorneys so that they can all sue each other. [3]  The app
markets are loaded with malware, spyware, adware, and crap.  And more
crap.  Also: still more crap.  Users will download and run any shiny thing
they see, doubly so if it purports to enhance their "social experience" --
much to the delight of the scammers and spammers running those operations.
Telcos are happy to turn user tracking/surveillance/etc. into profit
centers.  Governments want every scrap of data they can get from carriers
and there's now an entire subindustry for software that extracts data
from locked phones.
D'ya think if I asked them very nicely and politely they'd all stop?
There is NOTHING "constructive" to be done here.  It's not a fixable
situation at the moment or for the forseeable future.  The *only* thing
to do, as far as I can tell, is to stop pretending it's otherwise and
stop laboring under the delusion that smartphone apps have a chance in
hell of being secure in mass deployment scenarios.
(c) So to re-emphasize the more general point: no smartphone apps,
UNLESS you can produce a viable, workable, scalable, defensible plan
to keep the phones secure in the field.  Otherwise your app, whatever
it does, and however nifty it is, is probably going to be undercut from
the moment it's installed...or very soon thereafter, as soon as one or
two governments your users are annoying decide to deploy countermeasures.
(I think it's fair to say that, to a first approximation, the tempo
and scale of their response will be proportional to the adoption
rate and annoyance level.  Thus: the better your app and the more people
that use it, the sooner you should expect the backlash.)
And they don't *have* to crack your app if they 0wn the phones it runs on.
(I sure wouldn't.  Too much work.  Very tedious.  Better to just hijack the
phone, install a keystroke logger et.al., and compromise *all* the apps.)
(d) I don't think you [generic you] can come up with that plan (above)
and execute it.  I think you have no shot whatsoever.  But if you want
to take a crack at proving me wrong: be my guest.  I will be very surprised
but happy if you succeed.  I may even buy you beers.  Good beers.
(e) I *know* this is real unhappy news.  Sorry.  I didn't write the
cruddy smartphone software.  I didn't write the malware.  I didn't create
the situation.  I'm just pointing it out.  And yes, I know it would be
much nicer to just go on creating app after app and rolling them out
and pretending this problem doesn't exist, but ermmm...I think far more
unpleasant things than mere words on a screen will happen if lots of
people start betting their freedom and/or their lives on the security of
their smartphones/apps.
(f) And on that point ("pretending"), let me share with you one of the most
valuable pieces of guidance that I've ever read.  I have it printed out
and taped above where I'm working right now.  I think for many of the
projects and initiatives discussed here, it's terrific advice.  So even
if you think my analysis here isn't worth a load of fetid dingo's kidneys,
well, at least there's this:
(g) So do you wanna spend your time trying to convince me to change my
writing style (hint: success probability == low) OR would you like to
focus on the substance of my remarks -- because *if* I'm right, then
Bad Things are going to ensue as soon as various governments figure out
that exploiting smartphones is a cheap, effective and scalable tactic for
undermining communication among their opponents.  Morever, they will be
Bad Things that are (largely) independent of the cleverness of apps and
their supporting infrastructure, i.e. they're not going to be fixable
by the developers.  Which means years of work and piles of money spent
developing OverthrowYourDictator v1.2 will be rendered moot and, worse,
people running it may well face unhappy fates.
This may have already happened.
[1] I suspect some of you who are younger may not get the reference.
Therefore, let me introduce you to Professor Kingsfield:
[2] For example:
[3] Mike Masnick has a brilliant illustration of this:
Too many emails? Unsubscribe, change to digest, or change password by emailing moderator at companys at stanford.edu or changing your settings at

@_date: 2013-03-27 06:14:38
@_author: Rich Kulawiec 
@_subject: [liberationtech] Privacy, data protection questions 
You're misreading exasperation and frustration as anger, and you're
still focused on style rather than substance.  If you think I'm wrong
(and of course I might be) then make the case.  Show me how someone
can keep (let's say) a 1000-phone population in the field secure when
there's an adversary actively trying to make them otherwise.
Too many emails? Unsubscribe, change to digest, or change password by emailing moderator at companys at stanford.edu or changing your settings at

@_date: 2013-03-30 10:04:49
@_author: Rich Kulawiec 
@_subject: [liberationtech] skype 
[snip thorough and IMHO, on-point analysis]
You make an excellent (series of) points.  And I have to concede that
you're right.
So let me refocus my comments on the efforts made (here and elsewhere)
to get Microsoft to cough up answers: can't everyone see that these
responses have been carefully wordsmithed within an inch of their lives
in what is an obvious and deliberate attempt to say as little as possible
and omit as much as possible?
Microsoft, like many corporations, employs professional spokesliars who
are very, very good at crafting wording that can be defended (should it
come to that) but which doesn't present the truth in a straightforward
fashion.  That's their JOB.  After all: anyone there could tell the truth
