
@_date: 1996-04-04 15:22:32
@_author: Jim McCoy 
@_subject: Canada's ISO standards body? 
At 11:50 AM 4/3/96, Peter Trei is rumored to have typed:
ftp://hesiod.communities.com/pub/mccoy/ansi-x9.ps   I also have a PDF version
of the draft as ansi-x9.pdf, and the certificate DAM in the file certdam.ps.

@_date: 1996-04-04 18:26:48
@_author: Jim McCoy 
@_subject: Navajo code-talkers 
At 11:22 AM 4/3/96, Paul_Koning is rumored to have typed:
Linear B is Minoan, and knowing Greek helps in understanding what things
decipher to, but it predates the Greek alphabet by several centuries so
even if you knew Homer personally you would have had trouble reading it.
ObCrypto:  Unlike Egyptian hieroglyphics, we have yet to find a Rosetta
Stone equivalent for Linear B (or Linear A, it's predecessor, although I
seem to remember Linear A being more akin to ideograms)  Most of what is
known about Linear B was inferred using a sort of linguistic cryptanalysis,
in fact there was a paper in one of the Crypto proceedings from the mid-80s
which described some of the methods employed.
ObMoreDeadLanguages: Does anyone know if there are Unicode character sets
for Sanskrit or hieroglyphics?  How exactly does one get a proposed
character set approved/ratified if not?

@_date: 1996-04-05 17:43:35
@_author: Jim McCoy 
@_subject: Why pay??? 
At 3:44 PM 4/4/96, kreidl at newrock.com is rumored to have typed:
Because then useless noise (such as the message you posted) would
automagically get filtered out.  Some people do not have the time
to filter the noise from signal on mailing lists and this service
caters to their needs.

@_date: 1996-04-12 02:32:04
@_author: Jim McCoy 
@_subject: No matter where you go, there they are. 
At 8:53 AM 4/10/96, Hal is rumored to have typed:
There is going to be processing and network delay involved here (unless
Denning et al have figured out some way to communicate faster than the
speed of light), so drift between the what you report and what the checking
station and repeaters are hearing _at that time_ is inevitable.  This is the
loophole which allows  Peter's attack, a loophole which cannot be closed
(because the spoofer can always claim to be on a slower link than she
really is and there is nothing the verifiyer can do to prove otherwise.)
If I want to pretend to be closer to the receiver than my true location I
simulate a slow link which gives me enough time to record what the signals
would be at the near location and then quickly resend them to give the
appearance of the spoofed location.
In fact, I think that this really all boils down to trying to use GPS
as a non-interactive proof of location, and the information posted about
the system does not address the obvious attacks on such systems which
are known from research into ZNPs.
The authenticated repeaters may collect all signals, _but the receiving
station does not get them all at once_ because it will take time for
the signals to propogate from the repeater back to the station attempting
to determine location. Having all of the signals does not help the
checking station other than allowing it to share a set of sats with
the person attempting to authenticate.  It still does not
And perhaps more importantly, do you really want anyone you connect to
on the net to know your location to the nearest 10 meters?  What is
Dennings fascination with building Big Brother?

@_date: 1996-04-25 16:50:02
@_author: Jim McCoy 
@_subject: Golden Key Campaign 
[...why do people continue to promote the RSA method?...]
And there are other equally good algorithms which can also do the job.
A pretty insignificant base actually (at least compared to the internet
as a whole) and supposedly PGP 3.0 will support multiple encryption
methods so maybe the RSA reliance can die the ignoble death it deserves.
One point left out from the original posting is that a Rabin exchange
can use a RSA public key provided that the p and q in the public key are
Blum integers (which also lets you use the public key for probabalistic
PKE, as well as a few other neat tricks), so changing PGP to support
Rabin would not be much of an inconvenience...
Yes, and the most well-defined point is that until September in
the year 2000 you will pay an arm and both legs to use RSA.
A point in favor of non-RSA public-key methods.
You must be joking.  Have you ever tried to deal with RSA lawyers?
True, but Cylink needs to milk their patents for all they are worth for the
remaining 481 days they have left. In a little more than one year they will
not be left with much more than a footnote in the crypto history books.
Best known perhaps, but ElGamal and Rabin have also been studied in depth
(in fact, Rabin is provably as secure as factoring, RSA has not been
proven this secure, it is only assumed that it is.) Most public key methods
fall back to only a handful of real trap-doors, so there is only a limited
amount of vetting to be done (esp. when compared to symmetric encryption
Nope, it starts on August 19, 1997.  After that point it becomes possible
to deploy systems using secure public-key crypto worldwide without needing
to pay someone royalties... :)

@_date: 1996-04-28 12:41:48
@_author: Jim McCoy 
@_subject: The Joy of Java 
This is not as far away as you might think.  Trust me... :)
Wow, three incorrect assumption in a single sentence, another hat-trick for
Perry.  Speed of execution is not a major problem given JIT compiler and
interpreter improvements; this has been broadcast far and wide on the net
so your presumed ignorance of this is a bit hard to believe.  Additionally,
if you are buying cycles off the net you can set things up to run in
parallel and accomplish more than you ever could without the ability. To
farm out code.  This is absolutely trivial when it comes to tasks which
are inherently easy to break into chunks which can be run in this fashion
(like rendering and ray-tracing, etc.)  As far as safety goes there are a
lot of people working on this problem and for tasks of this type it is not
as difficult as you assume.  As far as it being insufficiently powerful for
running distributed computation and cycle serving I know know for a fact
that this is not the case.
Rather than trying (and often failing) to prove that unsolvable problems
exist in Java why don't you present the net with an alternative that does
not suffer from these limitations.

@_date: 1996-08-07 15:03:15
@_author: Jim McCoy 
@_subject: appropriate algorithm for application 
You can get the basic functionality you require by using a regular hybrid
PKE system (pubkey encrypts symmetric session key) and encrypting the
session key with the public key of a "master key" as well.  For example,
assuming a user A and a master key C you just have the program A uses to
encrypt files operate in a manner similar to that used by PGP and other
public-key encryption systems [pubkeyA(sessionkey),IDEA(sessionkey,data)]
except in addition to the pubkeyA(sessionkey) which encrypts the random
key used to encrypt the actual data you add a masterpubkeyC(sessionkey)
section to the beginning of the file as well.  The resulting data packet
is [pubkeyA(sessionkey),masterpubkeyC(sessionkey),IDEA(sessionkey, data)]
This system is as secure as the public-key system used for encryption and
would actually be fairly easy to hack in to PGP, although the modified PGP
messages which contain the master key information would not be usable by
regular PGP.

@_date: 1996-08-08 09:03:43
@_author: Jim McCoy 
@_subject: Wee Beasties on Mars [NOISE] 
Using the same methods that geologists use to determine whether or not
certain meteorites are from the moon, by chemical composition.  Material from
within the solar system actually has varied composition mainly determined by
the distance of the body from the Sun (there are various theories as to why
this is, an intro cosmology book will describe them all in detail), the
actual percentages of various elements and compounds can be used to make a
reasonable guess as to whether or not a particular meteorite was knocked off
of a planet or moon to which we have sent a probe.  For example, it is
possible to buy fragments of "moon rocks" which are not actually samples
returned from Apollo missions (which are all owned by the U.S. government)
but are from meteorites which match the exact chemical and physical
composition of the returned lunar samples.  Such determinations are a lot
easier for planets/moons which do not have active vulcanism or other events
which significantly mix up the composition of the planet.
At the news conference given this afternoon the fact that the meteorite was
Martian in origin was probably the least controversial.  It seems that
exobiology may no longer be a field without a subject :)  If the results are
confirmed what I think will end up being the most interesting fallout of this
will be in the creationism/evolution debate.  It seems that life may have
been independantly generated at multiple locations, barring a "space seed"
debate flaring up again, and the "impossible odds" argument has become pretty

@_date: 1996-08-12 20:28:23
@_author: Jim McCoy 
@_subject: US Power Outages 
Because the system designed to fail non-destructively rather than risk
a power surge.  Part of the problem is that the power being controlled
moves as fast as any information about the state of the network: all
decisions must be made locally at the switch level.  When a major line
fails the power generation stations can not just "turn off the juice" at
the speed required, the power must either be redistributed or else the
switch overloads and shuts down to prevent a massive power spike.  The
power companies would rather face the ire of consumers without power for
an evening than the outcry that would happen if every toaster, microwave,
and computer on the west coast was fried by the spike caused by 3 gigawatts
being dumped into grids that could not handle the load (not to mention the
long-term blackouts caused by local switching equipment getting fried.)
In this case the system must fail to prevent damage.
The great east coast blackout was caused by a $50 switch which wore out.
The switch happened to control a chunk of load which was re-routed on to
another line, causing a cascade failure as the excess load caused other
switches to fail when it was dumped on to those lines (and the excess
load caused by these other switches tripping accellerated the failure.)
Power distribution is not like telecom, if a phone switch dies the calls
end; the failure does not endanger the upstream switch with overload
from bits not going anywhere.
Imagine that cars on highways had no brakes until they reached an offramp
but the DOT could apply a kill-switch to segments between offramps (tying
this thread into another non-crypto thread on the list :),if a failure in
the roadway caused traffic to stop then all of the upstream traffic would
have to be dumped off the road via offramps that were only one or two lanes.
This would cause further bottlenecks and the kill-switch would need to be
applied to more and more segments upstream to prevent the traffic stopped
or being slowly bled off from causing more problems.  No imagine that
offramp-to-offramp messages were transmitted via messengers travelling
upstream in the carpool lane :)
Even the power company's secret experiments in the cores of nuclear reactors
have not found a way to get around the 186,000 km/s speed limit on everything.

@_date: 1996-08-14 10:03:51
@_author: Jim McCoy 
@_subject: [NOISE] Re: photographed license plates 
One problem with using such systems in the US (I have no idea about traffic
laws in Ontario so maybe this was the loophole you mentioned) is that even
with a perfect shot of the license plate the system only identifies a car,
not a driver.  Speeding tickets are given to drivers, not necessarily to
the owner of the speeding car.  Here in the states the easy challenge to
such a ticket would be "it was not me driving when that photo was taken" and
the burden of proof is on the prosecution to prove that you were the driver.
Since some states do not require front license plates the cameras take shots
of the tail end of the car, not the best angle for identifying drivers.

@_date: 1996-08-16 17:44:30
@_author: Jim McCoy 
@_subject: BlackNet as a Distributed, Untraceable, Robust Data Haven 
BlackNet also lacks any sense of persistence.  A message posted lives at
the whim of newsgroup expiration policies and getting a copy of an expired
message is a non-trivial task.  It is also not an overt data haven, there
is really no address or pointer you can direct someone to and say "look
here."  Usenet as a data haven is like dropping messages in to bottles
and casting them in to the sea; getting it where you want and having the
intended recipient be able to find the data easily is still an unsolved
problem.  It is a bulletin board for establishing private two-party
communications on any topic, but it is not even close to being a mechanism
for "publishing" in the manner to which people have becomed accostomed to on
the net.

@_date: 1996-08-18 18:25:39
@_author: Jim McCoy 
@_subject: Ad Hoc Bay Area Cypherpunks Thing--Sat., 24 Aug, 3 pm, Menlo Park 
[Typing from the courtyard outside Cafe Barone (love that Ricochet...)]
For those needing better directions, Cafe Barone/Keplers is at the Menlo Park
Center, at the corner of El Camino and Ravenswood in Menlo Park...

@_date: 1996-08-19 17:36:38
@_author: Jim McCoy 
@_subject: Why BlackNet *IS* a Data Haven 
I would be willing to concede the point if you would take a few seconds
to examine the issue of complete lack of persistence in BlackNet.
Your descriptions of BlackNet as a data haven seem to be completely
based upon the presumption that an anonymous contact service and contract
exchange is the functional equivalent to a data haven.  Here are a few
reasons why I would disagree:
As a publisher of "naughty bits" I do not have the ability to just toss
data up and assume that it will be there when someone wants it.  I am forced
to continuously monitor the appropriate newsgroups to find messages from
people asking me to post the blueprints to the orbital mind control lasers
or kiddie porn.  I cannot put my data onto "the Net" with an expectation
that any arbitrary user will be able to get the bits one month later.  To
maintain persistence I need to constantly repost my data, making it easier
for authorities to trace me through simple taffic analysis if nothing else.
No one has really claimed place is important, in fact the ideal data haven
has no physical existence whatsoever.  This is a given.  As a practical
matter it is a lot easier if you start off in a "place" because there are
fewer complications but this has never been a necessity.
Now you reveal the objection I had to BlackNet being a data haven.  What if
only one person has a copy of this banned material?  It may not be in this
publishers interest to have the data available to anyone for posting in
response to the query ("Information does not want to be free, it wants to
be expensive and liberated...") and some data is not widespread enough or of
interest to enough people to assume that multiple copies exist to those who
read BlackNet postings. Therefore the only way for a publisher to maintain
availability of their data is to constantly monitor the appropriate newsgroups
and republish for each request, persistence is maintained only through
eternal vigilence (much like liberty, only requiring a lot more effort :)
No, it is an anonymous contact service.  To claim this is a data haven is
like claiming that the classified ads in a newspaper are the equivalent to
a mall; you could probably find the same goods if you looked long enough, but
there is a reason that manufacturers sell goods through stores rather than
just posting classified ads across the country.  When one does not have the
time to check the classified ads, wants to goods from a reputable source, and
wants the goods in a timely fashion they will go to a shopping center.

@_date: 1996-08-20 17:27:29
@_author: Jim McCoy 
@_subject: [NOISE] Re: Indonesia detains democracy activist after post to mailing list (fwd) 
For those who are curious, Indonesia is an interesting test case among the
Pacific Rim counties because the current iron-fisted ruler is beginning to
get a bit long in the tooth and no one has any idea what it going to happen
when he finally croaks.  Indonesia has had almost no political opposition
since a rather violent anti-Communist crackdown/coup in the 60s.  All media
access was rigorously controlled and the possibilities the Internet and
similar computer networking technologies offer (ObCryptoAnarchy ref...) are
just now becoming apparent to those who are in charge.  How this plays out
will have interesting reprecussions in other such countries where politicial
discourse is a new phenomenon and where the Internet is just now being seen
as a threat to the current order.
jim, former exchange student to Indonesia who hopes the transition is less
bloddy than Indonesia's last change of government...

@_date: 1996-08-21 17:43:26
@_author: Jim McCoy 
@_subject: Edited Edupage, 18 Aug 1996 
You want to avoid moving parts like the plague in orbit.  They eventually
wear out or fail and once that happens you have a very expensive piece of
junk in orbit.  Solid-state storage is the _only_ way to go if you want to
avoid things like neding to pressurize the drive (eliminating any cost
advantage over solid-state.)  Its not like you can go up to swap a dead drive
out you know...
The big problem with orbiting datahavens is the cost.  Access requires going
to a commercial launching agency (approx $100K cost to put a smallsat in
LEO.)  The smallsat itself is relatively cheap at $25K.  Then multiply that
by 30 because with LEO (you will not get a GEO slot, ever) you will need a
swarm of sats to provide constant coverage; the orbit the sats are in means
that they are only overhead for minutes at a time.  When you add all of this
up it begins to make the idea of buying an old tanker or fish processing boat
pretty cost effective.
The big problem is that no one has data that is worth protecting enough to
make such a venture pay off.

@_date: 1996-08-21 18:07:04
@_author: Jim McCoy 
@_subject: PreRFD: comp.org.cypherpunks 
Suggestion 1 on how to diminish the feeble S/N ratio on cypherpunks:
        make it a newsgroup
Suggestion 2:
        make it an unmoderated newsgroup
I can think of nothing that would cause the remaining clue to flee faster
than a CP newsgroup in wide distribution (if it were gatewayed to the list)

@_date: 1996-08-23 09:04:33
@_author: Jim McCoy 
@_subject: Spamming 
Actually I believe that without "junk mail" costs for regular postage would
probably be higher: less mail = fewer packages over which to amortize the
cost of building the infrastructure necessary for ubiquitous messaging.
Direct-mail organizations get a lower rate by doing a lot of the expensive
parts of post office work themselves (pre-sorting the mail by zip code,
barcoding messages, etc) and not necessrily just based upon volume.  For all
the bitching Americans do about the high cost of first-class mail it is still
the least expensive of any western  nation and offers fairly good service
(and the USPS actually made a profit for the last two years so it is unlikely
that the cost will go up for a while...)

@_date: 1996-12-16 14:52:17
@_author: Jim McCoy 
@_subject: Securing ActiveX. 
The other problem is that the proposed Authenticode system and other "signed
applet" systems only provide accountability after the fact.  This is little
help when your hard drive is toast and the only proof you had was a logfile
which was the first thing erased...  The illusion that only "trusted software
puslishers" will be given blanket authorization is a pipe dream: users are
sheep who will hit that "OK" dialog box as many times as necessary to get the
tasty treat they are anticipating (and there is actual experimental evidence
to back this up :)  I expect that the first post-Authenticode ActiveX virus
will be one to modify the signature checking routines or add additional keys
to the registry which makes the second round of the attack appear to be a
valid OS update from Microsoft. What exactly does a signature get you other
than someone to point a finger at?  In case you don't read those legal weasel
words in software licenses there is no claim made that the product will work
as intended and the company does warn you that if the product fries your
disk then it is not their fault...
The state of the art was up to it quite a while ago.  Check out KeyKOS and
other OSes which use capability semantics for access control.  Rather than
the all or nothing approach to security which is currently built into Java
and continued with the code signing initiatives (albeit allowing you to
delegate responsibility regarding trust) what is needed is to extend the
signatures to granting the capability to perform a certain task and nothing
more.  If the signature could express things like "this ActiveX control
needs access to a writable file in C:\WINDOWS\TEMP which will not exceed
1 Megabyte in size" then the system would be flexible enough to succeed
and would allow users to express much more complex trust relationships than
the simple boolean expressions which current code signing mechanisms allow.

@_date: 1996-02-04 16:14:23
@_author: Jim McCoy 
@_subject: Imminent Death of Usenet Predicted 
Close, but not quite.  The role that the InterNIC serves is to register and to maintain the top-level mappings.  It is from InterNIC that the root-level nameservers load info regarding which domains are served by which The way this process works from any particular users point of view is as
1) You request that the host name  be resolved to an IP 2) Your TCP/IP software checks its local cache (if any) to see if it    has the requested information and if so it returns it without doing a
   lookup [there are timeouts and other bits involved but this is the simple version]
3) If a lookup is necessary your TCP/IP software digs up a pre-defined    for who is should ask.  This is the info that you enter into a resolv.conf file
   in unix, a MacTCP DNS setting, etc.  It is usually the nameserver for    internet service provider or a local nameserver for your network.  Once the
   resolver knows who to ask it formats a query and sends it off.
4) This nameserver checks its cache to see if it already has the info and if not
   it forwards the request to another nameserver.  Eventually the request    a root server; the root servers then check the domain name against their tables
   (the ones it loaded up from the NIC) and forward the request to the    nameserver.
5) Eventually the request is forwarded to a nameserver which is able to give an
   authortative answer for this domain and the result is sent back to the    requester.
At any point in this chain it is possible for someone to decide who will give the
authoratative answer for this domain.  It is possible for you, the requester, to
decide for yourself who will be asked.  All you need to do is to add nameserver you trust early into the query chain and that server will be asked first
and only if it does not answer authoratatively will the regular nameservers be
asked to resolve the request.
The DNS system represents to oldest digital reputation system I know ot.  It is _all_ about trust; if you think that someone is giving out bogus information or you want
your answers to come from someone else it is trivial to change the way your nameservice
is configured so that lookups happen in the manner that you want.  No one can control
how names are resolved into numbers unless someone else grants them that power.  There
was a minor rebellion among the internet service providers this fall when the NIC
announced that they would begin charging for their services and it flares up every now
and then when some of the larger independant ISPs begin to feel that the NIC is favoring
the major players like MCI, Sprint, et al. when it comes to address and routing blocks
and other name/IP number issues.  The point that is frequently raised to keep the NIC
in line is that there is nothing preventing these providers from going out and doing
whatever they want, whether it be establishing new root servers, allocating whatever
numbers they want, or just plain ignoring that the NIC exists.  And there would be
absolutely nothing that InterNIC could do about it, because that is how DNS works. The
biggest problems that would occur would be when there was a conflict in the namespaces
served (e.g. your lookup for  returns one number when a InterNIC served
root nameserver responds and another when a different set of root nameservers respond)
and the number that would be returned would depend entirely on which nameservers your
query asked to get the answer.  In short, it would depend on who you decided to trust...
On a more cypherpunk-related note, it is actually quite trivial for you to create your
own shadow domains which are completely private to whatever group you want.  If you
want to create the foo.cypherpunk domain you can do it just by downloading the BIND
nameserver code and settting up a nameserver which answers queries for the top-level
.cypherpunk domain.  All that is required for someone else to resolve names in this
set of domains is for them to know that a .cypherpunk address needs to be by the nameserver you created (which involves adding only a single line in every DNS config system that I know of.)  It is also difficult for any authority to mandate that certain nameservers be used because the entire system is already so distributed as to make such a mandate useless (it would also cause such a performance hit for net connections that it would be about as effective as the old 55mph federal speed limits :)
Jim McCoy
mccoy at communities.com

@_date: 1996-02-17 05:23:35
@_author: Jim McCoy 
@_subject: AT&T Public Policy Research -- hiring for cypherpunks 
But IPv6 also brings link-level encryption and makes subliminal
communications channels trivial; Big Brother (now does anyone know
what that that translates to in Chinese?) won't stand for that...
The enhancements of IPv6 make a lot more possiblities for
secure channels and untracable packet-level communications
available.  Instead of needing to jump through many hoops
you just have to subvert one of the new goodies IPv6 gives
you for free :)

@_date: 1996-07-09 11:10:45
@_author: Jim McCoy 
@_subject: Pseudo-DC-net Project 
Short version:
Your proposal will not work and is trivial for a TLA to break.
Long version:
There are two problems with this proposal, the star topology collapses the DC
network into a two-party version of the DC-net protocol (in which collusion
is trivial) and the shared PRNG allows _any_ participant to compromise a
target member of the network (or evesdrop at the server and decode all
A simple example of such an attack would be for the TLA to register a host on
the network and get the shared secret key for the PRNG.  The TLA then taps in
either to the server's internet connection or any point in the network which
divides the client graph into two parts, the server and a single client on
one side and the remaining clients on the other.  The TLA then just XORs out
the blinding data (which it knows because it is a member of the network) and
it has all of the connections.  Additionally, having a MAC is just plain
silly, the objective is to hide who is sending and having a MAC defeats the
entire purpose of the proposal.
You have basically created a simple packet anonymizer, which is not bad in
and of itself, but it is not even close to a true DC-net (at least I am
assuming so, based upon the initial description.) You have not mentioned
whether or not all traffic exits the network at the server, if this is the
case you are better off having each client establish a secure link to the
server, running a PRNG constantly that is mirrored by the server, and XORing
all of their traffic in to this stream.  The constant PRNG stream hides when
the client is sending or receiving and the secure channel to the server
discourages passive evesdropping. This does not defeat traffic analysis at
the server, but then again neither does your proposal.
Some other tips from someonw who has spent too much time thinking about
DC-net implementations:
        Ignore collision detection, just use ALOHA or a similar protocol.
        Until you get up to serious bandwidth the computational cost is
        not worth the effort.
        Don't abandon the ring topology (this is where the DC-net gets its
        security.)  Use multiple small (4-7 host) rings with overlap between
        the rings, think of each ring as a LAN and hosts which are on
        multiple rings as bridges/routers and you should get the picture...
        Bandwidth economy will always suck, you can use hash trees to get
        around a few of the problems but for the most part you have to accept
        the costs and work around them in other areas.
        You really, really need to read the 1987 Eurocrypt proceedings.

@_date: 1996-07-19 14:38:33
@_author: Jim McCoy 
@_subject: #E-CASH: PRODUCT OR SERVICE? 
[regarding the "Ecash" trademark...]
Digicash's ecash lacks various properties of real cash from the users point
of view (offline transferability, large scale acceptance, etc.) and a great
many from the issuers perspective (too many to list...), but we still seem to
want to call it electronic cash when it isn't.  It may be "Ecash" but it sure
ain't digital cash...

@_date: 1996-07-29 18:34:34
@_author: Jim McCoy 
@_subject: BOMB PLANS 
Sandy write:
This is no longer true with respect to hand grenades and was not really
accurate wrt the old pineapple grenades.  Modern grenades are pre-scored
to produce good fragments, in fact one reason for abandoning the old
grenades was that they fragmented into only a few large chunks along
the weakest stress lines of the pineapple gripping and this did not
produce the desired effect (which is lots of little high-KE pieces, four
or five big pieces with relatively low-KE were produced by the pineapple
grenades...)  An equivalent effect for a pipe bomb would be produced by
mixing in a handful of brads, wire cut into 5mm lengths, or tacks, most
"recipes" for such devices I have seen tell someone to mix in nails.  This
is really stupid if you consider that most people only have relatively big
nails sitting around and coupled with the volume restriction of a pipe
bomb you will get the same poor effects as the old hand grenades.

@_date: 1996-07-31 20:07:25
@_author: Jim McCoy 
@_subject: FPGAs and Heat (Re: Paranoid Musings) 
Oddly enough, I just left a talk at the '96 Genetic Programming conference on
developing adaptable hardware and silicon evolution.  One of the speakers at
this particular session was the Product Line Manager from Xilinx and one of
the goodies he handed out was pre-release data sheets for the new XC6200
series of FPGAs they are producing (the chips are already out in limited
quantities) so here is a little update on the state of the art in this area.
One can also use reversible logic to get arond the heat problem if mechanical
means are not enough.  This is a necessity for molecular-scale computing and
during the post-session BS at another talk we speced out a system that could
probably evolve a reversible logic compiler.  Heat will not be a "wall" at
any scale, it may add to the cost a little bit but the problem is solvable.
The interconnection problem has also been solved in this chip series. [A
long-standing problem with FPGAs is that there were generally a limited
amount of "wires" running between the logic elements and thus a lot of cells
were wasted because there were no interconnections left, I/O to the outside
world was also a problem.]  The chip has a really cool interconnection method
which allows a much more efficient use of the chip real estate and which
makes the entire chip directly addresable (like regular RAM) through an
on-chip interface module.  Given the relatively compact design in Ian and
Dave's paper and the new chips one might even fit two or four cracking
engines on a single FPGA.
Either the NSA did not do thier homework in this area or they are lying.
There are two types of FPGAs, one is based on anti-fuse technology which is
essentially a big complicated PROM, but the Xilinx FPGAs use SRAM to
configure the interconnections between logic elements.  The newest line from
Xilinx, the XC6000 series has the capability to be reconfigured either
partially or completely from an on-chip cache in 5 ns.  That is five
nanoseconds and you have a completely different piece of virtual hardware. If
the configuration is loaded through the slowest I/O port on the chip it only
takes 200 microseconds. Even if the encryption algorithm is secret these
chips open up interesting posiblities for developing general-purpose
cryptanalysis machines. [Hmm, there may be a paper in there... "Evolving A
General-Purpose Cryptanalysis Engine"...]  What is even better from the
perspective of the NSA accountants is that they only need to build the
machine _once_, after that they just load up a new set of interconnections
and now the DES cracker is an IDEA cracker.  Add to this the fact that the
XC6000 series were designed to be built cheaply in large quantities (the
Xilinx rep figures the price will get down to $29/chip in 5K lots for the
samples he was passing around and he is a wafer guy and not marketting droid
so this may be reasonably accurate.)  If anything, the Blaze, et many als.
paper _underestimated_ the cost of a FPGA hardware cracking engine,
particularly if you amortize the savings FPGAs give over the long term with
thier almost limitless flexibility.

@_date: 1996-06-05 16:01:08
@_author: Jim McCoy 
@_subject: FOR WHOM THE BELL TOLLS 
Hmmm... time to fix my Jim Bell filter, this message seemed to have
gotten around it.
Yes, I am sure Jim does.  Expect a few Treasury agents to visit
him in the near future regarding threats against the president,
they seem to be a little overzealous about this statute...
(a felony I believe...)
A movement is not complete until it has a few nuts who claim
you are not going far enough, only then does it have a chance
of being incorporated into the mainstream.  I would suggest
just ignoring him, and once he is arrested claim he was a plant
by the IRS :)

@_date: 1996-06-05 16:23:25
@_author: Jim McCoy 
@_subject: cycle market 
Tasks which are inherently parallel (preferably ones where the
various processes are loosly coupled and the need for inter-task
communication is low) are the first things that come to mind,
because advances in the speed of CPUs does not give you the same
advancement increment in solving these problems.  Some examples:
        -rendering and ray tracing
        -simulation
        -analysis of large datasets
        -genetic algorithms and genetic programming (something I am
         working on creating a "cycle market" for in my spare time)
The other class of tasks which could use such a market are those which
are limited more by bandwidth than by processor speed.  If the server can
be given many "heads" which can provide the service (with the back-end
processing done by cycle markets) then it is possible to make significant
gains in distributing the I/O load and getting around network latency by
creating server which is "virtually omnipresent."

@_date: 1996-06-06 16:36:23
@_author: Jim McCoy 
@_subject: How can you protect a remailer's keys? 
This is little better than leaving it around in a plaintext file, a pass
or two with gdb on your binary and I have your private key.
The "difficult, expensive, and pain in the ass code to write" solution that
I favor is to use secure multiparty computation to create the remailer.  It
does not exist on a single host, but is rather the sum of a collection of
hosts running on widely seperated machines.  It has the same type of drawback
as a per-execution password entered into a long-lived process (anyone with
root access to the host can yank it out of memory with little difficulty,)
but this is spread out across a larger collection of hosts, making the task
of actually getting the complete password somewhat difficult.  Getting a
subset of the individual host passwords does not provide any partial
information about the collective password (similar to secret sharing.)
The other drawback is that certain operations can be very slow, you end
up emulating a circuit with a _very_ slow clock (8-10 Hz.  Not MHz, not KHz,
but 8-10 ticks/second); as compensation you get a word-size that if
effectively infinite. I have to continue work on a subset of these methods
for a secure digital poker/card-playing system over the next couple of months
and if I have some spare time I might see just how difficult creating a
toolkit for building such virtual circuits really is...
OTOH, a secure PCMCIA or smart-card will probably end up being a better
practical solution.

@_date: 1996-06-06 19:45:43
@_author: Jim McCoy 
@_subject: FOR WHOM THE BELL TOLLS 
As long as that person is not the President of the United States (at least
for U.S. citizens.)  This was the issue which initiated this thread, the
implied threat made by our favorite nutcase.

@_date: 1996-06-11 15:47:22
@_author: Jim McCoy 
@_subject: Report from Germany on "backdoor" net-censorship 
Ulf forwards:
Did anyone else hear "Deutchland Uber Alles" in the back of their mind
while reading this?  I wonder if the gestapo.de domain name is taken
It is kinda sad that these German ISPs who claim that politicians and
governments do not understand the nature of the net seem themselves
guilty of not understand that all internet traffic is effectively
anonymous, Usenet is just obviously anonymous.
"Papieren bitte..."  Yellow stars, pink triangles, hmmm... seems to me
that the Germans have a rather poor history regarding registration and
identity services, but they are once again proving to be good at
encouraging "collaborators."

@_date: 1996-06-12 16:48:22
@_author: Jim McCoy 
@_subject: Micropayments are Crap 
Well, at the risk of being branded a heretic, maybe the mainframe days were
not as bad as you assume...  Back in "the mainframe days" computers cost
hundreds of thousands of dollars, and the best way to most efficiently use
that resource was to tiemsharing.  Currently I would guess that 2/3 of the
possible CPU cycles in the world go unused, wasted by machines that are
turned off sitting in someones den or running a screensaver in the cubicle of
some drone in the marketting department.  With micropayments one can purchase
access to these cycles and put them to use, allowing the user to recover
costs when they are not using their system and giving the user cheap access
when needed to computing resources way beyond what they would be capable of
purchasing themselves.
Some advantages to the user:
        -Faster and more frequent upgrades and bug fixes.  No need to
         wait for the CD or floppies to be shipped.
        -Better responsiveness from the vendor/distributor.  Currently once
         you buy a program you are stuck with it, warts and all.  A "test
         drive" is not an option, so vendors are led by their marketting
         droids.  With online "rental" the user has the ability to try a
         program before plunking down their $69.95 and possibly ending up
         with an unusable collection of annoying bugs.  This also means
         that they have the option of selecting a different program without
         risking paying the entire cost of a program they do not really want
         but which had good advertising.  Software vendors will be forced to
         actually pay attention to the users _after_ the initial sale and will
         also be motivated to create and provide more customized niche programs
         so you end up with a better selection of software as well.
        -Access to programs which the user could not normally afford or would
         not use enough to justify the purchase price.  I am not a chip
         designer and am not interested enough to drop $20K on a VHDL simulator
         and design synthesis program, but I would be willing to pay several
         dollars an hour to play around with one.
Then buy the program yourself, and then wait overnight for that ray tracing
and rendering program to complete two frames of that animated logo for your
kewl web page.  No one is saying that everything wll go to micropayments, in
some cases for software which is used constantly it does make more sense to
buy the program outright but in most cases you end up using the other programs
which clutter your hard disk a lot less than you think.  By renting your
non-essential programs you save money.
How did you make the leap from micropayments (remember that "micro" prefix)
to paying someone a lot of money to run your job.  With micropayments you
can pay a lot of people a very small amount of money to run your job and
get it done orders of magnitude faster than someone stuck with a lone PC.
You also avoid getting caught up in the hardware game.  Just a few years
ago everyone was told they needed to upgrade their 386SX to a 486 or 486DX2
or they would be left behind, now everyone simple must have a Pentium, and
tomorrow it will be the next chip du jour.  By only requiring the hardware
necessary for user interaction on the desktop one can get better economies of
scale (hence the so-called "Network Computer")  If you could get by with
having a 486 on your desk running the presentation and interface level and
then rented cycles on a huge cluster of pentium cycle servers to get real work
done you would probably end up saving money in the long run, and would not need
to run out to Fry's every year/month/week to upgrade your hardware with new
pieces which would soon be obsolete.

@_date: 1996-06-13 10:52:59
@_author: Jim McCoy 
@_subject: Anonymous remailers mentioned in CDA decision 
Raph quotes a few bits of the CDA decision:
It about jobs, that's it...  Let's keep America a major power
in the pornography industry (I can just imagine the commercial :)

@_date: 1996-06-18 19:27:55
@_author: Jim McCoy 
@_subject: [Noise] Re: Java 
Self also give a new meaning to phrase "code bloat."  A 'Hello, world!'
that requires more than a megabyte kind of kills any enthusiasm one might
or a language which otherwise takes a neat slant message passing...
[Although I gave up before version 4.0 so maybe things have gotten better]

@_date: 1996-06-21 11:36:34
@_author: Jim McCoy 
@_subject: Oil Change software snoops through hard drive 
[...auto updating software...]
[...intersting questions which are raised by such a service...]
I saw no mention of authentication between the Oil Change client and server,
so the first question that I had was "how do you know if you are actually
connecting to the legitimate Oil Change server?"
Since the updates are via dialup a few bridge clips in the right location
would be all it takes to have the call re-routed to someone else's server
(and if the update is done over the net hijacking the system is not much
harder...) Once you have people getting your server instead of the Oil
Change server you _own_ their machine.  You can install whatever trojan
horses or backdoors you want under the guise of an update or direct the
user to pull a hacked update from a server you designate (and it wouldly
not be hard to set up a dummy software package so that even if you later
lose your override of the system or remove it to cover your tracks the
system continues to keep your backdoors installed.)  This is some very bad
A little social engineering or midnight wiring and there will be a lot of
people in a world of pain. Nothing like designing a system which takes your
weak spot and makes it a security problem for every one of your customers...

@_date: 1996-06-27 09:54:11
@_author: Jim McCoy 
@_subject: Alternic.net (was domain zapping) 
[...regarding alternte registries...]
For 99.99999% of the Internet "real DNS" is defined by the root server list
distributed with the most recent version of BIND.
Sorry, but this only gives you domain name resolution for the .nic TLD, not
the other new top-level domains they want to create or any domains that
alternic is proposing to provide service for.  To do that one needs to add an
appropriate line into the root.cache file (or whatever the root server list
is in your name server setup), at which point you are also trusting alternic
with pointing you properly to any domain they get queried on.
It is not just about habit, it is also about trust.  There are alternatives,
but they need to be thought-out much more than this alternic stuff...

@_date: 1996-03-07 10:12:06
@_author: Jim McCoy 
@_subject: Jump Start ecash With IPhone 
Two problems:
        1- Chaum did not have the clue to pick up on this when two
           cypherpunks (who shall remain nameless...) pitched this
           and several other ideas to involve ISPs in jump-starting
           ecash almost two years ago, so why would he figure it out
           now?
        2- The phone companies (actually ACTA, the telco lobby) petitioned
           the FCC on Monday to regulate the Internet phone software
           companies.
IP phone systems themselves may need to move underground just to
escape regulation.  OTOH, there is nothing to prevent people from
building their own systems once some free software is out there...
On another related note the IRS is not getting someone what concerned
about the opportunities the Internet offers people to avoid taxes
according to the Treasury department's international-tax counsel. The
government will "maintain toll booths on the information superhighway."
(WSJ, 3/6/96)

@_date: 1996-03-07 16:06:57
@_author: Jim McCoy 
@_subject: (Fwd) Gov't run anon servers 
You are correct in stating that having a huge key on a remailer is
as silly as putting a $500 lock on a door made of balsa wood.  OTOH,
the key selected is vulnerable from attacks which you cannot protect
yourself against.  No amount of detailed security analysis for a host
is going to prevent someone else from factoring the keys, and there is
nothing that can be done to prevent this from happening.  To prevent
this is seesm reasonable to select a key which is at least somewhat
outside the range of most attackers, 510 bits seems to be pushing the
lower bounds of this range a bit (while more than 1024 is probably
useless overkill.)  With fairly decent logging and auditing at least
you know that you have been screwed when it comes to standard system
break-ins, you do not know that you have a problem when your key is
Well, most of the announcements in the past year have been attacks
through subsystems which a remailer should not be running in the
first place (e.g. the recent chargen/daytime/etc attacks.)  The fact
that the announcements come out in the first place is a "good thing"
because it makes you aware of the problem.  The timid will then think
that the system which is the subject of the announcement is insecure
and place their trust in a system which is not under the same sort of
public scrutiny (e.g. Windows NT, or a VM/CMS system) but which is
even easier to hack.  At least people are aware of security issues on
Unix hosts... (a quick walk through a Computer Literacy bookstore
last night turned up twelve books on Unix/internet-server security
and none dealing specifically with Windoze95 or NT security, does
that mean that my NT test box is perfectly secure? :)
Otherwise, I agree that assuming you have a secure remailer just
because you use a big key is a foolish attitude.

@_date: 1996-03-07 18:00:26
@_author: Jim McCoy 
@_subject: Jump Start ecash With IPhone 
The regulation in question was regarding things like local/state/federal
telecom taxes and levies, and all of the BS hoops that LD carriers must
jump through.  Regarding where such companies are located, I am also at
a loss as to how this recent action will be enforced; that does not
necessarily mean that a bureaucrat somewhere will not try to do something
Just because LD is "deregulated" does not mean that it is without any
governmental oversight, much as I wish it were...  LD companies still
have to pay certain taxes (take a look at your next phone bill, they are
clearly listed in addition to your actual phone charges) and I am certain
that they have entire office buildings stuffed with drones filling out
paperwork for Uncle Sam...

@_date: 1996-03-08 06:18:22
@_author: Jim McCoy 
@_subject: (Fwd) Gov't run anon servers 
[...regarding mixmaster remailer passwords...]
Then you need to start running PC unix systems which were last written
or updated during this decade.  Keeping a unix system running, _as long
as it is running a limited subset of application programs_, is a trivial
task in Linux, BSD/OS, FreeBSD, and others.  I routinely have server
systems which perform specific tasks (e.g. smtp mail services, DNS, etc.)
with uptimes of 5-6 months; there is no reason why a host serving as a
remailer should not be able to be as reliable.
"Security is economics"  -E. Hughes
The point is not to make a system which is absolutely, positively, no
doubt about it, secure against any attacker.  If cypherpunks could do
this they would be working for defense contractors and others who make
certified systems.  The objective is to make a system which is difficult
to attack, one which costs the attacker time/money.  After securing
a host against the obvious attacks one can turn to the esoteric ones
such as you present: move the key to kernel memory and remove tools
for accessing or manipulating that area, run the memory-space encrypted
and do not let it dump the contents to disk, etc.  Systems which
have been certified to high Orange book levels already exist, so there
are obviously solutions to the problems you present.  The tools and
tricks of these systems just need to be migrated into systems which
people actually use.
Then remember that remailers gain strength in numbers.  The more
remailers you chain your message through the better your chances of
passing through a single node which is not compromised, at which
point your message has been "mixed."  As long as it is easier for
someone to create new remailers than to break existing remailers
we are winning.
"Insisting on perfect security is for people who do not have the
balls to live in the real world"  -paraphrased from M. Shaefer
You give far too much credit to the potential attackers.  One advantage
that unix systems connected to the net have over your hypothetical
PC at home is the advantage of persistence, what is the point of
running a remailer if it is never up, or only up when you need to use
it?  Traffic analysis of that particular node becomes a pretty easy
task :)  The unix hosts running remailers also have the advantage in
that they have been subjected to attack for quite a while now and
most of the obvious problems (and some of the non-obvious problems)
have been fixed.
A strong key on such a host is better than a weak key, so why not
make systems as strong as you can?  The only way to have a completely
secure computer is to encase it in concrete, cut any network connections,
and drop it into the ocean; OTOH the only thing you have created in this
case is a fairly unique boat anchor.  You are beginning to sound like
the people who claim that the NSA can crack any encryption system, not
because they have any proof but just because they extrapolate their
limited knowledge into the unknown and mix in a bit of paranoia.
But the point is that it is _not_ easier to steal the keys.  It is
much easier to put up a remailer than to attack an existing remailer,
this is why the remailer system is winning the battle of security
economics.  By putting up its own remailers a potential attacker
probabalistically diminishes the number of systems which they must

@_date: 1996-03-08 16:27:46
@_author: Jim McCoy 
@_subject: TCP/IP Stego (was CU-SeeMe) 
I think that the original poster meant twiddling some of the (relatively)
unused fields of the header which most routers and applications do not
care about, the type-of-service field or priority would good place to
start.  This would have no effect on the data in the packet, particularly
if you fiddle at the IP level instead of TCP.  While it is a low
bandwidth comm channel, it has a couple of advantages which you seem to
        -It can be applied by two routers which are in the middle
         of the connection.  The two endpoints of the TCP/IP
         connection would not even notice.  For example, if I control
         a router "upstream" of a major connection point and the
         site I wish to communicate with is in a similar position
         then I can run the subliminal channel in a "spread spectrum"
         mode across many connections and the packets can get reset
         to their original settings by the other site. The user
         whose stream we fiddled with does not even know that they
         were used as carrier wave...
        -While the per-packet information rate is low, such a system
         has a _lot_ of packets to work with and a much larger choice
         of endpoints.  Your hypothetical .WAV file may pack more
         information in, but there are a miniscule amount of such files
         moving on the Internet; just by transmitting such a file you
         could be suspect (honestly, how many soundfiles do you think
         you could ship around before people get suspicious...)  By
         hiding the information in the lower layers of TCP/IP you also
         make it less likely to be noticed; unless someone hooks up a
         packet sniffer and filters at the IP level the stream will
         go unnoticed, while a soundfile is an application-level
         communication and much easier to watch.  It is, in effect,
         hiding the channel in the low-order bits of the comm channel
         used to transmit your soundfile...
        -An application encoding method (pictures,soundfiles, etc.)
         also needs a "reason" for being sent.  You can legitimately
         send packets for no reason whatsoever, at least from the users
         perspective (e.g. DNS lookups, ICMP messages, faked fragments,
         etc.)  A packet system also has a constant stream of traffic to
         play with; you could run TCP/IP _on top of such a system_!
         Passing soundfiles and images back and forth would not work
         for interactive communication, it is UUCP at best.

@_date: 1996-03-09 06:53:36
@_author: Jim McCoy 
@_subject: TCP/IP Stego (was CU-SeeMe) 
I know that, I was just pointing out advantages you overlooked.  I guess
that the fact that I probably know more ISP operators and techs then
non-geeks who use the net made this part more obvious to me.  The original
technique of doing stego on packets is still valid, and by adding it in
to a WinSock lib or linux tcp/ip implementation the user can send hidden
messages just by connecting to a friendly stego-enhanced web server out
on the net and doing some casual browsing.
The difference between the two methods is, as I said before, exactly
the same as the difference between TCP/IP and UUCP.  Hiding info in
images or sound files works fine for "email" or file storage but has
no chance of being an interactive protocol, sometimes you need to
get things done in real-time.
But your relatives are not the people who you need to communicate secrets
with securely.  These gross stego hacks to sound and image files are best
used to make postings to various binary Usenet newsgroups.  Broadcast the
message and then put it in a place where many people will download it
but only a few will know that it contains the hidden info.  Sending this
stuff via email is just begging for traffic analysis at the very least...
Provided the bits are random in the way that they should be... The low-order
bits in such files were chosen by implementors of stego programs because
modification would not be noticed by the person viewing or listening to
the file, not necessarily because there was actually randomness at this
level which could be replaced.  Does anyone know of a survey of images or
sound files which tested the statistical randomness of these bits?  They
may not be as random as people think they are.

@_date: 1996-03-09 21:42:23
@_author: Jim McCoy 
@_subject: Signature 2 
Derek is correct in that your use of the words "uncrackable" and
"immune to fraud" were a bit over the top (in recent years everyone
in the security and crypto community has become very nervous whenever
anyone says things like this; they are usually trying to sell you
something which is neither.)  OTOH, he might want to temper his
statement with a reference to fail-stop signatures...  Just because
someone with a lot of computational resources can produce a private
key which matches your public key does not necessarily mean that
they are the same ones that you generated, only that they found a
set which work for the particular modulus which was chosen...
In the "real world" there is nothing to prevent someone from forging
your real signature on a check or document or from disguising themselves
as you and taking your place at an important business meeting.  The
digital equivalents can be slightly more secure, but nothing is ever

@_date: 1996-03-14 13:49:16
@_author: Jim McCoy 
@_subject: LACC: PC Phones Home? 
A few questions:
1- How does the PC know where it is?
2- How does the PC know it has been stolen?
Since this is a software product I am assuming that the answer to is the use of CallerID on the line when the software calls, which is
defeated by the use of line blocking by the thief.  The obvious answer
to  seems to me to have the system call the CompuTrace office at
odd intervals to see if it has been reported stolen yet...
Obvious solution for potential thieves: wipe the disks and reinstall
an OS once you steal a PC.  This should be done anyway to remove any
bits of data which might identify the original owner.
Conclusion:  Yet another useless piece of software riding the
computer security bandwagon.

@_date: 1996-03-20 12:51:26
@_author: Jim McCoy 
@_subject: If you can't take the heat...  (Was Re: Keep the pressure!) 
At 12:05 PM 3/20/96, Perry E. Metzger is rumored to have typed:
What amuses me most about this series of rantings by whomever, other
than the paranoid and baseless claims made by the anonymous poster,
is the number of people who have been complaining about the author doing
so anonymously through a remailer.  The irony of such a situation is
too rich to pass up.
It seems that cypherpunks can dish it out when other newsgroups and
mailing lists suffer such problems ("well, the remailers do nothing
that telneting to port 25 cannot do..." or "internet identity is such
a fiction anyway, get used to it"  seem to be common responses), but
when the cypherpunks lists is the victim of unpleasant anonymous messages
we fall back to the tired refrain of "if you have nothing to hide why
are you posting anonymously."  How sad.
So, why the hypocrisy here?  If you don't want to be bothered by these
messages there is a simple solution, use a mail agent that can filter
out remailer postings and trash them.  Of course this would also kill
interesting messages from others who use remailers, but that's the price
we pay for having remailers that do not support anonymous identity upon
which reputation can be built.
Oh yeah, I forgot...cypherpunks write code (snicker).  So why not stop
bitching and write a bit of code that provides for useful anonymous
reputations and/or fix the glaringly obvious problems with current
jim, who is sorry that he is not the one posting such trolls to the list
just to make the puppets dance...

@_date: 1996-03-31 15:01:25
@_author: Jim McCoy 
@_subject: Why Americans feel no compulsion to learn foreign languages 
At 9:35 AM 3/30/96, Dr. Dimitri Vulis is rumored to have typed:
Well, I believe that Tim's original point was that Americans have little
to gain in practical terms from learning foreign languages, while others
are forced by necessity to learn English (and possibly other languages.)
So far no one has provided any convincing counter-argument to this point.
As an American who has learned a great many languages just for the sake of
knowing them I can assure you that this knowledge has turned out to have no
practical benefit to me in my daily life.  I can converse in French, German,
Italian, Indonesian/Malay, and can "get around" in Tamil, Dutch, Russian, and
Arabic. I can read Latin, Greek, Sanskrit, and Egyptian hieroglyphics (okay,
so I was on a dead languages kick in college, sue me...) and know enough in
eight or nine other languages to travel anywhere in the world and be secure
in the knowledge that I could order dinner, read a train schedule, and find
shelter.  Big deal.  This knowledge is still of no practical benefit to me;
it does not help me do my job any better, it does not make my life
significantly better than Americans who are not polyglots, and in the past
year the only time I have had occasion to really use my linguistic abilities
was when I was able to deliver a particularly nasty reminder that some
Americans do speak more than just English to a pair of obnoxious French
ladies in the Los Altos Starbuck's coffee shop who seemed to think that if
natives cannot understand you then you have permission to make rude comments
about them loudly and in public...  For this ability I spent eight years in
class learning when to use the past subjunctive form of etre?!?
BTW, those who learn as little as they can get away with may not fit into your
ivory tower definition of true knowledge, but they are doing the important
thing: "getting away with it."  Every time I hear someone whine about
knowledge for its own sake I get the fealing they are just jealous because
they wasted time learning more knowledge than was necessary for the task
at hand... :)

@_date: 1996-05-04 15:15:31
@_author: Jim McCoy 
@_subject: PGP API & PGP 3.0 
Yeah...  I was thinking a few months ago that it would be fun to set up
an idea-futures claim regarding which would appear in a usable fashion
first (if ever): PGP 3.0 and it's library or the GNU Hurd...

@_date: 1996-05-15 16:19:49
@_author: Jim McCoy 
@_subject: Rural Datafication (Was Re: Edited Edupage, 9 May 1996) 
Well, this sort of subsidization is in the grand tradition of the Rural
Electrification Act of the new deal era and it seems to have worked out
pretty well.  The point being that we, as a social group, benefit when
everyone has access to certain pieces of the general infrastructure:
if everyone has electricity then appliance manufacturers can sell to
everyone, etc.  This is particularly true when it comes to services like
electricity, phones, etc. where it is much easier to wire up the cities
than areas with a lower population density.
BTW, while there may have been a decent argument against the electrification
act, I think that you are paddling upstream when it comes to net connections.
The value of your net connection (or any connection to the net) _increases_
according to the number of people who are connected to the network.  Unlike
all of the other rural subsidies you pay for as an urban dweller (with the
possible exception of the phone subsidy), this is one which has direct benefit
to you.
Oh yeah, and you are already subsidizing their phone bill (at least the
increased cost of running a line out to them and maintaining that line), and
their electricity bill, and satellite TV took care of any need to run cable
TV lines out there or else you would also be subsidizing their cable TV by
now.  So what was your point?

@_date: 1996-05-16 13:19:33
@_author: Jim McCoy 
@_subject: [NOISE] Re: Edited Edupage, 9 May 1996 
[... regarding the unfortunate poor who Mr. Avon hates...]
Yes he is.  They are poor and it is all their fault.
[flame-bait approaching...]
There are two kinds of libertarians, those who hate the poor and those who
don't.  I always seem to meet the former, I am beginning to suspect the
latter don't exist.
Yes, he is.  It is times like this that I must count myself among the
pitchfork and torch wielding mob, if only because I have been cursed
with a small amount of compassion for those who were not as lucky as I.
BTW Mr. Avon, the reason we, the unruly mob of collectivists, socialists, and
[insert libertarian/anarchist buzzword here] should stick a gun in your
back and make you cough up money for education is because we can.  If you
don't want to do so, they why don't _you_ move?  Are your feet cast in
concrete blocks?
Welcome to the real world.

@_date: 1996-05-16 17:45:42
@_author: Jim McCoy 
@_subject: [NOISE] Re: Edited Edupage, 9 May 1996 
Hmmm... this is getting fun.  Now I have something to take out my
frustration at 3Com shipping me a broken 100baseTX hub...
I guess that farm subsidies, school lunches and the infamous "government
cheese" are all figments of our imagination...
Are you aware of the fact that it is next to impossible to disconnect
gas/electricity for poor customers during the winter in these areas?
Have you ever wondered why the services rep asks you questions regarding
your income when you sign up for phone or electrical/gas services?
Gee, I seem to remember when the only phone system of any consequence
in the US was the Bell System.  A heavily regulated monopoly with the
government overseeing almost all aspects of the services offered.
Can FedEx send a 1 oz. letter to anywhere in the world for 32 cents?  A
classic example of cherry-picking among private companies.
A private physician who must adhere to governement standards and who could
not practice medicine without the permission of the government?  [okay, you
sort of have a point on this one but you were really shooting blanks on
the other issues.]
Yes, but you should give better examples.  This is not an issue which is
easily argued using the "sound bites" you are trying to give us.

@_date: 1996-05-18 21:31:31
@_author: Jim McCoy 
@_subject: found nym-differentiation! Still need perpetual motion, FTL travel, cold fusion 
This is what secure bit-commitment is for.  The refinements to the DC-net
protocol since Chaum's original paper make this a non-issue if you are
willing to spend the CPU cycles to do all of the necessary work.
Or, to rephrase the question in a manner which my lead you to the solutions
which already exists for this problem:  You have an anonymous access channel
in which you need to do frame reservation such that each member can reserve
one and only one frame for the transmission phase which follows frame
reservation. You are both talking about disrupter detection in an anonymous
channel and it has already been solved...
They already have.  Actually, the trap method in Chaum's original paper
is both expensive and flawed.   Get a copy of EuroCrypt 89 and read
the DC nets papers in there by B. den Bos and by Michael Waidner.  If
you are in the Bay Area I have a copy of Pfitzmann and Waidner's "Dining
Cryptographers in the Disco: Unconditional Sender and Recipient Anonymity
with Computational Serviceability" which I would be happy to make copies of.
This is probably the most comprehensively secure DC-net scheme I am aware of;
although, like most Crypto papers, it is way more complicated and
computationally expensive than necessary for real life.

@_date: 1996-11-07 15:57:41
@_author: Jim McCoy 
@_subject: Why is cryptoanarchy irreversible? 
But the difference between strong crypto and weak crypto is not
something which is visible to an outside observer unless they make
the effort to attack a particular system or decrypt a message.  Such
an attack is beyond the capacity of most municipal or state governements
and is a difficult and expensive task for federal agencies other than
the NSA (who would nto be pleased if their machines were suddenly at
the beck and call of the FBI or any other organization; never underestimate
the power of inter-agency infighting :) What make such detection even
harder is that a good crypto system generates output which is
indistinguishable from noise, this makes it much easier to hide the fact
that an encrypted channel is being used.  The funny thing about noise in
the information theory sense is that it can actually be _anything_ depending
on context, and this sort of uncertainty is the bane of a legal system
which is solidly grounded upon technicalities (such as the US legal system.)

@_date: 1996-11-07 17:14:42
@_author: Jim McCoy 
@_subject: Why is cryptoanarchy irreversible? 
Getting a program to recognize a subliminal message channel is even
harder than teaching a human to do so, check out the book Disappearing
Cryptography or do a web search for "mimic functions" to see how easy it
is to hide messages in text which a program parses as regular English.
The other problem is that more and more of the data being tossed around
the net are images and sound files in which it is incredibly easy to
hide encrypted messages.
And if there was a penalty for using PGP then PGP would hide the fact
that such messages were being sent; that -----BEGIN PGP MESSAGE-----
line in the program output does not need to be there you know... Check
out Stealth PGP for an example.
Except for the fact that US law stops at the US border (modulo kidnapping
Mexican doctors or strongarming the rest of the world to obey US
dictates...)  Information, on the other hand, is very easy to transport
across national boundaries and such transmission is impossible to stop.
With remailers outside the US I can send a message to a free nation and
have it delivered to whomever I want.

@_date: 1996-11-07 17:46:46
@_author: Jim McCoy 
@_subject: Why is cryptoanarchy irreversible? 
Encryption itself will never be forbidden because there is far too much
money riding on electronic commerce.  An administration which tried to
outlaw all encryption would soon find itself on the next train out of
D.C. after the next election cycle.  [And high-tech is definitely getting
more politically aware and organized as the recent Calif. prop 211 shows]
There are a lot of very powerful people betting on systems which require
at least a minimal amount of encryption (at least enough to make random
ciphertext transmissions common on the net.)
Reviewing messages and actually finding stego'd messages is actually a
very, very, hard problem for a program.  This is the sort of AI problem
which people have been working on for more than thirty years and no one
has even come close to solving it.  When you add in the fact that
communication on the net is becoming more international there will be even
more problems for such a program to solve (e.g. a Malay<->English
translation program will throw a ton of false poitives into the mix for
any program developed which somehow has enough understanding of English
to detect messages whose grammar and word choice indicates a possible mimic
function, if the two users communicate using mimic functions within the
translation program itself you are completely screwed...)
You are mistaken.  Read Disappearing Cryptography to see just how easy
it is, then check out Romana Machado's EzStego program (done in Java so
it can be added to any web download with a bit of tweaking.)   If the
penalty for using bad stego is high enough you can be certain that natural
selection will make certain that eventually the programs being used are
top notch code :)
The problem is that you need to be able to prove that stego is in use, and
this is a much more difficult task than you suggest.  A good stego program
will turn out bits which are indistinguishable from noise, so there is no
way to actually _prove_ that stego is being used without actually breaking
the cipher used in the stego routines.  Remember, that life sentence you
suggests requires "proof beyond a reasonable doubt" in US courts, bit rot
from multiple image scannings or a bad microphone on a IP phone conversation
should be more than enough for the accused to cast doubt into the minds of
the jury members.
Get a warrant, search my system, find nothing but a bunch of applications
and a collection of risque (but definitely legal) pictures which I exchange
with a few friends.  You may suspect that when the images are concatenated
in a particular way the low-order bits form a stego filesystem but no one
will be able to prove it in court.
Few.  OTOH the interment of Japanese-Americans occurred during a period of
war, at a time when civil liberties were much more limited, and when
Asian-Americans were second-class citizens with very little political power
(that and the Korematsu decision was a complete piece of crap...)  Today
most US citizens distrust the US governement, civil liberties and protections
are fairly well established in law and legal precedence, and we techno-nerds
are actually the ones running the country :)  [Actually the internment of
Japanese-Americans was really a big land grab masquerading as a wartime
necessity, but that does not change the fact that it happened...]
It would have to be shattered to make such a ban stick.  Times have changed
quite significantly since the 40s, and free speech rights and the first
amendment have become rather important to our information society.

@_date: 1996-11-08 00:26:46
@_author: Jim McCoy 
@_subject: Why is cryptoanarchy irreversible? 
I hide the relatively small amount of data within a very large amount of
data which makes it impossible to find.  Data from analog sources, like
the "real world" (images, sounds, etc) is noisy.  This is a fact of life.
Because this data is noisy I can hide information in the noise.  As long
as the information I am hiding maintains the same statistical properties
of noise it is impossible to pull the information out of the data file unless
you have the key.  If I am paranoid enough I can make this key impossible
to discover without a breakthrough in factoring.  This is the essence of
steganography and the nature of signal and noise are fundemental principles
of information theory.  No legislative action or administrative decision
can change the laws of mathematics, this fact alone is why the crypto genie
is forever out of the bottle.
Ah yes, terrorist programs like cat and perl and operating systems like
Linux which contain a loopback filesystem that I can hook a perl
interpreter into at compile-time (which is enough for me to rewrite the
program from scratch each time if necessary, unless things like math
libraries are also outlawed on computers :)  I think that the crypto
concentration camps are going to be very crowded places.
jim, who answers to a higher law: the laws of mathematics...

@_date: 1996-11-11 14:22:09
@_author: Jim McCoy 
@_subject: Secrecy: My life as a nym. (Was: nym blown?) 
Do not declare your children as dependants.  If you do then you are required
to get a SSN for them, but if you are willing to waive the tax savings there
is no requirement than children have a SSN.  Not having a handy universal
index number like a SSN makes it a lot harder for people to accumulate
statistics on your kids.

@_date: 1996-11-15 15:01:56
@_author: Jim McCoy 
@_subject: ideal secure personal computer system 
And it is this sort of scratch space which the user does not want
to have on the unencrypted partition.  Unless the _system_ requires
writable area on the startup volume there is no disadvantage to locking
that volume.  Once the system is up and running use alias folders in the
system folder for those apps which are inconsiderate enough not to
ask you where they will be creating temp space.

@_date: 1996-11-15 15:03:06
@_author: Jim McCoy 
@_subject: Members of Parliament Problem 
There are several types of "group signature" schemes out there.  The one
which Chaum wrote about was signatures which require a group to perform
verification of the signature in relation to his undeniable signature
system (Lidong Chen advanced this a bit further to make the scheme more
general.)  There are also systems in which group or subset of a group is
necessary to sign the message, the original work was by Yves Desmet in his
paper "Social Cryptography" in Crypto 88 or 89 I think.  There have been
various advancements on these systems, with different threshold schemes
applied, the ability to have "super-votes" among the shares or veto schemes,
mechanisms using distributed computation to securely perform the signing
or encryption, as well other bells and whistles.  At one point I was thinking
about such systems in the context of the DNSSEC work as a means for creating
a pseudonymous top-level domain with the same mechanisms for adjudication and
dispute resolution as the current system through group signatures but had to
set it aside to work on something a bit more practical.  If anyone is really
interested I could probably put together a fairly comprehensive listing of
the literature in this particular area...

@_date: 1996-11-15 15:36:18
@_author: Jim McCoy 
@_subject: Members of Parliament Problem 
Correction:  That should have been "Society and Group Oriented
Cryptography: A new approach" by Yves Desmedt in Crypto '87  [It
was sitting next to my desk and I was too lazy to reach over and
check...sigh.]  This particular paper deals with groups recieving
messages and requiring a subset to decrypt, a later paper by Desmedt
(or maybe Desmedt and Yao) deals with the signature system I

@_date: 1996-11-24 23:55:38
@_author: Jim McCoy 
@_subject: Sameer R.I.P. 
Sameer was offering the net an essentially free service and
people should be greteful that it lasted as long as it did.
If people are so full of rightous indignation over this they
should pick up the torch and carry on using their own dime.
[OTOH, a word of explanation would have been nice...]
Translation:  C2 has a product which is making money.  Providing
support for a service which is essentially making no money was
taking time away from things like Stronghold and development of
other products.  The latter are much more important to C2 because
it lets them hire all kinds of nice people like Sandy :)

@_date: 1996-10-03 19:57:31
@_author: Jim McCoy 
@_subject: Fighting Clipper III 
Such an initiative will need publicity and letter-writing early in the
campaign will help us set the tone and points of debate on this issue.
A boycott works best when everyone knows why and there are a few key
phrases which can be used to get the message across.  Something like
"company X is helping build big brother, boycott their products" or a
few similar sound bites are needed fast.  The big brother inside stickers
from the last campaign were nice, maybe people can come up with variations
of various corporate logos or marketting phrases which help get the message

@_date: 1996-10-04 07:21:55
@_author: Jim McCoy 
@_subject: Clipper spin [was Re:Flood Warning] 
The "International Strong Encryption" phrase is something that we
need to become active in stopping.  Anything which responds to such
announcements should put a different spin on this phrase.  If the
Clipper farce is accepted as "strong" encryption then the battle is
lost; maybe something like "it is _international_ strong encryption
because it is the strongest encryption people like Saddam Hussein [insert
bogeyman du jour] want Americans to have access to"

@_date: 1996-10-04 07:23:04
@_author: Jim McCoy 
@_subject: Fighting Clipper III 
Actually RSA is not a hard target for people like us to threaten.  The
Diffie-Hellman patent expires in 210 days.  Cylink is prevented from taking
legal action against anyone for violating this patent while the current
lawsuit is being decided.  When Diffie-Hellman expires ElGamal is available
for use for free.  So the best threat one can make against RSA is to directly
challenge their revenue stream: start working on making ElGamal an available
option in all systems which use RSA.

@_date: 1996-10-04 17:06:18
@_author: Jim McCoy 
@_subject: Clipper III questions 
While I am not sure that this oft-made claim can actually be proven,
it does raise an interesting point:  a large amount of communications
traffic crosses international boundaries, which country's laws and
procedures are to be followed when a "legitimate law enforcement need"
is perceived?  While Americans have become somewhat disenchanted with
protections given to American suspects via our Fourth Amendment, a
possible line of attack upon Clipper III might be that those who
want to monitor communications will select the jurisdiction in which
it is easiest for them to get a court order.
While "coddling criminals" and "throwing out evidence based upon
technicalities" has a negative PR value, Americans are a cheuvanistic
lot who tend to go completely ballistic when told that they must be
subject to the laws of another country, and given the nature of internet
communications this might be something which could be used to our advantage.
Something like "Clipper III is giving away your First Amendment rights in
cyberspace and replacing them with the restrictive expresion laws of
Country X, is that what you really want?"
The international angle may be a good card to play in the American debate.
them little to work with: there are already numerous articles which can
be quoted pointing out that terrorists [insert optional horseman] already
have access to strong crypto so Clipper III will not catch them, the only
thing it is good for is spying on honest Americans... :)
p.s.  On the commercial side, the known economic espionage cases of the
French and Japanese governements may also be points to raise.

@_date: 1996-10-09 13:09:22
@_author: Jim McCoy 
@_subject: Microsoft CAPI 
But who may want to be, eh?  :)
Actually it is also possible to use a much more overt route and just
patch around anything which is doing the signature checking (possibly
on just a temporary basis if the checks are only made when the engine
is first loaded.)

@_date: 1996-10-10 16:19:28
@_author: Jim McCoy 
@_subject: AW: Binding cryptography - a fraud! 
This is a typical problem with people who have had some experience with
freedom (however limited), most of these people happen to be Americans.
Governments are run by people, so why are these people any more worthy
of trust than the hacker who lives next door?  Part of the reason for American
distrust of government agencies is that these organizations have a history
of abusing the powers entrusted to them.  Unless there is a proven need for
these capabilities why give up such liberties?  If we wanted to be EuroSheep
we would be living over there.

@_date: 1996-09-05 16:40:38
@_author: Jim McCoy 
@_subject: Reputations 
Go read Ender's Game by Orson Scott Card (a good book to read anyway :)
and examine the nature of the computer network "discussion groups" he talks
about: a classic example of reputation markets in many-to-many discussions.
With the proper tools someone with twice the reputation capital in a
particular category as another will have a greater chance of what they say
not being filtered out as noise.
Tell that to Walter Cronkite, Siskel & Ebert, Moody's and others who have
converted reputation capital into large piles of money.  Time is an asset
that has a monetary value to most people, and they are willing to spend money
to hear the opinions of sources which they feel have a high reputation in
a particular area rather than spending the time necessary to do the research
and investigation themselves.
No, I think that you just don't understand the mechanics of reputations and
how they interact with the most important resource in most people's lives:
time.  Instead of thinking of "reputation" look at it from the other end and
consider the "attention marketplace."  Right now reputation markets have a
limited presence on the internet (mostly through killfiles) because the tools
required are not integreated into the tools used to browse the information.
In time this will change.

@_date: 1996-09-07 09:32:47
@_author: Jim McCoy 
@_subject: Reputations 
If you look closer you would probably be surprised to see things starting to
move in this direction.  As the number of participants has grown the "noise"
in most newsgroups has grown to an unmanageable level.  Now most newsreaders
allow you to score authors or article threads so that you can keep individual
reputation and interest files.  I am actually an anomoly at my company, a
collection of very net-savvy people, because I actually still participate in
a few newsgroups; most of the interesting net discussions now take place on
mailing lists which allow further reputation filtering (most mail agents have
better and more flexible filters than news agents) and most bleeding-edge
traffic happens in private mailing lists where one cannot even participate
unless they have already established their reputation.  If these lists were
gatewayed to read-only newsgroups you would have what Card was talking about.
No, this is just an example of how reputations are not global values, each
reputation is modified by the perspective of the user.  _You_ disagreed
with the review and have probably used your experience to weight the
values of future reviews by those particular reviewers.  This is why there
are hundreds of different sources of reviews for movies, people weight the
recommendation given by the reviewer with
Incorrect.  One thought it was a good film and the other disagreed.  You
did not find it to be a good film and have since modified your weighting
of the Siskel & Ebert reputation value to reflect this.  It is highly
improbable that there were any behind-the-scenes machinations between the
movie backers
and the reviewers: such a person has a value which is directly proportional to
being viewed as impartial and once they have established a reputation the
value in maintaining the reputation outweighs the value a potential briber
could gain by trying to influence the review (nothing will drop the
reputation faster than getting caught cheating, and a single reviewer does
not have enough influence on the public to impact a films box office returns
enough to make the bribe worthwhile.)  It is more likely that you just
disagreed with the review and
you have since learned your lesson and now seek multiple review sources or
else switched to a different source for movie review information (dropping
your personal weighting of Siskel & Ebert down below other sources.)
I guess I could have been more diplomatic, but it seems that you just do not
understand that reputations are not a global value, rather they are a
weighted value which is modified over time as the user seeks to determine a
balance of raters and reviewers which most closely represents their
particular viewpoints, interests, and experiences.  There is no one single
reputation which a given person has, all reputations are dependant upon the
source of the reputation and the context in which that particular reputation
is used.
*Sigh*  There is no such thing as a "counterfeit" reputation.  When someone
joins a network with a particular set of interests they will start off by
finding a reputation service(s) which they think, though various channels
ranging from advertisement to word of mouth, closely matches their interests
and views.  This is the only time that outright deception can influence a
person and it is also the point at which deception is least profitable
(because the deceiver will be easily revealed once the user compares the
reputations with what they expect to see and because most new users will
choose multiple services to perform comparison shopping.)  There may even be
reputation services which rate other reputation services to let people know
how the service compares to its stated viewpoints and advertisements.  A
reputation service gains income by establishing a long-term replationship
with the customer, so it is in the services interests to maintain credibility
with its users.  If they do not then that reputation service will have a
negative weighting depending on what the user is interested in, so the
problem of correct vs. incorrect reputations will itself be handled by
reputation services.
An individual will have multiple reputations depending on which service is
providing the reputation and the context in which the reputation is being
used.  "Tim May" may have a relatively high reputation in most services on
cryptography and crypto-anarchy issues but this reputation will not apply to
football predictions or articles posted to soc.culture.swedish.  Someone may
try to burn a reputation to pass off a false statement as truth, but this is
as unlikely to work as it is for Peter Jennings to tell all of his viewers
that this afternoon Bill Clinton appointed me his senior domestic policy
advisor; people now have a wide variety of news and information sources to
use for comparing the veracity of the statement, getting caught diminishes
his reputation and this has a monetary value to him, and because his audience
is larger due to his increased reputation there is a greater chance that
others will investigate the matter and so his chance of getting caught is
Version 0.1 (coming to a news server near you by the end of the year) will
take the form of a service whereby you can subscribe to a usenet filtering
service which will present your newsreader with a database of articles which
have already been filtered by the reputation service to remove off-topic and
"me too" posts (or perhaps based upon other filtering criteria.)  The agency
making this service possible will also sell to individuals or groups the
ability to start their own service on this news host and perform whatever
filtering they want, this will also include adaptive filters (if I can ever
get the little bastards to use an internal weighting function which does not
converge too quickly) which will attempt to learn the general weighting
criteria are so that the people running reputation filtering need only update
the filters occasionally and not score each and every posting.
The hard part, and the part which is slowly gaining enough momentum to make
this possible, is the integration of cryptographic signatures into messages
so that one can determine the authenticity of a message and thereby assign
a reputation value to a real identity instead of an easily forgeable email

@_date: 1996-09-07 16:34:25
@_author: Jim McCoy 
@_subject: What is the EFF doing exactly? 
Just lie on the sender label, isn't that obvious?  I know people who
actually use "codeword" sender labels, in case FedEx or federales ask
about a package they can tell by the sender mentioned which to disavow :)
I always do and as long as I have exact change I have never been

@_date: 1996-09-07 16:35:38
@_author: Jim McCoy 
@_subject: Metcalf and Other Net.Fogies 
Well, having talked with people involved with the problems I can assure you
that they are real.  The net brownouts when MAE-East dumps its BGP core or
the fact that when one of the NAPs upgraded to FDDI it soon found that by
the time people had installed the upgrades to the routers the bandwidth was
already saturated should indicate that there are problems.  Most of the
problems are in the routers, even the top of the line Cisco boxes can only
handle so much.  The sky is not falling, but these sorts of problems are
cracking the
whip behind IPv6 and pushing the companies that make the routers pretty hard
(Have you ever tried to buy even a lowly Cisco 2401?  Do you know what the
wait is on delivery?  I really wish I had bought Cisco stock earlier...)
Then you should probably upgrade your traceroute, preferably to one which
allows source routing of the packets and then couple the output to a nice
udp source routing script which will bounce a few packets between links
with slow response times. Most of the problems are at the exchange points
where packets go from one company's network to another.  It seems that users
have the annoying habit of wanting to talk to other people's
customers...imagine the nerve :)
Bandwidth may be increasing quickly, but demand for it is increasing even
faster with every moron wanting tose the web while the routers to hook it all
together and make it work are still very expensive and not being produced
fast enough to satisfy the demand.  Compared to the way things were even a
few years ago the aggregate bandwidth that one person can expect is
decreasing, it seems that no one writing internet protocols passed an Intro
to Sociology/Poly Sci course and assumed that the tragedy of the commons did
not apply to them.  The upside of all of this is that it is creating a demand
for value-added services which offer users dedicated bandwidth and faster
response time in return for a little coin.
This will probably push micro-currency on to the net faster than any other
consumer demand...

@_date: 1996-09-07 16:42:18
@_author: Jim McCoy 
@_subject: Court challenge to AOL junk-mail blocks 
AOL has a service agreement with their customers, and they are not allowed
to change the rules just because they feel like it (I believe that this
is called a contract :)  This is the jist of the injunction.

@_date: 1996-09-16 16:45:46
@_author: Jim McCoy 
@_subject: Workers Paradise. /Political rant. 
Actually there is a fundemental difference:  what Tim demands is the
right to be left alone and to be free from exernal influence as long
as what he is doing does not directly hurt another, what "they" demand
is to be taken care of by others because they either cannot or choose not
to take care of themselves.  The latter requires that someone productive
(like Tim) be forced to take care of them through taxation or otherwise
at gunpoint.
In most societies this is considered the difference between a child and
an adult...

@_date: 1996-09-23 18:27:12
@_author: Jim McCoy 
@_subject: Evolving algorithm for faster brute force key searches? 
Adam Shostack While a well-designed algorithm has a flat search space in the case of
a single instance of a particular ciphertext/plaintext, this is not
necessarily the case for repeated encryptions using the same key and
possibly for other examples (hence differential cryptanalysis, etc.)
If there is a way to break a system that is less than a brute-force
search of all possible keys then the landscape is not flat.  The hard
part with making such discoveries using evolutionary methods is that
even if the landscape is not completely flat the positive and negative
reinforcement needed to perform selection in such an environment almost
always necessitates that the fitness function be crafted with this in
mind by the researcher and few evolutionary programming researchers know
anything about crypto.
While there are a few strikes against such research (as the oft repeated
"flat landscape" phrase shows) I would not let the current state of the
art in this area disuade anyone interested.  Most of the research done
so far has been done by people who either knew little about crypto or
little about evolutionary programming.  There are also other areas of
crypto relevance which may prove more amenable to evolutionary programming
methods, like factoring...

@_date: 1996-09-23 18:35:47
@_author: Jim McCoy 
@_subject: Bernstein hearing: The Press Release 
Brian Davis The states are prohibited through the 14th Amendment via the
Slaughterhouse cases, the ability of the executive branch to
violate due process is questionable (from a legal viewpoint, not
a practical one...the President cannot order you placed in jail
unless you have broken a law which requires congress to have
made the law in the first place...)

@_date: 1996-09-24 08:30:50
@_author: Jim McCoy 
@_subject: provably hard PK cryptosystems 
Solving such a problem is easy to break down into parallel steps, but
the advantage of using the infinite plane (or even a plane with "really
large" boundaries) which Tim mentioned is that you can make the search
space larger than anything which can possibly be solved in a reasonable
amount of time by these methods.  For example, factoring composites of
very large primes can also be done by such massively parallel systems, but
othe individual parts are no faster (actually they are almost always slower)
than regular computing elements.  Given a large enough search space even
a parallel system runs out of processing elements.

@_date: 1996-09-26 16:52:07
@_author: Jim McCoy 
@_subject: Bernstein hearing: The Press Release 
The executive branch cannot, but the legislative branch has the power to
restrict the jurisdiction of the courts in any way it wants to except
for cases in which the Supreme Court is given original jurisdiction (a
limited number of situations)  Ironically enough, Marshall's decision in
Marbury v. Madison was that the Judicial Act of 1789 which outlined the
jurisdiction of the court system was unconsitutional.  It is Congress
which gives the courts their jurisdiction, only the Supreme Court is given
original jurisdiction in the Constitution itself (interesting side note: The
case New York v. New Jersey regarding the ownership of Ellis island, I think,
was the first case of original jurisdction to be argued in the current
supreme court building if that tell you how often such cases come up...)

@_date: 1996-09-28 09:43:15
@_author: Jim McCoy 
@_subject: [NOISE] Re: Public Schools 
Well, even then you are probably going to have a tough time making your
argument.  Public "magnet" schools and other public schools which target
the top flight students in major metropolitan areas will usually have a
very high percentage of such students because they are able to "cherry pick"
the ones they want (and avoid dragging down averages with students whose
parents have "pull" that some private schools must deal with.)  If you take
the percentages for a school district or other large geographic area which
covers several schools you will probably end up with a better comparison.
Then again, even with such a geographic comparison you may not end up with
the results you seem to want.  In certain areas of the US the public schools
are excellent (generally the Midwest judging from published surveys of test
results and other somewhat meaningless tests :) and in some ares the public
schools are horrific.  Making broad claims regarding which types of
education are good and which are bad is often a fools errand....
