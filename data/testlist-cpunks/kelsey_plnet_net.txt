
@_date: 1997-08-13 02:00:59
@_author: John Kelsey 
@_subject: Eternity Uncensorable? 
[ To: cypherpunks at algebra.com, Wei Dai  Date: 08/08/97 10:37 pm   Subject: Re: Eternity Uncensorable? ]
I'm a little concerned with the usefulness of this idea in a
legal sense.  Imagine the physical analogue:  Alice buys the
guns and masks, and leaves them in a pre-arranged place.  Bob
anonymously buys a car and leaves it, with the keys inside, in
another pre-arranged place.  Carol and Dave collect the guns,
masks, and the car, and use them to rob a bank or hijack an
airplane.  Do you suppose the feds will have any problem
prosecuting Alice and Bob for their part in the conspiracy?
This part is somewhat more useful.  However, n copies of the
message are probably better.
I think the general problem here is unsolveable--running an
Eternity server is just going to be a dangerous thing to do if
you live somewhere where the police are likely to see
possessing, distributing, or selling some of the information on
it as a crime.  There are two possible solutions I can see:
Either make Eternity servers so widespread that taking down
individual servers in individual jurisdictions is futile, or
find some jurisdictions where virtually *nothing* will provoke
the police to act.  (Note that legal jurisdiction isn't the only
issue here.  Some groups may be willing to use terrorist tactics
to shut down these servers.)
Note:  Please respond via e-mail as well as or instead of posting,
as I get CP-LITE instead of the whole list.
   --John Kelsey, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36

@_date: 1997-12-23 14:37:01
@_author: John Kelsey 
@_subject: Question on CFB variant with c[i-N] 
I'm kind-of skeptical of the big advantages of this.  I mean, if you
were convinced
someone with a DES-cracking engine was listening in on an encrypted
channel, and you really wanted to make sure they wouldn't manage to get any
plaintext, would
you rather alter your system to use some weird and not-too-well
analyzed chaining
mode, or alter your system to use DESX or Blowfish or something else
with a key length too big to be vulnerable to such keysearch machines? There clearly *are*
ways to get more than 56 bits of security out of DES.  However,
they're not generally
obvious, and even very bright cryptographers have shot themselves in
the foot trying
to design them.  (Remember 3DES with internal CBC-mode chaining,
Ladder DES, and
--John Kelsey, kelsey at counterpane.com / kelsey at plnet.net
NEW PGP print =  5D91 6F57 2646 83F9 6D7F 9C87 886D 88AF

@_date: 1997-11-03 02:11:18
@_author: John Kelsey 
@_subject: Infastructure Protection and Paranoia 
[ To: cypherpunks  Date: 10/30/97   Subject: Re: Infastructure Protection and Paranoia ]
I agree.  This has always been my reaction to the infowar
folks--anyone who understands how to attack a system can
look around and find hundreds of fairly easy targets.  Some
of these targets just *can't* be protected in a
cost-effective way.  (Note the way the IRA and various
Palestinian terrorists still manage to find soft targets,
despite the fact that their intended victims have spent
years and millions of dollars hardening the obvious soft
Of course.  Any moron with a hammer can ruin a car engine;
it takes a skilled mechanic to fix one.  The same applies
almost everywhere--destroying something takes a fraction of
the skill of building or maintaining it.
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36

@_date: 1997-11-03 02:11:21
@_author: John Kelsey 
@_subject: Copyright commerce and the street musician protocol 
[ To: Perry's Crypto List, Cypherpunks  Date: 11/01/97   Subject: Copyright commerce and the street musician protocol ]
I've been working on various copyright protection schemes
from time to time over the last three years.  The general
goal is (naturally enough) to make some digital data hard to
copy without some kind of permission or payment or record
being made.  Thus, a user may have a book (mostly text,
perhaps with some illustrations) he is reading on his
computer, and the publisher wants to make sure that that
user can't give copies of the book to all his friends, or
post it to the net, or whatever.
I'm convinced that there will never be a secure solution to
this problem.  (I can't imagine that this is news to anyone
on these two lists.)  I have somewhat mixed feelings about
this--I'd hate to see my favorite authors and musicians
either waiting tables for a living, or having to insert
references to their sponsors' products in their stories.
(``And then he bought her a Coke, and her eyes lit up.'') On
the other hand, a widespread copyright commerce system that
really works is most of the infrastructure for a massive
censorship mechanism.  (Reset the price of books you don't
like to a billion dollars US per copy made.)
Suppose I want to get paid for the next chapter of my
thrilling novel.  A whole bunch of people want to see me
publish my next chapter.  So, I make some statement like
``When I get $1,000 in donations, I will publish
the next chapter in this novel.''  Readers can go to my
website, see how much further there is to go, and donate
money to the cause of getting my novel out.  Note that I,
the author, don't care *who* pays to get the next chapter
out; nor do I care about free riders.  Instead, I just care
that my $1,000 pot gets filled.  When it does, I publish the
next chapter.
There are basically three things that can go wrong here:
a.  I set my price too high, and never reach my amount.  (It
might be possible to decrease the total amount required
later, though it would be a little questionable to do this
b.  I set my price too low, and get lots less than I could
have gotten.  (This is self-correcting.)
c.  I get my amount filled, but still don't publish the next
chapter of my novel.
The trust issues, especially with (c), are worth
considering.  The obvious (clunky) way to solve this is to
have a trusted third party handle the whole transaction.  We
will call him the Publisher.
Now, I submit my novel, or parts of it, to the Publisher.
He has his editors review it to see if it's worth trying to
sell (like any publisher, albeit with rather low
printing/binding costs).  If so, he and I agree on a price
and split.  For unknown authors, the first several chapters,
or even the first few books, may be freely available, in
hopes of drawing in customers.  For known authors, perhaps
the first chapter or two is free, and the rest go through
the payment mechanism.  He has my whole novel, and on his
web site, he makes available, say, chapters 1-3 for free,
and chapter 4 will become available when $1000 is donated to
the cause of getting it out, or on January 1, 1998.
If enough readers want to hurry up and see the next chapter,
they can make a payment.  The publisher needs no
identification for this, so anonymous payment systems work
quite well.  The Publisher holds the payments in escrow
until the chapter is released, and then sends me my cut.
I think I can build a similar protocol without the Publisher
taking anything but a backup role--he gets the money
transfers and holds them in escrow, and if the chpater isn't
released, either he can release it or he can return the
money, or donate it to some charity, or whatever.  (The
whatever has to be spelled out beforehand, and the money
mustn't go to the author, directly or indirectly.)
This is obviously not a complete solution.  The neat thing
is, it can be used with other systems.  (Thus, if you want
to include a shareware/guiltware message on each copy, or
try to use some kind of software or hardware protection for
the chapters once they're published, then this system
doesn't alter that much--the donors simply get prepurchased
copies of the book, released on the normal release date.)
Similar ideas may work in other areas.  In software, I
suspect it would be a way of getting a feel from the market
for what new features are wanted.  In music, perhaps this
could be used for individual songs, or maybe it would work
better for whole albums.  Television and movie serials could
work this way (it works for PBS, doesn't it?).  Some books,
music, and movies would be *awful* to release this way,
though.  I wish I had a more useful general solution, but
maybe this will help a little.
Comments?  This is clearly not all that new, but I've never
seen it in a crypto context from anyone but me.
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36

@_date: 1997-11-03 02:15:13
@_author: John Kelsey 
@_subject: Kyl's internet gambling bill 
[ To: cypherpunks  Date: 10/30/97   Subject: Kyl's internet gambling bill ]
[Stuff about Kyl's anti-internet gambling bill.]
I always find these laws entertaining.  In Missouri, we have
state-run gambling in the lottery system, and state-licenced
gambling on the riverboat casinos.  Our Attorney General has
been very vocal about shutting down internet casinos, to
protect Missouri's citizens from being exploited.  His
concern for the welfare of problem gamblers in our state
is touching.  Odd that he isn't worried about those same
citizens being taken advantage of by the in-state
Of course, the real issue here isn't about protecting
citizens from themselves, or even about keeping citizens
from being cheated by the electronic equivalent of weighted
dice.  It's about protecting the financial interests of
those who now benefit from having local gambling monopolies.
The state gets quite a bit of money from the lottery, and
the companies that have invested in building riverboat
casinos here are surely concerned about potential
competition via the internet.  The cities that have
riverboat casinos typically get some part of the money made
from them, which nicely brings those city governments into
line.  Presumably, something similar is happening with
various states' Indian Reservations opening casinos.
It's an interesting side-point that really anonymous
communications and payment systems applied to gambling
systems mean not only that *governments* can't shut down
competing gambling schemes, but also that organized crime
can't shut them down, whether through influencing corrupt
governments to try to shut them down, or through direct
Ob Crypto:  There are cryptographic gambling protocols that
can be verified (given some set of assumptions about
underlying operations) to be fair.  Thus, it's possible for
a gambling operation to make their client software freely
available in source, and allow people to see what it does
and review it for fairness.  If you find a reviewer or two
you trust, you can ask them to digitially sign the
executable they got when they compiled the code, and refuse
to use any other code.  This gives you a level of certainty
that you're not being cheated by weighted dice that you
simply can't get in physical casinos.  (Sure, government
agencies inspect those casinos, but the inspectors aren't
incorruptible, and they can't be everywhere at once.)
For a simple example, consider a situation where Alice and
Bob need to agree on a shared seed.  Assume they already
have established a secure (encrypted and authenticated)
session. They can easily generate a new shared seed by doing
something like this:
1. Alice generates random R_0 and sends hash(R_0) to Bob.
2. Bob generates random R_1 and sends hash(R_1) to Alice.
3. Alice sends R_0 to Bob.
4. Bob sends R_1 to Alice.
5. Alice and Bob each generate their shared seed, R_0 XOR R_1.
If the hash function doesn't leak information about its
inputs, and if it is collision-resistant, then this protocol
should work.  If either party generates a random number,
then the resulting seed is random, regardless of the other
party's input.  (You still have to work out administrative
issues, like what happens when communications fail
conveniently just after Alice sends Bob R_0, but these are
easy enough to solve.)
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36

@_date: 1997-11-04 01:07:21
@_author: John Kelsey 
@_subject: Protocols for Insurance to Maintain Privacy 
[ To: Cypherpunks  Date: 11/01/97   Subject: Protocols for Insurance to Maintain Privacy ]
I can see practical problems with this (like finding out
that the fine print on page 248 of my insurance contract
turns out not to cover dog bites that occur on Thursdays),
but it's really just letting customers buy only what they
One problem with this is that, if it becomes widespread,
nobody will ever buy insurance for these diseases unless
they have it or probably will get it.  This kind-of defeats
the point of having insurance, which is to protect yourself
from low probability high cost things happening.  That is,
before I've taken the test for genetic disease X, my best
estimate of the probability that I will test positive is
very low.  Once I have taken it, I know the result.  If I
sign up for a-la-carte insurance for this disease, the
insurance company effectively knows I must have tested
positive for a predisposition to it, and so either won't
give me insurance, or will give me insurance only at an
extremely high rate (corresponding to a 1/10 chance of
getting the disease, rather than a 1/1,000,000 chance).
On the other hand, information isn't free--I have to spend
some money for each of the hundreds of genetic tests
available.  There may be a profitable business in providing
a battery of genetic tests for a large up-front fee, in a
sort-of inverse-lottery scheme--if you get unlucky enough to
have one or more of these disease precursors, we pay your
insurance costs, or at least give you a big bundle of money
to spend as you will.  This is subject to various kinds of
abuse (if you know you're predisposed to get some disease,
you have a strong incentive to enter the ``lottery''), but
it still might work.
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36

@_date: 1997-11-06 06:56:59
@_author: John Kelsey 
@_subject: Protocols for Insurance to Maintain Privacy 
[ To: cypherpunks  Date: 11/03/97   Subject: Re: Protocols for Insurance to Maintain Privacy ]
Yes, I understand this.  Nobody with a grain of sense
insures himself for things he knows will never happen.
An insurance broker and a bookie are in the same business.
A bookie takes a bet from me, at 1000 to 1 odds, for some
unlikely to occur event--which he thinks has a probability
of less than 1/1000.  An insurance broker does the same
thing.  The only important difference is my purpose in
placing the bet.  When I take out medical insurance, I am
placing a bet that I will get sick enough to spend more than
my deductable on doctors.  The insurance broker estimates
(based on whatever information is available) the probability
that this will happen, and makes me a bet at odds that are
in his favor, if his estimate is true.  If I get sick, I get
some money (or my doctors do).  If I stay well, I lose the
bet.  This is just paying someone to take some risk off my
Right.  I don't think I expressed my point too clearly,
because you seem to have responded to something different
than what I was saying.  Suppose there is some genetic
disease that kills its victims on their 31st birthday,
unless they get a $1,000,000 treatment first.  Before I have
taken the test for this disease, I have to accept a certain
risk--if I find out I have the disease, I have to raise a
million dollars in the next few months.  After I have taken
the test and gotten back the results, there's no more risk
involved (assuming the test is perfect)--I either have the
disease or I don't.  After the test, insurance isn't useful
(unless I defraud my insurer).  Before the test, though,
insurance might be useful--I could essentially place a bet
with someone that I had the disease--I pay $1, and get a
million dollars back if my test comes back positive--just
enough to pay for my treatment.
I know.  Let me make it clear that I am not at all
interested in banning private testing, coercing insurance
companies or anyone else into agreements they don't want to
make, etc.  I am saying it would be nice if I could buy
insurance against the results of the tests before I took
them.  The problem is, I can't see a really workable way to
do this, because there's no way to keep people from taking
the test beforehand.
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36

@_date: 1997-11-06 07:02:36
@_author: John Kelsey 
@_subject: Copyright commerce and the street musician protocol 
[ To: cypherpunks, Perry's Crypto List  Date: 11/03/97   Subject: Re: Copyright commerce and the street musician protocol ]
This is a nice situation for CD-ROM-based video games.
However, it's probably a temporary situation.  Currently,
downloading a novel, even over modem lines, isn't all that
time-consuming.  If available bandwidth and storage capacity
keeps getting cheaper, the same will soon be true for
digital audio, and later, for digital video.  The number of
bits required to hold a twenty-minute piece of music at CD
quality isn't going to increase over time.
Separate the medium from the information.  For computer
programs, it's possible to just keep bloating the data to
keep piracy from paying.  (To some extent, anyway.)  For
novels, music, and video, that's not going to work. The unit
of music I'm interested in listening to will probably not
change much.
But once someone has scanned in the text from the book, it
costs approximately nothing to make another copy.  This
works as well for digitized music, video, and images.  Once
the data is available somewhere in digital form, it's almost
free to copy.  In a world with jurisdiction-shopping,
eternity servers, high-quality anonymous e-mail, anonymous
payment mechanisms, and cheap, high-bandwidth connections,
that digital data has to get onto the net *once*, and it is
free forever to anyon who will take the trouble to find it.
For books, one reason this doesn't happen more often now is
that the display technology for most computers is not nearly
as easy to read as even cheaply-printed paperbacks.  This is
sure to change with time.  Widespread use of DVDs will get
rid of the advantages of CDs and cassettes for listening to
It's essentially the same problem for text works.  A text
work you can't fit on one CD with compression is unlikely to
be something you can get many people to read all the way
through.  (The exception is reference material, where you
want *everything* of interest to be there, even though you
will surely read only a tiny fraction of the material.)
The real distinction here is timeliness.  If some
information is only valuable when it's timely, then it's
probably going to make sense to get the information from its
source, even if it costs money or you have to look at some
ads.  If the information is valuable weeks later, then it
may be hard to charge much money for access to it.
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36

@_date: 1997-11-06 07:03:09
@_author: John Kelsey 
@_subject: Protocols for Insurance to Maintain Privacy 
[ To: cypherpunks  Date: 11/05/97   Subject: Re: Protocols for Insurance to Maintain Privacy ]
This seems straightforward enough in principle.  It's just
like a prepaid credit card, or even a normal credit card,
right?  I mean, what it says on the card is probably
different, but the financial arrangements are pretty-much
the same.  I suspect it would be easier to implement this
(at least in the US) as an extra function on a credit card,
rather than as a new kind of insurance, since there are so
many odd insurance regulations out there.  Currently, lots
of credit cards offer special benefits like automatic
insurance on rental cars--this seems like a close variation
on the same idea.
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36

@_date: 1997-11-25 20:36:46
@_author: John Kelsey 
@_subject: NBC Mugs Jim Bell 
[ To: cypherpunks  Date: 11/21/97   Subject: Re: NBC Mugs Jim Bell ]
I guess the good news is, we've finally figured out why
they've been holding him so long before sentencing--to make
sure he doesn't miss any of his scheduled media events.
Or perhaps, given the nature of the coverage, to make sure
he *does* miss them all.  We need a good posterboy for one
of the Four Horsemen, to ensure the passage of next year's
Guaranteeing Freedom through Imposition of a Benevolent
Police State Act of 1999, and the following year's
appointment of first lady Tipper Gore as Internet Czar.
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36

@_date: 1997-10-10 01:14:17
@_author: John Kelsey 
@_subject: Defeating MITM with Eric's Secure Phone 
[ To: cypherpunks, coderpunks, Perry's Crypto List   Date: 09-Oct-97   Subject: Defeating MITM with Eric's Secure Phone ]
[Method using stegoed audio noise deleted.]
I prefer to work on the more immediately useful problem:
How can I secure my use of the (very nicely done) Comsec
secure phones using existing infrastructure?  I am concerned
with the MITM voice impersonation attack, since that's the
easiest attack on the system. (Actually, it's probably
easier to physically tap my office, but I can't fix that
right now.)
The simple MITM defenses (like restating your checksum
spontaneously in the middle of the conversation) take care
of lots of this.  Here's another way that may make some
sense, though it's a little hard to use:
1.	Exchange PGP-encrypted e-mail establishing a set of
sixteen different words, labeled for 0..f in each direction.
0.	Dilbert
1.	Alpha
2.	Cable
3.	Swordsman
f.	Marxist
Now, the checksum reading is very hard to spoof.  Suppose I
get 0x33f. I say ``My checksum is Swordsman Swordsman
Marxist, or 33f.''
An attacker with digits besides 3 and f in his checksum
simply doesn't know how to impersonate me to the other
party.  He lacks the secret information we've shared.
Now, the problem with this is that it's too cumbersome.  I
would like the shared secret information to be usable with
less effort.
If we just want to detect the MITM eventually, then I can
send the other participant a PGP-signed e-mail, in which I
include the whole 6-digit checksum.  That won't prevent the
MITM attack from working once, but it will let us know
after-the-fact if our conversation was exposed.  If we find
evidence that our conversation was intercepted, then we can
start using my one-time word lists, or some other more
paranoid mechanism.
Still another approach, which may be applicable for some
people, is to write a simple calculator-type application
that uses a shared-secret to compute a checksum on the
checksum.  Thus, when I call Alice, I do the following:
1. Type the shared secret between Alice and me into the
calculator app.
2. Make the call to Alice and push the ``secure'' button.
3. Type the six-digit checksum into the calculator app.
4. Read the calculator's first three checksum digits.
5. Listen to her next three digits.
The simplest way to do this seems to be to just exchange a
six-digit hex value as a one-time password for a given
secure phone call.  This is done using PGP or some other
mail encryption package, and can legitimately be used to
exchange a long list of one-time passwords at once. Then,
use Windows' calculator application (with View set to
Scientific, and Mode set to Hex) to add your one-time
password to the checksum.  Thus:
1. I pull up Alice's latest encrypted e-mail, and get
today's phone password.
2. I open the Windows calculator, set it to View/Scientific
and hex mode, and type in the password (a six-digit hex
number) and ``+.''
3. I call Alice, say hello, and push the ``SECURE'' button.
4. I type the six digit hex checksum into my calculator.
5. I read the first three digits of the result to her.  She
reads the next three to me.
All of this (except for maybe re-reading the checksum in the
middle of the conversation) is probably overkill.  Still, it
may be worth something to someone.
Is there a clean way to have the secure phone box take input
from the dialpad on the phone, without sending it out on the
phone line?  If so, then maybe some later version could
include a PIN-secured mode, using EKE or SPEKE or something
similar.  (For a supported mode, the checksum wouldn't need
to be read over the phone anymore.  We would need to protect
the shared PIN from brute-force attack, however.)
   --John Kelsey, jmkelsey at plnet.net / kelsey at counterpane.com

@_date: 1997-10-10 01:14:59
@_author: John Kelsey 
@_subject: Applying ``Crowds'' idea to anonymous e-cash. 
[ To: cypherpunks, coderpunks, Perry's Crypto List   Date: 10/09/97   Subject: Applying ``Crowds'' idea to anonymous e-cash. ]
I was thinking about applying the ``Crowds'' idea to
anonymous e-cash, and came up with what I think is a pretty
good idea.  I am interested in seeing if anyone sees either
holes in it, or ways to improve it.  I am also interested in
hearing about whether or not it has been invented before.
Crowds, for those who haven't seen it, is a way of
giving web users partial anonymity by making it impossible
to determine which member of some ``crowd'' of users did
some action (such as requesting a document).  (This is a
very rough summary--read the paper for the real analysis.)
I can see a way to do something very similar with
withdrawing electronic coins.  (This works best with
online-cleared coins), without any blinding being used.
I think this gets around the Chaum patents.  I also think it
can probably be implemented more-or-less on top of the
web-anonymizing Crowds stuff, though I may be wrong.
Here's the basic idea:
1.      A Crowd of users forms up, each wanting to withdraw
some reasonably large amount of money, such as $100, in $1
2.      Each user provides a public key and pays some money
(perhaps $101) into the bank.  The bank registers each
public key as belonging to a member of the crowd.
3.      Each member of the crowd is given all other members'
public keys.
4.      Each member prepares 100 one-use symmetric
encryption keys, each with a 64-bit key ID.
5.      The members organize themselves into a sort of
one-time anonymous routing network, using those public keys.
Each message to be sent is encrypted in layers (a la onion
routing), so that each member appears at least once in the
message's path.  Each message ends up at the bank,
eventually.  I'll talk about likely network architectures
later, if anyone's interested.
6.      The bank publishes something noting that it has
received N*100 keys, where N = the number of members in the
crowd.  It also publishes the hashes of all N*100 symmetric
7.      Each member digitally signs something saying that he
agrees with the keys published, he hasn't been railroaded,
etc.  Nothing proceeds until this has been published from
each member.
8.      The bank encrypts one $1 online-cleared e-coin under
each symmetric key.  It publishes a list of (key ID, encrypted
coin) pairs for all the members to receive.
9.      Each member walks away with $100 in $1 e-coins.
Nobody can prove which member got which coin.  No linking of
coins is possible.
Now, the protocol isn't all *that* important here, but the
idea is:  We interface with the traceable money world, but
grant a sort of weak anonymity for all users in the crowd.
Because the coins are online-cleared, they must be deposited
immediately.  To protect recipient-confidentiality, these
can be deposited under a pseudonym account--basically just a
one-use public key.  The recipient accumulates a bunch of
credit under that public key, and then goes through the
withdrawal procedure again to get new, weakly anonymous
coins, which he can openly deposit without direct
traceability.  (That is, the bank can still learn that
certain coins were spent at the same place, but can't
identify the final recipient of the money.  I can think of
ways to adapt this idea to unlinkability, though they
involve some implementation hassles.)
Note that multiple iterations of the withdrawal protocol
make things much stronger.  That is, there is no reason why
the participants in the withdrawal protocol have to spend
their e-coins directly--they can also use them, along with a
one-use public key, to go back into the withdrawal protocol
again.  An attacker who manages to link a given coin to a
given crowd (possible only with the help of the bank) with
some anonymous participants (who paid in with coins from
this scheme) must face the possibility that this coin could
have come from the anonymous participants--which can then be
traced to another pool, with other anonymous participants,
etc.  The attacker can't even make statistical statements
in many cases, since, if I were doing something really hot,
I'd want to go through the withdrawal process lots of times.
The bank can tell only what crowd your coins came from, not
how many times you have swapped your coins out.  If you're
willing to pay the transaction costs and time, you can
withdraw and deposit as many times as you like.
Comments?  Is this idea practical at all?  Has someone else
already done it?
   --John Kelsey, jmkelsey at plnet.net / kelsey at counterpane.com

@_date: 1997-10-11 15:31:26
@_author: John Kelsey 
@_subject: Defeating MITM with Eric's Secure Phone 
[ To: Cryptography, cypherpunks  Date: 10/10/97   Subject: Re: Defeating MITM with Eric's Secure Phone ]
I wrote (and Bill commented on):
Bill responded with some nice reasoning:
This is *almost* right.  We need to add one more thing,
1.      Alice calls Mallory, thinking she's calling Bob.
She reads the first three digits to him.  He makes the
connection fall apart.  At the same time, Mallory calls Bob,
pretending to be Alice, and causes the connection to fall
apart at the same time.
2.      Alice calls Bob again, re-establishes their
connection, and talks to him.  Both seem to have had the
same thing happen, so it's believeable that it was just
noise on the line.  (Where I am, this isn't so uncommon that
it would imply an active attack.)
3.      Mallory now knows three of these words in the
dictionary.  He lies low for the next few calls before
trying the same trick again, until he learns most or all the
dictionary entries.
This implies a couple of things:  First, Alice and Bob
ought to be suspiscious of line noise that conveniently
clobbers them during reading of checksums.  Second, Alice
and Bob shouldn't keep the same 16-word dictionary forever.
If they change it once a week, this may be enough to make
the attack I describe above unworkable.
Note that this all works only when the phones/dictionaries
are used only by single users.
I also made a poorly-thought-through comment about using
6-digit hex secrets, and adding or XORing them into the
checksums.  This is vulnerable to a trivial attack, of
course.  The thing is, this doesn't need to be as complex or
cryptographically secure as a hash function or MAC, because
of the way it's used.  We can probably also expect
one-day-only keys for this application.
I can think of dozens of things that *ought* to work here,
and still be strong enough to resist the limited possible
attacks, but I can't seem to convince myself of the security
of any that are simple enough to use with a calculator.  If
I settled on one, it would be
New checksum = (((old checksum * C0) mod P)+ C1) mod 2^{64}.
where P is a random 64-bit prime, C0 is a random 64-bit
number between 0 and P-1 inclusive, and C1 is a random
64-bit number.  If P,C0, and C1 are all unknown, I *think*
that's secure.  An attacker given the high-order half of
this doesn't seem to have the information needed to guess
its low-order half on a different checksum, nor to reliably
learn the value of P.
This is essentially the IBC-Hash message authentication
code, which is provably secure if the key is used once.
I can't see a way that this could be attacked in this
application, given one-time use of the keys.  Can anyone
else?  (I may be missing something obvious again.)
I wish I could claim this, but it's been around for a while.
Didn't some of the PGPphone people come up with this idea?
(Or was it users of older, government-issued secure phones?)
95032, USA
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36

@_date: 1997-09-19 07:28:27
@_author: John Kelsey 
@_subject: Crypto-law etc 
Sure.  We get the same right to bear it as we have to own rocket
launchers, machine guns, or flame throwers--none.  The second amendment hasn't protected our right to possess those things, which pretty clearly fall into the realm of its direct intentions--why
would it protect our right to use crypto, which isn't even that clear
cut?  --John Kelsey, kelsey at counterpane.com

@_date: 1997-09-23 13:23:26
@_author: John Kelsey 
@_subject: US Senate bans laptops 
This is really encouraging news!  Computers would likely lead to increased efficiency in Congress, and *that* isn't in the interests of any of us. These folks are in the business of taking peoples' life, liberty and property, for fun,
profit, and ideology. Just about anything that slows them down, including
their own mind-numbing stupidity, is a good thing.
   --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36

@_date: 1997-09-25 13:55:01
@_author: John Kelsey 
@_subject: news story in the SD Daily Transcript 
Some of you might find an article in the San Diego Daily Transcript (I
it will appear tomorrow in the print version; it's up now at their website)
It's an article about today's moderately good news from Congress, and I'm
quoted extensively in it.  (The reporter is an old friend of mine, and he
what I do for a living, so he called me for a quote.)   It's currently at
and I *think* they will keep it up for a while.     --John Kelsey, Counterpane Systems, kelsey at counterpane.com
 PGP 2.6 fingerprint = 4FE2 F421 100F BB0A 03D1 FE06 A435 7E36

@_date: 1998-12-16 16:31:11
@_author: John Kelsey 
@_subject: Anyone Striking? 
What would be the usefulness of this, anyway?  Most of us who know and care about this issue are already working in the field of cryptography or computer security at some
level--how will slowing our projects down by a day help our cause?  How will refusing
to design strong systems that use cryptography send a message to the government that
their meddling won't keep us from designing such systems?  --John Kelsey, kelsey at counterpane.com / kelsey at plnet.net
NEW PGP print =  5D91 6F57 2646 83F9 6D7F 9C87 886D 88AF

@_date: 1998-02-02 06:47:30
@_author: John Kelsey 
@_subject: Chaining ciphers 
[ To: Cypherpunks  Date: 02/01/98   Subject: Re: Chaining ciphers ]
I've seen proposals along these lines before (I think there
was one by Ron Rivest).  If you have a hash function and any
symmetric cipher, you can do this.  BEAR and LION, the two
arbitrary-size block cipher constructions by Ross Anderson
and Eli Biham, have this property; you have to process every
bit of the message to check a key guess.  Using normal
chaining modes for this kind of thing, at least with 64-bit
block ciphers, usually exposes you to internal-collision
kinds of attacks.
Actually, this isn't necessarily true.  The problem is that
you can't guarantee that there won't be some interaction
between those encryption operations unless you can assume
independent keys.  The classic example is this:  Suppose the
first cipher is double-DES encryption with DES keys (K0,K1),
and the second and third encryptions are single-DES
decryptions with keys K1 and K0, respectively.  You now have
leaking all your plaintext directly.
The proof for why something like
E(X) = IDEA_{K_0}(3DES_{K_1}(X))
is at least as secure as 3DES is as follows:  Suppose those
keys are random and independent, and suppose you have a way
to break E(X).  Now, anytime you see a 3DES-encrypted block
of data, you can break it, as well, by simply choosing a
random IDEA key, encrypting it under that key, and then
applying your attack on E(X).  In other words, the attack on
E(X) implies the attack on 3DES(X), but only if the keys are
independent.  If there is some dependency between K_0 and
K_1 that's required for your attack on E(X), then you can't
generalize that out to an attack on 3DES, since you don't
know the 3DES key when you start attacking it.
To take this a little further, note that an attack on E(X)
also implies a chosen-plaintext attack on IDEA.  If I have
an attack that allows me to break E(X), then I can choose a
random 3DES key, pre-encrypt all my chosen plaintexts with
it, and then request the encryption of all those plaintexts
under the secret IDEA key.  The result is E(X), so I can now
apply my attack to E(X).
For more elaborate constructions, like
E3(X) = 3DES_{K_1}(IDEA_{K_2}(Blowfish_{K_3}(X))),
we can make the same kind of proof.  Suppose I can break
E3(X).  Now, I can mount a chosen-plaintext attack on IDEA.
I select a random encryption key and use it to encrypt all
my chosen plaintexts under with Blowfish, and then I request
their encryptions.  When I get the ciphertexts from that, I
select a random 3DES key and encrypt them again.  I then
apply my attack on E3(X) to break the system.  Thus, an
attack on E3(X) implies an attack on 3DES, IDEA, *and*
Blowfish.  But only if the keys are independent and random.
Note:  I read CP-LITE instead of the whole list.  Please CC
       me on replies.

@_date: 1998-01-22 23:36:48
@_author: John Kelsey 
@_subject: (eternity) Eternity as a secure filesystem/backup medium 
[ To: cypherpunks  Date: 01/21/98   Subject: Re: (eternity) Eternity as a secure filesystem/backup
medium ]
This is only a threat if the authorities have a good idea
who submitted the data, and want to prove it.  Otherwise,
you end up with billions of encrypted documents, each
encrypted with a moderately weak cipher.  (Even assuming
that the cipher turns out to have only 40 bits of strength,
this is too expensive to do for more than a handful of
Again, this won't be too economical unless the eternity
service is rarely used.
Definitely--this is always a good idea, right?
Yes.  Massey and Maurer did a Journal of Cryptography paper
titled ``The Importance of Being First,'' which says that
in any chain of encryptions with different ciphers and
independent keys, such as E_1(E_2(E_3(data))), the whole
thing is provably as strong as the first cipher used on the
data (E_3, in my example above).  This is really obvious,
when you reflect that an attacker can always try to break
data encrypted with E_3 by superencrypting it with E_1 and
E_2, and then mounting his attack on E_1(E_2(E_3(data))).
Of course, if keys aren't independent among the three
ciphers, then you don't get any guarantee of this kind.
The other thing to note is that if you're just generating
keystream sequences, as you would with RC4 or SEAL, then all
ciphers are ``first.''
Rivest and Sherman also did some work on randomized
encryption, of the kind you discuss, in the Crypto '82
proceedings.  Your construction is very similar to one of
theirs.  Let M = message and R = a message-sized random
number, then in
E_1(R), E_2(R XOR M)
both E_1 and E_2 must be broken to learn M.  (Imagine this
isn't the case, then either E_1 or E_2 wasn't broken.  If
you didn't break E_2 but broke E_1, then you only learn R,
which is useless to you--it's random and uncorrelated with
M.  If you broke E_2 but not E_1, you would have a message
encrypted with a one-time pad.)
This generalizes nicely to
E_1(R1), E_2(R2), ..., E_N(RN), E_{N+1}(R1 XOR R2 XOR ... XOR M).
If those random numbers are really random, then if any one
of those ciphers resists your attacks, the message can't be
Now, you can also do this with things that approximate
random functions, which they also discuss.  Thus, you might
f_1(),f_2(), ..., f_n() are N independently-keyed different
cryptographic functions that approximate random functions.
The funny thing is, if you instantiate this intelligently,
you get a message encrypted by N different stream ciphers,
perhaps with a random parameter per message thrown in during
keying of those ciphers.  Thus, suppose
s_1(K1) = RC4(K1)
s_2(K2) = 3DES-OFB(K2)
s_3(K3) = SHA1-Counter-Mode(K3)
s_4(K4) = Blowfish-OFB(K4)
s_5(K5) = SAFER-SK128(K5).
and that these keys are different per message and are all
independent.  Then, you get the result that
M XOR s_1(K1) XOR S_2(k2) XOR ... XOR s_5(k5).
leaves no way to recover M unless all five s_i() can be
Note that, in practice, this isn't likely to be useful
unless you've done the same kind of thing for symmetric key
distribution, random number generation, etc.  Otherwise,
your attacker in 2050 will bypass the symmetric encryption
entirely and factor your RSA modulus, or guess all the
entropy sources used for your PRNG, or whatever else you can
think of.
The good news, though, is that active attacks (like chosen
input attacks) and many side-channel attacks (e.g., timing
attacks) turn out not to be possible if you are trying to
mount them after the encryption has been carried out.

@_date: 1998-01-26 10:21:35
@_author: John Kelsey 
@_subject: Why no "Banner Ad Eaters"? 
[ To: cypherpunks  Date: 01/25/98   Subject: Re: Why no "Banner Ad Eaters"? ]
Note that there's a difference in incentives, here, too.
Porn sites in most countries, including the US, have some
strong legal and social incentives to rate themselves
honestly, and probably have relatively little financial
incentive to rate themselves inaccurately.  (Think of the
hassles you get with things like disputed credit card
payments made by someone's 14-year-old kid.)  This makes the
blocking software's job a lot easier.
I just can't see what incentive advertisers have to
co-operate with rating systems of this kind.  How would it
improve your bottom line?  Advertisers are likely to get
paid either on the basis of number of people who see the ad,
or on the basis of number of people who click on the ad.  In
either case, letting your ad be casually filtered out is
just not going to make you any money.  About the only
incentive I can see for letting your ads be blocked is the
desire not to make too many ad recipients mad at the
advertiser.  (Presumably, this is the reason why spam is
almost never used by reputable companies--they don't want to
make too many potential customers angry.)  But this doesn't
seem to apply to webpage ads, which manage not to be quite
intrusive enough to enrage their targets.
I assume that, sooner or later, the advertisements will be
woven in so well that it's all-but-impossible to get rid of
them without also getting rid of the useful content you're
trying to read/see/use.
[Good comments deleted.]
Maybe.  Either way, in the long run, ads that don't seem to
be generating sales aren't going to be renewed.  Being able
to count clicks gives you one metric for this; another is
completed sales from those clicks.  This defines why web
page owners that are making lots of ad revenue will have
lots of incentive to make people who use their services look
at and respond to their ads.  People will try various things
to make this happen.  If none of them work, then ad-supported
pages will cease to exist.
Many of the services now supported by ads have other good
revenue models.  Sites like Dejanews and Altavista have
enough name-recognition to do things like sell custom
searching or research from their Usenet and Web databases,
or provide statistical customer profiles that don't reveal
customer identities but are still of use to marketers.
Note:  I read CP-LITE instead of the whole list.  Please CC
       me on replies.

@_date: 1998-01-28 06:57:59
@_author: John Kelsey 
@_subject: future proofing algorithms 
[ To: Cypherpunks, Adam Back  Date: 01/26/98   Subject: future proofing algorithms ]
This is a good point.  The crypto looks like the strongest
link in the chain right now, but if it turns out not to be,
reliance on local physical security isn't a bad idea.
(This works only if the huge numbers of the local machines
must be subverted for an attack to work; if the attacker has
to take over only a couple machines, he can probably manage
this.)  Discovering a better way to bypass my physical
security today doesn't let you know who sent what last year,
and security guards don't become retroactively twice as
cheap to bribe every eighteen months.
Right.  I've seen some work done on this, mostly informally.
The basic result I'm aware of with hash functions is like
this:  Let f() and g() be two different hash functions,
such as SHA1 and RIPE-MD160.  Let X,Y be the concatenation
of X and Y.  Then:
Hash1(X) = f(X),g(X)
Hash2(X) = f(g(X)),g(f(X))
You can quickly convince yourself that Hash1(X) is at least
as resistant to collision as the stronger of f() and g(),
but it's only as resistant as the weaker of the two to
leaking information about X.  (That is, if f(X) just gives
you the low 160 bits of X, then Hash1(X) gives you the same
thing.)  Hash2() won't leak information unless both f()
and g() leak information about their inputs, but you can't
guarantee that it will be very good against collisions.
(That is, if f(X) = 0 for all X, then all possible X values
cause a collision in Hash2(X).)
If f() and g() are independent, and one of them
looks like a random function of X, then
Hash3(X) = f(X) XOR g(X)
looks pretty good.  But it's possible for either f() or g()
to be non-reversible without Hash3() being nonreversible.
(The obvious case occurs when you think of something like
f(X) = X
g(X) = encrypt_{knownKey}(X) XOR X.
Note that g() looks rather like some existing hash
functions, where encrypt() is a known function.
Right.  Choosing the PRNG well is important, but I suspect
that the real issue is going to be getting enough input
entropy.  If you can get 80 bits of real entropy today, you
have a reasonably secure system now, but NSA may not find
your system that secure in twenty years.
For resistance to cryptanalysis, we can use the same set of
stream ciphers as before.  If we run Blowfish, 3DES, and
SAFER-SK128 in OFB-mode, and XOR the streams together, we
get an output stream that's no easier to predict than the
weakest of the three ciphers used.
Entropy collection on a wide range of different machines,
without specialized hardware, is just a hard thing to do
well.  It's especially hard if you're postulating a
massively powerful attacker years in the future.
That sounds about right.  Note that LAMs and such can use
shared symmetric keys along with the public keys, so that an
attacker has to get both to defeat the system.  When the
number of mixes is small, maybe some informal
password-sharing at conferences might help this.  For LAMs,
some level of hand-carried key exchange can be used.  Then,
actual keys can be encrypted as
RSA(R_0), ElGamal(R_1) are sent
Previously shared secret key K_2 is known.
Session Key = SK = E_{K_2}(R_0) XOR E_{K_2}(R_2).
Also note that DH should probably be used with many
different prime moduli, to resist any massive precomputation
on one modulus.  Maybe each mix could have several
expensively-prepared Sophie Germaine primes, and senders
could randomly select one for DH or El Gamal encryption.
This would spread out a future attacker's resources, though
of course, the attacker's effort scales only linearly in the
number of (expensive to find) primes.
On the other hand, perhaps this is how NSA will pay their
employees' salaries once crypto becomes sufficiently
widespread:  They will start a search engine service on all
those archives of usenet/internet traffic for all these
years:  ``Check up on your political opponents' newsreading
habits.  Read the love letters of libertarian activists in
the 90s.  Find out whether Chief Justice Clarence Thomas
ever visits adult web sites these days.  *Only* at
 ''
It would actually be very funny if historians in a couple
centuries got access to the NSA's archives of recorded phone
calls, telegrams, and e-mails.  Imagine the odd assumptions
that would result, with history students having this image
of twentieth century america based on recorded phone calls
of anarchists, antiwar activists, civil rights activists,
communists, important politicians, mobsters, suspected
spies, and wealthy businessmen.
Note:  I read CP-LITE instead of the whole list.  Please CC
       me on replies.

@_date: 1998-02-01 15:11:34
@_author: John Kelsey 
@_subject: Chaining ciphers 
[ To: Cypherpunks  Date: 01/30/98   Subject: Re: Chaining ciphers ]
I believe Dave Wagner broke this, and posted his attack to
cypherpunks, a few months ago; if I recall correctly, his
attack reduced the final security of this to that of a
little more than one DES operation.  (The attack worked when
n=1.)  This reenforces what we already knew:  When you chain
multiple encryption algorithms, you can prove that your
result is no *weaker* than any one of those algorithms, but
that doesn't mean it's any *stronger* than the strongest of

@_date: 1998-09-18 12:47:47
@_author: John Kelsey 
@_subject: Questions for Magaziner? 
and the
on these
Here's a question I would like to ask, in a rather rough form:
There has been a lot of talk by the administration about ``striking a
balance'' between citizens privacy concerns and the interests of police and spy
Can you give us some concrete examples of what tradeoffs between
these two you
consider reasonable?  For example, what benefits to society would be
worth making
all private communications available to the FBI or NSA?  Would it be
a worthwhile
trade to the citizens of the US if we could double the street price
of cocaine, at the cost of essentially all phone calls being recorded and subject to
monitoring at any time?  How about cutting the (already barely measureable) risk of
dying from a terrorist act in half?  My complaint with their rhetoric is that they always talk about these
tradeoffs and
about striking a balance, but we never seem to see any balance being
struck.  Striking
a balance means acknowledging that some societal benefits aren't
worth giving up our
privacy.  Will doubling the street price of cocaine improve my life
much?  It sure doesn't look like it will to me.  How about cutting my risk of dying
from a terrorist
act?  This is already much smaller than my risk of dying in a plane
crash; how much lower does it need to go?  (There is also the issue of whether any claimed
set of benefits
can be accomplished by key-escrow, or for that matter by putting a
videocamera and microphone in every home.  But that's a different issue.)
Of course, there are a bunch of problems with trying to analyze
violating fundamental
individual rights for some perceived social benefit, but I don't
think their basic argument can work, even if we grant that this sort of tradeoff is a legitimate
thing for governments
to do.  The tradeoffs we've seen offered have not given much weight
to citizens' desires for
privacy.  Consider the Clipper chip, the continued use of export
controls to slow down deployment of encryption in the US and
worldwide, the FBI's CALEA demands (including their
demand a few years ago to be able to listen in on 1/2% of all ongoing
calls in urban areas), etc.  We haven't seen any attempt to strike a balance so far, just an
attempt to claim some bureaucratic turf.
--John Kelsey, kelsey at counterpane.com / kelsey at plnet.net
NEW PGP print =  5D91 6F57 2646 83F9 6D7F 9C87 886D 88AF
