
@_date: 2011-12-12 02:46:23
@_author: Yosem Companys 
@_subject: [liberationtech] http://peoplesskype.org/ 
The People's SkypeA phone-powered, distributed voice and voting system for
the  Movement
call 917-719-2006  Share on Tumblr The People's Mic works well for small General Assemblies, but in larger
GAs, multiple echoes of the speaker's words is hard to follow.
The People's Skype can help! Call & create a new Mic.
Share the unique Mic PIN with others.
Use phone speakerphones to create a distributed PA system.
Listeners can vote by dialing on their phone's keypad.
Hundreds of people can listen and vote at the same time.
People's Skype can also help in special cases, like
communicating across police barriers or kettled areas.
Powered by Tropo  (the coolest),
MongoDB (also
cool), & PHP
Bug Reports, Suggestions, Complaints, etc.? jrbaldwin--at--gmail--d0t--c0m
Building Better Speech + Globe project by --
jrbaldwin --
Instructors: Melanie Crean + Chris Csikszentmihalyi
Parsons, the New School for Design. Creative Commons License: [image:
Creative Commons License]
liberationtech mailing list
liberationtech at lists.stanford.edu
Should you need to change your subscription options, please go to:
If you would like to receive a daily digest, click "yes" (once you click above) next to "would you like to receive list mail batched in a daily digest?"
You will need the user name and password you receive from the list moderator in monthly reminders.
Should you need immediate assistance, please contact the list moderator.
Please don't forget to follow us on

@_date: 2011-11-23 08:02:18
@_author: Yosem Companys 
@_subject: [liberationtech] Transcript of Richard Stallman's Lecture on Oct 19 
Richard Stallman:
Projects with the goal of digital inclusion are making a big assumption.
They are assuming that participating in a digital society is good; but
thatbs not necessarily true. Being in a digital society can be good or bad,
depending on whether that digital society is just or unjust. There are many
ways in which our freedom is being attacked by digital technology. Digital
technology can make things worse, and it will, unless we fight to prevent
Therefore, if we have an unjust digital society, we should cancel these
projects for digital inclusion and launch projects for digital extraction.
We have to extract people from digital society if it doesnbt respect their
freedom; or we have to make it respect their freedom.
 [Surveillance]
What are the threats? First, surveillance. Computers are Stalinbs dream:
they are ideal tools for surveillance, because anything we do with
computers, the computers can record. They can record the information in a
perfectly indexed searchable form in a central database, ideal for any
tyrant who wants to crush opposition.
Surveillance is sometimes done with our own computers. For instance, if you
have a computer thatbs running Microsoft Windows, that system is doing
surveillance. There are features in Windows that send data to some server.
Data about the use of the computer. A surveillance feature was discovered
in the iPhone a few months ago, and people started calling it the
bspy-phone.b Flash player has a surveillance feature too, and so does the
Amazon bSwindle.b They call it the Kindle, but I call it the Swindle
(lbescroc) because itbs meant to swindle users out of their freedom. It
makes people identify themselves whenever they buy a book, and that means
Amazon has a giant list of all the books each user has read. Such a list
must not exist anywhere.
Most portable phones will transmit their location, computed using GPS, on
remote command. The phone company is accumulating a giant list of places
that the user has been. A German MP in the Green Party asked the phone
company to give him the data it had about where *he* was. He had to sue, he
had to go to court to get this information. And when he got it, he received
forty-four thousand location points for a period of six months! Thatbs more
than two hundred per day! What that means is someone could form a very good
picture of his activities just by looking at that data.
We can stop our own computers from doing surveillance on us if we have
control of the software that they run. But the software these people are
running, they donbt have control over. Itbs non-free software, and thatbs
why it has malicious features, such as surveillance. However, the
surveillance is not always done with our own computers, itbs also done at
one remove. For instance ISPs in Europe are required to keep data about the
userbs internet communications for a long time, in case the State decides
to investigate that person later for whatever imaginable reason.
With a portable phone b even if you can stop the phone from transmitting
your GPS location, the system can determine the phonebs location
approximately, by comparing the time when the signals arrive at different
towers. So the phone system can do surveillance even without special
cooperation from the phone itself.
Likewise, the bicycles that people rent in Paris. Of course the system
knows where you get the bicycle and it knows where you return the bicycle,
and Ibve heard reports that it tracks the bicycles as they are moving
around as well. So they are not something we can really trust.
But there are also systems that have nothing to do with us that exist only
for tracking. For instance, in the UK all car travel is monitored. Every
carbs movements are being recorded in real time and can be tracked by the
State in real time. This is done with cameras on the side of the road.
Now, the only way we can prevent surveillance thatbs done at one remove or
by unrelated systems is through political action against increased
government power to track and monitor everyone, which means of course we
have to reject whatever excuse they come up with. For doing such systems,
no excuse is valid b to monitor everyone.
In a free society, when you go out in public, you are not guaranteed
anonymity. Itbs possible for someone to recognize you and remember. And
later that person could say that he saw you at a certain place. But that
information is diffuse. Itbs not conveniently assembled to track everybody
and investigate what they did. To collect that information is a lot of
work, so itbs only done in special cases when itbs necessary.
But computerized surveillance makes it possible to centralize and index all
this information so that an unjust regime can find it all, and find out all
about everyone. If a dictator takes power, which could happen anywhere,
people realize this and they recognize that they should not communicate
with other dissidents in a way that the State could find out about. But if
the dictator has several years of stored records, of who talks with whom,
itbs too late to take any precautions then. Because he already has
everything he needs to realize: bOK this guy is a dissident, and he spoke
with him. Maybe he is a dissident too. Maybe we should grab him and torture
him.b
So we need to campaign to put an end to digital surveillance now. You canbt
wait until there is a dictator and it would really matter. And besides, it
doesnbt take an outright dictatorship to start attacking human rights.
I wouldnbt quite call the government of the UK a dictatorship. Itbs not
very democratic, and one way it crushes democracy is using surveillance. A
few years ago, people believed to be on their way to a protest; they were
going to protest. They were arrested before they could get there, because
their car was tracked through this universal car tracking system.
 [Censorship]
The second threat is censorship. Censorship is not new, it existed long
before computers. But 15 years ago, we thought that the Internet would
protect us from censorship, that it would defeat censorship. Then, China
and some other obvious tyrannies went to great lengths to impose censorship
on the Internet, and we said: bwell thatbs not surprising, what else would
governments like that do?b
But today we see censorship imposed in countries that are not normally
thought of as dictatorships, such as for instance the UK, France, Spain,
Italy, Denmarkb&
They all have systems of blocking access to some websites. Denmark
established a system that blocks access to a long list of webpages, which
was secret. The citizens were not supposed to know how the government was
censoring them, but the list was leaked, and posted on WikiLeaks. At that
point, Denmark added the WikiLeaks page to its censorship list.
So, the whole rest of the world can find out how Danes are being censored,
but Danes are not supposed to know.
A few months ago, Turkey, which claims to respect some human rights,
announced that every Internet user would have to choose between censorship
and more censorship. Four different levels of censorship they get to
choose! But freedom is not one of the options.
Australia wanted to impose filtering on the Internet, but that was blocked.
However Australia has a different kind of censorship: it has censorship of
links. That is, if a website in Australia has a link to some censored site
outside Australia, the one in Australia can be punished.
Electronic Frontier Australia, that is an organization that defends human
rights in the digital domain in Australia, posted a link to a foreign
political website. It was ordered to delete the link or face a penalty of
$11,000 a day. So they deleted it, what else could they do? This is a very
harsh system of censorship.
In Spain, the censorship that was adopted earlier this year allows
officials to arbitrarily shut down an Internet site in Spain, or impose
filtering to block access to a site outside of Spain. And they can do this
without any kind of trial. This was one of the motivations for the*
Indignados*, who have been protesting in the street.
There were protests in the street in Turkey as well, after that
announcement, but the government refused to change its policy.
We must recognize that a country that imposes censorship on the Internet is
not a free country. And is not a legitimate government either.
[Restricted data formats]
The next threat to our freedom comes from data formats that restrict the
Sometimes itbs because the format is secret. There are many application
programs that save the userbs data in a secret format, which is meant to
prevent the user from taking that data and using it with some other
program. The goal is to prevent interoperability.
Now, evidently, if the program implements a secret format, thatbs because
the program is not free software. So this is another kind of malicious
feature. Surveillance is one kind of malicious feature that you find in
some non-free programs; using secret formats to restrict the users is
another kind of malicious feature that you also find in some non-free
But if you have a free program that handles a certain format, *ipso facto* that
format is not secret. This kind of malicious feature can only exist in a
non-free program. Surveillance features could theoretically exist in a free
program but you donbt find them happening. Because the users would fix it.
The users wouldnbt like this, so they would fix it.
In any case, we also find secret data formats in use for publication of
works. You find secret data formats in use for audio, such as music, for
video, for booksb& And these secret formats are known as Digital
Restrictions Management, or DRM, or digital handcuffs (les menottes
So, the works are published in secret formats so that only proprietary
programs can play them, so that these proprietary programs can have the
malicious feature of restricting the users, stopping them from doing
something that would be natural to do.
And this is used even by public entities to communicate with the people.
For instance Italian public television makes its programs available on the
net in a format called VC-1, which is a standard supposedly, but itbs a
secret standard.
Now I canbt imagine how any publicly supported entity could justify using a
secret format to communicate with the public. This should be illegal. In
fact I think all use of Digital Restrictions Management should be illegal.
No company should be allowed to do this.
There are also formats that are not secret but almost might as well be
secret, for instance Flash. Flash is not actually secret but Adobe keeps
making new versions, which are different, faster than anyone can keep up
and make free software to play those files; so it has almost the same
effect as being secret.
Then there are the patented formats, such as MP3 for audio. Itbs bad to
distribute audio in MP3 format! There is free software to handle MP3
format, to play it and to generate it, but because itbs patented in many
countries, many distributors of free software donbt dare include those
programs; so if they distribute the GNU+Linux system, their system doesnbt
include a player for MP3.
As a result if anyone distributes some music in MP3 thatbs putting pressure
on people not to use GNU/Linux. Sure, if youbre an expert you can find a
free software and install it, but there are lots of non experts, and they
might see that they installed a version of GNU/Linux which doesnbt have
that software, and it wonbt play MP3 files, and they think itbs the
systembs fault. They donbt realize itbs MP3b2s fault. But this is the fact.
Therefore, if you want to support freedom, donbt distribute MP3 files.
Thatbs why I say if youbre recording my speech and you want to distribute
copies, donbt do it in a patented format such as MPEG-2, or MPEG-4, or MP3.
Use a format friendly to free software, such as the Ogg format or WebM. And
by the way, if you are going to distribute copies of the recording, please
put on it the Creative Commons-No derivatives
This is a statement of my personal views. If it were a lecture for a
course, if it were didactic, then it ought to be free, but statements of
opinion are different.
 [Software that isn't free]
Now this leads me to the next threat which comes from software that the
users donbt have control over. In other words: software that isnbt free,
that is not blibreb. In this particular point French is clearer than
English. The English word free means blibreb and bgratuitb, but what I mean
when I say free software is blogiciel libreb. I donbt mean bgratuitb. Ibm
not talking about price. Price is a side issue, just a detail, because it
doesbnt matter ethically. You know if i have a copy of a program and I sell
it to you for one euro or a hundred euros, who cares?Why should anyone
think that thatbs good or bad? Or suppose I gave it to you bgratuitementbb&
still, who cares? But whether this program respects your freedom, thatbs
So free software is software that respects usersb freedom. What does this
mean? Ultimately there are just two possibilities with software: either the
users control the program or the program controls the users. If the users
have certain essential freedoms, then they control the program, and those
freedoms are the criterion for free software. But if the users donbt fully
have the essential freedoms, then the program controls the users. But
somebody controls that program and, through it, has *power* over the users.
So, a non-free program is an instrument to give somebody *power* over a lot
of other people and this is unjust power that nobody should ever have. This
is why non-free software (les logiciels privateurs, qui privent de la
libertC)), why proprietary software is an injustice and should not exist;
because it leaves the users without freedom.
Now, the developer who has control of the program often feels tempted to
introduce malicious features to *further* exploit or abuse those users. He
feels a temptation because he knows he can get away with it: because his
program controls the users and the users do not have control of the
program, if he puts in a malicious feature, the users canbt fix it; they
canbt remove the malicious feature.
Ibve already told you about two kinds of malicious features: surveillance
features, such as are found in Windows, and the Iphone and Flash player,
and the bSwindleb. And there are also features to restrict users, which
work with secret data formats, and those are found in Windows, Macintosh,
the Iphone, Flash player, the Amazon bSwindleb, the Playstation 3 and lots
and lots of other programs.
The other kind of malicious feature is the backdoor. That means something
in that program is listening for remote commands and obeying them, and
those commands can mistreat the user. We know of backdoors in Windows, in
the Iphone, in the Amazon bSwindleb. The Amazon bSwindleb has a backdoor
that can remotely delete books. We know this by observation, because Amazon
did it: in 2009 Amazon remotely deleted thousands of copies of a particular
book. Those were authorized copies, people had obtain them directly from
Amazon, and thus Amazon knew exactly where they were, which is how Amazon
knew where to send the commands to delete those books. You know which book
Amazon deleted? *1984* by Georges Orwell. Itbs a book everyone should read,
because it discusses a totalitarian state that did things like delete books
it didnbt like. Everybody should read it, but not on the Amazon bSwindleb.
Anyway, malicious features are present in the most widely used non-free
programs, but they are rare in free software, because with free software
the users have control: they can read the source code and they can change
it. So, if there were a malicious feature, somebody would sooner or later
spot it and fix it. This means that somebody who is considering introducing
a malicious feature does not find it so tempting, because he knows he might
get away with it for a while but somebody will spot it, will fix it, and
everybody will loose trust in the perpetrator. Itbs not so tempting when
you know youbre going to fail. And thatbs why we find that malicious
features are rare in free software, and common in proprietary software.
 [The 4 freedoms of free software]
Now the essential freedoms are four:
   - freedom 0 is the freedom to run the program as you wish.
   - Freedom 1 is the freedom to study the source code and change it, so
   the program does your computing the way you wish.
   - Freedom 2 is the freedom to help others. Thatbs the freedom to make
   exact copies and redistribute them when you wish.
   - Freedom 3 is the freedom to contribute to your community. Thatbs the
   freedom to make copies of your modified versions, if you have made any, and
   then distribute them to others when you wish.
These freedoms, in order to be adequate, must apply to all activities of
life. For instance if it says: bThis is free for academic use,b itbs not
free. Because thatbs too limited. It doesnbt apply to all areas of life. In
particular, if a program is free, that means it can be modified and
distributed commercially, because commerce is an area of life, an activity
in life. And this freedom has to apply to all activities.
Now however, itbs not obligatory to do any of these things. The point is
youbre free to do them if you wish, when you wish. But you never have to do
them. You donbt have to do any of them. You donbt have to run the program.
You donbt have to study or change the source code. You donbt have to make
any copies. You donbt have to distribute your modified versions. The point
is you should be free to do those things if you wish.
Now, freedom number 1, the freedom to study and change the source code to
make the program do your computing as you wish, includes something that
might not be obvious at first. If the program comes in a product, and a
developer can provide an upgrade that will run, then you have to be able to
make your version run in that product. If the product would only run the
developerbs versions, and refuses to run yours, the executable in that
product is not free software. Even if it was compiled from free source
code, itbs not free because you donbt have the freedom to make the program
do your computing the way *you* wish. So, freedom 1 has to be real, not
just theoretical. It has to include the freedom to use your version, not
just the freedom to make some source code that wonbt run.
 [The GNU project and the free software movement]
I launched the free software movement in 1983, when I announced the plan to
develop a free software operating system whose name is GNU. Now GNU, the
name GNU, is a joke; because part of the hackerbs spirit is to have fun
even when youbre doing something very serious. Now I canbt think of
anything more seriously important than defending freedom.
But that didnbt mean I couldnbt give my system a name thatbs a joke. So GNU
is a joke because itbs a recursive acronym, it stands for bGNU is Not
Unixb, so G.N.U.: GNUbs Not Unix. So the G in GNU stands for GNU.
Now in fact that was a tradition at the time. The tradition was: if there
was an existing program and you wrote something similar to it, inspired by
it, you could give credit by giving your program a name thatbs a recursive
acronym saying itbs not the other one.
So I gave credit to Unix for the technical ideas of Unix, but with the name
GNU, because I decided to make GNU a Unix-like system, with the same
commands, the same system calls, so that it would be compatible, so that
people who used Unix can switch over easily.
But the reason for developing GNU, that was unique. GNU is the only
operating system, as far as I know, ever developed for the purpose of
freedom. Not for technical motivations, not for commercial motivations. GNU
was written for *your* freedom. Because without a free operating system,
itbs impossible to have freedom and use a computer. And there were none,
and I wanted people to have freedom, so it was up to me to write one.
Nowadays there are millions of users of the GNU operating system and most
of them donbt*know* they are using the GNU operating system, because there
is a widespread practice which is not nice. People call the system bLinuxb.
Many do, but some people donbt, and I hope youbll be one of them. Please,
since we started this, since we wrote the biggest piece of the code, please
give us equal mention, please call the system GNU+Linux, or GNU/Linux. Itbs
not much to ask!
But there is another reason to do this. It turns out that the person who
wrote Linux, which is one component of the system as we use it
today, doesnbt agree with the free software movement. And so if you call
the whole system Linux, in effect youbre steering people towards his ideas,
and away from our ideas. Because hebs not gonna say to them that they
deserve freedom. Hebs going to say to them that he likes convenient,
reliable, powerful software. Hebs going to tell people that those are the
important values.
But if you tell them the system is GNU+Linux b the GNU operating system
plus Linux the kernel b then theybll know about us, and then they might
listen to what *we* say. You deserve freedom, and since freedom will be
lost if we donbt defend it b therebs always going to be a Sarkozy to take
it away b we need above all to teach people to demand freedom, to be ready
to stand up for their freedom the next time someone threatens to take it
Nowadays, you can tell who doesbnt want to discuss these ideas of freedom
because they donbt say blogiciel libreb. They donbt say blibreb, they say
bopen sourceb. That term was coined by the people like Mr Torvalds who
would prefer that these ethical issues donbt get raised. And so the way you
can help us raise them is by saying libre. You know, itbs up to you where
you stand, youbre free to say what you think. If you agree with them, you
can say open source. If you agree with us, show it: say libre!
 Free software and education
Now the most important point about free software is that schools *must* teach
exclusively free software. All levels of schools from kindergarten to
university, itbs their *moral*responsibility to teach only free software in
their education, and all other educational activities as well, including
those that say that theybre spreading digital literacy. A lot of those
activities teach Windows, which means theybre teaching *dependence*. To
teach people the use proprietary software is to teach dependence, and
educational activities must never do that because itbs the opposite of
their mission. Educational activities have a social mission to educate good
citizens of a strong, capable, cooperating, independent and free society.
And in the area of computing, that means: teach free software. Never teach
a proprietary program because thatbs inculcating dependence.
Why do you think some proprietary developers offer gratis copies to
schools? They want the schools to make the children dependent. And then,
when they graduate, theybre still dependent and you know the company is not
going to offer them gratis copies. And some of them get jobs and go to work
for companies. Not many of them anymore, but some of them. And those
companies are not going to be offered gratis copies. Oh no! The idea is if
the school directs the students down the path of permanent dependence, they
can drag the rest of society with them into dependence. Thatbs the plan!
Itbs just like giving the school gratis needles full of addicting drugs,
saying binject this into your students, the first dose is gratis.b Once
youbre dependent, then you have to pay. Well, the school would reject the
drugs because it isnbt right to teach the students to use addictive drugs
and itbs got to reject the proprietary software also.
Some people say bletbs have the school teach both proprietary software and
free software, so the students become familiar with both.b Thatbs like
saying bfor the lunch lets give the kids spinach and tabacco, so that they
become accustomed to both.b No! The schools are only supposed to teach good
habits, not bad ones! So there should be no Windows in a school, no
Macintosh, nothing proprietary in the education.
But also, for the sake of educating the programmers. You see, some people
have a talent for programming. At ten to thirteen years old, typically,
theybre fascinated, and if they use a program, they want to know bhow does
it do this?b But when they ask the teacher, if itbs proprietary, the
teacher has to say bIbm sorry, itbs a secret, we canbt find out.b Which
means education is forbidden. A proprietary program is the enemy of the
spirit of education. Itbs knowledge withheld, so it should not be tolerated
in a school, even though there may be plenty of people in the school who
donbt care about programming, donbt want to learn this. Still, because itbs
the enemy of the spirit of education, it shouldnbt be there in the school.
But if the program is free, the teacher can explain what he knows, and then
give out copies of the source code, saying: bread it and youbll understand
everything.b And those who are really fascinated, they will read it! And
this gives them an opportunity to start to learn how to be good programmers.
To learn to be a good programmer, youbll need to recognize that certain
ways of writing code, even if they make sense to you and they are correct,
theybre not good because other people will have trouble understanding them.
Good code is clear code, that others will have an easy time working on when
they need to make further changes.
How do you learn to write good clear code? You do it by reading lots of
code, and writing lots of code. And only free software offers the chance to
*read* the code of large programs that we really use. And then you have to
write lots of code, which means you have to write changes in large programs.
How do you learn to write good code for the large programs? You have to
start small, which does not mean small program, oh no! The challenges of
the code for large programs donbt even begin to appear in small programs.
So the way you start small at writing code for large programs is by writing
small changes in large programs. And only free software gives you the
chance to do that!
So, if a school wants to offer the possibility of learning to be a good
programmer, it needs to be a free software school.
But there is an even deeper reason, and that is for the sake of moral
education, education in citizenship. Itbs not enough for a school to teach
facts and skills, it has to teach the spirit of goodwill, the habit of
helping others. Therefore, every class should have this rule: bStudents, if
you bring software to class, you may not keep it for yourself, you must
share copies with the rest of the class, including the source code in case
anyone here wants to learn! Because this class is a place where we share
our knowledge. Therefore, bringing a proprietary program to class is not
permitted.b The school must follow its own rule to set a good example.
Therefore, the school must bring only free software to class, and share
copies, including the source code, with anyone in the class that wants
Those of you who have a connection with a school, itbs your duty to
campaign and pressure that school to move to free software. And you have to
be firm. It may take years, but you can succeed as long as you never give
up. Keep seeking more allies among the students, the faculty, the staff,
the parents, anyone!
And always bring it up as an ethical issue. If someone else wants to
sidetrack the discussion into this practical advantage and this practical
disadvantage, which means theybre ignoring the most important question,
then you have to say: bthis is not about how to do the best job of
educating, this is about how to do a good education instead of an evil one.
Itbs how to do education right instead of wrong, not just how to make it a
little more effective, or less.b So donbt get distracted with those
secondary issues, and ignore what really matters!
 Internet services
So, moving on to the next menace. There are two issues that arise from the
use of internet services. One of them is that the server could abuse your
data, and another is that it could take control of your computing.
The first issue, people already know about. They are aware that, if you
upload data to an internet service, there is a question of what it will do
with that data. It might do things that mistreat you. What could it do? It
could lose the data, it could change the data, it could refuse to let you
get the data back. And it could also show the data to someone else you
donbt want to show it to. Four different possible things.
Now, here, Ibm talking about the data that you knowingly gave to that site.
Of course, many of those services do *surveillance* as well.
For instance, consider Facebook. Users send lots of data to Facebook, and
one of the bad things about Facebook is that it shows a lot of that data to
lots of other people, and even if it offers them a setting to say bno!b,
that may not really work. After all, if you say bsome other people can see
this piece of information,b one of them might publish it. Now, thatbs not
Facebookbs fault, there is nothing they could do to prevent that, but it
ought to warn people. Instead of saying bmark this as only to your
so-called friends,b it should say bkeep in mind that your so-called friends
are not really your friends, and if they want to make trouble for you, they
could publish this.b Every time, it should say that, if they want to deal
with people ethically.
As well as all the data users of Facebook voluntarily give to Facebook,
Facebook is collecting through data about peoplebs activities on the net
through various methods of surveillance. But for now I am talking about the
data that people *know* they are giving to these sites.
Losing data is something that could always happen by accident. That
possibility is always there, no matter how careful someone is. Therefore,
you need to keep multiple copies of data that matters. If you do that,
then, even if someone decided to delete your data intentionally, it
wouldnbt hurt you that much, because youbd have other copies of it.
So, as long as you are maintaining multiple copies, you donbt have to worry
too much about someonebs losing your data. What about whether you can get
it back. Well, some services make it possible to get back all the data that
you sent, and some donbt. Google services will let the user get back the
data the user has put into them. Facebook, famously, does not.
Of course in the case of Google, this only applies to the data the user *
knows* Google has. Google does lots of surveillance, too, and that data is
not included.
But in any case, if you can get the data back, then you could track whether
they have altered it. And they are not very likely to start altering
peoplebs data if the people can tell. So maybe we can keep a track on that
particular kind of abuse.
But the abuse of showing the data to someone you donbt want it to be shown
to is very common and almost impossible for you to prevent, especially if
itbs a US company. You see, the most hypocritically named law in US
history, the so-called USA Patriot Act, says that Big Brotherbs police can
collect just about all the data that companies maintain about individuals.
Not just companies, but other organizations too, like public libraries. The
police can get this massively, without even going to court. Now, in a
country that was founded on an idea of freedom, there is nothing more
unpatriotic than this. But this is what they did. So you mustnbt ever trust
any of your data to a US company. And they say that foreign subsidiaries of
US companies are subject to this as well, so the company you are directly
dealing with may be in Europe, but if itbs owned by a US company, you got
the same problem to deal with.
However, this is mainly a concern when the data you are sending to the
service is not for publication. There are some services where you publish
things. Of course, if you publish something, you know everybody is gonna be
able to see it. So, there is no way they can hurt you by showing it to
somebody who wasnbt supposed to see it. There is nobody who wasnbt supposed
to see it if you publish it. So in that case the problem doesnbt exist.
So these are four sub-issues of this one threat of abusing our data. The
idea of theFreedom Box project  is
you have your own server in your own home, and when you want to do
something remotely, you do it with your own server, and the police have to
get a court order in order to search your server. So you have the same
rights this way that you would have traditionally in the physical world.
The point here and in so many other issues is: as we start doing things
digitally instead of physically, we shouldnbt lose any of our rights,
because the general tendency is that we do lose rights.
Basically, Stallmanbs law says that, in an epoch when governments work for
the mega-corporations instead of reporting to their citizens, every
technological change can be taken advantage of to reduce our freedom.
Because reducing our freedom is what these governments want to do. So the
question is: when do they get an opportunity? Well, any change that happens
for some other reason is a possible opportunity, and they will take
advantage of it if thatbs their general desire.
But the other issue with internet services is that they can take control of
your computing, and thatbs not so commonly known. But Itbs becoming more
common. There are services that offer to do computing for you on data
supplied by you b things that you should do on your own computer but they
invite you to let somebody elsebs computer do that computing work for you.
And the result is you lose control over it. Itbs just as if you used a
non-free program.
Two different scenarios but they lead to the same problem. If you do your
computing with a non-free program b well, the users donbt control the
non-free program, it controls the users, which would include you. So youbve
lost control of the computing thatbs being done. But if you do your
computing in his server b well, the programs that are doing it are the ones
he chose. You canbt touch them or see them, so you have no control over
them. He has control over them b maybe.
If they are free software and he installs them, then he has control over
them. But even he might not have control. He might be running a proprietary
program in his server, in which case itbs somebody else who has control of
the computing being done in his server. He doesnbt control it and you donbt.
But suppose he installs a free program, then he has control over the
computing being done in his computer, but you donbt. So, either way, you
donbt! So the only way to have control over your computing is to do it with
*your copy* of a free program.
This practice is called B+ Software as a Service B;. It means doing your
computing with your data in somebody elsebs server. And I donbt know of
anything that can make this acceptable. Itbs always something that takes
away your freedom, and the only solution I know of is to refuse. For
instance, there are servers that will do translation or voice recognition,
and you are letting them have control over this computing activity, which
we shouldnbt ever do.
Of course, we are also giving them data about ourselves which they
shouldnbt have. Imagine if you had a conversation with somebody through a
voice-recognition translation system that was Software as as Service and
itbs really running on a server belonging to some company. That company
also gets to know what was said in the conversation, and if itbs a US
company that means Big Brother also gets to know. This is no good.
The next threat to our freedom in a digital society is using computers for
voting. You canbt trust computers for voting. Whoever controls the software
in those computers has the power to commit undetectable fraud. Elections
are special. Because therebs nobody involved that we dare trust fully.
Everybody has to be checked, crosschecked by others, so that nobody is in
the position to falsify the results by himself. Because if anybody is in a
position to do that, he might do it! So our traditional systems for voting
were designed so that nobody was fully trusted, everybody was being checked
by others. So that nobody could easily commit fraud. But once you introduce
a program, this is impossible! How can you tell if a voting machine would
honestly count the votes? Youbd have to study the program thatbs running in
it during the election, which of course nobody can do, and most people
wouldnbt even know how to do. But even the experts who might theoretically
be capable of studying the program, they canbt do it while people are
voting. Theybd have to do it in advance, and then how do they know that the
program they studied is the one thatbs running while pople vote? Maybe itbs
been changed. Now, if this program is proprietary, that means some company
controls it. The election authority canbt even tell what that program is
doing. Well, this company then could rig the election. There are
accusations that this was done in the US in the past ten years, that
election results were falsified this way.
But what if the program is free software? That means the election authority
who owns this voting machine has control over the software in it, so the
election authority could rig the election. You canbt trust them either. You
donbt dare trust *anybody* in voting, and the reason is, therebs no way
that the voters can verify for themselves that their votes were correctly
counted, nor that false votes were not added.
In other activities of life, you can usually tell if somebody is trying to
cheat you. Consider for instance buying something from a store. You order
something, maybe you give a credit card number. If the product doesnbt
come, you can complain and you can b of course if you got a good enough
memory you will b notice if that product doesnbt come. Youbre not just
giving total blind trust to the store, because you can *check*. But in
elections you canbt check.
I saw once a paper where someone described a theoretical system for voting
which uses some sophisticated mathematics so that people could check that
their votes had been counted, even though everybodybs vote was secret, and
they could also verify that false votes hadnbt been added. It was very
exciting, powerful mathematics; but even if that mathematics is correct,
that doesnbt mean the system would be acceptable to use in practice,
because the vulnerabilities of a real system might be outside of that
mathematics. For instance, suppose youbre voting over the Internet and
suppose youbre using a machine thatbs a zombie. It might tell you that the
vote was sent for A while actually sending a vote for B. Who knows whether
youbd ever find out? In practice, the only way to see if these systems work
and are honest is through years, in fact decades, of trying them and
checking in other ways what happened.
I wouldnbt want my country to be the pioneer in this. So, use paper for
voting. Make sure there are ballots that can be recounted.
The war on sharing
The next threat to our freedom in a digital society comes from the war on
One of the tremendous benefits of digital technology is that it is easy to
copy published works and share these copies with others. Sharing is good,
and with digital technology, sharing is easy. So, millions of people share.
Those who profit by having power over the distribution of these works donbt
want us to share. And since they are businesses, governments which have
betrayed their people and work for the empire of mega-corporations try to
serve those businesses, they are against their own people, they are for the
businesses, for the publishers.
Well, thatbs not good. And with the help of these governments, the
companies have been waging *war* on sharing, and theybve proposed a series
of cruel draconian measures. Why do they propose cruel draconian measures?
Because nothing less has a chance of success: when something is good and
easy, people do it. The only way to stop them is by being very nasty. So of
course, what they propose is nasty, nasty, and the next one is nastier. So
they tried suing teenagers for hundreds of thousands of dollars b that was
pretty nasty. And they tried turning our technology against us, Digital
Restrictions Management that means, digital handcuffs.
But among the people there were clever programmers too and they found ways
to break the handcuffs. For instance, DVDs were designed to have encrypted
movies in a secret encryption format, and the idea was that all the
programs to decrypt the video would be proprietary with digital handcuffs.
They would all be designed to restrict the users. And their scheme worked
okay for a while. But some people in Europe figured out the encryption and
they released a free program that could actually play the video on a DVD.
Well, the movie companies didnbt leave it there. They went to the US
congress and bought a law making that software illegal. The United States
invented censorship of software in 1998, with the Digital Millennium
Copyright Act [DMCA]. So the distribution of that free program was
forbidden in the United States. Unfortunately it didnbt stop with the
United States. The European Union adopted a directive in 2003 requiring
such laws. The directive only says that commercial distribution has to be
banned, but just about every country in the European Union has adopted a
nastier law. In France, the mere possession of a copy of that program is an
offense punished by imprisonment, thanks to Sarkozy. I believe that was
done by the law DADVSI. I guess he hoped that with an unpronounceable name,
people wouldnbt be able to criticize it.
So, elections are coming. Ask the candidates in the parties: will you
repeal the DADVSI? And if not, donbt support them. You mustnbt give up lost
moral territory forever. Youbve got to fight to win it back.
So, we still are fighting against digital handcuffs. The Amazon bSwindleb
has digital handcuffs to take away the traditional freedoms of readers to
do things such as: give a book to someone else, or lend a book to someone
else. Thatbs a vitally important social act. That is what builds society
among people who read: lending books. Amazon doesnbt want to let people
lend books freely. And then there is also selling a book, perhaps to a used
bookstore. You canbt do that either.
It looked for a while as if DRM had disappeared on music, but now theybre
bringing it back with streaming services such as Spotify. These services
all require proprietary client software, and the reason is so they can put
digital handcuffs on the users. So, reject them! They already showed quite
openly that you canbt trust them, because first they said: byou can listen
as much as you like.b, and then they said: bOh, no! You can only listen a
certain number of hours a month.b The issue is not whether that particular
change was good or bad, just or unjust; the point is, they have the power
to impose any change in policies. So donbt let them have that power. You
should have your own copy of any music you want to listen to.
And then came the next assault on our freedom: HADOPI, basically punishment
on accusation. It was started in France but itbs been exported to many
other countries. The United States now demand such unjust policies in its
free exploitation treaties. A few months ago, Columbia adopted such a law
under orders from its masters in Washington. Of course, the ones in
Washington are not the real masters, theybre just the ones who control the
United States on behalf of the Empire. But theybre the ones who also
dictate to Columbia on behalf of the Empire.
In France, since the Constitutional Council objected to explicity giving
people punishment without trial, they invented a kind of trial which is not
a real trial, which is just a form of a trial, so they can *pretend* that
people have a trial before theybre punished. But in other countries they
donbt bother with that, itbs explicit punishment on accusation only. Which
means that for the sake of their war on sharing, theybre prepared to
abolish the basic principles of justice. It shows how thoroughly
anti-freedom anti-justice they are. These are not legitimate governments.
And Ibm sure theybll come up with more nasty ideas because theybre paid to
defeat the people no matter what it takes. Now, when they do this, they
always say that itbs for the sake of the artists, that they have bprotectb
the bcreators.b Now those are both propaganda terms. I bm convinced that
the reason they love the word bcreatorsb is because it is a comparison with
a deity. They want us to think of artists as super-human, and thus
deserving special privileges and power over us, which is something I
disagree with.
In fact , the only artists that benefit very much from this system are the
big stars. The other artists are getting crushed into the ground by the
heels of these same companies. But they treat the stars very well, because
the stars have a lot of clout. If a star threatens to move to another
company, the company says: boh, webll give you what you want.b But for any
other artist they say: byou donbt matter, we can treat you any way we like.b
So the superstars have been corrupted by the millions of dollars or euros
that they get, to the point where theybll do almost anything for more
money. For instance, J. K. Rowling is a good example. J. K. Rowling, a few
years ago, went to court in Canada and obtained an order that people who
had bought her books must not read them. She got an order telling people
not to read her books.
Herebs what happened. A bookstore put the books on display for sale too
early, before the day they were supposed to go on sale. And people came
into the store and said: boh, I want that!b and they bought it and took
away their copies. Then, they discovered the mistake and took the copies
off of display. But Rowling wanted to crush any circulation of any
information from those books, so she went to court, and the court ordered
those people not to read the books that they now owned.
In response, I call for a total boycott of Harry Potter. But I donbt say
you shouldnbt read those books or watch the movies, I only say you
shouldnbt buy the books or pay for the movies. I leave it to Rowling to
tell people not to read the books. As far as Ibm concerned, if you borrow
the book and read it, thatbs okay. Just donbt give her any money! But this
happened with paper books. The court could make this order but it couldnbt
get the books back from the people who had bought them. Imagine if they
were ebooks. Imagine if they were ebooks on the bSwindleb. Amazon could
send commands to erase them.
So, I donbt have much respect for stars who will go to such lengths for
more money. But most artists arenbt like that, they never got enough money
to be corrupted. Because the current system of copyright supports most
artists very badly. And so, when these companies demand to expand the war
on sharing, supposedly for the sake of the artists, Ibm against what they
want but I would like to support the artists better. I appreciate their
work and I realize if we want them to do more work we should support them.
 [Supporting the arts]
I have two proposals for how to support artists, methods that are
compatible with sharing. That would allow us to end the war on sharing and
still support artists.
One method uses tax money. We get a certain amount of public funds to
distribute among artists. But, how much should each artist get? We have to
measure popularity.
The current system supposedly supports artists based on their popularity.
So Ibm saying letbs keep that, letbs continue on this system based on
popularity. We can measure the popularity of all the artists with some kind
of polling or sampling, so that we donbt have to do surveillance. We can
respect peoplebs anonymity.
We get a raw popularity figure for each artist, how do we convert that into
an amount of money? The obvious way is: distribute the money in proportion
to popularity. So if A is a thousand times as popular as B, A will get a
thousand times as much money as B. Thatbs not efficient distribution of the
money. Itbs not putting the money to good use. Itbs easy for a star A to be
a thousand times as popular as a fairly successful artist B. If we use
linear proportion, webll give A a thousand times as much money as we give
B. And that means that, either we have to make A tremendously rich, or we
are not supporting B enough.
The money we use to make A tremendously rich is failing to do an effective
job of supporting the arts; so, itbs inefficient. Therefore I say: letbs
use the cube root. Cube root looks sort of like this. The point is: if A is
a thousand times as popular as B, with the cube root A will get ten times
as much as B, not a thousand times as much, just ten times as much. The use
of the cube root shifts a lot of the money from the stars to the artists of
moderate popularity. And that means, with less money we can adequately
support a much larger number of artists.
There are two reasons why this system would use less money than we pay now.
First of all because it would be supporting artists but not companies,
second because it would shift the money from the stars to the artists of
moderate popularity. Now, it would remain the case that the more popular
you are, the more money you get. So the star A would still get more than B,
but not astronomically more.
Thatbs one method, and because it wonbt be so much money it doesnbt matter
so much how we get the money. It could be from a special tax on Internet
connectivity, it could just be some of the general budget that gets
allocated to this purpose. We wonbt care because it wonbt be so much money;
much less than webre paying now.
The other method Ibve proposed is voluntary payments. Suppose each player
had a button you could use to send one euro. A lot of people would send it,
after all itbs not that much money. I think a lot of you might push that
button every day, to give one euro to some artist who had made a work that
you liked. But nothing would demand this, you wouldnbt be required or
ordered or pressured to send the money; you would do it because you felt
like it. But there are some people who wouldnbt do it because theybre poor
and they canbt afford to give one euro. And itbs good that they wonbt give
it, we donbt have to squeeze money out of poor people to support the
artists. There are enough non poor people whobll be happy to do it. Why
wouldnbt you give one euro to some artists today, if you appreciated their
work? Itbs too inconvenient to give it to them. So my proposal is to remove
the inconvenience. If the only reason not to give that euro is [that ] you
would have one euro less, you would do it fairly often.
So these are my two proposals for how to support artists, while encouraging
sharing because sharing is good. Letbs put an end to the war on sharing,
laws like DADVSI and HADOPI, itbs not just the methods that they propose
that are evil, their purpose is evil. Thatbs why they propose cruel and
draconian measures. Theybre trying to do something thatbs nasty by nature.
So letbs support artists in other ways.
 [Rights in cyberspace]
The last threat to our freedom in digital society is the fact that we donbt
have a firm right to do the things we do, in cyberspace. In the physical
world, if you have certain views and you want to give people copies of a
text that defends those views, youbre free to do so. You could even buy a
printer to print them, and youbre free to hand them out on the street, or
youbre free to rent a store and hand them out there. If you want to collect
money to support your cause, you can just have a can and people could put
money into the can. You donbt need to get somebody elsebs approval or
cooperation to do these things.
But, in the Internet, you do need that. For instance if want to distribute
a text on the Internet, you need companies to help you do it. You canbt do
it by yourself. So if you want to have a website, you need the support of
an ISP or a hosting company, and you need a domain name registrar. You need
them to continue to let you do what youbre doing. So youbre doing it
effectively on sufferance, not by right.
And if you want to receive money, you canbt just hold out a can. You need
the cooperation of a payment company. And we saw that this makes all of our
digital activities vulnerable to suppression. We learned this when the
United States government launched a bdistributed denial of service attackb [
DDoS ]
against WikiLeaks. Now Ibm making a bit of joke because the words
bdistributed denial of service attackb usually refer to a different kind of
attack. But they fit perfectly with what the United States did. The United
States went to the various kinds of network services that WikiLeaks
depended on, and told them to cut off service to WikiLeaks. And they did.
For instance, WikiLeaks had rented a virtual Amazon server, and the US
government told Amazon: bcut off service for WikiLeaks.b And it did,
arbitrarily. And then, Amazon had certain domain names such as as
wikileaks.org, the US government tried to get all those domains shut off.
But it didnbt succeed, some of them were outside its control and were not
shut off.
Then, there were the payment companies. The US went to PayPal, and said:
bStop transferring money to WikiLeaks or webll make life difficult for
you.b And PayPal shut off payments to WikiLeaks. And then it went to Visa
and Mastercard and got them to shut off payments to WikiLeaks. Others
started collecting money on WikiLeaks behalf and their account were shut
off too. But in this case, maybe something can be done. Therebs a company
in Iceland which began collecting money on behalf of WikiLeaks, and so Visa
and Mastercard shut off its account; it couldnbt receive money from its
customers either. Now, that business is suing Visa and Mastercard
apparently, under European Union law, because Visa and Mastercard together
have a near-monopoly. Theybre not allowed to arbitrarily deny service to
Well, this is an example of how things need to be for all kinds of services
that we use in the Internet. If you rented a store to hand out statements
of what you think, or any other kind of information that you can lawfully
distribute, the landlord couldnbt kick you out just because he didnbt like
what you were saying. As long as you keep paying the rent, you have the
right to continue in that store for a certain agreed-on period of time that
you signed. So you have some rights that you can enforce. And they couldnbt
shut off your telephone line because the phone company doesnbt like what
you said or because some powerful entity didnbt like what you said and
threatened the phone company. No! As long as you pay the bills and obey
certain basic rules, they canbt shut off your phone line. This is what itbs
like to have some rights!
Well, if we move our activities from the physical world to the virtual
world, then either we have the same rights in the virtual world, or we have
been harmed. So, the precarity of all our Internet activities is the last
of the menaces I wanted to mention.
Now Ibd like to say that for more information about free software, look at
GNU.org . Also look at fsf.org ,
which is the website of the Free Software Foundation. You can go there and
find many ways you can help us, for instance. You can also become a member
of the Free Software Foundation through that site. [b&] There is also the
Free Software Foundation of Europe fsfe.org . You can
join FSF Europe also. [b&]
[Auction of an badorable GNU.b Highest bid was b,420!]
This transcription was done  by: Loki,
ThC)rC(se, duthils, regisrob, mrMuggles, Moonwalker, Hugo b 1 unnamed
author. A *big thanks* to them! The transcription of Richard Stallmanbs
lecture, as well as the video, are licensed under the
3.0 license .
liberationtech mailing list
liberationtech at lists.stanford.edu
Should you need to change your subscription options, please go to:
If you would like to receive a daily digest, click "yes" (once you click above) next to "would you like to receive list mail batched in a daily digest?"
You will need the user name and password you receive from the list moderator in monthly reminders.
Should you need immediate assistance, please contact the list moderator.
Please don't forget to follow us on

@_date: 2011-11-26 18:22:02
@_author: Yosem Companys 
@_subject: [liberationtech] How the Next Generation Diaspora* Should Be Built 
How the Next Generation Diaspora* Should Be Built to Help High-Risk
*I. Introduction*
An online privacy activist recently asked me: Suppose you were to build the
next-generation Diaspora* b i.e., a secure, private, and decentralized
social network b how would you go about it?
The question is an important one, especially considering that many
projects preceded Diaspora* but failed to gain
along with the skepticism with which Diaspora* has been met in hacker
Hacker News has been particularly vicious, with attacks on Diaspora*bs
security and privacy code implementation from the get
go and
with criticism of the Diaspora*bs team ability (or lack thereof) to
implement its vision .
Criticism has also come from the mainstream media, where reporters have
wondered bwhatever happened to
Diaspora*b
and bwhatbs taking so
long,b
though building a secure, private, and decentralized social network were as
easy as building a centralized alternative like Facebook.  In this context,
credit should be given to the Diaspora* founders for trying to advance the
vision by learning from the mistakes past projects have made in this space.
*II. What is the goal?*
One of the first steps to undertake when answering the question posed by my
online privacy activist friend is to determine what the goal of such a
next-generation Diaspora* would be.  For example, if the goal is to gain
traction among mainstream users, as Diso creator Steve Ivy has
then the focus would not be so much on the merits of the technology at
ensuring security and privacy, as it would be on its ability to use
decentralization to overcome Facebookbs considerable network
As one of Liberationtech bs
coordinators, Ibm much more interested in the former than the latter, for
there are many people in the world who care about security, privacy, and
decentralization for its own sake, and there is a very compelling reason
for giving these people such a solution, i.e., their very lives depend on
it.  Before we delve into that topic, however, Ibd like to address the
question of how one would overcome Facebookbs network effects.
*III. How does one overcome Facebookbs network effects?*
As you may recall from economics, a network
effect is
the effect one user of a good or service has on the value of that product
to other people.  A network with a lot of people has more value than one
that has fewer people.  For example, if you are looking for a job, or
searching for people who share your interests, you are more likely to find
them in a larger network than in a smaller one.  Since people will choose
to join the larger network at the expense of the smaller one, one will
ultimately end up with one giant network, as barring some kind of niche
offering in smaller networks, one is unlikely to find any value in the
smaller networks as the number of users on those networks dwindles.
This process also illustrates how difficult it is to persuade one person to
switch from one network to another.  A person benefits from her
participation in a social network because she has ties on that network.
That personbs friends benefit from their participation in that network
because of their ties.  As such, to persuade someone to switch from one
network to another, you must not only persuade that person to make the
switch but also that personbs ties, thereby creating a chicken-and-egg
problem : That person will
switch only if her friends switch, and the friends will switch only if that
person switches.  Thus, overcoming network effects is a group problem, not
an individual one: You must create a social movement of sorts to encourage
people to switch from one social network to another, or at the very least,
create an information cascade
 orbandwagon effect  that
encourages people to switch.
For those who may be skeptical about the strength of Facebookbs network
effects, consider the following:
find that approximately 70% of users are concerned about their Facebook
privacy and security, yet according to a proprietary Forrester study only
4% quit Facebook for this reason.  In fact, nearly half of those who quit
Facebook do so because they were bored with Facebook or found a better
niche site elsewhere.  These numbers suggest the strength of Facebookbs
social network effect.  Given the seriousness of peoplebs security and
privacy concerns, one would expect a much larger number of people to quit.
Yet they donbt do so because quitting would mean losing touch with your
friends and other contacts on the Facebook network.
You may immediately notice, however, that this economics story is
one-sided: The assumption is that advantages in network size will create an
inexorable trend towards consolidation, yet the disadvantages in network
size that could create an equally strong or more powerful effect away from
consolidation is left unexplored.  We know, however, that such effects
exist.  Otherwise, how would MySpace have replaced Friendster in the first
place?  Or how would Facebook have replaced MySpace?
The question that arises then is the following: How does one overcome
Facebookbs network effect?  There is less research on overcoming network
effects than on their inevitability, but some possibilities immediately
come to mind.
*A. Deep Pockets*
One obvious possibility is that a competitor may come along with pockets
sufficiently deep enough to challenge the entrenched network.  Such a
competitor could spend considerable resources on marketing and advertising
to attract users to switch from the dominant network to the competing one.
Yet, as Google+bs experience has shown, this process may be neither
immediate nor successful.  The verdict is still out, but Google+bs recent
that deep pockets may not be enough to counter a leading networkbs network
*B. People Discovery*
A second promising alternative is people discovery, i.e., a social network
that enables you to meet people you donbt know.  Despite an extensive
academic literature that suggests that people are distrustful at meeting
strangers in real life, proprietary Mintel data suggests the opposite:
Nearly 50% of those surveyed say they would like to meet strangers online,
and many admit to bfriendingb strangers on a regular basis, including
women, who are generally assumed to be much more distrustful of strangers.
Web inventor Tim Berners-Lee sees people discovery, or stretching onebs
ties to meeting people who are different from
as the next social networking frontier, and companies have heeded the call,
as Altlybs transformation from a private social network to a
people-discovery engine named
Itbs unclear, however, whether people discovery will be sufficient to
overcome Facebookbs network effects, especially since Facebook has
sufficient resources to copy any social network innovation in this area to
its advantage.  Moreover, by virtue of Facebookbs larger pool of users, the
company should be in an ideal position to introduce people to others they
do not know.
As Twitter has shown, however, people discovery has the distinct advantage
of circumventing Facebookbs network effect.  If a new social network
focuses on people who want to meet those they donbt know, then those people
are also less likely to care whether their existing ties are on that new
network, since by definition they donbt care as much about their existing
ties as they do about establishing new ones.  Twitter has capitalized on
this insight, and Facebook has recognized it, as the latterbs ongoing
transformation from a private, close-tie, college-based campus network to a
public, weak tie, international network has
In economics, somehave
argued that countries pursue protectionism when they are poor and free
trade when they are rich.  Similarly, Facebook was for privacy as a small
network and is now for openness as a large one.
*C. Technical Superiority*
A third possibility is to find a technical feature (or set of features)
that are more valuable than those offered by the dominant network.  In
other words, one would focus on technical advantages that overcome the
social advantages created through network effects.  An example of this can
be found in how Google overcame Yahoo at
Google had a search algorithm that generated better results, and over time,
people gravitated to Google over Yahoo.
One example that comes to mind in the network space would be the
application of natural language
enable users to get more benefits out of their social network ties.
Facebook does this through filtering, albeit not as transparently as many
would like, leading thinkers like Eli
Pariser to
complain about the dangers of bfilter
bubbles.b
In fact, there is a battle brewing
 and Google+  in this area, as
natural language processing is seen as the potential driver for a new wave
of social network interactions.  Nevertheless, just as Google did to Yahoo,
it is entirely conceivable that a new network could come along with a
proprietary algorithm in natural language processing that could give it a
similar technical advantage over Facebook or Google+ in the social
networking marketplace.
Moreover, there are many unexplored innovations in this space:  While
computational researchers have made advancements in the study of syntax and
semantics ,
pragmatics  remains a relatively
black box, despite media hype to the contrary.  In fact, the most
sophisticated research in this area comes not from computer science but
from social network
the behavioral sciences.  Surprisingly, however, programmers have yet to
mine this extensive literature for behavioral insights with which to
construct better social networking sites.
*D. Total Institutions*
One final possibility comes from the realm of total
A total institution can be defined as a place of work and residence where a
great number of similarly situated people, cut off from the wider community
for a considerable time, together lead an enclosed, formally administered
round of life.  Examples of total institutions include monasteries, the
army, prisons, and psychiatric institutions, among many others.  Total
institutions are dense locations of activity, where ideas can spread
quickly, and thus they are ideal locations for fostering the growth of
social networking sites.
Youbre probably thinking: bThatbs crazy. Are you suggesting that we build a
social network out of an insane asylum?b  But before you discount the idea,
remember that this is exactly one of the reasons why Facebook became a
dominant player in social networking.  Facebook, in fact, capitalized on
the most influential total institution of Western society, i.e., the
college campus.  On college campuses, students work and live together, and
they share similar values and engage in similar activities, cut off from
the wider community for at least four years.  Facebookbs strategy, as I
have explained elsewhere,
focused on controlled growth and saturation from one college to the next.
To the extent that female students had privacy fears about joining
Facebook, these concerns were assuaged by the fact that Facebook only
allowed people who had university email addresses to join, such that the
number of potential whack jobs were limited to those that you knew on your
college campus, not those that you did not.  This may also help explain why
Facebook, unlike other social networking and dating sites, is predominantly
female, and why men b as even the Facebook founders themselves acknowledge
b were so attracted to joining Facebook in the first place.
This story raises the question:  Can a new social networking site challenge
Facebook by taking over college campuses again?  The answer to that is
unclear.  Facebook remains strong among college campuses, though the bulk
of its growth is now coming from older demographics, such that the
proportion of college students in the network has fallen.  You could say
that Facebookbs strategy has now shifted from the campus as a total
institution to the elderly home as a total institution.  At the same time,
college campus-specific social networks have been launched in recent years
but have made scarcely a dent on Facebookbs college-age numbers.
As such, a better question to ask is the following:  Are there other total
institutions out there that social networking entrepreneurs can tap into to
challenge Facebookbs dominance?  I donbt really have a good answer to this
question, so it remains rhetorical.  But to the extent that Diaspora* has
gotten more traction than other social networking sites, it is because it
has tapped into the free culture
, hackerspaces  and maker
and so on.  Similarly, though Silicon Valley has an aversion to politics, a
social networking site that is built out of movements such as
,WikiLeaks , or the Occupy
movement may
be able to attain significant traction, if timed properly.  In short, while
the number of pure total institutions in our society is limited, it is
clear from Diaspora*bs experience that a group-based social networking
recruitment approach may work better for social networking entrepreneurs
than the traditional individual-based approach they have followed to date.
*IV. Getting back to the task at hand*
Overcoming Facebookbs network effect, however, only matter to the extent
that you want to build traction to supplant Facebook.  But suppose youbre
not interested in traction.  Suppose that what you care about is to create
a secure, private, and decentralized Facebook alternative that
protects high-risk
activists fighting for freedom, democracy, and human rights in oppressive,
dangerous environments .  Then,
many of the mainstream usersb considerations drop out of the equation, and
the problem becomes much more focused and manageable b albeit still
difficult.  At the same time, however, mainstream users who care about
privacy and security can still use the solution, if they are so inclined.
As a Stanford liberationtech
 coordinator,
you can see why I would be so interested in such a solution.  The goal of
our program is to conduct research and design of information and
communication technologies to foster freedom, democracy, human rights,
development, and effective governance.  In other words, we want to figure
out ways in which technology can support the dangerous work that activists
conduct every day to create a better world.  A secure, private, and
decentralized communication platform would help support activist efforts to
this end.  And such a platform only needs traction among activists, not all
mainstream users, to succeed.  In other words, it needs to solve the
activist problem, not the mainstream userbs problem, to be most effective.
*A. Organizing versus broadcasting*
But, you may ask, arenbt movements like the Occupy movement, theArab
or the *Indignados  *more
interested in spreading the word?  As such, how can you give up on traction
in pursuit of this goal?  To answer these questions, it is important to
differentiate between what activists do *before* a movement and what they
do *during* a movement.  As my doctoral dissertation shows, before a
movement, an activist needs a private and secure platform to organize with
a small group of people.  These are the people who lay the groundwork for
what the movement is to become.  Authoritarian regimes understand this,
which is why they seek to stamp out the early-movers, and why they
immediately crack down on any signs of free assembly.  When groups of
people are able to assemble in such environments, thatbs when the regimebs
days are numbered.
If people are able to assemble, then the activistbs task changes from
organizing to spreading the word.  It is at this point that traction, or
the broadcast capabilities of a social networking site, become important.
But as we have seen, large mainstream social networking sites like Facebook
and Twitter are more effective at doing this task.  Once activists get to
the broadcasting stage, what becomes more important to them is to protect
their identities as they spread the movementbs message.  But the organizing
task is never completed.  The organizing task continues.  And it is this
organizing task that I care about most.  This critical organizing task is
done by a small group of people that need to be able to maintain strong
ties to one another in a secure and private fashion if they are to succeed.
This explanation starts to draw the raw schematic of what a next generation
Diaspora*-like private, secure, and distributed social network should look
like, if it is to achieve
Liberationtech ends.
The network should facilitate the communication of a small group of people
seeking to organize social change and subsequently enable them to broadcast
that message through larger mainstream social networking sites to generate
the strength-in-numbers that can help movements grow and ultimately bring
about political change.  In other words, it must be a secure and private
social networking site with
capabilities that can protect the anonymity of the person broadcasting
messages to the larger and more mainstream social networking sites.
*B. Decentralization*
So far, my emphasis has been on security and privacy alone.  But
decentralization is inextricably tied to security and privacy and equally
important.  What do we mean by decentralization?  Decentralization means
that instead of having to post a message to a central server like Facebook,
and then wait for that server to transfer that message (or not, in the case
of censorship) to your friend, you send that message to your friend
directly.  To achieve this, communication must be machine-to-machine, where
the sender controls the first machine and the recipient controls the
second, and the message that is transmitted is encrypted to ensure that
only the sender and the recipient can read it.  In other words, the sender
and recipient must have an easy and fast means to install and manage the
software on their machines b whether these machines are servers, computers,
or phones, as in the FreedomBox vision.
 Furthermore, the sender and the recipient must have the ability to stop
using their machines and seamlessly use new ones, should the original
machines be compromised for whatever reason by an authoritarian regime.
The software would need to have an easy bself-destruct mechanismb such that
the data can be destroyed immediately in an emergency.  At the same time,
the bright to forgetb
would have to be embedded from the get go, such that the data would self
destruct after a certain period of time to prevent a trail of communication
that would make it easy for an authoritarian regime to track down the
activists.  As such, the next generation of secure, private, and
decentralized social networking site would create a one-click turnkey
solution for activists that could easily be discarded if compromised and
whose data could be destroyed automatically as the utility of the data
diminishes while organizing unfolds.
*C. Mobility*
There is one final consideration.  Activists are constantly on the move,
such that the social networking site will need to be mobile from the get go
and have the capability of synchronizing data on multiple machines
simultaneously.  Thus, if the activist needs to coordinate with others
elsewhere, she must have the capability to access her data from the
alternate location.  Similarly, there will be times when the activist will
attend a street protest, and the relevant social networking data will need
to be accessible on her phone.  Other times, the activist will need to go
to a bsafe house b and access her
data from there.
Moreover, connectivity will vary greatly.  At times the activist may have
access to broadband Internet, but other times, she may need to connect via
a 56K modem, a mobile connection, a mesh
or perhaps even a satellite link.  The social networking site will need to
be accessible regardless of the connectivity, which means significant work
on data compression  will be
required to ensure that the softwarebs performance remains nimble under
such disparate conditions.  This creates difficult challenges for the
developers of such an application that developers of mainstream
applications would never have to encounter.
*D.  Cooperative*
So how does one draw the necessary resources required to overcome the
aforementioned challenges of security, privacy, decentralization, and
mobility to build such a social networking site?  Western society gives us
two main legal-institutional vehicles for tackling the problem:  i) a
for-profit firm a la limited liability
 or C corporation ; or ii) a
non-profit firm a la private
 or 501(c) organization .
 (Another possibility is a hybrid for-profit/non-profit model a la
 or Mozilla , but letbs set that
aside for now.)  In either case, a group of individuals b usually, the
founders b become owners of the organization and raise the necessary
resources needed to execute the organizationbs mission, implement its
strategies, and reach its goals.
A for-profit organization like a C-Corp is ideally suited for the task
because the founders can sell an ownership stake in the firm in order to
raise the requisite resources.  But as the saying goes, therebs no such
thing as a free lunch.  The resources come at a cost in terms of the
organization having to perform in a reliable and accountable fashion
relative to the expectations of its shareholders.  In the pursuit of
profit, principle can easily be abandoned since, at the end of the day, all
the shareholders care about is obtaining superior returns relative to what
they could receive by investing elsewhere.  If the firm is able to secure
superior returns, however, other prospective investors will be attracted to
the investment opportunity, thereby providing the organization with the
resources to grow over time.  In the end, shareholders matter more than
customers b and for our purposes, the activists risking their lives for
freedom, democracy, and human rights b for without the shareholders there
is no business.
On the surface, a non-profit organization looks better on principle grounds
because the organization is not acting on the basis of profit alone.
 Nevertheless, a non-profit organization is still owned by a small group of
individuals, and as in the case of a for-profit firm, controlled by its
board of directors, which means all decisions with respect to the
organization and its customers b or in this case, activists b are made by
the board.  This means that, in both the for-profit and non-profit cases,
the product at the end of the day is determined by decisions resulting from
the good will and discretion of a small group of individuals.  Youbll
probably be surprised to hear that itbs often also the case for open-source
projects like Diaspora*.  As Karl Fogelbs book bProducing Open
Source Software: How to Run a Successful Free Software
Projectb teaches,
most open-source projects are run by bbenevolent
dictatorsb
in whom bfinal decision-making authority restsb and bwho, by virtue of
personality and experience, is expected to use it wisely.b Even in the case
where the project isAffero General Public License (or
the benevolent dictator can make decisions that can prevent the right
technologies from being implemented over the course of the project.  The
project may even create disincentives for open-source involvement by
creating restrictive intellectual property (IP) assignment contracts that
require developers to give up all rights to the code they produce.  And
worse, a non-profit organization cannot sell shares, which means that there
are no financial incentives other than the generosity of donors to raise
the resources required to develop it.
So to summarize, on the one hand, therebs the for-profit firm that can sell
shares to raise the necessary revenues to develop a product but in many
cases may sell out principle in pursuit of profit, and on the other hand,
therebs the non-profit firm that has to depend on donations but, as in its
for-profit counterpart, still makes the activists beholden to the actions
of a few individuals.  Given this predicament, what are we to do to ensure
that the organization is accountable to the activists it serves and can
mobilize developers to contribute in an open-source manner to the project?
 One possibility is the cooperative,
a business organization owned and controlled democratically by its members
for mutual benefit.  The cooperative can range from for-profit to
non-profit, depending on the projectbs ultimate goals.  Thus, while the
cooperative is not a magical solution to all of the aforementioned
problems, it can help ameliorate many of them, when correctly designed and
The advantage of the cooperative for purposes of the task at hand is that
it can ensure that the organization operates in a democratic and
accountable fashion relative to the developers who contribute the code to
solve the aforementioned technical challenges and relative to the activists
who risk their lives using the technology to do their jobs on the field.
 The developers can transfer their IP rights to the cooperative, knowing
that such rights will not be exploited for financial gain without them.
 Similarly, the activists can know that the organization has their best
interest at heart and thus can trust that the solution will be built and
subsequently developed with their needs and concerns in mind.
*V. Conclusion*
So in response to my online privacy activist friendbs question about how I
would build the next-generation Diaspora*, my answer is this:  I would
create it first and foremost as a secure, private, distributed, and mobile
platform with HootSuite -like (but
anonymous) broadcast capabilities and fast and reliable performance under
rapidly changing conditions.  But I would make sure to work within a
cooperative legal-institutional framework to find the correct design that
makes the organization accountable both to its developers and customers,
i.e., the activists that the social networking site is meant to serve.
liberationtech mailing list
liberationtech at lists.stanford.edu
Should you need to change your subscription options, please go to:
If you would like to receive a daily digest, click "yes" (once you click above) next to "would you like to receive list mail batched in a daily digest?"
You will need the user name and password you receive from the list moderator in monthly reminders.
Should you need immediate assistance, please contact the list moderator.
Please don't forget to follow us on

@_date: 2011-09-23 08:58:19
@_author: Yosem Companys 
@_subject: [liberationtech] Fear of Repression Spurs Scholars and Activists to 
September 18, 2011
Fear of Repression Spurs Scholars and Activists to Build Alternate Internets
[image: College 2.0: Fear of Repression Spurs Scholars and Activists to
Build Alternate Internets 1]
Yana Paskova for The Chronicle
Eben Moglen, a law professor at Columbia U., is developing the Freedom Box,
a personal server that makes data harder to intercept. "The Net we have is
increasingly monitored, measured, and surveilled everywhere by everybody all
the time," he says. "Our Net has been turned against us."
Enlarge Image
By Jeffrey R. Young
Computer networks proved their organizing power during the recent uprisings
in the Middle East, in which Facebook pages amplified street protests that
toppled dictators. But those same networks showed their weaknesses as well,
such as when the Egyptian government walled off most of its citizens from
the Internet in an attempt to silence protesters.
That has led scholars and activists increasingly to consider the Internet's
wiring as a disputed political frontier.
For example, one weekend each month, a small group of computer programmers
gathers at a residence here to build a homemade Internetbnamed Project
Byzantiumbthat could go online if parts of the current global Internet
becomes blocked by a repressive government.
Using an approach called a "mesh network," the system would set up an
informal wireless network connecting users with other nearby computers,
which in turn would pass along the signals. The mesh network could tie back
into the Internet if one of the users found a way to plug into an unblocked
route. The developers recently tested an early version of their software at
George Washington University (though without the official involvement of
campus officials).
The leader of the effort, who goes by the alias TheDoctor but who would not
give his name, out of concern that his employer would object to the project,
says he fears that some day repressive measures could be put into place in
the United States.
 Enlarge Image[image:
College 2.0: Fear of Repression Spurs Scholars and Activists to Build
Alternate Internets 2]
He is not the only one with such apprehensions. Next month TheB-Doctor will
join hundreds of like-minded high-tech activists and entrepreneurs in New
York at an unusual conference called the Contact
One of the participants is Eben Moglen, a professor at Columbia Law School
who has built an encryption device and worries about a recent attempt by
Wisconsin politicians to search a professor's e-mail. The summit's goal is
not just to talk about the projects, but also to connect with potential
financial backers, recruit programmers, and brainstorm approaches to
building parallel Internets and social networks.
The meeting is a sign of the growing momentum of what is called the
"free-network movement," whose leaders are pushing to rewire online networks
to make it harder for a government or corporation to exert what some worry
is undue control or surveillance. Another key concern is that the Internet
has not lived up to its social potential to connect people, and instead has
become overrun by marketing and promotion efforts by large corporations.
At the heart of the movement is the idea that seemingly mundane technical
specifications of Internet routers and social-networking software platforms
have powerful political implications. In virtual realms, programmers
essentially set the laws of physics, or at least the rules of interaction,
for their cyberspaces. If it sometimes seems that media pundits treat
Facebook's Mark Zuckerberg or Apple's Steve Jobs as gods, that's because in
a sense they arebsitting on Mount Olympus with the power to hurl digital
thunderbolts with a worldwide impact on people.
Instead of just complaining, many of those heading to New York next month
believe they can build alternatives that reduce the power of those virtual
deities and give more control to mere mortals.
I was surprised by the number of homegrown Internet projects described on
the Contact Summit's Web sitebthough most of them are not yet operational,
and some may never be. Among the approaches: an alternative to Facebook that
promises better privacy control; a device that automatically scrambles
e-mail and Web traffic so that only people authorized by the user can read
them; and various mesh-network efforts that can essentially create an
"Internet in a suitcase" to set up wherever unfettered Internet access is
Whether you see these techies as visionaries or paranoids, they highlight
the extent to which networks now shape nations.
"Anyone who cares about human rights anywhere should dedicate themselves to
building these systems," is how Yochai Benkler, co-director of the Berkman
Center for Internet and Society at Harvard University, put it when I asked
him about the trend.
 Bazaar 2.0
One organizer of the Contact Summit, Douglas Rushkoff, compares the
disruptive power of the Internet to the impact of bazaars in the Middle
In his latest book, *Program or Be Programmed* (OR Books), he argues that
the earliest bazaars helped transform feudal society by allowing vigorous
information sharingba low-tech peer-to-peer network. "Everyone was speaking
with everybody else, and about all sorts of things and ideas," he writes.
"All this information exchange allowed people to improve on themselves and
their situations," allowing craftsmen to form guilds and share techniques.
"As the former peasants rose to become a middle class of merchants and
craftsB-people, they were no longer dependent on feudal lords for food and
The Internet has created a bazaar 2.0, says Mr. Rushkoff, accelerating
information exchange and giving people the power to organize in new ways.
At least so far. Mr. Rushkoff argues that companies and governments are
gaining too much power, in ways that could limit communication in the
future. Facebook, for instance, is a centralized system that forces users to
run communications through its serversband, he observes, its main goal is to
make money by analyzing data about users and sharing that information with
"The Internet that we know and love is not up to the task of being both a
fully commercial network and a people's infrastructure," Mr. Rushkoff told
me. "The Net is not a marketing opportunitybit's something much bigger than
One idea: Create two parallel Internets, one run and optimized for banks and
entertainment giants (like Netflix, whose streaming movies take up more and
more of total bandwidth), and the other for academic research, civic
discourse, and independent artists. He points to Internet2, a high-speed
research network run by universities, as a step in the right direction. But
that network is available only on select campuses.
Perhaps other approaches will emerge that are designed to encourage the kind
of peer-to-peer trading of information that Mr. Rushkoff prefers. To
encourage that, the Contact Summit will organize a bazaar of its own, where
participants can seek supporters for their projects. The organizers plan to
award start-up grants to a few projects on the basis of a competition. "This
is a conference of doers and people looking for counsel and collaborators,"
Mr. Rushkoff explains.
He acknowledges that the crowd he is gathering can be hard to herd, though:
"There are people who are afraid to come to Contact because they think
they're going to be hacked or tracked or injected with something. There are
a lot of loonies out there."
 Protecting Privacy
One developer who is eager to go the summit is Mr. Moglen, the law
professor. He's leading the development of a device called the Freedom Box,
and though it doesn't look like muchba gadget the size of a paperback
bookbhe believes that it would be able to help Internet users preserve their
The concept: It's a personal server, which automatically scrambles digital
data to make them harder for unauthorized people to intercept. The idea is
to create a personal "cloud," or online storage space, for data before the
information is sent to standard e-mail or Web services.
Mr. Moglen and a team of programmers are developing the software under the
auspices of the FreedomBox Foundation, a nonprofit organization, and plan to
release it under an open license that lets anyone use and modify it. The
initial Freedom Box code is expected to hit the Web in the next week or two,
although it is more of a framework for developers at this point and lacks
most of the planned features.
For Mr. Moglen the work is part of a longtime mission. *The Chronicle* profiled
him  several years
ago, soon after he founded the Software Freedom Law Center and published
what he called *The dotCommunist Manifesto.*
In the manifesto, he argues that all software should be developed by groups
under free licenses rather than by companies out to make profit. Critics
have called his approach extreme and unworkable, but in some areas
open-source software has gained ground in recent years.
"The Net we have is increasingly monitored, measured, and surveilled
everywhere by everybody all the time, or at least by somebody who's doing it
for somebody else and would answer a subpoena if they got one," he argued at
a conference this year. "Our Net has been turned against us."
In an interview, Mr. Moglen emphasizes that professors in particular should
send their communications through his device. The reason? "Two words:
William Cronon."
Mr. Cronon, a history professor at the University of Wisconsin at Madison,
was recently the subject of an unusual public-records request by a political
group. The Republican Party of Wisconsin asked the university to turn over a
batch of e-mail messages by the professor containing certain keywords, as *The
Chronicle* reported,
he wrote a blog post examining how conservative groups had helped craft
controversial legislation, including the 2011 measure to strip Wisconsin
public employees of collective-bargaining rights.
Mr. Cronon believes that Republican officials were hunting for evidence that
he had violated state law by using his state-university account for
political speech, which he denies doing. He says other professors might be
discouraged from speaking publicly on controversial issues, for fear their
e-mail messages, too, might be sought by critics.
Some free-Internet projects have been under development for some time, and
many professors and business leaders have long encrypted their e-mail
messages. But there is a new emphasis on making such systems easier to use
and bringing them to a wider audience, says Sascha Meinrath, director of the
Open Technology Initiative at the New America Foundation.
"We're trying to move them out of the geekosphere and get them into
mainstream use," he told me.
And there's evidence of that happening. This summer the foundation received
a $2-million grant from the State Department to build its own mesh network,
which could be set up by dissidents abroad to avoid censors. That's the
system being called an "Internet in a suitcase."
Proponents of mesh projects like Byzantium say they can provide a different
kind of Internet freedomba connection that comes at no cost. Potentially,
mesh networks could be set up and shared as free community networks.
For activists like TheDoctor, that kind of freedom can give low-income users
a chance to access information that could help improve their lives.
"If a single Byzantium node gave a single person access to MIT's open
courseware," he says, "the whole project would be a success."
College 2.0 covers how new technologies are changing colleges. Please send
ideas tojeff.young at chronicle.com or  on Twitter.
liberationtech mailing list
liberationtech at lists.stanford.edu
Should you need to change your subscription options, please go to:
If you would like to receive a daily digest, click "yes" (once you click above) next to "would you like to receive list mail batched in a daily digest?"
You will need the user name and password you receive from the list moderator in monthly reminders.
Should you need immediate assistance, please contact the list moderator.
Please don't forget to follow us on

@_date: 2012-08-22 22:35:28
@_author: Yosem Companys 
@_subject: [liberationtech] Introducing 'Tent' - The decentralized social web 
The founder is a friend of the late Ilya Zhitomirskiy and a member of
this list...
"Introducing 'Tent' - The decentralized social web"
  (tent.io)
   "Tent is a new protocol for open, distributed social networking.  What
    we believe - The Tent Manifesto What makes Tent different?  Tent is
    decentralized, not federated or centralized. Any Tent server can
    connect to any other Tent server. All features are available to any
    server as first-class citizens. Anyone can host their own Tent server.
    Tent servers can also be run as Tor hidden services to create a social
    darknet for at-risk organizers and activists. Anyone can write
    applications that connect to Tent in order to display or create user
    content.  Relationships are between users, independent of their
    service providers, so users take their data and relationships with
    them when they change Tent service providers. Every user decide which
    other users can follow them and what information will be shared with
    each of their followers."
Unsubscribe, change to digest, or change password at:

@_date: 2012-08-22 23:16:13
@_author: Yosem Companys 
@_subject: [liberationtech] The Dictator's Practical Guide to Internet Power 
The Dictator's Practical Guide to Internet Power Retention, Global
By Cory Doctorow  at 8:57 pm
Wednesday, Aug 22
The Dictator's Practical Guide to Internet Power Retention, Global
Edition is
a wry little 45-page booklet that is, superfically, a book of practical
advice for totalitarian, autocratic and theocratic dictators who are
looking for advice on how to shape their countries' Internet policy to
ensure that the network doesn't loosen their grip on power.
Really, though, this is Laurier Rochon's very good critique of the state of
Internet liberation technologies -- a critical analysis of what works, what
needs work, and what doesn't work in the world of networked technologies
that hope to serve as a force for democratization and self-determination.
It's also a literal playbook for using technology, policy, economics and
propaganda to diffuse political dissent, neutralize opposition movements,
and distract and de-politicize national populations. Rochon's device is an
admirably compact and efficient means of setting out the similarities (and
dissimilarities) in the Internet control programs used by Singapore, Iran,
China, Azerbaijan, and other non-democratic states -- and the programs set
in place by America and other "democratic" states in the name of fighting
Wikileaks and piracy. Building on the work of such fierce and smart critics
as Rebecca McKinnon (see my review of her book *Consent of the
), *The Dictator's Guide* is a short, sharp look at the present and future
of networked liberation.
Firstly, the country you rule must be somewhat "stable" politically.
Understandably "stable" can be defined differently in different contexts.
It is essential that the last few years (at least) have not seen too many
demonstrations, protests questioning your legitimacy, unrest, political
dissidence, etc. If it is the case, trying to exploit the internet to your
advantage can quickly backfire, especially if you can't fully trust your
fellow party officials (this is linked to condition  Many examples of
relatively stable single-leader states exist if in need of inspiration,
Fidel Castro's Cuba for example. Castro successfully reigned over the
country for decades, effectively protecting his people from
counter-revolutionary individuals. He appointed his brother as the
commander in chief of Cuba's army and managed his regime using elaborate
surveillance and strict dissuasive mechanisms against enemies of the
state.[49] As is always the case, political incidents will occur and test
your regime's resilience (the Bay of Pigs invasion or the missile crisis,
for example), but even massive states have managed to uphold a single-party
model and have adapted beautifully to the digital age - in China's case,
despite close to 87 000 protests in 2005.[2] Follow these states' example
and seek stability, no matter what your regime type is. Without it, you are
jeopardizing the two next prerequisites and annihilating your chances to
rule with the internet at your side. If you are in the midst of an
important political transformation, busy chasing counter-revolutionary
dissidents or sending your military to the streets in order to educate
protesters, you will need to tame these fires first and come back to this
guide afterwards.
The Dictator's Practical Guide to Internet Power Retention, Global
Unsubscribe, change to digest, or change password at:

@_date: 2012-06-11 18:02:02
@_author: Yosem Companys 
@_subject: [liberationtech] TOMORROW - June 12 - Differential Privacy in the 
TITLE: Differential Privacy in the Real World: Imperfect Randomness and
Floating-Point Arithmetic
SPEAKER: Ilya Mironov Differential privacy, introduced by Dwork et al in 2006, has become a de
facto standard for definition of privacy for aggregate computations over
sensitive data. In this talk we consider two challenges in implementing
differential privacy that remarkably result in very similar procedures for
evaluating one basic differentially-private mechanism.
The first challenge is implementing differential privacy with access only
to a single imperfect source of randomness. It has been shown that
information-theoretic private-key encryption is impossible unless the
source of randomness is extractable (Bosley and Dodis, TCC'07). Somewhat
surprisingly, we show that the answer is reversed if the target notion of
security is differential privacy. We prove that an accurate and
differentially-private approximation to the Laplacian mechanism is feasible
even if the only source of randomness accessible to the mechanism is
semi-random (Santha-Vazirani).
Another problem area confronting implementations of differential privacy in
the real world is floating-point arithmetic. We demonstrate that all four
publicly available general-purpose systems for differential privacy are
vulnerable to the same attack exploiting the gap between mathematical
abstractions and their implementations. We also discuss a fix to the
problem, which coincides with the mechanism robust to imperfect randomness.
The talk is going to be self-contained, with all important concepts and
definitions introduced and developed as needed. The first part of the talk
is based on the joint work (to appear at CRYPTO'12) by Yevgeniy Dodis,
Adriana Lopez-Alt (both - NYU), and Salil Vadhan (Harvard, Stanford, and
TIME and PLACE
June 12 2012 (Tuesday) at 1630 hrs
Gates 463A
liberationtech mailing list
liberationtech at lists.stanford.edu
Should you need to change your subscription options, please go to:
If you would like to receive a daily digest, click "yes" (once you click above) next to "would you like to receive list mail batched in a daily digest?"
You will need the user name and password you receive from the list moderator in monthly reminders. You may ask for a reminder here: Should you need immediate assistance, please contact the list moderator.
Please don't forget to follow us on

@_date: 2012-03-08 21:17:04
@_author: Yosem Companys 
@_subject: [drone-list] New Meetup: Drone Journalism: Reporting from above 
[image: Meetup]   New Meetup
Drone Journalism: Reporting from above (with Wired's Chris Anderson,
Hacks and Hackers
 Added by Burt Herman
  Thursday, March 29, 2012
7:00 PM
 Storify
149 9th street, Suite 404
San Francisco, CA 94103
 Price: $10.00 per person
Pay online
  Will you attend?
  **Yes**
 98 spots left!
  2 Hacks and Hackers going, including:
 nicole martinelli
English-language editor & community manager at IJNet.org , a DC-based
 Burt Herman
I'm a longtime journalist who is taking the entrepreneurial path in this
time of...
   Drones aren't just for the miitary anymore. Remote-controlled flying
devices are becoming more widely available, and journalists have begun to
consider their use in reporting. That may or may not be a good thing, and
our panelists have strong opi...
Learn more
  Sponsored by Pearson  Follow us!   Add *info at meetup.com* to your address book to receive all Meetup emails
To manage your email settings, click here
Meetup, PO Box 4668  New York, New York 10163-4668
*Meetup HQ in NYC is hiring!* PRODID:-//Meetup//Meetup Events v1.0//EN
X-WR-CALNAME:Meetup Events
SUMMARY:Drone Journalism: Reporting from above (with Wired's Chris Anders
 on\, Occucopter)
DESCRIPTION:Hacks and Hackers\nThursday\, March 29 at 7:00 PM\n\nDrones a
 ren't just for the miitary anymore. Remote-controlled flying devices are
  becoming more widely available\, and journalists have begun to consider
 ...\n\nFee: Price: USD 10.00 per person\n\nDetails:  .hackshackers.com/events/55590572/
ORGANIZER;CN=Meetup Reminder:MAILTO:info at meetup.com
UID:event_55590572 at meetup.com
drone-list mailing list
drone-list at lists.stanford.edu
Should you need to change your subscription options, please go to:
If you would like to receive a daily digest, click "yes" (once you click above) next to "would you like to receive list mail batched in a daily digest?"
You will need the user name and password you receive from the list moderator in monthly reminders.
Should you need immediate assistance, please contact the list moderator.

@_date: 2012-05-07 10:17:03
@_author: Yosem Companys 
@_subject: [liberationtech] Information Technology and Homeland Security 
********************* CALL FOR PAPERS *************************
** **
SUBMISSION DUE DATE: *November 1, 2012*****
** **
SPECIAL ISSUE ON* Information **Technology and Homeland Security*
* *
*International Journal of E-Politics (IJEP)*
** **
Guest Editors:****
Prof. Christopher G. Reddick, University of Texas at San Antonio, USA  ****
Dr. Saqib Saeed, Bahria University Islamabad, Pakistan****
** **
Post 9/11 world has an enhanced focus on homeland security and as a result
huge investments have been done by governments to enhance the public
security. Advanced technological systems have been designed in countries to
improve monitoring, security, and control against a possible terrorist
attack. The focus of the proposed special issue is to analyze the political
implications of technology adoption for homeland security mechanisms. The
aim is to consider all relevant aspects of technology implications such as
citizenbs rights and privacy. The special issue explores implications and
issues with a view to suggesting appropriate strategies to improve the
system design by highlighting the political implications of technology.****
** **
OBJECTIVE OF THE SPECIAL ISSUE****
The objective of the proposed Special Issue is to highlight technology
design implications, user experiences and political implications of
technology usage for homeland security. Research contributions in this
special issue will provide guidelines for government agencies to better
understand the citizenbs perspective. The contents in this special issue
are of interest for researchers working in the domains of information
systems, human computer interaction, organizational science, and political
** **
RECOMMENDED TOPICS****
Topics to be discussed in this special issue include (but are not limited
to) the following:****
** **
   - Cost benefit studies of technology adoption for homeland security ****
   - Digital divide and technology adoption for citizen security****
   - Global politics and homeland security****
   - IT and effectiveness of security organizations****
   - Limitations, challenges and barriers to ICT adoption for government
   bodies****
   - Political, ethical, security, privacy, and legal issues****
   - Politics of the IT function and role in security organizations****
   - Precision and accuracy of homeland security IT infrastructure****
   - System design for homeland security applications****
   - User experiences with homeland security systems (e.g., body scanners,
   etc.)****
** **
SUBMISSION PROCEDURE****
Researchers and practitioners are invited to submit papers for this special
theme issue on *Information **Technology and Homeland Security on or
beforeNovember 1, 2012.
*All submissions must be original and may not be under review by another
publication. INTERESTED AUTHORS SHOULD CONSULT THE JOURNALbS GUIDELINES FOR
MANUSCRIPT SUBMISSIONS at
  All
submitted papers will be reviewed on a double-blind, peer review basis.
Papers must follow APA style for reference citations.**
** **
ABOUT *International Journal of E-Politics (IJEP)*
The *International Journal of E-Politics (IJEP)* establishes the
foundations of e-politics as an emerging interdisciplinary area of research
and practice, as well as offers a venue for publications that focus on
theories and empirical research on the manifestations of e-politics in
various contexts and environments. This journal encompasses diverse aspects
of e-politics, including: strategy, e-commerce, decision sciences,
marketing, economics, psychology, sociology, anthropology, media studies,
communication studies, women studies, black studies, political science,
philosophy, law, criminology, and ethics. ****
** **
This journal is an official publication of the Information Resources
Management Association    ****
** **
Editor-in-Chief*: *Dr. Celia Romm Livermore****
Published: Quarterly (both in Print and Electronic form)****
** **
The *International Journal of E-Politics (IJEP)* is published by IGI Global
(formerly Idea Group Inc.), publisher of the bInformation Science
Referenceb (formerly Idea Group Reference), bMedical Information Science
Referenceb, bBusiness Science Referenceb, and bEngineering Science
Referenceb imprints. For additional information regarding the publisher,
please visit  . ****
** **
All submissions should be should be directed to the attention of guest
** **
Prof. Christopher G. Reddick****
E-mail: Chris.Reddick at utsa.edu ****
University of Texas at San Antonio, USA              ****
** **
Dr. Saqib Saeed****
E-mail: saqib.saeed at gmail.com ****
Bahria University Islamabad, Pakistan
liberationtech mailing list
liberationtech at lists.stanford.edu
Should you need to change your subscription options, please go to:
If you would like to receive a daily digest, click "yes" (once you click above) next to "would you like to receive list mail batched in a daily digest?"
You will need the user name and password you receive from the list moderator in monthly reminders. You may ask for a reminder here: Should you need immediate assistance, please contact the list moderator.
Please don't forget to follow us on

@_date: 2012-11-07 18:20:31
@_author: Yosem Companys 
@_subject: [drone-list] Friday (11/9): Lives Under Drones: Civilian 
*Lives Under Drones: Civilian Consequences of Drone Warfare*
** **
A panel discussion on the civilian consequences of ****
the United States' drone program in Afghanistan, Pakistan, and Yemen ****
within the broader context of how the US conducts its political and
military operations in those countries****
* *
*Prof. Shahzad Bashir*****
(Stanford Religious Studies Professor and co-editor of  *Under the Drones:
Modern Lives in the Afghanistan-Pakistan Borderlands*)****
* *
*Medea Benjamin*****
(Co-founder of Code Pink and Global Exchange and author of *Drone Warfare:
Killing by Remote Control)*****
* *
*Prof. Robert Crews*****
(Stanford History Professor and co-editor of *Under the Drones: Modern
Lives in the Afghanistan-Pakistan Borderlands*)****
* *
*Omar Shakir*****
(3rd year Stanford Law student and co-author of the Stanford Law School
report "Living Under Drones: Death, Injury, and Trauma to Civilians from
Drone Practices in Pakistan")****
* *
*Friday, November 9, 2012,  4:15 PM*
Lane History Corner (Building 200), Room 205****
450 Serra Mall, Stanford****
** **
For more information,* *please visit antiwar.stanford.edu.****
** **
[Sponsored by Stanford Says No to War, Muslim Students Awareness Network,
Stanford NAACP, Stanford STAND, CDDRL Program on Human Rights, the Sohaib
and Sara Abbasi Program in Islamic Studies, Stanford Asian American
Activism Committee, Pakistanis at Stanford, and the Peninsula Peace and
Justice Center]****
** **
[image: Inline image 1]****
drone-list mailing list
drone-list at lists.stanford.edu
Should you need to change your subscription options, please go to:
If you would like to receive a daily digest, click "yes" (once you click above) next to "would you like to receive list mail batched in a daily digest?"
You will need the user name and password you receive from the list moderator in monthly reminders.
Should you need immediate assistance, please contact the list moderator.

@_date: 2012-11-07 18:23:48
@_author: Yosem Companys 
@_subject: [liberationtech] NSF grant opportunity 
I would like to invite you to learn more about NSF's Secure and
Trustworthy Cyberspace (SaTC) grants program.  SaTC provides grants
for research that a) makes theoretical and methodological
contributions to the SBE sciences and b) helps promote a secure and
trustworthy cyberspace.  Cybersecurity is a pressing national need for
which there are, as of 2012, new research resources in the Social,
Behavioral, and Economic (SBE) sciences directorate and which tap
resources in the Computer and Information Science and Engineering
(CISE) directorate.
In the past year, the SBE / SaTC program has, with co-funding from
CISE, provided over $15 million (over $6 million to small and
medium-sized projects) in funding for people in a range of social
sciences, including economics, psychology, sociology, political
science, communication research, science of organization, and
SaTC researchers can focus exclusively on social science matters
related to cybersecurity or can work with computer scientists.  For
instance, a purely social science topic of interest is international
norms with respect to cybersecurity / cyberwarfare.  For those
interested in working with computer scientists, the SaTC program is
holding a number of events to help social and computer scientists
discover mutually advantageous collaborations.
If you are interested in exploring the possibility of this line of
research, please feel free to look at the SaTC solicitation,
participate in the upcoming online cyber cafe in which CISE and SBE
scientists will discuss potential SaTC research, consider coming to
the SaTC PI meeting (even as a non-PI), and / or sign up for the SBE /
SaTC mailing list:
SaTC solicitation:
Cyber Cafe:  11:30-5:30 EDT, Fri. Nov. 2, 2012.  Learn more and register:
SBE / SaTC mailing list:
Send the following message text to LISTSERV at LISTSERV.NSF.GOV
SUBSCRIBE satcspi your_name
For example:
SUBSCRIBE satcspi John Wheeler
In addition to the cyber-cafe, there remain a limited number of SBE /
SaTC slots for the SaTC PI meeting, which can be attended by non-PI
social scientists interested in learning more about this line of
research.  This will be a major event with hundreds of participants.
Learn more:
Register:  Use the above site for conference and hotel reservation
links.  Use the case-sensitive registration code SaTC2012SBE when
Peter Muhlberger
SBE / Secure and Trustworthy Cyberspace Program Officer
National Science Foundation
pmuhlber at nsf.gov
Unsubscribe, change to digest, or change password at:

@_date: 2012-11-16 06:51:45
@_author: Yosem Companys 
@_subject: [liberationtech] Would this have worked better for Petraeus & 
What Petraeus & Broadwell *Should* Have Done
Remember, when trying to hide things from the FBI, no method is perfect,
especially when they're already on your trail. The following tools are
not 100% foolproof, but if employed early would have made for a much more
convoluted game of cat and mouse, and might even have concealed the amorous
activity long enough for the general and his fatal attraction to have
escaped unscathed.
* 1. PGP Encryption :* PGP stands
for "pretty good privacy," and that's exactly what it is. The service
encrypts data, like emails, which would have been another hurdle for the
FBI to jump through. If this method would have been used, it would have
forced Uncle Sam to deploy Trojan-style spyware onto Broadwellbs computer
to uncover the emails. With Google snitching the General out, PGP might not
have worked. For regular folks though, this tool is a good start.
*2. Hide Your IP:* Tools like Tor , an open
source method to conceal real IP addresses and Web browsing, would have
masked their IP address identification. Another is
an app that creates free, encrypted Virtual Private
between computers. Just use the VPN every time you log in, and don't log in
from your home IP, and you should be safer. Well, unless you're
*3. Disposable Email:* This message will self destruct after reading.
Really. If the General really was 007, or even 007-ish, he would have used
this method. Disposable email functions much like it sounds, with messages
that are deleted after reading. Disposable email services include
 and Mailinator , which were originally
designed to keep out spam, not the Feds.
*4. Don't Send Messages Online Period!* Keep it offline! If this was 1972,
short of the U.S. Postal Service intercepting their mail, this would have
been the ideal method, and some inquisitive papparazzi snapping a photo
would have been all they would have had to worry about. While the two
*did* spend
a good deal of time together in-person (Broadwell apparently traveled
overseas to Iraq and Afghanistan to visit Petraeus), they might have been
safer to keep the relationship in person only. The only truly private way
to use email? Don't!
Unsubscribe, change to digest, or change password at:

@_date: 2012-10-11 12:27:15
@_author: Yosem Companys 
@_subject: [liberationtech] Silent Circle to publish source code? 
Dan Gillmor   Phil Zimmerman told me yesterday
that Silent Circle (contrary to what you say in your post) will
publish source code.
Unsubscribe, change to digest, or change password at:

@_date: 2012-10-16 19:33:25
@_author: Yosem Companys 
@_subject: [liberationtech] Pakistan drone report talk in Baltimore/D.C.? 
I imagine you have heard about the report on drone strikes in Pakistan
put together by a team of law professors and students from NYU and
Standford ( We invited a professor
from NYU to talk at Hopkins about the report; she passed our invitation
along to folks at Stanford. The leader of the investigation, Professor
James Cavallaro, the Director of the International Human Rights and
Conflict Resolution Clinic at Stanford, and a law student, Omar Shakir,
who was on the team, are interested in coming. I'm wondering if there
might be interest in organizing a talk in Washington at the same time,
both to share the cost of bringing them and to make the trip more worth
their while. Do you know anyone at Georgetown or elsewhere who might be
Take care,
Joel Andreas
Associate Professor
Department of Sociology
East Asian Studies Program
Johns Hopkins University
3400 N. Charles Street
Baltimore, MD 21218
Unsubscribe, change to digest, or change password at:

@_date: 2012-10-21 01:46:20
@_author: Yosem Companys 
@_subject: [liberationtech] Code for America Open Data Hackathon 
Code for America's Data Deathmatch! Nov. 2rd/3rd, Fight Political
Corruption and Help Schools Work Smarter!
Are you a hacker, designer, or civic nerd who wants to fight political
corruption or thinks that our schools should work smarter? Choose your
focus, work with our government allies, and join Code for America for
a hackathon to improve the cities we live in. Webve opened datasets,
now available through well documented APIs, and have lined up a
blockbuster group of open data advocates standing ready to help you
build apps that will revolutionize the way citizens interact with
Data DeathMatch!
Nov 2nd, 2012: 6:30PM - 8PM (mixer, kickoff), Nov. 3rd 9AM - 7PM (hackathon)
Code for America HQ: 155 9th St, San Francisco, CA.
Sign-up: Guest Speakers:
Ann Ravel, Chair of Californiabs Fair Political Practices Commission
James Sanders, Innovation Manager for KIPP Bay Area Schools
Phil Trounstine, co-editor and publisher of Calbuzz
Kuang Chen, CEO of Captricity
Franklin Chien, CEO of LearnSprout
Alex Tran, Code for America Accelerator
How are we different than other hackathons? Webre bringing the experts
to YOU, to work on shiny, newly accessible data. If youbve ever wanted
to build a civic or education app with a real understanding of the
context behind the data, this is your chance.
What are we working with?
Government data: The Fair Political Practices Commission (FPPC) of
California (our statebs official watchdog that holds public officials
accountable) has recently taken the bold step to make the 2011
economic interest filings of some California officials available as
structured data, not just PDFs on a website. Stocks and houses and
gifts, oh my! You have the chance to raise the bar for all
transparency initiatives by creating new value out of this data.
Education Data: For developers looking to jump into the growing
educational technology market, LearnSprout offers a unique opportunity
to turbo charge your idea. The company has built the first-ever API
that allows you to tap into live data from a school or districtbs
Student Information System (SIS). This opens the door to countless
possibilities that before, would be impossible without access to live
Bonus: Prizes: $1000! Beer, breakfast, lunch, and dinner in the
amazing Code for America offices! Also, board games, ping pong and air
Unsubscribe, change to digest, or change password at:

@_date: 2012-09-03 01:45:29
@_author: Yosem Companys 
@_subject: [liberationtech] New policy directive for Internet Filtering in 
Dear Colleagues,
More bad news coming out from Pakistanb& so seemingly much talked about
Internet filtering system effectively gets an implementation through this
policy directive.
Best wishes
Unsubscribe, change to digest, or change password at:

@_date: 2012-09-09 01:36:00
@_author: Yosem Companys 
@_subject: [liberationtech] Amsterdam Privacy Conference 2012 
The Amsterdam Privacy Conference 2012 ( will be held
from 7-10 October: a four-day privacy conference with
interdisciplinarity and social relevance as spearheads. Topical issues
to take centre stage include cloud computing, privacy by design,
cookies, the economic value of personal data, social networks,
security and anti-terrorism measures, privacy and medical data,
consumersb perceptions and appraisal of privacy, privacy regulation
and the redefinition of privacy in a rapidly changing information
Many international experts from diverse disciplines will be speaking
at the conference: Alessandro Acquisti, renowned for his research into
the psychology behind and consumersb attitudes regarding their
privacy; Ross Anderson, IT specialist in security systems, including
those of medical record systems and smart meters; Jacob Applebaum, an
internationally acclaimed hacker who was involved in Wikileaks; Peter
Hustinx, chairman of the European Data Protection Supervisor; Sandra
Petronio, the originator of Communication Privacy Management theory;
and Priscilla Regan, author of the book, bLegislating Privacy:
Technology, Social Values and Public Policyb.
In addition, the conference is hosting over 30 specialist panels and
sessions that are sub- divided into six themes: Economics of Privacy,
Privacy and Security, Privacy in the Information Society, Privacy and
Technology, the Value and Principles of Privacy and Privacy and
Healthcare. There will also be sessions on the position of civil
rights organisations in the privacy discourse, presentations of
empirical research on consumersb behaviour with regard to their
personal data and a practical session: bring your own device and learn
how to hack. More than 150 academics with a large variety of
backgrounds will actively contribute to the conference by means of
presentations, panels and debates.
The opening day of the conference on Sunday 7 October features a
public lecture that also falls within the theme of the UvAbs 380th
anniversary year. The day will be opened by Dymph van den Boom, Rector
Magnificus of the UvA, and Lodewijk Asscher, Deputy Mayor of
Amsterdam. Helen Nissenbaum, who recently published the bestseller,
bPrivacy in Contextb, will give the public lecture, which examines the
role of privacy in modern society. Following this, a panel composed of
Jacob Kohnstamm, chairman of the Dutch Data Protection Authority and
the Article 29 Data Protection Working Party, Simon Davies, founder of
the civil rights organisation Privacy International, and Alma Whitten,
Google's Director of Privacy, will respond to the lecture and will
debate with each other and the audience. The lecture will be given in
the University Auditorium.
The programme of the remaining days will be held in the monumental
Felix Meritis building and the university library, both situated in
the centre of Amsterdam.
Conference registration at:  (students & PhD students:
b, 125; academics, civil servants & NGOs: b, 225; lawyers, notaries &
private sector: b, 550).
Unsubscribe, change to digest, or change password at:

@_date: 2013-02-11 15:26:22
@_author: Yosem Companys 
@_subject: [liberationtech] Stanford Security Seminar Tomorrow: Jay Lorch -- 
*Jay Lorch*  --  *Ensuring Private Access to Large-Scale Data in the Data
Tuesday, February 12, 2013
Talk at 4:30pm in Gates 463A
Recent events have shown online service providers the perils of possessing
private information about users. Encrypting data mitigates but does not
eliminate this threat: the pattern of data accesses still reveals
information. Thus, this talk will present Shroud, a general storage system
that hides data access patterns from the servers running it, protecting
user privacy. Shroud functions as a virtual disk with a new privacy
guarantee: the user can look up a block without revealing the block's
address. Such a virtual disk can be used for many purposes, including map
lookup, microblog search, and social networking. Shroud aggressively
targets hiding accesses among hundreds of terabytes of data. We achieve our
goals by adapting oblivious RAM algorithms to enable large-scale
parallelization. Specifically, we show, via new techniques such as
oblivious aggregation, how to securely use many inexpensive secure
coprocessors acting in parallel to improve request latency. Our evaluation
combines large-scale emulation with an implementation on secure
coprocessors and suggests that these adaptations bring private data access
closer to practicality.
Jacob R. Lorch has been a Researcher at Microsoft Research in Redmond, WA
for the last eleven years. Before that, he received his Ph.D. in Computer
Science from UC Berkeley in 2001 under the supervision of Alan Jay Smith.
Jacob's research focuses broadly on computer systems, with particular
emphasis on distributed systems, web security, cloud computing, and energy
management. In recent work, he has developed TrInc (NSDI 2009), a simple
piece of trusted hardware useful in securing a variety of distributed
systems; Memoir (IEEE S&P 2011), a framework for building stateful,
crash-resilient trusted modules; and GreenUp (NSDI 2012), a decentralized
system for maintaining the availability of machines while letting them save
energy by sleeping. His current work includes protecting user privacy when
using online services and simplifying the construction and deployment of
fault-tolerant systems.
Unsubscribe, change to digest, or change password at:

@_date: 2013-02-21 08:27:39
@_author: Yosem Companys 
@_subject: [liberationtech] Chinese Hacking, Mandiant & Cyber War 
No doubt all of you have seen the NY Times article about the Mandiant
report that pervades the news this week:
I believe it is important to understand the difference between cyber
espionage and cyber war.  Because espionage unfolds over months or years in
realtime, we can triangulate the origin of an exfiltration attack with some
certainty.  During the fog of a real cyber war attack, which is more likely
to happen in milliseconds,  the kind of forensic work that Mandiant did
would not be possible.  (In fact, we might just well be "Gandalfed" and pin
the attack on the wrong enemy as explained here:
Sadly, policymakers seem to think we have completely solved the attribution
problem.  We have not.  This article published in Computerworld does an
adequate job of stating my position:
Those of us who work on security engineering and software security can help
educate policymakers and others so that we don't end up pursuing the folly
of active defense.
company podcast blog book Unsubscribe, change to digest, or change password at:

@_date: 2013-01-12 00:35:49
@_author: Yosem Companys 
@_subject: [liberationtech] Tragic News: Aaron Swartz commits suicide 
This is a tragic loss and a terrible blow to the liberationtech community.
Aaron Swartz commits suicide
Web Update
By Anne Cai
NEWS EDITOR; UPDATED AT 2:15 A.M. 1/12/13
Computer activist Aaron H. Swartz committed suicide in New York City
yesterday, Jan. 11, according to his uncle, Michael Wolf, in a comment
to The Tech. Swartz was 26.
bThe tragic and heartbreaking information you received is,
regrettably, true,b confirmed Swartzb attorney, Elliot R. Peters of
Kecker and Van Nest, in an email to The Tech.
Swartz was indicted in July 2011 by a federal grand jury for allegedly
mass downloading documents from the JSTOR online journal archive with
the intent to distribute them. He subsequently moved to Brooklyn, New
York, where he then worked for Avaaz Foundation, a nonprofit bglobal
web movement to bring people-powered politics to decision-making
everywhere.b Swartz appeared in court on Sept. 24, 2012 and pleaded
not guilty.
The accomplished Swartz co-authored the now widely-used RSS 1.0
specification at age 14, was one of the three co-owners of the popular
social news site Reddit, and completed a fellowship at Harvardbs
Ethics Center Lab on Institutional Corruption. In 2010, he founded
DemandProgress.org, a bcampaign against the Internet censorship bills
SOPA/PIPA.b
Unsubscribe, change to digest, or change password at:

@_date: 2013-01-22 10:27:42
@_author: Yosem Companys 
@_subject: [liberationtech] Why Al-Qaida Hates the Internet: Trust Problems on 
Why Al-Qaida Hates the Internet: Trust Problems on Jihadi Discussion
*CISAC Social Science Seminar*
DATE AND TIME
January 24, 2013
3:30 PM - 5:00 PM
Open to the public
No RSVP required
Thomas Hegghammer  -
Zukerman Fellow at CISAC
 The trust problem limits what rebels can do online. The scarcity of
non-verbal cues in digital communication facilitates deceptive mimicry,
which undermines the interpersonal trust required for sensitive
transactions. Open-source data from jihadi discussion forums show that
distrust there is very high and direct recruitment rare. General trust also
declined during the observation period (2006-2011). As of 2012, forums are
still in use, but primarily for low-stake activities such as
propaganda-sharing and ideological debate. Confidence in the authenticity
of propaganda remains relatively high, due to vetting institutions and
hard-to-fake video formats. A modicum of interpersonal trust also remains,
thanks to reputation systems and a few relatively reliable signs of
trustworthiness involving time expenditure. The trust problem is an
Achillesb heel for terrorists online b but probably also for pro-democracy
activists in authoritarian settings.
CISAC Conference Room
Encina Hall Central, 2nd floor
616 Serra St.
Stanford University
Stanford, CA 94305
Unsubscribe, change to digest, or change password at:

@_date: 2013-03-05 20:26:37
@_author: Yosem Companys 
@_subject: [liberationtech] CfP: 4S, 
Call for Papers (w/ apologies for cross-listing)
Surveillance and the Mediation of Big Data
4S session(s) organized by Torin Monahan and Anders Albrechtslund
4S Annual Meeting (
San Diego, CA
October 9 - 12, 2013
The bbig datab paradigm signals an intensification and distribution of
algorithmic surveillance across multiple organizational and
geographical scales. More than an exponential advancement in storage
and processing capacity, big data currently operates as a fluid
metaphor for the potential of data analytics to intelligently predict
and respond to the needs of individuals and institutions. Clearly STS
inquiry could fruitfully deconstruct the technological deterministic
slant of discourses surrounding big data so that attention could be
drawn to the values being inscribed in algorithms, the profound
materiality of cloud computing, the control dimensions of pervasive
software, and the active cultivation of new subjectivities as people
come to understand themselves through their data doubles. Surveillance
is key to these processes, as the capture and processing of data is
frequently oriented toward some form of intervention or control.
Rather than viewing surveillance through big data as completely
automated or neutral processes, this panel seeks to investigate the
many forms of mediation and politics inherent in big-data
Possible areas of inquiry might include:
B7      Data fusion, profiling, and prediction by security organizations.
B7      The crafting of new subjectivities as individuals embrace
bquantified selfb movements.
B7      The social and political effects of bfilter bubblesb erected by
various search platforms.
B7      Gamification of interaction with customers and clients as
public and private organizations seek to capitalize on (and control)
user involvement.
B7      Activist and civil-society harnessing of data repositories and
sensing devices to achieve progressive outcomes.
B7      The optimization of urban infrastructures through bsmartb
information technologies.
B7      Health technologies used for documentation, analyses,
predictions and recommendations.
Please email titles, abstracts, and institutional affiliations to
Torin Monahan  and Anders Albrechtslund
 by March 15, 2013.
Torin Monahan, Ph.D.
Associate Editor, Surveillance & Society
Associate Professor
Dept. of Communication Studies
The University of North Carolina at Chapel Hill
NEW BOOK: SuperVision: An Introduction to the Surveillance Society
Too many emails? Unsubscribe, change to digest, or change password by emailing moderator at companys at stanford.edu or changing your settings at

@_date: 2013-03-08 12:06:28
@_author: Yosem Companys 
@_subject: [liberationtech] Mechanical Turk is not anonymous 
This may be of interest to those in community using Amazon's Mechanical
Turk platform for research, as well as those more generally interested
in how online data can be linked in ways that can be surprising to
people in practice and compromise their privacy in a manner they didn't
Several collaborators and I have just announced discovery of a
vulnerability on Amazon's Mechanical Turk platform, with potential
implications for IRB governance of human subjects research using AMT at
US universities. In particular, this vulnerability can be exploited to
obtain personally identifying information (PII) and other private
information of some workers, who may have shared this information online
in a way they did not recognize could be linked to their WorkerIDs.
This may impact IRB oversight of research conducted at UT with AMT, as
well as what research is classified as human research and subject to IRB
governance.  I am just starting to follow up on this now with our IRB
coordinator here at UT Austin.
The announcement of our finding is below:
Blog post: Paper: We are now trying to get the word out to be AMT workers, as well as
researchers whose might be impacted or who may have posted WorkerIDs
online which could be compromised via this vulnerability. We would
appreciate your help with this.
We are also specifically advocating *against* online posting of
WorkerIDs due to the risk of workers not having realized that
information they have shared could be linked with their worker accounts.
Regardless of the vulnerability, we have also found explicit requests
from workers to not post such uniquely identifying information.
Too many emails? Unsubscribe, change to digest, or change password by emailing moderator at companys at stanford.edu or changing your settings at

@_date: 2013-03-15 12:09:28
@_author: Yosem Companys 
@_subject: [liberationtech] Stanford Magazine - Can I Get Some Privacy? - 
How much do Internet companies know about us, and what do they plan to do with
the information? If only we knew.
By Brian Eule, Stanford Magazine
ASSUMING YOU POSSESS a cell phone and a computer and a credit card, the
following scenario, or something like it, might sound familiar.
Your morning begins with coffee and a bagel and the morning paper, perhaps
read on a laptop. You click on stories about Egyptian unrest, the firearms
industry and Downton Abbey. Two other websites are open on your desktop. One
of them shows your Facebook account. You notice that you've been "tagged" in a
photo from last week's poker game, in a pose that suggests one too many beers.
Meanwhile, a friend has sent you a link to an article in the Onion that
zestfully parodies a well-known senator. You "like" it.
You head out for your daily commute. At the toll booth, a Fastrak device
validates the code on your car and records the date and time of your arrival.
You stop for gas. You swipe your debit card. The pump asks for your ZIP code
and you type it in. As the 20-gallon tank fills, you pull out your smartphone
and do a quick search for a weekend flight to Chicago. Along with the flight
schedules and airfares, an advertisement appears about a local concert at the
same venue where you attended a performance last month.
In the first two hours of your day, computers have recorded that you are a
likely watcher of PBS, you drink alcohol and you have a penchant for
irreverent humor. They know you drive a large vehicle and probably have family
in the Midwest. They know when you go to work and the route you take. It's 8
a.m. and you've already left a sizable virtual fingerprint.
Now add the dozens of other electronic transactions you make in a given
daybevery website you visit, every item you purchase online, all the
searches you do, all the posts you make on social media sitesbplus those of
all your friends. Multiply that by hundreds of days of Internet activity.
Throw in motor vehicle records, mortgage documents, credit scores, medical
diagnoses. What does your profile look like now?
Data about all of us lives online, in "clouds," on our web browsers and in
others' databases. Cell phones show our physical location and track the places
we have been. Websites display the address and price of home purchases, along
with the buyer and seller. Advertising agencies know the web pages we have
visited and the text we have entered online. Increasingly, and with increasing
sophistication, companies are collecting, analyzing and selling data about
tens of millions of people. And most of those people have no idea when or how
it's happening.
"I don't think that people understand all the information that's out there
about them," says Jennifer Granick, director of civil liberties at Stanford
Law School's Center for Internet and Society. "People might not think that you
can put it all together, but they're wrong. It's increasingly easy to figure
out who people are. There is a treasure trove of information out there that is
The interdisciplinary CIS is helping to expose the massive asymmetry between
the average consumer's understanding and practices that might threaten their
privacy. Its scholars, along with privacy advocates in the nonprofit sector,
are pushing for more transparency and stricter industry standards in how data
is collected and used.
Concern about privacy intrusions often originates from an innocuous-sounding
source: cookies. So named because of the "crumbs" of information they collect,
cookies are codes imbedded in a computer hard drive that track web activity.
They are legal and in many ways beneficial. For example, cookies "remember"
passwords so repeat users of a site don't have to type it in every time they
return. They save user preferences and enable basic Internet conventions like
a shopping cart that makes online buying easier and less time-consuming. But a
third party, unbeknownst to the user, also can set cookies that follow that
user from site to site, gathering information about him or her. The
proliferation of this practice has spawned a new business category: data
brokers. These companies harvest public records along with web activity of all
kinds, then mash it up with algorithms designed to help clients target
potential customers with advertisements. Although individual names aren't
attached to this data, scholars say there is sufficient information to tease
out a person's identity.
"Web browsing history is inextricably linked to personal information," wrote
Jonathan Mayer, a Law School student and a PhD student in computer science,
and Stanford computer science professor John C. Mitchell, in a paper last year
for the Institute of Electrical and Electronics Engineers Symposium on
Security and Privacy. "The pages a user visits can reveal her location,
interests, purchases, employment status, sexual orientation, financial
challenges, medical conditions, and more. Examining individual page loads is
often adequate to draw many conclusions about a user; analyzing patterns of
activity allows yet more inferences."
AT AN EXTREME, piecing together information that exists about each of us can
be used for identity theft. But that's rare in comparison to more typical
concerns regarding the lack of control over who sees what personal
information, how they use it and what decisions they base on it. Aleecia M.
McDonald, director of privacy at the CIS, notes that banks might charge a
higher mortgage rate for a customer whose friends on Facebook had negative
credit events. Or, web merchants might adjust the price of products based on a
customer's ZIP code. Much of the concern, McDonald notes, resides in the
uncertainty over how all of the information will eventually be employed.
It's not just the things they disclose that people find troubling; "it's also
this data leakage about what they do online and what they're interested in,
their intellectual history and then also their friends," McDonald says. "They
don't know where the data is going, they don't know how it's used, and they
don't know what happens 10, 20, 40, 50 years from now."
Inferences based on what a user does online and who their friends are can be
misleading. Car insurance companies already vary premiums based on
demographics, but what if a user's Internet searches also informed a risk
assessment? Taken out of context, most of us have conducted searches that
might look suspicious if revealed in raw form. Employers are allowed to ask a
job applicant to log in and show them their Facebook page during an interview.
What if they also could see your search history? Might a college reject an
applicant based on additional information that now lives online?
Earlier this year, Facebook announced a feature it called "graph search" which
allowed users to search for others who have "liked" various topics or checked
in at specific locations. Privacy advocates howled. Here was information
people might have voluntarily shared, but did not expect to be catalogued.
Information once known only to close friends might now more easily be found by
strangersband paired with other information. The Electronic Frontier
Foundation, a nonprofit that champions consumers' digital rights, used the
example of a graph-search-enabled query for "People who work at Apple, Inc.
who like Samsung Mobile," information that, if shared, might put those
employees in an awkward position. For its part, Facebook is encouraging all
users to revisit their privacy settings, which locks down some of what others
could find via graph search.
Google logs massive amounts of information about its users and, "regularly
receives requests from governments and courts around the world to hand over
user data," according to the company's transparency reports. In the second
half of 2012, Google received requests for information on more than 33,000
users' accounts and complied with 66 percent of those.
An investigation by the Wall Street Journal in 2010 found that, "the nation's
50 top websites on average installed 64 pieces of tracking technology onto the
computers of visitors, usually with no warning." Twelve of them, it noted,
installed more than 100.
Privacy concerns may vary by age. McDonald speculates that younger generations
might be most vigilant about protecting their privacy from their parents. The
middle generation might be most concerned with what employers or health care
providers might learn about them. Regardless of age, much of the issue centers
around control, or lack of it.
"The question, on some level, is 'Whose data is it?' " McDonald says.
And the problem isn't confined to for-profit companies. Last October, Mayer
noticed an article in the New York Times about the use of third-party trackers
by the Obama and Romney campaigns. Both campaigns claimed they had safeguards
in place to protect users' anonymity. Mayer didn't buy it. "This seemed pretty
implausible to me," he says. "It was frustrating, at this level of politics,
that they were making this claim."
So he fired up an open source platform he had created, called FourthParty,
that measures dynamic web contentbsites whose offerings vary based on
different information provided by the user or the programband monitors
interactions with web applications. Mayer had to give himself a screen name,
so he went with "Leland Stanford." Then he entered some information and tried
to see what ended up in the page codes that got passed along.
Within a day, Mayer had confirmed his hunch. On both campaign sites, personal
informationbin some instances a user's name, in others an address or ZIP
codebwas included in the page web address that was given to the third-party
Mayer didn't think it was an intentional privacy breach, but he felt the
parties should have known better than to claim they could keep the data
Facebook presents a particular dilemma. The site is extraordinarily popular in
part because it fosters connections by inviting people to share information.
But its reach and aggressiveness in collecting user data are troubling, says
Mayer. His research indicates roughly half of web browsers are logged into
Facebook while users are visiting other pages. Each time those users visit a
page that also has a Facebook icon, the information is sent back to Facebook.
Even if the user doesn't click on that icon.
In the absence of strong controls, what are consumers to do to protect
themselves? One strategy: Pay for privacy. Start-ups such as Reputation.com
will scrub personal information from online databases for a fee. But while
some people are willing to pay, critics say consumers need better options.
"Having to pay a fee in order to engage in a retrospective effort to claw back
personal information doesn't seem to us the right way to go about this," David
Vladeck, then director of the Bureau of Consumer Protection at the Federal
Trade Commission, said at a congressional hearing in 2010.
Deleting cookies from one's computer is only a half measure. There are still
other fingerprints left behind, Mayer says. Which version of which web browser
they use, which Windows updates they have, which plugins they installed, the
order of the updates they downloaded, and so on, all create a unique trail of
sites visited. "Consumers by and large have no idea what's going on," he
Scholars at CIS are actively working to strengthen individuals' remedies. Each
Wednesday, members of an international World Wide Web working group on
tracking protection dial in to a conference call. Their mission is to "improve
user privacy and user control by defining mechanisms for expressing user
preferences around Web tracking and for blocking or allowing Web tracking
elements." Representatives from academia and industry, including people from
Microsoft, Apple, Facebook, Google and Mozilla, try to agree on a set of
recommendations for the field. McDonald and Mayer both participate.
Much of the discussion stems from a relatively simple idea that Mayer and
Arvind Narayanan, a former postdoc at Stanford, now an affiliate scholar at
the CIS and professor at Princeton, helped demonstrate.
Around 2007, in response to increased tracking on the web, privacy advocates
explored a Do Not Track program that would provide website users a means of
blocking trackers. It would work much like the Do Not Call registry adopted to
protect consumers from intrusive telephone marketers. It seemed more sensible
to work from the user end, rather than having each company offer an opt-out,
but many in the industry thought it was impossible to do.
Mayer and Narayanan began writing on the subject, describing on a blog how it
would work: A header in an HTTP field, the building block of the web, would
signal the computer not to collect information, thus enabling users to opt out
of tracking of all kinds. They tried to show companies ways they could respond
to protect their businesses. It is "a simple technology that is completely
compatible with the existing web," they wrote. "We believe regulation is
necessary to verify and enforce compliance with a user's choice to opt out of
tracking." In a "Do Not Track Cookbook," which they posted online, Mayer and
Narayanan proposed limiting identifiers to each website to prevent tracking
from one place to another.
A 2010 FTC report recommended implementing a Do Not Track mechanism; several
web browsers have adopted its use, but compliance is voluntary and its
effectiveness has been limited.
UNLIKE SOME COUNTRIES that have codified a comprehensive right to privacy,
Jennifer Granick notes, the United States has no universal privacy law.
Instead, it relies on a patchwork of regulations and the Fourth Amendment,
which states: "The right of the people to be secure in their persons, houses,
papers, and effects, against unreasonable searches and seizures, shall not be
violated, and no Warrants shall issue, but upon probable cause, supported by
Oath or affirmation, and particularly describing the place to be searched, and
the persons or things to be seized."
But the Fourth Amendment applies only to intrusions from the government. And
most federal privacy statutes apply only to specific sectors, such as health
care, education or communications and therefore fail to adequately protect
personal data on the Internet. The oddest origin of such a statute relates to
video rental records and stems from the days of Robert Bork's Supreme Court
confirmation hearings.
In 1987, Michael Dolan, then a reporter for the Washington City Paper, an
alternative weekly in Washington, D.C., walked into a local video store he
knew Bork and his wife frequented and requested a list of the couple's video
rentals. The subsequent article he wrote, describing Bork based on 146 videos
he had presumably watched, did little to define the man, other than revealing
a yen for Alfred Hitchcock and Cary Grant. But it caused a stir among the
nation's legislators, who were suddenly concerned about their own privacy.
Within a year, Congress passed the Video Privacy Protection Act to prohibit
"wrongful disclosure of video tape rental or sale records" without a
customer's consent. The Act recently returned to the floor of Congress, with
an amendment that makes it easier for companies like Netflix to have consumers
share their online video viewing as a means of delivering suggestions that fit
their tastes.
The law in general is still catching up to the technology. In early February,
the California Supreme Court ruled that Apple could legally require some
personal information as a means of validating users and preventing fraud.
However, the majority opinion suggested that new laws might be necessary to
adequately protect consumer privacy.
Narayanan tries to make a clear distinction between privacy research and
privacy advocacy. He believes in an individual's choice, and thus transparency
and consumer awareness are important. He also is quick to point out that
technology advancements can improve privacy options. At the start of the
privacy class he teaches each year, he shares an example.
The novel Fifty Shades of Grey might have been stigmatized by its graphic
sexual content, Narayanan tells his students, but because it first was
released as an e-book, people were able to read it on tablets or e-readers
without other people knowing. Then, when the book became popular enough that
there was no stigma attached, it was published in print.
"The narrative of technology killing privacy is, at best, dramatically
overstated," Narayanan says. "For every example of technology hurting privacy,
there's one of technology helping privacy." Another example: Self-checkout
kiosks used in some large retailers and grocery stores that allow shoppers to
make purchases without a store clerk knowing what they've bought.
These examples present an interesting paradox: While reading Fifty Shades of
Grey on a Kindle feels more private, there is still an electronic record of
the purchase. Compare that to buying it at a bookstore, with cash. A clerk
might know you like steamy novels but that's where the "record" of your
purchase ends. As technology is adopted more widely, old ways are made
obsolete or, in some cases, disappear altogether. But that limits our ability
to avoid the technology, and the attendant privacy concerns, if we chose to do
Solving the privacy conundrum would be easier if the solution didn't also
encroach on the ability of companies to prosper, and to deliver new and
interesting methods of entertainment, social engagement and commerce that
consumers happily embrace. The same technological developments that raise
privacy questions also add convenience to many ordinary tasks. They enable
instantaneous communication. Social media sites work because of the
participation of all of our friends, sharing photos and updates that we enjoy
receiving. What's the answer?
Control and transparency were major themes of a 2012 government report titled
"A Consumer Privacy Bill of Rights" that aimed to establish "a baseline of
clear protections for consumers and greater certainty for companies." The
report stated that "Consumers have a right to exercise control over what
personal data companies collect from them and how they use it" as well as a
right "to easily understandable and accessible information about privacy and
security practices."
The report recognized and attempted to account for the benefits of data
collection and to find ways of protecting privacy without thwarting
innovation. But it warned that if companies don't adopt measures themselves,
further regulatory scrutiny is likely. Those warnings are coming true. Last
July Congress began an inquiry into data mining practices. In October, a
similar probe was launched into nine data brokers.
The Electronic Frontier Foundation expects several pieces of legislation to go
before Congress over the next year, including amendments to existing bills
that would mandate a warrant for obtaining private electronic communications
such as old emails. Minnesota Sen. Al Franken recently introduced The Location
Protection Privacy Act of 2012 that would potentially prevent smartphone apps
from tracking a cell phone's location and sending it to a third party without
consent. Another major player is the Electronic Privacy Information Center,
whose president and executive director Marc Rotenberg, JD '87, has testified
before Congress on many issues related to consumer privacy.
"I think the next couple of years will be formative for the next decade
after," CIS's McDonald says. But forecasts about how business interests and
privacy concerns ultimately will be reconciled are cloudy at best. And the
proverbial slippery slope is getting more treacherous all the time.
"I would expect that targeting advertising is just the beginning of what could
be done with this data," McDonald says. She worries "that we will look back
later on and go, 'remember when it was so simple? It was only advertising.'"
Brian Eule, '01, is a frequent contributor to Stanford.
Too many emails? Unsubscribe, change to digest, or change password by emailing
moderator at companys at stanford.edu or changing your settings at
Eugen* Leitl leitl ICBM: 48.07100, 11.36820  8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE

@_date: 2013-10-09 10:01:52
@_author: Yosem Companys 
@_subject: [liberationtech] The Unintended Consequences of Internet Diffusion: Evidence from	Malaysia - CDDRL 
The Unintended Consequences of Internet Diffusion: Evidence from Malaysia  Program on Liberation Technology Seminar Series
DATE AND TIME
October 10, 2013
4:30 PM - 6:00 PM
Open to the public
No RSVP required
Luke Miner - Data Scientist at Stanford University
Can the introduction of the Internet undermine incumbent power in a semi-authoritarian regime? I examine this question using evidence from Malaysia, where the incumbent coalition lost its 40-year monopoly on power in 2008. I develop a novel methodology for measuring Internet penetration, matching IP addresses with physical locations, and apply it to the 2004 to 2008 period in Malaysia. Using distance to the backbone to instrument for endogenous Internet penetration, I find that areas with higher Internet penetration experience higher voter turnout and higher candidate turnover, with the Internet accounting for one-third of the 11% swing against the incumbent party in 2008. The results suggest that, in the absence of the Internet, the opposition would not have achieved its historic upset in the 2008 elections.
Luke Miner is a recent Ph.D. in Economics from the London School of Economics. He was also a postdoctoral fellowship at the Center on Democracy, Development and the Rule of Law (CDDRL) in the Liberation Technology program. He is currently working as a data scientist in the tech sector.
Miners research interests are political economy and development economics. In particular, he aims to quantitatively assess the effect of the Internet and new media on political accountability, development, and election outcomes. His past research finds a strong effect of Internet diffusion on results of Malaysia's 2008 elections, where it contributed to the ruling coalition's largest electoral setback in thirty years. His current research looks at the effect of the Internet on the 2008 US presidential elections, in particular as a means of promoting campaign contributions.
Wallenberg Theater
Wallenberg Hall
450 Serra Mall, Building 160
Stanford, Ca 94305-2055

@_date: 2013-09-05 08:53:43
@_author: Yosem Companys 
@_subject: PayPal freezes MailPile's account 
References: <2780551.exnjNUlKQP
 <522873CC.1030000 Yes, but they could have used WePay, Stripe, or some other alternative.
 Remember Diaspora?  $80K in donations frozen by PayPal.  Once you get your
account unfrozen, as Diaspora learned, your momentum stops.  So it's
doubtful that they'll make over $45K now, without another appeal.

@_date: 2013-09-11 14:52:06
@_author: Yosem Companys 
@_subject: [liberationtech] Henry Farrell for Democracy Journal: The Tech Intellectuals 
The Tech Intellectuals
The good, bad, and ugly among our new breed of cyber-critics, and the
economic imperatives that drive them.
Henry Farrell
A quarter of a century ago, Russell Jacoby lamented the demise of the
public intellectual. The cause of death was an improvement in material
conditions. Public intellectualsDwight Macdonald, I.F. Stone, and
their likeonce had little choice but to be independent. They had
difficulty getting permanent well-paying jobs. However, as
universities began to expand, they offered new opportunities to
erstwhile unemployables. The academy demanded a high price.
Intellectuals had to turn away from the public and toward the
practiced obscurities of academic research and prose. In Jacobys
description, these intellectuals no longer need[ed] or want[ed] a
larger public. Campuses [were] their homes; colleagues their
audience; monographs and specialized journals their media.
Over the last decade, conditions have changed again. New possibilities
are opening up for public intellectuals. Internet-fueled media such as
blogs have made it much easier for aspiring intellectuals to publish
their opinions. They have fostered the creation of new intellectual
outlets (Jacobin, The New Inquiry, The Los Angeles Review of Books),
and helped revitalize some old ones too (The Baffler, Dissent).
Finally, and not least, they have provided the meat for a new set of
arguments about how communications technology is reshaping society.
These debates have created opportunities for an emergent breed of
professional argument-crafters: technology intellectuals. Like their
predecessors of the 1950s and 60s, they often make a living without
having to work for a university. Indeed, the professoriate is being
left behind. Traditional academic disciplines (except for law, which
has a magpie-like fascination with new and shiny things) have had a
hard time keeping up. New technologies, to traditionalists, are
suspect: They are difficult to pin down within traditional academic
boundaries, and they look a little too fashionable to senior
academics, who are often nervous that their fields might somehow
become publicly relevant.
Many of these new public intellectuals are more or less self-made.
Others are scholars (often with uncomfortable relationships with the
academy, such as Clay Shirky, an unorthodox professor who is skeptical
that the traditional university model can survive). Others still are
entrepreneurs, like technology and media writer and podcaster Jeff
Jarvis, working the angles between public argument and emerging
business models.
These various new-model public intellectuals jostle together in a very
different world from the old. They arent trying to get review-essays
published in Dissent or Commentary. Instead, they want to give TED
talks that go viral. They argue with one another on a circuit of
business conferences, academic meetings, ideas festivals, and public
entertainment. They write books, some excellent, others incoherent.
In some ways, the technology intellectuals are more genuinely public
than their predecessors. The little magazines were just that, little.
They were written for an elite and well-educated readership that could
be measured in the tens of thousands. By contrast, TED talks are
viewed 7.5 million times every month by a global audience of people
who are mostly well-educated but are not self-conscious members of a
cultural elite in the way that the modal reader of Partisan Review
might have been.
In other ways, they are less public. They are more ideologically
constrained than either their predecessors or the general population.
There are few radical left-wingers, and fewer conservatives. Very many
of them sit somewhere on the spectrum between hard libertarianism and
moderate liberalism. These new intellectuals disagree on issues such
as privacy and security, but agree on more, including basic values of
toleration and willingness to let people live their lives as they
will. At their best, they offer an open and friendly pragmatism; at
their worst, a vision of the future that glosses over real politics,
and dissolves the spikiness, argumentativeness, and contrariness of
actual human beings into a flavorless celebration of superficial
This world of conversation and debate doesnt float unsupported in the
air. It has an underlying political economy, which is intuitively
understood by many of its participants. As Jacoby emphasizes, all
debates about ideas are shaped by their material conditions. The
intellectual possibilities of the purported golden age of the 1950s
were in part the product of bad pay, cheap rent, and a small but
intensely engaged audience of readers. Those of the 1960s and 70s
were influenced by a burgeoning university system, which rewarded
intellectuals for writing impenetrably for an audience of their peers.
The possibilities today reflect a different set of material conditions
again, which dont determine individual choices so much as they pull
on them, gently but insistently. They influence what is discussed and
what isnt, who wins and who loses. And much goes undiscussed. The
working consensus among technology intellectuals depicts a world of
possibilities that seems starkly at odds with the American reality of
skyrocketing political and economic inequality. It glosses over the
deep conflicts and divisions that exist in society and are plausibly
growing worse. And the critics of this consensus fare no better. They
work within the same system as their targets, in ways that compromise
their rejoinders, and stunt the development of more useful lines of

@_date: 2013-09-11 15:29:15
@_author: Yosem Companys 
@_subject: [liberationtech] Inside the Effort to Crowdfund NSA-Proof Email and Chat Services | Motherboard 
Back in 1999, Seattle-based activists formed the communication
collective Riseup.net. The site's email and chat services, among other
tools, soon offered dissidents a means of encrypted communication
essential to their work. Fourteen years later, Riseup is still going
strong. In fact, they've been fighting the US state surveillance
apparatus longer than most people have been aware of the NSA's
shenanigans. Now, the collective is hoping to expand, given the gross
privacy transgressions of the NSA and US government as a whole.
"What surveillance really is, at its root, is a highly effective form
of social control," reads an AugustRiseup newsletter. "The knowledge
of always being watched changes our behavior and stifles dissent. The
inability to associate secretly means there is no longer any
possibility for free association. The inability to whisper means there
is no longer any speech that is truly free of coercion, real or
implied. Most profoundly, pervasive surveillance threatens to
eliminate the most vital element of both democracy and social
movements: the mental space for people to form dissenting and
unpopular views."
The impetus behind the project is Riseup's struggle to keep up with
new user demand for an email service that doesn't log IP addresses,
sell data to third parties, or hand data over to the NSA. Riseup will
also be able to expand its considerable anonymous emailing lists,
which features nearly 6 million subscribers spread across 14,000
lists. Their Virtual Private Network (VPN), which allows users to
securely connect to the internet as a whole, will also be made more
robust. What Riseup can't do is offer its users an anonymous browsing
experience, but that's not their aim.
To offer Riseup to more users, Free Press's Joshua Levy, Elizabeth
Stark (an open internet advocate who has taught at Stanford and Yale),
as well as others at the StopWatching.Us campaign (backed by Mozilla)
recently launched an Indiegogo crowd-funding effort on behalf of the
group. They hope to raise $10,000 in order to provide Riseupwhich is
run by volunteerswith a new server, hardware, and software
capabilities. In short, they want to expand their reach so that
internet users have another alternative to email services such as
Gmail, Yahoo, and Hotmail.
To get a clearer picture of what StopWatching.Us and Riseup are doing,
I spoke with Levy, Stark, and an anonymous Riseup collective member.
We talked about how the crowdfunding money will be spent; how Riseup
helps users avoid NSA, as well as state and local repression; and why,
contrary to reports, the Tor Browser bundle is still the best option
for anonymous, encrypted browsing. (As of today, the crowdfunding
campaign reached it's $10,000 goal, but the organizers are hoping to
exceed that total by a good margin.)

@_date: 2015-02-16 12:27:19
@_author: Yosem Companys 
@_subject: [liberationtech] At Stanford on Friday, Feb. 20 -- Vitalik Buterin: Ethereum & Cryptoeconomic 
security-seminar at lists.stanford.edu at
  Introduction to Ethereum, and Cryptoeconomic Mechanisms
                        and Security
                      Vitalik Buterin
                 Friday, February 20, 2015
                       Talk at 4:15pm
                         Gates 463
The presentation will provide an introduction to the Ethereum protocol from
a technical perspective, including the high-level operation of the
protocol, contract calling and gas mechanics, use of Patricia Merkle
trees and
other cryptography and light client proofs. I will then discuss some of the
interplay between economics/game theory and cryptography both in consensus
algorithm design (eg. proof of work, proof of stake) as well higher-level
protocols like sidechains, challenge-response protocols and SchellingCoin,
and will attempt to define and dissect different interpretations of the
concept of "cryptoeconomic assurance".
