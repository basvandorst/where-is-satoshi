
@_date: 1995-08-24 12:33:51
@_author: Christian Wettergren 
@_subject: Matt Blaze's paper on Clipper... 
I don't seem to be able to locate it, but I had it earlier on.
Do anyone know where it is?
I'm talking to a reporter about the EPIC alert, and wants to show
him Matt's attack.

@_date: 1995-08-24 14:17:09
@_author: Christian Wettergren 
@_subject: SSL CHALLENGE: ALERT! probable misallocation of keys? 
Where can one observe the progress of the computations? What is allocated etc?

@_date: 1995-08-24 15:14:53
@_author: Christian Wettergren 
@_subject: server congestion? 
Couldn't one take advantage of the 50.000 mistake, by
setting up a second server for that space. I guess things will screw up when the first server reaches FFFF, as indicated earlier.
What would be nice is if one could divide up the key
between servers also.
Another thing that might decrease the load on the server
is if we start allocating more blocks at a time, lets
say 2-4 blocks each time. Wouldn't that help?

@_date: 1995-08-24 16:08:05
@_author: Christian Wettergren 
@_subject: server congestion? 
Ok, neat. I was merely thinking of a simple static partitioning of it
right now.
I was rather thinking of a simplistic solution right now, looking in
the log of active calculators, roughly dividing them up into two
similarly sized groups etc. But I guess this isn't as easy as I
thought it would be.

@_date: 1995-08-24 17:24:13
@_author: Christian Wettergren 
@_subject: Linux brutessl client 
I've tried to optimize the SunOS binary, but it seems as if 16400
keys/s is the maximum I can get on a SS10. No changes in optimization
flags has helped so far.
Has anyone got a better speed than this on a ordinary ss10, with SunOS

@_date: 1995-08-24 17:42:30
@_author: Christian Wettergren 
@_subject: Cypherpunks Santa Cruz meeting/party 
Anyone in the Palo Alto area going to Tim's who would like
to give me a ride there? If so, drop me a line.
And Tim, take that as indication that I'm interested in
participating in the meeting. :-)
 Nordic Viking
 Sweden

@_date: 1995-08-25 12:19:29
@_author: Christian Wettergren 
@_subject: Cypherpunk Brute Squad [Re: SSL Challenge: Server problems] 
[about manually updating ACKs]
Unfortunately, I don't dare do that, since my machines has crashed
a few times. (nightly reboots for example.)
I guess you dare do it if there is a no-line in the log.
Couldn't you insert some code that measures the time it has taken
that particular IP-number to ACK other block, and timeout the
reservation after double that time or something similar? In this case
you don't run the risk of ACKing a block with the key in it.
Some more work for the server! :-)

@_date: 1995-08-27 11:48:30
@_author: Christian Wettergren 
@_subject: SSL trouble 
And there is the third alternative, hierarchical search, which
distributes the task of giving out keys. This is admittedly a
little bit more involved, of course. The SKSP had provisions for
doing it hierarchically, as far as I understood it, although
I might be wrong.
What I wonder is wheter the server congestion really showed that
the protocol is flawed. Handing out bigger blocks relieved the situation. I think this can be further improved if you do a couple more things.
1. The server knows approximately how many requests per second it can take, and tells the clients this information.
2. The client initially does a testrun, and determines how fast it 3. Each client is handed a block that, given the approximate number
of currently pending and active blocks out there, together with the
calculation time of the client, will give an acceptable number of requests/time unit to the server.
4. The server acks (S-ACK) the block-ack to the client. If the client doesn't get an ack (S-ACK) from the server for its ack (B-ACK), it keeps the ack around til the next block is calculated, and sends this ack together with the new acks.
5. The server can hand out allocated blocks to others, for those
blocks that has not been acked in three times the estimated
calculation time. 6. If a client is unable to get a key allocation after a number of tries, it can chose a random block and search that. It can then be
acked to the server. This may result in overlapping blocks, but this
should not pose such a big problem, since most of the key space is
searched in an orderly manner anyway.
It would be very interesting if detailed statistics or the logfile
of the server could be published somewhere. How many machines were
involved? etc...

@_date: 1995-08-27 14:43:44
@_author: Christian Wettergren 
@_subject: proliferation of voicesystems 
Note that most of the MBone tools already has encrypted sessions
built in them, and have had that for at least a year, and that the
MICE project in Europe has tried to put encryption into the last ones.
There is also a lot of standardization efforts going on within the
IETF community, for example within the MMUSIC group, chaired by
Mark Handley from UCL, London . They are
standardizing the session control protocol, for example, using one
called CCCP. They are also concerned about security, thats for sure.

@_date: 1995-08-27 15:52:56
@_author: Christian Wettergren 
@_subject: SSL trouble 
And I guess they would consider even brute-forcing code to be cryptoanalysis? But not the actual netscape binaries, since they
are for "proper" use. :-(
Sigh. I'm getting tired of all this.

@_date: 1995-08-27 17:42:04
@_author: Christian Wettergren 
@_subject: Server congestion 
I talked about acks of acks in a previous message, and I guess is was
somewhat vague there.
What happened, according to my uninformed view, during the SSL2
challenge was that the server got congested, and had problems with
both answering to key allocation requests and ack replies. I guess that the load of the machine was so high that it lost packets in the
input queues.
Client -----> UDP/Key allocation req ----> Client -----> UDP/Key allocation req ----> Client -----> UDP/Key allocation req ----> Server ---+
 alloc
Client <------- UDP/allocation reply ----------------+
 working...
 Client ------- UDP/ack ------------------> ??
One problem was that the client believed that the ACK had arrived
at the server if it had sent it off, not counting with the possibility
of the ACK being lost on the way.
I instead propose that the Server sends a acknowledgement
back to the client once it has received an ACK from a client.
 working...
 Client ------- UDP/ack ------------------> Server -+
Client <------ UDP/Server-ack ------------ Server -+
And then the client knows the server actually received the ACK
and has incorporated it into its table.
The client has to handle the case that either the Ack or the
Server-ack is lost. I propose it doesn't retransmit immediately,
but rather waits until next time it has to ack something, and piggybacks the old ack onto the new one.
Client -----> UDP/Key allocation req ----> Client -----> UDP/Key allocation req ----> Client -----> UDP/Key allocation req ----> Server ---+
 alloc
Client <------- UDP/allocation reply ----------------+
 working...
 Client ------- UDP/ack1 ------------------> ??
 "oops, oh well, lets try later."
Client -----> UDP/Key allocation req ----> Server ---+
 alloc
Client <------- UDP/allocation reply ----------------+
 working...
 Client ------- UDP/ack2/ack1 ------------> Server -+
Client <------ UDP/Server-ack {1,2} ------ Server -+
 There are countermeasures if either part doesn't get messages for some
reason. If the server doesn't see the ACK for a block, it might give that
block out to someone else.
If the client is unable to retrieve a block from the server, I suggest
it just picks a random block and starts working on it. I may very
well not be allocated to someone else, and then the client was able
to do something good in the meantime even though it didn't get a
proper key alloc.

@_date: 1995-08-28 09:46:47
@_author: Christian Wettergren 
@_subject: Server congestion 
Ok, I'll be quiet now. It's funny when you think you know
what is happening based on an uninformed view, and simply
shuts out all the other pieces of info that gets to you.
By the way, thanks a lot Piete for the effort you put in!
You did excellent, and it was real fun! 32 hours with serious performance problems is simply amazing.

@_date: 1995-08-29 23:04:26
@_author: Christian Wettergren 
@_subject: SSL and MIPS... 
How much computing power did we actually
use, in terms of MIPS/FLOPS*hours?
An unloaded SS10 that didn't swap went at
approximately 16400 keys/s. How many
MIPS is an SS10 approximately?
How does different algoritms compare?
DES, RC40, RSA512 etc?
Or if I pose the question differently,
what can you do with 30 GIPS for a day?

@_date: 1995-09-04 15:17:31
@_author: Christian Wettergren 
@_subject: Emergency File Wipe Algorithim 
Anon writes>
Also note the recent posting on sci.crypt by Peter Gutmann about being
able to recover data from DRAMs and SRAMs after powerdown. It hits
cryptokeys really bad. I suppose this is really academic at the current stage, but that might

@_date: 1995-09-04 16:14:32
@_author: Christian Wettergren 
@_subject: Emergency File Wipe Algorithim 
Someone proposed that one could wipe the memory before power-down, for
example during 1 second or something like that. Unfortunately, that
wont help, unless I misread the paper. It is effectively the same as
if the key had been stored in the cell for 1 second less, nothing else.
The only way I can see how to avoid generating "imprints" of more or
less static data is to make them non-static. Start circulating them
One way that springs to mind for keys are to do something like
inverting the meaning of the key every x milliseconds. Like this;      /* pseudo code */
     char master_key[KEYSIZE];
     int  meaning = ZEROS;
     void encryption(char *input, char *output); /* implicit master_key */
     int using_key = FALSE;
     main() {
       input_from_keyboard(master_key);
       timer(100 ms, flipem()); /* calls flipem every 20 ms */
       main_loop(); /* occansionally using encryption() */
     }
     void flipem() {
       if (using_key) /* risk of never being able to flipem() */
         return;
       /* some kind of semaphored section */
       using_key = TRUE;
       master_key = inverse(master_key);
       meaning = (!meaning);
       using_key = FALSE;
     }
     void encryption(char *input, char *output) {
      char real_key[KEYSIZE]; /* must be on stack */
      copy_key(real_key, master_key);
      if (meaning == ONES)
        invert(real_key);           /* recovering real content */
      encrypt(input, output, real_key);
      write_random_key(real_key); /* so "real" key doesn't become                                      imprinted as well. */
     }
Do don't care about the plaintext in the above. Nor stack content vrey
much. Nor about coding style.

@_date: 1995-09-04 16:38:57
@_author: Christian Wettergren 
@_subject: Emergency File Wipe Algorithim 
Repost from sci.crypt. It seems as it has expired at some places.

@_date: 1995-09-11 18:07:21
@_author: Christian Wettergren 
@_subject: Media coverage of NIST Export meetings? 
I'm just in the process of sending off the abstract you did plus
the pointers to a number of journalist I know. But thats in Sweden,
so I guess it doesn't count. :-)

@_date: 1995-09-12 12:49:59
@_author: Christian Wettergren 
@_subject: Netscape to patch shareware version 
Hurray! We did it! We did it! :-)
Ok, any bet on how long it will take?
The power of the Net is actually quite astonishing at times. The
plotting in Ender's Game isn't all that unrealistic after all. (Oh,
well, ruler of the world is a bit of still. ;-))

@_date: 1995-09-16 22:18:02
@_author: Christian Wettergren 
@_subject: Anonymous WWW proxies 
Doesn't most of the browsers support a "firewall-proxy-mode", where
all queries are sent of to a special daemon, that forwards the query
on. This would probably be the place to add the header-munging.
How do you plan to get the reverse-path working? Having a
encrypted/chained return path in the request?
Encryption speed isn't all that an issue always. I'm planning to do an
Mbone encryption gateway, (RSN). I will precompute a cryptographic
mask during idle cycles, that can be XORed together with the
clear-text packet when it arrives. I expect it to reduce the latency
quite a lot. (This might not work, since it assumes the key distr
problem is already solved in good time before the packet arrives, to
be able to amass "precomputational power".)

@_date: 1995-09-18 11:23:52
@_author: Christian Wettergren 
@_subject: Netscape SSL implementation is broken! 
I should have known, since it was a draft years ago. Ok, you Netscape people, go read RFC 1750! :-)
Btw, I guess my asadi program is full of holes and bugs.
Where is a decent 'randomness generator' for a SunOS system?

@_date: 1995-09-18 11:37:55
@_author: Christian Wettergren 
@_subject: Code of Law 
I suddenly got very cold.
I thinnk the world has seen enough of 'revolutionary justice',
both in the Soviet Union; there are some fascinating passages
of Lenin about avoiding the bourgouise invented 'justice' concept, and that the revolution was well 'above' that whole thing,
and im Germany.
And I guess in current China.
When the people and the govering establishement has lost contact
this much, you're in for trouble.
(Ok, remember I'm a dumb Swede, that still happens to believe that
State and People doesn't have to be enemies. And I do believe in a
sensible dialog between different interest groups etc etc. Flame
away, I'm just dumb anyway. ;-))

@_date: 1995-09-19 01:19:55
@_author: Christian Wettergren 
@_subject: Brute Force and Smart Force 
What I don't understand is why the law-enforcement is so concerned about bruting things. It is probably quite easy to tap the keyboard,
smart force, exchange the binary with the real thing etc for them?
(Unless they want to read it all from a nice tipped-back armchair in
a certain location? :-))
What I'm saying is that this kind of attack should work quite easily
in the one-by-one cases, but not on a large scale, malicious data,
trojan horses, outright bugging. So why all this Clipper (son-of-X)
fuss? Ok, not for all data, especially not for the "untouched, rarely used"
ones. But is this any different from hiding your diary in a very safe
place anyway?

@_date: 1995-09-19 12:51:00
@_author: Christian Wettergren 
@_subject: Random publicity was: articles 
Ouch - had a good night's sleep, did you? :-)
Too bad, you should have been a Swede, like me. Wouldn't it be fun
to say something like; "Well, I'm not allowed to reveal this weakness
to any American, since I'm not allowed to export munitions!"

@_date: 1995-09-19 22:24:58
@_author: Christian Wettergren 
@_subject: PGP back in legal limbo? [noise] 
Conspiracy flag on.
Did anyone else but me see the discussion organized by Progress &
Freedom Foundation at SPAN, I believe yesterday night. John Barlow
from EFF was there, and he said a few things that certainly got
my attention.
He said that the "borders to cyberspace had to be protected", and
that the "fight for freedom in cyberspace was fought right now, not in
two years, but right now". And that we should "get encryption be
deployed out there, either in Europe [i think he said] or embedded as
a kind of holographic image in the Net". He also said that he
"expected 'blood' to be shed in this fight" (everything taken from memory, not exact quotes)
I was surprised at his intensity and outspokeness. I can't get this
kind of statements into agreement with the negative picture several
other cypherpunkers has painted of EFF.
I wonder whether the effort by EFF to put some sensibel input into the official loop is failing, and that is behind his statements?
(I haven't seen/heard him make statements earlier, maybe this is his
usual way of expression?)
Does anyone but me smell an attempt of rewinding part of the
widespread use of PGP, because of a "patent problem".
I got the GAO report on "requirements for the information highway",
and they even included a PGP-encrypted email there. The report was rather positive to protect the privacy of the users, noting that it
was a fine balance between many interests - not the "law enforcement
only" point of view.
Conspiracy flag off.

@_date: 1995-09-20 00:29:33
@_author: Christian Wettergren 
@_subject: netscape's response 
It isn't really easy. I guess you were around to see the pointer to
RFC 1750, approx "Security Randomness reqs"?
* I think you should use as much user-generated randomness as possible,
  like the mouse movement patterns, interarrival times of events from
  the user interface etc.
* You can also gather statistics from the networking card, like number
  of collisions, packets in/out, number of passing packets etc.
* Measuring the interarrival times of requests/responses from a remote
  server should also be a good one, I guess. I depends on the network
  in between, the actual processes executing on it, the scheduling
  algorithm etc.
* And finally, insert some sampling of the noise in the sound blaster.
* And try to reseed it, as often as possible and convenient. Make it   depend on the previous value of the random generator seed, somehow.
The difficult part is to verify the quality of the random seeding and
reseeding. How does it behave on a unloaded system? Could someone put
your system under some strain, and hence affect the random generator
to lock down into a small subspace or even onto a fixed value?
How independant are the values anyway? And when you start to talk
about ergodity etc, I'm lost anyway. :-)
I think it is important to bring together factors of the user _and_
the environment, preferrable an environment that reaches as far from
the local site as possible. This makes "jamming" of the random seed
selection process harder. The other problem in gathering random bits for a seed is that most
bits are visible by someone else close enough within your environment.
Interarrival times of packets are fine, but anyone can observe them
with quite a good accuracy. How do you escape the "local environment
problem"?                               . - .
One wild idea that I just got was to have servers and clients exchange
random numbers (not seeds of course), in a kind of chaining way. Since
most viewers connect to a number of servers, and all servers are
connected to by many clients, they would mix "randomness sources" with
each other, making it impossible to observe the local environment
only. And the random values would of course be encrypted under the
session key, making it impossible to "watch the wire".
* watch out for "multiply by zero" attacks by a rogue server/client.
* watch out for "almost singular values" in the same way.
* only let one source contribute a certain amount of randomness, like
  (key length)/(aver # of peers).
* never reveal your current seed, only a non-trivially derived random   value from it. (of course)
* make sure your initial seed is good enough, or the whole thing is
  broken.
* perhaps save part of the previous session state into a protected
  file, to be able to keep up the quality of the initial seed.
I think I like it, perhaps not from a practical point of view as much
as the 'non-attackability' of it. Its quite cypher-a. But I bet someone has already done this a long time ago. My usual
luck! :-(
If not, I want a 'I saved Netscape!' t-shirt from you, Jeff! PS. I'm a Swede, I don't know if I'm allowed to reveal these state
secrets. So please shut your eyes, ok?

@_date: 1995-09-20 00:38:41
@_author: Christian Wettergren 
@_subject: [NOISE] Unabomber - crypto-anarchist?!? 
A frame-up, I bet! What bothers me is that the it makes sense from a
certain twisted kind of view. Discrediting the group that actually
is a problem when it comes to ITAR, and recently has had good
publicity. And Tim being one of those who spotted Clipper coming,
early on. And the punch line;   "Look the terrorists and the crypto anarchists are the SAME guys!"
(Tim, not that I agree with your political views, but many Swedes
are like that. ;-) )
Why is it that my conspirational sides has blossomed once I joined
this group? I've posted more severely conspiritional posts recently
than I've done in my whole previous Inet presence. I gotta stop. :-)

@_date: 1995-09-20 16:29:25
@_author: Cwe@csli.stanford.edu 
@_subject: SSL and MIPS... 
How much computing power did we actually
use, in terms of MIPS/FLOPS*hours?
An unloaded SS10 that didn't swap went at
approximately 16400 keys/s. How many
MIPS is an SS10 approximately?
How does different algoritms compare?
DES, RC40, RSA512 etc?
Or if I pose the question differently,
what can you do with 30 GIPS for a day?

@_date: 1995-09-20 20:45:57
@_author: Christian Wettergren 
@_subject: netscape's response 
Bill Stewart answered:
Of course you have to be very careful, as you say. Did you see my
problem-section in the original letter? I included it above. Since
then I have realized that the  * only let one source contribute a certain amount of randomness, like
   (key length)/(aver # of peers).
really should be
 * only let one source contribute a certain amount of randomness, like
   (large entropy buffer)/(aver # of peers).
and that you should only give out approximately the same amount of randomness to the neighbour, as you point out below.
My approach solves part of the problem of "the observable local
environment" problem. Jeff's reply to this suggestion might be somewhat dangerous, if
the exchanged 'randomness bits' are the challenge/responses in the
exchange. (Based on his remark of not needing to change protocol.)
You would arguably not want to have the loop
         RNG --> "unguessable chall/resp" ---+
          /\                                 |
           +---------------------------------+
I would say that the only acceptable solution would be to have
(viewer)consumer <-------------------->consumer (srv)
          /\                             /\
                              |
   --->  RNG1 <---------------------->  RNG2 <----- RNGn
          /\                             /\
                              |
         RNGx                           RNGy
separating the "building up" of randomness from the consuming phase of that built up randomness, the actual
part which has to be totally unpredicate.

@_date: 1995-09-21 10:28:51
@_author: Christian Wettergren 
@_subject: Euro-Clipper 
It's time for a European wing of the cypherpunks list.
Europeans - unite!
And they even have the indecency to immediately propose
to outlaw 'strong encryption for the people' - no grace
period there.

@_date: 1995-09-21 10:35:26
@_author: Christian Wettergren 
@_subject: NSA and Netscape Crack 
It is dangerous that the general reaction is that of
'them being stupid', since that will prevent others
from stepping forward and reveal their own 'holes'.
I decree that 'all holes look stupid once located'.
But 'any non-trivially large program is bound to have
holes' => 'all programmers are stupid' (except me,
because I found the hole?)
Jeff, your and Netscape prompt response to this is
what counts - holes will always be uncovered, it's the
time before they are patched that really matters.

@_date: 1995-09-21 11:53:38
@_author: Christian Wettergren 
@_subject: Exchange random numbers (was: Re: netscape's response) 
Giving out contribution:      MD5(select_bits(my_seed, start_bit, stop_bit)) -> remote
Taking in contribution :      my_seed = my_seed XOR      ((select_low_bits(remote_contrib, contrib_width) << contrib_area)
You also need to keep track of who has contributed what, and how much.
This might become a problem if you don't have a safe authentification
mechanism, like baseing the tracking on the IP-numbers etc.
But I don't believe this is a real problem, since you always
contribute 'entropy', not exact values. You need to know the exact
state of the random generator to be able to predict how your
contribution will affect the generator.
The boot-strap stage is actually the big problem still. But if the
initial stages are 'random enough' to withstand a total crack, I guess
the randomness gathered will increase rapidly, and increase the
safety a lot.
This isn't a problem as I see it, he'll only know what bits he
flipped, not the actual state.
I guess someone could mount an attack on the remote_contrib, finding
the part of my_seed by bruting the remote_contrib that I submitted.
But even if that is done, you'll only know a small part of the total
seed. And the remote end can't choose which segment of my_seed that
will be revealed.
I also see a problem if an attacker is controlling the whole
environment, but this is no different from the original problem, and
a lot more unlikely.
Well, the reason would be that if someone bruted your contribution,
they would still have to guess the remaining part. Double safe! :-)
Yes, but if one assumes that the algorithm to gather the seed is
known, its quite possible for someone else to do it at the same time
as you do it, or even observe your ping packet req/reply. And how do
you determine which 'random host' to ping?
Yes, I believe this is important too.
