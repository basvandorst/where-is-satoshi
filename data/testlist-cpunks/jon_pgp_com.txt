
@_date: 1997-11-04 04:10:50
@_author: Jon Callas 
@_subject: RSA Blows Smoke 
Unfortunately PGP Inc have closed off dialogue on the topic --
   apparent blanket ban on employee discussion of CMR.
Horsefeathers, Adam. We've been talking about this with you a lot and you
know it. We set up a mailing list to discuss it, you've received personal
phone calls, and lots of people have bent over backwards for you.
If you think you're being ignored, perhaps you should re-examine the
signal-to-noise ratio of your posts.
Jon Callas                                  jon at pgp.com
Chief Scientist                             555 Twin Dolphin Drive
Pretty Good Privacy, Inc.                   Suite 570
(415) 596-1960                              Redwood Shores, CA 94065
Fingerprints: D1EC 3C51 FCB1 67F8 4345 4A04 7DF9 C2E6 F129 27A9 (DSS)
              665B 797F 37D1 C240 53AC 6D87 3A60 4628           (RSA)

@_date: 1997-10-08 05:44:17
@_author: Jon Callas 
@_subject: What's really in PGP 5.5? 
Hash: SHA1
I have a number of comments about the New York Times article on PGP 5.5 for
Business of which Martin Minow sent a synopsis.
If we had built what they said we had, then we'd deserve of all the
derision people have directed at us. But we didn't. The New York Times got
it flat wrong.
I'll describe what we built, how it works, and its limitations. But first,
some background on the problem we're trying to solve in PGP 5.5.
A couple of years ago, the government sugarcoated their surveillance plans
by switching from "key escrow" to "key recovery," and trying to sell
surveillance to people by pointing out some of the downsides of strong
cryptography, and selling key recovery as the way around them.
One of the downsides of cryptography is that if you lose your passphrase
(or token, PIN, smart card, or whatever), you've lost your data. My
favorite way of expressing this problem is, "if you lose the keys to your
car, then you have to get a new car."
This downside is particularly insidious for a number of reasons. First,
without fixing that problem, strong cryptography will be in some sort of
limbo. You want to use it to protect your valuable information, but you
won't want to use it for any information that's *too* valuable, because
it's easily lost. Crypto-protected information is fragile, and this
fragility could hurt its widespread deployment.
Worse, this gives the government a rationale for regulating cryptography.
Like it or not, government has a mandate to protect the people from
dangerous technologies, be they in foods, drugs, autos, or information
technologies. Many people believe that the government uses this mandate as
a rationale for acquiring power, many people would prefer that they let us
take our chances, but that's not germane to this discussion.
It *is* germane to note that when you hear some ham-fisted remark about how
surveillance is like air bags, they are saying: they have to protect people
from dangerous things, crypto is dangerous, therefore they have to protect
people from crypto.
When they started mumbling along these lines, the privacy community got
their own act together and started describing what we believe to be the
real solution. This is called "data recovery." The first time I heard the
term, I hated it. I still hate it. The reason I hate it is that it's got
the word "recovery" in it, which makes it sound to someone who isn't paying
a lot of attention that all recovery systems are basically the same thing.
Most of the people in the world don't pay a lot of attention most of the
time. When I was at HIP97 this August, I was amused to hear cypherpunks
chanting, "Data recovery good, key recovery bad." The sublimely Orwellian
tone of this mantra makes me laugh and cringe at the same time. (To explain
the reference, in Orwell's "Animal Farm," there's a revolution in the farm
and the animals take over, run by the pigs. One of the slogans they have is
"four legs good, two legs bad." By the end of the book, the pigs are nigh
indistinguishable from the people. But I digress.)
The essence of data recovery is that focusing on the keys is a canard. If
you've misplaced your data, you want the data back, not the keys. The only
people who want your keys are people who want to spy on you. If you've
locked yourself out of your car, you want the use of your car, not the just
the key. Thus, the solution to encrypted data being fragile is to let
people get to the data. Simple, obvious, but subtle, because the key to
getting the data is the key.
If you don't like data recovery, you aren't going to like what we did in
PGP 5.5 -- we built a data recovery system. Some people aren't going to
like it, and some of those will think this missive is a load of
self-serving twaddle. Myself, it gives me the same mildly uncomfortable
feeling that fake rocks for spare keys do, or skeleton keys do, financial
audits, or any other similar technology. Uncomfortable feelings aside, if
the fragility problem is not solved, then many people who should be using
crypto won't, and government will continue to view this problem as a
question of public safety, and thus in their mandate to regulate.
Data recovery is useful for a number of things. Perhaps you lost your
passphrase. Or data might have been encrypted by an employee or co worker
who was in an accident. (As an aside, fifteen years ago, the architect of a
product I worked on was in a severe car wreck. He was not killed, but
suffered brain damage and has never returned to work.) Your spouse might
need access to financial records. Everyone, be they an individual,
business, or coporation has a right to having their data protected, and
protection not only means being able to put it into a safe, but getting it
out of that safe later.
What makes data recovery different from key recovery? In my opinion, data
recovery allows you to get encrypted data without compromising the key of
the person who encrypted it. Data is property, and keys are property. An
ethically built system allows emergency access to data without destroying
the property of the key owner.
Ethically built data recovery software has a number of properties:
(1) It is surveillance-surly. It should be impossible or unwieldy for an
adversary, be they government (yours or foreign), dirtballs (such as
crackers), business competitors (who sometimes count as dirtballs), or
others to use this against you. The system should also be aware of how
passive surveillance (like traffic analysis) interacts with it.
(2) It is an "opt-in" system. Users must consent to it, and must take some
action to start using it. It should be as easy as possible to stop using
the system. The system must also allow someone who does not opt in to use
all the system's features. Please note that abuses of consent (for example,
an employer who says, "consent or we fire you") are something we can't
prevent in any system.
(3) It must obey the principle of fair warning. If you send me a message
that is subject to data recovery, you should know that before sending the
message. This way, if you don't agree with my policy, you can decide not to
send me that message. This interacts closely with the opt-in principle above.
(4) The data recovery system should be preferable to an escrow system. A
number of corporations who use PGP keep copies of their employees' secret
keys. This is both odious and dangerous. Escrowed keys are a target for
attackers, subpoena-bait, and potentially ruin the value of digital
signatures. It's just bad policy.
(5) The system has to allow someone under a legal threat to respond
effectively to that threat. Legal threats include warrants, subpoenas, and
discovery processes. You have to be able to respond to the request for
information without losing your keys and thus all of your data.
(6) It must also provide a response to those who would regulate crypto in
the name of public safety. Fortunately for us, potential regulators have
focused on the horsemen of the infocalyse. There are other
pseudo-public-welfare threats including the rights of a person to their
spouse's records, or the rights of heirs to information property. We, the
people who design privacy systems, have to think about what happens when
the regulators stop dragging out the pornographers and start dragging out
the poor widows and orphans.
Note that these requirements are not completely consistent with each other.
For example, an opt-in system is riskier than an opt-out system, yet
friendlier to one's own privacy. Balancing these requirements is part of
the difficulty of good software design.
If you have been skimming the above, wondering when I'm going to get around
to actually telling you what we did in PGP 5.5, this is it.
With PGP 5, there are a number of attributes of your key that are stored in
a self-signature. For example, your preferred symmetric algorithms are
stored in your self-signature. The data recovery feature -- which we call
"Corporate Message Recovery" -- is an attribute in your self-signature that
tells anyone who receives your key that you want messages encrypted to you
to also be encrypted to that other key. There is also a flag that tells the
encryptor, "please" or "I insist." Architecturally, there can even be more
than one recovery key. That's it. That's all it is.
Well, that's mostly all it is. There are other bits of the system. For
example, if I look up Alice's key on a key server and Alice has a recovery
key, I get Alice's recovery key, too. If Alice's recovery key is a "please
use" key, then I can encrypt to Alice alone. In any case, the PGP software
tells me that Alice has a recovery key, so I can decide to use some other
mechanism to talk to her.
Note that design satisfies the opt-in and fair-warning requirements. Also,
since Alice's recovery key is an attribute of her self-signature, she can
change it. She can even have a second user name (let's call it Bob), that
has no recovery key.
Also, we have three encryption products: PGP freeware, PGP for Personal
Privacy, and PGP for Business Security. Corporate Message Recovery is
included *only* in PGP for Business Security. It is not, and never will be,
in either the freeware or the Personal Privacy product. It is an extra cost
item that we created for businesses as per their requirements. As I stated
above, a number of these businesses keep copies of their employees' secret
keys. One of the reasons we created this feature is to satisfy their
requirements with some mechanism that is less blunt than key escrow.
When a PGP message is formed, there are a number of "packets" that make up
the message. The usual construction is that there is a "session key" packet
for each public key that the message is to be read by. Following that is
the actual message packet, that is encrypted with a symmetric cypher to
session key. The session key packets specify the *key*, by its 64-bit key ID.
This is an important and subtle point. Let's go back to Alice, a.k.a. Bob.
The information that specifies a recovery key is in a self-signature of a
user name, but the session key specifies a public key by keyID. It is
impossible, solely from looking at a message, to know if it is addressed to
Alice or Bob because that information is not stored in the message. A
message that does not honor recovery is syntactically correct.
I don't know why Bruce Schneier said that this is everything the FBI wants.
If it is, then they have changed spots! One of the major ways PGP's system
differs from anything else I've seen is that it has no enforcement built
into the protocol. This helps make PGP surveillance-surly, with or without
Corporate Message Recovery. If this is all the FBI needs, then they've
decided the way to get your files is to knock on your door with a warrant,
and that's a big, big, big step forward.
Getting back to the system, I'm sure you've noticed a gotcha there. If I
mail Alice a message that I encrypted to Bob, she can decrypt it, but the
recovery key can't. If you've been paying very close attention, you have
wondered something akin to, "hmm, if Alice's key accidentally lost its
self-signature, there would be no way to encrypt to her recovery key."
You're right. If Alice really wants recovery on messages sent to her, then
she has to use our SMTP Policy Management Agent.
The policy management agent is an SMTP proxy. You can configure it to do a
number of things. Most relevant to this discussion is that Alice can use
the policy agent to require that her recovery key gets used. However, the
policy agent does *not* decrypt the message. One of the very good features
of Business PGP is that it does not decrypt the message. It does not
prevent or even try to prevent multiple-encryption. It's really, really
easy to encrypt a message to Alice alone, and then encrypt that message to
both Alice and her recovery key. We're not going to change that. Nor does
the policy management agent archive messages, make copies, notify your
mother, or any of the other things we've been accused of doing with it.
It's simply the gatekeeper that enforces Alice's corporate policy.
To sum up, we created the Corporate Mesage Recovery feature to satisfy the
requirements of our customers who need emergency access to data. We made
careful decisions to make it useful and effective for honest people, while
minimizing its potential for abuse. No one has to use it; we do not include
it with PGP freeware, nor with PGP for Personal Privacy. We alert all users
of all products when they encrypt to someone who has a message recovery
key. It is an opt-in system that you can opt out of. It is not a
surveillance system. A few weeks ago, we showed it to the FBI and asked
their opinion. They told us it doesn't meet any of their needs.
- - ------
Jon Callas                                         jon at pgp.com
Chief Scientist                                    555 Twin Dolphin Drive
Pretty Good Privacy, Inc.                          Suite 570
(415) 596-1960                                     Redwood Shores, CA 94065
Fingerprints: D1EC 3C51 FCB1 67F8 4345 4A04 7DF9 C2E6 F129 27A9 (DSS)
              665B 797F 37D1 C240 53AC 6D87 3A60 4628           (RSA)
Jon Callas                                         jon at pgp.com
Chief Scientist                                    555 Twin Dolphin Drive
Pretty Good Privacy, Inc.                          Suite 570
(415) 596-1960                                     Redwood Shores, CA 94065
Fingerprints: D1EC 3C51 FCB1 67F8 4345 4A04 7DF9 C2E6 F129 27A9 (DSS)
              665B 797F 37D1 C240 53AC 6D87 3A60 4628           (RSA)

@_date: 1997-10-09 05:54:21
@_author: Jon Callas 
@_subject: What's really in PGP 5.5? 
>Also, we have three encryption products: PGP freeware, PGP for Personal
   >Privacy, and PGP for Business Security. Corporate Message Recovery is
   >included *only* in PGP for Business Security. It is not, and never will
   >be, in either the freeware or the Personal Privacy product.
   If this is true (and I have no reason to believe it isn't), then why is the
   key escrow code written (although not turned on) in the source code for 5.0
   that was posted internationally from PGP?
Bruce, I understand that you don't like any form of data recovery, but
there is no key escrow in PGP. Perhaps we should talk about this on the phone.
   Makes no sense.
   Bruce
Jon Callas                                         jon at pgp.com
Chief Scientist                                    555 Twin Dolphin Drive
Pretty Good Privacy, Inc.                          Suite 570
(415) 596-1960                                     Redwood Shores, CA 94065
Fingerprints: D1EC 3C51 FCB1 67F8 4345 4A04 7DF9 C2E6 F129 27A9 (DSS)
              665B 797F 37D1 C240 53AC 6D87 3A60 4628           (RSA)

@_date: 1997-10-09 07:27:31
@_author: Jon Callas 
@_subject: What's really in PGP 5.5? 
> Like it or not, government has a mandate to protect the people from
   > dangerous technologies, be they in foods, drugs, autos, or information
   > technologies.
   Please tell me where it says this in the U.S. Constitution.
   In particular, please tell me where the FEDERAL government is assigned    this power.
   Thank you.
There are a number of places. The usual one they abuse is what's called the
"commerce clause" which lets them regulate interstate commerce. They also
drag in "providing for domestic tranquility" or anything else that looks good.
If you'll look again at my next sentence, I said, "Many people believe that
the government uses this mandate as a rationale for acquiring power, many
people would prefer that they let us take our chances...." I'm one of those
many people.
One of the very sad things in our history is that limitations on Federal
power became hostage of the race issue a century ago. "States Rights" is a
real issue because the Constitution places severe limits on what the
federal government is supposed to do. Unfortunately, that term is nigh a
synonym for justification of slavery, racial segregation, and other odious
things. Limits on the federal government are a casualty of the War Between
the States.
Recently, the courts have been reversing this trend, tossing out some laws
that are justified by the commerce clause. A number of scholars predict
this will increase. We can only hope.
Jon Callas                                         jon at pgp.com
Chief Scientist                                    555 Twin Dolphin Drive
Pretty Good Privacy, Inc.                          Suite 570
(415) 596-1960                                     Redwood Shores, CA 94065
Fingerprints: D1EC 3C51 FCB1 67F8 4345 4A04 7DF9 C2E6 F129 27A9 (DSS)
              665B 797F 37D1 C240 53AC 6D87 3A60 4628           (RSA)

@_date: 1997-10-09 08:53:12
@_author: Jon Callas 
@_subject: What's really in PGP 5.5? 
Hash: SHA1
   If this is true (and I have no reason to believe it isn't), then why is the
   key escrow code written (although not turned on) in the source code for 5.0
   that was posted internationally from PGP?
I just got through talking to one of the developers, and think I found what
you're talking about, Bruce.
In "pgp.c" of the Unix 5.0 published edition, there's some old Viacrypt code
with a comment that says, 'This is our version of "Commercial Key Escrow"' but
in fact just adds an additional recipient to the encryption list.
It is not in any shipping PGP product. If there's anything to laugh about
in all
this, if you try to use the feature in the Unix freeware, it core-dumps. It
doesn't appear at all in the Mac and Windows code.
It's completely gone as of now.
Jon Callas                                         jon at pgp.com
Chief Scientist                                    555 Twin Dolphin Drive
Pretty Good Privacy, Inc.                          Suite 570
(415) 596-1960                                     Redwood Shores, CA 94065
Fingerprints: D1EC 3C51 FCB1 67F8 4345 4A04 7DF9 C2E6 F129 27A9 (DSS)
              665B 797F 37D1 C240 53AC 6D87 3A60 4628           (RSA)

@_date: 1997-10-10 02:39:33
@_author: Jon Callas 
@_subject: What's really in PGP 5.5? 
Here is what happens if you are using freeware/personal privacy:
It brings up a dialog box and gives you the option of encrypting to Alice
alone or Alice plus her corporate recovery key. If the "strict" flag is set
on Alice's CMRK and you remove it, we display a dialog box that wags a
finger at you and tells you you're being naughty, but that's it. If you
remove Alice's CMRK from your key ring, it just sends to Alice alone and
doesn't bother you at all.
If this isn't what happens, it's a bug. Tell us, we'll fix it.
Jon Callas                                         jon at pgp.com
Chief Scientist                                    555 Twin Dolphin Drive
Pretty Good Privacy, Inc.                          Suite 570
(415) 596-1960                                     Redwood Shores, CA 94065
Fingerprints: D1EC 3C51 FCB1 67F8 4345 4A04 7DF9 C2E6 F129 27A9 (DSS)
              665B 797F 37D1 C240 53AC 6D87 3A60 4628           (RSA)

@_date: 1997-10-11 06:07:04
@_author: Jon Callas 
@_subject: Why Corporate Message Recovery isn't Key Escrow 
Hash: SHA1
A number of people have asserted that the Corporate Message Recovery
feature is
key escrow. From where I sit, the difference is easy to see. My definition of
"key escrow" is that another person or organization keeps a copy of the user's
secret key.
Here's an example, based on actual customers who use key escrow to manage
This corporation uses PGP for a number of things. Email, engineering plans,
drawings, and so on. They've done so at least since the days when we were
Viacrypt, and I believe they even used PGP 2.x.
When an employee arrives at this company, they create a key pair for the new
employee, hand it to them on a floppy, keeping a duplicate floppy with the
keypair on it, which they toss into a safe. Literally. This is key escrow.
do this because they can't afford to lose their files and messages. Their
policies require them to keep the secret keys, as if they were the same as
to offices or file cabinets.
I don't know about you, but I'm appalled. Nonetheless, they're our
customers. In
spite of inheriting them, we have a responsibility as businesspeople to at
listen to their concerns. - From our standpoint, the issue gets even touchier. They don't like what
doing, and they want us to give them a better way to manage their data. Does
anyone really believe that only moral response is to flinch and turn away?
I'd like to be in a situation where I didn't have to deal with this. Wanna
positions? I'll sit over there and cluck my tongue about how adding an extra
recipient weakens security while you figure out how to help these folks out of
the mess they're in. While you're at it, I'll pen a few lines about how giving
clean needles to addicts undermines society, and handing out condoms
kids to have sex. Trust me, it's less nerve-wracking than what we have to
do to
solve this problem, which involves running through hypothetical scenario after
hypothetical scenario, balancing the user's privacy against the organizations
property rights, the privacy and property rights of one organization against
that of another, and so on.
Corporate Message Recovery isn't key escrow for a number of reasons. First, it
doesn't involve keeping a copy the end-user's secret key. I hope that's
now. Second, the system behaves very differently. With a key escrow system, there is a superb McGuffin (which is what Alfred
Hitchcock called the crux of a mystery, like the falcon in The Maltese
Falcon) -
 it's the safe. Break into the safe, or lend its contents out, and all Hell
breaks loose. Whoever has those keys (which easily fit on a single Zip
disk) has
the company at its mercy. They can decrypt or sign anything they care to.
is a great thriller to be written here.
It isn't so with a CMRK. The worst possible way to use the feature is to
have a
single, company-wide CMRK. If that gets lost, the thriller you can write isn't
nearly as interesting. Yup, you can steal any of the plans, read all the mail,
and so on. That's bad. It's deplorable, actually. But it isn't a difference
makes no difference. At least there isn't a gang of keys out there that can
anything with anyone's ID.
This is not the only way to use Corporate Message Recovery, it's just the
way. Remember, it's just a notation in the self-signature that states,
"When you
encrypt to me, encrypt to X." That's any X. You can have a different CMRK for
every department, every workgroup, or even every user.
A sophisticated policy might be that every user sets their supervisor's key to
be their CMRK. Another is that everyone in Department X sets their office
or lab partner, or other person. You can have anything that suits your group,
from Recovery Central, to Recovery Hierarchy, to Recovery Buddy System.
The significant improvement that PGP's web of trust has over a traditional
hierarchical system is that you can set up a top-down system for validity, but
you don't have to (and in our opinion, shouldn't). Analogously, the
improvement that Corporate Message Recovery has over key escrow is that you
tailor a recovery system to your needs (including and especially deciding it's
not for you). Jon Callas                                         jon at pgp.com
Chief Scientist                                    555 Twin Dolphin Drive
Pretty Good Privacy, Inc.                          Suite 570
(415) 596-1960                                     Redwood Shores, CA 94065
Fingerprints: D1EC 3C51 FCB1 67F8 4345 4A04 7DF9 C2E6 F129 27A9 (DSS)
              665B 797F 37D1 C240 53AC 6D87 3A60 4628           (RSA)

@_date: 1997-10-11 06:09:07
@_author: Jon Callas 
@_subject: PGP CAKware & IETF controlled Open-PGP standard 
I am adamantly opposed to any of PGP's business features being MUST
features of OpenPGP. If they were, then our freeware and personal privacy
products wouldn't be conforming applications, and we have *no* intention of
putting them in those products. Wouldn't that be an interesting situation?
I am strongly opposed the business features being SHOULD features. If I
were the only one arguing against them being SHOULD features, I'd make my
opposition clear and then shut up.
I am in favor of them being MAY features, along with a big section on
polite use. Jon Callas                                         jon at pgp.com
Chief Scientist                                    555 Twin Dolphin Drive
Pretty Good Privacy, Inc.                          Suite 570
(415) 596-1960                                     Redwood Shores, CA 94065
Fingerprints: D1EC 3C51 FCB1 67F8 4345 4A04 7DF9 C2E6 F129 27A9 (DSS)
              665B 797F 37D1 C240 53AC 6D87 3A60 4628           (RSA)

@_date: 1997-10-11 06:34:06
@_author: Jon Callas 
@_subject: Why Corporate Message Recovery isn't GAK 
Hash: SHA1
There are two things I will discuss in this missive:
(1) The assertion that Corporate Message Recovery is "just like Clipper"
and why this is not true.
(2) The fear a number of people have expressed that Corporate Message
Recovery (CMR) could be used by the US government to slide in GAK. I think we're agreed that CMR isn't itself GAK and I'll talk some about why
it isn't with (1).
CMR isn't like Clipper:
* Clipper was a 64-bit key. CMR symmetric keys are full-strength keys (128
bits or more), backed with a full-strength public key.
* Clipper's key was set in hardware by the manufacturer, and users were
required to use it. A CMR key is a software-enabled key, no user is ever
required to use it. There are cases in which a user might "volunteer" to
use a CMR because they work for someone who requires it, but that's a
problem we'll address with the PGP Secure Resume Server which allows
headhunters to securely and anonymously find people who've made bad career
As a corollary of of the previous paragraph, there's no reasonable
guarantee with a Clipper device that you haven't been black-bagged with an
insecure key. Using a CMR may be unwise, but at least you knowingly did it
to yourself.
* A CMR key can be revoked, reissued, or changed. You can periodically
change it as a matter of policy. You can even stop using it. Clipper's was,
again, set in hardware, with no option of not using it. * The Clipper symmetric algorithm was secret; CMR keys use publicly
available algorithms.
* With Clipper, there was always a concern that an outside agency had the
keys. This is true with a number of other systems (the so-called key
recovery systems), and is the reason that a number of them are lumped
together with the term GAK. Note that the user-organization creates a CMR
key, and the end-user enables it. If any government gets access to this
key, it is because either (1) they solved the Discrete Logarithm Problem,
(2) they broke the public CMR key, (3) they black-bagged your CMR key, or
(4) they are using a subpoena, warrant, or discovery to get the key. We're
working on a way around (1), we can't do anything about (2) or (3), but
these are fine reasons not to use CMR! If you're beset by (4), you need
lawyers, not cryptographers.
* With Clipper, there was a central repository of all the keys. With CMR,
there is not. I discussed that in detail in my message, "Why Corporate
Message Recovery isn't Key Escrow."
I have noticed that a number of people have the tacit assumption that
business people and corporations are in cahoots with the FBI, waiting to
hand over everyone's secret key. As in all parts of life, there are many,
many businesspeople and corporate execs who are not particularly moral. But
I don't think that their immorality takes this form. If we could examine
the dark, secret thoughts of a corporate scumwaffle -- the ones that he
*really* hopes don't hit the papers -- I sincerely doubt that, "Oh, Louis,
I love it when you rummage my drawers" is among them.
Now then, the next topic is the fear that CMR will be used in some
insidious government plot to slip in GAK everywhere.
I worry about this, too. But I don't think it's feasible that CMR can be a
stalking horse for GAK. If the government wants to GAK-enable all PGP,
they'll have to have a plan similar to this:
(1) Buy PGP, Inc. Since our worth is less than the black portion of the
Federal Budget, this is not impossible. Would that it were otherwise. Heck,
we're probably worth less than the black portion of New Zealand's budget.
(2) Fire all the current development staff. This isn't very hard. All the
new bosses have to do is round us up in a meeting and announce, "The next
version of PGP will have a 40-bit export option." We'll say, "Not while
*we're* working for the company!" They'll say, "Fine with us." Keep your
eye on the secure resume server for clues of this event.
(3) Hire a new staff. This is one of the places that the plan might fall
apart. We have such a hard time finding anyone who's qualified to work for
us that we have reqs we can't seem to fill. I suppose, though, that they'll
be able to find some people willing to relocate from Maryland.
(4) Stop the OpenPGP process in the IETF. Some people think that we did
this as part of our Evil Plan to Take Over the World by Giving Away
Software (hey, it almost worked for Netscape). Other people think it's part
of our Evil Plan to Take Over Crypto by Using Unpatented Algorithms. I can
neither confirm nor deny these, but I *will* tell you that it's part of our
Sniveling Plan To Convince the Feds They Can't Kill PGP by Killing Us,
which the source code books also fall into. If OpenPGP succeeds, then
anyone can build an interoperable version of PGP, not just us, Highware,
Systemics, etc.
(5) Wait until bitrot makes all those existing copies of PGP stop working.
I could make a few catty remarks about how quickly existing software stops
working on new releases of OSes, but you've probably thought of them yourself.
There are also a few details left, like shutting down all those
international FTP sites, but hey, they're the government, they're omnipotent.

@_date: 1997-10-11 09:13:50
@_author: Jon Callas 
@_subject: Attitude and Assumptions 
Hash: SHA1
In the course of all the discussion here, I have seen a number of implicit
attitudes and assumptions that irritate me. This is a short rant to air my
The first thing that bugs me is what I'm calling Crypto-Correctness. I
don't know a single person on cypherpunks who is against privacy, or is
against the notion that in the information society, keeping and bearing
crypto is an inalienable human right. Politically, I'm a Lockeian, and put
privacy up there with Locke's basic trio of life, liberty, and property. As
part of this, I fight the stupid notion that because there are bad people
out there, rights should be abridged. Crypto is a tool, and nigh any useful tool can be misused. If we let that
fact stop us from making tools, we'd be using nerf axes and dressing in
bubble wrap. If we let the fact that bad guys are using our stuff bother us
too much, we'd be against privacy.
Here at PGP, we like to make hay out of the fact Burmese freedom fighters
use PGP. A while ago, Tim May sent out something in which he stated that
Hamas uses PGP, making the very valid point that one person's freedom
fighters are another person's terrorists. He implied that they're not using
just to tell each other where the best hummous shops are, and I don't doubt
it. I like to say (now that I'm no longer an arms maker) that we are like
the Red Cross in that the Red Cross gives medical attention to everyone,
regardless of their moral worth; we supply privacy software to everyone,
regardless of their moral worth. In the days when crypto was a munition, I
used Winchester as a metaphor, complete with Sarah's cute bungalow.
In its milder forms, Crypto-Correctness thinks that if a bad guy is using
crypto, then it's a mitigating factor on what they're doing. I can see that
it might come from not liking tack-on laws like the clause in the present
bill that makes using crypto to hide a crime illegal. This is deplorable.
But using crypto doesn't make something good.
In some of its other forms, it pushes into what I perceive as
Crypto-Socialism. We just shrug if suicide bombers or paparazzi are using
crypto, but if a property-owner wants to use it, you can just hear the
sharp intake of breath. If that property-owner is Big Business, there are
howls of indignation. I get the impression that some people think crypto
should only be produced by non-profit organizations for the use of
non-profit organizations, or those that had the common decency to get their
profits illegally. The next thing that bugs me is that the government has us so scared of our
shadows that we look askance at anything that might make crypto
mass-market. Right now, crypto is rocket science. Many of the people who
need it most are only going to understand it after years of
acclimatization. The sorts who inhabit the nightmares of tech-support
people are going to take at least one more turn of the wheel of Maya to get
I think a lot of people here think that blade guards on crypto in any form
is stark moral evil. You lost your data? Good. Shows you're not worthy. You
shouldn't have data anyway. Information is property, and property is theft.
In the crypto-anarchist future, after the withering away of the state, you
won't need property anyway. I suppose we'll all just eat e-cash.
I really believe that this panicked, bunker-mentality fear of anything that
might complicate the system with blade guards is doing the cause of freedom
a sever disservice. Business people are subjected to a lot of the asinine
annoyances and minor evils that government brings, too. If we get them on
our side, they will be a powerful ally.
I believe that the central thesis of crypto-freedom is that it doesn't
matter if a document is on paper or in a text file; it doesn't matter if a
conversation is on the phone or in a restaurant. The medium doesn't matter.
My papers and effects have the same protection on a disk as on paper itself.
We all know that deployment is the key. But real deployment means deploying
to people who don't know how their toaster works, too. If we don't solve
this problem, we'll get hit with the backlash. Just you wait, once crypto
becomes trendy, there will be a Time cover story with some headline like,
"How Much Privacy is Enough? Who's Really After You, Anyway?" and in it
will be sob stories about how people lost their passphrases, were
blackmailed by employees (ask me, I have real-world tales of this), or
can't decrypt their backups. Congress will have hearings, and they aren't
going to be fun to watch. Is trying to head this eventuality off (yes, I
believe it's inevitable) really the work of Satan?
The last thing that really, really bugs me is the hostility that's directed
towards PGP Inc. because now we're an Inc.
The core group of people who are here are the same people they always were,
they're just being paid now. I'd love to be independently wealthy and do
this for the crypto-anarchist, non-profit joy of it, really I would. But
you know, as the great crypto-socialist Balzac said, "behind every great
fortune, there is a great crime" so I suppose we must be up to no good.
This is a blues riff, so let me tell you how we've paid our dues before I
get to the chorus:
We published our source code. One of our potential partners said and I
quote, "Are you mad?"
We stand firm on the issue of No Weak Crypto. A noted GAK proponent asked
me at a conference, "Aren't you folks going to do an export version?" I
replied, "Sure we are." This person asked, "When?" I said, "The day after
the law changes." We put out a freeware product, hoping people will upgrade to the for-pay
version. If you're thinking of your own startup, let me give you some
investment advice: the crowd who thinks the X-files is a documentary
doesn't upgrade to the for-pay version.
We started an IETF working group that will take our core technology and put
it out for anyone to use. They will own change control. We won't be able to
use any patents or intellectual property to enhance our business position.
We won't be able upgrade the protocol without a vote.
The only thing we offer as a selling point is our superb engineering and
our good name. The business version is funding the rest of the ball of wax.
Are you afraid we'll make a deal with the devil? I have two comments on that:
(1) I work in Silicon Valley. I tell headhunters, "no thank you" every
week. I took a pay cut to come here. I can get a 20% raise by going to
WebFoo any time I want. My options aren't worth what I would have gotten as
a layoff package had I stayed at Apple. If I send out an email message that
provides "technical support" to furriners, I could land in jail. I'm here
because I care. Ask the people here who left behind Cisco options at 40 if
they care.
(2) There's one surefire way to make sure we don't make any deals with the
devil. Buy the product. Encourage your friends, your mother to buy the
product. If you see someone who is using the freeware version, send them a
polite message to buy the product. Buy one and send it to your
congresscritter. If you don't, what you're saying is, "crypto-freedom is
very important to me, as long as I don't have to spend $49 on it." Convince
your employer that $119 isn't too much to pay for meta-introducers. Make
the crypto market so hot that someone competes with us by being badder than
Oh, yeah, baby, I got them crypto-startup blues.

@_date: 1997-10-16 10:19:56
@_author: Jon Callas 
@_subject: anti-GAK design principles: worked example #1 
Okay, Adam, I'll be civil here, but here's something I want to note:
You've ranted, raved, politicized, propagandized, given ad hominem attacks,
and stated the opinion that anyone who disagrees with you is evil. You've
sent flames to our internal development lists, which is at least impolite.
Yet you say, "constructive criticism only." Sure. I'd like an apology from
you, though. Deal?
Uh huh. Steer clear of rhetoric, but we'll take it as a given that you're
right and everyone else is wrong. At least this is a de-escalation.
Okay -- constructive criticism only. I sincerely hope I'm reading this
correctly. You're saying that someone's private key should be encrypted to
the corporation's key. This sounds like key escrow to me. How does this
differ from the overly strict, nit-picking, freedom-threatening definition
that I gave? This is better than the throw-the-floppy-in-the-safe model in that the
company-readable version of your key is sitting on your machine. That's good. I see a threat here that if the corporation backs up my disk, they they
have my secret key and thus can read all files that key has ever encrypted.
This is bad. Normally, if they back up my system, they have my secret key,
but they have to hack my secret key. Most people's passphrases are easier
to crack than a public key, but I think this is worse.
With this system, the corporation can read everything I encrypt with that
key, because they effectively own it. Encrypting my secret key to them
essentially gives it to them. With CMR, I have the option of making some
files readable, and some not. This isn't necessarily a good thing -- some
companies want access to all data, and your proposal helps them.
I'm actually very surprised by this design of yours. On the scale of
property-balanced-with-privacy, you've come down hard on the side of
property. Your system makes it so that an employee of a company can *never*
use this key for a purpose the company can't snoop on. This isn't
necessarily bad, I think that people *should* have separate keys for work
and personal use. This just makes the work key definitely the work key. A
number of our customers will like that.
This is security through obscurity. We publish our source code, so this
won't work.
Choosing a new passphrase is not sufficent. If the custodian ever uses that
key, it *must* be revoked, a new encryption key issued, and all data
encrypted with it re-encrypted. There is also the problem of
re-distributing the revocation and new encryption key to all the people who
have your old one. This is no worse than any other revocation problem, but
CMR does not require revoking the user's key.   This is no different with CMR. One of the design goals of CMR is to avoid
the myriad logistic and security problems associated with data archival.
Why? With your mechanism, if the G manages to A the K, then they can
decrypt every message that key has ever encrypted. I think this is a design
flaw. Okay, general observations:
I'm really surprised at this. In the continuum between privacy and
property, you've come down hard on the side of property. You've said that a
key owned by a corporation is *fully* owned by the corporation, and any
employee who uses it for personal purposes is daft. This is not what I
expected you to be arguing.
Enforcement. Most corporations want some level of enforcement on their
policies. The enforcement we put in isn't fool-proof, but it's far easier
to comply than resist. This is a design goal. I have a concern that the
only enforcement that the corporation has is to take your private key. If
this is their only way to make you follow their rules, they'll do it. Many
of them will play nice if possible, but hardball if they have to.
Fair-warning. In my first missive, I talked about my own principles, and
one of them is the "fair-warning" principle. It states that users should
know what is going on. If you have a key that is used in this system, there
is nothing in it that tells me that your company can read a message I send
you. I see this as a flaw, and one that I consider to be a *very* big deal.
Full disclosure is one of my hot buttons.
I think this is breaks a number of your principles.
Principle 1: The end-user's keys *are* escrowed with the company. If my
disk is ever backed up, then the corporation has my secret key. In order to
keep it from being implicitly escrowed, I have to put it someplace like
off-line media that can be gotten to if I'm hit by a bus. If you disagree,
please tell me how this is different from escrow.
Principle 2: The corporation is always a tacit crypto-recipient. It's no
different than CMR, and has the additional disadvantage that senders don't
know that the implicit receivers are there.
Principle 3: Again, the corporation is a tacit recipient in *all* uses of
the key. With CMR, they are an explicit recipient, and it's possible to
exclude them. There's no way to exclude the corporation here.
Principle 4: I don't see how this differs between your proposal and CMR.
Lastly, I here's a summation of what I think.
I think it's an interesting proposal. You're much more of a
corporate-control proponent than I am. I think control and privacy have to
be balanced, whereas you obviously think corporate control is trump. We
disagree there.
I am uncomfortable at the ease with which the end user can lose their key.
The end user must somehow prevent the employer from even so much as backing
up their computer, or it's just plain escrow.
I am uncomfortable not only with your siding with the corporation against
the employee's privacy, but also with your siding against the privacy of
someone who sends a message to the employee. Furthermore, I think that the
absence of a disclosure mechanism in your protocol is for us, a fatal flaw.
We'd never implement a system that does not have disclosure.
I do not see how your system is GAK-hostile. I think it is no more
GAK-hostile than CMR, and potentially more GAK-friendly, because it is
based around manipulating the actual secret key material. The failure mode
of CMR is that an adversary can decrypt messages, whereas the failure mode
of your proposal is that the adversary gets the key.
   Adam
   [1]
   ==============================8<==============================
   GAK-hostile design principles
   If we take the design goal of designing systems including
   confidentiality which are not GAK compliant, we can most succinctly
   state this design goal as the task of ensuring that:
   - at no point will any data transferred over communications links be
     accessible to anyone other than the sender and recipient with out
     also obtaining data on the recipient and/or senders disks
   We can then derive the design principles required to meet the design
   goal of a non-GAK compliant system with confidentiality services down
   to ensuring that:
   principle 1:
      no keys used to secure communications in any part of the system are
      a-priori escrowed with third parties
   principle 2:
      second crypto recipients on encrypted communications are not
      used to allow access to third parties who are not messaging
      recipients manually selected by the sender
   principle 3:
      communications should be encrypted to the minimum number of
      recipients (typically one), and those keys should have as short a
      life time as is practically possible
   principle 4:
      deployment wins.  violating any of principles 1 to 3 whilst
      still retaining some GAK-hostility can be justified where
      deployment is thereby increased to the extent that the violations
      increase the degree of GAK hostility in the target jurisdictions
      overall
   Corrollary 1: Included in design principle 2) is the principle of not
   re-transmitting keys or data after decryption over communication
   channels, re-encrypted to third parties -- that is just structuring --
   and violates design principle 2.
   Corrollary 2: where communications are transmitted which violate
   principles 1, 2 or 3 it is in general more GAK hostile to enforce as
   far as possible that the recovery or escrow information remains in as
   close proximity to the data as possible.
   Corrollary 3: where communications are transmitted which violate
   principles 1, 2 or 3 it is in general more GAK hostile to make these
   communications as difficult to automate as possible.  For example no
   scripting support is given to enforce that GUI user interaction is
   required, and/or that the process is made artificially time consuming,
   and/or that the communication must not use electronic communication
   channels
   ==============================8<==============================
Jon Callas                                  jon at pgp.com
Chief Scientist                             555 Twin Dolphin Drive
Pretty Good Privacy, Inc.                   Suite 570
(415) 596-1960                              Redwood Shores, CA 94065
Fingerprints: D1EC 3C51 FCB1 67F8 4345 4A04 7DF9 C2E6 F129 27A9 (DSS)
              665B 797F 37D1 C240 53AC 6D87 3A60 4628           (RSA)

@_date: 1997-10-17 02:04:16
@_author: Jon Callas 
@_subject: Praise the Lord! / Re: anti-GAK design principles: worked example #1 
I could be wrong, *but*:
     With PGP 5.0, I found that if someone sent me a message that
   was encrypted to someone else, I would get a message telling me
   that I didn't have the proper key, but would not tell me who the
   message *was* encrypted to.
You're right, that was in PGP 5.0. It sucked. It's fixed in 5.5. 5.5 shows
you a nice little box on every message showing you who it is encrypted to.
Jon Callas                                  jon at pgp.com
Chief Scientist                             555 Twin Dolphin Drive
Pretty Good Privacy, Inc.                   Suite 570
(415) 596-1960                              Redwood Shores, CA 94065
Fingerprints: D1EC 3C51 FCB1 67F8 4345 4A04 7DF9 C2E6 F129 27A9 (DSS)
              665B 797F 37D1 C240 53AC 6D87 3A60 4628           (RSA)

@_date: 1997-10-18 02:34:27
@_author: Jon Callas 
@_subject: consensus on pgp? can we consolidate for action? 
>    I have not seen any further discussion on my suggestion to
   >    create a sendmail type daemon which implements DH between
   >    mail clients. this, of course, is on the presumption that DH    >    is a wrapper for an already encrypted packet,    DH between mail clients and servers is a really fine idea if you're
   starting from scratch, but sendmail is such a wretched hive of
   crime, corruption, and villainy that nobody in their right mind
   really wants to mess with it.  You could implement it as a sendmail
   extension using the EHLO stuff, but you'd have to go get people
   to adopt it widely once you'd done it; I suppose if you could talk
   Netscape and Eudora into adding DH exchange to their client code
   and get it into a few popular servers, you'd have a large fraction    of the Internet's email encrypted, which would be a Good Thing.
   It'd still have some major traffic analysis issues,
   and if you want to deal with the Man In The Middle problem,
   you need a key distribution infrastructure, which is much harder.
   An alternative approach is to encrypt everything using IPSEC,
   and you don't have to mess with Sendmail, but there are
   performance issues, and there's a lot of work getting it deployed also.
There's another solution too -- make your mail servers talk with TLS
(Transport Level Security, a.k.a. SSL).
This solves some problems and not others. If your SMTP path includes any
hops, then the message is in plaintext on that machine. Complicating it
further, you cannot reliably enforce what the hops will be. This is one of the reasons that email keys are sometimes considered comm
keys and sometimes storage keys. Jon Callas                                  jon at pgp.com
Chief Scientist                             555 Twin Dolphin Drive
Pretty Good Privacy, Inc.                   Suite 570
(415) 596-1960                              Redwood Shores, CA 94065
Fingerprints: D1EC 3C51 FCB1 67F8 4345 4A04 7DF9 C2E6 F129 27A9 (DSS)
              665B 797F 37D1 C240 53AC 6D87 3A60 4628           (RSA)

@_date: 1997-10-18 08:07:57
@_author: Jon Callas 
@_subject: what is purpose of CMR? 
This is a question which I am unclear on about PGP Inc's design goals
   in using the CMR method.
     Is the CMR field to allow the company to recover from the user
     forgetting his password?  (recover his mail folder full of encrypted
     email).
   or
     Is the CMR field to allow the company to read the email in transit
   This seems like a fairly important distinction.
It's not for surveillance. It's for recovering from disaster. I think it
would be a good thing to send a PGP message over an encrypted link (TLS or
Jon Callas                                  jon at pgp.com
Chief Scientist                             555 Twin Dolphin Drive
Pretty Good Privacy, Inc.                   Suite 570
(415) 596-1960                              Redwood Shores, CA 94065
Fingerprints: D1EC 3C51 FCB1 67F8 4345 4A04 7DF9 C2E6 F129 27A9 (DSS)
              665B 797F 37D1 C240 53AC 6D87 3A60 4628           (RSA)

@_date: 1997-10-23 02:58:27
@_author: Jon Callas 
@_subject: PGP 5.5 CMR/GAK: a possible solution 
Thanks. I want to add that what's in 5.5 is hardly what we think is
perfect. The system is designed simply to be preferable to key escrow. We
have some improvements we're planning for it in the future. So you're right

@_date: 1997-10-23 03:17:10
@_author: Jon Callas 
@_subject: shared keys, proxy encryption (was Re: PGP 5.5 CMR/GAK: a possible solution) 
> The current system sends out a user's personal key, with a tag to say
   > if I don't encrypt to the company as well, my mail will bounce. But think
   > about this: how often do I want to send email to a particular person in a
   > company, and ensure that only they see it? And how often do I want to
   > mail to a particular group inside a company? All I want is to ensure that
   > I get a response from the company, I usually don't care who I talk to
in the
   > process.
   The CMR feature in pgp5.5 isn't so far intented to cope with this
   scenario I think.  That's because pgp5.5 I understand can only
   generate keys with one CMR request field.
Well, Adam, you are yet again describing it wrong. You can put in N of
them. You are right that the 5.5 UI isn't general. Something had to slip.
Also, there's another thing you're not describing correctly. This is not a
feature of the key -- it's a feature of the user name, and included in a
user name's self signature. It can be changed at any time, and you can even
have an ambivalent key that has a username with the CMR packet
(salesdweeb at foobar.com) and a without it (jblow at foobar.com).
   Problem for both approaches is re-keying: what happens when Fred
   leaves the sales team to work for a competitor.  Revoke the shared key
   and start over?  Or with the CMR method, revoke just the CMR request
   for Fred, and allow key servers to remove CMR requests when presented
   with a suitable CMR request revocation cert?  (How often will senders
   check key servers for revocation certs?)  Or have short expiries on
   encryption-only keys (one per day?), so that they key update happens
   soon enough anyway.  (pgp5.x allows for short lived encryption keys
   directly because of the separation of signature and encryption keys,
   the WoT applies to the signature key).
This is why any sort of shared or escrowed keys suck. But in most cases
it's good enough, because when Fred leaves sales, he loses access to the
sales computers. In most of these cases, when someone decrypts something
with the sales key, it ends up going into the order system in plaintext
However, one of the features of the new PGP key format is that you can
change encryption keys easily. If you
   Really it seems to me that actually having half a dozen sales droids
   sharing a key, or being able to decrypt a message because they are all
   CMR enforced multiple crypto recipients is a security nightmare either
   way :-)
   Reckon it would be arguably more secure to have the SMTP policy
   enforcer decrypt it for them, even.
Really? You think the SMTP agent should be decrypting? Wow. I don't. I
think that's *really* intrusive, and worse than what we did. Interestingly
enough, there are a number of people (like Bruce Schneier) who have no
problem with the additional encryption part, but think that the SMTP agent
is the work of the devil. Expect pushback.
   Another method of authenticating TLS is to base the authentication on
   the user's PGP WoT.  Include authentication information to the
   delivery agent which is capable of TLS, which is also exchanged inside
   the encryption envelope.  (Eg. transfer an authentication symmetric
   key k1 inside the encryption envelope; send the local TLS capable SMTP
   hub / SMTP policy enforcer the key k1.  The TLS forward secret key
   negotiation can then be authenticated using this key.  The remote TLS
   system can tack the authentication information on to the delivered
   message, in a header, or otherwise, and the recipient can check the
   authentication).
Note that the user's WoT is stored in the user's keyring. There's an
operational problem here. This means that the MTA has to have access to all
users' pubrings. This is not a good thing, to my mind.
   > So PGP's "everything private unless you choose to make it public" system
   > seems backwards. Surely what we really need to meet these customer
   > is an "everything public (within the company) unless you choose to
make it
   > private" system? That is, all mail to my department inside the company
   > should be encrypted to a department key, shared by all members, *unless*
   > it is confidential, in which case it should *only* be encrypted to me.    I think what PGP are arguing for is ability to recover stored messages
   even if they are intended for one recipient only.  As I think has been
   established this can be acheived by storage recovery, without exposing
   communications traffic to the associated risks.  It is possible that
   there is an unstated perceived user requirement, that the messaging
   standard be able to allow third party access to the communications
   traffic directly.
Nope, that's not what we're arguing for. What we're arguing for is an
alternative to key escrow -- the kind where your employer keeps your secret
key just in case they need it.
Jon Callas                                  jon at pgp.com
Chief Scientist                             555 Twin Dolphin Drive
Pretty Good Privacy, Inc.                   Suite 570
(415) 596-1960                              Redwood Shores, CA 94065
Fingerprints: D1EC 3C51 FCB1 67F8 4345 4A04 7DF9 C2E6 F129 27A9 (DSS)
              665B 797F 37D1 C240 53AC 6D87 3A60 4628           (RSA)

@_date: 1997-10-26 18:18:34
@_author: Jon Callas 
@_subject: I Broke PGP!!! 
Jon
Jon Callas                                  jon at pgp.com
Chief Scientist                             555 Twin Dolphin Drive
Pretty Good Privacy, Inc.                   Suite 570
(415) 596-1960                              Redwood Shores, CA 94065
Fingerprints: D1EC 3C51 FCB1 67F8 4345 4A04 7DF9 C2E6 F129 27A9 (DSS)
              665B 797F 37D1 C240 53AC 6D87 3A60 4628           (RSA)

@_date: 2004-12-16 21:28:59
@_author: Jon Callas 
@_subject: pgp "global directory" bugged instructions 
References: Thanks for the bug report. We appreciate your help in fine-tuning the language in the verification emails of the beta test of the PGP Global Directory. We noticed this one, ourselves, and put out an improvement to it on Tuesday. Please check it over and see what you think of the improved version.
If you would like to send bug reports to us directly, please feel free to send them to beta at pgp.com. Cypherpunks and Cryptography are both inefficient ways to get them to us, as Cryptography waits for Perry to approve the post, and Cypherpunks waits for Bob Hettinga to forward it.
However, the Global Directory does not consolidate information from any other keyservers. It is a replacement for the old keyserver, keyserver.pgp.com, and will take over that venerable old server's job once beta test is concluded. We are, however, migrating a number of keys from the old keyserver to that one.
Think of the new keyserver as a mix between traditional keyservers, mailing list servers like mailman, and a robot CA. Its intent is to improve upon the older keyservers by giving some modicum of assurance that keys in it belong to someone, as well as allowing someones to recover from forgetting their passphrase.

@_date: 2006-07-09 05:56:15
@_author: Jon Callas 
@_subject: [IP] more on FBI plans new Net-tapping push 
Brian Randell said:
I realize that there was a smiley face at the end of this, and I
might be showing humorlessness about this, but this concerns my
profession in general, and my software in particular. Consequently, I
have no choice but to comment on this remark.
Modern cryptographic systems are essentially unbreakable,
particularly if an adversary is restricted to intercepts. We have
argued for, designed, and built systems with 128 bits of security
precisely because they are essentially unbreakable. It is very easy
to underestimate the power of exponentials. 2^128 is a very big
number. Burt Kaliski first came up with this characterization, and if
he had a nickel for every time I tell it, he could buy a latte or three.
Imagine a computer that is the size of a grain of sand that can test
keys against some encrypted data. Also imagine that it can test a key
in the amount of time it takes light to cross it. Then consider a
cluster of these computers, so many that if you covered the earth
with them, they would cover the whole planet to the height of 1
meter. The cluster of computers would crack a 128-bit key on average
in 1,000 years.
If you want to brute-force a key, it literally takes a planet-ful of
computers. And of course, there are always 256-bit keys, if you worry
about the possibility that government has a spare planet that they
want to devote to key-cracking.
Now of course, there are other ways to break the system.
They could know something we don't. They could know some fundamental
truth about mathematics (like how to factor really fast), some
effective form of symmetric cryptanalysis, or something else. They
could know about quantum computers, DNA computers, systems based upon
non-Einsteinian physics, and so on. Yes, it's possible. But this
quickly gets into true paranoid thought. There isn't a lot of
difference between the *presumption* that they have such things and
the presumption that they have aliens in a vault in Nevada. It isn't
falsifiable. It gets irrational quickly. The evidence that we have
about this suggests quite the opposite, but more on that later.
They could have something we don't. For example, they could know
about software flaws in my or other people's computer systems. Yes,
that's possible, too. At PGP Corporation, we guard against this by
making our software available to people for their examination.
Approximately 2,000 people per month do that. If you want to be one
of them, go to  and look at it
yourself. While you're at it, take a look at our quality assurance
letter at .
They could be hacking people's systems. This is a much more
reasonable worry. If I were going to be doing this, it's what I would
do. The state of computer operational security is such that it makes
much more sense to invest time, money, and effort into rootkits than
into cryptanalysis.
However, there are things that we know that they *are* doing. One of
them is relevant to this particular case. That is work on cracking
the passphrases that people use to protect their keys. The
cryptography we're using is itself uncrackable, but about 2/3 of the
people in the world use a password (not even a passphrase) that
directly relates to a pet or loved one. The order of frequency seems
to be pets (living or dead), then children, then ex-loves. We know
that at least one government has a password cracker that is based
upon building a psychometric model of person who owns the key and
constructing passphrases on that model. If you're a Hollywood private
eye and they seize your computer and find on it that you're a
basketball fan from your browser cache, then "Lak3rz 4 Teh w1n!" is
actually a very bad passphrase. Don't blame me when they find it in
about two minutes.
It isn't just government that does this, either. Companies such as
Access Data and Elcomsoft have distributed password crackers. These
things aren't hacking the crypto, they're hacking the mind using the
crypto. My old friend and colleague, Drew Gross, who is a forensics
expert, has said, "I love crypto; it tells me what part of the system
not to bother attacking."
The last bit of evidence we have that suggests that they can't break
the crypto is that they are apparently devoting a lot of effort to
traffic analysis. Look at what we've learned in the last few months.
Listening for keywords is so twentieth century. They're looking at
call patterns, message flow, and so on. I could go on about this for
a long time, but it's a tangent from this. If you're interested in
more, I am going to be leading a panel at Defcon this August on
traffic analysis. Come liven up the discussion.
Jon Callas
CTO, CSO
PGP Corporation         Tel: +1 (650) 319-9016
3460 West Bayshore      Fax: +1 (650) 319-9001
Palo Alto, CA 94303     PGP: ed15 5bdf cd41 adfc 00f3
USA                          28b6 52bf 5a46 bc98 e63d
You are subscribed as eugen at leitl.org
To manage your subscription, go to
 Archives at: Eugen* Leitl leitl ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]
