
@_date: 2001-11-02 22:00:18
@_author: Rick Smith@Secure Computing 
@_subject: Re: Proving security protocols 
Okay, I'll grab this hot potato.
There are a few cases where a commercial development organization performs formal verification, which would seem to indicate that it can in fact provide benefits that outweigh the costs. In particular, I know that DEC/Compaq and Motorola have used formal verification, at least to some degree, to detect flaws in integrated circuit designs. This makes sense because it's so expensive to recover from an IC design flaw, so it's cheaper to spend money up front on eliminating possible flaws. If you're building your crypto protocols into hardware, particularly silicon, then you might see similar benefits to formal protocol assurance.
On the other hand, the software industry has marketed itself into a situation in which vendors are penalized if they spend too much effort on quality assurance, whether it be formal methods or even just testing. I've heard that NSA put a lot of effort into crypto protocol verification, but they weren't constrained by the same economic forces as others. A colleague who does formal verification of ICs looked at formal verification of non-crypto networking protocols a few years back, and concluded that the developers achieved sufficient quality through conventional testing.
The most recent issue of ACM's Transactions on Info Security carries my article on LOCK TCB assurance costs, and I made a number of observations on the cost/benefit of formal assurance in secure OS development. There's no either/or regarding testing and formal assurance: the question is whether you can afford to take money from your testing budget to pay for formal Bottom line: the LOCK experience suggests that you find more flaws through testing (per unit of resources spent) than you find through formal assurance. You can generally find a way to test (or at least exercise) just about every requirement and capability in a typical software product, but formal assurance can't come anywhere close to that degree of coverage in real world systems. Testing might not detect all flaws, but neither will formal assurance.
Ultimately, the decision to use formal assurance is driven by the types of flaws you need to detect, and the risks to the product caused by such flaws. In LOCK, there was a huge desire to detect covert channels before the system was deployed, and the assurance effort was deemed to be successful at pursuing that goal.
smith            roseville, minnesota
"Authentication" in bookstores

@_date: 2001-11-02 22:03:14
@_author: Rick Smith@Secure Computing 
@_subject: Re: Rubber hose attack 
The thread started with an op-ed piece by Diffie and Landau about MS .Net, briefly noting vulnerability reports about Microsoft's latest 'wallet' (called "Passport" and produced as part of .Net). Evidently the early version was storing passwords in a format that made them trivial to recover.
I think we can all agree that this is a Bad Idea, and that MS might have faced a good deal of liability and negative press if the system had been on-line and their .Net partners had been offering anything worth stealing.
While I prefer to see enterprises deploy strong security measures (especially ones they buy from us :->) it's important to acknowledge how much risk we routinely take, both personally and when operating businesses. We all settle for less than cosmically perfect automobiles, and they pose far more serious risks to us than credit card fraud.
smith            roseville, minnesota
"Authentication" in bookstores

@_date: 2001-11-02 20:13:08
@_author: Rick Smith@Secure Computing 
@_subject: Re: Rubber hose attack 
I might be. And maybe I'll have a terrific story to tell when it's all over. But I'm not daunted by the inconvenience of providing my contact information when I order something on-line, so I'm less likely to be drawn to one of their 'wallet' initiatives. Besides, this isn't the first time Microsoft has proposed a leaky wallet for use by the surfing public. So I'm more likely to suffer a more conventional (and less interesting) type of card fraud. It's happened before.
As I've said before, I think the security community plays an essential role when picking apart commercial security technologies, especially when they turn out to be as flawed as Microsoft's latest balloon.
smith            roseville, minnesota
"Authentication" in bookstores

@_date: 2001-11-02 19:58:36
@_author: Rick Smith@Secure Computing 
@_subject: Re: Rubber hose attack 
Of course. But this hasn't prevented people from acquiring and using credit cards. More to the point, it hasn't prevented the merchants, banks, and credit card issuers from maintaining and promoting this imperfect system. This would suggest that the losses from fraud (which customers don't pay, at least not here in the US) are amply covered by the income they bring in.
This sounds to me like a system that "works" in a practical sense.
An example of an authentication regime that did *not* work would be the password-based mechanism Citibank used on the cash management accounts for their large corporate customers, until they got hacked in the early '90s.
smith            roseville, minnesota
"Authentication" in bookstores

@_date: 2001-11-02 16:35:12
@_author: Rick Smith@Secure Computing 
@_subject: Re: Rubber hose attack 
Hmmm. I'm able to walk into a bank in semi-rural Italy and pull hundreds of dollars out of my credit card account. I'm able to buy subscriptions to Russian news sites. This seems pretty world-wide and Internet-wide to me. Existing systems work pretty well even if they don't achieve some cosmic notion of "Trust" or "Identity."
Of course, the process isn't 100% foolproof, and I'd be less likely to take advantage of it if fraud recovery fell more heavily on me as a consumer. Even so, there are generally enough valid transactions to cover the costs of the invalid ones to Web site proprietors and remote bank branches. Even if computer based mechanisms have shortcomings, the overall system is pretty robust.
If Microsoft's system is too brittle, then they'll pay for it through fraud expenses. If people find it unreliable or untrustworthy, they'll use other mechanisms for buying things. While I would feel compassion for consumers who are hurt or inconvenienced by some huge scam that exploited a poor Microsoft security implementation, such a scenario would be entertaining to Regardless of .Net's expected convenience, most people will probably still patronize non-.Net vendors when they offer better prices, regardless of the inconvenience. It's not that hard to re-enter billing information, especially when compared to driving across town to the discount store instead of using the higher-cost mini-mart down the street.
smith            roseville, minnesota
"Authentication" in bookstores

@_date: 2002-06-28 22:47:43
@_author: Rick Smith@Secure Computing 
@_subject: Palladium: Microsoft Bets the Company 
I have to admit I couldn't understand why, earlier this year, Bill Gates declared that security would be a key element of future Microsoft products. Now it looks like an innovative way to try to dominate the industry again.
This is a 'bet the company' strategy. Traditionally Microsoft has pushed third-party flexibility and programmability (subordinated to their own products, of course) over anything else. This allowed them to promote new sales and upgrades based on improved features.
By moving to security, however, Microsoft must move away from flexibility.
This is risky. Consider a quick history lesson: Why did the Wintel PC prevail over the Mac in the computing community? Answer: economy and flexibility.
Question: What do you give up when you implement a hermetically sealed system as is proposed by TCPA and Microsoft's Palladium? Answer: economy and flexibility.
Complicated cryptosystems are troublesome beasts. This is probably the main reason PKI is "mostly dead" instead of being the foundation of modern infosec. It's time consuming to get all the keys and permissions in the right places, and it costs money to keep all those bits of the infrastructure working. Remember: to make this work, the TCPA and Palladium people have to operate a bureaucracy to issue certificates, validate software, and do background checks. That drives up costs and it's really hard to do this efficiently.
Moreover, hermetically sealed systems like this aren't robust -- they trade off reliability for the protection of the 'protected material.' Things break when you don't expect them to, like the 9/11 recovery workers who had to abandon Windows XP when it died after failing to be properly registered. Your PC crashes more, but you get to watch "Bambi." Gosh.
Given that, most people will try to use non-TCPA computers whenever a PC isn't intended as an entertainment nexus. This turns the TCPA/Palladium machines into glorified set-top boxes and perhaps a 21st century Divix.
The only hope for TCPA and Palladium is for Congress to outlaw normal computers. Frankly, if grassroots computer users lose that battle, we deserve what we get. And we'd end up with the 21st century version of Prohibition in which people smuggle in large-screen monitors and unfettered motherboards instead of bathtub gin.
smith            roseville, minnesota
"Authentication" in bookstores
