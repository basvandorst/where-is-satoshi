
@_date: 2004-07-06 21:47:43
@_author: "Hal Finney" 
@_subject: Re: Email tapping by ISPs, forwarder addresses, and crypto proxies 
Right, mostly for use as disposable email addresses.  I've used
spamgourmet to good effect, myself.
One thing I haven't understood in all the commentary is whether law
enforcment still needs a warrant to access emails stored in this way.
Apparently the ISP can read them without any notice or liability, but
what about the police?
Also, what if you run your own mail spool, so the email is never stored
at the ISP, it just passes through the routers controlled by the ISP
(just like it passed through a dozen other routers on the internet).
Does this give the ISP (and all the other router owners) the right to
read your email?  I don't think so, it seems like that would definitely
cross over the line from "mail in storage" to "mail in transit".
That's a great idea.  You'd want to be sure and encrypt the whole message
including headers, and make the whole thing an encrypted attachment.
Has the added side benefits of compressing the email, and you could even
have the server do some spam filtering.
STARTTLS support at the proxy should pretty much go without saying these
days, so you might as well do it, but if you're already PGP encrypting
then it's not adding that much security.  Well, maybe it does, but you're
talking about a different threat.  For the problem that ISPs can read
your email in storage, STARTLS doesn't help much because it will only
protect the email until it gets to your local ISP, who will store your
email for you and can read it then (which is where the PGP comes in).
Where STARTTLS would help is with power users who run their own mail
servers.  But those people don't suffer from the problem we are talking
about here, legal access to the email by the ISP (I think, see above).
Nevertheless a mail-receiving proxy that uses STARTTLS connections to
power users would be kind of cool because it would keep anyone local
from knowing anything about the incoming mail.  Hopefully, STARTTLS will
eventually become so widespread that this functionality will be redundant,
but we are not there yet.
Absolutely, look at the threat model.  You're not worried about someone
breaking into your computer, you're worried about your ISP legally
reading your email.  To address this threat, auto-decryption is a
perfect solution.
Recently there was a proposal for a nym receiving service,
 by Bran Cohen and Len
Sassaman.  They have a complicated protocol for downloading email
anonymously.  To hide the complexity, they propose to set up a POP
compatible mail server agent on the user's computer running as a daemon
process (Windows service).  He would configure his mailer to connect to
localhost:4949 or whatever, just like any other POP server.  The service
would periodically go out and poll for email using the fancy protocol,
but then it would make it available to the local mail agent in perfectly
vanilla form.  The point is that this architecture hides the complexity
and makes it transparent for end users to use arbitrarily complex crypto
for mail receiving.  Something similar would be perfect for your idea.
I think it's a great idea.  Of course as you say there is still the
problem that the forwarding server could read your email, so you have
only moved the threat from the ISP to another operator.  The difference
I suppose is that the forwarder would be selling privacy services, hence
different ones would compete to get a good reputation.  Any cheating might
be detected by insider whistle blowers or perhaps some kind of audit.
Hal Finney

@_date: 2004-08-11 00:18:08
@_author: "Hal Finney" 
@_subject: DAA and Credentials 
A few weeks ago Adam Back sent me a pointer to a paper with what was
basically a new anonymous credential system, by Brickell, Camenisch
and Chen, I've followed Jan Camenisch's work pretty closely over the years and
although he is only the 2nd author here, the paper is very much based
on his ideas.
Actually the paper is about a very controversial topic, trusted computing:
TCPA, TCG, TPM, the Fritz chip, etc.  Despite the questions about that
technology, the paper has some interesting ideas which could be applied
more widely.
One of the concepts in trusted computing is that the computer would
have a chip in it with an embedded key.  This chip is called the TPM
officially but is widely known as the Fritz chip after the senator who
was pushing some legislation that might mandate technology controls.
Fritz Hollings is gone and so is his CBDTPA but now the FCC seems to be
taking up the gauntlet.  But that's another story.
Anyway, the TPM generates a key internally and it gets certified by some
kind of CA established by the TCG (the TCG is the new name for the TCPA).
When someone wants to, say, download some DRM-protected data, they could
prove they have a real TPM by providing this certificate from the TCG CA
on their TPM key.  This would let the data supplier know he was talking
to a system with a genuine TPM that would protect the data and keep the
user from defeating the DRM.
That would be the simple way to work, but the TCG didn't do it that way,
because having the user show his TPM certificate everywhere would violate
his privacy.  It may seem strange that a proposal which is built on the
idea that the user is the enemy will care about his privacy, especially
since most TCG uses will require the user to pay for things, meaning
showing a credit card number, so he has no privacy anyway.  But that's
the political decision the TCG made.
Instead, they came up with a "Privacy CA", where the user would in effect
show his TPM certificate to the PCA, and the PCA would then certify a
temporary "pseudonym key" that the user would then use in place of his
TPM key and certificate.  The problem here is that this doesn't protect
privacy all that well, plus the PCA needs to have both high availability
and high security, two requirements that don't work well together.
So TCG has approved this new proposal, cryptographically based, called
Direct Anonymous Attestation or DAA.  There is no more Privacy CA.
Instead, the user directly proves that he has a valid certificate on his
TPM key, but he does it in zero knowledge.  He doesn't reveal the TPM key
or the certificate, nevertheless the verifier (which would typically be a
seller of DRM'd content) gets convinced that he is talking to a real TPM.
The way it works is a modification of a group signature.  Camenisch has
done a lot of work on these over the years, with various co-authors.
But the general idea is the same, that group members each generate a key,
which gets certified by a "group ownership manager" and that means they're
officially part of the group.   Then they can create signatures of which
it can only be determined that they came from someone in the group, but
you can't tell which one.  This is done by the method described above,
a zero knowledge proof that you know a key and you have a certificate
(signature) on it by the group manager key.  That establishes that you
are a group member.
One of the new ideas in the DAA paper relates to revocation.  The TPM
private keys are supposed to remain locked in the chip.  But suppose
someone uses some fancy lab equipment or perhaps a side channel attack
and extracts one.  They could spread it around to their friends, who
could use it to pretend to have TPMs, download DRM-protected data and
easily remove the protections.  The TCG wanted to deal with this.
The assumption is that a secret this good can't be kept quiet for long,
so soon there will be lists of TPM-cracked keys floating out there.
TCG-based vendors are assumed to have access to such a list, so when
someone shows up with their ZK proof about having a good TPM, they want
to know if the TPM key is on the list.  The problem is that the TPM
key is not revealed in the ZK proof.  So the authors propose that, if
the key is k, another value of the form u^k mod p gets revealed, where
u is perhaps chosen by the vendor, or is perhaps random.  This doesn't
reveal k but there is a proof that the k used in u^k is the same k that
got certified as a TPM key.
Now the vendor can compare the reported u^k value with computed u^k based
on all known "bad" keys.  If it matches for any of them, he knows that
he is being offered a bogus TPM key proof.
That's the basic idea of the DAA, but there are two additional points
of interest.  The first is that DAA is really complicated, more so than
most group signatures of this type I have seen.  The main reason seems to
be a desire to not make the TPM work too hard.  The authors have cleverly
and diligently split up the protocol so that as much work as possible
is done by the host computer and not the TPM, even though the host is
not trusted.  The concept is similar to the old "wallet with observer"
protocols of Chaum and Brands.  But the effect is to add many extra
phases and passes, which could probably be eliminated if we didn't care
about that.
The second point relates to the system as a credential system.  This idea
of proving in zero knowledge that you have a cert on your key is the
basis of an earlier credential system from Camenisch and Lysyanskaya.
The concept is that credentials are represented by particular signatures
from particular signers.  Say, AAA could give me a credential as a member
for the year 2004 by a certain signature.  Then I could show possession
when I made a hotel reservation and get a discount, by proving that I
had that signature by AAA on a key I owned.  Doing it in ZK protects
my privacy.
I actually looked at implementing the C&L credential system a few
years ago, but there was a big stumbling block right at the beginning.
It would only work with an RSA key of a special form, one composed
of the product of two strong primes (primes p and q where (p-1)/2 and
(q-1)/2 were themselves prime).  And worse, it was necessary to prove
that the modulus was of that form, without of course revealing p and q.
Well, Camenisch had a protocol for this, but it was very complicated.
I implemented it and it was intolerably slow, it took many minutes or
even hours.  It just didn't appear feasible as the foundation for a
practical credential system.
One of the improvements in the new DAA system is that it escapes from
the need to prove that the RSA key is built of strong primes.  This means
that it could conceivably be the foundation for a credential system that
would actually be efficient enough to use.  That's very exciting!
Unfortunately, as I said the DAA system in its present form is not quite
right; it is too complicated due to the need to split up the work between
TPM and untrusted host.  That complication is not necessary for a plain
credentialling system.  So some work would have to be done to clean it
up and get it into a form that would work for credentials.
Crypto is next week and I hope to see Jan there and ask him about this.
If he thinks it would work then this is another project I might try
in the near future.  I would really like to see some kind of anonymous
credential system available for people to experiment with.  I had looked
into doing one with ring signatures but it would not be very efficient.
Camenisch's technology is far superior.
Hal Finney

@_date: 2004-08-04 18:04:15
@_author: "Hal Finney" 
@_subject: Re: On what the NSA does with its tech 
Not necessarily, if nanotechnology works.  128 bits is big but not
that big.
Eric Drexler, in Nanosystems, section 12.9, predicts that a nanotech
based CPU fitting in a 400 nm cube could run at 1000 MIPS and consume
60 nanowatts, performing 10^16 instructions per second per watt.
Let's design a system to break a 128 bit cipher.  Let's suppose it has
to do 2^10 instructions per test, so this is 2^138 instructions total,
or about 10^41.  Let's let it run for four months, which is 10^7 seconds,
so our necessary processing rate is 10^34 instructions per second.
This means we need 10^34 IPS / 1000 MIPS or 10^25 of Drexler's gigahertz
cubes, call it 10^25 cubic microns or 10^7 cubic meters, a cube about
220 meters on a side.
The system will consume 10^25 * 60 nanowatts or about 6 * 10^17 watts.
Now, that's a lot.  It's four times what the earth receives from the sun.
So we have to build a disk four times the area (not volume) of the earth,
collect that power and funnel it to our computers.  Probably we would
scatter the computers throughout the disk, which would be mostly composed
of solar collectors.  (Keeping the disk gravitationally stable is left
as an exercise for the student, as is the tradeoff involved in making
it smaller but moving it closer to the sun.)
Fortunately, exhaustive key search is perfectly parallelizable so there
is no need for complex communications or synchronizations between the
As you can see, breaking 128 bit keys is certainly not a task which is
so impossible that it would fail even if every atom were a computer.
If we really needed to do it, it's not outside the realm of possibility
that it could be accomplished within 50 years, using nanotech and robotics
to move and reassemble asteroids into the necessary disk.
Now, 256 bit keys really are impossible, unless the whole contraption
above can be made to operate as an enormous, unified quantum computer,
in which case it could theoretically break even 256 bit keys.
512 bit keys... now those really are impossible.

@_date: 2004-08-20 21:09:24
@_author: "Hal Finney" 
@_subject: Re: RPOW - Reusable Proofs of Work 
The first MTA would exchange the received RPOW for a new one of equal
value, and pass it along with the message to the next MTA in line.

@_date: 2004-08-19 05:45:57
@_author: "Hal Finney" 
@_subject: Re: RPOW - Reusable Proofs of Work 
Well, there are no digital cash implementations that I am aware of.
I think of RPOWs as a sort of "play money" that might be usable in some
applications that would otherwise use digital cash.  I have some code
to play online games with cryptographic protection, cards and dice,
and I am planning to modify it to let people make bets with RPOWs as
the betting chips.
Another way to think of RPOWs is as an implementation of Nick Szabo's
concept of "bit gold".  These are made of bits but have the rarity and
verifiable costliness of a commodity like gold.  Of course they lack
gold's appeal and attractiveness.  Perhaps they could be better thought
of as "bit copper".
It's possible that these things could happen, but that's not necessarily
bad.  After all, if people ever got to where they would buy and sell
RPOWs for money, they could serve in place of ecash.  The main question
is whether there will be any use for them so compelling that people
would buy them.
Hal Finney

@_date: 2004-08-17 16:21:56
@_author: "Hal Finney" 
@_subject: Re: RPOW - Reusable Proofs of Work 
A couple of quick responses to the questions on RPOW, as I am at
Crypto this week.
Taral asked about the attestation.  It is based on a root key
published in Appendix C of IBM's "IBM 4758 PCI Cryptographic
Coprocessor Custom Software Interface Reference", available from
It is also published on IBM's web page at
This tells you that the attestation refers to a valid IBM 4758.
Further, the attestation contains within it both a hash of the RPOW
program, and a set of keys generated by that program.  Using the methods
described on the rpow.net web site, it is possible to take the RPOW source
code and generate a hash which matches that reported in the attestation.
This tells you that you have access to the actual source code running
on the RPOW server.  By studying the source you can confirm that the
program never exposes its private keys or allows them to leave the
board.  This tells you that if you send a message encrypted to the RPOW
communications key and get a meaningful response (messages are protected
with HMAC), you are talking to the program described in the attestation.
Lynn Wheeler mentions the IBM 4758 break by Mike Bond and Richard Clayton
described at   This was not
actually a break of the 4758 but an exploit of a cryptographic weakness
in the application running on the board, which was IBM's CCA support
software.  RPOW does not use CCA and is not vulnerable to that attack,
and IBM has since fixed the CCA.
Of course it is possible that RPOW may have vulnerabilities and errors
of its own, being my own work and far from perfect.  I welcome review
and comment on the RPOW source code which is open source and available
from rpow.net.
Hal Finney

@_date: 2004-08-15 17:43:09
@_author: "Hal Finney" 
@_subject: RPOW - Reusable Proofs of Work 
I'd like to invite members of this list to try out my new
hashcash-based server, rpow.net.
This system receives hashcash as a Proof of Work (POW) token, and in
exchange creates RSA-signed tokens which I call Reusable Proof of Work
(RPOW) tokens.  RPOWs can then be transferred from person to person and
exchanged for new RPOWs at each step.  Each RPOW or POW token can only
be used once but since it gives birth to a new one, it is as though the
same token can be handed from person to person.
Because RPOWs are only created from equal-value POWs or RPOWs, they are
as rare and "valuable" as the hashcash that was used to create them.
But they are reusable, unlike hashcash.
The new concept in the server is the security model.  The RPOW server
is running on a high-security processor card, the IBM 4758 Secure
Cryptographic Coprocessor, validated to FIPS-140 level 4.  This card
has the capability to deliver a signed attestation of the software
configuration on the board, which any (sufficiently motivated) user
can verify against the published source code of the system.  This lets
everyone see that the system has no back doors and will only create RPOW
tokens when supplied with POW/RPOW tokens of equal value.
This is what creates trust in RPOWs as actually embodying their claimed
values, the knowledge that they were in fact created based on an equal
value POW (hashcash) token.
I have a lot more information about the system at rpow.net, along with
downloadable source code.  There is also a crude web interface which
lets you exchange POWs for RPOWs without downloading the client.
This system is in early beta right now so I'd appreciate any feedback
if anyone has a chance to try it out.  Please keep in mind that if there
are problems I may need to reload the server code, which will invalidate
any RPOW tokens which people have previously created.  So don't go too
crazy hoarding up RPOWs quite yet.
Thanks very much -
Hal Finney

@_date: 2004-08-19 20:51:10
@_author: "Hal Finney" 
@_subject: Re: HMAC? 
More on the question of HMAC.  As mentioned before, the potential attack
would be to find a collision on the inner hash, even without knowing the
key.  Since the key is exactly one hash block in length, the effect is
identical to finding a hash collision without knowing the IV.
Discussing this issue with Niels Ferguson, he pointed out that it
might turn out that the new attacks do provide some slight advantage for
guessing a hash collision even without knowing the IV values.  There might
be some differential, and conceivably even some choice of inputs, which
would have an enhanced collision probability.  If that were greater than
the one in 2^64 chance of a collision one would ordinarily expect with,
say, MD5, then technically that would be called a break of HMAC-MD5,
even if it were not possible to exploit it in practice.
Another point that was mentioned in the presentation on the new MD4
collisions was that they were so easy to find that the work factor was in
the range from 4 to 64.  It's not entirely clear what that means, but the
claim was that the work was so simple that it could be completed by hand.
I thought it was conceivable that this meant that some substantial
fraction of random inputs to MD4 would collide when using the differential
described in the eprint posting, so I tested that.  I wrote some code
to choose a random 512 bit block and then hash both it and a block
with the published differentials using MD4, and check for a collision.
I let it run for 1.7 billion tries without finding any.  The code is
below, but note that it will only run on a little-endian machine since
their differentials are for 32-bit blocks in that form.
So at least it's not just a matter of finding the right differential.
You've got to be somewhat smart in choosing the data values, which would
make it harder to attack HMAC since you presumably would not be able to
choose the data without knowing the IV.  It may still be that you could
do something with HMAC built on one of the broken ciphers, but we will
have to wait for a fuller description of the technique.
Hal Finney
 * work just getting lucky.
 */
   "openssl/rand.h"
 "openssl/md4.h"
typedef unsigned char uchar;
unsigned wang[16] = {
unsigned buf1[16];
unsigned buf2[16];
uchar md1[16];
uchar md2[16];
memdump (unsigned char *buf, int buflen)

@_date: 2004-08-17 06:04:10
@_author: "Hal Finney" 
@_subject: Re: HMAC? 
My guess is that HMAC is not vulnerable.  The basic structure of HMAC is
The attacker does not know the key(s) and is allowed to request MACs
on chosen messages; then he must produce a valid MAC on a new message.
The initial paper from Wang eg al announcing the results is unusual in
that it merely exhibits the collisions, while providing no information
whatsoever about how they were obtained.  They are simply presented as
a fait accompli, astonishing in their very existence.  It reminds me
of the story of how Cole demonstrated that the 67th Mersenne number was
nonprime, by silently walking to the backboard and patiently working out
the value of 2^67 - 1, and then the product of its two factors, by hand.
The nature of the exhibited hash collisions is that they are values which
differ in only a very few bits: 6 bits out of 1024 for the MD5 collisions;
4 bits out of 512 for the MD4.  Obviously it's not the case that for
most strings, you can toggle these 4 or 6 bits and produce a collision!
Instead, the authors must have some technique to create very special
strings which allow the changes made by these few bits to cancel each
other out.
If the attacker could find two messages such that there was an inner hash
collision, Hash(key2 || Msg1)  ==  Hash(key2 || Msg2), he could break
HMAC.  He'd get a MAC on Msg1 and then he could use that same MAC on Msg2.
But it seems impossible to find a collision like this without knowing
key2.  These hash functions are highly nonlinear and the choice of Msg1
and Msg2 would be completely dependent on key2.  Change 1 bit of key2
and half the bits of Msg1 and Msg2 would very probably have to change.
If the attacker knew key2, it sounds like the new attacks would likely
work to find an inner collision.  But without knowing that, there would
be no way to choose Msg1 and Msg2.
Given the special form of the colliding values, it appears that the
new technique does not solve hash inversion, or finding collisions
with arbitrary bit differentials.  The one possibility that I could
imagine for a threat to HMAC is their comment that the attack on MD4
(for which collisions were already known) is so easy that it can be done
by hand calculation.  Maybe that would suggest that given the proper
differentials, a non-negligible fraction of randomly chosen values would
collide.  Then conceivably you could get lucky and find a collision
without even knowing key2.  But that seems like a very remote possibility.
Hal Finney

@_date: 2004-10-01 17:11:38
@_author: "Hal Finney" 
@_subject: Re: Federal program to monitor everyone on the road 
There was a brief mention of this technology at the Crypto conference.
I provided some pointers in a comment to an Ed Felten blog entry at
 (scroll
down to the 3rd comment).
Dan Boneh et al presented a proposal for a group signature scheme so that
the data collected would not be personally identifiable.  The problem is
that the data needs to be authenticated, otherwise rogue transmitters
could send false data and perhaps cause traffic flow problems or even
serious accidents.  So they want to use some cryptographic method.
Putting a common key in the whole system would make it too easy for
rogues to get access to, would be unrevocable, and we are back to the
rogue transmitter problem.  Using individual certified keys is the
default solution but has privacy problems: everyone would be constantly
transmitting a cryptographically verifiable record of their driving
patterns, speed, lane changing and who knows what else.
With the group signature, everybody has a unique key but their
transmissions are not bound to that key.  And if a key gets scraped
out and goes rogue, it can be revoked.  This is supposed to provide
flexibility, authentication, and privacy.
In practice I am skeptical that society will choose to protect privacy at
the expense of security.  One optional feature of group signatures is a
trusted party who can penetrate the anonymity and learn the identity of
the author of a particular message.  I suspect that any vehicle based
embedded communications system will retain that capability, a sort of
"license plate" in the virtual realm.  The ability to track the paths of
bank robbers and terrorists would be too inviting for society to give up,
especially if the data is only available to government agents.

@_date: 2004-10-21 19:21:49
@_author: "Hal Finney" 
@_subject: Re: Financial identity is *dangerous*? (was re: Fake companies, real money) 
I would suggest pursuing work along the lines of a Virtual Machine Monitor
(VMM) like VMWare.  This way you can run a legacy OS, even Windows,
alongside a high security simplified OS which handles your transactions.
You run your regular buggy OS as usual, then hit a function key to
switch into secure mode, which enables access to your financial data.
The VMM does introduces some performance overhead but for typical web
browsing and email tasks it will not be significant.
This seems more promising than waiting for Windows to become secure,
or for everyone to switch to Linux.  I believe there are a number of
academic projects along these lines, for example the Terra project,
 , which uses
a hardware security chip to try to protect one VM's data from another.
I don't know if the extra complexity buys you much in this application
Hal Finney

@_date: 2004-11-08 18:51:24
@_author: "Hal Finney" 
@_subject: Re: Your source code, for sale 
Of course there has to be a third party in the form of the currency
issuer.  If it is someone like e-gold, they could do as I suggested and
add a feature where the buyer could transfer funds irrevocably into
an escrow account which would be jointly controlled by the buyer and
the seller.  This way the payment is already "gone" from the POV of the
buyer and if the seller completes the transaction, the buyer has less
incentive to cheat him.
In the case of an ecash mint, a simple method would be for the seller to
give the buyer a proto-coin, that is, the value to be signed at the mint,
but in blinded form.  The buyer could take this to the mint and pay to
get it signed.  The resulting value is no good to the buyer because he
doesn't know the blinding factors, so from his POV the money (he paid
to get it signed) is already "gone".  He can prove to the seller that
he did it by using the Guillou-Quisquater protocol to prove in ZK that
he knows the mint's signature on the value the seller gave him.
The seller thereby knows that the buyer's costs are sunk, and so the
seller is motivated to complete the transaction.  The buyer has nothing
to lose and might as well pay the seller by giving him the signed value
from the mint, which the seller can unblind and (provably, verifiably)
be able to deposit.

@_date: 2004-11-05 18:18:22
@_author: "Hal Finney" 
@_subject: RE: Your source code, for sale 
Yes, I'm looking at ideas like this for ecash gambling, but you have
a who-goes-first problem.  One side or the other has to "rip" their
own cash first, and then the other side can just go away and leave the
first side screwed.  The act of ripping cash is relatively atomic and
involves a transaction with the ecash mint, so they can't both do it at
the same time.
I guess the best fix is for each side to rip a little bit of cash at a
time, so that the guy who goes first only loses a trivial amount if the
other side aborts.  Then after a few rounds both sides are sunk pretty
deep and both have a strong incentive to complete the transaction.

@_date: 2004-11-05 18:18:22
@_author: "Hal Finney" 
@_subject: RE: Your source code, for sale 
Yes, I'm looking at ideas like this for ecash gambling, but you have
a who-goes-first problem.  One side or the other has to "rip" their
own cash first, and then the other side can just go away and leave the
first side screwed.  The act of ripping cash is relatively atomic and
involves a transaction with the ecash mint, so they can't both do it at
the same time.
I guess the best fix is for each side to rip a little bit of cash at a
time, so that the guy who goes first only loses a trivial amount if the
other side aborts.  Then after a few rounds both sides are sunk pretty
deep and both have a strong incentive to complete the transaction.

@_date: 2004-11-05 18:12:48
@_author: "Hal Finney" 
@_subject: Re: Your source code, for sale 
Interesting.  In the e-gold case, both parties have the same bank,
e-gold ltd.  The corresponding protocol would be for the buyer to instruct
e-gold to set aside some money which would go to the seller once the
seller supplied a certain receipt.  That receipt would be an email return
receipt showing that the seller had sent the buyer the content with hash
so-and-so, using a cryptographic email return-receipt protocol.
Actually you can arrange it so that neither the partially-released code
nor the partially-transferred ecash is of any value until the whole
transfer finishes.  For example, send the whole thing first in encrypted
form, then release the encryption keys bit-by-bit.  If someone aborts
the protocol early, the best each side can do is a brute force search
over the untransferred bits to try to find the key to unlock the data
they received.
That's a good point.  Maybe you could use some kind of DRM or trusted
computing concept to try to force the buyer to lock up his received data.
For source code that would be pretty difficult though, it needs to be
handled in flexible ways.

@_date: 2004-11-05 18:12:48
@_author: "Hal Finney" 
@_subject: Re: Your source code, for sale 
Interesting.  In the e-gold case, both parties have the same bank,
e-gold ltd.  The corresponding protocol would be for the buyer to instruct
e-gold to set aside some money which would go to the seller once the
seller supplied a certain receipt.  That receipt would be an email return
receipt showing that the seller had sent the buyer the content with hash
so-and-so, using a cryptographic email return-receipt protocol.
Actually you can arrange it so that neither the partially-released code
nor the partially-transferred ecash is of any value until the whole
transfer finishes.  For example, send the whole thing first in encrypted
form, then release the encryption keys bit-by-bit.  If someone aborts
the protocol early, the best each side can do is a brute force search
over the untransferred bits to try to find the key to unlock the data
they received.
That's a good point.  Maybe you could use some kind of DRM or trusted
computing concept to try to force the buyer to lock up his received data.
For source code that would be pretty difficult though, it needs to be
handled in flexible ways.

@_date: 2004-11-04 23:01:15
@_author: "Hal Finney" 
@_subject: RE: Your source code, for sale 
I've been thinking about how to do this kind of thing with ecash.
One project I'm hoping to work on next year is a P2P gambling game (like
poker or something) using my rpow.net which is a sort of play-money ecash.
You'd like to be able to do bets and have some kind of reasonable
assurance that the other guy would pay up if he loses.
In the case of your problem there is the issue of whether the source
code you are buying is legitimate.  Only once you have inspected it and
satisfied yourself that it will suit your needs would you be willing
to pay.  But attaining that assurance will require examing the code in
such detail that maybe you will decide that you don't need to pay.
You could imagine a trusted third party who would inspect the code and
certify it, saying "the source code with hash XXX appears to be legitimate
Cisco source code".  Then they could send you the code bit by bit and
incrementally show that it matches the specified hash, using a crypto
protocol for gradual release of secrets.  You could simultaneously do
a gradual release of some payment information in the other direction.
If you don't have a TTP, one idea for using ecash is Markus Jakobsson's
"Ripping Coins for a Fair Exchange".  Basically you withdraw ecash from
your account and in effect "rip it in half" and give half to the seller.
Now he gives you the product and you give him the other half of the coin.
The idea is that once you have given him the "ripped" ecash ("torn"
would be a better word because ripping means something else today),
you are out the value of the cash.  You have no more incentive to cheat,
as giving him the other half won't cost you anything additional.
(Even without ecash, a service like egold could mimic this functionality.
You'd create an escrow account with two passwords, one known to each
party.  Only with both passwords could data be withdrawn from the account.
Then the buyer would transfer funds into this account.  After receiving
the goods, the buyer would send his password to the seller.)
The problem is that if the source code you are purchasing is bogus,
or if the other side doesn't come through, you're screwed because you've
lost the value of the torn cash.  The other side doesn't gain anything
by this fraud, but they harm you, and if they are malicious that might
be enough.  And likewise you might be malicious and harm them by refusing
to give them your half of the coin even after you have received the goods.
Again, this doesn't benefit you, you're still out the money, but maybe
you like causing trouble.
Another idea along these lines is gradual payment for gradual release
of the goods.  You pay 10% of the amount and they give you 10% of the
source code.  You pay another 10% and you get the next 10% of the source,
and so on.  (Or it could be nonlinear; maybe they give out half the code
for free, but the final 10% requires a large payment.)  The idea is that
you can sample and make sure they do appear to have the real thing with
a fairly small investment.
If there is some mechanism for the seller to have a reputation (like
Advogato's perhaps, with some spoofing immunity) then the problem is
easier; the seller won't want to screw buyers because it hurts his rep.
In that case it may be reasonable to ask the buyer to pay in advance,
perhaps using the partial payment system just discussed.
These various ideas all have tradeoffs, and in general this kind of
problem is hard to solve because of the complexity of what constitutes a
successful transaction.  A reputation system helps a great deal to resolve
the issues, but opens up problems of its own.  The betting problem I
want to work on is relatively easy because there is no ambiguity about
who wins, but even then it is hard to make sure that neither party can
maliciously harm the other.
Hal F.

@_date: 2004-11-04 23:01:15
@_author: "Hal Finney" 
@_subject: RE: Your source code, for sale 
I've been thinking about how to do this kind of thing with ecash.
One project I'm hoping to work on next year is a P2P gambling game (like
poker or something) using my rpow.net which is a sort of play-money ecash.
You'd like to be able to do bets and have some kind of reasonable
assurance that the other guy would pay up if he loses.
In the case of your problem there is the issue of whether the source
code you are buying is legitimate.  Only once you have inspected it and
satisfied yourself that it will suit your needs would you be willing
to pay.  But attaining that assurance will require examing the code in
such detail that maybe you will decide that you don't need to pay.
You could imagine a trusted third party who would inspect the code and
certify it, saying "the source code with hash XXX appears to be legitimate
Cisco source code".  Then they could send you the code bit by bit and
incrementally show that it matches the specified hash, using a crypto
protocol for gradual release of secrets.  You could simultaneously do
a gradual release of some payment information in the other direction.
If you don't have a TTP, one idea for using ecash is Markus Jakobsson's
"Ripping Coins for a Fair Exchange".  Basically you withdraw ecash from
your account and in effect "rip it in half" and give half to the seller.
Now he gives you the product and you give him the other half of the coin.
The idea is that once you have given him the "ripped" ecash ("torn"
would be a better word because ripping means something else today),
you are out the value of the cash.  You have no more incentive to cheat,
as giving him the other half won't cost you anything additional.
(Even without ecash, a service like egold could mimic this functionality.
You'd create an escrow account with two passwords, one known to each
party.  Only with both passwords could data be withdrawn from the account.
Then the buyer would transfer funds into this account.  After receiving
the goods, the buyer would send his password to the seller.)
The problem is that if the source code you are purchasing is bogus,
or if the other side doesn't come through, you're screwed because you've
lost the value of the torn cash.  The other side doesn't gain anything
by this fraud, but they harm you, and if they are malicious that might
be enough.  And likewise you might be malicious and harm them by refusing
to give them your half of the coin even after you have received the goods.
Again, this doesn't benefit you, you're still out the money, but maybe
you like causing trouble.
Another idea along these lines is gradual payment for gradual release
of the goods.  You pay 10% of the amount and they give you 10% of the
source code.  You pay another 10% and you get the next 10% of the source,
and so on.  (Or it could be nonlinear; maybe they give out half the code
for free, but the final 10% requires a large payment.)  The idea is that
you can sample and make sure they do appear to have the real thing with
a fairly small investment.
If there is some mechanism for the seller to have a reputation (like
Advogato's perhaps, with some spoofing immunity) then the problem is
easier; the seller won't want to screw buyers because it hurts his rep.
In that case it may be reasonable to ask the buyer to pay in advance,
perhaps using the partial payment system just discussed.
These various ideas all have tradeoffs, and in general this kind of
problem is hard to solve because of the complexity of what constitutes a
successful transaction.  A reputation system helps a great deal to resolve
the issues, but opens up problems of its own.  The betting problem I
want to work on is relatively easy because there is no ambiguity about
who wins, but even then it is hard to make sure that neither party can
maliciously harm the other.
Hal F.

@_date: 2004-12-16 18:16:27
@_author: "Hal Finney" 
@_subject: Re: Off-the-Record Messaging (IM plugin) 
It looks like Ian Goldberg's site might be a more authoritative source,
 .
One interesting feature is authentication + deniability.  You know who
you are talking to, but afterwards anyone who captured a transcript can't
prove who said it.  Usually we do authentication with digital signatures,
but the problem is that binds you to what you say and it can be used
against you afterwards.
OTR does it by signing the key exchange which creates a MAC key for each
direction.  (A MAC is a keyed hash which is then applied to each message.)
Each message gets MAC'd and this way you know that the messages are
authentic and untampered.
This already protects you against your conversant; both of you know the
MAC keys in each direction (one knows them in order to MAC new messages;
the other knows them in order to verify the MAC), so each guy can
forge messages created by the other guy and create a bogus transcript.
That means that neither person can publish a transcript and credibly
claim that it authentically represents what was said.
Then, there's another trick: when you are through with them you publish
your MAC keys, in the clear.  This does not compromise secrecy; all of
the data is encrypted with a different key.  But it means that now, anyone
could in retrospect forge a transcript showing you saying anything at all.
And that of course means that no such transcript has any credibility in
terms of providing cryptographic evidence of what you said.

@_date: 2005-02-23 20:14:04
@_author: "Hal Finney" 
@_subject: Re: I'll show you mine if you show me, er, mine 
Markus Jakobsson is a really smart guy who's done some cool stuff, so I
think this is probably better than it sounds in the article.  His web
site is  but I don't see any
papers there that sound like what the article describes.  I tried to
reverse engineer the protocol from the article, and the results are below.
But first let me put this into context.
The security property seems to be that you send something to the server,
and it sends you back something that proves that it knows your password.
But neither a passive eavesdropper nor a MITM can learn anything about
your password from observing or influencing the exchange.  The best an
attacker can do is to try to brute force your password by guessing it
repeatedly and trying each guess out at the server.  And this can be
easily prevented by having the server refuse to answer more than a few
bad password attempts.
Note that this is different from simple PK based authentication,
because the secret is human memorizable.  And it's different from,
say, having the server respond with a keyed hash of your passphrase,
because an eavesdropper could then do an offline brute force search.
The key feature is that the only attack is online brute forcing.
There are already a lot of protocols in the literature which do this,
often performing key agreement at the same time.  The original one
and most famous was SPEKE.  There is a long list of such protocols at
  I don't
know what properties this new protocol has that the old ones don't.
Maybe it does have some and I am missing the point.  Or there might be
some patent issues that it is trying to work around.
Anyway, here's my attempt at mimicking the protocol, based on the
description of envelopes and carbon paper.
You have a password, and so does the site you will login to.  (Or,
maybe the site has a salted hash of your password; you could use that
instead.)  You set up a homomorphic encryption system.  This is one where
you can send an encrypted value to someone else, and he can do certain
operations on the encrypted value, like multiplying it by a constant.
In this case I think we only need to encrypt the value 1, and let the
other guy multiply by his constant, which makes it simpler.
I think ElGamal could work: you encrypt 1 as (g^k, y^k), where you'd
make up a key y = g^x on the spot.  You send this to the other guy who
picks a random power j and raises both elements to that power, then
multiplies the 2nd one by c: (g^(k*j), y^(k*j) * c), and sends it back
to you.  This is now a valid ElGamal encryption of c.  But an observer
can't tell what c is.
For a first cut at this protocol, you take each bit of the password (or
salted hash) and create two encryptions of m = 1.  It would look like
E(1)   E(1)   E(1)   E(1)   E(1)  ...
E(1)   E(1)   E(1)   E(1)   E(1)  ...
You send all these to the server.  The server knows your password (or
salted hash) and, for each pair of encrypted values, multiplies the
one corresponding to password bit b_i by some constant c_i.  The other
one of the pair, corresponding to !b_i, it multiplies by a random r_i.
The server sets it up so that the sum of all the c_i is zero.  Then it
sends all of them back to you.  If your passphrase started 01101...
it would be:
E(c_1)   E(r_2)   E(r_3)   E(c_4)   E(r_5)  ...
E(r_1)   E(c_2)   E(c_3)   E(r_4)   E(c_5)  ...
Now, you decrypt just the ones corresponding to the bits b_i and add up
the decrypted plaintexts, giving you sum of c_i.  If the result is zero,
you know the server knew your password (or salted hash).
Actually this is not quite right, because the article says that you are
not supposed to be able to decrypt both ciphertext values in the pair
that corresponds to a password bit.  Otherwise an imposter might be able
to figure out your passphrase by doing one interaction with the server,
then finding an element from each pair such that they all sum to zero.
This is kind of knapsacky and it might not be that hard, I'm not sure.
So I think what you could do is to send a valid ElGamal encryption of
1, and a bogus value which is not an ElGamal encryption of anything.
But the remote party wants to be sure that you can't decrypt them both.
One way to achieve this is to arrange that the first members of each pair,
g^k in the good encryption, multiply to some fixed value F for which the
discrete log is not known.  Maybe it's the hash of "I don't know if this
will work."  You can't know the DL of that hash, so you can't find two
g^k values which multiply to that hash.  That means that if you have a
pair of ElGamal ciphertexts which have this property, only one is a real,
valid ElGamal ciphertext and so only one is decryptable (I think!).  So
you would send, in the example above:
(g^k0, y^k0)    (F/g^k1, junk)  (F/g^k2, junk)   (g^k3, y^k3)   ...
(F/g^k0, junk)  (g^k1, y^k1)    (g^k2, y^k2)     (F/g^k3, junk) ...
When the server did its multiplications as above you'd still get the
correct encryptions of c_i, but the other pair would be junk and you
wouldn't learn the r_i values:
E(c_1)   junk     junk     E(c_4)   junk    ...
junk     E(c_2)   E(c_3)   junk     E(c_5)  ...
Now you can still decrypt it and verify your password.  But for someone
who is impersonating you and doesn't know your password, they're going
to get a mix of c_i and r_i values that won't add up to zero, and that
won't give them any clue about what the real password is, other than
that they guessed wrong.
I'm not 100% sure this will work, that the attacker can't create a bogus
pair (F/g^k, junk) which will allow him to determine what value the server
multiplied by.  At a minimum I see that if junk = F/g^k then it will be
obvious what the constant was, so the server would have to check for that.
This is why it's good to have provable security!
This way of doing things would also be quite inefficient; there are
two ElGamal encryptions going back and forth (typically 2048 bits each)
for every bit of your password.  I'll bet the actual paper has a much
more clever scheme which improves the efficiency and has a nice proof
of security.  I'm looking forward to seeing it.
Hal Finney

@_date: 2005-02-12 00:14:14
@_author: "Hal Finney" 
@_subject: Cypherpunk help with Hal Finney demo 
Here's a semi-urgent request.  I introduced the RPOW project last year
on this list, rpow.net.  It provides a sort of play-money form of digital
cash, an implementation of Nick Szabo's concept of "bit gold".
I am giving a talk at CodeCon,  on this system, in about
an hour(!) and I could use some help from you.
One of the things I have done to demo a possible use is to make a
patched version of BitTorrent, the widely used file sharing program, that
exchanges RPOW data objects in order to reward people for uploading and
seeding files.  In exchange, people with RPOWs can get priority on future
downloads, so by seeding today you can get a better download tomorrow.
That's the concept, although at this point it is just an experiment.
What I need is to have a dozen or so people doing regular BitTorrent
downloads of a file I will offer during the demo, which will be at
about 5:15 PM Pacific Standard Time, 8:15 PM EST, 1:15 AM GMT.  That's 1
hour from now.  You don't need to use any special RPOW software, just
the regular BitTorrent client.
If you have a BitTorrent client and know how to use it, could you start
up and leave running a download of the following .torrent file:
This is fully legal, it's just a home movie of my dog Arky playing on
the beach with his brother.
Nothing will happen with the download until I start the demo after 5.
But if you could start up your BitTorrent client before then and just
leave it running, it would be a big help for me.
If you are able to do this, please send me an email when you start up your
BT client, at hal  If you've never used BT, don't bother to
try downloading and figuring it out.  I only really need a minimum of
4 or 5 people doing it, but as I said a dozen or more would be great.
Sorry about the last minute notice; I know that most people won't see
this until too late, but if anyone sees it now and you know how to use
BT I'd appreciate your help.
Hal Finney

@_date: 2008-11-13 16:24:18
@_author: "Hal Finney" 
@_subject: Re: Bitcoin P2P e-cash paper 
I agree that the description is not completely clear on how these matters
are handled. Satoshi has suggested that releasing source code may be the
best way to clarify the design. As I have tried to work through details on
my own, it does appear that the rules become rather complicated and indeed
one needs at least a pseudo-code algorithm to specify the behavior. So
perhaps writing real code is not a bad way to go. I found that there is
a sourceforge project set up for bitgold, although it does not have any
code yet.
In answer to James' specific question, about what happens when different
nodes see different sets of transactions, due to imperfect broadcast, here
is how I understand it. Each node must be prepared to maintain potentially
several "candidate" block chains, each of which may eventually turn out
to become the longest one, the one which wins. Once a given block chain
becomes sufficiently longer than a competitor, the shorter one can be
deleted. This length differential is a parameter which depends on the
node's threat model for how much compute power an attacker can marshall,
in terms of the fraction of the "honst" P2P network's work capacity,
and is estimated in the paper. The idea is that once a chain gets far
enough behind the longest one, there is essentially no chance that it
can ever catch up.
In order to resolve the issue James raised, I think it is necessary
that nodes keep a separate pending-transaction list associated with
each candidate chain. This list would include all transactions the node
has received (via broadcast by the transactees) but which have not yet
been incorporated into that block chain. At any given time, the node is
working to extend the longest block chain, and the block it is working
to find a hash collision for will include all of the pending transactions
associated with that chain.
I think that this way, when a candidate chain is deleted because it
got too much shorter than the longest one, transactions in it are
not lost, but have continued to be present in the pending-transaction
list associated with the longest chain, in those nodes which heard the
original transaction broadcast. (I have also considered whether nodes
should add transactions to their pending-transaction list that they
learn about through blocks from other nodes, even if those blocks do
not end up making their way into the longest block chain; but I'm not
sure if that is necessary or helpful.)
Once these rules are clarified, more formal modeling will be helpful in
understanding the behavior of the network given imperfect reliability. For
example, if on average a fraction f of P2P nodes receive a given
transaction broadcast, then I think one would expect 1/f block-creation
times to elapse before the transaction appears in what is destined to
become the longest chain. One might also ask, given that the P2P network
broadcast is itself imperfectly reliable, how many candidate chains
must a given node keep track of at one time, on average? Or as James
raised earlier, if the network broadcast is reliable but depends on a
potentially slow flooding algorithm, how does that impact performance?
I am somewhat less worried about motivation. I'd be satisfied if the
system can meet the following criteria:
1. No single node operator, or small collection of node operators
which controls only a small fraction of overall network resources,
can effectively cheat, if other players are honest.
2. The long tail of node operators is sufficiently large that no small
collection of nodes can control more than a small fraction of overall
resources. (Here, the "tail" refers to a ranking based on amount of
resources controlled by each operator.)
3. The bitcoin system turns out to be socially useful and valuable, so
that node operators feel that they are making a beneficial contribution
to the world by their efforts (similar to the various " compute
projects where people volunteer their compute resources for good causes).
In this case it seems to me that simple altruism can suffice to keep the
network running properly.
A very good point, and a more complete specification is necessary in order
to understand how the network will respond to imperfections like this. I
am looking forward to seeing more detail emerge.
One thing I might mention is that in many ways bitcoin is two independent
ideas: a way of solving the kinds of problems James lists here, of
creating a globally consistent but decentralized database; and then using
it for a system similar to Wei Dai's b-money (which is referenced in the
paper) but transaction/coin based rather than account based. Solving the
global, massively decentralized database problem is arguably the harder
part, as James emphasizes. The use of proof-of-work as a tool for this
purpose is a novel idea well worth further review IMO.
Hal Finney

@_date: 2008-11-07 23:40:12
@_author: "Hal Finney" 
@_subject: Re: Bitcoin P2P e-cash paper 
Bitcoin seems to be a very promising idea. I like the idea of basing
security on the assumption that the CPU power of honest participants
outweighs that of the attacker. It is a very modern notion that exploits
the power of the long tail. When Wikipedia started I never thought it
would work, but it has proven to be a great success for some of the
same reasons.
I also do think that there is potential value in a form of unforgeable
token whose production rate is predictable and can't be influenced
by corrupt parties. This would be more analogous to gold than to fiat
currencies. Nick Szabo wrote many years ago about what he called "bit
gold"[1] and this could be an implementation of that concept. There have
also been proposals for building light-weight anonymous payment schemes on
top of heavy-weight non-anonymous systems, so Bitcoin could be leveraged
to allow for anonymity even beyond the mechanisms discussed in the paper.
Unfortunately I am having trouble fully understanding the system. The
paper describes key concepts and some data structures, but does not
clearly specify the various rules and verifications that the participants
in the system would have to follow.
In particular I don't understand exactly what verifications P2P nodes
perform when they receive new blocks from other nodes, and how they
handle transactions that have been broadcast to them. For example, it
is mentioned that if a broadcast transaction does not reach all nodes,
it is OK, as it will get into the block chain before long. How does this
happen - what if the node that creates the "next" block (the first node
to find the hashcash collision) did not hear about the transaction,
and then a few more blocks get added also by nodes that did not hear
about that transaction? Do all the nodes that did hear it keep that
transaction around, hoping to incorporate it into a block once they get
lucky enough to be the one which finds the next collision?
Or for example, what if a node is keeping two or more chains around as
it waits to see which grows fastest, and a block comes in for chain A
which would include a double-spend of a coin that is in chain B? Is that
checked for or not? (This might happen if someone double-spent and two
different sets of nodes heard about the two different transactions with
the same coin.)
This kind of data management, and the rules for handling all the packets
that are flowing around is largely missing from the paper.
I also don't understand exactly how double-spending, or cancelling
transactions, is accomplished by a superior attacker who is able to muster
more computing power than all the honest participants. I see that he can
create new blocks and add them to create the longest chain, but how can
he erase or add old transactions in the chain? As the attacker sends out
his new blocks, aren't there consistency checks which honest nodes can
perform, to make sure that nothing got erased? More explanation of this
attack would be helpful, in order to judge the gains to an attacker from
this, versus simply using his computing power to mint new coins honestly.
As far as the spending transactions, what checks does the recipient of a
coin have to perform? Does she need to go back through the coin's entire
history of transfers, and make sure that every transaction on the list is
indeed linked into the "timestamp" block chain? Or can she just do the
latest one? Do the timestamp nodes check transactions, making sure that
the previous transaction on a coin is in the chain, thereby enforcing
the rule that all transactions in the chain represent valid coins?
Sorry about all the questions, but as I said this does seem to be a
very promising and original idea, and I am looking forward to seeing
how the concept is further developed. It would be helpful to see a more
process oriented description of the idea, with concrete details of the
data structures for the various objects (coins, blocks, transactions),
the data which is included in messages, and algorithmic descriptions
of the procedures for handling the various events which would occur in
this system. You mentioned that you are working on an implementation,
but I think a more formal, text description of the system would be a
helpful next step.
Hal Finney
[1]

@_date: 2009-01-24 16:48:03
@_author: "Hal Finney" 
@_subject: Re: Bitcoin v0.1 released 
Certainly a valid point, and one which has been widely discussed in
the debates over the years about electronic cash. Bitcoin has a couple
of things going for it: one is that it is distributed, with no single
point of failure, no "mint", no company with officers that can be
subpoenaed and arrested and shut down. It is more like a P2P network,
and as we have seen, despite degrees of at least governmental distaste,
those are still around.
Bitcoin could also conceivably operate in a less anonymous mode, with
transfers being linked to individuals, rather than single-use keys. It
would still be useful to have a large scale, decentralized electronic
payment system.
It also might be possible to refactor and restructure Bitcoin to separate
out the key new idea, a decentralized, global, irreversible transaction
database. Such a functionality might be useful for other purposes. Once
it exists, using it to record monetary transfers would be a sort of side
effect and might be harder to shut down.
It's important to understand that the proof-of-work (POW) aspect of
Bitcoin is primarily oriented around ensuring the soundness of the
historical transaction database. Each Bitcoin data block records a set
of transactions, and includes a hash collision. Subsequent data blocks
have their own transactions, their own collisions, and also chain to
all earlier hashes.  The result is that once a block is "buried" under
enough new blocks, it is essentially certain (given the threat model,
namely that attackers cannot muster more than X% of the compute power
of legitimate node operators) that old transactions can't be reversed.
Creating new coins is indeed currently also being done by POW, but I
think that is seen as a temporary expedient, and in fact the current
software phases that out over several years. Hence worries about botnets
being able to manufacture large quantities of POW tokens are only a
temporary concern, in the context of Bitcoin.
There have been a number of discussions in the past about POW tokens as
anti spam measures, given the botnet threat. References are available from
"Proof-of-work system" on Wikipedia. Analyses have yielded mixed results,
depending on the assumptions and system design.
If POW tokens do become useful, and especially if they become money,
machines will no longer sit idle. Users will expect their computers to
be earning them money (assuming the reward is greater than the cost to
operate). A computer whose earnings are being stolen by a botnet will
be more noticeable to its owner than is the case today, hence we might
expect that in that world, users will work harder to maintain their
computers and clean them of botnet infestations.
Countermeasures by botnet operators would include moderating their take,
perhaps only stealing 10% of the productive capacity of invaded computers,
so that their owners would be unlikely to notice. This kind of thinking
quickly degenerates into unreliable speculation, but it points out the
difficulties of analyzing the full ramifications of a world where POW
tokens are valuble.
Hal Finney

@_date: 2009-01-11 02:22:01
@_author: "Hal Finney" 
@_subject: Re: Bitcoin v0.1 released 
Congratulations to Satoshi on this first alpha release.  I am looking
forward to trying it out.
It's interesting that the system can be configured to only allow a
certain maximum number of coins ever to be generated. I guess the
idea is that the amount of work needed to generate a new coin will
become more difficult as time goes on.
One immediate problem with any new currency is how to value it. Even
ignoring the practical problem that virtually no one will accept it
at first, there is still a difficulty in coming up with a reasonable
argument in favor of a particular non-zero value for the coins.
As an amusing thought experiment, imagine that Bitcoin is successful and
becomes the dominant payment system in use throughout the world.  Then the
total value of the currency should be equal to the total value of all
the wealth in the world. Current estimates of total worldwide household
wealth that I have found range from $100 trillion to $300 trillion. With
20 million coins, that gives each coin a value of about $10 million.
So the possibility of generating coins today with a few cents of compute
time may be quite a good bet, with a payoff of something like 100 million
to 1! Even if the odds of Bitcoin succeeding to this degree are slim,
are they really 100 million to one against? Something to think about...

@_date: 2009-02-23 19:30:16
@_author: "Hal Finney" 
@_subject: Re: Shamir secret sharing and information theoretic security 
No, not really. Think of this simple example.
We will have two shares, x and y. Let's work mod 10 to make it simple. The
secret value v will be x + y mod 10. The shares are created by choosing a
random value for x, and then setting y to be v - x mod 10.
So for example if you want to share v = 5, and x is 9, then y will be 6:
9 + 6 = 5 mod 10.
Suppose that you happen to know from other information that the secret
value v is either 1 or 2. Now you learn a share value x = 5. How much
have you learned about v?
Nothing: you can deduce that y is either 6 or 7, but you have no way
of knowing which.  Whatever x had turned out to be, there would be a y
value corresponding to each possible v value. Learning a share tells you
nothing about v, and in general Shamir sharing, learning all but one of
the needed shares similarly tells you nothing about the secret.
Hal Finney

@_date: 2009-08-11 18:47:27
@_author: "Hal Finney" 
@_subject: Ultimate limits to computation 
[Note subject line change]
Things may not be quite as favorable as this. Here is a posting I made
to cypherpunks in 2004:
Not necessarily, if nanotechnology works.  128 bits is big but not
that big.
Eric Drexler, in Nanosystems, section 12.9, predicts that a nanotech
based CPU fitting in a 400 nm cube could run at 1000 MIPS and consume
60 nanowatts, performing 10^16 instructions per second per watt.
Let's design a system to break a 128 bit cipher.  Let's suppose it has
to do 2^10 instructions per test, so this is 2^138 instructions total,
or about 10^41.  Let's let it run for four months, which is 10^7 seconds,
so our necessary processing rate is 10^34 instructions per second.
This means we need 10^34 IPS / 1000 MIPS or 10^25 of Drexler's gigahertz
cubes, call it 10^25 cubic microns or 10^7 cubic meters, a cube about
220 meters on a side.
The system will consume 10^25 * 60 nanowatts or about 6 * 10^17 watts.
Now, that's a lot.  It's four times what the earth receives from the sun.
So we have to build a disk four times the area (not volume) of the earth,
collect that power and funnel it to our computers.  Probably we would
scatter the computers throughout the disk, which would be mostly composed
of solar collectors.  (Keeping the disk gravitationally stable is left
as an exercise for the student, as is the tradeoff involved in making
it smaller but moving it closer to the sun.)
Fortunately, exhaustive key search is perfectly parallelizable so there
is no need for complex communications or synchronizations between the
As you can see, breaking 128 bit keys is certainly not a task which is
so impossible that it would fail even if every atom were a computer.
If we really needed to do it, it's not outside the realm of possibility
that it could be accomplished within 50 years, using nanotech and robotics
to move and reassemble asteroids into the necessary disk.
Now, 256 bit keys really are impossible, unless the whole contraption
above can be made to operate as an enormous, unified quantum computer,
in which case it could theoretically break even 256 bit keys.
512 bit keys... now those really are impossible.
Hal Finney
