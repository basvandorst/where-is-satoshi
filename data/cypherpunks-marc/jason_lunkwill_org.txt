
@_date: 2002-05-30 20:23:06
@_author: Jason Holt 
@_subject: Re: Making Veri$ign rich(er) 
bother with SSL at all?  SSL provides two things:
talking to
one is still nice, but if you're worried about me *watching* your traffic,
shouldn't you also be worried about me intercepting your DNS lookup and
replacing the response with my own IP?  If we all use self-signed certs,
you'll never be the wiser.
redirect *all* amazon.com traffic to me is hard.  And it can be pretty tough
to watch and modify an individual user's traffic.  But it's not nearly as
tough as breaking the crypto behind SSL.  If we use it right, that security
extends to the domain I type into my browser.  If we don't, we reduce it to
the hardness of manipulating the wire.
server end.  But that's orthogonal to the SSL issue.

@_date: 2002-05-30 16:22:35
@_author: Jason Holt 
@_subject: Re: When encryption is also authentication... 
Self signed certs defeat the purpose of the certificate chain mechanism, which
is not just there to make Veri$ign rich.  Mallory can self-sign a cert for
bob.com, and hack Alice's DNS to point bob.com at her own site.  But it's
(theoretically, anyway) much more difficult for her to convince Verisign that
she owns bob.com.  If we trust Verisign to do that, then we know we're really
talking to Bob when we visit bob.com.
Now, the ability to add other CAs which we trust would be a nice feature, and
if there were more trustworthy CAs which were added to the browsers by
default, we could get the costs down closer to the actual overhead of
verifying that the supplicant (er, applicant) actually owns the domain he's
trying to get a cert for.  But anyone can certify themselves as owning
amazon.com, and it's critical that my browser tell me when some stranger makes
such an assertion on their own.

@_date: 2002-06-05 19:37:34
@_author: Jason Holt 
@_subject: Laurie's blinding w/cut and choose? 
where h is the message, and g is the public generator:
r = blind(h) = h^y * g^b (mod p)
s = sign(r) = m^h
(s/g^k^b)^(1/y) (mod p)
signer can verify the signature).  Unfortunately, this doesn't work with cut
and choose where the signer signs the product of unrevealed documents, since the 1/y exponent above would distribute to all the internal terms:
    ((r  * r  * r   ...)^k)^(1/y )
       1    2    3              1
    ------------------------------     !=  (h  * r  * r   ...)^k   (mod p)
             (g^k)^b                         1    2    3
                    1
money system since he doesn't need cut and choose, but I'm working on a
patent-free credential system where the issuer needs to cut and choose to keep
the user from cheating.
(that foils the issuer from adding subliminal information that would
compromise the blinding) without stepping on Chaum's patent?  I hear Chaum
mentioned one himself at PET 2002, but I can't find anything about it online.

@_date: 2002-06-07 20:07:50
@_author: Jason Holt 
@_subject: More of Ben's blinding 
undeniable signatures, they're actually much closer to (h^y)(g^b), so your
suggestion should work great.  Thanks!
about Chaum's blind signature and undeniable signature patents, and want to
present as patent-free a system as possible.
(h1*g^b1 *h2*g^b2 *h3*g^b3...)^k
being hard.  If I replace h1 with (g^b0) and get the issuer to sign:
((g^b0)*g^b1 *h2*g^b2 *h3*g^b3...)^k
the cut-and-choose protocol will be to require that the n/2 checked documents
are all valid and different from any previous instances of the protocol.  So
it should be extremely hard for the user to sneak lots of previously used
values and fake h's (which are really blinding factors) into the unrevealed
documents.  But are there other ways to separate out signatures on individual

@_date: 2002-06-11 01:56:34
@_author: Jason Holt 
@_subject: Ben's blinding, plus pre-publishing 
maybe on sci.crypt.research) before sending it off to the journals.  What are
the issues surrounding that, though?
I'd be leaking something secret.  AFAICT, nobody else would be able to apply
for a patent on the idea without telling a lot of lies in the process.  So
that leaves the possibility that somebody whips out another paper on the topic
before mine's all the way done.  Are the journals going to be snippy about
copyright issues?  Why haven't I seen other papers published on usenet and
such before going to press?
each issuing session which gets hashed several times along with some other
data before going into the blinded messages.  You have to prove that the value
properly descends from the issuer's random value, which makes it tough to
reuse values from a previous session.

@_date: 2002-06-14 01:35:41
@_author: Jason Holt 
@_subject: Safe RSA variant? 
Well, I got such a good response from my last technical question that I'll try
again :)
If it's actually secure, it'll go really well with my credential system.
Trent generates primes p,q.  He publishes n=pq and some random value g.
Trent calculates a and a' such that aa' = 1 % (p-1)(q-1) and a' is prime.  He
sends Alice a' and g^a%n.  a' is her secret exponent and g^a%n her public
Bob can establish a shared secret with Alice if Alice got a' from Trent.  He
picks a random r and sends her g^ar%n.  She raises it to a' to compute the
shared secret g^r%n.
So the important questions are:
* Given g^a%n and a', can Alice derive (p-1)(q-1)?  If so, she'd be able to
take over Trent's job.
* Given g^k%n and k' for lots of different k, can we derive (p-1)(q-1) or
otherwise imitate Trent's ability to give out (g^k%n, k') pairs?
So IOW the goal is for Bob to be able to send Alice a message iff she knows a
secret from Trent.  And if Alice's secret is compromised, only messages sent
to (or possibly from)  Alice become vulnerable.
A friend of mine pointed out that Alice can trivially compute another working
pair of keys from her own: g^-a and -a'. And if the a' keys weren't prime,
Alice and Bob could factor them and generate other keypairs. Both of those
seem manageable, though.
The common modulus attack in which you use g^k and g^k' to get information on
g (which is public in this case) by calculating rk+sk'=1 caused me problems in
earlier equations I tried, but doesn't seem to help the attacker here.

@_date: 2002-07-23 19:58:00
@_author: Jason Holt 
@_subject: Re: Tunneling through hostile proxy 
I don't know of any other real-world examples.  Rescorla mentions the
technique on pp. 316-319 of "SSL and TLS".  Certainly Thawte isn't going to
issue such wildcard certs, for exactly the reasons you mention.  That's why
you (or your government, or company, or whoever keeps an eye on you) create
your *own* CA and tell your browser to trust it.  Then it'll accept the
wildcard certs without complaint.

@_date: 2002-07-23 18:11:04
@_author: Jason Holt 
@_subject: Tunneling through hostile proxy 
back and forth, allowing you to connect all the way to the other server.  However, it is possible for the proxy to have its own CA which has been added
to your browser.  Then it acts as a man in the middle and pretends to be the
remote host to you, and vice versa.  In that case, it works as you describe,
watching the data during its interim decryption.
"*.com"), but it could conceivably generate a certificate for each site you
visit ("secure.yahoo.com", etc.).  The way to tell would be to look at the
issuing authority according to your browser - if it's one of the public ones,
like Thawte, you've got a connection to the far end.  If it's "Th4wt3", or
your company's, the proxy is probably watching.
 (along with other nifty anonymizing stuff).

@_date: 2002-08-27 02:39:15
@_author: Jason Holt 
@_subject: Re: Chaum's unpatented ecash scheme 
credentials.  It'll be nice to have it at least referenced in the literature,
since Ben's paper is the only place I know of where it's really explained.  I
give a URL for it as well as credit to Anonymous, but it would be helpful to
know who really should be credited with what.
I haven't been able to tell how much David Wagner had to do with the idea.  Ben?  David? The URLs to the Anon messages are handy; I'll see about including
them too.

@_date: 2002-08-20 01:58:50
@_author: Jason Holt 
@_subject: Data Security class programming project 
I'm working on designing the programming projects for a data security class.  What do you think of this one?
I love its intrinsic irony, but can we actually get away with requiring it for
a university class?  I mean, Elcomsoft really is in court for this.  My
University is unfortunately not the type of organization to stand at the
forefront and protect our civil rights.
DRM Lab
* Make the lab open-ended - they get to pick what to break and how, as long as
they don't use a pre-packaged tool.  DVDs, CDs, .WMA, etc.
To demonstrate the fundamental futility of current attempts to prevent
unauthorized copying of published works.
_Here_ you can find a copy of Dmitry Sklyarov's Defcon slides in Adobe's eBook
format.  They were created with the eBookPro compiler, advertised as "the only
software in the universe that makes your information virtually 100%
Extract all text from the slides using the method of your choice and turn in
the resulting text file.  It needs no special formatting.

@_date: 2002-10-29 23:49:21
@_author: Jason Holt 
@_subject: patent free(?) anonymous credential system pre-print 
I've submitted a pre-print of my anonymous credential system to the IACR
ePrint server.  Thanks to all of you who responded to the questions I posted
here while working on it.  I'd love to hear feedback from any and all before I
sumbit it for publication; particularly, I want to make sure I haven't
forgotten to give proper attribution for any previous work.
It mentions how to use the blinding technique Ben Laurie describes in his
Lucre paper, which I don't think has been mentioned in the formal literature,
and also describes what I call a non-interactive cut and choose protocol which
is new AFAICT.  Thanks again!
                                        -J

@_date: 2002-11-06 05:18:40
@_author: Jason Holt 
@_subject: Re: "patent free(?) anonymous credential system pre-print" - a simple 
(Re: my paper at  )
response to Adam).
presenting her student ID along with the senior-citizen ID Bob loaned her (or
for which Bob is answering clandestine-ly), as if they both belonged to her,
in order to get both discounts on her movie tickets.  In my system, you get
your credentials issued in a set associated with a single identity, and it's
hard for Alice to get Bob's credentials included in one of her own sets.  It
works even if the CAs don't trust each other.
help in the case when Bob answers in Alice's behalf when she shows his
credentials.  In any case, section 5.5.2 only adds liability to pooling - it
doesn't prevent it mathematically.  (As to lending in general, I think you're
right that discouragement may be the best we can do).
the credentials which the holder can prove is or isn't the same as in other
credentials.  However, the discussion on page 193 is with respect to building
digital pseudonyms, and the discussion on page 210 seems to be about showing
that values are *not* the same, following a scenario in which a pseudonym
holder has been identified as a misbehaver. I can think of ways in which this
feature might be leveraged to create otherwise-unlinkable sets of credentials
from different (distrusting) CAs, but it's never addressed directly that I can
see, and would need some specifics filled in.  Nonetheless, I'll point out in
my paper that it's a possibility in your system.
selective disclosure.
I'm glad that was clear in my text.  This isn't a do-everything system like
Brands' - rather, it has 2 aims.  1: show how to do simple selective
disclosure in a Chaum/Fiat/Naor-like system using X.509v3 credentials as a
base, and 2: show how to link credentials from multiple issuers to the same
identity without compromising anonymity.
was to create a system not encumbered by your patents or Chaum's.
others have lots of features which my system doesn't attempt to provide.  My
apologies if my terse treatment mischaracterized your work.

@_date: 2002-11-06 05:18:40
@_author: Jason Holt 
@_subject: Re: "patent free(?) anonymous credential system pre-print" - a simple 
(Re: my paper at  )
response to Adam).
presenting her student ID along with the senior-citizen ID Bob loaned her (or
for which Bob is answering clandestine-ly), as if they both belonged to her,
in order to get both discounts on her movie tickets.  In my system, you get
your credentials issued in a set associated with a single identity, and it's
hard for Alice to get Bob's credentials included in one of her own sets.  It
works even if the CAs don't trust each other.
help in the case when Bob answers in Alice's behalf when she shows his
credentials.  In any case, section 5.5.2 only adds liability to pooling - it
doesn't prevent it mathematically.  (As to lending in general, I think you're
right that discouragement may be the best we can do).
the credentials which the holder can prove is or isn't the same as in other
credentials.  However, the discussion on page 193 is with respect to building
digital pseudonyms, and the discussion on page 210 seems to be about showing
that values are *not* the same, following a scenario in which a pseudonym
holder has been identified as a misbehaver. I can think of ways in which this
feature might be leveraged to create otherwise-unlinkable sets of credentials
from different (distrusting) CAs, but it's never addressed directly that I can
see, and would need some specifics filled in.  Nonetheless, I'll point out in
my paper that it's a possibility in your system.
selective disclosure.
I'm glad that was clear in my text.  This isn't a do-everything system like
Brands' - rather, it has 2 aims.  1: show how to do simple selective
disclosure in a Chaum/Fiat/Naor-like system using X.509v3 credentials as a
base, and 2: show how to link credentials from multiple issuers to the same
identity without compromising anonymity.
was to create a system not encumbered by your patents or Chaum's.
others have lots of features which my system doesn't attempt to provide.  My
apologies if my terse treatment mischaracterized your work.

@_date: 2004-04-28 19:54:50
@_author: Jason Holt 
@_subject: Brands' private credentials 
Here's what I remember from about a year ago about the current state of
private credentials.  That recollection comes with no warranties express or
Last I heard, Brands started a company called Credentica, which seems to only
have a placeholder page (although it does have an info@ address).
I also heard that his credential system was never implemented, but that might
be wrong now.  Anna Lysyanskaya and Jan Camenisch came up with a credential
system that I hear is based on Brands'. Anna's dissertation is online and
might give you some clues.  They might also have been working on an
I came up with a much simpler system that has many similar properties to
Brands', and even does some things that his doesn't.  It's much less developed
than the other systems, but we did write a Java implementation and published a
paper at WPES last year about it.  I feel a little presumptuous mentioning it
in the context of the other systems, which have a much more esteemed set of
authors and are much more developed, but I'm also pretty confident in its
Note that most anonymous credential systems are encumbered by patents.  The
implementation for my system is based on the Franklin/Boneh IBE which they
recently patented, although there's another IBE system which may not be
encumbered and which should also work as a basis for Hidden Credentials.

@_date: 2004-05-10 20:02:12
@_author: Jason Holt 
@_subject: Re: Brands' private credentials 
Yep, that'd be a problem in that case.  In the most recent (unpublished)  paper, I addressed that by using R as the key for a ciphertext+MAC on the
actual message.  So the server would have to find two R's that both satisfy
the MAC but produce different ciphertexts in order to learn anything from the
In either case, though, you can't just trust that the server encrypted against
"patient OR doctor" unless you have both creds and can verify that they each
recover the secret.  They might be lying about the "doctor" part, and really
sending against "patient OR nonexistant", in which case your response reveals
that you're a patient.  That's why we recommend that your response (if any)
include the policy for the creds you used in decryption.  So if Alice is
responding to a message she decrypted with her "patient" cred, which she only
(implicitly) discloses to Medicare, and the response itself is only for AIDS
clinics, she should encrypt against "Medicare AND AIDS_clinic".
(And you're right, the AIDS example is not very compelling.  The slides give a
better one about FBI agents, but I'm still looking for other examples of
super-sensitive transactions where HCs would fit)
That's very slick.  I'll check it out.
Hugo Krawczyk gave a great talk at Crypto about the going-first problem in
IPSec, which is where I got the phrase.  He has a nice compromise in letting
the user pick who goes first, but for some situations I think hidden
credentials really would hit the spot.
Yeah, although I think most of them would require an on-line trusted server.  But that just makes all sorts of things way too easy to be interesting. :)

@_date: 2004-05-10 20:02:12
@_author: Jason Holt 
@_subject: Re: Brands' private credentials 
Hash: SHA1
Yep, that'd be a problem in that case.  In the most recent (unpublished)  paper, I addressed that by using R as the key for a ciphertext+MAC on the
actual message.  So the server would have to find two R's that both satisfy
the MAC but produce different ciphertexts in order to learn anything from the
In either case, though, you can't just trust that the server encrypted against
"patient OR doctor" unless you have both creds and can verify that they each
recover the secret.  They might be lying about the "doctor" part, and really
sending against "patient OR nonexistant", in which case your response reveals
that you're a patient.  That's why we recommend that your response (if any)
include the policy for the creds you used in decryption.  So if Alice is
responding to a message she decrypted with her "patient" cred, which she only
(implicitly) discloses to Medicare, and the response itself is only for AIDS
clinics, she should encrypt against "Medicare AND AIDS_clinic".
(And you're right, the AIDS example is not very compelling.  The slides give a
better one about FBI agents, but I'm still looking for other examples of
super-sensitive transactions where HCs would fit)
That's very slick.  I'll check it out.
Hugo Krawczyk gave a great talk at Crypto about the going-first problem in
IPSec, which is where I got the phrase.  He has a nice compromise in letting
the user pick who goes first, but for some situations I think hidden
credentials really would hit the spot.
Yeah, although I think most of them would require an on-line trusted server.  But that just makes all sorts of things way too easy to be interesting. :)

@_date: 2004-05-10 02:42:04
@_author: Jason Holt 
@_subject: Re: Brands' private credentials 
Hash: SHA1
Right, good summary.
How would you use SSL to prove fulfillment without revealing how?  You could
get the CA to issue you a "patient or doctor" SSL cert, likewise for every
possible combination of things somebody might ask you for, but that's not very
practical.  Presumably this is why the other systems also allow proof of
expressions without revealing all the attributes you used to do so.
If you can trust the server to do so.  Firstly, hidden credentials limit what
the server learns, so you don't *have* to trust the server as much.  But
secondly, they also solve the problem which shifts to the server when it goes
first: now the server has to reveal attributes to a complete stranger.  For
sensitive systems, it's easy to get circular dependencies where neither side
wants to go first.  Hidden credentials let you enforce the policy in the
ciphertext: "if you can read this, let's talk.  if not, I didn't want to talk
to you anyway (and you won't learn why)".  (Incidentally, two other similar
systems came out at about the same time as mine, both geared less toward
extreme policy/credential paranoia and more toward resolving such circular
dependencies: OSBE (Li, Du, Boneh) and Secret Handshakes (Balfanz et al)).
Right, that is a big consideration with my system; CAs can be nosy.  Of
course, any CA will want you to show paper credentials or some other
real-world proof that they should give you a credential.  But you're right
that the Chaum/Brands/L&C family do have a big advantage in limiting the risks
of big-brother CAs once they've issued it to you.
If your definition requires anonymity wrt the CA, then you're right.  My
system lets folks:
* authenticate based on attributes rather than identity
* access resources without the server even knowing whether they fulfill the
* hide policies from people who don't fulfill them
So it's definitely in the realm of other privacy systems.  We could define a
new term just to exclude my system from the others, but at this point I don't
think naming confusion is any worse for my system; they all have lots of
different nonorthogonal features.  I have to write a survey paper for my Ph.D.
requirements, and I've been thinking I should write a big feature table as
part of it.
I've never really considered it as a payment system.  It's geared more toward
systems which use extremely sensitive resources, and their corresponding
sensitive policies and credentials.

@_date: 2004-05-10 18:45:56
@_author: Jason Holt 
@_subject: Re: blinding & BF IBE CA assisted credential system (Re: chaum's 
Well, he can always generate private keys for any pseudonym, just as in cash
systems where the bank can always issue bank notes.  Here's what I'm
suggesting, where "b" is a blinding function and n1... are random nyms:
Alice              FBI TTP
<---cut & choose: n1,n3
(Alice unblinds and now has a credential for nym n2)
So it's vanilla Chaum-style blinded credentials.  The FBI signs Alice's agent
cred without learning the nym.  Alice can use the nym, and the server can ask
the FBI the attributes (agent? chief? secretary?) of the person with the nym,
but the FBI won't know.  The FBI could eavesdrop on Alice's connection and
generate whatever creds are necessary to read the resource Bob sends her, but
that's why I was talking about building it in a protocol with PFS.
But now that I think of it, PFS isn't really necessary at all for Alice&Bob to
have a conversation where their policies are respected:
Alice                                         Bob
(Alice generates random nonce na)
HC_E(na, "Bob:agent", FBI)--->
                         (Bob generates random nb)
                 <---HC_E(nb, "Alice:member", NRA)
Both generate session keys from Hash(na,nb).
So, Alice wants to connect iff Bob's FBI, and Bob wants to talk iff Alice is
in the NRA, where "Alice" and "Bob" are random pseudonyms.  Thus they send
their random nonces na and nb encrypted against those creds (HC_E is a hidden
cred encrypt), then use those nonces for the session keys.
The FBI can *always* impersonate an agent, because, well, they're the CA and
they can make up pseudonymous agents all day long. But in this protocol, I
believe they wouldn't be able to be a MITM and/or just eavesdrop on Alice&Bob.  That's because Bob only wants to talk to NRA members, and the FBI can't
impersonate that.
Now, this is for an interactive session, rather than just sending a single
request/response round like I discuss in the paper.  But even then, policies
are always respected.  Just change "na" to "request" and "nb" to "response".  Alice's policy is respected whether she talks to FBI-authorized-Bob or
FBI-authorized-FBI, and the FBI doesn't get to read Bob's NRA-Alice-only

@_date: 2004-05-10 18:45:56
@_author: Jason Holt 
@_subject: Re: blinding & BF IBE CA assisted credential system (Re: chaum's 
Well, he can always generate private keys for any pseudonym, just as in cash
systems where the bank can always issue bank notes.  Here's what I'm
suggesting, where "b" is a blinding function and n1... are random nyms:
Alice              FBI TTP
<---cut & choose: n1,n3
(Alice unblinds and now has a credential for nym n2)
So it's vanilla Chaum-style blinded credentials.  The FBI signs Alice's agent
cred without learning the nym.  Alice can use the nym, and the server can ask
the FBI the attributes (agent? chief? secretary?) of the person with the nym,
but the FBI won't know.  The FBI could eavesdrop on Alice's connection and
generate whatever creds are necessary to read the resource Bob sends her, but
that's why I was talking about building it in a protocol with PFS.
But now that I think of it, PFS isn't really necessary at all for Alice&Bob to
have a conversation where their policies are respected:
Alice                                         Bob
(Alice generates random nonce na)
HC_E(na, "Bob:agent", FBI)--->
                         (Bob generates random nb)
                 <---HC_E(nb, "Alice:member", NRA)
Both generate session keys from Hash(na,nb).
So, Alice wants to connect iff Bob's FBI, and Bob wants to talk iff Alice is
in the NRA, where "Alice" and "Bob" are random pseudonyms.  Thus they send
their random nonces na and nb encrypted against those creds (HC_E is a hidden
cred encrypt), then use those nonces for the session keys.
The FBI can *always* impersonate an agent, because, well, they're the CA and
they can make up pseudonymous agents all day long. But in this protocol, I
believe they wouldn't be able to be a MITM and/or just eavesdrop on Alice&Bob.  That's because Bob only wants to talk to NRA members, and the FBI can't
impersonate that.
Now, this is for an interactive session, rather than just sending a single
request/response round like I discuss in the paper.  But even then, policies
are always respected.  Just change "na" to "request" and "nb" to "response".  Alice's policy is respected whether she talks to FBI-authorized-Bob or
FBI-authorized-FBI, and the FBI doesn't get to read Bob's NRA-Alice-only

@_date: 2004-05-10 22:37:15
@_author: Jason Holt 
@_subject: Re: more hiddencredentials comments (Re: Brands' private credentials) 
I don't quite get what you're suggesting.  Could you give a more concrete
example?  Well, I wouldn't complain. :)  (Although pairings are quite slow, on the order
of hundreds of milliseconds.)  Hilarie Orman presented it at an IETF meeting
to what was reportedly a lukewarm response, and they also raised the patent
issue.  Dan Boneh is sensitive to the issue of patented crypto, and was quite
considerate when I asked about it, but  still has the same
vague statement in their FAQ about how they're not going to be evil with the
patent, so it's still up in the air whether IBE will be useful in IETF

@_date: 2004-05-10 22:37:15
@_author: Jason Holt 
@_subject: Re: more hiddencredentials comments (Re: Brands' private credentials) 
Hash: SHA1
I don't quite get what you're suggesting.  Could you give a more concrete
example?  Well, I wouldn't complain. :)  (Although pairings are quite slow, on the order
of hundreds of milliseconds.)  Hilarie Orman presented it at an IETF meeting
to what was reportedly a lukewarm response, and they also raised the patent
issue.  Dan Boneh is sensitive to the issue of patented crypto, and was quite
considerate when I asked about it, but  still has the same
vague statement in their FAQ about how they're not going to be evil with the
patent, so it's still up in the air whether IBE will be useful in IETF

@_date: 2004-05-11 21:10:35
@_author: Jason Holt 
@_subject: Re: who goes 1st problem 
[Adam and I are taking this discussion off-list to spare your inboxes, but
this message seemed particularly relevant.  Perhaps we'll come back later if
we come up with anything we think will be of general interest.]
Agreed.  Ninghui Li's RSA OSBEs might be the answer; they're not quite as
elegant as the IBE version, but they work with blinded RSA signatures, and so
should be patent-free by next year, assuming Ninghui doesn't seek any patents.  Section 4 of his PODC paper describes the RSA implementation.  He also has a
new paper which does neat things with commitments that I haven't wrapped my
mind around yet.
Actually, we might also consider contacting Dan Boneh at some point; he seems
to be interested in the proliferation of IBE, and might be sympathetic to the
needs of the IETF to have free standards, especially considering the exposure
it'd get for his system.
However, we need to define just what we need to accomplish.  Since my lab
works in trust negotiation, we think in terms of policies a lot, whereas SSL
just assumes you know what certs you want to send to whom.  But let's assume
the SSL model for simplicity.
The second issue, now that I think of it in this context, would be how you
actually get your certs to the other guy.  Hidden credentials, as Ninghui
pointed out, assume you have some means for creating the other guy's cert,
eg., a template "(nym):Senior_Agent:(current year)" producing
The OSBE paper, OTOH, assumes we're going to exchange our certificates, just
without the CA signatures.  Then I can send you messages you can only read if
you really do have a signature on that cert.  But I've always thought that was
problematic, since why would honest people bother to connect then use fake
certs?  The attacker doesn't need to see the signature - he believes you.  So
honest users would need to regularly give out fake certs so they can hide
their legit behavior among the fake connects.  Will Winsborough also suggests
this with the notion of ACK policies - you *always* give people something they
ask for, so they can't tell what you have and what you don't.
So maybe what we really want is some sort of fair exchange or something, where
I can show you my valid certs as you show me the valid certs of your own.  If one side is guessable, we've discussed this sort of thing with hidden
E("Hi Bob, since you're a senior agent, you can see my agent credential:
'Alice:Denver field office agent (apprentice):2004",
E("Hi Bob, since you're a BYU alumnus, you can see my BYU credential:
'Alice:Senior:computer science:3.96 gpa:2004",
So that's an open problem.  But let's assume guessable-certs, since that's the
only way I know how to really keep certs and policies safe for now. The
OSBE-RSA math still works.  So we're good so far, except that the RSA approach
is interactive.  Section 4 says that in the RSA scheme, Alice sends her cert
can send back an encrypted message.  (In HC and IBE-OSBEs, Bob doesn't need
the blinded signature to use as a public key).
But maybe Robert's improved secret sharing scheme from the new HC paper can give us some ideas:
1. Alice sends blinded signatures for each of her relevant certs, not
revealing which signature goes with each cert, and not revealing the cert
2. Bob generates the contents of each of Alice's certs relevant to his policy,
and simply generates each possible combination of hash-of-cert-contents and
blinded-signature.  One from each row will be a match-up between contents and
signature, and Alice will have to figure out which.  Unfortunately, this
requires n^2 multiplies and exponentiations.

@_date: 2004-05-11 21:10:35
@_author: Jason Holt 
@_subject: Re: who goes 1st problem 
[Adam and I are taking this discussion off-list to spare your inboxes, but
this message seemed particularly relevant.  Perhaps we'll come back later if
we come up with anything we think will be of general interest.]
Agreed.  Ninghui Li's RSA OSBEs might be the answer; they're not quite as
elegant as the IBE version, but they work with blinded RSA signatures, and so
should be patent-free by next year, assuming Ninghui doesn't seek any patents.  Section 4 of his PODC paper describes the RSA implementation.  He also has a
new paper which does neat things with commitments that I haven't wrapped my
mind around yet.
Actually, we might also consider contacting Dan Boneh at some point; he seems
to be interested in the proliferation of IBE, and might be sympathetic to the
needs of the IETF to have free standards, especially considering the exposure
it'd get for his system.
However, we need to define just what we need to accomplish.  Since my lab
works in trust negotiation, we think in terms of policies a lot, whereas SSL
just assumes you know what certs you want to send to whom.  But let's assume
the SSL model for simplicity.
The second issue, now that I think of it in this context, would be how you
actually get your certs to the other guy.  Hidden credentials, as Ninghui
pointed out, assume you have some means for creating the other guy's cert,
eg., a template "(nym):Senior_Agent:(current year)" producing
The OSBE paper, OTOH, assumes we're going to exchange our certificates, just
without the CA signatures.  Then I can send you messages you can only read if
you really do have a signature on that cert.  But I've always thought that was
problematic, since why would honest people bother to connect then use fake
certs?  The attacker doesn't need to see the signature - he believes you.  So
honest users would need to regularly give out fake certs so they can hide
their legit behavior among the fake connects.  Will Winsborough also suggests
this with the notion of ACK policies - you *always* give people something they
ask for, so they can't tell what you have and what you don't.
So maybe what we really want is some sort of fair exchange or something, where
I can show you my valid certs as you show me the valid certs of your own.  If one side is guessable, we've discussed this sort of thing with hidden
E("Hi Bob, since you're a senior agent, you can see my agent credential:
'Alice:Denver field office agent (apprentice):2004",
E("Hi Bob, since you're a BYU alumnus, you can see my BYU credential:
'Alice:Senior:computer science:3.96 gpa:2004",
So that's an open problem.  But let's assume guessable-certs, since that's the
only way I know how to really keep certs and policies safe for now. The
OSBE-RSA math still works.  So we're good so far, except that the RSA approach
is interactive.  Section 4 says that in the RSA scheme, Alice sends her cert
can send back an encrypted message.  (In HC and IBE-OSBEs, Bob doesn't need
the blinded signature to use as a public key).
But maybe Robert's improved secret sharing scheme from the new HC paper can give us some ideas:
1. Alice sends blinded signatures for each of her relevant certs, not
revealing which signature goes with each cert, and not revealing the cert
2. Bob generates the contents of each of Alice's certs relevant to his policy,
and simply generates each possible combination of hash-of-cert-contents and
blinded-signature.  One from each row will be a match-up between contents and
signature, and Alice will have to figure out which.  Unfortunately, this
requires n^2 multiplies and exponentiations.

@_date: 2004-06-16 20:28:13
@_author: Jason Holt 
@_subject: Hiawatha's research 
Hash: SHA1
"Hiawatha's Research"
Jason Holt June, 2004, released into the public domain.
Dedicated to Eric Rescorla, with apologies to Longfellow.
("E. Rescorla" may be substituted for "Hiawatha" throughout.)
Hiawatha, academic,
he could start ten research papers,
start them with such mighty study,
that the last had left his printer,
ere the first deadline extended.
Then, to serve the greater purpose,
he would post these master papers,
post them with such speed and swiftness,
to gain feedback from his cohorts,
for their mighty learned comments.
from his printer, Hiawatha
took his publication paper,
sent it to the preprint archive,
sent it out to all the newsgroups
Then he waited, watching, listening,
for the erudite discussion,
for the kudos and the errors,
that the others soon would send him.
But in this my Hiawatha
was most cruelly mistaken,
for not one did read his papers,
not one got past the simple abstract.
Still did they all grab their keyboards,
writing with great flaming fury
of the folly of his venture,
of his paper's great misgiving.
Of his obvious omissions,
of his great misunderstandings,
of his utter lack of vision,
of his blatant plagiarism.
(This last point he found most galling,
found it really quite dumbfounding,
since for prior art, he'd listed
ninety-three related papers.)
Now the mighty Hiawatha,
in his office still is sitting,
contemplating on his research,
thinking on his chosen topic.
Wondering, in idle moments,
if he had not chosen wrongly,
the position he had taken
as a research paper author
And he thinks, my Hiawatha,
if he might not have been better
served by a more lowly station,
as a cashier at McDonalds,
as a washer at the car wash,
as a cleaner of the bathrooms.
Thus departs my Hiawatha.

@_date: 2005-02-04 19:35:59
@_author: Jason Holt 
@_subject: RE: Dell to Add Security Chip to PCs 
Yes, Senator McCarthy, I do in fact feel safer knowing that mathematics
protects my data.  Welcome to cypherpunks.
