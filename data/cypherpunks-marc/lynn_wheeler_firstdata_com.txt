
@_date: 2001-11-03 16:51:10
@_author: except for some specific exceptions 
@_subject: Re: Rubber hose attack 
i believe i said that ROI represented the total cost of the program to
eliminate some fraud  compared to the total amount of fraud. in the credit
card scenerio it isn't enuf to know the cost per event. assuming that
adding chips to those payment cards is a solution. in there US there are
something less than a billion new cards sent out each year ... and adding a
chip could cost on the order of $25 each. Just for the chips (ignoring for
the moment the issue of reader provisioning) ... that cost might be
somewhere in the $15b to $20b per annum range. There would have to be a
huge number of $3500 per fraud events eliminated by a comprehensive chip
program to justify it.
so as referenced in the previous postings .... advances in technology can
reduce the cost of dealing with fraud (in the chip card case ... it would
be nice to reduce it from $20b/annum to maybe under $1b/annum; say a
combination of significantly reduced chip costs as well as the number of
new sent out each year) while at the same time increasing the amount of
fraud (criminals find it easier to counterfiet existing cards increasing
the amount of traud that happens).
However, generically (except for some specific exceptions), the majority of
fraud has tended to be insider fraud. Just improving things with strong
authentication &/or identification doesn't directly address insider fraud,
significant audit, command & control, and compensating procedures are
needed to be in place to address significant amounts of insider fraud (who,
effectively by definition, have already been authenticated and identified).
JohnE37179 on 11/02/2001 08:26 pm wrote
Again, this is only a very small part of the problem. The Inspector
office reports that the average identity fraud in the Social Security
Administration costs over $100,000. Texas Medicaid loses approximately 25%
its $4 billion budget to fraud. The ABA reports that the average cost of
credit card fraud for the issuer exceeds $3500. Each incident of identity
fraud in recruiting costs DOD over $500,000.

@_date: 2001-11-03 02:45:26
@_author: indirectly, through the merchant discount 
@_subject: Re: Rubber hose attack 
the following from a thread on some of the fees related to fraud issues at
specifically from a thread on Visa/MasterCard Antitrust Comments.
Here's an interesting quote taken directly from Judge Barbara Nelson's
decision (the full text of the decision is available at:
"Defendants' ability to price discriminate also illustrates their market
Both Visa and MasterCard charge differing interchange fees based, in part,
on the degree to which a given merchant category needs to accept general
purpose cards.
Transactions with catalog and Internet merchants, for example, which rely
almost completely on general purpose cards, have higher interchange fees
than 'brick and mortar' merchants.
Defendants rationalize this difference by pointing to increased fraud in
these merchant categories, but this explanation is belied by the fact that
the Internet merchant, not Visa/MasterCard or their member banks, bears
virtually all the risk of loss from fraudulent transactions.
Even today, Amazon's fraud rate is lower than mail-order companies, yet it
is charged (indirectly, through the merchant discount) the same interchange
fee as these mail order companies.
The reality is that Visa and MasterCard are able to charge substantially
different prices for those hundreds of thousands of merchants who must take
credit cards at any price because their customers insist on using
those cards."

@_date: 2001-11-03 00:07:14
@_author: unknown_name 
@_subject: Re: Rubber hose attack 
also a somewhat related thread regarding costs for stronger authentication
 Smart Card vs. Magnetic Strip
 Smart Card vs. Magnetic Strip
 Smart Card vs. Magnetic Strip
 Smart Card vs. Magnetic Strip

@_date: 2001-11-02 23:21:37
@_author: addenda to chargebacks 
@_subject: Re: Rubber hose attack 
slight clarification .... while consumers don't directly pay the
transaction fees ... whatever fees that the merchants directly pay ... show
up in prices that come out of consumers pocket-book ... which they do pay
... as well as various & sundry fees that consumers pay to their issuing
bank as part of various credit related fees & charges.
parts of the issue has always been would the procedures to lower fraud,
cost more than the fraud they were limiting. Two things have been happening
... the cost of technology has in general been coming down rapdly ... both
the cost of technology needed to limit fraud as well as the cost of
technology for various kinds of fraud & counterfeiting (which tends to
increase the amount of fraud).
misc threads on the subject
 Simple PKI
 [FYI] Did Encryption
Empower These Terrorists? (addenda to chargebacks)
 Who or what to authenticate?
 Schneier: Why Digital
Signatures are not Signatures (was Re :CRYPTO-GRAM, November 15, 2000)
 "out of control credit card
 "out of control credit card
 Fake IDs swamp police
 Cryptogram Newsletter is off the
 PKI and Non-repudiation
 PKI and Non-repudiation
 Remove the name from credit
 No Trusted Viewer possible?
 No Trusted Viewer possible?
 E-commerce security????
credit has enjoyed quite a bit of market penetration in terms of internet
transactions ... in part because it was relatively simple to adopt the
existing MOTO-model to the internet
 Assurance, e-commerce, and
some x9.59 ... fyi
 Assurance, e-commerce, and
some x9.59 ... fyi
 Assurance, e-commerce, and
some x9.59 ... fyi
 loosely-coupled, sysplex,
cluster, supercomputer & electronic commerce
however, x9.59 which had a requirement to preserve the integrity for all
account-based transactions in all envrionments with only authentication ...
also opens up other payment methods to the internet (as well as general
ability to reduce fraud)
NACHA AADS results!!
with regard to to rubber hose attack ... there is an issue of ROI (assuming
a rubber hose attack has some rational financial motivation as opposed to
something akin to random violence) ... i.e. effort to mount the attack
vis-a-vis reward in return. The discussion of stealing a web merchant
credit card master file may have a relatively modest investment but result
in several hundred thousand account numbers for which fraudulent
transactions can be executed against.  The claim is that ROI for rubber
hose attacks would preclude majority of rational financial motivation ...
aka they're would be other attacks with signficiant better ROI. While
rubber hose attacks might never totally disappear ... the amount of fraud
from such events will be very small.
misc. past threads in the area:
 merchant web server
 [FYI] Did Encryption Empower
These Terrorists?
 [FYI] Did Encryption Empower
These Terrorists?
 The end of P-Cards?
 The end of P-Cards?
 net banking, is it safe??
... security proportional to risk
 some recent threads on
netbanking & e-commerce security
 3D Secure Vulnerabilities?
Photo ID's and Payment Infrastructure
 financial payment
standards ... finger slip
 PKI and Non-repudiation
 PKI and Non-repudiation
 Net banking, is it safe???
 Would this type of credit card
help online shopper to feel more secure?
 Credit Card # encryption
 E-commerce security????
 E-commerce security????
 E-commerce security????
 Does "Strong Security" Mean
 I-net banking security
 Why is UNIX semi-immune to viral
some more general threads:
In a message dated 11/2/01 2:03:05 PM, rick_smith
<< Of course. But this hasn't prevented people from acquiring and using
cards. More to the point, it hasn't prevented the merchants, banks, and
credit card issuers from maintaining and promoting this imperfect system.
This would suggest that the losses from fraud (which customers don't pay,
at least not here in the US) are amply covered by the income they bring in.
This sounds to me like a system that "works" in a practical sense. >>
In good times when a 5% loss factor disappeared in the profits it didn't
matter. In times when every penny is being squeezed (Airlines), and fraud
seems to have doubled the risk management view may have changed.
John Ellingson
Edentification, Inc.

@_date: 2001-12-31 00:01:30
@_author: and other flavors 
@_subject: Re: CFP: PKI research workshop 
somewhat as an aside .... the "gift" cards (and other flavors) that you see
at large percentage of retail check-out counters in the US are effectively
digital cash ... although the current incarnation results in a different
card at every retailer. however, they are online, magstripe-based digital
cash .... utilizing the same ubquituous point-of-sale infrastructure as
debit & credit (it is just that the transaction routing goes to different
online transaction processing than credit & debit). The issue of whether or
not it would be possible to use any card at any merchant is more of a
business rule issue than a technology issue.
note from a higher assurance standpoint ... the x9.59 work is applicable to
all electronic transactions .... whether they are credit, debit, e-check,
OR (online)  digital cash ... AND x9.59 transactions could flow over both
existing ubiquituous point-of-sale network and/or a ubiquituous internet
network (or any other kind of network).
random refs:
A "local" financial branch implementation and a digital cash implementation
might have a number of similar useability attributes .... aka from the
standpoint of how local funds do you have immediately available .... aka
funds are transferred into you local PDA as digital cash for immediate use
.... or funds are transferred into the local financial institution for
immediate use.

@_date: 2001-12-30 23:42:17
@_author: "buffer overflow" 
@_subject: Re: CFP: PKI research workshop 
another aspect that overlaps PKIs and quality is the difference between
"application" code and "service" code .... turning an application into a
service can be hard .... possibly writing 4-10 times as much code as in the
base application infrastructure .... and very high-quality code ....
dealing with potentially very complex failure modes. Related thread
("buffer overflow") has been running in the sci.crypt newsgroups. ....
partial reference:
 Buffer overflow
 Buffer overflow
 Buffer overflow
also an older thread regarding "assurance" in application and digital
signature authentication
 Assurance, e-commerce, and
some x9.59
 Assurance, e-commerce, and
some x9.59
 Assurance, e-commerce, and
some x9.59
 assurance, x9.59, etc
Now, an interesting thing might be regarding rapid uptake of general
security. One could contend that majority of the market believes that good,
strong security should be an attribute of the basic infrastructure ...
somewhat like the issue of automobile quality in the '70s, not going to pay
any more for it ... but would migrate to a manufactor that had
significantly better quality. You then have the 1) vendors that  don't see
quality as worth while since they won't be able to charge more 2) new
vendors that would like to sell "quality" as a stand-alone attribute ...
not actually having to manufactor automobiles .... but somehow convince
customers that they can sell quality independent of any product, and 3)
vendors that feel that they can eventually gain market share by providing
better quality.
Substitute "security" and/or "PKI" in place of "quality".
Part of the issue is that security (and strong authentication) should be an
attribute of the basic infrastructure ... not something that exists by
itself in a vacuum.

@_date: 2001-12-29 22:22:13
@_author: not purely an end in itself 
@_subject: Re: CFP: PKI research workshop 
everyday life has a lot of cryptography ... for instance ... there is quite
a bit of cryptography involved in every debit transaction (every time you
get money from ATM machine or use point-of-sale terminal).
a lot of PKI revolves around the business process of strong authentication
.... where some aspects of cryptography happens to be used. A subset of
this saw extremely rapid uptake with regard to SSL and online shopping
(again quite a bit of cryptography in use, one might make a case that
cryptography should be like electronic dsitributors, everybody may have one
... but very few could actually build one from scratch or even know thay
actually have one). One might be tempted to make the observation that
uptake rate is much faster if it is filling a new need as opposed to trying
to change existing operation.
However, PKI industry seems to have tried to make public key cryptography
and certificates an "end in themselves". First off, certificates are a
solution to strong authentication in an offline environment (aka early '80s
offline email paradigm) which doesn't have a very good match to most of the
business processes that are in use today.
A PIN debit transaction involves the relying-party (the consumer's bank
both authenticating and authorizing the transaction .... authentication
based on something you have and something you know ... and authorization on
a combination of authentication, available funds, any previous transactions
today, the aggregate value of any current day transactions, etc). Digital
signature can improve the integrity of the existing PIN-debit based
operation and also expand the use to open/insecure network (i.e. the
existing PIN-debit is predicated on closed, secure network). This is what
NACHA (national cllearing house association ... aka typically regional and
national financial industry organizations that provide infrastructure for
bank-to-bank wholesale financial transfers) did in the debit demonstration
.... basically upgrading PIN-based cyrptography for authentication to
digital-signature cryptography for authentication (where a shared secret
paradigm ... aka PIN-base was replaced with a non-shared secret paradigm).
There was no certificate necessary ... and, in fact, certificates aren't
really about cryptography, there are more about a specific kind of offline
business process (which is having difficulty finding a niche in an
increasingly online world).
Furthermore, not only is the offline-paradigm certificate model having a
difficulty finding a niche in an online world ... the idea of a purely
authentication business process is possibly having trouble finding its
... referencing prior posting that most business tend to perform
authentication ... a cost overhead ... as part of some useful, productive
business process (not purely an end in itself)
One might envision a Monty Python Department of Authentication. Citizens
are asked to visit their local Department of Authentication every day,
state their name, and provide certificate/credential for proof of their
claimed identity. The Department of Authentication doesn't actually record
that they've prooved any identity and citizens aren't actually mandated to
show up. However, if the citizens do show up everyday to their local
Department of Authentication, it makes the DoA employees feel that they are
providing a useful service in the scheme of the universe (as well as
certificates/credentials that are voluntarily verified everyday are better
than ones that aren't ... something like pet rocks).
Now, an interesting thing might be regarding rapid uptake of general
security. One could contend that majority of the market believes that good,
strong security should be an attribute of the basic infrastructure ...
somewhat like the issue of automobile quality in the '70s, not going to pay
any more for it ... but would migrate to a manufactor that had
significantly better quality. You then have the 1) vendors that  don't see
quality as worth while since they won't be able to charge more 2) new
vendors that would like to sell "quality" as a stand-alone attribute ...
not actually having to manufactor automobiles .... but somehow convince
customers that they can sell quality independent of any product, and 3)
vendors that feel that they can eventually gain market share by providing
better quality.
Substitute "security" and/or "PKI" in place of "quality".
Part of the issue is that security (and strong authentication) should be an
attribute of the basic infrastructure ... not something that exists by
itself in a vacuum.
Several of the comments about the slow uptake of PKI touch on what
seem to be two basic factors that are responsible for this phenomenon:
1.  Cryptography does not fit human life styles easily.  As an example,
truly secure systems would stop secretaries from forging their boss's
signatures, and this would bring all large beaucratic organizations to
a standstill.
2.  Novel technologies take a long time to diffuse through society.
"Internet time" is a myth.  As just one example, a news story I just
read was about the great success of online bill paying.  This is all
very well and good, but weren't we supposed to have that a long time
ago?  As a matter of fact, didn't Microsoft try to buy up Intuit back
in 1994 largely in order not to be deprived of the possibility of
controlling online payments?  (I have two papers on this subject,
one a short one, "The myth of Internet time" that appeared in the
April 2001 issue of Technology Review, and a longer, more detailed
one, "The slow evolution of electronic publishing," published in
1997, that argue that consumer adoption rates are not noticeably
faster now than in the pre-Internet days.  Both are available on
my home page.)
Andrew Odlyzko
  -----Please note new address-----
  Andrew Odlyzko
  University of Minnesota
  Digital Technology Center
  1200 Washington Avenue South
  Minneapolis, MN 55415
  odlyzko       email
  612-624-9510          voice phone
  612-625-2002          fax

@_date: 2001-12-28 23:50:04
@_author: limit 
@_subject: Re: CFP: PKI research workshop 
both atm debit network and domain name infrastructure care capable of local
caching .... so that timelyness is within seconds to minutes (or a few hrs
as parameter within the needs of the infrastructure). the offline world for
certificates is the analogy of the letters of credit from the days of the
sailing ships. near real time with managed caching (with relying parties
forced to deal with stale credentials manufactored months or years in the
part of the issue in clearing is who has the "liability" at any particular
instance; in the case of debit network caching there are very specific
procedures and processes. Are you suggesting that the certification
industry will assume liability in the case of offline clearing associated
with mars colonilization?
the process tends to be authentication, authorization, and finally
settlement and clearing. sometimes authorization, settlement and clearing
can be batched. if you are really talking about the bank account balance
resides on the earth and the access is from mars .... offline
authentication (clearing really needs to know whether the money actually
exists or not .... regardless of whether or not you are dealing with the
owner of the account) doesn't get you clearing .... and real clearing needs
to know that the money really exists (not just that a person is
authenticated)  ... and if the account balance is on earth and it takes 30
minutes elapsed time to establish it ... then that it what it takes.
More realistic is account balance caching at some near real-time location
on mars ... say within the parameters of the ATM withdrawal limit.
At one point in the PKI evolution there was the proposal that there could
be certificates analogous to the '70s "signing limit" checks .,... an
attempt to create certificates that not only provided authentication
information but also some hypothetical useful approximation to
authorization information (aka not quite reqressing totally to the pre-70s
credit card model). The issue in the "signing limit" checks was when they
found people writing 200 $5000 (limit) checks to get a million. What has
been seen since that time is near real-time purchasing department operation
(including business purchase cards that leverage the credit card system) to
provide real-time aggregation ... as opposed to sinlge event operation. In
the ATM machine withdrawal case, there are typically both single widthrawal
limits as well as daily aggregate withdrawal limits (aka the PKI proposal
for credit cards turned out to be a business process regression to pre-70s
and the PKI proposal for business checks turned out to be a business
process reqression to pre'80s).
Typically what you might have in a ATM withdrawal case .... with foreign
ATM machine (not your local bank) .... is that the owner of the ATM machine
is given a guarentee of funds from your financial institution prior to the
ATM machine releases paper money. Your bank then effectively debits your
account for the equivalent amount of funds. Then typically sometime that
evening, there is a settlement operation where there is funds transfer from
your bank to the financial institution that owns the ATM.
An offline, stale certificate .... only (slightly) addresses the issue of
authentication .... say an identification certificate ... which might not
even provide a binding between you and any particular bank or bank account.
Some sort of binding between you, your bank, and your bank account is
needed .... just for the authentication phase of what you are talking
about. There is still the authorization phase needed so that the owner of
the ATM machine believes that it can receive something (in return for
spitting out paper bills).  That effectively has to find that there are
actually sufficient funds in your account.
So a more realistic scenario would be that there is possibly dual account,
one local and one on earth ... with funds floating back and forth as needed
in evening settlements. If you are on Mars there is some local financial
branch with local record of funds that you have immediately available and
which can authorize that amount of money.
A "local" financial branch implementation and a digital cash implementation
might have a number of similar useability attributes .... aka from the
standpoint of how local funds do you have immediately available .... aka
funds are transferred into you local PDA as digital cash for immediate use
.... or funds are transferred into the local financial institution for
immediate use.
The only case in which the PKI solution is not redundant is in
offline clearing.  But getting your point-of-transaction online
is easier than paying attention to PKI.
I happen to like offline clearing -- it opens up the possibility of
new transaction types and doing transactions in places you couldn't
before.  But the practical issue is, everybody who's interested in
electronic transactions of any kind is also interested in getting
online, and when PKI's were deployed in "developing" areas (south
africa) they got dumped just as soon as the area was developed
enough for communications to support online clearing.
On the principle of people refusing to adopt something until
it relieves pain, maybe we won't see a real PKI deployed until
we need to serve markets where speed-of-light delays make online
clearing impractical.
Mars, for example, is 3 to 22 light-minutes away.  I don't imagine
someone using an ATM on Mars is going to want to wait 12 to 88
minutes for online clearing (more if the protocol is talky or the
bandwidth is busy...).  So a martian colony might be the first
practical application of PKI and/or digital cash, assuming the
colonists want to do business with Earth companies.  But a colony
looks pretty distant right now: we haven't even got an outpost
there yet.
                                          Bear

@_date: 2001-12-27 23:08:43
@_author: a revenue issue 
@_subject: Re: CFP: PKI research workshop 
I would tend to make the statement even stronger.
large, complex legacy systems tend to have slow technology uptake. most of
the certification authorities can be deployed in simple demos w/o impacting
the legacy systems and business process (possibly as a front-end process
that is pealed off before turning things over to the legacy business
if you have legacy business process designed to support millions or
hundreds of millions of customers ... then any change to that system tends
to be significantly more expensive than a stand-alone certification
authority demo for a couple hundred.  The problem has been the cross over
from toy-demo to real production. In general, the legacy infrastructures
and business processes have been put into place for perfectly valid reasons
.... even if somewhat slow to change.
I'm acquanted with one example where a single screen update (as part of a
new function rollout) to a customer call-center supporting tens of million
customer environment cost more than a dozen or so certification authority
demo systems.  The issue was that call center was highly optimized and had
significant investment to scale into handling tens of millions of customers
very, very efficiently. To optimize a single screen & get it integrated
into a real live production environment required some amount of investment.
Such things as customer call-centers (not to mention scallable customer
call centers, scallable administrative and management infrastructure, etc)
for a customer service oriented operation .... could be totally ignored
when testing purely demo operations.
However, even with the cost of modifying a legacy operation .... where
authentication is integrated into the standard every day business processes
.... is significantly cheaper than trying to treat authentication as an
independent service (and build a separate scallable infrastructure that
real customer service orientation involves).
As an aside point ... I've found very few business operations that go
around trying to perform authentication operations purely for the sake and
enjoyment of performing authentication operations. For the most part,
businesses will perform authentication operations (typically viewed as
overhead or cost issue) as part of some real, productive business service
(a revenue issue). I find it difficult to come up with a whole lot of
scenarios where cost overhead (authentication) operations are performed for
no business (revenue) purpose. As mentioned in prior posting
given that authentication is being performed as part of some business
process or function ...  then it is normally trivial to show it is easier
to have authentication (even digital signature authentication) integrated
into such business processes .... and correspondingly easy to show that
certificate-based operations are redundant, superfulous and extraneous
(modulo the issue of toy demos are cheaper than modifying production
business operations).
Naah, it's the monorail/videophone/SST of security.  Looks great at the
Fair, but a bit difficult to turn into a reality outside the fairgrounds.
Peter (who would like to say that observation was original, but it was
       stolen from Scott Guthery).

@_date: 2001-12-27 15:22:07
@_author: certificate 
@_subject: Re: CFP: PKI research workshop 
it isn't that you move it to a central authority .... you move it to an
authority that typically is already established in association with
authorization ... aka in normal business operation, a business relationship
is established that typically consists of creating an account record that
has various privileges associated with that account/entity. For
authentication purposes a public key can be bound to that account and/or
set of privileges. This goes on in the world today .... and would continue
to regardless of whether x.509 identity certificates were issued or not.
given that businesses have to play the registration function for
authorization & privileges ... aka normal procedure doesn't allow somebody
to walk into a random bank and withdraw funds from a random account ...
regardless of who they are ... aka indentity doesn't magically enable a
person to withdraw funds from an arbritrary account ... ability to withdraw
funds typically is a privilege associated with whether or not some entity
is authorized to perform that function for a specific account. As such, the
financial institution has to register lots of information for the account
... also registering a public key is consistent with the existing business
processes, liability, administrative and management infrastructure.
In effect, large numbers of business processes already exist for
registration, administration, and management of authentication information
.... and having a certificate in the loop doesn't eliminate those business
processes (whether or not I had a certificate .... there still would have
to be something registered that some attribute of "me" has authorization to
do certain things). Doing business flow and informatioin management
optimization just demonstrates that given existing business infrastructures
for registration, administration and management which also includes
certificates it is usually trivially possible to demonstrate that the
actual certificates are redundant, superfulous and extraneous ... aka
directly registering the public key and providing direct binding between
the authentication process and the authorization process .... eliminating a
possibly huge number of extraneous and unnecessary business entities and
business processes associated with certificate-based operation.
There doesn't have to be any single central authority in a certificateless
model. There can be all sorts of authorities for all sorts of infomation
.... which could be also hypothesized for a certificate-based certification
and authentication model. However, the certificateless exercise typically
trivially demonstrates that any certificate-based solution duplicates
existing business processes which aren't going to be eliminated. Therefor,
it is then possible to demonstrate business optimization where the
duplicate (certificate) business processes can be eliminated as extraneous,
redundant, and superfulous.
As for the "certificateless" model - all this really does is move the
binding from something you can carry around with you to something that
has to be done by a central authority. It is not clear to me why this is
such a marvellous improvement. Unless you happen to want to own the
central authority, of course, which, unlike certificates and CAs, is far
harder to replicate privately and therefore, presumably, potentially
even more profitable than Verisign's cash cow.
       "There is no limit to what a man can do or how far he can go if he
doesn't mind who gets the credit." - Robert Woodruff

@_date: 2001-12-27 01:26:40
@_author: at a minimum 
@_subject: Re: CFP: PKI research workshop 
for the most part HTTPS SSL is certificate manufactoring (a term we coined
a couple years ago) .... "infrastructure" typically implies the
administrative and management .... which would require (at a minimum) CRLs
for a certificate-based PKI.
the interesting thing about the use of SSL domain name server certificates
is that they supposedly are addressing an integrity issue in the domain
name infrastructure .... i.e. SSL checks that the domain name listed in the
SSL domain name server certificate is the same as the domain name
clicked/typed in for contacting the server. The issue is that the domain
name could be hijacked and instead of going to the "real" IP-address ....
it gets rerouted to a fraudulent IP-address.
however, if you track back the trust infrastructure for the SSL domain name
server certificate .... the process is somebody applies for a SSL domain
name server certifificate with a certification authority. The standard
operating procedure for certification authorities is that they typically
have to verify the information that they are certifying (in this case
domain name ownership) with the authoritative agency for the information
(in this case the domain name infrastructure). Now since there could be an
integrity problem in the domain name infrastructure with respect to domain
name hijacking ... there in fact could be a domain name hijacking prior to
the application for a certificate .... which results in the issuing of a
valid SSL domain name server certificate to the wrong entity.
One of the suggestions for addressing the domain name infrastructure
integrity issue is for public keys to be registered at the same time as the
domain name .... and then further communication with the domain name
infrastructure be with digitally signed messages ... as part of the process
for thwarting domain name hijacking. Note however, since the domain name
infrastructure is the registration authority for the public key as well as
the relying party receiving the signed messages .... certificates are
redundant, superfulous, and extraneous .... even tho it still could be
considered a (certificate-less) "publick key infrastructure" with
significant administrative and management support.
The other interesting aspect is that the existing domain name
infrastructure is set up for (presumably) trusted, (near) real-time
distribution (and updating) of almost any kind of information; not just the
(nearly) trusted binding of domain name to IP-address. Given that public
keys are also registered with domain names at the same time as domain name
and ip-address .... then a trusted domain name infrastructure could be
relied upon to implement a (certificate-less) near real-time "public key
infrastructure" (with full administrative and management functions already
in existance) .... aka the domain name infrastructure could optionally
distribute public key in the same response that it distributes ip-address
...... eliminating the requirement for a certificate-based PKI for trusted
public key distribution.
This is somewhat a catch-22 .... that one of the solutions to addressing a
basic SSL domain name certificate integrity problem (i.e. a CA has a broken
trust chain if there is an integrity issue with the authoritative agency
responsible for the information that a certification authority must
certificate) could also be the solution eliminating any requirement for SSL
domain name certificates.
As an aside, having the public key at the same time as the ip-address for
setting up the base TCP session could also be used to simplify the normal
SSL session setup (since there is no certificate distribution that has to
random additional discussion:
there is also the claim that 99.99999 percent of client authentication in
the internet world today is radius-based; typically userid/password
(although radius supports multiple authentication processes specifiable at
an individual userid/account level). There has been work done on an
authentication process for radius involving digital signature where a
public key is registered in place of a password. This would also represent
a (certificate-less) public key infrastructure with full administrative and
management support.
random raidus discussion
for pointer to radius standards & documents:
& click on "Term (term->RFC
and then click on "RADIUS" in the "Acronym fastpath" section
remote authentication dial in user service (RADIUS )
see also authentication , network access server , network services
3162 2882 2869 2868 2867 2866 2865 2809 2621 2620 2619 2618 2548 2139 2138
2059 2058
also of some interest are the AAA rfcs:
Authentication, Authorization and Accounting
see also accounting , authentication , authorization
3127 2989 2977 2906 2905 2904 2903
HTTPS SSL does not use PKI. SSL at best has this weird system in which
Verisign has somehow managed to charge web sites a toll for the use of
SSL even though for the most part the certificates assure the users of
nothing whatsoever. (If you don't believe me about the assurance
levels, read a Verisign cert practice statement sometime.)
Of course, client side certificates barely even exist, although people
made substantial preparation for them early on in the history of all
of this.
Were it not for historical accident no one would care about "PKI" in
this context.
I get PGP encrypted mail a few times a week. I've never received a
request from any counterparty to set myself up to receive S/MIME. Your
mileage may vary.
When I was still doing security consulting, nearly every firm I worked
for had installed Entrust or something similar -- and none of them
used the systems for anything.
PKI and the Emperor's New Clothes have a bunch in common.
The PKI vendors are, I think, largely surprised by what has
happened. They were expecting things like lots of mutual
authentication using PKI to be in place, and in fact, there's almost
none in use at all.
I think many of the PKI vendors haven't been doing too well -- some of
them that I used to have dealings with barely exist any longer. The
one business that seems to make money is charging a toll for running
an e-commerce site. I wonder who they might be.
Of course, none of this should be surprising in the least. Commerce
and the PKI model have nearly nothing to do with each other. Some of
us were writing about this years ago.
Perry E. Metzger                    perry
NetBSD Development, Support & CDs.

@_date: 2001-12-26 22:13:21
@_author: alchohol 
@_subject: Re: CFP: PKI research workshop 
I doubt if fast/fstc participants would look at the following example as a
prime example .... but there are various "age" authentication services that
are available on the internet today ... basically associated with adult
entertainment ... but would also be applicable to online gambling, various
kinds of online purchases (alchohol), etc.  It doesn't have to identify who
you are ... it just has to be able to answer the question that you are at
least of legal age.
now, it turns out that most of these services use effectively a "loop-hole"
in the current online credit card system to implement their age
authentication operation. There is such a thing in the industry called a
"one dollar auth". Credit card operations typically have financial
transactions authentication and authorized in real time .... but the actual
request for funds transfer is typically submitted in batches ... at end of
day or possibly end of shift. A "one dollar auth" is an authorization
request for a one dollar credit card transaction, typically also with name
& AVS (address verification) data. If the name, account number, and AVS all
verify .... and there are no other outstanding problems .... then the
request comes back approved. The "age" authentication services typically
are registering individuals by requesting the information to perform a "one
dollar auth" .... where there is no subsequent batch submission for actual
funds tranfer.  If the "one dollar auth" is approved, the age
authentication services take the result as indication of legal age .... the
credit card owner needing to have been of legal age to have legally signed
the credit card contract and obtained the credit cad in the first place.
Since no funds transfer actually takes place, nothing shows up on the
consumer's credit card bill. The age verification service is charged a very
nominal transaction fee for the "one dollar auth" (along with the AVS
The age verification service then just packages that one time charge into
the fees that they charge their customers. They effectively maintain a
local "cache" of the answer to the "one dollar auth" transaction.
I would contend that the evidence that such things are going on today ...
is that the current system is "open" in the sense that it has open
standards (like ISO 8583) and lots of entities are making use of it.
In theory, one opportunity for FAST-like offerings is for the financial
industry to get directly into the age authentication service business (in
theory being able to do it at least as well with the data as the 3rd party
players out there today). A x9.59-like transaction can be defined .... but
in place of "dollar amount", there are misc. other types of fields ....
like "legal age". The consumer then digitally signs the transaction and
forwards it to the merchant or server. The server takes the transactions
and ejects it into the appropriate authentication network (very much like
credit card transactions are done today) and gets back a "YES/NO" answerr
(again very much like credit card transactions happen today) .... the only
difference is instead of asking for consumer funds approval, the merchant
is asking question about legal age. Identity information isn't being
divulged ... not even date-of-birth ... which could raise a serious
identity fraud question .... just answerring YES/NO to the legal age
question. It could look like an X9.59 transaction, taste like an X9.59
transaction ... but instead of having funds involved, it has legal age
It effectively creates an "open" online, authentication infrastructure ...
requiring consumer to digital sign the transaction .... and a recognized
certification authority providing real time, non-privacy invasive, answers.
It otherwise has all the elements of an open public key infrastructure
(registration authorities, certification authorities, consumers, relying
parties, etc) w/o any certificates. In that sense it is an online PKI
paradigm .... rather than the certificate-based offline PKI paradigm (which
emulates the pre-70s offline credit card infrastructure).
in addition to the x9.59 for all electronic payment transactions ... it is
possible to extend online authentication where the institution possibly
isn't also responsible for the authorization (and/or access privileges)....
things like FAST projects in FSTC:

@_date: 2001-12-26 21:36:52
@_author: and/or access privileges 
@_subject: Re: CFP: PKI research workshop 
again, why would the financial industry be interested in regressing (at
least) 30 years to a certificate-based offline model?
they do authentication of transactions that they also need to do
authorization for ....  in a model that has prior business relationship
between the parties. certificate-based PKI were targeted at offline email
genre of the early '80s and analogous to the offline credit-card model
in addition to the x9.59 for all electronic payment transactions ... it is
possible to extend online authentication where the institution possibly
isn't also responsible for the authorization (and/or access privileges)....
things like FAST projects in FSTC:
In fact, that may be exactly it.  PKI, as espoused by vendors,
once established, will become an indispensable monopoly, like
AT&T before the breakup. Investors love the fantasy of buying
a kajillion shares for cheap today and then having them be
shares in an indispensable monopoly next year, so they are
inclined to believe.
The problem is that none of the vendors are offering anything
that someone who has significant volume (like a financial-services
company might) cannot provide for themselves.  The FS companies
can easily wait to adopt, because the margins offered by PKI are
fairly small and the initial investment required is fairly large.
Perhaps the margins will remain too small until royalty payments
can be eliminated entirely (until any patents expire) and the
FS companies can roll their own.  Whether or not the margins
are too small, The FS companies can wait that long easily.
But the PKI vendor cannot wait.  S/he will be out of business
in three or four years if nobody adopts.  The patents will be
for sale then much cheaper than the royalty payments s/he is
offering, and the FS negotiator across the table knows it.  The
PKI vendor therefore is going to get the worst end of the deal
every time s/he goes to financial services vendors, because s/he
is not dealing from a position of strength, and had best learn
the harsh lesson sooner rather than later.
A PKI will happen, eventually, but nobody is going to get into
a position where the financial-services sector depends on them
and has to pay them.  That's as fundamental in business as the
second law of thermodynamics in physics, and chasing the dream
of becoming an indispensable monopoly to the financial services
sector promises to be as frustrating to the seekers as the quest
for a perpetual motion device.
                                          Bear

@_date: 2001-12-26 20:35:14
@_author: x9.59 
@_subject: Re: CFP: PKI research workshop 
possibly not the ATM you were thinking of .... certificate-less digital
signature authentication by NACHA/ATM/debit networks
specific web page:
financial industry standard for digital signature authenticated electronic
payment transactions for all payments (x9.59):
misc discussions regarding privacy and certificate-less digital signature
As I never tire of saying, "PKI is the ATM of security."
Meaning that has a certain niche relevance, but is claimed by
proponents to be the answer to every need, and is the current magic
word for shaking the money tree.

@_date: 2001-12-26 20:03:19
@_author: basically containing an account number and a public key 
@_subject: Re: CFP: PKI research workshop 
note that the certificate-based PKI is an offline model .... it is the
credit card model pre-1970. the certificate-based PKI tends to bear a lot
of other resumblance to pre-1970 offline credit-card model .... the CRLs
invention is very similar to the paper booklets that were mailed out to
merchants every month of invalid credit card numbers (the credit-card
industry however had a significant advantage having a very strong
relying-party registration function .... so that there was high probability
of relying-parties getting the paper booklets of invalid numbers).
in the '70s, the credit card industry switched from an offline
infrastructures (aka similar to the certificate-based PKIs which were
effectively developed to address the offline email infrastructure of the
early 1980s) to an online infrastructure ... where every transaction was
executed online. A certificate-based PKI for credit cards would be like
regressing 30 years to the offline infrastructure (although using more
convoluted and complex technology). The issue is why would the payment card
industry want to regress 30 years to an offline model with
certificate-based PKI?
The financial industry has passed an online payment definition that does
use digital signature technology w/o all the complexity and short-comings
of a certificate-based PKI  (that would set-back/regress the infrastructure
30+ years to the offline model) .... which is X9.59.
Baiscally X9.59 defines a retail payment object that is valid for ALL
electronic online financial transactions (internet, non-internet,
point-of-sale, debit, credit, ACH, etc) which basically requires a digital
signature and does not require a certificate-based PKI.  The simplest
analogy is that digital signature technology upgrades the PIN-based
infrastructure found in current debit transactions and expands it to all
electronic financial transactions.
There have been some financial pilots using certificate-based PKI
operations .... but in all cases it is relatively trivial to show that the
certificate is redundant, superfulous and extraneous in an online world.
The certificates were effectively relying-party-only certificates
(basically containing an account number and a public key) .... in part to
meet liability and privacy requirements. Since only an account number was
used and the transactions &/or other operations were all online ... they
all referenced the account in order to execute the requested operation. It
is trivial to show that given online operation executioin (including things
like "logging in" for vaious kinds of things related to online banking
and/or other financial or securities industry transactions) .... that is
superfulous to have the certificate.
The certificate makes sense in an offline environment where there is no
prior business relationship between the entities. Given online situations
involving parties with prior relationships, certificates make no sense.
misc. x9.59 references:
misc certificate-less digital signature references (including pointers to
the NACHA/debit network implementation ... and a private key hardware token
description allowing the same private/public key to be used in an
arbritrary large number of different & public operations):
random client digital signature authentication refs:
misc. discussion of certificate-based SSL domain name operation:
Yep.  So far, that's true.  Financial stuff is the only killer app
in sight for a PKI, and the financial services sector is conservative
and heavily regulated.  There is a substantial barrier to entry: just
try to imagine running off a few thousand PKI-backed credit cards and
going into business competing against mastercard/visa/amex.  Vendor
acceptance is slow and the regulatory hurdles are high.
Odds are, however, that each and every one of them is going to want
their own PKI -- where P stands for Private, or Proprietary, rather
than Public.  A Public Key Infrastructure happens when the chaotic
situation which that brings about gets consolidated and standardized,
so don't look for that for at least a decade.  Basically we have no
chance of getting a Public Key Infrastructure in place right now
because we don't have enough different Private Key Infrastructures
in place for it to have started to hurt yet.  People won't go for
the PKI until they are in some kind of pain that it relieves. And
if financial services businesses are involved, they will do it in
such a way that no PKI vendor ever makes a profit they could possibly
have made themselves.  Look for them to be buying regulations that say
PKI is part of financial services and can only be provided by licensed
financial services corporations sometime in the next few years.
Like I said, don't get too discouraged -- these things happen slowly
and it's very much a matter of stages of development.  People don't
do things until the pain of not doing them gets worse than the pain
of doing them.  Public Key comes about when Private Keys have been
common for several years and their multiplicity causes pain.  That
in itself will take several years after the Private Key structures
are fully adopted. The Private Key structures get adopted several
years after the profit margins, split between consumers, vendors, and
financial institutions, each overcome the pain of changing infrastructure.
That will take several years after the initial offering.  The initial
offerings are happening now in very restricted markets, but don't
look for it to happen in domestic consumer markets until the results
of the restricted-market offerings are several years old and the
technology involved hasn't changed AT ALL for several years. They
are looking for a technology that's been in use long enough to
establish a baseline and get results that look stable and repeatable.
That's when financial services companies will begin to take them
seriously enough to consider that the pain of deploying new
infrastructure may overcome the painof absorbing losses due to
These are just network effects: PKI will trickle through at the end
as surely as water runs downhill, because it's a better solution.
It's just going to take a decade or two, or maybe four or five
decades if there's a substantial monopoly somewhere in the industry.
                                                    Bear

@_date: 2002-01-13 18:04:40
@_author: unknown_name 
@_subject: Re: CFP: PKI research workshop 
to be fair ... most commercial CA's have to verify with the domain name
infrastructure as to the owner of the domain name ... before issuing a SSL
domain name server cert. Note however, one of the justifications for having
SSL domain name server cert is because of concerns with regard to domain
name infrastructure integrity issues and things like domain name
hikjacking. Note however, that if the domain name infrastructure has had a
domain name hijack before the SSL server cert is applied for ... when the
CA goes to the domain name infrastructure to verify the domain name
ownership ... it will verify and a SSL server cert can be issued to the
wrong entity (aka the issuing of a SSL server cert is subject to some of
the same integrity exposures as concerns that gave rise to having SSL
server certs in the first place).
Furthermore, some of the proposals to address domain name infrastructure
integrity issues so that CAs can trust their verification as to domain name
ownership ... also eliminates justifications for needing SSL server certs
random refs:
To be fair,  most commercial CA's require evidence of "right to use"
a FQDN in an SSL server cert.  But your point is apt.

@_date: 2002-01-04 17:47:36
@_author: the Committee 
@_subject: Re: CFP: PKI research workshop 
one of the largest financial networks ...  slightly different kind
again financial ... discussion of additional kinds of risks/threats
Sound Practices for the Management and Supervision of Operational Risk
Intro ...
The purpose of this paper, prepared by the Risk Management Group of the
Basel Committee on Banking Supervision (the Committee), is to further
the Committee's dialogue with the industry on the development of Sound
Practices for the Management and Supervision of Operational
Risk. Comments on the issues outlined in this paper would be welcome,
and should be submitted to relevant national supervisory authorities
and central banks and may also be sent to the Secretariat of the Basel
Committee on Banking Supervision at the Bank for International
Settlements, CH-4002 Basel, Switzerland by 31 March 2002. Comments may
be submitted via e-mail: BCBS.capital or by fax: + 41 61 280
9100. Comments on this paper will not be posted on the BIS website.
to which I would add:
3. Cryptography, and therefore PKI, is meaningless unless you first
define a threat model.  In all the messages with this Subject, I've
only see one person even mention "threat model".  Think about the
varying threat models, and the type of cryptography one would propose
to address them.  Even the most common instance of encryption,
encrypted web forms for hiding credit card numbers, suffers from
addressing a limited threat model.  There's a hell of a lot of known
plaintext there.

@_date: 2002-01-02 16:56:09
@_author: 1 
@_subject: Re: CFP: PKI research workshop 
aka ... lots of people seem to equate privacy with personal privacy (as
well as legislative specification) ... while confidentiality has more of a
non-personal connotation
there seems to be 3-4 postings from yesterday that are still lost in the
ether ... they are recorded at
(1) The assurance that information is not disclosed to inappropriate
entities or processes. (2) The property that information is not made
available or disclosed to unauthorized entities. (3) The prevention of the
unauthorized disclosure of information. (4) The concept of holding
sensitive data in confidence, limited to an appropriate set of individuals
or organizations. [AJP] Assurance that information is not disclosed to
inappropriate entities or processes. [FCv1] The concept of holding
sensitive data in confidence, limited to an appropriate set of individuals
or organizations. [NCSC/TG004] The prevention of the unauthorized
disclosure of information. [ITSEC][NIAP] The principle that keeps
information from being disclosed to anyone not authorized to access it.
Synonymous with secrecy. [AFSEC] The property that information is not made
available or disclosed to unauthorized entities. [JTC1/SC27/N734] The
property that information is not made available or disclosed to
unauthorized individuals, entities, or processes. [TNI] The property that
sensitive information is not disclosed to unauthorized individuals,
entities or processes. [FIPS140] (see also assurance, data confidentiality,
data confidentiality service, privacy, privacy programs, security)
(1) The ability of an individual or organization to control the collection,
storage, sharing, and dissemination of personal and organizational
information. (2) The right to insist on adequate security of, and to define
authorized users of, information or systems. Note: The concept of privacy
cannot be very precise, and its use should be avoided in specifications
except as a means to require security, because privacy relates to 'rights'
that depend on legislation. [AJP] (1) the ability of an individual or
organization to control the collection, storage, sharing, and dissemination
of personal and organizational information. (2) The right to insist on
adequate security of, and to define authorized users of, information or
systems. Note: The concept of privacy cannot be very precise and its use
should be avoided in specifications except as a means to require security,
because privacy relates to 'rights' that depend on legislation. [TNI] (I)
The right of an entity (normally a person), acting in its own behalf, to
determine the degree to which it will interact with its environment,
including the degree to which the entity is willing to share information
about itself with others. (O) 'The right of individuals to control or
influence what information related to them may be collected and stored and
by whom and to whom that information may be disclosed.' (D) ISDs SHOULD NOT
use this term as a synonym for 'data confidentiality' or 'data
confidentiality service', which are different concepts. Privacy is a reason
for security rather than a kind of security. For example, a system that
stores personal data needs to protect the data to prevent harm,
embarrassment, inconvenience, or unfairness to any person about whom data
is maintained, and to protect the person's privacy. For that reason, the
system may need to provide data confidentiality service. [RFC2828] (see
also confidentiality, private communication technology, private key,
security, quality of protection) (includes Privacy Enhanced Mail, data
privacy, pretty good privacy, privacy programs, privacy, authentication,
identification, integrity, non-repudiation, privacy, authentication,
identification, non-repudiation, virtual private network)
well PAIN is out of some standards organization (as is 3-factor
authentication) .... i agree that privacy and confidentiality is sometimes
thot of as different .... but others argue that it reduces to the
effectively the same requirements ... even tho different people have
different connotations with the two terms.
i had fumble fingered 3-4 URLs yesterday .... and the posting to correct
them seems to have gotten suspended for some time in the ether .... note
however the url for the security taxonomy and glossary had been typed
correctly in a posting made earlier in the day ... i.e.

@_date: 2002-01-02 16:18:37
@_author: security.htm 
@_subject: Re: CFP: PKI research workshop 
well PAIN is out of some standards organization (as is 3-factor
authentication) .... i agree that privacy and confidentiality is sometimes
thot of as different .... but others argue that it reduces to the
effectively the same requirements ... even tho different people have
different connotations with the two terms.
i had fumble fingered 3-4 URLs yesterday .... and the posting to correct
them seems to have gotten suspended for some time in the ether .... note
however the url for the security taxonomy and glossary had been typed
correctly in a posting made earlier in the day ... i.e.
I think you should specify "confidentiality" as another issue to be
addressed.  Perhaps you include confidentiality in your "privacy" or
"security" subsections, but I've found that many people think (and
mean) different things when they use these two terms.  For example, is
privacy necessarily privacy of communicated data from eavesdroppers,
or is it the privacy of personal information (perhaps the privacy of
the authentication information) so an eavesdropper does not know who
is communicating?
Unfortunately your garlic.com URL (security.htm) does not work and
returns an HTTP 404 error.

@_date: 2002-01-01 18:50:55
@_author: PAIIN 
@_subject: Re: CFP: PKI research workshop 
sometimes the "principles" of security are referred to as PAIN or sometims
and click on PAIN & PAIIN in the acronym section of the glossary.
Doing a threat model ... would include not only end-to-end issues .... but
what aspects of PAIIN are being addressed.
privacy, authentication, identification, integrity, non-repudiation (PAIIN)
(see also authentication, identification, integrity, non-repudiation,
privacy, security)
an aspect of security can be integrity and and aspect of integrity can be
dependability .... leading to things like:
which is then related back to my posting on sunday (with regard to
 CFP: PKI research workshop
to which I would add:
3. Cryptography, and therefore PKI, is meaningless unless you first
define a threat model.  In all the messages with this Subject, I've
only see one person even mention "threat model".  Think about the
varying threat models, and the type of cryptography one would propose
to address them.  Even the most common instance of encryption,
encrypted web forms for hiding credit card numbers, suffers from
addressing a limited threat model.  There's a hell of a lot of known
plaintext there.

@_date: 2002-01-01 17:59:28
@_author: s 
@_subject: Re: CFP: PKI research workshop 
somewhat as an aside ... the requirement(s) given the X9A10 financial
standards working group for the development of the X9.59 standard was
* to preserve the integrity of the financial infrastructure for all retial
electronic payments without the use of encryption
"ALL" didn't just mean internet or just mean credit .... it met "ALL" ...
all environments ... all types of transactions, etc.
"Without the use of encryption" didn't mean that  information hiding wasn't
precluded (say for privacy reasons) but weren't required to preserve the
integrity of the financial infrastructure (aka that complete clear-text
could be made available and it wasn't possible to do a fraudulent
transaction based on everybody in the world potentially having the
cleartext of that payment transaction).
Implied in the requirement was that it had to also be extremely lightweight
in order to be applicable to some of the existing electronic payments
environments. Again "ALL" met "ALL" ... including a large number of
existing electronic environments. Frequently "from scratch" protocol
definitions are faster to do if you don't have to take into account any
existing infrastructure (and/or only addressing an extremely small subset
of the total end-to-end problem)..
To meet the requirements we eventually settled on a very lightweight,
end-to-end authentication definition (strong authentication of every
transaction had to flow completely through from the consumer all the way
through to the consumer's financial infrastructure).
x9.59 references:
to which I would add:
3. Cryptography, and therefore PKI, is meaningless unless you first
define a threat model.  In all the messages with this Subject, I've
only see one person even mention "threat model".  Think about the
varying threat models, and the type of cryptography one would propose
to address them.  Even the most common instance of encryption,
encrypted web forms for hiding credit card numbers, suffers from
addressing a limited threat model.  There's a hell of a lot of known
plaintext there.

@_date: 2002-01-07 15:10:25
@_author: unknown_name 
@_subject: Re: Hackers Targeting Home Computers 
lots of ISPs provide no-server, dial-up service .... they could start with
blocking HTTP & other server-type requests going to such ip-address/modem
subpools (i.e. customers that are getting dynamic ip address on dial-up
lines and have specific service agreements that preclude "server-type"
operation on those dial-up service).
some related discussion in various news groups:
 Internet like city w/o traffic
rules, traffic signs, traffic lights and traffic enforcement
 Internet like city w/o traffic
rules, traffic signs, traffic lights  and traffic enforcement
 Internet like city w/o traffic
rules, traffic signs, traffic lights and traffic enforcement
 Internet like city w/o traffic
rules, traffic signs, traffic lights and traffic enforcement
 Internet like city w/o traffic
rules, traffic signs, traffic lights   and traffic enforcement
 FreeBSD more secure than Linux
 Q: Buffer overflow
 Younger recruits versus
experienced veterans  ( was Re: The demise  of compa
 Buffer overflow
 ICMP Time Exceeded
 Buffer overflow
It surprises me that providers like Earthlink & GTE (I have one DSL on
each) aren't taking measures to filter out virus traffic from infected
systems.  It seems a simple enough task to me.
It seems to me that the biggest cause of the problems are ignorance and
lack of concern as the article suggests.  So rather than complain and rant,
I've setup a non-technical alert list for my friends and family to keep
them informed and safe.
I try to keep the list fun and easy to read.  Its taken a great deal of
time and explaining, but slowly more and more of them are beginning to see
the bigger picture.
My favorite scenario to lay out for my friends is simple and
effective.  Lets say that a hacker gains control of your computer and uses
it to attack another site/system.  Lets say that site is a Fortune 500
company or a military or government site.  Even if you don't get into
trouble, the FBI could still show up on your door step and take your
computer away for analysis.  No more email or web for you.  Oh, and they'll
probably need to sift through your phone records to see if the hacker
dialed out from your computer.  Kiss your privacy goodbye.

@_date: 2002-01-27 22:21:18
@_author: fwd 
@_subject: Re: Looking back ten years: Another Cypherpunks failure (fwd) 
there is another issue here in the corporate world. The issue is
availability of corporate assets. One particular study that showed it up
had to do with budiness that had no backup of critical disk and that disk
had a failure .... 50 percent of such occurances resulted in the company
declaring bankruptcy within 30 days.
The whole migration of critical business assets out of the enterprise
glasshouse environment to various corporate desktops has highlighted the
fact that more or more critical corporate assets are represented by that
data (simple example can be customer invoices & billing data).
Enterprises that are doing backup of critical data that is shipped off-site
as part of disaster/recovery scenarios are starting to find that such
backups require encryption (if not the original data stored on disk). The
quandrary then is the possible loss of the capability of decrypting the
data when necessary (aka replicated keying material stored in multiple safe
random ref:
 Secure File System
The Secure File System (SFS) is a joint project between the University of
Minnesota and StorageTek which aims to provide an easy to use cryptographic
file system. It allows you to store your files securely on remote sites
using normal networking protocols (FTP, HTTP, NFS, etc.). You can store
your files anywhere without worry of unauthorized access. SFS allows
distributed control of protected information through the use of a group
server which is responsible for all file access controls.
SFS currently uses smartcards, through MUSCLE software, for authentication
and signature purposes. We are currently using Linux with a patched version
of UFO, a user-space program that allows us to treat FTP, HTTP, etc. sites
as local filesystems. This patched version allows us to catch any file
requests and send them to another program to determine if they need to be
de/ encrypted. A diagram of the overall operation is available as a PDF
file or GIF. Note: Entire project source code will be available including
cryptographic routines. Our revised paper which was submitted to the USENIX
Security Symposium is also available in ps and pdf formats.
GET  is disk encryption.  Yes, it sounds so simple, but it is a
Great Tabboo, and this time there are no excuses.  None.  You don't
need any network effects.  Regulators in the US have little they can
do about it.  There are about half a dozen great Open Source OSes to
work on.  And yet there is nothing.

@_date: 2002-02-24 17:28:16
@_author: i.e. written off 
@_subject: Re: Blair accidently sells the roads (was Re: BBC article: 
note that it didn't eliminate the economies of scale of network operation
.... there is still massive investment required in things like fiber. some
amount of the current pricing could possibly be an "overbuilt" &
"over-invested" infrastructure ... some number of operations going bankrupt
... and then some amount of the infrastructure available on a pricing
structure that doesn't require full ROI recovery of the original investment
(i.e. written off).
the "electronics" revolution moved some amount of the economies of scale
into multi-billion dollar fabrication plants that have to be written off
every 3-5 years and new ones built at possible 2-3 times the cost of the
previous generation.  In some sense, the massive investment in the enabling
infrastructure has led to fewer, much more massive operations that are
required to support the massive cost reductions in other areas.
also, much of this is disruptive technology ... either because of
technology itself and/or the second order effects of infrastructure cost
reduction ... which would tend to have a distabelizing effects on
operations that had reached some sort of stabilized equilibrium under
earlier cost/price paradigms. One question might be "is the choatic nature
of the players in hese market segments a permanent feature or a temporary
transition phase as infrastructure attempts to re-establish some
equilibrium after significant disruptive influence"?
past ref:
 dbts: More on law vs economics
The resulting exponential drop in the price of switching completely
inverted the economies of scale of network operation, changing its
very structure from an increasingly larger, more unified hierarchy
with exactly one fixed-price circuit-switched route from any two
nodes to a massively geodesic network with a combinatorical number of
routes between any two nodes, each route with its own possible
auction price depending on latency, noise, and lots of other factors.
The result was a dramatic reduction in transaction cost, price
discovery, market entry, and of course firm size, and ultimately a
dramatic increase in the number of phone companies, even vertically
integrated ones, and we haven't even started cash-settlement of
network bandwidth yet. (The paradox, of course, is that every
"information worker" who sits in front of a microcomputer to work
these days, sizeably more than half the female population -- even a
MacDonald's cashier -- is doing exactly what a
turn-of-the-20th-century telephone operator does, reprocessing and
routing information from one part of the network to another.)

@_date: 2002-06-10 02:58:32
@_author: capital 
@_subject: Re:  PKI: Only Mostly Dead 
I think there is even less "I" than most people suspect. I've recently
taken to some manual sampling of  SSL domain name server certificates ...
and finding certificates that have expired ... but being accepted by
several browsers that i've tested with (no complaints or fault
there was thread in another forum where I observed that back when
originally working on this payment/ecommerce thing for this small
client/server startup that had invented these things called SSL & HTTPS ...
my wife and I had to go around to various certificate manufactures with
regard to some due diligence activity. I think w/o exception that they all
made some comment about the "PK" being technical ... and the "I" being
service ... and providing "service" is an extremely hard thing to do (and
they hadn't anticipated how really hard it is).
some past ssl domain name certificate threads:
As i've observed previously there are a number of ways that the technical
stuff for "PK" can be done w/o it having to equate to (capital) PKI ...
some recent threads on this subject:
 some certification &
authentication landscape summary from recent threads
 some certification &
authentication landscape summary from recent threads
 some certification &
authentication landscape summary from recent threads
 some certification &
authentication landscape summary from recent threads
 IBM alternative to PKI?
 IBM alternative to PKI?
 IBM alternative to PKI?
 IBM alternative to PKI?
 IBM alternative to PKI?
 Proxy PKI. Was: IBM alternative
to PKI?
 Proxy PKI. Was: IBM alternative
to PKI?
 Proxy PKI. Was: IBM alternative
to PKI?
 Proxy PKI
 Proxy PKI
 Proposal: A replacement for 3D
 ALARMED ... Only Mostly Dead ...
RIP PKI
 ALARMED ... Only Mostly Dead ...
RIP PKI
 ALARMED ... Only Mostly Dead ...
RIP PKI
 ALARMED ... Only Mostly Dead ...
RIP PKI .. addenda
 ALARMED ... Only Mostly Dead ...
RIP PKI .. addenda II
 ALARMED ... Only Mostly Dead ...
RIP PKI
 ALARMED ... Only Mostly Dead ...
RIP PKI ... part II
 ALARMED ... Only Mostly Dead ...
RIP PKI .. addenda
 ALARMED ... Only Mostly Dead ...
RIP PKI ... part II
 ALARMED ... Only Mostly Dead ...
RIP PKI ... part III
Thankyou Nobody.  You should have found the e-gold in your acount by now :
WHICH IS
  "Opinion is divided on the subject" -- Captain Rum, Blackadder, "Potato".
The use with SSL is what Anne|Lynn Wheeler refer to as "certificate
manufacturing" (marvellous term).  You send the CA (and lets face it,
going to be Verisign) your name and credit card number, and get back a
It's just an expensive way of doing authenticated DNS lookups with a ttl of
year.  Plenty of PK, precious little I.
You can play with semantics here and claim the exact opposite.  All of the
cases you've cited are actually examples of global distinguisher + locally
unique name.  For example the value 1234567890 taken in isolation could be
anything from my ICQ number to my shoe size in kilo-angstroms, but if you
it as the pair { ,  } then it makes
(disclaimer: I have no idea whether that's either a valid ICQ number or my
size in kilo-angstroms).
(This is very much a philosophical issue.  Someone on ietf-pkix a year or
 back tried to claim that X.500 DNs must be a Good Thing because RFC 822
 address and DNS names and whatnot are hierarchical like DNs and therefore
 can't be bad.  I would suspect that most people view them as just dumb
 strings rather than a hierarchically structured set of attributes like a
 The debate sort of fizzled out when no-one could agree on a particular
I think the unified view is that what you need for a cert is a global
distinguisher and a locally meaningful name, rather than some complex
hierarchical thing which tries to be universally meaningful.  Frequently
distinguisher is implied (eg with DNS names, email addresses, "for use
XYZ Copy only", etc), and the definition of "local" really means "local to
domain specified in the global distinguisher".  I'm not sure whether I can
easily fit all that into the paper without getting too philosophical - it
really meant as a guide for users of PKI technology.

@_date: 2002-06-10 02:58:32
@_author: capital 
@_subject: Re:  PKI: Only Mostly Dead 
I think there is even less "I" than most people suspect. I've recently
taken to some manual sampling of  SSL domain name server certificates ...
and finding certificates that have expired ... but being accepted by
several browsers that i've tested with (no complaints or fault
there was thread in another forum where I observed that back when
originally working on this payment/ecommerce thing for this small
client/server startup that had invented these things called SSL & HTTPS ...
my wife and I had to go around to various certificate manufactures with
regard to some due diligence activity. I think w/o exception that they all
made some comment about the "PK" being technical ... and the "I" being
service ... and providing "service" is an extremely hard thing to do (and
they hadn't anticipated how really hard it is).
some past ssl domain name certificate threads:
As i've observed previously there are a number of ways that the technical
stuff for "PK" can be done w/o it having to equate to (capital) PKI ...
some recent threads on this subject:
 some certification &
authentication landscape summary from recent threads
 some certification &
authentication landscape summary from recent threads
 some certification &
authentication landscape summary from recent threads
 some certification &
authentication landscape summary from recent threads
 IBM alternative to PKI?
 IBM alternative to PKI?
 IBM alternative to PKI?
 IBM alternative to PKI?
 IBM alternative to PKI?
 Proxy PKI. Was: IBM alternative
to PKI?
 Proxy PKI. Was: IBM alternative
to PKI?
 Proxy PKI. Was: IBM alternative
to PKI?
 Proxy PKI
 Proxy PKI
 Proposal: A replacement for 3D
 ALARMED ... Only Mostly Dead ...
RIP PKI
 ALARMED ... Only Mostly Dead ...
RIP PKI
 ALARMED ... Only Mostly Dead ...
RIP PKI
 ALARMED ... Only Mostly Dead ...
RIP PKI .. addenda
 ALARMED ... Only Mostly Dead ...
RIP PKI .. addenda II
 ALARMED ... Only Mostly Dead ...
RIP PKI
 ALARMED ... Only Mostly Dead ...
RIP PKI ... part II
 ALARMED ... Only Mostly Dead ...
RIP PKI .. addenda
 ALARMED ... Only Mostly Dead ...
RIP PKI ... part II
 ALARMED ... Only Mostly Dead ...
RIP PKI ... part III
Thankyou Nobody.  You should have found the e-gold in your acount by now :
WHICH IS
  "Opinion is divided on the subject" -- Captain Rum, Blackadder, "Potato".
The use with SSL is what Anne|Lynn Wheeler refer to as "certificate
manufacturing" (marvellous term).  You send the CA (and lets face it,
going to be Verisign) your name and credit card number, and get back a
It's just an expensive way of doing authenticated DNS lookups with a ttl of
year.  Plenty of PK, precious little I.
You can play with semantics here and claim the exact opposite.  All of the
cases you've cited are actually examples of global distinguisher + locally
unique name.  For example the value 1234567890 taken in isolation could be
anything from my ICQ number to my shoe size in kilo-angstroms, but if you
it as the pair { ,  } then it makes
(disclaimer: I have no idea whether that's either a valid ICQ number or my
size in kilo-angstroms).
(This is very much a philosophical issue.  Someone on ietf-pkix a year or
 back tried to claim that X.500 DNs must be a Good Thing because RFC 822
 address and DNS names and whatnot are hierarchical like DNs and therefore
 can't be bad.  I would suspect that most people view them as just dumb
 strings rather than a hierarchically structured set of attributes like a
 The debate sort of fizzled out when no-one could agree on a particular
I think the unified view is that what you need for a cert is a global
distinguisher and a locally meaningful name, rather than some complex
hierarchical thing which tries to be universally meaningful.  Frequently
distinguisher is implied (eg with DNS names, email addresses, "for use
XYZ Copy only", etc), and the definition of "local" really means "local to
domain specified in the global distinguisher".  I'm not sure whether I can
easily fit all that into the paper without getting too philosophical - it
really meant as a guide for users of PKI technology.

@_date: 2002-06-30 19:49:32
@_author: TCPA 
@_subject: Re: maximize best case, worst case, or average case? (TCPA) 
"security modules" are also inside the swipe & pin-entry boxes that you see
at check-out counters.
effectively both smartcards and dongles are forms of hardware tokens ....
the issue would be whether a smartcard form factor might be utilized in a
copy protection scheme similar to TCPA paradigm .... a single hardware chip
that you register for all you applications .... or in the dongle paradigm
.... you get a different smartcard for each application (with the downside
of the floppy copy protection scenario where a user with a half dozen
active copy protected applications all wanted "their" smartcard crammed
into the same smartcard reader simultaneously).
many of the current chipcards .... i believe are used in the magnetic
stripe "swipe" mode for authenticating specific transactions ....  most of
the rest are used for password substitute at login type events. Many of the
chipcards following the straight payment card model result in end-user
having large number of different institutional tokens (similar to the
floppy copy protect paradigm).  Following the institutional-specific and/or
application-specific token paradigm starts to become difficult to manage as
the number of tokens increase and the probability that multiple are
required simultaneously increases.
That eventually leads into some sort of person-centric or device-centric
paradigm .... not so much an issue of the form factor  (floppy, chipcard,
dongle, etc) .... but an issue of whether there are potentially large
numbers of institutional/application specific objects or small numbers of
person/device specific objects.
So a simple issue is the trade-off between the institutional/application
specific objects .... which seem to have some amount of acceptance (payment
cards, chip cards, various "dongle" forms, etc) but in many instances can
scale poorly ... especially if  multiple different such objects have to be
available concurrently .... vis-a-vis switching to a person/device specific
object paradigm (chipcard, dongles, etc, potentially exactly same
formfactor but different paradigm)
I think dongles (and non-copyable floppies) have been around since the
80s at least...maybe the 70s.  Tamper-resistant CPU modules have been
since the ATM network, I believe, in the form of PIN processors stored
inside safes)
The fundamental difference between a "dongle" and a full "trusted module"
containing the critical application code is that with a dongle, you can
just patch the application to skip over the checks (although they can be
repeated, and relatively arcane).
If the whole application, or at least the non-cloneable parts of the
application, exist in a sealed module, the rest of the application can't
be patched to just skip over this code.
Another option for this is a client server or oracle model where the really
sensitive pieces (say, a magic algorithm for finding oil from GIS data,
or a good natural language processor) are stored on vendor-controlled
hardware centrally located, with only the UI executing on the end user's
What I'd really like is a design which accomplishes the "good" parts of
ensuring that when code claims to be executing in a certain form, it really
and providing a way to guarantee this remotely -- without making it easy
to implement restrictions on content copying.  It would be nice to have the
good parts of TCPA, and given the resistance to DRM, if security and TCPA
have their fates bound, they'll probably both die an extended and painful
I suppose the real difference between a crypto-specific module and a
purpose module is how much of the UI is within the trusted platform
If the module is only used for handling cryptographic keys, as an addition
an insecure general purpose CPU, with no user I/O, it seems unlikely to be
useful for DRM.  If the entire machine is inside the envelope, it seems
obviously useful for DRM, and DRM would likely be the dominant application.
If only a limited user IO is included in the envelope, sufficient for
user authentication and keying, and to allow the user to load
initially-trusted code onto the general purpose CPU, but where the user
can fully use whatever general purpose code on the general purpose CPU,
even uncertified code, with the certified module, it's not really useful
for DRM, but still useful for the non-DRM security applications which are
the alleged purpose behind TCPA.
(given that text piracy doesn't seem to be a serious commercial concern,
simply keeping video and audio playback and network communications outside
the TCPA envelope entirely is good enough, in practice...this way, both
authentication and keying can be done in text mode, and document
distribution control, privacy of records, etc. can be accomplished,
there is ALSO the ability to do arbitrary text processing and computing
outside the trusted envelope, .)
If it's the user's own data being protected, you don't need to worry about
the user intentionally circumventing the protections.  Any design which
removes control from the 'superuser' of the machine is fundamentally about
protecting someone other than the user.
This, I think, is the difference between TCPA and smartcards.  Notice
which one has in its short lifetime attracted far more enmity :)
Quoting lynn.wheeler :
Ryan Lackey [RL7618 RL5931-RIPE]        ryan
CTO and Co-founder, HavenCo Ltd.        +44 7970 633 277
the free world just milliseconds away   OpenPGP 4096: B8B8 3D95 F940 9760 C64B  DE90 07AD BE07 D2E0 301F

@_date: 2002-06-30 19:49:32
@_author: TCPA 
@_subject: Re: maximize best case, worst case, or average case? (TCPA) 
"security modules" are also inside the swipe & pin-entry boxes that you see
at check-out counters.
effectively both smartcards and dongles are forms of hardware tokens ....
the issue would be whether a smartcard form factor might be utilized in a
copy protection scheme similar to TCPA paradigm .... a single hardware chip
that you register for all you applications .... or in the dongle paradigm
.... you get a different smartcard for each application (with the downside
of the floppy copy protection scenario where a user with a half dozen
active copy protected applications all wanted "their" smartcard crammed
into the same smartcard reader simultaneously).
many of the current chipcards .... i believe are used in the magnetic
stripe "swipe" mode for authenticating specific transactions ....  most of
the rest are used for password substitute at login type events. Many of the
chipcards following the straight payment card model result in end-user
having large number of different institutional tokens (similar to the
floppy copy protect paradigm).  Following the institutional-specific and/or
application-specific token paradigm starts to become difficult to manage as
the number of tokens increase and the probability that multiple are
required simultaneously increases.
That eventually leads into some sort of person-centric or device-centric
paradigm .... not so much an issue of the form factor  (floppy, chipcard,
dongle, etc) .... but an issue of whether there are potentially large
numbers of institutional/application specific objects or small numbers of
person/device specific objects.
So a simple issue is the trade-off between the institutional/application
specific objects .... which seem to have some amount of acceptance (payment
cards, chip cards, various "dongle" forms, etc) but in many instances can
scale poorly ... especially if  multiple different such objects have to be
available concurrently .... vis-a-vis switching to a person/device specific
object paradigm (chipcard, dongles, etc, potentially exactly same
formfactor but different paradigm)
I think dongles (and non-copyable floppies) have been around since the
80s at least...maybe the 70s.  Tamper-resistant CPU modules have been
since the ATM network, I believe, in the form of PIN processors stored
inside safes)
The fundamental difference between a "dongle" and a full "trusted module"
containing the critical application code is that with a dongle, you can
just patch the application to skip over the checks (although they can be
repeated, and relatively arcane).
If the whole application, or at least the non-cloneable parts of the
application, exist in a sealed module, the rest of the application can't
be patched to just skip over this code.
Another option for this is a client server or oracle model where the really
sensitive pieces (say, a magic algorithm for finding oil from GIS data,
or a good natural language processor) are stored on vendor-controlled
hardware centrally located, with only the UI executing on the end user's
What I'd really like is a design which accomplishes the "good" parts of
ensuring that when code claims to be executing in a certain form, it really
and providing a way to guarantee this remotely -- without making it easy
to implement restrictions on content copying.  It would be nice to have the
good parts of TCPA, and given the resistance to DRM, if security and TCPA
have their fates bound, they'll probably both die an extended and painful
I suppose the real difference between a crypto-specific module and a
purpose module is how much of the UI is within the trusted platform
If the module is only used for handling cryptographic keys, as an addition
an insecure general purpose CPU, with no user I/O, it seems unlikely to be
useful for DRM.  If the entire machine is inside the envelope, it seems
obviously useful for DRM, and DRM would likely be the dominant application.
If only a limited user IO is included in the envelope, sufficient for
user authentication and keying, and to allow the user to load
initially-trusted code onto the general purpose CPU, but where the user
can fully use whatever general purpose code on the general purpose CPU,
even uncertified code, with the certified module, it's not really useful
for DRM, but still useful for the non-DRM security applications which are
the alleged purpose behind TCPA.
(given that text piracy doesn't seem to be a serious commercial concern,
simply keeping video and audio playback and network communications outside
the TCPA envelope entirely is good enough, in practice...this way, both
authentication and keying can be done in text mode, and document
distribution control, privacy of records, etc. can be accomplished,
there is ALSO the ability to do arbitrary text processing and computing
outside the trusted envelope, .)
If it's the user's own data being protected, you don't need to worry about
the user intentionally circumventing the protections.  Any design which
removes control from the 'superuser' of the machine is fundamentally about
protecting someone other than the user.
This, I think, is the difference between TCPA and smartcards.  Notice
which one has in its short lifetime attracted far more enmity :)
Quoting lynn.wheeler :
Ryan Lackey [RL7618 RL5931-RIPE]        ryan
CTO and Co-founder, HavenCo Ltd.        +44 7970 633 277
the free world just milliseconds away   OpenPGP 4096: B8B8 3D95 F940 9760 C64B  DE90 07AD BE07 D2E0 301F

@_date: 2002-06-30 14:06:23
@_author: TCPA 
@_subject: Re: maximize best case, worst case, or average case? (TCPA) 
I remember looking at possibility at adding tamper resisistent hardware
chip to PCs back in 83 or 84 time frame (aka the TCPA idea for PCs is going
on at least 20 years old now).  It was the first time I ran into embedding
chip in a metal case that would create electrical discharge frying the chip
if the container was breached.
Remember when applications came with their own copy-protection floppy
disks? .... it was possible to build up a library of such disks ....
requiring all sorts of remove, search, insert ... when switching from one
application to another. They eventually disappeared ... but imagine if they
had survived into the multitasking era .... when it would have been
necessary to have multiple different copy protection floppy disks crammed
into the same drive at the same time. The chip was suppose to provide an
analog to the CPU serial number used for licensing software on mainframes
.... dating at least from the original IBM 370s (store cpuid hardware
Some of the higher-end applications still do that with some form of dongle
(originally in the serial port) that comes with the application .... it
doesn't quite have the downside of trying to cram multiple floppies into
the same drive concurrently; the serial port dongles allow for them to be
inline cascaded ... and in theory still be able to use the serial port for
other use at the same time.
i believe that there is some statistic some place about the UK and the US
are really great .... that in those two countries the copyright piracy is
estimated to only be 50 percent.

@_date: 2002-07-12 15:16:01
@_author: "404.notfound.com" 
@_subject: Re: IP: SSL Certificate "Monopoly" Bears Financial Fruit 
and just to make sure there is a common understanding regarding SSL cert
operation ... the browser code
1) checks that the SSL server cert can be validated by ANY public key that
is in the browser preloaded list (I haven't verified whether they totally
ignore all of the "cert" part of these preloaded public keys ... things
like expiration date ... that these preloaded public keys are in the
preloaded list appears to be sufficient ... details like the preloaded
public keys happened to be wrappered in these certificate containers is
almost extraneous).
2) validates the signature on the SSL server cert with the corresponding
public key
3) checks if the website domain/host name is the same (or in some cases
similar) to the domain/host name specificed in the SSL server cert. I have
noticed that browsers tend to pretty much ignore the contents of these SSL
server certificates ... things like expiration date ... except the public
key, the domain/host name, and the signature (and the signature only has
real meaning within the context of
the infrastructure associated with the public key in the preloaded list
with the lowest trust/integrity level;
this is analogous to security weakest link ... a bank vault with a 4ft
think vault door doesn't do much good
if the vault has no walls).
4) uses the public key in the SSL server cert to validate communication
with the server.
all of this happens automagically from most users' standpoint (probably
less than one percent of the population even knows that there is such a
thing as a preload list).
Both Netscape 6 and MSIE 5 contain ~100 built-in, automatically-trusted CA
 * Certs with 512-bit keys.
 * Certs with 40-year lifetimes.
 * Certs from organisations you've never heard of before ("Honest Joe's
   Cars and Certificates").
 * Certs from CAs with unmaintained/moribund websites ("404.notfound.com").
These certs are what controls access to your machine (ActiveX, Java,
on-demand, etc etc).
  * It takes 600-700 mouse clicks to disable these certs to leave only CAs
    really trust.
(The above information was taken from "A rant about SSL, oder: die grosse
 Sicherheitsillusion" by Matthias Bruestle, presented at the KNF-Kongress
 2002).
How many more do you need?

@_date: 2002-07-12 15:16:01
@_author: "404.notfound.com" 
@_subject: Re: IP: SSL Certificate "Monopoly" Bears Financial Fruit 
and just to make sure there is a common understanding regarding SSL cert
operation ... the browser code
1) checks that the SSL server cert can be validated by ANY public key that
is in the browser preloaded list (I haven't verified whether they totally
ignore all of the "cert" part of these preloaded public keys ... things
like expiration date ... that these preloaded public keys are in the
preloaded list appears to be sufficient ... details like the preloaded
public keys happened to be wrappered in these certificate containers is
almost extraneous).
2) validates the signature on the SSL server cert with the corresponding
public key
3) checks if the website domain/host name is the same (or in some cases
similar) to the domain/host name specificed in the SSL server cert. I have
noticed that browsers tend to pretty much ignore the contents of these SSL
server certificates ... things like expiration date ... except the public
key, the domain/host name, and the signature (and the signature only has
real meaning within the context of
the infrastructure associated with the public key in the preloaded list
with the lowest trust/integrity level;
this is analogous to security weakest link ... a bank vault with a 4ft
think vault door doesn't do much good
if the vault has no walls).
4) uses the public key in the SSL server cert to validate communication
with the server.
all of this happens automagically from most users' standpoint (probably
less than one percent of the population even knows that there is such a
thing as a preload list).
Both Netscape 6 and MSIE 5 contain ~100 built-in, automatically-trusted CA
 * Certs with 512-bit keys.
 * Certs with 40-year lifetimes.
 * Certs from organisations you've never heard of before ("Honest Joe's
   Cars and Certificates").
 * Certs from CAs with unmaintained/moribund websites ("404.notfound.com").
These certs are what controls access to your machine (ActiveX, Java,
on-demand, etc etc).
  * It takes 600-700 mouse clicks to disable these certs to leave only CAs
    really trust.
(The above information was taken from "A rant about SSL, oder: die grosse
 Sicherheitsillusion" by Matthias Bruestle, presented at the KNF-Kongress
 2002).
How many more do you need?

@_date: 2002-08-16 02:49:01
@_author: possibly 90 percent 
@_subject: Re: TCPA not virtualizable during ownership change (Re: 
I arrived at that decision over four years ago ... TCPA possibly didn't
decide on it until two years ago. In the assurance session in the TCPA
track at spring 2001 intel developer's conference I claimed my chip was
much more KISS, more secure, and could reasonably meet the TCPA
requirements at the time w/o additional modifications. One of the TCPA guys
in the audience grossed that I didn't have to contend with the committees
of hundreds helping me with my design.
There are actually significant similarities between my chip and the TPM
I'm doing key gen at very first, initial power-on/test of wafer off the
line (somewhere in dim past it was drilled into me that everytime something
has to be handled it increases the cost).
Also, because of extreme effort at KISS, the standard PP evaluation stuff
gets much simpler and easier because most (possibly 90 percent) of the
stuff is N/A or doesn't exist
early ref:
or refs at (under subject aads chip strawman):
brand & other misc. stuff:
random evauation refs:
 anybody seen (EAL5) semi-formal
specification for FIPS186-2/x9.62 ecdsa?
 formal fips186-2/x9.62 definition
for eal 5/6 evaluation
I think a number of the apparent conflicts go away if you carefully
track endorsement key pair vs endorsement certificate (signature on
endorsement key by hw manufacturer).  For example where it is said
that the endorsement _certificate_ could be inserted after ownership
has been established (not the endorsement key), so that apparent
conflict goes away.  (I originally thought this particular one was a
conflict also, until I noticed that.)  I see anonymous found the same
But anyway this extract from the CC PP makes clear the intention and
an ST based on this PP is what a given TPM will be evaluated based on:
p 20:
(if only they could have managed to say that in the spec).

@_date: 2002-08-11 05:40:00
@_author: unknown_name 
@_subject: Re: Challenge to TCPA/Palladium detractors 
oops, finger slip that should be
 security proportional to risk
aka 2001h.html not 2002h.html ....
small discussion of security proportional to risk:
 security proportional to risk

@_date: 2002-08-13 17:43:31
@_author: i.e. hard instruction ROM 
@_subject: Re: Challenge to David Wagner on TCPA 
actually it is possible to build chips that generate keys as part of
manufactoring power-on/test (while still in the wafer, and the private key
never, ever exists outside of the chip)  ... and be at effectively the same
trust level as any other part of the chip (i.e. hard instruction ROM).
using such a key pair than can uniquely authenticate a chip ....
effectively becomes as much a part of the chip as the ROM or the chip
serial number, etc. The public/private key pair .... if appropriately
protected (with evaluated, certified and audited process) then can be
considered somewhat more trusted than a straight serial number aka a
straight serial number can be skimmed and replayed ... where a digital
signature on unique data is harder to replay/spoof.  the hips come with
unique public/private key where the private key is never known.
sometimes this is a difficult consept ... the idea of a public/private key
pair as a form of a "difficult to spoof" chip serial  .... when all uses of
public/private key, asymmetric cryptograhy might have always been portrayed
as equilanet to x.509 identity certificates (it is possible to show in
large percentage of the systems that public/private key digital signatures
are sufficient for authentication and any possible certificates are both
redundant and superfulous).
misc. ref (aads chip strawman):
This makes a lot of sense, especially for "closed" systems like business
LANs and WANs where there is a reasonable centralized authority who can
validate the security of the SCP keys.  I suggested some time back that
since most large businesses receive and configure their computers in the IT
department before making them available to employees, that would be a time
that they could issue private certs on the embedded SCP keys. The
employees' computers could then be configured to use these private certs
for their business computing.
However the larger vision of trusted computing leverages the global
internet and turns it into what is potentially a giant distributed
computer.  For this to work, for total strangers on the net to have trust
in the integrity of applications on each others' machines, will require
some kind of centralized trust infrastructure.  It may possibly be
multi-rooted but you will probably not be able to get away from this
The main problem, it seems to me, is that validating the integrity of the
SCP keys cannot be done remotely.  You really need physical access to the
SCP to be able to know what key is inside it.  And even that is not enough,
if it is possible that the private key may also exist outside, perhaps
because the SCP was initialized by loading an externally generated
public/private key pair.  You not only need physical access, you have to be
there when the SCP is initialized.
In practice it seems that only the SCP manufacturer, or at best the OEM who
(re) initializes the SCP before installing it on the motherboard, will be
in a position to issue certificates.  No other central authorities will
have physical access to the chips on a near-universal scale at the time of
their creation and installation, which is necessary to allow them to issue
meaningful certs.  At least with the PGP "web of trust" people could in
principle validate their keys over the phone, and even then most PGP users
never got anyone to sign their keys.  An effective web of trust seems much
more difficult to achieve with Palladium, except possibly in small groups
that already trust each other anyway.
If we do end up with only a few trusted root keys, most internet-scale
trusted computing software is going to have those roots built in. Those
keys will be extremely valuable, potentially even more so than Verisign's
root keys, because trusted computing is actually a far more powerful
technology than the trivial things done today with PKI.  I hope the
Palladium designers give serious thought to the issue of how those trusted
root keys can be protected appropriately.  It's not going to be enough to
say "it's not our problem".  For trusted computing to reach its potential,
security has to be engineered into the system from the beginning - and that
security must start at the root!

@_date: 2002-08-07 19:33:23
@_author: augmented 
@_subject: RE: Challenge to David Wagner on TCPA 
it is relative common  for authentication hardware tokens with asymmetric
crypto to never divulge the private key .... there is big issue then
whether 1) the key pair is actually generated on the chip (and never
divulged) or 2) the keys are generated externally and injected into the
chip (with special compensating procedures that the chip never leaks the
private key ... and there is no record kept by the generation/injection
specifications for asymmetric cryptography for data encryption may include
key escrow of the private key (allowing business continuity for data that
has been encrypted with the public key).
lucky green  If I buy a lock I expect that by demonstrating ownership I
It appears the days when this was true are waning. At least in the PC
platform domain.

@_date: 2002-08-06 04:47:33
@_author: unknown_name 
@_subject: Re: dangers of TCPA/palladium 
a lot financial institutions went to certificates/credentials that only
contained an account number .... nothing else ... largely because of the
huge privacy exposure of any kind of identify certificate (everything about
you embedded in a certificate that is attached ... frequently totally in
the clear ... or at least at the end-points on every transaction ....
including intermediary points like merchants).
It was then possible to show (at least in the financial transaction &
relying-party-only certificates) that such certificates could easily be
compressed to zero bytes.
in the online financial transaction case, the merchant is interested in the
bank saying that the merchant gets the money ..... your identity isn't
necessary for that ... and in fact, the EU directive of making
point-of-sale transactions as anonymous as cash would also lead in that
direction. First step is removing you name from the piece of plastic, then
if the "plastic" credential doesn't have any identity .... why should there
be a certificate at all.
remail on 8/5/2002 6:25 pm wrote
Sure, but how many pages would it take in the spec to describe the
protocol?  Especially given their turgid technical-writer prose?
Brands took a whole book to describe his credentials thoroughly.
In any case, I agree that something like this would be an excellent
enhancement to the technology.  IMO it is very much in the spirit of TCPA.
I suspect they would be very open to this suggestion.

@_date: 2002-08-06 04:47:33
@_author: unknown_name 
@_subject: Re: dangers of TCPA/palladium 
a lot financial institutions went to certificates/credentials that only
contained an account number .... nothing else ... largely because of the
huge privacy exposure of any kind of identify certificate (everything about
you embedded in a certificate that is attached ... frequently totally in
the clear ... or at least at the end-points on every transaction ....
including intermediary points like merchants).
It was then possible to show (at least in the financial transaction &
relying-party-only certificates) that such certificates could easily be
compressed to zero bytes.
in the online financial transaction case, the merchant is interested in the
bank saying that the merchant gets the money ..... your identity isn't
necessary for that ... and in fact, the EU directive of making
point-of-sale transactions as anonymous as cash would also lead in that
direction. First step is removing you name from the piece of plastic, then
if the "plastic" credential doesn't have any identity .... why should there
be a certificate at all.
remail on 8/5/2002 6:25 pm wrote
Sure, but how many pages would it take in the spec to describe the
protocol?  Especially given their turgid technical-writer prose?
Brands took a whole book to describe his credentials thoroughly.
In any case, I agree that something like this would be an excellent
enhancement to the technology.  IMO it is very much in the spirit of TCPA.
I suspect they would be very open to this suggestion.

@_date: 2002-08-15 20:41:58
@_author: and preferably the source 
@_subject: Re: Overcoming the potential downside of TCPA 
hum, i guess i somewhat view the situation somewhat in flux ... maybe
analogous to the period when there was a claim that only auto mechanics
should be allowed to drive automobiles .... and only automobiles that
required mechanics to drive them should allowed to be built. The situation
today is that while anybody could build their own automobile from scratch,
few actually do.
as to putting together reliable configurations ... i've had a little
experience ... possible you've heard of some of it.
there was this little client/server startup in the valley that was
interested in implementing  server transactions ... with this emerging
technology that required some amount of vetting and maturing. during the
year that my wife and i worked with them on the implementation and
deployment they moved from menlo park to mountain view and changed their
name from mosaic to netscape .... the emerging technology is sometimes
referred to as SSL or HTTPS and the transactions they wanted to do are
sometimes now referred to as electronic commerce. Possibly you have heard
of some of this? Does Netscape, SSL, HTTPS, or electronic commerce ring any
some past integrity and security suggestions:
  E-commerce security
 Does "Strong Security" Mean
no matter how much I wanted the industry to not allow operation of systems
that didn't meet certain criteria, I wasn't succesful.
thread somewhat analogous to this one:
slightly related mumblings on security proportional to risk
 Security Proportional to Risc
rant about maybe in a couple thousands years security engineering will
reach the maturity level of civil engineering for bridge building
 Serious vulnerablity in several
common SSL implementations?
How many people participate in the creation of the bridges and roads that
you drive on ... so that you could examine the safety of the road bed
before it is paved over?
... wide ... open ...  <>  Do you even know what Kerchoff's
Principle IS?!  Look, I've been trying to hold back on actual ranting,
but... but...  you really don't get it, do you?
On the contrary, I have one box with all the protection I want: it's never
connected to the net at all.  I have another box with all the protection
that I consider practical for email and web use.  Both run only and exactly
the software I have put on them, which I obtained from sources trusted to
me and which do not and CAN NOT require any further interaction or
authorization whatsoever to run their software.  I have selected software,
on purpose, which denies someone who is not me even the bare possibility of
restricting my ability to run it at some future time.  I have the source
That is what I mean when I talk about trusted computing.  I trust that my
software does what it says it does, is completely open to inspection and
verification by first, second, and third parties, and cannot be denied to
me at any point after I have come to depend upon it, whether or not I have
a net connection at the moment to interact with its creators.  I trust that
I cannot be singled out remotely to have a sniffer installed on my local
machine through a backdoor.  I trust that code I can inspect at the level
of machine instructions is code that cannot keep secrets from me or forever
conceal malign intent.  I trust that I cannot be forced to depend on any
single commercial software provider, whether it be for the OS or for the
"trusted" compiler which can, of course, come from only one source.  I
trust that coercive "upgrades" done for the sake of incompatibility with
existing code,  do not and cannot happen automatically given my system
That is trusted computing sir, and TCPA/Palladium is a huge step *backward*
from it.  Anything that runs *ANY* code that cannot be inspected, or which
keeps data that cannot be inspected, is running code that cannot be
TCPA/Palladium does not provide trusted computing.  At least not computing
that I can trust in the way I trust what I've got now. In fact, from my
POV, TCPA/Palladium look like ways to enable the running of software which
I *CANNOT* trust. Imagine my excitement at the prospect.
This is a cryptography mailing list.  Do we even want to count the number
of times commercial software providers have come up with some crap and
claimed it was secure, and been just lying to us?  Do I have to recount all
the proprietary, snake-oil encryption systems that relied for its security
on not being inspected?  Do I have to recount the number of ways that
unstudied security designers have given us their best efforts and had them
shot down by professionals in seconds?  Do we have to speculate about what
can happen if the clowns who employ them think they'll never be caught?!
We've all been around the block enough to know this by now:
Kerchoff was absolutely right.  A hundred and twenty years since he
elucidated the Principle has not changed a thing.
NOBODY has the manpower or time to find all their bugs in-house.
If you can't inspect the machine code (and preferably the source) then you
are looking at something that is not and can never be made secure.
Now, you're talking about a system that gives people the opportunity to
HIDE THE CODE, and telling us that's security?!  What the hell are you
smoking?! You are confusing real security mistakes with the ability to
DETECT real security mistakes!
                                                 Bear

@_date: 2002-08-14 22:36:31
@_author: unknown_name 
@_subject: Re: Overcoming the potential downside of TCPA 
Just because some cars have anti-theft devices that can be defeated in
seconds .... doesn't make all auto anti-theft devices useless.
so you have currently have an environment that has no protection and
everything is totally wide open.
lets say a hardware chip that currently has no tamper resistance and a
whole infrastructure is put in place based on having security based on a
hardware chip. Hypothetically it eliminates allt the non-physical attacks.
however there are still vulnerabilities involving physical attacks on the
hardware components.
Would that be beneficial? Would it be helpful to eliminate all network and
electronic attacks leaving only physical attacks?
One of the issues is that some amount of the population actually has some
sensitivity for dealing with physical attacks. Part of the current problem
is many people don't have any experience dealing with electronic and
non-physical attacks. I would consider the elimination of all electronic
and network attacks as an interesting prospect.
So what does the world currently do about physical attacks.
Some organizations .... if they physical own the device and trying to
protect against outside attacks .... might put the device under armed
If it is DRM, where the chip is, in effect, acting as a proxy agent on
somebody else's behalf then there is issue about protection about physical
attacks by the person in possesion of the device. Tamper-resistance just
ups the cost of a succesful attack. One could hypothesis the value of
something that is always in excess of the protection measures. .... i.e.
security proportional to the risk; aka ... regardless of the protection
measures there could always be some hypothetical value making it worth the
cost of mounting an attack.
The hypothetical DRM risk is possibly 90 percent of the infrastructure (not
single, here & there isolated copying .... copying being done everywhere).
Would some TCPA possibly both increase the percent of authorized copies and
reduce the unauthorized copies (i.e. a method to reduce unauthorized copies
to zero is by not publishing the works at all). The issue isn't absolutely
ruling out unauthorized copies .... the issue is increasing the percent of
authorized copies.
So hypothetically, the environment has reduced all the vulnerabilities and
attacks to attacks just on the physical chip. It is possible that market
forces could  react to such an environment and opportunity.  One
opportunity might be higher priced PCs that have chips evaluated at
EAL7-high with loads of tamper-resistance along with certain works are only
available on machines having the higher evaluated chips.
random mutterings about parameterized risk management:
 Attacks on a PKI
 Attacks on a PKI
 EU digital signature
initiative stalled
 AADS Strawman
 cardtech/securetech & CA PKI
 cardtech/securetech & CA PKI
 cardtech/securetech & CA PKI
 cardtech/securetech & CA PKI
 Common misconceptions, was Re:
KISS for PKIX. (Was: RE: ASN.1 vs XML (used to be RE: I-D ACTION
 QC Bio-info leak?
 QC Bio-info leak?
 biometrics and electronic
 Risk Management in AA /
draft X9.59
 X9.59 Electronic Payment
standard issue
 question about PKI...
 RealNames hacked. Firewall issues.
The problem with this idea is that TCPA is useless.  For all the *useful*
things you are thinking of, you need TCPA plus an approved key.  The only
way you are going to get an approved key is inside a tamper-resistant chunk
of hardware.  If you should manage to extract the key, then yes, you'll be
able to create that CD.  But the idea is that you, the hardware owner, are
not authorized to extract the information contained in your own hardware.
I find the idea of "owning" something without having the legal right to
open it up and look inside legally dubious at best, but I'm no lawyer....
The idea is that you shouldn't get anywhere without hardware hacking. The
people doing this have decided hardware hacks are acceptable risks because
they only want to protect cheap data -- movies, songs, commercial software,
whatever.  They are sticking to stuff that's not expensive enough to
hardware hacks.
However, if this infrastructure does in fact become trusted and somebody
tries to use it to protect more valuable data, God help them.  They'll get
their asses handed to them on a platter.
                                          Bear

@_date: 2002-08-16 02:49:01
@_author: possibly 90 percent 
@_subject: Re: TCPA not virtualizable during ownership change (Re: Overcoming the 
I arrived at that decision over four years ago ... TCPA possibly didn't
decide on it until two years ago. In the assurance session in the TCPA
track at spring 2001 intel developer's conference I claimed my chip was
much more KISS, more secure, and could reasonably meet the TCPA
requirements at the time w/o additional modifications. One of the TCPA guys
in the audience grossed that I didn't have to contend with the committees
of hundreds helping me with my design.
There are actually significant similarities between my chip and the TPM
I'm doing key gen at very first, initial power-on/test of wafer off the
line (somewhere in dim past it was drilled into me that everytime something
has to be handled it increases the cost).
Also, because of extreme effort at KISS, the standard PP evaluation stuff
gets much simpler and easier because most (possibly 90 percent) of the
stuff is N/A or doesn't exist
early ref:
or refs at (under subject aads chip strawman):
brand & other misc. stuff:
random evauation refs:
 anybody seen (EAL5) semi-formal
specification for FIPS186-2/x9.62 ecdsa?
 formal fips186-2/x9.62 definition
for eal 5/6 evaluation
I think a number of the apparent conflicts go away if you carefully
track endorsement key pair vs endorsement certificate (signature on
endorsement key by hw manufacturer).  For example where it is said
that the endorsement _certificate_ could be inserted after ownership
has been established (not the endorsement key), so that apparent
conflict goes away.  (I originally thought this particular one was a
conflict also, until I noticed that.)  I see anonymous found the same
But anyway this extract from the CC PP makes clear the intention and
an ST based on this PP is what a given TPM will be evaluated based on:
p 20:
(if only they could have managed to say that in the spec).
