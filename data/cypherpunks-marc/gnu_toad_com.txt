
@_date: 2001-09-15 07:32:12
@_author: John Gilmore 
@_subject: Please make stable NON-US homes for strong crypto projects 
It's clear that the US administration is putting out feelers to
again ban publication of strong encryption.  See:
  The evil gnomes who keep advancing unconstitutional US anti-crypto
policies know that the current hysteria in Congress and the
Administration will not last forever.  So they will probably move very
quickly -- within a week is my guess -- to re-control encryption,
either by a unilateral action of the Administration (by amending
the Export Administration Regulations), or by stuffing a rider onto
some so-called "emergency" bill in Congress.
They maneuvered very carefully in the Bernstein case such that there
is no outstanding injunction against violating the Constitution this
way -- and even no binding 9th-Circuit precedent that tells them it's
unconstitutional to do so.  They know in their hearts that numerous
judges have found it unconstitutional, but they have proven throughout
the seven-year history of the case that they don't give a damn about
the Constitution.  Which means it may take weeks, months or years for
civil liberties workers to get a judge to roll back any such action.
Not just days.  We won the case, but they squirmed out of any
permanent restrictions -- so far.
The US government has a new mania for wiretapping everyone in case
they might be a terrorist.  There's already two bills in Congress to
make it trivial for them to wiretap anybody on flimsy excuses, and to
retroactively justify their precipitous act of rolling Carnivore boxes
into major ISPs this week and demanding, without legal authority, that
they be put at the heart of the networks.  See:
  Even more than before, we will need good encryption tools, merely to
maintain privacy for law-abiding citizens, political activists, and
human rights workers.  (In the current hysteria, mere messages
advocating peace or Constitutional rights might best be encrypted.)
The European Parliament also recently recommended that European
communications be routinely encrypted to protect them from pervasive
US Echelon wiretaps.
Some US developers, who thought such a reversal would never happen,
have built or maintained a number of good open source encryption tools
in the United States, and may not have lined up solid foreign
maintainers or home sites.
LET'S FIX THAT!  We need volunteers in many countries to mirror
current distributions, CVS trees, etc.  We need volunteers to also
act as maintainers, accepting patches and integrating them into
solid releases.
(Note that too many countries have pledged to stand toe-to-toe with the
US while they march off to make war on somebody they can't figure out
who it is yet.  If you live in one of those countries, you may
suddenly find that your own crypto regs have been sneakily altered.
Take care that each useful package has maintainers and distribution
points in diverse countries.)
I haven't kept close track of which packages are in danger.  I
suggest that people nominate packages on this mailing list, and that
others immediately grab mirror copies of them as they are nominated.
And that some of those who mirror them keep quiet, in case hysterical
governments make a concerted effort to stamp out all copies and/or all
major distribution sites.  If you aren't the quiet type, then *AFTER*
IMMEDIATELY PULLING A COPY OF THE CODE OUTSIDE US JURISDICTION,
announce your mirror on this mailing list.
We freedom-loving US citizens have had to rely on the freedom-loving
citizens of saner countries, to do the work of making strong
encryption, for many years.  We had a brief respite, which we will
eventually resume for good.  In the meantime, please let me apologize
for my countrymen and for my government, for asking you to shoulder
most of the burden again.  Thank you so much.
PS: Companies with proprietary encryption packages might consider
immediately open-sourcing and exporting their encryption add-ins, so
their customers can still get them from overseas archives.  Or taking
other actions to safeguard the privacy and integrity of their
customers' data and their society's infrastructure.  I also advise
that they lobby like hell to keep privacy and integrity legal in the US.

@_date: 2001-11-27 10:04:44
@_author: John Gilmore 
@_subject: cypherpunks@toad.com is going away 
The cypherpunks list degenerated a long time ago to the point where I
have no idea why more than 500 people are still receiving it every
As part of cleaning up the email system on toad.com, I plan to shut
down the cypherpunks-unedited list, which receives all the traffic
sent to cypherpunks within the next week or two.
I suggest that anyone who wants to talk or listen about encryption
should send mail to:
with a one-line plain text message saying "subscribe".  This will
begin the process of subscribing them to the Cryptography mailing
list, which is edited to remove irrelevant postings and to keep the
volume down and the discussion focused.  (I tried to do this with the
cypherpunks list some years ago, but was shouted down by people who
complained of "censorship".  So I just left it unedited, with the
expectable result that serious discussions deserted it.)
If you were subscribed to the cypherpunks-unedited list because
you like to collect spam, talk with me personally and I'll see if I can
help you.  I have a large collection :-).
The old "cypherpunks-announce" list was superseded many months ago by
"meetingpunks  Cypherpunks-announce is no longer in
There remains a single encryption-related mailing list on toad.com,
"coderpunks" which is for people who write code.

@_date: 2001-11-27 10:04:44
@_author: John Gilmore 
@_subject: cypherpunks@toad.com is going away 
The cypherpunks list degenerated a long time ago to the point where I
have no idea why more than 500 people are still receiving it every
As part of cleaning up the email system on toad.com, I plan to shut
down the cypherpunks-unedited list, which receives all the traffic
sent to cypherpunks within the next week or two.
I suggest that anyone who wants to talk or listen about encryption
should send mail to:
with a one-line plain text message saying "subscribe".  This will
begin the process of subscribing them to the Cryptography mailing
list, which is edited to remove irrelevant postings and to keep the
volume down and the discussion focused.  (I tried to do this with the
cypherpunks list some years ago, but was shouted down by people who
complained of "censorship".  So I just left it unedited, with the
expectable result that serious discussions deserted it.)
If you were subscribed to the cypherpunks-unedited list because
you like to collect spam, talk with me personally and I'll see if I can
help you.  I have a large collection :-).
The old "cypherpunks-announce" list was superseded many months ago by
"meetingpunks  Cypherpunks-announce is no longer in
There remains a single encryption-related mailing list on toad.com,
"coderpunks" which is for people who write code.

@_date: 2001-12-11 05:04:31
@_author: John Gilmore 
@_subject: Re: FreeSWAN & US export controls 
Anonymous said:
(From the pulpit:)
Once we kick John Asscroft's unconstitutional ash outta town, bush
George Bust along with more than a thousand other innocents, and
eliminate the spectre of Judd Gregg and other retrograde stalinists
're-regulating' US crypto, then we'll think about polluting the
precious bodily fluids of worldwide freeware privacy protection with
the stench of US crypto policy.  It probably won't happen for a few months.
Or hadn't you noticed that the US government is not in much of a mood
to follow the constitution or to tolerate dissent or privacy among the
sleepy sheeplike citizens?  They're doing their best to stamp that
radical stuff out right here in the USSA, let alone let it cross the
border into parts of the world that they don't have firmly under their
thumb.  Less than 100% support for every paranoid and senseless twitch
of the current Administration is a demonstration not not only of
treason but of active support for terrorism, which everyone knows is a
terrible thing except when the US or Israel or Great Britain does it.
Anybody reading this mailing list is already gonna be first up against
the wall once the joy of arresting immigrant movers as 'terrorists'
fades, and spying on 'domestic political groups' become fair game.
Your packets are already in the lint screen on that big, big vacuum
cleaner.  And our new policy of maximum sentences for trivial
'crimes', like forgetting to file some form, reduces the expense and
bother of actually trying suspects for the crimes that the agencies
suspect them of.  Of course you can confront your accusers!  Did you or
did you not jaywalk across Route 1 last July, Mr. May?
The reason I started the IPSEC-for-Linux project those many years ago
was because Linux kernel releases used to be built in free countries,
unlike the releases of most other operating systems.  Now they aren't.
Perhaps mr. or ms. 'anonymous' and the primary kernel developers
didn't spend seven years making a principled tilt at the windmill of
NSA's export controls.  We overturned them by a pretty thin margin.
The government managed to maneuver such that no binding precedents
were set: if they unilaterally change the regulations tomorrow to
block the export of public domain crypto, they wouldn't be violating
any court orders or any judicial decisions.  I.e. they are not BOUND
by the policy change.  They changed it "voluntarily", in order to
sneak out of the court cases by the back door.  Even today it is
sometimes said that once Dan Bernstein ends his court case (which
still continues today), the NSA is ready, willing, and able to slap
the controls right back on.  And it would take months or years in
court -- and lots more volunteer citizen money spent for freedom,
while the bastards spend tax money to lock us up -- to get the
controls removed again.  If the judges haven't changed their minds in
the meantime.
(You may have noticed that last month, the Second Circuit Court of
Appeals accpted Judge Kaplan's half-lies-half-truth judgment 3-0 in
the 2600 case appeal: Yes, absolutely, software is First Amendment
protected speech.  But no, somehow the First Amendment really doesn't
mean what it means elsewhere; of *course* they can regulate the
publication of software on flimsy grounds.  Like that sometime later,
somebody somewhere might potentially be somewhat hurt by something
somebody else does with the software, if we don't eliminate that
option by restricting the publication of that software now.  Suppose
the next crypto export court case happens in NY rather than CA?  EFF
would be proud to defend John Young and Perry Metzger, but all its
lawyers might be in prison, charged by John Asscroft with "aiding
terrorists by eroding our national unity and diminishing our
Make my day.
PS: Of course, the only software worth wasting your time on comes from
those macho dudes of the U.S. of A.  Those furriners don't even know
how to speek the lingua proper, let alone write solid buggy code like
Microsoft.  High crypto math is all Greek to them.  It's just lucky
for Linus that he moved to the US, otherwise we'd all know his furrin
software was crap too, even tho he tricked us by cloning it from Bell Labs.

@_date: 2001-12-11 05:04:31
@_author: John Gilmore 
@_subject: Re: FreeSWAN & US export controls 
Anonymous said:
(From the pulpit:)
Once we kick John Asscroft's unconstitutional ash outta town, bush
George Bust along with more than a thousand other innocents, and
eliminate the spectre of Judd Gregg and other retrograde stalinists
're-regulating' US crypto, then we'll think about polluting the
precious bodily fluids of worldwide freeware privacy protection with
the stench of US crypto policy.  It probably won't happen for a few months.
Or hadn't you noticed that the US government is not in much of a mood
to follow the constitution or to tolerate dissent or privacy among the
sleepy sheeplike citizens?  They're doing their best to stamp that
radical stuff out right here in the USSA, let alone let it cross the
border into parts of the world that they don't have firmly under their
thumb.  Less than 100% support for every paranoid and senseless twitch
of the current Administration is a demonstration not not only of
treason but of active support for terrorism, which everyone knows is a
terrible thing except when the US or Israel or Great Britain does it.
Anybody reading this mailing list is already gonna be first up against
the wall once the joy of arresting immigrant movers as 'terrorists'
fades, and spying on 'domestic political groups' become fair game.
Your packets are already in the lint screen on that big, big vacuum
cleaner.  And our new policy of maximum sentences for trivial
'crimes', like forgetting to file some form, reduces the expense and
bother of actually trying suspects for the crimes that the agencies
suspect them of.  Of course you can confront your accusers!  Did you or
did you not jaywalk across Route 1 last July, Mr. May?
The reason I started the IPSEC-for-Linux project those many years ago
was because Linux kernel releases used to be built in free countries,
unlike the releases of most other operating systems.  Now they aren't.
Perhaps mr. or ms. 'anonymous' and the primary kernel developers
didn't spend seven years making a principled tilt at the windmill of
NSA's export controls.  We overturned them by a pretty thin margin.
The government managed to maneuver such that no binding precedents
were set: if they unilaterally change the regulations tomorrow to
block the export of public domain crypto, they wouldn't be violating
any court orders or any judicial decisions.  I.e. they are not BOUND
by the policy change.  They changed it "voluntarily", in order to
sneak out of the court cases by the back door.  Even today it is
sometimes said that once Dan Bernstein ends his court case (which
still continues today), the NSA is ready, willing, and able to slap
the controls right back on.  And it would take months or years in
court -- and lots more volunteer citizen money spent for freedom,
while the bastards spend tax money to lock us up -- to get the
controls removed again.  If the judges haven't changed their minds in
the meantime.
(You may have noticed that last month, the Second Circuit Court of
Appeals accpted Judge Kaplan's half-lies-half-truth judgment 3-0 in
the 2600 case appeal: Yes, absolutely, software is First Amendment
protected speech.  But no, somehow the First Amendment really doesn't
mean what it means elsewhere; of *course* they can regulate the
publication of software on flimsy grounds.  Like that sometime later,
somebody somewhere might potentially be somewhat hurt by something
somebody else does with the software, if we don't eliminate that
option by restricting the publication of that software now.  Suppose
the next crypto export court case happens in NY rather than CA?  EFF
would be proud to defend John Young and Perry Metzger, but all its
lawyers might be in prison, charged by John Asscroft with "aiding
terrorists by eroding our national unity and diminishing our
Make my day.
PS: Of course, the only software worth wasting your time on comes from
those macho dudes of the U.S. of A.  Those furriners don't even know
how to speek the lingua proper, let alone write solid buggy code like
Microsoft.  High crypto math is all Greek to them.  It's just lucky
for Linus that he moved to the US, otherwise we'd all know his furrin
software was crap too, even tho he tricked us by cloning it from Bell Labs.

@_date: 2001-12-11 07:15:25
@_author: John Gilmore 
@_subject: Re: FreeSWAN & unnatural monopolies 
I doubt it.
The Linux kernels released by Linus Torvalds hold a similar 'natural
monopoly' over every other variant of free operating system kernel.  What
could explain this puzzling economic phenomenon?  Certainly the BSD folks
have been puzzled by it.
I mean, half a dozen people have rewritten 'grep', because it's just
not that hard.  And troff was cloned even though it was hard, because
the original was such a piece of unmaintainable (and nonfree) crud.
But you and you and you are all free to make your own variant of the
Linux kernel, and keep maintaining it and throwing in improvements.
Why don't you?  Even big companies keep following Linus's version.
Perhaps the puzzle results from someone who does a sufficiently hard
job, sufficiently well, that nobody who is actually capable of
competing WANTS to compete.  They have better things to do.
What puzzles me is how the mediocre X Window System has attracted no
competitors.  Yes, it's a hard job supporting all those hardware
variants by all those lovely undocumented proprietary companies.  But
the X model sucks on SO many fronts, breaking typeahead/mouseahead,
performance, display independence, having dozens of puzzling and
incompatible window managers, etc.
And have you looked at the 'object oriented' stuff layered on top of it?
  743 root      17   0 50896  44M  6320 S     0.7 36.0 15292m X
  874 gnu       11   0 14648  10M  3148 S     0.3  8.6  13:30 gnome-terminal
That's a 50Mbyte process (44M resident) of window drivers, and a
14Mbyte (10M resident) terminal window that I'm typing into.  I've
seen the terminal window get as high as 60 Mbytes, with more than 50

@_date: 2002-01-10 08:52:29
@_author: John Gilmore 
@_subject: Re: FreeSWAN & US export controls 
Absolutely.  It's already pretty secure.  We should just make it
trivial to install, automatic, transparent, self-configuring,
painless to administer, and free of serious bugs.  Then they'll have
every reason to drop it in.

@_date: 2002-01-10 08:52:29
@_author: John Gilmore 
@_subject: Re: FreeSWAN & US export controls 
Absolutely.  It's already pretty secure.  We should just make it
trivial to install, automatic, transparent, self-configuring,
painless to administer, and free of serious bugs.  Then they'll have
every reason to drop it in.

@_date: 2002-08-10 11:02:36
@_author: John Gilmore 
@_subject: Re: responding to claims about TCPA 
Many of the people who "know something about TCPA" are constrained
by NDA's with Intel.  Perhaps that is Eric's problem -- I don't know.
(I have advised Intel about its security and privacy initiatives,
under a modified NDA, for a few years now.  Ross Anderson has also.
Dave Farber has also.  It was a win-win: I could hear about things
early enough to have a shot at convincing Intel to do the right things
according to my principles; they could get criticized privately rather
than publicly, if they actually corrected the criticized problems
before publicly announcing.  They consult me less than they used to,
probably because I told them too many things they didn't want to
One of the things I told them years ago was that they should draw
clean lines between things that are designed to protect YOU, the
computer owner, from third parties; versus things that are designed to
protect THIRD PARTIES from you, the computer owner.  This is so
consumers can accept the first category and reject the second, which,
if well-informed, they will do.  If it's all a mishmash, then
consumers will have to reject all of it, and Intel can't even improve
the security of their machines FOR THE OWNER, because of their history
of "security" projects that work against the buyer's interest, such as
the Pentium serial number and HDCP.
TCPA began in that "protect third parties from the owner" category,
and is apparently still there today.  You won't find that out by
reading Intel's modern public literature on TCPA, though; it doesn't
admit to being designed for, or even useful for, DRM.  My guess is
that they took my suggestion as marketing advice rather than as a
design separation issue.  "Pitch all your protect-third-party products
as if they are protect-the-owner products" was the opposite of what I
suggested, but it's the course they (and the rest of the DRM industry)
are on.  E.g. see the July 2002 TCPA faq at:
    3. Is the real "goal" of TCPA to design a TPM to act as a DRM or
     Content Protection device?   No.  The TCPA wants to increase the trust ... [blah blah blah]
I believe that "No" is a direct lie.  Intel has removed the first
public version 0.90 of the TCPA spec from their web site, but I have
copies, and many of the examples in the mention DRM, e.g.:
    (still there)
This TCPA white paper says that the goal is "ubiquity".  Another way to
say that is monopoly.  The idea is to force any other choices out of
the market, except the ones that the movie & record companies want.
The first "scenario" (PDF page 7) states: "For example, before making
content available to a subscriber, it is likely that a service
provider will need to know that the remote platform is trustworthy."
       (gone now)
Even this 200-page TCPA-0.90 specification, which is carefully written
to be obfuscatory and misleading, leaks such gems as: "These features
encourage third parties to grant access to by the platform to
information that would otherwise be denied to the platform" (page 14).
"The 'protected store' feature...can hold and manipulate confidential
data, and will allow the release or use of that data only in the
presence of a particular combination of access rghts and software
environment.  ... Applications that might benefit include ... delivery
of digital content (such as movies and songs)."  (page 15).
Of course, they can't help writing in the DRM mindset regardless of
their intent to confuse us.  In that July 2002 FAQ again:
  9. Does TCPA certify applications and OS's that utilize TPMs?   No.  The TCPA has no plans to create a "certifying authority" to
  certify OS's or applications as "trusted".  The trust model the TCPA
  promotes for the PC is: 1) the owner runs whatever OS or
  applications they want; 2) The TPM assures reliable reporting of the
  state of the platform; and 3) the two parties engaged in the
  transaction determine if the other platform is trusted for the
  intended transaction.
"The transaction"?  What transaction?  They were talking about the
owner getting reliable reporting on the security of their applications
and OS's and -- uh -- oh yeah, buying music or video over the Internet.
Part of their misleading technique has apparently been to present no
clear layman's explanations of the actual workings of the technology.
There's a huge gap between the appealing marketing sound bites -- or
FAQ lies -- and the deliberately dry and uneducational 400-page
technical specs.  My own judgement is that this is probably
deliberate, since if the public had an accurate 20-page document that
explained how this stuff works and what it is good for, they would
reject the tech instantly.
Perhaps we in the community should write such a document.  Lucky and
Adam Back seem to be working towards it.  The similar document about
key-escrow (that CDT published after assembling a panel of experts
including me, Whit, and Matt Blaze) was quite useful in explaining to
lay people and Congressmen what was wrong with it.  NSA/DoJ had
trouble countering it, since it was based on the published facts, and
they couldn't impugn the credentials of the authors, nor the
document's internal reasoning.
Intel and Microsoft and anonymous chauvanists can and should criticize
such a document if we write one.  That will strengthen it by
eliminating any faulty reasoning or errors of public facts.  But they
had better bring forth new exculpating facts if they expect the
authors to change their conclusions.  They're free to allege that "No
current Microsoft products have Document Revocation Lists", but that
doesn't undermine the conclusion that their architectures make it easy
to secretly implement that feature, anytime they want to.

@_date: 2002-08-10 11:02:36
@_author: John Gilmore 
@_subject: Re: responding to claims about TCPA 
Many of the people who "know something about TCPA" are constrained
by NDA's with Intel.  Perhaps that is Eric's problem -- I don't know.
(I have advised Intel about its security and privacy initiatives,
under a modified NDA, for a few years now.  Ross Anderson has also.
Dave Farber has also.  It was a win-win: I could hear about things
early enough to have a shot at convincing Intel to do the right things
according to my principles; they could get criticized privately rather
than publicly, if they actually corrected the criticized problems
before publicly announcing.  They consult me less than they used to,
probably because I told them too many things they didn't want to
One of the things I told them years ago was that they should draw
clean lines between things that are designed to protect YOU, the
computer owner, from third parties; versus things that are designed to
protect THIRD PARTIES from you, the computer owner.  This is so
consumers can accept the first category and reject the second, which,
if well-informed, they will do.  If it's all a mishmash, then
consumers will have to reject all of it, and Intel can't even improve
the security of their machines FOR THE OWNER, because of their history
of "security" projects that work against the buyer's interest, such as
the Pentium serial number and HDCP.
TCPA began in that "protect third parties from the owner" category,
and is apparently still there today.  You won't find that out by
reading Intel's modern public literature on TCPA, though; it doesn't
admit to being designed for, or even useful for, DRM.  My guess is
that they took my suggestion as marketing advice rather than as a
design separation issue.  "Pitch all your protect-third-party products
as if they are protect-the-owner products" was the opposite of what I
suggested, but it's the course they (and the rest of the DRM industry)
are on.  E.g. see the July 2002 TCPA faq at:
    3. Is the real "goal" of TCPA to design a TPM to act as a DRM or
     Content Protection device?   No.  The TCPA wants to increase the trust ... [blah blah blah]
I believe that "No" is a direct lie.  Intel has removed the first
public version 0.90 of the TCPA spec from their web site, but I have
copies, and many of the examples in the mention DRM, e.g.:
    (still there)
This TCPA white paper says that the goal is "ubiquity".  Another way to
say that is monopoly.  The idea is to force any other choices out of
the market, except the ones that the movie & record companies want.
The first "scenario" (PDF page 7) states: "For example, before making
content available to a subscriber, it is likely that a service
provider will need to know that the remote platform is trustworthy."
       (gone now)
Even this 200-page TCPA-0.90 specification, which is carefully written
to be obfuscatory and misleading, leaks such gems as: "These features
encourage third parties to grant access to by the platform to
information that would otherwise be denied to the platform" (page 14).
"The 'protected store' feature...can hold and manipulate confidential
data, and will allow the release or use of that data only in the
presence of a particular combination of access rghts and software
environment.  ... Applications that might benefit include ... delivery
of digital content (such as movies and songs)."  (page 15).
Of course, they can't help writing in the DRM mindset regardless of
their intent to confuse us.  In that July 2002 FAQ again:
  9. Does TCPA certify applications and OS's that utilize TPMs?   No.  The TCPA has no plans to create a "certifying authority" to
  certify OS's or applications as "trusted".  The trust model the TCPA
  promotes for the PC is: 1) the owner runs whatever OS or
  applications they want; 2) The TPM assures reliable reporting of the
  state of the platform; and 3) the two parties engaged in the
  transaction determine if the other platform is trusted for the
  intended transaction.
"The transaction"?  What transaction?  They were talking about the
owner getting reliable reporting on the security of their applications
and OS's and -- uh -- oh yeah, buying music or video over the Internet.
Part of their misleading technique has apparently been to present no
clear layman's explanations of the actual workings of the technology.
There's a huge gap between the appealing marketing sound bites -- or
FAQ lies -- and the deliberately dry and uneducational 400-page
technical specs.  My own judgement is that this is probably
deliberate, since if the public had an accurate 20-page document that
explained how this stuff works and what it is good for, they would
reject the tech instantly.
Perhaps we in the community should write such a document.  Lucky and
Adam Back seem to be working towards it.  The similar document about
key-escrow (that CDT published after assembling a panel of experts
including me, Whit, and Matt Blaze) was quite useful in explaining to
lay people and Congressmen what was wrong with it.  NSA/DoJ had
trouble countering it, since it was based on the published facts, and
they couldn't impugn the credentials of the authors, nor the
document's internal reasoning.
Intel and Microsoft and anonymous chauvanists can and should criticize
such a document if we write one.  That will strengthen it by
eliminating any faulty reasoning or errors of public facts.  But they
had better bring forth new exculpating facts if they expect the
authors to change their conclusions.  They're free to allege that "No
current Microsoft products have Document Revocation Lists", but that
doesn't undermine the conclusion that their architectures make it easy
to secretly implement that feature, anytime they want to.

@_date: 2002-08-11 18:15:28
@_author: John Gilmore 
@_subject: Re: Seth on TCPA at Defcon/Usenix 
Isn't this how Windows XP and Office XP work?  They let you set up the
system and fill it with your data for a while -- then lock up and
won't let you access your locally stored data, until you put the
computer on the Internet and "register" it with Microsoft.  They
charge less than a million dollars to unhand your data, but otherwise
it looks to me like a very similar scheme.
There's a first-person report about how Office XP made the computers
donated for the 9/11 missing persons database useless after several
days of data entry -- so the data was abandoned, and re-entered into a
previous (non-DRM) Microsoft word processor.  The report came through
this very mailing list.  See:
  This scenario of word processor vendors denying people access to their
own documents until they do something to benefit the vendor is not
just "plausible" -- it's happening here and now.

@_date: 2002-08-11 18:15:28
@_author: John Gilmore 
@_subject: Re: Seth on TCPA at Defcon/Usenix 
Isn't this how Windows XP and Office XP work?  They let you set up the
system and fill it with your data for a while -- then lock up and
won't let you access your locally stored data, until you put the
computer on the Internet and "register" it with Microsoft.  They
charge less than a million dollars to unhand your data, but otherwise
it looks to me like a very similar scheme.
There's a first-person report about how Office XP made the computers
donated for the 9/11 missing persons database useless after several
days of data entry -- so the data was abandoned, and re-entered into a
previous (non-DRM) Microsoft word processor.  The report came through
this very mailing list.  See:
  This scenario of word processor vendors denying people access to their
own documents until they do something to benefit the vendor is not
just "plausible" -- it's happening here and now.

@_date: 2003-06-13 05:35:12
@_author: John Gilmore 
@_subject: Re: An attack on paypal 
Yes; this is why (I think) VeriSign bought Network Solutions.  Then no
matter who wins the tussle over which infrastructure certifies
peoples' keys, VeriSign will own it.  Of course, canny spooks at SAIC
extracted billions of dollars from VeriSign for this privilege...after
extracting hundreds of millions from gullible public investors, and
extracting more from domain users via their official government
approved monopoly...

@_date: 2003-12-17 23:56:40
@_author: John Gilmore 
@_subject: The RIAA Succeeds Where the CypherPunks Failed 
Sent: Wednesday, December 17, 2003 12:29 PM
NEC @ Shirky.com, a mailing list about Networks, Economics, and Culture
            Published periodically /  / December 17, 2003
                Subscribe at            Social Software weblog at In this issue:
  - Introduction
  - Essay: The RIAA Succeeds Where the Cypherpunks Failed
      Also at   - Worth Reading:
     - GrokLaw: MVP of the SCO Wars
     - Tom Coates Talks With A Slashdot Troller
* Introduction =======================================================
The end of another year. Thank you all for reading. See you in January.
* Essay ==============================================================
The RIAA Succeeds Where the Cypherpunks Failed
   For years, the US Government has been terrified of losing surveillance
powers over digital communications generally, and one of their biggest
fears has been broad public adoption of encryption. If the average user
were to routinely encrypt their email, files, and instant messages,
whole swaths of public communication currently available to law
enforcement with a simple subpoena (at most) would become either
unreadable, or readable only at huge expense.
The first broad attempt by the Government to deflect general adoption of
encryption came 10 years ago, in the form of the Clipper Chip
[ The Clipper Chip was part of a
proposal for a secure digital phone that would only work if the
encryption keys were held in such a way that the Government could get to
them. With a pair of Clipper phones, users could make phone calls secure
from everyone except the Government.
Though opposition to Clipper by civil liberties groups was swift and
extreme [1] the thing that killed it was work by Matt Blaze, a Bell Labs
security researcher, showing that the phone's wiretap capabilities could
be easily defeated [2], allowing Clipper users to make calls that even
the Government couldn't decrypt. (Ironically, ATT had designed the
phones originally, and had a contract to sell them before Blaze sunk the
The Government's failure to get the Clipper implemented came at a heady
time for advocates of digital privacy -- the NSA was losing control of
cryptographic products, Phil Zimmerman had launched his Pretty Good
Privacy (PGP) email program, and the Cypherpunks, a merry band of
crypto-loving civil libertarians, were on the cover of
[ the second
issue of Wired. The floodgates were opening, leading to...
...pretty much nothing. Even after the death of Clipper and the launch
of PGP, the Government discovered that for the most part, users didn't
_want_ to encrypt their communications. The single biggest barrier to
the spread of encryption has turned out to be not control but apathy.
Though business users encrypt sensitive data to hide it from one
another, the use of encryption to hide private communications from the
Government has been limited mainly to techno-libertarians and a small
criminal class.
The reason for this is the obvious one: the average user has little to
hide, and so hides little. As a result, 10 years on, e-mail is still
sent as plain text, files are almost universally unsecured, and so on.
The Cypherpunk fantasy of a culture that routinely hides both legal and
illegal activities from the state has been defeated by a giant
distributed veto. Until now.
It may be time to dust off that old issue of Wired, because the RIAA is
succeeding where 10 years of hectoring by the Cypherpunks failed. When
shutting down Napster turned out to have all the containing effects of
stomping on a tube of toothpaste, the RIAA switched to suing users
directly. This strategy has worked much better than shutting down
Napster did, convincing many users to stop using public file sharing
systems, and to delete MP3s from their hard drives. However, to sue
users, they had to serve a subpoena, and to do that, they had to get
their identities from the user's internet service providers.
Identifying those users has had a second effect, and that's to create a
real-world version of the scenario that drove the invention of
user-controlled encryption in the first place. Whitfield Diffie,
inventor of public key encryption
[ the
strategy that underlies most of today's cryptographic products, saw the
problem as a version of "Who will guard the guardians?"
In any system where a user's identity is in the hands of a third party,
that third party cannot be trusted. No matter who the third party is,
there will be at least hypothetical situations where the user does not
want his or her identity revealed, but the third party chooses or is
forced to disclose it anyway. (The first large scale example of this
happening was the compromise of anon.penet.fi, the anonymous email
service, in 1995
[ Seeing that this problem
was endemic to all systems where third parties had access to a user's
identity, Diffie set out to design a system that put control of
anonymity directly in the hands of the user.
Diffie published theoretical work on public key encryption in 1975, and
by the early 90s, practical implementations were being offered to the
users. However, the scenario Diffie envisioned had little obvious
relevance to users, who were fairly anonymous on the internet already.
Instead of worrying now about possible future dangers, most users'
privacy concerns centered on issues local to the PC, like hiding
downloaded pornography, rather than on encrypting network traffic.
However, Diffie's scenario, where legal intervention destroys the users'
de facto privacy wherever it is in the hands of commercial entities, is
now real. The RIAA's successful extraction of user identity from
internet service providers makes it vividly clear that the veil of
privacy enjoyed by the average internet user is diaphanous at best, and
that the obstacles to piercing that veil are much much lower than for,
say, allowing the police to search your home or read your (physical)
mail. Diffie's hypothetical problem is today's reality. As a result,
after years of apathy, his proposed solution is being adopted as well.
In response to the RIAA's suits, users who want to share music files are
adopting tools like WINW (WINW Is Not WASTE) [ and
BadBlue [ that allow them to create encrypted
spaces where they can share files and converse with one another. As a
result, all their communications in these spaces, even messages with no
more commercial content than "BRITN3Y SUX!!!1!" are hidden from prying
eyes. This is not because such messages are sensitive, but rather
because once a user starts encrypting messages and files, it's often
easier to encrypt everything than to pick and choose. Note that the
broadening adoption of encryption is not because users have become
libertarians, but because they have become criminals; to a first
approximation, every PC owner under the age of 35 is now a felon.
The obvious parallel here is with Prohibition. By making it
unconstitutional for an adult to have a drink in their own home,
Prohibition created a cat and mouse game between law enforcement and
millions of citizens engaged in an activity that was illegal but
popular. As with file sharing, the essence of the game was hidden
transactions -- you needed to be able to get into a speakeasy or buy
bootleg without being seen.
This requirement in turn created several long-term effects in American
society, everything from greatly increased skepticism of Government-
mandated morality to broad support for anyone who could arrange for
hidden transactions, including organized crime. Reversing the cause did
not reverse the effects; both the heightened skepticism and the
increased power of organized crime lasted decades after Prohibition
itself was reversed.
As with Prohibition, so with file sharing -- the direct effects from the
current conflict are going to be minor and over quickly, compared to the
shifts in society as a whole. New entertainment technology goes from
revolutionary to normal quite rapidly. There were dire predictions made
by the silent movie orchestras' union trying to kill talkies, or film
executives trying to kill television, or television executives trying to
kill the VCR. Once those technologies were in place, however, it was
hard to remember what all the fuss was about. Though most of the writing
about file sharing concentrates on the effects on the music industry,
whatever new bargain is struck between musicians and listeners will
almost certainly be unremarkable five years from now. The long-term
effects of file sharing are elsewhere.
The music industry's attempts to force digital data to behave like
physical objects has had two profound effects, neither of them about
music. The first is the progressive development of decentralized network
models [], loosely bundled together under the rubric of peer-to-peer.
Though there were several version of such architectures as early as the
mid-90s such as ICQ and SETI it took Napster to ignite general
interest in this class of solutions.
And the second effect, of course, is the long-predicted and oft-delayed
spread of encryption. The RIAA is succeeding where the Cypherpunks
failed, convincing users to trade a broad but penetrable privacy for
unbreakable anonymity under their personal control. In contrast to the
Cypherpunks "eat your peas" approach, touting encryption as a
first-order service users should work to embrace, encryption is now
becoming a background feature of  collaborative workspaces. Because
encryption is becoming something that must run in the background, there
is now an incentive to make it's adoption as easy and transparent to the
user as possible. It's too early to say how widely casual encryption use
will spread, but it isn't too early to see that the shift is both
profound and irreversible.
People will differ on the value of this change, depending on their
feelings about privacy and their trust of the Government, but the
effects of the increased use of encryption, and the subsequent
difficulties for law enforcement in decrypting messages and files, will
last far longer than the current transition to digital music delivery,
and may in fact be the most important legacy of the current legal
* Worth Reading =======================================================
- GrokLaw: MVP of the SCO Wars
My colleague Elizabeth Lawley of RIT has convinced me that one of the
most profound effects of weblogs is the communal workings of those who
publish them, and that they contribute significant new value to
collaboration across disciplines and boundaries.
And now that she's convinced me, I see the pattern everywhere. The Dean
campaign piece I posted earlier today exhibits much of that pattern, and
so does today's Groklaw piece on SCO. By way of background, SCO, once a
technology company, has become a company devoted to a single legal
1. Assert rights to the Unix operating system
2. Assert infirnging contributions of Unix source code to Linux 3. Sue
firms that sell or use Linux, especially deep-pocketed IBM 4.
Profit!!!1! (or at least buyout by IBM, to save them the expense of the
Much of the matter is in dispute, and IANAL, but what is clear is
this: a) many SCO employees contributed to the Linux kernel, back when
SCO was a tech company ("oldSCO"), with the approval of their bosses,
and b) the Groklaw is doing an astonishing, world-changing job of
finding, documenting and publicizing these occurrences (alongside much
other work on the case.)
A recent GrokLaw entry reads:
   Groklaw has reported before on contributions made to the Linux
   kernel by Christoph Hellwig while he was a Caldera employee.  We
   have also offered some evidence of contributions by oldSCO employees
   as well.  Alex Rosten decided to do some more digging about the
   contributions of one kernel coder, Tigran Aivazian.
   [...]
   This paper is a group effort.  Alex's research was shared with
   others in the Groklaw community, who honed, edited, and added
   further research.  Then the final draft was sent to Tigran himself,
   so he could correct and/or amplify, which he has done.
   Look at that second graf: "This paper is a group effort." Everyone
always says that about complex work, but this is different. This is the
end of two-party law, where plaintiff and defendant duke it out in an
arms race of $350/hr laywers and "Take that" counter-motions.
Instead, we have a third party, Groklaw, acting as a proxy for millions
of Linux users, affecting the public perception of the case (and the
outcome SCO wants has to do with its stock price, not redress in the
courts.) Groklaw may also be affecting the case in the courts, by
helping IBM with a distributed discovery effort that they, IBM, could
never accomplish on their own, no matter how may lawyers they throw at
There are two ways to change the amount of leverage you have. The
obvious one is to put more force on the lever, and this is what SCO
thought they were doing -- engaging IBM in a teeter-totter battle that
would make it cheaper for IBM to simply buy SCO than to fight it out in
the courts.
The other way to get more leverage is to move the fulcrum. Groklaw has
moved the fulcrum of this battle considerably closer to SCO, making it
easier for IBM to exert leverage, and harder for SCO to. I can't predict
how the current conflict will end, but the pattern Groklaw has
established, of acting on behalf of the people who will be adversely
affected by a two-party legal battle, has already been vindicated, even
if SCO avoids bankruptcy.
- Tom Coates talks with a Slashdot troller:
Tom Coates, who has been talking on EverythingInModeration.org about his
travails with a persistent troll on the Barbelith community and his
subsequent attempts to ban that user, has elicited a response, which has
now become a conversation, with a slashdot troller. This troller,
posting as 20721, is arguing that any hidden moderation system helps
stimulate an arms race:
   i believe that it takes a certain amount of hubris to assume that
   the people you want to exclude are, by their nature, not as smart as
   you. you may be right about the people you're trying to exclude; i
   defer to your judgement, i'm not a member of the communities you
   are; but where i come from, the best & the brightest are the ones
   being cast out. they're cast out from communities by the following
   chain of events:
   1) secretive backhanded moderation tactic by the admins is discovered
   2) someone alerts the community
   3) the most technically apt in the community are able to reproduce
   the backhanded moderation tactic and verify its existence
   4) these people call foul and are labelled "trolls" for doing so,
   leading to the institution of more of 1) (repeat).
   this is how i started down the road i'm on. i was one of the many
   people who discovered that the people at slashdot were secretly
   moderating the users' comments, and one day they moderated the same
   comment 800 times - and then they lied about it, and said anyone who
   told the truth about it was a "troll". hence i became what they
   called me.
More, much more, at
* End
This work is licensed under the Creative Commons Attribution License.
The licensor permits others to copy, distribute, display, and perform
the work.  In return, licensees must give the original author credit.
To view a copy of this license, visit
or send a letter to
Creative Commons, 559 Nathan Abbott Way, Stanford, California 94305,
2003, Clay Shirky _______________________________________________
NEC - Clay Shirky's distribution list on Networks, Economics & Culture

@_date: 2004-07-09 21:31:02
@_author: John Gilmore 
@_subject: Re: EZ Pass and the fast lane .... 
[By the way, die is being left out of this conversation,
 by his own configuration, because his site censors all emails from me.  --gnu]
If they could read the license plates reliably, then they wouldn't
need the EZ Pass at all.  They can't.  It takes human effort, which is
in short supply.
Actually, cellphones DO have other identifying information in them,
akin to license plates.  And their "toll gates" are cell sites.
It's not clear what your remark about phones having no cars has to do
with the issue of whether EZ Pass is likely to be widely spoofed.
(1) Same one they have for releasing viruses or breaking into
thousands of networked systems.  Because they can; it's a fun way to
learn.  Like John Draper calling the adjacent phone booth via
operators in seven countries.  (2) The miscreant gets a cheap toll
along with hundreds of other people who get altered tolls.
[Cory Doctorow's latest novel (Eastern Standard Tribe, available free
online, or in bookstores) hypothesizes MP3-trading networks among
moving cars, swapping automatically with whoever they pass near enough
for a short range WiFi connection.  Sounds plausible to me; there are
already MP3 players with built-in short range FM transmitters, so
nearby cars can hear your current selection.  Extending that to faster
WiFi transfers based on listening preferences would just require "a
simple matter of software".  An iPod built by a non-DRM company might
well offer such a firmware option -- at least in countries where
networking is not a crime.  Much of the music I have is freely

@_date: 2004-07-09 20:27:11
@_author: John Gilmore 
@_subject: Re: EZ Pass and the fast lane .... 
Am I missing something?
It seems to me that EZ Pass spoofing should become as popular as
cellphone cloning, until they change the protocol.  You pick up a
tracking number by listening to other peoples' transmissions, then
impersonate them once so that their account gets charged for your toll
(or so that it looks like their car is traveling down a monitored
stretch of road).  It should be easy to automate picking up dozens or
hundreds of tracking numbers while just driving around; and this can
foil both track-the-whole-populace surveillance, AND toll collection.
Miscreants would appear to be other cars; tracking them would not
be feasible.
The rewriteable parts of the chip (for recording the entry gate to
charge variable tolls) would also allow one miscreant to reprogram the
transponders on hundreds or thousands of cars, mischarging them when
they exit.  Of course, the miscreant's misprogrammed transponder would
just look like one of the innocents who got munged.
[I believe, by the way, that the EZ Pass system works just like many
other chip-sized RFID systems.  It seems like a good student project
to build some totally reprogrammable RFID chips that will respond to a
"ping" with any info statically or dynamically programmed into them by
the owner.  That would allow these hypotheses to be experimentally tested.]

@_date: 2004-11-22 00:20:30
@_author: John Gilmore 
@_subject: Re: Gov't Orders Air Passenger Data for Test 
Effective at what?  Preventing people from traveling?
The whole exercise ignores the question of whether the Executive Branch
has the power to make a list of citizens (or lawfully admitted non-citizens)
and refuse those people their constitutional right to travel in the United
Doesn't matter whether there's 1, 19, 20,000, or 100,000 people on the
list.  The problem is the same: No court has judged these people.
They have not been convicted of any crime.  They have not been
arrested.  There is no warrant out for them.  They all have civil
rights.  When they walk into an airport, there is nothing in how they
look that gives reason to suspect them.  They have every right to
travel throughout this country.  They have every right to refuse a
government demand that they identify themselves.
So why are armed goons keeping them off airplanes, trains, buses, and
ships?  Because the US constitution is like the USSR constitution --
nicely written, but unenforced?  Because the public is too afraid of
the government, or the terrorists, or Emmanuel Goldstein, or the
boogie-man, to assert the rights their ancestors died to protect?
PS: Oral argument in Gilmore v. Ashcroft will be coming up in the
Ninth Circuit this winter.

@_date: 2004-11-22 00:20:30
@_author: John Gilmore 
@_subject: Re: Gov't Orders Air Passenger Data for Test 
Effective at what?  Preventing people from traveling?
The whole exercise ignores the question of whether the Executive Branch
has the power to make a list of citizens (or lawfully admitted non-citizens)
and refuse those people their constitutional right to travel in the United
Doesn't matter whether there's 1, 19, 20,000, or 100,000 people on the
list.  The problem is the same: No court has judged these people.
They have not been convicted of any crime.  They have not been
arrested.  There is no warrant out for them.  They all have civil
rights.  When they walk into an airport, there is nothing in how they
look that gives reason to suspect them.  They have every right to
travel throughout this country.  They have every right to refuse a
government demand that they identify themselves.
So why are armed goons keeping them off airplanes, trains, buses, and
ships?  Because the US constitution is like the USSR constitution --
nicely written, but unenforced?  Because the public is too afraid of
the government, or the terrorists, or Emmanuel Goldstein, or the
boogie-man, to assert the rights their ancestors died to protect?
PS: Oral argument in Gilmore v. Ashcroft will be coming up in the
Ninth Circuit this winter.

@_date: 2007-11-15 05:23:02
@_author: John Gilmore 
@_subject: Re: Intelligence Official: Say Goodbye To Privacy 
Here's Dr. Donald MacLean Kerr, Jr's original speech that led to the
AP story about security, privacy, and anonymity.  It's more nuanced
than what the AP reported, but still basically wrong.  At least
there's somebody high up who's saying we don't have to trade privacy
for security.  (Instead he says we have to trade anonymity for
OK, Dr. Kerr, what's your address, birth date, and SSN?  Where do your
kids live?  What, don't you trust us?  You want all that info about
us, and trust is a two-way street.
What do we have to trade, to be secure from you and the rest of the
corrupt federal government -- which is working tomorrow on granting
itself retroactive impunity for crimes of high treason?  Why should I
trust *you* more than I trust the average illegal immigrant?  Those
immigrants aren't part of an organization designed to do mass murder
and get away with it; you are.
Dr. Kerr, read _The Transparent Society_ by David Brin.  He's thought
about it more than you have.  He thinks to be safe from tyranny, we'll
have to get rid of both privacy AND anonymity.  But this will be much
safer than losing privacy and anonymity AND being subject to tyrants.

@_date: 2007-11-21 19:57:27
@_author: John Gilmore 
@_subject: Wikileaks: NSA funding of academics 
Grant code 'MDA904' - National Security Agency
The NSA has pushed tens or hundreds of millions into the academy
through research grants using one particular grant code.  ...

@_date: 2009-03-04 01:05:32
@_author: John Gilmore 
@_subject: Re: Judge orders defendant to decrypt PGP-protected laptop 
Balls.  This is a straight end-run attempt around the Fifth Amendment.
The cops initially demanded a court order making him reveal his
password -- then modified their stance on appeal after they lost.  So
he can't be forced to reveal it, but "on a technicality" he can be
forced to produce the same effect as revealing it?  Just how broad is
this technicality, and how does it get to override a personal
constitutional right?
If the cops bust down your door and you foolishly left your computer
turned on, are they entitled to make you reveal your encryption
passwords anytime later, because your encrypted drive was accessible
when they ran in screaming at your family and shooting your dog?
Suppose they looked it over and typed a few things to the screen?
Suppose they didn't?  Suppose they used a fancy power-transfer plug to
keep it running as they walked it out the door, but they tripped and
dropped it and it powered off?  That's a technicality, isn't it?
Don't forget, this is a nuisance case.  It's about a harmless Canadian
citizen who's a permanent US resident, who crossed the Canadian border
with his laptop.  A guy smart enough to encrypt his drive.  On the
drive, among other things, was a few thousand porn images downloaded
from the net.  Legal porn.  The border guards, who had no business
even looking at his laptop's contents, trolled around in it until they
found some tiny fraction of the images that (they allege) contained
underage models.  (How would *he* know the ages of the models in
random online porn?  Guess he'd better just store no porn at all,
whether or not porn is legal.  That's the effect that the bluenoses
who passed the "child porn" laws want, after all.)  That's the "crime"
being prosecuted here.  This isn't the Four Horsemen's
torture-the-terrorist-for-the-password hostage situation where lives
are at stake and the seconds are ticking away.  This is a pointless
search containing the only evidence of a meaningless censorship
non-crime.  If the feds can force you to reveal your password in this
hick sideshow, they can force it anytime.
Suppose the guy had powered off his laptop rather than merely
foolishly suspending it.  If the border guards had DRAM key recovery
tools that could find a key in the powered-down RAM, but then lost
the key or it stopped working, would you think he should later be
forced to reveal his password?
Suppose they merely possessed DRAM key recovery software, but never
deployed it?  Hey, we claim that you crossed the border with that key
in decaying RAM; fork over that password, buddy!
Don't give them an inch, they'll take a mile.  Drug users can now not
safely own guns, despite the Second Amendment.  Not even guns locked
in safes in outbuildings, because the law passed against "using a gun
in a drug crime" has been expanded by cops and judges to penalize
"having a gun anywhere on the property even though it was never
touched", and even when the only drug crime was simple possession.
Five year mandatory minimum sentence enhancement.  (Don't expect NRA
to help -- their motto is "screw the criminals, leave us honest people
alone".  That's no good when everybody's a criminal, especially the
honest people like this guy, who had nothing to hide from the border
guards and helped them search his laptop.)
There is no such document as "an unencrypted version of the Z drive".
It does not exist.  It has never existed.  One could in theory be
created, but that would be the creation of a new document, not the
production of an existing one.  The existing one is encrypted, and
the feds already have it.
I'm still trying to figure out what the feds want in this case if the
guy complies.  They'll have a border guard testify that he saw a
picture with a young teen in it?  They'll show the jury a picture of a
young teen, but won't "authenticate" it as a picture that came off the
hard drive?  It can just be any random picture of a young teen, that
could've come from anywhere?  How will that contribute to prosecuting
this guy for child porn?
Maybe they're just bored from training themselves by viewing official
federal child porn images (that we're not allowed to see), or
endlessly searching gigabytes of useless stuff on laptops.  Instead
they want the thrill of setting a precedent that citizens have no
right to privacy in their encrypted hard drives.  Let's not help them
by declaring this guy's rights forfeit on a technicality.

@_date: 2013-09-08 01:50:06
@_author: John Gilmore 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
DNSSEC authenticates keys that can be used to bootstrap
confidentiality.  And it does so in a globally distributed, high
performance, high reliability database that is still without peer in
the world.
It was never clear to me why DNSSEC took so long to deploy, though
there was one major moment at an IETF in which a member of the IESG
told me point blank that Jim Bidzos had made himself so hated that the
IETF would never approve a standard that required the use of the RSA
algorithm -- even despite a signed blanket license for use of RSA for
DNSSEC, and despite the expiration of the patent.  I thought it was an
extreme position, and it was very forcefully expressed -- but it was
apparently widely enough shared that the muckety-mucks did force the
standard to go back to the committee and have a second algorithm added
to it (which multiplied the interoperability issues considerably and
caused several years of further delay).
PS: My long-standing domain registrar (enom.com) STILL doesn't support
DNSSEC records -- which is why toad.com doesn't have DNSSEC
protection.  Can anybody recommend a good, cheap, reliable domain
registrar who DOES update their software to support standards from ten
years ago?
The cryptography mailing list

@_date: 2013-09-07 00:22:26
@_author: John Gilmore 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
Speaking as someone who followed the IPSEC IETF standards committee
pretty closely, while leading a group that tried to implement it and
make so usable that it would be used by default throughout the
Internet, I noticed some things:
  *  NSA employees participted throughout, and occupied leadership roles
     in the committee and among the editors of the documents
  *  Every once in a while, someone not an NSA employee, but who had
     longstanding ties to NSA, would make a suggestion that reduced
     privacy or security, but which seemed to make sense when viewed
     by people who didn't know much about crypto.  For example,      using the same IV (initialization vector) throughout a session,
     rather than making a new one for each packet.  Or, retaining a
     way to for this encryption protocol to specify that no encryption
     is to be applied.
  *  The resulting standard was incredibly complicated -- so complex
     that every real cryptographer who tried to analyze it threw up
     their hands and said, "We can't even begin to evaluate its
     security unless you simplify it radically".  See for example:
             That simplification never happened.
     The IPSEC standards also mandated support for the "null"
     encryption option (plaintext hiding in supposedly-encrypted
     packets), for 56-bit Single DES, and for the use of a 768-bit
     Diffie-Hellman group, all of which are insecure and each of which
     renders the protocol subject to downgrade attacks.
  *  The protocol had major deployment problems, largely resulting from
     changing the maximum segment size that could be passed through an
     IPSEC tunnel between end-nodes that did not know anything about
     IPSEC.  This made it unusable as a "drop-in" privacy improvement.
  *  Our team (FreeS/WAN) built the Linux implementation of IPSEC, but
     at least while I was involved in it, the packet processing code
     never became a default part of the Linux kernel, because of
     bullheadedness in the maintainer who managed that part of the
     kernel.  Instead he built a half-baked implementation that never
     worked.  I have no idea whether that bullheadedness was natural,
     or was enhanced or inspired by NSA or its stooges.
In other circumstances I also found situations where NSA employees
explicitly lied to standards committees, such as that for cellphone
encryption, telling them that if they merely debated an
actually-secure protocol, they would be violating the export control
laws unless they excluded all foreigners from the room (in an
international standards committee!).  The resulting paralysis is how
we ended up with encryption designed by a clueless Motorola employee

@_date: 2013-09-27 07:59:15
@_author: John Gilmore 
@_subject: Re: [Cryptography] RSA equivalent key length/strength 
Can the client recover and do something useful when the server has a
buggy (key length limited) implementation?  If so, a new cipher suite
ID is not needed, and both clients and servers can upgrade asynchronously,
getting better protection when both sides of a given connection are
running the new code.
In the case of (2) I hope you mean "yes we really do PFS with an
unlimited number of bits".  1025, 2048, as well as 16000 bits should work.
The cryptography mailing list

@_date: 2013-09-06 17:27:58
@_author: John Gilmore 
@_subject: Re: [Cryptography] IA side subverted by SIGINT side 
Then be "shocked, shocked" that the muscular exploitation side of an
intelligence agency would overrule the weak Information Assurance
side.  It happens over and over.
It even happens in companies that have no SIGINT side, like Crypto AG,
when somebody near the top is corrupted or blackmailed into submission.
As late as 1996, the National Academy of Sciences CRISIS panel was
tasked by the US Congress with coming up with a US crypto policy that
would be good for the whole nation, updating the previous policy that
was driven by spy agency and law enforcement excesses to sacrifice the
privacy and security of both people and companies.  After taking a
large variety of classified and unclassified input, the panel's
unanimous consensus suggested that everybody standardize on 56-bit
DES, which they KNEW was breakable.
Diffie, Hellman and Baran persuasively argued in the 1970s when DES
was up for standardization that a brute force DES cracker was
practical; they recommended longer keys than 56 bits.  See for example
this contemporaneous 1976 cassette recording / transcript:
  Subsequent papers in 1993 (Weiner, "Efficient DES Key Search") and in
1996 (Goldberg & Wagner, "Architectural Considerations for
Cryptanalytic Hardware") provided solid designs for brute-force DES
key crackers.  Numerous cryptographers and cypherpunks provided input
to the CRISIS panel as well.  They even cited these papers and input
on page 288 of their report.
I have never seen a subsequent accounting by the CRISIS panel members
for this obviously flawed recommendation.  It was rapidly obsoleted by
subsequent developments when in June 1997 Rocke Verser coordinated a
team to publicly crack DES by brute force in months; when in 1998 EFF
revealed its DES Cracker hardware that cost $250K and could crack DES
in a week; and when in 2000 the export regs were effectively removed
on any strength encryption in mass market and free software, a change
forced upon them by EFF's success in Dan Bernstein's First Amendment
The panel members included substantial information-assurance folks
like Marty Hellman and Peter Neumann, Lotus Notes creator Ray Ozzie,
and Willis Ware (an engineer on WW2 radars and the Johnniac, who later
spread computers throughout aviation design and the Air Force, ended
up at RAND, and served on the 1974 Privacy Act's Privacy Protection
Study Commission).  But several of those people (and others on the
panel such as Ann Caracristi, long-term NSA employee and 2-year deputy
director of NSA) also have a long history involved with classified
military work, which makes their publicly-uttered statements unlikely
to reflect their actual beliefs.
PS: The CRISIS panel also recommended that encryption of any strength
be exportable "if the proposed product user is willing to provide
access to decrypted information upon a legally authorized request".
They assumed the ongoing existence of a democratic civilian government
and a functioning independent court system in the United States -- an
assumption that is currently questionable.  I don't think the panel
foresaw that a single "legally authorized request" would come with a
gag order from a secret court, would purport to "target" a single
unnamed individual, but would nevertheless require that information
about every person making a phone call in the United States be turned
over to a classified government agency for permanent storage and
exploitation.  Nor did they see that the government they were part of
would be committing serious international war crimes including political
assassination, torture, indefinite detention without trial, and wars
of aggression, on an ongoing basis.  Either that, or maybe NSA
blackmailed the committee members into these recommendations, just as
J. Edgar Hoover blackmailed his way through 40 years of unchecked
power.  Trouble is, Hoover eventually had to die; NSA, not being
human, does not have that natural limit.
The cryptography mailing list

@_date: 2013-09-18 01:02:27
@_author: John Gilmore 
@_subject: [Cryptography] FISA court releases its "Primary Order" re telephone metadata 
The FISA court has a web site (newly, this year):
  Today they released a "Memorandum Opinion and Primary Order" in case BR 13-109 ("Business Records, 2013, case 109"), which lays
out the legal reasoning behind ordering several telephone companies
to prospectively give NSA the calling records of every subscriber.
That document is here:
  I am still reading it...
The cryptography mailing list

@_date: 2013-10-05 18:00:45
@_author: John Gilmore 
@_subject: [Cryptography] System level security in "low end" environments 
Such environments are getting very rare these days.  For example, an
electrical engineer friend of mine was recently working on designing a
cheap aimable mirror, to be deployed by the thousands to aim sunlight
at a collector.  He discovered that connectors and wires are more
expensive than processor chips these days!  So he ended up deciding to
use a system-on-chip with a built-in radio that eliminated the need to
have a connector or a wire to each mirror.  (You can print the antenna
on the same printed circuit board that holds the chip and the
What dogs the security of our systems these days is *complexity*.  We
don't have great security primitives to just drop into place.  And the
ones we do have, have complicated tradeoffs that come to the fore
depending on how we compound them with other design elements (like
RNGs, protocols, radios, clocks, power supplies, threat models, etc).
This is invariant whether the system is "low end" or "high end".
That radio controlled mirror can be taken over by a drive-by attacker
in a way that would take a lot more physical labor to mess up a
wire-controlled one.  And if the attack aimed two hundred mirrors at
something flammable, the attacker could easily start a dangerous fire
instead of making cheap solar energy.  (Denial of service is even
easier - just aim the mirrors in random directions and the power goes
away.  Then what security systems elsewhere were depending on that
power?  This might just be one cog in a larger attack.)  Some of the
security elements are entirely external to the design.  For example,
is the radio protocol one that's built into laptops by default, like
wifi or bluetooth?  Or into smartphones?  Or does it require custom
hardware?  If not, a teenager can more easily attack the mirrors --
and a corrupt government can infect millions of laptops and phones
with malware that will attack mirror arrays that they come near to.
For products that never get made in the millions, the design cost
(salaries and time) is a significant fraction of the final cost per
unit.  Therefore everybody designs unencrypted and unauthenticated
stuff, just because it's easy and predictable.
For example it's pretty easy to make the system-on-chip above send or
receive raw frames on the radio.  Harder to get it to send or receive
UDP packets (now it needs an IP address, ARP, DHCP, more storage, ...).
Much harder to get it to send or receive *authenticated* frames or UDP
packets (now it needs credentials; is it two-way authenticated, if so
it needs a way to be introduced to its system, etc).  Much harder
again to get it to send or receive *encrypted* frames or UDP packets
(now it needs keys too, and probably more state to avoid replays,
etc).  And how many EE's who could debug the simple frame sending
firmware and hardware, can debug a crypto protocol they've just
implemented (even making the dubious assumpion that they compounded
the elements in a secure way and have just made a few stupid coding
The cryptography mailing list

@_date: 2013-10-15 01:53:58
@_author: John Gilmore 
@_subject: Re: [Cryptography] "/dev/random is not robust" 
I'll be the first to admit that I don't understand this paper.  I'm
just an engineer, not a mathematician.  But it looks to me like the
authors are academics, who create an imaginary construction method for
a random number generator, then prove that /dev/random is not the same
as their method, and then suggest that /dev/random be revised to use
their method, and then show how much faster their method is.  All in
all it seems to be a pitch for their method, not a serious critique of
They labeled one of their construction methods "robustness", but it
doesn't mean what you think the word means.  It's defined by a mess of
greek letters like this:
  Theorem 2. Let n > m, ,   be integers. Assume that G :
  {0, 1}m  {0, 1}n+ is a deterministic (t, prg )- pseudorandom
  generator. Let G = (setup, refresh, next) be defined as above. Then
  G is a ((t , qD , qR , qS ),   , )- 2 robust PRNG with
  input where t  t,  = qR (2prg +qD ext +2n+1 )
  as long as    m+2 log(1/ext )+1, n  m + 2
  log(1/ext ) + log(qD ) + 1.
Yeah, what he said!
Nowhere do they seem to show that /dev/random is actually insecure.
What they seem to show is that it does not meet the "robustness"
criterion that they arbitrarily picked for their own construction.
Their key test is on pages 23-24, and begins with "After a state
compromise, A (the adversary) knows all parameters."  The comparison
STARTS with the idea that the enemy has figured out all of the hidden
internal state of /dev/random.  Then the weakness they point out seems
to be that in some cases of new, incoming randomness with
mis-estimated entropy, /dev/random doesn't necessarily recover over
time from having had its entire internal state somehow compromised.
This is not very close to what "/dev/random is not robust" means in
English.  Nor is it close to what others might assume the paper
claims, e.g. "/dev/random is not safe to use".
PS: After attending a few crypto conferences, I realized that
academic pressures tend to encourage people to write incomprehensible
papers, apparently because if nobody reading their paper can
understand it, then they look like geniuses.  But when presenting at
a conference, if nobody in the crowd can understand their slides, then
they look like idiots.  So the key to understanding somebody's
incomprehensible paper is to read their slides and watch their talk,
80% of which is often explanations of the background needed to
understand the gibberish notations they invented in the paper.  I
haven't seen either the slides or the talk relating to this paper.

@_date: 2013-10-28 08:20:58
@_author: John Gilmore 
@_subject: Re: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
What else is on your LAN besides a network switch?  Do you have a
printer with an Ethernet jack?  Or a DSL modem?  Or a cable modem?  Or
a low-end commercial NAS box?  All of these typically run an embedded
system using some old version of Linux, and never get their firmware
updated to close zero-day security holes.  If one of them can be taken
over, and can convince your network switch to send them all the
packets (perhaps by ARP flooding or ARP spoofing), then that embedded
system can wiretap any LAN transaction it likes.  Many DSL modems contain a small switch, which if it's the only switch
in a small home or office network, would make all packets among local
nodes accessible to malware running in that DSL modem.
Many cheap Ethernet switches are 'intelligent' meaning that they have
an embedded processor that offers a Web configuration interface.
Such devices are fertile malware targets.
Automated global-scale attacks against such embedded systems are
certainly feasible.  Could the injected code be sufficiently subtle to
detect and store or report entropy events like packet timing, without
becoming sufficiently obvious that the malware's presence is detected
on the network?
PS: On the "big iron" rather than "small network" end of things, don't
forget virtual machines, in which a compromised VM hypervisor has full
access to all the packets (and to many other aspects of the machines
running under it).
The cryptography mailing list

@_date: 2013-10-28 08:20:58
@_author: John Gilmore 
@_subject: Re: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
What else is on your LAN besides a network switch?  Do you have a
printer with an Ethernet jack?  Or a DSL modem?  Or a cable modem?  Or
a low-end commercial NAS box?  All of these typically run an embedded
system using some old version of Linux, and never get their firmware
updated to close zero-day security holes.  If one of them can be taken
over, and can convince your network switch to send them all the
packets (perhaps by ARP flooding or ARP spoofing), then that embedded
system can wiretap any LAN transaction it likes.  Many DSL modems contain a small switch, which if it's the only switch
in a small home or office network, would make all packets among local
nodes accessible to malware running in that DSL modem.
Many cheap Ethernet switches are 'intelligent' meaning that they have
an embedded processor that offers a Web configuration interface.
Such devices are fertile malware targets.
Automated global-scale attacks against such embedded systems are
certainly feasible.  Could the injected code be sufficiently subtle to
detect and store or report entropy events like packet timing, without
becoming sufficiently obvious that the malware's presence is detected
on the network?
PS: On the "big iron" rather than "small network" end of things, don't
forget virtual machines, in which a compromised VM hypervisor has full
access to all the packets (and to many other aspects of the machines
running under it).
The cryptography mailing list

@_date: 2013-10-22 21:51:02
@_author: John Gilmore 
@_subject: Re: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Any computer that checks parity on its main memory, or uses ECC error
correcting codes on its main memory, will have to initialize its main
memory after power-on.  In x86's this is often done by the BIOS.
Failing to do this initialization would cause later main memory reads
of uninitialized variables to produce spurious parity or ECC errors
(spurious in the sense that the memory chip has not failed to retain a
value previously written to it).
Many modern memory controller chips automatically support parity or ECC,
depending on which memory DIMMs are plugged in.  One extra bit per byte
allows parity protection or (with 64-bit buses) ECC.
The cryptography mailing list

@_date: 2013-10-23 01:11:31
@_author: John Gilmore 
@_subject: Re: [Cryptography] programable computers inside our computers 
It is probably ALREADY running there.
With regard to the invisible single-chip computer that sits on every
server's motherboard (thanks, you idiots at Intel), I can't say it any
better than Dan Farmer:
  IPMI: Express Train to Hell, v2.0
  dan farmer/zen
  The cryptography mailing list

@_date: 2013-10-23 01:11:31
@_author: John Gilmore 
@_subject: Re: [Cryptography] programable computers inside our computers 
It is probably ALREADY running there.
With regard to the invisible single-chip computer that sits on every
server's motherboard (thanks, you idiots at Intel), I can't say it any
better than Dan Farmer:
  IPMI: Express Train to Hell, v2.0
  dan farmer/zen
  The cryptography mailing list

@_date: 2013-10-28 19:56:53
@_author: John Gilmore 
@_subject: Re: [Cryptography] DSL modems - how would we detect wholesale subversion? 
And most DSL modems are provided by your giant telco DSL provider --
such as AT&T -- which we already know has a long history of covertly
sucking up to NSA.  Besides their longstanding cooperation on domestic
and foreign fiber taps, they also produced the first-and-only Clipper
Chip subverted "telephone security device" for making voice calls that
"nobody but NSA" could listen to.  How hard would it be, really, for
them to subvert all their DSL modems to wiretap your LAN?
And how would you know if they had done so?  It's so convenient that
all AT&T DSL modems have a high bandwidth upstream connection to
AT&T's central office switches.  And even better that consumers have
no idea what packets are going up and down over that DSL signalling,
because they have no equipment for monitoring raw 2-wire DSL lines
(the way they could fairly easily detect inappropriate packets
traveling on an Ethernet, with a little free software and a little
replugging of Ethernet equipment).
Your DSL modem could be doing its main job (carrying your external
Internet traffic) using whatever fraction of the available bandwith
that requires in each millisecond, and using any spare capacity on the
DSL wire to mirror a select fraction, or all, of your local LAN
traffic up to the central office switch.  The switch would nominally
discard this 'filler traffic' -- but AT&T would be able to copy it to
NSA upon request, either by individual targeting of particular
customers, or wholesale.  In the better subverted DSL modems, the
filler/tap traffic would be fully encrypted between the modem and the
switch, so that even if you got professional equipment for monitoring
the DSL wire back to the central office, all you would see is 'random'
filler packets all the time.
Suppose AT&T and NSA really had no interest in doing this to you --
unlikely, I know -- but the Chinese manufacturers of DSL modems did
have such an interest?  The threat model is very similar, except the
Chinese would have to subvert the AT&T central office switches
covertly, without AT&T's willing cooperation, to extract your LAN
traffic from them.
You can guard against this threat by only plugging one Ethernet jack
into your DSL modem, and having that lead directly to a Linux or BSD
gateway box that is under your own control.  That way, the DSL modem
has no physical access to the rest of your LAN, and you can monitor
the upstream Ethernet to make sure that the only packets going to the
DSL modem are those that you intended to go upstream.
The cryptography mailing list

@_date: 2013-10-28 19:56:53
@_author: John Gilmore 
@_subject: Re: [Cryptography] DSL modems - how would we detect wholesale subversion? 
And most DSL modems are provided by your giant telco DSL provider --
such as AT&T -- which we already know has a long history of covertly
sucking up to NSA.  Besides their longstanding cooperation on domestic
and foreign fiber taps, they also produced the first-and-only Clipper
Chip subverted "telephone security device" for making voice calls that
"nobody but NSA" could listen to.  How hard would it be, really, for
them to subvert all their DSL modems to wiretap your LAN?
And how would you know if they had done so?  It's so convenient that
all AT&T DSL modems have a high bandwidth upstream connection to
AT&T's central office switches.  And even better that consumers have
no idea what packets are going up and down over that DSL signalling,
because they have no equipment for monitoring raw 2-wire DSL lines
(the way they could fairly easily detect inappropriate packets
traveling on an Ethernet, with a little free software and a little
replugging of Ethernet equipment).
Your DSL modem could be doing its main job (carrying your external
Internet traffic) using whatever fraction of the available bandwith
that requires in each millisecond, and using any spare capacity on the
DSL wire to mirror a select fraction, or all, of your local LAN
traffic up to the central office switch.  The switch would nominally
discard this 'filler traffic' -- but AT&T would be able to copy it to
NSA upon request, either by individual targeting of particular
customers, or wholesale.  In the better subverted DSL modems, the
filler/tap traffic would be fully encrypted between the modem and the
switch, so that even if you got professional equipment for monitoring
the DSL wire back to the central office, all you would see is 'random'
filler packets all the time.
Suppose AT&T and NSA really had no interest in doing this to you --
unlikely, I know -- but the Chinese manufacturers of DSL modems did
have such an interest?  The threat model is very similar, except the
Chinese would have to subvert the AT&T central office switches
covertly, without AT&T's willing cooperation, to extract your LAN
traffic from them.
You can guard against this threat by only plugging one Ethernet jack
into your DSL modem, and having that lead directly to a Linux or BSD
gateway box that is under your own control.  That way, the DSL modem
has no physical access to the rest of your LAN, and you can monitor
the upstream Ethernet to make sure that the only packets going to the
DSL modem are those that you intended to go upstream.
The cryptography mailing list

@_date: 2013-11-07 00:08:33
@_author: John Gilmore 
@_subject: Re: [Cryptography] randomness +- entropy 
You're right -- but this conflicts with "secure boot" schemes that
want to know the image is "authentic" (i.e. signed by a private key
that isn't on the local machine) before it is permitted to run.
(A secondary and more tractable problem is that the running system may
not know exactly where it was booted from, and may not have write
access to that location.  Consider a network boot via PXE or TFTP --
or a system booting from a read-only drive, which in other
circumstances we would applaud as a security improvement.)
It would be unsound to make such systems fail -- since
there are millions already in use, and if putting a newer
OS release on them would cause them to fail, people won't
bother putting a newer OS release on them.  So, if they don't
fail, what should we do to declare them "unsound" in a way
that the system user can detect (and ignore or fix)?
The cryptography mailing list

@_date: 2014-07-25 00:36:04
@_author: John Gilmore 
@_subject: Re: [Cryptography] hard to trust all those root CAs 
NSL's don't involve a judge.  Nor even a prosecutor.  They are an
investigative tactic, used by the FBI (or the FBI proxying for NSA),
long before a prosecutor is usually involved.
The more likely it is that you will disclose a government request for
snitching on your customers, the less likely it is that that request
will ever arrive.  Shining sunlight on spook activities is the best
way to make them crawl back into their hole.
Chuckle chuckle, just like the headlines about marijuana reform for
decades.  First they laugh at you, etc.  But the joke doesn't excuse
the iron fist you are trying to invoke to influence people.
Mr. Kelsey, you usually don't fall to this level of "be afraid, the
[government] terrorists are coming" propaganda.
Ladar Levison, Mr. Lavabit, the last guy to do exactly what was
suggested, is still out walking the streets -- and starting new
companies that offer to protect their customers from covert
surveillance.  As often occurs, the spooks were less interested in
smashing a guy who's standing up for the rights of the public, than
they were in preventing a detailed public airing of what they were up
to when they ran into him.
The cryptography mailing list

@_date: 2014-10-22 14:12:37
@_author: John Gilmore 
@_subject: Re: [Cryptography] Best internet crypto clock:  hmmmmm... 
That's fascinating!  Turning an annoyance of audio engineers and home
stereos into a forensic tool.
But once the technique is known, it can be forged, by pasting a
recording of the "hum" from one time or place, into a recording made
or edited at another time or place.  It would be amusing to file a
FOIA request for the FBI's recordings of US power networks' hum, and watch them squirm trying to find a reason why you couldn't have it.
Also, in theory, even if nobody was recording the hum continuously,
the hum could be extracted from two or more existing recordings and
compared to determine whether they happened at the same time (or
copied to another recording).  For example, two concerts that were
recorded at the same time should show the same hum if they were done
within the same power grid.
Isn't there also some research showing that over time, you can tell
what time zone a remote computer is in, by pinging it for timestamps,
and noticing when its oscillators run minutely faster during the heat
of the day, and slower during the cool of the night?
The cryptography mailing list

@_date: 2014-11-19 04:29:37
@_author: John Gilmore 
@_subject: Re: [Cryptography] STARTTLS, was IAB Statement on Internet Confidentiality 
Censorship of customer communications is always a "best practice"
according to some people.  Blocking communications based on the port
number in use?  That seems to many people to be heinous, "picking winners and losers", discriminating against
traffic based on what the endpoint services are, etc.  Wasn't
Network Neutrality supposed to outlaw all such discrimination?
Or, is it a catchphrase for "only the politically correct people
are allowed to censor or discriminate against traffic"?
The fact that some ISPs covertly built that censorship into a
supposedly transparent network must be why I never get any spam these
days.  But it doesn't matter to zealots whether their methods actually
work or not.  They're mad at spammers, and "Hulk smash" is their main
response.  Reason, principle, protocols, and respect all went out the
Anti-spammers have done far more damage to the Internet than spammers.
Now they are claiming that we can't be permitted to encrypt our
Internet connections because then their censorship scheme would stop
working?  I don't see any spammers claiming that end users should not
be permitted to encrypt their emails nor any other traffic.  To take
the privacy of our communications into our own hands, it is the
anti-spammers who stand in our way, not the spammers.
Exactly -- an anti-spammer group, the "Messaging, Malware and Mobile
Anti-Abuse Working Group", MAAWG.  Hmm, there seem to be more M's in
there than in their domain name.  Perhaps once they started advocating
censorship for one reason ("Messaging"), they found all sorts of
other reasons for it, too.  When you have a censorship hammer, every
problem looks like a need for censorship.
       (who regularly, daily, gets his personally typed emails - just
        like this one -- censored without recourse, by the ISPs of
        recipients who rely on unreliable third party censorship
        blacklists.)
The cryptography mailing list

@_date: 2015-02-17 21:32:44
@_author: John Gilmore 
@_subject: Re: [Cryptography] Equation Group Multiple Malware Program, NSA Implicated 
The simplest thing it can do is to read out malware-infested boot
code, but only right after reset (or during a pattern of accesses that
the BIOS uses during startup).  Anytime those sectors are read after
that, they appear to be perfectly normal.  And if you write to them,
they don't overwrite the malware.
If the system isn't using Full Disk Encryption, then there's lots more
that active disk drive malware can do.  All the instructions for all
the software that runs in the system are on the disk drive.  You
effectively have a man-in-the-middle attack between the CPU and the
drive platters, which can substitute data (e.g. the password file,
your .ssh config and cache), code (the login program), keys, web
server content (to attack people who access your web server), etc.
A mere disk drive, if properly programmed, can make your web server
serve different pages to different clients (including attack malware
to certain clients), examine the logfiles being written to itself in
order to detect incoming web accesses and respond individually to
them, etc.  Systems are just not written to assume malware in disk
drives, so they don't hide information from it that would help it
do nefarious things.
Once there's a MITM beachhead in the drive firmware, it can also be
configured to backdoor any number of likely installation candidates,
not just the software that happens to be installed on the drive at
that time.  So reinstalling the OS, or a later OS, or any OS
that boots with GRUB, say, doesn't present a problem to NSA.
If the system is using full disk encryption, then it needs to know the
keys and algorithms so it can see plaintext, but is otherwise the
same.  (Note that many disk drives now offer full disk
DRIVE-CONFIGURED AES encryption, done transparently to the software.
Just how much do you trust those drives?)
The cryptography mailing list

@_date: 2015-02-17 20:05:10
@_author: John Gilmore 
@_subject: Re: [Cryptography] Equation Group Multiple Malware Program, NSA Implicated 
This is a fascinating discussion.
It seems, both from listening to Mr. Snowden's descriptions of the
work environment inside NSA, and from some of the documents that he
released through the press or that have been declassified since his
inspiration, that NSA's internal networks are generally not encrypted.
They seem to operate in the clear (except with link encryption when
they go outside secure facilities).
This to me is the height of foolishness, unless NSA finds itself unable
to develop crypto protocols any better than the open world.
NSA basically uses the same computers and the same operating systems
internally as what we see in the sane world.  They have nothing
better!  And since in the sane world, we can't get working end-to-end
encryption in a way that a large organization can sanely manage, they
don't seem to have it either.
NSA likes to project an image of importance and invulnerability, but I
am coming to believe that instead they are more like petty thieves,
like jays stealing pretty trinkets from the public for their
collection.  Thieves that are paid with tax dollars and receive
impunity for their misdeeds can do a lot of minor damage.  Thieves
that can covertly influence policies imposed by a government that has
run roughshod over all the fences that were designed 200 years ago to
keep it from becoming despotic are much more dangerous.  Weinberg's
Second Law, "If builders built buildings the way programmers write
programs, then the first woodpecker that came along would destroy
civilization," was more prescient than Weinberg realized.  NSA are the
first woodpeckers, and they are doing their best to destroy
civilization for their own benefit.  We now see plenty of other birds
noting the rich pickings and flocking together with NSA.  Their
ugly colors are more readily visible to us -- as destructive malware,
cyber thieves, organized crime, and cyber war against civilian
I find it ironic that my efforts toward scalable "opportunistic
encryption" protocols and implementations might eventually allow NSA
to encrypt their own internal network.  But it will be worth it if
we can also encrypt the large bulk of the sane world, helping to
protect the public against the birds that would be happy to eat the
seed corn of civilization -- fundamental rights of privacy and
personal autonomy.
It's particularly ironic since NSA has been actively working in
standards committees to defeat public efforts to standardize better
encryption, particularly end-to-end encryption.  The reason they can't
encrypt their own networks is because they have used their influence
and our tax dollars to deter the rest of us from doing so.  Not only
have they shot themselves in the foot -- we're ALL limping because
the thieves have taken over the asylum at NSA.
Back in the '90s during the First Crypto War, it took me a while but I
eventually figured out that in the organization of the US Government,
there was nobody below the level of the Vice President whose job it was
to figure out what the best crypto policy was for the whole society.
Every agency had the incentive to tug the crypto policy in whatever
direction would make that agency's job easier.  State Dept, Commerce
Dept, NSA, Justice Dept, euphemistic Dept. of War, all sat on the
internal secret committees and all pulled for their own convenience.
The policies that resulted varied, basically depending on which agency
had strong personalities pushing hardest at the time.  Not a one of
the agencies had an eye out for the *public* interest.  (Further, NSA
sees its interest as making it easier to steal and disrupt
information, rather than easier to secure information, even though it
theoretically has both missions.)
Eventually I realized that *I* was in a better position to figure out
a good crypto policy for the whole society, than anyone inside the
government.  Even when participants like NSA weren't telling the
whole story and were actively lying about the impacts of various
policies.  Because at least I didn't have a hidden agenda of making
my own job easier.
That made me feel better about putting serious effort into creating
crypto code and crypto policies that matched my intuitions about what
would be best for the public.  And explained why the government was
clueless and incompetent at doing so.
Even the National Academy of Sciences' CRISIS report, a supposedly
independent body who took input from everybody, ended up recommending
that the policy should push everyone to use DES (by making everything
stronger non-exportable), even though multiple academics starting with
Diffie in the '70s had broken DES by brute force in paper designs.  By
then EFF was (privately) well on its way to building the physical
machine that proved to the world that DES was useless and therefore
that the CRISIS report was fatally flawed.
And nobody except EFF and a few supporters cared that the export
controls on encryption violated the fundamental rights of freedom of
speech and academic freedom of inquiry.  For that argument, we got
zero support from government agencies (though the initial clue did
come from a little known publication of the DoJ Office of Legal
Counsel, DoJ and NSA opposed us every step of the way), no support
from Congress, no support from the White House, little support from
commercial companies, and not even much from academics.
Constitutional rights seemed to them a quaint anachronism, a speed
bump that had already been passed decades ago, useless in the
hurly-burly of the market and in the political compromise process.
But that was the argument that ultimately forced a policy change, via
the federal courts, because the export controls on software
publications were BLATANTLY unconstitutional, a quintessential
licensing regime for censoring protected speech.
But the thieves found a defense against that.  In the intervening
decades they have hobbled the federal courts via the "state secrets
doctrine" -- so now anytime you sue them over something that the
spooks are doing, they just throw the case out.  But how else could
the federal government defend indefinite imprisonment without trial,
torture, indiscriminate mass wiretapping, a prior restraint licensing
scheme for travel, and their other serious crimes infringing
fundamental personal rights that we haven't yet discovered?  If the
courts had remained honest, these crooks would be out of a job.  From
the agencies' point of view (again not seeking the best result for the
public), it's better to screw up the courts than to get caught at
destroying another few cornerstones of civilization.
The cryptography mailing list

@_date: 2015-02-24 03:12:16
@_author: John Gilmore 
@_subject: Re: [Cryptography] trojans in the firmware 
That would be somewhat true on a disk drive, but not on a flash drive.
On a flash drive, the "Secure Erase" command is supposed to restore
the flash chips to their original performance, i.e. it's supposed to
actually erase all the write blocks, so that they can be efficiently
written without a slow erase cycle later.  This will take the same
amount of time, regardless of whether the data was encrypted or not.
Merely dumping the key leaves all the erase blocks full of data,
requiring that each one go through a slow erase cycle before each one
can be overwritten by new data.
The Secure Erase Extended command is also supposed to zeroize the
areas of the drive that might contain user data but which aren't
accessible via the normal read and write commands -- such as spare
sectors that may have had user data in the past, before or after an
error recovery sequence.  This is what distinguishes it from the
regular Erase command.
The UCSD Non-Volatile Systems Lab (a spinoff from their disk drive
research hotbed, the Center for Magnetic Recording Technology) tested
the Secure Erase features in a selection of SSD's, by writing
patterned data to every sector, then issuing Secure Erase, then
pulling out the drive and taking it apart and reading the flash chips
directly.  They didn't name the vendors, but they did find at least
one vendor whose "Secure Erase" command returned immediately without
an error, but didn't actually erase ANYTHING.  And many which only did
partial erasures, leaving the data patterns visible in some parts of
the flash chips.  See:
  The paper below, from USENIX 2013, describes some of the challenges
involved in the bizarre internal write performance of modern flash
chips (which Secure Erase is supposed to re-initialize):
  The cryptography mailing list

@_date: 2015-02-24 01:22:35
@_author: John Gilmore 
@_subject: Re: [Cryptography] trojans in the firmware 
You have an odd definition of "everyone".  Disk drives still matter.
The One Laptop Per Child (OLPC) project was the first to design and
ship laptops with no hard drive, only flash.  They started with bare
flash, using Linux flash file system support.  It turned out that that
was a problem for several reasons.
The Linux flash file systems were initially built for very small
devices.  When run on larger raw flash chips, they added many seconds
to the boot time, merely to scan all the flash blocks and build an
in-memory index of them.  OLPC spent some programmer time and improved
the flash file systems, but they were still pretty clunky and had
almost zero mass market burnin time, compared with the disk-based file
systems like ext2, ext3, ext4, or even the oddball file systems like
ZFS or ReiserFS, that have millions of daily users.
But much more important to OLPC was the dynamics of the flash market.
With each new generation of flash parts, the interfaces to the parts
changed.  They needed more or fewer wires, more or less voltage, more
or less current, more or less time for each kind of access.  They have
increasingly bizarre programming and erasure algorithms.  Merely
reading a cell in some raw flash chips perturbs the data stored in
nearby cells!  It became clear that long-lived systems designed to use
a particular flash interface would be stuck at that year's capacity
forever, with commodity parts harder and harder to find cheaply,
despite or rather because of rapid capacity increases across the
industry over time.  For example, their early devices used
single-level flash cells; later ones used multilevel cells.  The
single level cells can be erased and reused hundreds of thousands of
times; in multilevel cells the limit was only a few thousand.  But
multilevel had higher capacity.
They ultimately solved their design problem, procurement problem, and
programming problem by designing to use *mediated* flash, that comes
bundled with a dedicated controller -- SD cards, microSD cards, and
eMMC modules, all of which have the same electrical interface and
programming interface.  See e.g.:
  This lets their laptops upgrade what used to be a gigabyte of flash to
up to 32 gigs without changing the interface.  Of course this solution
adds other issues -- such as finding bugs or malice in the firmware in
the flash controllers.  Flash controller firmware is *complicated*
because it implements its own file system to pretend that flash chips
are just a series of working read/write sectors like disk drives.
They also do "wear leveling", moving the data around on the chips to
avoid doing too many writes to any given flash sector, and to try to
hide the erase latency.  Complex firmware means that bugs are
unavoidable, and obscure performance issues are very likely.  And there
are no free software implementations of flash controller firmware, so
you can't scrutinize the code yourself without using serious forensic
What distinguishes SD cards from ordinary MMC flash cards is that the
SD cards contain malicious firmware designed by Hollywood to let the
cards store information that the owner cannot access (we would call it
"DRM" but they call it "Secure Digital").  99% of devices with an SD
card slot don't use the DRM features (which were designed for MP3
players), but SD had much better marketing than MMC, so consumers
started demanding "SD" cards.  Of course this DRM leaves a nice back
door for NSA or other bad actors to cache information in SD cards
against the will of the card's owner or the owner of the system it
runs in.  I don't know of anyone who's surveyed the DRM
implementations on modern SD cards to even see how much of it works at
this point.  Since almost nobody uses the DRM code, vendors may be
leaving it out but using the SD logo anyway.  And if they keep it in,
that unexercised code is another highly probable source of exploitable
There are proprietary commands for reflashing the firmware on many SD
cards (which usually boot their controllers from firmware stored on
the flash chips themselves).  I expect that NSA knows them, just like
it has stolen or compelled the info needed to reflash disk drive
firmware for ten companies' disk drives.
Oh, one more big issue about the flash market.  Nobody, not even the
big vendors, can tell whether a given product was made by their
factory and sold through legitimate channels, or was made by a
fly-by-night vendor and labeled with a mainstream company's logo.
(There's a 3rd level - ghost runs -- which are made in mainstream
factories during off hours by corrupt employees without the company
knowing it.)  The only way to really tell is to destroy the device by
peeling it apart and analyzing it with instruments.  See:
    So even when buying a reputable brand from one of their main licensed
distributors, you have no idea who actually made or programmed
the chips you receive.  Have fun securing a system that boots from one
of these!
The cryptography mailing list
