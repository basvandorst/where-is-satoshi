
@_date: 2005-01-04 20:41:12
@_author: John Denker 
@_subject: Re: Conspiracy Theory O' The Day 
Another hypothesis:  Cover traffic, to defeat traffic analysis.
The procedure:  send N copies.  N-M of them are spam, sent to uninterested
parties.  The other M parties are the intended recipients.  Provided N>>M,
and other mild restrictions, they achieve plausible deniability.

@_date: 2013-09-06 19:31:47
@_author: John Denker 
@_subject: Re: [Cryptography] tamper-evident crypto? 
Hash: SHA1
Well, I'm sure /somebody/ on this list is clever enough to arrange countersurveillance and counterintrusion measures...
  a) especially given that detecting surveillance and/or
   intrusion is the whole point of the exercise;
  b) especially given that we have all the time in the world    to arrange boatloads of nanny-cams and silent alarms etc.,
   arranging everything in advance, before provoking the    opponent;
  c) especially given that we know it's a trap, and the
   opponent probably isn't expecting a trap;
  d) especially given that the opponent has a track record
   of being sometimes lazy ... for instance by swearing that    the fruits of illegal wiretaps came from a "confidential
   informant who has been reliable in the past" and using that
   as the basis for a search warrant, at which point you've
   got them for perjury as well as illegal wiretapping,
   *and* you know your information security is broken;
  e) especially given that we get to run this operation
   more than once.
  *) If they don't like that flavor of bait, we can give
   them something else.  For example, it is known that    there is a large-diameter pipeline from the NSA to the
   DEA.
      *) Again:  We get to run this operation more than once.  I repeat the question from the very beginning of this thread:
Shouldn't this be part of the /ongoing/ validation of any data security scheme?
There's a rule that says that you shouldn't claim a crypto
system is secure unless it has been subjected to serious
cryptanalysis.  I'm just taking the next step in this
direction.  If you want to know whether or not the system
is broken, /measure/ whether or not it is broken.
One of the rules in science, business, military planning,
et cetera is to consider /all/ the plausible hypotheses.
Once you consider the possibility that your data security
is broken, the obvious next step is to design an experiment
to /measure/ how much breakage there is.
The cryptography mailing list

@_date: 2013-10-19 21:21:15
@_author: John Denker 
@_subject: [Cryptography] PRNG WYTM 
OK, the next step in any such discussion is to ask the
famous question, What's Your Threat Model (WYTM).
Several different reasonable answers are possible.
1) At one extreme, we have the "no threat at all" model,
aka the "non-adversarial" model.  Examples include
 *) Doing a Monte Carlo integral in the context of   a molecular dynamics calculation.  The molecules   are not going to attack our PRNG.  They are not   going to cryptanalyze it.  Almost any PRNG is
  "random enough" for this purpose.
 *) Cooperative situations, such as friendly computers
  on a LAN, doing random exponential backoff as part
  of the layer-1 Ethernet CSMA/CD.  Everybody has a
  shared interest in implementing the protocol properly,
  so even if they could break the PRNG they wouldn't
  want to.
 *) Et cetera.  There are tons of examples in this   category.
A PRNG in category (1) could be considered "random" but not "secure".  It is usually adequate to seed this type of PRNG with things like the MAC address, serial number, and time-of-day.
2) At the opposite extreme we have high-stakes adversarial
applications, including military cryptography, banking,
other high-value business communications, high-stakes
gaming, etc. etc. etc.  A PRNG in this category needs to
be *secure* against a wide range of threats.
For tasks in this category, seeding the PRNG with things like the MAC address, serial number, and time-of-day is
nowhere near good enough.  It is a band-aid or worse.
It is security theater.  It gives you "randomness" in some weak sense, but it does not give you security.
The typical modern PRNG in this category consists of a
seed, a counter, a hash function, and a reseeding
mechanism.  Sometimes there is a block cipher in there somewhere, but to a sufficient approximation this is the same basic architecture, just with a fancier hash So let's look in more detail at the threats against such
a PRNG.
*) For starters we have the threat of direct cryptanalysis
of the output.  If the preimage can be found, all further
outputs will be known to the attacker, and probably all past outputs as well, over the span bounded by the nearest past and present reseedings.
The feasibility of finding a preimage depends on the number of bits output by the PRNG.  Therefore there
should be a limit on the number of output bits between
*) Another type of threat is more indirect.  For example,
suppose the PRNG was seeded at boot time from the saved
random-seed file.  It may be possible for the attacker to find this, perhaps by sneaking a peek at an old backup tape or whatever.  Such a threat is independent of the number of bits emitted by the PRNG.  It is hard to say what it /does/ depend on, but in the absence of anything better, wall-clock time is a plausible proxy.  Therefore there should be a time limit on how long a seed file is allowed to remain on disk before it is regenerated, and a time limit between reseedings of the PRNG.
That might be a "solution" in certain favorable cases, but
it is nowhere near being a reliable, general solution.  I
can think of five failure modes in five minutes.  Perhaps
the most obvious is this:  Suppose my system is sitting in
a rack at some colocation provider.  All the attacker needs
to do is rent a box in the same rack, on the same LAN
segment.  Then he knows my MAC address, the time at which
I booted up, and (to a good approximation) the arrival time
of every network packet addressed to me.
Similarly for my laptop on the corporate wifi network.  The
bad guy in the loft across the street has a nontrivial
chance of figuring out everything he needs to know about my network traffic.  If anybody has a proof that this
cannot happen, please explain.
Here's the only thing that has ever made sense to me:
 a) Any device that wants to have any security whatsoever
  needs to be able to store a seed, even when powered off.
 b) The seed needs to be provisioned on a per-device
  basis, much like the MAC address is provisioned.
 c) The seed needs to be big enough, randomly-chosen, and   secret, very unlike the MAC address, RTC, and device   serial number.
The cryptography mailing list

@_date: 2013-10-17 16:12:48
@_author: John Denker 
@_subject: Re: [Cryptography] /dev/random has issues 
Here is an experiment you can do, if you have a Linux system:
  cat /proc/sys/kernel/random/entropy_avail
I predict that it is likely to be a smallish number, less than 192
bits, not enough to cut a PGP key.  This seems to conflict with
the stated purpose of having /dev/random, and with the purpose
of having buffers within the device.
I find the current version of /dev/random to be partly yarrow-like =
and partly not.  It is yarrow-like in the sense that it performs =
updates in batches, with a substantial minimum batch-size. It =
is non-yarrow-like in that it presents far too much load on the =
upstream source of entropy.
I'm not at all convinced that hundreds of eyeballs have ever =
looked at the source code for Linux /dev/random.  In any case, =
a small number of careful eyeballs would be far more valuable =
than a huge number of cursory eyeballs.
Suppose we provide /dev/random with a good source of entropy,
including (!) a reliable estimate of the amount of entropy
(hint: turbid).  Even then, it is not at all obvious that the =
current version of the Linux /dev/random is a good custodian
of the entropy it is given.
I noticed this when working on the upcoming new version of
turbid.  It contains a subsystem that feeds entropy into
but eventually I had to, because I couldn't figure out a
way to feed it entropy without huge amounts of waste.
AFAICT that isn't possible in the current version, although
this is a fixable problem.
A non-exhaustive list of questions and issues -- some quite =
deep and some quite superficial -- can be found at
  I have a prototype ("alpha") version of random.c that =
addresses most of these issues.  If there are any
misunderstandings about what /dev/random is doing, it
would be good to clear them up sooner rather than later.
A word about the article by Dodis et al. claiming that =
It raises issues that have little direct importance.  For =
one thing, there is no consensus that their definition of =
"robust" is relevant in a practical engineering sense.
Perhaps more importantly, we must object to the assertions =
about =ABhow hard (or, perhaps, impossible?) it is to design =
a sound entropy estimation procedure=BB.
It is a truism in many fields, including sculpture as well as
programming, that it is easy to do things wrong and hard to do
things right.  However, that does not mean that things /cannot/
be done right.  In particular, it is definitely *not* impossible
to implement an entropy estimator based on the second law of
thermodynamics, which is far more reliable than several other
assumptions that form the basis of modern cryptography.  Such
a thing requires effort and depth of understanding and attention =
to detail, but it can be done.  Hint: turbid.
The existence of unimportant issues should not blind us to =
more-important issues.
The cryptography mailing list

@_date: 2013-10-20 13:30:14
@_author: John Denker 
@_subject: Re: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Could we please dial back the ad_hominem nonsense?
If we can't be respectful, could we at least be factual?
It is kinda comical to see the one guy who actually /has/
discussed a range of threat models (e.g. 10/19/2013 02:21 PM)
patronized via sweeping value judgments with no discernible connection to any of said threat models.
The cryptography mailing list

@_date: 2013-10-19 16:48:42
@_author: John Denker 
@_subject: Re: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Uhhh, that's the answer to a different question.  We
agree that the amount of available entropy is "small".
My point is that it is too small.  Furthermore, the
work imposed on the attacker is an /exponential/
function of this number, so the work is verrrry much
too small.
If the embedded device had a hundred different MAC
addresses, all unrelated, all unknown to the attacker,
each of which contributed a few bits to the available entropy, then there would be no problem ... but that's
not the situation we find ourselves in.  Not even close.
We do not get to make an argument about the perfect
being the enemy of the good in this case.  That's not
the choice we face.  Instead, there is a choice of
real security versus futile security-theater.
 a) Any device that wants to have any security whatsoever
  needs to be able to store a seed, even when powered off.
 b) The seed needs to be provisioned on a per-device
  basis, much like the MAC address is provisioned.
 c) The seed needs to be big enough, randomly-chosen, and   secret, very unlike the MAC address, RTC, and device   serial number.
Exactly so.
The cryptography mailing list

@_date: 2013-10-19 15:59:40
@_author: John Denker 
@_subject: Re: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
That the sort of thing that /might/ help.  It cannot hurt,
except insofar as people overestimate how effective it is.
What is the chance that the attacker can figure out the
MAC address of the box?
What is the chance that the attacker can figure out tight
uppper and lower bounds on the value of the real-time clock?
What is the chance that the attacker can figure out tight
uppper and lower bounds on the device serial number?
Constructive suggestion:  As I have been saying for years:
 a) Any device that wants to have any security whatsoever
  needs to be able to store a seed, even when powered off.
 b) The seed needs to be provisioned on a per-device
  basis, much like the MAC address is provisioned.
 c) The seed needs to be randomly-chosen and secret, very   unlike the MAC address, RTC, and device serial number.
Go ahead and mix in stuff likt he RTC and the MAC address if you want, but you'll have a hard time convincing anybody
that such things are sufficient.
The cryptography mailing list

@_date: 2013-10-18 23:02:21
@_author: John Denker 
@_subject: Re: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Could we please quote a little more of the context?
What I actually said on 10/18/2013 11:54 AM was:
On 10/18/2013 01:33 PM, Christoph Anton Mitterer continued:
1) As to the question of "why", here are some partial answers:
 a) If it doesn't block, it might not be secure.
    If it does block, it won't get used.  Application
    developers will roll their own PRNGs which leaves us
    in some ways worse off and in no ways better off.
 b) I've built plenty of systems where the only way in is
  via SSH.  If necessary, I can set up a one-foot-long
  network air-gapped from the rest of the world, and SSH
  in that way ... so long as the thing is not blocking.
2) Remember what I said originally:  Providing a good seed is the key.
 If you provide a good seed, it doesn't need to block.
3) You can run turbid, so there is always lots of entropy
 available, more than enough for reseeding your PRNGs.
4) In this business there is a proverb:  If you ask  whether the system is "secure", the answer is no.
 If you want any other answer, you need to specify
 your threat model in some detail, and then decide
 how much risk you can tolerate, and what kind(s)
 of risk.
The cryptography mailing list

@_date: 2013-10-18 18:54:56
@_author: John Denker 
@_subject: Re: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Hash: SHA1
Agreed, this is a system issue, not so much a /dev/u?random issue.
Blocking /dev/urandom is a bad idea.  Providing a good seed is the key.
Well, for qemu there is something.
I quote from  ...
Also:  Almost every VM I've seen provides a mechanism for shared
access to files.  A simple standard solution is to have the host
write some randomly-generated bits into a file that the guest can read.
Thirdly:  Booting from a read-only CD or similar .iso image, there is a problem if lots of people have images with the
same initial seed for the PRNG.
Several years ago I wrote some code that can take apart a .iso image, replace the seed, and put everything back together again.
This allows one to rather cheaply make N images all different.
For details, see
  I tried to get this incorporated into the Ubuntu distribution,
to no avail.
Note that if the machine can be booted with *some* randomness,
it can be given more, via a securely encrypted link, using
simple userspace tools.  There is a tool distributed with turbid that reads a file (or stdin) and does the ioctl to
feed randomness to the kernel.
The cryptography mailing list

@_date: 2013-10-27 22:17:14
@_author: John Denker 
@_subject: Re: [Cryptography] [RNG] /dev/random initialisation 
[sources for a good high-entropy seed]
This is excellent.  This is exactly the sort of discussion we
ought to be having.
I agree with the sentiment, but having lots of entropy isn't the only way of solving the problem;  we can make do with a lot less entropy if it is /computationally infeasible/ for the attacker to untangle what we have done.
OK, good.
It may help to add a little bit more detail to that analysis.  There are two subcases:
  a) The PRNG starts out in a good state, with a seed that is
   large enough, random enough, and unknown to the attacker.  If    we now use the real-time clock (RTC) to /stir/ the seed, that
   should be sufficient to guarantee no collisions.  That should
   be enough to stop replay attacks.
  b) If the PRNG starts out in a bad state, because the seed has
   been compromised, then the PRNG cannot quickly recover, and in
   particular it cannot recover while it is under attack.  The RTC
   is nowhere near sufficient to /substitute/ for a proper seed.
To say the same thing in slightly different words:  There are two
separate objectives that we need to consider:
  A) Resistance to attack, and
  B) Recovery from compromise.
In some rock-candy world it would be nice to do both at the same time, but in this world, there are situations where a practical
PRNG cannot do both at the same time, and that's OK.
The moral of the story is that it is super-important to make sure
the PRNG is properly seeded.  The seed needs to be big enough,
random enough, and unknown to the attacker.
Note that the RTC does not add real entropy to the PRNG.  All it
does is stir the PRNG.  Assuming the PRNG's hash function is working
properly, (seed + RTC1) should be effectively very different from
(seed + RTC2).  The attacker could try to mount a related-plaintext
attack against the hash, but for any decent cryptologic hash this
should be computationally infeasible.
There is a fundamental conceptual distinction between (a) reseeding
the PRNG with honest-to-goodness entropy and (b) merely stirring
the existing seed.  However, there are some situations in which
stirring suffices.
It shouldn't take much stirring, assuming the hash function is working
properly.  We absolutely require that the RTC produce non-repeating values, but that's about all we really require.  Again, this is all predicated on starting with a high-quality seed.
I hate to sound like a broken record, but the solution is the same in
all cases:  You need a proper seed:  big enough, random enough, and
unknown to the attacker.
The manufacturer reeeeally needs to provision each instance of the
device with a proper seed.  The cost of doing this is ridiculously
small.  The manufacturer already needs to provision things like the
MAC address, hostname, IMEI, et cetera ... and the addition burden
of provisioning the seed for the PRNG is negligible.
Again (!) the solution is the same:  If there is a proper seed, you're
fine.  If there is not a proper seed, you're screwed.
Specific suggestion:
  a) Download the .iso image onto disk.
  b) Provision a proper seed onto the image.
  c) Burn the modified image to CD if desired.
A few years ago I cooked up some tools to do exactly this.  I tried to
get support for it installed into the distributions, but the proposal
was shot down by some "expert" who decided that the RTC was sufficient
security, even if every attacker on earth knew what was in the distributed
seed-file ... and even if every attacker on earth knew what time it was.
More general suggestion:  We ought to produce some sort of "Best Practices"
document that explains to manufacturers, software distributors, VM providers,
et cetera how important it is to provision a proper seed, and explains how
to do it.
We should also provide tools and infrastructure that makes it easy to do
the right thing and hard to do the wrong thing.  For example, in the
general case, unpacking and repacking an .iso image is a pain in the neck,
but if the image is engineered to facilitate rewriting the seed-file the
procedure is much, much simpler.
Following up on a proposal by Jerry Leichter, on 10/25/2013 05:15 AM, I like this idea so much that I implemented it many years ago.  The
command line looks roughly like:
lynx -auth=harpo:swordfish -source ' | randomize kernel from -
I disagree; see below.
Again (!) the key is to have a proper seed stored on the machine
in question.  It's like the proverbial seed-corn:  If you have
none, you're screwed.  If you have some, you can grow more.
Some comments:
a) If you have 256 bits of honest-to-goodness entropy from
 /any/ source, OS or otherwise, then that's more than enough
 to seed the PRNG, and nothing on the list matters.
b) Ditto.
c) Not so good. Ping times are not guaranteed to be always
 different, and not guaranteed to be unknown to the attacker.
 In the crypto business it is conventional to worry about
 MITM attacks.  A scenario where the MITM doesn't need to
 mess with the packet contents, just the packet timing,
 is extra-easy for the attacker.
d) Not so good.  All that stuff is constant, and relatively
 easy for the attacker to know or guess.  The RTC wasn't  mentioned, but it is better than the items that were
 mentioned, in that it is at least non-constant and non-
 repeating.  The RTC cannot /substitute/ for a proper
 stored seed, but it can /stir/ the seed.
e) That's basically the right idea, except that we should
 call it the "stored" seed rather than the "at-birth" seed.
 The stored seed should be changed at frequent intervals.
 This helps with the recovery from compromise.  Perhaps
 more importantly, it reduces the window of vulnerability
 and reduces the value the attacker gets from peeking at  the stored seed.
The cryptography mailing list

@_date: 2013-10-27 22:17:14
@_author: John Denker 
@_subject: Re: [Cryptography] [RNG] /dev/random initialisation 
[sources for a good high-entropy seed]
This is excellent.  This is exactly the sort of discussion we
ought to be having.
I agree with the sentiment, but having lots of entropy isn't the only way of solving the problem;  we can make do with a lot less entropy if it is /computationally infeasible/ for the attacker to untangle what we have done.
OK, good.
It may help to add a little bit more detail to that analysis.  There are two subcases:
  a) The PRNG starts out in a good state, with a seed that is
   large enough, random enough, and unknown to the attacker.  If    we now use the real-time clock (RTC) to /stir/ the seed, that
   should be sufficient to guarantee no collisions.  That should
   be enough to stop replay attacks.
  b) If the PRNG starts out in a bad state, because the seed has
   been compromised, then the PRNG cannot quickly recover, and in
   particular it cannot recover while it is under attack.  The RTC
   is nowhere near sufficient to /substitute/ for a proper seed.
To say the same thing in slightly different words:  There are two
separate objectives that we need to consider:
  A) Resistance to attack, and
  B) Recovery from compromise.
In some rock-candy world it would be nice to do both at the same time, but in this world, there are situations where a practical
PRNG cannot do both at the same time, and that's OK.
The moral of the story is that it is super-important to make sure
the PRNG is properly seeded.  The seed needs to be big enough,
random enough, and unknown to the attacker.
Note that the RTC does not add real entropy to the PRNG.  All it
does is stir the PRNG.  Assuming the PRNG's hash function is working
properly, (seed + RTC1) should be effectively very different from
(seed + RTC2).  The attacker could try to mount a related-plaintext
attack against the hash, but for any decent cryptologic hash this
should be computationally infeasible.
There is a fundamental conceptual distinction between (a) reseeding
the PRNG with honest-to-goodness entropy and (b) merely stirring
the existing seed.  However, there are some situations in which
stirring suffices.
It shouldn't take much stirring, assuming the hash function is working
properly.  We absolutely require that the RTC produce non-repeating values, but that's about all we really require.  Again, this is all predicated on starting with a high-quality seed.
I hate to sound like a broken record, but the solution is the same in
all cases:  You need a proper seed:  big enough, random enough, and
unknown to the attacker.
The manufacturer reeeeally needs to provision each instance of the
device with a proper seed.  The cost of doing this is ridiculously
small.  The manufacturer already needs to provision things like the
MAC address, hostname, IMEI, et cetera ... and the addition burden
of provisioning the seed for the PRNG is negligible.
Again (!) the solution is the same:  If there is a proper seed, you're
fine.  If there is not a proper seed, you're screwed.
Specific suggestion:
  a) Download the .iso image onto disk.
  b) Provision a proper seed onto the image.
  c) Burn the modified image to CD if desired.
A few years ago I cooked up some tools to do exactly this.  I tried to
get support for it installed into the distributions, but the proposal
was shot down by some "expert" who decided that the RTC was sufficient
security, even if every attacker on earth knew what was in the distributed
seed-file ... and even if every attacker on earth knew what time it was.
More general suggestion:  We ought to produce some sort of "Best Practices"
document that explains to manufacturers, software distributors, VM providers,
et cetera how important it is to provision a proper seed, and explains how
to do it.
We should also provide tools and infrastructure that makes it easy to do
the right thing and hard to do the wrong thing.  For example, in the
general case, unpacking and repacking an .iso image is a pain in the neck,
but if the image is engineered to facilitate rewriting the seed-file the
procedure is much, much simpler.
Following up on a proposal by Jerry Leichter, on 10/25/2013 05:15 AM, I like this idea so much that I implemented it many years ago.  The
command line looks roughly like:
lynx -auth=harpo:swordfish -source ' | randomize kernel from -
I disagree; see below.
Again (!) the key is to have a proper seed stored on the machine
in question.  It's like the proverbial seed-corn:  If you have
none, you're screwed.  If you have some, you can grow more.
Some comments:
a) If you have 256 bits of honest-to-goodness entropy from
 /any/ source, OS or otherwise, then that's more than enough
 to seed the PRNG, and nothing on the list matters.
b) Ditto.
c) Not so good. Ping times are not guaranteed to be always
 different, and not guaranteed to be unknown to the attacker.
 In the crypto business it is conventional to worry about
 MITM attacks.  A scenario where the MITM doesn't need to
 mess with the packet contents, just the packet timing,
 is extra-easy for the attacker.
d) Not so good.  All that stuff is constant, and relatively
 easy for the attacker to know or guess.  The RTC wasn't  mentioned, but it is better than the items that were
 mentioned, in that it is at least non-constant and non-
 repeating.  The RTC cannot /substitute/ for a proper
 stored seed, but it can /stir/ the seed.
e) That's basically the right idea, except that we should
 call it the "stored" seed rather than the "at-birth" seed.
 The stored seed should be changed at frequent intervals.
 This helps with the recovery from compromise.  Perhaps
 more importantly, it reduces the window of vulnerability
 and reduces the value the attacker gets from peeking at  the stored seed.
The cryptography mailing list

@_date: 2013-11-05 16:51:50
@_author: John Denker 
@_subject: Re: [Cryptography] randomness +- entropy 
Are we not having a technical discussion?  If not, then what?
The physics entropy and the information-theory entropy are the
same thing.  This is not a mere "similarity in formalisms".
For example, it is a one-line calculation to find the entropy
of the nuclear spins in a sample of copper, starting from
statistical principles, namely
     S = R ln 4
and you can also measure S using a physical thermometer.
Mirabile dictu, you get the same answer either way.
Nevermind the word, ideas are what's important.  Terminology is
important only insofar as it helps formulate and communicate the
The /idea/ of entropy has tremendous significance.  If we didn't
call it "entropy" we would need to invent another name for it.  So
please let's save everybody a lot of trouble and call it "entropy".
Yes, "tied to" ... but that's not the same as "same as".  Simple
 -- If you mean "unpredictability", say "unpredictability".
 -- If you mean "entropy", say "entropy".
We have perfectly good words for each of these things.
Speak for yourself, Kemosabe.  As for me, I know of a systematic method for estimating the entropy, based on a series of intelligent guesses.  The method was described by some guy named Shannon, several decades ago.  It is consistent with everything else we know about Successful cryptography often depends on depth of understanding and
attention to detail.  The loosey-goosey approach is very likely to
get you into trouble.
The same idea applies to various other fields of endeavor
  There *is* a difference between a TRNG and a cryptographically-strong
  A) In /some/ situations, the difference doesn't matter very much.
  B) In other situations, it matters a great deal.
For starters,   A) It possible to imagine a TRNG independent of any PRNG.
  B) It is not possible to imagine a PRNG completely independent of
   any TRNG, because the PRNG needs a seed, and the seed has to
   come from somewhere.
Here's another contrast:
   A) It may be that under /normal/ operating conditions, the /user/
    does not care about TRNG versus PRNG.
   B) Anybody who is /designing/ any such thing needs to understand
    the distinction.  In particular, the /recovery from compromise/     is wildly different in the two cases.
Here's a highly-condensed tutorial:
Suppose we have N-bit codewords, and various statistical distributions
over codewords.
Entropy is a property of the ensemble (not of any particular codeword).
 1) If the ensemble consists of all 2^N possible codewords, evenly   distributed, the distribution has N bits of entropy.
 2) Now consider a different distribution.  If half the codewords are
  missing, and the rest are evenly distributed, the distribution has
  N-1 bits of entropy.
 2a) In the sub-case where you know exactly which codewords are missing,
  this distribution is noticeably less random, less predictable than
  distribution (1).
 2b) In the sub-case where it is computationally infeasible to figure
  out which codewords are missing, this distribution may be -- for a
  wide range of practical purposes -- just as unpredictable as
  distribution (1).  However, it still has less entropy.
 3) For a typical real-world PRNG, we are not talking about one bit of
  entropy going missing.  Almost all of the bits have gone missing!
  If we seed the PRNG with 100 bits and then use it to generate a
  billion bits, then there are 2^999999900 missing codes out of a
  possible 2^1000000000.  That's a lot of missing codes.  Well over
  99.99% of the codes are missing.
  With a TRNG, the situation is reversed.  Ideally there would be no
  missing codes whatsoever.  However, for reasons of computational
  efficiency, a practical TRNG will typically allow a few -- a very
  few -- codes to be missing or under-represented in the ensemble.
  The contrast is extreme:
   A) The cryptographic strength required to hide the missing codes
    when almost all codes are missing, versus
   B) The cryptographic strength required to hide the under-represented
    codes, when there are very few of them.
And on top of that, there is the issue or recovery from compromise.
There is an important idea here.  If you are not going to call this
idea "entropy", you need to come up with a different name for it.
Bear in mind that practically everybody in the world reserves the
word "entropy" to denote the genuine physical / statistical entropy.
Also note that we have perfectly good words like "randomness" and
"unpredictability" to cover the other cases.
The cryptography mailing list

@_date: 2013-11-05 18:57:24
@_author: John Denker 
@_subject: Re: [Cryptography] /dev/random is not robust 
I wouldn't have said that.
Statement [1] is true enough as it stands ... but it's looking
through the wrong end of the telescope.  We should instead turn
it around.  Consider the contrapositive:
  Given that we don't want to be completely screwed, we MUST
  ensure that the device has enough randomness onboard, so   that it can generate secure session keys.
  This is an entirely /solvable/ chicken-and-egg problem.
  Proper provisioning is a big part of the solution.  As
  soon as you can establish a secure connection, you can
  download tons of exogenous randomness.
That is not the "only" way to solve the main problem(s).  There must be a hardware RNG somewhere in the mix, and I have devoted a lot of time and effort to this part of the problem.  However, the fact remains that a properly seeded cryptographically strong PRNG is good enough for many purposes, and indeed superior for many purposes, especially given that the demand for randomly-distributed bits tends to be very bursty.
Increasing the number of critical failures is not a good
way to win friends and influence people.  -- Converting an insidious critical failure to a manifest
  critical failure is a small step in the right direction;
  however ...
 -- The real goal should be to eliminate the failure mode
  entirely.  This appears to be entirely doable.
Those are wise words.
 -- There are a couple of different common cases that
  require slightly different answers.
 -- There are a couple of unusual cases that require
  some extra effort, but are still entirely doable.
 -- I'm sure there are cases that cannot be handled.  It
  will always be possible to design a device that cannot
  be secured, because fools are so ingenious.  However,
  this is not the typical case.  Not even close.
There are huge categories of devices out there that could
be made much more secure at essentially zero incremental
cost, and that should be the first place we focus our
Exactly so.  Those are important cases.  Along the same lines, it should go without saying that proper provisioning of NON-virtual machines is also required.
Meanwhile, as another part of the overall solution, a good
hardware RNG is also required.  This does not, however need
to exist on every machine, and it does not need to meet every
demand for randomly-distributed bits.
Note the contrast:  As a rule of thumb:
  A) Seed-files and PRNGs tend to be good for meeting    short-term peak demand.
  B) There is still a long-term need for a HRNG.  A PRNG
   cannot exist without a HRNG backing it up.  On the
   other hand, the coupling between the two does not
   need to be particularly tight.
The cryptography mailing list

@_date: 2013-11-12 06:44:16
@_author: John Denker 
@_subject: Re: [Cryptography] randomness +- entropy 
Sorry, the problem is muuuuch harder than that.  If the solution
were that simple and that obvious, it would have been implemented
a long time ago.
The fact is, there are some applications that cannot make do with
low-quality randomness *and* cannot afford to wait.
  -- A PRNG that puts out low-quality randomness causes insidious
   failures.
  -- A PRNG that blocks causes manifest failures.
It could be argued that trading an insidious failure for a manifest
failure is a step in the right direction, but it is only a small
step, and it does not solve the main problem.
We need a PRNG that /always/ puts out a cryptographically-strong
random distribution ... early in the boot-up process and at all
times thereafter.  Specific constructive suggestions for how to
do this have been put forward ... such as putting a seed in the
kernel boot image, and making sure the seed is properly provisioned.
If/when we have a PRNG that is always ready to use, the question of blocking does not arise, and there is no need to define a new The cryptography mailing list

@_date: 2013-11-08 19:23:57
@_author: John Denker 
@_subject: Re: [Cryptography] randomness +- entropy 
Hash: SHA1
That inequality is true and useful and well said.
In a rational world that would be all there was to
say about it.  However, alas, there is more to the
story, especially when we look at the context, which
has to do with the Linux /dev/random and /dev/urandom.
It turns out that:
 1a) /dev/random is "supposed" to be a TRNG.
 1b) However, it can operate as a PRNG in exceptional   circumstances, when it is recovering from a compromise.
 2a) /dev/urandom is some sort of hermaphroditic chimera.
  That is to say, I don't know what it is.  Under a
  wide range of "typical" conditions it functions as
  a PRNG.
 2b) However, it also tries to approximate a TRNG if   it can.
There are some heavy tradeoffs involved here, trading
possibly-better performance under exceptional conditions against waste of CPU cycles and waste of entropy under normal conditions.  This leaves us with more questions
than answers.  There are as-yet unanswered questions
about the threat model, the cost of CPU cycles, the
cost of obtaining raw entropy, etc. etc. etc.  The
answers will vary wildly from machine to machine.
Because /dev/urandom is a hermaphroditic chimera, when
somebody says they are reading thousands of bits with
only 23 bits of entropy, that is not quite as insane
as you might think.  It's not a normal TRNG and it's
not a normal PRNG, but it is what it is.  There are
millions upon millions of machines in the field that
depend on it.
It's difficult even to describe what's going on in
is painful, because it is aggressively misleading if
not outright erroneous.  There are places in the code
where it is appropriately meticulous about accounting for entropy -- i.e. the actual real entropy -- and other places where it throws the word around recklessly.
In particular the get_random_bytes() function that has been featured in this thread basically just calls extract_entropy() ... even though it is extracting bytes from a quasi-PRNG that under /normal/ conditions will not have any appreciable entropy.
  So the name "extract_entropy()" is quite misleading.
The text of the printk warning mentions entropy, but we
should not pay attention to that, because what it says
is not what it means.  It does not communicate the real
meaning of the warning.  The if-condition that governs the printk checks the initialization flag ... not the entropy content.
Also note that this printk warning is in one person's
"development" branch and has not been incorporated into
any released version of the kernel.
  That reason doesn't make much sense.  There is a better reason,
as discussed below, but first we should observe that at present
Linux stores only a pseudo-random seed and then relies entirely on the PRNG!  This is in no way more trustworthy than storing
some real entropy.  Any attacker who could steal the hypothetical
random-seed file can also steal the urandom-seed file.
Here's a better reason why at present it would make no sense to
take the obvious approach to storing real entropy across reboots:
The /dev/urandom quasi-PRNG would immediately waste the entropy.
The device apparently assumes that a steady supply of new raw entropy will always be available.  In situations where entropy is scarce -- e.g. when there is a finite stored supply -- normal operation of /dev/urandom is tantamount to a denial-of-service attack on the entropy supply.
Any application that wants to file away some entropy can perfectly well do so, provided it does not let /dev/urandom get its hands on it.
The cryptography mailing list

@_date: 2013-11-06 19:40:28
@_author: John Denker 
@_subject: Re: [Cryptography] randomness +- entropy 
I have a /constructive/ suggestion, followed by a /specific/
constructive suggestion.  But first, some background:
We have seen that even the /unfounded/ rumor that the PRNG
might block causes users to shun the PRNG, substituting
something that is no better and almost certainly worse.
If the rumor were true, the user behavior would be even
Here's a suggestion:
--> Make sure the kernel PRNG is initialized very, very early.
 *) Then the question of whether or not to block does not arise.
 *) Then the users have no temptation to evade the block.
In more detail:  What we have now is an insidious failure, i.e. a PRNG that sometimes provides an insufficiently-random distribution
of bits.  This is a problem.  This is a Bad Thing.  The main goal should be to fix the problem ... and to fix it such a way that it Some applications cannot afford to wait.  For these applications,
if the PRNG blocks, we have converted an insidious failure into
a manifest failure.  It could be argued that this is a step in
the right direction ... but it is only a /small/ step, and it
does not really fix the problem.  It could be argued in political
terms that this would make users so angry that they would demand a real fix, but creating demand for a fix without actually providing
a fix is bad politics, bad marketing, and bad engineering.
So this brings us back to the main point:  The main goal should be to implement a PRNG that is up and running very, very early.
In engineering-management terms:  this is in the critical path.
  By way of contrast, blocking is not in the critical path,
  because even if you implement blocking, you *still* need
  to fix the problem.
Here is a specific suggestion for how the problem could be --> Incorporate the stored seed into the kernel boot image  (zImage or bzImage).  That ensures that the PRNG is "born"  ready to go, just as a newborn dolphin knows how to swim,  and a newly-hatched rattlesnake is already venomous.
I have looked into this a little bit.  Although I don't yet understand all the details, it looks like there is a
straightforward path.
Actually there are two complementary requirements:
 -- the stored seed must be available very, very early
 -- it should not be unduly difficult to refresh the
  stored seed from time to time.
Refer to the following for a simplified view of the structure
of the boot image:
    Actually things are somewhat more complicated than item
12 in the faqs.org document suggests.  The actual lines
from the relevant x86 Makefile include:
VMLINUX_OBJS = $(obj)/vmlinux.lds $(obj)/head_$(BITS).o $(obj)/misc.o \
        $(obj)/string.o $(obj)/cmdline.o $(obj)/early_serial_console.o \
        $(obj)/piggy.o
$(obj)/vmlinux: $(VMLINUX_OBJS) FORCE
        $(call if_changed,ld)
(and even that is a simplification).  Unless I am missing
something, it should be No Big Deal to add $(obj)/urandom-seed.o
to the list, somewhere ahead of $(obj)/piggy.o.
Next step:  It should be straightforward to write a tool
that efficiently updates the stored seed within the boot
image.  Updating MUST occur during provisioning, before
the device gets booted for the first time ... and also
from time to time thereafter.  Updating the boot image
isn't be quite as simple as   dd of=/var/lib/urandom/random-seed
but neither is it rocket surgery.  The cost is utterly
negligible compared to the cost of a security breach, which is the relevant comparison.
I have considered a *lot* of alternatives.  This is the
one that gives the most bang for the buck.
If we do this, many of the issues that we have recently
been discussing just melt and disappear.
Sometimes the system is booted from read-only media.
This must be handled as a special case.  In the case
of a "live CD" or "install CD" I recommend passing a
seed via the kernel boot cmdline.  We could teach
grub to demand a key from the user.
  If the machine is air-gapped and will not have
  any persistent consequences, then this step can
  be skipped.
Suppose we have something that boots from read-only media

@_date: 2013-11-05 16:51:50
@_author: John Denker 
@_subject: Re: [Cryptography] randomness +- entropy 
Are we not having a technical discussion?  If not, then what?
The physics entropy and the information-theory entropy are the
same thing.  This is not a mere "similarity in formalisms".
For example, it is a one-line calculation to find the entropy
of the nuclear spins in a sample of copper, starting from
statistical principles, namely
     S = R ln 4
and you can also measure S using a physical thermometer.
Mirabile dictu, you get the same answer either way.
Nevermind the word, ideas are what's important.  Terminology is
important only insofar as it helps formulate and communicate the
The /idea/ of entropy has tremendous significance.  If we didn't
call it "entropy" we would need to invent another name for it.  So
please let's save everybody a lot of trouble and call it "entropy".
Yes, "tied to" ... but that's not the same as "same as".  Simple
 -- If you mean "unpredictability", say "unpredictability".
 -- If you mean "entropy", say "entropy".
We have perfectly good words for each of these things.
Speak for yourself, Kemosabe.  As for me, I know of a systematic method for estimating the entropy, based on a series of intelligent guesses.  The method was described by some guy named Shannon, several decades ago.  It is consistent with everything else we know about Successful cryptography often depends on depth of understanding and
attention to detail.  The loosey-goosey approach is very likely to
get you into trouble.
The same idea applies to various other fields of endeavor
  There *is* a difference between a TRNG and a cryptographically-strong
  A) In /some/ situations, the difference doesn't matter very much.
  B) In other situations, it matters a great deal.
For starters,   A) It possible to imagine a TRNG independent of any PRNG.
  B) It is not possible to imagine a PRNG completely independent of
   any TRNG, because the PRNG needs a seed, and the seed has to
   come from somewhere.
Here's another contrast:
   A) It may be that under /normal/ operating conditions, the /user/
    does not care about TRNG versus PRNG.
   B) Anybody who is /designing/ any such thing needs to understand
    the distinction.  In particular, the /recovery from compromise/     is wildly different in the two cases.
Here's a highly-condensed tutorial:
Suppose we have N-bit codewords, and various statistical distributions
over codewords.
Entropy is a property of the ensemble (not of any particular codeword).
 1) If the ensemble consists of all 2^N possible codewords, evenly   distributed, the distribution has N bits of entropy.
 2) Now consider a different distribution.  If half the codewords are
  missing, and the rest are evenly distributed, the distribution has
  N-1 bits of entropy.
 2a) In the sub-case where you know exactly which codewords are missing,
  this distribution is noticeably less random, less predictable than
  distribution (1).
 2b) In the sub-case where it is computationally infeasible to figure
  out which codewords are missing, this distribution may be -- for a
  wide range of practical purposes -- just as unpredictable as
  distribution (1).  However, it still has less entropy.
 3) For a typical real-world PRNG, we are not talking about one bit of
  entropy going missing.  Almost all of the bits have gone missing!
  If we seed the PRNG with 100 bits and then use it to generate a
  billion bits, then there are 2^999999900 missing codes out of a
  possible 2^1000000000.  That's a lot of missing codes.  Well over
  99.99% of the codes are missing.
  With a TRNG, the situation is reversed.  Ideally there would be no
  missing codes whatsoever.  However, for reasons of computational
  efficiency, a practical TRNG will typically allow a few -- a very
  few -- codes to be missing or under-represented in the ensemble.
  The contrast is extreme:
   A) The cryptographic strength required to hide the missing codes
    when almost all codes are missing, versus
   B) The cryptographic strength required to hide the under-represented
    codes, when there are very few of them.
And on top of that, there is the issue or recovery from compromise.
There is an important idea here.  If you are not going to call this
idea "entropy", you need to come up with a different name for it.
Bear in mind that practically everybody in the world reserves the
word "entropy" to denote the genuine physical / statistical entropy.
Also note that we have perfectly good words like "randomness" and
"unpredictability" to cover the other cases.
The cryptography mailing list

@_date: 2013-11-04 19:21:00
@_author: John Denker 
@_subject: [Cryptography] randomness +- entropy 
Hash: SHA1
Hi Folks --
Some people have been throwing around the word "entropy" rather carelessly.
Entropy means something very special.
For a great many cryptological purposes, a high-quality PSEUDO-random distribution is good enough, even though its entropy density is very low.  Note the contrast:
  TRNG entropy density = 1 - epsilon
  PRNG entropy density =   epsilon
As another way of emphasizing the distinction:  a PRNG places orders-of-magnitude harsher demands on the strength of the cryptological primitives it uses.  This can be quantified in terms of classical cryptologic ideas such as unicity distance, but for present purposes I prefer the "entropy density" language. The rubber meets the road here:  Consider the contrast:
PRNG:  I am quite sure that on startup the machine needs to   have on board a crypographically strong, well-seeded PRNG.
  This needs to be up and running very, very early in the   boot-up process.  Some things that need the PRNG cannot
  wait.
TRNG:  At the moment I have no firm opinions as to how much   actual entropy the machine needs on start-up.  I look   forward to having a discussion on this topic, with use-case   scenarios et cetera.
  In particular, AFAICT it is not a settled question as   to whether the things that need a TRNG can wait, or how
  long they can wait.
Both of these are solvable problems.  They are not, however,
the same problem.    *) A reservoir of true-randomly distributed bits would,    as an immediate corollary, provide a seed that solves    the PRNG problem.
  *) The converse is spectacularly not true.
FWIW note that current Linux distros make no attempt to
provide a reservoir of true-randomly distributed bits for
use at the next startup.  There are some efforts toward storing a seed for the kernel PRNG, but the stored seed is itself pseudo-randomly generated, and the kernel correctly
attributes zero entropy to it.
Even more tangential remark:  Note that even if there were
a reservoir of true-randomly distributed bits, AFAICT ssh
would not use them.  Openssh is built on top of openssl,
which has its own internal PRNG, which it prefers to seed
using the kernel PRNG via /dev/urandom AFAICT.  I refuse
to get too excited about this, because obviously this is
not set in stone.  There is an engineering principle that
says we should "aim for the moving target" which in this
case means providing services to support the way apps /should/
work, even if some of them don't presently work that way.
By way of contrast, gnupg seems to be good about insisting
on true-randomly distributed bits for cutting its keys.
Bottom line:
  -- If you mean "randomness" please say "randomness"
  -- If you say "entropy", please be sure you really mean it.
  -- Please do not use "entropy" as a misnomer for "randomness",
   or even for "cryptologically strong randomness".
The cryptography mailing list

@_date: 2014-07-23 21:48:27
@_author: John Denker 
@_subject: Re: [Cryptography] hard to trust all those root CAs 
Under that assumption, there is no need for cryptography.
We should shut down this list.  We should all go do something else.  Orwell was an optimist.
Also under that assumption, there is no such thing as a
trade secret, and therefore no such thing as industrial
research and development.
To say the same thing in less sarcastic terms:  We had better do whatever it takes to make sure that assumption does not become true.
This affects many different aspects of life.   -- Baseball would be a very different game if the batter   could crack the communication between catcher and pitcher,
  and if the pitcher could crack the "bunt" and "steal"
  signs, et cetera.
 -- Poker would a verrrry different game if all the cards
  were transparent.
 -- I take this personally, because most of my adult life
  has been spent doing R&D.  Almost every dollar I ever
  earned was predicated on the idea that my work conferred
  some competitive advantage to the company that I owned
  and/or worked for.  It would be hard to have any kind of   intellectual property, or any kind of competition at all,
  if everything becomes an open book.
The cryptography mailing list

@_date: 2014-07-23 12:32:39
@_author: John Denker 
@_subject: Re: [Cryptography] hard to trust all those root CAs 
Hash: SHA1
The moderators wisely insist on brevity.  However, we have to give up something in return.  You don't get to
snip out the threat model and then complain that no
threat model was specified.
I hate to belabor the obvious, but on 07/19/2014 02:03 PM, the OP in this thread did mention MITM attacks and
did cite data on forged certificates in the wild.
If you want the next level of detail, it is known that
the NSA acts as a MITM at the /hardware/ layer:  they
intercept and tamper with shipments after they leave
the manufacturer and before they reach the end-user.
They can insert back doors in everything from consumer-
grade stuff like cable modems, to corporate firewalls,
to carrier-grade backbone routers.  This meddle-in-the-
middle approach saves them the trouble of suborning a
whole bunch of manufacturers directly;  all they need to do is suborn a handful of shipping companies.  This is documented in the Snowden files; no tin-foil hat is
If the Chinese PLA Third Department is not installing
their own back doors, I'd be shocked.  If they weren't
doing it a year ago, they must have read the Snowden
files as a how-to manual.  For equipment made in China, they can demand direct cooperation from the manufacturers.
Couple that with a rogue CA.  Now you're drowning in Note that back doors are notoriously hard to secure.
A third party gets to choose the NSA back door, or the Third Department back door, or some generic stack-
overflow bug, or whatever.
A question for each person on this list:  Are you sure
that all of your communications with your banker, doctor, lawyer, mistresses, etc. move over networks that are immune to MITM attacks?  If so, please raise your hand.
It can't be a very successful solution, if people refer
to it in the past tense, and can't remember the name.
Note the contrast:  As currently deployed:
  SSL relies on authority, with no pinning or notary.
  SSH relies on pinning, with no authority or notary.
  PGP relies on web-of-trust, which usually boils down
   to little more than a labor-intensive form of pinning.
As discussed on 09/27/2013 09:43 AM, I reckon a heterotic approach would greatly increase security in all three cases.
I use the term "pinning" to refer to local approaches, and "notary" to refer to network-based online approaches.
AFAICT no "perfect" solution is possible.  If somebody wants to make a Truman Show / Matrix fake universe for you to live in, they can do so -- in principle.  However,
I reckon that good crypto engineering can make this much more expensive to do, and much easier to detect.
Evidently there are no widely-deployed solutions;  otherwise we wouldn't be seeing forged certificates in the wild.  Is there anything on the horizon?
If not, why not?
The cryptography mailing list

@_date: 2014-07-19 21:03:24
@_author: John Denker 
@_subject: [Cryptography] hard to trust all those root CAs 
AFAICT, a lot of existing protocols were designed to resist
passive eavesdropping.  In contrast, the idea of large-scale MITM attacks was sometimes considered tin-foil-hat paranoia.
To this day, standard Ubuntu Firefox trusts 162 different
authorities (including the Hong Kong Post Office) to certify
In the /usr/share/ca-certificates/mozilla directory, only one of 163 root certificates has any v3 Name Constraints at all.
Why Ubuntu and Firefox tolerate this is beyond me; I can understand trusting Microsoft to sign Microsoft-related stuff, but allowing them to sign /anything and everything/ ?!????!!
     Actually it's even worse than that, because people like
     Microsoft have been issuing subsidiary certificates with      unlimited power, so you don't even need to capture a root      CA;  all you need is one of the subsidiary certs.
Forsooth, one would think that if these Authorities had any sense at all, they would voluntarily put constraints on their own certificates, just to make themselves less of a target.
Issuing an all-powerful cert is like walking through a bad neighborhood pushing a wheelbarrow full of cash.  If you carried less cash, you'd be less of a target.
Forged certs are a documented problem in the wild.  No tin-foil hat required:
     SSL "packet inspection" is an article of commerce.  The fact that
this is even remotely possible tells me that SSL fails to provide
the thing I most want it to provide.
  That crunching noise you hear is the sound of dead canaries
underfoot.  We really need to take action to reduce exposure
on this issue.
The cryptography mailing list

@_date: 2014-10-18 01:32:48
@_author: John Denker 
@_subject: Re: [Cryptography] Best internet crypto clock 
so far so good ....
Resetting the local clock hardware is not necessary, not desirable, and not implied by anything that was said.
When you grab the official time from NIST or wherever, you should use that to write a calibration certificate, which you keep in a file along with all the previous calibration certificates.
The local clock hardware continues to be free-running and imperturbable.
Using the calibration certificates, you can define a as a function of the local clock hardware reading.
This function is   a) one-to-one,
  b) continuous,
  c) differentiable [except on a set of measure zero, at worst],
  d) very nearly unit slope, and
  e) highly overconstrained.
Because it is overconstrained, you can perform jackknife
resampling and claim that the calibrated time was never
off by more than XYZ milliseconds during the times of
interest.  There is strong evidence in support of this
claim and no evidence against it.
Courts have seen this sort of calibration a gazillion
times, e.g. for the speedometers and radars in police
If you do it right, the evidence is so overwhelming that
the adversary will not seriously consider challenging it.
A challenge would look like a crackpot move, and would just be an admission of weakness and desperation.
The cryptography mailing list

@_date: 2014-11-17 20:27:14
@_author: John Denker 
@_subject: Re: [Cryptography] FW: IAB Statement on Internet Confidentiality 
Thanks to RS for forwarding the IAB statement.
Then on 17/11/2014 04:54 am, alex wrote in part:
On 11/17/2014 02:00 AM, ianG disagreed, saying:
I vote with Alex on this one.
a) Obviously, unencrypted communication is like walking
 around in a bad neighborhood pushing a wheelbarrow full
 of cash.  You are going to get mugged.
b) Encryption without authentication is like putting a
 tarp over the wheelbarrow, with a big sign that says =
 "please do not passively eavesdrop on all this cash".
To repeat:
a) Obviously, the era is over when we can leave the IP
 networks and (!) the phone networks unprotected.
b) Evidently less obvious, and in need of emphasis:
 The era is *also* over when we can pretend that high-
 power active attacks are infeasible or even rare.
 Defending the Home Despot PoS terminals against the
 script-kiddie-with-a-laptop-in-the-parking-lot is
 nice, but nowhere near sufficient.
c) Furthermore, we must add traffic analysis to the
 list of things to worry about.  The IAB statement
 did not even hint at this.
 For example, traffic to  is encrypted, but even a passive observer can tell
 what articles I've read, just by looking at the file
 sizes.
When the bad guys read "unauthenticated encryption, =
first and foremost" they start joyfully singing to =
  M-T-M all night,
  M-T-M all day,
  Traff'c analysis five miles long,
  Oh, de doo dah day.
Did you see the recent expos=E9 in the WSJ about the
dirtbox aka DRT Box?  Here's a rehash:
  I'm not surprised to hear that most of the population
is subject to more-or-less continual tracking.  Rather,
I was surprised that they bothered with aircraft and
dirtboxes rather than just vampiring the data out of
the phone companies.  Note the contrast:
 -- I can understand that a Stingray confers an
  advantage, namely pinpoint accuracy;
 -- but dirtboxes on aircraft?  Huh?
As a first guess, maybe they didn't want to risk =
the ever-so-slight chance that somebody at the =
phone company would notice that it's illegal and =
unconstitutional, and perhaps pull a Snowden on =
them.  I dunno, what am I missing here?
The cryptography mailing list

@_date: 2015-02-17 03:06:52
@_author: John Denker 
@_subject: Re: [Cryptography] trojans in the firmware 
Those are well worth reading.
There are two possible interpretations of the following passage, =
where Goodin quotes Costin Raiu, director of Kaspersky Lab's
global research and analysis team:
It may be not possible /at the moment/ ... but in context
Raiu seems to suggest it is not possible in principle, =
which is crazy wrong.  I say instead:
a) The disk manufacturer could allow you to read the firmware
 easily.  It's always going to be readable if somebody wants
 to go to enough trouble;  we're only arguing about the price.
b) If they don't want to make reading easy, they should
 provide /at least/ the following:
  -- the total number of times the firmware has been modified, and
  -- the current hash.  Cryptologically strong hash.
=3D=3D=3D>  Heretofore there hasn't been much market demand =
for such a feature, but that is something that can be
changed.  In particular, the Kaspersky guys, rather
than giving up, should be collaborating with the disk
vendors to come up with a workable solution.
Obviously the checksum reporting routine needs to be =
in a non-flashable part of the firmware.
OTOH, equally obviously, this may not solve the problem
if your threat model includes "interdictions", where
the opposition trojanizes your equipment while it is =
in transit from the vendor to you.
On the third hand, there are ways of defending against =
even that.  It's not particularly hard to build your own
computer from components;  Gazillions of hobbyists have
done so.  If you think you are under threat, buy the
components and test them at the component level.  For
instance, read the BIOS ROM using a ROM reader, i.e.
in a way that is not dependent on booting from that
ROM.  Note that there exist open-source BIOSes.
Ditto for the boot blocks on the disk.  It doesn't =
take a very fancy disk diagnostic to discover that =
what you are reading from block 0 isn't what you
Then put the components together in some slightly
eccentric way.  For example, if you're doing software
RAID, it becomes very much harder for the firmware in
the disk drive to screw you over.  That's because the
drive doesn't know what you're going to do with the
We need to exert serious pressure in this direction.
This isn't just about Iranian weaponeers versus the =
NSA, which is complicated by political questions
about who you think the are the bad guys.  It is also =
about bankers trying to fend off advanced persistent =
threats from bandits.  Even if you think bankers are
bad guys, the bandits are worse.
And then there is election machinery.  Vote-counting
is heavily computerized, and we reeeeally need more =
transparency and reliability at every level, from =
BIOS and disk firmware on up.
The cryptography mailing list
