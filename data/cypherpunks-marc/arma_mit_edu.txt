
@_date: 2002-08-15 16:46:59
@_author: Roger Dingledine 
@_subject: free haven status 
At this point, Free Haven has 3 major flaws, and I'm putting it on the
back burner while I address them:
* The reputation system is tricky and won't work. We need to replace the
gossip/credibility system with a mechanism for verifiable transactions.
See  for more details.
* Retrieval is currently broadcast, which is insane. I'm letting other
projects work on solutions here (eg Chord), and I'll pick my favorite
when the time comes.
* There is no anonymous communications infrastructure. This is the area
we're focusing on currently. See and

@_date: 2007-04-18 05:01:55
@_author: Roger Dingledine 
@_subject: Re: [Fwd: High-traffic Colluding Tor Routers in Washington, D.C.  Confirmed] 
"Nostra2004 sent me some follow-up questions, which
I'll answer here so we can keep the thread in one place. Maybe this
will finally put the topic to rest. :)
I believe they made some phone calls to their friends who work in the
network operations center at psinet.
They know the person who was running them. It was somebody in the security
field who was helping out but was embarrassed to realize that he was
actually putting the network at risk by helping out quite so much. :)
The fellow felt that private embarrassment was adequate, and asked not
to be publically named. I trust them, and they trust him, so from my
perspective it is now fine.
Yep. I agree. The Tor network may seem large, but it still needs to grow
a lot larger to resist even medium sized attackers.
If you launch a bunch of Tor servers that together push upwards of
200MBit/s each way sustained, ...that's a lot of bytes.
Tor weights path selection by bandwidth -- otherwise Tor performance
would be extremely miserable rather than just miserable.
There are even several research projects currently looking at how to
trade off a bit more privacy for better performance, including one of
our GSoC interns. See also item  on
Yes. See the previous post:
  This issue also prompted us to speed up the fix/feature in
  0.1.2.1-alpha:
  "Automatically avoid picking more than one node from the same
  /16 network when constructing a circuit."
  But the issue still exists with respect to people who control different
they can).
Well, the Tor directory authorities list servers, and can mark each
server as invalid, badexit, etc. So in effect the authority operators
can collude to blacklist nodes that we agree are behaving badly. A
majority of authority operators need to claim something before clients
will believe it. See for a few more details.
Yes, there is actually a video, courtesy the 23C3 folks:
look for talk 1513. For example,
Hope that helps,

@_date: 2007-12-19 15:46:56
@_author: Roger Dingledine 
@_subject: Re: another seeming attack on my server's DirPort 
Hi Scott,
Can you check what's being repeatedly fetched?
One way to do this is to run at loglevel debug briefly, and look for
  log_debug(LD_DIRSERV,"rewritten url as '%s'.", url);
My first guess is that it's a runaway Tor client, or a runaway cache
between the Tor client and you, rather than any intentionally abusive
behavior. (It's amazing what can go wrong on the Internet when you have
enough participants.)

@_date: 2008-10-31 05:03:51
@_author: Roger Dingledine 
@_subject: Re: German data rentention law 
There are at least four reasons why this would be a bad move.
First, Tor isn't actually that bulletproof against a distributed
attacker (see all the recent papers we've been adding to
 as well as the upcoming attack papers
we keep hearing rumors about), and we don't want to make the job even
easier by making each of these relays into a juicy data target.
Second, the rest of the Tor community would not easily believe that
trading off network security for network capacity in this way is a
tradeoff they want.
Third, if Tor tolerates this law because its network architecture resists
it, and we let the law survive, then the next iteration of the law will
be better adapted to Tor's threat model.
Fourth, we don't want to undermine the effort to make this data retention
law go away, by showing "oh, the law isn't so bad".
There are still people in Germany who run high profile Tor relays and
who say they will not log. I have no interest in adding logs to Tor.
I'm still surprised at all the people who think the choice is between
keeping their Tor relay without logs or adding logging. The choice is
to keep the relay running with no logs, or to shut down the relay.
Let's beat it here and now, rather than letting them gnaw us to death.

@_date: 2008-10-19 22:06:58
@_author: Roger Dingledine 
@_subject: Re: German data rentention law 
Great. That would make it even better.
"Some guy at 24C3 told me", I believe is what I'm working with. Lots of
rumors. It would be great to see this one turn out to be false.
That idea matches what the officers in Stuttgart told me they asked for:
But they also seemed to be under the impression they'd gotten a much
more far-reaching law than they asked for.
Quite so. Good thing all the German laws are so clear. :)
(To be fair, the amount of contradictory legal goo in other countries
is no better.)
So: if it turns out that German ISPs don't log anything related to traffic
headers, then the only remaining concern is the Germany-specific clause
about anonymizing services.
And we do not want to see any Tor relays that log traffic information. So
should Tor's role for now be to simply say "the only risk from the German
data retention law is if its vague wording convinces Tor operators
to install backdoors in their relays. If you think your new law is
enforceable, and would like to backdoor your relay, please shut it down
instead.", and then wait to see how the people fighting the law fare?
Is there anything more active that we could usefully do?
Are there actually any design changes in Tor that are needed for now?
Assuming ISPs don't suddenly start becoming logging stations, and assuming
not very many Tor relays become compromised, there really aren't any
new threats for Tor users.

@_date: 2008-10-18 23:03:34
@_author: Roger Dingledine 
@_subject: Re: German data rentention law 
To be clear, I didn't write the above line.
A fine question. Hopefully as we learn more about what ISPs will log,
we will come to decide that having Tor exit relays in Germany doesn't
pose much risk -- as long as we take appropriate other steps to make
sure the other end of the circuit isn't logged by German ISPs too.
It isn't just a matter of what port they listen on. So long as there's
a public list of Tor relays, then people can just compare IP addresses
they see to the public relay list. And that public relay list isn't
going away anytime soon, since Tor clients need it when picking a path.
But that said, hiding your first hop by using an entry guard that isn't
in the public relay list may be a fine strategy. We call these non-public
relays "bridges":

@_date: 2008-10-18 20:13:53
@_author: Roger Dingledine 
@_subject: Re: German data rentention law 
The JonDos folks are nice people, but they seem to be taking the approach
"let's work with law enforcement to comply with what they wanted the law
to include." I would rather take the approach "let's figure out how we
can keep Tor users and relay operators as safe as possible even if ISPs
in Germany start logging things."
Talking with law enforcement is generally a good idea, but asking them
for clarification and then believing that's the law may not be such a
good idea.
In my opinion we really have to look at the endpoints of the Tor circuit,
which is where Tor is most vulnerable (via end-to-end correlation
attacks): we are worried about A) an attacker who can watch the Tor user,
or its network connection, or its entry relay; and B) an attacker who
can watch the destination site, or its network connection, or the exit
relay. From that perspective, an attacker who can watch the website
doesn't really care where the exit relay is -- he's already got that
half of the conversation, and if he can combine it with knowing something
about the beginning of the circuit, he wins.
Consider instead my proposal from last week on or-dev:
The basic proposal there is:
1) Never assign the Guard flag to Tor relays in Germany.
2) Maybe, consider starting circuits unpredictably before we want to
attach a stream to them (we already mostly do that, since we build
circuits preemptively), and closing circuits unpredictably after we are
done using them. The idea there is to make the TCP connection logs at
ISPs not correlate with when a given Tor stream started or stopped. I say
"maybe" because it's far from clear that all ISPs will be forced to log
TCP connection start and stop timestamps.
Note that this strategy is designed to make it safe to have Tor relays
running at *ISPs* that log. Even if no German Tor relays log, data
retention poses a serious risk to Tor users if enough ISPs are logging
There will be no such thing as a Tor relay that logs. (If you wish to
run a Tor relay that logs all its connections in a way that's useful
to attackers, please do us the favor of shutting it off instead. If you
find a way to keep logs that are absolutely useless but that you think
will keep the police from hassling you, please talk to us first.)
Idea  above solves this issue: we can take the Guard flag away at the
authorities, so only the directory authorities need to upgrade.
Even if all German Tor relays became non-exit relays, we would still have
the worry that a user visited a German website using a German *entry*
point. According to our research if an attacker manages to get data from
both sides, this appears sufficient for linking the user to the website.
So no, I think that is not a sufficient fix. :)
In any case, I don't want to reach conclusions like "therefore all
German nodes have to stop providing exit service." The law is vague --
so let's fight the law, through lawsuits and other mechanisms, not try
to guess what it might mean and obey that guess.
There *will* be people in Germany who continue to run their Tor relay
(exit or not) and do not log anything. So we need to figure out how to
make successful test cases from the organizations that have the resources
and inclination to defend themselves. (This does mean, though, that
if you're running an exit relay in Germany and you're not comfortable
fighting this law, then you should consider becoming a non-exit in
January until things get more clear.)
There will be much more discussion at 25C3 I hope!

@_date: 2009-06-21 11:38:42
@_author: Roger Dingledine 
@_subject: Re: Help Iranian dissidents 
There are only a few hundred running bridges right now. I think it's fine
to "use" them all this week, if people want to. We'll have more later,
and it'll be good to learn some lessons here.
You can discover some bridge addresses either with a gmail account,
or with a web browser:
It seems that other people are collecting bridge addresses manually and
giving them out when they find people who could use one. This might
be a bad idea, in that it increases the risk that the attacker will
get ahold of the bridge address, since now there are two ways to learn
it. But it also might be a good idea, since now it's more likely to get
used by somebody who needs it (not everybody knows about the above two
URLs after all).
I'm not sure what the right balance is.
In any case, the Tor network itself hasn't been blocked in Iran, as far
as I can tell. So in a sense this bridge stuff (the next step in the
arms race) is all just practice.

@_date: 2009-06-26 14:45:44
@_author: Roger Dingledine 
@_subject: Re: A Few Random Thoughts... 
Sounds great. Let us know if you have any questions or run into any
Depending on how you're installing, you might like the development
version (currently 0.2.1.16-rc). The 0.2.1.x series is going to become
the new "stable" soon (it's already probably more stable in practice
than 0.2.0.35), and it's way better in a number of other ways.
But either 0.2.0.x or 0.2.1.x is fine, really.
That's a really good point.
Especially since a lot of the people who really hate/fear Tor are IT
folks who don't understand it.
Yep. The next step is to come up with some really good clean simple
example sentences for our new category. Those examples will dictate the
title we give it -- "Security experts use Tor", "Sysadmins use Tor",
"Computer experts use Tor", or something else.
If anybody knows good places, please let us know. :) There's a small
list being built here:
Another concern is that if we centralize all the exit relays in a few
places, we reduce the anonymity that the Tor network can provide. But I
don't think we're anywhere near doing that yet, so it's just something
to keep in the back of our minds.
Me too. Don't worry, we won't do it. But see also

@_date: 2009-08-06 05:51:12
@_author: Roger Dingledine 
@_subject: Tor 0.2.1.18 and 0.2.1.19 are released 
Tor 0.2.1.18 lays the foundations for performance improvements, adds
status events to help users diagnose bootstrap problems, adds optional
authentication/authorization for hidden services, fixes a variety of
potential anonymity problems, and includes a huge pile of other features
and bug fixes.
Tor 0.2.1.19 fixes a major bug with accessing and providing hidden
Changes in version 0.2.1.19 - 2009-07-28
  o Major bugfixes:
    - Make accessing hidden services on 0.2.1.x work right again.
      Bugfix on 0.2.1.3-alpha; workaround for bug 1038. Diagnosis and
      part of patch provided by "optimist".
  o Minor features:
    - When a relay/bridge is writing out its identity key fingerprint to
      the "fingerprint" file and to its logs, write it without spaces. Now
      it will look like the fingerprints in our bridges documentation,
      and confuse fewer users.
  o Minor bugfixes:
    - Relays no longer publish a new server descriptor if they change
      their MaxAdvertisedBandwidth config option but it doesn't end up
      changing their advertised bandwidth numbers. Bugfix on 0.2.0.28-rc;
      fixes bug 1026. Patch from Sebastian.
    - Avoid leaking memory every time we get a create cell but we have
      so many already queued that we refuse it. Bugfix on 0.2.0.19-alpha;
      fixes bug 1034. Reported by BarkerJr.
Changes in version 0.2.1.18 - 2009-07-24
  o Major features (clients):
    - Start sending "bootstrap phase" status events to the controller,
      so it can keep the user informed of progress fetching directory
      information and establishing circuits. Also inform the controller
      if we think we're stuck at a particular bootstrap phase. Implements
      proposal 137.
    - Clients replace entry guards that were chosen more than a few months
      ago. This change should significantly improve client performance,
      especially once more people upgrade, since relays that have been
      a guard for a long time are currently overloaded.
    - Network status consensus documents and votes now contain bandwidth
      information for each relay. Clients use the bandwidth values
      in the consensus, rather than the bandwidth values in each
      relay descriptor. This approach opens the door to more accurate
      bandwidth estimates once the directory authorities start doing
      active measurements. Implements part of proposal 141.
  o Major features (relays):
    - Disable and refactor some debugging checks that forced a linear scan
      over the whole server-side DNS cache. These accounted for over 50%
      of CPU time on a relatively busy exit node's gprof profile. Also,
      disable some debugging checks that appeared in exit node profile
      data. Found by Jacob.
    - New DirPortFrontPage option that takes an html file and publishes
      it as "/" on the DirPort. Now relay operators can provide a
      disclaimer without needing to set up a separate webserver. There's
      a sample disclaimer in contrib/tor-exit-notice.html.
  o Major features (hidden services):
    - Make it possible to build hidden services that only certain clients
      are allowed to connect to. This is enforced at several points,
      so that unauthorized clients are unable to send INTRODUCE cells
      to the service, or even (depending on the type of authentication)
      to learn introduction points. This feature raises the bar for
      certain kinds of active attacks against hidden services. Design
      and code by Karsten Loesing. Implements proposal 121.
    - Relays now store and serve v2 hidden service descriptors by default,
      i.e., the new default value for HidServDirectoryV2 is 1. This is
      the last step in proposal 114, which aims to make hidden service
      lookups more reliable.
  o Major features (path selection):
    - ExitNodes and Exclude*Nodes config options now allow you to restrict
      by country code ("{US}") or IP address or address pattern
      ("255.128.0.0/16"). Patch from Robert Hogan. It still needs some
      refinement to decide what config options should take priority if
      you ask to both use a particular node and exclude it.
  o Major features (misc):
    - When building a consensus, do not include routers that are down.
      This cuts down 30% to 40% on consensus size. Implements proposal
      138.
    - New TestingTorNetwork config option to allow adjustment of
      previously constant values that could slow bootstrapping. Implements
      proposal 135. Patch from Karsten.
    - Convert many internal address representations to optionally hold
      IPv6 addresses. Generate and accept IPv6 addresses in many protocol
      elements. Make resolver code handle nameservers located at IPv6
      addresses.
    - More work on making our TLS handshake blend in: modify the list
      of ciphers advertised by OpenSSL in client mode to even more
      closely resemble a common web browser. We cheat a little so that
      we can advertise ciphers that the locally installed OpenSSL doesn't
      know about.
    - Use the TLS1 hostname extension to more closely resemble browser
      behavior.
  o Security fixes (anonymity/entropy):
    - Never use a connection with a mismatched address to extend a
      circuit, unless that connection is canonical. A canonical
      connection is one whose address is authenticated by the router's
      identity key, either in a NETINFO cell or in a router descriptor.
    - Implement most of proposal 110: The first K cells to be sent
      along a circuit are marked as special "early" cells; only K "early"
      cells will be allowed. Once this code is universal, we can block
      certain kinds of denial-of-service attack by requiring that EXTEND
      commands must be sent using an "early" cell.
    - Resume using OpenSSL's RAND_poll() for better (and more portable)
      cross-platform entropy collection again. We used to use it, then
      stopped using it because of a bug that could crash systems that
      called RAND_poll when they had a lot of fds open. It looks like the
      bug got fixed in late 2006. Our new behavior is to call RAND_poll()
      at startup, and to call RAND_poll() when we reseed later only if
      we have a non-buggy OpenSSL version.
    - When the client is choosing entry guards, now it selects at most
      one guard from a given relay family. Otherwise we could end up with
      all of our entry points into the network run by the same operator.
      Suggested by Camilo Viecco. Fix on 0.1.1.11-alpha.
    - Do not use or believe expired v3 authority certificates. Patch
      from Karsten. Bugfix in 0.2.0.x. Fixes bug 851.
    - Drop begin cells to a hidden service if they come from the middle
      of a circuit. Patch from lark.
    - When we erroneously receive two EXTEND cells for the same circuit
      ID on the same connection, drop the second. Patch from lark.
    - Authorities now vote for the Stable flag for any router whose
      weighted MTBF is at least 5 days, regardless of the mean MTBF.
    - Clients now never report any stream end reason except 'MISC'.
      Implements proposal 148.
  o Major bugfixes (crashes):
    - Parse dates and IPv4 addresses in a locale- and libc-independent
      manner, to avoid platform-dependent behavior on malformed input.
    - Fix a crash that occurs on exit nodes when a nameserver request
      timed out. Bugfix on 0.1.2.1-alpha; our CLEAR debugging code had
      been suppressing the bug since 0.1.2.10-alpha. Partial fix for
      bug 929.
    - Do not assume that a stack-allocated character array will be
      64-bit aligned on platforms that demand that uint64_t access is
      aligned. Possible fix for bug 604.
    - Resolve a very rare crash bug that could occur when the user forced
      a nameserver reconfiguration during the middle of a nameserver
      probe. Fixes bug 526. Bugfix on 0.1.2.1-alpha.
    - Avoid a "0 divided by 0" calculation when calculating router uptime
      at directory authorities. Bugfix on 0.2.0.8-alpha.
    - Fix an assertion bug in parsing policy-related options; possible fix
      for bug 811.
    - Rate-limit too-many-sockets messages: when they happen, they happen
      a lot and end up filling up the disk. Resolves bug 748.
    - Fix a race condition that could cause crashes or memory corruption
      when running as a server with a controller listening for log
      messages.
    - Avoid crashing when we have a policy specified in a DirPolicy or
      SocksPolicy or ReachableAddresses option with ports set on it,
      and we re-load the policy. May fix bug 996.
    - Fix an assertion failure on 64-bit platforms when we allocated
      memory right up to the end of a memarea, then realigned the memory
      one step beyond the end. Fixes a possible cause of bug 930.
    - Protect the count of open sockets with a mutex, so we can't
      corrupt it when two threads are closing or opening sockets at once.
      Fix for bug 939. Bugfix on 0.2.0.1-alpha.
  o Major bugfixes (clients):
    - Discard router descriptors as we load them if they are more than
      five days old. Otherwise if Tor is off for a long time and then
      starts with cached descriptors, it will try to use the onion keys
      in those obsolete descriptors when building circuits. Fixes bug 887.
    - When we choose to abandon a new entry guard because we think our
      older ones might be better, close any circuits pending on that
      new entry guard connection. This fix should make us recover much
      faster when our network is down and then comes back. Bugfix on
      0.1.2.8-beta; found by lodger.
    - When Tor clients restart after 1-5 days, they discard all their
      cached descriptors as too old, but they still use the cached
      consensus document. This approach is good for robustness, but
      bad for performance: since they don't know any bandwidths, they
      end up choosing at random rather than weighting their choice by
      speed. Fixed by the above feature of putting bandwidths in the
      consensus.
  o Major bugfixes (relays):
    - Relays were falling out of the networkstatus consensus for
      part of a day if they changed their local config but the
      authorities discarded their new descriptor as "not sufficiently
      different". Now directory authorities accept a descriptor as changed
      if BandwidthRate or BandwidthBurst changed. Partial fix for bug 962;
      patch by Sebastian.
    - Ensure that two circuits can never exist on the same connection
      with the same circuit ID, even if one is marked for close. This
      is conceivably a bugfix for bug 779; fixes a bug on 0.1.0.4-rc.
    - Directory authorities were neglecting to mark relays down in their
      internal histories if the relays fall off the routerlist without
      ever being found unreachable. So there were relays in the histories
      that haven't been seen for eight months, and are listed as being
      up for eight months. This wreaked havoc on the "median wfu" and
      "median mtbf" calculations, in turn making Guard and Stable flags
      wrong, hurting network performance. Fixes bugs 696 and 969. Bugfix
      on 0.2.0.6-alpha.
  o Major bugfixes (hidden services):
    - When establishing a hidden service, introduction points that
      originate from cannibalized circuits were completely ignored
      and not included in rendezvous service descriptors. This might
      have been another reason for delay in making a hidden service
      available. Bugfix from long ago (0.0.9.x?)
  o Major bugfixes (memory and resource management):
    - Fixed some memory leaks -- some quite frequent, some almost
      impossible to trigger -- based on results from Coverity.
    - Speed up parsing and cut down on memory fragmentation by using
      stack-style allocations for parsing directory objects. Previously,
      this accounted for over 40% of allocations from within Tor's code
      on a typical directory cache.
    - Use a Bloom filter rather than a digest-based set to track which
      descriptors we need to keep around when we're cleaning out old
      router descriptors. This speeds up the computation significantly,
      and may reduce fragmentation.
  o New/changed config options:
    - Now NodeFamily and MyFamily config options allow spaces in
      identity fingerprints, so it's easier to paste them in.
      Suggested by Lucky Green.
    - Allow ports 465 and 587 in the default exit policy again. We had
      rejected them in 0.1.0.15, because back in 2005 they were commonly
      misconfigured and ended up as spam targets. We hear they are better
      locked down these days.
    - Make TrackHostExit mappings expire a while after their last use, not
      after their creation. Patch from Robert Hogan.
    - Add an ExcludeExitNodes option so users can list a set of nodes
      that should be be excluded from the exit node position, but
      allowed elsewhere. Implements proposal 151.
    - New --hush command-line option similar to --quiet. While --quiet
      disables all logging to the console on startup, --hush limits the
      output to messages of warning and error severity.
    - New configure/torrc options (--enable-geoip-stats,
      DirRecordUsageByCountry) to record how many IPs we've served
      directory info to in each country code, how many status documents
      total we've sent to each country code, and what share of the total
      directory requests we should expect to see.
    - Make outbound DNS packets respect the OutboundBindAddress setting.
      Fixes the bug part of bug 798. Bugfix on 0.1.2.2-alpha.
    - Allow separate log levels to be configured for different logging
      domains. For example, this allows one to log all notices, warnings,
      or errors, plus all memory management messages of level debug or
      higher, with: Log [MM] debug-err [*] notice-err file /var/log/tor.
    - Update to the "June 3 2009" ip-to-country file.
  o Minor features (relays):
    - Raise the minimum rate limiting to be a relay from 20000 bytes
      to 20480 bytes (aka 20KB/s), to match our documentation. Also
      update directory authorities so they always assign the Fast flag
      to relays with 20KB/s of capacity. Now people running relays won't
      suddenly find themselves not seeing any use, if the network gets
      faster on average.
    - If we're a relay and we change our IP address, be more verbose
      about the reason that made us change. Should help track down
      further bugs for relays on dynamic IP addresses.
    - Exit servers can now answer resolve requests for ip6.arpa addresses.
    - Implement most of Proposal 152: allow specialized servers to permit
      single-hop circuits, and clients to use those servers to build
      single-hop circuits when using a specialized controller. Patch
      from Josh Albrecht. Resolves feature request 768.
    - When relays do their initial bandwidth measurement, don't limit
      to just our entry guards for the test circuits. Otherwise we tend
      to have multiple test circuits going through a single entry guard,
      which makes our bandwidth test less accurate. Fixes part of bug 654;
      patch contributed by Josh Albrecht.
  o Minor features (directory authorities):
    - Try not to open more than one descriptor-downloading connection
      to an authority at once. This should reduce load on directory
      authorities. Fixes bug 366.
    - Add cross-certification to newly generated certificates, so that
      a signing key is enough information to look up a certificate. Start
      serving certificates by       pairs. Implements proposal 157.
    - When a directory authority downloads a descriptor that it then
      immediately rejects, do not retry downloading it right away. Should
      save some bandwidth on authorities. Fix for bug 888. Patch by
      Sebastian Hahn.
    - Directory authorities now serve a /tor/dbg-stability.txt URL to
      help debug WFU and MTBF calculations.
    - In directory authorities' approved-routers files, allow
      fingerprints with or without space.
  o Minor features (directory mirrors):
    - When a download gets us zero good descriptors, do not notify
      Tor that new directory information has arrived.
    - Servers support a new URL scheme for consensus downloads that
      allows the client to specify which authorities are trusted.
      The server then only sends the consensus if the client will trust
      it. Otherwise a 404 error is sent back. Clients use this
      new scheme when the server supports it (meaning it's running
      0.2.1.1-alpha or later). Implements proposal 134.
  o Minor features (bridges):
    - If the bridge config line doesn't specify a port, assume 443.
      This makes bridge lines a bit smaller and easier for users to
      understand.
    - If we're using bridges and our network goes away, be more willing
      to forgive our bridges and try again when we get an application
      request.
  o Minor features (hidden services):
    - When the client launches an introduction circuit, retry with a
      new circuit after 30 seconds rather than 60 seconds.
    - Launch a second client-side introduction circuit in parallel
      after a delay of 15 seconds (based on work by Christian Wilms).
    - Hidden services start out building five intro circuits rather
      than three, and when the first three finish they publish a service
      descriptor using those. Now we publish our service descriptor much
      faster after restart.
    - Drop the requirement to have an open dir port for storing and
      serving v2 hidden service descriptors.
  o Minor features (build and packaging):
    - On Linux, use the prctl call to re-enable core dumps when the User
      option is set.
    - Try to make sure that the version of Libevent we're running with
      is binary-compatible with the one we built with. May address bug
      897 and others.
    - Add a new --enable-local-appdata configuration switch to change
      the default location of the datadir on win32 from APPDATA to
      LOCAL_APPDATA. In the future, we should migrate to LOCAL_APPDATA
      entirely. Patch from coderman.
    - Build correctly against versions of OpenSSL 0.9.8 or later that
      are built without support for deprecated functions.
    - On platforms with a maximum syslog string length, truncate syslog
      messages to that length ourselves, rather than relying on the
      system to do it for us.
    - Automatically detect MacOSX versions earlier than 10.4.0, and
      disable kqueue from inside Tor when running with these versions.
      We previously did this from the startup script, but that was no
      help to people who didn't use the startup script. Resolves bug 863.
    - Build correctly when configured to build outside the main source
      path. Patch from Michael Gold.
    - Disable GCC's strict alias optimization by default, to avoid the
      likelihood of its introducing subtle bugs whenever our code violates
      the letter of C99's alias rules.
    - Change the contrib/tor.logrotate script so it makes the new
      logs as "_tor:_tor" rather than the default, which is generally
      "root:wheel". Fixes bug 676, reported by Serge Koksharov.
    - Change our header file guard macros to be less likely to conflict
      with system headers. Adam Langley noticed that we were conflicting
      with log.h on Android.
    - Add a couple of extra warnings to --enable-gcc-warnings for GCC 4.3,
      and stop using a warning that had become unfixably verbose under
      GCC 4.3.
    - Use a lockfile to make sure that two Tor processes are not
      simultaneously running with the same datadir.
    - Allow OpenSSL to use dynamic locks if it wants.
    - Add LIBS=-lrt to Makefile.am so the Tor RPMs use a static libevent.
  o Minor features (controllers):
    - When generating circuit events with verbose nicknames for
      controllers, try harder to look up nicknames for routers on a
      circuit. (Previously, we would look in the router descriptors we had
      for nicknames, but not in the consensus.) Partial fix for bug 941.
    - New controller event NEWCONSENSUS that lists the networkstatus
      lines for every recommended relay. Now controllers like Torflow
      can keep up-to-date on which relays they should be using.
    - New controller event "clients_seen" to report a geoip-based summary
      of which countries we've seen clients from recently. Now controllers
      like Vidalia can show bridge operators that they're actually making
      a difference.
    - Add a 'getinfo status/clients-seen' controller command, in case
      controllers want to hear clients_seen events but connect late.
    - New CONSENSUS_ARRIVED event to note when a new consensus has
      been fetched and validated.
    - Add an internal-use-only __ReloadTorrcOnSIGHUP option for
      controllers to prevent SIGHUP from reloading the configuration.
      Fixes bug 856.
    - Return circuit purposes in response to GETINFO circuit-status.
      Fixes bug 858.
    - Serve the latest v3 networkstatus consensus via the control
      port. Use "getinfo dir/status-vote/current/consensus" to fetch it.
    - Add a "GETINFO /status/bootstrap-phase" controller option, so the
      controller can query our current bootstrap state in case it attaches
      partway through and wants to catch up.
    - Provide circuit purposes along with circuit events to the controller.
  o Minor features (tools):
    - Do not have tor-resolve automatically refuse all .onion addresses;
      if AutomapHostsOnResolve is set in your torrc, this will work fine.
    - Add a -p option to tor-resolve for specifying the SOCKS port: some
      people find host:port too confusing.
    - Print the SOCKS5 error message string as well as the error code
      when a tor-resolve request fails. Patch from Jacob.
  o Minor bugfixes (memory and resource management):
    - Clients no longer cache certificates for authorities they do not
      recognize. Bugfix on 0.2.0.9-alpha.
    - Do not use C's stdio library for writing to log files. This will
      improve logging performance by a minute amount, and will stop
      leaking fds when our disk is full. Fixes bug 861.
    - Stop erroneous use of O_APPEND in cases where we did not in fact
      want to re-seek to the end of a file before every last write().
    - Fix a small alignment and memory-wasting bug on buffer chunks.
      Spotted by rovv.
    - Add a malloc_good_size implementation to OpenBSD_malloc_linux.c,
      to avoid unused RAM in buffer chunks and memory pools.
    - Reduce the default smartlist size from 32 to 16; it turns out that
      most smartlists hold around 8-12 elements tops.
    - Make dumpstats() log the fullness and size of openssl-internal
      buffers.
    - If the user has applied the experimental SSL_MODE_RELEASE_BUFFERS
      patch to their OpenSSL, turn it on to save memory on servers. This
      patch will (with any luck) get included in a mainline distribution
      before too long.
    - Fix a memory leak when v3 directory authorities load their keys
      and cert from disk. Bugfix on 0.2.0.1-alpha.
    - Stop using malloc_usable_size() to use more area than we had
      actually allocated: it was safe, but made valgrind really unhappy.
    - Make the assert_circuit_ok() function work correctly on circuits that
      have already been marked for close.
    - Fix uninitialized size field for memory area allocation: may improve
      memory performance during directory parsing.
  o Minor bugfixes (clients):
    - Stop reloading the router list from disk for no reason when we
      run out of reachable directory mirrors. Once upon a time reloading
      it would set the 'is_running' flag back to 1 for them. It hasn't
      done that for a long time.
    - When we had picked an exit node for a connection, but marked it as
      "optional", and it turned out we had no onion key for the exit,
      stop wanting that exit and try again. This situation may not
      be possible now, but will probably become feasible with proposal
      158. Spotted by rovv. Fixes another case of bug 752.
    - Fix a bug in address parsing that was preventing bridges or hidden
      service targets from being at IPv6 addresses.
    - Do not remove routers as too old if we do not have any consensus
      document. Bugfix on 0.2.0.7-alpha.
    - When an exit relay resolves a stream address to a local IP address,
      do not just keep retrying that same exit relay over and
      over. Instead, just close the stream. Addresses bug 872. Bugfix
      on 0.2.0.32. Patch from rovv.
    - Made Tor a little less aggressive about deleting expired
      certificates. Partial fix for bug 854.
    - Treat duplicate certificate fetches as failures, so that we do
      not try to re-fetch an expired certificate over and over and over.
    - Do not say we're fetching a certificate when we'll in fact skip it
      because of a pending download.
    - If we have correct permissions on $datadir, we complain to stdout
      and fail to start. But dangerous permissions on
      $datadir/cached-status/ would cause us to open a log and complain
      there. Now complain to stdout and fail to start in both cases. Fixes
      bug 820, reported by seeess.
  o Minor bugfixes (bridges):
    - When we made bridge authorities stop serving bridge descriptors over
      unencrypted links, we also broke DirPort reachability testing for
      bridges. So bridges with a non-zero DirPort were printing spurious
      warns to their logs. Bugfix on 0.2.0.16-alpha. Fixes bug 709.
    - Don't allow a bridge to publish its router descriptor to a
      non-bridge directory authority. Fixes part of bug 932.
    - When we change to or from being a bridge, reset our counts of
      client usage by country. Fixes bug 932.
  o Minor bugfixes (relays):
    - Log correct error messages for DNS-related network errors on
      Windows.
    - Actually return -1 in the error case for read_bandwidth_usage().
      Harmless bug, since we currently don't care about the return value
      anywhere. Bugfix on 0.2.0.9-alpha.
    - Provide a more useful log message if bug 977 (related to buffer
      freelists) ever reappears, and do not crash right away.
    - We were already rejecting relay begin cells with destination port
      of 0. Now also reject extend cells with destination port or address
      of 0. Suggested by lark.
    - When we can't transmit a DNS request due to a network error, retry
      it after a while, and eventually transmit a failing response to
      the RESOLVED cell. Bugfix on 0.1.2.5-alpha.
    - Solve a bug that kept hardware crypto acceleration from getting
      enabled when accounting was turned on. Fixes bug 907. Bugfix on
      0.0.9pre6.
    - When a canonical connection appears later in our internal list
      than a noncanonical one for a given OR ID, always use the
      canonical one. Bugfix on 0.2.0.12-alpha. Fixes bug 805.
      Spotted by rovv.
    - Avoid some nasty corner cases in the logic for marking connections
      as too old or obsolete or noncanonical for circuits. Partial
      bugfix on bug 891.
    - Fix another interesting corner-case of bug 891 spotted by rovv:
      Previously, if two hosts had different amounts of clock drift, and
      one of them created a new connection with just the wrong timing,
      the other might decide to deprecate the new connection erroneously.
      Bugfix on 0.1.1.13-alpha.
    - If one win32 nameserver fails to get added, continue adding the
      rest, and don't automatically fail.
    - Fix a bug where an unreachable relay would establish enough
      reachability testing circuits to do a bandwidth test -- if
      we already have a connection to the middle hop of the testing
      circuit, then it could establish the last hop by using the existing
      connection. Bugfix on 0.1.2.2-alpha, exposed when we made testing
      circuits no longer use entry guards in 0.2.1.3-alpha.
  o Minor bugfixes (directory authorities):
    - Limit uploaded directory documents to be 16M rather than 500K.
      The directory authorities were refusing v3 consensus votes from
      other authorities, since the votes are now 504K. Fixes bug 959;
      bugfix on 0.0.2pre17 (where we raised it from 50K to 500K ;).
    - Directory authorities should never send a 503 "busy" response to
      requests for votes or keys. Bugfix on 0.2.0.8-alpha; exposed by
      bug 959.
    - Fix code so authorities _actually_ send back X-Descriptor-Not-New
      headers. Bugfix on 0.2.0.10-alpha.
  o Minor bugfixes (hidden services):
    - When we can't find an intro key for a v2 hidden service descriptor,
      fall back to the v0 hidden service descriptor and log a bug message.
      Workaround for bug 1024.
    - In very rare situations new hidden service descriptors were
      published earlier than 30 seconds after the last change to the
      service. (We currently think that a hidden service descriptor
      that's been stable for 30 seconds is worth publishing.)
    - If a hidden service sends us an END cell, do not consider
      retrying the connection; just close it. Patch from rovv.
    - If we are not using BEGIN_DIR cells, don't attempt to contact hidden
      service directories if they have no advertised dir port. Bugfix
      on 0.2.0.10-alpha.
  o Minor bugfixes (tools):
    - In the torify(1) manpage, mention that tsocks will leak your
      DNS requests.
  o Minor bugfixes (controllers):
    - If the controller claimed responsibility for a stream, but that
      stream never finished making its connection, it would live
      forever in circuit_wait state. Now we close it after SocksTimeout
      seconds. Bugfix on 0.1.2.7-alpha; reported by Mike Perry.
    - Make DNS resolved controller events into "CLOSED", not
      "FAILED". Bugfix on 0.1.2.5-alpha. Fix by Robert Hogan. Resolves
      bug 807.
    - The control port would close the connection before flushing long
      replies, such as the network consensus, if a QUIT command was issued
      before the reply had completed. Now, the control port flushes all
      pending replies before closing the connection. Also fix a spurious
      warning when a QUIT command is issued after a malformed or rejected
      AUTHENTICATE command, but before the connection was closed. Patch
      by Marcus Griep. Fixes bugs 1015 and 1016.
    - Fix a bug that made stream bandwidth get misreported to the
      controller.
  o Deprecated and removed features:
    - The old "tor --version --version" command, which would print out
      the subversion "Id" of most of the source files, is now removed. It
      turned out to be less useful than we'd expected, and harder to
      maintain.
    - RedirectExits has been removed. It was deprecated since
      0.2.0.3-alpha.
    - Finally remove deprecated "EXTENDED_FORMAT" controller feature. It
      has been called EXTENDED_EVENTS since 0.1.2.4-alpha.
    - Cell pools are now always enabled; --disable-cell-pools is ignored.
    - Directory mirrors no longer fetch the v1 directory or
      running-routers files. They are obsolete, and nobody asks for them
      anymore. This is the first step to making v1 authorities obsolete.
    - Take out the TestVia config option, since it was a workaround for
      a bug that was fixed in Tor 0.1.1.21.
    - Mark RendNodes, RendExcludeNodes, HiddenServiceNodes, and
      HiddenServiceExcludeNodes as obsolete: they never worked properly,
      and nobody seems to be using them. Fixes bug 754. Bugfix on
      0.1.0.1-rc. Patch from Christian Wilms.
    - Remove all backward-compatibility code for relays running
      versions of Tor so old that they no longer work at all on the
      Tor network.
  o Code simplifications and refactoring:
    - Tool-assisted documentation cleanup. Nearly every function or
      static variable in Tor should have its own documentation now.
    - Rename the confusing or_is_obsolete field to the more appropriate
      is_bad_for_new_circs, and move it to or_connection_t where it
      belongs.
    - Move edge-only flags from connection_t to edge_connection_t: not
      only is this better coding, but on machines of plausible alignment,
      it should save 4-8 bytes per connection_t. "Every little bit helps."
    - Rename ServerDNSAllowBrokenResolvConf to ServerDNSAllowBrokenConfig
      for consistency; keep old option working for backward compatibility.
    - Simplify the code for finding connections to use for a circuit.
    - Revise the connection_new functions so that a more typesafe variant
      exists. This will work better with Coverity, and let us find any
      actual mistakes we're making here.
    - Refactor unit testing logic so that dmalloc can be used sensibly
      with unit tests to check for memory leaks.
    - Move all hidden-service related fields from connection and circuit
      structure to substructures: this way they won't eat so much memory.
    - Squeeze 2-5% out of client performance (according to oprofile) by
      improving the implementation of some policy-manipulation functions.
    - Change the implementation of ExcludeNodes and ExcludeExitNodes to
      be more efficient. Formerly it was quadratic in the number of
      servers; now it should be linear. Fixes bug 509.
    - Save 16-22 bytes per open circuit by moving the n_addr, n_port,
      and n_conn_id_digest fields into a separate structure that's
      only needed when the circuit has not yet attached to an n_conn.
    - Optimize out calls to time(NULL) that occur for every IO operation,
      or for every cell. On systems like Windows where time() is a
      slow syscall, this fix will be slightly helpful.

@_date: 2010-12-29 04:45:00
@_author: Roger Dingledine 
@_subject: Re: 27C3 on Tor 
Based on
I'm guessing they're basing the talk on their CCSW 2009 paper:
I was a reviewer on that paper. But alas I was in Hong Kong doing a Tor
training so I couldn't attend their presentation last November. It's the
best paper there is on the topic currently, but I feel that the attack
could become much much stronger against Tor than it was in the paper --
that paper's focus on size and frequency of IP packets was what made me
write on the Tor research page:
"The problem with all the previous attack papers is that they look at
timing and counting of IP packets on the wire. But OpenSSL's TLS records,
plus Tor's use of TCP pushback to do rate limiting, means that tracing by
IP packets produces very poor results. The right approach is to realize
that Tor uses OpenSSL, look inside the TLS record at the TLS headers,
and figure out how many 512-byte cells are being sent or received."
As a final note, on my reading list (which alas is growing rather than
shrinking) is
To unsubscribe, send an e-mail to majordomo with
unsubscribe or-talk    in the body.

@_date: 2010-12-29 04:29:09
@_author: Roger Dingledine 
@_subject: Re: 27C3 on Tor 
See also point 3 at
It's been sitting on our "this is important to learn more about"
research list for years.
It's also listed in the talk I did at 25c3:
 (slide 30)
So I'm glad to see more attention to the attack, but a bit frustrated that
we (the research community) are not farther along at understanding it.
Two other things to note:
The website fingerprinting attack works against other anonymity systems
too, in most cases even more straightforwardly than against Tor. We've
got 8+ years in the literature of applying it to other systems (most
thoroughly just attacking SSL streams to learn what web page is being
fetched despite the encryption), and in the past few years people have
improved the attack to get it to work against Tor also. As I understand
it, even now it only works consistently when they assume laboratory
conditions. That isn't to say that it won't work in real-world conditions

@_date: 2011-09-03 08:39:53
@_author: Roger Dingledine 
@_subject: [tor-talk] massive automated bridge requests: why? 
Hi folks,
Over the past few months the number of bridge users has spiked, most
prominently in Italy, but also plenty in Spain, Brazil, Israel, and
I believe it started out with a Tor bundle that somebody made that had
three bridges pre-configured -- we found a torrc file along with an
unofficial Windows Tor bundle. At the beginning, those few bridges had
tens of thousands of users each, and that was it.
Since then, we've seen an enormous spike in automated connections to
 -- more than a million requests an hour.
Now just about every bridge that's given out via the https pool (as
opposed to the gmail pool or the reserve pool) is seeing many many
thousands of users from Italy and these other countries.
It seems clear that somebody's unofficial Tor bundle automatically grabs
some bridges for its users, and that this somebody didn't understand
the notion of being polite to a remote service -- I think each user is
hitting the bridges page roughly every 30 seconds.
We've taken steps to defend the bridgedb service from this overload. And
I can imagine further steps, like finally rolling out a captcha on that
page, to block people from using it like a remote API (which I always
thought was kind of a neat option). Or heck, just moving to a different
URL and abandoning that one.
But the question first is: what's going on? Can those of you near or in
these countries please ask around and try to get some answers?
I don't think it's a censoring adversary trying to collect the list of
bridges. For one, it's way overkill; for another, why use the bridges
I don't think it's malware or some automated botnet that happens to
use bridges -- if it were, we should be seeing spikes in well-connected
countries like Japan.
tor-talk mailing list

@_date: 2012-04-05 01:14:53
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] access sites 
Notice that this paper is quite old. Since then Iran, has hit the "
country using Tor" mark:
So I expect the ratios will be different.
One of the important security properties of Tor is that is blends users
together. So if there are 10000 people in Saudi Arabia using Tor today,
and 5000 of them are using it to look at pictures of unclothed ankles,
that actually helps the other 5000 who may be using it for more diverse
(and potentially more risky) activities.
For what it's worth, it's the phrasing of assertions like this that make
people call your posts here trolling.
I am periodically invited to do talks for law enforcement about Tor,
and at basically every talk somebody there tells me they use Tor every
day for their work. See for example
 for an
early report on such a talk.
I've heard from dozens of soldiers and intelligence analysts who use
Tor for their work. Is it such a stretch to imagine that they would want
privacy online too, even if the adversaries they worry about aren't the
same ones you worry about?
This diversity of concerns is part of what makes Tor strong.
tor-talk mailing list

@_date: 2012-04-05 01:14:53
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] access sites 
Notice that this paper is quite old. Since then Iran, has hit the "
country using Tor" mark:
So I expect the ratios will be different.
One of the important security properties of Tor is that is blends users
together. So if there are 10000 people in Saudi Arabia using Tor today,
and 5000 of them are using it to look at pictures of unclothed ankles,
that actually helps the other 5000 who may be using it for more diverse
(and potentially more risky) activities.
For what it's worth, it's the phrasing of assertions like this that make
people call your posts here trolling.
I am periodically invited to do talks for law enforcement about Tor,
and at basically every talk somebody there tells me they use Tor every
day for their work. See for example
 for an
early report on such a talk.
I've heard from dozens of soldiers and intelligence analysts who use
Tor for their work. Is it such a stretch to imagine that they would want
privacy online too, even if the adversaries they worry about aren't the
same ones you worry about?
This diversity of concerns is part of what makes Tor strong.
tor-talk mailing list

@_date: 2012-04-04 22:45:15
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] access sites 
There has been some research on what Tor *traffic* is, but the methodology
soundness is always a question. The question here though is what the
breakdown of Tor *users* is. Nobody's done a scientifically valid study,
mostly because of the difficulty of getting a good sample when you're
talking about anonymous people.
tor-talk mailing list

@_date: 2012-08-21 23:11:07
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] End-to-end correlation for fun and profit 
I think your numbers may not be right (there are a lot of other subtleties
to the calculation), but your point is still generally correct. The Tor
network doesn't have enough diversity relative to an ideal Tor network we
could imagine. Worse, the Internet itself doesn't have as much diversity
as we'd like either.
all examine AS-level path diversity.
See also for another worrying concern about bottlenecks besides ASes. I also
worry about the bottleneck created by trans-ocean cables.
For more details calculating diversity, see
Help appreciated on those tickets!
Really? Across jurisdictions? And for 'all traffic of those relays'?
I don't want to downplay the risk too far, but I think you overestimate
"unsophisticated law enforcement operations".
Well, do you have an alternative design that scales adequately to 6 or
7 figures of users, provides roughly-real-time browsing and other TCP
connections, works on the Internet that we have, and has better traffic
confirmation resistance?
Or said another way, how well do other usable low-latency anonymity
systems hold up to ongoing wiretaps at 25 arbitrary network locations? I
believe the answer is 'mostly less well than Tor'.
tagnaq pointed to my response to a similar question on the tor-relays
talking about the tradeoff between "make it faster but more concentrated"
vs "make it less fast but less concentrated".
It would be interesting to see your stats on as AS level rather than
a /24 netblock level. But the challenge really is that we need to know
what networks the traffic flows traverse upstream -- e.g. how pervasive
a surveiller of Tor traffic could Deutsch Telekom be? This topic goes
back to my earlier blog post:
I think we still do a pretty good job explaining the risks and limitations
of using a system like Tor, e.g. in each Tor talk.
Tor used to print a warning message on start, to explain that it isn't
perfect. But a) no Windows users saw it, and b) it backfired in surprising
ways, like having journalists write "Tor recommends that you use something
else for now, since they're not ready yet":
Thanks for presenting the code too!
tor-talk mailing list

@_date: 2012-10-03 17:31:03
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] [tor-relays]  clockskewer attack 
In theory you don't need the open http server -- the Tor relay will tell
you what time it thinks it is during the TLS handshake (or if you do a
directory fetch of /tor/server/authority and look at the http headers
in its answer).
But yes, running a hidden service on a public relay may not be the
greatest idea. Even ignoring this 'clock skew fingerprinting' issue,
you can do much simpler things like correlate relay up/down time with
hidden service up/down time.
And just so nobody digs out papers in the future and is shocked, here are
some related papers you could read:
tor-talk mailing list

@_date: 2013-08-09 16:10:46
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] Secure email with limited usable metadata 
While I don't really have an opinion on whether this service should stay
dormant, I do hope they leave the TorMail name behind. Too many users got
confused about whether it was an official Tor service (it wasn't). And I
can't help but conclude that this confusion was intentional and welcome
on the part of the service operators -- which I confess makes me have
little sympathy for them disappearing.

@_date: 2013-09-03 18:09:58
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] New paper : Users Get Routed: Traffic Correlation on Tor by Realistic Adversaries 
Excellent point. This is a good argument for being able to unpack a new
TBB on top of the old one -- which I'm told usually works, but doesn't
always work, and that's a big problem.
Longer term, the right answer is to use the Firefox update mechanism in
TBB 3.0 to update, in place, only the parts that need updating.
...unless there are better answers?

@_date: 2013-09-02 02:10:56
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] New paper : Users Get Routed: Traffic Correlation on Tor by Realistic Adversaries 
Yep. They're part of the Tor research community. I have plans for writing
a blog post about the paper, to explain what it means, what it doesn't
mean, what we should do about it, and what research questions remain
open. Stuff keeps catching fire with bigger flames though.
The extremely short answer is "Yes, a big enough adversary can screw Tor
users. But we knew that. I think it's great that the paper presents the
dual risks of relay adversaries and link adversaries, since most of the
time when people are freaking out about one of them they're forgetting the
other one. And we really should raise the guard rotation period. If you
do their compromise graphs again with guards rotated every nine months,
they look way different."

@_date: 2013-10-04 02:21:16
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] Silk Road taken down by FBI 
Can you point to a specific statement in the affidavit that would be a
lie if the "NSA conspires to tip off FBI" theory were true?
Remember, the job of the guy writing the document is to lay out a set
of correct facts which together show clear evidence that he's a criminal.
Or to say it differently, it's his job to figure out the right way
(including the right order, and the right subset) of presenting his
facts so they make his case the best way he can.
And he's under no obligation to include all of the facts -- just the
ones that make his case most likely to win.
I'm not saying that this version of the conspiracy did or didn't happen
this way. You're right that "look, he screwed up enough different ways,
why do you need a more complicated theory?" is a convincing argument.
But if it *did* happen, there's no reason for them to have to lie --
they could have (should have) just gone and done all the things they
say they did, to be able to write a winning case.

@_date: 2013-10-03 22:54:04
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] Silk Road taken down by FBI 
Careful there -- while I assume they didn't lie in their affidavit, it's
quite reasonable to assume that they investigated all sorts of things,
all sorts of ways, and then afterwards chose to write down exactly the
set of facts that when lined up in the correct order makes it look like
a clean solid case.
It's a slippery slope from there to 'parallel construction', but I think
it's standard practice to start with some leads and use them to find
more solid facts, and it's also standard practice to not mention all
your leads in your affidavit.
To be more concrete, their job here is to link the guy to the website.
So if they had a pretty good idea of who the guy was, but not enough
evidence to bust him, it makes sense to me that they would go find one
of the servers, collect all the evidence they can from it, and hope
to find something specific that points back at the guy. And who knows,
maybe they did that several times before they found something they liked
enough to build a case from it.
Your theory that "he was sold out by one of his administrators" also
fits fine here -- the administrators pointed to the guy but then they
needed to build a solid-looking case.
Why? So everybody can abandon that VPN and move to a different one that
also responds to subpoenas but hasn't been written about in a high-profile
court case yet? :)

@_date: 2013-10-03 22:31:12
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] Silk Road taken down by FBI 
They're wondering about the botnet activity in late August, when all
the dates in the takedown pdf are in July?
I guess their conspiracy theory would go something like "those FBI people
lied about everything in their affidavit, and made up a smear campaign
about bad opsec to hide their actual attack"?
And at the same time, nobody who's said "I wonder if that botnet activity
is an anonymity attack of some sort" has provided any details on how
so many users might be needed to attack anonymity?
I think it's pretty clear by now that the August / September growth is
from a botnet. That plus the fact that nobody has described how "add
millions of users" is a required step for an anonymity-breaking attack,
plus the fact that the FBI would really have shot themselves in the foot
by lying so much (unless of course the pdf that everybody's reading is
a fake and a distraction -- down the rabbit hole we go!), makes me think
whoever wrote that article didn't do much of their homework.

@_date: 2013-10-03 22:24:01
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] Silk Road taken down by FBI 
This is a fine research paper attack:
and a good reason not to run your hidden service on your Tor relay,
but I think it's highly unlikely to have been relevant in this case.
That said, yes, the original question is unanswered still.

@_date: 2013-10-03 03:58:54
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] Silk Road taken down by FBI 
Our various Tor talks have long tried to explain that Tor doesn't
magically make "old-fashioned police work" obsolete, e.g.
"But remember that this doesn't mean that Tor is invulnerable. Traditional
police techniques can still be very effective against Tor, such as
investigating means, motive, and opportunity, interviewing suspects,
writing style analysis, technical analysis of the content itself, sting
operations, keyboard taps, and other physical investigations. The Tor
Project is also happy to work with everyone including law enforcement
groups to train them how to use the Tor software to safely conduct
investigations or anonymized activities online."
Too many police groups I've talked to just expect to have a newfangled
technology thing where you push a button and out pops the name of your
criminal. They all want it and it really screws up policy when they ask
for it, since when legislators hear it they also think it's a great idea.

@_date: 2013-10-03 02:07:00
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] Silk Road taken down by FBI 
We just put up a statement on the blog which basically says that:

@_date: 2013-10-04 15:38:10
@_author: Roger Dingledine 
@_subject: [tor-talk] Guardian Tor article 
Just to start off the new media frenzy thread.
(Did I miss any good links?)

@_date: 2013-11-16 18:55:48
@_author: Roger Dingledine 
@_subject: [tor-talk] Tor 0.2.4.18-rc is out 
Content-Disposition: inline
Content-Disposition: inline
Tor 0.2.4.18-rc is the fourth release candidate for the Tor 0.2.4.x
series. It takes a variety of fixes from the 0.2.5.x branch to improve
stability, performance, and better handling of edge cases.
Changes in version 0.2.4.18-rc - 2013-11-16
  o Major features:
    - Re-enable TLS 1.1 and 1.2 when built with OpenSSL 1.0.1e or later.
      Resolves ticket 6055. (OpenSSL before 1.0.1 didn't have TLS 1.1 or
      1.2, and OpenSSL from 1.0.1 through 1.0.1d had bugs that prevented
      renegotiation from working with TLS 1.1 or 1.2, so we had disabled
      them to solve bug 6033.)
  o Major bugfixes:
    - No longer stop reading or writing on cpuworker connections when
      our rate limiting buckets go empty. Now we should handle circuit
      handshake requests more promptly. Resolves bug 9731.
    - If we are unable to save a microdescriptor to the journal, do not
      drop it from memory and then reattempt downloading it. Fixes bug
      9645; bugfix on 0.2.2.6-alpha.
    - Stop trying to bootstrap all our directory information from
      only our first guard. Discovered while fixing bug 9946; bugfix
      on 0.2.4.8-alpha.
    - The new channel code sometimes lost track of in-progress circuits,
      causing long-running clients to stop building new circuits. The
      fix is to always call circuit_n_chan_done(chan, 0) from
      channel_closed(). Fixes bug 9776; bugfix on 0.2.4.17-rc.
  o Minor bugfixes (on 0.2.4.x):
    - Correctly log long IPv6 exit policies, instead of truncating them
      or reporting an error. Fixes bug 9596; bugfix on 0.2.4.7-alpha.
    - Our default TLS ecdhe groups were backwards: we meant to be using
      P224 for relays (for performance win) and P256 for bridges (since
      it is more common in the wild). Instead we had it backwards. After
      reconsideration, we decided that the default should be P256 on all
      hosts, since its security is probably better, and since P224 is
      reportedly used quite little in the wild.  Found by "skruffy" on
      IRC. Fix for bug 9780; bugfix on 0.2.4.8-alpha.
    - Free directory authority certificate download statuses on exit
      rather than leaking them. Fixes bug 9644; bugfix on 0.2.4.13-alpha.
  o Minor bugfixes (on 0.2.3.x and earlier):
    - If the guard we choose first doesn't answer, we would try the
      second guard, but once we connected to the second guard we would
      abandon it and retry the first one, slowing down bootstrapping.
      The fix is to treat all our initially chosen guards as acceptable
      to use. Fixes bug 9946; bugfix on 0.1.1.11-alpha.
    - Fix an assertion failure that would occur when disabling the
      ORPort setting on a running Tor process while accounting was
      enabled. Fixes bug 6979; bugfix on 0.2.2.18-alpha.
    - When examining the list of network interfaces to find our address,
      do not consider non-running or disabled network interfaces. Fixes
      bug 9904; bugfix on 0.2.3.11-alpha. Patch from "hantwister".
    - Avoid an off-by-one error when checking buffer boundaries when
      formatting the exit status of a pluggable transport helper.
      This is probably not an exploitable bug, but better safe than
      sorry. Fixes bug 9928; bugfix on 0.2.3.18-rc. Bug found by
      Pedro Ribeiro.
  o Minor features (protecting client timestamps):
    - Clients no longer send timestamps in their NETINFO cells. These were
      not used for anything, and they provided one small way for clients
      to be distinguished from each other as they moved from network to
      network or behind NAT. Implements part of proposal 222.
    - Clients now round timestamps in INTRODUCE cells down to the nearest
      10 minutes. If a new Support022HiddenServices option is set to 0, or
      if it's set to "auto" and the feature is disabled in the consensus,
      the timestamp is sent as 0 instead. Implements part of proposal 222.
    - Stop sending timestamps in AUTHENTICATE cells. This is not such
      a big deal from a security point of view, but it achieves no actual
      good purpose, and isn't needed. Implements part of proposal 222.
    - Reduce down accuracy of timestamps in hidden service descriptors.
      Implements part of proposal 222.
  o Minor features (other):
    - Improve the circuit queue out-of-memory handler. Previously, when
      we ran low on memory, we'd close whichever circuits had the most
      queued cells. Now, we close those that have the *oldest* queued
      cells, on the theory that those are most responsible for us
      running low on memory. Based on analysis from a forthcoming paper
      by Jansen, Tschorsch, Johnson, and Scheuermann. Fixes bug 9093.
    - Generate bootstrapping status update events correctly when fetching
      microdescriptors. Fixes bug 9927.
    - Update to the October 2 2013 Maxmind GeoLite Country database.
  o Documentation fixes:
    - Clarify the usage and risks of setting the ContactInfo torrc line
      for your relay or bridge. Resolves ticket 9854.
    - Add anchors to the manpage so we can link to the html version of
      the documentation for specific options. Resolves ticket 9866.
    - Replace remaining references to DirServer in man page and
      log entries. Resolves ticket 10124.
Content-Description: Digital signature
Content-Disposition: inline

@_date: 2013-11-10 05:29:42
@_author: Roger Dingledine 
@_subject: [tor-talk] Request for "Tor, king of anonymity" graphic 
Hello graphics-inclined readers,
Among the October leaked slides:
was one from (I assume) GCHQ saying that Tor is "Still the King of high
secure, low latency Internet Anonymity" and that "There are no contenders
for the throne in waiting".
I periodically find myself doing presentations for law enforcement
and other government groups (like the NSA talk documented in the above
This clearly calls for a goofy mashup of a crown and the Tor onion, so
I can drive the point home in a memorable way.
Can somebody here mash them up in an attractive way?
For the Tor logo side, you might find something you like in
For any other component images, please use something
Creative-Commons-acceptable or similar. That way we can use it in the
future for, say, an April 1 Tor website too. ;)

@_date: 2014-07-14 10:56:19
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] Questions about NSA monitoring of Tor users. 
You might want to read many of my answers on
Directory authority, yes.
No, I haven't seen any rules that tag flows based on whether they are
accessing one of the 5000ish Tor relay IP addresses. I just skimmed over
the Wired article and it appears they do say that but I think they're
misreading or misunderstanding the rules.
That said, I believe xkeyscore does have rules that DPI on a flow to
see if it looks like a Tor handshake has just happened. But nobody has
published (and I don't know) specifics of exactly what data they run
any of these rules over:
I've lost track of their codenames for things, but I think Quantum is
probably different than their general surveillance infrastructure.
In any case, it is still unclear whether the surveillance happens closer
to the website, closer to the user, or both. It depends on which website
and which user you're thinking about.
And this point leads to speculation about how maybe if you're in Germany
and you access a German Tor directory authority, NSA's surveillance
infrastructure doesn't see you because your request doesn't go over a
big enough backbone Internet link.
...which leads to speculation that the BND and NSA team up to share data,
so they can together cover more of the Internet. And round and round
we go.
Yes. But I assume they get IPs and also timestamps. And now if they
see something else going on that involves that IP address, they can
ask their database what else that IP address has done.
This is exactly the sort of thing that should scare ordinary people,
because I assume they hand all this data to a human analyst who tries
to make a guess about whether to send a drone. And if that human analyst
thinks Tor is only used by a tiny number of people, all of whom are bad,
then she could easily come to wrong conclusions.
And if some programmer tries to automate the job of that analyst, because
they have too much data coming in and they want to automatically determine
the right places to send drones... things can go wrong in a hurry.
I think it isn't either of these. I'm sure some of them think Tor is
only used by bad people (all the press about Tor and drugs, etc lately
sure hasn't helped).
But I think the general idea is to collect as much information about as
many things as possible, and then "surely" when you put it all together
it'll point you to the bad guys.
In particular, once they find something suspicious, they want to be able
to go back and see what else that person / computer / network was doing
in the past. And to do that, they need to collect as much as they can
about as many things as they can.
This is also the logic that leads them to redefine "collect" to be the
point where they actually *use* the information, not the point where
they, ehm, collect it. Because they know the various committees that
try to oversee them haven't given them permission to gather it all,
but they have also convinced themselves that they can't do a good job
at fighting bad guys if they don't gather it all.
And finally, don't put too much weight on these particular DPI rules.
The news here is not "we finally learned what the NSA are spying on,
and it's Tor connections and people looking at the Mixminion website."
They very likely spy on way way more than this. But these are the ones
that some journalists decided to write about (which in turn means that
they're the ones some whistleblower decided to leak).

@_date: 2014-10-31 12:54:27
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] Facebook brute forcing hidden services 
I talked to them about this. The short answer is that they did the vanity
name thing for the first half of it ("facebook"), which is only 40 bits
so it's possible to generate keys over and over until you get some keys
whose first 40 bits of the hash match the string you want.
Then they had some keys whose name started with "facebook", and they
looked at the second half of each of them to decide which one they thought
would be most memorable for the second half of the name as well. This
one looked best to them -- meaning they could come up with a story about
why that's a reasonable name for Facebook to use -- so they went with it.
So to be clear, they would not be able to produce exactly this name
again if they wanted to. They could produce other hashes that started
with "facebook", but that's not brute forcing all of the hidden
service name (all 80 bits).
For those who want to explore the math more, read about the "birthday
And for those who want to learn more (please help!) about the improvements
we'd like to make for hidden services, including stronger keys and
stronger names see,

@_date: 2016-03-20 01:56:47
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] Traffic shaping attack 
This assumed scenario seems extremely unlikely to be happening in
practice. First because there aren't any relays that are doing 1gbit/s
of traffic, so no onion service would be able to do that to its guard
(unless it used many entry guards and spread the load over them, in which
case it would be screwing its own anonymity). And second because the
graph at shows there's only something like 1.4gbit/s of onion service traffic in
the whole network. And third because scalability issues in the current
design make onion services unable to keep up with the number of users
that you're describing.
So I worry that it sounds similar to the "omg they're hidden so they
must be *huge*" mistake that a lot of the media suffers from.
More details please? This is not a crazy possibility, but it would be good
to know exactly what evidence we have for its being true. For example,
if somebody noticed "I get a burst of cells from this onion service,
then a few seconds of silence, then I get another burst of cells",
that's actually a property of our current load balancing algorithm,
and not necessarily evidence of an intentional signal being injected
into the circuit.

@_date: 2016-03-19 03:40:44
@_author: Roger Dingledine 
@_subject: Re: [tor-talk] Traffic shaping attack 
Right. This general idea of a traffic confirmation attack is an issue
to consider for any low-latency system.
One of the questions to ask is how many points you need to watch in order
to be in a position to launch the attack. This is where Tor fares better
than centralized approaches like VPNs or single-hop proxies, and it's
Tor's best line of defense here.
Another question to ask is whether there will be false positives in the
statistics, i.e. how often your analysis says "yes, match" when actually
it's mistaken. In your scenario, the adversary is doing an active attack
on the traffic, so while I think it's legitimate to speculate about
how false positive rates maybe get high when you're looking at many
Tor flows across many relays (the NSA scenario -- and we even have a
document from an NSA analyst being frustrated by the false positives),
I think it's fair to say that if you generate the signals clearly enough,
false positives will be much less of a worry.
The third question you might ask is: can I inject these signals in a
way that they're still recognizable to me, but observers don't realize
that anything weird is going on with the traffic? That is, can I do
this active traffic modulation attack but still be undetectable? For
that topic, check out these papers:
