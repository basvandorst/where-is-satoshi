
@_date: 2013-08-31 21:00:01
@_author: John Kelsey 
@_subject: Re: [Cryptography] NSA and cryptanalysis 
If I had to bet, I'd bet on bad rngs as the most likely source of a breakthrough in decrypting lots of encrypted traffic from different sources. The cryptography mailing list

@_date: 2013-09-08 03:45:22
@_author: John Kelsey 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
Let's suppose I design a block cipher such that, with a randomly generated key and 10,000 known plaintexts, I can recover that key.  For this to be useful in a world with relatively sophisticated cryptanalysts, I must have confidence that it is extremely hard to find my trapdoor, even when you can look closely at my cipher's design.   At this point, what I have is a trapdoor one-way function.  You generate a random key K and then compute E(K,i) for i = 1 to 10000.  The output of the one-way function is the ciphertext.  The input is K.  If nobody can break the cipher, then this is a one-way funciton.  If only I, who designed it, can break it, then it's a trapdoor one-way function.  At this point, I have a perfectly fine public key encryption system.  To send me a message, choose a random K, use it to encrypt 1 through 10000, and then send me the actual message encrypted after that in K.  If nobody but me can break the system, then this cipher works as my public key.  The assumption that matters here is that you know enough cryptanalysis that it would be hard to hide a practical attack from you.  If you don't know about differential cryptanalysis, I can do the master key cryptosystem, but only until you learn about it, at which point you will break my cipher.   But if you can, say, hide the only good linear characteristics for some cipher in its S-boxes in a way that is genuinely intractible for anyone else to find, then you have a public key cryptosystem. You can publish the algorithm for hiding new linear characteristics in an S-box--this becomes the keypair generation algorithm.  The private key is the linear characteristic that lets you break the cipher with (say) 10000 known plaintexts, the public key is the cipher definition.  The cryptography mailing list

@_date: 2013-09-06 05:19:10
@_author: John Kelsey 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
I don't see what problem would actually be solved by dropping public key crypto in favor of symmetric only designs.  I mean, if the problem is that all public key systems are broken, then yeah, we will have to do something else.  But if the problem is bad key generation or bad implementations, those will be with us even after we abandon all the public key stuff.  And as Jon said, the trust problems get harder, not easier.  With only symmetric crypto, whoever acts as the introducer between Alice and Bob can read their traffic passively and undetectably.  With public key crypto, the introducer can do a man in the middle attack (an active attack) and risks detection, as Alice and Bob now have things signed by the introducer associating the wrong keys with Bob and Alice, respectively.  The cryptography mailing list

@_date: 2013-09-06 05:04:31
@_author: John Kelsey 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
One thing I can say for certain:  NSA did not write SP 800-90.  (That was the implication of from the New York Times article.). That was mostly Elaine Barker, my coworker, with me providing a lot of text around technical issues.  The algorithms all came out of work from ANSI X9.82 Part 3, which Elaine also wrote with lots of input and text from me and the rest of the editing committee.  We worked with NSA people on this, and X9.82 Part 2 (the entropy source section) was written entirely by NSA people, but it isn't easy for me to see how anyone could stick a trapdoor in that.  We're still working with NSA people on SP 800-90B, which includes a lot of stuff on testing entropy sources.  When I started there was an RSA based algorithm which we eventually dropped (analogous to bbs), Dual EC DRBG, the hash drbg (which is still in 800-90 in a much-changed version for backward comatibility reasons, because the standardization process took forever and people started designing to the X9.82 standard before it was done--this was also the reason we ended up keeping the Dual EC DRBG) and an X9.17 based thing we got rid of.  A bunch of the symmetric stuff in there is mine--I made changes the the hash DRBG to address time/memory/data tradeoffs, and wrote the HMAC DRBG and CTR DRBG.  I also changed around the hash df and wrote the bc df.  It is possible Dual EC DRBG had its P and Q values generated to insert a trapdoor, though I don't think anyone really knows that (except the people who generated it, but they probably can't prove anything to us at this point).  It's also immensely slower than the other DRBGs, and I have a hard time seeing why anyone would use it.  (But if you do, you should generate your own P and Q.)
If you're trying to solve the problem of not trusting your entropy source, this is reasonable, but it doesn't exactly scale to normal users.  Entropy collection in software is a pain in the ass, and my guess is that the overwhelming majority of developers are happy to punt and just use the OS' random numbers.  That looks to be what happened with the Henninger and Lenstra results regarding lots of RSA keys with shared moduli.  That flaw implies a huge number of easily factored RSA keys out there, thanks to insufficient entropy and calling /dev/urandom on a system where it won't block even if it thinks it has zero entropy.  (This was a multi-level screw up, as I understand it, between a Linux version and OpenSSL and the implementors of various appliance network devices.). It would be smarter for any crypto software to use the OS source for some seed material, and then combine it with both unique or nearly unique information and anything that's likely to have some entropy, and use that to initialize a good PRNG.  (I'd use CTR DRBG.)   Your ethernet address doesn't have any entropy, but it works like a salt in a password hashing scheme--an attacker must now rerun his attack for each individual instance of the crypto software. In general, software that uses crypto should probably be trying to gather entropy wherever possible, not just trusting the OS.  And it should use that entropy plus the OS' entropy to seed its own PRNG.  And it should throw in any information that might distinguish this instance from other instances, to force any attackers to rerun their attack on each instance individually.  When I saw the keystore stuff, I thought "bad key generation."  Henninger found a bunch of RSA keys from the same make of devices that were sharing primes, thanks to really awful entropy collection.  If those devices had been collecting 40 bits of entropy for the first prime, she might never have found a pair of keys with a shared prime.  But someone using analogous methods might be able to generate 2^{40} primes ahead of time, and efficiently run each new RSA key sent in against that list and break a large fraction of the keys.
I think long-term public keys are the big weakness here, because they tend to be generated relatively early.  It's easy to see how you don't have any entropy in your pool a minute after starting up; it's much harder to see how that happens after a year of operation.  The cryptography mailing list

@_date: 2013-09-05 23:14:53
@_author: John Kelsey 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
First, I don't think it has anything to do with Dual EC DRGB.  Who uses it?  My impression is that most of the encryption that fits what's in the article is TLS/SSL.  That is what secures most encrypted content going online.  The easy way to compromise that in a passive attack is to compromise servers' private keys, via cryptanalysis or compromise or bad key generation.  For server side TLS using RSA, guessing just the client's random values ought to be enough to read the traffic.  For active attacks, getting alternative certs issued for a given host and playing man in the middle would work.  Where do the world's crypto random numbers come from?  My guess is some version of the Windows crypto api and /dev/random or /dev/urandom account for most of them.  What does most of the world's TLS?  OpenSSL and a few other libraries, is my guess.  But someone must have good data about this.  My broader question is, how the hell did a sysadmin in Hawaii get hold of something that had to be super secret?  He must have been stealing files from some very high ranking people.  The cryptography mailing list

@_date: 2013-09-15 14:50:38
@_author: John Kelsey 
@_subject: Re: [Cryptography] prism proof email, namespaces, and anonymity 
This seems like the main way most people would want PPE to work--like email they have now, but much more secure and resistant to abuse.  In the overwhelming majority of cases, I know and want to know the people I'm talking with.  I just don't want to contents of those conversations or the names of people I'm talking with to be revealed to eavesdroppers.  And if I get an email from one of my regular correspondents, I'd like to know it came from him, rather than being spoofed from someone else.  For most people, I'm pretty sure the security problems with email are centered around the problem of getting unwanted communication from people you don't want to hear from, some of which may manage install malware on your computer, others of which want to waste your time with scam ads, etc.  A PPE scheme that solves that problem can get a lot more users than one that doesn't, and may even eventually take over from the current kind of email.  The cryptography mailing list

@_date: 2013-09-13 20:55:05
@_author: John Kelsey 
@_subject: [Cryptography] prism proof email, namespaces, and anonymity 
The more I think about it, the more important it seems that any anonymous email like communications system *not* include people who don't want to be part of it, and have lots of defenses to prevent its anonymous communications from becoming a nightmare for its participants.  If the goal is to make PRISM stop working and make the email part of the internet go dark for spies (which definitely includes a lot more than just US spies!), then this system has to be something that lots of people will want to use.  There should be multiple defenses against spam and phishing and other nasty things being sent in this system, with enough designed-in flexibility to deal with changes in attacker behavior over tome.  If someone can send participants in the system endless spam or credible death threats, then few people are going to want to participate, and that diminishes the privacy of everyone remaining in the system, along with just making the system a blight in general.  If nonparticipants start getting spam from the system, it will either be shunned or shut down, and at any rate won't have the kind of reputation that will move a lot of people onto the system.  An ironclad anonymous email system with 10,000 users is a whole lot less privacy-preserving than one with 10,000,000 users.  As revelations of more and more eavesdropping come out, we might actually see millions of users want to have something really secure and anonymous, but not if it's widely seen as a firehose o' spam.  A lot of the tools we use on the net everyday suffer from having been designed without thinking very far ahead into how they might be exploited or misused--hence spam, malware in PDF files, browser hijacking sorts of attacks, etc.  My thought is that we should be thinking of multiple independent defenses against spamming and malware and all the rest, because parasites adapt to their environment.  We can't count on "and then you go to jail" as a final step in any protocol, and we can't count on having some friendly utility read millions of peoples' mail to filter the spam if we want this to be secure.  So what can we count on to stop spam and malware and other nastiness?  Some thoughts off the top of my head.  Note that while I think all these can be done with crypto somehow, I am not thinking of how to do them yet, except in very general terms.  a.  You can't freely send messages to me unless you're on my whitelist.  b.  This means an additional step of sending me a request to be added to your whitelist.  This needs to be costly in something the sender cares about--money, processing power, reputation, solving a captcha, rate-limits to these requests, whatever.  (What if the system somehow limited you to only, say, five outstanding requests at a time?). c.  Make account creation costly somehow (processing, money, solving a captcha, whatever).  Or maybe make creating a receive-only account cheap but make it costly to have an account that can request to communicate with strangers.  d.  Make sending a message in general cost something.  Let receiver addresses indicate what proof of payment of the desired cost they require to accept emails.  e.  Enable some kind of reputation tracking for senders?  I'm not sure if this would work or be a good idea, but it's worth thinking about.  f.  All this needs to be made flexible, so that as attackers evolve, so can defenses.  Ideally, my ppe (prism proof email) address would carry an indication of what proofs your request to communicate needed to carry in order for me to consider it.  g.  The format of messages needs to be restricted to block malware, both the kind that wants to take over your machine and the kind that wants to help the attacker track you down.  Plain text email only?  Some richer format to allow foreign language support?  h.  Attachments should become links to files in an anonymizing cloud storage system.  Among other things, this will make it easier to limit the size of the emails in the system, which is important for ensuring anonymity without breaking stuff.  What else?  I see this as the defining thing that can kill an anonymous encrypted communications system--it can become a swamp of spam and malware and nutcases stalking people, and then nobody sensible will want to come within a hundred meters of it.  Alternatively, if users are *more* in control of who contacts them in the prism-proof scheme than with the current kind of email, we can get a lot more people joining.  The cryptography mailing list

@_date: 2013-09-30 22:35:24
@_author: John Kelsey 
@_subject: Re: [Cryptography] RSA equivalent key length/strength 
Having read the mail you linked to, it doesn't say the curves weren't generated according to the claimed procedure.  Instead, it repeats Dan Bernstein's comment that the seed looks random, and that this would have allowed NSA to generate lots of curves till they found a bad one.  it looks to me like there is no new information here, and no evidence of wrongdoing that I can see.  If there is a weak curve class of greater than about 2^{80} that NSA knew about 15 years ago and were sure nobody were ever going to find that weak curve class and exploit it to break classified communications protected by it, then they could have generated 2^{80} or so seeds to hit that weak curve class.  What am I missing?  Do you have evidence that the NIST curves are cooked?  Because the message I saw didn't provide anything like that.  The cryptography mailing list

@_date: 2013-09-30 22:24:12
@_author: John Kelsey 
@_subject: Re: [Cryptography] RSA equivalent key length/strength 
Maybe you should check your code first?  A couple nist people verified that the curves were generated by the described process when the questions about the curves first came out.  Don't trust us, obviously--that's the whole point of the procedure.  But check your code, because the process worked right when we checked it.
The cryptography mailing list

@_date: 2013-09-01 17:32:06
@_author: John Kelsey 
@_subject: Re: [Cryptography] NSA and cryptanalysis 
What I think we are worried about here are very widespread automated attacks, and they're passive (data is collected and then attacks are run offline).  All that constrains what attacks make sense in this context.  You need attacks that you can run in a reasonable time, with minimal requirements on the amount of plaintext or the specific values of plaintext.  The perfect example of an attack that works well here is a keysearch on DES; another example is the attack on WEP.
All the attacks we know of on reduced-round AES and AES-like ciphers require a lot of chosen plaintexts, or related key queries, or both.  There is no way to completely rule out some amazing new break of AES that makes the cipher fall open and drop your plaintext in the attacker's lap, but I don't see anything at all in the literature that supports that fear, and there are a *lot* of smart people trying to find new ways to attack or use AES-like designs.  So I put this at the bottom of my list of likely problems.
Some attacks on public key systems also require huge numbers of encryptions or specially formed ciphertexts that get sent to the target for decryption--we can ignore those for this discussion.  So we're looking at trying to factor an RSA modulus or to examine a lot of RSA encryptions to a particular public key (and maybe some signatures from that key) and try to get somewhere from that.  I don't know enough about the state of the art in factoring or attacking RSA to have a strong intuition about how likely this is.  I'm pretty skeptical, though--the people. know who are experts in this stuff don't seem especially worried.  However, a huge breakthrough in factoring would make for workable passive attacks of this kind, though it would have to be cheap enough to use to break each user's public key separately.  Finally, we have the randomness sources used to generate RSA and AES keys.  This, like symmetric cryptanalysis, is an area I know really well.  And my intuition (backed by plenty of examples) is that this is probably the place that is most likely to yield a practical offline attack of this kind.  When someone screws up the implementation of RSA or AES, they may at least notice some interoperability problems.  They will never notice this when they screw up their implementation so that RNG only gets 32 bits of entropy before generating the user's RSA keypair.  And if I know that your RSA key is likely to have one of these 2^{32} factors, I can make a passive attack work really well.  The cryptography mailing list

@_date: 2013-09-08 22:16:45
@_author: John Kelsey 
@_subject: Re: [Cryptography] Techniques for malevolent crypto hardware 
I don't think you can do anything useful in crypto without some good source of random bits.  If there is a private key somewhere (say, used for signing, or the public DH key used alongside the ephemeral one), you can combine the hash of that private key into your PRNG state.  The result is that if your entropy source is bad, you get security to someone who doesn't compromise your private key in the future, and if your entropy source is good, you get security even against someone who compromises your private key in the future (that is, you get perfect forward secrecy).
The cryptography mailing list

@_date: 2013-09-08 20:21:55
@_author: John Kelsey 
@_subject: Re: [Cryptography] Techniques for malevolent crypto hardware 
In principle, the malevolent crypto accellerator could flip into weak mode (however that happens) only upon receiving a message for decryption with some specific value or property.  That would defeat any testing other than constant observation.  This is more or less the attack that keeps parallel testing of electronic voting machines from being a good answer to the security concerns about them.
The cryptography mailing list

@_date: 2013-10-10 15:51:04
@_author: John Kelsey 
@_subject: Re: [Cryptography] Iran and murder 
The problem with offensive cyberwarfare is that, given the imbalance between attackers and defenders and the expanding use of computer controls in all sorts of systems, a cyber war between two advanced countries will not decide anything militarily, but will leave both combattants much poorer than they were previously, cause some death and a lot of hardship and bitterness, and leave the actual hot war to be fought. Imagine a conflict that starts with both countries wrecking a lot of each others' infrastructure--causing refineries to burn, factories to wreck expensive equipment, nuclear plants to melt down, etc.  A week later, that phase of the war is over.  Both countries are, at that point, probalby 10-20% poorer than they were a week earlier.  Both countries have lots of really bitter people out for blood, because someone they care about was killed or their job's gone and their house burned down or whatever.  But probably there's been little actual degradation of their standard war-fighting ability.  Their civilian aviation system may be shut down, some planes may even have been crashed, but their bombers and fighters and missiles are mostly still working.  Fuel and spare parts may be hard to come by, but the military will certainly get first pick.  My guess is that what comes next is that the two countries have a standard hot war, but with the pleasant addition of a great depression  sized economic collapse for both right in the middle of it.    The cryptography mailing list

@_date: 2013-10-07 16:03:20
@_author: John Kelsey 
@_subject: [Cryptography] Iran and murder 
Alongside Phillip's comments, I'll just point out that assassination of key people is a tactic that the US and Israel probably don't have any particular advantages in.  It isn't in our interests to encourage a worldwide tacit acceptance of that stuff.  I suspect a lot of the broad principles we have been pushing (assassinations and drone bombings can be done anywhere, cyber attacks against foreign countries are okay when you're not at war, spying on everyone everywhere is perfectly acceptable policy) are in the short-term interests of various powerful people and factions in the US, but are absolutely horrible ideas when you consider the long-term interests of the US.  We are a big, rich, relatively free country with lots of government scientists and engineers (especially when you consider funding) and tons of our economy and our society moving online.  We are more vulnerable to widespread acceptance of these bad principles than almost anyone, ultimately,  But doing all these things has won larger budgets and temporary successes for specific people and agencies today, whereas the costs of all this will land on us all in the future.  The cryptography mailing list

@_date: 2013-10-25 12:15:57
@_author: John Kelsey 
@_subject: Re: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
I like this idea.  If my PRNG is in a secure state, I can give out random numbers to anyone who asks.  At first startup, it won't be possible to establish a secure connection yet (no entropy), but by asking some hosts for a random number, we ensure that if those messages aren't recorded, the attacker can't possibly guess our PRNG starting state.  The cryptography mailing list

@_date: 2013-10-25 12:12:00
@_author: John Kelsey 
@_subject: Re: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
This gets back to the threat model discussion.  If your attacker is watching you from the outside as you generate your key, then interacting with stuff over the local net won't help you much.  (You may get a bit or two of entropy from the attacker not being able to know exactly which clock-tick you were on when the interrupt was serviced, but not much.). If he's not watching you then, you can rule out a whole category of attackers.  Similarly, if you have some secret value that's available to any program on your machine, an attacker who can get onto your machine later can learn that.  But one who can't is just not able to guess your prng starting state.  What else can be done to rule out classes of attacker up front?  The cryptography mailing list

@_date: 2013-10-24 14:59:14
@_author: John Kelsey 
@_subject: Re: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
We seem to be seeing a move toward commonly-used CPUs including hardware entropy sources.  With those, we're in a much better position.  There's always the possibility that the entropy source was cooked or flawed, but that's something you can engineer your way around reasonably well.  Suppose you have a cryptographic PRNG that you initialize with a seed like this:
a.  Get 256 bits of entropy from the OS.
b.  Get 256 bits of entropy from the hardware entropy source.
c.  Ping several hosts on the internet and measure the response time, and fold that into your seed.
d.  Fold your ethernet address, IP address, and serial number into the seed.
e.  Fold the installed-at-birth secret 128 bit value from your device into the seed.
Initialize a PRNG with all that, and the attacker is in an extremely hard place, as he has to be able to guess all five elements.  (d) isn't all that hard to guess, but the rest will in general be very hard to guess.  The cryptography mailing list

@_date: 2013-10-24 14:59:14
@_author: John Kelsey 
@_subject: Re: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
We seem to be seeing a move toward commonly-used CPUs including hardware entropy sources.  With those, we're in a much better position.  There's always the possibility that the entropy source was cooked or flawed, but that's something you can engineer your way around reasonably well.  Suppose you have a cryptographic PRNG that you initialize with a seed like this:
a.  Get 256 bits of entropy from the OS.
b.  Get 256 bits of entropy from the hardware entropy source.
c.  Ping several hosts on the internet and measure the response time, and fold that into your seed.
d.  Fold your ethernet address, IP address, and serial number into the seed.
e.  Fold the installed-at-birth secret 128 bit value from your device into the seed.
Initialize a PRNG with all that, and the attacker is in an extremely hard place, as he has to be able to guess all five elements.  (d) isn't all that hard to guess, but the rest will in general be very hard to guess.  The cryptography mailing list

@_date: 2013-10-22 00:07:25
@_author: John Kelsey 
@_subject: Re: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
A formal security model is exactly what the /dev/random paper had.  Here's a much less formal one, from my paper with Bruce and David and Chris many years ago:
An RNG is in a secure state if it is generating outputs that no attacker can predict or distinguish (up to some bounds on the number of outputs) from ideal random bits.  If it is not in a secure state, then it must be in an insecure state.  For most decent RNGs, being in an insecure state means the attacker knows or can guess the entire internal state.  If an RNG is in a secure state, no additional input fed into it and no plausible amount of output from it should put the RNG into an insecure state.  (At some point, any deterministic rng must cycle, so there has to be a limit on the number of outputs, but that can be huge.).  The old DSA RNG and the RSAREF RNG both had problems with this.  In general, a good technique here is to hash the external input before combining it with the RNG state, or to generate a new RNG state using the RNG and then XOR the input into it.  If an RNG was previously in a secure state, but has been compromised and now is in an insecure state, then the attacker mustn't be able to go backward and learn previous states or predict previous outputs he hasn't seen, even if he is given some previous outputs and asked to predict others.  This is ensured by periodically applying a one-way function to the RNG state.  The simplest one to use is the RNG itself--just use the RNG to generate a new RNG state.  If an RNG is in an insecure state, it should be able to get to a secure state if given sufficient entropy (say 128 bits).  This is the reason for "catastrophic reseeding."  You want to put in 128 bits of entropy all at once, rather than trickling in a few bits, then generating another output, because an attacker who starts out knowing your state can guess the entropy input, and check his guess against your RNG output, and can iterate this process to keep you from ever reseeding.  Let's consider a system that starts up for the first time today, and very quickly generates a high value keypair.  We are concerned with whether the RNG is in a secure state at the moment the randomness is used to generate the keypair.  The attacker wants to guess the input to the key generation mechanism.  He buys several instances of the same device and reverse-engineers them and experimentally determines what entropy values they collect before the key generation is done.  He builds a predictive model.  Now, to understand the security of this system, we need to know something about how often his predictive model guesses right.  This works very much like a password guessing attack--the attacker runs his model to generate huge numbers of predicted entropy inputs for the RNG, sort of like a John the Ripper for the system's entropy collection mechanism.  Think of the RNG and the key generation mechanism as being a little like a password hash algorithm, with the public key (or the first prime factor of the RSA modulus) being the password hash.  The attacker has to run his entropy input guessing engine and check each guess against a given machine's public key.  Suppose the RNG doesn't include stuff like a MAC address or IP address.  Then the attacker need only run his entropy guessing routine once, and precompute some huge table of possible keys or prime factors to try.  Perhaps he will do some clever time/memory tradeoff here as well.  At any rate, if 50% of the devices' entropy inputs can be guessed with 2^{40} work, then the attacker does one big 2^{40} precomputation, and he can break 50% of the devices' keys, whenever he sees them.  It's just like unsalted password hashes.  Suppose the RNG hashes in a MAC address.  Immediately, the attacker has a worse life--now with the same amount of entropy, he must do a new 2^{40} search each time he encounters a new device with a public key.  It's like a salted password hash.  Suppose the device pings a dozen hosts on the internet and times the returns of the packets, and hashes those into its RNG state before it generates its keys along with the MAC address.  Now, an attacker who wants to recover the key probably needs to have been observing the device's local network at the time the key was generated, or it won't have enough information to predict the RNG state.  Supose the device has a factory-installed secret value of 128 bits, which is stored forever on the device.  If it hashes this secret into the RNG state before generating its key, then the attacker must compromise the device or the manufacturer to guess the key.  And so on.  For the initial state of the RNG, you get about 90% of the right intuitions for thinking about the attack by thinking about a password cracking attack.  The cryptography mailing list

@_date: 2013-10-19 19:19:20
@_author: John Kelsey 
@_subject: Re: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
You should think of this like salting a password hash, not like adding entropy.  The attacker can probably know most or all of this data, but he won't be able to just run his entropy pool state guessing attack once and then exploit it for everyone everywhere.  I think the problem we have now is built into the assumptions of /dev/random and /dev/urandom.  It looks like /dev/urandom is typically expected to both never block, and to always give cryptographically secure random bits.  Right now, when those two requirements are not compatible, it fails to give secure random bits.  Fixing that makes it block, which will presumably break some programs, maybe causing a big impact.  I think the problem is that random and urandom split the random number generation problem in the wrong place.  What we probably need is something like a best-try non-blocking random number generator, suitable for non-crypto things where you want really unpredictable values if they're available but you can live with less unpredictability if you have to--stuff like address space randomization might want this.  And then, we want a crypto random number generator that blocks only at the beginning when it doesn't have enough entropy, and otherwise manages its reseeds intelligently.  (Implicit in this:  While I get why people might like to have a full entropy source in some situations, I'm extremely skeptical that it adds much from a real security perspective.)
What would break if /dev/random became something that only provided cryptographic strength random bits instead of full entropy bits, but never blocked except at startup?  Would it be possible to convince developers to then only use /dev/urandom for non-cryptographic applications, and to use /dev/random when they needed cryotographic random bits?  I'm sure there is a ton of code out there that uses /dev/urandom the wrong way now, though, and a change like this wouldn't affect that at all.  For that, the better entropy collection and maybe some external seeding of distributions seem like the only easy fixes, assming you can't make /dev/urandom block.
The cryptography mailing list

@_date: 2013-10-19 13:33:32
@_author: John Kelsey 
@_subject: Re: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
My understanding from Nadia Henninger's talks (and discussions with her) was that many of the appliance network devices that had duplicate primes in their RSA keys were drawing random numbers from /dev/urandom on machines that weren't collecting much entropy.  If this is right, it's a pretty clear demonstration of what can go wrong when /dev/urandom won't block.  (There must be many, many more cases where the machines are collecting too much entropy to get duplicate primes in their RSA moduli, but they're still getting little enough entropy that an attacker can guess the first prime they generated and thus factor their RSA modulus.)
I think the most critical moment in the operation of any RNG is the decision to start producing outputs.  There is no way for the RNG to know whether these outputs will be used for something unimportant, or to generate the high-value keypair that this device will use for the rest of its lifetime.  For devices that do some crypto, it's probably relatively common to have the system generate a high-value keypair very soon after starting up, so that first output needs to be very likely to be secure.  It's worth thinking about what might be done to ensure the best possible chance of this working.   One other thing you can see from the duplicate RSA keys: many RNGs (I think instances of /dev/urandom drawn on by openSSL) do not incorporate any internal information that can work like a salt.  They should.  If my device has a device serial number, ethernet address, timestamp, etc., those should all be hashed into the entropy pool, with 0 entropy bits assessed.  An attacker trying to guess the state of the pool is in much the same position as an attacker trying to guess a password that was used to derive an encryption key, and any unique-to-this-instance information included works just like salt in a password hashing scheme.  In principle, you could imagine doing an expensive computation to reseed the RNG, but while that would make state guessing attacks a little harder, it would also have a pretty awful performance impact.  The cryptography mailing list

@_date: 2013-10-31 03:28:18
@_author: John Kelsey 
@_subject: Re: [Cryptography] [RNG] /dev/random initialisation 
The part of the standard involving entropy sources isn't done yet, but when it is, RBGs really will have to ultimately be fed by an approved entropy source.  The alternative seems to be leaving people in the current situation, where there's more or less no way of knowing how much entropy is being collected, or where it's coming from.  If the entropy source is good, then the RBG should end up secure.  The restriction on external sources of additional input is pretty obviously a misunderstanding--someone somewhere got confused between entropy source inputs (which need to come from some trusted entropy source) and additional inputs (which can come from anywhere).  I'm not sure what that "do a deal with fips authenticated inputs"  bit is even supposed to mean.  But this kind of nonsense doesn't have to make sense, it just has to be entertaining.  That's true.  But it's also true that security is hard to get right.  Lots and lots of dumb policies and decisions have been accepted or imposed by people who thought they were doing something sensible, but were really making security weaker.  And the bit where people make up conspiracy theories to explain every such failure has zero chance of improving security.  The cryptography mailing list

@_date: 2013-11-05 22:46:36
@_author: John Kelsey 
@_subject: Re: [Cryptography] /dev/random is not robust 
Okay, but if you don't have some starting value that I don't know and can't guess, you can't establish a cryptographically secure connection with anyone to get them to send you random bits.      How do you establish a key I don't know with your randomness-providing TTP?  If you have a single secret value I don't know and can't guess, you can use this as a PRNG seed, and as long as I don't compromise your state somehow, you can keep generating outputs that I can't distinguish from random for as long as you like.  If you share a single secret value I don't know with some TTP, you can use this secret as an encryption and authentication key, and get the TTP to send you some randomness.  Then, if I observed the ciphertext from the TTP to you, your PRNG's security is exactly the same as if you just used that starting value as a PRNG seed.  If I didn't observe the message from the TTP down to you, then no secure connection was needed.  The TTP could send you random bits in the clear, and that would be fine, because I wouldn't know them.  The cryptography mailing list

@_date: 2013-11-04 17:39:16
@_author: John Kelsey 
@_subject: Re: [Cryptography] /dev/random is not robust 
...           [I hope I got the attribution right]
Yep, this is an unfixable problem. Suppose you have a program to get a keypair, either by generating it or receiving it over the net.  But your program has no entropy.  Another way of saying that is that I (the attacker) can write a program that can do anything your program can do, because I have access to the same information as your program has.  If your program generates a keypair, mine will generate the same one.
If your program makes an encrypted channel to get the keypair from some trusted server, my program will know the encryption key and can decrypt it.  My program can play man in the middle, too, because your program can't do anything my program can't also do.  Without entropy--enough entropy to make me do an impossible amount of work getting my program to run like yours--there's just no way to get your program to generate or retrieve a keypair my program can't also generate or retrieve.
Now, if there is local traffic I can't intercept, your program can feed that into its RNG.  If I also can't guess that local traffic, then your program has enough entropy to generate a keypair. Yep.  It seems like getting random secure starting seeds into devices would be a huge win here.  Then they can combine that with whatever information they have locally, and initialize their RNG, and then generate their keypair.  The cryptography mailing list

@_date: 2013-11-11 19:38:52
@_author: John Kelsey 
@_subject: Re: [Cryptography] randomness +- entropy 
I can't think of many times when it's really appropriate to demand full entropy, rather than cryptographically secure bits.  It seems like having /dev/urandom be capable of *either* generating cryptographically secure bits *or* generating predictable bits forces application developers into either using /dev/random or crossing their fingers and using /dev/urandom.  And if lots of people are being security-conscious, they all have to use /dev/random, and it will block for a really long time.  If you imagine a choice between:
a.  A secure cryptographic PRNG (say CTR_DRBG using AES256) which is catastrophically reseeded whenever it's convenient and the entropy pool is assessed at more than 256 bits.  (The pool is then reset to 0.)
b.  /dev/urandom and /dev/random as they are now.
I'm not clear on what situations there are where (b) provides better practical security than (a).  Who will make use of this model?  I mean, it looks like a lot of real-world crypto developers now are using /dev/urandom (with crossing of fingers and rubbing of rabbits' feet) to generate their keys, rather than wait for /dev/random.  It's hard to imagine those guys trying to make use of a complicated multidimensional model of whom they want to trust and how much.  In practice, they're not even paying attention to your internal entropy estimates.  This problem must come up with every entropy source, right?  If I can suspect the hardware RNG is hacked, I can also suspect the kernel or BIOS or drive firmware on which you're relying for entropy from drive access timings is hacked.
The nice thing about RDRAND is that if the hardware RNG isn't cooked, it can be used to initialize /dev/urandom and /dev/random to secure states before anyone needs any outputs from them.  (The only reason to suspect it could be cooked is, basically, because it would be really convenient for the bad guys if it were cooked.)  Since there's widely-used crypto code generating keys from /dev/urandom, closing the hole where /dev/urandom might not be securely initialized yet when the keys are generated seems like it's a couple orders of magnitude more important than addressing the possibility that RDRAND might also be cooked.  One thing to consider: RDRAND is probably fast enough that you could just request a new 128 bits of output and stir it into /dev/urandom or /dev/random whenever an output is requested.  So in principle, you could not account for RDRAND as having any entropy at all, but use it in this way, and the system would work just like it did without RDRAND, but with the difference that you would never again have a situation where /dev/urandom had 20 bits of entropy and was used to generate an RSA keypair.  This would be annoying in the sense that /dev/random wouldn't get the speedup it should from having a fast hardware RNG on board, but it would represent a huge improvement in practical security.  The cryptography mailing list

@_date: 2013-11-11 19:07:22
@_author: John Kelsey 
@_subject: Re: [Cryptography] randomness +- entropy 
If we're talking about a PRNG (which /dev/urandom is), then there are really two cases of interest:
a.  The PRNG has accumulated too little entropy[1] to be in a secure state.  b.  The PRNG has accumulated enough entropy to be in a secure state--say 128 or more bits.
In case (b), if the PRNG is secure, there can be no harm in anyone seeing lots of outputs from it. Initializing your PRNG with 200 bits of entropy and then outputting a million bits leaves you perfectly fine in security terms.  In case (a), you have a big problem.  If your PRNG has accumulated 37 bits of entropy and you generate an output, you've lost all 37 bits of entropy, because I can guess the PRNG's state, and if my guess is right, I will be able to predict the outputs correctly.  This sets up the situation where you do something like
Feed in 50 bits of entropy
Generate an output
Feed in another 50 bits of entropy
Generate another output
Feed in another 50 bits of entropy
Generate another output
And you never get to a secure state, even though you've fed in 150 bits of entropy.  This is why Yarrow does catastrophic reseeding.  [1] I use "entropy" here in the sense of information not known to any attacker, not in the sense of fundamentally unknowable information like how many nuclei decayed in a given period of time.  Also, if you're computing the entropy, the right measure to use is min-entropy, not Shannon entropy.  That's -lg( P[max] ) where P[max] is the maximum probability of any possible input to the PRNG.    The cryptography mailing list

@_date: 2013-11-07 00:16:30
@_author: John Kelsey 
@_subject: Re: [Cryptography] randomness +- entropy 
It seems like this would allow stuff like OpenSSL to do the right thing (initialize from /dev/urandom, but only once it has reached a secure state) with no more performance impact than necessary.  Ideally, /dev/urandom would accumulate entropy till it had a lot and then catastrophically reseed and set its "ready" flag.  And then any crypto application could check the flag, and read its PRNG seed or starting value for its prime number search from /dev/urandom only when the flag was set.
It seems like the best way for things to work would be that /dev/urandom always gave cryptographically strong random numbers.  But if that isn't always going to be the case, then application programs that really need that should be able to check to see if they can safely draw a PRNG seed out of /dev/urandom yet, or if they need to wait or ask the user to do something.  The alternative is silent failures that lead to low-entropy keys and breakable systems.
I don't have any intuition for how much work this is, but it seems pretty critical.  Right now, if someone is generating a cryptographic key on a Linux system, there seems to be no way for them to generate that key from /dev/urandom safely, because they can't really know if /dev/urandom will be in a secure state when they need to generate their key.  I guess the right guidance to give them now is "generate your key from /dev/random."  The cryptography mailing list

@_date: 2013-11-06 23:40:18
@_author: John Kelsey 
@_subject: Re: [Cryptography] randomness +- entropy 
If the distribution can ship with a unique secret seed value, then that resolves the uninitialized rng problem against any attacker who doesn't know that seed value.
To update the seed, I think it's sufficient to initialize /dev/urandom from the seed file and write the first 256 bits of output back to the seed file before any outputs are generated for anything else.  That guarantees that /dev/urandom never gets seeded the same way twice.  If possible it would also be nice to have some process wait for the /dev/urandom ready flag to be set (assuming one is added), and then get another 256 bits from /dev/urandom and write those to the seed file.  That ensures that the seed file eventually can become unpredictable even to someone who knows the starting value of the seed file.  The cryptography mailing list

@_date: 2013-11-05 22:31:12
@_author: John Kelsey 
@_subject: Re: [Cryptography] randomness +- entropy 
Is there any way for a program to find out if /dev/urandom has been seeded properly?  It seems like the alternative for a developer is either hope /dev/urandom has gotten to a secure point before he reads his PRNG seed from it, or get his PRNG seed from /dev/urandom and potentially block, and also potentially make other stuff block.  But there isn't really any reason for that, right? If I want to initialize a cryptographic PRNG, or generate a RSA key, or whatever, I am shooting for computational security, which /dev/urandom should give me *once it has reached a secure state*.  I don't need full-entropy bits--I'm not generating a one-time pad or something.  I just need something that is impossible to guess without more computing power than my attacker has. The cryptography mailing list

@_date: 2014-03-07 15:23:32
@_author: John Kelsey 
@_subject: Re: [Cryptography] See??? Satoshi Nakamoto Smeared 
So the reporter found someone who might be the inventor of bitcoin, or might be a little crazy and just saying so, or might be sick of weirdos "tracking him down" because of his name and just be saying what he thinks will get the reporter to go away.  From what is in the article, how would we distinguish these possibilities?
The cryptography mailing list

@_date: 2014-06-09 17:06:08
@_author: John Kelsey 
@_subject: Re: [Cryptography] Help investigate cell phone snooping by police nationwide 
Blocking the RF on the phone (say, wrapping it in aluminum foil while leaving it in the same room with you) doesn't actually solve the problem.  Most smartphones have a fair bit of memory they can use to record audio, so you may just force the malware on the phone to record the conversation now and send it up later.
Making sure the phone isn't in a position to eavesdrop on a conversation at all is a lot smarter.  The phone designers have already put a lot of effort into optimizing the performance of the phone as a microphone, so it seems like you could test how well things got picked up with various levels of sound shielding (like putting the phone into another room) by using the voice recorder and the speaker phone setting, and seeing if it can detect a noise somewhat louder than anyone's voice is likely to be through the padding.  I think a phone that was generically eavesdropping on you would massively shorten its battery life.  Processing voice and streaming it via the cell network is what phones are designed to do, and reception and battery life are two of the things the phones' designers focus on.  It's unlikely that a malware writer will get much better performance out of the phones than they can normally do for voice calls.  I wonder what the optimal strategy for widespread eavesdropping via smartphones is.  Even just listening and running some local pattern-matching for words of interest would probably have a noticable impact on battery life.  (Anyone have hard data on this?)  But given the willingness of the NSA to try to get at everything, it's interesting to ask what they might be able to do on a massive (non-targeted) scale with smartphones.  The cryptography mailing list

@_date: 2014-06-18 13:44:14
@_author: John Kelsey 
@_subject: Re: [Cryptography] What has Bitcoin achieved? 
Bitcoin in its current form isn't much of a dream for crypto anarchists, since traceability is built in and it takes a lot of effort to avoid it.  Zerocoin or some other replacement would fit better.  More generally, I think one of Ian's
points can be made more succinctly:  the claim that all governments are corrupt and evil is an easier sell in Venezuela than it is in Switzerland.  The cryptography mailing list

@_date: 2014-07-28 16:07:31
@_author: John Kelsey 
@_subject: Re: [Cryptography] propaganda on "hurdles for law enforcement" 
Yeah, Clipper didn't catch on during the Clinton administration, and post-Snowden, I would expect it to be much less popular.  On the other hand, mass surveillance is one of those issues that gets a very strong consensus among the people at the top, regardless of their political party--even if the public as a whole doesn't like the idea of mass surveillance, if both big parties' leadership supports it, who are you going to vote for, to register your disagreement?  (See also: the drug war, bailouts for large financial companies, aggressive foreign policy, impunity for the well-connected, etc.)  I don't think this is quite right.  Media focus on fear and outrage because they sell papers and draw eyeballs, and they're easy to do.  (Nothing's easier than drumming up outrage by example on the talking heads shows, which is why they do that when there's no other news.)  But people mostly don't live their lives like people scared to death of terrorists.  *Lots* of people fly in planes, travel overseas, go to big events like the Superbowl or the Boston Marathon, etc.  There's probably good poll data on this somewhere....
The cryptography mailing list

@_date: 2014-10-29 20:23:30
@_author: John Kelsey 
@_subject: Re: [Cryptography] Best internet crypto clock 
You can solve one end of this problem with beacons--nobody could have known this information before this time.  You can do the same thing with public information that's unpredictable, like the complete contents of the New York Times front page, or today's sports scores or stock prices.
You can use a digital timestamping service to solve the other end--this information had to be available by this time.
I don't know about the kidnapping scenario, but consider some program that takes an RNG seed, or some experiment which requires some random inputs.  I use the beacon values for today at noon to run the experiment, and as soon as I have the results, I get them digitally timestamped--say, at 1PM today.  This binds the experiment in time--it can't have happened before noon today or after 1 PM today.  The cryptography mailing list
