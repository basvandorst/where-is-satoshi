
@_date: 2007-05-29 12:56:55
@_author: Paul Syverson 
@_subject: Re: Sampled Traffic Analysis by Internet-Exchange-Level Adversaries 
As the person (or one of the people?) who first started to complain
about the GPA I thought I should note that my objections were against
both adjectives, global and passive. A global adversary is too strong,
even if you do limit to just the internet links. I don't think that is
quite as strong a statement as when I first made it many years ago:
(1) the line of work that prompted this thread shows that if it's too
strong to posit a truly global adversary, the scope of a potential
realistic adversary is pretty large indeed.  (2) relatedly, underlying
layer networks change over time, lots of consolidating. Some things
seem more feasible...  Anyway, the main reason I'm writing is that my objection was not just
that the GPA was too strong but that it was too weak. Thinking you
could have an adversary powerful enough to monitor all the links
necessary to watch your whole large network but not able to do any
active traffic shaping at all anywhere seems obviously nuts. This is
one reason why padding on an open low-latency (lossless) network is
problematic: an adversary with any active capability at all can induce
a timing channel easily.

@_date: 2007-06-01 18:36:21
@_author: Paul Syverson 
@_subject: Re: Sampled Traffic Analysis by Internet-Exchange-Level Adversaries 
If the traffic patterns can be stored and analyzed offline rather than
in real time, it just makes my point stronger.  Assume
someone with the ability to do truly global monitoring, watching
every connection from every client everywhere in the world through
every tor node everywhere in the world to every server everywhere in
the world (Note that I was effectively assuming the filtering you mentioned.
I don't care if the adversary watches non-Tor traffic. I assume they
have already made that separation. As you note, it is trivial to
recognize traffic going to/from/between Tor IP addresses.)
What I am saying is that it is nuts to assume that someone could have
monitors on all of these places but can do nothing active at all,
not even doing something as trivial as killing a targeted circuit
and watching to see if a suspected circuit dies elsewhere. It doesn't
even have to be targetted. The adversary can simply arbitrarily induce timing
channels in various places or kill circuits or whatever
and watch for those patterns elsewhere (in the stored
data if this is done offline).
Lasse and I saw how incredibly easy it was to find patterns with very
limited resources. George and Steven showed how you could induce patterns
gross enough to even monitor them by interference (albeit on a much
smaller and generally lower bandwidth network). I'm not comparing a global passive adversary with a global active one
and claiming that global active is more realistic or practical.  I'm
saying that it is a mistake to posit a truly global adversary (not
just a really big adversary watching, e.g., eighty percent of all the
communication we would ever be talking about) that cannot do even the
tiniest local thing actively. Nonetheless, that is the adversary from
much of the literature.

@_date: 2008-02-04 16:48:33
@_author: Paul Syverson 
@_subject: Re: The use of malicious botnets to disrupt The Onion Router 
Those are all nice starting points. Roger also has some research in
this area that goes as far as anything to date in looking at the
issues. It may have been mentioned on this list or not ready for the
public (can't recall which). I've been talking to George and others
about this... In other words, there are people who know Tor quite well
who recognize the issues and are thinking about this area along with
others. People should please continue to discuss. The only thing I
wanted to point out is that this has at least as much of hard basic
problems to solve before its fully ready as say, switching to UDP or
some of the other basic issues, probably more.  (Cf. the challenges
paper  where
some of the difficulties are raised.)  But there are already some
smart people looking at it (and me too). So I'm not holding my breath,
but I'm hopeful.

@_date: 2008-12-19 13:05:52
@_author: Paul Syverson 
@_subject: Re: UDP and data retention 
(Sorry couldn't help myself. And sorry I don't have a substantive
answer to your question. -Paul)

@_date: 2009-09-17 20:34:31
@_author: Paul Syverson 
@_subject: Re: good troll, intelligence psyops, or the genuine article? you 
As I've said for a decade and a half, onion routing guards against
traffic analysis, not traffic confirmation. If your adversary has
already identified suspect endpoints to a communication, then they are
trivially confirmed. There's other subtleties, e.g., website
fingerprinting, latency attacks, etc.  but if someone is talking about
a vulnerability to traffic confirmation level attack, then this is
something explicitly acknowledged about Tor since the beginning of the
design (and before).
I must confess that I only glanced through and didn't follow much of
what was said (or not said ;>).  But whether it's crap or not, I do
think this thread has mostly strayed pretty offtopic and request that
it be voluntarily dropped before it must be involuntarily dropped.

@_date: 2009-09-24 16:56:35
@_author: Paul Syverson 
@_subject: Re: Random chaff [was: more work for Grobbages] 
I did, but I don't get the sigh.
I was trying to succinctly say that this is a component of a different
system architecture with different assumptions. In the second
generation onion routing system we developed, i.e., the one before
Tor, we actually included mixing for experimental purposes.  The
lessons so far has been that it isn't worth it and we did not bother
to put that in Tor. That could change, but so far there are no
positive indications from the research.
Yes of course. You say that like it's trivial (to design, implement, etc.)
rather than huge.
Plus, keeping the existing network nodes synched even just to the point that
things don't actually break has not been 100 percent successful, and
this would imply much tighter synchronization not just across the
nodes but across all the clients as well. And the synchronization is
not just to keep things running but now becomes security-critical.  Wah!
More importantly, it is trivial to beat this with an active attack.
Just delay circuit setup packets slightly and watch for the pattern
at the other end. Or if the circuit is established, stomp some bits
at one end and see if the other end has junk come out shortly thereafter.
I'm not saying it's forever hopeless. The things I've mentioned and
more have been considered and people have design and evaluated
countermeasures to them and continue to do so. As Nick said, the
problem isn't that padding doesn't work. It's that it doesn't work
nearly well enough (at least so far).
Ermm. The stuff that Lasse and I did _was_ on the deployed Tor
network. Now that is not today's network. The network then was
much smaller, it didn't have guard nodes, etc. Testing in the wild in general is very tricky because Tor _is_ an
operational network, and you don't want to do anything that would
inadvertently create problems. This is also an ongoing research
challenge. We would like to understand and improve performance by
gathering data but without doing anything to increase risk to users or
operators. Karsten and others have been working on that.
Yes. There might be. But you would first have to justify the overhead
cost to the network by giving at least some reasonable argument that
it might work reasonably well, at least better than anything that's
been considered to date.  "Hey we don't know this won't work unless we
try," is not an adequate justification. Vetting ideas through the
research community seems like a reasonable first step. You would also
have to adequately analyze the impact on client and relay performance
and security before deploying. Again, nobody's discouraging research
into these questions. They just want answers before deploying. So far
none of the research has been giving encouraging answers.
Sorry. I thought that was standard. It means 'Cf.' means _confer_, i.e.,
see here.  Woops, "i.e." stands for  'id est' which means _that is_.
To unsubscribe, send an e-mail to majordomo with
unsubscribe or-talk    in the body.

@_date: 2009-09-23 15:29:36
@_author: Paul Syverson 
@_subject: Re: Random chaff [was: more work for Grobbages] 
You're trying to turn it into a mix network. The order uncertainty
doesn't matter at this level of latency. The Bauer et al. research I
mentioned showed how to do timing attacks based just on setting
up the circuit. You don't even need to send any data.
Whatever solution (if one even exists) is out there, most of
the straightforward ideas and many of the not so straightforward
ideas have already been extensively researched. Cf. the papers
Nick and I mentioned before and others in the Freehaven anonbib.

@_date: 2009-09-23 14:59:03
@_author: Paul Syverson 
@_subject: Re: Random chaff [was: more work for Grobbages] 
Yes. But packet counting can also play a role. Cf, "Passive Attack Analysis for Connection-Based Anonymity Systems"
at It's not. Cf. my "Locating Hidden Servers"
wherein we had zero false positives on any timing attacks conducted
in finding hidden services, which generally was very quick.
(That such attacks existed were known for years. That they were not
just possible but so fast and effective using merely a single
node in the network was the reason that guard nodes were introduced
into the Tor network.)
And building on that see, "Low-Resource Routing Attacks Against Tor"
where timing attacks with epsilon false positives
were based simply on circuit setup and were shown on general
Tor circuits, not just for hidden services.
There's been a lot of research on this. I think Nick pointed at
some. Cf. the anonbib.
Research against timing attacks continues. (I'm doing some myself.)
But so far, any "chaff" strategy in the literature is both too
expensive and not at all effective against active attacks on
general low-latency systems for wide use, such as Tor.

@_date: 2009-11-23 15:05:49
@_author: Paul Syverson 
@_subject: Re: The Case for Banning Reduced Hop Count Implementations 
Thank you Lucky. I had been meaning to write something like your
Even if Lucky's basic points are eventually born out, you are right
that more analysis of latency and incentives would be valuable.  To
get an idea about incentive issues in anonymous communication in
general and Tor in particular you might want to look at "On the
Economics of Anonymity". Also "Anonymity Loves Company: Usability and
the Network Effect" both available from the Freehaven anonbib. Also,
"Deploying Low-Latency Anonymity: Design Challenges and Social
Factors" which is available from the onion-router.net publications
This has nothing to do with how long the connections are. Onion
routing going back even before Tor acknowledges that if the entry and
exit nodes are controlled/observed then an adversary will quickly and
trivially link them. The nutshell way we have said this is that onion
routing [including Tor] guards against traffic analysis not traffic
confirmation. This was acknowledged in the original Tor design paper
and was later born out by analysis ("Passive Attack Analysis for
Connection-Based Anonymity Systems") experiments on the live Tor
network ("Locating Hidden Services") and in simulation on PlanetLab
("Low-Resource Routing Attacks Against Tor"). These confirmed that
correlation was fast and easy. "Sampled Traffic Analysis by
Internet-Exchange-Level Adversaries" showed that it could also be done
sampling a tiny fraction of the traffic passing through an IX.  This
is also why onion routing's security is said to be roughly c^2/n^2,
where c is the number of compromised nodes in the network and n is the
total number of nodes. (Yes that is a little too quick, and you can
raise questions. See "Towards an Analysis of Onion Routing Security",
"A Model of Onion Routing with Provable Anonymity", and "Probabilistic
Analysis of Onion Routing in a Black-box Model" for details.)
The "Low-Resource" paper is especially telling wrt your point: the
attacks were done during connection setup _before a single data cell
was transmitted_ (and with vanishingly few false-positives). You just
don't need to have a long-lived connection to fall victim to this.  So
why bother with multiple hops? One part of the answer is already given
above: it reduces the threat quadratically. But why three hops instead
of just two? This comes back to Lucky's other point that you skipped
over. And this one is not subtle at all. Three hops is the minimum to guarantee that all an exit node knows is
that a circuit came from someone using Tor. The exit cannot say even where
in the Tor network the circuit started. Similarly, all an entry node
knows is that the circuit is headed somewhere. (Yes, this too is
actually more subtle; cf. "How Much Anonymity does Network Latency
Leak?" But, a priori, given ordinary log information, it is correct.
(Of course honest Tor nodes do not do any such logging.))
So, reducing the number of hops means that exit nodes have
significantly more information about connection origins. Reducing hops
to one means that they know everything about the origin of a
connection (up to the IP address from which the connection entered the
Tor network, which is all that Tor is designed to hide.)  That makes
their deniability of what they know about traffic exiting through them
no longer plausible (because, well now it will be false). That any of
the connections going through the network are single hop thus
increases incentives to attack any exit node, also any entrance
node---which basically means all the public nodes. Details would
depend on likelyhood that a given circuit is one hop and on the
incentives, legal considerations, resources, etc. of the
adversary. But absent such details, it would be unwise to allow such a
fundamental threat to the infrastructure itself.
As Lucky observed, this is a threat to the public Tor network itself
and should be treated as such. There are other drawbacks that could be
noted, but that is the central one.
To unsubscribe, send an e-mail to majordomo with
unsubscribe or-talk    in the body.

@_date: 2011-03-22 13:27:57
@_author: Paul Syverson 
@_subject: Re: [tor-talk] Iran cracks down on web dissident technology 
I think you also did a nice job of finding the Tor relevance buried
therein. I'll respond to those parts where I think I might have
something to contribute.
Distributing trust is also not just the number and diversity of users
(and relay providers) but how they are related in intentions and other
things. When going up against The Man*, you can't just assume a
uniform distribution on relays, users, and network links between those
wrt likelyhood-of-being-run-by-a-hostile/resilience-to-attack/etc
Which means numbers and even diversity isn't the whole picture. I go
into more on this in "Why I'm not an Entropist". It is also the basis
of the trust-based routing we have been working on, which is basically
how do you route if you consider the possibility that significant
portions of the network might be under the view/control of your
adversary even if the network has 10000 relays.
And since I'm really going to try to resist responding any more to
this thread, Thanks Mike for your other message containing the stab at
a soundbite-sized and coherent expression of what I was trying to say
about how the non-tech-savvy could trust Tor with the best
justification to effort ratio.
Right. See above.
*My name for a nation-state/organized-crime/your-favorite-big-scary
adversary. Gratis to Nick for enthusiastically liking this name in a
partially related discussion on trust based routing models and thus
encouraging me to use it.
tor-talk mailing list

@_date: 2011-03-21 19:39:52
@_author: Paul Syverson 
@_subject: Re: [tor-talk] Iran cracks down on web dissident technology 
Last comments for a while. (All I have time for, sorry.)  I'm just
going to respond to specific issues about system threats and the
like. I will not join in the speculation about what governments do or
That's why I mentioned design, code, deployments, what the nodes
are running, etc. These are all subject to well documented scrutiny,
(and could of course use more and better scrutiny).
Yes. This was an acknowledged tradeoff in design that is well discussed
and documented. And many people have tried to better assess its
significance and what to do about it. This connects to usability,
incentives to running a relay, many things. See for example
the original Tor design paper, also
Anonymity Loves Company: Usability and the Network
Effect. I have done some work myself on understanding and trying to counter
endpoint eavesdroppers in both theory
"More Anonymous Onion Routing Through Trust"
and practice
"AS-awareness in Tor Path Selection"
Addressed above and in previous messages.
Also addressed above. Not claiming it's completely understood,
but I am claiming it is being publicly examined.
 Advanced govts aren't prone to tor-talk mailing list

@_date: 2011-03-21 15:07:49
@_author: Paul Syverson 
@_subject: Re: [tor-talk] Iran cracks down on web dissident technology 
This is a reasonable concern, but I think you are oversimplifying the
assurance and risk management available to those who are not tech
savvy. If they are just going to look at one or two poorly researched
articles in a
blog/credentialed-news-publication/whatever-medium-you-want that
confirm their expectations, well there's not much more you can do to
help them. Whether they trust you or not, their beliefs will not be
very well grounded.  But if they do have the interest and time (lucky
them), they don't have to be able to read the source code themselves
or pay someone (and why trust the guy you are paying to read it
anyway?, and how do you know that this is the code running on all of
the relays out there?, or the code you downloaded, and ...)
There are good answers to the latter of these for people who
are tech savvy, but how do you get trust those answers short of
a significant self-education? Here are just a few of many possible
The Tor source is available and people are encouraged to check it out,
but that's _not_ the whole story. Tor is also fairly well documented
(meaning that description of what the different parts of the source
code does is available) which encourages people to look at it more
than if it was just this pile of code goo to wade through.  And lots
of independent people _do_ look at the source code. One way you can
tell this is that they find mistakes, sometimes some fairly bad
ones. (Fortunately not too bad very often and generally fixed
quickly.) You can look at the posted history of the announced versions
 and see
acknowledgments of who found flaws and look them up. Lots of times
these are researchers at some reputed place. Lots of times these are
smart people with no credentials you would recognize. In either case
you could look them up and see who they are. Ask them their experience
reporting a flaw and getting it fixed and what their overall
impression of Tor is. You can do this even if you have no idea what
the flaw is that the release notes are saying they found or how the
Tor people fixed it.
There's also lots of academic researchers looking at Tor all the time
(somewhat overlapping the people looking at the source) and poking
holes in the design, the deployment etc. testing its strengths and
weaknesses, suggesting improvements, which often do get incorporated.
This is also all well documented and vetted by publication in
peer-reviewed scientific venues. It is also work done at reputed
institutions of higher learning in various countries, if you want
to base anything on that. You could contact the authors of these.
There are also people at places you've never heard of if you don't
trust people at big institutions.
If you don't know anyone you trust who is tech savvy, you could
contact your favorite computer science department by looking them up
on the web and ask around till you get directed to someone who knows
something about Tor and ask them.
Yes, maybe someone bogusly directed you to a simulated website of
Enormous State University with fake phone numbers in it, and whoever
you talk to there might inadvertently link you back to the Tor cabal
rather than getting some random professor or savvy student's opinion,
and maybe all those publication venues and researchers and
universities are in on it, and the supposedly independent researchers
who found code flaws were also in on it (or sock puppets created by
Roger to create credibility). But at some point you have to look at
the size, diversity, and entrenchment of the conspiracy you think is
there. At some point there is only so much we can do to reassure
you. (I'm talking about reassuring you that there is no
conspiracy. That the stuff is good is a related but independent
question that the above suggested checks should help with.)  If the
above or some of the many other things you might do to check into it
yourself without needing to understand the technology doesn't convince
you, then probably you have already decided what to believe and no
evidence is going to change that.
And yes there's always things to do to improve
transparency/trustability/usability/etc. People worth trusting
probably have a processes to do that and a relatively independent and
confirmable history of doing it.
tor-talk mailing list

@_date: 2011-03-21 04:46:30
@_author: Paul Syverson 
@_subject: Re: [tor-talk] Iran cracks down on web dissident technology 
People seem to need a periodic refresher on this.
I will just state the long public and published facts.
Interpret them as you like. You can read more details at
but here's a quick summary:
I invented onion routing at NRL with David Goldschlag and Mike Reed in
1995-96 as a US Naval Research Laboratory project with initial funding
from ONR. All of us were NRL employees time. Our first deployed
system was in 1996 and source code for that system was distributed
later that year. (Code was entirely US government work by US
government employees, so not subject to copyright.)
As part of a later NRL project, I created the version of onion routing
that became known as Tor along with Roger Dingledine and Nick
Mathewson starting in 2002. I have been an NRL employee throughout all
this.  Roger and Nick were contractors working on my project. NRL
projects funded by ONR and DARPA were the only funding they had to
work on Tor until 2004. The first publicly deployed Tor network was in
2003, which was also when the source code was made available and
publicly licensed under the MIT license.  The first funding Roger and
Nick got to work on Tor that was other than as part of an NRL project
was from the EFF starting in 2004.
Tor got funding from a variety of sources after that, including several
U.S. government projects, both before and since becoming a US 501 (c)(3)
nonprofit. You can find a summary at
tor-talk mailing list

@_date: 2011-12-22 00:40:12
@_author: Paul Syverson 
@_subject: Re: [tor-talk] Automatic vulnerability scanning of Tor Network? 
Ah, perhaps they have read [1] and are trying to roll out such an
attack below the radar. Who _do_ they work for? ;>) On a less
facetious note, people might want to look at our trust work as a more
constructive response to the diversity of geolocations, jurisdictions,
OSes, operators, Tor versions, hardware etc. [2], although it is still
research and I do not pretend to have all the pieces to make this
fully practical without several more years of work.
[1] freehaven.net/anonbib/cache/ccs07-doa.pdf
[2] tor-talk mailing list

@_date: 2012-03-09 20:52:38
@_author: Paul Syverson 
@_subject: Re: [tor-talk] Tor and HTTPS graphic 
You misunderstand or at least misrepresent what is being argued
here. There does not even have to be anything incompatible in what you
are saying and this "insistence" as you put it.  The difference lies
entirely in the threat model. So we need to get more precise about
that (below).
Nobody's blinded to the possibility. Many of us knew long ago that
several things like this are easy to do. It's even easier to just do
bitsquashing, as we noted in the first onion routing paper in 1996
(there are tradeoffs and may be times when other tagging attacks are
preferable, that's not the point). As a more directly connected
indicator of prior awareness, Mixminion was designed by some of the
main research people who also worked on Tor, specifically Roger and
Nick together with George Danezis. They spent a significant part of
the research paper that sets out the design talking about tagging
attacks and their countermeasures to them. We're all well aware of many tagging variants here. What we're saying
about them is that (1) identifying another specific example of tagging
attack without other significant contribution is not a publishable
research contribution and (2) designing in countermeasures against
such attacks (such as the Mixminion paper and some of the subsequent
formatting work in that vein did) are not worth it because it's so
easy to attack Tor whether it's made resistant to this kind of
tagging or not. (I know you don't agree with that---yet. I'm coming to
Nobody said they were equivalent. What is actually said in [1] is
   "One of the unknowns in the research world is exactly how quickly
   the timing attack succeeds. How many seconds of traffic (and/or
   packets) do you need to achieve a certain level of confidence? I'll
   grant that if you run the entry and exit, tagging is a very simple
   attack to carry out both conceptually and in practice. But I think
   Fu underestimates how simple the timing attack can be also. That's
   probably the fundamental disagreement here."
And in that passage, they're only talking about the passive timing
attack. As noted earlier in the post and in many other places,
it's trivial to put in active timing signatures if they are needed.
Actually, the post notes that this was the maximum false positive rate
achieved in the cited simulation. In the analysis on the live Tor
network also cited, there were zero false positives in thousand of
runs of the experiment (not thousands of circuits, there were also
thousands of circuits in each run of the experiment). Nonetheless, you
are right to ask about scale and base rate, but I don't think
they undermine the effective adequacy of timing attacks
in ways that ultimately matter.
Again, you overstate. What it actually says is
     "If somebody can show us that tagging attacks are actually much
     more effective than their passive timing counterparts, we should
     work harder to fix them. If somebody can come up with a cheap way
     to make them harder, we're all ears. But while they remain on par
     with passive attacks and remain expensive to fix, then it doesn't
     seem like a good move to slow down Tor even more without actually
     making it safer."
More importantly, here's where we come to the crux of the
biscuit. What do we mean by "actually much more effective"?  You seem
primarily focused on a global passive hoovering adversary, perhaps at
a limited sample rate a la Murdoch and Zielinski. You seem to want to
show that timing correlation attack by such an adversary is not so
bad, but tagging would be effective. I think you are a little quick in
the practical conclusions you draw from your analysis (ignoring
intersections and ancillary information) and how you come up with the
numbers on which you base your analysis (what you do with them seems
fine), but I won't debate those points because I don't care even if
you turned out to be right in those aspects: I'm not very worried
about that adversary because I don't think it's realistic threat to be
that global or that passive (large is fine, even multijurisdictional,
and only making small delay patterns in passing traffic, hmmm OK
maybe. But GPA I just don't buy). In any case, even if we were worried
about the global hoover, you don't want to limit to a passive attacker
as your focus on tagging illustrates.  But once an adversary can be
active there are all kinds of active timing techniques that padding
can't address, ranging from the provably secure, provably undetectable
to the merely highly effective and practical. So the usability costs
and network overhead that countering tagging would imply would not
even help much.  So, to convince me that your analysis shows we should
revisit tagging for Tor you would have to show three things: (1) Convince me that a truly global adversary is realistically worth
worrying about, (2) convince me that an adversary that does active
timing correlation would not remain a significant threat even if
tagging were no longer possible, and (3) convince me that your numbers
correspond to reality and that the results are robust to intersection
attacks and ancillary information. (No need to bother with (3) until
(1) and (2) are established.)
I also want to comment on your consideration of an adversary looking
for the clients visiting a given website. Let's accept for the moment
the idea of full GPA and accept your numbers. Even if we accept your
EER that is at least an order of magnitude worse than experiments have
found (i.e., 99%) you come up with initial anonymity sets of who is
visiting a particular website (respectively which destinations a given
client is visiting) of around 50. That is essentially zero for a big
and powerful adversary. Then add in any ancillary information
geographic location of IP addresses, prior knowledge about the
clients, nature of the destination servers, etc. not to mention
intersections over time. Rather than undermine the adequacy of passive
correlation, you have supported its effectiveness.
tor-talk mailing list

@_date: 2012-03-09 15:51:39
@_author: Paul Syverson 
@_subject: Re: [tor-talk] Tor and HTTPS graphic 
And there was a star in the east...
I actually updated my webpage, not as fully as I would like, but
I updated all the dead links and added about a dozen or so papers.
In particular there is now a link to the "Why I'm not an Entropist"
paper, the "Practical Vulnerabilities of the Tor Anonymity Network"
paper that Andrew asked me to post over a year ago, my recent
historical review "A Peel of Onion", etc. HTH.
tor-talk mailing list

@_date: 2012-03-07 04:14:39
@_author: Paul Syverson 
@_subject: Re: [tor-talk] Tor and HTTPS graphic 
I'll try to get to it soon.
Actually there are many papers over the last several years (e.g., at
ACM CCS and Info Hiding) showing that one can place undetectable
timing channels on flows (for some schemes provably undetectable for
others practically undetectable).  But passive correlation is adequate
anyway, even at very low sampling rates (cf. Murdoch and Zielinski,
PETS 2007). This is long known and well understood. It's why we have
always said that onion routing resists traffic analysis not traffic
tor-talk mailing list

@_date: 2012-03-06 21:04:10
@_author: Paul Syverson 
@_subject: Re: [tor-talk] Tor and HTTPS graphic 
Is that a typo? The suggestion was that people _stop_ working on
defeating the GPA, which is unrealistic as both too strong (global)
and too weak (passive). I've been making the same point for over 15
years, but this was an attempt to sum a lot of that up in one
place. Adversaries may be really large, but it's generally unrealistic
to consider any one of them truly global on the internet.  (In the
paper I call realistically large adversaries, The Man.) And passive
makes your mathematical proofs cleaner (and sometimes doable at all)
but assuming your adversary can't even make use of delaying packets
passing by him for a few milliseconds is ridiculous. So you what
you end up proving doesn't really tell you much about real systems
even in principle. Which is why I (and others) have been working on
better models.
I'm a mere four years behind in putting my work up on the web, and
this one wasn't co-authored so nobody else did either. I'll try to do
something about that in my copious free time this week and send a
tor-talk mailing list

@_date: 2012-04-05 12:41:23
@_author: Paul Syverson 
@_subject: Re: [tor-talk] access sites 
We created Tor to protect military communications. Much like other
things invented at NRL (e.g., the joystick controller for remote
control---patented in 1923! or GPS) it also has widespread civilian
use. For most of those, the civilian, business, or other government
use is icing on the cake of the purpose that prompted research on
them.  For some, e.g., IFF (identification friend-or-foe) their
development into civilian use (ATCRBS, the air traffic control radar
beacon system) importantly facilitates military use of the shared
space. For onion routing, we argued publicly right from the start that
the diversity of users was an essential element in effective use of
the technology---even way back when we were just calling our systems
onion routing, rather than _the_ onion routing (Tor) to distinguish
from instances of onion routing developed elsewhere.
As you can see, I'm not averse to touting these creations. But I am a
researcher who does publicly published research in this area and whose
work largely benefits from visibility. As Roger and others have
pointed out earlier in this thread, people who rely on Tor to protect
sensitive communications are rarely going to be happy to have anything
revealed about their usage. You are simply not going to hear from
(most of) those people, and you are definitely not going to get a
representative sample of such use. At best you are going to be lucky
to have anecdotal examples or even just anecdotal claims of usage
from which to extrapolate.
You seem to be asking for a statistically accurate demographic study
of all users. But I am sure there are whole classes of users who don't
want even their class of activity on Tor, much less their specific
activity, known. I have no idea what classes, but that just makes
sense. And on a more individual level, for every stalking victim who
both managed to connect to Andrew and decided to trust him to help her
protect herself online there are ???  others who did not have that
opportunity or were unsure enough about trust to not reveal. (Of
course ideally anyone regardless of technical background should know
about the benefits of Tor and how to use it for their needs without
having to talk to Andrew or someone. Let's not get into any of those
A well-designed user study will tell us something interesting about
Tor users. What it will definitely not do is give us a representative
distribution of Tor users by purpose (and as already touched on usage
demographics, e.g., by country can be significantly
dynamic). And inferring user distributions from traffic distributions in
studies that are methodologically controversial is not helpful.  If
that's all we've got for now, then that's all we've got. But we should
be very careful what we infer from it.
tor-talk mailing list

@_date: 2012-09-26 08:31:25
@_author: Paul Syverson 
@_subject: Re: [tor-talk] Tor and P2P 
It wasn't efficiency per se. In many ways reply onions are more
efficient: one circuit build vs. versus four, fewer hops in the final
connection, etc. (Potentially, since the intermediate generation of
onion routing (the one before Tor had variable length routes.) In some
ways they were less efficient.  The first two generations of designs
used onions to build circuits.  These didn't use Diffie Hellman for
circuit building and so didn't have forward secrecy. (There are some
circuit building protocols that get back some virtues of the original
design without all the limitations, but they're still just academic at
this point.)  Onions also required relays storing records of onions
that had been processed before to guard against replay attacks.
Either originally or in the second gen design (can't recall) reply
onions had a flag that allowed them to be set for either single use or
repeated use (more efficient but with risk of replay.  Reply onions
were also designed just to protect the one being replied to (e.g., the
hidden service although we also expected them to be usable for
mail). We also had design for rendezvous servers, (but that was more
for things like, e.g., an anonymous chat room) and reply onions could
start from the end of a circuit similar to the rendezvous point of
today's design. Not the whole story there but already more than you
wanted to know. I still think there's some nice features of reply
onions that I miss. The whole design and ecosystem of replies and
hidden services could benefit from a revisit, in or copious free time.
Depends on your goals. If you are going to a server you trust in
appropriate ways there is no need to build a path to hide your IP
address from it. But for a mutually mistrusting client and server
neither party should rely on the other to protect their anonymity.
Hidden servicss were designed with that as a presumed default.
Reply onions were more flexible in that regard and could be used
either way. I guess the closest current analogue to reply onions
is tor2web. Gotta run. HTH.
tor-talk mailing list
