
@_date: 2010-10-08 00:35:42
@_author: Marsh Ray 
@_subject: Re: English 19-year-old jailed for refusal to disclose decryption 
Is there a way to prove that you did?
If yes, your jailers may say "We know you have more self-incriminating evidence there. Your imprisonment will continue until you prove that you've given us everything."
If no, your jailers may say "We know you have more self-incriminating evidence there. Your imprisonment will continue until you prove that you've given us everything."
Get it?
If the encrypted file is large, and disk file fragmentation patterns, timestamps, etc. suggest it has grown through reallocation, the 4 KB grocery list you decrypt out of it is not going to convince anyone.
On the other hand, if you produce a sufficient amount of relatively incompressable image, video, or encrypted data from it, you may be able to convince them that you've decrypted it all.
- Marsh

@_date: 2010-10-06 20:57:07
@_author: Marsh Ray 
@_subject: Re: English 19-year-old jailed for refusal to disclose decryption 
I am thankful to not be an English "subject".
Or that the authorities didn't want to reveal their capability to break it.
Or that they wanted to make an example out of him.
Really? Who makes these tools? Where do they make that claim?
Wouldn't drive manufacturers have heard about this? What would they do once they realized that drives had this extra data storage capacity sitting unused?
I see this idea repeated enough that people accept it as true, but no one ever has a published account of one existing or having been used.
 > (secure deletion being quite unexpectedly difficult)
Sure, but mainly because of stuff that doesn't get overwritten (i.e., drive firmware remaps sectors which then retain mostly valid data) not because atomic microscopy is available.
What makes you think these investigators were well-funded?
Or they wouldn't prefer to spend that money on other things?
Or that they necessarily would have asked the jailers to release the teen because they'd been successful in decrypting it. Perhaps their plan was to simply imprison him until he confesses?
SSDs retain info too. Due to the wear leveling algorithms they're quite systematic about minimizing overwrite.
But I doubt any of that is an issue in this case.
- Marsh

@_date: 2011-07-16 23:23:10
@_author: Marsh Ray 
@_subject: [cryptography] OTR and deniability 
It's a good bet the entirety of the informant's PC was acquired for computer forensic analysis, as well as every PC Manning is known to have touched. There's a good chance some traffic data was retained from the network where Manning allegedly did the chatting and data transfer.
Sure the logs we see are in plain text, but that's almost certainly not all the data in play. Deniability may yet still depend on OTR and its Note that the logs indicate the parties were unauthenticated and the connection was bouncing. Was this a man-in-the-middle interception? Does the protocol and implementation issue a message to the user when an "unauthenticated" identity changes its key?
- Marsh

@_date: 2011-07-15 17:03:00
@_author: Marsh Ray 
@_subject: [cryptography] OTR and deniability 
I think so too, if only to understand how the crypto turns out to be largely irrelevant once again.
There's very little data available. Is there anything other than what's been published by Wired?
That would be consistent with Lamo hinting to his peeps that his computer was taken by investigators. But his advice for others to regenerate their own private keys shows that either he himself doesn't understand the cryptographic properties of these protocols or he believes some other keys have been compromised too.
[5]

@_date: 2011-07-15 16:45:08
@_author: Marsh Ray 
@_subject: [cryptography] OTR and deniability 
The interesting thing in this case though is that the person providing the plaintext log file is:
a) a convicted felon
b) working for the investigators/prosecutors (since before the purported log file's creation?)
c) himself skilled in hacking
I haven't heard anything about any other evidence that may exist, but just a text file by itself (or perhaps even the informant's computer as a whole) doesn't seem particularly credible to me.
- Marsh

@_date: 2011-11-27 19:00:47
@_author: Marsh Ray 
@_subject: [cryptography] Declassified NSA Tech Journals 
Came across this on Reddit:
Declassified NSA Tech Journals
It all looks so interesting it's hard to know where to start.
- Marsh
* Emergency Destruction of Documents - April 1956 - Vol. I, No. 1
* Development of Automatic Telegraph Switching Systems - July 1957 - Vol. II, No. 3
* Chatter Patterns: A Last Resort - October 1957 - Vol. II, No. 4
* Introduction to Traffic Analysis - April 1958 - Vol. III, No. 2
* Signals from Outer Space - April 1958 - Vol. III, No. 2
* Science and Cryptology - July 1958 - Vol. III, No. 3
* Net Reconstruction - A Basic Step in Traffic Analysis - July 1958 - Vol. III, No. 3
* Weather; its Role in Communications Intelligence - July 1958 - Vol. III, No. 3
* A New Concept in Computing - December 1958 - Vol. III, No. 4
* About NSA - January 1959 - Vol. IV, No. 1
* Antipodal Propagation - January 1959 - Vol. IV, No. 1
* Data Transmission Over Telephone Circuits - January 1959 - Vol. IV, No. 1
* Soviet Science and Technology: Present Levels and Future Prospects - January 1959 - Vol. IV, No. 1
* Cryptanalysis in The German Air Force - April 1959 - Vol. IV, No. 2
* The Special Felix System - April 1959 - Vol. IV, No. 2
* Intercept of USSR Missile Transmissions - July 1959 - Vol. IV, No. 3
* A Program for Correcting Spelling Errors - October 1959 - Vol. IV, No. 4
* COMINT Satellites - A Space Problem- October 1959 - Vol. IV, No. 4
* The Borders of Cryptology - October 1959 - Vol. IV, No. 4
* Did Aleksandr Popov Invent Radio? - January 1960 - Vol. V, No. 1
* Bayes Marches On - January 1960 - Vol. V, No. 1
* Book Review: Lost Languages - Fall 1960 - Vol. V. Nos. 3 & 4
* The "Tunny" Machine and Its Solution - Spring 1961 - Vol. VI, No. 2
* The GEE System I - Fall 1961, Vol. VI, No. 4
* Book Review: Lincos, Design of a Language for Cosmic Intercourse, Part 1 -
       Winter 1962 - Vol. VII, No. 1
* A Cryptologic Fairy Tale - Spring 1962 - Vol. VII, No. 2
* Aristocrat - An Intelligence Test for Computers - Spring 1962 - Vol. VII, No. 2
* Why Analog Computation? - Summer 1962 - Vol. VII, No. 3
* German Agent Systems of World War II - Summer 1962 - Vol. VII, No. 3
* The GEE System - V - Fall 1962 - Vol. VII, No. 4
* How to Visualize a Matrix - Summer 1963 - Vol. VIII, No. 3
* Book Review: Pearl Harbor: Warning and Decision - Winter 1963 - Vol. VIII, No. 1
* Soviet Communications Journals as Sources of Intelligence - August 1964 - Vol. IX, No. 3
* Use of Bayes Factors With a Composite Hypothesis - Fall 1964 - Vol. IX, No. 4
* A List of Properties of Bayes-Turing Factors - Spring 1965 - Vol. X, No. 2
* A Boer War Cipher - Summer 1965 - Vol. X, No. 3 and Fall 1965 - Vol. X, No. 4
* Something May Rub Off! - Winter 1965 - Vol. X, No. 1
* Time Is - Time Was - Time Is Past Computes for Intelligence - Winter 1965 - Vol. X, No. 1
* The Apparent Paradox of Bayes Factors - Winter 1965 - Vol. X, No. 1
* Extraterrestrial Intelligence - Spring 1966 - Vol. XI, No. 2
* Some Reminiscences - Summer 1966 - Vol. XI, No. 3
* Communications with Extraterrestrial Intelligence - Winter 1966 - Vol. XI, No. 1
* The Voynich Manuscript: "The Most Mysterious Manuscript in the World" - Summer 1967 - Vol. XII, No. 3
* Weather or Not - Encrypted? - Fall 1967 - Vol. XII, No. 4
* The Library and the User - Spring 1968 - Vol. XIII, No. 2
* Mokusatsu: One Word, Two Lessons - Fall 1968 - Vol. XIII, No. 4
* Key to The Extraterrestrial Messages - Winter 1969 - Vol. XIV, No. 1
* Curiosa Scriptorum Sericorum: To Write But Not to Communicate - Summer 1971 - Vol. XVI, No. 3
* Multiple Hypothesis Testing and the Bayes Factor - Summer 1971 - Vol. XVI, No. 3
* The Rosetta Stone and Its Decipherment - Winter 1971 - Vol. XVI, No. 1
* Writing Efficient FORTRAN - Spring 1972 - Vol. IX, No. 1
* The Strength of the Bayes Score - Winter 1972 - Vol. XVII, No. 1
* Q.E.D. - 2 Hours, 41 Minutes - Fall 1973, Vol. XVIII, No. 4
* Rochford's Cipher: A Discovery in Confederate Cryptography - Fall 1973, Vol. XVIII, No. 4
* Earliest Applications of the Computer at NSA - Winter 1973 - Vol. XVIII, No. 1
* Addendum to "A Cryptologic Fairy Tale" - Winter 1973 - Vol. XVIII, No. 1
* Some Principles of Cryptographic Security - Summer 1974 - Vol. XIX, No. 3
* Selected SIGINT Intelligence Highlights - Fall 1974 - Vol. XIX, No. 4
* Der Fall WICHER: German Knowledge of Polish Success on ENIGMA - Spring 1975 - Vol. XX, No. 2
* A Personal Contribution to the Bombe Story - Fall 1975 - Vol. XX, No. 4
* Spacecraft Passenger Television from Laika to Gagarin - Spring 1976 - Vol. XXI, No. 2
* The Voynich Manuscript Revisited - Summer 1976 - Vol. XXI, No. 3
* An Application of Cluster Analysis and Multidimensional Scaling to the Question of "Hands" and "Languages" in the Voynich Manuscript - Summer 1978 - Vol. XXIII, No. 3
* An Application of PTAH to the Voynich Manuscript - Spring 1979 - Vol. XXIV, No. 2
* German Radio Intelligence - Fall 1980 - Vol. XXV, No. 4
cryptography mailing list

@_date: 2011-12-21 23:04:34
@_author: Marsh Ray 
@_subject: Re: [cryptography] How are expired code-signing certs revoked? 
Well the people involve are not dumb, right? They know the capabilities =
of malware as well as most anyone.
Here's an overview of the proposed system:
So my interpretation of what they're essentially saying is this:
There are mostly three categories of software that need to modify =
executable memory pages:
A. Operating system loaders. EXEs and DLLs are things AV companies =
already scan. These modules can be code-signed today (and we all know =
that signed code is safe code).
B. The "legitimate" code obfuscation systems currently for IP protection =
and DRM.
C. Malware, which today uses code polymorphism ("unpackers") to evade =
signature-based detection.
When today's host based antimalware systems see the code modifications =
happening, it doesn't have an easy way to distinguish category B from =
category C. So these researchers propose to move category B applications =
into category A (under the threat of "risk of triggering a negative =
response from common malware protection tools") and thereby emulate the =
success of the operating system-based code signing systems.
Here's a classic article on the topic. In this case, the OS executable =
loader itself is used as the unpacker:
- Marsh
cryptography mailing list

@_date: 2011-12-08 16:07:59
@_author: Marsh Ray 
@_subject: Re: [cryptography] How are expired code-signing certs revoked? 
There are systems that aren't online, and there are systems that shouldn't be online for good reasons. For example the power grid.
If we consistently neglect this scenario, then if the Internet ever suffers more than a brief outage we could find ourselves rebuilding society from the iron age.
- Marsh
cryptography mailing list

@_date: 2011-12-07 22:02:35
@_author: Marsh Ray 
@_subject: Re: [cryptography] How are expired code-signing certs revoked? 
[Really this is to the list, not so much Jon specifically]
We've discussed CAs, PKI, liability, policy, etc.
But conspicuously absent in this discussion has been the Relying Party
(i.e., the end user) and their software vendor.
As weird as this sounds, the RP is the party with the ultimate control.
With the notable exception of DRM, it is the end user and the software
they selected to operate on their behalf who takes the bits from various
sources, drops them into this Rube Goldberg contraption, turns the
crank, and receives a slip of paper as output. At that point, it is up
to the user (in coordination with their software vendor) to behave
differently according to their interpretation of the result.
So I would like to differ a little bit with this statement:
Maybe that's how it's design was originally motivated, but a facility
like revocation *is* precisely what users and their software vendors
make of it.
For example:
* There are operating systems that can and do apply regular updates on
root CAs and CRLs as part of their recommended regular patch channel.
* Microsoft implemented effectively CA pinning for certain Windows code
updates quite some time ago.
* A clueful Gmail user detected the otherwise-valid Iranian MitM cert
because Google implemented effectively CA pinning in Chrome, at least
for its own sites.
* Walled-garden app stores and DRM. Sure we all hate it and it's a
largely different threat model, but it's an example of something.
These examples have one thing in common: it is possible that something
can be widely deployed that's more effectively secure than we have now.
Yes, there will be difficulties. No, it will never be perfect. But boy
is there ever an opportunity for improvement.
It may upset some apple carts however, in particular one of my
favorites. It's called: "Wow PKI is really busted, let's make popcorn
and watch the slow motion train wreck play out on the tubes".
But I find this especially ridiculous because I know for a fact that
there are people on this list who working for and directly advising
every part of PKI: the big browsers, other client software vendors,
secure websites, CAs, cypherpunks, academic cryptographers, end users,
you name it!
Moxie gets this, his convergence proposal talk has > 33K views on
YouTube and he just sold his company to Twitter. What's up with that, hmm?
Google gets this, they have multiple proposals and implementation
projects going on for enhancements in this area. And they'll
nonchalantly deploy something into Chrome in some future unnumbered
update, Mozilla will follow soon after, and then the spec will be
submitted to IETF for copy editing.
CAs we will have with us always, but the current semantics of PKI
validation (trusted roots and spotty revocation checking) are on their
way out the door. Some products will rise, some will fall, some vendors
will feel some pressure, and yes even some users will get educated about
security in the process.
So, will you be making a contribution to the solution?
- Marsh
cryptography mailing list

@_date: 2011-12-07 15:54:05
@_author: Marsh Ray 
@_subject: Re: [cryptography] How are expired code-signing certs revoked? 
It's now clear that, aside from it being ineffectually implemented, 'revocation' is an oversimplified concept.
There are at least two kinds of revocation: revocation that revokes prior signatures retroactively (perhaps from a specified date), and revocation that does not.
Originally, public key systems were said to possess deliver this property of 'nonrepudiation', meaning a digital signature could effectively authenticate the intent of the party associated with the private key. However, today such a large percentage of endpoint systems (on which the private keys are held) are infected with info-stealing malware that most everyone has plausible deniability about what is signed with their private keys. (Exceptions being perhaps hardware systems that have not been hacked yet and "trust" vendors whose organizations are specifically built on their expertise at handling private keys.)
So current revocation schemes attempt to preserve nonrepudiation in an attempt to make digital signatures more like binding ink signatures on a But automated systems checking for signatures are usually authenticating server certs or validating signed code for execution. In these cases, we definitely need the party who has been compromised to be able to repudiate the evil things that have been been signed by their private key.
So it seems to me that PKI systems were designed with some sort of leagalistic contract-binding model in mind, when in turns out in practice that security (even of ecommerce transactions) depends more on an efficient repudiation mechanism than the prevention of it!
- Marsh
cryptography mailing list

@_date: 2012-02-24 20:24:14
@_author: Marsh Ray 
@_subject: Re: [cryptography] Bitcoin in endgame 
It is apparently different things to different people.
Mailing list rules can make it just what *you* want it to be.
- Marsh
cryptography mailing list

@_date: 2012-02-27 03:26:09
@_author: Marsh Ray 
@_subject: Re: [cryptography] US Appeals Court upholds right not to decrypt a	drive 
My post had about as much to do with standard police work as the traveling salesman problem has to do with actual salesmen, or the prisoner's dilemma has to do with actual prisoners.
I thought the situation might be amenable to a simple model, and it seemed like an interesting way to try to nudge the conversation back to discussing crypto, or comp sci at least.
I know that this is a terribly common scenario that todays computer crime investigators have to deal with on a daily basis, but isn't there some variant of Godwin's law I can invoke here?
- Marsh
cryptography mailing list

@_date: 2012-02-26 19:09:31
@_author: Marsh Ray 
@_subject: Re: [cryptography] US Appeals Court upholds right not to decrypt a	drive 
So everyone who now has a hidden 2nd Truecrypt partition with incriminating things in it needs to make it their hidden 3rd partition and in the hidden 2nd partition instead store things which are merely Except that as it is stipulated that the captors are "not stupid", we must assume they are perfectly rational actors who will have worked out this strategy too.
I bet there could be an interesting paper with a game-theoretic analysis of this "traveler's dilemma". Maybe it's been written?
On each round, a traveler with hidden encrypted volumes which he prefers not to disclose must cross a border in which he passes through a "civil rights-free zone", placing himself under the control of a jailer. At the beginning of each round, the traveler selects the number of hidden volumes he will carry from some set of predefined 4-tuples: (cost/payoff to traveler if disclosed/not disclosed, cost/payoff to jailer if not The round proceeds in turns. On each turn, the jailer may elect to pay a cost to imprison the traveler for another turn, or let the traveler go free. On each turn, the traveler selects to disclose some (or none) of any undisclosed volumes he has remaining. The round ends when the traveler goes free.
What is the optimal strategy for the jailer? For the traveler?
How does it make sense to set up the initial costs?
- Marsh
cryptography mailing list

@_date: 2012-02-25 07:57:45
@_author: Marsh Ray 
@_subject: Re: [cryptography] US Appeals Court upholds right not to decrypt a drive 
It's worth noting that some kind folks from the EFF gave a fascinating talk at the recent Shmoocon which dealt with this issue specifically. It was before the ruling but they gave a lot of contextual information and, IIRC, even some background on this case as it was pending.
Marcia Hofmann and Jerome Radcliffe -
Encryption, Passwords, and Data Security
- Marsh
cryptography mailing list

@_date: 2012-03-26 03:55:12
@_author: Marsh Ray 
@_subject: [cryptography] Key escrow 2012 
(Nod to the rest of what you said)
Aside from the deep moral and constitutional problems it poses, does anyone think the US Govt could have that even from a practical perspective?
* Some of the largest supercomputers in the world are botnets or are held by strategic competitor countries. This precludes the old key shortening trick.
* The Sony PS3 and HDMI cases show just how hard it can be to keep a master key secure sometimes. Master keys could be quite well protected, but from a policy perspective it's still a gamble that something won't go wrong which compromises everyone's real security (cause a public scandal, expose industrial secrets, etc.).
* Am I correct in thinking that computing additional trapdoor functions to enable USG/TLA/LEA decryption is not free? Mobile devices are becoming the primary computing devices for many. People may be willing to pay XX% in taxes, but nobody wants to pay a decrease in performance and battery life to enable such a misfeature.
- Marsh
cryptography mailing list

@_date: 2012-03-29 04:18:07
@_author: Marsh Ray 
@_subject: Re: [cryptography] [OT] Reworked Version of Stuxnet Relative Duqu Found	in Iran 
I hadn't heard about a driver signed with a "stolen Microsoft =
certificate. I suspect it's imperfect reporting.
That article links to
Which says: "Another difference is the old driver file was signed with a =
stolen certificate=97and this one is not."
Right. The legitimate Windows Update system application won't recognize =
certs from random CAs like DigiNotar. (Code signing PKI appears good =
enough for everyone except the vendors themselves.)
But it might be possible to silently pwn MSIE users who checked the box =
"Always trust ActiveX controls from microsoft.com" and the sky's the =
limit on how you might use something like that for social engineering.
Anyone can sign up to get a code signing cert for basic driver signing, =
there is no test of purity of heart involved. Probably the only reason =
the bad guys used a stolen one is that it was easier to steal or buy a =
private key than to set up a temporary identity and pay a few hundred =
bucks for an official one.
- Marsh
cryptography mailing list

@_date: 2012-05-25 15:23:07
@_author: Marsh Ray 
@_subject: Re: [cryptography] can the German government read PGP and ssh traffic? 
This seems to be the basis for the whole article:
Why would the question include that parenthetical? Surely anyone who would know what SSH or PGP is would know what the term "encrypted communications" means. Probably the person who constructed the question is specifically familiar with those protocols and does not want the response to weasel out due to over generality.
But this sounds to me like a very general answer which was probably prepared ahead of time to reveal the minimal amount of information. For this reason I don't think it should be interpreted as referring to SSH or PGP specifically. But the phrase "depending on the type and quality of the encryption" would seemingly rule out endpoint hacks.
Perhaps someone who knows German can better interpret it.
- Marsh
cryptography mailing list
