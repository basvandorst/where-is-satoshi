
@_date: 2001-12-28 21:29:04
@_author: Ray Dillinger 
@_subject: Re: CFP: PKI research workshop 
The only case in which the PKI solution is not redundant is in
offline clearing.  But getting your point-of-transaction online
is easier than paying attention to PKI.
I happen to like offline clearing -- it opens up the possibility of
new transaction types and doing transactions in places you couldn't
before.  But the practical issue is, everybody who's interested in
electronic transactions of any kind is also interested in getting
online, and when PKI's were deployed in "developing" areas (south
africa) they got dumped just as soon as the area was developed
enough for communications to support online clearing.
On the principle of people refusing to adopt something until
it relieves pain, maybe we won't see a real PKI deployed until
we need to serve markets where speed-of-light delays make online
clearing impractical.
Mars, for example, is 3 to 22 light-minutes away.  I don't imagine
someone using an ATM on Mars is going to want to wait 12 to 88
minutes for online clearing (more if the protocol is talky or the
bandwidth is busy...).  So a martian colony might be the first
practical application of PKI and/or digital cash, assuming the
colonists want to do business with Earth companies.  But a colony
looks pretty distant right now: we haven't even got an outpost
there yet.

@_date: 2001-12-26 19:31:51
@_author: Ray Dillinger 
@_subject: Re: CFP: PKI research workshop 
In fact, that may be exactly it.  PKI, as espoused by vendors,
once established, will become an indispensable monopoly, like
AT&T before the breakup. Investors love the fantasy of buying
a kajillion shares for cheap today and then having them be
shares in an indispensable monopoly next year, so they are
inclined to believe.
The problem is that none of the vendors are offering anything
that someone who has significant volume (like a financial-services
company might) cannot provide for themselves.  The FS companies
can easily wait to adopt, because the margins offered by PKI are
fairly small and the initial investment required is fairly large.
Perhaps the margins will remain too small until royalty payments
can be eliminated entirely (until any patents expire) and the
FS companies can roll their own.  Whether or not the margins
are too small, The FS companies can wait that long easily.
But the PKI vendor cannot wait.  S/he will be out of business
in three or four years if nobody adopts.  The patents will be
for sale then much cheaper than the royalty payments s/he is
offering, and the FS negotiator across the table knows it.  The
PKI vendor therefore is going to get the worst end of the deal
every time s/he goes to financial services vendors, because s/he
is not dealing from a position of strength, and had best learn
the harsh lesson sooner rather than later.
A PKI will happen, eventually, but nobody is going to get into
a position where the financial-services sector depends on them
and has to pay them.  That's as fundamental in business as the
second law of thermodynamics in physics, and chasing the dream
of becoming an indispensable monopoly to the financial services
sector promises to be as frustrating to the seekers as the quest
for a perpetual motion device.

@_date: 2001-12-26 19:03:31
@_author: Ray Dillinger 
@_subject: Re: CFP: PKI research workshop 
Yep.  So far, that's true.  Financial stuff is the only killer app
in sight for a PKI, and the financial services sector is conservative
and heavily regulated.  There is a substantial barrier to entry: just
try to imagine running off a few thousand PKI-backed credit cards and
going into business competing against mastercard/visa/amex.  Vendor
acceptance is slow and the regulatory hurdles are high.
Oh, I can.  If it's any good, you ought to be able to offer cards
with lower interest rates/fees, and people will go for that. The
whole idea of PKI in financial services after all, is to reduce
the amortized cost of transactions by reducing fraud.  If there's
a significant cost savings, you make more money even if you pass
part of it on to the consumers.
But nobody wants to be the first -- they all want to be able to look
at the business case built by some "bleeding-edge" financial-services
company that adopted and deployed PKI-based infrastructure in some
market and got measurable results, and they all want any and all
kinks in the technology to get worked out by someone else before
they touch it.  In financial services, they want mature technology
that's cheap and reliable to produce and use -- and they will roll
their own in order to make it cheaper instead of paying some "outside"
PKI company.
That's happening now, in fits and starts, with various
products internationally and in various closed markets.  If the
business case is good, the financial services companies will be
starting to pick it up for more mainstream use in a few years.
Odds are, however, that each and every one of them is going to want
their own PKI -- where P stands for Private, or Proprietary, rather
than Public.  A Public Key Infrastructure happens when the chaotic
situation which that brings about gets consolidated and standardized,
so don't look for that for at least a decade.  Basically we have no
chance of getting a Public Key Infrastructure in place right now
because we don't have enough different Private Key Infrastructures
in place for it to have started to hurt yet.  People won't go for
the PKI until they are in some kind of pain that it relieves. And
if financial services businesses are involved, they will do it in
such a way that no PKI vendor ever makes a profit they could possibly
have made themselves.  Look for them to be buying regulations that say
PKI is part of financial services and can only be provided by licensed
financial services corporations sometime in the next few years.
Like I said, don't get too discouraged -- these things happen slowly
and it's very much a matter of stages of development.  People don't
do things until the pain of not doing them gets worse than the pain
of doing them.  Public Key comes about when Private Keys have been
common for several years and their multiplicity causes pain.  That
in itself will take several years after the Private Key structures
are fully adopted. The Private Key structures get adopted several
years after the profit margins, split between consumers, vendors, and
financial institutions, each overcome the pain of changing infrastructure.
That will take several years after the initial offering.  The initial
offerings are happening now in very restricted markets, but don't
look for it to happen in domestic consumer markets until the results
of the restricted-market offerings are several years old and the
technology involved hasn't changed AT ALL for several years. They
are looking for a technology that's been in use long enough to
establish a baseline and get results that look stable and repeatable.
That's when financial services companies will begin to take them
seriously enough to consider that the pain of deploying new
infrastructure may overcome the painof absorbing losses due to
These are just network effects: PKI will trickle through at the end
as surely as water runs downhill, because it's a better solution.
It's just going to take a decade or two, or maybe four or five
decades if there's a substantial monopoly somewhere in the industry.

@_date: 2001-12-25 17:35:25
@_author: Ray Dillinger 
@_subject: Re: CFP: PKI research workshop 
Inherent conservatism of the financial business world.  The only
way you're going to get a PKI going fast is if people can use it
to do financial transactions they couldn't do before.  I mean,
there are other uses for PKI, but money is the heart and soul of
it because money is usually the only application people have where
security is important to them personally.  And you're not going to
get people to use it for money unless you can do it while all the
bankers and all the merchants get to do business with the same
companies they're doing business with now, the relatively few
"people" whom they trust with their money.
So far, PKI's have been mostly advanced by new companies which don't
have hooks into the infrastructure of financial services yet.  So
you get failure of interoperability, and a certain amount of FUD.
The ones that have been advanced by the companies who are among the
trusted elite, have been incomplete or flawed on technical grounds
(although that may be less of a barrier to adoption than initially
It's not like these barriers are going to last forever; they're
getting used up, and companies like VISA are now trying to develop
some kind of authentication scheme.  But they're not used up yet.
Hey, don't be too discouraged; have a little perspective. It's
going a lot faster than the adoption of paper money went.

@_date: 2002-05-13 16:45:49
@_author: bear 
@_subject: Re: objectivity and factoring analysis 
One thousand years = 10 iterations of Moore's law plus one year.
Call it 15-16 years?  Or maybe 20-21 since Moore's seems to have
gotten slower lately?

@_date: 2002-06-30 20:29:12
@_author: bear 
@_subject: Re: Ross's TCPA paper 
Actually, I don't have a problem with it being traced afterwards,
if a crime has been committed and there's a search warrant or
equivalent to trace it in order to further the investigation of
a specific crime.  And that's a pseudonym, not anonymity.
My problem is that if merchant's information is easily linkable,
or if several merchants have access to the same linkable field,
then privacy is out the window.  It's reasonable for a merchant
to know every deal I've ever done with him (pseudonymity).  It's
not reasonable for a merchant to know nothing at all about my
past dealings with anyone including himself (anonymity) nor for
a merchant to know every deal I've done in my life, with everyone
(marketing databases based on linkable ID's).

@_date: 2002-06-30 15:38:29
@_author: bear 
@_subject: Re: Ross's TCPA paper 
Are you one of those who makes no distinction between anonymity
and pseudonymity?  'Cause I've been talking about pseudonymity,
and all your answers have been talking about anonymity.

@_date: 2002-06-30 05:03:33
@_author: bear 
@_subject: Re: Ross's TCPA paper 
I don't think that privacy (in the sense of having the right
to keep private details of your life from being linked for
use unauthorized by you) is ever going to happen if merchants
have the right to demand true identities.
As a merchant, you have the right to be paid and to be sure of
your payment.  I don't think you have the right to collect
data that you can correlate with every public and business
record in the universe and build a profile linked to my identity
that says what brand of breakfast cereal I eat, how much a month
I spend on sex toys, what kind of books I read, and whether I'm
in trouble in divorce court.
The problem is that there is no way to check what merchants
do with the data once they've got it; customers are prevented
from getting into the customer databases and finding out what
a merchant's got on them.  Merchants have no motive whatsoever
to police or restrain their actions in invasion of privacy, and
they have a financial motive to link data -  so there is no
reason to believe that DRM stuff on consumer machines is going
to apply to their data handling in the least.  I just don't see
any possible application of DRM that merchants would allow that
protects consumer privacy.
So yeah, I think that the right to privacy implies the right to
use a pseudonym.  For any non-fraudulent purpose, including
doing business with merchants who don't know it's a pseudonym.
And I think that's a constitutional right, whether the merchants
happen to like it or not, just like the right to eat in a
restaurant even if the manager don't like colored folks, or picket
outside a merchant's business on public property seeking redress
of grievances, or tell the truth about a merchant even if it's
not flattering to him, or otherwise exercising ordinary civil
rights the merchant might prefer you didn't.  You can't have
privacy without the option of pseudonymity, any more than you
can have bread without flour.
A few years ago merchants were equally adamant and believed
equally in the rightness of maintaining their "right" to not
do business with blacks, chicanos, irish, and women.  It'll
pass as people wake up and smell the coffee.  Unfortunately
that won't be until after at least a decade of really vicious
abuses of private data by merchants who believe in their
god-given right to snoop on their customers.
Understand that I don't really give a flying crap about the
DVD player; if I want a nice movie, I'll get together with
some buddies and make one.  And I'll let anybody who wants
to watch it download it.
What I want is the right to prevent my customer records at
the bookstore from being correlated with the customer records
at my doctor, my dentist, my insurance agent, my therapist,
my attorney, my grocery store, my pharmacist, the comics
shop, the sex-toy shop, the car dealership, the art gallery,
the stained-glass place, the computer store, the video-rental
place, my favorite restaurants, and my travel agent, and sold
as a nice totally invasive bundle back to the marketing databases
of all of the above.  This is not a question about "number of
bits".  I figure the database will have an efficient, no-nonsense
representation of all of these things, and a photo of the screen,
if it can be scanned back, is just as good as a binary copy.
I don't see any way that DRM addresses the privacy concern
of database linking.  Especially since I expect database
linking to be done using specialized software that doesn't
have to get inspected by anybody with a motive to prevent it,
on "professional" (Non-DRM) machines if necessary.

@_date: 2002-06-29 02:49:52
@_author: bear 
@_subject: Re: Ross's TCPA paper 
The problem is that the "analog hole" is how we debug stuff.
When our speakers don't sound right, we tap the signal, put
it on an oscilloscope so we can see what's wrong, correct
the drivers, and try again.  When our monitor can't make sense
of the video signal, it's different equipment but the same
idea.  When you encrypt all the connections to basic display
hardware, as proposed in Palladium, it means nobody can write
drivers or debug hardware without a million-dollar license.
And if you do fix a bug so your system works better, your
system's "trusted computing" system will be shut down.  Not
that that's any great loss.
Likewise, encrypted instruction streams mean you don't know
what the hell your CPU is doing.  You would have no way to
audit a program and make sure it wasn't stealing stuff from
you or sending your personal information to someone else.
Do we even need to recount how many abuses have been foisted
on citizens to harvest marketing data, and exposed after-the-
fact by some little-known hero who was looking at the assembly
code and went, "Hey look what it's doing here.  Why is it
accessing the passwords/browser cache/registry/whatever?"
Do we want to recount how many times personal data has been
exported from customer's machines by "adware" that hoped not
to be noticed?  Or how popup ads get downloaded by software
that has nothing to do with what website people are actually
looking at?
I don't want to give vendors a tunnel in and out of my system
that I can't monitor.  I want to be able to shut it down and
nail it shut with a hardware switch.  I don't want to ever
run source code that people are so ashamed of that they don't
want me to be able to check and see what it does; I want to
nail that mode of my CPU off so that no software can turn it
on EVER.
I'll skip the digital movies if need be, but to me "trusted
computing" means that *I* can trust my computer, not that
someone else can.

@_date: 2002-06-29 02:49:52
@_author: bear 
@_subject: Re: Ross's TCPA paper 
The problem is that the "analog hole" is how we debug stuff.
When our speakers don't sound right, we tap the signal, put
it on an oscilloscope so we can see what's wrong, correct
the drivers, and try again.  When our monitor can't make sense
of the video signal, it's different equipment but the same
idea.  When you encrypt all the connections to basic display
hardware, as proposed in Palladium, it means nobody can write
drivers or debug hardware without a million-dollar license.
And if you do fix a bug so your system works better, your
system's "trusted computing" system will be shut down.  Not
that that's any great loss.
Likewise, encrypted instruction streams mean you don't know
what the hell your CPU is doing.  You would have no way to
audit a program and make sure it wasn't stealing stuff from
you or sending your personal information to someone else.
Do we even need to recount how many abuses have been foisted
on citizens to harvest marketing data, and exposed after-the-
fact by some little-known hero who was looking at the assembly
code and went, "Hey look what it's doing here.  Why is it
accessing the passwords/browser cache/registry/whatever?"
Do we want to recount how many times personal data has been
exported from customer's machines by "adware" that hoped not
to be noticed?  Or how popup ads get downloaded by software
that has nothing to do with what website people are actually
looking at?
I don't want to give vendors a tunnel in and out of my system
that I can't monitor.  I want to be able to shut it down and
nail it shut with a hardware switch.  I don't want to ever
run source code that people are so ashamed of that they don't
want me to be able to check and see what it does; I want to
nail that mode of my CPU off so that no software can turn it
on EVER.
I'll skip the digital movies if need be, but to me "trusted
computing" means that *I* can trust my computer, not that
someone else can.

@_date: 2002-06-26 21:53:46
@_author: bear 
@_subject: Re: Ross's TCPA paper 
As a business, you want to get paid.  As long as you are
sure of your money, what the hell business is it of yours
where I live, what name I'm currently registered under, or
who I'm screwing?
When I buy things with cash or silver, if they ask for ID
I leave or lie.  I think that people should be free to use
a pseudo for any non-fraudulent purposes.

@_date: 2002-06-26 17:01:00
@_author: bear 
@_subject: RE: Ross's TCPA paper 
You are fundamentally confusing the problem of
privacy (controlling unpublished information and
not being compelled to publish it) with the
problem of DRM (attempting to control published
information and compelling others to refrain
from sharing it).  Privacy does not require
anyone to be compelled against their will to
do anything.  DRM does.
As I see it, we can get either privacy or DRM,
but there is no way on Earth to get both.
Privacy can happen only among citizens who are
free to manage their information and DRM can
happen only among subjects who may be compelled
to disclose or abandon information against
their will.
Privacy without DRM is when you don't need anyone's
permission to run any software on your computer.
Privacy without DRM is when you are absolutely free
to do anything you want with any bits in your
posession, but people can keep you from *getting*
bits private to them into your posession.
Privacy without DRM means being able to legally
keep stuff you don't want published to yourself,
even if that means using pseudonymous or anonymous
transactions for non-fraudulent purposes.
Privacy without DRM means being able to simply,
instantly, and arbitrarily change legal identities
to get out from under extant privacy infringements,
and not have the new identity easily linkable to
the old.
Privacy without DRM means people being able to
create keys for cryptosystems and use them in
complete confidence that no one else has a key
that will decrypt the communication -- this is
fundamental to keeping private information
Privacy without DRM means no restrictions whatsoever
on usable crypto in the hands of citizens.  It may
be a crime to withhold any stored keys when under a
subpeona, but that subpeona should issue only when
there is probable cause to believe that you have
committed a crime or are withholding information
about one, and you should *ALWAYS* be notified of the
issue within 30 days.  It also means that keys which
are in your head rather than stored somewhere are
not subject to subpeona -- on fifth amendment grounds
(in the USA) if the record doesn't exist outside
your head, then you cannot be coerced to produce
Privacy without DRM means being able to keep and
do whatever you want with the records your business
creates -- but not being able to force someone to
use their real name or linkable identity information
to do business with you if that person wants that
information to remain private.

@_date: 2002-06-25 17:22:46
@_author: bear 
@_subject: Re: Ross's TCPA paper 
Yep.  It was a very similar frustration that moved Stallman to
start working on GNU.  At that time, no matter what programs
you wrote, you wound up relying on a proprietary operating system,
and nobody could run your programs without paying the reichsgelt.
Since Stallman wanted to share stuff even with poor people, he
launched what was then considered a lunatic's crusade, duplicating
the functionality of every damn proprietary thing, starting from
zero, under a free license.  None of which mattered much until
Torvalds wrote the linux kernel and it finally became possible
to actually run Stallman's free stuff without paying the reichsgelt.
An open-art movement faces a very similar problem, but from a
cultural rather than a technical perspective.  'happy birthday'
is copyrighted, so somebody needs to write a song capable of
being a cultural replacement and develop a free-play license
making it possible for other artists to do covers and adaptations
as they like provided they license their performance likewise.
With freeplay songs, bands could still make money from
performances and club dates.
Ever notice restaurants where the waitstaff sings happy birthday
to customers never use the copyrighted version?  I bet you could
get them to use the freeplay version.  I bet bars would go for
a jukebox full of songs they didn't have to pay ASCAP for.  And
musicians would really like a bundle of stuff they could do
covers of without worrying about that crap.  Picture distributions
of a dozen DVDs covered with a hundred thousand MP3's (and
MIDI files so people can do their own remixes) by a thousand
ObCrypto: Could we use the DRM/trusted platform stuff they plan
to put into the computers to "enforce" the freeplay license?  ie,
make sure all derivative works also bear the freeplay license?

@_date: 2002-06-25 01:54:56
@_author: bear 
@_subject: Re: Ross's TCPA paper 
What they are doing is, in one sense, "bundling" the proprietary
media content with the proprietary operating systems; trying to fix
it so you can't have one without the other. And in this, they may
well succeed.
I think the DRM//media thing needs to be fixed, at the root.  By which
I don't mean denying these clowns their sterile fantasy; I mean just
creating open source alternatives that leave them behind.  We don't
just need open source programmers anymore; we also need open source
bands, singers, actors, directors, animators, and misc. other artists.
Information may want to be free, but it's not going to happen, not for
long, unless the people who create the information *set* it free and
fight to *keep* it free.  Software artists, being sufficiently in demand
to get not-very-oppressive contracts and less financially desperate
on the whole than other artists, have been able to lead the curve in
creating art for the public -- but other kinds of artists need to
follow or the open-source movement is not going to get past this DRM

@_date: 2002-08-06 15:29:59
@_author: bear 
@_subject: Re: dangers of TCPA/palladium 
The TCPA hardware and Palladium Software make it possible.  It's not
in the spec per se, but given the possibility, it will be done.
Uh-huh.  At the expense of their "trusted machine" status and causing
every last bit of TCPA-disabled software they've got to quit operating
correctly, and locking them out of their own confidential data which
they've got stored in sealed areas on the machine.  To say that this
gives them the choice to "avoid installing it" is at best fatuous.
Moreover, we're not that worried about *obvious* bad things... we're
worried about very, very *subtle* bad things.  Keyboard sniffers, screen
dumpers, web-cache readers, and other snoopware, if it has a "sealed"
data space to hide its malicious code and stolen data, runs without a
single detectable trace.  And, if it has an unmonitorable encrypted pipe
to the outside world (which it gets every time someone remote-authenticates
your machine) it can deliver that stolen data to untrusted parties.
The hardware supports installing such snoopware remotely as part of a
"bug fix".  Nobody can tell whether the content of a "bug fix" is or
isn't what's claimed.  Why should we assume that these businesses,
*knowing that nobody can find out*, won't screw everybody to the max?
Wow.  You must really be an idiot.
It may be worth noting that I haven't installed flash BIOS upgrades,
and won't until I can compile them myself. My machine still works
fine.  You're talking about a system where failure to install an
"upgrade" will cause loss of all the system's sealed data, which makes
it something other than voluntary.  The word "extort" comes to mind.
Assuming they are given a choice.
Okay, the changes are:
1. Somebody implements Clipper in software.
2. A "bug fix" for TCPA hardware is announced.
3. The Clipper application is made available for download.
4. The software checksums are changed to require it to be loaded at bootup
   for "trusted computing" status.
5. People find they can't get at their own data unless they install it.
6. People download it and install it.
7. Sure people can still boot linux.  But if they boot in
   "trusted" mode they'll have clipper installed on their system.
Note that this requires lying about what it is.  Note that we're
talking about companies and agencies that don't have a history of
avoiding lying.

@_date: 2002-08-05 15:32:56
@_author: bear 
@_subject: Re: dangers of TCPA/palladium 
This is unacceptable.  If the vendor is so ashamed of his code
that he won't let anyone see it, I do not want it running on my
So the "file format prison" of software without backward compatibility
becomes completely absolute.  This is going to kill it in corporate
IT environments.
Offhand, it looks like a computer in this mode is just a sort of
inferior media player.  People will still need real computers.

@_date: 2002-08-12 02:58:17
@_author: bear 
@_subject: Re: Challenge to TCPA/Palladium detractors 
I don't like the idea of a "trusted compiler".  No matter who makes
it.  People should choose compilers based on the compiler's merits
and make optimization and configuration decisions when compiling
based on their particular hardware, not in order to match some other
machine's or other user's ideal of trustable code.  The minute a
compiler becomes a "standard", for any reason, it becomes a target
for people to subvert.
People who are likely to be a source of malicious clients will also
hack hardware if the data is sufficiently valuable to warrant it.
We have already seen how a relatively simple and inexpensive hardware
hack can be used to defeat palladium security, so while it may provide
suitable infrastructure if the attacker's motivation is just the price
of a movie ticket, it is not at all trustable as a structure if the
value of the data being "protected" rises above prices that justify
hardware hacking. Moreover, the same simple hardware hack defeats
every piece of palladium-protected content or software, so the cost
of hardware hacking can be amortized over many "breaks".
I think you are trying to solve in hardware, problems which are
properly protocol-design problems.  This looks like the easy way
out because protocol design is hard, but the fact is that if there
is data you really want to protect which is more valuable than movie
tickets, what you want is a protocol that ensures no one using the
data ever has sufficient information to reconstruct more of it
than their particular licit use of it requires.

@_date: 2002-08-15 03:54:17
@_author: bear 
@_subject: Re: Overcoming the potential downside of TCPA 
... wide ... open ...  <>  Do you even know
what Kerchoff's Principle IS?!  Look, I've been trying
to hold back on actual ranting, but... but...  you
really don't get it, do you?
On the contrary, I have one box with all the protection I want:
it's never connected to the net at all.  I have another box
with all the protection that I consider practical for email
and web use.  Both run only and exactly the software I have
put on them, which I obtained from sources trusted to me and
which do not and CAN NOT require any further interaction or
authorization whatsoever to run their software.  I have selected
software, on purpose, which denies someone who is not me even
the bare possibility of restricting my ability to run it at
some future time.  I have the source code.
That is what I mean when I talk about trusted computing.  I
trust that my software does what it says it does, is completely
open to inspection and verification by first, second, and third
parties, and cannot be denied to me at any point after I have
come to depend upon it, whether or not I have a net connection
at the moment to interact with its creators.  I trust that I
cannot be singled out remotely to have a sniffer installed on
my local machine through a backdoor.  I trust that code I can
inspect at the level of machine instructions is code that cannot
keep secrets from me or forever conceal malign intent.  I trust
that I cannot be forced to depend on any single commercial
software provider, whether it be for the OS or for the "trusted"
compiler which can, of course, come from only one source.  I
trust that coercive "upgrades" done for the sake of incompatibility
with existing code,  do not and cannot happen automatically given
my system configuration.
That is trusted computing sir, and TCPA/Palladium is a huge
step *backward* from it.  Anything that runs *ANY* code that
cannot be inspected, or which keeps data that cannot be inspected,
is running code that cannot be trusted.
TCPA/Palladium does not provide trusted computing.  At least
not computing that I can trust in the way I trust what I've
got now. In fact, from my POV, TCPA/Palladium look like ways
to enable the running of software which I *CANNOT* trust.
Imagine my excitement at the prospect.
This is a cryptography mailing list.  Do we even want to count
the number of times commercial software providers have come up
with some crap and claimed it was secure, and been just lying
to us?  Do I have to recount all the proprietary, snake-oil
encryption systems that relied for its security on not being
inspected?  Do I have to recount the number of ways that unstudied
security designers have given us their best efforts and had them
shot down by professionals in seconds?  Do we have to speculate
about what can happen if the clowns who employ them think they'll
never be caught?!  We've all been around the block enough to know
this by now:
Kerchoff was absolutely right.  A hundred and twenty years since
he elucidated the Principle has not changed a thing.
NOBODY has the manpower or time to find all their bugs in-house.
If you can't inspect the machine code (and preferably the source)
then you are looking at something that is not and can never be
made secure.
Now, you're talking about a system that gives people the opportunity
to HIDE THE CODE, and telling us that's security?!  What the hell
are you smoking?! You are confusing real security mistakes with the
ability to DETECT real security mistakes!

@_date: 2002-08-14 21:50:30
@_author: bear 
@_subject: Re: Overcoming the potential downside of TCPA 
Is that the one where the first elephant decides that
blind men are flat and squishy, and all the other elephants
check the blind men after he's done, and they agree?
I would say that it has been more impeded by misrepresentation.
The spec is designed to be hard to read and M. AARG, the
one who has been talking about the advantages of the proposal,
has been (hmmm) either terribly naive or deliberately
misleading.  As people actually work through the spec and
find the things s/he's been claiming aren't there or couldn't
be done with it, the odds of his/her being a mere paid shill
increase and his/her credibility decreases in direct
Yes, there has been some extremism.  The forum has a high
incidence of paranoia and distrust of authority -- but there
are few fora where people *KNOW* as many good reasons to be
paranoid and distrust authority as the posters to these
lists, having seen backpedaling, power grabs, and outright
misrepresentations and lies beyond counting as regards
security.  The distrust you see from the extremists here
has been well earned by those whom they distrust.  You
should expect extremism -- including mine.
But in the end, if a point is wrong, regardless of whether it
was made out of extremism, paranoia, or a deliberate will to
mislead, the truth comes out as people work through the
spec and find out what the heck is actually there.  No shill
can mislead people who are actually willing to go to source
documents and do the work, so putting a paid shill here is
just a waste of money.  In other words, the "Extremists"
will do the work to back up their points for free, whereas
the shill, if his/her points are wrong, cannot no matter how
much s/he is paid.
Shakespeare couldn't possibly have produced his body of work
if copyright laws had been in effect.  All the characters would
have "belonged" to someone else.  I'll go with patents about
technical things, although I think the duration is maybe too
long, but art, poetry, music, words -- they properly belong to
the public and I applaud the amateur writers, artists, and
musicians who do what they do because they love it instead of
doing what they do to get paid.  The professionals certainly
aren't producing work that's any better than the best amateurs
any more - and I doubt they ever have.
I am an extremist.  That's me under the banner that says
"Real Artists Have Day Jobs and Real Computers Can Copy Files."

@_date: 2002-08-14 15:19:01
@_author: bear 
@_subject: Re: Overcoming the potential downside of TCPA 
The problem with this idea is that TCPA is useless.  For all the *useful*
things you are thinking of, you need TCPA plus an approved key.  The only
way you are going to get an approved key is inside a tamper-resistant chunk
of hardware.  If you should manage to extract the key, then yes, you'll be
able to create that CD.  But the idea is that you, the hardware owner, are
not authorized to extract the information contained in your own hardware.
I find the idea of "owning" something without having the legal right to
open it up and look inside legally dubious at best, but I'm no lawyer....
The idea is that you shouldn't get anywhere without hardware hacking. The
people doing this have decided hardware hacks are acceptable risks because
they only want to protect cheap data -- movies, songs, commercial software,
whatever.  They are sticking to stuff that's not expensive enough to justify
hardware hacks.
However, if this infrastructure does in fact become trusted and somebody
tries to use it to protect more valuable data, God help them.  They'll get
their asses handed to them on a platter.

@_date: 2002-09-19 01:41:41
@_author: bear 
@_subject: Re: Cryptogram: Palladium Only for DRM 
In emergencies, yes.  Remember the people trying to deal with
and organize the WTC rescue efforts, whose software kept rebelling
because of inappropriately-enforced license issues?  Care to even
estimate the liability for lives lost due to that?  You want to
create a system where they'd have *NO* way to override copyright
in a real emergency, *NO* way to save lives?  No. That's cut and
dried, because Copyright is never an emergency.  Copyright infraction
never costs lives.
I for one don't give a flaming shit whether someone has the
"legal rights" to equipment he has to use in an emergency to
save lives.  When putting automatic enforcement in place
means that lives will be lost, it is a Bad Idea. A company
that did it might (and IMO should) be held liable in court.
Furthermore, if you think that Pd will only be used for legal
purposes by the software vendors and manufacturers who control
it, I strongly suggest you revise your trust model....  I have
seen no indication anywhere that these people are any more
trustworthy than those whose actions you decry. The only
difference is that the scale of abuses which can be perpetrated
by them is staggeringly large compared to the minor abuse of
someone copying a song or running a program out of license.

@_date: 2002-09-17 00:33:11
@_author: bear 
@_subject: Re: Cryptogram: Palladium Only for DRM 
You know what?
Any designer of financial services software should know better than
designing something which stores sufficient information on the local
machine to enable a signon to the account. Simply speaking, it is a
fundamental of financial services software that there must not be
adequate information on the machine to enable authentication without
an explicit user action. If posession of the machine alone is
sufficient to authenticate with financial services, then we are
back to the situation where thieves would break into the houses of
the wealthy to steal all their money -- except now they would do
it by stealing the computer instead of by stealing a big box of
jewelry, silverware, and gold coins.
Machine-based signon makes the PC into a thing that has to be locked
up in the safe at all times, just like a big pile of gold coins
sitting on the desk as far as thieves are concerned.  It would
remove all the protections normally associated with bank vaults
and Federal Deposit Insurance.
If anyone builds a system that allows authentication based solely
on information stored on the machine, they should not be surprised
when insurance companies which are sane refuse to insure
transactions mediated thereby, and refuse to ensure accounts
subject to such transactions.
Pd does not change this fundamental fact.  If it's possible for
software, including Palladium-dependent software, to sign on and
authenticate with the bank without having human input to the
authentication step, then it's possible for a thief in posession
of the machine to create a situation where the bank is fooled
into thinking that something is a legitimate transaction, when
it is not.
And if it is *not* possible for software to authenticate with the
bank without human input, whether or not it is palladium-dependent,
because there is not sufficient information on the machine to
enable an authentication, then it is not possible for the "next
nimda" to empty your bank account.  That is what we refer to as
a sane design, with or without Palladium.
Thus your argument defeats itself.  You can't have it both
ways.  This is why "single signon" is insane from a security
point of view, along with any software that permits it.
Machine-based authentication is suicidal for financial
applications, with or without Palladium in the mix.  It
gives thieves a motive to break into people's homes, which
makes those people less safe as well as risking their money.
Schneier reached exactly the same conclusion about Pd that I did,
for exactly the same reasons.

@_date: 2002-10-03 14:41:52
@_author: bear 
@_subject: Re: What email encryption is actually in use? 
I consider that state perfectly well defined -- it is the
"no connection" state.  The only reason any protocol works
is because people prefer abiding by its rules and the
policies each other set up in it to having no connection.
The essence of a protocol is to detect situations where
one party or the other prefers "No connection" over the
rules, and enforce that such detection happens before any
confidential data is shared.  According to this rule, I
would say that the protocol you say is in an "undefined
state" has in fact functioned perfectly.  It detected a
rule that the other was not willing to abide by and dropped
the connection *before* risking any confidential data.
That's precisely what it was supposed to do.
But if you are willing to abide by the sending-plaintext
protocol in the first place, this is perfectly reasonable
too. Protocol termination for lack of willingness to trust
single-DES is no different than termination of protocol
for lack of willingness to send (or receive) plaintext.
Where our protocol design fails is in considering "plaintext"
to be something other than "a particularly unreliable and
ineffective encryption algorithm."  Certainly nobody who's
willing to reject a connection for a self-signed certificate
should be willing to accept plaintext, because obviously
plaintext is not as secure as the minimum security they are
requiring.  But experience shows that people willing to
reject self-signed certs and poor ciphers always seem to
be willing to accept the even poorer cipher named plaintext.
This is completely irrational; either you need security or
you don't.

@_date: 2002-11-08 16:36:56
@_author: bear 
@_subject: Re: Did you *really* zeroize that key? 
I remember this issue from days when I wrote modem drivers.
I had a fight with a compiler vendor over the interpretation
of "volatile".
They agreed with me that "volatile" meant that all *writes*
to the memory had to happen as directed; but had taken the
approach that *reads* of volatile memory could be optimized
away if the program didn't do anything with the values read.
This doesn't work with the UARTs that I was coding for at the
time, because on those chips, *reads* have side effects on
the state of the chip.  If a read of the status register
doesn't happen, then subsequent writes to the data buffer will
not trigger a new transmit.
The compiler vendor had not foreseen a situation in which
reads might have side effects, and so the compiler didn't
work for that task. I wound up using a different compiler.
Although the bastards never admitted to me that they were wrong,
I noted that in their next patch release, it was listed number
one in the list of critical bugfixes.

@_date: 2003-06-30 16:10:24
@_author: bear 
@_subject: Re: Attacking networks using DHCP, DNS - probably kills DNSSEC NOT 
I think that the problem would be somewhat ameliorated if there
were a DNS cache on the laptop itself.  It would still use DNS
servers, but if it got a different IP number for the same address,
it should notify someone.
This can happen without an attack going on, if the legitimate
addressee's DNS record changes because the IP address of that
service actually changes - but with sites like Yahoo, Paypal,
etc, they've got a lot of infrastructure and momentum there.
Those IP addresses don't change on a whim. And those are the
major targets for a DNS spoof.

@_date: 2003-07-01 16:48:37
@_author: bear 
@_subject: Re: Attacking networks using DHCP, DNS - probably kills DNSSEC 
I tend to agree...  I don't think "zero-configuration" networking has
a real possibility to create any safety zones beyond the immediate
physical machine.  After all, if you can plug it into any network and
it just works, you can plug it into an insecure or subverted network
and it'll just work.
At the very least you've got to have a file of keys.

@_date: 2003-07-01 16:48:37
@_author: bear 
@_subject: Re: Attacking networks using DHCP, DNS - probably kills DNSSEC 
I tend to agree...  I don't think "zero-configuration" networking has
a real possibility to create any safety zones beyond the immediate
physical machine.  After all, if you can plug it into any network and
it just works, you can plug it into an insecure or subverted network
and it'll just work.
At the very least you've got to have a file of keys.

@_date: 2004-08-18 15:32:52
@_author: bear 
@_subject: Re: RPOW - Reusable Proofs of Work 
I'm wondering how applicable RPOW is.  Generally speaking, all
the practical applications I can think of for a proof-of-work
are defeated if proofs-of-work are storable, transferable, or
reusable.  Once they're storable, tranferable, and reusable,
aren't we restricted to applications already nailed down by
digital cash schemes?
So, even if it works flawlessly, this seems like an exercise
of cleverness that makes a cryptographic entity *less* generally
useful than the primitive from which it's derived. It probably
has a few specialized applications that normal POWs won't serve;
I just haven't been able to distinguish them from the applications
served by digital cash.
Why doesn't this scheme give rise to a "POW server" that just
sits there, generating proofs-of-work in advance of need and
dispensing them at request?  Or even to a company that sells
POW's to people who can't be bothered to run their own server?
And doesn't such a device or service defeat the use of POWs
for real-time load balancing, traffic control, etc?

@_date: 2008-11-15 07:04:21
@_author: Ray Dillinger 
@_subject: Re: Bitcoin P2P e-cash paper 
Okay, that's surprising.  If you're not using buyer/seller identities, then you are not checking that a spend is being made by someone who actually is the owner of (on record as having recieved) the coin being spent.  There are three categories of identity that are useful to think about.  Category one: public.  Real-world identities are a matter of record and attached to every transaction.  Category two: Pseudonymous.  There are persistent "identities" within the system and people can see if something was done by the same nym that did something else, but there's not necessarily any way of linking the nyms with real-world identities.  Category three: unlinkably anonymous.  There is no concept of identity,
persistent or otherwise.  No one can say or prove whether the agents involved in any transaction are the same agents as involved in any other transaction. Are you claiming category 3 as you seem to be, or category 2?
Lots of people don't distinguish between anonymous and pseudonymous protocols, so it's worth asking exactly what you mean here.  Anyway:  I'll proceed on the assumption that you meant very nearly (as nearly as I can imagine, anyway) what you said, unlinkably anonymous.  That means that instead of an "identity", a spender has to demonstrate knowledge of a secret known only to the real owner of the coin.  One way to do this would be to have the person recieving the coin generate an asymmetric key pair, and then have half of it published with the transaction.  In order to spend the coin later, s/he must demonstrate posession of the other half of the asymmetric key pair, probably by using it to sign the key provided by the new seller.  So we cannot prove anything about "identity", but we can prove that the spender of the coin is someone who knows a secret that the person who recieved the coin knows. And what you say next seems to confirm this: Note, even though this doesn't involve identity per se, it still makes the agent doing the spend linkable to the agent who earlier recieved the coin, so these transactions are linkable.  In order to counteract this, the owner of the coin needs to make a transaction, indistinguishable to others from any normal transaction, in which he creates a new key pair and transfers the coin to its posessor (ie, has one sock puppet "spend" it to another). No change in real-world identity of the owner, but the transaction "linkable" to the agent who spent the coin is unlinked.  For category-three unlinkability, this has to be done a random number of times - maybe one to six times?  BTW, could you please learn to use carriage returns??  Your lines are scrolling stupidly off to the right and I have to scroll to see what the heck you're saying, then edit to add carriage returns before I respond. Mmmm.  I don't know if I'm comfortable with that.  You're saying there's no effort to identify and exclude nodes that don't cooperate?  I suspect this will lead to trouble and possible DOS attacks. Okay, when you say "same" transaction, and you're talking about transactions that are obviously different, you mean a double spend, right?  Two transactions signed with the same key?
Until.... until what?  How does anybody know when a transaction has become irrevocable?   Is "a few" blocks three?  Thirty?  A hundred?  Does it depend on the number of nodes?  Is it logarithmic or linear in number of nodes?  But in the absence of identity, there's no downside to them if spends become invalid, if they've already recieved the goods they double-spent for (access to website, download, whatever).  The merchants are left holding the bag with "invalid" coins, unless they wait that magical "few blocks" (and how can they know how many?) before treating the spender as having paid.  The consumers won't do this if they spend their coin and it takes an hour to clear before they can do what they spent their coin on. The merchants won't do it if there's no way to charge back a customer when they find the that their coin is invalid because the customer has doublespent.
So there's a possibility of an early catch when the broadcasts of the initial simultaneous spends interfere with each other.  I assume here that the broadcasts are done by the sellers, since the buyer has a possible disincentive to broadly disseminate spends. Okay, that's a big difference between a proof of work that takes a huge set number of CPU cycles and a proof of work that takes a tiny number of CPU cycles but has a tiny chance of success.  You can change the data set while working, and it doesn't mean you need to start over. This is good in this case, as it means nobody has to hold recently recieved transactions out of the link they're
working on.
Right.  That was the misconception I was working with.  Again, the difference between a proof taking a huge set number of CPU cycles and a proof that takes a tiny number of CPU cycles but has a tiny chance of success.
It's like a random variation in the work factor; in this way it works in your favor. I don't understand how "transaction fees" would work, and how the money would find its way from the agents doing transactions to those running the network.  But the economic effect is the same (albeit somewhat randomized) if adding a link to the chain allows the node to create a coin, so I would stick with that.
Also, be aware that the compute power of different nodes can be expected to vary by two orders of magnitude at any given moment in history.

@_date: 2008-11-15 02:20:23
@_author: Ray Dillinger 
@_subject: Re: Bitcoin P2P e-cash paper 
Okay.... I'm going to summarize this protocol as I understand it. I'm filling in some operational details that aren't in the paper by supplementing what you wrote with what my own "design sense" tells me are critical missing bits or "obvious" methodologies for First, people spend computer power creating a pool of coins to use as money.  Each coin is a proof-of-work meeting whatever criteria were in effect for money at the time it was created.  The time of creation (and therefore the criteria) is checkable later because people can see the emergence of this particular coin in the transaction chain and track it through all its "consensus view" spends.  (more later on coin creation tied to adding a link). When a coin is spent, the buyer and seller digitally sign a (blinded) transaction record, and broadcast it to a bunch of nodes whose purpose is keeping track of consensus regarding coin ownership.  If someone double spends, then the transaction record can be unblinded revealing the identity of the cheater.  This is done via a fairly standard cut-
and-choose algorithm where the buyer responds to several challenges with secret shares, and the seller then asks him to "unblind" and checks all but one, verifying that they do contain secret shares any two of which are sufficient to identify the buyer.  In this case the seller accepts the unblinded spend record as "probably" containing a valid secret share. The nodes keeping track of consensus regarding coin ownership are in a loop where they are all trying to "add a link" to the longest chain they've so far recieved.  They have a pool of reported transactions which they've not yet seen in a "consensus" signed chain.  I'm going to call this pool "A".  They attempt to add a link to the chain by
moving everything from pool A into a pool "L" and using a CPU-
intensive digital signature algorithm to sign the chain including the new block L.  This results in a chain extended by a block containing all the transaction records they had in pool L, plus the node's digital signature.  While they do this, new transaction records continue to arrive and go into pool A again for the next cycle of work. They may also recieve chains as long as the one they're trying to extend while they work, in which the last few "links" are links that are *not* in common with the chain on which they're working.
These they ignore.  (?  Do they ignore them?  Under what circumstances would these become necessary to ever look at again, bearing in mind that any longer chain based on them will include them?) But if they recieve a _longer_ chain while working, they immediately check all the transactions in the new links to make sure it contains no double spends and that the "work factors" of all new links are appropriate.  If it contains a double spend, then they create a "transaction" which is a proof of double spending, add it to their pool A, broadcast it, and continue work.  If one of the "new" links has an inappropriate work factor (ie, someone didn't put enough CPU into it for it to be "licit" according to the rules) a new "transaction" which is a proof of the protocol violation by the link-creating node is created, broadcast, and added to pool A, and the chain is rejected.  In the case of no double spends and appropriate work factors for all links not yet seen, they accept the new chain as consensus. If the new chain is accepted, then they give up on adding their
current link, dump all the transactions from pool L back into pool A (along with transactions they've recieved or created since starting work), eliminate from pool A those transaction records which are already part of a link in the new chain, and start work again trying to extend the new chain. If they complete work on a chain extended with their new link, they broadcast it and immediately start work on another new link with all the transactions that have accumulated in pool A since they began work.  Do I understand it correctly?
Biggest Technical Problem: Is there a mechanism to make sure that the "chain" does not consist solely of links added by just the 3 or 4 fastest nodes?  'Cause a broadcast transaction record could easily miss those 3 or 4 nodes and if it does, and those nodes continue to dominate the chain, the transaction might never get added.  To remedy this, you need to either ensure provable propagation of
transactions, or vary the work factor for a node depending on how many links have been added since that node's most recent link.   Unfortunately, both measures can be defeated by sock puppets.  This is probably the worst problem with your protocol as it stands right now; you need some central point to control the identities (keys) of the nodes and prevent people from making new sock puppets. Provable propagation would mean that When Bob accepts a new chain from Alice, he needs to make sure that Alice has (or gets) all
transactions in his "A" and "L" pools.  He sends them, and Alice sends back a signed hash to prove she got them. Once Alice has recieved this block of transactions, if any subsequent chains including a link added by Alice do not include those transactions at or before that link, then Bob should be able to publish the block he sent Alice, along with her signature, in a
transaction as proof that Alice violated protocol.  Sock puppets defeat this because Alice just signs subsequent chains using a new key, pretending to be a different node. If we go with varying the work factor depending on how many new links there are,  then we're right back to domination by the 3 or 4 fastest nodes, except now they're joined by 600 or so sock puppets which they use to avoid the work factor penalty. If we solve the sock-puppet issue, or accept that there's a central point controlling the generation of new keys, then generation of coins should be tied to the act of successfully adding a block to the "consensus" chain.  This is simple to do; creation of a coin is a transaction, it gets added along with all the other transactions in the block.  But you can only create one coin per link, and of course if your version of the chain isn't the one that gets accepted,
then in the "accepted" view you don't have the coin and can't spend it.  This gives the people maintaining the consensus database a reason to spend CPU cycles, especially since the variance in work factor by number of links added since their own last link (outlined
above) guarantees that everyone, not just the 3 or 4 fastest nodes,
occasionally gets the opportunity to create a coin.
Also, the work requirement for adding a link to the chain should vary (again exponentially) with the number of links added to that chain in the previous week, causing the rate of coin generation (and therefore inflation) to be strictly controlled.  You need coin aggregation for this to scale.  There needs to be a "provable" transaction where someone retires ten single coins and creates a new coin with denomination ten, etc.  This is not too hard, using the same infrastructure you've already got; it simply becomes part of the chain, and when the chain is accepted
consensus, then everybody can see that it happened.

@_date: 2008-11-06 05:14:37
@_author: Ray Dillinger 
@_subject: Re: Bitcoin P2P e-cash paper 
I think the real issue with this system is the market for bitcoins.  Computing proofs-of-work have no intrinsic value.  We can have a limited supply curve (although the "currency" is inflationary at about 35% as that's how much faster computers get annually) but there is no demand curve that intersects it at a positive price point.
I know the same (lack of intrinsic value) can be said of fiat currencies, but an artificial demand for fiat currencies is created by (among other things) taxation and legal-tender laws.  Also, even a fiat currency can be an inflation hedge against another fiat currency's higher rate of inflation.   But in the case of bitcoins the inflation rate of 35% is almost guaranteed by the technology, there are no supporting mechanisms for taxation, and no legal-tender laws.  People will not hold assets in this highly-inflationary currency if they can help it.

@_date: 2009-03-05 06:15:30
@_author: Ray Dillinger 
@_subject: Re: Judge orders defendant to decrypt PGP-protected laptop 
The law is not administered by idiots.  In particular, the law is not administered by people who are more idiotic than you.  You may disagree with them, or with the law, but that does not make them stupid.
On the one hand there are (inevitable) differences in profile
between a partition that sees daily use and a partition that doesn't.  If a forensics squad had a good look at my laptop, they'd see that my (unencrypted) Windows partition has not been booted or used in three years, whereas file dates, times, and contents indicate that one of the other partitions is used daily.
If he decrypts a partition that clearly does not get used frequently, and more to the point shows no signs of having been used on a day when it is known that the laptop was booted up,
then he is clearly in violation of the order.
More to the point, you're arguing about a case where they have testimony from multiple officers who have *SEEN* that the images are on the computer, where both defense and prosecution agree that they do not enjoy fifth-amendment priveleges, and where the testomony of multiple officers gives the partition name ("Z drive") in which the images were found.  If the decrypted partition does not match in these particulars, and especially if it does not show any evidence of usage while the laptop is known to have been powered up during the initial search, then the defendant is clearly in violation of the order. Now, I think there is a legitimate argument to be made about whether the defendant can be compelled to *use* a key which he has not got written down or otherwise stored anywhere outside his own head.  It's generally agreed that people can't be compelled to produce or disclose the existence of memorized keys, but can be compelled to produce or disclose the existence of any paper or device on which a key is recorded.  But regardless, if the order to use the key is considered legit, then failure to comply with the order (by using a different or "wrong" key, unlocking a different volume) is direct violation of a court order.  People go to jail for that.
Keep in mind that the right to be secure from search and seizure of one's documents has always been subject to due process and court orders in the form of search warrants.  The right to privacy is not an absolute right and never has been, and obstructing the execution of a lawfully served warrant is not a viable strategy
for staying out of jail.
            (neither a lawyer, nor, usually, an idiot)

@_date: 2010-10-06 18:57:26
@_author: Ray Dillinger 
@_subject: English 19-year-old jailed for refusal to disclose decryption key 
a 19-year-old just got a 16-month jail sentence for his refusal to disclose the password that would have allowed investigators to see what was on his hard drive.  I suppose that, if the authorities could not read his stuff without the key, it may mean that the software he was using may have had no links weaker than the encryption itself -- and that is extraordinarily unusual - an encouraging sign of progress in the field, if of mixed value in the current case.
Really serious data recovery tools can get data that's been erased and overwritten several times (secure deletion being quite
unexpectedly difficult), so if it's ever been in your filesystem
unencrypted, it's usually available to well-funded investigators without recourse to the key.  I find it astonishing that they would actually need his key to get it. Rampant speculation: do you suppose he was using a solid-state drive instead of a magnetic-media hard disk?

@_date: 2013-08-31 18:02:00
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] NSA and cryptanalysis 
I have been hearing rumors lately that factoring may not in fact be as hard
as we have heretofore supposed.  Algorithmic advances keep eating into RSA
keys, as fast as hardware advances do.  A breakthrough allowing most RSA keys
to be factored could be just one or two more jumps of algorithmic leverage
away (from academics; possibly not from the NSA).  It could also be the case
that special-purpose ASICs that accelerate the process substantially may
have been designed and built.
We know about Shor's algorithm for factoring in NlogN time.  It requires a
quantum computer to run though.  We have heard rumors of quantum computers
being built, and I recall a group of academics who actually built one nearly
eight years ago.
That seems to be the sort of thing that would attract attention from a lot
of three-letter agencies, and efforts to scale it up would be intensely
supported with all the resources and brainpower that such an organization
could bring to bear.  How far have they come in eight years?  It is both
interesting and peculiar that so little news of quantum computing has been
published since.
The cryptography mailing list

@_date: 2013-09-08 03:14:10
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
I've seen this assertion several times in this thread, but I cannot
help thinking that it depends on what *kind* of backdoor you're
talking about, because there are some cases in which as a crypto
amateur I simply cannot see how the construction of an asymmetric
cipher could be accomplished.
As an example of a backdoor that doesn't obviously permit an
asymmetric-cipher construction, consider a broken cipher that
has 128-bit symmetric keys; but one of these keys (which one
depends on an IV in some non-obvious way that's known to the
attacker) can be used to decrypt any message regardless of the
key used to encrypt it.  However, it is not a valid encryption
key; no matter what you encrypt with it you get the same
There's a second key (also known to the attacker, given the IV)
which is also an invalid key; it has the property that no
matter what you encrypt or decrypt, you get the same result
(a sort of hash on the IV).
How would someone construct an asymmetric cipher from this?
Or is there some mathematical reason why such a beast as the
hypothetical broken cipher I describe, could not exist?
The cryptography mailing list

@_date: 2013-09-07 19:54:04
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
If it isn't, then you haven't considered its likely effects.
First of all, it makes CA's visibly redundant.  If people stop using
CA's that multiplies the number of channels that must be compromised
in order to eavesdrop.  Furthermore, it makes those channels parties
actually interested in the authenticity of the communications, such
as the companies whose keys are being authenticated.  In short, it
means the NSA would have to deal directly with the people they want
to eavesdrop on. That makes reaching a covert deal to expose keys a
bit more difficult, I'm thinking.
Secondly, it is the case that a DNS cache poisoning attack is an
occasionally useful technique allowing attackers to access things
that some people would rather they didn't access.  Such attackers
may or may not, apparently, include the NSA themselves, and if they
depend on that capability, then DNSSEC could be seen by them as a
threat against a useful channel for obtaining information.
The cryptography mailing list

@_date: 2013-09-08 14:45:49
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Why prefer symmetric crypto over public key crypto? 
You've answered your own conundrum!
Of course the idea of remembering keys established in previous
sessions and using them combined with keys negotiated in the next
session is a scalable way of establishing and updating pairwise
shared secrets.
In fact I'd say it's a very good idea.  One can use a distributed
public key (infrastructure fraught with peril and mismanagement)
for introductions, and thereafter communicate using a pairwise
shared secret key (locally managed) which is updated every time
you interact, providing increasing security against anyone who
hasn't monitored and retained *ALL* previous communications. In
order to get at your stash of shared secret keys Eve and Mallory
have to mount an attack on your particular individual machine,
which sort of defeats the "trawl everything by sabotaging vital
infrastructure at crucial points" model that they're trying to
One thing that weakens the threat model (so far) is that storage
is not yet so cheap that Eve can store *EVERYTHING*. If Eve has
to break all previous sessions before she can hand your current
key to Mallory, first her work factor is drastically increased,
second she has to have all those previous sessions stored, and
third, if Alice and Bob have ever managed even one secure exchange
or one exchange that's off the network she controls (say by local
bluetooth link)she fails. Fourth, even if she *can* store everything
and the trawl *has* picked up every session, she still has to guess
*which* of her squintillion stored encrypted sessions were part
of which stream of communications before she knows which ones
she has to break.
The cryptography mailing list

@_date: 2013-09-07 20:01:53
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Why prefer symmetric crypto over public key crypto? 
I think we can no longer rule out the possibility that some attacker
somewhere (it's easy to point a finger at the NSA but it could be
just as likely pointed at GCHQ or the IDF or Interpol) may have
secretly developed a functional quantum computer with a qbus wide
enough to handle key sizes in actual use.
And IIRC, pretty much every asymmetric ciphersuite (including all public-
key crypto) is vulnerable to some transformation of Shor's algorithm that
is in fact practical to implement on such a machine.
The cryptography mailing list

@_date: 2013-09-07 18:36:13
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Bruce Schneier has gotten seriously spooked 
Here is another interesting comment, on the same discussion.
Schneier states of discrete logs over ECC: "I no longer trust the constants.
I believe the NSA has manipulated them through their relationships with industry."
Is he referring to the "standard" set of ECC curves in use?  Is it possible
to select ECC curves specifically so that there's a backdoor in cryptography
based on those curves?
I know that hardly anybody using ECC bothers to find their own curve; they
tend to use the standard ones because finding their own involves counting all
the integral points and would be sort of compute expensive, in addition to
being involved and possibly error prone if there's a flaw in the implementation.
But are the standard ECC curves really secure? Schneier sounds like he's got
some innovative math in his next paper if he thinks he can show that they
The cryptography mailing list

@_date: 2013-09-20 19:14:22
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] RSA recommends against use of its own products. 
That said, it seems that most of these attacks on Pseudorandom
generators some of which are deliberately flawed, can be ameliorated
somewhat by using a known-good (if slow) Pseudorandom generator.
If we were to take the compromised products, rip out the PRNG's,
and replace them with Blum-Blum-Shub generators, we would have
products that work more slowly -- spending something like an
order of magnitude more time on the generation of Pseudorandom
bits -- but the security of those bits would be subject to an
actual mathematical proof that prediction of the next really is
at least equal in difficulty to a known-size factoring problem.
Factoring problems apparently aren't as hard as we used to think
but they *are* still pretty darn hard.
Slow or not, I think we do need to have at least one option
available in most PRNG-using systems which comes with a
mathematical proof that prediction is GUARANTEED to be hard.
Otherwise it's too easy for people and businesses to be caught
absolutely flatfooted and have no recourse when a flawed PRNG
is discovered or a trust issue requires them to do something
heroic in order to convince customers that the customers' data
can actually be safe.
We've been basing our notion of security on the idea that others
don't know something we don't know -- which is sort of nebulous
on its face and of course can never be provable. We can't really
change that until/unless we can say something definite about
P=NP, but we're a lot more sure that nobody else has anything
definite to say about P=NP than we are about most crypto
Do we know of anything faster than BBS that comes with a real
mathematical proof that prediction is at least as hard as
$SOME_KNOWN_HARD_PROBLEM ?
The cryptography mailing list

@_date: 2013-09-20 18:08:00
@_author: Ray Dillinger 
@_subject: [Cryptography] RSA recommends against use of its own products. 
More fuel for the fire...
RSA today declared its own BSAFE toolkit and all versions of its
Data Protection Manager insecure, recommending that all customers
immediately discontinue use of these products.
The issue is apparently the Random Number Generator that these
products use, the rather amusingly named "Dual Elliptic Curve
Deterministic Random Bit Generator." *1
And according to more of the Snowden Files released to (or by)
the New York Times last week, that pseudorandom generator is
deliberately flawed in order to allow it to be sod...  um,
excuse me, I should have said, to permit backdoor penetration.
RSA was truly between a rock and a hard place here as I see it.
With the deliberate weakness now made public, they took a terrific
blow to their business.  But failure to follow up with a
recommendation against their own products, no matter how much
additional financial pain that action entails, would have
destroyed all trust in their company and prospects for future
business.  As best I can tell, they have lost $Millions at least
due to the tampering of their products, and American security
and software companies taken as a whole are in the process of
losing $Billions to foreign competitors for the same reasons.
I wonder, would a class action suit seeking compensation for this
wholesale sabotage be within the jurisdiction of the FISA court?
*1 "Anyone who attempts to generate random numbers by
     deterministic means is, of course, living in a
     state of sin." -- John Von Neumann
The cryptography mailing list

@_date: 2013-10-15 07:57:06
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] "/dev/random is not robust" 
That was my takehome message as well.  But theirs is not the first
construction to address this, nor even really the best.  I recall
that Schneier's most recent PRNG recovers well from compromise too,
and I think it does so in a way that addresses the most common cases
of compromise faster than this one and the total compromise that
these authors are concerned about not much slower.
The cryptography mailing list

@_date: 2013-11-13 16:17:41
@_author: Bear 
@_subject: Re: [Cryptography] randomness +- entropy 
I think I'm not buying it.  Hard drive encryption doesn't need *randomness* early in the boot process; it needs *A KEY* early in the boot process.  A machine with an encrypted hard drive has to be able to read
and write sectors encrypted with an existing key before boot can proceed.  IMO that means it either halts during boot and the BIOS asks for someone to type in the passkey (the option I'd prefer on a "secure" machine) or it has the key stored unencrypted somewhere (obviously less secure but probably more manageable).  Randomness for keying material is needed when creating a *new* key, but does not help us get the existing key/s we need to read the boot sector.  Why would an encrypted drive really need a *new* key during bootup?  The cryptography mailing list

@_date: 2013-11-12 23:11:06
@_author: Bear 
@_subject: Re: [Cryptography] randomness +- entropy 
I'm inclined to agree.  IMO the kernel ought to simply terminate any
process that attempts to read /dev/random before the boot process is complete.   The cryptography mailing list

@_date: 2013-11-08 22:33:52
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] randomness +- entropy 
Is there any functionality now in the linux system that provides a
"pure" PRNG?  ie, if I know or have set the complete state, I can
then read from it an infinitely-long stream of bits which can be
repeated by initializing it with the same state (and which will
repeat after some finite but very long output stream) but which
is otherwise unpredictable?  Obviously this would be per-process;
sharing state would allow other processes to draw outputs and
therefore alter the sequence visible to the current process. This
used to be random(3). I believe this is still what random(3) does.
Is there any functionality now in the linux kernel that provides
a "pure" Random Number Generator?  IE, it would trap, or set an
'invalid' flag, or suspend the caller, or something, but won't!
ever! return a number when there is insufficient entropy to be
sure that that number is less than completely unpredictable?
This is what /dev/random was supposed to be, right?
Because, honestly, the 'hybrid' state of both of /dev/random and
time when /dev/random was supposed to deliver NOTHING but hard
randomness you could absolutely rely on for keying material, and
the latter but would rather return a (possibly somewhat)
predictable result than fail or slow down your process. Knowing
for sure which was what made designing robust and secure systems
straightforward, if sometimes hard.
The discussion here makes me want to craft something that gives
two simultaneous results; first, the "random number", and second,
a "confidence score" that indicates how certain I can be that the
"random number" is unpredictable.
The cryptography mailing list

@_date: 2014-01-18 03:04:15
@_author: Bear 
@_subject: Re: [Cryptography] Boing Boing pushing an RSA Conference boycott 
That is exactly the definition of a stream cipher.  Use a deterministic (Pseudo-random) number generator and seed to produce a stream of bits to encrypt with, and you have a stream cipher, which is NOT a one-time pad.  A one-time pad uses a fairly reliably *random* number generator, like this:  Unfortunately "real" random generators are difficult to implement in software, but thermal noise sensors, lava-lamp and aquarium cams, and
microphones pointed at freeways give pretty good results.  And yes, so do more amusing implementations like DiceOMatic. Actually I think that the *noise* produced by DiceOMatic, sampled a second at a time and sent through a hash function, would be a much higher-bandwidth source of randomness than the dice reading that the machine is actually built to do. Hmm.  It should not be too difficult to equip many servers in the same
room with $10 USB cameras, and have them all pointed at a cheap,
known-chaotic physical system like an aquarium with a bubbling filter,
moving aquarium toys, and swimming fish -- all from different angles -- running the resulting video, a half-second at a time, through a hash
function, and using the results for "real" random numbers.  And it amuses me that the sysadmin's job could legitimately include feeding
the fish.
The cryptography mailing list

@_date: 2014-01-17 00:54:00
@_author: Bear 
@_subject: Re: [Cryptography] Boing Boing pushing an RSA Conference boycott 
See, that is precisely the same problem that the NSA is up against. How can they know that terrorists *aren't* operating in a given theatre unless they know *EVERYTHING* that goes on in that theatre?
That is the rock, the demand on them, on which the waves of ethics and morality have broken.  The only way to 'prove' a negative proposition:  You have to know
absolutely everything about the universe in which it takes place.
And there is no way to do that.  There is no way to even approach
it other than by doing evil and betraying the trust of everyone. We'll never be able to 'prove' that something didn't happen unless we do the same kind of unethical crap and pervasive monitoring that is so repugnant.  So clearly we cannot make lack of evidence into a standard of trust.  We have to evaluate what is known and what isn't, and then reach and act on our conclusions even if we can't have direct evidence of malfeasance.  Or we have to descend into the kind of amoral
backstabbing behavior and pervasive monitoring that the NSA is now seen to have done.  The only alternative is sticking our fingers in our ears and going, "la la la" and pretending we don't have to think about it at all.
The cryptography mailing list

@_date: 2014-01-14 19:20:28
@_author: Bear 
@_subject: Re: [Cryptography] Boing Boing pushing an RSA Conference boycott 
I may be excessively cynical here, but when you wrote "etc" I think you might have been misspelling "RSA."
Why should we ask someone go to an RSA conference to get products to protect themselves from RSA itself?  Considering the conflicts of interest, that doesn't seem likely to be fruitful, does it?
While I think that a simple boycott is too broad, there has to be an alternative course of action.  The industry needs conferences (for sales) but would prefer not to have RSA's name plastered on them (for credibility).  The public needs conferences (for security
information and products) but would prefer not to be going to a conference organized by the very same people they have discovered that they need to secure their business against.  Both groups would be well-served by a parallel series of security
conferences, scheduled very deliberately to conflict with RSA's conferences and ideally not open to companies who are also presenting the same papers or products at the RSA conferences.  That would allow people to actually *do* the boycott of the RSA conferences without missing all possibility of making sales or all possibility of securing their infrastructure.  It would reduce the level of collateral damage and allow the very targeted kind of boycott that I think everyone could support. Can we get a University (one with a hell of a good math program, or who offer graduate degrees in cryptography) to organize one, or
if they won't organize it could we get them to host it?
The cryptography mailing list

@_date: 2014-01-14 18:36:00
@_author: Bear 
@_subject: Re: [Cryptography] Boing Boing pushing an RSA Conference boycott 
I tend to agree.  If RSA doesn't go down in flames over its utter failure, then people will learn from that fact that security is a joke industry.  That's a problem we already have badly enough with the failure after failure after failure revealed by the Snowdon
I don't think that there is any real hope of building a secure infrastructure for the world if the world learns by this example that an industry leading security company can completely fail in its primary mission without consequence.  That would be a vote of no confidence in the entire security industry, like an acknowledgement that there can never be security and there's no point in even trying. That said, I don't think a conference boycott is specific enough. A conference boycott hurts everyone at the conference.  And most of them have not been complicit (or merely incompetent, which is nearly as bad) in betrayal of the public. The cryptography mailing list

@_date: 2014-03-09 00:17:22
@_author: Bear 
@_subject: Re: [Cryptography] See??? Satoshi Nakamoto Smeared 
And let's not forget the possibility, that when he said "I no longer have anything to do with that and I can't talk about it," he might have been talking about his prior
work for the US gummint, and the reporter simply quoted him with an implication that he was talking about Bitcoin. "Can't talk about it" is some pretty specific language, I think.  It sounds to me like an NDA, not a project now being
carried on by others. I'd never have believed how much reporters misquote folks
or misapply the quotes they reproduce correctly, until I actually got some first-hand experience with it. The cryptography mailing list

@_date: 2014-06-24 23:12:56
@_author: Bear 
@_subject: Re: [Cryptography] What has Bitcoin achieved? 
TAPOS?   Transactions as Proof of Stake....
Okay. Cool name. Hmm, I wonder which of us thought of it first.  Could be they got it from my first article on Bitcointalk.  The attack you describe works if the attacker waits for a fork, then spends txout A for (say) 100 coins, in one branch of the fork and spends txout B for (say) 10000 coins in the other branch, which if accepted will 'unspend' his 100-coin transaction.    If the blocks are averaging substantially less than 10K coins in legitimate transactions per block, the 10K spend supporting
the fork is likely to get the fork accepted.  The 100-coin spend, unless attached to a block prior to the fork, cannot be replayed into the other fork, and so the coins are 'unspent'.  OTOH, the prospect of discounting large transactions, even a little bit, to attempt to correct that problem would open up new avenues of attack exploiting the "correction."
The alternative is to make sure that transactions turn the money over with high frequency, assuring very large transaction volume
per block.  One could structure proof-of-stake incentives so they
work hardest when turning the entire money supply over every 24 hours, and in that case the attacker would have to do something pretty amazing to overcome the volume.  I don't buy that as a solution;  Anything that bounds the weight of each block or constrains its weight to be close to the bound invites attacks via deliberate invocation of the regulatory mechanisms.  As far as I can see the only practical constraint on block volume for maximizing security with TaPoS is "as much as
practical". The cryptography mailing list

@_date: 2014-06-24 20:00:14
@_author: Bear 
@_subject: Re: [Cryptography] What has Bitcoin achieved? 
What you are describing is called a "proof-of-stake" system, as opposed to a "proof-of-work" system.  Several cryptocurrencies have implemented proof-of-stake, but, as yet, the versions of it that they have implemented are subject to attacks based on what has been called the "nothing-at-stake" problem.
I outline the problem and a partial solution below.
In order to distinguish a "correct" blockchain from an orphan (or attacking) blockchain, proof-of-work relies on the provable
expenditure of a finite resource - compute power.  The nothing-
at-stake problem arises when there is no ability to prove expenditure of a similarly finite resource to distinguish a correct from an orphan blockchain in a proof-of-stake Proof-of-stake as implemented in existing cryptocurrencies treats "coin days" as the finite resource whose expenditure distinguishes correct from attack blockchains.   The idea behind this is that when a txout is used in a transaction, the time since it was created is multiplied by the number of coins it represents to get a number of "coin days."  And the assumption is that whichever blockchain has created (or used up, depending on how you think of it) the greatest number of coin days is accepted as legitimate.
Nothing-at-stake arises because "coin days" are not a finite resource
in the way we need a resource to be finite in order to resist attacks.
When there is a fork, stake is duplicated on both sides of the fork. This leads to attacks based on the use of stake that the attacker has already spent in the other fork.  Also, the same unspent txout can generate more or fewer "coin days" depending on when it is spent, so an attacker can spend coins on both sides of a fork while choosing which side to generate more "coin days" in.  Also, under proof-of-stake, there is no need for a miner to forsake
one side of a fork in order to support another;  The miner has the same stake on both sides of the fork, and would be an idiot to stop
generating blocks supporting either side until he is absolutely certain which side which will be orphaned.  That makes the support  of miners effectively useless for deciding which side is to be
Finally, new unspent txouts are generated by transactions, including
coinbase transactions, on both sides of the fork, and expenditures of these txouts are 'noise' that an attacker (in an attack which gives
the attacker control of a higher proportion of the coinbase txouts on one side of a fork) can take advantage of to generate more coin days in his attack chain than in the legitimate chain. A partial solution to "nothing at stake" is to focus on a resource
which really is finite in the way we need it to be:  Uncontested expenditures of txouts that existed at the moment when the blockchains
When comparing two sides of a fork, instead of counting coin days, we should count the expenditure of txouts that existed at the moment of divergence.  But we should count only those transactions that do
not conflict with (do not use any of the same txouts as) transactions
on the other fork.  And we should count them strictly for the number
of coins spent, rather than varying it by block height as in counting "coin days". This means it is transactions, and not mining, that supports the security of the blockchain.   In order for transaction support to be finite (necessarily count for only one side of the fork) it is necessary for transactions to give a block hash from the blockchain
they support.  Any transaction that gives a pre-fork block hash can be replayed into either side of the fork, thus cancelling its support
for the other side.  Any transaction that gives a post-fork block hash can be counted as support only for the fork in which that block hash appears.  Thus, transactions that name more recent block
hashes (within the last 1-3 blocks) are more valuable for securing the chain than transactions that name later block hashes (within the last 4-7 blocks), and if compensated via proof-of-stake 'interest' payments for securing the chain, should be compensated more. Transactions giving block hashes older than 8 blocks are not terribly useful in securing the chain, and should not be accepted.  Because this solution is not subject to nothing-at-stake, at the very least attackers have to use real as opposed to already-
spent stake to attack it, and cannot support their attacks by
making transactions using the same coinbases they are trying to steal via their attacks.  But this is still a partial solution.  There is still a flaw in
that someone making a transaction can easily make it in both sides of a fork, therefore supporting neither.  Further, there is some motive for them to do so, unless such transactions can be demonstrated based on information to be recorded in the main branch and their proof-of-stake payment for securing the chain withheld.
I believe that this is possible, but complex and possibly unnecessary.
The cryptography mailing list

@_date: 2014-06-15 18:37:21
@_author: Bear 
@_subject: Re: [Cryptography] What has Bitcoin achieved? 
A.  You are ranting.  Most of the things you are reacting to are not things I said.  Please calm yourself and consider what has actually been said instead of jumping nine squares ahead to the worst of what you fear it might possibly mean.
B.  I am not talking about taking things people have and handing
them over to governments.  I am talking about a blockchain protocol
that allows people to voluntarily create and use subordinate claims on assets.  I expect that a lot of people will voluntarily
use this capability to create things that comply with existing
regulations in whatever jurisdictions they require - things with value, which could not otherwise exist.
C.  I was not talking about Bitcoin.  Bitcoin is controlled by the very community that I expect to most emphatically reject the idea of allowing identities, authentication, and the capacity to work within regulatory structures.  I think that they are fools in this rejection, and I think that they are limiting the prospects of Bitcoin to actually be adopted and used, but that is the behavior I expect of them.  The "Cryptocurrency anarchist" community will be displaced over the next few years by a "Cryptocurrency  plutocrat" community that better understands the opportunities to create value, so the foot-dragging is at most temporary.  Still,
it'll last far longer than I intend to wait, and if it goes on long enough, it will cause Bitcoin to fail because the plutocrats
will be adopting something else that better suits their purposes.
D. Therefore, I'll be looking at an altcoin implementation.  It is the market, and not any discussion between you and I, that will decide which is eventually dominant.  Perhaps both will be.
E. If an altcoin allowing authentication, identity, and working with regulatory structures is adopted by the plutocratic crew, then
the crypto anarchist crew will remain in control of Bitcoin - but will recede into economic insignificance.  If Bitcoin is adopted by the plutocrats instead, then Bitcoin will acquire these features
because the plutocrats need them and will get them built immediately
once they are in control - but the crypto anarchists will be displaced from control and will hate what Bitcoin has become.  Either way I expect that the crypto anarchists will be gnashing their teeth over their "loss" because what they want is, simply
speaking, destined to lose, one way or another.
A.  Comma splices are a sign of ranting.  Learn to control them.
B.  None of this follows from the idea of subordinate claims.  No
mechanism for keeping blockchain transactions secret has been introduced.  Not quite.  At that point we have a system that cuts a whole ecology
of rent seekers and parasites out of the money transfer business, and a way to do international and intranational business more efficiently.  The cryptography mailing list

@_date: 2014-06-14 17:50:01
@_author: Bear 
@_subject: Re: [Cryptography] What has Bitcoin achieved? 
And every part of the banking system arose in response to needs that have not gone away.
Maybe.  But even if that is the purpose of Bitcoin, it need not be the purpose of every implementation of a blockchain protocol.  Nor will it continue to be the purpose of Bitcoin itself if Bitcoin ever spreads beyond the crypto anarchist contingent.  Indeed, well over 90% of the trade that might ever be done in cryptocurrencies will not be done if they remain unregulatable.
So let the crypto anarchists continue to use Bitcoin as it is.  Serving the people at large has a different set of requirements
because most people want the security of operating within the framework of laws and authorities that provides the context of their societies. I know that it will not be welcomed by anarchists.  But that's a tiny, tiny bunch of people;  Most who are doing serious trade want
to be trading in assets that police can trace and courts can recover, because for most purposes and most people that's safer.  A blockchain "Open ledger" guarantees that the powers we give our regulatory agencies cannot be exercised secretly, and that if exercised in violation of law or due process, no one will be able to pretend otherwise.
The cryptography mailing list

@_date: 2014-06-07 01:35:42
@_author: Bear 
@_subject: Re: [Cryptography] What has Bitcoin achieved? 
True.  Cost of executing an "undo" - zero.  Cost of getting peers to agree on who can execute an "undo" and for what reasons - prohibitive. I've been working on a blockchain protocol extension that would allow "undo's" in some limited circumstances and could possibly exist in cooperation with regulations and laws and courts.  It's strictly opt-in, but I figure the "crypto anarchist" contingent will hate it anyway - because it becoming possible means some people will start refusing to do business with them unless they "voluntarily" abandon some privacy.
The first piece of the puzzle is the "subordinate claim" on blockchain assets.  An entity owning some asset can issue a subordinate claim on that asset to some other entity rather than transferring ownership of that asset to that other entity.  A subordinate claim in the asset can be used just like its superior claim could be used (bought, sold, transferred, etc), except that the holder of the superior claim has the ability to revoke either the subordinate or superior claim at any time.
The subordinate claim is revoked at any moment if the superior
claim is transferred to a new address. The superior claim is revoked if it is transferred to the current address holding
the subordinate claim. The second idea is that of a persistent identity, which really is just a species of PKI published to the blockchain. An entity could publish a key asserting its identity and/or identifying itself in transactions, so that subsequently people could use the blockchain to see how much and exactly what business that identity has done and how long it's been around.  Yes, it's an abandonment of privacy.  It is also strictly voluntary. Nothing compels anyone to link a particular transaction to their persistent identity, nor forbids them from having more than one, etc.   The reason why some entities might choose do this is to firmly establish their identity and trustworthiness, or at least their collateral, both as issuers and recipients of subordinate claims that might be revoked.  The idea is that regulated assets could have sovereign claims (that is, the top-level claim that is not subordinate to anyone or anything else) held by the regulatory agency, and then ordinary trade in those assets would be trading the subordinate claims.  Thus, someone with a publicly traded stock would hold his claim subordinate to the agency with authority on that stock, which would be someone like the SEC in the US, or equivalent national authority elsewhere.  If it's a privately held stock, the stockholder would hold a claim subordinate to the company's claim, which would in turn be subordinate to the sovereign claim held by the SEC (or whatever regulatory authority has jurisdiction
in that particular asset). That gives the regulatory agency the option to 'freeze trading' in a particular asset, or even claim it pursuant to court action, etc, without the cooperation of the holder or even after the death of the holder if necessary.  It gives the courts a way to recover assets that have been burgled or embezzled, or the assets of someone who died intestate or who has failed to pay fines, child support, or income taxes, etc -- provided those assets were held subordinate to court control in the first place.  It is still strictly opt-in, in that nothing could compel you
to do anything you don't want to do with a _sovereign_ claim, and if you don't *want* any subordinate claims, you don't have to buy any, and if you don't *want* to issue any subordinate claims under any circumstances, you don't have to issue any, and if you don't *want* to establish a persistent identity that
would doubtless quickly be associated with your legal identity
nothing would compel you to, and you'd always know exactly which persistent entities have the superior claims before you acquired a subordinate claim....  but I still figure the crypto
anarchists will hate it. The cryptography mailing list

@_date: 2014-06-03 16:55:51
@_author: Bear 
@_subject: Re: [Cryptography] What has Bitcoin achieved? 
One issue that is driving Bitcoin is the excruciatingly slow uptake of new technology into legitimate financial mechanisms. Finance in general is littered with obsolete crap that doesn't work all that well, supported by entire ecologies of rent-seekers
and fee-eaters luxuriating in a protected-species status thanks to very well-intentioned conservative laws intended to minimize fraud and theft which have the effect of making any way other than the ways now known to be obsolete and inefficient compared to new technology, illegal.  The experience of technologists is that more effective ways of solving financial problems, often with solutions that close significant security problems, are usually not permitted to succeed.  Any improvement requires the approval of legions of people whose job security would be threatened by the improvement. Even if the approval can be gained, it then requires literally hundreds of millions of dollars in licensing and permissions and infrastructure to conform with many of the regulatory processes, so startups are frozen-out.  Bitcoin, unlike most other fintech offerings, is financial technology that can exist independently of that regulatory structure.  You don't need anyone's permission to start using Bitcoin, and nobody else has to get regulatory approval to open a bank or become a credit card issuer etc before you can.  Entire legions of rent-seekers and fee-eaters are cut from the process by using cryptographic/mathematical/physics-based rather than institutional/legal/trust-based security. And if the failure of financial institutions to take up new technology has been driving bitcoin's adoption, the major factor
holding it back has been the appalling failure of institutional security wherever people dealing in bitcoins have been allowed or required to do so in ways that do not take advantage of the cryptographic security features of bitcoin. The major pain points have all occurred at the interfaces, such as brokerages and exchanges, where mathematical security and institutional security ought to be working together and are not.  What this says to me is that the more business we can find a way to do cryptographically, without ever touching those interfaces, the better off we will be.  How do you achieve the tech result, where the threat model includes Eve, Sybil, and Trent working together?  Heck, I'll give you a freebie and say we don't need to worry about Eve because we're not going to get financial privacy anyway.  But you still have to deal with Sybil and Trent.  If you can deal with Eve too, that's pure win.  All the good solutions to byzantine-generals I've seen require communication that scales with the square of the number of participants.  I've been trying to think of a way
to leverage that into something practical using overlapping cells, but I haven't found one yet.
The cryptography mailing list

@_date: 2014-08-04 17:19:23
@_author: Bear 
@_subject: Re: [Cryptography] You can't trust any of your hardware 
This will not get fixed until some virus or other using it to steal something important becomes widespread.  That's what I really hate about the situation; in order for it to be worth anyone's time to fix it, someone first has to use it to perpetrate a major ripoff.  Which means, if the black hats don't pick it up and run with it and use it to actually hurt people, nobody ever gets a secure machine.
Meanwhile, can anybody come up with the firmware for an update-
blocking USB hub?  I have a feeling that when somebody finally gets around to wanting one, they'll want it yesterday.
The cryptography mailing list

@_date: 2014-10-21 17:02:33
@_author: Bear 
@_subject: Re: [Cryptography] Best internet crypto clock 
IIRC a lot has been done to verify video and audio as having come from a certain moment in time or general location based on recovering
the precise 'drift' of the omnipresent 60-cycle (or 50-cycle if you're Australian) hum of the surrounding electrical system.  While it's fairly precise, it's not exact, and over very widespread areas the exact frequency and interference patterns recovered from a video or audio record have been used to determine exactly when (and to some extent where) the record was made.  Relevant law enforcement and Intel agencies are, yes, known to monitor and record the variances specifically for purposes of dating recordings
that later may become evidence. The cryptography mailing list

@_date: 2014-10-08 15:57:27
@_author: Bear 
@_subject: Re: [Cryptography] Best Internet crypto clock ? 
I have to point out here that there is absolutely nothing in the Bitcoin
protocol that prevents servers who solve a block from misreporting the time.
In fact, it has been a strategy in the past for parallelizing the
hashing. When the portion of the nonce that people could adjust seeking a winning hash was exceeded by hardware capacity, the time field was incremented even though the mentioned time had not yet arrived, and the search started over.  Because that was faster than rearranging the transactions to form a different base for hashing, I guess.  Anyway, the time reported in bitcoin blocks is approximate, and historically not even monotonically increasing.  It is testimony
that the Bitcoin network accepted the server's claim of what time it was, so probably, usually, within ten minutes of  the real time.  But it does not establish any precise notion of time. The cryptography mailing list

@_date: 2014-11-05 03:25:17
@_author: Bear 
@_subject: Re: [Cryptography] $750k Fine for exporting crypto 
Y'know what?  If they popped up for no reason other than "they broke the law" -- even when I think that particular law is stupid -- I'd
really prefer that situation to one where people get picked out for enforcement based on political connections or degree of covert
cooperation. I think the US is drifting dangerously far from the ideal of a rule of law.  You know, where the law is the same for everybody, no matter
how much you contributed to somebody's political campaign, no matter
whether you're sitting in an expensive government office, no matter how much money you make, no matter whether you're cooperating in
attempts to subvert the law against other citizens and no matter whether you're saying something unpopular?  Increasingly, we're behaving more like China, where they have a rule BY law instead; where the law is a tool for the powerful corrupt to
extract rents, to extort perks, to take revenge, to enforce covert or personal policies by selectively enforcing overt public law, etc. I know there's always some of this kind of slime under the corners when you have too close a look at any government, and always has been.  But really, a rule of law IS achievable, and when it's working it means that shit is the exception rather than the norm, and that
abusing the law that way is a crime which entails a genuine risk of getting caught, being publicly prosecuted, and going to the same jail where you've been putting your victims.
A stupid law can be oppressive, which is bad enough, but corruption is a pure poison that can suck the life out of an entire country, breeds domestic terrorists like flies, and generally drives us slowly down the road toward bloody revolution.  Stupid laws make me roll my eyes, file amicus briefs, write congresspeople, etc... Today it made me vote for several minor-party candidates where incumbents who favor stupid policies had no major-party
opposition. But corruption is altogether darker and the slowly rising tide we've been on for the last couple of decades makes me fear for my long-term safety.
I say enforce it uniformly or repeal it.  Every law that isn't uniformly and promptly enforced, all the time, contributes to public corruption because selective enforcement means someone is using it for blackmail or extortion -- and probably thinks "that's what it's for" meaning blackmail and extortion have become the norm. So yes, the whole damn thing from prostitution to labor laws to export restrictions to monopoly busters.  If you're not going to enforce it for everybody, all the time, then get rid of it so you don't have the temptation to become corrupt as you use it for blackmail, extortion, revenge, or for the harassment of dissenters.
The cryptography mailing list

@_date: 2014-11-26 18:05:00
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Blogpost: CITAS, a new FBI security program proposal 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="TE1qGvHwdCGe5hqWlAsDLWRw78HxwiMlx"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2014-11-25 16:31:01
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Blogpost: CITAS, a new FBI security program proposal 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="kCSLD97hpCLIVMfF0uiEFL9MSuQvg69ex"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2014-11-25 04:16:44
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Blogpost: CITAS, a new FBI security program proposal 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="GGhGucrUeONufDdXiOUC0qUjgRrps0339"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2014-11-25 01:24:47
@_author: Ray Dillinger 
@_subject: [Cryptography] Blogpost: CITAS, a new FBI security program proposal 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="LXVsB0a9Sm4X7t0u4sWQBogJlPJNJ6XRk"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2014-11-21 02:18:24
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] FW: IAB Statement on Internet  Confidentiality 
At the very least such a proposal would force us to confront the usability
and key management issues of the software and at least put us in a
position to become ware of its security interactions with various mail
I'm agnostic on the matter though; I've never really felt the need to
encrypt, or sign, on this very public forum.
The 'Outlanders' list and similar venues are a different matter entirely,
but they are not open-subscription, the encryption they use is not
public-key, and obviously they do not have the usability and security
issues of a PKI to worry about.
The cryptography mailing list

@_date: 2015-02-22 18:24:35
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Equation Group Multiple Malware Program, NSA Implicated 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="aFWSghelThgvEf5iRSFFLl1OBvbD8Fu14"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2015-02-18 22:35:45
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Equation Group Multiple Malware Program, NSA Implicated 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="es4xlOHJGFaQxCfGtg9Q9wvMu3e3KE7HB"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2015-03-26 04:37:56
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] "Most Americans Don't Mind Being on Candid Camera" 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="G9lgQAoxRk6Rh9737KK6Q8RWXqhUHDgwg"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2015-03-25 04:13:15
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] "Most Americans Don't Mind Being on Candid Camera" 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="crpUVmVIqB4hbiU0vob9cjb4djD4M1BnI"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2015-03-25 04:02:52
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] "Most Americans Don't Mind Being on Candid Camera" 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="TvKvFfQsxG57W5AB1K305broO1tCC9Bsb"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2015-07-14 16:27:19
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Super-computer project wanted 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="XUUJcNPnP5xEMCB9DBd4kswGLgeNA31Lb"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2015-12-19 03:02:07
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] What should I put in notifications to NSA? 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="erHsaBaoL2vjHscOJhwKX0iR9u348vJHR"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2015-12-29 18:34:30
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Understanding state can be important. 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="JGmXIcUohG5eFGIvjE1rGono2SFBSsuRT"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2015-12-28 19:45:31
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Understanding state can be important. 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="6v4q9X6sv3E7MgAhP7E5IErxFa4m5RARm"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2016-01-17 19:25:29
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Verisimilitrust 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="H72qnmqmXJEjSnl4COQmtclvINgEx4IAR"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2016-01-13 23:32:23
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Verisimilitrust 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="XUsmhkFbgRloLma2HufqAMIdmmMBISddH"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2016-01-09 20:52:11
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Verisimilitrust 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="IeH4vJu1B0Ais008cPr5uaw6l6r7mIhnj"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2016-02-11 20:58:26
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Proof that the NSA does not have a quantum computer capable of attacking public k 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="pIlBrpJnwJ10oAhw3dVSFVHSsbB88FCML"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2016-03-02 21:53:35
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] LibreSSL unaffected by DROWN 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="xq3V3LXTNrfR76UPXjSLx8W22bx7PJJOC"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 <20160302202037.GA10029

@_date: 2016-03-08 02:08:29
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] EFF amicus brief in support of Apple 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="KvmUhTdkpOnhIgCs1HonUGl4D5SwuADeb"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 <20160304220134.81297.qmail
 <20160306103307.5fdd9f98
 <56DC5D0E.3070102
 <20160306140308.1fd64444

@_date: 2016-03-06 16:38:38
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] EFF amicus brief in support of Apple 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="i6LmArApGJgLBbOqcVMwT49H2rloAMmei"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 <20160304220134.81297.qmail
 <20160306103307.5fdd9f98

@_date: 2016-03-16 20:02:47
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Lavabit's and Snowden's Solos 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="kfmbNOVSJt2QTtKBeIGPQQ2Nia5JfPmjl"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2016-03-13 01:23:40
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Govt Can't Let Smartphones Be 'Black Boxes, ' Obama Say 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="J1lwWEC1rVNggumafU02HQqABk1ImFgou"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
References:

@_date: 2016-03-27 02:15:06
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] More Bad Govt Shit To Fight (Burner Verizon FBI) 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="84EW52SQT2XiuTeh1hN6sXmoBJlRR8rhV"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2016-04-27 23:02:35
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Darpa wants a secure messaging app based on blockchains 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="2sbOJ9tgWSebQxtB28FJU97bXwtVaXLag"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
References:  <7BB5F42B-1659-487D-98C6-20EF4C3031E7
 <345AAD02-EA3F-4AA6-822C-18D4297DDE55

@_date: 2016-05-02 17:08:21
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] USB 3.0 authentication: market power and DRM? 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="CO9gqwVhoQjrgs8dR6oiw7WoxM4V0SJS7"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 <201604150721.u3F7LNfc007004
 <201605010713.u417DLVH007291 <572669DA.5060207
 <0BE930DF-1F0E-4609-90DB-5D8B5957D5BF

@_date: 2016-05-01 20:40:58
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] USB 3.0 authentication: market power and DRM? 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="d4TLD0XK5hwlSPqRJ0bVwda5bHWpxvNv7"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 <201604150721.u3F7LNfc007004
 <201605010713.u417DLVH007291

@_date: 2016-06-23 23:29:08
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Digital currencies 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="t4LfC019Qu34vru3qUi09WQHxKOql5mCi"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)

@_date: 2016-08-30 22:14:56
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] N. Korean radio broadcasts string of random numbers 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="cCCt5BqguDj2PK1Tt61w2iL7CJ5q0mjeb"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
References:

@_date: 2016-11-09 18:54:57
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] "we need to protect [our dox] by at least encrypting them" 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="weVlsJBBpTDSb9imTktHaL0hb2LAU12KU"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"
References:  <5a999e62-1cdb-2349-c212-cc44a552e2b9

@_date: 2016-11-08 19:53:43
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] "we need to protect [our dox] by at least encrypting them" 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="JNNqjs0mFf9LVMsBok8rHW5MQjjapQCbX"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"
References:  <5a999e62-1cdb-2349-c212-cc44a552e2b9

@_date: 2016-12-17 00:16:57
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Photojournalists & filmmakers want cameras to be encrypted 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="KKKf9cAJumJIiVjHG7mOF1xfSkAwG0Swg"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"
References:  <2ff45c9f-467f-0a2d-14d0-1685ade48f2e
 <7e758edb-7780-9910-a6d8-0793dca1574e

@_date: 2016-12-16 02:43:36
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Photojournalists & filmmakers want cameras to be encrypted 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="OQDgLjHDAxSPLAHAesPw04E1vlhh8lTQv"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"
References:  <2ff45c9f-467f-0a2d-14d0-1685ade48f2e

@_date: 2017-01-15 18:31:38
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Cryptocurrency Exchange without a trusted third party 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="kcn6mOUNXGlXqSiQpAJwa18d49EWpGSM5"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"
References: <20170114132532.GH13306

@_date: 2017-02-27 19:36:19
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Schneier's Internet Security Agency - bad idea because we don't know what it will 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="qxINfaxeD06jfjLG0fwWQOFHMvhuX5TRc"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"
References: <5a636025-7684-1a71-a4b7-0a32148b4312
 <20170225225233.GA16921
 <0496dbbf-7d6a-7456-3525-edcffe520c58
 <20170226233139.GA26437

@_date: 2017-02-28 22:27:48
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] jammers, nor not 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="StVdQjk6fEHlbxmjsi8wubf0DVdTnXbqx"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"
 <20170225225233.GA16921
 <0496dbbf-7d6a-7456-3525-edcffe520c58
 <20170226233139.GA26437
 <0d09bfa8-e930-52e9-0635-81e9cc1fe440

@_date: 2017-02-28 22:13:46
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] jammers, nor not 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="gLjdB19H7IDBJWep2BHrQPoth4Xox1dTE"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"
 <20170225225233.GA16921
 <0496dbbf-7d6a-7456-3525-edcffe520c58
 <20170226233139.GA26437
 <0d09bfa8-e930-52e9-0635-81e9cc1fe440
 <9420C391-A7DC-403A-BAAA-FDE03305A5ED
 <6E4F85C1-87E2-4B6F-8B5E-8B8A37DBFA2F

@_date: 2017-04-02 18:37:37
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Regulations of Tempest protections of buildings 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="PNCcP0HPeMdJLqT0A20in5TR8StspmAi9"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"

@_date: 2017-06-21 06:29:09
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] [ANNOUNCE] HashCash Digital Cash 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="KKoMP6VsobC6AU3WU6Vpaorrq2To5DWt1"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"

@_date: 2017-07-03 19:17:21
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Satoshi's Trump Card 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="rMbfwj3CF4XpT01x7e4lU7VnhwWJ3V75e"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"
 <9a53095b-9e7b-784c-a43b-535cb4bf49cf

@_date: 2017-07-02 19:01:45
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Satoshi's Trump Card 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="WHgIrHOxeMUR6jSQdmJ1MSw3Hxj6TWVb1"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"

@_date: 2017-09-04 07:47:25
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] early archives of cypherpunks? 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="wSPXvSqMJxqUNuDqH0Tx3iKRjl1qEWfL5"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"
 <796f94ba-2c02-f4ef-7a25-5a3456f3adb9
Content-Language: en-US

@_date: 2017-09-03 18:10:53
@_author: Ray Dillinger 
@_subject: [Cryptography] early archives of cypherpunks? 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="4Ugp4hMTLNM4q6IgX78bR4Wi6Q0pToUF5"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"
 Crypto-practicum , cypherpunks
Content-Language: en-US

@_date: 2017-12-04 22:17:52
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Cryptocurrency: CME Approved, Coin Paychecks, FED, OpenBazaar ZEC BCH 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="16TA5AMcG41KRmjfidcC9jA9L0NJdgjVN"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"
References:  <201712042016.vB4KG3K7003152
Content-Language: en-US

@_date: 2017-12-02 01:29:46
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Cryptocurrency: CME Approved, Coin Paychecks, FED, OpenBazaar ZEC BCH 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="WQRwkBUa2RvPsaDxrmpjPQL39d4RMXRx2"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"
References: Content-Language: en-US

@_date: 2018-01-26 00:10:50
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Perth Mint to back crypto-currency with gold 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="QE4stAS4GNDvfbcuFZspRGcAGk09zonZo"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"
 <72c360da-4245-3e91-366d-423bee71fa42
Content-Language: en-US

@_date: 2018-02-12 20:16:15
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Useless side channels 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="CLJIfrqikZMVYtinNfXYPXl45t001Zqh6"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"
 <20180212084933.59fb04f5
 <79d79449351c6460d29f2969c9b60441
Content-Language: en-US

@_date: 2018-08-09 19:33:46
@_author: Ray Dillinger 
@_subject: Re: [Cryptography] Krugman blockchain currency skepticism 
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protocol="application/pgp-signature";
 boundary="8El3i05jBAMdpUHZIT9IG0AqmUQZJ3qTS"
This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
 protected-headers="v1"
 <0d621af9-81a4-b423-2df9-217c7df67ea9
 <737f9c3cc57bad671afe8b8d4e05912ebd04067e.camel
 <7139a19b-332e-199c-24a8-e1d436ca7a36
Content-Language: en-US
