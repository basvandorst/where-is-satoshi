
@_date: 2010-12-05 19:57:58
@_author: James Hess 
@_subject: Re: U.S. officials deny technical takedown of WikiLeaks 
If you mean shooting people in order to protest a law, that
proposition is obscene,
and attempting to dehumanize flesh and blood, while hiding the nature
of the act through
name-calling does not make the act more civilized, sane,   or less
deserving of rebuke.
If "pig"  is defined as  person(s) conducting network abuse, violating
the AUP of
services they use in manners, such as sending spam,  transmitting
illegally obtained documents,  or posting  large numbers of off-topic political
rants to a technical discussion listserv contrary to its AUP.
And by "shoot" you mean turning off their network service, being used in
the abusive manner contrary to the terms agreed or as required by the law.
Then this is done every day, and I would applaud those such as Amazon
who have done a service to the network community by doing so.

@_date: 2010-12-08 06:21:11
@_author: James Hess 
@_subject: Re: Over a decade of DDOS--any progress yet? 
Very little,  no, and no.
Not counting occasional application bugs that are quickly fixed.
Even TCP weaknesses that can facilitate attack are still present in
the protocol.
New vectors and variations of those old vectors emerged since the 1990s.
So there is an increase in the number of attack vectors to be
concerned about, not a reduction.
SYN and Smurf are Swords and spears after someone came up with atomic weaponry.
The atomic weaponry named "bot net". Which is why there is less
concern about the former
types of  single-real-origin-spoofed-source attacks.
Botnet-based DDoS is just "Smurf"  where amplification nodes are
obtained by system compromise,
instead of router misconfiguration,  and a minor variation on the
theme where the chain
reaction is not started by sending spoofed ICMP ECHOs.
Since 2005 there are new beasts such as "Slowloris" and "DNS Reflection".
DNS Reflection attacks are a more direct successor to smurf;  true
smurf broadcast
amplification points are rare today,  diminishing returns for the
attacker, trying to find
the 5 or 6 misconfigured gateways out there, but that doesn't   diminish
the vector of spoofed  small request large response attacks.
Open DNS servers are everywhere.
SYN attacks traditionally come from a small number of sources and rely
on spoofing
to attack limitations on available number of connection slots for success.
New vectors that became most well-known in the late 90s utilize
botnets, and an attacker
can make full connections therefore requiring zero spoofing, negating
the benefit of SYN cookies.
In other words, SYN floods got supplanted by TCP_Connect  floods.

@_date: 2010-12-08 06:21:11
@_author: James Hess 
@_subject: Re: Over a decade of DDOS--any progress yet? 
Very little,  no, and no.
Not counting occasional application bugs that are quickly fixed.
Even TCP weaknesses that can facilitate attack are still present in
the protocol.
New vectors and variations of those old vectors emerged since the 1990s.
So there is an increase in the number of attack vectors to be
concerned about, not a reduction.
SYN and Smurf are Swords and spears after someone came up with atomic weaponry.
The atomic weaponry named "bot net". Which is why there is less
concern about the former
types of  single-real-origin-spoofed-source attacks.
Botnet-based DDoS is just "Smurf"  where amplification nodes are
obtained by system compromise,
instead of router misconfiguration,  and a minor variation on the
theme where the chain
reaction is not started by sending spoofed ICMP ECHOs.
Since 2005 there are new beasts such as "Slowloris" and "DNS Reflection".
DNS Reflection attacks are a more direct successor to smurf;  true
smurf broadcast
amplification points are rare today,  diminishing returns for the
attacker, trying to find
the 5 or 6 misconfigured gateways out there, but that doesn't   diminish
the vector of spoofed  small request large response attacks.
Open DNS servers are everywhere.
SYN attacks traditionally come from a small number of sources and rely
on spoofing
to attack limitations on available number of connection slots for success.
New vectors that became most well-known in the late 90s utilize
botnets, and an attacker
can make full connections therefore requiring zero spoofing, negating
the benefit of SYN cookies.
In other words, SYN floods got supplanted by TCP_Connect  floods.

@_date: 2012-06-08 12:09:53
@_author: Jimmy Hess 
@_subject: Re: LinkedIn password database compromised 
The PKI infrastructure and  authority validation components are not
required. Even if they were -- anyone  can setup a PKI infrastructure,
 the problem is trust.
Self-signed certificates are just fine for this application.   The
authentication credential stored on the server for the user, can
simply be the public key of the user's certificate, and the
certificate hash.
There's no need for the TLS server to verify the client cert  is
issued by a recognized authority;   although it would be nice for
there to be Free X.509 certificate authorities to issue a signed TLS
cert for E-MAIL address authentication.
This would allow websites to accept user signup without a need to spam
the user with additional  "Click this link here to prove that this is
actually your real e-mail address".
It should ideally be integrated with the web browser.    The user
should be prompted to create their certificate  by their web browser,
and given the option to  self-sign an "Anonymous" certificate;  use a
Free certificate authority,  that will  list and validate their e-mail
Or an alternate CA that will validate their e-mail address and
optionally additional fields, such as a real name.     Only fields
listed on a certificate need to be verified.
If a site doesn't trust the authority to issue the cert, the
connection proceeds,  the site just asks the user to prove  "Yes, that
really is their e-mail address"
SSH is vulnerable to MITM on the first connection to a new host, you
are prompted to save a host key,  but noone really verifies this.
After  you've saved a host key,  if the host has to change keys for
legitimate reasons, such as previous host key compromised,   the SSH
client refuses to connect,  and the user has to manually remove
entries from their known_hosts file.
Username, password  is more user-friendly than the SSH behavior, unfortunately.
Which means username/password would still be used in preference.
Most options that exists require setting up your own server or using a
third party.
No... that's not  convenient or user-friendly enough.
"Public what?"
There must be a browser integration where the public key is
automatically submitted (with the user's permission).
There are too many users who don't know how to use "copy and paste".
There are too many users not willing to dig into their browser's
settings to lookup their public key.

@_date: 2012-06-07 03:34:39
@_author: Jimmy Hess 
@_subject: Re: LinkedIn password database compromised 
One local password is an excellent idea of course.
"Remote servers directly handling user created credentials"   should be appended
to the list of the worst ideas in computer security.
Which digital id architecture should web sites implement, and what's
going to make them  all agree on one SSO system   and move from the
current state to one of the possible solutions though?  :)
        A TLS + Client-Side X.509 Certificate  for every user.
         BrowserID
         OpenID
         Active Directory Federation Services
         OASIS SAML  / STS + WS-Trust
         Shibboleth SSO
         CoSign SSO
         Facebook Connect
         Novell Access Manager
         Windows Live ID
[insert a thousand of the other  slightly more obscure Multi-website
Single-Login systems]

@_date: 2012-11-27 01:33:02
@_author: Jimmy Hess 
@_subject: Re: Adding GPS location to IPv6 header 
Just about every new technology, IP itself included has privacy concerns,
related to it;  which is really just a fancy new name for security
concerns, regarding WHO is doing what things on the network.   That doesn't
mean you blacklist those technologies....   In fact, in some cases
_identification_ of network nodes is a very good thing.
I would like very much for spammers to be identifiable,  even at the
cost of some so-called "privacy"  (not that embedding IP location data
helps with that)....
Heck,  HTTPS has privacy concerns,  because it requires a certificate,
personal details of the server to operate.    I suppose it would be
rather interesting if the certificate contained GPS details as well,
if   end hosts' IP stacks were required to verify the GPS data is
either accurate or not present,   and SSL clients were expected to
validate that the details in the IP packets matched,  and if a list of
GPS positions was declared as a critical X509 extension.
Then a third-party hosting provider would not be able to be used to
spoof a HTTPS site (without the intruder gaining root access,  in
order to spoof IP packets).
The existence of  privacy concerns,  does not mean you hesitate to implement a
protocol in any way, shape or form.
Privacy concerns,mean you as a user of that technology, pull out your handy
dandy risk calculator, and weight the details carefully consider,
what the probability
and impact of the various risks actually are  -- what bad  things can actually
happen, if the detail X is exposed, and what (if any)  mitigations you
choose for
your  particular scenario.
Which will for end users typically involve setting a local policy such as:
  o  Don't turn on the "Populate Packet headers with Location data"
  o Don't stamp packets with location data, except  to trusted hosts,
    when stamped packets are sent with headers encrypted over VPN in tunnel mode
   o Introduce sufficient error, that the GPS data does not
significantly compromise location

@_date: 2012-11-26 00:14:49
@_author: Jimmy Hess 
@_subject: Re: Adding GPS location to IPv6 header 
Nevertheless, there are some applications in which it might have some merit.
If  there is even one such application, then it is sensible to have the required
bits set aside, so there can be an extension in the limited cases
where it is required.
An extension header at Layer 3 containing this information should be just fine.
Or rather,  an extension, allowing a reference to a lookup service for
that information
to be placed in IP headers,  for network management should be just fine.
The actual underlying plaintext PII best be protected with IPsec and
additional measures, but that is the network implementor's
responsibility.     Not all Layer 3 headers have to influence path
There _ARE_  headers for strictly network management purposes.
Examples would include the  IP TOS header;   Route record  extensions;
Hop limit;   Timestamp.
The IP TOS header identifies a value, which can be used to prioritize
some packets;
similarly,  a network operator might have a need to  prioritize
packets with a certain
geographical origin at L3,  or   grant    certain  throughput and
performance characteristics
based on source region,   to ensure a degree of fairness with their application.
They generally will not.  The mechanism of operation of an anycasted
service is there are a small number of unicast addresses, with routes
announced from various different points.
If each region had its own unicast IP, it would just be a normal
DNS-balanced service.
Therefore, the same unicast IP address may be used from multiple regions,
for example,   the DNS servers  in different regions may have identical
IP addresses.
For network management purposes, on the End user side, it would be useful
in some cases, for  the  IP header  of  DNS and HTTP response packets,
to identify which "node"  or site is responding;
even if this cannot be indicated in the IP address fields.
It may help identify, if an issue accessing an any casted service is related to
instability of   which  route is preferred  (E.g.  thrashing of the
end user's site selection);
if there is an extension option available for  Recording or Tagging
packets with a source ID,
a situation, in which the  Record Route  IP  extension is not a viable option.

@_date: 2012-11-25 06:28:54
@_author: Jimmy Hess 
@_subject: Re: Adding GPS location to IPv6 header 
IP is the logical place for this kind of header,  as this information
is node dependent, not application dependent.
It would be useful for identifying the location of a server, when an
IP address does not.
For example, in the case of an  anycasted service,   the  source IP
address does not uniquely identify where the source came from.
The requirement that the embedded location data,  be GPS data,
however:  would seem to be overly restrictive;    a simple   8-bit
"Site number"  identifier  could be all the location data needed  for
diagnostic purposes.
"Privacy issues"  are policy considerations,  that have no place in
the determination of protocol header formats;  providers of a service
will generate  location header extensions, if they are useful to them,
 if they are not, then they would choose to not support the extension.
If a provider wants to attempt to implement rights management using
header fields, then more power to  them....   I never heard of a
digital rights management provider  implementing an open
standards-based approach,   and it would be a positive development  if
they did,  but more likely than not, they will ignore header extension
options,   and implement  rights management identification   inside
proprietary application layer payloads   that contain the actual
protected content,
instead of IP packet headers,  which are easily stripped off, and
replaced with new IP headers  containing the same packet data payload.

@_date: 2012-11-30 21:46:57
@_author: Jimmy Hess 
@_subject: Re: William was raided for running a Tor exit node. Please help if you can. 
As you know, there may always be some uncertainty about which computer
was using a certain IP address at a certain time --  the computer
assigned that address might have been off,  with a   deviant
individual spoofing MAC address and IP address of a certain computer,
using different equipment still attached to the same physical LAN.
Their warrant authors will probably not say "all computers";  they
will more likely say something like all digital storage media,  and
equipment required for access.
Which includes all hard drives, SSDs,  CF cards, diskettes, CDRs,  and
all the computing equipment they are installed in  (keyboard, monitor,
mouse, etc)  normally used to access the media.
If they had a qualified technician,  they probably wouldn't be raiding
a TOR exit node in the first place;   they would have investigated the
matter  more thoroughly, and saved precious time.

@_date: 2012-12-18 07:32:56
@_author: Jimmy Hess 
@_subject: Re: William was raided for running a Tor exit node. Please help if you can. 
I'm not so sure about that.   It's a kind of physical threat;  the set
of all physical threats includes a subset of threats that are LEO
threats involving authorities and are related to (quasi-)legal
threats.  The law enforcement personnel may have been paid off by a
rogue party in the first place,  to seize and "misplace" the data
(E.g.  deny the legitimate principal access to it  for the purposes of
competitive advantage),  or to seize and "accidentally" leak the data
to overseas entity attempting to gain the data for economic advantage,
by taking advantage of insufficient security controls of the law
enforcement entity.
It obviously wouldn't work for all kinds of data, but;
even if it's not a 5th amendment issue;   E.g.  "required to reveal
your keys and allow the data to be decrypted";    the POSSIBILITY  has
to exist that that you can in fact know or recover the keys.
You can't testify against yourself, if you had your memory permanently
wiped in some manner,  so that you are incapable of ever recalling,
because "there's nothing there to present" ---   it doesn't matter if
there was no 5th amendment,  the fact your memory was wiped,  erased
the possibility of ever testifying.
If an automatic response to the security breach results in complete
reliable destruction of physical and logical devices absolutely
required to be fully intact to  recover the keys  and execute
decryption activity, then  "there is inherently nothing to provide",
once that occured;  the remaining option would be for the LEO to
dedicate massive computing resources over a sufficient hundred years,
to  discover the key through brute force key space search  of  10^77+
That's assuming no backups of the key  devices.

@_date: 2012-12-18 02:45:04
@_author: Jimmy Hess 
@_subject: Re: William was raided for running a Tor exit node. Please help if you can. 
Yeah...  degaussing rings  consume a lot of energy you shouldn't need
to consume.   If you _must_  be able to protect data from extreme
physical threats:  keep it encrypted end to end at all times,    and
concentrate on Information assurance for  the key itself,   and
making the equipment  tamper resistant, to prevent eavesdropping,  for
example:  by incorporating computer chassis into the support structure
of the building,  with, EM shielding, plate steel vault doors  and
relocking mechanisms;    just as you'd want to safeguard other
physical valuables.
Encryption keys are short, and easy to store on small tamper-resistant
smartcards,   which can be burned up or erased in a second by a low
voltage circuit;   possibly one triggered automatically if the
incorrect PIN is entered,  or the  correct 3rd or 4th   (easily
accidentally lost,  or left at some other place) SIM Card/Micro-sim
shapped parts  containing enough other  shares  of the encryption key
 aren't inserted  in a partner module shortly after powerup.
As long as the crypto algorithm was sound,   reliable destruction of
the key should make the data as hard (or harder)  to be recovered,
than if media had been degaussed.

@_date: 2012-12-05 08:38:49
@_author: Jimmy Hess 
@_subject: Re: William was raided for running a Tor exit node. Please help if 
ISPs typically have a customer.    They know their customer, they
retain  sufficient information to identify  their customer,  such as
name, billing address, physical location,  telephone number,  and have
a signed agreement to provide the service.
They collect consideration from their customer; usually in the form of cash.
The customer of an ISP is normally expected to adhere to some sort of
AUP or TOU,  providing terms of their use of the service.   Typically
including some provisions,  such as  'customer is responsible for
activities that are performed while dialed into their account', 'no
illegal activities',   '  no sending spam',  conducting other network
For consumer ISPs,  sometimes activities such as running internet
servers, reselling,  or  providing ISP access to 3rd parties,  might
be restricted
(restrictions incompatible with running a TOR exit node on that service).
An end user operating a TOR exit node, or  wide open Wireless AP,
intentionally allows other people to connect  to their infrastructure
and the internet  whom  they have no relationship with or prior
dealings with, in spite of the possibility of network abuse or illegal
activities,    they choose to allow connectivity  without  first
gathering  information  required to hold the 3rd party responsible for
their activity.
An intentional "anonymizer" which is in contrast to what an ISP does.
The operator of an ordinary anonymizer service is subject to the
possibility of court-ordered intercept  upon future use.
If the operator of the Tor node believes that criminal intent is the
most likely use of the TOR exit node.    the degree of intentional
ignorance might be considered so severe,   that it becomes a situation
in which they are considered culpable.
E.g.  the Tor exit node operator might possibly be considered an
accessory, to the activity occuring on their node,  that they are
harboring / allowing to occur anonymously.
Not to say  whether Tor node operators are possibly guilty of anything or not.
But they are definitely different from ISPs  in  a number of important ways.
Any similarity between Open AP/Tor Exit node operator and ISP   are
highly superficial.

@_date: 2012-12-31 04:26:36
@_author: Jimmy Hess 
@_subject: Re: Gmail and SSL 
These CA's will normally require interactions be done through a web
site, there will often be captchas or other methods involved in
applying for a certificate that are difficult to automate.
They require payment, which requires a credit card,  and obtaining a
massive number of certificates is not a practical thing for malware to
perform,  unless they also possess a mass amount of stolen credit
cards, and stolen WHOIS e-mail address contacts;   on the other hand,
self-signed certificates can be generated on the fly by malware, using
a simple command or series of CryptoAPI calls.
I am aware of the procedure the CAs follow,  and I am well aware that
there are significant theoretical weaknesses inherent to the
procedures that are followed to authenticate such "Turbo",   "Domain
auth" based SSL certificates.    (They use an unencrypted e-mail
message to send the equivalent of a PIN number,  for getting a
certificate signed, in reliance of WHOIS information downloaded over
unencrypted connection: WHOIS data may be tampered with,  a MITM may
be used to alter WHOIS response in transit to the CA  ---    the PIN
number in confirmation e-mail can be sniffed in transit,  or  the
contact e-mail address may be hosted by a 3rd party insecure service
provider and/or no longer belong to the authorized contact).
All of these practices have considerable risks,  and the risk that
_some_   fraudulent requests are approved is signicant.
The very e-mail server the certificate is to be issued to, might be
the one that receives the e-mail,  and a passive sniffer there may
capture the PIN required to authorize the certificate.
However, the procedures required to exploit these weaknesses are
slightly more complicated than simply  producing a self-signed
certificate on the fly for man in the middle use --  they  require
planning,  a waiting period,  because CAs  do not typically issue
And the use of credit card numbers;  either legitimate ones, which
provide a trail to trace the attacker, or stolen ones,  which  is a
requirement,   that reduces the possible size of an attack  (since a
worm, or other malware infection,  won't have an infinite supply of
those to apply for certificates).
But   "Does the CA's signature actually represent a guaranteed
authentication" wasn't the question.
The only question is...   Does it provide an assurance that is at all
stronger than a self-signed certificate that can be made on the fly?
And it does...  not a strong one, but a slightly stronger one.

@_date: 2012-12-31 01:25:04
@_author: Jimmy Hess 
@_subject: Re: Gmail and SSL 
I would say those claiming certificates from a public CA provide no
assurance of authentication of server identity greater than that of a
self-signed one would have the burden of proof to show that it is no
less likely for an attempted forger to be able to obtain a false
"bought" certificate from a public trusted CA that has audited
certification practices statement,  a certificate improperly issued
contrary to their CPS,  than to have created a self-issued false
self-signed certificate.
It is certainly contrary to some basis on which web browser
implementations of HTTPS and TLS in practice rely upon.
While there have been failure in that area, regarding some particular
CAs, and some particular certificates,   the reported occurrences of
this were sufficiently rare,  that one doubts   "obtaining an
improperly issued certificate from a widely trusted CA"  is an  easy
feat for the most likely attackers to accomplish.
So  I would be very interested in any data you had to show that a CA
signature provides no additional assurance;   Especially,  when
combined with a policy of requiring manual human verification of the
certificate fingerprint,   and manual human agreement that the CA's
CPS  is strict enough for this certificate usage,  after  all the
automatic checks that it was properly signed by a well-known CA  with
an audited CPS statement,
with the usage of the certificate key  matching an allowed usage
declared by the Type/EKU/CA attributes of the subject and issuer

@_date: 2012-12-30 05:08:41
@_author: Jimmy Hess 
@_subject: Re: Gmail and SSL 
Hm...  Self-signed certificates, or   (worse) the use of hostnames not
on the certificate, are very common with POP/SMTP/IMAP over SSL/TLS
servers;  when setting up POP software, it is common that the user of
an e-mail service will have instructions to check and install the
certificate in the e-mail client,     instead of requiring a unique IP
address for every POP server mail domain, and a user purchased SSL
certificate for each IP.
The "major CAs" are not an authoritative list of  CAs that may be used
to sign POP, IMAP, or SMTP server certificates for various POP
servers'  on the internet;   so Google's choices would seem poorly
conceived in that regard.
If Google should wish to enforce a validation of SSL certificates, the
PKI authority required, should be specified by the user,  not Google,
or there should be a provision to accept any certificate  whatsoever,
 by fingerprint,  for a specific hostname;   defined by the user.
Google should go back to definitions.
   What is security:  security is the assurance that  the
Confidentiality, Integrity, and  Availability of data and systems are
How does this change apparently impact the assurances against risk?
    Availability:         This change breaks availability, for users accessing
     servers already using self-signed certificates.
     (In other words, the change itself is a compromise of security;
      the risk that you lose availability of access to your mail that you expect
      to be downloaded via POP3 is 100%,  if you have a self-signed
cert in place)
   Confidentiality:   The change prevents any transfer of data at all,
unless the
   user of a self-signed certificate makes one of three changes:
            (1)    Stop using gmail POP download altogether, in this
case, confidentiality
            assurance may be improved,  because no email can be downloaded
            and used with the service.    In general,   this may not
be much of an improvement,
            when email has already been transmitted in cleartext,
before it was placed
            on the remote POP server.
            (That might be their intended result --  discourage use of
POP downloads)
            (2)    Stop using SSL, and use regular POP3 instead.  In this case,
            confidentiality will be no better than before, and may be
significantly worse.
            A new risk of   breach by 'passive sniffing'  is created.
            When using SSL with a self-signed certificate;  passive
sniffing, or
            Deep packet inspection was not a risk:  an active attack
was a requirement.
            Therefore,  being forced to "never use SSL", even without
a CA signed cert,
            is not an improvement,  and a potential increase in risk.
            (3)   Users may  buy an official certificate, from a 3rd
party CA that Google trusts.
            In this case, the  SSL encrypted POP3  connections from Google to
            the POP server,  will have strong protection against
possible exposure of
            data in transit due to active Man-in-the-middle attack.
* In other words:  If you deem  Man-in-the-Middle attack more likely
than Passive sniffing exposure attacks  to discover users'  passwords,
and the majority of users'  POP servers likely to have or get
certificates from a CA that Google trusts,    then  forced  rejection
of  any other certificates may be an improvement in assurance against
these risks;      forcing the remaining users to not use SSL,  and
risk their password being exposed  is OK,   because you deemed  MITM
the greater risk.
If you do not make that assumption,  then it is not clear at all,
whether assurance of confidentiality has been improved or not;   it
may be improved slightly for some users, and terribly harmed for
many others.
    Integrity:   The change prevents any transfer of data at all, unless the
         user of a self-signed certificate makes one of three changes:
            (1)    Stop using POP download altogether, in this case, data
             cannot be altered by an unauthorized user as it transits
the network,
             data that wasn't downloaded couldn't have been tampered with.
            (2)    Stop using SSL, and use regular POP3 instead.
              In this case, a new risk of  "transparent inline
tampering" is created,
              without encryption, a full blown MITM attack is not required,
              a passive interceptor can flip random bits, as long as
they update the
              corresponding IP checksums;
              so there are new significant risks to integrity.
            (3)   Users may  buy an official certificate;  in this
case, the risk
               of  interception by inline Man-in-the-middle attack  is reduced.

@_date: 2013-01-04 02:08:08
@_author: Jimmy Hess 
@_subject: Re: Gmail and SSL 
I am not sure why this would be classified as a feature request.
If it is impacting you, and you had service before, then is an
Outage/Defect/Bug, full stop.
Describing working service for a previously supported scenario as a
"feature request"  would be beyond ridiculous :)

@_date: 2013-01-03 03:02:00
@_author: Jimmy Hess 
@_subject: Re: Gmail and SSL 
It's ashame they've stuck with a hardcoded list of "Acceptable CAs"
for certain certificates; that would be very difficult to update. The
major banks, Facebook, Hotmail, etc,   possibly have not made a
promise to anyone,  that all their future new renewal certificates
will be from a specific CA;   would be more interesting, if the Chrome
devs provided for a mechanism  for making a remote query or receiving
a digitally signed "PINned cert list" download,  that could be updated
 dynamically,   /and/  provided policy and mechanisms to have sites
included in the list.
One of the broken things about X500,  is a certificate can only have
one signature.
The trust could be strengthened,  if  there were a mechanism allowing
multiple 3rd party attestations to be made  (eg  PGP-like  multiple
signatures), or
a browser could be configured to only accept a certificate, if  BOTH
   (i)  Signed by a CA,   and
   (ii) The certificate's information, or the CA information for the
cert is published in a 3rd party corroborating database,   that  also
requires proof of ID/authorization to publish in that DB.
  (iii)  And the server does the work of querying the 3rd party
databases listed by the client, by sending the CA ID, Certificate ID,
through a query to some standardized URL format, and returns the
timestamped digitally signed result  (query answer, or affirmative
proof of no entry in the DB), during authentication, together with the
Depending on the authenticating browser's config, a domain not found
in the 3rd party corroborating datasources,   or listed by the 3rd
party source  with an attestation level of "Only domain control
validated",  might result in the CA's signature being ignored.
That is: the browser (or the user)  should pick how strong  the
certificate has to be, depending on the kind of business they will be
executing over the SSL channel.
CA's  could later become required to check at least 2 3rd party
databases,  to ensure any prior certificate issued by another CA was
actually revoked or expired, before allowing the signing of a new

@_date: 2013-01-03 02:06:15
@_author: Jimmy Hess 
@_subject: Re: Gmail and SSL 
Absolutely.  A certificate whose fingerprint has personally been
validated by a human, and compared to a SHA1 fingerprint learned
earlier out of band,  is to be trusted with a high level of
confidence.      It is in a sense may be a more reliable assurance
than a  CA signature on a certificate,  as long as a strong validation
process was followed --   it is still stronger if BOTH  fingerprint
manually validated _and_ signed by a recognized CA.
A problem, however, that can come in when designing software - such as
browsers -- How do you prove the human actually  was properly trained,
and followed the correct validation procedure?
If the human doesn't actually have to type the expected SHA1
fingerprint, and there is a way the human can just "click OK";  or
select an option to "disable checking"  -- the average human will
likely  just spontaneously click that -- not understanding what
fingerprint validation is, and simply  "Approve" or  "Skip"  the
validation process,  and mark as trusted, without manually verifying
Therefore:  the usefulness of fingerprint validation  is often
limited, to situations where the operator is specifically trained to
follow a reasonable validation procedure,  and adherence to the
validation procedure is enforced.
In resp to,
There are plenty of public CAs  that will allow you to generate your
own private key, and distribute only the CSR to the CA,  for their
signature attesting to the authenticity of every public attribute of
the certificate;  a CA  signs a certificate based on the public
information it claims,  based on its signing policy,  CAs don't ever
actually get to learn the private key of the certificate request.
If you are concerned about CA misbehavior on behalf of governments,
then it makes sense to have software  require manual
approval/certificate installation of even CA-validated certs.
And the "CA signature"  should then simply be a mandatory Pre-Check,
before being
allowed to install or trust a certificate.
In resp to
Correct,  when an organization name is not listed on the certificate;
that is not part of what has been authenticated, only domain control
was authenticated.
This is what CAs do.   They only necessarily attest the details
actually published on the certificate;  their job is not to attest
that the certificate will only be used for legitimate purposes,
although they may do that as well, through CSP and revokation
practices.   If you are the legitimate owner of a domain,  then a
certificate issued to it with a CN or Altname of a hostname within
that domain,  is legitimate, if you are actually the person that
authorized it,  you approved acceptance of the certificate request
containing that name, and you, and only people authorized by the
principal have access to the private key.
CAs,  could do their job better,  if DNSSEC is implemented securely
for a domain, and the CA required a  DNSSEC validated TXT  record
with the   Certificate Authority's  Issuer  /CN=..../OU=.../O=...
fields   and the   CSR Certificate Request's   public key SHA256 hash
code,  together with a DNSSEC validatable record published  containing
the /CN=..../OU=.../O=...   fields of the PKCS CSR, for the Common
name (hostname) and a DNSSEC signed CNAME for each alt name on  every
certificate to be issued.
I expect browser CA policies to evolve to require stronger validations.
Where do you draw the conclusion it is only 0.1%?
Not that 0.1% is a small number   1 time out of 1000...
If you anticipate 86400 attacks in a day,   0.2%  could be 8640 more
attacks succeeding.
I don't thinkyou give the CAs enough credit.    There are well-known
trojans that generate on the fly self-signed certificates
(specifically things like Flashback,Flame,Flashback,Tatanarg,ZeuS).
It seems to be a much rarer event,  that there is any report and then
only a small number of improperly issued CA signed certificates.
This is likely reflecting greater difficulty and much lower
practicality of improperly issued certificates as an effective attack
There have in the past been cases where a CA was compromised or
improperly issued certificates, and the certificates were revoked.
Self-signed certificates cannot be revoked, except by manually
updating software to blacklist them.
You may be missing the fact, that it's still _hard enough_   and
inefficient enough to apply for and get false SSL certificates en
masse,  that the possible attack scope is greatly limited.
That is, the CA certificates aren't low-hanging fruit  (Self signed ones are).
And the increase in difficulty,  if self-signed certs are blocked:
other attacks against parts of
the stack besides the certificate are more likely,  OR   another
target may be picked
(Such as brute force attempts to guess valid authentication credentials,
or a search for vulnerabilities  in the SSL implementation itself,  such as
buffer overflow,  authentication bypass, or MD5 weaknesses allowing
substitution of certificate signed content with fraudulent certificate

@_date: 2013-09-08 15:04:36
@_author: Jimmy Hess 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
Or there might be 2 good solutions for certain security functions around
$100.   And 10 different flavors of $90 snake oil,and plenty of $50, $100,
and $120 snake oil flavors. The world is full of salespeople and marketers;
 and the snakeoil  salespersons are just as great as the "good stuff"
salespeople  ----  also,  with more resources to devote to sales, than
engineering;  the snakeoil salespersons have more time and resources
available to look at their competitors' merchandising, and make the
snakeoil bottles on the store shelves are the ones that look the most
appealing to the potential buyers.
A wary buyer should not believe the salesperson, but demand a thorough
long-term critical review  (a 30 day demo of some product is not sufficient
duration to discover that it's totally bunk).
 2.  Security is *hard*, it is a negative deliverable. You do not know
This is because it doesn't make sense to say that security itself has a ROI
in the first place.
IT security is risk management --- therefore, in isolation security means
security is a way of mitigating fundamental risks  that are improbable
events that are
nevertheless certain to happen eventually (given enough time) that have an
average negative
There is a fundamental tradeoff between risk and return:  If you spend NO
money on security,
lawyers, to help structure the business to avoid liabilities,  and other
protections such as insurance
then you INCREASE return;  in the short term, you will most  likely have
much greater profit,
if you don't bother with any insurance, lawyers, or security.
It all works fine, until there is a disaster,  someone files a lawsuit,  or
you have a breakin.
For example:  by not purchasing insurance on your business assets;  you
avoid spending
insurance premium dollars.    This  increases how much money you make (your
as long as nothing bad happens.
However, not buying insurance, or not paying the costs of security greatly
increase the risk
that the business incurs a loss because something bad happens.
Furthermore,  spending a lot of money on security reduces return,  BUT also
reduces the risk.
Security does not have a ROI,  but it does have a tradeoff.
That tradeoff should be understood using the language of risk management,
not profit/loss.    And there is no reason people can't understand that....
after all;  they do understand,  what happens if you don't pay lawyers to
help your enterprises comply with the law, or draft successfully binding
You should expect to spend amounts on security per year, commensurate with
the costs of insuring
those data assets against the liability that would be incurred if they were
tampered with or leaked to the public;
granted,   plenty of orgs are much more likely to have an  internet-based
security breach than a fire or a flood,
therefore,  the risk you take on by not spending on security is possibly a
larger risk.
 2a. Most people don=92t really care until they have been personally
Most people purchase homeowners' insurance.
Vehicle insurance is mandated by the state in many cases.
I wonder if someday; a similar per-PC mandatory purchase will someday be
required for computer security.
Yes.   This is a total nightmare.
Before  Joe consumer can send an encrypted mail; he has to either go to
some command line and gpg --gen-key
or go to  Xyz CA  corporation,  buy a personal SSL certificate for some
expensive per-year  premium    $10 or more...
and then go through a lot of trouble to figure out how to import that into
the browser, and manually repeat this process every 1 to 3 years  that his
certificate expires;  the process Joe  has to go through  to  S/MIME enable
every copy of his mail client on all his different computers,  and  his
webmail provider, is even more complicated.
Before anyone can send Joe an encrypted message;  Joe somehow has to  get
all his correspondents to manually import a copy of his certificate.
This is clearly miles outside the realm of possibility for the average
Windows user.

@_date: 2013-11-02 18:42:04
@_author: Jimmy Hess 
@_subject: Re: latest Snowden docs show NSA intercepts all Google and Yahoo DC-to-DC traffic 
Better leverage quantum encryption tech to exchange those symmetric keys
securely;  I wouldn't be surprised if the NSA  has  DH,  DSA, and RSA  key
exchange schemes defeated or backdoored.
RC4 while not a particularly strong cipher may be strong enough
cryptography to dissaude the NSA,  until the matter comes up to budgeting,
and they get a few hundred billion extra in taxpayer money allocated in
order to get their truckload of ASICs live for rapidly brute-forcing RC4
keys, or AES keys, or  $cipher_of_the_day_keys.
With near certainty,  there would be more invasive methods of attack
available that do not require beating the actual cipher algorithm, and they
would exploit any available options --- figure out which devices are
responsible for doing the encryption, and  compromise the security of those
oh RC4 may be strong enough otherwise, but the cryptosystem or library that
actually implements the AES RC4 or whatever key/cipher scheme, weak.   It's
also entirely possible, the implementation you get of RC4, AES, RSA,
 etc... will contain subtle backdoors in the library, that reduce the
cipher strength to a level far less.

@_date: 2013-11-01 08:13:11
@_author: Jimmy Hess 
@_subject: Re: latest Snowden docs show NSA intercepts all Google and Yahoo DC-to-DC traffic 
So, crypto costs money at scale basically.
SSL Cryptography for web search is a different problem than, say
 Site-to-Site VPN encryption.
Every time a new browser connects, you have a new SSL session setup.
New SSL session setup requires  public cryptography operations which impose
a significant delay, and the public key operations have an enormous CPU
So much so,  that the key generation and signing operations involved in CPU
session setup are a big bottleneck, and therefore, a potential DoS risk.
For encryption of traffic between datacenters;    There should be very
little session setup and teardown  (very few public key operations);
 almost all the crypto load would be symmetric cryptography.
No doubt, there still  must be some cost in terms of crypto processors
required to achieve encryption of all the traffic on 100-gigabit links
 between datacenters;  it's always something, after all.

@_date: 2013-11-01 00:53:05
@_author: Jimmy Hess 
@_subject: Re: latest Snowden docs show NSA intercepts all Google and Yahoo DC-to-DC traffic 
No need for intrusive techniques such as direct taps:
For shame.... you've  sent in a link to some article behind a paywall, with
some insane download fee.
Which is an equivalent of hand-waving.
They must be hiding their content,  for fear that flaws be pointed out.
"Of all the techniques, the bent fiber tap is the most easily deployed with
There will be some wavelengths of light, that may be on the cable, that
bending won't get a useful signal from.
Bending the cable sufficiently to  break  the total internal reflection
 property,  and allow light to leak --  will generate power losses in the
cable,  that can be identified  on an OTDR.
