
@_date: 2002-07-05 10:52:52
@_author: Seth David Schoen 
@_subject: Re: Ross's TCPA paper 
The latter is closest to what's intended in Palladium.  Individual
programs using Palladium features are able to prevent one another from
reading their executing or stored state.  You can write your own
programs, but somebody else can also write programs which can process
data in a way that your programs can't interact with.
The Palladium security model and features are different from Unix, but
you can imagine by rough analogy a Unix implementation on a system
with protected memory.  Every process can have its own virtual memory
space, read and write files, interact with the user, etc.  But
normally a program can't read another program's memory without the
other program's permission.
The analogy starts to break down, though: in Unix a process running as
the superuser or code running in kernel mode may be able to ignore
memory protection and monitor or control an arbitrary process.  In
Palladium, if a system is started in a trusted mode, not even the OS
kernel will have access to all system resources.  That limitation
doesn't stop you from writing your own application software or scripts.
Interestingly, Palladium and TCPA both allow you to modify any part of
the software installed on your system (though not your hardware).  The
worst thing which can happen to you as a result is that the system
will know that it is no longer "trusted", or will otherwise be able to
recognize or take account of the changes you made.  In principle,
there's nothing wrong with running "untrusted"; particular applications
or services which relied on a trusted feature, including sealed
storage (see below), may fail to operate.
Palladium and TCPA both allow an application to make use of
hardware-based encryption and decryption in a scheme called "sealed
storage" which uses a hash of the running system's software as part of
the key.  One result of this is that, if you change relevant parts of
the software, the hardware will no longer be able to perform the
decryption step.  To oversimplify slightly, you could imagine that the
hardware uses the currently-running OS kernel's hash as part of this
key.  Then, if you change the kernel in any way (which you're
permitted to do), applications running under it will find that they're
no longer able to decrypt "sealed" files which were created under the
original kernel.  Rebooting with the original kernel will restore the
ability to decrypt, because the hash will again match the original
kernel's hash.
(I've been reading TCPA specs and recently met with some Microsoft
Palladium team members.  But I'm still learning about both systems and
may well have made some mistakes in my description.)

@_date: 2002-07-05 10:52:52
@_author: Seth David Schoen 
@_subject: Re: Ross's TCPA paper 
The latter is closest to what's intended in Palladium.  Individual
programs using Palladium features are able to prevent one another from
reading their executing or stored state.  You can write your own
programs, but somebody else can also write programs which can process
data in a way that your programs can't interact with.
The Palladium security model and features are different from Unix, but
you can imagine by rough analogy a Unix implementation on a system
with protected memory.  Every process can have its own virtual memory
space, read and write files, interact with the user, etc.  But
normally a program can't read another program's memory without the
other program's permission.
The analogy starts to break down, though: in Unix a process running as
the superuser or code running in kernel mode may be able to ignore
memory protection and monitor or control an arbitrary process.  In
Palladium, if a system is started in a trusted mode, not even the OS
kernel will have access to all system resources.  That limitation
doesn't stop you from writing your own application software or scripts.
Interestingly, Palladium and TCPA both allow you to modify any part of
the software installed on your system (though not your hardware).  The
worst thing which can happen to you as a result is that the system
will know that it is no longer "trusted", or will otherwise be able to
recognize or take account of the changes you made.  In principle,
there's nothing wrong with running "untrusted"; particular applications
or services which relied on a trusted feature, including sealed
storage (see below), may fail to operate.
Palladium and TCPA both allow an application to make use of
hardware-based encryption and decryption in a scheme called "sealed
storage" which uses a hash of the running system's software as part of
the key.  One result of this is that, if you change relevant parts of
the software, the hardware will no longer be able to perform the
decryption step.  To oversimplify slightly, you could imagine that the
hardware uses the currently-running OS kernel's hash as part of this
key.  Then, if you change the kernel in any way (which you're
permitted to do), applications running under it will find that they're
no longer able to decrypt "sealed" files which were created under the
original kernel.  Rebooting with the original kernel will restore the
ability to decrypt, because the hash will again match the original
kernel's hash.
(I've been reading TCPA specs and recently met with some Microsoft
Palladium team members.  But I'm still learning about both systems and
may well have made some mistakes in my description.)

@_date: 2008-12-05 09:22:07
@_author: Seth David Schoen 
@_subject: Re: No data retention in germany for donated services 
I'm not a lawyer in Germany or any jurisdiction and I don't have any
knowledge or opinion of the convincingness or legal well-foundedness
of this article.  I encourage anyone who might want to rely on it to
seek the expert opinion of a German lawyer.  But I do read German, so
I've translated Karsten's note and (most of) the text of the article
below for the benefit of anyone interested in this material who doesn't
read German.
NO DATA RETENTION FOR FREE-OF-CHARGE SERVICES
  Original German text of this article "Keine Vorratsdatenspeicherung fÃ¼r
  unentgeltliche Dienste" is available at
     Copyright 2008 Patrick Breyer; licensed under Creative Commons BY-2.0
  (Germany) license.
    Translation by Seth Schoen.  This text version omits hyperlinks to the
  German text of laws, treaties, and court decisions which appear in-line
  in the original German version.
Beginning on January 1, 2009 at the latest, those offering certain
publicly-accessible telecommunications services must store their users'
traffic data (Â§ 113a TKG). This applies to providers of land line
telephone services, mobile telephone services, Internet telephone
services, e-mail, Internet access, and anonymizing services. However,
it has thus far remained unnoticed that the obligation to store this
data applies only to compensated or commercial services. Free-of-charge
services do not have to store data. Indeed, data retention is forbidden
to them under penalty of a fine.
* Legal situation
The obligation to retain data in Germany arises from Â§ 113a TKG.
This rule is only applicable to "telecommunications services"
[Telekommunikationsdienste]. According to Â§ 3 no. 24 TKG,
"telecommunications services" are only "services normally provided
for remuneration" [in der Regel gegen Entgelt erbrachte Dienste].
For clarification of this distinguishing criterion, we find in the
explanatory statement of the corresponding bill: "This definition is
in accordance with art. 2 letter c sec. 1 RRL".
This refers to the EU Directive 2002/21/EC on on a common regulatory
framework for electronic communications networks and services.
This Directive defines as an "electronic communications service"
[quotation from official English version] only "a service normally
provided for remuneration" [quotation from official English version;
German 'gewÃ¶hnlich gegen Entgelt erbrachte Dienste']. The Commission
had originally even wanted to include only "a service provided for
remuneration" [gegen Entgelt erbrachte Dienste]. This was in accordance
with the then-effective German telecommunications law of 1996,
which was largely applicable only to "the commercial provision of
telecommunication" [das gewerbliche Angebot von Telekommunikation].
The European Parliament asked, however, for a broadening of the
framework directive to all services that are rendered "on a commercial
basis" [quotation from official English version; German 'auf
kommerzieller Basis']. For explanation it argued that "electronic
communications services may be offered on an unremunerated, yet
commercial basis" [quotation from official English version]. The
Council finally decided on the current formulation, according to which
all "services normally provided for remuneration" [gewÃ¶hnlich gegen
Entgelt erbrachte[n] Dienste] are included. The Council did not offer
an explanation for this formulation.
However, it is clear that as a compromise the definition of service
provision fom the EC Treaty was adopted in full (EC Treaty article
50). The EC Treaty defines service provision in article 50 as follows:
"Services shall be considered to be 'services' within the meaning of
this Treaty where they are normally provided for remuneration, in so
far as they are not governed by the provisions relating to freedom of
movement for goods, capital and persons. 'Services' shall in particular
include: (a) activities of an industrial character; (b) activities of
a commercial character; (c) activities of craftsmen; (d) activities
of the professions." [quotation from official English version] The
distinguishing criterion "normally provided for remuneration" [in der
Regel gegen Entgelt erbracht] was thus adopted word-for-word in the
telecommunications Framework Directive, which is also evident from the
other translations of the Directive. This imitation of the EC Treaty was
meaningful because the Framework Directive is founded upon the basis of
the European Single Market powers of the EC. The EC may not regulate
the provision of services other than those that are the subject of the
Single Market.
The definition of electronic communications services in the Framework
Directive applies to data retention as well according to article 2,
paragraph 1 of Directive 2006/24/EC. The data retention directive
applies according to its article 3 only to "electronic communications
services" [elektronische Kommunikationsdienste] in this sense. The
Directive on data retention could not include other services because
in any case it is founded on the basis of the Single Market powers (EC
Treaty article 95) and may thereby only regulate the Single Market.
The scope of Â§ 113a TKG is, in the end, consequently identical to
the scope of EC Treaty article 50. The German legislature did not
merely intend to take the definition of "telecommunications service"
[Telekommunikationsdienst] in Â§ 3 TKG from EC law (see explanation).
In this regard it also intended to implement data retention itself only
in accordance with European legal requirements. This is clear from the
title of the implementing legislation, but also from the rationale
for the law (pages 30 and 69). The Bundestag wanted to require only
those services (with the exception of anonymizing services) to retain
data which it had to require to do so according to the EC Directive on
data retention. The German Constitutional Court has ruled with regard
to European arrest warrants that European legal requirements must be
implemented as narrowly and compatibly with basic rights as possible.
In the application of implementing laws, a construction compatible
with basic rights should also be taken. A constitutionally compatible
construction of Â§ 113a TKG requires that data retention â to avoid
breaching German basic rights and the rule of proportionality â not be
expanded beyond what is necessary as a matter of European law.
* Precedent on the defining criterion "normally [provided] for
remuneration" [in der Regel gegen Entgelt]
Many decisions of the German court have been issued on the question of
when a service is "normally provided for remuneration" [in der Regel
gegen Entgelt erbracht]. In the leading decision "Humbel" from 1988,
the Court decided: "According to article 60, para. 1 of the EEC Treaty,
only 'services that are normally provided for remuneration' [quotation
from official English version; German 'Leistungen, die in der Regel
gegen Entgelt erbracht werden'] fall under the chapter on services. Even
if the term 'remuneration' [Entgelt] has not been expressly defined in
articles 59 and following of the EEC Treaty, its meaning can be inferred
from article 60, para. 2 of the EEC Treaty, according to which, in
particular, industrial, commercial, craft and professional activities
count as services. The essential feature of remuneration [Entgelt]
is thus that it shows the service provided in return for the service
concerned, in which the service provided in return is normally agreed
between the service provider and the recipient of the service."
In subsequent decisions, the court has clarified that such a service in
return can also be deemed to occur if it is paid for by a person other
than the recipient. Thus private television broadcasting is regarded as
a service provided for remuneration [gegen Entgelt erbrachte Leistung],
because it is paid for through advertising. Indeed, one can regard
private television broadcasting as a commercial service [entgeltliche
Leistung] for the advertising purchasers, which serves to draw viewers
for the commercials. The court has also considered the services of
hospitals as furnished for remuneration [gegen Entgelt erbracht], since
the hospitals are financed by health insurance companies â although in
the form of standard flat rates.
Now it is important that the court takes particular services into
account. The criterion "normally" [in der Regel] thus does not go so
far as to make a single category dispositive of all services. Rather,
the court determined with regard to universities, for instance, that
the freedom of services had no application to public, tax-supported
universities, but that it did apply to private colleges. It is thus
critical whether the particular provider offers his service "normally
for remuneration" [in der Regel gegen Entgelt] or not. The service must
be assigned according to EC Treaty article 2 to "economic activities"
[quotation from original English version; German 'Wirtschaftsleben'].
In the case of public schools, the court established that their public
funding still did not establish a remunerated service [entgeltliche
Leistung]. The public financing did not constitute a service directly
provided in return for a service rendered. Even a mandatory levied
tuition fee does not constitute a remunerated service [entgeltliche
Leistung], so long as the institution is funded substantially by
public means. That a service (necessarily) must be funded in one
way or another, then, still does not make it a remunerated service
[entgeltliche Leistung]. The funding must rather be able to be regarded
as provided directly in return for the service [gerade als Gegenleistung
fÃ¼r den Dienst].
* Application to data retention obligations
For telecommunication services and the obligation to retain data the
following thus apply:
Services that are financed essentially by something provided in exchange
[Gegenleistungen] by the user are in any event normally provided for
remuneration [in der Regel gegen Entgelt erbracht]. Such services must
thus retain data.
Those services that are financed essentially by accepting advertising
â such as banner ads â and that are run for profit are also normally
provided for remuneration [in der Regel gegen Entgelt erbracht]. Thus,
for example, the commercial free e-mail services must store data, even
if their users don't have to pay a subscription fee [Entgelt].
On the other hand, services that are provided for nothing substantial
in exchange [keine wesentliche Gegenleistung], either by their users
or by their parties, are normally provided for no remuneration [in der
Regel unentgeltlich erbracht]. For instance, a private party may provide
a free e-mail service, an open wireless network providing Internet
access, or a Tor server for no compensation [unentgeltlich] and financed
with his own means, and then no telecommunications service normally
provided for remuneration [in der Regel gegen Entgelt erbrachter
Telekommunikationsdienst] exists and the data retention obligation
according to Â§ 113a TKG does not apply.
Government services are also normally not provided for compensation [in
der Regel unentgeltlich erbracht]. Many local authorities, for example,
provide free Internet access or e-mail accounts. These essential
tax-financed services are exempt from data retention. This is even true
if a service charge is levied on the user, but the charge only defrays
a small part of the costs. This situation should not be considered as
different from the imposition of tuition fees or charges, concerning
which the European court has already ruled.
Correspondingly, even a private noncommercial service [unentgeltlicher
Dienst] does not always lose its noncommercial character
[unentgeltlichen Charakter] by collecting a service charge or showing
commercial advertising, as long as accepting these makes up only a
trivial share of the cost of the service. Whoever wants to be confident
in being exempt from the obligation to retain data should, however,
forego such sources of funding entirely.
Services that are offered by noncommercial providers (for example, by
individuals or organizations) without a profit motive, but that recoup
their costs essentially by payments from users or advertising customers,
will be regarded as "normally provided for remuneration" [in der Regel
gegen Entgelt erbracht]. After all, the requirement "for remuneration"
[gegen Entgelt] does not require any profit motive. Accordingly, the
European court has regarded private schools or hospitals as commercial
providers [entgeltliche Anbieter], even though they have no profit
motive. Thus even noncommercial services fall under the data retention
requirement if they are provided for remuneration [gegen Entgelt
The treatment of services whose costs are actually essentially borne by
private individual means, but which are offered as "additional" services
by commercial providers, is unclear. For example, some firms offer, in
addition to their paid services, a free public webmail service. The
question is whether the self-promotion, that is to say the publicity
for a commercial offering of the same firm, should be seen as a form
of compensation for the ostensibly free service [ein Entgelt fÃ¼r
den an sich kostenlosen Dienst]. EC Treaty article 50 particularly
includes industrial services, and a commercial firm always has a profit
movie. In this connection, the court has decided with regard to tobacco
advertising that commercial advertising falls within the scope of the
Single Market.
Uncompensated services [unentgeltliche Dienste] of a commercial firm
are thus to be viewed as "normally provided for remuneration" [in
der Regel gegen Entgelt erbracht] if they serve as advertising for
compensated products [entgeltliche Angebote] of the firm. With regard
to commercial firms, a certain appearance argues that their services
in the end promote their own profit motive. Nonetheless an individual
service of a commercial firm need not serve as advertising for the
firm's own compensated products [entgeltlichen Angebote]. For instance a
noncommercial offering [unentgeltliche Angbot] may be clearly separate
from the commercial operation [gewerblichen TÃ¤tigkeit] of its provider,
in that it for example is delivered through a separate portal without
any self-promotional materials; then a product normally provided without
remuneration [in der Regel ein unentgeltliches Angebot] will exist,
which does not fall under data retention requirements. If, on the other
hand, the uncompensated service is embedded in the commercial appearance
of the firm, normally a publicity interest and thereby a compensated
product will be presumed.
In summary, we should note that those services that are essentially
funded by private means and that also do not serve as advertising for
paid services are exempted from the obligation to retain data. For
instance, when an individual person offers an e-mail service, a public
wireless LAN with Internet access, or a Tor server without being paid
for it, and he essentially funds from his own resources and not by
receipts from its users or advertising customers, the data retention
obligation according to Â§ 113a TKG does not apply.
* Prohibition on data retention by non-commercial services
Uncompensated services are not only excepted from the obligation
to retain data. Their providers may also not "voluntarily" retain
data. This results from Â§ 96 para. 2 TKG, according to which traffic
data must be erased immediately after the end of the connection, if
they are not "necessary for the purposes established through [...]
legal requirements" [fÃ¼r die durch [...] gesetzliche Vorschriften
begrÃ¼ndeten Zwecke erforderlich]. This obligation to erase data
applies to all businesslike providers of telecommunications services
[geschÃ¤ftsmÃ¤Ãigen Anbieter von Telekommunikationsdiensten]. According
to Â§ 3 TKG, these are all providers of telecommunications, even if
their offering is uncompensated [unentgeltlich].
That "voluntary" data retention, as some Internet service providers
currently practice it, may also not be done on "security grounds"
according to Â§ 100 TKG has already been explained in more detail
Whoever violates the prohibition on data retention in Â§ 96 TKG is
acting illegally and can be punished with a fine up to ten thousand
Euro by the Federal Network Agency (Â§ 149 para. 1 no. 17 TKG). Anyone
may file a complaint. However, someone who is required to retain data
and does not do so is also acting illegally. Each provider of telephone
service, e-mail, Internet access, or anonymizing service should thus
make sure that he acts correctly. In case of doubt, he should ask the
Federal Network Agency.
* Non-public services
Data retention applies only to services that are publicly available
(Â§ 113a TKG). This is an independent restriction in addition to the
commercialness discussed above. The data retention obligation thus
applies only if a service is both normally provided for remuneration
and also publicly accessible. If either of these two criteria is not
met, data retention is not applicable and is forbidden.
A service is publicly available if anyone â and not just specified
groups of users â can use it. The availability of a service only
to members of an organization doesn't affect the public availability
of that service if anyone can become a member of the organization.
Non-publicly-accessible services, by contrast, are those offered, for
instance, by employers or universities, since these can be accessed only
by a limited group of people. These providers are neither required nor
authorized to retain data.
[Final section ("AusweichmÃ¶glichkeiten fÃ¼r entgeltliche Dienste") omitted
from this translation; it describes a procedure for commercial services
to try to obtain a financial indemnity or exemption from the government
while the constitutional challenge to the data retention law is pending,
by writing a letter to the Federal Network Agency.  This letter would
demand that that agency temporarily exempt commercial service providers
from implementing data retention or else promise to reimburse the service
providers for their implementation costs in case the German constitutional
court rules data retention unconstitutional or in case it rules that the
government must pay implementation costs.]

@_date: 2012-03-07 00:20:54
@_author: Seth David Schoen 
@_subject: Re: [tor-talk] Tor and HTTPS graphic 
I was concerned that the graphic should not make people think that
_no one_ can ever associate them with their browsing when they use
Tor.  I've been taught to think of the GPA threat (and other traffic
correlation threats) as real, so I thought people should have some
indication of those threats.

@_date: 2012-03-06 04:55:36
@_author: Seth David Schoen 
@_subject: [tor-talk] Tor and HTTPS graphic 
Eva Galperin and I worked on this graphic (drawn by Hugh D'Andrade)
that tries to show the difference between the threats Tor addresses
and the threats HTTPS addresses.
The complete interactive version is at
You can click to enable or disable the use of Tor and HTTPS and
see what information different parties can see about your
communications in each case.  (It even includes a global passive
adversary from the NSA in a position to do a traffic correlation
This is a very different kind of educational material than Joe Hall's
cool hands-on anonymity simulation concept, but I hope it will be
useful to some people trying to teach and learn about Tor.

@_date: 2012-06-28 05:28:20
@_author: Seth David Schoen 
@_subject: Re: [tor-talk] possible to identify tor user via hardware DRM? 
I find this message misleading in various ways.  The basic thing that
I've been telling people is that there are few situations in which
either PSN or TPM uniqueness makes things qualitatively worse.
There are lots of hardware unique IDs.  On Linux, try "sudo lshw" and
be surprised at all the things that have unique serial numbers.  There
are also things that are unique about your machine that are not
hardware serial numbers, like filesystem serial numbers and observed
combinations of software configurations.
These can be bad for privacy because software can tell which computer
it's running on.  If the software has an adversarial relationship with
you, it can then use that information in a way that you don't like.
We would be better off in some regards if operating systems let us
hide local uniqueness from software so that the software couldn't tell
what machine it was running on, or set fake values for these unique
Some proprietary software including Microsoft Windows already makes
a sophisticated profile of the local machine, including many kinds of
observations, to tie a copy of the software (or an "activation") to a
particular device (!).
The only substantive difference with the TPM uniqueness is that the TPM
uniqueness lets you prove (like a smartcard) to a remote system that
you're running some software on the same machine as before.  Even if
the OS did let you set fake values when software tried to examine the
system it was running on, the remote system could see that the
TPM-related values were fake.  That's useful for some applications,
including but not limited to DRM-like ones.
I've argued that this is bad in some ways, but at least you can still
turn off the TPM.  Then your system can't attempt to offer that kind
of proof.  As far as I know, turning off the TPM is pretty robust:
it really is turned off.
All of these things are anonymity problems in particular when some
software on your computer is actively _trying_ to tell someone else
what machine you're running on, either because it's programmed to do
so or because someone has broken into your computer and installed
spyware and is trying to use it to monitor you.  If you're not in
that situation, there is nothing especially magical about having
unique hardware IDs in your machine, because everyone's machine has
some uniqueness, and (for the most part) that uniqueness isn't part
of standard network protocols like TCP/IP and doesn't automatically
leak out to anyone and everyone you communicate with over the
Internet.  (There is a possible exception about clock skew, which you
can read about in Steven Murdoch's paper from 2006.)
Similarly, having a GPS receiver in your phone does not mean that
everyone you send an SMS to or everyone you call will learn your
exact physical location.  However, it does mean that if there's
spyware on your phone, that spyware is able to use the GPS to learn
your location and leak it.  If you're worried about spyware threats
on your phone, which can be quite a realistic concern, the GPS
itself isn't necessarily the unique core of the threat, because
there are also lots of other things in the phone that can be read to
help physically locate you (like wifi base station MAC addresses,
taking photographs of your surroundings with the phone's camera,
recording the identities and signal strengths of the GSM base
stations your phone sees...).  So a more fundamental question might
be whether your phone operating system is able to either prevent
you from getting malware or prevent the malware from accessing the
sensors on your phone.
In the case of a desktop PC, the hardware uniqueness is _there to
be read by software_, and if it's in a TPM it _may be able to give
the software remotely verifiable cryptographic proof that the
software is really running on the machine containing that particular
TPM_.  In neither case does the hardware uniqueness directly
broadcast itself to other machines, and in neither case does the
hardware uniqueness prevent the operating system from preventing
other software from reading it.
If you do have some kind of software running on your machine that's
trying to track you or trying to help other people track you,
hardware uniqueness is one thing that the software might look at.
But if you're a Tor user, a more basic thing for the software to
try to do is make network connections to leak your real IP address
in order to associate your Tor-based network activity with your
non-Tor-based network activity.  That might be even easier because
the tracking software could just try to make a direct network
If you're not using Tor, at least not at a particular moment, but
are still concerned about tracking, there's another problem, which
is that all existing browsers _already_ reveal a great deal of
software-based uniqueness to any interested web site, usually enough
to make your browser unique.  See
This is important because it doesn't require there to be any
malicious software on your computer, just a traditional web browser.
One of the defenses people have talked about against hardware
fingerprinting is running inside a virtual machine.  Normally,
software inside the virtual machine, even if it's malicious,
doesn't learn much about the physical machine that hosts the VM.
If you always use Tor inside a VM, then even if there's a bug
that lets someone take over your computer (or if they trick you
into installing spyware), the malicious software won't be able
to read much real uniqueness from the host hardware, unless
there's also a bug in the VM software.
Running in a VM isn't exactly a defense against software
fingerprinting (like browser fingerprinting) if you use the VM
for various non-Tor activities that you don't want to be linked
to one another, because the software configuration inside the VM
might be, or become, sufficiently different from others that it
can be recognized.  There's probably more research to be done
about the conditions under which VMs can be uniquely identified
both "from the inside" by malware, and remotely by remote
software fingerprinting, absent VM bugs that give unintended
access to the host.

@_date: 2012-09-26 06:01:14
@_author: Seth David Schoen 
@_subject: Re: [tor-talk] Tor and P2P 
I wonder if there's a way to extend the protocol to do ephemeral
hidden services (that are only meant to be used once for a single
inbound connection, perhaps, and that can be set up very quickly
with low overhead).  This might be something like the "reply onion"
concept in the original onion routing, where you can create an
object that represents an explicit route to reach a particular Tor
end user (but where the route is opaque to its users, so they don't
know where the connection they establish with it will go).
My limited understanding of onion routing history is that reply
onions were replaced by hidden services, which are meant to be
long-lived and usable by many clients.  I don't know whether reply
onions disappeared solely on efficiency grounds or whether there
are also bad security consequences.
In existing hidden services both sides are building a path through
the Tor network to the rendezvous, so you don't just have one side
choosing the complete path.  I have a vague recollection that there
are bad consequences if you allow one party to choose another party's
complete path through the network -- presumably based on the idea of
making the other party use an entry node secretly controlled by the
hidden service operator (!!!) in order to identify them.

@_date: 2013-10-28 13:30:03
@_author: Seth David Schoen 
@_subject: Re: [tor-talk] =?utf-8?q?PrivateCore_Demonstrates_Industry=E2=80=99s_?= 
Preventing the provider from viewing the virtual CPU's state is the
main goal of their PrivateCore software.  They encrypt the RAM that
contains the VM and they try to ensure that the key used to encrypt
it never leaves the CPU and that the providers don't get to see that
Evidently right now they use a TPM for bootstrapping, so the weak link
is probably the TPM: the provider could try to reboot the host while
attacking the TPM in some way.  If they had a completely fake or cracked
TPM that other people accepted as genuine, they could try to make it
boot the PrivateCore instance itself in a (provider-controlled) VM
pretending to be native hardware.
(The other potential weak link is exploiting the OS running inside the
VM.  Then even if you don't know the crypto keys that encrypt the memory,
you can tell the OS to let you monitor its processes or disk.)
There should be at least a brief discussion of this in the liberationtech

@_date: 2013-10-23 04:48:20
@_author: Seth David Schoen 
@_subject: Re: [tor-talk] Linux Kodachi 
Also enough _Linux_ stuff that source code must be made available.

@_date: 2014-07-03 23:58:49
@_author: Seth David Schoen 
@_subject: Re: [tor-talk] BlackHat2014: Deanonymize Tor for $3000 
The description on the Black Hat site refers "a handful of powerful
servers and a couple gigabit links" that are operated for "a couple
of months", which sounds like this involves actually running nodes and
getting the attack targets to build circuits through them.

@_date: 2014-07-14 19:11:56
@_author: Seth David Schoen 
@_subject: Re: [tor-talk] Questions about NSA monitoring of Tor users. 
It will be interesting to see what ISPs do with IPv6 assignment policies
and how much they can be influenced about this.
I was thinking of writing a blog post describing how, depending on
what the ISPs do about this, IPv6 could be drastically better than IPv4
for user privacy, or drastically worse.  After all, an end-user could
get anything from an unrecognizably different IPv6 address _per-TCP
connection_ to a single globally unique IPv6 address _per-device
lifetime_.  The latter was originally seriously proposed as the default
way of assigning IPv6 addresses because it would make some kinds of
roaming easier -- using the device EUI-64 directly in the address.
When talking to journalists about IP geolocation recently, I've been
using the example of Skyhook Wireless.
They're combining observations from multiple sources, including queries
from mobile devices that are connected to wifi networks, to build
associations between locations and IP addresses that may be down to the
building level.  (Google and Microsoft, at least, also have device
positioning services that make similar kinds of observations.)
