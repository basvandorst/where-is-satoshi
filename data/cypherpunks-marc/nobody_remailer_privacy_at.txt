
@_date: 2001-09-14 21:30:02
@_author: Anonymous 
@_subject: "bespectacled, nerdly remailer operators" 
Pictures of three of these bespectacled, nerdly remailer operators:
Clearly individuals are enemies of the state. Expect the pictures above to
be broadcast and rebroadcast on the evening news after the SWAT teams
eliminate this threat to the sheeple. Expect similar photos of other remailer operators, Photoshop touch-ups used liberally if required.

@_date: 2001-09-20 16:06:03
@_author: Anonymous 
@_subject: Congress 
It's beginning to look more and more like Tim is absolutely right.
There are just one fuck of a lot of people in this country that really,
seriously, need killing. It is utterly amazing how quickly, because
of one incident, all these "leaders" are jumping thru the "trash
the Constitution" hoop.   And, of course, anyone who attempts to actively oppose their fascist
schemes, is "aiding and abetting terrorists". Is there no way out
of this?

@_date: 2001-09-24 05:16:03
@_author: Anonymous 
@_subject: Expectation of privacy in public? 
For the lawyers and lawyer larvae out there...
In an article in the San Francisco Bay Guardian this week, there is an
article about MUNI's policy of making audio recordings of passengers.
Nathan Ballard of the City Attorney's Office told the Bay Guardian that
they were well aware of the policy and approved it. "There are no
expectations of privacy in public," he said. Ballard asserted that the
policy was constitutional and did not fall under any wiretapping laws.
When asked if all of the vehicles that employ this surveillance policy
post signs to inform passengers that their conversations are being
recorded, he said, "This policy does not require signs."
Frankly, if I'm sitting in the back of an empty bus, talking to the person
next to me, it's my opinion that there certainly is a reasonable expection
of privacy. Does anyone more qualified than I care to tell me why I'm right or wrong?
Legal or not, I'm also curious to see what the EFF has to say about this
wonderful incarnation of Big Brother.

@_date: 2001-10-10 04:50:04
@_author: Anonymous 
@_subject: Re: Talking to the Press Considered Harmful 
what's the point of having beliefs if one refuses to live by them?

@_date: 2001-11-24 07:23:05
@_author: Anonymous 
@_subject: Re: Pricing Mojo, Integrating PGP, TAZ, and D.C. Cypherpunks 
It's inference and observation based on their changing policies and
statements about mojo over the course of the project.  At first it was
going to be relatively hard to get and eventually be interchangeable
with money.  Then everyone got upset because they kept losing mojo,
partially because of bugs and mistunings which allowed certain people to
game the system and steal it away from others.  So they made mojo easier
and easier to get.  Eventually they decided not to display the amount
of mojo you have so that you wouldn't worry so much about losing it.
The specific problem of how to fairly give people initial mojo wasn't the
main driving factor but it was part of this constellation of problems
that they ran into.  If you've got to make mojo essentially free in
order to deal with other problems, then logically it wouldn't work that
well as a currency substitute.  It is this last step which is inference,
the rest is observation.
Anonymous posters don't have integrity; that is a property of persistent
identities.  With anonymity each message must stand on its own, without
the benefit of its author's reputation for integrity or intelligence.

@_date: 2001-11-18 21:41:02
@_author: Anonymous 
@_subject: Cookbooks and Pigs (Was Re: HOWTO Build a Nuclear Device) 
How did the Sheriff's Department manage to do this?

@_date: 2001-11-26 18:31:02
@_author: Anonymous 
@_subject: Re: HDCP break and DMCA 
It's understandable that you would be concerned about the DMCA.
Niels Ferguson raised the same issues when he decided not to publish.
Why, then, did you go ahead with publication?  This is the part which
is hard to understand.  Niels decided not to publish, you and your
co-authors apparently came to the opposite conclusion.  Rhetorically
you are saying the same things as him, but your actions are different.
It would be interesting to hear more about how you reconcile the decision
to publish this result with the belief that the DMCA makes publication
in this field too risky.

@_date: 2001-12-11 01:46:04
@_author: Anonymous 
@_subject: Re: "Spoiling" digital cash 
Yep, see Marcus Jakobsson, "Ripping Coins for Fair Exchange",
  The idea is analogous to
tearing a $100 bill in half and giving half to the taxi driver so he'll
wait while you go take care of some business.  The two halves together
are worth $100, but either alone is worthless.  Once you give him the
first half you're out $100, so you have no incentive to cheat him by
not giving the other half when you come back.
A simplification of Jakobsson's scheme works with Chaumian blinded cash
where the bank's RSA exponent e = e1*e2, where e1 > 1 is an odd integer
and e2 is prime.
The passenger (in the taxi example) withdrew the coin by choosing a
value x which had some special structure, blinding it and getting a
signature s on x such that s^e = x, mod n.  To spend the coin normally
he would reveal x and s which the bank would accept as it satisfies this
To rip the coin, the passenger gives the taxi driver t = s^e1, along
with x.  The driver can verify that t^e2 = s^(e1*e2) = s^e1 = x mod n
which tells him that it is a real coin.  He also sends (t, x) to the
bank, which verifies that no such x has been spent before (no double
spending) and also stores x as a ripped coin such that only the driver
can spend it.
When the passenger comes back he gives the taxi driver s, the real RSA
signature, so the driver can now spend the coin for good.  The passenger
can't renege and spend the coin himself because the driver has put a
block on that x value in the database.

@_date: 2001-12-16 17:17:05
@_author: Anonymous 
@_subject: Re: CNN.com on Remailers 
How much would be gained by using DC-Nets for inter-remailer communication?
Generally, DC-Nets increase the traffic by a factor equal to the number
of nodes in the net.  Suppose there were a core set of always-connected
remailers with about a dozen members, few enough to make a DC-Net
practical given current traffic loads.
Would this eliminate the benefits of remailer-to-remailer cover traffic?
Would it allow for shorter remailer chains while maintaining anonymity?
How much benefit do you get for the cost?

@_date: 2001-12-13 00:19:02
@_author: Anonymous 
@_subject: Re: CNN.com on Remailers 
Do you know how many messages are going through the remailer network
now?  How many do you think the average remailer processes in a day?
Now, how many do you think a remailer ought to be handling in order for
there to be enough traffic for people to feel safe?
Let's see some quantitative figures, both to show that you've done your
homework and to make clear what security assumptions you are making.

@_date: 2001-12-25 23:14:02
@_author: Anonymous 
@_subject: RE: Illusional delusions 
You have a problem with simple sentences. Also, when you want to switch
the arguments you must do it in more intelligent and coherent way.
Payments should happen. The solution is to make them invisible.
But let me do it in simpler terms:
I owe Mr. Melon 100 credits, which is well-established and provable (to
me and him) in our private currency. Mr. Melon owns Mr. Nomen 50
credits. It is very easy to transfer my debt and then I can perform some
task for Mr. Nomen worth 50 credits. This happens often in real life.
It's called barter and it is taxable, if it can be proved. Never
converting anything to paper/book dollars makes it extremely hard to
prove. People do favours to each other essentially on the same bases,
sans bookkeeping or crypto. Once I did some programming for the guy and
instead of paying me he gave his $2000 WW1 rifle to the mutual friend
who wanted it and he took it towards commission on a real-estate
transaction he did for me. This is a rare. Software could make it more
convenient. Just peg a credit to a dollar for the start.
That is the whole point of crypto. Once I declare your breathing to be a
crime (and I have a bigger gun than you do) you better conceal it.
I am talking about single-issuer currency.
High-interest credit cards or store credit-cards (same as high-interest
since they limit you to a single source) that young people or people
with no credit can get, for instance ?
Mortgage insurance for those with low down-payment ?
Maybe Mr. Anonymous who frequents South Africa will mediate transactions
between canadians and south africans, since he knows both sides, for a
fee ?
High-priced shysters introducing their clients to each other ?
Of course. I never buy controlled substances from dealers, for instance.
Always from end-users I knew for years.
You are just plain stupid, aren't you ? It takes some intelligence to do
ad hominems, you know. I sometimes make this mistake, taking plain idiocy
for misinformed insight worth arguing.
Go to a bookstore, there is a shelve labeled "Reference", take a book
called "Dictionary" and look up Illusion (two "l"s, not one):
Main Entry: il7lu7sion Pronunciation: i-'l|-zh&n
Function: noun
Etymology: Middle English, from Middle French, from Late Latin
illusion-, illusio, from
Latin, action of mocking, from illudere to mock at, from in- + ludere to
play, mock --
more at LUDICROUS
1 a obsolete : the action of deceiving b (1) : the state or fact of
being intellectually
deceived or misled : MISAPPREHENSION (2) : an instance of such deception
2 a (1) : a misleading image presented to the vision (2) : something
that deceives or
misleads intellectually b (1) : perception of something objectively
existing in such a way as to cause misinterpretation of its actual
nature (2) : HALLUCINATION 1 (3) : a pattern capable of reversible
3 : a fine plain transparent bobbinet or tulle usually made of silk and used for veils,
trimmings, and dresses
- il7lu7sion7al  /-'l|zh-n&l, -'l|-zh&-n&l/ adjective

@_date: 2002-01-31 23:09:04
@_author: Anonymous 
@_subject: beheading the Saudis 
"They hit me in the testicles with a stick. Then they hit
me on the chin each time I went down," he said. "They
threatened to plant drugs in my house to get my wife
and child beheaded."
-a Briton jailed in Arabia
Yep, these are the folks the US was created to defend.. its our
manifest destiny
Blowback is a spook's term for *feedback*... Osama is merely a servomechanism

@_date: 2002-01-31 18:07:02
@_author: Anonymous 
@_subject: Wearing masks in public 
Islamic veil costs woman driver's license                               Published 1/30/2002 1:32 PM
                              WINTER PARK, Fla., Jan. 30 (UPI) -- An attorney said he believes a Florida law will help overturn a decision
                              to deny a woman a driver's license because she refused to remove her Islamic veil for the identification
                              picture.
                              Sultaana Freeman says her religion forbids her from revealing her face to strangers.
                              Freeman had a Florida driver's license until Dec. 17 when the state revoked it because she refused to allow
                              examiners to take her photograph without a veil that shows only her eyes and forehead.
                              "It was not a problem until after Sept. 11," said civil liberties attorney Howard Marks, referring to the terrorist
                              attacks on the World Trade Center in New York and the Pentagon near Washington.
                              Marks filed a petition in circuit court in Orlando on Jan. 17 seeking to overturn the decision. He said similar
                              regulations have been overturned in Indiana, Colorado and Nebraska.
                              Marks is centering his approach on the Religious Freedom Restoration Act of 1998, which was passed to
                              shore up provisions of the Florida Constitution regarding free exercise of religion.
                              "It's a strong legal argument," he said.
                              No hearing dates or deadlines have been set in the case.                               But state officials are not backing down.
                              "Florida law requires a full facial view of a person on their driver's license photo," said Robert Sanchez of the
                              Department of Highway Safety and Motor Vehicles. "We have no choice but to enforce it."
                              Freeman is unemployed so she can care for her 7-month-old child, but she said when she lived in Illinois,
                              working as a civil engineer for the state utility company, she had no problem with her license. She said she
                              was photographed with her veil.
                              Freeman is a former evangelist preacher who converted to Islam about five years ago.
                              Altaf Ali, executive director of the Florida chapter of the Council on American-Islamic Relations, said there
                              are three other Muslim women who have been refused licenses because of their veils.
                              "I'm sure there's a lot more that's happening and not getting reported," Ali said.

@_date: 2002-01-30 23:56:02
@_author: Anonymous 
@_subject: domestic surveillance: nitrate false alarms shuts SFO 
Thousands Evacuated at S.F. Airport
By KIM CURTIS, Associated Press Writer SAN FRANCISCO (AP) - Thousands of people were evacuated
from San Francisco International Airport early Wednesday after
security guards detected explosives residue on the shoes of a man who
disappeared into the crowd, an airport spokesman said. ``When they went to stop him, he didn't stop,'' spokesman Mike
McCarron said. A search for the man was underway. The explosive material could be anything from fireworks residue to
nitroglycerin tablets, McCarron said. It was detected after a gauze-like
material was wiped across the man's shoes, then put through a
machine.

@_date: 2002-01-03 00:18:06
@_author: Anonymous 
@_subject: w00w00 --AOL msgr gets buffer overflowed 
New Hole Could Hurt AOL Messenger
By D. Ian Hopper
   AP Technology Writer
Wednesday, January 2, 2002; 3:09 PM
   WASHINGTON  A security hole in AOL Time Warner's Instant Messenger program used by millions of users worldwide can let a hacker take full control of a victim's computer, according to security researchers and the company.
An AOL spokesman said the problem will be fixed soon, and users won't have to download anything.
"We have identified the issue and have developed a resolution that should be deployed in the next day or two," AOL's Andrew Weinstein said. "To our knowledge, this issue has not affected any users."
The problem affects newest versions as well as many earlier iterations of AOL's Instant Messenger program.
Discovered by a loose team of international researchers called 'w00w00,' the hole is a "buffer overflow," like the problem recently found in Microsoft's Windows XP.
By sending a stream of junk messages to the program, a hacker can overwhelm the software and make the victim's computer run any commands the hacker wants.
"You could do just about anything, (you could) delete files on the computer or take over the machine," w00w00 founder Matt Conover said.
Conover said w00w00 has over 30 active members from 14 states and nine countries. Until AOL's fix is released, Conover said, Instant Messenger users should restrict incoming messages to friends on their "Buddy List."
"It will at least keep someone from attacking you at random," Conover said, but it wouldn't help if the attack code is added to a virus that propagates without the victim's knowledge. AOL said it has not given its users any advice in the interim.
Conover said the group found the problem several weeks ago, but didn't contact AOL until after Christmas. The group didn't get any response from AOL through an e-mail during the holiday week, he said, so w00w00 released details  and a program that takes advantage of it  to public security mailing lists less than a week later.
The program released by w00w00 remotely shuts down a person's Instant Messenger program, but could be modified to do more sinister things.
That practice is under scrutiny by security professionals. While some independent researchers argue for a "full disclosure" policy and say software vendors are trying to cover up their mistakes, many companies say users are better protected if the company has time to react.
Russ Cooper, who moderates a popular security mailing list and works for security firm TruSecure, said Conover's actions are "I think it's better to provide details of the exploit and then let other people write the actual code," Cooper said. "Unfortunately, these are fundamentally naive people with a very childish view of the world."
Cooper said he let Conover send the information out through his mailing list, but only did so after noticing it was released through other channels as well.
Conover said w00w00 set a New Year's deadline for sentimental reasons, because it was the anniversary of the group's last major security release. He defended the disclosure of the attack program.
"This is the approach that w00w00 has historically taken to the problem," he said. "For us it means providing all the information we have available to the security community."
AOL's Weinstein said the company would have appreciated more warning.
"We'd encourage any software programmer that discovers a vulnerability to bring it to our attention prior to releasing it," Weinstein

@_date: 2002-01-07 20:40:09
@_author: Anonymous 
@_subject: Re: CFP: PKI research workshop 
It's not clear what you mean by the limited threat model in encrypting web
forms, but one correction is necessary: known plaintext is not an issue.
See the sci.crypt thread "Known plaintext considered harmless" from June,
2001 (available by advanced search at groups.google.com).  Especially note
the perceptive comments by David Wagner and David Hopwood.  There is no
need to be concerned that encrypted web forms contain known plaintext:
no plausible threat model can exploit that information.

@_date: 2002-01-24 02:56:05
@_author: Anonymous 
@_subject: Re: Ecash fraud resolution 
If there is no fraud dispute mechanism, and Bob is paying Alice, only
Alice can profit from the fraud.  Presumably when the fraud occurs,
whichever party is at fault, Alice will refuse to deliver Bob the goods.
Hence if Bob defauds Alice by giving her bad cash, he will not accomplish
anything.  He will not get the goods, he will not get anything.  At most
he can complain that she cheated him, but if he is lying anyway he can
probably make such complaints without bothering to go through the trouble
of doing a real transaction with her.
So the real need with a reputation system is to detect the case where
the seller, rather than the buyer, commits fraud.  Luckily this is
easier as sellers often seek to build up their reputations and develop
persistent identities.
eBay is a good example of a reputation system in action.  It is not
perfect but it does a reasonably good job.  Many buyers will refuse
to bid on auctions if the seller has a reputation less than 20 or so.
Sellers generally have much less stringent requirements on buyers;
at most they want to see a positive reputation.

@_date: 2002-01-25 07:48:06
@_author: Anonymous 
@_subject: Re: Thinking outside the box, deviously 
The remaining step then is to show that the volume is independent of
the size of the sphere.  We will show that in fact the volume is equal
to that of a sphere of radius 5.  We will do this by showing that the
cross sectional area of the volume in question at each slice is equal to
the cross sectional area of the same slice through a sphere of radius 5.
Let the sphere radius be s, and the plug radius be p.  The first
relation we have is:
(1) s^2 = p^2 + 5^2
Let the z axis run down the length of the plug, so that the system is
symmetrical around the z axis.  Compare the sphere of radius 5 with the
(larger) sphere-plug as z goes from -5 to 5.  For each z value we will
show that the cross section of the two is the same.
For the first case, the sphere of radius 5, the cross section is a
circle.  Call its radius, r.  Then we have:
(2) r^2 + z^2 = 5^2
The area is pi r^2 and using (2) to substitute for r^2 we get as the
cross sectional area of the sphere of radius 5:
(3) A_sphere = pi (5^2 - z^2)
Now for the larger sphere minus plug.  The cross section is an annulus
(the space between two circles).  The inner radius of the annulus is
always p regardless of z, so the area of the inner circle is pi p^2.
Substituting (1) above we get:
(4) A_inner = pi (s^2 - 5^2)
Let the radius of the outer circle at height z be t, and we have
(5) t^2 + z^2 = s^2
similarly to (2).  The area of this circle is pi t^2 which is:
(6) A_outer = pi (s^2 - z^2)
The area of the annulus is A_outer - A_inner or:
(7) A_annulus = pi (5^2 - z^2)
which is the same as (3), as required.
Now let's see you shortcut this proof by "cheating".

@_date: 2002-01-30 15:46:16
@_author: Anonymous 
@_subject: Judge: no flags, or all flags, msgs 
[Kudos to these two women]
Flag Policy Voided
Freeways: Caltrans must either allow all signs or remove everything posted, judge rules.
By HUGO MARTIN, TIMES STAFF WRITER
A federal judge in San Jose ordered Caltrans on Tuesday to adopt a
consistent policy for removing signs and banners from freeway
property, even if it means taking down the hundreds of American flags
hung in the wake of the Sept. 11 terrorist attacks.
                     The preliminary injunction stems from a lawsuit filed by two Scotts
                     Valley women who charge that the state Department of Transportation
                     has a policy of removing banners with politically unpopular messages
                     while allowing flags to fly on overpasses and bridges.
                     "Government cannot pick and choose among the viewpoints that can
                     be expressed," said Nathan Benjamin, an attorney for Cassandra
                     Brown and Amy Courtney. In his ruling, U.S. District Judge Ronald
                     M. Whyte said Caltrans cannot allow the public to hang flags
                     alongside freeways while barring all other displays on bridges and
                     overpasses.
                     In response, Caltrans must either remove all banners, flags and signs
                     from freeway property or draft a policy that permits all such displays,
                     without regard to the content.
                     Caltrans spokesman Dennis Trujillo said Caltrans will abide by the
                     ruling and remove all banners and flags. He said it is still undecided
                     whether the state will continue to fight the lawsuit or simply adopt new
                     rules.
                     A court date for the suit has not been set.
                     The case began in November when Brown and Courtney hung a banner on a freeway overpass in
                     the Northern California community of Scotts Valley. The freeway overpass was already adorned
                     with a large American flag and a banner that read "SCNY" (Santa Cruz Loves New York) when
                     the women decided to add their 7-by-5-foot banner, which read: "At What Cost?"

@_date: 2002-03-28 19:46:07
@_author: Anonymous 
@_subject: Re: gnutella's problems (Re: network topology) 
You should try again.  That article you quoted about Gnutella's problems
was over a year old.  The network has improved enormously in the
past year.  Today I would say that 70% of downloads succeed, although
of course it works better for more popular files.  We have restarting
of failed downloads, and simultaneous downloads from multiple users.
With a widely shared file I sometimes max out this DSL line at 80-90
KB/sec downloads (that's bytes not bits).
One problem is that searches are still slow and it is still hard to find
uncommon files.
FastTrack is going to die.  The spyware installed by the clients pisses
users off, and the use of centralized servers is just too big a target for
the infinitely deep pockets of the recording industry.  Gnutella is now
a very adequate replacement, which was certainly not true a year ago.
In the long run, decentralized networks are the only ones which can

@_date: 2002-03-15 21:51:06
@_author: Anonymous 
@_subject: RE: Slashdot | Computers Summarize the News 
Wow, computers summarize the news so Choate doesn't have to!
Did you think of this yourself?

@_date: 2002-03-11 22:08:06
@_author: Anonymous 
@_subject: Re: what's up with *coder*punks @ toad? 
: Your request of Majordomo was:
: >>>> who coderpunks
: Members of list 'coderpunks':
: : madhuv
: rah
Hope you two have a lot to say to each other.
The story is that a few months ago a disk got full and somehow the list
of subscribers got wiped.  So far no one has one back and restored the
list from the backups.

@_date: 2002-03-18 18:43:05
@_author: Anonymous 
@_subject: Re: SF BAY CPUNK call for volunteer lecturers 
Nor can I authenticate you. I have no idea if you are the original anonymous poster, nor do I know that you are really what you claim to be.
It does make sense that I would wish to communicate in secret -- it allows for more freedom in the exchange of information between us. In chosing this particular forum for holding this discussion, you have guaranteed that many people who might otherwise be willing to respond to such a solicitation are unwilling to reveal themselves.
Saying "fuck you" to the silent watchers is easy if you're anonymous.
Alas, it looks like we'll be doing this the hard way...
Who is funding this? Are these sessions free?
What laws would you be challenging? Teaching classes on PGP to citizens of countries to which PGP can be legally exported shouldn't be challenging It appears that you think you are doing something far more naughty than you really are.

@_date: 2002-03-18 07:30:07
@_author: Anonymous 
@_subject: Re: SF BAY CPUNK call for volunteer lecturers 
I am interested in discussing further. Please respond to this list in encrypted PGP email to the following key:
-----BEGIN PGP PUBLIC KEY BLOCK-----
Version: Redacted
-----END PGP PUBLIC KEY BLOCK-----

@_date: 2002-03-23 08:26:05
@_author: Anonymous 
@_subject: Re: design considerations for distributed storage networks 
Another criterion you could use is download speed.  Freenet claims to
solve the "flash crowd" syndrome by automatically spreading the data
out as more requests are made.
Also, you have not distinguished clearly one of the main differences
between the Napster-type file sharing networks and what you are calling
storage-surface networks (what does "surface" mean here anyway?).
The difference is that in the latter you have to explicitly inject the
data to be stored, while the file sharing networks allow you to implicitly
share the data you already have.
A note, your links to various P2P products are a bit moldy (or mouldy
as you would say).  Mojonation.net is dead; the TAZ paper is from 1998.
Here is a list of recent file-sharing P2P products and projects from
1stWorks AlpineB, AudioFindB, BadBlueB, BearShareB, CareScience, Inc.B,
Clip2B, EudoraB, Fatbubble, Inc.B, File Rogue, Inc.B, FiletopiaB,
Frontcode TechnologiesB, GnotellaB, GnutellaB, Harmonic Invention
SoftwareB, Hotline ConnectB, iMesh Ltd.B, iNoizeB, JibeB, Jungle
MonkeyB, KaZaAB, LimeWireB, MangoSoftB, MorpheusB, MysterB, NapsterB,
NextPage, Inc.B, Ogg VorbisB, OhahaB, OnSystems, Inc.B, OpenNapB,
PointeraB, Radio UserlandB, RapigatorB, SoftwaxB, SongbirdB, SongSpy,
Inc.B, Spinfrenzy.comB, Splooge, Inc.B, Swaptor, Ltd.B, ThinkstreamB,
Toadnode.com, LLCB, Tripnosis, Inc.B, VitaminicB, WebDAVB,
And here is a list of "infrastructure" products:
Akamai Technologies, Inc.B, Alliance Consulting, Inc.B, BitziB, Brazil
ProjectB, Consilient, Inc.B, Freenet, The Free Network ProjectB,
Glue Technology, Inc.B, Groove NetworksB, HailStormB, JabberB, Kalepa
Networks, IncB, Oculus Technologies CorporationB, OpenDesignB, Planet
7 TechnologiesB, Prompt2UB, The Free Haven ProjectB, ThinkstreamB,
Tpresence, Inc.B, VeriscapeB, vTrailsB, Zodiac NetworksB,
Other neat ones are OpenPrivacy and of course Peek-A-Booty.  These are
all linked from Not all of these are still going but it shows that there is a lot more in
the P2P file sharing and publishing world than just a few moldering old
cypherpunk projects from the 90s.  P2P has really passed the cypherpunk
world by.
As far as the economics, one of the main lessons of the failure of Mojo
Nation was that Mojo didn't work, or perhaps you might say it worked too
well.  It caused nothing but problems for the operators of the network.
People tried to horde it, they got upset when they were losing Mojo,
they would cheat and steal to get more.  MN steadily downplayed the
importance of Mojo over the life of the project, making it harder to see
how much you had, decreasing its importance in terms of getting data, etc.
Eventually it was practically invisible.
The lesson?  Something may be needed to protect against DoS and similar
attacks, but it's not payment.  Look at how successful Napster-style
file sharing networks have been, despite predictions of parasitism since
there is no economic reward for sharing.
Unfortunately many of the programmer types who have been pushing P2P
development also happen to be libertarians.  Their sad faith in that
ancient religion prevents them from learning from experience.  They see
everything through the distorting prism of their ideology.  If people
are going to learn from the successes and failures of the past, they
must have clear vision and the courage to look beyond the circumscribed
boundaries imposed by their political beliefs.
Apparently you didn't notice but there was a huge influx of commercial
money flowing into P2P starting about two years ago.  Everyone wanted
to be the next Napster, forgetting or ignoring that Napster never made
any money.  P2P is actually yesterday's news now.  The money is quickly
evaporating and it will be left to the hobbyists, i.e., us.

@_date: 2002-03-24 07:47:04
@_author: Anonymous 
@_subject: Re: 1024-bit RSA keys in danger of compromise 
Is there anything written, even a paragraph or two of back of the
envelope scrawls, to justify these numbers?  How big a factor base are
they assuming?  What sieving/factoring method are they using to generate
the relations?  Are they following Bernstein's proposal to abandon
sieving and try to factor values directly using massive parallelism?
Rough calculations on the cryptography list showed that Bernstein's
strategy of replacing sieving with direct smoothness testing is
not feasible.  For a 1024 bit RSA modulus, assuming a factor base of
size approximately 2^36, we need to test approximately 2^89 values for
smoothness in order to get enough relations.  These values are several
hundred bits in length.
Assuming each smoothness test (which amounts to finding all the factors
of each of these values up to 2^36 in size) takes 2^18 cycles, the
total number of cycles in this phase is 2^107.  These are not trivial
algorithms, they involve multi-precision multiplication and will require
substantial complexity for each unit on the chip.  Any problem with a
work factor of 2^107 cycles is effectively impossible even if you've
got a billion dollars to spend.
Understand this: Bernstein only had two ideas in his paper.  The first was
to replace sieving with direct smoothness testing, which is asymptotically
faster (but almost certainly not faster for keys of practical size;
sieving is just too efficient).  The second was to speed up the matrix
solving phase by building a smart computing fabric.
It's possible that you can throw out the first idea and just use the
clever matrix solver, but that's not going to give you the kind of
speedups claimed by his paper (the factor of 3 in modulus length).
It seems very questionable that this change alone would let you solve
RSA keys in "seconds to minutes", unless you already thought that you
could solve them in hours to days using conventional technology of
comparable expense.
It's too bad that Lucky took the precipitous action of revoking his keys
before the community has had a chance to perform some peer review of
these claims of feasibility.  We need to see the analysis, rough though
it may be, so we can judge for ourselves whether these remarkable claims
are sound.

@_date: 2002-04-11 06:30:07
@_author: Anonymous 
@_subject: Re: all about transferable off-line ecash (Re: Brands off-line 
[By forwarding this mail to the DBS list, Robert Hettinga agrees that
 he is an arrogant, obnoxious, power-hungry asshole with no moral
 integrity whatsoever.]
Again, this escrow idea really can't work.  Suppose Alice withdraws $100.
Exactly how much additional would have to be withdrawn and put into an
escrow account?  $100?  That would cover only one double-spend.  But if
someone is going to cheat and double-spend, knowing it will be detected
later, obviously they will grab for as much as they can.  Alice would
have to put aside enough for hundreds or thousands of double-spends,
or even more.  So every time she withdraws $100, she has to set aside
$100,000 in an escrow account.  Does that sound realistic?
Then, the money stays in the account for the expiration period of the
coins, which would presumably be for weeks or months at least.  You
don't want coins expiring more often than that or there is too much
danger of people's money going bad while they carry it.
It's one thing to do this with pre-paid services, but quite another for
a banking system which aims to be universal.  Most people and businesses
would find it absolutely impossible to use a payment system which had
these properties.  Every time they got some income, they can spend only
a small fraction of it, depending on how big the escrow multiplier is.
Hopefully it is clear that escrow cannot work as a way of dealing with
double-spending after the fact.  The only other alternative is for the
bank to Know Its Customer intimately, and for there to be some kind of
worldwide police which can track and arrest people anywhere.  This would
entail strengthening and centralizing international law enforcement,
exactly the opposite of the trends we would want to encourage.
Okay, that sounds pretty good.  But it's specific to Brands cash, right?
The generic transferable off-line cash you described earlier can't
do that.
Of course Brands is patented up the wazoo.  It's amazing the harm
he and Chaum have done to the world by locking up their best ideas.
And they didn't even get rich.  What a waste.  If either of them had
the balls to put their patents into the public domain, they could make
a very comfortable living just from consulting and speaking fees.
Please, this is such ancient history.  MTB's ecash died a long time ago,
we don't need to keep rehashing how to work around its limitations.
The right way to do Chaum cash with two-sided anonymity is simply to allow
anonymous coin exchanges at the bank.  There is no issue in recognizing
the payee's deposited coins if he is fully anonymous and gets fresh coins
at that time.  In fact there don't need to be bank accounts at all, and in
further fact there doesn't need to be a bank; just a coin exchanging mint.
We talked about this a while ago.  You start it up and it emits one
coin, which represents all of the value of this mint's money supply.
From then on it does only one operation: you give it $X in old coins,
and it gives you $X in new coins (possibly partitioned differently).
When someone pays Alice, she turns it in at the bank and gets new coins,
incidentally checking the old ones for validity and double-spending.
Her new coins are completely untraceable and ready for whatever use she
desires.  She keeps all her money in her wallet.  Third parties can offer
secure backup services, exchange to other currencies, and even act as
banks with accounts, loans and interest.  None of this affects the mint.
That's enough for an ecash system.  It's simple, online, fully anonymous
and untraceable.  You might even be able to find someplace where it was
legal, since the mint is not a bank.  Or what the hell, put the fully
automated mint onto a satellite and shoot it into orbit, with wireless
data links to the net.  At least it'd give the military asat people
something to aim at.

@_date: 2002-04-01 21:16:10
@_author: Anonymous 
@_subject: American Homeland Radio 
You may just THINK that it's April 1st thing ...
(and live at  )

@_date: 2002-04-01 07:19:03
@_author: Anonymous 
@_subject: Re: 1024-bit RSA keys in danger of compromise 
Wow, really, Joe?  You went through a long thought process?  You dug
through old textbooks?  That's very impressive.  At least, it would be
if you were still a schoolboy.
Out here in the real world we have this crazy idea called "evidence".
When someone makes a claim, like that Bernstein's ideas mean that we
need to increase keysize by 1.5, we like to know WHY.  We like to see
some reason why we might believe a claim like this.
Here's a hint, Joe.  Telling people about all the hard work you went
through to come up with these amazing conclusions is WORTHLESS.  You
want to impress us?  We don't want to hear about your tireless hours
studying old text books.  We want to see your results.
If you have determined that we need keys 1.5 times bigger, then show
us why.  If you have a real analysis of what it would take to build
Bernstein's machine, how it would work in a real problem, what the
parameters are which are hidden by Bernstein's o(1) fudge factors,
then prove it.
No one has done this yet.  You have now joined the club of people
who claim to have done the math and determined that his machine will
work, but who for some reason won't print anything about their results.
What is it about the Bernstein machine that leads people to make claims
that they won't back up?

@_date: 2002-04-09 19:33:09
@_author: Anonymous 
@_subject: Re: all about transferable off-line ecash (Re: Brands off-line 
Yes.  You missed the point that the lack of anonymity is not in the coins,
but in the protocol.  An off-line system requires people to identify
themselves to the bank at withdrawal time, so that their identities can
be embedded in the coin.  That means no anonymous exchanges at the bank.
This is unlike an online system, which could allow someone to exchange
coins for fresh ones who never identifies himself to the bank, who has
no account at the bank, who in fact has never communicated with the bank
in any way, shape or form ever before.  There are no records of this
guy, his identity, how often he uses the bank, the amounts which he
deposits and withdraws.
That's real anonymity.  Off-line systems can't do this because they
need to track down double-spenders after the fact.  They accumulate
all kinds of information about their customers.
Reputation is overrated.  Here's a clue: if you want to know what people
really think of your ideas, post anonymously.
It's not you, it's Brian Minder.  Adam is on the cypherpunks-moderated
list.  Note the almost 24 hour delay between the initial response to his
message by Anonymous and Adam's reply.  This is almost certainly due to
moderation-imposed delay (plus time zone issues).  We might as well try
to converse by carrier pigeon.  Moderated lists do not support lively

@_date: 2002-04-09 16:17:06
@_author: Anonymous 
@_subject: Re: all about transferable off-line ecash (Re: Brands off-line 
Two problems with this escrow idea.  First, as noted before, there is no
limit on how much can be double-spent in a short time, hence the escrow
account can't cover it.  This is not just a minor flaw, it makes the whole
escrow idea unworkable, because it completely fails to achieve its goal of
forcing the user to make good his double spends.
And second, because the deposit is unlinkable to the withdrawal, there is
no way for the bank to know when it can safely release the escrow amount
back to the withdrawer.  How long is the bank going to hold onto those
escrowed funds?  A week?  A month?  The withdrawer can simply wait until
after that time interval and then double spend without losing a cent.
And how many people are going to want to use a bank which makes them
set aside an equal amount of every withdrawal for some extended period?
That is absolutely impossible given how most people and businesses manage
their cash flow.
Are you saying that if Alice pays Bob, he can anonymously exchange the
coins and end up with new fresh coins with ALICE's identity in them?
That's great, he can double spend all he wants and she ends up going
to the pokey.  No thanks.

@_date: 2002-04-09 06:37:05
@_author: Anonymous 
@_subject: Re: all about transferable off-line ecash (Re: Brands off-line 
[Copied to Adam so he doesn't have to wait for some moderator to get
off his fat ass and approve it.  And BTW permission is NOT granted to
forward this or any part of it to the DBS list because Hettinga is an
asshole who kicks people off his list for spite.  He can piss in his
own sandbox if he wants but we don't have to play in it.]
It's not just an extra feature; an off-line system inherently requires
users to identify themselves to the bank at withdrawal time.  It cannot
allow users to anonymously exchange coins at the bank.  So it has an
inherent lack of anonymity which is not present in an online system.
Furthermore, off-line coins require a complex infrastructure to work.
Unlike online systems, where cheating is impossible, off-line systems
attempt to locate and punish cheaters after the fact.  How can that
possibly work in an Internet system where people may be engaging in
transactions all over the world?  If someone cheats you from Timbuktu
do you really expect the cops over there to track him down for you?
Or maybe the bank will make good by forcing each person to keep a
certain amount in their account to pay off creditors they have cheated?
The problem there is that there is no limit to how fast people can cheat
in an off-line system, so there is no way the bank can force people to
keep enough in their account to cover cheating.
In short, off-line cash simply can't work in an Internet economy.
It violates the fundamental nature of the net, which is distributed and
anonymous.  An old cypherpunk aphorism says that any internet protocol
which ends with "then the cops track down the bad guy" is fundamentally
flawed.  Off-line cash is a non-starter by this criterion.
Most of the anonymity features are just as applicable in an online
system where people can exchange coins without identifying themselves.
This allows for fully anonymous transactions with the bank and accountless
You talked about moneychangers, but the discussion was confusing.
What exactly is a moneychanger?  You seem to have an unstated assumption
that moneychangers wouldn't be allowed by the bank and this was a way
around that.  But if transferrable off-line cash allows moneychangers,
which the bank won't allow, then such a bank probably wouldn't provide
for transferrable off-line cash either.
Anyway, what the hell is a moneychanger, and why wouldn't a bank allow
As for hidden banks, there is no evidence yet that people are clamoring
to trust their hard earned savings to a bank which won't even show its
face and which could abscond with the entire money supply at any time
without penalty.
Turning to the fact that the off-line coin chains are linkable, that's
such an ugly blot on the whole idea that it deserves to kill it on those
grounds alone.  In one stroke you've gone from mathematical anonymity to
"somewhat" anonymity.  It's reminiscent of Dan Simon's fully linkable
"cash", where he offered the same sort of lame ideas like spending to
yourself a few times.  If all you want is pretend anonymity then don't
bother with the fancy mathematics.  Real anonymity means unlinkable coins.
End of story.
Linkability can't be defeated.  The Chaum&Pedersen paper implies that
anyone can collude with the bank to determine if a coin is a later
instance of one they held earlier.  They simulate a second spend of
their earlier coin, and let the bank determine if that produces a
double-spending match with the later one, which it would have to do
if they were both on the same chain.  Hence there is no way even in
principle to avoid chain linkability.
Let's face it, transferrable off-line coins have so many limitations and
weaknesses that they are not worth pursuing.  Going forward, everyone
will be online all the time via wireless connections, as with the current
Blackberry handhelds.  Online systems can provide more anonymity than
off-line, including accountless, transfer based payments, with no need
ever to identify yourself to a bank.  And you don't have to rely on the
Keystone Kops to catch the guy who passed you a bad coin, because you
can protect yourself from getting ripped off in the first place.

@_date: 2002-04-08 02:15:09
@_author: Anonymous 
@_subject: Re: all about transferable off-line ecash (Re: Brands off-line 
The issue with off-line cash is this: has the coin being offered already
been spent?
With on-line cash, the offered coin is immediately deposited at the bank,
hence doubly-spent coins are detected instantly.  With off-line cash
this cannot be done because by definition there is no connection to the
bank.  Hence there is no way to know, off-line, if a coin has already
been spent.
The solution is to embed the identity of the withdrawer into the coin
when it is withdrawn from the bank, in such a way that this identity
will only be revealed if the coin is double-spent.  That provides a
partial solution to the off-line scenario.
A coin is offered off-line, and the recipient again has no guarantee that
it hasn't been spent already.  He accepts the coin anyway, and later when
he gets on-line he tries to deposit it at the bank.  But he learns that
he was cheated; the coin had already been spent.  Now he has a fall-back
solution: the doubly-spent coin reveals the embedded identity of the
party who withdrew it (and who doubly-spent it).  He can call the cops
and try to track down and prosecute the cheater.
All off-line spending schemes work this way.  All they can offer is
the hope of tracking down cheaters after the fact.  They can never
offer the assurance of validity that an immediate on-line check can
With off-line coins, unlike on-line coins, the spender knows more than
he's telling.  He knows secrets about those coins which would reveal his
identity; that is, his identity is embedded in some secret information
associated with the coin.  When he spends it at a shop, he responds
to a random challenge from the shop, using his secret information.
The system is set up so that the shop, and later the bank, can validate
his response as being valid, proving that he truly owned a coin.  For the
double-spending detection, the system is further arranged that if two
different shops offer two different random challenges, then from the
responses to these two challenges, the user's secret information and
therefore his identity is revealed.
To turn this into a transferrable system, we would allow a chain of
transfers before the bank gets involved.  Alice spends the coin with Bob,
who spends it with Carol, who spends it with David, who deposits it at
the bank.  There are two problems.  First, only Alice knows the secret
information associated with the coin.  She can't give all the secrets to
Bob, or else he would know her identity.  So Bob only has a limited amount
of information about the coin.  Second, after this chain of transfers,
if there was double-spending, it might have been anyone along the chain.
The system for double-spending detection has to be able to identify
which person was the cheater.
The solution which Adam describes works as follows.  Each party
pre-withdraws a zero-value coin from the bank.  This is an off-line
coin which has their identity encoded in it, if they double-spend it.
Alice first spends her coin with Bob in the normal off-line way.  Bob ends
up with a transcript sufficient to prove that he received a presumably
valid coin from Alice (but one which might have been doubly-spent).
Now Bob wants to spend with Carol.  He does two things: he gives her
the transcript of Alice's spend with him, which implicitly identifies
the value of the coin; and also he engages in the regular off-line
coin spend with her, using his zero-value coin.
If Carol then spends the coin with David, she does the same two things:
she gives David the transcript of Bob's spend with her (which itself
included the two parts above), and also spends a zero-value coin with
him.  The resulting transcript now has three parts.
So it grows at each transfer, and in the end the transcript is deposited.
If there was a double-spend, someone spent his zero-value coin twice,
and his own identity is revealed.
There is one flaw, which is that Bob could use the same Alice transaction
with more than one zero-value coin, which he after all gets for free.
Carol can't tell that the Alice transaction she sees is the same one
someone else saw, and if Bob uses a unique zero-value coin for each spend,
then Bob's identity will not be revealed as it should be.
The fix for this is that when Bob receives the coin from Alice, knowing
that he is going to pass it on, he must link the specific zero-value coin
he will later use into the transcript he will receive of Alice's spend
with him.  This is done by including a hash of the coin information into
the random challenge he sends to Alice.  Then when he tries to pass the
coin on to Carol, she checks that the zero-value coin he is spending with
her matches the value used in the Alice transcript.  That prevents Bob
from using two different zero-value coins with a single Alice transcript.
So it works, but broadly speaking there are two problems.  First, off-line
coins suck, as described above.  And second, because they grow, it is
possible to tell exactly how many hands a particular coin has passed
through - just count the transcripts of previous spends.  So coins are
not all that anonymous.  And further, there is no re-blinding of the
earlier transcripts.  The Alice transcript is in the clear in all
following uses of that same coin.  Transferred coins are recognizable
and linkable.  Hence they suck even worse than off-line coins.

@_date: 2002-04-26 21:32:08
@_author: Anonymous 
@_subject: Re: objectivity and factoring analysis 
In his paper Bernstein uses a relatively larger factor base than in
typical current choices of parameters.  It's likely that the factor
bases which have been used in the past are "too small" in the sense that
the linear algebra step is being limited by machine size rather than
runtime, because of the difficulty of parallelizing it.  For example in
 we find that the sieving took
8000 mips years but the linear algebra took 224 CPU hours on a 2GB Cray.
If there were a larger machine to do the matrix solution, the whole
process could be accelerated, and that's what Bernstein's figures assume.
Specifically he uses a factor base size of L^.7904, where L for 1024 bit
keys is approximately 2^45.  This is a matrix size of about 50 billion,
50 times larger than your estimate.  So a closer order of magnitude
esimate would be 10^11 for the factor base size and 10^13 for the weight
of the matrix.
The assumption of a larger factor base necessary for the large asymptotic
speedups would increase the cost estimate by a factor of about 50.
Instead of several hundred million dollars, it would be perhaps 10-50
billion dollars.  Of course at this level of discussion it's just as
easy to assume that the adversary spends $50 billion as $500 million;
it's all completely hypothetical.
Actually the sort algorithm described takes 8*sqrt(10^11) or about 2.5 *
10^6 cycles, and there are three sorts per dot product, so 10^7 cycles
would be a better estimate.
Using the larger factor base with 10^13 entries would imply a sort
time of 10^8 cycles, by this reasoning.
Taking into consideration that the sort algorithm takes about 8 times
longer than you assumed, and that "a few" minimal polynomials have to
be calculated to get the actual one, this adds about a factor of 20
over your estimate.  Instead of 4 months it would be more like 7 years.
This is pretty clearly impractical.
Apparently Ian Goldberg expressed concerns about the interconnections
when the machine was going to run at 1 MHz.  Now it is projected to run
10,000 times faster?  That's an aggressive design.  Obviously if this
speed cannot be achieved the run time goes up still more.  If only 1
GHz can be achieved rack to rack then the machine takes 70 years for one
factorization.  Needless to say, any bit errors anywhere will destroy the
result which may have taken years to produce, requiring error correction
to be used, adding cost and possibly slowing the effective clock rate.
Using the larger factor base from the Bernstein paper would increase
the time to something like 10^11 seconds, thousands of years, which is
out of the question.
These estimates are very helpful.  Thanks for providing them.  It seems
that, based on the factor base size derived from Bernstein's asymptotic
estimates, the machine is not feasible and would take thousands of years
to solve a matrix.  If the 50 times smaller factor base can be used,
the machine is on the edge of feasibility but it appears that it would
still take years to factor a single value.

@_date: 2002-04-25 18:21:06
@_author: Anonymous 
@_subject: Re: objectivity and factoring analysis 
In his paper Bernstein uses a relatively larger factor base than in
typical current choices of parameters.  It's likely that the factor
bases which have been used in the past are "too small" in the sense that
the linear algebra step is being limited by machine size rather than
runtime, because of the difficulty of parallelizing it.  For example in
 we find that the sieving took
8000 mips years but the linear algebra took 224 CPU hours on a 2GB Cray.
If there were a larger machine to do the matrix solution, the whole
process could be accelerated, and that's what Bernstein's figures assume.
Specifically he uses a factor base size of L^.7904, where L for 1024 bit
keys is approximately 2^45.  This is a matrix size of about 50 billion,
50 times larger than your estimate.  So a closer order of magnitude
esimate would be 10^11 for the factor base size and 10^13 for the weight
of the matrix.
The assumption of a larger factor base necessary for the large asymptotic
speedups would increase the cost estimate by a factor of about 50.
Instead of several hundred million dollars, it would be perhaps 10-50
billion dollars.  Of course at this level of discussion it's just as
easy to assume that the adversary spends $50 billion as $500 million;
it's all completely hypothetical.
Actually the sort algorithm described takes 8*sqrt(10^11) or about 2.5 *
10^6 cycles, and there are three sorts per dot product, so 10^7 cycles
would be a better estimate.
Using the larger factor base with 10^13 entries would imply a sort
time of 10^8 cycles, by this reasoning.
Taking into consideration that the sort algorithm takes about 8 times
longer than you assumed, and that "a few" minimal polynomials have to
be calculated to get the actual one, this adds about a factor of 20
over your estimate.  Instead of 4 months it would be more like 7 years.
This is pretty clearly impractical.
Apparently Ian Goldberg expressed concerns about the interconnections
when the machine was going to run at 1 MHz.  Now it is projected to run
10,000 times faster?  That's an aggressive design.  Obviously if this
speed cannot be achieved the run time goes up still more.  If only 1
GHz can be achieved rack to rack then the machine takes 70 years for one
factorization.  Needless to say, any bit errors anywhere will destroy the
result which may have taken years to produce, requiring error correction
to be used, adding cost and possibly slowing the effective clock rate.
Using the larger factor base from the Bernstein paper would increase
the time to something like 10^11 seconds, thousands of years, which is
out of the question.
These estimates are very helpful.  Thanks for providing them.  It seems
that, based on the factor base size derived from Bernstein's asymptotic
estimates, the machine is not feasible and would take thousands of years
to solve a matrix.  If the 50 times smaller factor base can be used,
the machine is on the edge of feasibility but it appears that it would
still take years to factor a single value.

@_date: 2002-04-24 09:36:02
@_author: Anonymous 
@_subject: Re: objectivity and factoring analysis 
Not so.  His actual comment, from one of the three messages Google
finds at the above URL, was:
The question is, is it practical?  At the time of that message, February
Yet since then he has had no more substantive comment, just a couple of
snide digs at RSA Labs.
Surely Silverman is indeed as qualified as anyone to judge whether
Bernstein's ideas have any practical value.  Yet almost two months later
he is apparently still unable to make a public judgement.
The fact is, the jury is still completely out on whether Bernstein's
ideas will reduce the cost of factoring 1024 bit keys.  Bernstein doesn't
say they will.  Silverman doesn't say they will.  In fact there almost
seems to be an inverse correlation between how much people know about
factoring and how much confidence they are willing to express that
Bernstein's machine will work for keys of this size.
The main people who have publically declared that Bernstein's machine is
a practical threat are Ray Dillinger, Nicko van Someren, Lucky Green,
and Joseph Ashwood, Since then Nicko van Someren has characterized his
comment as an estimate he came up with on the spot that he later found
was off by a factor of 100 billion.  Lucky Green relied on Nicko van
Someren's estimate.
So far no one who has claimed the machine to be practical has offered
the barest, sketchiest ghost of a design!  The most elementary, simple,
basic parameter which drives the design of such a machine is the size of
the factor base (or bases).  If they would just tell us how big the factor
base was they assumed, how many processing elements were are involved in
the matrix solution phase, and what clock speed they are assuming, that
would basically define that half of the design.  If they then indicated
what algorithm they were assuming for the "sieving" phase, how many
processors and what clock speed, that would define the other half.
Specifying these few parameters would allow a wide range of reviewers
to at least sanity-check the claims.  It should be a minimal requirement
for anyone who wants to claim that the Bernstein machine is a practical
threat to at least tell us the factor base size they are assuming.

@_date: 2002-04-22 03:27:04
@_author: Anonymous 
@_subject: Re: objectivity and factoring analysis 
But what does that mean, to specify (and stand by) the cost of
construction of a factoring machine, without saying anything about how
fast it runs?  Heck, we could factor 1024 bit numbers with a large abacus,
if we don't care about speed.  A cost figure is meaningless unless in the
context of a specific performance goal.
And yet here you say that it took you completely by surprise when someone
asked how fast the machine would run.  In all of your calculations on the
design of the machine, you had apparently never calculated how fast it
would be.
How could this be?  Surely in creating your hundreds of millions
of dollars estimate you must have based that on some kind of speed
consideration.  How else could you create the design?  This seems very
And, could you clarify just a few more details, like what was the size
you were assuming for the factor base upper bounds, and equivalently for
the size of the matrix?  This would give us a better understanding of the
requirements you were trying to meet.  And then, could you even go so far
as to discuss clock speeds and numbers of processing and memory elements?
Just at a back of the envelope level of detail?
No, Lucky made a few big mistakes.  First, he invoked Ian Goldberg's
name as a source of the estimate, which was wrong.  Second, he presented
Nicko's estimate as being more authoritative than it actually was,
as Nicko makes clear here.  And third, he fostered panic by precipitously
revoking his key and widely promulgating his "sky is falling" message.
We wouldn't be in this situation of duelling bias and authority if
people would provide some minimal facts and figures rather than making
unsubstantiated claims.

@_date: 2002-04-20 23:06:03
@_author: Anonymous 
@_subject: What are the red blotches in the Pirelli Tower internal footage? 
In the footage from inside the Pirelli Tower, when the camera pans out over the skyline, there are red blotches which appear along the horizon.  Could this be heat "fogging" the photo-voltaic "film"?

@_date: 2002-04-25 18:47:06
@_author: Anonymous 
@_subject: Re: Lucky's 1024-bit post [was: RE: objectivity and factoring analysis 
What he wrote originally was:
: The panel, consisting of Ian Goldberg and Nicko van Someren, put forth
: the following rough first estimates:
: While the interconnections required by Bernstein's proposed architecture
: add a non-trivial level of complexity, as Bruce Schneier correctly
: pointed out in his latest CRYPTOGRAM newsletter, a 1024-bit RSA
: factoring device can likely be built using only commercially available
: technology for a price range of several hundred million dollars to about
: 1 billion dollars....
: Bernstein's machine, once built, ... will be able to break a 1024-bit
: RSA or DH key in seconds to minutes.
It's not a matter of assuming parallel engineering estimates, but rather
the implication here is that Ian endorsed the results.  In saying that
the panel put forth a result, and the panel is composed of named people,
it implies that the named people put forth the result.  The mere fact
that Ian found it necessary to immediately post a disclaimer makes it
clear how misleading this phrasing was.
Another problem with Lucky's comment is that somewhere between Nicko's
thinking and Lucky's posting, the fact was dropped that only the matrix
solver was being considered.  This is only 1/2 the machine; in fact in
most factoring efforts today it is the smaller part of the whole job.
Neither Nicko nor Ian nor anyone else passed judgement on the equally
crucial question of whether the other part of the machine was buildable.
It is obvious that in fact Nicko had not spent much time going over
his figures, else he would have immediately spotted the factor of 10
million error in his run time estimate.  Saying that his estimates had
not changed is meaningless if he has not reviewed them.
Lucky failed to make clear the cursory nature of these estimates, that the
machine build cost was based on a hurried hour's work before the panel,
and that the run time was based on about 5 seconds calculation during
the panel itself.  It's not relevant whether this was in part Nicko's
fault for perhaps not making clear to Lucky that the estimate stood in
the same shape a week later.  But it was Lucky who went public with the
claim, so he must take the blame for the inaccuracy.
In fact, if Lucky had passed his incendiary commentary to Nicko and
Ian for review before publishing it, it is clear that they would have
asked for corrections.  Ian would have wanted to remove his name from
the implied endorsement of the numeric results, and Nicko would have
undoubtedly wanted to see more caveats placed on figures which were
going to be attached to his name all over the net, as well as making
clear that he was just talking about the matrix solution.  Of course
this would have removed much of the drama from Lucky's story.
The moral is if you're going to quote people, you're obligated to check
the accuracy of the quotes.  Lucky is not a journalist but in this
instance he is playing one on the net, and he deserves to be criticized
for committing such an elementary blunder, just as he would deserve
credit for bringing a genuine breakthrough to wide attention.
They are not mutually exclusive, and the difference is clear.  In the
first paragraph, Bruce is saying that Bernstein's design is not practical.
To get his asymptotic results of 3x key length, Bernstein must forego the
use of sieving and replace it with a parallel ECM factoring algorithm
to determine smoothness.  Asymptotically, this is a much lower cost
approach for finding relations, and this asymptotic improvement plays
a major part in Bernstein's dramatic result.
However, this specific improvement is almost certainly impractical for key
sizes in current use.  There is no way that sieving is going to be slower
than taking each value and doing a brute force ECM factoring effort on it!
We came up with estimates on this list a few weeks ago suggesting that
even with unreasonably extreme parallelism and clock rates, that this
approach would take 100 million years to factor.  (These estimates were
posted 3 weeks before Lucky's alarmist pronouncement.)
What Bruce is also saying, though, is that with sufficient money and
effort using conventional technology for the sieving, it might indeed be
possible to build a machine that could factor 1024 bit keys.  This would
not use Bernstein's sieving improvements and hence would not be a matter
of using his machine.  It has been known for years that factoring 1024
bit keys should be about 10^7 times more expensive than factoring 512.
And 2048 bit keys are another 10^9 times harder.  Obviously every key
can be factored with sufficient resources.
The bottom line is that Lucky made a mistake.  He went public with a
dramatic announcement that turns out to be based on inaccurate and off the
cuff estimates which have since been disclaimed by the relevant parties.
He should have waited a few weeks for Nicko to post his estimates and for
others to respond before sounding the alarm.  It was wrong to broadcast
an urgent warning based on the limited and crude figures available at
the time, which now appear to greatly underestimate the true costs.
Fine, people make mistakes, but they should take responsibility
afterwards.  It would be nice to see Lucky post a message to Bugtraq and
wherever else his first one appeared saying that things don't look quite
so dire as they appeared a few weeks ago, that at this point we have to
adopt a wait and see stance.  But it's probably not going to happen.

@_date: 2002-04-25 18:47:06
@_author: Anonymous 
@_subject: Re: Lucky's 1024-bit post [was: RE: objectivity and factoring 
What he wrote originally was:
: The panel, consisting of Ian Goldberg and Nicko van Someren, put forth
: the following rough first estimates:
: While the interconnections required by Bernstein's proposed architecture
: add a non-trivial level of complexity, as Bruce Schneier correctly
: pointed out in his latest CRYPTOGRAM newsletter, a 1024-bit RSA
: factoring device can likely be built using only commercially available
: technology for a price range of several hundred million dollars to about
: 1 billion dollars....
: Bernstein's machine, once built, ... will be able to break a 1024-bit
: RSA or DH key in seconds to minutes.
It's not a matter of assuming parallel engineering estimates, but rather
the implication here is that Ian endorsed the results.  In saying that
the panel put forth a result, and the panel is composed of named people,
it implies that the named people put forth the result.  The mere fact
that Ian found it necessary to immediately post a disclaimer makes it
clear how misleading this phrasing was.
Another problem with Lucky's comment is that somewhere between Nicko's
thinking and Lucky's posting, the fact was dropped that only the matrix
solver was being considered.  This is only 1/2 the machine; in fact in
most factoring efforts today it is the smaller part of the whole job.
Neither Nicko nor Ian nor anyone else passed judgement on the equally
crucial question of whether the other part of the machine was buildable.
It is obvious that in fact Nicko had not spent much time going over
his figures, else he would have immediately spotted the factor of 10
million error in his run time estimate.  Saying that his estimates had
not changed is meaningless if he has not reviewed them.
Lucky failed to make clear the cursory nature of these estimates, that the
machine build cost was based on a hurried hour's work before the panel,
and that the run time was based on about 5 seconds calculation during
the panel itself.  It's not relevant whether this was in part Nicko's
fault for perhaps not making clear to Lucky that the estimate stood in
the same shape a week later.  But it was Lucky who went public with the
claim, so he must take the blame for the inaccuracy.
In fact, if Lucky had passed his incendiary commentary to Nicko and
Ian for review before publishing it, it is clear that they would have
asked for corrections.  Ian would have wanted to remove his name from
the implied endorsement of the numeric results, and Nicko would have
undoubtedly wanted to see more caveats placed on figures which were
going to be attached to his name all over the net, as well as making
clear that he was just talking about the matrix solution.  Of course
this would have removed much of the drama from Lucky's story.
The moral is if you're going to quote people, you're obligated to check
the accuracy of the quotes.  Lucky is not a journalist but in this
instance he is playing one on the net, and he deserves to be criticized
for committing such an elementary blunder, just as he would deserve
credit for bringing a genuine breakthrough to wide attention.
They are not mutually exclusive, and the difference is clear.  In the
first paragraph, Bruce is saying that Bernstein's design is not practical.
To get his asymptotic results of 3x key length, Bernstein must forego the
use of sieving and replace it with a parallel ECM factoring algorithm
to determine smoothness.  Asymptotically, this is a much lower cost
approach for finding relations, and this asymptotic improvement plays
a major part in Bernstein's dramatic result.
However, this specific improvement is almost certainly impractical for key
sizes in current use.  There is no way that sieving is going to be slower
than taking each value and doing a brute force ECM factoring effort on it!
We came up with estimates on this list a few weeks ago suggesting that
even with unreasonably extreme parallelism and clock rates, that this
approach would take 100 million years to factor.  (These estimates were
posted 3 weeks before Lucky's alarmist pronouncement.)
What Bruce is also saying, though, is that with sufficient money and
effort using conventional technology for the sieving, it might indeed be
possible to build a machine that could factor 1024 bit keys.  This would
not use Bernstein's sieving improvements and hence would not be a matter
of using his machine.  It has been known for years that factoring 1024
bit keys should be about 10^7 times more expensive than factoring 512.
And 2048 bit keys are another 10^9 times harder.  Obviously every key
can be factored with sufficient resources.
The bottom line is that Lucky made a mistake.  He went public with a
dramatic announcement that turns out to be based on inaccurate and off the
cuff estimates which have since been disclaimed by the relevant parties.
He should have waited a few weeks for Nicko to post his estimates and for
others to respond before sounding the alarm.  It was wrong to broadcast
an urgent warning based on the limited and crude figures available at
the time, which now appear to greatly underestimate the true costs.
Fine, people make mistakes, but they should take responsibility
afterwards.  It would be nice to see Lucky post a message to Bugtraq and
wherever else his first one appeared saying that things don't look quite
so dire as they appeared a few weeks ago, that at this point we have to
adopt a wait and see stance.  But it's probably not going to happen.

@_date: 2002-05-31 22:44:05
@_author: Anonymous 
@_subject: Re: Bit commitment with hashes in Applied Cryptography 
Jason asks:
No, it's just a mistake.  AC's got more mistakes than a whore has crabs.
Never rely on it.  Always check the primary literature, or at least the
HAC, Using R1 you're basically choosing from a parameterized family of hash
functions.  But that's not necessary for this; you can choose a fixed
hash, junk R1, and just use the single random value R2.

@_date: 2002-05-31 16:57:04
@_author: Anonymous 
@_subject: Re:  PKI: Only Mostly Dead 
[Trying to get this posted to the moderated cryptography list...]
Peter Gutmann should be declared an international resource.  With one
foot in the commercial world, one in the government world and one in the
cypherpunk world, he has a rare perspective on the big security issues.
His irreverance, iconoclasm, frankness and humor make his essays a joy
to read.
Having said that, his recent analysis[1] falls prey to the conventional
wisdom in certain respects.  This gives him a curious blindness which
contrasts with his usual clear vision.  He scrupulously shines his light
on all the dirty corners which the powers-that-be would like to keep
hidden, all the while ignoring the elephant standing in the middle of
the room.
First is the fundamental claim that PKI is not working.  Peter goes into
detail about all the problems that are keeping PKI from success: CRLs,
user interface problems, cost issues, etc.  It's a sad litany of failure.
Only one little thing mars this picture.  PKI IS A TREMENDOUS SUCCESS
WHICH IS USED EVERY DAY BY MILLIONS OF PEOPLE.  Of course this is in
reference to the use of public key certificates to secure ecommerce
web sites.  Every one of those https connections is secured by an X.509
certificate infrastructure.  That's PKI.
One might even go so far as to say that PKI saved the internet, by
allowing people to engage in commerce without fear.  People have been
trained to look for the lock icon which tells them that they have a
secure connection and can safely enter their credit card information.
Certainly it is true that the internet today would be vastly different
if we did not have a deployed, successful, and heavily utilized public
key infrastructure.  Any discussion of PKI's supposed failure ought
to at least recognize that it has been an overwhelming success in this
extremely important market segment.
Another, less fundamental but equally annoying, blind spot is Peter's
allegience to what is conventional wisdom in certain circles, namely that
global names do not exist.  It's one thing for Carl Ellison to make such
a claim; after all, he's worn his SPKI blinders for so long that they
have practically grafted themselves onto his head.  But someone like
Peter ought to be capable of a little more independent thought.
Peter even goes so far as to refer to "a locally unique identifier such
as an email address."  Anyone who would refer to an email address as
being only locally unique is blinding himself most carefully.
The truth is that we are surrounded by globally unique identifiers and
we use them every day.  URLs, email addresses, DNS host names, Freenet
selection keys, ICQ numbers, MojoIDs, all of these are globally unique!
"pgut001 is a globally unique name; you can use that
address from anywhere in the world and it will get to the same mailbox.
The existence of globally unique identifiers may not fit into some
people's ideology but it is a matter of fact all the same.  And likewise
with the fact that there are extremely important areas where PKI has been
massively successful.  Let's hope that Peter's legendary clear vision
will allow him to pierce the orthodoxy that comes from his friends as
easily as that which comes from outsiders.
[1]

@_date: 2002-05-03 02:02:06
@_author: Anonymous 
@_subject: stego of the day 
Dear Friend , Your email address has been submitted to us indicating your interest in our publication . This is a one time mailing there is no need to request removal if you won't want any more . This mail is being sent in compliance with Senate bill 1623 ; Title 9 , Section 302 ! This is not multi-level marketing . Why work for somebody else when you can become rich as few as 59 days . Have you ever noticed people love convenience plus how many people you know are on the Internet ! Well, now is your chance to capitalize on this ! We will help you SELL MORE & use credit cards on your website . You are guaranteed to succeed because we take all the risk . But don't believe us ! Ms Jones who resides in Alaska tried us and says "Now I'm rich, Rich, RICH" ! We assure you that we operate within all applicable laws ! You will blame yourself forever if you don't order now ! Sign up a friend and your friend will be rich too ! Thank-you for your serious consideration of our offer . Dear E-Commerce professional , You made the right decision when you signed up for our directory . If you are not interested in our publications and wish to be removed from our lists, simply do NOT respond and ignore this mail ! This mail is being sent in compliance with Senate bill 2416 , Title 1 ; Section 305 ! This is not a get rich scheme ! Why work for somebody else when you can become rich as few as 64 days ! Have you ever noticed people will do almost anything to avoid mailing their bills & people love convenience . Well, now is your chance to capitalize on this . We will help you turn your business into an E-BUSINESS & deliver goods right to the customer's doorstep ! You are guaranteed to succeed because we take all the risk . But don't believe us ! Prof Ames who resides in North Dakota tried us and says "Now I'm rich many more things are possible" . We assure you that we operate within all applicable laws ! We beseech you - act now ! Sign up a friend and you'll get a discount of 20% ! Cheers .

@_date: 2002-05-30 05:03:05
@_author: Anonymous 
@_subject: Re: Forward-secure public-key encryption eprint 
Adam Back noted several years ago that identity-based encryption systems
could be converted into forward-secure PK encryption methods.  At the
time it did not appear that any of the identity-based encryption systems
were very secure.
In the past few years a number of cryptographic results have been
achieved by using the Weil and Tate pairings, which are mappings among
groups associated with supersingular elliptic curves.  These mappings
have special mathematical properties which give a new slant to a number
of cryptographic problems.  For example it can be shown that in the
appropriate group, the Decision Diffie-Hellman problem is easy while
the Diffie-Hellman problem is still thought to be hard.  On coderpunks
this was discussed as a possible approach to ecash.  The Weil pairing
can also be used to create short signatures, only 20 bytes long for the
same security as a DSA sig taking 40 bytes.
At Crypto 2001, Boneh and Franklin showed how to use the Weil pairing
to create an identity based PK system.  Unlike earlier constructions,
this one seems to have a good security margin.  Following Adam Back's
earlier idea, this means a forward-secure PKCS can be constructed,
and the new paper does so, using the Weil and Tate pairings.
One concern is that these mathematical techniques are new in cryptography
and so it is possible that new attacks will be found against them.
While the underlying math is old, the specific application is new and
so weaknesses may still be discovered.  Another problem is that the
math is really advanced and not many implementors or users are likely
to understand it very well.  Sure we've got a library but the kind of
people who want forward security would like to understand the principles
a little better.

@_date: 2002-06-21 15:41:07
@_author: Anonymous 
@_subject: Manifesto on a New Strategy 
Outlining the possibilities of creating freedom through new, non-traditional
financial business strategy and technology, in business- and economic details,
and specifications for technical development, this manuscript represents the
first integration of New-Technology/Internet-driven business infrastructures,
logistics, and markets of the future with core concepts of Neo-Tech and
Neo-Tech business. It outlines how the integration and evolution of three existing basic concepts -- 1) Wide-scope accounting strategies to protect
business assets, 2) Cyberspace/Logistics/Reputation-driven Barter Communities,
and 3) A Global Anonymized Computerized Market -- can together lead to total
economical freedom and volitional trade, on an individual and ultimately on a
world-wide scale. The practical implementation of the strategies described, and
the necessary infrastructures, while today in planning by only a small number
of businesses, is an enormous opportunity for any entrepreneur, manager or
CEO to understand, integrate with his business, contribute to and profit from.
First, what is Wide-Scope Accounting a.k.a. Golden Helmets? As a concept, it
is almost as old as human society itself, but was first explicitly identified
and named by Frank R. Wallace, author at Neo-Tech Publishing. The original
explanation of the concept of Golden Helmets, given in a courtroom speech,
can be found at: Wide-scope accounting is a wealth management tool, allowing a person to live
without any taxable personal income. Rather, all money is kept by one's company
and utilized to expand the company and maximize its values, while one's own
expenses necessary to live and work (food, housing, car, etc.) are company
expenses. Any individual living this way, in a 100% service environment, but
without private income or excess property, therefore, cannot be taxed. One's
own company itself focuses not on immediate profits but on building maximum
high-quality values, efficiency and new jobs. Taxable profits in a company are
minimized by re-investing, while the value-maximized work leads to high
revenues, and widens the business through additional partners and employees.
With Neo-Tech, Frank R. Wallace also openly identified that the reason for the
modern, century-old economy-controlling/economy-draining high income taxes are
not primarily to satisfy the financial requirements of governments and
"the public", which could as well be achieved through less compulsive, more
voluntary taxation schemes. Rather, the prime reason for income taxes and
their often life-destroying enforcement by armed government hunters is to
keep control over people -- legal, bureaucratical, social and psychological --
by controlling everyone with a strong, limiting grip on his or her prosperity,
privacy, business, happiness, and ultimately, life.
Wide-scope accounting in business lets a company always pay excess taxes
indirectly, by creating jobs and boosting markets, which leads to direct and
indirect tax payments by multiplying the profits of others, while minimizing
one's own financial liability. It allows any businessman to outmaneuver
criminal politics without being an "Atlas that Shrugs" -- in contrary, it
means producing more and harder than ever, and in the long term, profiting
enormously, but at the same time withdrawing all support for the force-backed
tax system -- legally, and without making any force or resistance necessary.
However, despite the tool of wide-scope accounting readily available to
everyone, one must face the reality of a politically undermined/controlled
economy existing practically everywhere today. Vast economies -- valuable,
but yet, drained -- today depend on monetary systems ultimately regulated
by local and international political authorities. Thus, the task is to
sublimate traditional economical dynamics to direct value-creation/value-
exchange dynamics of an economy beyond wide-scope accounting within traditional
currency systems -- immune from external force, authorities and corruptions.
Without making a mistake about it, official currencies do represent the
material values that they are exchanged for. And, contrary to the views
propagated by dishonest media, academics, traditionalists, politicians and
activists, money is not the "root of all evil". Yet, in a way, all official
money is corrupted, since it is regulated directly and indirectly by
governments through taxation-, banking-, anti-inflation-, anti-deflation-,
public insurance-, tariff-, business- and economic regulations and laws which
affect everyone who uses money and indirectly forces everyone to pay up insane
proportions of his personally earned wealth. As all official, government-issued
currencies for value exchange are regulated, drained and corrupted in
traditional economic systems, every magnificent commercial value is, too!
Hence, even beyond wide-scope strategies to protect from direct government
confiscation, taxation and attacks, the problem of force-backed economic
control remains. How could non-authority, non-force businesses and individuals
generate sufficient availability and acceptance of efficient, but gradual and
fully volitional changes from state-owned systems based on money to
individually-controlled, systems based on market value, available world-wide
to everyone? Obviously, cyberspace, which cannot be efficiently regulated, may
play a role. However, the decentralized Internet is only the foundation, upon
which scaling levels of infrastructures for specific financial solutions must
be consciously conceived and implemented with foresight and long-term efforts.
The globalization of free business activities, i.e., international competition
between businesses and between the degree of freedom in different states,
is crucial for a cyberspace-based economy to succeed -- as business on the
Internet does not have to be based in any single country and be restricted
by its laws. Unfortunately, the globalization of recent international political
policies, which enforce regulations (e.g. "financial-crime" surveillance,
international liability to violation of political/ethical/cultural policies,
international trade bans and regulations of certain goods, etc.), may partially
limit and dis-empower the trend of overcoming national laws through
globalization. These newly emerging freedoms of globalization
must not be limited. In order to achieve and maintain freedom from local laws,
regulated economies, mandatory regulated currencies, and now, international
regulations, a combination of logistical, technological, communicational and
financial solutions must be brought forward by market entrepreneurs
to prevent or reverse the expansion of international government force.
Wide-scope accounting is a simple protective measure, but it can require a
full-scale revision of business and employment policies. Ultimately, the
question is, Can wide-scope accounting alone and in every situation solve
the problem of ending political regulation of earnings and business values?
Bartering Communities, mentioned by futurist authors, including Alvin Toffler
and Barry Carter, as a complementary approach to wide-scope accounting,
especially when upgraded with modern technology and e-commerce dynamics,
are ironically exemplified within the politically/economically-collapsing
nation of Argentina. The concept is based on the idea of having trade
systems for goods and services that do not rely on officially issued
government currencies, and hence cannot be regulated by means of regulations
based on official currencies. It can also protect against inflation, deflation,
fiscal instability and other traditional economical short-term problems.
Argentina is taken as an example here because of the interesting grassroots
business infrastructures that have been building as a result of the total
government-led control and collapse of that country's traditional economy.
Those infrastructures are privately created trade/bartering communities,
not based in cyberspace, yet highly effective because of the enormous demand.
People meet at a physical center, i.e. a local community center, and offer
their own goods or service to others for some other goods or services, but
not for official currency. "Prices", i.e. the amount and ratio of values is
negotiable. Some of the people are well-known (i.e. their identity can be
confirmed by others at that center) and carry a reputation. Also, a completed
trade of goods or services has effects on the reputation/trustworthyness
of both exchange partners involved in that transaction. A completed trade may
also establish or re-affirm guidelines for specific exchange ratios, e.g.:
"1 pound of sausage for 10 apples", "1 haircut for 1 carwash", "400 sheets of
paper and a printer for 2 hours of business- or legal consulting". The same
works with privately-issued currencies: goods and services can be traded for
ad-hoc currencies, e.g. 5 ANON-Credits, 10 XYZ-Credits, 120 ABC-Credits.
Bartering communities are a very capitalistic answer to vanishing government
regulation. Capitalistic in the original definition of the term, i.e.,
a powerful solution, yet, an economical laissez-faire solution that works
by volitional free trade, without using force or fraud in any instance.
That nonviolent Ghandi-like withdrawal of support from the public systems is
even legal according to government's own laws. Removing that support is
achieved by ignoring currencies, and by privatizing the issuing of currencies,
a concept that only becomes so effective once combined with flexible, and
low-cost e-commerce technology -- a possibility that no government
originally conceived. As a result, it frees individuals and their businesses
financially, the economy, and ultimately, everyone -- from workers, small-
business "middle-class" producers, up to the richest, highly successful
entrepreneurs, but also and especially the poor, the needy and those without
an official job (as observed in Argentina, for example), by offering them
easy, unregulated work, as well as highly competitive, minimum-cost products
manufactured by unregulated companies using bartering-network logistics. It
benefits the whole of productive humanity, excluding only those who decide
to rely on support of organized politics or activist/lobbying groups,
regulation-based corporate privileges, or established force-backed
institutions. In fact, it can effectively ruin all those who live from systems
which finance themselves by any means of force (including higher social/
political causes rationalizing force), rather than volitional/competitive work.
Important to note is also that today, bartering systems, beyond niche
economies or other exceptional situations, are not science-fiction, but
already today a practical reality. The facts are that 40% of the world economy
is represented by some kind of bartering trade rather than financial
transactions, and that over 65% of the Fortune 500 companies at some
point are engaged in bartering.
Though it may seem as if there are no problems holding back the bartering
solution to an unrestricted economy, they unfortunately do exist in form of
big-brother governments in the economically most important western countries.
The US Internal Revenue Service, for example, claims that
any profits made through bartering, including intangible profits, are
taxable as income, officially demanding money for the state for each
successful bartering deal. Although it is much harder for the IRS to enforce
or to prove its taxation cases in bartering scenarios, this still has a
profound impact on the growth of the bartering economy. From an official
point of view, bartering is regulated and bartering independently of government
systems would be tax evasion and illegal. This is a major problem because
in business, profound trust, seriousness and security are generally expected
and required before a system will become widely accepted and employed.
A resolution of this issue could be to avoid relationships between any values
offered within the bartering economy and any and all officially issued
currencies. While pseudocurrencies, as mere internal aliases for values
exchanged, could exist, there must not be possibility to directly or
indirectly establish exchange rates of bartering goods and services
to official currency. Today's bartering and e-bartering seems to fail
exactly here, with none or relatively loose policies regarding the
association of bartering values with traditional money. By enforcing
contractual policies throughout e-bartering networks against the introduction
of official currencies in any exchange, and any products which obviously
translate to preset currency value (gold and stocks, perhaps), with all
the complications such a move might lead to, this could efficiently make
it impossible to tax bartering profits as income. With no easy-to-determine
equivalents of money for bartering profits, taxation may become impossible.
Whenever that happens -- secure, large, tax-free barter networks -- demand and
involvement in such networks by individuals and businesses would rise sharply.
                An Unassailable New Economical Infrastructure
                  Based On Privacy, Anonymity And Technology
Obviously, because of major issues that won't go away -- growing government
control and taxation in new areas, the need for permanent security and
stability of a widely accepted business system and the need for practical
feasibility, broad customer confidence and ease of use -- a solution beyond
simple bartering and e-bartering systems is necessary to successfully start
off a new, genuinely free economical system on a global scale.
The integration of all relevant knowledge, ideas and scenarios on this topic
suggests that the only viable route not dependent on politics or social change
must be based on technology, which involves cryptography-based anonymity that
conceptually cannot be subverted and trust/reputation-based transactions
through a decentralized network. Dealing with this concept involves detailed
technical specifications of the basic requirements and concepts necessary to
develop such a system. While some of these details may not be comprehensible
for technical amateurs, it is only important to understand the core concept,
and the fact that it is possible to create fully anonymous and untraceable
communication infrastructures with the help of extensive cryptography and
theories of information technology -- as outlined and partially implemented
by the libertarian cypherpunks and others.
There have been small-scale and experimental projects such as Freenet,
and limited-scope/limited-feature projects with the same goal such as
ZeroKnowledge's Freedom or Type-2 Mixmaster remailers. But, nobody has ever
attempted anything like the implementation of a global, decentralized, fully
anonymous trade and communication infrastructure before. Hence, chances are
that such a broad, complicated strategy will work. But first, what are the
current problems standing in the way of the achievement of that goal?
Realize that the establishment of the first business and private communication
infrastructure that couldn't be regulated or effectively banned by governments
equals a great confrontation between individual and government interests;
perhaps the first major nonviolent confrontation in western countries after
the violent days of past revolutions. Now, without any part of the
implementation of the infrastructure itself having to be illegal according to
current laws, anything that is a de-facto threat to today's authorities resting
on bona-fide subjective law, can be declared illegal -- if through no other
means, then by "democratic" criminalization through the manipulation of popular opinion through the association with terrorism and other non-sequitours. It
is this, and the necessity for political correctness and social acceptibility
of today's manipulated western cultures, that practically all significant
major businesses adhere to. Most managers feel that their company's success,
their customer relations, their very survival, depends on being politically
correct and devoting time and energy into what their government deems to be
"important tasks", "valid business activity" and "beneficial to society".
Yet, those managers and CEOs of major businesses are deeply mistaken. Many of
today's business leaders are merely non-thinking, easy-going individuals,
manipulated by public-opinion games into a following-mode of following the
"public interest" -- actually coming down to political agendas of a few
influential lobbyists -- including tax authorities, banking authorities,
socialist politicians and other destructive political hardliners. As long
as top business executives shun the controversial politically incorrect,
they keep shunning the confrontational dynamics of real business -- expansions
into new, untouched sectors and strategies that go beyond competition --
especially the competition of government and businesses who count on political
support to "succeed" economically. As long as controversial trade, development
and infrastructure-building business projects are shunned by stagnant major
companies, which once were active business giants, their only option is to
continue faking business success and growth off the existing assets of the
often great, valuable companies they manage; through creative bookkeeping and
projects that only are profitable through government privileges like "public"
funding or corrupt, competition-destroying legal/regulatory advantages.
To get involved in a confrontation-mode project, a business must be ready for
the politically incorrect, be willing to ignore intimidations, and must be
growing or willing to grow through hard, independent, competitive efforts
and money-generating actions of all of management and all employees. Also,
those companies must achieve a large customer base and broad private-sector
support in the early phase to be economically and technically successful.
From a technical point of view, the new economical infrastructure would be
based on strong cryptography and an ad-hoc public key infrastructuring model.
For it to be decentralized, all participating parties should be equal in
respect to the kind of communication and communication infrastructure, i.e.
a peer-to-peer network. This would effectively mean a decentralized, encrypted
network infrastructure on top of the decentralized public Internet. This
infrastructure would provide for anonymity (via routing over multiple
machines using routers that maintain distinct keys and routing information
for each source and destination) or pseudonymity (i.e. anonymity in which
parties are associated with an established, verifiable alias/pseudonym which
however is not directly linked to and does not reveal their official identity),
depending on what is necessary for a particular step in a business transaction.
On top of that infrastructure, a decentralized supply/demand infrastructure
could be built, with computer-based matching -- either, integrated into an
automated peer-to-peer protocol, directly between individual parties, or done
by one or many bartering agencies who collect supply and demand messages and
provide automated matching services.
One array of problems that naturally emerges under anonymous conditions,
are reputation issues -- as traditional reputation, trust and legal liability
that are given with officially issued identities (i.e. government identities),
do not exist or at least cannot be verified and relied on. For an anonymous/
pseudonymous trade system to work, it must efficiently deal with the issue
of trust and reputation under conditions lacking an infallible identification
of individual parties.
With a protocol supporting verifiable identity-hiding pseudonyms that last
permanently or for a longer time, initial reputation/trust could be
established for untrusted newcomers after a first successful mutually
consentual transaction, which would then continue to grow on subsequent
transactions. Reputation of a peer increases if he has provided the promised
values (including pseudo-currency) according to the transaction, and is
given mutually to each other by two or more parties involved in a transaction.
Technically, that reputation could take the form of serialized confirmation
tracking numbers combined with a cryptography-based digital signature by the
party confirming another party's reputation. In anonymous networks, reputation
becomes a value in itself because it guarantees more transactions, trade
and profit. Money, like pseudocurrencies, is merely an abstract promise to pay
later, and exchanged goods and services are direct payments, while reputation
assures security in-, and provides potential for trade. Hence, striving for
high reputation means more opportunities profits on the direct trade level.
Besides internet-driven local and global bartering communities, further great
potential is held by the idea of anonymous digital cash (e-cash) systems.
Though not using official currency, the existing digital cash systems are not
perfectly safe because their transfers can always be logged and parties have
to be identified to central servers and each other. Anonymous e-cash and other
digital currencies and checks (including anonymous bartering checks) can best
be established in a network that allows routing by 1) writing down the value
of the check or money transaction 2) adding a unique serial number 3) digitally
signing the check with a signing key that identifies the paying party by
a known (reputation/trust-based) pseudonym. This one-time certificate for
a money or bartering transaction is then sent over an anonymizing network,
encrypted with the public key of the recipient's pseudonymous identity.
Alternatively, according to a "BlackNet" scheme, encryption keys can also be
exchanged in secret, so they are only known by both parties, with only the
public-identification signature signing the transaction certificate (which
happens a level beyond that encryption layer for confidentiality). Then, those
messages are unidentifiable for third parties and can be posted into public
forums (such as news://alt.anonymous.messages) using anonymous remailers.
A broadly used digital cash system, however, would provide many more
benefits than just anonymity. With automated end-to-end transactions,
money transactions would become faster and the economy would become more
efficient, especially when guaranteed to be free of force-backed bureaucracy.
With money being circulated faster and more money circulated within
transactions than in static investments or savings, the global amount of
money effectively available increases. As a proof, consider that since the
financial world similarly migrated to satellite- and computer-based digital
bank transactions and online stock trade, the amount of wealth available
at any given time has increased, making modern world trade possible.
This new infrastructure would most probably resemble an ad-hoc heterogenous
environment with many different digital businesses doing combinations of
banking, trade, trust and anonymity services. Only some of them would have to
offer anonymity, some could offer converting online/digital currency to
official currency or paper checks describing an equivalent of digital currency.
Also, currency-less bartering checks could be used online and offline, even
anonymously with a system that supports it. Bartering is simply a matter of
supply and demand, which could be recorded (anonymously) in form of checks
with serial numbers, or saved on smart cards which would contain the necessary
cryptography algorithms, standard protocols, and public keys.
With financial transactions and other (i.e. bartering) exchanges encrypted
with public keys of the participating parties and reposted anonymously, they
efficiently become independent of, and safe from the surveillance by any third
party. Anyone issuing and accepting anonymous transactions could then decide
to become a customer of a digital business offering anonymous conversion
between pseudocurrencies and official currencies. Payment would largely be
in percentages of the exchanged wealth, which could be exchanged anonymously.
With confidential and pseudonymous transactions, new types of businesses
are imaginable. For example, eBay like matching/bartering services based on
pseudonymity and reputation, which could match supply/demand in goods,
services, inofficial currency exchange and more. Also, thinking about the
huge market that advertising is today, especially on the internet, ad space,
ad services, site traffic and hits could become niche markets with dedicated
businesses offering ad-hoc exchanges in advertising. Using certification
hierarchies, all of these services could also allow users to "export" their
reputation/trust gained from successful transactions to other markets.
The development of wide-scope business policy concepts to protect from
taxation and governments; the development of digital trade centers and
routine forms of bartering trade, and marketing them to combat inflation
and regulation; the design and creation of the underlying technology-based
infrastructure for anonymous networks against government regulations, and
the anonymization of existing business systems through informal gateways and
inofficial exchanges; this is a comprehensive complex of plans. Ultimately,
these plans have to be achieved, by one or more businesses, for creating a
safe and free future. Here is an outline of a combination approach.
Financial wide-scope accounting is necessary for basic individual independence
from governement and its destructive institutions. It is going to take the
form of general, officially legal accounting strategies in business.
The ultimate goal is to prevent all government attacks against private
property, -income and -assets. The necessary requirement is the readiness
of businesses on a broad scale to adopt new accounting strategies,
business policies, business philosophy and payment policies.
Digital trade centers are necessary to prevent government interference with
world markets. It is going to take the form of legal companies, departments,
and business models offering logistics and communication infrastructure for
financial trade and exchanging goods and services without currency. The
ultimate goal is to prevent inflation and economic depression caused by
government taxation and control exerted through regulated official currencies.
The necessary requirement is the establishment of providers of logistics
trade networks, and reputation/trust systems for pseudonymity, starting
websites, and offering start-up funding to build infrastructures for
global decentralized trade.
Technological anonymization/pseudonymization infrastructures for free trade
networks allow untraceable money transactions based on reputation/trust
schemes, privacy concepts, and a stealth, decentralized, internet-based
network infrastructure which utilizes strong cryptography. This leads to the
possibility of uncontrollable, unpreventable, "illegal" money transactions.
The ultimate goal is to establish indestructible black markets to catapult
the world economy beyond direct government control. The necessary requirements
are the establishment of a performant new peer-to-peer internet infrastructure
that provides decentralized, indestructible anonymity/pseudonymity, privacy
and confidentiality (using public-key encryption, digital signatures and
public key infrastructure), as well as trust/reputation services that work
with pseudonyms -- as a base for reliable financial transactions.
Depending on its size and possibilities, a business may take on all three
of these goals, one at a time (although they will eventually be interdependent
to some degree), or a partial accomplishment of one of these goals. As the
involvement of a Fortune 500 or larger company into this plan cannot be
expected, it has to be started by small business/bantam company efforts.
So, a more segmented approach is the most realistic -- especially, when it
comes to coordinating the efforts of marketing and business-to-business
affiliation and infrastructure building.
Any company initially creating and offering the technological or logistic
infrastructure would do best by disclaiming direct liability of third
party transactions performed over its independent infrastructure. Making
the burden of legal liability to the third parties who use the infrastructure
clear, similar to current internet trading businesses which aim to
emulate the Napster business model -- by officially taking the liability that
may or may not exist (including tax liability) to the third parties who
actually do the transactions -- would mitigate much of the legal risk involved.
To get to a free unregulated market one has to physically operate from within
today's regulated society. Unarguably, one of the biggest problem is the
inability of the majority of persons and small businesses to build private
(and investment) capital. Taxes are designed to destroy or prevent
accumulation of capital, earnings and potential investments that are necessary
for individuals to found their own businesses and jobs, for developing new
products, technologies and bootstrapping new business infrastructures.
Bartering somewhat does legally solve this problem by allowing tax-free
bartering "assets" to exist (according to current regulations on bartering),
in form of non-monetary "I-owe-you" service/good exchange checks and
certificates. To be efficient at this, however, bartering must include better
capital building mechanisms legal according to the current system, possibly
via allowing safe accumulated credits based on trust certification, i.e.
credits for specific material goods and services, which would not be official
or inofficial currency but could serve as de-facto savings currency.
The most probable chance for a commercial success of an anonymous trade
network is providing commercial incentives for maintaining high standards
of reputation. In this probably scenario, reputation would necessarily
have to become a second-level currency (as result of successful, mutually
consentual transactions, and secondarily, as result of a vote of trust
by already highly trusted parties). eBay like systems would be used to
build reputations and meta-certification authorities would make the
transfer of reputation between different anonymous businesses possible
(which could be practically realized as joint ventures between businesses
willing to exchange user reputations between their different systems).
At least three definite requirements exist for any businesses that
expects to be able to launch a project advancing one or more of the
three free-trade goals as stated above.
First, the independence from political correctness and social acceptance.
A competent business must act independently of the opinion or wishes
of any authority, only satisfying demand where it objectively exists,
by hard effort and trial and error strategies. Fear from government,
political entrepreneurs, and business regulations, but also with
government agencies, attempts to profit by "public" jobs or government
privileges, in the sense of political entrepreneurialism, will hold back
the competitiveness and dynamic of a business too much for it to be
able to participate in a project as controversial as this.
Secondly, the ability to step out of close-ended viewpoints and business
strategies is an absolute necessity for growth and success in new, unique
areas of business, (as also outlined under Businesses must be ready to accept that the evasion of government restrictions
through peaceful, volitional, business/technology/free-trade actions and
strategies will yield benefits for themselves, and ultimately for society
and everyone. This is an important not only for individual businesses, but
for the whole corporate world. The question of a controversial new area of
business being eventually able to succeed is a question of attaining a critical
mass of businesses and entrepreneurs who are ready to discard dogmas for new,
"politically incorrect", open-ended business viewpoints and strategies. Hence,
being able to easily affiliate with other companies finding business
associates, and being very active in the business-to-business area is a key
competency of a bantam company participating in a free-trade project, which
ultimately requires getting broader support in the business world.
Third, building effective customer confidence in systems which do not base on
traditional currency, and even in anonymous markets which are vastly different
from known economical systems, is crucial. Despite the probably vehement
opposition by established media/government authorities, honest business/
technology/media pioneers must propagate the honest facts and show how the
goal of markets with full choice, privacy and freedom leads to the greatest
net benefits for essentially everyone. High efforts and much care are also
required for designing business solutions around the basic concepts that
are comfortable, usable and appealing from the start, in order to create
a large base of customers/businesses which broadly use and thereby support the
bartering and anonymity features of a project, and with that, contribute to
its decentralized infrastructure. Such approaches require fast, dynamic and
highly adaptive strategies which balance between trial-and-error strategies,
and integrated trust/confidence-building strategies from the very beginning.
The different aspects of a business venturing into a free-market building
project in areas of finance, trust services, trade services, internet
services, communication, and so on, include at least: technical (mostly
internet software, cryptography and pki, network software, website interfaces,
user interfaces, secure payment applications, interfaces to existing
e-commerce systems); funding (fund raising and investment, currency systems
design, currency stability, user fees, price monitoring, capital management,
offshore management, general accounting); advertisement and marketing
(promotion and press handling, legal issues and court battles, if necessary
also against slander, business plan design, confidence and trust building,
mass distribution, quality assurance and ease of use for user applications,
marketing strategies, perhaps introducing Neo-Tech memes, business contacts);
art and business image (website design, user application design, quality for
user-friendlyless, ease of use and general appearance of software and offline
systems, corporate identity, press contacts/protection from press slander);
economics (wide-scope level infrastructure design, testing and building;
establishment of local communities, trials and test deployments of projects).
This publication ends here, after having provided much practical, action-mode
business information, possible strategies, caveats and solutions, and
wide-scope viewpoints on society in respect of a free trade project. What you
make of that knowledge, individually, or as entrepreneur, is up to you.
Independent economy means independence from criminal politics, regardless of
what anyone else thinks, says, or does. Try extrapolating that potential
and integrating it with different wide-scope effects.
Independence means freedom to create. Efficient value production means
increasing efficiency in any areas of business, especially new technology
and applied science, including communication, medicine and publishing. Your
own efforts count and can effect changes. Realize that anyone investing his
or her efforts into the first, most basic steps toward secure routes to
business freedom can profit enormously. The achievement of a free trade
project is up to individual actions. In any case, it will eventually be
achieved, and the speed and the specific routes that are going to be taken
are simply undetermined, open opportunities, waiting to be seized.

@_date: 2002-06-11 06:32:05
@_author: Anonymous 
@_subject: Interview questions for Stefan Brands 
pkiforum.com is soliciting questions which they will ask in
their interview with Dr. Stefan Brands.  Mail suggestions to
interviewbrands  Here is one question submitted:
Your technologies could provide for new forms of PKI, credentials,
privacy protection, pseudonymity, and digital cash among others.
Yet you have aggressively pursued patent protection on your ideas,
a relatively uncommon approach among academic cryptographers.
David Chaum before you followed a similar strategy of aggressive patenting
followed by attempts to commercialize his technologies, which covered many
of the same subjects (although generally in a less sophisticated way).
His efforts have been a dismal failure, leaving bankruptcy and business
collapses in his wake.
How do you evaluate your patenting strategy now?  Aren't you concerned
that you will have a similar lack of success?
Would you be willing to consider donating your patents into the public
domain in the hopes that they could be exploited by P2P developers and
other decentralized, open-source efforts?  These are the people who
care about privacy, pseudonymity and the other attributes which your
technology is so ideally suited to provide.  Isn't it possible that this
would be the best path to seeing your ideas being put into practice and
bringing benefits to society?
Thanks very much for your response.

@_date: 2002-06-07 21:13:04
@_author: Anonymous 
@_subject: Re: More of Ben's blinding 
There was extensive discussion on coderpunks about possible patent
implications of Wagner blinding.  Using the g^b blinding makes things
potentially a little worse, because it requires the server to publish g
and g^k.  This can be considered a public key, and brings the situation
closer to the blind signature patent.
Wagner blinding can be thought of as a blinded undeniable signature.
It is like a blind signature in that the server doesn't see what it is
"signing".  And it is like an undeniable signature in that the validity
can only be checked with the aid of the server.  It seems likely that
Wagner could have patented his blinding along these lines if he had
wanted to.
So the problem is, if this is a blind + undeniable signature, doesn't
that suggest that it infringes on both the blind and the undeniable
signature patents?  To answer this you have to look at the claims in
You can differentiate from the undeniable signature patent in that
there is no repudiation protocol in the ecash system - no way for
the server to prove that a purportedly signed value is actually bad.
(Of course this lack is a weakness in an ecash system, since the bank
might like to be able to prove that bogus cash is just that; but if it
were remedied then Wagner blinding would almost certainly infringe the
undeniable signature patent.)
Differentiation from the blind signature patent is done simply by
asserting that this is not a signature.  That's why we are always careful
to put "sign" into quotes when referring to server operations.  It's not
a signature because there is no way to independently verify it, which
one can argue is a de facto requirement for something to be considered
a signature.  But of course, by this definition the undeniable signature
is not a signature either.  Yet we call it a kind of signature.  If the
undeniable signature is a signature, then so is the Wagner blinding,
and so it is covered by the blind signature patent.
As you can see, the situation is murky.  One salvation is that the blind
signature patent will expire in about 3 years, and it is unlikely that
you will be successful enough in any project that it would be worthwhile
to sue you within that time frame.  Besides, everyone who takes control
of the blind sig patent soon goes broke, so they probably can't afford
a lawyer to sue you anyway.
You should be aware too that there are a number of credential patents,
which you can find by searching on the word credential.
Seems safe by the DDH assumption, which is that it is hard to recognize
that (g, g^a, g^b, g^ab) have the DH relationship.  If we let m = g^b
then this is (g, g^a, m, m^a).  In other words, we can't tell whether
two different values g and m are both being raised to the same power.
In your case, you know h1, h2, (h1h2)^k.  If you could then find h1^k,
you could construct a DDH tuple (h1, h1^k, h1h2, (h1h2)^k), so you
could violate the DDH assumption.  This is a little hand-wavy and only
deals with the two element case, but an argument along these lines will
probably work.
You're really going to remember all the discarded h values from all the
previous instances of credential issuing?  Seems like it might be a lot of
data.  How many h values do you typically expect?
Maybe you could say more about the details of your credential system.
Such a system built on Wagner blinding might be very interesting.

@_date: 2002-06-06 00:25:07
@_author: Anonymous 
@_subject: Re: Laurie's blinding w/cut and choose? 
Boy, you've got a lot of faith asking this question on cypherpunks.
It's not exactly the intellectual center of the crypto freedom movement
these days, you know.  The average IQ is rapidly descending into double
digits, even not counting Choate.  But let's see what we can do for you.
First, let's fix your notation.
r = blind(h) = h^y * g^b  OK
s = sign(r) = r^k, not m^h.
unblind(s) = (s/g^k^b)^(1/y) = h^k = sign(h).
That's what you want to end up with, h^k, as the pseudo-signature on h.
Now for a credential system, you apparently want to create a bunch
of values which have some structure, and get a signature on a product
of them.  Using cut and choose, the client will prepare blinded forms
of all of the values, then the server will ask for half of the blinding
factors to be revealed.  This exposes the raw values to be signed and
the server can make sure they are in the right form.  If so, it then
signs the product of the remaining values, which the client unblinds
to get back a good signature on the product of the unblinded values.
Done properly, with n values this gives you 2^n security against bogus
data in the credenial.
The fundamental problem with this is that the blinding factors have to
be different for each of the values.  If they are all the same, then
when they are revealed for some of the values during cut and choose,
that will reveal them for all of them, and so none of them will be
effectively blinded any more.
But if the blinding factors are all different, we can't unblind since
we don't have a unique power 1/y to raise to.
That's your problem, right?
Here are a couple of possible solutions.  First, you could do a cut and
choose in which all but one of the blinded values are revealed, and only
the remaining (unrevealed) one is signed.  This has the problem that it
has only a 1/n security factor with n values.  That is, the client can
just guess which one the server won't ask to check, and if it sent say 100
values, it has a 1/100 chance of getting lucky, which might seem too high.
However since credential issuing usually occurs in a non-anonymous
context, you can afford to penalize people very heavily if they are
caught in this manner.  (Cutting the connection and refusing to resume
with the previous values has to count as cheating.)
Another approach is as follows.  Go back to the 50-50 cut and choose
with signature on the product.  However, use the same y blinding factor
for all of the values.  Now when the client has to reveal during cut and
choose, it keeps the y value secret but reveals all of the h and b values.
It then proves in zero knowledge that there exists a y such that the h^y
equals the required value.  This is a standard ZK proof of knowledge
of a discrete logarithm.  It is similar to the example Ben's paper gives
of how the bank can prove it is raising to the right power.
Since you don't have to reveal y, you can use the same y for all of them
and successfully perform the unblind operation, getting back the signature
on the product of the h's as required.
But actually another solution is much simpler, which is to do blinding
as just h * g^b, without a y factor.  That works fine as long as the
bank is known not to be misbehaving.  Ben's paper shows how the bank
can use a ZK proof to show that it is raising to the same power k every
time, basically again that same ZK proof regarding discrete logarithms.
If the bank uses such a proof then you can use simpler blinding without
a y factor, and you can recover the signature on the product of your h
values by dividing by g^k^(sum of b's).
So there you go.  A little technical for cypherpunks, but unfortunately
coderpunks, like the little old lady, has fallen and it can't get up.

@_date: 2002-06-12 17:04:04
@_author: Anonymous 
@_subject: Re: Sci Journals, authors, internet 
Brilliant suggestion as usual.  This completely un-edited, un-reviewed
archive site accepts submissions from anyone in the world.  One might
as well learn physics from Jim Choate.  I wonder if Tim May's extensive
archive of printed papers includes such gems as these from xxx.lanl.gov:
  This one explains that general relativity is all wrong to attribute
  gravity to curved spacetime, and cosmological red-shift to expansion.
  It shows how to get these effects from a flat spacetime geometry.
  "We found a fundamental principle, the law of statistical balance
  in nature, that specifies quantum statistical theory among all other
  statistical theories of measurements. This principle plays in quantum
  theory the role that is similar to the role of Einstein's relativity
  principle."
  This astonishing paper tells what happens before the Big Bang.  During
  the pre-universe the vacuum evolves through four stages before producing
  the universe we see.  "The periodic table of elementary particles is
  constructed to account for all elementary particles and their masses
  in a good agreement with the observed values."  This is the holy grail
  of modern physics - a theory that explains the subatomic particle zoo!
  Definitely a must-have for Tim May's collection.
Clearly every one of these results would be shattering to the modern
physics paradigm, if true.  Tim May's advice puts readers at risk of
accepting the most absurd theories without any way of evaluating their
There is a reason why the peer review process and the academic journals
are still needed.  Online preprint archives are useless for the layman.
Only experts can use these archives with safety; they are able to sift
the wheat from the chaff.
As usual, readers are cautioned to take Tim May's "brilliant insights"
with a very generous grain of salt.

@_date: 2002-06-24 18:27:05
@_author: Anonymous 
@_subject: Re: Ross's TCPA paper 
The amazing thing about this discussion is that there are two pieces
of conventional wisdom which people in the cypherpunk/EFF/"freedom"
communities adhere to, and they are completely contradictory.
The first is that protection of copyright is ultimately impossible.
See the analysis in Schneier and Kelsey's "Street Performer Protocol"
paper,   Or EFF
columnist Cory Doctorow's recent recitation of the conventional wisdom
at  "providing
an untrusted party with the key, the ciphertext and the cleartext but
asking that party not to make a copy of your message is just silly,
and can't possibly work in a world of Turing-complete computing."
The second is that evil companies are going to take over our computers
and turn us into helpless slaves who can only sit slack-jawed as they
force-feed us whatever content they desire, charging whatever they wish.
The recent outcry over TCPA falls into this category.
Cypherpunks alternate between smug assertions of the first claim and
panicked wailing about the second.  The important point about both of
them, from the average cypherpunk's perspective, is that neither leaves
any room for action.  Both views are completely fatalistic in tone.
In one, we are assured victory; in the other, defeat.  Neither allows
for human choice.
Let's apply a little common sense for a change, and analyze the situation
in the context of a competitive market economy.  Suppose there is no
law forcing people to use DRM-compliant systems, and everyone can decide
freely whether to use one or not.
This is plausible because, if we take the doom-sayers at their word,
the Hollings bill or equivalent is completely redundant and unnecessary.
Intel and Microsoft are already going forward.  The BIOS makers are
on board; TPM chips are being installed.  In a few years there will
be plenty of TCPA compliant systems in use and most new systems will
include this functionality.
Furthermore, inherent to the TCPA concept is that the chip can in
effect be turned off.  No one proposes to forbid you from booting a
non-compliant OS or including non-compliant drivers.  However the TPM
chip, in conjunction with a trusted OS, will be able to know that you
have done so.  And because the chip includes an embedded, certified key,
it will be impossible to falsely claim that your system is running in a
"trusted" mode - only the TPM chip can convincingly make that claim.
This means that whether the Hollings bill passes or not, the situation
will be exactly the same.  People running in "trusted" mode can prove
it; but anyone can run untrusted.  Even with the Hollings bill there
will still be people using untrusted mode.  The legislation would
not change that.  Therefore the Hollings bill would not increase the
effectiveness of the TCPA model.  And it follows, then, that Lucky and
Ross are wrong to claim that this bill is intended to legislate use of
the TCPA.  The TCPA does not require legislation.
Actually the Hollings bill is clearly targeted at the "analog hole", such
as the video cable that runs from your PC to the display, or the audio
cable to your speakers.  Obviously the TCPA does no good in protecting
content if you can easily hook an A/D converter into those connections and
digitize high quality signals.  The only way to remove this capability
is by legislation, and that is clearly what the Hollings bill targets.
So much for the claim that this bill is intended to enforce the TCPA.
That claim is ultimately a red herring.  It doesn't matter if the bill
exists, what matters is that TCPA technology exists.  Let us imagine a
world in which most new PCs have TCPA built-in, Microsoft OS's have been
adapted to support it, maybe some other OS's have been converted as well.
The ultimate goal, according to the doom-sayers, is that digital content
will only be made available to people who are running in "trusted"
mode as determined by the TPM chip built into their system.  This will
guarantee that only an approved OS is loaded, and only approved drivers
are running.  It will not be possible to patch the OS or insert a custom
driver to intercept the audio/video stream.  You won't be able to run
the OS in a virtual mode and provide an emulated environment where you
can tap the data.  Your system will display the data for you, and you
will have no way to capture it in digital form.
Now there are some obvious loopholes here.  Microsoft software has a
track record of bugs, and let's face it, Linux does, too.  Despite the
claims, the TCPA by itself does nothing to reduce the threat of viruses,
worms, and other bug-exploiting software.  At best it includes a set of
checksums of key system components, but you can get software that does
that already.  Bugs in the OS and drivers may be exploitable and allow
for grabbing DRM protected content.  And once acquired, the data can
be made widely available.  No doubt the OS will be built to allow for
frequent updates, similar to antivirus software, so that as an exploit
becomes publicized, it will be closed.  There will be an ongoing war
between the hackers and the software companies, just as we see today.
Presumably this will see-saw back and forth for quite a while.
Hardware hacking will be another line of attack.  The TPM chip isn't
exactly omniscient.  It's a pretty simple gadget; its only view of the
world is through a few tiny wires.  Of course it will be surface-mount
soldered to the motherboard, but for a price you will probably be able
to get yours unsoldered and mounted in a socket which gives the chip a
"sanitized" view of your hardware configuration before boot, and switches
over to your real, hacked, system once things get running.  This will
allow you to run your supposedly "secure" OS in virtual mode and still
grab the protected data.  But it's probably an expensive hack.
Clearly no system can be perfect, and the same is true of the TCPA.
There will be ongoing leakage of digitally protected data.  Perhaps
watermarking technologies will be brought into play for another layer of
protection, but by and large those have been defeated as well.  The goal
of these systems is to reduce the quantity of piracy and to raise the
price, so that we move away from the system today where do-it-yourself
piracy is the norm.
Let us suppose that this is the world ten years from now: you can run a
secure OS in "trusted" mode and be eligible to download movies and music
for a price; or you can run in untrusted mode and no one will let you
download other than bootleg copies.  This is the horror, the nightmare
vision which the doom-sayers frantically wave before us.
The important thing to note is this: you are no worse off than today!
You are already in the second state today: you run untrusted, and none
of the content companies will let you download their data.  But boolegs
are widely available.
All the TCPA "threatens" to do is to provide new options to the world.
You will still be able to use your system in exactly the same ways that
you use it today; you will be able to run all of the software that you
run today.  The TPM chip can be disabled or ignored if you don't run
in "trusted" mode, and you get the same effect you have today with no
TPM chip.  You have lost nothing.
Ironically, if we lived in a world of honest people, the TCPA would
not be necessary.  You would be able to buy DRM protected data already,
agreeing to the restrictions in exchange for the content, and you would
follow the rules.  We would have a thriving market in digital content.
But we don't live in that world.  People can make all the promises
they like and the vendors know there is no way to hold them to what
they have said.  There is not even social opprobrium; look at how eager
everyone was to look the other way on the question of whether the DeCSS
reverse engineering violated the click-through agreement.
The TCPA allows you to do something that you can't do today: run your
system in a way which convinces the other guy that you will honor your
promises, that you will guard his content as he requires in exchange for
his providing it to you.  It allows you to be honest.  It doesn't force
it; you can still do everything you can do today.  But it allows it.
It gives you the chance to present an honest face even across the
anonymizing medium of the net.
Lucky, Ross and others who view this as a catastrophe should look at
the larger picture and reconsider their perspective.  Realize that the
"trusted" mode of the TCPA will always be only an option, and there
is no technological, political or economic reason for that to change.
The TCPA gives people new capabilities without removing any old ones.
It makes possible a new kind of information processing that cannot be
accomplished in today's world.  It lets people make binding promises that
are impossible today.  It makes the world a more flexible place, with
more opportunities and options.  Somehow that doesn't sound all that bad.

@_date: 2002-06-24 18:27:05
@_author: Anonymous 
@_subject: Re: Ross's TCPA paper 
The amazing thing about this discussion is that there are two pieces
of conventional wisdom which people in the cypherpunk/EFF/"freedom"
communities adhere to, and they are completely contradictory.
The first is that protection of copyright is ultimately impossible.
See the analysis in Schneier and Kelsey's "Street Performer Protocol"
paper,   Or EFF
columnist Cory Doctorow's recent recitation of the conventional wisdom
at  "providing
an untrusted party with the key, the ciphertext and the cleartext but
asking that party not to make a copy of your message is just silly,
and can't possibly work in a world of Turing-complete computing."
The second is that evil companies are going to take over our computers
and turn us into helpless slaves who can only sit slack-jawed as they
force-feed us whatever content they desire, charging whatever they wish.
The recent outcry over TCPA falls into this category.
Cypherpunks alternate between smug assertions of the first claim and
panicked wailing about the second.  The important point about both of
them, from the average cypherpunk's perspective, is that neither leaves
any room for action.  Both views are completely fatalistic in tone.
In one, we are assured victory; in the other, defeat.  Neither allows
for human choice.
Let's apply a little common sense for a change, and analyze the situation
in the context of a competitive market economy.  Suppose there is no
law forcing people to use DRM-compliant systems, and everyone can decide
freely whether to use one or not.
This is plausible because, if we take the doom-sayers at their word,
the Hollings bill or equivalent is completely redundant and unnecessary.
Intel and Microsoft are already going forward.  The BIOS makers are
on board; TPM chips are being installed.  In a few years there will
be plenty of TCPA compliant systems in use and most new systems will
include this functionality.
Furthermore, inherent to the TCPA concept is that the chip can in
effect be turned off.  No one proposes to forbid you from booting a
non-compliant OS or including non-compliant drivers.  However the TPM
chip, in conjunction with a trusted OS, will be able to know that you
have done so.  And because the chip includes an embedded, certified key,
it will be impossible to falsely claim that your system is running in a
"trusted" mode - only the TPM chip can convincingly make that claim.
This means that whether the Hollings bill passes or not, the situation
will be exactly the same.  People running in "trusted" mode can prove
it; but anyone can run untrusted.  Even with the Hollings bill there
will still be people using untrusted mode.  The legislation would
not change that.  Therefore the Hollings bill would not increase the
effectiveness of the TCPA model.  And it follows, then, that Lucky and
Ross are wrong to claim that this bill is intended to legislate use of
the TCPA.  The TCPA does not require legislation.
Actually the Hollings bill is clearly targeted at the "analog hole", such
as the video cable that runs from your PC to the display, or the audio
cable to your speakers.  Obviously the TCPA does no good in protecting
content if you can easily hook an A/D converter into those connections and
digitize high quality signals.  The only way to remove this capability
is by legislation, and that is clearly what the Hollings bill targets.
So much for the claim that this bill is intended to enforce the TCPA.
That claim is ultimately a red herring.  It doesn't matter if the bill
exists, what matters is that TCPA technology exists.  Let us imagine a
world in which most new PCs have TCPA built-in, Microsoft OS's have been
adapted to support it, maybe some other OS's have been converted as well.
The ultimate goal, according to the doom-sayers, is that digital content
will only be made available to people who are running in "trusted"
mode as determined by the TPM chip built into their system.  This will
guarantee that only an approved OS is loaded, and only approved drivers
are running.  It will not be possible to patch the OS or insert a custom
driver to intercept the audio/video stream.  You won't be able to run
the OS in a virtual mode and provide an emulated environment where you
can tap the data.  Your system will display the data for you, and you
will have no way to capture it in digital form.
Now there are some obvious loopholes here.  Microsoft software has a
track record of bugs, and let's face it, Linux does, too.  Despite the
claims, the TCPA by itself does nothing to reduce the threat of viruses,
worms, and other bug-exploiting software.  At best it includes a set of
checksums of key system components, but you can get software that does
that already.  Bugs in the OS and drivers may be exploitable and allow
for grabbing DRM protected content.  And once acquired, the data can
be made widely available.  No doubt the OS will be built to allow for
frequent updates, similar to antivirus software, so that as an exploit
becomes publicized, it will be closed.  There will be an ongoing war
between the hackers and the software companies, just as we see today.
Presumably this will see-saw back and forth for quite a while.
Hardware hacking will be another line of attack.  The TPM chip isn't
exactly omniscient.  It's a pretty simple gadget; its only view of the
world is through a few tiny wires.  Of course it will be surface-mount
soldered to the motherboard, but for a price you will probably be able
to get yours unsoldered and mounted in a socket which gives the chip a
"sanitized" view of your hardware configuration before boot, and switches
over to your real, hacked, system once things get running.  This will
allow you to run your supposedly "secure" OS in virtual mode and still
grab the protected data.  But it's probably an expensive hack.
Clearly no system can be perfect, and the same is true of the TCPA.
There will be ongoing leakage of digitally protected data.  Perhaps
watermarking technologies will be brought into play for another layer of
protection, but by and large those have been defeated as well.  The goal
of these systems is to reduce the quantity of piracy and to raise the
price, so that we move away from the system today where do-it-yourself
piracy is the norm.
Let us suppose that this is the world ten years from now: you can run a
secure OS in "trusted" mode and be eligible to download movies and music
for a price; or you can run in untrusted mode and no one will let you
download other than bootleg copies.  This is the horror, the nightmare
vision which the doom-sayers frantically wave before us.
The important thing to note is this: you are no worse off than today!
You are already in the second state today: you run untrusted, and none
of the content companies will let you download their data.  But boolegs
are widely available.
All the TCPA "threatens" to do is to provide new options to the world.
You will still be able to use your system in exactly the same ways that
you use it today; you will be able to run all of the software that you
run today.  The TPM chip can be disabled or ignored if you don't run
in "trusted" mode, and you get the same effect you have today with no
TPM chip.  You have lost nothing.
Ironically, if we lived in a world of honest people, the TCPA would
not be necessary.  You would be able to buy DRM protected data already,
agreeing to the restrictions in exchange for the content, and you would
follow the rules.  We would have a thriving market in digital content.
But we don't live in that world.  People can make all the promises
they like and the vendors know there is no way to hold them to what
they have said.  There is not even social opprobrium; look at how eager
everyone was to look the other way on the question of whether the DeCSS
reverse engineering violated the click-through agreement.
The TCPA allows you to do something that you can't do today: run your
system in a way which convinces the other guy that you will honor your
promises, that you will guard his content as he requires in exchange for
his providing it to you.  It allows you to be honest.  It doesn't force
it; you can still do everything you can do today.  But it allows it.
It gives you the chance to present an honest face even across the
anonymizing medium of the net.
Lucky, Ross and others who view this as a catastrophe should look at
the larger picture and reconsider their perspective.  Realize that the
"trusted" mode of the TCPA will always be only an option, and there
is no technological, political or economic reason for that to change.
The TCPA gives people new capabilities without removing any old ones.
It makes possible a new kind of information processing that cannot be
accomplished in today's world.  It lets people make binding promises that
are impossible today.  It makes the world a more flexible place, with
more opportunities and options.  Somehow that doesn't sound all that bad.

@_date: 2002-06-29 18:16:06
@_author: Anonymous 
@_subject: Piracy is wrong 
This shouldn't have to be said, but apparently it is necessary.
Piracy - unauthorized copying of copyrighted material - is wrong.
It inherently involves lying, cheating and taking unfair advantage
of others.  Systems like DRM are therefore beneficial when they help to
reduce piracy.  We should all support them, to the extent that this is
their purpose.
When an artist releases a song or some other creative product to the
world, they typically put some conditions on it.  If you want to listen
to and enjoy the song, you are obligated to agree to those conditions.
If you can't accept the conditions, you shouldn't take the creative work.
The artist is under no obligation to release their work.  It is like a
gift to the world.  They are free to put whatever conditions they like
on that gift, and you are free to accept them or not.
If you take the gift, you are agreeing to the conditions.  If you then
violate the stated conditions, such as by sharing the song with others,
you are breaking your agreement.  You become a liar and a cheat.
If you take the song without paying for it, you are again receiving this
gift without following the conditions that were placed on it as part
of the gift being offered.  You are taking advantage of the artist's
creativity without them receiving the compensation they required.
This isn't complicated.  It's just basic ethics.  It's a matter of honesty
and trust.  When someone makes you an offer and you don't find the terms
acceptable, you simply refuse.  You don't take advantage by taking what
they provide and refusing to do your part.  That's cheating.

@_date: 2002-07-01 21:23:10
@_author: Anonymous 
@_subject: Re: Ross's TCPA paper 
My God, how low the cypherpunk list has sunk.  Here we have someone
not only demanding that merchants be forced to deal with pseudonymous
customers, he invokes civil rights laws to support his argument!
Where's Tim May when we need him?  His racism is odious but at least
he's not trying to force other people to follow his beliefs.  I'm sure
he'd have a thing or two to say about our wonderful civil rights laws
and Bear's proposal to extend similar regulations to cyberspace.
Here's a clue, Mr. Bear.  The cypherpunks list was founded on the
principle that cyberspace can enhance freedom, and that includes freedom
to associate with whomever you choose.  Racism is evil, but the solution
must lie in people's hearts.  Pointing a gun at them and forcing them
to act in a politically correct manner (which is what civil rights
regulations really do) is no solution to the problem.
And of course any reference to the constitution betrays utter cluelessness
when talking on an international mailing list about technology which
spans national borders.  Unless you are prepared to be bound by the
Iraqi constitution, Mr. Bear, don't ask us to be governed by yours.

@_date: 2002-07-04 05:38:08
@_author: Anonymous 
@_subject: Re: maximize best case, worst case, or average case? (TCPA) 
Okay, you are afraid that only "properly authorized" code will run.
Let's talk about one area: programming languages.
What about compilers?  Development systems?  No doubt you'll claim these
will be restricted.  They'll be like assault weapons.  Use a compiler,
go to jail.  This despite the fact that they are necessary tools for
technological progress today.
And what about interpreted languages?  Python, Ruby?  What about Perl?
Seriously: will they ban Perl?  Half the web depends on it!  How can
they keep people from running Perl?
Or do you think that only "properly authorized" Perl scripts will run?
That will never work.  Perl is tweaked all the time; the whole point
of using it is so that you can adapt your site functionality quickly
and easily.
The whole idea of outlawing programming languages and allowing people
to only run software on an approved list is utterly ridiculous.
Custom software is widely used throughout the world for all kinds of
mission critical activities.  Business would never allow the government
to forbid custom software.
People point to guns.  Computer languages aren't anything like guns.
You can ban handguns and it doesn't hurt anyone's business except a
few gun sellers.  Banning custom computer software will drive a stake
through the heart of business innovation and competition.
It's time for cypherpunks to remove their paranoia-colored glasses.
One apocalyptic prediction after another has been proven false.
Even post 9/11 the government floated one timid trial balloon about
possibly restricting crypto, and it was shot down in a hail of criticism
from all directions.
If they can't even ban crypto, you think they'll be able to ban Perl?
People who believe this are utterly disconnected from reality.
To the extent that people fear the TCPA and DRM because they think it will
take us down a path to the mythical state where only approved software
runs, they need to think again.  It can't be done.  Software is infinitely
malleable, and it is this property that makes it so crucially important
in business today.  The government can no more ban unapproved software
than it could require companies to forego the use of computers entirely.

@_date: 2002-07-02 18:41:05
@_author: Anonymous 
@_subject: Re: maximize best case, worst case, or average case? (TCPA 
This has nothing to do with the definition of public versus private goods,
which was quoted in the message to which you replied.  Public goods are
non-rival and non-excludable, terms which were defined there.  Do you
understand what these words mean?  Can you use them in a sentence that
begins, "Digitally signed information is not a public good because..."?
Right, I'll do that as soon as you learn to spell dirigistes.  There's
nothing like using French incorrectly to show someone up as a pretentious

@_date: 2002-07-02 02:02:07
@_author: Anonymous 
@_subject: Re: maximize best case, worst case, or average case? (TCPA 
This is from "What is a public good? This question can best be answered by looking at
the counterpart, a private good. Private goods are typically traded in
markets. Buyers and sellers meet through the price mechanism. If they
agree on a price, the ownership or use of the good (or service) can be
transferred. Thus private goods tend to be excludable. They have clearly
identified owners; and they tend to be rival. For example, others cannot
enjoy a piece of cake, once consumed.
"Public goods have just the opposite qualities. They are non-excludable
and non-rival in consumption. An example is a street sign. It will not
wear out, even if large numbers of people are looking at it; and it would
be extremely difficult, costly and highly inefficient to limit its use to
only one or a few persons and try to prevent others from looking at it,
too. A traffic light or clean air is a further example. "
How can a signed piece of digital information be a private good, by
the definitions above?  It is non-rival: if someone enjoys the good,
he can give it to others and he will still be able to enjoy it.  And it
is non-excludable: if you give it to some people, they can share it with
others and you can't prevent that, as Napster proved.
Even encrypting the information won't help (unless to a key embedded
in some DRM related hardware).  The recipient can still decrypt it and
share it.  It is still non-rival and non-excludable.
Digital services, on the other hand, may well be rival and excludable,
and so do qualify as private goods.  Hence there is no need for DRM
mechanisms to control services.  Most observers believe this is a big
reason for the software industry's interest in "web services", that
they will not be vulnerable to software piracy.  Since such services
are excludable they are not relevant to our debate over DRM and TCPA.
But you claimed that signed pieces of digital information were private
goods.  Please explain.  Are you using standard economic definitions,
or are you inventing your own terminology?

@_date: 2002-07-02 02:02:07
@_author: Anonymous 
@_subject: Re: maximize best case, worst case, or average case? (TCPA 
This is from "What is a public good? This question can best be answered by looking at
the counterpart, a private good. Private goods are typically traded in
markets. Buyers and sellers meet through the price mechanism. If they
agree on a price, the ownership or use of the good (or service) can be
transferred. Thus private goods tend to be excludable. They have clearly
identified owners; and they tend to be rival. For example, others cannot
enjoy a piece of cake, once consumed.
"Public goods have just the opposite qualities. They are non-excludable
and non-rival in consumption. An example is a street sign. It will not
wear out, even if large numbers of people are looking at it; and it would
be extremely difficult, costly and highly inefficient to limit its use to
only one or a few persons and try to prevent others from looking at it,
too. A traffic light or clean air is a further example. "
How can a signed piece of digital information be a private good, by
the definitions above?  It is non-rival: if someone enjoys the good,
he can give it to others and he will still be able to enjoy it.  And it
is non-excludable: if you give it to some people, they can share it with
others and you can't prevent that, as Napster proved.
Even encrypting the information won't help (unless to a key embedded
in some DRM related hardware).  The recipient can still decrypt it and
share it.  It is still non-rival and non-excludable.
Digital services, on the other hand, may well be rival and excludable,
and so do qualify as private goods.  Hence there is no need for DRM
mechanisms to control services.  Most observers believe this is a big
reason for the software industry's interest in "web services", that
they will not be vulnerable to software piracy.  Since such services
are excludable they are not relevant to our debate over DRM and TCPA.
But you claimed that signed pieces of digital information were private
goods.  Please explain.  Are you using standard economic definitions,
or are you inventing your own terminology?

@_date: 2002-07-01 20:10:05
@_author: Anonymous 
@_subject: Re: maximize best case, worst case, or average case? (TCPA 
Brilliant.  Let the market solve the problem.  Why bother with the auction
part, then?  If the market's going to solve the problem for the 2nd guy
to hold the copy, why not let it solve the problem for the 1st?  The fact
is, quoting this mantra is simply a way of avoiding the hard issues.
You've got to show *how* the market is going to solve the problem.
Why would content creators get "a lot of money, cash"?  Obviously, only
if your  guy knows that he is also going to get a lot of money for it.
So you haven't taken a step towards solving the problem; you have simply
handed the problem off from  to The fact is that the market can't solve this kind of problem.  That's
right, markets are not perfect.  They do fine for ordinary, private
goods.  But information objects, absent successful DRM restrictions,
are effectively public goods.  That is, you can't restrict their
dissemination.  If you try to provide such goods only to a small group
of people, you've effectively given them to everyone.
This idea of digital content as a public good is developed in detail at
Markets do not handle public goods well.  It is a standard theorem of
economics that they underprovide public goods.  There is no way to charge
for goods that everyone can get for free, and ideas like Kelsey and
Schneier's Street Performer protocol don't work because of free riders.
The traditional way to provide for public goods is by government.
If we don't get DRM, that's probably what we will end up with: government
subsidies of the arts.  Most musicians and other artists won't be able to
make enough money to live on even if their works are relatively popular.
The government will have to tax consumers and distribute the proceeds
to artists (and the RIAA, etc) in order to protect the content industry.
This is the true alternative to DRM.  Anyone who respects the power of
markets should understand that DRM is the key to allowing markets to
function with information goods.  If you oppose DRM, you are working
to insure that creative content will become a public good.  And if you
understand econmics, you will see that this is an outcome to be avoided
if at all possible.

@_date: 2002-07-03 00:36:05
@_author: Anonymous 
@_subject: Re: [OT] why was private gold ownership made illegal in the US? 
Roosevelt needed to in effect devalue the dollar during the Great
Depression.  In a deflationary depression, this acts as an inflationary
force to cancel the negative effects of the deflation.  Even libertarian
monetarists such as Milton Friedman agree that this is the proper approach
when dealing with a depression.  Roosevelt did not have the advantage
of modern economics and he made many economic mistakes which prolonged
the depression, but devaluing the dollar was not one of them.
However doing a straight devaluation was politically unacceptable
at the time.  Because the dollar was pegged to gold, devaluing the
dollar meant in effect increasing the value of gold in terms of dollars.
This would represent a tremendous windfall to holders of gold.  And gold,
by and large, is owned by the rich.
At the time, the U.S. faced a significant chance of a Communist/Socialist
revolution such as had been seen in several other countries.  Class
warfare was widespread, with armed violence between workers and management
a common occurance.  Transferring a huge bounty into the hands of the
rich would have inflamed the working class and risked plunging the
country into chaos and revolution.
By eliminating private gold ownership, Roosevelt was able to take a
necessary step to invigorate the economy, devaluing the dollar, while
reducing the risk of a civil war.  The rich protested, of course, but
in practice they went along with the measure as they were terrified
of a workers' revolution.
Looking back, since there was, in fact, no revolution, it is easy to
forget today how perilous the state of the country was in those times.
For all those who curse Roosevelt's name, the U.S. at least ended up
the decade in better shape than many countries, and things could have
been far worse.  Americans could be living in a People's Republic today.
Confiscating gold was clearly the lesser of the evils.

@_date: 2002-07-03 21:30:06
@_author: Anonymous 
@_subject: Re: Hayek was right. Twice. 
There is more to it than a tautology.  Ignoring market failures (such
things as public goods and externalities), markets are efficient in the
sense that they produce a Pareto optimal outcome.  Pareto optimality is
a state in which you can't make everyone better off by rearranging who
has what; you have to make at least one person worse off if you benefit
anyone else.
A Pareto nonoptimal state, which is what you get with public goods,
is a condition where you could redistribute wealth and resources and
make every person happier or at least no less happy.  In the case of,
say, recorded music as a public good, the market will not produce
enough music relative to a Pareto optimal state.  Some people would be
willing to pay for more music, and this money would be more than enough
to pay musicians to produce that music.  So there is a redistribution
which would make many people happier without making anyone less happy.
But this redistribution won't happen, under market conditions.  There is
no mechanism to force people to pay when everyone can get music for
free.  And people are not willing to make sufficiently large voluntary
contributions to fund the musicians because they know others are going
to benefit just as much without paying a dime (the free rider problem).
Detailed analysis supports the conclusion that, in general, markets
under-provide public goods relative to a Pareto optimal outcome.
Therefore it is clear that it is quite meaningful to investigate whether
markets produce efficient or non-efficient outcomes in various situations.
There is no tautology involved.

@_date: 2002-07-05 00:06:06
@_author: Anonymous 
@_subject: Closed source more secure than open source 
Ross Anderson's paper at
has been mostly discussed for what it says about the TCPA.  But the
first part of the paper is equally interesting.
The author analyzes the security implications of software development
using open source vs closed source.  He sets up a mathematical model
for the number of bugs remaining after a certain amount of testing.
Based on this model, he finds that both open and closed source development
methodologies are equally secure.
However his model has some simplifications and assumptions which are
quite unrealistic.  A more careful analysis will show that closed source
is the superior development method.
Essentially, the model assumes that each bug has a certain independent
probability of being found by testers, its own "MTBF".  Based on this
model it turns out that the probability of a security failure after time
t is inversely proportional to t.
He then writes, "Consider now what happens if we make the tester's job
harder.  Suppose that after the initial alpha testing of the product,
all subsequent testing is done by beta testers who have no access to the
source code, but can only try out various combinations of inputs in an
attempt to cause a failure.  If this makes the testers job on average
L times harder, so the bugs are L times more difficult to find... then
the probability that the system will fail the next test is..." inversely
proportional to t*L.  "In other words, the system's failure rate has just
dropped by a factor of L, just as we would expect."
The result is that, with access to the source code, bugs are L times
easier to find, but they are removed L times faster.  This corresponds to
the open source model. With closed source there is no access to the code,
bugs are removed L times slower, but they are L times harder to find.
The net result is that both open source and closed source are equivalent
in terms of how fast bugs are found, therefore both will be equally
vulnerable to exploiters of security bugs.
There are several problems with this analysis.  First, it is really not
true that external beta testers will be slowed down significantly by
lack of access to source code.  For most programs, source code will be of
no benefit to external testers, because they don't know how to program.
Someone who is testing a spreadsheet or word processor will have virtually
no benefit from access to the source code.  They will have no choice
but, as described above, to "try out various combinations of inputs in
an attempt to cause a failure."  This is true regardless of whether the
source code is available or not.
Therefore the rate at which (external) testers find bugs does not vary
by a factor of L between the open and closed source methodologies,
as assumed in the model.  In fact the rates will be approximately equal.
Another problem is that there are really three groups of parties involved
here: developers, external testers, and attackers.  Attackers, who are
trying to find breaks in software, are often highly motivated and skilled.
They can read code.  For them, the factor of L does come into play.
If they have access to the source code, they can find bugs L times faster
than if they don't, in accordance with the author's model.
The result is that once a product has gone into beta testing and then into
field installations, the rate of finding bugs by authorized testers will
be low, decreased by a factor of L, regardless of open or closed source.
But the rate of finding bugs by unauthorized, skilled attackers will be
affected by the availability of source.  Closed source will impair their
effectiveness by a factor of L, just as with the testers, so the model in
the paper is accurate in that case.  Bug open source benefits attackers;
they can find bugs at a rate of 1/t, while the authorized testers are
finding bugs at the slower rate of 1/(t*L).  The open source case will
leave more bugs available for attack, and the attackers can use the source
code to find them more quickly.  Therefore open source is more vulnerable
to attack, and closed source is the superior development method.
The one class of programs where this is not true would be those for which
the external testers benefit from having source available, which would
be programs where the testers are programmers; i.e., development tools.
For these programs the testers and attackers would both be affected in the
same way by availability of source.  But for most programs, attackers will
gain much more by having source available than the beta testers would.

@_date: 2002-07-05 17:09:04
@_author: Anonymous 
@_subject: Re: Need voluntary/optional TCPA/Palladium quote 
Lucky asks:
The TCPA FAQ at includes the following:
: 13. What has the TCPA done to preserve privacy?
: The TCPA believes that privacy is a necessary element of a trusted system.
: The TCPA Specification has taken specific steps to enhance trust while
: preserving privacy.  The system owner has ultimate control and permissions
: over private information and must "opt-in" to utilize the TCPA subsystem.
: Integrity metrics can be reported by the TCPA platform, but do not
: restrict the choice and options of the owner preserving openness.
This describes the system as "opt-in" and that says that it will
not restrict the choice and options of the owner.  That is, users
can enable the TCPA system and get their integrity metrics reported
(these are basically hashes of the BIOS, OS boot loader, etc.), which
will allow third parties to know that they booted into an unmodified,
trusted system.  But they always have the choice to boot into a modified,
patched or untrusted system, and in that case either the TCPA chip will
report it, or they can forego the use of the TCPA subsystem entirely.

@_date: 2002-07-07 23:51:06
@_author: Anonymous 
@_subject: DRM as a Smart Contract 
Nick Szabo created the idea of Smart Contracts several years ago.
  These would be self-enforcing agreements
that were based on technology rather than laws.  It all sounded cool at
the time.
But isn't DRM a form of Smart Contract?  If I need a special viewer to
download some content, and that viewer enforces the terms of the contract
which allows me to do the download, that enforcement happens without
any laws.  It is all handled by the technology.  It's a Smart Contract.
It's interesting how ideas can sound good until you realize that they
won't let you take other people's creative output without their consent.
Maybe it's time for cypherpunks to put principle over greed.

@_date: 2002-07-08 23:01:07
@_author: Anonymous 
@_subject: DRM will not be legislated 
Several people have suggested that DRM software is not bad in and
of itself.  So long as it is used voluntarily, it is not infringing
on anyone's freedom.  In fact they will even agree that voluntary DRM
can be a good thing; it increases people's options and can provide a
mechanism where content producers can get paid.
However they oppose DRM anyway, even voluntary DRM.  The reason is because
they see it as the first step towards mandated DRM.  If DRM hardware
and software are widely available, they reason, it will be that much
easier to get legislation passed to make them mandatory.  Most people will
already have systems which comply with the laws, so there will be no great
costs involved in requiring the systems.  In contrast, if no one had DRM
hardware and software installed, then mandating it would be politically
impossible, requiring virtually every computer in use to be junked or at
least to go through an expensive upgrade.  The costs of such a transition
would be enormous, and legislation to mandate DRM would never succeed.
This argument makes superficial sense, but it ultimately contradicts
itself on one major point: if DRM is so successful and widely used as
would be necessary for its mandate to be low-cost, then there is no
need to require it!  Opponents of the legislation need only point out
that consumers are voluntarily adopting the technology and that the
marketplace is working to solve the problem for the record labels and
other content companies.
In fact, there is very little incentive to push for mandating DRM features
on the part of any of the participants in the dispute: content companies
or technology companies.  What they really need to do is to make DRM
become popular as the only way to have a variety of good, legal content
be available.  A substantial number of consumers will voluntarily adopt
DRM if it lets them have a Napster-style system of music on demand,
with wide variety and convenient downloads, as long as the songs are not
too expensive.  The advantages of having a legal system that is immune
to the woes of the P2P world (constant shutdowns of popular systems due
to lawsuits, the problem of bogus data, etc.) will amply justify a modest
fee for the download.
It seems clear that this is the direction the record labels want to
pursue, and the only problem is that right now, if they make downloads
available without DRM restrictions, they will go right into the pirate
networks.  With DRM they have more control over how the data is used,
there will be less piracy, and therefore they can charge less per song.
Legislating the DRM is of no value in this scenario, because people
will still be able to use P2P and other software for piracy, whether
they have software that can support DRM or not.  (We will neglect the
plainly absurd argument that the computational infrastructure of the
entire nation will be changed so that only "authorized" or "approved"
software can run.)  The record labels still must pursuade people that
DRM is worth having, and the way they will do so is by making their data
available at a reasonable price, while continuing their technological and
legal attacks on P2P networks.  Legislating DRM will not substantially
help with any of these subgoals.
The one exception where legislation might be helpful would be for "closing
the analog hole", requirements to detect watermarked data and not process
it.  If all systems could be designed so that they recognized watermarks
in music and video and refused to play them, then that would cut down
on piracy.  But this is not DRM per se, it is really an orthogonal
technology.  One can oppose efforts to legislatively close the analog
hole while still supporting voluntary use of DRM software and hardware.
Ultimately, DRM must succeed as a value proposition for the end user.
Legislation to require DRM-observant software and hardware in all
computers will not establish this value.  By itself, such legislation
will not stop piracy and file sharing.  The only way to stop file sharing
is with massively intrusive legislation that would practically shut
down the net and most businesses as well.  Such a course is impossible
outside of the raving fantasies of the paranoid.  Given the reality of
ongoing file sharing, DRM must succeed by offering good value and the
guarantees of high quality that are not available in a black market.
Legislation of DRM is not in the cards, and this remote, hypothetical
possibility should not stop us from supporting voluntary DRM systems.

@_date: 2002-07-11 22:22:06
@_author: Anonymous 
@_subject: Re: Rant: The U.S. facing the largest financial collapse ever 
Standard accounting rules are completely inappropriate when looking at
the situation for an entire country over a period of decades.  By this
reasoning, a young family borrowing money to buy a house is making a huge
mistake because it will be in debt to the tune of several years' salary.
What is overlooked in this analysis is that the family, just starting
out in the world, can expect increased income over years to come.  In the
long run, that house will be very affordable based on the expected growth
in income.  But standard accounting principles do not take into account
expected future income.
This shows up most drastically in the case of Social Security, where we
are supposedly $20 trillion in debt.  What about the income which will
be used to pay off that debt?  Those figures are not included.
The fact is, like a young family starting out in the world, we have
every reason to expect our income levels to rise steadily over future
decades, just as they have done in the past.  The world is not a static
place.  Technology and science are improving at an ever-increasing rate.
These translate into productivity improvements, greater national income,
and a higher standard of living.
In fact, with biotech, nanotech, and all the other -techs that are
expected to become feasible within the next few decades, there is every
reason to expect that our income will begin growing at unprecedented
rates.  See some of the predictions at  for examples
of what the future is likely to bring.  (For a good laugh, get Tim May
to repeat his prediction about how nanotech will never go anywhere!
This at a time when you can hardly pick up a business magazine without
finding another article about this new investment opportunity.  Take it as
further evidence of his prognosticative abilities, which are demonstrated
in this thread as well.)
Against this background, it's pointless to worry about a Social Security
debt amounting to $200,000 per household over many decades.  By the
time today's young people are old enough to begin collecting retirement,
two major changes will have occured:
First, the world will be a much wealthier place; standards of living will
likely have more than doubled; technology will have created commonplace
devices that would be literally priceless today.  For such a world,
providing the retirement benefits at the levels specified by today's
laws will be easy and cheap.
But second, and more importantly, health and longevity will likely have
increased substantially as well.  By 2040 it's highly unlikely that a 65
year old man will be facing the kinds of health limitations that a man of
that age has to deal with today.  Four decades of medical research will
allow people who are elderly by today's standards to retain considerable
health and vigor.  There will be no need to retire by 65 if people don't
want to; they can work productively for many more years.
Of course these changes will have almost infinite ramifications as they
affect other parts of society.  The world is likely to be a very different
place in the next decades, as the pace of progress continues to quicken.
It's impossible to predict how it will all work out.  But it seems safe
to say that the world will give people far more choices and opportunities
than we see today.
Those people who do choose to retire at a youthful 65 can be easily
supported by the incredible productivity increases which the working
population enjoys.  In fact, retirement benefits may well be increased
far beyond what seems practical today, as by the standards of our future
wealth, today's comfortable living is seen as the squalor of poverty.
We have seen this trend going on for many decades, and it is only going
to increase in the future.
There are great things ahead, and it's sad to see someone who claims to
have a clear vision of the future get caught up in such petty concerns
as Social Security obligations.  There are serious problems ahead, some
of which were brought up by Bill Joy in his famous article.  But paying
for Social Security isn't one of them.

@_date: 2002-08-16 23:15:14
@_author: Anonymous 
@_subject: Re: Schneier on Palladium and the TCPA 
Bruce Schneier wrote about Palladium:
Actually his discussion in the book is about traditional "secure OS"
concepts such as Multics.  Trusted computing attempts to go considerably
beyond this.
That was the idea for secure OS's.  For trusted computing it is more
that you can have trust in an application running on a remote system,
that it is what it claims, and that it has a certain degree of immunity
from being compromised.
It's interesting that Bruce sees it in terms of attacks like this.  As he
is now in the managed security business, it makes sense that he would
look at Palladium in terms of how much security it can add to a system.
As far as viruses and such, the protection Palladium offers would seem to
be that if you load a trusted component, and it has been infected by a
virus since the last time you ran it, its hash will change.  This means
that it will no longer be able to access sealed data - it won't be able
to get into the "virtual vault" because it is no longer the same program.
Likewise it would not be able to participate in any trusted networking
because the fact of its compromise would be remotely observable (due to
the hash change).
This is not an all-purpose defense against viruses and such; it would
be restricted to the "trusted" parts of applications and it would only
work specifically with sealed data and trusted networking.  But for some
purposes it could be quite useful.  Imagine a banking app which keeps
your account access info sealed in a virtual vault; then no other app
can get to the data, so you are immune to virus attacks elsewhere in
the system; and if even the banking app itself is compromised, it will
no longer be able to get into its own vault.
This is a pretty far-fetched scenario, for several reasons.  First,
according to Peter Biddle, Palladium is designed to protect content and
not programs.  Sure, maybe you don't believe him, but at least he's on
record as saying it.  And what is known of the Palladium architecture
is consistent with his claim.  The limited architectural diagrams in
the Palladium white paper don't show any mechanism for locking code to
a computer.
But there are other problems with Bruce's scenario.  It assumes
(apparently) that you aren't copying your programs to your replacement
computer when you get rid of the old one!  That doesn't make sense.
You have an investment of hundreds or thousands of dollars in software.
You'll want to copy it over, and certainly Palladium will allow that.
So what's his objection in that case: that you can't sell an illegal
copy of your old software once you've installed it on the new system?
What's the "First Sale Doctrine" got to do with that?  It doesn't allow
for you to both keep a copy of your software and to sell it.  If he's
objecting that Palladium won't let you break the law in some ways you can
today, let him say so openly.  But as it is he is claiming that Palladium
will compromise the First Sale Doctrine, and that interpretation doesn't
hold water.
It's also not at all clear why you would want to wipe your keys like
this.  It should be enough to just delete your data files from the disk.
It's not like the trusted computing chip will hold kilobytes of sensitive
personal data.  All it has is a few keys, so if you get rid of the
data, the keys don't matter.  And then, how different is that from
what you do today?  If you sell an old computer, you should clear out
the sensitive data files, even if you leave the applications in place.
There is no reason why Palladium would be any different.
Everyone says this last point, and maybe it's true.  But at the same
time it's worth noting that Pd does more than is necessary for DRM - and
in fact it is not optimal for DRM.  The fact that Pd is open and useful
for a wide range of other applications is one piece of evidence.  We have
even discussed a Palladiumized Napster (PDster?) which could undercut the
interests of the content companies.
Microsoft didn't have to make Palladium an open system; they could have
kept control over the keys, and required that only signed apps can run
as trusted (as most people still appear to believe; see the discussion
today on slashdot).  Maybe you can argue that Microsoft felt forced to do
an open system just for public relations reasons, that they knew they'd
take too much heat if they produced the closed system they hypothetically
wanted.  Whatever their reasons, the fact is that Pd is a lot more open
than is optimal for DRM, and people should recognize that fact.
This piece of sanity is a breath of fresh air.  If only Ross Anderson
and Lucky Green and most of the cypherpunks had a similarly sound grip
on reality, the discussion of these technologies would have been greatly
Right, I think one of the big issues is whether Microsoft's patents cover
Palladium and TCPA, and whether it will even be possible to make a Linux
version of a trusted computing system.  As I have written before, in some
ways Linux is a much better platform for trusted computing than Windows
(due to its transparency, so much more important now that apps can cloak
themselves from users).  But if Microsoft patents block such an effort,
that could be a serious problem.  It is encouraging that HP and perhaps
IBM are going forward with a TCPA-enabled Linux; that suggests that the
Microsoft patents don't cover at least that specific architecture.
Ross Anderson makes a similar point, but it is quite misleading.
It implies that trusted computing is in some sense weaker than ordinary
computing because it requires you to trust more systems.  But it misses
the point, that trusted computing for the first time gives you grounds
to trust remote systems.  That's what's really new here, the ability to
have some foundation for trust in what a remote system is doing.  And so
I think the word trust is very appropriate here, and it carries its
usual connotations and meaning.  No one is "forced" to trust anything.
Trusted computing will make it more reasonable for people to choose to
trust remote systems.
To a large extent this is already true.  Who knows what is in the data
files and registry entries for all the closed-source Windows apps on
the market?  You already have apps putting crap on your computer and you
have no idea what is there.  Pd lets them wrap it in a secure envelope,
but that doesn't change the fact that data files are already essentially
opaque to the typical user.
This reasoning is totally backwards.  The RIAA are not Microsoft's
customers.  Microsoft doesn't sell much software to them.  Why can't
Microsoft afford for them not to make content available?  It's because
of the end users.  Those are the people Microsoft cares about!  It is
those people who buy Microsoft software.  The RIAA is only a means to
the end, the end being making end users happy.  Users want to be able
to play music and movies on their computers.  Microsoft is trying to
satisfy this market need.
The implication that Microsoft somehow doesn't care about end users and
is only concerned about the content industry has it totally backwards.
Microsoft cares only about the end users; the problem is that it needs
the content industry's permission in order to make end users happy.
This puts Microsoft between a rock and a hard place: the insatiable thirst
for content on the part of users, and the unreasoning terror which the
content companies feel about making their wares available on the net.
IMO this explains the openness of the Pd design.  Microsoft is not in
the pocket of the content companies, and Pd is not primarily about DRM.
It needs to be sufficient to provide DRM, but at the same time Microsoft
really wants to satisfy its customers, the people who buy PCs.  It is
for them that Microsoft makes Pd open, makes it optional, lets people
run whatever apps they like in trusted space.  Microsoft is gambling
that an open Pd will provide benefits over and above DRM, even if its
openness makes the content companies unhappy.
I agree that the point of Pd is totally to increase Microsoft's market
share.  In fact, as a general principle, everything every business does
is for that specific reason.  IMO it is sufficient to point to the many
benefits Pd can provide to end users to explain why Microsoft is pushing
Bruce listed the increased immunity to viruses, trojans and the like;
and the better-than-expected protection of user privacy.  Not much else.
It's not clear whether this counts as a lot to like, or whether there
are other things he likes which he did not mention here.
I can understand that those who have this vision of the future would
oppose Pd.  But I don't see this road laid out before us as so many other
people do.  Pd allows you to run apps that can prove to others that they
are what they say, that can run and store data without being compromised.
I don't see this as a step towards Big Brother.
If it did what people believed, took over your computer and let other
people run apps on it without your permission, wouldn't let you run
your own apps, gave other people "root" on your computer and took it
away from you, I'd agree with the concerns Bruce and others have raised.
But it doesn't do these things.  And to the extent that Pd moves in that
direction, it seems to me that PKI's and digital certificates and even
encryption have already put us on the road, creating data that is opaque
to us, data that we hold but are powerless to alter, data which is in
effect owned by someone else even though it rests on our own equipment.

@_date: 2002-08-11 14:35:08
@_author: Anonymous 
@_subject: Re: On the outright laughability of internet "democracy" 
Sure it is. The measures, if any, taken to insure that the "person" being granted a "digital voter registration card" is a "qualified voter" can be as lax or as stringent as the issuer may require. There is no reason that they would need be more stringent than current process, which, in the US, prohibit voter registration staff from requiring verification of identity. See the "Motor Voter" law.
Except in Chicago, etc., etc.
No different from the current arrangement. Voting in many jurisdictions can be done today by mail. How would a digital vote, using cryptographic protocols to insure anonymity, and authenticity (the registered person who was issued the digital voter registration has digitally signed the vote) be less likely to be "sold" than a mailed in vote?
And pardon the political comment, but almost all votes are sold now, as in the United States the democratic custom has declined to using votes essentially to transfer wealth from earners to voting blocs.
It is quite simpler to do such fraud with mail in votes, or even "buy me a drink and I'll vote however you'd like", or "yes, this is my pictureless voter registration card, and I'm here to vote".
A laugh a day keeps the economists away.
The "sold vote" boogeyman".
You need to submit evidence that "anonymous" "internet" voting is more likely to be fraudulent than paper, voter-present by mail voting. You have submitted none, and the "cryptography" word is insufficient to scare me off.
The "bogus digital voter registration" boogeyman.
You may also wish to show how digital voter registration cards would be more likely to be bogus than "Motor Voter, no-id required" registration cards. Good luck.
The "crypto" boogeyman.
I challenge you to show that current, published crypto voting protocols cannot accomplish the following:
1. one digital sig, one vote, the first one, and the others are discarded
2. no dig signature, no vote
3. no dig voter registration, no dig sig
4. anonymity, i.e., no connectibility between the voter's choice and his identity.
5. auditability, i.e., connection between each voting "lever throw" and a dig sig for the current vote.
Next, the "internet" boogeyman.
It's just a pipe/wire/whatever. Bits. Don't be afraid. If the bits are properly signed, no problem and whether "internet" bits or voter-machine-punched-paper-tape-bits is irrelevant.

@_date: 2002-08-15 17:06:06
@_author: Anonymous 
@_subject: Re: Overcoming the potential downside of TCPA 
Actually, this is not true for the endoresement key, PUBEK/PRIVEK, which
is the "main" TPM key, the one which gets certified by the "TPM Entity".
That key is generated only once on a TPM, before ownership, and must
exist before anyone can take ownership.  For reference, see section 9.2,
"The first call to TPM_CreateEndorsementKeyPair generates the endorsement
key pair. After a successful completion of TPM_CreateEndorsementKeyPair
all subsequent calls return TCPA_FAIL."  Also section 9.2.1 shows that
no ownership proof is necessary for this step, which is because there is
no owner at that time.  Then look at section 5.11.1, on taking ownership:
"user must encrypt the values using the PUBEK."  So the PUBEK must exist
before anyone can take ownership.
I don't quite follow what you are proposing here, but by the time you
purchase a board with a TPM chip on it, it will have already generated
its PUBEK and had it certified.  So you should not be able to transfer
a credential of this type from one board to another one.
Actually I don't see a function that will let the owner wipe the PUBEK.
He can wipe the rest of the TPM but that field appears to be set once,
retained forever.
For example, section 8.10: "Clear is the process of returning the TPM to
factory defaults."  But a couple of paragraphs later: "All TPM volatile
and non-volatile data is set to default value except the endorsement
key pair."
So I don't think your fraud will work.  Users will not wipe their
endorsement keys, accidentally or otherwise.  If a chip is badly enough
damaged that the PUBEK is lost, you will need a hardware replacement,
as I read the spec.
Keep in mind that I only started learning this stuff a few weeks ago,
so I am not an expert, but this is how it looks to me.

@_date: 2002-08-15 17:06:06
@_author: Anonymous 
@_subject: Re: Overcoming the potential downside of TCPA 
Actually, this is not true for the endoresement key, PUBEK/PRIVEK, which
is the "main" TPM key, the one which gets certified by the "TPM Entity".
That key is generated only once on a TPM, before ownership, and must
exist before anyone can take ownership.  For reference, see section 9.2,
"The first call to TPM_CreateEndorsementKeyPair generates the endorsement
key pair. After a successful completion of TPM_CreateEndorsementKeyPair
all subsequent calls return TCPA_FAIL."  Also section 9.2.1 shows that
no ownership proof is necessary for this step, which is because there is
no owner at that time.  Then look at section 5.11.1, on taking ownership:
"user must encrypt the values using the PUBEK."  So the PUBEK must exist
before anyone can take ownership.
I don't quite follow what you are proposing here, but by the time you
purchase a board with a TPM chip on it, it will have already generated
its PUBEK and had it certified.  So you should not be able to transfer
a credential of this type from one board to another one.
Actually I don't see a function that will let the owner wipe the PUBEK.
He can wipe the rest of the TPM but that field appears to be set once,
retained forever.
For example, section 8.10: "Clear is the process of returning the TPM to
factory defaults."  But a couple of paragraphs later: "All TPM volatile
and non-volatile data is set to default value except the endorsement
key pair."
So I don't think your fraud will work.  Users will not wipe their
endorsement keys, accidentally or otherwise.  If a chip is badly enough
damaged that the PUBEK is lost, you will need a hardware replacement,
as I read the spec.
Keep in mind that I only started learning this stuff a few weeks ago,
so I am not an expert, but this is how it looks to me.

@_date: 2002-09-10 16:50:07
@_author: Anonymous 
@_subject: Re: A message from Alan I. Leshner, AAAS CEO 
I really urge AAAS and the US government to focus first on the US Government, as it is not disputed that that entity was responsible for the processing and distribution of the Ames Strain of Anthrax, the only recent bio agent released in terrorist action resulting in fatalities in the US. It would be nice if the US Government would proceed to assign a whipping boy, who will of course show up dead somewhere, avoiding any need for messy trials, evidence, facts, etc., so we can all go back to granting unprecedented powers to our government. And the CIA needs Anthrax exactly why? Since we have signed treaties about bio warfare and development of agents for it, are we to understand that the CIA simply fills in for USAMRIID and CDC in developing defenses? Where in the CIA charter can I find biowar defense R&D?
In the meanwhile, everyone should continue to be afraid --- very afraid. It expedites legislation when people are panicing or raised to high levels of emotion.

@_date: 2002-11-23 07:43:09
@_author: Anonymous 
@_subject: Re: Microsoft on Darknet 
Can you fill in some details or supply a reference as to why
those behind the e-rand fail to inspire confidence?
R. J.

@_date: 2003-02-24 05:40:10
@_author: Anonymous 
@_subject: Ethnomathematics ... or niggers in space ? 
February 23, 2003 By DIRK OLIN
Mathematics is one academic subject that would seem to reside in a world
of universality, protected from competing opinions by the objectivity of
its laws. But the real universal law is that everything is relative,
even in math. The release last month of a new math curriculum for New
York City schools by Mayor Michael R. Bloomberg has elicited something
just short of vituperation. Back-to-basics advocates denounce as ''fuzzy
math'' its inclusion of so-called constructivist teaching techniques.
Critics complain that those approaches encourage self-discovery and
collaborative problem-solving at the expense of proved practices like
memorization, repetition and mastery of algorithm.
It's all the latest in a century of American math wars. The previous
generation can remember the struggle over ''new math'' during the 1950's
and 60's. (''Hooray for new math,/New-hoo-hoo math!'' Tom Lehrer sang.
''It won't do you a bit of good to review math./It's so simple,/So very
simple./That only a child can do it!'') Battles flared even earlier in
the century over ''progressive'' agendas for math education of the type
pushed by John Dewey.
How tame those struggles seem, however, when compared to the rising
vanguard of self-described ethnomathematicians. For some, the new
discipline just means studying the anthropology of various measurement
methods; they merely want to supplement the accepted canon -- from
Pythagoras to Euclid to Newton -- with mind-expanding explorations of
mathematical ideas from other cultures. For others, however,
ethnomathematics is an effort to supplant the tyranny of Western
mathematical standards.
The Postulates
Ethnomathematics has a few parents, but most observers trace its formal
birth to a speech given by the Brazilian mathematician Ubiratan
D'Ambrosio in the mid-1980's. Now an emeritus professor of math at the
State University of Campinas outside S-o Paulo, he explained his
thinking a couple of years ago to The Chronicle of Higher Education:
''Mathematics is absolutely integrated with Western civilization, which
conquered and dominated the entire world. The only possibility of
building up a planetary civilization depends on restoring the dignity of
the losers.'' Robert N. Proctor, who teaches the history of science at
Pennsylvania State University, says he wants to counter the notion
''that the West is the be all and end all'' when it comes to
mathematical studies. ''After all,'' he adds, ''all math is ethnomath --
not just African kinship numerics or Peruvian bead counting, but also
the C.I.A.'s number-crunching cryptology and Reaganomics.''
To redress their pedagogical grievances, these ethnomathematicians want
math curriculums that place greater emphasis on the systems of previous
civilizations and certain traditional cultures. Studies of state
civilizations might focus on Chinese or Arabic math concepts. One study,
for example, has shown how the Chinese Chu Shih-chieh triangle
anticipated by more than three centuries the highly similar arrangement
of numerals by Pascal that holds sway in many Western teachings of
probability theory.
In her seminal books ''Ethnomathematics'' and ''Mathematics Elsewhere,''
Marcia Ascher, emerita professor of mathematics at Ithaca College,
chronicles the astonishingly complex data-storage systems embedded in
quipu, bundles of cotton cord knotted by Incans according to a
sophisticated base-10 numeration system. At a more quotidian level, Ron
Eglash of Rensselaer Polytechnic Institute has written and taught
extensively about the nuances of fractals, or repeating patterns, that
can be found in certain African craft work. (Eglash stresses a
distinction between simple-minded multicultural math -- ''which merely
replaces Dick and Jane counting marbles with Tatuk and Esteban counting
coconuts'' -- and what he calls the ''deep design themes'' that
represent mature, developed mathematical systems too often ignored in
the study of many societies.)
What Its Critics Fear
Some of this is just fine, says David Klein, a professor of mathematics
with California State University at Northridge. Klein (a self-described
liberal who insists on separating his academic critique from any
connection to a conservative political agenda) says the danger lies in
allowing such precepts to crowd out fundaments on which modernity is
based. He argues that the statistically lower achievements of some
female and minority math students have resulted in an overreaction that
doesn't serve their interests. ''The practical effect,'' Klein says,
''has been watered-down math books that overemphasize inductive
reasoning (like continuing visual patterns), because this is supposed to
be good for women and minorities, and de-emphasizing deductive reasoning
and mathematical proofs, which is the heart of mathematics, because that
supposedly favors white males.
''But mathematics is a worldwide monoculture. Look at the chalkboards in
math departments at universities all around the world -- in Africa,
Asia, Europe, Latin America. You will see the same symbols everywhere
you go on this planet, except perhaps in colleges of education where
fads reign supreme.'' Klein says he does spend some class time
discussing the math of Mayans, Egyptians and other early civilizations.
''But ancient techniques and early discoveries in math will not take
students very far who want to do something in the modern world with
mathematics,'' he says.
Will It Pass?
Some proponents argue that whatever the freestanding authenticity of the
cross-discipline, it is useful as a carrot to attract indifferent
students. Philip Straffin, who has been teaching the popular ''Cultural
Approaches to Mathematics'' at Beloit College for about 10 years, says
that the lectures lure a mix of teachers in training and art students:
''Every time we give this course, there are twice as many students who
want to take it as we have room for.'' As long as such developments
complement and enhance rather than take time from and substitute for
other mathematics learning, Judith Grabiner, who teaches at Pitzer
College, says they are a plus. ''I don't want people teaching students
that Mohammed ibn Musa al-Khwarizmi gave a systematic treatment of
quadratic equations in the 10th century instead of learning how to solve
quadratic equations,'' she says. ''But that's a false choice. Putting
the math in its cultural context helps teach the mathematics and makes
it more meaningful to students, since it has a human context.''
Indeed, those who think this threatens to spawn a brave new world of
mathematical correctness might search their memories to recall if they
didn't have a fourth- or fifth-grade teacher who brought an abacus to
Calculating Cultural Impact
From 'Ethnomathematics: A Multicultural View of Mathematical Ideas,' by
Marcia Ascher
For mathematics, however, there has been a long philosophical debate on
the reality of the objects it studies. Is a square something that has
external reality or is it something only in our minds? . . . The
relationship between the length of the hypotenuse and lengths of the
sides of a right triangle is an eternal truth, but that does not mean
that any other culture need share the categories triangle, right
triangle, hypotenuse. . . . A critical issue is that, as it stands, much
of mathematics education depends upon assumptions of Western culture and
carries with it Western values. Those with other traditions are, as a
result, often turned away by the subject or unsuccessful in learning it.
And, for them, the process of learning mathematics, particularly when
unsuccessful -- but even when successful -- can be personally
debilitating as it detracts from and conflicts with their own cultural
traditions. . . . [In] the United States, the concern has been
stimulated by the realization that our educational approaches have yet
to come to grips with the fact that we ourselves are a multicultural
Dirk Olin is national editor at The American Lawyer.
