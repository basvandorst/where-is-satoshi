
@_date: 2002-01-04 19:59:22
@_author: Hadmut Danisch 
@_subject: Re: Hackers Targeting Home Computers 
There's good reason for the different results.
I'm located in Germany and my DSL line is from "Deutsche Telekom"
(T-DSL, T-Online). This is by far the biggest provider in Germany for private DSL internet access, and they also do provide large numbers of modem and ISDN accounts. They use
a few very well known ip address ranges for all DSL, modem and
ISDN customers. Scanning the T-Online address ranges allows you to find heaps of german private computers. Many of the attacks
I detect come from within the T-Online network, others often come from
the countries you describe. I compared results with some of the colleagues results and with results we get from commercial firewalls
at the same time. There is a significant difference. It
appears that the T-Online network ranges are a favored
target of many hackers/scanners/script kiddies.
There's no doubt that some attackers prefer attacking private
computers and select address ranges where they find most of
these computers.

@_date: 2002-01-04 17:54:57
@_author: Hadmut Danisch 
@_subject: Re: Hackers Targeting Home Computers 
On my private computer (DSL, dynamically assigned IP address), I
detect an increasing density of attack attempts. More or less serious
attempts happen every few minutes in average (depends on daytime). Highest density is in the evening hours, when hackers and victims
find time to be online.
This means the probability of an infection of an unprotected
private computer is quite high after only some hours of internet
access. Most ("normal") people I know use such unprotected
computers for internet access.

@_date: 2002-07-05 14:20:02
@_author: Hadmut Danisch 
@_subject: Re: Ross's TCPA paper 
That's why I was talking about a shell script (or take any
other program to be interpreted).
What does need to be certified: The shell or the shell script?
The CPU doesn't recognize the shell script as a program, this
is just some plain data entered through the keyboard like
writing a letter. A shell script is not a program, it is
data entered at a program's runtime.
This moves one step forward:
The hardware (palladium chip, memory management, etc.) can
check the binary program to be loaded. So you won'te be able
to run a compiled program and to access protected information.
But once a certified software is running, it takes input
(reading mouse, keyboard, files, asking DNS, connecting servers,...). This input might cause (by interpretation, by
bug or however) the certified software to do certain things
which do not comply with DRM requirements.
At this stage, the running binary software itself is the
instance to provide the DRM security, not the palladium memory management anymore. I agree that this is not yet an "open sesame", but it shows
that the game does not play on the binary/memory management
layer only.
But who controls runtime input?
History shows, that M$ software is anything but able
to deal with malicious input. That's why the world is
using virus filters. That's nothing else than an external
filter to keep malicious input from an attacker away
from the running software.
By analogy, Palladium might require the same: an input
filter between attacker and running software. Since the
"attacker" is sitting in front of the computer this time,
this filter has to be applied to the user interface,
keyboard and mouse.
Maybe they'll install a filter between the keyboard and
the software, thus building a certified keyboard, which
filters out any malicious key sequences. And maybe you
can use your keyboard only, if you have downloaded the
latest patterns (like your daily virus filter update).
I agree that this depends on the assumption that the certified software is not perfect and can't
deal with arbitrary input. But that's reality.

@_date: 2002-07-05 14:20:02
@_author: Hadmut Danisch 
@_subject: Re: Ross's TCPA paper 
That's why I was talking about a shell script (or take any
other program to be interpreted).
What does need to be certified: The shell or the shell script?
The CPU doesn't recognize the shell script as a program, this
is just some plain data entered through the keyboard like
writing a letter. A shell script is not a program, it is
data entered at a program's runtime.
This moves one step forward:
The hardware (palladium chip, memory management, etc.) can
check the binary program to be loaded. So you won'te be able
to run a compiled program and to access protected information.
But once a certified software is running, it takes input
(reading mouse, keyboard, files, asking DNS, connecting servers,...). This input might cause (by interpretation, by
bug or however) the certified software to do certain things
which do not comply with DRM requirements.
At this stage, the running binary software itself is the
instance to provide the DRM security, not the palladium memory management anymore. I agree that this is not yet an "open sesame", but it shows
that the game does not play on the binary/memory management
layer only.
But who controls runtime input?
History shows, that M$ software is anything but able
to deal with malicious input. That's why the world is
using virus filters. That's nothing else than an external
filter to keep malicious input from an attacker away
from the running software.
By analogy, Palladium might require the same: an input
filter between attacker and running software. Since the
"attacker" is sitting in front of the computer this time,
this filter has to be applied to the user interface,
keyboard and mouse.
Maybe they'll install a filter between the keyboard and
the software, thus building a certified keyboard, which
filters out any malicious key sequences. And maybe you
can use your keyboard only, if you have downloaded the
latest patterns (like your daily virus filter update).
I agree that this depends on the assumption that the certified software is not perfect and can't
deal with arbitrary input. But that's reality.

@_date: 2002-07-05 11:31:48
@_author: Hadmut Danisch 
@_subject: Re: Ross's TCPA paper 
That *might* be a contradiction in terms.
If I understand this correctly, the TCPA or Palladium hardware will include some kind of memory management device, very similar
to the ones we have in hardware of the last years, but which stores
some kind of de-/encryption information for each page segment and
which de-/encrypts every memory access. Doesn't seem to be much of
a problem, except for speed.
But how does this device know which segments belong to the software
and which don't? Or how does it know whether an allowed or foreign task
is accessing the protected areas (which is the same question again,
= is the PC in a program segment which also belongs to the protected
area). If this is done the simple way, like a normal OS configures the
memory management when loading some executable software, the OS
might at any time give wrong information to the device. In this case, the security depends on the integrity and bug-freeness of the OS, because the OS _could_ do it, but it is not supposed to do it.
A more advanced way would be to have the program loaded by the operating system as before, but to have the Palladium device check
some kind of signature to verify the correctness of the OS loading operation. This might lead to an uncontrollable problems, if programs start to load DLLs. Is the TCPA/Palladium
trust transitive? If library A is trusted, and so is B, is then
(A+B) trusted?
A third way would be to keep the OS completely out of the job
of loading software/programs into memory, and to have it done
by the Palladium device. This isn't actually a third way, but
a redefinition of terms and a migration. The OS isn't the OS
anymore, because basic tasks of the OS have been migrated to
the Palladium device, which is now to be considered as a
piece of OS in silicon.
I didn't find the time yet to read the TCPA description in detail. But from my current point of view I doubt that this
will really work, provide the claimed security, and will still
be a useful computer at the same time.
I especially doubt that the same company, which completely fails to
make Outlook or Internet Explorer resistent against content attacks (viruses, worms, ...) will be able to provide
software which such a strict separation between trusted and untrusted
data, as it is required for such a project to work.

@_date: 2002-07-05 11:31:48
@_author: Hadmut Danisch 
@_subject: Re: Ross's TCPA paper 
That *might* be a contradiction in terms.
If I understand this correctly, the TCPA or Palladium hardware will include some kind of memory management device, very similar
to the ones we have in hardware of the last years, but which stores
some kind of de-/encryption information for each page segment and
which de-/encrypts every memory access. Doesn't seem to be much of
a problem, except for speed.
But how does this device know which segments belong to the software
and which don't? Or how does it know whether an allowed or foreign task
is accessing the protected areas (which is the same question again,
= is the PC in a program segment which also belongs to the protected
area). If this is done the simple way, like a normal OS configures the
memory management when loading some executable software, the OS
might at any time give wrong information to the device. In this case, the security depends on the integrity and bug-freeness of the OS, because the OS _could_ do it, but it is not supposed to do it.
A more advanced way would be to have the program loaded by the operating system as before, but to have the Palladium device check
some kind of signature to verify the correctness of the OS loading operation. This might lead to an uncontrollable problems, if programs start to load DLLs. Is the TCPA/Palladium
trust transitive? If library A is trusted, and so is B, is then
(A+B) trusted?
A third way would be to keep the OS completely out of the job
of loading software/programs into memory, and to have it done
by the Palladium device. This isn't actually a third way, but
a redefinition of terms and a migration. The OS isn't the OS
anymore, because basic tasks of the OS have been migrated to
the Palladium device, which is now to be considered as a
piece of OS in silicon.
I didn't find the time yet to read the TCPA description in detail. But from my current point of view I doubt that this
will really work, provide the claimed security, and will still
be a useful computer at the same time.
I especially doubt that the same company, which completely fails to
make Outlook or Internet Explorer resistent against content attacks (viruses, worms, ...) will be able to provide
software which such a strict separation between trusted and untrusted
data, as it is required for such a project to work.

@_date: 2002-07-04 20:54:11
@_author: Hadmut Danisch 
@_subject: Re: Ross's TCPA paper 
I don't think so. As far as I understood, the bus system (PCI,...) will be encrypted as well. You'll have
to use a NIC which is certified and can decrypt the information
on the bus. Obviously, you won't get a certification for such
an network card.
But this implies other problems:
You won't be able to enter a simple shell script through the
keyboard. If so, you could simple print protected files as
a hexdump or use the screen (or maybe the sound device or any
LED) as a serial interface.
Since you could use the keyboard to enter a non-certified
program, the keyboard is to be considered as a nontrusted
device. This means that you either
* have to use a certified keyboard which doesn't let   you enter bad programs
* don't have a keyboard at all
* or are not able to use shell scripts (at least not in
  trusted context). This means a   strict separation between certified software and data.
  If Microsoft was able to do so, we wouldn't have   worms.

@_date: 2002-07-04 20:54:11
@_author: Hadmut Danisch 
@_subject: Re: Ross's TCPA paper 
I don't think so. As far as I understood, the bus system (PCI,...) will be encrypted as well. You'll have
to use a NIC which is certified and can decrypt the information
on the bus. Obviously, you won't get a certification for such
an network card.
But this implies other problems:
You won't be able to enter a simple shell script through the
keyboard. If so, you could simple print protected files as
a hexdump or use the screen (or maybe the sound device or any
LED) as a serial interface.
Since you could use the keyboard to enter a non-certified
program, the keyboard is to be considered as a nontrusted
device. This means that you either
* have to use a certified keyboard which doesn't let   you enter bad programs
* don't have a keyboard at all
* or are not able to use shell scripts (at least not in
  trusted context). This means a   strict separation between certified software and data.
  If Microsoft was able to do so, we wouldn't have   worms.

@_date: 2002-08-16 16:27:46
@_author: Hadmut Danisch 
@_subject: Re: employment market for applied cryptographers? 
Same effect here in Germany.
I'm under the impression that security was never really done
for security reasons, but as a kind of fashion. Do it because
everyone is doing it. It's a problem of the decision makers.
Many companies don't effectively want to have security.
They just want to claim to have. Very few of them are really
interested in having a secure network structure. Decision
makers often still believe that "security" means having
a firewall and a virus filter. Meanwhile, virtually anyone has some kind of firewall. Everyone has installed some kind of virus scanning software
on the mailserver. That fulfills everything decision makers
know about security. Why waste money for a security engineer?
Why should we have a security engineer to keep the firewall
and the scanner alive, if our normal sysadmin can keep
the software alive as well?
I know several german companies who are explicitely looking
for a security specialist as an employee, but once you examine the job offer, you'll find that they don't want
a security engineer who makes their network or software secure. They're looking for a "security engineer" just to exist and to keep the mouth shut. Just to have an office
with the label "security", but not causing any trouble.
"Security" was never really a requirement, it was some
kind of fashion. Fashions come, fashions go. It's not seen
as causing revenue. So just drop it if times get worse. Security has crossed its highest level. It will decrease
from now on.

@_date: 2002-11-20 09:58:29
@_author: Hadmut Danisch 
@_subject: Re: 17 Cypherpunks subscribers on watch list, Project Lookout 
It's even worse: I know some american court decisions which limit the rights given in the american constitution to american citizens only. E.g. the fourth amendment does not
apply to non-americans, therefore police doesn't even need a
warrant to search their house or computer in the eyes of US justice.
e.g. the Gorshkov case:
Does anybody know how to get the text of the decision?

@_date: 2004-11-21 20:36:01
@_author: Hadmut Danisch 
@_subject: Re: E-Mail Authentication Will Not End Spam, Panelists Say 
which is, btw, not really correct.
I was one of those panelists, and I explicitely stated that
authentication is only the first step, but an important step, which requires a second step (literally in my slides). So the
first statement seems to be a quote of my talk.
But my statement about the second step was that "reputation" does not
work on an international scale, this works in the U.S. only. It might
even be unlawful in Europe. My proposal was to do the second step
individually for each country.
