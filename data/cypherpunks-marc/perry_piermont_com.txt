
@_date: 2002-08-16 16:57:09
@_author: "Perry E. Metzger" 
@_subject: Re: employment market for applied cryptographers? 
Hard to say.
I've seen very high rates of unemployment among people of all walks of
life in New York of late -- I know a lot of lawyers, systems
administrators, secretaries, advertising types, etc. who are out of
work or have been underemployed for a year or longer. I'm not sure
that it is just cryptographers.
Always keep in mind when you hear the latest economic statistics that
measuring the size of the US economy, or the number of unemployed
people, is partially voodoo. When was the last time you saw any
estimate of the margin of error on the supposedly "scientific"
measurement of quarterly economic growth? How many illegal immigrants
are being polled in the employment stats? How much of the revenue of
underground businesses gets counted in the GDP figures?
(I myself am unemployed at the moment, but voluntarily so I suppose I
wouldn't count in the statistics -- starting a company during a
recession turns out to be a great way to burn yourself out out, so I
decided to take some time off of working. Haven't given much thought
to what I'll do to find a job when I decide I want one again...)

@_date: 2002-08-16 16:57:09
@_author: "Perry E. Metzger" 
@_subject: Re: employment market for applied cryptographers? 
Hard to say.
I've seen very high rates of unemployment among people of all walks of
life in New York of late -- I know a lot of lawyers, systems
administrators, secretaries, advertising types, etc. who are out of
work or have been underemployed for a year or longer. I'm not sure
that it is just cryptographers.
Always keep in mind when you hear the latest economic statistics that
measuring the size of the US economy, or the number of unemployed
people, is partially voodoo. When was the last time you saw any
estimate of the margin of error on the supposedly "scientific"
measurement of quarterly economic growth? How many illegal immigrants
are being polled in the employment stats? How much of the revenue of
underground businesses gets counted in the GDP figures?
[I myself am not working at the moment, but voluntarily so I suppose I
wouldn't count in the statistics as "unemployed" -- starting a company
during a recession turns out to be a great way to burn yourself
completely out out, and I decided to take some time off of
working. Haven't given much thought to what I'll do to find a job when
I decide I want one again...]

@_date: 2002-09-19 01:55:38
@_author: "Perry E. Metzger" 
@_subject: Re: Cryptogram: Palladium Only for DRM 
This brings to mind my youth, in which I worked for a wall street firm
in which we systematically cracked the copy protection and license
managers on SunOS software we were using. Was it to pirate the
software? No. We paid for every license. It was because the
manufacturers had neglected to consider that in a 24x7 environment
having a machine go down meant that we needed to bring the software up
on hosts other than the one originally licensed, and we didn't have
time to wait until Monday when everyone got back to their office and
give us a new key. A few small kernel patches allowed us to routinely
tell programs that the host id was whatever we wanted them to think it was.
I recently have heard tell from friends of similar systematic uses of
cracked Microsoft software at a number of places -- not because these
places pirate the software, but because they can't deal with the
constant failures that the increasingly belligerent M$ copy
restrictions bring. Customers need to get work done, and the copy
protections get in the way. XP is particularly egregious in this
regard, but some people are getting around this with cracking tools,
even though they pay for their software legitimately.
One wonders if better license enforcement might not be a good thing,
since it would doubtless finish off Microsoft by eliminating the
ability of their legitimate customers to evade their license
enforcement software, thus driving them to use open source products.

@_date: 2002-09-17 03:01:06
@_author: "Perry E. Metzger" 
@_subject: Re: Cryptogram: Palladium Only for DRM 
It takes a lot for me to get cranky around here, but I'm afraid Aarg!
has done it.
You conveniently cut what I said selectively, sarcastically replying
to only pieces of it. You completely ignored much of the substance,
such as the fact that in a correctly operating OS, MMUs+file
permissions do more or less stop processes from seeing each others
data if the OS functions correctly.
So, to summarize, you ignored most of what I said, but managed to be
incredibly rude. I've noticed you doing the same to lots of others.
Here's a strong suggestion for the future, Anonymous. Never anger the
moderator of a moderated mailing list. You can be the agent
provocateur all day long, but you can't be snide and unresponsive.
I'm going to ask that you go back and respond to my message without
being insulting and without being selective about what sections you
quote. If you want another copy, well, I don't know how to send it to
you -- I can only hope you saved it. Until then, I'm not forwarding
your mail.
If you want to play your game here, you're going to have to do it
politely and reasonably. Sorry for doing this in public but I have no
other way of communicating with you.

@_date: 2002-09-16 20:32:04
@_author: "Perry E. Metzger" 
@_subject: Re: Cryptogram: Palladium Only for DRM 
That's what an MMU and file permissions are for. Palladium isn't
needed for such a thing.
Why not simply design the OS so it is not a likely victim for viruses?
This is a general security problem, not one special to banking
operations. My own machine doesn't seem to get viruses -- but then
again it doesn't run Windows. Funny, that.
(And before you mention the current worm infecting Linux apache sites,
that's also caused by bad design, not an problem that requires
hardware to fix.)
There are patches to NetBSD that happily prevent a program that does
not have a particular hash from executing, and similar code for
several other OSes I've seen. We need no hardware to do this. On the
other hand, who needs hash functions when an ordinary user can't alter
the executable because he doesn't have permissions?
I know this is a new concept to windows users -- I had to give my CFO
admin privs on his XP box because Quickbooks refused to run otherwise

@_date: 2002-11-06 16:58:45
@_author: "Perry E. Metzger" 
@_subject: Re: Did you *really* zeroize that key? 
Someone wrote to me:
K&R is not the C standard. Quoting the C99 standard, section 6.7.3.6:
     An object that has volatile-qualified type may be modified in
     ways unknown to the implementation or have other unknown side
     effects. Therefore any expression referring to such an object
     shall be evaluated strictly according to the rules of the
     abstract machine, as described in 5.1.2.3. Furthermore, at every
     sequence point the value last stored in the object shall agree
     with that prescribed by the abstract machine, except as modified
     by the unknown factors mentioned previously.
In other words: no, "volatile" is mandatory and in fact will be
guaranteed to be implemented as expected. This is very important --
virtually every operating system requires "volatile" for purposes like
writing device drivers.

@_date: 2003-08-21 19:10:02
@_author: "Perry E. Metzger" 
@_subject: ADMIN: List returning 
The list should be coming back on the air of the next few days. I'll
be approving a large batch of recent posts in a few hours, and then
most of the rest next Tuesday. (Don't expect new posts to be approved
over the weekend, though I'll do it if I can get to it.)
PS I'd say "We apologize for the inconvenience." but I don't want to
sound overly Sirius Cybernetics about it...

@_date: 2004-04-08 12:24:13
@_author: "Perry E. Metzger" 
@_subject: Re: voting 
Seems fine by me, except I'd make the ballot box only lightly frosted

@_date: 2004-04-07 21:19:11
@_author: "Perry E. Metzger" 
@_subject: voting 
I'm a believer in the KISS principle.
A ballot that is both machine and human readable and is constructed by
machine seems ideal. You enter your votes, a card drops down, you
verify it and drop it in a slot. Ideally, the cards would be marked
with something like OCR-B so that the correspondence between machine
marking and human marking is trivial.
You can't have "hanging chads" or mismarks on optical cards because a
machine marks it for you. You can always do a recount, just by running
the cards through the reader again. You can prevent ballot stuffing by
having representatives of several parties physically present during
the handling of the ballot boxes -- just like now. You can verify that
the counting mechanisms are working right by manually counting if
Complicated systems are the bane of security. Systems like this are
simple to understand, simple to audit, simple to guard.

@_date: 2004-05-28 17:28:07
@_author: "Perry E. Metzger" 
@_subject: Re: Satellite eavesdropping of 802.11b traffic 
As I mentioned, phased arrays are very good at getting out from under
the "too many users of the same channel" problem while
eavesdropping. They allow you to focus on multiple sources

@_date: 2004-05-28 01:19:17
@_author: "Perry E. Metzger" 
@_subject: Re: Satellite eavesdropping of 802.11b traffic 
Dunno if it would work in orbit,, but you can get surprising results
right here on earth using phased arrays.
Vivato is selling very long range phased array equipment as long
range/high quality 802.11 basestations, but you could do precisely the
same trick to eavesdrop instead of to communicate. With enough
computing power, one device could listen in on every 802.11
communication in a very large radius.
I don't know how practical it would be to set up some sort of large
scale phased array in orbit -- I suspect the answer is "not practical
at all" -- but the principle could apply there, too.

@_date: 2004-07-10 22:33:01
@_author: "Perry E. Metzger" 
@_subject: Re: EZ Pass and the fast lane .... 
By the way, this is yet another instance in which it is important to
consider threat models and economics when thinking about security
systems. The people willing to fake both their license plates and
their EZ Pass device are few, so the losses from them will be
small. (If you fake your license plates, in many instances you don't
even need to fake the EZ Pass device as nothing prevents you from
simply driving through.)
On the other hand, the cost of a system capable of doing a
challenge-response turnaround -- and we're talking both that of
building new tags plus the cost of designing and deploying units
capable of conducting two full round trip communications with cars
going through at 25 miles an hour -- is pretty high. You also will
always need the camera systems because you need to catch people simply
driving through, and because you will always get toll disputes that
need resolution. That means you can't even save the cost of the plate
cameras even with a challenge/response system.
Economically speaking, then, it doesn't seem like the threat (a small
amount of toll evasion by people willing to fake their license plates
and to clone EZ Pass equipment) doesn't cost as much as the putative
cure, and can't even cure the problem (since fare evaders with fake
plates will simply drive through toll lanes without physical barriers,
such as all the high speed toll lanes).
If I were advising the automated toll system people, I'd say it was
not worth it.
On the other hand, more complicated tags *might* be worth it for
another purpose -- preserving the privacy of drivers by using more
complicated protocols. However, as the benefit of such systems is to
people who are unlikely to have much voice in the construction of the
system, and who are also unlikely to be willing to pay more money to
gain privacy, I think the implementation of such tags is unlikely.

@_date: 2004-07-09 23:14:33
@_author: "Perry E. Metzger" 
@_subject: Re: EZ Pass and the fast lane .... 
I doubt it.
All the toll lanes that accept EZ Pass that I've seen are equipped
with cameras. These cameras are used to identify toll evaders
already. You point out that doing this would require manual work, but
in fact several systems (including the one used for handling traffic
fees in central London) have already demonstrated that automated
license plate reading systems are feasible. Even without automated
plate reading, storing photographs is also now astoundingly cheap
given how cheap storage has gotten, so if anyone ever complained about
incorrect charges on their bill, finding the plates of the cars that
went through during the disputed toll collections would be trivial.
Unlike cellphones, this is not an instance where it would be easy to
get away with theft by cloning.

@_date: 2004-08-17 02:29:24
@_author: "Perry E. Metzger" 
@_subject: HMAC? 
So the question now arises, is HMAC using any of the broken hash
functions vulnerable?
I can't answer that myself yet since I haven't given it a good enough
think, but I'll will point people at the original HMAC paper at:
The paper itself is at:

@_date: 2004-10-22 12:40:27
@_author: "Perry E. Metzger" 
@_subject: Re: Are new passports [an] identity-theft risk? 
I don't know who *else* has said it, but I've said this repeatedly at
conferences. With phased arrays, you should be able to read RFID tags
at surprising distances, and in spite of attempts to jam such signals
(such as RSA's proposed RFID privacy mechanism).
This isn't terribly surprising but for the fact that most people don't
think in terms of the fact that you can spatially discriminate radio

@_date: 2005-01-16 04:32:15
@_author: "Perry E. Metzger" 
@_subject: Re: panix.com hijacked 
Alexis Rosen of Panix was on the phone earlier today with the company
attorney for melbourneit -- reputedly he was informed that even if the
police called, they would not do anything about the problem until
Monday their time.
Alexis is a bit on the upset side, naturally -- his company is in
serious trouble because of very obvious fraud, and waiting a few days
isn't really something he can afford to do. (If you look at the whois
records now in place for panix.com they're pretty clearly the result
of fraudulent activity. There is a pretty clear attempt there to
maximally obscure who has stolen the domain name -- this is clearly
not an innocent mistake.)

@_date: 2005-01-16 03:50:49
@_author: "Perry E. Metzger" 
@_subject: Re: panix.com hijacked 
Dotster isn't in a position to do anything. They don't show the domain
as being transfered. Someone managed to hack the system. They're
pretty upset by the situation, too.
The membourneit.com folks conveniently refuse to do anything over the
weekend. The bad guys struck around midnight Saturday, Australian
time, so as to make the damage as bad as possible.
Panix is highly screwed by this -- their users are all off the air,
and they can't really wait for an appeals process to complete in order
to get everything back together again.

@_date: 2008-01-15 13:19:11
@_author: "Perry E. Metzger" 
@_subject: US drafting plan to allow government access to any email or Web search 
Forwarded from Dave Farber's list:
Sent: Monday, January 14, 2008 6:41 PM
Quoting from:
                National Intelligence Director Mike McConnell is drawing up
        plans for cyberspace spying that would make the current debate
        on warrantless wiretaps look like a "walk in the park," according
        to an interview published in the New Yorker's print edition today.
        Debate on the Foreign Intelligence Surveillance Act "will be a
        walk in the park compared to this," McConnell said. "this is going
        to be a goat rope on the Hill. My prediction is that we're going
        to screw around with this until something horrendous happens."
        The article, which profiles the 65-year-old former admiral
        appointed by President George W. Bush in January 2007 to oversee
        all of America's intelligence agencies, was not published on
        the New Yorker's Web site. (It can be read here in pdf).
        [...]
The PDF link points to:
        which I'm unable to access at the moment.

@_date: 2009-03-03 23:38:45
@_author: "Perry E. Metzger" 
@_subject: Re: Judge orders defendant to decrypt PGP-protected laptop 
Again, you seem to be operating under the common geek misperception
that courts operate like Turing machines, precisely and literally
executing precisely defined legal concepts.
They do not work that way.
Courts work much more the way the high school vice principal who put
you on detention for three weeks for throwing a snowball worked --
even though he didn't see you throw one, he just saw you were the only
person in the general vicinity, even though it was all patently unfair
since he had no "proof" by your lights.
The law's idea of what sufficient evidence means is not what you, as a
geek, think sufficient evidence means. For example, perhaps to you,
"beyond a reasonable doubt" means something like "there is no way you
couldn't be guilty", while to a court it means nothing like that -- it
means that an ordinary person (that is, not a geek, not a professional
defense attorney, not a mystery novel addict) wouldn't have serious
doubts about guilt. Not no doubts -- just no serious ones.
The law is used to people trying to weasel out of trouble -- people
have been trying to weasel out of trouble since the year 100,000
BC. Criminals were trying far more elaborate schemes to get out from
under trouble than you will ever think of back in ancient
Mesopotamia. You're not going to find something new that impresses a
real court.
Take a real common case. Someone is mugged by two people. One of them
shoots the victim and neither will say which of them did it. You, the
geek who thinks the law is a Turing machine, assume that neither can
go to jail for murder. "In the case of each criminal", you assume,
"there is a reasonable doubt as to whether or not the other guy did
it. 50/50 is a way reasonable doubt!"
Well, that's not how the real legal system works. In the real legal
system, the court will happily put both people in jail for murder even
though there is only one bullet in the victim so only one person could
have pulled the trigger. That's routine, in fact, never mind how
"unfair" that seems to you. (The charge of felony murder exists
precisely so that they don't need to know who pulled the
trigger. As I said, they're used to people trying to weasel out of
"But but!" you scream, "there has to be a reasonable doubt there! Only
one of them could have done it, clearly one person is in jail
unfairly, they both have to go free!" -- well, that's the difference
between you and a lawyer. The lawyer doesn't see this as
unreasonable. The court system is not a Turing machine.
Back to our topic: if the software can handle multiple hidden
encrypted volumes and there is unaccounted for space and the volume
you decrypt for them has nothing but pictures of bunnies and sunsets
and hasn't been touched in a year, I think you're going to jail for
contempt if the judge has ordered you to fork over the files.
"But!!!" you insist, "they don't have proof that I'm doing something
qua proof, they just a strong suspicion! Why, it could be anything in
that giant pool of random bits on the rest of the drive! How do they
*know* it isn't just random bits? How do they *know* I don't just look
at bunnies and sunsets and haven't opened that partition in a year?"
You only think that will protect you because you don't understand the
legal system. You see, you're making this assumption that most people
would call "assuming the judge is an idiot".
Judges take a very dim view of people playing them for fools, just
like high school vice principals, and again, the legal system is not a
Turing machine. The judge's superiors on the appeals court will take a
similar view because they were once trial judges and don't like when
judges are played for fools either.
So, the court is not going to pay the least attention to your
elaborate claims that you just like storing the output of your random
number generator on a large chunk of your hard drive. They really
don't give a damn about claims like that. Actually they do
care. They'll be pissed off that you're wasting their time.
If you believe otherwise, go right ahead, but as I said, the jails are
filled with people who have tried very elaborate strategies for
avoiding prison only to discover courts don't care. The courts are
used to people not wanting to go to jail and arguing all sorts of
stuff. Believe the courts are Turing machines if you like, but I don't
think anyone *rational* should go on that assumption. A rational
person is not going to assume that they're going to get off based on
an elaborate technological attempt to confuse the court. They won't.

@_date: 2009-03-03 18:53:50
@_author: "Perry E. Metzger" 
@_subject: Re: Judge orders defendant to decrypt PGP-protected laptop 
The judge doesn't "need" to know the difference to beyond any
doubt. If the judge thinks you're holding out, you go to jail for
Geeks expect, far too frequently, that courts operate like Turing
machines, literally interpreting the laws and accepting the slightest
legal "hack" unconditionally without human consideration of the impact
of the interpretation. This is not remotely the case.
I'll repeat: the law is not like a computer program. Courts operate on
reasonableness standards and such, not on literal interpretation of
the law. If it is obvious to you and me that a disk has multiple
encrypted views, then you can't expect that a court will not be able
to understand this and take appropriate action, like putting you in a

@_date: 2009-03-03 18:20:22
@_author: "Perry E. Metzger" 
@_subject: Re: Judge orders defendant to decrypt PGP-protected laptop 
This sort of thing has been discussed for a long time, but I doubt
that would work in practice. Law is not like software. Judges operate
on reasonableness, not on literal interpretation. If it was reasonably
obvious that you were using software like that and probably not
cooperating, the judge would just throw you in jail for contempt of
court anyway.
Well, it should be clear that any such scheme necessarily will produce
encrypted partitions with less storage capacity than one with only one
set of cleartext. You can't magically store 2N bytes in an N byte
drive -- something has to give. It should therefore be reasonably
obvious from partition sizes that there is something hidden.
In any case, unless you're really very energetic about it, it will be
obvious from things like access times and other content clues ("gee,
why is there nothing in the browser cache from the current year?")
that what is there is not the "real" partition you use day to day.

@_date: 2009-03-03 17:26:32
@_author: "Perry E. Metzger" 
@_subject: Judge orders defendant to decrypt PGP-protected laptop 
A federal judge has ordered a criminal defendant to decrypt his
   hard drive by typing in his PGP passphrase so prosecutors can view
   the unencrypted files, a ruling that raises serious concerns about
   self-incrimination in an electronic age.

@_date: 2009-07-21 17:36:09
@_author: "Perry E. Metzger" 
@_subject: Re: spyware on Blackberries 
An update: RIM confirms to its customers that the update was spyware
pushed on them by their own carrier.

@_date: 2010-04-19 16:43:04
@_author: "Perry E. Metzger" 
@_subject: Re: interesting recent political news... 
Alistair Crooks pointed out to me that the DOJ has dropped that fight:

@_date: 2010-04-19 15:40:42
@_author: "Perry E. Metzger" 
@_subject: interesting recent political news... 
1) NSA to suspend collecting metadata on domestic communications
   following trouble with the FISA court:
2) Former NSA official indicted for leaking to the press:
3) DOJ attempts to read Yahoo email accounts without a warrant, Yahoo
   resists:

@_date: 2010-07-12 16:22:51
@_author: "Perry E. Metzger" 
@_subject: Re: Intel to also add RNG 
It is disturbing to me that people oppose this so much.
For a lot of applications -- servers run in isolation, networking
equipment, etc. -- having hardware RNGs available is a really big win,
because there is no good local source of randomness. (We had a long
discussion of ways to mitigate this some time ago.) Plugging in an
external unit is not going to happen in practice. If it isn't nearly
free and built in, it won't be used.
I would suggest that in most cases, you are better off with a very
very mildly untrusted but ubiquitous hardware RNG than with the kinds
of kludges to get random numbers on unattended hardware we end up with
in the real world.
BTW, let me note that if Intel wanted to gimmick their chips to make
them untrustworthy, there is very little you could do about it. The
literature makes it clear at this point that short of carefully
tearing apart and analyzing the entire chip, you're not going to catch
subtle behavioral changes designed to allow attackers backdoor
access. Given that, I see little reason not to trust them on an RNG,
and I wish they would make it a standard part of the architecture

@_date: 2010-07-12 16:22:51
@_author: "Perry E. Metzger" 
@_subject: Re: Intel to also add RNG 
It is disturbing to me that people oppose this so much.
For a lot of applications -- servers run in isolation, networking
equipment, etc. -- having hardware RNGs available is a really big win,
because there is no good local source of randomness. (We had a long
discussion of ways to mitigate this some time ago.) Plugging in an
external unit is not going to happen in practice. If it isn't nearly
free and built in, it won't be used.
I would suggest that in most cases, you are better off with a very
very mildly untrusted but ubiquitous hardware RNG than with the kinds
of kludges to get random numbers on unattended hardware we end up with
in the real world.
BTW, let me note that if Intel wanted to gimmick their chips to make
them untrustworthy, there is very little you could do about it. The
literature makes it clear at this point that short of carefully
tearing apart and analyzing the entire chip, you're not going to catch
subtle behavioral changes designed to allow attackers backdoor
access. Given that, I see little reason not to trust them on an RNG,
and I wish they would make it a standard part of the architecture

@_date: 2010-10-08 21:45:16
@_author: "Perry E. Metzger" 
@_subject: Re: Photos of an FBI tracking device found by a suspect 
Yes. However, that's an accident. If you deliberately leave a package
on someone's doorstep, they then own the contents. (In fact, if
someone mails you something, US law is very clear that it is yours.)
I'd be interested in hearing what a lawyer thinks.

@_date: 2010-10-08 15:21:16
@_author: "Perry E. Metzger" 
@_subject: Photos of an FBI tracking device found by a suspect 
My question: if someone plants something in your car, isn't it your
property afterwards?

@_date: 2011-08-10 16:19:53
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Crypto being blamed in the London riots. 
Blackberry already more or less has that functionality, which
disproves your hypothesis.

@_date: 2011-08-10 16:13:32
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Crypto being blamed in the London riots. 
Funny, that, since Sampo's proposal is more or less how Blackberry
chat actually works. (Various previous posters had the details wrong.)
Also all blackberry corporate services work without RIM having any
access to the content -- they only get access to email for individual
users for whom they terminate the encrypted tunnel.

@_date: 2011-08-09 17:18:38
@_author: "Perry E. Metzger" 
@_subject: [Cryptography] Crypto being blamed in the London riots. 
Quoting from the New York Times:
  David Lammy, Britain's intellectual property minister, also called
  for a suspension of Blackberry's encrypted instant message service.
  Many rioters, exploiting that service, had been able to organize mobs
  and outrun the police, who were ill-equipped to monitor it. "It is
  unfortunate, but for the very short term, London can't have a night
  like the last," Mr. Lammy said in a Twitter post.
  Officials at Research in Motion, the corporate parent of Blackberry,
  declined to comment on whether the service would be suspended. But
  the company, based in Waterloo, Ontario, issued a statement saying:
  "We feel for those impacted by recent days' riots in London. We have
  engaged with the authorities to assist in any way we can."

@_date: 2013-08-28 02:18:18
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
My problem with the use of DNSSEC for such things is the barrier to
entry. It requires that a systems administrator for the domain your
email address is in cooperate with you. This has even slowed DNSSEC
deployment itself.
It is, of course, clearly the "correct" way to do such things, but
trying to do things architecturally correctly sometimes results in
solutions that don't deploy.
I prefer solutions that require little or no buy in from anyone other
than yourself. One reason SSH deployed so quickly was it needed no
infrastructure -- if you controlled a single server, you could log in
to it with SSH and no one needed to give you permission.
This is a guiding principle in the architectures I'm now considering.

@_date: 2013-08-28 01:41:59
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
You've forgotten other reasons. One might want to avoid a single
point of failure. One might also want to avoid having any central
organization responsible for running a database so that it cannot be
shut down by an adversary without shutting down thousands or millions
of nodes.
That is untrue.
Say that you want to distribute a database table consisting of human
readable IDs, cryptographic keys and network endpoints for some
reason. Say you want it to scale to hundreds of millions of users. A
quick back of the envelope shows that no home user's little ARM based
gateway machine is going to want to handle storing the entire database
or handling the entire update traffic volume -- the latter alone
might swamp someone even with quite reasonable connectivity.
I don't think so. Lets say you have a few hundred bytes per entry and
a billion users. That's hundreds of gigabytes, far more than you can
store on a thumb drive and an appreciable fraction even of today's
hard drives. Furthermore, say that 1% of the entries update per day

@_date: 2013-08-26 16:09:55
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
Though it appears that Tor uses them for its hidden service
directory. How does it do that robustly (or does it do it robustly)?
How do other users of DHTs handle attacks in practice (or is it just
that no one has tried attacking them enough?)
My back of the envelope says that there's little enough data needed
in the distributed data store I want that 1000x replication would not
be a serious problem. I presume that is not sufficient to make Sybil
attacks moot, given the size of modern botnets?

@_date: 2013-08-25 23:52:04
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
That is not my worry. Signing the data posted to the DHT can prevent
spoofing, querying it over a mix network or using a PIR protocol can
prevent eavesdropping. I'm more worried about various sorts of denial
of service attacks, or service being shut down by inadvertent

@_date: 2013-08-25 23:35:08
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
My knowledge of the field is pretty spotty in general as I've never
paid much attention up until now -- mostly I know about how people
have built DHTs in non-hostile environments. I'm close enough to
starting from scratch that I don't know yet what I don't know.

@_date: 2013-08-25 19:12:16
@_author: "Perry E. Metzger" 
@_subject: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
For some research on communications privacy I'm doing at the moment,
I'm interested in learning about the state of the art of DHT systems
and mix network systems. I'd like to know both which systems are
currently considered "state of the art" and what the state of the art
is on attacks against such systems.
Anyone care to shed some light? Pointers to literature are especially
welcome, but anything that is just "in the folklore" is also clearly
of use...

@_date: 2013-08-29 20:46:30
@_author: "Perry E. Metzger" 
@_subject: [Cryptography] The Case for Formal Verification 
Taking a break from our discussion of new privacy enhancing protocols,
I thought I'd share something I've been mumbling about in various
private groups for a while. This is almost 100% on the security side
of things, and almost 0% on the cryptography side of things. It is
long, but I promise that I think it is interesting to people doing
security work.
When I was a student the first time, in the early to mid 1980s, formal
verification was clearly a dead end that would never get anywhere. A
boss of mine once asserted (circa 1988) that there would never be a
verified program that did anything terribly interesting, and at time
he seemed right.
Today, there is a formally verified microkernel called seL4, a
formally verified C compiler called CompCert, a formally verified
experimental web browser called Quark, and lots of other stuff, much
of which I doubtless don't even know about.
_Things have changed_.
Much of what has changed is proof technology, and it is a
technology. The tools for doing formal verification are now, for the
first time, just barely usable for real work on interesting programs,
and getting better all the time. Over the last twenty five years, we
figured out a lot of stuff people didn't know before about how to
write verification tools and how to verify programs, and the results
have been impressive.
There are usually several arguments against formal verification:
1) We don't know what to specify, so what help does proving a buggy
specification do us?
2) Who would bother writing a proof vastly larger than their program?
3) You can't prove programs of interesting size anyway.
So, taking these in reverse order:
For 3 ("you can't prove anything big enough to be useful!"), the Quark
showed you don't need to prove a program of interesting size. You can
defend millions of lines of buggy code with a "software firewall" made
of formally verified code. Verify the right thousand lines of code
that the rest needs to use to talk to anything else, and you have very
strong security properties for the rest of the code. seL4 and CompCert
are clearly also quite useful programs.
For 2 ("Who would bother with all that work?"), we have libraries in
daily use like sqlite:
where the system has a fairly small amount of production code and
literally 1000 times more lines of test code than production code. If
you're willing to write ninety million lines of test to defend ninety
thousand lines of code, formal verification is totally doable.
Sure, it might not be worth it for throw away code or for your new
video game or conference room scheduler where failure isn't a big
deal, but it is *very* clear why you would want to do this for
foundational code of all sorts.
For 1 ("We'll never write a correct spec anyway, so what good is the
proof?"), I think we've been suffering from sour grapes. We didn't
have the ability to prove big things anyway, so why not tell ourselves
that there's nothing interesting and large we could prove that would
be worth proving?
CompCert is a fine counterexample, a formally verified C compiler:
It works by having a formal spec for C, and a formal spec for the
machine language output. The theorem they prove is that the
compilation process preserves observational equivalence between the
behavior of the C program and the output, which, given correct
notation, is a very small theorem to write down.
You might claim "so what, it is probably actually buggy as hell, the
spec probably isn't really correct anyway, etc." -- except when John
Regehr's group built tools to torture test C compilers, the only
compiler they did *not* find bugs in was CompCert. They found hundreds
of bugs each in every other compiler tested. (They actually found one,
but arguably it was a bug in a Linux include file, not in the
CompCert compiler.)
Similarly, one might claim "there is no way to formally specify a web
browser that won't be just as buggy as the web browser!", but Quark's
formal verification doesn't try to show that the entire Web browser is
correct, and doesn't need to -- it shows that some insecure behaviors
are simply impossible. *Those* are much simpler to describe.
Certainly there may be other properties that turn out to be important
that no one has considered yet. However, unlike testing, if people
discovered a hole in the set of theorems being proven -- some property
that was important but which had not been considered -- then that
could be added to what was proved, and _then the problem would be gone
forever_. Verification means you get actual incremental progress that
you can trust. Testing is much less powerful. (Furthermore, future
systems can learn from what you did and add the needed theorem to what
they prove about their own system.)
I don't think the technology is up to proving huge systems correct --
a fairly unambitious C compiler or a microkernel is the current limit

@_date: 2013-09-10 21:51:43
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
Note that the apparent attacks against Petrobras, SWIFT and others
disclosed a few days ago appear to have used precisely this attack.

@_date: 2013-09-06 17:05:59
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
I have re-read the NY Times article. It appears to only indicate that
this was *a* standard that was sabotaged, not that it was the only
one. In particular, the Times merely indicates that they can now
confirm that this particular standard was sabotaged, but presumably
it was far from the only target.

@_date: 2013-09-06 01:56:49
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
Maybe. Yesterday I would have consistently ascribed things to
bureaucracy instead of malice. Today, I'm less sure. At the very
least, the current revelations make such things less benevolent --
whether from malice or stupidity, we can no longer sit on security
fixes on the basis that "no one will exploit them" and "they're not
important to the user".

@_date: 2013-09-06 01:02:00
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
I'm aware of the randomness issues for ECDSA, but what's the issue
with ECDH that you're thinking of?
Yes, and 24 hours ago I would have said that was because they
themselves depended on the use of commercial products with such
algorithms available (as in Suite B.) Now I'm less sure.
Yes, though it doesn't sound like Suite B is what the article
meant when discussing standards.
Many people out there seem to claim the opposite of course. The
current situation doesn't give us a definitive way to resolve such an
RSA certainly appears to require vastly longer keys for the same
level of assurance as ECC.

@_date: 2013-09-05 23:35:37
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
It did *seem* to match the particular part of the story about a
subverted standard that was complained about by Microsoft
researchers. I would not claim that it is the most important part of
the story.
Yes, and if they have a real hole there they're exploiting, that is
quite disturbing. If they're merely using a hodge-podge of techniques
to get keys, it is less worrying.
I'm starting to think that I'd probably rather type in the results of
a few dozen die rolls every month in to my critical servers and let
AES or something similar in counter mode do the rest.
A d20 has a bit more than 4 bits of entropy. I can get 256 bits with
64 die rolls, or, if I have eight dice, 16 rolls of the group. If I
mistype when entering the info, no harm is caused. The generator can
be easily tested for correct behavior if it is simply a block cipher.
I believe there was already discussion in the press on that latter
point, but I think it is less germane to our discussion here and
would prefer that we avoid speculating on things that are only of
human/gossip interest.

@_date: 2013-09-05 22:06:09
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
The articles make it sound much more like implementation flaws that
have been intentionally placed in software and hardware, and a
select few bad protocols and standards. I'm not going to say that it
is impossible that they can break 3DES at this point, but it doesn't
sound like that's what is being discussed here.

@_date: 2013-09-05 20:57:51
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
There is now some speculation in places like twitter that this refers
to Dual_EC_DRBG though I was not aware that was widely enough deployed
to make a huge difference here, and am not sure which international
group is being mentioned. I would be interested in confirmation.

@_date: 2013-09-05 20:53:15
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
Please say it aloud. (I personally don't recognize the standard
offhand, but my memory is poor that way.)
BTW, I will now openly speculate if the deeply undeployable key
management protocols for IPSec that originated at the NSA were an
accident. I had enough involvement not to feel overly strongly that
this is what happened, but it does lead one to wonder strongly.

@_date: 2013-09-05 20:41:18
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
Here are a few guesses from me:
1) I would not be surprised if it turned out that some people working
for some vendors have made code and hardware changes at the NSA's
behest without the knowledge of their managers or their firm. If I
were running such a program, paying off a couple of key people here
and there would seem only rational, doubly so if the disclosure of
their involvement could be made into a crime by giving them a
clearance or some such.
2) I would not be surprised if some of the slow speed at which
improved/fixed hashes, algorithms, protocols, etc. have been adopted
might be because of pressure or people who had been paid off.
At the very least, anyone whining at a standards meeting from now on
that they don't want to implement a security fix because "it isn't
important to the user experience" or adds minuscule delays to an
initial connection or whatever should be viewed with enormous
suspicion. Whether I am correct or not, such behavior clearly serves
the interest of those who would do bad things.
3) I would not be surprised if random number generator problems in a
variety of equipment and software were not a very obvious target,
whether those problems were intentionally added or not.
4) Choices not to use things like Diffie-Hellman in TLS connections
on the basis that it damages user experience and the like should be
viewed with enormous suspicion.
5) Choices not to make add-ons available in things like chat clients
or mail programs that could be used for cryptography should be viewed
with suspicion.

@_date: 2013-09-05 19:58:04
@_author: "Perry E. Metzger" 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
I would like to open the floor to *informed speculation* about
Informed speculation means intelligent, technical ideas about what
has been done. It does not mean wild conspiracy theories and the
like. I will be instructing the moderators (yes, I have help these
days) to ruthlessly prune inappropriate material.
At the same time, I will repeat that reasonably informed
technical speculation is appropriate, as is any solid information

@_date: 2013-09-13 21:12:43
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] prism proof email, namespaces, and anonymity 
Indeed. As I said in the message I just pointed Nico at:
Quoting myself:
   Spam might be a terrible, terrible problem in such a network since
   it could not easily be traced to a sender and thus not easily
   blocked, but there's an obvious solution to that. I've been using
   Jabber, Facebook and other services where all or essentially all
   communications require a bi-directional decision to enable messages
   for years now, and there is virtually no spam in such systems
   because of it. So, require such bi-directional "friending" within
   our postulated new messaging network -- authentication is handled
   by the public keys of course. That's my solution. As I note, it seems to work for Jabber, Facebook
and other such systems, so it may be sufficient.
I'm not sure about that. Jabber doesn't really rate limit the number
of friend requests I get per second but I don't seem to get terribly
many, perhaps because fakes at most could hide some attempted phish
in a user name, which isn't very useful to scammers.
My claim that I make in my three messages from August 25 is that it
is probably best if we stick to existing formats so that we can
re-use existing clients. My idea was that you still talk IMAP and
SMTP and Jabber to a server you control (a $40 box you get at Best Buy
or the like) using existing mail and chat clients, but that past your
server everything runs the new protocols.
In addition to the message I linked to above, see also:
for my wider proposals.
I agree this makes email delivered malware continue to be a bit of a
problem, though you could only get it from your friends.

@_date: 2013-09-14 16:56:02
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] RSA equivalent key length/strength 
For those not aware, the document, by Paul and Hilarie Orman,
discusses equivalent key strengths and practical brute force methods,
giving extensive detail on how all calculations were done.
A URL for the lazy:
It is very well done. I'd like to see an update done but it does
feel like the methodology was well laid out and is difficult to
argue with in general. The detailed numbers are slightly different
from others out there, but not so much as to change the general
recommendations that have been floating around.
Their table, from April 2004, looked like this:
   +-------------+-----------+--------------+--------------+
 System      |           |              |              |
 requirement | Symmetric | RSA or DH    | DSA subgroup |
 for attack  | key size  | modulus size | size         |
 resistance  | (bits)    | (bits)       | (bits)       |
 (bits)      |           |              |              |
   +-------------+-----------+--------------+--------------+
     70      |     70    |      947     |     129      |
     80      |     80    |     1228     |     148      |
     90      |     90    |     1553     |     167      |
    100      |    100    |     1926     |     186      |
    150      |    150    |     4575     |     284      |
    200      |    200    |     8719     |     383      |
    250      |    250    |    14596     |     482      |
   +-------------+-----------+--------------+--------------+
They had some caveats, such as the statement that if TWIRL like
machines appear, we could presume an 11 bit reduction in strength --
see the RFC itself for details.

@_date: 2013-09-14 16:14:11
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] RSA equivalent key length/strength 
On what basis do you select your numbers? Have you done
calculations on the time it takes to factor numbers using modern
algorithms to produce them?

@_date: 2013-09-02 22:55:44
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] NSA and cryptanalysis 
Yes, certainly, but the end effect was that an untrustworthy piece of
code was then executing on the victim's machine. That can be happen
by many means, however, both intentional and accidental -- trojan
horses, vendor mistakes, bugs, rogue employees at a vendor, a vendor's
credentials being stolen, cryptographic breaks like this, etc.
Now, I do indeed find it interesting and exotic that someone involved
knows how to create MD5 collisions by a different method than we know
of in the open literature, and that tickles my fancy as a
person who loves cryptography, and probably tells us something about
who wrote that particular exploit.
What it does not do, however, is tell me much about how to
make systems robust against the wide variety of reasons why
untrustworthy software might appear on a machine.
As a security person, it is this latter problem that is vital
to me, since doubtless that will show up again in the future. Even
ignoring malice, bugs often happen in device drivers and other code
running in security critical environments like kernels.
I will again mumble things like: "typed assembly language, proof
carrying code, microkernels, hardware assists, formal verification..."
in the hopes that the mumbling might set some minds thinking.

@_date: 2013-09-02 21:35:43
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] NSA and cryptanalysis 
As would I. Not my wider point. My wider point is that the
speculation is not helpful, and one probably wants to think about how
to make things trustworthy even in the presence of bugs, adversaries
who look like bugs for most viewpoints, etc. Paranoid speculation is
useless, concrete discussion of threat models and how to address them
is useful. (Thus why I mentioned things like typed assembly language
as being a more productive topic than infinitely recursive paranoia.
One can speculate endlessly on who is collaborating with whom
without ever terminating, but robust threat models with technical
solutions are something you can actually do something about.)

@_date: 2013-09-02 19:55:45
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] NSA and cryptanalysis 
But of course, sufficiently paranoid people might contend that
perhaps the Microsoft people who complained might not have been
briefed by the ones who cooperated.
The problem with all such exercises is that they involve too many
layers of recursive paranoia, but do not pay off with useful
information that tells me how to act going forward.
In the current case, the fact that they *could* potentially suborn
process inside a vendor is an interesting thing to consider when
doing design, and whether they *have* is less interesting to me.
Clearly, as things like bad vendor drivers updates have been sent out
using stolen keys in the past, and clearly vendors might simply make
mistakes in the future.
From there, I can consider whether the "someone signs bad
updates" security model component is productive to defend against or
not, and how one might defend against it. (In the current case, I'd
say only typed assembly language offers an interesting defense
against bad binaries that get executed in kernel mode, regardless of
why they are bad. Using typed assembly language effectively of
course requires that the code be written in a high level language
with strong typing to be preserved in the delivered machine code in
the first place.)
I leave speculation to pundits, and prefer to write code and design

@_date: 2013-09-02 19:40:59
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] NSA and cryptanalysis 
Only as a legacy "you can do this for a while but please switch."
I'd say they're judging a balance between security and performance
while attempting not to leave particularly bad holes.
I believe that is indeed a factor here, and is probably part of why
the asymmetric key lengths aren't a bit longer. It is also possible
they've been selected based on knowledge that AES keys are slightly
weaker than we expect, but not radically so.
As an aside, I'm reminded of the fact that there were certificational
weaknesses in Skipjack that meant it was only more or less as
potentially secure as the number of bits available in they key
length. When this was pointed out to someone in the know, the mumble
back I remember was "in other words, they did the engineering
Anyway, as I've said, I'm paranoid, but I operate under the
assumption the counterparty is a reasonably rational actor that
understands the very limited duration of secrets.

@_date: 2013-09-02 17:25:38
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] NSA and cryptanalysis 
That is a misunderstanding.
If you look at the way that the NSA specs these things, they try to
keep all portions of a system of equal security so none is the weak
point. A 2048 bit RSA key is factored vastly more easily than a 256
bit AES key is brute forced (that's just public knowledge -- try doing
the back of the envelope yourself) so that size key would be
insufficient. However, a sufficiently large RSA key to be "correctly
sized" for 256 bit AES is totally impractical for performance reasons,
So clearly the purpose of pushing ECC for this application is that
they want the public key algorithm and its key size to have comparable
security while both performing reasonably well.
Not at all, and the rationale is public and seen above.
I believe you're incorrectly claiming that we know much less than we
actually do here.

@_date: 2013-09-01 22:06:20
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] NSA and cryptanalysis 
We know what they spec for use by the rest of the US government in
Suite B.
  AES with 128-bit keys provides adequate protection for classified
  information up to the SECRET level. Similarly, ECDH and ECDSA using
  the 256-bit prime modulus elliptic curve as specified in FIPS PUB
  186-3 and SHA-256 provide adequate protection for classified
  information up to the SECRET level. Until the conclusion of the
  transition period defined in CNSSP-15, DH, DSA and RSA can be used
  with a 2048-bit modulus to protect classified information up to the
  SECRET level.
  AES with 256-bit keys, Elliptic Curve Public Key Cryptography using
  the 384-bit prime modulus elliptic curve as specified in FIPS PUB
  186-3 and SHA-384 are required to protect classified information at
  the TOP SECRET level. Since some products approved to protect
  classified information up to the TOP SECRET level will only contain
  algorithms with these parameters, algorithm interoperability between
  various products can only be guaranteed by having these parameters as
  options.
We clearly cannot be absolutely sure of what they actually use, but
we know what they procure commercially. If you feel this is all a big
disinformation campaign, please feel free to give evidence for that. I
certainly won't exclude the possibility, but I find it unlikely.

@_date: 2013-09-01 18:11:48
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] NSA and cryptanalysis 
The fact that the USG likes using it, too.
That's also evidence for eliptic curve techniques btw.

@_date: 2013-09-01 18:05:14
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] NSA and cryptanalysis 
This seems by far the most probable conclusion. Note, for example,
Heninger et al's recent work on the Taiwanese national smartcards. A
discovery that some commonly used randomness sources are dramatically
less random than supposed could dramatically lower the work factor on
an otherwise brute force attack.
That said, we simply can't know, and I think excessive speculation on
the basis of no actual concrete information isn't that productive.

@_date: 2013-09-08 02:20:51
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Why prefer symmetric crypto over public key crypto? 
...and it appears I was completely wrong on that.
See, for example: Senility gets the best of us.
The cryptography mailing list

@_date: 2013-09-08 00:45:34
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Why prefer symmetric crypto over public key crypto? 
I'm unaware of an ECC equivalent of the Shor algorithm. Could you
enlighten me on that?
The cryptography mailing list

@_date: 2013-09-08 00:43:39
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Why prefer symmetric crypto over public key crypto? 
In the same sense that we can no longer rule out the possibility that,
given modern synthetic biology techniques, someone has already come up
with a way to create pigs with wings. I see the possibility of the
quantum computer as slightly smaller, however.
To my knowledge, there is no ECC analog of Shor's algorithm.
The cryptography mailing list

@_date: 2013-09-10 19:16:59
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Techniques for malevolent crypto hardware 
Oh, and of course, if you're doing a DSA style algorithm, you can
leak information in your choice of random nonce. This is yet more
reason to force protocols to use nonces that are deterministic based
on context, and to enforce that.

@_date: 2013-09-09 01:15:41
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Techniques for malevolent crypto hardware 
Lenstra, Heninger and others have both shown mass breaks of keys based
on random number generator flaws in the field. Random number
generators have been the source of a huge number of breaks over time.
Perhaps you don't see the big worry, but real world experience says
it is something everyone else should worry about anyway.

@_date: 2013-09-08 20:51:17
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Techniques for malevolent crypto hardware 
Ah, but it only needs to be found once to destroy the reputation of a
Inserting bugs into chips (say, random number generators that won't
work well in the face of fabrication processes that alter analog
characteristics of circuits slightly) results in a "could be an
accident" sort of mistake. Altering a chip to insert an encrypted
form of a key into the initialization vectors in use cannot be
explained away that way.
You may say "but how would you find that?". However, I've worked
in recent years with people who decap chips, photograph the surface
and reconstruct the circuits on a pretty routine basis -- tearing
apart secure hardware for fun and profit is their specialty. Even
when this process destructively eliminates in-RAM programming,
usually weaknesses such as power glitching attacks are discovered by
the examination of the "dead" system on the autopsy table and can
then be used with live hardware.
Now that it has been revealed that the NSA has either found or
arranged for bugs in several chips, I would presume that some of
these people are gearing up for major teardowns. Not all
such teardowns will happen in the open community, of course -- I'd
expect that even now there are folks in government labs around the
world readying their samples, their probe stations and their etchant
baths. Hopefully the guys in the open community will let us know
what's bad before the other folks start exploiting our hardware
silently, as I suspect the NSA is not going to send out a warning.
I'll repeat the same observation I've made a lot: Dorothy Denning's
description of the Clipper chip key insertion ceremony described the
keys as being generated deterministically using an iterated block
cipher. I can't find the reference, but I'm pretty sure that when she
was asked why, the rationale was that an iterated block cipher can be
audited, and a hardware randomness source cannot.

@_date: 2013-09-08 19:22:32
@_author: "Perry E. Metzger" 
@_subject: Re: [Cryptography] Techniques for malevolent crypto hardware 
Ah, now *this* is potentially interesting. Imagine if you have a
crypto accelerator that generates its IVs by encrypting information
about keys in use using a key an observer might have or could guess
from a small search space.
Hadn't even occurred to me since it seems way more blatant than
the other sort of leaks I was thinking of, but of course the mere
fact that it is blatant doesn't mean that it would never be tried...

@_date: 2013-09-08 18:34:26
@_author: "Perry E. Metzger" 
@_subject: [Cryptography] Techniques for malevolent crypto hardware (Re: Suite B after today's news) 
Yes and no. There are limits to what such hardware can do. If such
hardware fails to implement a symmetric algorithm correctly, that
failure will be entirely obvious since interoperation will fail
immediately. If it uses bad random numbers, that failure will be
The most obvious implementation defects are bad RNGs and bad
protection against timing analysis.
One might also add side channels to leak information. Obvious side
channels for malevolent hardware are radio frequency interference (if
you can deploy listening equipment in the same colo this might be
quite a practical way to extract information) and timing channels
(not only in the sense of failure to protect against timing analysis
but also in the sense of using inter-event delays to encode
information like keys).
I think that in most applications power consumption side channels are
probably not that interesting (smart cards etc. being an exception)
but I'm prepared to be proven wrong.
Any other thoughts on how one could sabotage hardware? An exhaustive
list is interesting, if only because it gives us information on what
to look for in hardware that may have been tweaked at NSA request.
I wonder, though, if one could add secret layers to FPGAs to leak
interesting information in some manner. It seems unlikely, but I
might simply not be creative enough in thinking about it.
