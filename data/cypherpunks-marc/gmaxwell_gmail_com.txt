
@_date: 2008-12-08 01:17:02
@_author: "Gregory Maxwell" 
@_subject: Re: UK internet filtering 
It's interesting to point out that Finnish Wikipedia has the image and
the UK is not censoring that:
(most non-english Wikipedias do not have it, but only because they
have no album covers at all because they only permit images under a
free content license)

@_date: 2008-12-07 02:23:20
@_author: "Gregory Maxwell" 
@_subject: Re: UK internet filtering 
I intentionally did not link to the Wikinews article: They're often junk.

@_date: 2008-12-07 00:49:58
@_author: "Gregory Maxwell" 
@_subject: UK internet filtering 
I've confirmed the reports of UK ISPs censoring Wikipedia using some
UK tor exists.

@_date: 2009-08-10 18:55:13
@_author: Gregory Maxwell 
@_subject: Re: Comcast throws down gauntlet to residential accounts 
VZN's residential AUP prohibits "servers" along with a number of other
offensive prohibitions which they don't currently enforce. (For
example, you're prohibited from using your VZN broadband for anything
"sexually explicit").
As I recall the business FiOS AUP had it's own set of ridiculous
terms... but it didn't attempt to prohibit you from running "servers".

@_date: 2009-08-10 18:55:13
@_author: Gregory Maxwell 
@_subject: Re: Comcast throws down gauntlet to residential accounts 
VZN's residential AUP prohibits "servers" along with a number of other
offensive prohibitions which they don't currently enforce. (For
example, you're prohibited from using your VZN broadband for anything
"sexually explicit").
As I recall the business FiOS AUP had it's own set of ridiculous
terms... but it didn't attempt to prohibit you from running "servers".

@_date: 2009-09-16 21:26:31
@_author: Gregory Maxwell 
@_subject: Re: "I Write Mass Surveillance Software" 
The hostility on reddit is odd and unfortunate.
The obvious sidestepping is MITM-ing connections for users then shove
manipulated binaries at them which disable encryption, leak key
material, or intercept keystrokes  ... or simply perform degradation
attacks, either forcing protocols to less secure modes, or simply
blocking or massively slowing secure connections to make the user
switch to something insecure.
These have the enormous downside of being detectable active attacks.
Not something you could afford to apply frequently against general
public unless you were willing to tip off your primary target that you
were watching.  Then againâ with ISPs like comcast injecting RST
packets, would a degradation attack be distinguishable?
Less obvious sidestepping would include things like simply monitoring
the remote side with the expectation that they won't be as prudent
with security as your primary target.
Black-helicopter mode sidestepping would be having pre-arranged back
doors in popular operating systems or client software.

@_date: 2009-09-16 21:26:31
@_author: Gregory Maxwell 
@_subject: Re: "I Write Mass Surveillance Software" 
The hostility on reddit is odd and unfortunate.
The obvious sidestepping is MITM-ing connections for users then shove
manipulated binaries at them which disable encryption, leak key
material, or intercept keystrokes  ... or simply perform degradation
attacks, either forcing protocols to less secure modes, or simply
blocking or massively slowing secure connections to make the user
switch to something insecure.
These have the enormous downside of being detectable active attacks.
Not something you could afford to apply frequently against general
public unless you were willing to tip off your primary target that you
were watching.  Then againâ with ISPs like comcast injecting RST
packets, would a degradation attack be distinguishable?
Less obvious sidestepping would include things like simply monitoring
the remote side with the expectation that they won't be as prudent
with security as your primary target.
Black-helicopter mode sidestepping would be having pre-arranged back
doors in popular operating systems or client software.

@_date: 2009-11-23 16:25:55
@_author: Gregory Maxwell 
@_subject: Re: The Case for Banning Reduced Hop Count Implementations 
Reduction to one is obviously quite terrible. The reason I trimmed off the
Lucky's message was that I thought it was just making a argument against
one-hop as endangering operators which I previously agreed with and had
argued here myself.
Thank you for taking the time to elaborate on the two-hop case.
I hadn't previously considered the entry node as valuable data worth hiding
from the exit node, but now that you point it out I find it to be a
convincing argument.
I'm not confident how real the the capacity consumption concerns are, or that
they couldn't be addressed by some other means (if you have some blinded method
of determining the minimum path length, then you could use it to
prioritize longer
path traffic by an amount sufficient to prevent it from being out competed too
I find it quite disappointing that two-hop isn't a reasonable measure to improve
performance for some users. As I've argued elsewhere I think it's important
that TOR carry a significant amount of perfectly ordinary traffic both
to provide
cover traffic, and to ensure that there is sufficient public support, as it's a
lot easier to turn a blind eye on a service you haven't used personallyâ¦
To make the point more forcefully:
I'll assume here that 'questionable origin' here is primarily talking about the
people illicitly downloading movies and the like.
I find it interesting to see the file transfer case as "comparatively low risk
behavior". The reason people have used tor for this in significant numbers is
that their activity is very likely to result in legal threats and disconnection
from their ISP, as those consequences have become common. This isn't a
risk these people face it's a real one, certainly more real than any that I've
personally had for using Tor.
(You don't have to even support the illegal propagation of copyrighted works to
support people engaging in downloadingâ  for example, someone might download
an album to recover material on a damaged CD, or they might be
recovering a track
they purchased but has been made available to them after the closure of a DRM
key provider,  and these use cases are no less likely to bring lawsuit than the
people who are downloading copyrighted works for which they have not
been licensed.)
Of course there are people with greater anonymity needs than the file
but if you are prepared to classify someone merely at risk of a costly
lawsuit and
disconnection from their ISP as someone who is insufficiently worthy
and guide them
and all the others with even lower needs to another service then would
TOR even come
close to the level of cover traffic required to provide anonymity to those more
strongly in need?
[The file downloading on Tor isn't a good thing: it's not good because
tor isn't the
best design for bulk transfers where latency isn't relevant... some
other design could
handle them better (and probably provide greater anonymity at the same
time). The
copyright-violating download case also has the problem that it doesn't
eliminate risks
it merely shifts them to the exit operators. (Because the copyright
holders are perfectly
happy to take the same actions against the exit operators, and many
ISPs are perfectly
happy to harass them)... but these are separate matters that have
little to do with
circuit length or the reality of the users desire for anonymization]
To unsubscribe, send an e-mail to majordomo with
unsubscribe or-talk    in the body.

@_date: 2009-11-23 07:43:47
@_author: Gregory Maxwell 
@_subject: Re: The Case for Banning Reduced Hop Count Implementations 
I presume you can back this assertion up with simulation results, at a minimum?
I look forward to reading your paper.
Which is why twiddling the hop count isn't attractive for them.
It is attractive for IRC, for example, because with the current hop counts
it can be difficult to keep a TCP connection up for long.  Long lived
connections don't benefit much from the longer paths in any case because the
provide ample opportunity to simply correlate entry and exit traffic and ignore
the interior path.
To unsubscribe, send an e-mail to majordomo with
unsubscribe or-talk    in the body.

@_date: 2010-12-08 15:50:18
@_author: Gregory Maxwell 
@_subject: Re: leaker-optimized versions of Tor 
It is strictly necessary that the bad guy not control 100% of the
forwarding nodes.
On a realtime onion network anonymity is bounded by timing attacksâ
even if you could tolerate the delay of having a zillion middle nodes
the attacker could just watch the entrances an exits and correlate
timing. So adding a great many hops would not significantly increase
A mix network can tolerate higher delays and, hopefully, eliminates
the timing attacks. So additional hops can be beneficial.
The down side is increased vulnerability to DOS attacks if flooders
can generate cheap round-the-world messages.
The creating a hidden service based overlay network, as was suggested
here by Karsten N., was what I thought when I read the threadâ but I
was concerned that if the network identity of all/most of the nodes is
hidden that an attacker could spin up thousands of fake mix nodes
without even needing a lot of network resources. They could make it
far more likely that all your hops were controlled by one party.
Although the risk exists for non hidden service based designs, it's
probably much easier with an anonymity layer in between. Any design
using hidden services would specifically need to address this risk.
To unsubscribe, send an e-mail to majordomo with
unsubscribe or-talk    in the body.

@_date: 2010-12-29 07:21:06
@_author: Gregory Maxwell 
@_subject: Re: 27C3 on Tor 
We can do some useful "back of the envelope calculations" so that we
can say _something_ useful about the rounding.
I spent a few minutes now contemplating this, and I thought I'd make
the data available that I used for anyone else for anyone interested
in studying this.
contains the uncompressed sizes of the wikitext for the 3.5 million
English Wikipedia articles (as of Wikimedia's 2010-10 dump).
Here is how we can use the data to reason about this attack:
Assume that the attacker knows the target is browsing Wikipedia, and
that they know the exact size of the pages loaded and want to know
what articles the person is reading. Based on this data we can compute
the  entropy and to discover how much they will learn about each page
load.  We can then study how much quantization the size reduces
Of course, attackers have a number of additional avenues to increase
the usefulness of the data they obtain: They may have some assumptions
about the prior probabilities (other than "user is browsing
Wikipeda"), they may also reason about the interlinkedness of
articlesâ e.g. a second page load is very likely a page linked from
the first load. You might conservatively estimate that each and every
request adds its total to the attackers aggregate knowledge.
There are a number of limits to this line of studyâ Wikipedia articles
are served in HTML form (not wikitext) and in the gzip encoding. I can
wave my arms and say that I don't expect the conversion HTML and HTTPS
transport to change the entropy much, and that I expect gzip to
decrease it (because smaller sizes have intrinsically less entropy).
Normally articles contain inline imagesâ the loading sizes of these
objects probably increase the entropy enormously. These probably
aren't important compared to the fact that Wikipedia is not the whole
internet. :) Still, it's a starting point.
Here is some data,
Using the James-Stein shrinkage estimate of entropy (which gives
slightly larger results than the empirical entropy):
log2(Cell size)    Entropy in bits
0	13.48422
1	12.48014
2	11.47869
3	10.47837
4	9.478465
5	8.478762
6	7.480331
7	6.48253
8	5.493885
9	4.507543
10	3.526705
11	2.551070
12	1.599523
13	0.8287433
14	0.3627942
15	0.1329697
16	0.03448373
17	0.004374095
18	0.0002002991
19	1.336822e-05
20	6.684109e-06
(there is a single page of size zero, otherwise 20 would have 0
entropy. Over a real transport the size would never be zero, so a unit
of 2^20 would be sufficient to reduce the leakage to zero for this
So for this data, changing the transmission unit from 512 (4) to 1024
(5) would only decrease the information learned by an unbiased
attacker from one request by one bit.  (Unsurprisingly, the entropy of
the pages sizes is not concentrated in the least significant bits)
If you make any assumption that the attacker accumulates data from
request to request (e.g. due to page linkage) then I think that a
change from 512 to 1024 does not effectively thwart this attack
against this data set. If the attacker does not have that ability then
the current transmission unit already provides a substantial, and
probably sufficient, reduction in information leaked.
To unsubscribe, send an e-mail to majordomo with
unsubscribe or-talk    in the body.

@_date: 2011-03-22 16:17:55
@_author: Gregory Maxwell 
@_subject: Re: [tor-talk] Iran cracks down on web dissident technology 
I hesitated in responding because it's just so easy to run of an infinite
series of explanations. While any particular reason might not actually
be valid, there are enough plausible ones that your argument of
inconceivability can not be support.
Because governments are not monolithic entities, because people don't have
perfect foresight, because the benefit to your interests can outweigh
the benefit against your interests, and communications technology arguably
disproportionally benefits larger groups.
Interests outweighed:  Funding something like TOR may be the most cost
effective way to achieve a particular end. In particular, a US government
only anonymity network would likely not be very useful ("I don't know who
this is, but it's a fed").  Regardless of it helping the enemy too, it
can still be a net win to support.
Not monolithic entities:  If you have an organizational unit charged with
accomplishing X they will work to accomplish X. Sometimes they may work
so hard at it that stop another unit from accomplishing Y, even if Y was
more important to the overall mission.  This happens frequently in
all kinds of large organizations.
No perfect foresight:  It's not always obvious to everyone that some move
may turn net negative in the future. E.g. the US supporting the Taliban.
Larger groups:  If just you and I want to communicate with secrecy we
can do so without something like TORâ we can send coded messages hidden
in innocuous usenet posts or Wikipedia articles. The value of a network
is related more to the square of its communicating members. If you're the
bigger party it can help you more than it helps your smaller enemies.
tor-talk mailing list

@_date: 2012-07-01 20:46:38
@_author: Gregory Maxwell 
@_subject: Re: [tor-talk] blocked exit node IP because of spam 
There are things the tor project and surrounding community could do to
help here.
For example, If I could anonymously donate $10 to a charity and in
return receive a persistent nym which I could use to get around those
kinds of blocks... I'd be hesitant to misbehave and get my nym
blocked.  (And forums should feel good about whatever small residual
amount of spammers who do buy donation nyms, because even though they
spam their need to keep buying nyms support the charities).
But no practical software infrastructure exists for this sort of thing today.
And until it does any education/advocacy will not go too far because
it doesn't offer much in terms of real alternatives.  "It's not really
so bad." "Yes it is, or we wouldn't have bothered putting in the
blocking in the first place" "er.."
tor-talk mailing list

@_date: 2012-08-11 02:32:19
@_author: Gregory Maxwell 
@_subject: Re: [tor-talk] Tor as ecommerce platform 
It's odd that this thread started with a discussion of some sketchy research
which worked by running an automated spider moving enormous amounts of
So the very thing that inspired the conversation ruins the proposed methodology.
Tisk tisk.
tor-talk mailing list

@_date: 2013-07-30 06:50:12
@_author: Gregory Maxwell 
@_subject: [Bitcoin-development] BitMail - p2p Email 0.1. beta 
Keep safe everyone:
A number of apparent sock accounts has been posting about what appears
to be the same software under the name "goldbug" for a couple days

@_date: 2013-09-08 03:09:24
@_author: Gregory Maxwell 
@_subject: Re: [tor-talk] NIST approved crypto in Tor? 
I believe Schneier was being careless there.  The ECC parameter sets
commonly used on the internet (the NIST P-xxxr ones) were chosen using
a published deterministically randomized procedure.  I think the
notion that these parameters could have been maliciously selected is a
remarkable claim which demands remarkable evidence.

@_date: 2013-10-28 03:15:06
@_author: Gregory Maxwell 
@_subject: Re: [tor-talk] x.509 for hidden services 
Fantastic point, and just as easily done. As obvious as it is, I'd
forgotten about people keeping the HS keys on separate hosts.
It also raises the point that perhaps future Tor HS should also
support delegation
so that the HS master identity key could be kept offline.  E.g. you
have a HS identity
key, and it delegates to a short term HS key which has a lifetime of
only 1 month,
and perhaps has some kind of priority scheme such that a key with a higher
sequence number takes precedence. E.g. if someone compromises your key you can
instantly throw up a new service which people will connect to instead...
If your HS (bastion) host is compromised you wouldn't completely lose
control of your HS identity.
Might even be useful to pre-define a maximum sequence number such that
an announcement with
that sequence number blocks access.  So if your site is compromised
you can announce a pre-signed HS revocation which forever kills the
address so long as someone keeps periodically rebroadcasting it to
Yea, I'm not too worried about that. If the Tor usage becomes very
common we could simply extend the protocol with a tor-specific
extension that supports them.  My thinking here is that at least for
today I can do something to make existing HS identities work with very
little effort.

@_date: 2013-10-26 08:53:23
@_author: Gregory Maxwell 
@_subject: Re: [tor-talk] x.509 for hidden services 
Link please. :)
At least in one (early) version it needed to access the HS keys so it
could sign with them and identify itself on outgoing connections. I
didn't mean to imply it used x.509, but rather just that something
else had used a HS identity key for some application level auth.

@_date: 2013-10-26 04:26:21
@_author: Gregory Maxwell 
@_subject: [tor-talk] x.509 for hidden services 
==Background== (you can skip to the Tor section if you don't care)
The Bitcoin universe is in the process of creating a specification for
digital invoices called "the bitcoin payment protocol". (More info:
The payment protocol allows someone to request someone else pay
Bitcoin for specific things, instructing them to pay specific amounts
in specific ways, and allows the receiver to provide things like
instructions for sending a refund if the transaction is for some
reason aborted... all sorts of extra metadata which doesn't belong in
the public Bitcoin network for scalability and privacy reasons.
One of the things these invoices have is an optional signing mechanism
for authentication and non-repudiation. Normally these requests would
be sent over an authenticated and encrypted channel which provides
confidentiality and authentication, but not non-repudiation.
The non-repudiation will provide cryptographic evidence to the
participants which can be used to resolve disputes: e.g.
"He didn't send me my alpaca socks!" "Thats not the address I told you to pay!"
"He told me he'd send my 99 red-balloons, not just one!"  "No way,
that was the price for 1 red-balloon!"
The payment protocol is extensible and may someday commonly support
many kinds of signatures, but the initial implementations only support
signing with internal x.509 certificates and verifying those
certificates with standard CAs. As _horrible_ as this is, it's better
than nothing, and the primary users asking for this functionality have
SSL websites today.  We don't believe that any other PKI mechenism is
actually functional enough to be usable (e.g. as evidenced by the fact
that downloads of our GPG signatures, is on the order of 1% of the
downloads of the Bitcoin software; and probably only a small portion
of those users have actually done anything to verify the signing keys)
today, so other options haven't been a priority.
However, the need to use the known insecure CA infrastructure for this
(optional!) feature has seriously spazzed out some people. A lot of
this is pure confusion, e.g. people thinking that all payment requests
would have to go via the CA (no kidding!), but its surprisingly hard
to convince people who are responding emotionally of the subtle
tradeoffs involved especially when they have the luxury of saying
"it's your problem to go figure out, figure it out and go write a
bunch extra of software for me". So having some alternative on day one
would be useful in helping the more conspiracy minded understand that
this isn't some effort to cram the use of CAs down their throat.
==Where Tor comes in==
One of the downsides if using x.509 certs to non-repudiate here is
that sites hosted as tor hidden services can't participate.
It occurred to me that this could be fixed with very little code:
Take the HS pubkey, pack it into a self-signed x.509 cert with the
cn=pubkeybase32.onion.  And specify that .onion certs have a special
hostname validation rule that hashes and encodes the key.
Then the whole process would work for .onion, we'd have a non-CA
option available and working, etc.
I'm aware that HS pubkeys have been used for application level
authentication in Tor elsewhere (e.g. I believe torchat does this) so
it's not entirely unprecedented. I'm not aware of anyone packing them
in x.509 certificates. If anyone has, I'd like to use the same
encoding style for greater compatibility.
The biggest reason I can see not to do this is that it will not be
compatible with future editions of hidden services which aren't based
on RSA keys. (e.g. the EC point addition stuff to protect against
enumeration attacks wouldn't fit into this model). I don't think this
is a serious concern: if HS x.509s do become widely used we could add
a new authentication type for the new onion addresses when those are
Does anyone else see any other reasons not to do this?
Are there other applications which would benefit from having x.509
certs for onion names?

@_date: 2013-10-26 04:26:21
@_author: Gregory Maxwell 
@_subject: [tor-talk] x.509 for hidden services 
==Background== (you can skip to the Tor section if you don't care)
The Bitcoin universe is in the process of creating a specification for
digital invoices called "the bitcoin payment protocol". (More info:
The payment protocol allows someone to request someone else pay
Bitcoin for specific things, instructing them to pay specific amounts
in specific ways, and allows the receiver to provide things like
instructions for sending a refund if the transaction is for some
reason aborted... all sorts of extra metadata which doesn't belong in
the public Bitcoin network for scalability and privacy reasons.
One of the things these invoices have is an optional signing mechanism
for authentication and non-repudiation. Normally these requests would
be sent over an authenticated and encrypted channel which provides
confidentiality and authentication, but not non-repudiation.
The non-repudiation will provide cryptographic evidence to the
participants which can be used to resolve disputes: e.g.
"He didn't send me my alpaca socks!" "Thats not the address I told you to pay!"
"He told me he'd send my 99 red-balloons, not just one!"  "No way,
that was the price for 1 red-balloon!"
The payment protocol is extensible and may someday commonly support
many kinds of signatures, but the initial implementations only support
signing with internal x.509 certificates and verifying those
certificates with standard CAs. As _horrible_ as this is, it's better
than nothing, and the primary users asking for this functionality have
SSL websites today.  We don't believe that any other PKI mechenism is
actually functional enough to be usable (e.g. as evidenced by the fact
that downloads of our GPG signatures, is on the order of 1% of the
downloads of the Bitcoin software; and probably only a small portion
of those users have actually done anything to verify the signing keys)
today, so other options haven't been a priority.
However, the need to use the known insecure CA infrastructure for this
(optional!) feature has seriously spazzed out some people. A lot of
this is pure confusion, e.g. people thinking that all payment requests
would have to go via the CA (no kidding!), but its surprisingly hard
to convince people who are responding emotionally of the subtle
tradeoffs involved especially when they have the luxury of saying
"it's your problem to go figure out, figure it out and go write a
bunch extra of software for me". So having some alternative on day one
would be useful in helping the more conspiracy minded understand that
this isn't some effort to cram the use of CAs down their throat.
==Where Tor comes in==
One of the downsides if using x.509 certs to non-repudiate here is
that sites hosted as tor hidden services can't participate.
It occurred to me that this could be fixed with very little code:
Take the HS pubkey, pack it into a self-signed x.509 cert with the
cn=pubkeybase32.onion.  And specify that .onion certs have a special
hostname validation rule that hashes and encodes the key.
Then the whole process would work for .onion, we'd have a non-CA
option available and working, etc.
I'm aware that HS pubkeys have been used for application level
authentication in Tor elsewhere (e.g. I believe torchat does this) so
it's not entirely unprecedented. I'm not aware of anyone packing them
in x.509 certificates. If anyone has, I'd like to use the same
encoding style for greater compatibility.
The biggest reason I can see not to do this is that it will not be
compatible with future editions of hidden services which aren't based
on RSA keys. (e.g. the EC point addition stuff to protect against
enumeration attacks wouldn't fit into this model). I don't think this
is a serious concern: if HS x.509s do become widely used we could add
a new authentication type for the new onion addresses when those are
Does anyone else see any other reasons not to do this?
Are there other applications which would benefit from having x.509
certs for onion names?

@_date: 2013-10-26 04:06:48
@_author: Gregory Maxwell 
@_subject: [Bitcoin-development] Payment protocol for onion URLs. 
The x.509 in the payment protocol itself is for authentication and
non-repudiation, not confidentiality.
It's used to sign the payment request so that later there is
cryptographic evidence in the event of a dispute:
"He didn't send me my alpaca socks!" "Thats not the address I told you to pay!"
"He told me he'd send my 99 red-balloons, not just one!"  "No way,
that was the price for 1 red-balloon!"
Just using SSL or .onion (or whatever else) gets you confidentiality
and authentication.  Neither of these things get you non-repudiation.
The payment protocol is extensible, so I hope that someday someone
will support namecoin authenticated messages (but note: this requires
namecoin to support trust-free SPV resolvers, otherwise there is no
way to extract a compact proof that can be stuck into a payment
request) and GPG authenticated messages.
But those things will require a fair amount of code (even fixing the
namecoin protocol in the nmc case), and GPG could be done just by
externally signing the actual payment request like you'd sign any
file... and considering the sorry state of their _practical_
usability, I don't think they're worth doing at this time.
By contrast, I _think_ the tor onion support would require only a
relatively few lines of code since it could just be the existing x.509
mechanism with just a simple special validation rule for .onion, plus
a little tool to repack the keys.  I think it would easily be more
widely used than namecoin (though probably both would not really be
used, as gavin notes).
w/ Gavin's comments I'll go check in with the tor folks and see if
anyone has ever though of doing this before and if there is already a
canonical structure for the x.509 certs used in this way.

@_date: 2013-10-26 03:31:05
@_author: Gregory Maxwell 
@_subject: [Bitcoin-development] Payment protocol for onion URLs. 
One limitation of the payment protocol as speced is that there is no
way for a hidden service site to make use of its full authentication
capability because they are unable to get SSL certificates issued to
A tor hidden service (onion site) is controlled by an RSA key.
It would be trivial to pack a tor HS pubkey into a self-signed x509
certificate with the cn set to foooo.onion.
If we specified in the payment protocol an additional validation
procedure for [base32].onion hosts that just has it hash and base32
encode the pubkey (as tor does) then the payment protocol could work
seamlessly with tor hosts. (Displaying that the payment request came
from "foooo.onion").  I believe that the additional code for this
would be trivial (and I'll write it if there is support for making
this a standard feature).
This would give us an fully supported option which is completely CA
free... it would only work for tor sites, but the people concerned
about CA trechery are likely to want to use tor in any case.
