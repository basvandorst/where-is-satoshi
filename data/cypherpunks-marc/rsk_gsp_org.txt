
@_date: 2010-12-09 11:45:45
@_author: Rich Kulawiec 
@_subject: Re: Over a decade of DDOS--any progress yet? 
I often disagree vehemently with JC, but not this time.
I've been studying bot-generated spam for most of the last decade, and to
about 6 nine's, it's all been from Windows boxes.  (The rest?  A smattering
of "indeterminate" and various 'nix systems including MacOS.)
The botnet problem is a Microsoft problem.
Now...whether the botnet problem will still be a Microsoft problem in 2015:
can't say.  Clearly attackers have plenty of reasons to attack other systems
and in some cases, they'll be successful.  But it appears that to date,
the advantages they might accrue from owning a box running one of the
superior operating systems are outweighed by the costs of the effort
to do so.  (With a few rare exceptions, of course.)
But you don't have to take my word for this.  Turn on passive OS
fingerprinting on your MX's and start recording data, including DNS
and rDNS, putative sender, recipient, etc.  Accumulate a couple
years' worth and analyze.
This is why some rather effective defensive techniques (not just for
spam) can be constructed by differentiating traffic based on the
operating system of the host originating that traffic.

@_date: 2012-01-21 12:11:50
@_author: Rich Kulawiec 
@_subject: Re: Megaupload.com seized 
But what -- *exactly* -- is an "illegal file"?
As Leo Bicknell astutely pointed out in this thread:
His example goes on to explain how this is so.  (And I'll point out
that his example applies, for example, to Amazon.  There are coprighted
files there -- e.g., books, music  -- which may be used legally
by those who have purchased them.  Do they become infringing
if someone finds a way to access them without authorization/payment
because Amazon's programmers made an error and left a backdoor open
that allow them to be retrieved via static links?  No, they don't.
Should Amazon delete them in this instance?  No.  Amazon should fix
the backdoors, i.e., remove the spurious links.)
Suppose that Joe and Jane are photographers.  Joe has produced image X
(to which he holds copyright) and Jane has produced image Y (similarly).
Digital images X and Y are used as inputs to program P which produces
output Z that is visually unrecognizable -- that is, anyone who looks
at it sees what appears to be random noise.
Does Z infringe on Joe or Jane's copyrights?  How?  Why?
How does this change (or does it change) if program P' which can
reverse the actions of P exists?
Let me give another example, this time using content that is intrinsically
illegal -- and to avoid triggering hot-button responses, I'm going to
posit a hypothetical: marshmallow peep dioramas.  Let's suppose that
these are illegal in every country on the planet, that those responsible
for them are universally reviled, that it's a crime to photograph them,
possess photographs of them, etc.
We thus conclude that a file consisting of a picture of one of these
is always illegal: that is, it's illegal no matter where it's found.
Now what happens if that picture is decomposed into individual files, each
consisting of one row of pixels from the original?  None of those files
contain anything recognizable as a marshmallow peep diorama.  The original
cannot be reconstructed from any one of them.
Is any one of them illegal?
Further: reassembling these will require something: an index, an algorithm,
some construct that allows the individual files to be recombined.
(This construct contains no content of any kind, marshmallow peep or
otherwise.  It's merely a recipe for putting together files.)
Is that construct illegal? If those individual files are spread across a multitude of hosts,
are any of those hosts holding an illegal file?  How would they know?
(If you're going to argue that those individual rows of pixels are illegal
because the original is illegal, then replace the above with "individual
pixels".  I trust nobody will argue that a single pixel is illegal.  Ever.)
One more scenario: a photo of a marshmalllow peep diorama
is encrypted and uploaded onto server A.  Does server A hold an illegal
file?  How would the operators of server A know?  How would anyone
(other than the uploader) know?  Now suppose that the uploader,
the only person on the planet with the decryption key for that file,
dies; therefore, the file is reduced to -- for all practical purposes --
a random collection of bits.  Is that file still illegal?  Why?  How?
Who will be able to determine this?  (Schrodinger's cat paradox in 1...2...)
I posit these thought experiments (and I'll stop here, although
many others suggest themselves) to highlight some serious
problems with terminology, and with the law: it's an attempt to apply
the principles of the physical world to the digital one, and it's a
total failure.  The putative sharp dividing line between "legal file"
and "illegal file" doesn't really exist -- although many people would
like it to exist, hope it exists, etc., because it serves their agendas
or would make things easier for them.  That doesn't make it so.
Sometimes the world changes, and sometimes when it does, it's time to
discard outdated philosophy that no longer applies to current reality --
because stubborn attempts to hang onto it at all costs, especially by
warping it into something completely unrecognizable from the original
framework, really DO cost, often dearly.  (It's 2012, and there are
still inferior people living on this planet who assign more credibility
to astrology and ghosts than to evolution or anthropocentric global warming.
This isn't funny or quaint any more.  It's stupid and dangerous.)
Schneier famously said "Trying to make bits uncopyable is like trying
to make water not wet".  What we are witnessing is precisely an
attempt to do that, via a combination of anti-security technology
(e.g., DRM) and purchased legislation, orchestrated by failing,
legacy companies run by insatiably greedy people.  These people simply
don't care how much damage they do, how many lives they destroy,
how much they hold back civilization, how much they twist the law,

@_date: 2012-06-21 21:44:49
@_author: Rich Kulawiec 
@_subject: Re: LinkedIn password database compromised 
+1.  I've been reading and thinking about:
for quite some time, and I recommend that others interested in
this topic do the same.

@_date: 2012-06-21 12:56:06
@_author: Rich Kulawiec 
@_subject: Re: LinkedIn password database compromised 
(on the use of public/private keys)
It's a nice thought, but it won't work.   There are two large-scale
security problems which prevent it from working:
1. Fully-compromised/hijacked/botted/zombied systems.  Pick your term,
but any estimate of this population under 100M should be laughed out
of the room.  Plausible estimates are now in the 200M to 300M range.
Any private key present on any of those is accessible to The Bad Guys
whenever they can trouble themselves to grab it.  (Just as they're
already, quite obviously, grabbing passwords en masse.)
2. Pre-compromised-at-the-factory smartphones and similar.  There's
no reason why these can't be preloaded with spyware similar to CarrierIQ
and directed to upload all newly-created private keys to a central
collection point.  This can be done, therefore it will be done, and when
some security researcher discovers it, the usual excuses and justifications
will be made by the designated spokesliars for the companies involved...
which will of course keep right on doing it, albeit perhaps with more
Problem  has been extant for ten years and no (meaningful) progress
whatsoever has been made on solving it.
Problem  is newer, but I'm willing to bet that it will also last
at least a decade and that it will get worse, since there are
substantial economic incentives to make it so.

@_date: 2012-06-08 11:21:17
@_author: Rich Kulawiec 
@_subject: Re: LinkedIn password database compromised 
I think it's mandatory.  It's the only way we can have even modest trust
that it does what it claims to do.  And...as the last week's events have
shown us...vendor-signed software sometimes isn't.

@_date: 2012-11-30 12:58:53
@_author: Rich Kulawiec 
@_subject: Re: William was raided for running a Tor exit node. Please help if you can. 
Question: what evidence has been published -- that is, placed somewhere
that we can all see it -- that substantiates the claim that child porn
traversed the node in question?
Followup question 1: if no such evidence has been produced, then
why should we believe that it exists?  Extraordinary claims require
extraordinary proof.
Followup question 2: if the goal is to identify and apprehend the
perpetrators of child porn (and that's a good goal) then why would
the police raid this operation?  Would it not make far more sense to
take advantage of the operator's knowledge and experience and quietly
ask for his/her cooperation *while leaving the node running*?
Followup question 3: what evidence in front of us allows us to clearly
discern that this is what it purports to be and not simply an attempt
to shut down a Tor node (and intimidate the operators of others)
by using a plausible excuse based on a universal hot-button issue?

@_date: 2012-12-03 11:31:02
@_author: Rich Kulawiec 
@_subject: Re: William was raided for running a Tor exit node. Please help if 
Yes, I can.  I've participated in some that went on for months.  It's simply
a matter of effectiveness and attention span.
I disagree, strongly, as this is an issue of unfortunate timely
relevance to the community.  However, if you, personally, grow tired
of the discussion then of course you can use your email client to
ignore all messages in the thread -- all superior mail clients make
that a trivial exercise.  (I recommend mutt, possibly supplemented
by procmail.  Both tools are suitable for professionals: stable,
mature, portable, and extremely efficient.)

@_date: 2012-12-01 16:50:26
@_author: Rich Kulawiec 
@_subject: Re: William was raided for running a Tor exit node. Please help if 
There is another problem with that approach.  Actually, two, one
that affects us, one that bears on the root cause.
We all know, or should know, that there are a couple hundred million
zombies (aka bots) out there.  Nobody knows exactly how many, of course,
because it's impossible to know.  But any estimate under 100M should be
discarded immediately, and I think numbers in the 200M to 300M are at
least plausible, if not probable.
Those systems are pretty much EVERYWHERE.  The thing is, we don't know
specifically where until either (a) they do something that's externally
observable that indicates they're zombies AND someone in a position
to observe it makes the observation or (b) someone does a forensic-grade
examination of them -- which is often what it takes to find some of
the more devious malware.
There is nothing at all that stops child porn types from leasing zombies
or creating their own.  There is also nothing stopping them from setting
those systems up to transmit/receive child porn via HTTP/S or SMTP or FTP
or any other protocol.  Or through a VPN or whatever.  No Tor required.
So -- five minutes from now -- you (generic you) could suddenly be in
a position where what happened to this guy is happening to you, because
7 zombies on your network just went active and started shovelling child
porn.  And you probably won't know it because the traffic will be noise
buried in all the other noise.
That is, until the authorities, whoever they are wherever you are,
show up and confiscate everything, including desktops, laptops, servers,
tablets, phones, printers, everything with a CPU.  And why shouldn't they?
Do you think you're immune to this?  Why should you be?  Because you're
an ISP?  A Fortune 500 company?  A major university?  Joe's Donut Shop?
Why should *you* get a pass from this treatment?
My point, which I suppose I should get to, is this:
This tactic (confiscating everything) is simply not a sensible response
by any law enforcement agency.  It's bad police work.  It's lazy. It's
stupid.  And worse than any of THAT, it *helps* the child porn types do
their thing.  (Why?  Because it clearly signals the nature and location
and time of a security breach.  This helps them avoid capture and provides
useful intelligence that can be used to design the next operation.)
The right tactic is to keep all that gear exactly where it is and doing
exactly what it's doing.  The children who have already been horribly,
tragically exploited will not be any more so if those systems keep
running: that damage is done and unplugging computers won't fix it.
But keeping that stuff in place and figuring how to start tracing the
purveyors and producers, THAT will attack the root cause of the problem,
so that maybe other children will be spared, and the people responsible
brought to justice.
I know it's unfashionable for police to, you know, actually engage in
police work any more.  It's tedious, boring, and doesn't make headlines.
It's much easier to hold self-congratulory press conferences, torture
helpless people with tasers, and try to out-do Stasi by setting up a
surveillance state.  But it would be nice if someone with a clue got
them to stop supporting child porn by virtue of being so damn lazy,
ignorant and incompetent.
TL;DR: try a rapier rather than a bludgeon.

@_date: 2012-12-31 11:44:34
@_author: Rich Kulawiec 
@_subject: Re: Gmail and SSL 
You're kidding, right?  Captchas have been quite, quite thoroughly beaten
for some time now.  See, among others:

@_date: 2013-02-26 11:43:09
@_author: Rich Kulawiec 
@_subject: Re: NYT covers China cyberthreat 
[a number of very good points ]
Geoblocking, like passive OS fingerprinting (another technique that
reduces attack surface as measured along one axis but can be defeated
by a reasonably clueful attacker), doesn't really solve problems, per se.
If you have a web app that's vulnerable to SQL injection attacks, then
it's still just as hackable -- all the attacker has to do is try from
somewhere else, from something else.
1. It raises the bar.  And it cuts down on the noise, which is one of the
security meta-problems we face: our logs capture so much cruft, so many
instances of attacks and abuse and mistakes and misconfigurations and
malfunctions, that we struggle to understand what they're trying to tell
us.  That problem is so bad that there's an entire subindustry built
around the task of trying to reduce what's in the logs to something
that a human brain can process in finite time.  Mountains of time
and wads of cash have been spent on the thorny problems that arise
when we try to figure out what to pay attention to and what to ignore...
and we still screw it up.  Often.
So even if the *only* effect of doing so is to shrink the size of
the logs: that's a win.  (And used judiciously, it can be a HUGE win,
as in "several orders of magnitude".)  So if your security guy is
as busy as you say...maybe this would be a good idea.
And let me note in passing that by raising the bar, it ensures that
you're faced with a somewhat higher class of attacker.  It's one
thing to be hacked by a competent, diligent adversary who wields
their tools with rapier-like precision; it's another to be owned
by a script kiddie who has no idea what they're doing and doesn't
even read the language your assets are using.  That's just embarassing.
2. Outbound blocks work too, y'know.  Does anybody in your marketing
department need to reach Elbonia?  If not, then why are you allowing
packets from that group's desktops to go there?  Because either
(a) it's someone doing something they shouldn't or (b) it's something doing
something it shouldn't, as in a bot trying to phone home or a data
exfiltration attack or something else unpleasant.  So if there's
no business need for that group to exchange packets with Elbonia
or any of 82 other countries, why *aren't* you blocking that?
3. Yes, this can turn into a moderate-sized matrix of inbound and
outbound rules.  That's why make(1) and similar tools are your friends,
because they'll let you manage this without needing to resort to scotch
by 9:30 AM.  And yes, sometimes things will break (because something's
changed) -- but the brokeness is the best kind of brokeness: obvious,
deterministic, repeatable, fixable.
It's not hard.  But it does require that you actually know what your
own systems are doing and why.
4. "We were hacked from China" is wearing awfully damn thin as the
feeble whining excuse of people who should have bidirectionally firewalled
out China from their corporate infrastructure (note: not necessarily
their public-facing servers) years ago.  And "our data was exfiltrated
to Elbonia" is getting thin as an excuse too: if you do not have an
organizational need to allow outbound network traffic to Elbonia, then
why the hell are you letting so much as a single packet go there?
Like I said: at least make them work for it.  A little.  Instead of
doing profoundly idiotic things like the NYTimes (e.g., "infrastructure
reachable from the planet", "using M$ software", "actually believing that
anti-virus software will work despite a quarter-century of uninterrupted
failure", etc.).  That's not making them work for it: that's inviting
them in, rolling out the red carpet, and handing them celebratory champagne.

@_date: 2013-02-21 16:00:24
@_author: Rich Kulawiec 
@_subject: Re: NYT covers China cyberthreat 
Would it hurt their business?  Really?
Well, if they're eBay, probably.  If they're Joe's Fill Dirt and
Croissants in Omaha, then probably not, because nobody, NOBODY in China
is ever actually going to purchase a truckload of dirt or a tasty
croissant from Joe.  So would it actually matter if they couldn't
get to Joe's web site or Joe's mail server or especially Joe's VPN server?
Probably not.
Nobody in Peru, Egypt, or Romania is likely to be buying from Joe
any time soon either.
This is why I've been using geoblocking at the network and host levels
for over a decade, and it works. But it does require that you make an
effort to study and understand your own traffic patterns as well as your
organizational requirements. [1]
I use it on a country-by-country basis (thank you ipdeny.com) and
on a service-by-service basis: a particular host might allow http
from anywhere, but ssh only from the country it's in.  I also
deny selected networks access to selected services, e.g., Amazon's
cloud doesn't get access to port 25 because of the non-stop spam
and Amazon's refusal to do anything about it.  Anything on the
Spamhaus DROP or EDROP lists (thank you Spamhaus) is not part
of my view of the Internet.  And so on.  Combined, all this
achieves lossless compression of abusive traffic.
This is not a security fix, per se; any services that are vulnerable
are still vulnerable.  But it does cut down on the attack surface as
measured along one axis, which in turn reduces the scope of some
problems and renders them more tractable to other approaches.
An even better approach, when appropriate, is to block everything
and then only enable access selectively.  This is a particularly
good idea when defending things like ssh.  Do you *really* need to
allow incoming ssh from the entire planet?  Or could "the US, Canada,
the UK and Germany" suffice?  If so, then why aren't you enforcing that?
Do you really think it's a good idea to give someone with a 15-million
member global botnet 3 or 5 or 10 brute-force attempts *per bot*
before fail2ban or similar kicks in?  I don't.  I think 0 attempts per
most bots is a much better idea.  Let 'em eat packet drops while they
try to figure out which subset of bots can even *reach* your ssh server.
Which brings me to the NYTimes, and the alleged hacking by the Chinese.
Why, given that the NYTimes apparently handed wads of cash over to
various consulting firms, did none of those firms get the NYTimes to
make a first-order attempt at solving this problem?  Why in the world
was anything in their corporate infrastructure accessible from the 2410
networks and 143,067,136 IP addresses in China?  Who signed off on THAT?
(Yes, yes, I *know* that the NYTimes has staff there, some permanently
and some transiently.  A one-off solution crafted for this use case
would suffice.  I've done it.  It's not hard.  And I doubt that
it would need to work for more than, what, a few dozen of the NYTimes'
7500 employees?  Clone and customize for Rio, Paris, Moscow, and
other locations.  This isn't hard either.  Oh, and lock it out of
everything that a field reporter/editor/photographer doesn't need,
e.g., there is absolutely no way someone coming in through one of
those should be able to reach the subscriber database.)
Two more notes: first, blocking inbound traffic is usually not enough.
Blocks should almost always be bidirectional. [2]  This is especially
important for things like the DROP/EDROP lists, because then spam
payloads, phishes, malware, etc. won't be able to phone home quite
so readily, and while your users will still be able to click on
links that lead to bad things...they won't get there.
Second, this may sound complex.  It's not.  I handle my needs with
make, rsync, a little shell, a little perl, and other similar tools,
but clearly you could do the same thing with any system configuration
management setup.  And with proper logging, it's not hard to discover
the mistakes and edge cases, to apply suitable fixes and temporary
point exceptions, and so on.
[1] 'Now, your typical IT executive, when I discuss this concept with
him or her, will stand up and say something like, "That sounds great,
but our enterprise network is really complicated. Knowing about all the
different apps that we rely on would be impossible! What you're saying
sounds reasonable until you think about it and realize how absurd it
is!" To which I respond, "How can you call yourself a 'Chief Technology
Officer' if you have no idea what your technology is doing?" A CTO isn't
going to know detail about every application on the network, but if you
haven't got a vague idea what's going on it's impossible to do capacity
planning, disaster planning, security planning, or virtually any of the
things in a CTO's charter.'  --- Marcus Ranum
[2] "We were so concerned with getting out that we never stopped to
consider what we might be letting in, until it was too late."
Let's see who recognizes that one. ;-)
