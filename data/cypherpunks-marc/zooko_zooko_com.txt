
@_date: 2002-03-23 12:34:35
@_author: Zooko 
@_subject: Re: Resources discussing secure time (nonce) in a distributed environment. 
Ross Anderson's [1] "Security Engineering" [2] gives this reference:
L Lamport, "Time, Clocks and the Ordering of Events in a Distributed System," in Communications of the ACM, v 21 no 7 (July 1978), pp 558-565
If you want my advice, you don't.  Design your system so that you don't need to prevent this.  In general, design your system so that it doesn't need clock synchronization of any kind other than "Lamport Time", as described in the above reference, which can be cryptographically assured.
[1] [2]                  zooko.com
Security and Distributed Systems Engineering

@_date: 2008-07-16 16:42:23
@_author: zooko 
@_subject: Re: how bad is IPETEE? 
Oh, then they should learn about Adam Langley's Obfuscated TCP:
One of the design constraints for Obfuscated TCP was that an  Obfuscated TCP connection is required to take zero more round trips  to set up and use than a normal TCP connection.  Way to go, Adam!

@_date: 2009-04-14 17:52:47
@_author: zooko 
@_subject: ANNOUNCING Tahoe-LAFS v1.4 
We use cygwin tools quite a lot to build the native-Win32 version of  Tahoe-LAFS, and we also maintain a cygwin port.  You can see the  results of the unit tests on Cygwin on our buildbot.
ANNOUNCING Tahoe, the Least-Authority Filesystem, v1.4
The allmydata.org team is pleased to announce the release of version
1.4.1 of "Tahoe", the Lightweight-Authorization Filesystem. This is the
first release of Tahoe-LAFS which was created solely as a labor of love
by volunteers -- it is no longer funded by allmydata.com (see [1] for
Tahoe-LAFS is a secure, decentralized, fault-tolerant cloud storage
system.  All of the source code is publicly available under Free
Software, Open Source licences.
This filesystem is distributed over multiple servers in such a way the
filesystem continues to operate correctly even when some of the servers
are unavailable, malfunctioning, or malicious. Here is the one-page
explanation of Tahoe's unique security and fault-tolerance properties:
This is the successor to Tahoe-LAFS v1.3, which was released February
13, 2009 [2].  This is a major new release, adding garbage collection,
improved diagnostics and error-reporting, and fixing a critical
performance problem when downloading large (many GB) files.
See the NEWS file [3] and the known_issues.txt file [4] for more
Besides the Tahoe core, a crop of related projects have sprung up,
including frontends for Windows and Macintosh, two front-ends written in
JavaScript, a Ruby interface, a plugin for duplicity, a plugin for
TiddlyWiki, a new backup tool named "GridBackup", CIFS/SMB integration,
an iPhone app, and three incomplete frontends for FUSE. See the Related
Projects page on the wiki: [5].
Tahoe v1.4 is fully compatible with the version 1 series of Tahoe. Files
written by v1.4 clients can be read by clients of all versions back to
v1.0. v1.4 clients can read files produced by clients of all versions  v1.0.  v1.4 servers can serve clients of all versions back to v1.0  and v1.4
clients can use servers of all versions back to v1.0.
This is the fifth release in the version 1 series. The version 1 series
of Tahoe will be actively supported and maintained for the forseeable
future, and future versions of Tahoe will retain the ability to read
files and directories produced by Tahoe v1 for the forseeable future.
The version 1 branch of Tahoe is the basis of the consumer backup
product from Allmydata, Inc. --  .
WHAT IS IT GOOD FOR?
With Tahoe, you can distribute your filesystem across a set of servers,
such that if some of them fail or even turn out to be malicious, the
entire filesystem continues to be available. You can share your files
with other users, using a simple and flexible access control scheme.
Because this software is new, we do not categorically recommend it as
the sole repository of data which is extremely confidential or
precious.  However, we believe that erasure coding, strong encryption,
Free/Open Source Software and careful engineering make Tahoe safer than
common alternatives, such as RAID, removable drive, tape, "on-line
storage" or "Cloud storage" systems.
This software comes with extensive tests, and there are no known
security flaws which would compromise confidentiality or data integrity.
(For all currently known issues please see the known_issues.txt file
This release of Tahoe is suitable for the "friendnet" use case [6] --
it is easy to create a filesystem spread over the computers of you and
your friends so that you can share disk space and files.
You may use this package under the GNU General Public License, version
2 or, at your option, any later version.  See the file "COPYING.GPL"
[7] for the terms of the GNU General Public License, version 2.
You may use this package under the Transitive Grace Period Public
Licence, version 1 or, at your option, any later version.  (The
Transitive Grace Period Public Licence has requirements similar to the
GPL except that it allows you to wait for up to twelve months after you
redistribute a derived work before releasing the source code of your
derived work.) See the file "COPYING.TGPPL.html" [8] for the terms of
the Transitive Grace Period Public Licence, version 1.
(You may choose to use this package under the terms of either licence,
at your option.)
Tahoe works on Linux, Mac OS X, Windows, Cygwin, and Solaris, and
probably most other systems.  Start with "docs/install.html" [9].
HACKING AND COMMUNITY
Please join us on the mailing list [10].  Patches are gratefully
accepted -- the RoadMap page [11] shows the next improvements that we
plan to make and CREDITS [12] lists the names of people who've
contributed to the project.  The wiki Dev page [13] contains resources
for hackers.
Tahoe was originally developed thanks to the sponsorship of Allmydata,
Inc. [14], a provider of commercial backup services.  Allmydata,
Inc. created the Tahoe project, and contributed hardware, software,
ideas, bug reports, suggestions, demands, and money (employing several
Tahoe hackers and instructing them to spend part of their work time on
this Free Software project).  Also they awarded customized t-shirts to
hackers who find security flaws in Tahoe (see ). After discontinuing funding of Tahoe R&D in early 2009, Allmydata,
Inc. has continued to provide servers, co-lo space and bandwidth to the
open source project. Thank you to Allmydata, Inc. for their generous and
public-spirited support.
Zooko Wilcox-O'Hearn
on behalf of the allmydata.org team
Special acknowledgment goes to Brian Warner, whose superb engineering
skills and dedication are primarily responsible for the Tahoe
implementation, and significantly responsible for the Tahoe design as
well, not to mention most of the docs and tests and many other things
April 13, 2009
Boulder, Colorado, USA
[1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] Tahoe, the Least-Authority Filesystem -- store your data: $10/month -- I am available for work -- Unsubscribe info:      Problem reports:       Documentation:         FAQ:

@_date: 2009-04-14 17:26:50
@_author: zooko 
@_subject: ANNOUNCING Tahoe-LAFS v1.4 
ANNOUNCING Tahoe, the Least-Authority Filesystem, v1.4
The allmydata.org team is pleased to announce the release of version
1.4.1 of "Tahoe", the Lightweight-Authorization Filesystem. This is the
first release of Tahoe-LAFS which was created solely as a labor of love
by volunteers -- it is no longer funded by allmydata.com (see [1] for
Tahoe-LAFS is a secure, decentralized, fault-tolerant cloud storage
system.  All of the source code is publicly available under Free
Software, Open Source licences.
This filesystem is distributed over multiple servers in such a way the
filesystem continues to operate correctly even when some of the servers
are unavailable, malfunctioning, or malicious. Here is the one-page
explanation of Tahoe's unique security and fault-tolerance properties:
This is the successor to Tahoe-LAFS v1.3, which was released February
13, 2009 [2].  This is a major new release, adding garbage collection,
improved diagnostics and error-reporting, and fixing a critical
performance problem when downloading large (many GB) files.
See the NEWS file [3] and the known_issues.txt file [4] for more
Besides the Tahoe core, a crop of related projects have sprung up,
including frontends for Windows and Macintosh, two front-ends written in
JavaScript, a Ruby interface, a plugin for duplicity, a plugin for
TiddlyWiki, a new backup tool named "GridBackup", CIFS/SMB integration,
an iPhone app, and three incomplete frontends for FUSE. See the Related
Projects page on the wiki: [5].
Tahoe v1.4 is fully compatible with the version 1 series of Tahoe. Files
written by v1.4 clients can be read by clients of all versions back to
v1.0. v1.4 clients can read files produced by clients of all versions  v1.0.  v1.4 servers can serve clients of all versions back to v1.0  and v1.4
clients can use servers of all versions back to v1.0.
This is the fifth release in the version 1 series. The version 1 series
of Tahoe will be actively supported and maintained for the forseeable
future, and future versions of Tahoe will retain the ability to read
files and directories produced by Tahoe v1 for the forseeable future.
The version 1 branch of Tahoe is the basis of the consumer backup
product from Allmydata, Inc. --  .
WHAT IS IT GOOD FOR?
With Tahoe, you can distribute your filesystem across a set of servers,
such that if some of them fail or even turn out to be malicious, the
entire filesystem continues to be available. You can share your files
with other users, using a simple and flexible access control scheme.
Because this software is new, we do not categorically recommend it as
the sole repository of data which is extremely confidential or
precious.  However, we believe that erasure coding, strong encryption,
Free/Open Source Software and careful engineering make Tahoe safer than
common alternatives, such as RAID, removable drive, tape, "on-line
storage" or "Cloud storage" systems.
This software comes with extensive tests, and there are no known
security flaws which would compromise confidentiality or data integrity.
(For all currently known issues please see the known_issues.txt file
This release of Tahoe is suitable for the "friendnet" use case [6] --
it is easy to create a filesystem spread over the computers of you and
your friends so that you can share disk space and files.
You may use this package under the GNU General Public License, version
2 or, at your option, any later version.  See the file "COPYING.GPL"
[7] for the terms of the GNU General Public License, version 2.
You may use this package under the Transitive Grace Period Public
Licence, version 1 or, at your option, any later version.  (The
Transitive Grace Period Public Licence has requirements similar to the
GPL except that it allows you to wait for up to twelve months after you
redistribute a derived work before releasing the source code of your
derived work.) See the file "COPYING.TGPPL.html" [8] for the terms of
the Transitive Grace Period Public Licence, version 1.
(You may choose to use this package under the terms of either licence,
at your option.)
Tahoe works on Linux, Mac OS X, Windows, Cygwin, and Solaris, and
probably most other systems.  Start with "docs/install.html" [9].
HACKING AND COMMUNITY
Please join us on the mailing list [10].  Patches are gratefully
accepted -- the RoadMap page [11] shows the next improvements that we
plan to make and CREDITS [12] lists the names of people who've
contributed to the project.  The wiki Dev page [13] contains resources
for hackers.
Tahoe was originally developed thanks to the sponsorship of Allmydata,
Inc. [14], a provider of commercial backup services.  Allmydata,
Inc. created the Tahoe project, and contributed hardware, software,
ideas, bug reports, suggestions, demands, and money (employing several
Tahoe hackers and instructing them to spend part of their work time on
this Free Software project).  Also they awarded customized t-shirts to
hackers who find security flaws in Tahoe (see ). After discontinuing funding of Tahoe R&D in early 2009, Allmydata,
Inc. has continued to provide servers, co-lo space and bandwidth to the
open source project. Thank you to Allmydata, Inc. for their generous and
public-spirited support.
Zooko Wilcox-O'Hearn
on behalf of the allmydata.org team
Special acknowledgment goes to Brian Warner, whose superb engineering
skills and dedication are primarily responsible for the Tahoe
implementation, and significantly responsible for the Tahoe design as
well, not to mention most of the docs and tests and many other things
April 13, 2009
Boulder, Colorado, USA
[1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] Tahoe, the Least-Authority Filesystem -- store your data: $10/month -- I am available for work --

@_date: 2009-04-14 16:49:24
@_author: zooko 
@_subject: ANNOUNCING Tahoe-LAFS v1.4 
ANNOUNCING Tahoe, the Least-Authority Filesystem, v1.4
The allmydata.org team is pleased to announce the release of version
1.4.1 of "Tahoe", the Lightweight-Authorization Filesystem. This is the
first release of Tahoe-LAFS which was created solely as a labor of love
by volunteers -- it is no longer funded by allmydata.com (see [1] for
Tahoe-LAFS is a secure, decentralized, fault-tolerant cloud storage
system.  All of the source code is publicly available under Free
Software, Open Source licences.
This filesystem is distributed over multiple servers in such a way the
filesystem continues to operate correctly even when some of the servers
are unavailable, malfunctioning, or malicious. Here is the one-page
explanation of Tahoe's unique security and fault-tolerance properties:
This is the successor to Tahoe-LAFS v1.3, which was released February
13, 2009 [2].  This is a major new release, adding garbage collection,
improved diagnostics and error-reporting, and fixing a critical
performance problem when downloading large (many GB) files.
See the NEWS file [3] and the known_issues.txt file [4] for more
Besides the Tahoe core, a crop of related projects have sprung up,
including frontends for Windows and Macintosh, two front-ends written in
JavaScript, a Ruby interface, a plugin for duplicity, a plugin for
TiddlyWiki, a new backup tool named "GridBackup", CIFS/SMB integration,
an iPhone app, and three incomplete frontends for FUSE. See the Related
Projects page on the wiki: [5].
Tahoe v1.4 is fully compatible with the version 1 series of Tahoe. Files
written by v1.4 clients can be read by clients of all versions back to
v1.0. v1.4 clients can read files produced by clients of all versions  v1.0.  v1.4 servers can serve clients of all versions back to v1.0  and v1.4
clients can use servers of all versions back to v1.0.
This is the fifth release in the version 1 series. The version 1 series
of Tahoe will be actively supported and maintained for the forseeable
future, and future versions of Tahoe will retain the ability to read
files and directories produced by Tahoe v1 for the forseeable future.
The version 1 branch of Tahoe is the basis of the consumer backup
product from Allmydata, Inc. --  .
WHAT IS IT GOOD FOR?
With Tahoe, you can distribute your filesystem across a set of servers,
such that if some of them fail or even turn out to be malicious, the
entire filesystem continues to be available. You can share your files
with other users, using a simple and flexible access control scheme.
Because this software is new, we do not categorically recommend it as
the sole repository of data which is extremely confidential or
precious.  However, we believe that erasure coding, strong encryption,
Free/Open Source Software and careful engineering make Tahoe safer than
common alternatives, such as RAID, removable drive, tape, "on-line
storage" or "Cloud storage" systems.
This software comes with extensive tests, and there are no known
security flaws which would compromise confidentiality or data integrity.
(For all currently known issues please see the known_issues.txt file
This release of Tahoe is suitable for the "friendnet" use case [6] --
it is easy to create a filesystem spread over the computers of you and
your friends so that you can share disk space and files.
You may use this package under the GNU General Public License, version
2 or, at your option, any later version.  See the file "COPYING.GPL"
[7] for the terms of the GNU General Public License, version 2.
You may use this package under the Transitive Grace Period Public
Licence, version 1 or, at your option, any later version.  (The
Transitive Grace Period Public Licence has requirements similar to the
GPL except that it allows you to wait for up to twelve months after you
redistribute a derived work before releasing the source code of your
derived work.) See the file "COPYING.TGPPL.html" [8] for the terms of
the Transitive Grace Period Public Licence, version 1.
(You may choose to use this package under the terms of either licence,
at your option.)
Tahoe works on Linux, Mac OS X, Windows, Cygwin, and Solaris, and
probably most other systems.  Start with "docs/install.html" [9].
HACKING AND COMMUNITY
Please join us on the mailing list [10].  Patches are gratefully
accepted -- the RoadMap page [11] shows the next improvements that we
plan to make and CREDITS [12] lists the names of people who've
contributed to the project.  The wiki Dev page [13] contains resources
for hackers.
Tahoe was originally developed thanks to the sponsorship of Allmydata,
Inc. [14], a provider of commercial backup services.  Allmydata,
Inc. created the Tahoe project, and contributed hardware, software,
ideas, bug reports, suggestions, demands, and money (employing several
Tahoe hackers and instructing them to spend part of their work time on
this Free Software project).  Also they awarded customized t-shirts to
hackers who find security flaws in Tahoe (see ). After discontinuing funding of Tahoe R&D in early 2009, Allmydata,
Inc. has continued to provide servers, co-lo space and bandwidth to the
open source project. Thank you to Allmydata, Inc. for their generous and
public-spirited support.
Zooko Wilcox-O'Hearn
on behalf of the allmydata.org team
Special acknowledgment goes to Brian Warner, whose superb engineering
skills and dedication are primarily responsible for the Tahoe
implementation, and significantly responsible for the Tahoe design as
well, not to mention most of the docs and tests and many other things
April 13, 2009
Boulder, Colorado, USA
[1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] Tahoe, the Least-Authority Filesystem -- store your data: $10/month -- I am available for work --

@_date: 2009-04-14 16:48:51
@_author: zooko 
@_subject: [cap-talk] ANNOUNCING Tahoe-LAFS v1.4 
ANNOUNCING Tahoe, the Least-Authority Filesystem, v1.4
The allmydata.org team is pleased to announce the release of version
1.4.1 of "Tahoe", the Lightweight-Authorization Filesystem. This is the
first release of Tahoe-LAFS which was created solely as a labor of love
by volunteers -- it is no longer funded by allmydata.com (see [1] for
Tahoe-LAFS is a secure, decentralized, fault-tolerant cloud storage
system.  All of the source code is publicly available under Free
Software, Open Source licences.
This filesystem is distributed over multiple servers in such a way the
filesystem continues to operate correctly even when some of the servers
are unavailable, malfunctioning, or malicious. Here is the one-page
explanation of Tahoe's unique security and fault-tolerance properties:
This is the successor to Tahoe-LAFS v1.3, which was released February
13, 2009 [2].  This is a major new release, adding garbage collection,
improved diagnostics and error-reporting, and fixing a critical
performance problem when downloading large (many GB) files.
See the NEWS file [3] and the known_issues.txt file [4] for more
Besides the Tahoe core, a crop of related projects have sprung up,
including frontends for Windows and Macintosh, two front-ends written in
JavaScript, a Ruby interface, a plugin for duplicity, a plugin for
TiddlyWiki, a new backup tool named "GridBackup", CIFS/SMB integration,
an iPhone app, and three incomplete frontends for FUSE. See the Related
Projects page on the wiki: [5].
Tahoe v1.4 is fully compatible with the version 1 series of Tahoe. Files
written by v1.4 clients can be read by clients of all versions back to
v1.0. v1.4 clients can read files produced by clients of all versions  v1.0.  v1.4 servers can serve clients of all versions back to v1.0  and v1.4
clients can use servers of all versions back to v1.0.
This is the fifth release in the version 1 series. The version 1 series
of Tahoe will be actively supported and maintained for the forseeable
future, and future versions of Tahoe will retain the ability to read
files and directories produced by Tahoe v1 for the forseeable future.
The version 1 branch of Tahoe is the basis of the consumer backup
product from Allmydata, Inc. --  .
WHAT IS IT GOOD FOR?
With Tahoe, you can distribute your filesystem across a set of servers,
such that if some of them fail or even turn out to be malicious, the
entire filesystem continues to be available. You can share your files
with other users, using a simple and flexible access control scheme.
Because this software is new, we do not categorically recommend it as
the sole repository of data which is extremely confidential or
precious.  However, we believe that erasure coding, strong encryption,
Free/Open Source Software and careful engineering make Tahoe safer than
common alternatives, such as RAID, removable drive, tape, "on-line
storage" or "Cloud storage" systems.
This software comes with extensive tests, and there are no known
security flaws which would compromise confidentiality or data integrity.
(For all currently known issues please see the known_issues.txt file
This release of Tahoe is suitable for the "friendnet" use case [6] --
it is easy to create a filesystem spread over the computers of you and
your friends so that you can share disk space and files.
You may use this package under the GNU General Public License, version
2 or, at your option, any later version.  See the file "COPYING.GPL"
[7] for the terms of the GNU General Public License, version 2.
You may use this package under the Transitive Grace Period Public
Licence, version 1 or, at your option, any later version.  (The
Transitive Grace Period Public Licence has requirements similar to the
GPL except that it allows you to wait for up to twelve months after you
redistribute a derived work before releasing the source code of your
derived work.) See the file "COPYING.TGPPL.html" [8] for the terms of
the Transitive Grace Period Public Licence, version 1.
(You may choose to use this package under the terms of either licence,
at your option.)
Tahoe works on Linux, Mac OS X, Windows, Cygwin, and Solaris, and
probably most other systems.  Start with "docs/install.html" [9].
HACKING AND COMMUNITY
Please join us on the mailing list [10].  Patches are gratefully
accepted -- the RoadMap page [11] shows the next improvements that we
plan to make and CREDITS [12] lists the names of people who've
contributed to the project.  The wiki Dev page [13] contains resources
for hackers.
Tahoe was originally developed thanks to the sponsorship of Allmydata,
Inc. [14], a provider of commercial backup services.  Allmydata,
Inc. created the Tahoe project, and contributed hardware, software,
ideas, bug reports, suggestions, demands, and money (employing several
Tahoe hackers and instructing them to spend part of their work time on
this Free Software project).  Also they awarded customized t-shirts to
hackers who find security flaws in Tahoe (see ). After discontinuing funding of Tahoe R&D in early 2009, Allmydata,
Inc. has continued to provide servers, co-lo space and bandwidth to the
open source project. Thank you to Allmydata, Inc. for their generous and
public-spirited support.
Zooko Wilcox-O'Hearn
on behalf of the allmydata.org team
Special acknowledgment goes to Brian Warner, whose superb engineering
skills and dedication are primarily responsible for the Tahoe
implementation, and significantly responsible for the Tahoe design as
well, not to mention most of the docs and tests and many other things
April 13, 2009
Boulder, Colorado, USA
[1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] Tahoe, the Least-Authority Filesystem -- store your data: $10/month -- I am available for work -- cap-talk mailing list

@_date: 2009-07-31 21:49:35
@_author: "Zooko Wilcox-O'Hearn" 
@_subject: Re: cleversafe says: 3 Reasons Why Encryption is Overrated 
Over on the Tahoe-LAFS mailing list Brian Warner gave a typically  thoughtful, thorough, and precise analysis of cleversafe access  control as contrasted with Tahoe-LAFS access control.  Brian  attempted to cross-post it to this list, but it bounced since he is  not a subscriber.
Jason Resch of cleversafe has also been participating in the  discussion on that list.

@_date: 2009-07-24 13:33:29
@_author: "Zooko Wilcox-O'Hearn" 
@_subject: cleversafe says: 3 Reasons Why Encryption is Overrated 
[cross-posted to tahoe-dev and cryptography
Disclosure:  Cleversafe is to some degree a competitor of my Tahoe- LAFS project.  On the other hand, I tend to feel positive towards  them because they open-source much of their work.  Our "Related  Projects" page has included a link to cleversafe for years now, I  briefly collaborated with some of them on a paper about erasure  coding last year, and I even spoke briefly with them about the idea  of becoming an employee of their company this year.  I am tempted to  ignore this idea that they are pushing about encryption being  overrated, because they are wrong and it is embarassing.  But I've  decided not to ignore it, because people who publicly spread this  kind of misinformation need to be publicly contradicted, lest they  confuse others.
Cleversafe has posted a series of blog entries entitled "3 Reasons  Why Encryption is Overrated".
 # 3 Reasons Why Encryption is   # Response Part 1: Future  Processing Power
 # Response Part 2:  Complexities of Key Management
 # Response Part 3: Disclosure  It begins like this:
When it comes to storage and security, discussions traditionally  center on encryption.  The reason encryption  or the use of a  complex algorithm to encode information  is accepted as a best  practice rests on the premise that while its possible to crack  encrypted information, most malicious hackers dont have access to  the amount of computer processing power they would need to decrypt  But not so fast.  Lets take a look at three reasons why encryption  is overrated.
The first claim -- the today's encryption is vulnerable to tomorrow's  processing power -- is a common goof, which is easy to make by  conflating historical failures of cryptosystems due to having too  small of a crypto value with failures due to weak algorithms.   Examples of the former are DES, which failed because its 56-bit key  was small enough to fall to brute force, and the bizarre "40-bit  security" policies of the U.S. Federal Government in the 90's.  An  example of the latter is SHA1, whose hash output size is *not* small  enough to brute-force, but which is insecure because, as it turns  out, the SHA1 algorithm allows the generation of colliding inputs  much quicker than a brute force search would.
Oh boy, I see that in the discussion following the article "Future  I dont think symmetric ciphers such as AES-256 are under any threat  of being at risk to brute force attacks any time this century.
What?  Then why is he spreading this Fear, Uncertainty, and Doubt?   Oh and then it gets *really* interesting: it turns out that  cleversafe uses AES-256 in an All-or-Nothing Transform as part of  their "Information Dispersal" algorithm.  Okay, I would like to  understand better the cryptographic effects of that (and in  particular, whether this means that the cleversafe architecture is  just as susceptible to AES-256 failing as an encryption scheme such  as is used in the Tahoe-LAFS architecture).
But, it is time for me to stop reading about cryptography and get  ready to go to work.  :-)
Tahoe, the Least-Authority Filesystem -- store your data: $10/month -- I am available for work --

@_date: 2009-08-10 19:52:58
@_author: "Zooko Wilcox-O'Hearn" 
@_subject: Re: [tahoe-dev] cleversafe says: 3 Reasons Why Encryption isOverrated 
Oh, and while I don't mind if people want to talk about this on the  tahoe-dev list, it doesn't have that much to do with tahoe-lafs  anymore, now that we're done comparing Tahoe-LAFS to Cleversafe and  are just arguing about the cryptographic design of Cleversafe.  ;-)   So, it seems quite topical for the cryptography list and only  tangentially topical for the tahoe-dev list.  I've also been enjoying  the subthread about the physical limits of computation that have  spawned off on the cryptography mailing list.  Ooh, were you guys  considering only classical computers and not quantum computers when  you estimated that either 2^128, 2^200 or 2^400 was the physical  limit of possible computation?  :-)

@_date: 2009-08-10 19:47:42
@_author: "Zooko Wilcox-O'Hearn" 
@_subject: Re: [tahoe-dev] cleversafe says: 3 Reasons Why Encryption isOverrated 
This conversation has bifurcated, since I replied and removed tahoe- dev from the Cc: line, sending just to the cryptography list, and  David-Sarah Hopwood has replied and removed cryptography, leaving  just the tahoe-dev list.
Here is the root of the thread on the cryptography mailing list archive:
Here it is on the tahoe-dev mailing list archive.  Note that  threading is screwed up in our mailing list archive.  :-(

@_date: 2009-08-09 20:48:20
@_author: "Zooko Wilcox-O'Hearn" 
@_subject: Re: cleversafe says: 3 Reasons Why Encryption is Overrated 
[dropped tahoe-dev from Cc:]
This is true for information-theoretically secure secret sharing, but  not true for Cleversafe's technique of composing an All-Or-Nothing- Transform with Reed-Solomon erasure coding.
Hey, let's be nice.  Cleversafe has implemented a storage system  which integrates encryption in the attempt to make it safer.  They  GPL at least some of their work [*], and they publish their ideas and  engage in discussion about them.  These are all good things.  My  remaining disagreements with them are like this:
1.  (The important one.)  I don't think the access control policy of  "whoever can access at least K of the N volumes of data" is the  access control policy that I want.  For one thing, it immediately  leads to the questions that James Hughes was asking, about who is  authorized to access what servers.  For another thing, I would really  like my access control policy to be fine-grained, flexible, and  dynamic.  So for example, I'd like to be able to give you access two  three of my files but not all my other files, and I'd like you to  then be able to give your friend access to two of those files but not  the third.  See Brian Warner's and Jason Resch's discussion of these  issues: [1, 2].
2.  Cleversafe seems to think that their scheme gives better-than- computational security, i.e. that it guarantees security even if  AES-256 is crackable.  This is wrong, but it is an easy mistake to  make!  Both Ben Laurie and James Hughes have jumped to the conclusion  (in this thread) that the Cleversafe K-out-of-N encoding has the same  information-theoretic security that secret-sharing K-out-of-N  encoding has.
3.  Cleversafe should really tone down the Fear Uncertainty and Doubt  about today's encryption being mincemeat for tomorrow's  cryptanalysts.  It might turn out to be true, but if so it will be  due to cryptanalytic innovations more than due to Moore's Law.  And  it might not turn out like that -- perhaps AES-256 will remain safe  for centuries.  Also, Cleversafe's product is not more secure than  any other product against this threat.
It is hard to explain to non-cryptographers how much they can rely on  the security of cryptographic schemes.  It's very complicated, and  most schemes deployed have failed due to flaws in the surrounding  system, engineering errors or key management (i.e. access control)  problems.  Nobody knows what cryptanalytic techniques will be  invented in the future.  My opinion is that relying on well- engineered strong encryption to protect your data is at least as safe  alternatives such as keeping the data on your home computer or on  your corporate server.  The Cleversafe FUD doesn't help people  understand the issues better.
[1] [2] [*] Somebody stated on a mailing list somewhere that Cleversafe has  applied for patents.  Therefore, if you want to use their work under  the terms of the GPL, you should also be aware that if their patents  are granted then some of what you do may be subject to the patents.   Of course, this is always true of any software (the techniques might  be patented), but I thought it was worth mentioning since in this  case the company authoring the software is also the company applying  for patents.

@_date: 2009-08-09 04:49:36
@_author: "Zooko Wilcox-O'Hearn" 
@_subject: Re: cleversafe says: 3 Reasons Why Encryption is Overrated 
[dropping tahoe-dev from Cc:]
I'm sorry, I don't understand your sentence.  Cleversafe isn't using  threshold secret sharing -- it is using All-Or-Nothing-Transform  (built out of AES-256) followed by Reed-Solomon erasure-coding.  The  resulting combination is a computationally-secure (not information- theoretically-secure) secret-sharing scheme.  The Cleversafe  documentation doesn't use these terms and is not precise about this,  but it seems to claim that their scheme has security that is somehow  better than the mere computational security that encryption typically  Oh wait, now I understand your sentence.  "You" in your sentence is  the attacker.  Yes, an information-theoretically-secure secret- sharing scheme does have that property.  Cleversafe's scheme hasn't.

@_date: 2009-08-05 15:28:59
@_author: "Zooko Wilcox-O'Hearn" 
@_subject: Re: cleversafe says: 3 Reasons Why Encryption is Overrated 
[cross-posted to tahoe-dev and cryptography
It doesn't look like I'm going to get time to write a long post about  this bundle of issues, comparing Cleversafe with Tahoe-LAFS (both use  erasure coding and encryption, and the encryption and key-management  part differs), and arguing against the ill-advised Fear, Uncertainty,  and Doubt that the Cleversafe folks have posted.  So, I'm going to  try to throw out a few short pieces which hopefully each make sense.
First, the most important issue in all of this is the one that my  programming partner Brian Warner already thoroughly addressed in [1]  (see also the reply by Jason Resch [2]).  That is the issue of access  control, which is intertwined with the issues of key management.  The  other issues are cryptographic details which are important to get  right, but the access control and key management issues are the ones  that directly impact every user and that make or break the security  and usefulness of the system.
Second, the Cleversafe documents seem to indicate that the security  of their system does not rely on encryption, but it does.  The data  in Cleversafe is encrypted with AES-256 before being erasure-coded  and each share stored on a different server (exactly the same as in  Tahoe-LAFS).  If AES-256 is crackable, then a storage server can  learn information about the file (exactly as in Tahoe-LAFS).  The  difference is that Cleversafe also stores the decryption key on the  storage servers, encoded in such a way that  any K of the storage  servers must cooperate to recover it.  In contrast, Tahoe-LAFS  manages the decryption key separately.  This added step of including  a secret-shared copy of the decryption key on the storage servers  does not make the data less vulnerable to weaknesses in AES-256, as  their documents claim.  (If anything, it makes it more vulnerable,  but probably it has no effect and it is just as vulnerable to  weaknesses in AES-256 as Tahoe-LAFS is.)
Third, I don't understand why Cleversafe documents claim that public  key cryptosystems whose security is based on "math" are more likely  to fall to future advances in cryptanalysis.  I think most  cryptographers have the opposite belief -- that encryption based on  bit-twiddling such as block ciphers or stream ciphers is much more  likely to fall to future cryptanalysis.  Certainly the history of  modern cryptography seems to fit with this -- of the original crop of  public key cryptosystems founded on a math problem, some are still  regarded as secure today (RSA, DH, McEliece), but there has been a  long succession of symmetric crypto primitives based on bit twiddling  which have then turned out to be insecure.  (Including, ominously  enough, AES-256, which was regarded as a gold standard until a few  months ago.)
Fourth, it seems like the same access control/key management model  that Cleversafe currently offers could be achieved by encrypting the  data with a random AES key and then using secret sharing to split the  key and store on share of the key with each server.  I *think* that  this would have the same cryptographic properties as the current  Cleversafe approach of using an All-Or-Nothing-Transform followed by  erasure coding.  Both would qualify as "computation secret sharing"  schemes as opposed to "information-theoretic secret sharing"  schemes.  I would be curious if there are any significant differences  between these two constructions.
I don't think there is any basis to the claims that Cleversafe makes  that their erasure-coding ("Information Dispersal")-based system is  fundamentally safer, e.g. these claims from [3]: "a malicious party  cannot recreate data from a slice, or two, or three, no matter what  the advances in processing power." ... "Maybe encryption alone is  'good enough' in some cases now  - but Dispersal is 'good always' and  represents the future."
Fifth, as I've already mentioned, the emphasis on cryptography being  defeated due to advances in processing power e.g. reference to  Moore's Law is confused.  Advances in processing power would not be  sufficient to crack modern cryptosystems and in many cases would not  be necessary either.
Okay I think that's it.  I hope these notes are not so terse as to be  confusing or inflammatory.
Zooko Wilcox-O'Hearn
[1] [2] [3]

@_date: 2009-11-08 11:30:47
@_author: "Zooko Wilcox-O'Hearn" 
@_subject: hedging our bets -- in case SHA-256 turns out to be insecure 
We're going to be deploying a new crypto scheme in Tahoe-LAFS next  year -- the year 2010.  Tahoe-LAFS is used for long-term storage, and  I won't be surprised if people store files on Tahoe-LAFS in 2010 and  then rely on the confidentiality and integrity of those files for  many years or even decades to come.  (People started storing files on  Tahoe-LAFS in 2008 and so far they show no signs of losing interest  in the integrity and confidentiality of those files.)
This long-term focus makes Tahoe-LAFS's job harder than the job of  protecting transient network packets.  If someone figures out in 2020  or 2030 how to spoof a network transaction that you sent in 2010 (see  [1]), it'll be far too late to do you any harm, but if they figure  out in 2030 how to alter a file that you uploaded to a Tahoe-LAFS  grid in 2010, that might harm you.
Therefore I've been thinking about how to make Tahoe-LAFS robust  against the possibility that SHA-256 will turn out to be insecure.
A very good way to do this is to design Tahoe-LAFS so that it relies  as little as possible on SHA-256's security properties.  The property  that seems to be the hardest for a secure hash function to provide is  collision-resistance.  We are analyzing new crypto schemes to see how  many security properties of Tahoe-LAFS we can continue to guarantee  even if the collision-resistance of the underlying secure hash  function fails, and similarly for the other properties of the secure  hash function which might fail [2].
This note is not about that design process, though, but about how to  maximize the chance that the underlying hash function does provide  the desired security properties.
We could use a different hash function than SHA-256 -- there are many  alternatives.  SHA-512 would probably be safer, but it is extremely  expensive on the cheap, low-power 32-bit ARM CPUs that are one of our  design targets [3], and the output size of 512 bits is too large to  fit into Tahoe-LAFS capabilities.  There are fourteen candidates left  in the SHA-3 contest at the moment.  Several of them have  conservative designs and good performance, but there is always the  risk that they will be found to have catastrophic design flaws or  that a great advance in hash function cryptanalysis will suddenly  show how to crack them.  Of course, a similar risk applies to SHA-256!
So I turn to the question of how to combine multiple hash functions  to build a hash function which is secure even if one or more of the  underlying hash functions turns out to be weak.
I've read several interesting papers on the subject -- such as [4, 5]  and especially "Robust Multi-Property Combiners for Hash Functions  Revisited" by Marc Fischlin, Anja Lehmann, and Krzysztof Pietrzak  [6].  The good news is that it turns out to be doable!  The latter  two papers show nice strong theoretical results -- ways to combine  hash functions so that the resulting combination is as strong or  stronger than the two underlying hash functions.  The bad news is  that the proposal in [6] builds a combined function whose output is  twice the size of the output of a single hash function.  There is a  good theoretical reason for this [4], but it won't work for our  practical engineering requirements -- we need hash function outputs  as small as possible (partially due to usability issues)
The other bad news is that the construction proposed in [6] is  complicated, underspecified, and for the strongest version of it, it  imposes a limit on the length of the inputs that you can feed to your  hash function.  It grows to such complexity and incurs such  limitations because it is, if I may call it this, "too theoretical".   It is designed to guarantee certain output properties predicated on  minimal theoretical assumptions about the properties of the  underlying hash functions.  This is a fine goal, but in practice we  don't want to pay such a high cost in complexity and performance in  order to gain such abstract improvement.  We should be able to "hedge  our bets" and achieve a comfortable margin of safety with a very  simple and efficient scheme by making stronger, less formal, but very  plausible assumptions about the underlying hash functions.  Read on.
I propose the following combined hash function C, built out of two  hash functions H1 and H2:
C(x) = H1(H1(x) || H2(x))
The first observation is that if H1 is collision-resistant then so is  C.  In practice I would expect to use SHA-256 for H1, so the  resulting combiner C[SHA-256, H2] will be at least as strong as  SHA-256.  (One could even think of this combiner C as just being a  tricky way to strengthen SHA-256 by using the output of H2(x) as a  randomized salt -- see [7].)
The next observation is that finding a pair of inputs x1, x2 which  collide in *both* H1 and in H2 is likely to be much harder than  finding a pair of inputs that collide in H1 and finding a pair of  inputs that collide in H2 (see [5]).
Now the reason that a combiner like this one is not published in  theoretical crypto literature is that it obviously could fail if the  outer hash function H1 fails.  For example, even if H2 is collision- resistant, if H1 turns out to be susceptible to collisions, then  theoretically speaking C[H1, H2] might be susceptible to collisions.   However, in real life C[H1, H2] would most likely still be collision  All practical attacks on real hash functions so far (if I understand  correctly) are multi-block attacks in which the attacker is able to  feed a sufficiently long and unconstrained input to the hash  functions that the effects of the later parts of his inputs are able  to manipulate the state generated by the earlier parts of his  inputs.  My combiner C uses H1 in its outer invocation on a single- block-sized input, which means no such multi-block attacks are  possible on the outer invocation.  In addition, the inputs that the  attacker gets to feed to the outer invocation of H1 are highly  constrained.  Basically, he would already have to be very good at  manipulating the inner invocations H1 and H2 in ways that he isn't  supposed to before he can even begin to manipulate the outer  invocation of H1.
A measure of the practical security of a combiner like this one would  be "how safe would it be if it were instantiated using broken  practical hash functions such as MD5 and SHA1?".  It appears to me  (from an admittedly cursory analysis) that there is no realistic way  to find collisions in C[MD5, SHA1] even though there are realistic  ways to find collisions in MD5 and in SHA1.  Of course, I'm not  proposing to use C[MD5, SHA1]!  I'm proposing to use C[SHA-256, _]  where _ is some other hash function which is believed to be strong.   The example of instantiating C with MD5 and SHA1 just goes to show  that C is a hash function which is stronger than either of its two  underlying hash functions.
The other desirable security properties such as second-preimage  resistance and pre-image resistance seem to follow the same pattern  as collision-resistance -- C[H1, H2] seems to be much stronger than  H1 or H2 alone.
[1] [2] [3] [4] Krzysztof Pietrzak: "Non-Trivial Black-Box Combiners for  Collision-Resistant Hash-Functions don't Exist"
[5] Jonathan J. Hoch, Adi Shamir: "On the Strength of the  Concatenated Hash Combiner when All the Hash Functions are Weak"
[6] Marc Fischlin, Anja Lehmann, Krzysztof Pietrzak: "Robust Multi- Property Combiners for Hash Functions Revisited"
[7]

@_date: 2011-06-14 03:15:08
@_author: Zooko O'Whielacronx 
@_subject: [cryptography] Is BitCoin a triple entry system? 
Also related, Eric Hughes posted about something he called "Encrypted
Open Books" on 1993-08-16. The idea was to allow an auditor to confirm
the correctness of the accounts without being able to see the details
of people's accounts.

@_date: 2012-03-29 16:17:47
@_author: "Zooko Wilcox-O'Hearn" 
@_subject: [tahoe-dev] should we work on critical bugs or fix easy stuff? :-)  Re: what should we work on at th 
Yes, I too think the biggest issues right now have to do with
mutables. In addition to the long-standing issue that repair
increments the version number ( there are several major bugs in
mutables, especially MDMFs, but also regressions in SDMF mutables:
Kevan has been working on these and for some of them has posted
patches for people to test whether the patches fix the problems they
A couple of weeks ago I spent a plane flight (about 3 hours) reading
through the mutable code to refresh my understanding of it, but I had
barely begun getting all back in my head when the plane landed. :-) I
hope to make time to do that again soon. I have a lot of notes from
the flight.
Anyway, as far as what's most important for making a new release of
Tahoe-LAFS that the most people can rely on, fixing and auditing
mutables is probably the most important! You can see that I've
signalled that by marking those tickets as "Priority: critical" if you
view all tickets sorted by their Priority:
However, my assumption was that for this weekend's Hack Fest, it would
take too much time to get anyone trained up on the theory of mutables
well enough that they could start reviewing Kevan's fix-it patches,
reading the code in search of other bugs, or writing tests or patches
for the known bugs. I figured the thing most likely to reach
completion in one weekend is code review of smaller patches for
simpler issues, or writing unit tests for simple issues.
Maybe this is wrong! Maybe diving in by reading a bug description (on
a ticket) and a patch by Kevan that fixes that bug is the fastest way
to become an expert.
I think I'll try to suss out what motivates the attendees at the Hack
Fest. If you show up (on IRC, or in person in Boulder), and you're
awfully keen to fix a certain issue, then I'll try to help you do
 repair of mutable
files/directories should not increment the sequence number
tahoe-dev mailing list

@_date: 2012-03-28 21:32:30
@_author: "Zooko Wilcox-O'Hearn" 
@_subject: [cryptography] Bitcoin-mining Botnets observed in the wild? (was:  Re: Bitcoin in endgame 
(N.B. I (still) disagree with Ian Grigg's thesis in several of its
other steps. However, the part about how botnets, which don't pay for
the marginal cost of their electricity, will provide an increasing
contribution to the global Bitcoin transaction-confirmation service
(a.k.a. "mining") -- that part I'm starting to agree with.)
"In addition to spamming and distributed denial-of-service attacks,
this latest botnet was capable of both stealing Bitcoin wallets from
infected computers, and BitCoin mining, which uses the resources of
victimized computers to make new Bitcoins." B9
B9 So, Kaspersky and company took down this botnet, which they say had
about 116,000 bots, starting on March 21, nabbing three quarters of
them within 24 houres, and the botnet was mostly dead within a week.
Note that a lot of the bots would not be powered on or connected to
the Internet 24/7. That might be part of why it took a week to reach
most of them and sinkhole them, and it also means that the
*continuous* number of bots connected at any one time was a fraction
of 116,000 -- probably around 5% of the total, or around 5000,
extrapolating from B2  -- or if you look at Figure 3 on B3 and squint
real hard at the altitude of the red line.
B2 B3 Can we see a blip in the Bitcoin charts starting on March 21?
Here's the chart of aggregate mining power: b4. I uploaded a snapshot
of the relevant time span here: b5.
b4 b5 How to interpret this? There *is* a significant dip in aggregate
mining power beginning on the 22nd, not the 21st. Hm, yeah I guess
that roughly lines up with Fig 4 from B3.
Heh, I note that B3 doesn't mention Bitcoin mining, only wallet theft,
and the Ars Technica article's only other source -- the blog entry
from Kaspersky b6 -- mentions only "bitcoin-mining wallet theft", which
is a funny jumble of two different things.
b6 The security company people told the Ars Technica reporter that they
were surprised that the Botnet operators didn't try to recover control
of the bots. Look at the way the aggregate mining power rebounded in
the ensuing days. Could it be that the operators were too busy renting
and spinning up their new botnet to struggle for control of their old
Here's another graph -- number of nodes connected to a Bitcoin node: b7.
b7 There's a substantial dip followed by a recovery within a couple of
days. Oh, but if b8 (snapshot b9) is accurate, that dip began on the
16th and was over by the 19th. So that probably has nothing to do with
it. I guess a Bitcoin-mining Botnet would not show up on this graph
anyway, as it would proxy all of its connections to the Bitcoin
network through a single Bitcoin node or a small number of Bitcoin
b8 b9 I'm beginning to doubt that the takedown of the botnet had anything to
do with the dip in mining power, because (a) the statements from
security companies are light on details and unclear on the concept,
and (b) 84% of the infected machines were running Windows XP (most of
them were located in Poland), which I suspect means they don't have a
modern enough GPU to contribute to the global transaction-confirmation
But what if? Suppose, just suppose, that of the 5000 continuous bots,
500 of them had a modern GPU and that the botnet operators had
actually gone ahead and installed a Bitcoin mining plugin on them.
Looking at the Bitcoin Mining Hardware Comparison B9b0 and looking at
the cheaper cards costing around $100, I guess that this might be
worth about 200 Mhash/sec for each of the 500 bots, or 100 Ghash/sec
for the whole botnet. The range from the peak to the trough of the
blue line (1 day window estimate) on b4 is about 3000 Ghash/sec. Hm, so
that's much more than the botnet could have been producing, by my
estimates. Even if we are a lot more generous with our assumptions
about how many of those bots had GPUs, and how fancy and expensive
those GPUs were, they probably couldn't account for even half of that
1-day window estimate delta of 3000 GHash/sec.
B9b0 BOTTOM LINE
A 100,000-node botnet was taken down. The architects of the takedown
made statements that it was used for Bitcoin mining. At the same time,
there was a substantial dip in the global rate of transaction
confirmation (a.k.a. "mining"), which last about 48 hours. However,
back-of-the-envelope calculations by yours truly indicate that a
100,000-node botnet would not contribute even 10% of the hash rate
seen in the dip.
cryptography mailing list

@_date: 2012-04-13 06:41:02
@_author: "Zooko Wilcox-O'Hearn" 
@_subject: Re: [cryptography] Doubts over necessity of SHA-3 cryptography  standard 
Yes, when the SHA-3 process was launchedbin the exciting time when MD5
and SHA-1 had been dramatically shown to be weakbit seemed like we
were in danger of waking up one day and finding out that we had no
strong hash functions left. It was prudent to get started on SHA-3
ASAP in order to have an alternative ready for that eventuality. NIST
explicitly called for hash functions which were different from SHA-256
and which seemed likely to survive a breakthrough that would destroy
Now these few years later *my* feelings, at least, have kind of
flip-flopped. SHA-256 feels a lot *less* likely to suddenly succumb,
now that it has weathered the Wang attacks for half a decade.
I was, frankly, disappointed that the SHA-3 project didn't produce
something *both* safer *and* faster than SHA-1 (not to mention SHA-2),
in the same way that AES provided an algorithm both safer and faster
than DES (not to mention 3-DES). But I can understand where NIST, and
the many cryptographers involved, were coming from. Again, they were
starting from a position of uncertainty about whether there were
critical flaws in our basic assumptions, so conservatism reined. I
overheard one SHA-3 designer (who reads this list) comment "At that
time, we weren't sure that we knew how to build secure hash
The major result of the SHA-3 process appears to be that not only is
it quite possible for cryptographers to build new secure hash
functions [*], but also that SHA-256 is a secure hash function.
[*] All five of the SHA-3 Round 3 candidates (finalists) seem quite
secure. In addition, all nine of the Round 2 candidates seem quite
secure. In addition, there were eleven Round 1 candidates without
published attacks, plus five Round 1 candidates without attacks better
than brute force (counting time*memory), plus twelve Round 1
candidates without attacks that were demonstrated in practice (some of
them nearly practical e.g 2b6b7 work, and others extremely far from
practical, e.g. 2B9b4B3 work). In addition there was at least one (a
personal favorite), EnRUPT, which was practically vulnerable with the
proposed parameters, but might be counted as "evidence that we know
how to build secure hash functions" with slightly larger parameters
[B9]. See the SHA-3 Zoo [B2] for a catalogue of these candidates and
published attacks on them.
So the SHA-3 project has shown that cryptographers could, in about a
year, come up with, depending on how you count, somewhere between
twenty-five and fortyish different functions which cryptographers, in
about four years, couldn't (practically) break.
Perhaps once the SHA-3 project wraps up, cryptographers will start
searching for the limit on how efficient they can make hash functions
before they break. The "lightweight cryptography" research (Quark,
Spongent, Photon) is a step in that direction.
Another approach would be cataloguing attacks on reduced-round
variants of otherwise believed-good functions. For example, SHA-256
runs at about 25 cycles/byte [B3] and has 64 rounds, and the best known
attack on reduced SHA-256 is on 41 rounds (according to wikipedia),
which suggests that a 42-round variant of SHA-256, which would run at
about 17 cpb, ought to be safe. Then there is Skein. It runs at 23 cpb
and has 72 rounds, and there is no published attack of any kind (even
the unreasonable kind) on more than 57 rounds of Skein [b4], so if you
used 58-round Skein it would cost about 19 cpb. Then Blake [b5] (my
current favorite). 14 rounds, 31 cpb, no attacks known on more than 6
rounds, so it ought to be possible to have a cut-down version of Blake
that runs at about 16 cpb.
Note that all of these numbers above are still pretty conservative!
For example, I said that there were no known attacks on Blake with
more than 6 rounds, but the known "attacks" on Blake with 6 rounds are
not really "attacks", but more like "interesting theoretical
observations". If you only count attacks which are actually computable
in the real world, which apply to the full hash function (not just to
some internal component of it), and which are a full collision (not
just some "near miss" like a "partial pseudo-collision"), then I don't
think there is an attack on even 1 round of Blake. If 1-round Blake is
actually secure, then that would mean you can have a secure hash
function in about 2 cpb! A similar argument goes for Skein and even
Another approach would be to look at the most efficient full hash
functions that have been studied. If you look at the most efficient
hash functions on [B3], they are:
md4 -- 7 cpb -- insecure
md5 -- 8 cpb -- insecure
edonr -- 11 cpb -- secure! It was rejected from the SHA-3 contest, not
because it was shown to be insecure but from an abundance of caution
(in my humble opinion -- I know others who know a lot more than I do
about this would disagree).
shabal -- 15 cpb -- secure! ditto
sha-1 -- 15 cpb -- insecure
bmw -- 15 cpb -- secure! ditto
All this makes me think that it really ought to be possible to have a
function more efficient than SHA-256 and is still secure, and perhaps
even possible to have a function more efficient than SHA-1 or even MD5
and is still secure. I guess it is going to be quite a few years
before we gain confidence in any such function, though, unfortunately.
To be clear, I'm not exactly recommending that you should *use* a
reduced-round SHA-256, a reduced-round SHA-3 finalist like Blake, or a
SHA-3 reject like Edon-R. I'm not saying you shouldn't use such a
thing either. What I'm saying is: their existence is reason to believe
that a secure hash function with this kind of efficiency could exist.
[B9] [B2] [B3]  ; 32-bit ARM
"h6dragon", 4096 byte input, worst quartile
[b4] [b5] cryptography mailing list

@_date: 2012-07-03 11:41:34
@_author: "Zooko Wilcox-O'Hearn" 
@_subject: Re: [tahoe-dev] switching from introducers to gossip? 
... snipping out a lot of useful, clear details about the new
introduction and accounting mechanisms ...
This is not true of the grid I'm most familiar with: volunteergrid2.
In that grid almost every node is either a client or a server --
almost no nodes act as both. (I think. This is just judging from
reading the volunteergrid2-l mailing list.)
Maybe we need two different names, one for the "p2p style" friendnet
that you describe in your letter (partially quoted below) and the
other for the "sysadmins offering one another access to their servers"
friendnet, such as volunteergrid2.
I don't understand enough to have an opinion on that specific
question, but in general I think there is a growing tension between
"p2p style" and "client/server style", and the above smells like
baking "p2p style" into the introduction protocol.
I think that's great! I love the idea! I hope you keep working on it,
and I will endeavour to help. If we succeed, it will be the
long-awaited reincarnation of the Mojo Nation dream.
But, it is rather different in deployment/management from what our
current users do with our current software. Maybe it won't work out.
It requires engineering effort to implement and maintain, makes the
behavior of the software harder to predict, and introduces more
complex failure modes.
If possible, I would like to support people continuing to use
Tahoe-LAFS as service administered by diligent sysadmins even while
extending it to be deployable by inattentive end users as you've
I think not too far down this path there might come a time to split
Tahoe-LAFS into separate packages targeted at different deployment
scenarios. Note that the i2p folks appear to have already forked it
for this reason -- in order to maintain different deployment features!
Also note that you, Brian, have published some experimental
forks/variants focused on different deployment patterns.
If you want "user friendly p2p software", then you probably want:
b" Which services? Each node operates, by default, multiple services --
storage server, storage client == web gateway, introducer/gossiper,
and in the future other services like relay server (to help get around
incomplete connectivity of the underlying network -- b" Which IP addresses? Nodes automatically detect their own IP
addresses, such as by inspecting the output of "/sbin/ifconfig" or
"route.exe", or opening a TCP connection to some helpful STUNT/ICE
server and asking that server what IP address your packets appear to
be coming from (
b" Which connections? Nodes advertise multiple IP addresses / DNS names
(possibly including those auto-discovered as above, plus any that were
manually entered by the user ( plus 127.0.0.1 or any
globally-non-routeable IP addresses revealed by ifconfig, and possibly
in the future including indirection through a relay server), peers
attempt to connect to nodes on all advertised IP addresses / DNS names
in parallel, then use whichever connections succeeded.
b" How to handle NAT/firewall/inconveniently-behaving-router? Nodes
utilize the latest and greatest Romulan packet technology, such as
UPnP ( "NAT hole punching" techniques ( or even B5TP (
or relay service ( to breeze through such impediments as though
they weren't even there.
b" Reverse connections? If a TCP connection is established from node A
to node B, then B can use that in the "reverse direction" to make
requests of A, just as well as A can use it to make requests of B.
This means that if A is behind a firewall which allows outgoing but
not incoming connections to be established, and A established an
outgoing connection to B, then B can use A as a server, but C, which
for some reason didn't get a connection from A, cannot use A as a
server. (
If you want "sysadmin-friendly software" then you probably want the
opposite of all these features!
b" Which services? Each node operates, by default, only the services
that the operator manually configured it to run. Even better you can
install the software sufficient to run a specific kind of node, e.g. a
storage server, without installing the software that would let it run
other servers, such as introducers or storage clients (
b" Which IP addresses? Nodes do not automatically detect their own IP
addresses, but instead use only the IP address that their sysadmin
manually told them to use. This is especially important for tor and
i2p people where any auto-discovered IP address threatens the user's
safety (
b" Which connections? You try to establish the prescribed TCP
connection(s) to your server. If that fails, you log/announce failure.
In the future you might even be able to configure it to run
exclusively over HTTP(S) and then pass all of its connections through
your HTTP proxies and Web Services tools ( (Although sysadmins may actually like the "try to connect to multiple
IP/DNS addresses at once" feature, if it is sufficiently
understandable and controllable to them. It would ease some headaches
provided by the Amazon Web Services EC2 TCP/DNS infrastructure, for
b" How to handle NAT/firewall/inconveniently-behaving-router? If you
can't establish a TCP connection to your prescribed target, then
obviously you should not talk to it. Either some wise sysadmin doesn't
want you to (firewall) or some stupid sysadmin has screwed up the
network config and needs to fix it. In either case you should log
failure and give up immediately.
b" Reverse connections? Clients connect to servers. Servers do not
connect to clients, clients do not connect to other clients, and
servers do not connect to other servers ( To violate this
principle means you will receive a visit from your keen-eyed sysadmin
who will want to know what the hell you are doing B9.
Don't get me wrong -- I think the p2p style, which foolscap already
implements part of -- is sweet. I'd like to improve it, in the
interests of making Tahoe-LAFS deployment more automatic for
end-users. However, we should probably pay attention to the fact that
many of our current users do not use those features, and some of them
are actively requesting the ability to turn off those features.
Maybe some kind of friendly fork or more targeted packaging would help
us manage these diverging deployment scenarios?
B9  UPnP
 STUNT/ICE
 tcp hole-punching!
 more
client-vs-server refactoring: servers-only shouldn't subscribe to
storage announcements
 implement relay:
allow storage servers behind NAT
 use plain HTTP for
storage server protocol
 make tahoe Tor- and
 merge manually
specified tub location with autodetected tub location
 HTTP proxy support
for node to node communication
 servers should
attempt to open connections to clients
 use N<TP
 package client and
server separately
tahoe-dev mailing list

@_date: 2013-08-29 19:54:50
@_author: zooko 
@_subject: Re: [cryptography] LeastAuthority.com announces PRISM-proof storage service 
The Least-Authority Filesystem does all of the above. We have some pretty good
cryptography mailing list

@_date: 2013-08-16 19:11:22
@_author: zooko 
@_subject: Re: [cryptography] LeastAuthority.com announces PRISM-proof storage service 
I agree that compromise of the client is relevant. My current belief is that
nobody is doing this on a mass scale, pwning entire populations at once, and
that if they do, we will find out about it.
My goal with the S4 product is not primarily to help people who are being
targeted by their enemies, but to increase the cost of indiscriminately
surveilling entire populations.
Now maybe it was a mistake to label it as "PRISM-Proof" in our press release
and media interviews! I said that because to me "PRISM" means mass surveillance
of innocents. Perhaps to other people it doesn't mean that. Oops!
cryptography mailing list

@_date: 2013-08-29 22:26:48
@_author: zooko 
@_subject: Re: [cryptography] Reply to Zooko (in Markdown) 
I don't know. I asked a lawyer a few days ago -- a person who is, as far as I
can tell, one of the leading experts in this field. Their answer was that
nobody knows.
In any case, you don't appear to be arguing that Silent Text is different than
Silent Mail, only that the U.S. Federal Government would not require Silent
Circle to actively backdoor their own products. This argument applies equally
to the canceled product and the current ones.
In fact, I don't think it is a useful question for evaluating the security of
services that you rely on. If a service provider could spy on you at the behest
of their government, then an attacker who infiltrated that service provider's
systems could also spy on you.
Imagine that your adversary is not the U.S. NSA, but instead Chinese
cyber-warriors, and instead of contacting your service provider and demanding
cooperation, they simply remotely infiltrate your service provider's employee's
laptops. They've apparently done this many times in recent years, to Adobe,
Google, Microsoft, Nortel Networks, and basically every other company you can
So I don't think the question of "To whom is my service provider vulnerable?"
is the right question. You can't really know the answer, so it doesn't help you
much to wonder about it. The right question is "Am I vulnerable to my service
provider?". The answer, as far as Silent Circle's current products go, is
Here are the first five hits from DuckDuckGo for the query "silent circle
    "We knew USG would come after us." That's why Silent Circle CEO Michael
    Janke tells TechCrunch his company shut down its Silent Mail encrypted
    email service.
        Silent Circle, the provider of a range of secure communications services,
    has pre-emptively closed its Silent Mail email service in order to stop
    U.S.  authorities from spying on its customers
        Silent Circle, the global encrypted communications firm revolutionizing
    mobile security for organizations and individuals alike, today announced it
    has discontinued its Silent Mail e-mail encryption service in order to
    preempt governments' demands for customer information in the escalating
    surveillance environment targeting global communications.         the Lavabit e-mail service used by National Security Agency leaker Edward
    Snowden announced Thursday that it would shut down, implying heavily that
    it had received some sort of government request for information. Hours
    later ... Silent Circle, said it would preemptively shut down its Silent
    Mail service to avoid ending up in the same position.
        There are far too many leaks of information and metadata intrinsically in
    the email protocols themselves. Email as we know it with SMTP, POP3, and
    IMAP cannot be secure.
    (Kudos to Jon for saying something sensical in that last one!)
cryptography mailing list

@_date: 2013-09-26 18:06:15
@_author: zooko 
@_subject: Re: [cryptography] [Cryptography] RSA equivalent key length/strength 
This is a very good resource because it includes recommendations from multiple
sources and makes it easy to compare them:
cryptography mailing list

@_date: 2013-09-11 05:53:01
@_author: zooko 
@_subject: Re: [Cryptography] Why prefer symmetric crypto over public key crypto? 
I agree that randomness-reuse is a major issue. Recently about 55 Bitcoin were
stolen by exploiting this, for example:
However, it is quite straightforward to make yourself safe from re-used nonces
in (EC)DSA, like this:
Whenever the public-key crypto spec says that you have to come up with a random
number, don't do it! Instead of just pulling a random number from your PRNG,
mix the message into your PRNG to generate a random number which will therefore
be unique to this message.
Note that you don't have to get anyone else's cooperation in order to do this

@_date: 2013-10-04 17:44:23
@_author: zooko 
@_subject: Re: how to use Tor securely (Re: Silk Road founder arrested ...) 
Thanks for mentioning Tahoe-LAFS, Adam. I think combining Tahoe-LAFS with Tor
is a good idea. It is already almost there. It is usable, but it doesn't
yet protect your anonymity correctly. There is a recent burst of work to
improve usability, security, and performance, and we need help.
Also, below, I'll talk about the different, but complementary idea of
"decentralized web apps" (i.e. Javascript apps hosted on Tahoe-LAFS).
But before we get into decentralized web apps, here's the status of
Tahoe-LAFS+Tor: it is currently working, by using a socks proxy that routes
through Tor and configuring your Tahoe-LAFS instance to use it.  Here are some
open issue tickets about tweaks to the Tahoe-LAFS software or documentation
which are needed:
 use only 127.0.0.1 as local address
 Improve docs about Tahoe-LAFS+Tor
 make tahoe Tor- and I2P-friendly
Note that some of these tickets refer to I2P, which is another re-routing
network sort of like Tor, but the ones I mentioned above are just as applicable
to Tor as to I2P. The tickets mention I2P because I2P developers, in addition
to Tor developers, are contributing bug reports and patches.
There is a recent move to a better approach which doesn't require the user to
configure a socks proxy. That approach is to switch Tahoe-LAFS to using a new
network abstraction provided by the "Twisted" library which Tahoe-LAFS uses.
That abstraction is named "Endpoints". The idea is to switch Tahoe-LAFS from
IPv4 to "Endpoints", and then implement Tor and I2P routing as implementations
of the "Endpoints" abstraction. This approach would also probably work with a
cjdns transport, too. (Also it would help Tahoe-LAFS work over IPv6.)
This approach would also allow other Twisted-based applications (besides
Tahoe-LAFS) to use those interesting new transport layers.
We could use help! If you know Python, please do code-review of these patches:
 switch to using Endpoints
How to review patches:
By the way, we LAFS hackers are well aware that anonymity is very hard. In
fact, low-latency anonymity against a modern "global surveillance" threat model
may be impossible. But even the anonymity properties that *are* possible, and
the ones that are currently provided by Tor, might get ruined by some mistake
that Tahoe-LAFS makes, so I wouldn't rely on the Tahoe-LAFS+Tor for anonymity
until it has had a lot more study and testing. (Which we need help with!)
I don't quite follow this sentence. You can write code that uses Tahoe-LAFS
from Javascript if you want. I think that is a *great* idea, and I think that
it is inevitable that in the future "decentralized web apps" will be written in
either Javascript + LAFS, or else Javascript + some-other-decentralized-
However, if you are not ready to accept the inevitable and start running
Javascript in your web browser, you can also poke at Tahoe-LAFS from plain old
HTML forms, or use Tahoe-LAFS from code (written in any programming language)
running on your local machine.
Here's a live demo of a "decentralized web app" in which all storage in an
encrypted, decentralized, fault-tolerant storage network, and all computation
is in the client -- in fact in the web browser. The demo is my blog:
That link gives you read-only access to my blog. If you interact with it, for
example by clicking on "Tags" or using the search box, then you're interacting
with Javascript running in your web browser. When *I* interact with it (I have
read-write access to my blog), for example by creating new entries or editing
existing entries, then I too am interacting Javascript running in my browser.
There is no server anywhere that has code for the functionality of my blog. All
code that implements functionalit is in the client. The storage server does
nothing but store ciphertext to which it doesn't have the decryption key.
Now, there's a subtlety here that will probably confuse some people. To be
truly *decentralized*, the URL you put into your browser has to start with
" rather than with "
right? So when you look at the URL above, you aren't actually *using* a
decentralized web app, you're looking at a demo of a decentralized web app.
To put it another way, when *I* use  I'm using a
decentralized web app, because I control my own node in the network. When I
allow *you* to use  then you are not controlling your own
node in the network -- you are relying on me and on my node.
But if you install Tahoe-LAFS yourself and connect to the Public Test Grid,
then you can join us in playing with true decentralized web apps. :-)
Start with the newest version of TiddlyWiki, which comes with a Tahoe-LAFS
(The demo above -- my blog -- is a much older and more kludgey combination of
TiddlyWiki and Tahoe-LAFS.)
