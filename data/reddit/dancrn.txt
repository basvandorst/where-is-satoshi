@_author: dancrn
@_date: 2013-09-04 21:29:03
different ALUs implement floating point ops differently. this results in a different noise pattern in the floating point error.
if a standard pack/unpack method was not created/specified, then it might lead to some clients on some family of CPUs accepting blocks that others reject.
@_date: 2013-09-07 12:18:50
that's not the level of reordering i'm speaking of -
    float r = (1.0/x) + (x*y)/2.0;
each sub expression can be done in parallel. IEEE doesn't specify this level of parallelism. in this particular case, no amount of re-ordering should change the value of r. however, when you have larger expressions with lots of sub-expressions, results get computed differently. 
i should also say, i see this variation across compute devices every day (have a job related to high performance computing), so i know it's there :)
as for (2), well, that, in essence, is my point - bitcoind will probably be ported to a large number of different types of CPU. because a fixed point method has been specified, there is no room for error in anybody's implementation. either it doesn't work at all, or it works all the time. 
@_date: 2013-09-05 09:34:04


can we not do that please? that would be pretty uncool.
@_date: 2013-07-16 19:08:51
i just made a [post]( about this..
4 weeks and still nothing.
@_date: 2013-09-04 21:31:24
transaction fees.
@_date: 2013-07-16 16:56:35
the withdraw bounty?
@_date: 2013-09-05 09:28:29
i don't wish to sound rude, but i know how floating point works :)
yes, i know that if an FPU is IEEE conforment, then in principle the result should be bit for bit identical. however, this neglects two issues - 
1) IEEE says nothing about order of operations. Haswell has an instruction window of 192 (i think) instructions, and a metric fuck ton of floating point units. different order -&gt; different result.
2) OK, your CPUs probably conform to IEEE. but what about some random MIPS core? or some other random unknown processor? 
ultimately, if floating point was as standard as you suggest, then there would be absolutely no reason to not use it. even *if* it's inaccurate, if everyone computes the same result, it shouldn't matter - if the difficulty is supposed to be 83,152,000, but is stored as 83,151,301.04585... well, that's hardly going to be a significant change in difficulty these days :)