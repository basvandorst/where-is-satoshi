@_author: aberrygoodtime
@_date: 2015-12-14 06:18:27
The response at scaling bitcoin and otherwise has been pretty resounding.  The community at large does not support BIP 101.
You can listen to some of the discussion here: 
The miner panel was interesting.
@_date: 2015-12-26 17:23:25
LN is a planned addition to Bitcoin Core - and likely prior to that a different open source implementation.  Trust in the client will be motivated in the same way as trust in Core.
@_date: 2015-12-31 06:24:36
This has been covered. Find Maxwells summary, or the dev roadmap, or any post about orphan rates. Thin blocks, iblt propagation, relay networks......
These are all proposals which reduce mining centralization pressure
@_date: 2015-12-16 02:45:25
Maybe will weigh in.
@_date: 2015-12-25 18:21:44
You control two of the three keys.
@_date: 2015-12-16 02:42:42
The block size will have to increase to some degree in the future.  
Aside from that, Greg Maxwell put it nicely during Peter Wuille's recent presentation.  Paraphrasing: We'd like to implement changes as soft forks initially to nail down the economics and details, then after a time hardfork to get the changes organized in a sane way.  This was in reference to implementing segwit as a soft fork before a hard fork to include it in the merkle tree.   
@_date: 2015-12-26 07:16:52
@_date: 2015-12-16 07:38:42
I get that. I guess I'm asking more for your opinion on cost of upgradimg. As more devices join the network there will be more drag, devices that interact with the blockchain may be challenging to update, etc.
As a concrete example consider a segwit hard fork (if it were eventually hard, not soft, forked in).  Every full wallet implementation would have to be updated to understand the new format.  Wallets are a clear use case and easy to upgrade if they run on a pc but as interactions with the block chain diversify one can imagine your coffee pot listening to transactions.
Edit. And things like lightning, colored coins, etc. As more things are bitcoin won't the core protocol become much harder to change?
@_date: 2015-12-14 06:38:06
You can watch here. To me it appeared to be a great forum that was really beneficial to the development community.  There were a lot of great ideas flying around and that's always great for creativity.
As for action items, there were several including segwit and improving east/west relationships.  But due to the nature of this project the conference was really a place for discussion between smaller groups.  Specifics about consensus and direction really emerge in public online channels. 
@_date: 2015-12-16 01:21:27
Every meaningful improvement to Bitcoin will be a fork.
@_date: 2015-12-16 07:17:46
Hey luke, thanks for the insight. To make sure i understand, you don't see a point in the future when hardforks will become impossible? Will they always be about the current level of challenge?
@_date: 2015-12-16 01:19:16
"The nodes that didn't upgrade" is the focus of this question.  This is not a question of hard fork courtesy, but feasibility.
In the future the network will be diverse with implementations of the protocol expecting to be able to talk to each other.  Upgrading 50 implementations which mimic core would be very challenging. 
I'm looking for information on this topic.  
@_date: 2015-12-16 02:48:29
I'd put increased block size in the need category. No matter how you look at it, for bitcoin to work it will have to increase in the future.  I don't think we need it now, though - you are right.
I do think, though, it is probable that we will find a few other, similar needs which will require hard forks to implement.
@_date: 2015-12-14 07:04:24
I agree. I still want to see that graph though.
@_date: 2015-12-14 06:13:54
Does anyone know of a graph showing the current minimum transaction fee included in each block?  I'd bet some miners already don't respect the priority queue.
@_date: 2015-12-19 18:40:39
It doesn't make him look stupid, he clearly disagrees with Gavin's perspective here.  People can disagree, people can be wrong, and be far from stupid.  One or both of them are wrong on this point.
I don't agree with either of them.  There is likely a super-linear dependence on number of participants, so greater than O(n), but less than O(n^2).  
I'd go so far as to say, in the context of each of their arguments, they are both right.
@_date: 2015-12-06 23:50:48
I had a hard time finding the talks I was interested online.  Here are some links:
Schedule: 
* Intro
* BIP99 and uncontroversial hardforks - Jorge Timon
* Fungibility and scalability - Adam Back
* Zero-knowledge proofs for Bitcoin scalability and beyond- Madars Virza
* Security assumptions - Andrew Poelstra
* In adversarial environments, blockchains don't scale - Peter Todd
* Why miners will not voluntarily individually produce smaller blocks - Jonathan Bier
* IBLT and weak block propagation performance - Kalle Rosenbaum and Rusty Russell
* Tampering with the delivery of blocks and transactions in Bitcoin - Arthur Gervais
* BIP101 block propagation data from testnet - Jonathan Toomim
* Miner Panel
* Works In Progress (The first speaker is the coordinator of the conference, well spoken, and worth listening to) 
I think this was everything from today.
@_date: 2015-12-14 06:40:31
Those specs can be had for half the price.  It is definitely an expensive option.
I like them though, they are a good option as well.
@_date: 2015-12-19 18:33:59
The idea that BIP202 or any proposed increase is conservative is flawed.  Compromise can result in a choice which is sub-optimal.  
There is a right answer here, we just don't have enough knowledge to discern what it is.  
@_date: 2015-12-31 16:33:30
As asics plateau in efficiency there will be more time for the physical hash power to distribute, resulting in (a slightly) less centralized set of miners.  
I also see the possibility of altruistic mining drastically affecting the mining landscape. Or mining for device functionality rather than profit (21inc).  Both of these could possibly push us twoards a more acceptable level of centralization. And both will play a larger role when efficiency plateaus.
In this sense I have hope. Even if the roadmap only keeps the bitcoin ecosystem evolving.
@_date: 2015-12-21 04:22:31
Attacks referenced: (VC = Virtual Currency)
**Level I and II**
* DDOS
* 51%, not specifically by accruing mining power but instead compromising mining pools via hacking or otherwise. "In such a manner, an attacker with 
relatively little initial resources could mount a 51 percent attack on Bit-
*  Compromising 3rd parties, either degrading service or stealing keys
**Level III and IV**
* Zero day attacks, vague references to this consensus code implicating hard forks
* Zero day attacks to take control of pool operators and 51%. "Even in the decentralized case, advanced opponents 
can successfully exploit specific targets with high probability and canpublically target high-net-worth individuals to reduce confidence in 
the currency (or can randomly target average citizens to sow distrust)."
* "Tier IV opponents would likely have the capability to construct 
and use zero-day exploits against critical VC services such as exchanges and wallets as well as cell-phone applications used to conduct everyday transactions. Indeed, they may look to use fake permissions and certificates to install applications that subvert (or spy on) user VC applications. They would then either disrupt those applications or publicize vulnerabilities to degrade confidence in a VC."
**Level V and VI**
* Supply chain attacks. "Weakening of hardware, backdoors in hardware and software. They might target cell phones or other hardware, including computers used as servers for critical VC services or special-purpose hardware used for mining, and corrupt them before delivery."
* Broken cryptography.
* Human attacks. "to bribe or otherwise co-opt such per-
sonnel, either within a VC’s organization or at other organizations that provide critical services to a VC."
* "A sophisticated nation-state is 
the most capable actor to ensure this security, which is another reason 
why a VC has the greatest chance for cyber survival when a non-state 
actor is supported by a nation-state that possesses cyber sophistication. 
At the very least, the level of sophistication and investment to success-
fully attack a VC would be raised, making any opponent’s decision 
calculus to attack a VC more complicated."
@_date: 2015-12-02 15:52:49
Title is a bit misleading - he says proof of work in general will win over all other consensus systems - not specifically Bitcoin's sha256 based proof of work.
@_date: 2015-12-04 21:31:18
Regardless of how successfully this can be implemented, the whitepaper is a trove of clever optimizations to bitcoin.  The Local Route Optimization Protocol to optimize miner communication seems especially neat.  Do you know how much of this is novel?
Edit: Also, fraud proofs.  How neat.
@_date: 2015-12-15 15:37:18
Is there somewhere I can read about this? I haven't seen this presented.
@_date: 2015-12-10 03:28:56
Bitcointalk thread link anyone?
@_date: 2015-12-30 20:28:25
Wuille didn't invent Segwit.  Its been a part of Elements for a while.  I think Juke-Jr came up with a way to soft fork it.
Still a great intro to watch by a very informed dev.
@_date: 2015-12-25 20:38:50
Your vault is a 2 of 3 multisig bitcoin address.
@_date: 2016-01-20 20:23:21
Classic and this are, in the long run, equivalent.
@_date: 2016-03-11 22:51:21
BTC is held in escrow via multisig until seller releases.  Arbiters step in when there is a dispute.  Think openbazaar.
@_date: 2016-01-23 20:53:44
It's also a build argument. Avoids needing BerkleyDB.
--disable-wallet        disable wallet (enabled by default) 
@_date: 2016-03-29 18:37:32
Hey thanks for the info. I haven't used a GUI version of core for several versions.  Just to clarify, is there an easy way to manipulate the UTXOs I include in my transaction?
@_date: 2016-01-08 03:02:32
Gotta downvote the stuff you agree with.  Makes sense.
@_date: 2016-03-13 23:02:29
Latency across the firewall goes so far as to improve revenue of miners in china. It's a benefit not a penalty.
@_date: 2016-01-23 20:54:21
This was it, thanks.  Do you think a pull to include this in the build instructions in /doc would be silly?
@_date: 2016-03-12 19:28:25
What has this sub become.
@_date: 2016-01-12 22:54:32
I'd add more ranges for up speed.  You also probably meant Kb.
@_date: 2016-03-08 14:50:20
@_date: 2016-01-09 06:01:11
Your argument barely supports any increase, not even an order of magnitude. Unless your solution scales 100x its not meaningful.
@_date: 2016-01-08 03:09:51
Great looking user experience.
@_date: 2016-01-11 04:30:01
This is irrelevant in the world of bitcoin. We are building a trustless system. We should not need to envoke the embarassingly inefficient legal system.
This is precisely the type of situation bitcoin seeks to make obsolete.  And in this, Todd's actions have spoken volumes.  
@_date: 2016-06-03 17:25:17
My issue was with permissions of the authcookie.  If bitcoind and tor run as different users there are issues.  I added the bitcoind running user to the same group as the tor running user - in my case debian-tor.
@_date: 2016-06-03 17:25:02
My issue was with permissions of the authcookie.  If bitcoind and tor run as different users there are issues.  I added the bitcoind running user to the same group as the tor running user - in my case debian-tor.
@_date: 2016-06-01 02:54:51
Yes thank you.  
I relied on this guide which suggested a hidden service would be created automatically.
At this point I could use some guidance.  I may have interpreted point 3 on that page incorrectly.  For point three I have to pass -listenonion -torcontrol and -torpassword? (This I did not do)
Is there a best practice configuration for supporting both networks?
Thanks again.
@_date: 2016-02-15 15:48:28
They model circuit area as inversely proportional to hash rate.  Is this true or is area related to power density and other factors which might improve this optimization's effectiveness further.
@_date: 2016-02-02 23:52:08
Great link.  This was a neat toy for learning as well: 
@_date: 2016-02-17 16:23:54
Great explanation.
@_date: 2016-02-01 22:12:48
Bitcoin mining works by brute forcing SHA(SHA(previous block's headers + the nonce)).  In this scheme the nonce is a random number is adjusted and the hash calculated until a result less than that set by the difficulty is obtained.  This is proof of work.
In this way the nonce is guaranteed to be somewhat random and large.
In this proposal new blocks must contain, in addition to the proof of work, a "proof of data".  This is the SHA3-512 hash of the nonce-th byte of every block in the blockchain. In order to calculate this, a miner must find an acceptable proof of work (and thus, nonce), take that nonce and calculate a hash.  This hash requires data from every previous block in a way which is not predictable until the nonce is known.
In this way miners will have to have a complete copy of the blockchain to mine and/or gives nodes something valuable they can sell to miners (precomputed hashes for various nonces).
From the article: 


*Edit* See dooglus below for some important clarifications.
@_date: 2016-02-18 22:40:41
Hey this is neat.  You show a compression of about 12x - this is for the block propagation at the chain tip, right?  And the benefit is primarily reduced latency for propagation?
Can you give me a sense of what portion of total bandwidth a node uses comes from the new block download and broadcast?  My current impression is that the majority of our bandwidth usage right now comes from getting new nodes a copy of the blockchain.
Still, this is great from a latency/mining perspective and its interesting to see real numbers.
@_date: 2016-02-19 16:20:27
Good tip, especially that transaction data changes depending on time of creation. Hum.
@_date: 2016-02-29 06:12:33
Nice. Immutable and readable.
@_date: 2016-02-02 20:37:39
Thanks, these are really important distinctions I missed. 
The core clarification is that POW depends on current headers and thus the proof of data. So for every nonce tried, the proof of data must be generated.
@_date: 2016-02-15 15:41:42
This makes some nonce+header combinations impossible to hash accurately.  I don't think there will be any effect on the distribution of block times though - the choice of nonce and headers is already random enough - there are many solutions, excluding some solutions only makes the effective difficulty higher.  Maybe some slight effect based on the number of valid vs invalid solutions per block, but when were trying billions of nonces per block its not going to make much difference between blocks.
Edit. I think I'd rather say, the important parameter your referencing is errored valid solutions / valid valid solutions per block. If this differs between block we will see it in the distribution of block times. My argument is that sha is so stochastic that the valid/invalid fraction will be identical for every block.
Further, if somehow this wasn't the case, the fraction would have to be significantly different block to block for us to notice as an increase in block time variance. This is due to the inherent variance already being high.
@_date: 2015-10-28 17:41:43
Thanks for the answer!  I'm sure you've thought about this but randomizing the query times for the XPUBs in sentinel wmight be nice, rather than always querying them together, even in the tor case. I guess there are a lot of similar considerations, and limiting the linkage of addresses which are only associated in your wallet would be and interesting challenge.
Aside, I like the app even if it is unsuitable for isolated sets of addresses!
@_date: 2016-05-25 15:04:33
A great guide.  In simple terms - if you install recent versions of tor and bitcoin core your node will automatically be advertised on both networks.  This is what you want from a network health perspective - more precautions are needed when the goal is personal anonymity.
@_date: 2015-10-28 03:08:12
I'm late to the party but I had a question - does sentinel store my public keys anywhere but on my device?  Are they stored encrypted on my device?
Linking addresses to personas is a concern. I'm trying to decide if the addresses I add to sentinel will be linked together in a way which may be obtained by others.  I hope they aren't sent to your servers or anywhere but the device.
An answer would be great, though we really won't know until you disclose the source!